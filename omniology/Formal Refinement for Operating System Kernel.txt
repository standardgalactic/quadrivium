Formal Refinement for Operating System Kernels 

123
Iain D. Craig
Formal Refinement
for Operating System
Kernels

Printed on acid-free paper.
9 8 7 6 5 4 3 2 1
springer.com
e-ISBN
..
Iain Craig, MA, PhD, FBCF, CITP
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
ISBN 978-1-84628-966-8
978-1-84628-967-5
Library of Congress Control Number: 2007931774 
The publisher makes no representation, express or implied, with regard to the accuracy of
the information contained in this book and cannot accept any legal responsibility or liability
for any errors or omissions that may be made.
Apart from any fair dealing for the purposes of research or private study, or criticism or
review, as permitted under the Copyright, Designs and Patents Act 1988, this publication
may only be reproduced, stored or transmitted, in any form or by any means, with the
prior permission in writing of the publishers, or in the case of reprographic reproduction in
accordance with the terms of licences issued by the Copyright Licensing Agency. Enquiries
concerning reproduction outside those terms should be sent to the publishers.
The use of registered names, trademarks, etc. in this publication does not imply, even in
the absence of a speciﬁc statement, that such names are exempt from the relevant laws and
regulations and therefore free for general use.
c⃝Springer-VerlagLondonLimited2007

To my Father at 75

Preface
This book was written as a companion to my book on modelling operating
system kernels. It is intended to demonstrate that the formal derivation of
kernels is possible (and, actually, quite easy, or so I have found thus far).
It is important for the reader to understand that the reﬁnements contained
in this book are not the only ones I have performed of microkernels. To date,
I have reﬁned four microkernels down to executable code and have now pro-
duced a kit of formally speciﬁed components that can be composed to form
kernels. The ﬁrst kernel included in this book is just one example of this work.
The second kernel, the Separation Kernel, is new and was partly constructed
out of the kit of parts (and the reader will see reuse in its speciﬁcation and
reﬁnement) and was included for speciﬁc reasons that will become clear anon.
Both kernels took less than three months’ working time to produce (the actual
time is rather hard to calculate because of frequent interruptions). Previous
experience in reﬁning kernels also paid oﬀin the sense that there was lit-
tle revision involved in their speciﬁcation or reﬁnement; the usual process of
yo-yoing between levels of the derivation was absent. This appears to be an
inevitable consequence of experience.
The time factor has been important in the production of the various kernels
that I have derived. The micro kernel helps in no little way by imposing the
rule that the kernel should be as small as possible. This is not to say that I
would not be interested or willing to reﬁne a kernel such as the second one
I modelled in [4]. Such an exercise would be extremely interesting and one
I would very much like to undertake; however, it would require time (and I
am quite willing to put it in) and would require ﬁnancial support. In today’s
climate, one would probably also have to ask what the point of such an exercise
would be.
It is necessary to position this book. Mainly, I believe it to be an essay
in formal methods software engineering and in operating systems. It can be
argued that this book is a contribution to reﬁnement, in particular, to re-
ﬁnement in the large. There is nothing in the literature on the scale of the
reﬁnements that are the subject of this book, as far as I am aware.

viii
Preface
The Separation Kernel was included for speciﬁc reasons. First, there is at
least one document from the US National Security Agency (NSA) recommend-
ing the Separation Kernel as the cryptographic kernel par excellence. In their
documents, the NSA also states that the formal speciﬁcation of a Separation
Kernel would be highly desirable. Having looked at the various documents,
the original paper by Rushby [11] in particular, the structure and functioning
of the Separation Kernel appeared to be fairly simple. This would appear to
have been one of the goals that Rushby had in mind when deﬁning the archi-
tecture in the ﬁrst place—it is another good example of how simplicity wins
every time (Less is more.) As a result, I wondered what a speciﬁcation would
look like. What I found was what I expected. The result was quite easy to
specify and to reﬁne.
The reader will observe that there is little or nothing about bootstrapping
or hardware-speciﬁc initialisation. This is because we do not consider these
matters to be part of the kernel; they belong to the environment within which
the kernel executes.
I think it necessary to make a couple of observations about the reﬁnement
itself. In the Z literature, two kinds of reﬁnement are described: one relational,
one functional. The relational reﬁnement is the worst-case scenario. The func-
tional reﬁnement is, in my experience, the usual case. Indeed, in more than
twenty years’ experience reﬁning speciﬁcations, I have found that the rela-
tionship between the abstract and concrete statements is almost always an
identity. This experience is not restricted to kernels (of course) for a great
deal of the code I have produced during that time has had at least some for-
mally speciﬁed component (usually the components that are the hardest to
understand). The code has included virtual machines and parts of compilers,
so it is quite varied. For this reason, the fact that the abstraction relations in
this book are identities does not cause me any concern. (Steve Schumann re-
ports in a private communication the same experience.) I decided that proofs,
which are strictly unnecessary when using a functional abstraction relation,
should be included in the book. This was to show how they enter the reﬁne-
ment process and to show that they are relatively simple (given the prevalence
of identity relationships, proofs of similar complexity are to be expected and
that is a level of complexity that can easily be handled). Furthermore, I wanted
to counter the claims that either the proofs could not be done or that they
were too complicated; neither is the case. In the case of the Separation Kernel,
a number of proofs are omitted (this was also for the reason that space was
getting short and devoting much more space to such a simple system did not
appear warranted). This is particularly the case with operations deﬁned over
conjunctions of state spaces. The proofs and preconditions of the components
are given, as are the abstraction relations, so the production of the required
proofs is a straightforward matter and can be produced in a relatively short
period. In each case, the compound operation was checked against the com-
ponents and short (i.e., outline or sketch) proofs produced as a safety device.

Preface
ix
The purely textual parts of this book were written using voice-input soft-
ware because my daily typing time was severely restricted on medical advice.
Using voice-input software for the ﬁrst time was an interesting and sometimes
frustrating experience. The frustrations were mostly due to my being so used
to typing and I found that having to speak rather than compose on the key-
board sometimes confusingly diﬃcult. In particular, initially, I found it quite
hard to navigate back and forth using just voice commands. (It led to the
occasional and unwanted inclusion of expletives in the text and I hope that
I have removed them all!) With greater experience, it turned out to be an
eﬀective method for producing text. It is worth trying!
A Note on Interrupts
When I started out, it was conventional wisdom that interrupts should be
disabled for as short a period as possible. The reader will note that the space
between disabling and enabling interrupts in the speciﬁcations and reﬁnements
that follow can be rather large. In some case (e.g., the interface routines at
the end of Chapter 3), the reason for this is that I wanted to emphasise the
fact that interrupts should be disabled for some part of the operation (for
reasons that will become clear in a second, without necessarily being forced
into saying which parts). Some processors have pipelines that might aﬀect
the exact time at which the interrupt operation is performed; this cannot
be taken into account until the processor is known, so the safe option was
chosen. In addition, the period during which interrupts are disabled can be
extended when the desired response time of the system is known (here, we
have no such knowledge). In such a case, the interrupt operations can be
moved using the distributive law (p ∨(q ∧r) ⇔(p ∧q) ∨(p ∧r)) and the
idempotent laws (p ∧p ⇔p and p ∨p ⇔p). In the other cases, the change
to the interrupt ﬂag (or whatever mechanism is used on the implementation
platform) might have some interaction with another part of the system (e.g.,
on the IA32, if the INT bit in the EFLAGS register is not the same value as
the processor interrupt ﬂag, the system will crash); again, without knowing
the exact hardware, precise location of the interrupt operationsis impossible.
Acknowledgements
First of all, I would like to thank Beverley Ford for agreeing to publish this
book. Thanks are due in equal measure to Helen Desmond for making the
process of producing this book as painless as possible. They have jointly per-
formed the proof and copy editing stages of the test in order to expedite its
publication. I would like to thank Steve Schuman for reading the manuscript
while it was in sketch and in a more developed form and for a number of
extremely interesting discussions on the reﬁnement process (any errors are,
naturally, my own fault). Considerable thanks are due to my brother, Adam.
Once again, he drew the ﬁgures for me; in addition, he patiently typed those

x
Preface
parts from my dictation that could not easily be done using voice-input soft-
ware. Without his dedicated eﬀort, the text of this book could not have been
completed. As for the others who have helped (the regulars), as always, I oﬀer
my thanks.
Iain Craig
North Warwickshire
April, 2007

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Reasons for Selecting the Examples . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Reﬁnement Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.3
Code Production . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.4
Organisation of this Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.5
Relationship to Other Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2
The Simple Kernel’s Organisation . . . . . . . . . . . . . . . . . . . . . . . . . 11
3
A Simple Kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3.1
Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3.2
Hardware. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
3.3
The Process Table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.3.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.3.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
3.3.3
Reﬁnement Two. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
3.4
Process Queue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
3.4.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
3.4.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
3.4.3
Reﬁnement Two. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.5
Priority Queue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
3.5.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
3.5.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
3.5.3
Reﬁnement Two. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
3.6
The Scheduler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
3.6.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
3.6.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
3.6.3
Reﬁnement Two. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
3.7
Semaphores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
3.7.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
3.7.2
Reﬁnement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

xii
Contents
3.8
Semaphore Table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.8.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.8.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
3.8.3
Reﬁnement One–Again . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
3.9
Synchronous Messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
3.9.1
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
3.9.2
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
3.9.3
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
3.9.4
Reﬁnement Two. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
3.10 The Clock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
3.11 Sleepers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
3.11.1 Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
3.11.2 Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
3.11.3 Reﬁment Two. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
3.12 User Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
3.12.1 System Initialisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
3.12.2 Process Creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
3.12.3 Process Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
3.12.4 Inter-process Communication and Synchronisation . . . . . 198
3.12.5 Clock Operations and the Clock ISR . . . . . . . . . . . . . . . . . 201
3.12.6 Final Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
4
The Separation Kernel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
4.1
Basic Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
4.2
Extending the Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
4.3
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
4.4
An Overview of the Formal Speciﬁcation . . . . . . . . . . . . . . . . . . . 207
5
A Separation Kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
5.1
Basic Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
5.2
Hardware Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
5.3
Security Exits and Return Values . . . . . . . . . . . . . . . . . . . . . . . . . . 218
5.4
The Process Table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
5.4.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
5.4.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
5.4.3
Reﬁnement Two. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
5.5
Process Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
5.5.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
5.5.2
Reﬁnement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
5.6
The Scheduler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
5.7
Storage Pools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
5.7.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
5.7.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
5.8
Raw Storage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
5.8.1
Top level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264

Contents
xiii
5.8.2
Message Buﬀering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
5.9
Message Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
5.9.1
Top Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
5.9.2
Reﬁnement One . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
5.10 Kernel Interface – User Processes . . . . . . . . . . . . . . . . . . . . . . . . . . 286
5.10.1 Auxilliary Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
5.10.2 Initialisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
5.10.3 Process Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
5.10.4 Message Passing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
5.11 Devices—Trusted Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
5.11.1 Device replies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
5.11.2 Device numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306
5.11.3 Device process creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
5.12 Process Interface to the Kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
5.13 Final Thoughts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316
6
Closing Thoughts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
List of Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325

List of Figures
1.1
The NSA cryptographic architecture. . . . . . . . . . . . . . . . . . . . . . . . .
6
2.1
Organisation of the simple kernel. . . . . . . . . . . . . . . . . . . . . . . . . . . 15
4.1
Devices and interfaces in the Separation Kernel.. . . . . . . . . . . . . . 206
4.2
The internal organisation of our Separation Kernel. . . . . . . . . . . 207

1
Introduction
This book is a follow-up to our earlier one on the modelling of operating
system kernels [4]. The aim of that book was to argue that formal speciﬁ-
cation of kernels was possible in the sense that formal modelling could be
undertaken and then followed by a speciﬁcation, a design and then reﬁnement
to running code. The ﬁrst part of this was the subject of [4]. This book is
concerned entirely with the speciﬁcation, design and reﬁnement to executable
code of two operating system kernels. One kernel is of the kind found in small
systems, while the other is intended for use in cryptographic and other secure
systems. The book does not contain reasoning about models and concentrates
on reﬁnement. The reﬁnements are from abstract or high-level speciﬁcations
to a level at which programming language code can be immediately derived
by obvious translation from the last stage of the reﬁnement process.
In [4], it was our aim to show that detailed models were useful. This allows
designers to identify properties of their designs without the need to construct
a system. This could well have economic advantages and might spark new
and necessary work in the general area of operating systems. It was also
argued in that book that the post hoc veriﬁcation of systems, particularly
critical systems and components such as kernels, was not a good solution to
the problem of reliability; instead, we argued that a synthetic method was
superior.
The main purpose of the book is to demonstrate that the reﬁnement of for-
mal speciﬁcations of (micro) kernels is possible and, moreover, quite tractable.
This should be obvious, given the fact that it is possible to model a (micro)
kernel formally. The reﬁnement is a process of documentation, as well as proof
and justiﬁcation, so it is worthwhile to record it, thus adding weight to the
argument at the start of [4].
A secondary purpose is to give examples of reﬁnements that are larger
than those we have found in the literature. There are issues raised by the
reﬁnement process that are never considered in the standard literature:
•
How many reﬁnements should complex operations receive?

2
1 Introduction
•
When should implicit preconditions be used?
•
When is it worth relying on the properties of functional abstraction rela-
tions?
Some might now argue that this is not a complete speciﬁcation and
reﬁnement because we have not included device drivers and low-level device-
interface code. Some might even go as far as to claim that this is not possible
because, for example, it involves bitmasks; it also requires processes to wait
for ﬂags to change state. It is our opinion that the formal speciﬁcation of such
things is possible; this opinion is based upon experience with small examples
and with the speciﬁcation of low-level operations (for example, the bitmap
that is used as the basis for the semaphore table in the ﬁrst reﬁnement below;
we also speciﬁed some generic device-handlers while writing [4] but they had
to be omitted for reasons of time and space).
In any case, at this point, we cannot specify the actual pieces of hardware
that might be controlled by this book’s systems. For this reason, we have
to be as generic as possible, so we have concentrated on the speciﬁcation
of portable systems. This does mean that we have ignored low-level issues.
On the contrary, we felt it essential that context switches and other essential
kernel operations should be included in the speciﬁcation. The approach we
have taken is that the hardware and instruction set is a given and cannot be
further reﬁned. One aim of the work reported here was to reduce the assembly
language programming to the level of triviality, thus making it possible to
encapsulate the assembly language in a couple of operations1.
As can be seen from the speciﬁcations, interrupt-driven architectures are
assumed, thus rendering the interface between the software and hardware
speciﬁcations as small as possible. The context switch is thus reduced to a
single instruction, one which raises an interrupt. The major part of the hard-
ware speciﬁcation is as generic as this. For the hardware architecture we have
in mind, this is quite adequate and represents a reasonable speciﬁcation of it;
for other architectures (e.g., MIPS), it might be necessary to reﬁne, perhaps,
the high-level operations deﬁned here.
By the publication of this book, we have shown that it is possible (and
relatively easy) to specify small kernels and reﬁne them to running code. What
we have not done is try to specify a monolithic kernel such as the one used by
Linux. One reason for this is that we do not care very much for the monolithic
kernel for the reasons that it is too tempting just to add a feature to such a
kernel on the grounds that there is nowhere else to put it (i.e., it is tempting
not to solve a problem, just to throw things into the kernel); that is, the
monolithic kernel does not require a clear separation of kernel versus non-
kernel functionality. This lack of distinction has many implications for the
performance of the resulting system. Instead, we prefer a smaller kernel that
1 We write this as if assembly language were some kind of toxic material. There is
no a priori reason why one cannot formally specify assembly-language programs,
even though it is rarely done.

1.1 Reasons for Selecting the Examples
3
includes only those functions that are necessary. We prefer not to engage in
further justiﬁcation of our position; like many such debates, it is based upon
a combination of technical and æsthetic factors.
1.1 Reasons for Selecting the Examples
This book contains the speciﬁcation and reﬁnement of two kernels:
1. A small and simple kernel.
2. A microkernel for cryptographic and other secure applications. This kernel
is an instance of the Separation Kernel concept of Rushby [11].
The ﬁrst kernel is related to the µC/OS kernel of Labrosse [8], a kernel
that has been employed in a number of real-time and embedded systems. The
kernel speciﬁed and reﬁned in this book is also a close relative of the ﬁrst
kernel model in our [4]2.
Another reviewer complained that the speciﬁcation we gave in another
paper was too simple to be of any use in real systems. We need to address
this point because it could be levelled by the same reviewer of this work. The
small kernel that is reﬁned in this book is similar to µC/OS and other kernels
for small systems. We have read the code of such systems, and also used
them, over the period of a good many years. The kernels that we have looked
at are not undergraduate exercises or simpliﬁed versions, they are real kernels
that are used in real applications. The initial design of the small kernel is
based upon this experience. It was intended that the level of functionality be
such that it could be used with only minor modiﬁcation (context switch and
interrupt enable/disable operations) in a real application. The modiﬁcations
expected require only minor modiﬁcations to the formal speciﬁcation; the
remainder would remain the same.
It is true that we have not included sophisticated real-time scheduling
methods. However, the kernels that we have inspected and used do not con-
tain them, either; to claim that we have an unrealistic, over-simpliﬁed system
because it lacks some particular real-time scheduling algorithm appears unrea-
sonable. It is also true that we have not included alarm timers. The reasons
for this are that they are not always provided by the kernels that we have
2 A reviewer of a paper we wrote on this kernel strongly objected to the use of
the adjective (they said “term”) “real-time” in connection with this model. They
claimed that the model could not be of a “real-time” system because it does not
contain any temporal operators. There is a number of replies to this: (i) C and
Ada are “real-time” programming languages but they do not contain temporal
operators (and their formal semantics do not required them); (ii) there is a con-
siderable number of small kernels similar to ours, µC/OS being one example, that
are used in the development of “real-time” systems. We have read the descrip-
tions, speciﬁcations and code of quite a few of these systems and have failed to
locate a single temporal operator.

4
1 Introduction
examined or used and that they are not particularly diﬃcult to specify and,
therefore, to reﬁne to code using the formal method. If we extend the small
kernel, asynchronous events such as alarms will constitute the ﬁrst extension.
In brief, the kernel is composed of the following components.
•
A process representation (the process table).
•
A scheduler based on a priority queue.
•
Semaphores in a global semaphore table.
•
A simple synchronous message-passing system.
•
A mechanism for putting processes to sleep for a speciﬁed period of time.
(There is no alarm mechanism in this kernel, however).
•
A set of initialisation and interface routines so that user-supplied code can
call kernel operations (i.e., perform system calls).
User processes execute in the same address space as the kernel. To produce a
working system, the code for user processes is linked to that of the kernel and
the result bootstrapped somehow (this is considered outside of the speciﬁca-
tion, being, really, a processor-speciﬁc matter). Storage must be allocated by
the user. This implies that they must deﬁne a memory map when designing
their system.
It seemed appropciate to select this kernel as the ﬁrst example reﬁnement
because
•
It is a relatively simple example of a kernel. It contains no storage man-
agement, device drivers or Interrupt-Service Routines (ISRs).
•
It makes few assumptions about the hardware upon which it runs. Indeed,
it is quite portable; only a relatively few lines of code need be changed
when porting to another processor.
On the other hand, the very simplicity of this ﬁrst kernel is a problem
precisely because it is processor-independent. In particular, there are no de-
vice drivers and ISRs to specify (other than the simple one for the clock).
The speciﬁcation and reﬁnements employ a hardware model that is relatively
general and portable; indeed, it can be employed on a number of processors.
However, the interrupt mechanisms of processors vary considerably, so the
speciﬁcation included here is tailored to the Intel IA32 architecture3.
We could have included speciﬁc hardware devices into the speciﬁcation
and its reﬁnement just to show that it is possible. This was not done be-
cause we want this kernel to be portable and the inclusion of a speciﬁc device
might have suggested that we were not being portable. In addition, we had
already encountered space problems with this book and the inclusion of the
description of a hardware device, its interface and the speciﬁcation of its ISR
3 The MIPS has also been considered and would have been used. However, we found
problems with the GNU C compiler for the simulated MIPS that we intended to
use.

1.1 Reasons for Selecting the Examples
5
and driver would have caused us to omit the Separation Kernel’s speciﬁca-
tion, something we preferred not to do. We hope to specify a device’s support
software elsewhere in the near future.
The second example is the Separation Kernel introduced by Rushby in
1981 [11] for secure systems. The Separation Kernel derives its name from the
fact that user processes are separated from each other both in space and in
time. This implies that the address spaces of all user processes are disjoint
and that the time during which one process executes can be identiﬁed as
being diﬀerent from that during which any other user process executes. The
Separation Kernel is intended as a simulation of a distributed system. In a
distributed system, in theory, all processes execute on their own processor,
thus aﬀording disjointness of address space. In addition, the execution of one
process occurs on a processor during a particular time but does not aﬀect
the execution of other processes on other processors. Thus, one can say that
process P1 executes on processor p1 during the period t1 . . tn, while process
P2 executes on processor p2 during the period ti . . tm.
The problem is to translate this scheme to uniprocessor systems. This
can be done by ensuring that all address spaces are disjoint, say by means
of segmentation. Temporal separation can be had by ensuring that only one
process executes at any point in time. Temporal separation is easy to arrange
on a sequential processor (indeed, it is so obvious a property that it can be a
little hard to explain convincingly).
The reasons for including the Separation Kernel are as follows:
•
It is a little-known architecture and its speciﬁcation and reﬁnement are
novel.
•
It is a simple architecture and is, thus, easy to specify and reﬁne in a few
pages.
•
It is an architecture that was explicitly deﬁned for applications that
should demand a formal approach to software development. Indeed, the
US National Security Agency has stated [10] that the formal speciﬁcation
of Separation Kernels is highly desirable.
The speciﬁcation and reﬁnement in this book follow the recommenda-
tions of the National Security Agency’s document [10]. The Separation Kernel
proper is a microkernel that is formally speciﬁed. Upon the microkernel, there
is a layer of so-called “trusted” code, principally device drivers and associated
code. This trusted layer need not be formally speciﬁed but its speciﬁcation,
design and construction is carefully monitored so that it cannot engage in
activities that would compromise the security of the system. Above this layer
comes user-supplied code. This code is completely untrusted and can perform
any activity and might be compromised in some way; although one might
want this layer to be formally speciﬁed and tightly controlled, it is unlikely
that it will be, at least in the near term. The overall architecture is depicted
in Figure 1.1.

6
1 Introduction
User Processes
(untrusted)
Device
Processes
(trusted)
ISRs
(trusted)
Separation 
Kernel
External 
Environment
Fig. 1.1. The NSA cryptographic architecture.
The Separation Kernel itself is organised as follows (the reader will see
that it is a simple structure):
•
A process representation.
•
A round-robin scheduler.
•
Asynchronous inter-process message passing.
•
Storage allocation mechanisms.
In addition, the speciﬁcation includes:
•
An interface for system calls from user processes.
•
A collection of operations to support the construction of ISRs and device
drivers.
These two last items are added so that the security of the system can be
enhanced.
Our speciﬁcation assumes that the processor upon which the microkernel
executes supports segmentation. It was decided that virtual storage would not
be included for the following reasons:
•
Virtual storage requires some form of external store for page swapping.
This would commit the speciﬁcation to a particular hardware conﬁgura-
tion, which was considered undesirable.
•
It is possible in principle that external virtual storage can be attacked
by malicious persons (e.g., corrupting or replacing pages). This was also
considered undesirable.

1.2 Reﬁnement Method
7
It was, therefore, assumed that all user processes would reside in main storage
and that they would be composed of two memory segments (the GNU C com-
piler generates two segments); they would be, in any case, memory resident.
The kernel would also be memory resident. It would reside in segments that
are disjoint from all others. Device drivers and ISRs are trusted code, so can
be stored in the same segments as the kernel. This is more of an optimisation
than anything else because it was considered that the time required to perform
an address-space switch would not be tolerable for device-related code. Since
this kind of code is trusted, it can be assumed that it will not interfere with
the operations of the kernel (which is, in any case, an opaque chunk of code as
far as they are concerned). The loading of user-process images into main store
is something that we do not consider here (it is a matter that depends upon
the hardware conﬁguration); indeed, we have it in mind that the Separation
Kernel would probably run on a co-processor. Finally, it was assumed that the
processor would provide some mechanism for detecting illegal cross-segment
references (segmentation errors) and that an ISR could be written to handle
such references.
The assumptions of segmentation and cross-segment reference detection
are reasonable. There are many processors supporting these features. The
Intel IA32 and IA64 series of processors support them, for example.
For a full security kernel, it is necessary to write a formal security policy.
This is an abstract model of the system that shows how violations of temporal
and spatial separation are handled. This model has not been included in this
book for the reason that it is not strictly relevant to the current task. However,
readers should note that such a model for this speciﬁcation is in the process
of being documented and the relevant proofs are being undertaken.
1.2 Reﬁnement Method
The method adopted in this book follows the conventional approach as deﬁned
by Spivery [12] and Woodcock and Davies [13].
First, an abstract speciﬁcation is created, then a reﬁned version (the con-
crete version) is created; the two are then related by the deﬁnition of an
abstraction relation. Proofs are then undertaken to show that concrete opera-
tions represent abstract ones correctly. The concept of correctness reduces to
showing the following two properties. First, the states in which an abstract
operation can start are also, modulo the abstraction relation, those states in
which the concrete one can start. Second, it is shown that if the abstract
operation terminates in a state, s, then the concrete operation terminates
in a state, sc, that is related to s by the abstraction relation. In addition, a
theorem is proved that the initialisation of the two state spaces are equivalent.
Once this has been completed, what was the concrete version becomes the
new abstract version. A new concrete representation and abstraction relation
are deﬁned and the process iterates.

8
1 Introduction
For the speciﬁcations in this book, some modules required no reﬁnement,
while others required two steps. In some cases, therefore, a state space was
deﬁned that does not require reﬁnement; this is done when the state space
consists of simple variables that are just updated by simple assignments.
Example cases are the clock in the ﬁrst reﬁnement, parts of the scheduler
in both reﬁnements and the semaphore counter component in the ﬁrst speci-
ﬁcation. In contrast, there are modules that required three reﬁnement steps.
It could be argued that two steps could be used instead. The reduction to
two steps would, in our opinion, have made the reﬁnement process less clear
and clarity is an essential aspect of system design as well as documentation.
The PROCESSQUEUE and PRIOQUEUE types both require two reﬁnement
steps: one from an abstract speciﬁcation to an array-based representation and
then to a representation based on the next attribute in the process table. The
reader could try to reﬁne the top-level speciﬁcation to the one using next; it
is certainly possible but, we consider, less clear than the three-step version.
In addition, the abstraction relation is an identity4. This makes proofs
particularly simple. Indeed, because identity is a functional relation, the re-
ﬁnement process can be modiﬁed slightly, as outlined in [13]. Woodcock et
al. show how the operation schemata can be calculated from the abstract
speciﬁcation and the abstraction relation. This has the implication that the
proofs listed above need not be undertaken because they are guaranteed by
the abstraction relation.
In this book, particularly in the ﬁrst part, proofs are included; in the re-
ﬁnement of the separation kernel, some proofs are given but not others. In
both exercises, the reader will see that the abstraction relations are all identi-
ties. We could have omitted the proofs in the reﬁnement of the ﬁrst kernel. We
preferred not to do this for a number of reasons. First, we wanted to show how
the full method operates on a scale somewhat larger than those usually found
in the published literature. Second, we wanted to include proofs to counter the
claim that they were either impossible, unintelligible or excessively complex;
they are none of these and are all quite straightforward. In another of the
kernel reﬁnements that we have performed (but not published), some proofs
did cause problems which were eventually resolved. Third, we also wanted
to show how proofs are still possible even when working on conjoined state
spaces. Fourth, undertaking a proof is a good way to gain a better understand-
ing of the operation and it is also useful as a way of checking the abstract
and concrete operation speciﬁcations as well as the abstraction relation. In
another piece of work, we deﬁned a concrete operation in a way that looked
entirely sensible but it was found that it caused a revision of the abstraction
relation which, it turned out, had not been properly thought out. Such er-
rors or misconceptions should not be a cause for censure. Instead, they are
valuable.
4 This is something that we have found in almost every reﬁnement we have done
over the last twenty-odd years.

1.3 Code Production
9
In the reﬁnement of the Separation Kernel, proofs of individual modules
have been included. The two proofs associated with many of the complex
operations (those deﬁned over conjunctions of state spaces) are not included,
even though they have been undertaken and recorded. One reason for this is
space (the book would become excessively long); another is that too many
obvious proofs become rather tedious and would put the reader oﬀcontinu-
ing. Finally, there is the reason that the proofs are not required because the
abstraction relations are identities; the proofs of the components are given, so
those of the complex operations can be derived in an obvious fashion.
Finally, as always, there is the matter of hardware. As in [4], we have
treated the hardware as a given. For the purposes of reﬁnement, this implies
that it is a state space and set of operations that cannot be further reﬁned.
This does mean that the speciﬁcation can appear a little low-level in places
but, as usual, appropriate abstract operations are deﬁned over the hardware
state space (context switch, half context switch, raise interrupt and so on),
so some measure of abstraction can be had. The approach adopted is, in any
case, akin to that one must adopt when specifying software that interfaces to
a pre-existant library or subsystem; the software external to the speciﬁcation
can only be treated as a given. In the case of system models, this implies
that the properties of the external entity must be inferred. In the case of
reﬁnements, it implies that no further reﬁnement can be undertaken (in any
case, one has no control over pre-existant entities).
1.3 Code Production
This book does not contain any code that can be executed. There are examples
of the translation between ﬁnal reﬁnements and Dijkstra’s Guarded Command
Language [6]. These translations are included to show just how close to a
programming notation the reﬁnements reach.
There is no C or Ada. The complete code is not included. The reason for
this is that there is no space.
We are, at the time of writing, translating the ﬁnal reﬁnements of the
simple kernel into code so that it can be executed. The ﬁrst reﬁnement is has
been translated to GNU C compiler. The target hardware is the Intel IA32
Pentium processor. The translation is a simple matter given the detail of the
ﬁnal reﬁnement. Once translated into C, the result is tested and is, in this
case, fairly exhaustive. It is pleasing to report that the code passed all of the
tests. Testing, we believe, should be a conﬁdence-building part of the method;
we are making relatively exhaustive tests in this case because of the nature
and size of the problem. All modules have passed their tests ﬁrst time, so the
reﬁnement process can be argued to have worked. The low-level operations
included in the speciﬁcation are coded in assembly language; this is, again, a
relatively simple activity. At the time of writing, the implementation has yet
to be completed.

10
1 Introduction
1.4 Organisation of this Book
This book naturally falls into four main sections:
1. This introduction (Chapter 1).
2. The speciﬁcation and formal reﬁnement of a small kernel (Chapters 2 and
3).
3. The speciﬁcation and formal reﬁnement of a Separation Kernel (Chapters
4 and 5).
4. Concluding remarks (Chapter 6).
The two reﬁnements are also accompanied by a short, informal, introduction
that outlines the organisation of each kernel in high-level terms. The reﬁne-
ments are annotated in English; the main concern is to justify the decisions
made in the face of alternatives.
1.5 Relationship to Other Work
It has been pointed out that other workers have produced models of operating
systems. This was a fact known to us when [4] was written. What made us
continue with that book was the fact that it was intended that proofs of
many properties, some obvious, some less so would be included in the book.
Comparing what we wanted to do with the published literature, we found
that published material either lacked proofs altogether or did not contain the
range that we intended to produce (typically the former); we also wanted to
work in a framework that was not based upon temporal logic.
As far as we are aware, there is nothing in the literature on the formal
reﬁnement of operating system kernel code from a formal speciﬁcation.
In the case of veriﬁcation, if one single bit in the code is altered, the entire
system must be re-veriﬁed. Furthermore, veriﬁcation often involves taking
an informally speciﬁed object and reconstructing a formal speciﬁcation from
it. Unless the original designers are part of the exercise, it does not appear
possible to determine whether the result of veriﬁcation really does conform
to the design. This must be true even when design documents are available
for, as is often stated, a natural-language speciﬁcation leaves a considerable
amount unspeciﬁed because of our understanding of language. On the other
hand, and this is another frequently made point, formal speciﬁcation captures
speciﬁcations unambiguously. The formal speciﬁcation and reﬁnement process
requires that everything be captured in documents. It is clear that, should a
single bit of a formally speciﬁed program be altered, the program no longer
conforms to the speciﬁcation. Unlike veriﬁcation, it is possible, in this case,
to determine whether the change is signiﬁcant or not. It is also possible to
propagate design decisions through a formal speciﬁcation without requiring
the production of code (by its very nature, veriﬁcation depends upon the
existence of code).

2
The Simple Kernel’s Organisation
The purpose of this chapter is to describe in informal terms the organisation
and purpose of the “simple” kernel that is speciﬁed in the remainder of this
chapter.
As noted in Chapter 1, the kernel speciﬁed in this chapter is intended
for use, actual or otherwise, as the kernel of embedded and simple real-time
systems. The kernel is similar to Labrosse’s µC/OS [8] and the ﬁrst kernel
modelled in [4]. This kernel was deliberately chosen as a link back to [4] and
because we consider it important to demonstrate that this class of kernel can
be formally speciﬁed and reﬁned to working code.
In this kernel, each process has a unique identiﬁer that is assigned to
it by the kernel from a ﬁxed set in a purely sequential fashion. The ﬁrst
process to be allocated is the idle process, the process that runs when no other
processes are ready for execution; the second to be allocated will usually be the
initial process, the process that creates all the other processes in the system
(the model is not related to the one employed by Unix, it should be noted).
Thereafter, the identiﬁers are allocated to processes in order of creation.
At present, each process has to make an explicit system call to obtain its
identiﬁer and there is no facility for determining, at runtime, the identiﬁer
of other processes (unless they, too, have determined their identity by means
of the same system call). An obvious extension would be to make process
identiﬁers available in a more usable way. Meanwhile, the mechanism speciﬁed
here is workable.
The process representation is a set of mappings that are reﬁned to vectors
(one-dimensional arrays). The collection of these mappings is equivalent to the
process table in other systems and we will refer to this collection of mappings
as the process table or PTAB (this is the name of the state representation in
the speciﬁcation). The mappings are keyed by the identiﬁer of the process and
each mapping represents a diﬀerent piece of information about the process.
In this kernel, the representation of processes is uniform in the sense that
all processes are associated with the same kinds of information (in the other
kernel speciﬁed in this book, there is a distinction imposed between diﬀerent

12
2 The Simple Kernel’s Organisation
types of process). In this kernel, processes are represented by the following
information:
•
Stack pointer. This is a pointer to the top of the process’ stack. It is used
when performing a context switch.
•
Priority. This is a small integer value. Small negative values represent high
priorities, while small positive values represent low priorities. The default
value is 0. The priority is used to sort the scheduler’s ready queue and is
also used to determine whether or not to cause a context switch.
•
State. This is an enumeration type. The value associated with each process
denotes the current state of the process. The state is used by the scheduler
when determining whether a context switch can be performed. It is also
used to document the process; an extension to the system is the inclusion
of an operation that obtains the states of all the processes in the system
(an operation similar to the Unix ps operation).
•
Incoming Message. Processes can communicate using synchronous mes-
sages. This mapping is used to hold the latest message that has been sent
to each process. When there is no message to be received or a message has
just been read by its receiver, the value of the mapping is nullmsg.
•
Waking Time. Processes can perform a system call that makes them wait
for a speciﬁed period of time. The process speciﬁes the duration of its
sleeping time. The value stored in this mapping is the sum of the current
time and the time at which the process should wake up. When a process
wakes up, it is returned to the scheduler’s ready queue and can be executed
at some subsequent time.
In many kernels, processes are represented by structures or blocks of
storage; the Linux kernel [2], on the other hand, employs an array-based
representation similar to the one adopted here. A block/structure-based rep-
resentation can be speciﬁed in Z and would use promotion to include the
structure in the containing table. This approach separates the reﬁnement of
the structure from that of the table. The reﬁnement process employed here
combines the reﬁnement of the mappings.
There are arguments for and against the beneﬁts of these representations.
As far as we are can see, the arguments balance out and what is left is per-
sonal preference. In other kernel speciﬁcations, we have adopted the other
representation to good eﬀect; in the end, though, we just like the mapping-
or vector-based implementation of the process table.
In addition, the process table contains a state variable, used. This contains
the identiﬁers of those processes that have been allocated. If a process identi-
ﬁer is not in this set, it does not represent a process that currently exists in
the system. This variable is reﬁned to the freechain. The freechain is a chain
of elements in a vector called next. If an element is in the freechain, it denotes
a process that is not in the system; the identiﬁer of the process is the index
of the element in next.

2 The Simple Kernel’s Organisation
13
The next major component is the scheduler. The scheduling r´egime is
based on a simple priority queue with highest priority at the head. We refer
to this queue as the ready queue. When a process is added to this queue, its
priority is used to determine where it should be inserted.
The priority queue is ﬁrst speciﬁed as a separate module, whose elements
are in a variable called pq. For the speciﬁcation of the scheduler proper, promo-
tion is used so the reﬁnement of the priority queue can proceed independently
of that of the rest of the scheduler.
The priority queue is reﬁned to a chain through the next PTAB map.
This removes the need to allocate additional storage inside the kernel. The
complexity of the chain operations is a little higher than those on a simple
one-dimensional vector but it was employed here for the following reasons:
•
It shows that such chaining can be handled formally.
•
Chaining, as noted above, uses no more space in the kernel.
The scheduler proper contains three variables in addition to the ready
queue. One variable contains the identiﬁer of the null process so that it can
be easily accessed when the scheduler determines that there is nothing to do.
The null process is included explicitly as a process for the following reasons:
•
It can be removed in other versions of the system.
•
Its behaviour can be altered from a completely null behaviour (an inﬁnite
loop with no body) to something else.
These modiﬁcations require trivial respeciﬁcations of the system.
The other variables contain the identiﬁer of the process that is currently
executing and that of the process that ran immediately before the current
one. The identiﬁer of the currently executing process is required by the sched-
uler when performing a rescheduler operation, as follows. A slightly simpli-
ﬁed account of the scheduler’s conditions for rescheduling are as follows. If a
reschedule is to be performed and the following conditions are satisﬁed, the
scheduler schedules another process and performs a context switch:
•
There are processes in the ready queue.
•
The priority of the current process is lower than that on the head of the
ready queue.
•
The state of the current process is not marked as ready or running.
If there are no processes in the ready queue, the idle process is run. If either
of the other conditions is not satisﬁed, the current process is continued and
no context switch is performed.
Keeping the current and previous process identiﬁers is also useful when
performing the context switch because it allows the switching code to access
process data. It is also useful when testing systems built using the kernel. In
the current version, it allows the scheduler to access the stacks of the two
processes.
The scheduler provides the following operations:

14
2 The Simple Kernel’s Organisation
•
An operation to initialise the various data structures. This is called on
system start-up.
•
An operation to schedule the next process (SchedNext).
•
An operation that suspends its caller and schedules the next process. If
there are no other processes in the ready queue, the idle process is run.
The operation forces a context switch.
Processes can synchronise using semaphores. The kernel contains a single
table that holds all the semaphores that can be used by processes. The size
of the table is a compile-time constant. It is organised as a bit map. The
semaphores held in the table are counting semaphores; this is no restriction
upon the semaphores’ behaviour because the semaphore type contains an
initialisation variable that can be set to 1 for binary semaphores.
Semaphores are deﬁned as a separate type. Semaphore operations are pro-
moted by the table type. There are three operations provided by semaphores:
1. Initialise.
2. Allocate a semaphore if possible (if not, an error is reported).
3. Free a semaphore1.
4. Signal (the V operation).
5. Wait (the P operation).
The reﬁnement of the semaphore table to bit maps was performed in or-
der to demonstrate that structures requiring “bit banging” can be speciﬁed
formally2.
Semaphores are implemented using promotion. The semaphore proper con-
tains a counter and a FIFO queue. The queue is deﬁned as a separate type
and its operations are promoted by the semaphore, thus simplifying the reﬁne-
ment. The FIFO is, like the priority queue, reﬁned to a chain through the next
map in the process table. In this case, chaining was considered essential. This
is because there could be many semaphores in the system. Each semaphore
contains its own, independent, FIFO queue. If the FIFO were implemented
as a vector, this would mean allocation of a vector of suitable size for each
semaphore. The scheme adopted here has the advantages that the space is
allocated once and that each FIFO can be of arbitrary length.
Processes can also communicate by the synchronous exchange of messages.
When a process is ready to receive a message, it executes a system primitive
and enters the psreceiving state and is suspended. It remains in that state
1 No check on ownership is performed, so freeing someone else’s semaphore is a
neat way to cause trouble! In a more secure version, recording the ownership of
resources would be a good idea.
2 In other work, we have also attempted the speciﬁcation of the kinds of operations
required, for example, in controlling hardware devices. Device controllers typically
require bits to be set and unset by controlling software; they are often cited as
a problem for the formal approach. After a little thought, we found that there is
no such problem—provided, that is, one thinks clearly about it.

2 The Simple Kernel’s Organisation
15
System Calls
Previous
Process
Priority-Based
Scheduler
Process
Repn
Clock ISR
Kernel
ISRs
Current
Process
Messager
Semaphore
Tables
Sleep
List
Fig. 2.1. Organisation of the simple kernel.
until another process sends a message to it. When the message is received,
the receiver’s state is set to psready and it is put back into the scheduler’s
ready queue. If a process sends a message to a process that is not blocked
in the psreceiving state, the system reports the fact and the sender must try
again (this rather crude approach could be hidden inside a library routine).
The organisation of this kernel is shown in Figure 2.1.
The interface to the system’s facilities are made as simple and direct as
possible so that the result is reasonably fast. In addition, the kernel assumes
that the code implementing processes is linked with the kernel to form a
single, loadable image. Storage is allocated by the programmer; the kernel,
as it stands, does not contain any storage-allocation code. Storage can be
allocated as data structures in C or assembly code or can be allocated as part
of the linkage process.
The speciﬁcation deﬁnes system calls for many of the operations mentioned
above. Included in the calls are the following:
•
Create process.
•
Terminate. This operation is used when a process needs to terminate itself
(it should be the last operation performed by all processes except the
initial one). The operation works by killing the currently active process.
•
Get process identiﬁer.
•
Send a synchronous message.

16
2 The Simple Kernel’s Organisation
•
Receive a synchronous message.
•
Allocate a semaphore; an identiﬁer is returned.
•
Deallocate a semaphore. The identiﬁer returned by the allocation opera-
tion is used to identify the semaphore to be freed.
•
Wait. The P operation on a semaphore.
•
Signal. The V operation on a semaphore.
•
Sleep. This causes the suspension of the caller for the speciﬁed period of
time. When the time has elapsed, the caller is resumed.
Each system call works as follows. It ﬁrst disables interrupts, then performs
the operation and ﬁnally re-enables interrupts. Disabling interrupts ensures
that the operation is indivisible. Most of the operations are quite short, so
interrupt disabling should not cause too many problems (this is not a kernel
for hard real-time processing, in any case).
The speciﬁcation includes the mechanism for making processes sleep. This
is another case in which a high-level speciﬁcation is reﬁned to a chain through
the next vector in the process table. When processes are not sleeping, their
waking time value is 0; when they are sleeping, the waking time value is greater
than 0. This provides a quick check that a process is not asleep.
To make the sleep mechanism work, the speciﬁcation contains a clock. The
clock is intended to be implemented as an Interrupt Service Routine (ISR) or
interrupt handler.
The clock should work as follows. On every interrupt from the real
hardware clock, the clock ISR increments a tick variable. If there are t ticks
each second, when tick = t, the time in seconds since boot time is incremented
by one, as is a second variable that records the number of ticks since boot
time. If the number of seconds since boot is 0 mod 60, the minute counter is
incremented by one; if the minute counter is 0 mod 60, the hour counter
is incremented by one. In the current version, the actual clock time is not
recorded (this could be included with relatively little work but could involve
a hardware dependency).
If the clock used by the processor ticks at a rate such as once every
100msec, the above scheme can be used. Unfortunately, some processors do
not have such accommodating clocks. The Intel IA32, for example, has a clock
that has a cycle of something like 18.4MHz, a rate that is not all that help-
ful for keeping the time. For the IA32, the clock ISR is activated on every
clock interrupt, as usual. When activated, the ISR increments an activation
counter. When the activation counter reaches a certain value, the tick counter
is incremented, as above. The IA32 clock’s rate is doubly awkward because
it does not divide the second exactly, so either a little clock drift has to be
tolerated or a correction must be made from time to time. In the speciﬁcation
here, drift is tolerated (it is an example, after all!)
Now, many readers will be wondering about the real hardware issues. In
particular, how context switches are performed. Furthermore, nothing has
been said about processor registers—the process context, in other words.

2 The Simple Kernel’s Organisation
17
The answer is that we prefer to have as little as possible to do with the
processor’s low-level details! One reason for this is that it makes the kernel
more portable (all the hardware-speciﬁc operations are ﬁrmly delineated). The
low-level operations required are:
•
Enable and disable interrupts. These operations are usually performed by
one instruction each.
•
A return from interrupt (IRET) is also required to terminate ISRs. This
is also frequently implemented as one or two instructions (usually one but,
on the MIPS, for example, interrupts must be re-enabled and the return
has to be performed explicitly).
•
A context switch. The scheme adopted in this speciﬁcation is that the
registers are stored on the top of the process stack. This has the advantage
that there is no permanent store allocated in the process table for the
register set; this also implies that it is not necessary, a priori to ﬁx the
number of registers in the process table.
•
A “half-context switch”. This is used to set up the intial process’ regis-
ters when creating it. This operation pushes one value (0) onto the initial
process’ stack when it is created. The reason for this is explained immedi-
ately below.
The context-switching scheme is also a fairly standard one. When the sched-
uler requires a context switch, it raises an interrupt. This interrupt is handled
by an ISR that pushes the outgoing process’ registers onto its stack and then
pops the incoming process’ registers from the stack. The ISR then immediately
executes an IRET instruction and the incoming process is switched in.
Because the incoming process has been suspended using an interrupt, it
will have the registers needed by the IRET instruction on its stack immediately
below its other registers. This is clearly impossible if the process has never
been interrupted, as is the case with the initial process. In this case, the stack
must be set up so that the processor ﬁnds all the information it requires. To do
this, dummy values are pushed onto the stack when creating the inital process.
The IRET instruction needs to have an address to which control should be
returned. Usually, this is the address of the instruction that was interrupted.
In the case of the initial process, the address has to be its entry point.
On an Intel IA32, the above scheme is extremely easy to implement. The
hardware pushes the return address and the ﬂags register onto the interrupted
process’ stack when an interrupt occurs. The pushad instruction pushes the
general-purpose registers onto the stack and the popad instruction pops them
back. If the kernel executes within a single address space (as this one does),
there is no problem with the scheme outlined above (the Separation Kernel
in Chapter 5 uses multiple address spaces, so another approach is required).
On a MIPS, the scheme outlined above can still be used. However, it is
up to the implementer to push and pop the registers. In addition, the return-
from-interrupt operation must be implemented as a macro. First, the interrupt
ﬂag is reset; next, the instruction pointer in force when the interrupt occurred

18
2 The Simple Kernel’s Organisation
must be fetched from a co-processor register and incremented by four (four
bytes, i.e.) and stored in a register; ﬁnally, a jump-on-register instruction is
executed, citing the register in which the old instruction pointer is stored.
Although a bit longer, the MIPS sequence is still comparatively simple. It
is clear that it can be represented in Z with a little work. Because we are aim-
ing our reﬁnements and implementation at the IA32/64 (simply because we
have them available), we have omitted a detailed speciﬁcation of the context-
switching operation. A speciﬁcation for the MIPS (or any other processor like
it, for that matter) would include the speciﬁcation of the registers and the
operations required to implement the push and pop operations, as well as the
return-from-interrupt operation. This is not diﬃcult; indeed, we undertook it
when examining a reﬁnement of this kernel to the MIPS processor3.
With this general outline of the kernel and the reﬁnement out of the way,
it is possible to progress to the speciﬁcation and reﬁnement proper. Both
top-level speciﬁcation and the various reﬁnements are accompanied by a com-
mentary to aid the reader’s understanding.
3 We did this as an exercise in reﬁning to a RISC machine to determine what the
problems, if any, might be; as with the IA32/64, we were pleased to ﬁnd that
it was straightforward. Unfortunately, we do not have a MIPS or other RISC
available so that we can run the result—perhaps, one day!

3
A Simple Kernel
The ﬁrst speciﬁcation and reﬁnement is of a small kernel of the type often used
in embedded and real-time systems. The kernel resembles Labrosse’s µC/OS
[8] and the kernel of Chapter 3 of our [4].
The structure of the chapter is as follows. First, the types that are used
throughout the speciﬁcation and the reﬁnement are deﬁned.
Second, a speciﬁcation of the hardware is given. This speciﬁcation is at a
relatively high level but could be reﬁned to a lower one. The speciﬁcation is
aimed at an Intel IA32 implementation but should be suﬃciently general to
change to another architecture.
Third comes the speciﬁcation and reﬁnement of the kernel proper. This
part occupies the vast majority of the chapter. Each major component is spec-
iﬁed and then reﬁned; this constitutes a section of the chapter. Reﬁnements
constitute a subsection and usually consist of the reﬁned state space and oper-
ations followed by the abstraction relation; in some cases, where it seems more
appropriate, the abstraction relation comes before the reﬁned operations. The
relevant proofs come at the end of each section. In a couple of cases, proofs
are included within the statement of the reﬁned operations.
3.1 Types
In this section, the major types are deﬁned. As noted above, the types deﬁned
here are used throughout the rest of this chapter.
First, the PID and GPID types are deﬁned. These types are used to name
processes. The PID type is a subrange type with range minpid to maxpid,
while GPID extends PID by the addition of the nullpid. The nullpid is deﬁned
below and represents the null process. The null process should not be confused
with the idle process; the former is intended to be a null reference, while the
latter merely does nothing while it executes—it is executed when the processor
has nothing to do. The idle process has a normal process identiﬁer (an element
of PID) and is allocated at system startup time.

20
3 A Simple Kernel
PID = minpid . . maxpid
GPID = {nullpid} ∪PID
nullpid : N
∀p : PID •
p < nullpid
The null value is usually the least element or somewhere in the middle. How-
ever, in a implementation using C vectors, indexing is zero-based, so the
natural choice of zero is not available. The actual choice of value for nullpid
is, in any case, arbitrary; what must be ensured is that there is no way in
which nullpid can be confused with a valid value.
The PSTATE type is deﬁned next.
PSTATE ::= psterm
|
psrunning
|
psready
|
pswaitsema
|
pssleeping
|
pssending
|
psreceiving
This type represents the state of processes. A process can be in exactly one
state at any time. The names denote states:
•
State psterm denotes the terminated state.
•
State psrunning is the state of a process that is currently executing.
•
State psready is the state of a process that is ready to execute but not yet
executing.
•
State pswaitsema is the state of a process that is waiting on a semaphore.
•
State pssleeping is the state of a process that is in a sleeping state (i.e., is
waiting for a timer to expire before it can resume execution).
•
State pssending is the state of a process that is sending a message (this
might involve the process being suspended before the message can be
exchanged).
•
State psreceiving is the state of a process that is ready to receive a message.
The next deﬁnitions concern process priorities. Priorities are deﬁned in
terms of the range maxprio . . minprio, with smaller values denoting higher
priorities.
minprio, maxprio : Z
The type denoting process priorities is PPRIO.
PPRIO == maxprio . . minprio

3.1 Types
21
The type representing messages is, for simplicity, deﬁned as atomic.
[MSG]
The MSG type includes a value denoting the null message:
nullmsg : MSG
It will be necessary to access components of elements of MSG. It is common,
for checking purposes, to require access to the sender (msgsrc) and destination
(msgdest) of a message; in addition, the msgsize function returns the size of
a message
msgsrc : MSG →PID
msgdest : MSG →PID
msgsize : MSG →N
The WORD type denotes the contents of a word of storage.
[WORD]
Addresses in the store are represented by the ADDR type.
ADDR == nulladdr . . maxaddr
Addresses are deﬁned in terms of a range. The lower bound, nulladdr is address
zero.
nulladdr : N
maxaddr : N
nulladdr = 0
nulladdr < maxaddr
A representation is also required for time. This representation is called
TIME. It is deﬁned as a synonym for the naturals. Time can be assumed, for
now, to start when the system is started.
TIME == N
Finally, the SYSERR type is deﬁned. This type deﬁnes the values of the
error variable set by various system components. When all is well, the error
variable is set to sysok; when an error has occurred, the variable is set to
another value.
SYSERR ::= sysok
|
pdinuse
|
unusedpd
|
ptabfull

22
3 A Simple Kernel
|
emptyqueue
|
schedqfull
|
schedqempty
|
alreadyasleep
|
toomanysleepers
|
notallocsema
|
nofreesemas
|
procalreadyhasmsg
|
destinationnotrcving
|
badmsgdestination
|
nomsg
The interpretation of the values are:
•
Value pdinuse denotes the state in which a process descriptor (process
identiﬁer) is already in use;
•
Value unusedpd denotes the state in which a reference has been made to
a process descriptor that is not in use.
•
Value ptabfull denotes the state in which no more process descriptors can
be allocated.
•
Value emptyqueue denotes the state in which a queue of processes is empty
and an attempt to dequeue a process has taken place.
•
Value schedqfull denotes the state in which the scheduler’s ready queue is
full.
•
Value schedqempty denotes the state in which the scheduler’s ready queue
is empty.
•
Vaue alreadyasleep denotes the state in which an attempt is made by a
process to enter a sleep state but that process is already marked as being
asleep.
•
Value toomanysleepers denotes the state in which there are too many
processes in the sleep list.
•
Value notallocsema denotes the state in which an attempt has been made
to access a semaphore that has not been allocated.
•
Value nofreesemas denotes the state in which no more semaphores can be
allocated.
•
Value procalreadyhasmsg denotes the state in which a receiving process
already has an incoming message but has not yet processed it (thereby
freeing its incoming-message slot).
•
Value destinationnotrcving denotes the state in which the intended desti-
nation of a message is not currently in the state to receive it. The sender
should wait until later.
•
Value badmsgdestination denotes the state in which the destination process
of a message does not exist.
•
Value nomsg denotes the state in which there is no message in the
incoming-message slot when an attempt to receive a message is made.

3.2 Hardware
23
This section concludes with the deﬁnition of three schemata that are used
in generic error situations.
When all is well, the SysOk schema sets the error variable, serr!, to sysok.
SysOk
serr! : SYSERR
serr! = sysok
The following operation tests err to determine whether it is sysok.
IsSysOk
err : SYSERR
err = sysok
This operation is used to re-direct the value of serr!. It is intended that
terr? should be renamed when using this schema.
ReturnSysError
terr? : SYSERR
serr! : SYSERR
serr! = terr?
3.2 Hardware
The reader is warned that this section is heavily inﬂuenced by the Intel
IA32/64 architecture.
First, a type is deﬁned to denote the values on and oﬀ. This type is to be
the value of the interrupt status ﬂag (the “interrupt ﬂag”).
ONOFF == oﬀ| on
The processor implements a ﬁnite number of interrupt types, each denoted
by a small integer in the range minintno to maxintno.
minintno, maxintno : N
minintno < maxintno
A type, INTRPTNO is deﬁned to represent the interrupt number.
INTRPTNO == minintno . . maxintno
The hardware state is represented by the following schema.

24
3 A Simple Kernel
HARDWARE
genregs : REGID →WORD
intﬂg : ONOFF
intno : INTRPTNO
The hardware has a set of general-purpose registers, genregs, an interrupt ﬂag,
intﬂg and a number denoting the current interrupt (if there is one), intno.
In a fuller model, intno would be used to activate the appropriate interrupt
service routine. Here, it is used just to provide a parameter to the operation
that raises software interrupts. The general-purpose registers, genregs, is a
function from register identiﬁer, REGID, to a value (represented as a single
word).
First of all, we need operations to enable and disable interrupts. First, the
operation to enable interrupts is deﬁned.
EnableInts
∆HARDWARE
intﬂg′ = on
Next, the operation that disables interrupts is deﬁned.
DisableInts
∆HARDWARE
intﬂg′ = oﬀ
Since these operations do not refer to the before state, their precondition is
true.
The above operations merely operate on the interrupt ﬂag in the simpliﬁed
hardware models.
A Return From Interrupt instruction is assumed. On many processors, this
operation corresponds to a single instruction, often called rti. Amongst other
things, this operation disables interrupts, increments the program counter so
that it points to the instruction after the one that caused the interrupt and
restores it to the hardware so that execution can continue. Since much of this
is internal to the processor, we only specify it in outline.
ReturnFromInterrupt =
. . .
o
9EnableInts
The process table, PTAB, is the structure maintained by the kernel to
represent processes. Processes are represented as a collection of data items
that collectively represent a process. As far as the hardware is concerned, it
is necessary for each process’ current stack top pointer to be stored in the

3.2 Hardware
25
process table. The reason for this is that, between activations, the values of
the registers belonging to a process are stored on top of the stack.
PTAB
...
stacktop : PID →ADDR
...
...
dom stacktop = used
...
When a context switch occurs, the registers belonging to the outgoing
process are pushed onto its stack. Then the registers of the incoming process
are popped oﬀits stack.
ContextSwitch
∆HARDWARE
ΞPTAB
inpid?, outpid? : PID
pushregs(stacks(outpid?))
o
9popregs(stacks(inpid?))
where pushregs is an operation that pushes all (necessary) registers onto the
stack pointed to by stacks(outpid?) and popregs pops the equivalent registers
from the stack pointed to by stacks(inpid?). This is an old technique for stor-
ing registers; it has the enormous advantage that it does not require storage
in the process table. It has another advantage: the registers are always in an
easily accessible location and access to them is relatively cheap.
Because of the architecture of most processors, we are compelled to assume
that there will always be suﬃcient space on the outgoing process’ stack to hold
all the necessary registers. This is, however, a matter for the programmer.
Furthermore, nowhere is the size limit for the stack saved, so it is not possible
to determine whether there is any space available; even if there were, the test
might be too expensive to apply, so we are left where we began.
The precondition of ContextSwitch could be true or it could be
pre ContextSwitch = {inpid?, outpid?} ⊆used
The process is only partially complete at this point. When the ﬁrst process
is executed, where do the outgoing registers come from? To solve this problem,
we deﬁne the following operation

26
3 A Simple Kernel
HalfContextSwitch
∆HARDWARE
ΞPTAB
inproc? : PID
pushregszero(stacks(inproc?))
where pushregszero is a function that pushes one zero on the stack pointed to
by stacks(inproc?) for every register that must be used by the process inproc?.
Finally, it is assumed that when a context switch is to occur, an interrupt is
raised. On many processors, when an interrupt is raised, the program counter
of the interrupting process is stored on the stack. On other processors, the
program counter is stored in a well-deﬁned location, usually in a designated
register (as it is on MIPS processors). In order to complete the speciﬁcation
of the context switch, it is necessary to deﬁne an operation that raises the
interrupt (RaiseInterrupt).
RaiseInterrupt
∆HARDWARE
ino? : INTRPTNO
intno′ = ino?
Note that we say nothing about how the hardware responds to this. The
precondition of this operation is true, as the following calculation shows. First,
∃HARDWARE ′ •
intno′ = ino?
This then becomes
∃genregs′ : REGID →WORD; intﬂg′ : ONOFF; intno′ : INTRPTNO •
intno′ = ino? ∧
genregs′ = genregs ∧
intﬂg′ = intﬂg
Using the one-point rule, this simpliﬁes to
∃genregs′ : REGID →WORD; intﬂg′ : ONOFF; intno′ : INTRPTNO •
ino? = ino? ∧
genregs = genregs ∧
intﬂg = intﬂg
This is clearly equivalent to true, so we can state
pre RaiseInterrupt = true
To cause a context-switching interrupt, the following operation is invoked

3.2 Hardware
27
CTXTSW =
∃ino : INTRPTNO | ino = context switch •
RaiseInterrupt[ino/ino?]
This expands into
CTXTSW
∆HARDWARE
intno′ = context switch
In this case, too, the precondition is
pre CTXTSW = true
This fact saves a good deal of work when deﬁning the scheduler’s main
operation.
When the interrupt occurs, the ISR performs the following operations
CTXTSWISR =
ContextSwitch o
9 ReturnFromInterrupt
This operation calls the context switch to push the outgoing process’ registers
onto its stack. The outgoing process was the one that was executing before the
context switch occurred, so its program counter will be pushed onto the stack
by the CTXTSW operation. The incoming process will have had its stack
organised by the CTXTSW operation, so we can expect its stack to have
its registers at the top and its program counter underneath. By popping the
registers, the stack is left in the state required by the ReturnFromInterrupt.
In this case, however, control is passed to the incoming process, not to the
one that caused the interrupt.
Although the principle of the above is quite general, it assumes that there
is a rti instruction and that the stack contains the program counter on inter-
rupt. These assumptions are not universal. There are processors that only push
the interrupted process’ program counter on the stack; there are processors
that store the interrupting process’ program counter in a register. MIPS does
this and MIPS requires the programmer to increment the program counter
themselves; its equivalent of the rti instruction just clears the interrupt ﬂag.
In the case of MIPS, therefore, a little more work must be done than we have
outlined here.
The ISR for the half context switch also needs to ﬁnd a program counter
on the incoming process’ stack. Since the process has not executed yet, so
the stack has to be pre-loaded with program counter and default values for
the other data that is pushed by the raise interrupt operation. The program
counter value will be the entry point of the ﬁrst process.
In a similar fashion, when a process is run for the ﬁrst time, there is no
program counter for it. In this case also, the program counter’s value should
be the entry point to the main procedure in the process.

28
3 A Simple Kernel
3.3 The Process Table
In the last section, reference was made to the Process Table, a data structure
maintained by the kernel to represent the processes it currently contains.
Here, the process table, PTAB, and the operations required to support it, are
deﬁned.
First, the error schemata are deﬁned.
The ﬁrst operation is used to set the error ﬂag when a process descriptor
is unused and something wants to operate on it.
UnusedPD
serr! : SYSERR
serr! = unusedpd
The next schema represents the operation that records the error state when
a process descriptor is in use and an attempt to allocate it again is made.
PDInUse
serr! : SYSERR
serr! = pdinuse
The ﬁnal schema represents the operation to set the error value when the
process table is full.
PTABFull
serr! : SYSERR
serr! = ptabfull
3.3.1 Top Level
Now, the state schema for the process table is deﬁned.
PTAB
used : F PID
prio : PID →PPRIO
state : PID →PSTATE
stacktop : PID →ADDR
smsg : PID →MSG
wakingtime : PID →TIME
used = dom prio
dom prio = dom state
dom prio = dom smsg
dom prio = dom wakingtime
dom prio = dom stacktop

3.3 The Process Table
29
The used variable records the identiﬁers of those processes currently in the
system. Each process in used has a priority that is represented by prio and a
state that is represented by state. A pointer to the top of each process’ stack
is represented by stacktop. Processes are permitted to communicate using
messages, following a synchronous r´egime, and messages, when received, are
stored in smsg. Processes are each associated with a value that denotes the
period, expressed in seconds, that it is to be suspended on a timer queue;
when the period expires, the process is made ready for execution. By default,
a process that is not sleeping is assigned a wakingtime value of 0 (zero).
When allocating process identiﬁers, it is useful to know which identiﬁers
are free and which are used. Since PID is ﬁnite and used ⊆PID, we can
deﬁne free as:
PID \ used = free
This deﬁnition will make reﬁnement considerably easier. It will also help in
reasoning about the process table.
The process table is initialised by the following operation. Initialisation
consists simply of setting used to empty. Since the domains of the partial
functions comprising the rest of the PTAB schema are identical to used, this
implies that the domains of these functions is also ∅.
PTABInit
PTAB ′
used ′ = ∅
The UsedPID schema deﬁnes an operation that is true when the input,
p?, is an element of used. When this is the case, p? refers to a known process
(i.e., one that is present in the system).
UsedPID
ΞPTAB
p? : PID
p? ∈used
The next operation is true when there are process identiﬁers that can be
allocated.
GotFreePIDs
ΞPTAB
used ⊂PID
Note that ∅⊂PID. In this case, there are no allocated PIDs. If used = PID,
then used ⊂PID is false and there are no free elements of PID. This scheme is
used because process identiﬁers are cycled in the sense that a single identiﬁer

30
3 A Simple Kernel
can be allocated (i.e., denoting some process) at one time and unallocated (i.e.,
denoting no process) at another time. This is similar to the cycling indices
when process identiﬁers are represented by array indices. The operation to
allocate a process identiﬁer is the following:
AllocPID
∆PTAB
p! : PID
p! ̸∈used
used ′ = used ∪{p!}
By the deﬁnition of free, p! ̸∈free follows from the predicate of AllocPID’s
schema.
When deallocating or freeing a process identiﬁer, the FreePID operation
is employed.
FreePID
∆PTAB
p? : PID
used ′ = used \ {p?}
The deﬁnition of free permits the inference from the schema of FreePID that
p? ∈free′, or that p? is an element of free in the after state of this operation.
The lowest level of process descriptor allocation is the creation of the
initial representation of the process. When a process is created, an identiﬁer
is allocated and some basic information about it is recorded in the process
table. This second part of the operation is captured by AddPDESC.
AddPDESC
∆PTAB
p? : PID
st? : PSTATE
pr? : PPRIO
prio′ = prio ∪{p? →pr?}
state′ = state ∪{p? →st?}
smsg′ = smsg ∪{p? →nullmsg}
wakingtime′ = wakingtime ∪{p? →0}
It is clear that p? ∈used is required. It can also be seen that the default value
for wakingtime is used to denote the fact that p? is not currently sleeping.
The full operation to create a representation of a process within the process
table is the following.

3.3 The Process Table
31
AddPD =
((GotFreePIDs ∧AllocPID)o
9
(¬ UsedPID[p!/p?] ∧AddPDESC[p!/p?] ∧SysOk)
∨PDInUse)
∨PTABFull
First, a test is performed to determine that the process table is not empty.
If this is the case, a process identiﬁer is allocated and a check is made to
determine whether the newly allocated identiﬁer is currently in use (if it is,
something serious has gone wrong, perhaps an attack—we do not deal with
such matters in this system but we do record the fact). If all is well, basic
information about the process is recorded in the process table and sysok is
returned.
This expands into:
AddPD
∆PTAB
p! : PID
pr? : PPRIO
st? : PSTATE
serr! : SYSERR
((used ⊂PID ∧
p! ̸∈used ∧used ′ = used ∪{p!} ∧
p! ∈used ′ ∧prio′ = prio ∪{p! →pr?} ∧
state′ = state ∪{p! →st?} ∧smsg′ = smsg ∪{p! →nullmsg} ∧
wakingtime′ = wakingtime ∪{p! →0} ∧
serr! = sysok)
∨serr! = pdinuse)
∨serr! = ptabful
For the purposes of reﬁnement, it is necessary to calculate the precondition
of this operation. It is
pre AddPD =
used ⊂PID
It is equivalent to
PID \ used ̸= ∅
and to
used ̸= PID
When a process terminates, its descriptor must be removed from the sys-
tem. The DelPD operation does this.

32
3 A Simple Kernel
DelPD =
(UsedPID ∧FreePID ∧SysOk)
∨UnusedPD
The deletion of process descriptors is simpliﬁed by the fact that the domain
of each of the maps that constitute its representation is identical to used.
Therefore, by deleting the process identiﬁer from used, it is also removed
from the other domains.
The DelPD operation expands into:
DelPD
∆PTAB
p? : PID
serr! : SYSERR
(p? ∈used ∧
used ′ = used \ {p?} ∧
serr! = sysok)
∨serr! = unusedpd
The precondition of DelPD is given by
pre DelPD =
∃PTAB ′ • p? ∈used
The next few operations are required to read and write the attributes that
comprise the representation of a process. The attributes of interest here are
prio, state and wakingtime. In the case of state, there are operations that set
the state to speciﬁc values; later in this speciﬁcation, there will be other such
operations deﬁned. The structure of the operations is very much as one would
expect, given the deﬁnition of the types in question. For this reason, little is
said about the details.
ProcPrio
ΞPTAB
p? : PID
pr! : PPRIO
pr! = prio(p?)
SetProcPrio
∆PTAB
p? : PID
pr? : PPRIO
prio′ = prio ⊕{p? →pr?}

3.3 The Process Table
33
ProcState
ΞPTAB
p? : PID
st! : PSTATE
st! = state(p?)
SetProcState
∆PTAB
p? : PID
st? : PSTATE
state′ = state ⊕{p? →st?}
It is useful to have operations that set the value of state. The most useful
is the one that sets the state to psready (this operation is applied when a
process enters the scheduler’s ready queue).
SetProcessStateToReady =
∃st : PSTATE | st = psready •
SetProcState[st/st?]
It expands into
SetProcessStateToReady
∆PTAB
p? : PID
state′ = state ⊕{p? →psready}
SetWaitingTime
∆PTAB
p? : PID
t? : TIME
wakingtime′ = wakingtime ⊕{p? →t?}
WaitingTime
ΞPTAB
p? : PID
t! : TIME
t! = wakingtime(p?)

34
3 A Simple Kernel
3.3.2 Reﬁnement One
In this reﬁnement, a free chain of process descriptors is introduced. This is
used to allocate and free descriptors. At present, the free chain is deﬁned in
terms of an additional function, freech; in the next subsection, the free chain
is reﬁned to the next chain that forms part of PTAB.
The state representation for the reﬁned process table, PTAB1, is as follows.
PTAB1
hdfree, endfree : GPID
freech : PID
↣GPID
prio1 : PID →PPRIO
state1 : PID →PSTATE
smsg1 : PID →MSG
stacktop1 : PID →ADDR
wakingtime1 : PID →TIME
hdfree = nullpid ⇔endfree = nullpid
hdfree = nullpid ⇔dom freech = ∅
hdfree ̸= nullpid ⇔dom freech ̸= ∅
hdfree ̸= nullpid ⇔hdfree ∈dom freech
hdfree ̸= nullpid ⇔endfree ∈dom freech
hdfree ̸= nullpid ⇔freech(endfree) = nullpid)
First, it should be noted that prio1, state1 and wakingtime1 are similar to
those in PTAB; in PTAB, these variables are partial functions, while here they
are total functions. This clearly has implications for the domain constraint on
them that was used so successfully in the speciﬁcation of PTAB.
The other point of interest is the representation of the free chain. We use two
variables, hdfree and endfree to denote the ﬁrst and last elements of the chain.
So that an empty chain can be represented, these variables are of type GPID,
so can be assigned to the value nullpid. The main part of the chain is rep-
resented by the (ﬁnite) partial injection freech. For the reason that freech is
an injection, it follows immediately that it is 1-1; for the reason that freech is
partial, it allows some elements of PID to be absent from its domain. When
the freechain is empty, dom freech = ∅. An empty free chain implies that
there are no more process identiﬁers to allocate. This is the central point of
the initialisation operation for PTAB1:
PTAB1Init
PTAB1′
hdfree′ = minpid ∧endfree′ = maxpid
∀p : PID •
(p = maxpid ⇒freech′(p) = nullpid) ∧(p < maxpid ⇒freech′(p) = p + 1)

3.3 The Process Table
35
This operation merely sets freech to map to the next process identiﬁer (second
conjunct). The last proper process identiﬁer is mapped to nullpid by the ﬁrst
conjunct.
The following operation corresponds to UsedPID. It employs the same
logic as in the case of PTAB: a process identiﬁer is used iﬀit is not free. Here,
free is equivalent to being in the free chain, or, more precisely, in the domain
of the freech.
UsedPID1
ΞPTAB1
p? : PID
p? ̸∈dom freech
The next operation could be deﬁned in terms of dom freech. However,
it is somewhat more useful to use hdfree. The invariant of PTAB1 states
that hdfree = nullpid ⇔endfree = nullpid, and that hdfree = nullpid ⇔
dom freech = ∅. This permits a good deal of simpliﬁcation so that the follow-
ing schema is obtained.
GotFreePIDs1
ΞPTAB1
hdfree ̸= nullpid
Using the invariant, the predicate of this schema implies that endfree =
nullpid and dom freech = ∅, so there can be no free identiﬁers.
The next operation allocates a new process identiﬁer from the free chain.
AllocPID1
∆PTAB1
p! : PID
p! = hdfree
freech′ = freech −◁{p!}
hdfree′ = freech(hdfree)
First, the next free identiﬁer is the value of hdfree, so it can be made the
output variable, p!. The value of hdfree must be updated to freech(hdfree), so
that hdfree′ is the successor of hdfree in freech. It is also necessary to remove
hdfree or p! from freech; p! is a domain element of freech, so the −◁operation
suﬃces to remove it from freech. It should be noted that, since p! is hdfree, it
can only occur in the domain of freech, so the domain subtraction operation
is adequate and there is no requirement to remove p! from the codomain.
This operation corresponds to AddPDESC. The correspondence should be
clear.

36
3 A Simple Kernel
AddPDESC1
∆PTAB1
p? : PID
pr? : PPRIO
st? : PSTATE
prio1′ = prio1 ⊕{p? →pr?}
state1′ = state1 ⊕{p? →st?}
wakingtime1′ = wakingtime1 ⊕{p? →0}
The following operation corresponds to AddPD.
AddPD1 =
((GotFreePIDs1 ∧AllocPID1)
o
9(UsedPID1[p!/p?] ∧AddPDESC1[p!/p?]) ∧SysOk)
∨PDInUse
∨PTABFull
This expands into:
AddPD1
∆PTAB1
p! : PID
serr! : SYSERR
((hdfree ̸= nullpid ∧
p! = hdfree ∧freech′ = freech −◁{p!} ∧
hdfree′ = freech(hdfree)) ∧
(p! ̸∈dom freech′ ∧
prio1′ = prio1 ⊕{p! →pr?} ∧
state1′ = state1 ⊕{p! →st?}) ∧
smsg1′ = smsg1 ⊕{p! →nullpid} ∧
wakingtime1′ = wakingtime1 ⊕{p! →0} ∧
serr! = sysok)
∨serr! = pdinuse
∨serr! = ptabfull
Using the fact that pre(A ∨B) ⇔pre A ∨pre B, we can omit serr! =
ptabfull immediately. In addition, the assignments serr! = unusedpd and
serr! = sysok contribute nothing to the precondition and can also be omitted.
The precondition of AddPD1 is required so that reﬁnement proofs can be
undertaken.

3.3 The Process Table
37
pre AddPD1 =
∃PTAB1′; p! : PID •
hdfree ̸= nullpid ∧
p! = hdfree ∧
freech′ = freech −◁{p!} ∧
hdfree′ = freech(hdfree)) ∧
(p! ̸∈dom freech′ ∧
prio1′ = prio1 ⊕{p! →pr?} ∧
state1′ = state1 ⊕{p! →st?})
This simpliﬁes to:
pre AddPD1 =
hdfree ̸= nullpid ∧
hdfree ̸∈dom(freech −◁{hdfree} ∧
It is equivalent to
hdfree ̸= nullpid
The next few schemata deﬁne operations over the free chain. The pur-
pose of deﬁning these operations is to make manipulation of the free chain
somewhat easier.
The ﬁrst schema deﬁnes a predicate that is true when the free chain is
empty.
EmptyFreeChain1
ΞPTAB1
dom freech = ∅
The next schema deﬁnes an operation that adds an element to the end of
the free chain.
AddNewLastFreechain
∆PTAB1
p? : PID
freech′ = freech ⊕{endfree →p?}
The next schema deﬁnes an operation that maps the last element of the free
chain to nullpid.
AddFreechainLast
∆PTAB1
p? : PID
freech′ = freech ∪{p? →nullpid}

38
3 A Simple Kernel
The SetFCHead operation sets the value of hdfree.
SetFCHead
∆PTAB1
p? : PID
hdfree′ = p?
Analogously, SetFCLast sets the value of endfree.
SetFCLast
∆PTAB1
p? : PID
endfree′ = p?
Using the schemata just deﬁned, the operation to deallocate a process
identiﬁer can be deﬁned. The freeing operation is initially deﬁned as follows:
FreePID1 =
(UsedPID1 ∧
(((EmptyFreeChain1 ∧AddFreechainLast ∧
SetFCLast ∧SetFCHead)
∨(UsedPID1 ∧
(AddNewLastFreechain o
9 AddFreechainLast) ∧
SetFCLast)) ∧
SysOk))
∨UnusedPID
This version is adequate but not very good. In particular, if EmptyFreeChain1
is true, this fact implies that UsedPID1 is also true. That is, dom freech = ∅
implies that p? ̸∈dom freech. By omitting UsedPID1, the following is ob-
tained:
FreePID1 =
(((EmptyFreeChain1 ∧
AddFreechainLast ∧SetFCLast ∧SetFCHead)
∨(UsedPID1 ∧
(AddNewLastFreechain o
9 AddFreechainLast) ∧SetFCLast)) ∧
SysOk)
∨UnusedPID
This can be transformed by distribution of SysOk. The transformation is
justiﬁed by the propositional calculus theorem (p ∨q) ∧r ⇔(p ∧r) ∨(q ∧
r). The use of this theorem occurs frequently and can be used both to expand
a schema by producing copies of conjuncts and to contract them by reducing
multiple occurrences of a conjunct to a single one.

3.3 The Process Table
39
FreePID1 =
((EmptyFreeChain1 ∧
AddFreechainLast ∧SetFCLast ∧SetFCHead ∧SysOk)
∨(UsedPID1 ∧
(AddNewLastFreechain o
9 AddFreechainLast) ∧SetFCLast ∧SysOk))
∨UnusedPID1
This deﬁnition can then be expanded into the schema that follows. A little
simpliﬁcation has been performed on the schema, it should be noted. Very
often, when expanding deﬁnitions into schemata, we will take the opportunity
to engage in some simpliﬁcation; we will, though, outline the transformations
employed unless they are obvious.
FreePID1
∆PTAB1
p? : PID
serr! : SYSERR
((dom freech = ∅∧
freech′ = freech ∪{p? →nullpid} ∧
endfree′ = p? ∧
hdfree′ = p? ∧
serr! = sysok)
∨(p? ̸∈dom freech ∧
freech′ = (freech ⊕{endfree →p?}) ∪{p? →nullpid} ∧
endfree′ = p? ∧
serr! = sysok))
∨serr! = usedpd
In order to prove that FreePID1 is a correct reﬁnement of FreePID, the
precondition of FreePID1 is required. It is calculated as follows.
pre FreePID1 =
∃PTAB1′ •
(dom freech = ∅∧
freech′ = freech ∪{p? →nullpid} ∧
endfree′ = p? ∧
hdfree′ = p?)
∨(p? ̸∈dom freech ∧
freech′ = (freech ⊕{endfree →p?}) ∪{p? →nullpid} ∧
endfree′ = p?)
This simpliﬁes to

40
3 A Simple Kernel
pre FreePID1 =
∃PTAB1′ •
((dom freech = ∅∧
freech ∪{p? →nullpid} = freech ∪{p? →nullpid} ∧
p? = p? ∧p? = p?)
∨(p? ̸∈dom freech ∧
(freech ⊕{endfree →p?}) ∪{p? →nullpid}) =
(freech ⊕{endfree →p?}) ∪{p? →nullpid}) ∧
p? = p?)
and again to
pre FreePID1 =
dom freech = ∅∧
∨p? ̸∈dom freech
It is equivalent to
p? ̸∈dom freech
This is justiﬁed as follows. If dom freech = ∅, then p? ̸∈dom freech, trivially.
The DelPD1 operation can be deﬁned as an equivalence:
DelPD1 = FreePID1
The operations to access and set state components must be deﬁned for
PTAB1, just as they were for PTAB. The deﬁnitions are quite obvious, so
we just give one as an example. As with the corresponding operations over
PTAB, there is the tacit assumption that p? is in used. The operations are
not used as independent operations but as components of larger operations
that require that p? ∈used or some equivalent condition.
SetProcState1
∆PTAB1
p? : PID
st? : PSTATE
state1′ = state1 ⊕{p? →st?}
The relationship between PTAB and PTAB1 is expressed by the predicate
of the AbsPTAB1 schema. This schema is referred to below as the “abstraction
relation”.

3.3 The Process Table
41
AbsPTAB1
PTAB
PTAB1
dom freech = PID \ used
dom freech ∩used = ∅
∀p : PID •
p ∈used ⇒prio(p) = prio1(p)
∀p : PID •
p ∈used ⇒state(p) = state1(p)
∀p : PID •
p ∈used ⇒wakingtime(p) = wakingtime1(p)
∀p : PID •
p ∈used ⇒smsg(p) = smsg1(p)
∀p : PID •
p ∈used ⇒stacktop(p) = stacktop1(p)
It is clear that the predicate of the AbsPTAB1 schema is a function; indeed,
it is an identity. Abstraction relations of this kind are extremely common.
It is possible to calculate the various operations of the reﬁnement from a
functional abstraction relation and this we resist. Moreover, the fact that the
abstraction relation is an identity implies that the reﬁnement proofs are quite
simple (perhaps even trivial); we include the proofs as a demonstration.
With the abstraction relation deﬁned, it is possible to prove the initialisa-
tion theorem.
Theorem 1. ∀PTAB′; PTAB1′ • PTAB1Init ∧AbsPTAB1 ⇒PTABInit.
Proof. By the predicate of AbsPTAB1, dom freech′ = PID \ used′. The uni-
versally quantiﬁed formula in PTAB1Init’s predicate implies that maxpid ∈
dom freech′ and for all p < maxpid, p ∈dom freech′. This implies that
PID = dom freech′, so, by the abstraction relation, used′ = ∅. 2
Until the end of this section, reﬁnement proofs are presented, two for each
operation that is reﬁned. The proofs are the standard ones (cf. [12] or [13]).
Theorem 2. ∀PTAB; PTAB1 • pre AddPD ∧AbsPTAB1 ⇒pre AddPD1
Proof. We have the following preconditions:
pre AddPD = PID \ used ̸= ∅
and
AddPD1 = hdfree ̸= nullpid
By the abstraction relation, dom freech = PID \ used. If PID \ used ̸= ∅,
it follows that dom freech ̸= ∅. By the invariant of PTAB1, dom freech ̸= ∅
implies that hdfree ̸= nullpid. 2

42
3 A Simple Kernel
Theorem 3.
∀PTAB; PTAB ′; PTAB1; PTAB1′;
pr? : PRIO; st? : PSTATE; p! : PID; serr! : SYSERR •
pre AddPD
∧AbsPTAB1 ∧AbsPTAB1′
∧AddPD1
⇒AddPD
Proof. By the invariant of PTAB1, it is clear that hdfree ̸= nullpid implies
that dom freech ̸= ∅. By the abstraction relation, this implies that PID \
used ̸= ∅, and so used ⊂PID. If used = ∅, used ⊂PID since ∅⊂S, for all
S; if, on the other hand, used ̸= ∅, used ⊂PID by deﬁnition.
If p! = hdfree then p! ̸∈used.
Now, freech −◁{p!} implies used ∪{p!} and by the abstraction relation,
dom freech′ = PID \ used′, so dom freech −◁{p!} = (PID \ used) ∪{p!}, which
is equivalent to PID \ (used ∪{p!}) since free ∪used = PID, and this is
equivalent to PID \ used by the predicate of AbsPTAB1′. From this, we can
infer that used ∪{p!} = used′.
By the abstraction relation, AbsPTAB1
∀p : PID •
p ∈used ⇒prio(p) = prio1(p)
and
∀p : PID •
p ∈used ⇒state(p) = state1(p)
Now, we need to observe that AddPD is deﬁned in terms of a sequential
composition, so the start state of the second component is the after state
of the ﬁrst. Writing the after state for used as used′′, it can be seen that
used′ = used′′. Therefore, p! ̸∈dom freech′ is equivalent to p! ̸∈dom freech′′
and implies p! ̸∈used′ or p! ̸∈used′′. From this, it can be inferred that
prio1 ⊕{p! →pr?} = prio ⊕{p! →pr?}. Since p! ̸∈used′, prio ⊕{p? →
pr?} = prio ∪{p? →pr?} and prio ∪{p? →pr?} = prio′ since prio1′ =
prio1 ⊕{p! →pr?} and prio1′(p) = prio′(p) for all p ∈used′ by AbsPTAB1′.
2
Theorem 4. ∀PTAB; PTAB1; p? : PID • pre DelPD ∧AbsPTAB1 ⇒
pre DelPD1
Proof. The precondition of DelPD is p? ∈used and that of DelPD1 is
p? ̸∈dom freech. By the abstraction relation, dom freech = PID \ used, so
p? ∈used implies that p? ̸∈PID \ used. From this, it may be inferred that
p? ̸∈dom freech. 2

3.3 The Process Table
43
Theorem 5.
∀PTAB; PTAB ′; PTAB1; PTAB1′; p? : PID; serr! : SYSERR •
pre DelPD ∧
AbsPTAB1 ∧AbsPTAB1′ ∧
DelPD1
⇒DelPD
Proof. First, we note that the precondition of DelPD is p? ∈used. We have
a proof composed of two cases.
Case 1. dom freech = ∅implies that used = PID and freech∪{p?} implies that
dom freech∪{p?}. By the identity in AbsPTAB1, dom freech = PID\used, this
clearly implies used \ {p?} iﬀdom freech ∪{p?}. More formally, we can write
this as follows. We start with dom freech = PID \ used, so if dom freech = ∅,
we have:
dom freech = PID \ used
= dom freech ∪{p?} = PID \ (used \ {p?})
= ∅∪{p?} = used \ {p?}
= {p?} = used \ {p?}
By the predicate of FreePID1, dom freech′ = dom freech ∪{p?}, and, by the
predicate of AbsPTAB1′, dom freech′ = PID\used′. Then, dom freech∪{p?} =
dom freech′ = PID \ used′, so, by the above reasoning, used′ = used \ {p?}.
Case 2. dom freech ̸= ∅. In a similar fashion, dom freech = PID \ used, so
dom freech ∪{p?} = PID \ (used \ {p?})
= dom freech′ = PID \ (used \ {p?}
Since dom freech′ = PID \ used′ by the predicate of AbsPTAB1′ and by the
above reasoning, dom freech′ = PID \ (used ∪{p?}) = used′. 2
At this point, it is necessary to point out that, throughout the speciﬁcation
and reﬁnement of this kernel, there are many operations on the state-describing
components of PTAB and its derivatives. For example, the operation to update
the value of the state component of PTAB is
SetProcState
∆PTAB
p? : PID
st? : PSTATE
state′ = state ⊕{p? →st?}
In each case, it would be possible to write such an operation as
(p? ∈used ∧Op ∧SysOk) ∨Error
In the case of SetProcState, it would be
(p? ∈used ∧SetProcState ∧SysOk) ∨UnusedPD

44
3 A Simple Kernel
However, the operations are only deﬁned in terms of their testing or of their
eﬀect on PTAB components (and their reﬁnements). The reason for this is
that the operation or predicate is used within a context that ensures that
p? ∈used is always the case. We argue that this condition does not have to
be ensured by the operation because some other component will do it anyway.
If the operations were deﬁned as disjunctions, it would be necessary to use
(p ∨q) ∧r ⇔(p ∧r) ∨(q ∧r) to move and combine SysOk (and possibly
move the error schema).
As far as the precondition of these operations is concerned, they typically
occur as conjuncts and therefore must be recalculated wherever they occur.
There appears to be very little to be gained by explicitly calculating the
precondition when deﬁning the operation.
It might be argued that the reﬁnement process is not complete until these
two steps have been completed. We argue that the reﬁnement of these op-
erations is a rather trivial matter, a matter that can be done in one’s head,
by inspection, so the requirement that the proofs be recorded should not de-
tain us—they are obvious given the abstraction relation. We can assure the
reader that the necessary checking (making the assumption that p? ∈used
and p? ̸∈dom freechain) has been done by us in order to verify the reﬁnement.
Should the above prove too oﬀensive to the reader, they can always assume
that the operation has been deﬁned in the “export” (disjunctive) form and
that the precondition has been calculated. The reader can, in any case, always
supply the proofs for themselves; each should take no more than a couple of
seconds.
3.3.3 Reﬁnement Two
In this reﬁnement, the function freech is replaced by the next function. The in-
tention is that next allows us to represent a list of process descriptors (actually
a list of process identiﬁers).
The next function will be used in other modules. In particular, it will be
used by reﬁnement of the PROCESSQUEUE type to implement FIFO queues.
PTAB2
freehd, freelst : GPID
prio2 : PID →PPRIO
state2 : PID →PSTATE
smsg2 : PID →MSG
stacktop2 : PID →ADDR
wakingtime2 : PID →TIME
next : PID ↣GPID
freehd = nullpid ⇔freelst = nullpid
freehd = nullpid ⇒next∗(| {freehd} |) = ∅

3.3 The Process Table
45
freehd ̸= nullpid ⇔
∀p : PID •
p = freehd ⇒nullpid ∈next+(| {freehd} |)
freehd ̸= nullpid ⇔
∀p : PID •
p = freelst ⇒next(freelst) = nullpid
freehd ̸= nullpid ⇒∃1 k : N • nextk(freehd) = nullpid
The new function, next, replaces freech (as will be seen in the next para-
graph, it actually does a little more). In this reﬁnement, next is an injection, so
it is 1-1. Furthermore, it is a total function for the reason that other operations
(e.g., queues of various kinds) are implemented using next, thus accounting
for the majority of process identiﬁers. When an identiﬁer is not present in a
structure, it is mapped to nullpid (this is the justiﬁcation for the codomain
type).
The fact that next will be used by other modules implies that we are not
permitted to assume that all of its domain is relevant to the free list. This in
turn implies that the reﬂexive transitive closure of the next, next∗, must be
used to determine membership of the free list.
PTAB2Init
PTAB2′
freehd ′ = minpid
freelst′ = maxpid
∀p : PID •
p = maxpid ⇒next′(p) = nullpid ∧
p < maxpid ⇒next′(p) = p + 1
Note that the invariant on PTAB2 does not mention the state-denoting func-
tions prio2, state2, stacktop2 and wakingtime2. In the present case, they are
all total functions, so their domains are pre-deﬁned. The question as to their
initialisation also arises. It is considered that the operations deﬁned below
are suﬃcient to guarantee that a valid value is not supplied to a non-existant
process.
Since the PTAB reﬁnement has already progressed some way, the abstrac-
tion relation is presented immediately.
AbsPTAB2
PTAB1
PTAB2
freehd = hdfree
freelst = endfree

46
3 A Simple Kernel
freehd ̸= nullpid ⇔next∗(| {freehd} |) \ {nullpid} = dom freech
dom freech = ∅⇔freehd = freelst ∧freehd = nullpid
freehd ̸= nullpid ⇔∀p : PID • p ∈dom freech ⇒next(p) = freech(p)
dom freech ⊆dom next
ran freech ⊆ran next
∀p : PID • p ∈dom freech ⇔next(p) = freech(p)
∀p : PID •
p ̸∈next∗(| {freehd} |) \ {nullpid} ⇒state1(p) = state2(p)
∀p : PID •
p ̸∈next∗(| {freehd} |) \ {nullpid} ⇒
prio1(p) = prio2(p)
∀p : PID •
p ̸∈next∗(| {freehd} |) \ {nullpid} ⇒
smsg1(p) = smsg2(p)
∀p : PID •
p ̸∈next∗(| {freehd} |) \ {nullpid} ⇒
stacktop1(p) = stacktop2(p)
∀p : PID •
p ̸∈next∗(| {freehd} |) \ {nullpid} ⇒
wakingtime1(p) = wakingtime2(p)
One of the interesting features of this schema is the implication
freehd ̸= nullpid ⇒
next∗(| {freehd} |) \ {nullpid} = dom freech
In what follows, relational images will be used quite extensively. In this case,
the relational image is that of the transitive closure of the head of the next
chain; the set that results includes the nullpid that terminates the next chain
and this has to be removed to yield a set of type F PID.
A second interesting feature is the use of the next function together with
the freehd and freelst variables. The next function has a domain that includes
the domain of freech and its codomain includes freech’s domain. The freehd
and freelst variables record the head and last elements of the chain, so it is
easy to remove elements from the head and add them at the end.
The initialisation theorem can now be proved. Over the years, we have
found it useful to attempt the initialisation theorem as soon as the abstraction
relation has been deﬁned, for it is a good way of determining whether the
abstraction relation is adequate.
Theorem 6. ∀PTAB1′; PTAB2′ • PTAB1Init ∧AbsPTAB2 ⇒PTAB2Init
Proof. By the abstraction relation, freehd′ = hdfree′ and freelst′ = endfree′,
so freehd′ = minpid
⇒hdfree′ = minpid and freelst′ = maxpid
⇒

3.3 The Process Table
47
endfree′ = maxpid. By the invariants of PTAB1 and PTAB2, next′(freelst′) =
nullpid = freech′(endfree′). Finally, the quantiﬁed formulae are equivalent by
the abstraction relation. The two conjuncts have the same antecedents and
p = maxpid and p < maxpid imply that p ranges over all of PID. By the
consequents, p ∈dom next′ for all p ∈PID, which implies, by dom freech′ ⊆
dom next′, that dom freech′ = dom next′ for the reason that dom next′ = PID
by this quantiﬁed formula. This also implies that dom freech ̸= ∅, so freehd′ =
nullpid is justiﬁed. 2
The operations that are now deﬁned should be familiar to the reader by
now. In any case, they are deﬁned in the obvious fashion, given the deﬁnition
of PTAB2. The one exception is that the transitive closure of a relational
image is frequently used for PTAB2 operations where a simple set operation
is used by the corresponding operation over PTAB1.
GotFreePIDs2
ΞPTAB2
freehd ̸= nullpid
AllocPID2
∆PTAB2
p! : PID
p! = freehd
freehd ′ = next(freehd)
UsedPID2
ΞPTAB2
p? : PID
p? ̸∈next∗(| {freehd} |) \ {nullpid}
AddPDESC2
∆PTAB2
p? : PID
pr? : PPRIO
st? : PSTATE
prio2′ = prio2 ⊕{p? →pr?}
state2′ = state2 ⊕{p? →st?}
wakingtime2′ = wakingtime2 ⊕{p? →0}
stacktop2′ = stacktop2 ⊕{p? →nulladdr}

48
3 A Simple Kernel
The next few operations deal with addition to the free chain. The deﬁn-
itions are directly analogous to those employed for PTAB1 and the overall
structure of the composite operations is similar. For these reasons, we believe
there is little to be said about these schemata.
SetFCLast2
∆PTAB2
p? : PID
freelst′ = p?
SetFCHead2
∆PTAB2
p? : PID
freehd ′ = p?
AddFreechainLast2
∆PTAB2
p? : PID
next′ = next ⊕{p? →nullpid}
AddNewLastFreechain2
∆PTAB2
p? : PID
next′ = next ⊕{freelst →p?}
AddPD2 =
((GotFreePIDS2 ∧AllocPID2)
o
9((UsedPID2[p!/p?] ∧AddPDESC2[p!/p?] ∧SysOk)
∨PDInUse))
∨PTABFull
This expands to:

3.3 The Process Table
49
AddPD2
∆PTAB2
p! : PID
serr! : SYSERR
pr? : PPRIO
st? : PSTATE
((freehd ̸= nullpid ∧
p! = freehd ∧
freehd ′ = next(freehd))
o
9(p! ̸∈next∗(| {next(freehd)} |) \ {nullpid} ∧
prio2′ = prio2 ⊕{p! →pr?} ∧
state2′ = state2 ⊕{p! →st?} ∧
serr! = sysok)
∨serr! = pdinuse)
∨serr! = ptabful
Note that the form of this operation causes a little confusion, especially
when transcribed to code.
Expanding the sequential composition, o
9, we obtain the following schema:
AddPD2
∆PTAB2
p! : PID
serr! : SYSERR
pr? : PPRIO
st? : PSTATE
(∃next′′ : PID ↣GPID •
freehd ̸= nullpid ∧
p! = freehd ∧
freehd ′′ = next(freehd) ∧
p! ̸∈next∗(| {freehd ′′} |) \ {nullpid} ∧
prio2′ = prio2 ⊕{p! →pr?} ∧
state2′ = state2 ⊕{p! →pr?} ∧
serr! = sysok)
∨serr! = pdinuse
∨serr! = ptabfull
This can be simpliﬁed in a number of steps. First, next′′ = next and, what is
more, next′ = next for the reason that it is never updated (all that is done
is to move freehd down the chain). It is also the case that freehd′′ = freehd′.
The output p! is retained. This entitles us to rewrite AddPD2 as:

50
3 A Simple Kernel
AddPD2
∆PTAB2
p! : PID
serr! : SYSERR
pr? : PPRIO
st? : PSTATE
(freehd ̸= nullpid ∧
p! = freehd ∧
freehd ′ = next(freehd) ∧
p! ̸∈next∗(| {next(freehd)} |) \ {nullpid} ∧
prio2′ = prio2 ⊕{p! →pr?} ∧
state2′ = state2 ⊕{p! →pr?} ∧
serr! = sysok)
∨serr! = pdinuse
∨serr! = ptabfull
For reasons that will later become clear, it should be noted that prio2 = prio2′′
and state2 = state2′′.
Omitting the assignments to serr! (since they contribute nothing to the
precondition), we have
pre AddPD2 =
∃PTAB2′; p! : PID •
freehd ̸= nullpid ∧
p! = freehd ∧
freehd ′ = next(freehd) ∧
p! ̸∈next∗(| {next(freehd)} |) \ {nullpid} ∧
prio2′ = prio2 ⊕{p! →pr?} ∧
state2′ = state2 ⊕{p! →pr?}
This simpliﬁes to
pre AddPD2 =
freehd ̸= nullpid ∧
freehd ̸∈next∗(| {next(freehd)} |) \ {nullpid}
This can be simpliﬁed to
freehd ̸= nullpid
If freehd ̸= nullpid, next∗(| {next(freehd)} |) \ {nullpid} = next+(| {freehd} \
{nullpid} and freehd is not an element of this set by deﬁnition. If freehd =
nullpid, then next∗(| {next(freehd)} |) \ {nullpid} = ∅, so freehd cannot be an
element.
Because we are dealing with modiﬁed relational images so frequently, it is
essential to prove the following theorem.

3.3 The Process Table
51
Theorem 7. The following are equivalent.
p ∈next∗(| {next(freehd)} |) \ {nullpid}
and
p = freehd
∨∃k : N •
0 < k ∧k ≤# dom next∗(| {next(freehd)} |) \ {nullpid} •
p = nextk(freehd)
Proof. By the deﬁnition of ∗,
next∗(| {next(freehd)} |) \ {nullpid}
= {freehd} ∪next+(| {next(freehd)} |) \ {nullpid}
for the reason that R∗= {k : N • Rk} and R+ = {k : N1 • Rk}. As
usual, for k > 0, Rk = R o
9 Rk−1, here, expressed as a function, so nextk =
next(nextk−1(x)). We also note that the above expressions in next are well-
typed (F PID) owing to the elimination of nullpid.
For convenience, let N = next∗(| {next(freehd)} |)\{nullpid}. If p = freehd,
p ∈N by the identity at the start of this proof. Otherwise, assume that there
is some n −1 < # dom N such that ∀i : 1 . . n −1 • p ̸= nexti(freehd). Then,
for n, either p = nextn(freehd) or p ̸= nextn(freehd). If p = nextn(freehd), it
follows that p ∈N and we are done. Otherwise, we continue. If n = #N and
p ̸= nextn(freehd), then p ̸∈N ; otherwise, p ∈N . 2
This result permits us to re-write p ∈next∗(| {next(freehd)} |) \ {nullpid}
as
p = freehd
∨∃k : N •
0 < k ∧k ≤# dom next∗(| {next(freehd)} |) \ {nullpid} •
p = nextk(hd)
and p ̸∈next∗(| {next(freehd)} |) \ {nullpid} as
p ̸= freehd
∨¬ ∃k : N •
0 < k ∧k ≤# dom next∗(| {next(freehd)} |) \ {nullpid} •
p = nextk(hd)
The reason for this is that the quantiﬁed form of set membership is, we
believe, much closer to a computationally realisable form than the somewhat
more cryptic relational image.
There are other cases in which this equivalence can be used to re-write
schemata. They will be indicated and the re-written schema will be given.
Therefore, given the equivalence, AddPD2 becomes

52
3 A Simple Kernel
AddPD2
∆PTAB2
p! : PID
serr! : SYSERR
pr? : PPRIO
st? : PSTATE
(freehd ̸= nullpid ∧
p! = freehd ∧
freehd ′ = next(freehd) ∧
p! ̸∈next∗(| {next(freehd)} |) \ {nullpid} ∧
(p ̸= freehd
∨(¬ ∃k : N •
0 < k ≤#next∗(| {next(freehd)} |) \ {nullpid} ∧
nextk(freehd) = p) ∧
prio2′ = prio2 ⊕{p! →pr?} ∧
state2′ = state2 ⊕{p! →pr?} ∧
serr! = sysok)
∨serr! = pdinuse
∨serr! = ptabfull
For FreePID2, we need to deﬁne EmptyFreeChain2. It is the negation of
GotFreePIDs2:
EmptyFreeChain2
ΞPTAB2
freehd = nullpid
(This schema is exactly as we would expect.)
The operation to deallocate a process identiﬁer is similar to FreePID2.
The reader can compare the two to see that this is the case (in fact, FreePID2
was deﬁned by rewriting FreePID1, substituting the operations directly).
FreePID2 =
((EmptyFreeChain2 ∧
AddFreechainLast2 ∧SetFCLast2 ∧SetFCHead2 ∧
SysOk)
∨(UsedPID2 ∧
(AddNewLastFreechain2 o
9 AddFreechainLast2) ∧
SetFCLast2 ∧
SysOk)
∨UnusedPID
The deﬁnition of FreePID2 expands into the following schema:

3.3 The Process Table
53
FreePID2
∆PTAB2
p? : PID
serr! : SYSERR
(freehd = nullpid ∧
next′ = next ⊕{p? →nullpid} ∧
freelst′ = p? ∧
freehd ′ = p? ∧
serr! = sysok)
∨((p? ̸∈next∗(| {freehd} |) \ {nullpid} ∧
(∃next′′ : PID ↣GPID •
next′′ = next ⊕{freelst →p?} ∧
next′ = next′′ ⊕{p? →nullpid}) ∧
freelst′ = p? ∧
serr! = sysok)
∨serr! = unusedpd)
The schema can be simpliﬁed, so we obtain the following:
∆PTAB2
p? : PID
serr! : SYSERR
(freehd = nullpid ∧
next′ = next ⊕{p? →nullpid} ∧
freelst′ = p? ∧
freehd ′ = p? ∧
serr! = sysok)
∨((p? ̸= freehd ∨
¬ (∃k : N •
0 < k ∧k ≤#next∗(| {freehd} |) \ {nullpid} ∧
nextk(freehd) = p)
next′ = (next ⊕{freelst →p?}) ⊕{p? →nullpid} ∧
freelst′ = p? ∧
serr! = sysok)
∨serr! = unusedpd)
The precondition of FreePID2 is required by the reﬁnement proofs. It is
calculated as follows.
pre FreePID2 =
freehd = nullpid
∨p? ̸∈next∗(| {freehd} |) \ {nullpid}
This simpliﬁes to

54
3 A Simple Kernel
p? ̸∈next∗(| {freehd} |) \ {nullpid} pre FreePID2 =
freehd = nullpid
∨p? ̸∈next∗(| {freehd} |) \ {nullpid}
This simpliﬁes to
p? ̸∈next∗(| {freehd} |) \ {nullpid}
If freehd = nullpid, then next∗(| {freehd} |) \ {nullpid} = ∅, so p? cannot be
an element.
We continue with the statement and proof of the theorems required by the
reﬁnement process.
Theorem 8.
∀PTAB1; PTAB2; pr? : PPRIO; st? : PSTATE •
pre AddPD1 ∧AbsPTAB2 ⇒AddPD2
Proof. If freehd = nullpid, then next∗(| {freehd} |) \ {nullpid} = ∅, so p?
cannot be an element. 2
Theorem 9.
∀PTAB1; PTAB2; pr? : PPRIO; st? : PSTATE •
pre AddPD1 ∧AbsPTAB2 ⇒AddPD2
Proof. The precondition of AddPD1 is hdfree ̸= nullpid, while that of
AddPD2 is freehd ̸= nullpid. By the predicate of AbsPTAB2, freehd = hdfree.
2
Theorem 10.
∀PTAB1; PTAB1′; PTAB2; PTAB2′; pr? : PPRIO; st? : PSTATE
p! : PID; serr! : SYSERR •
pre AddPD1 ∧
AbsPTAB2 ∧
AbsPTAB2′ ∧
AddPD2
⇒AddPD1
Proof. By the predicate of AbsPTAB2, freehd ̸= nullpid implies hdfree ̸=
nullpid, so freehd = hdfree. We note that freehd ̸= nullpid is pre AddPD1.
The same identity, this time in the after state, as required by AbsPTAB2′,
permits us to reason that freehd′ = hdfree′ = p!.
It is given that next′ = next(freehd). This implies that
dom next′ =
(next∗(| {freehd} |) \ {nullpid}) \ {freehd}
= next+(| {freehd} |) \ {nullpid})
= next∗(| {next(freehd)} |) \ {nullpid}

3.3 The Process Table
55
and by the predicate of AbsPTAB2
(next∗(| {freehd} |) \ {nullpid}) \ {freehd}
= (dom freech) \ {freehd}
By the deﬁnition of −◁, dom freech \{freehd} implies freech −◁{freehd}. We may
infer that dom next′ = dom freech \ {freehd} = freech −◁{freehd} and, for the
reason that freehd = p!, we have freech −◁{p!}. The predicate of AbsPTAB2′
permits us to infer that, since next′ = freech −◁{p!}, freech′ = freech −◁{p!}.
For the remainder, we need to remember that the operation is deﬁned in
terms of sequential composition. The variables updated by the ﬁrst component
are unaﬀected by the second, so next′ = next′′. We can express the condition
on prio1 and prio2 and on state1 and state2 as:
∀p : PID •
p! ̸∈next∗(| {next(freehd)} |) \ {nullpid} ⇒
prio1(p) = prio2(p)
and
∀p : PID •
p! ̸∈next∗(| {next(freehd)} |) \ {nullpid} ⇒
state1(p) = state2(p)
The antecedent in both cases has already been established, so prio1(p) =
prio2(p) and state1(p) = state2(p) for all p not in the next chain, so prio1 ⊕
{p! →pr?} = prio2 ⊕{p! →pr?} and state1 ⊕{p! →st?} = state2 ⊕{p! →
st?}. In the ﬁrst case, prio2⊕{p! →st?} = prio2′ by the predicate of AddPD2
and, by the predicate of AbsPTAB2′, prio2′(p) = prio1′(p) for all p not in
the modiﬁed next chain. The case for state1 is similar. 2
Theorem 11. ∀PTAB1; PTAB2; p? : PID • pre FreePID1 ∧AbsPTAB2 ⇒
pre FreePID2
Proof. The precondition of FreePID1 is p? ̸∈dom freech and that of
FreePID2 is p? ̸∈next∗(| {freehd} |){nullpid}. By the predicate of AbsPTAB2,
dom freech = next∗(| {freehd} |) \ {nullpid}. The result is immediate. 2
Theorem 12.
∀PTAB1; PTAB1′; PTAB2; PTAB2′; p? : PID; serr! : SYSERR •
pre FreePID1 ∧
AbsPTAB2 ∧
AbsPTAB2′ ∧
FreePID2
⇒FreePID1
Proof. The result immediately follows from the identities in AbsPTAB1 and
AbsPTAB2. 2
The schemata from this last reﬁnement have now been shown to be correct.
They can be converted directly into executable code.

56
3 A Simple Kernel
3.4 Process Queue
Process queues are used in a variety of places, most notably in semaphores.
The queue type deﬁned in this section is not the one used by the scheduler.
The scheduler employs a priority queue that is, ultimately, implemented as a
vector (one-dimensional array). The queue deﬁned here will be implemented
as a list of process descriptor references. comprising th The plan is to reﬁne
the top-level representation to a chain in next. This will require two steps of
reﬁnement.
As usual, we begin with the statement of the error schemata. In the case
of PROCESSQUEUE, there is only one such schema. It reports the condition
that the process queue is empty (presumably this condition is reported when
an attempt to dequeue an element has been attempted).
ProcessQueueEmpty
serr! : SYSERR
serr! = emptyqueue
3.4.1 Top Level
This is a relatively straightforward speciﬁcation of a FIFO queue. It uses a
sequence as its basic container structure.
The queue state space is deﬁned as follows. The queue itself is procs.
PROCESSQUEUE
PTAB
procs : iseq PID
ran procs ⊂used
Note that the invariant is being used to enforce a global condition upon the
queue, namely that all elements of the queue must also be elements of used—
in other words, every process identiﬁer in the queue must be that of a process
that exists in the system.
PROCESSQUEUEInit
PROCESSQUEUE ′
procs′ = ⟨⟩
The initialisation is as one would expect. The queue is set to empty (to the
empty sequence, that is). This initialisation trivially preserves the invariant.
The next operation is a predicate that evaluates to true when the queue,
procs, is not empty.

3.4 Process Queue
57
IsNotEmptyPROCESSQUEUE
ΞPROCESSQUEUE
procs ̸= ⟨⟩
The operation to enqueue a process identiﬁer on the queue is deﬁned next.
It is deﬁned in the obvious fashion.
EnqueuePROCESSQUEUE
∆PROCESSQUEUE
p? : PID
procs′ = procs ⌢⟨p?⟩
By substitution of identicals, the precondition of the enqueue operation is
obtained.
pre EnqueuePROCESSQUEUE =
procs ⌢⟨p?⟩= procs ⌢⟨p?⟩
This version of the precondition is clearly equivalent to the following:
pre EnqueuePROCESSQUEUE = true
The next few operations are concerned with dequeueing elements. In the
present case, the operation is decomposed into a number of smaller operations,
the ﬁrst of which merely returns the head of the queue.
TheHeadOfPROCESSQUEUE
ΞPROCESSQUEUE
p! : PID
p! = head procs
Note that this operation leaves the queue, procs, invariant.
The previous operation cannot be used in isolation because it does not
include checks that the queue is empty (if procs = ⟨⟩, head procs is undeﬁned).
Therefore, the following is deﬁned.
HeadOfPROCESSQUEUE =
(IsNonEmptyPROCESSQUEUE ∧
TheHeadOfPROCESSQUEUE ∧
SysOk)
∨ProcessQueueEmpty
This composite operation expands into:

58
3 A Simple Kernel
HeadOfPROCESSQUEUE
ΞPROCESSQUEUE
p! : PID
serr! : SYSERR
(procs ̸= ⟨⟩∧
p! = head procs ∧
serr! = sysok)
∨serr! = emptyqueue
We calculate the precondition, should it be required by reﬁnement proofs.
pre HeadOfPROCESSQUEUE =
procs ̸= ⟨⟩
The dequeue operation is deﬁned in terms of the removal of the ﬁrst ele-
ment of the queue. Removal is performed by the following schema.
DelHeadOfPROCESSQUEUE
∆PROCESSQUEUE
procs′ = tail procs
This is another partial operation (partial in the sense that when procs = ⟨⟩,
tail procs is undeﬁned). In order to make the operation useful, it is necessary
to test whether the queue, procs, is empty. Therfore, the following is required:
DequeuePROCESSQUEUE =
(IsNotEmptyPROCESSQUEUE ∧
HeadOfPROCESSQUEUEU ∧
DelHeadOfPROCESSQUEUE ∧
SysOk)
∨ProcessQueueEmpty
This composite operation expands into:
DequeuePROCESSQUEUE
∆PROCESSQUEUE
p! : PID
serr! : SYSERR
(procs ̸= ⟨⟩∧
p! = head procs ∧
procs′ = tail procs ∧
serr! = sysok)
∨serr! = emptyqueue

3.4 Process Queue
59
The precondition is easily calculated:
pre DequeuePROCESSQUEUE =
procs ̸= ⟨⟩
3.4.2 Reﬁnement One
In this subsection, we will refer to PROCESSQUEUE’s reﬁnement as PQ1;
this is just so that typing is reduced.
PQ1
hdproc, lstproc : GPID
procseq : PID
↣GPID
hdproc = nullpid ⇔lstproc = nullpid
(hdproc = nullpid ∧
lstproc = nullpid ⇔
dom procseq = ⟨⟩)
(hdproc ̸= nullpid ⇔
hdproc ∈dom procseq ∧
lstproc ∈dom procseq ∧
dom procseq ̸= ∅)
The sequence procs is represented by procseq a partial injection between PID
and GPID. It will be remembered that GPID = PID ∪{nullpid}. The func-
tion procseq is 1-1, so each element maps to exactly one element of PID, thus
permitting each domain element exactly one successor; procseq is partial be-
cause not all process identiﬁers are in the queue at any one time (and because
they enter and leave the queue). The function procseq models the ordered
part of the sequence procs, as well as procs’ rˆole as a container. The value
nullpid is the value that is always assigned to the last element of procseq.
The two variables hdproc and lstproc represent the ﬁrst and last elements of
the sequence, so when hdproc = lstproc and hdproc = nullpid, the queue is
empty.
We will now give the abstraction relation. It is very much as one would
expect and it is, once more, an identity.
AbsPQ1
PROCESSQUEUE
PQ1
dom procseq = ran procs
hdproc = nullpid ⇔procs = ⟨⟩
(hdproc ̸= nullpid ∧hdproc = lstproc ⇔head procs = last procs)
hdproc ̸= nullpid ⇔
hdproc = head procs

60
3 A Simple Kernel
hdproc ̸= nullpid ⇔
lstproc = last procs
hdproc ̸= nullpid ⇔
procseq(lstproc) = nullpid
hdproc ̸= nullpid ⇔
∀i : 1 . . #procs −1 •
procseq(procs(i)) = procs(i + 1))
The initialisation operation is as one would expect:
PQ1Init
PQ1′
hdproc′ = nullpid
lstproc′ = nullpid
It merely sets the queue to empty.
The emptiness of PQ1 is determined by the following operation:
IsNonEmptyPQ1
ΞPQ1
hdproc ̸= nullpid
The invariant of PQ1 states that hdproc ̸= nullpid implies hdproc ̸= lstproc,
which, in turn, implies that procseq is not empty.
The operation to enqueue a process identiﬁer is slightly more complex
than for the top-level state space. It is necessary to divide enqueueing into
two cases: where the queue is empty (so the newly added element will be both
ﬁrst and last), and where the queue is not empty (and so the newly added
element is the last).
EnqueuePQ1
∆PQ1
p? : PID
(hdproc = nullpid ∧
procseq′ = {p? →nullpid} ∧
hdproc′ = p? ∧
lstproc′ = p?)
∨((∃procseq′′ : PID
↣GPID •
procseq′′ = procseq ⊕{lstproc →p?} ∧
procseq′ = procseq′′ ∪{p? →nullpid} ∧
lstproc′ = p?)
The existential quantiﬁer can be removed using the one-point rule and the
schema becomes

3.4 Process Queue
61
EnqueuePQ1
∆PQ1
p? : PID
(hdproc = nullpid ∧
procseq′ = {p? →nullpid} ∧
hdproc′ = p? ∧
lstproc′ = p?)
∨(procseq′ = (procseq ⊕{lstproc →p?}) ∪{p? →nullpid} ∧
lstproc′ = p?)
Rewriting the identities, the schema now becomes
EnqueuePQ1
∆PQ1
p? : PID
(hdproc = nullpid ∧
{p? →nullpid} = {p? →nullpid} ∧
p? = p? ∧
p? = p?)
∨(procseq ⊕{lstproc →p?}) ∪{p? →nullpid}
= (procseq ⊕{lstproc →p?}) ∪{p? →nullpid} ∧
p? = p?)
To calculate the precondition, the fact that lstproc ∈dom procseq allows us
to infer that dom procseq ̸= ∅, so we have
(hdproc = nullpid) ∨(hdproc ̸= nullpid)
⇔true
More formally,
pre EnqueuePQ1 = true
The next few operations constitute the sub-operations needed to deﬁne
the dequeue operation. These operations are directly analogous to those re-
quired by PROCESSQUEUE and are presented in the same order. First, the
operation to return the head of the queue is deﬁned.
TheHeadOfPQ1
ΞPQ1
p! : PID
p! = hdproc
In the present case, returning the head of the queue is as easy as it was at top
level. The head is always hdproc, so p! = hdproc returns the head element.

62
3 A Simple Kernel
The above operation does not guard for the empty queue, so the following
is required:
HeadOfPQ1 =
(IsNonEmptyPQ1 ∧TheHeadOfPQ1 ∧SysOk)
∨ProcessQueueEmpty
It expands into:
HeadOfPQ1
ΞPQ1
p! : PID
serr! : SYSERR
(hdproc ̸= nullpid ∧
p! = hdproc ∧
serr! = sysok)
∨serr! = emptyqueue
A simple and easy calculation yields the precondition.
pre HeadOfPQ1 = hdproc ̸= nullpid
The operation to remove the head of the queue is a little more complex
than in the top-level case.
DelHeadOfPQ1
∆PQ1
procseq′ = procseq −◁{hdproc}
hdproc′ = procseq(hdproc)
The head element must be removed and the head pointer must be updated.
In this case, if the queue becomes empty by the deletion of the head element,
the last element must be updated to nullpid. Note that when hdproc′ is bound
to nullpid, the invariant requires that lstproc′ is also assigned to that value.
To make the operation safer, the following is deﬁned. Schema DequeuePQ1
is similar to the corresponding operation deﬁned for PROCESSQUEUE.
DequeuePQ1 =
(IsNonEmptyPQ1 ∧HeadOfPQ1 ∧DelHeadOfPQ1 ∧SysOk)
∨ProcessQueueEmpty
The deﬁnition expands into:

3.4 Process Queue
63
DequeuePQ1
∆PQ1
p! : PID
serr! : SYSERR
(hdproc ̸= nullpid ∧
p! = hdproc ∧
procseq′ = procseq −◁{hdproc} ∧
hdproc′ = procseq(hdproc) ∧
serr! = sysok)
∨serr! = emptyqueue
(Again, it is worth noting that, by the invariant, the assignment of nullpid to
hdproc′ implies that lstproc′ is also bound to nullpid.)
Substitution of identicals yields the following as the precondition:
hdproc ̸= nullpid
by the invariant of PQ1, this is equivalent to
dom procseq ̸= ∅
To see the ﬁrst version, it should be noted that hdproc = lstproc ∧lstproc′ =
nullpid has the implication that hdproc ̸= lstproc ∧lstproc′ = lstproc. In any
case, hdproc = lstproc and hdproc ̸= nullpid conjointly imply that lstproc ̸=
nullpid, so dom procseq ̸= ∅, so the precondition is quite adequate.
Theorem 13. ∀PROCESSQUEUE ′; PQ1′ • PQ1Init ∧AbsPTAB1′ ⇒
PQInit
Proof. By the invaraiant of PQ1, hdproc′ = nullpid ⇔lstproc′ = nullpid.
Since hdproc′ = nullpid, it follows that procs′ = ⟨⟩. The initialisation schema
of PQ is precisely procs′ = ⟨⟩. 2
Theorem 14. ∀PROCESSQUEUE;
PQ1;
p? : PID
• pre Enqueue
∧
AbsPQ1 ⇒pre Enqueue1
Proof. Trivial (true ⇒true). 2
Theorem 15.
∀PROCESSQUEUE; PROCESSQUEUE ′; PQ1; PQ1′; p? : PID •
pre Enqueue ∧
AbsPQ1 ∧AbsPQ1′ ∧
EnqueuePQ1
⇒Enqueue

64
3 A Simple Kernel
Proof. By the invariant of PQ1, hdproc = nullpid, which, by the predicate
of AbsPQ1, implies that dom procseq = ∅. The abstraction relation states
that dom procseq = ran procs, so procs = ⟨⟩.
By the predicate of AbsPQ1′, hdproc′ = head procs′ and lstproc′ =
last procs′. We have hdproc′ = p? ∧lstproc′ = p?, so head procs′ =
last procs′ = p?, so procs′ = ⟨p?⟩= ⟨⟩⌢⟨p?⟩= procs ⌢⟨p?⟩.
Otherwise, dom procseq ̸= ⟨⟩. We have (procseq ⊕{lstproc →p?} ∪{p? →
nullpid})(p?) = nullpid and this implies that lstproc′ = p? (since the invariant
requires that procseq(lstproc) = nullpid). This, by the predicate of AbsPQ1′,
implies that last procs′ = p?. Since hdproc ̸= nullpid, the last conjunct of the
abstraction schema,
∀i : 1 . . #procs; p : PID •
procseq(procs(i)) = procs(i + 1)
allows us to infer that procs ⌢⟨p?⟩is equivalent to procseq′ and, therefore,
procs ⌢⟨p?⟩= procs′ as required. 2
Theorem 16.
∀PROCESSQUEUE; PQ1 •
pre DequeuePROCESSQUEUE ∧AbsPQ1 ⇒pre DequeuePQ1
Proof. The precondition of DequeuePROCESSQUEUE is procs ̸= ⟨⟩and
that of DequeuePQ1 is dom procseq ̸= ∅. The predicate of the AbsPQ1
states that dom procseq = ran procs, so procs ̸= ⟨⟩implies that ran procs ̸=
∅. Therefore, we have ran procs ̸= ∅and ran procs = dom procseq, so
dom procseq = ∅. 2
Theorem 17.
∀PROCESSQUEUE; PROCESSQUEUE ′; PQ1; PQ1′;
p! : PID; serr! : SYSERR •
pre DequeuePROCESSQUEUE ∧
AbsPQ1 ∧AbsPQ1′ ∧
DequeuePQ1
⇒DequeuePROCESSQUEUE
Proof. First of all, we have hdproc ̸= nullpid. By the invariant, this implies
that dom procseq ̸= ∅which, in turn, by the abstraction relation, AbsPQ1,
implies that ran procs ̸= ∅or procs ̸= ⟨⟩.
Now, by the predicate of AbsPQ1, hdproc = head procs, so head procs =
p?.
We have procseq −◁{hdproc} implies (dom procseq) \ {hdproc}. By the ab-
straction schema, AbsPQ1, hdproc = head procs, so we are entitled to infer
that ran procs \ {head procs} = (dom procseq) \ {hdproc}, so head procs is re-
moved from procs when hdproc is. By the identity, hdproc′ = procseq(hdproc),

3.4 Process Queue
65
head procs′ = procseq(head procs) = procseq(procs(1)) = procs(1 + 1) =
procs(2). This implies that procs′ = tail procs.
We can check that the result has suﬃcient elements by observing that
#(procseq −◁{hdproc}) = (# dom procseq) −1 = # tail procs = #procs −1. 2
3.4.3 Reﬁnement Two
In this reﬁnement, the process queue is reduced to a queue in the process
table. This reﬁmenent uses the next attribute of the process descriptor. The
reﬁnement process is achieved by reducing the function procseq to the next
sequence in a manner that should be relatively clear and familiar.
This reﬁnement saves space in the kernel by reducing every FIFO queue
of processes to a head and end pointer and a chain using the next process
attribute.
Comparison of the following schema and PQ1 will reveal that the diﬀer-
ences are more apparent than real. In the present case, the next function in
PTAB2 takes over from procseq, thus permitting the abbreviation of the PQ2
schema.
PQ2
PTAB2
hdq, endq : GPID
hdq = nullpid ⇔endq = nullpid
hdq ̸= nullpid ⇔
next(endq) = nullpid
hdq ̸= nullpid ⇒
endq ∈next∗(| {hdq} |)
Here, again, the transitive closure of a relational image is employed to denote
a subset.
The initialisation schema is as one would expect:
PQ2Init
PQ2′
hdq′ = nullpid
endq′ = nullpid
The operation to enqueue a process identiﬁer on PQ2 is deﬁned. Just as
was the case with PQ1, the predicate is divided into two cases: the case in
which the queue is empty and that in which the queue is non-empty.
In the ﬁrst case, the head and last variables must be assigned to p?,
the identiﬁer of the process being enqueued, and p? must be added to next.
Since p? is now the last element of the chain, the image of p? under next must
be nullpid, so {p? →nullpid} must be added to next. In the second case, the

66
3 A Simple Kernel
queue is not empty, so p? must be added to the end of the queue. To satisfy
the invariant, next′(p?) = nullpid so nullpid must be added to next, as well
as p?; for the reason that there are two additions, not one, what amounts to
a sequential composition is hidden within this schema.
EnqueuePQ2
∆PQ2
p? : PID
(hdq = nullpid ∧
hdq′ = p? ∧
endq′ = p? ∧
next′ = next ⊕{p? →nullpid})
∨(endq′ = p? ∧
(∃next′′ : PID →GPID •
next′′ = next ⊕{endq →p?} ∧
next′ = next′′ ⊕{p? →nullpid})
The schema simpliﬁes to
EnqueuePQ2
∆PQ2
p? : PID
(hdq = nullpid ∧
hdq′ = p? ∧
endq′ = p? ∧
next′ = next ⊕{p? →nullpid})
∨(endq′ = p? ∧
next′ = (next ⊕{endq →p?}) ⊕{p? →nullpid}
Immediately, the precondition can be calculated and can be questioned:
pre EnqueuePQ2 =
hdq = nullpid ∨endq = p?
It is clear that endq = p? implies that hdq ̸= nullpid, so the precondition can
be further simpliﬁed to
pre EnqueuePQ2 = true
The remaining operations are deﬁned in the same order as for PQ1. The
deﬁnitions are all straightforward and should be immediately obvious, given
the deﬁnition of PQ1 and PQ2.
IsNonEmptyPQ2
ΞPQ2
hdq ̸= nullpid

3.4 Process Queue
67
The invariant of PQ2 states that hdq = nullpid exactly when endq = nullpid
and in this case, the image of hdq through next is the emtpy set, so the queue
must be empty.
The operation to remove the head of the queue is deﬁned as follows. As
should now be familiar, this deﬁnition will have to be strengthened to account
for the empty queue.
TheHeadOfPQ2
ΞPQ2
p! : PID
p! = hdq
The strengthened deﬁnition now follows.
HeadOfPQ2 = (IsNonEmptyPQ2 ∧TheHeadOfPQ2) ∨ProcessQueueEmpty
DelHeadOfPQ2
∆PQ2
hdq′ = next(hdq)
next′ = next ⊕{hdq →nullpid}
hdq = endq ∧endq′ = nullpid
The operation to dequeue an element from the queue is now deﬁned.
DequeuePQ2 = (HeadOfPQ2 ∧DelHeadOfPQ2 ∧SysOk) ∨ProcessQueueEmpty
It expands into
DequeuePQ2
∆PQ2
p! : PID
serr! : SYSERR
(hdq ̸= nullpid ∧
p! = hdq ∧
hdq′ = next(hdq) ∧
next′ = next ⊕{hdq →nullpid} ∧
serr! = sysok)
∨serr! = emptyqueue
The precondition can now be calculated.
pre DequeuePQ2 =
∃PQ2′; p! : PID •
hdq ̸= nullpid ∧
p! = hdq ∧
hdq′ = next(hdq) ∧
next′ = next ⊕{hdq →nullpid}

68
3 A Simple Kernel
This version simpliﬁes to
pre DequeuePQ2 =
hdq ̸= nullpid ∧
hdq = hdq ∧
next(hdq) = next(hdq) ∧
next ⊕{hdq →nullpid} = next ⊕{hdq →nullpid}
and then to
hdq ̸= nullpid
A more general statement of the above is
next∗(| {hdq} |) \ {nullpid} ̸= ∅
Therefore, we have
pre DequeuePQ2 = next∗(| {hdq} |) \ {nullpid} ̸= ∅
The abstraction relation is now deﬁned. It should be obvious.
AbsPQ2
PQ1
PQ2
hdq = hdprocs
endq = lastprocs
dom procseq ⊆dom next
ran procseq ⊆ran next
dom procq = next∗(| {hdq} |) \ {nullpid}
∀p : PID •
p ∈dom procseq ⇒procseq(p) = next(p)
Once again, this abstraction relation is mostly the identity. The two ⊆rela-
tions do not cause much of a problem and should not deter us from considering
the above a function, for they are not the most important conjuncts.
Theorem 18. ∀PQ1′; PQ2′ • PQ2Init ∧AbsPQ2′ ⇒PQ1Init
Proof. By the abstraction relation, hdq′ = hdproc′ and endq′ = lstproc′, so
hdq′ = nullpid = hdproc′ and endq′ = nullpid = lstproc′. 2
Theorem 19. ∀PQ1; PQ2; p? : PID • pre EnqueuePQ1 ∧AbsPQ2 ⇒
pre EnqueuePQ2
Proof. Both preconditions are true and true ⇒true is, clearly, true. 2

3.4 Process Queue
69
Theorem 20.
∀PQ1; PQ1′; PQ2; PQ2′; p? : PID •
pre EnqueuePQ1 ∧
AbsPTAB2 ∧
AbsPTAB2′ ∧
EnqueuePQ2
⇒EnqueuePQ1
Proof. Immediate from the abstraction relations. 2
Theorem 21.
∀PQ1; PQ2 •
pre DequeuePQ1 ∧AbsPQ2 ⇒pre DequeuePQ2
Proof. The precondition of pre DequeuePQ1 is dom procseq ̸= ∅and that of
pre DequeuePQ2 is next∗(| {hdq} |){nullpid} ̸= ∅. By the abstraction relation,
AbsPQ2, we have dom procseq = next∗(| {hdq} |){nullpid}. 2
Theorem 22.
∀PQ1; PQ1′; PQ2; PQ2′; p! : PID; serr! : SYSERR •
pre DequeuePQ1 ∧
AbsPQ2 ∧
AbsPQ2′ ∧
DequeuePQ2
⇒DequeuePQ1
Proof. The precondition of DequeuePQ1 is hdproc ̸= nullpid.
The interesting part of the proof is as follows. hdq′ = next(hdq) = next′ =
next ⊕{hd →nullpid}. By the predicate of AbsPQ2′, hdq′ = hdproc′, so
hdproc′
= next(hdq)
= procseq(hdq)
= procseq(hdproc).
We have next′ = next ⊕{hdq →nullpid}, which implies that procseq −◁
{hdproc} = procseq′.
To see this, consider
dom procseq
= next∗(| {hdq} |) \ {nullpid}
= next∗(| {next(hdq)} |) \ {nullpid}
= next+(| {hdq} |) \ {nullpid}
= (next∗(| {hdq} |) \ {nullpid}) \ {hdq}
= (dom procseq) \ {hdq}
= (dom procseq) \ {hdproc}
By deﬁnition of −◁
= procseq −◁{hdproc}
2

70
3 A Simple Kernel
The schemata from this last reﬁnement have now been shown to be correct.
They can be converted directly into executable code.
3.5 Priority Queue
In this kernel, the data structure used by the scheduler is a priority queue. This
is to be interpreted as a sequence of process identiﬁers, ordered by priority.
The operations are the usual ones (enqueue, dequeue). The enqueue operation
requires either that the sequence is sorted or that the appropriate place to
insert the new element is found.
In this section, the priority queue is speciﬁed in terms of a sequence. The
aim is eventually to reﬁne it to a chain running through the next function in
PTAB2.
As usual, the error schemata are deﬁned ﬁrst. There are two cases: the
case in which the queue is full and that in which it is empty.
PRIOQFull
serr! : SYSERR
serr! = schedqfull
PRIOQEmpty
serr! : SYSERR
serr! = schedqempty
3.5.1 Top Level
PRIOQ
PTAB
pq : seq PID
maxs : N1
#pq ≤maxs
ran pq ⊂used
∀i : 1 . . #pq −1 •
prio(pq(i)) ≤prio(pq(i + 1))
The queue container is pq and its maximum size is represented by maxs.
The elements of pq are held in ascending order so that the highest priority
corresponds to the lowest index. The invariant requires that all elements of pq

3.5 Priority Queue
71
must be elements of used and that nullpid is never an element of the queue.
It is also required that the identiﬁer of the idle process should never be an
element of pq but this is harder to do.
The initialisation operation merely sets the maximum length of the queue
and the queue to empty.
PRIOQInit
PRIOQ′
mps? : N1
maxs′ = mps?
pq′ = ⟨⟩
The following schema determines whether the priority queue is empty.
IsEmptyPRIOQ
ΞPRIOQ
pq = ⟨⟩
The current head of the priority queue is returned as p! by the next schema.
The priority queue is a sequence, so the head operation is applicable.
PRIOQHd
ΞPRIOQ
p! : PID
p! = head pq
When enqueueing an element, it is necessary to be able to obtain the last
element of the queue. The following schema represents an operation that does
just that.
PRIOQLast
ΞPRIOQ
p! : PID
p! = last pq
The operation of enqueueing an element is quite involved. This is because
the queue is sorted by priority. The ﬁrst part of the operation enqueues a
new element on the head of the queue. This operation is performed whenever
the priority of the new element, p?, is higher (lower in value, note) than the
current head of pq.
PRIOQEnqueueHd
∆PRIOQ
p? : PID
⟨p?⟩⌢pq = pq′

72
3 A Simple Kernel
Next, the operation to enqueue an element at the end of the queue is deﬁned.
This operation is performed whenever the priority of the new element p? is
lower (higher in value, note) than the current last element of pq.
PRIOQEnqueueLast
∆PRIOQ
p? : PID
pq′ = pq⌢⟩p?⟩
If the queue is empty and a new element is to be added, the following schema
deﬁnes the operation to enqueue on an empty queue.
PRIOQAddSingleton
∆PRIOQ
p? : PID
pq′ = ⟨p?⟩
Finally, there is the operation that inserts a new element, p?, into a queue.
When this operation is used, it is known that the priority of p? is less than
that of the head of pq and greater than its last element.
PRIOQInsert
∆PRIOQ
p? : PID
∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2) ∧
pq′ = s1 ⌢⟨p?⟩⌢s2
This operation divides the queue, pq, into two parts, s1 and s2, where the last
element of s1 has a priority higher than that of p? and the ﬁrst element of s2
has a priority that is at least that of p?.
The next schema deﬁnes one of the priority tests required by the enqueue
operation. It is satisﬁed when the priority of p?, the element to be enqueued,
is higher (i.e., of lower value) than that of the head of pq. In this case, p?
should be added to the head of the queue using PRIOQEnqueueHd.
ShouldAddPRIOQHd
ΞPRIOQ
p? : PID
prio(p?) ≤prio(head pq)
The following schema deﬁnes a predicate that is satisﬁed when the priority
of the last element of pq is lower than that of p?. When this is the case, p? is
added to pq at the end using PRIOQEnqueueLast.

3.5 Priority Queue
73
ShouldAddPRIOQLast
ΞPRIOQ
p? : PID
prio(last pq) < prio(p?)
The speciﬁcation of the enqueue operation is given by the PRIOQEnqueue
schema.
PRIOQEnqueue =
(CanEnqueuePRIOQ ∧
((IsEmptyPRIOQ ∧PRIOQAddSingleton) ∨
(ShouldAddPRIOQHd ∧PRIOQEnqueueHd) ∨
(ShouldAddPRIOQLast ∧PRIOQEnqueueLast) ∨
PRIOQInsert) ∧
SysOk)
∨PRIOQFull
This schema expands as follows:
PRIOQEnqueue
∆PRIOQ
p? : PID
serr! : SYSERR
(#pq < maxs ∧
((pq = ⟨⟩∧pq′ = ⟨p?⟩) ∨
(prio(p?) ≤prio(head pq) ∧pq′ = ⟨p?⟩⌢pq) ∨
(prio(last pq) < prio(p?) ∧pq′ = pq ⌢⟨p?⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2) ∧
pq′ = s1 ⌢⟨p?⟩⌢s2)) ∧
serr! = sysok)
∨serr! = schedqfull
Before moving on, it is necessary to prove a small result. This will help us
at a later stage. The result is similar to the “implicit” precondition.
Lemma 1. ∀p : PID • p ∈ran pq′ ⇒p ∈used
Proof. By the invariant of PRIOQ, ran pq ⊂used. Since there is no modiﬁ-
cation of used in the schema of PRIOQEnqueue, so the addition of p? to pq
does not aﬀect used. Therefore, for the invariant to hold, it is necessary for
p? ∈used, so ran(pq ⌢⟨p?⟩) ⊂used.

74
3 A Simple Kernel
Moreover, the invariant of PTAB states that dom prio = used. For this
operation to be well-deﬁned, prio(p)?) must also be well-deﬁned. For this to
be the case, p? ∈used, as required. 2
The enqueue operation will be reﬁned in the next subsection, so its pre-
condition must be calculated.
pre PRIOQEnqueue =
∃PRIOQ′; serr! : SYSERR •
(#pq < maxs ∧
((pq = ⟨⟩∧pq′ = ⟨p?⟩) ∨
(prio(p?) ≤prio(head pq) ∧pq′ = ⟨p?⟩⌢pq) ∨
(prio(last pq) < prio(p?) ∧pq′ = pq ⌢⟨p?⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2) ∧
pq′ = s1 ⌢⟨p?⟩⌢s2)) ∧
serr! = sysok)
∨serr! = schedqfull
Since serr! does not contribute to the precondition and for the reason that
pre(A ∨B) ⇔pre A ∨pre B, we can omit all occurrences of this variable
immediately. This gives
pre PRIOQEnqueue =
∃PRIOQ′; serr! : SYSERR •
(#pq < maxs ∧
((pq = ⟨⟩∧pq′ = ⟨p?⟩) ∨
(prio(p?) ≤prio(head pq) ∧pq′ = ⟨p?⟩⌢pq) ∨
(prio(last pq) < prio(p?) ∧pq′ = pq ⌢⟨p?⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2) ∧
pq′ = s1 ⌢⟨p?⟩⌢s2)))
We can now simplify the precondition schema to
pre PRIOQEnqueue =
(#pq < maxs ∧
(pq = ⟨⟩
∨(prio(p?) ≤prio(head pq))
∨(prio(last pq) < prio(p?))
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2))))
It is clear that

3.5 Priority Queue
75
(prio(p?) ≤prio(head pq))
∨(prio(last pq) < prio(p?))
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2))
implies that prio(p?) ∈PPRIO and that pq ̸= ⟨⟩. It is also clear that
prio(p?) ∈PPRIO ⇔true, so this part reduces to pq ̸= ⟨⟩. Plugging this
back into the rest of the precondition, we obtain
#pq < maxs ∧(pq = ⟨⟩∨pq ̸= ⟨⟩)
or
#pq < maxs ∧true ⇔
#pq < maxs
So, we may conclude that
pre PRIOQEnqueue = #pq < maxs
The operation to remove an element of pq is deﬁned by the following
schema:
PRIOQRemove
∆PRIOQ
p? : PID
∃s1, s2 : seq PID •
s1 ⌢⟨p?⟩⌢s2 = pq ∧
s1 ⌢s2 = pq′
Unfortunately, it is not possible to remove an element from an empty queue.
Indeed, it is necessary to deﬁne an operation that ﬁrst tests whether pq is
empty. The reason for this is that when the scheduler’s queue is empty, the
idle process must be scheduled.
DelPRIOQElem =
¬ IsEmptyPRIOQ ∧PRIOQRemove
This operation expands into the following schema:
DelPRIOQElem
∆PRIOQ
p? : PID
pq ̸= ⟨⟩
∃s1, s2 : seq PID •
s1 ⌢⟨p?⟩⌢s2 = pq ∧
s1 ⌢s2 = pq′

76
3 A Simple Kernel
This is an operation that will be used by the scheduler, so will be reﬁned.
For this reason, its precondition must be calculated.
pre DelPRIOQElem =
∃PRIOQ′ •
pq ̸= ⟨⟩∧
(∃s1, s2 : seq PID •
s1 ⌢⟨p?⟩⌢s2 = pq ∧
s1 ⌢s2 = pq′)
This simpliﬁes to:
pre DelPRIOQElem =
pq ̸= ⟨⟩∧p? ∈ran pq
The second conjunct is justiﬁed as follows.I It is clear that ran pq = ran(s1 ⌢
⟨p?⟩⌢s2) by the deﬁnition of ⌢and of sequence. Therefore, let ran s1 = R1
and ran s2 = R2. It follows that, since p? ∈ran pq, p? ̸∈R1 ∪R2, so ran pq =
R1 ∪R2 ∪{p?}.
Finally, we observe that p? ∈ran pq implies pq ̸= ⟨⟩, so
pre DelPRIOQElem = p? ∈ran pq
The scheduler requires that it must be possible to inspect the head of pq
and also to remove pq’s head as a separate operation. Dequeueing is, therefore,
composed of these two operations. The following schema deﬁnes an operation
to remove the head of pq. Since pq is just a sequence, the tail operation is
perfect for our needs.
PRIOQDelHd
∆PRIOQ
pq′ = tail pq
For the precondition, calculation yields
tail pq = tail pq
⇔true
However, this is not of much use. The stronger precondition, namely pq ̸= ⟨⟩
is preferred.
The dequeue operation is composed of returning the head and then re-
moving it. This is the core of the following deﬁnition.
PRIOQDequeue =
(¬ IsEmptyPRIOQ ∧PRIOQHd ∧PRIOQDelHd ∧SysOk)
∨PRIOQEmpty

3.5 Priority Queue
77
The interesting part is the second conjunct:
PRIOQHd ∧PRIOQDelHd
∆PRIOQ
p! : PID
p! = head pq
pq′ = tail pq
Again, calculation yields the weak precondition, true. A moment’s thought
shows that the precondition pq ̸= ⟨⟩also implies the operation.
The entire schema expands into
PRIOQDequeue
∆PRIOQ
p! : PID
serr! : SYSERR
(pq ̸= ⟨⟩∧
p! = head pq ∧
pq′ = tail pq ∧
serr! = sysok)
∨serr! = schedqempty
Schema PRIOQDequeue’s precondition can now be calculated. We ﬁrst
have
pre PRIOQDequeue =
∃PRIOQ′; p! : PID; serr! : SYSERR •
(pq ̸= ⟨⟩∧
p! = head pq ∧
pq′ = tail pq ∧
serr! = sysok)
∨serr! = schedqempty
This simpliﬁes to:
pre PRIOQDequeue =
(pq ̸= ⟨⟩∧
head pq = head pq ∧
tail pq = tail pq ∧
sysok = sysok)
∨schedqempty = schedqempty
This is clearly equivalent to
pre PRIOQDequeue =
pq ̸= ⟨⟩

78
3 A Simple Kernel
3.5.2 Reﬁnement One
The ﬁrst reﬁnement consists of replacing the sequence by a function. The
domain of the function is a numeric type, 1 . . maxs1, where maxs1 = maxs
or the maximum length of the sequence, pq, in the top-level speciﬁcation (the
maximum number of elements in this queue, too). The range is PID, as was
the case in the speciﬁcation. Therefore, the domain permits the function to
represent as many values as the original sequence. The variable maxs1 records
the maximum size of the queue at this level, pq1. The ﬁnal variable is nxtp,
the index of the next element to be added to pq1 (which can be thought of as
a one-dimensional array or vector).
PRIOQ1
pq1 : 1 . . maxs1 →PID
maxs1 : N1
nxtp : 1 . . maxs + 1
∀i : 1 . . nxtp −2 •
prio1(pq1(i)) ≤prio(pq1(i + 1))
Note that pq1 is ordered by priority. The condition that every element of pq1
is in used (or, equivalently, at this level, not in the free chain) is not repeated.
The reason for this is that it can be inferred from the equivalent schema in
the speciﬁcation.
The initialisation operation is deﬁned next.
PRIOQInit1
PRIOQ1′
mps? : N1
maxs1′ = mps?
nxtp′ = 1
The initialisation consists only of setting the maximum length of the queue
and setting the initial value of nxtp to 1 (i.e., the beginning of the vector).
The next schema deﬁnes a predicate that is true when pq1 is empty.
IsEmptyPRIOQ1
ΞPRIOQ1
nxtp = 1
This operation’s predicate should be compared with the initialisation schema.
In both cases nxtp takes the value 1. The scheme adopted here is that the
element is assigned to the element indexed by nxtp which is then incremented.
The following few operations are concerned with accessing the ﬁrst and
last elements of the queue, with determining whether the element to be added

3.5 Priority Queue
79
to the queue has an appropriate priority and with inserting a new element into
the queue. The operations correspond directly to those in the speciﬁcation as
presented in the last section.
PRIOQHd1
ΞPRIOQ1
p! : PID
p! = pq1(1)
PRIOQLast1
ΞPRIOQ1
p! : PID
p! = pq1(nxtp −1)
The next schema deﬁnes an operation that is satisﬁed when the length of
the queue is less than the maximum.
CanEnqueuePRIOQ1
ΞPRIOQ1
nxtp < maxs + 1
As in the speciﬁcation, this operation enqueues an element at the head of
the queue (because it has a priority higher than any queue element).
PRIOQEnqueueHd1
∆PRIOQ1
p? : PID
pq1′ = pq1 ⊕{1 →p?}
The following operation enqueues an element at the end of the queue
(because it has a priority lower than any in the queue).
PRIOQEnqueueLast1
∆PRIOQ1
p? : PID
pq1′ = pq1 ⊕{nxtp →p?}
nxtp′ = nxtp + 1
The next schema deﬁnes an operation that moves the elements of a vector
up by one place. Note that this is an example of how arrays (vectors) and
functions are considered equivalent.

80
3 A Simple Kernel
MovePRIOQUp1
∆PRIOQ1
∀i : 1 . . nxtp −1 •
pq1′ = pq1 ⊕{i + 1 →pq1(i)}
nxtp′ = nxtp + 1
Finally, we are able to deﬁne the enqueue operation. As with the speciﬁ-
cation, the operation is deﬁned in small parts that are composed to form the
ﬁnal operation. First, the operation to enqueue on the head is deﬁned.
PRIOQEnqueueHd1 =
MovePRIOQUp1 o
9 PRIOQEnqueueHd1
This expands into:
PRIOQEnqueueHd1
∆PRIOQ1
p? : PID
∃pq1′′ : 1 . . maxs1 →PID •
(∀i : 1 . . nxtp −1 •
pq1′′ = pq1 ⊕{i + 1 →pq1(i)}) ∧
nxtp′ = nxtp + 1 ∧
pq1′ = pq1′′ ⊕{1 →p?}
If the queue is empty, the following is used to enqueue the new element.
PRIOQAddSingleton1
∆PRIOQ1
p? : PID
pq1′ = {nxtp →p?}
nxtp′ = nxtp + 1
This schema deﬁnes the inverse of the MovePRIOQUp1 schema. In this
case, the elements of the vector are moved down one place and the ﬁrst element
is over-written.
PRIOQMoveUpFrom
∆PRIOQ1
where? : 1 . . maxs1
∀j : where? + 1 . . nxtp −1 •
pq1′ = pq1 ⊕{j + 1 →pq1(j)}
The next operation sets the i + 1st element to p?. This is used when
inserting a new element into the queue.

3.5 Priority Queue
81
PRIOQSetIthSucc
∆PRIOQ1
p? : PID
i? : 1 . . maxs1
pq1′ = pq1 ⊕{i + 1 →p?}
This schema deﬁnes a predicate that is true when the new element should
be enqueued on the head of pq1 (i.e, when it has a higher priority than the
current head—recall that higher priority is equivalent to lower value for the
priority).
ShouldAddPRIOQHd1
ΞPRIOQ1
p? : PID
prio1(p?) ≤prio1(pq1(1))
The test for adding at the end is deﬁned next.
ShouldAddPRIOQLast1
ΞPRIOQ1
p? : PID
prio1(pq1(nxtp −1)) < prio1(p?)
Next comes a predicate that is true when the priority of the element to
be added to the queue is somewhere between those of the head and the last
elements.
PRIOQInsertMidPoss1
ΞPRIOQ1
p? : PID
i? : 1 . . maxs1
prio1(pq1(i)) < prio1(p?)
prio1(p?) ≤prio1(pq1(i + 1))
Associated with this predicate is the PRIOQInsert1 operation. This operation
inserts a new element somewhere between the head and the last elements,
based upon its priority.
PRIOQInsert1 =
∃i : 1 . . nxtp −2 •
PRIOQInsertMidPoss1[i/i?] ∧
(PRIOQMoveUpFrom[i/where?] o
9 PRIOQSetIthSucc[i/i?]) ∧
nxtp′ = nxtp + 1

82
3 A Simple Kernel
This expands into:
∆PRIOQ1
p? : PID
∃i : 1 . . nxtp −2 •
prio1(pq1(i)) < prio1(p?) ∧
prio1(p?) ≤prio1(pq1(i + 1)) ∧
(∃pq1′′ : 1 . . maxs1 →PID •
(∀j : i + 1 . . nxtp −1 •
pq1′′ = pq1 ⊕{j + 1 →pq1(j)}) ∧
pq1′ = pq1′′ ⊕{i + 1 →p?}) ∧
nxtp′ = nxtp + 1
Finally, the enqueue operation can be deﬁned. It is given by the following
formula:
PRIOQEnqueue1 =
(CanEnqueuePRIOQ1 ∧
((IsEmptyPRIOQ1 ∧PRIOQAddSingleton1) ∨
(ShouldAddPRIOQHd1 ∧PRIOQEnqueueHd1) ∨
(ShouldAddPRIOQLast1 ∧PRIOQEnqueueLast1) ∨
PRIOQInsert1) ∧
SysOk)
∨PRIOQFull
This complex deﬁnition expands into the following schema
PRIOQEnqueue1
∆PRIOQ1
p? : PID
serr! : SYSERR
(nxtp < maxs1 + 1 ∧
((nxtp = 1 ∧pq1′ = {1 →p?} ∧nxtp′ = 2) ∨
(prio1(p?) ≤prio1(pq1(1)) ∧
(∃pq1′′ : 1 . . maxs1 →PID •
(∀i : 1 . . nxtp −1 •
pq1′′ = pq1 ⊕{i + 1 →pq1(i)}) ∧
nxtp′ = nxtp + 1 ∧pq1′ = pq1′′ ⊕{1 →p?}))
∨(prio1(pq1(nxtp −1)) < prio1(p?) ∧
pq1′ = pq1 ⊕{nxtp →p?} ∧nxtp′ = nxtp + 1)
∨(∃i : 1 . . nxtp −2 •
prio1(pq1(i)) < prio(p?) ∧prio1(p?) ≤prio1(pq1(i + 1)) ∧
(∃pq1′′ : 1 . . maxs1 →PID •

3.5 Priority Queue
83
(∀j : i + 1 . . nxtp −1 •
pq1′′ = pq1 ⊕{j + 1 →pq1(j)}) ∧
pq1′ = pq1′′ ⊕{i + 1 →p?}) ∧nxtp′ = nxtp + 1)) ∧
serr! = sysok) ∨serr! = schedqfull
The schema’s predicate can be simpliﬁed in a fairly obvious way. After sim-
pliﬁcation, the schema becomes
PRIOQEnqueue1
∆PRIOQ1
p? : PID
serr! : SYSERR
(nxtp ≤maxs1 ∧
((nxtp = 1 ∧pq1′ = {1 →p?} ∧nxtp′ = 2) ∨
(prio1(p?) ≤prio1(pq1(1)) ∧
(∀i : 1 . . nxtp −1 •
pq1′ = (pq1 ⊕{i + 1 →pq1(i)}) ⊕{1 →p?}) ∧
nxtp′ = nxtp + 1) ∨
(prio1(pq1(nxtp −1)) < prio1(p?) ∧
pq1′ = pq1 ⊕{nxtp →p?} ∧
nxtp′ = nxtp + 1) ∨
(∃i : 1 . . nxtp −2 •
prio1(pq1(i)) < prio1(p?) ∧prio1(p?) ≤prio1(pq1(i + 1)) ∧
(∀j : i + 1 . . nxtp −1 •
pq1′ = (pq1 ⊕{j + 1 →pq1(j)}) ⊕{i + 1 →p?} ∧
nxtp′ = nxtp + 1)) ∧
serr! = sysok)
∨serr! = schedqfull
The enqueue operation is a reﬁnement, so we need to calculate its precon-
dition. It is given by the following predicate:
pre PRIOQEnqueue1 =
∃PRIOQ1′; serr! : SYSERR •
(nxtp ≤maxs1 ∧
((nxtp = 1 ∧pq1′ = {1 →p?} ∧nxtp′ = 2) ∨
(prio1(p?) ≤prio1(pq1(1)) ∧
(∃pq1′′ : 1 . . maxs1 →PID •
(∀i : 1 . . nxtp −1 •
pq1′′ = pq1 ⊕{i + 1 →pq1(i)}) ∧
nxtp′ = nxtp + 1 ∧
pq1′ = pq1′′ ⊕{1 →p?})) ∨

84
3 A Simple Kernel
(prio1(pq1(nxtp −1)) < prio1(p?) ∧
pq1′ = pq1 ⊕{nxtp →p?} ∧
nxtp′ = nxtp + 1) ∨
(∃i : 1 . . nxtp −2 •
prio1(pq1(i)) < prio1(p?) ∧prio1(p?) ≤prio1(pq1(i + 1)) ∧
(∃pq1′′ : 1 . . maxs1 →PID •
(∀j : i + 1 . . nxtp −1 •
pq1′′ = pq1 ⊕{j + 1 →pq1(j)}) ∧
pq1′ = pq1′′ ⊕{i + 1 →p?} ∧
nxtp′ = nxtp + 1)) ∧
serr! = sysok)
∨serr! = schedqfull
Since serr! makes no contribution to the precondition, we can omit it. The
second outermost disjunct can be immediately deleted by this fact. The inner
occurrence can be removed by noting that pre(A ∨B) ⇔pre A ∨pre B
and serr! = sysok, by the one-point rule, is sysok = sysok (a tautology). So,
simplifying the existential quantiﬁer involving pq1′′ using the one-point rule
pre PRIOQEnqueue1 =
∃PRIOQ1′; serr! : SYSERR •
(nxtp ≤maxs1 ∧
((nxtp = 1 ∧pq1′ = {1 →p?} ∧nxtp′ = 2) ∨
(prio1(p?) ≤prio1(pq1(1)) ∧
(∀i : 1 . . nxtp −1 •
pq1′ = (pq1 ⊕{i + 1 →pq1(i)}) ⊕{1 →p?}) ∧
nxtp′ = nxtp + 1 ∧
(prio1(pq1(nxtp −1)) < prio1(p?) ∧
pq1′ = pq1 ⊕{nxtp →p?} ∧
nxtp′ = nxtp + 1) ∨
(∃i : 1 . . nxtp −2 •
prio1(pq1(i)) < prio1(p?) ∧prio1(p?) ≤prio1(pq1(i + 1)) ∧
(∀j : i + 1 . . nxtp −1 •
pq1′ = (pq1 ⊕{j + 1 →pq1(j)}) ⊕{i + 1 →p?} ∧
nxtp′ = nxtp + 1))))
Next, the one-point rule is applied repeatedly to give
pre PRIOQEnqueue1 =
nxtp ≤maxs1 ∧
(nxtp = 1 ∧
∨(prio1(p?) ≤prio1(pq1(1)))
∨(prio1(pq1(nxtp −1)) < prio1(p?))
∨(∃i : 1 . . nxtp −2 •
prio1(pq1(i)) < prio1(p?) ∧prio1(p?) ≤prio1(pq1(i + 1))))
Again, the 3 disjuncts

3.5 Priority Queue
85
(prio1(p?) ≤prio1(pq1(1)))
∨(prio1(pq1(nxtp −1)) < prio1(p?))
∨(∃i : 1 . . nxtp −2 •
prio1(pq1(i)) < prio1(p?) ∧prio1(p?) ≤prio1(pq1(i + 1)))
jointly imply that prio1(p) ∈PPRIO. This permits us to reduce these dis-
juncts to true. In addition, they also imply that nxtp > 1 for the reason that
there must be at least one element in pq1 for any of these comparisons to
succeed.
We therefore have at this stage nxtp < maxs1+1 ∧(nxtp = 1 ∧nxtp > 1).
The second conjunct implies that nxtp ≥1 and we can infer that 1 ≤nxtp <
maxs1+1 or 1 ≤nxtp ≤maxs1. This is equivalent to nxtp ∈1. .maxs1, which
is the deﬁnition of nxtp’s type, so reduces to true.
The precondition, therefore, reduces to
pre PRIOQEnqueue1 = nxtp ≤maxs1
We must now handle the operations that remove elements from the priority
queue. The ﬁrst operation to be deﬁned removes a speciﬁed element, p?, from
the queue. If p? is not present in the queue, the operation just terminates,
otherwise it removes p? and adjusts the insertion point (nxtp).
PRIOQRemove1
∆PRIOQ1
p? : PID
∃i : 1 . . nxtp −1 •
pq1(i) = p? ∧
(∀j : i + 1 . . nxtp −1 •
pq1′ = pq1 ⊕{j −1 →pq1(j)}) ∧
nxtp′ = nxtp −1
The operation to remove the head of the priority queue is deﬁned next
and is
PRIOQDelHd1
∆PRIOQ1
nxtp′ = nxtp −1
∀i : 1 . . nxtp −2 •
pq1′ = pq1 ⊕{i →pq1(i + 1)}
The precondition of this operation is as now given.
pre PRIOQDelHd1 = nxtp > 1
This can be seen from the following. If nxtp = 1, there are no elements in pq1,
so the operation must fail.

86
3 A Simple Kernel
The operation performing the dequeue operation is the following
PRIOQDequeue1 =
(¬ IsEmptyPRIOQ1 ∧PRIOQHd1 ∧PRIOQDelHd1 ∧SysOk)
∨PRIOQEmpty
The entire schema, after expansion, is
PRIOQDequeue1
∆PRIOQ1
p! : PID
serr! : SYSERR
(nxtp > 1 ∧
p! = pq1(1) ∧
(∀i : 1 . . nxtp −2 •
pq1′ = pq1 ⊕{i →pq1(i + 1)}) ∧
nxtp′ = nxtp −1 ∧
serr! = sysok)
∨serr! = schedqempty
The precondition is
pre PRIOQDequeue1 =
∃PRIOQ1′; p! : PID; serr! : SYSERR •
(nxtp > 1 ∧
p! = pq1(1) ∧
(∀i : 1 . . nxtp −2 •
pq1′ = pq1 ⊕{i →pq1(i + 1)}) ∧
nxtp′ = nxtp −1 ∧
serr! = sysok)
∨serr! = schedqempty
For well-advertised reasons, this immediately reduces to
pre PRIOQDequeue1 =
∃PRIOQ1′; p! : PID; serr! : SYSERR •
(nxtp > 1 ∧
p! = pq1(1) ∧
(∀i : 1 . . nxtp −2 •
pq1′ = pq1 ⊕{i →pq1(i + 1)}) ∧
nxtp′ = nxtp −1)
This now reduces to

3.5 Priority Queue
87
pre PRIOQDequeue1 =
∃PRIOQ1′; p! : PID; serr! : SYSERR •
(nxtp > 1 ∧
pq1(1) = pq1(1) ∧
(∀i : 1 . . nxtp −2 •
pq1 ⊕{i →pq1(i + 1)} = pq1 ⊕{i →pq1(i + 1)}) ∧
nxtp −1 = nxtp −1)
or
pre PRIOQDequeue1 = nxtp > 1
This can be expressed as the proposition that the queue is not empty.
The abstraction relation is now presented.
AbsPRIOQ1
PRIOQ
PRIOQ1
maxs1 = maxs
nxtp = #pq + 1
∀i : 1 . . nxtp −1 •
pq(i) = pq1(i)
The important parts are the second and third conjuncts. The second conjunct,
nxtp = #pq +1 states that nxtp −1 is always the current length of the queue;
nxtp always points to the next free element in the queue vector or has the
value of the maximum length of the queue plus one. The third conjunct states
that all the elements in pq1 are also in pq and all elements appear in the same
order. The abstraction relation inherits the constraint that all elements in pq
and pq1 must be elements of used (or, equally, not on the free chain).
Theorem 23.
∀PRIOQ′; PRIOQ1 •
PRIOQInit1 ∧AbsPRIOQ1′ ⇒PRIOQInit
Proof. By the abstraction relation, maxs′ = maxs1′, and by the predicate
of PRIOQInit1, maxs1′ = mps?, so maxs′ = mps?. Also by the abstraction
relation, nxtp′ = #pq′ + 1; by the predicate of PRIOQInit1, nxtp′ = 1 =
#pq′ + 1, so #pq′ = 0. 2
Theorem 24.
∀PRIOQ; PRIOQ1; p? : PID •
pre PRIOQEnqueue ∧AbsPRIOQ ⇒pre PRIOQEnqueue1

88
3 A Simple Kernel
Proof. We have
pre PRIOQEnqueue = #pq < maxs
and
pre PRIOQEnqueue1 = nxtp < maxs1 + 1
.
By the predicate of AbsPRIOQ, maxs = maxs1 and nxtp = #pq + 1.
Since #pq = nxtp −1, and #pq < maxs, then nxtp −1 < maxs1 and nxtp <
maxs1 + 1, as required. 2
Theorem 25.
∀PRIOQ; PRIOQ′; PRIOQ1; PRIOQ1′; p? : PID; serr! : SYSERR •
pre PRIOQEnqueue ∧
AbsPRIOQ1 ∧AbsPRIOQ1′ ∧
PRIOQEnqueue1
⇒PRIOQEnqueue
Proof. The precondition of PRIOQEnqueue is #pq < maxs.
Now, nxtp < maxs + 1, by AbsPRIOQ1, maxs1 = maxs and nxtp =
#pq + 1, substituting, we obtain #pq + 1 < maxs + 1 ⇔#pq < maxs.
Given nxtp = 1, by absPRIOQ1, pq = ⟨⟩, for nxtp = 1 implies #pq = 0.
It is clear that {1 →p?} = pq1′(1) = p?, and we note that {1 →p?} = ⟨p?⟩,
If {1 →p?} = pq1′(1) = p? and, by AbsPRIOQ1′, pq1′(i) = pq′(i), for all
i ∈1 . . #pq′, so pq1′(1) = pq′(1) = head pq′ by the deﬁnition of head. Now,
nxtp′ = 2, which implies that #pq′ = 1 since nxtp′ = #pq′+1 by the predicate
of AbsPRIOQ1′ and we have 2 = nxtp′ = #pq′ + 1, so nxtp′ −1 = #pq′ = 1.
Therefore, pq′ = ⟨p?⟩.
By AbsPTAB1, prio1(p) = prio(p), provided that p ∈used. By the
predicate of AbsPRIOQ1, pq1(1) = pq(1) = head pq. From this, we have
prio1(p?) ≤prio(pq1(1)) ⇔prio(p?) ≤prio(head pq). It should be noted
that last pq can be handled in a similar fashion, noting that nxtp = #pq + 1,
so nxtp −1 = #pq and pq(#pq) = last pq. This allows us to infer that
prio1(pq1(nxtp −1)) < prio1(p?) ⇔prio(last pq) < prio(p?). Now, returning
to prio(p?) ≤prio(head pq), we have, by AbsPRIOQ1,
∀i : 1 . . nxtp −1 •
pq1′ = (pq1 ⊕{i + 1 →pq1(i)})) ⊕{1 →p?}
= (pq ⊕{i + 1 →pq(i)}) ⊕{1 →p?}
and
(pq ⊕{i + 1 →pq(i)}) ⊕{1 →p?}
= {1 →p?} ⊕(pq ⊕{i + 1 →pq(i)})
= ⟨p?⟩⌢pq

3.5 Priority Queue
89
The second line is justiﬁed by the fact that the domains of the two maplets
are disjoint. More speciﬁcally, {i + 1 →pq(i)} is undeﬁned at 1.
In the next case, we have pq1′ = pq1 ⊕{nxtp →p?}. By AbsPRIOQ1,
nxtp = #pq + 1, so, by AbsPRIOQ1′, pq1′(nxtp) = pq′(nxtp) = pq′(#pq + 1)
and p? = pq1′(nxtp) = pq′(nxtp) = pq′(#pq + 1) which implies that pq′ =
pq ⌢⟨p?⟩.
By the arguments given above, it can be inferred that the condition (the
guard) is correct. We may then concentrate on the quantiﬁed formulæ. Note
that the existential has range 1 . . nxtp −2, so pq1(1) and pq1(nxtp −1) are
not to be altered.
The predicate prio1(pq1(i)) < prio(p?) ∧prio1(p?) ≤prio1(pq1(i + 1))
divides pq1 into two segments, one with priority < prio(p?) and one with
priority > prio(p?). Neither segment can, then, be empty. We can, therefore,
consider two segments, s1 and s2 of pq, s.t. s1 ̸= ⟨⟩and s2 ̸= ⟨⟩and s.t.
s1 ⌢s2 = pq. This is valid according to the conjunct of AbsPRIOQ1 which
states ∀i : 1 . . #pq • pq1(i) = pq(i).
Now, let #s1 = i, so pq(i) = s1(i) = last s1 and pq1(i + 1) = (s1 ⌢
s2)(i + 1) = pq(i + 1) = head s2. Let j = i + 1, then the quantiﬁed formula
implies that pq1′(j) = pq1(j) and, in particular, that pq1′(i +1) = pq1(i) and
pq1′(nxtp) = pq1(nxtp −1) and we now have three segments:
pq1′(k) = pq1(k), 1 ≤k ≤i
pq1′(i + 1) = pq1(i + 1)
pq1′(l) = pq1(i + 1 + n), i + 1 ≤n ≤nxtp −1
For the central segment, it can be seen from the universal that pq1′(i +1) = p?
(i.e., {i + 1 →p?}), so by AbsPRIOQ1′, pq′(i + 1) = p?. We can iden-
tify the ﬁrst component, pq1′(k) = pq1(k), with s1 since k < nxtp −1 and
pq1(k) = pq(k) by AbsPRIOQ1. The third segment is s2 by AbsPRIOQ1.
Since AbsPRIOQ1′ requires that pq1′(i) = pq′(i), i ∈1 . . #pq′, we have
pq1′ = s1 ⌢⟨p?⟩⌢s2 = pq′.
Finally, nxtp′ = nxtp + 1 in each case. By AbsPRIOQ1, nxtp = #pq + 1,
nxtp + 1 = #pq + 2 which implies that #pq′ = #pq + 1.
2
Theorem 26. ∀PRIOQ; PRIOQ1 • pre PRIOQDequeue ∧AbsPRIOQ1 ⇒
pre PRIOQDequeue1
Proof. The preconditions are as follows:
pre PRIOQDequeue = pq ̸= ⟨⟩
pre PRIOQDequeue1 = nxtp > 1
By the abstraction relation, the predicate of AbsPRIOQ1, nxtp = #pq +1, so
pq ̸= ⟨⟩implies that #pq > 0. If #pq = 0, then nxtp = 1. Therefore, pq ̸= ⟨⟩
implies that nxtp > 1. 2

90
3 A Simple Kernel
Theorem 27.
∀PRIOQ; PRIOQ′; PRIOQ1; PRIOQ1′; p! : PID; serr! : SYSERR •
pre PRIOQDequeue ∧
AbsPRIOQ1 ∧
AbsPRIOQ1′ ∧
PRIOQDequeue1
⇒PRIOQDequeue
Proof. The preconditon of PRIOQDequeue is pq ̸= ⟨⟩.
Now, nxtp > 1, impiles that pq ̸= ⟨⟩. By AbsPRIOQ1, nxtp = #pq + 1, so
if #pq = 0, nxtp = 1 and #pq = 0 implies that pq = ⟨⟩. Therefore, it follows
that nxtp > 1 implies pq ̸= ⟨⟩.
The assignment, p! = pq1(1) is equivalent to p! = pq(1) = head pq. The
predicate of AbsPRIOQ1 states that ∀i : 1. .#pq • pq1(i) = pq(i), so pq1(1) =
pq(1) and, using the deﬁnition of head, it is immediate that pq(1) = head pq.
Now, the quantiﬁed formala can be handled, ∀i : 1. .#pq • pq1(i) = pq(i),
as follows.
∀i : 1 . . nxtp −2 •
pq1′ = pq ⊕{i →pq1(i + 1)}
= pq ⊕{i →pq1(i + 1)}
= pq ⊕{i →pq(i + 1)}
= tail pq
To see this, consider that
(tail pq)(1) = pq(2)
. . . (tail pq)(# tail pq) = pq(#tailpq + 1)
= pq(#pq)
since #pq = # tail pq + 1. By the predicate of AbsPRIOQ1′, pq1′ = pq′ for
all i ∈1 . . #pq′, so pq1′ = tail pq = pq′. 2
Theorem 28. ∀PRIOQ; PRIOQ1 • pre PRIOQDelHD ∧AbsPRIOQ1 ⇒
pre PRIOQDelHd1
Proof. The two preconditions are
pre PRIOQDelHd = pq ̸= ⟨⟩
pre PRIOQDelHd1 = nxtp > 1
The proof is concluded in a manner similar to the proof of Theorem 26 2
Theorem 29.
∀PRIOQ; PRIOQ′; PRIOQ1; PRIOQ1′ •
pre PRIOQDelHd ∧
AbsPRIOQ1 ∧
AbsPRIOQ1′ ∧
PRIOQDelHd1
⇒PRIOQDelHd

3.5 Priority Queue
91
Proof. The deﬁnition of PRIOQDelHd is
∆PRIOQ
pq′ = tail pq
and it precondition is pq ̸= ⟨⟩.
The deﬁnition of PRIOQDelHd1 is
∆PRIOQ1
nxtp′ = nxtp −1
∀i : 1 . . nxtp −2 •
pq1′ = pq1 ⊕{i →pq1(i + 1)}
and its precondition is nxtp > 1.
It should be clear that
∀i : 1 . . nxtp −2 •
(tail pq)(i) = pq1 ⊕{i →pq1(i + 1)}
so pq1′ = tail pq = pq′. To see this consider the following:
(tail pq)(1) = pq(2) = pq1(2)
...
last(tail pq) = tail pq(# tail pq) = pq1(nxtp −1)
2
The result of this reﬁnement is a collection of schemata that can be trans-
lated to executable code. This produces a priority queue implemented in terms
of a vector, a perfectly adequate implementation. However, we continue with
a second reﬁnement which will reﬁne the vector to a list threaded through the
next function (i.e., a list of process identiﬁers or, equivalently, a list of process
descriptors).
3.5.3 Reﬁnement Two
In this reﬁnement, the queue elements are now stored in next, a component
of PTAB2. In many real-time kernels, the ready queue (which is really the
priority queue) is implemented as a small vector of process identiﬁers or ref-
erences. The vector implementation saves a few operations and is justiﬁed by
the fact that only a few processes are usually in the ready queue at any time.
The advantages of the current approach are that any number of processes
can be in the ready queue and that it occupies no extra space whatsoever;

92
3 A Simple Kernel
access and update of the two structures take very roughly the same number
of instructions on most contemporary processors.
The state space for this reﬁnement is the following.
PRIOQ2
PTAB2
qhd, qlst : GPID
qlen : N
maxs2 : N1
qlen ≤maxs2 ∧qhd = nullpid ⇔qlst = nullpid
qhd = nullpid ⇔qlen = 0 ∧qhd ̸= nullpid ⇔next(qlst) = nullpid
qhd ̸= nullpid ⇔qlst ∈next∗(| {qhd} |) \ {nullpid}
The variables qhd and qlst represent the head and last elements of the ready
queue; the length of the queue is represented by qlen. The maximum length
to which the ready queue can grow is determined by maxs2. The invariant
states that the length of the queue must always be less than maxs2 + 1 and
that when the queue is empty, qhd = qlst = nullpid. There is more that could
be included in the invariant but the above is quite adequate for our current
needs.
The initialisation schema is deﬁned next. Given the last paragraph, the
predicate of PRIOQInit2 should be clear.
PRIOQInit2
PRIOQ2′
mps? : N1
qhd ′ = qlst′ = nullpid
maxs2′ = mps?
qlen′ = 0
The operations now follow in the same order as they were presented for
PRIOQ1, so nothing will be said about them unless there is a point of interest.
IsEmptyPRIOQ2
ΞPRIOQ2
qlen = 0
The approach adopted to the deﬁnition of the enqueue operation is the
same as in the last subsection.
PRIOQHd2
ΞPRIOQ2
p! : PID
p! = qhd

3.5 Priority Queue
93
PRIOQLast2
ΞPRIOQ2
p! : PID
p! = qlst
CanEnqueuePRIOQ2
ΞPRIOQ2
qlen < maxs2
PRIOQEnqueueHd2
∆PRIOQ2
p? : PID
qhd ′ = p?
next′ = next ⊕{p? →qhd}
qlen′ = qlen + 1
PRIOQAddSingleton2
∆PRIOQ2
p? : PID
qhd ′ = p?
qlst′ = p?
next′ = next ⊕{p? →nullpid}
qlen′ = 1
ShouldAddPRIOQHd2
ΞPRIOQ2
p? : PID
prio2(p?) ≤prio2(qhd)
ShouldAddPRIOQLast2
ΞPRIOQ2
p? : PID
prio2(qlst) < prio2(p?)
The following is the insertion operation:

94
3 A Simple Kernel
PRIOQInsert2
∆PRIOQ2
p? : PID
∃p1, p2 : PID •
p1 ∈next∗(| {qhd} |) \ {nullpid} ∧
p2 ∈next∗(| {qhd} |) \ {nullpid} ∧
prio2(p1) ≤prio2(p?) ∧
prio2(p?) < prio2(p2) ∧
next(p1) = p2 ∧
next′ = next ⊕{p1 →p?, p? →p2} ∧
qlen′ = qlen + 1
Note how next is updated by the addition of p?. Also, the update of next is
really a sequential composition since two elements are added to it. The two
elements have been reduced to one as a notational nicety.
Finally, the enqueue operation proper is deﬁned.
PRIOQEnqueue2 =
(CanEnqueuePRIOQ2 ∧
((IsEmptyPRIOQ2 ∧PRIOQAddSingleton2)
∨(ShouldAddPRIOQHd2 ∧PRIOQEnqueueHd2)
∨(ShouldAddPRIOQLast2 ∧PRIOQEnqueueLast2)
∨PRIOQInsert2) ∧
SysOk)
∨PRIOQFull
It expands into
PRIOQEnqueue2
∆PRIOQ2
p? : PID
serr! : SYSERR
qlen < maxs2
(qlen = 0 ∧
qhd ′ = p? ∧qlst′ = p? ∧
next′ = next ⊕{p? →nullpid} ∧
qlen′ = 1)
∨(prio2(p?) ≤prio2(qhd) ∧
qhd ′ = p? ∧
next′ = next ⊕{p? →qhd} ∧
qlen′ = qlen + 1)
∨(prio2(qlst) < prio2(p?) ∧
qlst′ = p? ∧
next′ = next ⊕{qlst →p?, p? →nullpid} ∧
qlen′ = qlen + 1)

3.5 Priority Queue
95
∨(∃p1, p2 : PID •
p1 ∈next∗(| {qhd} |) \ {nullpid} ∧
p2 ∈next∗(| {qhd} |) \ {nullpid} ∧
prio2(p1) ≤prio2(p?) ∧
prio2(p?) < prio2(p2) ∧
next(p1) = p2 ∧
next′ = next ⊕{p1 →p?, p? →p2} ∧
qlen′ = qlen + 1) ∧
∨serr! = sysok)
∨serr! = schedqfull
The predicate of this schema can be simpliﬁed to
qlen < maxs2 ∧
[((qlen = 0 ∧
qhd ′ = p? ∧qlst′ = p? ∧
next′ = next ⊕{p? →nullpid})
∨(prio2(p?) ≤prio2(qhd) ∧
qhd ′ = p? ∧
next′ = next ⊕{p? →qhd})
∨(prio2(qlst) < prio2(p?) ∧
qlst′ = p? ∧
next′ = next ⊕{qlst →p?, p? →nullpid})
∨(∃p1, p2 : PID •
p1 ∈next∗(| {qhd} |) \ {nullpid} ∧
p2 ∈next∗(| {qhd} |) \ {nullpid} ∧
prio2(p1) ≤prio2(p?) ∧
prio2(p?) < prio2(p2) ∧
next(p1) = p2 ∧
next′ = next ⊕{p1 →p?, p? →p2}))
∧qlen′ = qlen + 1
∧serr! = sysok]
∨serr! = schedqfull
It is also clear that the calculation of prio2(p?) can be turned into a local
variable using existential quantiﬁcation
∃pr : PPRIO | pr = prio2(p?) •
qlen < maxs2 ∧
[((qlen = 0 ∧
qhd ′ = p? ∧qlst′ = p? ∧
next′ = next ⊕{p? →nullpid})
∨(pr ≤prio2(qhd) ∧
qhd ′ = p? ∧
next′ = next ⊕{p? →qhd})

96
3 A Simple Kernel
∨(prio2(qlst) < pr ∧
qlst′ = p? ∧
next′ = next ⊕{qlst →p?, p? →nullpid})
∨(∃p1, p2 : PID •
p1 ∈next∗(| {qhd} |) \ {nullpid} ∧
p2 ∈next∗(| {qhd} |) \ {nullpid} ∧
prio2(p1) ≤prio2(p?) ∧
prio2(p?) < prio2(p2) ∧
next(p1) = p2 ∧
next′ = next ⊕{p1 →p?, p? →p2}))
∧qlen′ = qlen + 1
∧serr! = sysok]
∨serr! = schedqfull
This is one case in which the re-introduction of quantiﬁers can lead to better
code.
The precondition of PRIOQEnqueue2 is
pre PRIOQEnqueue2 = qlen < maxs2
As above, the deletion and dequeueing operations are deﬁned next.
PRIOQDelHd2
∆PRIOQ2
qlen′ = qlen −1
qhd ′ = next(qhd)
By calculation, we obtain
pre PRIOQDelHd2 = true
but this is not particularly useful. Instead, the following weaker form is
employed:
pre PRIOQDelHd2 = qlen > 0
This formula is also employed by the predicate of PRIOQDelHd2.
PRIOQDequeue2 =
(¬ IsEmptyPRIOQ2 ∧
PRIOQHd2 ∧
PRIOQDelHd2 ∧
SysOk)
∨PRIOQEmpty
This complex deﬁnition expands into

3.5 Priority Queue
97
PRIOQDequeue2
∆PRIOQ2
p! : PID
serr! : SYSERR
(qlen ̸= 0 ∧
p! = qhd ∧
qlen′ = qlen −1 ∧
qhd ′ = next(qhd) ∧
serr! = sysok)
∨serr! = schedqempty
This operation’s precondition is immediately calculated
pre PRIOQDequeue2 = qlen ̸= 0
However, since qlen ∈N, this can be re-written as
pre PRIOQDequeue2 = qlen > 0
To end the sequence of deﬁnitions, the abstraction relation is now deﬁned.
AbsPRIOQ2
PRIOQ1
PRIOQ2
maxs2 = maxs2
nxtp > 1 ⇔qhd = pq1(1)
nxtp > 1 ⇔qlst = pq1(nxtp −1)
qlen = nxtp −1
next(pq1(nxtp −1)) = nullpid
∀i : 1 . . nxtp −2 •
i = j −1 ⇒
next(pq1(i)) = pq1(i + 1)
This is yet another identity, so the proofs of reﬁnement are straightforward.
Theorem 30. ∀PRIOQ1;
PRIOQ2 • PRIOQInit2 ∧AbsPRIOQ2′ ⇒
PRIOQInit1
Proof. By the abstraction relation, qlen′ = nxtp′ −1, so we have 1 −1 =
0 = qlen′. In addition, the same realtion states that maxs2 = maxs1. 2
Theorem 31. ∀PRIOQ1; PRIOQ2; p? : PID • pre PRIOQEnqueue1 ∧
AbsPRIOQ2 ⇒pre PRIOQEnqueue2

98
3 A Simple Kernel
Proof. The two preconditions are
pre PRIOQEnqueue1 = nxtp ≤maxs1
and
pre PRIOQEnqueue2 = qlen < maxs2
Since maxs1 = maxs2, we have
nxtp ≤maxs2
and
qlen < maxs2
The abstraction relation, states that qlen = nxtp −1, so qlen + 1 ≤maxs2,
which imples that qlen < maxs2 as required. 2
Theorem 32.
∀PRIOQ1; PRIOQ1′; PRIOQ2; PRIOQ2′; p? : PID; serr! : SYSERR •
pre PRIOQEnqueue1
∧AbsPRIOQ2
∧AbsPRIOQ2′
∧PRIOQEnqueue2
⇒PRIOQEnqueue1
Proof. There are four cases.
Case 1. qlen < maxs2. By the abstraction relation, qlen = nxtp −1 and
maxs2 = maxs1, so nxtp −1 < maxs2 implies nxtp −1 < maxs1, which
implies nxtp ≤maxs1. Ad qlen = 0, again using qlen = nxtp −1, 0 = nxtp −1
implies nxtp = 1. By the predicate of AbsPRIOQ2′ qhd′ = pq1′(1) and qlst′ =
pq1′(nxtp′ −1), so qhd′ = p? implies pq1 ⊕{1 →p?} = pq1′ and qlst′ = p?
implies pq1 ⊕{1 →p?} = pq1′ since nxtp = 1. The identity qlen′ = qlen + 1,
implies that nxtp′ = nxtp + 1 = nxtp′ = 2.
Case 2. prio2(p?) implies prio1(p?) by AbsPTAB1; this is justiﬁed by the in-
variant condition that ran pq ⊂used. We also have prio2(qhd) = prio2(pq1(1))
= prio1(pq1(1)) by the abstraction relation and therefore pq1′ = pq1 ⊕{1 →
p?}. By the universal formula in the abstraction relation, next′ = next⊕{p? →
qhd} implies next′ = next⊕{p? →pq1(1)}; this now implies that pq1′(1) = p?,
pq1′(2) = pq1(1) and by induction, we have pq1′ = (pq1 ⊕{i + 1 →
pq1(i)}) ⊕{1 →p?}. The increase in qlen is as in Case 1 above.
Case 3. The abstraction relation permits us to infer that prio2(qlst) =
prio2(pq1(nxtp −1)) = prio1(pq1(nxtp −1)) since pq1(nxtp −1) is a known
process. For p? to be an element of the queue, p? must be a deﬁned process,
so prio2(p?) = prio1(p?) by AbsPTAB2. We note that qlst = pq1(nxtp −1),
so that we may continue. Next, we deal with next′ = next ⊕{qlst →
p?, p? →nullpid}. First, we note that the map {p? →nullpid} is required
by the invariant of PRIOQ2, thus permitting us to concentrate on the map
{qlst →p?}, which implies that next′(qlst) = p?, so next′(nxtp −1) = p? so
next′(nxtp) = p?. The increment of nxtp and qlen is as in Case 1 above.

3.5 Priority Queue
99
Case 4. Since p1, p2 ∈next∗(| {qhd} |) \ {nullpid}, it follows, by the invariant,
that {p1, p2} ⊂used, so prio2(p1) = prio1(p1) and prio2(p2) = prio1(p1).
For p? to be a valid element of the queue, it must also be a deﬁned process
identiﬁer (p? ∈used or equivalent). If next(p1) = p2, it must be true that
∃i : 1 . . nxtp −2 • p1 = pq1(i) ∧pq1(i + 1) = p2 (this follows from the
abstraction relation). The remainder can be proved by induction. 2
Theorem 33.
∀PRIOQ1; PRIOQ2 •
pre PRIOQDequeue1 ∧AbsPRIOQ2 ⇒pre PRIOQDequeue2
Proof. The two preconditions are:
pre PRIOQDequeue1 = nxtp > 1
and
pre PRIOQDequeue2 = qlen ̸= 0
The abstraction relation states that qlen = nxtp −1, so nxtp > 1 iﬀqlen +1 >
1, which implies that qlen > 0 and it follows that qlen ̸= 0. 2
Theorem 34.
∀PRIOQ1; PRIOQ1′; PRIOQ2; PRIOQ2′; p! : PID; serr! : SYSERR •
pre PRIOQDequeue1
∧AbsPRIOQ2
∧AbsPRIOQ2′
∧PRIOQDequeue2
⇒PRIOQDequeue1
Proof. We start with qlen ̸= 0, because of the deﬁnition of qlen’s type,
this implies that qlen > 0. By the abstraction relation, qlen = nxtp −1, so
qlen ̸= 0 implies nxtp −1 ̸= 0 and qlen > 0 implies nxtp −1 > 0, so nxtp > 1,
as required.
By the abstraction relation, pq1(1) = qhd if the queue is not empty; it
cannot be empty by the deﬁnition of the operation, so this equation holds. It
follows that p! = qhd implies p! = pq1(1).
The queue-length reduction, qlen′ = qlen −1 requires us to take the pred-
icate of AbsPRIOQ2′ into account. By AbsPRIOQ2, we have qlen = nxtp −1
and, by AbsPRIOQ2′, we have qlen′ = nxtp′−1. From this, qlen−1 = nxtp−2,
so qlen′ = nxtp −2 or nxtp′ −1 = nxtp −2, so nxtp′ = nxtp −1.
Finally, since pq1(1) = qhd, and qhd′ = next(qhd), then qhd′ = next(qhd)
= pq1(2). Using the quantiﬁed formula in the abstraction relation, it can be
inferred that ∀i : 1 . . nxtp −2 • pq1′ = pq1 ⊕{i →pq1(i + 1)}; this can be
veriﬁed by a simple induction. 2
Theorem 35. ∀PRIOQ1; PRIOQ2 • pre PRIOQDelHd1 ∧AbsPRIOQ2 ⇒
pre PRIOQDelHd2

100
3 A Simple Kernel
Proof. The precondition of PRIOQDelHd1 is nxtp > 1 and that of PRIO-
QDelHd2 is qlen > 0. The abstraction relation states that qlen = nxtp −1.
From the abstraction relation, we have qlen + 1 = nxtp, and so qlen + 1 > 1,
from which it follows that qlen > 0. 2
Theorem 36.
∀PRIOQ1; PRIOQ1′; PRIOQ2; PRIOQ2′ •
pre PRIOQDelHd1
∧AbsPRIOQ2
∧AbsPRIOQ2′
∧PRIOQDelHd2
⇒PRIOQDelHd1
Proof. By the predicate of AbsPRIOQ2, nxtp = qlen −1 and, by that of
AbsPRIOQ2′, we have nxtp′ = qlen′ −1, so qlen′ = nxtp′ +1. In the predicate
of PRIOQDelHd2, qlen′ = qlen −1, so qlen −1 = nxtp −2, so qlen′ = nxtp −2,
from which it follows that nxtp′ −1 = nxtp −2, or nxtp′ = nxtp −1.
Now, assuming qlen > 1, by the predicate of AbsPRIOQ2, qhd = pq1(1)
and next(qhd) = next(pq1(1)) = pq1(2). Using the quantiﬁed formula, the
index of each element of pq1 decreases by 1.
On the other hand, if qlen = 1, the next(qhd) = nullpid, so qhd′ = qlst
which, by the invariant, implies that qhd′ = nullpid and qlen = 0, so nxtp = 1
and the queue is empty. 2
The schemata from this last reﬁnement have now been shown to be correct.
They can be converted directly into executable code.
3.6 The Scheduler
The scheduler is comprised of the priority queue whose reﬁnement has just
been undertaken, together with a variable to identify the currently executing
process, a variable to identify the process that was executing immediately
before the current one; there is also a varible to identify the idle process.
The scheduler undergoes 3 reﬁnements to reach the level at which code
can be extracted. Without further ado, we press on, therefore.
3.6.1 Top Level
This section contains the speciﬁcation of the scheduler.
Before presenting the speciﬁcation, let us prove the following little theo-
rem. The variable curr denotes the current process; SchedNext is the name of
the scheduler routine.
The idle process (sometimes called the “null” process) is just a process
that does little or nothing. It can be implemented as a simple loop, such as:

3.6 The Scheduler
101
while true do
skip
od
The idle process is executed when there is nothing else to do.
As far as this part of the speciﬁcation is concerned, support for the idle
process is required.
It is assumed that the idle process is an element of used. This has the
implication that the identiﬁer of the idle process cannot be nullpid.
Here, then, is the deﬁnition of the scheduler’s state space. The variable
curr denotes the currently executing process, prev denotes the previously
executed process, iprc is the identiﬁer of the idle process (it is a write-once
variable that is set at initialisation time). Finally, sq is the scheduler’s queue,
an instance of PRIOQ. It will be remembered that PRIOQ is a schema, so
we have a promotion in this case. This is good for it reduces the amount of
work required of us.
SCHED
curr, prev : PID
iprc : PID
sq : PRIOQ
iprc ̸= nullpid
Theorem 37. If pq ̸= ⟨⟩, ∀p : PID • p ∈ran pq ⇒p ∈used.
Proof. By the invariant of PRIOQ, ran pq ⊂used. This clearly implies that
∀p : PID • p ∈ran pq ⇒p ∈used. 2 It has two corollaries.
Corollary 1. curr ∈used ∨state(curr) = psterm.
Proof. There is only one operation that sets state(curr) to psterm. That is
TerminateSelf. As part of its operation, it deletes curr from the process table
and causes a reschedule via a call to SchedNext. Before the call to SchedNext,
TerminateSelf sets the state of the current process as state′ = state⊕{curr →
psterm}, so state(curr) = psterm.
The other operations updating curr are SchedNext (as noted in the last
paragraph) and SuspendMe.
The SuspendMe operation removes the head from the ready queue, pq,
if there is one and requeues curr. If the ready queue is empty, iprc (the idle
process) is selected instead. The old queue head (or iprc) is made curr for exe-
cution. The setting of curr is performed by SetNewCurrentProcess[head pq/p?].
If the ready queue, pq, is empty, curr is updated by MakeIdleProcessCurrent.
Inspection of SchedNext shows that the same two operations are used to
set the state of curr and prev. Their deﬁnitions are repeated.

102
3 A Simple Kernel
SetNewCurrentProcess
∆SCHED
p? : PID
curr ′ = p?
prev ′ = curr
MakeIdleProcessCurrent
∆SCHED
curr ′ = iprc
prev ′ = curr
It can be seen that neither operator aﬀects used in any way (indeed, used is
not mentioned by either schema). It is therefore necessary to determine where
p? and iprc originate.
In SuspendMe and in SchedNext, there is a substitution instance of
SetNewCurrentProcess, SetNewCurrentProcess[head pq/p?]. This expands to
curr ′ = head pq
prev ′ = curr
By Theorem 37, head pq ∈used.
The null or idle process is created by CreateNullProcess which is deﬁned
in terms of AddPD. The output, p!, of AddPD is then assigned to iprc via
SCHEDInit. The initialisation SCHEDInit in the system initialisation has an
instance of
SCHEDInit
SCHED′
p? : PID
curr ′ = minpid ∧prev ′ = minpid ∧iprc′ = p?
sq′ = θPRIQOInit
in a substitution instance [ipid/p?]. Inspection of the deﬁnition of CreateNull-
Process shows that there are no operations that rebind ipid. Now, AddPD
implies that ipid ∈used, so iprc = ipid.
It should be noted that it will usually be the case that iprc is bound to
minpid. This permits the inference that curr ∈used at initialisation time,
also. 2
Corollary 2. prev ∈used ∨state(prev) = psterm
Proof. As noted in Corollary 1, only TerminateSelf can set the process
state to psterm. The TerminateSelf operation is deﬁned in terms of SchedNext

3.6 The Scheduler
103
which, at various points, updates prev (prev ′ = curr). The variable prev is
always a copy of curr. The critical operation is SetNewCurrentProcess, whose
deﬁnition is
∆SCHED
p? : PID
curr ′ = p?
prev ′ = curr
So, the value bound prev ′ is identical to that bound to curr, so must have
the same properties. In particular, if curr ∈used, prev ′ ∈used and if
state(curr) = psterm, state(prev ′) = psterm.
It should be clear that the assignment prev ′ = curr establishes the binding
of prev from that point until it is next updated. This permits us to reach the
conclusion that prev ∈used ∨state(prev) = psterm.
Finally, as noted above, iprc is usually bound to minpid, so the statement
of this corollary also applies at initialisation time. 2
Here is the framing or promotion schema.
ΦSCHED
∆SCHED
∆PRIOQ
sq = θPRIOQ
sq′ = θPRIOQ′
The deﬁnition of the initialisation schema is repeated. The deﬁnition is
comparatively straightforward, as can be seen. The only thing to notice is
that sq′ = θPRIOQInit, since sq is of a schema type.
SCHEDInit
SCHED′
p? : PID
curr ′ = minpid ∧prev ′ = minpid ∧iprc′ = p?
sq′ = θPRIOQInit
Recall that PRIOQ includes PTAB in its state.
The next operation returns the identiﬁer of the idle process.
IDLEPROCESSIdent
ΞSCHED
p! : PID
p! = iprc

104
3 A Simple Kernel
When the identiﬁer of the currently executing process is required to be
set, this schema deﬁnes the operation that performs it.
SetCurrentProcessId
∆SCHED
p? : PID
curr ′ = p?
The names of the next few schemata should be all that is required to
interpret them.
MakeCurrentPrevious
∆SCHED
prev ′ = curr
IsCurrentProcess
ΞSCHED
p? : PID
p? = curr
CurrentProcessId
ΞSCHED
p! : PID
p! = curr
SetStateToRunning =
∃st : PSTATE | st = psrunning •
SetProcState[st/st?]
or
SetStateToRunning
∆PTAB
p? : PID
state′ = state ⊕{p? →psrunning}
SetNewCurrentProcess =
(MakeCurrentPrevious ∧SetCurrentProcessId)
o
9(CurrentProcessId[c/p!] ∧SetStateToRunning[c/p?]) \ {c}

3.6 The Scheduler
105
After simpliﬁcation, this expands into
∆SCHED
p? : PID
curr ′ = p?
prev ′ = curr
state′ = state ⊕{curr ′ →psrunning}
IsPreviousProcess
ΞSCHED
p? : PID
p? = prev
IsCurrentProcessIdle
ΞSCHED
curr = iprc
This predicate is true iﬀthe previously active process was the idle process.
IsPrevProcessIdle
ΞSCHED
prev = iprc
SetProcessStateToReady =
∃st : PSTATE | st = psready •
SetProcState[st/st?]
This expands and simpliﬁes to
SetProcessStateToReady
∆PTAB
p? : PID
state′ = state ⊕{p? →psready}
The operation that places a process identiﬁer in the scheduler’s ready
queue is called MakeReady. The main part of MakeReady is deﬁned by the
following

106
3 A Simple Kernel
MakeReadya =
∃∆PRIOQ •
ΦSCHED ∧PRIOQEnqueue
To make life a little easier and to avoid errors, the following operation is
deﬁned. It sets the state of the process being added to the ready queue as well
as performing the queue-insertion operation. This operation is used in a lot of
places and it is easy to forget to set the state; this is the reason for deﬁning
this operation.
MakeReady =
(SetProcessStateToReady ∧MakeReadya)
It expands into the following. It should be noted that the strict expansion of
the promoted action should yield a queue whose name is sq.pq.
MakeReady
∆PRIOQ
p? : PID
serr! : SYSERR
state′ = state ⊕{p? →psready} ∧
(#sq.pq < maxs ∧
((sq.pq = ⟨⟩∧sq.pq′ = ⟨p?⟩) ∨
(prio(p?) ≤prio(head sq.pq) ∧sq.pq′ = ⟨p?⟩⌢sq.pq) ∨
(prio(last sq.pq) < prio(p?) ∧sq.pq′ = sq.pq ⌢⟨p?⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2) ∧
sq.pq′ = s1 ⌢⟨p?⟩⌢s2)) ∧
serr! = sysok)
∨serr! = schedqfull
This schema can be simpliﬁed to the following:
∆PRIOQ
p? : PID
serr! : SYSERR
(#sq.pq < maxs ∧
((sq.pq = ⟨⟩∧sq.pq′ = ⟨p?⟩) ∨
(prio(p?) ≤prio(head sq.pq) ∧sq.pq′ = ⟨p?⟩⌢sq.pq) ∨
(prio(last sq.pq) < prio(p?) ∧sq.pq′ = sq.pq ⌢⟨p?⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2) ∧

3.6 The Scheduler
107
sq.pq′ = s1 ⌢⟨p?⟩⌢s2)) ∧
state′ = state ⊕{p? →psready} ∧
serr! = sysok)
∨serr! = schedqfull
The precondition is
pre MakeReady = #sq < maxs
Note that this precondition can rely upon the lemma proved above (Lemma
1) to ensure that p? ∈used, so that the update of state is well deﬁned.
Next, we deﬁne a number of operations in terms of promotion. Each deﬁ-
nition is accompanied by its simpliﬁcation; in some cases, a complete step-by-
step simpliﬁcation is given so that the reader can be sure of the derivation,
as well as the logical form of these operations.
The test for an empty ready queue in the scheduler is deﬁned by the
following
IsEmptySCHEDQ =
∃∆PRIOQ •
ΦSCHED ∧IsEmptyPRIOQ
Its predicate expands into (using the same abuse of notation mentioned above)
∃pq, pq′ : seq PID; maxs, maxs′ : N •
sq = θPRIOQ ∧
sq′ = θPRIOQ′ ∧
pq = ⟨⟩
or
sq = ⟨| pq →pq, maxs →maxs |⟩∧
sq′ = ⟨| pq ⇝pq′, maxs ⇝maxs′ |⟩∧
pq = ⟨⟩
which is
∃pq, pq′ : seq PID; maxs, maxs′ : N •
sq = ⟨| pq →pq, maxs →maxs |⟩∧
sq′ = ⟨| pq ⇝pq′, maxs →maxs′ |⟩∧
pq = ⟨⟩
or
sq = sq′ ∧
sq.maxs = sq.maxs′ ∧
sq.pq = ⟨⟩

108
3 A Simple Kernel
The scheduler’s dequeue operation is deﬁned as the following promotion
SCHEDQDequeue =
∃∆PRIOQ •
ΦSCHED ∧PRIOQDequeue
It simpliﬁes to
sq.pq = pq
sq.maxs = maxs
((sq.pq ̸= ⟨⟩
p! = head sq.pq
sq′.pq = tail sq.pq
serr! = sysok)
∨serr! = schedqempty)
An operation that returns the head element of the ready queue is as follows
SCHEDQHd =
∃∆PRIOQ •
ΦSCHED ∧PRIOQHd
It expands and simpliﬁes to
sq = sq′
sq.maxs = sq′.maxs
p! = head sq.pq
The operation to remove the head of the scheduler’s queue is another
promotion
SCHEDQDelHd =
∃∆PRIOQ •
ΦSCHED ∧PRIOQDelHd
The predicate expands and simpliﬁes to
sq.pq = pq
sq′.maxs = sq.maxs
sq′.pq = tail sq.pq
The arbitrary element deletion operation is another promotion.
DelSCHEDQElem =
∃∆PRIOQ • ΦSCHED ∧DelPRIOQElem
This expands into

3.6 The Scheduler
109
∃pq, pq′ : seq PID; maxs, maxs′ : N •
sq = θPRIOQ ∧
sq′ = θPRIOQ′ ∧
pq ̸= ⟨⟩∧
(∃s1, s2 : seq PID •
s1 ⌢⟨p?⟩⌢s2 = pq ∧
pq′ = s1 ⌢s2)
Ignoring the intermediate steps, we have
sq.maxs = sq′.maxs
sq.pq ̸= ⟨⟩
(∃s1, s2 : seq PID •
s1 ⌢⟨p?⟩⌢s2 = sq.pq ∧
sq′.pq = s1 ⌢s2)
The precondition is not much of a surprise, as the following calculation
shows.
pre DelSCHEDQElem =
pre ΦSCHED ∧pre DelPRIOQElem
⇔pre DelPRIOQElem
This is equivalent to
p? ∈ran pq
or
ran pq ̸= ∅
When there is nothing else to do, the idle process is executed. The following
schema deﬁnes the operation that sets the schedulers’ local variables ready to
switch to the idle process’ context.
MakeIdleProcessCurrent
∆SCHED
curr ′ = iprc
prev ′ = curr
Under the right conditions, the current process is continued:
ContinueCurrent
ΞSCHED
curr ′ = curr
prev ′ = prev

110
3 A Simple Kernel
This is just an identity (which is what is required).
If the current process’ state is not psready or psrunning, it can no longer be
considered for execution by the scheduler. The next deﬁnition is of a predicate
that performs this test.
CurrentProcessStateIsReadyOrRunning =
(CurrentProcessId[c/p!] ∧
(∃st : PSTATE | st = psready •
ProcState[c/p?, st/st!]) ∧
(∃st : PSTATE | st = psrunning •
ProcState[c/p?, st/st!])) \ {c}
The deﬁnition expands into:
CurrentProcessStateIsReadyOrRunning
ΞSCHED
ΞPTAB
∃c : PID •
curr = c ∧
(∃st : PSTATE | st = psready •
state(c) = st)
∨(∃st : PSTATE | st = psrunning •
state(c) = st)
It simpliﬁes to:
ΞSCHED
ΞPTAB
(state(curr) = psready) ∨(state(curr) = psrunning)
Note that ¬ CurrentProcessStateIsReadyOrRunning is
¬ CurrentProcessStateIsReadyOrRunning
ΞSCHED
ΞPTAB
state(curr) ̸= psready ∧state(curr) ̸= psrunning
It is easy, when not paying suﬃcient attention, to forget to change ∨to ∧
when negating.
Before deﬁning SchedNext, we need
QueueHdHasHigherPriority =
(CurrentPriority[cp/pr!] ∧
SCHEDQHd[h/p!] ∧
ProcPrio[h/p?, hpr/pr!] ∧
hpr < cp) \ {h, hpr, cp}

3.6 The Scheduler
111
This expands to
QueueHdHasHigherPriority
ΞPTAB
ΞSCHED
∃h, cp : PID; hpr : PPRIO •
prio(curr) = cp ∧
head sq.pq = h ∧
prio(h) = hpr ∧
hpr < cp
The predicate of this schema simpliﬁes to
prio(head sq.pq) < prio(curr)
The schema is
QueueHdHasHigherPriority
ΞPTAB
ΞSCHED
prio(head sq.pq) < prio(curr)
Finally, we reach the scheduling function itself. It is a complex operation
but should not prove diﬃcult to understand.
SchedNext =
(IsCurrentProcessIdle ∧
((IsEmptySCHEDQ ∧ContinueCurrent)
∨(SCHEDQDequeue[p/p!] ∧
SetNewCurrentProcess[p/p?]
o
9CTXTSW ) \ {p}))
∨(IsEmptySCHEDQ ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨((¬ CurrentProcessStateIsReadyOrRunning
∨QueueHdHasHigherPriority) ∧
(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧
SetNewCurrentProcess[hpid/p?]
o
9CTXTSW ) \ {hpid})
∨ContinueCurrent
Since CTXTSW does not have any variables that interact with any others in
SchedNext, it is possible to reduce the strength of o
9 to ∧.
The deﬁnition expands into the following schema. The context-switching
operation, CTXTSW, is left unexpanded (its predicate consists solely of
intno′ = context swictch).

112
3 A Simple Kernel
∆SCHED
(curr = iprc ∧
((sq.pq = ⟨⟩∧curr ′ = curr ∧prev ′ = prev)
∨(∃p : PID •
p = head pq ∧curr ′ = p ∧prev ′ = curr ∧
state′ = state ⊕{head sq.pq →psrunning} ∧CTXTSW )))
∨(sq.pq = ⟨⟩∧prev ′ = curr ∧curr ′ = iprc ∧CTXTSW )
∨((state(curr) ̸= psready ∧state(curr) ̸= psrunning
∨prio(head sq.pq) < prio(curr)) ∧
(∃hpid : PID •
head sq.pq = hpid ∧
sq′.pq = tail sq.pq ∧
curr ′ = hpid ∧
state′ = state ⊕{hpid →psrunning} ∧
prev ′ = curr ∧CTXTSW ))
∨(curr ′ = curr ∧prev ′ = prev)
This simpliﬁes to
∆SCHED
(curr = iprc ∧
((sq.pq = ⟨⟩∧curr ′ = curr ∧prev ′ = prev)
∨(curr ′ = head sq.pq ∧prev ′ = curr ∧
state′ = state ⊕{head sq.pq →psrunning} ∧CTXTSW )))
∨(sq.pq = ⟨⟩∧prev ′ = curr ∧curr ′ = iprc ∧CTXTSW )
∨((state(curr) ̸= psready ∧state(curr) ̸= psrunning
∨prio(head sq.pq) < prio(curr)) ∧
sq′.pq = tail sq.pq ∧
curr ′ = head sq.pq ∧
state′ = state ⊕{head sq.pq →psrunning} ∧
prev ′ = curr ∧CTXTSW )
∨(curr ′ = curr ∧prev ′ = prev)
To calculate the precondition of SchedNext, it is ﬁrst noted that Sched-
Next takes the form of a disjunction, so it is permitted to decompose the
precondition into disjuncts since pre(P ∨Q) ⇔pre P ∨pre Q). Therefore,
we decompose the SchedNext schema into its components and handle them
separately; then we combine the result to form the precondition.

3.6 The Scheduler
113
pre SchedNext =
pre[(IsCurrentProcessIdle ∧
((IsEmptySCHEDQ ∧ContinueCurrent)
∨(SCHEDQDequeue[p/p!] ∧SetNewCurrentProcess[p/p?]
o
9CTXTSW ) \ {p}))
∨(IsEmptySCHEDQ ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨((¬ CurrentProcessStateIsReadyOrRunning
∨QueueHdHasHigherPriority) ∧
(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧
SetNewCurrentProcess[hpid/p?]
o
9CTXTSW ) \ {hpid})
∨ContinueCurrent]
The SchedNext operation is composed of disjunctions. Each disjunct can be
treated independently, so we have:
pre SchedNext =
pre(IsCurrentProcessIdle ∧
((IsEmptySCHEDQ ∧ContinueCurrent)
∨(SCHEDQDequeue[p/p!] ∧
SetNewCurrentProcess[p/p?]
o
9CTXTSW ) \ {p}))
∨pre(IsEmptySCHEDQ ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨pre((¬ CurrentProcessStateIsReadyOrRunning
∨QueueHdHasHigherPriority) ∧
(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧
SetNewCurrentProcess[hpid/p?]
o
9CTXTSW ) \ {hpid})
∨pre ContinueCurrent
Taking each disjunct in turn, we obtain, after simpliﬁcation:
pre SchedNext =
curr = iprc
∨sq.pq = ⟨⟩
∨(state(curr) ̸= psready ∨state(curr) ̸= psrunning
∨prio(head sq.pq) < prio(curr))
and we note that the precondition of the fourth disjunct simpliﬁes to true.
There are two
Theorem 38. curr ∈used ∨curr = minpid.
Proof. By inspection, it can be seen that curr is assigned a value that is
head sq.pq. Since ran sq.pq ⊂used, curr ∈used. The idle process, iprc, as will
be seen, is allocated a normal PID, like any other process, so iprc ∈used.
After the initialisation of the scheduler, curr ′ = minpid. 2

114
3 A Simple Kernel
Corollary 3. prev ∈used ∨prev = minpid.
Proof. In all cases, prev obtains is value by assignments prev ′ = curr. Given
that curr ∈used, it follows immediately prev ∈used. The other case holds
immediately after the initialisation operation has been applied. 2
In this kernel, processes can request that they be suspended, This is the
operation as far as the scheduler is concerned.
SuspendMe =
((IsEmptySCHEDQ ∧MakeIdleProcessCurrent)
∨((SCHEDQDequeue[p/p!]o
9
(CurrentProcessId[c/p!] ∧MakeReady[c/p?]) \ {c})
o
9SetNewCurrentProcess[p/p?]) \ {p})
o
9CTXTSW
(Note, again, that o
9CTXTSW can be reduced in strength to ∧CTXTSW .)
The deﬁnition of SuspendMe expands and simpliﬁes to the following
schema:
SuspendMe
∆SCHED
∆PRIOQ
state′ = state ⊕{curr →psready}
((pq = ⟨⟩∧curr ′ = prev ∧prev ′ = curr)
∨(curr ′ = head pq ∧
(#(tail pq) < maxs ∧
prev ′ = curr ∧
((tail pq = ⟨⟩∧pq′ = ⟨curr⟩)
∨(prio(curr) ≤prio(head tail pq) ∧pq′ = ⟨curr⟩⌢tail pq)
∨(prio(last tail pq) < prio(curr) ∧pq′ = (tail pq) ⌢⟨curr⟩)
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = tail pq •
prio(last s1) < prio(curr) ∧
prio(curr) ≤prio(head s2) ∧
pq′ = s1 ⌢⟨curr⟩⌢s2) ∧
serr! = sysok))
∨serr! = schedqfull) ∧
CTXTSW
The movement of prev ′ = curr is justiﬁed by the combination of Distrib∨and
p ∧q ⇒p; the conjunction of CTXTSW is also a simpliﬁcation of the orginal
statement (the simpliﬁcation is justiﬁed above).
The precondition is
pre SuspendMe = pq = ⟨⟩∨# tail pq < maxs
There is an argument that SuspendMe should be deﬁned as follows

3.6 The Scheduler
115
SuspendMe =
((IsEmptySCHEDQ ∧MakeIdleProcessCurrent ∧
(CurrentProcessId[c/p!] ∧
MakeReady[c/p?]) \ c)
∨((SCHEDQDequeue[p/p!]o
9
(CurrentProcessId[c/p!] ∧MakeReady[c/p?]) \ {c})
o
9SetNewCurrentProcess[p/p?]) \ {p})
o
9CTXTSW
After expansion and simpliﬁcation (note that CTXTSW is moved inwards
using the Distrib rule for ∧over ∨), we have
SuspendMe
∆SCHED
∆PRIOQ
state′ = state ⊕{curr →psready}
((sq.pq = ⟨⟩∧curr ′ = iprc ∧prev ′ = curr ∧sq.pq′ = ⟨curr⟩∧CTXTSW )
∨(curr ′ = head sq.pq ∧
(#(tail sq.pq) < maxs ∧
prev ′ = curr ∧
((tail sq.pq = ⟨⟩∧sq.pq′ = ⟨curr⟩)
∨(prio(curr) ≤prio(head tail sq.pq) ∧
sq.pq′ = ⟨curr⟩⌢tail sq.pq)
∨(prio(last tail sq.pq) < prio(curr) ∧
sq.pq′ = (tail sq.pq) ⌢⟨curr⟩)
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = tail sq.pq •
prio(last s1) < prio(curr) ∧
prio(curr) ≤prio(head s2) ∧
sq.pq′ = s1 ⌢⟨curr⟩⌢s2) ∧
CTXTSW ∧
serr! = sysok))
∨serr! = schedqfull)
The precondition is the same as in the other version.
3.6.2 Reﬁnement One
There is a number of things that should be said about the reﬁnement of
the scheduler. The ﬁrst thing is that, since the scheduler consists of three
simple variables and a promoted schema, the reﬁnement of the three variables
will consist of the identity, leaving the reﬁnement of the promoted schema.
However, the reﬁnement of a promotion is equivalent to the promotion of a
reﬁnement, so there is nothing to do for the reason that the reﬁnement of
PRIOQ has already been completed in the last section. For these reasons, all

116
3 A Simple Kernel
we need do in this and the next subsection is to write out the deﬁnitions of
the various schemata using the operations of the current level of reﬁnement.
In this subsection, the current level of reﬁnement is 1; in the next, it is 2.
We have little or nothing to say about these reﬁnements. We have not said
all there is to say about them already but believe that what we have not said
is inessential1.
MakeReady1 =
SetProcessStateToReady1 ∧
∃∆PRIOQ1 •
ΦSCHED ∧PRIOQEnqueue1
CurrentProcessStateIsReadyOrRunning1 =
(CurrentProcessId[c/p!] ∧
(∃st1, st2 : PSTATE | st1 = psready ∧st2 = psrunning •
ProcState1[c/p?, st1/st!] ∨ProcState1[c/p?, st2/st!])) \ {c}
This expands to
CurrentProcessStateIsReadyOrRunning1
ΞPTAB1
ΞSCHED
∃c : PID •
c = curr ∧
(∃st1, st2 : PSTATE | st1 = psready ∧st2 = psrunning •
st1 = state1(c) ∨st2 = state1(c))
It can be simpliﬁed to
CurrentProcessStateIsReadyOrRunning1
ΞPTAB1
ΞSCHED
psready = state1(curr) ∨psrunning = state1(curr)
QueueHdHasHigherPriority1 =
(CurrentPriority[cp/pr!] ∧
SCHEDQHd1[h/p!] ∧
ProcPrio1[h/p?, hpr/pr!] ∧
hpr < cp) \ {h, hpr, cp}
This expands into
1 We hope!

3.6 The Scheduler
117
QueueHdHasHigherPriority1
ΞSCHED
ΞPTAB1
∃h : PID; hpr, cp : PPRIO •
prio1(curr) = cp ∧
h = pq1(1) ∧
prio1(h) = hpr ∧
hpr < cp
and then to
QueueHdHasHigherPriority1
ΞSCHED
ΞPTAB1
∃hpr, cp : PPRIO •
h = pq1(1) ∧
prio1(h) = hpr ∧
hpr < prio1(curr)
and ﬁnally to
QueueHdHasHigherPriority1
ΞSCHED
ΞPTAB1
prio1(pq1(1)) < prio1(curr)
SchedNext1 =
(IsCurrentProcessIdle ∧
((IsEmptySCHEDQ1 ∧ContinueCurrent)
∨(SCHEDQDequeue1[p/p!] ∧SetNewCurrentProcess[p/p?]
o
9CTXTSW ) \ {p}))
∨(IsEmptySCHEDQ1 ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨((¬ CurrentProcessStateIsReadyOrRunning1
∨QueueHdHasHigherPriority1) ∧
(SCHEDQHd1[hpid/p!] ∧
SCHEDQDelHd1 ∧
SetNewCurrentProcess[hpid/p?] o
9 CTXTSW ) \ {hpid})
∨ContinueCurrent
The precondition, when simpliﬁed, is

118
3 A Simple Kernel
pre SchedNext1 =
curr = iprc
∨nxtp = 1
∨(prio1(pq1(1)) < prio1(curr)
∨psready ̸= state1(curr) ∨psrunning ̸= state1(curr))
The reader should not be surprised at the similarity between this precondition
and that of SchedNext1. This is clearly because the abstraction relation is an
identity.
The ﬁrst reﬁnement of SuspendMe1 is
SuspendMe1 =
((IsEmptySCHEDQ1 ∧MakeIdleProcessCurrent ∧
(CurrentProcessId[c/p!] ∧
MakeReady1[c/p?]) \ c)
∨((SCHEDQDequeue1[p/p!]o
9
(CurrentProcessId[c/p!] ∧MakeReady1[c/p?]) \ {c})
o
9SetNewCurrentProcess[p/p?]) \ {p})
o
9SwitchContext
3.6.3 Reﬁnement Two
These reﬁnements are mostly concerned with the PTAB2 component of sched-
uler operations. We have already reﬁned the priority queue as far as we require,
so all components included from the priority queue are the same as in the pre-
vious reﬁnement. The priority queue component is a promoted component, so
there are no reﬁnement proofs required. The other immediate components of
the scheduler are scalar variables and they cannot be reﬁned for the very rea-
son that they have reached their ﬁnal level of reﬁnement already. This leaves
components of PTAB as candidates for reﬁnement proofs. In each case, there
is the requirement that p? ∈used (or equivalent under reﬁnement) and this
condition is met by the implicit precondition to PRIOQ that ran pq ⊂used.
We believe, therefore, that no reﬁnement proofs are required in this subsec-
tion. We will, though, include the reﬁnements of the primary schemata plus
some auxilliary operations.
CurrentProcessStateIsReadyOrRunning2 =
(CurrentProcessId[c/p!] ∧
(∃st1, st2 : PSTATE | st1 = psready ∧st2 = psrunning •
ProcState2[c/p?, st1/st!] ∨ProcState2[c/p?, st2/st!])) \ {c}
As in the previous cases, this operation reﬁnes to
CurrentProcessStateIsReadyOrRunning2
ΞPTAB1
ΞSCHED
psready = state2(curr) ∨psrunning = state2(curr)

3.7 Semaphores
119
QueueHdHasHigherPriority2 =
(CurrentPriority[cp/pr!] ∧
SCHEDQHd1[h/p!] ∧
ProcPrio2[h/p?, hpr/pr!] ∧
hpr < cp) \ {h, hpr, cp}
As in the previous cases, this expands and simpliﬁes to
QueueHdHasHigherPriority1
ΞSCHED
ΞPTAB1
prio2(pq1(1)) < prio2(curr)
SchedNext2 =
(IsCurrentProcessIdle ∧
((IsEmptySCHEDQ1 ∧ContinueCurrent)
∨(SCHEDQDequeue1[p/p!] ∧SetNewCurrentProcess[p/p?]
o
9CTXTSW ) \ {p}))
∨(IsEmptySCHEDQ1 ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨((¬ CurrentProcessStateIsReadyOrRunning2
∨QueueHdHasHigherPriority2) ∧
(SCHEDQHd1[hpid/p!] ∧
SCHEDQDelHd1 ∧
SetNewCurrentProcess[hpid/p?] o
9 CTXTSW ) \ {hpid})
∨ContinueCurrent
The second reﬁnement of SuspendMe is
SuspendMe2 =
((IsEmptySCHEDQ2 ∧MakeIdleProcessCurrent ∧
(CurrentProcessId[c/p!] ∧
MakeReady2[c/p?]) \ c)
∨((SCHEDQDequeue2[p/p!]o
9
(CurrentProcessId[c/p!] ∧MakeReady2[c/p?]) \ {c})
o
9SetNewCurrentProcess[p/p?]) \ {p})
o
9CTXTSW
The schemata from this last reﬁnement have now been shown to be correct.
They can be converted directly into executable code.
3.7 Semaphores
The kernel allows processes to synchronise using semaphores. This section
contains the deﬁnition of the semaphore type.

120
3 A Simple Kernel
The kernel only uses semphores. It would be very easy to extend it so that
it included, say, condition variables. We refrain from such extensions because
of their eﬀect on the length of this book.
Semaphores are deﬁned as a counter and a queue. The queue is the FIFO
queue type deﬁned for processes. This is done using promotion. This en-
ables the separate reﬁnement of the queue of waiting processes, waiters (of
type PROCESSQUEUE). Since the PROCESSQUEUE type has already been
speciﬁed and reﬁned, there is no work to do with respect to its use in the cur-
rent context. The only thing we really have to do is to rename the components
of the PROCESSQUEUE and its operations so that they are more appropriate
to semaphores.
The deﬁnition of the semaphore state space schema is
SEMAPHORE
scnt : Z
waiters : PROCESSQUEUE
where scnt is the semaphore’s counter and waiters is the queue of waiting
processes.
3.7.1 Top Level
We will need to prove the following result:
Theorem 39. If waiters ̸= ⟨⟩, ∀p : PID • p ∈ran waiters ⇒p ∈used
It should be noted that the schema for semaphore has an often ignored in-
teraction with the scheduler. If there is more than one waiter and the current
process waits on the same semaphore, if the scheduler’s queue is now empty,
the semaphore will hang indeﬁnitely because the idle process will run. Consid-
eration of this leads to the inevitable conclusion that this is correct behaviour
for the semaphore. If all runnable processes are waiting on the semaphore,
there is no process to signal on it, so they must wait indeﬁnitely.
A promotion schema is clearly required so that the relevant operations on
PROCESSQUEUE can be promoted to semaphore operations.
ΦSEMAPHORE
∆SEMAPHORE
∆PROCESSQUEUE
waiters = θPROCESSQUEUE
waiters′ = θPROCESSQUEUE ′
The operations to add and remove a waiting process (a “waiter”) are
deﬁned by promotion as follows:

3.7 Semaphores
121
AddWaiter =
∃∆SEMAWAITERS •
ΦSEMAPHORE ∧EnqueuePROCESSQUEUE
RemoveWaiter =
∃∆SEMAWAITERS •
ΦSEMAPHORE ∧DequeuePROCESSQUEUE
Semaphores are initialised by clearing their queue of waiters and by setting
the counter to some value (here ival?). Appropriate setting of the semaphore
gives a binary semaphore and a larger value for ival? will give a general
semaphore.
SEMAPHOREInit
SEMAPHORE ′
ival? : Z
scnt′ = ival?
waiters′ = θPROCESSQUEUEInit
The wait and signal operations require the counter to be incremented and
decremented, so the following operations are required. Note that they do not
depend upon promotion but act on the variables of the SEMAPHORE type.
IncSEMACNT
∆SEMAPHORE
scnt′ = scnt + 1
DecSEMACNT
∆SEMAPHORE
scnt′ = scnt −1
The following schema deﬁnes a predicate which is true iﬀscnt is negative.
NegativeSemaCount
ΞSEMAPHORE
scnt < 0
The next schema deﬁnes a predicate which is true iﬀscnt is not positive—i.e.,
is either 0 or negative.
NonpositiveSemaCount
ΞSEMAPHORE
scnt ≤0

122
3 A Simple Kernel
A process that is waiting on a semaphore has a state value pswaitsema
(reasonably enough!). The following schema on PTAB deﬁnes the appropriate
action:
SetStateToWaitSema =
∃st : PSTATE | st = pswaitsema •
SetProcState[st/st?]
This expands and simpliﬁes to
SetStateToWaitSema
∆PTAB
p? : PID
state′ = state ⊕{p? →pswaitsema}
The operation that waits on a semaphore is deﬁned as:
WaitSema =
DecSEMACNT o
9
((NegativeSemaCount ∧
SetStateToWaitSema ∧
AddWaiter[caller?/p?]o
9
SchedNext)
∨ContinueCurrent)
The caller, caller?, is always the currently executing process, so caller? =
curr, so the WaitSema operation is, more correctly
WaitSema =
DecSEMACNT o
9
((NegativeSemaCount ∧
(CurrentProcessId[c/p!] ∧
SetStateToWaitSema[c/p?] ∧
AddWaiter[c/p?]) \ {c}
o
9SchedNext)
∨ContinueCurrent)
Notice that WaitSema can be equivalently expressed as follows
WaitSema =
DecSEMACNT o
9
((NegativeSemaCount ∧
(CurrentProcessId[c/p!] ∧
SetStateToWaitSema[c/p?] ∧
(∃∆PROCESSQUEUE •
ΦSEMAPHORE ∧
EnqueuePROCESSQUEUE[c/p?])) \ {c} ∧
o
9SchedNext)
∨ContinueCurrent)

3.7 Semaphores
123
The full expansion is as follows. The WaitSema schema expands ﬁrst (after
elimination of the existential quantiﬁer by the one-point rule) into
WaitSemaa
∆PTAB
∆SEMAPHORE
∆PROCESSQUEUE
∆SCHED
serr! : SYSERR
(scnt′ = scnt −1 ∧
(scnt′ < 0 ∧
state′ = state ⊕{curr →pswaitsema} ∧
waiters.procs = waiters.procs ⌢⟨curr⟩o
9
SchedNext)
∨(curr ′ = curr ∧prev ′ = prev))
Its second expansion is
WaitSema
∆SCHED
∆PTAB
∆SEMAPHORE
∆PROCESSQUEUE
serr! : SYSERR
∃state′′ : PID →PSTATE •
(scnt′ = scnt −1 ∧
((scnt′ < 0 ∧
waiters.procs′ = waiters.procs ⌢⟨curr⟩∧
state′′ = state ⊕{curr →pswaitsema} ∧
(curr = iprc ∧
((pq = ⟨⟩∧curr ′ = curr ∧prev ′ = prev)
∨(curr ′ = head pq ∧prev ′ = curr ∧
state′ = state ⊕{head pq →psrunning}
∧CTXTSW )))
∨(pq = ⟨⟩∧prev ′ = curr ∧curr ′ = iprc ∧CTXTSW )
∨((state′′(curr) ̸= psready ∧state′′(curr) ̸= psrunning
∨prio(head pq) < prio(curr)) ∧
pq′ = tail pq ∧
curr ′ = head pq ∧
state′ = state ⊕{head pq →psrunning} ∧
prev ′ = curr ∧
CTXTSW )
∨(curr ′ = curr ∧prev ′ = prev)
∨(curr ′ = curr ∧prev ′ = prev))

124
3 A Simple Kernel
In the call to SchedNext, the state of curr is clearly pswaitsema, this can be
used as an additional fact in simplifying the predicate.
WaitSema
∆SCHED
∆PTAB
∆SEMAPHORE
∆PROCESSQUEUE
serr! : SYSERR
((scnt ≤0 ∧
waiters.procs′ = waiters.procs ⌢⟨curr⟩∧
state′ = state ⊕{curr →pswaitsema} ∧
((pq = ⟨⟩∧prev ′ = curr ∧curr ′ = iprc)
∨(pq = tail pq ∧
curr ′ = head pq ∧
state′ = state ⊕{head pq →psrunning} ∧
prev ′ = curr)))
∨(curr ′ = curr ∧prev ′ = prev))
and its precondition is
pre WaitSema = scnt ≤0
Note that the SignalSema operation can be performed by any piece of
code, not just the current process. This implies that it can be called by, for
example, a device interface.
Finally, it should be noted that curr ′ = curr ∧prev ′ = prev is just skip
when implemented. Next we have the signal operation (the V operation in
the original):
SignalSema =
IncSEMACNT o
9
(NonPositiveSemaCount ∧
(∃p : PID •
RemoveWaiter[p/p!] ∧
MakeReady[p/p?])) ∧
ContinueCurrent)
Schema SignalSema expands into:
SignalSema
∆SEMAPHORE
∆PROCESSQUEUE
serr! : SYSERR
scnt′ = scnt + 1 ∧
(scnt′ ≤0 ∧
waiters.procs′ = tail waiters.procs ∧

3.7 Semaphores
125
MakeReady[head waiters.procs/p?]) ∧
(curr ′ = curr ∧prev ′ = prev)
Note how this speciﬁcation is much simpler than in [4]. This is because
we are interested only in the reﬁnement not in a (relatively) complete micro
model of the operation of the semaphore.
The SignalSema operation expands next into the following schema:
SignalSema
∆PRIOQ
∆SEMAPHORE
∆PROCESSQUEUE
serr! : SYSERR
(scnt < 0 ∧
waiters.procs′ = tail waiters.procs ∧
((#sq.pq < maxs ∧
((sq.pq = ⟨⟩∧sq.pq′ = ⟨head waiters.procs⟩)
∨(prio(head waiters.procs) ≤prio(head sq.pq) ∧
sq.pq′ = ⟨head waiters.procs⟩⌢sq.pq)
∨(prio(last sq.pq) < prio(head waiters.procs) ∧
sq.pq′ = sq.pq ⌢⟨head waiters.procs⟩)
∨(∃s1, s2 : seq PID |
s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(head waiters.procs) ∧
prio(head waiters.procs) ≤prio(head s2) ∧
sq′ = s1 ⌢⟨head waiters⟩⌢s2)) ∧
state′ = state ⊕{head waiters →psready} ∧
serr! = sysok)
∨serr! = schedqfull))
∧(curr ′ = curr ∧prev ′ = prev)
The ﬁnal conjunct (curr ′ = curr ∧prev ′ = prev) reduces to skip because
it is just the identity applied to the scheduler’s state. It could, therefore, be
omitted; it will be left as a reminder when translating the schema.
There is not a great deal that can be done with this schema! Let us,
instead, calculate the precondition.
pre SignalSema =
scnt + 1 ≤0 ∧#sq.pq < maxs ∧waiters.procs ̸= ⟨⟩
or:
scnt < 0 ∧#sq.pq < maxs ∧waiters.procs ̸= ⟨⟩

126
3 A Simple Kernel
3.7.2 Reﬁnement
Because of the use of promotion in the deﬁnition of SEMAPHORE, there is
very little to do as far as reﬁnement is concerned. The reﬁnement of scnt is just
scnt itself (it is just a scalar variable), while the reﬁnement of the queue type
has already been completed. The only slight complication is the alteration of
the state variable in PTAB; two reﬁnements of PTAB should be taken into
account.
The production of reﬁnement schemata consists only of substituting new
names into those presented above. There is no need to engage in any correct-
ness proofs because they have already been done.
The substitution of the apporpriate promoted schemata into the schemata
deﬁning WaitSema and SignalSema produces schemata that are suitable for
translation into code.
The schemata derived in this section can be implemented directly as ex-
ecutable code. In the current case, the semaphore construct is composed of
already reﬁned constructs, its implementation is less obvious in the schemata.
3.8 Semaphore Table
Now that we have semaphores, a table to hold them can be deﬁned. This table
will be maintained by the kernel, so a measure of control can be exerted on
the number of semaphores in the system.
The table has the usual operations.
Following our convention, the error schemata are deﬁned ﬁrst. There are
two error schemata: NotAllocSema for when an attempt has been made to per-
form an operation on a semaphore that has not been allocated and NoFreeSe-
mas which reports that the semaphore table is full.
NotAllocSema
serr! : SYSERR
serr! = notallocsema
NoFreeSemas
serr! : SYSERR
serr! = nofreesemas
3.8.1 Top Level
This subsection contains the speciﬁcation of the semaphore table. The table
supports the following operations:

3.8 Semaphore Table
127
•
Initialisation.
•
Allocate a new semaphore.
•
Free a semaphore.
Since semaphores were speciﬁed and reﬁned to near code in the last section,
the semaphore table can be speciﬁed using promotion.
An indentiﬁer type for semaphores must ﬁrst be deﬁned. This is an atomic
type. Its elements are semaphore identiﬁers.
[SID]
This type will be reﬁned.
The semaphore table is deﬁned as follows:
SEMATBL
semas : SID →SEMAPHORE
semasinuse : F SID
semasinused = dom semas
The variable semas is the table, a partial mapping from semaphore identiﬁers
to semaphores; semasinuse contains the identiﬁers of those semaphores that
are currently in use. The semasinuse variable is used to determine whether it
is possible to allocate another semaphore, whether a semaphore is in use, and
so on.
The initialisation schema is deﬁned as:
SEMATBLInit
SEMATBL′
semasinuse′ = ∅
This is very much as would be expected. By making semasinuse′ = ∅, the
domain of semas is also made empty.
The promotion schema is a textbook case:
ΦSEMATBL
∆SEMATBL
∆SEMAPHORE
s? : SID
s? ∈semasinuse
semas(s?) = θSEMAPHORE
semas′ = semas ⊕{s? →θSEMAPHORE ′}
The following schema deﬁnes the operation to free a semaphore. Freeing a
semaphore consists of removing the semaphore’s identiﬁer from semasinuse.

128
3 A Simple Kernel
FreeSema
∆SEMATBL
s? : SID
semasinuse′ = semasinuse \ {s?}
The following schema deﬁnes the allocation operation for semaphore iden-
tiﬁers. A semaphore can be allocated only when an identiﬁer has been allo-
cated, so this schema amounts to the ﬁrst stage in allocating a semaphore.
AllocSID
∆SEMATBL
s! : SID
s! ̸∈semasinuse
semasinuse′ = semasinuse ∪{p!}
The operation is nondeterministic. The identiﬁer to be returned, s!, is chosen
nondeterministically so that it does not occur in semasinuse (the operation
must be used only when it is known that semasinuse ̸= ∅). The newly allo-
cated identiﬁer is added to semasinuse in the last conjunct.
The next schema deﬁnes a predicate which is satisﬁed when there are some
elements of SID that are not elements of semasinuse.
FreeSIDs
ΞSEMATBL
semasinuse ⊂SID
The following deﬁnes the initialisation of a semaphore, once allocated.
Given a semaphore identiﬁer, s?, the associated semaphore is initialised us-
ing θSEMAPHOREInit. There is no magic here; the value used to initialise
the semaphore is merely implicitly declared in the signature of the InitSema
schema).
InitSema
∆SEMATBL
s? : SID
semas′ = semas ∪{s? →θSEMAPHOREInit}
The operation to allocate semaphores is
AllocSema =
(AllocSID ∧InitSema ∧SysOk)
∨NoFreeSemas

3.8 Semaphore Table
129
It expands into:
AllocSema
∆SEMATBL
s! : SID
serr! : SYSERR
(s? ̸∈semasinuse ∧
semasinuse′ = semasinuse ∪{s!} ∧
semas′ = semas ∪{s? →θSEMAPHOREInit} ∧
serr! = sysok)
∨serr! = nofreesemas
The precondition is
pre AllocSema = ∃s : SID • s ∈semasinuse
To free a semaphore, the ReleaseSema operation is used. This operation
is deﬁned as follows.
ReleaseSema =
(SemaInUse ∧FreeSema ∧SysOk)
∨NotAllocSema
This deﬁnition expands into the following schema:
ReleaseSema
∆SEMATBL
s? : SID
serr! : SYSERR
(s? ∈semasinuse ∧
semasinuse′ = semasinuse \ {s?} ∧
serr! = sysok)
∨serr! = notallocsema
The ReleaseSema schema’s precondition is given by the following schema.
pre ReleaseSema = s? ∈semasinuse
The semaphore operations can be promoted to operations on the table.
The deﬁnitions are quite standard and are as follows:
STWaitSema =
∃∆SEMAPHORE •
ΦSEMATBL ∧WaitSema
and

130
3 A Simple Kernel
STSignalSema =
∃∆SEMAPHORE •
ΦSEMATBL ∧SignalSema
There is no reﬁnement necessary for these operations.
3.8.2 Reﬁnement One
The ﬁrst object of concern is the type SID. This was an atomic type when
initially deﬁned. For this reﬁnement, it is itself reﬁned to:
SID == minsid . . maxsid
In addition, it is necessary to deﬁne:
minsid, maxsid : N1
minsid < maxsid
Good values for minsid are zero or one.
The semaphore table type can now be deﬁned as the following schema
ST1
semas1 : SID →SEMAPHORE
sinuse : SID →{0, 1}
Here, the set, semasinuse, is replaced by a function. The evaluation of the
function for an arbitrary value of s is sinuse(s) = 1 iﬀs ∈semasinuse,
sinuse(s) = 0 otherwise. In other words, sinuse is the characteristic function
of semasinuse. The other component, semas1, is now a total function but its
domain and codomain are identical. Moreover, it is intended that the value of
semas1(s) is deﬁned at s iﬀsinuse(s) = 1.
The initialisation schema is very much as one might expect:
ST1Init
ST1′
∀s : SID •
sinuse′(s) = 0
The operation to allocate a semaphore is, again, nondeterministic.
AllocST1
∆ST1
s! : SID
∃s : SID •
sinuse(s) = 0 ∧
sinuse′ = sinuse ⊕{s →1} ∧
s! = s

3.8 Semaphore Table
131
Here, the nondeterminism is located in the choice of s, not s!, as was the case
in the last subsection. The predicate of this schema is equivalent to
sinuse(s!) = 0
sinuse′ = sinuse ⊕{s! →1}
which, we believe, makes the nondeterminism harder to detect. Nonetheless,
the two deﬁnitions of the operation are perfectly adequate for our needs; we do
not care which particular identiﬁer is chosen, as long as one is. The identiﬁer
should not be in current use; once chosen, it should be marked as being in
use. This is what the operation states, so it is adequate.
FreeSID1
∆ST1
s? : SID
sinuse′ = sinuse ⊕{s? →0}
The operation to free a semaphore identiﬁer is just an update of the sinuse
function. This is obvious given the relationship between semasinuse and
sinuse.
The semaphore initialisation operation is next.
InitSema1
∆ST1
s? : SID
semas1′ = semas1 ⊕{s? →θSEMAPHOREInit}
The next schema deﬁnes a predicate that is satisﬁed when s? is in use.
SemaInUse1
ΞST1
s? : SID
sinuse(s?) = 1
The allocation operation should cause no problems. It is deﬁned as
AllocSema1 =
(AllocSID1 ∧InitSema![s!/s?] ∧SysOk)
∨NoFreeSema
and expands into:

132
3 A Simple Kernel
AllocSema1
∆ST1
s! : SID
serr! : SYSERR
((∃s : SID •
sinuse(s) = 0 ∧
sinuse′ = sinuse ⊕{s →1} ∧
s! = s) ∧
semas1′ = semas1 ⊕{s! →θSEMAPHOREInit} ∧
serr! = sysok)
∨serr! = nofreesema
The precondition of AllocSema1 is easily calculated. It is
pre AllocSema1 =
∃s : SID •
sinuse(s) = 0
The operation to free a semaphore is the following:
ReleaseSema1 =
(SemaInUse1 ∧FreeSID1 ∧SysOk)
∨NotAllocSema
It expands into the next schema:
ReleaseSema
∆ST1
s? : SID
(sinuse(s?) = 1 ∧
sinuse′ = sinuse ⊕{s? →0} ∧
serr! = sysok)
∨serr! = notallocsema
An abstraction relation is needed so that this level of representation can be
related to the top-level speciﬁcation. The abstraction relation is the obvious
one.
AbsST1
ST
ST1
∀s : SID •
sinuse(s) ⇔s ∈semasinuse
∀s : SID •
s ∈semasinuse ⇒semas1(s) = semas(s)

3.8 Semaphore Table
133
3.8.3 Reﬁnement One–Again
The ﬁrst reﬁnement of SEMATBL reﬁnes the partial function to what amounts
to an array indexed by SID. The other component of ST1, sinuse, is a mapping
between semaphore identiﬁers and the set {0, 1}, which is used to represent
semasinuse. The object of this reﬁnement is to ﬁnd a more compact repre-
sentation for semasinuse or sinuse. The aim is to reﬁne sinuse to a bitmap.
First, the number of bits per machine word must be deﬁned.
bpw : N1
Next, it is necessary to deﬁne how many words are required to represent
the elements of SID, one element per bit.
msize : N1
msize = ⌈maxsid−minsid
bpw
⌉
Clearly, if minsid = 0, this simpliﬁes to
⌈maxsid
bpw
⌉
One machine word can represent values in the range 0 . . 2bpw −1. This
can also be written as {0 . . bpw −1} if log2 s, s ∈SID is used. Therefore, the
type
MWORD == {0 . . bpw −1}
is deﬁned.
The ﬁrst deﬁnition of the bitmap is:
BMASK == 0 . . msize −1 →MWORD
This can be interpreted as a vector of msize elements each of which is a set
of bits. It can be veriﬁed that the union of the domain elements of BMASK
covers all elements of SID.
An encoding is required for elements of SID. It is fairly obvious and that
integer division and mod are appropriate. Integer division will be written ÷.
Let bm : BMASK, so
s ∈semasinuse ⇔(s mod bpw) ∈bm(s ÷ bpw)
⇒{(s mod bpw)} ⊆bm(s ÷ bpw)
semasinuse ∪{s} ⇔{(s mod bpw)} ∪bm(s ÷ bpw)
semasinuse \ {s} ⇔bm(s ÷ bpw) \ {(s mod bpw)}
These equivalents are straightforward to verify. For example, the implication
on line two can be proved from the biconditional on line one using the fact
that x ∈X ⊆Y ⇒x ∈Y .

134
3 A Simple Kernel
We have deﬁned MWORD as {0 . . bpw −1}. This can be improved upon
with relative ease. First, consider the eﬀect of redeﬁning MWORD as 0 . .
bpw −1 and deﬁne a new type, BM , as:
BM : 0 . . bpw −1 →{0, 1}
This is the characteristic function of the membership function deﬁned for
SID. In particular, if f ∈BM (f : BM ), deﬁne x ∈dom f ⇔f (x) = 1 and
x ̸∈dom f ⇔f (x) = 0.
The following operations can be deﬁned. Note that BM has a ﬁxed ﬁnite
domain, so it is possible to iterate over it.
& : BM × BM →BM
∀f1, f2 : BM •
∃1 fr : BM | fr = f1&f2 •
∀i : 0 . . bpw −1 •
f1(i) = 1 ∧f2(i) = 1 ⇒fr(i) = 1 ∧
f1(i) ̸= 1 ∨f2(i) ̸= 1 ⇒fr(i) = 0
| : BM × BM →BM
∀f1, f2 : BM | fr = f1|f2 •
∃1 fr : BM •
∀i : 0 . . bpw −1 •
f1(i) = 1 ∨f2(i) = 1 ⇒fr(i) = 1 ∧
f1(i) = 0 ∧f2(i) = 0 ⇒fr(i) = 0
∼: BM →BM
∀f1 : BM •
∃1 fr : BM | fr =∼f1 •
∀i : 0 . . bpw −1 •
f1(i) = 1 ⇒fr(i) = 0 ∧
f1(i) = 0 ⇒fr(i) = 1
↑: BM × BM →BM
∀f1, f2 : BM •
∃1 fr : BM | fr = f1 ↑f2 •
∀i : 0 . . bpw −1 •
f1(i) = f2(i) ⇒fr(i) = 0 ∧
f1(i) ̸= f2(i) ⇒fr(i) = 1
In particular, it should be noted that x ∈X can be written as ({x}∩X )̸=∅.
This is the memebership test for bit maps, as a moment’s thought reveals.

3.8 Semaphore Table
135
Lemma 2. & represents set intersection. It is bitwise “and.”
Proof. Actually, quite easy given the deﬁnitions. If f1 and f2 are interpreted
as the characteristic function of ∈, the deﬁnition of ∩is readily retrieved.
Given two sets, X and Y , x ∈X ∩Y ⇔x ∈X ∧x ∈Y . 2
Lemma 3. | represents set union. It is bitwise “or.”
Proof. Again, taking f1 and f2 to be the characteristic function of ∈, the
function is immediately seen to deﬁne ∪: given two sets, X and Y , x ∈
X ∪Y ⇔(x ∈X ) ∨(x ∈Y ); if x ̸∈X ∧x ̸∈Y , it is not in X ∪Y . This is
equivalent to an expansion of the deﬁnition of |. 2
Lemma 4. ∼rerpesents set complementation. It is bitwise complement.
Proof. This is, again, easy to deduce. If x ∈X , x ̸∈∼X ; if x ̸∈∼X , x ∈X .
2
Lemma 5. ↑represents a form of set diﬀerence, speciﬁcally symmetric set
diﬀerence.
Proof. The easiest way to view this is with a Venn diagram from which it can
be deduced that X ↑Y = (X ∪Y )\(X ∩Y ), or X ↑Y = (X \Y )∪(Y \X ). This
is the symmetric set diﬀerence operator; it is also an exclusive-or operation.
2
These operations correspond to bit operations provided by languages like
C, C++ and Ada.
Note that the above construction can easily be generalised. The domain
SID upon which this construction is based can be replaced by any arbitrary
set, X , subject to the restrictions that (a) X is discrete, (b) X is bounded
above and below.
With these operations in place, a bit map type can be deﬁned for the
semaphore table type.
Now let us deﬁne a new type:
BITMAP = 0 . . msize −1 →BM
or, in expanded form:
BITMAP = 0 . . msize = 1 →(0 . . bpw −1 →{0, 1})
Let s be an arbitrary element of SID and let
w = s ÷ bpw
b = {s mod bpw →1} ⊕(λ i : 0 . . bpw −1 • 0)
In the identity expression deﬁning b, the λ expression deﬁnes a function whose
domain is 0. .bpw−1 and whose value is uniformly zero (i.e., if f is the function,
∀x : 0. .bpw −1 • ((λ i : 0. .bpw −1 • 0)x) = 0). The maplet {s mod bpw →1}
clearly has the value at s mod bpw: viz., {s mod bpw →1}(s mod bpw) = 1.

136
3 A Simple Kernel
Therefore, the composition of these two functions has the following behaviour.
Let the function {s mod bpw →1} ⊕(λ i : 0 . . bpw −1 • 0) be called f , then:
f (x) =

1, x = s mod bpw
0, otherwise
Now assume:
sinuse : BITMAP
We can write the following identities. Each identity is justiﬁed by one or more
of the lemmata above.
s ∈semasinuse ⇔sinuse(w) | b
semasinuse ∪{s} ⇔sinuse(w) | b
semasinuse \ {s} ⇔(∼sinuse(w) ↑b
The appropriate updates are as follows:
semasinuse′ = semasinuse ∪{s} ⇔
sinuse = sinuse ⊕{w →sinuse(w) & b}
semasinuse′ = semasinuse \ {s} ⇔
sinuse = sinuse ⊕{w →(∼sinuse(w)) ↑b}
Using this new structure, it is possible to deﬁne new schemata for the
semaphore table. These schemata will be given a a subscript for now (and the
state schema will be similarly annotated).
SemaInUsea
ΞST1a
s? : SID
sinuse(s? ÷ bpw) & ((λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1})
̸= ((λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1})
FreeSIDa
∆ST1a
s? : SID
∃w : 0 . . bpw −1; b : 0 . . bpw −1 →{0, 1} •
w = s? ÷ bpw ∧
b = (λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1} ∧
sinuse′ = sinuse ⊕{w →((∼sinuse(w)) ↑b)}
Using the one-point rule twice, the predicate becomes

3.8 Semaphore Table
137
sinuse′ =
sinuse ⊕{(s? ÷ bpw) →
((∼sinuse(s? ÷ bpw))
↑(λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1})}
AllocST1a
∆ST1a
s! : SID
∃s : SID •
(∃w : 0 . . bpw −1; b : 0 . . bpw −1 →{0, 1} •
w = s ÷ bpw ∧
b = (λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1} ∧
(sinuse(w) & b) ̸= b ∧
sinuse′ = sinuse ⊕{w →(sinuse(w) | b)} ∧
s! = s)
∃w : 0 . . bpw −1; b, bv : 0 . . bpw −1 →{0, 1} •
w = s! ÷ bpw ∧
bv = {s! mod bpw →1} ∧
b = (λ i : 0 . . bpw −1 • 0) ⊕bv ∧
(sinuse(w) & b) ̸= b ∧
sinuse′ = sinuse ⊕{w →(sinuse(w) | b)} ∧
s! = w + bv
where + is integer addition. The last line is jutiﬁed by the observation that
if b = s mod bpw and w = s ÷ bpw then w × b = s. This predicate can be
further simpliﬁed:
sinuse(s? ÷ bpw) & (λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1}
̸= (λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1}
sinuse′ =
sinuse ⊕{(s? ÷ bpw) →sinuse(s? ÷ bpw) |
(λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1}
s! = (s? ÷ bpw) × (s? mod bpw)
The argument preceding the deﬁnition of these schemata amounts to their
reﬁnement proof.
The speciﬁcation at this level can therefore be completed as follows.
SID == minsid . . maxsid
minsid, maxsid : N1
minsid < maxsid

138
3 A Simple Kernel
msize : N1
bpw : N1
The semaphore table is now deﬁned by the following schema:
ST1
semas1 : SID →SEMAPHORE
sinuse : BITMAP
The initialisation operation is given by the next schema.
ST1Init
ST1′
∀w : 0 . . msize −1 •
∀b : 0 . . bpw −1 →{0, 1} •
sinuse′(w)(b) = 0
The next schema deﬁnes the operation to initialise a semaphore once its
identiﬁer, s?, has been allocated.
InitSema1
∆ST1
s? : SID
semas1′ = semas1 ⊕{s? →θSEMAPHOREInit}
The deallocation operation is given by
FreeSID1 = FreeSIDa
and the allocation operation by
AllocSID1 = AllocST1a
The operation to allocate a new semaphore identiﬁer and to initialise the
semaphore is deﬁned as
AllocSema1 =
(AllocSID1 ∧InitSema[s!/s?] ∧SysOk)
∨NoFreeSema
The operation that performs the required checks when freeing a semaphore is
the following
ReleaseSema1 =
(SemaInUse1 ∧FreeSID1 ∧SysOk) ∨NotAllocSema

3.8 Semaphore Table
139
We now deﬁne the abstraction relation
AbsST1
SEMATBL
ST1
∀s : SID •
s ∈semasinuse ⇔semas(s) = semas1(s)
∀s : SID •
s ∈semasinuse ⇔
(∃w : 0 . . msize −1; b : 0 . . bpw −1 →{0, 1} •
sinuse(w)(b) = 1)
Theorem 40. ∀SEMATBL′; ST1′ • SEMATBLInit ∧AbsST1 ⇒ST1Init
Proof. The predicate of SEMATBLInit is semasinuse′ = ∅. By the abstrac-
tion relation,
∀s : SID •
s ̸∈semasinuse ⇔
̸ (∃w : 0 . . msize −1; b : 0 . . bpw −1 →{0, 1} •
sinuse(w)(b) = 1)
The predicate of ST1Init is
∀w : 0 . . msize −1; b : 0 . . bpw −1 →{0, 1} •
sinuse(w)(b) = 0
By predicate calculus (¬ ∃x • P(x) ⇔¬ ¬ ∀x • ¬ P(x) ⇔∀x • ¬ P(x))
the two are equivalent. 2
Theorem 41.
∀SEMATBL; ST1 •
pre AllocSema ∧AbsST1 ⇒pre AllocSema1
Proof. The two preconditions are
pre AllocSema = s ̸∈semasinuse
and
pre AllocSema1 = sinuse(s ÷ bpw)(s mod bpw) = 0
First note that
((λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1})(x) =

1, x = s
0, otherwise

140
3 A Simple Kernel
By the deﬁnition of &, it is evident that
sinuse(s ÷ bpw)&(λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1}
̸= (λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1}
when sinuse(s ÷bpw)(b mod bpw) = 0. By the above deﬁntiions, this is equiv-
alent to s ̸∈semasinuse. 2
Theorem 42.
∀SEMATBL; SEMATBL′; ST1; ST1′; s! : SID •
pre AllocSema ∧
AbsST1 ∧
AbsST1′ ∧
AllocSema1
⇒AllocSema
Proof. The important part of predicate of AllocSema1 is
sinuse′ = sinuse ⊕{w →(sinuse(w) | b)}
where w = s ÷ bpw and b = s mod bpw. Expanding the right-hand side, the
following is obtained
sinuse′
= sinuse⊕
{w →(sinuse(s ÷ bpw)
|(λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1})
It should be noted that ((λ i : 0. .bpw −1 • 0)⊕{s mod bpw →1}))(x) = 1 if
x = s mod bpw, so sinuse(w)(b) = 1 iﬀs = w +b. From this, it can be inferred
that sinuse′(w)(b) = 1, i.e., s? ∈semasinuse′ by the abstraction relation. 2
Theorem 43. ∀SEMATBL; ST1; s? : SID • pre ReleaseSema ∧AbsST1 ⇒
pre ReleaseSema1.
Proof. In this case, we have
sinuse(s? ÷ bpw)&(λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1}
= (λ i : 0 . . bpw −1 • 0) ⊕{s? mod bpw →1}
For this to be true, sinuse(s? ÷ bpw)(s? mod bpw) = 1, so s ∈semasinuse by
the abstraction relation. 2
Theorem 44.
∀SEMATBL; SEMATBL′; ST1; ST1′; s? : SID; serr! : SYSERR •
pre ReleaseSema ∧
AbsST1 ∧
AbsST1′ ∧
ReleaseSema1
⇒ReleaseSema

3.9 Synchronous Messages
141
Proof. This is the dual of AllocSema.
Let w = s? ÷ bpw and v = s? mod bpw.
The interesting part is w →(∼sinusew(w)) ↑b. By the deﬁnition of ∼,
and thinking pointwise,
∼sinuse(w)(v) =

0, sinuse(w)(v) = 1,
1, otherwise
That is, ∼complements sinuse(w)’s elements.
Now, let b = (λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1}, noting that
((λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1})(s mod bpw) = 1), it should be
clear that
∼sinuse(w) ↑(λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1}
=

0, if ∼sinuse(w)(s mod bpw) = 1
1, otherwise
Therefore, if sinuse(w)(v) = 1, sinuse′(w)(v) = 0 for the important part of
the predicate of ReleaseSema1 is
sinuse′ = sinuse ⊕{w →((∼sinuse(w) ↑b)}
Writing out the interesting part, we have
∼sinuse(w) ↑(λ i : 0 . . bpw −1 • 0) ⊕{s mod bpw →1}
=

0, if ∼sinuse(w)(s mod bpw) = 1
1, otherwise
By AbsST1′,
∀s : SID •
s ∈semasinuse′ ⇔
(∃w : 0 . . msize −1; b : 0 . . bpw −1 →{0, 1} •
sinuse′(w)(b) = 1)
it can be seen that the above expression is equivalent to semasinuse \ {s?}
which is equivalent, by FreeSIDa’s predicate, to semasinuse′. 2
The schemata derived in this subsection can now be translated into exe-
cutable code. The code will employ a bitmask to represent those slots in the
table that are in use.
3.9 Synchronous Messages
This section is concerned with the speciﬁcation and reﬁnement of the synchro-
nous message-passing subsystem in the kernel. Message passing is used as the
primary means for processes to exchange information while using semaphores
as a synchronisation mechanism.

142
3 A Simple Kernel
3.9.1 Preliminaries
First, a few deﬁnitions are required. In particular, it is necessary to deﬁne a
type to represent the data held by messages. The type representing messages,
MSG, was deﬁned at the start of this chapter, as was the constant nullmsg.
[MDATA]
Using this new type, the type of messages, MSG, can be deﬁned.
MSG = PID × PID × MDATA
In addition, a constructor function is useful, so one is deﬁned
mkmsg : PID × PID × MDATA
∀s, t : PID; d : MDATA •
mkmsg(s, t, d) = (s, (t, d))
Furthermore, some functions to access the components of a message are
needed. In particular, functions to access the sender’s and destination’s iden-
tiﬁers is required; a function to return the data held in a message is required.
msgsrc, msgdest : MSG →PID
msgdata : MSG →MDATA
∀m : MSG •
msgsrc(m) = fst m
msgdest(m) = fst(snd m)
msgdata(m) = snd 2 m
Just to make schema deﬁnition and manipulation a little easier, the fol-
lowing schema is deﬁned. It just creates a new message and returns it as m.
MakeMessage
sndr?, dest? : PID
payload? : MDATA
m : MSG
m = mkmsg(sndr?, dest?, payload?)
The error schemata now follow. The names for these schemata are intended
to be suggestive as to their functions.
AlreadyHasMsg
serr! : SYSERR
serr! = procalreadyhasmsg

3.9 Synchronous Messages
143
DestinationNotReceiving
serr! : SYSERR
serr! = destinationnotrcving
BadDestination
serr! : SYSERR
serr! = badmsgdestination
NullMsgValue
serr! : SYSERR
serr! = nomsg
The two following operations are added to PTAB:
SourceExists
ΞPTAB
src? : PID
src? ∈used
and
DestinationExists
ΞPTAB
dest? : PID
dest? ∈used
3.9.2 Top Level
The top-level speciﬁcation can now be started.
The process table, PTAB, is also extended by the addition of a new state
variable:

144
3 A Simple Kernel
PTAB
...
smsg : PID →MSG
...
...
dom smsg = dom prio
...
The mapping, smsg, maps process identiﬁers to messages, including, of course,
the nullmsg. Each process maps to exactly one message. The idea is that each
process should have at most one message available to it at any one time.
The initialisation schema is implicit and can be inferred from that of
PTAB.
GotSynchMsg
ΞPTAB
p? : PID
smsg(p?) ̸= nullmsg
A sending process can send a message (attach it to the smsg slot) only
when the destination has no message in smsg. In other words, if d is the
destination, then a sender, s, can tell that d can be passed a message when
smsg(d) = nullmsg. This justiﬁes the deﬁnition
CanSendSynchMsg = ¬ GotSynchMsg
which expands into:
ΞPTAB
p? : PID
smsg(p?) = nullmsg
The actual operation of sending a synchronous message is considered to
be assigning the destination’s smsg to the message. In symbols:
SendSynchMsg
∆PTAB
dest? : PID
m? : MSG
smsg′ = smsg ⊕{dest? →m?}

3.9 Synchronous Messages
145
When a process receives a message, it should copy the contents of the
message to some place and to set smsg to nullmsg.
ClrSynchMsgSlot
∆PTAB
p? : PID
smsg′ = smsg ⊕{p? →nullmsg}
Receiving proper is considered to be the act of removing the latest message
from smsg. The next schema puts this into symbols.
ReceiveSMsg
ΞPTAB
p? : PID
m! : MSG
m! = smsg(p?)
Ideally, when one process is to send a message to another, it should check
the state that the destination is in. If the destination is in the psreceiving
state, the message can be sent. This is captured by the following deﬁnition.
IsDestinationReceiving =
∃st : PSTATE | st = psreceiving •
ProcState[st/st!]
This deﬁnition expands into:
IsDestinationReceiving
ΞPTABS
p? : PID
state(p?) = psreceiving
Conversely, when a process wants to receive a message, it should enter the
psreceiving state. The following deﬁnes this operation.
MakeReceiver =
∃st : PSTATE | st = psreceiving •
SetProcState[st/st?]
The schema that results by expansion is the following.
MakeReceiver
∆PTABS
p? : PID
state′ = state ⊕{p? →psreceiving}

146
3 A Simple Kernel
Similarly, if a process wants to send a message, it should enter the
pssending state. It might have to wait in this state before it can actually
send the message.
MakeSender =
∃st : PSTATE | st = pssending •
SetProcState[st/st?]
This deﬁnition expands to form the following schema:
MakeSender
∆PTAB
p? : PID
state′ = state ⊕{p? →pssending}
The complete operation to send a synchronous message is deﬁned thus:
SendASynchMsg =
(DestinationExists ∧
((IsDestinationReceiver[dest?/p?] ∧
((¬ GotSynchMsg[dest?/p?] ∧
SendSynchMsg ∧
MakeSender
o
9(MakeReady[dest?/p?] o
9 SchedNext) ∧
SysOk)
∨AlreadyHasMsg))
∨DestinationNotReceiving))
∨BadDestination
The basic idea is that the destination must be a process that is currently in the
system and must be in the receiving state but not have a message assigned to
it by smsg. If this is the case, the sender places the message in smsg and sets
its state to pssending. It then places the destination on the scheduler’s ready
queue and calls SchedNext so that a reschedule is performed. The remainder
of the operations just set serr! appropriately, depending upon the condition
being reported.
This operation contains a reschedule at is core. This will lead to an inter-
esting argument when simplifying this deﬁnition.
We now need to expand and simplify this deﬁnition. This will be done in
pieces.
The composition (MakeReady[dest?/p?] o
9 SchedNext) must be calculated
and simpliﬁed.

3.9 Synchronous Messages
147
SchedNext =
(IsCurrentProcessIdle ∧
((IsEmptySCHEDQ ∧ContinueCurrent)
∨(SCHEDQDequeue[p/p!] ∧SetNewCurrentProcess[p/p?]
o
9CTXTSW ) \ {p}))
∨(IsEmptySCHEDQ ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨((¬ CurrentProcessStateIsReadyOrRunning
∨QueueHdHasHigherPriority) ∧
(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧
SetNewCurrentProcess[hpid/p?] o
9 CTXTSW ) \ {hpid})
∨ContinueCurrent
We know a priori that the current process is not idle (for otherwise, how
could this call have been made?), the ﬁrst disjunct can be omitted. Equally,
we know that the ready queue (pq) cannot be empty if the ﬁrst component of
the composition MakeReady[dest?/p?] o
9 SchedNext succeeds. This permits us
to remove the disjunct IsEmptySCHEDQ ∧MakeIdleProcessCurrent. We are
left, therefore, with
∨((¬ CurrentProcessStateIsReadyOrRunning
∨QueueHdHasHigherPriority) ∧
(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧
SetNewCurrentProcess[hpid/p?] o
9 CTXTSW ) \ {hpid})
∨ContinueCurrent
The state of curr is pssending when SchedNext is executed, so it is obvious that
¬ CurrentProcessStateIsReadyOrRunning is satisﬁed. To see this, consider
¬ CurrentProcessStateIsReadyOrRunning
⇔state(curr) ̸= psready ∧state(curr) ̸= psrunning
We have state(curr) = pssending, so, given the last equivalence, we have
state(curr) ̸= psready ∧state(curr) ̸= psrunning ∧state(curr) = pssending
which is true, so the disjunction
¬ CurrentProcessStateIsReadyOrRunning ∨QueueHdHasHigherPriority)
is satisﬁed; this permits MakeReady[dest?/p?] o
9 SchedNext to be simpliﬁed to
MakeReady[dest?/p?]
o
9(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧SetNewCurrentProcess[hpid/p?] o
9 CTXTSW ) \ {hpid}
Noting that o
9CTXTSW can be simpliﬁed to ∧CTXTSW because it does not
aﬀect any variables that occur in the rest of the schema, this composition now
expands into

148
3 A Simple Kernel
MakeReady
o
9
(∃hpid : PID •
hpid = head sq.pq′′ ∧
sq.pq′ = tail sq.pq′′ ∧
curr ′ = hpid ∧prev ′ = curr ∧
CTXTSW )
and the existential simpliﬁes to
MakeReady
o
9
(curr ′ = head sq.pq′′ ∧prev ′ = curr ∧sq.pq′ = tail sq.pq′′ ∧CTXTSW )
This composition simpliﬁes to the following predicate:
(#sq.pq < maxs ∧
((sq.pq = ⟨⟩∧
∧curr ′ = dest? ∧prev ′ = curr ′′ ∧sq.pq′ = ⟨⟩∧CTXTSW ) ∨
(prio(dest?) ≤prio(head sq.pq) ∧
curr ′ = dest? ∧prev ′ = curr ∧CTXTSW ) ∨
(prio(last sq.pq) < prio(dest?)
∧curr ′ = head sq.pq′′ ∧prev ′ = curr ∧
sq.pq′ = (tail sq.pq) ⌢⟨dest?⟩∧CTXTSW ) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(dest?) ∧
prio(dest?) ≤prio(head s2) ∧
sq.pq′ = (tail s1) ⌢⟨dest?⟩⌢s2)) ∧
state′ = state ⊕{dest? →psready} ∧
curr ′ = head s1 ∧prev ′ = curr ∧
CTXTSW ∧
serr! = sysok)
∨serr! = schedqfull
The complete expansion of SendASynchMsg is
SendASynchMsg
∆PTAB
∆SCHED
dest? : PID
m? : MSG
serr! : SYSERR
∃state′′ : PID →PSTATE •
(dest? ∈used ∧
((state(dest?) = psreceiving ∧
((smsg(dest?) = nullmsg ∧
smsg′ = smsg ⊕{dest? →m?} ∧

3.9 Synchronous Messages
149
state′′ = state ⊕{p? →pssending} ∧
(#sq.pq < maxs ∧
((sq.pq = ⟨⟩∧
∧curr ′ = dest? ∧prev ′ = curr ′′ ∧sq.pq′ = ⟨⟩
∧CTXTSW ) ∨
(prio(dest?) ≤prio(head sq.pq) ∧
curr ′ = dest? ∧prev ′ = curr ∧CTXTSW ) ∨
(prio(last sq.pq) < prio(dest?)
∧curr ′ = head sq.pq′′ ∧prev ′ = curr ∧
sq.pq′ = (tail sq.pq) ⌢⟨dest?⟩∧CTXTSW )
∨(∃s1, s2 : seq PID |
s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(dest?) ∧
prio(dest?) ≤prio(head s2) ∧
sq.pq′ = (tail s1) ⌢⟨dest?⟩⌢s2)) ∧
state′ = state ⊕{dest? →psready} ∧
curr ′ = head s1 ∧prev ′ = curr ∧
CTXTSW ∧
serr! = sysok)
∨serr! = schedqfull
serr! = sysok)
serr! = procalreadyhasmsg))
serr! = destinationnotrcving))
∨serr! = badmsgdestination
It is easy to see how this can be re-arranged as follows
SendASynchMsg
∆PTAB
∆SCHED
dest? : PID
m? : MSG
serr! : SYSERR
(dest? ∈used ∧
((state(dest?) = psreceiving ∧
((smsg(dest?) = nullmsg ∧
((sq.pq = ⟨⟩∧curr ′ = dest? ∧
state′ = state ⊕{p? →pssending, dest? →psrunning})
∨((#sq.pq < maxs ∧
∨(prio(dest?) ≤prio(head sq.pq) ∧curr ′ = dest? ∧
state′ = state ⊕{p? →pssending, dest? →psrunning})

150
3 A Simple Kernel
∨(prio(last sq.pq) < prio(dest?) ∧
curr ′ = head sq.pq ∧
sq.pq′ = (tail sq.pq) ⌢⟨dest?⟩∧
state′ = state ⊕{p? →pssending, dest? →psready})
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(dest?) ∧
prio(dest?) ≤prio(head s2) ∧
sq.pq′ = (tail s1) ⌢⟨dest?⟩⌢s2 ∧
curr ′ = head s1) ∧
prev ′ = curr ∧
CTXTSW ∧
serr! = sysok)
∨serr! = schedqfull))
∨serr! = procalreadyhasmsg))
∨serr! = destinationnotrcving))
∨ser! = badmsgdestination)
The precondition can now be seen to be
pre SendASynchMsg =
dest? ∈used ∧
state(dest?) = psreceiving
However, dest? ∈used is an implicit precondition provided by PTAB’s invari-
ant. It can, if required, be omitted.
We now turn our attention to the top-level message reception operation.
First, we deﬁne a simple operation that actually receives a message.
RcvSynchMsg =
(GotSynchMsg ∧ReceiveMsg ∧ClrSynchMsgSlot ∧SysOk)
∨NullMsgValue
The deﬁnition expands into
RcvSynchMsg
∆PTAB
p? : PID
m! : MSG
(smsg(p?) ̸= nullmsg ∧
m! = smsg(p?) ∧
smsg′ = smsg ⊕{p? →nullmsg} ∧
serr! = sysok)
∨m! = nullmsg

3.9 Synchronous Messages
151
Next, the full top-level operation is deﬁned. This operation, like the send-
message operation, includes a reschedule. The presence of the reschedule (i.e.,
the SchedNext schema) complicates the expansion of the operation, just as it
did for the send-message operation.
ReceiveSynchMsg =
MakeReceiver
o
9SchedNext
o
9(RcvSynchMsg ∧
((IsSysOk ∧
(∃s : PID | s = msgsrc(m!) •
MakeReady[s/p?]) ∧
SysOk)
∨NullMsgValue)
The deﬁnition expands into
ReceiveSynchMsg
∆SCHED
∆PTAB
m! : MSG
serr! : SYSERR
∃state′′ : PID →PSTATE; sq.pq′′ : seq PID •
state′′ = state ⊕{p? →psreceiving}
o
9
(curr = iprc ∧
((sq.pq′′ = ⟨⟩∧curr ′ = curr ∧prev ′ = prev)
∨(curr ′ = head sq.pq ∧prev ′ = curr o
9 CTXTSW )))
∨(sq.pq = ⟨⟩∧prev ′ = curr ∧curr ′ = iprc o
9 CTXTSW )
∨((state(curr) ̸= psready ∧state(curr) ̸= psrunning
∨prio(head sq.pq) < prio(curr)) ∧
sq.pq′′ = tail sq.pq ∧
curr ′ = head sq.pq ∧
prev ′ = curr
o
9CTXTSW )
∨(curr ′ = curr ∧prev ′ = prev)o
9
((smsg(p?) ̸= nullmsg ∧
m! = smsg(p?) ∧
smsg′ = smsg ⊕{p? →nullmsg} ∧
serr! = sysok)
∨(m! = nullmsg ∧serr! = nomsg))

152
3 A Simple Kernel
∧serr! = sysok
∧∃s : PID | s = msgsrc(m!) •
state′ = state′′ ⊕{s →psready} ∧
(#sq.pq < maxs ∧
((sq.pq′′ = ⟨⟩∧sq.pq′ = ⟨s⟩) ∨
(prio(s) ≤prio(head sq.pq′′) ∧sq.pq′ = ⟨s⟩⌢sq.pq′′) ∨
(prio(last sq.pq′′) < prio(s) ∧sq.pq′ = sq.pq′′ ⌢⟨s⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq′′ •
prio(last s1) < prio(s) ∧
prio(s) ≤prio(head s2) ∧
sq.pq′ = s1 ⌢⟨s⟩⌢s2)) ∧
serr! = sysok)
∨serr! = schedqfull
∧serr! = sysok ∨serr! = nomsg
We now turn to the simpliﬁcation of this schema.
It should be clear that the caller, p?, is always the current process, curr,
so curr = p?. It is also clear that state(curr) = psrunning. However, it is not
known a priori whether the scheduler’s ready queue is empty or not. Given
that the predicate can be written as
state′′ = state ⊕{p? →psreceiving}
o
9SchedNext
o
9(((smsg(p?) ̸= nullmsg ∧
m! = smsg(p?) ∧
smsg′ = smsg ⊕{p? →nullmsg} ∧
serr! = sysok)
∨serr! = nomsg ∧m! = nullmsg)
∧((serr! = sysok ∧
(∃s : PID | s = msgsrc(p?) • MakeReady[s/p?]) ∧
serr! = sysok)
∨serr! = nomsg)
Since it is known that the current process is not the idle process, the ﬁrst
disjunct of SchedNext can be omitted, leaving
(IsEmptySCHEDQ ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨((¬ CurrentProcessStateIsReadyOrRunning
∨QueueHdHasHigherPriority) ∧
(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧
SetNewCurrentProcess[hpid/p?]
o
9CTXTSW ) \ {hpid})
∨ContinueCurrent

3.9 Synchronous Messages
153
When the message-receiving operation is called, the state of curr must be
psrunning and CurrentProcessStateIsReadyOrRunning is deﬁned as
state(curr) = psready ∨state(curr) = psrunning
so ¬ CurrentProcessStateIsReadyOrRunning is
state(curr) ̸= psready ∧state(curr) ̸= psrunning
so the current process’ state satisﬁes this condition, so the remaining guard
need not be attempted.
The predicate of SchedNext can now be simpliﬁed to
(IsEmptySCHEDQ ∧MakeIdleProcessCurrent o
9 CTXTSW )
∨(SCHEDQHd[hpid/p!] ∧
SCHEDQDelHd ∧
SetNewCurrentProcess[hpid/p?] o
9 CTXTSW ) \ {hpid}
It can be further simpliﬁed: the update of prev can be factored out using
(p ∧q) ∨(r ∧q) ⇒(p ∨r) ∧q to yield
(((sq.pq = ⟨⟩∧curr ′ = iprc)
∨(sq.pq′′ = tail sq.pq ∧
curr ′′ = head pq)) ∧
prev ′′ = curr ∧
CTXTSW )
The sequential composition of CTXTSW can be reduced to conjunction, as
noted many times above, and can also be moved to the end. The movement
can be justiﬁed by the same theorem as above. Note that this predicate is
part of a sequential composition, so its after-state must be doubly primed.
The existential ∃s : PID | s = msgsrc(m!) • MakeReady[s/p?] simpliﬁes
as follows. First, the existential formula expands into the following. (It must
be remembered that the before state of this schema is the intermediate state
of a sequential composition.)
MakeReady[s/p?]
∆PRIOQ
p? : PID
serr! : SYSERR
state′ = state ⊕{s →psready}
(#sq.pq′′ < maxs ∧
((sq.pq′′ = ⟨⟩∧sq.pq′ = ⟨s⟩) ∨
(prio(s) ≤prio(head sq.pq′′) ∧sq.pq′ = ⟨s⟩⌢sq.pq′′) ∨
(prio(last sq.pq′′) < prio(s) ∧sq.pq′ = sq.pq′′ ⌢⟨s⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq′′ •
prio(last s1) < prio(s) ∧
prio(s) ≤prio(head s2) ∧

154
3 A Simple Kernel
sq.pq′ = s1 ⌢⟨s⟩⌢s2)) ∧
serr! = sysok)
∨serr! = schedqfull
Using the one-point rule to substitute msgsrc(m!) for s, the predicate becomes
state′ = state ⊕{msgsrc(m!) →psready}
(#sq.pq′′ < maxs ∧
((sq.pq′′ = ⟨⟩∧sq.pq′ = ⟨msgsrc(m!)⟩) ∨
(prio(msgsrc(m!)) ≤prio(head sq.pq′′) ∧
sq.pq′ = ⟨msgsrc(m!)⟩⌢sq.pq′′) ∨
(prio(last sq.pq′′) < prio(msgsrc(m!)) ∧
sq.pq′ = sq.pq′′ ⌢⟨msgsrc(m!)⟩)
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq′′ •
prio(last s1) < prio(msgsrc(m!)) ∧
prio(msgsrc(m!)) ≤prio(head s2) ∧
sq.pq′ = s1 ⌢⟨msgsrc(m!)⟩⌢s2)) ∧
serr! = sysok)
∨serr! = schedqfull
The ReceiveSynchMsg operation can now be considerably simpliﬁed. This
yields the following schema:
ReceiveSynchMsg
∆SCHED
∆PTAB
m! : MSG
serr! : SYSERR
((smsg(curr) ̸= nullmsg ∧
m! = smsg(curr) ∧
smsg′ = smsg ⊕{curr →nullmsg} ∧
state′ = (state ⊕{curr →psreceiving}) ⊕{msgsrc(m!) →psready} ∧
((sq.pq = ⟨⟩∧curr ′ = iprc ∧sq.pq′ = ⟨msgsrc(m!)⟩∧CTXTSW )
∨[(#sq.pq ≤maxs ∧
(curr ′ = head sq.pq ∧
prev ′ = curr ∧
((prio(msgsrc(m!)) ≤prio(head tail sq.pq) ∧
sq.pq′ = ⟨msgsrc(m!)⟩⌢tail sq.pq)
∨(prio(last sq.pq) < prio(msgsrc(m!)) ∧
sq.pq′ = tail sq.pq ⌢⟨msgsrc(m!)⟩)
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(msgsrc(m!)) ∧
prio(msgsrc(m!)) ≤prio(head s2) ∧
s1 ⌢⟨msgsrc(m!)⟩⌢s2 = sq.pq′)) ∧

3.9 Synchronous Messages
155
CTXTSW ∧
serr! = sysok))
∨serr! = schedqfull]))
∨serr! = nomsg
The precondition is immediately
pre ReceiveSynchMsg =
smsg(p?) ̸= nullmsg
To justify this, it is noted that the ﬁrst disjunct simpliﬁes to smsg(curr) ̸=
nullmsg. Similarly, sq.sq.pq = ⟨⟩∧curr ′ = iprc ∧sq.pq′ = ⟨msgsrc(m!)⟩∧
CTXTSW simpliﬁes to sq.sq.pq = ⟨⟩∧true ∧true ∧intno′ = context switch,
so it ﬁnally reduces to sq.sq.pq = ⟨⟩. Given this, the remainder of the simpli-
ﬁcation is as follows:
smsg(p?) ̸= nullmsg ∧sq.pq = ⟨⟩
∨(#sq.pq ≤maxs ∧
(prio(msgsrc(m!)) ≤prio(head tail sq.pq)
∨prio(last sq.pq) < prio(msgsrc(m!))
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(msgsrc(m!)) ∧
prio(msgsrc(m!)) ≤prio(head s2))))
Now, from
(prio(msgsrc(m!)) ≤prio(head tail sq.pq)
∨(prio(last sq.pq) < prio(msgsrc(m!)))
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(msgsrc(m!)) ∧
prio(msgsrc(m!)) ≤prio(head s2)
it can be inferred that prio(msgsrc(m!)) ∈PPRIO. This is true, so all that
remains is
smsg(p?) ̸= nullmsg ∧sq.pq = ⟨⟩∨#sq.pq ≤maxs
The disjunction sq.pq = ⟨⟩∧#sq.pq ≤maxs imply sq.pq = ⟨⟩∨sq.pq ̸= ⟨⟩,
so we are left with smsg(p?) ̸= nullmsg, which is our precondition.
3.9.3 Reﬁnement One
This is the ﬁrst of two reﬁnments. It is concerned with the reﬁnement of the
scheduler’s structures and the process table. The second reﬁnement concerns
the reﬁnement of PTAB1 to PTAB2.

156
3 A Simple Kernel
In a sense, all reﬁnements are trivial because, once more, the abstration
relation is a set of identities. Furthermore, the operations in this section are
deﬁned in terms of promotions that are embedded in operations over PTAB.
However, we present the reﬁnement (making use of promotion and of the
existing reﬁnements of PTAB) just to convince ourselves that the reﬁnement
really does work and in an attempt to convince the reader of the correctness
of the development.
The contents of this subsection mirror that of the last. For this reason, we
will not comment as much.
DestinationExists1
ΞPTAB1
dest? : PID
dest? ̸∈dom freech
MakeReceiver1 =
∃st : PSTATE | st = psreceiving •
SetProcState1[st/st?]
MakeSender1 =
∃st : PSTATE | st = pssending •
SetProcState1[st/st?]
IsDestinationReceiving1
ΞPTAB1
p? : PID
state1(p?) = psreceiving
GotSynchMsg1
ΞPTAB1
p? : PID
smsg1(p?) ̸= nullmsg
ClrSynchMsgSlot1
∆PTAB1
p? : PID
smsg1′ = smgs1 ⊕{p? →nullmsg}

3.9 Synchronous Messages
157
Partly out of interest and partly to see whether any simpliﬁcations can be
performed (which they can), the major operations are fully expanded (and
simpliﬁed). However, as noted above, there is little that can usefully be done
in the reﬁnement process for reasons given above.
SendASynchMsg1 =
(DestinationExists1 ∧
((IsDestinationReceiver1[dest?/p?] ∧
((¬ GotSynchMsg1[dest?/p?] ∧
SendSynchMsg1 ∧
MakeSender1
o
9(MakeReady[dest?/p?] o
9 SchedNext) ∧
SysOk)
∨AlreadyHasMsg))
∨DestinationNotReceiving))
∨BadDestination
Immediately, we are in a position to prove the following theorems. The
proofs are quite straightforward but are omitted because of their length.
Theorem 45.
∀PTAB; PTAB1; SCHED; dest? : PID; m? : MSG •
pre SendASynchMsg ∧AbsPTAB1 ⇒pre SendASynchMsg1
Proof. Omitted. 2
Theorem 46.
∀PTAB; PTAB ′; PTAB1; PTAB1′; SCHED;
dest? : PID; m? : MSG; serr! : SYSERR •
pre SendASynchMsg
∧AbsPTAB1
∧AbsPRIOQ1
∧SendASynchMsg1
⇒SendASyncMsg1
Proof. Omitted. 2
The ﬁrst-level reﬁnement of the receive operation is deﬁned as:
ReceiveSynchMsg =
MakeReceiver1
o
9SchedNext
o
9(RcvSynchMsg1 ∧
((IsSysOk ∧
(∃s : PID | s = msgsrc(m!) •
MakeReady[s/p?]) ∧
SysOk)
∨NullMsgValue)

158
3 A Simple Kernel
3.9.4 Reﬁnement Two
The second-level reﬁnements can be derived with ease.
SendASynchMsg2 =
(DestinationExists2 ∧
((IsDestinationReceiver2[dest?/p?] ∧
((¬ GotSynchMsg1[dest?/p?] ∧
SendSynchMsg1 ∧
MakeSender2
o
9(MakeReady[dest?/p?] o
9 SchedNext) ∧
SysOk)
∨AlreadyHasMsg))
∨DestinationNotReceiving))
∨BadDestination
and
ReceiveSynchMsg2 =
MakeReceiver2
o
9SchedNext
o
9(RcvSynchMsg2 ∧
((IsSysOk ∧
(∃s : PID | s = msgsrc(m!) •
MakeReady[s/p?]) ∧
SysOk)
∨NullMsgValue)
Although it is not entirely clear from the schemata in this section, the
constructs derived here can now be translated directly into executable code.
The reason that matters are not clear is that the operations are deﬁned in
terms of a mixture of existing schemata (e.g., the scheduler and the process
table) and new ones. However, the claim that an implementation is the next
step can be readily veriﬁed.
3.10 The Clock
This section contains the speciﬁcation of the real-time clock. The clock is used
by processes to determine the current time. It is also used to determine how
long processes have slept and when to wake them.
The time between clock ticks is denoted by the following constant
ticklength : TIME
On some machines, this will be 100ms, on others it will be another value.

3.10 The Clock
159
The error schema is the following. It denotes the fact that a process is
requesting a 0 sleep time.
SleepTooShort
err! : SYSERR
err! = sleeptimetooshort
This is the basic clock. It just contains the time since the system was
booted in multiples of ticklength seconds.
TIMESINCEBOOT
tnow : TIME
Clearly, when the system starts, the time is 0.
TIMESINCEBOOTInit
TIMESINCEBOOT ′
tnow ′ = 0
The clock is updated every time the hardware clock interrupts the proces-
sor. The hardware clock interrupts every ticklength seconds, so on every
interrupt, the software clock is updated as follows.
UpdateTIMESINCEBOOT
∆TIMESINCEBOOT
tnow ′ = tnow + ticklength
To ﬁnd out what the current time is, the following schema is used:
TimeNow
ΞTIMESINCEBOOT
tn! : TIME
tn! = tnow
tickspersec : N
Unfortunately, people want the time in seconds, minutes and hours. The
following schema deﬁnes the variables used to record the time in human-
oriented units.
CLOCKTIME
secs, mins, hrs : TIME
0 ≤secs < 60
0 ≤mins < 60

160
3 A Simple Kernel
Note that the invariant merely states the moduli for seconds and minutes.
We consider it unnecessary to include days; they could be added, should the
reader wish.
The clock time is initialised in the obvious manner.
CLOCKTIMEInit
CLOCKTIME ′
secs′ = 0
mins′ = 0
hrs′ = 0
On every hardware interrupt, the time since boot is incremented. At the
same time, the human-readable time is also updated when there have been
enough interrupts since the last one. This is the purpose of tickspersec—after
tickspersec interrupts, the seconds counter is incremented by one, possibly
causing the other counters to be updated.
UpdateClockTime
∆CLOCKTIME
t? : TIME
((t? mod tickspersec = 0) ∧
((secs + 1 mod 60 = 0 ∧
secs′ = 0 ∧
((mins + 1 mod 60 = 0 ∧
mins′ = 0 ∧
hrs′ = hrs + 1)
∨mins′ = mins + 1))
∨secs′ = secs + 1))
To ﬁnd out what the human-readable time is since boot, use the following
operation:
ClocktimeNow
ΞCLOCKTIME
s!, m!, h! : TIME
s! = secs
m! = mins
h! = hrs
It is now necessary to consider the operations required by the sleep timer.
When a process requests a period of sleep, it also speciﬁes the period
through which it will sleep. The period is speciﬁed in seconds and is added to
the current time to produce the time at which the process is to be awakened.
This is what the following schema does. The variable tn? denotes the time

3.11 Sleepers
161
now, stm? is the length to time the process wants to remain asleep and cst!
is the computed sleep time—i.e., the time at which the process should be
returned to the ready queue. The time is expressed in seconds since boot.
CorrectWakeTime
tn?TIME
stm? : TIME
cst! : TIME
stm? + tn? = cst!
The above operation requires the current time (in units since boot time)
and the following composition deﬁnes the required operation:
ComputeWakeTime =
(TimeNow[tn/tn!] ∧CorrectWakeTime[tn/tn?]) \ {tn}
This expands and simpliﬁes into:
ComputeWakeTime
ΞTIMESINCEBOOT
stm? : TIME
cst! : TIME
stm? + tnow = cst!
The schemata deﬁned in this section can be translated directly into
executable code. In the present case, there is no reﬁnement because the state
schema contains only simple variables.
3.11 Sleepers
We need a conception of time. For the purposes of this speciﬁcation, the
following suﬃces:
TIME = N
(It was deﬁned at the start of this chapter.)
We also need an extension of PTAB:
PTAB
PTAB
...
wakingtime : PID →TIME
...

162
3 A Simple Kernel
...
dom wakingtime = dom prio
...
The reader is reminded of the convention that a process without a waking
time has a zero as the value of wakingtime. That is, if p is a process that is
not sleeping, waketime(p) = 0.
The wakingtime function must be reﬁned along with the remainder of
PTAB, it should be noted. This reﬁnement can be omitted for the reason
that wakingtime has exactly the same form as prio.
The following PTAB schemata are also required.
SetWaitingTime
∆PTAB
p? : PID
t? : TIME
wakingtime′ = wakingtime ⊕{p? →t?}
In order to arrive at a valid waiting time, the actual time, ta, is added to the
time tr, requested by process, p?. When deﬁning the ISR, this will be taken
into account. Furthermore, a value of tr = 0 will be considered invalid.
WaitingTime
ΞPTAB
p? : PID
t! : TIME
t! = wakingtime(p?)
The waiting (waking) time must be cleared when a process is awakened
(i.e., returned to the scheduler’s ready queue). The following schema deﬁnes
this operation:
ClearWaitingTime
∆PTAB
p? : PID
∃t : TIME | t = 0 • wakingtime′ = wakingtime ⊕{p? →t}
The predicate of this schema simpliﬁes to wakingtime′ = wakingtime ⊕{p? →
0}.
We need a way to determine whether a process is sleeping. This will be
used when determining whether a sleep request can be honoured.

3.11 Sleepers
163
IsProcessSleeping
ΞPTAB
p? : PID
wakingtime(p?) > 0
The relevant error schemata are as follows.
TooManySleepers
serr! : SYSERR
serr! = toomanysleepers
There are too many processes in the system that are asleep.
AlreadyAsleep
serr! : SYSERR
serr! = alreadyasleep
The process requesting a sleep period is already recorded as being asleep. (Has
someone hacked in?)
3.11.1 Top Level
We can proceed to the top-level speciﬁcation of the sleep module. The speci-
ﬁcation is contained in this subsection.
This is another case in which we require PTAB to be included in a the
state schema.
SLEEPERS
PTAB
slps : F PID
maxslps : N1
slps ⊂used
∀p : PID •
p ∈slps ⇒state(p) = pssleeping
∀p : PID •
p ∈slps ⇒wakingtime(p) > 0
∀p : PID •
p ∈slps ⇒p ∈used
The correctness of the ﬁnal universal can be seen when it is considered that
not all processes in used are asleep at any given time but all processes that
are asleep are in used. We will need to prove the following.

164
3 A Simple Kernel
Theorem 47. If p ∈slps, then p ∈used.
The initialisation operation is the obvious one:
SLEEPERSInit
SLEEPERS ′
smax? : N1
slps′ = ∅
maxslps′ = smax?
The following is a predicate that is true iﬀthere are currently processes
that are asleep.
GotSleepers
ΞSLEEPERS
slps ̸= ∅
The following is a predicate that is true iﬀthe process p? is currently
asleep (i.e., an element of slps).
IsAsleep
ΞSLEEPERS
p? : PID
p? ∈slps
The variable maxslps is the maximum number of process identiﬁers that
can be in slps—i.e., it is the maximum cardinality for slps. A sleeper can be
added if #slps is strictly less than the maximum size which it can attain.
CanAddSleeper
ΞSLEEPERS
#slps < maxslps
The operation to add a sleeper, p?, to the sleepers set, slps, is speciﬁed by
the following schema. It is the obvious operation, given the deﬁnitions.
AddSleeperProc
∆SLEEPERS
p? : PID
slps′ = slps ∪{p?}
To deﬁne the ﬁrst main operation, it is necessary to deﬁne two new oper-
ations on PTAB.

3.11 Sleepers
165
SetWaitingTime
∆PTAB
p? : PID
t? : TIME
wakingtime′ = wakingtime ⊕{p? →t?}
SetStateToSleeping
∆PTAB
p? : PID
state′ = state ⊕{p? →pssleeping}
The operation to add a sleeper process is deﬁned by
AddSleeper =
(IsAsleep ∧AlreadyAsleep)
∨(CanAddSleeper ∧
AddSleeperProc ∧
SetWaitingTime ∧
SysOk)
∨TooManySleepers
(Note that the operation represented by this schema requires a reschedule
after use.) The deﬁnition expands into the following schema:
AddSleeper
∆SLEEPERS
∆SCHED
p? : PID
t? : TIME
serr! : SYSERR
(p? ∈slps ∧serr! = alreadyasleep)
∨(#slps < maxslps ∧
slps′ = slps ∪{p?} ∧
wakingtime′ = wakingtime ⊕{p? →t?} ∧
serr! = sysok)
∨serr! = toomanysleepers
Since AddSleeper is a major operation, we need to calculate its precondi-
tion. The calculation is simple and the precondition obvious.
pre AddSleeper =
p? ∈slps ∨#slps < maxslps

166
3 A Simple Kernel
When a process’ sleep time expires, it must be removed from the set of
sleeping processes. The following schema deﬁnes this operation—it is, again,
obvious.
RemoveSleeper
∆SLEEPERS
p? : PID
slps′ = slps \ {p?}
If the time a process, p, requires to wake is t, and 0 < t ≤now, p should
wake up now. This is expressed by the following schema:
ShouldWakeUp
t? : TIME
now? : TIME
0 < t?
t? ≤now?
A process should wake if the following condition is met:
ShouldWake =
(WakingTime[t/t!] ∧ShouldWakeUp[t/t?]) \ {t}
This condition can be expanded into the following schema. It turns out to
be an important operation in deciding which processes to wake when such a
decision is required.
ShouldWake
ΞPTAB
p? : PID
now? : TIME
∃t : TIME •
t = waitingtime(p?) ∧
0 < t ∧t ≤now?
After simpliﬁcation, it becomes:
ShouldWake
ΞPTAB
p? : PID
now? : TIME
0 < waitingtime(p?) ≤now?
Next, we deﬁne the FindAndWake operation.

3.11 Sleepers
167
FindAndWake =
GotSleepers ∧
(∀p : PID •
IsAsleep[p/p?] ∧
ShouldWake[p/p?] ⇒
RemoveSleeper[p/p?] ∧
ClearWaitingTime[p/p?] ∧
MakeReady[p/p?]
It expands into
FindAndWake
∆SLEEPERS
ΞPTAB
∆SCHED
now? : TIME
slps ̸= ∅
∀p : PID •
p ∈slps ∧
0 < waitingtime(p) ≤now? ⇒
waitingtime′ = waitingtime ⊕{p →0} ∧
slps′ = slps \ {p} ∧
state′ = state ⊕{p →psready} ∧
(#sq.pq < maxs ∧
((sq.pq = ⟨⟩∧sq.pq′ = ⟨p⟩) ∨
(prio(p) ≤prio(head sq.pq) ∧sq.pq′ = ⟨p⟩⌢sq.pq) ∨
(prio(last sq.pq) < prio(p) ∧sq.pq′ = sq.pq ⌢⟨p⟩) ∨
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = sq.pq •
prio(last s1) < prio(p) ∧
prio(p) ≤prio(head s2) ∧
sq.pq′ = s1 ⌢⟨p⟩⌢s2)) ∧
state′ = state ⊕{p →psready} ∧
serr! = sysok)
∨serr! = schedqfull
Note that sequential composition is not required between ClearWaitingTIme
and MakeReady because the components of PTAB they update are distinct.
The FindAndWake operation is important, so its precondition must be
calculated. The precondition is
pre FindAndWake =
slps ̸= ∅∧∀p : PID • p ∈slps ∧0 < waitingtime(p) ≤now? ∧#sq < maxs
or, after simpliﬁcation, it becomes

168
3 A Simple Kernel
pre FindAndWake =
slps ̸= ∅∧
{p : PID | p ∈slps ∧0 < waitingtime(p) ≤now?} ⊆slps ∧
#sq + #{p : PID | p ∈slps ∧0 < waitingtime(p) ≤now?} < maxs
When a process is sleeping, its state value should be pssleeping. Setting
state to pssleeping is performed by the following operation:
SetStateToSleeping =
∃st : PSTATE | st = pssleeping •
SetProcState[st/st?]
The operation expands and simpliﬁes to:
SetStateToSleeping
∆PTAB
p? : PID
state′ = state ⊕{p? →pssleeping}
The following is a predicate. It is used to determine when a process is
trying to sleep for a period of 0 seconds—any longer period is valid.
BadSleepTime
t? : TIME
t? = 0
An operation, called SendMeToSleep is required. It is deﬁned by
SendMeToSleep =
(BadSleepTime ∧SleepTooShort)
∨(ComputeWakeTime[t?/stm?, cst/cst!] ∧AddSleeper[cst/t?] ∧
SetStateToSleeping) \ {cst}
Again this operation requires a reschedule after use.
Expansion of this deﬁnition yields the following schema:
SendMeToSleep
∆SLEEPERS
ΞTIMESINCEBOOT
∆PTAB
p? : PID
t? : TIME
tnow? : TIME
serr! : SYSERR
(t? = 0 ∧serr! = sleeptimetooshort)
∨(∃cst : TIME | cst = t? + tnow •
(p? ∈slps ∧serr! = alreadyasleep)

3.11 Sleepers
169
∨(#slps < maxslps ∧
slps′ = slps ∪{p?} ∧
wakingtime′ = wakingtime ⊕{p? →t? + tnow?} ∧
serr! = sysok)
∨serr! = toomanysleepers ∧
serr! = sysok))
∨serr! = toomanysleepers)
∧state′ = state ⊕{p? →pssleeping}
We can immediately simplify this schema to the following:
ΞTIMESINCEBOOT
∆SLEEPERS
∆PTAB
p? : PID
t? : TIME
tnow? : TIME
serr! : SYSERR
(t? = 0 ∧serr! = sleeptimetooshort)
(p? ∈slps ∧serr! = alreadyasleep)
∨(#slps < maxslps ∧
slps′ = slps ∪{p?} ∧
wakingtime′ = wakingtime ⊕{p? →t? + tnow?} ∧
serr! = sysok)
∨serr! = toomanysleepers ∧
serr! = sysok))
∨serr! = toomanysleepers)
∧state′ = state ⊕{p? →pssleeping}
By repeated application of Distrib-∨and p ∧q ⊢p, the predicate can be
transformed into
(t? = 0 ∧serr! = sleeptimetooshort)
∨(p? ∈slps ∧serr! = alreadyasleep)
∨(#slps < maxslps ∧
slps′ = slps ∪{p?} ∧
wakingtime′ = wakingtime ⊕{p? →t? + tnow?} ∧
state′ = state ⊕{p? →pssleeping} ∧
serr! = sysok)
∨serr! = toomanysleepers ∧
serr! = sysok))
∨serr! = toomanysleepers)
The precondition of this important operation is easy to calculate.

170
3 A Simple Kernel
pre SendMeToSleep =
t? = 0 ∨p? ∈slps ∨#slps < maxslps
3.11.2 Reﬁnement One
Having deﬁned the sleeper set and the operations required to maintain it, it
is time to engage in the ﬁrst reﬁnement. The strategy is to reﬁne the set to
a singly linked list of process identiﬁers in the next mapping in PTAB. By
implementing the sleeper set this way, space is saved; the list is, in any case,
limited in length.
The ﬁrst step of the reﬁnement is to ﬁnd a representation for the sleeper
set. The identiﬁer set slps is replaced by slps1 but now slps1 is a partial
(ﬁnite) injection from process identiﬁers to GPIDs (process identiﬁers plus
nullpid). The idea is that slps1 contains the elements of slps in some order.
The ﬁrst element is denoted by hds and the last by ends—we can talk of “ﬁrst”
and “last” because of the temporal ordering on the insertion of identiﬁers into
slps. The number of elements in slps1 is recorded in slcnt1, so slcnt1 = #slps.
The limit on the size of slps1 is maxslps1 (which is intended to be equal to
maxslps). The reﬁnement state space is given by the following schema:
SLEEPERS1
slps1 : PID
↣GPID
hds, ends : GPID
slcnt1 : N
maxslps1 : N1
hds = nullpid ⇔ends = nullpid
hds = nullpid ⇔dom slps1 = ∅
hds = nullpid ⇔maxslps1 = 0
slcnt1 = # dom slps1
hds ̸= nullpid ⇔
slps1(ends) = nullpid ∧
hds ∈dom slps1 ∧
ends ∈dom slps1 ∧
# dom slps1 > 0
SLEEPERSInit1
SLEEPERS1′
smax? : N1
maxslps1′ = smax?
hds′ = ends′ = nullpid
slcnt1′ = 0

3.11 Sleepers
171
IsAsleep1
ΞSLEEPERS1
p? : PID
p? ∈dom slps1
(We can, and will, do better than this.)
CanAddSleeper1
ΞSLEEPERS1
slcnt1 < maxslps1
AddSleeperProc1
∆SLEEPERS1
p? : PID
(hds = nullpid ∧
hds′ = p? ∧
ends′ = p? ∧
slps1′ = slps1 ⊕{p? →nullpid})
∨(ends′ = p? ∧
slps1′ = slps1 ⊕{ends →p?, p? →nullpid})
∧slcnt1′ = slcnt1 + 1
AddSleeper1 =
(IsAsleep ∧AlreadyAsleep)
∨(CanAddSleeper ∧AddSleeperProc ∧SetWaitingTime ∧SysOk)
∨TooManySleepers
This expands to:
∆SLEEPERS1
∆PTAB1
p? : PID
t? : TIME
serr! : SYSERR
(p? ∈dom slps1 ∧serr! = alreadyasleep)
∨(p? ̸∈dom slps1 ∧
(slcnt1 < maxslps1 ∧
((hds = nullpid ∧
hds′ = ends′ = p? ∧

172
3 A Simple Kernel
slps1′ = slps1 ⊕{p? →nullpid})
∨(ends′ = p? ∧slps1′ = slps1 ⊕{ends →p?, p? →nullpid})) ∧
slcnt1′ = slcnt1 + 1 ∧
wakingtime′ = wakingtime ⊕{p? →t?} ∧
serr! = sysok))
∨serr! = toomanysleepers
DelSleeperProc1
∆SLEEPERS1
p? : PID
(hds = p? ∧
slps1′ = slps1 −◁{p?} ∧
hds′ = slps1(hds))
∨(∃p1 : PID | p? = slps1(p1) •
(∃slps1′′ : PID
↣GPID •
slps1′′ = slps1 ⊕{p1 →slps1(p?)}) ∧
slps1′ = slps1 −◁{p?})
slcnt1′ = slcnt1 −1
This simpliﬁes to:
∆SLEEPERS1
p? : PID
(hds = p? ∧slps1′ = slps1 −◁{p?} ∧
hds′ = slps1(p?))
∨(∃p1 : PID | p? = slps1(p1) •
slps1′ = (slps1 −◁{p?}) ⊕{p1 →slps1(p?)})
slcnt1′ = slcnt1 −1
The test whether there are any processes in the list of sleepers is now
reﬁned to a test of the counter, slcnt1. The counter is incremented by one
when a process is added to the list and decremented by one when a process
is removed.
GotSleepers1
ΞSLEEPERS1
slcnt1 ̸= 0
The removal of a process from the list of sleeping processes is reﬁned to
the following schema. If the process to be removed, p?, is the head of the list,
the head, hds, is updated and p? removed from slps1. Otherwise, p? is just

3.11 Sleepers
173
removed from slps1. In both cases, slcnt1 is decremented by one, as stated
above.
RemoveSleeper1
∆SLEEPERS1
p? : PID
((p? = hds ∧
hds′ = slps1(hds) ∧
slps1′ = slps1 −◁{p?})
∨slps1′ = slps1 −◁{p?})
slcnt1′ = slcnt1 −1
The following is the reﬁnement of the ShouldWakeUp predicate. The con-
dition is the same as in the speciﬁcation.
ShouldWakeUp1
t?, now? : TIME
0 < t?
t? ≤now?
The ShouldWake predicate is reﬁned to the following:
ShouldWake1 =
(WakingTime1[t/t!] ∧ShouldWakeUp1[t/t?]) \ {t}
The deﬁnition expands into the following schema:
ShouldWake1
ΞPTAB
p? : PID
now? : TIME
∃t : TIME •
t = waitingtime1(p?) ∧
0 < t ∧t ≤now?
which can be simpliﬁed using the one-point rule to
ShouldWake1
ΞPTAB
p? : PID
now? : TIME
0 < waitingtime1(p?) ≤now?

174
3 A Simple Kernel
The form of the reﬁnement of FindAndWake is identical to the speciﬁca-
tion (only identiﬁers are altered).
FindAndWake1 =
GotSleepers1 ∧
(∀p : PID •
IsAsleep1[p/p?] ∧
ShouldWake1[p/p?] ⇒
RemoveSleeper1[p/p?] ∧
ClearWaitingTime1[p/p?] ∧
MakeReady1[p/p?]
In order to work with the deﬁnition, it must be expanded. The expansion is
as follows:
FindAndWake1
∆SLEEPERS1
∆SCHED1
now? : TIME
slcnt1 ̸= 0
∀p : PID •
p ∈dom slps1 ∧
0 < waitingtime1(p) ≤now? ⇒
slps1′ = slps1 −◁{p}
((p = hds ∧
hds′ = slps1(hds) ∧
slps1′ = slps1 −◁{p?})
∨slps1′ = slps1 −◁{p?}) ∧
slcnt1′ = slcnt1 −1 ∧
waitingtime1′ = waitingtime1 ⊕{p →0} ∧
state1′ = state1 ⊕{p →psready} ∧
(nxtp ≤maxs1 ∧
((nxtp = 1 ∧sq.pq1′ = {1 →p} ∧nxtp′ = 2) ∨
(prio1(p) ≤prio1(sq.pq1(1)) ∧
(∀i : 1 . . nxtp −1 •
sq.pq1′ = (sq.pq1 ⊕{i + 1 →sq.pq1(i)}) ⊕{1 →p}) ∧
nxtp′ = nxtp + 1) ∨
(prio1(sq.pq1(nxtp −1)) < prio1(p) ∧
sq.pq1′ = sq.pq1 ⊕{nxtp →p} ∧
nxtp′ = nxtp + 1) ∨
(∃i : 1 . . nxtp −2 •
prio1(sq.pq1(i)) < prio1(p) ∧
prio1(p) ≤prio1(sq.pq1(i + 1))
∨(∀j : i + 1 . . nxtp −1 •
sq.pq1′ = (sq.pq1 ⊕{j + 1 →sq.pq1(j)}) ⊕{i + 1 →p}
∧nxtp′ = nxtp + 1)) ∧

3.11 Sleepers
175
serr! = sysok)
∨serr! = schedqfull
The precondition of FindAndWake1 must be calculated. The calculation
yields the following predicate:
pre FindAndWake1 =
slcnt1 ̸= 0
nxtp + #{p : PID | p ∈dom slps1 ∧0 < waitingtime1(p) ≤now?} < maxs1
{p : PID | p ∈dom slps1 ∧0 < waitingtime1(p) ≤now?} ⊆dom slps1
The composite operation that places processes in a sleeping state reﬁnes
to the following deﬁnition (it is similar to the speciﬁcation):
SendMeToSleep1 =
(BadSleepTime ∧SleepTooShort)
∨(ComputeWakeTime[t?/stm?, cst/cst!] ∧AddSleeper1[cst/t?] ∧
SetStateToSleeping1) \ {cst}
Its expansion is the following schema:
SendMeToSleep1
∆PTAB1
∆SLEEPERS1
p? : PID
t?, now? : TIME
serr! : SYSERR
(t? = 0 ∧serr! = sleeptimetooshort)
∨(∃cst : TIME •
(cst = t? + now? ∧
(p? ∈dom slps1 ∧serr! = alreadyasleep)
∨(p? ̸∈dom slps1 ∧
(slcnt1 < maxslps1 ∧
((hds = nullpid ∧
hds′ = ends′ = p? ∧
slps1′ = slps1 ⊕{p? →nullpid})
∨(ends′ = p? ∧slps1′ = slps1 ⊕{ends →p?, p? →nullpid})) ∧
slcnt1′ = slcnt1 + 1 ∧
wakingtime′ = wakingtime ⊕{p? →t?} ∧
serr! = sysok))
∨serr! = toomanysleepers)
∧state1′ = state ⊕{p? →pssleeping})
This schema can be simpliﬁed in a fairly obvious way. After simpliﬁcation,
the following is obtained:

176
3 A Simple Kernel
∆PTAB1
∆SLEEPERS1
p? : PID
t?, now? : TIME
serr! : SYSERR
(t? = 0 ∧serr! = sleeptimetooshort)
∨(p? ∈dom slps1 ∧serr! = alreadyasleep)
∨(p? ̸∈dom slps1 ∧
(slcnt1 < maxslps1 ∧
((hds = nullpid ∧
hds′ = ends′ = p? ∧
slps1′ = slps1 ⊕{p? →nullpid})
∨(ends′ = p? ∧slps1′ = slps1 ⊕{ends →p?, p? →nullpid})) ∧
slcnt1′ = slcnt1 + 1 ∧
∧state1′ = state ⊕{p? →pssleeping})
wakingtime′ = wakingtime ⊕{p? →t? + now?} ∧
serr! = sysok))
∨serr! = toomanysleepers)
Since this is an important operation, its precondition must be calculated.
It is easy to see that the precondition is
pre SendMeToSleep1 =
t? = 0 ∨p? ∈dom slps1 ∨slcnt1 < maxslps1
Finally, we have the abstraction relation. It is an extremely simple relation
and is given as the predicate of the following schema.
AbsSLEEPERS1
SLEEPERS
SLEEPERS1
maxslps1 = maxslps
dom slps1 = slps
slcnt1 = #slps
Theorem 48.
∀SLEEPERS ′; SLEEPERS1′ •
SLEEPERSInit ∧AbsSLEEPERS1′ ⇒SLEEPERSInit1
Proof. By the abstraction relation, maxslps1′ = maxslps′ = smax?. Also
by the invariant of SLEEPERRS1′, hds′ = ends′ = nullpid ⇒dom slps1′ =
∅= slps′ by the one-point rule. Finally, #slps′ = slcnt1′ and slps′ = ∅, so
#slps′ = 0, from which we are entitled to conclude that slcnt1′ = 0. 2

3.11 Sleepers
177
Theorem 49.
∀SLEEPERS; SLEEPERS1; now? : TIME •
pre FindAndWake ∧AbsSLEEPERS1 ⇒pre FindAndWake1
Proof. The preconditions are
pre FindAndWake =
slps ̸= ∅∧
{p : PID | p ∈slps ∧0 < waitingtime(p) ≤now?} ⊆slps ∧
#sq.pq + #{p : PID | p ∈slps ∧0 < waitingtime(p) ≤now?} < maxs ∧
and
pre FindAndWake1 =
slcnt1 ̸= 0
nxtp + #{p : PID | p ∈dom slps1 ∧0 < waitingtime1(p) ≤now?} < maxs1
{p : PID | p ∈dom slps1 ∧0 < waitingtime1(p) ≤now?} ⊆dom slps1
The abstraction relation, AbsSLEEPERS1 gives the relevant identities. The
predicate of AbsSLEEPERS1 states that p ∈dom slps1 ⇔p ∈slps and
slps ⊂used, so the reﬁnement of waitingtime is correct. The remainder of the
proof is immediate. 2
Theorem 50.
∀SLEEPERS; SLEEPERS ′; SLEEPERS1; SLEEPERS1′;
now? : TIME; serr! : SYSERR •
pre FindAndWake ∧
AbsSLEEPERS1 ∧
AbsSLEEPERS1′ ∧
FindAndWake1
⇒FindAndWake1
Proof. The predicate of AbsSLEEPERS1 states that slcnt1 = #slps,
so slcnt1 ̸= 0 implies slps ̸= ∅. Next, p ∈dom slps1, by the predicate
of AbsSLEEPERS1, implies p ∈slps, since dom slps1 = slps. The in-
variant of SLEEPERS states that slps ⊂used and this guarantees that
p ∈dom waitingtime; from this, it may be inferred ﬁrst that waitingtime(p) =
waitingtime1(p) and consequently that 0 < waitingtime1(p) ≤now? implies
that 0 < waitingtime(p) ≤now?.
As far as the update of slps1 is concerned, the important conjunct is
slps1′ = slps1 −◁{p}. The predicate of AbsSLEEPERS1′ states that slps′ =
dom slps1. This fact permits the following inference slps1′ = slps1 −◁{p}
implies that
dom slps1′
= (dom slps) \ {p}
= slps \ {p}
= slps′

178
3 A Simple Kernel
as required.
By AbsSLEEPERS1, slcnt1 = #slps and by AbsSLEEPERS1′, slcnt1 =
#slps′, so slcnt1′ = slcnt −1 = #slps −1 = slps′.
The update of waitingtime1 is justiﬁed as follows. It is known, for rea-
sons that have already been given, that p ∈used, so waitingtime1(p) =
waitingtime(p) for all p ∈slps. It also follows that waitingtime1′(p) =
waitingtime′(p) for all p ∈used, so
waitingtime1′
= waitingtime1 ⊕{p →0}
= waitingtime ⊕{p →0}
= waitingtime′
The update of state1 and its equivalence to state also follows the same line of
reasoning
state1′
= state1 ⊕{p →psready}
= state ⊕{p →psready}
= state′
The reﬁnement of MakeReady has already been taken into account above.
As noted there, MakeReady is deﬁned in terms of promotion.
2
Theorem 51.
∀SLEEPERS; SLEEPERS1; p? : PID; t? : TIME; now? : TIME •
pre SendMeToSleep ∧AbsSLEEPERS1 ⇒pre SendMeToSleep1
Proof. We have:
pre SendMeToSleep = #slps < maxslps ∨t? = 0 ∨p? ̸∈slps
pre SendMeToSleep1 = t? = 0 ∨slcnt1 < maxslps1 ∨p? ̸∈dom slps1
Clearly t? = 0 is the same in both cases and the result can be deduced using
∨-introduction.
For the second case, the abstraction relation states that slcnt1 = #slps and
maxslps = maxslps1, so substituting into #slps < maxslps, slcnt1 < maxslps1
is obtained. Again, a step of ∨-introduction permits the conclusion to be
reached, viz. t? = 0 ∨slcnt1 < maxslps1.
Finally, p? ̸∈dom slps1 and, by the abstraction relation, dom slps1 = slps,
so p? ̸∈slps is equivalent to p? ̸∈dom slps1. 2

3.11 Sleepers
179
Theorem 52.
∀SLEEPERS; SLEEPERS ′; SLEEPERS1; SLEEPERS1′;
p? : PID; t?, now? : TIME; serr! : SYSERR •
pre SendMeToSleep ∧
AbsSLEEPERS1 ∧
AbsSLEEPERS1′ ∧
SendMeToSleep1
⇒SendMeToSleep
Proof. We can safely ignore the ﬁrst disjunct,
t? = 0 ∧serr! = sleeptimetooshort
It is the same in both cases and contributes only t? = 0 to the precondition.
Everything is relatively straightforward; the interesting part is the update
of slps1. We start with slps1 = slps1 ⊕{p? →nullpid}. By AbsSLEEPERS1,
dom slps1 = slps, so taking domains, we have
dom slps1′
= dom(slps1 ⊕{p? →nullpid}
= dom(slps1 ∪{p? →nullpid}),
p? ̸∈dom slps1
= (dom slps1) ∪(dom{p? →nullpid})
= (dom slps1) ∪{p?}
= slps ∪{p?}
= slps′
where the last step is justiﬁed by AbsSLEEPERS1′ (dom slps1′ = slps′).
Similarly, for slps1′ = slps1 ⊕{p? →hds}, for the same reason, we again
take domains
dom slps1′
= dom(slps1 ⊕{send →p?, p? →nullpid})
= dom(slps1 ∪{send →p?, p? →nullpid}),
p? ̸∈dom slps1
= dom slps1 ∪(dom{p? →nullpid})
= dom slps1 ∪{p?}
= slps ∪{p?}
= slps′
again, the ﬁnal step is justiﬁed by AbsSLEEPERS1′ (dom slps1′ = slps′).
Finally, since p? ∈used and slps ⊂used and ∀p : PID • p ∈used ⇒
wakingtime(p) = wakingtime1(p) in AbsPTAB1, and ∀p : PID • p ∈used′ ⇒
wakingtime′(p) = wakingtime1′(p), we can infer that
wakingtime1′
= wakingtime1 ⊕{p? →t? + now?}
= wakingtime ⊕{p? →t? + now?}
= wakingtime′
The correspondence between state and state1 is proved in a similar fashion.
2

180
3 A Simple Kernel
3.11.3 Reﬁment Two
SLEEPERS2
PTAB1
slcnt2 : N
maxslprs2 : N
shd, send : GPID
shd = nullpid ⇔send = nullpid
shd ̸= nullpid ⇔slcnt2 > 0
shd ̸= nullpid ⇔
next∗(| {shd} |) \ {nullpid} ̸= ∅shd ̸= nullpid ⇔
next(send) = nullpid
shd ̸= nullpid ⇔
∀p : PID •
p ∈next∗(| {shd} |) \ {nullpid} ⇒
∃k : N • k ≥0 ∧k ≤maxslprs2 ∧nextk(shd) = p
SLEEPERSInit2
SLEEPERS2
smax? : N1
maxslprs2′ = smax?
shd ′ = nullpid
slcnt2′ = 0
IsAsleep2
ΞSLEEPERS2
p? : PID
shd = p? ∨
send = p? ∨
p? ∈next+(| {shd} |) \ {nullpid}
CanAddSleeper2
ΞSLEEPERS2
slcnt2 < maxslprs2

3.11 Sleepers
181
AddSleeperProc2
∆SLEEPERS2
p? : PID
slcnt2′ = slcnt2 + 1
(shd = nullpid ∧
shd ′ = p? ∧
send ′ = p? ∧
next′ = next ⊕{p? →nullpid})
∨(send ′ = p? ∧
next′ = next ⊕{send →p?, p? →nullpid})
DelSleeperProc2
∆SLEEPERS2
p? : PID
slcnt2′ = slcnt2 −1
((shd = p? ∧shd ′ = next(shd))
∨(∃p1 : PID | p? = next(p1) •
next′ = next ⊕{p1 →next(p?)})
AddSleeper2 =
(IsAsleep2 ∧AlreadyAsleep)
∨(CanAddSleeper2 ∧
(¬ IsAsleep2 ∧
AddSleeperProc2 ∧
SetWaitingTime2 ∧
SysOk))
∨TooManySleepers
AddSleeper2
∆SLEEPERS2
p? : PID
serr! : SYSERR
t? : TIME
(shd = p? ∨p? ∈next+(| {shd} |) \ {nullpid} ∧
serr! = alreadyasleep)
∨(shd ̸= p? ∧
∨(slcnt2 < maxslprs2 ∧
p? ̸∈next+(| {shd} |) \ {nullpid} ∧
wakingtime2′ = wakingtime2 ⊕{p? →t?} ∧
slcnt2′ = slcnt2 + 1 ∧

182
3 A Simple Kernel
((shd = nullpid ∧
shd ′ = p? ∧
send ′ = p? ∧
next′ = next ⊕{p? →nullpid})
∨(send ′ = p? ∧
next′ = next ⊕{send →p?, p? →nullpid})
∧serr! = sysok))
∨serr! = toomanysleepers
Note that
p? ̸= shd ∧
p? ̸∈next+(| {shd} |) \ {nullpid}
can be rewritten as
p? ̸= shd ∧
¬ ∃k : N •
0 < k ∧k ≤#next∗(| {shd} |) \ {nullpid} ∧
nextk(shd) ̸= p?
GotSleepers2
ΞSLEEPERS1
slcnt2 ̸= 0
RemoveSleeper2
∆SLEEPERS2
p? : PID
(p? = shd ∧
shd ′ = next(hds))
∨next′ = next ⊕{p? →nullpid}
slcnt2′ = slcnt2 −1
ShouldWakeUp2
p? : PID
t?, now? : TIME
0 < t?
t? ≤now?

3.11 Sleepers
183
ShouldWake2 =
(WakingTime2[t/t!] ∧ShouldWakeUp2[t/t?]) \ {t}
This expands into
ShouldWake2
ΞPTAB
p? : PID
now? : TIME
∃t : TIME •
t = waitingtime2(p?) ∧
0 < t ∧t ≤now?
or
ShouldWake2
ΞPTAB
p? : PID
now? : TIME
0 < waitingtime2(p?) ≤now?
FindAndWake2 =
GotSleepers2 ∧
(∀p : PID •
IsAsleep2[p/p?] ∧ShouldWake2[p/p?] ⇒
RemoveSleeper2[p/p?] ∧ClearWaitingTime2[p/p?] ∧MakeReady1[p/p?]
This expands into
FindAndWake2
∆SLEEPERS2
∆SCHED
∆PTAB2
now? : TIME
slcnt2 ̸= 0
∀p : PID •
p ∈next∗(| {shd} |) \ {nullpid} ∧0 < waitingtime2(p) ≤now? ⇒
((p = shd ∧shd ′ = next(hds))

184
3 A Simple Kernel
∨next′ = next ⊕{p →nullpid}) ∧
slcnt2′ = slcnt2 −1 ∧
waitingtime2′ = waitingtime2 ⊕{p →0} ∧
MakeReady1[p/p?]
pre FindAndWake2 =
slcnt2 ̸= 0 ∧
nextp + #{p : PID | 0 < waitingtime2(p) ≤now? ∧
next∗(| {shd} |) \ {nullpid}} −1 < maxs1 ∧
{p : PID | 0 < waitingtime2(p) ≤now? ∧
p ∈next∗(| {shd} |) \ {nullpid}}
⊆next∗(| {shd} |) \ {nullpid}
SendMeToSleep2 =
(BadSleepTime ∧SleepTooShort)
∨(ComputeWakeTime[t?/stm?, cst/cst!] ∧
AddSleeper2[cst/t?] ∧
SetStateToSleeping2) \ {cst}
This expands into and simpliﬁes to
SendMeToSleep2
∆SLEEPERS2
∆PTAB2
t?, now? : TIME
p? : PID
serr! : SYSERR
(t? = 0 ∧serr! = sleeptimetooshort)
∨(slcnt2 < maxslps2 ∧
(shd = p? ∨
(∃k : N •
0 < k ∧k ≤#next+(| {shd} |) \ {nullpid} ∧
nextk(shd) = p)) ∧
serr! = alreadyasleep)
∨(shd ̸= p? ∧p? ̸∈next+(| {shd} |) \ {nullpid} ∧
wakingtime2′ = wakingtime2 ⊕{p? →t? + now?} ∧
slcnt2′ = slcnt2 + 1 ∧
((shd = nullpid ∧shd ′ = p? ∧send ′ = p? ∧
next′ = next ⊕{p? →nullpid})
∨(shd ′ = p? ∧next′ = next ⊕{p? →shd}))
∧state2′ = state2 ⊕{p? →pssleeping}
∧serr! = sysok))
∨serr! = toomanysleepers)

3.11 Sleepers
185
This is interesting because shd = p? ∨p? ∈next+(| {shd} |) \ {nullpid} is
equivalent to p? ∈next∗(| {shd} |) \ {nullpid}.
pre SendMeToSleep2 =
t? = 0
∨(shd = p? ∨
(∃k : N •
0 < k ∧k ≤#next+(| {shd} |) \ {nullpid} ∧
nextk(shd) = p))
∨slcnt2 < maxslps2
AbsSLEEPERS2
SLEEPERS1
SLEEPERS2
maxslprs2 = maxslprs1
dom slps1 ⊆dom next
ran slps1 ⊆ran next
slscnt2 = slscnt1
dom slps1 = next∗(| {shd} |) \ {nullpid}
∀p : PID •
p ∈dom slps1 ⇒
slps1(p) = next(p)
shd = hds
send = ends
Theorem 53.
∀SLEEPERS1′; SLEEPERS2′ •
SLEEPERSInit2 ∧AbsSLEEPERS2′ ⇒SLEEPERSInit1
Proof. By the abstraction relation, maxslprs2′ = maxslps1′, and since
maxslprs2′ = smax?, we may infer maxslps1′ = smax?.
Again, by the abstraction relation, slcnt2′ = slcnt1′, and since slcnt2′ = 0,
we are entitled to infer that slcnt1′ = 0.
We deal with hds and ends as follows. The abstraction relation states
that hds′ = shd and shd′ = nullpid, so hds′ = nullpid by the transitivity of
identity. Given that shd′ = nullpid ⇒send′ = nullpid and, by the abstraction
relation, send′ = ends′, Modus Ponens allows us to infer that ends′ = nullpid.
By transitivity of identity, we have the desired shd′ = ends′ = nullpid. 2
Theorem 54.
∀SLEEPERS1; SLEEPERS2; now? : TIME •
pre FindAndWake1 ∧AbsSLEEPERS2 ⇒pre FindAndWake2

186
3 A Simple Kernel
Proof.
pre FindAndWake1 =
slcnt1 ̸= 0
nxtp + #{p : PID | p ∈dom slps1 ∧0 < waitingtime1(p) ≤now?} < maxs1
{p : PID | p ∈dom slps1 ∧0 < waitingtime1(p) ≤now?} ⊆dom slps1
pre FindAndWake2 =
slcnt2 ̸= 0 ∧
nextp + #{p : PID | 0 < waitingtime2(p) ≤now? ∧
next∗(| {shd} |) \ {nullpid}} −1 < maxs1 ∧
{p : PID | 0 < waitingtime2(p) ≤now? ∧
p ∈next∗(| {shd} |) \ {nullpid}}
⊆next∗(| {shd} |) \ {nullpid}
The abstraction relation, AbsSLEEPERS2 gives the relevant identities.
By a previous result, we have it that p ∈dom slps1 ⇔p ∈slps and slps ⊂
used and nxtp#next∗(| {shd} |) \ {nullpid} = dom slps1, so the reﬁnement of
waitingtime1 is correct. The remainder of the proof is immediate. 2
Theorem 55.
∀SLEEPERS1; SLEEPERS1′; SLEEPERS2; SLEEPERS2′;
now? : TIME; serr! : SYSERR •
pre FindAndWake1 ∧
AbsSLEEPERS2 ∧
AbsSLEEPERS2′ ∧
FindAndWake2
⇒FindAndWake1
Proof. By the predicate of AbsSLEEPER2, slcnt2 = slcnt1, so slcnt2 ̸= 0
implies slcnt1 ̸= 0. By that same predicate, next∗(| {shd} |) \ {nullpid} =
dom slps1, so p ∈next∗(| {shd} |) \ {nullpid} implies that p ∈dom slps1.
Next, it is clear that next∗(| {freehd} |) \ {nullpid} = dom slps1 by the
predicate of the abstraction relation AbsSLEEPERS2 and that dom slps1 =
slps by AbsSLEEPERS1 and slps ⊂used, p ∈next∗(| {freehd} |) \ {nullpid}
(∗) implies that 0 < waitingtime2(p) ≤now? implies 0 < waitingtime1(p) ≤
now?.
The removal of p from the list of sleepers is given, in FindAndWake2, as
(p = shd ∧shd ′ = next(shd))
∨(∃p1 : PID •
next(p1) = p ∧
next′ = next ⊕{p1 →next(p)}
It is clear that each should be taken separately (and an appeal to ∨-I would
be made if one wanted a fully formal proof).

3.11 Sleepers
187
By the predicate of the schema AbsSLEEPERS2, hds = shd and by the
predicates of both AbsSLEEPERS2 and AbsSLEEPERS2′, shd′ = next(shd)
= slps1(hds) = hds′. The identity next(shd) = slps1(hds) is justiﬁed by the
observation that
hds ∈next∗(| {hds} |) \ {nullpid} = dom slps1
Next, the existential contains next′ = next ⊕{p1 →next(p)}. This implies
that p ̸∈dom next′ and, by AbsSLEEPERS2′, next′(p) = slps1′(p), for all p ∈
dom slps1′ (or equivalently, p ∈next∗(| {shd} |)\{nullpid}). For p ̸∈dom slps1′
and p ∈dom slps1 both to be true, it must be the case that dom slps1′ =
(dom slps1) \ {p} which is equivalent to slps1 \ {p} and slps1 \ {p} = slps1′.
By the abstraction relations, slcnt2 = slcnt1 and slcnt2′ = slcnt1′, so
slcnt2′ = slcnt2 −1 = slcnt1 −1 = slcnt1′.
The update of waitingtime2 and state2 can be handled in a simple way.
The chain of equivalences ∗above is required.
Finally, MakeReady1, as observed elsewhere is deﬁned in terms of promo-
tion and its reﬁnement has already been undertaken.
2
Theorem 56.
∀SLEEPERS1; SLEEPERS2; p? : PID; t?, now? : TIME •
pre SendMeToSleep1 ∧AbsSLEEPERS1 ⇒pre SendMeToSleep2
Proof. We have
pre SendMeToSleep1 = t? = 0
∨slcnt1 < maxslps1
∨p? ̸∈dom slps1
pre SendMeToSleep2 =
t? = 0 ∨slcnt2 < maxslps2 ∨
p? ̸∈next∗(| {shd} |) \ {nullpid}
The abstraction relation states that slcnt1 = slcnt2 and that maxslps1 =
maxslps2. Furthermore, next∗(| {shd} |) \ {nullpid} = dom slps1. 2
Theorem 57.
∀SLEEPERS1; SLEEPERS1′; SLEEPERS2; SLEEPERS2′;
p? : PID; t?, now? : TIME; serr! : SYSERR •
pre SendMeToSleep1 ∧
AbsSLEEPERS2 ∧
AbsSLEEPERS2′ ∧
SendMeToSleep2
⇒SendMeToSleep1

188
3 A Simple Kernel
Proof. We can ignore with impunity the ﬁrst conjunct (t? = 0 ∧serr! =
sleeptimetooshort).
By the predicate of AbsSLEEPERS2, we have slcnt2 = slcnt1 and
maxslps1 = maxslps2, so slcnt2 < maxslps2 ⇔slcnt1 < maxslps1.
The guard
shd = p? ∨p? ∈next∗(| {shd} |) \ nullpid}
implies
p? ∈next∗(| {shd} |) \ nullpid}
which, in turn, by the predicate of AbsSLEEPERS2, implies that p? ∈
dom slps1.
If shd = nullpid, next∗(| {shd} |) \ nullpid} = ∅, which implies that
dom slps1 = ∅. We now reason as follows.
next′
= next ⊕{p? →nullpid}
= slps1 ⊕{p? →nullpid},
since dom slps1 = ∅
= slps1′
The last step is justiﬁed by AbsSLEEPERS2′.
In addition, we have
next′
= next ⊕{send →p?, p? →nullpid}
= slps1 ⊕{endss →p?, p? →nullpid},
since send = ends
= slps1′
The last step is, once more, justiﬁed by AbsSLEEPERS2′.
Since p? is not an element of the free chain, the proof of wakingtime2′ =
wakingtime1′ and state2′ = state1′ is straightforward.
In the ﬁnal section, it will become clear that we are justiﬁed in assuming
that p? is not on the free chain. 2
The operations and data structures derived in this section can now be
translated directly into execuable code.
3.12 User Interface
Here, the interface operations are deﬁned. These are the operations that con-
stitute the system as far as user processes are seen.
3.12.1 System Initialisation
This consists of

3.12 User Interface
189
•
Creation and initialisation of process table (PTAB);
•
Creation of idle (null) process
•
Initialisation of scheduler
•
Initialisation of semaphore table
•
Initialisation of sleeper list
This operation creates the idle process (variously called “null process” or
“idle process”).
CreateNullProcess =
∃st : PSTATE; pr : PPRIO •
st = psready ∧
pr = minprio ∧
AddPD[st/st?, pr/pr?] ∧
InitProcessStack
It expands into
CreateNullProcess
∆PTAB
p! : PID
serr! : SYSERR
((used ⊂PID ∧
p! ̸∈used ∧
used ′ = used ∪{p!} ∧
p! ∈used ′ ∧
prio′ = prio ∪{p! →pr} ∧
state′ = state ∪{p! →st} ∧
smsg′ = smsg ∪{p? →nullmsg} ∧
wakingtime′ = wakingtime ∪{p! →0} ∧
InitProcessStack ∧
serr! = sysok)
∨serr! = pdinuse)
∨serr! = ptabful
The update of state by the addition of p! satisﬁes the update condition for prio
(etc.) as already noted. This is because the AddPD operation is a sequential
composition and what would be the intermediate state, used′′, is identical to
the after state, used′, because it is not further updated.
The InitProcessStack operation is deﬁned below when discussing the cre-
ation of new processes in general.
The deﬁnition of CreateNullProcess is just a substitution instance of
AddPD. The reﬁnement of this operation is just the reﬁnement of AddPD
suitably instantitated.

190
3 A Simple Kernel
SystemInit =
PTABInit
o
9(TIMESINCEBOOTInit ∧CLOCKTIMEInit)
o
9(CreateNullProcess[ipid/p!, err/serr!] ∧
((IsSysOk ∧SCHEDInit[ipid/p?] ∧SEMATBLInit)
∨ReturnSysErr[err/terr?])) \ {ipid, err}
o
9ExitCritical
After re-arrangement, the predicate simpliﬁes to
tnow ′ = 0
secs′ = 0
mins′ = 0
hrs′ = 0
curr ′ = minpid
prev ′ = minpid
iprc′ = ipid
sq′.pq = ⟨⟩
semasinuse′ = ∅
used ′ = {ipid}
prio′ = {ipid →pr?}
state′ = {ipid →st?}
smsg′ = {ipid →nullmsg}
wakingtime′ = {ipid →0}
The assignment to prio′, state′, smsg′ and wakingtime′ are justiﬁed by the fact
that dom prio′ = dom state′ = dom smsg′ = dom wakingtime′ = used′ and
used′ = {ipid}. The initialisation of the scheduler is obtained by expanding
θPRIOQInit to sq′.pq = ⟨⟩.
Some of the components of the deﬁnition of SystemInit do not reﬁne.
Removing them, the following is revealed
PTABInit
o
9CreateNullProcess
o
9SEMATABInit
This forms the core of the reﬁnement. (For veriﬁcation purposes, the invariant
components can be added and checked that the result satisﬁes the reﬁnement
homomorphism)
The initial process is the one that is started ﬁrst. More important, it is the
root process and is responsible for the creation of all processes in the system.
CreateInitialProcess =
NewProcess
o
9SchedNext

3.12 User Interface
191
Since SchedNext is deﬁned in terms of a promotion, the reﬁnement of New-
Process is the central aspect. The reﬁnement of this operation is discussed in
the next subsection.
3.12.2 Process Creation
Process creation involves:
•
Adding a descriptor to the process table
•
Insertion of process reference in scheduler queue (MakeReady)
With the exception of the null (idle) and initial processes, each process is
created by some other process. The other process, the parent, must be the
currently executing process, of course, when the operation is performed. This
has the consequence that the NewProcess operation can handle errors in any
way it sees ﬁt. It also means that there is no need to obtain the identiﬁer of
the current process before doing anything else.
It should be noted that the entire operation is wrapped in an EnterCritical,
LeaveCritical pair. These operations disable and enable interrupts, respec-
tively.
NewProcess =
EnterCritical
(∃st : PSTATE | st = psready •
(AddPD[mypid!/p!, err/serr!] ∧
InitProcessStack
o
9((IsSysOk[err/serr!] ∧MakeReady[mypid!/p?, err/serr!] ∧SysOk)
∨ReturnSysErr[err/terr?])) \ {err})
o
9ExitCritical
As far as the reﬁnement process is concerned, this operation is the reason
for our making the assumption p? ∈used above; every process must be created
by the above operation and it ensures that p ∈used holds, for all newly
allocated p. Below, we are able to discharge the assumption.
The last deﬁnition expands and simpliﬁes to
((used ⊂PID ∧
(mypid! ̸∈used ∧
used ′ = used ∪{mypid!} ∧
prio′ = prio ⊕{mypid! →pr?} ∧
smsg′ = smsg ⊕{mypid! →nullmsg} ∧
wakingtime′ = wakingtime ⊕{mypid! →0} ∧
InitProcessStack ∧
state′ = (state ⊕{mypid →st?}) ⊕{mypid! →psready} ∧
((pq = ⟨⟩∧pq′ = ⟨p?⟩∧serr! = sysok)

192
3 A Simple Kernel
∨(((#pq < maxs ∧
((prio(p?) ≤prio(head pq) ∧pq′ = ⟨p?⟩⌢pq)
∨(prio(last pq) < prio(p?) ∧pq′ = pq ⌢⟨p?⟩)
∨(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(p?) ∧
prio(p?) ≤prio(head s2) ∧
pq′ = s1 ⌢⟨p?⟩⌢s2)) ∧
serr! = sysok))
∨serr! = schedqfull))
∨serr! = pdinuse))
∨serr! = ptabful)
The NewProcess operation is called by the initial process to create processes.
The precondition is
pre NewProcess = used ̸= PID ∧#pq < maxs
The ﬁrst conjunct is derived from used ⊂PID, note.
Again, some of the components do not reﬁne. This implies that the reﬁne-
ment process should be in terms of
AddPD o
9 MakeReady
This expands into
AddPD o
9
SetStateToReady ∧
∃∆PRIOQ •
ΦSCHED ∧MakeReady
This is a reﬁnement and the reﬁnement of MakeReady has already been under-
taken. Furthermore, the reﬁnement of MakeReady in this context involves the
substitution of a value (p?) whose priority is not aﬀected by that operation.
It appears logical, therefore, to concentrate on the composition
AddPD o
9 SetStateToReady
It should be noted that mypid! ∈used, so SetStateToReady is valid in this
case.
The InitProcessStack is a low-level operation that is hardware-speciﬁc. On
the Intel IA32 processor, for example, this operation would ﬁrst simulate a
procedure call (so that any parameters can be passed to the new process);
next, it would push a dummy ﬂags register (set to denote interrupted code),
followed by a word containing the oﬀset of the code segement in a table (the
TSS), then the entry point of the process; the eight 0s (one per register) are
then pushed onto the stack and the operation is ready. On other machines,
this operation would be diﬀerent, hence the reason for merely stating its spec-
iﬁcation in English. (But note that we could specify it formally—all of the
concepts are readily amenable to formalisation.)

3.12 User Interface
193
3.12.3 Process Management
Here, we deal with
•
Self-suspension
•
Sleep
•
Termination
All process-management operations are performed by the currently exe-
cuting process. This has the consequence that any errors must be handled
either by the process itself or just left for something else to pick them up. In
addition, the operations must be wrapped inside the operations that disable
and then enable interrupts. The reason for this is that the operation must be
atomic as far as other processes are concerned.
As will be seen, a useful property of both EnterCritical and ExitCritical
is that they can be omitted when calculating preconditions. The reason for
this is that they only aﬀect the after state. Here, again, is the deﬁnition of
EnterCritical, by way of example:
EnterCritical
∆HW
intﬂg′ = on
The predicate of this schema reduces to true when existentially quantiﬁed and
then simpliﬁed.
The SuspendSelf operation suspends its caller. It is the SuspendMe oper-
ation wrapped in the interrupt disable/enable operations.
SuspendSelf =
EnterCritical
o
9SuspendMe
o
9ExitCritical
Given the property of the interrupt-ﬂag manipulation operations, we can
express the precondition immediately
pre SuspendSelf = pre SuspendMe
The critical-section operations do not reﬁne (or, more correctly, reﬁne to
themselves), so SuspendSelf reﬁnes to SuspendMe. The SuspendMe opera-
tion, however, is deﬁned as the composition of SCHED operations (which
reﬁne to themselves) and SCHED operations deﬁned in terms of promotion.
This implies that the reﬁnement of the PRIOQ operations has already been
performed, so there is nothing left to be done here.
The SendSelfToSleep operation puts the caller to sleep for a period deter-
mined by a parameter to the operation.

194
3 A Simple Kernel
SendSelfToSleep =
EnterCritical
o
9((CurrentProcessId[c/p!] ∧
TimeNow[t/tn!] ∧
SendMeToSleep[c/p?, t/tnow?]) \ {c, t}
o
9SchedNext)
o
9ExitCritical
The precondition is given by the next deﬁnition
pre SendSelfToSleep = pre SendMeToSleep ∧pre SchedNext
The precondition can be written thus because its components contain disjoint
sets of variables.
The deﬁnition again involves components that do not reﬁne, so reﬁnement
should concentrate on
(CurrentProcessId[c/p!] ∧
TimeNow[t/tn!] ∧
SendMeToSleep[c/p?, t/tnow?]) \ {c, t}
o
9SchedNext
Since TimeNow does not reﬁne any further, this can be simpliﬁed to
(CurrentProcessId[c/p!] ∧SendMeToSleep[c/p?, tnow/tnow?]) \ {c}
o
9SchedNext
where the substitution (not strictly Z) [tnow/tnow?] merely substitutes the
current value of the clock from the global variable. (The precondition of
TimeNow is true, in any case.)
We begin with
(CurrentProcessId[c/p!] ∧SendMeToSleep[c/p?, tnow/tnow?]) \ {c}
but this is just a substitution instance of SendMeToSleep and this operation
has already been reﬁned.
When a process is terminated by some external agency (but not an error—
this kernel is too simple) or by calling TerminateSelf, its state has to be set
to psterm.
SetProcessStateToTerminated =
∃st : PSTATE | st = psterm •
SetProcState[st/st?]
This expands into
SetProcessStateToTerminated
∆PTAB
p? : PID
state′ = state ⊕{p? →psterm}

3.12 User Interface
195
The termination operation is now deﬁned. Clearly, it is only called by
the currently executing process. In this system, it is not possible for one
process directly to terminate another. Each process is responsible for freeing
the resources it holds.
TerminateSelf =
EnterCritical
o
9((CurrentProcessId[c/p!] ∧
SetProcessStateToTerminated[c/p?])
o
9DelPD[c/p?]) \ {c}
o
9SchedNext
This is
TerminateSelf
ΞSCHED
∆PTAB
serr! : SYSERR
∃c : PID : PTAB •
curr = c ∧
(state′′ = state ⊕{c →psterm} ∧
c ∈used ∧
used ′ = used \ {c} ∧
serr! = sysok)
∨serr! = unusedpd
o
9SchedNext
This is equivalent to
∃PTAB •
state′′ = state ⊕{curr →psterm} ∧
(curr ∈used ∧
used ′ = used \ {curr} ∧
serr! = sysok)
∨serr! = unusedpd
o
9SchedNext
and to
TerminateSelf
∆PTAB
serr! : SYSERR
((state′ = state ⊕{curr →psterm} ∧curr ∈used ∧used ′ = used \ {curr} ∧
serr! = sysok)
∨serr! = unusedpd)
o
9SchedNext

196
3 A Simple Kernel
The precondition can be written as
pre TerminateSelf = curr ∈used ∧pre SchedNext
or as
pre TerminateSelf =
curr ∈used ∧
curr = iprc
∨sq.pq = ⟨⟩
∨(state(curr) ̸= psready ∨state(curr) ̸= psrunning
∨prio(head sq.pq) < prio(curr))
The operation reﬁnes as follows. It can be seen that the deﬁnition involves
components that can not be further reﬁned. This suggests that the reﬁnement
be of
SetProcessStateToTerminated[curr/p?]
o
9DelPD[curr/p?]
The reﬁnement of SchedNext is that of a promotion, so it can be removed
from the process.
First, the following operation is required.
SetProcessStateToTerminated1
∆PTAB
p? : PID
state1′ = state1 ⊕{p? →psterm}
TerminateSelf 1 =
EnterCritical
o
9((CurrentProcessId[c/p!] ∧
SetProcessStateToTerminated1[c/p?])
o
9FreePID1[c/p?]) \ {c}
o
9SchedNext1
The inner composition expands into, after use of the one-point rule, is
state1′ = state ⊕{curr →psterm} ∧
((dom freech = ∅∧
freech′ = freech ∪{curr →nullpid} ∧
endfree′ = curr ∧
hdfree′ = curr ∧
serr! = sysok)
∨(curr ̸∈dom freech ∧
freech′ = (freech ⊕{endfree →curr}) ∪{curr →nullpid} ∧
endfree′ = curr ∧
serr! = sysok))
∨serr! = usedpd

3.12 User Interface
197
In this kernel, process can change their priority. The following is the deﬁ-
nition of this operation.
ChangeMyPriority =
EnterCritical
o
9(CurrentProcessId[c/p!] ∧SetProcPrio[c/p?]) \ {c}
o
9ExitCritical
This deﬁnition expands into the following schema:
ChangeMyPriority
∆HARDWARE
∆PTAB
pr? : PPRIO
EnterCritical
o
9(∃c : PID •
c = curr ∧
prio′ = prio ⊕{c →pr?})
o
9ExitCritical
which simpliﬁes, using the one-point rule, to
ChangeMyPriority
∆HARDWARE
∆PTAB
pr? : PPRIO
EnterCritical
o
9prio′ = prio ⊕{curr →pr?}
o
9ExitCritical
The reﬁnement of this operation has already been undertaken. It is the
reﬁnement of SetProcPrio (with the substitution of curr for p?).
Its ﬁrst reﬁnement is
ChangeMyPriority1
∆HARDWARE
∆PTAB1
pr? : PPRIO
EnterCritical
o
9prio1′ = prio1 ⊕{curr →pr?}
o
9ExitCritical
The second reﬁnement of ChangeMyPriority is

198
3 A Simple Kernel
ChangeMyPriority2
∆HARDWARE
∆PTAB2
pr? : PPRIO
EnterCritical
o
9prio2′ = prio2 ⊕{curr →pr?}
o
9ExitCritical
One way for a process to obtain is identiﬁer is by calling the following
operation:
MyProcessId =
EnterCritical
o
9CurrentProcessId
o
9ExitCritical
This expands into
MyProcessId
∆HARDWARE
ΞSCHED
p! : PID
EnterCritical
p! = curr
o
9ExitCritical
This schema does not reﬁne. The reason for this is that SCHED does not
reﬁne (although its component priority queue does).
3.12.4 Inter-process Communication and Synchronisation
This consists of semaphore operations:
•
Allocate and intialise semaphores in semaphore table
•
Wait
•
Signal
•
Deallocate semaphore
As noted above, it is always the current process that calls these operations.
The use of curr is already handled in the semaphore operations WaitSema and
SignalSema but not in the operations to allocate and deallocate semaphores
in the semaphore table.
AllocateSemaphore =
EnterCritical
o
9AllocSema
o
9ExitCritical

3.12 User Interface
199
Apart from being wrapped in the interrupt ﬂag operations, this operation is
just AllocSema. It reﬁnes to AllocSema1 and its precondition is
pre AllocateSemaphore = pre AllocSema
DeallocateSemaphore =
EnterCritical
o
9ReleaseSema
o
9ExitCritical
This reﬁnes to ReleaseSema1 for reasons similar to that mentioned above.
The precondition is, trivially,
pre DeallocateSemaphore = pre ReleaseSema
The wait and signal operations on semaphores are, here, those deﬁned in
terms of the semaphore table. As will be remembered, wait and signal are
provided by the semaphore table as promoted operations. There is no need
to reﬁne these operations because the semaphore table’s reﬁnement already
takes care of them in the sense that the reﬁnement of the table is independent
of the reﬁnement of the semaphore operations proper.
SemaphoreWait =
EnterCritical
o
9STWaitSema
o
9ExitCritical
The precondition is unaﬀected by the locking operations
pre SemaphoreWait = pre SemaWait
SemaphoreSignal =
EnterCritical
o
9STSignalSema
o
9ExitCritial
pre SemaphoreSignal = pre SemaSignal
The message operations
•
Send synchronous message
•
Receive synchronous message
are supported.
First, the send operation.

200
3 A Simple Kernel
SendSMsg =
EnterCritical
o
9(CurrentProcessId[c/p!] ∧
MakeMessage[c/sndr?] ∧SendASynchMsg[c/p?, m/m?]) \ {c, m}
o
9ExitCritical
Ignoring the critical-section operations (they reﬁne to themselves, in any case),
this partially expands into
SendSMsg
∆HARDWARE
∆SCHED
dest? : PID
payload? : MDATA
∃c : PID; m : MSG | c = curr ∧m = mkmsg(curr, dest?, payload?) •
SendASynchMsg[c/p?, m/m?]
This particular schema expands into
SendSMsg
∆PTAB
∆SCHED
dest? : PID
payload? : MDATA
serr! : SYSERR
(dest? ∈used ∧
((state(dest?) = psreceiving ∧
((smsgs(dest?) = nullmsg ∧
smsgs′ = smsgs ⊕{dest? →mkmsg(curr, dest?, payload?)} ∧
state′ = state ⊕{curr →pssending, dest? →psready} ∧
((pq = ⟨⟩∧curr ′ = dest?)
∨((#pq < maxs ∧
(prio(dest?) ≤prio(head pq) ∧curr ′ = dest?)
∨(((prio(last pq) < prio(dest?) ∧
pq′ = (tail pq) ⌢⟨dest?⟩)
(∃s1, s2 : seq PID | s1 ̸= ⟨⟩∧s2 ̸= ⟨⟩∧s1 ⌢s2 = pq •
prio(last s1) < prio(dest?) ∧
prio(dest?) ≤prio(head s2) ∧
pq′ = (tail s1) ⌢⟨dest?⟩⌢s2)) ∧
curr ′ = head pq) ∧
prev ′ = curr ∧serr! = sysok)
∨serr! = schedqfull)))
∨serr! = procalreadyhasmsg))

3.12 User Interface
201
∨serr! = destinationnotrcving))
∨serr! = badmsgdestination
This is merely a substitution instance of the predicate of SendASynchMsg, so
the reﬁnement is identical to that of SendASynchMsg.
pre SendSMsg = SendASynchMsg
Next, the receive operation.
RcvSMsg =
EnterCritical
o
9(CurrentProcessId[c/p!] ∧ReceiveSynchMsg[c/p?]) \ {c}
o
9ExitCritical
The RcvSMsg schema is a substition instance of ReceiveSynchMsg, so it has
already been reﬁned.
pre RcvSMsg = ReceiveSynchMsg
Finally, an operation that ﬁrst puts the calling process to sleep for a spec-
iﬁed time and then tries to receive a message.
3.12.5 Clock Operations and the Clock ISR
In this section, we include the operations of the clock and the system operation
FindAndWake an operation that is invoked on every clock tick.
The clock is intended as an interrupt-service routine that is executed when-
ever there is a clock interrupt. On activation, the time-denoting variables are
updated and the list of waiting processes is searched to determine whether
there are any processes to activate. These operations are performed when
interrupts are disabled, so there is no need to put them in a critical section.
SystemClockOps =
UpdateTIMESINCEBOOT
o
9(TimeNow[now/tn!] ∧UpdateClockTime[now/t?] ∧
FindAndWake[now/now?]) \ {now}
If an interrupt-service routine is required, here it is:
CLOCKISR = SystemClockOps
The expansion of the deﬁnition of SystemClockOps is the following schema.
This is again a case in which promotion does much of the work; the rest is
handled by the fact that simple variables reﬁne to themselves.

202
3 A Simple Kernel
SystemClockOps
∆TIMESINCEBOOT
∆CLOCKTIME
∆SLEEPERS
∆SCHED
tnow ′ = tnow + ticklength
∃now : TIME | now = tnow ′ ∧
((now mod tickspersec = 0) ∧
((secs + 1 mod 60 = 0 ∧
secs′ = 0 ∧
((mins + 1 mod 60 = 0 ∧
mins′ = 0 ∧
hrs′ = hrs + 1)
∨mins′ = mins + 1))
∨secs′ = secs + 1)) ∧
slps ̸= ∅∧
(∀p : PID | p ∈slps ∧0 < waitingtime(p) ≤now •
slps′ = slps \ {p} ∧
waitingtime′ = waitingtime ⊕{p →0} ∧
MakeReady[p/p?])
This simpliﬁes to
((tnow + ticklength mod tickspersec = 0) ∧
((secs + 1 mod 60 = 0 ∧secs′ = 0 ∧
((mins + 1 mod 60 = 0 ∧mins′ = 0 ∧hrs′ = hrs + 1)
∨mins′ = mins + 1))
∨secs′ = secs + 1)) ∧
slps ̸= ∅∧
(∀p : PID | p ∈slps ∧0 < waitingtime(p) ≤tnow + ticklength •
slps′ = slps \ {p} ∧
waitingtime′ = waitingtime ⊕{p →0} ∧
MakeReady[p/p?])
3.12.6 Final Remarks
Some operations deﬁned in this section cannot be further reﬁned (e.g., the
stack initialisation operation) but others can and their reﬁnement has been
outlined in this section. It is now an easy step to translate the resulting
schemata results into executable code. We have, with this, concluded the
reﬁnement of the ﬁrst kernel.

4
The Separation Kernel
The next reﬁnement is of a Separation Kernel. The Separation Kernel is an
architecture introduced by John Rushby as an architecture of cryptographic
and other secure applications [11].
The purpose of this chapter is to describe the architecture and to outline
its reﬁnement.
4.1 Basic Architecture
The architecture of the Separation Kernel is simple. It is a single-processor
model of a distributed system in which all user processes are separated in
time and space from each other. In a distributed system, the execution of
each process takes place in a manner independent of any other. Processes can
wait for data inputs, particularly inputs from communications channels. For
the remainder of the time, the component processes execute at rates inde-
pendent of all others. There is, in a distributed system, temporal separation
between the execution of one process and all other processes. Separation in
space means that the processes constituting a distributed system each have
their own disjoint address spaces. If two address spaces are disjoint, it is not
possible for one process directly to write to the address space of any other
process.
The Separation Kernel is based on these two fundamental observations.
Separation in time results from the fact that no two processes can be ac-
tive at exactly the same time. Furthermore, if processes communicate using
asynchronous channels, no synchronisation points are required, so processes
can proceed at their own rate. Separation in space results from the fact that
processes are allocated their own disjoint address spaces.
Temporal separation can be enforced by the system’s scheduler and by
a message-passing system. On a uni-processor system, the scheduler ensures
that only one process executes at any time and executions are interleaved in
time. The length of time during which any process will be executing (be

204
4 The Separation Kernel
active) depends upon the scheduling algorithm and, as will be seen, the
algorithm proposed by Rushby is particularly simple. In addition, the use
of asynchronous messages means that processes do not synchronise during
the exchange of messages, although they are permitted to wait for responses
or results to be returned. Even in the case of waiting for a response, the wait-
ing state depends upon the algorithms used to implement processes, not upon
the underlying system.
Spatial separation can be enforced by segmentation. Most processors sup-
porting segmented address spaces also have mechanisms for detecting and
reacting to attempts by one process to access the segments of another. On
the Intel IA32 and IA64 machines, for example, attempts to cross segment
boundaries causes a hardware exception; a handler can be provided to handle
the exception by, for example, killing the oﬀending process. Each process is,
therefore, allocated one or more segments. Should a process, either by error or
through malice, attempt to address a location in another process’ segments,
the hardware should cause an exception to be raised. This permits the kernel
to detect such illegal accesses and to perform some action.
The original proposal for the Separation Kernel was included the stipula-
tion that a round-robin scheduler would be adequate. The round-robin scheme
can be used in real-time applications because of its simplicity; it can also be
used to simulate distributed systems because processes only enter the queue
when they are ready to execute. Temporal separation is supported by the fact
that, under pure round-robin, there is no a priori limit to the length of the
period during which a process can execute. In many systems, timeslicing is
used to share the processor between processes; each process is permitted to
execute for a deﬁned period of time and, when this period is exhausted, the
process is suspended and another continues its execution. The property that
round-robin scheduling allows processes to execute for indeﬁnite periods must
be qualiﬁed. Processes execute until such time as they are no longer able to
continue and at such a time, they must relinquish the processor. Processes
relinquish the processor either on a purely voluntary basis by executing a
voluntary suspension operation or by executing some other operation whose
deﬁnition includes the an operator that suspends the caller. The primitive
that sends messages might suspend the caller, for example.
It should be clear that the kernel must reside in an address space that is
disjoint from all user address spaces. This ensures that the kernel is protected
against malicious processes. Furthermore, it is also separated in time because,
by deﬁnition, it executes only when processes do not. In order to enforce
the spatio-temporal separation of the kernel, it is essential to deﬁne a clean
interface between it and user processes.

4.2 Extending the Architecture
205
4.2 Extending the Architecture
The Separation Kernel deﬁnes a basic and simple set of mechanisms for mana-
ging secure applications. It makes a distinction between trusted software (the
kernel) and untrusted software (applications in user processes). The architec-
ture requires some extension in order to include devices such as communica-
tions lines, printers and so on.
The US National Security Agency has produced an extension to the Sepa-
ration Kernel architecture [10] so that device handling can be included. This
introduces the concept of “trusted” code into the system. The context in
which trusted code is introduced is the following. The document [10] assumes
that the kernel proper is formally speciﬁed and that its properties are there-
fore well understood. Because it is formally speciﬁed, it is completely trusted.
User processes are completely untrusted; this is because they are not under
the control of the developers of the kernel and are assumed not to have been
formally constructed. There is no control, it is assumed, over the content of
user processes. Device processes (drivers and associated support code) require
greater access to kernel facilities and might have to do such things as allocating
their own storage, directly accessing the scheduler queues, and so on. This has
the implication that devices should only be introduced into a secure system
if they are trusted to a much greater extent than user code. The production
of device-related code must be carefully controlled. Ideally, this code would
be constructed using formal methods. One reason for assuming that it is not
so constructed is the range of possible hardware that any implementation of
the Separation Kernel can control (this is quite reasonable—it is a constraint
adopted for the work in reported in this book and was also adopted in our
[4]). A second reason is that the NSA probably do not believe that device-
handling code can be constructed formally—our opinion is at variance with
theirs (and we have unpublished cases that tend to support our position). No
matter what the reason, it is important that device-handling code should be
trusted.
It is important, then, to support device-handling code. This kind of code
needs to be fast and it needs access to low-level facilties. One way to sup-
port device-handling is to make the kernel open. This subverts the whole
project. Instead, it is better to deﬁne and formally construct an interface to
the kernel for use by device-handling code. The interface should only give
device code access to a miminal set of services. In particular, it should deﬁne
operations that
•
Pass parameters from and to requesting user processes.
•
Allow device-handling processes to suspend themselves.
•
Cause device-handling processes to become active (i.e., to enter the sched-
uler’s queue of processes ready to execute).
In addition, it should be possible to determine whether the services requested
by user processes correspond to what is possible.

206
4 The Separation Kernel
Kernel Space
Device
Process1
ISR1
Device
Processn
ISRn
Sep Kern
User Process Space1
User Process Spacem
Fig. 4.1. Devices and interfaces in the Separation Kernel.
This is the approach adopted in this book. A set of operations is deﬁned
that provide exactly those capabilities listed above. In addition, devices are
represented by “device numbers” as far as user processes are concerned. The
kernel maps device numbers to actual devices, thus decoupling device (service)
naming from the devices themselves (it also allows for some ﬂexibility in the
kernel). Some might object that device numbers are a low-level representation.
The reply is that user processes use library calls to request such services; the
bottom level of such libraries will use device numbers, not the higher levels
and not user code.
4.3 Summary
The Separation Kernel can be summarised as follows
•
A segmented main store that is supported by the processor hardware.
•
A round-robin scheduling r´egime.
•
Natural-break scheduling by user and device processes.
•
A well-deﬁned set of interfaces for device-handling processes.
•
A well-deﬁned interface for user processes (see Figure 4.2).
The internal organisation of our Separation Kernel can be seen in Figure 4.2.

4.4 An Overview of the Formal Speciﬁcation
207
User-Process Interface
Processes Repn
R-R Scheduler
Main Store Allocator
Ctx Sw
Msg Buffer Area
Device 
Process
Interface
Fig. 4.2. The internal organisation of our Separation Kernel.
4.4 An Overview of the Formal Speciﬁcation
The purpose of this section is to describe in outline the formal speciﬁcation
of the Separation Kernel that is included in this book. In particular, it out-
lines the structures included in the kernel and attempts to make clear the
assumptions upon which the major decisions were made.
The ﬁrst thing to note is that a number of components are the same in
the Separation Kernel and in the simple kernel that precedes it in this book.
Firstly, the process table’s general format is identical in both cases; the two
tables contain slightly diﬀerent information but the representations are the
same in both cases. Second, the primary data structure used by the Separa-
tion Kernel’s scheduler is a pair of FIFO queues. The round-robin scheduling
r´egime only requires a simple FIFO for its implementation. Processes enter
the queue at the end and progressively move to the head; when a process
reaches the head of the queue, it is ready to execute. The Separation Ker-
nel requires two FIFOs in its scheduler: one for user processes and one for
device processes (device-handling processes, that is). The reason for this is
that device processes run at a higher priority than user processes. This spec-
iﬁcation uses a synchronous I/O model. For present purposes, it is assumed
that device processes are concerned with input and output operations, so
the model seems appropriate. This choice has the consequence that device

208
4 The Separation Kernel
processes can be scheduled in a strictly FIFO manner. Further consequences
of these decisions are:
•
The process table’s reﬁnement can proceed by analogy with that in the
ﬁrst kernel’s reﬁnement. We include the full reﬁnement, however.
•
The reﬁnement of the FIFO can be taken directly from that in the earlier
kernel.
This makes the reﬁnement of the Separation Kernel a little simpler.
The operations required by the scheduler diﬀer from those in the ﬁrst
kernel. However, the reﬁnement relations are identities, so the necessary proofs
are straightforward.
The major problem is the asynchronous message-passing component. One
issue is preventing processes from evesdropping. For this reason, it was decided
that messages would be handed to the kernel and the kernel would then copy
them to kernel space. Copying is not usually a good idea because it requires
space and time to perform. However, there seemed to be no alternative. This
decision requires that the kernel allocates a buﬀer area for messages. It has
the consequence that the message queues owned by user processes can contain
pointers to messages stored in the kernel’s buﬀer area. This poses no problems
from the speciﬁcation viewpoint but it does require some form of pointer-
dereference operation is required when handing the message to the destination
when it is to be read. It is also necessary to have a mechanism for deleting
the store occupied by a message when it is no longer required. It is clear that
such deletion cannot be left to user processes (for one thing, it provides an
appealing way to crash the system).
The low-level message operations are implemented using a type that rep-
resents the buﬀer space itself (essentially a vector of storage elements, say
bytes) together with storage-management operations. The latter is provided
by the same mechanisms that is used to allocate the large chunks of store that
hold processes and their data and stack areas. The diﬀerence between the two
is some renaming and the scales upon which the two instances act. This is
another case in which we were able to re-use speciﬁcations and reﬁnements in
the development of a new speciﬁcation.
In both cases, the storage manager uses tables that are separate from
the store that is managed. Some might object to this. The two could be
conﬂated to form a single module. This would require a number of type-
transfer functions, as well as other very low-level operations. There is much
detail in this work1 that does not add much to the overall presentation. There
is another reason. In the case of the main store allocator, the aim is to have
separate segments that are allocated from a pool that, in essence, belongs
to no-one. We do not want anything to reside in the main store that could
be used by a malicious process. The separation of store from its description
1 This statement is based on experience. We have attempted this very conﬂation
in other, unpublished, work.

4.4 An Overview of the Formal Speciﬁcation
209
achieves this, even at a cost. All the pointers and size annotations in the
scheme adopted here are in a space that is formally speciﬁed and under the
control of formally speciﬁed operations; there is no data in places where other
processes can manipulate them.
The design of the Separation Kernel should ensure security. As stated,
user processes cannot be trusted, while device processes can. Trust can be
maintained by ensuring that certain development methods be followed and
that development is done by trusted persons under appropriate supervision.
However, as far as the speciﬁcation and its reﬁnement are concerned, this
has a number of consequences. First, an interface must be deﬁned to support
device processes. A device process is a device driver and requires access to
a set of kernel functions and to ﬁxed chunks of main store that it and its
associated ISR use to hold data during transfer.
The kernel operations are mostly those supporting processes but a security
“feature” of this speciﬁcation is that device processes are known by a device
number, a small numeric code that denotes a device process (and associated
device); device numbers are allocated when the system is conﬁgured. Further-
more, device processes do not have external identiﬁers; instead, their device
number serves as their identiﬁer. Message passing between device processes
is not permitted, but there is the requirement that user processes be able to
send data to and receive data from device processes; this impacts upon the
interface presented by device processes.
The speciﬁcation contains a separate module that implements the inter-
face required by device processes. The aim of this module is to provide the
minimum set of operations required by device processes in order to do their
job. This set of operations is also required to isolate the kernel from device
processes so that the latter are required
1. To know as little possible about the kernel and its operations, and
2. To make the task of interfacing device processes as simple as possible.
It is assumed that there is some way to map main store in the kernel segment so
that shared memory can be allocated; if this is not possible, it is relatively easy
to introduce another storage manager, one distinct from the others employed
in this system (for security reasons).
As is the case with the other kernel, there are low-level operations that
require the direct use of machine-level operations. As before, there are the
context-switch and interrupt-related operations to be speciﬁed. There are also
ISRs to be speciﬁed. The approach adopted here is diﬀerent from that in the
other kernel. In particular, it is assumed that the Separation Kernel will exe-
cute on the Intel IA32/64 range of processors. This permits us to exploit the
task-management instructions provided by them. Furthermore, there a prob-
lems with the management of a segmented store. The hardware instructions
solve these problems for us2.
2 In the current case, we have not examined the implications of porting it to another
hardware architecture such as the MIPS or ARM.

5
A Separation Kernel
This chapter is concerned with the speciﬁcation and reﬁnement of a Separation
Kernel. This, as described in the last chapter, is a type of kernel that was
speciﬁcally designed for cryptographic and other secure applications.
The speciﬁcation and reﬁnement in this chapter relies to a certain extent
on the existence of components that were speciﬁed and reﬁned in the chapter
on the simple kernel (Chapter 3). In particular, the queue types used to deﬁne
the Separation Kernel’s round-robin scheduler were speciﬁed in full in Chapter
3. The process representation employed in this chapter is related to that used
for the earlier exercise.
The abstraction relations in this reﬁnement are all identities (which is not
at all unusual). This allows the reﬁnement process to be shortened somewhat,
for, once the abstraction relation has been identiﬁed, it is possible immediately
to write out the reﬁnements of the various operations. Furthermore, since the
relationship between speciﬁcation and reﬁnement is that of identity, there
is, strictly speaking, no need to engage in a proof. Below, we do present
proofs, mainly for new state spaces or for state spaces that are markedly
diﬀerent from those in the previous reﬁnement; we believe that these proofs
are worth doing and recording as a safety check (they are, in any case, almost
entirely straightforward). We are therefore permitted to reduce the length of
the current chapter by the omission of much immediately derivable material.
5.1 Basic Types
We need to deﬁne the main types to be used by the Separation Kernel. The
reader will ﬁnd the majority of the types familiar from Chapter 3.
First, a type that will take the place of explicit truth values:
YESNO ::= yes | no
The type for process identiﬁers is very much as in the previous exercise.

212
5 A Separation Kernel
PID = minpid . . maxpid
GPID = {nullpid} ∪PID
In this speciﬁcation, the nullpid, null process value is also required.
nullpid : N
∀p : PID •
nullpid < p
This last deﬁnition might need a bit of a tweak.
Since this is a secure kernel, it is necessary to have a naming scheme for
user processes. These names are intended to be unrelated to process identiﬁers.
The simplest form of user identiﬁer is to use a natural number to denote each
process. It is assumed that the supply of natural numbers is large enough to
suit the needs of the user.
UPID = N
We need to distinguish between user and device processes for scheduling
purposes.
PTYPE ::= uproc | dproc
The reason for this is that the scheduler maintains two queues: one for user
processes and one for device processes. Device processes are always at a higher
priority than user processes.
Device processes are assumed to be trusted code that controls peripheral
devices. They reside within the kernel’s address space and are independent of
user processes.
Devices are identiﬁed by a unique number (the “device” or “service” num-
ber).
mindev, maxdev : N
mindev < maxdev
These two values determine the type DEVNO:
DEVNO == mindev . . maxdev
All Separation Kernel processes are in a unique state at any time. The
Separation Kernel has fewer types than the one in Chapter 3.
PSTATE ::= psterm
|
psrunning
|
psready
|
psdevwait
|
pswtgdev

5.1 Basic Types
213
The last value of PSTATE denotes the state in which a device process is
waiting for a request from a user process or when it is waiting for a device to
return data to it.
The ADDR type deﬁnes addresses. Addresses must be between 0 and the
maximum address supported by the particular processor being used (or some
other a priori limit).
ADDR == nulladdr . . maxaddr
nulladdr : N
maxaddr : N
nulladdr = 0
nulladdr < maxaddr
The following type
[PSU ]
denotes the Primary Storage Unit. On some machines, this is 8 bits, while on
others it is 16-, 32- or 64-bits. It is the unit by which main store is addressed
and is used in the speciﬁcation of storage mechanisms.
[MSG]
[MSGDATA]
nullmsg : MSG
Although there is no use put to the following, it is still useful to include it as
a reminder that messages containing no data are also possible.
nullmsgdata : MSGDATA
User processes communicate with the Separation Kernel using struc-
tures that look rather like messages (even though they are not handled like
messages—a somewhat more direct method is used). Each “message” has a
single opcode to denote its function. The type to which opcodes belong is
SYSOPCODE:
SYSOPCODE ::= newuproc
|
suspself
|
termself
|
sndmsg
|
gotmsgs
|
gotmsgfromsrc
|
nextmsg
|
nextmsgfromsrc
|
devrequest

214
5 A Separation Kernel
Finally, we still need the error type. Here it is:
SYSERR ::= sysok
|
unusedpd
|
pdinuse
|
ptabfull
|
emptyqueue
|
nospaceinstore
|
blocklocerror
|
badblockaddr
|
msgqfull
|
emptymsgq
|
nomsgsfrom
|
calleridentmismatch
|
mainstorefull
|
badmsgdest??
|
nodevreply
|
baddevnum
|
badcallerid
In this kernel, the latest error is stored in a global variable. The variable
is the state component of the following schema:
ERRV
serr : SYSERR
This variable is updated by various kernel operations and could be inspected
by user processes. At present, the user-level operation required to inspect serr
is not provided; its inclusion is a simple matter, though.
The error variable is initially set to ok:
ERRVInit
ERRV ′
serr ′ = sysok
The error variable is set by the following operation
SetSysErr
∆ERRV
e? : SYSERR
serr ′ = e?
and is read by the next one

5.2 Hardware Issues
215
SysErr
ΞERRV
e! : SYSERR
e! = serr
We deﬁne an abbreviation for recording the fact that an operation has
gone according to plan.
SysOk = (∃e : SYSERR | e = sysok • SetSysErr[e/e?])
5.2 Hardware Issues
In the case of the Separation Kernel, we are aiming our speciﬁcation mostly
at the Intel IA32/64 architectures in uni-processor versions only (we could
run on a multi-core by executing on one processor only but this will still
complicate our assumptions and require some additional machinery).
The IA32 architecture supports tasking by providing appropriate instruc-
tions and data formats. In particular, it has a structure called a TSS (Task
Structure Segment) which contains all the registers of a process (including its
segment registers).
Since we are aiming at an IA32 implementation, it will be necessary to
refer to TSSs from within this speciﬁcation, it is necessary to deﬁne a type
[TSS]
A few functions need to be deﬁned:
tss stacktop : TSS →ADDR
tss stackseg : TSS →ADDR
The ﬁrst returns a pointer to the top of the current stack (often the ESP
registers on the Intel IA32), the second returns the start address (the base)
of the segment in which the stack resides.
The TSS must be pointed to by the process descriptor. It is necessary to
deﬁne the TSS table, together with allocation and deallocation operations.
We sketch them only.
HW
...
tsstab : seq TSS
...
We assume an operation AllocateTSS that allocates the TSS table in main
store; we also assume that AllocateIDT is deﬁned—this is the operation to
allocate the IDT (interrupt vector) in main store.

216
5 A Separation Kernel
The AllocateProcTSS operation allocates a TSS when a new process is
allocated.
AllocateProcTSS
∆HW
...
tss! : TSS
...
...
When a process terminates, its TSS must be returned to the pool. This is
the outline of the deallocation operation that returns a process’ TSS to the
free pool.
DeallocateTSS
∆HW
p? : PID
tss? : TSS
...
...
The process table must refer to TSS:
PTAB
...
tss : PID →TSS
...
dom tss = used
∀p : PID •
p ∈dom tss ⇔ptype(p) = uproc
(We assume that device processes have a TSS.)
The context switch proper now handled by a single instruction and can be
deﬁned as
ContextSwitch
∆HARDWARE
outproc? : PID
jmp tss(outproc?)
This will automatically switch between the currently running process and
outproc?. The IA32/64 processor records the identity of the suspended process
(however, it will be recorded by software).

5.2 Hardware Issues
217
The IA32 makes the combination of interrupts and context switches nat-
ural. Therefore, the context-switching mechanism will be speciﬁed as interrupt
driven. To do this, an interrupt number is allocated for the context switch op-
eration and an ISR that acutally performs the context switch (by calling the
ContextSwitch operation, in particular), must be deﬁned. Inside the kernel,
an operation to cause an interrupt must be deﬁned.
First, we deﬁne the interrupt type. As far as we are concerned, interrupts
are just small positive integers:
minint, maxint : N
minint < maxint
INTNO == minint . . maxint
The operation of causing a software interrupt is performed by the following
operation:
RaiseInterrupt
∆HW
ino? : INTNO
intno′ = ino?
The number of the interrupt that causes system termination is (partially)
deﬁned as
killintno : INTNO
The operation to cause killintno is
RaiseKillInterrupt =
∃ino : INTNO | ino = killintno •
RaiseInterrupt[ino/ino?]
Below, more will be said on the content of the ISR that must service this
interrupt.
Finally, we deﬁne the number of the interrupt that will cause the context
switch
ctxtswintno : INTNO
The operation that causes this interrupt is the following
CTXTSW =
∃ino : INTNO | ino = ctxtswintno •
RaiseInterrupt[ino/ino?]
There is very little else to say about context switches because the IA32 handles
the rest. It switches registers between TSSs when context switches occur. This
is very pleasant for IA32 users; for users of other processors, more work will
have to be done.

218
5 A Separation Kernel
5.3 Security Exits and Return Values
In this kernel design, the information returned to users is deliberately minimal.
This is so that malicious users can infer as little as possible about what has
happened.
In some cases of error, the kernel halts and all processes are killed. This
can occur, for example, if an attempt is made to create more processes than
there are slots in the process table or if a segmentation fault occurs. The
kernel kill prints a message stating “Kernel halted. Security violation?”. This
requires the types
CHAR == ‘a′ . . ‘z ′,
‘A′ . . ‘Z ′,
‘0′ . . ‘9′,
‘.′, ‘,′ , ‘\n′, ‘?′
(where ‘\n’ is the newline character, as in C; other characters can be assumed
as required) and
STRING == seq CHAR
The printing is eﬀected by the following operation
PrintKMsg
km? : STRING
kprint(km?)
It is assumed that there is some mechanism outside of the kernel that can
print a string on some screen or send it elsewhere. The kprint operation is not
further speciﬁed. It is hardware dependent.
Next, we deﬁne a mechanism which will halt the processor and kill all
current processes. It should do this when a fatal error occurs. The operation
is to be called from an ISR that is executed as a result of some piece of code
raising the killintno interrupt. This interrupt is raised to signal the fatal error.
The kernel kill operation requires the DeleteAllProcesses operation deﬁned
over the process table (PTAB). It also sets the current process to the idle
process.
KillKernel =
(IDLEPROCESSIdent[ip/p!] ∧
UpdateCurrentProcess[ip/p?]) \ {ip}
o
9DeleteAllProcesses
o
9(∃msg : STRING | msg = “Kernel halted. Security violation?′′ •
PrintKMsg[msg/km?])
This deﬁnition expands into the following schema.

5.4 The Process Table
219
KillKernel
∆PTAB
∃ip : PID •
ip = ipid ∧
curr ′ = ip ∧
prev ′ = curr ∧
used ′ = ∅∧
(∃msg : STRING | msg = “Kernel halted. Security violation?′′ •
kprint(msg))
The KillKernel schema can then be simpliﬁed and we obtain (using the one-
point rule):
KillKernel
∆PTAB
curr ′ = ipid
prev ′ = curr ′
used ′ = ∅
kprint(“Kernel halted. Security violation?′′)
The KillKernel operation is intended to constitute a generic ISR. This ISR
is executed whenever a lethal (or in the present case, any) error is encoun-
tered. For simplicity, as well as to demonstrate the paranoia principle, this
speciﬁcation and its reﬁnement treats all errors as possible indications that
something untoward has happened, so the KillKernel operation is invoked for
every error.
5.4 The Process Table
The process table is very similar to that used by the ﬁrst system.
First, the error schemata are deﬁned.
UnusedPD =
(∃e : SYSERR | e = unusedpd •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
When it is detected that a process identiﬁer has already been allocated,
the error is raised by the following schema:
PDInUse =
(∃e : SYSERR | e = pdinuse •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt

220
5 A Separation Kernel
If an attempt to allocate more process identiﬁers than there are slots in
the process table, the following schema is used to report the error.
PTABFull =
(∃e : SYSERR | e = ptabfull •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
5.4.1 Top Level
This speciﬁcation organises the process table as a collection of arrays. At
the top level, the arrays are modelled as partial functions whose domain is
almost always PID, the type of process identiﬁers. The reader will see that the
process table, again called PTAB, is somewhat more complex than the one
used in Chapter 3. In particular, the need to provide user-oriented identiﬁers
for user processes introduces the nextupid, extpid and pidext variables. The
variables devmap, devrqs and devrpy are used to support device processes.
The remainder of the variables are common to user and device processes.
PTAB
nextupid : UPID
extpid : UPID →PID
pidext : PID →UPID
used : F PID
tss : PID →TSS
devmap : DEVNO →PID
state : PID →PSTATE
ptype : PID →PTYPE
msgq : PID →MSGQ
devrqs : PID →MSG
devmsg : PID →(GPID × MSG)
devrpy : PID →MSG
cdseg : PID →SDESC
dsseg : PID →SDESC
∃devs, uprocs : F PID |
devs = {p : PID | p ∈used ∧ptype(p) = dproc} ∧
uprocs = {p : PID | p ∈used ∧ptype(p) ̸= dproc} •
used = dom state ∧
used = dom ptype ∧
uprocs = dom cdseg ∧
uprocs = dom dsseg ∧
used = dom tss ∧
ran devmap = dprocs ∧
uprocs = dom msgq ∧

5.4 The Process Table
221
dprocs = dom devrqs ∧
dprocs = dom devmsg ∧
dprocs = dom devrpy
ran extpid = uprocs
dom pidext = uprocs
pidext = extpid −1
∀d : DEVNO •
d ∈dom devmap ⇒
∃1 p : PID •
p = devmap(d)
The invariant of this schema is somewhat more complex than in the corre-
sponding one in Chapter 3. This is because some components relate only to
device processes. For example, device processes have device numbers, which
are stored in the devmap variable, while the identiﬁers user processes are given
to identify themselves and other processes are stored in pidext and extpid.
Note that these two functions are mutually inverse. The pidext map trans-
lates internal process identiﬁers to external ones, while extpid performs the
inverse operation. We decided to have two functions to make the operations
more explicit.
The various components will be explained in more detail when the relevant
operations are deﬁned.
We can deﬁne free as:
PID \ used = free
This is the same as in Chapter 3, so proofs involving used and free identiﬁers
will be the same here as they were there.
The initialisation operation for this version of PTAB is scarcely more com-
plex than the other one. The diﬀerence is that the external process identiﬁer
source, nextupid, must be initialised to 1.
PTABInit
PTAB ′
used ′ = ∅
nextupid ′ = 1
The following is a schema that is true when the internal process identiﬁer,
p?, is an element of used.
UsedPID
ΞPTAB
p? : PID
p? ∈used

222
5 A Separation Kernel
The next schema deﬁnes a predicate. The interpretation and justiﬁcation
for this schema is the same in this case as in the previous one.
GotFreePIDs
ΞPTAB
used ⊂PID
In this kernel, process identiﬁers are allocated by a non-deterministic op-
eration, called AllocPID. This operation is the same as in the previous speci-
ﬁcation.
AllocPID
∆PTAB
p! : PID
p! ̸∈used
used ′ = used ∪{p!}
In this kernel, however, we do not want user processes to have any knowledge
of the workings of the kernel. One aspect of this is that we do not want user
processes to know what their process identiﬁer (an element of PID) is. This is
achieved by allocating another identiﬁer, an element of UPID, which can be
used by user processes. This requires translation between PID and UPID at
various points in the kernel but this is a small price for privacy. The operation
to allocate an element of UPID is deﬁned by the following schema.
AllocUPID
∆PTAB
u! : UPID
u! = nextupid
nextupid ′ = nextupid + 1
The operation is, itself, quite simple. The current value of nextupid is used as
the external process identiﬁer. The counter, nextupid, is then incremented by
one.
The following schema deﬁnes an operation that adds an external identiﬁer
to the extpid external identiﬁer mapping table.
AddProcUPID
∆PTAB
p? : PID
u? : UPID
extpid ′ = extpid ⊕{u? →p?}
When a user process is created, the following operation is used to generate
the two identiﬁers associated with it.

5.4 The Process Table
223
NewUPIDForProcess =
AllocPID ∧
AllocUPID ∧
AddProcUPID[p!/p?, u!/u?]
The deﬁnition of NewUPIDForProcess expands into the following schema:
NewUPIDForProcess
∆PTAB
u! : UPID
p! ̸∈used
used ′ = used ∪{p!}
u! = nextupid
nextupid ′ = nextupid + 1
extpid ′ = extpid ⊕{u! →p!}
The kernel allows two kinds of process to be created: user and device
processes. The type PTYPE has two elements, one denoting user processes,
the other denoting device processes. The type of each process is stored in
ptype. The operation to add the type of a new process is deﬁned thus:
SetProcType
∆PTAB
p? : PID
pt? : PTYPE
ptype′ = ptype ∪{p? →pt?}
The operation to allocate user-process identiﬁers (if there are any free), an
external identiﬁer and record the type of the new process (if it can be created)
is deﬁned by the following formula. The operation has the same name as the
similar operation in the ﬁrst speciﬁcation, namely AddPD.
AddPD =
((GotFreePIDs ∧
NewUPIDForProcess[uu!/u!] ∧
SetProcType[p!/p?] ∧
SysOk)
∨PTABFull
The AddPD operation expands into:
AddPD
∆PTAB
∆HW
∆ERRV

224
5 A Separation Kernel
p! : PID
u! : UPID
pt? : PTYPE
(used ⊂PID ∧
p! ̸∈used ∧
used ′ = used ∪{p!} ∧
u! = nextupid ∧
nextupid ′ = nextupid + 1 ∧
extpid ′ = extpid ⊕{u! →p!} ∧
ptype′ = ptype ∪{p! →pt?} ∧
serr ′ = sysok)
∨(serr ′ = ptabfull ∧intno′ = killintno)
The AddPD operation is very important, so its precondition has to be
calculated. It is:
pre AddPD =
used ⊂PID ∧
p! ̸∈used
This formula implies
pre AddPD = used ⊂PID
We can prove a useful result at this stage.
Theorem 58. AddPD ⇒p! ̸∈free′. In other words, p! is not a free process
identiﬁer in the after state of AddPD.
Proof. The predicate contains the conjunct used′ = used ∪{p!}. By the
deﬁnition of used, free = PID \ used, so if p! ∈used′, p! ̸∈free′ for the
equation implies free \{p!} = PID \(used ∪{p!}) since the set of all identiﬁers
is ﬁxed. 2
We need to deﬁne an operation that sets the initial values for process
attributes. This operation will be used when a process is created.
AddPDESC
∆PTAB
p? : PID
st? : PSTATE
state′ = state ∪{p? →st?}
An operation is required to create the idle process. This process does not
have a UID since it cannot be accessed outside the kernel. Even though it

5.4 The Process Table
225
resides in the kernel, the idle process is still regarded as a user process (this
is really just a matter of choice—it could equally be a device process).
AddIdleProcess =
∃pt : PTYPE; st : PSTATE | pt = uproc ∧st = psready •
AllocPID[ip!/p!] ∧
AddPDESC[ip!/p?, st/st?]
SetProcType[ip!/p?, pt/pt?]
This deﬁnition expands to:
AddIdleProcess
∆PTAB
p! : PID
∃pt : PTYPE; st : PSTATE| pt = dproc ∧st = psready •
ip! ̸∈used ∧
used ′ = used ∪{ip!} ∧
state′ = state ∪{ip! →st} ∧
ptype′ = ptype ∪{ip! →pt}
Removing the existential quantiﬁer using the one-point rule, the following is
obtained:
AddIdleProcess
∆PTAB
ip! : PID
ip! ̸∈used
used ′ = used ∪{ip!}
state′ = state ∪{ip! →psready}
ptype′ = ptrype ∪{ip! →dproc}
The next schema deﬁnes the operation that translates an external user
process identiﬁer, an element of UPID, and translates it into an element of
PID.
PIDforUPID
ΞPTAB
u? : UPID
p! : PID
p! = extpid(u?)
The following is the deﬁnition of the operation that deallocates a process
identiﬁer. It is similar to the one in the earlier speciﬁcation and its justiﬁcation
is also similar.

226
5 A Separation Kernel
FreePID
∆PTAB
p? : PID
used ′ = used \ {p?}
On termination, the external identiﬁer of a process must be cancelled. This
schema deﬁnes the operation.
DelProcUPID
∆PTAB
p? : PID
extpid ′ = extpid −◁{p?}
We need an operation to remove a process’ external identiﬁer when it is
terminated. This schema deﬁnes that operation.
DelExtPD
∆PTAB
p? : PID
extpid ′ = extpid −◁{p?}
To delete a user process, the following is required:
DelUserPD = DelExtPD ∧FreePID
This operation expands into
∆PTAB
p? : PID
extpid ′ = extpid −◁{p?}
used ′ = used \ {p?}
By calculation, the precondition of this operation is just true. This does not
seem adequate, so we deﬁne
pre DelUserPD = p? ∈used
Sometimes, it is necessary to terminate all processes and to do it as
quickly as possible. The following operation deletes all the information about
processes.
DeleteAllProcesses
∆PTAB
used ′ = ∅

5.4 The Process Table
227
This operation is used (gleefully!) by the ISR that responds to lethal errors.
Operations to access and set various process attributes are deﬁned in the
next few schemata. The structure of these schemata is relatively simple and
their interpretation should be immediate.
ProcType
ΞPTAB
p? : PID
pt! : PTYPE
pt! = ptype(p?)
ProcState
ΞPTAB
p? : PID
st! : PSTATE
st! = state(p?)
SetProcState
∆PTAB
p? : PID
st? : PSTATE
state′ = state ⊕{p? →st?}
pre SetProcState = p? ∈used
Note that this is implied by the invariant.
SetStateToReady =
∃st : PSTATE | st = psready •
SetProcState[st/st?]
SetStateToRunning =
∃st : PSTATE | st = psrunning •
SetProcState[st/st?]
SetStateToTerminated =
∃st : PSTATE | st = psterm •
SetProcState[st/st?]
Because all of the SetState operations are similar, only SetStateToReady
is expanded here.

228
5 A Separation Kernel
SetStateToReady
∆PTAB
p? : PID
state′ = state ⊕{p? →psready}
(The remainder can be obtained by an obvious substitution.)
The reader is warned that a signiﬁcant number of operations, those dealing
with device processes, are not included in this subsection. The missing class
of operation is deﬁned in the section dealing with device processes. The re-
ﬁnement of the device-process operations is directly analogous to the process
whose documentation now begins.
5.4.2 Reﬁnement One
Having deﬁned the process table and the general operations that act upon it,
the reﬁnement can begin. The ﬁrst step is to deﬁne the reﬁned process table
and its initialisation schema; then the abstraction relation is deﬁned.
This ﬁrst reﬁnement corresponds closely to that of the PTAB in the ﬁrst
speciﬁcation. The strategy is exactly the same as in that case, namely that
the set of free process table entries (denoted by process identiﬁers) should
be implemented as a chain through a vector, called next, that maps process
identiﬁers to process identiﬁers. As a ﬁrst step, used is replaced by a free
chain mapping. In addition, we require that all the partial functions that
initially speciﬁed the various attributes of processes should be reﬁned to func-
tions whose domains are PID and whose codomains are the sets deﬁning each
attribute type (e.g., for state, we want a function PID →PSTATE). This
second goal is achieved at this stage in the reﬁnement. The ﬁrst goal is only
partially reached; it will require a second step to reﬁne to the representation
in which next is used.
Now, it should be clear that this reﬁnement strategy is identical to that
used in the reﬁnement documented in Chapter 3 of this book. The represen-
tation of the process tables in this and in the other case are extremely close
(sets and partial functions). For this reason and for reasons given after the
abstraction relation has been stated, most of the reﬁnement proofs that would
normally be associated with reﬁnement steps are omitted from this chapter.
PTAB1
hdfree, endfree : GPID
freech : PID
↣GPID
nextupid1 : UPID
extpid1 : UPID →PID
pidext1 : PID →UPID
devmap1 : DEVNO →PID
tss1 : PID →TSS
state1 : PID →PSTATE

5.4 The Process Table
229
ptype1 : PID →PTYPE
msgq1 : PID →MSGQ
devrqs1 : PID →MSG
devmsg1 : PID →(GPID × MSG)
devrpy1 : PID →MSG
cdseg1 : PID →SDESC
dsseg1 : PID →SDESC
hdfree = nullpid ⇔endfree = nullpid
hdfree = nullpid ⇔dom freech = ∅
(hdfree ̸= nullpid ⇒
dom freech ̸= ∅∧
hdfree ∈dom freech ∧
endfree ∈dom freech ∧
freech(endfree) = nullpid)
The initialisation schema is much as one would expect.
PTAB1Init
PTAB1′
hdfree′ = minpid
endfree′ = maxpid
∀p : PID •
(p = maxpid ⇒freech′(p) = nullpid) ∧
(p < maxpid ⇒freech′(p) = p + 1)
nextupid1′ = 0
UsedPID1
ΞPTAB1
p? : PID
p? ∈dom freech
GotFreePIDs1
ΞPTAB1
hdfree ̸= nullpid

230
5 A Separation Kernel
AllocPID1
∆PTAB1
p! : PID
p! = hdfree
freech′ = freech −◁{p!}
hdfree′ = next(hdfree)
AllocUPID1
∆PTAB1
u! : UPID
u! = nextupid1
nextupid1′ = nextupid1 + 1
AddProcUPID1
∆PTAB1
p? : PID
u? : UPID
extpid1′ = extpid1 ⊕{u? →p?}
NewUPIDForProcess1 =
AllocPID1 ∧
AllocUPID1 ∧
AddProcUPID1[p!/p?, u!/u?]
The deﬁnition of NewUPIDForProcess1 expands into the following schema:
NewUPIDForProcess1
∆PTAB1
p! : PID
u! : UPID
p! = hdfree
freech′ = freech −◁{p!}
hdfree′ = next(freech)
u! = nextupid1
nextupid1′ = nextupid1 + 1
extpid1′ = extpid1 ⊕{u! →p!}

5.4 The Process Table
231
SetProcType1
∆PTAB1
p? : PID
pt? : PTYPE
ptype1′ = ptype1 ⊕{p? →pt?}
AddPD =
((GotFreePIDs1 ∧
NewUPIDForProcess1[uu!/u!] ∧
SetProcType1[p!/p?] ∧
SysOk)
∨PTABFull
The AddPD1 operation expands into:
AddPD1
∆PTAB1
∆ERRV
∆HW
p! : PID
u! : UPID
pt? : PTYPE
(hdfree ̸= nullpid ∧
p! = hdfree ∧
freech′ = freech −◁{p!} ∧
hdfree′ = next(freech) ∧
u! = nextupid1 ∧
nextupid1′ = nextupid1 + 1 ∧
extpid1′ = extpid1 ⊕{u! →p!} ∧
ptype1′ = ptype1 ⊕{p! →pt?} ∧
serr ′ = sysok)
∨(serr ′ = ptabfull ∧intno′ = killintno)
The AddPD1 operation is very important, so its precondition has to be
calculated. It is:
pre AddPD1 =
hdfree ̸= nullpid
This formula implies
pre AddPD1 = used ⊂PID
We need to reﬁne the operation that sets the initial values for process
attributes. It is as follows:

232
5 A Separation Kernel
AddPDESC1
∆PTAB
p? : PID
st? : PSTATE
state1′ = state1 ⊕{p? →st?}
AddIdleProcess1 =
∃pt : PTYPE; st : PSTATE | pt = uproc ∧st = psready •
AllocPID1[ip!/p!] ∧
AddPDESC1[ip!/p?, st/st?]
SetProcType1[ip!/p?, pt/pt?]
PIDforUPID1
ΞPTAB1
u? : UPID
p! : PID
p! = extpid1(u?)
The following schemata deﬁne operations on the free chain. They are iden-
tical to those in the previous reﬁnement.
EmptyFreeChain1
ΞPTAB1
dom freech = ∅
The AddNewLastFreechain schema deﬁnes an operation that adds an ele-
ment to the end of the free chain.
AddNewLastFreechain
∆PTAB1
p? : PID
freech′ = freech ⊕{endfree →p?}
The AddFreechainLast schema deﬁnes an operation that maps the last
element of the free chain to nullpid.
AddFreechainLast
∆PTAB1
p? : PID
freech′ = freech ∪{p? →nullpid}

5.4 The Process Table
233
The SetFCHead operation sets the value of hdfree.
SetFCHead
∆PTAB1
p? : PID
hdfree′ = p?
Analogously, SetFCLast sets the value of endfree.
SetFCLast
∆PTAB1
p? : PID
endfree′ = p?
The following is the deﬁnition of the operation that deallocates a process
identiﬁer. It is similar to the one in the earlier speciﬁcation and its justiﬁcation
is also similar.
FreePID1 =
(((EmptyFreeChain1 ∧
AddFreechainLast ∧SetFCLast ∧SetFCHead)
∨(UsedPID1 ∧
(AddNewLastFreechain o
9 AddFreechainLast) ∧SetFCLast)) ∧
SysOk)
∨UnusedPID
This can be transformed by distribution of SysOk. The transformation is
justiﬁed by the propositional calculus theorem (p ∨q) ∧r ⇔(p ∧r) ∨(q ∧
r). The use of this theorem occurs frequently and can be used both to expand
a schema by producing copies of conjuncts and to contract them by reducing
multiple occurrences of a conjunct to a single one.
FreePID1 =
((EmptyFreeChain1 ∧
AddFreechainLast ∧SetFCLast ∧SetFCHead ∧SysOk)
∨(UsedPID1 ∧
(AddNewLastFreechain o
9 AddFreechainLast) ∧SetFCLast ∧SysOk))
∨UnusedPID1
This deﬁnition can then be expanded into the schema that follows. A small
amount of simpliﬁcation has been performed on the schema, it should be
noted. Very often, when expanding deﬁnitions into schemata, we will take
the opportunity to engage in some simpliﬁcation; we will, though, outline the
transformations employed unless they are obvious.

234
5 A Separation Kernel
FreePID1
∆PTAB1
∆ERRV
∆HW
p? : PID
((dom freech = ∅∧
freech′ = freech ∪{p? →nullpid} ∧
endfree′ = p? ∧
hdfree′ = p? ∧
serr ′ = sysok)
∨(p? ̸∈dom freech ∧
freech′ = (freech ⊕{endfree →p?}) ∪{p? →nullpid} ∧
endfree′ = p? ∧
serr ′ = sysok))
∨(serr ′ = usedpd ∧intno′ = killintno)
On termination, the external identiﬁer of a process must be cancelled. This
schema deﬁnes the operation.
DelProcUPID1
∆PTAB1
p? : PID
extpid1′ = extpid1 −◁{p?}
We need an operation to remove a process’ external identiﬁer when it is
terminated. This schema deﬁnes that operation.
DelExtPD1
∆PTAB1
p? : PID
extpid1′ = extpid1 −◁{p?}
To delete a user process, the following is required:
DelUserPD1 = DelExtPD1 ∧FreePID1
This operation expands into
∆PTAB1
∆ERRV
∆HW
p? : PID
extpid1′ = extpid1 −◁{p?}

5.4 The Process Table
235
((dom freech = ∅∧
freech′ = freech ∪{p? →nullpid} ∧
endfree′ = p? ∧
hdfree′ = p? ∧
serr ′ = sysok)
∨(p? ̸∈dom freech ∧
freech′ = (freech ⊕{endfree →p?}) ∪{p? →nullpid} ∧
endfree′ = p? ∧
serr ′ = sysok))
∨(serr ′ = usedpd ∧intno′ = killintno)
By calculation, the precondition of this operation is just true. This does not
seem adequate, so we deﬁne
pre DelUserPD1 = p? ̸∈freech
Sometimes, it is necessary to terminate all processes and to do it as
quickly as possible. The following operation deletes all the information about
processes.
DeleteAllProcesses1
∆PTAB1
hdfree′ = nullpid
dom freech′ = ∅
This operation is used by the ISR that responds to lethal errors. Its precon-
dition is true, so it can be applied at any time!
ProcType1
ΞPTAB1
p? : PID
pt! : PTYPE
pt! = ptype(p?)
ProcState1
ΞPTAB1
p? : PID
st! : PSTATE
st! = state(p?)

236
5 A Separation Kernel
SetProcState1
∆PTAB1
p? : PID
st? : PSTATE
state′ = state ⊕{p? →st?}
pre SetProcState1 = p? ∈used
Note that this is implied by the invariant.
SetStateToReady1 =
∃st : PSTATE | st = psready •
SetProcState1[st/st?]
SetStateToRunning1 =
∃st : PSTATE | st = psrunning •
SetProcState1[st/st?]
SetStateToTerminated1 =
∃st : PSTATE | st = psterm •
SetProcState1[st/st?]
Because all of the SetState1 operations are similar, only SetStateToReady1
is expanded here.
SetStateToReady1
∆PTAB1
p? : PID
state1′ = state1 ⊕{p? →psready}
We now give the abstraction schema. The diﬀerence between the schema
as presented here and the one in the previous reﬁnement is that the current
one has more process attributes to relate. The “structural” components (those
dealing with the existence of processes) are the same in both cases.
AbsPTAB1
PTAB
PTAB1
dom freech = PID \ used
dom freech ∩used = ∅
nextupid1 = nextupid
∀p : PID • p ∈used ⇔pidext(p) = pidext1(p)
∀p : PID • p ∈used ⇔extpid(pidext(p)) = extpid1(pidext1(p))
∀p : PID • p ∈used ⇔state(p) = state1(p)

5.4 The Process Table
237
∀p : PID • p ∈used ⇔ptype(p) = ptype1(p)
∀p : PID • p ∈used ⇔msgq(p) = msgq1(p)
∀p : PID • p ∈used ⇔pidext(p) = pidext1(p)
∀p : PID • p ∈used ∧ptype(p) ̸= dproc ⇔cdseg(p) = cdseq1(p)
∀p : PID • p ∈used ∧ptype(p) ̸= dproc ⇔dsseg(p) = dsseg1(p)
∀p : PID • p ∈used ∧ptype(p) = dproc ⇔devrqs(p) = devrqs1(p)
∀p : PID • p ∈used ∧ptype(p) = dproc ⇔devrpy(p) = devrpy1(p)
∀p : PID • p ∈used ∧ptype(p) = dproc ⇔devmsg(p) = devmsg1(p)
∀d : DEVNO • devmap(d) ∈used ⇔devmap1(d) = devmap(d)
This schema is yet another identity (and this is usual). This implies that we
can compute the operations we require for PTAB1, using those deﬁned for
PTAB. It also implies that the reﬁnement proofs must be straightforward. We
give the initialisation theorem as an example proof.
Next, we state and prove the initialisation theorem for PTAB1. This is
the only proof in this section. It is included to demonstrate to the reader that
the abstraction relation is sensible. The other proofs could be included but
they are all relatively straightforward. (The interested reader might like to
compare this abstraction relation with the parallel one in Chapter 3 and thus
gain an idea of what the proofs are like.)
Theorem 59. ∀PTAB′; PTAB1′ • PTAB1Init ∧AbsPTAB1 ⇒PTABInit
Proof. The universal implies that dom freech′ = PID since PID \ used′ =
freech′. We have PID \ used = PID, so used′ = ∅, dom freech′ ̸= ∅for
hdfree ̸= endfree ̸= nullpid.
By AbsPTAB1′, nextupid′ = nextupid1′ = 1. 2
5.4.3 Reﬁnement Two
The second reﬁnement of PTAB is the subject of this subsection. The new
PTAB2 schema is given immediately.
PTAB2
freehd, freelst : GPID
next : PID ↣GPID
nextupid2 : UPID
extpid2 : UPID →PID
pidext2 : PID →UPID
devmap2 : DEVNO →PID
state2 : PID →PSTATE
tss2 : PID →TSS
ptype2 : PID →PTYPE
msgq2 : PID →MSGQ
devrqs2 : PID →MSG

238
5 A Separation Kernel
devmsg2 : PID →(GPID × MSG)
devrpy2 : PID →MSG
cdseg2 : PID →SDESC
dsseg2 : PID →SDESC
freehd = nullpid ⇔freelst = nullpid
freehd = nullpid ⇒next∗(| {freehd} |) = ∅
freehd ̸= nullpid ⇔
∀p : PID •
p = freehd ⇒nullpid ∈next+(| {freehd} |)
freehd ̸= nullpid ⇔
∀p : PID •
p = freelst ⇒next(freelst) = nullpid
freehd ̸= nullpid ⇒∃1 k : N • nextk(freehd) = nullpid
The reader should compare this with the corresponding schema in the reﬁne-
ment of the other kernel in this book. It will be seen that the two are quite
similar. We make use of the similarity in the remainder of this subsection.
We immediately present the abstraction schema.
AbsPTAB2
PTAB1
PTAB2
freehd = hdfree
freelst = endfree
freehd ̸= nullpid ⇒
next∗(| {freehd} |) \ {nullpid} = dom freech
dom freech = ∅⇔freehd = freelst ∧freehd = nullpid
freehd ̸= nullpid ⇔∀p : PID • p ∈dom freech ⇒next(p) = freech(p)
dom freech ⊆dom next
ran freech ⊆ran next
∀p : PID •
p ∈dom freech ⇔next(p) = freech(p)
Again, this is similar to the corresponding schema in Chapter 3. With the
exception of the relationships between the domain and codomain of freech
and next, the other conjuncts are identities. We can treat the predicate of this
schema as if it were an identity. This has what, by now, should be familiar
consequences for the conduct of the reﬁnement.
We state the initialisation schema (it is quite obvious):

5.5 Process Queues
239
PTAB2Init
PTAB2′
freehd ′ = minpid
freelst′ = maxpid
∀p : PID •
p = maxpid ⇒next′(p) = nullpid ∧
p < maxpid ⇒next′(p) = p + 1
The schemata deﬁned at this level can be translated with ease into a
programming language, so there is no more to be done here.
5.5 Process Queues
This section contains the reﬁnement of the FIFO queue type used to imple-
ment the process queues manipulated by the Separation Kernel’s scheduler.
The type is identical to that deﬁned in Chapter 3. This means that we can
import all reﬁnements and proofs intact from that earlier exercise and use
them in the current context. This clearly saves us a little work; it also serves
to shorten this book a little.
We will state the single error schema required by the process queue type.
It is
ProcessQueueEmpty =
(∃e : SYSERR | e = emptyqueue •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
5.5.1 Top Level
This is a relatively straightforward speciﬁcation of a FIFO queue. It uses a
sequence as its basic container structure.
The state schema is the following.
PROCESSQUEUE
procs : seq PID
As was the case with the previous example, it is possible to include PTAB
in the PROCESSQUEUE schema, thus making used a visible component.
This would permit the invariant to include ran procs ⊆used. Equally, the
sequence type could be declared as being an injective sequence. This would
imply that elements can appear only once. In this case, as in the last, we
prefer not to take these measures. We can prove that only elements of used
can be in procs since only elements of used can execute on the processor.

240
5 A Separation Kernel
Furthermore, it is not necessary to use an injective sequence. The reason for
this is that when a process is in the scheduler’s queue, it cannot be executed
and cannot, therefore, be placed on the scheduler’s queue; necessarily, each
process identiﬁer occurs in procs exactly once.
The initialisation operation is the obvious one.
PROCESSQUEUEInit
PROCESSQUEUE ′
procs′ = ⟨⟩
The test for queue emptiness is equally obvious.
IsEmptyPROCESSQUEUE
ΞPROCESSQUEUE
procs = ⟨⟩
New elements are enqueued at the back of the queue (it is a FIFO queue).
This is captured by the following schema.
EnqueuePROCESSQUEUE
∆PROCESSQUEUE
p? : PID
procs′ = procs ⌢⟨p?⟩
The head of the queue is the ﬁrst element or head procs, since head procs =
procs(1) iﬀprocs ̸= ⟨⟩. The next schema deﬁnes the basic operation; the
condition on the queue will be imposed at a later time.
TheHeadOfPROCESSQUEUE
ΞPROCESSQUEUE
p! : PID
p! = head procs
The above operation is not useful. It must test for the empty queue. This
extension is made in the following deﬁnition.
HeadOfPROCESSQUEUE =
(IsNonEmptyPROCESSQUEUE ∧
TheHeadOfPROCESSQUEUE ∧
SysOk)
∨ProcessQueueEmpty
The deﬁnition expands into:

5.5 Process Queues
241
HeadOfPROCESSQUEUE
ΞPROCESSQUEUE
∆ERRV
∆HW
p! : PID
(procs ̸= ⟨⟩∧
p! = head procs ∧
serr ′ = sysok)
∨(serr ′ = emptyqueue ∧intno′ = killintno)
When a process is removed from the queue, it is removed from the head.
The following schema deﬁnes this operation. It is the obvious speciﬁcation,
taking the tail of the queue and assigning it to the after state of the queue
(procs′):
DelHeadOfPROCESSQUEUE
∆PROCESSQUEUE
procs′ = tail procs
A dequeue can only take place when the queue is not empty. The operation
to perform the dequeue is totalised by the addition of checks. It is
DequeuePROCESSQUEUE =
(IsNotEmptyPROCESSQUEUE ∧
HeadOfPROCESSQUEUEU ∧
DelHeadOfPROCESSQUEUE ∧
SysOk)
∨ProcessQueueEmpty
This compound operation expands into:
DequeuePROCESSQUEUE
∆PROCESSQUEUE
∆ERRV
∆HW
p! : PID
(procs ̸= ⟨⟩∧
p! = head procs ∧
procs′ = tail procs ∧
serr ′ = sysok)
∨(serr ′ = emptyqueue ∧intno′ = killintno)
This is all there is to the queue type used by the scheduler. The round
robin scheduling algorithm requires a strict FIFO queue. This is what has
been presented.

242
5 A Separation Kernel
5.5.2 Reﬁnement
The reﬁnement of this type follows that in the PROCESSQUEUE section of
the ﬁrst kernel. The proofs are not repeated here.
It should be noted that the DEVPROCQUEUE type is deﬁned in the
next section. Type DEVPROCQUEUE is another FIFO queue type whose
elements are elements of PID. The DEVPROCQUEUE type is deﬁned in
terms of renaming components of PROCESSQUEUE. The reﬁnement proofs
for DEVPROCQUEUE are identical to those for PROCESSQUEUE, so they
may safely be omitted.
5.6 The Scheduler
The separation kernel is intended to model a distributed sytem. This implies
that the scheduler can be very simple.
The original paper on Separation Kernels, [10], speciﬁes the round-robin
scheduling algorithm. A problem can arise when high-priority devices need
to be included in the system. To solve this, the scheduler is speciﬁed as two
queues. One queue is used to schedule user-level processes. The second queue
is used to schedule device processes. The device process queue has higher
priority than the one for scheduling user processes.
It is necessary to begin by deﬁning a separate queue type for device
processes. This is required so that the names of device and process queue
components and operations do not clash. We continue by deﬁning new queue
types and operations by renaming those deﬁned for FIFO queues. Note that
name substitutions must be performed in order to ensure that the new queue
type does not contain names that clash with any existing (or to be deﬁned)
types.
DEVPROCQUEUE = PROCESSQUEUE[devs/procs]
DEVPROCQUEUEInit = PROCESSQUEUEInit[devs/procs]
IsEmptyDEVPROCQUEUE = IsEmptyPROCESSQUEUE[devs/procs]
EnqueueDEVPROCQUEUE =
EnqueuePROCESSQUEUE[devs/procs, devs′/procs′, dp?/p?]
DequeueDEVPROCQUEUE =
DequeuePROCESSQUEUE[devs/procs, devs′/procs′, dp!/p!]
To assure the reader that this is proper, the above operations are now
expanded so that their full deﬁnition can be seen.
First, there is the queue type schema:
DEVPROCQUEUE
devs : seq PID
The device queue is initialised by the following operation:

5.6 The Scheduler
243
DEVPROCQUEUEInit
DEVPROCQUEUE ′
devs′ = ⟨⟩
The emptiness of the device queue is tested by the following operation:
IsEmptyDEVPROCQUEUE
ΞDEVPROCQUEUE
devs = ⟨⟩
The enqueue operation for device processes is deﬁned by the following
schema:
EnqueueDEVPROCQUEUE
∆DEVPROCQUEUE
dp? : PID
devs′ = devs ⌢⟨dp?⟩
The dequeue operation expands to the following:
DequeueDEVPROCQUEUE
∆DEVPROCQUEUE
∆ERRV
∆HW
dp! : PID
(devs ̸= ⟨⟩∧
dp! = head devs ∧
devs′ = tail devs ∧
serr ′ = sysok)
∨(serr ′ = emptyqueue ∧intno′ = killintno)
Finally, the scheduler schema can be deﬁned. This schema contains vari-
ables to represent the currently executing process, the previously executed
process, the identiﬁer of the idle process and two FIFO queues, one each for
user and device processes. The schema is:
SKSCHED
curr, prev : PID
ipid : PID
devq : DEVPROCQUEUE
procq : PROCESSQUEUE
It should be noted that the user-process queue is just an unmodiﬁed copy of
PROCESSQUEUE.

244
5 A Separation Kernel
Upon seeing this deﬁnition, it should be clear that promotion is to be used
in the deﬁnition of the scheduler, just as it was in the case of the previous
one. This is a natural method for the speciﬁcation of the scheduler (it also
cuts down the work to be done in reﬁning it to executable code).
The associated initialisation schema is the next one to be deﬁned.
SKSCHEDInit
SKSCHED′
p? : PID
curr ′ = minpid
prev ′ = minpid
ipid ′ = p?
devq′ = θDEVPROCQUEUEInit
procq′ = θPROCESSQUEUEInit
Note that the initialisation of the two FIFO queues, devq and procq uses the
θ notation.
The component ipid is the identiﬁer of the idle process (sometimes called
the “null” process). This is just a process that does nothing; it is there to ab-
sorb processor time in when there is nothing else to do. It can be implemented
as a simple loop, such as:
while true do
skip
od
The next few schemata deﬁne operations that manipulate the scalar vari-
ables in the scheduler’s schema. Their names are chosen so that they indicate
function. The names of the variables are identical to those in the previous
speciﬁcation, so the reader can refer to the previous scheduler for explana-
tion, should it be required.
IDLEPROCESSIdent
ΞSKSCHED
p! : PID
p! = ipid
RunningProcess
ΞSKSCHED
p! : PID
p! = curr

5.6 The Scheduler
245
SetRunningProcess
∆SKSCHED
p? : PID
curr ′ = p?
PreviouslyRunningProcess
ΞSKSCHED
p! : PID
p! = prev
SetPreviousProcess
∆SKSCHED
p? : PID
prev ′ = p?
The ﬁnal operation in this set is a little more complex. It is deﬁned as the
composition of other schemata:
UpdateCurrentProcess =
SetRunningProcess ∧
(RunningProcess[p/p!] ∧SetPreviousProcess[p/p?]) \ {p}
It expands into a simple schema that can be simpliﬁed to give the following
schema:
∆SKSCHED
p? : PID
curr ′ = p?
prev ′ = curr
The scheduler, SKSCHED, is deﬁned in terms of promotion. The promoted
components are the user- and device-process queues. The promotion schema
is deﬁned in the obvious fashion as follows.
ΦSKSCHED
∆SKSCHED
∆DEVPROCQUEUE
∆PROCESSQUEUE
devq = θDEVPROCQUEUE
devq′ = θDEVPROCQUEUE ′
procq = θPROCESSQUEUEInit
procq′ = θPROCESSQUEUEInit′

246
5 A Separation Kernel
We can now deﬁne the promoted operations. Again, names are chosen to
indicate function. We have little to say about these deﬁnitions. The operations
correspond to those deﬁned for device queues and are deﬁned in a fashion
similar to them.
IsEmptyUSERPROCESSQUEUE =
∃∆PROCESSQUEUE •
ΦSKSCHED ∧IsEmptyPROCESSQUEUE
EnqueueUSERPROCESSQUEUE =
∃∆PROCESSQUEUE •
ΦSKSCHED ∧EnqueuePROCESSQUEUE
DequeueUSERPROCESSQUEUE =
∃∆PROCESSQUEUE •
ΦSKSCHED ∧DequeuePROCESSQUEUE
IsEmptyDEVICEQUEUE =
∃∆DEVPROCQUEUE •
ΦSKSCHED ∧IsEmptyDEVPROCQUEUE
EnqueueDEVICEPROCESS =
∃∆DEVPROCQUEUE •
ΦSKSCHED ∧EnqueueDEVPROCQUEUE
DequeueDEVICEQUEUE =
∃∆DEVPROCQUEUE •
ΦSKSCHED ∧DequeueDEVPROCQUEUE
The operation that enqueues a user process in the user process ready queue
is deﬁned as follows:
MakeReady =
SetStateToReady ∧EnqueueUSERPROCQUEUE
It is possible to strengthen this deﬁnition, making it more secure. The
deﬁnition of MakeReady would look something like:

5.6 The Scheduler
247
MakeReady =
(KnownPID ∧
(IsUserPID ∧
SetStateToReady ∧
EnqueueUSERPROCQUEUE ∧
SysOk)
∨NotUserPID)
∨UnknownPID
This would be a much more secure operation. However, it would require addi-
tional checks, KnownPID and IsUserPID, whose execution might incur unac-
ceptable amounts of additional time (KnownPID must search the free chain in
PTAB). The use of this operation (which requires the deﬁnition of additional
schemata) remains an option but it is one with which we do not continue.
Next, the operation to place a device process on the ready devices queue,
devq, is deﬁned:
ReadyDeviceProcess =
SetStateToReady ∧EnqueueDEVPROCQUEUE
This expands and simpliﬁes to:
∆PTAB
∆SKSCHED
∆PROCESSQUEUE
state′ = state ⊕{p? →psready}
devs′ = devs ⌢⟨p?⟩
The operation is now deﬁned that executes the idle process at times when
the scheduler determines that there is nothing else to do.
RunIdleProcess =
(IDLEPROCESSIdent[i/p] ∧
SetStateToRunning[i/p?] ∧
UpdateCurrentProcess[i/p?]) \ {i}
This expands and simpliﬁes to:
∆PTAB
∆SKSCHED
∆PROCESSQUEUE
state′ = state ⊕{ip →psrunning}
curr ′ = ip
prev ′ = curr

248
5 A Separation Kernel
It is sometimes necessary for a process to be removed from the scheduler
queue in which it currently resides. When this happens, the process is said to
be unreadied. Unreadying can occur when, for example, the current process
makes a request for an I/O operation. I/O operations require time to complete
and a device process must be scheduled, data transferred and the requesting
process must be notiﬁed and then put back into the scheduler’s queue. This
is the most common case of unreadying and is, probably the only case rele-
vant to the Separation Kernel. In other cases, a process that is not currently
running is identiﬁed and removed from the queue. It is considered that, in the
conﬁguration of the Separation Kernel deﬁned in this chapter, that this will
not be a frequent operation; the case is included in the schema deﬁning the
unready operation, however.
In the operations speciﬁed here, an unready operation will not be used.
Instead, use will be made of the fact that it is the current process that is
performing the operation that requires the current process to be suspended.
Nevertheless, the provision of the operation is useful because it provides a
clean operation that can be employed by device processes (which are not
speciﬁed in detail in this book).
It is also expected that device processes will never be unreadied. Therefore,
the following deﬁnition is of the operation to remove user-level processes from
the scheduler. If the process is the currently executing one, another process
must be selected to execute. If the process to be unreadied is not yet executing
(and is, therefore, in the user-process queue), it is merely removed from the
queue and the current process continued.
SKMakeUnready =
(RunningProcess[r/p!] ∧
(IsEmptyUSERPROCESSQUEUE ∧RunIdleProcess o
9 CTXTSW )
∨(DequeueUSERPROCESSQUEUE[n/p!] ∧
SetStateToRunning[n/p?] ∧
UpdateCurrentProcess[n/p?] o
9 CTXTSW ) \ {n}) \ {r}
The main scheduling operation is the following:
SKSchedNext =
(IsEmptyDEVICEQUEUE ∧
(IsEmptyUSERPROCESSQUEUE ∧RunIdleProcess o
9 CTXTSW )
∨(DequeueUSERPROCESSQUEUE[n/p!] ∧
SetStateToRunning[n/p?] ∧
UpdateCurrentProcess[i/p?] o
9 CTXTSW ) \ {n})
∨(DequeueDEVICEQUEUE[d/p!] ∧
SetStateToRunning[d/p?] ∧
UpdateCurrentProcess[d/p?] o
9 CTXTSW ) \ {d}
Notice that SKSchedNext always stores in prev the identiﬁer of the process
that was current in its before state. After simpliﬁcation, this operation can
be written as

5.6 The Scheduler
249
∆SKSCHED
(devq = ⟨⟩∧
(procq = ⟨⟩∧
curr ′ = ip ∧prev ′ = curr ∧
state′ = state ⊕{ip →psrunning} o
9 CTXTSW )
∨(state′ = state ⊕{head procq →psrunning} ∧
procq′ = tail procq ∧
curr ′ = head procq ∧prev ′ = prev o
9 CTXTSW ))
∨(devq′ = tail devq ∧
state′ = state ⊕{head devq →psrunning} ∧
curr ′ = head devq ∧prev ′ = curr o
9 CTXTSW )
Since this is such an important operation, its precondition must be calcu-
lated.
pre SKSchedNext = true
The requeue operation just puts an unreadied process back onto the ap-
propriate queue in the scheduler. Requeueing occurs, for example, when a user
process has received data from a device request (e.g., received a data buﬀer
from an input device). There are two versions of this operation, one each for
user and device processes. Here, initially, is the requeue operation for user
processes.
RequeueUserProcess =
(SKSchedNext o
9 MakeReady)
This deﬁnition expands into
RequeueUserProcess
∆SCHED
p? : PID
∃procq′′ : seq PID; curr ′′, prev ′′ : PID; state′′ : PID →PSTATE •
((devq = ⟨⟩∧
(procq = ⟨⟩∧
curr ′ = ip ∧prev ′ = curr ∧
state′′ = state ⊕{ip →psrunning} o
9 CTXTSW )
∨(state′ = state ⊕{head procq →psrunning} ∧
procq′′ = tail procq ∧
curr ′ = head procq ∧prev ′ = curr o
9 CTXTSW ))
∨(devq′ = tail devq ∧
state′′ = state ⊕{head devq →psrunning} ∧
curr ′ = head devq ∧prev ′ = curr o
9 CTXTSW ))
∧procq′ = procq′′ ⌢⟨p?⟩
∧state′ = state′′ ⊕{p? →psready}

250
5 A Separation Kernel
The operation deals only with user processes, so only that part of SKSchedNext
is aﬀected by simpliﬁcation (this is also the reason for the omission of devq in
the enclosing existential quantiﬁer). The simpliﬁed operation is
RequeueUserProcess
∆SCHED
p? : PID
(devq = ⟨⟩∧
(procq = ⟨⟩∧curr ′ = ip ∧prev ′ = curr ∧
state′ = state ⊕{ip →psrunning, p? →psready} ∧
procq′ = ⟨p?⟩
o
9CTXTSW )
∨(state′ = state ⊕{head procq →psrunning, p? →psready} ∧
procq′ = (tail procq) ⌢⟨p?⟩∧
curr ′ = head procq ∧prev ′ = curr
o
9CTXTSW ))
∨(devq′ = tail devq ∧
state′ = state ⊕{head devq →psrunning} ∧
curr ′ = head devq ∧prev ′ = curr
o
9CTXTSW )
This is another important operation, so its precondition is calculated.
pre RequeueUserProcess = true
The requeue operation for device processes is now deﬁned. Uses of this
operation will be seen when the device-process interface is deﬁned. The device-
requeue operation is analogous to that for user processes, as can be seen from
its deﬁnition.
RequeueDeviceProcess =
(SKSchedNext o
9 ReadyDeviceProcess)
The reader will undoubtedly notice the considerable similarity between the
deﬁniton of this operation and the corresponding one for user processes. The
deﬁnition of RequeueDeviceProcess expands to
RequeueDeviceProcess
∆SKSCHED
p? : PID
∃devq′′ : seqPID; curr ′′, prev ′′ : PID; state′′ : PID →PSTATE •
(devq = ⟨⟩∧
(procq = ⟨⟩∧
curr ′ = ip ∧prev ′ = curr ∧
state′′ = state ⊕{ip →psrunning} o
9 CTXTSW )
∨(state′′ = state ⊕{head procq →psrunning} ∧
procq′ = tail procq ∧

5.7 Storage Pools
251
curr ′ = head procq ∧prev ′ = curr o
9 CTXTSW ))
∨(devq′′ = tail devq ∧
state′′ = state ⊕{head devq →psrunning} ∧
curr ′ = head devq ∧prev ′ = curr o
9 CTXTSW )
o
9
devq′′ = devq ⌢⟨p?⟩∧
state′ = state′′ ⊕{p? →psready}
Simpliﬁcation of the above schema yields the following:
RequeueDeviceProcess
∆SKSCHED
p? : PID
(devq = ⟨⟩∧
devq′ = ⟨p?⟩∧
(procq = ⟨⟩∧
curr ′ = ip ∧prev ′ = curr ∧
state′ = state ⊕{ip →psrunning, p? →psready}
o
9CTXTSW )
∨(state′ = state ⊕{head procq →psrunning, p? →psready} ∧
procq′ = tail procq ∧
curr ′ = head procq ∧prev ′ = curr
o
9CTXTSW ))
∨(devq′ = (tail devq) ⌢⟨p?⟩∧
state′ = state ⊕{head devq →psrunning, p? →psready} ∧
curr ′ = head devq ∧prev ′ = curr o
9 CTXTSW )
Again, the precondition is required and is, therefore, calculated:
pre RequeueDeviceProcess = true
5.7 Storage Pools
The Separation Kernel requires storage allocation to be performed in a number
of places:
•
In main store when processes are allocated. This operation consists of al-
locating the store and partitioning it into the required number of segments
(2 in the current scheme).
•
Inside the kernel, to allocate buﬀer space for inter-process messages.
The same operations can be used to implement storage allocation in both
contexts. Although this might not be ideal, due to the fact that the allocator

252
5 A Separation Kernel
was originally speciﬁed for the allocation and deallocation of small buﬀers and
might not be optimal when operating on larger chunks of store, it shows how
one speciﬁcation can be employed in a number of contexts.
The error schemata are deﬁned before the operations, as is our convention.
There are 3 schemata.
The NoSpace operation sets the error varible when all the space in the
pool has been allocated (this is probably going to be a rarely used operation).
NoSpace =
(∃e : SYSERR | e = nospaceinstore •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
5.7.1 Top Level
The top-level speciﬁcation now follows. The speciﬁcation introduces a state
space (called STOREPOOL), its initialistion schema and the following oper-
ations:
•
An allocation operation.
•
A deallocation operation.
•
A scavenge operation that is called periodically to merge any isolated free
blocks.
The storage-freeing operation speciﬁed in this section is relatively naive. The
basic idea behind it is that it merges blocks whenever possible. However, due to
the fact that the order in which deallocation requests occur is unrelated to that
in which blocks were allocated, it is possible for isolated blocks to be left in the
pool. These isolated blocks count as storage leaks and must be collected and
merged with other blocks. For this reason, the scavenge operation is included.
Before deﬁning the operations, it is necessary to deﬁne a type.
The MD type is the Memory Descriptor type. It consists of the address of
the start of a block of storage and the size of the block in bytes. An element
of MD represents a block of storage.
MD = ADDR × N1
It is necessary to deﬁne three operations: one to construct elements of MD
(mkmd), one to access the address of the block (mdaddr) and one to access
the block’s size (mdsz). The deﬁnitions are simple and are as follows:

5.7 Storage Pools
253
mkmd : ADDR × N1 →MD
mdaddr : MD →ADDR
mdsz : MD →N1
∀a : ADDR; sz : N1 •
mkmd(a, sz) = (a, sz)
∀m : MD •
mdaddr(m) = fst m
mdsz(m) = snd m
Next, the deﬁnition of the storage pool schema is given; it is called STORE-
POOL:
STOREPOOL
freebs : seq MD
maxfree : N1
alloc : N
psize : N1
scavthresh : N
scavcnt : N
(freebs = ⟨⟩∧alloc = psize)
∨(freebs ̸= ⟨⟩∧
i=#freebs
i=1
mdsz(freebs(i)) + alloc = psize)
The schema is composed of the following components:
•
freebs: A sequence of memory descriptors. The descriptors point into the
area of storage that is to be operated upon. Elements of this sequence de-
note the free blocks in the storage area; initially, there is just one descriptor
in the sequence.
•
maxfree: The maximum number of free blocks permitted in the storage
pool.
•
alloc: The number of bytes currently allocated in the storage pool.
•
psize: The size of the storage area in bytes.
•
scavthresh: The scavenge threshold (see below).
•
scavcnt: The scavenge count (see below).
The initialisation operation is as follows:
STOREPOOLInit
STOREPOOL′
mf ? : N1
ba? : ADDR
ps? : N1

254
5 A Separation Kernel
scthrsh? : N
maxfree′ = mf ?
psize′ = ps?
alloc′ = 0
freebs′ = ⟨mkmd(ba?, ps?)⟩
scavthresh′ = scthrsh?
scavcnt′ = 0
The amount allocated is set to 0 (alloc′ = 0) and the various sizes are also set
by input variables. The scavenger-related variables are set (see below).
The interesting part is the assignment to freebs′. A single element of type
MD is assigned to the sequence. The MD element is composed of the start
address of the storage pool (i.e., a pointer to the start of the pool), ba?,
and the size of the pool in bytes, ps?. Initially, the storage pool is completely
unallocated, so this memory descriptor correctly describes the initial situation.
The following operation checks that there is suﬃcient space left in the
buﬀer pool and there are suﬃcient blocks remaining, it also tests that there
is a block whose size is at least that requested.
CanAllocateBlock
ΞSTOREPOOL
rqsz? : N1
alloc + rqsz? ≤psize
#freebs < maxfree
∃i : 1 . . #freebs •
mdsz(freebs(i)) ≥rqsz?
The basic block allocation operation is now given.
AllocBlk
∆STOREPOOL
rqsz? : N1
a! : ADDR
∃i : 1 . . #freebs •
(mdsz(freebs(i)) = rqsz? ∧
freebs′ = freebs −▷{freebs(i)} ∧
alloc′ = alloc + rqsz? ∧
a! = mdaddr(freebs(i)))
∨(mdsz(freebs(i)) > rqsz? ∧
freebs′ =
freebs ⊕{i →
mkmd(mdaddr(freebs(i))
+rqsz?, mdsz(freebs(i)) −rqsz?)} ∧

5.7 Storage Pools
255
alloc = alloc + rqsz? ∧
a! = mdaddr(freebs(i)))
The operation works by iterating over the free blocks in freebs. If there is a
block of identical size, it is returned; if there is a block of size greater than
that requested, it is split into two.
The AllocBlk operation is important, so its precondition is calculated.
pre AllocBlk =
∃i : 1 . . #freebs •
mdsz(freebs(i)) ≥rqsz?
The block-freeing operation is as follows. It works by iterating over the
free blocks, looking for a block that starts immediately after or immediately
before the one being freed. If there is no such block in the storage pool, the
one being freed is added to the end of the MD list in freebs.
FreeBlk
∆STOREPOOL
a? : ADDR
sz? : N1
(∃i : 1 . . #freebs •
(mdaddr(freebs(i)) = a? + sz? ∧
alloc′ = alloc −sz? ∧
freebs′ = freebs ⊕{i →mkmd(a?, mdsz(freebs(i)) + sz?)})
∨(mdaddr(freebs(i)) + mdsz(freebs(i)) = a? ∧
alloc′ = alloc −sz? ∧
freebs′ =
freebs ⊕{i →mkmd(mdaddr(freebs(i)), mdsz(freebs(i)) + sz?)})
∨(freebs′ = freebs ⌢⟨mkmd(a?, sz?)⟩∧
alloc′ = alloc −sz?)
This operation’s precondition is also required.
pre FreeBlk = true
Finally, a block-scavenging operation is deﬁned. This reduces the store as
far as possible to a single block. This requires the following function
mergemds : MD × MD →MD
∀m1, m2 : MD •
mergemds(m1, m2) = mkmd(mdaddr(m1), mdsz(m1) + mdsz(m2))
The block scavenger operation is applied on a periodic basis. It iterates over
the storage pool and tries to merge blocks wherever possible.

256
5 A Separation Kernel
BlockScavenge
∆STOREPOOL
∀i : 1 . . #freebs •
∀j : 1 . . #freebs | i ̸= j •
[mdaddr(freebs(i)) + mdsz(freebs(i)) = mdaddr(freebs(j)) ∧
∃freebs′′ : seq MD •
freebs′′ = freebs −▷{freebs(j)} ∧
freebs′ = freebs′′ ⊕{i →mergemds(freebs(i), freebs(j))}]
∨[mdaddr(freebs(j)) + mdsz(freebs(j)) = mdaddr(freebs(i)) ∧
∃freebs′′ : seq MD •
freebs′′ = freebs −▷{freebs(i)} ∧
freebs′ = freebs ⊕{j →mergemds(freebs(j), freebs(i))]
The BlockScavenge operation’s precondition must be calculated. It is:
pre BlockScavenge =
∀i : 1 . . #freebs •
∀j : 1 . . #freebs | i ̸= j •
mdaddr(freebs(i)) + mdsz(freebs(i)) = mdaddr(freebs(j))
∨mdaddr(freebs(j)) + mdsz(freebs(j)) = mdaddr(freebs(i))
The scavenger is triggered by a “scavenge counter”. This counter is incre-
mented when a deallocation is performed. It is:
IncFreeCnt
∆STOREVEC
scavcnt′ = scavcnt + 1
After a block scavenge operation is performed, the counter should be
cleared. The following operation deﬁnes it:
ClearFreeCnt
∆STOREVEC
scavcnt′ = 0
When the scavenge counter reaches the threshold, the next operation, a
predicate, is true.
ShouldScavenge
∆STOREVEC
scavcnt = scavthresh
The speciﬁcation is now complete and the reﬁnement can start.

5.7 Storage Pools
257
5.7.2 Reﬁnement One
This is the ﬁrst level of reﬁnement.
Initially, a nullmd must be deﬁned. It is clear that it should be the following
unique deﬁnition:
nullmd : MD
nullmd = mkmd(0, 0)
The ﬁrst reﬁnement of the STOREPOOL schema is the following:
STOREPOOL1
freebs1 : 1 . . maxfblocks →MD
maxfblocks : N1
nextm : N1
alloc1 : N
psize1 : N
scavthresh1 : N
scavcnt1 : N
(nextm = 1 ∧alloc1 = psize1)
∨(nextm > 0 ∧i=nextm−1
i=1
mdsz(freebs1(i)) + alloc1 = psize1)
The biggest diﬀerence between this schema and the one in the speciﬁcation is
that freebs is to be related to freebs1, whose type is 1 . . maxfblocks →MD,
not seq MD.
Note that the variable nextm has been introduced. This variable is used
to indicate the next element of freebs1 into which an MD can be stored. The
nextm variable is used only when deallocating variables.
STOREPOOLInit1
STOREPOOL1′
mf ? : N1
ba? : ADDR
ps? : N1
scthrsh? : N
maxfblocks′ = mf ?
psize1′ = ps?
alloc1′ = 0
nextm′ = 2
freebs1′(1) = mkmd(ba?, ps?)
scavthresh1′ = scthrsh?
scavcnt1′ = 0

258
5 A Separation Kernel
The initialisation schema is as one would expect. The principle behind it is
identical.
The next schema corresponds directly to the one in the speciﬁcation.
EnoughSpace1
ΞSTOREPOOL
rqsz? : N1
alloc1 + rqsz? ≤psize1
The following schema also corresponds directly to CanAllocateBlock:
CanAllocateBlock1
ΞSTOREPOOL1
rqsz? : N1
alloc1 + rqsz? ≤psize1
nextm ≤maxfblocks
∃i : 1 . . nextm −1 •
mdsz(freebs1(i)) ≥rqsz?
The allocation operation is now deﬁned. It is also very close to the original
speciﬁcation, the diﬀerences being due to the diﬀerent representation of the
free block list.
AllocBlk1
∆STOREPOOL1
rqsz? : N1
a! : ADDR
∃i : 1 . . nextm −1 •
(mdsz(freebs1(i)) = rqsz? ∧
alloc1′ = alloc1 + rqsz? ∧
a! = mdaddr(freebs1(i)) ∧
nextm′ = nextm −1 ∧
∀j : i . . nextm −2 •
freebs1′ = freebs1 ⊕{j →freebs1(j + 1)})
∨(mdsz(freebs1(i)) > rqsz? ∧
alloc1′ = alloc1 + rqsz? ∧
a! = mdaddr(freebs1(i)) ∧
freebs1′ =
freebs1 ⊕{i →
mkmd(mdaddr(freebs1(i)) + rqsz?,
mdsz(freebs1(i)) −rqsz?)})
The deallocation operation’s schema reﬁnes to the following schema:

5.7 Storage Pools
259
FreeBlk1
∆STOREPOOL1
a? : ADDR
sz? : N1
(∃i : 1 . . nextm −1 •
(mdaddr(freebs1(i)) = a? + sz? ∧
alloc1′ = alloc1 −sz? ∧
freebs1′ = freebs1
⊕{i →mkmd(a?, mdsz(freebs1(i)) + sz?)})
∨(mdaddr(freebs1(i)) + mdsz(freebs1(i)) = a? ∧
alloc1′ = alloc1 −sz? ∧
freebs1′ =
freebs1⊕
{i →mkmd(mdaddr(freebs1(i)), mdsz(freebs1(i)) + sz?)})
∨(freebs1′ = freebs1 ⊕{nextm →mkmd(a?, sz?)} ∧
nextm′ = nextm + 1 ∧
alloc1′ = alloc1 −sz?)
The diﬀerent representation of the free list is quite clear from a comparison
of this schema with the original speciﬁcation.
Finally, the block scavenger’s ﬁrst reﬁnement now follows:
BlockScavenge1
∆STOREPOOL
∀i : 1 . . nextm −1 •
∀j : 1 . . nextm −1 | i ̸= j •
[mdaddr(freebs1(i)) + mdsz(freebs1(i)) = mdaddr(freebs1(j)) ∧
nextm′ = nextm −1 ∧
∃freebs1′′ : 1 . . maxfblocks →MD •
freebs1′′ = freebs1 −▷{freebs1(j)} ∧
freebs1′ = freebs1′′ ⊕{i →mergemds(freebs1(i), freebs1(j))}]
∨[mdaddr(freebs1(j)) + mdsz(freebs1(j)) = mdaddr(freebs1(i)) ∧
nextm′ = nextm −1 ∧
∃freebs1′′ : 1 . . maxfblocks →MD •
freebs1′′ = freebs1 −▷{freebs1(i)} ∧
freebs1′ = freebs1 ⊕{j →mergemds(freebs1(j), freebs1(i))]
pre BlockScavenge =
∀i : 1 . . nextm −1 •
∀j : 1 . . nextm −1 | i ̸= j •
mdaddr(freebs1(i)) + mdsz(freebs1(i)) = mdaddr(freebs1(j))
∨mdaddr(freebs1(j)) + mdsz(freebs1(j)) = mdaddr(freebs1(i))

260
5 A Separation Kernel
The reﬁned scavenge count operations are now given.
First, the operation to increment the scavenge count.
IncFreeCnt1
∆STOREVEC1
scavcnt1′ = scavcnt1 + 1
It is identical to the original speciﬁcation, as is the schema to clear the scav-
enge count.
ClearFreeCnt1
∆STOREVEC1
scavcnt1′ = 0
The schema deﬁning the operation that determines whether a block scavenge
should occur is also identical to the speciﬁcation:
ShouldScavenge1
∆STOREVEC1
scavcnt1 = scavthresh1
That these 3 operations are identical to the speciﬁcation should not come
as too much of a surprise, for all 3 schemata perform simple operations on
scalar variables. In each case, the variable name is diﬀerent but operation is
the same. This suggests how the abstraction relation will be deﬁned. It is to
this relation that we now turn.
The abstraction relation is deﬁned by the following schema.
AbsSTOREPOOL1
STOREPOOL
STOREPOOL1
alloc1 = alloc
psize1 = psize
maxfblocks = maxfree
#freebs = nextm −1
∀i : 1 . . #freebs •
freebs1(i) = freebs(i)
scavcnt1 = scavcnt
scavthresh1 = scavthresh
The abstraction relation is an identity. The scalar variables are just renamed
and so their reﬁnement is not terribly interesting. The most interesting
conjunct (if there is anything interesting about this relation, it is so straight-
forward) are:

5.7 Storage Pools
261
#freebs = nextm −1 ∀i : 1 . . #freebs •
freebs1(i) = freebs(i)
Here, the relationship between the index of the next free element of freebs1
and the length of freebs is deﬁned. The nextm variable always points to the
next element of freebs1 that can be used to store an MD; this corresponds to
the next element after the end of freebs, so must be equal to nextm −1.
The other conjunct relates the two free block lists. It states that all de-
scriptors in the two representations of the list are identical.
Theorem 60.
∀STOREPOOL′; STOREPOOL1′ •
STOREPOOLInit1 ∧AbsSTOREPOOL1′ ⇒STOREPOOLInit
Proof. It is immediate from the abstraction relation that maxfblocks′ =
maxfree = mf ?, alloc1′ = alloc′ = 0 and psize′ = psize1′ = ps?.
The abstraction relation states that nextm′ = #freebs′ + 1, so nextm′ =
2 implies that #freebs = 1, which, in turn, implies that freebs′ = 1. The
predicate of the abstraction relation requires that freebs1′(i) = freebs′(i) for
all i ∈1 . . #freebs′ (or, equivalently i ∈1 . . nextm′ −1. Since nextm′ = 2,
nextm′ −1 = 1 and freebs1′(1) = freebs′(1) (= head freebs′) and freebs1′(1) =
mkmd(ba?, ps?) = freebs′(1).
Finally, since scavcnt1 = scavcnt and scavthresh1 = scavthresh, the proof
is done. 2
Theorem 61. ∀STOREPOOL; STOREPOOL1; rqsz? : N1 • pre AllocBlk ∧
AbsSTOREPOOL1 ⇒pre AllocBlk1
Proof. The precondition of AllocBlk is
∃i : 1 . . #freebs • mdsz(freebs(i)) ≥rqsz?
and that of AllocBlk1 is
∃i : 1 . . nextm −1 • mdsz(freebs1(i)) ≥rqsz?
By the predicate of AbsSTOREPOOL1, nextm = #freebs + 1, so #freebs =
nextm −1. Since 1 ≤i ≤#freebs (or, equivalently, 1 ≤i ≤nextm −1), by
the abstraction relation, freebs(i) = freebs1(i). The remainder is immediate.
2
Theorem 62.
∀STOREPOOL; STOREPOOL′; STOREPOOL1; STOREPOOL1′;
rqsz? : N1; s! : ADDR •
pre AllocBlk ∧
AbsSTOREPOOL1 ∧
AbsSTOREPOOL1′ ∧
AllocBlk1
⇒AllocBlk

262
5 A Separation Kernel
Proof. First, that the ranges of the quantiﬁers are identical can be seen from
the following. By the predicate of AbsSTOREPOOL1, nextm = #freebs + 1,
so #freebs = nextm −1. Next, by the same predicate, alloc = alloc1, so
alloc1 + rqsz? = alloc + rqsz?, while the predicate of AbsSTOREPOOL1′
requires that alloc′ = alloc1′, so alloc1 + rqsz? = alloc + rqsz? = alloc1′ =
alloc′.
For the reason that 1 ≤i ≤nextm −1, or equivalently that 1 ≤i ≤
#freebs, freebs1(i) = freebs(i) and freebs1′(i) = freebs′(i) by the predi-
cates of the two abstraction schemata. From this, it can be inferred that
mdsz(freebs1(i)) = rqsz? = mdsz(freebs(i)), mdsz(freebs1(i)) > rqsz? im-
plies mdsz(freebs(i)) > rqsz? and mdaddr(freebs1(i)) = mdaddr(freebs(i)). A
consequence of the last is that a! = mdaddr(freebs1(i)) = mdaddr(freebs(i)).
All that remains is the equivalence of ∀j : i . . nextm −2 • freebs1′ =
freebs1 ⊕{j →freebs1(j + 1)} and freebs′ = freebs −▷{freebs(i)} (the update
in the second disjunct is a simple consequence of the abstraction relations and
the range condition, 1 ≤i ≤#freebs). It should be clear that freebs1′(i) =
freebs1(i + 1); that is, freebs1′ = freebs1 −▷{freebs1(i)} and the abstraction
relations permit the proof to be completed. 2
Theorem 63.
∀STOREPOOL; STOREPOOL1; a : ADDR; sz? : N1 •
pre FreeBlk ∧AbsSTOREPOOL1 ⇒pre FreeBlk1
Proof. Trivial. 2
Theorem 64.
∀STOREPOOL; STOREPOOL′; STOREPOOL1; STOREPOOL1′;
a : ADDR; sz? : N1 •
pre FreeBlk ∧
AbsSTOREPOOL1 ∧
AbsSTOREPOOL1′ ∧
FreeBlk1
⇒FreeBlk
Proof. The quantiﬁer range 1 . . nextm −1 is equivalent, by the predicate of
AbsSTOREPOOL1, to 1 . . #freebs since nextm = #freebs + 1.
The rest of the proof divides into three cases. However, in all cases, the
equation alloc1′ = alloc1 −sz? occurs. By the predicate of the abstrac-
tion relation, AbsSTOREPOOL1, alloc1 = alloc and by the predicate of
AbsSTOREPOOL1′, alloc1′ = alloc′, so alloc1′ = alloc1−sz? = alloc −sz? =
alloc′.
It should be noted that in all three cases, 1 ≤i ≤nextm −1, by the
predicate of the abstraction relation AbsSTOREPOOL1, is equivalent to 1 ≤
i ≤#freebs, so i is always in range. This has the implication, by the predicates

5.7 Storage Pools
263
of the two abstraction relations, that freebs(i) = freebs1(i) and freebs′(i) =
freebs1′(i).
Case 1. mdaddr(freebs1(i)) = a? + sz?. By the above remarks, this is clearly
equivalent to mdaddr(freebs(i)) = a? + sz?. The update of freebs1 follows
(RHS) from the fact that i is in the range 1 . . nextm −1 or, equivalently, to
1 . . #freebs and (LHS) from the fact that freebs1′(i) = freebs′(i), 1 ≤i ≤
nextm −1.
Case 2. Similar to Case 1.
Case 3. First, it is clear that nextm −1 = nextm′ = #freebs′ = #freebs −1,
since, by AbsSTOREPOOL1, nextm = #freebs+1 and, by AbsSTOREPOOL1,
nextm′ = #freebs′ + 1. Finally, letting m denote mkmd(a?, sz?),
freebs1′
= freebs1 ⊕{nextm →m}
= freebs ⊕{nextm →m}
= freebs ⊕{#freebs + 1 →m}
= freebs ∪{#freebs + 1 →m}
= freebs ⌢⟨m⟩
= freebs′
where, nextm = #freebs + 1. The equivalence of the ﬁrst and last lines is
a consequence of AbsSTOREPOOL1′. The fourth to sixth lines are justiﬁed
by the fact that nextm = #freebs + 1 and #freebs + 1 ̸∈dom freebs, so
freebs⊕{#freebs+1 →m} = freebs∪{#freebs+1 →m}; it is also the case that
(freebs∪{#freebs+1 →m})(#freebs) = last freebs, while (freebs∪{#freebs →
m})(#freebs + 1) = m or last freebs′ = m; therefore, freebs′ = freebs ⌢⟨m⟩.
2
Theorem 65.
∀STOREPOOL; STOREPOOL1 •
pre BlockScavenge ∧AbsSTOREPOOL1 ⇒pre BlockScavenge1
Proof. Since, by the abstraction relation, 1 ≤i, j ≤next −1 iﬀ1 ≤i, j ≤
#freebs, freebs(i) = freebs1(i) and freebs(j) = freebs1(j). The remainder is
trivial. 2
Theorem 66.
∀STOREPOOL; STOREPOOL′; STOREPOOL1; STOREPOOL1′ •
pre BlockScavenge ∧
AbsSTOREPOOL1 ∧
AbsSTOREPOOL1′ ∧
BlockScavenge1
⇒BlockScavenge

264
5 A Separation Kernel
Proof. By the predicates of AbsSTOREPOOL1 and AbsSTOREPOOL1′ and
by the fact that, given AbsSTOREPOOL1, 1 ≤i, j ≤next −1 iﬀ1 ≤i, j ≤
#freebs, freebs(i) = freebs1(i) and freebs(j) = freebs1(j) and, furthermore,
freebs′(i) = freebs1′(i) and freebs′(j) = freebs1′(j). The result then follows
using the deﬁnition of mergemds. 2
The rest of the reﬁned operations are trivially related to the top-level
speciﬁcation and the associated proofs are also trivial (simple identities), so
they are omitted.
5.8 Raw Storage
The last section dealt with a storage allocator. The current section deals with
the storage itself. The speciﬁcation is quite obvious.
First, the necessary error schema is deﬁned. It sets the error variable when-
ever an attempt to address a block fails.
BlockLocError =
(∃e : SYSERR | e = blocklocerror •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
The speciﬁcation requires the deﬁnition of a new type, PSU :
[PSU ]
This is the Primary Storage Unit. On some machines it is a byte and on others
it is a 16-, 32- or 64-bit word.
5.8.1 Top level
The schema representing raw storage is as follows:
STOREVEC
sv : 1 . . svsize →PSU
svsize : N1
startaddr : ADDR
scavcnt : N
scavthresh : N1
The store proper is represented by sv. The size of the store (in terms of PSU )
is given by svsize. The store starts at address startaddr. The remaining two
variables are used for storage management.
This schema can be directly implemented as code, as, indeed, can the
operations deﬁned over it. There is no reﬁnement required in the case of
STOREVEC and its associated operations.

5.8 Raw Storage
265
The initialisation operation is given by the schema:
STOREVECInit
STOREVEC ′
ps? : N1
sa? : ADDR
svsize′ = ps?
startaddr ′ = sa?
The following schema deﬁnes a predicate that is true when the address,
loc?, plus the block size, sz?, is within the storage area being modelled.
CanStoreBlock
ΞSTOREVEC
loc? : ADDR
sz? : N1
startaddr ≤loc?
loc? + sz? ≤startaddr + svsize
The next schema deﬁnes an operation that copies a block of store from
one location to another.
CopyBlock
∆STOREVEC
v? : 1 . . sz? →PSU
loc? : ADDR
sz? : N1
∃a : 1 . . svsize | a = startaddr −loc? •
∀i : 1 . . sz? •
sv ′ = sv ⊕{a + (i −1) →v?(i)
The entire block is passed as v? and the destination address is passed as loc?
and its size is passed as sz?.
The CopyBlock operation is unsafe in the sense that it performs no checks
that the address and size passed to it are correct in the sense that the start
and end of the block are inside the storage area to which the block is to be
copied.
StoreBlock =
(CanStoreBlock ∧CopyBlock ∧SysOk)
∨BlockLocError
The deﬁnition expands into

266
5 A Separation Kernel
StoreBlock
∆STOREVEC
∆ERRV
∆HW
v? : 1 . . sz? →PSU
loc? : ADDR
sz? : N1
(startaddr ≤loc? ∧
loc? + sz? ≤startaddr + svsize ∧
(∃a : 1 . . svsize | a = startaddr −loc? •
∀i : 1 . . sz? •
sv ′ = sv ⊕{a + (i −1) →v?(i)) ∧
serr ′ = sysok)
∨(serr ′ = blocklocerror ∧intno′ = killintno)
The following operation is a checking operation. It returns a block of stor-
age that has been stored in the vector. The returned block is bound to v! and
its size is sz?; the address at which the block starts in the storage vector is
addr?.
StoredBlock
ΞSTOREVEC
∆ERRV
∆HW
addr? : ADDR
sz? : N
v! : 1 . . sz? →PSU
(startaddr ≤addr? ∧
addr? + sz? ≤startaddr + svsize ∧
(∃v : 1 . . sz? →PSU •
(∀i : 1 . . sz? •
v(i) = sv(addr? + i)) ∧
v! = v) ∧
serr ′ = sysok)
∨(serr ′ = badblockaddr ∧intno′ = killintno)
The simpliﬁcation is omitted because it will be used in the expansion and
simpliﬁcation of the next schema.
5.8.2 Message Buﬀering
This subsection contains the deﬁnitions required to turn the storage vector just
deﬁned into an area of store that can be used to represent a buﬀer pool suitable

5.8 Raw Storage
267
for use by a message-passing system. The basic deﬁnitions are performed by
renaming existing components.
First, we deﬁne the storage area for messages. This is done in terms of
renaming, using the STOREVEC state schema and its associated operations.
Note that renaming, in eﬀect, provides us with a new copy of STOREVEC.
It is necessary for the reader to remember that the deﬁnitions that fol-
low are of the storage area only. The storage-management operations will be
deﬁned at this subsection.
MSGSTORE = STOREVEC[mv/sv, mvsize/svsize, mstartaddr/startaddr,
mscavcnt/scavcnt, mscavthresh/scavthresh]
MSGSTOREInit = STOREVECInit
[MSGSTORE ′/STOREVEC ′, mps?/ps?, msa?/sa?]
CanStoreMsg = CanStoreBlock[MSGSTORE/STOREVEC]
StoreMsg = StoreBlock[MSGSTORE/STOREVEC]
StoredMsg = StoredBlock[MSGSTORE/STOREVEC]
In these deﬁnitions, as in the ones that occur at the end of this subsec-
tion, it is assumed that the substitution of the name of the new state schema
(MSGSTORE) for the basic one (STOREVEC) also substitutes the appro-
priate state variables, thus renaming the variables. This convention applies to
CanStoreMsg, StoreMsg and StoredMsg.
The operation to delete stored messages must perform checking. It is de-
ﬁned as:
DeleteStoredMsg =
(∃sz : N | sz = msgsz(msgat(a?)) •
(StoredMsg[a?/addr?, m/v!, sz/sz?] ∧
FreeMsg))
o
9(IncMsgFreeCnt ∧
((ShouldScavengeMsgs ∧MsgScavenge) o
9 ClearMsgFreeCnt))
After expansion and simpliﬁcation, this operation can be transformed into

268
5 A Separation Kernel
DeleteStoredMsg
∆MSGSTORE
∆STOREPOOL
∆ERRV
∆HW
a? : ADDR
(startaddr ≤a? ∧
a? + msgsz(msgat(a?)) ≤startaddr + svsize ∧
(∀i : 1 . . msgsz(msgat(a?)) •
v!(i) = sv(a? + i)) ∧
FreeMsg
o
9(scavcnt = scavthresh −1 ∧
MsgScavenge ∧
scavcnt′ = 0)
serr ′ = sysok)
∨(serr ′ = badblockaddr ∧intno′ = killintno)
Since it is known that FreeBlk1 is a proper reﬁnement of FreeBlk and that
BlockScavenge1 properly reﬁnes BlockScavenge, and noting that STOREVEC
does not reﬁne any further, the above can immediately be reﬁned to
DeleteStoredMsg
∆MSGSTORE
∆STOREPOOL1
∆ERRV
∆HW
a? : ADDR
(startaddr ≤a? ∧
a? + msgsz(msgat(a?)) ≤startaddr + svsize ∧
(∀i : 1 . . msgsz(msgat(a?)) •
v!(i) = sv(a? + i)) ∧
FreeMsg1
o
9(scavcnt = scavthresh −1 ∧
MsgScavenge1 ∧
scavcnt′ = 0)
serr ′ = sysok)
∨(serr ′ = badblockaddr ∧intno′ = killintno)
The remaining storage-area operations are deﬁned as follows. In these and
the next set of deﬁnitions, the renaming convention we described above is
assumed.
IncMsgFreeCnt = IncFreeCnt[MSGSTORE/STOREVEC]
ShouldScavengeMsgs = ShouldScavenge[MSGSTORE/STOREVEC]
ClearMsgFreeCnt = ClearFreeCnt[MSGSTORE/STOREVEC]

5.9 Message Queues
269
The next set of operations deal with storage management. The state space
is called MSGPOOL and corresponds to STOREPOOL. The same renaming
convention is assumed here as for MSGSTORE.
MSGPOOL = STOREPOOL[msgbs/freebs, mgfree/maxfree,
msgalloc/alloc, mpsize/psize,
mscavthresh/scavthresh, mscavcnt/scavcnt]
MSGPOOLInit = STOREPOOLInit[MSGPOOL/STOREPOOL,
mmf ?/mf ?, mba?/ba?, mps?/ps?, mscthrsh?/scthrsh?]
CanAllocateMsg = CanAllocateBlock[MSGPOOL/STOREPOOL]
AllocMsg = AllocBlk[MSGPOOL/STOREPOOL]
FreeMsg = FreeBlk[MSGPOOL/STOREPOOL]
MsgScavenge = BlockScavenge[MSGPOOL/STOREPOOL]
5.9 Message Queues
The separation kernel is intended as a simulation of a distributed system. In
distributed systems, asynchronous message passing is the norm.
The speciﬁcation begins, as usual, with the error schemata.
Each process has a message queue. If the queue becomes full and an at-
tempt is made to enqueue another message, the following schema is used.
MessageQueueFull =
(∃e : SYSERR | e = msgqfull •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
If an attempt is made to dequeue a message from an empty message queue,
the following operation is used to signal the error.
EmptyMessageQueue =
(∃e : SYSERR | e = emptymsgq •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
This message-passing system allows processes to ask for messages from a
designated source. The following schema sets the error variable when there
are no messages from the designated source.
NoMessagesFrom =
(∃e : SYSERR | e = nomsgsfrom •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt

270
5 A Separation Kernel
5.9.1 Top Level
The speciﬁcation can now be undertaken. Basically, the requirement is that a
FIFO queue of message structures is to be speciﬁed. The speciﬁcation that fol-
lows diﬀers from many others in an important aspect. Instead of operating on
message-representing structures, this speciﬁcation consists of schemata deﬁn-
ing operations over message pointers. The queue is, here, a queue of pointers
to messages and the dequeue operation returns a pointer to a message; clearly,
the enqueue operation adds a pointer to a message to the queue. This has the
implication that we must, at some stage, specify the way in which messages
are stored.
The following function creates a message. It requires the source and des-
tination process identiﬁers and some data.
mkmsg : PID × (PID × MSGDATA)
∀src, dest : PID; data : MSGDATA •
mkmsg(src, dest, data) = (src, (dest, data))
The length of message payloads (the data component) is given by the ﬁrst
of the following two functions. The second function returns the length of the
message header; for any system, this function should be a constant.
msgpayloadlen : MSG →N
msghdrlen : MSG →N1
The message header is composed of the source and destination slots (it might
also contain the length of the payload). The header imposes a ﬁxed overhead
on messages and will always be the same.
These two functions are not further speciﬁed.
Given the structure of a message as a product, it is possible to give deﬁ-
nitions for the functions that return the source, destination and data compo-
nents of a message:
msgsrc : MSG →PID
msgdest : MSG →PID
msgdata : MSG →MSGDATA
∀m : MSG •
msgsrc(m) = fst m
msgdest(m) = fst(snd m)
msgdata(m) = snd(snd m)
The address of a message structure is given by the following (partially-
deﬁned) function:
msgaddr : MSG →ADDR

5.9 Message Queues
271
The total size of the message is the size of the payload plus the size of the
header. It is computed by the following function.
msgsz : MSG →N1
∀m : MSG •
msgsz(m) = msgpayloadlen(m) + msghdrlen(m)
Below, the MPTR type is deﬁned. It is the type of message pointers. The
msgat function takes a message pointer and returns the message that is located
at that address; if the pointer is null, msgat returns the null message. Other
than that, the function is not further deﬁned.
msgat : MPTR →MSG
∀mp : MPTR •
msgat(nullmptr) = nullmsg
. . .
msgToPSU : MSG →seq PSU
PSUsToMsg : seq PSU →MSG
These two functions are just type-changing functions or casts.
msz : MSG →N
∀m : MSG •
msz(m) =

0,
if m = nullmsg
msgsz(m), otherwise
We need to get down to the byte level in this speciﬁcation and its reﬁne-
ment.
BYTE == 0 . . 255
msgtobytes : MSG →seq BYTE
This is used by the copy operation.
The message pointer type is a subset of ADDR:
MPTR ⊂ADDR
The null message pointer:
nullmptr : MPTR
Message queues are implemented by a slot in the PTAB. The deﬁnition
at the top level is the following.

272
5 A Separation Kernel
PTAB
. . .
msgq : PID →MSGQ
. . .
dom msgq = used
The usual constraint is imposed upon the domain of msgq.
In the following, the subscript, M , is used. In the schema, all components
of PTAB that do not relate to msgq are assumed constant. This diﬀerentiates
this schema from all others.
ΦPTABM
∆PTAB
∆MSGQ
p? : PID
θMSGQ = msgq(p?)
msgq′ = msgq ⊕{p? →θMSGQ′}
The message queue proper is deﬁned by the following schema. Note that
there is a limit to the size of the queue. The queue obeys the FIFO discipline
and there can be duplicates; a simple sequence is the obvious representation.
MSGQ
mq : seq MPTR
maxms : N1
#mq ≤maxms
The initialisation schema is deﬁned in the obvious manner.
MSGQInit
MSGQ′
mm? : N1
maxms′ = mm?
mq′ = ⟨⟩
The schema that follows deﬁnes the operation that answers the question:
is there enough space in the queue for a new message?
CanEnqueueMsg
ΞMSGQ
#mq < maxms

5.9 Message Queues
273
The enqueue operation simply adds a new message to the end of the queue:
EnqueueMsg
∆MSGQ
mp? : MPTR
mq′ = mq ⌢⟨mp?⟩
As with process queues, the dequeue operation is decomposed into obtain-
ing the queue head and removing it. The complete operation is given by the
following schema:
DelMSGQHd
∆MSGQ
mp! : MPTR
mp! = head mq
mq′ = tail mq
GotMsgs
ΞMSGQ
mq ̸= ⟨⟩
This is a predicate which is true if there are any messages left in the queue.
GotMsgsFromSrc
ΞMSGQ
src? : PID
∃i : 1 . . #mq •
msgsrc(msgat(mq(i))) = src?
This is a predicate which is true when the message queue is not empty and
there is at least one message from process src?. This is the ﬁrst point where the
fact that the entries of the mq FIFO are message pointers becomes important.
In addition to GotMsgsFromSrc, there is the NextMsgFromSrc operation.
It is used when there are messages and at least one is from the destination
speciﬁed by src?. The message is returned as mp!.
NextMsgFromSrc
∆MSGQ
src? : PID
mp! : MPTR
∃i : 1 . . #mq; q1, q2 : seq MPTR •
∃m : MPTR | m = mq(i) •
q1 ⌢⟨m⟩⌢q2 = mq ∧

274
5 A Separation Kernel
q1 ⌢q2 = mq′ ∧
msgsrc(msgat(mq(i))) = src? ∧
mp! = m ∧
(∀j : 1 . . i −1 •
msgsrc(msgat(mq(j))) ̸= src?)
The precondition is clearly
pre NextMsgFromSrc =
mq ̸= ⟨⟩∧
∃m : MSG | m ∈ran mq •
msgsrc(msgat(m)) = src?
The operation to add a message to the queue is deﬁned as follows:
AddMsg =
∃sz : N | sz = msgsz(m?) •
(CanAllocateBlock[sz/rqsz?] ∧
((CanEnqueueMsg ∧
AllocMsg[sz/rqsz?, m/a!] ∧
(∃v : 1 . . N1 →PSU ; sz : N1
| v = msgToPSU (m?) ∧sz = msgsz(m?) •
StoreMsg[v/v?, m/loc?, sz/sz?]) ∧
EnqueueMsg[m/mp!] ∧
SysOk)
∨MessageQueueFull)) \ {m}
∨NoSpace
The operation checks whether a buﬀer can be allocated (if not, the operation
aborts—why continue when the store cannot be allocated?); if it can, the
operation tests that there is space left in the destination process’ message
queue. Next, the message is allocated a buﬀer and stored; it is then enqueued.
The schema for the operation expands and simpliﬁes to:
AddMsg
∆MSGQ
∆ERRV
∆HW
m? : MSG
(alloc + msgsz(m?) ≤psize ∧#freebs < maxfree ∧
(#mq < maxms ∧
((∃i : 1 . . #freebs •
msgsz(freebs(i)) ≥msgsz(m?) ∧
(mdsz(freebs(i)) = msgsz(m?) ∧
freebs′ = freebs −◁{freebs(i)} ∧

5.9 Message Queues
275
alloc′ = alloc + msgsz(m?) ∧
mq′ = mq ⌢⟨mdaddr(freebs(i))⟩∧
startaddr ≤mdaddr(freebs(i)) ∧
mdaddr(freebs(i)) + msgsz(m?) ≤startaddr + svsize ∧
∀j : 1 . . msgsz(m?) •
sv ′ = sv ⊕{(startaddr −mdaddr(freebs(i))) + (j −1)
→msgToPSU (m?)(j)})
∨(mdsz(freebs(i)) > msgsz(m?) ∧
freebs′ = freebs ⊕{i →
mkmd(mdaddr(freebs(i)) + msgsz(m?),
mdsz(freebs(i)) −msgsz(m?))} ∧
alloc′ = alloc + msgsz(m?) ∧
mq′ = mq ⌢⟨mdaddr(freebs(i))⟩∧
startaddr ≤mdaddr(freebs(i)) ∧
mdaddr(freebs(i)) + msgsz(m?) ≤startaddr + svsize ∧
∀j : 1 . . msgsz(m?) •
sv ′ = sv ⊕{(startaddr −mdaddr(freebs(i))) + (j −1)
→msgToPSU (m?)(j)})) ∧
serr ′ = sysok)
∨(serr ′ = msgqfull ∧intno′ = killintno)
∨(serr ′ = nospaceinstore ∧intno′ = killintno))
The precondition must be calculated. It is:
pre AddMsg =
alloc + msgsz(m?) < psize ∧#mq < maxms ∧
(∃i : 1 . . #freebs • msgsz(freebs(i)) ≥msgsz(m?)) ∧
startaddr ≤mdaddr(freebs(i)) ∧
mdaddr(freebs(i)) + msgsz(m?) ≤startaddr + svsize
The NextMsg operation is, basically, a dequeue operation. It tests that
there are messages in the queue and returns the head. If there are no messages,
EmptyMessageQueue is used).
NextMsg =
(GotMsgs ∧DelMSGQHd ∧SysOk) ∨EmptyMessageQueue
The operation expands into
NextMsg
∆MSGQ
∆ERRV
∆HW
mp! : MPTR
(mq ̸= ⟨⟩∧mp! = head mq ∧mq′ = tail mq ∧serr ′ = sysok)
∨(serr ′ = emptymsgq ∧intno′ = killintno)

276
5 A Separation Kernel
The precondition is
pre NextMsg = mq ̸= ⟨⟩
The following is similar to NextMsg but, instead of returning just the head,
it returns the ﬁrst element of the queue that is from the designated source.
The operation performs the relevant checks.
NextMessageFromSource =
((GotMsgsFromSrc ∧NextMsgFromSrc ∧SysOk) ∨NoMessagesFrom
The deﬁnition expands into
NextMessageFromSource
∆MSGQ
∆ERRV
∆HW
src? : PID
mp! : MPTR
(∃i : 1 . . #mq •
msgsrc(msgat(mq(i))) = src?) ∧
(∃i : 1 . . #mq; q1, q2 : seq MPTR •
∃m : MPTR | m = mq(i) •
q1 ⌢⟨m⟩⌢q2 = mq ∧
q1 ⌢q2 = mq′ ∧
msgsrc(msgat(mq(i))) = src? ∧
mp! = m ∧
(∀j : 1 . . i −1 •
msgsrc(msgat(mq(j))) ̸= src?)
This can be simpliﬁed as follows. First, the two outer quantiﬁers have the
same range and matrix, so they can be merged. Next, the one-point rule can
be applied to remove mp!.
NextMessageFromSource
∆MSGQ
∆ERRV
∆HW
src? : PID
mp! : MPTR
serr! : SYSERR
(∃i : 1 . . #mq; q1, q2 : seq MPTR •
q1 ⌢⟨mp!⟩⌢q2 = mq ∧
q1 ⌢q2 = mq′ ∧
msgsrc(msgat(mp!)) = src? ∧
(∀j : 1 . . i −1 •
msgsrc(msgat(mq(j))) ̸= src?)

5.9 Message Queues
277
The precondition must be calculated for this important operation.
pre NextMessageFromSource =
∃i : 1 . . #mq •
msgsrc(msgat(mq(i))) = src? ∧
¬ (∃j : 1 . . i −1 •
msgsrc(msgat(mq(j))) = src?)
This concludes the speciﬁcation. We now turn to its reﬁnement.
5.9.2 Reﬁnement One
We immediately state the reﬁned version of the message queue type. Note
that, by use of promotion, we are separating the development of the queue
type from that of the process table.
MSGQ1
mq1 : 1 . . maxmsgs →MPTR
maxmsgs : N1
mnxt : N
mnxt ≤maxmsgs + 1
The reﬁned message queue type diﬀers from the original in that the former uses
a function to represent the queue; the original used a sequence. The domain
of the function is an subrange of the naturals, so the function represents a
vector. The variable, mnxt, is the index of the next free element of the vector,
mq1.
The initialisation schema is exactly as one might expect.
MSGQInit1
MSGQ1′
mm? : N1
maxmsgs′ = mm?
mnxt′ = 1
The predicate determining whether there are free elements of mq1, the
message queue, is now deﬁned in terms of indices:
CanEnqueueMsg1
ΞMSGQ1
mnxt ≤maxmsgs
Equally, the predicate determining whether there are messages in the queue
is deﬁnded in terms of the mnxt index.

278
5 A Separation Kernel
GotMsgs1
ΞMSGQ1
mnxt > 1
The enqueueing operation consists of assigning a message (pointer) to the
next free element of mq1 and then incrementing mnxt, the end pointer, by
one.
EnqueueMsg1
∆MSGQ1
mp? : MPTR
mq1′ = mq1 ⊕{mnxt →mp?}
mnxt′ = mnxt + 1
Removal of a message consists of copying the ﬁrst element, then copying
the vector down one element; ﬁnally, the insertion point is moved down one
position.
DelMSGQHd1
∆MSGQ1
mp! : MPTR
mp! = mq1(1)
∀i : 1 . . mnxt −2 • mq1′ = mq1 ⊕{i →mq1(i + 1)}
The next operation is the reﬁnment of GotMsgsFromSrc. At any time, there
are only mnxt −1 elements in mq1 (when there are no elements, mnxt = 1).
GotMsgsFromSrc1
ΞMSGQ1
src? : PID
∃i : 1 . . mnxt −1 • msgsrc(msgat(mq1(i))) = src?
The following operation corresponds to NextMsgFromSrc. The two uni-
versals can be accounted for as follows. The second moves all elements from
the one selected for output down one position (so that the hole produced by
selecting a message is healed). The ﬁrst is part of the condition: the selected
message is the ﬁrst in the queue from the source speciﬁed by src?.

5.9 Message Queues
279
NextMsgFromSrc1
∆MSGQ1
src? : PID
mp! : MPTR
∃i : 1 . . mnxt −1; m : MPTR | m = mq1(i) •
msgsrc(msgat(m)) = src? ∧
(∀j : 1 . . i −1 • msgsrc(msgat(mq1(j))) ̸= src?) ∧
(∀j : i + 1 . . mnxt −1 • mq1′ = mq1 ⊕{j −1 →mq1(j)}) ∧
mp! = m
This schema easily simpliﬁes to:
NextMsgFromSrc1
∆MSGQ1
src? : PID
mp! : MPOTR
∃i : 1 . . mnxt −1 •
mp! = mq(i) ∧
msgsrc(msgat(mp!)) = src? ∧
(∀j : 1 . . i −1 •
msgsrc(msgat(mq1(j))) ̸= src?) ∧
(∀j : i + 1 . . mnxt −1 •
mq1′ = mq1 ⊕{j −1 →mq1(j)})
The AddMsg1 operation corresponds to AddMsg:
AddMsg1 =
∃sz : N | sz = msgsz(m?) •
(CanAllocateBlock[sz/rqsz?] ∧
((CanEnqueueMsg1 ∧
AllocMsg1[sz/rqsz?, m/a!] ∧
(∃v : 1 . . N1 →PSU ; sz : N1
| v = msgToPSU (m?) ∧sz = msgsz(m?) •
StoreMsg[v/v?, m/loc?, sz/sz?]) ∧
EnqueueMsg1[m/mp!] ∧
SysOk)
∨MessageQueueFull)) \ {m}
∨NoSpace
After expansion and simpliﬁcation, it is

280
5 A Separation Kernel
AddMsg1
∆MSGQ
∆ERRV
∆HW
m? : MSG
(alloc1 + msgsz(m?) ≤psize1 ∧nextm ≤maxfblocks ∧
(mnxt ≤maxmsgs ∧
((∃i : 1 . . nextm −1 •
msgsz(freebs1(i)) ≥msgsz(m?) ∧
(mdsz(freebs1(i)) = msgsz(m?) ∧
(∀j : i . . nextm −1 •
freebs1′ = freebs1 ⊕{j →freebs1(j + 1)}) ∧
alloc1′ = alloc1 + msgsz(m?) ∧
mq1′ = mq1 ⊕{nextm →mdaddr(freebs1(i))} ∧
nextm′ = nextm + 1 ∧
startaddr ≤mdaddr(freebs1(i)) ∧
mdaddr(freebs1(i)) + msgsz(m?) ≤startaddr + svsize ∧
∀j : 1 . . msgsz(m?) •
sv ′ = sv ⊕{(startaddr −mdaddr(freebs1(i))) + (j −1)
→msgToPSU (m?)(j)})
∨(mdsz(freebs1(i)) > msgsz(m?) ∧
freebs1′ = freebs1⊕
{i →
mkmd(mdaddr(freebs1(i)) + msgsz(m?),
mdsz(freebs1(i)) −msgsz(m?))} ∧
alloc1′ = alloc1 + msgsz(m?) ∧
mq1′ = mq1 ⊕{nextm →mdaddr(freebs1(i))} ∧
−
nextm′ = nextm + 1 ∧
startaddr ≤mdaddr(freebs(i)) ∧
mdaddr(freebs1(i)) + msgsz(m?) ≤startaddr + svsize ∧
∀j : 1 . . msgsz(m?) •
sv ′ = sv ⊕{(startaddr −mdaddr(freebs1(i))) + (j −1)
→msgToPSU (m?)(j)})) ∧
serr ′ = sysok)
∨(serr ′ = msgqfull ∧intno′ = killintno))
∨(serr ′ = nospaceinstore ∧intno′ = killintno))
The precondition is calculated:
pre AddMsg1 =
alloc1 + msgsz(m?) < psize1 ∧
mnxt < maxmsgs ∧
(∃i : 1 . . nextm −1 • msgsz(freebs1(i)) ≥msgsz(m?)) ∧
startaddr ≤mdaddr(freebs1(i)) ∧
mdaddr(freebs1(i)) + msgsz(m?) ≤startaddr + svsize

5.9 Message Queues
281
Operation NextMsg1 corresponds to NextMsg:
NextMsg1 =
(GotMsgs1 ∧DelMSGQHd1 ∧SysOk)
∨EmptyMessageQueue
This deﬁnition expands into:
NextMsg1
∆MSGQ1
∆ERRV
∆HW
mp! : MPTR
(mnxt > 1 ∧
mp! = mq1(1) ∧
(∀i : 1 . . mnxt −2 • mq1′ = mq1 ⊕{i →mq1(i + 1)}) ∧
serr ′ = sysok) ∨(serr ′ = emptymsgq ∧intno′ = killintno)
The precondition of this operation is
pre NextMsg1 = mnxt > 1
The NextMessageFromSrc1 operation corresponds to NextMessageFrom-
Src. The deﬁnition is
NextMessageFromSrc1 =
((GotMsgsFromSrc1 ∧
NextMsgFromSrc1 ∧SysOk)
∨NoMessagesFrom
The deﬁnition expands to
NextMessageFromSrc1
∆MSGQ1
∆ERRV
∆HW
src? : PID
mp! : MPOTR
((∃i : 1 . . mnxt −1 •
msgsrc(msgat(mq1(i))) = src?) ∧
(∃i : 1 . . mnxt −1; m : MPTR •
m = mq(i) ∧mp! = m ∧
msgsrc(msgat(mp!)) = src? ∧
(∀j : 1 . . i −1 •
msgsrc(msgat(mq1(j))) ̸= src?) ∧
(∀j : i + 1 . . mnxt −1 •
mq1′ = mq1 ⊕{j −1 →mq1(j)})) ∧
mnxt′ = mnxt −1 ∧

282
5 A Separation Kernel
serr ′ = sysok)
∨(serr ′ = nomsgsfrom ∧intno′ = killintno)
This schema can be simpliﬁed to produce
NextMessageFromSrc1
∆MSGQ1
∆ERRV
∆HW
src? : PID
mp! : MPOTR
(∃i : 1 . . mnxt −1 •
mp! = mq1(i) ∧
msgsrc(msgat(mp!)) = src? ∧
(∀j : 1 . . i −1 •
msgsrc(msgat(mq1(j))) ̸= src?) ∧
(∀j : i + 1 . . mnxt −1 •
mq1′ = mq1 ⊕{j −1 →mq1(j)})) ∧
mnxt′ = mnxt −1 ∧
serr ′ = sysok)
∨(serr ′ = nomsgsfrom ∧intno′ = killintno)
The precondition is
pre NextMessageFromSrc1 =
∃i : 1 . . mnxt −1 •
msgsrc(msgat(mq1(i))) = src? ∧
¬ (∃j : 1 . . i −1 •
msgsrc(msgat(mq1(i))) = src?)
Finally, the abstraction relation is deﬁned.
AbsMSGQ1
MSGQ
MSGQ1
maxmsgs = maxms
mnxt = #mq + 1
∀i : 1 . . #mq •
mq(i) = mq1(i)
There should be no surprises here!
Theorem 67.
∀MSGQ′; MSGQ1′ •
MSGQ1Init ∧AbsMSGQ1 ⇒MSGQInit

5.9 Message Queues
283
Proof. By the abstraction relation, maxmsgs′ = maxms′, so mm? =
maxmsgs′ = maxms′. The abstraction relation also states that mnxt =
#mq + 1, so mnxt′ = 1 = #mq + 1 = 0 + 1, from which it follows that
mq′ = ⟨⟩. 2
Theorem 68.
∀MSGQ; MSGQ1; m? : MSG
pre AddMsg ∧AbsMSGQ1 ∧AbsSTOREPOOL1 ⇒pre AddMsg1
Proof. The preconditions are:
pre AddMsg =
alloc + msgsz(m?) < psize ∧
#mq < maxms ∧
(∃i : 1 . . #freebs • msgsz(freebs(i)) ≥msgsz(m?)) ∧
startaddr ≤mdaddr(freebs(i)) ∧
mdaddr(freebs(i)) + msgsz(m?) ≤startaddr + svsize
and
pre AddMsg1 =
alloc1 + msgsz(m?) < psize1 ∧
mnxt ≤maxmsgs ∧
(∃i : 1 . . nextm −1 • msgsz(freebs1(i)) ≥msgsz(m?)) ∧
startaddr ≤mdaddr(freebs1(i)) ∧
mdaddr(freebs1(i)) + msgsz(m?) ≤startaddr + svsize
It should be noted that the STOREVEC component cannot be subjected
to reﬁnement. Therefore, there is an identity relation between the components
of STOREVEC in the two preconditons.
The abstraction relation states that psize = psize1, alloc = alloc1 and
that maxmsgs = maxms. It also states that mnxt = #mq + 1. This permits
the inferences that alloc +msgsz(m?) < psize ⇔alloc1+msgsz(m?) < psize1
and #mq < maxms ⇔mnxt ≤maxmsgs.
The range of the quantiﬁer is 1 . . #freebs and by the abstraction relation
for STOREPOOL, #freebs = nextm −1, and that abstraction relation also
states that ∀i : 1 . . #freebs • freebs(i) = freebs1(i)x, so it follows that
msgsz(freebs(i)) ≥msgsz(m?)
⇔msgsz(freebs1(i)) ≥msgsz(m?)
mdaddr(freebs(i)) = mdaddr(freebs1(i)) and, ﬁnally, that
mdaddr(freebs(i)) + msgsz(m?) ≤startaddr + svsize
⇔mdaddr(freebs1(i)) + msgsz(m?) ≤startaddr + svsize
2

284
5 A Separation Kernel
Theorem 69.
∀MSGQ; MSGQ′; MSGQ1; MSGQ1′; m? : MSG •
pre AddMsg ∧
AbsMSGQ1 ∧
AbsMSGQ1′ ∧
AbsSTOREPOOL1 ∧
AbsSTOREPOOL1′ ∧
AddMsg1
⇒AddMsg
Proof. The abstraction relations states that alloc = alloc1, maxfree =
maxfblocks and #freebs
= nextm −1. This permits the inference that
alloc + msgsz(m?) = alloc1 + msgsz(m?) and #freebs < maxfree implies
that nextm ≤maxfblocks. The relation also states that #mq = mnxt −1,
so mnxt ≤maxmsgs implies #mq < maxms. The same relation permits the
inference that nextm−1 = #freebs, so the bound variable of the outer existen-
tial quantiﬁer is in range and it can be inferred that freebs(i) = freebs1(i) (for
the reason that ∀i : 1 . . #freebs • freebs(i) = freebs1(i) ⇒∃i : 1 . . #freebs •
freebs(i) = freebs1(i)). This permits the inference that mdsz(freebs(i)) =
mdsz(freebs1(i)) and mdaddr(freebs(i)) = mdaddr(freebs1(i)). Most of the
remainder of the proof follows immediately.
The only point of note is
∀j : i . . nextm −1 •
freebs1′ = freebs1 ⊕{j →freebs1(j + 1)}
This clearly removes freebs1(i) from freebs1 and corresponds directly to
freebs′ = freebs −▷{freebs(i)}. In support of this claim, the following rea-
soning is oﬀered. The above formula implies that freebs1′(i) = freebs1(i + 1),
so freebs1(i) is no longer an element of freebs1′. By the equivalence of freebs′
and freebs1′ required by AbsSTOREPOOL1′, freebs(i) cannot be an element
of freebs′(i), so freebs′ = freebs −▷{freebs(i)}. 2
Theorem 70.
∀MSGQ; MSGQ1 •
pre NextMsg ∧AbsMSGQ1 ⇒pre NextMsg1
Proof. The preconditions are as follows:
pre NextMsg = mq ̸= ⟨⟩
and
pre NextMsg1 = mnxt > 1
By the abstraction relation, mnxt = #mq + 1, so if mq = ⟨⟩, mnxt = 1 since
#⟨⟩= 0. If mq ̸= ⟨⟩, #mq > 0, so mnxt > 1. 2

5.9 Message Queues
285
Theorem 71.
∀MSGQ; MSGQ′; MSGQ1; MSGQ1′; mp! : MPTR; •
pre NextMsg ∧
AbsMSGQ1 ∧
AbsMSGQ1′ ∧
NextMsg1
⇒NextMsg
Proof. By the previous result, mnxt > 1 implies mq ̸= ⟨⟩. Since 1 is in
range as an index of mq1, the predicate of AbsMSGQ1 permits the inference
that mq1(1) = mq(1) and mq(1) = head mq by the deﬁnition of head; so,
mp! = mq1(1) = head mq.
The quantiﬁed formula ∀i : 1 . . mnxt • mq1′ = mq1 ⊕{i →mq1(i + 1)}
translates mq1 one position downwards with the result that mq1′(1) = mq1(2)
and so on. This is the removal of the ﬁrst element of mq1 which, as noted in
the last paragraph is equivalent to head mq. The removal of the head of a
sequence is the result of the tail operation and it is clear that the universally
quantiﬁed formula is equivalent to mq′ = tail mq. 2
Theorem 72.
∀MSGQ; MSGQ1; src? : PID •
pre NextMessageFromSource ∧AbsMSGQ1 ⇒pre NextMessageFromSource1
Proof. The preconditions are:
pre NextMessageFromSource =
∃i : 1 . . #mq •
msgsrc(msgat(mq(i)) = src? ∧
¬ (∃j : 1 . . j −1 •
msgsrc(msgat(mq(j))) = src?)
and
pre NextMessageFromSource1 =
∃1 . . mnxt −1 •
msgsrc(msgat(mq1(i))) = src? ∧
¬ (∃j : 1 . . i −1 •
msgsrc(msgat(mq1(i))) = src?)
By the abstractin relation, mnxt = #mq −1, so #mq = mnxt −1. From
this, the equivalence of ranges of the outer quantiﬁers can be inferred. This
equivalence also permits us to infer that ∀i : 1. .#mq • mq(i) = mq1(i)) and,
then, that msgsrc(msgat(mq(i))) = msgsrc(msgat(mq1(i))) for 1 ≤i ≤#mq.
2

286
5 A Separation Kernel
Theorem 73.
∀MSGQ; MSGQ′; MSGQ1; MSGQ1′; src? : PID; mp! : MPTR •
pre NextMessageFromSource ∧
AbsMSGQ1 ∧
AbsMSGQ1′ ∧
NextMessageFromSource1
⇒NextMessageFromSource
Proof. First of all, it is necessary to observe that mnxt−1 = #mq is a simple
consequence of AbsMSGQ1, so it can be inferred that the outermost quantiﬁer
ranges are equivalent. This also permits the inference that ∀i : 1 . . #mq •
mq(i) = mq1(i) and that msgsrc(msgat(mq(i))) = msgsrc(msgat(mq1(i)))
for 1 ≤i ≤#mq; in particular, if 1 ≤i ≤#mq and j < i, this identity also
holds. It also permits the inference that
∀j : i + 1 . . mnxt −1 •
mq1′
= mq1 ⊕{j −1 →mq1(j)}
= mq ⊕{j −1 →mq1(j)}
= mq ⊕{j −1 →mq(j)}
= mq′
The equivalence of mq1′ and mq′ is assured by the condition in AbsMSGQ1′
that ∀i : 1. .#mq′ • mq′(i) = mq1′(i); the remainder of the steps are justiﬁed
by the equivalence noted above.
Finally, it can be seen that if msgsrc(msgat(mq1(i))) = src?, mq1 is di-
vided into three segments: an initial segment (1 ≤j < i), the segment con-
sisiting only of mq1(i) and a ﬁnal segment whose indices are in the range
i +1 ≤j ≤mnxt −1. The last range, in mq, is i +1 ≤j ≤#mq. Since mq and
mq1 coincide by the AbsMSGQ1, it is possible to write mq as q1⌢⟨mq(i)⟩⌢q2,
where q1(j) = mq(j) for 1 ≤j < i, and q2(j) = mq(j) for i + 1 ≤j ≤#mq.
The quantiﬁer ∀j : i + 1 . . mnxt −1 • mq1′ = mq1 ⊕{j −1 →mq1(j) clearly
removes mq1(i) from mq1. From this, it can be concluded that mq′ = q1 ⌢q2.
To verify this, mq1′(i) = mq1(i + 1) and mq′(i) = mq(i + 1) = head q2; by
the abstraction relation, head q2 = mq1(i + 1). 2
This module is now at a level where implementation is possible.
5.10 Kernel Interface – User Processes
5.10.1 Auxilliary Operations
VerifyCallerIdent =
(RunningProcess[c/p!] ∧PIDforUPID[c/p!]) \ {c}

5.10 Kernel Interface – User Processes
287
or
VerifyCallerIdent
ΞPTAB
u? : UPID
curr = extpid(u?)
InsuﬃcientMainStore =
(∃e : SYSERR | e = mainstorefull •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
SEGMENTS =
STOREPOOL[frees/freebs, maxsgs/maxfree,
allocs/alloc, spsize/psize, spaddr/paddr]
SEGMENTSInit = STOREPOOLInit[frees/freebs, maxsgs/maxfree,
allocs/alloc, spsize/psize, spaddr/paddr]
AllocateSegment = AllocBlk[frees/freebs, maxsgs/maxfree, allocs/alloc]
FreeSegment = FreeBlk[frees/freebs, maxsgs/maxfree, allocs/alloc]
CanAllocateSegment = CanAllocateBlock[allocs/alloc, frees/freebs]
The following is just a convenience
SegmentTableInit = SEGMENTSInit
For present purposes, it is assumed that segmentation is aimed at the
output of the GNU C compiler, which requires two segments. One segment
is the code segment (also called the “text” segment and is assumed to be
read-only), the other is the combined stack and data segment. In the latter
segment, the stack is assumed to grow downwards from the top, while data is
allocated upwards from the bottom.
The size of the code segment is codesz and that of the combined stack and
data segment is dssize. The descriptors returned are sd! for the stack segment
and ds! for the other segment.
The descriptors are sd? for the stack segment and ds? for the combined
segments.
It is also necessary to declare some store to be used as a message
pool. This entails the allocation of a STOREVEC and a STROREPOOL;
the STOREPOOL, however, must be distinct from the segment table just
described.

288
5 A Separation Kernel
5.10.2 Initialisation
This subsection deals with system initialisation for non-device processes.
The ﬁrst task is to deﬁne the operations on segments in main store. To
do this, it is necessary to deﬁne the type for segment descriptors. Segment
descriptors are composed of an address (the start of the segment) and a size
(the size of the segment in some units—bytes seem the most appropriate).
SDESC == ADDR × N
The size (the second component) must admit zero so that the null process can
be represented.
Given this type deﬁnition, it is useful to have a constructor function for
segment descriptors, just as we had for storage descriptors (type MD).
mksdesc : ADDR × N →SDESC
∀a : ADDR; s : N •
mksdesc(a, s) = (a, s)
The constructor function just creates pairs.
It is also useful to have accessor functions, one for each component.
segaddr : SDESC →ADDR
segsize : SDESC →N
∀s : SDESC •
segaddrs(s) = fst s
segsize(s) = snd s
The ﬁrst accessor returns the segment’s start address, while the second returns
the size.
The process table is expanded by two components: one to record code seg-
ment information and one to record data and stack segment information. The
code segment information is stored in cdseg and that for the combined data
and stack segement is stored in dsseg. Clearly there must be one segment of
each type for every process (the idle, or null, process must have zero segments,
recall for the reason that it does not have any data, does not consume a stack,
nor does it have a code segment—the code for the idle process is a part of the
kernel).
PTAB
...
cdseg : PID →SDESC
dsseg : PID →SDESC

5.10 Kernel Interface – User Processes
289
· · ·
...
The segment usage of the GNU C compiler is assumed (it uses two segments,
one for code and one for data and the stack—the stack resides at the top of
the data segment and grows downwards towards the area in which data is
stored). The invariant for cdseg (the code segment) and that for the combined
stack and data segment, dsseg, is the same.
The operation to set the code segment information for a process is deﬁned
by the following schema:
SetCodeSegInfo
∆PTAB
p? : PID
a? : ADDR
sz? : N
cdseg′ = cdseg ∪{p? →mksdesc(a?, sz?)}
Segments are allocated only once, so any data that is set remains in the process
table until its owning process is deleted.
In a similar fashion, the combined stack and data segment information for
a new process is set by the following schema:
SetStackDataSegInfo
∆PTAB
p? : PID
a? : ADDR
sz? : N
dsseg′ = dsseg ∪{p? →mksdesc(a?, sz?)}
The next two schemata use the accessor functions deﬁned for segment
descriptors and apply them to the segments of a process. This ﬁrst schema
returns the descriptor for the code segment.
CodeSegAddr
ΞPTAB
p? : PID
a! : ADDR
a! = segaddr(cdseg(p?))
The second schema returns the combined segment for the named process.

290
5 A Separation Kernel
StackDataSegAddr
ΞPTAB
p? : PID
a! : ADDR
a! = segaddr(dsseg(p?))
The following operation sets the registers up ready for the context switch
to the intial process. The most important part of this consists of setting the
registers to default or dummy values so that they can be switched into the
processor’s registers. The entry point of the initial process must be speciﬁed
as the address at which to start the execution of the initial process when
swapped onto the processor.
SwitchToFirstProcess =
CreateDummyRegs
o
9 . . .
The idle process must be created. The kernel contains the code that imple-
ments this process. The code has to be made into a process. First, a process
identiﬁer (PID) must be created using AddIdleProcess. Next, the segments
must be created. As noted above, each segment has a zero start address (rep-
resented by nulladdr and has a size of 0. The segment information must be
stored in the process table.
CreateIdleProcess =
AddIdleProcess ∧
AllocateProcTSS ∧
∧(∃na : ADDR; nsz : N | na = nulladdr ∧nsz = 0 •
SetCodeSegInfo[ip!/p?, na/a?, nsz/sz?]
o
9SetStackDataSegInfo[ip!/p?, na/a?, nsz/sz?])
The CreateIdleProcess operation is required so that the scheduler can be
initialised. It is now possible to deﬁne the SKInitSys operation, the operation
that represents the initialisation of the system proper.
SKInitSys =
AllocateGDT ∧AllocateIDT ∧AllocateTSSs ∧
InitDevNums ∧
PTABInit ∧
SegmentTableInit ∧
MSGSTOREInit ∧
MSGPOOLInit ∧
((SKCreateNullProcess[ip/ip!] ∧SKSCHEDInit[ip/p?]) \ {ip}
o
9SKCreateAndRunInitialProcess)
First, the process table is initialised to empty and the segment table is also
initialised to empty. The storage area for messages is allocated and initialised,

5.10 Kernel Interface – User Processes
291
as is the descriptor space. Next the idle (null) process is created and its data
stored in the process table. The scheduler is then initialised and the identiﬁer
of the idle process is stored in the variable in the scheduler. Finally, the initial
process is created and its data stored in the process table. The intial process
is then executed.
5.10.3 Process Management
The process management operations must be deﬁned. These operations handle
such matters as segment allocation and process creation. The operations in
this section deal with user processes only.
The segment allocation operation is deﬁned as follows:
AllocateSegments =
∃totsize : N1 | totsize = cdssize? + stkdsize? •
(CanAllocateSegment[totsize/rqsz?] ∧
AllocateSegment[totsize/rqsz?, csaddr!/c!] ∧
stkaddr! = csaddr! + cdssize? ∧
SysOk)
∨InsuﬃcientMainStore
The deﬁnition expands into:
AllocateSegments
∆STOREPOOL
∆ERRV
∆HW
cdssize?, stkdsize? : N
csaddr!, stkdaddr! : ADDR
∃totsize : N1 | totsize = cdssize? + stkdsize? •
(totsize + alloc ≤psize ∧
(#frees < maxsgs ∧
(∃i : 1 . . #frees • mdsz(frees(i)) ≥totsize) ∧
AllocateSegment[totsize/rqsz?, csaddr!/a!] ∧
stkaddr! = csaddr! + cdssize? ∧
serr ′ = sysok)
∨(serr ′ = mainstorefull ∧intno′ = killintno)
The primitive for creating new processes is as follows:

292
5 A Separation Kernel
SKNewProcess =
(AllocSegments[totsize?/rqsz?, csaddr/csaddr!, stkdaddr/stkdaddr] ∧
(∃pt : PTYPE | pt = uproc • AddPD)
o
9SetCodeSegInfo[cdssize?/sz?, csaddr/a?]
o
9SetSetDataSegInfo[stkdsize?/sq?, stkdaddr/a?]))
o
9AllocateProcTSS ∧AddPD
o
9InitDevReply
o
9ClearMsgQ
o
9Clear
o
9 MakeReady[p!/p?]
∧SysOk) \ {csaddr, stkdaddr}
First, the segments for the new process are allocated. The segment informa-
tion is then stored in PTAB and the process is made ready (added to the
scheduler’s ready queue).
The UPID for each process is returned to the newly created process, while
the PID is retained by the kernel and never revealed to an untrusted process.
The expansion of SKNewProcess is quite long and can be transformed by
the use of the distributive rule for ∧over ∨.
Register values need to be set before the process can run. All the informa-
tion is, though, present.
When a request to create a new process is made, it must be made by some
process or other. In the basic model, it should be the initial process but it
is possible to arrange for other processes to have the ability to create child
processes. Whatever approach is adopted, the identity of the creating process
must be veriﬁed. If veriﬁcation succeeds, SKNewProcess is called to create the
process in PTAB and add it to the ready queue. The operation is deﬁned as
follows:
USKNewProcess =
(VerifyCallerIdent ∧
SKNewProcess[p/p!] \ {p})
∨BadCallerIdent
Creating a processes is only half the story. It is necessary to create and
execute an initial process just so that there is something to which a half
context switch can be made. The initial process can be put to many uses, one
of which is as the ancestor of all processes in the system. For present purposes,
the initial process in this speciﬁcation just serves as a place to which context
can be switched.
CreateAndRunInitialProcess =
(SKNewProcess[fp/p!] o
9 RunFirstProcess[fp/p?]) \ {fp}
The RunFirstProcess operation assumes that no other processes are execut-
ing. It must be executed during the low-level initialisation operation. If this
condition is violated, process switches will fail. The operation basically sets
up the stack with registers that can be popped when the ﬁrst context switch

5.10 Kernel Interface – User Processes
293
occurs; in order for the ﬁrst context switch not to fail, the stack have the
contents the hardware expects. Since we are not using the process stack for
intermediate register storage, the stack need only to be initialised to the entry
point of the initial process and the ﬂags register (F register on the IA32).
The operation can be approximated by the following:
SetupFirstProcess
p? : PID
ep? : ADDR
ﬂgs? : WORD
push stack(p?, ep?)
push stack(p?, ﬂgs?)
SetHWTSS
∆HW
ΞPTAB
p? : PID
hwtss′ = tss(p?);
RunFirstProcess =
(SetupFirstProcess o
9 SetHWTSS) o
9 ContextSwithc
Processes must be able to suspend themselves. The basic idea adopted for
the Separation Kernel is that natural-break scheduling should be employed.
This has the implication that each process, by and large, determines for itself
when it should be suspended. The self-suspending operation is deﬁned by the
next schema:
SKSuspendSelf = (RequeueUserProcess o
9 SwitchContext)
This operation is then wrapped inside a check on the identity of the re-
questing process, as follows:
USKSuspendSelf =
(VerifyCallerIdent ∧SKSuspendSelf )
∨BadCallerIdent
The last action a process takes is to terminate itself. The following schema
deﬁnes this operation.
SKTerminateSelf =
((RunningProcess[c/p!] ∧
SetStateToTerminated[c/p?] ∧
FreeCodeSegment[c/p?] ∧
FreeSDSegment[c/p?] ∧
(DelProcUPID o
9 DelPD[c/p?]) \ {c})
o
9SKSchedNext)

294
5 A Separation Kernel
For security, it must be wrapped inside an identity test.
USKTerminateSelf =
(VerifyCallerIdent ∧SKTerminateSelf )
∨BadCallerIdent
5.10.4 Message Passing
The operations in this subsection are mostly those deﬁned above. The main
diﬀerence is that what is deﬁned here is part of the system call’s handling
code.
In the deﬁnition of message-passing operations at the interface between
the kernel and user processes, promotion is extensively employed. The reader
will remember that in the section in which the message-passing primitives
were deﬁned, the ΦPTABM schema was deﬁned but not used; it is in the deﬁ-
nition of the following operations that this schema ﬁnds its use. It is necessary
to recall that promotion has the useful property that the reﬁnement of the
contained and containing state spaces can proceed independently. Because of
this, the reﬁnement of the operations in this section requires little or no extra
work here.
When sending a message, the user process (or libary routine) has the
following interface
UsrSendMsgI
...
dest? : UPID
data? : MSGDATA
...
...
At the interface to the message-passing subsystem, user processes only
communicate identiﬁers as elements of UPID, not as elements of PID. The
interface operation for sending a message can be deﬁned as
...
dest? : UPID
data? : MSGDATA
result! : YESNO
...
Inside the module handling message passing, a translation scheme will need
to be employed. Note ﬁrst that the above schema does not actually construct

5.10 Kernel Interface – User Processes
295
a message object, while the message-queueing operations do. This provides an
opportunity, as follows.
First, assume that the following is called after the veriﬁcation of the caller
(or src?, that is).
TranslateMessageAddrs
ΞPTAB
src?, dest? : UPID
data? : MSGDATA
m! : MSG
∃srcpid, destpid : PID •
PIDforUPID[src?/u?, srcpid/p!] ∧
PIDforUPID[dest?/u?, destpid/p!] ∧
∃m : MSG •
msgsrc(m) = srcpid ∧
msgdest(m) = destpid ∧
msgdata(m) = data? ∧
m! = m
This operation could be implemented as a pair of assignments if the number
of bits required to store elements of PID ≤the number of bits required to
store elements of UPID.
On the output side, there is the need to translate a message structure into
a form that can be understood by a user process.
MSGToUserData
ΞPTAB
src! : UPID
dest! : UPID
data! : MSGDATA
m? : MSG
src! = pidext(msgsrc(m?))
dest! = pidext(msgdest(m?))
data! = msgdata(m?)
In order for this operation to work properly, it is essential that the outputs
are placed on the user-process stack.
Using this approach, it is possible to deﬁne the remaining user-level oper-
ations.
When a message is sent, the user interface passes objects of type UPID as
well as the message payload (the message data, an object of type MSGDATA).
It is necessary to translate the UPID objects to objects of type PID and to
create an object of type MSG.

296
5 A Separation Kernel
TranslateMsgAddrs
ΞPTAB
src?, dest? : UPID
data? : MSGDATA
m! : MSG
∃srcpid, destpid : PID •
PIDforUPID[src?/u?, srcpid/p!] ∧
PIDforUPID[dest?/u?, destpid/p!] ∧
∃m : MSG •
msgsrc(m) = srcpid ∧
msgdest(m) = destpid ∧
msgdata(m) = data? ∧
m! = m
This schema simpliﬁes to:
ΞPTAB
src?, dest? : UPID
data? : MSGDATA
m! : MSG
msgsrc(m!) = extpid(src?)
msgdest(m!) = extpid(dest?)
msgdata(m!) = data?
The object, m!, will have to be stored using AddMsg; meanwhile, it remains
on the stack. This causes no problems because AddMsg allocates dynamic
storage for the message and only requires that the message take the form of
a record or structure.
Promotion is used to deﬁne the basic operations, as observed when deﬁning
the message queue type. The SendToProcess operation adds a message to the
destination process/
SendToProcess =
∃∆MSGQ • ΦPTABM ∧AddMsg
The full send-message primitive is deﬁned as:
USKSendMsg =
(VerifyCallerId ∧
(∃mu : MSG; sz : N1; d : PID | sz = msgsz(mu) •
PIDforUPID[dest?/u?, d/p!] ∧
TranslateMsgAddrs[u?/src?, mu/m!] ∧
SendToProcess[d, mu/m?, sz/rqsz?] ∧
SysOk))
∨BadCallerIdent

5.10 Kernel Interface – User Processes
297
This is the interface operation. It veriﬁes the caller’s identity.
The data in a message has to be extracted so that it can be handed to the
destination process. the following operation does this.
MSGToUserData
ΞPTAB
src! : UPID
dest! : UPID
data! : MSGDATA
datalen! : N
m? : MPTR
src! = pidext(msgsrc(msgat(m?)))
dest! = pidext(msgdest(msgat(m?)))
data! = msgdata(msgat(m?))
datalen! = msgpayload(msgat(m?))
This operation is a surrogate boolean. It is used to return a value to user
processes attempting to determine whether they have messages (or messages
from a stated source) in their message queue.
UReturnYes
resp! : YESNO
resp! = yes
UReturnNo
resp! : YESNO
resp! = no
The operation that tests for the presence of messages in its message queue
is now deﬁned. This is a promoted operation.
ProcessHasMsgs =
∃∆MSGQ • ΦPTABM ∧GotMsgs
The interface primitive for the GotMsgs predicate is the following:
USKGotMsgs =
(VerifyCallerIdent ∧
(PIDforUPID[p/p!] ∧
((ProcessHasMsgs[p/p?] ∧UReturnYes) ∨UReturnNo) \ {p}
SysOk)
∨BadCallerIdent

298
5 A Separation Kernel
This operation can be called from a user process.
The operation to return the next message in the queue is now deﬁned by
promotion.
NextMsgForProcess =
∃∆MSGQ • ΦPTABM ∧NextMsg
The user-interface level operation for getting the next message is deﬁned
as
SKNextMsg =
(VerifyCallerIdent ∧
(PIDforUPID[p/p!] ∧
(∃mp : MPTR •
((NextMsgForProcess[mp/mp!] ∧MSGToUserData[mp/m?])
o
9DeleteStoredMsg[mp/addr?])
∧SysOk))
∨BadCallerIdent
As can be seen from the deﬁnition of the message queue type, processes
can determine whether there are any messages from a given source in its input
message queue.
ProcessHasMsgsFromSrc =
∃∆MSGQ •
ΦPTABM ∧GotMsgsFromSrc
The operation that can be invoked from a user interface is the following:
SKProcessHasMsgsFromSrc =
(VerifyCallerIdent ∧
(PIDforUPID[src?/u?, srcpid/p!] ∧
PIDforUPID[destpid/p!] ∧
(ProcessHasMsgsFromSrc[destpid/p?, srcpid/src?] ∧UReturnYes)
∨UReturnNo)) \ {srcpid, destpid}
∨BadCallerIdent
Promotion is used to deﬁne the actual operation.
NextMsgForProcessFromSrc =
∃∆MSGQ •
ΦPTABM ∧NextMsgFrom
The operation actually to get the next message is deﬁned below.

5.11 Devices—Trusted Code
299
SKNextMsgFrom =
(VerifyCallerIdent ∧
(PIDforUPID[src?/u?, srcpid/p!] ∧
PIDforUPID[destpid/p!] ∧
(∃mp : MPTR •
SKNextMsgFromSrc[destpid/p?, srcpid/src?, mp/mp!] ∧
MSGToUserData[mp/m?))
o
9DeleteStoredMsg) \ {srcpid, destpid})
∨BadCallerIdent
5.11 Devices—Trusted Code
Devices are trusted processes. In this design, trust only goes so far. Devices
are not permitted full access to the kernel and have to respect a well-deﬁned
interface.
It would be extremely expensive to have each device process occupy its
own set of segments. It is more convenient to have them reside in the same
address space as the kernel. It would be preferable for each device not to have
a stack but, inevitably, many will.
Device processes are expected never to terminate. For simplicity, it is as-
sumed that, should it be necessary to replace a driver, the system must be
shut down and rebooted with the new driver conﬁgured.
There are two main parts:
1. activation as a result of a user-process request, and
2. activation as a result of the device becoming ready or having data ready
to read.
The links between device processes, the devices they control and the
processes that require their services must be provided. The relationship be-
tween the device process and the physical device is a matter of addressing;
each physical device has its own set of reserved addresses, so this is not an
issue. This alone requires device processes either to be constructed of
•
a component that operates on the physical device, and
•
a component that handles requests from user processes and that passes
data back to user processes (when required).
This separation of concerns is attractive.
Clearly, there must be an ISR to handle interrupts generated by the phys-
ical device’s interface. The ISR can cause a component of the device process
to execute. One way to do this is to use a semaphore. A second way is for the
ISR to send a message. The message need not be anything involved because
it merely denotes the availability of the device for writing or the availability
of data for reading.

300
5 A Separation Kernel
On the other side, user processes must make a request to the device process.
The user process might then wait for the request to be serviced (e.g., when
it is a request for data) or might continue (e.g., when the request is to write
data). Synchronous protocols for writing might also be employed in which
the servicing entity returns a sucess code to the user process. A synchronous
interface can be implemented using the standard message-passing operations.
For the time being, it is assumed that the low-level device interface consists
of an ISR and a set of addresses plus a piece of code that interfaces to the
command bits in that address set. It is assumed that the code can be directly
accessed by the device process.
A simple solution at the bottom level for reads is that the ISR hands a
pointer to the newly input buﬀer to the device process, then places the device
process on the device ready queue and causes a reschedule.
The device process, on the other hand, has made the device request and
has passed any parameters to the device. Immediately thereafter, the device
process suspends. Upon resumption, the device process reads the contents of
the buﬀer passed to it by the ISR and passes the associated data or result
code to the requesting user process.
This assumes that requests can be serviced in a simple FIFO manner and
that the ISR knows the identiﬁer of the device process. It also assumes that the
device interface can be directly addressed by the device process. The second
assumption suggests that:
•
The device process resides in the same address space as the device-
manipulating code. This implies that the device process resides in the
kernel’s address space.
•
There must be some kind of buﬀer space inside the kernel to hold the data
passed to and from devices.
•
The interface to device processes can be eﬀected via a mapping table.
This has the implication that all devices are conﬁgured before the sys-
tem is started. This scheme also permits the user-process interface to be
extended to include a (polymorphic) DeviceCall operation. Furthermore,
this scheme is in line with the general approach adopted here that user
processes access the kernel and its services only by means of a well-deﬁned
and relatively small set of operations.
Storing device processes in the kernel’s address space is just a convenience to
avoid an expensive segment swap; it is also necessary for most processors allow
only a limited number of physical segments. In this speciﬁcation, only physical
segmentation is assumed for the reason that it does not involve any secondary
storage. Swapping between main and secondary storage could provide a secu-
rity hole for the malicious; the assumption also has speed advantages.
Placing device processes in the kernel address space does not imply that
they have complete access to the kernel. Even for device processes, all kernel
operations are in terms of a small, well-deﬁned set of processes. There is the
chance that a device process could write to kernel data structures but this is an

5.11 Devices—Trusted Code
301
inevitable risk that the design implies. However, an assumption is that device
processes are trusted not to operate in malicious ways. It would be far better to
avoid this but, as noted above, it would require each device process to reside
in its own, totally separate, address space. This, in turn, would require an
address-space swap when entering the kernel, an operation that is somewhat
costly on most machines (inter alia, it involves saving the entire context of
the calling process). The introduction of virtual store appears to solve some of
the problems. Again, as noted above, swapping processes between main store
and some form of backing store is attractive but is costly and also opens up
the possibility of attack.
The current scheme also appears to keep the design as simple as possible.
It is our belief, based upon experience with similar and other software, that
the simpler the software the easier it is to maintain and the easier it is to
protect.
Some processors (e.g., Intel IA32) have instructions to support context
switches. On the IA32, a jump or call instruction can be used to switch be-
tween address spaces. It is attractive to employ instructions such as these
whenever possible on the grounds of potential speed improvement (although
the IA32 switching times are about the same for all methods). By placing
device processes in the same address space, the address-space switch is no
longer required; this might require an additional piece of code to switch de-
vice contexts.
There is another issue that must be discussed. By permitting device
processes to reside in the kernel’s address space, the possibility of concur-
rency within that address space is opened up. This is particularly the case
when prioritised interrupts are supported by the hardware. For simplicity, it
will be assumed that all devices have the same interrupt priority (this is not
uncommon and is assumed in many portable operating systems). Higher pri-
ority interrupts (hardware and software error conditions except segmentation
violations) can be handled in the normal way and are orthogonal. Under this
assumption, there is no contention between device processes and between de-
vice processes and ordinary ones. The scheduler’s organisation only permits
either a device or a user process to execute at any time.
It is ﬁrst necessary to deﬁne a collection of operations that deal directly
with the data structures relating to device processes. We will begin with a
state-setting operation.
SetDevProcStateToWaiting =
∃st : PSTATE | st = pswtgdev •
SetProcState[st/st?]
This sets the state of a device process to pswtgdev when it is waiting for a
request or for data from a device (the two states can be separately identiﬁer,
if so wished).
The following operation is a predicate that is true if the process identiﬁer
bound to p? is that of a device process.

302
5 A Separation Kernel
IsDeviceProcess
ΞPTAB
p? : PID
ptype(p?) = dproc
When a device process is created, its device-message slot is initialised to
the null message.
InitDeviceMsg
∆PTAB
d? : PID
devmsg′ = devmsg ∪{d? →(nullpid, nullmsg)}
After a device process has serviced a request, it clears its device-message
slot in PTAB by setting it to a null message.
ClearDevMsg
∆PTAB
d? : PID
devmsg′ = devmsg ⊕{d? →(nullpid, nullmsg)}
When a user process makes a request to a device process, it performs
an action akin to sending a message. This “device message’ is stored in the
devmsg slot corresponding to the device process.
SetDevMsg
∆PTAB
d? : PID
p? : PID
m? : MSG
devmsg′ = devmsg ⊕{d? →(p?, m?)}
The following is the operation performed by a device process when it reads
a request message.
GetDevMsg
ΞPTAB
d? : PID
m! : MSG
m! = snd devmsg(d?)
The next two schemata deﬁne operations on device-process requests. The
ﬁrst returns the identiﬁer of the requesting process (which can never be a
device process)

5.11 Devices—Trusted Code
303
DevRequesterId
ΞPTAB
d? : PID
p! : PID
p! = fst devmsg(d?)
The next schema deﬁnes a predicate that is true when the device message for
the device, d?, is not null.
GotDevMSg
ΞPTAB
d? : PID
devmsg(d?) ̸= (nullpid, nullmsg)
The following is just another name for the same operation.
NonNullDevRq = GotDevMsg
Device requests cannot be made by the null process, the idle process or
another device process:
ValidDevRqProcessId
ΞPTAB
rqid? : GPID
iprc? : PID
rqid? ̸= nullpid
rqid? ̸= iprc?
ptype(rqid?) ̸= dproc
ISRs use this operation to pass data to the associated device process.
PassDataToDeviceProcess =
SetDevMsg
o
9ReadyDeviceProcess
PassDataToDeviceProcess
∆PTAB
∆SKSCHED
∆PROCESSQUEUE
d? : PID
p? : PID

304
5 A Separation Kernel
m? : MSG
devmsg′ = devmsg ⊕{d? →(p?, m?)}
state′ = state ⊕{d? →psready}
devq′ = devq ⌢⟨d?⟩
The precondition is (notionally) required for the reﬁnement process, so we
calculated it.
pre PassDataToDeviceProcess = true
5.11.1 Device replies
When a device process has completed its operation, it sends a reply message
to the requesting user process. In the case of write-only devices, the reply will
consist of a return code denoting the success of the operation (it might also
contain some other date, say conﬁrmation of the number of bytes written).
These device replies are stored in PTAB and each process has a devrpy entry.
The following schema deﬁnes the operation to initialise the device reply
entry for a newly created process.
InitDevReply
∆PTAB
p? : PTAB
devrpy′ = devrpy ∪{p? →nullmsg}
When a process has received a reply from a device process, it should copy
the data to its own address space and then clear the reply entry. This schema
deﬁnes the operation:
ClearDevReply
∆PTAB
p? : PID
devrpy′ = devrpy ⊕{p? →nullmsg}
When a device process has completed its task, it reports the result to the
requesting user process by setting a “message” in the devrpy table within
PTAB. This is achieved by the operation deﬁned by the following schema:
SetDevReply
∆PTAB
p? : PID
m? : MSG
devrpy′ = devrpy ⊕{p? →m?}

5.11 Devices—Trusted Code
305
The user process obtains device replies by means of the operation deﬁned
by the following schema:
ReplyFromDeviceProc
ΞPTAB
p? : PID
m! : MSG
m! = devrpy(p?)
Should a process be unsure about the result of a device request, the fol-
lowing predicate is deﬁned.
GotReplyFromDeviceProc
ΞPTAB
p? : PID
devrpy(p?) ̸= nullmsg
If a process does not receive a device reply when it should, it can use the
following schema to notify the system of this eventuality.
NoDeviceReply =
(∃e : SYSERR | e = nodevreply •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
The operation employed by a device process to reply to a user process
request is deﬁned as:
DevReplyToUserProc =
(GotReplyFromDeviceProc ∧
(ReplyFromDeviceProc o
9 ClearDevReply) ∧
SysOk)
∨NoDeviceReply
The condition NoDeviceReply should never happen!
The expansion of DevReplyToUserProc is
DevReplyToUserProc
∆PTAB
∆ERRV
∆HW
p? : PID
m! : MSG
(devrpy(p?) ̸= nullmsg ∧
m! = devrpy(p?) ∧
devrpy′ = devrpy ⊕{p? →nullmsg} ∧

306
5 A Separation Kernel
serr ′ = sysok)
∨(serr ′ = nodevreply ∧intno′ = killintno)
pre DevReplyToUserProc =
p? ∈dom devrpy ∧devrpy(p?) ̸= nullmsg
5.11.2 Device numbers
The following is an error-reporting schema:
BadDeviceNumber =
(∃e : SYSERR | e = baddevnum •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
This schema is used when it is detected that a process is requesting a ser-
vice from a device whose number is unknown to the system. Devices are known
internally to the system by process identiﬁers (elements of PID); outside the
kernel, user processes know them only by device numbers (or service numbers).
When a device process is created, it is allocated a PID and a DEVNO (device
number). The following operation sets the device number in the devmap table
in PTAB when a device process is created.
InitDeviceNum
∆PTAB
dno? : DEVNO
d? : PID
devmap′ = devmap ∪{dno? →d?}
The precondition is simply
pre InitDeviceNum = true
Checking that a device number exists is done by the operation deﬁned by
the following schema:
IsKnownDeviceNumber
ΞPTAB
dno? : DEVNO
dno? ∈dom devmap
Device numbers are allocated by the person who conﬁgures the system, not
by the system proper. This way, the implementers of user processes as well as
the system can know the device numbers that are in use.

5.11 Devices—Trusted Code
307
Given a device number, dno?, what is the corresponding process identiﬁer?
The following schema deﬁnes this operation. The result is returned in d!. The
operation can only be applied when it is known that dno? is an element of
devmap’s domain (is a deﬁned device number, that is).
DeviceProcessId
ΞPTAB
dno? : DEVNO
d! : PID
d! = devmap(dno?)
Device suspension. Devices are responsible for suspending themselves.
SuspendDeviceProcess =
RequeueDeviceProcess[d?/p?]
This operation was deﬁned when specifying the scheduler.
5.11.3 Device process creation
Device processes must be created, usually at boot time. Unlike user processes,
it is expected that device processes will not terminate until the system as a
whole is shut down.
There is no need to create a user-level identiﬁer, so the following new
composition is adequate.
SetPDState
∆PTAB
p? : PID
st? : PSTATE
state′ = state ∪{p! →st?}
ptype′ = ptype ∪{p! →dproc}
The fact that device processes do not have external identiﬁers means that
the operation to enter their basic details into the process table is a little dif-
ferent from the one used for user processes. The operation for device processes
is:
AddDevPD =
((GotFreePIDs ∧AllocPID)
o
9SetPDState[p!/p?] ∧
SysOk)
∨PTABFull
This deﬁnition expands, after slight simpliﬁcation, into

308
5 A Separation Kernel
AddDevPD
∆PTAB
∆ERRV
∆HW
p! : PID
st? : PSTATE
(used ⊂PID ∧
p! ̸∈used ∧
used ′ = used ∪{p!} ∧
state′ = state ∪{p! →st?} ∧
ptype′ = ptype ∪{p! →dproc} ∧
serr ′ = sysok)
∨(serr ′ = ptabfull ∧intno′ = killintno)
The simpliﬁcation is to identify state with state′′ and ptype′ with ptype′′. This
is permitted because they are only updated in the second component of the
sequential composition.
pre AddDevPD = used ⊂PID
The primitive that creates a new device process is speciﬁed ass
NewDeviceProcess =
(IsKnownDeviceNumber ∧BadDeviceNumber)
∨(AddDevPD[d!/p!] o
9 InitDeviceNum[d!/d?] o
9 InitDeviceMsg[d!/d?]o
9
InitDeviceRq[d!/d?] o
9 InitDevReply[d!/p?]o
9
SetDevProcStateToWaiting)
After merging the existentials, this deﬁnition expands into the following
schema:
NewDeviceProcess
∆PTAB
∆ERRV
∆HW
d! : PID
dno? : DEVNO
∃devmsg′′ : PID →MSG; devrqs′′ : PID →MSG;
devrpy′ : PID →MSG •
(dno? ∈dom devmap ∧serr ′ = baddevnum ∧intno′ = killintno)
∨(used ⊂PID ∧
d! ̸∈used ∧used ′ = used ∪{d!} ∧
state′ = state ∪{d! →st?} ∧ptype′ = ptype ∪{d! →dproc} ∧
serr ′ = sysok)
∨(serr ′ = ptabfull ∧intno′ = killintno)

5.11 Devices—Trusted Code
309
o
9devmap′ = devmap′′ ∪{d! →dno?}
o
9devmsg′ = devmsg′′ ∪{d! →nullmsg}
o
9devrqs′ = devrqs′′ ∪{d! →nullmsg}
o
9devrpy′ = devrpy′′ ∪{d! →nullmsg}
Note that the double-primed variables are only aﬀected once and in their
respective composition elements. This permits the following simpliﬁcation.
NewDeviceProcess
∆PTAB
∆ERRV
∆HW
d! : PID
dno? : DEVNO
(dno? ∈dom devmap ∧serr ′ = baddevnum ∧intno′ = killintno)
∨((used ⊂PID ∧d! ̸∈used ∧used ′ = used ∪{d!} ∧
state′ = state ∪{d! →st?} ∧ptype′ = ptype ∪{d! →dproc} ∧
o
9devmap′ = devmap′′ ∪{d! →dno?}
devmsg′ = devmsg′′ ∪{d! →nullmsg} ∧
devrqs′ = devrqs′′ ∪{d! →nullmsg} ∧
devrpy′ = devrpy′′ ∪{d! →nullmsg} ∧
serr ′ = sysok)
∨(serr ′ = ptabfull ∧intno′ = killintno))
The precondition of NewDeviceProcess is given by:
pre NewDeviceProcess =
dno? ∈dom devmap ∨used ̸= PID
There is only one thing left. Some device processes will need to initialise
their hardware as soon as the system boots. This has to be included as an
option. Therefore, the following is added.
NewDeviceProcessPossInitHW =
NewDeviceProcess o
9 (runatboot? = yes ∧ReadyDeviceProcess[d!/dp?])
After a little obvious transformation and expansion, this schema expands into
NewDeviceProcessPossInitHW
∆PTAB
d! : PID
dno? : DEVNO
runatboot? : YESNO
(dno? ∈dom devmap ∧serr! = baddevnum)
∨((used ⊂PID ∧

310
5 A Separation Kernel
d! ̸∈used ∧used ′ = used ∪{d!} ∧
state′ = state ∪{d! →st?} ∧ptype′ = ptype ∪{d! →dproc} ∧
devmsg′ = devmsg′′ ∪{d? →nullmsg} ∧
devrqs′ = devrqs′′ ∪{d? →nullmsg} ∧
devrpy′ = devrpy′′ ∪{d? →nullmsg} ∧
(runatboot? = yes ∧
ReadyDeviceProcess[d!/dp?])
∧serr ′ = sysok)
∨(serr ′ = ptabfull ∧intno′ = killintno)
The precondition is:
pre NewDeviceProcessPossInitHW =
dno? ∈dom devmap
∨used ̸= PID
It is now necessary to account for three things:
1. Communicating parameters to the device process;
2. Readying a device process when its associated ISR has completed;
3. Returning values to the user process that initially made the request.
It must be pointed out that a synchronous I/O model is assumed in this
speciﬁcation. The reason for this is that it is simple to specify and to imple-
ment.
It is assumed that user processes communicate with device processes via
an interrupt. The ISR associated with this interrupt decodes the request and
passes appropriate parameters to the device process. Until the device process
has completed its operations and has returned at least a return code to the
caller, the caller is suspended in a waiting state (pswaitdev). When the device
process has completed, it must ready the requesting user process—this implies
that the device process stores the identiﬁer of the requesting process.
SetStateToDevWait =
∃st : PSTATE | st = psdevwait •
SetProcState[st/st?]
It must be emphasised that this operation is intended for use by user
processes only. Device processes have their own waiting state and setter op-
eration.
When a device request is made, the requesting process’ PID and device
number are checked. Should either fail, an error value is returned in serr.
The device data is passed to the device process, together with the requesting
process’ PID.
The parameters passed by the requesting process take the form of a mes-
sage. The message is passed to the device process using PassDataToDevice-
Process. The requesting process then waits until the device process posts a

5.11 Devices—Trusted Code
311
message to its devrpy slot using DevReplyToUserProc and then readies the
requesting process using MakeReadyUserProcess. The identiﬁer of the request-
ing process must be checked to see that it is valid (not the null or idle process
and not another device process).
The following operation is part of the handler code that activates device
processes. If device requests are handled by an interrupt, the following oper-
ation will be used by the associated ISR.
BadCallerIdent =
(∃e : SYSERR | e = badcallerid •
SetSysErr[e/e?]) ∧
RaiseKillInterrupt
When a request is made to a device process, it must be veriﬁed and the
device process activated. Veriﬁcation, here, consists of verifying that there is
a device process corresponding to the speciﬁed device number and that the
requesting process is genuine. If the tests have been passed, the request is
passed to the device process and the requesting user process’ state is set to
“waiting on device” (psdevwait). The operation is deﬁned as follows:
VerifyAndActivateDevProc =
(VerifyCallerIdent ∧PIDforUPID[caller/p!] ∧
IDLEPROCESSIdent[iprc/p!] ∧
(ValidDevRqProcessId[caller/rqid?, iprc/iprc?] ∧
(IsKnownDevideNumber ∧
(DeviceProcessId[dp/d!] ∧
((PassDataToDeviceProcess[dp/d?, caller/p?]
o
9SetStateToDevWait[caller/p?]) ∧
SysOk
o
9SKSchedNext)) \ {dp})
∨BadDeviceNumber)) \ {caller, iprc}
∨BadCallerIdent
For safety, this operation is expanded.
VerifyAndActivateDevProc
∆SCHED
∆PRIOQ
∆HW
∆ERRV
ΞPTAB
u? : UPID
dno? : DEVNO
m? : MSG
∃caller, iprc : PID •
(curr = extpid(u?) ∧caller = extpid(u?) ∧iprc = ipid ∧
((caller ̸= nullpid ∧caller ̸= iprc ∧ptype(caller) ̸= dproc ∧

312
5 A Separation Kernel
(∃dp : PID •
dno? ∈dom devmap ∧dp = devmap(dno?) ∧
(∃devq : seq PID •
(∃state′′ : PID →PSTATE •
devmsg′ = devmsg ⊕{dp →(caller, m?)} ∧
state′′ = state ⊕{dp →psready} ∧
devq′′ = devq ⌢⟨dp⟩∧
state = state′′ ⊕{caller →psdevwait}) ∧
serr ′ = sysok
∧SKSchedNext)))
∨(serr ′ = baddevnum ∧intno′ = killintno))
∨(serr ′ = badcallerident ∧intno′ = killintno))
The expansion of this operation shows that a request to a device causes the
device process to be readied on the scheduler’s ready device queue (devq) and
the requesting process is suspended. The operation also causes a reschedule.
This deﬁnition exempliﬁes our use of the reschedule operation instead of
the MakeUnready. It is known that when the above is exceuted, the current
process is the one that needs to be removed from the scheduling queue.
Note that device requests are a case where the currently executing process
is unreadied. The requesting user process remains in a waiting state until the
device process whose services it has requested has completed and placed a
reply message in the requesting process’ reply slot in PTAB.
The method by which the device process communicates with the hardware
device under its control is not further speciﬁed here. Some shared memory
will probably be employed for data buﬀering. Since this speciﬁcation is not
machine speciﬁc, it is impossible to decide here which methods should be used.
When the device process has obtained a reply from the hardware, it uses
the following operation to return the data to the requesting user process. It
then suspends itself ready for the next request.
DevReturnDataAndSuspend =
((DevRequesterId[rqid/p!] ∧
DevReplyToUserProc[rqid/p?] ∧
MakeReadyUserProcess[rqid/p?]) \ {rqid}
o
9SKSchedNext) o
9 SetDevProcStateToWaiting
This partially expands into:
DevReturnDataAndSuspend
∆PTAB
∆SKSCHED
∆ERRV
∆HW
d? : PID

5.12 Process Interface to the Kernel
313
m! : MSG
(∃rqid : PID | rqid = fst devmsg(d?) •
((devrpy(rqid) ̸= nullmsg ∧
m! = devrpy(rqid) ∧
devrpy′ = devrpy ⊕{rqid →nullmsg} ∧
serr ′ = sysok)
∨(serr ′ = nodevreply ∧intno′ = killintno) ∧
MakeReadyUserProcess[rqid/p?])
o
9SKSchedNext o
9 SetDevProcStateToWaiting
This operation can be used to return status information as well as requested
data. In the case of output devices, a completion code could be returned in
the message passed to the requesting user process.
SetDeviceProcessData =
(DevRequestId[rqid/p!] ∧SetDevReply[rqid/p?])
It is now necessary to specify how the reply from the device process is
handed to the requesting process. This is, basically, an architecture-speciﬁc
issue but a general solution is to return the data as a message on the requesting
process’ stack.
In this model, when a device process makes a request to its associated
hardware, it must suspend itself until the device has completed the requested
operation (generally, it is assumed that the operation returns a value). When
the ISR or device interface has completed, it must ready the device process
so that it can perform its next operation. If the device process deals with
hardware that does not require it to wait, it should immediately suspend ready
for the next user request. The suspension of a device process is achieved by
action of SKSchedNext o
9SwitchContext) because this operation unconditionally
schedules a new process and switches the context to it.
Because device processes are trusted, a suspension operation can be deﬁned
that does not engage in all the checking required for user processes. It is
SelfSuspendDeviceProcess = SKSchedNext
The ISR needs, however, to obtain the device process’ identiﬁer; this might
change between boots. However, the device number does not, so the ISR can
call DeviceProcessId to obtain the device number.
AwakenDeviceProcessFromISR =
(DeviceProcessId[d/d!] ∧ReadyDeviceProcess[d/dp?]) \ {d}
5.12 Process Interface to the Kernel
It is assumed that user processes, when performing a system call, place the
input parameters on their stack. They will also retrieve results from the kernel

314
5 A Separation Kernel
from their stack. This requires that user-process stacks be accessible from
within the kernel even though user-process stacks reside in segments other
than the one in which the kernel resides.
Finally, device processes are trusted code and are programmed by systems
programmers. It seems permissible, therefore, to provide direct access to all of
the operations deﬁned above. Moreover, there are no problems with crossing
segment boundaries when device processes are active. The only issue is how
a user process can activate a device process. This operation will be included
in this section.
The ﬁrst calls that are considered are those performing message-passing
functions. They are directly called from user processes and are relatively com-
plex to specify.
It should be noted that the above operations deal mostly with pointers to
messages, not to message structures proper. In particular, this leads to two
problems:
1. How to pass a message structure to the destination process. (This involves
crossing address space boundaries.)
2. Deletion of the message structure after the destination has read the mes-
sage.
In addition, there is the question of reclaiming all storage in the message pool.
As noted above, the FreeBlk algorithm does not collect and merge all possible
blocks but, if a block cannot be connected immediately to an existing free
block, the algorithm just adds the newly freed block to the end of the free
block chain. This leads to space leaks and is the reason for the deﬁnition of
the block scavenging operation. The block scavenging operation is relatively
expensive, so should not be called very frequently.
Of the process control operations, those that suspend and terminate their
caller are intended to be called directly by a user-level process. The process
creation operation is intended to be called from a library routine; the library
routine will be called by the initial or some other process.
As an intermediate solution to the above problems, the following opera-
tion is deﬁned. This operation is intended to be called from the ISR that is
activated when a user process performs a system call; system calls consist of
a number of operations on the user stack (essentially a conventional proce-
dure call) followed by the raising of a dedicated interrupt. The top of the user
stack is the opcode, rqop? (requested operation—an element of SYSOPCODE)
which determines the operation to be performed by the system. Immediately
underneath the opocde are the parameters to the system call. The decode rou-
tine performs the operation and returns values on the user’s stack. All that is
missing from the DecodeSysCall speciﬁcation is the mechanism for accessing
the user-process stack.

5.12 Process Interface to the Kernel
315
DecodeSysCall
rqop? : SYSOPCODE
(rqop? = newuproc ∧USKNewProcess)
∨(rqop? = suspself ∧USKSuspendSelf )
∨(rqop? = termself ∧USKTerminateSelf )
∨(rqop? = sndmsg ∧USKSendMsg)
∨(rqop? = gotmsgs ∧USKGotMsgs)
∨(rqop? = gotmsgfromsrc ∧SKProcessHasMsgsFromSrc)
∨(rqop? = nextmsg ∧USKNextMsg)
∨(rqop? = nextmsgfromsrc ∧SKNextMsgFrom)
∨(rqop? = devrequest ∧VerifyAndActivateDevProc)
We have ignored the issue of obtaining parameters from the user process.
The actual answer, of course, depends upon the processor being used. On
the IA32, the parameters are on the user’s stack. On interrupt, the user’s
stack is pointed to by the current hardware TSS register; the stack pointer is
stored in the TSS; when an interrupt occurs, the stack regiser can be retrieved
from the TSS. This is not the entire story because the IA32 is a segmented
architecture, so a segment register has to be set up to point to the stack
segment (combined stack and data segment in the present case) so that the
user’s stack can be addressed. When an interrupt occurs, the IA32 pushes two
double words (two 32-bit quantities, i.e.) on the current stack—one is the ﬂags
(F) register, the other is the PC. Underneath these comes the parameter area
that can be accessed to obtain parameter values. Once extracted, the stack can
be adjusted ready to return results. Other architectures will arrange matters
in a diﬀerent way, it must be stressed.
When this operation has completed, the ISR returns. The reason for this is
that any context switches are performed by component operations as their last
operation (context switches also perform a Return From Interrupt operation
as standard). For this reason, the DecodeSysCall operation does not assign a
value to the standard error-return variable, serr.
As far as the user stack is concerned, the following must be emphasised:
•
Input values are taken from the user-process stack. This resides in the user
process stack segment, not in the kernel’s address space.
•
Output values are placed on the user-process stack, not the kernel stack.
When taking inputs and returning outputs, access to the user stack is required.
This is a low-level operation programmed in assembly code. The complexity
of this operation is dependent upon the architecture of the processor upon
which the separation kernel runs.
The problem is not in principle diﬃcult. Within the structure representing
each process’ state (in its process table), there is a slot each for its segments.
The stack pointer is also stored there. Depending upon the architecture and
compiler, there might also be a pointer to the user process’ zcurrent stack

316
5 A Separation Kernel
frame. This last pointer allows the kernel direct access to the top of the user’s
stack, albeit at the cost of a number of accesses to the process table and other
structures.
5.13 Final Thoughts
The NSA documents [10] frequently refer to threads inside each Separation
Kernel process. The speciﬁcation that is reﬁned in this chapter makes no
mention of threads. The explicit inclusion of threads would increase the length
of the chapter somewhat.
There is, however, no real need to include threads in this chapter because
they can be included by simple modiﬁcations to the speciﬁcation, in particular
the mechanisms of the simple kernel speciﬁed and reﬁned in Chapter 3 can
be included in the Separation Kernel. The inclusion requires, among others,
a few changes to the Separation Kernel’s process table (PTAB). To see that
this works, it is necessary to consider that the simple kernel operates in a
single address space. The processes that the simple kernel supports do not
require address-space manipulation when context switches occur; indeed, they
resemble threads quite closely.
This is the other reason for combining the simple kernel and the Separation
Kernel in this book.

6
Closing Thoughts
In this last chapter, we will try to collect some threads and review the content
of this book.
First, the book contains the speciﬁcation and reﬁnement of two micro
kernels. The ﬁrst is suitable for use in embedded systems and the other is
speciﬁcally a kernel for cryptographic systems. Each speciﬁcation is relatively
complete and the reﬁnements reach the level at which executable code in a
language such as C or Ada can be read oﬀfrom the Z schemata.
The reﬁnements are based on the standard Z technique as it is described
in the literature (e.g., [12, 13]). The reﬁned state schema was deﬁned and then
the abstraction relation was deﬁned. Thereafter, the operation schemata were
deﬁned. The initialisation theorem was used as a test of the adequacy of the
abstraction relation.
It was found that the abstraction relations were
•
Functions;
•
Identities.
These properties, in principle, permitted the calculation of all operations in
the reﬁnement and obviated all the associated proofs. We included all proofs
in the ﬁrst reﬁnement so that the reader could see that they were possible
(actually, quite simple). In the second reﬁnement (that of the Separation Ker-
nel), we included all the bottom-level proofs but had to omit those for the
more complex operations (this had also to be done in a few cases in the ﬁrst
reﬁnement); this was done to reduce the length of an already over-long book
and so as not further to bore the reader with straightforward proofs.
The fact that we included proofs in both reﬁnements is an indication of our
position on formal methods. We consider that, even though they are strictly
unnecessary, the inclusion of explicit and complete proofs is an essential part
of the reﬁnement to code. Proofs require us to examine our deﬁnitions and to
reason about them. By engaging in proof, we have a guarantee that our deﬁn-
itions (state schemata) and relationships between them (operation schemata)
are correct according to the axioms of the various theories we use. Without

318
6 Closing Thoughts
proof, we might as well not bother for there is no guarantee of anything—it
is like sleepwalking through a formal notation, much as we sleepwalk from an
informal speciﬁcation to a piece of (one hopes) working code. The production
of proofs forces us to think carefully and in detail about things; this is, we
believe, essential.
That the abstraction relations are all identities is not a surprise to us. As
we have already noted, the vast majority of the abstraction relations we have
found over a very long period have been identities.
The speciﬁcation of hardware poses a slight problem for us. This was
because we did not want, in the case of this book, to specify any particular
piece of hardware for the kernel of Chapters 2 and 3; the Separation Kernel is
aimed at the Intel IA32 and 64 processors, so we could be a little more deﬁ-
nite. In the case of the Separation Kernel, we speciﬁed the IA32/64 hardware
operations at a level of detail that we felt adequate for the production of the
tiny amounts of assembly code required to complete the kernel. In the case
of the kernel of Chapters 2 and 3, the register-save operation was speciﬁed
as operations on the process’ stack; the operations correspond exactly to two
IA32 instructions. In both cases, context switches are caused by a software
interrupt (which is speciﬁed).
Turning to the reﬁnement process itself, there are some points that can be
made.
First, there is the fact that a speciﬁcation is a conjunction of wﬀs. This
implies that they lack structure. The lack of structure can be exploited by the
distributive rules for ∧and ∨. However, it poses problems if one expects that
what one considers to be a routine should be represented in a modular fashion;
after all, standard software engineering requires us to consider routines as
abstractions that are referred to by name.
This lack of structure is clear when a complex deﬁnition (i.e., a deﬁnition
involving more than one operation schema) is expanded for simpliﬁcation or
for the calculation of a precondition. It would be highly desirable if each
operation schema could be represented by a precondition (and, possibly, by
a postcondition). This is not always possible because preconditions are rep-
resented by existentially quantiﬁed wﬀs in Z. In some cases, it is possible to
separate operation schemata from the surrounding conjuncts in some cases
(and we have encountered them in this book) but they must ﬁrst be inves-
tigated in order to determine that such treatment is valid. The organisation
of a speciﬁcation as a conjunct is rarely mentioned in the literature. It has
a further implication: as a speciﬁcation grows in size, so do the conjunctions
that result from the composition of operations.
As can be seen from the calculations in this book, it is sometimes possible
to exploit substitutions as a way to handle complexity in expanded operations.
The deﬁnition of complex operations has implications other than visibility.
It is to these that we now turn.
We have used simpliﬁcation extensively above. In some cases, it was the
simpliﬁcation of simple operations; in others, it was the simpliﬁcation of

6 Closing Thoughts
319
complex operations; in still others, it was the simpliﬁcation of preconditions.
We need to ask what the purpose of simpliﬁcation is. In the case of the simpli-
ﬁcation of simple operations (those composed of a single schema), we have a
form of optimisation. The simpliﬁed operation can be used directly in reﬁne-
ment or the production of code. In the case of preconditions, we are interested
in the logical form of the operation; this is what simpliﬁcation gives us, for a
simpliﬁed precondition is at least implied by the unsimpliﬁed version (at best,
it is materially equivalent). It is the case of complex operations, operations
composed of more than one operation schema, that is interesting. Clearly,
it is possible to view the simpliﬁcation as an optimisation. In this case, the
simpliﬁed version can be employed in reﬁnement or the production of code.
However, the simpliﬁcation of a complex operation violates the modularity
of its components (this, again, is the problem that speciﬁcations are large
conjunctions).
If a simple (or less complex) operation is included in more than one com-
plex one, and the more complex operations are simpliﬁed, it is more than
possible that the boundaries of the included operations will not be respected
in the formula that results from simpliﬁcation. This might not appear prob-
lematic but an example shows that it poses problems.
Consider the case of a storage-allocation operation. In a complex sys-
tem (such as an operating system or a virtual machine for a programming
language), the allocation operation might be included in a number of com-
plex operations. The storage-allocation operation will, almost certainly, be
a complex operation deﬁned in terms of a number of suboperations. When
the storage-allocation operations is included in more complex operations, it
becomes a candidate for simpliﬁcation. When simpliﬁed, the storage-allocation
operation’s abstraction boundary will probably not be respected. While we
are dealing with a mathematical abstraction, this is not a problem (it might
be when manipulating the resulting wﬀs but that is another matter). It can
become a problem when the production of code is concerned. If the simpliﬁed
operations are considered the basis for reﬁnement or code production, it is
clear that we have the following to consider:
•
Parts of the code that would comprise the storage-allocation operation
appear in various other, more complex operations. It is possible (indeed,
probable) that the entire operation never appears intact.
•
It is possible (probable) that there will be replication of code because
the simpliﬁcations will not necessarily remove the same conjuncts of the
original operation.
It can be argued that the ﬁrst of these two cases is not much of a problem
and that it is, on the contrary, a beneﬁt. The process of producing the ﬁnal
simpliﬁed operation is clearly documented and the result proved to be correct.
The second case is more of a problem. In traditional software engineering, we
are taught to deﬁne abstractions and to avoid destroying them; simpliﬁcation
is a clear case in which abstraction boundaries are broken. Furthermore, we

320
6 Closing Thoughts
are used, using traditional methods, not to expand code without good reason
(object-oriented progamming is another case in which this principle is violated,
often for what appears not to be a very good reason and could be solved if
compilation and linking were more selective).
We do not agree with the position that storage chips are becoming cheaper
all the time, so we can be proﬂigate with code and data structures. This
position is, in our opinion, an attempt to justify sloppy thinking. We need
more thought in Computer Science and Software Engineering, not less!
Next, we have to comment on the use of deferred assumptions and implicit
preconditions. In some parts of the speciﬁcation, particularly those parts speci-
fying some simpler operations over the process table, we could have guarded
each operation with a test that the process identiﬁer bound to the input
variable was an element of used. This was something we did not do. Instead,
we assumed that this was true and continued with the reﬁnement. At the
ﬁnal stage, it was clear that the current process was always bound to the
input variable p? and, by other reasoning, it can be shown that p? ∈used.
The alternative would have been to include a check that became increasingly
costly as the reﬁnement progressed (this is something we observed in Chapter
4). We consider that waiting to discharge assumptions is a reasonable option,
at least on logical grounds, even though it is, in human terms, a bit risky (one
has to remember to discharge the assumption). It is part of our reﬁnement
plan to make the assumption that p? ∈used early on and then to discharge
the assumption later on. In a case such as this, the process is harmless for the
reason that we had to discharge the assumption later on (and the assumption
was, in any case, quite harmless). There will be cases where the logical position
should not be adopted for pragmatic reasons.
We also used an implicit precondition (a precondition that derives from
the invariant) in order to show that the ready queue was valid. This is logically
valid and appears to us to be a technique that should be adopted. The use
of implicit preconditions makes the invariant more central. The reﬁnement
method, as presented in the literature, centres on the abstraction relation.
However, it is essential that the invariant of the speciﬁcation and that of the
reﬁnement be related by the abstraction relation for the reason that it is the
invariant that determines the integrity (correctness) of an operation’s eﬀects
in the sense that it deﬁnes the set of legal states (the invariant plays a much
greater part in reﬁnement in the B Method [1]). The use of the invariant does
not appear to be as prominent as it might be (a proof that the invariants are
so related should appear as part of the reﬁnement process). Strictly speak-
ing, when deﬁning each operation schema, there should be a proof that the
operation’s predicate preserves the invariant; this is important for possibly
interacting operations (e.g., operations deﬁned by the composition of simpler
ones).
Of course, it can be argued that the invariant is always implicitly present in
all proofs because they universally. Our points are that this is not prominent

6 Closing Thoughts
321
enough and that the reﬁnement relations should, ideally, be established between
invariants in speciﬁcation and reﬁnement. quantify over state schemata.
In the construction of some proofs, we referred to invariants or to results at
a higher level in the reﬁnement process. This is, we believe, to be quite valid; it
is justiﬁed by the following reasoning. The abstraction realtion should be a pair
of homomorphisms: one transforming the speciﬁcation into the reﬁnement,
the other performing the opposite transformation (they should be mutually
inverse). The composition of homomorphisms is also be a homomorphism. If
we have a speciﬁcation, S, and two reﬁnements of this speciﬁction, R1 and
R2, such that R1 is a reﬁnement of S and R2 is a reﬁnement of R1, and
if h1 : S →R1 and h2 : R1 →R2, there exists a h1,2 : S →R2. In the
particular case of the reﬁnements in this book, h1 and h2 are both identities,
so h1,2 = h2 ◦h1 (with h2 ◦h1 = h2(h1(S))) deﬁnitely exists and is well deﬁned.
In our second reﬁnement, we reused components from the ﬁrst and relied
upon existing proofs as our guarantees of correctness. Reuse of this kind is
natural in formal speciﬁcation and is, we believe, superior to the reuse of
executable code. One reason for this claim is that the reuse of speciﬁcations
makes the assumptions about components explicit.
Is formal reﬁnement worth the eﬀort? If one is used to informal methods
(or no methods), particuarly when one does not engage in extensive docu-
mentation, formal methods will cost more in time and eﬀort. A resistence
to documentation is something that we have often encountered in so-called
“real-world” contexts—it is often “justiﬁed” on cost grounds (but consider
the costs of having to justify undocumented software as part of a court case).
We believe that the amount of work required to produce a formal speciﬁcation
and its reﬁnement is about the same as producing informal documents. Fur-
thermore, formal methods yield connections between decisions made at one
level with those as a lower level. In addition, there is the matter of testing.
In our case, we have engaged in testing. This is just so we can check that
the resulting code is a correct transcription (i.e., contains no transcription
errors); it also serves to increase our conﬁdence that the result is correct. In
the case of the ﬁrst kernel, we engaged in quite exhaustive testing just to
assure ourselves that the code is correct. However, this testing is not only a
way to increase conﬁdence; it provides additional evidence that the code is
correct. Fairly extensive testing appears useful in cases such as kernels where
we want to be as sure as we can be that the code behaves correctly; in other
cases, we might want to be assured that the code contains no transcription
errors. It would, in any case, be far better to have a mechanical method for
checking the result, for the process is fairly mechanical. We found, of course,
that the code performs exactly as it should in all cases. (We have also to admit
that we tested somewhat more thoroughly than usual when dealing with for-
mally derived code so that we could state that it behaved correctly. We have
previous experience of the correct functioning of code derived from formally
reﬁned speciﬁcations.)

322
6 Closing Thoughts
To conclude this chapter and this book, one last issue must be raised:
automation. We did all of the work in this book by hand (or by mouth because
much of the text was dictated). It is clear that a good deal of automation
should be possible. The construction of schema compositions can be mecha-
nised with ease and would be most welcome as a way of helping with document
management. The complete automation of simpliﬁcation and proof does not
appear within reach at the moment but it is clear that there are ways in
which it can be supported. By this, we do not mean using current-generation
proof assistants which can be rather hard to use and have a long learning
curve, requiring the user to learn new names for methods and new notations.
Of course, some of us ﬁnd the production of proofs to be one of the more
interesting and enjoyable aspects of formal speciﬁcation—complete automa-
tion would deprive us of that pleasure. The checking that code conforms to
the bottom level of reﬁnement is also a case in which automation could assist,
for example in generating veriﬁcation conditions that can be related to the
ﬁnal stage of reﬁnement. A moderate amount of carefully designed automation
would help considerably.
We hope that this book has served to indicate that there are interesting
issues raised by reﬁnement in the large and that these issues have not been
discussed much in the published literature. We hope that we have also demon-
strated that the formal speciﬁcation of operating system kernels is viable; in
addition to the reﬁnements in this book, our experience with our collection of
components has been extremely positive.

References
1. Abrial, J.-R., The B Book: Assigning Programs to Meanings, CUP, 1996.
2. Bivot, Daniel C. and Cesati, Marco, Understanding the LINUX Kernel, O’Reilly
& Associates, Sebastapol, CA, 2001.
3. Craig, I. D., Formal Speciﬁcation of Advanced AI Architectures, Ellis Horwood,
Chichester, England, 1991?
4. Craig, I. D., Formal Models of Operating System Kernels, Springer-Verlag,
London, England, 2006.
5. Derrick, J. and Boiten, E., Reﬁnement in Z and Object-Z, Springer-Verlag,
London, 2001.
6. Dijkstra, E. J., A Discipline of Programming, Prentice-Hall, Englewood Cliﬀs,
NJ, 1976.
7. Jones, C. B., Systematic Software Development Using VDM, Prentice-Hall,
Englewood Cliﬀs, NJ, 1986.
8. Labrosse, Jean J., MicroC/OS-II, The Real-Time Kernel, Miller Freeman, Inc.,
Lawrence, KS, 1999.
9. Morgan, C. C., Programming from Speciﬁcations, 2nd edn., Prentice-Hall, Hemel
Hempstead, England, 1994.
10. National Security Agency, Separation Kernel Documents, e.g., SSE-100-1; many
others on line at www:nsa.gov.
11. Rushby, John, Design and Veriﬁcation of Secure Systems, ACM Operating Sys-
tems Review, Vol. 15, No. 5, pp. 12–21, 1981.
12. Spivey, J. M., The Z Notation: A Reference Manual, 2nd edn., Prentice-Hall,
Hemel Hempstead, 1992.
13. Woodcock, J. and Davies, J., Using Z: Speciﬁcation, Reﬁnement and Proof,
Prentice-Hall, Hemel Hempstead, 1996.

List of Deﬁnitions
Type:
ADDR 213
ADDR 21
BITMAP 135
BM 134
BMASK 133
BYTE 271
CHAR 218
DEVNO 212
GPID 19
GPID 211
INTNO 217
INTRPTNO 23
MD 252
MDATA 142
MPTR 271
MSG 142
MSG 213
MSG 21
MSGDATA 213
MWORD 133
ONOFF 23
PID 19
PID 211
PPRIO 20
PSTATE 20
PSTATE 212
PSU 264
PTYPE 212
SDESC 288
SID 127
SID 130
SID 137
STRING 218
SYSERR 214
SYSERR 21
SYSOPCODE 213
TIME 161
TIME 21
TSS 215
UPID 212
WORD 21
YESNO 211
Constant:
bpw 133
ctxtswintno 217
killintno 217
maxaddr 21, 213
maxdev 212
maxint 217
maxintno 23
maxprio 20
maxsid 130
mindev 212
minint 217
minintno 23
minprio 20
minsid 130
msize 133
nulladdr 21, 213

326
List of Deﬁnitions
nullmd 257
nullmsg 21, 213
nullmsgdata 213
nullpid 20, 212
ticklength 158
tickspersec 159
Function:
PSUsToMsg 271
& 134
| 134
↑134
∼134
mdaddr 252
mdsz 252
mergemds 255
mkmd 252
mkmsg 270
mksdesc 288
msgToPSU 271
msgaddr 270
msgat 271
msgdata 142, 270
msgdest 21, 142, 270
msgpayloadlen 270
msgsize 21
msgsrc 21, 142, 270
msgsz 271
msgtobytes 271
msz 271
segaddr 288
segsize 288
tss stackseg 215
tss stacktop 215
Precondition:
AddDevPD 308
AddMsg 275
AddMsg1 280
AddPD 31, 224
AddPD1 231
AddPD1 36
AddPD2 50
AddSleeper 165
AllocBlk 255
AllocSema 129
AllocSema1 132
AllocateSemaphore 199
BlockScavenge1 259
ContextSwitch 25
DeallocateSemaphore 199
DelPD 32
DelPRIOQElem 76
DelSCHEDQElem 109
DequeuePQ2 67
DequeuePROCESSQUEUE 59
EnqueuePQ1 61
EnqueuePQ2 66
EnqueuePROCESSQUEUE 57
FindAndWake 167
FindAndWake1 175
FindAndWake2 184
FreeBlk 255
FreePID1 39
FreePID2 53
HeadOfPROCESSQUEUE 58
NewDeviceProcess 309
NewDeviceProcessPossInitHW 310
NewProcess 192
NextMessageFromSource 277
NextMessageFromSrc1 282
NextMsg 276
NextMsg1 281
PRIOQDelHd1 85
PRIOQDequeue 77
PRIOQDequeue1 86
PRIOQEnqueue 74
PRIOQEnqueue1 83
PRIOQEnqueue2 96
RcvSMsg 201
ReceiveSynchMsg 155
ReleaseSema 129
RequeueDeviceProcess 251
RequeueUserProcess 250
SKSchedNext 249
SchedNext 112
SemaphoreSignal 199
SemaphoreWait 199
SendASynchMsg 150
SendMeToSleep 169

List of Deﬁnitions
327
SendMeToSleep1 176
SendMeToSleep2 185
SendSMsg 201
SendSelfToSleep 194
SetProcState 227
SetProcState1 236
SignalSema 125
SuspendMe 114
SuspendSelf 193
TerminateSelf 196
Schema:
AbsMSGQ1 282
AbsPQ1 59
AbsPQ2 68
AbsPRIOQ1 87
AbsPRIOQ2 97
AbsPTAB1 40, 236
AbsPTAB2 45, 238
AbsSLEEPERS1 176
AbsSLEEPERS2 185
AbsST1 132
AbsSTOREPOOL1 260
AddDevPD 307
AddFreechainLast 37, 48, 232
AddIdleProcess 225
AddMsg 274
AddMsg1 279
AddNewLastFreechain 37, 48, 232
AddPD 30, 223
AddPD1 36, 231
AddPD2 48
AddPDESC 30, 224
AddPDESC1 35, 231
AddPDESC2 47
AddProcUPID 222
AddProcUPID1 230
AddSleeper 165
AddSleeper1 171
AddSleeper2 181
AddSleeperProc 164
AddSleeperProc1 171
AddSleeperProc2 180
AddWaiter 120
AllocBlk 254
AllocBlk1 258
AllocMsg 269
AllocPID 30, 222
AllocPID1 35, 229
AllocPID2 47
AllocSID 128
AllocSID1 138
AllocST1 130
AllocST1a 137
AllocSema 128
AllocSema1 131, 138
AllocUPID 222
AllocUPID1 230
AllocateProcTSS 216
AllocateSegment 287
AllocateSegments 291
AllocateSemaphore 198
AlreadyAsleep 163
AlreadyHasMsg 142
AwakenDeviceProcessFromISR 313
BadCallerIdent 311
BadDestination 143
BadDeviceNumber 306
BlockLocError 264
BlockScavenge 255
BlockScavenge1 259
CLOCKISR 201
CLOCKTIME 159
CLOCKTIMEInit 160
CTXTSW 26, 217
CTXTSWISR 27
CanAddSleeper 164
CanAddSleeper1 171
CanAddSleeper2 180
CanAllocateBlock 254
CanAllocateBlock1 258
CanAllocateMsg 269
CanAllocateSegment 287
CanEnqueueMsg 272
CanEnqueueMsg1 277
CanEnqueuePRIOQ1 79
CanEnqueuePRIOQ2 93
CanSendSynchMsg 144
CanStoreBlock 265
CanStoreMsg 267

328
List of Deﬁnitions
ChangeMyPriority 197
ChangeMyPriority1 197
ChangeMyPriority2 197
ClearDevMsg 302
ClearDevReply 304
ClearFreeCnt 256
ClearFreeCnt1 260
ClearMsgFreeCnt 268
ClearWaitingTime 162
ClocktimeNow 160
ClrSynchMsgSlot 145
ClrSynchMsgSlot1 156
ComputeWakeTime 161
ContextSwitch 25, 216
ContinueCurrent 109
CopyBlock 265
CreateAndRunInitialProcess 292
CreateIdleProcess 290
CreateInitialProcess 190
CreateNullProcess 189
CurrentProcessId 104
CurrentProcessStateIsReady−
OrRunning 110
DEVPROCQUEUE 242
DEVPROCQUEUEInit 242
DeallocateSemaphore 199
DeallocateTSS 216
DecSEMACNT 121
DecodeSysCall 314
DelExtPD 226
DelExtPD1 234
DelHeadOfPQ1 62
DelHeadOfPQ2 67
DelHeadOf −
PROCESSQUEUE 58, 241
DelMSGQHd 273
DelMSGQHd1 278
DelPD 31
DelPD1 40
DelPRIOQElem 75
DelProcUPID 226
DelProcUPID1 234
DelSCHEDQElem 108
DelSleeperProc1 172
DelSleeperProc2 181
DeleteAllProcesses 226
DeleteAllProcesses1 235
DeleteStoredMsg 267
DequeueDEVICEQUEUE 246
DequeueDEVPROCQUEUE 242
DequeuePQ1 62
DequeuePQ2 67
DequeuePROCESSQUEUE 58, 241
DequeueUSER−
PROCESSQUEUE 246
DestinationExists 143
DestinationExists1 156
DestinationNotReceiving 143
DevReplyToUserProc 305
DevRequesterId 302
DevReturnDataAndSuspend 312
DeviceProcessId 307
DisableInts 24
ERRV 214
ERRVInit 214
EmptyFreeChain1 37, 232
EmptyFreeChain2 52
EmptyMessageQueue 269
EnableInts 24
EnoughSpace1 258
EnqueueDEVICEPROCESS 246
EnqueueDEVPROCQUEUE 242
EnqueueMsg 273
EnqueueMsg1 278
EnqueuePQ1 60
EnqueuePQ2 66
EnqueuePROCESSQUEUE 57, 240
Enqueue−
USERPROCESSQUEUE 246
EnterCritical 193
FindAndWake 166
FindAndWake1 174
FindAndWake2 183
FreeBlk 255
FreeBlk1 258
FreeMsg 269
FreePID 30, 225
FreePID1 38, 233
FreePID2 52
FreeSID1 131, 138

List of Deﬁnitions
329
FreeSIDa 136
FreeSIDs 128
FreeSegment 287
FreeSema 127
GetDevMsg 302
GotDevMSg 303
GotFreePIDs 222
GotFreePIDs 29
GotFreePIDs1 35, 229
GotFreePIDs2 47
GotMsgs 273
GotMsgs1 277
GotMsgsFromSrc 273
GotMsgsFromSrc1 278
GotReplyFromDeviceProc 305
GotSleepers 164
GotSleepers1 172
GotSleepers2 182
GotSynchMsg 144
GotSynchMsg1 156
HARDWARE 23
HW 215
HalfContextSwitch 25
HeadOfPQ1 62
HeadOfPQ2 67
HeadOfPROCESSQUEUE 57, 240
IDLEPROCESSIdent 103, 244
IncFreeCnt 256
IncFreeCnt1 260
IncMsgFreeCnt 268
IncSEMACNT 121
InitDevReply 304
InitDeviceMsg 302
InitDeviceNum 306
InitSema 128
InitSema1 131
InitSema1 138
InsuﬃcientMainStore 287
IsAsleep 164
IsAsleep1 170
IsAsleep2 180
IsCurrentProcess 104
IsCurrentProcessIdle 105
IsDestinationReceiving 145
IsDestinationReceiving1 156
IsDeviceProcess 301
IsEmptyDEVICEQUEUE 246
IsEmptyDEVPROCQUEUE 242
IsEmptyPRIOQ 71
IsEmptyPRIOQ1 78
IsEmptyPRIOQ2 92
IsEmptyPROCESSQUEUE 240
IsEmptySCHEDQ 107
IsEmpty−
USERPROCESSQUEUE 246
IsKnownDeviceNumber 306
IsNonEmptyPQ1 60
IsNonEmptyPQ2 66
IsNotEmptyPROCESSQUEUE 56
IsPrevProcessIdle 105
IsPreviousProcess 105
IsProcessSleeping 162
IsSysOk 23
KillKernel 218
MSGPOOL 269
MSGPOOLInit 269
MSGQ 272
MSGQ1 277
MSGQInit 272
MSGQInit1 277
MSGSTORE 267
MSGSTOREInit 267
MSGToUserData 295
MakeCurrentPrevious 104
MakeIdleProcessCurrent 102
MakeMessage 142
MakeReady 106, 246
MakeReady1 116
MakeReadya 105
MakeReceiver 145
MakeReceiver1 156
MakeSender 146
MakeSender1 156
MessageQueueFull 269
MovePRIOQUp1 79
MsgScavenge 269
MyProcessId 198
NegativeSemaCount 121
NewDeviceProcess 308
NewDeviceProcessPossInitHW 309

330
List of Deﬁnitions
NewProcess 191
NewUPIDForProcess 222
NewUPIDForProcess1 230
NextMessageFromSource 276
NextMessageFromSrc1 281
NextMsg 275
NextMsg1 281
NextMsgForProcess 298
NextMsgForProcessFromSrc 298
NextMsgFromSrc 273
NextMsgFromSrc1 278
NoDeviceReply 305
NoFreeSemas 126
NoMessagesFrom 269
NoSpace 252
NonNullDevRq 303
NonpositiveSemaCount 121
NotAllocSema 126
NullMsgValue 143
PDInUse 28, 219
PIDforUPID 225
PQ1 59
PQ1Init 60
PQ2 65
PQ2Init 65
PRIOQ 70
PRIOQ1 78
PRIOQ2 92
PRIOQAddSingleton 72
PRIOQAddSingleton1 80
PRIOQAddSingleton2 93
PRIOQDelHd 76
PRIOQDelHd1 85
PRIOQDelHd2 96
PRIOQDequeue 76
PRIOQDequeue1 86
PRIOQDequeue2 96
PRIOQEmpty 70
PRIOQEnqueue 73
PRIOQEnqueue1 82
PRIOQEnqueue2 94
PRIOQEnqueueHd 71
PRIOQEnqueueHd1 79
PRIOQEnqueueHd2 93
PRIOQEnqueueLast 72
PRIOQEnqueueLast1 79
PRIOQFull 70
PRIOQHd 71
PRIOQHd1 79
PRIOQHd2 92
PRIOQInit 71
PRIOQInit1 78
PRIOQInit2 92
PRIOQInsert 72
PRIOQInsert1 81
PRIOQInsert2 93
PRIOQInsertMidPoss1 81
PRIOQLast 71
PRIOQLast1 79
PRIOQLast2 93
PRIOQMoveUpFrom 80
PRIOQRemove 75
PRIOQRemove1 85
PRIOQSetIthSucc 80
PROCESSQUEUE 56, 239
PROCESSQUEUEInit 56, 240
PTAB 25, 143, 161, 216, 220, 271, 288
PTAB1 34, 228
PTAB1Init 34, 229
PTAB2 44, 237
PTAB2Init 45, 238
PTABFull 28, 220
PTABInit 29, 221
PassDataToDeviceProcess 303
PreviouslyRunningProcess 245
PrintKMsg 218
ProcPrio 32
ProcState 33, 227
ProcState1 235
ProcType 227
ProcType1 235
ProcessHasMsgs 297
ProcessHasMsgsFromSrc 298
ProcessQueueEmpty 56, 239
QueueHdHasHigherPriority 110
QueueHdHasHigherPriority1 116
QueueHdHasHigherPriority2 119
RaiseInterrupt 26, 217
RaiseKillInterrupt 217
RcvSMsg 201

List of Deﬁnitions
331
RcvSynchMsg 150
ReadyDeviceProcess 247
ReceiveSMsg 145
ReceiveSynchMsg 151
ReceiveSynchMsg1 157
ReceiveSynchMsg2 158
ReleaseSema 129, 132
ReleaseSema1 138
RemoveSleeper 166
RemoveSleeper1 173
RemoveSleeper2 182
RemoveWaiter 120
ReplyFromDeviceProc 305
RequeueDeviceProcess 250
RequeueUserProcess 249
ReturnFromInterrupt 24
ReturnSysError 23
RunFirstProcess 293
RunIdleProcess 247
RunningProcess 244
SCHED 101
SCHEDInit 102
SCHEDInit 103
SCHEDQDelHd 108
SCHEDQDequeue 108
SCHEDQHd 108
SEGMENTS 287
SEGMENTSInit 287
SEMAPHORE 120
SEMAPHOREInit 121
SEMATBL 127
SEMATBLInit 127
SKInitSys 290
SKMakeUnready 248
SKNewProcess 291
SKNextMsg 298
SKNextMsgFrom 298
SKProcessHasMsgsFromSrc 298
SKSCHED 243
SKSCHEDInit 244
SKSchedNext 248
SKSuspendSelf 293
SKTerminateSelf 293
SLEEPERS 163
SLEEPERS1 170
SLEEPERS2 180
SLEEPERSInit 164
SLEEPERSInit1 170
SLEEPERSInit2 180
ST1 130
ST1Init 130
ST1Init 138
STOREPOOL 253
STOREPOOLInit 253
STOREPOOLInit1 257
STOREVEC 264
STOREVECInit 265
SchedNext 111
SchedNext1 117
SchedNext2 119
SegmentTableInit 287
SelfSuspendDeviceProcess 313
SemaInUse1 131
SemaInUsea 136
SemaphoreSignal 199
SemaphoreWait 199
SendASynchMsg 146
SendASynchMsg1 157
SendASynchMsg2 158
SendMeToSleep 168
SendMeToSleep1 175
SendMeToSleep2 184
SendSMsg 199
SendSelfToSleep 193
SendSynchMsg 144
SendToProcess 296
SetCodeSegInfo 289
SetCurrentProcessId 104
SetDevMsg 302
SetDevReply 304
SetDeviceProcessData 313
SetFCHead 38, 233
SetFCHead2 48
SetFCLast 38, 233
SetFCLast2 48
SetHWTSS 293
SetNewCurrentProcess 101
SetPDState 307
SetPreviousProcess 245
SetProcPrio 32

332
List of Deﬁnitions
SetProcState 33, 227
SetProcState1 40, 235
SetProcType 223
SetProcType1 230
SetProcessStateToReady 105
SetProcessStateToReady 33
SetProcessStateToTerminated 194
SetProcessStateToTerminated 196
SetRunningProcess 244
SetStackDataSegInfo 289
SetStateToDevWait 310
SetStateToReady 227
SetStateToReady1 236
SetStateToRunning 104, 227
SetStateToRunning1 236
SetStateToSleeping 165
SetStateToTerminated 227
SetStateToWaitSema 122
SetSysErr 214
SetWaitingTime 33, 162
SetupFirstProcess 293
ShouldAddPRIOQHd 72
ShouldAddPRIOQHd1 81
ShouldAddPRIOQHd2 93
ShouldAddPRIOQLast 72
ShouldAddPRIOQLast1 81
ShouldAddPRIOQLast2 93
ShouldScavenge 256
ShouldScavenge1 260
ShouldScavengeMsgs 268
ShouldWake1 173
ShouldWake2 182
ShouldWakeUp 166
ShouldWakeUp1 173
ShouldWakeUp2 182
SignalSema 124
SleepTooShort 159
SourceExists 143
StackDataSegAddr 289
StoreBlock 265
StoreMsg 267
StoredBlock 266
StoredMsg 267
SuspendDeviceProcess 307
SuspendMe 114
SuspendMe1 118
SuspendMe2 119
SuspendSelf 193
SwitchToFirstProcess 290
SysErr 214
SysOk 23, 215
SystemClockOps 201
SystemInit 189
TIMESINCEBOOT 159
TIMESINCEBOOTInit 159
TerminateSelf 195
TerminateSelf 1 196
TheHeadOfPQ1 61
TheHeadOfPQ2 67
TheHeadOf −
PROCESSQUEUE 57, 240
TimeNow 159
TooManySleepers 163
TranslateMessageAddrs 295
TranslateMsgAddrs 295
UReturnNo 297
UReturnYes 297
USKGotMsgs 297
USKNewProcess 292
USKSendMsg 296
USKSuspendSelf 293
USKTerminateSelf 294
UnusedPD 28, 219
UpdateClockTime 160
UpdateCurrentProcess 245
UpdateTIMESINCEBOOT 159
UsedPID 29, 221
UsedPID1 35
UsedPID2 47
UsrSendMsgI 294
ValidDevRqProcessId 303
VerifyAndActivateDevProc 311
VerifyCallerIdent 286
WaitSema 122
WaitingTime 33, 162
ΦPTABM 272
ΦSCHED 103
ΦSEMAPHORE 120
ΦSEMATBL 127
ΦSKSCHED 245

