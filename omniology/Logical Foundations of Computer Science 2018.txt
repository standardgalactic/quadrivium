Sergei Artemov
Anil Nerode (Eds.)
 123
LNCS 10703
International Symposium, LFCS 2018
Deerfield Beach, FL, USA, January 8–11, 2018
Proceedings
Logical Foundations
of Computer Science

Lecture Notes in Computer Science
10703
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison
Lancaster University, Lancaster, UK
Takeo Kanade
Carnegie Mellon University, Pittsburgh, PA, USA
Josef Kittler
University of Surrey, Guildford, UK
Jon M. Kleinberg
Cornell University, Ithaca, NY, USA
Friedemann Mattern
ETH Zurich, Zurich, Switzerland
John C. Mitchell
Stanford University, Stanford, CA, USA
Moni Naor
Weizmann Institute of Science, Rehovot, Israel
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Bernhard Steffen
TU Dortmund University, Dortmund, Germany
Demetri Terzopoulos
University of California, Los Angeles, CA, USA
Doug Tygar
University of California, Berkeley, CA, USA
Gerhard Weikum
Max Planck Institute for Informatics, Saarbrücken, Germany

More information about this series at http://www.springer.com/series/7407

Sergei Artemov
• Anil Nerode (Eds.)
Logical Foundations
of Computer Science
International Symposium, LFCS 2018
Deerﬁeld Beach, FL, USA, January 8–11, 2018
Proceedings
123

Editors
Sergei Artemov
City University of New York
New York, NY
USA
Anil Nerode
Cornell University
Ithaca, NY
USA
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Computer Science
ISBN 978-3-319-72055-5
ISBN 978-3-319-72056-2
(eBook)
https://doi.org/10.1007/978-3-319-72056-2
Library of Congress Control Number: 2017960856
LNCS Sublibrary: SL1 – Theoretical Computer Science and General Issues
© Springer International Publishing AG 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, express or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
The Symposium on Logical Foundations of Computer Science provides a forum for the
fast-growing body of work on the logical foundations of computer science, e.g., those
areas of fundamental theoretical logic related to computer science. The LFCS series
began with “Logic at Botik,” Pereslavl-Zalessky, 1989, which was co-organized by
Albert R. Meyer (MIT) and Michael Taitslin (Tver). After that, organization passed to
Anil Nerode.
Currently LFCS is governed by a Steering Committee consisting of Anil Nerode
(General Chair), Stephen Cook, Dirk van Dalen, Yuri Matiyasevich, Gerald Sacks,
Andre Scedrov, and Dana Scott.
The 2018 Symposium on Logical Foundations of Computer Science (LFCS 2018)
took place at the Wyndham Deerﬁeld Beach Resort, Deerﬁeld Beach, Florida, USA,
during January 8–11, 2018. This volume contains the extended abstracts of talks
selected by the Program Committee for presentation at LFCS 2018.
The scope of the symposium is broad and includes constructive mathematics and
type theory, homotopy type theory, logic, automata and automatic structures, com-
putability and randomness, logical foundations of programming, logical aspects of
computational complexity, parameterized complexity, logic programming and con-
straints, automated deduction and interactive theorem proving, logical methods in
protocol and program veriﬁcation, logical methods in program speciﬁcation and
extraction, domain theory logics, logical foundations of database theory, equational
logic and term rewriting, lambda and combinatory calculi, categorical logic and
topological semantics, linear logic, epistemic and temporal logics, intelligent and
multiple-agent system logics, logics of proof and justiﬁcation, non-monotonic rea-
soning, logic in game theory and social software, logic of hybrid systems, distributed
system logics, mathematical fuzzy logic, system design logics, and other logics in
computer science.
We thank the authors and reviewers for their contributions. We acknowledge the
support of the U.S. National Science Foundation, The Association for Symbolic Logic,
Cornell University, the Graduate Center of the City University of New York, and
Florida Atlantic University.
October 2017
Anil Nerode
Sergei Artemov

Organization
Steering Committee
Stephen Cook
University of Toronto, Canada
Yuri Matiyasevich
Steklov Mathematical Institute, St. Petersburg, Russia
Anil Nerode (General Chair)
Cornell University, USA
Gerald Sacks
Harvard University, USA
Andre Scedrov
University of Pennsylvania, USA
Dana Scott
Carnegie-Mellon University, USA
Dirk van Dalen
Utrecht University, The Netherlands
Program Committee
Sergei Artemov (Chair)
The City University of New York, USA
Eugene Asarin
Université Paris Diderot - Paris 7, France
Steve Awodey
Carnegie Mellon University, USA
Matthias Baaz
The Vienna University of Technology, Austria
Lev Beklemishev
Steklov Mathematical Institute, Moscow, Russia
Andreas Blass
University of Michigan, Ann Arbor, USA
Samuel Buss
University of California, San Diego, USA
Robert Constable
Cornell University, USA
Thierry Coquand
University of Gothenburg, Sweden
Nachum Dershowitz
Tel Aviv University, Israel
Michael Fellows
University of Bergen, Norway
Melvin Fitting
The City University of New York, USA
Sergey Goncharov
Sobolev Institute of Mathematics, Novosibirsk, Russia
Denis Hirschfeldt
University of Chicago, USA
Martin Hyland
University of Cambridge, UK
Rosalie Iemhoff
Utrecht University, The Netherlands
Hajime Ishihara
Japan Advanced Institute of Science and Technology,
Kanazawa, Japan
Bakhadyr Khoussainov
The University of Auckland, New Zealand
Roman Kuznets
The Vienna University of Technology, Austria
Daniel Leivant
Indiana University Bloomington, USA
Robert Lubarsky
Florida Atlantic University, USA
Victor Marek
University of Kentucky, Lexington, USA
Lawrence Moss
Indiana University Bloomington, USA
Anil Nerode
Cornell University, USA
Hiroakira Ono
Japan Advanced Institute of Science and Technology,
Kanazawa, Japan
Alessandra Palmigiano
Delft University of Technology, The Netherlands
Ruy de Queiroz
The Federal University of Pernambuco, Recife, Brazil

Ramaswamy Ramanujam
The Institute of Mathematical Sciences, Chennai, India
Michael Rathjen
University of Leeds, UK
Jeffrey Remmel
University of California, San Diego, USA
Andre Scedrov
University of Pennsylvania, USA
Helmut Schwichtenberg
University of Munich, Germany
Philip Scott
University of Ottawa, Canada
Alex Simpson
University of Ljubljana, Slovenia
Sonja Smets
University of Amsterdam, The Netherlands
Sebastiaan Terwijn
Radboud University Nijmegen, The Netherlands
Alasdair Urquhart
University of Toronto, Canada
Additional Reviewers
Josef Berger
S. P. Suresh
Catalin Dima
Giuseppe Greco
Yanjing Wang
Heinrich Wansing
Toshiyasu Arai
Lutz Straßburger
Rohit Parikh
VIII
Organization

Contents
The Completeness Problem for Modal Logic . . . . . . . . . . . . . . . . . . . . . . .
1
Antonis Achilleos
Justification Awareness Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
Sergei Artemov
A Minimal Computational Theory of a Minimal
Computational Universe. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
Arnon Avron and Liron Cohen
A Sequent-Calculus Based Formulation of the Extended
First Epsilon Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
Matthias Baaz, Alexander Leitsch, and Anela Lolic
Angluin Learning via Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
Simone Barlocco and Clemens Kupke
A Universal Algebra for the Variable-Free Fragment of RCr . . . . . . . . . . . .
91
Lev D. Beklemishev
A Logic of Blockchain Updates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
107
Kai Brünnler, Dandolo Flumini, and Thomas Studer
From Display to Labelled Proofs for Tense Logics . . . . . . . . . . . . . . . . . . .
120
Agata Ciabattoni, Tim Lyon, and Revantha Ramanayake
Notions of Cauchyness and Metastability . . . . . . . . . . . . . . . . . . . . . . . . . .
140
Hannes Diener and Robert Lubarsky
A Gödel-Artemov-Style Analysis of Constructible Falsity . . . . . . . . . . . . . .
154
Thomas Macaulay Ferguson
Probabilistic Reasoning About Simply Typed Lambda Terms . . . . . . . . . . . .
170
Silvia Ghilezan, Jelena Ivetić, Simona Kašterović, Zoran Ognjanović,
and Nenad Savić
Polyteam Semantics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
Miika Hannula, Juha Kontinen, and Jonni Virtema
On the Sharpness and the Single-Conclusion Property of Basic
Justification Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
211
Vladimir N. Krupski

Founded Semantics and Constraint Semantics of Logic Rules. . . . . . . . . . . .
221
Yanhong A. Liu and Scott D. Stoller
Separating the Fan Theorem and Its Weakenings II . . . . . . . . . . . . . . . . . . .
242
Robert S. Lubarsky
Dialectica Categories for the Lambek Calculus . . . . . . . . . . . . . . . . . . . . . .
256
Valeria de Paiva and Harley Eades III
From Epistemic Paradox to Doxastic Arithmetic . . . . . . . . . . . . . . . . . . . . .
273
V. Alexis Peluce
A Natural Proof System for Herbrand’s Theorem . . . . . . . . . . . . . . . . . . . .
289
Benjamin Ralph
Metastability and Higher-Order Computability . . . . . . . . . . . . . . . . . . . . . .
309
Sam Sanders
The Completeness of BCD for an Operational Semantics . . . . . . . . . . . . . . .
331
Rick Statman
A Tableau System for Instantial Neighborhood Logic . . . . . . . . . . . . . . . . .
337
Junhua Yu
Interpretations of Presburger Arithmetic in Itself . . . . . . . . . . . . . . . . . . . . .
354
Alexander Zapryagaev and Fedor Pakhomov
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
369
X
Contents

The Completeness Problem for Modal Logic
Antonis Achilleos(B)
School of Computer Science, Reykjavik University, Reykjavik, Iceland
antonios@ru.is
Abstract. We introduce the completeness problem for Modal Logic and
examine its complexity. For a deﬁnition of completeness for formulas,
given a formula of a modal logic, the completeness problem asks whether
the formula is complete for that logic. We discover that completeness and
validity have the same complexity — with certain exceptions for which
there are, in general, no complete formulas. To prove upper bounds, we
present a non-deterministic polynomial-time procedure with an oracle
from PSPACE that combines tableaux and a test for bisimulation, and
determines whether a formula is complete.
Keywords: Modal logic · Completeness · Computational complexity
Bisimulation
1
Introduction
For a modal logic l, we call a modal formula ϕ complete when for every modal
formula ψ on the same propositional variables as ϕ, we can derive from ϕ in l
either the formula ψ or its negation. For diﬀerent modal logics l, we examine the
following problem: given a modal formula ϕ, is it complete for l? We call this
the completeness problem for l and we examine its complexity. Our main results
show that the completeness problem has the same complexity as provability, at
least for the logics we consider.
Given Modal Logic’s wide area of applications and the importance of logical
completeness in general, we ﬁnd it surprising that, to the best of our knowledge,
the completeness problem for Modal Logic has not been studied as a computa-
tional problem so far. On the other hand, the complexity of satisﬁability (and
thus validity) for Modal Logic has been studied extensively — for example, see
[1–3]. We examine the completeness problem for several well-known modal log-
ics, namely the extensions of K by the axioms Factivity, Consistency, Positive
Introspection, and Negative Introspection (also known as T, D, 4, and 5, respec-
tively) — i.e. the ones between K and S5. We discover that the complexity of
provability and completeness tend to be the same: the completeness problem
This research was partly supported by the project “TheoFoMon: Theoretical Foun-
dations for Monitorability” (grant number: 163406-051) of the Icelandic Research
Fund.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 1–21, 2018.
https://doi.org/10.1007/978-3-319-72056-2_1

2
A. Achilleos
is PSPACE-complete if the logic does not have Negative Introspection and it is
coNP-complete otherwise. There are exceptions: for certain logics (D and T),
the completeness problem as we deﬁne it is trivial, as these logics have no ﬁnite
complete theories.
Our motivation partly comes from [4] (see also [5]), where Artemov raises the
following issue. It is the usual practice in Game Theory (and Epistemic Game
Theory) to reason about a game based on a model of the game description. On
the other hand, it is often the case in an epistemic setting that the game spec-
iﬁcation is not complete, thus any conclusions reached by examining any single
model are precarious. He thus argues for the need to verify the completeness of
game descriptions, and proposes a syntactic, proof-centered approach, which is
more robust and general, and which is based on a syntactic formal description of
the game. Artemov’s approach is more sound, in that it allows one to draw only
conclusions that can be safely derived from the game speciﬁcation; on the other
hand, the model-based approach has been largely successful in Game Theory for
a long time. He explain that if we can determine that the syntactic speciﬁcation
of a game is complete, then the syntactic and semantic approaches are equiv-
alent and we can describe the game eﬃciently, using one model. Furthermore,
he presents a complete and an incomplete formulation of the Muddy Children
puzzle.
For a formula–speciﬁcation ϕ (for example, a syntactic description of a game),
if we are interested in the formulas we can derive from ϕ (the conclusions we can
draw from the game description), knowing that ϕ is complete can give a signiﬁ-
cant computational advantage. If ϕ is complete and consistent, for a model M for
ϕ, ψ can be derived from ϕ exactly when ψ is satisﬁed in M at the same state
as ϕ. Thus, knowing that ϕ is complete allows us to reduce a derivability problem
to a model checking problem, which is easier to solve (see, for example, [3]). This
approach may be useful when we need to examine multiple conclusions, especially
if the model for ϕ happens to be small. On the other hand, if we discover that ϕ is
incomplete, then, as a speciﬁcation it may need to be reﬁned.
Notions similar to complete formulas have been studied before. Characteristic
formulas allow one to characterize a state’s equivalence class for a certain equiv-
alence relation. In our case, the equivalence relation is bisimulation on states of
(ﬁnite) Kripke models and the notions of characteristic and complete formulas
collapse, by the Hennessy-Milner Theorem [6], in that a formula is complete for
one of the logics we consider if and only if it is characteristic for a state in a
model for that logic. A construction of characteristic formulas for variants of
CCS processes [7] was introduced in [8]. This construction allows one to ver-
ify that two CCS processes are equivalent by reducing this problem to model
checking. Similar constructions were studied later in [9–11] for instance.
Normal forms for Modal Logic were introduced by Fine [12] and they can
be used to prove soundness, completeness, and the ﬁnite frame property for
several modal logics with respect to their classes of frames. Normal forms are
modal formulas that completely describe the behavior of a Kripke model up to a
certain distance from a state, with respect to a certain number of propositional

The Completeness Problem for Modal Logic
3
variables. Therefore, every complete formula is equivalent to a normal form, but
not all normal forms are complete, as they may be agnostic with respect to states
located further away. We may deﬁne that a formula is complete up to depth d
for logic l when it is equivalent to a normal form of modal depth (the nesting
depth of a formula’s modalities) at most d. We brieﬂy discuss these topics in
Sect. 6.
We focus on a deﬁnition of completeness that emphasizes on the formula’s
ability to either aﬃrm or reject every possible conclusion. We can also consider
a version of the problem that asks to determine if a formula is complete up to its
modal depth — that is, whether it is equivalent to a normal form. If we are inter-
ested in completely describing a setting, the deﬁnition we use for completeness
is more appropriate. However, it is not hard to imagine situations where this
variation of completeness is the notion that ﬁts better, either as an approxima-
tion on the epistemic depth agents reason with, or, perhaps, as a description of
process behavior for a limited amount of time. We brieﬂy examine this variation
in Sect. 6.
Overview. Section 2 provides background on Modal Logic, bisimulation, and rel-
evant complexity results. In Sect. 3, we draw our ﬁrst conclusions about the com-
pleteness problem in relation to bisimulation and give our ﬁrst complexity result
for logics with Negative Introspection. In Sect. 4, we examine diﬀerent logics and
in which cases for each of these logics the completeness problem is non-trivial.
In Sect. 5, we examine the complexity of the completeness problem. We ﬁrst
present a general lower bound. For logics with Negative Introspection we prove
coNP-completeness. For the remaining logics — the ones without Negative Intro-
spection for which the problem is not trivial — we present a non-deterministic
polynomial-time procedure with an oracle from PSPACE that accepts incomplete
formulas, as the section’s main theorem, Theorem 6 demonstrates. This proves
that the completeness problem for these cases is PSPACE-complete. These com-
plexity results are summarized in Table 1. In Sect. 6, we consider variations of
the problem and draw further conclusions. Full proofs for our results can be
found in the extended version, [13].
2
Background
We present needed background on Modal Logic, its complexity, and bisimulation,
and we introduce the completeness problem. For an overview of Modal Logic and
its complexity, we refer the reader to [3,14,15].
2.1
Modal Logic
We assume a countably inﬁnite set of propositional variables p1, p2, . . .. Literals
are all p and ¬p, where p is a propositional variable. Modal formulas are con-
structed from literals, the constants ⊥, ⊤, the usual operators for conjunction
and disjunction ∧, ∨, and the dual modal operators, □and ♦:
ϕ ::= ⊥| ⊤| p | ¬p | ϕ ∧ϕ | ϕ ∨ϕ | □ϕ | ♦ϕ.

4
A. Achilleos
The negation ¬ϕ of a modal formula, implication ϕ →ψ, and ϕ ↔ψ are
constructed as usual. The language described by the grammar above is called L.
For a ﬁnite set of propositional variables P, L(P) ⊆L is the set of formulas
that use only variables from P. For a formula ϕ, P(ϕ) is the set of propositional
variables that appear in ϕ, so ϕ ∈L(P(ϕ)). If ϕ ∈L, then sub(ϕ) is the set of
subformulas of ϕ and sub(ϕ) = sub(ϕ) ∪{¬ψ | ψ ∈sub(ϕ)}. For Φ a nonempty
ﬁnite subset of L,  Φ is a conjunction of all elements of Φ and  ∅= ⊤;
we deﬁne  Φ similarly. The modal depth md(ϕ) of ϕ is the largest nesting
depth of its modal operators; the size of ϕ is |ϕ| = |sub(ϕ)|. For every d ≥0,
subd(ϕ) = {ψ ∈subd(ϕ) | md(ψ) ≤d}.
Normal modal logics use all propositional tautologies and axiom K, Modus
Ponens, and the Necessitation Rule:
K : □ϕ ∧□(ϕ →ψ) →□ψ;
ϕ ϕ →ψ
ψ
;
ϕ
□ϕ.
The logic that has exactly these axioms and rules is the smallest normal modal
logic, K. We can extend K with more axioms:
D : ♦⊤;
T : □ϕ →ϕ;
4 : □ϕ →□□ϕ;
5 : ♦ϕ →□♦ϕ.
We consider modal logics that are formed from a combination of these axioms.
Of course, not all combinations make sense: axiom D (also called the Consistency
axiom) is a special case of T (the Factivity axiom). Axiom 4 is called Positive
Introspection and 5 is called Negative Introspection. Given a logic l and axiom a,
l+a is the logic that has as axioms all the axioms of l and a. Logic D is K+D, T
is K+T, K4 = K+4, D4 = K+D+4 = D+4, S4 = K+T +4 = T+4 = K4+T,
KD45 = D4 + 5, and S5 = S4 + 5. From now on, unless we explicitly say
otherwise, by a logic or a modal logic, we mean one of the logics we deﬁned
above. We use ⊢l ϕ to mean that ϕ can be derived from the axioms and rules of
l; when l is clear from the context, we may drop the subscript and just write ⊢.
A Kripke model is a triple M = (W, R, V ), where W is a nonempty set of
states (or worlds), R ⊆W × W is an accessibility relation and V is a function
that assigns to each state in W a set of propositional variables. If P is a set
of propositional variables, then for every a ∈W, VP (a) = V (a) ∩P. To ease
notation, when (s, t) ∈R we usually write sRt.
Truth in a Kripke model is deﬁned through relation |= in the following way:
M, a |= p iﬀp ∈V (a), and
M, a ̸|= ⊥and M, a |= ⊤;
M, a |= p iﬀp ∈V (a) and M, a |= ¬p iﬀp /∈V (a);
M, a |= ϕ ∧ψ iﬀboth M, a |= ϕ and M, a |= ψ;
M, a |= ϕ ∨ψ iﬀM, a |= ϕ or M, a |= ψ;
M, a |= ♦ϕ iﬀthere is some b ∈W such that aRb and M, b |= ϕ; and
M, a |= □ϕ iﬀfor all b ∈W such that aRb it is the case that M, b |= ϕ.

The Completeness Problem for Modal Logic
5
If M, a |= ϕ, we say that ϕ is true/satisﬁed in a of M. (W, R) is called a frame.
We call a Kripke model (W, R, V ) (resp. frame (W, R)) ﬁnite if W is ﬁnite.1 If
M is a model (for logic l) and a is a state of M, then (M, a) is a pointed model
(resp. for l).
Each modal logic l is associated with a class of frames F(l), that includes
all frames (W, R) for which R meets certain conditions, depending on the logic’s
axioms. If l has axiom:
D, then R must be serial (for every state a ∈W there must be some b ∈W
such that aRb);
T, then R must be reﬂexive (for all a ∈W, aRa);
4, then R must be transitive (if aRbRc, then aRc);
5, then R must be euclidean (if aRb and aRc, then bRc).
A model (W, R, V ) is a model for a logic l if and only if (W, R) ∈F(l). We
call a formula satisﬁable for logic l, if it is satisﬁed in a state of a model for l.
We call a formula valid for logic l, if it is satisﬁed in all states of all models for l.
Theorem 1 (Completeness, Finite Frame Property). A formula ϕ is valid
for l if and only if it is provable in l; ϕ is satisﬁable for l if and only if it is
satisﬁed in a ﬁnite model for l.
For the remainder of this paper we only consider ﬁnite Kripke models and
frames. For a ﬁnite model M = (W, R, V ), we deﬁne |M| = |W| + |R|.
Deﬁnition 1. A formula ϕ is called complete for logic l when for every ψ ∈
L(P(ϕ)), ⊢l ϕ →ψ or ⊢l ϕ →¬ψ; otherwise, it is incomplete for l.
By Theorem 1, ϕ is complete for l exactly when for every ψ ∈L(P(ϕ)), either
ψ or its negation is true at every (ﬁnite) pointed model for l that satisﬁes ϕ.
2.2
Bisimulation
An important notion in Modal Logic (and other areas) is that of bisimulation. Let
P be a (ﬁnite) set of propositional variables. For Kripke models M = (W, R, V )
and M′ = (W ′, R′, V ′), a non-empty relation R ⊆W × W ′ is a bisimulation
(respectively, bisimulation modulo P) from M to M′ when the following condi-
tions are satisﬁed for all (s, s′) ∈R:
– V (s) = V ′(s′) (resp. VP (s) = V ′
P (s′)).
– For all t ∈W such that sRt, there exists t′ ∈W ′ s.t. (t, t′) ∈R and s′R′t′.
– For all t′ ∈W ′ such that s′R′t′, there exists t ∈W s.t. (t, t′) ∈R and sRt.
1 According to our deﬁnition, for a ﬁnite model M = (W, R, V ) and a ∈W, V (a)
can be inﬁnite. However, we are mainly interested in (W, R, VP ) for ﬁnite sets of
propositions P, which justiﬁes calling M ﬁnite.

6
A. Achilleos
We call pointed models (M, a), (M′, a′) bisimilar (resp. bisimilar modulo P)
and write (M, a) ∼(M′, a′) (resp. (M, a) ∼P (M′, a′)) if there is a bisim-
ulation (resp. bisimulation modulo P) R from M to M′, such that aRa′.
If (M, a) is a pointed model, and P a set of propositional variables, then
ThP (M, a) = {ϕ ∈L(P) | M, a |= ϕ}. We say that two pointed models are
equivalent and write (M, a) ≡P (M′, a′) when ThP (M, a) = ThP (M′, a′). The
following simpliﬁcation of the Hennessy-Milner Theorem [6] gives a useful char-
acterization of pointed model equivalence; Proposition 1 is its direct consequence.
Theorem 2 (Hennessy-Milner Theorem). If (M, a), (M′, a′) are ﬁnite
pointed models, then
(M, a) ≡P (M′, a′) if and only if (M, a) ∼P (M′, a′).
Proposition 1. A formula ϕ is complete for a logic l if and only if for every
two pointed models (M, a) and (M′, a′) for l, if M, a |= ϕ and M′, a′ |= ϕ, then
(M, a) ∼P (M′, a′).
Paige and Tarjan in [16] give an eﬃcient algorithm for checking whether two
pointed models are bisimilar. Theorem 3 is a variation on their result to account
for receiving the set P of propositional variables as part of the algorithm’s input.
Theorem 3. There is an algorithm which, given two pointed models (M, a)
and (M′, a′) and a ﬁnite set of propositional variables P, determines whether
(M, a) ∼P (M′, a′) in time O(|P| · (|M| + |M′|) · log(|M| + |M′|)).
2.3
The Complexity of Satisﬁability
For logic l, the satisﬁability problem for l, or l-satisﬁability asks, given a formula
ϕ, if ϕ is satisﬁable. The provability problem for l asks if ⊢l ϕ.
The classical complexity results for Modal Logic are due to Ladner [1], who
established PSPACE-completeness for the satisﬁability of K, T, D, K4, D4,
and S4 and NP-completeness for the satisﬁability of S5. Halpern and Rˆego
later characterized the NP–PSPACE gap by the presence or absence of Negative
Introspection [2], resulting in Theorem 4.
Theorem 4. If l ∈{K, T, D, K4, D4, S4}, then l-provability is PSPACE-
complete and l + 5-provability is coNP-complete.
3
The Completeness Problem and Axiom 5
The completeness problem for l asks, given a formula ϕ, if ϕ is complete for l.
In this section, we explain how to adjust Halpern and Rˆego’s techniques from
[2] to prove similar complexity bounds for the completeness problem for logics
with Negative Introspection. In the course of proving the coNP upper bound for
logics with Negative Introspection, Halpern and Rˆego give in [2] a construction
that provides a small model for a satisﬁable formula. We can adjust parts of

The Completeness Problem for Modal Logic
7
their construction and conclude with Corollary 2 and from that, Lemma 1 and
Corollary 1. The remaining results in this section are consequence of these.
For a logic l + 5, we call a pointed model (M, s) for l + 5 ﬂat when
– M = ({s} ∪W, R, V );
– R = R1 ∪R2, where R1 ⊆{s} × W and R2 is an equivalence relation on W;
and
– if l ∈{T,S4}, then s ∈W.
Lemma 1 informs us that ﬂat models are a normal form for models of logics with
axiom 5. Negative Introspection. and it is part of the construction from [2].
Lemma 1. Every pointed l + 5-model (M, s) is bisimilar to a ﬂat pointed l + 5-
model.
Proof. Let W ′ be the set of states of M reachable from s and R the restriction of
the accessibility relation of M on W ′. It is easy to see that the identity relation is
a bisimulation from M to M′, so (M, s) ∼(M′, s); let W = {w ∈W ′ | ∃w′Rw}.
Therefore W ′ = W ∪{s} and if l ∈{T,S4}, then s ∈W. Since M is an l + 5-
model, R is euclidean. Therefore, the restriction of R on W is reﬂexive. This in
turn means that R is symmetric in W: if a, b ∈W and aRb, since aRa, we also
have bRa. Finally, R is transitive in W: if aRbRc and a, b, c ∈W, then bRa, so
aRc. Therefore R is an equivalence relation when restricted on W.
⊓⊔
The construction from [1,2] continues to ﬁlter the states of the ﬂat model,
resulting in a small model for a formula ϕ. Using this construction, Halpern
and Rˆego prove Corollary 1 [2]; the NP upper bound for l + 5-satisﬁability of
Theorem 4 is a direct consequence.
Corollary 1. Formula ϕ is l + 5-satisﬁable if and only if it is satisﬁed in a ﬂat
l + 5-model of O(|ϕ|) states.
Since we are asking whether a formula is complete, instead of whether it is
satisﬁable, we want to be able to ﬁnd two small non-bisimilar models for ϕ when
ϕ is incomplete. For this, we need a characterization of bisimilarity between ﬂat
models.
Lemma 2. Flat pointed models (M, a) = ({a}∪W, R, V ) and (M′, a′) = ({a′}∪
W ′, R′, V ′) are bisimilar modulo P if and only if VP (a) = VP (a′) and:
– for every b ∈W, there is some b′ ∈W ′ such that VP (b) = V ′
P (b′);
– for every b′ ∈W ′, there is some b ∈W ′ such that VP (b) = V ′
P (b′);
– for every b ∈W, if aRb, then there is a b′ ∈W ′ such that a′Rb′ and VP (b) =
V ′
P (b′); and
– for every b′ ∈W ′, if a′Rb′, then there is a b ∈W ′ such that aRb and VP (b) =
V ′
P (b′).

8
A. Achilleos
Proof. If these conditions are met, we can deﬁne bisimulation R such that aRa′
and for b ∈W and b′ ∈W ′, bRb′ iﬀVP (b) = V ′
P (b′); on the other hand, if there
is a bisimulation, then it is not hard to see by the deﬁnition of bisimulation that
these conditions hold — for both claims, notice that the conditions above, given
the form of the models, correspond exactly to the conditions from the deﬁnition
of bisimulation.
⊓⊔
This gives us Corollary 2, which is a useful characterization of incomplete
formulas.
Corollary 2. Formula ϕ is incomplete for l + 5 if and only if it has two non-
bisimilar ﬂat pointed models for l + 5 of at most O(|ϕ|) states.
Proof. If ϕ has two non-bisimilar pointed models for l + 5, then by Theorem 2,
it is incomplete. On the other hand, if ϕ is incomplete, again by Theorem 2 and
Lemma 1, ϕ has two non-bisimilar ﬂat pointed models, (M, a) = ({a}∪W, R, V )
and (M′, a′) = ({a′} ∪W ′, R′, V ′). By Lemma 2 and without loss of generality,
we can distinguish three cases:
– there is some p ∈VP (a) \ VP (a′): in this case let ψ = p;
– there is some b ∈W, such that for all b′ ∈W ′, VP (b) ̸= V ′
P (b′): in this case
let ψ = ♦♦( VP (b) ∧¬ (P \ VP (b)));
– there is some b ∈W, such that aRb and for all b′ ∈W ′ such that a′Rb′,
VP (b) ̸= V ′
P (b′): in this case let ψ = ♦( VP (b) ∧¬ (P \ VP (b))).
In all these cases, both ϕ ∧ψ and ϕ ∧¬ψ are satisﬁable and of size O(|ϕ|), so
by Corollary 1, each is satisﬁed in a non-bisimilar ﬂat pointed model for l + 5 of
at most O(|ϕ|) states.
⊓⊔
Our ﬁrst complexity result is a consequence of Corollary 2 and Theorem 3:
Proposition 2. The completeness problem for logic l + 5 is in coNP.
Proof. By Corollary 2 and Theorem 3.
⊓⊔
In the following, when P is evident, we will often omit any reference to it and
instead of bisimulation modulo P, we will call the relation simply bisimulation.
4
The Completeness Problem and Triviality
The ﬁrst question we must answer concerning the completeness problem for l is
whether there are any satisﬁable and complete formulas for l. If not, then the
problem is trivial. We examine this question with parameters the logic l and
whether P, the set of propositional variables we use, is empty or not. If for a
logic l the problem is nontrivial, then we give a complete formula ϕl
P that uses
exactly the propositional variables in P. We see that for P = ∅, completeness
can be trivial for another reason: for some logics, when P = ∅, all formulas are
complete. On the other hand, when P ̸= ∅,  P is incomplete for every logic.

The Completeness Problem for Modal Logic
9
4.1
Completeness and K
Whether P = ∅or not, completeness is nontrivial for K and K4: let ϕK
P =
ϕK4
P
=  P ∧□⊥for every ﬁnite P. Formula ⊤is incomplete for K and K4.
Lemma 3. Formula  P ∧□⊥is complete and satisﬁable for K and for K4.
Proof. A model that satisﬁes ϕK
P is M = ({a}, ∅, V ), where V (a) = P. If there
is another model M′, a′ |= ϕK
P , then M′, a′ |= □⊥, so there are no accessible
worlds from a′ in M′; therefore, R = {(a, a′)} is a bisimulation.
⊓⊔
Notice that if ϕ is complete for l, then it is complete for every extension of l.
Thus, ϕK
P is complete for all other logics. However, we are looking for satisﬁable
and complete formulas for each logic, so ﬁnding one complete formula for K is
not enough. On the other hand, if l′ is an extension of l (by a set of axioms) and a
formula ϕ is complete for l and satisﬁable for l′, then we know that ϕ is satisﬁable
and complete for all logics between (and including) l and l′. Unfortunately, the
following lemma demonstrates that we cannot use this convenient observation
to reuse ϕK
P — except perhaps for K5 and K45, but these can be handled just
as easily together with the remaining logics with Negative Introspection.
4.2
Completeness and Consistency
When l has axiom T or D, but not 4 or 5, P determines if a formula is complete:
Lemma 4. Let l be either D or T. A satisﬁable formula ϕ ∈L is complete with
respect to l if and only if P(ϕ) = ∅.
Proof. When P = ∅, all models are bisimilar through the total bisimulation;
therefore, all formulas ϕ, where P(ϕ) = ∅are trivially complete. We now consider
the case for P ̸= ∅; notice that we can assume that l = D, as D is contained in
T. Let the modal depth of ϕ be d and let M, a |= ϕ, where M = (W, R, V ); let
x /∈W ∗, a0 = a, and
Πd = {a0 · · · ak ∈W ∗| k ≤d and for all 0 ≤i < k, aiRai+1}.
Then, we deﬁne M′
1 = (W ′, R′, V ′
1) and M′
2 = (W ′, R′, V ′
2), where
W ′ = Πd ∪{x};
R′ = {(α, αb) ∈W ′2 | b ∈W} ∪{(a0a1 · · · ad, x) ∈W ′2} ∪{(x, x)}
V ′
i (αb) = V (b), for i = 1, 2, 0 ≤|α| < d;
V ′
1(x) = ∅;
and V ′
2(x) = P.
To prove that M′
1, a |= ϕ and M′
2, a |= ϕ, we prove that for ψ ∈sub(ϕ),
for every i = 1, 2 and w = a0 · · · ak ∈Πd, where k ≤d −md(ψ), M′
i, w |= ψ if
and only if M, ak |= ψ. We use induction on ψ. If ψ is a literal or a constant,
the claim is immediate and so are the cases of the ∧, ∨connectives. If ψ = □ψ′,
then md(ψ′) = md(ψ) −1; M′
i, w |= ψ iﬀfor every wR′w′, M′
i, w′ |= ψ′ iﬀfor

10
A. Achilleos
every akR′b, M, b |= ψ′ (by the Inductive Hypothesis) iﬀM, ak |= ψ; the case
of ψ = ♦ψ′ is symmetric.
If (M′
1, a) ∼(M′
2, a) through bisimulation R from M′
1 to M′
2, then notice
that in both models any suﬃciently long path from a will end up at x; therefore,
by the conditions of bisimulation, xRx, which is a contradiction, since V ′
1(x) ̸=
V ′
2(x). So, ϕ is satisﬁed in two non-bisimilar models for D.
⊓⊔
4.3
Completeness, Consistency, and Positive Introspection
For every ﬁnite P, let ϕD4
P
= ϕS4
P
=  P ∧□ P. As the following lemma
demonstrates, ϕD4
P
is a complete formula for D4 and S4.
Lemma 5. For every ﬁnite P, ϕD4
P
is complete for D4 and S4; all formulas in
L(∅) are complete for D4 and S4.
Proof. Let M, a |= ϕD4
P
and M′, a′ |= ϕD4
P ; let R be the relation that connects
all states of M that are reachable from a (including a) to all states of M′ that are
reachable from a′ (including a′); it is not hard to verify that R is a bisimulation.
Notice that if P = ∅, then ϕD4
P
is a tautology, thus all formulas are complete. ⊓⊔
It is straightforward to see that ϕD4
P
is satisﬁable for every logic l: consider a
model based on any frame for l, where  P holds at every state. Therefore:
Corollary 3. ϕD4 is satisﬁable and complete for every extension of D4.2
4.4
Consistency and Negative Introspection
For logic l = l′ + 5, let ϕl
P =  P ∧♦□ P.
Lemma 6. For any logic l = l′ + 5, ϕl
P is a satisﬁable complete formula for l.
Proof. By Lemma 1, ϕl
P is complete. It is satisﬁed in ({a}, {(a, a)}, V ), where
V (a) = P.
⊓⊔
When P = ∅, we can distinguish two cases. If l′ ∈{D,D4,T,S4}, then ϕl
∅is a
tautology, therefore all formulas in L(P) are complete for l.3 If l′ ∈{K,K4},
then there are exactly two non-bisimilar modulo ∅models for l; Therefore, if
P = ∅the completeness problem for K5 and K45 is not trivial, but it is easy to
solve: a formula with no propositional variables is complete for l ∈{K5, K45}
if it is satisﬁed in at most one of these two models.
Corollary 4. If P = ∅, the completeness problem for K5 and K45 is in P.
2 Although for the purposes of this paper we only consider a speciﬁc set of modal
logics, it is interesting to note that the corollary can be extended to a much larger
class of logics.
3 This is also a corollary of Lemma 4, as these are extensions of D and T.

The Completeness Problem for Modal Logic
11
4.5
Completeness and Modal Logics
A logic l has a nontrivial completeness problem if for P ̸= ∅, there are com-
plete formulas for l. From the logics we examined, only D and T have trivial
completeness problems. Table 1 summarizes the results of this section and of
Sect. 5 regarding the completeness problem. As the table demonstrates, we can
distinguish the following cases. For K, the completeness problem is non-trivial
and PSPACE-complete; this does not change when we add axiom 4. Once we
add axiom D to K, but not 4 or 5, the completeness problem becomes trivial;
adding the stronger axiom T does not change the situation. Adding both 4 and
D or T to K makes completeness PSPACE-complete again, except when P = ∅.
Regardless of other axioms, if the logic has Negative Introspection, completeness
is coNP-complete — unless P = ∅, when the situation depends on whether the
logic has D (or the stronger T) or not.
Table 1. The complexity of the completeness problem for diﬀerent modal logics. Trivial
(all) indicates that all formulas in this case are complete for the logic; trivial (none)
indicates that there is no satisﬁable, complete formula for the logic.
Modal logic
P = ∅
P ̸= ∅
K, K4
PSPACE-complete PSPACE-complete
D, T
Trivial (all)
Trivial (none)
D4, S4
Trivial (all)
PSPACE-complete
K5, K45
In P
coNP-complete
l + 5, l ̸= K, K4 Trivial (all)
coNP-complete
5
The Complexity of Completeness
Our main result is that for a modal logic l, the completeness problem has the
same complexity as provability for l, as long as we allow for propositional vari-
ables in a formula and l-completeness is nontrivial (see Table 1). For the lower
bounds, we consider hardness under polynomial-time reductions. As the hard-
ness results are relative to complexity classes that include coNP, these reductions
suﬃce.
5.1
A Lower Bound
We present a lower bound for the complexity of the completeness problem: that
the completeness problem is at least as hard as provability for a logic, as long as
it is nontrivial.
Theorem 5. Let l be a logic that has a nontrivial completeness problem and let
C be a complexity class. If l-provability is C-hard, then the completeness problem
for l is C-hard.

12
A. Achilleos
Proof. To prove the theorem we present a reduction from l-provability to the
completeness problem for l. From a formula ϕ, the reduction constructs in poly-
nomial time a formula ϕc, such that ϕ is provable if and only is ϕc is complete.
For each logic l with nontrivial completeness and ﬁnite set of propositional vari-
ables P, in Sect. 4 we provided a complete formula ϕl
P . This formula is satisﬁed
in a model of at most two states, which can be generated in time O(|P|). Let
(Ml, al) be such a pointed model for ϕl
P .
Any pointed model that satisﬁes ϕl
P is bisimilar to (Ml, al). Given a formula
ϕ ∈L(P), we can determine in linear time if Ml, al |= ϕ. There are two cases:
– Ml, al ̸|= ϕ, in which case ϕ is not provable and we set ϕc =  P.
– Ml, al |= ϕ, so ¬ϕ ∧ϕl
P is not satisﬁable, in which case we set ϕc = ϕ →ϕl
P .
We demonstrate that ϕ is provable if and only if ϕ →ϕl
P is complete.
– If ϕ is provable, then ϕ →ϕl
P is equivalent to ϕl
P , which is complete.
– On the other hand, if ϕ →ϕl
P is complete and (M, a) is any pointed
model, we show that M, a |= ϕ, implying that if ϕ →ϕl
P is complete,
then ϕ is provable. If (M, a) ∼P (Ml, al), then from our assumptions
M, a ̸|= ¬ϕ, thus M, a |= ϕ. On the other hand, if (M, a) ̸∼P (Ml, al),
since (Ml, al) |= ϕ →ϕl
P and ϕ →ϕl
P is complete, M, a ̸|= ϕ →ϕl
P ,
therefore M, a |= ϕ.
⊓⊔
Theorem 5 applies to more than the modal logics that we have deﬁned in
Sect. 2. For Propositional Logic, completeness amounts to the problem of deter-
mining whether a formula does not have two distinct satisfying assignments,
therefore it is coNP-complete. By similar reasoning, completeness for First-order
Logic is undecidable, as satisﬁability is undecidable.
5.2
Upper Bounds
The case of logics with axiom 5 is now straightforward; from Theorem 5 and
Proposition 2:
Proposition 3. The completeness problem for logic l + 5 is coNP-complete.
For the logics without axiom 5, by Theorem 4, satisﬁability and provability
are both PSPACE-complete. So, completeness is PSPACE-hard, if it is nontrivial.
It remains to show that it is also in PSPACE. To this end we present a procedure
that decides completeness for a modal formula. We call it the CC Procedure.
Parts of this procedure are similar to the tableaux by Fitting [17] and Massacci
[18] for Modal Logic, in that the procedure explores local views of a tableau.
For more on tableaux the reader can see [19]. The CC Procedure is a non-
deterministic polynomial time algorithm that uses an oracle from PSPACE. It
accepts exactly the incomplete formulas, thus establishing that the completeness
problems for these logics is in PSPACE. We have treated the case for logics with
axiom 5, and the completeness problem for D and T is trivial. Therefore, form
now on, we ﬁx a logic l that can either be K, or have axiom 4 and be one of
K4, D4, and S4.

The Completeness Problem for Modal Logic
13
The CC Procedure for Modal Logic l on ϕ. Intuitively, the procedure tries
to demonstrate that there are two models for ϕ that are not bisimilar. We ﬁrst
give a few deﬁnitions that we need to describe the procedure.
For our procedure, states are sets of formulas from sub(ϕ). The procedure
generates structures that we call views. A view S is a pair (p(S), C(S)) of a
(possibly empty) set C(S) of states, that are called the children-states of S and
a distinguished state p(S) called the parent-state of S. Each view is allowed to
have up to |ϕ| children-states.
Deﬁnition 2. We call a set s of formulas l-closed if the following conditions
hold:
– if ϕ1 ∧ϕ2 ∈s, then ϕ1, ϕ2 ∈s;
– if ϕ1 ∨ϕ2 ∈s, then ϕ1 ∈s or ϕ2 ∈s;
– if □ψ ∈s and l has axiom T, then ψ ∈s;
– for every p ∈P, either p ∈s or ¬p ∈s.
We call a view S l-complete (or complete if l is ﬁxed) if the following con-
ditions hold:
– the parent-state and every child-state of that view are l-closed;
– for every ♦ψ ∈p(S), ψ ∈ C(S);
– for every □ψ ∈p(S), ψ ∈ C(S);
– if l has axiom 4, then for every □ψ ∈p(S), □ψ ∈ C(S);
– if l has axiom D, then C(S) ̸= ∅.
For state a, th(a) =  a. A state a ⊆sub(ϕ) is maximal if it is a maximally
consistent subset of sub(ϕ). A child-state c of a view S is K-maximal when it is a
maximally consistent subset of subd(ϕ), where d = max{md(c′) | c′ ∈C(S)}. A
view S is consistent when every state of S is a consistent set of formulas. A view
S′ completes view S when: S′ is l-complete; p(S) ⊆p(S′); for every a ∈C(S)
there is an a′ ∈C(S′) such that a ⊆a′; and: if l = K, then every a′ ∈C(S′) is
K-maximal; if l has axiom 4, then every a′ ∈C(S′) is maximal.
A view gives a local view of a model, as long as it is consistent. The proce-
dure generates views and ensures that they are complete — so that all relevant
information is present in each view — and consistent — so that the view indeed
represents parts of a model. If the parent-state can represent two non-bisimilar
states of two models (say, s and t), then the procedure should be able to provide
a child, representing a state accessible from s or t that is not bisimilar to any
state accessible from s or t, respectively. Since the states are (K-)maximal, two
states that are not identical can only be satisﬁed in non-bisimilar models. The
procedure is given in Table 2.
This section’s main theorem is Theorem 6 and informs us our procedure can
determine the completeness of formula ϕ in at most |ϕ| + 2 steps. We conclude
that the completeness problem for logics without axiom 5 is in PSPACE.
Theorem 6. The CC Procedure accepts ϕ if and only if ϕ is incomplete.

14
A. Achilleos
Table 2. The CC Procedure on ϕ for logic l ∈{K, K4, D4, S4}.
Initial conditions: Non-deterministically generate maximal states a and b that
include ϕ; if there are none, then return “reject”.
If a ̸= b, then return “accept.”
Initialize N to |ϕ| + 2.
Construction:
Non-deterministically generate a consistent view S that
completes (a, ∅), having up to |ϕ| children-states.
Condition:
If C(S) = ∅, then return “reject.”
If there is a child-state c ∈C(S), such that ̸⊢l th(a) →♦th(c),
then return “accept.”
Next step:
Otherwise, non-deterministically pick a child c ∈C(S) and set
a := c.
If N > 0, then set N := N −1 and continue from
“Construction.”
If N = 0, then return “reject”.
Proof (Part of Proof). We give the proof of the theorem, but we omit certain
details. The interested reader can see [13] for a full proof. We prove that the CC
Procedure has a way to accept ϕ if and only if ϕ is satisﬁed in two non-bisimilar
models. By Theorem 2, the theorem follows.
We assume that there are two non-bisimilar pointed models (A, w) and (B, w′),
such that A, w |= ϕ and B, w′ |= ϕ. We prove that the CC Process accepts ϕ
in |ϕ| + 2 steps. We call these models the underlying models; the states of the
underlying models are called model states to distinguish them from states that
the process uses. Let A = (W A, RA, V A) and B = (W B, RB, V B); we can assume
that W A ∩W B = ∅. Let f : W A × W B →W A ∪W B be a partial function that
maps every pair (s, t) of non-bisimilar pairs to a model state c accessible from s
or t that is non-bisimilar to every state accessible from t or s, respectively. We
call f a choice-function. We can see that the procedure can maintain that the
maximal state it generates each time is satisﬁed in two non-bisimilar states s, t,
one from A and the other from B, respectively: at the beginning these are w
and w′. At every step, the procedure can pick a child c that is satisﬁed in f(s, t).
If ̸⊢l th(a) →♦th(c), then the procedure terminates and accepts the input.
Otherwise, c is satisﬁed in f(s, t) and in another state that is non-bisimilar to
f(s, t). Let that other state be called a counterpart of f(s, t).
If l = K, then at every step, the procedure can reduce the modal depth of a,
and therefore, after at most |ϕ| steps, the procedure can simply choose P = P(ϕ)
as a state. Since ♦ P is not derivable from any consistent set of modal depth 0,
the procedure can terminate and accept the input. We now assume that l ̸= K.
We demonstrate that if ϕ is incomplete, then the CC Procedure will accept
ϕ after a ﬁnite number of steps. As we have seen above, the procedure, given
non-bisimilar pointed models (A, a) and (B, b) of ϕ, always has a child to play

The Completeness Problem for Modal Logic
15
according to f. For convenience, we can assume that models A and B have no
cycles, so the choice-function never repeats a choice during a process run. If for
every choice of f, the process does not terminate, then we show that (A, w) ∼
(B, w′), reaching a contradiction. Let R =∼∪Z, where ∼is the bisimilarity
relation between the states of A and the states of B, and xZy when for some
choice-function, there is an inﬁnite execution of the procedure, in which y is
a counterpart of x, or x a counterpart of y. If xRy, either (A, x) ∼(B, y), so
V A
P (x) = V B
P (y), or xZy, so, again, V A
P (x) = V B
P (y), since x and y satisfy he
same maximal state. If xRy and xRAx′, then if (A, x) ∼(B, y), immediately
there is some yRBy′ so that (A, x′) ∼(B, y′); if x is a counterpart of y or y is a
counterpart of x during a non-terminating run, then for every x′ accessible from
x (the case is symmetric for a y′ accessible from y), either x′ is bisimilar to some
y′ accessible from y, or we can alter the choice-function f that the procedure uses
so that x′ = f(x, y). Since for that altered f, the procedure does not terminate, x′
has a counterpart as well. Therefore, the bisimulation conditions are satisﬁed and
R is a bisimulation. If for every choice-function, the procedure never terminates,
then (A, w) ∼(B, w′), and we have reached a contradiction. Therefore, there is
a choice-function f that ensures the procedure terminates after a ﬁnite number
of steps. We call that number of steps the length of choice-function f. For every
state a, let D(a) = {♦ψ ∈a} and B(a) = {□ψ ∈a}. Then, 0 ≤|D(a)| ≤k1
and 0 ≤|B(a)| ≤k2, where 0 ≤k1 + k2 ≤|ϕ| −1. Notice that according to the
deﬁnition of f above, as the process runs, D(a) decreases and B(a) increases —
though, not necessarily strictly.
Lemma 7. Let l ∈{K4, D4, S4} and let a, b, c be maximal states. If B(a) =
B(b), D(a) = D(b), ⊢th(a) →l ♦th(c), and ̸⊢l th(b) →♦th(c), then c = a ̸= b
and l = S4.
Proof. See [13].
⊓⊔
We can safely assume that the procedure never repeats the same choice of
child-state — otherwise, it could continue from the second repetition and shorten
its run. If during an execution, the CC Procedure picks states a, and in a follow-
ing step, a state b, so that B(a) = B(b) and D(a) = D(b), and immediately after
b the procedure picks child-state c, we claim that either the procedure could
pick c right after a without aﬀecting its run, or a and b are consecutive picked
states and after picking c, the procedure terminates. Since c can be a child-state
for a view that has b as parent-state, it satisﬁes all necessary closure conditions
for l-complete views, so it can appear as a child-state for a view that has a as
parent-state. If ̸⊢l th(a) →♦th(c), then the procedure can pick c right after a
and terminate immediately; if ⊢l th(a) →♦th(c), but ̸⊢l th(b) →♦th(c), then
the procedure terminates at c and, by Lemma 7, l = S4 and a = c. If a and b
are not consecutive states, then there is a maximal state a′ picked after a and
before b, so that B(a′) = B(b) and D(a′) = D(b). Similarly to the above, a′ = c,
and therefore, a = a′ — so, the procedure repeated the same child-state choice.
Therefore, a minimal-length choice function can ensure that the CC Procedure
terminates after |ϕ| + 2 steps.

16
A. Achilleos
On the other hand, we prove that if ϕ is complete, then the CC Procedure can
never accept ϕ. For this, we use the following lemmata:
Lemma 8. If a view S is consistent and complete and C(S) ̸= ∅, then
– if l does not have axiom 4 (l = K), then the following formula is consistent:
th(p(S)) ∧

c∈C(S)
♦th(c) ∧□

c∈C(S)
th(c);
– if l has axiom 4 (l ∈{K4, D4, S4}), then the following formula is consistent:
th(p(S)) ∧

c∈C(S)
♦th(c).
Proof. See [13].
⊓⊔
Lemma 9. Let s be a consistent, and complete state, and for l ̸= K, also a
maximal state; d a maximal state; and ψ a formula. If
– ⊢l th(s) →♦th(d),
– th(d) is not equivalent to th(s), and
– d ∪{□ψ} is consistent,
then th(s) ∧□(¬th(d) ∨□ψ) is consistent.
Proof. See [13].
⊓⊔
Lemma 10. For a consistent view S that completes itself, for every child c ∈
C(S), if th(p(S)) is complete, then so is th(c).
Proof. See [13].
⊓⊔
By Lemma 10, all parent-states that appear during a run are complete. If at
some point, the process picks a child-state c and a is the parent-state, then by
Lemma 8, th(a) ∧♦th(c) is consistent; since a is complete, ⊢l th(a) →♦th(c).
Therefore, there is no way for the procedure to accept if the input formula is
complete.
⊓⊔
Corollary 5. The completeness problem for K, K4, D4, and S4 is PSPACE-
complete.
Proof. PSPACE-hardness is a consequence of Theorem 5. The CC Procedure is a
non-deterministic polynomial-time algorithm with an oracle from PSPACE. Each
condition that it needs to check is either a closure condition or a condition for
the consistency or provability of formulas of polynomial size with respect to |ϕ|;
therefore, they can be veriﬁed either directly or with an oracle from PSPACE.
Thus, the completeness problem for these logics is in coNPPSPACE = PSPACE. ⊓⊔

The Completeness Problem for Modal Logic
17
6
Variations and Other Considerations
There are several variations one may consider for the completeness problem.
One may deﬁne the completeness of a formula in a diﬀerent way, consider a
diﬀerent logic, depending on the intended application, or wonder whether we
could attempt a solution to the completeness problem by using Fine’s normal
forms [12].
6.1
Satisﬁable and Complete Formulas
It may be more appropriate, depending on the case, to check whether a for-
mula is satisﬁable and complete. In this case, if the modal logic does not have
axiom 5, we can simply alter the CC Procedure so that it accepts right away
if the formula is not satisﬁable. Therefore, the problem remains in PSPACE; for
PSPACE-completeness, notice that the reduction for Theorem 5 constructs sat-
isﬁable formulas. For logics with axiom 5 (and plain Propositional Logic), the
language of satisﬁable and complete formulas is US-complete, where a language
U is in US when there is a nondeterministic Turing machine T, so that for every
instance x of U, x ∈U if and only if T has exactly one accepting computation
path for x4 [20]: UniqueSAT is a complete problem for US and a special case of
this variation of the completeness problem.
6.2
Completeness with Respect to a Model
A natural variation of the completeness problem would be to consider com-
pleteness of a formula over a satisfying model. That is, the problem would ask:
given a formula ϕ and pointed model (M, s), such that M, s |= ϕ, is formula ϕ
complete? For this variation, we are given one of ϕ’s pointed models, so it is a
reasonable expectation that the problem became easier. Note that in many cases,
this problem may be more natural than the original one, as we are now testing
whether the formula completely describes the pointed model (that is, whether
the formula is characteristic for the model). Unfortunately, this variation has
the same complexity as the original completeness problem. We can easily reduce
completeness with respect to a model to plain completeness by dropping the
model from the input. On the other hand, the reduction from provability to
completeness of Sect. 5 still works in this case, as it can easily be adjusted to
additionally provide the satisfying model of the complete formula ϕl
P .
4 We note that US is diﬀerent from UP; for UP, if T has an accepting path for x, then
it is guaranteed that it has a unique accepting path for x.

18
A. Achilleos
6.3
Completeness and Normal Forms for Modal Logic
In [12], Fine introduced normal forms for Modal Logic. The sets F d
P are deﬁned
recursively on the depth d, which is a nonnegative integer, and depend on the set
of propositional variables P (we use a variation on the presentation from [21]):
F 0
P =
⎧
⎨
⎩

p∈S
p ∧

p/∈S
¬p | S ⊆P
⎫
⎬
⎭;
and
F d+1
P
=
⎧
⎨
⎩ϕ0 ∧

ϕ∈S
♦ϕ ∧□

ϕ∈S
ϕ | S ⊆F d
P , ϕ0 ∈F 0
P
⎫
⎬
⎭.
For example, formula ϕK
P from Sect. 4 is a normal form in F 1
P .
Theorem 7 (from [12]). For every modal formula ϕ of modal depth at most d,
if ϕ is consistent for K, then there is some S ⊆F d
P , so that ⊢K ϕ ↔ S.
Furthermore, as Fine [12] demonstrated, normal forms are mutually exclusive:
no two distinct normal forms from F d
P can be true at the same state of a model.
Normal forms are not necessarily complete by our deﬁnition (for example, con-
sider p ∧♦p ∧□p for P = {p}), but, at least for K, it is not hard to distinguish
the complete ones; by induction on d, ϕ ∈F d
P is complete for K if and only if
md(ϕ) < d. Therefore, for K, the satisﬁable and complete formulas are exactly
the ones that are equivalent to such a complete normal form. However, we cannot
use this observation to test formulas for completeness by guessing a complete
normal form and verifying that it is equivalent to our input formula, as normal
forms can be of very large size: |F 0
P | = 2|P |; |F d+1
P
| = |P| · 2|F d
P |; and if ψ ∈F d
P ,
|ψ| can be up to |P| + 2|F d−1
P
|. We would be guaranteed a normal form of rea-
sonable (that is, polynomial w.r.to |ϕ|) size to compare to ϕ only if ϕ uses a
small (logarithmic with respect to |ϕ|) number of variables and its modal depth
is very small compared to |ϕ| (that is, md(ϕ) = O(log∗(|ϕ|))).
6.4
Completeness up to Depth
Fine’s normal forms [12] can inspire us to consider a relaxation of the deﬁnition of
completeness. We call a formula ϕ complete up to its depth for a logic l exactly
when for every formula ψ ∈L(P(ϕ)) of modal depth at most md(ϕ), either
⊢l ϕ →ψ or ⊢l ϕ →¬ψ. Immediately from Theorem 7:
Lemma 11. All normal forms are complete up to their depths.
Lemma 12. Formula ϕ is satisﬁable and complete up to its depth for logic l if
and only if it is equivalent in l to a normal form from F md(ϕ)
P
.
Proof. From Theorem 7, if ϕ is satisﬁable, then it is equivalent to some  S,
where S ⊆F md(ϕ)
P
, but if it is also complete up to its depth, then it can derive a

The Completeness Problem for Modal Logic
19
the normal form ψ ∈S; so, ⊢l ϕ →ψ, but also ⊢l ψ → S and  S is equivalent
to ϕ. For the other direction, notice that every normal form in F md(ϕ)
P
is either
complete or has the same modal depth as ϕ, so by Lemma 11, if ϕ is equivalent
to a normal form, in the ﬁrst case it is complete and in the second case it is
complete up to its depth.
Therefore, all modal logics have formulas that are complete up to their depth.
In fact, for any ﬁnite set of propositional variables P and d ≥0, we can deﬁne
ϕd
P = d
i=0 □i  P, which is equivalent in T and D to a normal form (by induc-
tion on d). Then, we can use a reduction similar to the one from the proof of
Theorem 5 to prove that for every modal logic, completeness up to depth is as
hard as provability.
Proposition 4. For any complexity class C and logic l, if l-provability is
C-hard, then completeness up to depth is C-hard.
Proof. The proof is similar to that of Theorem 5 and can be found in [13].
⊓⊔
We demonstrate that this variation of the completeness problem is in PSPACE
when the logic is K; it seems plausible that one can follow similar approaches
that use normal forms for the remaining modal logics.
Proposition 5. A formula ϕ is complete up to its depth for K if and only if
ϕ ∧□md(ϕ)+1⊥is complete for K.
Proof. Let ψ ∈F d
P be a normal form. Then, ψ ∧□d+1⊥is equivalent in K to
ψ+1 ∈F d+1
P
, which is ψ after we replace all ♦ψ′ in ψ by ♦(ψ′ ∧□⊥), where
ψ′ ∈F 0
P . Notice that ψ1, ψ2 ∈F d
P are distinct normal forms if and only if
ψ+1
1 , ψ+1
2
are distinct normal forms in F r
P for every r > d. So, ϕ is complete
up to its depth for K if and only if ϕ ∧□md(ϕ)+1⊥is complete for K.
⊓⊔
6.5
More Logics
There is more to Modal Logic— and more modal logics,— so, perhaps, there is
also more to discover about the completeness problem. We based the decision
procedure for the completeness problem for each logic on a decision procedure for
satisﬁability. We distinguished two cases, depending on the logic’s satisﬁability-
testing procedures.
– If the logic has axiom 5, then to test satisﬁability we guess a small model and
we use model checking to verify that the model satisﬁes the formula. This
procedure uses the small model property of these logics (Corollary 1). To
test for completeness, we guess two small models; we verify that they satisfy
the formula and that they are non-bisimilar. We could try to use a similar
approach for another logic based on a decision procedure for satisﬁability
based on a small model property (for, perhaps, another meaning for “small”).
To do so successfully, a small model property may not suﬃce. We need to ﬁrst
demonstrate that for this logic, a formula that is satisﬁable and incomplete
has two small non-bisimilar models.

20
A. Achilleos
– For the other logics, we can use a tableau to test for satisﬁability. We were able
to combine the tableaux for these logics with bisimulation games to provide
an optimal — when the completeness problem is not trivial — procedure
for testing for completeness. For logics where a tableau gives an optimal
procedure for testing for satisﬁability, this is, perhaps, a promising approach
to also test for completeness.
Another direction of interest would be to consider axiom schemes as part of
the input — as we have seen, axiom 5 together with ϕS5 is complete for T, when
no modal formula is.
Acknowledgments. The author is grateful to Luca Aceto for valuable comments that
helped improve the quality of this paper.
References
1. Ladner, R.E.: The computational complexity of provability in systems of modal
propositional logic. SIAM J. Comput. 6(3), 467–480 (1977)
2. Halpern, J.Y., Rˆego, L.C.: Characterizing the NP-PSPACE gap in the satisﬁability
problem for modal logic. J. Logic Comput. 17(4), 795–806 (2007)
3. Halpern, J.Y., Moses, Y.: A guide to completeness and complexity for modal logics
of knowledge and belief. Artif. Intell. 54(3), 319–379 (1992)
4. Artemov, S.: Syntactic epistemic logic. In: Book of Abstracts, 15th Congress of
Logic, Methodology and Philosophy of Science CLMPS 2015, pp. 109–110 (2015)
5. Artemov, S.: Syntactic epistemic logic and games (2016)
6. Hennessy, M., Milner, R.: Algebraic laws for nondeterminism and concurrency. J.
ACM (JACM) 32(1), 137–161 (1985)
7. Milner, R.: Communication and Concurrency. Prentice-Hall Inc., Upper Saddle
River (1989)
8. Graf, S., Sifakis, J.: A modal characterization of observational congruence on ﬁnite
terms of CCS. Inf. Control 68(1–3), 125–145 (1986)
9. Steﬀen, B., Ing´olfsd´ottir, A.: Characteristic formulas for processes with divergence.
Inf. Comput. 110(1), 149–163 (1994)
10. Mller-Olm, M.: Derivation of characteristic formulae. Electr. Notes Theor. Comput.
Sci. 18, 159–170 (1998)
11. Aceto, L., Della Monica, D., F´abregas, I., Ing´olfsd´ottir, A.: When are prime formu-
lae characteristic? In: Italiano, G.F., Pighizzini, G., Sannella, D.T. (eds.) MFCS
2015. LNCS, vol. 9234, pp. 76–88. Springer, Heidelberg (2015). https://doi.org/10.
1007/978-3-662-48057-1 6
12. Fine, K.: Normal forms in modal logic. Notre Dame J. Formal Logic 16(2), 229–237
(1975)
13. Achilleos, A.: The completeness problem for modal logic. CoRR abs/1605.01004
(2016)
14. Blackburn, P., de Rijke, M., Venema, Y.: Modal Logic. Cambridge Tracts in The-
oretical Computer Science. Cambridge University Press, Cambridge (2001)
15. Chagrov, A., Zakharyaschev, M.: Modal Logic. Oxford University Press, Oxford
(1997)
16. Paige, R., Tarjan, R.E.: Three partition reﬁnement algorithms. SIAM J. Comput.
16(6), 973–989 (1987)

The Completeness Problem for Modal Logic
21
17. Fitting, M.: Tableau methods of proof for modal logics. Notre Dame J. Formal
Logic 13(2), 237–247 (1972)
18. Massacci, F.: Single step tableaux for modal logics. J. Autom. Reasoning 24(3),
319–364 (2000)
19. D’Agostino, M., Gabbay, D.M., H¨ahnle, R., Posegga, J.: Handbook of Tableau
Methods. Springer, Dordrecht (1999). https://doi.org/10.1007/978-94-017-1754-0
20. Blass, A., Gurevich, Y.: On the unique satisﬁability problem. Inf. Control 55(1–3),
80–88 (1982)
21. Moss, L.S.: Finite models constructed from canonical formulas. J. Philos. Logic
36(6), 605–640 (2007)

Justiﬁcation Awareness Models
Sergei Artemov(B)
The City University of New York, The Graduate Center,
365 Fifth Avenue, New York City, NY 10016, USA
sartemov@gc.cuny.edu
Abstract. Justiﬁcation Awareness Models, JAM s, incorporate two
principal ideas: (i) justiﬁcations are prime objects of the model: knowl-
edge and belief are deﬁned evidence-based concepts; (ii) awareness
restrictions are applied to justiﬁcations rather than to propositions,
which allows for the maintaining of desirable closure properties. JAM s
naturally include major justiﬁcation models, Kripke models and, in addi-
tion, represent situations with multiple possibly fallible justiﬁcations. As
an example, we build a JAM for Russell’s well-known Prime Minister
scenario which, in full generality, was previously oﬀthe scope of rigorous
epistemic modeling.
Keywords: Modal logic · Justiﬁcation logic · Epistemology
Knowledge · Belief
1
Context and Motivations
Proof systems of justiﬁcation logic and general purpose classes of models for these
systems have been studied in [1–3,9,10,16,18,20] and many other sources. How-
ever, for formalizing epistemic scenarios, one needs speciﬁc domain-dependent
models with additional features that are not necessary for standard soundness
and completeness analysis of proof systems.
Awareness is an important concept in epistemic modeling, but, when applied
to propositions directly, it may seriously diverge from the intuition due to
lack of natural closure properties [7,8,17]. We suggest applying awareness to
justiﬁcations
agent is aware/unaware of a justification t for a proposition F
rather then to propositions “agent is aware/unaware of a proposition F”; this
approach allows for the maintaining of natural closure properties.
We introduce justiﬁcation awareness models, JAMs, in which justiﬁcations
are primary objects and a distinction is made between accepted and knowledge-
producing justiﬁcations. In JAM s, belief and knowledge are derived notions
which depend on the status of supporting justiﬁcations. We argue that JAMs can
work in situations in which standard non-hyperintensional tools (Kripke, topo-
logical, algebraic) fail to fairly represent the corresponding epistemic structure.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 22–36, 2018.
https://doi.org/10.1007/978-3-319-72056-2_2

Justiﬁcation Awareness Models
23
2
Preliminaries
Standard modal epistemic models have “propositional” precision, i.e., they do
not distinguish sentences with the same truth values at each possible world. The
expressive power of such models for analysis of justiﬁcation, belief, and knowl-
edge is rather limited, and so we have to “go hyperintensional.”1 Speciﬁcally, if,
at all possible worlds, t is a justiﬁcation for F
⊩t:F,
and G has the same truth value as F
⊩F ↔G,
we still cannot conclude that t is a justiﬁcation for G
̸⊩t:G.
A natural example from mathematics: both statements 0 = 0 and Fermat’s Last
Theorem, FLT, are true (proven) mathematical facts and hence are true at all
possible worlds. However, we cannot claim that a proof of 0 = 0 is a proof of
FLT as well.
A sample justiﬁcation logic analysis of some standard epistemic situations
(Gettier examples, Red Barn example) is presented in [2] using justiﬁcation
Fitting models [9] though, due to the relative simplicity of those examples, this
analysis could be replicated in a bi-modal language (cf. [21]).
However, we cannot go much farther without adopting a justiﬁcation frame-
work: the situation changes when we have to represent several conﬂicting pieces
of evidence for a stated fact, cf. the following Russell example of 1912 ([19]):
If a man believes that the late Prime Minister’s last name began with a
‘B,’ he believes what is true, since the late Prime Minister was Sir Henry
Campbell Bannerman2. But if he believes that Mr. Balfour was the late
Prime Minister, he will still believe that the late Prime Minister’s last
name began with a ‘B,’ yet this belief, though true, would not be thought
to constitute knowledge.
To keep it simple, we consider proposition Q
the late Prime Minister’s last name began with a ‘B,’
with two justiﬁcations for Q: the right one r and the wrong one w; the agent
chooses w as a reason to believe that Q holds.
To avoid a misleading reduction of failures of justiﬁcations to “false
premises,” consider another Russell example from [19].
1 From [6]: “Hyperintensional contexts are simply contexts which do not respect logical
equivalence”.
2 Which was true in 1912.

24
S. Artemov
If I know that all Greeks are men and that Socrates was a man, and I infer
that Socrates was a Greek, I cannot be said to-know-that Socrates was a
Greek, because, although my premisses and my conclusion are true, the
conclusion does not follow from the premisses.
This Russell’s example illustrates that “false premises” in the Prime Minis-
ter story is an instance of a more general phenomenon: an erroneous justiﬁca-
tion which, in principle, can fail for many diﬀerent reasons: unreliable premises,
hidden assumptions, deduction errors, an erroneous identiﬁcation of the goal
sentence, etc.3
There is a mathematical version of the story with a true proposition and its
two justiﬁcations; one is correct, the other is not.
Consider the picture4:
1̸6
̸64 = 1
4.
(1)
The true proposition is “16/64 = 1/4,” the right justiﬁcation is dividing
both the numerator and the denominator by 16, and the wrong (but shorter
and more attractive) justiﬁcation is simplifying as in (1).
Given these considerations, we prefer speaking about erroneous justiﬁcations
in a general setting without reducing them to propositional entities such as “false
premises.” To be speciﬁc, we’ll continue with Russell’s Prime Minister example.
To formalize Russell’s scenario in modal logic (cf. [21]), we introduce two
modalities: K for knowledge and J for justiﬁed belief. In the real world,
– Q holds;
– JQ holds, since the agent has a justiﬁcation w for Q;
– KQ does not hold;
thus yielding the set of assumptions
Γ = {Q, JQ ¬KQ}.
However, Γ doesn’t do justice to Russell’s scenario: the right justiﬁcation r
is not represented and Γ rather corresponds to the same scenario but lacking r.
The epistemic structure of the example is not respected.
Within the JAM framework, we provide a model for Russell’s Prime Min-
ister example which, we wish to think, fairly represents its intrinsic epistemic
structure.
3 Moreover, one can easily imagine knowledge-producing reasoning from a source with
false beliefs (both an atheist and a religious scientist can produce reliable knowledge
products though one of them has false beliefs), so “false premises” are neither nec-
essary nor suﬃcient for a justiﬁcation to fail.
4 Which the author saw on the door of the Mathematics Support Center at Cornell
in 2017.

Justiﬁcation Awareness Models
25
3
Generic Logical Semantics of Justiﬁcations
What kinds of logical objects are justiﬁcations? When asked in a mathematical
context “what is a predicate?” we have a ready answer: a subset of a Cartesian
product of the domain set. Within an exact mathematical theory, there should
be a similar kind of answer to the question “what is a justiﬁcation?”
We consider this question in its full generality which, surprisingly, yields
a clean and meaningful answer. We assume the language of justiﬁcation logic
consists of two disjoint sets of syntactic objects:
1. a set of justiﬁcation terms Tm;
2. a set of formulas Fm, built inductively from propositional atoms using
Boolean connectives and the justiﬁcation formula formation rule: if F is a
formula, F ∈Fm, and t a justiﬁcation term, t ∈Tm, then t:F is again a
formula, t:F ∈Fm.
The meaning assigned to formulas is a classical truth value, 0 for false and
1 for true, and we retain classical logic behavior for propositional connectives.
The key item is to give meaning to justiﬁcation terms, and this will be a set
of formulas interpreted as the set of formulas for which it is a justiﬁcation. A
formal deﬁnition follows.
Deﬁnition 1 (Basic Model). A basic model, simply called ∗, consists of an
interpretation of the members of Fm, and an interpretation of the members of
Tm.
The interpretation of a formula in a basic model is a truth value. That is,
∗: Fm →{0, 1}.
We assume the Boolean truth tables: (X →Y )∗= 1 if and only if X∗= 0 or
Y ∗= 1, etc. Let also |=∗X stand for X∗= 1.
We interpret justiﬁcation terms as sets of formulas. That is,
∗: Tm →2Fm.
Our ﬁnal requirement connects the two mapping roles that ∗plays in a basic
model. For any X ∈Fm and any t ∈Tm,
|=∗t:X if and only if X ∈t∗.
It is easy to check that any mapping ∗from propositional letters to truth
values, and from justiﬁcation terms to sets of formulas, determines a unique
basic model.
So far, a basic model is merely a classical propositional model in which jus-
tiﬁcation assertions t:F are treated as independent propositional atoms.
Note that while propositions are interpreted semantically as truth values,
justiﬁcations are interpreted syntactically as sets of formulas. This is a principal
hyperintensional feature: a basic model may treat distinct formulas F and G as
equal, i.e. F ∗= G∗, but still be able to distinguish justiﬁcation assertions t:F
and t:G, e.g., when F ∈t∗, but G ̸∈t∗yielding |=∗t:F but ̸|=∗t:G.

26
S. Artemov
Deﬁnition 2. Let S a set of formulas, S ⊆Fm, and X be a formula, X ∈Fm.
We write S ⊢X if X is derivable from S in classical logic that treats justiﬁcation
assertions t:F as propositional atoms (with Modus Ponens as the only rule of
inference). We say that S is consistent if S ̸⊢⊥.
A basic model of S is merely a possible world containing S in the canonical model,
i.e., a maximal consistent set Γ of formulas, with the convenience agreement
reading t:F ∈Γ as F ∈{X | t:X ∈Γ}. In this respect, basic models and the
canonical model are slightly diﬀerent but obviously equivalent ways of presenting
the same object. When we move to more sophisticated models (Fitting models,
modular models), the advantage of dealing with sets and operations (e.g. basic
models) over logical conditions (e.g. the canonical model) becomes clear.
Deﬁnition 3. For S ⊆Fm, BM(S) is the class of all basic models of S.
Theorem 1. Each set of formulas S is sound and complete with respect to its
class of basic models BM (S). In other words, S ⊢F iﬀF is true in each basic
model of S.
Proof. This theorem is merely a reformulation of the soundness and completeness
of classical propositional logic with hypotheses. Indeed, if S ⊢F and |=∗S, then
|=∗F since propositional derivations respect validity.
If S ̸⊢F, then there is a Boolean evaluation ∗which makes all formulas from
S true, S∗= 1, and F false, F ∗= 0. In this case, there are two types of atomic
propositions: propositional letters P and justiﬁcation assertions t:X. Deﬁne
t∗= {X | (t:X)∗= 1}
and note that (t:X)∗= 1 iﬀX ∈t∗. Therefore, ∗is a propositional evaluation
and ∗is a basic model yielding the same truth values of atomic formulas P and
t:X. Since S∗= 1 and F ∗= 0, we have |=∗S and ̸|=∗F for basic model ∗.
An easy corollary: ⊢F iﬀF is a tautology (with t:Xes as distinct proposi-
tional atoms).
Example 1. In Deﬁnition 2, take S = ∅.
1. For any justiﬁcation term t,
̸⊢t:F.
Straightforward, since t : F is not a propositional tautology. For a speciﬁc
countermodel, deﬁne t∗= ∅for each term t ∈Tm, which makes ̸|=∗t:F.
2. For any propositional letter P, and term t,
̸⊢t:P →P.
Likewise, this holds because t:P →P is not a propositional tautology. Specif-
ically, put t∗= Fm and P ∗= 0, with other assignments being arbitrary. In
this model, all justiﬁcation assertions are true, but t:P →P is false.

Justiﬁcation Awareness Models
27
3. For any propositional letter P, and term t,
̸⊢P →t:P.
Again, this holds since P →t:P is not a propositional tautology. For example,
put t∗= ∅and P ∗= 1. In this model, t is not a justiﬁcation for P (i.e.,
̸|=∗t:P) and P →t:P is false.
4. A somewhat less trivial example illustrating hyperintensionality: for a justi-
ﬁcation variable x and formula F
̸⊢x:F →x:(F ∧F).
A high-level argument is the same: formulas x:F and x:(F ∧F), evaluated from
a Boolean point of view, can be regarded as distinct propositional variables.
Hence x:F →x:(F ∧F) is not a tautology. For a countermodel, take x∗= {F}.
Then |=∗x:F, but ̸|=∗x:(F ∧F). This demonstrates hyperintensionality of a
justiﬁcation logic base, since F and F ∧F are provably equivalent, but not
x:F and x:(F ∧F).
4
Basic Justiﬁcation Logic J−
Within the Justiﬁcation Logic framework, there are two sorts of logical objects:
justiﬁcation terms Tm and formulas Fm. Let us become more speciﬁc about
both.
– For Tm, reserve a set of justiﬁcation constants a, b, c, . . . with indices, and
variables x, y, z, . . . with indices. Justiﬁcation terms are built from constants
and variables by a binary operation · (application).
– Formulas are built from propositional letters p, q, r, . . . (with indices) and
Boolean constant ⊥(falsum) by the standard Boolean connectives ∧, ∨,→, ¬
with a new formation rule: whenever t is a justiﬁcation term and F is a
formula, t : F is a formula (with the informal reading “t is a justiﬁcation
for F”). For better readability, we will interchangeably use brackets 0, 0 and
parentheses (, ). Our preferred notation is [s · t]:(F →G) which is the same as
(s · t):(F →G).
The logical system J−consists of two groups of postulates.
– Background logic: axioms of classical propositional logic, rule Modus
Ponens.
– Application: s:(F →G)→(t:F →[s·t]:G).
Basic models corresponding to J−are those in which the application axiom holds.
They can be speciﬁed by a natural combinatorial condition.
Deﬁnition 4. For sets of formulas S and T, we deﬁne
S ▷T = {F | G→F ∈S and G ∈T for some G}.
Informally, S ▷T is the result of applying Modus Ponens once to all members of
S and of T (in a given order).

28
S. Artemov
Theorem 2. BM (J−) is the class of basic models with the following closure
condition
s∗▷t∗⊆[s·t]∗.
(2)
Proof. Let us assume the closure condition (2) and check the validity of the
application axiom. Indeed, |=∗s:(F →G) and |=∗t:F yield (F →G) ∈s∗and
F ∈t∗. By the closure condition, G ∈[s·t]∗, i.e., |=∗[s·t]:G.
Now assume the application axiom and derive the closure condition (2). Let
(F →G) ∈s∗and F ∈t∗. By deﬁnition, this yields |=∗s:(F →G) and |=∗t:F.
By the application axiom, |=∗[s·t]:G, hence G ∈[s·t]∗.
Example 2. None of the formulas from Example 1: t:F, t:P →P, P →t:P,
x : F →x : (F ∧F) is derivable in J−. Indeed, every speciﬁc evaluation from
Example 1.1–3 satisﬁes the closure condition (2), hence their countermodels are
J−-models. Consider the latter formula 4. Put x∗= {F} and t∗= Fm for all
other terms t. The closure condition (2) holds vacuously, hence ∗is a J−-model.
Obviously, |=∗x:F and ̸|=∗x:(F ∧F).
Constants in justiﬁcation logic are used to denote justiﬁcations of assump-
tions, in particular, axioms. Indeed, as we have already seen in Example 2, no
formula t:F is derivable in J−. In particular, no logical axiom is assumed justiﬁed
in J−which is not realistic.
Deﬁnition 5. A set X of formulas is reﬂexive if for each s:t:F ∈X, t:F is also
in X. By constant speciﬁcation CS we understand a reﬂexive set of formulas of
the type
cn:cn−1:cn−2: . . . c1:A
where A is a J−-axiom and ci are justiﬁcation constants. The major classes of
constant speciﬁcations are empty, total— (each constant is a justiﬁcation for
each axiom), axiomatically appropriate (each axiom has a justiﬁcation at any
depth).
Let CS be a constant speciﬁcation. Then by J−(CS), we understand J−with
additional axioms CS. A CS-model is a model in which all formulas from CS
hold.
Corollary 1. Basic models for J−(CS) are the basic CS-models for J−. J−(CS)
is sound and complete with respect to the class of its basic models.
4.1
Other Justiﬁcation Logics
There is a whole family of justiﬁcation logics and they all extend J−; the reader
is referred to [2,11] for details. Here we list just the main systems of justiﬁcation
logic for purposes of general orientation.
Logic J is obtained from J−by adding a new operation on justiﬁcations ‘+’
and the principle
s:F ∨t:F →[s + t]:F.

Justiﬁcation Awareness Models
29
Logics JD, JT, J4, J5, etc., are obtained by adding the corresponding combination
of principles
D = ¬t:⊥,
T = t:F →F,
4 = t:F →!t:t:F,
5 = ¬t:F →?t:¬t:F.
The family of justiﬁcation logics has now grown to be inﬁnite, cf. [11].
4.2
Sharp Models
In closure condition (2) from Theorem 2, one cannot, generally speaking, replace
the inclusion “⊆” by the equality “=” without violating completeness Theorem 1.
Indeed, ﬁx a justiﬁcation constant 0 and consider logic
L = J−+ {¬0:F | F ∈Fm}.
Informally, justiﬁcation 0 receives empty evaluation in any basic model, 0∗= ∅.
We claim that formula G = ¬[0·0]:P is not derivable in L, but is true in any
basic model of L with the closure condition s∗▷t∗= [s·t]∗. To show that L ̸⊢G,
it suﬃces to ﬁnd a basic model for L in which G is false. Consider a basic model
♯such that 0♯= ∅and t♯= Fm for any other justiﬁcation term t. Obviously,
the closure condition from Theorem 2, together with 0♯= ∅, is met. Therefore,
♯is a basic model of L. It is immediate that G is false in ♯, since [0·0]♯= Fm.
On the other hand, G holds in any basic model of L with the closure condition
[0·0]∗= 0∗▷0∗. Indeed, in such a model, [0·0]∗= ∅since 0∗= ∅and ∅▷∅= ∅.
Deﬁnition 6. Sharp basic models are those in which the application closure
condition has the form
[s·t]∗= s∗▷t∗.
(3)
Note that a sharp model is completely deﬁned by evaluations of atomic propo-
sitions and atomic justiﬁcations.
5
Justiﬁcation Awareness
We need more expressive power to capture epistemic diﬀerences between jus-
tiﬁcations and their use by the knower. Some justiﬁcations are knowledge-
producing, some are not. The agent makes choices on which justiﬁcations to base
an agent’s beliefs/knowledge and which justiﬁcations to ignore in this respect.
These actions are present in epistemic scenarios, from which we will primarily
focus on Russell’s Prime Minister example, which has them all:
– there are justiﬁcations w (Balfour was the late prime minister) and r
(Bannerman was the late prime minister) for Q;
– r is knowledge-producing whereas w is not;
– the agent opts to base his belief on w and ignores r;
– the resulting belief is evidence-based, but is not knowledge.

30
S. Artemov
5.1
Justiﬁcation Awareness Models
Fix J−(CS) for some axiomatically appropriate constant speciﬁcation CS.
Deﬁnition 7. A set X of justiﬁcation terms is properly closed if X contains all
constants and is closed under applications. If X is a set of justiﬁcation terms,
then by X we mean the proper closure of X, i.e., the minimal properly closed
superset of X.
Deﬁnition 8. A (basic) Justiﬁcation Awareness Model is (∗, A, E) where
– ∗is a basic J−(CS)-model;
– A ⊆Tm is a properly closed set A of accepted justiﬁcations;
– E ⊆Tm is a properly closed set E of knowledge-producing justiﬁcations.
Unless stated otherwise, we also assume consistency of accepted justiﬁcations:
|=∗¬t : ⊥for any t ∈A, and factivity of knowledge-producing justiﬁcations,
|=∗t:F →F for each F and each t ∈E. In models concerning beliefs rather then
knowledge, the component E can be dropped.
Both sets A and E contain all constants. This deﬁnition presumes that con-
stants in a model are knowledge-producing and accepted.
Deﬁnition 9. In a JAM (∗, A, E), a sentence F is believed if there is t ∈A
such that |=∗t:F. Sentence F is known if there is t ∈A ∩E such that |=∗t:F.
By ground term we understand a term containing no (justiﬁcation) variables.
In other words, a term is ground iﬀit is built from justiﬁcation constants only.
Sets of accepted and knowledge-producing justiﬁcations overlap on ground
terms but otherwise can be in a general position5. There may be accepted,
but not knowledge-producing, justiﬁcations and vice versa. So, JAM s do not
analyze why certain justiﬁcations are knowledge-producing or accepted, but
rather provide a formal framework that accommodates these notions.
5.2
Single-Conclusion Justiﬁcations
The notions of accepted and knowledge-producing justiﬁcations should be utilized
with some caution. Imagine a justiﬁcation t for F (i.e., t:F holds) and for G (t:G)
such that, intuitively, t is a knowledge-producing justiﬁcation for F but not for
G. Is such a t knowledge-producing, trustworthy, acceptable for a reasonable
agent? The answers to these questions seem to depend on F and G, and if we
prefer to handle justiﬁcations as objects rather than as justiﬁcation assertions, it
is technically convenient to assume that justiﬁcations are single-conclusion (or,
equivalently, pointed):
there is at most one formula F such that t:F holds.
5 In principle, one could consider smaller sets A, which would correspond to the high
level of skepticism of an agent who does not necessarily accept logical truths (axioms)
as justiﬁed. We leave this possibility for further studies.

Justiﬁcation Awareness Models
31
Conceptually, by turning to pointed justiﬁcations, one does not lose generality:
if p is a proof of F and of something else, then the same p with a designated
statement F, symbolically, a pair (p, F), can be regarded as a single-conclusion
(or pointed) proof of F.
In model R for the Russell Prime Minister example, Sect. 6, all justiﬁcations
are pointed.
Note that J−is not complete with respect to the class of basic models which
are both sharp and pointed (as model R for the Russell Example). Indeed,
consider formula F,
F = ¬(x:(P →Q) ∧y:P ∧[x·y]:R)
where P, Q, R are distinct propositional letters and x, y justiﬁcation variables.
Obviously, F holds in any basic model ∗which is sharp and pointed. Imagine a
sharp pointed ∗in which x:(P →Q) and y:P hold. In such ∗, [x·y]∗= {Q}, hence
both ¬[x·y]:R, and F hold. On the other hand, F is not derivable in J−, e.g.,
F fails in the basic model ∗with x∗= {P →Q}, y∗= {P}, and t∗= Fm for
any other t (check closure condition (2)!). So, “sharp and pointed” justiﬁcation
tautologies constitute a proper extension SP of J−. The problem of ﬁnding com-
plete axiomatization of SP was ﬁrst stated in [5]. This question was answered
in [15] along the lines of studying single-conclusion logic of proofs [13,14].
6
Russell Scenario as a JAM
Consider the version of J−in a language with two justiﬁcation variables w and r,
one propositional letter Q, and pointed constant speciﬁcation CS:
cn:A ∈CS iﬀA is an axiom and n is the G¨odel number of A.
Deﬁne a model ∗such that
– Q∗= 1, i.e., |=∗Q;
– c∗
n = {A} if A is an axiom and n is the G¨odel number |A| of A, and c∗
n = ∅
otherwise;
– w∗= r∗= {Q}, e.g., |=∗r:Q and ̸|=∗r:F for any F other than Q (the same
for w);
– application is sharp: [s·t]∗= s∗▷t∗.
A JAM R (for Russell’s scenario) is (∗, A, E) with
– A = {w}, i.e., the set of accepted justiﬁcations is {w}, properly closed;
– E = {r}, i.e., the set of knowledge-producing justiﬁcations is {r}, properly
closed.
Though the idea behind R is quite intuitive, we need to ﬁll in some techni-
cal details: extending truth evaluations to all terms and formulas and checking
closure conditions.

32
S. Artemov
6.1
Technicalities of the Model
Deﬁne c∗
|A| = {A} for each axiom A of J−(CS). Technically, this is an inductive
deﬁnition with induction on n in cn.
Base: n = 0. Here c∗
0 = ∅, given 0 is not a G¨odel number of any formula.
Inductive step: suppose n is the G¨odel number |F| of some formula F. If F
is an axiom of J−, put c∗
n = {F}. If F = ck :G for some ck and G, then, by
monotonicity of G¨odel numbering, k < n, hence c∗
k is deﬁned. If c∗
k = {G}, then
ck :G is an axiom of J−(CS) and we can deﬁne c∗
n = {F}. In all other cases,
c∗
n = ∅.
Since application is sharp, the evaluation of each term is, at most, a single-
ton. Together with Boolean truth tables, this determines the truth value of any
formula.
Lemma 1. Each t ∈Tm is factive, |=∗t:F →F.
Proof. Induction on t. Assume |=∗t:F; that means t∗= {F}. If t is w or r, then
F is Q, which is true in the model ∗. If t is a constant, then F is an axiom and
hence true in ∗. The induction step corresponds to application, which preserves
the truth of justiﬁed formulas.
It follows from Lemma 1, that accepted justiﬁcations are consistent and
knowledge-producing justiﬁcations are factive. Therefore, R = (∗, A, E) is indeed
a JAM.
Theorem 3. In model R, sentence Q is true, justiﬁed and believed, but not
known.
Proof. In model R, sentence Q is
– true, since |=∗Q;
– justiﬁed, since |=∗w:Q;
– believed, since w ∈A.
We have to show that Q is not known, i.e., for any justiﬁcation g ∈A ∩E,
̸|=∗g:Q.
Consider an auxiliary basic model • which is the same as ∗but with Q• = 0,
i.e., the truth value of Q is ﬂipped from ‘true’ to ‘false.’ In particular, application
in • is sharp.
Lemma 2. For each justiﬁcation term t,
t∗= t•.
Proof. The inductive process (based on sharp application) of evaluating all justi-
ﬁcations, given evaluations of atomic justiﬁcations, operates only with formulas
of type t:F and starts with the same initial set of such formulas in ∗and •.
Hence the results of these processes in ∗and • coincide.

Justiﬁcation Awareness Models
33
In particular, for all g ∈A ∩E, g∗= g•, and if |=∗g:Q, then |=• g:Q as well.
Lemma 3. Each g ∈A ∩E is factive in •, i.e., |=• g:F →F.
Proof. All g ∈A∩E are obtained from constants by application. By construction,
if |=• c:X, then X ∈c∗and X is an axiom, hence true. Application obviously
preserves factivity.
To complete the proof of Theorem 3, suppose R |= g:Q, i.e., |=∗g:Q, for
some g ∈A ∩E. By Lemma 2, |=• g:Q, and, by Lemma 1, |=• Q, which is not
the case.
6.2
Can Russell’s Scenario Be Made Modal?
One could try to express Russell’s scenario in a modal language by introducing
the justiﬁed belief modality
JF
⇔
there is t ∈A such that |= t:F,
and the knowledge-producing modality
EF
⇔
there is t ∈E such that |= t:F,
and by stipulating that F is known iﬀF is both accepted and supported by a
knowledge-producing justiﬁcation:
KF
⇔
JF ∧EF.
This, however, fails, since both JQ and EQ hold in R, but KQ does not. We
are facing a Gettier-style phenomenon (cf. [12]), when a proposition is supported
by a knowledge-producing justiﬁcation (hence true), and believed, but not known
(since knowledge-producing and accepted justiﬁcations for Q are diﬀerent). This
once again illustrates the limitations of modal language in tracking and sorting
justiﬁcations.
7
Kripke Models and Master Justiﬁcation
From the Justiﬁcation Logic point of view, Kripke models may be regarded as a
special case of multi-world JAM s6; the Kripkean accessibility relation between
worlds, uRv, can be recovered by the usual rule what is believed at u, holds at v.
Moreover, such representation of Kripke models as justiﬁcation models reveals
and formalizes the observation made in [4] that epistemic reading of Kripke
models relies on a hidden assumption of (common) knowledge of the model.
The informal argument is as follows. We have to ﬁnd a justiﬁcation m:F for
each knowledge/belief assertion □F in a model K. We claim that the model K
itself is such a justiﬁcation. Indeed, let u⊩□F in K. Then a complete description
6 In which we suppress the knowledge-producing component E to capture beliefs.

34
S. Artemov
of K yields that at state u, the agent knows/believes F because the agent
knows the model K and knows that F holds at all possible worlds. So,
the knowledge/belief-producing evidence for F is delivered by K itself, assuming
the agent is aware of K.
Syntactically, we consider a very basic justiﬁcation language in which the
set of justiﬁcation terms consists of just one term m, called master justiﬁcation.
Think of m as representing a complete description of model K = (W, R,⊩).
Speciﬁcally, we extend the truth evaluation in K to justiﬁcation assertions by
stipulating at each u ∈W
K, u⊩m:X
iﬀ
K, v⊩X for any v ∈R(u)
iﬀ
K, u⊩□X.
This reading provides a meaningful justiﬁcation semantics of epistemic assertions
in K via the master justiﬁcation m representing the whole K. Since a Kripkean
agent is logically omniscient, along with K, the agent knows all its logical con-
sequences. Technically, we can assume that the description K is closed under
logical consequence and hence m is idempotent w.r.t. application, m · m = m.
This condition manifests itself in a special form of the application principle
m:(A→B)→(m:A→m:B).
On the technical side, a switch from □X to m:X is a mere transliteration
which does not change the epistemic structure of a model. Finally, for each
u ∈W, we deﬁne a basic model – maximal consistent set Γu in the propositional
language with Tm = {m}:
Γu = {X | u⊩X}.
So, from a justiﬁcation perspective, a Kripke model is a collection of basic models
with master justiﬁcation that represents (common) knowledge of the model.
8
Discussion
Comparisons of justiﬁcation awareness models with other justiﬁcation epistemic
structures such as Fitting, Mkrtychev, and modular models, can be found in [5].
Technically, basic models and Mkrtychev models may be regarded as special
cases of Fitting models. On the other hand, Fitting models can be identiﬁed
as modular models with additional assumptions, cf. [3]. This provides a natural
hierarchy of the aforementioned classes of models:
basic and Mkrtychev models
⊂
Fitting models
⊂
modular models
⊂
JAMs.
Even the smallest class, basic models, is already suﬃcient for mathematical
completeness of justiﬁcation logics. So, the main idea of progressing to Fitting
models, modular models, or JAM s is not a pursuit of completeness but rather
a desire to oﬀer natural models for a variety of epistemic situations involving
evidence, belief, and knowledge.

Justiﬁcation Awareness Models
35
JAM s do not oﬀer a complete self-contained analysis of knowledge but rather
reduce knowledge to knowledge-producing justiﬁcations accepted by the agent.
This, however, constitutes a meaningful progress; it decomposes knowledge in
a way that moves justiﬁcation objects to the forefront of epistemic modeling.
Note that Gettier and Russell examples, clearly indicate which justiﬁcations are
knowledge-producing or accepted. So JAM s fairly model situations in which the
corresponding properties of justiﬁcations (knowledge-producing, accepted) are
given.
There are many natural open questions that indicate possible research direc-
tions. Are justiﬁcation assertions checkable, decidable for an agent? Is the prop-
erty of a justiﬁcation to be knowledge-producing checkable by the agent? In
multi-agent cases, how much do agents know about each other and about the
model? Do agents know each other’s accepted and knowledge-producing justiﬁ-
cations? What is the complexity of these new justiﬁcation logics and what are
their feasible fragments which make sense for epistemic modeling?
Acknowledgements. The author is grateful to Melvin Fitting, Vladimir Krupski,
Elena Nogina, and Tudor Protopopescu for helpful suggestions. Special thanks to Karen
Kletter for editing and proofreading this text.
References
1. Artemov, S.: Explicit provability and constructive semantics. Bull. Symbolic Logic
7(1), 1–36 (2001)
2. Artemov, S.: The logic of justiﬁcation. Rev. Symbolic Logic 1(4), 477–513 (2008)
3. Artemov, S.: The ontology of justiﬁcations in the logical setting. Stud. Logica.
100(1–2), 17–30 (2012)
4. Artemov, S.: Knowing the model. Published online at: arXiv:1610.04955 [math.LO]
(2016)
5. Artemov,
S.:
Epistemic
modeling
with
justiﬁcations.
Published
online
at:
arXiv:1703.07028 [math.LO] (2017)
6. Cresswell, M.J.: Hyperintensional logic. Stud. Logica. 34(1), 25–38 (1975)
7. Fagin, R., Halpern, J.: Belief, awareness, and limited reasoning. Artif. Intell. 34(1),
39–76 (1988)
8. Fagin, R., Halpern, J., Moses, Y., Vardi, M.: Reasoning About Knowledge. MIT
Press, Cambridge (1995)
9. Fitting, M.: The logic of proofs, semantically. Ann. Pure Appl. Logic 132(1), 1–25
(2005)
10. Fitting, M.: Possible world semantics for ﬁrst-order logic of proofs. Ann. Pure Appl.
Logic 165(1), 225–240 (2014)
11. Fitting, M.: Modal logics, justiﬁcation logics, and realization. Ann. Pure Appl.
Logic 167(8), 615–648 (2016)
12. Gettier, E.: Is justiﬁed true belief knowledge? Analysis 23, 121–123 (1963)
13. Krupski, V.N.: Operational logic of proofs with functionality condition on proof
predicate. In: Adian, S., Nerode, A. (eds.) LFCS 1997. LNCS, vol. 1234, pp. 167–
177. Springer, Heidelberg (1997). https://doi.org/10.1007/3-540-63045-7 18
14. Krupski, V.: The single-conclusion proof logic and inference rules speciﬁcation.
Ann. Pure Appl. Logic 113(1), 181–206 (2002)

36
S. Artemov
15. Krupski, V.: On the sharpness and the single-conclusion property of basic justiﬁ-
cation models. In: Artemov, S., Nerode, A. (eds.) LFCS 2018. LNCS, vol. 10703,
pp. 211–220. Springer, Cham (2018)
16. Kuznets, R., Struder, T.: Justiﬁcations, ontology, and conservativity. In: Bolander,
T., Bra¨uner, T., Ghilardi, S., Moss, L. (eds.) Advances in Modal Logic, vol. 9, pp.
437–458. College Publications, London (2012)
17. Meyer, J.-J.C., van der Hoek, W.: Epistemic Logic for AI and Computer Science.
CUP, Cambridge (1995)
18. Mkrtychev, A.: Models for the logic of proofs. In: Adian, S., Nerode, A. (eds.)
LFCS 1997. LNCS, vol. 1234, pp. 266–275. Springer, Heidelberg (1997). https://
doi.org/10.1007/3-540-63045-7 27
19. Russell, B.: The Problems of Philosophy. Williams and Norgate, London (1912)
20. Sedl´ar, I.: Justiﬁcations, awareness and epistemic dynamics. In: Artemov, S.,
Nerode, A. (eds.) LFCS 2013. LNCS, vol. 7734, pp. 307–318. Springer, Heidelberg
(2013). https://doi.org/10.1007/978-3-642-35722-0 22
21. Williamson, T.: A note on Gettier cases in epistemic logic. Philos. Stud. 172(1),
129–140 (2015)

A Minimal Computational Theory of a Minimal
Computational Universe
Arnon Avron1 and Liron Cohen2(B)
1 Tel Aviv University, Tel-Aviv, Israel
aa@post.tau.ac.il
2 Cornell University, Ithaca, NY, USA
lironcohen@cornell.edu
Abstract. In [3] a general logical framework for formalizing set theo-
ries of diﬀerent strength was suggested. We here employ that framework,
focusing on the exploration of computational theories. That is, theories
whose set of closed terms suﬃces for denoting every concrete set (includ-
ing inﬁnite ones) that might be needed in applications, as well as for
computations with sets. We demonstrate that already the minimal com-
putational level of the framework, in which only a minimal computational
theory and a minimal computational universe are employed, suﬃces for
developing large portions of scientiﬁcally applicable mathematics.
Keywords: Formalized mathematics · Computational theories
Computational universes · Rudimentary set theory
1
Introduction
Formalized mathematics and mathematical knowledge management (MKM) are
extremely fruitful and quickly expanding ﬁelds of research at the intersection of
mathematics and computer science (see, e.g., [2,8,23]). The declared goal of these
ﬁelds is to develop computerized systems that eﬀectively represent all impor-
tant mathematical knowledge and techniques, while conforming to the highest
standards of mathematical rigor. At present there is no general agreement what
should be the best framework for this task. However, since most mathematicians
view set theory as the basic foundation of mathematics, formalized set theories
seem to us as the most natural choice.1,2
1 Already in [9] it was argued that “a main asset gained from Set theory is the ability
to base reasoning on just a handful of axiom schemes which, in addition to being
conceptually simple (even though surprisingly expressive), lend themselves to good
automated support”. More recently, H. Friedman wrote (in a message on FOM on
Sep 14, 2015): “I envision a large system and various important weaker subsystems.
Since so much math can be done in systems much weaker than ZFC, this should
be reﬂected in the choice of Gold Standards. There should be a few major Gold
Standards ranging from Finite Set Theory to full blown ZFC”.
2 Notable set-based automated provers are Mizar [29], Metamath [25] and SETL [30].
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 37–54, 2018.
https://doi.org/10.1007/978-3-319-72056-2_3

38
A. Avron and L. Cohen
In [3,4] a logical framework for developing and mechanizing set theories was
introduced. Its key properties are that it is based on the usual (type-free) set
theoretic language and makes extensive use of statically deﬁned abstract set
terms. Furthermore, it enables the use of diﬀerent logics and set theories of
diﬀerent strength. This modularity of the system has been exploited in [5], where
a hierarchy of set theories for formalizing diﬀerent levels of mathematics within
this framework was presented.
The current paper concentrates on one very basic theory, RST F OL
HF , from the
above-mentioned hierarchy, and on its minimal model. The latter is shown to be
the universe J2 in Jensen’s hierarchy [22]. Both RST F OL
HF
and J2 are computa-
tional (in a precise sense deﬁned below). With the help of the formal framework
of [3–5] they can therefore be used to make explicit the potential computational
content of set theories (ﬁrst suggested and partially demonstrated in [9]). On
the other hand, they also suﬃce (as we show) for developing large portions of
scientiﬁcally applicable mathematics [17], especially analysis.3 In [15–17] it was
forcefully argued by Feferman that scientiﬁcally applicable mathematics, i.e. the
mathematics that is actually indispensable to present-day natural science, can
be developed using only predicatively acceptable mathematics. We here sup-
port this claim, using a much simpler framework than the systems employed by
Feferman.
The restriction to a minimal, concrete framework has of course its price. Not
all standard mathematical structures are elements of J2. (The real line is a case
in point.) Hence we have to treat such objects in a diﬀerent manner: as proper
classes. Accordingly, in this paper we introduce for the ﬁrst time classes into the
formal framework of [3–5], and develop eﬃcient ways for handling them.
The paper is organized as follows: In Sect. 2 we present the formal framework,
deﬁne the notions of computational theory and universe, and describe the compu-
tational theories which are minimal within the framework. Section 3 is dedicated
to the introduction of standard extensions by deﬁnitions of the framework, done
in a static way. We deﬁne the notions of sets and classes in our framework, and
describe the way standard set theoretical notions are dealt with in the system.
In Sect. 4 we turn to real analysis, and demonstrate how it can be developed
in our minimal computational framework, although the reals are a proper class
in it. This includes the introduction of the real line and real functions, as well
as formulating and proving classical results concerning these notions.4 Section 5
concludes with directions for future continuation of the work.5
3 The thesis that J2 is suﬃcient for core mathematics was already put forward in [33].
4 A few of the claims in Sect. 4 have counterparts in [5]. The main diﬀerence is that
in this paper the claims and their proofs have to be modiﬁed to handle classes.
5 Due to page constraints, all proofs in the paper were omitted, and will appear in an
extended version of the current paper.

A Minimal Computational Theory of a Minimal Computational Universe
39
2
Preliminaries
2.1
The Framework
Notation. To avoid confusion, the parentheses {◦◦} are used in our formal lan-
guages, while in the meta-language we use { }. We use the letters X, Y, Z, ...
for collections; Φ, Θ for ﬁnite sets of variables; and x, y, z, ... for variables in
the formal language. Fv(exp) denotes the set of free variables of exp, and
ϕ [t1/x1, . . . , tn/xn] denotes the result of simultaneously substituting ti for xi in ϕ.
Deﬁnition 1. Let C be a ﬁnite set of constants. The language LC
RST and the
associated safety relation ≻are simultaneously deﬁned as follows:
– Terms:
• Every variable is a term.
• Every c ∈C is a term (taken to be a constant).
• If x is a variable and ϕ is a formula such that ϕ ≻{x}, then {◦x | ϕ◦} is a
term (Fv ({◦x | ϕ◦}) = Fv (ϕ) −{x}).
– Formulas:
• If s, t are terms, then t = s, t ∈s are atomic formulas.
• If ϕ, ψ are formulas and x is a variable, then ¬ϕ, (ϕ ∧ψ) , (ϕ ∨ψ), ∃xϕ
are formulas.6
– The safety relation ≻:
• If ϕ is an atomic formula, then ϕ ≻∅.
• If t is a term such that x /∈Fv (t), and ϕ ∈{x ∈x, x ∈t, x = t, t = x},
then ϕ ≻{x}.
• If ϕ ≻∅, then ¬ϕ ≻∅.
• If ϕ ≻Θ and ψ ≻Θ, then ϕ ∨ψ ≻Θ.
• If ϕ ≻Θ, ψ ≻Φ and Φ∩Fv (ϕ) = ∅or Θ∩Fv (ψ) = ∅, then ϕ∧ψ ≻Θ∪Φ.
• If ϕ ≻Θ and y ∈Θ, then ∃yϕ ≻Θ −{y}.
Notation. We take the usual deﬁnition of ⊆in terms of ∈, according to which
t ⊆s ≻∅. {◦t◦} denotes the term {◦x | x = t◦}, and s∪t the term {◦x | x ∈s∨x ∈t◦}.
Deﬁnition 2. The system RST F OL
C
is the classical ﬁrst-order system with vari-
able binding term operator (vbto; see, e.g., [13]) in LC
RST which is based on the
following set of axioms:7
– Extensionality:
∀z (z ∈x ↔z ∈y) →x = y
– Comprehension Schema:
∀x (x ∈{◦x | ϕ◦} ↔ϕ)
– Restricted ∈-induction Schema:
(∀x (∀y (y ∈x →ϕ [y/x]) →ϕ)) →∀xϕ , for ϕ ≻∅
6 Though the oﬃcial language does not include ∀and →, since we assume classical
logic we take ∀x1...∀xn (ϕ →ψ) as an abbreviation for ¬∃x1...∃xn (ϕ ∧¬ψ).
7 RST F OL can be shown to be equivalent to the system obtained from Gandy’s basic
set theory [20] by adding to it the Restricted ∈-induction schema.

40
A. Avron and L. Cohen
In case HF ∈C, the following axioms are added:
– ∅∈HF (where ∅= {◦x ∈HF | x ̸= x◦})
– ∀x∀y (x ∈HF ∧y ∈HF →x ∪{◦y◦} ∈HF)
– ∀y (∅∈y ∧∀v, w ∈y.v ∪{◦w◦} ∈y →HF ⊆y)
Notation. In what follows, in case C = ∅we elide C from our notations (e.g., we
write RST F OL for RST F OL
∅
). Also, if C = {HF} we simply write RST F OL
HF .
An important feature of RST F OL
C
is that its ﬁrst two axioms directly lead
(and are equivalent) to the set-theoretical β and η reduction rules (see [3]).
In [3] it was suggested that the computationally meaningful instances of the
Comprehension Axiom are those which determine the collections they deﬁne
in an absolute way, independently of any “surrounding universe”. In the con-
text of set theory, a formula ϕ is “computable” w.r.t. x if the collection
{x | ϕ (x, y1, ..., yn)} is completely and uniquely determined by the identity of
the parameters y1, ..., yn, and the identity of other objects referred to in the for-
mula (all of which are well-determined beforehand). Note that ϕ is computable
for ∅iﬀit is absolute in the usual sense of set theory. In order to translate this
idea into an exact, syntactic deﬁnition, the safety relation is used. Thus, only
those formulas which are safe with respect to {x} are allowed in the Compre-
hension Scheme.
Concerning ∈-induction, even the full one does not seem to be in any conﬂict
with the notion of a computational theory since it only imposes further restric-
tions on the collection of acceptable sets. Nevertheless, to be on the safe side,
we adopt here only a very restricted variation of it. Moreover, we try to avoid
(when possible) the use of this axiom, and shall point out the places where it is
used.
It is easy to verify that the system RST F OL
C
is a proper subsystem of ZF.
On the other hand, in [3] it was shown that the full power of ZF can be achieved
by simply adding certain syntactic clauses to the deﬁnition of the safety relation.
While the formal language allows the use of set terms, it also provides a
mechanizable static check of their validity due to the syntactic safety relation.
To obtain decidable syntax logically equivalent formulas are not taken to be safe
w.r.t. the same set of variables. However, if ϕ ↔ψ is provable in RST F OL
C
, then
so is x ∈{◦x | ϕ◦} ↔ψ. Thus, we freely write {◦x | ψ◦} for of {◦x | ϕ◦} for such ϕ, ψ.
Deﬁnition 3. Let C be a set of constants.
1. A function is called C-rudimentary if it rudimentary relative to the interpre-
tations of the constants in C.8
2. A C-universe is a transitive collection of sets closed under C-rudimentary
functions.
For simplicity, in what follows we do not distinguish between a C-universe W
and a structure for LC
RST with domain W and an interpretation function I that
8 Rudimentary functions are obtained by omitting the recursion schema from the usual
list of schemata for primitive recursive set functions (see, e.g., [14]).

A Minimal Computational Theory of a Minimal Computational Universe
41
assigns the obvious interpretations to the symbols ∈, =, the set of hereditary
ﬁnite sets to HF (if HF ∈C), and an element in W to every c ∈C.
Deﬁnition 4. Let v be an assignment in a C-universe W. For a term t
and formula ϕ of LC
RST , a collection ∥t∥W
v
and a truth value ∥ϕ∥W
v
∈
{t, f} are standardly deﬁned, with the additional clause: ∥{◦x | ϕ◦}∥W
v
=

a ∈W | ∥ϕ∥W
v[x:=a] = t

.9
From Corollary 6 below it follows that ∥t∥W
v
is an element of W, and ∥ϕ∥W
v
denotes the truth value of the formula ϕ under W and v.
Notation. In case exp is a closed expression, we denote by ∥exp∥W the value of
exp in W, and at times we omit the superscript W and simply write ∥exp∥.
The following theorem is a slight generalization of a theorem in [4].
Theorem 5. Let C be a set of constants.
1. If F is an n-ary C-rudimentary function, then there exists a formula ϕF of
LC
RST s.t. Fv (ϕF ) ⊆{y, x1, ..., xn}, ϕF ≻{y} and F (x1, ..., xn) = {y | ϕF }.
2. If ϕ is a formula of LC
RST
s.t. Fv (ϕ)
⊆
{y1, ..., yk, x1, ..., xn} and
ϕ
≻
{y1, ..., yk}, then there exists a C-rudimentary function Fϕ s.t.
Fϕ (x1, ..., xn) = {⟨y1, ..., yk⟩| ϕ}.
3. If t is a term of LC
RST s.t. Fv (t) ⊆{x1, ..., xn}, then there exists a
C-rudimentary function Ft s.t. Ft (x1, ..., xn) = t for every x1, ..., xn.
Corollary 6. Let v be an assignment in a C-universe W.
1. For a term t of LC
RST , ∥t∥W
v ∈W.
2. For a formula ϕ of LC
RST s.t. {y1, ..., yn} ⊆Fv (ϕ):
(a) If ϕ ≻{y1, ..., yn} (n > 0),

⟨a1, ..., an⟩∈W n | ∥ϕ∥W
v[y:=−
→
a ] = t

∈W.
(b) If ϕ ≻∅and X ∈W, then

⟨a1, ..., an⟩∈Xn | ∥ϕ∥W
v[y:=−
→
a ] = t

∈W.
If t is a closed term s.t. ∥t∥W = X, we say that t deﬁnes X (X is deﬁnable by t).
Corollary 7. Any C-universe is a model of RST F OL
C
.
Lemma 8. [5] The following notations are available in RST F OL (i.e. they can
be introduced as abbreviations in LRST and their basic properties are provable
in RST F OL): ∅, ⟨t1, ..., tn⟩, {◦t1, ..., tn◦}, {◦x ∈t | ϕ◦} (provided ϕ ≻∅and x /∈
Fv (t)), {◦t | x ∈s◦} (provided x /∈Fv (s)), s × t, s ∪t, s ∩t, s −t, ∪t, ∩t,
π1 (t) , π2 (t), Dom (t) , Im (t), ιx.ϕ (provided ϕ ≻{x}), λx ∈s.t (provided
x /∈Fv (s)).
9 v [x := a] denotes the x-variant of v which assigns a to x.

42
A. Avron and L. Cohen
2.2
Computational Theories and Universes
Computations within a set of objects require concrete representations of these
objects. Accordingly, we call a theory computational if its set of closed terms
induces in a natural way a minimal model of the theory, and it enables the key
properties of these elements to be provable within it. Next we provide a more
formal deﬁnition for the case of set theories which are deﬁned within our general
framework. Note that from a Platonist point of view, the set of closed terms of
such a theory T induces some subset ST of the cumulative universe of sets V ,
as well as some subset MT of any transitive model M of T .
Deﬁnition 9. 1. A theory T in the above framework is called computational
if the set ST it induces is a transitive model of T , and the identity of ST
is absolute in the sense that MT = ST for any transitive model M of T
(implying that ST is actually a minimal transitive model of T ).
2. A set is called computational if it is ST for some computational theory T .
The most basic computational theories are the two minimal theories in the
hierarchy of systems developed in [5]. This fact, as well as the corresponding
computational universes, are described in the following three results from [5].
Proposition 10. Let J1, J2 be the ﬁrst two universes in Jensen’s hierarchy [22].
1. J1 is a model of RST F OL.
2. J2 with the interpretation of HF as J1 is a model of RST F OL
HF .
Theorem 11
– X ∈J1 iﬀthere is a closed term t of LRST s.t. ∥t∥J1 = X.
– X ∈J2 iﬀthere is a closed term t of LHF
RST such that ∥t∥J2 = X.
Corollary 12. RST F OL and RST F OL
HF
are computational, and J1 and J2 are
their computational universes.
Now J1, the minimal computational universe, is the set of hereditary ﬁnite
sets. This universe captures the standard data structures used in computer sci-
ence, like strings and lists. However, in order to be able to capture computational
structures with inﬁnite objects, we have to move to RST F OL
HF , whose computa-
tional universe, J2, seems to be the minimal universe that suﬃces for this purpose.
RST F OL
HF
still allows for a very concrete, computationally-oriented interpretation,
and it is appropriate for mechanical manipulations and interactive theorem prov-
ing. Moreover, as noted in the introduction, its corresponding universe J2 is rich
enough for a systematic development of applicable mathematics.
3
Static Extensions by Deﬁnitions
When working in a minimal computational universe such as J2 (as done in the
next section), many of the standard mathematical objects (such as the real line

A Minimal Computational Theory of a Minimal Computational Universe
43
and real functions) are only available in our framework as proper classes. Thus,
in order to be able to formalize standard theorems regarding such objects we
must enrich our language to include them. Introducing classes into our frame-
work, however, is a part of the more general method of extensions by deﬁnitions
which is an essential part of every mathematical research and its presentation.
Now, there are two principles that govern this process in our framework. First,
the static nature of our framework demands that conservatively expanding the
language of a given theory should be reduced to the use of abbreviations. Sec-
ond, since the introduction of new predicates and function symbols creates new
atomic formulas and terms, one should be careful that the basic conditions con-
cerning the underlying safety relation ≻are preserved. Thus only formulas ϕ s.t.
ϕ ≻∅can be used for deﬁning new predicate symbols.
We start with the problem of introducing new unary predicate symbols to
the base langauge.10 In standard practice such extensions are carried out by
introducing a new unary predicate symbol P and either treating P (t) as an
abbreviation for ϕ (t) for some formula ϕ, or (what is more practical) adding
∀x (P (x) ↔ϕ) as an axiom to the (current version of the base) theory, obtain-
ing by this a conservative theory in the extended language. However, in the
set theoretical framework it is possible and frequently more convenient to uni-
formly use class terms, rather than introduce a new predicate symbol each time.
Thus, instead of writing “P (t)” one uses an appropriate class term S and writes
“t ∈S”. Whatever approach is chosen – in order to respect the deﬁnition of a
safety relation, class terms should be restricted so that “t ∈S” is safe w.r.t.
∅. Accordingly, we extend our language by incorporating class terms which are
objects of the form {◦xˆ| ϕ◦}, where ϕ ≻∅. The use of these terms is done in the
standard way. In particular, t ∈{◦xˆ| ϕ◦} (where t is free for x in ϕ) is equivalent to
(and may be taken as an abbreviation for) ϕ [t/x]. It should be emphasized that
a class term is not a valid term in the language, only a deﬁnable predicate. The
addition of the new notation does not enhance the expressive power of LC
RST ,
but only increases the ease of using it.
A further conservative extension of the language that we shall use incorpo-
rates free class variables, X, Y , Z, and free function variables, F , G, into LC
RST
(as in free-variable second-order logic [31]). These variables stand for arbitrary
class or function terms (the latter is deﬁned in Deﬁnition 20), and they may only
appear as free variables, never to be quantiﬁed. We allow occurrences of such
variables inside a formula in a class term or a function term. One may think of
a formula with such variables as a schema, where the variables play the role of
“place holders”, and whose substitution instances abbreviate oﬃcial formulas of
the language (see Example 2). In eﬀect, a formula ψ (X) with free class variable
X can be intuitively interpreted as “for any given class X, ψ (X) holds”. Thus,
a free-variable formulation has the ﬂavor of a universal formula. Therefore, this
addition allows us to make statements about all potential classes as well as all
potential functions.
10 The use of n-ary predicates can standardly be reduced, of course, to unary predicates.

44
A. Avron and L. Cohen
We deﬁne
{◦xˆ| ϕ◦}

W
v
=

a ∈W | ∥ϕ∥W
v[x:=a] = t

. We say that the class
term deﬁnes the latter collection (which might not be an element of W).
Deﬁnition 13. Let X be a collection of elements in W.
– X is a ≻-set if there is a closed term that deﬁnes it. If X is a ≻-set, 
X
denotes some closed term that deﬁnes it.
– X is a ≻-class if there is a closed class term that deﬁnes it. If X is a ≻-class,
¯X denotes some closed class term that deﬁnes it.
Note that, by Corollary 6, if X is a ≻-set then X ∈W.
Proposition 14. The following holds:
1. Every ≻-set is a ≻-class.
2. The intersection of a ≻-class with a ≻-set is a ≻-set.
3. Every ≻-class that is contained in a ≻-set is a ≻-set.
Remark 15. A semantic counterpart of our notion of a ≻-class was used in
[33], and is there called an ι-class. It is deﬁned as a deﬁnable subset of J2
whose intersection with any element of J2 is in J2. The second condition in
this deﬁnition seems somewhat ad hoc. More importantly, it is unclear how it
can be checked in general, and what kind of set theory is needed to establish
that certain collections are ι-classes. The deﬁnition of a ≻-class used here is, in
contrast, motivated by and based on purely syntactical considerations. It is also
a simpliﬁcation of the notion of ι-class as by Proposition 14(2) every ≻-class is
an ι-class.11
Proposition 16. The following holds:
– Let Y be a ≻-set. If ϕ ≻∅and Fv (ϕ) ⊆{x}, then {x ∈Y | ϕ} is a ≻-set.
– If ϕ ≻{x1, ..., xn}, then {⟨x1, ..., xn⟩| ϕ} is a ≻-set.
Proposition 17. For every n-ary C-rudimentary function f there is a term t
with Fv (t) ⊆{x1, ..., xn} s.t. for any ⟨A1, ..., An⟩∈W n, f returns the ≻-set
∥t∥W
[x1:=A1,...,xn:=An].
Proposition 18. If X, Y are ≻-classes, so are X ∪Y , X ∩Y , X × Y , J2 −X,
and PJ2 (X) = {z ∈J2 | z ⊆X}.
For a class term s we denote by 2s the class term {◦zˆ| z ⊆s◦}. Note that for
any assignment v in W and class term s, ∥2s∥W
v
is equal to PW

∥s∥W
v

, i.e.,
the intersection of the power set of ∥s∥W
v
and W. This demonstrates the main
diﬀerence between set terms and class terms. The interpretation of set terms is
absolute, whereas the interpretation of class terms might not be (though mem-
bership in the interpretation of a class term is absolute).
11 Two other ideas that appear in the sequel were adopted from [33]: treating the
collection of reals as a proper class, and the use of codes for handling certain classes.
It should nevertheless be emphasized that the framework in [33] is exclusively based
on semantical considerations, and it is unclear how it can be turned into a formal
theory like ZF or PA (and it is certainly not suitable for mechanization as is).

A Minimal Computational Theory of a Minimal Computational Universe
45
Deﬁnition 19. A ≻-relation from a ≻-class X to a ≻-class Y is a ≻-class A
s.t. A ⊆X × Y . A ≻-relation is called small if it is a ≻-set.
Next we extend our framework by the introduction of new function symbols. This
poses a new diﬃculty. While new relation symbols are commonly introduced in
a static way, new function symbols are usually introduced dynamically: a new
function symbol is made available after appropriate existence and uniqueness
theorems had been proven.
However, one of the main guiding principles of our framework is that its
languages should be treated exclusively in a static way. Thus function symbols,
too, are introduced only as abbreviations for deﬁnable operations on sets.12
Deﬁnition 20. – For a closed class term T and a term t of LC
RST ,
λx
∈
T.t
is
a
function
term
which
is
an
abbreviation
for
{◦zˆ| ∃x∃y (z ˇ= ⟨x, y⟩∧x ∈T ∧y = t) ◦}.13
– A ≻-class F is called a ≻-function on a ≻-class X if there is a function term
λx ∈T.t such that X = ∥T∥, Fv (t) ⊆{x} and F = ∥λx ∈T.t∥. t is called a
term which represents F.
– A ≻-class is called a ≻-function if it is a ≻-function on some ≻-class.
– A ≻-function is called small if it is a ≻-set.
Note that the standard functionality condition is always satisﬁed in a ≻-function.
Terminology. In what follows, claiming that an object is available in RST F OL
C
as
a ≻-function (≻-relation) means that it is deﬁnable as a ≻-function ( ≻-relation)
in LC
RST , and that its basic properties are provable in RST F OL
C
.14
Proposition 21. Let X, Y be ≻-classes and R a ≻-relation from X to Y .
1. R is small iﬀDom (R) and Im (R) are ≻-sets.
2. R−1 = {⟨y, x⟩| ⟨x, y⟩∈R} is available in RST F OL
C
as a ≻-relation from Y
to X. If R is small, then so is R−1.
3. If Z ⊆X and U ⊆Y are ≻-classes, then R∩(Z × U) is available in RST F OL
C
as a ≻-relation from Z to U.
Proposition 22. A ≻-set is a function according to the standard mathematical
deﬁnition (a single-valued relation) iﬀit is a small ≻-function.
Notation. Let F =
λx ∈¯X.t
 be a ≻-function. We employ standard β-reduction
for λ terms. Thus, we write F (s) for t [s/x] if s is free for x in t. Hence F (s) = y
stands for t [s/x] = y, and so if y /∈Fv [t] ∪Fv [s] \ {x}, then F (s) = y ≻{y}.
12 In this paper, as in standard mathematical textbooks, the term “function” is used
both for collections of ordered pairs and for set-theoretical operations (such as ∪).
13 We abbreviate by z ˇ= ⟨x, y⟩and ⟨x, y⟩ˇ∈z the two formulas that are provably equiv-
alent to z = ⟨x, y⟩and ⟨x, y⟩∈z and are safe w.r.t. {x, y} which were introduced
in [5].
14 The “basic properties” of a certain object is of course a fuzzy notion. However, it is
not diﬃcult to identify its meaning in each particular case, as will be demonstrated
in several examples below.

46
A. Avron and L. Cohen
Proposition 23 (Replacement axiom in class form).
Let F be a ≻-
function on a ≻-class X. Then for every ≻-set A ⊆X, F [A] = {F (a) | a ∈A}
is a ≻-set.
Below is a natural generalization of Deﬁnition 20 to functions of several variables.
Lemma 24. If
X1, ..., Xn are ≻-classes and t is a term s.t. Fv (t)
⊆
{x1, ..., xn}, then F =
λx1 ∈¯
X1, ..., xn ∈¯
Xn.t
 is available in RST F OL
C
as
a ≻-function on X1 ×...×Xn. (where λx1 ∈¯
X1, ..., xn ∈¯
Xn.t is an abbreviation
for {◦⟨⟨x1, ..., xn⟩, t⟩ˆ| ⟨x1, ..., xn⟩∈¯
X1 × ... × ¯
Xn◦}).
Corollary 25. Every C-rudimentary function is available in RST F OL
C
as a ≻-
function.
Proposition 26. Let F be a ≻-function on a ≻-class X.
1. F is small iﬀX is a ≻-set.
2. If Y0 is a ≻-class, then F −1 [Y0] = {a ∈X | F (a) ∈Y0} is a ≻-class. If F is
small, then F −1 [Y0] is a ≻-set.
3. If X0 ⊆X is a ≻-class, then F ↾X0 is available in RST F OL
C
as a ≻-function.
4. G◦F is available in RST F OL
C
as a ≻-function on X, in case G is a ≻-function
on a ≻-class Y and Im(F) ⊆Y .
5. If G is a ≻-function on a ≻-class Y and F and G agree on X ∩Y , then G∪F
is available in RST F OL
C
as a ≻-function on X ∪Y .
6. If Z is a ≻-class then the identity on Z and any constant function on Z are
available in RST F OL
C
as ≻-functions.
4
Real Analysis in J2
It is not diﬃcult to formalize the deﬁnitions, claims, and proofs of this section in
our formal framework. These translations are straightforward, but rather tedious.
Hence we shall omit them, with the exception of a few outlined examples.
4.1
The Natural Numbers
We follow the standard construction of the natural numbers: 0 := ∅;
n + 1 :=
S (n), where S (n) = n ∪{n}. Each n ∈N is a ≻-set, and N (the set of natural
numbers) is contained in the interpretation of HF.
In mainstream mathematics, as well as in standard computerized theorem
provers, the collection of natural numbers is taken as a basic object. This is
because it constitutes a well-understood, computational concept. Now, the com-
putational universe associated with RST F OL is J1, in which N is available only
as a proper ≻-class. To solve this, in RST F OL
HF
a special constant HF was added,
whose axioms ensure (as far as possible on the ﬁrst-order level) that it is to be
interpreted as the set of hereditary ﬁnite sets. These axioms in fact replace the
usual inﬁnity axiom of ZF. This increases the computational power of the theory
and captures the natural numbers as a ≻-set. Thus, in what follows we restrict

A Minimal Computational Theory of a Minimal Computational Universe
47
our attention to the computational theory RST F OL
HF
and its computational uni-
verse J2. Therefore, for readability, we simply write ∥exp∥v instead of ∥exp∥J2
v .
The induction rule is available in RST F OL
HF , but only for ϕ ≻∅.
Proposition 27. ⊢RST F OL
HF
(ϕ (0) ∧∀x (ϕ →ϕ (S (x)))) →∀x ∈
N.ϕ, for
ϕ ≻∅.
Basic properties of the natural numbers which can be formulated in the language
of ﬁrst-order Peano arithmetics are provable in RST F OL
HF
using the restricted
induction principle given in Proposition 27. This is because in their translation to
LHF
RST , all the quantiﬁcations are bounded in N, and thus they are safe w.r.t. ∅.15
4.2
The Real Line
The standard construction of Z, the set of integers, as the set of ordered pairs
(N × {0}) ∪({0} × N) can be easily carried out in RST F OL
HF , as can the usual
construction of Q, the set of rationals, in terms of ordered pairs of relatively
prime integers. There is also no diﬃculty in deﬁning the standard orderings
on Z and Q as small ≻-relations, as well as the standard functions of addition
and multiplication as small ≻-functions. The main properties of addition and
multiplication are provable in RST F OL
HF , as the standard proofs by induction
can be carried out within it. Furthermore, all the basic properties of Z and
Q (such as Q being a dense unbounded ﬁeld) are straightforwardly proven in
RST F OL
HF .
Now we turn to the standard construction of the real line using Dedekind
cuts. Since it is well known that the real line and its open segments are not
absolute, they cannot be ≻-sets, only proper ≻-classes. Thus the collection of
real numbers in RST F OL
HF
will not be a term but merely a deﬁnable predicate.16
Let ψ (u) = ∀x, y ∈Q.x ∈u ∧y < x →y ∈u, ϕ (u) = ¬∃x ∈u∀y ∈u.y ≤x.
Deﬁnition 28 (The Reals). R is
{◦u ∈PJ2 (Q) \ {∅, Q}ˆ| ψ (u) ∧ϕ (u) ◦}
.
The above term is a valid class term as PJ2 (Q)\{∅, Q} is a ≻-class, and ϕ, ψ ≻∅.
Note that the ≻-class R is not the “real” real-line (if such a thing really
exists). However, it does contain all computable real numbers, such as
√
2 and π
(see [5]).
Notation. We employ the following notations: Q+ = {q ∈Q | 0 < q}, R+ =
{r ∈R | 0 < r}, (a, b) = {r ∈R | a < r < b} and [a, b] = {r ∈R | a ≤r ≤b},
for a, b real numbers.17
15 It can be shown that the power of full induction over N (i.e. for any formula ϕ) can
be achieved by adding to RST F OL
HF
the full ∈-induction scheme.
16 As noted in Footnote 4, some of claims in the sequel have counterparts in [5]. How-
ever, the minimality restriction on the universe employed in this paper, which in
turn requires the use of classes, makes a crucial diﬀerence.
17 Notice that Q+ is a ≻-set and R+ is a ≻-class.

48
A. Avron and L. Cohen
Proposition 29. The following holds:
1.
The standard ordering < on R is available in RST F OL
HF
as a ≻-relation.
2. The standard addition and multiplication of reals are available in RST F OL
HF
as ≻-functions.
We next show that the least upper bound principle is provable in RST F OL
HF
for
≻-subsets of R.
Theorem 30. It is provable in RST F OL
HF
that every nonempty ≻-subset of R
that is bounded above has a least upper bound in R. Furthermore, the induced
mapping (l.u.b) is available in RST F OL
HF
as a ≻-function.
Theorem 30 only states that ≻-subsets of R have the least upper bound property.
Thus, it is insuﬃcient for the development of most of standard mathematics in
RST F OL
HF . The reason is that even the most basic substructures of R, like the
intervals, are not ≻-sets, but proper ≻-classes in RST F OL
HF . Hence, a stronger
version of the theorem, which ensures that the least upper bound property holds
for standard ≻-subclasses of R, is needed. Theorem 40 below provides such an
extension, but it requires some additional deﬁnitions and propositions.18
First we consider ≻-classes U ⊆R which are open. These ≻-classes are
generally not ≻-sets (unless empty), since they contain an interval of positive
length, which is a proper ≻-class and thus cannot be contained in a ≻-set (see
Proposition 14(3)). Clearly, there is no such thing as a ≻-set of ≻-classes, as a
proper ≻-class can never be an element of another ≻-set or ≻-class. However,
the use of coding (following [32,33]19) allows us, for example, to replace the
meaningless statement “the union of a ≻-set of ≻-classes is a ≻-class” with
“given a ≻-set of codes for ≻-classes, the union of the corresponding ≻-classes
is a ≻-class”.
The coding technique we use is based on the standard mathematical notation
for a “family of sets”, (Ai)i∈I, where I is a set of indices and Ai is a set for each
i ∈I. In RST F OL
HF
we cannot construct the collection of all such Ai’s if Ai is a
≻-class for some i ∈I. Thus, we treat the ≻-set I as a code for the “family of
classes” (Ai)i∈I. In fact, we mainly use the union of such families, i.e.,  Ai
i∈I
.
Deﬁnition 31. For any p ∈R and q ∈R+, the open ball Bq (p) is the ≻-class
{r ∈R | |r −p| < q}.
Deﬁnition 32. Let U ⊆R be a ≻-class. If there exists a ≻-set u ⊆Q × Q+ s.t.
U =  Bq (p)
⟨p,q⟩∈u
= {r ∈R | ∃p, q (⟨p, q⟩∈u ∧|r −p| < q)}, then U is called open
and u is a code for U.
18 It should be noted that the least upper bound principle is not derivable for all
subsets also in Weyl’s approach [34]. We next use similar coding techniques to the
ones employed by Weyl to obtain the principle for standard mathematical objects.
19 In [33] such codings are called “proxies”.

A Minimal Computational Theory of a Minimal Computational Universe
49
In what follows, the formalizations in RST F OL
HF
are carried out as follows:
– To quantify over open ≻-classes: Qu ⊆

Q × Q+ (Q ∈{∀, ∃}).
– To decode the open ≻-class whose code is u:
dec (u) := {◦r ∈¯Rˆ| ∃p, q (⟨p, q⟩ˇ∈u ∧|r −p| < q) ◦}
– To state that a class variable U is an open ≻-class:
Open (U) := ∃u ⊆

Q × Q+.U = dec (u)
Proposition 33. The following are provable in RST F OL
HF :
1. For any ≻-set u ⊆R×R+, {r ∈R | ∃p, q (⟨p, q⟩∈u ∧|r −p| < q)} is an open
≻-class.
2. The open ball Bq (p) is an open ≻-class for any p ∈R and q ∈R+.
Proposition 34. The following are provable in RST F OL
HF :
1. The union of a ≻-set of open ≻-classes is an open ≻-class. i.e., given a ≻-set
of codes of open ≻-classes, the union of the corresponding open ≻-classes is
an open ≻-class.
2. The intersection of ﬁnitely many open ≻-classes is an open ≻-class.
Example 1. As an example of the use of the coding technique, we demonstrate
the formalization of Proposition 34(1):
∀z.(∀x ∈z.x ⊆

Q × Q+) →∃w ⊆

Q × Q+.dec (w) = {◦rˆ| ∃x ∈z.r ∈dec (x) ◦}
Deﬁnition 35. A ≻-class X ⊆R is closed if R −X is open.
Lemma 36. Let X ⊆R be a ≻-class and A ⊆X be a ≻-set. The following are
equivalent in RST F OL
HF :
1. Every open ball about a point in X intersects A.
2. Every open ≻-class that intersects X also intersects A.
Example 2. As an example of a full formalization which uses class variables, the
formalization of the Lemma above is:
φ := X ⊆¯R →∀a ⊆X

∀x ∈X∀ε ∈¯
R+ (Bε (x) ∩a ̸= ∅) ↔
∀u ⊆

Q × Q+ (dec (u) ∩X ̸= ∅→dec (u) ∩a ̸= ∅)

We now demonstrate how to obtain a formula in the basic LHF
RST by replacing
each appearance of a class term or variable with the formula it stands for. First,
we explain the translation of x ∈¯R to LHF
RST . One iteration of the translation
entails x ∈PJ2 (Q) \ {∅, Q} ∧ϕ (x) ∧ψ (x) for ϕ, ψ as in Deﬁnition 28. A second
iteration yields R (x) := x ⊆˜Q ∧x ̸= ˜Q ∧x ̸= ∅∧ϕ (x) ∧ψ (x) which is in LHF
RST .
For the translation of φ, ﬁrst substitute {◦xˆ| θ◦} for X, where θ ≻∅. Proceeding

50
A. Avron and L. Cohen
with the translation steps results in the following formula (scheme) of LHF
RST , for
θ ≻∅:
∀b (θ (b) →R (b)) →∀a ((∀z.z ∈a →θ (z)) →∀x (θ (x) →∀ε ((R (ε) ∧0 < ε) →
∃w. |w −x| < ε ∧w ∈a ↔∀u ⊆

Q × Q+ (∃w.R (w) ∧∃p, q (⟨p, q⟩ˇ∈u ∧|w −p| < q) ∧
θ (w)) →∃w.R (w) ∧∃p, q (⟨p, q⟩ˇ∈u ∧|w −p| < q) ∧w ∈a)
Remark 37. When we say that a theorem about a ≻-class or a ≻-function is
provable in RST F OL
HF
(as in Lemma 36), we mean that it can be formalized and
proved as a scheme. That is, that its proof can be carried out in RST F OL
HF
using
a uniform scheme. The one exception is theorems about open ≻-classes, which
due to the coding machinery can be fully formalized and proved in RST F OL
HF .
Deﬁnition 38. Let X ⊆R be a ≻-class, and A ⊆X a ≻-set. A is called dense
in X if one of the conditions of Lemma 36 holds. X is called separable if it
contains a dense ≻-subset.
Proposition 39. It is provable in RST F OL
HF
that an open ≻-subclass of a sepa-
rable ≻-class is separable.
Now we can ﬁnally turn to prove a more encompassing least upper bound theo-
rem.
Theorem 40. It is provable in RST F OL
HF
that every nonempty separable ≻-
subclass of R that is bounded above has a least upper bound in R.
Deﬁnition 41. A ≻-class X ⊆R is called an interval if for any a, b ∈X s.t.
a < b: if c ∈R ∧a < c < b then c ∈X.
Proposition 42. It is provable in RST F OL
HF
that a non-degenerate interval is
separable. If it is also bounded above then it has a least upper bound.
Proposition 43. Let X ⊆R be a ≻-class. It is provable in RST F OL
HF
that X is
connected (i.e. cannot be disconnected by two open ≻-classes) iﬀit is an interval.
4.3
Real Functions
Deﬁnition 44. Let X be a ≻-class. A ≻-sequence in X is a ≻-function on N
whose image is contained in X.
Lemma 45. It is provable in RST F OL
HF
that Cauchy ≻-sequences in R converge
to limits in R. The induced map (lim) is available in RST F OL
HF
as a ≻-function.
Proposition 46. It is provable in RST F OL
HF
that if X ⊆R is closed, then every
Cauchy ≻-sequence in X converges to a limit in X.

A Minimal Computational Theory of a Minimal Computational Universe
51
Next we want to study sequences of functions, but Deﬁnition 44 cannot be
applied as is, since ≻-functions which are proper ≻-classes cannot be values
of a ≻-function (in particular, of a ≻-sequence). Instead, we use the standard
Uncurrying procedure.
Deﬁnition 47. For X, Y ≻-classes, a ≻-sequence of ≻-functions on X whose
image is contained in Y is a ≻-function on N × X with image contained in Y .
Proposition 48. Any point-wise limit of a ≻-sequence of ≻-functions on a ≻-
class X ⊆R whose image is contained in R is available in RST F OL
HF
as a ≻-
function.
Next we turn to continuous real ≻-functions. One possibility of doing so, adopted
e.g., in [32,34], is to introduce codes for continuous real ≻-functions (similar to
the use of codes for open ≻-classes). This is of course possible as such ≻-functions
are determined by their values on the ≻-set Q. However, we prefer to present
here another approach, which allows for almost direct translations of proofs in
standard analysis textbook into our system. This is done using free function
variables. Accordingly, the theorems which follow are schemes. Implicitly, the
previous sections of this paper can also be read and understood as done in this
manner. Therefore, in what follows we freely use results from them.
Deﬁnition 49. Let X ⊆R be a ≻-class and let F be a ≻-function on X whose
image is contained in R. F is called a continuous real ≻-function if:
∀a ∈X∀ε ∈R+∃δ ∈R+∀x ∈X. |x −a| < δ →|F (x) −F (a)| < ε
Proposition 50. Let X ⊆R be a ≻-class and F be a ≻-function on X whose
image is contained in R. It is provable in RST F OL
HF
that if for every open ≻-class
B ⊆R, there is an open ≻-class A s.t. F −1 [B] = A ∩X, then F is continuous.
Lemma 51. The following are provable in RST F OL
HF :
1. The composition, sum and product of two continuous real ≻-functions is a
continuous real ≻-function.
2. The uniform limit of a ≻-sequence of continuous real ≻-functions is a con-
tinuous real ≻-function.
Theorem 52 (Intermediate Value Theorem). Let F be a continuous real
≻-function on an interval [a, b] with F (a) < F (b). It is provable in RST F OL
HF
that for any d ∈R s.t. F (a) < d < F (b), there is c ∈[a, b] s.t. F (c) = d.
Theorem 53 (Extreme Value Theorem). Let F be a continuous real ≻-
function on a non-degenerate interval [a, b]. It is provable in RST F OL
HF
that F
attains its maximum and minimum.
The next step is to introduce in RST F OL
HF
the concepts of diﬀerentiation, inte-
gration, power series, etc., and develop their theories. It should now be clear that
there is no diﬃculty in doing so. Since a thorough exposition obviously could
not ﬁt in one paper we omit it here, but use some relevant facts in what follows.

52
A. Avron and L. Cohen
We now show that all elementary functions that are relevant to J2 are avail-
able in RST F OL
HF . Even though for every real number y in J2, λx ∈R.y is
available in RST F OL
HF
as a ≻-function, not all constant functions on the “real”
real line are available in J2. The reason is that λx ∈R.y does not exists in J2 for
every “real” number y (simply since not every “real” real number is available in
RST F OL
HF ).
Deﬁnition 54. The collection of J2-elementary functions is deﬁned like the
standard elementary functions (see, e.g., [28]), replacing the constant functions
by J2-constant functions, which are λx ∈R.c where c is a real in J2.
Proposition 55. Let F be a continuous, strictly monotone real ≻-function on
a real interval. Then it is provable in RST F OL
HF
that the inverse function F −1 is
available in RST F OL
HF
as a ≻-function, and its continuity is provable in RST F OL
HF .
Proposition 56. All J2-elementary functions are available in RST F OL
HF . Also,
any piece-wise deﬁned function with ﬁnitely many pieces such that its restriction
to any of the pieces is a J2-elementary function, is available in RST F OL
HF .
5
Conclusion and Further Research
In this paper we showed that a minimal computational framework is suﬃcient for
the development of applicable mathematics. Of course, a major future research
task is to implement and test the framework. A critical component of such imple-
mentation will be to scale the cost of checking the safety relation. We then plan
to use the implemented framework to formalize even larger portions of mathe-
matics, including ﬁrst of all more analysis, but also topology and algebra.
Another important task is to fully exploit the computational power of our
computational theories. This includes ﬁnding a good notion of canonical terms,
and investigating various reduction properties such as strong normalization. We
intend to try also to proﬁt from this computational power in other ways, e.g.,
by using it for proofs by reﬂection as supported by well-known proof assistant
like Coq [10], Nuprl [12] and Isabelle/HOL [27].
An intuitionistic variant of the system RST F OL
C
, RST iF OL
C
, can be also con-
sidered. It is based on intuitionistic ﬁrst-order logic (which underlies constructive
counterparts of ZF, like CZF [1] and IZF [7]), and is obtained by adding to
RST F OL
C
the axiom of Restricted Excluded Middle: ϕ ∨¬ϕ, where ϕ ≻∅. This
axiom is computationally acceptable since it simply asserts the deﬁniteness of
absolute formulas. The computational theory RST iF OL
HF
should allow for a sim-
ilar formalization of constructive analysis (e.g., [26]).
Further exploration of the connection between our framework and other
related works is also required. This includes works on: computational set theory
[1,7,9,19,26], operational set theory [18,21], and rudimentary set theory [6,24].
Another direction for further research is to consider larger computational
structures. This includes Jω or even Jωω (which is the minimal model of the
minimal computational theory based on ancestral logic [4,11]). On the one hand,

A Minimal Computational Theory of a Minimal Computational Universe
53
in such universes standard mathematical structures can be treated as sets. On
the other hand, they are more comprehensive and less concrete, thus include
more objects which may make computations harder.
Acknowledgements. The second author is supported by: Fulbright Post-doctoral
Scholar program; Weizmann Institute of Science – National Postdoctoral Award pro-
gram for Advancing Women in Science; Eric and Wendy Schmidt Postdoctoral Award
program for Women in Mathematical and Computing Sciences.
References
1. Aczel, P., Rathjen, M.: Notes on constructive set theory. Technical report 40,
Mittag-Leﬄer (2001)
2. Avigad, J., Harrison, J.: Formally veriﬁed mathematics. Commun. ACM 57(4),
66–75 (2014)
3. Avron, A.: A framework for formalizing set theories based on the use of static set
terms. In: Avron, A., Dershowitz, N., Rabinovich, A. (eds.) Pillars of Computer
Science. LNCS, vol. 4800, pp. 87–106. Springer, Heidelberg (2008). https://doi.
org/10.1007/978-3-540-78127-1 6
4. Avron, A.: A new approach to predicative set theory. In: Schindler, R. (ed.) Ways
of Proof Theory, Onto Series in Mathematical Logic, pp. 31–63. Verlag (2010)
5. Avron, A., Cohen, L.: Formalizing scientiﬁcally applicable mathematics in a deﬁ-
nitional framework. J. Formalized Reasoning 9(1), 53–70 (2016)
6. Beckmann, A., Buss, S.R., Friedman, S.D.: Safe recursive set functions. J. Symbolic
Logic 80(3), 730–762 (2015)
7. Beeson, M.J.: Foundations of Constructive Mathematics: Metamathematical Stud-
ies, vol. 6. Springer Science & Business Media, Boston (2012)
8. Autexier, S., Campbell, J., Rubio, J., Sorge, V., Suzuki, M., Wiedijk, F. (eds.):
CICM 2008. LNCS, vol. 5144. Springer, Heidelberg (2008). https://doi.org/10.
1007/978-3-540-85110-3
9. Cantone, D., Omodeo, E., Policriti, A.: Set Theory for Computing: From Decision
Procedures to Declarative Programming with Sets. Springer, New York (2001)
10. Chlipala,
A.:
Certiﬁed
Programming
with
Dependent
Types.
MIT
Press,
Cambridge (2013)
11. Cohen, L., Avron, A.: The middle ground-ancestral logic. Synthese, 1–23 (2015)
12. Constable, R.L., Allen, S.F., Bromley, M., Cleaveland, R., et al.: Implementing
Mathematics with the Nuprl Proof Development System. Prentice Hall, Englewood
Cliﬀs (1986)
13. Corcoran, J., Hatcher, W., Herring, J.: Variable binding term operators. Math.
Logic Q. 18(12), 177–182 (1972)
14. Devlin, K.: Constructibility. Perspectives in Mathematical Logic. Springer,
Heidelberg (1984)
15. Feferman, S.: Systems of predicative analysis. J. Symbolic Logic 29(01), 1–30
(1964)
16. Feferman, S.: Systems of predicative analysis, II: representations of ordinals. J.
Symbolic Logic 33(02), 193–220 (1968)
17. Feferman, S.: Why a little bit goes a long way: logical foundations of scientiﬁ-
cally applicable mathematics. In: PSA: Proceedings of the Biennial Meeting of the
Philosophy of Science Association, pp. 442–455. JSTOR (1992)

54
A. Avron and L. Cohen
18. Feferman, S.: Operational set theory and small large cardinals. Inf. Comput.
207(10), 971–979 (2009)
19. Friedman, H.: Set theoretic foundations for constructive analysis. Ann. Math.
105(1), 1–28 (1977)
20. Gandy, R.O.: Set-theoretic functions for elementary syntax. In: Proceedings of
Symposia in Pure Mathematics, vol. 13, pp. 103–126 (1974)
21. J¨ager, G., Zumbrunnen, R.: Explicit mathematics and operational set theory: some
ontological comparisons. Bull. Symbolic Logic 20(3), 275–292 (2014)
22. Jensen, R.B.: The ﬁne structure of the constructible hierarchy. Ann. Math. Logic
4(3), 229–308 (1972)
23. Kamareddine, F.D.: Thirty Five Years of Automating Mathematics, vol. 28.
Springer, Netherlands (2003)
24. Mathias, A.R.D., Bowler, N.J., et al.: Rudimentary recursion, gentle functions and
provident sets. Notre Dame J. Formal Logic 56(1), 3–60 (2015)
25. Megill, N.: Metamath: A Computer Language for Pure Mathematics. Elsevier Sci-
ence, Amsterdam (1997)
26. Myhill, J.: Constructive set theory. J. Symbolic Logic 40(03), 347–382 (1975)
27. Nipkow, T., Wenzel, M., Paulson, L.C. (eds.): Isabelle/HOL: A Proof Assistant
for Higher-Order Logic. LNCS, vol. 2283. Springer, Heidelberg (2002). https://
doi.org/10.1007/3-540-45949-9
28. Risch, R.H.: Algebraic properties of the elementary functions of analysis. Am. J.
Math. 101(4), 743–759 (1979)
29. Rudnicki, P.: An overview of the MIZAR project. In: Proceedings of the 1992
Workshop on Types for Proofs and Programs, pp. 311–330 (1992)
30. Schwartz, J.T., Dewar, R.B., Schonberg, E., Dubinsky, E.: Programming with
Sets: An Introduction to SETL. Springer-Verlag New York Inc., New York (1986).
https://doi.org/10.1007/978-1-4613-9575-1
31. Shapiro, S.: Foundations Without Foundationalism: A Case for Second-Order
Logic. Oxford University Press, Oxford (1991)
32. Simpson, S.G.: Subsystems of Second Order Arithmetic, vol. 1. Cambridge
University Press, Cambridge (2009)
33. Weaver, N.: Analysis in J2. arXiv preprint arXiv:math/0509245 (2005)
34. Weyl, H.: Das Kontinuum: Kritische Untersuchungen ¨uber die Grundlagen der
Analysis. W. de Gruyter (1932)

A Sequent-Calculus Based Formulation
of the Extended First Epsilon Theorem
Matthias Baaz1
, Alexander Leitsch2
, and Anela Lolic1(B)
1 Institute of Discrete Mathematics and Geometry 104, TU Wien, Vienna, Austria
{baaz,anela}@logic.at
2 Institute of Computer Languages (E185), TU Wien, Vienna, Austria
leitsch@logic.at
Abstract. The optimal calculation of Herbrand disjunctions from
unformalized or formalized mathematical proofs is one of the most promi-
nent problems of computational proof theory. The up-to-date most direct
approach to calculate Herbrand disjunctions is based on Hilbert’s epsilon
formalism (which is in fact also the oldest framework for proof theory).
The algorithm to calculate Herbrand disjunctions is an integral part of
the proof of the extended ﬁrst epsilon theorem. This paper connects
epsilon proofs and sequent calculus derivations with cuts. This leads to
an improved notation for the epsilon formalism and a computationally
improved version of the extended ﬁrst epsilon theorem, which allows a
nonelementary speed-up of the computation of Herbrand disjunctions.
Keywords: Extended ﬁrst epsilon theorem · Herbrand disjunctions
Epsilon calculus
1
Introduction
The optimal calculation of Herbrand disjunctions from unformalized or formal-
ized mathematical proofs is one of the most prominent problems in proof theory
of ﬁrst-order logic. So far, the most direct approach to calculate Herbrand dis-
junctions is based on Hilbert’s ε-formalism, cf. which is also the oldest framework
for proof theory [7].
The ε-calculus uses ε-terms to represent ∃xA(x) by A(εxA(x)) (∀xA(x) is
consequently represented by A(εx¬A(x))). As the ε-calculus is only based on the
representation of substitutions (critical formulas A(t) →A(εxA(x)) for A(t) →
∃xA(x)) and propositional axioms and rules, the unrestricted deduction theorem
of propositional calculus transfers to this formalization of ﬁrst order logic: The
ε-proof itself is a tautology ((n
i=1 Ai(ti) →Ai(εxAi(x))) →E, where E is the
original result translated into ε-calculus). Note that strong quantiﬁer inferences
are replaced by substitutions of εx¬A(x) for ∀xA(x) positive and εxA(x) for
∃xA(x) negative. Valid propositional formulas do not inﬂuence an ε-proof. The
extended ﬁrst ε-theorem [7,9] eliminates algorithmically the critical formulas
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 55–71, 2018.
https://doi.org/10.1007/978-3-319-72056-2_4

56
M. Baaz et al.
obtaining a Herbrand disjunction m
i=1 E(ti), where E is the ε-translation of
∃xE′(x), E′ being quantiﬁer-free.
There are many advantages of the extended ﬁrst ε-theorem w.r.t. the cal-
culation of Herbrand disjunctions, which are not shared by more widespread
approaches to obtain Herbrand disjunctions. First of all, the ε-calculus is not sen-
sitive w.r.t. addition of (arbitrary) tautologies. This implies that bounds depend
on ﬁrst-order features only. More precisely, the complexity of the Herbrand dis-
junction does not depend on the complexity of the derivation, but only on the
number of critical formulas and on the complexity of the ε-terms occurring in
it. Note that the complexity of ε-terms measures just the quantiﬁer complex-
ity of the formulas involved, not the propositional complexity. Furthermore, the
extended ﬁrst ε-theorem develops the Herbrand disjunctions as contraposition of
all case distinctions in the proof: the Herbrand disjunction may be understood
as the only remaining case distinction. This explains why Herbrand disjunctions
may be short even for high level mathematical proofs (cf. the complexity of the
Herbrand disjunction in [8]). Another advantage is that a proof might be formal-
ized disregarding propositional features: represent all substitutions in the proof;
if the obtained ε-proof is not a tautology, a substitution has been overlooked.
Despite the advantages, the ε-calculus has never become popular in compu-
tational proof theory of ﬁrst order logic. The main reasons are the untractabil-
ity of almost all nonclassical logics by any adaptation of the ε-formalism and
the clumsiness of the ε-formalism itself: consider the ε-translation of ∃x∃y∃z
A(x, y, z): A(εx A(x, εy A(x, y, εz A(x, y, z)), εzA(x, εy A(x, y, εz A(x, y, z)), z)),
εy A(εx A(x, εy A(x, y, εzA(x, y, z)), εzA(x, εyA(x, y, εzA(x, y, z)), z)), y, εzA(εx
A(x, εy A(x, y, εz A(x, y, z)), εz A(x, εy A(x, y, εz A(x, y, z)), z)), y, z)), εzA(εx
A(x, εy A(x, y, εz A(x, y, z)), εzA(x, εy A(x, y, εz A(x, y, z)), z)), εyA(εx A(x, εy
A(x, y, εz A(x, y, z)), εz A(x, εy A(x, y, εz A(x, y, z)), z)), y, εz A(εx A(x, εy A(x,
y, εz A(x, y, z)), εz A(x, εy A(x, y, εz A(x, y, z)), z)), y, z)), z)).
This paper addresses the second problem by deﬁning a translation of LK-
proofs with cuts to ε/τ-proofs1. This translation leads to a simpliﬁed notation
and a new elimination order that eliminates the critical formulas based on the
critical formulas that are present and not on internal features of the ε-terms.
This leads to a non-elementary speed-up of the length of the obtained Herbrand
sequents w.r.t. the length of the Herbrand sequents obtained by the original
elimination order.
2
Hilbert’s Extended First ε-Theorem in a Modern
Setting
Hilbert’s ε-calculus is formulated by representing ∃xA(x) by A(εxA(x)) and
∀xA(x) by A(εx¬A(x)) (or by A(τxA(x)) if τ-terms are used). This transla-
tion easily extends to the whole language. Critical formulas are of the form
1 To represent the symmetry of LK we will work with critical τ-formulas, i.e.
A(τxA(x)) →A(t) represents ∀xA(x) →A(t). This is only a notational convenience.

A Sequent-Calculus Based Formulation
57
A(t) →A(εxA(x)) and A(τxA(x)) →A(t), respectively. An ε/τ-matrix of
an ε-term is obtained by replacing all diﬀerent proper subterms by diﬀerent
variables. An ε/τ-proof in a modern setting is a valid quantiﬁer-free sequent
C1, . . . , Cr, Π ⊢Δ, where C1, . . . , Cr are critical formulas. ε/τ-proofs of transla-
tions of LK derivations can be easily obtained by replacing
Π ⊢Δ, A(t)
∃r
Π ⊢Δ, ∃xA(x)
by
Π ⊢Δ, A(t)
A(t) →A(εxA(x)), Π ⊢Δ
analogously for ∀l and
Π ⊢Δ, A(α)
∀r
Π ⊢Δ, ∀xA(x)
by substituting α by τxA(x),
analogously for ∃l. Otherwise the proof remains unchanged. The end-sequent is
the ε/τ-proof.
The ﬁrst ε-theorem states roughly speaking that the critical formulas can
be eliminated from the sequent if Π and Γ do not contain ε/τ-terms. We are
interested in the extended ﬁrst ε-theorem, which constructs Herbrand sequents
Πσ1, . . . , Πσn ⊢Δσ1, . . . , Δσn from ε/τ-proofs C1, . . . , Cr, Π ⊢Δ.
Lemma 1 (Hilbert’s Ansatz).
If A(t1) →A(εxA(x)), . . . , A(tn) →A(εx
A(x)), Π ⊢Δ is valid then Π{εxA(x) →t1}, . . . , Π{εxA(x) →tn}, Π ⊢Δ{εx
A(x) →t1}, . . . , Δ{εx A(x) →tn}, Δ is valid (εxA(x) can then be substituted
by a ﬁxed constant).
Proof. (See [7].) Note that A(ti), Π{εxA(x) →ti} ⊢Δ{εxA(x) →ti} and
¬A(t1), . . . , ¬A(tn), Π ⊢Δ are valid.
For the ε-theorems the following deﬁnition is central.
Deﬁnition 1. An ε/τ-term e is nested in an ε/τ-term e′ if e is a proper subterm
of e′. An ε/τ-term e is subordinate to an ε/τ-term e′ = εxA(x) (or e′ = τxA(x))
if e occurs in e′ and x is free in e.
The rank counts the subordination levels and the degree the length of the maxi-
mal inclusion chain.
Theorem 1 (Extended ﬁrst ε-theorem). Given a proof C1, . . . , Cr, Π ⊢Δ
we obtain a valid sequent Πσ1, . . . , Πσn ⊢Δσ1, . . . , Δσn containing no ε/τ-
terms, where the σi are substituting ε/τ-terms by closed terms.
Proof (Sketch). c.f. [7]. Hilbert’s Ansatz is repeatedly applied to ε/τ-terms of
maximal rank and maximal degree and to the remaining critical formulas to
obtain an expansion both of the other critical formulas and of the rest of the
sequent. The condition of maximal rank is necessary to guarantee that criti-
cal formulas are transformed into critical formulas by these substitutions. The
maximal degree is necessary for termination.

58
M. Baaz et al.
The proof in [7] implicitly contains the following algorithm:
Deﬁnition 2
begin % algorithm AlgOld
1. let F = C1, . . . , Cn, Π ⊢Δ be an ε/τ-proof and deﬁne S0 = C1, . . . , Cn,
F ′
0 = Π, F ′′
0 = Δ;
2. check whether F ′
k ⊢F ′′
k is a tautology, if yes substitute all remainung
ε/τ-terms by the ﬁxed constant c and terminate AlgOld;
3. delete A →A from Sk and let S′
k be the result;
4. choose an ε/τ-term e of maximal rank and maximal degree;
5. delete the critical formulas S(e) belonging to e. Let σ1 . . . σi be the
corresponding substitutions. Sk+1 = (S′
k −S(e))σ1λ . . . (S′
k −S(e))σiλ,
F ′
k+1 = F ′
kσ1λ . . . F ′
kσiλ, F ′
kλ, F ′′
k+1 = F ′′
k σ1λ . . . F ′′
k σiλ, F ′′
k λ,
where λ is e ←c for the ﬁxed constant c. Repeat this operation until there
are no critical formulas belonging to e. Proceed with 2.;
end.
3
A Function Variable Variant of ε/τ-Proofs
We deﬁne a new abstract format for ε/τ-proofs, where ε/τ-terms are replaced
by critical terms fulﬁlling a minimal set of conditions. This format will make it
easier to make use of structural properties of given LK derivations. Deﬁnition 7
will provide an inductive translation of LK proofs into function variable proofs.
This translation is based on the identiﬁcation of critical function symbols at
some nodes of the proof: therefore our abstract notion of ε/τ-proofs is based on
function variables.
Deﬁnition 3 (critical formulas). Let s1, . . . , sn be arbitrary terms and fQ
for Q ∈{∀, ∃} be n-ary function variables. Then formulas of the form A(t) →
A(fQ(s1, . . . , sn)) and A(fQ(s1, . . . , sn)) →A(t) are called critical formulas.
fQ is a critical function variable and fQ(s1, . . . , sn) is a critical function term.
A(fQ(s1, . . . , sn)) is the head of the critical formula.
Deﬁnition 4 (function variable proof).
A function variable proof F is a
quantiﬁer-free sequent of the form C1, . . . , Cn, Γ ⊢Δ s.t.
1. C1, . . . , Cn, Γ ⊢Δ is valid,
2. C1, . . . , Cn are critical formulas,
3. the set Δ(F) of all critical function variables can be partially ordered by an
irreﬂexive, transitive relation < s.t. whenever a critical function term of the
form gQ(. . . x . . .){x ←fQ′(. . .)} occurs in F then gQ < fQ′,
4. let σ be a substitution of critical function terms by terms s.t. fQ(u)σ =
fQ(v)σ, where Q ∈{∀, ∃}, for critical function terms fQ(u), fQ(v) associ-
ated with A(x), B(x), then A(fQ(u))σ = B(fQ(v))σ.
Note that condition 4 of Deﬁnition 4 replaces the fact that traditional ε/τ-terms
contain all subterms of the heads of critical formulas.

A Sequent-Calculus Based Formulation
59
Example 1. 1. F
= A(t) →A(fQ(t)), (A(t) →A(fQ(t))) →(A(eQ′) →
A(fQ( eQ′))) ⊢A(eQ′) →A(fQ(eQ′)) with critical terms fQ(t), eQ′, where
Δ(F) = {fQ, eQ′}, with fQ < eQ′, is a function variable proof (in fact, a
proof of the drinker’s principle).
2. E = (A(s, fQ(s)) →A(s, fQ(gQ′(s)))), (B(u, gQ′(u)) →B(u, gQ′(fQ(u)))) ⊢
(A(s, fQ(s)) →A(s, fQ(gQ′(s)))) ∧(B(u, gQ′(u)) →B(u, gQ′(fQ(u)))) with
critical terms fQ(s), gQ′(s), gQ′(u), where Δ(E) = {fQ, gQ′}, fulﬁls 1, 2, 4 of
Deﬁnition 4 but cannot fulﬁl 3.
3. G = A(c) →A(eQ), ¬A(d) →¬A(eQ) ⊢A(c) →A(d) with critical term eQ,
where Δ(G) = {eQ} fulﬁlls conditions 1, 2, 3 but not condition 4.
Proposition 1. It can be eﬀectively checked if sequents fulﬁlling condition 1
and 2 of Deﬁnition 4 are function variable proofs.
Proof. First determine the critical terms and from the critical terms the critical
function variables (their outermost function symbol). Check whether the transi-
tive closure of the relation in the sense of condition 3 of Deﬁnition 4 determines
a partial order, i.e. is loop-free. To check condition 4 of Deﬁnition 4 consider
all pairs of critical function terms with identical outermost function variable.
Replace all critical function terms properly within the selected pair with diﬀer-
ent variables and unify. If the uniﬁcation is successful apply the most general
uniﬁer in the same way to the corresponding heads of critical formulas, they
have to be identical.
Example 2. Let E = A(cQ′, s) →A(cQ′, fQ(cQ′)), A(t, s) →A(t, fQ(t)), B(u) →
B(cQ′) ⊢C(cQ′, fQ(cQ′)) with critical terms fQ(cQ′), fQ(t), cQ′, where Δ(E) =
{cQ′, fQ}, with fQ < cQ′. Condition 4 of Deﬁnition 4 on E can be checked in the
following way: We check the uniﬁability of fQ(x) and fQ(t), the most general
uniﬁer is σ = {x ←t}. Then A(x, fQ(x))σ = A(t, fQ(t))σ.
Proposition 2. ε/τ-proofs can be considered as instances of function variable
proofs.
Proof. Replace the variables deﬁned by the matrices of occurring ε-terms by
function variables. Condition 3 of Deﬁnition 4 is fulﬁlled as the order of func-
tion variables reﬂects the overbinding of the matrices. Condition 4 is fulﬁlled as
critical ε-terms and heads are in a 1 −1 relation.
The soundness of function variable proofs will be shown as corollary to the
extended ε-theorem for the function variable format.
4
A Sequent-Based Translation into the Function
Variable Proof Format
As noted in Sect. 1 the translation into ε-calculus is in general problematic and
leads to very long and complicated formulas. To obtain a better readability of ε-
expressions and making use of given LK-proofs, we propose a new nonextensional
translation from formulas and proofs into a function variable format.

60
M. Baaz et al.
Deﬁnition 5 (function variable translation). We deﬁne the function vari-
able translation FT(A), the corresponding set of function variables Δ(A) and
the set of relations Γ(A) of a formula A inductively as follows:
1. A is an atom, then FT(A) = A and Δ(A) = ∅, Γ(A) = ∅,
2. A = ¬B, then FT(A) = ¬FT(B) and Δ(A) = Δ(B), Γ(A) = Γ(B),
3. A = B ◦C, where ◦∈{∧, ∨, →}, then FT(A) = FT(B) ◦FT(C) and Δ(A) =
Δ(B) ∪Δ(C), Γ(A) = Γ(B) ∪Γ(C),
4. A = QxF(x) where Q ∈{∃, ∀}, then FT(A) = FT(F(x)){x ←fQ(y1, . . . ,
yn)}, where fQ is a new function variable, y1, . . . , yn are bound variables s.t.
their corresponding quantiﬁers are in the scope of Qx and Δ(A) = Δ(F(x))∪
{fQ}. For all g ∈Δ(F(x)), whenever x occurs in the form g(. . . x . . .) in
FT(F(x)) we deﬁne Γ(A) to be the transitive closure of Γ(F(x)) ∪{g < fQ},
where < is a partial order on function symbols.
Remark 1. Note that FT(B) and Δ(B) will diﬀer for two diﬀerent occurrences
of a subformula B of A and the diﬀerence between functions in Δ and Skolem
functions: functions in Δ depend on all quantiﬁers, Skolem functions only on
strong quantiﬁers.
Note that this deﬁnition can be easily extended to sequents. Indeed, any sequent
S = A1, . . . , Am ⊢B1, . . . , Bm is equivalent to S′ = ⊢(A1 ∧. . . ∧Am) →
(B1 ∨. . . ∨Bn), containing only one formula. (A1 ∧. . . ∧Am) →(B1 ∨. . . ∨Bn)
can then be transformed into its function variable translation as usual.
Example 3. Let E = ∀x(P(x) →∃y∀zQ(x, y, z)). Then FT(E) = P(c) →
Q(c, g(c), f(c, g(c))), Δ(E) = {c, g, f} and Γ(E) = {f < g, f < c, g < c}.
In the cases contraction and cut in Deﬁnition 7 we will deal with uniﬁcation of
terms containing function variables, where only function variables are substituted
for function variables of the same arity. We call such a uniﬁcation restricted
function uniﬁcation.
Deﬁnition 6 (restricted function uniﬁcation). Let s and t be terms con-
taining function variables. A restricted function uniﬁer is deﬁned by a substi-
tution σ s.t. sσ = tσ, where exclusively function variables are substituted for
function variables of the same arity. σ is a most general restricted function uni-
ﬁer mf(s, t) iﬀany other restricted function uniﬁer σ′ of s and t is an extension,
i.e. there is a substitution σ′′ s.t. σ′ = mf(s, t)σ′′.
Proposition 3. It is decidable whether there exists a restricted function uniﬁer
and in case there is one there is a most general one.
Proof. Parse s and t from left to the right. At the ﬁrst place of diﬀerence check
whether there are two function variables of the same arity and substitute one by
the other, otherwise there is no restricted function uniﬁer. Repeat the procedure
until the terms are identical or the output is non-uniﬁable.

A Sequent-Calculus Based Formulation
61
Proofs in sequent calculus can also be transformed into the function variable
format. The translation follows the height of the proof. We deﬁne the translation
for proofs with atomic axioms, arbitrary cuts and end-sequents containing weak
quantiﬁers only (note that strong quantiﬁers in the end-sequents can be replaced
by Skolem functions without increasing the complexity of the proof [6] and that
from a cut-free proof Skolem functions can be eliminated at exponential expense
[4]). Technically we deﬁne an extension LK∗of LK with the additional rules
Γ ⊢Δ, A(t)
Γ ⊢Δ, A(s)fvr
A(t), Γ ⊢Δ
A(t), Γ ⊢Δfvl
where s is a function term and add the formulas A(t) →A(s) for fvr and
A(s) →A(t) for fvl. In the end of the transformation these formulas will be the
critical formulas corresponding to a proof in LK and guarantee the soundness of
LK∗.
Every sequent occurrence in a proof ϕ is labelled by a label (node) ν and ϕ.ν
is the subproof of ϕ ending in ν.
To make use of contraction more explicitly, we use a multiplicative version
of LK in the following deﬁnition:
Deﬁnition 7 (minimal translation of an LK proof). We deﬁne a proof
transformation T transforming every LK proof ϕ into an LK∗proof T(ϕ) and
simultaneously generating the set of critical formulas. We construct T(ϕ) con-
taining the critical formulas (S∃and S∀), Δ(ϕ) (the set of function variables)
and Γ(ϕ) (a partial order on Δ(ϕ)) inductively over the nodes ν in ϕ.
ϕ.ν is an axiom A ⊢A. Here we deﬁne T(ϕ.ν) = A ⊢A and S∃(ν) = S∀(ν) =
Δ(ν) = Γ(ν) = ∅.
Let ξ be a unary rule diﬀerent from quantiﬁer rules, contraction and weak-
ening, μ the node of the premise and let ϕ.ν =
(ψ)
μ: Γ ⊢Δ
ν : Γ1 ⊢Δ1 ξ
Let T(ϕ.μ) be a proof ψ∗of the sequent Γ ∗⊢Δ∗. Then we deﬁne T(ϕ.ν) as
(ψ∗)
Γ ∗⊢Δ∗
Γ ∗
1 ⊢Δ∗
1
ξ
and S∃(ν) = S∃(μ), S∀(ν) = S∀(μ), Δ(ν) = Δ(μ), Γ(ν) = Γ(μ).
Note that the auxiliary formulas in Γ ∗⊢Δ∗and principal formula in Γ ∗
1 ⊢
Δ∗
1 correspond to those in Γ ⊢Δ and Γ1 ⊢Δ1, respectively.
Let ϕ.ν =
(ψ1)
μ1 : Γ ⊢Δ
(ψ2)
μ2 : Π ⊢Λ
ν : Γ1, Π1 ⊢Δ1, Λ1
ξ

62
M. Baaz et al.
where ξ is a binary rule diﬀerent from cut. Let us assume that T(ϕ.μ1) = ψ∗
1
with end-sequent Γ ∗⊢Δ∗, and T(ϕ.μ2) = ψ∗
2 with end sequent Π∗⊢Λ∗. Then
we deﬁne T(ϕ.ν) as
(ψ∗
1)
Γ ∗⊢Δ∗
(ψ∗
2)
Π∗⊢Λ∗
Γ ∗
1 , Π∗
1 ⊢Δ∗
1, Λ∗
1
ξ
and S∃(ν) = S∃(μ1) ∪S∃(μ2), S∀(ν) = S∀(μ1) ∪S∀(μ2) and Δ(ν) = Δ(μ1) ∪
Δ(μ2), Γ(ν) is the transitive closure of Γ(μ1) ∪Γ(μ2).
Let ϕ.ν be
(ψ)
μ: Γ ⊢Δ, A(t)
ν : Γ ⊢Δ, ∃x.A(x) ∃r
Assume that T(ϕ.u) = ψ∗where ψ∗is a proof with end-sequent Γ ∗⊢Δ∗, A∗(t∗).
Let t1, . . . , tn be the terms eliminated by quantiﬁers overbinding ∃x in ϕ (in a
derivation going to the end-sequent or to a cut). Let f∃be a new function variable
of arity n (not occurring in Δ(μ)) and
θ = {x ←f∃(y1, . . . , yn)}{y1 ←t1, . . . , yn ←tn}.
Then we deﬁne T(ϕ.ν) as
(ψ∗)
Γ ∗⊢Δ∗, A∗(t∗)
Γ ∗⊢Δ∗, A∗(x)θ fvr
S∃(ν) = S∃(μ) ∪{A∗(t∗) →A∗(x)θ}, S∀(ν) = S∀(μ), Δ(ν) = Δ(μ) ∪{f∃} and
if there are g1, . . . , gk in Δ(μ) s.t. A∗(t∗) is of the form A∗∗(gi(. . . t∗. . .)) for
1 ≤i ≤k, then Γ(ν) is the transitive closure of Γ(μ)∪{g1 < f∃}∪. . .∪{gk < f∃}.
The last inference in ϕ.ν is ∀l inferring ∀x.A(x): analogous to the case ∃r
above. The last rule in T(ϕ.ν) is fvl, the new variable is f∀,
θ = {x ←f∀(y1, . . . , yn)}{y1 ←t1, . . . yn ←tn},
and S∀(ν) = S∀(μ) ∪{A∗(x)θ →A∗(t∗)}. Δ(ν) = Δ(μ) ∪{f∀} and if there are
g1, . . . , gk in Δ(μ) s.t. A∗(t∗) is of the form A∗∗(gi(. . . t∗. . .)) for 1 ≤i ≤k,
then Γ(ν) is the transitive closure of Γ(μ) ∪{g1 < f∃} ∪. . . ∪{gk < f∃}.
Let ϕ.ν =
(ψ)
μ: Γ ⊢Δ, A(α)
ν : Γ ⊢Δ, ∀x.A(x) ∀r
Let T(ϕ.μ) = ψ∗where ψ∗is a proof of Γ ∗⊢Δ∗, A∗(α). Let t1, . . . , tn be the
terms eliminated by quantiﬁers overbinding ∀x in ϕ (in a derivation going to
the end-sequent or to a cut). Let f∀be a new function variable of arity n (not
occurring in Δ(μ)) and
θ = {α ←f∀(y1, . . . , yn)}{y1 ←t1, . . . , yn ←tn}.

A Sequent-Calculus Based Formulation
63
Then we deﬁne T(ϕ.ν) = ψ∗θ, S∃(ν) = S∃(μ)θ, S∀(ν) = S∀(μ)θ. Δ(ν) = Δ(μ)∪
{f∀} and if there are g1, . . . , gk in Δ(μ) s.t. A∗(α) is of the form A∗∗(gi(. . . α . . .))
for 1 ≤i ≤k, then Γ(ν) is the transitive closure of Γ(μ)∪{g1 < f∃}∪. . .∪{gk <
f∃}.
The case of ∃l is analogous to ∀r.
Contraction: let ϕ.ν be of the form
(ψ)
μ: Γ ⊢Δ, A, A
ν : Γ ⊢Δ, A
cr
Assume that T(ϕ.μ) = ψ∗where ψ∗is a proof of Γ ∗⊢Δ∗, A∗
1, A∗
2. Note that
A∗
1 and A∗
2 diﬀer only in the occurrence of function variables, i.e. there exists a
formula A0 and function variables f1, . . . , fn, g1, . . . , gn s.t.
A∗
1 = A0(f1, . . . , fn), A∗
2 = A0(g1, . . . , gn).
We use a most general restricted function uniﬁer of A∗
1 and A∗
2: Θ = mf(A∗
1, A∗
2).
We deﬁne T(ϕ.ν) as
(ψ∗Θ)
Γ ∗Θ ⊢Δ∗Θ, A∗
1Θ, A∗
2Θ
Γ ∗Θ ⊢Δ∗Θ, A∗
1Θ
cr
and S∃(ν) = S∃(μ)Θ, S∀(ν) = S∀(μ)Θ. Δ(ν) = Δ(μ)Θ and Γ(ν) is the transi-
tive closure of Γ(μ)Θ.
The case of cl is analogous.
The case of cut: Let ϕ.ν =
(ψ1)
μ1 : Γ ⊢Δ, A
(ψ2)
μ2 : A, Π ⊢Λ
ν : Γ, Π ⊢Δ, Λ
cut
assume that T(ϕ.μ1) = ψ∗
1 where ψ∗
1 is a proof of Γ ∗⊢Δ∗, A∗
1 and T(ϕ.μ2) = ψ∗
2
where ψ∗
2 is a proof of A∗
2, Π∗⊢Λ∗. Like in the case of contraction there exists
a formula A0 and function variables f1, . . . , fn, g1, . . . , gn s.t.
A∗
1 = A0(f1, . . . , fn), A∗
2 = A0(g1, . . . , gn).
We deﬁne Θ = mf(A∗
1, A∗
2). Then T(ϕ.ν) =
(ψ∗
1Θ)
Γ ∗Θ ⊢Δ∗Θ, A∗
1Θ
(ψ∗
2Θ)
A∗
2Θ, Π∗Θ ⊢Λ∗Θ
Γ ∗Θ, Π∗Θ ⊢Δ∗Θ, Λ∗Θ
cut
We deﬁne S∃(ν) = S∃(μ1) ∪S∃(μ2)Θ, S∀(ν) = S∀(μ1) ∪S∀(μ2)Θ and Δ(ν) =
(Δ(μ1) ∪Δ(μ2))Θ, Γ(ν) is the transitive closure of (Γ(μ1) ∪Γ(μ2))Θ.

64
M. Baaz et al.
The case of weakening: let ϕ.ν be of the form
(ψ)
μ: Γ ⊢Δ
ν : Γ ⊢Δ, A wr
Let T(ϕ.μ) be a proof ψ∗of the sequent Γ ∗⊢Δ∗and let A∗be the function
variable translation of A. Then we deﬁne T(ϕ.ν) as
(ψ∗)
Γ ∗⊢Δ∗
Γ ∗⊢Δ∗, A∗wr
and S∃(ν) = S∃(μ), S∀(ν) = S∀(μ), Δ(ν) = Δ(μ) ∪Δ(A), Γ(ν) is the transitive
closure of Γ(μ) ∪Γ(A).
The case of wl is analogous.
Let T(ϕ.ν0) = Π ⊢Γ, where ν0 is the root node of ϕ. The function vari-
able proof corresponding to ϕ is the sequent F(ϕ) = S∃(ν0), S∀(ν0), Π ⊢Γ.
Δ(F(ϕ)) = Δ(ν0) and Γ(F(ϕ)) = Γ(ν0).
Note that in all cases Γ(F(ϕ)) is acyclic, because of the order of the quantiﬁers.
Proposition 4. Let F(ϕ) = S∃(ν0), S∀(ν0), Π ⊢Γ be the sequent obtained from
an LK-proof ϕ as in Deﬁnition 7 and let Δ(F(ϕ)) and Γ(F(ϕ)) be the cor-
responding sets of function variables and relations. Then F(ϕ) is a function
variable proof.
Proof. Note that by construction F(ϕ) is a valid sequent and S∃(ν0), S∀(ν0)
are critical formulas, hence conditions 1, 2 of Deﬁnition 4 are fulﬁlled. The set
Δ(F(ϕ)) contains all critical function variables and can be partially ordered by
the set of relations deﬁned in Γ(F(ϕ)). Note that indeed, the transitive closure
of the set of relations in Γ(F(ϕ)) is irreﬂexive and whenever a critical function
term of the form gQ(. . . x . . .){x ←fQ′(. . .)} occurs in F(ϕ) then gQ < fQ′ as
fQ′ occurs below gQ in the proof-tree. Therefore, condition 3 of Deﬁnition 4 is
fulﬁlled as well. Condition 4 holds because the critical function terms constructed
in this translation contain all other critical terms in the head as subterms.
Example 4. Let π be the proof of “There are irrational numbers x and y s.t. xy
is rational”. Let uv = exp(u, v) and
√
2 be a constant. Then π =
(π1)
F1, F2 ⊢F3, R(
√
2
√
2)
(π2)
R(
√
2
√
2), F1, F2 ⊢F3
cut + contractions
¬R(
√
2), R(
√
2
√
2
√
2
) ⊢∃x∃y¬R(x) ∧¬R(y) ∧R(xy)
where F1 = ¬R(
√
2), F2 = R(
√
2
√
2
√
2
), F3 = ∃x∃y(¬R(x) ∧¬R(y) ∧R(xy)) and
π1 =

A Sequent-Calculus Based Formulation
65
R(
√
2
√
2) ⊢R(
√
2
√
2)
¬r
⊢¬R(
√
2
√
2), R(
√
2
√
2)
(π′
1)
¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2) ∧R(
√
2
√
2
√
2
) ∧r
¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2
√
2
), R(
√
2
√
2)
∃r
¬R(
√
2), R(
√
2
√
2
√
2
) ⊢∃y(¬R(
√
2
√
2) ∧¬R(y) ∧R(
√
2
√
2y
)), R(
√
2
√
2) ∃r
¬R(
√
2), R(
√
2
√
2
√
2
) ⊢∃x∃y(¬R(x) ∧¬R(y) ∧R(xy)), R(
√
2
√
2)
π′
1 is
¬R(
√
2) ⊢¬R(
√
2)
R(
√
2
√
2
√
2
) ⊢R(
√
2
√
2
√
2
) ∧r
¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2) ∧R(
√
2
√
2
√
2
)
and π2 =
¬R(
√
2) ⊢¬R(
√
2)
¬R(
√
2) ⊢¬R(
√
2)
R(
√
2
√
2) ⊢R(
√
2
√
2) ∧r
¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧R(
√
2
√
2) ∧r
¬R(
√
2), ¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2) cl
¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)
wl
R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)
∃r
R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
⊢∃y(¬R(
√
2) ∧¬R(y) ∧R(
√
2
y)) ∃r
R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢∃x∃y(¬R(x) ∧¬R(y) ∧R(xy))
Consider the minimal translation of π2 in order to obtain the critical formulas:
in a ﬁrst step, π2 is translated into π′
2:
¬R(
√
2) ⊢¬R(
√
2)
¬R(
√
2) ⊢¬R(
√
2)
R(
√
2
√
2) ⊢R(
√
2
√
2) ∧r
¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧R(
√
2
√
2) ∧r
¬R(
√
2), ¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2) cl
¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)
wl
R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)
fvr
ν : R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
⊢¬R(
√
2) ∧¬R(f(
√
2)) ∧R(
√
2
f(√
(2))) ∃r
R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢∃x(¬R(x) ∧¬R(f(x)) ∧R(xf(x)))
where S∃(ν) = {(¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)) →(¬R(
√
2) ∧¬R(f(
√
2)) ∧
R(
√
2
f(√
(2))))}, Δ(ν) = {f}, Γ(ν) = ∅. To eliminate the second ∃inference we
construct π′′
2 =

66
M. Baaz et al.
¬R(
√
2) ⊢¬R(
√
2)
¬R(
√
2) ⊢¬R(
√
2)
R(
√
2
√
2) ⊢R(
√
2
√
2) ∧r
¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧R(
√
2
√
2) ∧r
¬R(
√
2), ¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2) cl
¬R(
√
2), R(
√
2
√
2) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)
wl
R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)
fvr
ν : R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
⊢¬R(
√
2) ∧¬R(f(
√
2)) ∧R(
√
2
f(√
(2))) fvr
μ : R(
√
2
√
2), ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(d) ∧¬R(f(d)) ∧R(df(d))
and S∃(μ) = S∃(ν) ∪{(¬R(
√
2) ∧¬R(f(
√
2)) ∧R(
√
2
f(√
(2)))) →(¬R(d) ∧
¬R(f(d)) ∧R(df(d)))}, Δ(ν) = {f, d} and Γ(ν) = {f < d}. The same transfor-
mation is performed on π1, hence the set of critical formulas is {C1, C2, C3, C4},
where
C1 = (¬R(
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2)) →
(¬R(
√
2) ∧¬R(f(
√
2)) ∧R(
√
2
f(
√
2)))
C2 = (¬R(
√
2
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2
√
2
)) →
(¬R(
√
2
√
2) ∧¬R(f(
√
2
√
2)) ∧R(
√
2
√
2
f(
√
2
√
2)
))
C3 = (¬R(
√
2) ∧¬R(f(
√
2)) ∧R(
√
2
f(
√
2))) →
(¬R(d) ∧¬R(f(d)) ∧R(df(d)))
C4 = (¬R(
√
2
√
2) ∧¬R(f(
√
2
√
2)) ∧R(
√
2
√
2
f(
√
2
√
2)
)) →
(¬R(d) ∧¬R(f(d)) ∧R(df(d)))
The function variable proof is
C1, C2, C3, C4, ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(d) ∧¬R(f(d)) ∧R(df(d)).
5
A New Version of the Extended First ε-Theorem
In this section we make use of the partial order on terms and thus deﬁne a new
elimination order, leading to a nonelementary speed-up of the computation of
Herbrand disjunctions.
Lemma 2 (Hilbert’s Ansatz in the new format). Let
A(t1) →A(e), . . . , A(tr) →A(e), Γ ⊢Δ
be a valid sequent, where A(t1) →A(e), . . . , A(tr) →A(e) are critical formulas
and e is a term. Then the critical formulas and e can be eliminated and we
obtain a valid sequent (Γσ1, . . . , Γσr, Γ ⊢Δσ1, . . . , Δσr, Δ){e ←c} where σi =
{e ←ti} and c is a ﬁxed constant. (Analogously for critical formulas of the form
A(e) →A(t1), . . . , A(e) →A(tr)).

A Sequent-Calculus Based Formulation
67
Proof. Analogous to the proof of Lemma 1.
Theorem 2 (function
variable
elimination
theorem).
Let
F
=
C1, . . . , Cr, A1, . . . , Am ⊢Am+1, . . . , An be a function variable proof with Δ(F)
and Γ(F). Then F can be transformed into a valid sequent without function vari-
ables . . . , Aiσ1
i , . . . , Aiσr1
i , . . . ⊢. . . , Ajσ1
j , . . . , Ajσrj
j , . . . where σu
v replace terms
with outermost function variables by terms without function variables.
Proof. Let F = C1, . . . , Cr, A1, . . . , Am ⊢Am+1, . . . , An be a function variables
proof. By Hilbert’s Ansatz we may eliminate any speciﬁc critical function term
and all critical formulas belonging to it. The problem is that the substitution
might render other critical formulas into formulas which are not critical formulas
any more. Consider e.g. a critical formula A(gQ(t(s))) →A(gQ(t(f∃(u1, . . . ,
um)))) where both gQ(t(f∃(u1, . . . , um))) and f∃(u1, . . . , um) are critical terms.
If we eliminate gQ(t(f∃(u1, . . . , um))) before f∃(u1, . . . , um) we might obtain the
spoiled formula A(gQ(t(s))) →A(h), similar for the left part of the implication.
This situation will not occur if we always eliminate critical formulas belonging
to a Γ-maximal function variable (here condition 3 of Deﬁnition 4 is applied).
Furthermore, it cannot occur that critical formulas with diﬀerent heads belong to
one critical term. This is ensured by condition 4 of Deﬁnition 4. (Indeed, if during
the elimination process diﬀerent critical terms become equal, the heads have to
become equal too as the unifying substitution is instance of the most general
uniﬁer existing by condition 4 of Deﬁnition 4). This ensures the soundness of the
elimination procedure. To ensure the termination of the elimination procedure
we will order the critical terms fQ(t) belonging to a maximal function variable
fQ according to the subterm property and always eliminate maximal terms fQ(t)
under this partial order.
Example 5. (Example 1.3 continued.) The critical formulas cannot be eliminated
from A(c) →A(eQ), ¬A(d) →¬A(eQ) ⊢A(c) →A(d) with critical function
variable eQ as A(c) →A(d) is the only possible Herbrand disjunction, but
A(c) →A(d) is not valid. This shows that condition 4 of Deﬁnition 4 is essential
for the application of variants of Hilbert’s Ansatz.
Corollary 1. The function variable elimination theorem constructs a Herbrand
sequent for ∀x1A1, . . . , ∀xmAm ⊢∃xm+1Am+1, . . . , ∃xnAn, where Ai for 1 ≤i ≤
n is quantiﬁer-free.
Note that the result of the function variable elimination theorem can also be used
to construct Herbrand expansions in case the weak quantiﬁers are positioned
inﬁx. This is done by considering the resulting sequent as an iterated conjunction
implying an iterated disjunction and moving conjunctions and disjunctions inside
if necessary. The size of each resulting conjunction and disjunction is obviously
limited by the number of formulas in the original sequent (cf. [1]).
Corollary 2. Let F = C1, . . . Cn, Π∗⊢Δ∗be a function variable proof with
Δ(F) and Γ(F), where Π∗and Δ∗are function variable translations of instances
by restricted function uniﬁers of Π and Δ, Π and Γ contain only weak quanti-
ﬁers. Then Π ⊢Δ is valid.

68
M. Baaz et al.
Theorem 2 induces the following non-deterministic algorithm.
Deﬁnition 8
begin % algorithm AlgNew
1. let F = C1, . . . , Cn, Π ⊢Δ be a function variable proof with Δ∗
0(F) = Δ(F)
and Γ(F) and deﬁne S0 = C1, . . . , Cn, F ′
0 = Π, F ′′
0 = Δ and let k = 0;
2. check whether F ′
k ⊢F ′′
k is a tautology, if yes substitute all remaining
function variable terms by the ﬁxed constant c and terminate AlgNew;
3. delete A →A from Sk. Let S′
k be the result.;
4. choose Γ-maximal function symbols f1, . . . , fn in Δ∗
k(F);
5. order the critical terms e1, . . . , er (which have an outermost function
symbol among f1, . . . , fn) by the subterm property and eliminate a maximal
ei according to the modiﬁcation in Hilbert’s Ansatz. Delete the critical
formulas S(ei) belonging to ei. Let σi1 . . . σil be the corresponding
substitutions. Sk+1 = (S′
k −S(ei))σi1λ . . . (S′
k −S(ei))σilλ,
F ′
k+1 = F ′
kσi1λ . . . F ′
kσilλ, F ′
kλ, F ′′
k+1 = F ′′
k σi1λ . . . F ′′
k σilλ, F ′′
k λ,
where λ is ei ←c for the ﬁxed constant c.
Repeat this operation until there are no critical terms with outermost
function symbols f1 . . . fn. Let Δ∗
k+1 = Δ∗
k −{f1, . . . , fn}. Proceed with 2.;
end.
Note that the original elimination algorithm for ε/τ terms can be considered as
instance of this algorithm using a more deterministic order of terms.
Example 6. Example 4 continued. We have f < d and proceed with the elimina-
tion procedure:
1. Eliminate d by eliminating C3 and C4 via {d ←
√
2} and {d ←
√
2
√
2}:
C1, C2, ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2)∧¬R(f(
√
2))∧R(
√
2
f(
√
2)), ¬R(
√
2
√
2)
∧¬R(f(
√
2
√
2)) ∧R(
√
2
√
2
f(
√
2
√
2)
).
2. Eliminate f by eliminating C1, C3:
(a) Eliminate C3 via {f(
√
2) ←
√
2}: C2, ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2) ∧
¬R(
√
2) ∧R(
√
2
√
2), ¬R(
√
2
√
2) ∧¬R(f(
√
2
√
2)) ∧R(
√
2
√
2
f(
√
2
√
2)
).
(b) Eliminate C2 via {f(
√
2
√
2) ←
√
2}: ¬R(
√
2), R(
√
2
√
2
√
2
) ⊢¬R(
√
2) ∧
¬R(
√
2) ∧R(
√
2
√
2), ¬R(
√
2
√
2) ∧¬R(
√
2) ∧R(
√
2
√
2
√
2
).
Example 7 illustrates the advantage of the nonextensionality of the new
method, which in fact may lead to shorter Herbrand disjunctions and a nonele-
mentary speed-up without using the eﬀects of the partial order of our algorithm.
Example 7. Let c, d be constants and a, u variables. Consider the proof Ψ =

A Sequent-Calculus Based Formulation
69
(Ψ1)
A ⊢B, C
(Ψ2)
B ⊢∃x(P(x) ∨E)
cut
A ⊢C, ∃x(P(x) ∨E)
(Ψ3)
C ⊢∃x(P(x) ∨F)
cut
A ⊢∃x(P(x) ∨E), ∃x(P(x) ∨F)
where A = P(c) ∨P(d), B = ∃xP(x) ∨E, C = ∃xP(x) ∨F and Ψ1 =
P(c) ⊢P(c)
∃r
P(c) ⊢∃xP(x)
∨r
P(c) ⊢∃xP(x) ∨E
P(d) ⊢P(d)
∃r
P(d) ⊢∃xP(x)
∨r
P(d) ⊢∃xP(x) ∨F
∨l
P(c) ∨P(d) ⊢∃xP(x) ∨E, ∃xP(x) ∨F
Ψ2 =
P(a) ⊢P(a)
∨r
P(a) ⊢P(a) ∨E
∃r
P(a) ⊢∃x(P(x) ∨E)
∃l
∃xP(x) ⊢∃x(P(x) ∨E)
E ⊢E
∨r
E ⊢P(a) ∨E
∃r
E ⊢∃x(P(x) ∨E) ∨l
∃xP(x) ∨E ⊢∃x(P(x) ∨E)
Ψ3 =
P(u) ⊢P(u)
∨r
P(u) ⊢P(u) ∨F
∃r
P(u) ⊢∃x(P(x) ∨F)
∃l
∃xP(x) ⊢∃x(P(x) ∨F)
F ⊢F
∨r
F ⊢P(u) ∨F
∃r
F ⊢∃x(P(x) ∨F) ∨l
∃xP(x) ∨F ⊢∃x(P(x) ∨F)
After the minimal transformation a function variable proof Ψ ′ is obtained: Ψ ′ =
C1, C2, C3, C4, P(c) ∨P(d) ⊢P(e1) ∨E, P(e2) ∨F, where C1 = P(c) →P(e3),
C2 = P(d) →P(e4), C3 = P(e3) ∨E →P(e1) ∨E and C4 = P(e4) ∨F →
P(e2)∨F are the critical formulas and Δ(Ψ ′) = {e1, e2, e3, e4}. After elimination
and contraction we obtain P(c)∨P(d) ⊢P(c)∨E, P(d)∨F. Note that this result
is obtained with any elimination procedure.
In the usual ε-formalism e3 and e4 coincide. The ε/τ-proof (written in sequent
notation) is D1, D2, D3, D4, P(c) ∨P(d) ⊢P(f1) ∨E, P(f2) ∨F, where D1 =
P(c) →P(f), D2 = P(d) →P(f), D3 = P(f) ∨E →P(f1) ∨E and D4 =
P(f) ∨F →P(f2) ∨F, where f ∼εxP(x), f1 ∼εx(P(x) ∨E) and f2 ∼
εx(P(x) ∨F). After elimination and contraction we obtain the longer Herbrand
sequent P(c) ∨P(d) ⊢P(c) ∨E, P(d) ∨E, P(c) ∨F, P(d) ∨F. Again, this result
is obtained with any elimination procedure.
6
Complexity Analysis
In this section we analyze the computational complexity of the elimination of
ε/τ-terms and compare the algorithms AlgOld and AlgNew. The worst-case
complexity of the elimination procedures is inherently nonelementary (like for
cut-elimination) because the size of the shortest Herbrand sequents Sn corre-
sponding to proofs ϕn cannot be bounded in the length of ϕn.

70
M. Baaz et al.
Deﬁnition 9. The complexity of a formula is the number of subformula occur-
rences in it. The complexity of a sequent is the sum of the complexities of the
formula occurrences in it. The complexity of a proof is the sum of the complexities
of the sequents occurring in it.
Theorem 3. There exists a sequence of proofs ψn s.t. the ε/τ-elimination via
AlgOld requires a computing time > s(n)/2 (where s(0) = 1, s(k + 1) = 2s(k) for
al k ≥0) while the computing time via AlgNew is bounded by Mnk for constants
M, k.
Proof. Consider the Statman sequence ϕn of Γn ⊢An as deﬁned in [5]. Replace
all atoms s = t in ϕn by a formula ∃x∃yP(c, x, y, s, t) where c is a new constant
symbol and P is a 5-ary predicate symbol. We obtain a proof sequence ϕ′
n of
Γ ′
n ⊢A′
n. In the next step replace all axioms of the form ∃x∃yP(c, x, y, s, t) ⊢
∃x∃yP(c, x, y, s, t) by their obvious LK-derivation from other atomic axioms
P(c, x1, x2, s, t) ⊢P(c, x1, x2, s, t):
P(c, x1, x2, s, t) ⊢P(c, x1, x2, s, t)
∃r
P(c, x1, x2, s, t) ⊢∃yP(c, x1, y, s, t)
∃r
P(c, x1, x2, s, t) ⊢∃x∃yP(c, x, y, s, t)
∃l
∃yP(c, x1, y, s, t) ⊢∃x∃yP(c, x, y, s, t)
∃l
∃x∃yP(c, x, y, s, t) ⊢∃x∃yP(c, x, y, s, t)
We thus obtain a sequence ϕ′′
n of Γ ′
n ⊢A′
n. It is obvious that the Herbrand
complexity of ψn is the same as that of ϕn itself. Now we deﬁne the following
LK-proof sequence ψn:
(ϕ′′
n)
Γ ′
n ⊢A′
n
wr
Γ ′
n ⊢A′
n, P(c, c, c, c, c)
∃r
Γ ′
n ⊢A′
n, ∃xP(x, x, x, x, x)
wl
P(c, c, c, c, c), Γ ′
n ⊢A′
n, ∃xP(x, x, x, x, x)
Then we transform ψn to its LK∗-version ψ∗
(ϕ′′∗
n )
Γ ∗
n ⊢A∗
n
wr
Γ ∗
n ⊢A∗
n, P(c, c, c, c, c)
fvr
Γ ∗
n ⊢A∗
n, P(d, d, d, d, d)
wl
P(c, c, c, c, c), Γ ∗
n ⊢A∗
n, P(d, d, d, d, d)
where ϕ′′∗
n
is the LK∗-version of ϕ′′
n. Now Δ(ψ∗
n) = Δ(ϕ′′∗
n ) ∪{d} and the set
of critical formulas S(ψ∗
n) = S(ϕ′′∗
n ) ∪{P(c, c, c, c, c) →P(d, d, d, d, d)}. Note
that in our partial ordering d ̸< g for all g ∈Δ(ϕ′′∗
n ) and d is locally maximal.
So our (nondeterminisitc) algorithm AlgNew may eliminate the term d, thus

A Sequent-Calculus Based Formulation
71
obtaining the valid sequent P(c, c, c, c, c), Γ ∗
n ⊢A∗
n, P(c, c, c, c, c). In order to
obtain a sequent without function variable symbols we may replace all remaining
function terms by c. The whole procedure works in polynomial time in ||ψn||.
As ||ψn|| ≤2kn for a constant k we get a total time bound of ≤2k′n for a
constant k′.
AlgOld must ﬁrst eliminate all ε-terms of rank >1 before eliminating d. But
the elimination down to the innermost quantiﬁers ∃x∃yP(c, x, y, s, t) already
produces a sequence of Herbrand sequents Sn (still containing ε-terms) of ψn;
this sequence Sn must be of size >s(n)/2 for s(0) = 1, s(k + 1) = 2s(k) for
all k and thus is nonelementary. Therefore there is no elementary bound of the
computing time of AlgOld in n.
7
Conclusion
This paper can be considered as a ﬁrst approach to an eﬀective algorithmic
formulation of the computational content of the extended ﬁrst ε-theorem. Addi-
tional reﬁnements such as a restriction of the function variables in the sense of the
Andrews Skolemization (see [2,3]) are possible. Additional research may restrict
the application of the tautology check in the algorithm without inﬂuencing its
eﬃciency.
Acknowledgments. Partially supported by FWF grants P-26976-N25, I-2671-N35
and the Czech-Austrian project MOBILITY No. 7AMB17AT054.
References
1. Aguilera, J.P., Baaz, M.: Unsound inferences
make proofs shorter. CoRR,
abs/1608.07703 (2016)
2. Andrews, P.B.: Resolution in type theory. In: Siekmann, J.H., Wrightson, G. (eds.)
Automation of Reasoning. Symbolic Computation (Artiﬁcial Intelligence), pp. 487–
507. Springer, Heidelberg (1971). https://doi.org/10.1007/978-3-642-81955-1 29
3. Andrews, P.B.: Theorem proving via general matings. J. ACM (JACM) 28(2), 193–
214 (1981)
4. Baaz, M., Hetzl, S., Weller, D.: On the complexity of proof deskolemization. J.
Symbolic Logic 77(2), 669–686 (2012)
5. Baaz, M., Leitsch, A.: On skolemization and proof complexity. Fundamenta Infor-
maticae 20(4), 353–379 (1994)
6. Baaz, M., Leitsch, A.: Cut normal forms and proof complexity. Ann. Pure Appl.
Logic 97(1–3), 127–177 (1999)
7. Hilbert, D., Bernays, P.: Grundlagen der Mathematik II (1939)
8. Luckhardt, H.: Herbrand-analysen zweier Beweise des Satzes von Roth: Polynomiale
Anzahlschranken. J. Symbolic Logic 54, 234–263 (1989)
9. Moser, G., Zach, R.: The epsilon calculus and Herbrand complexity. Stud. Logica.
82(1), 133–155 (2006)

Angluin Learning via Logic
Simone Barlocco and Clemens Kupke(B)
Computer and Information Sciences, University of Strathclyde, Glasgow, Scotland
{simone.barlocco,clemens.kupke}@strath.ac.uk
Abstract. In this paper we will provide a fresh take on Dana Angluin’s
algorithm for learning using ideas from coalgebraic modal logic. Our work
opens up possibilities for applications of tools & techniques from modal
logic to automata learning and vice versa. As main technical result we
obtain a generalisation of Angluin’s original algorithm from DFAs to
coalgebras for an arbitrary ﬁnitary set functor T in the following sense:
given a (possibly inﬁnite) pointed T-coalgebra that we assume to be
regular (i.e. having an equivalent ﬁnite representation) we can learn its
ﬁnite representation by asking (i) “logical queries” (corresponding to
membership queries) and (ii) making conjectures to which the teacher
has to reply with a counterexample. This covers (a known variant) of the
original L* algorithm and the learning of Mealy/Moore machines. Other
examples are bisimulation quotients of (probabilistic) transition systems.
Keywords: Automata learning · Coalgebra · Modal logic
1
Introduction
Coalgebra studies “generated behaviour” that can be observed when interacting
with a system. A lot of progress has been made thus far to formalise behaviour
and to create languages that allow to specify and reason about it (cf. e.g. [1]).
Intriguingly little, however, has been done to formalise the process of making
observations and of using these observations to learn how a system works.
This has changed thanks to a series of recent work [2–5] but the connections
between coalgebra & learning are still far from being completely understood. In
this paper we will describe one such connection between the above mentioned
coalgebraic speciﬁcation languages (aka coalgebraic modal logics) and the well-
known L∗algorithm [6] for learning deterministic ﬁnite automata (DFA).
This algorithm constructs a minimal DFA accepting a (at the beginning
unknown) regular language by asking a teacher membership queries of the form
“is word w in the language?” and by making conjectures for what the lan-
guage/DFA is, to which the teacher replies with a counterexample in case the
conjecture is false. A central role in the algorithm is played by so-called tables
Supported by EPSRC grant EP/N015843/1.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 72–90, 2018.
https://doi.org/10.1007/978-3-319-72056-2_5

Angluin Learning via Logic
73
that essentially consist of two sets of ﬁnite words S and E of which the ﬁrst cor-
responds to the states of the constructed DFA and the second set corresponds
to observations or tests that we are performing on states.
The use of tests shows that the connection to logic is not at all surprising. A
bit more surprising was for us the observation that closed & consistent tables can
be best understood using the notion of a ﬁltration from modal logic. We will not
discuss this observation in detail - instead we will describe a generalisation of the
L∗algorithm to coalgebras that was made possible by it. Our “Lco algorithm”
allows - in principle - the learning of regular coalgebras for an arbitrary ﬁnitary
set functor. This generalisation of L∗is the main contribution of this paper.
1.1
What the Algorithm Learns
The classical L∗algorithm looks very much like a bottom up procedure. The
starting point of the algorithm are two singleton sets that grow step-by-step
until the desired DFA has been learned. It is instructive, however, to think of
the algorithm as follows: The regular language L ⊆Σ∗that we intend to learn
can be thought as represented by the inﬁnite DFA
⟨o, δ⟩: Σ∗→2 × (Σ∗)Σ
where o(w) = 1 iﬀw ∈L and δ(w)(a) = w·a for all w ∈Σ∗, a ∈Σ. The assump-
tion that L is a regular language can be rephrased by stating that the pointed
coalgebra (Σ∗, ⟨o, δ⟩, λ) is behaviourally equivalent to a ﬁnite well-pointed coal-
gebra [7]. The aim of the algorithm is to learn this ﬁnite well-pointed coalgebra
using queries that can be asked concerning the given inﬁnite coalgebra. Our
generalisation of Angluin’s algorithm looks thus as follows: We are given a (pos-
sibly inﬁnite) pointed T-coalgebra (X, γ, x) (corresponding to the language L)
and we assume that (X, γ, x) is regular, i.e. behaviourally equivalent to a ﬁnite
well-pointed T-coalgebra (Y, δ, y). The goal of the algorithm is to learn (Y, δ, y).
1.2
Means to Learn
The central device for learning in our setting is logic: we assume that we are pro-
vided with an expressive modal language that allows to characterise coalgebras
up-to behavioural equivalence. The learner is able to ask two types of queries:
– Logical queries of the form “is formula ϕ true at some state x′ ∈X?”
– Conjectures of the form “is this the correct well-pointed T-coalgebra?”
Logical queries are answered truthfully with Yes or No by the teacher, con-
jectures are either conﬁrmed or the teacher provides a counterexample in the
shape of a formula ψ ∈F(Λ) that can be used to distinguish the point of the
conjectured coalgebra from the point x of the coalgebra that we are trying to
learn.

74
S. Barlocco and C. Kupke
1.3
Related Work
Within the large body of literature on Angluin learning [6], the line of research
closely related to our paper is [2–5] which applies categorical techniques to
automata learning. There are, however, important diﬀerences to our work. On
the one hand, our logic-based methodology allows us to make the L∗algorithm
parametric in the system type, which is less clear in the cited articles. On the
other hand, our results are limited to the category of sets - results such as learn-
ing linear weighted or nominal automata [2,5] are currently out of reach for our
approach. Connections between modal logic and automata theory are of course
well-known [8], but the link between modal logic and automata learning that we
are describing is, to the best of our knowledge, new.
2
Preliminaries
We assume that the reader is familiar with basic category theory [9] and coalge-
bra [10]. We brieﬂy recall some deﬁnitions from coalgebra & modal logic that will
play a central role in the paper. Throughout the paper we will be working with
an arbitrary ﬁnitary set functor T and we will assume - without loss of general-
ity [7,11] - that T preserves intersections and for any sets X, Y with X ⊆Y the
inclusion map ιX,Y : X →Y gets mapped to the inclusion ιT X,T Y (in particular,
we have TX ⊆TY ). Under this assumption ﬁnitariness of the functor T means
that for all sets X and all elements t ∈TX there is a ﬁnite subset X′ ⊆X such
that t ∈TX′. Another functor that will be playing an important role in our paper
is the contravariant power set functor P : Setop →Set that maps a set X to the
collection PX of subsets of X and a function f : X →Y to the inverse image
function Pf = f −1 where for V ⊆Y we have f −1(V ) = {x ∈X | f(x) ∈V }.
Finally, for a set X we denote by #X the cardinality of X and we write X′ ⊆ω X
if X′ is a ﬁnite subset of X.
2.1
Coalgebra
A T-coalgebra is a pair (X, γ) where X is a set and γ : X →TX is a function. A
T-coalgebra morphism from a T-coalgebra (X, γ) to another T-coalgebra mor-
phism (Y, δ) is a function f : X →Y such that the following diagram commutes.
X
γ

f
 Y
δ

TX
T f  TY
We call two states x1 ∈X1 and x2 ∈X2 of two T-coalgebras (X1, γ1) and
(X2, γ2) behaviourally equivalent1 if there exists a T-coalgebra (Y, δ) and coal-
gebra morphisms fi : (Xi, γi) →(Y, δ) for i = 1, 2 such that f1(x1) = f2(x2).
1 Readers should think of “behavioural equivalence” as a general notion of bisimilarity.
In all concrete examples in this paper both notions of equivalence coincide.

Angluin Learning via Logic
75
In this case we write x1 ↔T x2 or simply x1 ↔x2. A pointed T-coalgebra is a
triple (X, γ, x) where (X, γ) is a T-coalgebra and x ∈X is a distinguished point
(to be thought of as the “initial state”). A morphism f : (X, γ, x) →(Y, δ, y) is
a T-coalgebra morphism f : (X, γ) →(Y, δ) such that f(x) = y. Two pointed
coalgebras (X, γ, x) and (Y, δ, y) are behaviourally equivalent if x ↔y. When
discussing concrete constructions on transition systems it is important to be
able to express the notion of a “successor state”, i.e. a state that can be reached
after performing one step in the transition structure. Coalgebra does not come
with such a notion from the outset, but it is well-known that successors can be
formalised via the notion of base.
Deﬁnition 1. Given a ﬁnitary set functor T and an element t ∈TX, we deﬁne
BaseT
X(t) :=

{Y ⊆ω X | t ∈TY }.
Whenever T and X are clear from the context we will drop the super- and sub-
script, respectively, and simply write Base(t).
Fact 1. Let T be a ﬁnitary set functor, let X be a set and let t ∈TX. Then
t ∈TBaseT
X(t) and for any proper subset X′ ⊂BaseT
X(t) we have t ̸∈TX′.
The notion of base can be used to associate with any T-coalgebra a graph that
can be used to give a concrete representation of reachability.
Deﬁnition 2 ([7]). Let (X, γ) be a T-coalgebra. The canonical graph (X, canγ :
X →PfX) is deﬁned by putting canγ(x) := BaseT
X(γ(x)) for all x ∈X.
Note that we can conﬁne ourselves to ﬁnitely branching canonical graphs as
we are considering only ﬁnitary set functors.
Example 1. 1. T = A × Id where A is a set and Id is the identity functor. In
this case BaseT
X((a, x)) = {x} for (a, x) ∈A × X.
2. T = 2 × IdA where A is a ﬁnite set (the “alphabet”). Then BaseT
X((i, f)) =
{fa | a ∈A} for (i, f) ∈TX.
3. Let T = Dω where DωX denotes the collection of discrete probability distrib-
utions over X with ﬁnite support, i.e. DωX = {μ : X →[0, 1] | 
x∈X μ(x) =
1, supp(μ) ﬁnite} and for a function f : X →Y and μ : X →[0, 1] we have
(Dωf)(μ)(y) = 
f(x)=y μ(x), where supp(μ) = {x ∈X | μ(x) ̸= 0} denotes
the support of μ. In this case BaseDω
X (μ) = supp(μ). Note that while Dω does
not satisfy our condition that X ⊆Y implies DωX ⊆DωY , an isomorphic
modiﬁcation of Dω does, e.g. the functor D′
ω that maps a set X to the set
of partial functions μ : X ⇀(0, 1] with supp(μ) ﬁnite and 
x∈X μ(x) = 1.
We stick with the functor Dω as it is commonly used and as this technical
subtlety is irrelevant for this speciﬁc example.
We are going to describe a learning algorithm that learns a minimal ﬁnite
representation of the behaviour of a given pointed coalgebra. Minimal here means
that the learned pointed coalgebra should not have any proper subcoalgebras or
proper quotients. Let us ﬁrst recall those notions.

76
S. Barlocco and C. Kupke
Deﬁnition 3. Let (X, γ, x) be a pointed T-coalgebra. We say (Y, δ, y) is a quo-
tient of (X, γ, x) if there is a surjective morphism q : (X, γ, x) →(Y, δ, y). We say
(Y, δ, y) is a subobject of (X, γ, x) if there is an injection m : (Y, δ, y) →(X, γ, x).
A quotient or subobject (Y, δ, y) of (X, γ, x) is said to be proper if (Y, δ, y) is not
isomorphic to (X, x, γ).
Minimality of a pointed coalgebra is captured by the following notion from [7].
Deﬁnition 4. A pointed T-coalgebra (X, γ, x) is called well-pointed if it is sim-
ple and reachable, i.e. if it does not have proper quotients or proper subcoalgebras.
Example 2. 1. For T = 2×( )A, the (ﬁnite) well-pointed T-coalgebras are DFAs
where each state is reachable from the initial state and where no two states
represent the same (regular) language.
2. For T = Pω (where PωX = {X′ | X′ ⊆ω X}) well-pointed T-coalgebras are
ﬁnitely-branching Kripke frames with a designated state such that each state
is reachable from the designated state and such that no two distinct states
are bisimilar.
2.2
Coalgebraic Modal Logic
Coalgebraic modal logics [12,13] are a family of logics that allow to express prop-
erties of pointed coalgebras that are invariant under behavioural equivalence. We
ﬁrst recall the basic deﬁnitions and state an important fact on expressivity of
these logics. Later in the paper formulas will serve as tests that allow to learn a
given (pointed) coalgebra. The language of coalgebraic modal logic is determined
by choosing a collection of modal operators - the so-called similarity type:
Deﬁnition 5. A (modal) similarity type is a set of modal operators with arities.
If Λ is a similarity type, a Λ-structure consists of an endofunctor T : Set →Set,
together with an assignment of an n-ary predicate lifting, that is, a natural
transformation of type [[♥]] : (P)n →P ◦T where P : Set →Setop is the
contravariant powerset functor, to every n-ary operator ♥∈Λ.
The syntax is now given as propositional modal logic, where the modal operators
are the elements of Λ. To keep things simple we treat propositional variables as
nullary predicate liftings. The deﬁnition of the semantics is also standard.
Deﬁnition 6. The language induced by a modal similarity type Λ is the set
F(Λ) of formulas given by
F(Λ) ∋ϕ, ψ :: = ⊤| ϕ ∧ψ | ¬ϕ | ♥(ϕ1, . . . , ϕn)
(♥∈Λ n-ary)
Given a Λ-structure T and a T-coalgebra (X, γ), the semantics of ϕ ∈F(Λ) is
inductively given by
[[⊤]](X,γ) = X
[[ϕ ∧ψ]](X,γ) := [[ϕ]](X,γ) ∩[[ψ]](X,γ)
[[¬ϕ]](X,γ) := X \ [[ϕ]](X,γ),
[[♥(ϕ1, . . . , ϕn)]](X,γ) := Pγ ◦[[♥]]X([[ϕ1]](X,γ), . . . , [[ϕn]](X,γ)),
Instead of x ∈[[ϕ]](X,γ) we will often write (X, γ, x) |= ϕ or simply x |= ϕ. In
words “the pointed coalgebra (X, γ, x) satisﬁes ϕ”, or simply “x satisﬁes ϕ”.

Angluin Learning via Logic
77
The logics give rise to the notion of logical equivalence.
Deﬁnition 7. Let (X, γ) and (Y, δ) be T-coalgebras and let Σ ⊆F(Λ) be a set
of formulas. Two states x ∈X and y ∈Y are logically equivalent wrt Σ if for all
formulas ϕ ∈Σ we have x |= ϕ iﬀy |= ϕ. In this case we write x ≡Σ y. The
equivalence classes wrt ≡Σ on a coalgebra (X, γ) will be denoted by |x|Σ, i.e. we
put |x|Σ = {x′ ∈X | x′ ≡Σ x}. If Σ = F(Λ) is the set of all formulas we simply
write ≡for the equivalence and denote the equivalence class of some x by |x|.
The semantics of formulas of coalgebraic modal logic is invariant under behav-
ioural equivalence. An important stronger property that coalgebraic modal log-
ics often possess is expressivity, i.e. the property that logical equivalence implies
behavioural equivalence.
Deﬁnition 8. The language F(Λ) is called expressive if for all T-coalgebras
(X, γ) and (Y, δ) and all x ∈X, y ∈Y we have x ≡y iﬀx ↔y.
For a ﬁnitary set functor T we are always able to ﬁnd an expressive language,
cf. e.g. [14]. Many expressive coalgebraic modal logics have been considered in
the literature, we mention two examples - note that in both examples we do
not need the full Boolean structure of the language to obtain expressivity. Also
note that we are simply sketching the semantics of the logics without explicitly
explaining how its deﬁnition can be seen as special case of Deﬁnition 6.
Example 3. 1. For T = ( × O)I coalgebras correspond to so-called Mealy
machines [15] and we deﬁne:
F(Λ) ∋ϕ :: = ⊤| pi/o, i ∈I, o ∈O | [i]ϕ, i ∈I.
Given a T-coalgebra (X, γ), a state x ∈X and i ∈I, o ∈O, we put x |= pi/o if
π2(γ(x)(i)) = o. Intuitively, pi/o is true in x if the output of the coalgebra at
x on input i is equal to o. Furthermore we put x |= [i]ϕ if π1(γ(x)(i)) |= ϕ.
2. For T = PAt × Dω with At a set of propositional variables, coalgebras cor-
respond to probabilistic transition systems and an expressive language [16] is
given by
F(Λ) ∋ϕ :: = ⊤| p, p ∈At | ϕ1 ∧ϕ2 | Lqϕ, q ∈[0, 1],
where for a coalgebra (X, γ) we have x |= p if p ∈π1(γ(x)) and x |= Lqϕ if

x′ |= ϕ π2(γ(x))(x′) ≥q, in words, if the probability of reaching a successor
of x that makes ϕ true is at least q.
2.3
Logical Quotients
Given an expressive modal language F(Λ) for T, it is well known that we can
compute the maximal quotient of a coalgebra simply by identifying states that
satisfy the same modal formulas in F(Λ).

78
S. Barlocco and C. Kupke
Fact 2. Let (X, γ) be a T-coalgebra and let F(Λ) be an expressive language, let
|X| = {|x| | x ∈X} and deﬁne γFΛ : |X| →T|X| by putting γF(Λ)(|x|) :=
(T| |)(γ(x)). Then the logical quotient γFΛ is well-deﬁned and q : X →|X|
given by x →|x| is a T-coalgebra map that computes the maximal quotient of
(X, γ).
The proof of well-deﬁnedness can e.g. be found in [17]. That the quotient is
maximal is an immediate consequence of the fact that truth of modal formulas
is preserved by coalgebra morphisms. The method also allows us to obtain the
well-pointed coalgebra that is equivalent to a given pointed T-coalgebra.
Lemma 1. Let (X, γ, x) be a pointed T-coalgebra and let (Y, δ, x) be its smallest
pointed subcoalgebra. The logical quotient (|Y |, δF(Λ), |x|) is well-pointed.
Proof. First note that the smallest pointed subcoalgebra (Y, δ, x) exists as T
preserves intersections. It is reachable by deﬁnition. Therefore also its quotient
will be reachable because (i) it is easy to see that the canonical graph of the quo-
tient is a quotient of the canonical graph of (Y, δ, x) and (ii) by [7, Lemma 3.16]
reachability of its canonical graph implies reachability of a pointed T-coalgebra.
Furthermore the logical quotient of (Y, δ, x) is simple as any two distinct states
can be distinguished by a formula in F(Λ) and can thus not be behaviourally
equivalent. This implies that (|Y |, δF(Λ), |x|) is well-pointed (cf. Deﬁnition 4).
3
The Lco Algorithm
We ﬁrst describe the possible conﬁgurations of the algorithm. After that we
describe the algorithm parametric in a ﬁnitary set functor T. Finally we prove
termination and correctness of the algorithm. Throughout this section we assume
that we are given a pointed T-coalgebra (X, γ, x) whose ﬁnite representation we
are trying to learn. Furthermore we are given an expressive language F(Λ) for T.
3.1
Filtrations and Logical Tables
Following Angluin’s original terminology we will refer to conﬁgurations of our
algorithm as logical tables or simply as tables. First we need some terminology
concerning sets of formulas from F(Λ).
Deﬁnition 9. A set Σ ⊆F(Λ) is closed under taking subformulas or subfor-
mula closed if we have
– ϕ1 ∧ϕ2 ∈Σ implies ϕi ∈Σ for i ∈{1, 2}
– ¬ϕ ∈Σ implies ϕ ∈Σ, and
– for all ♥∈Λ we have ♥(ϕ1, . . . , ϕn) ∈Σ implies ϕi ∈Σ for all i ∈{1, . . . , n}.
Sets that are closed under taking subformulas are used in modal logic to compute
ﬁltrations of Kripke models and to prove a truth lemma for such ﬁltrations [18].
It turns out that a similar idea is at work in the L∗algorithm, although the
relevant construction is a modiﬁcation of the standard ﬁltration. We ﬁrst give a
coalgebraic account of the ﬁltrations that play a role in our algorithm.

Angluin Learning via Logic
79
Deﬁnition 10. Let (X, γ) be a T-coalgebra, let Σ ⊆F(Λ) be a subformula
closed set of formulas and let S ⊆X be a selection of points in X such that
1. for all x1, x2 ∈S we have x1 ̸≡Σ x2
2. for all x ∈S and all x′ ∈Base(γ(x)) we have |x′|Σ ∈|S|Σ
where |S|Σ = {|x|Σ | x ∈S}. The (S, Σ)-ﬁltration of (X, γ) has as carrier the
set |S|Σ and as coalgebra structure γS,Σ we deﬁne the map
γS,Σ(|x|Σ) := (T| |Σ)(γ(x))
where we view the operation of identifying equivalent points as a function | |Σ :
X →|X|Σ to which the functor T is applied.
Lemma 2. Under the conditions on (S, Σ) from the previous deﬁnition, the
(S, Σ)-ﬁltration of a T-coalgebra (X, γ) is well-deﬁned.
Proof. This follows as x ≡Σ x′ implies x = x′ and thus γ(x) = γ(x′) for all
x, x′ ∈S by condition 1 and as (T| |Σ)(γ(x)) ∈T|S|Σ as S satisﬁes condition 2.
Deﬁnition 10 is reminiscent of the deﬁnition of a logical quotient in Fact 2 - the
diﬀerences are that we select only one representant for each ≡Σ-equivalence class
and that a (S, Σ)-ﬁltration of a coalgebra is in general not a quotient. Instead a
weaker property holds: restricted to elements in S, the map | |Σ preserves truth
of formulas in Σ.
Lemma 3. Let (X, γ) be a T-coalgebra, let Σ ⊆F(Λ) be a subformula closed
set of formulas and let (|S|Σ, γS,Σ) be the (S, Σ)-ﬁltration of (X, γ) for some
suitable S ⊆X. Then for all x ∈S and all ϕ ∈Σ we have
(X, γ, x) |= ϕ
iﬀ
(|S|Σ, γS,Σ, |x|Σ) |= ϕ.
In particular, (|S|Σ, γS,Σ) is simple.
Proof. We prove the statement by induction on the structure of the formula ϕ. In
case ϕ = ⊤is obvious. Similarly, the Boolean cases ϕ = ψ1∧ψ2 and ϕ = ¬ψ easily
follow from the induction hypothesis. Suppose now that ϕ = ♥(ψ1, . . . , ψn).
We have x |= ♥(ψ1, . . . , ψn) iﬀγ(x) ∈[[♥]]X([[ψ1]](X,γ), . . . , [[ψn]](X,γ)) iﬀx ∈
Pγ

[[♥]]X([[ψ1]](X,γ), . . . , [[ψn]](X,γ))

. The last statement is by I.H. on the ψi’s
equivalent to
σ(x) ∈Pγ

[[♥]]X(P| |Σ([[ψ1]](|S|Σ,γS,Σ)), . . . , P| |Σ([[ψn]](|S|Σ,γS,Σ)))

which is by naturality of [[♥]] equivalent to
x ∈(Pγ ◦PT| |Σ)

[[♥]]|S|Σ([[ψ1]](|S|Σ,γS,Σ), . . . , [[ψn]](|S|Σ,γS,Σ))

which is equivalent to T| |Σ(γ(x)) ∈[[♥]]|S|Σ([[ψ1]](|S|Σ,γS,Σ)), . . . , [[ψn]](|S|Σ,γS,Σ))
which ﬁnally is equivalent to |x|Σ |= ♥(ψ1, . . . , ψn) as required.

80
S. Barlocco and C. Kupke
Given our observations on ﬁltrations we are now ready to introduce the tables
that will form the conﬁgurations of our algorithm.
Deﬁnition 11. A (logical) table is a pair (S, Σ) where S ⊆X and Σ ⊆F(Λ)
is a set of formulas that is closed under taking subformulas. A table (S, Σ) is
closed if for all x ∈S we have |Base(γ(x)|Σ ⊆|S|Σ. Finally we call (S, Σ) sharp
if for all x1, x2 ∈S we have x1 ̸= x2 implies x1 ̸≡Σ x2.
Remark 1. Readers familiar with the L∗algorithm will recognise the closedness
condition. The condition that a table is sharp implies the consistency require-
ment in Angluin’s work. Sharpness will be maintained by adding counterexam-
ples to the tests and not to the states, similar to what is done e.g. in [19].
3.2
Description of the Algorithm
Let (X, γ, x) be a pointed coalgebra that is behaviourally equivalent to a ﬁnite
well-pointed coalgebra and let F(Λ) be an expressive language. We will now
describe a procedure that allows to learn the well-pointed coalgebra by asking
queries to a teacher that knows (X, γ, x). Our algorithm will compute a closed
and sharp table (S, Σ)2 such that x ∈S and such that the pointed T-coalgebra
(|S|Σ, γS,Σ, |x|Σ) that is based on the (S, Σ)-ﬁltration of (X, γ, x) is the ﬁnite
quotient of a subcoalgebra of (X, γ, x) that contains x. The algorithm - depicted
in Algorithm 1 - makes the following steps:
1. The start table is ({x}, {⊤}) - the ﬁrst component ensures that the distin-
guished point of (X, γ, x) is represented, the second component equals {⊤}
to keep the formulation uniform as ⊤∈F(Λ) independently of the choice of
language.
2. At conﬁguration (S, Σ), check whether (S, Σ) is closed. If yes, jump to Step
4. If not, proceed with the next step.
3. Given a conﬁguration (S, Σ) that is not closed, pick an element x′ ∈S such
that |Base(γ(x′))|Σ ̸⊆|S|Σ. For all x′′ ∈Base(γ(x′)) check whether |x′′|Σ ∈
|S|Σ, i.e. whether the equivalence class of x′′ is already represented by some
other element of S. If not, then add x′′ to S. Otherwise check the next element
of Base(γ(x′)). Note that we are adding elements of Base(γ(x′)) one-by-one
to maintain sharpness of the table.
4. Given the closed conﬁguration (S, Σ), present the (S, Σ)-ﬁltration γS,Σ to
the teacher. If teacher accepts, the algorithm terminates. If teacher rejects,
she has to provide a counterexample, i.e. a formula ϕ ∈F(Λ) s.t. x |= ϕ
and |x|Σ ̸|= ϕ or vice versa. In this case we put Σ′ = Σ ∪Sub(ϕ) and the
algorithm continues at Step 3.2 with (S, Σ′).
2 Instead, we could use triples (S, Σ, |=S) to be in line with [6] but we decided to leave
the third “bookkeeping” component implicit.

Angluin Learning via Logic
81
Algorithm 1. The Lco algorithm with teacher (X, γ, x) and language F(Λ)
Initialize table T = (S, Σ), with S = {x} and Σ = {⊤}
⋆Check if T = (S, Σ) is closed
1 if Closed(T ) then
Given T closed
Conjecture: γS,Σ : |S|Σ →T|S|Σ
|x|Σ →(T| |Σ)(γ(x))
2
if Conjecture ==⊥then
Provide ϕ ∈F(Λ) s.t. x ⊨ϕ and |x| ⊭ϕ
Update Σ ←Σ ∪Sub(ϕ)
return T
Go to ⋆
else
return Aut(T )
else
Given T not closed
Pick x ∈S s.t. |Base(γ(x))|Σ ̸⊆|S|Σ
3
while Base(γ(x)) ̸= ∅do
Take y ∈Base(γ(x))
4
if |y| ∈|S|Σ then
Base(γ(x)) ←Base(γ(x)) \ {y}
else
Update S ←S ∪{y}
Base(γ(x)) ←Base(γ(x)) \ {y}
return T
Go to ⋆
3.3
Termination and Correctness
In this section we are going to prove termination and correctness of our Lco
algorithm. We ﬁrst state the theorem and sketch its proof. After that we will
provide the proofs for the necessary technical lemmas.
Theorem 3. Let (X, γ, x) be a pointed T-coalgebra and suppose (X, γ, x) is
behaviourally equivalent to a ﬁnite well-pointed T-coalgebra (Y, δ, y). Let F(Λ) be
an expressive language for T-coalgebras. The Lco algorithm with teacher (X, γ, x)
and test language F(Λ) terminates and returns the correct well-pointed coalgebra.
Proof. That the algorithm terminates can be seen as follows:
– The algorithm builds tables (S, Σ) where S is a subset of the carrier of the
smallest subcoalgebra of (X, γ, x) that contains x. Therefore the size of S is
bound by the number of elements of Y (Lemmas 4 and 5).
– Whenever a table is not closed, the algorithm will be able to close it. Whenever
the algorithm turns a table into a closed one, the size of S strictly increases
(Lemma 6).

82
S. Barlocco and C. Kupke
– Whenever the teacher provides a counterexample the resulting table will not
be closed (Lemma 7).
Collectively these claims show that the teacher eventually will accept the conjec-
ture that the algorithm produces. Correctness of the algorithm then follows: Let
(S, Σ) be a closed & sharp table. By Lemma 3 we have that the (S, Σ)-ﬁltration
(|S|Σ, γS,Σ, |x|Σ) of (X, γ, x) is simple. To see that it is reachable consider the
following diagram
TS
BaseT
S 
T | |Σ

PωS
Pω| |Σ

T|S|Σ BaseT
|S|Σ
 Pω|S|Σ
where | |Σ is the mapping to equivalence classes restricted to S ⊆X. Clearly | |Σ
is mono (due to sharpness of (S, Σ)) and thus we know from [7, Remark 2.49]
that the square commutes (and even forms a pullback). Whenever the algorithm
adds a state x′ to S we know that x′ ∈Base(γ(x′′)) for some x′′ ∈S that has
been already added at an earlier stage. Commutation of the diagram implies that
|x′|Σ ∈Base(T| |Σ(γ(x′′))) = Base(γS,Σ(|x′′|Σ)) where the equality is a conse-
quence of the deﬁnition of the ﬁltration. A routine induction argument together
with [7, Lemma 3.16] reducing reachability of the coalgebra to reachability of its
canonical graph can now be used to show that the (S, Σ)-ﬁltration is reachable
and hence well-pointed. If, in addition, the teacher accepts the (S, Σ)-ﬁltration
of (X, γ, x) we have that (X, γ, x) |= ϕ iﬀ(|S|Σ, γS,Σ, |x|Σ) |= ϕ for all formulas
ϕ ∈F(Λ). By expressivity of F(Λ) this means (X, γ, x) is behaviourally equiva-
lent to (|S|Σ, γS,Σ, |x|Σ), i.e. we have learned the correct well-pointed coalgebra.
3.4
Termination Lemmas
In this section we prove the claims from the proof of Theorem 3. In the following
let (X, γ, x) be a pointed T-coalgebra that is behaviourally equivalent to a ﬁnite
well-pointed coalgebra (Y, δ, y). We start by proving that states occurring in
tables are always taken from the reachable part of (X, γ, x).
Lemma 4. Let (S, Σ) be a table that is obtained in a run of the Lco algorithm
with teacher (X, γ, x). Then S is contained in the subcoalgebra of (X, γ) that is
generated by x.
Proof. Let (X′, γ↾X′, x) be the smallest pointed subcoalgebra of (X, γ, x). Clearly
we have Base(γ(x′)) ⊆X′ for all x′ ∈X as the coalgebra map γ restricts to a
map X′ →TX′. Now we can easily prove the claim on the number n of steps the
Lco algorithm was closing a table to reach the table (S, Σ). For n = 0 we have
S = {x} and obviously x ∈X′. For n = m + 1 there is a table (S′, Σ) such that
S is obtained from S by closing the table (S′, Σ). By I.H. we know that S′ ⊆X′

Angluin Learning via Logic
83
and by the deﬁnition of the algorithm we have S ⊆S′ ∪
x′∈S′ Base(γ(x′)). But
as we saw at the beginning of our proof the latter is a subset of X′ which shows
that S ⊆X′ as required.
Consequently, we obtain an upper bound for the number of elements of S for
each table S.
Lemma 5. Let (S, Σ) be a table computed by the Lco algorithm with teacher
(X, γ, x). Then #S ≤#Y .
Proof. By Lemma 1 we know that (Y, δ, y) is the quotient of the smallest pointed
subcoalgebra (X′, γ′, x) of (X, γ, x) and by the previous lemma we have S ⊆X′.
The quotient map from (X′, γ′) to (Y, δ) is a coalgebra morphism and preserves
the truth of modal formulas. Therefore, for any element of x′ ∈S ⊆X′ there
exists a y ∈Y such that x′ ≡y, in other words there is a function f : S →Y
such that x ≡f(x). We also know that (S, Σ) is sharp which means that x1 ≡y
and x2 ≡y implies x1 = x2. Therefore the function f : S →Y has to be injective
which shows that #S ≤#Y as required.
This ﬁnishes the argument for why there is a ﬁnite upper bound on the number
of states stored in a table. Let us now turn to what happens in case the current
table is not closed.
Lemma 6. Let (S, Σ) be a table computed by the Lco algorithm with teacher
(X, γ, x). If (S, Σ) is not closed then Lco computes a closed table (S′, Σ) such
that #S < #S′.
Proof. Suppose (S, Σ) is a table that is not closed. While (S, Σ) is not closed, the
Lco algorithm extends the collection of states S by elements of X as described
in the previous section. By Lemma 5 this can only happen ﬁnitely often which
implies that after ﬁnitely many additions to S the table will be closed as required.
Finally we need to investigate what happens in case the teacher is providing a
counterexample.
Lemma 7. Let (S, Σ) be a closed and sharp table computed by the Lco algorithm
with teacher (X, γ, x). If the teacher provides a counterexample ϕ, then (S, Σ′)
is not closed where Σ′ is the smallest set of formulas that contains Σ ∪{ϕ} and
that is closed under subformulas.
Proof. Suppose for a contradiction that (S, Σ′) is closed (obviously it will be
sharp). For every set Z ⊆X let fZ : |Z|Σ′ →|Z|Σ given by fZ(|x′|Σ′) := |x′|Σ
for all x′ ∈Z. Note this is well-deﬁned as Σ′ ⊇Σ and thus x1 ≡Σ′ x2 implies
x1 ≡Σ x2. We now claim that fS is a pointed T-coalgebra morphism from the
(S, Σ′)-ﬁltration of (X, γ, x) to its (S, Σ) ﬁltration. To check this we ﬁrst note
that fX ◦| |Σ′ = | |Σ. Let x′ ∈S be arbitrary. We calculate:
γS,Σ(fS(|x′|Σ′)) = γS,Σ(|x′|Σ) = (T| |Σ)(γ(x′)) = T(fX ◦| |Σ′)(γ(x′))
= TfX(T| |Σ′(γ(x′)))
T | |Σ′ (γ(x′)) ∈T |S|Σ′
=
TfS(T| |Σ′(γ(x′)))

84
S. Barlocco and C. Kupke
which shows that fS is indeed a pointed T-coalgebra morphism between the
ﬁltrations. This is, however, a contradiction to Σ′ containing a counterexample,
i.e. a formula ϕ ∈F(Λ) such that w.l.o.g. |x|Σ′ |= ϕ and |x|Σ ̸|= ϕ.
This ﬁnishes the proofs of the claims that are necessary to prove Theorem 3. In
summary, we have proved termination and correctness of our algorithm. Remark-
ably, if we measure the complexity of the algorithm in the number of logical
and equivalence queries, our algorithm meets similar bounds as Angluin’s L∗-
algorithm. The main diﬀerence is that the run-time of our algorithm also depends
on the maximal number of successors a state of the original coalgebra has - in
the case of ﬁnite automata the branching is bounded by a constant, namely the
size of the input alphabet. We need the following deﬁnitions for our complexity
considerations:
– The size of a formula is the number of its distinct subformulas.
– A T-coalgebra (X, γ) is k-branching if there exists some k ∈ω such that for
all x ∈X we have #Base(γ(x)) ≤k.
Proposition 1. Let (X, γ, x) be a k-branching pointed T-coalgebra, let n be the
size of the behavioural equivalent well-pointed T-coalgebra that the algorithm
learns and let m be the maximal size of the counterexample provided by the
Teacher. Then the algorithm terminates after asking O(k · m · n2) logical queries
and at most n equivalence queries.
Proof. Let (S, Σ) be a table occurring during the run of the algorithm. By
Lemma 5 we have #S ≤n. Furthermore, the size of Σ is bound by m ·(n−1) as
each counterexample is of size at most m and at most n−1 counterexamples can
be added to Σ as the addition of a counterexample always results in an increase
of the size of S by Lemmas 6 and 7. To check closedness of a table (S, Σ) we need
to ask logical queries about the elements of S and their successors. Therefore,
we need at most (k + 1) · n · m · (n −1) such queries. This shows that we need
O(k · m · n2) logical queries. The upper bound on equivalence queries is obvious.
Our discussion demonstrates that the move from deterministic ﬁnite
automata to T-coalgebras does not essentially alter the number of queries. At
this stage we cannot predict how fast queries can be answered in practice. To
answer this question we plan to implement our algorithm in the near future.
4
Examples
We will illustrate our algorithm with two examples: One known example on
learning Mealy machines and one example that is to the best of our knowledge
new, an Angluin learning algorithm for discrete Markov chains. While learning
probabilistic automata is an active area [20–22], existing work uses other learning
paradigms and focuses on constructing minimal automata for a probabilistic
language rather than - as our algorithm does - on bisimulation quotients of
transition systems.

Angluin Learning via Logic
85
Example 4 (Mealy machines). In the ﬁrst example we show how the algorithm
learns functions L: I+ →O, i.e. maps from ﬁnite sequences over I to elements of
O where I and O are ﬁnite sets that constitute the input and output alphabet,
respectively. The “regularity” assumption on L is that L can be represented by a
ﬁnite Mealy machine. The latter are a generalization of deterministic automata
where each transition has an associated input and output letter. Such Mealy
machines correspond to coalgebras for the Mealy functor T = ( × O)I [15].
Learning L is equivalent to learning a ﬁnite representation of the coalgebra
I∗
γ→(I∗× O)I with designated point λ ∈I∗, where γ(w)(a) = ⟨wa, L(wa)⟩.
Recall the expressive language from Example 3 for the Mealy functor.
As a concrete example, we want to learn the function L represented by the
Mealy machine in the following diagram, where the input alphabet is I = {a, b}
and the output alphabet is O = {x, y}:
According to the Algorithm 1, the ﬁrst thing to do is checking if the starting
table T = ({λ}, {⊤}) is closed. The table is trivially closed, as ⊤is always true
and the ﬁrst conjecture of the algorithm is as follows:
As the conjecture is incorrect the teacher returns a counterexample, e.g. the
formula [a]pa/y. We update the set Σ of formulas with this new formula together
with all its subformulas. Note that this process is a well-known variant of the
one described in [6] where the counterexample is usually added to the set S of
states and not to Σ. We use this variant that allows to automatically maintain
the table consistent (cf. [19]), in order to be sure to have a sharp table at every
step.
The table is now T = ({λ}, {⊤, pa/y, [a]pa/y}) and it is not closed. Therefore,
we add another state to the set of states according to the else part of the if-
statement 1. We pick a state x′ ∈|S|Σ such that its successors’ equivalence
classes are not represented in S, in symbols: |Base(γ(x′))|Σ ̸⊆|S|Σ. In our
particular case, we can pick only λ; the two successors of λ are ⟨a, x⟩and ⟨b, x⟩
and we have Base(γ(λ)) = {a, b}. We take one element of this set, say a, the
equivalence class of a is not equal to |λ|Σ, therefore we add a to S and we remove
it from Base(γ(λ)). We do the same for b. Because |b|Σ /∈|{λ, a}|Σ, b is also
added to S.
This procedure can be seen as the standard table ﬁlling process in the L*-
algorithm: in the lower part of the table, we identify those states that do not

86
S. Barlocco and C. Kupke
have a corresponding representative in the set of states S and we add them in
the upper part of the table; in our case both a and b have to be added. The
entries of the table are 1 and 0, according to the truth values which the formula
assumes in a particular state. We can schematically see this process in Table 1,
where the values in the ﬁrst column are shorthands for π1(γ(w)(a)), i.e., we write
wa for the state reached from w after reading input a.
Table 1. From a not closed table to a closed one
Having added a and b to S, we have a new table: T
=
({λ, a, b},
{⊤, pa/y, [a]pa/y}), that is closed. Now, we can make our conjecture:
But the conjecture is incorrect and we again receive a counterexample, e.g.
[a][b][b][a]pa/x. The resulting table is not closed, as |Base(γ(a))|Σ ̸⊆|S|Σ. Indeed,
the successor of a, aa, should satisfy [a][b][b][a]pa/x, whereas the formula is false
in a. We only pick the element aa from Base(γ(a)) = {aa, ab} as the equivalence
class of ab is already represented. The new table is: T = ({λ, a, b, aa}, Σ).
Closing the table with aa, we go to else 2 and we compute our conjecture.
Table 2 on page 16 represents this step. No counterexamples are given back,
therefore the conjecture is the right one and we have the same automaton Aut(T )
describing the Mealy machine we wanted to learn.
Note that there is a diﬀerence with the standard Angluin algorithm adapted
for Mealy machines. Usually the entries of the tables are the output values that
the Mealy automata produce. This is not the case in our algorithm. The entries
are always the values 1 or 0 according to the truth values of the formulas, whereas
the output values are given by the function γ.
Example 5 (Discrete Markov Chain). In this example we show that our algorithm
can learn bisimulation quotients of (discrete) probabilistic transition systems. We
conﬁne ourselves to a ﬁnite example and we model probabilistic transition systems
as PAt×Dω -coalgebras where At is a set of propositional variables - in our exam-
ple we will assume At = {p} for a single proposition p. Note, however, that the

Angluin Learning via Logic
87
Table 2. Changing of the table according to the Base-step of the algorithm
⊤pa/y [a]pa/y pa/x [a]pa/x [b][a]pa/x [b][b][a]pa/x [a][b][b][a]pa/x
λ
1
0
1
1
0
1
0
1
a
1
1
1
0
0
1
1
1
b
1
0
0
1
1
0
1
0
aa
1
1
1
0
0
1
1
1
ab
1
0
0
1
1
1
0
1
ba
1
0
1
1
0
1
0
1
bb
1
0
1
1
0
1
0
1
⇓
⊤pa/y [a]pa/y pa/x [a]pa/x [b][a]pa/x [b][b][a]pa/x [a][b][b][a]pa/x
λ
1
0
1
1
0
1
0
1
a
1
1
1
0
0
1
1
1
b
1
0
0
1
1
0
1
0
aa
1
1
1
0
0
1
1
1
ab
1
0
0
1
1
1
0
1
ba
1
0
1
1
0
1
0
1
bb
1
0
1
1
0
1
0
1
aaa
1
1
1
0
0
1
1
1
aab
1
1
1
0
0
1
1
1
input model of our learning algorithm could be inﬁnite and that our coalgebraic
framework is general enough to cover a large variety of probabilistic systems [23].
Recall an expressive language for this example from Example 3. Consider now the
following pointed PAt×Dω -coalgebra based on X = {x0, x1, . . . , x6} with initial
state x0 and transition map γ, where transitions are labelled with their likelihoods
and proposition p holds exclusively at state x5:

88
S. Barlocco and C. Kupke
The algorithm tries to learn a minimal pointed coalgebra that is behaviourally
equivalent to (X, γ, x0). As always the algorithm starts with table ({x0}, {⊤}).
This table is trivially closed and our ﬁrst conjecture will be a state at which
p does not hold and with a loop of probability 1. The teacher has to reject
the conjecture and provides a counter example, e.g. the formula ϕ = L0.2L1p
as x0 |= ϕ and |x0| ̸|= ϕ. This leads to the new table ({x0}, Σ1) with Σ1 =
{L0.2L1p, L1p, p, ⊤}). We have Base(γ(x0)) = {x2, x3, x4, x6} and it is easy to
see that |{x2, x3, x4, x6}|Σ1 ̸⊆|{x0}|Σ1. Therefore the table is not closed. It
can easily be checked that x2 ≡Σ1 x3 and x4 ≡Σ1 x6 and closing the table
leads to ({x0, x2, x4}, Σ1). We have Base(γ(x4)) = {x5} and obviously |x5|Σ1 ̸∈
|{x0, x2, x4}|Σ1 as x5 is the only state satisfying proposition p. Closing the table
we arrive at ({x0, x2, x4, x5}, Σ1) and this table is closed as readers can easily
convince themselves. The table leads to the correct conjecture:
5
Conclusions
While the last example was simple it demonstrates how our algorithm can be
used to determine the quotient of a discrete Markov chain modulo behavioural
equivalence, i.e. bisimilarity. Other transition systems can be quotiented in the
same way. This is interesting as bisimulation quotients play an important role in
veriﬁcation [24] and as the complexity of standard algorithms is determined by
the size of the system before taking the quotient whereas the complexity of the
learning algorithm depends on the size of the potentially much smaller quotient.
To explore the practical usefulness of our algorithm in these cases we are planning
to provide an implementation in the near future. The biggest challenge will in
our view be to implement a teacher that provides “good” counterexamples.
There are many more questions concerning our work that we would like to
clarify: Our approach is currently very much based on the category of sets. This
excludes for example the important example of linear weighted automata [2]. We
believe that our arguments can be extended by (i) building on a duality between
algebras and coalgebras and (ii) understanding how ﬁltrations translate via this
duality. There are some partial answers to the latter question in the modal logic
literature (cf. e.g. [25,26]) but modal logicians usually focus on properties of
ﬁltrations that do not play a role in learning. Closely related to this question
is a more diagrammatic understanding of termination and correctness of our
algorithm: we believe that all essential ingredients for this are contained in our
work but we need to understand ﬁltrations on a more abstract, categorical level.

Angluin Learning via Logic
89
Acknowledgements. The authors would like to thank Nick Bezhanishvili and
Alexandra Silva for helpful discussions and pointers to the literature.
References
1. Jacobs, B.: Introduction to Coalgebra: Towards Mathematics of States and Obser-
vation. Cambridge Tracts in TCS. Cambridge University Press, New York (2016)
2. Jacobs, B., Silva, A.: Automata learning: a categorical perspective. In: van Breugel,
F., Kasheﬁ, E., Palamidessi, C., Rutten, J. (eds.) Horizons of the Mind. A Tribute
to Prakash Panangaden. LNCS, vol. 8464, pp. 384–406. Springer, Cham (2014).
https://doi.org/10.1007/978-3-319-06880-0 20
3. van Heerdt, G.: An abstract automata learning framework. Master’s thesis,
Radboud Universiteit Nijmegen (2016)
4. Moerman, J., Sammartino, M., Silva, A., Klin, B., Szynwelski, M.: Learning nom-
inal automata. In: POPL 2017 (2017)
5. van Heerdt, G., Sammartino, M., Silva, A.: Learning automata with side-eﬀects.
CoRR abs/1704.08055 (2017)
6. Angluin, D.: Learning regular sets from queries and counter examples. Inf. Comput.
75(2), 87–106 (1987)
7. Ad´amek, J., Milius, S., Moss, L.S., Sousa, L.: Well-pointed coalgebras. Logical
Methods Comput. Sci. 9(3) (2013)
8. Gr¨adel, E., Thomas, W., Wilke, T. (eds.): Automata Logics, and Inﬁnite
Games. LNCS, vol. 2500. Springer, Heidelberg (2002). https://doi.org/10.1007/
3-540-36387-4
9. Mac Lane, S.: Categories for the Working Mathematician. Graduate Texts
in Mathematics, vol. 5. Springer, New York (1971). https://doi.org/10.1007/
978-1-4757-4721-8
10. Jacobs, B., Rutten., J.: An introduction to (co)algebras and (co)induction. In:
Advanced Topics in Bisimulation and Coinduction. Cambridge Tracts in Theoret-
ical Computer Science, vol. 5, pp. 38–99. Cambridge University Press (2011)
11. Ad´amek, J., Trnkov´a, V.: Automata and Algebras in Categories. Kluwer Academic
Publishers, Dordrecht (1990)
12. Cirstea, C., Kurz, A., Pattinson, D., Schr¨oder, L., Venema, Y.: Modal logics are
coalgebraic. Comput. J. 54(1), 31–41 (2009)
13. Kupke, C., Pattinson, D.: Coalgebraic semantics of modal logics: an overview.
Theoret. Comput. Sci. 412(38), 5070–5094 (2011)
14. Schr¨oder, L.: Expressivity of coalgebraic modal logic: the limits and beyond. The-
oret. Comput. Sci. 390(2), 230–247 (2008)
15. Hansen, H.H., Rutten, J.J.M.M.: Symbolic synthesis of mealy machines from arith-
metic bitstream functions. Sci. Ann. Comp. Sci. 20, 97–130 (2010)
16. Desharnais, J., Edalat, A., Panangaden, P.: Bisimulation for labelled markov
processes. Inf. Comput. 179(2), 163–193 (2002)
17. Kupke, C., Leal, R.A.: Characterising behavioural equivalence: three sides of
one coin. In: Kurz, A., Lenisa, M., Tarlecki, A. (eds.) CALCO 2009. LNCS,
vol. 5728, pp. 97–112. Springer, Heidelberg (2009). https://doi.org/10.1007/
978-3-642-03741-2 8
18. Blackburn, P., de Rijke, M., Venema, Y.: Modal Logic. Cambridge Tracts in The-
oretical Computer Science, vol. 53. Cambridge University Press, New York (2001)
19. Maler, O., Pnueli, A.: On the learnability of inﬁnitary regular sets. Inf. Comput.
118(2), 316–326 (1995)

90
S. Barlocco and C. Kupke
20. Balle, B., Castro, J., Gavald, R.: Learning probabilistic automata: a study in state
distinguishability. TCS 473, 46–60 (2013)
21. Mao, H., Chen, Y., Jaeger, M., Nielsen, T.D., Larsen, K.G., Nielsen, B.: Learning
probabilistic automata for model checking. In: 2011 Eighth International Confer-
ence on Quantitative Evaluation of Systems, pp. 111–120 (2011)
22. Tzeng, W.G.: Learning probabilistic automata and markov chains via queries.
Mach. Learn. 8(2), 151–166 (1992)
23. Sokolova, A.: Probabilistic systems coalgebraically: a survey. TCS 412(38), 5095–
5110 (2011)
24. Gl¨uck, R., M¨oller, B., Sintzoﬀ, M.: Model reﬁnement using bisimulation quotients.
In: Johnson, M., Pavlovic, D. (eds.) AMAST 2010. LNCS, vol. 6486, pp. 76–91.
Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-17796-5 5
25. Ghilardi, S.: Continuity, freeness, and ﬁltrations. J. Appl. Non Class. Logics 20(3),
193–217 (2010)
26. Bezhanishvili, G., Bezhanishvili, N., Iemhoﬀ, R.: Stable canonical rules. J. Symbol.
Logic 81(1), 284–315 (2016)

A Universal Algebra for the Variable-Free
Fragment of RC∇
Lev D. Beklemishev(B)
Steklov Mathematical Institute of the Russian Academy of Sciences, Moscow, Russia
bekl@mi.ras.ru
Abstract. The language of Reﬂection Calculus RC consists of impli-
cations between formulas built up from propositional variables and the
constant ‘true’ using only conjunction and the diamond modalities which
are interpreted in Peano arithmetic as restricted uniform reﬂection prin-
ciples. In [6] we introduced RC∇, an extension of RC by a series of
modalities representing the operators associating with a given arithmeti-
cal theory T its fragment axiomatized by all theorems of T of arithmetical
complexity Π0
n, for all n > 0. In this paper we continue the study of the
variable-free fragment of RC∇and characterize its Lindenbaum–Tarski
algebra in several natural ways.
Keywords: Strictly positive logics · Reﬂection principle · Provability
GLP
1
Introduction
A system, called Reﬂection Calculus and denoted RC, was introduced in [9]
and, in the present format, in [5]. From the point of view of modal logic, RC can
be seen as a fragment of Japaridze’s polymodal provability logic GLP [8,16,23]
consisting of the implications of the form A →B, where A and B are formu-
las built-up from ⊤and propositional variables using just ∧and the diamond
modalities. We call such formulas A and B strictly positive (s.p.).
Strictly positive modal logics earlier appeared in two other contexts: in the
work on description logic, on the one hand, and in universal algebra, as a study of
the varieties of semilattices with monotone operators, on the other (see e.g. [15,
24]). The recent paper [19] and its predecessors [18,20] is a systematic study of
general s.p. logics and contains comprehensive references.
The main advantage of the use of reﬂection calculus in provability logic is its
simplicity combined with suﬃcient expressivity for main proof-theoretic appli-
cations (see [1,3–5]). Unlike GLP, the system RC is complete with respect to
a natural class of ﬁnite Kripke frames [9]. Also, RC is decidable in polynomial
L. D. Beklemishev—This work is supported by the Russian Science Foundation under
grant 16–11–10252.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 91–106, 2018.
https://doi.org/10.1007/978-3-319-72056-2_6

92
L. D. Beklemishev
time [9], whereas most of the standard modal logics are PSpace-complete and
the same holds even for the variable-free fragment of GLP [21].
A system RC∇with modalities 3n representing uniform reﬂection principles
of arithmetical complexity Σ0
n, and ∇n representing Π0
n+1-conservativity oper-
ators was introduced in [6]. Provability interpretation of RC∇is formulated in
terms of the semilattice GEA of (numerated) arithmetical r.e. theories extend-
ing elementary arithmetic EA. Under this semantics, propositional variables are
interpreted as the elements of the lattice (i.e., theories extending EA modulo
provable deductive equivalence), operators 3n associate with a theory T ∈GEA
the extension of EA by the uniform Σn-reﬂection principle for T, whereas the
operators ∇n associate with a theory T its Π0
n+1-fragment, i.e., the extension
of EA by all Π0
n+1-theorems of T. We refer to [6] for a more comprehensive
discussion and motivation.
The following results on RC∇were established in [6]. Firstly, RC∇can express
α-iterations of modalities 3n, for each n < ω and ordinals α < ε0. A variable-free
s.p. logic where such iterations are explicitly present in the language has been
introduced by Joosten and Hermo Reyes [11,12] which is, thereby, contained
in RC∇. Secondly, unique normal forms for the formulas of the variable-free
fragment of the system RC∇were provided. As a corollary, this fragment was
shown to be decidable and arithmetically complete [6].
In this paper we consider algebraic semantics for the variable-free fragment
of RC∇. We characterize its Lindenbaum–Tarski algebra in several natural ways.
It turns out that this structure is tightly related to the so-called Ignatiev frame
I for modal logic GLP [14], a Kripke frame whose points are certain sequences
of ordinals below ε0. We deﬁne on the domain of I the structure of a lower
semilattice I with the appropriate operations 3n and ∇n, for each n < ω. This
algebra is shown to be isomorphic to the Lindenbaum–Tarski algebra of the
variable-free fragment of RC∇; moreover, every sequence in I corresponds to a
variable-free formula of RC∇in the normal form.
Another characterization of the same algebra is obtained by identifying the
points of I with bounded variable-free RC-theories. Via the isomorphic embed-
ding of I into GEA, such RC-theories, in turn, correspond to natural arithmetical
theories related to Turing–Feferman progressions of iterated reﬂection principles
up to the ordinals below ε0.
The points of I have a natural proof-theoretic interpretation in terms of
sequences of proof-theoretic ordinals of (bounded) arithmetical theories for each
complexity level Π0
n+1. Such collections, called conservativity spectra, appeared
for the ﬁrst time in the work of Joost Joosten [17]. He established a one-to-one
correspondence between conservativity spectra (for a certain class of theories)
and the points of Ignatiev’s model. Our results show that conservativity spectra
can be naturally seen as the points of the RC∇-algebra I.

A Universal Algebra for the Variable-Free Fragment of RC∇
93
2
Strictly Positive Logics and Reﬂection Calculi
2.1
Normal Strictly Positive Logics
Consider a modal language LΣ with propositional variables p, q,. . . , a constant
⊤, conjunction ∧, and a possibly inﬁnite set of symbols Σ = {ai : i ∈J}
understood as diamond modalities. The family Σ is called the signature of the
language LΣ. Strictly positive formulas (or simply formulas) are built up by the
grammar:
A ::= p | ⊤| (A ∧A) | aA,
where a ∈Σ.
Sequents are expressions of the form A ⊢B where A, B are strictly positive
formulas.
Basic sequent-style system, denoted K+, is given by the following axioms and
rules:
1. A ⊢A;
A ⊢⊤;
from A ⊢B and B ⊢C infer A ⊢C;
2. A ∧B ⊢A;
A ∧B ⊢B;
from A ⊢B and A ⊢C infer A ⊢B ∧C;
3. from A ⊢B infer aA ⊢aB, for each a ∈Σ.
It is well-known that K+ axiomatizes the strictly positive fragment of a poly-
modal version of basic modal logic K. All our systems will also contain the
following principle corresponding to the transitivity axiom in modal logic:
4. aaA ⊢aA.
The extension of K+ by this axiom will be denoted K4+.
Let C[A/p] denote the result of replacing in C all occurrences of a variable p
by A. A set of sequents L is called a normal strictly positive logic if it contains the
axioms and is closed under the rules of K+ and under the following substitution
rule: if (A ⊢B) ∈L then (A[C/p] ⊢B[C/p]) ∈L. We will only consider normal
strictly positive logics below. We write A ⊢L B for the statement that A ⊢B is
provable in L (or belongs to L). A =L B means A ⊢L B and B ⊢L A.
2.2
Algebraic Semantics
Algebraic semantics for normal strictly positive logics is given by semilat-
tices with monotone operators (SLOs), that is, structures of the form M =
(M; ∧M, {aM : a ∈Σ}) where (M, ∧M) is a semilattice with top and each
aM : M →M is a monotone operator on M: x ⩽y implies aM(x) ⩽aM(y),
for all x, y ∈M. Every strictly positive formula A of LΣ represents a term
AM of M. We say that A ⊢B holds in M (or M satisﬁes A ⊢B) if
M ⊨∀x AM(x) ⩽BM(x). It is easy to see that A ⊢K+ B if and only if A ⊢B
holds in each SLO M. The SLOs satisfying all the theorems of a normal s.p.
logic L are called L-algebras.
Given a normal s.p. logic L in a signature Σ and an alphabet of variables
V , its Lindenbaum–Tarski algebra is a SLO LV
L whose domain consists of the

94
L. D. Beklemishev
equivalence classes of formulas of the language of L modulo =L. Let [A]L denote
the equivalence class of A. The operations are deﬁned in a standard way as
follows: [A]L ∧L [B]L := [A ∧B]L, aL([A]L) := [aA]L, for each a ∈Σ. It is
well-known that A ⊢L B iﬀA ⊢B holds in LV
L. Hence, any normal s.p. logic L is
complete w.r.t. its algebraic semantics, that is, w.r.t. the class of all L-algebras.
The algebra LV
L is also called the free V -generated L-algebra. In this paper
we will be particularly interested in the algebras LV
L where V is empty. In this
case we denote the algebra LV
L by L0
L.
2.3
The System RC
Reﬂection calculus. RC is a normal strictly positive logic formulated in the sig-
nature {3n : n ∈ω}. It is obtained by adjoining to the axioms and rules of K4+
(stated for each 3n) the following principles:
5. 3nA ⊢3mA, for all n > m;
6. 3nA ∧3mB ⊢3n(A ∧3mB), for all n > m.
We notice that the converse of Axiom 6 is also provable in RC, so that in fact
3n(A ∧3mB) =RC 3nA ∧3mB.
(1)
Dashkov [9] showed that RC axiomatizes the set of all sequents A ⊢B such
that the implication A →B is provable in the polymodal logic GLP.
We recall a correspondence between variable-free RC-formulas and ordinals
[2]. Let F denote the set of all variable-free RC-formulas, and let Fn denote its
restriction to the signature {3i : i ⩾n}, so that F = F0. For each n ∈ω we
deﬁne binary relations <n on F by
B <n A
def
⇐⇒A ⊢RC 3nB.
Obviously, <n is a transitive relation invariantly deﬁned on the equivalence
classes w.r.t. provable equivalence in RC (denoted =RC). Since RC is polytime
decidable, so are both =RC and all of <n.
An RC-formula without variables and ∧is called a word. In fact, any such
formula syntactically is a ﬁnite sequence of letters 3i (followed by ⊤). If A, B
are words then AB will denote A[B/⊤], that is, the word corresponding to
the concatenation of these sequences. A ⊜B denotes the graphical identity of
formulas (words). The set of all words will be denoted W, and Wn will denote
its restriction to the signature {3i : i ⩾n}. The following facts are from [2,5]:
– Every A ∈Fn is RC-equivalent to a word in Wn;
– (Wn/=RC, <n) is isomorphic to (ε0, <).
Here, ε0 is the ﬁrst ordinal α such that ωα = α. Thus, the set Wn/=RC is
well-ordered by the relation <n. The isomorphism can be established by an onto
and order preserving function on : Wn →ε0 such that, for all A, B ∈Wn,
A =RC B ⇐⇒on(A) = on(B).

A Universal Algebra for the Variable-Free Fragment of RC∇
95
Then on(A) is the order type of {B ∈Wn : B <n A}/=RC.
The function o(A) := o0(A) can be inductively calculated as follows: If A ⊜
3k
0⊤then o(A) = k. If A ⊜A130A230 · · · 30An, where all Ai ∈W1 and not all
of them are empty, then
o(A) = ωo(A−
n ) + · · · + ωo(A−
1 ).
Here, B−is obtained from B ∈W1 replacing every 3m+1 by 3m. For n > 0 and
A ∈Wn we let on(A) = on−1(A−).
2.4
The System RC∇and Fat Normal Forms
The signature of RC∇consists of modalities 3n and ∇n, for each n < ω. The
system RC∇is a normal s.p. logic given by the following axioms and rules, for
all m, n < ω:
1. RC for 3n; RC for ∇n;
2. A ⊢∇nA;
3. 3nA ⊢∇nA;
4. 3m∇nA ⊢3mA; ∇n3mA ⊢3mA if m ⩽n.
A formula A is called ordered if no modality (be it 3i or ∇i) occurs in A
within the scope of a modality with a strictly larger index. The following lemma
is easy [6].
Lemma 1. Every formula A of RC∇is equivalent to an ordered one.
Ordered formulas equivalent to a given formula need not be unique. Normal
forms for the variable-free fragment of RC∇were introduced in [6]. Let F∇denote
the set of variable-free formulas of RC∇.
A formula A ∈F∇is in the fat normal form if either A ⊜⊤or A has the
form ∇0A0 ∧∇1A1 ∧· · · ∧∇kAk, where for all i = 0, . . . , k, Ai ∈Wi, Ak ̸⊜⊤,
and
∇iAi ⊢RC∇∇i(∇iAi ∧· · · ∧∇kAk).
One of the main results in [6] is the following proposition.
Proposition 1
(i) Every A ∈F∇is equivalent to a formula in the fat normal form.
(ii) For all A ∈F∇, the words Ai in the fat normal form of A are unique modulo
equivalence in RC.
A corollary of this theorem is that the variable-free fragment of RC∇is
decidable and arithmetically complete [6].

96
L. D. Beklemishev
3
Ignatiev Frame and Ignatiev RC∇-Algebra
In this and the following section we characterize in several ways the Lindenbaum–
Tarski algebra of the variable-free fragment of RC∇. It turns out that this
structure is tightly related to the so-called Ignatiev’s Kripke frame. This frame,
denoted here I, has been introduced by Konstantin Ignatiev [14] as a universal
frame for the variable-free fragment of Japaridze’s logic GLP. Later this frame
has been slightly modiﬁed and studied in more detail in [7,13]. In particular,
Thomas Icard established a detailed relationship between I and the canonical
frame for the variable-free fragment of GLP and used it to deﬁne a complete
topological semantics for this fragment. David Fern´andez and Joost Joosten [10]
generalized I to a version of GLP with transﬁnitely many modalities. Ignatiev’s
frame is deﬁned constructively (‘coordinatewise’) as follows.
Let ¯I denote the set of all ω-sequences of ordinals α = (α0, α1, . . . ) such that
αi ⩽ε0 and αi+1 ⩽ℓ(αi), for all i ∈ω. Here, the function ℓis deﬁned by:
ℓ(β) = 0 if β = 0, and ℓ(β) = γ if β = δ + ωγ, for some δ, γ. Thus, all sequences
of ¯I, with the exception of identically ε0, are eventually zero. Relations Rn on ¯I
are deﬁned by:
αRnβ ⇐⇒(∀i < n αi = βi and αn > βn).
The structure I = (¯I, (Rn)n∈ω) is called the extended Ignatiev frame (see [13]).
The Ignatiev frame is its restriction to the subset I of all sequences α ∈¯I such
that ∀i ∈ω αi < ε0. This subset is upwards closed w.r.t. all relations Rn, hence
the evaluation of the variable-free RC-formulas (and GLP-formulas) in I and in
I coincide. We denote by I, α ⊩ϕ the truth of a GLP-formula ϕ at a node α of
I. The following important theorem is a corollary of the results of Ignatiev but,
in fact, has an easier direct proof (which we omit for the reasons of brevity).
Proposition 2. For any variable-free formulas A, B of RC, A ⊢RC B iﬀI, α ⊩
A →B, for all α ∈I.
The set of sequences α ∈I such that ∀i < ω αi+1 = ℓ(αi) is called the main
axis of I and is denoted O. Obviously, a sequence in O is uniquely determined
by its initial element α0, hence O naturally corresponds to the ordinals up to ε0.
We can also associate with every word A ∈W an element ι(A) ∈O by letting
ι(A) := (o(A), ℓ(o(A)), . . . , ℓ(n)(o(A)), . . . ).
The following lemma, explicitly stated by Thomas Icard [13, Lemma 3.8],
describes all the subsets of I deﬁnable by words (and hence by all variable-free
s.p. formulas of RC).
Lemma 2. Suppose A ∈W and α = ι(A). Then, for all β ∈I, I, β ⊩A iﬀ
∀i ∈ω αi ⩽βi.
Our goal is to transform I into an RC∇-algebra I with the same domain I,
that is, into an SLO satisfying RC∇. We consider the set ¯I equipped with the
ordering
α ⩽I β
def
⇐⇒∀n ∈ω αn ⩾βn.

A Universal Algebra for the Variable-Free Fragment of RC∇
97
The structure (¯I, ⩽I) can be seen as a subordering of the product ordering on
the set of all ω-sequences of ordinals ⩽ε0, which we denote E.
A cone in E is the set of points Eα := {β ∈E : β ⩽I α}, for some α ∈E. A
sequence α ∈E is called bounded if ∀i ∈ω αi < ε0 and αi ̸= 0 for only ﬁnitely
many i ∈ω. Obviously, each α ∈I is bounded.
Lemma 3. Suppose α ∈E is bounded. Then Eα ∩I is not empty and has a
greatest point β w.r.t. ⩽I.
Proof. Let n ∈ω be the largest number such that αn ̸= 0. Consider the sequence
β such that βi = 0 for all i > n, βn := αn, and, for all i < n:
βi :=

αi,
if ℓ(αi) ⩾βi+1,
αi + ωβi+1,
otherwise.
It is easy to see that β is the greatest point of Eα ∩I. Also notice that β can be
eﬀectively computed from α.
Corollary 1. (I, ⩽I) is a meet-semilattice with top.
Proof.
Let α, β ∈I. The sequence γ := (max(αi, βi))i<ω is the g.l.b. of α and
β in E and is bounded. By Lemma 3, Eγ ∩I has a greatest point, which has to
be the g.l.b. of α and β in I.
We denote by ∧I the meet operation of this semilattice. A nonempty set
Cα := Eα ∩I is called a cone in I. The set of all cones in I ordered by inclusion
is denoted C(I). The orderings (C(I), ⊆) and (I, ⩽I) are isomorphic by the map
α →Cα. So, we have
Corollary 2. For all α, β ∈I, Cα∧Iβ = Cα ∩Cβ.
Let C(O) denote the set {Cα : α ∈O} of all cones in I generated by the
points of the main axis. For all X ⊆¯I deﬁne R−1
n (X) := {y ∈X : xRny}.
We claim that the operations ∩and R−1
n
map cones of C(O) to cones of C(O).
Moreover, the following proposition holds.1
Proposition 3. The algebra C(O) = (C(O); ∩, {R−1
n
: n ∈ω}) is isomorphic to
the Lindenbaum–Tarski algebra L0
RC.
Proof.
Let v : F →P(I) denote the map associating with every variable-free
formula A of RC the set of points v(A) := {α ∈I : I, α ⊩A}. By the soundness
and completeness of RC w.r.t. the Ignatiev model we have v(A) = v(B) iﬀ
A =RC B. Moreover, by Lemma 2 the range of v consists of all the cones of
C(O). So, v factors to a bijective map ¯v : L0
RC →C(O). The operations ∩and
R−1
n
correspond to the deﬁnition of truth in a Kripke model, hence C(O) is closed
under these operations and ¯v is an isomorphism of the respective algebras.
1 We do not distinguish notationally an operation on a set and its restriction to a
subset.

98
L. D. Beklemishev
We remark that the work of Pakhomov [22] shows that the elementary theory
of the algebra L0
RC is undecidable. We now deﬁne the structure of an RC∇-algebra
on I.
Deﬁnition 1. For all n ∈ω we deﬁne the functions ∇I
n, 3I
n : I →I. For each
element α = (α0, α1, . . . , αn, . . . ) ∈I let:
∇I
n(α) := (α0, α1, . . . , αn, 0, . . . );
3I
n(α) := (β0, β1, . . . , βn, 0, . . . ), where βn+1 := 0 and βi := αi + ωβi+1, for
all i ⩽n.
The algebra I = (I, ∧I, {3I
n, ∇I
n : n ∈ω}) is called the Ignatiev RC∇-algebra.
The deﬁnition of the operations 3I
n is motivated by the following lemma and
its corollary.
Lemma 4. Suppose α ∈I and β = 3I
n(α). Then β ∈O and
(i) Cβ = 
i⩽n R−1
i (Cα);
(ii) If α ∈O then Cβ = R−1
n (Cα).
Proof. (i) It is easy to see that each of the sets R−1
i (Cα), for i ⩽n, is a cone in I
generated by the bounded sequence (α0, . . . , αi−1, αi + 1, 0, . . . ) from E. Hence,
the intersection of these cones is a cone generated by (α0 +1, . . . , αn−1 +1, αn +
1, 0, . . . ). Its greatest element in I obviously coincides with 3I
n(α).
(ii) Clearly, β ∈R−1
n (Cα), since β′ := (β0, β1, . . . , βn−1, αn, αn+1, . . . ) satis-
ﬁes βRnβ′ and β′ ⩽I α. In the opposite direction, show by downward induction
on i ⩽n that if γ ∈R−1
n (Cα) then γi ⩾βi. For i = n the claim is obvious.
Assume i < n, then γi ⩾αi. Since ℓ(γi) ⩾γi+1 ⩾βi+1 and ℓ(αi) = αi+1 < βi+1,
we must also have γi ⩾αi + ωβi+1 = βi.
Corollary 3. C(O) is isomorphic to the algebra O = (O, ∧I, {3I
n : n ∈ω}).
Proof. Consider the bijection c : α −→Cα from O to C(O). By Corollary 2 this
map preserves the meet, and by Lemma 4 it preserves the diamond modalities.
We summarize the previous results in the following theorem characterizing
the Lindenbaum–Tarski algebra of the variable-free fragment of RC.
Theorem 1. The algebras L0
RC, C(O), O are naturally isomorphic by the fol-
lowing maps:
(i) ¯v : L0
RC →C(O);
(ii) c : O →C(O);
(iii) ¯ι : L0
RC →O.
Here, for any A ∈F, ¯ι([A]RC) := ι(A′), where A′ ∈W is a word such that
A =RC A′. This deﬁnition is invariant, since, for any words A′, A′′, if A′ =RC
A′′ then o(A′) = o(A′′) and hence ι(A′) = ι(A′′). For a proof that (iii) is an
isomorphism it is suﬃcient to remark that v(A) = c(ι(A)), for each A ∈W, by
Lemma 2.
Our next goal is to show that I is isomorphic to the Lindenbaum–Tarski
algebra of RC∇. First, we need an auxiliary lemma.

A Universal Algebra for the Variable-Free Fragment of RC∇
99
Lemma 5. For every α ∈I and n ∈ω, there is an α′ ∈O such that α′ ⩽I α
and 3I
n(α) = 3I
n(α′).
Proof.
Let α′
n := αn, ∀i ⩾n α′
i+1 := ℓ(α′
i), and ∀i < n α′
i := αi + ωα′
i+1. It is
easy to check that α′ is as required.
Let AI denote the value of a variable-free RC∇-formula A in I. The following
lemma shows that I satisﬁes the variable-free fragment of RC∇.
Lemma 6. For any A, B ∈F∇, A ⊢RC∇B implies AI ⩽I BI.
Proof.
We argue by induction on the length of RC∇-derivation. In almost all
the cases the proof is routine. We consider the nontrivial case of the axiom
3nA ∧3mB ⊢3n(A ∧3mB) for m < n. Let α = AI and β = BI. Using
Lemma 5 we obtain α′, β′ ∈O such that α′ ⩽I α, β′ ⩽I β and 3I
nα = 3I
nα′,
3I
mβ = 3I
mβ′. By Theorem 1 the algebra O satisﬁes RC, hence
3I
nα′ ∧I 3I
mβ′ ⩽I 3I
n(α′ ∧I 3I
mβ′).
Therefore, 3I
nα ∧I 3I
mβ ⩽I 3I
n(α′ ∧I 3I
mβ) ⩽I 3I
n(α ∧I 3I
mβ). The second
inequality holds by the monotonicity of ∧I and 3I
n.
Lemma 7. Suppose A ⊜∇0A0 ∧∇1A1 ∧· · · ∧∇nAn is in the fat normal form.
Then AI = (o0(A0), o1(A1), . . . , on(An), 0, . . . ).
Proof.
Firstly, since each Ai ∈Wi we obtain from Theorem 1 that
(Ai)I = ι(Ai) = (ωi(oi(Ai)), ωi−1(oi(Ai)), . . . , ωoi(Ai), oi(Ai), ℓ(oi(Ai)), . . . ),
where by deﬁnition ω0(α) = α and ωk+1(α) = ωωk(α). Hence,
(∇iAi)I = (ωi(oi(Ai)), ωi−1(oi(Ai)), . . . , ωoi(Ai), oi(Ai), 0, . . . ).
Denote Ai := ∇iAi ∧∇i+1Ai+1 ∧· · · ∧∇nAn. By downwards induction on
i ⩽n we show that (Ai)I equals
(ωi(oi(Ai)), ωi−1(oi(Ai)), . . . , oi(Ai), oi+1(Ai+1), . . . , on(An), 0, . . . ).
(2)
For i = n the claim follows from the above. Assume i < n and that the claim
holds for i + 1. Since in a fat normal form
∇iAi ⊢RC∇∇i(∇iAi ∧∇i+1Ai+1),
by Lemma 6 we obtain that the sequence (∇iAi)I coordinatewise majorizes
the sequence (∇i(∇iAi ∧∇i+1Ai+1))I. The former has the ordinal oi(Ai) at
i-th position, and the latter has at the same place the least ordinal α such
that α ⩾oi(Ai), ωoi+1(Ai+1) and ℓ(α) ⩾oi+1(Ai+1). Therefore, oi(Ai) = α and
ℓ(oi(Ai)) ⩾oi+1(Ai+1).
Now consider the sequence (Ai)I = (∇iAi ∧Ai+1)I. By the induction
hypothesis its tail coincides with that of (2) starting from position i + 1. Since
ℓ(oi(Ai)) ⩾oi+1(Ai+1), the ordinal oi(Ai) occurs in it on i-th position. Also, for
each k < i we have ωk(oi(Ai)) ⩾ωk(ωoi+1(Ai+1)). It follows that the sequence
(Ai)I coincides with (2).

100
L. D. Beklemishev
The following corollary will be useful later on.
Corollary 4. For any A, B ∈W and n ∈ω, if I ⊨∇nA = ∇nB then A =RC B.
Proof. Firstly, we infer: I ⊨∇0A = ∇0∇nA = ∇0∇nB = ∇0B. By Lemma 7 we
conclude o(A) = o(B), therefore A =RC B.
Theorem 2. For all A, B ∈F∇, A ⊢RC∇B iﬀAI ⩽I BI.
Proof.
We must only prove the ‘only if’ part. Moreover, it is suﬃcient to prove
it for fat normal forms A ⊜∇0A0 ∧∇1A1 ∧· · · ∧∇nAn and B ⊜∇0B0 ∧∇1B1 ∧
· · ·∧∇mBm. If AI ⩽I BI then by Lemma 7 we have n ⩾m and oi(Ai) ⩾oi(Bi),
for each i ⩽m. Since Ai, Bi ∈Wi, this means that Ai ⊢RC 3iBi or Ai =RC Bi.
In either case we can infer ∇iAi ⊢RC∇∇iBi for each i ⩽m. It follows that
A ⊢RC∇B.
Theorem 2 essentially means the following.
Corollary 5. The Ignatiev RC∇-algebra I is isomorphic to the Lindenbaum–
Tarski algebra of the variable-free fragment of RC∇.
4
I as the Algebra of Variable-Free RC-Theories
Another, perhaps even more natural, view of the Ignatiev RC∇-algebra is via
an interpretation of the points of I as variable-free RC-theories. It nicely agrees
with the arithmetical interpretation in that we can also view such a theory
as an arithmetical theory (every variable-free RC-formula corresponds to an
arithmetical sentence). In this section we will presuppose that the language is
variable-free and will only consider variable-free formulas and theories.
A set of strictly positive formulas T is called an RC-theory if B ∈T whenever
there are A1, . . . , An ∈T such that A1 ∧· · · ∧An ⊢RC B. A theory T is called
improper if T coincides with the set of all strictly positive formulas, otherwise it
is called proper.2 A theory is called bounded if there is a strictly positive formula
A such that T ⊆{B : A ⊢RC B}. We will use the following basic fact.
The set ¯I bears a natural topology generated as a subbase by the set of all
cones in I and their complements. By [13, Theorem 3.12], this topology coincides
with the product topology of the space E induced on ¯I. Obviously, for each RC-
formula A, the set v(A) is clopen. Moreover, this topology is compact and totally
disconnected on ¯I, since ¯I is closed in E and E is compact by Tychonoﬀtheorem.
As a corollary we obtain the following strong completeness result.
Proposition 4. Let T be an RC-theory and A an RC-formula.
(i) T ⊬RC A iﬀthere is an α ∈I such that I, α ⊩T and I, α ⊮A;
(ii) If T is bounded then T ⊬RC A iﬀthere is an α ∈I such that I, α ⊩T and
I, α ⊮A.
2 We avoid the term ‘consistent’, for even the improper theory corresponds to a con-
sistent set of arithmetical sentences.

A Universal Algebra for the Variable-Free Fragment of RC∇
101
Proof
(i) The nontrivial implication is from left to right. Assume T ⊬RC A. There is
an increasing sequence of ﬁnite theories (Tn)n∈ω such that T = 
n∈ω Tn.
By the completeness of the variable-free fragment of RC w.r.t. I each of the
sets v(Tn) \ v(A) is nonempty and clopen. By the compactness of ¯I there is
a point α ∈
n∈ω v(Tn) \ v(A) = v(T) \ v(A).
(ii) In case T is bounded we have v(T) ⊇v(B), for some word B. There is a
bounded sequence β ∈E such that v(T) = Eβ ∩¯I: consider the pointwise
supremum of the generating points of the cones v(Tn) in I, each of which is
pointwise majorized by the greatest element BI of v(B). By Lemma 3, the
set v(T) has a greatest point, say γ ∈I. Since α ∈v(T) we have α ⩽I γ,
hence I, γ ⊮A.
For any RC-theories T, S deﬁne T ⩽RC S iﬀT ⊇S. The g.l.b. of T and S
in this ordering, denoted T ∧RC S, is the theory generated by the union T ∪S.
Thus, the set T0
RC of all bounded variable-free RC-theories is a semilattice (it is,
in fact, a lattice with T ∩S the l.u.b. of T and S). The set {A ∈F : ⊤⊢RC A}
corresponds to the top of this lattice and is denoted ⊤RC.
For each α ∈I deﬁne an RC-theory [α] := {A : I, α ⊩A}. Clearly, [α] is
bounded if α ∈I. For each RC-theory T deﬁne v(T) := {α ∈I : I, α ⊩T}.
Proposition 5
(i) The map α →[α] is an isomorphism between (I, ⩽I) and the ordered set
T0
RC of bounded RC-theories.
(ii) The map v is an isomorphism between T0
RC and the ordered set (C(I), ⊆) of
cones in I.
Proof.
It is suﬃcient to prove that
(a) The maps α →[α] and T →v(T) are order-preserving;
(b) ∀α ∈I v([α]) = Cα;
(c) If v(T) = Cα then T = [α].
Item (a) is obvious. For (b) we observe:
β ∈v([α]) ⇐⇒∀A (I, α ⊩A ⇒I, β ⊩A).
The right hand side is equivalent to β ⩽I α: If β ⩽I α and I, α ⊩A then
I, β ⊩A by Proposition 2. If β I α then there is a word A such that I, α ⊩A
and I, β ⊮A, by [13, Corollary 3.9]. Hence, β ∈v([α]) iﬀβ ∈Cα.
For (c) we use Proposition 4. Suppose α ∈I and v(T) = Cα. Then I, α ⊩T
and thus T ⊆[α]. For the opposite inclusion assume A ∈[α] and A /∈T. By
Proposition 4 there is a node β ∈I such that I, β ⊩T and I, β ⊮A. Thus,
β ∈v(T) and, since v(A) is downwards persistent, β I α. It follows that
v(T) ⊈Cα.

102
L. D. Beklemishev
The operations of the Ignatiev RC∇-algebra can be interpreted in terms of
the semilattice of bounded theories as follows. For each T ∈T0
RC let ∇RC
n T
denote the RC-theory axiomatized by {3mA : 3mA ∈T and m ⩽n}.
Lemma 8. For all α ∈I, ∇RC
n ([α]) = [∇I
nα].
Proof.
For the inclusion (⊆) we need to show: if m ⩽n and 3mA ∈[α] then
3mA ∈[∇I
nα]. If 3mA ∈[α] then I, α ⊩3mA, hence there is a β such that
αRmβ and I, β ⊩A. So, we have ∀i < m αi = βi and αm > βm. Since
m ⩽n, the node ∇I
nα has the same coordinates as α for all i ⩽m. Therefore,
(∇I
nα)Rmβ and I, (∇I
nα) ⊩3mA.
For the inclusion (⊇) we consider any node γ ∈I such that I, γ ⊩∇RC
n [α]
and show that I, γ ⊩[∇I
nα]. This means that v(∇RC
n [α]) ⊆v([∇I
nα]) and hence
∇RC
n ([α]) ⊇[∇I
nα] by Proposition 5.
Assume I, γ ⊮[∇I
nα]. Since v(∇I
nα) = C∇I
nα we have γ /∈C∇I
nα, hence
there is an m ⩽n such that γm < αm. Consider a word A ∈Wm such that
om(A) = γm. Recall that that the point on the main axis corresponding to A is
ι(A) = (ωm(γm), . . . , ωγm, γm, ℓ(γm), . . . ).
We claim that I, γ ⊮3mA, whereas I, α ⊩3mA. The former holds,
since for all δ such that γRmδ one has δm < γm, hence δ I ι(A) and
I, δ ⊮A. On the other hand, I, α ⊩3mA holds, since there is a sequence
α′ := (α0, . . . , αm−1, γm, γm+1, . . . ) such that αRmα′ and I, α′ ⊩A.
To show that α′ ⩽I ι(A) we prove that ∀i ⩽mωm−i(γm) ⩽αi by downward
induction on i ⩽m. Assume the claim holds for some i such that 0 < i ⩽m.
Then αi−1 ⩾ωℓ(αi−1) ⩾ωαi ⩾ωγi = γi−1.
In order to deﬁne the operations 3RC
n
on the set of bounded RC-theories
we need a few deﬁnitions. An RC-theory T is of level n if T is generated by a
(nonempty) set of formulas 3nA such that A ∈Wn. A theory T is of level at
least n if it is generated by a (nonempty) subset of Wn \ {⊤}.
Lemma 9. Every bounded RC-theory T is representable in the form T = T0∧RC
T1 ∧RC · · · ∧RC Tn where each Ti is of level i or Ti = ⊤RC.
Proof.
Recall that every RC-formula is RC-equivalent to an ordered formula.
Moreover, every variable-free RC-formula in which only the modalities 3i with
i ⩾m occur is equivalent to a word in Wm. Hence, every formula is equivalent
to a conjunction of formulas of the form 3iA with A ∈Wi. Since T is bounded,
the set of indices of modalities occurring in the axioms of T is bounded, say
by n. Hence, each axiom of T can be replaced by a ﬁnite set of formulas of
various levels below n and one can partition the union of all these axioms into
the disjoint subsets of the same level.
Lemma 10. For each α ∈I such that αn > 0, the theory generated by [α]∩Wn
corresponds to the sequence α′ := (ωn(αn), . . . , ωαn, αn, αn+1, . . . ).
We remark that if αn = 0 then the theory generated by [α] ∩Wn is ⊤RC.

A Universal Algebra for the Variable-Free Fragment of RC∇
103
Proof.
Let T be the theory generated by [α] ∩Wn. We consider a β ∈I such
that [β] = T and show that β = α′. It is easy to see that α ⩽I α′ and that the
submodel of I generated from α by the relations Rk, for all k ⩾n, is isomorphic
to the submodel generated by these relations from α′. Hence, if B is a formula
in which only the modalities 3k with k ⩾n occur, then I, α ⊩B holds iﬀ
I, α′ ⊩B. It follows that [α] ∩Wn ⊆[α′], that is, α′ ⩽I β.
Now assume α′ <I β, so there is a k ∈ω such that βk < α′
k. If k < n
then βk < ωn−k(αn). For all ordinals γ, δ, if γ < ωδ then ℓ(γ) < δ. Then, by
induction, for all i = k, . . . , n we obtain βi < ωn−i(αn). Ergo βn < αn.
So, we may assume that k ⩾n. In this case consider a word B ∈Wk such
that ok(B) = βk + 1. Then,
ι(B) = (ωk(βk + 1), . . . , ω1(βk + 1), βk + 1, 0, . . . ).
We have I, β ⊮B, since βk + 1 > βk. On the other hand,
∀i ⩽k ωi(βk + 1) ⩽αk−i,
which is easy to see by induction on i. It follows that I, α ⊩B, therefore [β] ̸= T,
a contradiction.
Corollary 6. For each α ∈I, [α] is of level at least n iﬀαn > 0 and
∀i < n αi = ωn−i(αn).
(3)
Lemma 11.
For each bounded RC-theory T of level at least n, there is an
RC-formula A ∈Wn such that ∇RC
n A = ∇RC
n T holds in T0
RC.
Proof. Suppose T = [α] is of level at least n. Let A ∈Wn be such that on(A) =
αn > 0. Then, by Lemma 8, ∇RC
n (T) = ∇RC
n ([α]) = [∇I
nα]. By (3) we have
∇I
nα = (ωn(αn), ωn−1(αn), . . . , αn, 0, . . . ).
On the other hand, ι(A) = (ωn(αn), ωn−1(αn), . . . , αn, ℓ(αn), . . . ), and we obtain
∇RC
n A = [∇I
n(ι(A))] = [(ωn(αn), ωn−1(αn), . . . , αn, 0, . . . )]. Proposition 5 yields
the result.
Now we can give the following deﬁnition of the theory 3RC
n T, for each
bounded RC-theory T.
If T is of level at least n or T = ⊤RC, we let 3RC
n T be the theory generated
by the formula 3nA, where A ∈Wn is such that ∇RC
n A = ∇RC
n T in T0
RC.
(Notice that this deﬁnition is correct, since any two words A1, A2 satisfying
∇RC
n A1 = ∇RC
n A2 in T0
RC also satisfy 3nA1 =RC 3nA2 by Corollary 4.)
For each i ⩽n, let Ti denote the theory generated by T ∩Wi. We deﬁne
3RC
n (T) := 3RC
0 (T0) ∧RC 3RC
1 (T1) ∧RC · · · ∧RC 3RC
n (Tn).
The following lemma shows that this deﬁnition agrees with the operations
on the Ignatiev algebra.

104
L. D. Beklemishev
Lemma 12. For all α ∈I, 3RC
n ([α]) = [3I
n(α)].
Proof. If T = [α] then by Lemma 10, for each i ⩽n, either the theory Ti := T ∩
Wi is ⊤RC or corresponds to the sequence α′ := (ωi(αi), . . . , ωαi, αi, αi+1, . . . )
with αi > 0. If Ti = ⊤RC we have 3RC
i
Ti = 3i⊤. Otherwise, 3RC
i
Ti = 3iAi
where Ai corresponds to (ωi(αi), . . . , ωαi, αi, ℓ(αi), . . . ). In both cases
3RC
i
Ti = [(ωi(αi + 1), . . . , ωαi+1, αi + 1, 0, . . . )].
Then we observe that 3RC
n (T) = 3RC
0 (T0) ∧RC 3RC
1 (T1) ∧RC · · · ∧RC 3RC
n (Tn)
corresponds to the cone generated by (α0 + 1, α1 + 1, . . . , αn + 1, 0, . . . ) in E
which coincides with the cone of 3I
n(α) (cf Lemma 4).
Using Lemma 4 we can also isomorphically represent I as an algebra of cones
in I. Given a cone C ∈C(I) let 3C
n(C) := 
i⩽n R−1
i (C). We also deﬁne
∇C
n(C) :=

{R−1
i (D) : D ∈C(I), i ⩽n, R−1
i (D) ⊇C}.
We summarize the information in the following theorem.
Theorem 3. The following structures are isomorphic:
(i) The Lindenbaum–Tarski algebra of the variable-free fragment of RC∇;
(ii) I = (I, ∧I, {3I
n, ∇I
n : n ∈ω});
(iii) (T0
RC, ∧RC, {3RC
n , ∇RC
n
: n ∈ω});
(iv) C(I) = (C(I), ∩, {3C
n, ∇C
n : n ∈ω}).
Proof.
We only need to prove the isomorphism of (iv) with either (ii) or (iii).
Proposition 5 provides the isomorphisms of the semilattice reducts. Further, for
all α ∈I, 3C
n(Cα) = C3I
n(α) by Lemma 4(i). Hence, 3C
n corresponds to 3I
n of
(ii). On the other hand, ∇C
n(Cα) = v(∇RC
n ([α])). Hence, ∇C
n corresponds to ∇RC
n
of (iii).
We remark that the algebra C(I) has rather simple deﬁnitions of meet and
diamonds, but somewhat convoluted nablas. In contrast, T0
RC has simple meet
and nablas but somewhat convoluted diamonds. The algebra I, perhaps the most
elegant of all three, has a more complicated meet operation (though the order
relation ⩽I is simple).
5
A Universal Kripke Frame for RC∇
In view of Theorem 3 it is natural to ask if one can describe a universal Kripke
frame for the variable-free fragment of RC∇. There is a general construction
associating with a SLO B = (B, ∧B, {aB : a ∈Σ}) its ‘dual’ Kripke frame,
similar to the way the canonical model of an s.p. logic L is obtained from its
Lindenbaum–Tarski algebra.
Recall that a ﬁlter in B is a nonempty subset F ⊆B such that

A Universal Algebra for the Variable-Free Fragment of RC∇
105
1. If x ⩽B y and x ∈F then y ∈F;
2. If x, y ∈F then x ∧B y ∈F.
The set of ﬁlters of B will be denoted F(B). On F(B) one can deﬁne binary
relations {Ra : a ∈Σ} as follows: For all F, G ∈F(B),
FRaG
def
⇐⇒∀x ∈G aB(x) ∈F.
Let B∗denote the Kripke frame (F(B), {Ra : a ∈Σ}) together with the canon-
ical valuation v : B →P(F(B)), where v(x) := {F ∈F(B) : x ∈F}. It is then
easy to see that, for all x ∈B and a ∈Σ, R−1
a (v(x)) = v(aB(x)). Hence, we
obtain the following corollaries.
Proposition 6
(i) The map v
:
B
→
P(B∗) is an embedding of B into the algebra
(P(B∗), ∩, {R−1
a
: a ∈Σ}).
(ii) If A, B in LΣ are variable-free, then A ⊢B holds in B iﬀB∗, F ⊩A →B
for all F ∈B∗.
Corollary 7. I∗is complete for the variable-free fragment of RC∇.
It is possible to give a more explicit description of the set of ﬁlters in I in
terms of sequences of ordinals. With each ﬁlter F in I we associate a sequence
αF ∈E by letting αi := sup{βi + 1 : β ∈F}, for each i ∈ω.
Lemma 13. For each ﬁlter F, the sequence α = αF satisﬁes the following
condition: For all i ∈ω, either αi is a limit ordinal and αi+1 ⩽ℓ(αi), or
αi = α′
i + 1 and αi+1 ⩽ℓ(α′
i) + 1, for some α′
i.
Vice versa, if a sequence α satisﬁes the condition of Lemma 13, then the
set Fα := {β ∈I : ∀i ∈ω αi > βi} is a ﬁlter in I. However, at present we
lack a characterization of the relations Rn and Sn on I∗corresponding to the
modalities 3n and ∇n by formulas that would be as nice as the deﬁnition of
these operations in I itself. So, we prefer not to go into the details here and to
leave Lemma 13 without proof.
References
1. Beklemishev, L.D., Onoprienko, A.A.: On some slowly terminating term rewriting
systems. Sbornik Math. 206, 1173–1190 (2015)
2. Beklemishev, L.D.: Provability algebras and proof-theoretic ordinals. Ann. Pure
Appl. Logic 128, 103–123 (2004)
3. Beklemishev, L.D.: Reﬂection principles and provability algebras in formal arith-
metic. Russ. Math. Surv. 60(2), 197–268 (2005). Russian original: Uspekhi Matem-
aticheskikh Nauk, 60(2): 3–78 (2005)
4. Beklemishev, L.D.: The Worm principle. In: Chatzidakis, Z., Koepke, P., Pohlers,
W. (eds.) Logic Colloquium 2002. Lecture Notes in Logic, vol. 27, pp. 75–95.
AK Peters (2006). Preprint: Logic Group Preprint Series 219, Utrecht University,
March 2003

106
L. D. Beklemishev
5. Beklemishev, L.D.: Calibrating provability logic: from modal logic to reﬂection
calculus. In: Bolander, T., Bra¨uner, T., Ghilardi, S., Moss, L. (eds.) Advances in
Modal Logic, vol. 9, pp. 89–94. College Publications, London (2012)
6. Beklemishev, L.D.: On the reﬂection calculus with partial conservativity operators.
In: Kennedy, J., de Queiroz, R.J.G.B. (eds.) WoLLIC 2017. LNCS, vol. 10388, pp.
48–67. Springer, Heidelberg (2017). https://doi.org/10.1007/978-3-662-55386-2 4
7. Beklemishev, L.D., Joosten, J., Vervoort, M.: A ﬁnitary treatment of the closed
fragment of Japaridze’s provability logic. J. Logic Comput. 15(4), 447–463 (2005)
8. Boolos, G.: The Logic of Provability. Cambridge University Press, Cambridge
(1993)
9. Dashkov, E.V.: On the positive fragment of the polymodal provability logic GLP.
Matematicheskie Zametki 91(3), 331–346 (2012). English translation: Mathemat-
ical Notes 91(3):318–333, 2012
10. Fern´andez-Duque, D., Joosten, J.: Models of transﬁnite provability logic. J. Sym-
bol. Logic 78(2), 543–561 (2013)
11. Reyes, E.H., Joosten, J.J.: The logic of Turing progressions. arXiv:1604.08705v2
[math.LO] (2016)
12. Reyes, E.H., Joosten, J.J.: Relational semantics for the Turing Schmerl calculus.
arXiv:1709.04715 [math.LO] (2017)
13. Icard III, T.F.: A topological study of the closed fragment of GLP. J. Logic Comput.
21(4), 683–696 (2011)
14. Ignatiev, K.N.: On strong provability predicates and the associated modal logics.
J. Symbol. Logic 58, 249–290 (1993)
15. Jackson, M.: Semilattices with closure. Algebra Universalis 52, 1–37 (2004)
16. Japaridze, G.K.: The modal logical means of investigation of provability. Thesis in
Philosophy, in Russian, Moscow (1986)
17. Joosten, J.J.: Turing–Taylor expansions of arithmetical theories. Studia Logica
104, 1225–1243 (2015). https://doi.org/10.1007/s11225-016-9674-z
18. Kikot, S., Kurucz, A., Tanaka, Y., Wolter, F., Zakharyaschev, M.: On the complete-
ness of EL-equations: ﬁrst results. In: 11th International Conference on Advances
in Modal Logic, Short Papers (Budapest, 30 August – 2 September, 2016), pp.
82–87 (2016)
19. Kikot, S., Kurucz, A., Tanaka, Y., Wolter, F., Zakharyaschev, M.: Kripke Com-
pleteness of strictly positive modal logics over meet-semilattices with operators.
ArXiv e-prints, August 2017
20. Kurucz, A., Tanaka, Y., Wolter, F., Zakharyaschev, M.: Conservativity of Boolean
algebras with operators over semi lattices with operators. In: Proceedings of TACL
2011, pp. 49–52 (2011)
21. Pakhomov, F.: On the complexity of the closed fragment of Japaridze’s provability
logic. Archive Math. Logic 53(7), 949–967 (2014)
22. Pakhomov, F.: On elementary theories of ordinal notation systems based on reﬂec-
tion principles. Proc. Steklov Inst. Math. 289, 194–212 (2015)
23. Shamkanov, D.: Nested sequents for provability logic GLP. Logic J. IGPL 23(5),
789–815 (2015)
24. Sofronie-Stokkermans, V.: Locality and subsumption testing in EL and some of its
extensions. In: Areces, C., Goldblatt, R. (eds.) Advances in Modal Logic, vol. 7,
pp. 315–339. College Publications, London (2008)

A Logic of Blockchain Updates
Kai Br¨unnler1, Dandolo Flumini2, and Thomas Studer3(B)
1 Bern University of Applied Sciences, Bern, Switzerland
kai.bruennler@bfh.ch
2 ZHAW School of Engineering, Winterthur, Switzerland
dandolo.flumini@zhaw.ch
3 University of Bern, Bern, Switzerland
tstuder@inf.unibe.ch
Abstract. Blockchains are distributed data structures that are used
to achieve consensus in systems for cryptocurrencies (like Bitcoin) or
smart contracts (like Ethereum). Although blockchains gained a lot of
popularity recently, there are only few logic-based models for blockchains
available. We introduce BCL, a dynamic logic to reason about blockchain
updates, and show that BCL is sound and complete with respect to a
simple blockchain model.
Keywords: Blockchain · Modal logic · Dynamic epistemic logic
1
Introduction
Bitcoin [16] is a cryptocurrency that uses peer-to-peer technology to support
direct user-to-user transactions without an intermediary such as a bank or credit
card company. In order to prevent double spending, which is a common issue
in systems without central control, Bitcoin maintains a complete and public
record of all transactions at each node in the network. This ledger is called the
blockchain.
The blockchain is essentially a growing sequence of blocks, which contain
approved transactions and a cryptographic hash of the previous block in the
sequence. Because the blockchain is stored locally at each node, any update to it
has to be propagated to the entire network. Nodes that receive a transaction [1,18]
1. ﬁrst verify its validity (i.e., whether it is compatible with all preceeding trans-
actions);
2. if it is valid, then it is added to the blockchain and
3. sent to all other nodes.
Blockchain technology, as a general solution to the Byzantine Generals’ Prob-
lem [15], is now not only used for ﬁnancial transactions but also for many other
applications like, e.g., smart contracts [5].
T. Studer—Supported by the Swiss National Science Foundation grant 200021 165549.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 107–119, 2018.
https://doi.org/10.1007/978-3-319-72056-2_7

108
K. Br¨unnler et al.
Herlihy and Moir [11] propose to develop a logic of accountability to design
and verify blockchain systems. In particular, they discuss blockchain scenarios
to test (i) logics of authorization, (ii) logics of concurrency, and (iii) logics of
incentives.
Halpern and Pass [10] provide a characterization of agents’ knowledge when
running a blockchain protocol using a variant of common knowledge.
In the present paper, we are not interested in accountability or aspects of
common knowledge. We study the local, single agent perspective of a blockchain.
That is we investigate steps 1 and 2 of the above procedure for receiving a
transaction. Our approach is inspired by dynamic epistemic logic [7]. A given
state of the local blockchain entails knowledge about the transactions that have
taken place. We ask: how does this knowledge change when a new block is received
that might be added to the blockchain? We develop a dynamic logic, BCL, with
a semantics that is based on a blockchain model. The update operators of BCL
are interpreted as receiving new blocks. It is the aim of this paper to investigate
the dynamics of local blockchain updates.
The deductive system for BCL includes reduction axioms that make it possi-
ble to establish completeness by a reduction to the update-free case [13]. How-
ever, since blockchain updates are only performed if certain consistency con-
ditions are satisﬁed, we use conditional reduction axioms similar to the ones
developed by Steiner to model consistency preserving updates [19]. Moreover,
unlike traditional public announcements [7], blockchain updates cannot lead to
an inconsistent state, i.e., updates are total, like in [20].
We do not base BCL on an existing blockchain implementation but use a very
simple model. First of all, the blockchain is a sequence of propositional formulas.
Further, we maintain a list of provisional updates. Our blocks consist of two
parts: a sequence number (called the index of the block) and a propositional
formula. If a block is received, then the following case distinction is performed
where i is the index of the block and l is the current length of the blockchain:
1. i ≤l. The block is ignored.
2. i = l + 1. If the formula of the block is consistent with the blockchain, then it
is added to the blockchain; otherwise the block is ignored. If the blockchain
has been extended, then this procedure is performed also with the blocks
stored in the list of provisional updates.
3. i > l + 1. The block is added to the list of provisional updates.
Although this is a simple model, it features two important logical properties of
blockchains: consistency must be preserved and blocks may be received in the
wrong order, in which case they are stored separately until the missing blocks
have been received.
The main contribution of our paper from the point of view of dynamic epis-
temic logic is that we maintain a list of provisional updates. That means we
support updates that do not have an immediate eﬀect but that may lead to a
belief change later only after certain other updates have been performed. BCL
is the ﬁrst logic that features provisional updates of this kind.

A Logic of Blockchain Updates
109
The paper is organized as follows. The next section introduces our blockchain
model, the language of BCL, and its semantics. In Sect. 3, we introduce a deduc-
tive system for BCL. We establish soundness of BCL in Sect. 4. In Sect. 5, we
show a normal form theorem for BCL, which is used in Sect. 6 to prove com-
pleteness of BCL. The ﬁnal section studies some key principles of the dynamics
of our blockchain logic and discusses future work.
We will only mention the lemmas that are needed to establish the main
theorems of this paper; but we do not give any proofs because of lack of space.
Detailed proofs can be found in the accompanying arXiv paper [3].
2
A Simple Blockchain Logic
The set of all natural numbers is denoted by N := {0, 1, 2, . . .}. The set of positive
natural numbers is denoted by N+ := {1, 2, . . .}. We use ω for the least ordinal
such that ω > n, for all n ∈N.
Let σ = ⟨σ1, . . . , σn⟩be a ﬁnite sequence. We deﬁne its length by len(σ) := n.
For an inﬁnite sequence σ = ⟨σ1, σ2, . . .⟩we set len(σ) := ω. For a (ﬁnite or
inﬁnite) sequence σ = ⟨σ1, σ2, . . . , σi, . . .⟩we set (σ)i := σi for i ≤len(σ). The
case i > len(σ) can be safely ingored. The empty sequence is denoted by ⟨⟩and
we set len(⟨⟩) := 0. We can append x to a ﬁnite sequence σ := ⟨σ1, . . . , σn⟩, in
symbols we set σ◦x := ⟨σ1, . . . , σn, x⟩. We will also need the set of all components
of a sequence σ and deﬁne
set(σ) := {x | there is an i such that x = σi}.
In particular, we have set(⟨⟩) := ∅. Moreover, we use the shorthand x ∈σ for
x ∈set(σ).
We start with a countable set of atomic propositions AP := {P0, P1, . . .}.
The set of formulas Lcl of classical propositional logic is given by the following
grammar
A ::= ⊥| P | A →A,
where P ∈AP.
In order to introduce the language LB for blockchain logic, we need another
countable set of special atomic propositions AQ := {Q1, Q2, . . .} that is disjoint
with AP. We will use these special propositions later to keep track of the length
of the blockchain. The formulas of LB are now given by the grammar
F ::= ⊥| P | Q | F →F | 2A | [i, A]F,
where P ∈AP, Q ∈AQ, A ∈Lcl, and i ∈N+. The operators of the form [i, A]
are called blockchain updates (or simply updates).
Note that in LB we cannot express higher-order knowledge, i.e., we can only
express knowledge about propositional facts but not knowledge about knowledge
of such facts.

110
K. Br¨unnler et al.
For all languages in this paper, we deﬁne further Boolean connectives (e.g. for
negation, conjunction, and disjunction) as usual. Moreover, we assume that
unary connectives bind stronger than binary ones.
For Lcl we use the semantics of classical propositional logic. A valuation v is
a subset of AP and we deﬁne the truth of an Lcl-formula A under v, in symbols
v |= A as usual. For a set Γ of Lcl-formulas, we write v |= Γ if v |= A for all
A ∈Γ. The set Γ is satisﬁable if there is a valuation v such that v |= Γ. We
say Γ entails A, in symbols Γ |= A, if for each valuation v we have
v |= Γ
implies
v |= A.
Now we introduce the blockchain semantics for LB.
Deﬁnition 1. A block is a pair [i, A] where A is an Lcl-formula and i ∈N+.
We call i the index and A the formula of the block [i, A]. We deﬁne functions ind
and fml by ind[i, A] := i and fml[i, A] := A.
Deﬁnition 2. A model M := (I, BC, PU, v) is a quadruple where
1. I is a set of Lcl-formulas
2. BC is a sequence of Lcl-formulas
3. PU is a ﬁnite sequence of blocks
4. v is a valuation, i.e. v ⊆AP
such that
I ∪set(BC) is satisfiable
(1)
and
for each block [i, A] ∈PU we have i > len(BC) + 1.
(2)
The components of a model (I, BC, PU, v) have the following meaning:
1. I models initial background knowledge.
2. BC is the blockchain.
3. PU stands for provisional updates. The sequence PU consists of those blocks
that have been announced but that could not yet be added to the blockchain
because their index is too high. Maybe they will be added to BC later (i.e.,
after the missing blocks have been added).
4. v states which atomic propositions are true.
We need some auxiliary deﬁnitions in order to precisely describe dynamics
of the blockchain.
Deﬁnition 3
1. Let PU be a ﬁnite sequence of blocks. Then we let ﬁnd(i, PU) be the least j ∈
N+ such that there is an Lcl-formula A with [i, A] = (PU)j.
2. Let σ = ⟨σ1, . . . , σi−1, σi, σi+1, . . .⟩be a sequence. We set
remove(i, σ) := ⟨σ1, . . . , σi−1, σi+1, . . .⟩.

A Logic of Blockchain Updates
111
3. Given a set of Lcl-formulas I, a sequence of Lcl-formulas BC, and a ﬁnite
sequence of blocks PU, then the chain completion complete(I, BC, PU) is com-
puted according to Algorithm 1.
Algorithm 1. Chain Completion Algorithm: complete
Input: (I, BC, PU)
1: n ←len(BC) + 1
2: while [n, A] ∈PU for some formula A do
3:
i ←ﬁnd(n, PU)
4:
B ←fml((PU)i)
5:
remove(i, PU)
6:
if I ∪set(BC) ∪{B} is satisﬁable then
7:
BC ←BC ◦B
8:
n ←len(BC) + 1
9:
end if
10: end while
11: for i ∈len(PU), . . . , 1 do
12:
if ind((PU)i) < n then
13:
remove(i, PU)
14:
end if
15: end for
16: return (BC, PU)
Let us comment on the chain completion procedure. The numbers refer to
the lines in Algorithm 1.
1: n is the index a block must contain so that it could be added to the
blockchain BC.
2: ‘[n, A] ∈PU for some formula A’ means that PU contains a block that
could be added to BC.
3–5: Find the next formula B that could be added to BC and remove the
corresponding block from PU.
6: ‘I ∪set(BC) ∪{B} is satisﬁable’ means that B is consistent with the
current belief. This test guarantees that (1) will always be satisﬁed.
7, 8: Update the blockchain BC with B.
11–15: Remove all blocks from PU whose index is less than or equal to the
current length of the blockchain BC. Because the blockchain never gets
shorter, these block will never be added. Removing them guarantees
that (2) will always be satisﬁed.
Note if BC and PU satisfy condition (2) in the deﬁnition of a model, then the
chain completion algorithm will return BC and PU unchanged.
Lemma 1. Let I be a set of Lcl-formulas and let BC be a sequence of Lcl-formulas
such that I ∪set(BC) is satisﬁable. Let PU be an arbitrary ﬁnite sequence of
blocks. For (BC′, PU′) := complete(I, BC, PU) we ﬁnd that

112
K. Br¨unnler et al.
1. I ∪set(BC′) is satisﬁable and
2. for each block [i, A] ∈PU′ we have i > len(BC′) + 1.
Deﬁnition 4. Let M := (I, BC, PU, v) be a model and [i, A] be a block. The
updated model M[i,A] is deﬁned as (I, BC′, PU′, v) where
(BC′, PU′) := complete(I, BC, PU ◦[i, A]).
Remark 1. Note that M[i,A] is well-deﬁned: by Lemma 1 we know that M[i,A] is
indeed a model.
Deﬁnition 5. Let M := (I, BC, PU, v) be a model. We deﬁne the truth of an
LB-formula F in M, in symbols M |= F, inductively by:
1. M ̸|= ⊥;
2. M |= P if P ∈v for P ∈AP;
3. M |= Qi if i ≤len(BC) for Qi ∈AQ;
4. M |= F →G if M ̸|= F or M |= G;
5. M |= 2A if I ∪set(BC) |= A;
6. M |= [i, A]F if M[i,A] |= F.
A formula 2A means that A follows from the blockchain, i.e. A is a logical
consequence from the propositions stored in the blockchain. We can consider 2
to be an epistemic operator since the blockchain represents our knowledge about
which transactions have happened.
We deﬁne validity only with respect to the class of models that do not have
provisional updates.
Deﬁnition 6. We call a model M = (I, BC, PU, v) initial if PU = ⟨⟩. A for-
mula F is called valid if M |= F for all initial models M.
3
The Deductive System BCL
In order to present an axiomatic system for our blockchain logic, we need to for-
malize an acceptance condition stating whether a received block can be added to
the blockchain. That is we need a formula Acc(i, A) expressing that the formula A
is consistent with the current beliefs and the current length of the blockchain is
i−1. Thus if Acc(i, A) holds, then the block [i, A] will be accepted and added to
the blockchain. The truth deﬁnition for the atomic propositions Qi ∈AQ says
that Qi is true if the blockchain contains at least i elements. That means the
formula Q(i −1) ∧¬Qi is true if the blockchain contains exactly i −1 elements.
This leads to the following deﬁnition of Acc(i, A) for i ∈N+:
Acc(i, A) :=

¬Qi ∧¬2¬A
if i = 1
Q(i −1) ∧¬Qi ∧¬2¬A
if i > 1
As desired, we ﬁnd that if Acc(i, A) is true, then the chain completion algorithm
can append the formula A to the blockchain (see Lemma 2 later).
An LB-formula is called compliant if the blockchain updates occur in the
correct order. Formally, we use the following deﬁnition.

A Logic of Blockchain Updates
113
Deﬁnition 7. An LB-formula F is called compliant if no occurrence of a [i, A]-
operator in F is in the scope of some [j, B]-operator with j > i.
Now we can deﬁne a deductive system for BCL. It is formulated in the
language LB and consists of the following axioms:
(PT)
Every instance of a propositional tautology
(K)
2(F →G) →(2F →2G)
(D)
¬2⊥
(Q)
Qi →Qj if i > j
(A1)
[i, A]⊥→⊥
(A2)
[i, A]P ↔P for P ∈AP
(A3.1) Acc(i, A) →([i, A]Qi ↔⊤) for Qi ∈AQ
(A3.2) ¬Acc(i, A) →([i, A]Qi ↔Qi) for Qi ∈AQ
(A3.3) [i, A]Qj ↔Qj for Qj ∈AQ and i ̸= j
(A4)
[i1, A1] . . . [ik, Ak](F →G) ↔
([i1, A1] . . . [ik, Ak]F →[i1, A1] . . . [ik, Ak]G)
(A5.1) Acc(i, A) →([i, A]2B ↔2(A →B))
(A5.2) ¬Acc(i, A) →([i, A]2B ↔2B)
(A6)
[h1, C1] . . . [hk, Ck][i, A][j, B]F ↔
[h1, C1] . . . [hk, Ck][j, A][i, B]F
for i ̸= j
We need a little arithmetic: Axiom (Q) is used to compare indexes. But we
do not need anything else.
Note that in (A6), we may choose k to be 0, in which case the axiom has the
form [i, A][j, B]F ↔[j, A][i, B]F for i ̸= j.
In order to formulate the rules of BCL, we need the following notation. Let
H(P) be a formula that may contain occurrences of the atomic proposition P.
By H(F), we denote the result of simultaneously replacing each occurrence of
P in H(P) with the formula F. The rules of BCL are:
(MP) F
F →G
G
(NEC) A
2A
(SUB)
F ↔G
H(F) ↔H(G)
where (SUB) can only be applied if H(F) ↔H(G) is a compliant formula.
Remark 2. Our semantics includes the case of inﬁnite blockchains: in a given
model (I, BC, PU, v), the sequence BC may have inﬁnite length. If we want to
exclude such models, then we have to add an inﬁnitary rule
Qi
for all i ∈N+
⊥
to BCL. This rule states that some Qi must be false, which means that BC has
ﬁnite length.
4
Soundness
Before we can establish soundness of BCL, we have to show some preparatory
lemmas.

114
K. Br¨unnler et al.
Lemma 2. Let M := (I, BC, ⟨⟩, v) be an initial model. Further let
(I, BC′, PU′, v) := M[i,A]
for some block [i, A].
1. If M |= Acc(i, A), then BC′ = BC ◦A. In particular, this yields len(BC′) = i
and for each j with j ̸= i,
M |= Qj
if and only if
M[i,A] |= Qj.
2. If M ̸|= Acc(i, A), then BC′ = BC.
Lemma 3. Each axiom of BCL is valid.
Lemma 4. Let M = (I, BC, PU, v) be an arbitrary model and let [i, A] be a block
such that i > len(BC) + 1. Then we have M[i,A] = (I, BC, PU ◦[i, A], v).
Lemma 5. Let M = (I, BC, ⟨⟩, v) be an initial model and let [i, A] be a block
such that i ≤len(BC) + 1. Then M[i,A] is an initial model, too.
Lemma 6. Let (I, BC, PU, v) be a model and F be an LB-formula such that for
each [i, A] occurring in F we have i > len(BC) + 1. Then
(I, BC, PU, v) |= F
if and only if
(I, BC, ⟨⟩, v) |= F.
Now we can show that the rule (SUB) preserves validity.
Lemma 7. Let H(P), F, G be LB-formulas such that H(F) ↔H(G) is compli-
ant. We have that
if F ↔G is valid, then H(F) ↔H(G) is valid, too.
We have established that the axioms of BCL are valid and that (SUB) pre-
serves validity. It is easy to see that the rules (MP) and (NEC) also preseve
validity. Soundness of BCL follows immediately.
Corollary 1. For each formula F we have
⊢F implies F is valid.
Remark 3. The reduction axiom (A3.3) does not hold in non-initial models.
Indeed, let M := (∅, ⟨⟩, ⟨[2, ⊤]⟩, ∅). We ﬁnd that M[1,P ] = (∅, ⟨P, ⊤⟩, ⟨⟩, ∅). Hence
M[1,P ] |= Q2, which is M |= [1, P]Q2. But we also have M ̸|= Q2.
Remark 4. The above remark also implies that a block necessitation rule would
not be sound, that is the validity of F does not entail the validity of [i, A]F.
Indeed, the axiom [1, P]Q2 ↔Q2 is valid; but the formula [2, ⊤]([1, P]Q2 ↔Q2)
is not valid as shown in the previous remark.
Remark 5. The rule (SUB) would not preserve validity if we drop the condition
that the conclusion must be compliant. Indeed, let us again consider the valid
formula [1, P]Q2 ↔Q2. Without the compliance condition, the rule (SUB) would
derive [2, P ′][1, P]Q2 ↔[2, P ′]Q2, which is not a valid formula.

A Logic of Blockchain Updates
115
5
Normal Form
Remember that a formula is compliant if the blockchain updates occur in the
correct order. In this section, we establish a normal form theorem for our simple
blockchain logic.
Deﬁnition 8. A base formula is a formula that has one of the following forms
(which include the case of no blockchain updates):
1. [i1, A1] . . . [im, Am]⊥
2. [i1, A1] . . . [im, Am]P with P ∈AP ∪AQ
3. [i1, A1] . . . [im, Am]2B
Formulas in normal form are given as follows:
1. each compliant base formula is in normal form
2. if F and G are in normal form, then so is F →G.
Remark 6. As an immediate consequence of this deﬁnition, we obtain that for
each formula F,
if F is in normal form, then F is compliant.
The following theorem states that for each formula, there is a provably equiv-
alent formula in normal form. The proof is by induction on the structure of F.
Theorem 1. For each LB-formula F, there is an LB-formula G in normal form
such that ⊢F ↔G.
6
Completeness
We ﬁrst show that BCL is complete for modal formulas. The modal language LM
consists of all update-free LB-formulas. Formally, LM is given by the following
grammar
F ::= ⊥| P | Q | F →F | 2A,
where P ∈AP, Q ∈AQ, and A ∈Lcl.
We need the collection BCL2 of all BCL axioms that are given in LM. The
usual satisfaction relation for Kripke models is denoted by |=2.
Lemma 8. For each LM-formula F we have
F is valid implies ⊢F.
We establish completeness for compliant formulas using a translation from
compliant formulas to provably equivalent update-free formulas. We start with
deﬁning a mapping h that eliminates update operators.

116
K. Br¨unnler et al.
Deﬁnition 9. The mapping h from {[i, A]F | F ∈LM} to LM is inductively
deﬁned by:
h([i, A]⊥) := ⊥
h([i, A]P) := P
for P ∈AP
h([i, A]Qi) := Acc(i, A) ∨Qi
h([i, A]Qj) := Qj
for Qj ∈AQ and i ̸= j
h([i, A](F →G)) := h([i, A]F) →h([i, A]G)
h([i, A]2B) := (Acc(i, A) ∧2(A →B)) ∨(¬Acc(i, A) ∧2B)
The mapping h corresponds to the reduction axioms of BCL. Thus it is easy
to show the following lemma by induction on the structure of F.
Lemma 9. Let F be an LB-formula of the form [i, A]G such that G ∈LM. We
have that ⊢F ↔h(F).
We deﬁne a translation t from LB to LM
Deﬁnition 10. The mapping t : LB →LM is inductively deﬁned by:
t(⊥) := ⊥
t(P) := P
for P ∈AP ∪AQ
t(F →G) := t(F) →t(G)
t(2A) := 2A
t([i, A]F) := h([i, A]t(F))
Lemma 10. For each compliant formula F, we have
⊢F ↔t(F).
Theorem 2. For each compliant LB-formula F we have
F is valid implies
⊢F.
Combining Theorems 1 and 2 easily yields completeness for the full language.
Theorem 3.
For each LB-formula F we have
F is valid implies
⊢F.
7
Conclusion
We have presented BCL, a dynamic logic to reason about updates in a sim-
ple blockchain model. Our semantics does not have the full complexity of the
blockchains used in Bitcoin or Ethereum, yet it exhibits two key properties of
blockchains: blockchain extensions must preserve consistency and blocks may
be received in the wrong order. Note, however, that although receiving blocks

A Logic of Blockchain Updates
117
in the wrong order is an important logical possibility, it only happens rarely in
practice: in the Bitcoin protocol the average generation time of a new block is
10 min; the average time until a node receives a block is only 6.5 s [6].
In order to illustrate the dynamics of our simple blockchain logic, we state
some valid principles of BCL:
Persistence: 2A →[i, B]2A. Beliefs are persistent, i.e., receiving a new block
cannot lead to a retraction of previous beliefs.
Consistency: [i, B]¬2⊥. Receiving a new block cannot result in inconsistent
beliefs.
Success: Acc(i, A) →[i, A]2A. If a block [i, A] is acceptable, then A is believed
after receiving [i, A].1
Failure: (Qi ∨¬Q(i −1)) →([i, B]2A ↔2A). If the current length of the
blockchain is not i−1, then receiving a block [i, B] will not change the current
beliefs.
Proof. 1. Persistence: 2A →[i, B]2A. Let M := (I, BC, ⟨⟩, v) be an initial model
and assume M |= 2A. That is I ∪set(BC) |= A. Let (I, BC′, PU′, v) := M[i,B].
We ﬁnd that set(BC) ⊆set(BC′). Therefore, I ∪set(BC′) |= A, hence we have
M[i,B] |= 2A and M |= [i, B]2A.
2. Consistency: [i, B]¬2⊥. We let M := (I, BC, ⟨⟩, v) be an initial model. Further,
we set (I, BC′, PU′, v) := M[i,B]. By Lemma 1 we know that I ∪set(BC′) is
satisﬁable, i.e., I ∪set(BC′) ̸|= ⊥. Hence we have M[i,B] |= ¬2⊥, which is
M |= [i, B]¬2⊥.
3. Success: Acc(i, A) →[i, A]2A. Let M := (I, BC, ⟨⟩, v) be an initial model and
assume M |= Acc(i, A). Let (I, BC′, PU′, v) := M[i,A]. By Lemma 2, we know
BC′ = BC ◦A. Thus I ∪set(BC′) |= A and, therefore M[i,A] |= 2A, which is
M |= [i, A]2A.
4. Failure: (Qi∨¬Q(i−1)) →([i, B]2A ↔2A). Again, let M := (I, BC, ⟨⟩, v) be
an initial model and assume M |= Qi∨¬Q(i−1). We ﬁnd that M ̸|= Acc(i, B).
Indeed,
M |= Qi implies M ̸|= Acc(i, B)
and
M |= ¬Q(i −1) implies i > 1 and M ̸|= Acc(i, B).
Let (I, BC′, PU′, v) := M[i,B]. By Lemma 2, we know BC′ = BC. Therefore,
M[i,B] |= 2A if and only if M |= 2A, which yields M |= [i, B]2A ↔2A. ⊓⊔
There are several open issues for future work. Let us only mention two of
them. Although blockchains are called chains, the data structure that is actually
used is more tree-like and there are diﬀerent options how to choose the valid
branch: Bitcoin currently uses the branch that has the greastest proof-of-work
eﬀort invested in it [16] (for simplicity we can think of it as the longest branch);
but recent research shows that the GHOST rule [18] (used, e.g., in Ethereum [21])
1 We call this prinicple success; but it is not related to the notion of a successful
formula as studied in dynamic epistemic logic, see, e.g., [8].

118
K. Br¨unnler et al.
provides better security at higher transaction throughput. We plan to extend
BCL so that it can handle tree-like structures and the corresponding forks of the
chain. In particular, this requires some form of probability logic to model the
fact that older transactions are less likely reversed [9,16,18].
In a multi-agent setting, each agent (node) has her own instance of the
blockchain. Justiﬁcation logics [2] could provide a formal approach to handle this.
Evidence terms could represent blockchain instances and those instances can be
seen as justifying the agents’ knowledge about the accepted transactions. This
approach would require to develop new dynamic justiﬁcation logics [4,14,17].
Moreover, if the underlying blockchain model supports forks of the chain, then
we need justiﬁcation logics with probability operators [12].
Acknowledgements. We would like to thank Eveline Lehmann and Nenad Savic
for carefully reading a previous version of this paper. We also thank the anonymous
referees for many valuable comments that helped to improve this paper.
References
1. Antonopoulos, A.M.: Mastering Bitcoin: Unlocking Digital Crypto-Currencies.
O’Reilly Media, Inc., Sebastopol (2014)
2. Artemov, S.N.: Explicit provability and constructive semantics. Bullet. Symbolic
Logic 7(1), 1–36 (2001)
3. Br¨unnler, K., Flumini, D., Studer, T.: A logic of blockchain updates. E-print
1707.01766. arXiv.org (2017)
4. Bucheli, S., Kuznets, R., Studer, T.: Realizing public announcements by justiﬁca-
tions. J. Comput. Syst. Sci. 80(6), 1046–1066 (2014)
5. Buterin, V.: Ethereum: a next-generation smart contract and decentralized appli-
cation platform (2013). https://github.com/ethereum/wiki/wiki/White-Paper.
Accessed 2 Feb 2017
6. Decker, C., Wattenhofer, R.: Information propagation in the Bitcoin network. In:
13th IEEE International Conference on Peer-to-Peer Computing, pp. 1–10 (2013)
7. van Ditmarsch, H., van der Hoek, W., Kooi, B.: Dynamic Epistemic Logic.
Synthese Library, vol. 337. Springer, Dordrecht (2008). https://doi.org/10.1007/
978-1-4020-5839-4
8. van Ditmarsch, H., Kooi, B.: The secret of my success. Synthese 151(2), 201–232
(2006)
9. Grunspan, C., P´erez-Marco, R.: Double spend races. ArXiv e-prints 1702.02867
(2017)
10. Halpern, J.H., Rafael, P.: A knowledge-based analysis of the blockchain protocol.
In: Lang, K. (ed.) TARK 2017, pp. 324–335, no. 251 in EPTCS (2017)
11. Herlihy, M., Moir, M.: Blockchains and the logic of accountability: keynote address.
In: LICS 2016, pp. 27–30 (2016)
12. Kokkinis, I., Maksimovi´c, P., Ognjanovi´c, Z., Studer, T.: First steps towards prob-
abilistic justiﬁcation logic. Logic J. IGPL 23(4), 662–687 (2015)
13. Kooi, B.: Expressivity and completeness for public update logics via reduction
axioms. J. Appl. Non Classical Logics 17(2), 231–253 (2007)
14. Kuznets, R., Studer, T.: Update as evidence: belief expansion. In: Artemov, S.,
Nerode, A. (eds.) LFCS 2013. LNCS, vol. 7734, pp. 266–279. Springer, Heidelberg
(2013). https://doi.org/10.1007/978-3-642-35722-0 19

A Logic of Blockchain Updates
119
15. Lamport, L., Shostak, R., Pease, M.: The byzantine generals problem. ACM Trans.
Program. Lang. Syst. 4(3), 382–401 (1982)
16. Nakamoto, S.: Bitcoin: a peer-to-peer electronic cash system (2009)
17. Renne, B.: Public communication in justiﬁcation logic. J. Logic Comput. 21(6),
1005–1034 (2011). Published online July 2010
18. Sompolinsky, Y., Zohar, A.: Secure high-rate transaction processing in bitcoin. In:
B¨ohme, R., Okamoto, T. (eds.) FC 2015. LNCS, vol. 8975, pp. 507–527. Springer,
Heidelberg (2015). https://doi.org/10.1007/978-3-662-47854-7 32
19. Steiner, D.: A system for consistency preserving belief change. In: Artemov, S.,
Parikh, R. (eds.) Proceedings of Rationality and Knowledge, 18th ESSLLI, pp.
133–144. Association for Logic, Language and Information (2006)
20. Steiner, D., Studer, T.: Total public announcements. In: Artemov, S.N., Nerode,
A. (eds.) LFCS 2007. LNCS, vol. 4514, pp. 498–511. Springer, Heidelberg (2007).
https://doi.org/10.1007/978-3-540-72734-7 35
21. Wood, G.: Ethereum: a secure decentralised generalised transaction ledger, EIP-
150 revision (2017). https://ethereum.github.io/yellowpaper/paper.pdf. Accessed
2 Feb 2017

From Display to Labelled Proofs for Tense Logics
Agata Ciabattoni, Tim Lyon(B), and Revantha Ramanayake
Institut f¨ur Computersprachen, Technische Universit¨at Wien, 1040 Wien, Austria
{agata,lyon,revantha}@logic.at
Abstract. We introduce an eﬀective translation from proofs in the dis-
play calculus to proofs in the labelled calculus in the context of tense
logics. We identify the labelled calculus proofs in the image of this trans-
lation as those built from labelled sequents whose underlying directed
graph possesses certain properties. For the basic normal tense logic Kt,
the image is shown to be the set of all proofs in the labelled calculus G3Kt.
Keywords: Display calculus · Labelled calculus
Structural proof theory · Tense logic · Modal logic
1
Introduction
The widespread application of logical methods in several areas of computer sci-
ence, epistemology, and artiﬁcial intelligence has resulted in an explosion of new
logics — each requiring an analytic proof calculus to facilitate study and appli-
cations. The reason is that the rules in an analytic calculus (de)compose the
formula to be proved in a stepwise manner. This systematic decomposition can
be exploited to prove important metalogical properties of the formalized log-
ics and is central to developing automated reasoning methods. Being relatively
simple and not requiring much technical machinery (‘bureaucracy’), the sequent
calculus has always been the most popular formalism to use and try to con-
struct analytic calculi. However, its simplicity means that it is also limited in
its expressive power, and is hence unable to support analytic calculi for the
many logics of interest. This has motivated the search for other, more expressive
formalisms. Many proof formalisms generalizing the sequent calculus have been
introduced in the last 30 years; each of them incorporates the bureaucracy in a
distinct way and hence possesses distinct strengths, weaknesses, and expressive
power. In particular, certain formalisms are more helpful than others for proving
certain computational or metalogical properties. For this reason, it is fruitful to
study logics in a number of diﬀerent formalisms. For example, a large class of
extensions of the minimal tense logic Kt have been presented as instances of
the labelled calculus (e.g., [17,21]) and of the display calculus [10,14,22]. The
former is an extension of the sequent calculus in which the relational semantics
of the formalized logics is made an explicit part of the syntax; the latter extends
Gentzen’s language of sequents with new structural connectives that allow each
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 120–139, 2018.
https://doi.org/10.1007/978-3-319-72056-2_8

From Display to Labelled Proofs for Tense Logics
121
formula in a sequent to be “displayed” as the whole of the antecedent or the
whole of the succedent.
Labelled and display calculi substantially diﬀer in their nature. Display cal-
culi are typically internal in the sense that each step in a proof can be read
as a formula of the logic.1 In general, labelled calculi appear to manipulate
formulae from a more expressive language which partially encodes the logic’s
semantics, and are hence termed external. Internal and external calculi have
been introduced and studied within two essentially independent–and sometimes
competing–streams in proof theory. These calculi possess diﬀerent properties and
lead to distinct proofs.
An eﬀective way to relate calculi is by deﬁning embeddings, i.e. functions
that stepwise transform any proof in a calculus into a proof of the same formula
in another calculus. A crucial feature of such a function is that the structural
properties of the derivation are preserved in the translation. Such embeddings
permit the transfer of certain proof theoretic results, thus alleviating the need
for independent proofs in each system (see [9,11,18]). Moreover they shed light
on the role of bureaucracy in proof calculi, and on the relationships between
diﬀerent syntactic and semantic presentations of a logic.
In this paper we investigate the relationships between display and labelled
proofs for a well known class of tense logics obtained by extending Kt with
Scott-Lemmon [15] axioms ♦h□ip →□j ♦k p (h, i, j, k ≥0). This class is an
adequate case study as it includes many interesting/well-known logics, its display
calculi are all internal, and the display and labelled rules capturing the Scott-
Lemmon axioms2 have a simple form. Due to their distinct foundational origins–
the algebraic semantics for display calculi [14] and Kripke semantics for labelled
calculi [17]–the relationship between their proofs is prima facie unclear; this
is particularly true for the direction from labelled to display proofs (e.g., [19]
contains a translation of display sequents into labelled sequents).
Exploiting the work of Gor´e et al. [10] who present the display calculus for
the basic tense logic Kt as a nested sequent with two types of nesting construc-
tors, we show the equivalence of the display calculus to a calculus on labelled
directed graphs whose underlying undirected graph is a tree. These structures
–labelled UT graphs–are a natural generalization of the labelled trees shown in
[11] to correspond to nested sequents [3,13].
In particular, we give a bi-directional embedding between proofs in the
display calculus and the labelled UT graph calculus. The latter are then mapped
into Negri’s [17] labelled sequent proofs. In the reverse direction, we then consider
speciﬁcally Negri’s labelled calculus for Kt and show that every derivation there
is a derivation in the labelled UT graph calculus.
1 More speciﬁcally, this is true of a display calculus for a logic such that every structural
connective can be interpreted as a connective of the logic.
2 Extending to primitive tense axioms [14] is straightforward though more syntactically
involved.

122
A. Ciabattoni et al.
2
Display and Labelled Calculi for Tense Logics
The tense logic Kt extends the normal modal logic K with the tense connectives♦
and ■and the following axioms and inference rule (see, e.g. [2,4]):
■(p →q) →(■p →■q)
♦p ↔¬■¬p
A
(nec)
■A
p →□♦p
p →■♦p
An intuitive interpretation of □A is the statement “it will always be the case
that A” (i.e. it is necessarily the case that in the future A). Then ■A can be
interpreted as “it has always been the case that A” (it is necessarily the case
that in the past A). Then ♦A may be interpreted as “it is possible that in the
future A”, and ♦A as “it is possible that in the past A”. Of course, suitable
other interpretations may be used as demanded by application.
We assume that our language consists of formulae in negation normal form,
where all negation signs are pushed inward onto the propositional atoms. In
particular, formulae are built from literals p and p using ∧, ∨, ♦, □,♦, and ■.
Note that all results still hold for the full language where the ¬, →, and ↔
connectives are taken as primitive. Nevertheless, we restrict ourselves to negation
normal form for matters of convenience.
The logics we consider in this paper are extensions of Kt with the Scott-
Lemmon axioms ♦h□ip →□j ♦k p (or equivalently, ♦
h ♦j p →♦i♦
kp), for
h, j, i, k ≥0. In negation normal form and in the absence of implication, the
axioms become □h ♦i ¯p∨□j ♦k p (equivalently, ■h□j ¯p∨♦i♦
kp). We have limited
ourselves here to the Scott-Lemmon axioms in order to simplify the notation and
exposition, and also because this class of axioms is well-known within the modal
logic community. Nevertheless, it is worth observing that our results extend in a
natural way beyond the Scott-Lemmon axioms to Kracht’s [14] primitive tense
axioms (or, equivalently, I2 [5] or analytic inductive [12] axioms).
2.1
Display Calculi for Tense Logics
Introduced under the name Display Logic, Belnap’s Display Calculus [1] gen-
eralises Gentzen’s sequent calculus by supplementing the structural connective
(comma) with new structural connectives. The beauty of the display calculus lies
in a general cut-elimination theorem for all calculi obeying eight easily veriﬁable
syntactic conditions [1,22]; this makes the display calculus a good candidate for
capturing large classes of logics in a uniﬁed way, irrespective of their semantics
or connectives.
We will present Gor´e et al.’s [10] display calculus SKT for Kt. This calculus
can be seen as a one-sided version of Kracht’s [14] display calculus for Kt, and
also as a variant of Kashima’s calculus [13]. The sequents of SKT are generated
by the following grammar: X := A|X, X|◦{X}|•{X}.

From Display to Labelled Proofs for Tense Logics
123
Deﬁnition 1 (The Calculus SKT[10])
(id)
Γ, p, p
Γ, A, B
( ∨)
Γ, A ∨B
Γ, A
Γ, B ( ∧)
Γ, A ∧B
Γ, Δ, Δ (ctr)
Γ, Δ
Γ
(wk)
Γ, Δ
Γ, ◦{Δ} (rf)
•{Γ}, Δ
Γ, •{Δ} (rp)
◦{Γ}, Δ
Γ, •{A} (■)
Γ, ■A
Γ, ◦{A} (□)
Γ, □A
Γ, •{Δ, A},♦A
(♦)
Γ, •{Δ},♦A
Γ, ◦{Δ, A}, ♦A (♦)
Γ, ◦{Δ}, ♦A
SKT is referred to as a shallow nested sequent calculus because (i) the ◦{ } and
•{ } provide (two types of) nesting and (ii) all the rules are shallow in the sense
that they operate at the root of the sequent (when the sequent is viewed in terms
of its grammar tree). Although the rules in SKT are shallow, the two rules (rf)
and (rp) can be used to bring nested formulae to the root.
Deﬁnition 2 (display property). A display calculus has the display property
if it contains a set of rules (the ‘display rules’) such that for any sequent X
containing an occurrence of Y, there exists Z such that Y, Z is derivable from X
using the display rules.
The display property states that any substructure in X can be brought to the
‘top level’ using the display rules. By inspection, SKT has the display property
when {(rp), (rf)} is chosen to be the set of display rules. Incidentally, the display
property is a crucial component in the proof of the general cut-elimination the-
orem. The interpretation I of a display sequent as a tense formula is deﬁned as
follows.
I(A) = A for every formula A
I(◦X) = □I(X)
I(X, Y ) = I(X) ∨I(Y )
I(•X) = ■I(X)
A modular method of extending a base display calculus for Kt by a large
class of axioms inclusive of the Scott-Lemmon axioms was introduced in [14] (see
also [5]). Following [14], Gor´e et al. [10] present the rule d(h, i, j, k) corresponding
to the Scott-Lemmon axiom ■h□j ¯p ∨♦i♦
kp.
Γ, ◦i{•k{Δ}} d(h, i, j, k)
Γ, •h{◦j{Δ}}
Theorem 1 ([10,14]). Let S be any ﬁnite set of Scott-Lemmon axioms. A ∈
Kt+S iﬀA is derivable in SKT+S′, where S′ = {d(h, i, j, k)|■h□j ¯p∨♦i♦
kp ∈S}.
2.2
Labelled Calculi for Tense Logics
Labelled sequents [8,16] generalise Gentzen sequents by the preﬁxing of state
variables to formulae occurring in the sequent and by making the relational
semantics explicit in the syntax. A labelled sequent has the form R, Γ where the
relation mset (multiset) R consists of terms of the form Rxy. Meanwhile Γ is a

124
A. Ciabattoni et al.
multiset of labelled formulae (e.g. x : A →B, y : p). A labelled sequent can be
viewed as a directed graph (deﬁned using the set R) with formulae decorating
each node [19,20].
Negri [17] has presented a method for generating cut-free and contraction-free
labelled sequent calculi for the large family of modal logics whose Kripke seman-
tics are deﬁned by geometric (ﬁrst-order) formulae. The proof of cut-elimination
is general in the sense that it applies uniformly to every modal logic deﬁned by
geometric formulae. This result has been extended to labelled sequent calculi
for intermediate and other non-classical logics [6] and indeed to arbitrary ﬁrst-
order formulae [7]. See also Vigan`o [21] where non-classical logics with semantics
deﬁned by Horn formulae are investigated using cut-free labelled calculi intro-
duced therein.
We begin by extending in the natural way the usual labelled sequent calculus
for K to a labelled sequent calculus for Kt.
Deﬁnition 3 (The labelled sequent calculus G3Kt [17])
(id)
R, x : p, x : p, Γ
R, x : A, x : B, Γ
( ∨)
R, x : A ∨B, Γ
R, x : A, Γ
R, x : B, Γ
( ∧)
R, x : A ∧B, Γ
R, Ryx, y : A, Γ
(■)∗
R, x : ■A, Γ
R, Rxy, y : A, Γ
(□)∗
R, x : □A, Γ
R, Ryx, y : A, x :♦A, Γ
(♦)
R, Ryx, x :♦A, Γ
R, Rxy, y : A, x : ♦A, Γ
(♦)
R, Rxy, x : ♦A, Γ
The (□) and (■) rules have a side condition: (∗) the variable y does not occur
in the conclusion. When a variable is not allowed to occur in the conclusion of
an inference, we refer to it as an eigenvariable.
Following the method in [17], the rule l(h, i, j, k) corresponding to the Scott-
Lemmon axiom ■h□j ¯p ∨♦i♦
kp is given below. We use the notation Rnxz to
represent a relational sequence Rxy1, Ry1y2, ..., Ryn−1z of length n.
R, Rivx, Rkux, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
l(h, i, j, k)∗
R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
(∗) All variables occurring in the relational atoms Rivx, Rkux with the excep-
tion of v and u are eigenvariables.
Remark 1. In the rule above, some care is needed in the boundary case when
some of the parameters h, i, j, and k are zero. The table below speciﬁes the
instances of the rule depending on whether the parameter is greater than zero
(marked with >), or equal to zero (marked with 0):

From Display to Labelled Proofs for Tense Logics
125
h
j
i
k
Premise
Conclusion
>
>
>
>
R, Rivx, Rkux, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
0
>
>
>
R, Rivx, Rkux, Rjvu, v : Δ, u : Δ′, Γ
R, Rjvu, v : Δ, u : Δ′, Γ
0
>
>
0
R, Rivu, Rjwu, v : Δ, u : Δ′, Γ
R, Rjvu, v : Δ, u : Δ′, Γ
>
0
0
>
R, Rkuv, Rhuv, v : Δ, u : Δ′, Γ
R, Rhuv, v : Δ, u : Δ′, Γ
0
0
>
>
R, Rivx, Rkvx, v : Δ, v : Δ′, Γ
R, v : Δ, v : Δ′, Γ
0
0
>
0
R, Rivv, v : Δ, v : Δ′, Γ
R, v : Δ, v : Δ′, Γ
>
>
>
0
R, Rivu, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
0
0
0
0
R, v : Δ, u : Δ′, Γ
R, v : Δ, u : Δ′, Γ
Although there are sixteen cases to consider, we only give eight of these
as the others are similar. For some entries in the table, the equality sym-
bol that arises (R0uv is taken to be u = v) has been eliminated by suitable
argumentation. This argumentation can be formalised using the equality rules
speciﬁed by Negri [17]. In particular, when i = k = 0 and h > 0, j > 0 the rule
obtained in this way has the following form.
R, Rhwv, Rjwv, v : Δ, v : Δ′, Γ
l(h, i, j, k)∗
R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
Negri [17] does not explicitly consider structural rules of this form (observe how
v : Δ′ in the premise becomes u : Δ′ in the conclusion). The results in this paper
apply to such rules as well, by extending Negri’s arguments in order to justify
the elimination of the equality symbol.
The following contraction and weakening rules are admissible [17] in G3Kt +
l(h, i, j, k).
R, Q, Q, Δ, Δ, Γ
(ctr)
R, Q, Δ, Γ
R, Γ
(wk)
R, Q, Γ, Δ
Theorem 2 ([17]). Let S be any ﬁnite set of Scott-Lemmon axioms. A ∈Kt+S
iﬀx : A is derivable in SKT + S′, where S′ = {l(h, i, j, k)|■h□j ¯p ∨♦i♦
kp ∈S}.
3
Interpreting a Display Sequent as a Labelled UT
In this section we show how to translate (back and forth) a display sequent into
a labelled directed graph whose underlying undirected graph is a tree.
We write V = V1⊔V2 to mean that V = V1∪V2 and V1∩V2 = ∅. The multiset
union of multisets M1 and M2 is denoted M1 ⊎M2. A labelling function L is a
map from a set V to a multiset of tense formulae. For labelling functions L1
and L2 on the set V1 and V2 respectively, let L1 ∪L2 be the labelling function
on V1 ∪V2 deﬁned as follows:
L1 ∪L2(x) =
⎧
⎪
⎨
⎪
⎩
L1(x)
x ∈V1, x ̸∈V2
L2(x)
x ̸∈V1, x ∈V2
L1(x) ⊎L2(x)
x ∈V1, x ∈V2

126
A. Ciabattoni et al.
A labelled graph (V, E, L) is a directed graph (V, E) (V ̸= ∅) equipped with a
labelling function L on V .
Deﬁnition 4 (Labelled graph isomorphism). We say that two labelled
graphs u1 = (V1, E1, L1) and u2 = (V2, E2, L2) are isomorphic (written u1 ∼= u2)
if and only if there is an isomorphism f : V1 →V2 such that:
(i) for every x, y ∈V1, (x, y) ∈E1 iﬀ(fx, fy) ∈E1
(ii) for every x ∈V , L(x) = L(fx).
Deﬁnition 5 (Labelled UT). A labelled graph whose underlying (undirected)
graph is a tree is termed a UT (underlying tree).
Example 1. Assuming that the nodes are decorated with multisets of formulae,
the following two graphs represent labelled UTs:
x
y







z

w

y








u

v
x
Interpreting a Display Sequent Γ as a labelled UT. Every display sequent
has a natural interpretation as a labelled tree with two types of directed edges:
◦→and
•→. If we interpret every directed edge α
•→β as the directed edge β
◦←α,
we can then interpret every display sequent as a connected labelled graph with a
single type of directed edge (so we can drop the ◦symbol altogether). Moreover,
it is easy to see that its underlying graph (i.e. the undirected graph obtained
obtained treating all edges as undirected) has no cycles.
Remark 2. Every display sequent Γ can be interpreted naturally as a UT.
Example 2. First interpret the display sequent A, ◦{B, •{}}, •{D, E, •{F},
◦{G}} as the labelled tree with two types of directed edges, below left. Next,
convert this labelled tree to a labelled graph (with a single type of directed edge)
by reading each α
•→β as α ←β (below right).
x
◦

•








y
•

w
•
	
◦








z
u
v
x

y
w









z

u









v
L(x) = {A}
L(y) = {B}
L(z) = ∅
L(w) = {D, E}
L(u) = {F}
L(v) = {G}

From Display to Labelled Proofs for Tense Logics
127
For concreteness let us formally deﬁne the map du from a display sequent to
a UT. Let N<N denote the set of ﬁnite sequences on N.
Given (x) ∈N<N and a display sequent Γ, consider the following recursive
deﬁnition for du(x)(Γ) on the depth of Γ:
1. Base case. Γ = A1, . . . , AM. A pictorial representation is given below right.
du(x)(A1, . . . , AM) = ({(x)}, ∅, x →{A1, . . . , An})
(x)
A1, . . . , AM
2. Inductive case. Γ = A1, . . . , AM, ♥1{X1}, . . . , ♥N{XN} where ♥j ∈{◦, •}.
Since each ♥j{Xj} has strictly smaller depth than Γ, the following are well-
deﬁned:
du(xj)(♥j{Xj}) = (Vj, Ej, Lj) for 1 ≤j ≤N
Deﬁne du(x)(Γ) = (V, E, L) such that
V = {(x)} ∪V1 ∪. . . ∪VN
E = {((x), (xj)) | ♥j = ◦} ∪{((xj), (x)) | ♥j = •} ∪E1 ∪. . . ∪EN
L = {(x) →{A1, . . . , AM}} ∪L1 ∪. . . ∪LN
A pictorial representation is given below. The orientation of the arrows is
determined by ♥j. If ♥j = ◦then the arrow directs away from (x); if ♥j = •
then the arrow directs towards (x)
du(x1)(X1)
. . .
du(xN)(XN)
(x)
A1, . . . , AM
♥1
♥N−1
♥2
♥N
Remark 3. Every comma occurring in the display sequent Γ is associated
(though not necessarily a one-to-one association) with a vertex in du(Γ).
Example 3. Given Γ = A, ◦{B, •{C}}, •{D}, the UT du(1)(Γ) = (V, E, L) is
computed below:
(11)
B
(111)
C

(12)
D

(1)
A

Note that in practice we use the more familiar symbols x, y, z, ... to denote
labels. The numerical labels are used here for technical convenience.

128
A. Ciabattoni et al.
Deﬁnition 6 (u[v] notation). We write u[v] to mean the labelled graph con-
taining labelled subgraphs u[ ] and v which have a single vertex x in common such
that the label of x in u[v] is the union of L(x) from u[ ] and v.
Example 4. Consider the labelled graph u[v]—x is the common vertex between
u[] and v—shown below right. Then either of the two labelled graphs below right
may be v, and the other will be u[].
x3
M3

x2
M2
x
M ⊎N


x1
M1

u
N1
	
	
	
	
	
	
	
	
	
v
N2
x3
M3

x2
M2
x
M

x1
M1

x
N

u
N1








v
N2
If u[v] = (V, E, L), then there exist partitions V = V1⊔{x}⊔V2, E = E1⊔E2,
and L1 and L2 such that L = L1 ∪L2, where u[ ] = (V1 ⊔{x}, E1, L1) and v =
(V2 ⊔{x}, E2, L2). In particular, L(x) = L1(x) ⊎L2(x). Note that when u[v] is
a labelled UT, then u[ ] and v must necessarily be labelled UTs.
We have seen that every display sequent deﬁnes (up to isomorphism) a
labelled UT. With a slight abuse of notation, we will use the display sequent
notation to denote a labelled UT. For example, we will write u[X] to mean the
labelled graph such that the labelled graph u[ ] and the labelled UT du(X) are
subgraphs with a single common vertex. The context will make it clear if we are
referring to a display sequent or a labelled UT.
The translation from a display sequent to a labelled UT extends naturally to
a translation from a display sequent rule to a labelled UT rule. This leads us to
the deﬁnition of the following calculus.
Deﬁnition 7 (UT calculus). Every sequent in this calculus is a labelled UT.
(id)u
u[p, p]
u[A]
u[B] (∧)u
u[A ∧B]
u[A, B]
(∨)u
u[A ∨B]
A, ◦{X} (■)u
■A, X
u[◦{Δ, A}, ♦A] (♦)u
u[◦{Δ}, ♦A]
u[◦{Δ,♦A}, A]
(♦)u
u[◦{Δ,♦A}]
u[◦{A}] (□)u
u[□A]
u[Γ]
(wk)u
u[Γ, Δ]
u[Δ, Δ] (ctr)u
u[Δ]
For convenience, we drop the subscript (x) and write du for du(x).

From Display to Labelled Proofs for Tense Logics
129
Recall that SKT + d(h, i, j, k) (see below left) is a calculus for the exten-
sion of Kt with the Scott-Lemmon axiom ■h□j ¯p ∨♦i♦
kp. We deﬁne the UT
rule u(h, i, j, k) as below right.
Γ, ◦i{•k{Δ}} d(h, i, j, k)
Γ, •h{◦j{Δ}}
u[◦i{•k{Δ}}] u(h, i, j, k)
u[•h{◦j{Δ}}]
Since display sequents may be interpreted as trees with two types of edges
(◦-edges and •-edges), they possess a root node, whereas UTs do not possess
a root in general. Nevertheless, the underlying tree structure of a UT permits
us to view any node as the root, and the lemma below ensures that we obtain
deductively equivalent labelled UTs via the residuation rules regardless of the
node where we begin the translation.
Lemma 1. For every Γ and Δ: du(Γ, ◦{Δ}) ∼= du(•{Γ}, Δ)
Proof. Let (V, E, L) = du(Γ, ◦{Δ}). Then there exists x, y ∈V and (x, y) ∈E
such that V = V1 ⊔{x}⊔V2 ⊔{y} and E = E1 ⊔E2 ⊔{(x, y)} and du(Γ) = (V1 ⊔
{x}, E1, L|V1⊔{x}) and du(Δ) = (V2 ⊔{y}, E2, L|V2⊔{y}). In particular, observe
that comma displayed in Γ, ◦{Δ} corresponds to x and the nesting where Δ
occurs corresponds to y.
Now consider du(•{Γ}, Δ) = (V ′, E′, L′). There exists u, v ∈V ′ and (u, v) ∈
E such that V ′ = V ′
1 ⊔{u} ⊔V ′
2 ⊔{y} and E′ = E′
1 ⊔E′
2 ⊔{(u, v)} and du(Γ) =
(V ′
1 ⊔{u}, E′
1, L′|V ′
1⊔{u}) and du(Δ) = (V ′
2 ⊔{v}, E′
2, L′|V ′
2⊔{v}). In particular,
observe that comma displayed in •{Γ}, Δ corresponds to v and the nesting
where Γ occurs corresponds to u.
It follows that there are isomorphisms witnessing each of the following such
that x maps to u (ﬁrst line) and y maps to v (second line).
du(Γ) = (V1 ⊔{x}, E1, L|V1⊔{x}) ∼= (V ′
1 ⊔{u}, E′
1, L′|V ′
1⊔{u}) = du(Γ)
du(Δ) = (V2 ⊔{y}, E2, L|V2⊔{y}) ∼= (V ′
2 ⊔{v}, E′
2, L′|V ′
2⊔{v}) = du(Δ)
Taking the graph union of these disjoint graphs:
(V1 ⊔{x} ⊔V2 ⊔{y},E1 ⊔E2, L|V1⊔{x} ∪L|V2⊔{y}) ∼=
(V ′
1 ⊔{u} ⊔V ′
2 ⊔{y}, E′
1 ⊔E′
2, L′|V ′
1⊔{u} ∪L′|V ′
2⊔{v})
Adding the edge (x, y) on the left and (u, v) on the right, we get (V, E, L) ∼=
(V ′, E′, L′).
Interpreting a Labelled UT as a Display Sequent. Given a UT u =
⟨V, E, L⟩we ﬁrst pick a vertex x ∈V to compute the display sequent udx(u).
If E = ∅, then ud(u) = L(x) is the desired display sequent. Otherwise, for all
n forward looking edges (x, yi) ∈E (with 1 ≤i ≤n) where yi is the common
label of u = u[vi] and vi, and for all k backward looking edges (zj, x) ∈E (with

130
A. Ciabattoni et al.
1 ≤j ≤k) where zj is the common label of u = u[wj] and wj, we deﬁne the
image of udx(u) as the display sequent
L(x), ◦{udy1(v1)}, . . . , ◦{udyn(vn)}, •{udz1(w1)}, . . . , •{udzk(wk)}
Since the UTs v1, . . . , vn, w1, . . . , wk are smaller than u, the recursive deﬁnition
of ud is well-founded.
Lemma 2. For any UT u = ⟨V, E, L⟩, and for any vertices x, y ∈V, the display
sequent udx(u) is derivable from udy(u) via the residuation rules (rf) and (rp).
Proof. Follows by Lemma 1.
When translating a labelled UT we must choose a vertex as the starting
point of our translation. This lemma states that all display sequents obtained
from choosing a diﬀerent vertex are mutually derivable from one another. In
fact, all such display sequents are display equivalent, meaning they are derivable
from each other by use of the residuation rules (rp) and (rf) only. To clarify
the translation procedure, we provide an example below of the various display
sequents obtained from translating at a diﬀerent vertex initially.
Example 5. Suppose we are given the labelled UT u = ⟨V, E, L⟩where V =
{x, y, z}, E = {(x, y), (z, x)}, L(x) = {A}, L(y) = {B, C}, and L(z) = {D}.
A pictorial representation of the labelled UT u is given on the left with the
corresponding display sequent translations on the right:
x
A

y
B, C
z
D








udx(u) = A, ◦{B, C}, •{D}
udy(u) = B, C, •{A, •{D}}
udz(u) = D, ◦{A, ◦{B, C}}
When providing the construction of an eﬀective translation between display
calculus proofs and UT calculus proofs, we make use of the notation Γ, Δ for
display sequents and u[v] for corresponding labelled UTs (under the translation).
The following lemma ensures that the pieces of the display sequent Γ and Δ,
and the pieces of the labelled UT u[] and v, correctly map to each other under
our translation functions.
Lemma 3
(i) For every Γ and Δ, du(Γ, Δ) is the UT u[v], where v is the UT du(Δ)
and u[ ] is the UT du(Γ).
(ii) For every UT u[v], ud(u[v]) is the display sequent Γ, Δ (up to display equiv-
alence) where Γ = ud(u[ ]) and Δ = ud(v).
Proof. By construction of du and ud.

From Display to Labelled Proofs for Tense Logics
131
Theorem 3 (Translating derivations: SKT + S and UT calculus+S′).
Let S be any ﬁnite set of d(h, i, j, k) rules and S′ be the set {u(h, i, j, k)|
d(h, i, j, k) ∈S}. Then:
(i) Let δ be a derivation of Γ in SKT+S. Then there is an eﬀective translation
of δ to a derivation δ′ of du(Γ) in the UT calculus with S′.
(ii) Let δ be a derivation of the labelled UT u in the UT calculus with S′. Then
there is an eﬀective translation of δ to a derivation of ud(g) in SKT + S.
Proof. (i) Induction on the height of δ.
Base case. du(Γ, p, ¯p) is a UT of the form u[p, ¯p] (Lemma 3(i)) and is hence
an initial sequent in the UT calculus.
Inductive case. It suﬃces to simulate each rule instance of SKT in the UT
calculus. Every rule in SKT other than (rf), (rp), (■) and (♦) has the form below
left for suitable Y1 and Y0; moreover, there is a corresponding rule in the UT
calculus as shown below right.
Γ, Y1 (r)
Γ, Y0
u[Γ, Y1] (r)u
u[Γ, Y0]
The induction hypothesis gives us a derivation of du(Γ, Y1) = u[Γ, Y1]. Apply-
ing (r)u we get u[Γ, Y0] = du(Γ, Y0) as required.
We consider the remaining rules below.
Γ, ◦{Δ} (rf)
•{Γ}, Δ
dux(Γ, ◦{Δ})
Lem. 1
∼= dux(•{Γ}, Δ)
Γ, •{Δ} (rp)
◦{Γ}, Δ
dux(Γ, •{Δ})
Lem. 1
∼= dux(◦{Γ}, Δ)
Γ, •{A} (■)
Γ, ■A
dux(Γ, •{A})
◦{Γ}, A (■)
Γ, ■A
Γ, •{Δ, A},♦A
(♦)
Γ, •{Δ},♦A
dux(Γ, •{Δ, A},♦A)
Δ, A, ◦{Γ,♦A}
(♦)
Δ, ◦{Γ,♦A}
du(Γ, •{Δ},♦A)
(ii) Induction on the height of δ. The argument is similar to the above case
and uses Lemma 3(ii).
4
From Labelled UTs to Labelled Sequents
We identify a subclass of labelled sequents which we call G3Kt(UT) sequents,
and prove that they correspond to labelled UT graphs. Due to the relations of
the latter with the display calculi shown in the previous section, it follows that
every derivation in the SKT + u(h, i, j, k) calculus corresponds to a derivation in
the labelled calculus restricted to G3Kt(UT) sequents.

132
A. Ciabattoni et al.
Transforming a labelled UT u = (V,E,L) into a labelled sequent R, −.
Deﬁne R = {Rxy|(x, y) ∈E} and
Γ =

x∈V,L(x)̸=∅
x : L(x)
where x : L(x) represents the multiset L(x) with each formula prepended with
a label x.
Example 6. The UT u = ⟨V, E, L⟩where V = {x, y, z}, E = {(x, y), (z, x)},
L(x) = {A}, L(y) = {B}, and L(z) = {C} corresponds to the labelled sequent
Rxy, Rzx, x : A, y : B, z : C.
Transforming a labelled sequent R, Γ into a labelled graph (V,E,L).
Let V be the set of all labels occurring in R, Γ . Deﬁne
E = {(x, y)|Rxy ∈R}
L(x) = {multiset of formulae with label x in Γ}
Example 7. The labelled sequent Rxy, Ryz, Rux, x : A, z : B, z : C, u : D
becomes the UT u = ⟨V, E, L⟩where V = {x, y, z, u}, E = {(x, y), (y, z), (u, x)},
L(x) = {A}, L(y) = ∅, L(z) = {B, C} and L(u) = {D}.
The reader will observe that the translations are obtained rather directly.
This is because the main diﬀerence between a labelled graph and a labelled
sequent is notation. The main step of the translation was already established in
the previous section. Our interest in this work is the image of a display sequent
in the labelled calculus. This motivates the following deﬁnitions.
Deﬁnition 8 (G3Kt(UT) sequent). A labelled sequent whose image (under the
above translation) is a labelled UT is called a G3Kt(UT) sequent.
Deﬁnition 9 (G3Kt(UT) calculus). Deﬁne the calculus G3Kt(UT) to be the
labelled calculus restricted to G3Kt(UT) sequents and with weakening and con-
traction deﬁned as follows:
R, Γ
(wk)∗
ul
R, Q, Δ, Γ
R, Q, ˆQ, Δ, ˆ
Δ, Γ
(ctr)∗
ul
R, Q, Δ, Γ
Weakening has the side condition that the conclusion must be a G3Kt(UT)-
sequent. Contraction possesses side conditions that ensure it behaves just as the
(ctr)u rule:
1. The labelled graph of ˆQ, ˆ
Δ must be isomorphic to the labelled graph of Q, Δ.
2. The conclusion must be a G3Kt(UT)-sequent.
3. Both Q, Δ and ˆQ, ˆ
Δ form labelled UTs that share a root, and all other vari-
ables in ˆQ, ˆ
Δ do not appear in the conclusion of the inference, i.e. they are
eigenvariables.

From Display to Labelled Proofs for Tense Logics
133
We use the notation (r)ul to indicate the remaining inference rules of G3Kt(UT).
For h, i, j, k ∈N, deﬁne ul(h, i, j, k) as follows:
R, Rivx, Rkux, v : Δ, u : Δ′, Γ
ul(h, i, j, k)∗
R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
The asterisk indicates the following side conditions: (i) all variables occur-
ring in Rivx, Rkux with the exception of v and u are eigenvariables and (ii) all
variables occurring in Rhwv, Rjwu with the exception of v and u are fresh.
Remark 4. Similar to the presentation of the l(h, i, j, k) rules (cf. Remark 1), we
provide the table below showing the diﬀerent instances of the rule depending
on the values of the parameters h, i, j, and k. The reduction in cases is due to
the fact that we allow the ul(h, i, j, k) rules to relabel formulae from premise to
conclusion–an action which is not allowed for the l(h, i, j, k) rules.
i k
Premise
> > R, Rivx, Rkux, v : Δ, u : Δ′, Γ
0 >
R, Rkuv, v : Δ, u : Δ′, Γ
> 0
R, Rivu, v : Δ, u : Δ′, Γ
0 0
R, v : Δ, v : Δ′, Γ
h j
Conclusion
> > R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
0 >
R, Rjwu, w : Δ, u : Δ′, Γ
> 0
R, Rhwv, v : Δ, w : Δ′, Γ
0 0
R, w : Δ, w : Δ′, Γ
To see that the G3Kt(UT) + ul(h, i, j, k) calculus is well-deﬁned, it suﬃces
to observe that the conclusion of every G3Kt rule is a G3Kt(UT) sequent given
that the premise(s) is (are) G3Kt(UT) sequents.
Lemma 4. If the premise of a G3Kt(UT) + ul(h, i, j, k) inference is a
G3Kt(UT)-sequent, then the conclusion is an G3Kt(UT)-sequent.
Proof. We argue the result for the (wk)ul, (ctr)ul, (■)ul, and ul(h, i, j, k) rules
since all other cases are similar or trivial.
Case 1 and 2. These cases follow from the side conditions on the (wk)ul
and (ctr)ul rules, which only allow application of the rule when the result is a
G3Kt(UT) sequent.
Case 3. Assume that R, Ryx, y : A, Γ is a G3Kt(UT)-sequent and that u =
⟨V, E, L⟩is the corresponding UT. Since y is an eigenvariable, the conclusion
R, x : ■A, Γ gives a labelled graph u′ = ⟨V ′, E′, L′⟩where V ′ = V −{y},
E′ = E −{(y, x)}, L′(y) is undeﬁned, L′(x) is equal to L(x) extended with
x →{■A}, and L′ is equal to L for all other labels in V ′.
Case 4. We prove the claim for when h, i, j, k > 0 since other cases are
similar. Assume that the premise R, Rixy, Rkzy, Γ is a G3Kt(UT)-sequent with
all variables ym strictly between x and z eigenvariables. Observe that in u =
⟨V, E, L⟩there is a path of length i + k from the node x to z where the ﬁrst i
edges are forward looking, and the last k edges are backwards looking. Observe
that the UT u′ = ⟨V ′, E′, L′⟩of the conclusion R, Rhwx, Rjwz, Γ will contain a
path of length h + j from the node x to z where the ﬁrst h edges are backwards
looking, and the last j edges are forwards looking. Due to the eigenvariable

134
A. Ciabattoni et al.
condition on all nodes ym strictly between x and z, it cannot be the case that
an edge given by R contains a label ym, and it must be the case that L(ym) = ∅
(thus ensuring u′ is connected). Also, all new nodes along the h+j-path strictly
between x and z will be fresh (thus ensuring u′ is free of cycles). Hence, u′ will
be a UT.
Lemma 5 (Translating derivations: G3Kt(UT)+S and UT calculus+S′).
Let
S
be
any
ﬁnite
set
of
ul(h, i, j, k)
rules
and
S′
=
{u(h, i, j, k)|
ul(h, i, j, k) ∈S}. Then
(i) Let δ be a derivation of x : A in G3Kt(UT) + S. Then there is an eﬀective
translation of δ to a derivation δ′ of A in the UT calculus+S′.
(ii) Let δ be a derivation of A in the UT calculus+S′. Then there is an eﬀective
translation of δ to a derivation δ′ of x : A in G3Kt(UT) + S.
Proof. Follows from the observation that the translation of every rule instance
in G3Kt(UT) + S is a rule instance in the UT calculus+S′ and vice versa.
Combining the previous results we obtain:
Theorem 4 (Translating derivations: SKT + S and G3Kt(UT) + S′). Let
S be any ﬁnite set of d(h, i, j, k) rules and S′ = {ul(h, i, j, k)|d(h, i, j, k) ∈S}.
Then
1. Let δ be a derivation of A in SKT + S. Then there is an eﬀective translation
of δ to a derivation δ′ of x : A in G3Kt(UT) + S′.
2. Let δ be a derivation of x : A in G3Kt(UT) + S′. Then there is an eﬀective
translation δ to a derivation δ′ of A in SKT + S.
Proof. Immediate from Theorem 3 and Lemma 5.
Example 8. Below we translate a derivation of ■□¯p ∨♦♦p in SKT + d(1, 1, 1, 1)
to a derivation in G3Kt(UT) + ul(1, 1, 1, 1).
♦p, •{p, ¯p}, •{♦♦p}
(♦)
♦p, •{¯p}, •{♦♦p} (rp)
◦{♦p, •{¯p}}, ♦♦p (♦)
◦{•{¯p}}, ♦♦p d(1, 1, 1, 1)
•{◦{¯p}}, ♦♦p (rp)
◦{¯p}, ◦{♦♦p} (□)
□¯p, ◦{♦♦p} (rf)
•{□¯p}, ♦♦p (■)
■□¯p, ♦♦p
(∨)
■□¯p ∨♦♦p
Rzu, Rxu, u :♦p, z : p, z : ¯p, x : ♦♦p
(♦)ul
Rzu, Rxu, u :♦p, z : ¯p, x : ♦♦p (♦)ul
Rzu, Rxu, z : ¯p, x : ♦♦p ul(1, 1, 1, 1)
Ryz, Ryx, z : ¯p, x : ♦♦p (□)ul
Ryx, y : □¯p, x : ♦♦p (■)ul
x : ■□¯p, x : ♦♦p (∨)ul
x : ■□¯p ∨♦♦p

From Display to Labelled Proofs for Tense Logics
135
5
Labelled UTs vs Labelled Sequents
In the previous sections, we observed how to embed the display calculus SKT+S
(for a ﬁnite set S of d(h, i, j, k) rules) in the labelled calculus formalism,
in particular, as a proper fragment, which we called G3Kt(UT) + S′ (S′ =
{ul(h, i, j, k)|d(h, i, j, k) ∈S}). Indeed, an G3Kt(UT)-sequent is a severe restric-
tion of a labelled sequent since the underlying graph in the former is restricted
to a tree. For example, Rxy, Ryx, x : A, z : B is a labelled sequent in the tradi-
tional sense, but fails to be a G3Kt(UT)-sequent since it contains the relational
cycle Rxy, Ryx and is not connected due to z : B. As a result we have two
distinct labelled calculi for Scott-Lemmon extensions of Kt. In this section we
investigate the natural question that arises: what is the relationship between
these calculi? As seen below, the labelled calculus simulates G3Kt(UT) + S′,
despite the slightly diﬀerent rules (i.e. ul(h, i, j, k)) used by the latter to capture
the Scott-Lemmon axioms. The next question is therefore whether the converse
also holds, that is, whether the two calculi can represent the same proofs. In the
case of the normal minimal tense logic Kt the answer is aﬃrmative.
From
G3Kt(UT) + ul(h, i, j, k) to G3Kt + l(h, i, j, k). As observed in
Remark 1, the structural rules corresponding to i = k = 0 and h > 0, j > 0 do
not match the form of the rules given in [17] (and hence the results in [17] need
to be suitably extended to apply to this case). Although an eﬀective translation
from G3Kt(UT) + ul(h, i, j, k) to G3Kt + l(h, i, j, k) can be deﬁned for this case,
in the following we restrict ourselves to i > 0 or k > 0.
Lemma 6 ([17], Sect. 4). The calculus G3Kt+l(h, i, j, k) admits height preserv-
ing substitution of variables.
In the following, the requirement that i > 0 or k > 0 may be dropped by a slight
extension of Negri’s arguments (see after Remark 1).
Theorem 5. Let δ be a derivation of x : A in G3Kt(UT) + ul(h, i, j, k), with
i > 0 or k > 0. Then there is an eﬀective translation of δ to a derivation δ′
of x : A in G3Kt + l(h, i, j, k).
Proof. We prove the result by induction on the height of the derivation δ.
Base case. It is easy to see that initial sequents of G3Kt(UT) are initial
sequents of G3Kt.
Inductive step. We show the inductive step for four instances ul(h, i, j, k),
ul(h, i, 0, k), ul(0, i, 0, k), and ul(0, i, 0, 0) (h, i, j, k > 0). We also show the induc-
tive step for the (ctr)ul rule. The translation of the other rules is trivial.
R, Rivx, Rkux, v : Δ, u : Δ′, Γ
R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ
R, Rivx, Rkux, v : Δ, u : Δ′, Γ
(wk)
R, Rhwv, Rjwu, Rivx, Rkux, v : Δ, u : Δ′, Γ
l(h, i, j, k)
R, Rhwv, Rjwu, v : Δ, u : Δ′, Γ

136
A. Ciabattoni et al.
R, Rivx, Rkux, v : Δ, u : Δ′, Γ
R, Rhwv, v : Δ, w : Δ′, Γ
R, Rivx, Rkux, v : Δ, u : Δ′, Γ
(wk)
R, Rhuv, Rivx, Rkux, v : Δ, u : Δ′, Γ
l(h, i, 0, k)
R, Rhuv, v : Δ, u : Δ′, Γ
R, Rivx, Rkux, v : Δ, u : Δ′, Γ
R, v : Δ, v : Δ′, Γ
R, Rivx, Rkux, v : Δ, u : Δ′, Γ
lem. 6
R, Rivx, Rkvx, v : Δ, v : Δ′, Γ
l(0, i, 0, k)
R, v : Δ, v : Δ′, Γ
R, Rivu, v : Δ, u : Δ′, Γ
R, v : Δ, v : Δ′, Γ
R, Rivu, v : Δ, u : Δ′, Γ
lem. 6
R, Rivv, v : Δ, v : Δ′, Γ
l(0, i, 0, 0)
R, v : Δ, v : Δ′, Γ
R, Q, ˆQ, Δ, ˆ
Δ, Γ
R, Q, Δ, Γ
R, Q, ˆQ, Δ, ˆ
Δ, Γ
lem. 6
R, Q, Q, Δ, Δ, Γ
(ctr)
R, Q, Δ, Γ
Example 9. The derivation of x : ■□p ∨♦♦p in G3Kt(UT) + ul(1, 1, 1, 1) (see
Example 8) can be transformed into a derivation in G3Kt+l(1, 1, 1, 1) as follows:
Rzu, Rxu, u :♦p, z : p, z : ¯p, x : ♦♦p
(♦)
Rzu, Rxu, u :♦p, z : ¯p, x : ♦♦p (♦)
Rzu, Rxu, z : ¯p, x : ♦♦p
(w)
Rzu, Rxu, Ryz, Rzx, z : ¯p, x : ♦♦p l(1, 1, 1, 1)
Ryz, Ryx, z : ¯p, x : ♦♦p (□)
Ryx, y : □¯p, x : ♦♦p (■)
x : ■□¯p, x : ♦♦p (∨)
x : ■□¯p ∨♦♦p
From G3Kt + l(h, i, j, k) to G3Kt(UT)+ul(h, i, j, k). Consider now the
converse direction. Let S be a ﬁnite set of Scott-Lemmon axioms and deﬁne
Sul = {ul(h, i, j, k)| ■h□j ¯p ∨♦i♦
kp ∈S}
Sl = {l(h, i, j, k)| ■h□j ¯p ∨♦i♦
kp ∈S}
Given a derivation δ in G3Kt + Sl, in general δ will not be a derivation
in G3Kt(UT) + Sul because some sequents in δ (possibly even the endsequent)
may not be a G3Kt(UT)-sequent. A more meaningful question is: given a deriva-
tion of x : A in G3Kt + Sl, is there a derivation of x : A in G3Kt(UT) + Sul that
is eﬀectively related to δ? The constraint that the new derivation is “eﬀectively
related” is crucial, for otherwise one could trivially relate δ with the derivation δ′
obtained from the following equivalence:
⊢δ
G3Kt+Sl x : A iﬀA ∈Kt + ■h□j ¯p ∨♦i♦
kp iﬀ∃δ′. ⊢δ′
G3Kt(UT )+Sul x : A
Although the phrase ‘eﬀectively related’ has not been explicitly deﬁned, what
we envisage is a local (i.e. rule by rule) transformation on δ, which is sensitive

From Display to Labelled Proofs for Tense Logics
137
to its structure, that ultimately yields a G3Kt(UT) + Sul derivation of x : A.
Notice that the G3Kt(UT) + Sul derivation obtained via the above argument is
not sensitive to the input in the sense that any two G3Kt+Sl derivations of x : A
would be mapped to the same G3Kt(UT) + Sul derivation.
In the boundary case for Kt when S = Sl = Sul = ∅we have the following
result, which also establishes that G3Kt is an internal calculus with respect to
derivations that end with a single formula.
Proposition 1. Every labelled derivation in G3Kt of x : A is also a derivation
in G3Kt(UT).
Proof. We argue by contradiction. Let δ be a derivation of x : A in G3Kt and
suppose there is a labelled sequent R, Γ in δ that is not a G3Kt(UT)-sequent.
This means that the underlying graph of R is not a tree. If R is not connected,
then by inspection of the rules of G3Kt, the underlying graph of every sequent
below it (and hence x : A) would not be connected and this is a contradiction.
On the other hand, if R is connected and its underlying graph is not a tree, then
the underlying graph must contain a cycle. This follows from the fact that R is
assumed connected, and the fact that any acyclic connected graph forms a tree.
This means that there exist x, y, w such that {Rxw, Ryw} ⊆R. By inspection of
the rules of G3Kt, every sequent below R, Γ will contain this cycle contradicting
the assumption that x : A is the end sequent.
This argument does not work for extensions of G3Kt because the additional
structural rules may be capable of removing cycles in the following sense: the
underlying (i.e. undirected) graph of the premise might have a cycle yet the
underlying graph of the conclusion might not (this was not the case for any rule
in G3Kt). Indeed, consider the rule for transitivity:
R, Rxy, Ryz, Rxz, Γ
(Trans)
R, Ryz, Rxz, Γ
In a rule instance of (Trans), the underlying graph of the premise necessarily
contains a cycle. However, it need not be the case that the underlying graph of
the conclusion contains a cycle. As a consequence, a labelled derivation of x : A
in G3Kt + (Trans) may contain sequents whose underlying graph is not a tree.
Such a derivation cannot be a derivation in any UT calculus.
It is tempting to replace (Trans) with its non-invertible form in order
to remove the cycle. However the (ctr) rule seems not to be admissible in
G3Kt + (Trans′) which means that it needs to be included to ensure complete-
ness. The simulation of the above rule instance in G3Kt+ (ctr) + (Trans′) below
right indicates that we have merely shifted the problem to a new setting.
R, Rxz, Γ
(Trans′)
R, Rxy, Ryz, Γ
R, Rxy, Ryz, Rxz, Γ
(Trans′)
R, Rxy, Ryz, Rxy, Ryz, Γ
(ctr)
R, Rxy, Ryz, Γ
In summary: embedding the display calculus into the labelled calcu-
lus has yielded two seemingly distinct labelled calculi for the tense logics:

138
A. Ciabattoni et al.
G3Kt+l(h, i, j, k) and G3Kt(UT)+ul(h, i, j, k). Investigating the (im)possibility
of a pointwise translation from the derivations in the former to the latter is an
interesting problem which we defer to future work.
Acknowledgments. Work supported by the FWF projects: START Y544-N23 and I
2982.
References
1. Belnap Jr., N.D.: Display logic. J. Philos. Logic 11(4), 375–417 (1982)
2. Blackburn, P., de Rijke, M., Venema, Y.: Modal Logic. Cambridge Tracts in Theo-
retical Computer Science, vol. 53. Cambridge University Press, Cambridge (2001)
3. Br¨unnler. K.: Deep sequent systems for modal logic. In: Advances in Modal Logic,
vol. 6, pp. 107–119. College Publications, London (2006)
4. Chagrov, A., Zakharyashchev, M.: Modal companions of intermediate propositional
logics. Stud. Logica. 51(1), 49–82 (1992)
5. Ciabattoni, A., Ramanayake, R.: Power and limits of structural display rules. ACM
Trans. Comput. Logic 17(3), 1–39 (2016)
6. Dyckhoﬀ, R., Negri, S.: Proof analysis in intermediate logics. Arch. Math. Log.
51(1–2), 71–92 (2012)
7. Dyckhoﬀ, R., Negri, S.: Geometrization of ﬁrst-order logic. Bull. Symbolic Logic
21, 123–163 (2015)
8. Fitting, M.: Proof Methods for Modal and Intuitionistic Logics. Synthese Library,
vol. 169. D. Reidel Publishing Co., Dordrecht (1983)
9. Fitting, M.: Preﬁxed tableaus and nested sequents. Ann. Pure Appl. Logic 163(3),
291–313 (2012)
10. Gor´e, R., Postniece, L., Tiu, A.: On the correspondence between display postulates
and deep inference in nested sequent calculi for tense logics. Log. Methods Comput.
Sci. 7(2), 1–38 (2011). (2:8)
11. Gor´e, R., Ramanayake, R.: Labelled tree sequents, tree hypersequents and nested
(deep) sequents. In: Advances in Modal Logic, vol. 9. College Publications, London
(2012)
12. Greco, G., Ma, M., Palmigiano, A., Tzimoulis, A., Zhao, Z.: Uniﬁed correspondence
as a proof-theoretic tool. J. Logic Comput. (2016, to appear). https://doi.org/10.
1093/logcom/exw022
13. Kashima, R.: Cut-free sequent calculi for some tense logics. Stud. Logica. 53(1),
119–135 (1994)
14. Kracht, M.: Power and weakness of the modal display calculus. In: Proof Theory
of Modal Logic (Hamburg, 1993) Applied Logic Series, vol. 2, pp. 93–121. Kluwer
Academic Publishers, Dordrecht (1996)
15. Lemmon, E.J., Scott, D.S.: The ‘Lemmon Notes’: An Introduction to Modal Logic.
Blackwell, Oxford (1977)
16. Mints, G.: Indexed systems of sequents and cut-elimination. J. Philos. Logic 26(6),
671–696 (1997)
17. Negri, S.: Proof analysis in modal logic. J. Philos. Logic 34(5–6), 507–544 (2005)
18. Ramanayake, R.: Inducing syntactic cut-elimination for indexed nested sequents.
In: Proceedings of IJCAR, pp. 416–432 (2016)
19. Restall, G.: Comparing modal sequent systems. http://consequently.org/papers/
comparingmodal.pdf

From Display to Labelled Proofs for Tense Logics
139
20. Restall, G., Poggiolesi, F.: Interpreting and applying proof theory for modal logic.
In: Restall, G., Russell, G. (eds.) New Waves in Philosophical Logic, pp. 39–62
(2012)
21. Vigan`o, L.: Labelled Non-Classical Logics. Kluwer Academic Publishers, Dordrecht
(2000). With a foreword by Dov M. Gabbay
22. Wansing, H.: Displaying Modal Logic. Trends in Logic-Studia Logica Library, vol.
3. Kluwer Academic Publishers, Dordrecht (1998)

Notions of Cauchyness and Metastability
Hannes Diener1(B)
and Robert Lubarsky2
1 University of Canterbury, Christchurch, New Zealand
hannes.diener@canterbury.ac.nz
2 Florida Atlantic University, Boca Raton, FL 33431, USA
Robert.Lubarsky@alum.mit.edu
Abstract. We show that several weakenings of the Cauchy condition are
all equivalent under the assumption of countable choice, and investigate
to what extent choice is necessary. We also show that the syntactically
reminiscent notion of metastability allows similar variations, but is empty
in terms of its constructive content.
Keywords: Cauchy condition · Metastability · Axiom of choice
Constructive analysis
1
Almost Cauchyness
Apart from the last section, we work in Bishop style constructive mathemat-
ics [4]—that is mathematics using intuitionistic instead of classical logic and
some appropriate set-theoretic or type theoretic foundation [1]. Unlike Bishop,
however, we do not freely use the axiom of countable/dependent choice, but
explicitly state every such use.
In [3] a weakened form of the usual Cauchy condition is considered. There
a sequence (xn)n⩾1 in a metric space (X, d) is called almost Cauchy, if for any
strictly increasing f, g : N →N
d(xf(n), xg(n)) →0
as n →∞. (This property will be named C2 below). Unsurprisingly, and as
indicated by its name, every Cauchy sequence is almost Cauchy. In the same
paper mentioned above it is also shown that Ishihara’s principle BD-N suﬃces
to show the converse: that every almost Cauchy sequence is Cauchy. Thus the two
conditions are equivalent not only in classical mathematics (CLASS), but also in
Brouwer’s intuitionism (INT) and Russian recursive mathematics ´a la Markov
(RUSS) as in all these models BD-N holds. In fact, it was only recently that it
has been shown that there are models1 in which this principle fails [7,10]. In this
1 As BISH is not formalised in the same spirit as normal, everyday, mathematics is
formalised, we use the phrase “model of” here somewhat loosely. Of course there are
strict formalisations of BISH and the structures falsifying BD-N are models of such
formalisations.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 140–153, 2018.
https://doi.org/10.1007/978-3-319-72056-2_9

Notions of Cauchyness and Metastability
141
paper we will link the notion of almost Cauchyness to various other weakenings
proposed by Fred Richman and investigate similarities and diﬀerences to the
notion of metastability which was proposed by Terence Tao.
Without further ado we will start the mathematical part of the paper with
the following convention: For two natural numbers n, m the interval [n, m] will
denote all natural numbers between n and m; notice that this notation does not
necessitate n ⩽m.
Proposition 1. Consider the following conditions for a sequence (xn)n⩾1 in
a metric space (X, d), where each condition should be read as prefaced by “for
every ϵ > 0 and for all strictly increasing f, g : N →N there exists N ∈N such
that for all n ⩾N”
C1 d(xn, xg(n)) < ε
C1′ ∀i, j ∈[n, g(n)] : d(xi, xj) < ε
C2 d(xf(n), xg(n)) < ε
C2′ ∀i, j ∈[f(n), g(n)] : d(xi, xj) < ε
C3 d(xg(n), xg(n+1)) < ε
C3′ ∀i, j ∈[g(n), g(n + 1)] : d(xi, xj) < ε
The following implications hold.
C1
C1′
C2
C2′
C3
C3′
Furthermore all conditions are equivalent using countable choice.
Proof. C1 implying C2 is a simple consequence of the triangle inequality—
nevertheless, this small point is of importance in the later discussion. It is
also trivial to see that Ci′ implies Ci for i = 1, 2, 3. With f = id one can
also see that C1 is a special case of C2 and the same holds for C1′ and
C2′. Similarly one can see that C2 implies C3 and C2′ implies C3′. Since
[f(n), g(n)] ⊂[n, max{g(n), f(n)}] for strictly increasing f and g C1′ implies
C2′
To see that C3′ implies C1′ consider the intervals
Gn = [gn(0), gn+2(0)] .
We claim that for every n there is a k such that
[n, g(n)] ⊂Gk .
(1)
To see this let n ∈N be arbitrary. Since g is strictly increasing we can easily
show by induction that gn(0) ⩾n. Therefore there exists k ⩽n such that
gk(0) ⩽n ⩽gk+1(0) .

142
H. Diener and R. Lubarsky
Applying g to the second of these two inequalities we also get g(n) ⩽gk+2(0),
and thus [n, g(n)] ⊂Gk.
Now consider the functions f and h deﬁned by f(n) = g2n(0) and h(n) =
g2n+1(0). By C3′ eventually
∀i, j ∈[f(n), f(n + 1)] : d(xi, xj) < ε
and
∀i, j ∈[h(n), h(n + 1)] : d(xi, xj) < ε .
Since for even n, say n = 2k, we have Gn = [f(k), f(k + 1)] and for odd n, say
n = 2ℓ+ 1 we have that Gn = [h(ℓ), h(ℓ+ 1)], we can conclude that eventually
∀i, j ∈Gn : d(xi, xj) < ε
and thus have shown C1′.
For the rest of the proof we will assume countable choice and prove that
C3 implies C3′, which in turn by transitivity will show that all conditions are
equivalent. To this end let g be an arbitrary increasing function and ε > 0. For
each n choose natural numbers in and jn and a binary ﬂagging sequence λn such
that g(n) ⩽in < jn ⩽g(n + 1) and
λn = 0 =⇒∀i, j ∈[g(n), g(n + 1)] : d(xi, xj) < ε ,
λn = 1 =⇒d(xin, xjn) > ε
2 .
Notice that it might happen that in+1 = jn, but at least always jn < in+2.
Therefore, to get strictly increasing functions, we need to work with two functions
f and g deﬁned by f(2n) = i2n, f(2n+1) = j2n, g(2n) = i2n+1, and g(2n+1) =
j2n+1. By C3 there is N and M such that for all n ⩾N d(xf(n), xf(n+1)) < ε
2
and for all n ⩾M d(xg(n), xg(n+1)) < ε
2. We claim that there cannot be n ⩾
max{N, M} such that λn = 1. For if there were such an even n we would have
the contradiction
ε
2 < d(xin, xjn) = d(xf(n), xf(n+1)) .
We can treat the odd case in a similar fashion, and therefore λn = 0 for all
n ⩾max{N, M}, which is saying that C3′ holds.
We say that a sequence is almost Cauchy if it satisﬁes C2′ (and therefore
any of the above properties).2 Naturally, we are going to consider the following
statement
(aCC) Every almost Cauchy sequence in a metric space is Cauchy.
2 Notice that in [3] “almost Cauchy” is deﬁned as satisfying C2. Since in that work the
authors assume countable choice this is not a conﬂicting deﬁnition. In the absence
of choice it seems, to us, most natural to use the strongest notion.

Notions of Cauchyness and Metastability
143
As mentioned above, it is shown in [3] that BD-N implies that every almost
Cauchy sequence is Cauchy, and therefore
BD-N =⇒aCC .
In the same paper it is also shown that if one drops the triangle inequality
and works with so called semi-metric spaces, then this is in fact an equivalence.
However, the Berger, Bridges, and Palmgren proof crucially needs semi-metric
spaces instead of metric spaces, since in [8] it is shown that the statement that
every almost Cauchy sequence is Cauchy implies BD-N is not provable within
BISH. This is done by giving a topological model T. Notice that T also proves
countable choice, so this result does not change, even if we switch to any of the
other conditions of Proposition 1.
Next we can show that, conveniently, it is enough to consider the monotone,
real case.
Proposition 2. (countable choice) If every decreasing/increasing sequence of
reals that satisﬁes the almost Cauchy condition is Cauchy, then aCC holds.
Proof. Let xn be a sequence satisfying C2′. First note that for every m the
sequence deﬁned by
r(m)
n
=
max
i,j∈[m,m+n]{d(xi, xj)}
is increasing. We want to show that it also satisﬁes the almost Cauchy condition.
To this end let f and g be strictly increasing and ε > 0. We know, by C2′, that
there is N such that for all n ⩾N and i, j ∈[m + f(n), m + g(n)]
d(xi, xj) < ε/2 .
(2)
Now consider k, ℓ∈[f(n), g(n)]. W.l.o.g. ℓ< k. Then
r(m)
k
−r(m)
ℓ
 =
max
i,j∈[m,m+k]{d(xi, xj)} −
max
i,j∈[m,m+ℓ]{d(xi, xj)} .
We will show that this distance is less than ε. First, by the deﬁnition of the
maximum3 we can choose p, q ∈[m, m + k] such that
d(xp, xq) >
max
i,j∈[m,m+k]{d(xi, xj)} −ε/2 .
We may assume that p ⩽q. We have to distinguish three cases depending
whether p and q are both to the left of m + ℓor on both sides or to the right
of it:
3 Notice that in general, even given just two numbers x, y we cannot decide whether
x = max{x, y} or y = max{x, y}, since that would imply the non-constructive lesser
limited principle of omniscience. We can, however, given real numbers x1, . . . , xn
and ε > 0 ﬁnd i such that xi > max{x1, . . . , xn} −ε.

144
H. Diener and R. Lubarsky
– If q ⩽m + ℓ, then
max
i,j∈[m,m+ℓ]{d(xi, xj)} ⩾d(xp, xq)
and therefore
max
i,j∈[m,m+k]{d(xi, xj)} −
max
i,j∈[m,m+ℓ]{d(xi, xj)}
< d(xp, xq) + ε/2 −
max
i,j∈[m,m+ℓ]{d(xi, xj)}
⩽d(xp, xq) + ε/2 −d(xp, xq) < ε
– If p ⩽m + ℓ< q, then
max
i,j∈[m,m+ℓ]{d(xi, xj)} ⩾d(xp, xm+ℓ) .
Furthermore if m + ℓ⩽q, then q ∈[m + ℓ, m + k] ⊂[m + f(n), m + g(n)] and
therefore d(xm+ℓ, xq) < ε/2 by Eq. 2. Together
max
i,j∈[m,m+k]{d(xi, xj)} −
max
i,j∈[m,m+ℓ]{d(xi, xj)}
< d(xp, xq) + ε/2 −
max
i,j∈[m,m+ℓ]{d(xi, xj)}
⩽d(xp, xm+ℓ) + d(xm+ℓ, xq) + ε/2 −
max
i,j∈[m,m+ℓ]{d(xi, xj)}
⩽d(xp, xm+ℓ) + d(xm+ℓ, xq) + ε/2 −d(xp, xm+ℓ)
< ε/2 + ε/2 = ε
– If m + ℓ⩽p, then p, q ∈[m + ℓ, m + k] ⊂[m + f(n), m + g(n)] and therefore
d(xp, xq) < ε/2 by Eq. 2. Thus we have
max
i,j∈[m,m+k]{d(xi, xj)} < d(xp, xq) + ε/2 < ε/2 + ε/2 = ε .
And in particular
max
i,j∈[m,m+k]{d(xi, xj)} −
max
i,j∈[m,m+ℓ]{d(xi, xj)} ⩽
max
i,j∈[m,m+k]{d(xi, xj)} < ε
That is in all cases for n ⩾N and k, ℓ∈[f(n), g(n)]
r(m)
k
−r(m)
ℓ
 < ε ,
which means that the sequence

r(m)
n

n⩾1 satisﬁes the almost Cauchy condition.
Thus, by our assumption, it is Cauchy and converges to a limit, say ym.
Since by deﬁnition r(m)
n+1 ⩾r(m+1)
n
we also have that in the limit ym ⩾ym+1
([4, Proposition 2.3.4.f]), so (ym)m⩾1 is decreasing. We want to show that it also
satisﬁes the almost Cauchy condition C2′. So let f and g be strictly increasing

Notions of Cauchyness and Metastability
145
and ε > 0. Since (r(i)
k )k⩾1 converges to yi for every n we can use countable choice
to ﬁx a function h : N →N such that
∀i ∈[f(n), g(n)] : |yi −r(i)
k | < ε/4
for all k ⩾h(n). Since xn satisﬁes C2′ there exists N such that for all n ⩾N we
have
∀i′, j′ ∈[min{f(n), g(n)}, max{f(n), g(n)} + h(n)] : d(xi′, xj′) < ε/4 .
Then, in particular, for all i, j ∈[f(n), g(n)] we have that

max
ℓ,ℓ′∈[i,i+h(n)] d(xℓ, xℓ′) −
max
p,p′∈[j,j+h(n)] d(xp, xp′)

⩽

max
ℓ,ℓ′∈[i,i+h(n)] d(xℓ, xℓ′)
 +

max
p,p′∈[j,j+h(n)] d(xp, xp′)

⩽ε/4 + ε/4 = ε/2 ,
since
[i, i + h(n)] ⊂[min{f(n), g(n)}, max{f(n), g(n)} + h(n)]
and
[j, j + h(n)] ⊂[min{f(n), g(n)}, max{f(n), g(n)} + h(n)] .
Combining all of this we get that for all n ⩾N and i, j ∈[f(n), g(n)]
|yi −yj| ⩽|yi −r(i)
h(n)| + |yj −r(j)
h(n)| + |r(i)
h(n) −r(j)
h(n)|
⩽ε/4 + ε/4 + ε/2 .
So (ym)m⩾1 is a Cauchy sequence converging to a limit z ⩾0. We want to show
that z = 0. So assume4 z > 0. That means that ym ⩾z > 0 for all m ∈N, since
ym is decreasing. Therefore, using countable choice, we can ﬁx g : N →N such
that
r(m)
g(m) > z/2 .
But if we apply property C2′ of (xn)n⩾1 to f = id, id +g, and ε = z/2 we get
that for i, j ∈[m, m + g(m)]
d(xi, xj)<z/2
eventually, and therefore
r(m)
g(m) =
max
i,j∈[m,m+g(m)] {d(xi, xj)} < z/2
eventually. This is a contradiction and thus z = 0.
So z = 0 and since d(xi, xj) ⩽ym for all i, j ⩾m, we have shown that
(xn)n⩾1 is Cauchy.
4 We remind the reader that even constructively equality is stable.

146
H. Diener and R. Lubarsky
2
Metastability
In a program suggested by Terence Tao [13], it is proposed to recover the “ﬁnite”
(constructive) content of theorems by replacing them with logically (using clas-
sical logic) equivalent ones that can be proven by ﬁnite methods. Since often
there is no way to establish the Cauchy condition it is suggested to be replaced
with the following notion of metastability. A sequence (xn)n⩾1 in a metric space
(X, d) is called metastable iﬀ
∀ϵ > 0, f : ∃m : ∀i, j ∈[m, f(m)] : d(xi, xj) < ε .
Notice that this is almost the same deﬁnition as C1′, and, in fact, one can easily
show that an almost Cauchy sequence is metastable. However—as we will see—
metastability contains almost no constructive content.
As noted in [2] every non-decreasing sequence of reals bounded by B ∈R
is metastable since it is impossible that d(xm, xf(m)) > ε
2 for all 1 ⩽m ⩽2B
ε .
How about the converse: is every non-decreasing metastable sequence bounded?
There is no hope in ﬁnding a constructive proof since we will see that it is
equivalent to the non-constructive limited principle of omniscience
(LPO) For every binary sequence (an)n⩾1 we can decide whether
∀n ∈N : an = 0 ∨∃n ∈N : an = 1.
Under the assumption of countable choice LPO is equivalent to deciding for all
real numbers whether x < 0∨x = 0∨0 < x. Countable choice is needed to given
a real number x construct a sequence of rationals converging to x. LPO is also
equivalent to even stronger statements:
Proposition 3. (countable choice) LPO is equivalent to either of the following
1. The Bolzano Weierstraß theorem: every sequence of reals in [0, 1] has a con-
vergent subsequence.
2. For every binary sequence (an)n⩾1
∃N : ∀n ⩾N : an = 0 ∨∃kn ∈NN : akn = 1.
Proof. The equivalence of LPO with the Bolzano Weierstraß theorem can be
found in [11].
2 obviously implies LPO. Conversely we can show 2 by applying LPO count-
ably many times: using LPO (and unique choice) construct a binary sequence
bn such that
bk = 0 =⇒∃n ⩾k : an = 1
bk = 1 =⇒∀n ⩾k : an = 0
Now, using LPO again, either ∃N : bN = 1 or ∀k : bk = 0. In the ﬁrst case
∀n ⩾N : an = 0. In the second case we can use unique choice5 to ﬁnd kn ∈NN
such that ∀n ∈N : akn = 1.
5 To use unique choice we need to always pick the smallest kn+1 > kn such that
akn+1 = 1.

Notions of Cauchyness and Metastability
147
Proposition 4. (countable choice)
LPO is equivalent to the statement that
every metastable, non-decreasing sequence of rationals is bounded.
Proof. Assume (xn)n⩾1 is non-decreasing and metastable. For every k we can
ﬁx, using LPO countably many times, a binary sequence (λ(k))n⩾1 such that
λ(k)
n
= 0 =⇒xn ⩽k
λ(k)
n
= 1 =⇒xn > k .
Then for every k, using LPO on (λ(k)
n )n⩾1, we can decide whether k is an upper
bound of (xn)n⩾1 or not. So we can ﬁx another binary sequence ηk such that
ηk = 1 =⇒k is an upper bound
ηk = 0 =⇒∃ℓ: xℓ> k .
Using LPO yet again, we can thus either ﬁnd an upper bound or, using dependent
choice, we can ﬁx a function f : N →N such that xf(n+1) > xf(n) + 1 for all
n ∈N. Since xn is non-decreasing f is increasing. Furthermore
d(xf(n+1), xf(n)) > 1 ;
a contradiction to the metastability. Hence (xn)n⩾1 is bounded.
Conversely, let (an)n⩾1 be a binary sequence that has, w.l.o.g., at most one
1. Now consider
xn =
n

i=1
iai .
(3)
It is easy to see that xn is metastable: if f : N →N is increasing, then either
ai = 0 for all i ∈[1, f(1)] or ai = 0 for all i ∈[f(2), f(f(2))]. In both cases xi is
constant on an interval of the form [m, f(m)].
Now if xn is bounded, there is N ∈N with xn < N. If there was i > N with
ai = 1, then xi = i > N which is a contradiction. Hence ai = 0 for all i > N,
that is we only need to check ﬁnitely many entries to see if (an)n⩾1 consists of
0s or whether there is a term equalling 1.
Since the construction of the sequence in the proof above (see Eq. 3) relies on
the terms being potentially very large one might still hope that there is maybe
a chance that every bounded, metastable sequence converges. However, also this
statement is equivalent to LPO.
Proposition 5. (countable choice) LPO is equivalent to the statement that
every bounded, metastable sequence of rationals converges.
Proof. Assume that LPO holds and that (xn)n⩾1 is a bounded and metastable
sequence of rationals. Since LPO implies the Bolzano Weierstraß theorem (see
Proposition 4) there exists x ∈R and kn ∈NN such that xkn converges to x.
Now let ε > 0 be arbitrary. For every n ∈N we can use LPO to decide whether
|x −xn| < ε ∨|x −xn| ⩾ε .

148
H. Diener and R. Lubarsky
So, using (unique) countable choice we can ﬁx a binary sequence (λn)n⩾1 such
that
λn = 0 =⇒|x −xn| < ε
λn = 1 =⇒|x −xn| ⩾ε .
By Proposition 4 either there exists N such that λn = 0 for all n ⩾N or there
exists a strictly increasing ℓn ∈NN such that λℓn = 1 for all n ∈N. We will
show that the second alternative is ruled out by the metastability: ﬁx M such
that |xkn −x| < ε
2 for n ⩾M and hence
|xkn −xℓn| ⩾ε
2 for n ⩾M .
(4)
Now deﬁne f : N →N by f(n) = max{kn+M, ℓn+M}. Then f is increasing.
Since (xn)n⩾1 is metastable there exists m such that for all i, j ∈[m, f(m)] we
have |xi −xj| <
ε
2. Since km+M, ℓm+M ∈[m + M, f(m)] we get the desired
contradiction to 4.
Conversely let (an)n⩾1 be a binary sequence with at most one term equalling
1. We will show that (an)n⩾1 is metastable. So let f : N →N an increasing
function. Now either there exists i ∈[1, f(1)] such that ai = 1 or for all i ∈
[1, f(1)] we have ai = 0. In the ﬁrst case, since (an)n⩾1 has at most one 1, for
all i ∈[f(1) + 1, f(f(1) + 1)] we have ai = 0. In both cases there exists m such
that, regardless of ε > 0, we have
∀i, j ∈[m, f(m)] : |ai −aj| = 0 < ε ;
that is (an)n⩾1 is metastable. Now if this sequence converges it must converge
to 0. So there exists N ∈N such that for all n ⩾N we have aN = 0. So we only
need to check ﬁnitely many indices n ∈N for an = 1, and hence LPO holds.
It is only natural to ask how variants of metastability along the lines con-
sidered in the ﬁrst section interact. To this end let us consider the properties
MS(′)1 −3 of a sequence, which are the same as C(′)1 −3 in Proposition 1,
only that they are read as being prefaced by “for every ϵ > 0 and for all strictly
increasing f, g : N →N there exists n ∈N.” With this notation metastability, as
deﬁned above, is MS1′. Not surprisingly we can reuse large parts of the proof
of Proposition 1 in the next one.
Proposition 6. The following implications hold among conditions MS(′)1 −3
for a sequence in a metric space.
MS1
MS1′
MS2
MS2′
MS3
MS3′
The proof is identical to the one of Proposition 1, apart from the proof that
MS1 implies MS2 which does not translate and which leaves us therefore with
fewer implications.

Notions of Cauchyness and Metastability
149
3
Choice Is Necessary
In recent years, there has been an increasing sensitivity to the use of countable
choice in constructive mathematics. In Bishop’s words, “meaningful distinctions
deserve to be preserved” and some researchers have argued [12] that the distinc-
tions which are removed by the use of countable choice are, indeed, meaningful.
So the elephant-in-the-room question raised by Sect. 1 is, whether the use of
countable choice in Proposition 1 was really necessary. We will show in the next
proposition that this is the case—at least to prove the equivalence between the
weakest (C3) and the strongest (C3′) notion. This means that in the absence
of choice the middle (C1) must be inequivalent to at least one of the other two
levels, but it is not clear to which, and whether it is to both of them.
Theorem 1. C3 does not imply C3′.
Proof. We will ﬁrst sketch the basic idea. The counter-example will involve a
sequence xn of reals. We will also make use of particular natural numbers a < b,
with several counter-examples i, j coming from the interval [a, b]. These a and
b will be non-standard, and also a non-standard distance apart. The sequence
xn will be 0 outside the interval [a, b]; within that interval, the sequence will
increase by 2/(b −a) each step for the ﬁrst half of that interval, up to a value
of 1, and then decrease that same amount for each step in the second half, back
down to 0. How does this help satisfy C3? For g’s which take on no values in
[a, b], there is nothing to do, as then d(xg(n), xg(n+1)) is always 0. For other g’s,
in the end we will see that we need concern ourselves only with standard ϵ. For
values within [a, b], whenever g(n + 1) −g(n) is standard, d(xg(n), xg(n+1)) is
inﬁnitesimal and hence less than ϵ. Of course, from xn one can easily deﬁne a
and b, and so their midpoint (a + b)/2, which would ruin C3. To avoid this, we
will need to fuzz xn up, so that the earlier cases mentioned are the only ones
that happen.
In order to accomplish all of this we will need to exercise some care in the
choice not only of a and b but also in the model in which they are embedded. It
is easiest to work with an ultrapower of the universe V . (For the model theory
about to be used, see standard references, such as [5, Sect. 4.3].) Where c is
(the size of) the continuum, take an ultrapower M using a c-regular ultraﬁlter.
Then M is c+ saturated over V ([5, Cororllary 4.3.14]). In the following, we will
identify a set in V with its image in M. In particular, g refers both to a function
(from N to N) in V and to its image in M.
The point of the saturation is that the model realizes any type of size c. The
type of interest to us is in a triple a, b, and k of (symbols standing for) natural
numbers. Start by including the formulas b > a, b−a > 0, b−a > 1, . . ., as well as
2k ≤a and b ≤2k+1. This much is easily seen to be consistent, by compactness.
Toward realizing the ﬁrst option listed above, consider an axiom which says
“g takes on no values in (a, b)”; more formally,
φg = ∃n : g(n) ≤a ∧b ≤g(n + 1) ,
for some g : N →N in V .

150
H. Diener and R. Lubarsky
Of course, φg might not be consistent (with the rest of the type); consider for
example the identity function. For those g’s, we will go toward the second option
from above. For any g ∈V , and standard natural number β (for “bound”), let
ψg,β be
∀k : (if g(k) or g(k + 1) is in the interval (a, b), then g(k + 1) −g(k) < β) .
Notice that there are only c-many formulas of the form φg and ψg,β. Let the
type Ty be a maximal consistent extension of the starting formulas by φg’s and
ψg,β’s. By the c+-saturation of M, Ty is realized in M. We would like to show
that, for all increasing h ∈V , either φh ∈Ty or, for some β, ψh,β ∈Ty.
If h takes on no values in (a, b), then φh is true, and hence consistent with
Ty, and so by maximality is in Ty. Else consider the non-empty set
Ih = {h(k + 1) −h(k) | h(k) or h(k + 1) is in (a, b)} .
If every member of Ih were standard, then, since Ih is deﬁnable in M, it has a
standard bound, say β. Immediately, ψh,β is true, and so is consistent with Ty,
and therefore is in Ty. The other possibility is that Ih contains a non-standard
element. There are several cases here.
The simplest case is that, for some k with h(k + 1) −h(k) non-standard,
a ≤h(k) and h(k + 1) ≤b. In that case, a and b could be re-interpreted to be
h(k) and h(k+1) respectively. That would still satisfy Ty, and make φh true, and
again we would be done by maximality. If that does not happen, then, whenever
k generates a non-standard element of Ih, either h(k) < a or h(k + 1) > b (so
Ih contains at most 2 non-standard elements). We will show what to do when
both of those possibilities occur (for diﬀerent k’s, of course). This will call for
a two-step procedure. If only one of those possibilities occurs, then only one of
those steps need be done.
Toward this end, we have h(k) < a, and also a < h(k + 1) < b, else Ih would
be empty. The ﬁrst sub-case is that h(k +1)−a is non-standard. Then, similarly
to the above, we could re-interpret b as h(k + 1) (and leave a ﬁxed), and get φh
consistent with Ty. The other sub-case is that h(k +1)−a is standard. Then we
could interpret a as h(k + 1) (and leave b ﬁxed). Re-interpreting Ty with this
new choice of a, the new Ih has size 1. Now one considers the other choice of k,
with h(k) < b < h(k + 1), and argues similarly.
So we conclude that Ty is complete in this sense. Returning to the model
construction, we are going to work over a two-node Kripke model. To the bottom
node associate V , and the top M. Take the full model F over that structure.
(For the deﬁnition of a full model, see [6].) Consider the sequence xn described
at the beginning of this work: xn is 0 outside of [a, b], increases starting at a by
2/(b −a) at each step up to a value of 1 at the midpoint, then decreases by the
same amount back to 0 at b. It would be no trouble to show C3 for this sequence
for g ∈V . The problem is, the full model contains a lot more functions g than
just those from V . In particular, from xn, a and b are easily deﬁnable, which
would kill C3 holding. So we need to hide things better. This can be done by

Notions of Cauchyness and Metastability
151
working within a topological model (built over the full model), and then taking
a sub-model of it.
Working in F, let the space T consist of all sequences yn such that |xn−yn| <
1/n (starting the indexing from 1, obviously), except for n in the interval [a, b],
in which |xn −yn| < 2/(b −a). A basic open set is given by restricting each
component yn to an open interval. Let Gn be the generic. In passing, we mention
that, by standard arguments, any g : N →N in the topological model is in its
ground model, which in this case is the full model F. We need more than that:
we need a model in which any such g, at least at ⊥, is in V .
To this end, we build essentially L[G]. At ⊤, this would be unambiguous.
That is, at ⊤we have a topological model over M, which models IZFRef, the
version with Reﬂection. It was shown in [9] that such a theory can deﬁne its
version of L and show it to be a model of IZFRef. It is not immediately clear,
though, that this construction is consistent with what we need to do at ⊥. So
we describe the situation at ⊥, and bring ⊤along for the ride, and show what
we need to for both.
The deﬁnition of Lα[G], inductively on α an ordinal of M, is straightforward,
and is the same as in classical set theory. For α ∈V an ordinal, its image in the
full model, for which we temporarily use the notation αf (f for “full”), works as
follows: ⊥⊩“x ∈αf” iﬀfor some β < α, ⊥⊩“x = βf”; and ⊤⊩“x ∈αf” iﬀ,
in M, identifying α with its image under the elementary embedding into M, for
some β < α, ⊥⊩“x = βf”. Since αf is in the full model, which is the ground
model for the topological model, it is also in the topological model. So within
the topological model, the set Lαf [G] can be deﬁned by induction. We do not
know whether the topological model can separate ordinals of the form αf from
any others, or even whether the full model can do so, so the ﬁnal step is done in
V resp. M: at bottom, L[G] is deﬁned in V to be the union over the ordinals α
of Lαf [G], whereas at ⊤that union is taken in M.
What remains to be shown? For one, IZF, which we postpone to the end. By
the presence of G, it should be clear that C3′ fails, for g(n) = 2n: even if the
generic diﬀers from xn, it is only by an inﬁnitesimal amount at each component.
All that remains is that C3 holds for G. At ⊤, G is a Cauchy sequence, so that
is taken care of. We need check C3 for G only at ⊥.
At ⊥, we need concern ourselves with only standard ϵ. For any such ϵ > 1/n,
n standard, let N be n. For g ∈V , the whole set-up all along the way is to
make C3 true for that g. So we will be done if we can show that any h is in V :
if ⊥⊩h : N →N then, for some g ∈V , ⊥⊩h = g.
By hypothesis, ⊥forces a standard value for h on each standard input. So
that is the obvious choice for g: let g be such that g(n) is the value forced by
⊥for h(n). In our model, let X be {n | h(n) ̸= g(n)}. This could have only non-
standard elements. We will show that it is decidable: for any n, either T |= n ∈X
or T |= n /∈X. Then we will show that any decidable set is either empty or has
a standard member. That then suﬃces.
For decidability: any value for h(n) has to be forced by T, by standard
arguments, as follows. If not, let O be a maximal open set forcing a value for

152
H. Diener and R. Lubarsky
h(n). Pick a point on the boundary of O. What value could a neighborhood of
it force? If there is no such neighborhood, then h is not total, so need not be
considered. If it forces a diﬀerent value than O does, then, by connectedness,
consider the overlap: h(n) is then no longer single-valued. So whatever value
h(n) has is forced by T. Now compare that to g(n).
As for a non-empty decidable set X having standard members: If it has a
member at all, consider the deﬁnition φ of X over Lα[G]. With regard to the
parameters in φ, one can unpack them by their deﬁnitions, ultimately reducing
the parameters used to ﬁnitely many standard ordinals and G. We will in the
course of this argument consider alternate interpretations of a and b. Of course,
when doing so, there is no longer any reason to believe that C3 still holds, or that
C3′ does not. This is of no matter for showing our current goal. The construction
of T, and of L[G], still makes sense, for any choice of a < b. Now consider the
space T1 based on the pair a −1, b −1. Notice that T ∩T1 is a non-empty open
subset of both T and T1. So it forces the same facts about X that T does, and
that T1 does. So the interpretation of X stays the same when we shift a and
b down by 1. Iterate this procedure until the lower number is some standard
value, say a, larger than all of the natural number parameters used in φ. Then
hold a ﬁxed, and reduce the upper number by one. By similar arguments, again
X remains unchanged. Iterate until this upper number is standard, say b. Call
the space based on a and b U. In M, X is still interpreted the same way, so, in
M, U |= “X has a member.” By elementarity, the same holds in V . Any such
member there has to be standard: V |= k ∈X. So X has a standard member.
Finally, we sketch brieﬂy why IZF holds. For the axioms of Empty Set and
Inﬁnity, ∅is deﬁnable over L0[G], and ω over Lω[G]. Pair and Union hold easily.
Extensionality is valid because that is how equality is deﬁned. ∈-Induction holds,
even though M is ill-founded, because ∈-Induction holds in M. Reﬂection holds
because it holds in V : If Vα is a Σn-elementary substructure of V , then the
initial segment of L[G] up to α is itself a Σn-elementary substructure of the
whole thing. From this, Separation follows easily. For Power Set, given x ∈L[G],
since the whole construction took place in V , the ordinals at which new subsets
of x appear are bounded, and at the next level they can all be collected into one
set.
References
1. Aczel, P., Rathjen, M.: Notes on constructive set theory. Technical report 40, Insti-
tut Mittag-Leﬄer. The Royal Swedish Academy of Sciences (2001)
2. Avigad, J., Dean, E.T., Rute, J.: A metastable dominated convergence theorem.
J. Logic Anal. 4(3), 1–19 (2012)
3. Berger, J., Bridges, D., Palmgren, E.: Double sequences, almost cauchyness and
BD-N. Logic J. IGPL 20(1), 349–354 (2012)
4. Bishop, E., Bridges, D.: Constructive Analysis. Springer, Heidelberg. https://doi.
org/10.1007/978-3-642-61667-9 (1985)
5. Chang, C.C., Keisler, H.J.: Model Theory. Dover Books on Mathematics, 3rd edn.
Dover Publications, New York (2013)

Notions of Cauchyness and Metastability
153
6. Hendtlass, M., Lubarsky, R.: Separating fragments of WLEM, LPO, and MP. J.
Symbol. Logic 81(4), 1315–1343 (2016)
7. Lietz, P.: From Constructive Mathematics to Computable Analysis via the Real-
izability Interpretation. PhD thesis, TU Darmstadt (2004)
8. Lubarsky, R.S., Diener, H.: Principles weaker than BD-N. J. Symbol. Logic 78(3),
873–885 (2014)
9. Lubarsky, R.S.: Intuitionistic L. In: Crossley et al. (ed.) Logical Methods. In Honor
of Anil Nerode’s Sixtieth Birthday of Progress in Computer Science and Applied
Logic, vol. 12, pp. 555–571. Birkh¨auser Boston, Boston (1993)
10. Lubarsky, R.S.: On the failure of BD-N and BD, and an application to the anti-
Specker property. J. Symbol. Logic 78(1), 39–56 (2013)
11. Mandelkern, M.: Limited omniscience and the Bolzano-Weierstrass principle. Bull.
London Math. Soc. 20, 319–320 (1988)
12. Richman, F.: Constructive mathematics without choice. In: Schuster, P., Berger,
U., Osswald, H. (eds.) Reuniting the Antipodes: Constructive and Nonstandard
Views of the Continuum. Synthese Library. Kluwer Academic Publishers, Dor-
drecht (2001)
13. Tao, T.: Soft analysis, hard analysis, and the ﬁnite convergence principle, May 2007.
http://terrytao.wordpress.com/2007/05/23/soft-analysis-hard-analysis-and-the-
ﬁnite-convergence-principle/

A G¨odel-Artemov-Style Analysis
of Constructible Falsity
Thomas Macaulay Ferguson1,2(B)
1 Cycorp, Austin, TX, USA
tferguson@gradcenter.cuny.edu
2 Saul Kripke Center, CUNY Graduate Center, New York, NY, USA
Abstract. David Nelson’s logic of constructible falsity N is a well-known
conservative extension to intuitionistic logic Int. Heinrich Wansing has
suggested that extending the provability interpretation of Int to such
extensions requires that one enriches the single category of formal proofs
assumed intuitionistically with further categories representing formal
refutations. This paper adapts the framework of Sergei Artemov’s justi-
ﬁcation logic—which has provided incredible insight into Int—to capture
a proof/refutation interpretation of N. To represent distinct types of jus-
tiﬁcation, we identify the distinct agents of Tatiana Yavorskaya-Sidon’s
two-agent logic of proofs LP2
↑↑with categories of proof and refutation,
permitting an embedding of N into LP2
↑↑. In conclusion, we describe how a
G¨odel-Artemov-style analysis can be given for Cecylia Rauszer’s Heyting-
Brouwer logic and show that Melvin Fitting’s semantic realization proof
can be extended to normal multimodal logics in general.
Keywords: Justiﬁcation logic · Constructible falsity · Refutation
Intuitionistic logic · Logic of proofs
1
Introduction
From formal, philosophical, and practical perspectives, intuitionistic logic (Int)
has proven to be an extraordinarily natural and fruitful framework. Since its
development, a number of systems related to intuitionistic logic have appeared,
such as David Nelson’s logics of constructible falsity of [14,16] and Cecylia
Rauszer’s Heyting-Brouwer logic HB of [19,20]. Each of these systems enrich
the language of Int with novel connectives. The success of intuitionistic logic
has often led to an expectation that intuitionistic interpretations will naturally
extend to these conservative systems. In [25], Heinrich Wansing has suggested
that many of these systems are best interpreted as logics in which both proof
and refutation receive equal treatment.
In this paper, we lay the groundwork for an investigation into the interpreta-
tion of constructible falsity and Heyting-Brouwer logic (and their compatriots)
by adapting the framework of Sergei Artemov’s logic of proofs to Nelson’s sys-
tem. It is hoped that the naturalness of the present G¨odel-Artemov-style inter-
pretation of constructible falsity will serve as a platform from which to launch
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 154–169, 2018.
https://doi.org/10.1007/978-3-319-72056-2_10

A G¨odel-Artemov-Style Analysis of Constructible Falsity
155
a deeper investigation into Heyting-Brouwer logic and other systems that com-
plement intuitionistic notions of provability with refutation.
1.1
The Logic of Constructible Falsity
The primary target for the present analysis is Nelson’s logic of constructible fal-
sity N (frequently encountered as “N3” or “CF”). N, introduced in [14], was moti-
vated by Nelson’s diagnosis of deﬁciencies in intuitionistic disproof. N enriches
the familiar language of intuitionistic logic by adding to the intuitionistic nega-
tion an additional strong negation connective representing a constructible fal-
sity. In [14], Nelson argues that the intuitionistic framework implicitly imposes
asymmetries to the notions of truth and falsity that reveal that disproof in Int
is non-constructive. For example, while a proof of a disjunction ϕ ∨ψ requires
either an explicit proof of ϕ or an explicit proof of ψ, a disproof of a conjunction
ϕ′ ∧ψ′ does not require an explicit disproof of one of the conjuncts. Intuitionis-
tically, the judgment that a simple contradiction ϕ ∧⌢ϕ is false (where ⌢repre-
sents intuitionistic negation)1 requires no judgment concerning which conjunct
in particular contributes to the contradiction’s falsehood.
The aim of the present paper is to contribute to the understanding of N and,
ultimately, related systems by shining a light on some of its subtle and implicit
machinery. The route through which this contribution will be made is an exten-
sion of Sergei Artemov’s program of justiﬁcation logic, in which the techniques
and operations of traditional modal logic are made explicit by introducing terms
corresponding to an ontology of idealized justiﬁcations (cf. [4]).
One of the most notable successes of Artemov’s program is its illumination
of the inner machinery of intuitionistic logic, provided by recasting the familiar
G¨odel-McKinsey-Tarski translation of intuitionistic logic as an embedding of Int
into Artemov’s logic of proofs LP—the explicit counterpart to S4. The close
relationship between intuitionistic logic and its conservative extensions suggests
that exegetical work on Int may lead to a similar clariﬁcation of interpretive
matters in N.
The type of constructivity implicit in N requires that one must countenance
not merely a category of proofs but must also embrace a distinct category of
disproofs. This suggests that to recapture Artemov’s success in the context of
the system N requires an adaptation of justiﬁcation logic that is versatile enough
to distinguish proof from refutation. For example, successfully applying this
framework would permit us to formally represent distinct and independent theses
representing various ways in which proofs and refutations might be thought to
interact with one another.2
1 This paper follows the notational convention for negations of [24], in which four
types of negation connective are studied. The notation for intuitionistic negation ⌢
reﬂects its duality with the conegation ⌣of Heyting-Brouwer logic.
2 Both Nelson’s realizability semantics of [14] and Lopez-Escobar’s BHK-style inter-
pretation of [10] permit that a veriﬁer of one formula may act as a falsiﬁer of another
formula. It is not necessary that the categories distinguish proofs and refutations
ontologically so much as that they track the diﬀerence between the purpose or sense
in which a justiﬁcation is presented.

156
T. M. Ferguson
1.2
Artemov’s Program of Justiﬁcation Logic
Kurt G¨odel took the ﬁrst steps towards making the engine driving intuitionistic
operations explicit in the abstract [9], in which it is observed that the theorems
of intuitionistic propositional logic can be embedded into the modal logic S4.
Under G¨odel’s interpretation of the S4 modality, “ϕ” is read as “ϕ is provable.”
Alternative—and arguably more natural—versions of G¨odel’s 1933 translation
are frequently adopted, as found in, e.g., in [12], including the translation favored
by Artemov himself.
With the introduction of Artemov’s logic of proofs LP in [2], the logic of proofs
and intuitionistic logic are succinctly represented in the following “foundational
picture” drawn from [3], which acts as a portrait of what was revealed by the
G¨odel-McKinsey-Tarski-style translations found in [9,12]:
Int →S4 →LP →Classical Proofs
Nelson’s suggestion that N should admit provability-style interpretations anal-
ogous to G¨odel’s interpretation increases the plausibility of the merits of an
analogous “foundational picture” for constructible falsity. This plausibility is
reinforced by the fact that N can be faithfully embedded into modal logics that
are very similar to S4, a fact studied in detail in [17].
On its face, the philosophical discussions of constructible falsity in [14,15] are
formulated in terms that allow us to readily export the fundamental concepts
of intuitionistic logic and apply them to N. Nelson emphatically endorses the
intuitionistic understanding of proof but insists that intuitionistic conceptions
of proof must be supplemented by a constructive notion of falsity. The task
of articulating a fundamental picture of N, then, might be best considered as
ﬁnding a natural way of extending the corresponding picture for Int. By Rich-
mond Thomason’s result in [23], there exists a translation from N to the modal
logic S4 that successfully translates N within the S4 consequence relation. In
many ways, Thomason’s translation is a salient and faithful representation of
Nelson’s position on constructible falsity. The translation, for example, captures
Nelson’s notions of proof and disproof by the distinct S4 modalities of  and ¬,
respectively, and provides a framework that is more expressive than the standard
G¨odel-McKinsey-Tarski translations. Seeking to reconcile Nelson’s intuitions and
Thomason’s translation of N suggests the following foundational picture:
N →S4 →? →Classical Proofs and Disproofs
Despite the apparent acceptability of the above picture, Thomason’s translation
faces some limitations. By Thomason’s result, N can be mapped into Artemov’s
LP as well, which at ﬁrst blush suggests that LP itself might ﬁll in the lacuna.
However, Nelson’s work presupposes a non-trivial distinction between the cate-
gories of proof and refutation. Contrary to the spirit of Nelson’s investigations,
the formalism of LP proper requires a collapse of the categories of proof and
disproof.
In light of this, in the following sections, I suggest that this distinction is
respected by the additional expressivity of the bimodal logic S42
Triv—a bimodal

A G¨odel-Artemov-Style Analysis of Constructible Falsity
157
logic with two interchangeable S4 modalities 0 and 1. Furthermore, I will sug-
gest that Tatiana Yavorskaya-Sidon’s two-agent logic of proofs LP2
↑↑—introduced
in [29]—provides a more satisfactory analysis of N. This leads to the following
foundational picture of Nelson’s logic of constructible falsity:
N →S42 →LP2
↑↑→Classical Proofs and Disproofs
Now, we will begin to outline the formalisms required to provide the foundational
picture of N.
2
Constructible Falsity and Two Modal Companions
Now, we introduce Nelson’s logic in conjunction with two modal logics to which
it may be faithfully translated. As N expands the language of intuitionistic logic,
we will ﬁrst discuss a number of formal languages.
2.1
The Basic System of Constructible Falsity N
We begin to deﬁne the richer languages by deﬁning a set of atomic formulae:
Deﬁnition 1. At is a denumerable set of atomic formulae {p0, p1, ..., q0, ...}.
From At, we construct the languages of classical logic (CL) and N.
Note that each of these systems includes a distinct, characteristic negation
(or negation-like) operator. To prevent ambiguity, we will employ the notational
convention for negations of [24]. That is, we employ “¬” to denote classical
negation while Nelson’s strong negation will be denoted by “∼.” In the case of
other connectives—disjunction, conjunction, implication, etc.—we allow context
to determine which reading is appropriate. We then deﬁne the following formal
languages:
LCL: ϕ ::= p|¬ϕ|ϕ ∧ϕ|ϕ ∨ϕ|ϕ →ϕ
LN: ϕ ::= p|∼ϕ|ϕ ∧ϕ|ϕ ∨ϕ|ϕ →ϕ
It is worth mentioning that intuitionistic negation is deﬁnable in N, as any contra-
diction ϕ∧∼ϕ can serve as a deﬁnable falsum constant from which intuitionistic
negation may be deﬁned so that ⌢ϕ =df ϕ →(ϕ ∧∼ϕ).
We stick to Kripke semantics for the systems that follow.
Deﬁnition 2. An n-ary Kripke frame is an n + 1-tuple ⟨W, ≤0, ..., ≤n−1⟩where
each ≤i is a binary relation on the nonempty set W.
In the sequel, we will sometimes use “≥” to indicate the inverse of an accessibility
relation ≤.
Deﬁnition 3. An N-model M is a 3-tuple ⟨W, ≤, v+, v−⟩where ⟨W, ≤⟩is a
reﬂexive and transitive Kripke frame and v+ and v−are maps from At to ℘(W)
such that for all p ∈At:

158
T. M. Ferguson
– if w ∈v+(p) and w ≤w′, then w′ ∈v+(p)
– if w ∈v−(p) and w ≤w′, then w′ ∈v−(p)
– v+(p) ∩v−(p) = ∅
Nelson’s demand for independent notions of constructible truth and falsity leads
to the formulation of two forcing relations in tandem:
– M, w ⊩+ p iﬀw ∈v+(p) for p ∈At
– M, w ⊩+ ∼ϕ iﬀM, w ⊩−ϕ
– M, w ⊩+ ϕ ∧ψ iﬀM, w ⊩+ ϕ and M, w ⊩+ ψ
– M, w ⊩+ ϕ ∨ψ iﬀM, w ⊩+ ϕ or M, w ⊩+ ψ
– M, w ⊩+ ϕ →ψ iﬀfor all w′ s.t. w ≤w′, if M, w′ ⊩+ ϕ then M, w′ ⊩+ ψ
– M, w ⊩−p iﬀw ∈v−(p) for p ∈At
– M, w ⊩−∼ϕ iﬀM, w ⊩+ ϕ
– M, w ⊩−ϕ ∧ψ iﬀM, w ⊩−ϕ or M, w ⊩−ψ
– M, w ⊩−ϕ ∨ψ iﬀM, w ⊩−ϕ and M, w ⊩−ψ
– M, w ⊩−ϕ →ψ iﬀM, w ⊩+ ϕ and M, w ⊩−ψ
Validity of an inference Γ ⊨N ϕ is deﬁned as the preservation of truth at each
point in each model.3
Deﬁnition 4. Γ ⊨N ϕ holds if for every point w in every N-model M, whenever
M, w ⊩+ ψ for every ψ ∈Γ, also M, w ⊩+ ϕ.
As a Hilbert-style calculus, N may be considered as an axiomatic extension of
positive intuitionistic propositional logic by adding the following schemes gov-
erning strong negation, where “↔” is deﬁned in the standard fashion:
N1
∼(ϕ ∧ψ) ↔(∼ϕ ∨∼ψ)
N2
∼(ϕ ∨ψ) ↔(∼ϕ ∧∼ψ)
N3
∼(ϕ →ψ) ↔(ϕ ∧∼ψ)
N4
∼∼ϕ ↔ϕ
N5
∼ϕ →(ϕ →ψ)
This gives us the following deﬁnition of provability in N:
Deﬁnition 5. Γ ⊢N ϕ if there is a proof of ϕ from hypotheses Γ through
the rules and axioms of positive intuitionistic logic supplemented by the axiom
schema N1–N5.
3 As a referee has pointed out, Nelson’s N is on its face very similar to classical logic
and might be expected to be complete with respect to Boolean algebras. That this is
not the case can be seen by observing that N is not closed under uniform substitution;
while ∼(ϕ →ψ) is logically equivalent to ϕ∧∼ψ, it is not the case that ∼∼(ϕ →ψ)
(i.e., ϕ →ψ) is equivalent to ∼(ϕ ∧∼ψ) (i.e., ∼ϕ ∨ψ).

A G¨odel-Artemov-Style Analysis of Constructible Falsity
159
N, like Int, is constructive in the sense that it enjoys the disjunction property
according to which if a formula ϕ ∨ψ is a theorem, then either ϕ or ψ is a
theorem as well. N enhances the constructivity of Int by adding to this the
constructible falsity property by which if ∼(ϕ ∧ψ) is a theorem, either ∼ϕ or
∼ψ is a theorem, that is, if a conjunction is false then one can pinpoint which
conjunct fails.4
2.2
Bi-modal Logics S42 and S42
Triv
An interest in considering multi-modal systems in the interpretation of N has
been acknowledged. Hence, we will at this point consider bimodal logics, that is,
expansions of classical logic CL that include two independent modal operators 0
and 1. For purposes that will become clear, we employ without loss of generality
notational variants of the following systems by using a modal operator 1 as a
shorthand for 1¬. From these operators, we describe the language L 2
:
Deﬁnition 6. The language L 2
 is deﬁned with p ∈At as follows:
ϕ ::= p|¬ϕ|ϕ ∧ϕ|ϕ ∨ϕ|ϕ →ϕ|0ϕ|1ϕ
The basic bimodal system for which all modal logics considered herein will be
based is K2, the bimodal logic for which the two modalities each behave as in
the monomodal logic K:
K0
0(ϕ →ψ) →(0ϕ →0ψ)
K1
1(ϕ ∧¬ψ) →(1¬ϕ →1¬ψ)
And rule of inference:
Necessitation
From theoremhood of ϕ, infer 0ϕ and 1¬ϕ
In order to succinctly deﬁne extensions of K2, we consider the following opera-
tion:
Deﬁnition 7. Let L be an axiomatic system and let A be an axiom scheme or
rule of inference. Then L ⊕A is the axiomatic system determined by adding A
to the axiom schemes of L and closing the union under the rules of L.
Deﬁnition 8. A K2-model M is a 4-tuple ⟨W, ≤0, ≤1, v⟩such that ⟨W, ≤0, ≤1⟩
is a binary Kripke frame and v : At →℘(W).
On each model M, a forcing relation is extended recursively as follows:
Deﬁnition 9. The forcing relation is deﬁned so that:
– M, w ⊩p if w ∈v(p) for p ∈At
– M, w ⊩¬ϕ if M, w ⊮ϕ
4 In the quantiﬁed case, the intuitionistic existence property is dualized by a property
in N so that when a negated universal formula ∼∀xϕ(x) is a theorem, there is a term
t that witnesses this fact, i.e., for which ∼ϕ(t) is a theorem.

160
T. M. Ferguson
– M, w ⊩ϕ ∧ψ if M, w ⊩ϕ and M, w ⊩ψ
– M, w ⊩ϕ ∨ψ if M, w ⊩ϕ or M, w ⊩ψ
– M, w ⊩ϕ →ψ if M, w ⊮ϕ or M, w ⊩ψ
– M, w ⊩0ϕ if for all w′ such that w ≤0 w′, M, w′ ⊩ϕ
– M, w ⊩1ϕ if for all w′ such that w ≤1 w′, M, w′ ⊮ϕ
Validity is deﬁned as usual, that is, in a similar fashion to that of validity in N.
Just as the axiom scheme K has an instance for each modality, the axiom
schemes T and 4 give rise to bimodal analogues:
T0
0ϕ →ϕ
T1
1ϕ →¬ϕ
40
0ϕ →00ϕ
41
1ϕ →1¬1ϕ
We now introduce an intermediate system: the bimodal logic S42.
Deﬁnition 10. S42 = K2 ⊕T0 ⊕T1 ⊕40 ⊕41
Deﬁnition 11. An S42-model M is a K2 model for which ≤0 and ≤1 are reﬂex-
ive and transitive.
It is well-known that the Hilbert-style presentation of S42 is sound and complete
with respect to the above class of models. Our primary interest S42
Triv, a trivially
bimodal extension of S4 introduced by Yavorskaya-Sidon in [30]. The system
is “trivial” in the sense that the modalities 0 and 1 (or 0¬ and 1 in our
notational variant) are intersubstitutable in any context. Axiomatically, S42
Triv is
deﬁned as follows:
Deﬁnition 12. S42
Triv = S42 ⊕0¬ϕ →1ϕ ⊕1ϕ →0¬ϕ
Model theoretically, S42
Triv corresponds to the condition that ≤0=≤1. Now, let
us brieﬂy observe the “triviality” in more detail.
Deﬁnition 13. The map
† maps formulae of the bimodal language of S42
Triv to
formulae of the monomodal language of S4 replacing each instance of 0 and 1
with an instance of .
For ϕ in the language of S42
Triv, we may observe the following:
Observation 1. ⊢S4 ϕ† iﬀ⊢S42
Triv ϕ
Proof. Left-to-right is trivial. Because there are two copies of S4 contained in
S42
Triv, one can replace each instance of  with 0 and yield an S42
Triv theorem
in the process. Right-to-left can be easily established by induction on length of
proofs.
The feature described in Observation 1 provides a bridge between N and exten-
sions of LP with suﬃcient machinery to formally distinguish proofs from refuta-
tions.

A G¨odel-Artemov-Style Analysis of Constructible Falsity
161
2.3
Two Faithful Translations of N
As was suggested in Sect. 1, the G¨odel-McKinsey-Tarski translation of intuition-
istic logic into S4 forms the core of similar translations for N. In [23], Richmond
Thomason provided a translation of N into S4, acknowledging the inﬂuence of
the G¨odel-McKinsey-Tarski translation. Thomason’s translation, of course, is
limited by the use of a single modal operator, entailing that refutations must
reduce to proofs. To more closely mirror Nelson’s intuitions, we can increase the
expressivity of Thomason’s map by deﬁning an enriched version
‡ translating
the language of N into the bimodal language of S42
Triv.
Deﬁnition 14. The map
‡ maps formulae of the language of N to the bimodal
language of S42
Triv by the following recursive deﬁnition:
(p)‡ = 0p for p ∈At
(∼p)‡ = 1p for p ∈At
(ϕ ∧ψ)‡ = ϕ‡ ∧ψ‡
(∼(ϕ ∧ψ))‡ = (∼ϕ)‡ ∨(∼ψ)‡
(ϕ ∨ψ)‡ = ϕ‡ ∨ψ‡
(∼(ϕ ∨ψ))‡ = (∼ϕ)‡ ∧(∼ψ)‡
(ϕ →ψ)‡ = 0(ϕ‡ →ψ‡) (∼(ϕ →ψ))‡ = (ϕ‡) ∧(∼ψ)‡
(∼∼ϕ)‡ = ϕ‡
Note that while Nelson’s refutability semantics for N treats P-realizers and N-
realizers—proofs and refutations—as distinct categories of objects, Thomason’s
translation treats Nelsonian refutability as a deﬁned notion, that is, as the prov-
ability of a negation. Thomason’s translation is therefore not ﬁne-grained enough
to fully capture Nelson’s intuitions. More adequate is a translation into the lan-
guage L 2
, in which distinct, G¨odelian readings can be given to 0 and 1 that
syntactically distinguish between proofs and refutations.
Given the translations
† and
‡, we are capable of providing a more ﬁne-
grained representation of one of Thomason’s principal results from [23], where
ϕ is a formula in the language of N:
Theorem 1 (Thomason). ⊢N ϕ iﬀ⊢S4 (ϕ‡)†
As a corollary, we may infer the following for formulae ϕ in the language of N:
Observation 2. ⊢N ϕ iﬀ⊢S42
Triv ϕ‡
Following Nelson’s picture of N as a logic that tacitly distinguishes proofs from
refutations, we can look to two-agent epistemic logics to uncover the implicit
machinery of proofs and refutations in the system S42
Triv.
3
Two-Agent Logics of Proof and N
Myriad accounts of multiple-agent epistemic logic have been introduced and ana-
lyzed, that is, systems in which an agent may have knowledge concerning other
agents’ knowledge. The system most important to the present task, however,
is the two-agent generalization of Artemov’s LP, in which the justiﬁcations of
one agent are inﬂuenced by the justiﬁcations of the other agent. In this section,

162
T. M. Ferguson
we will pay particular attention to Tatiana Yavorskaya-Sidon’s two-agent logic of
proofs LP2, described in [29,30], although we will employ some of the conventions
of Antonis Achilleos’ study of LP2 and related systems from [1].
The intuitions underlying Yavorskaya-Sidon’s work distinguish the justiﬁca-
tions of each agent from those of any other, leading to an agent-centric distinction
between categories of justiﬁcation. While Yavorskaya-Sidon interprets the typ-
ing of justiﬁcation terms as an indication of the particular agent who possesses
some justiﬁcation or other, the agents are abstract enough to stand in for the
categories of justiﬁcation we have been considering. When we come to examine
explicit interpretations of S42
Triv, we will inherit a great degree of ﬂexibility with
respect to the basis upon which these types are distinguished.
3.1
Two-Agent LP with Conversions
Yavorskaya-Sidon initially oﬀers the basic system LP2 before deﬁning extensions
determined by diﬀerent stipulations about the interactions between diﬀerent
agents’ justiﬁcations. We presume that each agent may possess a distinct type
of justiﬁcation, represented by the members of the sets P0 and P1.
Deﬁnition 15. P0 and P1 are two sets of justiﬁcation terms deﬁned so that
there are two disjoint sets of variables Vi = {x0
i , x1
i , ..., y0
i , ...} and two disjoint
sets of constants Ci = {c0
i , c1
i , ..., d0
i , ...}. Each Pi is recursively constructed in
Backus-Naur form with xj
i ∈Vi and ck
i ∈Ci:
t ::= xj
i|ck
i |t + t|t · t|!t
An atomic proof constant in Ci is interpreted as a simple proof, while the above
operations on these terms construct iteratively more complex proofs. A term
s+t—the sum of proofs s and t—is a proof that proves precisely those statements
either proven by s or proven by t. A term s · t—the application of the proof s to
the proof t—corresponds to a proof such that if s proves a conditional statement
the antecedent of which is proven by t, then s · t proves the consequent. Finally,
the term !t represents a proof checker that, when applied to a purported proof
t of a formula, can verify whether t indeed proves that formula.
Now, we deﬁne a language including these justiﬁcation terms, again appealing
to a notational variant of the one used in [30].
Deﬁnition 16. The language L2 is recursively deﬁned in Backus-Naur form
with p ∈At, t0 ∈P0, and t1 ∈P1:
ϕ ::= p|¬ϕ|ϕ ∧ϕ|ϕ ∨ϕ|ϕ →ϕ|t00ϕ|⟬t1⟭1ϕ
The intended reading of t0ϕ is that t is a proof of ϕ while ⟬t⟭1 represents that
t is a refutation of ϕ.
An important notion in justiﬁcation logic is that of a constant speciﬁcation.
In the context of many-agent justiﬁcation logic, a constant speciﬁcation is a set
of formulae reﬂecting the extent to which the agents possess justiﬁcations for
axioms.

A G¨odel-Artemov-Style Analysis of Constructible Falsity
163
Deﬁnition 17. A constant speciﬁcation CS is a set (possibly empty) of formu-
lae of L2 of the form:
σ0σ1...σn−1ϕ
where ϕ is an instance of an axiom and each σi is an instance of either ti0 or
⟬ti⟭1¬. We assume that a constant speciﬁcation CS enjoys the closure property
such that whenever s0ψ ∈CS or ⟬t⟭1¬ψ ∈CS, also ψ ∈CS. We call the
maximal constant speciﬁcation TCS for total constant speciﬁcation.
Deﬁnition 18. We say that a constant speciﬁcation CS is axiomatically appro-
priate if for every formula ψ such that ψ is either
– a substitution instance of an axiom scheme A, or
– a member of CS
there exist c, c′ ∈Ci such that c0ψ ∈CS and ⟬c′⟭1¬ψ ∈CS.5
Now, to deﬁne LP2 and its extensions from a proof-theoretic perspective, we
consider a number of axiom schemes.
For each i ∈{0, 1} and s, t ∈Pi, we include the following axiom schema:
Application0
s0(ϕ →ψ) →(t0ϕ →s · t0ψ)
Application1
⟬s⟭1(ϕ ∧¬ψ) →(⟬t⟭1¬ϕ →⟬s · t⟭1¬ψ)
Sum0
s0ϕ →s + t0ϕ and t0ϕ →s + tiϕ
Sum1
⟬s⟭1ϕ →⟬s + t⟭1ϕ and ⟬t⟭1ϕ →⟬s + t⟭1ϕ
Proof Checker0
t0ϕ →!t0t0ϕ
Proof Checker1
⟬t⟭1ϕ →⟬!t⟭1¬⟬t⟭1ϕ
Reﬂectioni
t0ϕ →ϕ
Reﬂectioni
⟬t⟭1ϕ →¬ϕ
This permits us to deﬁne the two-agent logic of proofs as follows.
Deﬁnition 19. With respect to a constant speciﬁcation CS, we deﬁne the two-
agent logic of proofs LP2
CS
PC⊕(

i∈{0,1}(Applicationi⊕Sumi⊕Proof Checkeri⊕Reﬂectioni))⊕CS
We employ the convention of referring to LP2
T CS as LP2.
In LP2, the only particular interactions between agents are those codiﬁed by a
constant speciﬁcation. For example, in the case of TCS, the interaction amounts
to common knowledge of axioms. To capture more elaborate interactions between
the two agents of LP2, Yavorskaya-Sidon introduces a number of unary operations
on proof terms including ↑0
1 and ↑1
0 representing the conversion between agents’
justiﬁcations. With these operations, Yavorskaya-Sidon proposes extensions of
LP2 by enriching its theory by the following axioms:
5 The property of being axiomatically appropriate is sometimes described as “fullness”
in, e.g., [5] or [21].

164
T. M. Ferguson
0-1 Conversion
t0¬ϕ →⟬↑1
0 t⟭1ϕ
1-0 Conversion
⟬t⟭1ϕ →↑0
1 t0¬ϕ
As an illustration, note that it is trivial to convert a classical proof of ϕ into a
refutation of ¬ϕ. If we read the operator t0ϕ as asserting that t is a proof of
ϕ, then this example is captured by 0-1 Conversion to infer ⟬↑1
0 t⟭1¬ϕ, i.e.,
that ↑1
0 t modiﬁes proof t to produce a refutation of ¬ϕ.
From these axioms, Yavorskaya-Sidon deﬁnes the two-agent logic of proofs
LP2
↑↑:
Deﬁnition 20. With respect to a constant speciﬁcation CS, the logic LP2
CS↑↑is
deﬁned so that:
LP2
CS↑↑= LP2
CS ⊕0-1 Conversion ⊕1-0 Conversion
The semantical approach to justiﬁcation logics that we will adopt follows the
approach initiated by Alexey Mkrtychev in [13] and exhaustively developed by
Melvin Fitting in a number of papers, e.g, [5].
Deﬁnition 21. An LP2 Fitting model M is a 6-tuple ⟨W, ≤0, ≤1, E0, E1, v⟩such
that
– W is a nonempty set of points
– ≤0 and ≤1 are partial orders on W
– Ei is a function from Pi × L2 to ℘(W)
– v is a map from At to ℘(W)
where M enjoys the following properties for each i ∈{0, 1} and s, t ∈Pi:
Monotonicity
If w ∈Ei(t, ϕ) and w ≤i w′, then w′ ∈Ei(t, ϕ)
Application
Ei(s, ϕ →ψ) ∩Ei(t, ψ) ⊆Ei(s · t, ψ)
Sum
Ei(s, ϕ) ∪Ei(t, ϕ) ⊆Ei(s + t, ϕ)
Proof Checker
Ei(t, ϕ) ⊆Ei(!t, tiϕ)
In addition to the familiar notion of truth at a point, the Fitting model also is
equipped with evidence functions E0 and E1. The intuitive reading of the fact
that w ∈Ei(t, ϕ) where w ∈W and t ∈Pi is that t counts as adequate evidence
for ϕ for agent i at state w. Note that in general truth of ϕ does not entail the
existence of evidence for ϕ, nor does the existence of evidence for ϕ entail the
truth of the formula.
Deﬁnition 22. A model M meets a constant speciﬁcation CS if for all tiϕ ∈
CS or ⟬t⟭i¬ϕ ∈CS,
W = Ei(t, ϕ).
We then provide an account of a forcing relation in the model by adapting the
particulars of Deﬁnition 9:
Deﬁnition 23. In a model M = ⟨W, ≤0, ≤1, E0, E1, v⟩, the relation ⊩is deﬁned
by replacing the conditions for 0 and 1 from Deﬁnition 9 with:

A G¨odel-Artemov-Style Analysis of Constructible Falsity
165
– M, w ⊩t0ϕ if

for all w′ such that w ≤0 w′, w′ ⊩ϕ, and
w ∈Ei(t, ϕ)
– M, w ⊩⟬t⟭1ϕ if

for all w′ such that w ≤i w′, w′ ⊮ϕ, and
w ∈Ei(t, ¬ϕ)
Hence, for a formula t0ϕ to be true at a point w is not only that t is counted
as adequate evidence for ϕ but also that ϕ is necessary along the relation ≤0.
3.2
Interpreting N in LP2
↑↑
An important notion in justiﬁcation logics is that of a forgetful projection, deﬁned
as an injective map from the language of a justiﬁcation logic to that of its
non-explicit, monomodal counterpart in which instances of justiﬁcation terms
are uniformly replaced by instances of the necessity operator . For example,
in the single-agent LP, the forgetful projection of the formula t(p ∧¬sq) is
(p∧¬q). In the ﬁeld of justiﬁcation logics, the notion of a forgetful projection
is important because it provides a framework in which the correctness of an
explicit justiﬁcation logic with respect to its non-explicit counterpart can be
judged.
As S42
Triv is bimodal, the notion of forgetful projection must be generalized
to the case of bimodal logics.
Deﬁnition 24. The forgetful projection ϕ◦of a formula ϕ ∈L2 is determined
by the map
◦: L2 →L 2
 deﬁned by the following clauses:
– (p)◦= p for p ∈At
– (¬ϕ)◦= ¬(ϕ◦)
– (ϕ ∗ψ)◦= (ϕ◦) ∗(ψ◦) for ∗∈{∧, ∨, →}
– (t0ϕ)◦= 0(ϕ◦) for all t ∈P0
– (⟬t⟭1ϕ)◦= 1(ϕ◦) for all t ∈P1
In general, for a set of formulae Γ, we will let Γ ◦denote the set {ϕ◦| ϕ ∈Γ}.
This eﬀectively projects the rich language of LP2 onto the less expressive bimodal
language L 2
. Then the Realization Theorem correlating S42
Triv and LP2
↑↑in [30]
gives us the following:
Theorem 2. (Yavorskaya-Sidon) ⊢S42
Triv ϕ iﬀthere is a formula ψ ∈LLP2
↑↑
such that ψ◦= ϕ and ⊢LP2
↑↑ψ.
Taken together, Observation 2 and Theorem 2 suggest that whenever one can
prove a formula ϕ in N, one can constructively determine and represent its
proof- and refutation-theoretic content in a corresponding LP2
↑↑theorem.
This observation suggests that LP2
↑↑supplies an appropriate account of proofs
and disproofs in Nelson’s N. Returning to Artemov’s foundational picture of Int

166
T. M. Ferguson
from Sect. 1, the foregoing theorems lead to the following G¨odel-Artemov-style
“foundational picture” of the logic of constructible falsity:
N →S42
Triv →LP2
↑↑→Proofs and Disproofs
Nelson’s [14] ensures that the introduction of the formal system N is accom-
panied by an extraordinarily salient critique of the restrictions implicit in the
intuitionistic account of constructivity. In hindsight, the clarity of the philosoph-
ical foundation codiﬁed by N—and its reliance on the same concepts employed
in the G¨odel-Artemov-style interpretation of Int—leads to a sense of inevitability
with respect to the above picture.
4
Preliminary Remarks on Heyting-Brouwer Logic
I believe that the naturalness of the above “foundational picture” conﬁrms that
Nelson’s distinctions were timely and serves to reinforce his critique of intuition-
istic constructivity. Moreover, the ease by which Artemov’s program extends to
N demonstrates the utility of employing distinct modalities to model notions of
falsiﬁcation alongside provability.
There are quite a few neighbors of intuitionistic logic with embeddings into
modal logics including a falsiﬁcation-type interpretation of one or more modal
operators. Fitting, for example, has given in [8] an evidence-based interpreta-
tion of the paraconsistent variant of N via an embedding. Yaroslav Shramko’s
[22] suggests a straightforward falsiﬁcationist interpretation of dual-intuitionistic
logic, and Wansing’s 2Int described in [27] involves a proof-and-refutation inter-
pretation that is distinct from Nelson’s. The story in these cases, however, is
typically not as straightforward as Nelson’s and Artemov’s approach to these
systems, and a hope for the G¨odel-Artemov-style interpretation of N is that it
might serve to help clarify the interpretations of these systems. I’d like to con-
clude by providing some preliminary remarks on the application of the foregoing
work to the case of Rauszer’s Heyting-Brouwer logic HB.
Just as Nelson suggests two categories of proof and refutation, Heinrich Wans-
ing’s [26] suggests that HB can be interpreted in terms of proofs and their duals,
where a dual proof is a “canonical reduction to non-truth.” Hence, it is prima
facie plausible that the picture corresponding to HB can be ﬁlled in by examin-
ing a formal analogue to LP with elements corresponding not only to proofs but
to dual proofs as well.
In [11,28], it has been demonstrated that a G¨odel-McKinsey-Tarski-style
translation of HB embeds the logic into the bimodal tense logic KtT4. Given
an adequate explicit counterpart to KtT4—a system that by convention might
be called JtT4—the corresponding foundational picture might be represented as:
HB →KtT4 →JtT4 →Proofs and Dual Proofs
There are a number of extraordinarily interesting features that such a foun-
dational picture seems to bring to light. For example, there is a clear analogy

A G¨odel-Artemov-Style Analysis of Constructible Falsity
167
between the characteristic interaction axioms of KtT4 governing the interaction
between the tense operators and the negative introspection axiom 5. Because
HB is non-constructive—it proves a version of excluded middle with respect
to its conegation connective—an adequate characterization of JtT4 aligns the
failure of constructivity and the interaction between proofs and dual proofs.
Furthermore, there have been a number of issues concerning cut eliminability in
HB—[18] shows, for example, that Rauszer’s proof of cut-elimination is faulty—
that might be clariﬁed by making explicit the implicit interaction between proof
and refutation in HB.
Although space considerations prevent describing a full characterization of
such a JtT4, we will close the paper with a useful and general demonstration
that such a system in fact exists by extending the semantic proof of Realization
introduced by Fitting in [6] or [7] to the multimodal case. Between these papers,
Fitting proves that if KL is any normal monomodal logic with a corresponding
justiﬁcation logic JL, then given very modest conditions on the canonical model
of JL, Realization holds.
First, let us examine an important property called Internalization. This is
the property that for an axiomatically appropriate constant speciﬁcation CS, a
logic JLCS is able to “internalize” its own notion of proof so that for every JLCS
theorem ϕ, one can construct a term t such that t0ϕ is also a theorem. Then:
Theorem 3. (Fitting) Let KL be a normal monomodal logic characterized by a
class of Kripke frames F and let JL be an axiomatizable justiﬁcation logic enjoy-
ing Internalization whose canonical frame ( i.e., the frame of the canonical model
MJL) is a member of F. Then every theorem of KL has a provable realization
in a logic JLCS for some constant speciﬁcation CS.
Much of this generality stems from Fitting’s observation that the semantic proof
of Realization for LP in [5] makes no essential use of the particulars of LP. In
[7], in which the proof of [5] is corrected and reﬁned, the proof of Realization
only covers the monomodal case but even a cursory inspection of its arguments
reveals that the proof extends to normal multimodal logics and their justiﬁcation
counterparts as well. Formally, the adaptation of the proof requires only changes
to the bookkeeping conventions of [6,7].
In the monomodal case, Fitting tracks instances of “” in modal formulae
by decorating instances of the operator with distinct natural number subscripts,
e.g., an “annotated” version of the formula p →(q ∨p) is 3p →(q ∨
47p).6 When “i” appears positively in an annotated formula ϕ, Fitting
associates the operator with a distinct justiﬁcation variable xi to record the
correspondence throughout the realization process. In the present paper, we have
explicitly typed the justiﬁcation terms, so a convention is required to associate
instances of the operators 0 and 1 with the appropriate type of variable.
6 In the monomodal case, Fitting indicates particular instances of “” by decorating
them with subscripts rather than superscripts. In the multimodal case, this notation
would contradict our convention of distinguishing between distinct modal operators
by subscripts.

168
T. M. Ferguson
We are thus able to provide the following generalization by describing a
procedure to adapt Fitting’s semantic proof to the multimodal case:
Observation 3. Let KLn be a normal multimodal logic with modalities 0, ...,
n−1 that is characterized by a class of Kripke frames F and let JLn be an
axiomatizable, n-agent justiﬁcation logic enjoying Internalization whose canon-
ical frame ( i.e., the frame of the canonical model MJLn) is a member of F.
Then every theorem of KLn has a provable realization in a logic JLn
CS for some
constant speciﬁcation CS.
Proof. In his proof, Fitting ﬁxes an enumeration of justiﬁcation variables
x0, x1, ... and associates a variable xi with the decorated operator i for each
i ∈ω. In response, we explicitly type our variables {x0
0, x0
1, ..., x1
0, x1
1, ...} and for
each i < n associate variables xj
i with the annotated operator j
i, that is, the
instance of “i” annotated by the index j. Retaining a distinction between types
of variables also demands that whenever Fitting appeals to a property such as
Internalization, care is taken to preﬁx a provable formula with a justiﬁcation
term of the appropriate type. Likewise, whenever [7] proves a lemma by induc-
tion on complexity of formulae, clauses for formulae ϕ must be reproduced n
times for formulae iϕ, with minor adjustments in notation.
The clarity and generality of Fitting’s proof of Realization in [7] ensures that
these bookkeeping matters are very straightforward and, by the foregoing con-
siderations, guarantee that the reach of Fitting’s result extends to normal mul-
timodal logics as well. The deﬁnition of the system JtT4 and the proofs that the
system has Strong Internalization and that its frames are among those which
characterize KtT4 are left for a future investigation into the G¨odel-Artemov-style
analysis of Heyting-Brouwer logic and other related systems.
References
1. Achilleos, A.: On the complexity of two-agent justiﬁcation logic. In: Bulling, N.,
van der Torre, L., Villata, S., Jamroga, W., Vasconcelos, W. (eds.) CLIMA 2014.
LNCS (LNAI), vol. 8624, pp. 1–18. Springer, Cham (2014). https://doi.org/10.
1007/978-3-319-09764-0 1
2. Artemov, S.: Operational modal logic. Technical report MSI 95–29, Cornell
University (1995)
3. Artemov, S.: On two models of provability. In: Gabbay, D., Zakharyaschev, M.,
Goncharov, S.S. (eds.) Mathematical Problems from Applied Logics II, pp. 1–52.
Springer, New York (2007). https://doi.org/10.1007/978-0-387-69245-6 1
4. Artemov, S.: The ontology of justiﬁcations in the logical setting. Stud. Logica.
100(1–2), 17–30 (2012)
5. Fitting, M.: The logic of proofs, semantically. Ann. Pure Appl. Logic 132(1), 1–25
(2005)
6. Fitting,
M.:
Realization
implemented.
Technical
report
TR-2013005,
City
University of New York (2013)
7. Fitting, M.: Justiﬁcation logics and realization. Technical report TR-2014004, City
University of New York (2014)

A G¨odel-Artemov-Style Analysis of Constructible Falsity
169
8. Fitting, M.: Paraconsistent logic, evidence, and justiﬁcation. Stud. Logica, 1–18
(2017, to appear)
9. G¨odel, K.: Eine Interpretation des intuitionistischen Aussagenkalk¨uls. In: Ergeb-
nisse eines mathematischen Kolloquiums, vol. 4, pp. 39–40 (1933)
10. L´opez-Escobar, E.G.K.: Refutability and elementary number theory. Indagationes
Math. 75(4), 362–374 (1972)
11. Lukowski, P.: Modal interpretation of Heyting-Brouwer logic. Bull. Sect. Logic
25(2), 80–83 (1996)
12. McKinsey, J., Tarski, A.: Some theorems about the sentential calculi of Lewis and
Heyting. J. Symbolic Logic 13(1), 1–15 (1948)
13. Mkrtychev, A.: Models for the logic of proofs. In: Adian, S., Nerode, A. (eds.)
LFCS 1997. LNCS, vol. 1234, pp. 266–275. Springer, Heidelberg (1997). https://
doi.org/10.1007/3-540-63045-7 27
14. Nelson, D.: Constructible falsity. J. Symbolic Logic 14(1), 16–26 (1949)
15. Nelson, D.: Negation and separation of concepts in constructive systems. In:
Heyting, A. (ed.) Constructivity in Mathematics, pp. 208–225. North-Holland,
Amsterdam (1959)
16. Nelson, D., Almukdad, A.: Constructible falsity and inexact predicates. J. Symbolic
Logic 49(1), 231–233 (1984)
17. Odintsov, S.: Constructive Negations and Paraconsistency. Springer, Dordrecht
(2008). https://doi.org/10.1007/978-1-4020-6867-6
18. Pinto, L., Uustalu, T.: Proof search and counter-model construction for bi-
intuitionistic propositional logic with labelled sequents. In: Giese, M., Waaler,
A. (eds.) TABLEAUX 2009. LNCS (LNAI), vol. 5607, pp. 295–309. Springer,
Heidelberg (2009). https://doi.org/10.1007/978-3-642-02716-1 22
19. Rauszer, C.: A formalization of the propositional calculus of H-B logic. Stud. Log-
ica. 33(1), 23–34 (1974)
20. Rauszer, C.: Semi-Boolean algebras and their application to intuitionistic logic
with dual operations. Fundamenta Math. 83(1), 219–249 (1974)
21. Rubtsova, N.: Evidence reconstruction of epistemic modal logic S5. In: Grigoriev,
D., Harrison, J., Hirsch, E.A. (eds.) CSR 2006. LNCS, vol. 3967, pp. 313–321.
Springer, Heidelberg (2006). https://doi.org/10.1007/11753728 32
22. Shramko, Y.: A modal translation for dual-intuitionistic logic. Rev. Symbolic Logic
9(2), 251–265 (2016)
23. Thomason, R.H.: A semantical study of constructible falsity. Zeitschrift f¨ur Math-
ematische Logik und Grundlagen der Mathematik 15(16–18), 247–257 (1969)
24. Wansing, H.: Sequent systems for modal logics. In: Gabbay, D.M., Guenthner, F.
(eds.) Handbook of Philosophical Logic, vol. 8, pp. 61–145. Kluwer, Boston (2002)
25. Wansing, H.: Constructive negation, implication, and co-implication. J. Appl. Non-
class. Logics 18(2–3), 341–364 (2008)
26. Wansing, H.: Proofs, disproofs, and their duals. In: Areces, C., Goldblatt, R. (eds.)
Advances in Modal Logic, vol. 7, pp. 483–505. College Publications, London (2008)
27. Wansing, H.: Falsiﬁcation, natural deduction and bi-intuitionistic logic. J. Logic
Comput. 26(1), 425–450 (2016)
28. Wolter, F.: On logics with coimplication. J. Philos. Logic 27(4), 353–387 (1998)
29. Yavorskaya (Sidon), T.: Multi-agent explicit knowledge. In: Grigoriev, D.,
Harrison, J., Hirsch, E.A. (eds.) CSR 2006. LNCS, vol. 3967, pp. 369–380.
Springer, Heidelberg (2006). https://doi.org/10.1007/11753728 38
30. Yavorskaya (Sidon), T.: Interacting explicit evidence systems. Theory Comput.
Syst. 43(2), 272–293 (2008)

Probabilistic Reasoning About Simply Typed
Lambda Terms
Silvia Ghilezan1,2, Jelena Iveti´c1, Simona Kaˇsterovi´c1, Zoran Ognjanovi´c2,
and Nenad Savi´c3(B)
1 Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia
{gsilvia,jelenaivetic,simona.k}@uns.ac.rs
2 Mathematical Institute SANU, Belgrade, Serbia
zorano@mi.sanu.ac.rs
3 Institute of Computer Science, University of Bern, Bern, Switzerland
savic@inf.unibe.ch
Abstract. Reasoning with uncertainty has gained an important role
in computer science, artiﬁcial intelligence and cognitive science. These
applications urge for development of formal models which capture rea-
soning of probabilistic features. We propose a formal model for reasoning
about probabilities of simply typed lambda terms. We present its syntax,
Kripke-style semantics and axiomatic system. The main results are the
corresponding soundness and strong completeness, which rely on two key
facts: the completeness of simple type assignment and the existence of a
maximal consistent extension of a consistent set.
Keywords: Simply typed lambda calculus · Probabilistic logic
Soundness · Strong completeness
1
Introduction
In the last three decades several formal tools have been developed for reason-
ing about uncertain knowledge. One of these approaches concerns formaliza-
tion in terms of probabilistic logics. Although the idea of probabilistic logic can
be traced back to Leibnitz, Lambert and Boole, the modern development was
started by Nils Nilsson, who tried to provide a logical framework for uncertain
reasoning [22]. After Nilsson, a number of researchers proposed formal systems
for probabilistic reasoning, for example [9,10]. The general lack of compactness
for probabilistic logics causes that one of the main proof-theoretical problems
in this framework is to provide a strongly complete axiomatic system. Several
inﬁnitary logics have been introduce to deal with that issue, a detailed overview
can be found in [16,24,25]. Note that the term “inﬁnitary” concerns the meta
language only, i.e. the object language is countable, and formulas are ﬁnite,
while only proofs are allowed to be inﬁnite. It turns out that this approach can
be combined, for example, with temporal [7,23] and intuitionistic reasoning [20].
So, building on our previous experience (e.g. see [17,24,26]), we describe a class
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 170–189, 2018.
https://doi.org/10.1007/978-3-319-72056-2_11

Probabilistic Reasoning About Simply Typed Lambda Terms
171
of so called measurable models for a probabilistic extension of the simply typed
lambda terms and give a sound and strongly complete (every consistent set of
formulas is satisﬁable) inﬁnitary axiomatization.
The λ-calculus, proposed by Church in the early 1930s, is a simple for-
mal system capable of expressing all eﬀectively computable functions, and it is
equivalent to Turing machines. Typed λ-calculus is a restricted system, where
application is controlled by objects (types) assigned to λ-terms. Already Church
introduced the system with simple (functional) types that turned out to rep-
resent the computational interpretation of intuitionistic natural deduction as
stated by the well-known Curry-Howard correspondence. A variety of type sys-
tems (such as intersection types, dependent types, polymorphic types, etc.) were
proposed in the last decades, ﬁnding application in programming languages for
certiﬁed compilers, automated theorem provers and proof assistants, software
veriﬁcation, computational linguistics, among others. For more details we refer
the reader to [3,4,11]. Soundness and completeness of the simple type assignment
has been proved with respect to semantics developed in [13,14].
Reasoning with uncertainty has gained an important role in computer science,
artiﬁcial intelligence and cognitive science. These applications urge for develop-
ment of formal models which capture reasoning of probabilistic features [12]. This
is our motivation for developing a new formal model for reasoning about simply
typed lambda terms.
Contributions and Main Results. We introduce in this paper a formal model
PΛ→for reasoning about probabilities of simply typed lambda terms which is a
combination of lambda calculus and probabilistic logic. We propose its syntax,
Kripke-style semantics and an inﬁnitary axiomatization.
We ﬁrst endow the language of typed lambda calculus with a probabilistic
operator P≥s and obtain formulas of the form
P≥sM : σ
to express that the probability that the lambda term M is of type σ is equal to
or greater than s. More generally, formulas are of the form P≥sα, where α is a
typed lambda statement M : σ or its Boolean combination. We then propose a
semantics of PΛ→based on a set of possible worlds, where each possible world
is a lambda model. The set of possible worlds is equipped with a probability
measure μ. The set [α] is the set of possible worlds that satisfy the formula α.
Then the probability of α is obtained as μ([α]). Further, we give an inﬁnitary
axiomatization of PΛ→and prove the deduction theorem.
The main results are the soundness and strong completeness of PΛ→with
respect to the proposed model, where strong completeness means that every
consistent set of formulas is satisﬁable. The construction of the canonical model
is crucial for the proof and relays on two key facts. The ﬁrst one is that the
simple type assignment is complete with respect to the simple semantics and
the second one is the property that every consistent set can be extended to the
maximal consistent set.

172
S. Ghilezan et al.
Related Work.
In the last decade, several probabilistic extensions of the
λ-calculus have been introduced and investigated. They are concerned with
introducing non-determinism and probabilities into the syntax and operational
semantics of the λ-calculus in order to formalize computation in the presence of
uncertainty rather than with providing a framework that would enable proba-
bilistic reasoning about typed terms and type assignments.
Audebaud and Paulin-Mohring in [2] gave the axiomatic rules for the estima-
tion of the probability that programs satisfy some given properties. Furthermore,
Dal Lago and Zorzi in [19] considered a non deterministic extension of lambda
calculus, deﬁned small-step and big-step semantics, and proved that the calcu-
lus is sound and complete with respect to computable probability distributions,
whereas Bizjak and Birkedal in [5] constructed a step-indexed logical relations
for a probabilistic extension of a certain higher-order programming language
and showed that the relation is sound and complete with respect to the contex-
tual preorder. Ehrhard et al. in [8] study the probabilistic coherent spaces as a
denotational semantics and show soundness of a probabilistic extension of the
untyped λ-calculus, which is a quantitative reﬁnement to the soundness of the
untyped λ-calculus with respect to the Scott’s model in a probabilistic setting.
A slightly similar approach to ours, that provides a framework for probabilis-
tic reasoning about typed terms, was treated by Cooper et al. in [6], where the
authors proposed a probabilistic type theory in order to formalize computation
with statements of the form “a given type is assigned to a given situation with
probability p”. However, the developed theory was used for analyzing semantic
learning of natural languages in the domain of computational linguistics, and no
soundness or completeness issues were discussed.
We provide a formal model for probabilistic reasoning about simply typed
lambda terms. Our formal model is developed along the lines of the method that
was used in [17,18] to obtain a formal model for probabilistic justiﬁcation logic.
However, the logic of uncertain justiﬁcation already existed ([21]), so the authors
have compared in [17] their logic with Milnikel’s logic proposed in [21], whereas,
to the best of our knowledge, the formal model that we propose is the ﬁrst one.
Outline of the Paper. Section 2 revisits basic notions of lambda calculus, sim-
ple type assignment and simple semantics. In Sect. 3 we present the syntax and
Kripke-style semantics of our probabilistic formal model for reasoning about
simply typed lambda terms. The axiomatic system, together with the sound-
ness theorem, is given in Sect. 4. The completeness of the proposed probabilistic
formal model is proved in Sect. 5.
2
Simple Type Assignment Λ→
In this section, we recall some basic notions of lambda calculus ([3]), simple types
([4,14]), lambda models ([3,14,15]) and revisit the soundness and completeness
result for the simple type assignment proved in [13].

Probabilistic Reasoning About Simply Typed Lambda Terms
173
2.1
Lambda Terms and Types
We recall now some basic notions of the simply typed lambda calculus.
Let VΛ = {x, y, z, . . . , x1, . . .} be a countable set of λ-term variables. Terms
(λ-terms) are generated by the following grammar:
M ::= x | λx.M | MM.
The set of all terms is denoted by Λ and is ranged over by M, N, . . . , M1, . . .. The
operator λx is a binder and the set of free variables of a term M is deﬁned as
usual. The α-conversion, the renaming of bound variables, enables to implement
Barendregt’s convention that bound variables are distinct from free variables.
The β-reduction is a rewriting rule (λx.M)N →β M[N/x]. The deﬁnition
and main properties of β-reduction (and βη-reduction) can be found in [3,14].
The lambda term M is β-equal, (β-convertible), to the lambda term N (notion
M =β N) if and only if there is a sequence M ≡N0, N1, . . . , Nn ≡N, where
Ni →β Ni+1 or Ni+1 →β Ni for all i ∈{0, 1, . . . , n}.
Let VType = {a, b, c, . . . } be a denumerable set of propositional variables.
Types (simple types) are generated by the following grammar:
σ ::= a | σ →σ.
The set of all types is denoted by Type and is ranged over by σ, τ, . . . , σ1, . . ..
A lambda statement is an expression of the form M : σ, where M ∈Λ and
σ ∈Type. Moreover, x : σ is a basic statement. A basis (context) is a set of basic
statements with distinct term variables (can be inﬁnite).
Deﬁnition 1. The simple type assignment, Λ→, is deﬁned ([13]) as follows:
M : σ →τ
N : σ (→E)
MN : τ
[x : σ]
...
M : τ
(→I)
λx.M : σ →τ
M : σ
M =β N
(eq)
N : σ
If M : σ is derivable by the given rules from a basis Γ, it is denoted by
Γ ⊢M : σ. In the sequel we work with this simple type assignment `a la Curry.
There is an equivalent simple type assignment `a la Church, which is out of our
scope.

174
S. Ghilezan et al.
2.2
Lambda Models
We assume that the reader is familiar with the notion of the lambda model and
the interpretation of terms in it. Basic notions and deﬁnitions can be found in
[3,13–15].
The term model M = ⟨D, ·, [[ ]]⟩is deﬁned as follows:
Deﬁnition 2
(i) The domain of a term model is a set of all convertibility-classes of terms.
For M ∈Λ, the convertibility-class represented by M will be denoted by
[M], i.e., [M] = {N : N =β M}.
(ii) If ρ : VΛ →D is the valuation of term variables in D, then [[M]]ρ ∈D is
the interpretation of M ∈Λ in M via ρ.
(iii) The map · is deﬁned by
[M] · [N] = [MN],
and [[ ]]ρ is deﬁned by
[[M]]ρ = [M[N1, . . . , Nn/x1, . . . , xn]],
where x1, . . . , xn are the free variables of M, and ρ(xi) = [Ni] and [· · · / · · · ]
is simultaneous substitution.
(iv) Let ξ : VType →P(D) be a valuation of type variables. The interpretation of
σ ∈Type in M via ξ, denoted by [[σ]]ξ ∈P(D), is deﬁned:
– [[a]]ξ = ξ(a);
– [[σ →τ]]ξ = {d ∈D | ∀e ∈[[σ]]ξ, d · e ∈[[τ]]ξ}.
(v)
– M, ρ, ξ |= M : σ iﬀ[[M]]ρ ∈[[σ]]ξ;
– M, ρ, ξ |= Γ iﬀM, ρ, ξ |= x : σ for all x : σ ∈Γ;
– Γ |= M : σ iﬀ(∀M, ρ, ξ |= Γ) M, ρ, ξ |= M : σ.
The soundness and completeness of type assignment is proved in [13] with
this notion of lambda model. The above semantics is called the simple semantics.
The following results are the key for proving strong completeness for the logic
we propose in this paper.
Theorem 1 (Soundness). Γ ⊢M : σ ⇒Γ |= M : σ.
Theorem 2 (Completeness).
Γ |= M : σ ⇒Γ ⊢M : σ.
3
Probabilistic Logical System for Simply Typed Lambda
Terms PΛ→
The probabilistic logical system for typed lambda terms, PΛ→, is a probabilistic
logic over the simple type assignment Λ→. In this section, we introduce the
syntax and semantics of PΛ→.

Probabilistic Reasoning About Simply Typed Lambda Terms
175
3.1
Syntax of PΛ→
Let S be the set of rational numbers from [0, 1], i.e., S = [0, 1] ∩Q. The alphabet
of the logic PΛ→consists of
– all symbols needed to deﬁne simply typed lambda terms, given in Sect. 2.1,
– the classical propositional connectives ¬ and ∧,
– the list of probability operators P≥s, for every s ∈S.
Other propositional connectives ⇒, ∨, ⇔are deﬁned as usual.
Basic Formulas. All lambda statements of the form M : σ, where M ∈Λ and σ ∈
Type, or statements of the same form connected with Boolean connectives, will
be called basic formulas. Basic formulas are generated by the following grammar:
ForB
α ::= M : σ | α ∧α | ¬α.
The set of all basic formulas is denoted by ForB and will be ranged over by
α, β, . . . , possibly indexed.
Probabilistic Formulas. If α ∈ForB and s ∈S, then a basic probabilistic formula
is any formula of the form P≥sα. The set of all probabilistic formulas, denoted
by ForP, is the smallest set containing all basic probabilistic formulas which is
closed under Boolean connectives.
Probabilistic formulas are generated by the following grammar:
ForP
φ ::= P≥sα | φ ∧φ | ¬φ.
The set ForP will be ranged over by φ, ψ, . . . , possibly with subscripts.
Formulas of PΛ→. The language of PΛ→consists of both basic formulas and
probabilistic formulas
ForPΛ→= ForB ∪ForP.
The set of formulas ForPΛ→will be ranged over by A, A1, A2, . . . .
We use the following abbreviations to introduce other inequalities:
P<sα stands for ¬P≥sα,
P≤sα stands for P≥1−s¬α,
P>sα stands for ¬P≤sα,
P=sα stands for P≥sα ∧¬P>sα.
We also denote both α ∧¬α and φ ∧¬φ by ⊥(and dually for ⊤).
Note that neither mixing of basic formulas and probabilistic formulas,
nor nested probability operators is allowed.
For example, the following two expressions are not (well deﬁned) formulas of
the logic PΛ→:
α ∧P≥1
2 β,
P≥1
3 P≥1
2 α.
The former is not well deﬁned since it is a Boolean combination of a basic formula
and probabilistic formula, whereas the latter is not well deﬁned PΛ→formula
because it contains nested probability operators.

176
S. Ghilezan et al.
3.2
Semantics of PΛ→
The semantics for PΛ→is a Kripke-style semantics based on the possible-world
approach.
Deﬁnition 3 (PΛ→-structure). A PΛ→-structure is a tuple M = ⟨W, ρ, ξ, H,
μ⟩, where:
(i) W is a nonempty set of worlds, where each world is one term model, i.e.,
for every w ∈W, w = ⟨L(w), ·w, [[ ]]w⟩;
(ii) ρ : VΛ × {w} −→L(w), w ∈W;
(iii) ξ : VType × {w} −→P(L(w)), w ∈W;
(iv) H is an algebra of subsets of W, i.e. H ⊆P(W) such that
– W ∈H,
– if U, V ∈H, then W \ U ∈H and U ∪V ∈H;
(v) μ is a ﬁnitely additive probability measure deﬁned on H, i.e.,
– μ(W) = 1,
– if U ∩V = ∅, then μ(U ∪V ) = μ(U) + μ(V ), for all U, V ∈H.
The elements of H are called measurable worlds. We will write ρw(x), instead
of ρ(x, w) and similarly for ξ.
We say that a lambda statement M : σ holds in a world w, notation w |= M : σ,
if and only if
[[M]]w
ρ ∈[[σ]]w
ξ ,
where [[M]]w
ρ is the interpretation of a term M in a world w via ρ, and [[σ]]w
ξ is
the interpretation of a type σ in a world w via ξ. Also, we deﬁne that
w |= M : σ ∧N : τ iﬀw |= M : σ and w |= N : τ,
w |= ¬(M : σ) iﬀw ̸|= M : σ.
For a given α ∈ForB and PΛ→-structure M, let
[α]M = {w ∈W | w |= α}.
We will omit the subscript M when there is no ambiguity from the context.
Deﬁnition 4 (Measurable structure). A structure M is measurable if
[α]M ∈H for every α ∈ForB. The class of all measurable structures of the
logic PΛ→will be denoted by PΛMeas
→
.
Deﬁnition 5 (Satisﬁability
relation).
The
satisﬁability
relation
|= ⊆
PΛMeas
→
× ForPΛ→is deﬁned in the following way:
– M |= M : σ iﬀw |= M : σ, for all w ∈W;
– M |= P≥sα iﬀμ([α]) ≥s;
– M |= ¬A iﬀit is not the case that M |= A;
– M |= A1 ∧A2 iﬀM |= A1 and M |= A2.

Probabilistic Reasoning About Simply Typed Lambda Terms
177
Deﬁnition 6 (Formula satisﬁability). Let A ∈ForPΛ→be a formula and
F ⊆ForPΛ→
– A is satisﬁable if there is an PΛMeas
→
-model M such that M |= A;
– A is valid if for every PΛMeas
→
-model M, M |= A;
– A set of formulas F is satisﬁable if there is a PΛMeas
→
-model M such that
M |= A for every A ∈F.
We now give a couple of simple examples in order to clarify the above notions.
Example 1. Consider the following model with three worlds, i.e., let M =
⟨W, ρ, ξ, H, μ⟩, where:
– W = {w1, w2, w3},
– H = P(W),
– μ({wj}) = 1
3, j = 1, 2, 3,
and ρ and ξ are deﬁned such that
w1 |= (x : σ →τ) ∧(y : σ),
w2 |= (x : σ1 →τ) ∧(y : σ1),
w3 |= (x : σ2 →τ) ∧(y : σ2) (Fig. 1).
It is obvious that M
|=
P= 1
3 (x : σ
→τ), M
|=
P= 1
3 (y
: σ) and
M |= P=1(xy : τ).
Note that this example shows that in the case of an application of two terms,
the probability of an application can not be smaller than the probability of the
conjunction of its components, but it can be any number greater than or equal
to it (and less or equal to 1).
Fig. 1. An illustration of the Example 1.
The previous example showed that an application always has a probability
bigger than or equal to the conjunction of its components. On the other hand,
each conjunct can have a probability greater than the application as we will
show in the following example.

178
S. Ghilezan et al.
Example 2. Let M = ⟨W, ρ, ξ, H, μ⟩, where:
– W = {w1, w2, w3},
– H = P(W),
– μ({wj}) = 1
3, j = 1, 2, 3,
and ρ and ξ are deﬁned such that
w1 |= (x : σ →τ) ∧(y : σ),
w2 |= (x : σ →τ) ∧(y : σ1),
w3 |= (x : σ2 →τ) ∧(y : σ).
Now, it is clear that M |= P= 1
3 (xy : τ), while M |= P= 2
3 (x : σ →τ) and
M |= P= 2
3 (y : σ).
The next example shows that we must provide an inﬁnitary axiomatization
in order to obtain strong completeness for our formal model.
Example 3. Consider the set
F = {¬P=0α} ∪{P< 1
n α | n
is
a
positive
integer}.
Every ﬁnite subset of F is clearly PΛMeas
→-satisﬁable, but the set F itself is not,
since there is no real number greater than 0 and smaller than all positive rationals
due to the Archimedean property of real numbers.1 Therefore, the compactness
theorem which states that “if every ﬁnite subset of F is satisﬁable, then F is
satisﬁable” does not hold for PΛ→.
4
The Axiomatization AxPΛ→
We introduce an axiomatic system for the logic PΛ→which will be denoted by
AxPΛ→. Inference rules will be divided in two groups, such that inference rules
from the ﬁrst group can be applied only to lambda statements.
Axiom schemes
(1) all instances of the classical propositional tautologies, (atoms are any PΛ→-
formulas),
(2) P≥0α,
(3) P≤rα ⇒P<sα, s > r,
(4) P<sα ⇒P≤sα,
(5) (P≥rα ∧P≥sβ ∧P≥1(¬α ∨¬β)) ⇒P≥min{1,r+s}(α ∨β),
(6) (P≤rα ∧P<sβ) ⇒P<r+s(α ∨β), r + s ≤1,
(7) P≥1(α ⇒β) ⇒(P≥sα ⇒P≥sβ).
1 For any real number ϵ > 0 there exists an n ∈N such that 1
n < ϵ.

Probabilistic Reasoning About Simply Typed Lambda Terms
179
Inference Rules I
M : σ →τ
N : σ
(1)
(→E)
MN : τ
[x : σ]
...
M : τ
(2)
(→I)
λx.M : σ →τ
M : σ
M =β N
(3)
(eq)
N : σ
Inference Rules II
(1) From A1 and A1 ⇒A2 infer A2,
(2) from α infer P≥1α,
(3) from the set of premises
{φ ⇒P≥s−1
k α | k ≥1
s}
infer φ ⇒P≥sα.
Axiom 2 announces that every formula is satisﬁed in a set of worlds whose
measure is at least 0, and we can easily infer (using ¬α instead of α) that
the upper bound is 1, i.e., P≤1α. Axioms 3 and 4 provide the monotonicity of
a measure, Axioms 5 and 6 correspond to the ﬁnite additivity of a measure,
whereas Axiom 7 ensures that equivalent formulas have equal measures.
Inference Rules I are the rules that correspond to correct inference of typed
lambda terms.
Inference Rules II:
– Rule II.1 is modus ponens (MP);
– Rule II.2 is the probability necessitation;
– Rule II.3 is the only inﬁnitary rule of inference, and states that if probability
is arbitrary close to s then it is at least s.
Deﬁnition 7 (Inference relation)
Let T be a set of formulas and A a formula.
1. T ⊢A means that there exists a sequence A0, . . . , Aλ+1 (λ is ﬁnite or countable
ordinal) of formulas, such that Aλ+1 = A and for all i ⩽λ+1, Ai is an axiom-
instance, or Ai ∈T, or Ai can be derived by some inference rule applied on
some previous members of the sequence.
2. Instead of ∅⊢A we write ⊢A. Any formula A such that ⊢A will be called a
theorem.
3. T is consistent if

180
S. Ghilezan et al.
– there is at least a formula α ∈ForB and a formula φ ∈ForP that are not
deducible from T and
– for every lambda statement M : σ such that M : σ ∈T, if xi, i ∈I are all
free variables of M, then all basic statements of the form xi : τi (needed
to adequately derive M : σ according to and inference rules I) are also
in T.
Otherwise, T is inconsistent.
4. T is a maximally consistent set if it is consistent and:
(1) for every α ∈ForB, if T ⊢α, then α ∈T and P≥1α ∈T,
(2) for every φ ∈ForP, either φ ∈T or ¬φ ∈T.
5. T is deductively closed if for every A ∈ForPΛ→, if T ⊢A, then A ∈T.
Note that it is not required that for every α ∈ForB, either α or ¬α belongs
to a maximal consistent set (as it is done for formulas from ForP). It can be
proved that, otherwise, in our canonical model, for each α we would have P=1α
or P=0α, so the probability operator would not make sense.
Theorem 3 (Deduction theorem). Let T be a set of formulas and φ, ψ ∈
ForP. If T ∪{φ} ⊢ψ then T ⊢φ ⇒ψ.
Proof. The proof is given in Appendix.
□
Theorem 4 (Soundness). The axiomatic system AxPΛ→is sound with respect
to the class of PΛMeas
→
-models.
Proof. The proof is given in Appendix.
□
5
Completeness
In order to prove the completeness theorem we start with some auxiliary state-
ments. After that, we show how to extend a consistent set of formulas T to a
maximal consistent set of formulas T ⋆. Finally, we construct the canonical model
using the set T ⋆such that MT ⋆|= A iﬀA ∈T ⋆.
Lemma 1. Let T be a consistent set of formulas.
(1) For any formula φ ∈ForP, either T ∪{φ} is consistent or T ∪{¬φ} is
consistent.
(2) If ¬(φ ⇒P≥sα) ∈T, then there is some n > 1
s such that
T ∪{φ ⇒¬P≥s−1
n α} is consistent.
Proof. The proof is given in Appendix.
□
Lemma 2. Let T be a maximal consistent set of formulas.
(1) ψ ∈ForP, if T ⊢ψ, then ψ ∈T.
(2) For any formula α, if t = sup{s | P≥sα ∈T}, and t ∈S, then P≥tα ∈T.
Proof. The proof is given in Appendix.
□

Probabilistic Reasoning About Simply Typed Lambda Terms
181
Theorem 5. Every consistent set can be extended to a maximal consistent set.
Proof. Consider a consistent set T. By CnB(T) we will denote the consistent set of
all basic formulas that are consequences of T. Let φ0, φ1, . . . be an enumeration
of all formulas from ForP. We deﬁne a sequence of sets Ti, i = 0, 1, 2, . . . as
follows:
(1) T0 = T ∪CnB(T) ∪{P≥1α | α ∈CnB(T)},
(2) for every i ≥0,
(a) if Ti ∪{φi} is consistent, then Ti+1 = Ti ∪{φi}, otherwise
(b) if φi is of the form ψ ⇒P≥sβ, then
Ti+1 = Ti ∪{¬φi, ψ ⇒¬P≥s−1
n β}, for some positive integer n, so that
Ti+1 is consistent, otherwise,
(c) Ti+1 = Ti ∪{¬φi},
(3) T ⋆= ∞
i=0 Ti.
The set T0 is obviously consistent. Note that the existence of the natural number
(n) from the step 2(b) of the construction is provided by Lemma 1(2), and each
Ti is consistent.
It still remains to show that T ⋆is a maximal consistent set. The steps (1)
and (2) of the above construction ensure that T ⋆is maximal.
T ⋆obviously does not contain all formulas. If α ∈ForB, by the construction
of T0, α and ¬α can not be both in T0. For a formula φ ∈ForP, the set T ⋆does
not contain both φ = φi and ¬φ = φj, because the set Tmax{i,j}+1 is consistent.
Let us prove that T ⋆is deductively closed. If a formula α ∈ForB and T ⊢α,
then by the construction of T0, α ∈T ⋆and P≥1α ∈T ⋆. Let φ ∈ForP. It can
be easily proved (induction on the length of the inference) that if T ⋆⊢φ, then
φ ∈T ⋆. Note the fact that if φ = φj and Ti ⊢φ it has to be φ ∈T ⋆because
Tmax{i,j}+1 is consistent. Suppose that the sequence φ1, φ2, . . . , φ is the proof of
φ from T ⋆. If the mentioned sequence is ﬁnite, there must be some set Ti such
that Ti ⊢φ, and φ ∈T ⋆. Therefore, suppose that the sequence is countably
inﬁnite. We can show that, for every i, if φi is obtained by an application of an
arbitrary inference rule, and all the premises belong to T ⋆, then, also φi ∈T ⋆.
If the inference rule is a ﬁnitary one, then there must be a set Tj which contains
all the premises and Tj ⊢φi. So, we conclude that φi ∈T ⋆. Now, consider the
inﬁnitary Rule II.3. Let φi = ψ ⇒P≥sα be obtained from the set of premises
{φk
i = ψ ⇒P≥skα | sk ∈S}. By the induction hypothesis, we have that φk
i ∈T ⋆,
for every k. If φi /∈T ⋆, by step (2)(b) of the construction, there are some l and j
so that ¬(ψ ⇒P≥sα), ψ ⇒¬P≥s−1
l α ∈Tj. Thus, we have that for some j′ ≥j:
– ψ ∧¬P≥sα ∈Tj′,
– ψ ∈Tj′,
– ¬P≥s−1
l α ∈Tj′,
– P≥s−1
l α ∈Tj′ Ind. Hyp.
Contradiction with the consistency of a set Tj′.
Thus, T ⋆is a deductively closed set which does not contain all formulas, so
it is consistent.
□

182
S. Ghilezan et al.
Deﬁnition 8. If T ⋆is a maximally consistent set of formulas, then a tuple
MT ⋆= ⟨W, ρ, ξ, H, μ⟩is deﬁned:
– W = {w = ⟨L(w), ·w, [[ ]]w⟩| w |= CnB(T)} contains all term models that
satisfy the set CnB(T),
– ρw(x) = [x],
– ξw(a) = {[M] ∈L(w) | w |= M : a},
– H = {[α] | α ∈ForB}, where [α] = {w ∈W | w |= α},
– μ([α]) = sup{s | P≥sα ∈T ⋆}.
Lemma 3
(1) H is an algebra of subsets of W,
(2) If [α] = [β], then μ([α]) = μ([β]),
(3) μ([α]) ≥0,
(4) μ(W) = 1, μ(∅) = 0,
(5) μ([α]) = 1 −μ([¬α]),
(6) μ([α] ∪[β]) = μ([α]) + μ([β]), for [α] ∩[β] = ∅.
Proof. The proof is given in Appendix.
□
Consequence of this Lemma is that MT ⋆is well deﬁned.
Lemma 4. Let T ⋆be a maximal consistent set of formulas. Then, MT ⋆∈
PΛMeas
→
.
Proof. Directly from the construction of MT ⋆.
□
We are now ready to prove the main result of this paper.
Theorem 6 (Strong completeness). Every consistent set of formulas T is
PΛMeas
→
-satisﬁable.
Proof. We construct PΛMeas
→
-model MT ⋆and show that for every A ∈ForPΛ→,
MT ⋆|= A iﬀA ∈T ⋆. We use the induction on the complexity of the formula.
(1) A is a lambda statement, A = M : σ. If A ∈CnB(T), then by deﬁnition
of MT ⋆we have MT ⋆|= A. Conversely, suppose MT ⋆|= A, that is, for
all worlds w ∈MT ⋆, w |= M : σ, i.e., [[M]]w
ρ ∈[[σ]]w
ξ . Let B be the set of
all basic statements that are in CnB(T), i.e. B is basis and B ⊆CnB(T).
First, let us consider the case when there is an inﬁnite number of variables
that are not in B. We extend B to a set, B+, of statements in which each
type is assigned to an inﬁnite number of variables and no variable is subject
of more than one statement and no variable in B+ \ B occurs in M (the
construction of a set B+ can be found in [13]). Since no variable from B+\B
appears in the set CnB(T), there is a world, w0, in which only consequences
of B+ hold. Let us show that ξw0(a) = {[N] | B+ ⊢N : a} holds, i.e.,
{[N] | w0 |= N : a} = {[N] | B+ ⊢N : a}.

Probabilistic Reasoning About Simply Typed Lambda Terms
183
(⊆) Suppose that [N1] ̸∈{[N] | B+ ⊢N : a}, that is B+ ⊬N1 : a. Using
Theorem 2, we obtain B+ ̸|= N1 : a. Hence, w0 ̸|= N1 : a and therefore
[N1] ̸∈{[N] | w0 |= N : a}.
(⊇) If [N1] ∈{[N] | B+ ⊢N : a}, we have that B+ ⊢N1 : a. Now, by
Theorem 1, we have B+ |= N1 : a. Since, w0 |= B+, we obtain w0 |= N1 : a
and [N1] ∈{[N] | w0 |= N : a}.
Furthermore, [N] ∈[[σ]]w0
ξ
⇔B+ ⊢N : σ (the proof can be found in [13]).
Since M : σ holds in every world, whence in w0 as well, we obtain B+ ⊢M : σ.
Now, the fact that M does not contain any variable from B+ \ B, gives us
that B ⊢M : σ, and so CnB(T) ⊢M : σ, which means that M : σ ∈T ⋆.
The case when there is a ﬁnite number of variables that are not in B can be
proved using the same idea as in [13].
(2) A is a Boolean combination of lambda statements. If A ∈CnB(T), then,
again, by deﬁnition of MT ⋆we have MT ⋆|= A. Conversely, let
MT ⋆|= A. The goal is to show that A ∈T ⋆, i.e., it is enough to show that
T ⊢A. The Axiom 1 and Modus Ponens give us that A can be proved from
T because of the completeness of classical propositional calculus.
– Next, consider the case A = P≥sα. If P≥sα ∈T ⋆, then
sup{r | P≥rα ∈T ⋆} = μ([α]) ≥s, and so MT ⋆|= P≥sα. Conversely,
suppose that MT ⋆|= P≥sα, i.e. sup{r | P≥rα ∈T ⋆} ≥s. If μ([α]) >
s, then by the properties of supremum and monotonicity of μ, we have
P≥sα ∈T ⋆. If μ([α]) = s, then, from Lemma 2, we have that P≥sα ∈T ⋆.
– Further, let A = ¬ψ ∈ForP. Then MT ⋆|= ¬ψ iﬀit is not the case that
MT ⋆|= ψ iﬀψ /∈T ⋆iﬀ¬ψ ∈T ⋆.
– Finally, let A = φ ∧ψ ∈ForP. Then, MT ⋆|= φ ∧ψ iﬀMT ⋆|= φ and
MT ⋆|= ψ iﬀφ, ψ ∈T ⋆iﬀφ ∧ψ ∈T ⋆.
□
6
Conclusion
In this paper, we introduced the logic PΛ→for reasoning about probabilities of
simply typed lambda terms. The language of this logic is obtained by adding the
operators for probabilities and Boolean connectives to simple type assignment.
An axiomatization for this logic is proposed and proved sound and strongly com-
plete. Since this logic is not compact, the axiomatization contains one inﬁnitary
rule of inference.
As a topic for a further research, we will work towards simpliﬁcation of the
semantics in order to achieve compactness using ﬁnite sets of probability values
for those logics. Another goal is to provide ﬁnitary axiomatizations for those
logics. Also, for a further research we want to consider a case when Axiom 1 is
replaced by an Axiom that states that all intuitionistic propositional tautologies
hold, thus to work in an intuitionistic setting. Furthermore, we want to develop
a ﬁrst order extension of the logic PΛ→. Note that such a logic would extend
classical ﬁrst order logic, so the set of all valid formulas is not recursively enumer-
able [1] and no complete ﬁnitary axiomatization is possible in that undecidable
framework.

184
S. Ghilezan et al.
Another line of research is to develop probabilistic reasoning in other type
disciplines such as polymorphic, intersection and higher-order types.
Acknowledgements. This work was supported by the SNSF project 200021 165549
Justiﬁcations and non-classical reasoning, and by the Serbian Ministry of Education,
Science and Technological Development through projects ON174026, III 044006 and
ON174008.
Appendix Proofs
Proof of Theorem 3. Suppose that T ∪{φ} ⊢ψ. We use transﬁnite induction
on the length of a proof.
If the length of a proof is equal to 1, then ψ is either an axiom or ψ ∈
T ∪{φ}.
(a) If ψ is an axiom:
– T ⊢ψ
Ax
– T ⊢ψ ⇒(φ ⇒ψ)
Ax
– T ⊢φ ⇒ψ
MP,
(b) If ψ ∈T:
– T ⊢ψ
Hyp
– T ⊢ψ ⇒(φ ⇒ψ)
Ax
– T ⊢φ ⇒ψ
MP,
(c) If ψ ∈{φ}:
– T ⊢φ ⇒φ
Ax.
Now, suppose that the length of a proof is k > 1. Formula ψ can belong to the
set T ∪{φ}, but then the proof is the same as above. Therefore, suppose that the
formula ψ is obtained by an application of some inference rule from the Inference
Rules II.
First, if ψ is obtained by an application of Rule II.1 from T, φ ⊢ψ1 and
T, φ ⊢ψ1 ⇒ψ:
– T ⊢φ ⇒ψ1
Ind. Hyp.
– T ⊢φ ⇒(ψ1 ⇒ψ)
Ind. Hyp.
– T ⊢(φ ⇒(ψ1 ⇒ψ)) ⇒((φ ⇒ψ1) ⇒(φ ⇒ψ))
Taut.
– T ⊢(φ ⇒ψ1) ⇒(φ ⇒ψ)
MP
– T ⊢φ ⇒ψ
MP
Next, let us consider the case ψ = P≥1α is obtained from T ∪{φ} by an
application of Rule II.2. In that case:
– T, φ ⊢α,
– T, φ ⊢P≥1α by IR II.2.
However, since α ∈ForB and φ ∈ForP (otherwise, φ ⇒P≥1α would not make
sense), φ cannot aﬀect the proof of α from T ∪{φ}, and we have:

Probabilistic Reasoning About Simply Typed Lambda Terms
185
(1) T ⊢α
Hyp.
(2) T ⊢P≥1α
IR II.2
(3) T ⊢P≥1α ⇒(φ ⇒P≥1α)
Taut.
(4) T ⊢φ ⇒P≥1α
MP.
Finally, let us consider the case ψ = ψ1 ⇒P≥sα is obtained from T ∪{φ} by an
application of Rule II.3. Then:
(1) T, φ ⊢ψ1 ⇒P≥s−1
k α, for all k ≥1
s
Hyp.
(2) T ⊢φ ⇒(ψ1 ⇒P≥s−1
k α)
Ind.Hyp.
(3) T ⊢(φ ∧ψ1) ⇒P≥s−1
k α
Taut.
(4) T ⊢(φ ∧ψ1) ⇒P≥sα
IR II.3
(5) T ⊢φ ⇒ψ Taut.
□
Proof of Theorem 4. Our goal is to show that every instance of an axiom
scheme holds in every model and that the inference rules preserve the validity.
The Axiom 1 holds in every model because of the completeness of classical
propositional logic.
By the Deﬁnition of the ﬁnitely additive probability measure we have that
μ([α]) ≥0 for all α ∈ForB. Hence, M |= P≥0α, for every model M and the
Axiom 2 is valid.
Let us consider the Axiom 3. Suppose that P≤rα holds in model M =
⟨W, ρ, ξ, H, μ⟩and s > r. It means that μ([α]) ≤r. Since s > r, we obtain
μ([α]) < s, that is M |= P<sα.
Similarly, for the Axiom 4, suppose that M |= P<sα. Then, we have μ([α]) <
s, that implies μ([α]) ≤s. Thus, M |= P≤sα.
Next, let us consider Axiom 5. Suppose that in a model M = ⟨W, ρ, ξ, H, μ⟩,
P≥rα, P≥sβ and P≥1¬(α ∨β)
hold. Then, μ([α]) ≥r, μ([β]) ≥s and [α] and [β] are disjoint sets. Since μ is a
ﬁnitely additive measure, we have that
μ([α] ∪[β]) = μ([α ∨β]) = μ([α]) + μ([β]).
Thus, M |= P≥min{1,r+s}(α ∨β), so Axiom 5 holds in the model M.
Now, let us consider the Axiom 6. Suppose that P≤rα, P<sβ hold in a model
M = ⟨W, ρ, ξ, H, μ⟩. Then, μ([α]) ≤r and μ([β]) < s. From
[α] = ([α] ∩(W \ [β])) ∪[α ∧β],
follows that
μ([α]) ≥μ([α] ∩(W \ [β])).
Since [α ∨β] = ([α] ∩(W \ [β])) ∪[β], we have that
μ([α ∨β]) ≤μ([α]) + μ([β]) < r + s.
Therefore, M |= P<r+s(α ∨β).

186
S. Ghilezan et al.
Finally, for the Axiom 7, suppose that P≥1(α ⇒β) holds in a model M =
⟨W, ρ, ξ, H, μ⟩. Then, the set of all worlds in which α holds, but β does not hold
has the measure 0, i.e., μ([α] ∩(W \ [α ⇒β])) = 0. From
[α] = ([α] ∩(W \ [α ⇒β])) ∪([α] ∩[α ⇒β])
follows that μ([α]) = μ([α] ∩[α ⇒β]) and, since [α] ∩[α ⇒β] ⊆[β], we have
that μ([α]) ≤μ([β]). Thus, M |= P≥sα ⇒P≥sβ and Axiom 7 holds in M.
The proof that Inference Rules I are sound can be found in [13].
Inference Rules II:
Rule II.1 is validity-preserving for the same reason as in classical logic.
Rule II.2: suppose that α holds in M = ⟨W, ρ, ξ, H, μ⟩, then [α] = W, and
therefore μ([α]) = 1, so M |= P≥1α.
Rule II.3: Suppose that M |= φ ⇒P≥s−1
k α whenever k ≥1
s. If M ̸|= φ,
then obviously M |= φ ⇒P≥sα. Otherwise M |= P≥s−1
k α for every k ≥1
s,
so M |= P≥sα because of the Archimedean properties of the set of reals. □
Proof of Lemma 1
(1) If T ∪{φ} ⊢⊥, and T ∪{¬φ} ⊢⊥, then by Deduction theorem we have
T ⊢¬φ and T ⊢φ. Contradiction.
(2) Suppose that for all n > 1
s:
T, φ ⇒¬P≥s−1
n α ⊢⊥.
Therefore, by Deduction theorem and propositional reasoning, we have
T ⊢φ ⇒P≥s−1
n α,
and by an application of Rule II.3 we obtain T ⊢φ ⇒P≥sα. Contradiction
with the fact that ¬(φ ⇒P≥sα) ∈T.
□
Proof of Lemma 2
(1) Consequence of Deﬁnition 7.4.
(2) Let t = sup{s | P≥sα ∈T} ∈S. By the monotonicity of a measure, for each
s ∈S, s < t, T ⊢P≥sα. Using Inference rule 3, we obtain
T ⊢P≥tα.
T is a maximal consistent set of formulas, so, from (1), we have that
P≥tα ∈T.
□
Proof of Lemma 3
(1) The prove that H is an algebra is straightforward using that W = [α ∨¬α],
[α]C = [¬α] and [α] ∪[β] = [α ∨β].

Probabilistic Reasoning About Simply Typed Lambda Terms
187
(2) It suﬃces to prove that [α] ⊂[β] implies μ([α]) ≤μ([β]). According to the
completeness of the propositional logic, we have that [α] ⊂[β] means that
α ⇒β ∈CnB(T), and then also P≥1(α ⇒β) ∈T ⋆. By axiom 7, we obtain
that for each s ∈S, P≥sα ⇒P≥sβ ∈T ⋆, so μ([α]) ≤μ([β]).
(3) P≥0α is an axiom, so μ([α]) ≥0.
(4) For any α ∈T, we have that α ∨¬α ∈CnB(T) and P≥1(α ∨¬α) ∈T ⋆,
therefore, we obtain that W = [α ∨¬α] and μ(W) = 1. Since
P≥1(α ∨¬α) = P≥1−0(α ∨¬α) = P≤0¬(α ∨¬α) = P≤0(¬α ∧α)
= ¬P>0(¬α ∧α), using that P≥tα ⇒P>sα, for t > s, we obtain that
sup{s | P≥s(¬α ∧α) ∈T ⋆} = 0,
and μ(∅) = 0.
(5) Let μ([α]) = sup{s | P≥sα ∈T ⋆} = r. If r = 1, then from Lemma 2 we
obtain P≥1α ∈T ⋆. Therefore, ¬P>0¬α ∈T ⋆. Again, using the fact that
P≥tα ⇒P>sα, for t > s, we obtain that μ([¬α]) = 0. Now, suppose that
r < 1. Then, for each rational number r′ ∈(r, 1], ¬P≥r′α = P<r′α ∈T ⋆. By
Axiom 4, we obtain that P≤r′α, P≥1−r′¬α ∈T ⋆. If there is some rational
number r′′ ∈[0, r) such that P≥1−r′′¬α ∈T ⋆, then ¬P>r′′α ∈T ⋆, contra-
diction. Thus,
sup{s | P≥s¬α ∈T ⋆} = 1 −sup{s | P≥sα ∈T ⋆},
i.e., μ([α]) = 1 −μ([¬α]).
(6) Let [α] ∩[β] = ∅, and let μ([α]) = r and μ([β]) = s. From the fact that
[β] ⊂[¬α], using steps (2) and (5), we obtain that r + s ≤r + (1 −r) = 1.
Suppose that both r > 0 and s > 0. Using properties of the supremum, for
every rational number r′ ∈[0, r), and for every rational number
s′ ∈[0, s), we have that P≥r′α, P≥s′β ∈T ⋆. By the Axiom 5, we know that
P≥r′+s′(α ∨β) ∈T ⋆. Therefore, r + s ≤t0 = sup{t | P≥t(α ∨β ∈T ⋆)}.
In the case that r + s = 1, the statement holds obviously, so suppose that
r + s < 1. If r + s < t0, then for every rational number t′ ∈(r + s, t0) we
have P≥t′(α ∨β) ∈T ⋆. There exists rational numbers r′′ > r and s′′ > s,
such that:
¬P≥r′′α, P<r′′α ∈T ⋆
, ¬P≥s′′α, P<s′′α ∈T ⋆,
and
r′′ + s′′ = t′ ≤1.
By Axiom 4, we obtain P≤r′′ ∈T ⋆. Using Axiom 6, we get
P≤r′′+s′′(α ∨β) ∈T ⋆,
¬P≥r′′+s′′(α ∨β) ∈T ⋆,
and
¬P≥t′(α ∨β) ∈T ⋆.
Contradiction. Hence, r + s = t0 and we obtain that
μ([α] ∪[β]) = μ([α]) + μ([β]). Finally, if we suppose that r = 0 or s = 0, we
can reason as above, where r′ = 0 or s′ = 0.
□

188
S. Ghilezan et al.
References
1. Abadi, M., Halpern, J.Y.: Decidability and expressiveness for ﬁrst-order logics of
probability. Inf. Comput. 112(1), 1–36 (1994)
2. Audebaud, P., Paulin-Mohring, C.: Proofs of randomized algorithms in Coq. Sci.
Comput. Program. 74(8), 568–589 (2009)
3. Barendregt, H.P.: The Lambda Calculus: Its Syntax and Semantics. North Holland,
New York (1984)
4. Barendregt, H.P., Dekkers, W., Statman, R.: Lambda Calculus with Types (Per-
spectives in logic). Cambridge University Press, Cambridge (2013)
5. Bizjak, A., Birkedal, L.: Step-indexed logical relations for probability. In: Pitts, A.
(ed.) FoSSaCS 2015. LNCS, vol. 9034, pp. 279–294. Springer, Heidelberg (2015).
https://doi.org/10.1007/978-3-662-46678-0 18
6. Cooper, R., Dobnik, S., Lappin, S., Larsson, S.: A probabilistic rich type theory
for semantic interpretation. In: Proceedings of the EACL 2014 Workshop on Type
Theory and Natural Language Semantics (TTNLS), pp. 72–79 (2014)
7. Doder, D., Grant, J., Ognjanovi´c, Z.: Probabilistic logics for objects located in
space and time. J. Logic Comput. 23(3), 487–515 (2013)
8. Ehrhard, T., Pagani, M., Tasson, C.: The computational meaning of probabilistic
coherence spaces. In: Proceedings of the 26th Annual IEEE Symposium on Logic
in Computer Science, LICS 2011, pp. 87–96 (2011)
9. Fagin, R., Halpern, J.Y., Megiddo, N.: A logic for reasoning about probabilities.
Inf. Comput. 87(1/2), 78–128 (1990)
10. Fattorosi-Barnaba, M., Amati, G.: Modal operators with probabilistic interpreta-
tions. I. Studia Logica 46(4), 383–393 (1987)
11. Ghilezan, S., Likavec, S.: Computational interpretations of logics. Zbornik radova,
Special Issue Logic and Computer Science, Matematiˇcki institut 12(20), 159–215
(2009)
12. Goodman, N.D.: The principles and practice of probabilistic programming. In: The
40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, POPL 2013, pp. 399–402 (2013)
13. Hindley, J.R.: The completeness theorem for typing lambda-terms. Theor. Comput.
Sci. 22, 1–17 (1983)
14. Hindley, J.R.: Basic Simple Type Theory. Cambridge Tracts in Theoretical Com-
puter Science 42. Cambridge University Press, Cambridge (1997)
15. Hindley, J.R., Longo, G.: Lambda-calculus models and extesionality. Math. Logic
Q. 26, 289–310 (1980)
16. Ikodinovi´c, N., Ognjanovi´c, Z., Raˇskovi´c, M., Markovi´c, Z.: First-order probabilistic
logics and their applications. Zbornik radova, Subseries Logic in Computer Science,
Matematiˇcki institut 18(26), 37–78 (2015)
17. Kokkinis, I., Maksimovi´c, P., Ognjanovi´c, Z., Studer, T.: First steps towards prob-
abilistic justiﬁcation logic. Logic J. IGPL 23(4), 662–687 (2015)
18. Kokkinis, I., Ognjanovi´c, Z., Studer, T.: Probabilistic justiﬁcation logic. In:
Artemov, S., Nerode, A. (eds.) LFCS 2016. LNCS, vol. 9537, pp. 174–186.
Springer, Cham (2016). https://doi.org/10.1007/978-3-319-27683-0 13
19. Lago, U.D., Zorzi, M.: Probabilistic operational semantics for the lambda calculus.
RAIRO Theor. Inform. Appl. 46(3), 413–450 (2012)
20. Markovi´c, Z., Ognjanovi´c, Z., Raˇskovi´c, M.: A probabilistic extension of intuition-
istic logic. Math. Logic Q. 49(4), 415–424 (2003)

Probabilistic Reasoning About Simply Typed Lambda Terms
189
21. Milnikel, R.S.: The logic of uncertain justiﬁcations. Ann. Pure Appl. Logic 165(1),
305–315 (2014)
22. Nilsson, N.J.: Probabilistic logic. Artif. Intell. 28(1), 71–87 (1986)
23. Ognjanovi´c, Z.: Discrete linear-time probabilistic logics: completeness, decidability
and complexity. J. Logic Comput. 16(2), 257–285 (2006)
24. Ognjanovi´c, Z., Raˇskovi´c, M., Markovi´c, Z.: Probability logics. Zborik radova, Sub-
series Logic in Computer Science, Matematiˇcki institut 12(20), 35–111 (2009)
25. Ognjanovi´c, Z., Raˇskovi´c, M., Markovi´c, Z.: Probability Logics: Probability-Based
Formalization of Uncertain Reasoning. Springer, Cham (2016)
26. Savi´c, N., Doder, D., Ognjanovi´c, Z.: Logics with lower and upper probability
operators. Int. J. Approx. Reason. 88, 148–168 (2017)

Polyteam Semantics
Miika Hannula1, Juha Kontinen2, and Jonni Virtema2,3(B)
1 University of Auckland, Auckland, New Zealand
m.hannula@auckland.ac.nz
2 University of Helsinki, Helsinki, Finland
juha.kontinen@helsinki.fi
3 Hasselt University, Hasselt, Belgium
jonni.virtema@uhasselt.be
Abstract. Team semantics is the mathematical framework of modern
logics of dependence and independence in which formulae are inter-
preted by sets of assignments (teams) instead of single assignments as in
ﬁrst-order logic. In order to deepen the fruitful interplay between team
semantics and database dependency theory, we deﬁne Polyteam Seman-
tics in which formulae are evaluated over a family of teams. We begin
by deﬁning a novel polyteam variant of dependence atoms and give a
ﬁnite axiomatisation for the associated implication problem. We also
characterise the expressive power of poly-dependence logic by proper-
ties of polyteams that are downward closed and deﬁnable in existential
second-order logic (ESO). The analogous result is shown to hold for poly-
independence logic and all ESO-deﬁnable properties.
Keywords: Team semantics · Dependency theory · Expressive power
1
Introduction
Team semantics is the mathematical framework of modern logics of dependence
and independence. The origin of team semantics goes back to [15] but its devel-
opment to its current form began with the publication of the monograph [24]. In
team semantics formulae are interpreted by sets of assignments (teams) instead
of single assignments as in ﬁrst-order logic. The reason for this change is that
statements such as the value of a variable x depends on the value of y do not
really make sense for single assignments. Team semantics has interesting connec-
tions with database theory and database dependencies [11–13,18]. In order to
facilitate the exchange between team semantics and database theory, we intro-
duce a generalisation of team semantics in which formulae are evaluated over a
family of teams. We identify a natural notion of poly-dependence that generalises
This research was supported by a Marsden grant from Government funding, admin-
istered by the Royal Society of New Zealand, and grants 292767 and 308712 of the
Academy of Finland.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 190–210, 2018.
https://doi.org/10.1007/978-3-319-72056-2_12

Polyteam Semantics
191
dependence atoms to polyteams and give a ﬁnite axiomatisation for its implica-
tion problem. We also deﬁne polyteam versions of independence, inclusion and
exclusion atoms, and characterise the expressive power of poly-dependence and
poly-independence logic.
A team X is a set of assignments with a common ﬁnite domain x1, . . . , xn
of variables. Such a team can be viewed as a database table with x1, . . . , xn as
its attributes. Dependence logic extends the language of ﬁrst-order logic with
atomic formulae = (x, y) called dependence atoms expressing that value of the
variable y is functionally determined by the values of the variables in x. On the
other hand, independence atoms y ⊥x z [9] express that, for any ﬁxed value of
x, knowing the value of z does not tell us anything new about the value of y.
By viewing a team as a database, the atoms = (x, y) and y ⊥x z correspond
to the widely studied functional and embedded multivalued dependencies. Fur-
thermore, inclusion atoms x ⊆y and exclusion atoms x|y of [6] inherit their
semantics from the corresponding database dependencies.
Independence, inclusion, and exclusion atoms have very interesting properties
in the team semantics setting. For example, inclusion atoms give rise to a variant
of dependence logic that corresponds to the complexity class PTIME over ﬁnite
ordered structures [7] whereas all the other atoms above (and their combinations)
give rise to logics that are equi-expressive with existential second-order logic
and the complexity class NP. The complexity theoretic aspects of logics in team
semantics have been studied extensively during the past few years (see [4] for a
survey).
A multiset version of team semantics was recently deﬁned in [3]. Multiteam
semantics is motivated by the fact that multisets are widely assumed in database
theory and occur in applications. Multiteam semantics can be also used to model
and study database, probabilistic, and approximate dependencies in a uniﬁed
framework (see [3,25]).
The aim of this work is similar to that of [3], i.e., we want to extend
the applicability of team semantics. In database theory dependencies are often
expressed by so-called embedded dependencies. An embedded dependency is a
sentence of ﬁrst-order logic with equality of the form
∀x1 . . . ∀xn

φ(x1, . . . , xn) →∃y1 . . . ∃ykψ(x1, . . . , xn, y1, . . . , yk)

,
where φ and ψ are conjunctions of relational atoms R(x1, . . . , xn) and equalities
x = y. In the literature embedded dependencies have been thoroughly classiﬁed
stemming from real life applications. Examples of well-known subclasses include
full, uni-relational, 1-head, tuple-generating, and equality-generating. For exam-
ple, an embedded dependency is called tuple-generating if it is equality free (for
further details see, e.g., [16, Sect. 3]). The uni-relational dependencies can be
studied also in the context of team semantics as generalised dependencies [21].
However in many applications, especially in the area of data exchange and data
integration, it is essential to be able to express dependencies between diﬀerent
relations.
In the context of data exchange (see e.g. [5]) the relational database is divided
into a set of source relations S and a set of target relations T . Dependencies are

192
M. Hannula et al.
used to describe what kind of properties should hold when data is transferred
from the source schema to the target schema. In this setting a new taxonomy of
embedded dependencies rises: An embedded dependency ∀x

φ(x) →∃yψ(x, y)

is source-to-target if the relation symbols occurring in φ and ψ are from S and T ,
respectively. The embedded dependency is target if the relation symbols occur-
ring in it are from T . There is no direct way to study these classes of dependencies
in the uni-relational setting of team semantics. In this paper we propose a gen-
eral framework in which these inherently poly-relational dependencies can be
studied.
In Sect. 2 we lay the foundations of polyteam semantics. The shift to poly-
teams is exempliﬁed in Sect. 2.2, by the deﬁnition of poly-dependence atoms
and an Armstrong type axiomatisation for the associated implication prob-
lem. In Sect. 3 polyteam semantics is extended from atoms to complex formu-
lae. Section 4 studies the expressive power of the new logics over polyteams.
The main technical results of the section characterises poly-independence (poly-
dependence) logic as the maximal logic capable of deﬁning all (downward closed)
properties of polyteams deﬁnable in existential second-order logic.
2
From Uni-dependencies to Poly-dependencies
We start by deﬁning the familiar dependency notions from the team semantics
literature. In Sect. 2.2 we introduce a novel poly-relational version of dependence
atoms and establish a ﬁnite axiomatisation of its implication problem. We then
continue to present poly-relational versions of inclusion, exclusion, and inde-
pendence atoms, and a general notion of a poly-relational dependency atom. We
conclude this section by relating the embedded dependencies studied in database
theory to our new setting.
2.1
Dependencies in Team Semantics
Vocabularies τ are sets of relation symbols with prescribed arities. For each
R ∈τ, let ar(R) ∈Z+ denote the arity of R. A τ-structure is a tuple A =

A, (RA
i )Ri∈τ

, where A is a set and each RA
i is an ar(Ri)-ary relation on A
(i.e., RA
i ⊆Aar(Ri)). We use A, B, etc. to denote τ-structures and A, B, etc. to
denote the corresponding domains.
Let D be a ﬁnite set of ﬁrst-order variables and A be a nonempty set. A
function s: D →A is called an assignment. For a variable x and a ∈A, the
assignment s(a/x): D ∪{x} →A is obtained from s as follows:
s(a/x)(y) :=

a
if y = x,
s(y)
otherwise.
For an assignment s and a tuple of variables x = (x1, . . . , xn), we write s(x)
to denote the sequence

s(x1), . . . , s(xn)

. A team is a set of assignments with a

Polyteam Semantics
193
common domain D and codomain A. Let A be a τ-structure and X a team with
codomain A, then we say that X is a team of A.
The following dependency atoms were introduced in [6,9,24].
Deﬁnition 1 (Dependency atoms). Let A be a model and X a team with
codomain A. If x, y are variable sequences, then = (x, y) is a dependence atom
with the truth condition:
A |=X=(x, y) if for all s, s′ ∈X s.t. s(x) = s′(x), it holds that s(y) = s′(y).
If x, y are variable sequences of the same length, then x ⊆y is an inclusion
atom and x | y an exclusion atom with satisfaction deﬁned as follows:
A |=X x ⊆y if for all s ∈X there exists s′ ∈X such that s(x) = s′(y).
A |=X x | y if for all s, s′ ∈X : s(x) ̸= s′(y).
If x, y, z are variable sequences, then y ⊥x z is a conditional independence atom
with satisfaction deﬁned by
A |=X y ⊥x z if for all s, s′ ∈X such that s(x) = s′(x) there exists s′′ ∈X
such that s′′(x) = s(x), s′′(y) = s(y), and s′′(z) = s′(z).
Note that in the previous deﬁnitions it is allowed that some or all of the
vectors of variables have length 0. For example, A |=X= (x) holds iﬀ∀s ∈X :
s(x) = c holds for some ﬁxed tuple c, and A |=X y ⊥x z holds always if either
of the vectors y or z is of length 0.
All the aforementioned dependency atoms have corresponding variants in
relational databases. One eﬀect of this relationship is that the axiomatic proper-
ties of these dependency atoms trace back to well-known results in database the-
ory. Armstrong’s axioms for functional dependencies constitute a ﬁnite axioma-
tisation for dependence atoms [1,9], and inclusion atoms can be ﬁnitely axioma-
tised using the axiomatisation for inclusion dependencies [2]. On the other hand,
the non-axiomatisability and undecidability of the (ﬁnite and unrestricted) impli-
cation problem for embedded multivalued dependencies both carry over to con-
ditional independence atoms [14,22,23]. Restricting attention to the so-called
pure independence atoms, i.e., atoms of the form x ⊥∅y, a ﬁnite axiomatisation
is obtained by relating to marginal independence in statistics [8,18].
2.2
The Notion of Poly-dependence
For each i ∈N, let Var(i) denote a distinct countable set of ﬁrst-order variable
symbols. We say that these variables are of sort i. Relating to databases, sorts
correspond to table names. Usually we set Var(i) = {xi
j | j ∈N}. We write xi,
yi, xi
j to denote variables form Var(i), and xi to denote tuples of variables from
Var(i). Sometimes we drop the index i and write simply x and x instead of xi and
xi, respectively. Note that x is always a tuple of variables of a single sort. In order

194
M. Hannula et al.
to simplify notation, we sometimes write xi and xj to denote arbitrary tuples of
variables of sort i and j, respectively. We emphasise that xi and xj might be of
diﬀerent length and may consist of distinct variables. Let A be a τ-model and let
Di ⊆Var(i) for all i ∈N. A tuple X = (Xi)i∈N is a polyteam of A with domain
D = (Di)i∈N, if Xi is a team with domain Di and co-domain A for each i ∈N.
We identify X with (X0, . . . , Xn) if Xi is the singleton team consisting with the
empty assignment for all i greater than n. Let X = (Xi)i∈N and Y = (Yi)i∈N be
two polyteams. We say that X is a subteam of Y if Xi ⊆Yi for all i ∈N. By
the union (resp. intersection) of X and Y we denote the polyteam (Xi ∪Yi)i∈N
(resp. (Xi ∩Yi)i∈N). By a slight abuse of notation we write X ∪Y (resp. X ∩Y )
for the union (resp. intersection) of X and Y , and X ⊆Y to denote that X is
a subteam of Y . For a tuple V = (Vi)i∈N where Vi ⊆Var(i), the restriction of
X to V , written X ↾V , is deﬁned as (Xi ↾Vi)i∈N where Xi ↾Vi denotes the
restriction of Xi to Vi.
Next we generalise dependence atoms to the polyteam setting. In contrast
to the standard dependence atoms, poly-dependence atoms declare functional
dependence of variables over two teams.
Poly-dependence. Let xiyi and ujvj be sequences of variables such that xi
and uj, and yi and uj have the same length, respectively. Then =

xi, yi/uj, vj
is a poly-dependence atom whose satisfaction relation |=X is deﬁned as follows:
A |=X=

xi, yi/uj, vj
⇔∀s ∈Xi∀s′ ∈Xj : s(xi) = s′(uj) implies s(yi) = s′(vj).
Note that the atom = (x, y/x, y) corresponds to the dependence atom = (x, y).
For empty tuples xi and uj the poly-dependence atom reduces to a “poly-
constancy atom” =

yi/vj
. We will later show (Remark 13) that poly-
dependence atoms of the form =

xi, yi/ui, vi
can be expressed with formulae
using only ordinary dependence atoms. Thus poly-dependence atoms of this
form are considered as primitive notions only when xiyi = uivi; otherwise
=

xi, yi/ui, vi
is considered as a shorthand for the equivalent formula obtained
from Remark 13.
The ability to reason about database dependencies can be employed to facili-
tate many critical data management tasks such as schema design, query optimi-
sation, and integrity maintenance. Keys, inclusion dependencies, and functional
dependencies in particular have a crucial role in all of these processes. A tradi-
tional way to approach the interaction between dependencies has been the utili-
sation of proof systems similar to natural deduction systems in logic. The most
signiﬁcant of all these systems is the Armstrong’s axiomatisation for functional
dependencies. This inference system consists of only three rules which we depict
below using the standard notation for functional dependencies, i.e., X →Y
denotes that an attribute set X functionally determines another attribute set Y .
Deﬁnition 2 (Armstrong’s axiomatisation [1])
– Reﬂexivity: If Y ⊆X, then X →Y
– Augmentation: if X →Y , then XZ →Y Z
– Transitivity: if X →Y and Y →Z, then X →Z

Polyteam Semantics
195
Our ﬁrst development is the generalisation of Armstrong’s axiomatisation to
the poly-dependence setting. To this end, we assemble the three rules of Arm-
strong and introduce three auxiliary rules: Union, Symmetry, and Weak Tran-
sitivity. Contrary to the Armstrong’s proof system, here Union is not reducible
to Transitivity and Augmentation because we operate with sequences instead of
sets of variables or attributes. Symmetry in turn is imposed by the sequential
notation employed by the poly-dependence atom. Weak Transitivity exhibits
transitivity of equalities on the right-hand side of a poly-dependence atom, a
phenomenon that arises only in the polyteam setting.
Deﬁnition 3 (Axiomatisation for poly-dependence atoms)
– Reﬂexivity: =

xi, prk(xi)/yj, prk(yj)

, where k = 1, . . . , |xi| and prk takes
the kth projection of a sequence.
– Augmentation: if =

xi, yi/uj, vj
, then =

xizi, yizi/ujwj, vjwj
– Transitivity: if =

xi, yi/uj, vj
and =

yi, zi/vj, wj
, then =

xi, zi/uj, wj
– Union: if =

xi, yi/uj, vj
and =

xi, zi/uj, wj
then =

xi, yizi/uj, vjwj
– Symmetry: if =

xi, yi/uj, vj
, then =

uj, vj/xi, yi
– Weak Transitivity: if =

xi, yizizi/uj, vjvjwj
, then =

xi, yi/uj, wj
This proof system forms a complete characterisation of logical implication for
poly-dependence atoms. We use |= to refer to logical implication, i.e., we write
Σ |= σ if A |=X Σ implies A |=X σ for all models A and polyteams X. Given an
axiomatisation R, that is, a set of axioms and inference rules, we write Σ ⊢R σ
if R yields a proof of σ from Σ. Given a class of dependency atoms C, we then
say that R is sound (complete, resp.) for C if for all ﬁnite sets of dependency
atoms Σ ∪{σ} from C, Σ ⊢R σ implies (is implied by, resp.) Σ |= σ.
Theorem 4. The axiomatisation of Deﬁnition 3 is sound and complete for poly-
dependence atoms.
Proof. The proof of soundness is straightforward and omitted. We show that the
axiomatisation is complete, i.e., that Σ |= σ implies Σ ⊢σ for a set Σ ∪{σ} of
poly-dependence atoms. Assume σ is =

xi, yi/xj, yj
. First we consider the case
where i = j in which case σ is a standard dependence atom. Let Σ∗be the subset
of Σ consisting of all standard dependence atoms over Var(i). Since all teams
satisfying Σ∗can be extended to a polyteam satisfying Σ by introducing new
empty teams, we have that Σ∗|= σ in the team semantics setting. Since depen-
dence atoms = (x, y) in team semantics correspond to functional dependencies
{x ∈xi} →{y ∈yi} in relational databases (see e.g. [9]), Armstrong’s com-
plete axiomatisation from Deﬁnition 2 yields a deduction of σ0 from Σ∗
0 where
Σ∗
0 and {σ0} are obtained from Σ∗and σ by replacing dependence atoms with
their corresponding functional dependencies. Since dependence atoms are prov-
ably order-independent (i.e. one derives =(x0, x1) from =(y0, y1) by Reﬂexivity,
Union, and Transitivity if xi and yi list the same variables), the deduction in
Armstrong’s system can be simulated with the rules in Deﬁnition 3. This proves
the case i = j.

196
M. Hannula et al.
Let us then consider the case i ̸= j. We will show that Σ ̸⊢σ implies Σ ̸|= σ.
Assume Σ ̸⊢σ. Deﬁne ﬁrst a binary relation ∼on Var(i) ∪Var(j) such that
ai ∼aj if Σ ⊢=

xi, ai/xj, aj
, aj ∼ai if Σ ⊢=

xj, aj/xi, ai
, and ai ∼bi
(aj ∼bj, resp.) if ai = bi or Σ ⊢=

xi, aibi/xj, ajaj
for some aj (aj = bj or
Σ ⊢=

xj, ajbj/xi, aiai
for some ai, resp.). We show that ∼is an equivalence
relation.
– Reﬂexivity: Holds by deﬁnition.
– Symmetry: First note that ai ∼aj and aj ∼ai are derivably equiv-
alent by the symmetry rule. Assume that ai
∼
bi in which case =

xi, aibi/xj, ajaj
is derivable for some aj. Then derive =

aibi, bi/ajaj, aj
and =

aibi, ai/ajaj, aj
by using the reﬂexivity rule, and then =

xi, bi/xj, aj
and =

xi, ai/xj, aj
by using the transitivity rule. Finally
derive =

xi, biai/xj, ajaj
by using the union rule.
– Transitivity: Assume ﬁrst that ai ∼bi ∼ci, where ai, bi, ci and are pair-
wise distinct. Then =

xi, aibi/xj, ajaj
and =

xi, bici/xj, bjbj
are deriv-
able for some aj and bj. Then analogously to the previous case assemble
=

xi, aibibi/xj, ajajbj
which admits =

xi, ai/xj, bj
by weak transitivity,
and detach =

xi, ci/xj, bj
from =

xi, bici/xj, bjbj
. By the union rule we
then obtain =

xi, aici/xj, bjbj
and thus that ai ∼ci. Since all the other
cases are analogous, we observe that ∼is transitive.
Let s be a function that maps each x ∈Var(i)∪Var(j) that appears in Σ∪{σ}
to the equivalence class x/ ∼. We deﬁne X = (Xi, Xj) where Xk = {s ↾Var(k)}
for k = i, j. First notice that X ̸|=
σ for, by union, it cannot be the case
that prk(yi) ∼prk(yj) for all k = 1, . . . , |yi|. It suﬃces to show that X satisﬁes
each =(um, vm/un, vn) in Σ. If m = n or {m, n} ̸= {i, j}, the atom is trivially
satisﬁed. Hence, and by symmetry, we may assume that the atom is of the form
=

ui, vi/uj, vj
. Assume that s(ui) = s(uj), that is, prk(ui) ∼prk(uj) for all k =
1, . . . , |ui|. We obtain by the union rule that =

xi, ui/xj, uj
is derivable, and
hence by the transitivity rule that =

xi, vi/xj, vj
is also derivable. Therefore,
by using the reﬂexivity and transitivity rules we conclude that s(vi) = s(vj). ⊓⊔
2.3
A General Notion of a Poly-dependency
Next we consider suitable polyteam generalisations for the dependencies dis-
cussed in Sect. 2.1 and also deﬁne a general notion of poly-dependency. This gen-
eralisation is immediate for inclusion atoms which are inherently multi-relational;
relational database management systems maintain referential integrity by enforc-
ing inclusion dependencies speciﬁcally between two distinct tables. With poly-
inclusion atoms these multi-relational features can now be captured.

Polyteam Semantics
197
Poly-inclusion. Let xi and yj be sequences of variables of the same length.
Then xi ⊆yj is a poly-inclusion atom whose satisfaction relation |=X is deﬁned
as follows:
A |=X xi ⊆yj ⇔∀s ∈Xi∃s′ ∈Xj : s(xi) = s′(yj).
If i = j, then the atom is the standard inclusion atom.
Poly-exclusion. Let xi and yj be sequences of variables of the same length.
Then xi | yj is a poly-exclusion atom whose satisfaction relation |=X is deﬁned
as follows:
A |=X xi | yj ⇔∀s ∈Xi, s′ ∈Xj : s(xi) ̸= s′(yj).
If i = j, then the atom is the standard exclusion atom.
Poly-independence. Let xi, yi, aj,b
j, uk, vk, and wk be tuples of variables
such that |xi| = |aj| = |uk|, |yi| = |vk|, |b
j| = |wk|. Then yi/vk ⊥xi,aj/uk b
j/wk
is a poly-independence atom whose satisfaction relation |=X is deﬁned as follows:
A |=X yi/vk ⊥xi,aj/uk b
j/wk ⇔∀s ∈Xi, s′ ∈Xj : s(xi) = s′(aj) implies
∃s′′ ∈Xk : s′′(ukvk) = s(xiyi) and s′′(wk) = s′(b
j).
The atom y/y ⊥x,x/x z/z, where all variables are of the same sort, corresponds to
the standard independence atom y ⊥x z. Furthermore, a pure poly-independence
atom is an atom of the form yi/vk ⊥∅,∅/∅b
j/wk, written using a shorthand
yi/vk ⊥b
j/wk.
Poly-independence atoms are closely related to equi-join operators of rela-
tional databases as the next example exempliﬁes.
Example 5. A relational database schema
P(rojects) = {project,team},
T(eams) = {team,employee},
E(mployees) = {employee,team,project},
stores information about distribution of employees for teams and projects in a
workplace. The poly-independence atom
P[project]/E[project] ⊥P[team],T[team]/E[team] T[employee]/E[employee]
(1)
expresses that the relation Employees includes as a subrelation the natural join
of Projects and Teams. If furthermore E[project,team] ⊆P[project,team]
and E[team,employee] ⊆T[team,employee] hold, then Employees is exactly
this natural join.
In addition to the poly-atoms described above we deﬁne a notion of a gener-
alised poly-atom, similarly to the notion of generalised atom of [21].
Generalised poly-atoms. Let (j1, . . . , jn) be a sequence of positive integers. A
generalised quantiﬁer of type (j1, . . . , jn) is a collection Q of relational structures

198
M. Hannula et al.
(A, R1, . . . , Rn) (where each Ri is ji-ary) that is closed under isomorphisms.
Then, for any sequence (x1, . . . , xn) where xi is a length ji tuple of variables
from some Var(li), AQ(x1, . . . , xn) is a generalised poly-atom of type (j1, . . . , jn).
For a model A and polyteam X where xi ⊆Dom(Xli), the satisfaction relation
with respect to AQ is deﬁned as follows:
A |=X AQ(x1, . . . , xn)
⇔

Dom(A), R1 := rel(Xl1, x1) . . . , Rn := rel(Xln, xn)

∈Q.
By rel(X, x), for x = (x1, . . . , xm), we denote the relation {(s(x1), . . . , s(xm)) |
s ∈X}. A poly-atom AQ(x1, . . . , xn) is a uni-atom if the variable sequences
x1, . . . , xn are of a single sort. Uni-atoms correspond exactly to generalised atoms
of [21]. We say that the atom AQ(x1, . . . , xn) is deﬁnable in a logic L if the
class Q is deﬁnable in L. For instance, we notice that a poly-inclusion atom
(x1, y1) ⊆(u2, v2) is a ﬁrst-order deﬁnable generalised poly-atom of type (2, 2).
2.4
Database Dependencies as Poly-atoms
Embedded dependencies in a multi-relational context can now be studied with
the help of generalised poly-atoms and polyteam semantics. Conversely, strong
results obtained in the study of database dependencies can be transferred and
generalised for stronger results in the polyteam setting. In particular, each
embedded dependency can be seen as a deﬁning formula for a generalised poly-
atom, and hence the classiﬁcation of embedded dependencies naturally yield a
corresponding classiﬁcation of generalised poly-atoms. For example, the class
C := {AQ(x1, . . . , xn) | Q is deﬁnable by an FO(R1, . . . , Rn)-sentence in
the class of equality-generating dependencies}
is the class of equality-generating poly-atoms. The deﬁning formula of the gen-
eralised atom of type (2, 2) that captures the poly-dependence atom of type
=

xi, yi/uj, vj
is
∀x1∀x2∀y1∀y2

(R1(x1, x2) ∧R2(y1, y2) ∧x1 = y1) →x2 = y2

.
Thus poly-dependence atoms are included in the class of equality-generating
poly-atoms.
In order to study data exchange in the polyteam setting, we ﬁrst need to
deﬁne the notions of source-to-target and target poly-atoms. This classiﬁcation
of poly-atoms requires some more care as it is not enough to consider the deﬁn-
ing formulae of the corresponding atoms, but also the variables that the atom
is instantiated with. We will return to this topic brieﬂy after we have given
semantics for logics that work on polyteams.

Polyteam Semantics
199
3
Polyteam Semantics for Complex Formulae
We next delineate a version of team semantics suitable for the polyteam context.
We note here that it is not a priori clear what sort of modiﬁcations for connectives
and quantiﬁers one should entertain when shifting from teams to the polyteam
setting.
3.1
Syntax and Semantics
Deﬁnition 6. Let τ be a set of relation symbols. The syntax of poly ﬁrst-order
logic PFO(τ) is given by the following grammar rules:
φ ::= x = y | x ̸= y | R(x) | ¬R(x) | (φ ∧φ) | (φ ∨φ) | (φ ∨j φ) | ∃xφ | ∀xφ,
where R ∈τ is a k-ary relation symbol, j ∈N, x ⊆Var(i)k and x, y ∈Var(i)
for some i, k ∈N.
We say that ∨is a global disjunction whereas ∨i is a local disjunction. Note that
in the deﬁnition the scope of negation is restricted to atomic formulae. Note also
that the restriction of PFO(τ) to formulae without the connective ∨j and using
only variables of a single ﬁxed sort is FO(τ).
For the deﬁnition of the polyteam semantics of PFO, recall the deﬁnitions
of teams and polyteams from Sects. 2.1 and 2.2, respectively. Let X be a team,
A a ﬁnite set, and F : X →P(A) \ {∅} a function. We denote by X[A/x] the
modiﬁed team {s(a/x) | s ∈X, a ∈A}, and by X[F/x] the team {s(a/x) | s ∈
X, a ∈F(s)}. Again note that if restricted to the above fragment of PFO(τ) the
polyteam semantics below coincides with traditional team semantics, see e.g.
[4] for a deﬁnition. Thus for FO(τ) formulae we may write A |=Xi φ instead of
A |=(Xi) φ.
Deﬁnition 7 (Lax polyteam semantics). Let A be a τ-structure and X a
polyteam of A. The satisfaction relation |=X for poly ﬁrst-order logic is deﬁned
as follows:
A |=X x = y
⇔if x, y ∈Var(i) then ∀s ∈Xi : s(x) = s(y)
A |=X x ̸= y
⇔if x, y ∈Var(i) then ∀s ∈Xi : s(x) ̸= s(y)
A |=X R(x)
⇔if x ∈Var(i)k then ∀s ∈Xi : s(x) ∈RA
A |=X ¬R(x)
⇔if x ∈Var(i)k then ∀s ∈Xi : s(x) ̸∈RA
A |=X (ψ ∧θ) ⇔A |=X ψ and A |=X θ
A |=X (ψ ∨θ) ⇔A |=Y ψ and A |=Z θ for some Y , Z ⊆X s.t. Y ∪Z = X
A |=X (ψ ∨j θ)⇔A |=X[Yj/Xj] ψ and A |=X[Zj/Xj] θ,
for some Yj, Zj ⊆Xj s.t. Yj ∪Zj = Xj
A |=X ∀xψ
⇔A |=X[Xi[A/x]/Xi] ψ, when x ∈Var(i)
A |=X ∃xψ
⇔A |=X[Xi[F/x]/Xi ψ holds for some F : Xi →P(A) \ {∅},
when x ∈Var(i)

200
M. Hannula et al.
The truth of a sentence φ (i.e., a formula with no free variables) in a model A
is deﬁned as: A |= φ if A |=({∅}) φ, where ({∅}) denotes the polyteam consisting
only singleton teams of the empty assignment. We write Fr(φ) for the set of free
variables in φ, and Fri(φ) for Fr(φ) ∩Var(i).
Polyteam semantics is a conservative extension of team semantics in the same
fashion as teams semantics is a conservative extension of Tarski semantics [24].
Proposition 8. Let φ ∈FO(τ) whose variables are all of sort i ∈N. Let A be
a τ-structure and X a polyteam of A. Then A |=X φ ⇔A |=Xi φ ⇔∀s ∈Xi :
A |=s φ, where |=s denotes the ordinary satisfaction relation of ﬁrst-order logic.
Example 9. A relational database schema
Patient ={patient id,patient name},
Case ={case id,patient id,diagnosis id,confirmation},
Test ={diagnosis id,test id},
Results ={patient id,test id,result}
stores information about patient cases and their related laboratory tests. In
order to maintain consistency of the stored data, database management sys-
tems support the use of integrity constraints that are based on functional
and inclusion dependencies. For instance, on relation schema Patient the key
patient id (i.e. the dependence atom = (patient id,patient name)) ensures
that no patient id can refer to two diﬀerent patient names. On Case the foreign
key patient id referring to patient id on Patient (i.e. the inclusion atom
Case[patient id] ⊆Patient[patient id]) enforces that patient ids on Case
refer to real patients. The introduction of poly-dependence logics opens up pos-
sibilities for more expressive data constraints. The poly-inclusion formula
φ0 =confirmation ̸= positive ∨Case ∃x1x2

x1 ̸= x2∧

i=1,2
(Case[diagnosis id, xi] ⊆Test[diagnosis id,test id]∧
Case[patient id, xi, positive] ⊆Results[patient id,test id,result])

ensures that a diagnosis may be conﬁrmed only if it has been aﬃrmed by two
diﬀerent appropriate tests. The poly-exclusion formula
φ1 =confirmation ̸= negative ∨Case
∀x

Case[diagnosis id, x] | Test[diagnosis id,test id]∨Case
Case[patient id, x, positive] | Results[patient id,test id,result]

makes sure that a diagnosis may obtain a negative conﬁrmation only if it has
no positive indication by any suitable test. Note that both formulae employ
local disjunction and quantiﬁed variables that refer to Case. Interestingly, the
illustrated expressive gain is still computationally feasible as both φ0 and φ1
can be enforced in polynomial time. For φ0 note that the data complexity of
inclusion logic is in PTIME [7]; for φ1 observe that satisfaction of a formula of
the form x1 | y2 ∨1 x1 | z3 can be decided in PTIME as well.

Polyteam Semantics
201
Poly-dependence logics. Poly-dependence, poly-independence, poly-inclusion,
and poly-exclusion logics (PFO(pdep), PFO(pind), PFO(pinc), and PFO(pexc),
resp.) are obtained by extending PFO with poly-dependence, poly-independence,
poly-inclusion, and poly-exclusion atoms, respectively. In general, given a set of
atoms C we denote by PFO(C) the logic obtained by extending PFO with the
atoms of C. We also consider poly-atoms in the team semantics setting; by FO(C)
we denote the extension of ﬁrst-order logic by the poly-atoms in C. Similarly, it is
also possible to consider atoms of Sect. 2.1 in the polyteam setting by requiring
that the variables used with each atom are of a single sort.
3.2
Basic Properties
We say that a formula φ is local in polyteam semantics if for all V = (Vi)i∈N
where Fri(φ) ⊆Vi for i ∈N, and all models A and polyteams X, we have
A |=X φ ⇔A |=X↾V φ.
In other words, the truth value of a local formula depends only on its free vari-
ables. Furthermore, a logic L is called local if all its formulae are local.
Proposition 10 (Locality). For any set C of generalised poly-atoms PFO(C)
is local.
Furthermore, the downward closure of dependence logic as well as the union
closure of inclusion logic generalise to polyteams.
Proposition 11 (Downward Closure and Union Closure). Let φ be a for-
mula of PFO(pdep), ψ a formula of PFO(pinc), A a model, and X, Y two poly-
teams. Then A |=X φ and Y ⊆X implies that A |=Y φ, and A |=X ψ and
A |=Y ψ implies that A |=X∪Y ψ.
The following proposition shows that the substitution of independence
(dependence) atoms for any (downwards closed) class of atoms deﬁnable in exis-
tential second-order logic (ESO) results in no expressive gain.
Proposition 12. Let C (D, resp.) be the class of all (all downward closed, resp.)
ESO-deﬁnable poly-atoms. The following equivalences of logics hold: FO(C) ≡
FO(ind), FO(D) ≡FO(dep), and FO(pinc) ≡FO(inc).
Proof. The claim FO(pinc) ≡FO(inc) follows directly from the observation that
in the team semantics setting poly-inclusion atoms are exactly inclusion atoms.
Note that FO(ind) (FO(dep), resp.) captures all (all downward closed, resp.)
ESO-deﬁnable properties of teams (see Theorem 18). It is easy to show (cf. [17,
Theorem 6]) that every property of teams deﬁnable in FO(C) (FO(D), resp.) is
ESO-deﬁnable (ESO-deﬁnable and downward closed, resp.). Thus since ind ∈C
and dep ∈D, we obtain that FO(C) ≡FO(ind) and FO(D) ≡FO(dep).
⊓⊔

202
M. Hannula et al.
Remark 13. In particular it follows from the previous proposition that, in the
polyteam setting, each occurrence of any (any downward closed, resp.) ESO-
deﬁnable poly-atom that takes variables of a single sort as parameters may be
equivalently expressed by a formula of PFO(ind) (PFO(dep), resp.) that only
uses variables of the same single sort.
We end this section by considering the relationship of global and local dis-
junctions. In particular, we observe that by the introduction of local disjunction
its global variant becomes redundant. To facilitate our construction we here
allow the use of ∨I, where I is a set on indices, with obvious semantics. We then
show that ∨can be replaced by ∨I and ∨I by ∨i.
Proposition 14. For every formula of PFO there exists an equivalent formula
of PFO that only uses disjunctions of type ∨i.
Proof. Let φ be a formula of PFO and let I list the sorts of all the variables
that occur in φ. Let φ∗denote the formula obtained from φ by substituting all
occurrences of ∨by ∨I. It is a direct consequence of the locality property that
φ and φ∗are equivalent.
We will next show how to eliminate disjunctions of type ∨I from φ∗. Let
φ0 ∨I φ1 be a formula of PFO and let I = {i1, . . . , in}. Deﬁne
ψ := ∃zi1
0 ∃zi1
1 . . . ∃zin
0 ∃zin
1 (θ0 ∧θ1),
where zi1
0 , zi1
1 , . . . , zin
0 , zin
1
are fresh and distinct variables, and
θ0 := (zi1
0 = zi1
1 ∨i1 (zi1
0 ̸= zi1
1 ∧(zi2
0 = zi2
1 ∨i2 (zi2
0 ̸= zi2
1
∧(. . . ∧(zin
0 = zin
1 ∨in (zin
0 ̸= zin
1 ∧φ0) . . .),
θ1 := (zi1
0 ̸= zi1
1 ∨i1 (zi1
0 = zi1
1 ∧(zi2
0 ̸= zi2
1 ∨i2 (zi2
0 = zi2
1
∧(. . . ∧(zin
0 ̸= zin
1 ∨in (zin
0 = zin
1 ∧φ1) . . .).
The idea above is that the variables zij
0 , zij
1 are used to encode a split of the
team Xj. Using locality it is easy to see that (φ0 ∨I φ1) and ψ are equivalent
over structures of cardinality at least two. From this the claim follows in a
straightforward manner.
⊓⊔
3.3
Data Exchange in the Polyteam Setting
As promised, we now return to the topic of modelling data exchange in our
new setting. In this section we restrict our attention to poly-atoms that are
embedded dependencies. Our ﬁrst goal is to deﬁne the notions of source-to-target
and target poly-atoms. For this purpose we deﬁne a normal form for embedded
dependencies. We call an embedded dependency ∀x

φ(x) →∃yψ(x, y)

sepa-
rated if the relation symbols that occur in φ and ψ are distinct. A poly-atom
is called separated, if the deﬁning formula is a separated embedded dependency.

Polyteam Semantics
203
In the polyteam setting this is just a technical restriction as non-separated poly-
atoms can be always simulated by separated ones. Below we use the syntax
A(x1, . . . , xl, y1, . . . , yk) for separated poly-atoms. The idea is that xis project
extensions for relations used in the antecedent and yjs in the consequent of the
deﬁning formula.
Let S and T be a set of source relations and target relations from some data
exchange instance, respectively. Let X = (S1, . . . Sn, T1, . . . , Tm) be a polyteam
that encodes S and T in the obvious manner. We say that an instance of a
separated atom A(x1, . . . , xl, y1, . . . , yk) is source-to-target if each xi is a tuple
of variables of the sort of Sj, for some j, and each yi is a tuple of variables of
the sort of Tj, for some j. Analogously the instance A(x1, . . . , xl, y1, . . . , yk) is
target if each xi and yj is a tuple of variables of the sort of Tp for some p.
Data exchange problems can now be directly studied in the polyteam setting.
For example the existence-of-solution problem can be reduced to a model check-
ing problem by using ﬁrst-order quantiﬁers to guess a solution for the problem
while the rest of the formula describes the dependences required to be fulﬁlled
in the data exchange problem.
Example 15. A relational database schemas
S :
P(rojects) = {name, employee, employee position},
T :
E(mployees) = {name, project 1, project 2}
are used to store information about employees positions in diﬀerent projects.
We wish to check whether for a given instance of the schema S there exists an
instance of the schema T that does not lose any information about for which
projects employees are tasked to work and that uses the attribute name as a key.
The PFO(pinc, dep)-formula
φ := ∃x1∃x2∃x3

P[employee, name] ⊆E[x1, x2]
∨P P[employee, name] ⊆E[x1, x3]

∧=(x1, (x2, x3))

,
when evaluated on a polyteam that encodes an instance of the schema S,
expresses that a solution for the data exchange problem exists. The variables x1,
x2 and x3 above are of the sort E and are used to encode attribute names name,
project 1 and project 2, respectively. The dependence atom above enforces
that the attribute name is a key.
4
Expressiveness
The expressiveness properties of dependence, independence, inclusion, and exclu-
sion logic and their fragments enjoy already comprehensive classiﬁcations.
Dependence logic and exclusion logic are equi-expressive and capture all down-
ward closed ESO properties of teams [6,19]. Independence logic, whose indepen-
dence atoms violate downward closure, in turn captures all ESO team properties

204
M. Hannula et al.
[6]. On the other hand, the expressivity of inclusion logic has been characterised
by the so-called greatest ﬁxed point logic [7]. In this section we turn attention
to polyteams and consider the expressivity of the poly-dependence logics intro-
duced in this paper. Section 4.1 deals with logics with only uni-dependencies
whereas in Sect. 4.2 poly-dependencies are considered.
4.1
Uni-dependencies in Polyteam Semantics
The following theorem displays how polyteam semantics over logics with only
uni-atoms collapses to standard team semantics.
Theorem 16. Let C be a set of uni-atoms. Each formula φ(x1, . . . , xn) ∈
PFO(C) can be associated with a sequence of formulae ψ1(x1), . . . , ψn(xn) ∈
FO(C) such that for all X = (X1, . . . , Xn), where Xi is a team with domain
xi,
M |=X φ(x1, . . . , xn) ⇔∀i = 1, . . . , n : M |=Xi ψi(xi).
Similarly, the statement holds vice versa.
Proof. The latter statement is clear as it suﬃces to set φ(x1, . . . , xn) := ψ1(x1)∧
. . .∧ψn(xn). For the other direction, we deﬁne recursively functions fi that map
formulae φ(x1, . . . , xn) ∈PFO(C) to formulae ψi(xi) ∈FO(C). By Proposition
14 we may assume that only disjunctions of type ∨i, for some i ∈N, may occur
in φ. The functions fi are deﬁned as follows:
– If φ(xj) is an atom, then fi(φ) =

φ
if i = j,
⊤
otherwise.
– fi(ψ ∨j θ) =

fi(ψ) ∨fi(θ)
if i = j,
fi(ψ) ∧fi(θ)
otherwise.
– fi(ψ ∧θ) = fi(ψ) ∧fi(θ).
– For Q ∈{∃, ∀}, if fi(Qxjψ) =

Qxfi(ψ)
if i = j,
fi(ψ)
otherwise.
We set ψi := fi(φ) and show the claim by induction on the structure of the
formula. The cases for atoms and conjunctions are trivial. We show the case for
∨i.
Let φ = ψ ∨j θ and assume that the claim holds for ψ and θ. Now
A |=X φ
iﬀ
A |=X[Yj/Xj] ψ and A |=X[Zj/Xj] θ,
for some Yj, Zj ⊆Xj such that Yj ∪Zj = Xj.
By the induction hypothesis, A |=X[Yj/Xj] ψ and A |=X[Zj/Xj] θ iﬀA |=Yj fj(ψ),
A |=Zj fj(θ), and A |=Xi fi(ψ), A |=Xi fi(θ) for each i ̸= j. Thus we obtain that
A |=X φ holds iﬀ
A |=Xj fj(ψ) ∨fj(θ), and A |=Xi fi(ψ) and A |=Xi fi(θ) for each i ̸= j.

Polyteam Semantics
205
The above can be rewritten as
A |=Xj fj(ψ) ∨fj(θ), and A |=Xi fi(ψ) ∧fi(θ) for each i ̸= j.
The claim now follows, since fj(ψ) ∨fj(θ) = fj(ψ ∨j θ) and fi(ψ) ∧fi(θ) =
fi(ψ ∨j θ), for i ̸= j.
The cases for the quantiﬁers are similar.
This theorem implies that poly-atoms which describe relations between two
teams are beyond the scope of uni-logics. The following proposition illustrates
this for PFO(dep).
Proposition 17. The poly-constancy atom =

x1/x2
cannot be expressed in
PFO(dep).
Proof. Assume that =

x1/x2
can be deﬁned by some φ(x1, x2) ∈PFO(dep).
By Theorem 16 there are FO(dep)-formulae ψ1(x1) and ψ2(x2) such that for all
X = (X1, X2), where Xi is a team with domain xi, it holds that
M |=X=

x1/x2
⇔∀i = 1, 2 : M |=Xi ψi(xi).
(2)
Deﬁne teams X1 := {x1 →0}, X2 := {x2 →0}, Y1 := {x1 →1}, and Y2 :=
{x2 →1}. Now clearly M |=(X1,X2)=

x1/x2
, and M |=(Y1,Y2)=

x1/x2
. Hence
by (2), we obtain ﬁrst that M |=X1 ψi(x1) and M |=Y2 ψi(x2), and then that
M |=(X1,Y2)=

x1/x2
, which is a contradiction.
⊓⊔
Using Theorem 16 we may now compare and characterise the expressivity of
PFO(dep) and PFO(ind) in terms of existential second-order logic. To this end, let
us ﬁrst recall the ESO characterisations of open dependence and independence
logic formulae. Note that rel(X) refers to a relation {s(x1, . . . , xn) | s ∈X}
where x1, . . . , xn is some enumeration of Dom(X).
Theorem 18 ([6,19]). Let φ(x) be an independence logic (dependence logic,
resp.) formula, and let R be an |x|-ary relation. Then there is an (downward
closed with respect to R, resp.) ESO-sentence ψ(R) such that for all teams X ̸= ∅
where Dom(X) = x,
M |=X φ(x) ⇔(M, R := rel(X)) |= ψ(R)
The same statement holds also vice versa.
It is now easy to see that Theorems 16 and 18 together imply that PFO(dep)
captures all conjunctions of downward closed ESO properties of teams whereas
PFO(ind) captures all such properties.
Theorem 19. Let φ(x1, . . . , xn) be a PFO(ind) (PFO(dep), resp.) formula
where xi is a sequence of variables from Var(i). Let Ri be an |xi|-ary rela-
tion symbol for i = 1, . . . , n. Then there are (downward closed with respect
to Ri, resp.) ESO-sentences ψ1(R1), . . . , ψn(Rn) such that for all polyteams
X = (X1, . . . , Xn) where Dom(Xi) = xi and Xi ̸= ∅
M |=X φ(x1, . . . , xn)
⇔(M, R1 := rel(X1), . . . , Rn := rel(Xn)) |= ψ1(R1) ∧. . . ∧ψn(Rn).
The same statement holds also vice versa.

206
M. Hannula et al.
4.2
Poly-dependencies in Polyteam Semantics
Next we consider poly-dependencies in polyteam semantics.
Lemma 20. The following equivalences hold:
=

x1, y1/u2, v2
≡y1/y1 ⊥x1,u2/x1 v2/y1,
(3)
=

x1, y1/u2, v2
≡∀z1(y1 = z1 ∨1 x1z1 | u2v2),
(4)
x1 ⊆u2 ≡x1/u2 ⊥∅/∅,
(5)
x1 ⊆u2 ≡∀v2(x1 | v2 ∨2 v2 ⊆u2),
(6)
x1 | u2 ≡∃y1z1v2w2(=

x1, y1z1/u2, v2w2
(7)
∧y1 = z1 ∧v2 ̸= w2),
x1 | u2 ≡∃y1(u2 ⊆y1 ∧x1 | y1),
(8)
y2/y1 ⊥x2,x3/x1 z3/z1 ≡∀p2q2∃u2v2∀p3q3r3∃u3v3
(9)
=

p2q2, u2v2/p3q3, u3v3
∧

u2 = v2 ∨1 (u2 ̸= v2 ∧x2y2 | p2q2)

∧

u3 ̸= v3 ∨2 x3z3 | p3r3 ∨2 p3q3r3 ⊆x1y1z1
.
Proof. The equivalences (3)–(8) are straightforward and (9) is analogous to the
corresponding translation in the team semantics setting (see [6]).
⊓⊔
The following theorem compares the expressive powers of diﬀerent polyteam-
based logics. Observe that the expressivity of the logics with two poly-
dependency atoms remains the same even if either one of the atoms has the
standard team semantics interpretation.
Theorem 21. The following equivalences of logic hold:
(1) PFO(pdep) ≡PFO(pexc),
(2) PFO(pind) ≡PFO(pexc, inc) ≡PFO(pinc, exc) ≡PFO(pdep, inc)
≡PFO(pinc, dep) ≡PFO(pdep, ind) ≡PFO(pexc, ind) ≡PFO(pinc, ind).
Proof. Item (1) follows by Eqs. (4) and (7). Item (2) follows from the below list
of relationships:
– PFO(pind) ⊆PFO(pexc, inc) by (4), (6), and (9).
– PFO(pexc, inc) ≡PFO(pinc, exc) by (6) and (8).
– PFO(pexc, inc) ≡PFO(pdep, inc) by (4) and (7).
– PFO(pinc, exc) ≡PFO(pinc, dep), since exclusion (dependence, resp.) atoms
can be described in FO(dep) (FO(exc), resp.) [6].
– PFO(pdep, inc) ⊆PFO(pdep, ind), PFO(pexc, inc) ⊆PFO(pexc, ind), and
PFO(pinc, dep) ⊆PFO(pinc, ind) since inclusion atoms can be described in
FO(ind) [6] and dependence atoms by independence atoms [9].

Polyteam Semantics
207
– PFO(pdep, ind) ⊆PFO(ind), PFO(pexc, ind) ⊆PFO(ind), and PFO(pinc, ind)
⊆PFO(pind) by (3), (5), and (7).
⊓⊔
Next we show the analogue of Theorem 18 for polyteams.
Theorem 22. Let φ(R1, . . . , Rn) be an ESO-sentence. There is a PFO(pdep,
inc) formula φ∗(x1, . . . , xn), where |xi| = ar(Ri), such that for all polyteams
X = (X1, . . . , Xn) with Dom(Xi) = xi and Xi ̸= ∅,
M |=X φ∗(x1, . . . , xn) ⇔(M, R1 := rel(X1), . . . , Rn := rel(Xn)) |= φ(R1, . . . , Rn).
The statement holds also vice versa.
Proof. The direction from PFO(pdep, inc) to ESO is proven by a translation
similar to the one from dependence logic to ESO in [24]. We show only the
opposite direction. Analogously to [6], we can rewrite φ(R1, . . . , Rn) as
∃f∀u

n

i=1
(Ri(ui) ↔f2i−1(ui) = f2i(ui)) ∧ψ(u, f)

where f = f1, . . . , f2n, . . . , fm is a list of function variables, ψ is a quantiﬁer-free
formula in which no Ri appears, each ui is a subsequence of u, and each fi occurs
only as fi(uji) for some ﬁxed tuple uji of variables. For instance, ji = i/2 for
even i ≤2n.
Let b
i be sequences of variables of sort i such that |b
i| = |ui|, and let u1y1 be
a sequence of variables of sort 1 such that u1 is a copy of u and y1 = y1
1, . . . , y1
m.
We deﬁne φ∗(x1, . . . , xn) as the formula
∀b
1∃z1
0z1
1 . . . ∀b
n∃zn
0 zn
1 ∀u1∃y1
θ0 ∧θ1 ∧ψ′(u1, y1))
where
θ0 :=
n

i=1
=

b
i, zi
0

∧=

b
i, zi
1

∧((b
i ⊆xi ∧zi
0 = zi
1) ∨i (xi | b
i ∧zi
0 ̸= zi
1)),
θ1 :=
n

i=1
=

u1
i , y1
2i−1/b
i, zi
0

∧=

u1
i , y1
2i/b
i, zi
1

∧
m

i=n+1
=

u1
ji, y1
i

,
and ψ′(u1, y1) is obtained from ψ(u, f) by replacing u pointwise with u1 and
each fi(uji) with y1
i . Above, θ0 amounts to the description of the characteristic
functions f2i−1 and f2i. We refer the reader to [6] to check that M |=X θ0 iﬀfor
all i the functions s(b
i) →s(zi
0) and s(b
i) →s(zi
1) determined by the assignments
s ∈Xi agree on s(b
i) exactly when s(b
i) ∈rel(Xi). The poly-dependence atoms
in θ1 then transfer these functions over to the ﬁrst team, and the dependence
atoms in ψ1 describe the remaining functions. As in [6], it can now be seen that
φ∗correctly simulates φ. Since exclusion atoms can be expressed in dependence
logic, the claim then follows.
⊓⊔

208
M. Hannula et al.
By item (2) of Theorem 21 the result of Theorem 22 extends to a number of other
logics as well. For instance, we obtain that poly-independence logic captures all
ESO properties of polyteams. The proof of Theorem 22 can be now easily adapted
to show that poly-exclusion and poly-dependence logic capture all downward
closed ESO properties of polyteams.
Theorem 23. Let φ(R1, . . . , Rn) be an ESO-sentence that is downward closed
with respect to Ri. Then there is a PFO(pdep)-formula φ∗(x1, . . . , xn), where
|xi| = ar(Ri), such that for all polyteams X = (X1, . . . , Xn) with Dom(Xi) = xi
and Xi ̸= ∅,
M |=X φ∗(x1, . . . , xn) ⇔(M, R1 := rel(X1), . . . , Rn := rel(Xn)) |= φ(R1, . . . , Rn).
The statement holds also vice versa.
Proof. The direction from PFO(pdep) to ESO is again similar to the standard
translation of [24]. For the other direction, let φ(R1, . . . , Rn) be an ESO-sentence
in which the relations Ri appear only negatively. As in the proof of Theorem 22
and by downward closure we may transform it to an equivalent form (see [19]
for details)
∃f∀u

n

i=1
(¬Ri(ui) ∨f2i−1(ui) = f2i(ui)) ∧ψ(u, f)

Now the translation φ(x1, . . . , xn) is deﬁned analogously to the proof of Theorem
22 except for θ0 which is redeﬁned as
θ0 :=
n

i=1
=

b
i, zi
0

∧=

b
i, zi
1

∧(xi | b
i ∨i zi
0 = zi
1).
Finally the claim follows by eliminating the exclusion atoms from θ0.
5
Conclusion
In this article we have laid the foundations of polyteam semantics in order to
facilitate the fruitful exchange of ideas and results between team semantics and
database theory. Our results show that many of the familiar properties and
results from team semantics carry over to the polyteam setting. In particular, we
identiﬁed a natural polyteam analogue of dependence atoms and gave a complete
axiomatisation for the associated implication problem. It is an interesting task
to develop axiomatic characterisations for these new logics (cf. [10,20]). Another
interesting issue is to study the expressive power of various syntactic fragments
of logics over polyteams.

Polyteam Semantics
209
References
1. Armstrong, W.W.: Dependency structures of data base relationships. In: Proceed-
ings of IFIP World Computer Congress, pp. 580–583 (1974)
2. Casanova, M.A., Fagin, R., Papadimitriou, C.H.: Inclusion dependencies and their
interaction with functional dependencies. J. Comput. Syst. Sci. 28(1), 29–59 (1984)
3. Durand, A., Hannula, M., Kontinen, J., Meier, A., Virtema, J.: Approximation
and dependence via multiteam semantics. In: Gyssens, M., Simari, G. (eds.) FoIKS
2016. LNCS, vol. 9616, pp. 271–291. Springer, Cham (2016). https://doi.org/10.
1007/978-3-319-30024-5 15
4. Durand, A., Kontinen, J., Vollmer, H.: Expressivity and complexity of dependence
logic. In: Abramsky, S., Kontinen, J., V¨a¨an¨anen, J., Vollmer, H. (eds.) Dependence
Logic: Theory and Applications, pp. 5–32. Springer, Cham (2016). https://doi.org/
10.1007/978-3-319-31803-5 2
5. Fagin, R., Kolaitis, P.G., Miller, R.J., Popa, L.: Data exchange: semantics and
query answering. Theoret. Comput. Sci. 336(1), 89–124 (2005)
6. Galliani, P.: Inclusion and exclusion dependencies in team semantics: on some
logics of imperfect information. Ann. Pure Appl. Logic 163(1), 68–84 (2012)
7. Galliani, P., Hella, L.: Inclusion logic and ﬁxed point logic. In: Proceedings of CSL,
pp. 281–295 (2013)
8. Geiger, D., Paz, A., Pearl, J.: Axioms and algorithms for inferences involving prob-
abilistic independence. Inf. Comput. 91(1), 128–141 (1991)
9. Gr¨adel, E., V¨a¨an¨anen, J.A.: Dependence and independence. Studia Logica 101(2),
399–410 (2013)
10. Hannula, M.: Axiomatizing ﬁrst-order consequences in independence logic. Ann.
Pure Appl. Logic 166(1), 61–91 (2015)
11. Hannula, M.: Reasoning about embedded dependencies using inclusion dependen-
cies. In: Davis, M., Fehnker, A., McIver, A., Voronkov, A. (eds.) LPAR 2015.
LNCS, vol. 9450, pp. 16–30. Springer, Heidelberg (2015). https://doi.org/10.1007/
978-3-662-48899-7 2
12. Hannula, M., Kontinen, J.: A ﬁnite axiomatization of conditional independence
and inclusion dependencies. Inf. Comput. 249, 121–137 (2016)
13. Hannula, M., Kontinen, J., Link, S.: On the ﬁnite and general implication problems
of independence atoms and keys. J. Comput. Syst. Sci. 82(5), 856–877 (2016)
14. Herrmann, C.: On the undecidability of implications between embedded multival-
ued database dependencies. Inf. Comput. 122(2), 221–235 (1995)
15. Hodges, W.: Compositional semantics for a language of imperfect information. J.
Interest Group Pure Appl. Logics 5(4), 539–563 (1997)
16. Kanellakis, P.C.: Elements of relational database theory. In: Handbook of Theoreti-
cal Computer Science, Volume B: Formal Models and Sematics (B), pp. 1073–1156.
MIT Press, Cambridge (1990)
17. Kontinen, J., Kuusisto, A., Virtema, J.: Decidability of predicate logics with team
semantics. In: Proceedings of MFCS 2016, pp. 60:1–60:14 (2016)
18. Kontinen, J., Link, S., V¨a¨an¨anen, J.: Independence in database relations.
In: Libkin, L., Kohlenbach, U., de Queiroz, R. (eds.) WoLLIC 2013. LNCS,
vol. 8071, pp. 179–193. Springer, Heidelberg (2013). https://doi.org/10.1007/
978-3-642-39992-3 17
19. Kontinen, J., V¨a¨an¨anen, J.: On deﬁnability in dependence logic. J. Logic Lang.
Inf. 3(18), 317–332 (2009)

210
M. Hannula et al.
20. Kontinen, J., V¨a¨an¨anen, J.: Axiomatizing ﬁrst-order consequences in dependence
logic. Ann. Pure Appl. Logic 164(11), 1101–1117 (2013)
21. Kuusisto, A.: A double team semantics for generalized quantiﬁers. J. Logic Lang.
Inf. 24(2), 149–191 (2015)
22. Sagiv, Y., Walecka, S.F.: Subset dependencies and a completeness result for a
subclass of embedded multivalued dependencies. J. ACM 29(1), 103–117 (1982)
23. Parker Jr., D.S., Parsaye-Ghomi, K.: Inferences involving embedded multivalued
dependencies and transitive dependencies. In: Proceedings of the 1980 ACM SIG-
MOD International Conference on Management of Data, pp. 52–57 (1980)
24. V¨a¨an¨anen, J.: Dependence Logic. Cambridge University Press, New York (2007)
25. V¨a¨an¨anen, J.: The logic of approximate dependence. In: Ba¸skent, C., Moss, L.S.,
Ramanujam, R. (eds.) Rohit Parikh on Logic, Language and Society, vol. 11, pp.
227–234. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-47843-2 12

On the Sharpness and the Single-Conclusion
Property of Basic Justiﬁcation Models
Vladimir N. Krupski(B)
Faculty of Mechanics and Mathematics, Lomonosov Moscow State University,
Moscow 119992, Russia
krupski@lpcs.math.msu.su
Abstract. Justiﬁcation Awareness Models,
JAMs, were proposed by
S. Artemov as a tool for modelling epistemic scenarios like Russell’s
Prime Minister example. It was demonstrated that the sharpness and
the single-conclusion property of a model play essential role in the epis-
temic usage of JAMs. The problem to axiomatize these properties using
the propositional justiﬁcation language was left opened. We propose the
solution and deﬁne a decidable justiﬁcation logic Jref that is sound and
complete with respect to the class of all sharp single-conclusion justiﬁ-
cation models.
Keywords: Modal logic · Justiﬁcation logic
Justiﬁcation awareness models · Single-conclusion property
Sharpness property
1
Introduction
Justiﬁcation Awareness Models (JAM) were introduced in [3] (see also [4]) as
a ﬂexible tool for modelling epistemic scenarios like Russell’s Prime Minister
example.1 A JAM consists of a basic model for justiﬁcation logic J−(see [2]), sup-
plied with the means to distinguish acceptable (i.e. meaningful) and knowledge-
producing justiﬁcations.
In this paper we consider the ﬁrst component. It is referred in [3] as a basic
justiﬁcation model. The language of the model extends the usual propositional
language by new atoms, justiﬁcation assertions, of the form t : F with the
intended meaning “t is a justiﬁcation of F”. Justiﬁcations are terms built from
atomic ones by a binary operation · (application) that reﬂects logical reasonings
via Modus ponens rule, so the following property is assumed:
s:(F →G) →(t:F →[s·t]:G).
(1)
Justiﬁcation logic J−is the extension of the classical propositional logic by
Application axiom (1) and a basic justiﬁcation model (up to some details of
1 In [3] they were referred as JEMs, Justiﬁcation Epistemic Models. Later the termi-
nology was changed, see [4].
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 211–220, 2018.
https://doi.org/10.1007/978-3-319-72056-2_13

212
V. N. Krupski
the formulation, see Sect. 2.1) corresponds to a single world in the constructive
canonical model for J−. In such a model a justiﬁcation t denotes the set of
formulas justiﬁed by t and the justiﬁcation assertion t : F means that F is a
member of this set. The application · denotes a binary operation on sets of
formulas that satisfy the condition (1).
The epistemic usage of JAMs involves the detailed analysis of the term struc-
ture of a model. The following properties of a model, the sharpness and the
single-conclusion property, are pointed out in [3] as essential.
Sharpness. Consider a model with some true justiﬁcation assertion of the form
[s·t]:G. It is a claim that G follows by logical reasoning using Modus ponens rule
from some facts already justiﬁed by s and t respectively. One should treat it as
nonsense when there is no such facts. The sharpness condition eliminates this
possibility. It requires that application should be interpreted by the following
operation on sets of formulas:
S ▷T = {G | F →G ∈S and F ∈T for some F}.
So, in a sharp model the application means application of Modus ponens rule
and nothing more.
Single-conclusion justiﬁcations.2 A model is single-conclusion if for every jus-
tiﬁcation t there exists at most one formula that is justiﬁed by t. This requirement
admits the treatment of justiﬁcations as objects, not only as parts of justiﬁca-
tion assertions. The decision whether a justiﬁcation t is meaningful or knowledge-
producing can be made on the basis of the analysis of t itself and does not depend
on the context where it is used. The justiﬁed statement vt can be restored from
it, so for meaningful t the justiﬁcation assertion t:F implies vt = F and t:vt.
Justiﬁcation logic J−is sound and complete with respect to the class of all
basic justiﬁcation models (see [2,3]). How to axiomatize the class of all basic
justiﬁcation models that are sharp and single-conclusion? This question was
stated as an open problem in [3]. We provide the solution.
The key idea is to distinguish between the language of a model and the lan-
guage of the logic. Both of them are justiﬁcation languages but in the ﬁrst one
atoms are treated as constants whereas in the second one they are syntacti-
cal variables that admit substitution. An interpretation of the logical language
in a model is an inﬁnite substitution that replaces syntactical variables with
corresponding expressions of the language of the model, the translation need
not be injective. This approach gives the possibility to axiomatize the single-
conclusion property of a model via Uniﬁcation axioms (see [1,7,8] where they
are used for axiomatization of the single-conclusion property of arithmetical
proof predicates).
In the presence of Uniﬁcation axioms the sharpness property can be expressed
using reference constructions vt. We add them to the logical language. Reference
constructions in the justiﬁcation language were considered in [9,10] where the
general technique was developed and used in the context of Logic of Proofs.
We simplify the exposition and adjust it to the case of J−and the particular
2 In [3] they were referred as injective justiﬁcations. In [4] the terminology was changed.

On the Sharpness and the Single-Conclusion Property
213
reference construction “the judgement justiﬁed by t”. As a result we obtain a
decidable justiﬁcation logic Jref and prove that it is sound and complete with
respect to the class of all sharp single-conclusion basic justiﬁcation models.
2
Preliminaries
2.1
Basic Justiﬁcation Models
Let P 0 (atomic propositions) and J0 (atomic justiﬁcations) be disjoint countable
sets of identiﬁers. The justiﬁcation language L(P 0, J0) has two sorts of expres-
sions — justiﬁcation terms (Tm0) and formulas (Fm0), deﬁned by the following
grammar:
Tm0 ::= J0 | Tm0 · Tm0,
Fm0 ::= ⊥| P 0 | Fm0 →Fm0 | Tm0 : Fm0.
A basic justiﬁcation model is deﬁned in [3] as a pair ⟨L(P 0, J0), ∗⟩where ∗is
an interpretation that consists of two parts, ∗: Fm0 →{0, 1}, ∗: Tm0 →2Fm
0.
It has the following properties:
⊥∗= 0,
(F →G)∗= 1 ⇔(F ∗= 0 or G∗= 1),
(t:F)∗= 1 ⇔F ∈t∗,
s∗▷t∗⊆(s · t)∗.
The class of all basic models can be axiomatized by the system J−(see [2])
which is asserted in [3] to be the base system of justiﬁcation epistemic logic.
Basic models correspond to possible worlds in the canonical model of J−, so J−
is sound and complete with respect to this semantics (see [3,4]).
A basic model is called sharp when s∗▷t∗= (s · t)∗for all t, s ∈Tm0.
It is single-conclusion if for all t ∈Tm0 the set t∗contains no more than one
formula. These properties of a model become essential when we analyze the term
structure of justiﬁcations in more details. Single-conclusion justiﬁcations can be
used as pointers (see [7,9,10] for details). Below we exploit this ability in order
to axiomatize the sharpness property.
2.2
Uniﬁcation
We recall the uniﬁcation technique developed in [9,10]. Let P = {p0, p1, . . .}
and J = {x0, x1, . . .} be sets of syntactical (ﬁrst-order) variables of two sorts.
The language Lv(P, J) is the extension of L(P, J) by the additional second-order
function variable v of type Tm →Fm. It is deﬁned by the grammar
Tm ::= J | Tm · Tm,
Fm ::= ⊥| P | Fm →Fm | Tm: Fm | v(Tm),
so expressions of the form v(t) are additional ﬁrst-order variables indexed by
terms, vt = v(t). Below we use this notation for better readability.3
3 In [9,10] these variables are called reference constructions. In the context of Single-
Conclusion Logic of Proofs they represent syntactical operations that restore some
parts of a formula given its proof. It will be seen that v corresponds to the proof
goal operation that extracts a formula from its proof.

214
V. N. Krupski
Members of Expr = Tm ∪Fm will be considered as terms in the signature
Ω = {⊥, →, :, ·} and will be called expressions. In this context a substitution
is a sort preserving homomorphism of free term algebras of signature Ω, i.e.
a function on Expr that maps terms into terms, formulas into formulas and
commutes with symbols from Ω.
We admit inﬁnite substitutions too. A substitution θ is completely deﬁned
by its values on atomic expressions from the set V ar = J ∪P ∪v(Tm). Let
Dom(θ) = {z ∈V ar | zθ ̸= z},
V ar(θ) = Dom(θ) ∪

z∈Dom(θ)
V ar(zθ),
where V ar(e) denotes the set of all z ∈V ar that occur in e ∈Expr.
A substitution θ is called comprehensive if t1θ = t2θ implies vt1θ = vt2θ for
all t1, t2 ∈Tm.
A conditional uniﬁcation problem is a ﬁnite set of conditional equalities
Ai = Bi ⇒Ci = Di,
Ai, Bi, Ci, Di ∈Expr, i = 1, . . . , n.
(2)
Its solution, or uniﬁer, is a comprehensive idempotent (θ2 = θ) substitution
θ : Expr →Expr such that Aiθ = Biθ implies Ciθ = Diθ for i = 1, . . . , n. The
conditional uniﬁcation problem is called uniﬁable when such a uniﬁer does exist.
The classical (unconditional) ﬁrst-order uniﬁcation is a special case of these
deﬁnitions. In our case the main results of the classical uniﬁcation theory are
also valid. It was established in [8] for the ﬁrst-order conditional uniﬁcation; the
case of a language with reference constructions of the form v(t) was considered
in [9,10] where the following statements were proved:4
– The uniﬁability property for conditional uniﬁcation problems of the form (2)
is decidable.
– Any uniﬁable problem of the form (2) has a uniﬁer θ that is the most general
uniﬁer (m.g.u) in the following weak sense: any substitution θ′ that uniﬁes
(2) has the form θ′ = θλ for some substitution λ. (Note that not every
substitution of the form θλ must unify (2).)
– The m.g.u. of (2) can be computed eﬀectively given Ai, Bi, Ci, Di, i =
1, . . . , n.
– The computation of θ can be detailed in the following way. Let V be the set
of all variables v ∈V ar that occur in (2). It is possible to compute a ﬁnite
substitution θ0 with Dom(θ0) ⊆V such that
zθ =
⎧
⎨
⎩
zθ0,
if z ∈V,
z,
if z ∈(P ∪J) \ V,
(vtθ0)θ0, if z = vt ∈v(Tm) \ V.
(3)
We may also assume that θ0 is conservative, i.e.
V ar(θ0) ⊆V ∪{vtθ0 | vt ∈V }.
(4)
4 The general second-order uniﬁcation problem is known to be undecidable [5,6]. In
our case it is decidable. The problem is more simple because there is no nested
occurrences of the function variable v in the language.

On the Sharpness and the Single-Conclusion Property
215
The ﬁnite substitution θ0 (together with the ﬁnite set V ) can be used as a
ﬁnite representation of the most general uniﬁer θ. We will call it the ﬁnite part of
θ. It can be computed by the variable elimination method, so if two conditional
uniﬁcation problems S and S′ are uniﬁable, S ⊆S′, and θ is a m.g.u. of S with
the ﬁnite part θ0, then it is possible to choose a m.g.u. θ′ of S′ with the ﬁnite
part θ′
0 for which Dom(θ0) ⊆Dom(θ′
0). In this case we will write θ ⪯θ′. Note
that if θ ⪯θ′ and Dom(θ0) = Dom(θ′
0) then S′ has the same uniﬁers as S.
Deﬁnition 1. Let S be the conditional uniﬁcation problem (2) and A, B ∈
Expr. We shall write A = B mod S when Aθ = Bθ for every uniﬁer θ of S.
Lemma 2 ([9,10]). The relation A = B mod S is decidable.
Proof. The uniﬁability property of S is decidable. If S is not uniﬁable then
A = B mod S holds for every A, B ∈Expr. For uniﬁable S one should restore
the most general uniﬁer θ of S and test the equality Aθ = Bθ.
⊓⊔
With a formula of the form G = n
i=1 ti : Fi we associate a conditional
uniﬁcation problem:
ti = tj ⇒Fi = Fj,
i, j = 1, . . . , n.
(5)
We shall write A = B mod G
when A = B mod S
and S is the conditional
uniﬁcation problem (5).
3
Referential Justiﬁcation Logic Jref
The idea to express the injectivity of justiﬁcations via uniﬁcation ﬁrst appeared
in [1]. Later it was developed in order to axiomatize the single-conclusion prop-
erty of arithmetical proof predicates (see [7–10]). It was used for axiomatization
of symbolic models of single-conclusion proof logics in [11,12]. The concept of
an single-conclusion basic justiﬁcation model is more general, so we extend this
approach.
We will distinguish between the language of a basic justiﬁcation model and
the language Lv(P, J) that will be used to formulate the properties of the model.
Deﬁnition 3. An interpretation of the language Lv(P, J) in a basic justiﬁcation
model M = ⟨L(P 0, J0), ∗⟩is a comprehensive (inﬁnite) substitution σ that maps
terms and formulas of the language Lv(P, J) into terms and formulas of the
language L(P 0, J0) respectively,
σ : Tm →Tm0,
σ : Fm →Fm0. We also
require that vtσ ∈(tσ)∗when (tσ)∗is nonempty. The corresponding validity
relation for formulas F ∈Fm is deﬁned in the usual way:
⟨σ, M⟩|= F
iﬀ
(Fσ)∗= 1.
Referential justiﬁcation logic Jref in the language Lv(P, J) is deﬁned by the
following calculus:

216
V. N. Krupski
(A0) axioms of the classical propositional logic,
(A1) s:(F →G) →(t:F →[s · t]:G),
(Application)
(A2)
n
i=1
ti :Fi →(F ↔G)
if
F = G mod
n
i=1
ti :Fi,
(Uniﬁcation)
(A3) t:F →t:vt,
(Assignment)
(A4) [s · t]:vs·t →s:(vt →vs·t) ∧t:vt.
(Sharpness)
Inference rule: F →G, F ⊢G.
(Modus ponens)
Jref extends the justiﬁcation logic J−. The set of its axioms is decidable by
Lemma 2. We will prove that Jref is sound and complete with respect to the class
of all interpretations in sharp and single-conclusion basic justiﬁcation models.
Uniﬁcation axioms (A2) reﬂect the single-conclusion property (see [8,10]).
Assignment axioms (A3), together with Uniﬁcation, provide the correct values
for reference variables vt when t : F is valid (the statement vt restored from
t must be equivalent to F). The last axiom scheme (A4) makes it possible to
reconstruct logical reasonings given the term structure of justiﬁcations. It means
the sharpness property.
Theorem 4. Let σ be an interpretation of Lv(P, J) in a sharp single-conclusion
basic justiﬁcation model M = ⟨L(P 0, J0), ∗⟩and F ∈Fm. Then Jref ⊢F implies
⟨σ, M⟩|= F.
Proof. It is suﬃcient to prove that the translations of axioms (A0)-(A4) are valid
in M. For (A0), (A1) it follows from the fact that M is a model for J−.
Case (A2). Suppose that ⟨σ, M⟩|=
n
i=1
ti :Fi, so
(tiσ)∗= {Fiσ},
i = 1, . . . , n.
There exists a uniﬁer θ of (5) such that
e1σ = e2σ ⇔e1θ = e2θ
(6)
holds for all expressions e1, e2 occurring in (A2). Indeed, let V be the ﬁnite set
of all variables v ∈V ar that occur in (A2) and σ0 be the restriction of σ to V ,
zσ0 =

zσ, z ∈V,
z,
z ∈V ar \ V.
Consider a substitution θ0 = σ0λ where λ is an injective substitution that maps
P 0 into (P \ V ) and J0 into (J \ V ). The substitution θ0 maps Expr into Expr
and is idempotent, because any expression of the form eθ0 does not contain vari-
ables from Dom(θ0) ∪Dom(λ). It satisﬁes the limited comprehension condition
(t1θ0 = t2θ0 ⇒vt1θ0 = vt2θ0) only for terms that occur in (A2). The full-scale
comprehension will be forced by the transformation (3). The corresponding sub-
stitution θ is comprehensive and idempotent. It coincides with θ0 on variables
from V , so the equivalence (6) follows from the injectivity of λ.

On the Sharpness and the Single-Conclusion Property
217
We claim that θ is a uniﬁer of (5). Indeed,
tiθ = tjθ ⇒(tiσ)∗= (tjσ)∗⇒Fiσ = Fjσ ⇒Fiθ = Fjθ.
But F = G mod
n
i=1
ti :Fi implies Fθ = Gθ and Fσ = Gσ. Thus, F and G
denote the same formula in the language L(P 0, J0), so ⟨σ, M⟩|= (F ↔G).
Case (A3) follows from the deﬁnition of the translation. If ⟨σ, M⟩|= t: F
then vtσ = Fσ because M is single-conclusion, so t:F and t:vt denote the same
formula in the language L(P 0, J0).
Case (A4). Suppose ⟨σ, M⟩|= [s · t] : vs·t. Then vs·tσ ∈(sσ · tσ)∗. By the
sharpness property of M, there exists a formula F such that F ∈(tσ)∗and
(F →vs·tσ) ∈(sσ)∗. But vtσ ∈(tσ)∗because (tσ)∗is nonempty, so F = vtσ by
the single-conclusion property of M. Thus, ⟨σ, M⟩|= s:(vt →vs·t) ∧t:vt.
⊓⊔
4
Completeness
Theorem 5. Let Jref ̸⊢F. There exists an interpretation σ of the language
Lv(P, J) in a sharp single-conclusion basic justiﬁcation model M such that
⟨σ, M⟩̸|= F.
The completeness proof is based on the saturation procedure from [9,10]
where its general form for languages with reference constructions is developed.
We will use a simpliﬁed version that ﬁts the language Lv(P, J).
Let (θ, Γ, Δ) be the global data structure, where θ : Expr →Expr is a sub-
stitution5 and Γ, Δ ⊂Fm are ﬁnite sets of formulas. The saturation is a nonde-
terministic procedure that starts from a formula F ∈Fm. It initializes the data
structure: θ := id, Γ := ∅, Δ := {⊥, F}. Then it applies repeatedly the following
blocks of instructions:
1. For every X →Y ∈Γ that has not been discharged by the rule 1 before
nondeterministically add Y to Γ or add X to Δ. Discharge X →Y and all
its descendants (its substitutional instances that will be added to Γ by block
3 later). For every X →Y ∈Δ add X to Γ and add Y to Δ. Repeat these
actions until Γ, Δ will not change. If Γ ∩Δ ̸= ∅then terminate with failure
else go to 2.
2. For every t : X ∈Γ add t : vt to Γ. For every term t that occurs in some
formula from Γ ∪Δ do: if tθ :vtθ ∈Γ add t:vt to Γ. For every [s · t]:X ∈Γ
also add s:(vt →X) and t:vt to Γ. For every pair s:(X →Y ), t:X ∈Γ do:
if the term s · t occurs in some formula from Γ ∪Δ then add [s · t]:Y to Γ.
Repeat these actions until Γ will not change. If Γ ∩Δ ̸= ∅then terminate
with failure else go to 3.
5 θ is an inﬁnite substitution of the form (3). We store the ﬁnite part of it.

218
V. N. Krupski
3. Combine a formula t1 : F1 ∧. . . ∧tn : Fn where ti : Fi, i = 1, . . . , n are all
formulas of the form t:X from Γ. Test the corresponding uniﬁcation problem
(5) for uniﬁability. If it is not uniﬁable then terminate with failure. If it is
uniﬁable then compute an m.g.u. θ′ ⪰θ of (5) and update Γ := Γ ∪Γθ′,
Δ := Δ ∪Δθ′. If Γ ∩Δ ̸= ∅then terminate with failure. Otherwise compare
the ﬁnite parts θ′
0 and θ0. If Dom(θ′
0) = Dom(θ0) then set θ := θ′ and
terminate with success; else update θ := θ′ and go to 1.
Consider a computation of the saturation procedure. Any action in it that
changes the data structure (θ, Γ, Δ) will be called a saturation step. There are
steps of type 1, 2 or 3 depending on the block involved.
Lemma 6. Every computation of the saturation procedure terminates.
Proof. Consider a computation starting from F. Suppose that it does not ter-
minate with failure. It is suﬃcient to prove that it contains a ﬁnite number of
steps.
Let
V i = V i
1 ∪V i
2 ,
V i
1 ⊂(P ∪J),
V i
2 ⊂v(Tm)
be the set of all variables occurring in Γ ∪Δ and T i be the set of all terms
occurring in Γ ∪Δ at some state i of the computation.
The computation does not change the set V i
1 because all substitutions con-
structed by steps of type 3 are conservative (see (4)). All variables of a term
t ∈T i belong to V i
1 . Steps of types 1,2 do not change the set T i. Steps of type 3
may extend the set T i by terms of the form tθ′, t ∈T i, but the choice of θ′ ⪰θ
together with the idempotency of m.g.u.’s imply that sets T i will stabilize after
some steps too. One more iteration after it will stabilize the set V2. Consider the
part of the computation after it.
Consider two consecutive iterations of blocks 1–3. Suppose that at the start of
the second one there exists a formula X →Y ∈Γ ∪Δ that is not discharged. It is
obtained at the previous iteration from some variable p ∈Γ ∪Δ by substitution
θ executed by block 3,
X →Y = pθ,
p ∈P ∪v(Tm).
Formula X →Y and all its descendants will be discharged at the second iteration
by block 1. It means that p will be never used in this role later because later
the substitution will be updated as θ′ = θλ and p θ′ = p θλ = p θ2λ = (X →
Y )θ′, so p θ′ will be a descendant of X →Y and must be already discharged.
Thus, the number of iterations with active steps of type 1 does not exceed the
maximal cardinality of sets V i plus one. Two iterations after the last active step
of type 1 will stabilize the conditional uniﬁcation problem (5) extracted from Γ
and terminate the computation with success.
⊓⊔
Let the initial formula F be ﬁxed. All computations starting from F form a
saturation tree. It has no inﬁnite paths by Lemma 6. Its branching is bounded,
so the saturation tree is ﬁnite.

On the Sharpness and the Single-Conclusion Property
219
Lemma 7. If
all
computations
starting
from
F
terminate
with
failure
then Jref ⊢F.
Proof. Consider a node of the saturation tree. Let Γ, Δ be the contents of the
data structure at that node. One can establish by the straightforward induction
on the depth of the node that Jref ⊢ Γ → Δ. For the root node it implies
Jref ⊢F.
⊓⊔
Proof of Theorem 5. Suppose Jref ̸⊢F. By Lemma 7, there exists a successful
computation of the saturation procedure starting from F. Let (θ, Γ, Δ) be the
resulting contents of the data structure, Expr′ = {eθ | e ∈Expr},
V ar′ = V ar ∩Expr′,
Tm′ = Tm ∩Expr′,
Fm′ = Fm ∩Expr′,
Γ ′ = Γ ∩Expr′,
Δ′ = Δ ∩Expr′.
The substitution θ is idempotent, so the set Expr′ consists of all ﬁxed points
of θ. For every term t ∈Tm′ the set Fm′ contains at most one formula of the
form t:X because θ is comprehensive.
Completion. We construct the set Γ ′′ ⊇Γ ′, Γ ′′∩Δ′ = ∅, and the substitution
λ: Expr′ →Expr′ as follows. Consider a pair of formulas s:(X →Y ), t:X ∈Γ ′
such that [s·t]:Y ̸∈Γ ′. By the restriction from saturation block 2, [s·t]:Y ̸∈Δ′,
the variable vs·t does not occur in formulas from Γ ′ ∪Δ′ and vs·t ∈V ar′. Add
[s · t] : Y to Γ ′ and set vs·tλ := Y . Note that the set of all variables occurring
in formulas from Γ ′ ∪Δ′ remains unchanged. Repeat this step until Γ ′ will not
change and deﬁne Γ ′′ as the least ﬁxed point of it.
The substitution λ deﬁned by this process is idempotent, Dom(λ) ⊂v(Tm′),
V ar(λ) ⊂V ar′ and Xλ = X for X ∈Γ ′ ∪Δ′. Let
P 0 = {p ∈V ar′ | pλ = p},
J0 = V ar′ ∩J.
Consider the language L(P 0, J0) with the interpretation ∗deﬁned by Γ ′′:
p∗= 1 ⇔p ∈Γ ′′
for p ∈P 0,
t∗= {X | t:X ∈Γ ′′}
for t ∈Tm0.
By the construction, it is a basic justiﬁcation model M that is sharp and single-
conclusion. The sharpness condition is forced by saturation block 2 and the
completion procedure. The model is single-conclusion because for each t the set
Γ ′ contains at most one formula of the form t:X and the completion procedure
preserves this property.
Lemma 8 (Truth lemma). If G ∈Γ ′′ then G∗= 1, if G ∈Δ′ then G∗= 0.
Proof. Straightforward induction on the complexity of G. Note that Γ ′′∩Δ′ = ∅.
If G is atomic or has the form t:X then the statement follows from the deﬁnition
of *. For G of the form X →Y it is forced by saturation block 1. In this case
G ∈Γ ′ ∪Δ′, so it will be discharged by block 1 at some step.
⊓⊔

220
V. N. Krupski
The substitution σ = θλ is an interpretation of the language Lv(P, J) in M.
Indeed, it is idempotent because V ar(λ) ⊂V ar′ and both substitutions θ and λ
are idempotent. It is comprehensive because θ is comprehensive and Dom(λ) ⊆
v(Tm′). As a consequence, the equality vtσ = vtσσ holds for each t ∈Tm.
Suppose (tσ)∗̸= ∅for some t ∈Tm. Then tσ = tθ = t′, (t′)∗= {X′} and
t′ : X′ ∈Γ ′′ for some t′ ∈Tm′, X′ ∈Fm′. If t′ : X′ ∈Γ ′ then, by saturation
block 2, t′ : vt′ ∈Γ ′, and vt′θ = X′θ = X′ by saturation block 3. But in this
case vtσ = vt′θ because X′λ = X′. If t′ : X′ ∈Γ ′′ \ Γ ′ then vt′λ = F ′ by the
deﬁnition of λ and vtσ = vt′λ. In both cases vtσ = X′ ∈(tσ)∗.
We have Fσ = Fθ ∈Δ′. By Truth lemma, (Fσ)∗= 0, so ⟨σ, M⟩̸|= F.
⊓⊔
Corollary 9. The logic Jref is decidable.
Proof. Jref ⊢F iﬀall computations of the saturation procedure starting from F
terminate with failure. The saturation tree is ﬁnite and can be restored from F. ⊓⊔
Comment. Basic justiﬁcation models that are single-conclusion but not neces-
sarily sharp can be axiomatized in the language L(P, J) without function variable
v by axioms (A0)–(A3). The deﬁnition of a uniﬁer used in (A3) should be sim-
pliﬁed by omitting the comprehension condition and all other items that involve
expressions of the form vt. The corresponding justiﬁcation logic is also decidable.
Acknowledgements. I would like to thank Sergei Artemov who attracted my atten-
tion to the problem.
References
1. Artemov, S., Straßen, T.: Functionality in the basic logic of proofs. Technical report
IAM 92–004, University of Bern (1993)
2. Artemov, S.: The logic of justiﬁcation. Rev. Symb. Log. 1(4), 477–513 (2008)
3. Artemov, S.: Epistemic Modeling with Justiﬁcations. arXiv:1703.07028v1 (2017)
4. Artemov, S.: Justiﬁcation awareness models. In: Artemov, S., Nerode, A. (eds.)
LFCS 2018. LNCS, vol. 10703, pp. 22–36. Springer, Cham (2018)
5. Farmer, W.M.: Simple second-order languages for which uniﬁcation is undecidable.
Theor. Comput. Sci. 87, 25–41 (1991)
6. Goldfarb, W.G.: The undecidability of the second-order uniﬁcation problem.
Theor. Comput. Sci. 13, 225–230 (1981)
7. Krupski, V.N.: Operational logic of proofs with functionality condition on proof
predicate. In: Adian, S., Nerode, A. (eds.) Logical Foundations of Computer Science
1997. LNCS, vol. 1234, pp. 167–177. Springer, Heidelberg (1997)
8. Krupski, V.N.: The single-conclusion proof logic and inference rules speciﬁcation.
Ann. Pure Appl. Log. 113(1–3), 181–206 (2001)
9. Krupski, V.N.: Reference constructions in the single-conclusion proof logic. J. Log.
Comput. 16(5), 645–661 (2006)
10. Krupski, V.N.: Referential logic of proofs. Theor. Comput. Sci. 357, 143–199 (2006)
11. Krupski, V.N.: Symbolic models for single-conclusion proof logics. In: Ablayev, F.,
Mayr, E.W. (eds.) CSR 2010. LNCS, vol. 6072, pp. 276–287. Springer, Heidelberg
(2010). https://doi.org/10.1007/978-3-642-13182-0 26
12. Krupski, V.N.: On symbolic models for single-conclusion logic of proofs. Sb. Math.
202(5), 683–695 (2011)

Founded Semantics and Constraint Semantics
of Logic Rules
Yanhong A. Liu(B) and Scott D. Stoller
Computer Science Department, Stony Brook University,
Stony Brook, NY 11794, USA
liu@cs.stonybrook.edu
Abstract. Logic rules and inference are fundamental in computer sci-
ence and have been studied extensively. However, prior semantics of logic
languages can have subtle implications and can disagree signiﬁcantly.
This paper describes a simple new semantics for logic rules, founded
semantics, and its straightforward extension to another simple new
semantics, constraint semantics, that unify the core of diﬀerent prior
semantics. The new semantics support unrestricted negation, as well as
unrestricted existential and universal quantiﬁcations. They are uniquely
expressive and intuitive by allowing assumptions about the predicates
and rules to be speciﬁed explicitly. They are completely declarative and
relate cleanly to prior semantics. In addition, founded semantics can be
computed in linear time in the size of the ground program.
Keywords: Datalog · Unrestricted negation
Existential and universal quantiﬁcations · Fixed-point semantics
Constraints · Well-founded semantics · Stable model semantics
Fitting (Kripke-Kleene) semantics · Supported model semantics
1
Introduction
Logic rules and inference are fundamental in computer science, especially for
solving complex modeling, reasoning, and analysis problems in critical areas
such as program analysis and veriﬁcation, security, and decision support.
The semantics of logic rules and their eﬃcient computations have been a sub-
ject of signiﬁcant study, especially for complex rules that involve recursion and
unrestricted negation and quantiﬁcations. Many diﬀerent semantics and compu-
tation methods have been proposed, e.g., see surveys [1,2]. Even those used in
many Prolog-based systems and Answer Set Programming systems—negation
as failure [3], well-founded semantics (WFS) [4], and stable model semantics
(SMS) [5]—have subtle implications and diﬀer signiﬁcantly. Is it possible to cre-
ate a simple semantics that also uniﬁes these diﬀerent semantics?
This work was supported in part by NSF under grants CCF-1414078, CNS-1421893,
IIS-1447549, CCF-1248184, CCF-0964196, and CCF-0613913; and ONR under
grants N000141512208 and N000140910651.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 221–241, 2018.
https://doi.org/10.1007/978-3-319-72056-2_14

222
Y. A. Liu and S. D. Stoller
In practice, diﬀerent semantics may be useful under diﬀerent assumptions
about the facts, rules, and reasoning used. For example, an application may
have complete information about some predicates, i.e., sets and relations, but
not other predicates. Capturing such situations is important for increasingly
larger and more complex applications. Any semantics that is based on a single
set of assumptions for all predicates cannot best model such applications. How
can a semantics be created to support all diﬀerent assumptions and still be
simple and easy to use?
This paper describes a simple new semantics for logic rules, founded seman-
tics, and its straightforward extension to another simple new semantics, con-
straint semantics.
– The new semantics support unrestricted negation (both stratiﬁed and non-
stratiﬁed), as well as unrestricted combinations of existential and universal
quantiﬁcations.
– They allow each predicate to be speciﬁed explicitly as certain (each assertion
of the predicate has one of two values: true, false) or uncertain (has one of
three values: true, false, undeﬁned), and as complete (all rules deﬁning the
predicate are given) or not.
– Completion rules are added for predicates that are complete, as explicit
rules for inferring the negation of those predicates using the negation of the
hypotheses of the given rules.
– Founded semantics infers all true and false values that are founded, i.e., rooted
in the given true or false values and exactly following the rules, and it com-
pletes certain predicates with false values and completes uncertain predicates
with undeﬁned values.
– Constraint semantics extends founded semantics by allowing undeﬁned values
to take all combinations of true and false values that satisfy the constraints
imposed by the rules.
Founded semantics and constraint semantics unify the core of previous
semantics and have three main advantages:
1. They are expressive and intuitive, by allowing assumptions about predicates
and rules to be speciﬁed explicitly, by including the choice of uncertain pred-
icates to support common-sense reasoning with ignorance, and by adding
explicit completion rules to deﬁne the negation of predicates.
2. They are completely declarative. Founded semantics takes the given rules
and completion rules as recursive deﬁnitions of the predicates and their nega-
tion, and is simply the least ﬁxed point of the recursive functions. Constraint
semantics takes the given rules and completion rules as constraints, and is
simply the set of all solutions that are consistent with founded semantics.
3. They relate cleanly to prior semantics, including stratiﬁed semantics [6], ﬁrst-
order logic, Fitting semantics (also called Kripke-Kleene semantics) [7], sup-
ported models [6], as well as WFS and SMS, by precisely capturing corre-
sponding assumptions about the predicates and rules.

Founded Semantics and Constraint Semantics of Logic Rules
223
Additionally, founded semantics can be computed in linear time in the size of
the ground program, as opposed to quadratic time for WFS.
Finally, founded semantics and constraint semantics can be extended to allow
uncertain, complete predicates to be speciﬁed as closed—making an assertion of
the predicate false if inferring it to be true (respectively false) using the given
rules and facts requires assuming itself to be true (respectively false)—and thus
match WFS and SMS, respectively.
2
Motivation for Founded Semantics and Constraint
Semantics
Founded semantics and constraint semantics are designed to be intuitive and
expressive. For rules with no negation or with restricted negation, which have
universally accepted semantics, the new semantics are consistent with the
accepted semantics. For rules with unrestricted negation, which so far lack a
universally accepted semantics, the new semantics unify the core of prior seman-
tics with two basic principles:
1. Assumptions about certain and uncertain predicates, with true (T) and false
(F) values, or possibly undeﬁned (U) values, and about whether the rules
deﬁning each predicate are complete must be made explicit.
2. Any easy-to-understand semantics must be consistent with one where every-
thing inferred that has a unique T or F value is rooted in the given T or F
values and following the rules.
This section gives informal explanations.
Rules with no negation. Consider a set of rules with no negation in the
hypotheses, e.g., a rule can be “q(x) if p(x)” but not “q(x) if not p(x)”
for predicates p and q and variable x. The meaning of the rules, given a set of
facts, e.g., a fact p(a) for constant a, is the set of all facts that are given or
can be inferred by applying the rules to the facts, e.g., {p(a),q(a)} using the
example rule and fact given. In particular,
1. Everything is either T or F, i.e., T as given or inferred facts, or F as otherwise.
So one can just explicitly express what are T, and the rest are F.
2. Everything inferred must be founded, i.e., rooted in the given facts and fol-
lowing the rules. So anything that always depends on itself, e.g., p(a), given
only the rule “p(x) if p(x)”, is not T.
In technical terms, the semantics is 2-valued, and the set of all facts, i.e., true
assertions, is the minimum model, equal to the least ﬁxed point of applying the
rules starting from the given facts.
Rules with restricted negation. Consider rules with negation in the hypothe-
ses, but with each negation only on a predicate all of whose facts can be inferred
without using rules that contain negation of that predicate, e.g., one can have

224
Y. A. Liu and S. D. Stoller
“q(x) if not p(x)” but not “p(x) if not p(x)”. The meaning of the rules
is as for rules with no negation except that a rule with negation is applied only
after all facts of the negated predicates have been inferred. In other words,
The true assertions of any predicate do not depend on the negation of that
predicate. So a negation could be just a test after all facts of the negated
predicate are inferred. The rest remains the same as for rules with no negation.
In technical terms, this is stratiﬁed negation; the semantics is still 2-valued, the
minimum model, and the set of all true assertions is the least ﬁxed point of
applying the rules in order of the strata.
Rules with unrestricted negation. Consider rules with unrestricted negation
in the hypotheses, where a predicate may cyclically depend on its own negation,
e.g., “p(x) if not p(x)”. Now the value of a negated assertion needs to be
established before all facts of the negated predicate have been inferred. In par-
ticular,
There may not be a unique T or F value for each assertion. For example,
given only rule “p(x) if not p(x)”, p(a) cannot be T because inferring it
following the rule would require itself be F, and it cannot be F because it
would lead to itself being T following the rule. That is, there may not be a
2-valued model.
In technical terms, the negation may be non-stratiﬁed. There are two best solu-
tions to this that generalize a unique 2-valued model: a unique 3-valued model
and a set of 2-valued models, as in well-founded semantics (WFS) and stable
model semantics (SMS), respectively.
In a unique 3-valued model, when a unique T or F value cannot be estab-
lished for an assertion, a third value, undeﬁned (U), is used. For example, given
only rule “p(x) if not p(x)”, p(a) is U, in both WFS and founded semantics.
– With the semantics being 3-valued, when one cannot infer that an assertion is
T, one should be able to express whether it is F or U when there is a choice.
For example, given only rule “p(x) if p(x)”, p(a) is not T, so p(a) may
in general be F or U.
– WFS requires that such an assertion be F, even though common sense gener-
ally says that it is U. WFS attempts to be the same as in the case of 2-valued
semantics, even though one is now in a 3-valued situation.
– Founded semantics supports both, allowing one to choose explicitly when
there is a choice. Founded semantics is more expressive by supporting the
choice. It is also more intuitive by supporting the common-sense choice for
expressing ignorance.
For a set of 2-valued models, similar considerations motivate our constraint
semantics. In particular, given only rule “p(x) if not p(x)”, the semantics is
the empty set, i.e., there is no model, in both SMS and constraint semantics,
because no model can contain p(a) or not p(a), for any a, because p(a) cannot

Founded Semantics and Constraint Semantics of Logic Rules
225
be T or F as discussed above. However, given only rule “p(x) if p(x)”, SMS
requires that p(a) be F in all models, while constraint semantics allows the
choice of p(a) being F in all models or being T in some models and F in other
models.
Certain or uncertain. Founded semantics and constraint semantics ﬁrst allow
a predicate to be declared certain
(i.e., each assertion of the predicate has
one of two values: T, F) or uncertain
(i.e., each assertion of the predicate has
one of three values: T, F, U) when there is a choice. If a predicate is deﬁned (as
conclusions of rules) with use of non-stratiﬁed negation, then it must be declared
uncertain, because it might not have a unique 2-valued model. Otherwise, it may
be declared certain or uncertain.
– For a certain predicate, everything T must be given or inferred by follow-
ing the rules, and the rest are F, in both founded semantics and constraint
semantics.
– For an uncertain predicate, everything T or F must be given or inferred,
and the rest are U in founded semantics. Constraint semantics then extends
everything U to be combinations of T and F that satisfy all the rules and
facts as constraints.
Complete or not. Founded semantics and constraint semantics then allow an
uncertain predicate that is in the conclusion of a rule to be declared complete,
i.e., all rules with that predicate in the conclusion are given.
– If a predicate is complete, then completion rules are added to deﬁne the
negation of the predicate explicitly using the negation of the hypotheses of
all given rules and facts of that predicates.
– Completion rules, if any, and given rules are used together to infer everything
T and F. The rest are U in founded semantics, and are combinations of T
and F in constraint semantics as described above.
Closed or not. Finally, founded semantics and constraint semantics can be
extended to allow an uncertain, complete predicate to be declared closed, i.e.,
an assertion of the predicate is made F, called self-false, if inferring it to be T
(respectively F) using the given rules and facts requires assuming itself to be T
(respectively F).
– Determining self-false assertions is similar to determining unfounded sets in
WFS. Repeatedly computing founded semantics and self-false assertions until
a least ﬁxed point is reached yields WFS.
– Among combinations of T and F values for assertions with U values in WFS,
removing each combination that has self-false assertions that are not already
F in that combination yields SMS.
Correspondence to prior semantics, more on motivation. Table 1 summa-
rizes corresponding declarations that capture diﬀerent assumptions under prior
semantics; formal deﬁnitions and proofs for these and for additional relationships

226
Y. A. Liu and S. D. Stoller
Table 1. Correspondence between prior semantics and the new semantics, with decla-
rations for all predicates, capturing diﬀerent assumptions under prior semantics. Strat-
iﬁed semantics is given only for rules that do not use non-stratiﬁed negation, whereas
the other semantics are given for rules with unrestricted negation.
Prior
semantics
New
Certain?
Complete?
Closed?
Theorem
Stratiﬁed
Founded
Yes
(Implied yes) (Implied yes) 5
Constraint
First-Order
Logic
Constraint No
No
(Implied no)
6
Fitting
(Kripke-
Kleene)
Founded
No except
for
extensional
predicates
Yes
No
7
Supported
Constraint
11
WFS
Founded
Any
allowed
Yes
Yes
17
SMS
Constraint
18
appear in the following sections. Founded semantics and constraint semantics
allow additional combinations of declarations besides those in the table.
Some observations from the table may help one better understand founded
semantics and constraint semantics.
– The 4 wide rows cover all combinations of allowed declarations (for all pred-
icates).
– Wide row 1 is a special case of wide row 4, because being certain implies being
complete and closed. So one could prefer to use only the latter two choices
and omit the ﬁrst choice. However, being certain is uniquely important, both
for conceptual simplicity and practical eﬃciency:
(1) It covers the vast class of database applications that do not use non-
stratiﬁed negation, for which stratiﬁed semantics is universally accepted.
It does not need to be understood by explicitly combining the latter two
more sophisticated notions.
(2) It allows founded semantics to match WFS for all example programs we
found in the literature, with predicates being certain when possible and
complete otherwise, but without the last, most sophisticated notion of
being closed; and the semantics can be computed in linear time.
– Wide rows 2 and 3 allow the assumption about predicates that are uncertain,
not complete, or not closed to be made explicitly.
In a sense, WFS uses F for both false and some kinds of ignorance (no
knowledge of something must mean it is F), uses T for both true and some kinds
of ignorance inferred through negation of F, and uses U for conﬂict, remaining

Founded Semantics and Constraint Semantics of Logic Rules
227
kinds of ignorance from T and F, and imprecision; SMS resolves the ignorance
in U, but not the ignorance in F and T. In contrast,
– founded semantics uses T only for true, F only for false, and U for conﬂict,
ignorance, and imprecision;
– constraint semantics further diﬀerentiates among conﬂict, ignorance, and
imprecision—corresponding to there being no model, multiple models, and
a unique model, respectively, consistent with founded semantics.
After all, any easy-to-understand semantics must be consistent with the T
and F
assertions that can be inferred by exactly following the rules and com-
pletion rules starting from the given facts.
– Founded semantics is the maximum set of such T and F assertions, as a
least ﬁxed point of the given rules and completion rules if any, plus U for the
remaining assertions.
– Constraint semantics is the set of combinations of all T and F assertions that
are consistent with founded semantics and satisfy the rules as constraints.
Founded semantics without closed predicates can be computed easily and eﬃ-
ciently, as a least ﬁxed point, contrasting with an alternating ﬁxed point or
iterated ﬁxed point for computing WFS.
3
Language
We ﬁrst consider Datalog with unrestricted negation in hypotheses. We extend
it in Sect. 7 to allow unrestricted combinations of existential and universal quan-
tiﬁcations and other features.
Datalog with unrestricted negation. A program in the core language is a
ﬁnite set of rules of the following form, where any Pi may be preceded with
¬, and any Pi and Q over all rules may be declared certain or uncertain, and
declared complete or not:
Q(X1, . . . , Xa) ←P1(X11, . . . , X1a1) ∧· · · ∧Ph(Xh1, . . . , Xhah)
(1)
Symbols ←, ∧, and ¬ indicate backward implication, conjunction, and negation,
respectively; h is a natural number, each Pi (respectively Q) is a predicate of
ﬁnite number ai (respectively a) of arguments, each Xij and Xk is either a
constant or a variable, and each variable in the arguments of Q must also be in
the arguments of some Pi.
If h = 0, there is no Pi or Xij, and each Xk must be a constant, in which case
Q(X1, . . . , Xa) is called a fact. For the rest of the paper, “rule” refers only to
the case where h ≥1, in which case each Pi(Xi1, . . . , Xiai) or ¬Pi(Xi1, . . . , Xiai)
is called a hypothesis of the rule, and Q(X1, . . . , Xa) is called the conclusion of
the rule. The set of hypotheses of the rule is called the body of the rule.
A predicate declared certain means that each assertion of the predicate has
a unique true (T) or false (F) value. A predicate declared uncertain means that

228
Y. A. Liu and S. D. Stoller
each assertion of the predicate has a unique true, false, or undeﬁned (U) value.
A predicate declared complete means that all rules with that predicate in the
conclusion are given in the program.
A predicate in the conclusion of a rule is said to be deﬁned using the predi-
cates or their negation in the hypotheses of the rule, and this deﬁned-ness relation
is transitive.
– A predicate must be declared uncertain if it is deﬁned transitively using its
own negation, or is deﬁned using an uncertain predicate; otherwise, it may
be declared certain or uncertain and is by default certain.
– A predicate may be declared complete or not only if it is uncertain and is in
the conclusion of a rule, and it is by default complete.
In examples with no explicit speciﬁcation of declarations, default declarations
are used.
Rules of form (1) without negation are captured exactly by Datalog [8,9], a
database query language based on the logic programming paradigm. Recursion
in Datalog allows queries not expressible in relational algebra or relational calcu-
lus. Negation allows more sophisticated logic to be expressed directly. However,
unrestricted negation in recursion has been the main challenge in deﬁning the
semantics of such a language, e.g., [1,2], including whether the semantics should
be 2-valued or 3-valued, and whether the rules are considered complete or not.
Example. We use win, the win-not-win game, as a running example, with
default declarations: move is certain, and win is uncertain and complete. A move
from position x to position y is represented by a fact move(x,y). The following
rule captures the win-not-win game: a position x is winning if there is a move
from x to some position y and y is not winning. Arguments x and y are variables.
win(x) ←move(x,y) ∧¬ win(y)
Note that the declarations for predicates move and win are diﬀerent. Other
choices of declarations can lead to diﬀerent results, e.g., see the last example
under least ﬁxed point in Sect. 4.
■
Additional examples are given in Appendices A and B of [10].
Notations. In arguments of predicates, we use letter sequences for variables,
and use numbers and quoted strings for constants.
In presenting the semantics, in particular the completion rules, we use equal-
ity and the notations below for existential and universal quantiﬁcations, respec-
tively, in the hypotheses of rules, and use negation in the conclusions.
∃X1, . . . , Xn | Y
existential quantiﬁcation
∀X1, . . . , Xn | Y
universal quantiﬁcation
(2)
The quantiﬁcations return T iﬀfor some or all, respectively, combinations of
values of X1, . . . , Xn, the value of Boolean expression Y is T. The domain of
each quantiﬁed variable is the set of all constants in the program.

Founded Semantics and Constraint Semantics of Logic Rules
229
4
Formal Deﬁnition of Founded Semantics and Constraint
Semantics
Atoms, literals, and projection. Let π be a program. A predicate is inten-
sional in π if it appears in the conclusion of at least one rule; otherwise, it is
extensional. An atom of π is a formula formed by applying a predicate symbol in
π to constants in π. A literal of π is an atom of π or the negation of an atom of
π. These are called positive literals and negative literals, respectively. The literals
p and ¬p are complements of each other. A set of literals is consistent if it does
not contain a literal and its complement. The projection of a program π onto a
set S of predicates, denoted Proj(π, S), contains all facts of π whose predicates
are in S and all rules of π whose conclusions contain predicates in S.
Interpretations, ground instances, models, and derivability. An inter-
pretation of π is a consistent set of literals of π. Interpretations are generally
3-valued: a literal p is true (T) in interpretation I if it is in I, is false (F) in I if
its complement is in I, and is undeﬁned (U) in I if neither it nor its complement
is in I. An interpretation of π is 2-valued if it contains, for each atom A of π,
either A or its complement. An interpretation I is 2-valued for predicate P if, for
each atom A for P, I contains A or its complement. Interpretations are ordered
by set inclusion ⊆.
A ground instance of a rule R is any rule that can be obtained from
R by expanding universal quantiﬁcations into conjunctions over all constants
in the domain, and then instantiating the remaining variables with con-
stants. For example, q(a)
←
p(a)
∧
r(b) is a ground instance of
q(x)
←
p(x) ∧∃y | r(y). An interpretation is a model of a program if
it contains all facts in the program and satisﬁes all rules of the program, inter-
preted as formulas in 3-valued logic [7], i.e., for each ground instance of each rule,
if the body is true, then so is the conclusion. The one-step derivability operator
Tπ for program π performs one step of inference using rules of π, starting from a
given interpretation. Formally, C ∈Tπ(I) iﬀC is a fact of π or there is a ground
instance R of a rule of π with conclusion C such that each hypothesis of R is
true in interpretation I.
Dependency graph. The dependency graph DG(π) of program π is a directed
graph with a node for each predicate of π, and an edge from Q to P labeled +
(respectively, −) if a rule whose conclusion contains Q has a positive (respec-
tively, negative) hypothesis that contains P. If the node for predicate P is in
a cycle containing only positive edges, then P has circular positive dependency
in π; if it is in a cycle containing a negative edge, then P has circular negative
dependency in π.
Founded
semantics.
Intuitively,
the
founded
model
of
a
program
π,
denoted
Founded(π),
is
the
least
set
of
literals
that
are
given
as
facts
or
can
be
inferred
by
repeated
use
of
the
rules.
We
deﬁne
Founded(π) = UnNameNeg(LFPbySCC(NameNeg(Cmpl(π)))), where functions
Cmpl, NameNeg, LFPbySCC, and UnNameNeg are deﬁned as follows.

230
Y. A. Liu and S. D. Stoller
Completion. The completion function, Cmpl(π), returns the completed program
of π. Formally, Cmpl(π) = AddInv(Combine(π)), where Combine and AddInv
are deﬁned as follows.
The function Combine(π) returns the program obtained from π by replac-
ing the facts and rules deﬁning each uncertain complete predicate Q with
a single combined rule for Q, deﬁned as follows. Transform the facts and
rules deﬁning Q so they all have the same conclusion Q(V1, . . . , Va), where
V1, . . . , Va are fresh variables (i.e., not occurring in the given rules deﬁning
Q), by replacing each fact or rule Q(X1, . . . , Xa)
←
H1 ∧· · · ∧Hh with
Q(V1, . . . , Va) ←(∃Y1, . . . , Yk | V1 = X1 ∧· · · ∧Va = Xa ∧H1 ∧· · · ∧Hh),
where Y1, . . . , Yk are all variables occurring in the given fact or rule. Combine the
resulting rules for Q into a single rule deﬁning Q whose body is the disjunction
of the bodies of those rules. This combined rule for Q is logically equivalent to
the original facts and rules for Q. Similar completion rules are used in Clark
completion [3] and Fitting semantics [7].
Example. For the win example, the rule for win becomes the following. For
readability, we renamed variables to transform the equality conjuncts into tau-
tologies and then eliminated them.
win(x) ←∃y | (move(x,y) ∧¬ win(y))
■
The function AddInv(π) returns the program obtained from π by adding, for
each uncertain complete predicate Q, a completion rule that derives negative
literals for Q. The completion rule for Q is obtained from the inverse of the
combined rule deﬁning Q (recall that the inverse of C ←B is ¬C ←¬B), by
putting the body of the rule in negation normal form, i.e., using laws of predicate
logic to move negation inwards and eliminate double negations, so that negation
is applied only to atoms.
Example. For the win example, the added rule is
¬ win(x) ←∀y | (¬ move(x,y) ∨win(y))
■
Least ﬁxed point. The least ﬁxed point is preceded and followed by func-
tions that introduce and remove, respectively, new predicates representing the
negations of the original predicates.
The function NameNeg(π) returns the program obtained from π by replac-
ing each negative literal ¬P(X1, . . . , Xa) with n.P(X1, . . . , Xa), where the new
predicate n.P represents the negation of predicate P.
Example. For the win example, this yields:
win(x) ←∃y | (move(x,y) ∧n.win(y))
n.win(x) ←∀y | (n.move(x,y) ∨win(y))
■
The function LFPbySCC(π) uses a least ﬁxed point to infer facts for each
strongly connected component (SCC) in the dependency graph of π, as follows.
Let S1, . . . , Sn be a list of the SCCs in dependency order, so earlier SCCs do not
depend on later ones; it is easy to show that any linearization of the dependency

Founded Semantics and Constraint Semantics of Logic Rules
231
order leads to the same result for LFPbySCC. For convenience, we overload S
to also denote the set of predicates in the SCC.
Deﬁne LFPbySCC(π)
=
In, where I0 is the empty set and Ii
=
AddNeg(LFP(TIi−1∪Proj(π,Si)), Si) for i ∈1..n. LFP is the least ﬁxed point
operator. The least ﬁxed point is well-deﬁned, because the one-step derivability
function TIi−1∪Proj(π,Si) is monotonic, because the program π does not con-
tain negation. The function AddNeg(I, S) returns the interpretation obtained
from interpretation I by adding completion facts for certain predicates in S to
I; speciﬁcally, for each certain predicate P in S, for each combination of val-
ues v1, . . . , va of arguments of P, if I does not contain P(v1, . . . , va), then add
n.P(v1, . . . , va).
Example. For the win example, the least ﬁxed point calculation
1. infers n.win(x) for any x that does not have move(x,y) for any y, i.e., has
no move to anywhere;
2. infers win(x) for any x that has move(x,y) for some y and n.win(y) has
been inferred;
3. infers more n.win(x) for any x such that any y having move(x,y) has win(y);
4. repeatedly does 2 and 3 above until a ﬁxed point is reached.
■
The function UnNameNeg(I) returns the interpretation obtained from inter-
pretation I by replacing each atom n.P(X1, . . . , Xa) with ¬P(X1, . . . , Xa).
Example. For the win example, positions x for which win(x) is T, F, and U,
respectively, in the founded model correspond exactly to the well-known winning,
losing, and draw positions, respectively. In particular,
1. a losing position is one that either does not have a move to anywhere or has
moves only to winning positions;
2. a winning position is one that has a move to a losing position; and
3. a draw position is one not satisfying either case above, i.e., it is in a cycle of
moves that do not have a move to a losing position, called a draw cycle, or is
a position that has only sequences of moves to positions in draw cycles.
■
Example. Suppose the running example uses the declaration that move is uncer-
tain instead of the default of being certain. This means that moves not in the
given move have U values, not allowing any n.win or win facts to be inferred.
Therefore, the founded semantics infers that win is U for all positions.
■
Constraint semantics. Constraint semantics is a set of 2-valued models based
on founded semantics. A constraint model of π is a consistent 2-valued interpre-
tation M such that M is a model of Cmpl(π) and Founded(π) ⊆M. We deﬁne
Constraint(π) to be the set of constraint models of π. Constraint models can be
computed from Founded(π) by iterating over all assignments of true and false
to atoms that are undeﬁned in Founded(π), and checking which of the resulting
interpretations satisfy all rules in Cmpl(π).
Example. For win, draw positions (i.e., positions for which win is undeﬁned)
are in draw cycles, i.e., cycles that do not have a move to a n.win position, or
are positions that have only a sequence of moves to positions in draw cycles.

232
Y. A. Liu and S. D. Stoller
1. If some SCC has draw cycles of only odd lengths, then there is no satisfying
assignment of T and F to win for positions in the SCC, so there are no
constraint models of the program.
2. If some SCC has draw cycles of only even lengths, then there are two satisfying
assignments of T and F to win for positions in the SCC, with the truth values
alternating between T and F around each cycle, and with the second truth
assignment obtained from the ﬁrst by swapping T and F. The total number
of constraint models of the program is exponential in the number of such
SCCs.
■
5
Properties of Founded Semantics and Constraint
Semantics
Proofs of theorems appear in Appendix C of [10].
Consistency and correctness. The most important properties are consistency
and correctness.
Theorem 1. The founded model and constraint models of a program π are
consistent.
Theorem 2. The founded model of a program π is a model of π and Cmpl(π).
The constraint models of π are 2-valued models of π and Cmpl(π).
Same SCC, same certainty. All predicates in an SCC have the same certainty.
Theorem 3. For every program, for every SCC S in its dependence graph, all
predicates in S are certain, or all of them are uncertain.
Higher-order programming. Higher-order logic programs, in languages such
as HiLog, can be encoded as ﬁrst-order logic programs by a semantics-preserving
transformation that replaces uses of the original predicates with uses of a sin-
gle predicate holds whose ﬁrst argument is the name of an original predicate
[11]. For example, win(x) is replaced with holds(win,x). This transformation
merges a set of predicates into a single predicate, facilitating higher-order pro-
gramming. We show that founded semantics and constraint semantics are pre-
served by merging of compatible predicates, deﬁned below, if a simple type sys-
tem is used to distinguish the constants in the original program from the new
constants representing the original predicates.
We extend the language with a simple type system. A type denotes a set of
constants. Each predicate has a type signature that speciﬁes the type of each
argument. A program is well-typed if, in each rule or fact, (1) each constant
belongs to the type of the argument where the constant occurs, and (2) for
each variable, all its occurrences are as arguments with the same type. In the
semantics, the values of predicate arguments are restricted to the appropriate
type.

Founded Semantics and Constraint Semantics of Logic Rules
233
Predicates of program π are compatible if they are in the same SCC in DG(π)
and have the same arity, same type signature, and (if uncertain) same complete-
ness declaration. For a set S of compatible predicates of program π with arity a
and type signature T1, . . . , Ta, the predicate-merge transformation MergeS trans-
forms π into a program MergeS(π) in which predicates in S are replaced with a
single fresh predicate holds whose ﬁrst parameter ranges over S, and which has
the same completeness declaration as the predicates in S. Each atom A in a rule
or fact of π is replaced with MergeAtomS(A), where the function MergeAtomS
on atoms is deﬁned by: MergeAtomS(P(X1, . . . , Xa)) equals holds(“P”, X1,
. . . , Xa) if P ∈S and equals P(X1, . . . , Xa) otherwise. We extend MergeAtomS
pointwise to a function on sets of atoms and a function on sets of sets of atoms.
The predicate-merge transformation introduces S as a new type. The type sig-
nature of holds is S, T1, . . . , Ta.
Theorem 4. Let S be a set of compatible predicates of program π. Then
MergeS(π) and π have the same founded semantics, in the sense that
Founded(MergeS(π)) = MergeAtomS(Founded(π)). MergeS(π) and π also have
the same constraint semantics, in the sense that Constraint(MergeS(π))
=
MergeAtomS(Constraint(π)).
6
Comparison with Other Semantics
Stratiﬁed semantics. Let Stratiﬁed(π) denote the unique 2-valued model of a
program with stratiﬁed negation, as discussed in Sect. 2.
Theorem 5. For a program π with stratiﬁed negation and in which all predi-
cates are certain, Founded(π) = Stratiﬁed(π).
First-order logic. The next theorem relates constraint models with the inter-
pretation of a program as a set of formulas in ﬁrst-order logic.
Theorem 6. For a program π in which all predicates are uncertain and not
complete, the constraint models of π are exactly the 2-valued models of π.
Fitting semantics. The Fitting model of a program π, denoted Fitting(π), is
the least model of a formula in 3-valued logic [7]; Sect. 6 of [10] summarizes the
deﬁnition.
Theorem 7. For a program π in which all extensional predicates are cer-
tain, and all intensional predicates are uncertain and complete, Founded(π) =
Fitting(π).
Theorem 8. (a) For a program π in which all intensional predicates are uncer-
tain and complete, Founded(π) ⊆Fitting(π). (b) If, furthermore, some exten-
sional predicate is uncertain, and some positive literal p for some uncertain
extensional predicate does not appear in π, then Founded(π) ⊂Fitting(π).

234
Y. A. Liu and S. D. Stoller
Theorem 9. (a) For a program π in which all predicates have default declara-
tions as certain or uncertain and complete or not, Fitting(π) ⊆Founded(π). (b)
If, furthermore, Fitting(π) is not 2-valued for some certain intensional predicate
P, then Fitting(π) ⊂Founded(π).
Well-founded semantics. The well-founded model of a program π, denoted
WFS(π), is the least ﬁxed point of a monotone operator Wπ on interpretations
[4]; Sect. 6 of [10] summarizes the deﬁnition.
Theorem 10. For every program π, Founded(π) ⊆WFS(π).
Supported models. Supported model semantics of a logic program π is a set
of 2-valued models [6], denoted Supported(π); Sect. 6 of [10] summarizes the
deﬁnition.
Theorem 11. For a program π in which all extensional predicates are cer-
tain, and all intensional predicates are uncertain and complete, Supported(π) =
Constraint(π).
Theorem 12. For a program π in which all intensional predicates are uncertain
and complete, Supported(π) ⊆Constraint(π).
Theorem 13. For a program π in which all predicates have default declarations
as certain or uncertain and complete or not, Constraint(π) ⊆Supported(π).
Stable models. Gelfond and Lifschitz deﬁne stable model semantics (SMS) of
logic programs [5]. They deﬁne the stable models of a program π to be the 2-
valued interpretations of π that are ﬁxed points of a particular transformation.
Let SMS(π) denote the set of stable models of π.
Theorem 14. For a program π in which all predicates have default declarations
as certain or uncertain, SMS(π) ⊆Constraint(π).
Example. For the win example with default declarations, Fitting semantics
and WFS are the same as founded semantics in Sect. 4, and supported model
semantics and SMS are the same as constraint semantics in Sect. 4. Additional
examples can be found in Appendix B of [10].
■
7
Computational Complexity and Extensions
Computing founded semantics and constraint semantics
Theorem 15. Computing founded semantics is linear time in the size of the
ground program.

Founded Semantics and Constraint Semantics of Logic Rules
235
Proof. First ground all given rules, using any grounding. Then add completion
rules, if any, by adding an inverse rule for each group of the grounded given
rules that have the same conclusion, yielding ground completion rules of the
same asymptotic size as the grounded given rules.
Now compute the least ﬁxed point for each SCC of the resulting ground
rules using a previous method [12]. To do so, ﬁrst introduce a new intermediate
predicate and rule for each conjunction and disjunction in the rules, yielding a
new set of rules of the same asymptotic size. In computing the least ﬁxed point,
each resulting rule incurs at most one rule ﬁring because there are no variables
in the rule, and each ﬁring takes worst-case O(1) time. Thus, the total time is
worst-case linear in the size of all ground rules and therefore in the size of the
grounded given rules.
■
The size of the ground program is polynomial in the size n of input data, i.e.,
the given facts, because each variable in each rule can be instantiated at most
O(n) times (because the domain size is at most n), and there is a ﬁxed number
of variables in each rule, and a ﬁxed size of the given rules. Precisely, the size
of the ground program is in the worst case O(nk × r), where k is the maximum
number of variables in a rule, and r is the size of the given rules.
Computing constraint semantics may take exponential time in the size of the
input data, because in the worst case, all assertions of all predicates may have U
values in founded semantics, and there is an exponential number of combinations
of T and F values of all assertions, where each combination may be checked for
whether it satisﬁes the constraints imposed by all rules.
These complexity analyses also apply to the extensions below except that
computing founded semantics with closed predicates may take quadratic time
in the size of the ground program, because of repeated computation of founded
semantics and self-false assertions.
Closed predicate assumption. We can extend the language to support dec-
laration of uncertain complete predicates as closed. Informally, this means that
an atom A of the predicate is false in an interpretation I, called self-false in I, if
every ground instance of rules that concludes A, or recursively concludes some
hypothesis of that rule instance, has a hypothesis that is false or, recursively, is
self-false in I. Self-false atoms are elements of unfounded sets [4].
Formally, SelfFalseπ(I), the set of self-false atoms of program π with respect
to interpretation I, is deﬁned in the same way as the greatest unfounded set
of π with respect to I, except replacing “some positive hypothesis of R is in
U” with “some positive hypothesis of R for a closed predicate is in U”. The
founded semantics of this extended language is deﬁned by repeatedly computing
the semantics as per Sect. 4 and then setting self-false atoms to false, until a least
ﬁxed point is reached. Formally, the founded semantics is FoundedClosed(π) =
LFP(Fπ), where Fπ(I) = Founded(π ∪I) ∪¬ · SelfFalseπ(Founded(π ∪I)).
The constraint semantics for this extended language includes only inter-
pretations that contain the negative literals required by the closed declara-
tions. Formally, a constraint model of a program π with closed declarations is
a consistent 2-valued interpretation M such that M is a model of Cmpl(π),

236
Y. A. Liu and S. D. Stoller
FoundedClosed(π) ⊆M, and ¬ · SelfFalseπ(M) ⊆M. Let ConstraintClosed(π)
denote the set of constraint models of π.
The next theorem states that changing predicate declarations from uncertain,
complete, and closed to certain when allowed, or vice versa, preserves founded
and constraint semantics. Theorem 3 implies that this change needs to be made
for all predicates in an SCC.
Theorem 16. Let π be a program. Let S be an SCC in its dependence graph
containing only predicates that are uncertain, complete, and closed. Let π′ be a
program identical to π except that all predicates in S are declared certain. Note
that, for the declarations in both programs to be allowed, predicates in SCCs that
follow S in dependency order must be uncertain, predicates in SCCs that precede
S in dependency order must be certain, and predicates in S must not have
circular negative dependency. Then FoundedClosed(π) = FoundedClosed(π′) and
ConstraintClosed(π) = ConstraintClosed(π′).
Theorem 17. For a program π in which every uncertain predicate is complete
and closed, FoundedClosed(π) = WFS(π).
Theorem 18. For a program π in which every uncertain predicate is complete
and closed, ConstraintClosed(π) = SMS(π).
Note, however, that founded semantics for default declarations (certain when
possible and complete otherwise) allows the number of repetitions for computing
self-false atoms to be greatly reduced, even to zero, compared with WFS that
does repeated computation of unfounded sets.
In all examples we have found in the literature, and all natural examples
we have been able to think of, founded semantics for default declarations, with-
out closed predicate assumption, infers the same result as WFS. However, while
founded semantics computes a single least ﬁxed point without the outer repeti-
tion and is worst-case linear time, WFS computes an alternating ﬁxed point or
iterated ﬁxed point and is worst-case quadratic. In fact, we have not found any
natural example showing that an actual quadratic-time alternating or iterated
ﬁxed-point for computing WFS is needed.1
Unrestricted quantiﬁcations in hypotheses. We extend the language to
allow unrestricted combinations of existential and universal quantiﬁcations as
well as negation, conjunction, and disjunction in hypotheses. The domain of
each quantiﬁed variable is the set of all constants in the program.
1 Even a contrived example that demonstrates the worst-case quadratic-time compu-
tation of WFS has been challenging to ﬁnd. For example, the quadratic-time example
in [13] turns out to be linear in XSB; after signiﬁcant eﬀort between us and Warren,
we found a much more sophisticated example that appears to take quadratic time,
but a remaining bug in XSB makes the correctness of its computation unclear.

Founded Semantics and Constraint Semantics of Logic Rules
237
Example. For the win example, the following two rules may be given instead:
win(x) ←∃y | move(x,y) ∧lose(y)
lose(x) ←∀y | ¬ move(x,y) ∨win(y)
■
The semantics in Sect. 4 is easily extended to accommodate this extension:
these constructs simply need to be interpreted, using their 3-valued logic seman-
tics [7], when deﬁning one-step derivability. Theorems 1–3 hold for this extended
language. The other semantics discussed in Sect. 6 are not deﬁned for this exten-
sion, thus we do not have theorems relating to them.
Negation in facts and conclusions. We extend the language to allow negation
in given facts and in conclusions of given rules; such facts and rules are said to be
negative. The Yale shooting example in Appendix B of [10] is a simple example.
The deﬁnition of founded semantics applies directly to this extension, because
it already introduces and handles negative rules, and it already infers and handles
negative facts. Note that Combine combines only positive facts and positive rules
to form combined rules; negative facts and negative rules are copied unchanged
into the completed program.
With this extension, a program and hence its founded model may be incon-
sistent; for example, a program could contain or imply p and ¬p. Thus, Theorem
1 does not hold for such programs. When the founded model is inconsistent, the
inconsistent literals in it can easily be reported. When the founded model is
consistent, the deﬁnition of constraint semantics applies directly, and Theorems
2 and 3 hold. The other semantics discussed in Sect. 6 are not deﬁned for this
extended language, so we do not have theorems relating to them.
8
Related Work and Conclusion
There is a large literature on logic language semantics and eﬃcient computations.
Several overview articles [1,2,14,15] give a good sense of the challenges when
there is unrestricted negation. We discuss major prior semantics here.
Clark [3] describes completion of logic programs to give a semantics for nega-
tion as failure. Numerous others, e.g., [16–21], describe similar additions. Fit-
ting [7] presents a semantics, called Fitting semantics or Kripke-Kleene seman-
tics, that aims to give a least 3-valued model. Apt et al. [6] deﬁnes supported
model semantics, which is a set of 2-valued models; the models correspond to
extensions of the Fitting model. Apt et al. [6] introduces stratiﬁed semantics.
WFS [4] also gives a 3-valued model but aims to maximize false values. SMS [5]
also gives a set of 2-valued models and aims to maximize false values. Other
formalisms and semantics include partial stable models, also called stationary
models [14], and FO(ID), for ﬁrst-order logic with inductive deﬁnitions
[22].
There are also many studies that relate diﬀerent semantics, e.g., [23,24].
Our founded semantics, which extends to constraint semantics, is unique in
that it allows predicates to be speciﬁed as certain or uncertain, as complete or
not, and as closed or not. These choices clearly and explicitly capture the diﬀer-
ent assumptions one can have about the predicates, rules, and reasoning, includ-
ing the well-known closed-world assumption vs open-world assumption—i.e.,

238
Y. A. Liu and S. D. Stoller
whether or not all rules and facts about a predicate are given in the program—
and allow both to co-exist naturally. These choices make our new semantics
more expressive and intuitive. Instead of using many separate semantics, one
just need to make the assumptions explicit; the same underlying logic is used for
inference. In this way, founded semantics and constraint semantics unify diﬀerent
semantics.
In addition, founded semantics and constraint semantics are completely
declarative, as a least ﬁxed point and as constraint satisfaction, respectively.
Our default declarations without closed predicates lead to the same semantics
as WFS and SMS for all natural examples we have found. Additionally, founded
semantics without closed predicates can be computed in linear time in the size
of the ground program, as opposed to quadratic time for WFS.
There are many directions for future study, including additional relationships
with prior semantics, further extensions, eﬃcient implementations, and applica-
tions.
Acknowledgment. We thank David S. Warren, Michael Kifer, Anil Nerode, Tun-
cay Tekle, Molham Aref, Marc Denecker, Cordell Green, Goyal Gupta, Bob Kowalski,
Fangzhen Lin, Alberto Pettorossi, Maurizio Proietti, Neng-Fa Zhou, and many oth-
ers for helpful comments and discussions on logic languages, semantics, and eﬃcient
computations.
A
Comparison of Semantics for Well-Known Small
Examples and More
Table 2 shows well-known example rules and more for tricky boundary cases
in the semantics, where all uncertain predicates that are in a conclusion are
declared complete, but not closed, and shows diﬀerent semantics for them.
– Programs 1 and 2 contain only negative cycles. All three of Founded, WFS,
and Fitting agree. All three of Constraint, SMS, and Supported agree.
– Programs 3 and 4 contain only positive cycles. Founded for certain agrees
with WFS; Founded for uncertain agrees with Fitting. Constraint for certain
agrees with SMS; Constraint for uncertain agrees with Supported.
– Programs 5 and 6 contain no cycles. Founded for certain agrees with WFS
and Fitting; Founded for uncertain has more undeﬁned. Constraint for certain
agrees with SMS and Supported; Constraint for uncertain has more models.
– Programs 7 and 8 contain both negative and positive cycles. For program
7 where ¬ q and q are disjunctive, all three of Founded, WFS, and Fitting
agree; Constraint and Supported agree, but SMS has no model. For program
8 where ¬ q and q are conjunctive, Founded and Fitting agree, but WFS has
q being F; all three of Constraint, SMS, and Supported agree.
For all 8 programs, with default complete but not closed predicates, we have the
following:

Founded Semantics and Constraint Semantics of Logic Rules
239
Table 2. Diﬀerent semantics for programs where all uncertain predicates that are in a conclusion are declared complete, but not closed.
“uncertain” means all predicates in the program are declared uncertain. “certain” means all predicates in the program that can be
declared certain are declared certain; “–” means no predicates can be declared certain, so the semantics is the same as “uncertain”. p, p
and p mean p is T, F, and U, respectively.
Program Founded (not closed) WFS
Fitting (Kripke-Kleene) Constraint (not closed) SMS
Supported
Uncertain Certain
Uncertain
Certain
1 q ←¬ q {q}
–
{q}
{q}
No model
–
No model
No model
2 q ←¬ p
p ←¬ q {p, q}
–
{p, q} {p, q}
{p, q},{p, q} –
{p, q},{p, q} {p, q},{p, q}
3 q ←q
{q}
{q}
{q}
{q}
{q},{q}
{q}
{q}
{q},{q}
4 q ←p
p ←q
{p, q}
{p, q}
{p, q} {p, q}
{p, q},{p, q} {p, q}
{p, q}
{p, q},{p, q}
5 q ←¬ p {p, q}
{p, q}
{p, q} {p, q}
{p, q},{p, q} {p, q}
{p, q}
{p, q}
6 q ←p
{p, q}
{p, q}
{p, q} {p, q}
{p, q},{p, q} {p, q}
{p, q}
{p, q}
7 q ←¬ q
q ←q
{q}
–
{q}
{q}
{q}
–
no model
{q}
8 q ←¬ q
∧q
{q}
–
{q}
{q}
{q}
–
{q}
{q}

240
Y. A. Liu and S. D. Stoller
– If all predicates are the default certain or uncertain, then Founded agrees
with WFS, and Constraint agrees with SMS, with one exception for each:
(1) Program 7 concludes q whether q is F or T, so SMS having no model
is an extreme outlier among all 6 semantics and is not consistent with
common sense.
(2) Program 8 concludes q if q is F and T, so Founded semantics with q
being U is imprecise, but Constraint has q being F. WFS has q being F
because it uses F for ignorance.
– If predicates not in any conclusion are certain (not shown in Table 2 but
only needed for q in programs 5 and 6), and other predicates are uncertain,
then Founded equals Fitting, and Constraint equals Supported, as captured
in Theorems 7 and 11, respectively.
– If all predicates are uncertain, then Founded has all values being U, capturing
the well-known unclear situations in all these programs, and Constraint gives
all diﬀerent models except for programs 2 and 5, and programs 4 and 6, which
are pair-wise equivalent under completion, capturing exactly the diﬀerences
among all these programs.
Finally, if all predicates in these programs are not complete, then Founded
and Constraint are the same as in Table 2 except that Constraint for uncer-
tain becomes equivalent to truth values in ﬁrst-order logic: programs 1 and 8
have an additional model, {q}, program 6 has an additional model, {p, q}, and
programs 2 and 5 have an additional model, {p,q}.
References
1. Apt, K.R., Bol, R.N.: Logic programming and negation: a survey. J. Log. Program.
19, 9–71 (1994)
2. Fitting, M.: Fixpoint semantics for logic programming: a survey. Theor. Comput.
Sci. 278(1), 25–51 (2002)
3. Clark, K.L.: Negation as failure. In: Gallaire, H., Minker, J. (eds.) Logic and Data-
bases, pp. 293–322. Plenum Press, New York (1978)
4. Van Gelder, A., Ross, K., Schlipf, J.S.: The well-founded semantics for general
logic programs. J. ACM 38(3), 620–650 (1991)
5. Gelfond, M., Lifschitz, V.: The stable model semantics for logic programming. In:
Proceedings of the 5th International Conference and Symposium on Logic Pro-
gramming, pp. 1070–1080. MIT Press (1988)
6. Apt, K.R., Blair, H.A., Walker, A.: Towards a theory of declarative knowledge. In:
Foundations of Deductive Databases and Logic Programming, pp. 89–148. Morgan
Kaufman (1988)
7. Fitting, M.: A Kripke-Kleene semantics for logic programs. J. Log. Program. 2(4),
295–312 (1985)
8. Ceri, S., Gottlob, G., Tanca, L.: Logic Programming and Databases. Springer,
Heidelberg (1990)
9. Abiteboul, S., Hull, R., Vianu, V.: Foundations of Databases: The Logical Level.
Addison-Wesley, Reading (1995)

Founded Semantics and Constraint Semantics of Logic Rules
241
10. Liu, Y.A., Stoller, S.D.: The founded semantics and constraint semantics of logic
rules. Computing Research Repository arXiv:1606.06269 [cs.LO] (Revised 2017)
(2016)
11. Chen, W., Kifer, M., Warren, D.S.: HiLog: a foundation for higher-order logic
programming. J. Log. Program. 15(3), 187–230 (1993)
12. Liu, Y.A., Stoller, S.D.: From datalog rules to eﬃcient programs with time and
space guarantees. ACM Trans. Program. Lang. Syst. 31(6), 1–38 (2009)
13. Zukowski, U.: Flexible computation of the well-founded semantics of normal logic
programs. Ph.D. thesis, Faculty of Computer Science and Mathematics, University
of Passau (2001)
14. Przymusinski, T.C.: Well-founded and stationary models of logic programs. Ann.
Math. Artif. Intell. 12(3), 141–187 (1994)
15. Ramakrishnan, R., Ullman, J.D.: A survey of deductive database systems. J. Log.
Program. 23(2), 125–149 (1995)
16. Lloyd, J.W., Topor, R.W.: Making Prolog more expressive. J. Log. Program. 1(3),
225–240 (1984)
17. Sato, T., Tamaki, H.: Transformational logic program synthesis. In: Proceedings of
the International Conference on Fifth Generation Computer Systems, pp. 195–201
(1984)
18. Jaﬀar, J., Lassez, J.-L., Maher, M.J.: Some issues and trends in the semantics of
logic programming. In: Shapiro, E. (ed.) ICLP 1986. LNCS, vol. 225, pp. 223–241.
Springer, Heidelberg (1986). https://doi.org/10.1007/3-540-16492-8 78
19. Chan, D.: Constructive negation based on the completed database. In: Proceedings
of the 5th International Conference and Symposium on Logic Programming, pp.
111–125. MIT Press (1988)
20. Foo, N.Y., Rao, A.S., Taylor, A., Walker, A.: Deduced relevant types and construc-
tive negation. In: Proceedings of the 5th International Conference and Symposium
on Logic Programming, pp. 126–139 (1988)
21. Stuckey, P.J.: Constructive negation for constraint logic programming. In: Pro-
ceedings of the 6th Annual IEEE Symposium on Logic in Computer Science, pp.
328–339 (1991)
22. Denecker, M., Ternovska, E.: A logic of nonmonotone inductive deﬁnitions. ACM
Trans. Comput. Log. 9(2), 14 (2008)
23. Dung, P.M.: On the relations between stable and well-founded semantics of logic
programs. Theor. Comput. Sci. 105(1), 7–25 (1992)
24. Lin, F., Zhao, Y.: Assat: computing answer sets of a logic program by sat solvers.
Artif. Intell. 157(1–2), 115–137 (2004)

Separating the Fan Theorem
and Its Weakenings II
Robert S. Lubarsky(B)
Department of Mathematical Sciences, Florida Atlantic University,
Boca Raton, FL 33431, USA
Robert.Lubarsky@alum.mit.edu
Abstract. Varieties of the Fan Theorem have recently been developed in
reverse constructive mathematics, corresponding to diﬀerent continuity
principles. They form a natural implicational hierarchy. Earlier work
showed all of these implications to be strict. Here we re-prove one of the
strictness results, using very diﬀerent arguments. The technique used is
a mixture of realizability, forcing in the guise of Heyting-valued models,
and Kripke models.
Keywords: Fan Theorems · Kripke models · Forcing
Heyting-valued models · Formal topology · Recursive realizability
AMS 2010 MSC: 03C90 · 03E70 · 03F50 · 03F60 · 03D80
1
Introduction
The Fan Theorem states that, in 2<ω, every bar (i.e. set of nodes which contains a
member of every (inﬁnite) path) is uniform (i.e. contains a member of every (inﬁ-
nite) path by some ﬁxed level of 2<ω). It has been important in the foundation
of constructive mathematics every since it was ﬁrst articulated (by Brouwer),
and so it is no surprise that with the development of reverse mathematics in
recent years it has become an important principle there. In particular, various
weakenings of it have been shown to be equivalent to some principles involving
continuity and compactness [2,4,9]. These weakenings all involve strengthening
the hypothesis, by restricting which bars they apply to. The strictest version,
FANΔ or Decidable Fan, is to say that the bar B in question is decidable: every
node is either in B or not. Another natural version, FANΠ0
1 or Π0
1 Fan, is to
consider Π0
1 bars: there is a decidable set C ⊆2<ω × N such that σ ∈B iﬀ, for
all n ∈N, (σ, n) ∈C. Nestled in between these two is FANc or c-Fan, which is
based on the notion of a c-bar, which is a particular kind of Π0
1 bar: for some
decidable set C ⊆2<ω, σ ∈B iﬀevery extension of σ is in C. It is easy to see
that the implications all hold over a weak base theory. What about the reverse
implications? (We always include the implication of FANΔ from basic set theory
when discussing the converses of the conditionals above.)
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 242–255, 2018.
https://doi.org/10.1007/978-3-319-72056-2_15

Separating the Fan Theorem and Its Weakenings II
243
There had been several proofs that some of the converses did not hold [1,3,6].
These were piecemeal, in that each applied to only one converse, or even just a
weak form of the converse, and used totally diﬀerent techniques, so that there was
no uniform view of the matter. This situation changed with [10], which provided
a family of Kripke models showing the non-reversal of all the implications. It
was asked there whether those models were in some sense the right, or canonical,
models for this purpose; implicit was the question whether the other common
modeling techniques, realizability and Heyting-valued models, could provide the
same separations.
Here we do not answer those questions. We merely bring the discussion along,
by providing a diﬀerent kind of model. It should be pointed out early on that,
at this point, the only separation provided is that FANΔ does not imply FANc,
although we see no reason the arguments could not be extended to the other
versions of Fan.
There are several ways that the model here diﬀers from those of [10]. In the
earlier paper, a tree with no simple paths was built over a model of classical ZFC
via forcing, and the non-implications were shown by hiding that tree better or
worse in various models of IZF. In particular, we showed there that FANΔ does
not imply FANc by including that tree as the complement of a c-bar in a gentle
enough way that no new decidable bars were introduced. Here, we start with a
model of ¬FANΔ, and extend it by including paths that miss decidable (former)
bars. If this is done to all decidable bars, FANΔ can be made to hold. If this is
done gently enough, counter-examples to FANc will remain as counter-examples.
The other diﬀerence is in the techniques used. It is like a Kripke model built
using Heyting-valued extensions of a realizability model. This is not the ﬁrst
time that some of these techniques have been combined (see [11] for references
and discussion). This is the ﬁrst time we are aware of that all three have been
combined. Perhaps that in and of itself makes this work to be of some interest.
This work was started while the author was a fellow at the Isaac Newton
Institute’s fall 2015 program in the Higher Inﬁnite. The author warmly thanks
them for their support and hospitality during that time. Thanks are due also to
Andrew Swan, a conversation with whom led to this work. Thanks go in addition
to Francois Dorais and Noah Schweber for their input on Math Overﬂow about
Francois’s example of a c-bar which is not decidable.
2
Kripke Structures of Constructive Models
While the general theory of models of constructive systems is often itself pre-
sented constructively (for example in [7,8,12]), particular models are often built
within a classical meta-theory, because essential use is made of classical construc-
tions (as in [5] or [10], for instance). For Kripke models, that means, working
classically, giving a partial order, and associating to each node a classical model
(for the similarity type in question), along with a family of transition functions;
this then determines a model of constructive logic. Our current setting is
diﬀerent.

244
R. S. Lubarsky
A warning shot is given by the fact that the root of this model is, eﬀectively,
Kleene’s recursive realizability model MK1; to the degree we work within this
model, we must work constructively, and not classically. This point could be
ﬁnessed, though, by insisting that MK1 was itself built within a classical theory.
More crucially, the structures at each node will be determined by Heyting-
valued extensions of MK1. These structures are no longer of the right type. A
structure of the language of set theory would, among other things, determine,
for objects a and b, whether a ∈b. A Heyting-valued model, though, determines
whether H ⊩“a ∈b”, where H is a value in the Heyting algebra T in question.
To address these matters, a structure at a node will be, in addition to a
Heyting-valued model, also a Heyting value H from the Heyting algebra, and
we will let a formula be true there only if H forces it. To have forcing truth still
be valid within this Kripke structure, we will allow an extension of a node to be
determined in part by a strengthening of the Heyting value H.
Before giving the formal deﬁnitions, we sketch the idea. We will need to iter-
ate taking Heyting-valued extensions. By way of notation, T will be taken to be
a typical complete Heyting algebra, to be consistent with the notation below.
Some of these Heyting algebras T will show up only in some previously con-
structed Heyting-valued extension. So we assume we have a deﬁnable collection
of Heyting algebras, say with deﬁnition φ(T ), which IZF proves to be a set.
To each node p will be associated a string ⟨(T0, O0), (T1, O1), ..., (Tn, On)⟩such
that each Heyting value Oi is not ⊥and forces that the next Ti+1 is an allow-
able Heyting algebra, as given by φ. A child of p is determined by, optionally,
extending some of the Oi’s, and, optionally, including another pair (Tn+1, On+1)
onto the string.
More formally, let φ(x) be a formula such that IZF proves “if φ(x) then x
is a complete Heyting algebra, and φ is satisﬁed by only set-many objects.” We
will have occasion to consider φ as evaluated in a Heyting-valued extension, and
so as applied to a term. Even if there are only set-many objects satisfying φ in
this extension, there could still be class-many such terms. In order to keep this
construction fully set-sized, we will implicitly allow only minimal terms T to be
applied to φ. In more detail, suppose we assert in some context that φ(T ). If this
context is the ground model MK1, then there are only set-many such T ’s within
this model. Else the context will be some Heyting-valued extension, given by a
Heyting value H – H ⊩φ(T ) – within some other context. This latter context
will then satisfy “for any other term t of rank less than that of T , H ⊩t ̸= T ”.
Similarly for the members of, or the Heyting values in, T .
Deﬁnition 1. Deﬁnition of the nodes, and their associated models, by induction
on ω.
The unique node of length 0 is the empty sequence ⟨⟩, with associated model
M⟨⟩= MK1.
Inductively, given the set of nodes of length n, a node p of length n+1 will be
a string of the form ⟨(T0, O0), (T1, O1), ..., (Tn, On)⟩such that p ↾n is a node,
and, in MK1, O0 ⊩“O1 ⊩...“On−1 ⊩“φ(Tn) and On ̸= ⊥is a Heyting value
in the Heyting algebra Tn”” ... ”. The model Mp associated to p is the forcing

Separating the Fan Theorem and Its Weakenings II
245
extension by Tn, with truth determined by On, as evaluated within the model for
p ↾n.
We abbreviate the iterated forcing O0 ⊩“O1 ⊩...“On−1 ⊩ψ” ...” as
⟨O0, ..., On−1⟩⊩H ψ. The reason for the subscript H is to emphasize that this
notion of truth is given by iterated forcing. In contrast, for example, truth in
MK1 is given by realizers, and will be written as e ⊩r ψ. One important instance
of that will be iterated forcing over MK1. So truth in the model given by forcing
with T over MK1 would be written as e ⊩r “O ⊩H ψ”.
By our various conventions, there are only set-many nodes.
By way of notation, we will typically suppress mention of the Ti’s, as they are
implicit in the choice of the Oi’s. The opens of a node will (at least sometimes)
be written as Op
i , so that p of length n will be ⟨Op
0, ..., Op
n−1⟩.
Deﬁnition 2. The partial order on the set of nodes. For q to be an extension of
p, written q ≥p, q has to be at least as long as p, and, for i less than the length
of p, q ↾i ⊩H Oq
i ≤Op
i . (For this to make sense, implicitly q ↾i ⊩H T q
i = T p
i .)
We leave it to the reader to show that this is indeed a partial order. Notice
that an extension of a node is indicated with the standard notation for par-
tial orders, ≥, in contrast with the strengthening of a Heyting value, which is
indicated with the standard notation for forcing, ≤.
This p.o. is in MK1. Since a model embeds into any Heyting-valued extension,
the p.o. is also in any of the models associated with a node. Furthermore, consider
the p.o. restricted to a node (i.e. the extensions of any node, including itself).
This restriction is deﬁnable in the node’s model, uniformly from the node. That
is, given any node as a parameter, the node’s model can ﬁgure out the rest of
the p.o.
We will need the notion of a node being covered by a set of nodes, akin to
an open set in a topological space being covered by a collection of open sets, or,
more generally, a member of a Heyting algebra being (less that) the join of a
subset of the algebra.
Deﬁnition 3. We deﬁne p of length n being covered by P = {pj | j ∈J} by
induction on n.
– For n = 0, ⟨⟩is covered by only {⟨⟩}.
– For n = 1, p of the form ⟨(T , O)⟩is covered by P if each pj also has length
1, and pj ≥p (so pj is of the form ⟨(T , Oj)⟩, the point being that T is the
same), and {Oj | j ∈J} covers O in the sense of T : O ≤{Oj | j ∈J}.
– For a length n + 1 > 1, some conditions are immediate analogues: each pj
extends p in the Kripke order, and each pj has length n + 1. Furthermore,
letting P ↾n be {pj ↾n | j ∈J}, we have that P ↾n is to cover p ↾n. Finally,
we want to view P as a term for a set in the model associated with p ↾n.
Recall that a term for a Heyting-valued model is an arbitrary collection of pairs
⟨O, σ⟩, where O is a member of the Heyting algebra and σ is (inductively)
a term. If we are considering a two-step iteration, then σ is (a term for) a

246
R. S. Lubarsky
pair ⟨ˆO, τ⟩, where ˆO is a value from the second Heyting algebra. This can
be abbreviated by ⟨(O, ˆO), τ⟩. Whereas each pj is of the form ⟨O0, . . . , On⟩,
it induces a set alt −pj := ⟨(O0, . . . , On−1), On⟩, which is a term, in the
language for an n-fold forcing iteration, with value (forced to be) an open set
in Tn. Of course, the n-fold iteration in question is just the model associated
with p ↾n. So, letting Pn be {alt −pj | j ∈J}, p ↾n ⊩H Pn is a collection of
open sets of Tn. Our ﬁnal condition is that p ↾n ⊩H Pn covers p(n).
(At some point, we might need that the transitivity condition is satisﬁed: if
P covers p, and each pj ∈P is covered by Pj, then 
j∈J Pj covers p.)
We are ﬁnally in a position to deﬁne the model. Working within MK1, induc-
tively on the ordinals α, we deﬁne the members Mp
α of the model at node p of
rank α (where we associate α with its canonical image in each of the associated
models), along with the transition functions fpq from Mp
α to Mq
α. We will usu-
ally drop the subscripts and just write f as a polymorphic transition function.
Similarly, we will not adorn f with any α, since the deﬁnition of f will be uni-
form in α. Do not confuse the associated models Mp from above with the Mp
about to be deﬁned.
Deﬁnition 4. The universe Mp of the model at node p. First we deﬁne Mp
α
inductively on ordinals α. A member σ of Mp
α is a function with domain the
p.o. restricted to p (i.e. p and its extensions). Furthermore, σ(q) ⊆
β<α Mq
β.
In order to fulﬁll the basic Kripke condition, if τ ∈σ(q), and r ≥q, then
f(τ) ∈σ(r). If q ≥p, then f(σ) = σ ↾P≥q. Let Mp be 
α Mp
α.
(If you’re wondering whether there are any such members, or whether instead
the deﬁnition is vacuous, consider the constant function, with domain the entire
tree, which always returning the empty set; this is an object of rank 0, and repre-
sents the empty set. The reader is invited to think through now what, inductively,
represents any natural number n, and why there is (something playing the role
of) ω within this formalism.)
Because this model has aspects of both a Kripke and a Heyting-valued model,
it is in actuality neither. So to give the semantics, we cannot rely on any standard
deﬁnition already extant in the literature. Rather, we have to give an indepen-
dent, inductive deﬁnition of satisfaction. In this case we do not subscript ⊩,
because it is our main notion of truth; if we ever need to disambiguate, it will
be written as ⊩K. Furthermore, we will refer to it as a Kripke model, because it
is similar to one, and so we can distinguish it verbally from the various Heyting-
valued models considered and from the realizability model in which this is all
taking place.
Deﬁnition 5. Implicitly in what follows, when we write “p ⊩φ”, the parameters
in φ are all in Mp. Also implicit is the application of the transition function f,
as need be. For future reference, ⊩and ⊩K are the same thing.
– p ⊩σ ∈τ iﬀp is covered by some P, and for all pj ∈P there is a σj ∈τ(pj)
such that pj ⊩σ = σj.

Separating the Fan Theorem and Its Weakenings II
247
– p ⊩σ = τ iﬀfor all q ≥p and all ρ ∈σ(q), q ⊩ρ ∈τ, and vice versa.
– p ⊩φ ∧ψ iﬀp ⊩φ and p ⊩ψ.
– p ⊩φ ∨ψ iﬀp is covered by some Q, and for each q ∈Q either q ⊩φ or
q ⊩ψ.
– p ⊩φ →ψ iﬀfor all q ≥p if q ⊩φ then q ⊩ψ.
– p ⊩⊥never.
– p ⊩∀x φ(x) iﬀfor all q ≥p and σ ∈Mq q ⊩φ(σ).
– p ⊩∃x φ(x) iﬀp is covered by some Q and for all q ∈Q there is some σ such
that q ⊩φ(σ).
Now that we have a semantics, we can state what we would like the semantics
to do for us. Although, as we already emphasized, we cannot rely on established
theorems to tell us anything about our ⊩, since the techniques used are a mixture
of standard methods for building models of constructivism, it should come as
no surprise that we have such a model. Since all of these results are only to be
expected, the proofs are omitted.
Lemma 1. Each node satisﬁes the equality axioms.
Lemma 2. If Q covers p, and for each q ∈Q we have q ⊩φ, then p ⊩φ.
Proof. By a straightforward induction on φ.
Corollary 3. Each node satisﬁes constructive logic.
Theorem 4. This structure models IZF.
3
FANΔ Does Not Imply FANc
For the moment, we will work simply under IZF.
Our primary task is now to deﬁne the right φ, the class of Heyting algebras
we will use to build the nodes. They will be induced by the possible counter-
examples B to FANΔ: B is a decidable set of binary strings, but is not uniform.
It is safe to assume that B is closed upwards. Mostly we’re interested in when B
is in addition a bar, there famously being such a creature in Kleene’s recursive
realizability model. The reason that we do not include being a bar in this deﬁn-
ition is that would then be another condition to check before being able to use
B. This is more than just a matter of convenience, or saving a little work. When
we’re working within a Heyting-valued extension of a realizability model, say,
diﬀerent conditions might decide whether B is a bar diﬀerently, and if B had to
be a bar then we’d need to ﬁnd an inﬁnite path through those conditions along
which B became a bar, meaning either there is such a path, or we’d have to ﬁnd
a non-uniform bar forcing such a path, and all of a sudden the thicket starts to
look impenetrable. Although it seems unaesthetic to force paths that we really
don’t need, this is a small price to pay for having a theorem with a proof.
Let T be the complement of B. So T is a decidable, inﬁnite tree. We will
generically shoot a branch through T.

248
R. S. Lubarsky
We will deﬁne a formal topology S from T. To help make this paper self-
contained, we present a deﬁnition of a formal topology. Such deﬁnitions are not
uniform in the literature. Here we will use the one from [8], Sect. 2.1.
Deﬁnition 6. A formal topology is a poset (S, ≤) and a relation ◁between
elements and subsets of S. (One should think of the elements of S as open sets,
with ≤as containment and ◁as covering.) The axioms are:
– if a ∈p then a ◁p,
– if a ≤b and b ◁p then a ◁p,
– if a ◁p and ∀x ∈p x ◁q then a ◁q, and
– if a ◁p and a ◁q then a◁↓p∩↓q,
where ↓p is the downward closure of p.
Deﬁnition 7. The formal topology induced by B:
Let B be a decidable, upwards-closed, non-uniform set of binary strings, and
T its complement in 2<ω. A member of S is a union of ﬁnitely many basic
members of S. A basic member of S, Oσ, is given by a node σ ∈T, and is
the set of all nodes in T compatible with σ, that is, all initial segments and
extensions, when it is inﬁnite. A witness that O ∈S, that is, a ﬁnite set Σ such
that O = 
σ∈Σ Oσ, is called a base for O; note that bases are not unique. The
partial order ≤on S is just the subset relation ⊆.
A subset U of S covers O ∈S, O ◁U, if it is not the case that there is no
ﬁnite length n such that, for all σ ∈T of length n, either σ ̸∈O or, for some
initial segment τ of σ and for some OU ∈U, we have Oτ ⊆O and Oτ ⊆OU.
In symbols, U covers O iﬀ
¬¬∃n ∀σ ∈T | σ |= n →(σ ̸∈O ∨∃τ ⊆σ ∃OU ∈U Oτ ⊆(O ∩OU)).
For any such n, we say that U covers O by length n.
Remarks: By choosing the base to be empty, ∅∈S.
If the set of nodes compatible with σ is ﬁnite, then σ does not determine an
open set; alternatively, we could allow the induced set to be open, and it will be
covered by the empty set.
For σ ∈T and O ∈S it is decidable from a base for O whether σ ∈O.
Note that if U covers O by n then U covers O by any k ≥n. The reason for
the double-negation in the deﬁnition of covering should become clear, when it is
used, in Theorems 6 and 7.
Proposition 5. (S, ≤, ◁) from above constitutes a formal topology.
The reason for this formal topology is so that we can take the Heyting-valued
model MT over it.
We do not know whether the next theorem is true in general (meaning prov-
able in IZF). So for the moment, we work in the recursive realizability model.
That is, the model MT is taken as being built within it.

Separating the Fan Theorem and Its Weakenings II
249
Theorem 6. Working within the recursive realizability model, in MT , the
generic G is (identiﬁable with) an inﬁnite branch through T.
Proof. We can identify the generic G with {⟨Oσ, τ⟩| τ ⊆σ, Oσ a basic open
set}. We want to show that O∅⊩H “for all k there is a unique σ of length k
with σ ∈G.” Since the natural numbers in the sense of MT can be identiﬁed
with those of MK1, which are themselves just those of V , it suﬃces to ﬁx a k in
the sense of V . It is easy to see that if Oσ is a basic open set with σ of length k
then Oσ ⊩H “σ is the unique member of G of length k.” Let U be {Oσ | σ has
length k and Oσ is a basic open set}. It suﬃces to show that U covers O∅.
Because of the double negation in the deﬁnition of covering, when showing
that U covers O∅it is not necessary to get the n as a computable function of k;
rather, any realizer will do. So it’s just a matter of ﬁnding an n in the ground
model V such that the rest (of the deﬁnition of covering) is easily seen to be
forced. Toward this end, let n be large enough so that, whenever T beneath σ of
length k is ﬁnite, T contains no descendants of σ of length n. In other words, go
through level k of T, take all those nodes whose subtrees will eventually die, of
which there are only ﬁnitely many, and then go out far enough that all of them
have died already. Now given a node τ of T of length n, τ ↾k and Oτ↾k are the
desired witnesses.
The preceding lemma will help us with the analysis of the Kripke model at
nodes of length 1. Of course, we need to consider longer nodes too. Hence we
must prove the corresponding lemma for base models a ﬁnite iteration of these
extensions.
Theorem 7. Let p be some node of the Kripke model, with associated model
Mp. Suppose that, within Mp, T is an inﬁnite, decidable tree. Then, work-
ing within Mp, in MT , the generic G is (identiﬁable with) an inﬁnite branch
through T.
Proof. For ease of exposition, we take p to be ⟨(T0, O⟨⟩)⟩; that is, to have length
1 and to have the open set be the entire tree. We leave the general case to the
reader.
By way of notation, let O0 refer to open sets in the formal topology in MK1
induced by T0, and O1 refer to open sets in the formal topology in Mp for T.
As in the previous theorem, the natural numbers of MT can be identiﬁed with
those of V . So let k be a natural number, and in Mp let U1 be {O1
σ | σ has length
k and O1
σ is a basic open set}. As before, it suﬃces to show that U1 covers O1
∅;
actually, we must show that O0
∅⊩H “U1 covers O1
∅”; actually, what we really
must show is that there is some e which realizes the above forcing assertion,
uniformly in k.
Recall that “U1 covers O1
∅” is an abbreviation of “not not there is an n
such that U1 covers O1
∅by n.” So we must realize “for every O0
σ extending
O0
∅, O0
σ ̸⊩H there is no n such that U1 covers O1
⟨⟩by n.” Toward that end,
suppose f ⊩r O0
σ is an open set of the space T0. Then we must have chosen
e so that {e}(k, f) ⊩r “O0
σ ̸⊩H there is no n such that U1 covers O1
⟨⟩by n.”

250
R. S. Lubarsky
By the realizability semantics, everything realizes a negation, as long as nothing
realizes the statement being negated. So we must show, in V , that nothing
realizes “O0
σ ⊩H there is no n such that U1 covers O1
⟨⟩by n.”
Suppose, toward a contradiction, that g does realize that statement. Unpack-
ing the semantics further, g ⊩r “for every extension O0
τ of O0
σ, O0
τ ̸⊩there is an n
such that U1 covers O1
⟨⟩by n.” Let h ⊩r O0
τ extends O0
σ. Then {g}(h) ⊩r “O0
τ ̸⊩
there is an n such that U1 covers O1
⟨⟩by n.” The only way to realize a negation is
if nothing realizes the statement being negation. So nothing realizes “O0
τ ⊩there
is an n such that U1 covers O1
⟨⟩by n.” We will have our desired contradiction
once we ﬁnd a O0
τ extending O0
σ, an integer n and a realizer of “O0
τ ⊩U1 covers
O1
⟨⟩by n.”
We will construct a ﬁnite sequence of basic open sets of T0, starting with O0
σ
and ending with the desired O0
τ. The steps of this procedure are indexed by the
binary sequences of length k. At each step, indexed by say ρ, extend the current
open set if possible to force T beneath ρ to be ﬁnite, and then again to force a
level nρ witnessing this ﬁniteness (i.e. that ρ has no extension in T of length nρ);
whenever this is not possible, the open set at hand already forces T beneath ρ
to be inﬁnite. Let n be the maximum of the nρ’s. Working beneath O0
τ, if π of
length n is ever forced to be in T, then π ↾k and O1
π↾k will be as desired.
Corollary 8. For p a node in the Kripke partial order, with ﬁnal entry (T, O),
and B the complement of T, p ⊩K B is not a bar.
Proof. Let G be the generic for forcing with T. The function (with domain the
partial order from p onwards) with constant output G (more accurately, the
canonical image of G in the input’s associated model) witnesses that B is not a
bar.
The next two theorems ﬁnish this paper.
Theorem 9. M |= FANΔ.
Proof. The idea is simple enough. If, at a node, B is forced to be a decidable
bar, then B must also be forced to be uniform, because, if not, the node would
have an extension given by forcing with the complement of B, showing that B
could not have been a bar. We need to check the details though, to guard against
things like the use of classical logic and to make sure we’re using the semantics
of the model at hand. For better or worse, I know of no other way to do this
than to unravel the statement to be shown, using the semantics given.
We need to show ⟨⟩⊩FANΔ, working within MK1, meaning we must ﬁnd a
realizer e for the statement ⟨⟩⊩FANΔ. As a reminder, ⟨⟩is the empty sequence,
the bottom node in the partial order underlying the model. For reference, FANΔ
is the assertion “for all B, if B is an upwards-closed decidable bar (in 2<ω), then
B is uniform, i.e. there is a natural number n such that all binary sequences of
length n are in B.”
The Hypothesis: Unpacking the meaning of ⊩, we need to show that within
MK1, if B ∈Mp then p ⊩“if B is such a bar then B is uniform.” That means

Separating the Fan Theorem and Its Weakenings II
251
that if t ⊩r p is a node and B ∈Mp then {e}(t) ⊩r “p ⊩“if B is such a
bar then B is uniform”.” To save on notation, we will suppress mention of t.
This means that we must show e ⊩r “for all q ≥p, if q ⊩B is such a bar then
q ⊩B is uniform.” Again suppressing the realizer that q ≥p, we must show
e ⊩r “if q ⊩B is such a bar then q ⊩B is uniform.” So, suppose f ⊩r “q ⊩B is
such a bar;” we must have that {e}(f) ⊩r “q ⊩B is uniform.”
Unpacking some more, there is a realizer g, easily computable from f, with
g ⊩r “q ⊩B is decidable;” and that means g ⊩r “q ⊩for all σ ∈2<ω, either
σ ∈B or σ ̸∈B.” Since 2<ω does not change from node to node, that means g ⊩r
“for all σ ∈2<ω, q ⊩(either σ ∈B or σ ̸∈B).” Identifying a realizer that σ ∈2<ω
with σ itself, that becomes “for all σ ∈2<ω {g}(σ) ⊩r q ⊩(σ ∈B ∨σ ̸∈B).”
And that means that “for all σ ∈2<ω there is a Qσ such that {g}(σ) ⊩r (Qσ
covers q and for each r ∈Qσ either r ⊩σ ∈B or r ⊩σ ̸∈B).”
The Conclusion: Having just unpacked the hypothesis, we will now analyze
the conclusion. Recall what we need to show: {e}(f) ⊩r “q ⊩B is uniform;”
i.e. {e}(f) ⊩r “q ⊩there is a bound n witnessing that B is uniform;” which is
{e}(f) ⊩r “there is a cover R of q, and for all r ∈R there is some object n such
that r ⊩n is a natural number witnessing the uniformity of B.” That comes
down to the existence of a set R such that {e}(f) ⊩r “R covers q, and for all
r ∈R there is some object n such that r ⊩n is a natural number witnessing the
uniformity of B.”
Since this is complicated enough, we’re now going to build up somewhat
slowly. We will examine several cases, based on the length of q. Since e has
access to a realizer that q is a node, e has access to q’s length, and so can make
this case distinction.
Case I: For the ﬁrst pass, suppose q = ⟨⟩. Every element in the cover Qσ must
have the same length as the thing covered, which in this case is 0, so Qσ = {⟨⟩}.
So we have {g}(σ) ⊩r (either ⟨⟩⊩σ ∈B or ⟨⟩⊩σ ̸∈B).” Similarly for R:
we must have {e}(f) ⊩r “there is some n such that ⟨⟩⊩n is a natural number
witnessing the uniformity of B.” The obvious algorithm to ﬁnd a uniform bound
for B is to run through the various {g}(σ)’s until one ﬁnds such a bound. All
there is left to do in this case is to show that this algorithm terminates. If not,
then every K1 realizer will realize that B is not uniform. So, in MK1, letting T
be the complement of B, ⟨(ST , O⟨⟩)⟩is a node (where ST is the formal topology
induced by T). By the corollary, ⟨(ST , O⟨⟩)⟩⊩“B is not a bar,” contradicting
the assumption that f ⊩r “⟨⟩⊩B is (such) a bar.”
Case II: For our second pass, suppose that q has length 1. So the notion that
Qσ as a set of nodes covers q as a node reduces to covering in the sense of
the Heyting algebra ST , where q = ⟨(ST , O)⟩. Letting Uσ be the set of second
components of the members of Qσ (actually, a member of Qσ being a sequence
of length 1, we are identifying such a sequence with its sole entry), {g}(σ) yields
a realizer that Uσ covers O in the sense of ST . Now recall that the deﬁnition of
covering begins with a double negation; unpacking what it is to realize a double
negation, since something realizes that Uσ covers O, everything does; and there

252
R. S. Lubarsky
is a realizer that Uσ covers O by some witnessing length n, but those latter two
items are not uniformly computable from {f}(σ).
We need to deﬁne a set R with which we can work easily. Towards this end,
say that a binary sequence ρ is suﬃciently long if it is at least as long as each σ
in the given ﬁxed base Σ for O. (That is, e computes a realizer that q is a node.
Being a node includes that O is open in ST , meaning that O has a ﬁnite base,
which is then witnessed by the realizers at hand.) By way of notation, for r ≥q
of length 1, r will be ⟨(ST , Or)⟩. In V , let R be {⟨h, r⟩| h ⊩r “r ≥q, Or = Oρ ≤
O, ρ is suﬃciently long, and there is an n ≤| ρ | such that r ⊩n is a natural
number witnessing the uniformity of B”}. (The reason to insist that r ≤q is
that, in order for r to force B to be uniform, r already has to force that B is a
set of binary strings; recalling that our assumption is no more than that q forces
B to be a bar, we remain on the safe side by working beneath q.)
From a realizer that r is in R, it is easy (and uniform) to compute an n and
a realizer that r forces n to witness the uniformity of B. So there is a uniform
realizer, not even depending on f, of the second part of what {e}(f) is supposed
to realize. Take such a realizer for the second part of {e}(f). As for the ﬁrst part
of {e}(f), it is supposed to realizes that R covers q. Working in MK1, let U be
{Or | r ∈R}. We need to realize that U covers O.
Recall that the notion of covering begins with a double negation. So if any-
thing realizes that, then everything does. Hence we need only the existence of
an n and a realizer that n witnesses that U covers O by length n; n and the
realizer do not have to be computed.
In V , either there are such an n and a realizer, or there aren’t. If there are, we
are done (with this case of q having length 1). If not, then we would like to force
with the complement of U. Now, it does us little good to do such forcing over
MK1; rather, we need to work beneath q, or, more accurately, in MT . Toward
this end, let BR be the term in MK1 for the MT -set which is (the canonical
embedding of) {ρ | Oρ ∈U ∨ρ ̸∈O}. We would like BR to induce an extension of
MT . That is, for the complement TR of BR, we would like that q⌢⟨(STR, O⟨⟩)⟩is
an extension of q. (Please note that TR = O\{ρ | Oρ ∈U}.) We will argue later
why that essentially does it for this case; in the meantime, our intermediate goal
is to show that O ⊩H “BR is a decidable, upwards closed set of binary strings,
which is not uniform.”
Easily, BR is forced to be an upwards closed set of binary strings.
Turning to BR being decidable, it is not clear that it (rather, its MK1 version)
is so in MK1. After all, the deﬁnition of BR depends on R, which itself depends
on B; even though p forces B to be decidable, it is not clear that translates to an
algorithm for deciding facts about forcing the uniformity of B. Serendipitously,
we do not need decidability of BR in MK1, but only in MT (which, recall, is
q’s associated model), as forced by O. We will be able to leverage the diﬀerence
between decidability in MK1 and in MT to get the latter.
Unpacking the assertion O ⊩H “BR is decidable,” we must show that for all
ρ ∈2<ω, O ⊩ρ ∈BR ∨ρ ̸∈BR. And that means that for all such ρ there is a
cover Rρ of O such that, for all Os ∈Rρ, either Os ⊩ρ ∈BR or Os ⊩ρ ̸∈BR.

Separating the Fan Theorem and Its Weakenings II
253
Given such a ρ, ﬁrst determine whether ρ ∈O, using the decidability of T and
the ﬁnite base of O. If so, then determine whether ρ is suﬃciently long. If so,
consider all binary σ of the same length as ρ. Using the meet operation of the
Heyting-algebraic structure of ST , applied to the (ﬁnitely many) Uσ’s, there
is a cover Q of O each member of which decides B of level | ρ | (i.e. decides
membership in B of all strings of the same length as ρ). It is not hard to see
that this Q suﬃces for our Rρ.
With decidability out of the way, we now show that O ⊩H BR is not uniform.
That is, we are interested in evaluating whether BR is uniform in MT . That
means that for no ˆO ≤O do we have that ˆO ⊩BR is uniform. Suppose to the
contrary we had such an ˆO. Then any witness to the uniformity of BR is then
a witness to the uniformity of U as a cover of O, which is assumed not to exist.
So O ⊩H BR is not uniform.
So we have an extension node of q, achieved by forcing over TR. That induces
a generic path through TR. From this path, we can interpret B as a non-uniform
tree. B is already assumed to be forced to be upwards closed and decidable.
So now B induces an extension in the Kripke partial order. This gets a path
avoiding B. So B cannot be forced to be a bar. This contradiction ﬁnishes the
proof of this case.
Case III: It is time to ﬁnish the proof of this theorem. So, let q be a node. If
need be, we will work inductively on the length of q, so q can be taken to have
length at least 1. To recall, we have a realizer f that q ⊩B is an upwards closed
decidable bar. We are searching for a realizer that q ⊩B is uniform. As above,
we will need a set R such that it is easily realizable that R covers q, and for
all r ∈R there is an n such that r ⊩n witnesses the uniformity of B. By our
notational conventions, we can omit mention of the spaces Ti in q, and consider q
to be ⟨Oq
0, . . . , Oq
m⟩(m ≥0); similarly for extensions of q. This means that nodes
can also be taken to be iterated forcing conditions, thereby eliminating the need
for notation to translate between nodes and their corresponding conditions.
For r ≤q as a forcing condition, we say that r is in normal form if (for all
i) r ↾i ⊩H Or
i = Oρi, for some speciﬁc ρi ∈2<ω. Let the length of r be the
maximum of m and the length of each ρi occurring in r. Let R be {⟨h, r⟩| h ⊩r “r
is in normal form, and for some n at most the length of r, r ⊩n witnesses the
uniformity of B”}. All that remains to do is to realize that R covers q, the rest
of what needs showing being trivial. For that, we show by induction on n up to
m + 1, that R ↾n covers q ↾n.
For n = 0, this is just that R is non-empty. This is a simple case, which
can be handled by methods similar to those that follow, and so is left to the
reader. For n ̸= 0, we need to show that q ↾n ⊩H Rn covers q(n), i.e. q ↾n ⊩H
“not there is a witness k that Rn covers q(n) by length k.” Toward that end,
let r extend q ↾n (in the iterated forcing T0 × . . . × Tn−1). We need to show
that r ̸⊩H “there is no such witness k.” Aiming toward a contradiction, suppose
instead that r ⊩H “there is no such witness k.”
Now viewing r and q as nodes in the Kripke partial order, let r∨q be the least
common extension of r and q in this p.o. We would like to show that r ∨q ⊩K

254
R. S. Lubarsky
“there is no such k” (i.e. in the sense of the Kripke model). Let s ≥K r ∨q.
Assume toward a contradiction that s ⊩K there is such a k. Since s is covered
by a set forcing a particular such witness, we can assume that s itself forces that
Rn covers q(n) by length k. Now extend s in the Kripke p.o. (to, by abuse of
notation, s) to decide on membership in q(n) of each σ of length k, and, for
each such σ forced to be in q(n), witnesses τ ⊆σ and O ∈Rn to the covering
property. Keeping in mind that q(n) and Rn are sets in the model associated
with q ↾n, these same facts about Rn and q(n) are therefore forced by s ↾n in
the sense of iterated forcing. Since s ↾n ≤r, this is the desired contradiction.
Hence we conclude that r ∨q ⊩K “there is no such k.”
Let BRn be a term (in r ∨q’s associated model) for {ρ | Oρ ∈Rn or ρ ̸∈
q(n)}. We would like to show that r ∨q ⊩H “BRn is a decidable, upwards
closed, non-uniform set of binary strings.” Once we do that, BRn induces a
Heyting-valued extension, in which B is not witnessed to be uniform. So then B
induces a Heyting-valued extension in which it is not a bar. This is the ultimate
contradiction toward which we were aiming.
It is easy to see that BRn is forced to be an upwards closed set of binary
strings. For the non-uniformity, use the previous result that there is no witness
k to Rn covering q(n).
All we need left to do in this entire1 proof is to show that BRn is forced to
be decidable. As in the previous case (for q of length 1), for any ﬁnite binary
string ρ, we must ﬁnd a set S covering r ∨q such that each s ∈S forces either
ρ ∈BRn or ρ ̸∈BRn. As before, cover r ∨q with a set, each member of which
decides on a ﬁnite base for q, as well as on B up to the level of the length of ρ.
This suﬃces.
Theorem 10. M |= ¬FANc.
Proof. Recall that a c-fan is based on a decidable set of C, which can be taken
to be a computable assignment of “in” and “out” to all the nodes. A node is in
the bar if it and all of its successors are assigned “in”, and out of the bar, or in
the tree, if one of its successors is “out”.
Consider the following c-fan, due to Francois Dorais. Let K be some complete
c.e. set, with enumeration Ks (K at stage s). Let C be such that all nodes on level
n are labeled “in” except for the unique node consistent with Kn (i.e. convert Kn
into a characteristic function). It is easy to see that the characteristic function of
K, if it exists, is the unique branch missing the induced c-set B, which is a bar
in the realizability model, because, as is well known, K’s characteristic function
does not exist in that model. We must, and need only, show that B remains
a bar in M, the idea being that generically K is not added by forcing to the
model.
Suppose toward a contradiction that p ⊩K witnesses that B is not a bar,
in that K is an inﬁnite path avoiding B. What that comes down to is that
for every natural number n there is a covering Qn of p such that every q ∈Q
1 If the reader is feeling any frustration at the length and detail of this proof, it might
amuse them to know that in an earlier draft, the spot above contained an expletive.

Separating the Fan Theorem and Its Weakenings II
255
forces a unique binary string of length n to be in K and that all such strings
in K cohere. It is easy to see that p could not be ⟨⟩, because ⟨⟩is covered by
only {⟨⟩}, at which point K could be externalized from M⟨⟩to MK1, which as
already remarked is not the case.
More generally, when q ⊩σ ∈K, then σ really is an initial part of K’s
characteristic function. After all, if not, then at some stage s an element k is
enumerated into K such that σ(k) = 0. So all descendants of σ of length t ≥s
are in C, and hence in the bar B. That would mean that q could not force an
extension of σ of length s to be in K, contradicting K being forced to be an
inﬁnite path. Hence any such σ in an initial segment of K. That means that
all such σ’s among all such q’s cohere. By taking their union, the characteristic
function of K can be built in MK1.
References
1. Beeson, M.: Foundations of Constructive Mathematics. Springer, Heidelberg (1985)
2. Berger, J.: The logical strength of the uniform continuity theorem. In: Beckmann,
A., Berger, U., L¨owe, B., Tucker, J.V. (eds.) CiE 2006. LNCS, vol. 3988, pp. 35–39.
Springer, Heidelberg (2006). https://doi.org/10.1007/11780342 4
3. Berger, J.: A separation result for varieties of Brouwer’s Fan Theorem. In: Pro-
ceedings of the 10th Asian Logic Conference (ALC 10), Kobe University in Kobe,
Hyogo, Japan, 1–6 September 2008, pp. 85–92 (2010)
4. Diener, H., Loeb, I.: Sequences of real functions on [0, 1] in constructive reverse
mathematics. Ann. Pure Appl. Logic 157(1), 50–61 (2009)
5. Diener, H., Lubarsky, R.: Notions of cauchyness and metastability. In: Artemov, S.,
Nerode, A. (eds.) Symposium on Logical Foundations in Computer Science 2018,
LNCS. Springer, Heidelberg (2018, to appear)
6. Fourman, M.P., Hyland, J.M.E.: Sheaf models for analysis. In: Fourman, M., Mul-
vey, C., Scott, D. (eds.) Applications of Sheaves. LNM, vol. 753, pp. 280–301.
Springer, Heidelberg (1979). https://doi.org/10.1007/BFb0061823
7. Fourman, M.P., Scott, D.S.: Sheaves and logic. In: Fourman, M., Mulvey, C., Scott,
D. (eds.) Applications of Sheaves. LNM, vol. 753, pp. 302–401. Springer, Heidelberg
(1979). https://doi.org/10.1007/BFb0061824
8. Gambino, N.: Heyting-valued interpretations for Constructive Set Theory. Ann.
Pure Appl. Logic 137, 164–188 (2006)
9. Julian, W., Richman, F.: A uniformly continuous function on [0,1] that is every-
where diﬀerent from its inﬁmum. Pac. J. Math. 111(2), 333–340 (1984)
10. Lubarsky, R., Diener, H.: Separating the Fan Theorem and its weakenings. J.
Symbolic Logic 79, 792–813 (2014)
11. van Oosten, J.: Realizability: An Introduction to its Categorical Side. Elsevier,
Amsterdam (2008)
12. Troelstra, A.S., van Dalen, D.: Constructivism in Mathematics, Vol. 2. In: Studies
in Logic, vol. 123, Elsevier (1988)

Dialectica Categories for the Lambek Calculus
Valeria de Paiva1(B) and Harley Eades III2
1 Nuance Communications, Sunnyvale, CA, USA
valeria.depaiva@gmail.com
2 Computer Science, Augusta University, Augusta, GA, USA
harley.eades@gmail.com
Abstract. We revisit the old work of de Paiva on the models of the
Lambek Calculus in dialectica models making sure that the syntactic
details that were sketchy on the ﬁrst version got completed and veriﬁed.
We extend the Lambek Calculus with a κ modality, inspired by Yetter’s
work, which makes the calculus commutative. Then we add the of-course
modality !, as Girard did, to re-introduce weakening and contraction for
all formulas and get back the full power of intuitionistic and classical
logic. We also present the categorical semantics, proved sound and com-
plete. Finally we show the traditional properties of type systems, like
subject reduction, the Church-Rosser theorem and normalization for the
calculi of extended modalities, which we did not have before.
Keywords: Lambek calculus · Dialectica models
Categorical semantics · Type theory · Structural rules
Non-commutative · Linear logic
1
Introduction
Lambek introduced his homonymous calculus (originally called the ‘Syntactic
Calculus’) for proposed applications in Linguistics.
However the calculus got
much of its cult following and reputation by being a convenient, well-behaved
prototype of a Gentzen sequent calculus without any structural rules.
This note recalls a Dialectica model of the Lambek Calculus presented by
the ﬁrst author in the Amsterdam Colloquium in 1991 [10]. Here, like then, we
approach the Lambek Calculus from the perspective of Linear Logic, so we are
interested in the basic sequent calculus with no structural rules, except asso-
ciativity of tensors. In that earlier work we took for granted the syntax of the
calculus and only discussed the exciting possibilities of categorical models of
linear-logic-like systems. Many years later we ﬁnd that the work on models is
still interesting and novel, and that it might inform some of the most recent work
on the relationship between categorial grammars and notions of distributional
semantics [8].
Moreover, using the Agda proof assistant [6] we verify the correctness of our
categorical model (Sect. 5.1), and we add the type theoretical (Sect. 6) notions
that were left undiscussed in the Amsterdam Colloquium presentation. All of
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 256–272, 2018.
https://doi.org/10.1007/978-3-319-72056-2_16

Dialectica Categories for the Lambek Calculus
257
the syntax in this paper was checked using Ott [23]. The goal is to show that
our work can shed new light on some of the issues that remained open. Mostly
we wanted to check the correctness of the semantic proposals put forward since
Szabo’s seminal book [24] and, for future work, on the applicability and ﬁt of
the original systems to their intended uses.
Overview. The Syntactic Calculus was ﬁrst introduced by Joachim Lambek
in 1958 [19]. Since then the rechristened Lambek Calculus has had as its main
motivation providing an explanation of the mathematics of sentence structure,
starting from the author’s algebraic intuitions. The Lambek Calculus is the core
of logical Categorial Grammar. The ﬁrst use of the term “categorial grammar”
seems to be in the title of Bar-Hillel, Gaifman and Shamir (1960), but categorial
grammar began with Ajdukiewicz (1935) quite a few years earlier. After a period
of ostracism, around 1980 the Lambek Calculus was taken up by logicians inter-
ested in Computational Linguistics, especially the ones interested in Categorial
Grammars.
The work on Categorial Grammar was given a serious impulse by the advent
of Girard’s Linear Logic at the end of the 1980s. Girard [12] showed that there
is a full embedding, preserving proofs, of Intuitionistic Logic into Linear Logic
with a modality “!”. This meant that Linear Logic, while paying attention to
resources, could always code up faithfully Classical Logic and hence one could,
as Girard put it, ‘have one’s cake and eat it’, paying attention to resources, if
desired, but always forgetting this accounting, if preferred. This meant also that
several new systems of resource logics were conceived and developed and these
reﬁned resource logics were applied to several areas of Computer Science.
In Computational Linguistics, the Lambek Calculus has seen a signiﬁcant
number of works written about it, apart from a number of monographs that
deal with logical and linguistic aspects of the generalized type-logical approach.
For a shorter introduction, see Moortgat’s entry on the Stanford Encyclopedia of
Philosophy on Type Logical Grammar [20]. Type Logical Grammar situates the
type-logical approach within the framework of Montague’s Universal Grammar
and presents detailed linguistic analyses for a substantive fragment of syntactic
and semantic phenomena in the grammar of English. Type Logical Semantics
oﬀers a general introduction to natural language semantics studied from a type-
logical perspective.
This meant that a series of systems, implemented or not, were devised that
used the Lambek Calculus or its variants as their basis. These systems can be as
expressive as Intuitionistic Logic and the claim is that they are more precise i.e.
they make ﬁner distinctions. Some of the landscape of calculi can be depicted as
follows:

258
V. de Paiva and H. Eades III
From the beginning it was clear that the Lambek Calculus is the multiplica-
tive fragment of non-commutative Intuitionistic Linear Logic. In the diagrams L
stands for the Lambek Calculus, as expounded in [19] but with the unit I added
for the tensor connective (there was a certain amount of dispute on that, as the
original system did not introduce the constant corresponding to the nullary case
of the tensor product, here written as I). The system LP is the Lambek Calculus
with permutation, sometimes called the van Benthem calculus. We are calling
LA the Lambek Calculus with additives, the more usual algebraic connectives
corresponding to meet and join. Hence adding both permutation and additives
to the Lambek Calculus we get to intuitonistic linear logic. On the other diagram
to the Lambek Calculus with permutation we add either weakening (LPweak) or
contraction (LPcont) or both to get the implicational fragment of Intuitionsitic
Propositional Logic.
The Lambek Calculus also has the potential for many applications in other
areas of computer science, such as, modeling processes. Linear Logic has been
at the forefront of the study of process calculi for many years [1,14,22]. We can
think of the commutative tensor product of linear logic as a parallel operator.
For example, given a process A and a process B, then we can form the process
A ⊗B which runs both processes in parallel. If we remove commutativity from
the tensor product we obtain a sequential composition instead of parallel com-
position. That is, the process A ▷B ﬁrst runs process A and then process B in
that order. Paraphrasing Vaughan Pratt, “The sequential composition operation
has no evident counterpart in type theory” see page 11 of [22]. We believe that
the Lambek Calculus will lead to ﬁlling this hole, and the results of this paper
as a means of obtaining a theory with both a parallel operator and a sequen-
tial composition operator. This work thus has a potential to impact research
in programming languages and computer security where both linear logic and
sequential composition play important roles.
There are several interesting questions, considered for Linear Logic, that
could also be asked of the Lambek Calculus or its extensions. One of them,
posed by Morrill et al. is whether we can extend the Lambek Calculus with a
modality that does for the structural rule of (exchange) what the modality of
course ‘!’ does for the rules of (weakening) and (contraction). A preliminary
proposal, which answers this question aﬃrmatively, is set forward in this paper.
The answer was provided in semantical terms in the ﬁrst version of this work.

Dialectica Categories for the Lambek Calculus
259
Here we provide also the more syntactic description of these modalities. Building
up from work of Ciabattoni, Galatos and Terui in [7] and others that describe
how to transform systems of axioms into cut-free sequent rules, we aim to reﬁne
the algebraization of proof theory.
2
Related Work
Lamarche and Retor´e [18] give an overview of proof nets for the Lambek Calculus
where they discuss the addition of various exchange rules to the calculus. For
example, the following permutation and cycle rules:
A1, A2, Γ ⊢B
A2, A1, Γ ⊢B
perm
A1, A2, Γ ⊢B
A1, Γ, A2, Γ ⊢B
cycl
Taken in isolation each rule does not imply general exchange, but taken together
they do. Thus, it is possible to take a restricted notion of exchange to the Lambek
Calculus without taking general exchange. However, applications where one needs
a completely non-commutative tensor product and a commutative tensor product
cannot be modeled in the Lambek Calculus with these rules.
Polakow and Pfenning [21] combine intuitionistic, commutative linear, and
non-commutative linear logic into a system called Ordered Linear Logic (OLL).
Polakow and Pfenning then extend OLL into two new systems: a term assignment
of OLL called OLLi, and a logical framework in the tradition of LF called OLF.
OLL’s sequent is of the form Γ, Δ, Ω ⊢A where Γ is a multiset of intu-
itionistic assumptions, Δ is a multiset of commutative linear assumptions, and
Ω is a list of non-commutative linear assumptions. Furthermore, OLL contains
logical connectives from each logic. For example, there are two diﬀerent tensor
products and three diﬀerent implications. Thus, the systems developed here are
a simpliﬁcation of OLL showing how to get all of these systems using modalities.
Greco and Palmigiano [13] give a type of logic called a proper display logic
for the Lambek Calculus with exponentials. However, they decompose the linear
exponential into an adjunction in the spirit Benton’s LNL models. In this paper
we concentrate on sequent calculi rather than display logic.
3
The Lambek Calculus
The Lambek Calculus, formerly the Syntactic Calculus L, due to Lambek [19],
was created to capture the logical structure of sentences. Lambek introduced
what we think of as a substructural logic with an operator denoting concate-
nation, A ⊗B, and two implications relating the order of phrases, A ↼B and
A ⇀B. The ﬁrst implication corresponds to a phrase of type A when followed
by a phrase of type B, and the second is a phrase of type B when preceded by
a phrase of type A.
The Lambek Calculus, deﬁned in Fig. 1, can be presented as a non-
commutative intuitionistic multiplicative linear logic. Contexts are sequences

260
V. de Paiva and H. Eades III
A ⊢A
ax
· ⊢I
Ur
Γ2 ⊢A
Γ1, A, Γ3 ⊢B
Γ1, Γ2, Γ3 ⊢B
cut
Γ1, Γ2 ⊢A
Γ1, I, Γ2 ⊢A
Ul
Γ, A, B, Γ ′ ⊢C
Γ, A ⊗B, Γ ′ ⊢C
Tl
Γ1 ⊢A
Γ2 ⊢B
Γ1, Γ2 ⊢A ⊗B
Tr
Γ2 ⊢A
Γ1, B, Γ3 ⊢C
Γ1, A ⇀B, Γ2, Γ3 ⊢C
IRl
Γ2 ⊢A
Γ1, B, Γ3 ⊢C
Γ1, Γ2, B ↼A, Γ3 ⊢C
ILl
Γ, A ⊢B
Γ ⊢A ⇀B
IRr
A, Γ ⊢B
Γ ⊢B ↼A
ILr
Fig. 1. The Lambek Calculus: L
of formulas, and we denote mapping the modalities over an arbitrary context by
!Γ and κΓ.
Because the operator A ⊗B denotes the type of concatenations the types
A ⊗B and B ⊗A are not equivalent, and hence, L is non-commutative which
explains why implication must be broken up into two operators A ↼B and
A ⇀B. In the following subsections we give two extensions of L: one with
the well-known modality of-course of linear logic which adds weakening and
contraction, and a second with a new modality adding exchange.
4
Extensions to the Lambek Calculus
The linear modality, !A, read “of-course A” was ﬁrst proposed by Girard [12] as
a means of encoding non-linear logic in both classical and intuitionistic forms in
linear logic. For example, non-linear implication A ⇀B is usually encoded into
linear logic by !A ⊸B. Since we have based L on non-commutative intuitionistic
linear logic it is straightforward to add the of-course modality to L. The rules
for the of-course modality are deﬁned by the following rules:
Γ1, !A, Γ2, !A, Γ3 ⊢B
Γ1, !A, Γ2, Γ3 ⊢B
C
Γ1, Γ2 ⊢B
Γ1, !A, Γ2 ⊢B
W
!Γ ⊢B
!Γ ⊢!B
Br
Γ1, A, Γ2 ⊢B
Γ, !A, Γ2 ⊢B
Bl
The rules C and W add contraction and weakening to L in a controlled way. Then
the other two rules allow for linear formulas to be injected into the modality; and
essentially correspond to the rules for necessitation found in S4 [5]. Thus, under
the of-course modality the logic becomes non-linear. We will see in Sect. 5.1 that
these rules deﬁne a comonad. We call the extension of L with the of-course
modality L!.
As we remarked above, one leading question of the Lambek Calculus is: can
exchange be added in a similar way to weakening and contraction? That is, can
we add a new modality that adds the exchange rule to L in a controlled way?

Dialectica Categories for the Lambek Calculus
261
The answer to this question is positive, and the rules for this new modality are
as follows:
κΓ ⊢B
κΓ ⊢κB
Er
Γ1, A, Γ2 ⊢B
Γ1, κA, Γ2 ⊢B
El
Γ1, κA, B, Γ2 ⊢C
Γ1, B, κA, Γ2 ⊢C
E1
Γ1, A, κB, Γ2 ⊢C
Γ1, κB, A, Γ2 ⊢C
E2
The ﬁrst two rules are similar to of-course, but the last two add exchange
to formulas under the κ-modality. We call L with the exchange modality Lκ.
Thus, unlike intuitionistic linear logic where any two formulas can be exchanged,
Lκ restricts exchange to only formulas under the exchange modality. Just like
of-course the exchange modality is modeled categorically as a comonad; see
Sect. 5.1.
5
Categorical Models
We now turn to the categorical models, ones where one considers diﬀerent proofs
of the same theorem. Since the Lambek Calculus itself came from its categori-
cal models, biclosed monoidal categories, there is no shortage of these models.
However, Girard’s insight of relating logical systems via modalities should also
be considered in this context.
Lambek’s work on monoidal biclosed categories happened almost three
decades before Girard introduced Linear Logic, hence there were no modalities
or exponentials in Lambek’s setting. The categorical modelling of the modalities
(of-course! and why-not?) was the diﬃcult issue with Linear Logic. This is where
there are design decisions to be made.
5.1
Dialectica Lambek Spaces
A sound and complete categorical model of the Lambek Calculi can be given
using a modiﬁcation of de Paiva’s dialectica categories [9]. Dialectica categories
arose from de Paiva’s thesis on a categorical model of G¨odel’s Dialectica inter-
pretation, hence the name. Dialectica categories were one of the ﬁrst sound
categorical models of intuitionistic linear logic, with linear modalities. We show
in this section that they can be adapted to become a sound and complete model
for the Lambek Calculus, with both the exchange and of-course modalities. We
call this model dialectica Lambek spaces.
Due to the complexities of working with dialectica categories we have formally
veriﬁed1 this section in the proof assistant Agda [6]. Dialectica categories arise
as constructions over a given monoidal category. Suppose C is such a category.
Then in complete generality the objects of the dialectica category over C are
triples (U, X, α) where U and X are objects of C, and
is a
subobject of the tensor product in C of U and X. Thus, we can think of α as a
relation over U ⊗X. If we specialize the category C to the category of sets and
1 The complete formalization can be found online at https://github.com/heades/
dialectica-spaces/blob/Lambek/NCDialSets.agda.

262
V. de Paiva and H. Eades III
functions, Set, then we obtain what is called a dialectica space. Dialectica spaces
are a useful model of full intuitionistic linear logic [15].
Morphisms between objects (U, X, α) and (V, Y, β) are pairs (f, F) where
and
are morphisms of C such that the pullback condition
(U ⊗F)−1(α) ≤(f ⊗Y )−1(β) holds. In dialectica spaces this condition becomes
∀u ∈U.∀y ∈Y.α(u, F(y)) ≤β(f(u), y). The latter reveals that we can think
of the condition on morphisms as a weak form of an adjoint condition. Finally,
through some nontrivial reasoning on this structure we can show that this is
indeed a category; for the details see the formal development. Dialectica cat-
egories are related to the Chu construction [11] and to Lafont and Streicher’s
category of games GAMEκ [17].
To some extent the underlying category C controls the kind of structure we
can expect in the dialectica category over C. However, de Paiva showed [11]
that by changing the relations used in the objects and the order used in the
‘adjoint condition’ (which also controls the type of structure) we can obtain a
non-symmetric tensor in the dialectica category, if the structure of the underlying
category and the structure of the underlying relations are compatible. She also
showed that one can abstract the notion of relation out as a parameter in the
dialectica construction, so long as this has enough structure, i.e. so long as you
have an algebra (that she called a lineale) to evaluate the relations at. We denote
this construction by DialL(C) where L is the lineale controlling the relations
coming from the monoidal category C. For example, Dial2(Set) is the category
of usual dialectica spaces of sets over the Heyting (or Boolean) algebra 2.
This way we can see dialectica categories as a framework of categorical models
of various logics, varying the underlying category C as well as the underlying
lineale or algebra of relations L. Depending on which category we start with
and which structure we use for the relations in the construction we will obtain
diﬀerent models for diﬀerent logics.
The underlying category we will choose here is the category Set, but the
structure we will deﬁne our relations over will be a biclosed poset, deﬁned in the
next deﬁnition.
Deﬁnition 1. Suppose (M, ≤, ◦, e) is an ordered non-commutative monoid. If
there exists a largest x ∈M such that a◦x ≤b for any a, b ∈M, then we denote
x by a ⇀b and called it the left-pseudocomplement of a w.r.t b. Additionally,
if there exists a largest x ∈M such that x ◦a ≤b for any a, b ∈M, then we
denote x by b ↼a and called it the right-pseudocomplement of a w.r.t b.
A biclosed
poset, (M, ≤, ◦, e, ⇀, ↼), is an ordered non-commutative
monoid, (M, ≤, ◦, e), such that a ⇀b and b ↼a exist for any a, b ∈M.
Now using the previous deﬁnition we deﬁne dialectica Lambek spaces.
Deﬁnition 2. Suppose (M, ≤, ◦, e, ⇀, ↼) is a biclosed poset. Then we deﬁne
the category of dialectica Lambek spaces, DialM(Set), as follows:
– objects, or dialectica Lambek spaces, are triples (U, X, α) where U and X are
sets, and
is a generalized relation over M, and

Dialectica Categories for the Lambek Calculus
263
– maps that are pairs
where
and
are functions such that the weak adjointness condition ∀u ∈
U.∀y ∈Y.α(u, F(y)) ≤β(f(u), y) holds.
Notice that the biclosed poset is used here as the target of the relations in
objects, but also as providing the order relation in the weak adjoint condition
on morphisms. This will allow the structure of the biclosed poset to lift up into
DialM(Set).
We will show that DialM(Set) is a model of the Lambek Calculus with modali-
ties. First, we show that it is a model of the Lambek Calculus without modalities.
Thus, we must show that DialM(Set) is monoidal biclosed.
Deﬁnition 3. Suppose (U, X, α) and (V, Y, β) are two objects of DialM(Set).
Then their tensor product is deﬁned as follows:
(U, X, α) ⊗(V, Y, β) = (U × V, (V →X) × (U →Y ), α ⊗β)
where −→−is the function space from Set, and (α ⊗β)((u, v), (f, g)) =
α(u, f(v)) ◦β(g(u), v).
The identity of the tensor product just deﬁned is I = (1, 1, e), where 1 is the
terminal object in Set, and e is the unit of the biclosed poset. It is straightforward
to show that the tensor product is functorial, one can deﬁne the left and right
unitors, and the associator for tensor; see the formalization for the deﬁnitions. In
addition, all of the usual monoidal diagrams hold [9]. Take note of the fact that
this tensor product is indeed non-commutative, because the non-commutative
multiplication of the biclosed poset is used to deﬁne the relation of the tensor
product.
The tensor product has two right adjoints making DialM(Set) biclosed.
Deﬁnition 4. Suppose (U, X, α) and (V, Y, β) are two objects of DialM(Set).
Then two internal-homs can be deﬁned as follows:
(U, X, α) ⇀(V, Y, β) = ((U →V ) × (Y →X), U × Y, α ⇀β)
(V, Y, β) ↼(U, X, α) = ((U →V ) × (Y →X), U × Y, α ↼β)
These two deﬁnitions are functorial, where the ﬁrst is contravariant in the ﬁrst
argument and covariant in the second, but the second internal-hom is covariant in
the ﬁrst argument and contravariant in the second. The relations in the previous
two deﬁnitions prevent these two from collapsing into the same object, because
of the use of the left and right pseudocomplement. It is straightforward to show
that the following bijections hold:
Hom(A ⊗B, C) ∼= Hom(B, A ⇀C) Hom(A ⊗B, C) ∼= Hom(A, C ↼B)
Therefore, DialM(Set) is biclosed, and we obtain the following result.
Theorem 1. DialM(Set) is a sound and complete model for the Lambek Calculus
L without modalities.

264
V. de Paiva and H. Eades III
We now extend DialM(Set) with two modalities: the usual modality, of-course,
denoted !A, and the exchange modality denoted κA. However, we must ﬁrst
extended biclosed posets to include an exchange operation.
Deﬁnition 5. A
biclosed
poset
with
exchange
is
a
biclosed
poset
(M, ≤,◦, e, ⇀, ↼) equipped with an unary operation κ : M →M satisfying the
following:
(Compatibility)
a ≤b implies κa ≤κb for all a, b, c ∈M
(Minimality)
κa ≤a for all a ∈M
(Duplication)
κa ≤κκa for all a ∈M
(Left Exchange) κa ◦b ≤b ◦κa for all a, b ∈M
(Right Exchange) a ◦κb ≤κb ◦a for all a, b ∈M
Compatibility results in κ : M →M being a functor in the biclosed poset, and
the remainder of the axioms imply that κ is a comonad extending the biclosed
poset with left and right exchange.
We can now deﬁne the two modalities in DialM(Set) where M is a biclosed
poset with exchange; clearly we know DialM(Set) is also a model of the Lambek
Calculus without modalities by Theorem 1 because M is a biclosed poset.
Deﬁnition 6. Suppose (U, X, α) is an object of DialM(Set) where M is a
biclosed poset with exchange. Then the of-course and exchange modalities can
be deﬁned as !(U, X, α) = (U, U →X∗, !α) and κ(U, X, α) = (U, X, κα) where
X∗is the free commutative monoid on X, (!α)(u, f) = α(u, x1) ◦· · · ◦α(u, xi)
for f(u) = (x1, . . . , xi), and (κα)(u, x) = κ(α(u, x)).
This deﬁnition highlights a fundamental diﬀerence between the two modalities.
The deﬁnition of the exchange modality relies on an extension of biclosed posets
with essentially the exchange modality in the category of posets. However, the
of-course modality is deﬁned by the structure already present in DialM(Set),
speciﬁcally, the structure of Set.
Both of the modalities have the structure of a comonad. That is, there are
monoidal natural transformations
and
which satisfy the appropriate diagrams; see the formalization
for the full proofs. Furthermore, these comonads come equipped with arrows
Thus, we arrive at the following result.
Theorem 2. Suppose M is a biclosed poset with exchange. Then DialM(Set) is
a sound and complete model for the Lambek Calculi L!, Lκ, and L!κ.
6
Type Theory for Lambek Systems
In this section we introduce typed calculi for each of the logics discussed so far.
Each type system is based on the term assignment for Intuitionistic Linear Logic
introduced in [2]. We show that they are all strongly normalizing and conﬂuent,
but we do not give full detailed proofs of each of these properties, because they are

Dialectica Categories for the Lambek Calculus
265
straightforward consequences of the proofs of strong normalization and conﬂuence
for intuitionistic linear logic. In fact, we will reference Bierman’s thesis often within
this section. The reader may wish to review Sect. 3.5 on page 88 of [4].
6.1
The Typed Lambek Calculus: λL
The ﬁrst system we cover is the Lambek Calculus without modalities. This sys-
tem can be seen as the initial core of each of the other systems we introduce
below, and thus, we will simply extend the results here to three other systems.
The syntax for patterns, terms, and contexts are described by the following
grammar:
(patterns) p := −| x | unit | p1 ⊗p2
(terms)
t := x | unit | t1 ⊗t2 | λlx : A.t | λrx : A.t | appl t1 t2 |
appr t1 t2 | let t1 be p in t2
(contexts) Γ := · | x : A | Γ1, Γ2
Contexts are sequences of pairs of free variables and types. Patterns are only
used in the let-expression which is itself used to eliminate logical connectives
within the left rules of L. All variables in the pattern of a let-expression are
bound. The remainder of the terms are straightforward.
x : A ⊢x : A
T var
· ⊢unit : I
T Ur
Γ2 ⊢t1 : A
Γ1, x : A, Γ3 ⊢t2 : B
Γ1, Γ2, Γ3 ⊢[t1/x]t2 : B
T cut
Γ1, Γ2 ⊢t : A
Γ1, x : I, Γ2 ⊢let x be unit in t : A
T Ul
Γ, x : A, y : B, Γ ′ ⊢t : C
Γ, z : A ⊗B, Γ ′ ⊢let z be x ⊗y in t : C
T Tl
Γ1 ⊢t1 : A
Γ2 ⊢t2 : B
Γ1, Γ2 ⊢t1 ⊗t2 : A ⊗B
T Tr
Γ2 ⊢t1 : A
Γ1, x : B, Γ3 ⊢t2 : C
Γ1, z : A ⇀B, Γ2, Γ3 ⊢[appr z t1/x]t2 : C
T IRl
Γ2 ⊢t1 : A
Γ1, x : B, Γ3 ⊢t2 : C
Γ1, Γ2, z : B ↼A, Γ3 ⊢[appl z t1/x]t2 : C
T ILl
Γ, x : A ⊢t : B
Γ ⊢λrx : A.t : A ⇀B
T IRr
x : A, Γ ⊢t : B
Γ ⊢λlx : A.t : B ↼A
T ILr
Fig. 2. Typing rules for the Typed Lambek Calculus: λL
The typing rules can be found in the in Fig. 2 and the reduction rules in Fig. 3.
The typing rules are as one might expect. The reduction rules were extracted
from the cut-elimination procedure for L.

266
V. de Paiva and H. Eades III
appl (λlx : A.t2) t1 ⇝[t1/x]t2
R Betal
appr (λrx : A.t2) t1 ⇝[t1/x]t2
R Betar
let t1 be unit in [unit/z]t2 ⇝[t1/z]t2
R BetaU
let t1 ⊗t2 be x ⊗y in t ⇝[t1/x][t2/y]t
R BetaT1
let t1 be x ⊗y in [x ⊗y/z]t2 ⇝[t1/x]t2
R BetaT2
[let t1 be unit in t2/z]t3 ⇝let t1 be unit in [t2/z]t3
R NatU
[let t1 be x ⊗y in t2/z]t3 ⇝let t1 be x ⊗y in [t2/z]t3
R NatT
let unit be unit in t ⇝t
R LetU
Fig. 3. Rewriting rules for the Lambek Calculus: λL
We denote the reﬂexive and transitive closure of the ⇝by ⇝∗. We call a
term with no β-redexes a normal form, and we denote normal forms by n. In
the interest of space we omit the congruence rules from the deﬁnition of the
reduction relation; we will do this for each calculi introduced throughout this
section. The other typed calculi we introduce below will be extensions of λL,
thus, we do not reintroduce these rules each time for readability.
Strong normalization. It is well known that intuitionistic linear logic (ILL) is
strongly normalizing, for example, see Bierman’s thesis [4] or Benton’s beautiful
embedding of ILL into system F [3].
It is fairly straightforward to deﬁne a reduction preserving embedding of λL
into ILL. Intuitionistic linear logic can be obtained from λL by replacing the
rules T IRl, T ILl, T IRr, and T ILr with the following two rules:
Γ2 ⊢t1 : A
Γ1, x : B, Γ3 ⊢t2 : C
Γ1, z : A ⊸B, Γ2, Γ3 ⊢[z t1/x]t2 : C
T Il
Γ, x : A ⊢t : B
Γ ⊢λx : A.t : A ⊸B
T Ir
In addition, contexts are considered multisets, and hence, exchange is handled
implicitly. Then we can reuse the idea of Benton’s embeddings to show type
preservation and type reduction.
At this point we deﬁne the following embeddings.
Deﬁnition 7. We embed types and terms of λL into ILL as follows:

Dialectica Categories for the Lambek Calculus
267
Types:
Ie = I
(A ⊗B)e = Ae ⊗B e (A ⇀B)e = Ae ⊸B e
(A ↼B)e = Ae ⊸B e
Terms:
x e = x
unite = unit
(t1 ⊗t2)e = t1
e ⊗t2
e
(let t1 be p in t2)e = let t1
e be p in t2
e
(λlx : A.t)e = λx : A.te
(λrx : A.t)e = λx : A.te
(appl t1 t2)e = t1
e t2
e
(appr t1 t2)e = t1
e t2
e
The previous embeddings can be extended to contexts in the straightforward way,
and to sequents as follows:
(Γ ⊢t : A)e = Γ e ⊢te : Ae
We can now prove strong normalization using the embedding preserves.
Theorem 3 (Strong Normalization)
– If Γ ⊢t : A in λL, then Γ e ⊢te : Ae in ILL.
– If t1 ⇝t2 in λL, then t1e ⇝t2e in ILL.
– If Γ ⊢t : A, then t is strongly normalizing.
Proof. The ﬁrst two cases hold by straightforward induction on the form of the
assumed typing or reduction derivation. They then imply the third.
Conﬂuence. The Church-Rosser property is well known to hold for ILL modulo
commuting conversions, for example, see Theorem 19 of [4] on page 96. Since
λL is essentially a subsystem of ILL, it is straightforward, albeit lengthly, to
simply redeﬁne Bierman’s candidates and carry out a similar proof as Bierman’s
(Theorem 19 on page 96 of ibid.).
Theorem 4 (Conﬂuence). The reduction relation, ⇝, modulo the commuting
conversions is conﬂuent.
6.2
The Typed Lambek Calculus: λL!
The calculus we introduce in this section is an extension of λL with the of-course
modality !A. This extension follows from ILL exactly. The syntax of types and
terms of λL are extended as follows:
(types) A := · · · |!A
(terms) t := · · · | copy t′ as t1, t2 in t | discard t′ in t | promote! t′ for t′′ in t |
derelict! t
The new type and terms are what one might expect, and are the traditional
syntax used for the of-course modality. We add the following typing rules to λL:
Γ1, x :!A, Γ2, y :!A, Γ3 ⊢t : B
Γ1, z :!A, Γ2, Γ3 ⊢copy z as x, y in t : B
T C
Γ1, Γ2 ⊢t : B
Γ1, x :!A, Γ2 ⊢discard x in t : B
T W
−→
x :!Γ ⊢t : B
−→
y :!Γ ⊢promote! −→
y for −→
x in t :!B
T Br
Γ1, x : A, Γ2 ⊢t : B
Γ1, y :!A, Γ2 ⊢[derelict! y/x]t : B
T Bl

268
V. de Paiva and H. Eades III
Finally, the reduction rules can be found in Fig. 4. The equality used in the
R BetaC rule is deﬁnitional, meaning, that the rule simply gives the terms on
the right side of the equation the name on the left side, and nothing more. This
makes the rule easier to read.
Strong normalization. Showing strong normalization for λL! easily follows by
a straightforward extension of the embedding we gave for λL.
Deﬁnition 8. The following is an extension of the embedding of λL into ILL
resulting in an embedding of types and terms of λL! into ILL. First, we deﬁne
(!A)e = !Ae, then the following deﬁnes the embedding of terms:
(copy t′ as t1, t2 in t)e = copy t′e as t1
e, t2
e in te
(discard t′ in t)e = discard t′e in te
(promote! t′ for t′′ in t)e = promote! t′e for t′′e in te
(derelict! t)e = derelict! te
Just as before this embedding is type preserving and reduction preserving.
Theorem 5 (Type and Reduction Preserving Embedding)
– If Γ ⊢t : A in λL!, then Γ e ⊢te : Ae in ILL.
– If t1 ⇝t2 in λL!, then t1e ⇝t2e in ILL.
– If Γ ⊢t : A, then t is strongly normalizing.
Proof. The ﬁrst two cases hold by straightforward induction on the form of the
assumed typing or reduction derivation. They then imply the third.
Conﬂuence. The Church-Rosser property also holds for λL!, and can be shown
by straightforwardly applying a slightly modiﬁed version of Bierman’s proof [4]
just as we did for λL. Thus, we have the following:
Theorem 6 (Conﬂuence). The reduction relation, ⇝, modulo the commuting
conversions is conﬂuent.
derelict! (promote!
−→t for −→
x in t1) ⇝[−→t /−→
x ]t1
R BetaDR
discard (promote!
−→t for −→
x in t1) in t2 ⇝discard −→t in t2
R BetaDI
t′
1 = promote! −→
w for −→
x in t1
t′′
1 = promote! −→z for −→
x in t1
copy (promote!
−→t for −→
x in t1) as w, z in t2 ⇝copy −→t as −→
w , −→z in [t′
1/w][t′′
1 /z]t2
R BetaC
[discard t in t1/x]t2 ⇝discard t in [t1/x]t2
R NatD
[copy t as x, y in t1/x]t2 ⇝copy t as x, y in [t1/x]t2
R NatC
Fig. 4. Rewriting rules for The Typed Lambek Calculus: λL!

Dialectica Categories for the Lambek Calculus
269
6.3
The Typed Lambek Calculus: λLκ
The next calculus we introduce is also an extension of λL with a modality that
adds exchange to λLκ denoted κA. It is perhaps the most novel of the calculi we
have introduced.
The syntax of types and terms of λL are extended as follows:
(types) A := · · · | κA
(terms) t := · · · | exchangel t1, t2 with x, y in t3 | exchanger t1, t2 with x, y in t3 |
promoteκ t′ for t′′ in t | derelictκ t
The syntax for types has been extended to include the exchange modality,
and the syntax of terms follow suit. The terms exchangel t1, t2 with x, y in t3 and
exchanger t1, t2 with x, y in t3 are used to explicitly track uses of exchange through-
out proofs.
We add the following typing rules to λL:
Γ1, x1 : κA, y1 : B, Γ2 ⊢t : C
Γ1, y2 : B, x2 : κA, Γ2 ⊢exchangel y2, x2 with x1, y1 in t : C
T E1
Γ1, x1 : A, y1 : κB, Γ2 ⊢t : C
Γ1, y2 : κB, x2 : A, Γ2 ⊢exchanger y2, x2 with x1, y1 in t : C
T E2
−
→
x : κΓ ⊢t : B
−
→
y : κΓ ⊢promoteκ −
→
y for −
→
x in t : κB
T Er
Γ1, x : A, Γ2 ⊢t : B
Γ1, y : κA, Γ2 ⊢[derelictκ y/x]t : B
T El
The reduction rules are in Fig. 5, and are vary similar to the rules from λL!.
derelictκ (promoteκ
−→t for −→
x in t1) ⇝[−→t /−→
x ]t1
R BetaEDR
[exchangel t1, t2 with x, y in t3/z]t4 ⇝exchangel t1, t2 with x, y in [t3/z]t4
R NatEl
[exchanger t1, t2 with x, y in t3/z]t4 ⇝exchanger t1, t2 with x, y in [t3/z]t4
R NatEr
Fig. 5. Rewriting rules for The Typed Lambek Calculus: λLκ
Strong normalization. Similarly, we show that we can embed λLκ into ILL,
but the embedding is a bit more interesting.
Deﬁnition 9. The following is an extension of the embedding of λL into ILL
resulting in an embedding of types and terms of λLκ into ILL. First, we deﬁne
(κA)e =!Ae, and then the following deﬁnes the embedding of terms:

270
V. de Paiva and H. Eades III
(exchangel t1, t2 with x, y in t3)e = [t2
e/x][t1
e/y]t3
e
(exchanger t1, t2 with x, y in t3)e = [t2
e/x][t1
e/y]t3
e
(promoteκ t′ for t′′ in t)e = promote! t′e for t′′e in te
(derelictκ t)e = derelict! te
The embedding translates the exchange modality into the of-course modality
of ILL. We do this so as to preserve the comonadic structure of the exchange
modality. One might think that we could simply translate the exchange modality
to the identity, but as Benton showed [3], this would result in an embedding that
does not preserve reductions. Furthermore, the left and right exchange terms are
translated away completely, but this works because ILL contains exchange in
general, and hence, does not need to be tracked explicitly. We now have strong
normalization and conﬂuence.
Theorem 7 (Strong Normalization)
– If Γ ⊢t : A in λL!, then Γ e ⊢te : Ae in ILL.
– If t1 ⇝t2 in λL!, then t1e ⇝t2e in ILL.
– If Γ ⊢t : A, then t is strongly normalizing.
– The reduction relation, ⇝, modulo the commuting conversions is conﬂuent.
Proof. The ﬁrst two cases hold by straightforward induction on the form of the
assumed typing or reductions derivation. They then imply the third case.
6.4
The Typed Lambek Calculus: λL!κ
If we combine all three of the previous typed Lambek Calculi, then we obtain the
typed Lambek Calculus λL!κ. The main characteristics of this system are that
it provides the beneﬁts of the non-symmetric adjoint structure of the Lambek
Calculus with the ability of having exchange, and the of-course modality, but
both are carefully tracked within the proofs.
Strong normalization for this calculus can be proved similarly to the previ-
ous calculi by simply merging the embeddings together. Thus, both modalities of
λL!κ would merge into the of-course modality of ILL. The Church-Rosser prop-
erty also holds for λL!κ by extending the proof of conﬂuence for ILL by Bierman
[4] just as we did for the other systems. Thus, we have the following results.
Theorem 8 (Strong Normalization). If Γ ⊢t : A, then t is strongly nor-
malizing.
Theorem 9 (Conﬂuence). The reduction relation, ⇝, modulo the commuting
conversions is conﬂuent.
7
Conclusions
We have recalled how to use biclosed posets and sets to construct dialectica-like
models of the Lambek Calculus. This construction is admittedly not the easiest
one, which is the reason why we use automated tools to verify our deﬁnitions, but

Dialectica Categories for the Lambek Calculus
271
it has one striking advantage. It shows how to introduce modalities to recover
the expressive power of intuitionistic (and a posteriori classical) propositional
logic to the system. We know of no other construction of models of Lambek
Calculus that does model modalities, not using their syntactic properties. (The
traditional view in algebraic semantics is to consider idempotent operators for
modalities like !). The categorical semantics here has been described before [10],
but the syntactic treatment of the lambda-calculi, in the style of [2] had not been
done and there were doubts about its validity, given the results of Jay [16]. We
are glad to put this on a ﬁrm footing, using another one of Benton’s ideas: his
embedding of intuitionistic linear logic into system F. Finally, we envisage more
work, along the lines of algebraic proof theory, for modalities and non-symmetric
type systems.
Acknowledgments. The authors would like to thank the anonymous reviewers for
their feedback which did make this a better paper. The second author was partially
supported by the NSF grant #1565557.
References
1. Abramsky, S.: Proofs as processes. Theor. Comput. Sci. 135(1), 5–9 (1994)
2. Benton, N., Bierman, G., de Paiva, V., Hyland, M.: A term calculus for Intuition-
istic Linear Logic. In: Bezem, M., Groote, J.F. (eds.) TLCA 1993. LNCS, vol. 664,
pp. 75–90. Springer, Heidelberg (1993). https://doi.org/10.1007/BFb0037099
3. Benton, P.N.: Strong normalisation for the linear term calculus. J. Funct. Program.
5(1), 65–80 (1995)
4. Bierman, G.M.: On Intuitionistic Linear Logic. PhD thesis, Wolfson College,
Cambridge, December 1993
5. Bierman, G.M., de Paiva, V.C.V.: On an intuitionistic modal logic. Stud. Logica
65(3), 383–416 (2000)
6. Bove, A., Dybjer, P., Norell, U.: A brief overview of Agda-a functional language
with dependent types. TPHOLs 5674, 73–78 (2009)
7. Ciabattoni, A., Galatos, N., Terui, K.: Algebraic proof theory for substructural
logics: Cut-elimination and completions. Ann. Pure Appl. Logic 163(3), 266–290
(2012)
8. Coecke, B., Grefenstette, E., Sadrzadeh, M.: Lambek vs. Lambek: Functorial vector
space semantics and string diagrams for Lambek calculus. Ann. Pure Appl. Logic
164(11), 1079–1100 (2013)
9. de Paiva, V.: The dialectica categories. PhD thesis, Computer Laboratory, Univer-
sity of Cambridge, PhD Thesis, 1990. Computer Laboratory, University of Cam-
bridge, PhD Thesis (1990)
10. de Paiva, V.: A Dialectica model of the Lambek calculus. In: 8th Amsterdam Logic
Colloquium (1991)
11. De Paiva, V.: Dialectica and chu constructions: Cousins? Theory Appl. Categories
17(7), 127–152 (2007)
12. Girard, J.-Y.: Linear logic. Theor. Comput. Sci. 50(1), 1–101 (1987)
13. Greco, G., Palmigiano, A.: Linear Logic Properly Displayed. ArXiv e-prints,
November 2016

272
V. de Paiva and H. Eades III
14. Honda, K., Laurent, O.: An exact correspondence between a typed pi-calculus and
polarised proof-nets. Theor. Compu. Sci. 411(22), 2223–2238 (2010)
15. Hyland, M., de Paiva, V.: Full intuitionistic linear logic (extended abstract). Ann.
Pure Appl. Logic 64(3), 273–291 (1993)
16. Barry Jay, C.: Coherence in category theory and the Church-Rosser property. Notre
Dame J. Formal Logic 33(1), 140–143 (1991). 12
17. Lafont, Y., Streicher, T.: Games semantics for linear logic. In: Proceedings of Sixth
Annual IEEE Symposium on Logic in Computer Science, 1991, LICS 1991, pp. 43–
50. IEEE (1991)
18. Lamarche, F., Retor´e, C.: Proof nets for the Lambek calculus - an overview. In:
Proceedings of the Third Roma Workshop. Proofs and Linguistic Categories, pp.
241–262 (1996)
19. Lambek, J.: The mathematics of sentence structure. In: American Mathematical
Monthly, pp. 154–170 (1958)
20. Moortgat, M.: Typelogical grammar. In: Zalta, E.N. (ed.) The Stanford Encyclo-
pedia of Philosophy, Spring 2014 edition (2014)
21. Polakow, J.: Ordered linear logic and applications. PhD thesis, Carnegie Mellon
University (2001)
22. Pratt, V.R.: Types as processes, via Chu spaces. Electr. Notes Theor. Comput.
Sci. 7, 227–247 (1997)
23. Sewell, P., Nardelli, F., Owens, S., Peskine, G., Ridge, T., Sarkar, S., Strnisa, R.:
Ott: Eﬀective tool support for the working semanticist. J. Funct. Program. 20,
71–122 (2010)
24. Szabo, M.E.: Algebra of Proofs. Studies in Logic and the Foundations of Mathe-
matics, vol. 88, North-Holland (1978, 1979)

From Epistemic Paradox to Doxastic Arithmetic
V. Alexis Peluce(B)
The Graduate Center of the City University of New York, New York City, USA
vpeluce@gradcenter.cuny.edu
Abstract. The logical analysis of epistemic paradoxes—including, for
example, the Moore and G¨odel-Buridan paradoxes—has traditionally
been performed assuming the whole range of corresponding modal logic
principles: {D, T, 4, 5}. In this paper, it is discovered precisely which of
those principles (including also the law of excluded middle, LEM) are
responsible for the paradoxical behavior of the Moore, G¨odel-Buridan,
Dual Moore, and Commissive Moore sentences. Further, by reproducing
these paradoxes intuitionistically we reject a conjecture that these para-
doxes are caused by the LEM. An exploration of the G¨odel-Buridan
sentence prompts the inquiry into a system, Doxastic Arithmetic, DA,
designed to represent the arithmetical beliefs of an agent who accepts all
speciﬁc arithmetical proofs and yet believes in the consistency of their
own beliefs. For these reasons, DA may be regarded as an epistemic way
to circumvent limitations of G¨odel’s Second Incompleteness Theorem.
Keywords: Modal logic · Epistemology · Paradoxes
Doxastic arithmetic
1
Introduction
Many ﬁnd the Moore sentence paradoxical. How can it be the case, it might be
asked, that one consistently assert: “it is raining but I do not believe that it is
raining?” If one asserts it, the reasoning would go, then it is strange to say that
they do not also believe it. But if they believe the conjunction, then we would be
inclined to say that they believe that it is raining. If we already have that it was
not the case that our agent believed it was raining, we will have a contradiction.
More clearly, the Moore sentence, M, is the following:
A ∧¬□A
Perhaps what we ﬁnd paradoxical about our situation is not that there is
some problem with M itself, but that something goes wrong with the related
believed Moore sentence, □M:
□(A ∧¬□A)
V. A. Peluce—The author would like to thank Sergei Artemov for discussion and
guidance throughout the development of this project.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 273–288, 2018.
https://doi.org/10.1007/978-3-319-72056-2_17

274
V. A. Peluce
Jaakko Hintikka put forth such a response to the Moore paradox in his
Knowledge and Belief, [10], p. 67. He writes, “In short, the gist of Moore’s para-
dox may be said (somewhat elliptically) to lie in the fact that [M] is necessarily
unbelievable by the speaker.” We will use paradoxicality in this sense of Hintikka,
to mean:
Hintikka Paradoxicality: A formula F is Hintikka Paradoxical in some logic
L if and only if F is satisﬁable in L, while □F is not satisﬁable in L.1
The goal of this paper is to investigate exactly the circumstances in which four
related sentences, the Moore sentence (A ∧¬□A), the G¨odel-Buridan sentence
(A ↔¬□A), the—introduced in this paper—Dual Moore sentence (¬A ∧□A),
and the Commissive Moore sentence (A ∧□¬A), are paradoxical. Note that for
A we have in mind some atomic proposition. Call these sentences M, G, DM ,
and CM , respectively. We aim to carry out this investigation in the general
epistemic context, that is, we will consider the modal logics both of belief and
of knowledge. Speciﬁcally, assuming iK (K over intuitionistic logic), we aim to
discover all subsets of principles from the set P where:
P = {LEM , D, T, 4, 5}
that make M, G, DM, and CM paradoxical in Hintikka’s sense. By starting with
iK rather than K itself, we extend our analysis to capture LEM—the Law of
Excluded Middle—as well.
Inquiry into these sentences, speciﬁcally the G¨odel-Buridan sentence prompts
further exploration of a system for representing arithmetical beliefs of an agent.
We call this system Doxastic Arithmetic, or DA. The idea is that DA allows us
to model beliefs of an agent who accepts all speciﬁc arithmetical proofs and yet
believes in the consistency of their own beliefs; it thus may be regarded as an
epistemic way to sidestep constraints imposed by G¨odel’s Second Incompleteness
Theorem.
2
Moore’s Paradox
The Moore sentence M is the sentence A ∧¬□A. M is paradoxical in the sense
that, in certain contexts, it is satisﬁable while □M is not. It is obvious that
the context of knowledge is one such context. More interesting for our purposes,
however, is the context of belief in which □is not factive.
In this section it is shown that in iKD4, the intuitionistic version of KD4,
□M is not satisﬁable. It is then shown that □M is satisﬁable in K45 and KD.
1 This notion is closely related to Hintikka’s similar concept of doxastic indefensibility,
[10], p. 71. Utterance, being of central importance to Hintikka’s concept, does not
enjoy the same status in our notion, however. Hintikka writes, “[W]e shall call the
set {p1, p2, . . . pk} doxastically indefensible for the person referred to by this term to
utter if and only if the sentence Ba(p1 & p2 & . . . & pk) is indefensible simpliciter.” A
natural question is: what Hintikka meant by a formula’s indefensibility simpliciter?
Given [10], p. 32, a natural answer is inconsistency.

From Epistemic Paradox to Doxastic Arithmetic
275
Along with the well-known observation that iKT ⊢¬□M, this provides an exact
characterization of the combination of principles from P which make M para-
doxical in our sense: M is paradoxical over a logic L = K + X where X ⊆P iﬀ
X contains either T or D + 4. This thus suggests that even though the Moore
sentence shares in some paradoxicality in the context of belief, neither 5 nor the
law of excluded middle are to blame. Even more D or 4 alone are not strong
enough to make M paradoxical in this sense.
Theorem 1. M is Hintikka Paradoxical over a logic L = iK + X where X ⊆P
iﬀX contains either D + 4, or T.
Proof. This follows from Lemmas 1, 2, 3, 4, and 5.
■
Lemma 1. M is satisﬁable in S5
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1, 2}. Let R = {(1, 1),
(1, 2), (2, 2), (2, 1)}. Here R is transitive, reﬂexive, and also euclidean; hence this
will be an S5 model. Let also 1 ⊩A and 2 ⊩¬A. Hence, also 1 ⊩¬□A. But
A ∧¬□A is M, the Moore sentence (Fig. 1).
■
Fig. 1. S5 model of M
Lemma 2. iKT ⊢¬□M 2
Proof. It suﬃces to establish that iKT + □M ⊢⊥
1. □(A ∧¬□A) - Assumption.
2. □A ∧□¬□A - K reasoning on 1.
3. □A ∧¬□A - T reasoning on 2.
4. ⊥- 3.
■
Lemma 3. iKD4 ⊢¬□M 3
Proof. It suﬃces to establish that iKD4 + □M ⊢⊥
1. □(A ∧¬□A) - Assumption.
2. □A ∧□¬□A - K reasoning on 1.
3. □□A ∧□¬□A - 4 reasoning on 2.
4. □□A ∧¬□□A - D reasoning on 3.
5. ⊥- From 4.
■
Lemma 4. □M is satisﬁable in KD5
Proof. Consider the three world model M = ⟨W, R, ⊩⟩. Let W = {1, 2, 3}. Let
R = {(1, 2), (2, 2), (2, 3), (3, 3)}. This is a D model insofar as every world can
access another world and is a 5 model because R is euclidean. This is not a 4
model, since R is not transitive. Let 2 ⊩A and 3 ⊩¬A. So, 2 ⊩M and 1 ⊩□M
(Fig. 2).
■
2 This sort of result is oﬀered in [10].
3 In its classical form, this sort of observation is not a new one, see for instance, [11],
p. 2. It is not clear, however, that this has been demonstrated in iKD4.

276
V. A. Peluce
Fig. 2. KD5 model of □M
Lemma 5. □M is satisﬁable in K45
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1}. Let R = ∅. This is
trivially a 4 and a 5 model. Clearly, 1 ⊩□M (Fig. 3).
■
Fig. 3. K45 model of □M
3
The G¨odel-Buridan Paradox
The philosophical tradition, see Tyler Burge’s [5] (1978),4 attributes the inves-
tigation into an interesting paradox to Jean Buridan. In that context, it is more
recently discussed in Michael Caie’s [6,7], though it has obvious ties to the work
of Kurt G¨odel.5 The paradox is the following sentence:
I don′t believe that this sentence is true.
In addition to a modality for belief, both a device for self-reference and a
truth predicate are employed. In this part of our discussion, however, we can set
the second and third of these features aside (though self-reference `a la G¨odel will
come up again in Sect. 7). We thus understand the G¨odel-Buridan sentence, G,
as the sentence A ↔¬□A.6 Now, in which cases is G paradoxical?
Theorem 2. G is Hintikka Paradoxical over a logic L = iK + X where X ⊆P
iﬀX contains either T or D + 4.
4 Burge writes that “In Sophism 13 of Chapter VIII Buridan supposes the following
proposition is written on the wall: Socrates knows the proposition written on the wall
to be doubted by him. Socrates reads it, thinks it through and is unsure (doubts)
whether or not it is true. Further, he knows that he doubts it. Buridan asks whether
or not the proposition is true.” [5], p. 22.
5 Caie in [6], pp. 16–17, conjectures that the law of excluded middle is to blame for
the refutability of □G in the context of belief. This is refuted by Theorem 2.
6 It would be more precise to use notation GA here since G actually depends on A
for the reasons mentioned. Since we said we would set those considerations aside for
now, we stick to a shorter notation.

From Epistemic Paradox to Doxastic Arithmetic
277
Proof. This follows from Lemmas 6, 7, 8, 9, and 10.
■
Lemma 6. G is satisﬁable in S5
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1, 2}. Let R = {(1, 1),
(1, 2), (2, 1), (2, 2)}. Each world can access each world, so this is an S5 model.
Let 1 ⊩A and 2 ⊩¬A. Clearly, 1 ⊩G.
■
The ﬁgure for this model is the same as the one in Lemma 1.
Lemma 7. iKT ⊢¬□G7
Proof. It suﬃces to show that iKT + □G ⊢⊥
1. □(A →¬□A) - Assumption.
2. □(¬□A →A) - Assumption.
3. □(□A →A) - Necessitation on T.
4. □(□A →¬□A) - From 1 and 3 by K reasoning.
5. □(□A →(□A ∧¬□A)) - From 4 by K reasoning.
6. □¬□A - From 5.
7. ¬□A - T on 6.
8. □¬□A →□A - K reasoning on 2.
9. □A - Modus Ponens on 6 and 8.
10. ⊥- 7 and 9.
■
Lemma 8. iKD4 ⊢¬□G
Proof. It suﬃces to show that iKD4 + □B ⊢⊥
1. □(A ↔¬□A) - Deﬁnition of □G.
2. □(A →(A ∧¬□A)) - propositional reasoning on 1.
3. □A →□(A ∧¬□A) - K reasoning on 2.
4. □A →(□A ∧□¬□A) - K reasoning on 3.
5. □A →(□□A ∧□¬□A) - 4 and K reasoning on 4.
6. □A →□(□A ∧¬□A) - K reasoning on 5.
7. □A →□⊥- K reasoning on 6.
8. □A →⊥- D and K reasoning on 7.
9. ¬□A - 8.
10. □¬□A - 9 and Necessitation.8
11. □A ↔□¬□A - K reasoning on 1.
12. □A - 10 and 11, Modus Ponens.
13. ⊥- 9 and 12 and propositional logic or 8 and 12 and Modus Ponens.
■
Lemma 9. □G is satisﬁable in KD5
7 The author thanks Sergei Artemov for this proof.
8 Necessitation is not always unproblematic, especially in the epistemic context. See,
for instance, Artemov’s [2]. It is admissible in this case, however, because ¬□A
follows using only iKD4 and □G.

278
V. A. Peluce
Proof. Consider the three world model M = ⟨W, R, ⊩⟩. Let W = {1, 2, 3}. Let
R = {(1, 2), (2, 2), (2, 3), (3, 3)}. This is a D model insofar as every world can
access another world and is a 5 model because R is euclidean. This is not a
4 model, since R is not transitive. Let 2 ⊩A and 3 ⊩¬A. So, 2 ⊩G and
1 ⊩□G.
■
This ﬁgure is the same as the one in Lemma 4.
Lemma 10. □G is satisﬁable in K45.
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1}. Let R = ∅. This is
trivially a 4 and a 5 model. Clearly, 1 ⊩□G.
■
This ﬁgure is the same as the one in Lemma 5.
4
Moore, G¨odel-Buridan, and Dual Moore
In the previous sections we explored the conditions in which M and G were
paradoxical. There are similarities between those two sentences, though those
similarities can be overstated.9 In this section, we show how G can be read as
a disjunction of M and something else. That something else, which we will call
the Dual Moore, is itself an interesting formula.
The reader will recall that G was the sentence:
A ↔¬□A
The following is a classical tautology:
((X ∧¬Y ) ∨(¬X ∧Y )) ↔(X ↔¬Y )
We can prove both of sides of the biconditional classically. In intuitionistic
logic, however, the →holds while ←fails. Substituting A for X and □A for Y ,
we get:
(A ∧¬□A) ∨(¬A ∧□A)
9 Caie [7], p. 36, discusses the Moore sentence as relates to G. There are some things
having to do with that discussion, though, that are worth clarifying. He writes,
“We’ve considered two classes of sentences, the Moore-paradoxical and the Burge-
Buridan sentences. It’s worth noting, however, that the latter class is really a subclass
of the former. In general, a Moore-paradoxical sentence is one that has the following
form φ ∧¬Bφ. A Burge-Buridan sentence, on the other hand, has the form ¬BT(β),
where β refers to that very sentence. On the surface, of course, this does not seem
to have the form of a Moore-paradoxical sentence. However, given the plausible
assumption that T(β) and ¬BT(β) are logically equivalent, then we get that ¬BT(β)
is, in fact, equivalent to T(β) ∧¬BT(β). Thus a Burge-Buridan sentence, while not
having the overt form of a Moore-paradoxical sentence, is equivalent to a Moore-
paradoxical sentence.” Though G does in fact share features with M, Caie’s claim
is too strong. For as we have shown, G is equivalent not to the Moore sentence M
but to the disjunction of the Moore and Dual Moore, DM.

From Epistemic Paradox to Doxastic Arithmetic
279
The sentence on the left side of the disjunction is just the Moore sentence,
M, which has been the focal point of much discussion in epistemology. Call the
sentence on the right side the Dual Moore or DM:
¬A ∧□A
5
The Dual Moore
We now turn our investigation to the Dual Moore sentence. As was seen in
Sect. 4, DM is one disjunct of G, the other being M. Now, M is paradoxical
even in the context of knowledge (insofar as M is satisﬁable in S5 while □M is
not). Unlike M, the Dual Moore does not make it to the knowledge context even
without a □. This suggests that DM is truly a paradox of belief. In this section,
we explore the properties of DM. We prove that DM is not satisﬁable in any
extension of T (tying DM uniquely to belief ), that DM is satisﬁable in KD45,
that □DM is not satisﬁable both iKD4 and iKD5, and that □DM is satisﬁable
in both K45 and KD.
Before moving on, though, we stop to acknowledge a related sentence, the
Commissive Moore, A ∧□¬A. This sentence will be the topic of Sect. 6. It will
turn out that though DM is classically equivalent to the Commissive Moore in
one of its forms, it is not intuitionistically equivalent, meaning thus that it is
worth examining the Dual and Commissive Moores separately.
First, it is obvious that DM is not satisﬁable, and hence not paradoxical, in
T. We now prove the following:
Theorem 3. DM is Hintikka Paradoxical over a logic L = iK+X where X ⊆P
iﬀX contains either D + 4 or D + 5.
Proof. This follows from the fact that DM is not satisﬁable in T and Lemmas 11,
12, 13, 14, and 15.
■
Lemma 11. DM is satisﬁable in KD45.
Proof. Consider the model M
=
⟨W, R, ⊩⟩. Let W = {1, 2}. Let R
=
{(1, 2), (2, 2)}. Here R is transitive, serial, and also euclidean; hence this will
be a KD45 model. Let 1 ⊩¬A and 2 ⊩A. Hence, also 1 ⊩□A. But ¬A ∧□A is
DM, the Dual Moore sentence (Fig. 4).
■
Fig. 4. KD45 model of DM

280
V. A. Peluce
Lemma 12. □DM is not satisﬁable in iKD4.
Proof. It suﬃces to check that iKD4 + □DM ⊢⊥
1. □(¬A ∧□A) - Assumption.
2. □¬A ∧□□A - K reasoning on 1.
3. □□¬A ∧□□A - 4 reasoning on 2.
4. □□(¬A ∧A) - K reasoning on 3.
5. ⊥- 4 D reasoning on 4.
■
Lemma 13. □DM is not satisﬁable in iKD5.
Proof. It suﬃces to check that iKD5 + □DM ⊢⊥
1. □(¬A ∧□A) - Assumption.
2. □¬A ∧□□A - K reasoning on 1.
3. ¬□A ∧□□A - D reasoning on 2.
4. □¬□A ∧□□A - 5 reasoning on 3.
5. □(¬□A ∧□A) - K reasoning on 4.
6. ¬□⊥- D.
7. ⊥- 5 and 6.
■
Lemma 14. □DM is satisﬁable in K45.
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1}. Let R = ∅. This
model is trivially a K45 model since R is transitive and euclidean. Clearly,
1 ⊩□DM .
■
This ﬁgure is the same as the one in Lemma 5.
Lemma 15. □DM is satisﬁable in KD.
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1, 2, 3}. Let R = {(1, 2),
(2, 3), (3, 3)}. This is a D model since R is serial. Let 2 ⊩¬A and 3 ⊩A. Hence,
1 ⊩□DM (Fig. 5).
■
Fig. 5. KD model of □DM

From Epistemic Paradox to Doxastic Arithmetic
281
6
The Commissive Moore
It might be pointed out that DM looks very much like another sentence, one also
discussed by Moore [13]: the Commissive Moore, or CM .10 It is the following:
A ∧□¬A
Within classical logic, DM and CM may be regarded equivalent. We should
not, however, expect this equivalence to hold intuitionistically. For this reason,
CM is worth studying independently.
First, it is immediate that CM is not satisﬁable in T.
Theorem 4. CM is Hintikka Paradoxical over a logic L = iK+X where X ⊆P
iﬀX contains either D + 4, or D + 5.
Proof. This is clear from the fact that CM is not satisﬁable in T, and Lemmas 16,
17, 18, 19, and 20.
■
Lemma 16. CM is satisﬁable in KD45.
Proof. Consider the model M
=
⟨W, R, ⊩⟩. Let W = {1, 2}. Let R
=
{(1, 2), (2, 2)}. Here R is transitive, serial, and also euclidean; hence this will
be a KD45 model. Let 1 ⊩A and 2 ⊩¬A. Hence, also 1 ⊩□¬A. But A ∧□¬A
is CM , the Commissive Moore sentence (Fig. 6).
■
Fig. 6. KD45 model of CM
Lemma 17. □CM is not satisﬁable in iKD4
Proof. It suﬃces to show that iKD4 + □CM ⊢⊥.
1. □(A ∧□¬A) - Assumption.
2. □A ∧□□¬A - K reasoning on 1.
3. □□A ∧□□¬A - 4 reasoning on 2.
4. □□(A ∧¬A) - K reasoning on 3.
5. ⊥- D reasoning on 4.
■
Lemma 18. □CM is not satisﬁable in iKD5
Proof. It suﬃces to show that iKD5 + □CM ⊢⊥.
10 For an overview of its discussion in the literature, see Green and Williams [12].

282
V. A. Peluce
1. □(A ∧□¬A) - Assumption.
2. □A ∧□□¬A - K reasoning on 1.
3. ¬□¬A ∧□□¬A - D reasoning on 2.
4. □¬□¬A ∧□□¬A - 5 reasoning on 3.
5. □(¬□¬A ∧□¬A) - K reasoning on 4.
6. ⊥- D reasoning on 5.
■
Lemma 19. □CM is satisﬁable in K45
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1}. Let R = ∅. Here
R is trivially transitive and euclidean; hence this will be a K45 model. Clearly,
1 ⊩□(A ∧□¬A).
■
This ﬁgure is the same as the one in Lemma 5.
Lemma 20. □CM is satisﬁable in KD.
Proof. Consider the model M = ⟨W, R, ⊩⟩. Let W = {1, 2, 3}. Let R = {(1, 2),
(2, 3), (3, 3)}. This is a D model since R is serial. Let 2 ⊩A and 3 ⊩¬A. Hence,
1 ⊩□CM (Fig. 7).
■
Fig. 7. KD model of □CM
7
Doxastic Arithmetic
What use can these epistemic-logical insights be put to? An intuitively appeal-
ing project is to create a model of the epistemic states of an idealized math-
ematician. In this section, we outline one method of achieving this goal:
Doxastic Arithmetic, or DA. We begin by stating DA. As will be seen, the epis-
temic notion we make use of, □(x), interpreted as “the agent believes that x,” is
explicitly a predicate and not a modal connective. We discuss the merits of this
approach. Next, we prove some properties about DA, including the facts that
□(x) respects both proofs and Σ sentences but is not complete with respect
to Pr(x). We then prove the ﬁxed point lemma for DA. This illuminates a key
diﬀerence between DA and systems that make use of □as a normal modal con-
nective; in those systems, no such ﬁxed point is provable. We then note that DA
has an arithmetical interpretation, hence DA is consistent.
A brief typographical note: following George Boolos [4], p. 45, we make use
of square bracket notation for G¨odel numbers of formulas. Where P(x) is some
predicate in the language of DA and F is a formula of DA with n free variables,
the formula P[F] is a formula of DA with the same n variables free as F. Note
thus that if F is a sentence, then P[F] also has no free variables.

From Epistemic Paradox to Doxastic Arithmetic
283
Where A is an atomic formula of Peano Arithmetic, PA, and F and G are
formulas of DA, the following provides the syntax of DA:
Φ = ⊥| A | F →G | F ∧G | F ∨G | ¬F | ∃xF | ∀xF | □[F]
Where s is a term, formula, or symbol of DA, the G¨odel number of s is ⌜s⌝.
Note that □(x) is a fresh designated unary predicate, and not a connective. This
distinguishes the current approach from those that make use of a □that is a
connective (see, for instance, Shapiro in [14] who takes the connective approach
for diﬀerent reasons). The consequences of this will be seen in Theorems 7 and 8.
The axioms and rules of DA are deﬁned as follows:
1. Axioms and rules of PA
2. □[F →G] →(□[F] →□[G])
3. ⊢F then ⊢□[F]
4. ¬□[⊥]
(1) is self-explanatory. We see in (2) an expression of K. We understand this
as the assumption that our mathematician’s beliefs are closed with respect to
deduction. This does involve some idealization, but this much seems intuitive.
(3) says that if DA ⊢F, that is, F is provable in DA using no assumptions, then
our agent believes that F. This is the analog of the modal Necessitation rule.
Lastly, (4) is the built-in consistency axiom. We read it as “The agent does not
believe that a contradiction holds.”
At this point we are in the position to prove some properties of DA. First,
we will see that □(x) respects proof, which is to say that if t is a speciﬁc proof
of F in DA, then our agent believes F. We symbolize that t is a proof of F with
Proof (t, ⌜F⌝). More formally, this says that t is a ﬁnite sequence of axioms,
formulas used in Modus Ponens, or ones in Universal Generalization.
Theorem 5. Belief Respects Proof: For each t, DA ⊢Proof (t, ⌜F⌝) →□[F]
Proof. There are two cases: either Proof (t, ⌜F⌝) is true or it is not. If
Proof (t, ⌜F⌝) is true, then it holds that t is a code for a proof of F. But
then DA ⊢F. By DA’s Necessitation, it follows that DA ⊢□[F], and so
DA ⊢Proof (t, ⌜F⌝) →□[F]. If Proof (t, ⌜F⌝) is not true, then ¬Proof (t, ⌜F⌝) is
true. Because ¬Proof (t, ⌜F⌝) is a provably primitive recursive formula, it follows
that DA ⊢¬Proof (t, ⌜F⌝). For any G, then, DA ⊢Proof (t, ⌜F⌝) →G. Thus,
DA ⊢Proof (t, ⌜F⌝) →□[F].
■
Next, we note that □(x) is complete with respect to Σ sentences.
Theorem 6. Σ Completeness of Belief: For each Σ sentence σ, DA ⊢σ →
□[σ]
Proof. By Theorem 5, we know that DA ⊢Proof (t, ⌜σ⌝) →□[σ] But then,
because it holds that DA ⊢σ →Proof (t, ⌜σ⌝) (see, for instance, Boolos’ [4],
pp. 46–49), we have thus shown that □(x) is Σ complete.
■

284
V. A. Peluce
Interestingly, the ﬁxed point lemma is also provable for ¬□(x).11
Theorem 7. Fixed Point Lemma for □: For some DA-formula G, it holds
that DA ⊢G ↔¬□[G].
Proof. We already know that for each predicate P(x) in the language of PA,
there is a formula G for which it holds that (cf., Boolos [4], p. 53):
PA ⊢G ↔P[G]
Then, DA can prove this as well with ¬□(x). We thus get the ﬁxed point
lemma for ¬□(x) in DA, that for some G:
DA ⊢G ↔¬□[G]
■
This brings out an important diﬀerence between the approach taken in this
paper, that of taking □(x) to be a predicate, and that of interpreting □as a
connective. The ﬁxed point lemma does not hold in systems with □as a modality
compatible with D + 4.
Theorem 8. For every normal modal logic L, where LD4 ⊬⊥, there is no A
such that L ⊢A ↔¬□A
Proof. Assume that L ⊢A ↔¬□A, then LD4 ⊢A ↔¬□A. But then, LD4 ⊢
□(A ↔¬□A) by Necessitation. In Lemma 8, we saw that LD4 ⊢¬□(A ↔¬□A).
So, LD4 ⊢⊥. Since LD4 ⊬⊥, it follows thus that L ⊬A ↔¬□A.
■
We now deﬁne an arithmetical interpretation ∗of DA.
Deﬁnition 1. An arithmetical interpretation of DA in PA is a pair (B(x),
∗)
in which B(x) is an arithmetical predicate such that for any PA-formulas F and
G it holds that:
1. PA ⊢B[F →G] →(B[F] →B[G])
2. PA ⊢F then PA ⊢B[F]
3. PA ⊢¬B[⊥]
And ∗is a mapping from the language of DA to that of PA such that:
4. F ∗= F, for each □-free formula
5. ∗commutes with Boolean connectives and quantiﬁers.
6. (□[F])∗= B[F ∗]
We now prove that DA has an interpretation in PA.
Lemma 21. DA has an interpretation in PA.
11 We follow the proofs in Boolos’ The Logic of Provability [4], pp. 53–54 and Hartry
Field’s Saving Truth from Paradox [9], pp. 26–27.

From Epistemic Paradox to Doxastic Arithmetic
285
Proof. Consider now one of the systems with non-G¨odelian proof predicates.
Take Sol Feferman’s system F (see [8] and Albert Visser’s [16], pp. 173–178,
esp. 174. See [16] also for other options of suitable systems with non-G¨odelian
proof predicates.). Feferman’s system has a predicate Δ(x) which satisﬁes the
following:
1f. PA ⊢Δ[F →G] →(Δ[F] →Δ[G])
2f. PA ⊢F then PA ⊢Δ[F]
3f. PA ⊢¬Δ[⊥]
Thus, interpreting B(x) as Δ(x), we see that DA in fact has an interpretation
in PA.
■
Lemma 22. Let (B(x),
∗) be an interpretation of DA in PA. Then, for any
DA-formula F, if DA ⊢F, then PA ⊢F ∗.
Proof. Induction on derivability in DA, that is, assume DA ⊢F and consider the
following cases:
Case 1: F is an instance of a logical or arithmetical axiom. Then, F ∗is also
an instance of the same logical or arithmetical axiom. So PA ⊢F ∗.
Case 2: F is an instance of modal axiom 1 or 3. By Deﬁnition 1 it is clear
that PA ⊢F ∗.
Case 3: F follows by Modus Ponens or Universal Generalization. These are the
same in both PA and DA. In the ﬁrst case, we assume that DA ⊢G, DA ⊢G →F
and also that PA ⊢G∗, PA ⊢G∗→F ∗. But then it is clear that PA ⊢F ∗. The
argument is similar for Universal Generalization.
Case 4: F follows by DA’s Necessitation. That is, F = □G and DA ⊢□G. By
induction hypothesis, PA ⊢G∗. It follows then that PA ⊢B[G∗]. But (□[G])∗=
B[G∗]. So, PA ⊢(□[G])∗. Hence, PA ⊢F ∗.
■
There is an important corollary to be drawn. Namely, the consistency of DA:
Corollary 1. Consistency of DA : DA ⊬⊥
Proof. By Lemma 22, if DA ⊢⊥then PA ⊢⊥∗. Since ⊥∗= ⊥, it would follow
that PA ⊢⊥. But, we know that PA ⊬⊥.12 So, DA ⊬⊥.
■
Insofar as Robinson Arithmetic Q is suﬃcient for the ﬁxed point lemma, Q
taken along with a KD4 unary predicate □(x) will be inconsistent. The proof
of this that we will present is nearly identical to that of Lemma 8; due to the
signiﬁcance of Lemma 23, we include the proof here too.
Lemma 23. KD4 + Q is inconsistent.
Proof. It suﬃces to show that K4 + D + Necessitation + G ⊢⊥.
1. □⊥→⊥- D.
12 See [3] for some discussion.

286
V. A. Peluce
2. A →¬□A - First half of G.
3. □(A →¬□A) - Necessitation on 2.
4. □A →□¬□A - K reasoning on 3.
5. □A →(□A ∧□¬□A) - Propositional reasoning on 4.
6. □A →(□□A ∧□¬□A) - 4 reasoning on 5.
7. □A →□(□A ∧¬□A) - K reasoning on 6.
8. □A →□⊥- 7.
9. □A →⊥- 1 and 8.
10. ¬□A - 9.
11. ¬□A →A - Second half of G.
12. A - Modus Ponens with 10 and 11.
13. □A - Necessitation on 12.
14. ⊥- 10 and 13.
■
A corollary of Lemma 23, then, is that there is no interpretation of a predicate
□(x) with these properties in PA:
Corollary 2. There is no interpretation of □(x) in PA, where □(x) is under-
stood explicitly as a KD4 predicate.
Proof. Assume that there were such an interpretation. By the ﬁxed point lemma,
we would be able to construct a G such that PA ⊢G ↔¬□[G]. By Lemma 23,
this would mean that PA ⊢⊥. But PA is not inconsistent. So, there is no inter-
pretation of □(x) in PA.
■
It is worth noting some advantages that DA will enjoys. First, DA allows for a
ﬁxed point lemma for □(x), as we saw in Theorem 7, and therefore incorporates
G¨odel’s argument. Contrast this with systems that make use of □as a modal
connective, which we saw in Theorem 8 will not admit of any ﬁxed point provided
they are normal and consistent with KD4.
It might be objected: our agent should also believe that they believe every-
thing that they believe. So, since □(x) of DA does not have an analog of the 4
axiom, DA falls short as a representation of such an agent.
But should an agent simply believe that they believe everything that they
believe? For at least one reason, related to the sorts of reasons that motivate
explicit approaches to epistemic logic more generally, the answer seems to be
“no.” The idea would be that, following reasoning in Arthemov’s [1], p. 6, we do
not simply grant that because our agent believes in F based on some evidence,
they also believe that they believe in F based on that evidence. The thought is
that some further justiﬁcation or piece of evidence would be required to warrant
this higher order belief.
Is it obvious that we should build an evidence based belief predicate into
the model of our agent? For instance, the argument might go, “think of people
from (place that is viewed negatively). They believe all sorts of falsehoods for no
reason!” That such a tendency to dismiss the beliefs of others as being without
reason exists is undeniable. The question is whether or not this sort of dismissal is
metaphorical in some sense. After all, it does seem plausibly interpreted instead

From Epistemic Paradox to Doxastic Arithmetic
287
as “those people believe all sorts of falsehoods for terrible reasons” or even “those
people believe all sorts of falsehoods for no good reasons.” Hence it seems not
implausible—or at least this speciﬁc appeal to natural language does not make
it seem implausible—to endorse an evidence based picture of belief.
Another advantage of DA is that it underlies the class of arithmetical prov-
ability predicates with built-in consistency. These systems are studied extensively
in Visser’s [16] and Shavrukov’s [15]. As DA is not tied down to any one speciﬁc
arithmetic interpretation of □(x), it is an abstract and more general version of
those systems.
The current formulation of DA is intentionally kept independent of any spe-
ciﬁc proof predicate to provide a code-free axiomatization of arithmetical beliefs.
Two natural candidates, however, come to mind for connecting the belief modal-
ity with standard proof predicates:
Pr[F] →□[F]
(1)
or
□[F] →Pr[F]
(2)
for the G¨odel proof predicate Pr(x) in the reference system. However, (1) makes
this version of DA inconsistent insofar as ⊢¬□[⊥] →¬Pr[⊥] and ⊢¬□[⊥] yields
⊢¬Pr[⊥]. This would mean that the G¨odel consistency of the reference system
is internally provable, which, by G¨odel’s Incompleteness Theorem, in turn yields
the inconsistency of the reference system. Adding (2) is consistent, however,
since both the Rosser and Feferman provability predicates satisfy (2) (see [16],
pp. 166, 169, and 173–175).
8
Conclusions
In this paper we have discovered the minimal conditions in which M, G, DM
and CM are paradoxical in Hintikka’s sense. The Moore sentence was minimally
paradoxical in iKT and iKD4. Like the Moore, the G¨odel-Buridan sentence was
also minimally paradoxical in iKT and iKD4. Interestingly, the Dual Moore sen-
tence was minimally paradoxical in iKD4 or iKD5, but not iKT. The Commissive
Moore was also minimally paradoxial in iKD4 and iKD5. We noted that classi-
cally, the Dual and Commissive Moores will be equivalent though clearly this
equivalence will fail to hold in the intuitionistic context.
One line of analysis suggested by the ﬁrst part of this paper was pursued
in the second part of this paper. Speciﬁcally, we built a system DA of Doxas-
tic Arithmetic that models the agent’s arithmetical beliefs. The agent accepts
all speciﬁc arithmetical proofs and yet believes in the consistency of their own
beliefs. We proved important properties of this system, including its ﬁxed point
lemma and its consistency, and then discussed its merits and motivations.

288
V. A. Peluce
References
1. Artemov, S.: Explicit provability and constructive semantics. Bull. Symbolic Logic
7, 1–36 (2001)
2. Artemov, S.: Knowing the model. Published online at: arXiv:1610.04955 [math.LO]
(2016)
3. Bernays, P.: On the original Gentzen proof for number theory. In: Intuitionism and
Proof Theory. Proceedings of the Summer Conference at Buﬀalo, NY, 1968, vol.
60, pp. 409–417 (1970)
4. Boolos, G.: The Logic of Provability. Cambridge University Press, Cambridge
(1995)
5. Burge, T.: Buridan and epistemic paradox. Philos. Stud. Int. J. Philos. Anal. Tra-
dit. 34, 21–35 (1978)
6. Caie, M.: Belief and indeterminacy. Philos. Rev. 121, 1–54 (2012)
7. Caie, M.: Doxastic logic. In: Weisberg, J., Pettigrew, R. (eds.) Open Hand-
book of Formal Epistemology (2017). Forthcoming. https://sites.google.com/site/
caiemike/
8. Feferman, S.: Arithmetization of metamathematics in a general setting. Funda-
menta Mathematica 49, 35–92 (1960)
9. Field, H.: Saving Truth from Paradox. Oxford University Press, Oxford (2008)
10. Hintikka, J.: Knowledge and Belief: An Introduction to the Logic of the Two
Notions. Cornell University Press, Ithaca (1962)
11. Holliday, W., Icard, III, T.F.: Moorean phenomena in epistemic logic. In: Goranko,
V., Shehtman, V. (eds.) Advances in Modal Logic, vol. 8, pp. 178–199 (2010)
12. Green, M., Williams, J.N.: Introduction. In: Green, M., Williams, J.N. (eds.)
Moore’s Paradox: New Essays on Belief, Rationality, and the First Person. Oxford
University Press (2007)
13. Moore, G.E.: Russell’s theory of descriptions. In: Schilpp, P. (ed.) The Philosophy
of G.E. Moore, pp. 175–225 (1944)
14. Shapiro, S.: Epistemic and intuitionistic arithmetic. Stud. Logic Found. Math. 118,
11–46 (1985)
15. Shavrukov, V.Y.: A smart child of Peano’s. Notre Dame J. Formal Logic 35(2),
161–185 (1994)
16. Visser, A.: Peano’s smart children: a provability logical study of systems with
built-in consistency. Notre Dame J. Formal Logic 30(2), 161–196 (1998)

A Natural Proof System
for Herbrand’s Theorem
Benjamin Ralph(B)
University of Bath, Bath, UK
b.d.ralph@bath.ac.uk
http://people.bath.ac.uk/bdr25
Abstract. The reduction of undecidable ﬁrst-order logic to decidable
propositional logic via Herbrand’s theorem has long been of interest to
theoretical computer science, with the notion of a Herbrand proof moti-
vating the deﬁnition of expansion proofs. The problem of building a nat-
ural proof system around expansion proofs, with composition of proofs
and cut-free completeness, has been approached from a variety of dif-
ferent angles. In this paper we construct a simple deep inference system
for ﬁrst-order logic, KSh2, based around the notion of expansion proofs,
as a starting point to developing a rich proof theory around this foun-
dation. Translations between proofs in this system and expansion proofs
are given, retaining much of the structure in each direction.
Keywords: Structural proof theory · First-order logic
Deep inference · Herbrand’s theorem · Expansion proofs
1
Introduction
A focus on the existential witnesses created in proofs has long been central
to ﬁrst-order proof theory. If one ignores all other information about a ﬁrst-
order proof except for the details of existential introduction rules, one still has
an important kernel of the proof, in some sense the part of the proof that is
inherently ﬁrst-order, as opposed to merely propositional. Herbrand, in [13],
innovated an approach to ﬁrst-order proof theory that isolates this ﬁrst-order
content of the proof, and today the notion of a Herbrand proof is common, a
proof-theoretic object that shows the carrying out of the following four steps,
usually but not always in this order:
1. Expansion of existential subformulae.
2. Prenexiﬁcation/elimination of universal quantiﬁers.
3. Term assignment.
4. Propositional tautology check.
This research has been supported by EPSRC Project EP/K018868/1 Eﬃcient and
Natural Proof Systems and ANR project FISP ANR-15-CE25-0014-01.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 289–308, 2018.
https://doi.org/10.1007/978-3-319-72056-2_18

290
B. Ralph
For example, we have the following theorem from [8] which exactly follows this
scheme:
Theorem 1 (Herbrand’s theorem). A ﬁrst-order formula A is valid if
and only if A has a Herbrand proof. A Herbrand proof of A consists of a
prenexiﬁcation A⋆of a strong ∨-expansion of A plus a witnessing substitution σ
for A⋆.
Or take the presentation of Herbrand’s theorem in a deep inference system in [7]:
Theorem 2 (Herbrand’s theorem). For each proof of a formula S in sys-
tem SKSgr there is a substitution σ, a propositional formula P, a context Q{ }
consisting only of quantiﬁers and a Herbrand proof:
KS∪{ai↑}
∀xPσ
{n↓}
Q{P}
{gr↓}
S′
{qc↓}
S
One obvious diﬀerence between the two formulations is that while the ﬁrst deﬁ-
nition of a Herbrand proof does not involve a proof in any commonly used proof
system, the second deﬁnition is based around a factorisation of a proof in deep
inference. Thus, the second deﬁnition gives us more opportunities to manipulate,
compose and identify Herbrand proofs as proof theoretic objects.
The basic observation of this paper is that deﬁning Herbrand proofs in a
deep inference setting is easier and more natural than doing so in Gentzen-style
systems (in particular the Sequent Calculus and Natural Deduction). This is
because the steps (1), (2) and (3) as deﬁned above are standard inference rules
in ﬁrst-order deep inference proof systems, and, while it is obviously possible to
include them as ad hoc rules, they are not natural for Gentzen-style systems,
especially carried out in this order.
To put it another way: if we want to build a proof theory around Herbrand’s
theorem, in which the propositional and ﬁrst-order content of a cut-free proof
is separated in a natural way, then deep inference is a superior setting to the
sequent calculus, in some concrete senses. To substantiate this claim, we deﬁne
two inter-translatable classes of deep inference proofs. The ﬁrst class comprises
analytic Herbrand proofs, deﬁned similarly to those in Theorem 2 above, and
we borrow a result from [7] to show that the class is complete for FOL. We
show a tight correspondence between the second class and expansion proofs,
a minimalistic formalism for ﬁrst-order (and higher-order) proofs that ignores
all but the most essential ﬁrst-order structure. This correspondence suggests
the second class as a good candidate for canonical ﬁrst-order proofs. Therefore,
the translation between the two classes enables us to see Herbrand proofs as
canonical ﬁrst-order proofs.

A Natural Proof System for Herbrand’s Theorem
291
It should be noted that, while a translation between expansion proofs and
ﬁrst-order deep inference proofs has not previously been shown, Straßburger
has developed a notion of expansion proofs for MLL2, and provided a similar
translation between these structures and a deep inference proof system for that
logic [18,19].
2
Expansion Proofs
In [17], Miller generalises the concept of the Herbrand expansion to higher order
logic, representing the witness information in a tree structure, and explicit trans-
formations between these ‘expansion proofs’ and cut-free sequent proofs are pro-
vided. Miller’s presentation of expansion proofs lacked some of the usual features
of a formal proof system, crucially composition by an eliminable cut, but exten-
sions in this direction have been carried out by multiple authors. In [12], Heijltjes
presents a system of ‘proof forests’, a graphical formalism of expansion proofs
with cut and a local rewrite relation that performs cut elimination. Similar work
has been carried out by McKinley [16] and more recently by Hetzl and Weller
[14] and Alcolei et al. [1]. As expansion proofs and the related formalisms only
represent the ﬁrst-order content of a proof, we will ﬁrst deﬁne expansion proofs
in order to guide the deﬁnition of the proof systems.
Remark 1. Throughout the paper, we use ⋆in place of ∧and ∨, and Q in place of ∀
and ∃if both cases can be combined into one. For clarity, we will sometimes distin-
guish between connectives in expansion trees, ⋆E, and in formulae/derivations, ⋆F .
Deﬁnition 1. We deﬁne expansion trees, the two functions Sh (shallow) and
Dp (deep) from expansion trees to formulae, a set of eigenvariables EV (E) for
each expansion tree, and a partial function Lab from edges to terms, following
[9,12,17]:
1. Every literal A (including the units t and f) is an expansion tree. Sh(A) := A,
Dp(A) := A, and EV (A) = ∅.
2. If E1 and E2 are expansion trees with EV (E1)∩EV (E2) = ∅, then E1 ⋆E2 is
an expansion tree, with Sh(E1 ⋆E E2) := Sh(E1) ⋆F Sh(E2), Dp(E1 ⋆E E2) :=
Dp(E1) ⋆F Dp(E2), and EV (E1 ⋆E2) = EV (E1) ∪EV (E2). We call ⋆a ⋆-
node and each unlabelled edge ei connecting the ⋆-node to Ei a ⋆-edge. We
represent E1 ⋆E2 as:
⋆
E1
e1
E2
e2
3. If E′ is an expansion tree s.t. Sh(E′) = A and x /∈EV (E′), then E =
∀xA +x E′ is an expansion tree with Sh(E) := ∀xA, Dp(E) := Dp(E′), and
EV (E) := EV (E′) ∪{x}. We call ∀xA a ∀-node and the edge e connecting
the ∀-node and E′ a ∀-edge, with Lab(e) = x. We represent E as:

292
B. Ralph
∀xA
E′
x
e
4. If t1, . . . , tn are terms (n ≥0), and E1, . . . , En are expansion trees s.t. x /∈
EV (Ei) and EV (Ei) ∩EV (Ej) = ∅for all 1 ≤i < j ≤n, and Sh(Ei) =
A{x ⇐ti}, then E = ∃xA +t1 E1 +t2 · · · +tn En is an expansion tree, where
Sh(E) := ∃xA, Dp(E) := Dp(E1) ∨· · · ∨Dp(En), and EV (E) = n
1 EV (Ei).
We call ∃xA an ∃-node and each edge ei connecting the ∃-node with Ei an
∃-edge, with Lab(ei) = ti. We represent E as:
∃xA
E1
e1
t1 · · ·
En
en
tn
Remark 2. Let ρ be a permutation of [1 . . . n]. We consider the expansion trees
∃xA +t1 E1 +t2 · · · +tn En and ∃xA +tρ(1) Eρ(1) · · · +tρ(n) Eρ(n) equal. Our trees
are also presented the other way up to usual, e.g. [12]. This is so that they are
the same way up as the deep inference proofs we will translate them to below.
Deﬁnition 2. Let E be an expansion tree and let <−
E be the relation on the
edges in E deﬁned by:
– e <−
E e′ if the node directly below e is the node directly above e′.
– e <−
E e′ if e is an ∃-edge with Lab(e) = t, there is an x which is free in t, e′
is a ∀-edge and Lab(e′) = x. In this case, we say e′ points to e.
The dependency relation of E, <E, is the transitive closure of <−
E.
Deﬁnition 3. An expansion tree E is correct if <E is acyclic and Dp(E) is a
tautology. We can then call E an expansion proof of Sh(E).
Example 1. Below is an expansion tree E, with Sh(E) = ∃x∀y[ ¯Px ∨Py] and
Dp(E) = [ ¯Pc ∨Py1] ∨[ ¯Py1 ∨Py2]. The tree is presented with all edges explicitly
named, to deﬁne the dependency relation below, as well as the labels for the
∃-edges and ∀-edges.
∃x∀y[ ¯Px ∨Py]
∀y1[ ¯Pc ∨Py1]
∨
¯Pc
e1
Py1
e2
y1
e5
c
e7
∀y2[ ¯Py1 ∨Py2]
∨
¯Py1
e3
Py2
e4
y2
e6
e8
y1

A Natural Proof System for Herbrand’s Theorem
293
The dependency relation is generated by the following inequalities: e3, e4 < e6 <
e8 and e1, e2 < e5 < e7 and e8 < e5. e5 points to e8. As this dependency relation
is acyclic and [ ¯Pc ∨Py1] ∨[ ¯Py1 ∨Py2] is a tautology, E is correct, and thus an
expansion proof.
3
Proof Systems
3.1
Motivation for the Proof Systems
What features would a proof system, PS, designed around Expansion Proofs,
EP, have? Say we have a translation π : EP →PS.
Firstly, we might want that composition of proofs in PS matches closely to
composition of expansion proofs, that something close to functoriality of π holds:
π(E1 ⋆E E2) ≈π(E1) ⋆F π(E2)
For Gentzen-style systems this will prove diﬃcult, as there is no natural way to
compose two proofs by disjunction.
A second attractive feature would be that we could isolate a part of the
proof system that is relevant to Herbrand’s theorem, stating and proving it as a
factorisation of proofs, where the ﬁrst order content of the proof is isolated from
the propositional content:
π(E) =
πUp(E)
P rop
Dp(E)
πLo(E)
F O
Sh(E)
Interestingly, this is impossible in the usual sequent calculus systems, which we
can see by considering Br¨unnler’s second restriction on contraction. Consider
the following property of proof systems:
“Proofs can be separated into two phases (seen bottom-up): The lower phase
only contains instances of contraction. The upper phase contains instances of
the other rules, but no contraction. No formulae are duplicated in the upper
phase” [6].
Br¨unnler shows that a standard sequent calculus proof system with multi-
plicative rules cannot satisfy this property. The suggested way round this restric-
tion is to use systems with deep contraction. In fact, this restriction on sequent
calculus systems is shown by McKinley in [15] to create a gap in Buss’s proof
of Herbrand’s theorem in [8]. The faulty proof assumes that if one restricts
contraction to only existential formulae, one retains completeness (assuming a
multiplicative ∧R rule). That this is false can be seen by considering the sequent
below, where the application of any multiplicative ∧R rule leads to an invalid
sequent:
⊢∀xA ∧∀xB,

∃x ¯A ∨∃x ¯B

∧
∃x ¯A ∨∃x ¯B


294
B. Ralph
Thus to achieve the desired factorisation property, we either need to add
unrestricted contraction by the back-door, say by using additive ∧R rules, or use
a system with deep contraction.
Both the above considerations suggest the formalism of open deduction for
proofs of Herbrand’s theorem [10]. It is a deep inference formalism which allows
for free composition of proofs by ∧and ∨at the propositional level, satisfying
the ﬁrst desideratum. Also, the deep contraction rule is certainly a natural rule
for a deep inference system, allowing us to satisfy the second desideratum.
3.2
Open Deduction
As discussed above, we will work in the open deduction formalism. Open deduc-
tion diﬀers from the sequent calculus in that we build up complex derivations
with connectives and quantiﬁers in the same way that we build up formulae [10].
We can compose two derivations horizontally with ⋆, quantify over derivations,
and compose derivations vertically with an inference rule.
Deﬁnition 4. An open deduction derivation is inductively deﬁned in the follow-
ing way:
– Every atom Pt1 . . . tn is a derivation, where P is an n-ary predicate, and ti
are terms. The units t and f are also derivations.
If
A
φ
B
and
C
ψ
D
are derivations, then:
–
A ⋆C
φ⋆ψ
B ⋆D
=
A
φ
B
⋆
C
ψ
D
and
QxA
Qxφ
QxB
= Qx
⎡
⎣
A
φ
B
⎤
⎦are derivations.
–
A
χ
D
=
A
φ
B
ρ
C
ψ
D
is a derivation, if
B
ρ
C is an instance of ρ.
When we write
A
φ
S
B
, it means that every inference rule in φ is an element of the
set S or an equality rule.
Remark 3. Formulae are just derivations built up with no vertical composition.
Open deduction and the calculus of structures (the better known deep inference
formalism) polynomially simulate each other [11].
Deﬁnition 5. We deﬁne a section of a derivation in the following way:

A Natural Proof System for Herbrand’s Theorem
295
– Every atom a has one section, a.
– If A is a section of φ, and B is a section of ψ, then A ⋆B is a section of
φ ⋆ψ, and QxA is a section of Qxφ.
– If A is a section of
B
φ1
C
or
D
φ2
E
and φ =
B
φ1
C
ρ
D
φ2
E
then A is a section of φ.
The premise and conclusion of a derivation are, respectively, the uppermost and
lowermost section of the derivation. A proof of A is a derivation with premise t
and conclusion A, sometimes written
φ
A.
Deﬁnition 6. We deﬁne the rewriting system Seq as containing the following
two rewrites Sl and Sr:
A
K
	
A1
ρ1 B1

{A2}
=
K {B1}
	
A2
ρ2 B2

B
Sl
←−−
A
K
	
A1
ρ1 B1

 	
A2
ρ2 B2

B
Sr
−−→
A
K {A1}
	
A2
ρ2 B2

=
K
	
A1
ρ1 B1

{B2}
B
If φ is in normal form w.r.t. Seq, we say φ is in sequential form. If φ −→∗
Seq ψ
and ψ is in sequential form, we say that ψ is a sequentialisation of φ.
Proposition 1. A derivation φ is in sequential form iﬀ. It is in the following
form, where ρi are all the non-equality rules:
A
=
K1
	
A1
ρ1 B1

=
...
=
Kn
	
An
ρn Bn

=
B
Deﬁnition 7. A closed derivation is one where every section of the derivation
is a sentence (i.e. a formula with no free variables).

296
B. Ralph
3.3
KSh1 and Herbrand Proofs
We can now deﬁne an open deduction proof system for Herbrand proofs. We will
extend the propositional system KS [5]:
KS =
t
ai↓
a ∨¯a
a ∨a
ac↓
a
f
aw↓
a
A ∧[B ∨C]
s
(A ∧B) ∨C
(A ∧B) ∨(C ∧D)
m
[A ∨C] ∧[B ∨D]
+
A ∧t
=
A
A ∨f
=
A
t ∨t
=
t
f ∧f
=
f
A ∧(B ∧C) = (A ∧B) ∧C A ∨[B ∨C] = [A ∨B] ∨C
A ∧B
=
B ∧A
A ∨B
=
B ∨A
We will write
A
=
B if B can be obtained from A by equality rules (treating
multiple instances of diﬀerent equality rules as one instance of a general equality
rule).
We now introduce rules for the ﬁrst three steps of a Herbrand Proof:
1. For expansion of existential subformulae, we have the rule:
∃xA ∨∃xA
qc↓
∃xA
For technical reasons, we insist that all three instances of ∃xA in qc↓are
α-equivalent with unique bound variables, but as above we will sometimes
refer to them all as ∃xA for simplicity.
2. For prenexiﬁcation, we have four rules, where B is free for x:
∀x[A ∨B]
r1↓
∀xA ∨B
∀x(A ∧B)
r2↓
∀xA ∧B
∃x[A ∨B]
r3↓
∃xA ∨B
∃x(A ∧B)
r4↓
∃xA ∧B
We consider commutative variants of these rules valid instances, e.g.
∀x[B ∨A]
r1↓
B ∨∀xA .
3. For term assignment, we have the rule:
A{x ⇐t}
n↓
∃xA

A Natural Proof System for Herbrand’s Theorem
297
Deﬁnition 8. We deﬁne a proof system for FOL, KSh1:
KSh1 = KS +
∀x[A ∨B]
r1↓
[∀xA ∨B]
∀x(A ∧B)
r2↓
(∀xA ∧B)
A{x ⇐t}
n↓
∃xA
∃x[A ∨B]
r3↓
[∃xA ∨B]
∃x(A ∧B)
r4↓
(∃xA ∧B)
∃xA ∨∃xA
qc↓
∃xA
+
∀xA
= ∀zA{x ⇐z}
∃zA
= ∃zA{x ⇐z}
∀x∀yA =
∀y∀xA
∃x∃yA =
∃y∃xA
∀xt
=
t = ∃xt
∀xf
=
f = ∃xf
Where z does not occur in A for the top two equalities.
For an example of a KSh1 proof, see (Fig. 1).
t
=
∀y1∀y2
⎡
⎢⎣
t
ai↓
Py1 ∨¯Py1
∨

f
aw↓¯Pc
∨
f
aw↓
Py2

=
 ¯Pc ∨Py1

∨ ¯Py1 ∨Py2

⎤
⎥⎦
r1↓
∀y1

 ¯Pc ∨Py1

∨
∀y2
 ¯Py1 ∨Py2

n↓
∃x2∀y2
 ¯Px2 ∨Py2


r1↓
∀y1
 ¯Pc ∨Py1

n↓
∃x1∀y1
 ¯Px1 ∨Py1
 ∨∃x2∀y2
 ¯Px2 ∨Py2

qc↓
∃x∀y
 ¯Px ∨Py

Fig. 1. A KSh1 proof of a variant of the “drinking principle’, ∃x∀y[ ¯Px∨Py], popularised
by Smullyan: “There is someone in the pub such that, if he is drinking, then everyone
in the pub is drinking.”
Proposition 2. KSh1 is sound and complete.
Proof. Soundness is trivial. Completeness follows from the proof of Herbrand’s
theorem in [7] (as stated in the introduction) and the observation that with the
four rules {r1↓, r2↓, r3↓, r4↓} we can simulate the general retract rule:
Q{P{A}}
gr↓
P{Q{A}} ,
where Q{ } is a sequence of quantiﬁers and P{ } is a propositional context with
no variables bound by any quantiﬁer in Q{ }.

298
B. Ralph
Following [7], we deﬁne a Herbrand proof in the context of KSh1 in the following
way.
Deﬁnition 9. A closed KSh1 proof is a Herbrand proof if it is in the following
form:
KS
∀xB{y ⇐t}
{n↓}
Q{B}
{r1↓,r2↓,r3↓,r4↓}
A′
{qc↓}
A
where Q{ } is a context consisting only of quantiﬁers and B is quantiﬁer-free.
For an example of a Herbrand proof, see (Fig. 2).
Proposition 3. Every proof in KSh1 can be converted to a Herbrand Proof.
t
=
∀y1∀y2
⎡
⎢⎣
t
ai↓
Py1 ∨¯Py1
∨

f
aw↓¯Pc
∨
f
aw↓
Py2

=
 ¯Pc ∨Py1

∨ ¯Py1 ∨Py2

⎤
⎥⎦
n↓
∃x1
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
∀y1
⎡
⎢⎢⎢⎢⎣
 ¯Px1 ∨Py1

∨ ¯Py1 ∨Py2

n↓
∃x2

∀y2
 ¯Px1 ∨Py1

∨ ¯Px2 ∨Py2

r1↓ ¯Px1 ∨Py1

∨∀y2
 ¯Px2 ∨Py2


r3↓
 ¯Px1 ∨Py1

∨∃x2∀y2
 ¯Px2 ∨Py2

⎤
⎥⎥⎥⎥⎦
r1↓
∀y1
 ¯Px1 ∨Py1

∨∃x2∀y2
 ¯Px2 ∨Py2

⎤
⎥⎥⎥⎥⎥⎥⎥⎦
r3↓
∃x1∀y1
 ¯Px1 ∨Py1

∨∃x2∀y2
 ¯Px2 ∨Py2

qc↓
∃x∀y
 ¯Px ∨Py

Fig. 2. A Herbrand proof of the drinking principle
Proof. [7, Theorem 4.2]
3.4
KSh2 and Herbrand Normal Form
To aid the translation between open deduction proofs and expansion proofs, we
introduce a slightly diﬀerent proof system to KSh1. It involves two new rules.

A Natural Proof System for Herbrand’s Theorem
299
Deﬁnition 10. We deﬁne the rule h↓, which we call a Herbrand expander and
the rule ∃w↓, which we call existential weakening:
∃xA ∨A{x ⇐t}
h↓
∃xA
f
∃w↓
∃xA
For technical reasons again, we insist that A{x ⇐t} is in fact A′{x ⇐t}, where
A′ is an α-equivalent formula to A with fresh variables for all quantiﬁers, but
for simplicity we will usually denote it A.
Deﬁnition 11
KSh2 = KS +
∀x[A ∨B]
r1↓
[∀xA ∨B]
∃xA ∨A{x ⇐t}
h↓
∃xA
∀x(A ∧B)
r2↓
(∀xA ∧B)
f
∃w↓
∃xA
+
∀xA
= ∀zA{x ⇐z}
∃zA
= ∃zA{x ⇐z}
∀x∀yA =
∀y∀xA
∃x∃yA =
∃y∃xA
∀xt
=
t = ∃xt
∀xf
=
f = ∃xf
Where z does not occur in A for the top two equalities.
Remark 4. The ∃w↓rule is derivable for KSh2\{∃w↓}, but we explicitly include
it so that we can restrict weakening instances in certain parts of proofs.
Deﬁnition 12. We say that a proof in KSh2 is regular if there are no α-
substitutions in the proof, and no variable is used in two diﬀerent quantiﬁers.
Deﬁnition 13. If φ is a closed KSh2 proof in the following form, where ∀x is a
list of universal quantiﬁers with distinct variables, and Lo(φ) is regular and in
sequential form, we say φ is in Herbrand Normal Form (HNF):
Up(φ)
KS
∀xHφ(A)
{∃w↓}
∀xH+
φ (A)
Lo(φ)
{r1↓,r2↓,h↓}
A
Hφ(A), the Herbrand disjunction of A according to φ, or just the Herbrand dis-
junction of A, contains no quantiﬁers, whereas H+
φ (A), the expansive Herbrand
disjunction of A according to φ, may contain quantiﬁers. Up(φ) is called the
upper part of φ, and Lo(φ) the lower part of φ.
For an example of a proof in HNF, see (Fig. 3).

300
B. Ralph
t
=
∀y1∀y2

t
ai↓
Py1 ∨¯Py1
∨

f
aw↓¯Pc
∨
f
aw↓
Py2

=
∀y1
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
∀y2

f
∃w↓
∃x∀y
 ¯Px ∨Py
 ∨ ¯Py1 ∨Py2


∨ ¯Pc ∨Py1


r1↓
∀y2

∃x∀y
 ¯Px ∨Py

∨ ¯Py1 ∨Py2

r1↓
∃x∀y
 ¯Px ∨Py

∨∀y2
 ¯Py1 ∨Py2

h↓
∃x∀y
 ¯Px ∨Py

∨ ¯Pc ∨Py1

⎤
⎥⎥⎥⎥⎥⎥⎥⎦
r1↓
∃x∀y
 ¯Px ∨Py

∨∀y1
 ¯Pc ∨Py1

h↓
∃x∀y
 ¯Px ∨Py

Fig. 3. A proof of the drinking principle in HNF
Proposition 4. A formula A has a proof in HNF iﬀ. It has a Herbrand proof.
Proof. Let φ be a proof of A in HNF. As Hφ(A) is the Herbrand expansion of
A, it is straightforward to construct a Herbrand proof for A: one can infer the
necessary n↓and qc↓rules by comparing Hφ(A) and A. Now let φ be a Herbrand
Proof. The order of the quantiﬁers in Q{ } (as in Deﬁnition 9) is used to build
the HNF proof. Thus, we proceed by induction on the number of quantiﬁers in
Q{ }. If there are none, it is obviously trivial. We split the inductive step into
two cases.
First, consider φ1 of the form shown, where P is a quantiﬁer-free context and
Q{ } = ∀zQ′{ }. Clearly φ2 is also a Herbrand proof, so by the IH the proof
φ3 in HNF is constructible, from which we can construct φ4.
KS
∀z∀xB{y ⇐t}
{n↓}
∀zQ′{B}
{r1↓,r2↓,r3↓,r4↓}
P{∀zC′}
{qc↓}
P{∀zC}
KS
∀xB{y ⇐t}
{n↓}
Q′{B}
{r1↓,r2↓,r3↓,r4↓}
P{C′}
{qc↓}
P{C}
Upφ3
KS
∀xHφ3P{C}
{∃w↓}
∀xH+
φ3P{C}
Lo(φ3)
{r1↓,r2↓,h↓}
P{C}
∀zUpφ3
KS
∀z∀xHφ3P{C}
{∃w↓}
∀z∀xH+
φ3P{C}
∀zLoφ3
{r1↓,r2↓,h↓}
∀zP{C}
{r1↓,r2↓}
P{∀zC}
φ1
φ2
φ3
φ4
In the same way, we consider the case where Q{ } = ∃zQ′{ }. Below we only
show the case where there is no contraction acting on ∃zC, but the case with
such a contraction is similar.

A Natural Proof System for Herbrand’s Theorem
301
KS
∀xB{y ⇐t}{z ⇐t}
{n↓}
∃zQ′{B}
{r1↓,r2↓,r3↓,r4↓}
P {∃zC′}
{qc↓}
P {∃zC}
KS
∀xB{y ⇐t}{z ⇐t}
{n↓}
Q′{B}{z ⇐t}
{r1↓,r2↓,r3↓,r4↓}
P {C′{z ⇐t}}
{qc↓}
P {C{z ⇐t}}
Up(φ3)
KS
∀xP {D{z ⇐t}}
{∃w↓}
∀xP {D+{z ⇐t}}
Lo(φ3)
{r1↓,r2↓,h↓}
P {C{z ⇐t}}
Up(φ3)
KS
∀xP {D{z ⇐t}}
{∃w↓}
∀xP {∃zC ∨D+{z ⇐t}}
Lo(φ3)
{r1↓,r2↓,h↓}
P

∃zC ∨C{z ⇐t}
h↓
∃zC

φ1
φ2
φ3
φ4
where
P{D{z ⇐t}} = Hφ3(P{C{z ⇐t}}) and P{D+{z ⇐t}} = H+
φ3(P{C{z ⇐t}}).
4
Translations Between KSh2 and Expansion Proofs
Above, we gave translations between Herbrand proofs in KSh1 and KSh2 proofs
in HNF. We will now give a translations between KSh2 proofs in HNF and
expansion proofs, thus giving us a link between deep inference Herbrand proofs
and expansion proofs.
Remark 5. We extend the notion and syntax of contexts from derivations to
expansion trees. For the notion to make sense, a context can only take expansion
trees with the same shallow formula.
4.1
KSh2 to Expansion Proofs
Before stating and proving the main theorem, we will deﬁne the map π1 from
KS proofs to expansion proofs, and then prove some lemmas to help prove that
the dependency relation in all expansion proofs in the range of π1 is acyclic.
Deﬁnition 14. We deﬁne a map π′
1 from the lower part of KSh2 proofs in HNF
to expansion trees in the following way, working from the bottom
On the conclusion of φ, we deﬁne π′
1 as follows:
– π′
1(B ⋆C) = π′
1(B) ⋆π′
1(C)
– π′
1(∀xB) = ∀xB +x π′
1(B)
– π′
1(∃xB) = ∃xB
The r1↓and r2↓rules are ignored by expansion trees and each h↓rule adds a
branch to a ∃-node:
– If φ =
K
	
∀x[B ∨C]
r1↓
∀xB ∨C

φ′
A
then π′
1 (φ) = π′
1
⎛
⎝
K{∀xB ∨C}
φ′
A
⎞
⎠.
– If φ =
K
	
∀x(B ∧C)
r2↓
(∀xB ∧C)

φ′
A
then π′
1 (φ) = π′
1
⎛
⎝
K{∀xB ∧C}
φ′
A
⎞
⎠.

302
B. Ralph
– If π′
1
⎛
⎝
K{∃xB}
φ
A
⎞
⎠= Kπ1(∃xB +τ1 E1 + · · · +τn En), then:
π′
1
⎛
⎜
⎜
⎜
⎝
K
	
∃xB ∨B{x ⇐τn+1}
h↓
∃xB

φ
A
⎞
⎟
⎟
⎟
⎠= Kπ1(∃xB +τ1 E1 + · · · +τn+1 En+1)
where En+1 = π′
1(B{x ⇐τn+1}).
We then deﬁne the map π1 from KSh2 proofs in HNF to expansion trees as
π1(φ) = π′
1(Lo(φ)).
To show that π1(φ) is an expansion proof, we need to prove that ∀xHφ(A) is a
tautology and <E is acyclic. As ∀xHφ(A) has a proof in KS it is a tautology.
Thus all that is needed is the acyclicity of <E. To do so, we deﬁne the following
partial order on variables in the lower part of KSh2 proofs in HNF.
Deﬁnition 15. Let φ be a proof in HNF. Deﬁne the partial order <φ on the
variables of occurring in Lo(φ) to be the minimal partial order such that y <φ x
if K1{Q1xK2{Q2yB}} is a section of Lo(φ).
Proposition 5. <φ is well-deﬁned for all KSh2 proofs in HNF.
Proof. Let φ be a proof of A in HNF, as in Deﬁnition 13. As Lo(φ) only contains
h↓, r1↓and r2↓rules and no α-substitution, if a variable v occurs in Lo(φ) then
v occurs in ∀xH+
φ (A). Notice also that none of h↓, r1↓and r2↓can play the role
of ρ in the following scheme:
K{Q1v1A1}{Q2v2A2}
ρ
K′{Q1v1{K′′Q2v2B}} .
Therefore, we observe that if K1{Q1xK2{Q2yB}} is a section of Lo(φ), then
∀xH+
φ (A) is of the form L1{Q1xL2{Q2yC}}, i.e. no dependencies can be
introduced below ∀xH+
φ (A). Thus x <φ
y iﬀ. ∀xH+
φ (A) can be written
L1{Q1xL2{Q2yC}} for some L1{ }, L2{ } and C and is therefore a well-deﬁned
partial order.
Lemma 1. Let φ be an KSh2 proof in HNF and e′ an ∀-edge in π1(φ) that points
to the ∃-edge e. If Lab(e′) = y and the ∃-node below e is ∃xA, then x <φ y.
Proof. Since we have an ∃-node ∃xA in π1(φ) with an edge labelled t below it,
there must be the following h↓rule in φ:
K
	
∃xA ∨A{x ⇐t}
h↓
∃xA

Since e points to e′, y must occur freely in t. As φ is closed, y cannot be a free
variable in K{∃xA ∨A{x ⇐t}}. Thus K{ } must be of the form K1{∀yK2{ }}.
Therefore x <φ y.

A Natural Proof System for Herbrand’s Theorem
303
Lemma 2. Let φ be an KSh2 proof in HNF, e a ∀-edge of π1(φ) labelled by x
and e′ an ∃-edge above an ∃-node ∃yA. If e is a descendant of e′ then x <φ y.
Proof. Sh(π1(φ)) = K1{∃yK2∀x{B}} (for some K1{ }, K2{ }, and B) is the
conclusion of φ, so x <φ y.
Lemma 3. Let φ be an KSh2 proof in HNF, Eφ = π1(φ) and e and e′ be edges
in Eφ s.t. e <Eφ e′, Lab(e) = x and Lab(e′) = x′. Then x <φ x′.
Proof. As e <Eφ e′, there must be a chain
eq0 <−
Eφ · · · <−
Eφ ep1 <−
Eφ eq1 <−
Eφ · · · <−
Eφ epm <−
Eφ eqm <−
Eφ · · · <−
Eφ epn
where eq0 = e and epn = e′, eqi points to epi, and eqi is a descendant of epi+1 in
the expansion tree. By Lemma 1, we know that if ∃xpi is the node above pi and
Lab(eqi) = xqi, then xpi <φ xqi. By Lemma 2, since eqi is a descendant of epi+1
in the expansion tree, xqi <φ xpi+1. Therefore x <φ x′.
Theorem 3. If φ is an KSh2 proof of A in HNF, then we can construct an
expansion proof Eφ = π1(φ), with Sh(Eφ) = A, and Dp(Eφ) = Hφ(A).
Proof. As described above, we only need to show that the dependency relation
of Eφ is acyclic. Assume there were a cycle in <Eφ. Clearly, it could not be
generated by just by travelling up the expansion tree. Thus, there is some e and
e′ such that e points to e′ and e <Eφ e′ <Eφ e. But then, if Lab(e) = x, by
Lemma 3, x <φ x. But this contradicts Proposition 5. Therefore <Eφ is acyclic.
Expansion Proofs to KSh2: For the translation from expansion proofs to KSh2
proofs in HNF, we show that we can always construct a total order on the edges
in an expansion proof that guides the construction of the lower part of a proof
in HNF. Unlike the previous translation, there is not necessarily a unique proof
corresponding to each expansion proof, but the choice of a total order determines
the proof that will be created.
Deﬁnition 16. A weak expansion tree is deﬁned in the same way as in
Deﬁnition 1 except that the ﬁrst condition is weakened to allow any formula to
be a leaf of the tree. A weak expansion tree with an acyclic dependency relation
is correct regardless of whether its deep formula is a tautology.
Deﬁnition 17. We deﬁne the expansive deep formula Dp+(E) for (weak)
expansion trees, which is deﬁned in the same way as the usual deep formula
except that:
Dp+(∃xA +t1 E1 +t2 · · · +tn En) := ∃xA ∨Dp+(E1) ∨. . . ∨Dp+(En)
Deﬁnition 18. A minimal edge of a (weak) expansion tree E is an edge that is
minimal w.r.t. to <E.

304
B. Ralph
Deﬁnition 19. Let E be a (weak) expansion proof. Let <+
E be a total order
extending <E such that the following condition holds: if ⋆is a node with edges
e and e′ below it, then e and e′ are consecutive elements in the total order. We
say <+
E is a sequentialisation of E.
Lemma 4. Every (weak) expansion proof has a sequentialisation, often many.
Proof. We proceed by induction on the number of nodes in a weak expansion
proof. The base case is trivial. For the inductive step, we will show that every
weak expansion tree has either a minimal edge e below an existential or universal
node, or that there are two minimal edges e1 and e2 below a ⋆-node. As the rest
of the weak expansion proof has a sequentialisation by the inductive hypothesis,
we can extend it with the minimal element e or the two minimal elements e1
and e2 for a sequentialisation for the full weak expansion proof.
Assume E is a weak expansion proof with no minimal edges below existential
or universal nodes. As <E is a partial order, there must be at least one minimal
edge e0, and by the assumption it must be below a node ⋆0. Let e′
0 be the other
edge below ⋆0. If e′
0 is minimal, we are done. If not, pick some minimal edge
e1 < e′
0, which again, with e′
1 < e′
0, must be below some ⋆1. For each e′
i that is
not minimal, we can ﬁnd e′
i+1 < e′
i. As E is ﬁnite, this sequence cannot continue
indeﬁnitely, so eventually we will ﬁnd two minimal edges en and e′
n below ⋆n.
Note that en and e′
n need not be unique and thus the sequentialisation is not
unique.
Proposition 6. Let E = KE{∀xA +x A}, with Dp+(E) = K{A}, be a correct
weak expansion tree with the ∀-edge labelled by x (which we will call e) minimal
w.r.t. <E. Then there is a derivation
∀xK{A}
{r1↓,r2↓}
K{∀xA}
.
Proof. We proceed by induction on the height of the node ∀xA in E. If ∀xA is
the bottom node, then K{A} = A and we are done. Let E be an expansion tree
where ∀x is not the bottom node. There are three possible cases to consider. In
each case, E1 = KE1 {∀xA +x A} is an expansion tree with Dp+(E1) = K1{A}
and, by the inductive hypothesis, we have a derivation
∀xK1{A}
{r1↓,r2↓}
K1{∀xA}
.
1. E = (E1⋆E2), with Dp+(E) = [K1{A}⋆Dp+(E2)]. As e is minimal, it cannot
point to any edge in E2. Therefore B := Dp+(E2) is free for x. Therefore we
can construct the derivations:
∀x[K1{A} ∨B]
r1↓
∀xK1{A}
{r1↓,r2↓}
K1{∀xA}
∨B
and
∀x(K1{A} ∧B)
r2↓
∀xK1{A}
{r1↓,r2↓}
K1{∀xA}
∧B
2. E = ∀y(Sh(E1)) +y E1. As Dp+(E) = Dp+(E1), we are already done.

A Natural Proof System for Herbrand’s Theorem
305
3. E
=
∃yK0{A0} +t1 E1 · · · +tn En,
with
Dp+(Ei)
=
Bi
:=
[K0{A0}]{y ⇐ti} and in particular B1
= K1{A}. Thus Dp+(E) =
∃yB0 ∨K1{A} ∨B2 ∨. . . ∨Bn. Again, e cannot point to any edge in any of
the E′
i, so we can construct:
∀x[∃yB0 ∨K1{A} ∨B2 ∨. . . ∨Bn]
r1↓
∀x[∃yB0 ∨K1{A}]
r1↓⎡
⎣∃yB0 ∨
∀xK1{A}
{r1↓,r2↓}
K1{∀xA}
⎤
⎦
∨[B2 ∨. . . ∨Bn]
Deﬁnition 20. We deﬁne the map πLo
2
that takes an expansion tree E and a
sequentialisation <+
E to a derivation:
πLo
2 (E, <+
E) =
∀xDp+(E)
{h↓,r1↓,r2↓}
Sh(E)
In each case <+
E′ is <+
E restricted to E′.
– If E is just a leaf A, πLo
2 (E, <+
E) = A.
– If E = KE{A1 ⋆E A2} is e1, and the minimal edge w.r.t <+
E is between ⋆E
and A1, then by Deﬁnition 19 the next-but-minimal edge is between ⋆E and
A2. Then, E′ = KE{A1 ⋆F A2} is a correct weak expansion tree and we can
deﬁne:
πLo
2 (E, <+
E) = πLo
2 (E′, <+
E′)
Pictorially:
⋆
A1
A2
E = KE
E′ = KE{A1 ⋆A2}
– If E = KE{∀xA +x A} and the minimal edge w.r.t. <+
E is between ∀xA and
A, then, by Proposition 6, E′ = KE{∀xA} is a correct weak expansion tree
and we can deﬁne:
πLo
2 (E, <+
E) =
∀xDp+(E)
{r1↓,r2↓}
Dp+(E′)
=
πLo
2 (E′, <+
E′)
Pictorially:

306
B. Ralph
∀xA
A
E = KE
E′ = KE{∀xA}
– If the minimal edge of E = KE{∃xA +t1 E1 · · · +tn An}, with Dp+(E) =
K{∃xA ∨A1 ∨. . . ∨An}, is between ∃xA and An, then E′ = KE{∃xA +t1
E1 · · · +tn−1 En−1} is a correct weak expansion tree with Dp+(E′) = K{A1 ∨
. . . ∨An−1} and we can deﬁne:
πLo
2 (E, <+
E) =
K
⎧
⎪
⎨
⎪
⎩
∃xA ∨A1 ∨. . . ∨An
=
∃xA ∨An
h↓
∃xA
∨A1 ∨. . . ∨An−1
⎫
⎪
⎬
⎪
⎭
=
πLo
2 (E′, <+
E′)
Pictorially:
∃xA
E1
· · ·
En−1 An
E = KE
∃xA
E1
· · ·
En−1
E′ = KE
Theorem 4. If E is an expansion proof with Sh(E) = A, then we can construct
an KSh2 proof φ of A in HNF, where Hφ(A) = Dp(E).
Proof. As Dp(E) is a tautology, there is a proof
πUp
2 (E)
KS
∀xDp(E)
and clearly there
is a proof
Dp(E)
{∃w↓}
Dp+(E)
. Thus, choosing an arbitrary sequentialisation <+
E of E, we
can deﬁne π2 from expansion proofs to KSh2 proofs in HNF as:
π2(E) =
πUp
2 (E)
KS
∀xDp(E)
{∃w↓}
∀xDp+(E)
πLo
2 (E,<+
E)
{r1↓,r2↓,h↓}
Sh(E)
Remark 6. For all expansion proofs E we have πUp
2 (E) = Up(π2(E)) and
πLo
2 (E) = Lo(π2(E)).

A Natural Proof System for Herbrand’s Theorem
307
5
Further Work
The translations between deep inference proofs and expansion proofs should be
seen as a springboard for further investigations. One obvious next step is to
extend KSh2 with cut, and prove cut elimination, so that completeness does
not depend on the translation into KSh1 and Br¨unnler’s result. Having done so,
we can then make a proper comparison with the cut elimination procedures for
expansion proofs described in [1,12,15]. Additionally, it would be interesting to
try and situate this work in the context of recent work by Aler Tubella and
Guglielmi [2,3], in which they provide a general theory of normalisation for
various diﬀerent propositional logics. In their terminology, a Herbrand proof
is close to the notion of a decomposed proof, which has two phases: the ﬁrst
contraction-free and the second consisting only of contractions. Extending the
procedure, described in [4], to remove identity-cut cycles from SKS proofs to
ﬁrst-order systems is likely to be an important aspect of this research.
References
1. Alcolei, A., Clairambault, P., Hyland, M., Winskel, G.: The true concurrency of
Herbrand’s theorem (2017, submitted)
2. Aler Tubella, A.: A study of normalisation through subatomic logic. University of
Bath (2016)
3. Aler Tubella, A., Guglielmi, A.: Subatomic proof systems: splittable systems. arXiv
preprint arXiv:1703.10258 (2017)
4. Aler Tubella, A., Guglielmi, A., Ralph, B.: Removing cycles from proofs. In:
Goranko, V., Dam, M. (eds.) 26th EACSL Annual Conference on Computer Sci-
ence Logic (CSL 2017), Stockholm, Sweden 2017. Leibniz International Proceed-
ings in Informatics (LIPIcs), pp. 9:1–9:17. Schloss Dagstuhl-Leibniz-Zentrum fuer
Informatik (2017)
5. Br¨unnler, K.: Deep inference and symmetry in classical proofs. Logos Verlag (2003)
6. Br¨unnler, K.: Two restrictions on contraction. Logic J. IGPL 11(5), 525–529 (2003)
7. Br¨unnler, K.: Cut elimination inside a deep inference system for classical predicate
logic. Stud. Logica. 82(1), 51–71 (2006)
8. Buss, S.R.: On Herbrand’s theorem. In: Leivant, D. (ed.) LCC 1994. LNCS,
vol. 960, pp. 195–209. Springer, Heidelberg (1995). https://doi.org/10.1007/
3-540-60178-3 85
9. Chaudhuri, K., Hetzl, S., Miller, D.: A multi-focused proof system isomorphic to
expansion proofs. J. Logic Comput. 26(2), 577–603 (2016). https://doi.org/10.
1093/logcom/exu030
10. Guglielmi, A., Gundersen, T., Parigot, M.: A proof calculus which reduces syntactic
bureaucracy. In: Proceedings of the 21st International Conference on Rewriting
Techniques and Applications (Rta 2010), vol. 6, pp. 135–150 (2010). https://doi.
org/10.4230/LIPIcs.RTA.2010.135
11. Gundersen, T.E.: A general view of normalisation through atomic ﬂows. University
of Bath (2009)
12. Heijltjes, W.: Classical proof forestry. Ann. Pure Appl. Logic 161(11), 1346–1366
(2010). https://doi.org/10.1016/j.apal.2010.04.006

308
B. Ralph
13. Herbrand, J., Goldfarb, W.D.: Logical Writings. Springer, Dordrecht (1971).
https://doi.org/10.1007/978-94-010-3072-4
14. Hetzl, S., Weller, D.: Expansion trees with cut. arXiv preprint arXiv:1308.0428
(2013)
15. McKinley, R.: A sequent calculus demonstration of Herbrand’s theorem. arXiv
preprint arXiv:1007.3414 (2010)
16. McKinley, R.: Proof nets for Herbrand’s theorem. ACM Trans. Comput. Logic
(TOCL) 14(1), 1–31 (2013). https://doi.org/10.1145/2422085.2422090
17. Miller, D.A.: A compact representation of proofs. Stud. Logica. 46(4), 347–370
(1987). https://doi.org/10.1007/BF00370646
18. Straßburger, L.: Some observations on the proof theory of second order propo-
sitional multiplicative linear logic. In: Curien, P.-L. (ed.) TLCA 2009. LNCS,
vol. 5608, pp. 309–324. Springer, Heidelberg (2009). https://doi.org/10.1007/
978-3-642-02273-9 23
19. Straßburger, L.: Deep inference, expansion trees, and proof graphs for second order
propositional multiplicative linear logic, vol. RR-9071, p. 38. Inria Saclay Ile de
France (2017)

Metastability and Higher-Order Computability
Sam Sanders(B)
Center for Advanced Studies and Munich Center for Mathematical Philosophy,
LMU Munich, Munich, Germany
sasander@me.com
Abstract. Tao’s notion of metastability is classically equivalent to the
well-known ‘epsilon delta’ deﬁnition of Cauchy sequence, but the former
has much nicer computational properties than the latter. In particu-
lar, results from the proof mining program suggest that metastability
gives rise to highly uniform and computable results under very general
conditions, in contrast to the non-uniform and/or non-computable rates
of convergence emerging from basic convergence theorems involving the
deﬁnition of Cauchy sequence. As a trade-oﬀfor these high levels of uni-
formity, metastability only provides information about a ﬁnite but arbi-
trarily large domain. In this paper, we apply this ‘metastability trade-oﬀ’
to basic theorems of mathematics, i.e. we introduce in the latter ﬁnite
domains in exchange for high(er) levels of uniformity. In contrast to the
aforementioned eﬀective results from proof mining, we obtain functionals
of extreme computational hardness. Thus, our results place a hard limit
on the generality of the metastability trade-oﬀand show that metastabil-
ity does not provide a ‘king’s road’ to computable mathematics. Perhaps
surprisingly, we shall make use of Nonstandard Analysis (NSA) to estab-
lish the aforementioned results (which do not involve NSA).
Keywords: Metastability · Higher-order computability
Nonstandard analysis
1
Introduction
Tao’s notion1 of metastability, as discussed in e.g. [1, Sect. 1], [12, Sect. 2.29],
or [28, Sect. 2.3.1], is a notion of convergence, namely a classically2 equivalent
formulation of the (epsilon-delta) deﬁnition of Cauchy sequence. Interestingly,
metastability gives rise to quite elegant computable (or ‘eﬀective’) results, in
contrast to the deﬁnition of Cauchy sequence, as rates of convergence can be
non-computable even in the case of basic convergence theorems. In particu-
lar, the trade-oﬀinvolved in metastability is that only computable information
S. Sanders—This research was supported by the Alexander von Humboldt Founda-
tion and LMU Munich (via the Excellence Initiative).
1 Note that the notion of metastability was known in mathematical logic (See [12,
Remark 2.29]) under a diﬀerent name well before Tao discussed this notion in [28].
2 Unless explicitly stated otherwise, we work in classical mathematics.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 309–330, 2018.
https://doi.org/10.1007/978-3-319-72056-2_19

310
S. Sanders
about convergence on a ﬁnite -but arbitrarily large- domain is obtained, but this
information is ‘highly uniform’ in that it only depends on a small numbers of
parameters (relative to the theorem at hand). This trade-oﬀhas been observed
in proof mining:
Whereas in general noneﬀective proofs of convergence statements [. . . ]
might not provide a (uniform) computable rate of convergence, highly
uniform rates of metastability can under very general conditions always
be extracted using tools from mathematical logic [. . . ]. ([11, p. 1090])
Following the previous quote, the term ‘metastability trade-oﬀ’ shall refer to
the phenomenon that introducing a ﬁnite but arbitrarily large domain results in
highly uniform and computable results. We discuss the textbook example of the
metastability trade-oﬀin Sect. 2.2 in detail.
In light of the widespread interest in metastability, it is a natural question
how general the metastability trade-oﬀis? For instance: is this trade-oﬀlim-
ited to convergence, or does it apply to other notions? Perhaps the metastabil-
ity trade-oﬀeven constitutes a recipe for ‘automatically’ obtaining computable
mathematics? The hope is that, when faced with non-computable objects, intro-
ducing a ﬁnite (but arbitrarily large) domain always results in highly uniform
and computable results. To answer these questions, we shall apply the metasta-
bility trade-oﬀto basic mathematical theorems, i.e. we introduce in the latter
ﬁnite domains in exchange for high(er) levels of uniformity. However, in doing
so, we obtain functionals of extreme computational hardness, in particular the
special fan functional Θ from [21]. Intuitively speaking, Θ computes the ﬁnite
sub-cover stated to exist by the Heine-Borel theorem (for uncountable covers),
but Θ cannot be computed by any type two functional (See Sect. 2.3).
As to the structure of this paper, metastability is discussed in Sect. 2.2, while
we introduce the functional Θ in Sect. 2.3 and list its basic properties. We obtain
our main results in Sect. 3. In particular, we apply the metastability trade-oﬀ
to the following theorems: the intermediate and extreme value theorems, BD-N,
and the existence of the Riemann integral. We shall make use of Nonstandard
Analysis (NSA) as a tool to obtain the aforementioned computability theoretic
results (whose formulation does not involve NSA). We provide a brief introduc-
tion to the computational content of NSA in Sect. 2.4. A detailed and elementary
introduction to this topic may be found in [24], while advanced results are avail-
able in [19]. Finally, in Sect. 3.4, we provide a short and elegant derivation of Θ
in full second-order arithmetic, also using NSA. This signiﬁcantly improves the
associated result from [19].
In conclusion, the results in this paper place a hard limit on the generality
of the metastability trade-oﬀand shows that metastability does not provide a
‘king’s road’ towards computable mathematics. Along the way, we establish an
intimate connection between higher-order computability theory and NSA, which
we hope might spur the reader to become acquinted with the latter.

Metastability and Higher-Order Computability
311
2
Background and Preliminaries
2.1
Introduction
First of all, we make our notion of computability precise.
(I) We adopt ZFC set theory as the oﬃcial metatheory, unless stated otherwise.
(II) We adopt Kleene’s notion of higher-order computation as given by his nine
clauses S1-S9 (See [16, Deﬁnition 5.1.1, p. 170]) as our notion of ‘com-
putable’.
For reference and to promote understanding, we sometimes connect our results
to well-known systems from the Reverse Mathematics program (See [26]).
Secondly, one does not require much familiarity with computability theory as
in item (II) for this paper; we only assume familiarity with G¨odel’s system T of
(higher-order) primitive recursion, and the associated formal system E-PAω∗from
[3], i.e. Peano arithmetic with all ﬁnite types. We do point out one notational
peculiarity: E-PAω∗has, for every ﬁnite type σ, the type σ∗of ﬁnite sequences of
objects of type σ (See [3, Sect. 2]). In this way, ‘xσ ∈yσ∗’ is shorthand for (∃i0 <
|y|)(x =σ y(i)) where |y| is the length of y, i.e. |y| = k if y = ⟨xσ
0, . . . , xσ
k−1⟩, and
the empty sequence (of any type) has length zero. A set of natural numbers X1
is represented by its characteristic function, i.e. a binary sequence.
Thirdly, as to the structure of this section, we discuss basic results in and
related to computability theory, namely Tao’s notion of metastability and the
associated trade-oﬀin Sect. 2.2. As will be established in Sect. 3, applying the
aforementioned trade-oﬀto basic mathematical theorems will give rise to the
special fan functional Θ, introduced in Sect. 2.3.
Finally, the functional Θ actually originates from Nonstandard Analysis
(NSA), and we provide a brief introduction to the computational content of
NSA in Sect. 2.4. The results in Sect. 3 are established by proving suitable the-
orems in NSA, and then translating these results to computability theory (no
longer involving NSA) using Sect. 2.4. A detailed and elementary introduction
to this topic is [24]; advanced results are available in [19].
2.2
The Textbook Example of Metastability
We study the ‘textbook’ example of metastability from [1, Sect. 1] and [28,
Sect. 2.3.2]. We make use of basic type theoretic notation and the associated
representation of real numbers (using fast-converging Cauchy sequences) from
[13, Sect. 2].
Example 2.1 (Metastability). The monotone convergence theorem MCT
states that any non-decreasing sequence in [0, 1] converges to a limit. Now, a
convergent sequence is a Cauchy sequence, and the epsilon-delta deﬁnition of
the latter (for a ﬁxed sequence of rationals a(·)) is:
(∀ε >R 0)(∃N 0)(∀n0, m0 ≥N)(|an −am| ≤ε).
(2.1)

312
S. Sanders
Using classical logic, (2.1) is equivalent to the deﬁnition of metastable sequence:
(∀ε >R 0, F 1)(∃M 0)(∀n0, m0 ∈[M, F(M)])(|an −am| ≤ε).
(2.2)
While (2.1) and (2.2) are classically equivalent, we now show that their compu-
tational behaviour is quite diﬀerent (a well-known phenomenon in general).
First of all, a rate of convergence for the sequence a(·) is a function which
provides an upper bound to N 0 from k0 in (2.1). There are (Turing) computable
monotone sequences of rationals in the unit interval for which there is no (Turing)
computable rate of convergence (See e.g. [26, I.8.4] or [12, Sect. 13.3]). Further-
more, MCT is equivalent to ACA0 in Reverse Mathematics, and the latter system
implies the existence of a solution to the Halting problem ([26, III]).
Secondly, a rate of metastability for a(·) provides an upper bound for M 0
from ε, F as in (2.2). As it happens, such a rate is given by the elementary
function F ⌈1
ε ⌉+1(0), i.e. the result of iterating F for ⌈1
ε⌉+ 1-many times and
then evaluating at 0. In particular, M 0 as in (2.2) is exactly one of the values in
the ﬁnite sequence ⟨0, F(0), F(F(0)), . . . , F ⌈1
ε ⌉+1(0)⟩. We obtain:
(∃θ(0×1)→0∗)(∀k0, F, a(·) ∈mon([0, 1]))(∃M ∈θ(k, F))
(2.3)
(∀n, m ∈[M, F(M)])(|an −am| ≤1
k)
where ‘a(·) ∈mon([0, 1])’ means that a(·) is a non-decreasing sequence in [0, 1].
In conclusion, while rates of convergence can be non-computable (in the sense of
Turing), rates of metastability (in the case at hand) are elementary computable.
Example 2.1 illustrates a considerable advantage of metastability (2.2) over (2.1):
By introducing F as in (2.2), we reduce the underlined pair of quantiﬁers of the
form ‘∃∀’ in (2.1) to the underlined ‘∃’ quantiﬁer in (2.2) as the universal
quantiﬁer (∀n, m) in (2.2) is bound by F(M), and hence may be neglected.
Thanks to this reduction in quantiﬁer complexity (in favour of higher types),
there is a ﬁnite sequence θ(k, F) which is independent of the sequence a(·) as in
(2.3), i.e. we in fact obtain highly uniform and computable information. Hence,
we observe the following version of the aforementioned metastability trade-oﬀ:
By introducing the interval [M, F(M)] as in (2.2), one only obtains
‘bounded’ information (in contrast to the unbounded quantiﬁer (∀n, m)
in (2.1)) about the convergence of a(·), but this information is computable
and highly uniform, i.e. independent of the choice of sequence a(·).
Now, there is nothing inherently special about convergence or metastability:
Whenever we encounter a quantiﬁer pair ‘∃∀’, we can formulate a classically
equivalent ‘metastable’ version in which the universal quantiﬁer is bounded,
namely by introducing a functional similar to F as in (2.2). It is then a natural
question whether, as suggested by the metastability trade-oﬀand the quote
in Sect. 1, we also obtain computable and uniform results. In Sect. 3, we shall
study a number of theorems from basic mathematics from this point of view,
i.e. we introduce ﬁnite domains in exchange for high(er) levels of uniformity.

Metastability and Higher-Order Computability
313
Perhaps surprisingly, we obtain functionals of extreme computational hardness
in each case; in particular, the special fan functional, introduced in the next
section, shall come to the fore.
2.3
The Special Fan Functional
In this section, we introduce the special fan functional Θ, discuss its computa-
tional properties, and sketch its connection to NSA. The functional Θ emerges
naturally from Cousin’s lemma (published in 1895 in [5]), which is the Heine-
Borel theorem in the general3, i.e. the statement that any (possibly uncountable)
open cover of the unit interval has a ﬁnite sub-cover. In particular, any Ψ 2 gives
rise a ‘canonical’ open cover ∪x∈[0,1](x −
1
Ψ(x)+1, x +
1
Ψ(x)+1) of [0, 1]. Hence,
Cousin’s lemma immediately implies:
(∀Ψ 2)(∃w1∗)(∀x ∈[0, 1])(∃y ∈w)(|x −y| <
1
Ψ(y)).
(HBU)
The special fan functional computes such a ﬁnite sub-cover (given by w) from
any Ψ 2 by Corollary 3.29. To avoid using representations of the real numbers,
the special fan functional is deﬁned on Cantor space. We usually talk about
‘the’ special fan functional Θ, though the latter is not unique, but given by
the following speciﬁcation. We reserve the variable ‘T 1’ for trees and denote by
‘T 1 ≤1 1’ that T is a binary tree. We usually simplify the type of Θ to ‘3’.
Deﬁnition 2.2 (Special fan functional). For Θ(2→(0×1∗)), SCF(Θ) is as follows:
(∀g2, T ≤1 1)

(∀α ∈Θ(g)(2))(αg(α) ̸∈T) →(∀β ≤1 1)(∃i ≤Θ(g)(1))(βi ̸∈T)

.
Any functional Θ satisfying SCF(Θ) is referred to as a special fan functional.
From a computability theoretic perspective, the main property of Θ is the selec-
tion of Θ(g)(2) as a ﬁnite sequence of binary functions ⟨f0, . . . , fn⟩such that
the neighbourhoods deﬁned from fig(fi) for i ≤n form a cover of Cantor space;
almost as a by-product, Θ(g)(1) can then be chosen to be the maximal value
of g(fi) + 1 for i ≤n. As it happens, Θ arises from the nonstandard compact-
ness of Cantor space as in Robinson’s theorem from NSA (See [6, p. 42]), as
discussed in Sect. 2.4. In particular, Θ was ﬁrst introduced in [21] in the study
of the Gandy-Hyland functional using NSA.
Finally, Θ appears similar in name and behaviour to Tait’s ‘classical’ fan
functional. However, Θ behaves quite diﬀerently in that it cannot be computed
by any type two functional, as proved in [19, Sect. 3]. As also proved in the latter,
Θ can be computed from the ‘second-order arithmetic’ functional ξ3 given by
the following speciﬁcation SO(ξ); one writes ‘(∃3)’ for (∃ξ)SO(ξ).
(∀Y 2)

(∃f 1)(Y (f) = 0) ↔ξ(Y ) = 0

.
(SO(ξ))
However, the intuitionistic fan functional MUC (See [13, Sect. 3]) does compute Θ
(See [21, Sect. 3]), i.e. most of our results are part of intuitionistic mathematics.
3 Heine-Borel theorem in Reverse Mathematics deals with countable covers ([26,
IV.1]).

314
S. Sanders
2.4
Nonstandard Analysis and Its Computational Content
We introduce Nelson’s internal set theory IST and the fragment P based on
Peano Arithmetic from [3]. We discuss the computational content of P, as this
content is essential to the results in Sect. 3.
Internal Set Theory. In Nelson’s syntactic (or ‘axiomatic’) approach to NSA
([17]), a new predicate ‘st(x)’, read as ‘x is standard’ is added to the language of
ZFC, the usual foundation of mathematics4. The notations (∀stx) and (∃sty) are
short for (∀x)(st(x) →. . . ) and (∃y)(st(y) ∧. . . ). A formula is called internal if
it does not involve ‘st’, and external otherwise.
The external axioms Idealisation, Standardisation, and Transfer govern the
new predicate ‘st’; we state these axioms5 as follows:
(I) (∀st ﬁnx)(∃y)(∀z ∈x)ϕ(z, y) →(∃y)(∀stx)ϕ(x, y), for any internal ϕ.
(S) (∀stx)(∃sty)(∀stz)

(z ∈x ∧ϕ(z)) ↔z ∈y

, for any ϕ.
(T) (∀stt)

(∀stx)ϕ(x, t) →(∀x)ϕ(x, t)

, for internal ϕ with all variables shown.
The system IST is the internal system ZFC extended with the aforementioned
external axioms; Internal set theory IST is a conservative extension of ZFC for
the internal language ([17, Sect. 8]), i.e. these systems prove the same internal
sentences. It goes without saying that the step from ZFC to IST can be done for
a large spectrum of logical systems weaker than ZFC. In Sect. 2.4, we study this
extension for Peano Arithmetic with all ﬁnite types.
The classical system P. In this section, we introduce the system P, a conser-
vative extension of E-PAω∗with fragments of Nelson’s IST.
We ﬁrst introduce the system E-PAω∗
st . We use the same deﬁnition as [3,
Deﬁnition 6.1], where E-PAω∗is the deﬁnitional extension of E-PAω with types
for ﬁnite sequences as in [3, Sect. 2] and Sect. 2.1. The language of E-PAω∗
st (and
P) is the language of E-PAω∗extended with a new symbol ‘stρ’ for any ﬁnite
type ρ in the language of E-PAω∗; the typing of ‘st’ is omitted.
Deﬁnition 2.3. The set T ∗is the collection of all the terms in the language of
E-PAω∗. The system E-PAω∗
st is E-PAω∗+ T ∗
st + IAst, where T ∗
st consists of:
(i) The schema6 st(x) ∧x = y →st(y),
(ii) The schema providing for each closed7 term t ∈T ∗the axiom st(t).
4 The acronym ZFC stands for Zermelo-Fraenkel set theory with the axiom of choice.
5 The superscript ‘ﬁn’ in (I) means that x is ﬁnite, i.e. its number of elements is
bounded by a natural number.
6 The language of E-PAω∗
st contains a symbol stσ for each ﬁnite type σ, but the subscript
is essentially always omitted. Hence T ∗
st is an axiom schema and not an axiom..
7 A term is called closed in [3] if all variables are bound via lambda abstraction. Thus,
if x, y are the only variables occurring in the term t, the term (λx)(λy)t(x, y) is
closed while (λx)t(x, y) is not. The second axiom in Deﬁnition 2.3 thus expresses that
stτ

(λx)(λy)t(x, y)

if (λx)(λy)t(x, y) is type τ. We shall omit lambda abstraction.

Metastability and Higher-Order Computability
315
(iii) The schema st(f) ∧st(x) →st(f(x)).
(iv) The external induction axiom IAst: For any external formula Φ:
Φ(0) ∧(∀stn0)(Φ(n) →Φ(n + 1)) →(∀stn0)Φ(n).
Secondly, we introduce some essential fragments of IST studied in [3].
Deﬁnition 2.4 (External axioms of P)
1. HACint: For any internal formula ϕ, we have
(∀stxρ)(∃styτ)ϕ(x, y) →

∃stF ρ→τ ∗
(∀stxρ)(∃yτ ∈F(x))ϕ(x, y),
(2.4)
2. I: For any internal formula ϕ, we have
(∀stxσ∗)(∃yτ)(∀zσ ∈x)ϕ(z, y) →(∃yτ)(∀stxσ)ϕ(x, y),
The system P is then deﬁned as E-PAω∗
st + I + HACint.
Note that I and HACint are fragments of Nelson’s axioms Idealisation and Stan-
dard part. By deﬁnition, F in (2.4) only provides a ﬁnite sequence of witnesses
to (∃sty), explaining its name Herbrandized Axiom of Choice.
Now, P is connected to E-PAω by Theorem 2.5, which is essential to this
paper. Indeed, Theorem 2.5 expresses that we may obtain eﬀective results as in
(2.6) from any theorem of NSA which has the same form as (2.5). By results in
[21–25], the scope of Theorem 2.5 is huge.
Theorem 2.5 (Term Extraction). For Δint a collection of internal formulas
and ψ internal, if
P + Δint ⊢(∀stx)(∃sty)ψ(x, y, a),
(2.5)
then one can extract from the proof a sequence of closed terms t in T ∗such that
E-PAω∗+ Δint ⊢(∀x)(∃y ∈t(x))ψ(x, y, a).
(2.6)
Proof. See [21, Sect. 2], [23, Sect. 2], or [24, Appendix].
⊓⊔
Note that the conclusion of the theorem, namely (2.6), does not involve NSA
anymore. The term t from the previous theorem is part of G¨odel’s system T, i.e.
essentially a computer program. For the rest of this paper, the notion ‘normal
form’ shall refer to a formula as in (2.5), i.e. of the form (∀stx)(∃sty)ϕ(x, y) for
ϕ internal. For an internal formula ϕ, the (possibly external) ϕst is obtained by
appending ‘st’ to all quantiﬁers, except bounded numerical ones.
Next, we show that Theorem 2.5 works for weaker systems.
1. Let E-PRAω be the system deﬁned in [13, Sect. 2] and let E-PRAω∗be its
deﬁnitional extension with types for ﬁnite sequences as in [3, Sect. 2].
2. (QF-ACρ,τ) For every quantiﬁer-free internal formula ϕ(x, y), we have
(∀xρ)(∃yτ)ϕ(x, y) →(∃F ρ→τ)(∀xρ)ϕ(x, F(x))
(2.7)

316
S. Sanders
The system RCAω
0 is E-PRAω + QF-AC1,0, which is the ‘base theory of higher-
order Reverse Mathematics’ as introduced in [13, Sect. 2]. We permit ourselves
a slight abuse of notation by also referring to E-PRAω∗+ QF-AC1,0 as RCAω
0 .
Corollary 2.6. Theorem 2.5 goes through for P and E-PAω∗replaced by P0 ≡
E-PRAω∗+ T ∗
st + HACint + I + QF-AC1,0 and RCAω
0 .
Proof. The proof of [3, Theorem 7.7] goes through for any fragment of E-PAω∗
which includes EFA, sometimes also called IΔ0 + EXP. In particular, the expo-
nential function is (all what is) required to ‘easily’ manipulate ﬁnite sequences. ⊓⊔
Most of our results will pertain to P0 and RCAω
0 . We refer to [13, Sect. 3] for
the usual deﬁnition (involving fast-converging Cauchy sequences) of real number,
the associated equality ‘=R’, and related notions inside RCAω
0 . We ﬁnish with
the following remark on how HACint and I are used.
Remark 2.7 (Using HACint and I). By deﬁnition, HACint produces the func-
tional F σ→τ ∗which outputs a ﬁnite sequence of witnesses. However, HACint pro-
vides an actual witnessing functional assuming (i) τ = 0 in HACint and (ii) the
formula ϕ from HACint is ‘suﬃciently monotone’ as in: (∀stxσ, n0, m0)

[n ≤0
m ∧ϕ(x, n)] →ϕ(x, m)

. Indeed, in this case one simply deﬁnes Gσ+1 by
G(xσ) := maxi<|F (x)| F(x)(i) which satisﬁes (∀stxσ)ϕ(x, G(x)). To save space
in proofs, we may skip the step involving the maximum of ﬁnite sequences. We
assume the same convention for terms obtained from Theorem 2.5, and applica-
tions of the contraposition of idealisation I.
Nonstandard Compactness and Related Notions. We discuss some results
from NSA. We will observe that the special fan functional Θ emerges from the
nonstandard compactness of 2N. The fragment of Transfer for Π0
1-formulas is:
(∀stf 1)

(∀stn)f(n) ̸= 0 →(∀m)f(m) ̸= 0

(Π0
1−TRANS)
is the nonstandard counterpart of arithmetical comprehension as in ACA0.
Similar to how one ‘bootstraps’ Π0
1-comprehension to the latter, the system
P0 + Π0
1−TRANS proves ϕ ↔ϕst for any internal arithmetical formula (only
involving standard parameters). The following fragment of Standard Part is the
nonstandard counterpart of weak K¨onig’s lemma ([10]):
(∀α1 ≤1 1)(∃stβ1 ≤1 1)(α ≈1 β),
(STP)
where α ≈1 β is (∀stn)(α(n) =0 β(n)). Note that STP expresses the nonstandard
compactness of Cantor space as in Robinson’s theorem ([6, p. 42]). There is no
deep meaning in the words ‘nonstandard counterpart’: This is just what STP
and Π0
1−TRANS are called in [10,23,27].
Secondly, the following theorem provides a normal form for STP and estab-
lishes a connection to Θ. In particular, the latter emerges from STP when apply-
ing Theorem 2.5. Note that STPR is the statement (∀x ∈[0, 1])(∃sty ∈[0, 1])
(x ≈y), i.e. the nonstandard compactness of the unit interval, where inﬁnitesi-
mal proximity ‘x ≈y’ is just [x =R y]st.

Metastability and Higher-Order Computability
317
Theorem 2.8. In P, STP is equivalent to STPR and to the following:
(∀stg2)(∃stw1∗≤1∗1, k0)(∀T 1 ≤1 1)

(∀α1 ∈w)(αg(α) ̸∈T)
(2.8)
→(∀β ≤1 1)(∃i ≤k)(βi ̸∈T)

,
and is equivalent to
(∀T ≤1 1)

(∀stn)(∃β0)(|β| = n ∧β ∈T) →(∃stα ≤1 1)(∀stn0)(αn ∈T)

.
(2.9)
Furthermore, P0 proves (∃stΘ)SCF(Θ) →STP.
Proof. See e.g. [24, Appendix] or [21, Sect. 3].
⊓⊔
By the theorem, STP is just WKLst with the leading ‘st’ dropped; this observation
explains why STP deserves the monicker ‘nonstandard counterpart of WKL’.
3
Metastability and Computability
We apply the metastability trade-oﬀfrom Sects. 1 and 2.2 to basic mathematical
theorems, i.e. we introduce in the latter ﬁnite domains in exchange for high(er)
levels of uniformity. In contrast to the eﬀective results from proof mining (per-
taining to metastability) mentioned in Sect. 1, we obtain the special fan func-
tional Θ from Sect. 2.3. As the latter functional cannot be computed by any
type two functional, we obtain a hard limit on the generality of the metastabil-
ity trade-oﬀ. We shall study the intermediate value theorem, variations of the
extreme value theorem, a theorem pertaining to Riemann integration, and BD-N.
3.1
The Intermediate Value Theorem
We apply the metastability trade-oﬀto the intermediate value theorem (IVT),
which states that a continuous function f : I →R on I = [0, 1] such that
f(0)f(1) <R 0 has a zero, i.e. (∃x ∈I)(f(x) =R 0). Unless explicitly stated,
notions like continuity, convergence, etc. have their usual ‘epsilon-delta’ deﬁni-
tions, not involving NSA. The nonstandard continuity of f : I →R is :
(∀stx ∈I)(∀y ∈I)(x ≈y →f(x) ≈f(y)).
(3.1)
As to its history, IVT is an example of a non-constructive theorem, as it implies a
fragment of the law of excluded middle (See [2, I.7]). There are a number of con-
structive versions of IVT, e.g. dealing with approximate intermediate values like
(∀k0)(∃q0 ∈I)(|f(q)| < 1
k) as in [4, II.4.8]. Furthermore, Kohlenbach introduces
‘uniform IVT’ in [13] where Φ(1→1)→1 outputs a zero on input a function f 1→1
as in IVT. Over RCAω
0 , such a functional Φ computes (via a term of G¨odel’s T)
the following ‘arithmetical comprehension functional’ by [13, Proposition 3.14]:
(∃ϕ2)(∀f 1)

(∃n0)(f(n) = 0) ↔ϕ(f) = 0

.
(∃2)

318
S. Sanders
Hence, there is no way to compute intermediate values in general, and we shall
therefore consider the following equivalence inspired by metastability:
(∃x ∈I)(f(x) =R 0) ↔(∀G2)(∃x ∈I)(|f(x)| <
1
G(x)).
(3.2)
The left-hand side of (3.2) expresses that f has a zero, and has the form ‘∃∀’
due to the presence of ‘=R’. The right-hand side of (3.2) expresses that f has a
‘metastable zero’, and has the form ‘∀∃’. Furthermore, the following holds (even
constructively) for continuous f : I →R, namely (∃x ∈I)(f(x) =R 0) implies
(∀G2)(∃x ∈I)(|f(x)| <
1
G(x)) →(∀k0)(∃q0 ∈I)(|f(q)| < 1
k).
In light of the previous, we expect that computing a metastable zero is at most as
hard as computing (∃2) and at best computable. The question however remains
which inputs we shall use to compute a metastable zero, besides G2 as in (3.2).
We provide the following answer:
First of all, an indispensable part of an ‘epsilon-delta’ deﬁnition in construc-
tive/computable mathematics is the modulus, which computes the delta from
the epsilon (and other data). Moreover, in the case of Riemann integration on
I, a modulus of uniform continuity suﬃces to obtain a modulus of Riemann
integration (See [4, p. 51]). Hence, to obtain highly uniform results as suggested
by the metastability trade-oﬀ, it makes sense (in general) to keep the modulus of
continuity as input and omit the function as input.
Secondly, we mentioned approximate versions of IVT above; it is fairly easy to
show that there is a term t from G¨odel’s T such that for k0 and f : [0, 1] →R with
modulus of continuity H and f(0)f(1) <R 0, we have (∃q0 ∈t(H))(|f(q)| < 1
k).
This fact will be proved below in Theorem 3.7 and we stress that the term t
only depends on the modulus of continuity H. Hence, to obtain highly uniform
results as suggested by the metastability trade-oﬀ, it makes sense (in the case of
IVT) to keep the modulus of continuity as input and omit f as input.
The previous leads us to the following ‘metastable’ version of IVT in which a
metastable zero is computed (only) from a modulus of continuity of the function
at hand, i.e. a uniform result. Note that Ψ provides a ﬁnite sequence of witnesses
to ‘(∃x ∈I)’, just as θ in (2.3).
Principle 3.1 (IVTmeta). There is Ψ 2→1∗such that for f
: [0, 1] →R
with modulus of cont. H2
and f(0)f(1)
<
0, (∀G2)(∃x
∈
Ψ(G, H))

x ∈I ∧|f(x)| <
1
G(x)

.
We could require that H in IVTmeta be continuous (in the usual epsilon-delta
sense), but that would not really change any of the below results. As noted above,
we expect that computing a metastable zero is at most as hard as computing (∃2).
Such ‘great expectations’ turn out to be spectacularly wrong: Ψ as in IVTmeta is
surprisingly hard to compute by the following theorem, where IVTmeta(Ψ) is just
IVTmeta with the leading existential quantiﬁer dropped.
Theorem 3.2 (ZFC). A functional Ψ satisfying IVTmeta(Ψ) can be computed
from ξ3 as in (∃3). No type two functional can compute such a functional Ψ.

Metastability and Higher-Order Computability
319
As noted above, we shall make use of NSA to prove Theorem 3.2. To this end,
we introduce the following somewhat subtle8 nonstandard version of IVT.
Deﬁnition 3.3 (IVTns). For f : [0, 1] →R with standard modulus of continuity
and f(0)f(1) <R 0, we have (∃stx ∈[0, 1])(f(x) ≈0).
Theorem 3.4. The system P0 proves STP ↔IVTns.
Proof. For the forward direction, we imitate the usual proof of IVT as follows:
If for f as in IVTns, there is standard and rational q0 ∈[0, 1] such that f(q) ≈
0, we are done. Otherwise, we have (∀stq0 ∈I)(∃stk0)(|f(q)| >
1
k). Applying
HACint, there is standard Φ0→0∗such that (∀stq0 ∈I)(∃k0 ∈Φ(q))(|f(q)| > 1
k).
Now deﬁne g1 as follows: g(q) := maxi<|Φ(q)| Φ(q)(i). Hence, we have (∀stq0 ∈
I)(|f(q)| >
1
g(q)). Approximating the function values of f up to precision 2g(q),
we can decide whether f(q) ≫0 or f(q) ≪0 for any standard q0 ∈[0, 1]. Now
use the usual interval halving technique (See [26, II.6.6]) relative to ‘st’ to deﬁne
a real x0 such that f(x0) ≈0. By STP, there is standard x1 ≈x0. Now, f as in
IVTns is also nonstandard continuous as in (3.1), as its modulus of continuity is
standard, implying f(x1) ≈f(x0) ≈0. For the reverse direction, assume IVTns
and ﬁx x0 ∈[0, 1]. Now consider f : [0, 1] →R deﬁned as f(x) := x −x0, which
has a standard modulus of continuity, namely H2 deﬁned as H(x1, k0) := k0.
Clearly, we have |f(x)| ≫0 for x ̸≈x0, and since IVTns implies there is standard
x1 ∈[0, 1] such that f(x1) ≈0, we must have x0 ≈x1, and STP follows.
⊓⊔
Here, SCF(Θ) is the speciﬁcation of the special fan functional from Sect. 2.3.
Corollary 3.5. There are terms s, t of G¨odel’s T such that RCAω
0 proves:
(∀Θ3)

SCF(Θ) →IVTmeta(s(Θ))

∧(∀Ψ)

IVTmeta(Ψ) →SCF(t(Ψ))

,
(3.3)
Proof. We shall prove the second conjunction of (3.3) in detail, and leave the ﬁrst
one to the reader. By Theorem 2.8, STP has a normal form as in (2.8), which we
abbreviate by (∀stg2)(∃stw1∗≤1∗1, k0)ϕ(g, w, k). We now obtain a normal form
for IVTns; the latter yields the following, where ‘MPC(f, H)’ expresses that H is
a modulus of continuity for f, and ‘f ∈D’ that f : [0, 1] →R ∧f(0)f(1) <R 0:
(∀stH2)(∀f ∈D)

MPC(f, H) →(∀stG2)(∃stx ∈[0, 1])(|f(x)| <
1
G(x))

.
Pulling outside all standard quantiﬁers as far as possible, we obtain the following:
(∀stH2, G2)(∀f ∈D)(∃stx ∈[0, 1])

MPC(f, H) →(|f(x)| <
1
G(x))

.
8 Note that IVTns looks fairly close to IVTst, and the latter is provable in P0. Nonethe-
less, IVTns turns out to be equivalent to STP from Sect. 2.4. Furthermore, an obvious
mistake is to apply Transfer to the conclusion of IVTns and conclude there is a stan-
dard intermediate value. Indeed, the function f from IVTns need not be standard,
making application of the Transfer axiom illegal, following Nelson [17].

320
S. Sanders
Let B(f, G, H) be the internal formula in square brackets in the previous formula;
applying Idealisation to the latter yields:
(∀stH2, G2)(∃sty1∗)(∀f ∈D)(∃x ∈y)B(f, G, H),
(3.4)
which is a normal form, abbreviated (∀stH2, G2)(∃sty1∗)ψ(H, G, y). Hence, the
implication IVTns →STP yields
(∀stH2, G2)(∃sty1∗)ψ(H, G, y) →(∀stg2)(∃stw1∗≤1∗1, k0)ϕ(g, w, k),
(3.5)
and it is straightforward to obtain a normal form from (3.5) (See e.g. [24, Remark
4.8]). To further understanding, we will spell out how to obtain a normal from
(3.5) this once: Since standard functionals produce standard outputs from stan-
dard inputs, (3.5) implies that for all standard Ψ 2→1∗
(∀stH2, G2)ψ(H, G, Ψ(G, H)) →(∀stg2)(∃stw1∗≤1∗1, k0)ϕ(g, w, k).
We may trivially drop the remaining ‘st’ in the antecedent of the previous:
(∀stΨ 2→1∗)

(∀H2, G2)ψ(H, G, Ψ(G, H)) →(∀stg2)(∃stw1∗≤1∗1, k0)ϕ(g, w, k)

,
and bringing outside all standard quantiﬁers, we obtain a normal form:
(∀stΨ 2→1∗, g2)(∃stw ≤1, k0)

(∀H2, G2)ψ(H, G, Ψ(G, H)) →ϕ(g, w, k)

, (3.6)
Applying Theorem 2.5 to ‘P0 ⊢(3.6)’ yields a term t of G¨odel’s T such that
(∀Ψ, g2)(∃w ≤1, k ∈t(Ψ, g))

(∀H2, G2)ψ(H, G, Ψ(G, H)) →ϕ(g, w, k)

(3.7)
is provable in RCAω
0 . Now, (3.7) implies the second conjunct of (3.3) by bringing
the existential quantiﬁers into the consequent. Indeed, the antecedent of (3.7)
is exactly IVTmeta(Ψ), while for such Ψ, (3.7) yields (∀g2)(∃w1∗≤1∗1, k0 ∈
t(Ψ, g))ϕ(g, w, k), which readily implies the speciﬁcation of Θ.
⊓⊔
Theorem 3.2
is
now
immediate
from
Corollary 3.5
and
the
following
([19, Sect. 3]).
Theorem 3.6 (ZFC). A functional Θ satisfying SCF(Θ) can be computed from
∃3. No type two functional can compute such a functional Θ.
As an aside, the ‘hardness’ of IVTmeta is not due to the use of higher types: The
‘lower type’ version (3.8) of IVTmeta cannot be proved in RCAω
0 + QF-AC + (S2),
a Π1
3-conservative extension of Π1
1-CA0. This result is however beyond the scope
of this paper and requires results from [20].
(∀G2, H2)(∃w1∗)(∀f ∈D)

MPC(f, H) →(∃x ∈w)

|f(x)| <
1
G(x)

.
(3.8)
Finally, what is left is to prove the following theorem.

Metastability and Higher-Order Computability
321
Theorem 3.7. There is a term t from G¨odel’s T such that RCAω
0 proves that for
k0 and f ∈D with modulus of continuity H, we have (∃q0 ∈t(H))(|f(q)| < 1
k).
Proof. The theorem is established by modifying the proof of Corollary 3.5 to
apply to ‘P0 ⊢IVT′
ns’ (rather than P0 ⊢[IVTns →STP]); IVT′
ns is deﬁned as:
Deﬁnition 3.8 (IVT′
ns). For f : [0, 1] →R with standard modulus of continuity
and f(0)f(1) <R 0, we have (∀stk0)(∃stq0 ∈[0, 1])(|f(q)| < 1
k).
Note that IVT′
ns has a normal form similar to (3.4), i.e. applying Theorem 2.5
is straightforward. To prove IVT′
ns inside P0, consider the proof of the forward
implication in Theorem 3.4. Note that STP is only needed to convert x0 to a
standard real x1, i.e. we can decide inside P0 whether f(q) ≫0 or f(q) ≪0
for q0 ∈[0, 1] (if there is no standard rational r0 ∈I such that f(r) ≈0).
Use the interval halving technique ([26, II.6.6]) relative to ‘st’ to deﬁne (for
any standard k) qk such that |f(qk)| ≤
1
2k . By deﬁnition, qk is standard for
standard k.
⊓⊔
The ﬁnal step of the proof involves a hidden subtlety: while qk is a standard
rational for every standard k0, the (type one) function λk.qk is not a standard
function (since f may be nonstandard). This situation is actually familiar: every
binary sequence α1 is such that α(k) is standard (for all k0), while α1 itself may
not be a standard sequence.
3.2
On Maxima, Suprema, and Integrals
It goes without saying that the results regarding IVT from Sect. 3.1 can be
obtained for similar theorems. In this section, we discuss such results, but also
uncover some non-obvious pitfalls. Our main result is that applying the metasta-
bility trade-oﬀto theorems of constructive mathematics yields Θ. Thus, our
results are not a ‘defect’ of classical logic, but also come to the fore constructively.
The Extreme Value Theorem. We apply the metastability trade-oﬀto the
extreme value theorem (EVT), which is the statement that a continuous function
f : I →R attains its maximum, i.e. (∃y ∈I)(∀x ∈I)(f(x) ≤f(y)). The
treatment of EVT is similar to that of IVT.
As to its history, EVT is equivalent to WKL in Reverse Mathematics by [26,
IV.2.3]. As for IVT, Kohlenbach introduces ‘uniform EVT’ in [13] where Φ1→1
outputs y ∈I such that (∀x ∈I)(f(x) ≤R f(y)) on input a function f as in
EVT. In the presence of the axiom of extensionality, such a Φ also computes
(∃2) by [13, Proposition 3.14]. Hence, there is no way to (extensionally) com-
pute extreme values in general, and we shall therefore consider the notion of
‘metastable maximum’, similar to ‘metastable zero’ as in (3.2). In particular,
the following holds (even constructively) for continuous f : I →R, while the
reversal holds classically:
(∃y ∈I)(∀x ∈I)(f(x) ≤R f(y))
→(∀G1→1∗)(∃y ∈I)(∀x ∈G(y) ∩I)(f(x) <R f(y) +
1
|G(y)|+1).

322
S. Sanders
We say that ‘f has a metastable maximum’ if it satisﬁes the consequent. Inspired
by IVTmeta, we formulate the following ‘metastable’ version of EVT in which a
metastable maximum is computed (only) from a modulus of continuity.
Principle 3.9 (EVTmeta). There is Ψ 2→1∗such that for f : [0, 1] →R with
modulus of continuity H2, we have (∀G1→1∗)(∃y ∈Ψ(G, H) ∩I)(∀x ∈G(y) ∩
I)(f(x) <R f(y) +
1
|G(y)|+1).
We could require that f in EVTmeta be uniformly continuous (in the usual epsilon-
delta sense), but that would not really change any of the below results. We now
show that Ψ as in EVTmeta is surprisingly hard to compute by the following theo-
rem, where EVTmeta(Ψ) is just EVTmeta without the leading existential quantiﬁer.
Theorem 3.10 (ZFC). A functional Ψ satisfying EVTmeta(Ψ) can be computed
(∃3). No type two functional can compute such a functional Ψ.
As above, we shall make use of NSA to prove Theorem 3.10. To this end, we
introduce the following nonstandard version of EVT, similar to IVTns
Deﬁnition 3.11 (EVTns). For f : [0, 1] →R with standard modulus of conti-
nuity, we have (∃stx ∈[0, 1])(∀sty ∈[0, 1])(f(y) ⪅f(x)).
The use of WKL in the following proof is avoidable: we could require that H
in EVTmeta and EVTns be continuous (in the usual sense), and the only change
would be that we may remove WKL from the following theorem and corollary.
Theorem 3.12. The system P0 + WKL proves STP ↔EVTns.
Proof. For the forward direction, WKL implies the usual extreme value theorem
by combining [26, IV.2.3] and [14, Theorem 4.10]. Hence, f as in EVTns satisﬁes
(∃x0 ∈[0, 1])(∀y ∈[0, 1])(f(y) ≤R f(x0)). Now let x0 be as in the latter and
use STP to obtain standard x1 ≈x0. Since f as in EVTns is also nonstandard
continuous, we have (∀sty ∈[0, 1])(f(y) ⪅f(x1)). For the reverse direction,
assume EVTns and ﬁx x0 ∈[0, 1] such that 0 ̸≈x0 ̸≈1. Now consider f : [0, 1] →
R deﬁned as x/x0 if x ≤x0 and −x
3x0 + 4
3 otherwise; the function f has a standard
modulus of continuity, which is readily deﬁned using any standard a, b such that
0 ≪a <R x0 <R b ≪1 (which exist by assumption). Now f(x0) =R 1 and
f(x) ≪1 when x ̸≈x0 ∧x ∈I, and since EVTns implies there is standard
x1 ∈[0, 1] such that (∀stx ∈I)(f(x) ⪅f(x1)), we have x0 ≈x1.
⊓⊔
Corollary 3.13. There are terms s, t of G¨odel’s T such that RCAω
0 + WKL
proves:
(∀Θ3)

SCF(Θ) →EVTmeta(s(Θ))

∧(∀Ψ)

EVTmeta(Ψ) →SCF(t(Ψ))

,
(3.9)
Proof. Analogous to Corollary 3.5. Note that the conclusion of EVTns, namely
the formula (∃stx ∈[0, 1])(∀sty ∈[0, 1])(f(y) ⪅f(x)), implies a normal form:
(∀stG2→1∗)(∃stx ∈[0, 1])(∀y ∈G(x) ∩I)(f(y) <R f(x) +
1
|G(x)|+1),
as G(x) is standard (thus with only standard elements) for standard x, and hence
its length |G(x)| is also standard (by the axioms in Deﬁnition 2.3).
⊓⊔
Theorem 3.10 is now immediate from Corollary 3.13 and Theorem 3.6.

Metastability and Higher-Order Computability
323
Supremum of Continuous Functions. In this section, we apply the metasta-
bility trade-oﬀto a version of EVT which states the existence of a supremum. We
shall observe a non-obvious complication which does not occur for EVT itself.
On the other hand, the notion of supremum enables us to study a constructive
theorem, namely that a uniformly continuous (with a modulus) function on I has
a supremum (See [4, p. 94]). Despite the latter theorem’s constructive standing,
applying the metastability trade-oﬀresults in functionals computing Θ.
First of all, a word regarding variations of the above argument for EVT: a
function with a standard modulus of continuity can only have a standard supre-
mum if (and only if) it additionally has a standard upper bound. Thus, any
variation of EVTns involving the supremum of a function (rather than the attain-
ment of a maximum) must assume a standard upper bound on that function,
while such a bound is absent from EVTns itself. The same holds for EVTmeta,
which however is quite complicated compared to e.g. IVTmeta.
Deﬁnition 3.14 (SUPns). For f : [0, 1] →R with standard modulus of uniform
continuity and (∃stN 0)(∀x ∈I)(f(x) ≤R N), there is standard y1 such that
(∀stx ∈[0, 1])(f(x) ⪅y) ∧(∀stk0)(∃stz ∈I)(f(z) > y −1
k)

.
(3.10)
Principle 3.15 (SUPmeta). There is Ψ 2→1∗such that for f : I →R with mod-
ulus of continuity H2 and upper bound N 0 on I, and all G1→1∗and k0 we have:
(∃y ∈Ψ(G, H, N, k))(∀x ∈G(y) ∩I)(f(x) <R y +
1
|G(y)|)
∧(∃z ∈Ψ(G, H, N, k) ∩I)(f(z) > y −1
k).
Theorem 3.16. The system P0 + WKL proves STP ↔SUPns.
Proof. The forward direction is immediate by Theorem 3.12 as we clearly
have EVTns →SUPns. The reverse direction follows in the same way as for
Theorem 3.12 by ﬁxing x0 ∈I and considering the function f(x) := −x2 + 2x0x
(with obvious standard modulus of uniform continuity). Clearly, f(x0) = x2
0 and
if x ̸≈x0, we have f(x0) ≪x2
0. By SUPns, f has a standard supremum y1 as in
(3.10), and we must have x2
0 ≈y. Since √y is also standard, x0 ≈√y.
⊓⊔
Corollary 3.17. There are terms s, t of G¨odel’s T such that RCAω
0 + WKL
proves:
(∀Θ3)

SCF(Θ) →SUPmeta(s(Θ))

∧(∀Ψ)

SUPmeta(Ψ) →SCF(t(Ψ))

,
(3.11)
Proof. Analogous to Corollary 3.5.
⊓⊔
In conclusion, applying the metastability trade-oﬀto constructive theorems can
also give rise to Θ. One however needs to be careful: the treatment of suprema
and maxima diﬀers in a non-obvious way. Finally, SUPmeta is not that elegant;
we remedy this in the next section.

324
S. Sanders
Riemann Integration. We previously studied the non-constructive IVT and
EVT, while the results from Sect. 3.2 based on constructive mathematics were not
that elegant. Lest the reader gets the idea that theorems of constructive math-
ematics cannot (elegantly and naturally) give rise to the special fan functional,
we now study the statement that a uniformly continuous function is Riemann
integrable on I ([4, p. 51]). As above, applying the metastability trade-oﬀto this
constructive theorem, gives rise to the special fan functional.
Bishop proves in [4, 6.6.3] that for f : I →R with modulus of uniform
continuity g1, this modulus is also a modulus of Riemann integration for f. The
Riemann sum Sn(f) is deﬁned (essentially) as 2n
i=0 f( i
2n ) 1
2n , and for n →∞the
latter is shown to converge to the Riemann integral
 1
0 f(x)dx. Constructively
(and with a classical equivalence), the previous implies that
(∀G2)(∃x1)(∀k0, n0 ≤G(x))(n ≥2g(k) →|Sn(f) −
 1
0 f(x)dx| < 1
k),
(3.12)
for f with modulus of uniform continuity g1. The following principle states that
we can uniformly compute a ‘metastable integral’ as in (3.12), assuming an upper
and lower bound.
Principle 3.18 (RIEmeta). There is Ψ (1→1)→1∗such that for f : [0, 1] →R with
modulus of uniform continuity g1 and bound N 0 such that (∀x ∈I)(|f(x)| ≤N):
(∀G2)(∃x1 ∈Ψ(G, N))(∀k0, n0 ≤G(x))(n ≥2g(k) →|Sn(f) −x| < 1
k). (3.13)
As discussed in Sect. 3.1, to obtain highly uniform results as suggested by the
metastability trade-oﬀ, it makes sense to keep the modulus of continuity as input
and omit the function as input. Furthermore, (2.3) does not depend on the choice
of sequence a(·), while Riemann integration deals with the convergence of the
sequence Sn(f). Hence, the functional Ψ as in (3.13) from RIEmeta should be
independent of Sn(f), and hence deﬁnitely be independent of f.
To establish the properties of RIEmeta, we need a nonstandard principle.
Deﬁnition 3.19 (RIEns). For f : [0, 1] →R with standard modulus of uniform
cont. g1 and such that (∃stN 0)(∀x ∈I)(|f(x)| ≤R N), there is standard y1 with
(∀stk0, n0)(n ≥2g(k) →|Sn(f) −y| < 1
k).
(3.14)
It is an easy exercise to see that the bound N is essential.
Theorem 3.20. The system P0 proves STP ↔RIEns.
Proof. The forward direction is almost immediate as follows: for f as in RIEns,
the Riemann integral exists by following the usual proof (not involving ‘st’) in
constructive ([4, 6.6.3]) or computable ([26], IV.2.6) mathematics. For (standard)
N as in RIEns, the Riemann integral is a real x in [−N, N], and use STP to obtain
a standard y such that x ≈y. The reverse direction follows by ﬁxing x0 ∈I and
considering f(x) :=
x0
e−1ex (with obvious standard modulus of uniform continuity
and standard bounds). By RIEns, there is a standard y1 such that (3.14) and apply
overspill (See [3, Prop. 3.3]) to the latter to obtain nonstandard M 0 such that
SM(f) ≈y. Since SM(f) ≈
 1
0 f(x)dx = x0, we obtain STPR from y ≈x0.
⊓⊔

Metastability and Higher-Order Computability
325
Corollary 3.21. There are terms s, t of G¨odel’s T such that RCAω
0 proves:
(∀Θ3)

SCF(Θ) →RIEmeta(s(Θ))

∧(∀Ψ)

RIEmeta(Ψ) →SCF(t(Ψ))

,
(3.15)
Proof. Analogous to Corollary 3.5.
⊓⊔
3.3
The Principle BD-N
In this section, we apply the metastability trade-oﬀto the ‘boundedness’ princi-
ple BD-N, and obtain Θ in the process. The BD-N axiom deals exclusively with
sets of natural numbers, i.e. BD-N is ‘more basic’ than e.g. IVT in the sense
that it involves only objects of types zero and one. Another interesting aspect
of BD-N is that it yields a number of variations, all of which however give rise
to Θ, i.e. our results exhibit some robustness.
First of all, as to its provenance, BD-N was introduced by Ishihara ([8,9])
and is an example of a statement which can be proved in classical, recursive, and
intuitionistic mathematics, but cannot be proved in (systems generally consid-
ered providing formalisations of) Bishop’s constructive analysis ([7,15]). Now,
BD-N is the statement that a countable inhabited pseudo-bounded subset of N,
is also bounded; a set X ⊆N is pseudo-bounded if
(∀s1
(·))

(∀n0)(sn ∈X) →(∃k0)(∀n ≥k)(sn < n)

.
(3.16)
Secondly, Normann shows in [18, Example 2.6] that BD-N fails in Kleene’s second
model K2. In particular, the upper bound claimed to exist by BD-N cannot
be computed (in the sense of K2) from the other data. Now, the notion of
upper bound of a set X ⊂N has the typical ‘∃∀’ structure which invites the
modiﬁcation involving [M, F(M)] as in metastability (2.2):
(∃k0)(∀n ≥k)(n ̸∈X) ↔(∀g1)(∃k0)(∀n ∈[k, g(k)])(n ̸∈X).
(3.17)
We say that X ⊂N is metastable-bounded if it satisﬁes the right-hand side of
(3.17); a functional G2 outputting an upper bound to k0 from g1 is called a rate
of metastable-boundedness.
It is now a natural question from what inputs we should compute a rate of
metastable-boundedness: We could use a realiser for (3.16), but we could equally
well use a realiser for (3.18), which introduces the notion of metastable-pseudo-
bounded for X as follows:
(∀s1
(·))

(∀n)(sn ∈X) →(∀h1)(∃k0)(∀n0 ∈[k, h(k)])(sn < n)

.
(3.18)
As we will establish below, either version gives rise to the special fan functional
when applying the metastability trade-oﬀ. Finally, since metastable-boundedness
-for ﬁxed g1 in (3.17)- only provides approximations to actual upper bounds, it
seems reasonable that for such ﬁxed g1, we can compute k0 such that [k, g(k)] ∩
X = ∅by only making use of (3.16) or (3.18) for a ﬁnite number of sequences
s(·) (dependent on the choice of g and other data).
The previous considerations lead to two versions of ‘metastable BD-N’.

326
S. Sanders
Deﬁnition 3.22 (BD-Nmeta). There is Ψ such that for all X1, m0 ∈X, g1, G2:
(∀s1
(·), h1 ∈Ψ(m, g, G)(1))

(∀n)(sn ∈X)
→(∃k0 ≤G(s(·), h))(∀n0 ∈[k, h(k)])(sn < n)

→(∃n ≤Ψ(m, g, G)(2))(∀k ∈[n, g(n)])(k ̸∈X).
Deﬁnition 3.23 (BD-N′
meta). There is Ψ such that for all X1, m0 ∈X, g1:
(∀s1
(·) ∈Ψ(m, g)(1))

(∀n)(sn ∈X) →(∃k0)(∀n ≥k)(sn < n)

.
→(∃n ≤Ψ(m, g)(2))(∀k ∈[n, g(n)])(k ̸∈X).
Note that Ψ does not have access to the set X as an input, as suggested by
the metastability trade-oﬀ. Furthermore, since LPO →BD-N in constructive
mathematics (See [7]), (∃2) yields a realiser for BD-N. Nonetheless, we now show
that Θ computes Ψ as in BD-Nmeta via a term of G¨odel’s T, and vice versa. We
shall use ‘nonstandard BD-N’ as follows.
Deﬁnition 3.24 [BD-Nns]. For any set X1 and any standard m0 ∈X:
(∀sts1
(·))

(∀n)(sn ∈X) →(∃stk)(∀stn ≥k)(sn < n)

→(∃stn)(∀stk ≥n)(k ̸∈X).
(3.19)
The absence of ‘st’ in ‘(∀n)(sn ∈X)’ in (3.19) (only) leads to a nicer normal
form; the standard m0 ∈X is however essential, as is clear from the following
proof. Let BD-N′
ns be BD-Nns with (∃k)(∀n ≥k)(sn < n) in the antecedent
(which follows from BD-Nns via Π0
1−TRANS).
Theorem 3.25. The system P0 proves STP ↔BD-Nns; P0 + TRANS proves
STP ↔BD-N′
ns.
Proof. For the ﬁrst forward implication, ﬁx X1
0 and standard m0
0 ∈X0 such that
(∀sts1
(·))

(∀n)(sn ∈X0) →(∃stn)(∀stk ≥n)(sk < k)

(3.20)
Now ﬁx standard t1
(·) such that (∀stn)(tn ∈X0) and suppose (∀stn)(∃stk ≥
n)(tk ≥k). Applying HACint, there is standard f 1 such that (∀stn)(f(n) ≥
n ∧tf(n) ≥f(n)). Now deﬁne the standard sequence s(·) by sn := tf(n) if
tf(n) ≥n, and m0 otherwise. Clearly, s(·) satisﬁes the antecedent of (3.20), and
hence there is some standard n0 such that (∀stk ≥n0)(sk < k). By deﬁnition,
we have (∀stk ≥n0)(k > sk = tf(k) ≥k), a contradiction. Thus, we have:
(∀stt1
(·))

(∀stn)(tn ∈X0) →(∃stn)(∀stk ≥n)(tk < k)

(3.21)
follows from (3.20), i.e. we may indeed drop the ‘st’ in the antecedent of
BD-Nns, as claimed right after Deﬁnition 3.24. In light of the connection between
(3.20) and (3.21), P0 + STP proves [BD-N]st →BD-Nns as X only occurs as
‘call by (standard) value’. To establish [BD-N]st in P0, suppose X is standard
and satisﬁes (∀stn)(∃stk ≥n)(k ∈X). Applying HACint, there is standard

Metastability and Higher-Order Computability
327
Φ0→0∗such that (∀stn)(∃k ∈Φ(n))(k ≥n ∧k ∈X). Since X is actually a
standard binary sequence, one readily uses Φ to deﬁne standard g1 such that
(∀stn)(g(n) ≥n ∧g(n) ∈X). Clearly, X is not pseudo-bounded relative to ‘st’,
due to the sequence g, and [BD-N]st follows.
For the ﬁrst reverse implication, we establish BD-Nns →(2.9) in P0, and the
theorem then follows from Theorem 2.8. Working in P0 + BD-Nns, ﬁx T ≤1 1
such that (∀stn)(∃β0)(|β| = n ∧β ∈T). Applying overspill ([3, Proposition 3.3])
to the latter formula yields β0∗
0
such that ¬st(|β0|) and β0 ∈T. Now deﬁne the
set X := {β01, β02, β03, . . . } ⊆N using a (standard) sequence coding function π.
Note that for standard n, the sequence β0n is standard as it has standard length
n and standard inputs (See [3, Corollary 2.19]). Hence, X satisﬁes (∀stn)(∃stk ≥
n)(k ∈X) and by BD-Nns there is a standard sequence s1
(·) of elements of X such
that (∀stn)(∃stk ≥n)(sk ≥k). Applying HACint to the latter, there is standard
f 1 such that (∀stn)(sf(n) ≥f(n) ∧f(n) ≥n). Let the (standard) function h1 be
such that (∀x0∗≤1, n0)(|x| < n →π(x) < h(n)). By deﬁnition, sf(h(n)) codes a
subsequence of β0 of at least length n due to sf(h(n)) ≥h(n) (for standard n).
Modulo the (standard) decoding function associated to π, the standard function
λn.sf(h(n)) thus deﬁnes a standard path of T, i.e. (∀stn0)(sf(h(n)) ∈T). Hence, we
obtain (2.9). The second equivalence is now immediate as Π0
1−TRANS allows us
to drop the second and third ‘st’ in the antecedent of (3.19). Indeed, the formula
(∃stk)(∀stn ≥k)(sn < n) does not involve X (which is nonstandard), while the
only other parameter is the standard s(·).
⊓⊔
The proof of the ﬁrst forward implication contains a subtlety: To deﬁne the
standard g1 from Φ, it is essential that X be standard. Thus, P0 proves BD-Nst,
but to conclude BD-Nns, STP is essential, as is also clear from the theorem.
Corollary 3.26. The functional Ψ from BD-Nmeta computes Θ via a term of
G¨odel’s T, and vice versa, provable in RCAω
0 .
Proof. Proceed as for Corollary 3.5 for STP ↔BD-Nns. A normal form for BD-Nns
is obtained using the ‘metastability trick’ of introducing [M, F(M)] as in (2.2)
on both the consequent and antecedent, and bringing outside the standard quan-
tiﬁers (using Idealisation I).
⊓⊔
Applying the ECF-translation (See [13, Sect. 2] for details) to the previous proof,
we observe that WKL ↔[BD-Nmeta]ECF, i.e. weak K¨onig’s lemma turns out to be
equivalent to computing a metastable bound for BD-N from continuous (as in
Reverse Mathematics) realisers for pseudo-boundedness. This result should be
compared to [18, Example 2.6]. Finally, we need Feferman’s ‘search functional’
μ2 which is deﬁned by the following speciﬁcation:
(∀f 1)

(∃n0)(f(n) = 0) →f(μ(f)) = 0

.
(MU(μ))
Corollary 3.27. The functional Ψ from BD-N′
meta computes Θ via a term of
G¨odel’s T with input Feferman’s μ2, and vice versa, provable in RCAω
0 + (μ2).

328
S. Sanders
Proof. Proceed as for Corollary 3.5 for [STP + Π0
1−TRANS] →BD-N′
ns and
[Π0
1−TRANS + BD-N′
ns] →STP. A normal form for BD-N′
ns is readily obtained
using the ‘metastability trick’ of introducing [M, F(M)] as in (2.2) on the con-
sequent (only); Π0
1−TRANS is equivalent to:
(∀stf 1)(∃stn0)

(∃m0)(f(m) = 0) →f(n) = 0

,
(3.22)
which is a normal form, and explains the presence of Feferman’s μ2.
⊓⊔
As an aside, similar to IVTmeta, the ‘hardness’ of BD-Nmeta is not due to the
use of high types. There is a second-order version of BD-Nmeta which cannot be
proved in RCAω
0 + QF-AC + (S2), a Π1
3-conservative extension of Π1
1-CA0. This
result is however beyond the scope of this paper.
3.4
Computing the Special Fan Functional
In this section, we provide a short and elegant derivation of Θ in second-order
arithmetic. This signiﬁcantly improves the associated result from [19]. We need
the following instance of Tranfer:
(∀stY 2)

(∃f 1)(Y (f) = 0) →(∃stf 1)(Y (f) = 0)

,
(SOT)
and recall HBU introduced in Sect. 2.3, which follows from Cousin’s lemma ([5]);
the latter is essentially the Heine-Borel theorem in the general case, i.e. the
statement that any (possibly uncountable) open cover of I has a ﬁnite sub-cover.
We have the following theorem.
Theorem 3.28. The system P0 + HBU proves SOT →STP.
Proof. First of all, SOT implies Π0
1−TRANS and hence (3.22). Apply HACint to
the latter, bearing in mind Remark 2.7, and obtain standard μ2 such that
(∀stf 1)(∃n0 ≤μ(f))

(∃m0)(f(m) = 0) →f(n) = 0

.
(3.23)
Applying SOT to (3.23) yields (∃stμ2)MU(μ). Now, HBU trivially implies:
(∀Ψ 2)(∃w1∗)(∀q0 ∈I)(∃y ∈w)(|q −y| <
1
Ψ(y)+1).
(3.24)
Thanks to (∃stμ2)MU(μ), the underlined formula in (3.24) is equivalent to a
formula Y0(Ψ, w) = 0 for any Ψ, w, and where Y 3
0 is standard. For standard Ψ 2,
apply SOT to (∃w1∗)Y0(Ψ, w) = 0, yielding:
(∀stΨ 2)(∃stw1∗)(∀q0 ∈I)(∃y ∈w)(|q −y| <
1
Ψ(y)+1),
(3.25)
and the latter readily yields STP. Indeed, (3.25) trivially implies:
(∀stΨ 2)(∀q0 ∈I)(∃sty)(|q −y| <
1
Ψ(y)+1),
(3.26)

Metastability and Higher-Order Computability
329
as a standard sequence w1∗only has standard elements (and standard length)
by Deﬁnition 2.3. But (3.26) also trivially yields (by switching quantiﬁers):
(∀q0 ∈I)(∀stΨ 2)(∃sty ∈I)(|q −y| <
1
Ψ(y)+1),
(3.27)
and the underlined formula in (3.27) is equivalent (using the usual ‘metastability’
trick and HACint) to (∃sty ∈I)(∀stk0)(|q −y| < 1
k). Now, for nonstandard N 0
and x1 ∈I, we have x ≈[x](N) where [x](N) is the N-th approximation of x.
Hence, we have obtained (∀x1 ∈I)(∃sty ∈I)(x ≈y), which is equivalent to STP
by Theorem 2.8.
⊓⊔
Consider the following speciﬁcation, similar to SO(ξ) from Sect. 2.3, as follows:
(∀Y 2)

(∃f 1)(Y (f) = 0) →Y (ξ(Y )) = 0

.
(SOC(ξ))
Corollary 3.29. There is t in G¨odel’s T such that RCAω
0 + HBU proves that
(∀ξ)

SOC(ξ) →SCF(t(ξ))].
Proof. Apply term extraction as in Theorem 2.5 to the proof of the theorem. ⊓⊔
The previous corollary signiﬁcantly improves the associated result from
[19, Sect. 3]:
1. The base theory in Corollary 3.29 is conservative9 over WKL0, which is weak
compared to the results in [19, Sect. 3].
2. The extracted term in Corollary 3.29 seems simpler than the one in
[19, Sect. 3].
Finally, the proof of the theorem can be adapted to show that HBU does not
follow from the existence of the Suslin functional (akin to the results claimed
for (3.8) and BD-Nmeta). However, we are running out of space and we would
require the (unpublished) results from [20].
References
1. Avigad, J., Dean, E.T., Rute, J.: A metastable dominated convergence theorem.
J. Log. Anal. 4, 1–19 (2012)
2. Beeson, M.J.: Foundations of Constructive Mathematics: Metamathematical Stud-
ies. Ergebnisse der Mathematik und ihrer Grenzgebiete, vol. 6. Springer, Heidelberg
(1985)
3. van den Berg, B., Briseid, E., Safarik, P.: A functional interpretation for nonstan-
dard arithmetic. Ann. Pure Appl. Logic 163, 1962–1994 (2012)
4. Bishop, E., Bridges, D.S.: Constructive Analysis, Grundlehren der Mathematischen
Wissenschaften, vol. 279. Springer, Berlin (1985)
9 It is an easy exercise to show that (3.24) is provable in RCAω
0 + MUC, where the
latter states the existence of the intuitionistic fan functional. The latter system is
conservative over WKL0 (See [13, Sect. 3]).

330
S. Sanders
5. Cousin, P.: Sur les fonctions de n variables complexes. Acta Math. 19(1), 1–61
(1895)
6. Hurd, A.E., Loeb, P.A.: An Introduction to Nonstandard Real Analysis, Pure and
Applied Mathematics, vol. 118. Academic Press Inc., Orlando (1985)
7. Ishihara,
H.:
Reverse
mathematics
in
Bishop’s
constructive
mathematics.
Philosophia Scientiae (Cahier Sp´ecial) 6, 43–59 (2006)
8. Ishihara, H.: Continuity properties in constructive mathematics. JSL 57, 557–565
(1992)
9. Ishihara, H.: Continuity and nondiscontinuity in constructive mathematics. JSL
56, 1349–1354 (1991)
10. Keisler, H.J.: Nonstandard arithmetic and reverse mathematics. Bull. Symb. Log.
12, 100–125 (2006)
11. Kohlenbach, U., Koutsoukou-Argyraki, A.: Rates of convergence and metastability
for abstract Cauchy problems generated by accretive operators. J. Math. Anal.
Appl. 423(2), 1089–1112 (2015)
12. Kohlenbach, U.: Applied Proof Theory: Proof Interpretations and Their Use in
Mathematics. Springer Monographs in Mathematics. Springer, Berlin (2008)
13. Kohlenbach, U.: Higher order reverse mathematics. In: Reverse mathematics 2001.
Lecture Notes in Logistics, vol. 21, pp. 281–295. ASL (2005)
14. Kohlenbach, U.: Foundational and mathematical uses of higher types. Lecture
Notes in Logistics, vol. 15, pp. 92–116. ASL (2002)
15. Lietz, P., Streicher, T.: Realizability models refuting Ishihara’s bound- edness prin-
ciple. Ann. Pure Appl. Log. 163(12), 1803–1807 (2012)
16. Longley, J., Normann, D.: Higher-Order Computability. Theory and Applications
of Computability. Springer, Heidelberg (2015)
17. Nelson, E.: Internal set theory: a new approach to nonstandard analysis. Bull. Am.
Math. Soc. 83(6), 1165–1198 (1977)
18. Normann, D.: The extensional realizability model of continuous functionals and
three weakly non-constructive classical theorems. Log. Methods Comput. Sci. 11,
1–27 (2015)
19. Normann, D., Sanders, S.: Nonstandard analysis, computability theory, and their
connections (2017, submitted). https://arxiv.org/abs/1702.06556
20. Normann, D.: Nonstandard analysis, computability theory, and metastability
(2017)
21. Sanders, S.: The Gandy-Hyland functional and a hitherto unknown computational
aspect of Nonstandard Analysis. Computability, arXiv: http://arxiv.org/abs/1502.
03622 (2015)
22. Sanders, S.: Grilliot’s trick in Nonstandard Analysis. Logical Methods in Computer
Science, Special Issue for CCC15 (2017)
23. Sanders, S.: The unreasonable eﬀectiveness of Nonstandard Analysis (2015).
http://arxiv.org/abs/1508.07434
24. Sanders, S.: To be or not to be constructive, Indagationes Mathematicae, p. 69,
arXiv: https://arxiv.org/abs/1704.00462 2017
25. Sanders, S.: The reﬁning of the taming of the Reverse Mathematics zoo. Notre
Dame J. Formal Log. (2016). http://arxiv.org/abs/1602.02270
26. Stephen, G.: Simpson, Subsystems of Second Order Arithmetic. Perspectives in
Logic, 2nd edn. CUP, Cambridge (2009)
27. Simpson, S.G., Yokoyama, K.: A nonstandard counterpart of WWKL. Notre Dame
J. Form. Log. 52(3), 229–243 (2011)
28. Tao, T.: Structure and randomness, pp. xii+298. American Mathematical Society,
Providence, RI (2008)

The Completeness of BCD
for an Operational Semantics
Rick Statman(B)
Department of Mathematical Sciences, Carnegie Mellon University,
Pittsburgh, PA 15213, USA
statman@cs.cmu.edu
Keywords: Lambda calculus · Intersection types
Completeness theorem · Operational semantics
1
Introduction
The theorem of Coppo et al. ([3,6]) states that an untyped lambda term is
strongly normalizable if and only if it provably has an intersection type. Here
we consider which terms have which types.
We deﬁne an operational semantics for the collection of intersection types which
assigns to every intersection type A a set of strongly normalizable terms [[A]]. We
show that the theory of intersection types BCD (Barendregt, Coppo, Dezani) [2],
pp. 582–583, proves X : A for an untyped term X if and only if X : [[A]] for all inter-
pretations of [[, ]] in the operational semantics. Here we shall use the notation ‘:’ for
both the formal statement that X has type A, and also set theoretic membership.
Our view of what operational semantics should be begins with Tait style
proofs ([8]) of strong normalization. These proofs consider a complete lattice of
sets S of strongly normalizable untyped terms ([2], 9.3). Not all such sets are
considered but the lattice operations are union and intersection. We require that
S is closed under reduction, and possibly some other conditions, such as head
expansion with strong normalizable arguments, depending on the variant. The
operation →is then introduced
S →T = {X|for all Y : S ⇒(XY ) : T}.
This is certainly familiar from the theory of logical relations ([2], 3.3) for the
simple typed case, positive recursive types, and our principal concern in this note;
intersection types. Given an intersection type A, if the atoms (atomic types) of
A are evaluated among the sets S then A has a value among the sets S. This
will be the interpretation [[A]].
2
Beth Models
SN is the set of strongly normalizable untyped terms. Here, we do not distinguish
beta from beta-eta strong normalizability since they are equivalent. A Beth
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 331–336, 2018.
https://doi.org/10.1007/978-3-319-72056-2_20

332
R. Statman
model consists of a pair (O, E) where O is a poset with partial order [, and E
is a monotone map from O x Atoms into the subsets of SN closed under beta
reduction and we shall assume that E(p, a) is non empty except possibly when
p is the [ smallest element of O, should this exist.
For λ terms X we deﬁne the “forcing relation” |= by
p |= X : a if for all q]p there exists r]q s.t. X : E(r, a)
p |= X : A/\B if p |= X : Ap |= X : B
p |= X : A →B if whenever q]p and q |= U : A there exists r]q
such that r |= (XU) : B
and we assume that E satisﬁes the generalized monotonicity property if [Y/x]X :
E(p, a), q]p, and q |= Y : A then there exists r]q such that (\xXY ) : E(r, a)
where [Y/x] is the the substitution operation (the term Y for the variable x).
Deﬁnition 1. An O chain (linearly ordered subset) W is generic if
(i) for any X and atom a there exists p : W such that either X : E(p, a) or
there is no q]p such that q |= X : a, and
(ii) for each A →B there exists p : W such that either p |= X : A →B or
there exists U and q : W such that q]p and q |= U : A but there is no r]q
such that r |= (XU) : B. We could just as easily use directed subsets of O
instead of chains but chains suﬃce.
For what follows the reader should consult the deﬁnition of BCD in [2] which
appears on pages 582–583, but without the top element (Utop). When we
wish to include the top element, Utop, together with its axiom ([2], p. 583),
we will write BCD+Utop. Especially, the reader should look at the deﬁnitions
of equality and the ordering of types on page 582. These are reproduced in
the appendix.
Facts
1. if p |= X : A and q]p then q |= X : A
2. p |= X : A iﬀfor each q]p there exists r]q s.t. r |= X : A
3. if p |= X : A and
A < B or A = B in BCD (page 582)
then p |= X : B
4. if W is generic then for any X and atom a there exists p : W such that for
all q]p we have q |= X : a or there is no q]p s.t. q |= X : a
5. if W is generic then for any X and A/\B there exists a p : W such that
p |= X : A/\B or there is no q]p such that q |= X : A/\B
6. if W is an O chain with a maximal element then there exists a generic O
chain extending W.
Proposition 1. Let W be a generic O chain and set R(A) = {X| there exists
p : W such that p |= X : A}. Let X : SN then

The Completeness of BCD for an Operational Semantics
333
(i) X : R(a) iﬀthere exists p : W s.t. X : E(p, a)
(ii) X : R(A →B) iﬀfor each
U : R(A) we have (XU) : R (B)
(iii) X : R(A/\B) iﬀX : R(A) & X : R(B)
Proof by induction on A. The basis case (i) is by deﬁnition. Induction step;
Case (ii) ⇒. Suppose that we have a p : W such that p |= X : A ⇒B and we
have U : R(A). Thus there exists q : W such that q |= U : A. By fact (1) we
may assume that q]p. Now for any r]q there exists t]r such that t |= (XU) : B
but W is generic so there must be an r : W such that r |= (XU) : B. That is
(XU) : R(B). ⇐. Suppose that for each U : R(A) we have (XU) : R(B). Now
if there is no p : W such that p |= X : A →B, since W is generic, there exists
p : W and aU such that p |= U : A but there is no q]p such that q |= (XU) : B.
But by fact (1) this contradicts the hypothesis. Case (iii) similar to case (ii).
End of proof.
The proposition clearly states that if the atoms a are evaluated {X| for some
p : W we have X : E(p, a)} then the value of the type A mentioned in the
introduction is R(A).
Example 1 (ﬁnite sets). In this case we let O be the collection of ﬁnite sets
of SN terms closed under beta-eta reduction and ordered by inclusion. We set
E(p, a) = p. Suppose that A = A(1) →(...(A(t) →)...) and ∼(p |= X : A).
Then there exists q]p and Y (1), ..., Y (t) s, t q |= Y (i) : A(i) for i = 1, ..., t
but there is no r]q with XY (1)...Y (t) : r. But this can only be the case if
XY (1)...Y (t) is not SN. Thus we can ﬁnd a generic W such that X : R(A) or
there exists Y (1), ..., Y (t) s.t. Y (i) : R(A(i)) for i = 1, ..., t and XY (1)...Y (t) is
not SN.
Example 2. In this case we consider sets S : O of closed beta-eta normal terms
for which there exists an integer n such that X : S iﬀevery path in the Bohm
tree of X has at most n lambdas and every node in the Bohm tree ([1], p. 212)
of X has at most n descendants. Then for any partial recursive function f which
is total on S and maps S to S there exists M : R(S →S) such that for any
N : S we have MN = f(N) modulo beta-eta conversion.
Proposition 2. Suppose that O has a smallest element 0. Then,
0 |= X : A iﬀfor every generic W we have
X : R(A).
Proof. Immediate by facts (1)–(6). End of proof.
We next consider the theory BCD with its provability relation ⊢as described
in [2] and reproduced in the appendix. A basis F is a map from a ﬁnite set of
lambda calculus variables, dom(F), to the set of types. Below we shall often
conﬂate F with the ﬁnite set
{x : F(x)|x : dom(F)}.
Let O, E be as above and W generic.

334
R. Statman
Proposition 3 (soundness). Suppose that @ is a substitution and F is a base
such that for all x : dom(F), @(x) : R(F(x)). Then if in BCD
F ⊢X : A
we have @(X) : R(A)
Now let O be the set of bases partially ordered by F[G iﬀdom(F) is contained
in dom(G) and for each x : dom(F) we have G(x) and F(x) are equal types in
BCD. Now deﬁne E(a) by X : E(F, a) if FV (X) is contained in dom(F) and
F ⊢X : a. Clearly E is [ monotone. In addition, E(F, a) is closed under beta-eta
reduction. However, generally E(F, a) is not closed under beta head expansion
for reasons similar to the case of BCD. In particular this happens when (\uUV )
reduces to X, u is not free in U and there is an x : FV (V )/\FV (U) such that
the basis entry x : F(x) prevents V from having a BCD type. Thus we have
to verify the generalized monotonicity property to insure soundness.First, we
observe that there is no diﬀerence between E and |= at atomic types.
Fact 7. F |= X : a iﬀX : E(F, a)
Proof. If FV (X) is contained in dom(F) then the equivalence follows from
the monotonicity of E and the weakening rule of BCD ([2], p. 585). Otherwise
suppose that F |= X : a. For each x : FV (X) −dom(F) add a new atom
a(x) and extend F to G by G(x) = a(x). Then G |= X : a so by the previous
argument G ⊢X : a in BCD. But we may substitute Utop for each a(x) and
(\x.xx)(\x.xx) for each x. So in BCD + Utop we have
F ⊢[..., (\x.xx)(\x.xx)/x, ...]X : a
and this contradicts the fact that if a term has a BCD type (Utop free) in
BCD + Utop then it is strongly normalizable (Theorem 17.2.15 (i) [2]).
Lemma 1. Suppose that FV (X) is contained in dom(F).
F |= X : A iﬀF ⊢X : A in BCD
Proof this is proved by induction on A. The basis case is by fact 7. For the
induction step the case A = B/\C is obvious. We consider the case A = B →
C. ⇒. Suppose that F |= X : B →C. Let z be a new variable and extend F
by G by with G(z) = B. Since G |= z : B by induction hypothesis G |= z : B
thus there exists H]G such that H |= Xz : C. Again by induction hypothesis
H ⊢Xz : C in BCD. Reasoning in BCD, H −{z : B} ⊢\z(Xz) : B →C. Now
by hypothesis FV (X) is contained in dom(F), so by weakening, F ⊢\z(Xz) :
B →C. Hence by subject reduction for eta ([2], p. 621)
F ⊢X : B →C.

The Completeness of BCD for an Operational Semantics
335
Conversely, suppose that F ⊢X : A. Let G]F and G |= U : B. By induction
hypothesis G ⊢U : B in BCD Thus by induction hypothesis G |= (XU) : C.
Hence
F |= X : B →C.
End of proof.
Corollary 1. Generalized monotonicity holds and we have a Beth model.
From the lemma we get the completeness theorem.
Theorem. Let M be closed. Then BCD ⊢M : A iﬀfor every Beth model
(O, E) and generic W, M : R(A).
Proof. ⇒. This is the soundness proposition. ⇐. Consider the Beth model
deﬁned by the conditions above. By Proposition 2 0 |= M : A. Hence by the
lemma ⊢M : A in BCD. End of proof.
Appendix
(1) terms and types
variables x, y, z, ... are terms
if X and Y are terms then so are (XY ) and \xX
atoms a, b, c, ... are types
if A and B are types then so are A/\B and A →B
(2) (quasi) order on types
A less than or equal A
A/\B less than or equal A
A/\B less than or equal B
(A →B)/\(A →C) less than or equal A →(B/\C)
if C less than or equal A and C less than or equal B
then C less than or equal A/\B
if C less than or equal B and B less than or equal A
then C less than or equal A
if A less than or equal C and D less than or equal B
then C →D less than or equal A →B
A equals B if A less than or equal B and
B less than or equal A
(3) axioms and rules of BCD
F ⊢x : A if (x : A) belongs to F
if F, x : A ⊢X : B then F ⊢\xX : A →B
if F ⊢X : A →B and F ⊢Y : A then F ⊢(XY ) : B
if F ⊢X : A and F ⊢X : B then F ⊢X : A/\B
if F ⊢X : A and A less then or equal B in BCD
then F ⊢X : B

336
R. Statman
References
1. Barendregt, H.P.: The Lambda Calculus. North Holland, New York (1981)
2. Barendregt, H., Dekkers, W., Statman, R.: Lambda Calculus with Types.
Cambridge University Press, New York (2013)
3. Coppo, M., Dezani, M.: A new type assignment for lambda terms. Archiv fur Math.
Logik 19, 139–156 (1978)
4. van Dalen, D.: Intuitionistic logic. In: Gobble, L. (ed.) The Blackwell Guide to
Philosophical Logic. Blackwell, Oxford (2001)
5. Plotkin, G.D.: Lambda deﬁnability in the full type hierarchy. In: Hindley, J.R.,
Seldin, J.P. (eds.) To H.B. Curry: Essays on Combinatory Logic, Lambda Calculus
and Formalism, pp. 363–373. Academic Press, London (1980)
6. Pottinger, G.: A type assignment for the strongly normalizable lambda terms. In:
Hindley, J., Seldin, J. (eds.) To H.B. Curry: Essays on Combinatory Logic, Lambda
Calculus and Formalism, pp. 561–577. Academic Press, London (1980)
7. Statman, R.: Logical relations and the typed lambda calculus. Inf. Contr. 165(2/3),
85–97 (1985)
8. Tait, W.W.: Constructive reasoning. In: Van Rootselaar, B., Staal, J.F. (eds.) Stud-
ies in Logic and the Foundations of Mathematics, vol. 52, pp. 185–199. Elsevier,
NorthHolland (1968)

A Tableau System for
Instantial Neighborhood Logic
Junhua Yu(B)
Department of Philosophy, Tsinghua University, Beijing 100084, China
junhua.yu.5036@outlook.com
Abstract. Extending classical propositional logic, instantial neighbor-
hood logic (INL) employs formulas like □(α1, ..., αj; α0). The intended
meaning of such a formula is: there is a neighborhood (of the current
point) in which α0 universally holds and none of α1, ..., αj universally
fails. This paper oﬀers to INL a tableau system that supports mechanical
proof/counter-model search.
Keywords: Neighborhood logic · Tableau
1
Instantial Neighborhood Logic
Instantial neighborhood logic (INL) [14] is a recent development in neighborhood
logic [4,12], a ﬁeld dedicated to describe neighborhood models using methods of
logic. In the most general setting, neighborhood models are deﬁned as triples of
the form (W, N, V ), where W is a non-empty set of points, N :: W →P(P(W))
is a neighborhood function that maps each point to a set of point-sets (called
neighborhoods), and V is a propositional valuation. The notion of neighborhood
model is related to both relational model (also known as Kripke model) [3,4]
and topological model [2], as they each can be seen as a neighborhood model
with additional properties.
Given a model M = (W, N, V ) and u ∈W, the generated sub-model of M by
u is Mu := (Wu, N ↾Wu, V ↾Wu) where Wu is the collection of all points in W
that can be reached from u via a chain of N−∋steps.1 As expected, at point u
models M and Mu agree on all INL-formulas [14].
Most of existing works on neighborhood logic use modal language, that is,
propositional language extended by unary operator □. There are two popular
ways to interpret a formula like □α: (A) the current point has a neighborhood
in which α universally holds; and (B) the set of all points satisfying α is a neigh-
borhood of the current point. It is obvious that (B) implies (A), and additional
J. Yu—Supported by Tsinghua University Initiative Scientiﬁc Research Program
20151080426.
1 By v1(N−∋)v2 we mean that v2 ∈S ∈N(v1) for some S ⊆W, i.e., v2 is a point in
a neighborhood of v1.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 337–353, 2018.
https://doi.org/10.1007/978-3-319-72056-2_21

338
J. Yu
conditions like monotonicity2 are required for the other direction to hold. These
two interpretations are equally good, but only on (A) INL naturally extends. In
this paper, the neighborhood logic that uses modal language with (A) is called
basic neighborhood logic (BNL).
Language of INL is classical propositional language enriched by a two-sorted
operator (also written as □). For each natural number j, if α0, α1, ..., αj are all
formulas, then so is □(α1, ..., αj; α0). In a neighborhood model, □(α1, ..., αj; α0)
means “the current point has a neighborhood in which α0 universally holds,
and none of α1, ..., αj universally fails”. That is to say, in order to jus-
tify □(α1, ..., αj; α0), a neighborhood should not only support α0 everywhere,
but also include ‘instantial’ points that respectively support α1, ..., αj. In
a □-preﬁxed formula like □(α1, ..., αj; α0), sub-formulas α1, ..., αj are called
instances. By a literal, we mean ⊤, ¬⊤, ⊥, ¬⊥, a propositional atom or its
negation. The size of ﬁnite set S is denoted by |S|.
As shown in [14], INL has a strictly stronger expressive power on neighbor-
hood models than BNL, and hence its axiomatization cannot be achieved using
reduction axioms. In [14], a Hilbert-style axiomatization of INL is provided, and
we denote it by Hinl.
Deﬁnition 1 (Calculus Hinl). As a Hilbert-style axiomatization, Hinl has
schematic axioms:
(Prop)
Propositional tautologies,
(R-Mon) □(α1, ..., αj; α0)→□(α1, ..., αj; α0∨β),
(L-Mon) □(α1, ..., αj−1, αj; α0)→□(α1, ..., αj−1, αj∨β; α0),
(Inst)
□(α1, ..., αj−1, αj; α0)→□(α1, ..., αj−1, αj∧α0; α0),
(Norm)
¬□(⊥; α0),
(Case)
□(α1, ..., αj; α0)→□(α1, ..., αj, δ; α0)∨□(α1, ..., αj; α0∧¬δ),
(Weak)
□(α1, ..., αi−1, αi, αi+1, ..., αj; α0)
→□(α1, ..., αi−1, αi+1, ..., αj; α0),
(Dupl)
□(α1, ..., αj; α0)→□(α1, ..., αi, β, αi+1, ..., αj; α0)
where β ∈{α1, ..., αj};
and rules:
α→β α (MP),
β
α→β β →α φq
α (RE),
φq
β
where φq
ψ is the result of uniformly substituting all occurrences of propositional
atom q in φ by ψ.
As usual, ⊢Hinl φ means that φ is provable in Hinl.
Most axioms in Hinl are straight-forward, and we explain (Case) here a bit.
Once a neighborhood justifying □(α1, ..., αj; α0) is given, we can check it with
2 That is, if S1 ∈N(w) and S1 ⊆S2, then S2 ∈N(w).

A Tableau System for Instantial Neighborhood Logic
339
a formula δ, to see whether or not that neighborhood accommodates δ some-
where. If it does, then we safely take δ as an extra instance, and have disjunct
□(α1, ..., αj, δ; α0); otherwise, δ universally fails and hence we have disjunct
□(α1, ..., αj; α0∧¬δ).
Shown in [14], Hinl is sound and complete for INL:
Theorem 1 (Sound-and-completeness of Hinl). For every INL-formula φ,
it holds that: ⊢Hinl φ iﬀφ is valid.
This paper oﬀers to INL a tableau system called Tinl. In the following Sect. 2,
we recall a tableau system for classical propositional logic, and deﬁne Tinl as
an extension of it. In Sect. 3, we show that proof search in Tinl always termi-
nates. Then in Sects. 4 and 5 soundness and completeness of Tinl are respectively
veriﬁed. The ﬁnal Sect. 6 concludes this paper.
In the author’s other paper in a parallel process [15], a sequent calculus
G3inl for INL is introduced, and based on it the Lyndon interpolation theorem
of INL is constructively proved. Actually, the discovery of G3inl was inspired
by Tinl, and a hyper-sequent version of the former amounts to a dual of the
latter. Although it is possible to establish the equivalence between these two, the
author intentionally use them to explore diﬀerent aspects of INL. As presented
in [15], G3inl is purely proof-theoretical, and whose completeness is shown via a
syntactical cut-elimination. In this paper, we emphasize Tinl’s close relation to
semantics of INL, and completeness of Tinl will be shown via an extraction of
counter-models out of failed attempts of Tinl-proofs.
2
Tableau System Tinl
Invented independently by Beth [1] and Hintikka [10] and later reﬁned indepen-
dently by Lis [11] and Smullyan [13], tableau is a popular framework of formal
proofs [8]. Compared to other styles of formulation used in proof theory, the
most distinguishing feature of tableau is that it closely connects to semantics,
which earns it another well-known name: “semantic tableau”. A good tableau
system of a (decidable) logic should support proof/counter-model search in the
sense that, once a formula φ is given, by mechanically trying rules in the tableau
system, one can decide whether or not φ is valid, construct either a (tableau)
proof (when φ is valid) or a counter-model of φ (when φ is not valid). This paper
will oﬀer to INL a tableau system Tinl that is good in the above sense.
Deﬁnition 2 (Basic tableau). A basic tableau is a tree of formulas that can
be created from its root by consecutively applying speciﬁc tree extension rules
in a way that, each node triggers at most one rule-application on each branch
it belongs to.3 A basic tableau is said to be exhausted, if each of its non-literal
nodes triggers a rule-application on each branch it belongs to.
3 In some tableau systems, like that for intuitionistic logic [7], it is sometimes necessary
to trigger rule-applications multiple times at a same node. Since all systems we
consider in this paper are free of such a need, we simply exclude it at this beginning
deﬁnition.

340
J. Yu
For classical propositional logic, we have the following seven rules (¬¬), (∧),
(¬∨), (¬→), (¬∧), (∨), and (→) (in the order displayed below) [9].
¬¬φ

φ
φ ∧ψ

φ
ψ
¬(φ ∨ψ)

¬φ
¬ψ
¬(φ→ψ)

φ
¬ψ
¬(φ ∧ψ)






¬φ
¬ψ
φ ∨ψ


φ
ψ
φ→ψ


¬φ
ψ
These seven rules each oﬀers an option to extend an existing branch in a tree.
Among them, the four in the ﬁrst line are non-branching rules. For instance, if an
existing branch has node φ ∧ψ (not necessarily at the end of that branch), then
that node can trigger an application of (∧) that extends the branch by adding
two new nodes φ and ψ one after another to the end. To the contrary, the three
in the second line are branching rules. For instance, if an existing branch has
node φ →ψ (not necessarily at the end of that branch), then that node can
trigger an application of (→) that adds two distinct children ¬φ and ψ to the
end of that branch, thereby extending it while splitting it into two.
We are ready to deﬁne the tableau system Tcpc for classical propositional
logic.
Deﬁnition 3 (Tableau system Tcpc). The system Tcpc has all the seven tree
extension rules presented above, and a Tcpc-tableau is a basic tableau as deﬁned
in Deﬁnition 2 w.r.t. these seven rules. A branch in a Tcpc-tableau is said to be
closed, if it has node ⊥, node ¬⊤, or both node φ and node ¬φ for a formula
φ. A Tcpc-tableau is said to be closed, if all its branches are closed. A branch
(resp. Tcpc-tableau) is open if it is not closed. A proof of formula φ in Tcpc is
a closed Tcpc-tableau with root ¬φ.
By ⊢Tcpc φ, we mean that formula φ has a Tcpc-proof. It is well-known that
Tcpc is sound and complete for classical propositional logic [9].
Theorem 2 (Soundness and completeness of Tcpc). For every proposi-
tional formula φ, it holds that: φ is a tautology iﬀ⊢Tcpc φ.
It is obvious that, in these seven Tcpc-rules, each formula introduced is
strictly shorter compared to the formula by which the rule-application is trig-
gered (actually, only its proper sub-formulas and their negations are permitted).
A rule with such a property is said to be analytic, and a tableau system is said
to be analytic if all of its rules are. Since all rules of Tcpc are ﬁnitely-branching
(i.e., can introduce only ﬁnitely many children) and analytic, as well as the fact
that no literals can trigger any rule-application, we see that all Tcpc-tableaux are

A Tableau System for Instantial Neighborhood Logic
341
ﬁnite in size. This facilitates a straight-forward proof/counter-model search in
Tcpc. Starting from the initial root and consecutively extending the Tcpc-tableau
by any rule that applies, one ﬁnally ends by getting either a closed Tcpc-tableau
(a proof) or an exhausted open Tcpc-tableau. If the latter happens, then in the
Tcpc-tableau there must be an open branch, and a propositional valuation that
satisﬁes exactly propositional atoms in that branch is a counter-model of the
root. Details of what sketched above can be found in [5].
We now turn to a tableau system for INL called Tinl. Objects of Tinl are
neighborhood tableaux instead of basic tableaux.
Deﬁnition 4 (Neighborhood tableau). In a tree of formulas and ﬁnite for-
mula multi-sets:
– a node is regular if it is a formula, and is irregular if it is a formula multi-set;
– a regular node that is not a child of any regular node is called an initial node,
and a regular node that has no regular child is called an end node;
– a branch is a path from an initial node to an end node that passes through
only regular nodes;
– a regular node that is neither a literal nor a ¬□-preﬁxed formula is said to
be active.
A neighborhood tableau is a tree of formulas and ﬁnite formula multi-sets in
which:
– the root is regular;
– children of nodes are created by applying speciﬁc tree extension rules;
– each node triggers at most one rule-application on each branch it belongs to.
A branch is propositionally exhausted, if each of its active nodes that are not
□-preﬁxed (i.e., nodes with ∧, ¬∧, ∨, ¬∨, →, or ¬ →as main connective(s))
triggers a rule-application on it. A branch is fully exhausted, if each of its active
nodes triggers a rule-application on it. A neighborhood tableau is said to be
exhausted, if all branches in it are fully exhausted, and each of its non-empty
irregular nodes triggers an application of rule (MS).
For INL, we employ not only propositional rules but also two extra rules.
Deﬁnition 5 (Rule (MS)). Rule (MS) (where “MS” stands for “multi-set”)
{φ1, φ2, ..., φm}

									









φ1
φ2
· · ·
φm
can be triggered by any non-empty irregular node. It introduces exactly elements
of the irregular node as its children, which are all regular.
Deﬁnition 6 (Rule (□)). Rule (□)4 is a branching rule that introduces irreg-
ular children to the end node of a propositionally exhausted branch, where the
4 While “□” is an operator, “(□)” is the name of a rule.

342
J. Yu
number of these children depends on ¬□-preﬁxed formulas in that branch. The
rule has the following form:
□(α1, ..., αj; α0)
¬□(β1
1, ..., β1
j1; β1
0)
...
¬□(βk
1 , ..., βk
jk; βk
0 )
irregular child {α0 ∧σ ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)) | σ ∈A ∪BI} for each I ∈
k

l=1
{0, 1, ..., jl}
where A = {α1, ..., αj} and BI = {¬βi
0 | i ∈{1, ..., k}, I(i) = 0}.
Certainly this rule needs explanations. Only if a propositionally exhausted
branch has a □-preﬁxed node (formula) □(α1, ..., αj; α0) with j-many instances,
as well as exactly k-many ¬□-preﬁxed nodes (formulas) ¬□(β1
1, ..., β1
j1; β1
0), ...,
¬□(βk
1, ..., βk
jk; βk
0) that respectively have j1, ..., jk-many instances, then an appli-
cation of rule (□) can be triggered by the node □(α1, ..., αj; α0), and it creates a
new phase (separated by the horizontal line) in which k
l=1(jl + 1)-many irreg-
ular nodes are attached to the end of the existing branch as children. Each of
these irregular nodes is indexed by an I ∈k
l=1{0, 1, ..., jl} and has |A ∪BI|-
many elements that are identical to each other except for the conjunct σ. The
following points deserve special attentions:
– We have emphasized that the existing branch should have exactly k-many
¬□-preﬁxed nodes. In other words, rule (□) always takes all ¬□-preﬁxed
nodes on the branch as inputs. In the special case k = 0, only one irregular
node indexed the by empty sequence is introduced.
– In the special case that j = 0 (hence A = ∅) and none of j1, ..., jk is 0, there
can be some I ∈k
l=1{0, 1, ..., jl} s.t. A ∪BI = ∅. Hence, the irregular node
with index I is empty.5
– Although an application of rule (□) takes (k+1)-many nodes as inputs, only
the □-preﬁxed one is said to trigger that application. Rule (□) always takes
exactly one □-preﬁxed node as input, even though there may be more on the
branch.
– Rule (□) is destructive, as all information on the existing branch cannot be
referred later in the new phase created. While nodes taken as inputs jointly
determine irregular nodes introduced, all other nodes simply expire (in the
created phase), including nodes with □-preﬁxed or ¬□-preﬁxed sub-formulas
like ⊤∧¬□(φ; ψ). In order to avoid unnecessary loss of information, rule (□)
is restricted to apply only on propositionally exhausted branches.
5 Since rule (MS) can only be triggered by non-empty irregular nodes, the irregular
node with index I has no child. It will not be hard to see from Deﬁnition 7 and
Theorem 5 (both to be presented later) that empty irregular nodes are always open
and indicate empty neighborhoods of the current point.

A Tableau System for Instantial Neighborhood Logic
343
Having presented all rules that will be employed, we are now ready to deﬁne
Tinl. In contrast to Tcpc in which we deﬁne openness and closure of branches,
here in Tinl it is more convenient to talk about also that of nodes.
Deﬁnition 7 (Tableau system Tinl). System Tinl inherits all the seven rules
of Tcpc (now in the language of INL), and also employs rules (MS) and (□).
A Tinl-tableau is a neighborhood tableau as deﬁned in Deﬁnition 4 w.r.t. to all
these nine rules. A branch in a Tinl-tableau is said to be closed, if it has (regular)
node ⊥, node ¬⊤, or both node φ and node ¬φ for a formula φ. A node in a
Tinl-tableau is said to be closed, if one of the following holds:
– it is a regular node with no child, and the unique branch it belongs to is
closed;
– it is a regular node with regular children, and all of its children are closed;
– it is a regular node with irregular children, and there exists a phase in which
all its irregular children are closed;
– it is an irregular node, and one of its children is closed.
A Tinl-tableau is said to be closed, if so is its root. A branch (resp. node, or
Tinl-tableau) is open if it is not closed. A proof of formula φ in Tinl is a closed
Tinl-tableau with root ¬φ.
As usual, by ⊢Tinl φ, we mean formula φ has a Tinl-proof.
We have some remarks here:
– according to rules of Tinl, a regular node may have only regular children or
only irregular children, but not a mixture of both.
– rule (MS) is the only rule that an irregular node can trigger, and hence an
irregular node can only have regular children (viz. its elements).
– by deﬁnition, an empty irregular node is always open.
Machineries in a Tinl-tableau have their semantic counterparts. Intuitively
speaking, initial nodes correspond to points in the model, branches starting from
initial nodes correspond to possibilities of points, irregular nodes correspond to
neighborhoods in the model, and regular children of an irregular node correspond
to points inside the neighborhood. These correspondences will be made more
formal in a model construction employed later in the proof of Theorem 5.
Example 1. A Tinl-proof of □(p ∨q; r)→□(p; r) ∨□(q; r) is shown in Fig. 1. For
the only application of rule (□), in notations of Deﬁnition 6, we have k = 2 and
j = j1 = j2 = 1, hence that application introduces four irregular nodes, each
indexed by some I ∈2
l=1{0, 1, ..., jl}. These four irregular nodes are listed in
the index-order of (0, 0), (0, 1), (1, 0), (1, 1), and indexes also determine elements
of these irregular nodes. Take I = (1, 0) as an instance, since each of “A” and
“B(1,0)” in Deﬁnition 6 is a singleton, the irregular node with index (1, 0) has
two elements as shown. Among them the ﬁrst is indexed by p ∨q ∈A, and the
second is indexed by ¬r ∈B(1,0).

344
J. Yu
¬(□(p ∨q; r)→□(p; r) ∨□(q; r))

□(p ∨q; r)
¬(□(p; r) ∨□(q; r))

¬□(p; r)
¬□(q; r)
⎧
⎨
⎩
r ∧(p ∨q)
r ∧¬r
r ∧¬r
⎫
⎬
⎭

r ∧¬r

r
¬r
 r ∧(p ∨q) ∧¬q
r ∧¬r ∧¬q
	

r ∧¬r ∧¬q

r ∧¬r
¬q

r
¬r
 r ∧(p ∨q) ∧¬p
r ∧¬r ∧¬p
	

r ∧¬r ∧¬p

r ∧¬r
¬p

r
¬r
{r ∧(p ∨q) ∧¬p ∧¬q}

r ∧(p ∨q) ∧¬p ∧¬q

r ∧(p ∨q)
¬p ∧¬q

r
p ∨q

¬p
¬q










q
p
Fig. 1. A Tinl-proof of □(p ∨q; r)→□(p; r) ∨□(q; r).
In order for Tinl to be indeed a good tableau system for INL, its provabil-
ity should be both decidable and correct. Here “decidable” means that, there
is a mechanical method to determine whether or not any given formula is
Tinl-provable, which amounts to termination of proof search in Tinl (Sect. 3);
and “correct” means that, Tinl proves exactly all of valid INL-formulas, which
amounts to its soundness (Sect. 4) and completeness (Sect. 5). Since Tinl is an
extension of Tcpc, each of these three meta-theorems can be proved by extending
a proof of the corresponding meta-theorem for Tcpc. As all these three are well-
known to hold for Tcpc with proofs available [5], we omit details of propositional
base and concentrate on extensions typical for Tinl.
3
Termination of Proof-Search in Tinl
In this section we will show that every proof-search in Tinl always terminates.
What follows is a deﬁnition of degrees that takes only operator □into account,
which is a convenient simpliﬁcation, since we will concentrate on only factors of
Tinl that are absent in Tcpc.

A Tableau System for Instantial Neighborhood Logic
345
Deﬁnition 8 (Degrees). The degree of an INL-formula φ, denoted by dg(φ),
is the maximal number of nested □’s in φ, that is:
dg(φ) :=
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0
if □does not occur in φ
dg(φ1)
if φ is ¬φ1
max{dg(φ1), dg(φ2)}
if φ is φ1 △φ2 where △∈{∧, ∨, →}
1+max{dg(φi) | i ∈{0, 1, ..., j}} if φ is □(φ1, ..., φj; φ0)
Since regular nodes in Tinl-tableaus are merely formulas, what above also deﬁnes
degree of regular nodes. The degree of a branch is the maximal degree enjoyed
by nodes on the branch.
Theorem 3 (Termination theorem). There is a mechanical procedure of
proof-search in Tinl that terminates on every input.
Proof. The mechanical procedure can be described by the following instruction:
– if the tableau is closed,
then exit with success.
– else if there is a regular node that can, but has not, triggered a propositional
rule-application on a branch,
then perform that application, and start over again;
– else if there is a regular node that can, but has not, triggered an application
of rule (□) on a branch,
then perform that application, immediately apply rule (MS) on each
irregular node introduced that is non-empty, and then start over again;
– else exit with failure.
In each round, the procedure distinguishes four cases, among them two lead to
exits, and two lead to start-overs. The procedure is designed so that applications
of propositional rules have priority over that of rule (□). It is known (like in Tcpc)
that, in ﬁnitely many rounds since any snapshot, the procedure will either exit
or make all branches propositionally exhausted. Hence, the procedure cannot
loop forever through only the ﬁrst else if.
If the second else if is called, then a □-preﬁxed node on a propositionally
exhausted branch is about to trigger an application of rule (□). By the design of
the procedure, a same application will not happen again on this branch. Intro-
duced by this application are ﬁnitely many irregular children, each of which has
ﬁnitely many regular children created by subsequent applications of rule (MS).
In total, only ﬁnitely many regular nodes are introduced, and these regular nodes
are themselves new branches that the procedure will take into account in the
next round. Recall that an application of rule (□) takes as inputs one □-preﬁxed
node and all ¬□-preﬁxed nodes on the existing branch, and the maximal degree
enjoyed by these input formulas cannot exceed the degree of that branch. By an
easy observation of the rule (□) (and rule (MS)), we see that aforementioned
newly introduced regular nodes are Boolean combinations of proper sub-formulas
from the scope of the outermost □of these input formulas. That is to say, afore-
mentioned newly introduced branches each has a degree strictly smaller than

346
J. Yu
that of the existing branch where the application is triggered. Since on the exist-
ing branch there are only ﬁnitely many □-preﬁxed nodes, fully exhausting a
branch amounts to reducing it into ﬁnitely many branches with strictly smaller
degrees. Note that, applications of propositional rules do not increase degrees of
branches, and hence in summary, the procedure cannot go through the second
else if inﬁnitely many times.
⊓⊔
It may be helpful to emphasize that, the procedure we just oﬀered may
(meaninglessly) extend branches that are already closed. But doing so can waste
only ﬁnitely many rounds (before exhausting everything in the occasion), and
hence has no eﬀect in terms of termination. Optimization will be welcomed,
although satisﬁability problem of INL is known to be PSPACE-complete [14].
4
Soundness of Tinl
This section addresses soundness of the tableau system Tinl. With the help of
Hinl’s soundness (Theorem 1), it is suﬃcient to show that Tinl-provability entails
Hinl-provability.
Observe that in a Tinl-tableau, each end node determines an unique branch.
A branch is said to be inconsistent, if ⊢Hinl ( S) →⊥for S being the set of
regular nodes (formulas) on that branch. A regular node (formula) φ is said to
be inconsistent, if it holds that ⊢Hinl φ→⊥. Soundness of Tinl can be proved as
a corollary of the following theorem.
Theorem 4. In a Tinl-tableau, every closed initial node is inconsistent.
Corollary 1 (Soundness of Tinl). For every INL-formula φ, if ⊢Tinl φ, then φ
is valid.
Proof. Assume that ⊢Tinl φ, then there exists a closed Tinl-tableau with root
¬φ. Since root ¬φ is initial, by Theorem 4, the root is inconsistent, and hence
⊢Hinl ¬φ →⊥, which implies ⊢Hinl φ. By soundness of Hinl, we know that φ is
valid.
⊓⊔
It remains to verify Theorem 4.
Proof (of Theorem 4). By an induction on the given Tinl-tableau.
For the base case. Observe that minimal initial nodes in a Tinl-tableau are
such initial nodes that all branches from them terminate at end nodes with no
irregular children. Assume that a minimal initial node is closed, then by deﬁni-
tion of open/close-ness in Deﬁnition 7, we see that all branches from it terminate
at closed end nodes with no child, and hence all these branches are closed. Since
all these branches were extended from the initial node by only propositional rules,
we can directly apply existing veriﬁcations for Tcpc’s soundness, and conclude
that the initial node itself is inconsistent.
For the induction step. Assume that an initial node is closed, by Deﬁnition 7,
all branches from it terminate at closed end nodes that may have irregular chil-
dren. We claim that: If an end node is closed, then the branch it determines is

A Tableau System for Instantial Neighborhood Logic
347
inconsistent. With this claim, we can conclude as in the base case that the initial
node itself is inconsistent. It is therefore suﬃcient to verify the claim as follows.
If the closed end node has no child, then by Deﬁnition 7, the branch it deter-
mines is closed. Also by that deﬁnition, that branch has node ⊥, node ¬⊤, or
nodes χ and ¬χ for some formula χ, and hence is inconsistent.
If the closed end node (denote it by d) has irregular children, then by deﬁni-
tion, there exists a phase in which all its irregular children are closed. Note that
an irregular node can only have regular children, and is closed only if at least one
of these regular children are closed. Thus, there exists a phase in which each irreg-
ular child S of d has a closed regular child e (which is an element of S). Observe
that, e cannot be a child of any regular node, and hence is initial, which by induc-
tion hypothesis implies the inconsistency of e. In summary, there exists a phase in
which each irregular child of d has an inconsistent element.
By the design of Tinl, we know that irregular children of d in that phase
are introduced by an application of rule (□), triggered by a □-preﬁxed node
on the branch determined by d. Without loss of generality, assume that the
□-preﬁxed node is formula □(α1, ..., αj; α0), and there are k-many ¬□-preﬁxed
nodes ¬□(β1
1, ..., β1
j1; β1
0), ... , ¬□(βk
1, ..., βk
jk; βk
0) on the branch determined by
d. It is therefore suﬃcient to show inconsistency of formula set
D = {□(α1, ..., αj; α0), ¬□(β1
1, ..., β1
j1; β1
0), ..., ¬□(βk
1 , ..., βk
jk; βk
0)}.
Observe the form of rule (□), we see that in the phase created by the above
mentioned application, each irregular node introduced as a child of d is indexed
by an I ∈k
l=1{0, 1, ..., jl}, while the irregular node with index I has regular
children α0 ∧σ ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)) for each σ ∈{α1, ..., αj}∪{¬βi
0 | i ∈{1, ..., k},
I(i) = 0}. Since each irregular child of d has an inconsistent element, we know
that for each I ∈k
l=1{0, 1, ..., jl}, at least one of the following holds:
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
there exists x ∈{1, ..., j} s.t. ⊢Hinl α0 ∧αx ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i))→⊥,
or
there exists y ∈{1, ..., k} s.t. I(y) = 0 and ⊢Hinl α0 ∧¬βy
0 ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i))→⊥.
Entailment from this to
⊢Hinl □(α1, ..., αj; α0)→

l∈{1,...,k}
□(βl
1, ..., βl
jl; βl
0)
(and hence to the desired inconsistency of D) was veriﬁed by the author in the
proof of Theorem 2.6 in [15].6
⊓⊔
6 That proof is devoted to establish soundness of G3inl, a sequent calculus for INL.
Due to the length of that proof and the limit of space here, we have to omit further
details and refer to [15] for a full presentation.

348
J. Yu
5
Completeness of Tinl
In this section, we prove completeness of Tinl by extracting counter-models from
failed attempts of Tinl-proofs.
Theorem 5 (Completeness of Tinl). ⊢Tinl φ holds for every INL-formula φ
that is valid.
Proof. We prove the contrapositive of the theorem.
With the assumption that ⊬Tinl φ, the procedure presented in Theorem 3,
when being performed on the Tinl-tableau with only one node ¬φ, terminates
with failure. That is to say, the result of the procedure is an exhausted open
Tinl-tableau T with root ¬φ.
We deﬁne an INL-model M = (W, N, V ) as follows:
– The point-set W is the collection of all open initial regular nodes in T . For
each open initial regular node d in tableau T , by Deﬁnition 7, there must be
a branch Od that starts from d, travels through only open regular nodes, and
ends at open end regular node ed.
– Let V (d), the propositional valuation on d, be the one that assigns exactly
propositional atoms on branch Od true.
– Let N(d), the collection of d’s neighborhoods, be exactly the collection of ed’s
open irregular children in all phases. Each of these neighborhoods is an open
irregular node, and by Deﬁnition 7, all of its elements (viz. its children) are
open initial regular nodes, and hence are also points in W.7
It remains to show that M satisﬁes ¬φ at the root, and hence φ cannot be valid.
Temporally in this proof, call a formula non-compound, if it is a propositional
atom, a □-preﬁxed formula, or a negation of one of that. As in Tcpc, if a model
satisﬁes all non-compound formulas (regular nodes) in a branch, then it satisﬁes
all formulas on that branch including the initial node. We claim that:
for each open initial regular node d in T , the generated sub-model Md
satisﬁes d (as a formula) at d (as a point in Md).
With that claim, we know that M, as the generated sub-model of itself by the
root, satisﬁes the root ¬φ at the root, and hence φ is not valid. Therefore, it is
suﬃcient to verify the claim by an induction on points in M as follows.
For the base case. If d ∈W and N(d) = ∅, then d is a minimal open initial
regular node. Without loss of generality, assume among all possibilities, the one
represented by branch Od is taken in the construction of M. So Od starts from
d, travels through only open nodes, and ends at some open end node ed that has
7 This vacuously covers the special case that the irregular node is empty and hence
has no elements.

A Tableau System for Instantial Neighborhood Logic
349
no child.8 By the design of M, we know that V (d) assigns exactly propositional
atoms in branch Od true, and Md has d as its only point.
By the design of V , the collection of propositional atoms and their negations
are satisﬁed by Md at d. Since Od is fully exhausted but yet ed has no irregular
child, we know that Od has no □-preﬁxed formulas. Since d has no neighborhood
in M, all ¬□-preﬁxed formulas in Od are automatically satisﬁed. In summary,
Md satisﬁes all non-compound formulas in Od at point d, and hence it also
satisﬁes the initial node d at point d.
For the induction step. Assume d ∈W and N(d) ̸= ∅. Without loss of generality,
assume among all possibilities, the one represented by branch Od is taken in the
construction of M. So Od starts from d, travels through only open nodes, and
ends at some open end node ed whose open irregular children in all phases are
exactly neighborhoods of d. As in the base case, the design of V guarantees the
satisfaction of all propositional atoms and their negations in Od by Md at d.
For each □-preﬁxed formula □(α1, ..., αj; α0) (abbreviated as α) in Od, since
Od is fully exhausted, α has triggered an application of rule (□) that created a
phase with irregular nodes. Since ed is open, by Deﬁnition 7, in that phase there
exists an open irregular child S. By the design of M, we see that S ∈N(d). Since
S is open, so are all its elements (viz. all its regular children). Thus, as desired,
elements of S are open initial regular nodes and hence are points in Md. As a
formula, each regular node s ∈S has a form of α0 ∧σ ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)) where
σ ∈{α1, ..., αj}∪{¬βi
0 | i ∈{1, ..., k}, I(i) = 0}. Since s is an open initial regular
node, by induction hypothesis, Ms satisﬁes α0 ∧σ ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)) at s, and
hence Md satisﬁes α0 at s. By arbitrariness of s, we know that α0 universally
holds in S. For each x ∈{1, ..., j}, let sx be the element of S whose index σ
is αx. By induction hypothesis, Msx satisﬁes α0 ∧αx ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)) at sx,
and hence Md satisﬁes αx at sx. By arbitrariness of x, we know that none of
α1, ..., αj universally fails in S. In summary, Md satisﬁes α at d.9
For each ¬□-preﬁxed formula μ in Od, we need to show that Md satisﬁes μ
on d. Let S ∈N(d) be an arbitrary neighborhood of d in M (also in Md). By
design of M and that of Tinl, neighborhood S is an open irregular child of ed
that is introduced by an application of rule (□) with one □-preﬁxed formula and
8 Suppose that ed has children. Since ed is an end node, all children it has are irregular.
Since N(d) = ∅, all these irregular children are closed. As ed’s irregular children must
be introduced in phases by applications of rule (□), by Deﬁnition 7, ed is closed, a
contradiction.
9 Note that our proof works in a vacuous way for the special case that S = ∅. In that
case, the set A ∪BI in Deﬁnition 6 is be empty, and hence it must be the case that
j = 0.

350
J. Yu
all ¬□-preﬁxed formulas in Od (including μ) as inputs. Assume that in Od there
are k-many ¬□-preﬁxed formulas μ1, ..., μk, where μy is ¬□(βy
1, ..., βy
jy; βy
0) for
each y ∈{1, ..., k}. Without loss of generality, let μ be μk. Observe that as an
irregular node introduced by an application of rule (□), S is indexed by some
I ∈k
l=1{0, 1, ..., jl}. [Case (i)] I(k) (the k-th element of sequence I) is 0, then
¬βk
0 is in set “BI” of Deﬁnition 6, hence there is sk ∈S that (as a formula)
is α0 ∧¬βk
0 ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)). As a node, sk is also a regular child of S, and
since S is open, so is sk. That is to say, sk is an open initial regular node,
and hence by induction hypothesis, Msk satisﬁes α0 ∧¬βk
0 ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i))
at sk. As a consequence, Md falsiﬁes βk
0 at sk ∈S, and hence βk
0 is not univer-
sally true in S. [Case (ii)] I(k) ̸= 0. As a formula, an arbitrary s ∈S should
be α0 ∧σ ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)) for some formula σ. Since S is open, so is s, and
hence s is an open initial regular node. By induction hypothesis, Ms satisﬁes
α0 ∧σ ∧(
I(i)̸=0

i∈{1,...,k}
¬βi
I(i)) at s, and hence, Md falsiﬁes βk
I(k) at s. By arbi-
trariness of s, we see that βk
I(k) universally fails in S. [Summary] In both Case
(i) and Case (ii), S fails to be a neighborhood that justiﬁes □(βk
1, ..., βk
jk; βk
0).
By arbitrariness of S, we see that point d has no neighborhoods that justify
□(βk
1, ..., βk
jk; βk
0), and hence Md satisﬁes μ at d.
We have shown that Md satisﬁes all non-compound formulas in branch Od
at d, and hence it also satisﬁes the initial node d at point d. This ﬁnishes the
induction as well as our proof of the claim.
⊓⊔
In the proof above, we have actually given a method to extract counter-
models from failed attempts of proof-search. By termination theorem (Theorem 3),
a proof-search in Tinl always terminates. If it terminates with a success, then by
deﬁnition we have a proof of the goal; otherwise it terminates with a failure, and
employing the method from the proof of Theorem 5, we get a counter-model of the
goal.
We ﬁnish this section with an illustration of counter-model construction.
Example 2. We perform for formula
□(; q) ∧□(p ∨q; ¬□(; q))→□(p; ⊤)
(abbreviate it by η) a proof/counter-model search in Tinl. Start with a tableau
with ¬η as root and the only node, using propositional rules, we get the following
tableau whose only branch is propositionally exhausted.

A Tableau System for Instantial Neighborhood Logic
351
¬(□(; q) ∧□(p ∨q; ¬□(; q))→□(p; ⊤))

□(; q) ∧□(p ∨q; ¬□(; q))
¬□(p; ⊤)

□(; q)
□(p ∨q; ¬□(; q))
The only option to continue is to apply the rule (□), which by deﬁnition takes
all ¬□-preﬁxed formulas (here ¬□(p; ⊤) is the only one of that type) and one
□-preﬁxed formula on the branch as inputs. There are two □-preﬁxed formulas,
□(; q) and □(p ∨q; ¬□(; q)), on the branch, so rule (□) can be applied twice,
thereby create two phases. Since there is exactly one instance in the only ¬□-
preﬁxed formula, we know that in each of these two phases two irregular children
respectively indexed by (0) and (1) are introduced. By Deﬁnition 7, in order to
close the end node as well as the tableau, it is suﬃcient to ﬁnd one phase in
which all irregular children introduced are closed.
Phase □(; q). By the design of rule (□) (cf. Deﬁnition 6), irregular node with
index (0) is {q ∧¬⊤}, and that with index (1) is ∅. While the former can be
closed, the latter cannot. By Deﬁnition 5, on irregular node ∅rule (MS) is not
applicable, so ∅has no closed regular child and hence is open. Therefore, this
phase does not close the tableau.
Phase □(p∨q; ¬□(; q)). By the design of rule (□), irregular node with index (0) is
{¬□(; q)∧(p∨q), ¬□(; q)∧¬⊤}, and that with index (1) is {¬□(; q)∧(p∨q)∧¬p}.
While the former can be closed (left to the reader), the latter cannot. Try all
applicable to continue on the latter, we have:
{¬□(; q) ∧(p ∨q) ∧¬p}

¬□(; q) ∧(p ∨q) ∧¬p

¬□(; q) ∧(p ∨q)
¬p

¬□(; q)
p ∨q
	









p
q

352
J. Yu
in which the right branch is fully exhausted10 yet open. Therefore, this phase
does not close the tableau either.
In conclusion, we result in an exhausted open tableau (denote it by T ) with
root ¬η. We now construct a counter-model (W, N, V ) of η following the instruc-
tion presented in the proof of Theorem 5.
Above applications of rule (□), there is only one open initial regular node
(i.e., the root) and only one branch in T . Let us call the root n0, and that
branch O0. Since there are no literals in O0, we see that V (n0) should make no
propositional atom true.
In phase □(; q), the irregular node with index (0) is closed and that with
index (1) is ∅(hence open by deﬁnition). As no open initial regular node exists
in this phase, no new point is added to the model. However, as ∅is an open
irregular child, we have ∅∈N(n0).
In phase □(p∨q; ¬□(; q)), the irregular node with index (0) is closed and that
with index (1) is open. Denote the irregular node with index (1) by S, we should
have S ∈N(n0). In T , irregular node S has only one child (its only element),
which is initial and open, and hence is a point in the model. Let us call that
node n1. Starting from n1, there is an open branch that ends at end node q, and
q is the only propositional atom on that branch. Therefore, V (n1) should make
q the only true propositional atom.
In summary, the model constructed can be displayed as
• n0













	



	
• n1
q
and we leave it to the reader to check that the constructed model falsiﬁes η at n0.
6
Conclusions and Discussions
In this paper we oﬀered to INL a sound-and-complete tableau system Tinl that
supports mechanical proof/counter-model search.
While Tinl naturally connects to semantics of the logic, it also connects to
other formal proof systems. It is well-known that tableau system and sequent
calculus for classical propositional logic each can be seen as the dual of the
other. Due to our employment of irregular nodes, the dual of Tinl is a hyper-
sequent calculus. In the author’s other parallel work [15], we oﬀer to INL a sequent
calculus G3inl that amounts to the result of breaking the only essentially-“hyper”
rule scheme in the dual of Tinl into inﬁnitely-many (normal) sequent rule schemes
with sophisticated parameters. As a normal sequent calculus, G3inl admits cut,
enjoys the sub-formula property, and has a splitting version that supports a
construction of Lyndon interpolants [15].
10 Recall here that unlike □-preﬁxed formulas, ¬□-preﬁxed formulas are not active.

A Tableau System for Instantial Neighborhood Logic
353
One may say that INL is simple, as with primary formulations like normal
sequent calculus we already had a nice treatment. As instanced by modal logics,
compared to a calculus for a logic (e.g., K), that for an extension (e.g., S5) can
be essentially harder. There are meaningful extensions of INL with neighborhood
function N in models restricted, and for which adding rule schemes to G3inl may
not directly work. When diﬃculties are encountered, one coping strategy is to
consult formulations closer to semantics, like Tinl.
Acknowledgements. The tableau system introduced in this paper was invented by
the author during his January 2015 visit to University of Amsterdam, where he was
led by Johan van Benthem and Nick Bezhanishvili to the ﬁeld of neighborhood logic.
Four anonymous referees have oﬀered helpful suggestions to the initial submission of
this paper.
References
1. Beth, E.W.: Semantic Entailment and Formal Derivability. Mededelingen van de
Koninklijke Nederlandske Akademie van Wetenschappen, vol. 18, no. 13, pp. 309–
342 (1955)
2. ten Cate, B., Gabelaia, D., Sustretov, D.: Modal languages for topology: expres-
sivity and deﬁnability. Ann. Pure Appl. Log. 159(1), 146–170 (2006)
3. Chagrov, A., Zakharyashche, M.: Modal Logic. Oxford Science Publications,
Oxford (1997)
4. Chellas, B.F.: Modal Logic - An Introduction. Cambridge University Press,
Cambridge (1980)
5. D’Agostino, M.: Tableau methods for classical propositional logic. In: [6]
6. D’Agostino, M., Gabbay, D.M., H¨ahnle, R., Posegga, J. (eds.): Handbook of
Tableau Methods. Kluwer Academic Publisher, Dordrecht (1999)
7. Fitting, M.: Proof Methods for Modal and Intuitionistic Logics. D. Reidel,
Dordrecht (1983)
8. Fitting, M.: Introduction. In: [6]
9. Fitting, M.: Types, Tableaus, and G¨odel’s God. Kluwer Academic Publisher,
Dordrecht (2002)
10. Hintikka, J.: Two papers on symbolic logic: form and content in quanliﬁcation
thoery. Acta Philos. Fenn. 8, 8–55 (1955)
11. Lis, Z.: Wynikanie semantyczne a wynikanie fonnalne. Stud. Log. 10, 39–60 (1960).
(in Polish)
12. Pacuit, E.: Neighborhood semantics for modal logic - An introduction. ESSLLI
2007 course notes (2007)
13. Smullyan, R.: First-Order Logic. Springer, Heidelberg (1968)
14. van Benthem, J., Bezhanishvili, N., Enqvist, S., Yu, J.: Instantial neighbourhood
logic. Rev. Symb. Log. 10(1), 116–144 (2017)
15. Yu, J.: Lyndon interpolation theorem of instantial neighborhood logic - construc-
tively via a sequent calculus (submitted)

Interpretations of Presburger Arithmetic
in Itself
Alexander Zapryagaev(B) and Fedor Pakhomov
Steklov Mathematical Institute, Russian Academy of Sciences,
8, Gubkina Street, Moscow 119991, Russian Federation
rudetection@gmail.com
Abstract. Presburger arithmetic PrA is the true theory of natural
numbers with addition. We study interpretations of PrA in itself. We
prove that all one-dimensional self-interpretations are deﬁnably isomor-
phic to the identity self-interpretation. In order to prove the results we
show that all linear orders that are interpretable in (N, +) are scattered
orders with the ﬁnite Hausdorﬀrank and that the ranks are bounded
in terms of the dimension of the respective interpretations. From our
result about self-interpretations of PrA it follows that PrA isn’t one-
dimensionally interpretable in any of its ﬁnite subtheories. We note that
the latter was conjectured by A. Visser.
Keywords: Presburger Arithmetic · Interpretations
Scattered linear orders
1
Introduction
Presburger Arithmetic PrA is the ﬁrst-order theory of natural numbers with
addition. It was introduced by Presburger in 1929 [13]. Presburger Arithmetic
is complete, recursively-axiomatizable, and decidable.
The method of interpretations is a standard tool in model theory and in the
study of decidability of ﬁrst-order theories [8,12]. An interpretation of a theory
T in a theory U essentially is a uniform ﬁrst-order deﬁnition of models of T in
models of U (we present a detailed deﬁnition in Sect. 3). In the paper we study
certain questions about interpretability for Presburger Arithmetic that were well-
studied in the case of stronger theories like Peano Arithmetic PA. Although,
from technical point of view the study of interpretability for Presburger Arith-
metic uses completely diﬀerent methods than the study of interpretability for
PA (see for example [18]), we show that from interpretation-theoretic point of
view, PrA has certain similarities to strong theories that prove all the instances
of mathematical induction in their own language, i.e. PA, Zermelo-Fraenkel set
theory ZF, etc.
A reﬂexive arithmetical theory ([18, p. 13]) is a theory that can prove the
consistency of all its ﬁnitely axiomatizable subtheories. Peano Arithmetic PA
This work is supported by the Russian Science Foundation under grant 16-11-10252.
c
⃝Springer International Publishing AG 2018
S. Artemov and A. Nerode (Eds.): LFCS 2018, LNCS 10703, pp. 354–367, 2018.
https://doi.org/10.1007/978-3-319-72056-2_22

Interpretations of Presburger Arithmetic in Itself
355
and Zermelo-Fraenkel set theory ZF are among well-known reﬂexive theories.
In fact, all sequential theories (very general class of theories similar to PA,
see [5, III.1(b)]) that prove all instances of induction scheme in their language
are reﬂexive. For sequential theories reﬂexivity implies that the theory cannot
be interpreted in any of its ﬁnite subtheories. A. Visser have conjectured that
this purely interpretational-theoretic property holds for PrA as well. Note that
PrA satisﬁes full-induction scheme in its own language but cannot formalize the
statements about consistency of formal theories.
The conjecture was studied by Zoethout [19]. Note that Presburger Arith-
metic, unlike sequential theories, cannot encode tuples of natural numbers by
single natural numbers. And hence for interpretations in Presburger Arithmetic
it is important whether individual objects are interpreted by individual objects
(one-dimensional interpretations) or by tuples of objects of some ﬁxed length
m (m-dimensional interpretations). Zoethout considered only the case of one-
dimensional interpretations and proved that if any one-dimensional interpreta-
tion of PrA in (N, +) gives a model that is deﬁnably isomorphic to (N, +) then
Visser’s conjecture holds for one-dimensional interpretations, i.e. there are no
one-dimensional interpretations of PrA in its ﬁnite subtheories. In the present
paper we show that the following theorem holds and thus prove Visser’s conjec-
ture for one-dimensional interpretations:
Theorem 1.1. For any model A of PrA that is one-dimensionally interpreted
in the model (N, +), (a) A is isomorphic to (N, +); (b) the isomorphism is deﬁn-
able in (N, +).
Note that Theorem 1.1(a) was established by Zoethout in [19].
We also study whether the generalization of Theorem 1.1 to multi-
dimensional interpretations holds. We prove:
Theorem 1.2. For any m and model A of PrA that is m-dimensionally inter-
preted in (N, +), the model A is isomorphic to (N, +).
We don’t know whether the isomorphism is always deﬁnable in (N, +).
In order to prove Theorem 1.2, we show that for every m each linear order
that is m-dimensionally interpretable in (N, +) is scattered, i.e. it doesn’t contain
a dense suborder. Moreover, our construction gives an estimation for Cantor-
Bendixson ranks of the orders (a notion of Cantor-Bendixson rank for scattered
linear orders goes back to Hausdorﬀ[7] in order to give more precise estimation
we use slightly diﬀerent notion of V D∗-rank from [10]):
Theorem 1.3. All linear orders m-dimensionally interpretable in (N, +) have
the V D∗-rank at most m.
Note that since every structure interpretable in (N, +) is automatic, the fact
that both the V D∗and Hausdorﬀranks of any scattered linear order inter-
pretable in (N, +) is ﬁnite follows from the results on automatic linear orders by
Khoussainov et al. [10].

356
A. Zapryagaev and F. Pakhomov
The work is organized as follows. Section 2 introduces the basic notions. In
Sect. 3 we give the deﬁnitions of non-parametric interpretations and deﬁnable
isomorphism of interpretations. In Sect. 4 we deﬁne the dimension of Presburger
sets and prove Theorem 1.3. In Sect. 5 we prove Theorem 1.1 and explain how
it implies the impossibility to interpret PrA in its ﬁnite subtheories. In Sect. 6
we discuss the approach for the multi-dimensional case.
2
Presburger Arithmetic and Deﬁnable Sets
In the section we give some results about Presburger Arithmetic and deﬁnable
sets in (N, +) from the literature that will be relevant for our paper.
Deﬁnition 2.1. Presburger Arithmetic (PrA) is the elementary theory of the
model (N, +) of natural numbers with addition.
It is easy to see that every number n ∈N, the relations < and ≤, modulo
comparison relations ≡n, for natural n ≥1, and the functions x −→nx of mul-
tiplication by a natural number n are deﬁnable in the model (N, +). We ﬁx some
deﬁnitions for these constants, relations, and functions. This gives us a transla-
tion from the ﬁrst-order language L of the signature ⟨=, {n | n ∈N}, +, < , {≡n|
n ≥1}, {x −→nx | n ∈N}⟩to the ﬁrst-order language L−of the signature
⟨=, +⟩. Since PrA is the elementary theory of (N, +), regardless of the choice
of the deﬁnitions, the translation is uniquely determined up to PrA-provable
equivalence. Thus we could freely switch between L-formulas and equivalent
L−-formulas. Note that PrA admits the quantiﬁer elimination in the extended
language L [13].
The well-known fact about order types of nonstandard models of PA also
holds for models of Presburger arithmetic:
Theorem 2.1. Any nonstandard model A |= PrA has the order type N + Z · A,
where ⟨A, <A⟩is some dense linear order without endpoints. Thus, in particular,
any countable model of PrA either has the order type N or N + Z · Q.
For vectors c, p1, . . . , pn ∈Zm we call the set {c +  kipi | ki ∈N} a lattice
with the generating vectors p1, . . . , pn and the initial vector c. If p1, . . . , pn are
linearly independent (n ≤m) we call the set an n-dimensional fundamental
lattice.
Ito [9] have proved that any union of ﬁnitely many (possibly, intersecting)
lattices in Nm is a disjoint union of ﬁnitely many fundamental lattices. Ginsburg
and Spanier [4, Theorem 1.3] have shown that the subsets of Nk deﬁnable in (N, +)
are exactly the subsets of Nk that are unions of ﬁnitely many (possibly, intersect-
ing) lattices; note that the sets from the latter class are known as semilinear sets.
Combining these two results we obtain
Theorem 2.2. All subsets of Nk deﬁnable in (N, +) are exactly the subsets of
Nk that are disjoint unions of ﬁnitely many fundamental lattices.

Interpretations of Presburger Arithmetic in Itself
357
Let us now consider the extension of the ﬁrst-order predicate language with
an additional quantiﬁer ∃=yx, called a counting quantiﬁer (notion introduced
in [2]), used as follows: if f(x, z) is an L-formula with the free variables x, z, then
F = ∃=yz G(x, z) is also a formula with the free variables x, y.
We extend the standard assignment of truth values to ﬁrst-order formulas in
the model (N, +) to formulas with counting quantiﬁers. For a formula F(x, y) of
the form ∃=yz G(x, z), a vector of natural numbers a, and a natural number n
we say that F(a, n) is true iﬀthere are exactly n distinct natural numbers b such
that G(a, b) is true. Apelt [1] and Schweikardt [15] have discovered that such an
extension does not extend the expressive power of PrA:
Theorem 2.3 ([15, Corollary 5.10]). Every L-formula F(x) that uses counting
quantiﬁers is equivalent in (N, +) to a quantiﬁer-free L-formula.
3
Interpretations
Deﬁnition 3.1. Suppose we have two ﬁrst-order signatures Ω1 and Ω2. An m-
dimensional translation ι of a ﬁrst order language of the signature Ω1 to the
ﬁrst-order language of the signature Ω2 consists of
1. a ﬁrst-order formula Domι(y) of the signature Ω2, where x is a vector of
variables of the length m, with the intended meaning of the deﬁnition of the
domain of translation;
2. ﬁrst-order formulas Predι,P (y1, . . . , yn) of the signature Ω2, where each yi is
a vector of variables of the length m, for each predicate P(x1, . . . , xn) from
Ω1 (including x1 = x2);
3. ﬁrst-order formulas Funι,f(y0, y1, . . . , yn, ) of the signature Ω2, where each
yi is a vector of variables of the length m, for each function f(x1, . . . , xn)
from Ω1.
Translation ι is an interpretation of a model A of the signature Ω1 with the
domain A in a model B of the signature Ω2 with the domain B if
1. Domι(y) deﬁnes a non-empty subset D ⊆Bm;
2. Predι,=(y1, y2) deﬁnes an equivalence relation ∼on the set D;
3. there is a bijection h: D/∼→A such that for each predicate P(x1, . . . , xn)
from Ω1 and b1, . . . , bn ∈D we have
A |= P(h([b1]∼), . . . , h([bn]∼)) ⇐⇒B |= Predι,P (b1, . . . , bn)
and for each function f(x1, . . . , xn) from Ω1 and b0, b1, . . . , bn ∈D we have
A |= h([b0]∼) = f(h([b1]∼), . . . , h([bn]∼)) ⇐⇒B |= Funι,f(b0, b1, . . . , bn).
Translation ι is an interpretation of a theory T of the signature Ω1 in a model
B of the signature Ω2 if it is an interpretation of some model of T in B. ι is an
interpretation of a theory T of the signature Ω1 in a theory U of the signature
Ω2 if it is an interpretation of T in every model B of U.

358
A. Zapryagaev and F. Pakhomov
Translation ι is called non-relative if the formula Domι(y) ≡⊤, where y
is (y1, . . . , ym). We say that translation ι has absolute equality if the formula
Predι,=(y, z) is y1 = z1 ∧. . . ∧ym = zm, where y is (y1, . . . , ym) and z is
(z1, . . . , zm).
Note that naturally for each translation ι of a signature Ω1 to a signature Ω2,
we could deﬁne a map F(x1, . . . , xn) −→F ι(y1, . . . , ym) from formulas of the
signature Ω1 to formulas of the signature Ω2 such that if ι is an interpretation
of a model A in a model B then for each b1, . . . , bn ∈D we have
A |= F(h([b1]∼), . . . , h([bn]∼)) ⇐⇒B |= F ι(b1, . . . , bn),
where m, D, and h are as in the deﬁnition above.
Also we note that if ι is an interpretation of a theory T in a model B then
there is a unique up to isomorphism model A of T such that ι is an interpretation
of B in A.
Deﬁnition 3.2. Suppose ι1 and ι2 are respectively an m1-dimensional and m2-
dimensional translations from a signature Ω1 to a signature Ω2. And suppose
that I(y, z) is a ﬁrst-order formula of the signature Ω2, where y consists of m1
variables and z consists of m2 variables.
Now assume ι1 and ι2 are interpretations of the same model A of the signature
Ω1 with the domain A in a model B of the signature Ω2 with the domain B. As
in Deﬁnition 3.1 translations ι1 and ι2 give us respectively sets D1 ⊆Bm1, D2 ⊆
Bm2 and equivalence relations ∼1 on D1 and ∼2 on D2. Under this assumption
we say that I(y, z) is a deﬁnition of an isomorphism of ι1 and ι2 if we could
choose bijections h1 : D1 →A and h2 : D2 →A (satisfying properties of h from
Deﬁnition 3.1, for respective ιi) such that for each b ∈D1 and c ∈D2 we have
h1([b]∼1) = h2([c]∼1) ⇐⇒B |= I(b, c).
If ι1 and ι2 are interpretations of the theory T in a theory U and for each
model B of U the formula I(y, z) is a deﬁnition of an isomorphism between ι1
and ι2 as interpretations in Bm then we say that I(y, z) is a deﬁnition of an
isomorphism between ι1 and ι2 as interpretations of T in U.
If ι1 and ι2 are interpretations of a theory T in a theory U (a model A) and
there is a deﬁnition of an isomorphism then we say that ι1 and ι2 as interpreta-
tions of a theory T in a theory U (a model A) are deﬁnably isomorphic.
Since the theory PrA that we study is an elementary theory of some model
(PrA = Th(N, +)), actually there is not much diﬀerence between interpretations
in the standard model and in the theory. A translation ι is an interpretation of
some theory T in PrA iﬀι is an interpretation of T in (N, +). A formula I is a
deﬁnition of an isomorphism between interpretations ι1 and ι2 of some theory T
in PrA iﬀI is a deﬁnition of an isomorphism between ι1 and ι2 as interpretations
of T in (N, +).

Interpretations of Presburger Arithmetic in Itself
359
4
Linear Orders Interpretable in (N, +)
4.1
Functions Deﬁnable in Presburger Arithmetic
Deﬁnition 4.1. Suppose A ⊆Nn is a deﬁnable set. We call a function f : A →
N piecewise polynomial of a degree ≤m if there is a decomposition of A into
ﬁnitely many fundamental lattices C1, . . . , Ck such that the restriction of f on
each Ci is a polynomial with rational coeﬃcients of a degree ≤m1.
In particular, a piecewise linear function is a piecewise polynomial function
of a degree ≤1.
Theorem 4.1. All deﬁnable in (N, +) functions f : Nn →N are exactly piece-
wise linear.
Proof. The deﬁnability of all piecewise linear functions in Presburger Arithmetic
is obvious. A function f : Nn →N is deﬁnable iﬀits graph
G = {(f(a1, . . . , an), a1, . . . , an) | (a1, . . . , an) ∈Nn}
is deﬁnable. According to Theorem 2.2, G is a ﬁnite union of fundamental lattices
J1 ⊔. . . ⊔Jk. For 1 ≤i ≤k we denote by J′
i the projections of Ji along the ﬁrst
coordinate, J′
i = {(a1, . . . , an) | ∃a0((a0, a1, . . . , an) ∈Ji)}. Clearly, all J′
i are
fundamental lattices. And the restriction of the function f on each of J′
i is linear.
Corollary 4.1. All deﬁnable in (N, +) functions f : N →N can be bounded from
above by a linear function with a rational slope. Conversely, if h1(x) < f(x) <
h2(x) for all x, where h1(x) and h2(x) are linear functions of the same irrational
slope, then f(x) is not deﬁnable.
4.2
Dimension
Here we give the deﬁnition for the notion of dimension of Presburger-deﬁnable
sets.
Deﬁnition 4.2. The dimension dim(A) of a Presburger-deﬁnable set A ⊆Nm
is deﬁned as follows.
– dim(A) = 0 iﬀA is empty or ﬁnite;
– dim(A) = k ≥1 iﬀthere is a deﬁnable bijection between A and Nk.
The following theorem shows that the deﬁnition indeed gives the unique
dimension for each PrA-deﬁnable set.
Theorem 4.2. Suppose M is an inﬁnite Presburger deﬁnable subset of Nk,
k ≥1. Then there is a unique natural number l ∈N such that there is a Pres-
burger deﬁnable bijection between M and Nl, 1 ≤l ≤k.
1 In our work, we use the word ‘piecewise’ only in the sense deﬁned here.

360
A. Zapryagaev and F. Pakhomov
Proof. First let us show that there is some l with the property. According to
Theorem 2.2, all deﬁnable in (N, +) sets are disjoint unions of fundamental lattices
L1, . . . , Ln of the dimensions s1, . . . , sn, respectively. It is easy to see that for each
Li there is a linear bijection with Nsi, which is obviously deﬁnable. Let us put l to
be the maximum of si’s. Now we just need to notice that for each sequence of nat-
ural number r1, . . . , rm and u = max(r1, . . . , rm) if u ≥1 then we could split a set
Nu into sets A1, . . . , Am for which we have deﬁnable bijections with Nr1, . . . , Nrm,
respectively. We prove the latter by induction on m.
Now let us show that there is no other l with this property. Assume the con-
trary. Then clearly, for some l1 > l2 there is a mapping f : Nl1 →Nl2. Let us con-
sider a sequence of expanding cubes, Il1
n
def
= {(x1, . . . , xk) | 0 ≤x1, . . . , xk ≤n}.
We deﬁne function g: N →N to be the function which maps a natural number n
to the least m such that f(Il1
n ) ⊆Il2
m. Clearly, g is a Presburger-deﬁnable func-
tion. Then there should be some linear function h: N →N such that g(n) ≤h(n),
for all n. But since for each n ∈N and m < nl1/l2 the cube Il1
n contains more
points than the cube Il2
m, from the deﬁnition of g we see that g(n) ≥nl1/l2. This
contradicts the linearity of the function h.
⊓⊔
From the proof above we see that the following corollary holds:
Corollary 4.2. The dimension of a set M ⊆Nk is equal to the maximal l such
that there exists an exactly l-dimensional fundamental lattice which is a subset
of M.
4.3
Presburger-Deﬁnable Linear Orders
Lemma 4.1. Let x = (x1, . . . , xn) and y = (y1, . . . , yk) be vectors of free vari-
ables, where y will be treated as a vector of parameters. Let F(x, y) be an L−-
formula such that for an inﬁnite set of parameter vectors B = {b1, b2, . . .} the
sets deﬁned by F(x, bi) are disjoint in Nn. Then only a ﬁnite number of those
deﬁnable sets can be exactly n-dimensional.
Proof. Let us consider the set A ⊆Nn+k deﬁned by the formula F(x, y). For
each vector b = (b1, . . . , bk) ∈Nk and set S ⊆Nn+k we consider section
S ↾b = {(a1, . . . , an, b1, . . . , bk) | (a1, . . . , an, b1, . . . , bk) ∈S}. Clearly in this
terms in order to prove the lemma, we need to show that there are only ﬁnitely
many distinct b ∈B such that the section A ↾b is an n-dimensional set. By
Theorem 2.2, the set A is a disjoint union of ﬁnitely many of fundamental lat-
tices Ji ⊆Nn+k. It is easy to see that if some section A ↾b were an n-dimensional
set then at least for one Ji, the section Ji ↾b were an n-dimensional set. Thus
it is enough to show that for each Ji there are only ﬁnitely many vectors b ∈B
for which the section Ji ↾b is an n-dimensional set.
Let us now assume for a contradiction that for some Ji there are inﬁnitely
many Ji ↾b0, for b0 ∈B, that are n-dimensional sets. Let us consider some
parameter vector b ∈Nk such that the section J ↾b is an n-dimensional set. Then
by Corollary 4.2 there exists an n-dimensional fundamental lattice K ⊆Ji ↾b0.
Suppose the generating vectors of K are v1, . . . , vn and initial vector of K is

Interpretations of Presburger Arithmetic in Itself
361
u. It is easy to see that each vector vj is a non-negative linear combination of
generating vectors of J, since otherwise for large enough h ∈N we would have
c+hvj ̸∈J. Now notice that for any b ∈B and a ∈J ↾b the n-dimensional lattice
with generating vectors v1, . . . , vn and initial vector a is a subset of a ∈J ↾b.
Thus inﬁnitely many of the sets deﬁned by F(x, b), for b ∈B contain the
shifts of the same n-dimensional fundamental lattice. It is easy to see that the
latter contradicts the assumption that all the sets are disjoint.
⊓⊔
Deﬁnition 4.3. We call a linear ordering (L, <) scattered if it does not have
an inﬁnite dense suborder.
Deﬁnition 4.4. Let (L, ≺) be a linear ordering. We deﬁne a family of equiva-
lence relations ≃α, for ordinals α ∈Ord by transﬁnite recursion:
– ≃0 is just equality;
– ≃λ= 
β<λ
≃α, for limit ordinals λ;
– a ≃α+1 b
def
⇐⇒|{c ∈L | (a ≺c ≺b) or (b ≺c ≺a)}/≃α| < ℵ0.
Let us deﬁne V D∗-rank2 rk(L, ≺) ∈Ord ∪{∞} of the order (L, ≺). The V D∗-
rank rk(L, ≺) is the least α such that L/≃α is ﬁnite. And if for all α ∈Ord the
factor-set L/≃α is inﬁnite then we put rk(L, ≺) = ∞.
By deﬁnition we put α < ∞, for all α ∈Ord.
Remark 4.1. Linear orders (L, ≺) such that rk(L, ≺) < ∞are exactly the scat-
tered linear orders.
Example 4.1. The orders with the V D∗-rank equal to 0 are exactly ﬁnite orders,
and the orders with V D∗-rank ≤1 are exactly the order sums of ﬁnitely many
copies of N, −N and 1 (one element linear order).
Theorem 4.3 (Restatement of Theorem 1.3). For every natural m ≥1,
linear orders which are m-dimensionally interpretable in (N, +) have V D∗-rank
m or below.
Proof. We prove the theorem by induction on m.
Suppose we have an m-dimensional interpretation of a linear order (L, ≺) in
(N, +), i.e. there is an L−formula D(x) giving the domain of the interpretation
and L−formula ≺∗(x, y) giving interpretation of the order relation, where both
x and y consist of m variables. Without loss of generality we may assume that
L = {a ∈Nm | (N, +) |= D(a)} and ≺is deﬁned by the formula ≺∗.
Now assume for a contradiction that rk(L, ≺) > m. By the deﬁnition of V D∗-
rank, there are inﬁnitely many distinct ≃m-equivalence classes in L. Hence there
is an inﬁnite chain a0 ≺a1 ≺. . . of elements of L such that ai ̸≃m ai+1, for each i.
Let us consider intervals Li = {b ∈L | ai < b < ai+1}. Since ai ̸≃m ai+1, the set
Li/≃m−1 is inﬁnite and rk(Li, ≺) > m −1.
2 V D stand for very discrete; see [14, pp. 84–89].

362
A. Zapryagaev and F. Pakhomov
Clearly, all Li are Presburger deﬁnable sets. Let us show that dim(Li) ≥m,
for each i. If m = 1 then it follows from the fact that Li is inﬁnite. If m > 1 then
we assume for a contradiction that dim(Li) < m. And notice that in this case
(Li, ≺) would be m −1-dimensionally interpretable in (N, +) which contradict
induction hypothesis and the fact that rk(Li, ≺) > m −1. Since Li ⊆Nm, we
conclude that dim(Li) = m, for all i.
Now consider the parametric family of subsets of Nm given by the formula
y1 ≺∗x ≺∗y2, where we treat variables y1 and y2 as parameters. We consider
sets given by pairs of parameters y1 = ai and y2 = ai+1, for i ∈N. Clearly the
sets are exactly Li’s. Thus we have inﬁnitely many disjoint sets of the dimension
m in the family and hence we have contradiction with Lemma 4.1.
Remark 4.2. Each scattered linear order of V D∗-rank 1 is 1-dimensionally inter-
pretable in (N, +). There are scattered linear orders of V D∗-rank 2 that are not
interpretable in (N, +).
Proof. The interpretability of linear orders with rank 0 and rank 1 follows from
Example 4.1.
Since there are uncountably many non-isomorphic scattered linear orders of
V D∗-rank 2 and only countably many linear orders interpretable in (N, +), there
is some scattered linear order of V D∗-rank 2 that is not interpretable in (N, +). ⊓⊔
5
One-Dimensional Self-interpretations and Visser’s
Conjecture
The following theorem is a generalization of [19, pp. 27–28, Lemmas 3.2.2–3.2.3].
Theorem 5.1. Let U be a theory and ι be an m-dimensional interpretation of
U in (N, +). Then for some m′ ≤m there is an m′-dimensional non-relative
interpretation with absolute equality κ of U in (N, +) which is deﬁnably isomor-
phic to ι.
Proof. First let us ﬁnd κ with absolute equality. Indeed there is a deﬁnable in
(N, +) well-ordering ≺of Nm:
(a0, . . . , am−1) ≺(b0, . . . , bm−1)
def
⇐⇒∃i < m(∀j < i (aj = bj) ∧ai < bi).
Now we could deﬁne κ by taking the deﬁnition of + from ι, taking the trivial
interpretation of equality, and taking the domain of interpretation to be the part
of the domain of ι that consists of the ≺-least elements of equivalence classes with
respect to ι-interpretation of equality. It is easy to see that this κ is deﬁnably
isomorphic to ι.
Now assume that we already have ι with absolute equality. We ﬁnd the desired
non-relative interpretation κ by using Theorem 4.2 and bijectively mapping
the domain of ι to Nm′, where m′ is the dimension of the domain of the inter-
pretation ι.
⊓⊔

Interpretations of Presburger Arithmetic in Itself
363
Combining Theorems 2.1 and 4.3, we obtain
Theorem 5.2 (Restatement of Theorem 1.1). For any model A of PrA
that is one-dimensionally interpreted in the model (N, +), (a) A is isomorphic
to (N, +); (b) the isomorphism is deﬁnable in (N, +).
Proof. Let us denote by <∗the order relation given by the PrA deﬁnition of
< within A. Clearly <∗is deﬁnable in (N, +). Thus we have an interpretation
of the order type of A in PrA. Hence by Theorem 4.3 the order type of A is
scattered. But from Theorem 2.1 we know that the only case when the order
type of a model of PrA is scattered is the case when it is exactly N. Thus A
is isomorphic to (N, +). From Theorem 5.1 it follows that it is enough to show
the deﬁnability of the isomorphism only in the case when the interpretation that
gives us A is a non-relative interpretation with absolute equality.
It is easy to see that, the isomorphism f from A to (N, +) is the function
f : x −→|{y ∈N | y <∗x}|. Now we use counting quantiﬁer to express the
function:
f(a) = b ⇐⇒(N, +) |= ∃=bz (z <∗a)
(1)
Now apply Theorem 2.3 and see that f is deﬁnable in (N, +).
Theorem 5.3. Theory PrA is not one-dimensionally interpretable in any of
its ﬁnitely axiomatizable subtheories.
Proof. Assume ι is an one-dimensional interpretation of PrA in some ﬁnitely
axiomatizable subtheory T of PrA. In the standard model (N, +) the interpre-
tation ι will give us a model A for which there is a deﬁnable isomorphism f with
(N, +). Now let us consider theory T′ that consists of T and the statement that
the deﬁnition of f gives an isomorphism between (internal) natural numbers and
the structure given by ι. Clearly T′ is ﬁnitely axiomatizable and true in (N, +),
and hence is subtheory of PrA. But now note that T′ proves that if something
was true in the internal structure given by ι, it is true. And since T′ proved any
axiom of PrA in the internal structure given by ι, the theory T′ proves every
axiom of PrA. Thus T′ coincides with PrA. But it is known that PrA is not
ﬁnitely axiomatizable, contradiction.
6
Multi-dimensional Self-interpretations
We already know that the only linear orders that it is possible to interpret in (N, +)
(even by multi-dimensional interpretations) are scattered linear orders. And we
could use this to prove the analogue of Theorem 1.1(a) for multi-dimensional inter-
pretations by the same reasoning as we have used for Theorem 1.1(a).
However, the only way any interpretation can be isomorphic to trivial in a
multi-dimensional case is by having a one-dimensional set as its domain and
from Theorem 1.1 it follows that all interpretations of PrA in (N, +) that have
one-dimensional domain are deﬁnably isomorphic to (N, +). Thus in order to

364
A. Zapryagaev and F. Pakhomov
prove the analogue of Theorem 1.1(b) for multi-dimensional interpretations one
should in fact show that the domain of any interpretation of PrA in (N, +)
should be one-dimensional set.
In the section we will give some partial results about multi-dimensional self-
interpretations of PrA.
Cantor polynomials are quadratic polynomials that deﬁne a bijection between
N2 and N:
C1(x, y) = C2(y, x) = 1
2(x + y)2 + 1
2(x + 3y).
(2)
The bijections C1 and C2 are the isomorphism of (N2, ≺1) and (N, <) and
the isomorphism of (N2, ≺2) and (N, <), where
(a1, a2) ≺1 (b1, b2)
def
⇐⇒(a2 < b2 ∧a1 + a2 = b1 + b2) ∨(a1 + a2 < b1 + b2),
(a1, a2) ≺2 (b1, b2)
def
⇐⇒(a2 > b2 ∧a1 + a2 = b1 + b2) ∨(a1 + a2 < b1 + b2).
Note that both ≺1 and ≺2 are deﬁnable in (N, +). The following theorem show
that this interpretations of (N, <) could not be extended to interpretations of
(N, x →sx), for some s and thus shows that this interpretations could not be
extended to interpretations of (N, +).
Theorem 6.1. Let s be a natural number that is not a square and i be either 1
or 2. Let us denote by f : N2 →N2 the function f(a) = C−1
i
(s · Ci(a)), i.e. the
preimage of the function x →s · x under the bijection Ci : N2 →N. Then the
function f is not deﬁnable in (N, +).
Proof. Since the cases of i = 1 and i = 2 are essentially the same, let us
consider just the case of i = 1. Suppose the contrary: there is an L−-formula
F(x1, x2, y1, y2) which deﬁnes the graph of f:
(N, +) |= F(a1, a2, b1, b2) ⇐⇒f(a1, a2) = (b1, b2), for all a1, a2, b1, b2 ∈N.
Then the following function h(x) : N →N is also deﬁnable:
h(a) = b
def
⇐⇒∃c, d(f(a, 0) = (c, d) ∧b = c + d).
(3)
Now it is easy to see that the following inequalities holds for all a ∈N:
C1(h(a), 0) ≤s · C1(a, 0) < C1(h(a) + 1, 0)
⇒h(a)(h(a) + 1)
2
≤sa(a + 1)
2
< (h(a) + 1)(h(a) + 2)
2
⇒y2 < S(x + 1)2 and Sx<(y + 2)2
⇒
√
Sx −2 < y <
√
Sx +
√
S.
We conclude that a Presburger-deﬁnable function h(x) is bounded both from
above and below with linear functions of the same irrational slope. Contradiction
with Corollary 4.1.
⊓⊔

Interpretations of Presburger Arithmetic in Itself
365
We conjecture the following general fact holds:
Conjecture 6.1. For any (multi-dimensional) interpretation ι of PrA in the
model (N, +) there is a deﬁnable isomorphism with the trivial interpretation of
(N, +) in (N, +).
The following theorem is a slight modiﬁcation of the theorem by Blakley [3].
Theorem 6.2. Let A be a d × n matrix of integer numbers, function ϕA : Zd →
N ∪{ℵ0} is deﬁned as follows:
ϕA(u)
def
= |{λ = (λ1, . . . , λn) ∈Nn | Aλ = u}|.
Then if the values of ϕA are always ﬁnite, the function ϕA is a piecewise
polynomial function of a degree ≤n −rk(A).
Proof. The existence of the fundamental lattices C1, . . . , Cl on which ϕA is poly-
nomial follows from [17, p. 302]. Now we prove that the n −rk(A) bound on the
degree holds.
Let us consider any fundamental lattice L with the initial vector v and gen-
erating vectors s1, . . . , sm such that the restriction of ϕA to L is a polynomial.
Now it is easy to see that we could ﬁnd a polynomial P(x1, . . . , xm) such that
ϕA(v + η1s1 + . . . + ηmsm) = P(η1, . . . , ηm), for all η1, . . . , ηm ∈N. Since the
choice of L was arbitrary, we could ﬁnish the proof of the theorem by showing
that P is of the degree ≤n −rk(A). Let us assume for a contradiction that the
degree of P is > n −rk(A). Clearly, then there are θ1, . . . , θm ∈N such that
the polynomial Q(y) = P(θ1y, . . . , θmy) is of the degree k > n −rk(A). Now we
consider the vector d = η1s1 + . . . + ηmsm and the vectors el = v + ld, for l ∈N.
We have ϕA(el) = Q(l).
Let us now estimate the values of ϕA(el). The value ϕA(el) is the number
of integer points in the polyhedron Hl = {(λ1, . . . , λn) = λ ∈Rn | Aλ =
el and λ1, . . . , λn ≥0}. And now it is easy to see that ϕA(el) ≤hl/o, where o
is the volume of (n −rk(A))-dimensional sphere of the radius 1/2 and hl is the
(n−rk(A))-dimensional volume of (at most) (n−rk(A))-dimensional polyhedron
H′
l = {(λ1, . . . , λn) = λ ∈Rn | Aλ = el and λ1, . . . , λn ≥−1}. Now we just need
to notice that the linear dimensions of the polyhedra H′
l are bounded by a linear
function of l and hence the volumes hl are bounded by some polynomial of the
degree n −rk(A), contradiction with the fact that the polynomial Q(y) were of
the degree k > n −rk(A).
⊓⊔
Recall that a semilinear set is a ﬁnite union of lattices and that by result of
[9] any semilinear set is a disjoint union of fundamental lattices. It is easy to see
that the following lemma holds:
Lemma 6.1. 1. If f, g: A →Z are piecewise polynomial functions of a degree ≤
m then the function h: A →Z, h(v) = f(v) + g(v), is a piecewise polynomial
function of a degree ≤m;

366
A. Zapryagaev and F. Pakhomov
2. if A ⊆Zn is a semilinear set, f : A →Z is a piecewise polynomial function
of a degree ≤m, and B ⊆A is PrA-deﬁnable set then the restriction of f to
B is a piecewise polynomial function of a degree ≤m;
3. if A ⊆Zn is a semilinear set, f : A →Z is a piecewise polynomial function
of a degree ≤m, and F : Zn →Zk is a linear operator, then the function
h: F(A) →Zk is a piecewise polynomial function of a degree ≤m.
We prove the lemma that generalizes the one-dimensional construction of the
cardinality of sections.
Lemma 6.2. Let S ⊆Nn+m be a deﬁnable set in (N, +). For each vector b =
(b1, . . . , bm) ∈Nm we deﬁne section A ↾b to be the set of all elements of S of the
form (a1, . . . , an, b1, . . . , bm). Suppose all sets S ↾b are ﬁnite. For each vector
a ∈Nn. Consider the section cardinality function fS : Nm →N, fS : a →|S ↾b|.
Then fS is a piecewise polynomial function of a degree ≤n.
Proof. Let us ﬁrst prove the theorem for the case when S is a fundamental
lattice with the initial vector c and the generating vectors v1, . . . , vs ∈Nn+m.
We consider the vectors c′, v′
1, . . . , v′
s ∈Nm that consist of the last m components
of vectors c, v1, . . . , vs, respectively. Clearly, for each b ∈Nm, the value fS(b) =
|A ↾b| is equal to the number of diﬀerent λ = (λ1, . . . , λs) ∈Ns such that
λ1v′
1 + . . . + λsv′
s = b −c′. Now we compose a matrix A from the vectors
v′
1, . . . , v′
s and see that fS(b) = |{λ ∈Nm | Aλ = b −c′}| = ϕA(b −c). Note that
since S was a fundamental lattice, s −rk(A) ≤n. Now we apply Theorem 6.2
and see that ϕA is a piecewise polynomial of a degree ≤n. Now from Lemmas
6.1(2) and 6.1(3) it follows that f is piecewise polynomial of a degree ≤n too.
In the case of arbitrary deﬁnable A, we apply Theorem 2.2 and ﬁnd funda-
mental lattices J1, . . . , Js such that A = J1 ⊔J2 ⊔. . . ⊔Js. Now we see that
for each b ∈Nm, we have fA(a) = fJ1(a) + . . . + fJs(a) and since we already
know that all fJi are piecewise polynomial of a degree ≤n, by Lemma 6.1(1)
the function fA is piecewise polynomial of a degree ≤n.
⊓⊔
Theorem 6.3. Suppose a deﬁnable in (N, +) binary relation ≺on Nn has the
order type N. Then the order isomorphism between (Nm, ≺) and (N, <) is a
piecewise polynomial function of a degree ≤n.
Proof. We see that the order isomorphism is the function f : Nm →N given by
f(a1, . . . , an) = |{(b1, . . . , bn, a1, . . . , an) | (b1, . . . , bn) R (a1, . . . , an)}|.
By Lemma 6.2 we see that f is a piecewise polynomial function.
⊓⊔
Fueter-P´olya theorem [6,11] states that every quadratic polynomial that
maps N2 onto N is one of two Cantor polynomials (2). If one would want to
prove Conjecture 6.1 one of the possible approaches would be to give a classiﬁ-
cation of all piecewise polynomial bijections and then use the classiﬁcation and
a generalization of Theorem 6.1 in order to show that no two-dimensional non-
relative interpretation of (N, <) in (N, +) could be extended to an interpretation
of (N, +).

Interpretations of Presburger Arithmetic in Itself
367
Acknowledgments. The authors wish to thank Lev Beklemishev for suggesting to
study Visser’s conjecture, number of discussions of the subject, and his useful comments
on the paper.
References
1. Apelt, H.: Axiomatische Untersuchungen ¨uber einige mit der Presburgerschen
Arithmetik verwandte Systeme. MLQ Math. Log. Q. 12(1), 131–168 (1966)
2. Barrington, D., Immerman, N., Straubing, H.: On uniformity within NC1. J. Com-
put. System Sci. 41(3), 274–306 (1990)
3. Blakley, G.R.: Combinatorial remarks on partitions of a multipartite number. Duke
Math. J. 31(2), 335–340 (1964)
4. Ginsburg, S., Spanier, E.: Semigroups, Presburger formulas, and languages. Paciﬁc
J. Math. 16(2), 285–296 (1966)
5. H´ajek, P., Pudl´ak, P.: Metamathematics of First-Order Arithmatic. Springer,
New York (1993)
6. Fueter, R., P´olya, G.: Rationale Abzhlung der Gitterpunkte, Vierteljschr. Natur-
forsch. Ges. Zrich 58, 280–386 (1923)
7. Hausdorﬀ, F.: Grundz¨uge einer Theorie der geordneten Mengen. Math. Ann. 65(4),
435–505 (1908)
8. Hodges, W.: Model Theory, vol. 42. Cambridge University Press, Cambridge (1993)
9. Ito, R.: Every semilinear set is a ﬁnite union of disjoint linear sets. J. Comput.
Syst. Sci. 3(2), 221–231 (1969)
10. Khoussainov, B., Rubin, S., Stephan, F.: Automatic linear orders and trees. ACM
Trans. Comput. Log. 6(4), 675–700 (2005)
11. Nathanson, M.B.: Cantor polynomials and the Fueter-P´olya theorem. Am. Math.
Monthly 123(10), 1001–1012 (2016)
12. Tarski, A., Mostowski, A., Robinson, R.M.: Undecidable Theories. Studies in Logic
and the Foundations of Mathematics. North-Holland, Amsterdam (1953)
13. Presburger, M.: ¨Uber die Vollst¨andigkeit eines gewissen Systems der Arithmetik
ganzer Zahlen, in welchem die Addition als einzige Operation hervortritt. Comptes
Rendus du I congr`es de Math´ematiciens des Pays Slaves 92101 (1929). English
translation in [16]
14. Rosenstein, J.: Linear Orderings, vol. 98. Academic Press, New York (1982)
15. Schweikardt, N.: Arithmetic, ﬁrst-order logic, and counting quantiﬁers. ACM
Trans. Comput. Log. 6(3), 634–671 (2005)
16. Stansifer, R.: Presburger’s Article on Integer Arithmetic: Remarks and Translation
(Technical report). Cornell University (1984)
17. Sturmfels, B.: On vector partition functions. J. Combin. Theory Ser. A 72(2),
302–309 (1995)
18. Visser, A.: An overview of interpretability logic. In: Kracht, M., de Rijke, M.,
Wansing, H., Zakharyaschev, M. (eds.) Advances in Modal Logic. CSLI Lecture
Notes, vol. 87, pp. 307–359 (1998)
19. Zoethout, J.: Interpretations in Presburger Arithmetic. BS thesis. Utrecht
University (2015)

Author Index
Achilleos, Antonis
1
Artemov, Sergei
22
Avron, Arnon
37
Baaz, Matthias
55
Barlocco, Simone
72
Beklemishev, Lev D.
91
Brünnler, Kai
107
Ciabattoni, Agata
120
Cohen, Liron
37
de Paiva, Valeria
256
Diener, Hannes
140
Eades III, Harley
256
Ferguson, Thomas Macaulay
154
Flumini, Dandolo
107
Ghilezan, Silvia
170
Hannula, Miika
190
Ivetić, Jelena
170
Kašterović, Simona
170
Kontinen, Juha
190
Krupski, Vladimir N.
211
Kupke, Clemens
72
Leitsch, Alexander
55
Liu, Yanhong A.
221
Lolic, Anela
55
Lubarsky, Robert S.
140, 242
Lyon, Tim
120
Ognjanović, Zoran
170
Pakhomov, Fedor
354
Peluce, V. Alexis
273
Ralph, Benjamin
289
Ramanayake, Revantha
120
Sanders, Sam
309
Savić, Nenad
170
Statman, Rick
331
Stoller, Scott D.
221
Studer, Thomas
107
Virtema, Jonni
190
Yu, Junhua
337
Zapryagaev, Alexander
354

