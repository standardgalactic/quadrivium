
Notes on logic and set theory


Notes on logic and
set theory
P. T. JOHNSTONE
University Lecturer in Pure Mathematics
University of Cambridge
| CAMBRIDGE
UNIVERSITY PRESS

Published by the Press Syndicate of the University of Cambridge
The Pitt Building, Trumpington Street, Cambridge CB2 1RP
40 West 20th Street, New York, NY 10011-4211, USA
10 Stamford Road, Oakleigh, Melbourne 3166, Australia
© Cambridge University Press 1987
First published 1987
Reprinted 1992,1996
British Library cataloguing in publication data
Johnstone, P.T.
Notes on logic and set theory.
1. Logic, symbolic and mathematical
I. Title
511.3 BC135
Library of Congress cataloguing in publication data
Johnstone, P. T.
Notes on logic and set theory.
1. Logic, Symbolic and mathematical. 2. Set theory.
I. Title.
QA9.J64 1987 511.3 87-11758
ISBN 0 521 33502 7 hard covers
ISBN 0 521 33692 9 paperback
Transferred to digital printing 2002
MP

Contents
Preface 
vii
1 Universal algebra 
1
2 Propositional calculus 
11
3 First-order theories 
18
4 Recursive functions 
34
5 Zermelo-Fraenkel set theory 
53
6 Ordinals and well-orderings 
68
7 The axiom of choice 
78
8 Cardinal arithmetic 
88
9 Consistency and independence 
97
Index of definitions 
108
Index of names 
111


Preface
This book has its origins in a course of lectures entitled 'Set Theory
and Logic' which is given to third-year undergraduates in
Cambridge. The Cambridge Mathematical Tripos contains rather
little on the foundational aspects of mathematics: this course is (at the
time of writing - though there are plans for a change before long) the
only opportunity which undergraduates have to learn about the basic
ideas of logic and axiomatic set theory in an examinable context, and
its aim is therefore to provide a general introduction to these ideas for
students who, though they may possess considerable sophistication
in other areas of mathematics, have no previous experience of logic
beyond a nodding acquaintance with 'naive' set theory, and whose
primary interests may well lie in other areas of pure (or even applied)
mathematics. Having lectured this course in 1984, 1985 and 1986,1
have been struck by the fact that there was no single textbook
available covering both logic and set theory at the level of rigour and
sophistication appropriate to such a course, and - in the belief that
there might be universities other than Cambridge where the need for
such a textbook was felt - I conceived the idea of expanding my
lecture notes into a publishable text. I am glad to say that this idea
was enthusiastically received by Cambridge University Press; I am
grateful, in particular, to David Tranah and Martin Gilchrist for
their support of the project.
The raison d'etre of this book, then, is to try to collect within a
single pair of covers everything that the well-educated mathematician
in the late twentieth century needs to know about the foundations of
his subject. Though there has, as indicated above, been some
expansion as compared with the original lecture course, it has been

viii 
Preface
kept to a bare minimum: anything which is merely of specialist
interest to logicians has (I hope) been excluded. (Briefly, the additions
consist of the whole of Chapter 4 on recursion theory - there was,
regrettably, not enough time to cover recursive functions in the
original course - plus more detailed proofs of one or two major
results (such as the Completeness Theorem for the Predicate
Calculus) which were merely stated, or given sketch-proofs, in the
lectures.)
However, I have refrained from giving the book a title of the Logic
for the Working Mathematician variety, since such titles are often a
cover for compromise: in their anxiety to make material accessible to
the general reader, authors have a tendency to skate over details
when to do otherwise would involve them in discussion of what might
be considered specialist matters. (I should hastily add that the last
sentence is not intended as a criticism of any particular book whose
title may approximate to that quoted.) In this book I have tried to be
completely honest with the reader; I have always sought the simplest
and most direct proof, but where there are genuine technical
difficulties in the way I have not been afraid to say so (even though, in
some cases, it has not been possible within the compass of a book like
this to give a full account of the difficulties or of the manner of their
resolution). In an effort to prevent the text from becoming too
indigestible, I have often relegated the discussion of these difficulties
to a remark (sometimes headed 'Note for worriers', or something
equally facetious) enclosed within square brackets; the reader who
wishes to confine himself to the basic ideas and not bother about the
technicalities can usually skip over such bracketed passages without
loss of continuity.
The layout of the book is as follows. Chapters 1-3 develop the
language and machinery of first-order logic, up to the proof of the
Completeness Theorem and some of its consequences. Chapter 4
develops recursion theory from its beginnings up to (but not quite
including) the Recursion Theorem. Chapters 5-8 develop Zermelo-
Fraenkel set theory, beginning with the axioms and working up to
the 'traditional' discussion of ordinal and cardinal arithmetic.
Finally, Chapter 9 contains a proof of Gddel's Incompleteness
Theorems, followed by a fairly informal discussion of the technology
of set-theoretic independence proofs. There are exercises at the end of
each chapter (except Chapter 9, where it did not seem appropriate);

Preface 
ix
these range from mere five-finger exercises, through the verification of
minor details which have been omitted from the proofs of theorems in
the text, to quite substantial problems whose results might well have
been included in the text as propositions, had it not been for the
policy of exclusion mentioned earlier. The latter kind (in particular)
have been provided with what I hope is a generous supply of hints,
enclosed within square brackets.
Although it is clearly preferable that a student should work
through the whole book from beginning to end, it is possible to meet
the demands of shorter courses by omitting material in various ways.
In particular, if it is desired to omit recursion theory (as in the course
from which the book developed), then Chapter 4 can be skipped
without any loss of understanding of Chapters 5-8; there will
inevitably be more difficulty with the Incompleteness Theorems in
Chapter 9, but I hope that it would still be possible to understand the
discussion of them on an informal level. On the other hand, if one is
not particularly interested in covering axiomatic set theory, it should
be possible to jump from the end of Chapter 4 - or, even better, from
about halfway through Chapter 5 - to the beginning of Chapter 9.
The prerequisites for reading the book are fairly few; in particular,
though the opening chapters presuppose some acquaintance with
naive set theory, there is no presumption that the reader knows
anything about logic. Otherwise, his mathematical knowledge is
assumed to be what would be usual for a final-year undergraduate in
Britain: some familiarity with subjects such as group theory, ring
theory and point-set topology is presumed in some of the examples,
but the omission of these examples should not seriously damage one's
understanding of the mainstream of the text. Thus, although this is
not its primary purpose, the book could be used as a first course in
logic for rather more specialist logicians than I have envisaged.
There is one respect, however, in which the book is rather
conspicuously aimed at non-specialists: namely, I have not been
afraid to shoot a few of the sacred cows of logical tradition for the
sake of rendering the exposition more smoothly compatible with
mathematical practice. Perhaps the most obvious instance occurs in
Chapter 3 where, in order to develop a logical calculus which is both
sound and complete for possibly-empty models, I found it necessary
to introduce the restriction that quantifiers may only be applied to
formulae which actually involve the quantified variable [if (Vx)±

x 
Preface
were allowed as a formula, then neither of the implications ((Vx)i. =>
(Vx)~1(x = x)) and ((Vx)~1(x = x) =>(Vx)l) would be provable]. I
can well imagine that professional logicians will find this hard to
swallow (I did myself at first, though I am not by training a logician);
but I would ask them to reflect, before they condemn me, on whether
anyone other than a logician would find this restriction at all odd.
Although, as indicated in the first paragraph, the selection of topics
covered in this book does not exactly correspond to that in any
previous book known to me, there are a number of previous texts
from which I have borrowed ideas concerning the arrangement and
presentation of material, and to whose authors I must therefore
express my indebtedness - it would be obvious in any case from the
text itself. For the logic chapters (1-3), I have taken various ideas
from An Algebraic Introduction to Mathematical Logic by D. W.
Barnes and J. M. Mack (Springer-Verlag, 1975); in particular, the
idea of beginning a treatment of first-order logic by studying
universal algebra is theirs. In Chapter 4, the influence of N. J.
Cutland's book Computability (Cambridge University Press, 1980)
will be apparent to anyone who knows it well. And in the set theory
chapters (5-8), the ordering of material (in particular) owes a good
deal to Sets: Naive, Axiomatic and Applied by D. van Dalen, H. C.
Doets and H. de Swart (Pergamon Press, 1978). [The citation of
these three texts has an ulterior motive. It occurs to me that many
students, having read the deliberately brief accounts of first-order
logic, recursion theory and set theory in this book, will want to
pursue at least one of them in greater depth. For this purpose, I
should be happy to steer them towards the three books just
mentioned.]
But, far more than to any of these authors, I am indebted to the
three generations of undergraduates who struggled through the
lectures that generated successive approximations to these notes, and
to my colleagues who, in tutorials, found themselves obliged to patch
up my mistakes and eliminate the misunderstandings I had created. It
would be invidious to mention any particular names, but it is
undoubtedly true that, but for the feedback I received from them,
these notes would contain a great many more errors than they do.
Cambridge, January 1987 
P. T. Johnstone

1
Universal algebra
The function of mathematical logic is to provide formal languages for
describing the structures with which mathematicians work, and the
methods of proof available to them. Obviously, the more
complicated we make our language, the more powerful it will be as an
instrument for expressing our ideas; but in these notes we are going to
begin with what is perhaps the simplest useful language, that of
universal algebra (sometimes called equational logic). Although
simple, it displays many of the characteristic features of more
complicated languages, which is why it makes a good introduction
to them.
Universal algebra begins by abstracting the common features of a
number of familiar mathematical structures, including groups, rings
and vector spaces. In each of these cases, the structure is defined to be
a set equipped with certain finitary operations, which satisfy certain
equations. For example, a group is a set G equipped with
a binary operation m:G x G->G 
(multiplication),
a unary operation i:G -> G 
(inversion),
and a nullary operation e:G° -> G 
(identity)
[note: we adopt the convention that G° is a singleton set for any G, so
that a 0-ary operation - also called a constant - simply picks out a
single element of G], satisfying the equations
m(x, m(y, z)) = m(m(x, y), z) (associative law),
m(e, x) = x 
(left identity law),
and m(i(x), x) = e 
(left inverse law),
which are supposed to hold for all possible values of x, y, z in G.
We leave it as an exercise for the reader to write down similar

2 
Notes on logic and set theory
descriptions of the notion of ring (with 1), and of the notion of K-
vector space for a given field K. Note that for the latter it is necessary
(or at least convenient) to take (scalar multiplication by) each element
of K as a unary operation; thus in general the set of operations and/or
equations required to define a given type of structure may be infinite.
Abstracting from the above examples, we introduce the notion of
an operational type. An operational type is a pair (Q, a) where Q is a
set of operation-symbols and a is a function assigning to each w e Q a
natural number <x(co), called its arity. [N.B.: throughout these notes, 0
is considered to be a natural number.] Frequently, we suppress any
explicit mention of the function a, and simply write 'Q is an
operational type'. Thus in our example above we have Q = {m, /, e}
with a(m) = 2, a(0 = 1, oc(e) = 0.
Given an operational type (Q, a), a structure of type (Q, a) (or Q-
structure, or Q-algebra) is a set A equipped with functions
coA: A*{<a) -* A for each coeQ. We call coA the interpretation of the
abstract symbol co in the structure A; we also speak of the family of
functions (coA | co e Q) as an Q-structure on the set A. A homomorphism
f.A^Bof 
Q-structures is a function such that
f(a>A(ax,..., 
aa(co))) = ^ ( / ( f l j , . . . , 
f(aaito)))
for all co eQ and all ax, a2,..., 
aaita) in A.
So much for the operations; how about the equations? Before
answering this question, we turn to a seemingly different topic: the
notion of a term or derived operation. Let Q be an operational type
and X a set (whose elements we shall call variables; we assume for
convenience Q n X = 0 ) ; then the set Fa(X) (or simply FX) of Q-
terms in X is defined inductively as follows:
(a) ifxeX, then xeFn(X).
(b) If 
coed, 
oc(co) = n 
and 
tl9t2,. 
•. ,tneFa(X), 
then
art1f2...tlleFQ(A').
(c) That's all.
[Inductive definitions of this type are very common in the
construction of formal languages. Formally, what this one means is
that Fn(X) is the smallest subset of the set (M, say) of all finite strings
of elements o f Q u I which satisfies the closure properties (a) and (b),
i.e. the intersection of all such subsets.]

Universal algebra 
3
Remark 
1.1. Note in passing that we have a simple algorithm for
determining whether a given finite string in M belongs to FQ(X): start
at the right-hand end of the string with counter set to 0, and move
leftwards increasing the count by 1 each time you pass a variable, and
decreasing it by n — 1 each time you pass an n-ary operation-symbol.
Then the string belongs to FX iff the counter never falls below 1 after
your start, and finishes at 1. As illustrations, we show the counter
values for a number of strings where Q is the operational type of
groups and X = {x, y, z}; the first one is in FX, the other two are not.
1 2 1 2 3 3 2 1 1 0 
1 2 2 2 1 0 
1 0 
3 3 2 3 2 2 1 0
m e m m i x y i z ; 
m i i x y m z \ 
i x m e i y x .
Theorem 
1.2. (i) Fa(X) has an Q-structure.
(ii) Fn(X) is the free Q-structure generated by AT; i.e., given
any Q-structure A and any function f:X -* A, there exists a
unique homomorphism / : FQ(AT) -* A extending /.
Proof. The existence of the Q-structure is immediate from clause (b)
of the definition: if co e Q (with a(a>) = n, say) and tl9t29. -. 9tne FX,
define
o ) F X ( t l 9 t 2 9 . . . 
9t n) = (ot 1t 2 . . . t n
(i.e. just erase the brackets and commas).
Part (ii) is essentially a matter of putting the brackets back in. Since
FX was defined inductively, we can define / inductively:
if t = xeX, then f(t) = f(x);
if t = wt1 ... tn where co e Q, OL(CO) = n and / has already been
defined at tl9..., tHeFX, then f(t) = 
comfit,),...,/(;„)).
It is then clear that / is a homomorphism, and that it is the unique
homomorphism extending /. 
•
Another important (and trivial) property of free Q-structures is
Lemma 7.3. For any X,
Fcl(X) = {J{FQ(X')\X'^X, 
A" finite}. •
Thus we may, for many purposes, restrict our attention to free
structures generated by finite sets. Let Xn = {xl9x2,... 
,xn} be a
standard n-element set; let teFXn, and let A be any Q-structure.

4 
Notes on logic and set theory
Then we may define a function tA:An-+A 
inductively as follows:
if t = x( (1 ^ i ^ n), then r^ is projection onto the rth factor;
if t = (£>txt2 •.. tm where oc(co) = m, then r^ is the composite
A.
In particular, if t is the term cox1x2.. . xM, where a(co) = n, then
tA^(OA- The function f^ is called (the interpretation in A of) the rc-ary
derived operation corresponding to the term t (in contrast to the
'primitive operations' which are the functions of the form a>A). It is
easy to see that a homomorphism f:A->B 
of Q-structures
commutes with all derived operations as well as with primitive ones.
Now let us return to the equations. If we look, for example, at the
associative law for groups, we see that each side of the equation is a
ternary derived operation (let us call the corresponding terms 5 and
t); and the assertion that the associative law holds in a group G is just
the assertion that the functions sG and tG are equal. We thus define an
n-ary equation (in an operational type Q) to be an expression (5 = t),
where s and t are elements of Fa(Xn)9 and we say an equation (s = t) is
satisfied in a structure A if sA = tA. Finally, we define an algebraic
theory to be a pair T = (Q, E) where Q is an operational type and E is
a set of equations in Q, and we define a model for T (or 7-algebra) to
be an Q-structure which satisfies all the equations in E.
Thus, for example, a group is exactly an (Q, £)-model, where
Q = \m, 1, e) as before and
E = {(^1x^X2X3 = mmx1x2x3), (mexl = x j , (mixlx1 = e)}.
[Note that, as in the third member of E above, it is not necessary for
each of the variables x1,..., 
xn to appear explicitly on each side of an
n-ary equation.]
Just as we did with operations, we may now enlarge the set E of
'primitive' equations to a larger set E of derived equations. [For
example, one proves in a first course on group theory that any Q-
structure satisfying the three equations in the particular E above also
satisfies the 'right identity' and 'right inverse' equations (mx1e = x j ,
(mXi/Xj = e).] Once again, we give an inductive definition of E:
(a) 
E^E.
(b) E is an equivalence relation on the set of terms: thus
(i) for any term t, (t = t)e£;

Universal algebra 
5
(ii) if (5 = t) e E, then (t = s)e E;
(iii) if (s = t) and (t = u) are in £, then (s = u)e£.
(c) E is closed under substitution, in two different ways:
(i) if (5 = t)eE, xt is a variable involved in s and/or t and u is any
term, then (s[w/xj = t[u/x^)eE9 where s[w/xj denotes the effect
of replacing each occurrence of xt in s by the term u;
(ii) if 5 is a term, xf a variable involved in s and (£ = u) is in E, then
(d) That's all.
[As before, this definition really means that E is the smallest subset of
the set of all expressions (s = t) which is closed under (a), (b) and (c).]
If s and t are elements of F^X) for some X, let us write s ~Et to
mean (s = t) e E; then by (b) above ~ £ is an equivalence relation, and
we can form the set F(n>E)(X) of ~ £-equivalence classes.
Theorem 
7.4. (i) F(Q>E)(X) inherits an Q-structure from FQ(X), and
it satisfies the equations in E.
(ii) F(Qt£)(X) is the free (Q,£)-model generated by X.
Proof, (i) Clause (c)(ii) of the definition of E says that the
interpretations in FQ(X) of the operations of Q respect the
equivalence relation ~ £, and hence induce operations on the
quotient set FiQE)(X). The fact that these induced operations satisfy
the equations in E follows from ((a) and) (c)(i), since every element of
F(Q,E)(X) is the equivalence class of some term.
(ii) Let E denote the set of expressions (5 = t) where s and t are
elements of FQ(X) such that h(s) = h(t) for every Q-homomorphism h
from FQ(X) to an (Q,£)-model A. Then it is easily verified that E
satisfies the closure properties (a), (b) and (c) [for (c), this requires the
observation 
that 
h(s[u/xi']) = hf(s), where W is the 
unique
homomorphism sending xt to h(u) and the other elements of X to
their images under hi]; so E^E, 
and hence every homomorphism
h: F(X) -» A factors through the quotient map Fn(X) -> F{ClE)(X). In
particular, if h = f is the unique homomorphism extending a given
map f:X -+ A (as in Theorem 1.2(ii)), we obtain a homomorphism
/:^(fi,£)W->^> which is clearly the unique homomorphism
extending /. 
•
Corollary 1.5. Let (Q, E) be an algebraic theory. Then an equation
(5 = t) belongs to E iff it is satisfied in every (Q, £)-model.

6 
Notes on logic and set theory
Proof. One direction is easy: the set of equations satisfied in a given
(Q, E)-model (and hence, the set of equations satisfied in every (Q, E)-
model) has the closure properties (a), (b) and (c), and so contains E.
Conversely, if (s = t) is satisfied in every (Q,£)-model, then it is
satisfied in F(QE)(Xn) for any n\ in particular (assuming for notational
convenience that both s and t involve exactly the variables
x 1,x 2,...,xj, we have
(where the square brackets denote ~ ^-equivalence classes). But by
definition we have
and similarly the right-hand side of (*) equals [t]; so [5] = [t], i.e.
(s = t)e£. 
D
Corollary 1.5 is our first example of a completeness theorem, i.e. a
theorem asserting (for some class of theories) that the things which
are true (i.e. are satisfied in every model of a given theory) coincide
with the things which are provable (i.e. are derivable from the
postulates of the theory - in this case, the primitive equations - by a
specified deduction process - in this case, the closure properties (b)
and (c)). Clearly, the acid test of any formal deduction-system is
whether we can prove a completeness theorem for it. The existence of
free models, as we have seen, makes the completeness theorem for
algebraic theories comparatively easy to prove; in the next two
chapters we shall prove completeness theorems in other contexts
where we have to do a good deal more work to show that every true
statement is provable.
However, even for algebraic theories not everything in the garden
is rosy. In contrast to the situation for terms, there is in general no
algorithm for determining whether or not a given equation (5 = t) is
derivable from a given theory. For some particular theories (e.g. that
of groups - see Exercise 1.6) we can find such an algorithm; but in
Chapter 4 we shall give an explicit example of an algebraic theory for
which we can prove that no such algorithm exists. The problem of
finding such an algorithm, for a given T, is called the word problem for
T. ['Word' is an old-fashioned synonym for 'term'.]
There is one case where the word problem always has a trivial

Universal algebra 
7
solution. Let Q be an operational type, and let si = {A1, A2,..., 
An}
be a finite set of finite Q-structures. Then if we define E to be the set of
all equations which are satisfied in every Ah it is clear that we already
have E = E; and so to determine whether (5 = t) is a (derived)
equation of this theory it suffices to compute sA. and tA. for each i -
which is a finite process since each At is finite.
An important example of a theory of this kind is the theory of
Boolean algebras, which may be loosely described as 'everything you
can say about a two-element set' (that is, if you confine yourself to the
language of universal algebra). There are various ways of presenting
this theory: a highly generous one uses two nullary operations T
(true) and _L (false), a unary operation ~" (not), and four binary
operations A (and), v (or), => (implies) and <=> (iff). The set 2 = {0,1}
is given a structure for this operational type by setting
T 2 = l
± 2 = 0
-•2(fl)=l-£I
A 2(a, b) = min{a, b}
v 2(a, b) = ma.x{a, b}
=>2(a, b) = 0 iff a = 1 and b = 0
o2(a9b)=liffa 
= b.
We then define a Boolean algebra to be an (Q, £)-model; where Q is as
above and E is the set of all equations satisfied in 2. [Note: henceforth
we shall generally revert to the more familiar 'algebraic' way of
writing binary operations :(x A y) instead of A xy, etc.] Of course, the
above presentation is highly inefficient, because E contains a good
many equations which tell us that some of the seven primitive
operations are definable in terms of the others. For example, it is easy
to verify that E contains
and 
((x oy) = ((x =>y) A(y=> x))),
so that every Q-term is ~ £-equivalent to one involving only the

8 
Notes on logic and set theory
primitive operations J_ and =>. Henceforth, we shall regard _L and =>
as the only primitive operations in the theory of Boolean algebras,
and regard the above equations as defining T, ~\ v, A and o as
(shorthand for) certain derived operations. There are many other
ways of reducing the number of primitive operations; this one has the
(small) merit that it gets the number down to the least possible (see
Exercise 1.10).
This reduction has not exhausted all the equations in E; there are
still others that we need to consider. We note, however, that (s = t)
belongs to E iff ((s<=>t)= T) does; therefore we can restrict our
attention to equations of the form (t = T). We say a term Ms a
tautology if (t = T) is in E (equivalently, if t2 is the constant function
2" -• 2 with value 1, where n is the number of variables in t). It is easy
to verify that the following are tautologies:
(a) (*=>()/=>*)),
(b) ((x => (y => z)) => ((x => y) => (x => z))),
(c) (((x=>±)=>±)=>x).
(c) looks more familiar if we write it as ("• n x => x); but we wanted to
emphasize that => and 1 are now our only primitive operations. We
shall be meeting these three tautologies quite frequently in future.
Exercises
1.1. 
Let Q = {t,b,u,c} 
with <x(f) = 3, <x(b) = 2, <x(u)= 1, <x(c) = 0, and let
x, y, z be variables. Which of the following are Q-terms?
(i) ttxbucyzzz 
(ii) xubytcz 
(iii) tcucbucc
(iv) bbbxbybyybxbzbyyy 
(v) bxytczuz 
(vi) tbxxxxx.
1.2. 
Show that the following definition of the derived operation induced by
a term is equivalent to the one given in the text:
'If teFa(Xn) 
and al9... ,an are elements of an Q-structure A, then
tA(al9.. .,#„) = f(t), 
where /:Fa(Xn) -• A is the unique homo-
morphism extending the map f:Xn-+ 
A with f(xt) = at (1 ^ i ^ n).'
1.3. 
Let s, t and u be Q-terms (for some fixed Q), and let xt and x, be distinct
variables. We write s[t,u/xi9xj] 
for the term obtained from s on
simultaneously replacing each occurrence of x, by t and each
occurrence of Xj by u. Show that s[t, u/xi9 x j is not in general the same
as s[t/xl}[u/xj]9 but that it is the same as 
s[t[xn/xj]/xi][u/Xj'][xJ/xn]9

Universal algebra 
9
provided n is chosen so large that xn does not occur anywhere in s, t or
u. Hence show that if (5 = s'), (t — f) and (u = u') are all derived
equations of some theory (Q, £), so is (s[t, u/xi9 xj = s'[t\ u'/xi9 xj).
1.4. 
Let T be an algebraic theory. Show that the one-element set {0} has a
unique T-model structure, and that the empty set has a T-model
structure iff T contains no nullary operations.
1.5. Let Q = {m, i, e] with a(m) = 2, a(i) = a(e) = 1, and let E consist of the
four 
equations 
(mxmyz = mmxyz), 
(ex — ey), 
(mexx = x) 
and
(mixx = ex). Show that every group is an (Q,£)-model in a natural
way. Is the converse true?
1.6. 
Let Q be the operational type of groups. We say that an Q-term is
reduced if it is either the single symbol e or of the form mm ... mw,
where w is a string of symbols involving only variables and the
operation 1, and not including any substring of the form ii, ixx or xix
(except as part of a substring ixix).
(i) Describe an algorithm which, given an arbitrary Q-term t,
produces a reduced term tfor which (t = t) is a derived equation of
the theory of groups.
(ii) Show that the set of all reduced terms in a given set X of variables
can be made into a group RX containing X as a subset. By considering
the induced homomorphism FX -* RX, where FX is the free group
generated by X (defined as in Theorem 1.4), show that if s and t are
reduced terms for which (5 = t) is a derived equation, then s and t are
identical.
(hi) Use (i) and (ii) to solve the word problem for groups.
[Feel free to use everything you know about group theory in
answering this question.]
1.7. 
(i) Let T be an algebraic theory, and suppose T contains a ternary
(possibly derived) operation p for which
(pxyy = x) and
are (possibly derived) equations of T. Let A be a T-model, and let R be
a sub-T-model of Ax A which contains {(a, a) | a eA) (i.e., considered
as a binary relation on A, R is reflexive). Show that R is also symmetric
and transitive.
(ii) Conversely, if T is an algebraic theory such that every reflexive
submodel of the square of a T-model is also symmetric, show that T
contains a ternary operation satisfying (*). [Hint: let F be the free T-
model generated by {x, y}9 and consider the sub-T-model of F x F
generated by {(x, x), (x, y), (y, y)}.]

10 
Notes on logic and set theory
(iii) Give an example of an operation p satisfying (*) when T is the
theory of groups, but show that there is no such operation in the theory
of semigroups (i.e. the theory obtained from that of groups by deleting
the operation i and the equation in which i occurs).
1.8. 
(i) Let Q = {e, m} with a(e) = 0, a(m) = 2, and let E consist of the two
equations (mex = x) and (mxe = x). Suppose a set A has two (Q, E)-
model structures (el9m1) and (e2,m2) such that the operations of the
second structure are Q-homomorphisms 1 -• A and A x A -> A for the
first structure. Show that A satisfies the equations (ex = e2) and
(m1m2xzm2yt = m2m1xym1zt), and deduce that ml — m2 and that mx is
commutative and associative.
(ii) Ask an algebraic topologist to explain what this has to do with the
result that the fundamental group of a topological group is abelian.
1.9. 
Let 2 = {0,1} with its usual Boolean algebra structure, and let n be a
natural number. Show that every function 2" -• 2 is (the interpretation
of) an n-ary derived operation of the theory of Boolean algebras.
[Hint: use induction on n.] Deduce that the free Boolean algebra on n
generators has 22" elements.
1.10. Let B be the theory of Boolean algebras, and let j be the (derived)
binary operation of B defined by
(xiy)=^(x Ay).
Show that the subtheory Bo of B generated by j (i.e. the set of all
operations derivable from j) contains all of B except the two constants.
Show also that no single operation can generate the whole of B; and
that B cannot be generated by either A or v plus one other operation.

Propositional calculus
The names which we gave to the operations of the theory of Boolean
algebras, at the end of the last chapter, indicated that we were
thinking of the variables to which they were applied as 'propositions'
to be combined and manipulated according to rules of logic. In this
chapter we make that idea more explicit; one symptom of this is that
we shall change our notation and terminology slightly. We shall use
the letters p, q, r rather than x, y9 z to denote variables, and call them
primitive propositions; by a compound proposition we shall mean a
{1, =>}-term in some set P of primitive propositions (or else the
element of the free Boolean algebra FP which it represents). We shall
refer to the elements 0,1 of the fundamental Boolean algebra as truth-
values; by a valuation of P, we mean a function v:P -* 2 (which of
course corresponds to a Boolean homomorphism v:FP -+ 2).
The notion of tautology, which we introduced in the previous
chapter, is a special case of that of semantic entailment. If S is a set of
propositions and t a single proposition, we say that S semantically
entails t (and write S \= t) if, for every valuation v (of the primitive
propositions involved in S u {t}) such that v(s) = 1 for all 5 6 5, we
also have v(t) — 1; i.e. '£ is true whenever S is'. Clearly, t is a tautology
iff 0|=r, which we abbreviate to |= t.
An important example of a semantic entailment is
Note that if S f=£ is a semantic entailment, then so is any substitution
instance of it, i.e. anything obtained by substituting terms for the
primitive propositions appearing in 5u{f}. Thus for example
{p» (P => (q. => P))} H# ^ ^) *s a s e m a n t i c entailment. Note also that if

12 
Notes on logic and set theory
Su{s}|=f and s is a tautology, then S\=t, since the presence of 5
amongst the premisses of the entailment does not affect anything.
The last few remarks represent the beginning of a notion of proof
for propositions, i.e. of the idea that all valid semantic entailments
should be obtainable by a deductive process from certain basic
ones. We now set up a formal system of proofs. We begin by adopt-
ing as axioms all substitution instances of the three propositions
(a) (p=>(q=>p))
(b) 
((p=>(q^r))=>((p=>q)^(p=>r)))
(c) P^p^p)
which we observed to be tautologies at the end of the last chapter.
And we have one rule of inference, which is known by the Latin name
modus ponens: from p and (p => q), we may infer q. (Again, we allow
substitution instances of this rule.)
We now define the relation of syntactic entailment inductively: we
say a set S (whose members we shall call premisses of the entailment)
syntactically entails a proposition t (written S (-1) if
(i) t is an axiom,
(ii) te 5, or
(iii) for some s, we have S \-s and S \- (s => t).
In conjunction with this definition, it is convenient to introduce the
notion of a deduction from S: a deduction of t from S is a finite
sequence of propositions such that each member of the sequence is
either an axiom or a member of S or is obtained via modus ponens
from two earlier members of the sequence, and the last member of the
sequence is t. Clearly, S f-1 iff there exists a deduction of t from 5. A
deduction from the empty set of premisses is also called a proof; if
0 \-1 (which we abbreviate to f-1) we say t is a theorem (of the
propositional calculus).
To illustrate the notion of deduction, we give two examples.
Example 2.1. The following is a proof of the theorem (p =>p):
(P => ((P => P) => P)) 
(instance of (a))
((?=* ((P=> P)=> P))=> ((p=> (P=> P))=> (/?=> P)))
(instance of (b))
((P => (P => P)) =>(p=> P)) 
(modus ponens)

Propositional calculus 
13
(P => (P => P)) 
(instance of (a))
(P => P) 
(modus ponens).
Example 
2.2. We deduce (p => r) from {(p => q), (q => r)} :
(q => r) 
(premiss)
((q =>r)=>(p=>(q=> r))) 
(instance of (a))
(p => (q => r)) 
(modus ponens)
((P =>(<!=> r)) => ((P => <?) => (P => **))) 
(instance of (b))
((P^ #)=* (P=* r)) 
(modus ponens)
(p => q) 
(premiss)
(p => r) 
(modus ponens).
We now embark on the proof of the Completeness Theorem for the
Propositional Calculus, which in the notation we have developed is
the assertion that the relations |- and \= coincide. In one direction, the
implication is straightforward:
Proposition 
2.3 (the Soundness Theorem). If S\-t, 
then S|=f; in
particular, every theorem is a tautology.
Proof 
We have to show that the set {f|Sf=f} satisfies the closure
conditions in the definition of f-. It certainly contains the axioms,
since they are tautologies; and it trivially contains the members of 5.
Finally, if S\=s and S|=(s=>0> then since {s, (s=>f)}(=r 
w e 
^ a v e
Sf=f. 
•
For the converse direction, an important tool is the following:
Theorem 
2.4 (the Deduction Theorem). S (- (5 => t) iff S u {s} \-1.
Proof 
If S \- (s => t), we may obtain a deduction of t from S u {5} by
writing down a deduction of (5 => t) from S and adding on the two
propositions 5 (premiss) and t (modus ponens). Conversely, let
(tl912, 
...,r H = r ) b e a deduction from S u {s}. We shall show by
induction on i that S f- (s => t() for each i.
If tt is an axiom, or a member of S, we write down the deduction
t{ 
(axiom or premiss)
(tt => (5 => tt)) 
(instance of (a))
(s => tt) 
(modus ponens).

14 
Notes on logic and set theory
If tt is s itself, we write down the proof of (5 => s) given in Example 2.1.
There remains the case when we have j , k < i such that tk is (tj => tt). In
this case, by inductive hypothesis, we have deductions of (s => tj) and
of (5 => (tj => t()) from S. So we write both of these down, and then add
((s =* (tj => f.)) => ((s => tj) => (5 => *,))) (instance of (b))
((5 => tj) =>(s=> tt)) 
(modus ponens)
(s => tt) 
(modus ponens). 
•
The Deduction Theorem tells us that the abstract symbol =>
really does behave like implication in formal proofs. We can often
use it 
to 
simplify 
derivations: for 
example, to 
establish
{(P => <?)> (<Z => r)} h (P => r)> instead of writing down the deduction in
Example 2.2, it suffices to show {(p => q), (q => r), p} (- r. And for this
we have only to write down the three premisses and apply modus
ponens twice.
The Deduction Theorem also allows us to reduce the general
Completeness Theorem to a particular case, sometimes known as the
Adequacy Theorem. We say that a set S of propositions is inconsistent
ifS\~l.
Lemma 2.5 (the Adequacy 
Theorem). If Sf=l, 
then 
S is
inconsistent.
Note that 'Sf= J_' simply means that there is no valuation of the
primitive propositions involved in S for which every member of S has
truth-value 1. Before giving the proof of Lemma 2.5, we use it to
obtain
Theorem 2.6 (the Completeness Theorem). S^t iff S\-t.
Proof. One direction is Proposition 2.3. Conversely, suppose Sf=t.
Then since {*, ""•*} j= 1, we clearly have S u {~"t} |= 1. By Lemma 2.5,
we have Sv{^t}[-±. 
By Theorem 2.4, we have S j - C ^ ^ l ) , i.e.
51_ ~i —11 g u t w e m a y t ak e a deduction of 
' 't from 5, and adjoin
(~]~nt=>t) 
(instance of (c))
t 
(modus ponens)
to obtain a deduction of t from 5. 
•
Note that the above argument is the only place so far where we
have made use of axiom (c).

Propositional calculus 
15
Proof of Lemma 2.5. We shall give the proof only in the case when
the set P of primitive propositions (and hence also the set of
compound propositions) is countable; the general case is similar, but
requires the technical machinery of Zorn's Lemma (see Exercise 2.5,
and also Chapter 7 below).
Suppose S is consistent. Then we have to show that there is a
valuation v of P with v(t) = 1 for all teS. Our technique for doing this
will be to enlarge S as much as possible while keeping it consistent.
Note first that, for any t9 either S u {t} or S u {~^t} is consistent; for if
S u {t} is inconsistent, then by the Deduction Theorem we have
S\- "^r, and so 5 u {~lr} has the same syntactic consequences as S
itself.
We now enumerate the compound propositions, and go through
them one by one: at each stage, if we can consistently adjoin the
proposition under consideration to the set we have accumulated so
far we do so, and otherwise we add its negation. At the end of this
process, we have a set S' 3 S which is consistent (since a deduction of
± from it would involve only finitely many of its members, and so
would imply the inconsistency of the set constructed after finitely
many steps) and such that, for every t9 at least one of t and ~~*t (in fact
exactly one, because {r, ~"t} is inconsistent) belongs to S'.
We now define a function v by v(t) = 1 if te S", v(t) = 0 otherwise.
We claim that v is a {±, =>}-homomorphism, and hence is the unique
homomorphism extending its restriction to the set of primitive
propositions; this will clearly suffice to prove the Lemma, since
v(t) = 1 for all teS. Clearly v(±) = 0, since 1 cannot belong to any
consistent set. To show that v(s =>t) = (v(s) =>2 v(t))9 we shall consider
three cases:
(i) v(t)=l, 
i.e. teS'. Then we cannot have " H s ^ ^ e S ' , since
t \- (s => t) and S' is consistent. So (s => t) eS\ i.e. v(s => t) = 1 =
(ii) v(s) = 0. In this case we have ~~<s e S', and since ~~*s \- (s => t) (see
Exercise 2.2), we deduce as in (i) that we must have v(s =>t) =
(iii) v(s) = 1, v(t) = 0. In this case we have seS' and t$S', so since
{s, (s=>t)}\-t we must have (s=>t)$Sf. Hence v(s=>t) = 0 =
D

16 
Notes on logic and set theory
We conclude this chapter by mentioning two applications of the
Completeness Theorem. Each of them takes a property which is
obvious for one of the relations |-, f=, and applies it to the other one.
Corollary 2.7 (the Compactness Theorem). If S j= t9 then there is a
finite subset S' c S such that S' f= t.
Proof. This is obvious for j-, since a deduction of t from S can only
involve finitely many of the premisses. 
•
The name 'Compactness Theorem' is more than a fanciful analogy;
this result really is tantamount to the assertion that a certain
topological space is compact (see Exercise 2.6).
Corollary 2.8 (the Decidability Theorem). There is an algorithm
which, given a finite set S of propositions and a proposition t,
determines whether or not S\-t.
Proof. To determine whether or not S f= t, we have only to compute
the truth-values of the members of S and of t for each of the 2n
valuations of the primitive propositions involved in S u {t} (where n
is the number of such propositions). 
•
Observe that even without the Completeness Theorem it would be
easy to construct an algorithm which, given 5, would enumerate all
possible syntactic consequences of S; but if S]f-t9 there is no way in
which such an algorithm could produce this information in a finite
time.
Exercises
2.1. Which of the following expressions are tautologies?
(i) 
(«P=>«)=>P)=>P)
(ii) {((pvq)A ~"p)^>q)
(iii) {p^(~"pvq))
(iv) (((pA -ig)=>r)=>4)
(v) (((p => q) A (r => s)) => ((p A r) => (q v 5)))
(vi) (((P => q) v (r =* 5)) => ((p A r) => (q v 5))).
2.2. Write down a proof of (± =>q) in the propositional calculus. Hence
obtain a proof of (~"p => (p => #)).

Propositional calculus 
17
2.3. Use the Deduction Theorem to show that the converse of axiom (c) (i.e.
the proposition (p => ~"""») is a theorem of the propositional calculus.
2.4. (For masochists only.) Write down a deduction of (p A q) (i.e. of
((p => (g => ±)) => 1)) from {p,q}. [Hint: first write down a deduction of
J_ from {p, q, (p=>(q=> -L))}, and then use the method described in the
proof of the Deduction Theorem to convert it into the required
deduction.]
2.5. (This question is intended for those who already have some
acquaintance with Zorn's Lemma.) Let T be the set of all compound
propositions in a (not necessarily countable) set P of primitive
propositions.
(i) If {Ct | iel} is a family of consistent subsets of T which is totally
ordered by inclusion (i.e. for each Ujel 
we have either C^Cj 
or
Cj c Ct), prove that {JieI C{ is consistent.
(ii) Using Zorn's Lemma, deduce that each consistent subset of T is
contained in a maximal consistent subset.
(iii) If M is a maximal consistent subset of T, show that for each t e T we
have either teM or """teM.
(iv) Prove Lemma 2.5 without the assumption that the set P of primitive
propositions is countable.
2.6. Let P and T be as in the last question, and let V be the set of all
valuations of P. For each t e T, define
(i) Show that U^) n U(t2) = U(tl A t2), and deduce that {U(t) 
\teT}
is a base for a topology on V.
(ii) If S is a subset of T, show that 5 f= 1 iff {U( ~" r) 11 e S} covers V.
(iii) Deduce that the Compactness Theorem (2.7) is equivalent to the
assertion that the space V is compact.

First-order theories
So far, we have considered equational logic (where we could
formulate assertions (equations) about the mathematical structures
we were discussing, but didn't have any way of combining them) and
propositional logic (where we studied logical combinations of
assertions, but didn't attach any intrinsic meaning to the primitive
propositions which were being combined). The obvious next step is to
put these two ideas together. Actually, we shall miss out the next step
in a traditional development of logic, the study of the first-order
predicate calculus, and pass straight on to the predicate calculus with
equality; predicate calculus without equality is generally similar but
less interesting.
We wish to define a notion of formal language which will be
adequate for handling a wide variety of mathematical structures. In
addition to the features we have met so far (primitive operations,
equations between terms, propositional connectives), there will be
two new ones: primitive predicates and first-order quantifiers. An
(w-ary) primitive predicate (0, say) is something whose intended
interpretation in a structure A is a subset of An\ thus if ax,..., 
an are
elements of A, <f)(al9... ,an) will be the assertion that the n-tuple
(al9... 
,an) belongs to the subset which interprets </>. A quantifier is a
unary operation on assertions of the type represented by the English
phrases 'for all x ...' or 'there exists x such that...'; the qualification
'first-order' means that the 'x' being quantified is understood to
range over elements of the structure A (rather than, for example,
arbitrary subsets of A).
Our language j£? will be specified by two things: an operational type
(Q, a), which means exactly what it did in Chapter 1, and a predicate

First-order theories 
19
type (Il,a), whose formal definition is the same as that of an
operational type but whose intended interpretation is as a set of
predicates with specified arities. The language itself then consists of
the following things:
(1) Variables x1,x2,x3,... 
[We assume we are given a countably
infinite supply of these; of course, at any moment we shall use
only a finite number of them, but it is important that the supply
should never be exhausted.]
(2) Terms which are defined inductively, as in Chapter 1, by the
following:
(a) Every variable is a term.
(b) If co G Q, oc(a>) — n and t1,..., tn are terms, then cot1 ... tn is a
term.
(c) That's all.
(3) Atomic formulae which are of two kinds:
(a) If 5 and t are terms, then (s = t) is an atomic formula.
(b) If (f)eII, 
(x((/)) = n and tl9t29... 
,tn 
are terms, then
(t>(tut2,..., 
tn) is an atomic formula.
[Note: part (a) of this definition essentially says that = is a
primitive predicate of arity 2. The reason why we keep it
separate from the predicates in FI is that its intended
interpretation in any structure A is fixed as the diagonal subset
of A x A, whereas the interpretations of members of II can be
specified arbitrarily.]
(4) Formulae which are defined by a further induction:
(a) Atomic formulae are formulae.
(b) ± is a formula; and if p and q are formulae so is (p => q). [As
previously, we introduce T, ""•/?, (p v q), (p A q) and {poq) 
as
abbreviations for certain compound formulae.]
(c) If p is a formula and x is a variable which occurs free in p (see
below), then (Vx)/> is a formula. [We similarly introduce (3x)p as
an abbreviation for the formula """(Vx)"1/?.]
(d) That's all.
To explain clause 4(c) above, we need to introduce the notion of
free and bound occurrences of variables in a formula. Informally, any
occurrence of a variable in a formula in which V does not appear is
free; and in (Vx)/? the quantifier 'binds' all those occurrences of x in p

20 
Notes on logic and set theory
which were not previously bound. Formally, we define FV(p), the set
of free variables in a term or formula p, by induction:
FV(x) = {x}
FVM1r2...g = U?=
FV(s = t) = FV(s) u FV(f)
FV(^l5t2,...,O)=U?
FV(1) = 0
Note that it is quite possible for the same variable to appear both free
and bound in different parts of a compound formula; but in practice it
is usually sensible to choose one's variables so that this doesn't
happen.
The intended interpretation of all this is as follows. If if = (Q, II) is
a language, an ^-structure 
is a set A equipped with a function
coA:Aa{a)^A 
for each coeQ, and a subset [(j>]A^Aa{<l>) for each
(j)ell. We may then interpret each term t of <£ with FV(t)c
{xl9x2,. 
• • >xn} as a function tA(n):An -• A, just as we did in Chapter
1; and each formula p with FV(p)£.{x l 9... 9x n} is interpreted as a
subset [p]A(n) c A" (or equivalently as a function pA(n):An ->2,
namely the characteristic function of [ p ] ^ ) ) by the following
inductive definition (in which we suppress the suffix (n) wherever
possible):
(5 = t)A is the composite
An 
> A2 
• 2,
where d(a, b) = 1 if a = b, and 0 otherwise (equivalently,
[(5 = ij]A = {{au. 
..9an)\ 
sA(au... 
,an) = U ^ i , • • • ,«„)}).
<t>{tu...,tm)A 
is similarly
^4" 
• Am 
• 
2 ,
where $A is the characteristic function of \_4>\A>
±A is the constant function with value 0.
(p=>q)A is the composite
• 2 2 
• 2 .

First-order theories 
21
[(Vxn + i)pL(n)is the set
{(au... 
,aj|for all an+1 eA9 (al9.. .,an,an 
+ 1)e[jp]A(n + 1)}.
We say a formula p is satisfied in a structure A (and write A\=p) ifpA
is the constant function with value 1 (equivalently, \_p\A is the whole
of An). [Note: here as elsewhere, when we don't specify the arity of pA,
we think of it as being precisely the number of free variables of p -
though in this case it doesn't make a lot of difference.] Note that A\=p
iff A f=p, where p is the universal closure of p, i.e. the formula obtained
by prefixing p with universal quantifiers for each of the free variables
of p (in any order). A formula with no free variables is called a
sentence.
By a first-order theory T in a language jSf, we mean a set of
sentences of if (called axioms of the theory); an if-structure A is a
model for T (written A (= T) if 4 |=p for each /? e 7. At this point we
clearly need some examples to illuminate all the above definitions!
Example 3.1. We can regard any algebraic theory (Q, E) as a first-
order theory (without changing the meanings of the words 'structure'
and 'model'): just take a language if in which II is empty, and replace
each equation in E by its universal closure.
Example 3.2. We can also express more complicated concepts by
means of first-order axioms. The theory of commutative rings with 1
is algebraic, but that of fields is not (e.g. because the 1-element ring is
not a field: cf. Exercise 1.4); but we can express the theory of fields by
adding the first-order axioms
-(0=1)
and (Vx)p(x = 0) =>(3y)(x 
.y=l))
to those of the theory of commutative rings with 1.
Example 3.3. A propositional language is one in which Q is empty,
and all the predicates in II have arity 0; a propositional theory is a set
of axioms not involving equality (i.e. containing no subformula of the
form (5 = t)) in a propositional language. If we think of the elements
of II as primitive propositions, then (forgetting about the underlying
set, which is irrelevant in this context) a structure for a propositional
language is just a valuation of these propositions as considered in

22 
Notes on logic and set theory
Chapter 2, and a model for a theory T is a valuation which assigns
truth-value 1 to all the propositions in T. Thus the notion of a model
for a first-order theory includes one which was fundamental in the
last chapter; and we shall see before long that the main theorems
of the last chapter 
(completeness, compactness, etc.) have
generalizations to this new context.
Example 3.4. As an example of a non-propositional theory
expressed using primitive predicates rather than operations, we give
the theory of projective planes. By a projective plane we mean a
system of lines' and 'points' such that there is a unique line through
any two points, and any two lines meet in a unique point. We express
this by taking as primitive two unary predicates n ('is a point') and k
('is a line') and a binary predicate e ('lies on'), with axioms
(VX)(TC(X) v
Q/x,y)(e(x9y)=>{n(x)AX(y)))
(Vx, y)((n(x) A n(y) A "»(X = y)) => (3! z)(e(x, z) A e(y9 z)))
and (Vx, y)((A.(x) A k{y) A ->(X = y)) => (3! z)(e(z, x) A e(z,y))),
where in the last two axioms we have introduced the abbreviation
(3! z)p(x, y, z) for (3z)(p(x, y9 z) A (Vf)(p(x, y, t) => (t = z))).
In fact (see Exercise 3.5) it is always possible to replace a given first-
order theory by an 'equivalent' theory expressed in a language which
has no primitive operations, only primitive predicates; and many
accounts of first-order logic confine themselves to this case. (An
intermediate position, adopted by some authors, is to allow primitive
constants but not primitive operations of arity >0.) However, this
restriction doesn't make life all that much easier, and it doesn't
accord very well with mathematical practice - when we study groups
or rings, it is surely natural to think of their structure in terms of
operations rather than predicates.
[Note for fusspots. 
The operation of substituting one variable for
another, which we used implicitly in Example 3.4 when we defined the
unique existential quantifier (3! z), is actually more complicated than
it seems, because of the distinction between free and bound variables,
and the danger that a variable substituted into a formula might
accidentally get bound. Formally, if p is a formula, t a term and x a

First-order theories 
23
variable, we define p[t/x] ('p with t for x') to be the formula obtained
from p on replacing each free occurrence of x by r, provided no free
variable of t occurs bound in p; if it does, we must first replace each
bound occurrence of such a variable by a bound occurrence of some
new variable which didn't occur previously in either p or t. Of
course, common sense is a much better guide than following rules
such as the above when making substitutions.]
We now define the notion of semantic entailment for the predicate
calculus, which is easily seen (using Example 3.3) to generalize that
for the propositional calculus. If T is a set of sentences in a given first-
order language and p is a sentence, we write T \=-p to mean that every
model for T satisfies p. For formulae with free variables the notion of
semantic entailment is less simple, because the free variables have to
be assigned particular values in the structures under consideration;
the easiest way to do this is to enrich our language if to a language
<£' by adding new constants corresponding to the free variables in
T u {p}, and then to say that T (=p iff V j=p', where p' is the sentence
of $£' obtained on replacing the free variables of p by the
corresponding constants (and similarly for T').
Our next task is to develop a notion of proof for the predicate
calculus with equality, and prove a completeness theorem saying that
the corresponding notion of syntactic entailment coincides with
semantic entailment as just defined. The overall strategy of the proof
of the Completeness Theorem, and many of the details, are very
similar to the propositional case, which we covered in the last
chapter; so we shall give the proof here in slightly sketchy form,
concentrating on the points where new ideas and difficulties arise.
Our deduction-system is, as before, defined by means of axioms
and rules of inference. In addition to the three axioms we had in the
propositional case, we shall require two new axioms to handle
quantifiers, and two to handle equality; we shall also need one new
rule of inference, the rule of generalization. Our complete list of
axioms is
(a) (p=>(q=>p))
(b) 
({p^{q=>r))^{(p=>q)^{p^r)))
(c) 
p-^p)
(here p, q, r may be any formulae of <£)

24 
Notes on logic and set theory
(d)
(here p is any formula with xeFV(p), t any term whose free
variables don't occur bound in p)
(e) 
((Vx)(p=>q)=>(p^(\/x)q))
(p, q formulae, x $ FY(p))
(f) (Vx)(x = x)
(g) (Vx,y)((x = y)^(p=>p[y/x]))
(p any formula with xeFV(p), y not bound in p).
It is straightforward to verify that each of these axioms is a tautology,
i.e. is satisfied in any j£?-structure. Our rules of inference are
(MP) from p and (p => q), we may infer q, provided either q has
a free variable or p is a sentence, and
(Gen) from p we may infer (Vx)p, provided x does not occur free
in any premiss which has been used in the proof of p.
[The reason for the proviso about free variables in (MP) is the
possibility that, if our language <£ has no constants, the underlying
set of an if-structure might be empty: if p has a free variable, then p
and (p => q) will automatically be satisfied in the empty structure,
even if q is the sentence _L. A more traditional way of avoiding this
difficulty is to demand that the underlying set of any structure should
be nonempty; once again, we have rejected this approach because it
doesn't accord well with mathematical practice.]
With the above provisos about free variables, it is easy to verify
that if 5 is a set of formulae and we have S (=p and S )= (p => q), then
S\=q; and similarly for the rule of generalization. An easy induction
then completes the proof of
Proposition 
3.5 (the Soundness Theorem). If S\-p, then S\=p.
•
Theorem 3.6 (the Deduction Theorem). Suppose either that q has
a free variable or that p is a sentence; then Su{p}\-q 
iff
S\-(p=>q).
Proof. Most of this proof can simply be copied from that of Theorem
2.4; but for the left-to-right implication we have one further case to
deal with, namely when q = (Vx) r is obtained from r by an application
of (Gen). In this case our inductive hypothesis yields S f- (p => r), from

First-order theories 
25
which we obtain S \- (Vx)(p => r) by (Gen), and then axiom (e) plus
(MP) is exactly what we need to obtain S\-(p=>(ix)r) - unless x
occurs free in p, in which case p can't have been used in the deduction
of r and so we actually have S \- q (from which 5 f- (p => q) follows by
standard methods). 
•
Theorem 3.7 (the Completeness Theorem). S\-p iff Sj=p.
Proof. One direction is Proposition 3.5. For the converse, we may
immediately reduce to the case when S u {p} is a set of sentences; for,
if Sf-p, then it is easy to see that (in the notation introduced when
defining |=) S'\-p\ by substituting constants for free variables in a
deduction of p from S. Then, as in Chapter 2, the Deduction Theorem
allows us to reduce further to the case p = _L; that is, we are reduced
to showing that if a first-order theory S is consistent (i.e. S ^- ±) then it
has a model.
As in Chapter 2, we shall do this by enlarging 5 to a consistent
theory which is maximal in a suitable sense - only this time we shall
have to enlarge the language as well as the set of sentences. In order to
avoid complications with Zorn's Lemma, we shall again restrict
ourselves to the case when the original language $£ is countable (i.e.
when Q u IT is countable - an easy induction then shows that the set
of all formulae of S£ is countable).
We say that a theory S (in a given language <£) is complete if, for
every sentence p of if, we have either S \-p or S \- ~^p. We say S has
witnesses if, whenever S\-(3x)p (with FV(p) = {x}), there is a closed
term t of if (i.e. a term with no free variables, for example a constant)
such that S \-p[t/x], (The term t is called a witness to the provability
of (3x)p.) We aim to show that any consistent theory S can be
extended to a consistent theory 5* (in some extension if* of if)
which is complete and has witnesses; clearly it will then suffice to
construct a model of 5*, since any such will define a model of S by
restriction.
The extension of 5 to a complete consistent theory can be done
without change of language; in fact we did it in the proof of Lemma
2.5. Now suppose S \- (3x)p, where FV(p) = {x}; let <£' be S£ plus one
new constant c, and S' = Su{p[c/x]}. Suppose Sf \-±; then by the
Deduction Theorem we have 5|- ~lp[c/x]. But since the constant c
does not appear anywhere in S, we may replace it by x throughout

26 
Notes on logic and set theory
this deduction to obtain iS |— '/?; and then by (Gen) we obtain
Sj-fVx)"1/?. But by hypothesis we have S\-(3x)p, i.e. Sf- ~-|(Vx)""1p;
so 5 is inconsistent. The above argument shows that, given a
consistent theory S, we may consistently adjoin a witness for a single
sentence of the form (3x)p; hence we may consistently adjoin
witnesses for all such sentences of <£ which are deducible from S.
Unfortunately, the two processes of completion and of adjoining
witnesses tend to pull in opposite directions: when we complete a
theory, we add lots of new deducible sentences of the form (3x)p, for
which we may not have witnesses, and when we add witnesses we
create lots of new sentences which may be neither provable nor
refutable. So we have to do both processes repeatedly, as follows.
Starting from our theory S = So in a language S£ = J?o, we define a
sequence of pairs (J^,5n) inductively: if n is even, we put £?n + 1 = S£n
and let Sn + x be a completion of SM, and if n is odd we let {S£n+x, Sn + x)
be the result of adjoining witnesses for each sentence of the form (3x)p
deducible from Sn. (Note that there are only countably many such
sentences, so our language remains countable at every stage.) Finally,
we define ¥* = (J*°°=o^, and 5* = (J^o 5*; then S* is consistent,
since a deduction of _L from it would involve only finitely many of its
members and so would imply the inconsistency of some Sn, and
similar arguments show that S* is complete and has witnesses.
To complete the proof of Theorem 3.7, we have to show that if a
consistent theory is complete and has witnesses, then it has a model.
Let S be such a theory; let C be the set of closed terms of its language,
and let A be the quotient of C by the relation ~ , where
(It follows from axioms (f) and (g) that ~ is an equivalence relation
on C; cf. Exercise 3.6.) We make A into an J&f-structure by defining
<M|>i], • • •, OJ) = [ph ... rj 
for coeQ9 CL(CD) = n
and
<M>i], • • •, W ) = 1 iff S\-<l>(tl9... , 0 
for ct>ell9 *(<t>) = n
(here square brackets denote ~-equivalence classes; it is again easy
to verify that these definitions are independent of the choice of
representatives). Now a straightforward induction over the structure
of p shows that, for any formula p of Z£ (with FV(p) — {xl9... 
,xn},

First-order theories 
27
say), we have
PA(UI], • • • > W ) = 1 iff S|»p[r l f..., tjxl9... 
, x j .
(The hypotheses that S is complete and has witnesses are both used in
proving the left-to-right implication in the case when p has the form
(Vxn + 1)q.) In particular, if p e S, then since S \- p we have A\=p; i.e. A is
a model for S. 
•
Corollary 3.8 (the Compactness Theorem). If S is a set of sentences
such that every finite subset of S has a model, then 5 has a
model.
Proo/. As in the proof of Corollary 2.7, this is trivial if we replace the
words 'has a model' by 'is consistent'. 
•
However, we do not have an analogue of Corollary 2.8 for
predicate logic; there is in general no algorithm for determining
whether or not a given sentence p is deducible from a set of sentences
S. (If there were, we could in particular solve the word problem for
any algebraic theory.)
While Theorem 3.7 and Corollary 3.8 may seem to represent a
highly desirable state of affairs, they are also indications of the
limitations of first-order logic. For example, we have the following
easy consequence of 3.8:
Proposition 
3.9 (the Upward Lowenheim-Skolem Theorem). If a
first-order theory T has an infinite model (i.e. one whose
underlying set is infinite), then it has models of arbitrarily
large cardinality.
Proof. Let T be a theory (in a language if, say) with an infinite model
A, and let / be an arbitrary set. We wish to construct a model A' of T
whose cardinality is at least that of/. To do this, we define S£' to be <£
plus a new family (ct \iel) of constants, and T' to be T plus the new
axioms 
'(c£ = Cj) for each / # 7 in /. Now any finite subset of T' has a
model, since it will mention only finitely many of the ct and we can
find distinct values for these in our T-model A. So T' has a model; but
any such is just a model A' of T together with an injection / -• A'. 
•
There is also a 'downward' Lowenheim-Skolem theorem, which
we shall merely state without detailed proof (and only in the special
case of countable languages).

28 
Notes on logic and set theory
Proposition 
3.10 
(the Downward Lowenheim-Skolem Theorem).
If a first-order theory T in a countable language has an infinite
model, then it has a countably infinite model. More
specifically, if A is any model of T, and B any countable subset
of A, then there is a countable submodel of A containing B.
The concept of submodel hasn't been defined, but it is easy to see
what it must be. To understand the idea behind the proof of
Proposition 3.10, think of what it says when T is the theory of groups:
it is then (essentially) the assertion that the subgroup of a group A
generated by a countable subset B is countable. The proof in general
is quite similar to what we would do to prove this, namely start from
B and go on adjoining elements of A whenever forced to do so by T
until the process terminates - and then show that we haven't gone
outside the realm of countable sets. (The major extra complication in
the general case is that we may have to make arbitrary choices: for
example, if T contains a sentence of the form (Vx)(3y)p and beB,
there may be uncountably many a e A for which (b, a) € \_p] A9 and we
can't afford to add them all to our submodel.) Note in passing that
the technique we used to prove 3.7 is already sufficient to prove the
first sentence of the statement of 3.10, since it produces a countable
model of any consistent theory in a countable language (we can
ensure that it is countably infinite rather than finite by using the
technique in the proof of 3.9, with / taken to be countably infinite).
A theory T is said to be categorical if it has only one model, up to
isomorphism (again, we haven't defined isomorphism of 7-models,
but...). The Lowenheim-Skolem theorems tell us that a first-order
theory with an infinite model can't be categorical (although there are
categorical first-order theories with finite models: for example, the
theory of simple groups of order 168). In the practice of mathematics,
we are accustomed to come across axiom-systems which (in the
above sense) categorize infinite structures; so what is going on here?
A good example of such an axiom-system is Peano9 s postulates for
the natural numbers (G. Peano, 1891). These say, approximately,
(i) 0 is a natural number. [Peano actually started at 1, but who
cares?]
(ii) Every natural number has a successor.

First-order theories 
29
(iii) 0 is not a successor.
(iv) Distinct natural numbers have distinct successors.
(v) (The induction postulate) If p is a property of natural numbers
which is true for 0, and which is true for the successor of x
whenever it's true for x, then P is true for all natural numbers.
Expressed in modern terminology, postulates (i) and (ii) are not
axioms; they simply define the language by saying that it contains a
constant 0 and a unary operation s. Postulates (iii) and (iv) may then
be expressed by first-order sentences in this language:
(Vxp(sx = 0)
and (Vx, y)((sx = sy) => (x = y)).
The problem comes with postulate (v), which speaks (implicitly) of all
possible properties of natural numbers, i.e. of all possible subsets of
our intended model M. In first-order logic we're not allowed to
quantify over subsets, but only over elements; but we might try to
approximate to Peano's intentions by introducing a scheme of axioms
of the form
((p[0/x] A (Vx)(p => p[sx/x])) => (Vx)p), 
(*)
one for each formula p of our language with FV(p) = {x}. Actually,
we can be a little more general than this by allowing 'induction with
parameters': that is, we can allow p to have additional free variables
yx,..., 
yn and then apply (iyx,... 
,yn)to the formula (*) above. If we
do this, we obtain a first-order theory which we shall call 'weak
Peano arithmetic'.
However, when logicians speak of 'Peano arithmetic', they
generally mean an extension of this theory obtained by adjoining two
binary operations a and m to the language, plus the axioms
(Vx)(axO = x)
(Vx, y){axsy = saxy)
(Vx)(mxO = 0)
and (Vx, y)(mxsy = amxyx)
which express the usual recursive definitions of addition and
multiplication (and, of course, all the extra instances of (*) arising
from the extension of the language). First-order Peano arithmetic
(which we shall abbreviate to PA) is a useful and versatile theory
(though it's doubtful whether Peano himself would have recognized

30 
Notes on logic and set theory
it), and we shall make extensive use of it in Chapter 9. But we haven't
captured the full force of Peano's fifth postulate; for our language is
still countable, and hence there are only countably many axioms of
the form (iyt,..., 
yn) (•) (each of which, if interpreted in a countable
structure A, makes an assertion about countably many subsets of A-
one for each assignment of values to the parameters yl9... 
,yn),
whereas Peano's (v) applies to each of the uncountably many subsets
of 1^1. Thus the fact that PA has models not isomorphic to M is not,
after all, surprising.
Similar remarks can be applied to the assertion, familiar from a
first course on real analysis, that the axioms for a (Dedekind)
complete ordered field categorize the real line U. The problem is that
the Dedekind completeness axiom
(VS £ R)((5 # 0 and S has an upper bound) =>
(S has a least upper bound))
involves a quantification over subsets of R; once again, we can
replace it by a scheme of first-order axioms in the language of ordered
rings (i.e. the language of rings with an additional binary predicate
O , but there are only countably many such axioms and the resulting
theory will have a countable model.
Exercises
3.1. 
Formulate sets of axioms in suitable first-order languages (to be
specified) for the following theories:
(i) The theory of integral domains.
(ii) The theory of algebraically closed fields of characteristic zero,
(iii) The theory of separably closed fields of characteristic 2. [A field K
is said to be separably closed if each polynomial over K which has no
common factor with its (formal) derivative has a root in K.~\
(iv) The theory of local rings. [A local ring is a commutative ring
which has a unique maximal ideal.]
(v) The theory of partially ordered sets.
(vi) The theory of partially ordered sets having greatest and least
elements.
(vii) The theory of totally ordered fields,
(viii) The first-order theory of Dedekind-complete ordered fields.

First-order theories 
31
(ix) The theory of simplicial complexes. [Take the underlying set to
consist of vertices, with an n-ary predicate <f>n for each n to express the
assertion that a given n-tuple of vertices spans a simplex.]
(x) The theory of groups of order 168. [Add 167 constants to the
language of groups.]
(xi) The theory of simple groups of order 168.
3.2. 
Let if be the first-order language having one binary predicate <£r for
each real number r ^ 0, and let T be the if-theory with axioms
(Vx, y)((t>r(x, y) => <t>s(y, x)) 
for each (r, 5) with r < 5,
and (Vx, y, z)(((t>r(x, y) A (/>s(y, z)) =» <t>r+s(x, z)) 
for each (r, s).
Show that a metric space (X, d) becomes a T-model if we interpret
<j>r(x, y) as 'd(x, y) < r'.Is every T-model obtained from a metric space
in this way?
3.3. (a) Define the notion of substructure of an if-structure A.
(b) Show that if B is a substructure of A, and p is a quantifier-free
formula of ^£ (with n free variables, say), then
[P]B=[P]A^B\
[If you can't do this, your answer to (a) is probably wrong.]
(c) By considering the centre of a group, or otherwise, show that the
conclusion of (b) may fail if p contains quantifiers.
3.4. (a) A first-order theory is called universal if its axioms all have the form
(Vx*)p, where 3? is a finite (possibly empty) string of variables and p is
quantifier-free. If T is a universal theory, show that every substructure
of a T-model is a T-model.
(b) T is called inductive if its axioms have the form (Vx)(3>0p, where p
is quantifier-free. Let T be an inductive theory, and A a structure for
the language of T; suppose A is the union of a family of substructures
(Bt 11 el), where the B{ are totally ordered by inclusion and each Bt is a
T-model. Show that A is a T-model.
(c) Which of the theories in Exercise 3.1 are (expressible as) universal
theories? And which are inductive?
3.5. 
Let if be a first-order language having sets Q and IT of primitive
operations and predicates. Let S£* be the language obtained from if
on replacing each primitive operation co by a primitive predicate co*
with a(co*) = cc(co) + 1. If T is a theory in ^£, show how to construct a
theory T* in i*7* which is equivalent to T in the sense that it has 'the
same' models. [Hint: first write down axioms to express '[w*] is the
graph of a function'.]

32 
Notes on logic and set theory
3.6. 
Show that the sentences
(ix,y)((x = y)=>(y = x))
and (Vx, y, z)((x = y) => ((y = z) => (x = z)))
are theorems of the predicate calculus with equality.
3.7. 
Show that the first-order theory T whose only axiom is
(Vxp(x = x)
is consistent iff the language in which it is written has no constants.
Show also that, if it is consistent, it is complete (provided the language
has no nullary predicate symbols) and has witnesses. [Hint: first show
that every sentence of the form (Vx)p is provable in T - you will find
Exercise 2.2 useful for this.]
3.8. 
(a) Let if be the language of weak Peano arithmetic, and let N be an
if-structure. Show that the following are equivalent:
(i) N is a model for the higher-order Peano postulates.
(ii) For any if-structure A, there is a unique homomorphism N -• A
(i.e. N is freely generated by the empty set; cf. Theorem 1.2).
[Hint: given (i) and an if-structure A, let S be the sub-if-structure of
N x A generated by the empty set, and show that S-* N x A^> N is a
bijection.]
(b) Let N be an if-structure satisfying the equivalent conditions of
part (a). By taking A to be the set NN of all functions N -+ N (equipped
with suitable maps 1 -• A -• A), show that there exist functions
aN:N2 -+N and mN:N2 -+N making N into a model of (first-order)
Peano arithmetic.
3.9. 
Show that the sentences
(Vx, y, z)(axayz = aaxyz) 
and (Vx, y)(axy = ayx)
are provable in Peano arithmetic.
3.10. Let S£ be the language with one binary predicate <, and let T be the
if-theory with axioms
(Vxp(x<x)
(Vx, y){(x <y)v{y<x)v{x 
= y))
(Vx, y, z)(((x < y) A (y < z))=> (x < z))
(Vx)(3y,z)((y<x)A(x<z))
and (Vx, y)((x <y)=> (3z)((x < z) A (z < y))).
Show that every countable T-model is isomorphic to the ordered set Q
of rational numbers. Is every countable model of Peano arithmetic
isomorphic to Nl

First-order theories 
33
3.11. Let T be the first-order theory of Dedekind-complete ordered fields (cf.
Exercise 3.1(viii)). If K is a T-model, show that K is a real-closed field
(that is, an ordered field in which every positive element has a square
root, and such that every odd-degree polynomial over K has a root in
K). [In fact it can be shown that the theory of Dedekind-complete
ordered fields is equivalent to the theory of real-closed fields.]

Recursive functions
At one or two points in the preceding chapters, we have referred to
the existence or non-existence of algorithms to solve particular
problems. It's easy to see how one proves that an algorithm exists:
one simply constructs it, and demonstrates that it does the job one
wants it to do. But how can one prove that no algorithm exists for a
particular problem?
Clearly, in order to do this, we are going to have to be more precise
than hitherto about what we mean by an algorithm. Informally, we
can think of an algorithm as some calculation which a computer
could be programmed to carry out; but, in order to make this precise,
we need a precise definition of what we mean by a computer. In fact,
our 'idealized' mathematical model of a computer will be a pretty
feeble thing in comparison with most physically existing computers
(we are not, on this theoretical level, interested in questions of speed
or efficiency of computation, and so for simplicity we shall give our
computer only the minimum of features needed for it to function at
all); but in one respect it will be more powerful than the largest
computer ever built - it will be able to handle arbitrarily large natural
numbers. Of course, any physically existing machine suffers from
limitations on the size of the numbers it can handle, but for our
purposes it is essential that we dispense with this restriction - if we
want to know whether some function /: N -> I\J is algorithmically
computable, it is not enough to say that we can build a machine
guaranteed to give the right value of f(n) for all n < 10lol°, since such
a machine might really be computing a different function which just
happens to agree with / at these values.
The first person to formulate the idea of such a theoretical

Recursive functions 
35
computer, and of the class of theoretically computable functions, was
the British mathematician A. M. Turing, in 1936. (After the Second
World War, Turing was also a pioneer in the practical development
of electronic computers.) We shall not follow Turing's description of
a theoretical computer exactly, but instead use a notion of 'register
machine' (essentially due to M. Minsky) which has certain technical
advantages over Turing's machine, and turns out to have exactly the
same computing power.
A register machine, then, has a sequence of registers Rl9R2,... 
,
each of which may at any time hold an arbitrary natural number. A
program for the machine is defined by specifying a finite number of
states S0,Sl9..., 
Sn, together with, for each / > 0, an instruction to be
carried out whenever the machine is in state St. (So is the terminal
state; on reaching it, the machine 'switches itself off'.) These
instructions are of two kinds:
(a) add 1 to register Rj9 and move to state Sk;
(b) test whether Rj holds the number 0: if it does, move to state St;
otherwise subtract 1 from it and move to state Sk.
We can represent these instructions diagrammatically, as follows:
A program may be represented by putting together several such
diagrams: here is a simple example which (starting from Sx, which we
normally take as our initial state) adds the contents of R2 to R1,
leaving R2 empty.
Alternatively, we may write a program as a finite sequence of triples
(j> + 9 k) or quadruples (j9 —, /c, /) (representing the basic instructions
(a) and (b) above; the rth term of the sequence is the instruction to be
obeyed in state /). The following sequence represents a program
which first empties R3, then adds twice the contents of R2 to Rx, and

36 
Notes on logic and set theory
finishes with R2 containing what it did initially:
(3,-,1,2)
(2,-,3,6)
(3,+,4)
(3,-,7,0)
(2,+,6).
[Exercise: rewrite this program as a diagram, and verify that it does
what was claimed above.]
We note that any given program, since it has a finite number of
instructions, will affect only finitely many of the registers of our
machine; but (as with variables in the predicate calculus) it is
convenient to have an unbounded supply of registers available.
Normally, we think of a certain initial segment (Rx, R2,..., 
Rk) of the
registers as 'input registers', which are loaded before the start of a
program with the data on which we wish to perform some
computation; the remaining registers constitute the program's
'scratch pad', and are normally assumed to be set to 0 before it starts.
Thus we say that a function f:Nk -+N is computable by a given
program P if, starting from state Sx with the registers holding
(nx, n2,..., nk, 0,0,...), the machine eventually reaches state So with
f(nx, n 2,..., nk) in register Rx.
Of course, a given program may run for ever without reaching state
So, or may reach So only for certain values of the input data; so our
notion of computable function includes partial functions (i.e.
functions defined on subsets of Nk) as well as globally defined ones.
Here, for example, is a program which computes n1 — n2 if n1 ^ n2,
and fails to terminate if n1<n2:
The next problem is clearly to determine which functions are
computable. We begin by showing that the class of computable
functions has good closure properties.

Recursive functions 
37
Theorem 4.1. (a) For 
each 
j'^/c, 
the 
projection 
function
(«!,...,nk)y-+nt is computable.
(b) The constant function with value 0, and the successor
function N -> N, are computable.
(c) If / is a computable (partial) function of k variables and
gx,..., 
gk are computable functions of / variables, then the
function h defined by
h(nl9..., 
w,) = f{gx{nl9 ... ,n,),... ,gk(nl9..., 
w,))
is computable. [Note that if / and the gt are not globally
defined, we regard h as being defined at (n1,..., 
nt) iff each gt is
defined there and / is defined at the resulting fc-tuple of
values.]
(d) If / and g are computable functions of arities k and k + 2
respectively, then the (k + l)-ary function h defined by
h{nx, 
n2,..., 
nh9 0) = /(i^, n 2,..., nk)
h(nl9...,nk,nk 
+ 1 + 1) = ^ ! , . . . 
9n
is computable. [Again, we adopt the obvious convention
about when /i is undefined.]
(e) If / is a computable function of arity k + 1, then the /c-ary
function # defined by
g ( n l 9 . . . 9 n k ) = nif f ( n l 9 . . . , n k , n ) = 0 a n d
f(nl,..., 
nk9 m) > 0 for all m < n
(and ^(wj,..., nk) undefined if no such n exists) is computable.
We summarize parts (a) and (b) of this theorem by saying that the
basic functions are computable, part (c) by saying that the class of
computable functions is closed under composition, part (d) by saying
that it is closed under (primitive) recursion, and part (e) by saying that
it is closed under minimalization.
Proof, (a) For i = 1, the projection function can be computed by any
program which leaves Rt alone and is guaranteed to terminate, for
example the one-line program (2,+,0). For f > l , we write a
program which first empties Rx and then transfers the contents of Rt
to it, thus: (1, -,1,2), (i, -,3,0), (1, +,2).

38 
Notes on logic and set theory
(b) These two functions can both be computed by one-line
programs, namely (1, —, 1,0) and (1, +,0).
(c) We construct a program for computing h as follows. First we
t r a n s f e r 
t h e c o n t e n t s o f R l , R 2 , . , R l 
t o Rn + l 9 R n + 29... 
, R n + t
respectively, where n is chosen so large that these registers will not be
disturbed in the subsequent computations. Then, for 1 ^ i ^ k, we
transfer these contents to Rk + 1,Rk + 2, • • >Rk+i (without destroying
the contents of Rn + l9... 
9Rn+l)9 
and perform our program for
computing gt (with all registers shifted k places to the right), storing
the answer in Rt. Finally, we perform our program for computing /,
terminating when (and if) the latter does.
(d) Here we again begin by copying our input data from
Rx,..., 
Rk + x to a 'remote' set of registers Rn + l9... 
9Rn+k + 1. Next we
perform our program for computing /; having reached the end of
this, we obey the instruction (n + k + 1, —, j9 0), where state Sj is the
beginning of a 'subroutine' which transfers the contents of Rx to
Rk + 2, t h e n t h o s e o f Rn + 1,... 
9 R n + k t o R l 9 . . . 9 R k a n d t h o s e o f
Rn+k + 2 to Rk + i, then performs the program for computing g and
finally adds 1 to Rn+k + 2. At the end of the subroutine we go back to
the state in which we obeyed the instruction (n + k + 1, —, j , 0).
(e) Once again, we first copy Rx,..., 
Rk to Rn + x , . . . , Rn +k. Then
we enter a subroutine in which we copy Rn + l9... 
9Rn+k + 1 to
Rl9... 
9Rk + l and then perform the computation of /. At the end of
the subroutine we obey (1, —, j9 / ) ; from Sj we add 1 to Rn+k+1 
and
return to the beginning of the subroutine, and from Sj> we transfer the
contents of Rn+k + 1 to Rx and then terminate. 
•
We define the class of recursive functions to be the smallest class of
(partial) functions from powers of M to M having the closure
properties of Theorem 4.1; thus a function is recursive iff it can be
constructed from the basic functions by a finite number of
applications of composition, primitive recursion and minimalization.
If / can be constructed without using minimalization then we call it
primitive recursive. Note that if the input data in Theorem 4. l(c) or (d)
consists of globally defined functions, then so does the output; thus
every primitive recursive function is globally defined. (However, not
every globally defined recursive function is primitive recursive, as we
shall see later.) As an example, the recursion equations

Recursive functions 
39
Hi + ("2 + 1) = (nx + n2) + 1
and
wx .0 = 0
«i • (»2 + 1) = ("I • "2) + «i
tell us successively that the addition and multiplication functions
N x f^J—>f^J are primitive recursive. Hence (the interpretation in N
of) every term of the language of PA is a primitive recursive function.
(We shall return to this point later-see Theorem 4.13.)
Theorem 4.1 tells us in particular that every recursive function is
computable. In the other direction, we have
Theorem 4.2. Every computable function is recursive.
Proof. Let P be a program for computing a (partial) fc-ary function /.
We define an auxiliary function g, of arity k + 2, as follows:
g(nl,..., 
nk9 0, t) is the number of the state reached after P has
been running for t steps, given that it started in state Sx with
the registers set to (nx,..., 
nk, 0,0,...) (it is understood that if
P terminates in fewer than t steps, then it remains in state 0
after it has terminated).
For i > 0, g(nl,..., 
nk, i91) is the contents of Rt after P has been
running for t steps (with the same convention about what
happens after P has terminated).
Clearly, g is globally defined. It is not immediately obvious that g is
recursive (in fact it is primitive recursive), since the value of
g(n1,..., 
nk, i, 14-1) depends on that of g(nl,..., 
nk, /', t) for values of
/' other than 1; it thus appears that we need a double recursion to
compute it, rather than a primitive recursion as in Theorem 4.1(d).
However, there are only finitely many values of i for which
g(nl9...,nk9 
i91) can ever be nonzero; and we can 'code' the finite
sequence (go,gl9... 
,gr) of its values for 0 < 1 < r (and some fixed
nx,..., 
nk and t) by the single integer 2Sf03gi... pfr, where p, denotes
the (i + l)th prime number. It is clear that the 'coding' function which
sends (g0,..., 
gr) to this product is primitive recursive; it is less clear
that the 'decoding' functions n\-^{n)i are so, where (n), denotes the
exponent of the largest power of p( dividing n, but see Exercise 4.3

40 
Notes on logic and set theory
below. Given this, it is easy to show that the function which sends
(nl9...,nk,t)to 
the product defined above is primitive recursive, and
hence that g is.
Now we observe that f{nx,..., 
nk) = 0(7^,..., nk, 1, h(nl,..., 
nk))
where h(nl9... ,nk) is the least t such that g(n1,..., 
nk, 0, t) is 0, if this
exists (and the = sign is interpreted as meaning that the expression
on one side is defined iff the other is and then they are equal). So / is
recursive. 
•
Theorems 4.1 and 4.2 together constitute one instance of Church's
Thesis (named after A. Church, who introduced the class of recursive
functions - via a different definition, which we shall not explore here -
independently of, and at the same time as, Turing); the thesis asserts
that the recursive functions coincide with the computable functions
for any reasonable 'abstract theory of computation'. As a general
assertion, Church's Thesis is obviously not capable of formal proof-
it is always possible that somebody will devise a new theory of
computation which is capable of computing more functions than our
register machine - but it has been verified for every such theory which
has been proposed so far, and is generally accepted as true by those
who work with recursive functions. Henceforth we shall assume it in
the following informal sense: if we wish to show that a given function
is recursive, we shall regard it as sufficient to give an informal
description of an algorithm for computing it, without verifying
explicitly that this description can be translated into a register
machine program.
Clearly, not every function f^k -• M is recursive, since there are
uncountably many such functions, but only countably many
programs for our register machine. We can code programs by natural
numbers, as follows: first we replace the triples (7, + ,fc) and
quadruples (j9 —, k, I) which form the individual instructions by
numbers 2j. 5k and 2j'. 3 . 5k. I1 respectively, and then we replace the
finite sequence of numbers il9i29 — -9ir which correspond to the
instructions in our program by the single number 2il. 3 1 2... pji x. We
write Pn for the program coded in this way by the natural number n.
Of course, not every natural number will code a program in this way -
for example, if n codes a program then each of the numbers (n)r,
defined as in the proof of Theorem 4.2, is divisible only by primes ^7

Recursive functions 
41
- but it is easy to construct an algorithm which determines whether n
codes a program, i.e. the function / defined by
f(n) = 1 
if n codes a program
= 0 
otherwise
is recursive. We say that a set of natural numbers (or more generally a
subset of N* for some fe) is a recursive set if its characteristic function is
a recursive function, as here.
Of course, a program does not uniquely specify the function which
it computes, since if P computes a fc-ary function / it also computes
the (fc - l)-ary function / ' defined by
f'(nl9 ...,n k_ 1) = /(n 1,...,w k_ 1,0).
But / is uniquely specified by giving its arity together with a program
for computing it; we shall write fnk for the fe-ary (partial) function
computed by Pn (ifPn exists). Adapting Cantor's diagonal argument,
we can now give an explicit definition of a function N -> N which is
not recursive: if we define
g(n) = fn,i(n) + * 
if (fn,i e x i s t s a n d) fnAn)is 
defined
= 0 
otherwise,
then clearly g^ fnl for any n.
At first sight, this is rather surprising, since the definition of g just
given appears to yield an algorithm for computing its value at any
natural number n. However, this is not so, since the 'otherwise' clause
of the definition includes cases where fnl exists but the computation
of fnl(n) 
does not terminate; in such cases we shall not be able to
deduce the value of g(n) from any finite computation. If we modified
the definition of g by leaving it undefined at these values of n, then it
would be recursive: this follows easily from
Theorem 4.3. There exists a recursive function u (of three variables)
such that
w(n,fc,m) = r if n codes a program, m codes a fc-tuple
((m)1,..., 
(m)k) of natural numbers and
fn,k((m)i> • • •' (m)fc) (is defined and) equals r,
and u(n9k,m) is undefined otherwise.
Proof. We give an informal description of an algorithm for
computing u. First we decode n and check whether it is a code for a

42 
Notes on logic and set theory
program (if not, we enter some non-terminating loop), and then we
decode m as a fc-tuple, if possible. Then we 'simulate' the operation of
Pn on the input data ((m)1?... ,(m)fc,0,0,...), by computing the
auxiliary function g((m)l9... 
,(m)k,i9t) 
defined in the proof of
Theorem 4.2, for the relevant range of values of i and for successive
values of t. (It is clear that this can be done algorithmically from the
input data (rc,fc,m), in such a way that the computation of each
successive value can be guaranteed to terminate in a finite time.) If we
ever reach a value of t for which g((m)l9... 
, (m)fc,0, t) = 0, we
compute the corresponding g((m)l,..., 
(m)k91, t) and then terminate;
otherwise we go on computing for ever. 
•
A program for computing a function like u of Theorem 4.3 is
said to be universal, since it is capable of simulating the action oiany
program that we can write for our register machine. It is possible to
give explicit examples of universal programs, but it would take too
long to do so here.
Next we consider a close relative of the notion of a recursive set.
Lemma 4.4. For a subset E of N, the following are equivalent:
(a) E is the set of values taken by some recursive function
(possibly of several variables).
(b) E is the domain of definition of some (partial) recursive
function of 1 variable.
(c) The function (j)E defined by (t>E(n) = 0 if n e E9 undefined
otherwise, is recursive.
(d) The function \j/E defined by ^/E{n) = n if neE, undefined
otherwise, is recursive.
Moreover, £ is a recursive set iff E and N — E both satisfy the
above conditions.
Proof, (b) => (c): Given a program for computing some function /
with domain £, we may modify it to compute <\>E by adding an
instruction which resets Rx to 0 before the program terminates.
(c)=>(d): Similarly, a program for computing (f)E may easily be
modified to compute ij/E; and (d) => (a) is immediate.
(a) => (b): Given a program P which computes a function / whose
range of values is £, we set up a new program Q which, given an input
n, systematically computes P for all possible values of the input to P

Recursive functions 
43
(doing finitely many steps at a time from each computation, in such a
way that it is bound to reach the end of each terminating
computation in a finite time). Each time this computation produces a
value of /, Q compares it with the input n\ if the two are equal, Q
terminates, otherwise it continues with the computation of values
of/
For the last part, if the characteristic function xE °^E *S computable
then so are <\>E and <$>H_E. Conversely, if (f)E and <f)N_E are both
computable we may write a program to run both computations
simultaneously, and produce the output 1 or 0 according to which
one finishes first. •
A set satisfying the conditions (a)-(d) of Lemma 4.4 is called
recursively enumerable. Not every such set is recursive:
Example 4.5. The set {n e N | u(n, 1,3") is defined} (where u is the
function defined in Theorem 4.3) is recursively enumerable but not
recursive. The first statement is obvious from the definition of the set;
but if the set were recursive, then it would be easy to write a program
for computing the function g defined before Theorem 4.3, since
g(n) = u(n91,3") + 1 whenever the latter is defined, and g(n) = 0
otherwise.
Example 4.6. Similarly, we may show that the set
E = {n e N | /„A is globally defined}
is not even recursively enumerable. For, if it were, then (cf. Exercise
4.4) we could find a globally defined recursive function (h, say) whose
range of values is E, and then define
Gin) = fhin)fl(n) 
+ 1 = u(h(n), 1,3") + 1.
Then g is recursive, and globally defined, but g # fml for any meE.
The fact that the set of Example 4.5 (and hence also the set
{(n,/c,m)| u(n,k9m) is defined}) fails to be recursive is generally
expressed by saying that the halting problem for register machines is
undecidable: that is, there is no algorithm which, given codes for a
program and for an input to it, determines whether the program will
terminate starting from the given input. The undecidability of other
mathematical problems, such as those to which we alluded in
Chapters 1 and 3, is generally proved by showing that, given an

44 
Notes on logic and set theory
algorithm for solving the problem under discussion, we could
construct one to solve the halting problem. (See Example 4.11
below.)
Let / be a recursive function of (k + /) variables, say / = fn,k + i- If
we fix the values of the first k variables at ax, a2,..., 
ak, then we have
a recursive function g of / variables defined by
g ( n l 9 . . . 9 n l ) = f ( a 1 , . . . 9 a k 9 n l 9 . . . , w , ) .
Clearly, we can write g = fml for some m (in fact for infinitely many m,
since there are infinitely many ways in which we can introduce
inessential modifications into a program for computing g); however,
the question arises whether we can choose a suitable m in some
algorithmic way, given a code n for a program which computes / and
the 'parameter' values al9... ,ak. The answer, pretty clearly, is yes:
given a program for computing /, we simply prefix it by a program
which transfers the contents of Rx,..., 
Rt to Rk + x,..., 
Rk+l and then
loads Rl9..., 
Rk with the given parameter values. Since this process
is algorithmic, it corresponds by Church's Thesis to a recursive
function of the k + 1 variables n,al9... 
,ak. Thus we have
Theorem 4.7. For each pair (/c, /) of positive integers, there is a
globally defined recursive function tkl of k + 1 variables such
that
fn,k+i(ai>- • • >a*> bu . . . , bt) = jJw(Bffllf...,flJk),i(6i, • • •, bt)
for all n9al9...9ak9bl9...9bl 
(in the sense that one side is
defined iff the other is and then they are equal). 
•
Theorem 4.7 (like a good deal of recursion theory) is due to S. C.
Kleene; it is commonly called the 's-m-n theorem', a meaningless
name derived from the notation originally used by Kleene (and
copied by most subsequent writers). In conjunction with the existence
of a universal program (4.3), it is a very powerful tool for showing
that certain functions are recursive. For example,
Lemma 4.8. For each fe, there is a recursive function rk of two
variables which 'codes primitive recursion', in the sense that
frk(n,m),k + 1 ( X l > • • • > Xk> 0 ) = fn,k(Xl» 
• • • > Xk)

Recursive functions 
45
and
frk(n,m),k 
+ 1 (Xl 
> • • • ? Xfc> Xk + 1
Proof. Consider the (k + 3)-ary function g defined by
g(n,m,xl9... 
,xk,xk + 1) = f(xl9... 
9xk9xk + 1)
where / is the (k + l)-ary function defined (as above) by recursion
from fnk and fmtk + 2' It is clear that g is recursive, since it may be
defined by primitive recursion using u:
g(n,m9xl9...,xk90) 
= u(n, k9 3*
1 5* 2... p£*),
with a similar expression for g(n9m9xl9... ,xk,xk+1 + 1). Suppose
g = frfk + 3; then the function rk which we require is given by
rh(n9rn) = t2tk + 1(r9n9m). 
•
Similarly (cf. Exercise 4.7) we may code the process of composing
recursive functions (as in Theorem 4. l(c)) by a recursive function. We
thus obtain
Proposition 4.9. There is a recursively enumerable set E such that
(a) for every neE, fnl is primitive recursive, and
(b) every primitive recursive function of 1 variable occurs as
fnl for some neE.
Note that we do not assert that the set of all codes for primitive
recursive unary functions is recursively enumerable. Nevertheless, in
conjunction with the argument of Example 4.6, Proposition 4.9
suffices to prove our earlier assertion that not every globally defined
recursive function is primitive recursive.
Proof. By definition, a function is primitive recursive iff it appears as
the last term in a finite sequence fl9f2, -. • ,ft, in which each term is
either a basic function, or obtained by composing earlier terms in the
sequence, or obtained by performing primitive recursion on two
earlier terms. (We can think of such a sequence as a 'program for
proving that ft is primitive recursive'.) Clearly, we may code such
'programs' by natural numbers. Now we can give explicit codes for
the basic functions, since we gave explicit programs for computing
them in the proof of Theorem 4.1; thus we may describe an algorithm
which, given a code for a sequence (fl9... ,ft) as above, successively

46 
Notes on logic and set theory
computes codes for each fh using the functions rk of Lemma 4.8 and
ckl of Exercise 4.7 as 'subroutines'. By Church's Thesis, this
algorithm corresponds to a recursive function, whose image is the
required set E. 
•
As another example of the combined power of Theorems 4.3 and
4.7, we give
Proposition 
4.10. Let h be a globally defined recursive function of
1 variable. Then there is a number n such that / M = fhin)tl.
Proof. Consider the binary recursive function
g(x9y) = 
u(h(u(x9l93*))X3>).
By Theorem 4.7, we can find a globally defined recursive function of 1
variable (/w>1, say) such that g(x,y) = ffmi{x)tl(y). 
Let n = 
fmA(m).
Then for all y we have
fnAy) = ffmAm),i{y)
= g(™, y)
= 
u(h(fm9l(m)),l,y)
as required. 
•
Proposition 4.10 is of most interest in the case when the function h
is 'extensional' in the sense that, if n1 and n2 are codes for the same
(unary) recursive function, then so are /i(wi) and h(n2). We can then
think of h as a 'recursive' mapping of the set of recursive functions
into itself; and Proposition 4.10 tells us that every such mapping has a
fixed point. (This is part of a general result called the Recursion
Theorem, which implies that every such mapping has a smallest fixed
point; i.e., among all the fixed points of the mapping, there is one with
smallest possible domain, which is the restriction of all the others to
that domain.) However, it should be noted that the fixed point fnl
may not be globally defined, even if h sends (codes for) globally
defined functions to globally defined functions; for example, if h
corresponds to the operation on programs which inserts a subroutine
to add 1 to the final output, then the only fixed point of h is the empty
function.

Recursive functions 
47
Next we fulfil a promise made in Chapter 1, by giving an example of
an algebraic theory whose word problem is recursively insoluble. To
do this, we must first 'code' the problem as a problem about natural
numbers: for this, let us suppose that our operational type Q is a
countable set {co0, col9a)2>- •} and that the function which sends n to
the arity oc(con) of con is recursive. Next, we suppose our set of variables
is X = {xo,xl9x2,...}, 
and we code finite strings of elements of
flul 
by numbers of the form 2*°31'1.. .pj% where ij = 2n if the
(/' + l)th member of the string is con, and ij = In + 1 if the (/' + l)th
member is xn. Remark 1.1 can now be interpreted as a proof that the
set of codes for Q-terms is recursive.
Let us write r€ for the number coding a term t. We now further
suppose that our set E of primitive equations is such that the set
{(V,T)|(5 = f)e£}
is recursive. An algebraic theory (Q, E) satisfying the assumptions we
have made so far is said to be recursively presented', we say that such a
theory as a {recursively) soluble word problem if the set
{(rs\rn\(s = t)e£}
of codes for derived equations is also recursive.
Example 4.11. We shall construct a recursively presented theory
(Q, E) whose word problem is insoluble. Our operational type Q will
have one binary operation and a countable infinity of constants; our
equations will include the associative law for the binary operation,
and we shall find it convenient to denote this operation simply by
juxtaposition. It will also be convenient to label our constants (in
some recursive fashion) in two families pn
m (m, n e N) and <?„ (m, n e M).
Among the Q-terms we shall have strings like
which begin with a a followed by a finite string of ps, and in which all
the superscript indices have the same value n; we shall call these
special terms of index n, and our remaining primitive equations will
all be between pairs of such special terms having the same index. We
regard a special term as above as corresponding to a 'configuration'
of our register machine when it is running the program Pn, namely
that in which the program is in state Sio and the registers Rj hold the
numbers ij (1 < jf ^ t). We say a special term of index n has adequate

48 
Notes on logic and set theory
length if it contains enough ps to specify the contents of every register
which can be affected by Pn.
Our next group of primitive equations is determined, for each n, by
the instructions in the program Pn: for example, if the instruction to
be obeyed in state 5 3 of Pn is (2, —, 4,7), we write down all equations
of the forms
Clearly, the set of (codes for) such equations is recursive. Let us now
say that two configurations Cx and C2 are n-equivalent if the equality
of the corresponding special terms of index n is derivable from the
primitive equations we have so far; then it is clear that Cx and C2 are
n-equivalent if the program Pn, starting from configuration Cl (with
some suitable values in the registers whose contents are not specified
by CJ, eventually reaches C2. The converse is false, because of the
symmetric nature of equality: essentially, n-equivalence corresponds
to what would happen if the machine were allowed to run backwards
as well as forwards. However, because the forwards behaviour of the
machine is deterministic (i.e. there is only one configuration to which
it can move in a single step from a given configuration, although there
may be several from which it can move to a given one), it is easy to see
that two configurations Ct and C2 of adequate length are n-
equivalent iff there is some third configuration C3 which is eventually
reachable by Pn from either of them.
Finally, we add to our theory all equations of the form
this has no effect on the notion of n-equivalence for configurations
from which Pn can never terminate, but has the effect of making all
eventually-terminating 
configurations 
n-equivalent. 
Thus 
the
program Pn9 starting with input (n,0,0,...), will eventually
terminate iff
is a derived equation of the theory we have constructed (the number
of PQS on the left-hand side being one less than the number of the
remotest register affected by Pn - which is of course recursively
computable from n). So a recursive solution of the word problem for
this theory would lead to a recursive solution of the halting problem,
contradicting Example 4.5.

Recursive functions 
49
To conclude this chapter, we shall investigate the relationship
between Peano arithmetic, as defined in the last chapter, and
recursive functions. To do this, we need to introduce a general
concept of definability. Let Tbe a first-order theory (in a language if,
say) and M a T-model; then a (partial) function /: Mk -*> M is said to
be definable in T (or T-definable) if there is a formula p of ££ with
(k + 1) free variables (x x,..., xk, y, say) which is provably functional
(i.e. the sentence
is provable in T) and whose interpretation in M is the graph of/ (i.e.
(ml,..., 
mk, n) e [p] M 
iff 
(/(m x,..., mk) 
is 
defined 
and)
f(ml9... 
,mk) = n). [Note: some authors would call this 'strong
definability'.] If / is definable in T, we shall often denote a formula
defining it by '/(x l 9... 9xk) = y' (and indeed we shall treat
'/(*i> • • • 9*kY a s if it w e r e a term °f ^f)- O u r a i m is t 0 prove that
every recursive function N* -• M is definable in PA.
In general, it is easy to see that the interpretation in M of any term
of J£? is a T-definable function; in the particular case which concerns
us, this means that every polynomial function Nk -> M with natural
number coefficients is PA-definable. But we may also define
polynomials with negative or non-integral coefficients, provided they
take natural numbers as values: for example, the function
nir->%n(n+ 1) is definable by the formula (ayy = mxsx). Also, the
division algorithm
(Vx, y)(-^(y = 0) => (3! z, t)((t < y) A (X = amyzt))
is provable in PA (by induction on x, with y as a parameter; here
(t < y) is an abbreviation for (3u)(atsu = y)); thus the function
r(m9 n) = remainder when m is divided by n if n > 0,
undefined 
if n = 0
is PA-definable.
Let v: N3 -• M be the function (m, n, p) \-+ r(m, n(p + 1) + 1). By the
above remarks, v is clearly PA-definable. We shall require the
following lemma from elementary number theory.
Lemma 4.72.Given any finite sequence (n0, nl9..., 
nk) of natural
numbers, there exist numbers m0 and m^ such that
v(m0, m1, i) = nt for all i < k.

50 
Notes on logic and set theory
Proof. First we choose mx to be a multiple of fc! which is greater than
nt for all i < fc. Then the numbers mx(i + 1) + 1,0 ^ i ^ fc, are pairwise
coprime, for if d divides both mx(i + 1) + 1 and m^j + 1) + 1 (i # ;),
then it also divides
(7 + l)K(i + 1) + 1) - (i + lXm^j + 1) + 1) = j - U
and so (since 0 < \j - i\ ^fe) d divides ml9 whence d = 1. So, by the
Chinese Remainder Theorem, the congruences
x = n{ mod (mx(i + 1) + 1) (0 < i < fe)
are simultaneously soluble; we let m0 be any positive solution of these
congruences. 
•
The above proof can be formalized within PA; this should be
intuitively clear by now, although actually writing down such a
formal proof would be fairly tedious. We can now prove
Theorem 4.13. Every recursive function is PA-definable.
Proof. We shall show that the class of PA-definable functions has the
closure properties given in the statement of Theorem 4.1. (a) and (b)
are obvious, since the basic functions are the interpretations of terms
in the language of PA (indeed, of weak PA); and it is also clear that a
composite of PA-definable functions is PA-definable. Now suppose
that g is obtained from / by minimalization (as in Theorem 4.1(e)),
and that / is definable by a formula p(xx,... 
,xk,xk + l,y); then g is
definable by
Finally, suppose h is obtained from / and g by primitive recursion (as
in Theorem 4.1(d)) and / and g are definable by formulae p and q.
Consider the formula
(3z1, z2)(p(x1,..., 
xk9 v(zx, z2,0))
< Xfc + i) = > 4 ( * i , . ..,xk91, 
v(zuz2, 
r), 
v(zl9z29st)))
Using Lemma 4.12, we see that this formula is satisfied by a
(fc + 2)-tuple 
of 
natural 
numbers 
(nl,..., 
nk9 nk + x, m) 
iff
h(n1,..., 
nk9 nk + x) = m. Thus h is PA-definable. 
•

Recursive functions 
51
Theorem 4.13 explains why, in defining the theory PA, we
introduced addition and multiplication as primitive operations, as
well as zero and successor. It is certainly not true that every recursive
function is definable in weak PA: indeed, it can be shown that the
addition map I^J2->f^ is not so definable. However, including
addition and multiplication as primitives gives us 'just enough' to
ensure the definability of the function v, which (as we have seen) is the
key to proving the 'primitive recursion case' of Theorem 4.13.
It should also be mentioned that the converse of Theorem 4.13 is
false: there exist PA-definable functions which are not recursive. For
if £ is a recursively enumerable set which is not recursive, then the
function </>£ of Lemma 4.4(c) is recursive and hence PA-definable, say
by p(x9 y); and then the formula
((y = 0) A ~]p(x, y))
defines the function </>N_E9 which by hypothesis is not recursive.
Exercises
4.1. Describe the behaviour of the following programs:
(a)
(b)
(c) (l,-,2,4), (3,+.3), (4.+.1), (2,-,5,7), (5,+,6), (6,+,4),
(3,-,8,9), (5,-.7,16), (5, -,10,18), (5, +,11), (4,-,12,14),
(7, +, 13), (3, +, 11), (7, - , 15,7), (4, +, 14), (6, - , 17,0), (2, +, 16),

52 
Notes on logic and set theory
4.2. (a) Write a program which computes n2 — 5n + 2 if this is non-negative,
and fails to terminate otherwise.
(b) Write a program which, given input w, computes the (n + l)th prime
number pn.
4.3. Prove successively that the following functions are primitive recursive:
(i) The function /x which is 1 if n = 0, and 0 otherwise.
(ii) f2(n) = the remainder when n is divided by 2.
(iii) /3(n) = the integer part of n/2.
(iv) f4(n) = n/2 if n is even, 0 otherwise.
(v) fs(n>m) — n/2m if this is a n integer, 0 otherwise,
(vi) f6(n) = the exponent of the largest power of 2 dividing n, if n > 0,
= 0 if « = 0.
4.4. If £ is a nonempty recursively enumerable subset of Py, show that there is
a globally defined recursive function with E as its set of values.
4.5. If £ is an infinite subset of M, show that E is recursive iff there is a strictly
increasing, globally defined recursive function M -> N with E as its set of
values.
4.6. If /: N -+ N is a (globally defined) recursive bijection, show that f'1 
is
also recursive.
4.7. Let k and / be positive integers. Show that there is a recursive function
ckl of k + 1 variables such that
Xkfl(n,in1,...,mk),/(*l J • • • » X/) = fn,k(fml,l(Xl» 
• • • > **)> • • • »fmk,l(Xl» • • • > X/)) •
4.8. Let S be a subset of the set of all unary recursive functions, such that
both S and its complement are nonempty. Show that the set
is not recursive. [Hint: let g be a function belonging to whichever of 5
and its complement does not contain the empty function, and consider
the function h defined by
h(m, n) — g(n) 
if fmt t (m) is defined,
undefined otherwise.]

Zermelo-Fraenkel set theory
We now begin our formal development of set theory. We shall
formulate it as a first-order theory in a language S£ whose only
primitive symbol, apart from equality, is a binary predicate e. (The
axioms will, however, allow us to enrich 5£ by introducing other
primitive symbols later on.) A model of set theory will generally be
denoted by the letter V; we think of Fas being the 'universe' of all sets
that we wish to talk about. Of course, V itself will be a set (or rather,
will have an underlying set) in some 'meta-universe' which is clearly
not identical with V; if we start trying to specify precisely what this
meta-universe is we are clearly going to be led into problems of
infinite regression, so we deliberately assume as little as possible
about it. (Roughly, what we assume about the meta-universe is that it
behaves in a way consistent with what we did in the first three
chapters.)
We shall call the elements of V sets; and if (a, b) e [e] v c V2, we
shall say that a is an element of b (in the model V). There is a
possibility of confusion here, in that the words 'set' and 'element' now
have technical meanings, when applied to elements of V, which may
conflict with their meanings in the meta-universe; if we were very
fussy we should probably introduce some formal means of
distinguishing between the two uses of these words, but in fact it's
usually possible to avoid confusion without going to such lengths,
given common-sense and a modicum of goodwill. Note that, within
our model, the elements of a set are themselves sets; we do not have a
separate collection of 'ur-elements' which can occur on the left of the
predicate e but not on the right (though there are some variants of set
theory in which such things are allowed). Informally, the idea is that

54 
Notes on logic and set theory
the entire universe can be built up inductively from the empty set 0
by iterating the operation of forming collections of things. (We shall
make this idea precise later on.)
Our fundamental picture of a set is that it is nothing more than the
collection of its elements. This leads us to formulate our first axiom,
the axiom of Extensionality
(Ext) 
(Vx, y)((Vz)((z ex)o(ze 
y)) =>(x = y))
which says that two sets with the same elements are equal. (Note that
the converse implication, that equal sets have the same elements,
follows from our logical axioms for equality.)
Next, we want to be able to say that there exists a set whose
elements are precisely the members of some well-defined collection.
One appealing way to formalize this idea is the axiom-scheme of
comprehension, which was (in essence) proposed by G. Frege in
1893:
(3yWx)((xey)op)
for every formula p with FV(p) = {x}. Unfortunately, as Bertrand
Russell pointed out, this scheme is inconsistent: by taking p to be the
formula n(x6x), we deduce (3y)((yey)<:>~l(yey)). Clearly, we
have to be more careful about the formulae p that we allow. Russell's
own solution to the problem was to reject set theory in favour of type
theory, in which every entity we consider has a 'type' attached to it
and the membership relation may only hold between entities of
different types; thus the formula n(xex) becomes impossible to
interpret. However, in type theory we have to give up (or at least
modify) the axiom of Extensionality, since there will exist empty
sets of many different types. A variant of Russell's idea, which is
associated with the name of W. Quine, is to retain the notion that we
have just one type of entity (sets) but to restrict the comprehension-
scheme to cases when the formula p is stratified; that is, when we can
assign integer levels' to all the variables of/? (both bound and free) in
such a way that in any subformula (x = y) the variables x and y have
the same level, and in any subformula (z e t) the level of t is one greater
than that of z.
However, in these notes we shall follow a different course, which
was first proposed by E. Zermelo in 1908 (and formalized by T.
Skolem in 1922), and which is now accepted by the great majority of

Zermelo-Fraenkel set theory 
55
set-theorists: namely, to restrict the use of the comprehension pro-
cess to the construction of subsets of previously-constructed sets. In
addition, we'll allow parameters in our formula p, as we did in the
first-order induction-scheme for Peano arithmetic; thus we arrive at
the following scheme, called the axiom-scheme of Separation:
(Sep) (Vz,,.. .9zHWyi)(3y2Wx)((xey2)o((xeyi) 
Ap))
where p is any formula with FY(p) = {x,zl9... 
,zn}. Note that (Ext)
assures us that the value of y2 making this sentence true (in a given
model of set theory) is uniquely determined by the values assigned to
zt,..., 
zn and yx; so we may if we wish enrich our language by adding
an (n + l)-ary operation-symbol Sp for each formula p as above,
where
((y2 = 
Sp(zl9...9zH,y1))o<yx)({xey2)o((xey1)Ap))).
Of course, we usually use the notation
for Sp(z1,..., 
zn9 yi); note that x appears in this notation as a bound
variable.
Unfortunately, (Sep) on its own does not provide us with enough
power to 'get started' in the business of constructing sets. The next
four axioms are all instances of the comprehension-scheme (in fact
stratified ones in the sense of Quine), which assert the existence of
certain 'fundamental' sets, or of operations that we can perform on
sets. Of course, now that we have (Sep), it is sufficient merely to assert
the existence of some set containing the one we're interested in as a
subset; thus each of these axioms can be presented in a 'strong' and a
'weak' form.
The first and simplest of them asserts that the empty set exists:
(Emp)s 
(3x)(Vy)--(yex).
The weak form (Emp)w of this axiom simply asserts that some set
exists: (3x)(x = x). In the presence of (Ext), we know that the empty
set is unique, so we may add a constant 0 to our language with the
axiom (V)>)~1(>>e0).
Next, we want an axiom to say that, given a set b, we can form the
set whose only member is b. Actually, it is convenient for technical
reasons to have an axiom about (unordered) pair-sets, from which the
existence of singleton-sets follows as an easy consequence. The weak

56 
Notes on logic and set theory
form of the Pair-set axiom says
(Pair)w 
(Vx,y)(3z)((xEz)A(>;ez));
the strong form (Pair)s is
(Vx, y)(3z)(Vt)((t ez)o ((t = x)v(t = y))).
The binary operation on V whose existence is implied by this axiom
will of course be denoted by {x,y}; and we'll write {x} as an
abbreviation for {x,x}.
Thirdly in this group, we have the Union axiom
(Un)s 
(Vx)(3jO(Vf)((f ey)o(3z)((tez) 
A (zex)))
(we leave it as an exercise to formulate the weak version), which says
that the union of all the members of a set is a set. We write (J for the
unary operation which this axiom allows us to introduce, and (x u y)
for (J {x, y). We shall similarly write f] x for the intersection of all
the elements of x (provided x # 0 - if x is empty then f] x doesn't
exist!), but we don't need an extra axiom to introduce this one, since
its existence follows from (Sep). (Similarly, (Sep) allows us to define
the pairwise intersection x n y and the set-theoretic difference x — y
of two sets x and y.)
The last axiom in this group is the Power-set axiom; we introduce
the notation (x c y) as a shorthand for (Vz)((zex) => (zey)).
(Pow)s 
(Vx)(3 JO(VZ)((Z ey)o{zci 
x)).
We denote the unary operation introduced via this axiom by 0>.
We now have enough axioms to do quite a lot of mathematics
within our model V: for example, we can define the ordered-pair
operation by
<x,yy = {{x}9{x,y}}
(this trick is due independently to K. Kuratowski and N. Wiener),
and prove that it has the property we expect of it :
(Vx, y, z, 0(«x, y> = <z, t}) o((x = z)A(y= t))).
We can also define two unary operations
First(x)=UH* 
if*#0
= 0 
otherwise,
= U(U*" fl *) if(U*
= First (x) 
otherwise;

Zermelo-Fraenkel set theory 
57
then First«x, y}) = x, Second«x, >>» = )>, and we can define the
predicate 'is an ordered pair' by
(x is an ordered pair)o(x = <First(x),Second(x)».
So we can define the cartesian product:
x x y= {te&g* (J {x,y)|(r is an ordered pair)
A (First(f)ex) A (Secondly)};
the predicate 'is a function':
(x is a function)o((Vt)((tex) => (t is an ordered pair))
A (Vy,z1,z2)((«>;,z1>Gx) A (<y,z2>Gx))
=>(z1=z2)));
the ternary predicate 'is a function from ... to ...' (for which we use
the familiar arrow notation):
(x: y -• z) o ((x is a function) A (Vt)((t ex)=> (First(f) e y))
A (Vil)((K6)0 => (3v)((V€z) A «H, V} Gx))))j
and the exponential:
zy={xe0>(yx z)\x:y-+z}.
Note, particularly in connection with the last but one of these, that
it is convenient to introduce the restricted quantifiers (Vyex)p and
(3yex)p to mean, respectively,
(Vy)((yex)^p) and (3y)((yex) AP).
Observe that the variable x is free in these expressions, although y is
bound; it is a condition of their use that x does not occur free in p.
Of course, when we say 'we can define' an n-ary operation symbol,
we mean that there is an (n + l)-ary predicate (p, say) in our original
language (with only = and e), which is provably functional (i.e. the
sentence
(Vx1,...,xw)(a!xw + 1)p
is deducible from the axioms we have so far) and can be proved to
have the properties we expect of it. Obviously, it would be
unutterably tedious to reduce everything to formulae involving only
= and G, which is why we feel free to enrich our language in this way,
but the important thing is that it is in principle possible to do without
the abbreviations we've introduced.

58 
Notes on logic and set theory
What we can't do from the first six axioms is to construct any
infinite sets. We can certainly construct infinitely many distinct sets
(for example, the sequence 0 , ^ 0 , ^ ^ 0 , . . . , or alternatively the
sequence of (von Neumann) natural numbers defined inductively by
0 = 0 , 
n+l = nv{n},
so that the natural number n has exactly n elements), but we have no
way of 'collecting' such sequences into infinite sets. 'Obviously',
infinite collections form part of our mathematical intuition (though
there are those who would argue against this), and so we need an
axiom which allows us to do this. Such an axiom is the axiom of
Infinity:
(Inf)w 
(3x)((0ex) A (Vy)((yex)=>(y+ ex))),
where we have introduced the notation y+ for y u {y} (the successor
ofy). A set x with the properties required by (Inf)w is called a successor
set; clearly, if a successor set exists then (Sep) allows us to find the
unique smallest one, namely the intersection of all successor sets
[exercise: formulate the strong axiom (Inf)s yourself], and (Ext) tells
us that this smallest successor set is unique, so that we can introduce a
new constant co to denote it.
Note that, in the presence of (Inf), the empty-set axiom (Emp)
becomes redundant. Previously, it was the only axiom which
unconditionally asserted the existence of a set, so that without it our
universe F might have been empty. (Of course, if we eliminated (Emp)
we'd have to eliminate the constant 0 from the formula (Inf)w; but
this is not hard to do.)
The seven axioms we have introduced so far, plus the axiom of
Choice (which we shall discuss in Chapter 7 below), are essentially the
axioms for set theory given by E. Zermelo in 1908. [Note for
historians: Zermelo's axiom of infinity was slightly different from
ours, since he defined the natural numbers by 0 = 0 , n + 1 = {n}; but
this doesn't make any essential difference. Also, his separation axiom
was not exactly like ours, because the concept of an arbitrary first-
order formula didn't then exist and he referred to p as being a 'definite
property' of sets, a phrase for which he never found a satisfactory
definition.] However, subsequent workers in set theory realized the
need for two more axioms, which have been added to the above seven

Zermelo-Fraenkel set theory 
59
to form what we now call Zermelo-Fraenkel set theory (ZF, for
short).
The first of these extra axioms is the axiom-scheme of Replacement,
which is traditionally associated with the name of A. Fraenkel, but
which was in fact introduced independently by Fraenkel and by T.
Skolem, about 1922. To see the need for this, let us return to the two
infinite sequences ( 0 , ^ 0 , £ ^ 0 , . . . ) and (0,1,2,...) that we con-
sidered before introducing the axiom of Infinity. (Adopting part of
a notation which will later become standard, we'll denote the former
sequence by (Ko, Vl9 V29...).) The axiom of Infinity tells us that we
can 'collect' the terms of the second sequence into a single set w; but it
is not clear that we can do the same for the first, even though the
sequences have 'the same number' of terms. More precisely, the
'function' n i—• 1^ is definable by a first-order formula (see Exercise
5.2) and its 'domain' is a set, but we don't yet know that its 'range' is a
set.
Digress/on on sets and c/asses.We put the words 'function',
'domain' and 'range' into inverted commas in the last sentence,
because n f—• Vn is not (yet) a function inside our model V. In order to
get over this difficulty, it's convenient to introduce the notion of a
class; informally, a class is a sub-(meta-)set of V which is the
interpretation of some first-order formula of our language. More
formally, a class is an equivalence class of formulae with one free
variable (x, say), the equivalence relation being that p and q define the
same class if we can prove (Vx)(p o q) (in which case we say that p and
q are extensionally equivalent). We'll use the informal notation {x\p}
for the class defined by a formula p; then (ye{x|p}) is just another
way of writing the formula p[y/x~\. Also, we'll say the class {x\p} is a
set if we can prove
(3yWx)(po(xey)); 
(*)
if we can prove the negation of this formula, then we call {x\p} a
proper class. (Of course, we may not be able to prove either (*) or its
negation, and indeed (*) may have different truth-values in different
models of set theory.) In a similar way, we'll use the term function-
class for (the extensional equivalence class of) a formula / with two
free variables (x and y, say) for which we can prove

60 
Notes on logic and set theory
the domain of a function-class / is then the class {x | (3y)f}9 and its
range is the class {y | (3x)/}.
In terms of the concepts introduced in the last paragraph, we want
an axiom which says that if the domain of a function-class is a set,
then its range is a set. Of course, this involves a quantification over
function-classes, and so we shall have to represent it as a scheme of
first-order axioms, one for each formula defining a function-class.
And once again it will be convenient to allow additional parameters
in our formula; thus we arrive at the axiom-scheme
(Rep) 
(Vz,,..., zJ((Vx, yx, y2)((p A p[y2/yi}) 
=> (yx = y2))
=> (MQuWyMyi 
eu)o(3x)((xet) 
A p)))9
where p is any formula with FV(p) = {x, yt, zx,..., 
zn). (If you find it
hard to visualize what this is saying, think first about the case where
there are no parameters, i.e. n = 0.) This formulation of the
replacement-scheme is actually rather stronger than we need; in
particular, it implies the separation-scheme (see Exercise 5.1). There
are weaker versions of replacement which do not have this property,
but they are (even) less intuitive than the one we've given.
Using Replacement, we can form the set which it is natural to
denote informally by {Vn \ n e co}; and then we can form [j {Vn \ n e co},
which we denote by Va. This is a fairly large set (albeit still countable);
in fact it contains as a subset every particular set that we've
mentioned so far. But the universe doesn't end here, since (by the
Cantor diagonal argument) &Vm is strictly larger; it seems reasonable
to denote ^ F w by Va + l9 and to define Kw + 2 = PVa + l9... 
, Kw+0) =
U {Va+H \neco}, Kw+W + 1 = ^ F w + a , , . . . .
How long should we go on doing this? We'll defer the answer to
this question until Chapter 6, and look instead at a related one: can
we be sure that every set in our universe eventually turns up inside
some Val [At the moment, 'a' is simply a generic name for the
subscripts which appeared in the last paragraph; in the next chapter it
will have a more specific meaning.] The answer (at present) is no,
because we don't have anything to exclude the possibility that some
set may be an element of itself, whereas it's easy to see that no such set
can occur as a member of any Va (consider the first Va to which it
belongs). To exclude this sort of pathological behaviour of the e-
predicate we need one further axiom, whose importance was first

Zermelo-Fraenkel set theory 
61
recognized (around 1925) by J. von Neumann, and which is called the
axiom of Foundation (or Regularity).
The simplest formulation of this axiom is somewhat opaque: it says
that every nonempty set has an element which is disjoint from itself,
or in symbols
(Fdn) 
(Vx)H (x = 0 ) => (3yex)(y n x = 0)).
The idea is that, if we think of the universe as being built up in
successive 'stages' represented by the Vas, then among the members of
a given nonempty set x there must be one which was constructed 'at
least as early' as all the others; the members of this set must all have
been constructed strictly earlier, and so cannot be members of x. In
general, we shall say that a binary relation-class (defined by a formula
r(x, y) with two free variables) is well-founded if every nonempty set
has an 'r-minimal' element (i.e.
so the axiom of Foundation is simply the assertion 'e is well-founded'.
The chief use of the axiom of Foundation is to enable us to prove
things about sets by induction over the membership relation e. Before
embarking on this topic, however, we need to introduce the concepts
of transitive set and transitive closure. We say a set x is transitive if
it is easy to see that this is equivalent to either of the assertions
(J x ^ x or x ^ 0>x. (However, it is not the same as saying that the
restriction of e to x x x is a transitive relation in the usual sense - the
latter is equivalent to saying that every member of x is a transitive
set.) It's not hard to see that an arbitrary intersection of transitive sets
is transitive; hence if a given set x is contained in some transitive set,
then there is a unique smallest transitive set which contains it, namely
the intersection of all such sets. We call this smallest set the transitive
closure of x, and denote it by TC(x); given (Un), (Inf) and (Rep), it
may be constructed explicitly by
We are finally ready to prove the first theorem of this chapter:
Theorem 5.1. In the presence of the other axioms of ZF, the axiom
of Foundation is equivalent to the following axiom-scheme,

62 
Notes on logic and set theory
known as the principle of e-induction:
(Vzx,..., zn)Wx)Wy ex)(p[>/x]) => p) => (Vx)p), (*)
where p is any formula with FV(p) = {x, z1,..., 
zn}.
Proof. First assume the axiom of Foundation. For simplicity, we
shall consider the 'no-parameter' case of (•), i.e. the case n = 0. Let p
be some formula with FV(p) = {x}, and assume the hypothesis that p
is 'e-inductive', i.e.
(Vx)((Vyex)(p(>/x])=>p).
Assume further ~n(Vx)p, i.e. (3x)~]p. Given a particular x for which
—•p, consider the set
M is nonempty since x ew, and so it has an e-minimal member y, say.
But then we have ~~*p\_y/x\ since yeu, and (Vzey)p[z/x~] since the
members of y are all in TC({x}) — u. This contradicts the e-
inductiveness of p; so from (p is e-inductive) and ""^Vxjp we have
deduced J_. Hence ((p is e-inductive) => (Vx)p).
Conversely, suppose given the principle of e-induction. We shall
apply it to the predicate 'is a regular set', where 'x is a regular set'
means
Clearly, the axiom of Foundation is equivalent to saying that every
set is regular, so it suffices to show that the property of being regular is
e-inductive. So suppose (Vyex)(y is regular), and let xez. Then
either x itself is an e-minimal member of z, or x n z is nonempty. But
in the latter case, any y e x n z is regular (being a member of x), and
hence z has an e-minimal member. 
•
Generalizing the first half of the proof of Theorem 5.1, we can
prove a 'principle of ^-induction' for any well-founded relation-class
R, provided we have the analogue for R of the transitive closure
operation. We can get this using the axioms of Infinity and
Replacement, as before, provided we know that the '/^-predecessors'
of any set form a set, i.e. provided
A relation-class with this property (which is of course trivial for e) is
said to be local. We can further modify the principle of /^-induction

Zermelo-Fraenkel set theory 
63
by restricting the variables x and y to some class (or even a set), rather
than the whole universe, provided R satisfies the well-foundedness
condition relative to this class; note that if we restrict to a set, then the
'local' condition is automatic. If R is well-founded and local relative
to a class M, we shall write RCM for the /^-closure operation relative
to M; i.e. if x is a subset of M, we write RCM(*) for the smallest set y
satisfying x^y and
In particular, eCv is the function-class which we have previously
called TC.
Example 5.2. Let R be the successor-relation on co (i.e.
Then R is local (since each element of co has at most one R-
predecessor) and well-founded (since any e-minimal member of a
nonempty subset of co is also /^-minimal). Thus we obtain the usual
principle of mathematical induction:
{{pl0/x] A (Vxeco)(p=>p[x+/x-]))^(Vxeco)p)
where p is any formula with one free variable x (and the extension of
this where p is allowed to contain parameters). Since every subset of co
is a subclass, this means that within our universe V co is a model for
the higher-order Peano postulates, as discussed in Chapter 3. Viewed
from outside (i.e. as a set in our meta-universe), the class of natural
numbers in V may not satisfy the higher-order induction postulate
(since it may have sub-meta-sets which do not correspond to actual
subsets of co in V), but it is at least a model of first-order Peano
arithmetic: the addition and multiplication maps co x co -> co may be
defined by applying the argument of Exercise 3.8(b) internally in V.
(We shall return to this example in Chapter 9.)
The natural next step after induction is recursion, which is
concerned with defining things 'step by step' rather than proving
them. Since we made extensive use of recursive definitions in the first
four chapters, it is clearly desirable to prove a theorem saying that
such definitions can be carried out within a model of ZF set theory.
Before embarking on the proof of the R-Recursion Theorem, we need
one technical preliminary: there is one point in the proof where we

64 
Notes on logic and set theory
need to assume that our relation-class R is transitive (in the usual
sense!), and so we require
Lemma 5.3. Let R be a relation-class which is well-founded and
local relative to a class M. Then there exists a relation-class R
containing R, which is also well-founded and local relative to
M, and additionally transitive on M, i.e.
(Vx9y,zeM)((((x,y)eR)A((y,z)eR))=>((x,z}eR)).
Proof. We define R by
\(x9y)eR)o((yeM)A(xeRCM({y}))).
From the form of the definition, R is local; and it is transitive since
XERCM(Z) implies RCM({x}) £ RCM(z). Suppose x is a nonempty
subset of M with no /^-minimal member; then the set
{yGRCM(x)\(3zex)({z,y)eR)}
is nonempty (since it contains x as a subset) and has no ^-minimal
member. So the well-foundedness of R implies that of R. 
•
Theorem 5.4 (^-Recursion Theorem). Let M be a class, R a
relation-class which is well-founded and local on M, and G a
function-class (of two variables) which is defined everywhere
on M x V (i.e. such that
(Vx,>>)((xeM)=>(3!z)(z=G(x,y))) ).
Then there exists a unique function-class F, defined
everywhere on M, satisfying
(VxeM)(F(x) = G(x, {F(y) \ (yeM) A «>;,X> eR)})). (*)
The function-class F is said to be defined by K-recursion from G over
the class M. A further generalization of the theorem allows
parameters (i.e. additional variables, which may range over some
class other than M) in F and G; their presence doesn't complicate the
ideas of the proof, but only its notation.
Proof. Uniqueness is easy: ifF1 and F2 both satisfy (*), we may prove
(Vx eM)(Fx(x) = F2(x)) by /^-induction over M. To prove existence,
we introduce the notion of an attempt at defining F: by '/is an

Zermelo-Fraenkel set theory 
65
attempt' we mean
(/ is a function) A (dom(/) c M)
A(\/x,yeM)((((x,y>eR)A(yedom(f)))=>(xedom(f)))
A (Vxedom(/))(/(x) = G(x, {/(y) | (y eAf) A «y,x> eU)})).
Our function-class F will be the 'union' of all possible attempts, i.e.
(F(x) = y)o (3/)((/ is an attempt) A (f(x) = y)).
To prove that this is a function-class, we must show that any two
attempts agree on the intersection of their domains; but this is just the
uniqueness argument again, except that the induction is over this
subset of M rather than the whole class.
To show that F is defined everywhere on M, we must prove
(VxeM)(3/)((/ is an attempt) A (xedom(/))).
Suppose this fails; let x be an element of M which is not in the domain
of any attempt. Let x0 be an .R-minimal member of
{yeRCM({x})\-i(yedom(F))}9
where R is defined as in the proof of Lemma 5.3; then all the members
of RCM({x0}), except x0 itself, are in the domain of F, and
{<u,v>\((ueRCM({x0}) 
A(V = F(U)))}
(which is a set by Replacement) is itself an attempt, f0 say. We may
now define
fi=fov{<xo,G(xo,{fo(y)\(yeM)A«y,xo>eR)}))},
and fx is an attempt with x0 edom(/1), contradicting our hypothesis.
So F is defined everywhere on M; and it clearly satisfies (*). 
•
We shall meet numerous applications of the e-Recursion Theorem
in the next chapter. For the present, we give an application of the
r-Recursion Theorem, where r is a well-founded relation on a set. We
need a new definition: we say a relation-class R is extensional if
(Vx, )0((Vz)(«z, x}eR)o 
«z, y) e R)) => (x = y)).
Thus the axiom of Extensionality is just the assertion that e is
extensional.
Theorem 5.5 (Mostowski's Isomorphism Theorem). Let a be a set,
and r a well-founded extensional relation on a. Then there
exists a unique pair (b,f) where b is a transitive set and

66 
Notes on logic and set theory
f:(a,r)-^> (b,e) is an isomorphism of sets-with-a-binary-
relation.
Proof. We define / by r-recursion over a:
f(x) = {f(y)\(yea) A«y9x>er)}
(i.e. we take G(x, y) = y in the notation of Theorem 5.4), and we define
b — {f(x) | xea}. Then it is clear from the definition that b is a
transitive set, that / is surjective and that «x,y>er) implies
(f(x)ef(y)). To establish the converse of the latter implication, it
suffices to show that / is injective - which we have to do anyway.
Consider the formula (with free variable x)
p(x): (Vj/ea)((/(x) = f(y)) => (x = y));
we shall prove (Vx ea)p(x) by r-induction. For if p holds for all the r-
predecessors of x and f(x) = f(y), then <z, y)er implies f(z) e/(x)
and hence f(z) = /(f) for some r-predecessor t of x, whence z=t, i.e.
<z,x>er. Similarly, (z9x}er 
implies (z,y)er, 
so x = >^ by
extensionality of r.
To show the uniqueness of (b, / ) , suppose (b\ /') is another such.
By composing the inverse of / with /', we get an isomorphism
g: (b, e) -» (£>', e); then an easy e-induction shows (Vy eb)(g(y) = y).
So b = b' and f = f. 
Q
Exercises
5.1. Show that the Pair-set axiom and the axiom-scheme of Separation are
deducible from the Empty-set and Power-set axioms and the axiom-
scheme of Replacement. [Hint for the latter: to verify the instance of
Separation corresponding to a formula p, consider the function-class
which is the identity in so far as p holds, and undefined otherwise.]
5.2. Write down a first-order formula p, with one free variable /, to express
the assertion that / is a function whose domain is a nonzero natural
number, with /(O) = 0 and f(n+) = 0>f(n) for all n such that
n+edom(/). Show that
(Vn6o>)(3/)(p A(dom(/) = n + )),
and deduce (without using Replacement) that the operation n H-> Vn is
representable by a function-class.

Zermelo-Fraenkel set theory 
67
5.3. A class M is said to be transitive if
(\/x,y)(((xey)A(yeM))^(xeM)).
If M is transitive and (F, e) is any model of set theory, show that the
substructure ([M] v, e) of (V9 e) satisfies the axiom of Extensionality,and
that it satisfies each of the axioms of Empty set, Pair-set and Union iff
[M] v is closed under the corresponding finitary operation on V. What
further property of M do we need to get a similar result for the Power-set
axiom?
5.4. The class HF of hereditarily finite sets is defined by
(xsHF)o(VyeTC({x}))(y 
is finite),
where *y is finite' means that there exists a bijection from y to some
natural number. Show that the class of hereditarily finite sets, when
regarded (as in Exercise 5.3) as a substructure of V, satisfies all the
axioms of ZF except the axiom of Infinity.
5.5. Which axioms of ZF are satisfied (a) by the class oi hereditarily countable
sets, and (b) by the class of hereditarily small sets, where ly is countable'
means that there exists an injection y-xo, and 'y is small' means that
there is an injection from y to some set in the sequence
co, ^co, &&(o,... ? [Note: this use of 'small' is not standard
terminology.]
5.6. Let a\ V -+ V be the permutation which interchanges 0 and {0} and
leaves everything else fixed. Define a new binary relation ex on V by
Which of the axioms of ZF are satisfied in the structure (K Gj)? Would it
make any difference if we used the relation 'xeafj/)' instead of 
ia(x)ey'c!
5.7. If x is a transitive set, show that (J x and 0>x are both transitive. Is either
of the converse implications true?
5.8. Use the e-Recursion Theorem to show that there is a unique function-
class TC such that
(Vx)(TC (x) = x u U {TC (y) | y sx}),
and show that TC coincides with the transitive closure operation as
defined in the text. Why is TC unsatisfactory as a definition of the
transitive closure operation?
5.9. If a is any subset of co, show that e is well-founded and extensional as a
binary relation on a. What does the Mostowski Isomorphism Theorem
yield when applied to (a,e)?

6
Ordinals and well-orderings
In this chapter we investigate a particular class of well-founded
relations, namely those which are linear orderings. We begin with a
few definitions.
Let < be a binary relation on a set a. We say
< is irreflexive if (Vx ea)^(x 
< x);
< is antisymmetric if (Vx, y ea)((x <y)=> ^(y < x));
< is transitive if (Vx, y9 zea)(((x < y) A (y < z)) => (x < z));
< is trichotomous if (Vx, y ea)((x < y) v (y < x) v (x = y));
and < is a linear (or total) order on a if it satisfies all the above
conditions. Actually, the second condition is redundant, since it is
implied by the first and third. Moreover, a well-founded relation is
always irreflexive (since if x < x then {x} has no < -minimal member),
and a well-founded trichotomous relation is transitive (since if we
have x < y and y < z but not x < z, then {x, y, z} has no minimal
member). Thus a well-founded relation is a linear order iff it is
trichotomous; we call such a relation a well-ordering of the set a.
Equivalently, a well-ordering of a is a linear ordering < of a such that
every nonempty subset of a has a (necessarily unique) <-least
member. (We say that x is the least member of a subset fe, rather than
simply minimal, if (Vy efe)((x < y) v (x = y)).)
A linear ordering is clearly extensional, so we have an immediate
special case of Mostowski's Theorem (5.5): if (a, <) is a well-ordered
set, then there exists a unique pair (b,f) where b is a transitive set
well-ordered by e and / : (a, <) -• (b, e) is an order-isomorphism. We
define a (von Neumann) ordinal to be a transitive set well-ordered
(equivalently, linearly ordered) by e; we shall adopt the usual

Ordinals and well-orderings 
69
convention of using Greek letters to denote ordinals. Mostowski's
Theorem tells us that the ordinals form a system of representatives for
the isomorphism classes of well-ordered sets; we shall refer to the
unique ordinal isomorphic to a given well-ordered set (a, <) as the
order-type of (a, <).
Do we know any examples of ordinals? Well, 0 is (rather trivially)
an ordinal; and in fact all the (von Neumann) natural numbers, as
defined in Chapter 5, are ordinals. More generally,
Lemma 6.1. If a is an ordinal, then so is a + (= a u {a}).
Proof. If xey ea + , then either yeoc or y = a, and in either case we
deduce x e a ^ a + ;soa+ inherits transitivity from a. The proof that it
inherits trichotomy is equally easy. 
•
The set co of all natural numbers is easily seen to be an ordinal; this
is a particular case of the result that the union of any set of ordinals is
an ordinal. To prove this, we need a couple of lemmas.
Lemma 6.2. Any member of an ordinal is an ordinal.
Proof. Let a be an ordinal, /?ea. Since a is transitive, we also have
P ^ a, and hence fi is linearly ordered by e. To show j8 is transitive,
suppose Seyefl; then both 3 and (I are members of a, so we have one
of <5G/?, <5 = /? or fieS. But the latter two possibilities imply that
{fi,y,S} has no G-minimal member, 
n
Lemma 6.3. If a and /? are ordinals, then either a c f} or /? £ a.
Proof. Suppose a $ /?; let y be the e-least member of a - p. We shall
show y = a n /?. For if <5ea n /?, then yedory = S would imply y e/?,
and so (since both y and (5 are members of a) we must have dey; and
conversely, if <5ey, then <5ea but <5£a-/?, so dean/i. 
Hence by
Extensionality y=anfi. 
Thus a$/? implies anf} = yea; and
similarly jS $ a implies a n /? e /?. So if neither inclusion holds, we have
a n PSOL n /?, contradicting Foundation. 
•
Corollary 6.4. (a) For ordinals a and j8, a^ j8 is equivalent to
(OLEP or ot = 
p).
(b) If a and /? are ordinals, then one of ae/?, a = /? or /?ea
holds.

70 
Notes on logic and set theory
(c) If a is a nonempty set of ordinals, then f] a (is an ordinal
and) is the e-least member of a.
Proof, (a) If a £ /?, then either a = /? or (I $ a, whence a e /? by the
proof of Lemma 6.3. Conversely, cuefi implies a^j? since /? is
transitive.
(b) follows from (a) and the statement of Lemma 6.3.
(c) By Foundation, a has an e-minimal member; by (b) any such
member is actually e-least, and by (a) it equals f] a, since it is
contained in every member of a and equal to one of them. 
•
Proposition 6.5. The union of any set of ordinals is an ordinal.
Proof. A union of transitive sets is transitive. If a is a set of ordinals,
then the members of [j a are ordinals by Lemma 6.2; and by
Corollary 6.4(b) they are linearly ordered by e. 
•
Note that, by Lemma 6.2 and Corollary 6.4(b), the class ON of all
ordinals satisfies all the properties of an ordinal except that of being a
set. Our next goal is to prove that ON is characterized by the closure
properties of Lemma 6.1 and Proposition 6.5: for this, we need to
introduce the notions of limit and successor ordinals. Let a be an
ordinal; then either a has an e-greatest member or it doesn't. If it does
(say /?), then we have
i.e. a = P+, and we say a is a successor. If not, then we have a = (J a
(recall that we always have (J a ^ a, since a is transitive), and we say a
is a limit. [According to this definition 0 is a limit, though it's
sometimes convenient to exclude 0 from the class of limit ordinals; we
shall always make this exclusion explicit when we need it.]
Theorem 6.6. Let M be any class satisfying
(Vx)((xeM)=>(x+eM))
and
Then every ordinal is in M.
Proof We show (Va)((aeON)=>(aeM)) by e-induction. Suppose
aeON; then (V/?ea)(/?eON) by Lemma 6.2, so the inductive
hypothesis yields (V/?ea)(/?eM). But by the remarks above, we have

Ordinals and well-orderings 
71
either (a = (J a) or (3/?ea)(a = /?+); and in either case we deduce
aeM. 
•
In proving things by e-induction, or defining them by e-recursion,
over the class ON, it is often convenient to subdivide the argument
into cases, to deal separately with 0, with successors and with
nonzero limits. We shall see numerous examples of this in the pages
which follow. (Incidentally, when a and /? are ordinals, we shall
sometimes write a < fi (resp. a ^ /?) instead of a e/? (resp. a ^ /?).)
Now that we have the concept of ordinal, we can give a precise
definition of the sequence of sets Va (sometimes called the von
Neumann hierarchy) which we mentioned in the last chapter.
Explicitly, we define a function-class (a i—• Va) from ON to V by e-
recursion:
if a = f}+ is a successor, Va = ^Vp;
if a is a limit, 
K= [j {Vp | £ea}.
[Note that the second clause of the definition includes the assertion
Vo = 0. If we wanted to, we could combine the two clauses into one
saying Va = [j {^Vp | /?ea}.] While we're about it, let us also define
the rank function by e-recursion on V:
rank(x) = (J {rank(y)+ | yex}.
An easy induction shows that the rank of any set is an ordinal (and
that the rank of any ordinal is itself); the rank function and the von
Neumann hierarchy are related by
Proposition 
6.7. For any set x and any ordinal a, we have
((xeKJ
and
Proof. Since jS^a iff j?<a + and x^Va 
iff xeFa+, the second
assertion follows from the first. For the left-to-right implication of the
first assertion, we prove
(Va e ON)(Vx)((x e Va) => (rank(x) < a))
by e-induction in a. Suppose x e Va; if a is a limit then by definition we
have xeVp for some jS<a, so that rank(x)</? by the inductive

72
Notes on logic and set theory
hypothesis. If a = fi+ is a successor, then we have
(Vyex)(yeVp)9
whence by the inductive hypothesis we obtain
so that rank(x) < j8 by the definition of the rank function. The proof
of the right-to-left implication is a similar e-induction, but this time in
the variable x; we leave the details as an exercise. 
•
The von Neumann hierarchy gives rise to an appealing (if
somewhat unstable-looking) 'picture' of the set-theoretic universe,
which perhaps explains why it is usually denoted by the letter V.
The idea of the picture is that the ordinals form a 'spine' running up
the centre of the universe, and that the level at which any other set
appears in the picture is determined by its rank. Thus Proposition 6.7
tells us that the set Va is obtained by truncating the picture at level a. It
is perhaps ironic that it should be the axiom of Foundation which
tells us that the whole structure is balanced on a single 'point', namely
the empty set. (However, the picture should not be taken too literally.
It is certainly true in an informal sense that the universe 'gets wider as
you go up', but the outer edges of the Kdo not exist in any meaningful
sense.)
The von Neumann hierarchy can be defined even in set theory
without the axiom of Foundation, since it follows from the definition

Ordinals and well-orderings 
73
of an ordinal that the restriction of e to ON is well-founded, even if e
is not well-founded on V. In this context, the axiom of Foundation is
equivalent to the assertion that every set lies in some Va9 or
equivalently that the rank function is everywhere defined (cf.
Exercise 6.2).
We now turn to the arithmetic of ordinals. There are two possible
approaches to this subject, inductive and synthetic: for the former, we
define the operations of addition and multiplication by e-recursion
over ON, and use e-induction to prove that they satisfy certain laws
(associativity, etc.), whereas in the latter we rely on Mostowski's
Theorem, by defining a + /? and a . /? as the order-types of certain
well-ordered sets constructed from a and /?. For completeness, we
shall give (an outline of) both approaches.
The ordinal sum a 4- /? is defined by e-recursion on /? (with a as a
parameter):
a + 0 = a;
a + /? = (a + y)+ 
if /? = y + is a successor;
a + / ? = | J { a + y|y</?} if/? is a nonzero limit.
The ordinal product a . f$ is also defined by recursion on /?:
(a.0 = 0);
a . /? = a .y + a 
if /? = y + is a successor;
a . p = (J {a . y | y < ft) if fi is a limit.
(In this case the first clause of the definition isn't needed, because the
third reduces to it when /? = 0.)
Alternatively, we define a + ft to be the order-type of the disjoint
union all/? (by which we mean, by definition, a x {0} u/? x {1}),
ordered by
«7,0 < <S, j» o ((i < J) v ((/ = j) A (y < 6)))
(i.e. the ordering in which all the elements of a precede all the
elements of /?; this is known as reverse lexicographic ordering, and it's
easy to prove that r.l.o. on (a subset of) the product of two well-
ordered sets is a well-ordering), a. /? is defined to be the order-type
of the cartesian product a x /?, ordered by r.l.o.
To verify that these two definitions agree, it is of course sufficient to
show that the 'synthetic' definitions satisfy the various clauses of the
recursive definitions. For example, if we take the successor case

74 
Notes on logic and set theory
P = y + of multiplication, the synthetic definition tells us to form
a x y + = (a x y) u (a x {y}) with r.l.o.; but the elements of a x y
precede those of a x {y} (and the latter have order-type a), so the
inductive hypothesis that a x y has order-type a. y implies that
<xx y+ has order-type a . y + a. Similarly, if yS is a limit, then we have
a x / ? = ( J { a x y | y < / ? } , and each a x y forms an initial segment of
a x p in the r.l.o.; so if we have order-preserving bijections
a x 7 -• a . y for each y < /?, we can put them together to form an
order-preserving bijection a x p -»a . /?.
It follows immediately from either definition that a + 1 = a + for all
a (so that we can now drop the notation a+ for successors, if
we wish). However, 
l + a # a + l in general: for example,
1 +co = (J{1 +n\nEco} =co^co + 1 . 
Similarly, 
2.co = co 
but
co .2 = co + co^co. Thus ordinal addition and multiplication do not
satisfy the commutative laws of ordinary (finite) arithmetic - which is
not surprising when we consider the asymmetric nature of the
definitions. The next question we must deal with, therefore, is which
laws of arithmetic do hold for ordinals.
We begin with the order-preserving properties.
Lemma 6.8. (a) If p < y, then a + p < a + y.
(b) If p < y, then p + a ^ y + a.
(c) If a ^ 1 and /? < y, then a . P < a . y.
(d) If £ < y , then jS.a^y.a.
Proo/. Each of these may be proved either inductively or
synthetically. In fact (a) and (c) are most easily proved synthetically,
by showing that ocllp (resp. a x /?) is a proper initial segment of a II y
(resp. a x y). (b) and (d) are most easily proved by induction on a: at a
limit stage of the induction, we use the (obvious) fact that if each
member of a set x is a subset of some member of y, then
U^U^- 
•
Next, some identities.
Lemma 6.9. The following hold for all ordinals a, P,y:
(a) 0 + a = a,
(b) 0 . a = 0,
(c) a . 1 = a = 1. a,
(d) a

Ordinals and well-orderings 
75
(e)
(f)
Proof. Again, each of these can be proved by induction (except for
the first half of (c), which follows at once from the definition and (a);
the induction is on a in the first three cases, on y in the other three), or
synthetically by setting up an order-isomorphism between two well-
ordered sets. We give one example of each method.
For the synthetic proof of (e), we must set up an order-
isomorphism between a x (/? II y) and (a x /?) II (a x y). But the first of
these sets has elements of the form <<5, <?/, />> where Sea and either
(rjep and i = 0) or (rj e y and i = 1); and the second has elements of the
form <<<5, */>,*> subject to the same restrictions. It is clear that the
unique sensible bijection between these two sets preserves r.l.o.
For the inductive proof of (f), suppose a . (/?. 8) = (a . /?). S for all
5<y. Ify = (5 +isa successor, then we have
by definition
= 0L.(p.8) 
+ a . p 
b y ( e )
= (a . P). 6 + a . P by inductive hypothesis
= (a . P). y 
by definition.
If y is a limit, then a . (/?. y) — a . (J {/?. 5 \ 5 < y}; but the sequence of
ordinals /?. S (d < y) is strictly increasing by 5.8(c) (except in the case
P = 0, which is trivial), from which it follows easily that its union must
be a limit. Moreover, since any rj less than this limit is less than some
P. 5, we actually have
= 
U{z.(p.S)\6<y}
= (J {(a . P). d | 5 < y) 
by inductive hypothesis
= (a . P) .y 
by definition. 
•
However, in addition to the two commutative laws, the 'right
distributive law' (a + p) .y = a .y + /? .y does not hold for ordinals:
for example, take a = /? = l,y = co.

76 
Notes on logic and set theory
Exercises
6.1. 
Some writers on set theory define an ordinal to be a transitive set
whose members are all transitive sets. By Lemma 6.2, the definition
given in the text implies this one; use e-induction to prove that the
converse holds. Show also that the converse does not hold if we delete
Foundation from our axioms. [Consider the model of Exercise 5.6.]
6.2. 
Show that, if we do not assume the axiom of Foundation, we still have
(Vx)((x is regular) <^> (3a e ON)(x e VJ)
where 'x is regular' is defined as in the proof of Theorem 5.1.
6.3. 
Show that rank(x) = rank(TC(x)) and that
rank(x) = {rank(>>) | y eTC(x)}
for all sets x.
6.4. 
Show that any member of Vw + 1 — V^ is infinite, and deduce that the
class HF defined in Exercise 5.4 is exactly the set Vm. Show also that the
class HC of hereditarily countable sets (see Exercise 5.5) is a subset of
Va for a suitably chosen a.
6.5. 
Define a binary operation — on ordinals such that
(a) a - $ = 0 if a < 0, and
(b) p + (a-p) = 0Lifa^p.
Give an example of a pair of ordinals (a, /?) with a > /?, for which there
does not exist y with y + /? = a.
6.6. 
(The division algorithm for ordinals.) Let a and f$ be ordinals, ft # 0.
Show that there exists a unique pair (y, 3) such that OL = P .y + 3 and
3 < p. [Hint: first show that there exists / such that a < p. / , and that
the least such / is a successor.]
6.7. 
(a) Let a and /? be ordinals. Show that the set F of all functions ft -• a is
linearly ordered by lexicographic ordering (i.e.
(/ < g)o(3yeP)((f(y) 
< g(y)) A (V<5 < y)(f(3) = g(3))) ),
but is not well-ordered unless /? is finite.
(b) A function / : ft -* a is said to have finite support if {y e /? | f(y) ^ 0}
is finite; let F o c F be the subset of functions of finite support. Show
that F o is still not well-ordered by lexicographic ordering, but that it is
well-ordered by reverse lexicographic ordering (i.e. / < g iff/(y) < g(y)
for the largest y at which they differ).
6.8. 
We define the ordinal exponential OLP, for ordinals a and ft, by recursion

Ordinals and well-orderings 
77
in /?, as follows:
<x°=l
<x
p — ccy. a, 
if p = y + is a successor
OL
P = \J {ay\y <p} 
if ^ is a nonzero limit.
(a) Prove that <xfi is the order-type of the well-ordered set (Fo, r.l.o.)
defined in Exercise 6.7(b).
(b) Prove that the laws afi+y = <xfi .<xy and afi-y = (<x')y hold for all
(c) Find a triple (a, 0, y) such that (a£)y # a7. £y.
6.9. 
A function-class F: ON -• ON is called a normal function if
(a) (Va, /»)((« < P) => (F(a) < F(0))), and
(b) (Vx s ON)((x # 0 ) => (F(|J x) = U (^(a) Ia e^D) (equivalent^,
F is 'continuous' at limits).
If F is a normal function, show that a < F(a) for all a e ON, and that
is the least ft e ON satisfying a < /? = F(j5). Hence show that there exists
a normal function G: ON -> ON (called the derivative of F) such that
the values of G are precisely the fixed points of F.
If P and y are ordinals with y # 0, show that the functions F^ and Gy
defined by F/3(a) = /? + a and Gy(a) = y . a are normal. What are their
derivatives?
6.10. Show that the function a h->coa (defined as in Exercise 6.8) is a normal
function in the sense of Exercise 6.9. Hence show that every nonzero
ordinal a has a unique representation of the form
a = co
ao. a0 + co"
1 .a1+... 
+ co
a».a n,
where a ^ a0 >a x > ... >aw and aOial9... 
,an are nonzero natural
numbers. [This representation is called the Cantor Normal Form
of a.]

7
The axiom of choice
We saw in the last chapter that ordinals (or equivalently well-
orderings) are useful things to have around. Moreover, any model of
set theory contains 'arbitrarily large' ordinals: not only is the class
ON not a set (if it were, it would be a member of itself by Lemma 6.2
and Corollary 6.4(b), contradicting the well-foundedness of ordinals
- this is known as the Burali-Forti paradox), but we have
Lemma 7.1 (Hartogs' Lemma). For any set a, there exists an
ordinal a which cannot be mapped injectively into a.
Proof, OL can be mapped injectively into a iff a is the order-type of
some well-ordering of a subset of a. We can form the set 5 ^ gP(a x a)
of all well-orderings of subsets of a using the Power-set and
Separation axioms, and Mostowski's Theorem in fact produces a
function-class which sends every well-ordering to its order-type; so
by Replacement the ordinals which can be mapped injectively into a
form a set y(a), say. y(a) is clearly an initial segment of ON, and hence
is itself an ordinal; and it cannot be mapped injectively into a. 
•
Nevertheless, for many purposes we would like something better
than this: namely a bijection between a and an ordinal, or
equivalently a well-ordering of the whole of a. The need for such
became apparent in the last years of the nineteenth century, when G.
Cantor began to prove results in point-set topology by transfinite
induction methods. In 1904 E. Zermelo published his 'Beweis, dass
jede Menge wohlgeordnet werden kann' (Proof that every set can be
well-ordered), in which he used for the first time (explicitly, at any
rate) a new principle about sets which became known as the axiom of
choice.

The axiom of choice 
79
This axiom immediately attracted controversy, essentially because
it differs from the other axioms of set theory [apart from Foundation]
in asserting the existence of something which is not specified exactly
in terms of its members, but which can only be produced by making
arbitrary choices. Explicitly, the axiom says that if (at \ i el) is a family
of sets (indexed by a set /) and for each i e / at is nonempty, then there
exists a function /: / -> (J {a{ \iel} with the property that /(/) e at for
each iel. As a particular case, the axiom asserts that for any set a
there is a function g:(0>a — {0}) -+a such that g(b)eb for each
bedom(g); but this particular case implies the general one by taking
a = (J {at | i el}. A function g as above is called a choice function for
the set a.
Clearly, if / is finite we do not need any new axiom to define a
function / as in the last paragraph; the case of interest is thus when /
is infinite. Even here there may, in particular cases, be some
'uniformity' about the sets at which enables us to define / without
making infinitely many choices: for example, if we had an infinite set
of pairs of shoes, we could define the function which chooses the left
shoe from each pair. (But if we had an infinite set of pairs of socks,
things would be more difficult.)
Because of its controversial nature, mathematicians generally
prefer not to regard the axiom of choice as one of the basic axioms of
set theory, but to invoke it only when it is clear that the result they are
aiming at cannot be achieved without it. Thus a great deal of work
has been done on studying set-theoretical and mathematical
statements which are equivalent (in the presence of the axioms of ZF
set theory) to the axiom of choice, or to weak versions of it. One such
is the result for which Zermelo introduced the axiom: the well-
ordering theorem.
Proposition 7.2. For a set a, the following are equivalent:
(i) a can be well-ordered,
(ii) a has a choice function.
Proof. Given a well-ordering < of a, we may define a choice function
g: {0>a - {0}) -+aby g(b) = <-least element of b.
Conversely, let g:(0>a — {0}) ->abea choice function. If a = 0
we have nothing to prove; otherwise, we define a function-class

80 
Notes on logic and set theory
F:ON -> a by recursion:
If {F(P) | fi < a} # a, then F(a) = </(a - {F(f) \ fi < a});
otherwise F(a) = #(a) (= F(0)).
By Lemma 7.1, there exists ye ON such that the restriction of F to y
isn't injective. But the only way it could fail to be injective is for the
second clause of the definition to come into operation, i.e. there must
exist oi<y with {F(/?) | j? < a} = a. Consider the least such a: then F\a
is bijective, so we may transfer the well-ordering of a along it to get a
well-ordering of a. 
•
Remark. Proposition 7.2 is usually stated in the 'global' version
(AC) o (Every set can be well-ordered);
but it's sometimes useful to have the 'local' version which applies to a
particular set a, even when AC doesn't hold globally. Our proof of
(ii) => (i) is not the same as Zermelo's original proof, since we used
Replacement (which wasn't available to Zermelo) in the proof of
Lemma 7.1; Zermelo's method is sketched in Exercise 7.2 below.
In applying the axiom of choice to other areas of mathematics, the
well-ordering theorem is often useful (and was extensively used by
mathematicians in the 1920s and 1930s); but it has now been largely
superseded by the result generally known as Zorn's Lemma or
HausdorfFs Maximal Principle. The latter name is more correct,
since Hausdorff published a version of it in 1909, some 26 years before
Zorn; but it attracted little attention at the time, and it was not until
Zorn's paper was published that the maximal principle began to be
widely used as a substitute for the well-ordering theorem. (Also,
Hausdorff has many other things named after him, whereas Zorn's
only claim to fame is his Lemma.)
Before we state it, a bit of terminology: a chain in a partially
ordered set (a, ^) is a subset b which is linearly ordered by the
restriction of < (i.e. ^ and ^) to b x b. We say (a, <) is inductive if
every chain bin a has an upper bound (in a, not necessarily in b). Note
that, since 0 is a chain, an inductive p.o. set must in particular be
nonempty. A maximal element of (a, <) is an element m such that
(Vx ea)((m < x) => (m = x)). Then Zorn's Lemma asserts
(ZL) Every inductive partially ordered set has a maximal element.

The axiom of choice 
81
Proposition 7.3. AC is equivalent to ZL.
Proof. Assume AC holds: let (a, <) be an inductive p.o. set with no
maximal element. Let c be the set of chains in a; by AC, there exist
functions
g:a-+a 
such that (Vxea)(x <g(x))
and h:c-+a 
such that (Vyec)(h(y) is an upper bound for y).
Now define F: ON -> a recursively by
and F(a) = g(h({F(fi) | /? < a})) if a is a nonzero limit ordinal.
An easy induction shows that F is strictly order-preserving, and in
particular injective; but this contradicts Lemma 7.1.
Conversely, suppose ZL holds and let a be any set. Let b be the set
of partial choice functions for a (i.e. functions / defined on a subset of
(&a-{0}) 
and satisfying f(c)ec for all cedom(/)). We may
partially order b by setting f ^g iff g extends /; then (b, <) is
inductive since the union of a chain of partial choice functions is a
p.c.f. (and in particular the empty function is a p.cf.). So b has a
maximal element f0, say. Suppose dom(/0) ^ (2Pa — {0}); then by
choosing ce(0>a - {0} -dom(/0)) 
and dec we may define
f1= /0 u {<c,d}}. Now /i efr and f0 < fx, contradicting maximality
of /0; so /0 must be a global choice function for a. 
•
The style of the second half of the proof of Proposition 7.3 is
entirely typical of arguments involving Zorn's Lemma. For example,
one can give a direct proof of the well-ordering theorem from ZL, by
applying it to the set of all partial well-orderings of a set a (= well-
orderings of subsets of a), partially ordered by the relation 'is an
initial segment of. We shall meet some further examples below.
Next, we list some examples of the applications of AC in areas of
mathematics other than set theory. One of the most famous comes
from general topology:
Theorem 7.4 (Tychonoff s Theorem). If AC holds, than an
arbitrary cartesian product of compact topological spaces is
compact.

82 
Notes on logic and set theory
This was proved by A. N. Tychonoff in 1929 using well-ordering;
the proof involves too many topological ideas to be given here. In
1950 J. L. Kelley showed that the converse of TychonofFs Theorem
holds; his argument is quite simple, and is sketched in Exercise 7.3
below.
Next, one from ring theory:
Theorem 7.5 (Maximal Ideal Theorem). If AC holds, then any
proper ideal in a ring (with 1) is contained in a maximal
(proper) ideal.
Proof. Apply ZL to the set of proper ideals which contain the given
one. To verify that this set is inductive, we need to show that the
union of a chain of proper ideals is proper; this is true because an
ideal is proper iff it doesn't contain 1. 
•
The Maximal Ideal Theorem was first proved (using well-ordering)
by W. Krull in 1927; the fact that it too has a converse was proved
much more recently (in 1979, in fact) by W. Hodges.
Theorem 7.6 (Hamel's Theorem). If AC holds, then any vector
space has a basis.
Proof. Apply ZL to the set of linearly independent subsets of the
space, ordered by inclusion. Since a set is l.i. iff each of its finite
subsets is l.i., it's easy to show that this is inductive. The proof that a
maximal l.i. set must be a spanning set is straightforward. 
•
This result was proved by W. Hamel in 1905 (for the particular case
of U as a vector space over Q); it is thus one of the earliest
applications of AC outside set theory. Again, the converse is much
more recent: in 1966 J. D. Halpern proved that the familiar assertion
'Any linearly independent set in a vector space can be extended to a
basis' implies AC (part of his argument is sketched in Exercise 7.11
below), and in 1983 A. R. Blass proved that 'Every vector space has a
basis' implies AC. Halpern's proof allows you to fix the underlying
field before you start, but Blass's doesn't; thus it is still an open
problem whether, for example, 'Every vector space over R has a basis'
implies AC.
The last three results may all be considered 'pleasant'
consequences of AC, in that they are important and useful tools in the

The axiom of choice 
83
development of the subjects to which they belong. (The same applies
to the result, fundamental to the development of Galois theory, that
AC implies that every field has an algebraic closure.) But in other
areas the effect of AC can be less benign: a good example is measure
theory, where AC implies the existence of subsets of IR which are not
Lebesgue measurable. (It was shown in 1970 by R. M. Solovay that if
we are willing to jettison AC - and to make certain other set-theoretic
assumptions - then we can find a model of ZF set theory in which
every set of real numbers is measurable.)
A more spectacular 'unpleasant' consequence of AC is the so-called
Banach-Tarski paradox. Banach and Tarski showed that, assuming
AC, it is possible to decompose the unit ball in (R3 into a finite number
of disjoint pieces, and then reassemble two copies of the unit ball from
congruent copies of these pieces (i.e. sets onto which the original
pieces can be mapped by Euclidean motions of IR3). [The argument is
too complicated to give here; there is a good account of it on pp. 3-6
of The Axiom of Choice by T. J. Jech (North-Holland, 1973).]
Because of paradoxical results like this, mathematicians have
devoted a good deal of study to weaker 'choice principles' which do
not imply AC but which may be sufficient for the development of
particular areas of mathematics. One of the most important is the
(Boolean) Prime Ideal Theorem, which is the assertion that every
nontrivial Boolean algebra has a homomorphism into 2. (A prime
ideal in a Boolean algebra is a subset satisfying closure conditions
which make it the kernel of such a homomorphism, i.e. the set of
elements mapped to 0. The maximal consistent set S' which we
constructed in the proof of the Completeness Theorem (2.5) is thus
the complement of a prime ideal - such a set is called a prime filter -
and in fact (see Exercise 7.5) the Completeness Theorem for
Propositional Logic (within a given model of set theory) is equivalent
to the Prime Ideal Theorem.)
D. S. Scott showed in 1954 that the Prime Ideal Theorem is
equivalent to the assertion 'Every proper ideal in a commutative ring
(with 1) is contained in a prime ideal' (cf. Theorem 7.5 above; recall
that maximal ideals in a commutative ring are prime, but not in
general conversely); and J. Los and C. Ryll-Nardzewski showed at
about the same time that it is equivalent to 'An arbitrary cartesian
product of compact Hausdorff spaces is compact' (cf. Theorem 7.4).

84 
Notes on logic and set theory
Both of these results have recently (1983-4) been extended, as a result
of work by B. Banaschewski, A. R. Blass and P. T. Johnstone: they
have shown that the word 'commutative' may be omitted from the
ring-theoretic assertion, and that the word 'HausdorfF in the
topological one may be replaced by the much weaker condition
'sober'.
The Prime Ideal Theorem (PIT) implies that every set can be
linearly ordered (cf. Exercise 7.6), which in turn implies the axiom of
choice for families of finite sets (cf. Exercise 7.8). Neither of these
implications is reversible, and the implication (AC => PIT) is also
irreversible; the latter fact was first proved by J. D. Halpern in 1963.
(We shall have a little to say about the technology of proving such
'independence' results in Chapter 9.)
Another obvious way of restricting the axiom of choice, apart from
restricting the size of the sets in the families for which we demand
choice functions, is to restrict the size of the families themselves. We
have already remarked that we don't need any extra axiom to make a
finite number of choices, so the first interesting case of this is the
assertion that every countable family of nonempty sets has a choice
function. Actually, this 'axiom of Countable Choice' is a little too
weak for most of the situations where we need to make countably
many arbitrary choices, since we often want to make them
sequentially, in such a way that the range of values from which we
make the nth choice depends on the preceding n — 1 choices. A way of
expressing this is the axiom of Dependent Choices, formulated by P.
Bernaysin 1942:
(DC) If r is a binary relation on a set a such that
(Vxea)(3yea)«x9y}er)
and b is any element of a, then there exists f:co->a such that
/(0) = b and (Vneco)«/(n),/(n + )>er).
Uses of DC are quite common in mathematics, often to prove that
two definitions of a concept are equivalent. A good example is given
by the two definitions of a Noetherian ring, as a ring in which every
ideal is finitely generated, or as a ring in which every increasing
sequence of ideals is eventually constant: if we are given a strictly
increasing sequence of ideals, then the union of the terms of the
sequence is an ideal which cannot be finitely generated, but to go in

The axiom of choice 
85
the opposite direction from a non-finitely-generated ideal to an
increasing sequence of ideals requires a sequence of dependent
choices. A similar example from within set theory itself is
Proposition 7.7. Assume DC holds. Then a relation-class R is well-
founded iff there are no infinite ^-descending sequences,
where an /^-descending sequence is a function / with domain
co such that
(Vneco)((f(n+),f(n))eR).
Proof. If / is an /^-descending sequence, then {f(n)\neco} is a
nonempty set with no /^-minimal member. Conversely, if we are given
a set a with no /^-minimal member, then a straightforward
application of DC produces an /^-descending sequence of members
of a. 
•
In particular, in the presence of DC, the axiom of Foundation is
equivalent to the assertion that there are no infinite e-descending
sequences.
There are also numerous applications of DC in topology; for
example, in the proof that compactness implies sequential
compactness in first countable spaces, and in the proof of Urysohn's
Lemma about continuous real-valued functions on normal spaces.
Exercises
7.1. A choice function g:(0>a — {0}) -»a is said to be orderly if
g(bvc) = g({g(b)9g(c)})
for all nonempty sets b,c^a. Show that g is orderly iff it is induced (as
in the first half of the proof of Proposition 7.2) by a well-ordering of a.
[Hint: if g is so induced, we can recover the ordering by
(x<y)o(g({x,y}) 
= x).']
7.2. Let g: (^a — {0}) -• a be a choice function. We shall say that a subset
c of &a is closed if
(i) (b EC and b # a) implies (b u {g(a — b)} ec), and
(ii) the union of any chain of members of c belongs to c (so that in
particular 0ec).
(a) Show that there is a unique smallest closed set 
co^^a.
(b) An element b of c0 is called a pinch point if it is comparable (for the

86 
Notes on logic and set theory
inclusion ordering) with every other member of c0. Show that the set of
pinch points of c0 is closed, and deduce that c0 is linearly ordered
by c .
(c) Show that for any xea there is a unique largest bec0 with x$b,
and that for this b we have x = g(a — b).
(d) Deduce that a is well-ordered by < , where
((x<y)o(3bec0)((xeb)A(y$b))).
[This is (essentially) Zermelo's proof of the well-ordering theorem; cf.
the Remark after Proposition 7.2.]
7.3. (a) Show that the axiom of choice is equivalent to the assertion that an
arbitrary cartesian product of nonempty sets is nonempty.
(b) Let (flf \iel) be a family of nonempty sets, and for each iel let
bt = at u {oo}, where oo £ (J {a( \iel}. 
Topologize bt so that its open
sets are 0 , {oo} and all subsets with finite complements; observe that
b{ is compact. By considering the closed subsets ct= {feb\ f(i) #00}
of the product space b = Yliei h, show that the assertion 'A product of
compact topological spaces is compact' implies the axiom of choice.
7.4. A selection function on a set a is a function / : &a -• 0>a such that
f(0) = 0 and 0 # f(b) c b for all b e 0>a - {0}, the latter inclusion
being strict unless b is a singleton. Suppose a has a selection function /,
and let g: a -• 2 (a e ON) be any transfinite sequence of Os and Is. We
define a subset b(g) of 0 by recursion on a, as follows:
if a = 0, 
b(g) = a
if a = fi + and #(0) = 0, 
b(g) = / ( % |,))
if a is a nonzero limit, 
b(g) = f] {b(g\y) \ y < a}.
Show that there exists a such that b(g) has at most one element for each
g with domain a, and deduce that there exists an injection a -• ^a.
Conversely, if a is a subset of ^ a for some ordinal a, show that a has a
selection function. [Hint: for each b^a with at least two elements,
consider the least pea such that ft belongs to some member of b but
not to all of them.]
7.5. 
Let P be a set of propositional variables, and let S be a set of compound
propositions with variables from P. Define a relation = on the free
Boolean algebra FP by setting
p = q 
iffS\-(poq).
Show that = is a Boolean algebra congruence on FP (i.e. that the
quotient FP/= inherits a Boolean algebra structure from FP), and

The axiom of choice 
87
that FP/= is nontrivial (i.e. has more than one element) iff S is
consistent. Hence show that the Prime Ideal Theorem is equivalent to
the Completeness Theorem for Propositional Logic.
7.6. Show that the Prime Ideal Theorem implies that every set can be
linearly ordered. [Hint: given a set a, apply the Compactness Theorem
to a propositional theory whose models are linear orderings of a.]
7.7. Show that the assertion 'Every set has a selection function' (cf. Exercise
7.4) implies that every set can be linearly ordered. [Hint: use Exercise
6.7(a).]
7.8. Show that the assertion 'Every set can be linearly ordered' implies that
every family of nonempty finite sets has a choice function.
7.9. A multiple-choice function for a family of sets (at | ie/) is a function /
with domain / such that, for each iel, f(i) is a nonempty finite subset
of at. If every family of nonempty sets has a multiple-choice function,
prove that every linearly orderable set can be well-ordered.
7.10. Suppose that the power-set of any well-ordered set can be well-
ordered. Show that Va can be well-ordered for each a e ON, and deduce
that AC holds. [This is harder than it looks; remember that we can't
make infinitely many arbitrary choices of well-orderings for Vas. To
well-order Va when a is a limit, begin by choosing a well-ordering of
&y, where y is the least ordinal not mapping injectively into Va, and use
this to construct a 'uniform' sequence of well-orderings of (Vp \ p < a).]
7.11. Let K be a field, and let (at \ iel) be a family of nonempty sets. (We
shall assume for convenience that the at are pairwise disjoint.) Let Kbe
the K-vector space with basis a = [j {at\iel}, 
and let Vo be the
subspace consisting of those finite sums £ k} Xj (^ eK,XjEa) such that,
for each iel, the sum of those coefficients X} for which x^ea{ is 0.
Suppose Vo has a complementary subspace Vx. Show that for each iel
there is a unique vt e Vx such that, for all x eai9 (x - vt) e Vo. Deduce
that (at\iel) has a multiple-choice function.
7.12. Use Zorn's Lemma to prove the axiom of Dependent Choices.

8
Cardinal arithmetic
Informally, cardinal arithmetic is what remains of set theory when
you forget the fact that the members of a set are themselves sets (with
their own particular structure), so that the only comparison you can
make between two sets is to ask whether one has more members than
the other. Slightly less informally, we'd like to define a cardinal (as
Bertrand Russell proposed) to be an equivalence class of sets under
the relation =, where
(x = y) o (3/)(/ is a bijection x -> y).
Unfortunately, the equivalence classes of this relation (except for the
class {0}) are all proper classes; for example, the class of all singleton
sets is itself in bijective correspondence with V. Since we wish to
manipulate cardinals within set theory, it is convenient to find some
way of representing these equivalence classes by sets; that is, we seek
a function-class card: V -• V with the property that
(Vx, j>)((card(x) = card( JO) o (x = y)). 
(*)
There are two standard ways of defining such a function,
depending on whether or not we assume the axiom of Choice. If we
do, then each = -equivalence class contains at least one ordinal by
Proposition 7.2, and so we may represent each class by the least
ordinal which it contains; i.e.
cardi (x) = f] {a e ON | (x = a)}.
[If you dislike forming the intersection of a class rather than a set, you
may replace ON by the ordinal y(x) constructed in the proof of
Lemma 7.1.] An ordinal is said to be initial if it is the least ordinal in
some =-equivalence class: every finite ordinal is initial, but infinite

Cardinal arithmetic 
89
ordinals are much rarer. Note that the Hartogs function x\—>y(x)
(cf. Lemma 7.1) takes values in the class of initial ordinals.
If we do not have the axiom of Choice, then it seems unlikely that
we can define a cardinal function which picks out a single element of
each equivalence class; but what we can do is to pick out a nonempty
subset of each class, by the following device (due to D. S. Scott).
Define the essential rank of a set x [note: this is not standard
terminology] by
ess rank(x) = f] {a eON | (3y)((mnk(y) = a) A (y = x))},
and then define
card2(x) = {ye Kessrank(JC) + 11 (y = x)},
which is a set by Separation. Then it is clear form the definition
that x = y implies ess rank(x) = ess rank(y) and hence card2(x) =
card2(y); and conversely since we have
(Vx)((card2(x) # 0 ) A (VzGcard2(x))(z = x))
we can deduce x = y from card2(x) = card2(y).
Henceforth, we shall use 'card' to denote either of the functions
cardx and card2; but it really doesn't matter which one we use, since
the only property of the cardinal function we shall ever require is the
property (*). [However, even if we are using cardx, we shall find it
convenient to distinguish notationally between an infinite initial
ordinal and its cardinal, if only because the sum and product
operations we're going to introduce on cardinals don't agree with
ordinal sum and product. On the other hand, we shall tend to confuse
finite cardinals with natural numbers, even if we are using card2. Note
also that we shall tend to transfer epithets from sets to their cardinals;
thus we shall speak of a cardinal being infinite, well-orderable, etc.,
when we mean that the corresponding property holds for the sets
whose cardinal it is.] Thus when we define arithmetic operations, etc.,
on cardinals, what we are really doing is defining operations on sets
and verifying that they respect the relation =.
We shall find it convenient, for this chapter, to adopt the
convention 
that 
m,n,p,... 
will denote cardinals 
and 
the
corresponding capital letters M,iV,P,... denote sets of the
corresponding cardinalities. We also define a normal function (cf.

90 
Notes on logic and set theory
Exercise 6.9) ai—• coa by recursion:
(J00 = (O
™* = y(wp) 
ifa = j?+
coa = (J {(Op | jSea} if a is a nonzero limit.
Then it is easy to see that the coa are all the infinite initial ordinals.
Following Cantor, we shall write Ka for card(coa); in particular, Ko is
the cardinality of all countably infinite sets.
With these preliminaries out of the way, we may start doing some
cardinal arithmetic. If m and n are cardinals, we write m ^ n to mean
that there exists an injection M -» N, and m ^ *n to mean that either
m = 0 (= card(0)) or there exists a surjection N -+ M. Clearly, these
definitions do not depend on the choice of representatives M and N.
(We also write m < n for (m < n and m ^ n), etc.) They are related by
Lemma 8.1. (i) If m ^ n , then
(ii) If m ^*n and n is well-orderable, then
Proof, (i) The case m = 0 is trivial, so suppose M ^ 0 and we have
an injection / : M -» AT. Choose x o e M and define g:N ^ M by
g(y) = the unique x e M with /(*) = y, if such exists,
= x0 otherwise.
Then g is a surjection.
(ii) Again, the case m = 0 is trivial. Suppose we have a surjection
g:N -+M and a well-ordering < of N. Then we may define an
injection f:M-+N 
sending xeM 
to the <-least element of
{yeN\g(y) = x}. 
•
In particular, if AC holds then < and <* coincide; in general,
however, they may be different. It is easy to see that both < and ^ *
are reflexive and transitive, and ^ is actually a partial order:
Proposition 8.2(the Cantor-Bernstein Theorem). If m^n 
and
then m = n.
Proof. Let / : M -> N and g:N-+M 
be injections. To construct a
bijection M -+ N9 it is sufficient to partition M as a disjoint union
Mo u M l 5 and N as NouNl9 
such that / restricts to a bijection
Mo -• No and g to a bijection JVj -• M x. But finding such a pair of
partitions is equivalent to finding a fixed point of the function

Cardinal arithmetic 
91
h\0>M-* &M defined by h(A) = M-g[N- 
f[Aj] 
(where we write
f[A] for {/(x) | x GA}, etc.). It is clear that the function h preserves
inclusions, i.e. Ax ^ A2 implies h(AY) £ h(A2).
Let X = {A e 0>M \ A <= h(A)}9 and let M o = [j X. Then for every
AeX,v/e 
have ,4 c h(A) c fc(M0), and hence M o c /z(M0). Hence also
h(M0)ch(h(M0))9 
so / I ( M 0 ) G I and thus h(M0)^M0. 
So Mo is a
fixed point of h, as required. 
•
However, < * may fail to be a partial order if we do not assume AC
(see Exercise 8.6). The next obvious question to ask is when < is a
linear order.
Proposition 
8.3. In a model of set theory, the following are
equivalent:
(i) 
< is a linear ordering of the class of cardinals,
(ii) < is a well-ordering of the class of cardinals,
(iii) AC holds.
Proof, (iii) =>(ii): If AC holds, then the class of cardinals is order-
isomorphic to the class of initial ordinals, which is well-ordered as a
subclass of ON.
(ii) => (i) is trivial.
(i) => (iii): If x is any set, then by Lemma 7.1 we have card(y(x)) ^
card(x). So (i) implies that we have an injection x -> y(x), which
enables us to well-order x. 
•
In the absence of AC, the law of trichotomy holds for finite
cardinals, but it may even break down when one of the cardinals
involved is Ko. If m ^ Ko, then an easy induction shows that we have
injections n -> M for each natural number n, but it requires an
application of (countable) choice to construct an injection co -» M. A
set M is said to be Dedekind infinite if Ko ^card(M); the following
equivalence is easily established, even without Choice.
Proposition 
8.4. A set M is Dedekind infinite iff there exists an
injection M ^ M which is not surjective.
Proof. Given an injection f:co-> M, define g:M -+ M by
g(x) = f(n+l) 
if(3n60>)(/(n) = x)
= x 
otherwise.

92 
Notes on logic and set theory
Then g is injective, but not surjective since /(0) $im(g). Conversely,
given an injection g.M^M 
and xeM — im(#), define 
f:co-^M
recursively by /(0) = x, f(n + 1) = g(f(n)); then an easy induction
shows that / is injective. 
•
Next 
we 
define 
cardinal 
addition, 
multiplication 
and
exponentiation:
m + n = card(M IIN) 
(= card(M u N) if M and N are disjoint)
m.n = card(M x N)
mn = card(MN) 
(where MN = {/1 /: N -> M}).
If we assume AC, we may also define infinite sums and products of
cardinals by ^ ^ m ^ c a r d ^ ^ M , ) (where the infinite disjoint
union ]JI6/Mf is defined to be (J {Mt x {i} | iel}) and f|. e /m f =
card(fjie/Mf). However, these operations may not be well-defined
without AC, since if we are merely given that card(Mf) = card(MJ) for
each i, we cannot prove card(]JI-e/Ml-) = card(]JI-e/Ml-) without
choosing a particular bijection M{ -• M\ for each i.
The next lemma summarizes the properties of the finitary cardinal
operations (we leave those of the infinitary operations as an exercise):
Lemma 8.5. (a) If m^n, then m + p^n + p, m.p^n.p 
and
mp ^ np.
(b) If m^*n, then m + p^*n +p, m .p^*n .p and pm ^p"
unless p = m = 0.
(c) 0 + m = m,0.m = 0,1 .m = m,m°= 
l.m1 =mand l m = 1.
(d) 1 + m = m iff m is Dedekind infinite.
(e) m + n = n + m and m + (n + p) = (m + n) 4- p .
(f) m.n = n .m and m . (n .p) = (m .n).p.
(g) m.(n + p) = m.n + m.p and m(ll+p) = m" .mp.
(h) m(n'p) = {mn)p and (m . n)p = mp. «p.
(j) If a and /? are ordinals, then card(a + fi) = card(a) 4-
card(j8) and card(a . jS) = card(a). card(j8), but card(a^)/
card(a)card(^ in general,
(k) If m ^ 2 and n ^ 2, then m + n^m .n.
Proof. Almost all of these are trivial when translated into assertions
about bijections (etc.) between certain sets. We comment on a few of
them:

Cardinal arithmetic 
93
(b)(iii): Given a surjection f:N ->M, the operation of composing
with / defines a function PM -> PN, which is easily seen to be injective.
If m = 0, then pm = 1 ^ pn unless p = 0.
(d) follows from Proposition 8.4: given an injection g: M -> M as in
the proof of 8.4, we have m = m + card(M — im(#)) ^ m + 1 ^ m, so
m = m 4-1 by Proposition 8.2. The converse is similar.
(g)(ii): We have a bijection M{NuP) -+MN x Mp (if N and P are
disjoint) sending / to </| N,/| P>.
(j)(i) and (ii) follow from the synthetic definitions of ordinal sum
and product. For (j)(iii) take a = 2, /? = co; then card(a^) = Ko but
card(a)card(/0 = 2*° = card(^a>) ^ Ko by Cantor's diagonal argument.
(k) Choose distinct elements x0, xxeM and y0, y1 eN. Then define
f:MUN-+MxNby
/ « x , 0 » = <x,>;0> (xeM)
It is clear that / is injective. 
•
In the presence of AC, the addition and multiplication of infinite
cardinals becomes very simple; recall that in this case any infinite
cardinal is of the form Ka for some ordinal a.
Lemma 8.6. For any a, Ka. Ka = Ka.
Proof by induction on a. Define a well-ordering of coa x a>a by setting
It is straightforward to verify that this is indeed a well-ordering;
moreover, for each 6 < coa9 the subset S x 6 is an initial segment of
coa x coa, and every proper initial segment of coa x coa is contained in
one of this form. But for any such (5, either 5 is finite (in which case
card(<5 x d) < Ko ^ KJ or by the inductive hypothesis we have
card(<5 x <5) = card((5) < Ka. So we have constructed a well-ordering of
coa x coa in which every proper initial segment has cardinality < Ka,
which means that its order-type is at most coa. But card(coa x coa) ^ Ka
since Xa ^ 1, and so the order-type must be exactly coa; i.e. it defines a
bijection <ya x coa -• coa. 
•

94 
Notes on logic and set theory
Corollary 8.7. For any a, Ka + Ka = Ka.
Proof. 
From 
Lemma 
8.5, 
we 
have 
inequalities
N« ^ Ka + Xa ^ Ka. Ka, so the result follows from Lemma 8.6 and
Proposition 8.2. Alternatively, it can be proved directly by
constructing a suitable well-ordering of coa llcoa and arguing as in the
proof of Lemma 8.6 (cf. Exercise 8.7). 
•
There is in fact a converse to Lemma 8.6: if the equality m2 = m
holds for all infinite cardinals m, then AC holds (see Exercise 8.3). On
the other hand, the assertion '2m = m for all infinite m\ though not
provable from the axioms of ZF, does not imply AC.
Corollary 8.8. For all a and /?, Ka + K^ = Ka. K^ = K(auA).
Proof. Suppose a ^ /?. Then we have
K < K + K/l < K • ^ < ^ • *a = Ka
by Lemmas 8.5 and 8.6; an application of Proposition 8.2 yields the
result. 
•
There are similar results for infinite sums of infinite cardinals, if we
assume AC: if card(/)<Ka and m, < Xa for each iel, 
then
Zie/mf^^a> since we can use AC to construct an injection
LLe/ Mt ~> coa x coa. (The case a = 0 of this is the familiar assertion
that a countable union of countable sets is countable; note that it
requires (countable) Choice even in this case.) To get results on
infinite products, however, we need to investigate the behaviour of
cardinal exponentials; and this is less straightforward than addition
or multiplication, even with AC.
We can use Proposition 8.2 to achieve some reductions in the
problem of determining cardinal exponentials: for example, for any
P ^ a we have
2K ^ K*- ^ (2N°f* = 2(X"*-) = 2*S
and so our attention is focused on the function /:ON—• ON defined
by 2H' = K/(flt). Cantor's diagonal argument tells us that a < /(a) for
all a; and it is clear that a ^ /? implies / ( a ) ^ /(/?). Cantor spent
many years trying to prove the Continuum Hypothesis (CH) that (in
this notation) /(0) = 1; i.e. that the cardinality 2N° of the continuum
(the set of all real numbers) is the first uncountable (well-orderable)
cardinal. A natural extension of this was the Generalized Continuum

Cardinal arithmetic 
95
Hypothesis (GCH) that /(a) = a + 1 for all a. In 1938 K. Godel
showed that the GCH is consistent relative to the other axioms of set
theory; it does, however, imply AC (this follows from the result of
Exercise 7.10, or from Exercise 8.5 if GCH is reformulated so that it
doesn't refer to alephs). In 1963 P. Cohen showed that it is consistent
relative to the other axioms of set theory (including AC) that CH
doesn't hold; in fact, using his methods, one can show that there
are virtually no restrictions on the function / apart from those we
have mentioned, plus certain conditions involving limit ordinals (cf.
Exercises 8.8 and 8.9).
Exercises
[Note: the axiom of Choice should not be assumed in Exercises 8.1-8.6, but is
required in Exercises 8.8 and 8.9.]
8.1. If m ^ Ko, show that No ^ * 2m. [Hint: consider the mapping which sends
a subset of M to its cardinality if it's finite, and to 0 otherwise.] Deduce
that any cardinal of the form 22"1 is either < Ko or > Ko.
8.2. If m + n = m .n, show that either n <m or m^*n. 
[Hint: given a
bijection f.MUN 
-> M x N, consider whether the composite
/
N 
• MUN 
• MxN 
• M
is surjective, where n denotes projection on the first factor.]
8.3. Let m = card(M) be an infinite cardinal, and let n = card(y(M)). If
(m + n)2 = m + w, deduce from Exercise 8.2 that m < * w, and hence show
that M can be well-ordered. Deduce that the assertion Tor all Dedekind
infinite cardinals m, m2 — m' is equivalent to the axiom of Choice.
8.4. We write mo n to mean that m<n and, for all p, m^p^n 
implies
either m = p or p = n. If mo n and n is Dedekind infinite, show that
either y(M) = y(N) or n = n 4- card(y(M)) = m + card(y(M)).
8.5. Show that card(y(M)) ^*2(m2) [hint: consider the proof of Lemma 7.1].
Now suppose m o 2m for all infinite m; let m be an infinite cardinal, and
define a sequence of cardinals mt by
mo = m, mi + 1=2 m'.
Using Exercises 8.1 and 8.4, show that for some ieco we have mf = m,
and mi+1 = m, + card(y(M,)). Deduce, using Exercise 8.3, that M can be
well-ordered. [Thus the GCH, in the form 'mo2 w for all infinite m\
implies the axiom of Choice.]

96 
Notes on logic and set theory
8.6. Let us say that two elements R, S of ^(co x co) are similar if there exists a
permutation / of co such that
By considering equivalence relations on co with finite equivalence
classes, or otherwise, show that there is a set of pairwise dissimilar
elements of 0>(co x co) having cardinality 2X°. By considering similarity
classes of well-orderings, show that the set of all similarity classes of
elements of ^(co x co) has cardinality ^ Kj + 2K°. Deduce that if every
well-orderable set of real numbers is countable, then there exist
cardinals m and n with m^n and n^*m but m# n.
8.7. Define a well-ordering of coallcoa having order-type coa.
8.8. Let (mt \iel) and {nt \iel) be two families of cardinals, and suppose that
for each iel we have mf < nt. Prove that
iel 
iel
What can you deduce from this result (a) when m, = 0 for all i, and (b)
when mt = 1 and nt = 2 for all i? By taking / = w, m, = K; and nt = Kw for
all i, show that 2*° # Kw.
8.9. Show that
2(Iie/»"i) = FT (2mi)
16/
for any family of cardinals (m£ 11 e/). Deduce that if 2**1" = Kf + 1 for all
ieco, then 2^» = (XJX°.

9
Consistency and independence
Throughout our discussion of ZF set theory, we have been tacitly
assuming that it is consistent - or equivalently (if we assume the
Completeness Theorem holds in our meta-universe) that it has a
model. If so, then we know from the Lowenheim-Skolem theorems
that this model will not be unique, even up to isomorphism; but we
might still hope that ZF is a complete theory in the sense defined in
the proof of Theorem 3.7, i.e. that every sentence in the language of
ZF is either provable or refutable from the axioms. (Again assuming
the Completeness Theorem, this is equivalent to saying that any two
models of ZF are elementarily equivalent, i.e. that they satisfy exactly
the same sentences.)
It was thus a natural programme, once the axioms of ZF set theory
had been established, to seek to prove that it was both consistent and
complete (or alternatively, if it turned out not to be complete, to seek
extra axioms which would make it into a complete theory). This
programme was first explicitly proposed by D. Hilbert, around 1920;
but just ten years later K. Godel showed that it could not be carried
out, by proving his two Incompleteness Theorems. These assert,
respectively, that if set theory is consistent then it is incomplete, and
that if set theory is consistent then no proof of its consistency can be
formalized within set theory. Moreover, the incompleteness of ZF is
an 'essential' one, which cannot be remedied by adding finitely many
new axioms or axiom-schemes. (In contrast, the theory of
algebraically closed fields is incomplete, since the sentence '1 + 1 = 0'
is satisfied in some algebraically closed fields but not in others; but if
we add an extra axiom or scheme of axioms to specify what the
characteristic is, we do in fact obtain a complete theory.)

98 
Notes on logic and set theory
Before giving the precise statements of the Incompleteness
Theorems, we need a couple of preliminaries: the notion of an
interpretation of one theory in another, and the idea of formalizing
proofs and provability within Peano arithmetic. For the first of these,
we begin with an example: recall that we have already observed that,
if Kis any model of set theory, then the class of natural numbers in V
has the structure of a model of Peano arithmetic. Thus we have a
recipe for constructing models of PA from models of ZF; and the
recipe does not depend on any particular features of the ZF-model
from which we start, because it can be described entirely in terms of
the syntax of the two theories.
More generally, if Tx and T2 are first-order theories in languages J^i
and J^2> a n interpretation v:Tl—*T2 is a 'uniform' recipe for
constructing 7i -models from T2-models. It is specified by giving, first,
a formula v(x) of if2 (the idea being that if M is our T^-model then
[u(x)]M will be the underlying set of our Tx-model; for convenience
we shall assume that v has just one free variable x, although it is
possible to consider more general interpretations), and then for each
primitive function-symbol co (respectively predicate-symbol </>) of J^
a term i?w (respectively a formula v^) of 5£2 with the same number of
free variables. Given these, we may then inductively assign to each
term t or formula p of J^i a corresponding term vt or formula vp of J^2,
the only nontrivial point in the induction being that quantifiers must
be 'relativized to [u(x)]', i.e. u(Vx)p is (Vx)(i;(x) => vp). Then the
assertion that v is an interpretation of Tx in T2 means that, for each
axiom p of Tl9 vp is a theorem of T2.
Returning to our example of an interpretation PA -» ZF, we have
for v(x) the formula 'x is a natural number' (i.e.
(Vy)((y is a successor set) => (x ey)) 
),
the constant 0 and the unary operation 5 of the language of PA are
interpreted by the constant 0 and the unary operation ( ) +, and the
binary operations a and m are interpreted by ordinal addition and
multiplication. [We are cheating slightly here, in that our original
language for ZF did not have any primitive function-symbols, and so
did not contain the terms mentioned above; if we wish to interpret PA
in ZF as formulated in this language, then we must reformulate PA in
a language without primitive function-symbols, along the lines
indicated in Exercise 3.5.]

Consistency and independence 
99
For the second ingredient of the Incompleteness Theorems, we
need to recall the notion of a recursively presented theory, which we
last met (in the particular case of an algebraic theory) in Chapter 4.
For the general case, we suppose first that we have a language <£ with
countably many primitive symbols, which are enumerated in such a
way that the function assigning their arities is recursive. [Readers
who have skipped Chapter 4 will lose relatively little, in the discussion
which follows, by substituting the phrase 'definable by a formula in
the language of PA' whenever they see the word 'recursive'; those
who have read Chapter 4 should note that we shall be relying heavily
on Theorem 4.13, which proved that every recursive function is PA-
definable.] Note that if (as is the case with both ZF and PA) the set of
primitive symbols of the language is actually finite, then the
recursiveness of the arity function imposes no further restriction.
We further assume that we are given an enumeration, not only of
the primitive symbols of our particular language J^ but also of the
countably many 'standard symbols' (variables, parentheses, logical
connectives, etc.) which are used in constructing terms and formulae
of <£. A term t or formula p may thus be specified by giving the finite
sequence (no,n1,... 
,nk) of natural numbers corresponding to the
individual symbols which make it up; and this sequence may be
specified by the single number
2M°3"1.. .p^
(where pk denotes the (k + l)th prime number), which we call the code
or Godel number of the term or formula, and denote by T or rp"1 as
appropriate. A straightforward extension of Remark 1.1 shows that
we can construct an algorithm for determining whether a given
number is the code for a formula of if; i.e. the set of such codes is
recursive.
The precise details of the coding whereby we represent formulae of
<£ by natural numbers are not of great importance; but it is
important to note that, for any reasonable coding, the (algorithmic)
operations which we are accustomed to carry out on terms and
formulae will be coded by recursive functions. For example, for each
variable x there will be a recursive function subx such that
for each formula p and term t of !£. We now say that a theory 7, in a

100 
Notes on logic and set theory
language $£ as above, is recursively presented if the set of codes for
axioms of T is recursive. Clearly, this will be the case if T is specified
by a finite number of individual axioms plus a finite number of axiom-
schemes; thus both PA and ZF are recursively presented.
Now a derivation in 5£ is just a finite string of formulae, and so we
can also code them by natural numbers in a straightforward way.
Moreover, for a recursively presented theory T, the problem of
determining whether a given finite string of formulae is a derivation
from the axioms of T is algorithmically soluble; thus we have a
formula DerT(x,y) in the language of PA, such that PA|~DerT(m,n)
(for natural numbers m and n, regarded as closed terms in the
language of PA) iff m is the code of a derivation from the axioms of T
of the formula whose code is n.
When we are dealing with recursively presented theories, it makes
sense to consider interpretations v\T1-+T2 which are recursive, in the
following sense: first, the functions T i—• ri?r'1 and rp't\-^rvp't are
recursive (for this, it clearly suffices that their restrictions to the
primitive symbols of 5£x should be recursive), and second, there is a
recursive function which, given the code for an axiom p of Tl5
produces the code for a derivation of vp from the axioms of T2. Given
this, the process of converting a derivation of an arbitrary formula p
from the axioms of Tx into a derivation of vp from the axioms of T2
becomes algorithmic; so there are recursive functions / and g such
that f(rpn) = V 
a n d
PA f- (Vx, y)(DerTi(x, y) => DerT2(g(x), f(y))).
Until further notice, we shall assume that T is a recursively
presented theory equipped with a recursive interpretation v: PA -> T.
(For example, T might be PA itself, or ZF, or any extension of either
of these theories obtained by adding finitely many new axioms or
axiom-schemes.) To simplify the notation, we shall identify formulae
of PA with their interpretations in the language of T, whenever it is
possible to do so without confusion. We now introduce the unary
predicate 'is provable in T" by
PTT(y)o(3x)(DerT(x9y)).
Clearly, if T\-p then PA(-Pr r(V); the converse may not be true,
because PA does not have witnesses (i.e. the fact that we can prove a
sentence of the form (3x)q(x) in PA does not imply the existence of a

Consistency and independence 
101
closed term m such that PA\-q(m)). We can, however, formalize the
above implication in the sense that we can prove
because the process of constructing a proof of PrrCy) m PA from a
proof of p in T is an algorithmic one, and so can be coded by a
recursive function. For similar reasons, 'formalized modus ponens' is
provable in PA, i.e.
PA \- (Vx, y)«PTT(x) A PrT(imp(x, y))) => PiT(y)),
where imp is a recursive function such that imp(rp\ rq*) — r(p =>q)"1.
Now let p(x) be the formula ""• Prr(x) of PA (or its interpretation in
the language of T). Let c be a recursive function such that c{n) = rrC
for each natural number n (where the V on the right-hand side is
regarded as a closed term in the language of T), and let q(y) be the
formula p{sxxbx{y, c(y))). Finally, let m be the code for q(x). Then the
sentence q(m) asserts its own unprovability in T, in that we have
q(m) = p(subx(m9 c{m))) = p(subx(rq(x)\ 
rmn))
= p(rq(mY) =~-I>rTC q(mY).
Clearly, if Tis consistent then we cannot have T\-q(m); for, if we did,
then we should have PA\-PrT(rq(mY) and hence T\-~^q(m). Thus
q(m) is true (in an informal sense) but not provable in T; this gives us
an informal version of the First Incompleteness Theorem.
However, it is possible to have a consistent theory T such that
T\-~^q(m), because of the lack of witnesses in PA which we
mentioned earlier. Thus, to get a formal incompleteness proof, we
need to strengthen the assumption of consistency in some way. There
are various ways of doing this: the one originally used by Godel was
to demand that T should be co-consistent, which means that if p(x) is a
formula of PA with one free variable x, then we do not
simultaneously have T \- (3x)p(x) and T \- ~^p{n) for each closed term
n. If this condition holds, then it is easy to see that we cannot have
T\- ^qim); thus we have established
Theorem 9.1 (First Incompleteness Theorem). Let T be a
recursively 
presented, co-consistent 
first-order 
theory
containing a recursive interpretation of PA. Then T is
incomplete. 
•

102 
Notes on logic and set theory
For the Second Incompleteness Theorem, let ConT = ~~lPrr(rJ_"1)
be the formalized version of the assertion that T is consistent.
Theorem 9.2 (Second Incompleteness Theorem). Let T be a
recursively presented, consistent first-order theory containing
a recursive interpretation of PA. Then T^ConT.
Proof. Let q(m) be the unprovable sentence constructed above. We
shall show that PA |- (q(m) o ConT), so that Conr is also unprovable
in T.
In one direction, the implication is easy: (_L => q(m)) is a theorem of
T (as of any first-order theory; cf. Exercise 2.2), and so
Prr(r(-L => q(m)y) is a theorem of PA. By formalized modus ponens,
we obtain
PA\-(PrT(rr)=>PrT(rq(my)).
But q(m) is the sentence Try-C^m)"1), so we deduce
Conversely, we have 
PA\-(PrT(rq(my)=>PrT(rPrT(rq(myy))9
which is equivalent to PA\-(PTT(rq(my) =>PrT(p~1^(m)'1)). An
elementary logical argument, formalized in PA, then yields
PA\-(PrT(rq(my) =>PrT(r(q(m) A ^q(m)T))9
whence PA\-(PrT(r q(my)=> PrT(rl')). So
PA|-(Conr=>4(m)). 
D
The message of Theorem 9.2 is that we cannot hope to give a 'self-
supporting' proof of the consistency of any formal system which is
powerful enough to be used as a foundation for mathematics; in order
to prove the consistency of such a system 7, we have to make
assumptions which are stronger than T. [There is an obvious minimal
such assumption: namely, adopt Conr as an extra axiom. However,
for obvious reasons, we cannot hope to deduce the consistency of the
theory T u {ConT} from that of T.] On the other hand, we can hope
to prove relative consistency results of the form (ConTi => ConTz),
where Tx and T2 are as in Theorem 9.2; the rest of this chapter will be
devoted to results of this general kind. In particular, we shall be
interested in results of the form
(ConZF => ConZF _ {p} u {^p})

Consistency and independence 
103
where p is one of the axioms of ZF; we call this an independence result
for the axiom p.
The obvious technique for proving the consistency of T2 relative to
7i is to construct a recursive interpretation v\T2-*Tx\ for we then
have
for any p in the language of T2, and taking p = 1 yields the desired
result. In practice, it is almost always easier to think of these
interpretations in semantic terms, as constructions on models of Tx;
but it is important to notice that the constructions we describe
operate 'uniformly' on all models of Tx, and that they are really the
reflections of syntactic interpretations as defined earlier (so that, in
particular, the relative consistency results we obtain do not depend
on the Completeness Theorem).
Let us, for the moment, take 7i to be ZF. A particularly simple
class of interpretations T2 -• ZF arises from what are commonly
called standard models: in these we take some class M to be the
underlying (meta-)set of our T2-model, and interpret the membership
predicate in the language of T2 by itself in the language of ZF. (The
term inner model is also used if the class M is a set.) Many of the
axioms of ZF are inherited in a straightforward way by substructures
of this kind, as we saw in the Exercises at the end of Chapter 5: in
particular, if M is transitive then it inherits Extensionality and
Foundation from V9 and if M is 'super-transitive' (i.e. 
x^yeM
implies xeM) then it inherits Separation. (However, super-
transitivity is by no means necessary for M to satisfy Separation, as
we shall see later.) In this way we constructed, in Exercises 5.4 and
5.5, inner models HF, HC and HS consisting of hereditarily finite,
hereditarily countable and hereditarily small sets, which respectively
establish the independence of the axioms of Infinity, Power-set and
Union. [Actually, to prove that Replacement holds in HS, we need to
assume that the axiom of Choice holds in V, in order to show that the
image of a small set under a function is small (cf. Lemma 8.1(ii)); but
this is no hardship, since we shall shortly demonstrate the consistency
of AC relative to ZF.]
Each of the inner models HF, HC and HS can be presented as the
union of a 'hierarchy' like the von Neumann hierarchy, in which we

104 
Notes on logic and set theory
replace the successor clause Va+1 = 0>Va in the definition of the latter
by, for example,
HF a + 1 = {XG 0>UFa | x is finite}.
Thus we can regard them as 'slimmed-down' versions of the universe,
in which the full power-set operation & has been replaced by
something more restrictive. Another obvious way of 'cutting down'
the universe is to truncate the von Neumann hierarchy at some
ordinal a: if we stop at a successor ordinal a, the inner model Va will
fail to satisfy (at least) the Pair-set and Power-set axioms, but if we
stop at a limit ordinal we may get something more interesting. In fact
Va is simply another name for HF, as we saw in Exercise 6.4; but V^+w
provides us with an independence proof for the axiom-scheme of
Replacement. (Once again, we leave as an exercise the fact that VW + (O
satisfies all the other axioms of ZF; the reason why it fails
Replacement is that the set (in V)
{<n,co + w> | new}
defines a function-class in Vm+(a, whose domain is a set in J^,+to but
whose range is not.)
We cannot hope to demonstrate the independence of the axiom of
Foundation using a standard model; but in fact Exercise 5.6 provides
an independence proof for this axiom, using an interpretation where
the underlying meta-set is interpreted as itself, but the interpretation
of e is 'twisted' to yield a set which is a member of itself. On the other
hand, the relative consistency of Foundation can be shown using a
standard model: if V is a model for ZF — {Fdn}, then the class of
regular sets in V (which we sometimes describe informally as 'the
well-founded part of the universe') is a model of ZF. (Again, we leave
the proof of this as an exercise; most of it follows straightforwardly
from the result of Exercise 6.2.)
Our next goal is to prove the relative consistency of the axiom of
Choice, i.e. (ConZF => ConZF u{AC}). To do this, we shall follow Godel's
1938 proof, the idea of which is again to build a standard model by
'slimming down' the von Neumann hierarchy. Given a set x, let <£(x)
denote the language of set theory enriched by adding a family of
constants {y \ y ex}; of course, we make V into a structure for this
language by interpreting each y as y. We now define the set Def(x) of
definable subsets of x to be the collection of sets of the form

Consistency and independence 
105
{yex\p(y)}
where p(y) is a formula of if (x) with one free variable y, and all
quantifiers relativized to x. (Intuitively, if x is the collection of all sets
we have constructed up to some point in a recursive construction of
the universe, then Def(x) is the collection of all those subsets of x
which we are immediately forced to add if we want the axiom-scheme
of Separation to hold. The reason why we allow members of x to
appear as constants in the formula p is that they are possible values
for the parameters in an instance of the Separation-scheme.) We
now define the Godel hierarchy a i-+ La by setting
La = (J {Lp | P < a} if a is a limit ordinal.
We define the class L of constructible sets to be the union of all the La,
a G ON.
The Godel hierarchy grows much more slowly than the von
Neumann hierarchy; the two agree for a ^ a>, since any finite subset
of a set x is in Def(x), but La) + 1 is countable (since ^(Lw) 
is) and
hence cannot be the whole of V^ +1. (In fact La is countable for every
countable ordinal a.) On the other hand, the La fit together rather
well. We note first that if x is transitive then x ^ Def(x) (since if zex
we have z= {yex\yez}e 
Def(x)); and an easy induction shows that
each La is transitive. Also, if x has a well-ordering then so does the set
of primitive symbols of if(x); hence we can well-order the set of
formulae of if (x) with one free variable (e.g. lexicographically), and
so we obtain a well-ordering of Def(x). If x is both well-ordered and
transitive, then it is easy to arrange things so that x occurs as an initial
segment of Def(x) (with its original well-ordering); hence we can
recursively define a well-ordering of each La, and indeed of the entire
constructible universe L.
Proposition 
9.3. If V is a model of ZF, then L is a model of
ZFu{AC}.
Proof. The remarks in the preceding paragraph ensure that,
provided L is a model of ZF, it will also satisfy AC. The verification in
L of most of the axioms of ZF is straightforward; the two non-trivial
ones are Separation and Power-set. We discuss the latter first. Note

106 
Notes on logic and set theory
that L is not necessarily super-transitive; so we are not trying to prove
that the full power-set gPvx of a constructible set x is constructive,
but rather that
is a member of L. (On the other hand, 0>Lx will in general be larger
than Def(x): for example, Lui + 1= Def(Lw) is countable even in L (i.e.
there is a bijection co -• L(O + 1 which is a set in L), and so cannot be the
power-set of Lw in L.) However, for each y e 0>Lx there is an ordinal a
such that yeLa, and so by Replacement (in V) we can find an ordinal
y which is an upper bound for all such a. Now, if we rewrite the
definition of @>Lx as
{yeLy\(VzeLy)((zey)^(zex))},
we see that it belongs to Ly + l.
The verification of the Separation-scheme is similar. Let x be a
constructible set, and p a formula with one free variable y (the other
free variables having been replaced by constants corresponding to
elements of L). We must show that x n [p] L is a set in L. Now if a is
an ordinal large enough for La to contain x and all the sets appearing
as constants in p, then we have
the problem is that, if p contains quantifiers, it is not necessarily true
that [p] L nLa = [p]La (cf- Exercise 3.3). We must show that, given p,
there exists P such that [ p ] L n L p = [p]Lp; we do this by induction on
the structure of p, using the validity of Replacement in V in the case
when p has the form (iz)q. 
•
The model L also satisfies Godel's Axiom of Constructibility, which
is the assertion that every set is constructible (in symbols, V = L); i.e.,
if we perform the construction of the La within L, we end up with the
whole of L. (In fact a stronger result is true: for a given V9 L is the
unique smallest substructure of V which contains all the ordinals of V
and satisfies the axioms of ZF.) By what we have just shown, the
axiom V = L implies AC; it also settles the status of a number of other
assertions which cannot be either proved or disproved in ZF,
including the Generalized Continuum Hypothesis. [GCH is true in
L; intuitively, the reason for this is that a counterexample to GCH -
for example, a subset of ZPco whose cardinality is strictly between that

Consistency and independence 
107
of co and that of gPto - could not possibly be constructible, but the
actual proof of GCH in L is rather more complicated.]
It remains to discuss the independence of AC and of GCH. The first
'independence proof for AC was given by A. Fraenkel in 1922;
however, the model he constructed was not a model of ZF, in that it
contained 'atoms' ('Urelemente' in German) which were not sets (and
in particular had no members) but were allowed to be members of
sets. (It is intuitively clear that if we adjoin enough atoms to our
universe, and make them sufficiently indistinguishable, then we are
going to have difficulty in finding choice functions for sets of sets of
atoms. The indistinguishability is ensured by allowing some group of
permutations G to act on the atoms, and then taking as elements of
the model only those sets which are 'nearly' G-invariant.) Fraenkel's
model thus fails to satisfy the axiom of Extensionality, as we have
formulated it.
In 1939, A. Mostowski modified Fraenkel's method so that
Extensionality was preserved, although Foundation was violated (he
replaced the atoms by sets x satisfying x = {x}, which also tend to be
indistinguishable). Also, by taking a linearly ordered set of such xs
and allowing only order-preserving permutations of them, he showed
that 'Every set can be linearly ordered' can remain true even when AC
fails; later, J. D. Halpern showed that Mostowski's model in fact
satisfies the Prime Ideal Theorem (cf. Exercise 7.6). It was not until
1963 that P. Cohen developed a technique for 'forcing' the
counterexample to AC which exists in Mostowski's model into the
well-founded part of the universe, and hence (by taking the well-
founded part of the resulting model) obtaining a model of ZF in
which AC fails. (Actually, Cohen's independence proof for AC was
originally presented in a rather different way, but it's equivalent to
the technique just described.) Cohen's 'forcing' technique (which is
a technique for adjoining things to a model of set theory-in the case
just cited, what we need to adjoin is an injection from a given non-
well-orderable set to (say) tPco) also enabled him to produce a model
of ZF (and of AC) in which the Continuum Hypothesis fails, as we
mentioned at the end of Chapter 8. Since 1963 the technique has been
greatly developed to prove other independence results, which we do
not have space to discuss here.

Index of definitions
algebraic theory, 4
arity, 2
atomic formula, 19
axiom
of proportional calculus, 12
of predicate calculus, 23
of a first-order theory, 21
of ZF set theory, 54ff
see also names of particular axioms
axiom-scheme, 29
Boolean algebra, 7
Cantor-Bernsein theorem, 90
Cantor Normal Form, 77
cardinal, 88
choice, axiom of, 79
choice function, 79
choice function, orderly, 85
Church's Thesis, 40
class, 59
class, proper, 59
closed term, 25
code, 47, 99
Compactness Theorem, 16, 27
Completeness Theorem, 6, 14, 25
comprehension, axiom-scheme of, 54
computable function, 36
consistent set of propositions), 14
constant, 1
constructibility, axiom of, 106
constructible universe, 105
continuum hypothesis, 94
Decidability Theorem, 16
Dedekind infinite set, 91
Deduction
in propositional calculus, 12
in predicate calculus, 24
Deduction Theorem, 13, 24
definable function, 49, 57
definable subset, 104
Dependent Choices, axiom of, 84
derived operation, 4
elementary equivalence, 97
Empty set axiom, 55
entailment, semantic, 11
entailment, syntactic, 12
equation, 4
essential rank, 89
extensional relation, 65
extensionality, axiom of, 54
extensionally equivalent, 59
formula, 19
atomic, 19
stratified, 54
Foundation, axiom of, 61
function
basic, 37
choice, 79
computable, 36
definable, 49
multiple-choice, 87
primitive recursive, 38
recursive, 38
selection, 86
function-class, 59
Generalized Continuum Hypothesis, 94
Godel hierarchy, 105
Godel number, 99
halting problem, 43
Hartogs' Lemma, 78
Incompleteness Theorems, 101, 102

Index of definitions
109
induction, mathematical, 63
induction, principle of, 62
initial ordinal, 88
interpretation
of formula in structure, 20
of first-order theories, 98
recursive, 100
language, first-order, 18
language, propositional, 21
lexicographic ordering, 73, 76
limit ordinal, 70
Lowenheim-Skolem Theorems, 27, 28
minimalization, 37
model
of algebraic theory, 4
of first-order theory, 21
free, 5
inner, 103
standard, 103
modus ponens, 12
Mostowski's theorem, 65
multiple-choice function, 87
natural number, 58
normal function, 77
operation, derived, 4
operation, primitive, 4
operational type, 2
operation-symbol, 2
order-type, 69
ordinal, 68
initial, 88
limit, 70
successor, 70
ordinal exponential, 76
ordinal product, 73
ordinal sum, 73
Pair-set axiom, 56
Peano arithmetic, 29
Peano's postulates, 28
Power-set axiom, 56
predicate, primitive, 18
predicate type, 19
Prime Ideal Theorem, 83
primitive operation, 4
primitive predicate, 18
primitive proposition, 11
primitive recursive function, 38
program (for register machine), 35
program, universal, 42
proof, 12
proper class, 59
proposition, compound, 11
proposition, primitive, 11
quantifier, 18
quantifier, restricted, 57
rank (of a set), 71
rank, essential, 89
recursion, primitive, 37
recursion, set-theoretic, 63
Recursion Theorem, 46, 64
recursive function, 38
recursive interpretation, 100
recursive set, 41
recursively enumerable set, 43
recursively presented theory, 47, 99
register machine, 35
regular set, 62
Regularity, axiom of, 61
relation-class, 61
extensional, 65
local, 62
trichotomous, 68
well-founded, 61
Replacement, axiom-scheme of, 60
reverse lexicographic ordering, 73
satisfaction, 4, 21
selection function, 86
semantic entailment, 11
sentence, 21
Separation, axiom-scheme of, 55
set, 53
constructible, 105
Dedekind infinite, 91
hereditarily finite, 67
recursive, 41
recursively enumerable, 43
successor, 58
transitive, 61
Soundness Theorem, 13, 24
state (of register machine), 35
structure, 2, 20
structure, free, 3
substructure, 31
successor, 28, 58
successor ordinal, 70
successor set, 58
syntactic entailment, 12
tautology, 8

110 
Index of definitions
term, 2, 19 
union axiom, 56
closed, 25 
universal closure, 21
special, 47 
universal program, 42
theorem, 12 
universal theory, 31
theory
algebraic, 4 
valuation, 11
categorical, 28 
v o n N e u m a n n hierarchy, 71
complete, 25
first-order, 21
inductive 31 
well-founded relation, 61
prepositional, 21 
well-ordering, 68
recursively presented, 47, 99 
witnesses, 25
universal 31 
word problem, 6
transitive closure, 61 
recursively soluble, 47
transitive set, 61
trichotomous relation, 68 
Zorn's Lemma, 80

Index of names
Banach, S., 83
Banaschewski, B., 84
Bernays, P., 84
Bernstein, F., 90
Blass, A. R., 82, 84
Burali-Forti, C, 78
Cantor, G., 77, 78, 90, 94
Church, A., 40
Cohen, P., 95, 107
Dedekind, R., 91
Fraenkel, A., 59, 107
Frege, G., 54
Godel, K., 95, 97, 104, 106
Halpern, J. D., 82, 84, 107
Hamel, W., 82
Hartogs, F., 78
Hausdorff, F., 80
Hilbert, D., 97
Hodges, W., 82
Jech, T. J., 83
Johnstone, P. T., 84
Kelley, J. L., 82
Kleene, S. C, 44
Krull, W., 82
Kuratowski, K., 56
Los, J., 83
Lowenheim, L., 27, 28
Minsky, M., 35
Mostowski, A., 65, 68, 107
Neumann, J. von, 61, 68, 71
Peano, G., 28
Quine, W., 54
Russell, B., 54, 88
Ryll-Nardzewski, C , 83
Scott, D. S., 83, 89
Skolem, T., 27, 28, 54, 59
Solovay, R. M., 83
Tarski, A., 83
Turing, A. M., 35, 40
Tychonoff, A. N., 82
Wiener, N., 56
Zermelo, E., 54, 58, 78, 80, 86
Zorn, M., 80

