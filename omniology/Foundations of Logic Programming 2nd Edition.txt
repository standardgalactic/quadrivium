Lloyd
Foundations of Logic PrQgramming
This is the second edition of the first book to give an account of
the mathematical foundations of Logic Programming. Its pur-
pose is to collect, in a unified and comprehensive manner, the
basic theoretical results of Logic Programming, which have
previously only been available in widely scattered research
papers.
In addition to presenting the technical results, the book also
contains many illustrative examples and problems. Some of
them are part of the folklore of Logic Programming and are not
easily obtainable elsewhere.
The book is intended to be self-contained, the only prerequisites
being some familiarity with PROLOG and knowledge of some
basic undergraduate mathematics. The material is suitable
either as a reference book for researchers or as a text book for
a graduate course on the theoretical aspects of Logic Program-
ming and Deductive Database Systems.
I
I
"TIC'..
O'
§~
a.C
a,o
_.'<
oa.
::::II
1IIa
i
(')'
"D
c8
iil33
~.
N
::::IIa.
me:
:::!:o
::::II
J.W Lloyd
Foundations of
[1@~Dcs
[P[?@~[?~ITUUITUU D[Ji)~
Second, Extended Edition
ISBN 3-540-18199-7
ISBN 0-387-18199-7
~I
Springer-Verlag

Springer Series
SYMBOLIC COMPUTATION -Artificial Intelligence
N.J. Nilsson: Principles of Artificial Intelligence. XV, 476 pages,
139 figs., 1982
J.H. Siekmann, G. Wrightson (Eds.): Automation of Reasoning 1.
Classical Papers on Computational Logic 1957-1966. XXII. 525
pages, 1983
J.H. Siekmann, G. Wrightson (Eds.): Automation of Reasoning 2.
Classical Papers on Computational Logic 1967-1970. XXII. 638
pages, 1983
L. Bole (Ed.): The Design of Interpreters, Compilers, and Editors
for Augmented Transition Networks. XI, 214 pages, 72 figs., 1983
R. S. Michalski, J. G. Carbonell, T. M. Mitchell (Eds.): Machine
Learning. An Artificial Intelligence Approach. XI, 572 pages, 1984
L. Bole (Ed.): Natural Language Communication with Pictorial
Information Systems. VII, 327 pages, 67 figs., 1984
J. W. Lloyd: Foundations of Logic Programming. X, 124 pages, 1984;
Second, extended edition, XII, 212 pages, 1987
A. Bundy (Ed.): Catalogue of Artificial Intelligence Tools. XXV,
150 pages, 1984. Second, revised edition, IV, 168 pages, 1986
M. M. Botvinnik: Computers in Chess. Solving Inexact Search Prob-
lems. With contributions by A.I. Reznitsky, B.M. Stilman, M.A.
Tsfasman,A.D. Yudin. Translated from the Russian by A. A. Brown.
XIV, 158 pages, 48 figs., 1984
C. Blume, W. Jakob: Programming Languages for Industrial Robots.
XIII, 376 pages, 145 figs., 1986
L. Bolc (Ed.): Computational Models of Learning. IX, 208 pages, 34
figs., 1987
L. Bole (Ed.): Natural Language Parsing Systems. Approx. 384
pages, 155 figs., 1987
1. W Lloyd
Foundations of
Logic Programming
Second, Extended Edition
Springer-Verlag
Berlin Heidelberg NewYork
London Paris Tokyo

John Wylie Lloyd
Department of Computer Science
University of Bristol
Queen's Building, University Walk
Bristol BS81TR, UK
First Corrected Printing 1993
ISBN 3-540-18199-7 Springer-Verlag Berlin Heidelberg New York
ISBN 0-387-18199-7 Springer-Verlag NewYork Berlin Heidelberg
ISBN 3-540-13299-6 1. Auflage Springer-Verlag Berlin Heidelberg NewYork Tokyo
ISBN 0-387-13299-6 1st edition Springer-Verlag NewYork Berlin HeidelbergTokyo
Library of Congress Cataloging in Publication Data. Lloyd, J. W. (John Wylie), 1947-.
Foundations of logic programming. (Symbolic computation. Artificial intelligence) Biblio-
graphy: p. Includes index. 1. Logic programming. 2. Programming languages (Electronic
computers)-Semantics. I. Title. II. Series. QA76.6.L583 1987005.187-20753
ISBN 0-387-18199-7 (U.S.)
This work is subject to copyright. All rights are reserved, whether the whole or part of the
material is concerned, specifically the rights of translation, reprinting, re-use of illustrations,
recitation, broadcasting, reproduction on microfilms or in other ways, and storage in data
banks. Duplication of this publication or parts thereof is only permitted under the provi-
sions of the German Copyright Law of September 9,1965, in its version of June 24,1985,
and a copyright fee must always be paid. Violations fall under the prosecution act of the
German Copyright Law.
© J. W. Lloyd 1984, 1987
Printed in Germany
Printing: Druckhaus Beltz, 6944 HemsbachlBergstr.
Bookbinding: J. Schaffer GmbH & Co. KG, 6718 Griinstadt
45/3140-543210
To
Susan, Simon and Patrick

PREFACE TO THE SECOND EDITION
In the two and a half years since the fIrst edition of this book was published,
the field of logic programming has grown rapidly.
Consequently, it seemed
advisable to try to expand the subject matter covered in the fIrst edition. The new
material in the second edition has a strong database flavour, which reflects my own
research interests over the last three years.
However, despite the fact that the
second edition has
about 70%
more material
than
the fIrst
edition, many
worthwhile topics are still missing. I can only plead that the field is now too big
to expect one author to cover everything.
In the second edition, I discuss a larger class of programs than that discussed
in the fIrst edition. Related to this, I have also taken the opportunity to try to
improve
some
of
the
earlier
terminology.
Firstly,
I
introduce
"program
statements", which are formulas of the form Af-W, where the head A is an atom
and the body W is an arbitrary formula.
A "program" is a finite set of program
statements. There are various restrictions of this class. "Normal" programs are
ones where the body of each program statement is a conjunction of literals.
(The
terminology "general", used in the first edition, is obviously now inappropriate).
This. terminology is new and I risk causing some confusion. However, there is no
widely used terminology for such programs and "normal" does have the right
connotation.
"DefInite" programs are ones where the body of each program
statement is a conjunction of atoms. This terminology is more standard.
The material in chapters 1 and 2 of the fIrst edition has been reorganised so
that the fIrst chapter now contains all the preliminary results and the second
chapter now contains both the declarative and procedural semantics of definite
programs. In addition, chapter 2 now contains a proof of the result that every
computable function can be computed by a definite program.
Further material on negation has been added to chapter 3, which is now
entitled
"Normal
Programs".
This
material
includes
discussions
of
the

VIII
consistency of the completion of a normal program, the floundering of SLDNF-
resolution, and the completeness of SLDNF-resolution for hierarchical programs.
The fourth chapter is a new one on (unrestricted) programs. There is no good
practical or theoretical reason for restricting the bodies of program statements or
goals to be conjunctions of literals. Once a single negation is allowed, one should
go all the way and allow arbitrary formulas. This chapter contains a discussion of
SLDNF-resolution for programs, the main results being the soundness of the
negation as failure rule and SLDNF-resolution. There is also a discussion of error
diagnosis
in
logic
programming,
including
proofs
of
the
soundness
and
completeness of a declarative error diagnoser.
The fifth chapter builds on the fourth by giving a theoretical foundation for
deductive database systems.
The main results of the chapter are soundness and
completeness results for the query evaluation process and a simplification theorem
for integrity constraint checking. This chapter should also prove useful to those in
the "conventional" database community who want to understand the impact logic
programming is having on the database field.
The last chapter of the second edition is the same as the last chapter of the
first edition on perpetual processes.
This chapter is still the most speculative and
hence has been left to the end. It can be read directly after chapter 2, since it does
not depend on the material in chapters 3, 4 and 5.
This second edition owes much to Rodney Topor, who collaborated with me
on four of the papers reported here. Various people made helpful suggestions for
improvements of the first edition and drafts of the second edition. These include
David Billington, Torkel Franzen, Bob Kowalski, Jean-Louis Lassez, Donald
Loveland, Gabor Markus, Jack Minker, Ken Ross, John Shepherdson, Harald
Sondergaard, Liz Sonenberg, Rodney Topor, Akihiro Yamamoto and Songyuan
Yan.
John Crossley read the entire manuscript and found many improvements.
John Shepherd showed me how to use ditroff to produce an index.
He also
introduced me to the delights of cip, which I used to draw the figures.
Rodney
Topor helped with the automation of the references.
PREFACE TO THE FIRST EDITION
This
book gives an
account of the mathematical
foundations of logic
programming. I have attempted to make the book self-contained by including
proofs of almost all the results needed. The only prerequisites are some familiarity
with a logic programming language, such as PROLOG, and a certain mathematical
maturity. For example, the reader should be familiar with induction arguments and
be comfortable manipulating logical expressions.
Also the last chapter assumes
some
acquaintance with the elementary aspects of metric spaces,
especially
properties of continuous mappings and compact spaces.
Chapter 1 presents the declarative aspects of logic programming. This chapter
contains the basic material from first order logic and fixpoint theory which will be
required. The main concepts discussed here are those of a logic program, model,
correct
answer
substitution
and
fixpoint.
Also
the
unification
algorithm is
discussed in some detail.
Chapter 2 is concerned with the procedural semantics of logic programs. The
declarative concepts are implemented by means of a specialised form of resolution,
called SLD-resolution. The main results of this chapter concern the soundness and
completeness of SLD-resolution and the independence of the computation rule. We
also
discuss
the
implications
of omitting
the
occur
check from
PROLOG
implementations.
Chapter 3 discusses negation. Current PROLOG systems implement a form of
negation by means of the negation as failure rule. The main results of this chapter
are the soundness and completeness of the negation as failure rule.
April 1987
JWL
Chapter 4 is concerned with the semantics of perpetual processes. With the
advent of PROLOG systems for concurrent applications, this has become an area
of great theoretical importance.

x
The material of chapters 1 to 3, which is now very well established, could be
described as "what every PROLOG programmer should know".
In chapter 4, I
have allowed myself the luxury of some speculation. I believe the material
presented there will eventually be incorporated into a much more extensive
theoretical
foundation
for
concurrent
PROLOGs.
However,
this
chapter
is
incomplete insofar as I have confined attention to a single perpetual process.
Problems of concurrency and communication, which are not very well understood
at the moment, have been ignored.
My view of logic programming has been greatly enriched by discussions with
many people over the last three years. In this regard, I would particularly like to
thank Keith Clark, Maarten van Emden, Jean-Louis Lassez, Frank McCabe and Lee
Naish. Also various people have made suggestions for improvements of earlier
drafts of this book. These include Alan Bundy, Herve
Gallaire, Joxan Jaffar,
Donald Loveland, Jeffrey Schultz, Marek Sergot and Rodney Topor. To all these
people and to others who have contributed in any way at all, may I say thank you.
CONTENTS
Chapter 1. PRELIMINARIES
§1. Introduction
1
§2. First Order Theories
4
§3. Interpretations and Models
10
§4. Unification
20
§5. Fixpoints
26
Problems for Chapter 1
31
1
July 1984
JWL
Chapter 2. DEFINITE PROGRAMS
§6. Declarative Semantics
35
§7. Soundness of SLD-Resolution
40
§8. Completeness of SLD-Resolution
47
§9. Independence of the Computation Rule
49
§1O. SLD-Refutation Procedures
55
§11. Cuts
63
Problems for Chapter 2
66
Chapter 3. NORMAL PROGRAMS
§12. Negative Information
71
§13. Finite Failure
74
§14. Programming with the Completion
77
§15. Soundness of SLDNF-Resolution
84
§16. Completeness of SLDNF-Resolution
95
Problems for Chapter 3
102
35
71

XII
Chapter 4. PROGRAMS
§17. Introduction to Programs
107
§18. SLDNF-Resolution for Programs
112
§19. Declarative Error Diagnosis
119
§20. Soundness and Completeness of the Diagnoser
130
Problems for Chapter 4
136
Chapter 5. DEDUCTIVE DATABASES
§21. Introduction to Deductive Databases
141
§22. Soundness of Query Evaluation
150
§23. Completeness of Query Evaluation
156
§24. Integrity Constraints
158
Problems for Chapter 5
169
Chapter 6. PERPETUAL PROCESSES
§25. Complete Herbrand Interpretations
173
§26. Properties of Tp 182
§27. Semantics of Perpetual Processes
188
Problems for Chapter 6
192
REFERENCES
NOTATION
INDEX
107
141
173
195
205
207
Chapter 1
PRELIMINARIES
This chapter presents the basic concepts and results which are needed for the
theoretical foundations of logic programming.
After a brief introduction to logic
programming,
we
discuss
fIrst
order
theories,
interpretations
and
models,
unifIcation, and fIxpoints.
§1. INTRODUCTION
Logic programming began in the early 1970's as a direct outgrowth of earlier
work in automatic theorem proving and artifIcial intelligence.
Constructing
automated deduction systems is, of course, central to the aim of achieving artificial
intelligence. Building on work of Herbrand [44] in 1930, there was much activity
in theorem proving in the early 1960's by Prawitz [84], Gilmore [39], Davis,
Putnam [26] and others. This effort culminated in 1965 with the publication of the
landmark
paper
by
Robinson
[88],
which
introduced
the
resolution
rule.
Resolution is an inference rule which is particularly well-suited to automation on a
computer.
The credit for the introduction of logic programming goes mainly to Kowalski
[48]
and Colmerauer [22], although Green [40]
and Hayes [43]
should be
mentioned in this regard.
In 1972, Kowalski and Colmerauer were led to the
fundamental idea that logic can be used as a programming language.
The
acronym PROLOG
(PROgramming in LOGic) was conceived, and the first
PROLOG interpreter [22]
was implemented in the language ALGOL-W by
Roussel, at Marseille in 1972.
([8] and [89] describe the improved and more
influential version written in FORTRAN.) The PLANNER system of Hewitt [45]
can be regarded as a predecessor of PROLOG.

2
Chapter 1. Preliminaries
§1. Introduction
3
The idea that first order logic, or at least substantial subsets of it, could be
used as a programming language was revolutionary, because, until 1972, logic had
only ever been used as a specification or declarative language in computer science.
However, what [48] shows is that logic has a procedural interpretation, which
makes it very effective as a programming language. Briefly, a program clause
A~Bl'..:,Bn is regarded as a procedure definition. If ~Cl'""Ck is a goal, then
each Cj IS regarded as a procedure call. A program is run by giving it an initial
goal. If the current goal is ~Cl,...,<1<:, a step in the computation involves unifying
some Cj with the head A of a program clause A~Bl'...,Bn and thus reducing the
c~e~t goal .to .the
go~
~(Cl'""Cj_l,Bl,...,Bn,Cj+l"",Ck)e, where e is the
umfymg substitution. Umficatlon thus becomes a uniform mechanism for parameter
passing, data selection and data construction.
The computation terminates when
the empty goal is produced.
One of the main ideas of logic programming, which is due to Kowalski [49],
[50], is that an algorithm consists of two disjoint components, the logic and the
control.
The logic is the statement of what the problem is that has to be solved.
The control is the statement of how it is to be solved. Generally speaking, a logic
programming system should provide ways for the programmer to specify each of
these components. However, separating these two components brings a number of
benefits, not least of which is the possibility of the programmer only having to
specify the logic component of an algorithm and leaving the control to be
exercised solely by the logic programming system itself. In other words, an ideal
of logic programming is purely declarative programming.
Unfortunately, this has
not yet been achieved with current logic programming systems.
Most current logic programming systems are resolution theorem provers.
However, logic programming systems need not necessarily be based on resolution.
They can be non-clausal systems with many inference rules [11], [41], [42]. This
account only discusses logic programming systems based on resolution and
concentrates particularly on the PROLOG systems which are currently available.
There are two major, and rather different, classes of logic programming
languages currently available. The first we shall call "system" languages and the
second "application" languages.
These terms are not meant to be precise, but
only to capture the flavour of the two classes of languages.
For "system" languages, the emphasis is on AND-parallelism, don't-care
non-determinism and definite programs (that is, no negation). In these languages,
according to the process interpretation of logic, a goal ~Bl,...,Bn is regarded as a
system of concurrent processes. A step in the computation is the reduction of a
process to a system of processes (the ones that occur in the body of the clause that
matched the call).
Shared variables act as communication channels between
processes.
There
are
now
several
"system"
languages
available,
including
PARLOG [18], concurrent PROLOG [93] and GHC [106].
These languages are
mainly intended for operating system applications and object-oriented programming
[94]. For these languages, the control is still very much given by the programmer.
Also these languages are widely regarded as being closer to the machine level.
"Application" languages can be regarded as general-purpose programming
languages with a wide range of applications.
Here the emphasis is on OR-
parallelism, don't-know non-determinism and (unrestricted) programs (that is, the
body of a program statement is an arbitrary formula).
Languages in this class
include Quintus PROLOG [10], micro-PROLOG [20] and NU-PROLOG [104].
For these languages, the automation of the control component for certain kinds of
applications has already largely been achieved. However, there are still many
problems to be solved before these languages will be able to support a sufficiently
declarative style of programming over a wide range of applications.
"Application"
languages are better suited to deductive database systems and
expert systems. According to the database interpretation of logic, a logic program
is regarded as a database [35], [36], [37], [38]. We thus obtain a very natural and
powerful generalisation of relational databases.
The latter correspond to logic
programs consisting solely of ground unit clauses. The concept of logic as a
uniform language for data, programs, queries, views and integrity constraints has
great theoretical and practical power.
The distinction between these two classes of languages is, of course, by no
means clearcut. For example, non-trivial problem-solving applications have been
implemented in GHC. Also, the coroutining facilities of NU-PROLOG make it
suitable as a system programming language. Nevertheless, it is useful to make the
distinction.
It also helps to clarify some of the debates in logic programming,
whose source can be traced back to the "application" versus "system" views of
the participants.

4
Chapter 1. Preliminaries
§2. First Order Theories
5
The emergence of these two kinds of logic programming languages has
complicated the already substantial task of building parallel logic machines.
Because of the differing hardware requirements of the two classes of languages, it
seems that a difficult choice has to be made.
This choice is between building a
predominantly AND-parallel machine to directly support a "system" programming
language or building a predominantly OR-parallel machine to directly support an
"application" programming language.
There is currently substantial effort being invested in the ftrst approach;
certainly, the Japanese fifth generation project [71] is headed this way.
The
advantage of this approach is that the hardware requirements for an AND-parallel
language, such as GHC, seem less demanding than those required for an OR-
parallel language. However, the success of a logic machine ultimately rests on the
power and expressiveness of its application languages. Thus this approach requires
some method of compiling the application languages into the lower level system
language.
In summary, logic provides a single formalism for apparently diverse parts of
computer science. It provides us with general-purpose, problem-solving languages,
concurrent languages suitable for operating systems and also a foundation for
deductive database systems and expert systems. This range of application together
with the simplicity, elegance and unifying effect of logic programming assures it of
an important and influential future.
Logical inference is about to become the
fundamental unit of computation.
§2. FIRST ORDER THEORIES
This section introduces the syntax of well-formed formulas of a first order
theory.
While all the requisite concepts from frrst order logic will be discussed
informally in this and subsequent sections, it would be helpful for the reader to
have some wider background on logic. We suggest reading the first few chapters of
[14], [33], [64], [69] or [99].
First order logic has two aspects: syntax and semantics. The syntactic aspect is
concerned with well-formed formulas admitted by the grammar of a formal
language, as well as deeper proof-theoretic issues. The semantics is concerned with
the meanings attached to the well-formed formulas and the symbols they contain.
We postpone the discussion of semantics to the next section.
A first order theory consists of an alphabet, a ftrst order language, a set of
axioms and a set of inference rules [69], [99]. The frrst order language consists of
the well-formed formulas of the theory.
The axioms are a designated subset of
well-formed formulas.
The axioms and rules of inference are used to derive the
theorems of the theory.
We now proceed to define alphabets and first order
languages.
Definition An alphabet consists of seven classes of symbols:
(a) variables
(b) constants
(c) function symbols
(d) predicate symbols
(e) connectives
(f) quantifiers
(g) punctuation symbols.
Classes (e) to (g) are the same for every alphabet, while classes (a) to (d) vary
from alphabet to alphabet.
For any alphabet, only classes (b) and (c) may be
empty.
We
adopt
some
informal
notational
conventions
for
these classes.
Variables will normally be denoted by the letters u, v, w, x, y and z (possibly
subscripted). Constants will normally be denoted by the letters a, b and c (possibly
subscripted). Function symbols of various arities > 0 will normally be denoted by
the letters f, g and h (possibly subscripted). Predicate symbols of various arities ;;::
o will normally be denoted by the letters p, q and r (possibly subscripted).
Occasionally, it will be convenient not to apply these conventions too rigorously.
In such a case, possible confusion will be avoided by the context. The connectives
are -, /\, V, ~ and ~, while the quantifiers are 3 and V. Finally, the punctuation
symbols are "(", ")" and ",". To avoid having formulas cluttered with brackets,
we adopt the following precedence hierarchy, with the highest precedence at the
top:
-, V,3
v
/\

6
Chapter 1. Preliminaries
§2. First Order Theories
7
Next we tum to the definition of the first order language given by an alphabet.
Definition A term is defined inductively as follows:
(a) A variable is a term.
(b) A constant is a term.
(c) If f is an n-ary function symbol and tl'...,tn are terms, then f(tl'...,tn) is a term.
Definition A (well-formed) formula is defined inductively as follows:
(a) If p is an n-ary predicate symbol and tl'...,tn are terms, then p(tl,...,tn) is a
formula (called an atomic formula or, more simply, an atom).
(b) If F and G are formulas, then so are (-F), (FAG), (FvG), (F~G) and (F~G).
(c) If F is a formula and x is a variable, then (\:Ix F) and (3x F) are formulas.
It will often be convenient to write the formula (F~G) as (G~F).
Definition The first order language given by an alphabet consists of the set of
all formulas constructed from the symbols of the alphabet.
Example
(\:Ix (3y (p(x,y)~q(x»»,
(-(3x (p(x,a)Aq(f(x)))))
and
(V'x (p(x,g(x»~(q(x)A(-r(x»»)
are formulas. By dropping pairs of brackets when
no confusion is possible and using the above precedence convention, we can write
these formulas more simply as
\:Ix3y (P(x,y)~q(x», -3x (p(x,a)Aq(f(x») and
\:Ix (P(x,g(x»~q(x)A-r(x». We will simplify formulas in this way wherever
possible.
The informal semantics of the quantifiers and connectives is as follows.
- is
negation, A is conjunction (and), v is disjunction (or), ~ is implication and ~ is
equivalence. Also, 3 is the existential quantifier, so that "3x" means "there exists
an x", while \:I is the universal quantifier, so that "Vx" means "for all x". Thus
the informal semantics of Vx (P(x,g(x»
~ q(x)A-r(x»
is "for every x, if q(x) is
true and r(x) is false, then p(x,g(x» is true".
Definition The scope of \:Ix (resp. 3x) in \:Ix F (resp. 3x F) is F.
A bound
occurrence of a variable in a formula is an occurrence immediately following a
quantifier or an occurrence within the scope of a quantifier, which has the same
variable immediately after the quantifier. Any other occurrence of a variable is
free.
Example In the formula 3x p(X,y)Aq(X), the first two occurrences of x are
bound, while the third occurrence is free, since the scope of 3x is p(x,y). In
3x (P(X,y)Aq(X», all occurrences of x are bound, since the scope of 3x is
p(X,y)Aq(X).
Definition A closed formula is a formula with no free occurrences of any
variable.
Example
\:Iy3x (P(X,y)Aq(X» is closed. However, 3x (p(X,y)Aq(X»
is not
closed, since there is a free occurrence of the variable y.
Definition If F is a formula, then V(F) denotes the universal closure of F,
which is the closed formula obtained by adding a universal quantifier for every
variable having a free occurrence in F. Similarly, 3(F) denotes the existential
closure of F, which is obtained by adding an existential quantifier for every
variable having a free occurrence in F.
Example If F is p(X,y)Aq(X), then V(F) is \:Ix\:ly (p(X,y)Aq(X», while 3(F) is
3x3y (p(X,y)Aq(X».
In chapters 4 and 5, it will be useful to have available the concept of an atom
occurring positively or negatively in a formula.
Definition An atom A occurs positively in A.
If atom A occurs positively (resp., negatively) in a formula W, then A occurs
positively (resp., negatively) in 3x W
and
\:Ix W
and
WAV
and WvV
and
W~V.
If atom A occurs positively (resp., negatively) in a formula W, then A occurs
negatively (resp., positively) in -W and
V~W.
Next we introduce an important class of formulas called clauses.
Definition A literal is an atom or the negation of an atom. A positive literal is
an atom. A negative literal is the negation of an atom.
Definition A clause is a formula of the form
\:Ix1..·Vxs (Llv...vLm)
where each Li is a literal and xl""'xs are all the variables occurring in L1v...vLm·
Example The following are clauses
\:Ix\:ly\:lz (p(x,z)v-q(x,y)v-r(y,z»
\:IxVy (-p(x,y)vr(f(x,y),a»

8
Chapter 1. Preliminaries
§2. First Order Theories
9
Because clauses are so common in logic programming, it will be convenient to
adopt a special clausal notation. Throughout, we will denote the clause
'v'xl''''v'xs (A1v...vAkv-B1v...v-Bn)
where Al'...,Ak,Bl'...,Bn are atoms and xl'...,xs are all the variables occurring in
these atoms, by
Al,..·,Ak~BI, ..·,Bn
Thus, in the clausal notation, all variables are assumed to be universally quantified,
the commas in the antecedent Bl'...,Bn denote conjunction and the commas in the
consequent Al'...,Ak denote disjunction. These conventions are justified because
'v'xl..·'v'xs (Alv...vAkv-Blv...v-Bn)
is equivalent to
To illustrate the application of the various concepts in this chapter to logic
programming, we now define definite programs and definite goals.
Definition A definite program clause is a clause of the form
A~Bl'...,Bn
which contains precisely one atom (viz. A) in its consequent. A is called the head
and Bl'...,Bn is called the body of the program clause.
Definition A unit clause is a clause of the form
A~
that is, a definite program clause with an empty body.
The informal semantics of A~Bl'...,Bn is "for each assignment of each
variable, if BI,...,Bn are all true, then A is true". Thus, if n>O, a program clause is
conditional. On the other hand, a unit clause A~ is unconditional. Its informal
semantics is "for each assignment of each variable, A is true".
Definition A definite program is a finite set of definite program clauses.
Definition In a definite program, the set of all program clauses with the same
predicate symbol p in the head is called the definition of p.
Example The following program, called slowsort, sorts a list of non-negative
integers into a list in which the elements are in increasing order. It is a very
inefficient sorting program! However, we will find it most useful for illustrating
various aspects of the theory.
In this program, non-negative integers are represented using a constant 0 and a
unary function symbol f. The intended meaning of 0 is zero and f is the successor
function. We define the powers of f by induction: fl(x)=o and fl+1(x)=f(t\x».
Then the non-negative integer n is represented by the term fl(O). In fact, it will
sometimes be convenient simply to denote fl(O) by n.
Lists are represented using a binary function symbol "." (the cons function
written infix) and the constant nil representing the empty list. Thus the list
[17,22,6,5] would be represented by 17.(22.(6.(5.nil»). We make the usual right
associativity convention and write this more simply as 17.22.6.5.nil.
SLOWSORT PROGRAM
sort(x,y) ~ sorted(y), perm(x,y)
sorted(nil) ~
sorted(x.nil) ~
sorted(x.y.z) ~ x~y, sorted(y.z)
perm(nil,nil) ~
perm(x.y,u.v) ~ delete(u,x.y,z), perm(z,v)
delete(x,x.y,y) ~
delete(x,y.z,y.w) ~ delete(x,z,w)
O~x~
f(x)~f(y) ~ x~y
Slowsort contains definitions of five predicate symbols, sort, sorted, perm,
delete and ~ (written infix). The informal semantics of the definition of sort is "if
x and y are lists, y is a permutation of x and y is sorted, then y is the sorted
version of x". This is clearly a correct top-level description of a sorting program.
Similarly, the first clause in the definition of sorted states that "the empty list is
sorted". The intended meaning of the predicate symbol delete is that delete(x,y,z)
should hold if z is the list obtained by deleting the element x from the list y. The
above definition for delete contains obviously correct statements about the delete
predicate.
Definition A definite goal is a clause of the form
~Bl'...,Bn
that is, a clause which has an empty consequent. Each Bi (i=l,...,n) is called a
subgoal of the goal.
If Yl'''''Yr are the variables of the goal
~BI,·..,Bn

10
Chapter 1. Preliminaries
§3. Interpretations and Models
11
or, equivalently,
then this clausal notation is shorthand for
V'Yl···V'Yr (-B1v...v-Bn)
Example To run slowsort, we give it a goal such as
+- sort(17.22.6.5.nil,y)
This is understood as a request to find the list y, which is the sorted version of
17.22.6.5.nil.
Definition The empty clause, denoted D, is the clause with empty consequent
and empty antecedent. This clause is to be understood as a contradiction.
Definition A Horn clause is a clause which is either a definite program clause
or a definite goal.
§3. INTERPRETATIONS AND MODELS
The declarative semantics of a logic program is given by the usual (model-
theoretic) semantics of formulas in first order logic. This section discusses
interpretations and models, concentrating particularly on the important class of
Herbrand interpretations.
Before we give the main definitions, some motivation is appropriate. In order
to be able to discuss the truth or falsity of a formula, it is necessary to attach some
meaning to each of the symbols in the formula first.
The various quantifiers and
connectives have fixed meanings, but the meanings attached to the constants,
function symbols and predicate symbols can vary.
An interpretation simply
consists of some domain of discourse over which the variables range, the
assignment to each constant of an element of the domain, the assignment to each
function symbol of a mapping on the domain and the assignment to each predicate
symbol of a relation on the domain. An interpretation thus specifies a meaning for
each symbol in the formula. We are particularly interested in interpretations for
which the formula expresses a true statement in that interpretation. Such an
interpretation
is
called
a
model
of the
formula.
Normally
there
is
some
distinguished interpretation, called the intended interpretation, which gives the
principal meaning of the symbols.
Naturally, the intended interpretation of a
formula should be a model of the formula.
First order logic provides methods for deducing the theorems of a theory.
These can be characterised (by GlXlel's completeness theorem [69], [99]) as the
formulas which are logical consequences of the axioms of the theory, that is, they
are true in every interpretation which is a model of each of the axioms of the
theory. In particular, each theorem is true in the intended interpretation of the
theory. The logic programming systems in which we are interested use the
resolution rule as the only inference rule.
Suppose we want to prove that the formula
3Yl..·3Yr (Bl"···,,Bn)
is a logical consequence of a program P. Now resolution theorem provers are
refutation systems. That is, the negation of the formula to be proved is added to
the axioms and a contradiction is derived. If we negate the formula we want to
prove, we obtain the goal
+-Bl'...,Bn
Working top-down from this goal, the system derives successive goals. If the
empty clause is eventually derived, then a contradiction has been obtained and later
results assure us that
3y1·..3yr (B l"···,,Bn)
is indeed a logical consequence of P.
From a theorem proving point of view, the only interest is to demonstrate
logical consequence.
However, from a programming point of view, we are much
more interested in the bindings that are made for the variables y1,...,yr' because
these give us the output from the running of the program.
In fact, the ideal view
of a logic programming system is that it is a black box for computing bindings and
our only interest is in its input-output behaviour.
The internal workings of the
system should be invisible to the programmer. Unfortunately, this situation is not
true, to various extents, with current PROLOG systems. Many programs can only
be understood in a procedural (i.e. operational) manner, because of the way they
use cuts and other non-logical features.
Returning to the slowsort program, from a theorem proving point of view, we
can
regard
the
goal
+-sort(17.22.6.5.nil,y)
as
a
request
to
prove
that
3y sort(l7.22.6.5.nil,y) is a logical consequence of the program. In fact, we are
much more interested that the proof is constructive and provides us with a specific

12
Chapter 1. Preliminaries
§3. Interpretations and Models
13
y which makes sort(l7.22.6.5.nil,y) true in the intended interpretation.
We now give the definitions of pre-interpretation, interpretation and model.
Definition A pre-interpretation of a first order language L consists of the
following:
(a) A non-empty set D, called the domain of the pre-interpretation.
(b) For each constant in L, the assignment of an element in D.
(c) For each n-ary function symbol in L, the assignment of a mapping from Dn to
D.
Definition An interpretation I of a first order language L consists of a pre-
interpretation J with domain D of L together with the following:
For each n-ary predicate symbol in L, the assignment of a mapping from Dn into
(true, false} (or, equivalently, a relation on Dn).
We say I is based on J.
Definition Let J be a pre-interpretation of a first order language L. A variable
assignment (wrt 1) is an assignment to each variable in L of an element in the
domain of J.
Definition Let J be a pre-interpretation with domain D of a first order
language L and let V be a variable assignment. The term assignment (wrt J and V)
of the terms in L is defined as follows:
(a) Each variable is given its assignment according to V.
(b) Each constant is given its assignment according to J.
(c) If tl,···,t~ are the term assignments of tl'...,tn and f' is the assignment of the
n-ary function symbol f, then f'(tl,...,t~)eD is the term assignment of f(tl'...,tn).
Definition Let J be a pre-interpretation of a first order language L, V a
variable assignment wrt J, and A an atom. Suppose A is p(tl'...,tn) and dl'...,dn in
the domain of J are the term assignments of tl'...,tn wrt J and V.
We call
AJ,y =p(dl'...,dn) the I-instance of A wrt V. Let [AlJ ={AJ,V : V is a variable
assIgnment wrt J}. We call each element of [AlJ a I-instance of A. We also call
each p(dl,...,dn) a I-instance.
Definition Let I be an interpretation with domain D of a first order language L
and let V be a variable assignment. Then a formula in L can be given a truth
value, true or false, (wrt I and V) as follows:
(a) If the formula is an atom p(tl,...,tn), then the truth value is obtained by
calculating the value of p'(t'l'... ,t~), where p' is the mapping assigned to p by I and
t1,... ,t~ are the term assignments of tl,...,tn wrt I and V.
(b) If the formula has the form -F, FAG, FvG, F~G or F~G, then the truth
value of the formula is given by the following table:
F
G
-F
FAG
FvG
F~G
F~G
true
true
false
true
true
true
true
true
false
false
false
true
false
false
false
true
true
false
true
true
false
false
false
true
false
false
true
true
(c) If the formula has the form 3x F, then the truth value of the formula is true
if there exists deD such that F has truth value true wrt I and Vex/d), where Vex/d)
is V except that x is assigned d; otherwise, its truth value is false.
(d) If the formula has the form Vx F, then the truth value of the formula is
true if, for all deD, we have that F has truth value true wrt I and Vex/d);
otherwise, its truth value is false.
Clearly the truth value of a closed formula does not depend on the variable
assignment. Consequently, we can speak unambiguously of the truth value of a
closed formula wrt to an interpretation. If the truth value of a closed formula wrt
to an interpretation is true (resp., false), we say the formula is true (resp,. false)
wrt to the interpretation.
Definition Let I be an interpretation for a first order language L and let W be
a formula in L.
We say W is satisfiable in I if 3(W) is true wrt L
We say W is valid in I if 'V(W) is true wrt L
We say W is unsatisfiable in I if 3(W) is false wrt L
We say W is nonvalid in I if 'V(W) is false wrt L
Definition Let I be an interpretation of a first order language L and let F be a
closed formula of L. Then I is a model for F if F is true wrt I.
Example Consider the formula Vx3y p(x,y) and the following interpretation L
Let the domain D be the non-negative integers and let p be assigned the relation <.
Then I is a model of the formula, as is easily seen. In I, the formula expresses the
true statement that "for every non-negative integer, there exists a non-negative

14
Chapter 1. Preliminaries
§3. Interpretations and Models
15
integer which is strictly larger than it". On the other hand, I is not a model of the
formula 3y\ix p(x,y).
The axioms of a first order theory are a designated subset of closed formulas
in the language of the theory. For example, the first order theories in which we are
most interested have the clauses of a program as their axioms.
Definition Let T be a first order theory and let L be the language of T.
A
model for T is an interpretation for L which is a model for each axiom of T.
If T has a model, we say T is consistent.
The concept of a model of a closed formula can easily be extended to a model
of a set of closed formulas.
Definition Let S be a set of closed formulas of a first order language L and let
I be an interpretation of L. We say I is a model for S if I is a model for each
formula of S.
Note that, if S = {Fl'...,Fn} is a finite set of closed formulas, then I is a model
for S iff! is a model for FI A...AFn'
Definition Let S be a set of closed formulas of a first order language L.
We say S is satisfiable if L has an interpretation which is a model for S.
We say S is valid if every interpretation of L is a model for S.
We say S is unsatisfiable if no interpretation of L is a model for S.
We say S is nonvalid if L has an interpretation which is not a model for S.
Now
we
can
give
the
definition
of the
important
concept of logical
consequence.
Definition Let S be a set of closed formulas and F be a closed formula of a
first order language L. We say F is a logical consequence of S if, for every
interpretation I of L, I is a model for S implies that I is a model for F.
Note that if S = {F1,...,Fn} is a finite set of closed formulas, then F is a
logical consequence of S iff F1A...AFn~F is valid.
Proposition 3.1 Let S be a set of closed formulas and F be a closed formula
of a first order language L. Then F is a logical consequence of S iff S u {-F} is
unsatisfiable.
Proof Suppose that F is a logical consequence of S. Let I be an interpretation
of L and suppose I is a model for S. Then I is also a model for F. Hence I is not a
model for S u {-F}. Thus S u {-F} is unsatisfiable.
Conversely, suppose S u {-F} is unsatisfiable. Let I be any interpretation of
L. Suppose I is a model for S. Since S u {-F} is unsatisfiable, I cannot be a
model for -F. Thus I is a model for F and so F is a logical consequence of S. I
Example Let S = (p(a), \ix(p(x)~q(x))} and F be q(a). We show that F is a
logical consequence of S. Let I be any model for S. Thus p(a) is true wrt I. Since
\ix(p(x)~q(x)) is true wrt I, so is p(a)~q(a). Hence q(a) is true wrt I.
Applying these definitions to programs, we see that when we give a goal G to
the system, with program P loaded, we are asking the system to show that the set
of clauses P u {O} is unsatisfiable. In fact, if 0 is the goal f-B1,..·,Bn with
variables y1'''',yr' then proposition 3.1 states that showing P u {O} unsatisfiable is
exactly the same as showing that 3y1...3yr (B l'" ...ABn) is a logical consequence of
P.
Thus the basic problem is that of determining the unsatisfiability, or otherwise,
of P u {O}, where P is a program and 0 is a goal.
According to the definition,
this implies showing every interpretation of P u {O} is not a model.
Needless to
say, this seems to be a formidable problem. However, it turns out that there is a
much smaller and more convenient class of interpretations, which are all that need
to be investigated to show unsatisfiability.
These are the so-called Herbrand
interpretations, which we now proceed to study.
Definition A ground term is a term not containing variables.
Similarly, a
ground atom is an atom not containing variables.
Definition Let L be a first order language.
The Herbrand universe UL for L
is the set of all ground terms, which can be formed out of the constants and
function symbols appearing in L.
(In the case that L has no constants, we add
some constant, say, a, to form ground terms.)
Example Consider the program
p(x) f- q(f(x),g(x))
r(y) f-
which has an underlying first order language L based on the predicate symbols p, q
and r and the function symbols f and g. Then the Herbrand universe for L is

16
Chapter 1. Preliminaries
§3. Interpretations and Models
17
(a, f(a), g(a), f(f(a», f(g(a», g(f(a», g(g(a»,...}.
Definition Let L be a fIrst order language. The Herbrand base BL for L is the
set of all ground atoms which can be formed by using predicate symbols from L
with ground terms from the Herbrand universe as arguments.
Example For the previous example, the Herbrand base for L is
(p(a), q(a,a), r(a), p(f(a», p(g(a», q(a,f(a», q(f(a),a),... }.
Definition Let L be a fIrst order language.
The Herbrand pre-interpretation
for L is the pre-interpretation given by the following:
(a) The domain of the pre-interpretation is the Herbrand universe UL.
(b) Constants in L are assigned themselves in UL.
(c) If f is an n-ary function symbol in L, then the mapping from (UL)n into U
L
defIned by (t1,...,tn) ~ f(t1,...,tn) is assigned to f.
An Herbrand interpretation for L is any interpretation based on the Herbrand
pre-interpretation for L.
Since, for Herbrand interpretations, the assignment to constants and function
symbols is fIxed, it is possible to identify an Herbrand interpretation with a subset
of the Herbrand base. For any Herbrand interpretation, the corresponding subset of
the Herbrand base is the set of all ground atoms which are true
wrt the
interpretation. Conversely, given an arbitrary subset of the Herbrand base, there is
a corresponding Herbrand interpretation defIned by specifying that the mapping
assigned to a predicate symbol maps some arguments to "true" precisely when the
atom made up of the predicate symbol with the same arguments is in the given
subset.
This identifIcation of an Herbrand interpretation as a subset of the
Herbrand base will be made throughout. More generally, each interpretation based
on an arbitrary pre-interpretation J can be identifIed with a subset of J-instances, in
a similar way.
Definition Let L be a fIrst order language and S a set of closed formulas of L.
An Herbrand model for S is an Herbrand interpretation for L which is a model for
S.
It will often be convenient to refer, by abuse of language, to an interpretation
of a set S of formulas rather than the underlying first order language from which
the formulas come.
Normally, we assume that the underlying first order language
is defined by the constants, function symbols and predicate symbols appearing in
S.
With this understanding, we can now refer to the Herbrand universe Us and
Herbrand base BS of S and also refer to Herbrand interpretations of S as subsets of
the Herbrand base of S. In particular, the set of formulas will often be a program
P, so that we will refer to the Herbrand universe Up and Herbrand base Bp of P.
Example We now illustrate these concepts with the slowsort program.
This
program can be regarded as the set of axioms of a fIrst order theory. The language
of this theory is given by the constants 0 and nil, function symbols f and "." and
predicate symbols sort, perm, sorted, delete and ::;;. The only inference rule is the
resolution rule. The intended interpretation is an Herbrand interpretation. An atom
sort(l,m) is in the intended interpretation iff each of I and m is either nil or is a list
of terms of the form ;c(O) and m is the sorted version of 1. The other predicate
symbols have the obvious assignments. The intended interpretation is indeed a
model for the program and hence a model for the associated theory.
Next we show that in order to prove unsatisfiability of a set of clauses, it
sufftces to consider only Herbrand interpretations.
Proposition 3.2 Let S be a set of clauses and suppose S has a model. Then S
has an Herbrand model.
Proof Let I be an interpretation of S. We defIne an Herbrand interpretation I'
of S as follows:
It = {p(tl'...,tn)eBS : p(tl'...,tn) is true wrt I}.
It is straightforward to show that if I is a model, then l' is also a model. I
Proposition 3.3 Let S be a set of clauses. Then S is unsatisfiable iff S has no
Herbrand. models.
Proof If S is satisfIable, then proposition 3.2 shows that it has an Herbrand
model. I
It is important to understand that neither proposition 3.2 nor 3.3 holds if we
drop the restriction that S be a set of clauses. In other words, if S is a set of
arbitrary closed formulas, it is not generally possible to show S is unsatisfiable by
restricting attention to Herbrand interpretations.
Example Let S be {p(a), 3x -p(x)}. Note that the second formula in S is not a
clause. We claim that S has a model. It sufftces to let D be the set {O, I}, assign 0
to a and assign to p the mapping which maps 0 to true and 1 to false. Clearly this

18
Chapter 1. Preliminaries
§3. Interpretations and Models
19
gives a model for S.
However,
S
does
not
have
an
Herbrand
model.
The
only
Herbrand
interpretations for S are 0
(the empty set) and {p(a)}. But neither of these is a
model for S.
The point is worth emphasising. Much of the theory of logic programming is
concerned only
with
clauses
and
for
this
Herbrand interpretations
suffice.
However, non-clausal formulas do arise naturally (particularly in chapters 3, 4 and
5).
For this part of the
theory,
we
will be forced
to consider arbitrary
interpretations.
There are various normal forms for formulas.
One, which we will fInd useful,
is prenex conjunctive normal form.
Definition A formula is in prenex conjunctive normal form if it has the form
Qx1···Qxk «L11v...vL1m1)A...A(Ln1v...vLnmn»
where each Q is an existential or universal quantifIer and each L.. is a literal
IJ
.
The next proposition shows that each formula has an "equivalent" formula,
which is in prenex conjunctive normal form.
Definition We say two formulas
W and V are logically equivalent if
V(W~V) is valid.
In other words, two formulas are logically equivalent if they have the same
truth values wrt any interpretation and variable assignment.
Proposition 3.4 For each formula W, there is a formula V, logically equivalent
to W, such that V is in prenex conjunctive normal form.
Proof The proof is left as an exercise. (See problem 5.) II
When we discuss deductive database systems in chapter 5, we will base the
theoretical developments on a typed fIrst order theory.
The intuitive idea of a
typed theory (also called a many-sorted theory [33]) is that there are several sorts
of variables, each ranging over a different domain.
This can be thought of as a
generalisation of the theories we have considered so far which only allow a single
domain.
For example, in a database context, there may be several domains of
interest, such as the domain of customer names, the domain of supplier cities, and
so on.
For semantic integrity reasons, it is important to allow only queries and
database clauses which respect the typing restrictions.
In addition to the components of a fIrst order theory, a typed fIrst order theory
has a fInite set, whose elements are called types.
Types are denoted by Greek
letters, such as 1: and cr.
The alphabet of the typed fIrst order theory contains
variables, constants, function symbols, predicate symbols and quantifIers, each of
which is typed.
Variables and constants have types such as 1:. Predicate symbols
have types of the form 1:1x...X1:n and function symbols have types of the form
1:1x...X1:n
~1:. If f has type 1:1x...X1:n
~1:, we say f has range type 1:. For each type
1:, there is a universal quantifIer V1: and an existential quantifIer 31:'
Definition A term of type 1: is defIned inductively as follows:
(a) A variable of type 1: is a term of type 1:.
(b) A constant of type 1: is a term of type 1:.
(c) If f is an n-ary function symbol of type 1:1x...X1:n
~1: and ti is a term of type 1:i
(i=l,...,n), then f(tl'...,tn) is a term of type 1:.
Definition A typed (welljormed ) formula is defIned inductively as follows:
(a) If p is an n-ary predicate symbol of type 1:1x...X1:n and ti is a term of type 1:i
(i=l,...,n), then p(t1
,~..,tn) is a typed atomic formula.
(b) If F and G are typed formulas, then so are -F, FAG, FvG, F~G and F~G.
(c) If F is a typed formula and x is a variable of type 1:, then V1:x F and 31:x F are
typed formulas.
Definition The typed first order language given by an alphabet consists of the
set of all typed formulas constructed from the symbols of the alphabet.
We will fInd it more convenient to use the notation Vx/1: F in place of V1:x F.
Similarly, we will use the notation 3x/1: F in place of 31:x F. We let V(F) denote
the typed universal closure of the formula F and :3(F) denote the typed existential
closure. These are obtained by prefIxing F with quantifIers of appropriate types.
Definition A pre-interpretation of a typed fIrst order language L consists of
the following:
(a) For each type 1:, a non-empty set D1:' called the domain of type 1: of the pre-
interpretation.
(b) For each constant of type 1: in L, the assignment of an element in D1:'
(c) For each n-ary function symbol of type 1:1x...X1:n
~1: in L, the assignment of a
mapping from Dt x...xDt
to D1:'
1
n

20
Chapter 1. Preliminaries
§4. Unification
21
Definition An interpretation I of a typed first order language L consists of a
pre-interpretation J with domains {D't} of L together with the following:
For each n-ary predicate symbol of type 't1x...x'tn in L, the assignment of a
mapping from
D-r x...xD-r
into {true, false}
(or, equivalently, a relation on
1
n
Dt x...xDt
).
1
n
We say I is based on 1.
It is straightforward to define the concepts of variable assignment, term
assignment, truth value, model, logical consequence, and so on, for a typed first
order theory.
We leave the details to the reader.
Generally speaking, the
development of the theory of first order logic can be carried through with only the
most trivial changes for typed first order logic.
We shall exploit this fact in
chapter 5, where we shall use typed versions of results from earlier chapters.
The other fact that we will need about typed logics is that there is a
transformation of typed formulas into (type-free) formulas, which shows that the
apparent
extra generality
provided
by
typed
logics
is
illusory
[33].
This
transformation allows one to reduce the proof of a theorem in a typed logic to a
corresponding theorem in a (type-free) logic.
We shall use this transformation
process as one stage of the query evaluation process for deductive database
systems in chapter 5.
§4. UNIFICATION
Earlier we stated that the main purpose of a logic programming system is to
compute bindings. These bindings are computed by unification. In this section, we
present a detailed discussion of unifiers and the unification algorithm.
Definition A substitution a is a finite set of the form {v/tl'...,vJtn}, where
each Vi is a variable, each ti is a term distinct from viand the variables vl""'vn
are distinct. Each element v·/t. is called a binding for v"
a is called a ground
1 1
1
substitution if the ti are all ground terms. a is called a variable-pure substitution if
the ti are all variables.
Definition An expression is either a term, a literal or a conjunction or
disjunction of literals. A simple expression is either a term or an atom.
Definition Let a = {v1/t1,...,vJtn} be a substitution and E be an expression.
Then Ea, the instance of E by a, is the expression obtained from E by
simultaneously replacing each occurrence of the variable Vi in E by the term ti
(i=l,...,n). If Ea is ground, then Ea is called a ground instance of E.
Example Let E = p(x,y,f(a» and a = {xfb, y/x}. Then ES = p(b,x,f(a».
If S = {El'...,En} is a finite set of expressions and a is a substitution, then SS
denotes the set {E1a,...,Ena}.
Definition Let a = {u1/sl'...,urrr'sm} and a = {vlit1,...,VJtn} be substitutions.
Then the composition aa of a and a is the substitution obtained from the set
{u11s1a,...,urrr'sma, v1/tl""'vJtn}
by deleting any binding u!sia for which ui=sia and deleting any binding vitj for
which VjE {ul""'um}·
Example Let a = {x/f(y), y/z} and a = {x/a, ylb, z/y}. Then Sa = {x/f(b),
z/y}.
Definition The substitution given by the empty set is called the identity
substitution.
We denote the identity substitution by c. Note that Be = E, for all expressions
E.
The elementary properties of substitutions are contained in the following
proposition.
Proposition 4.1 Let a, a and y be substitutions. Then
(a) ae = ea = a.
(b) (ES)a = E(aa), for all expressions E.
(c) (Sa)y = a(cry).
Proof (a) This follows immediately from the definition of c.
(b) Clearly it suffices to prove the result when E is a variable, say, x.
Let
a = {u/sl'...,urrr'sm} and a = {v1/tl'...,vJtn}. If xi {u1,..·,um} U {vl""'vn}, then
(xa)a = x = x(aa).
If XE {ul'''''um}, say x=ui' then
(xS)a = sia = x(Sa).
If
XE{V1,...,vn}\{u1,...,um}, say x=vj' then (xa)a = tj = x(Sa).
(c) Clearly it suffices to show that if x is a variable, then x«aa)y) = x(S(cry».
In fact, x«aa)y) = (x(aa»y = «xa)a)y = (xa)(cry) = x(a(cry», by (b). I

22
Chapter 1. Preliminaries
§4. Unification
23
Proposition 4.1(a) shows that e acts as a left and right identity for composition.
The definition of composition of substitutions was made precisely to obtain (b).
Note that (c) shows that we can omit parentheses when writing a composition
81...8n of substitutions.
Example Let 8={x/f(y), y/z} and a={x/a, zIb}. Then 8a = lx/fey), yfb, zIb}.
Let E = p(x,y,g(z». Then E8 = p(f(y),z,g(z»
and (E8)a =
p(f(y),b,g(b». Also
E(8a) = p(f(y),b,g(b» = (E8)a.
Definition Let E and F be expressions. We say E and F are variants if there
exist substitutions 8 and a such that E=F8 and F=Ea. We also say E is a variant
of F or F is a variant of E.
Example p(f(x,y),g(z),a) is a variant of p(f(y,x),g(u),a). However, p(x,x) is not
a variant of p(x,y).
Definition Let E be an expression and V be the set of variables occurring in E.
A renaming substitution for E is a variable-pure substitution {x1/Y1,...,xiYn} such
that {xl""'xn} ~ V, the Yi are distinct and (V \ (xl'''''xn}) n {Yl""'Yn} = 0.
Proposition 4.2 Let E and F be expressions which are variants. Then there
exist substitutions 8 and a such that E=F8 and F=Ea, where 8 is a renaming
substitution for F and a is a renaming substitution for E.
Proof Since E and F are variants, there exist substitutions 8
and a
such that
1
1
E=F81 and F=Ea1. Let V be the set of variables occurring in E and let a be the
substitution obtained from a1 by deleting all bindings of the form x/t, where xiV.
Clearly F=Ea. Furthermore, E=F81=Ea81 and it follows
that a must be a
renaming substitution for E.
11III
We will be particularly interested in substitutions which unify a set of
expressions, that is, make each expression in the set syntactically identical.
The
concept of unification goes back to Herbrand [44] in 1930. It was rediscovered in
1963 by Robinson [88] and exploited in the resolution rule, where it was used to
reduce the combinatorial explosion of the search space.
We restrict attention to
(non-empty) finite sets of simple expressions, which is all that we require. Recall
that a simple expression is a term or an atom.
Definition Let S be a finite set of simple expressions. A substitution 8 is
called a unifier for S if S8 is a singleton.
A unifier 8 for S is called a most
general unifier (mgu) for S if, for each unifier a of S, there exists a substitution 'Y
such that a=8y.
Example (p(f(x),a), p(y,f(w»} is not unifiable, because the second arguments
cannot be unified.
Example (p(f(x),z), p(y,a)} is unifiable, since a = (y/f(a), x/a, zla} is a
unifier. A most general unifier is 8 = (y/f(x), zla}. Note that a = 8{x/a}.
It follows from the definition of an mgu that if 8 and a are both mgu's of
{E1,··.,En}, then E18 is a variant of E1a. Proposition 4.2 then shows that E1a can
be obtained from E18 simply by renaming variables. In fact, problem 7 shows that
mgu's are unique modulo renaming.
We next present an algorithm, called the unification algorithm, which takes a
finite set of simple expressions as input and outputs an mgu if the set is unifiable.
Otherwise, it reports the fact that the set is not unifiable. The intuitive idea behind
the unification algorithm is as follows. Suppose we want to unify two simple
expressions. Imagine two pointers, one at the leftmost symbol of each of the two
expressions. The pointers are moved together to the right until they point to
different symbols. An attempt is made to unify the two subexpressions starting
with these symbols by making a substitution. If the attempt is successful, the
process
is
continued
with
the
two
expressions
obtained
by
applying
the
substitution. If not, the expressions are not unifiable.
If the pointers eventually
reach the ends of the two expressions, the composition of all the substitutions
made is an mgu of the two expressions.
Definition Let S be a finite set of simple expressions. The disagreement set of
S is' defined as follows. Locate the leftmost symbol position at which not all
expressions in S have the same symbol and extract from each expression in S the
subexpression beginning at that symbol position. The set of all such subexpressions
is the disagreement set.
Example
Let
S = (p(f(x),h(y),a), p(f(x),z,a), p(f(x),h(y),b)}.
Then
the
disagreement set is (heY), z}.
We now present the unification algorithm. In this algorithm, S denotes a finite
set of simple expressions.

24
Chapter 1. Preliminaries
§4. Unification
25
UNIFICAnON ALGORITHM
1. Put k=O and 0'0=£'
2. If SO'k is a singleton, then stop; O'k is an mgu of S.
Otherwise, find the
disagreement set Dk of SO'k'
3. If there exist v and t in Dk such that v is a variable that does not occur in t,
then put O'k+l = O'k{v/t}, increment k and go to 2.
Otherwise, stop; S is not
unifiable.
The unification algorithm as presented above is non-deterministic to the extent
that there may be several choices for v and t in step 3. However, as we remarked
earlier, the application of any two mgu's produced by the algorithm leads to
expressions which differ only by a change of variable names.
It is clear that the
algorithm terminates because S contains only finitely many variables and each
application of step 3 eliminates one variable.
Example Let S = {p(f(a),g(x)), p(y,y)}.
(a) 0'0 = E.
(b) DO = {f(a), y}, 0'1 = {y/f(a)} and SO'I = {p(f(a),g(x)), p(f(a),f(a))}.
(c) D1 = {g(x), f(a)}. Thus S is not unifiable.
Example Let S = {p(a,x,h(g(z))), p(z,h(y),h(y))}.
(a) 0'0 = E.
(b) DO = {a, z}, 0'1 = {z/a} and SO'I = {p(a,x,h(g(a))), p(a,h(y),h(y))}.
(c) D1 = {x, hey)}, 0'2 = {z/a, x/h(y)} and S0'2 = {p(a,h(y),h(g(a))), p(a,h(y),h(y))}.
(d) D2 = {y, g(a)}, 0'3 = {z/a, x/h(g(a)), y/g(a)}
and S0'3 = {p(a,h(g(a)),h(g(a)))}.
Thus S is unifiable and 0'3 is an mgu.
In step 3 of the unification algorithm, a check is made to see whether v occurs
in t. This is called the occur check. The next example illustrates the use of the
occur check.
Example Let S = {p(x,x), p(y,f(y))}.
(a) 0'0 = E.
(b) DO = {x, y}, 0'1 = {x/y} and SO'I = {p(y,y), p(y,f(y))}.
(c) D1 = {y, fey)}. Since y occurs in fey), S is not unifiable.
Next we prove that the unification algorithm does indeed find an mgu of a
unifiable set of simple expressions. This result first appeared in [88].
Theorem 4.3 (Unification Theorem)
Let S be a finite set of simple expressions. If S is unifiable, then the
unification algorithm terminates and gives an mgu for S. If S is not unifiable, then
the unification algorithm terminates and reports this fact.
Proof We have already noted that the unification algorithm always terminates.
It suffices to show that if S is unifiable, then the algorithm finds an mgu. In fact,
if S is not unifiable, then the algorithm cannot terminate at step 2 and, since it
does terminate, it must terminate at step 3. Thus it does report the fact that S is
not unifiable.
Assume then that S is unifiable and let a be any unifier for S. We prove first
that, for ~O, if O'k is the substitution given in the kth iteration of the algorithm,
then there exists a substitution I'k such that a = O'kl'k'
Suppose first that k=O. Then we can put YO =a, since a=Ea. Next suppose,
for some ~O, there exists I'k such that a = O'kI'k' If SO'k is a singleton, then the
algorithm terminates at step 2. Hence we can confine attention to the case when
SO'k is not a singleton. We want to show that the algorithm will produce a further
substitution O'k+1 and that there exists a substitution I'k+1 such that a = O'k+Il'k+l'
Since SO'k is not a singleton, the algorithm will determine the disagreement set
Dk of SO'k and go to step 3. Since a = O'kl'k and a unifies S, it follows that I'k
unifies Dk. Thus Dk must contain a variable, say, v. Let t be any other term in Dk.
Then v cannot occur in i because Vl'k = tyk' We can suppose that {v/t} is indeed
the substitution chosen at step 3. Thus O'k+1 = O'k{v/t}.
We now define I'k+l =I'k'{v/Vl'k}' If I'k has a binding for v, then
I'k = {v/Vl'k} U I'k+l
= {v/tl'k} U I'k+l
(since Vl'k = tyk)
= {v/tyk+I} U I'k+1
(since v does not occur in t)
= {v/t}l'k+l
(by the definition of composition).
If I'k does not have a binding for v, then I'k+l = I'k' each element of Dk is a
variable and I'k = {v/t}l'k+l'
Thus a= O'kl'k = O'k{v/t}l'k+l = O'k+Il'k+1, as
required.
Now we can complete the proof. If S is unifiable, then we have shown that the
algorithm must terminate at step 2 and, if it terminates at the kth iteration, then
a= O'kI'k' for some I'k' Since O'k is a unifier of S, this equality shows that it is
indeed an mgu for S. I

26
Chapter 1. Preliminaries
§5. Fixpoints
27
The unification algorithm which we have presented can be very inefficient. In
the worst case, its running time can be an exponential function of the length of the
input.
Consider
the
following
example,
which
is
taken
from
[9].
Let
S = {p(xl""'xn), p(f(xO,xO),·..,f(xn_l,xn_l»}' Then 01 = {xl/f(xO'xO)} and SOl =
{p(f(xO'xO)'x2,·..,xn), p(f(xO,xO),f(f(xO,xO),f(xO,xO»,f(x2,x2),···,f(xn_1,xn_l»}. The
next substitution is 02 = {xl/f(xO'xO)' x2/f(f(xO'xO)' f(xO'xO))}' and so on. Note
that the second atom in SOn has 2k-1 occurrences of f in its kth argument
(1~:Lc;:;n). In particular, its last argument has 2n_l occurrences of f.
Now recall
that step 3 of the unification algorithm has the occur check. The perfonnance of
this check just for the last substitution will thus require exponential time. In fact,
printing on also requires exponential time. This example shows that no unification
algorithm which explicitly presents the (final) unifier can be linear.
Much more efficient unification algorithms than the one presented above are
known. For example, [67] and [80] give linear algorithms (see also [68]). In [80],
linearity is achieved by the use of a carefully chosen data structure for representing
expressions and avoiding the explicit presentation of the unifier, which is instead
presented as a composition of constituent substitutions.
Despite its linearity, this
algorithm is not employed in PROLOG systems. Instead, most use essentially the
unification algorithm presented earlier in this section, but with the expensive occur
check omitted!
From a theoretical viewpoint, this is a disaster because it destroys
the soundness of SLD-resolution. We discuss this matter further in §7.
§5. FIXPOINTS
Associated with every definite program is a monotonic mapping which plays. a
very important role in the theory. This section introduces the requisite concepts and
results concerning monotonic mappings and their fixpoints.
Definition Let S be a set. A relation R on S is a subset of SxS.
We usually use infix notation writing (x,y)eR as xRy.
Definition A relation R on a set S is a partial order if the following
conditions are satisfied:
(a) xRx, for all xeS.
(b) xRy and yRx imply x=y, for all x,yeS.
(c) xRy and yRz imply xRz, for all x,y,zeS.
Example Let S be a set and 2S be the set of all subsets of S. Then set
inclusion, S;;;;, is easily seen to be a partial order on 2S.
We adopt the standard notation and use ~ to denote a partial order. Thus we
have (a) x~x, (b) x~y and y~x imply x=y and (c) x~y and y~z imply x~z, for all
x,y,zeS.
Definition Let S be a set with a partial order ~. Then ae S is an upper bound
of a subset X of S if x~a, for all xeX. Similarly, beS is a lower bound of X if
b~x, for all xeX.
Definition Let S be a set with a partial order ~. Then aeS is the least upper
bound of a subset X of S if a is an upper bound of X and, for all upper bounds a'
of X, we have ~a'. Similarly, beS is the greatest lower bound of a subset X of S
if b is a lower bound of X and, for all lower bounds b' of X, we have b·~b.
The least upper bound of X is unique, if it exists, and is denoted by lub(X).
Similarly, the greatest lower bound of X is unique, if it exists, and is denoted by
glb(X).
Definition A partially ordered set L is a complete lattice if lub(X) and glb(X)
exist for every subset X of L.
We let T
denote the top element lub(L) and .1 denote the bottom element
glb(L) of the complete lattice L.
Example In the previous example, 2S under S;;;; is a complete lattice.
In fact,
the least upper bound of a collection of subsets of S is their union and the greatest
lower bound is their intersection. The top element is S and the bottom element is
0.
Definition Let L be a complete lattice and T : L~L be a mapping. We say T
is monotonic if T(x)~T(y), whenever x~y.
Definition Let L be a complete lattice and X S;;;; L.
We say X is directed if
every finite subset of X has an upper bound in X.
Definition Let L be a complete lattice and T : L~L be a mapping. We say T
is continuous if T(1ub(X» = lub(T(X», for every directed subset X of L.

28
Chapter 1. Preliminaries
§5. Fixpoints
29
By taking X = {x,y}, we see that every continuous mapping is monotonic.
However, the converse is not true. (See problem 12.)
Our interest in these definitions arises from the fact that for a definite program
P, the collection of all Herbrand interpretations forms a complete lattice in a
natural way and also because there is a continuous mapping associated with P
defined on this lattice. Next we study fixpoints of mappings defined on lattices.
Definition Let L be a complete lattice and T : L~L be a mapping.
We say
aeL is the least fzxpoint of T if a is a fixpoint (that is, T(a)=a) and for all fixpoints
b of T, we have ~b. Similarly, we define greatest fzxpoint.
The next result is a weak form of a theorem due to Tarski [103], which
generalises an earlier result due to Knaster and Tarski. For an interesting account
of the history of propositions 5.1, 5.3 and 5.4, see [55].
Proposition 5.1 Let L be a complete lattice and T : L~L be monotonic. Then
T has a least fixpoint, Ifp(T), and a greatest fixpoint, gfp(T). Furthermore, Ifp(T) =
glb{x: T(x)=x} = glb{x: T(x)~x} and gfp(T).= lub{x: T(x)=x} = lub{x: x~T(x)}.
Proof Put G = {x : T(x)~x} and g = glb(G). We show that geG.
Now g::;;x,
for all xeG, so that by the monotonicity of T, we have T(g)::;;T(x), for all xeG.
Thus T(g)~x, for all xeG, and so T(g)~g, by the definition of glb. Hence geG.
Next we show that g is a fixpoint of T. It remains to show that g~T(g). Now
T(g)~g implies
T(T(g»~T(g) implies T(g)eG.
Hence
g~T(g), so that g is a
fixpoint of T.
Now put g' = glb{x : T(x)=x}.
Since g is a fixpoint, we have g'::;;g.
On the
other hand, {x : T(x)=x} !:: {x : T(x)~x} and so g~g'. Thus we have g=g' and the
proof is complete for Ifp(T).
The proof for gfp(T) is similar.
III
Proposition 5.2 Let L be a complete lattice and T: L~L be monotonic.
Suppose aeL and
~T(a). Then there exists a fixpoint a' of T such that
~a'.
Similarly, if beL and T(b)~b, then there exists a fixpoint b' of T such that b'~b.
Proof By proposition 5.1, it suffices to put a'=gfp(T) and b'=lfp(T).
III
We will also require the concept of ordinal powers of T. First we recall some
elementary properties of ordinal numbers, which we will refer to more simply as
ordinals. Intuitively, the ordinals are what we use to count with. The first ordinal 0
is defined to be 0. Then we define 1 = {0} = {OJ, 2 = {0, {0}} = {O, l},
3 = {0, {0}, {0, {0}}} = {O, 1, 2}, and so on. These are the finite ordinals, the
non-negative integers.
The first infinite ordinal is ro = {O, 1, 2,... }, the set of all
non-negative integers. We adopt the convention of denoting finite ordinals by
roman letters n, m,..., while arbitrary ordinals will be denoted by Greek letters a,
~,.... We can specify an ordering < on the collection of all ordinals by defining
a<~ if ae~. For example, n<ro, for all finite ordinals n. We will normally write
ne ro rather than n<ro. If a is an ordinal, the successor of a is the ordinal a+1 =
a u {a}, which is the least ordinal greater than a.
a+1 is then said to be a
successor ordinal. For example, 1 = 0+1, 2 = 1+1, 3 = 2+1, and so on. If a is a
successor ordinal, say a = ~+1, we denote ~ by a-I. An ordinal a is said to be a
limit ordinal if it is not the successor of any ordinal. The smallest limit ordinal
(apart from 0) is roo After ro comes ro+1 = ro u fro}, ro+2 = (ro+1)+1, ro+3, and so
on. The next limit ordinal is ro2, which is the set consisting of all n, where ne ro,
and all ro+n, where nero. Then come ro2+1, ro2+2,...,ro3, ro3+1,...,r04,...,cpn,....
We will also require the principle of transfinite induction, which is as follows.
Let P(a) be a property of ordinals. Assume that for all ordinals
~, if P(y) holds for
all y<~, then P(~) holds. Then P(a) holds for all ordinals a.
Now we can give the definition of the ordinal powers of T.
Definition Let L be a complete lattice and T : L~L be monotonic. Then we
define
Tio =..L
Tia = T(Ti(a-1», if a is a successor ordinal
Tia = lub{Ti~ : ~<a}, if a is a limit ordinal
T.iO =T
T.ia = T(T.i(a-1», if a is a successor ordinal
T.ia = glb{T.i~ : ~<a}, if a is a limit ordinal
Next we give a well-known characterisation of Ifp(T) and gfp(T) in terms of
ordinal powers of T.
Proposition 5.3 Let L be a complete lattice and T : L~L be monotonic.
Then, for any ordinal a, Tia ~ Ifp(T) and T.ia ~ gfp(T). Furthermore, there exist
ordinals ~1 and ~2 such that Y1 ~ ~1 implies TiY1 = Ifp(T) and Y2 ~ ~2 implies
T.iY2 = gfp(T).

30
Chapter 1. Preliminaries
Problems for Chapter 1
31
Proof The proof for Ifp(T) follows from (a) and (e) below. The proofs of (a),
(b) and (c) use transfinite induction.
(a) For all a., Tia. :s; Ifp(T):
If a. is a limit ordinal, then Tia. = lub{Tip : p<a.} :s; Ifp(T), by the induction
hypothesis.
If
a.
is
a
successor
ordinal,
then
Tia. = T(Ti(a.-l»
:s;
T(lfp(T» = Ifp(T), by the induction hypothesis, the monotonicity of T and the
fixpoint property.
(b) For all a., Tia.:S; Ti(a.+l):
If a. is a successor ordinal, then Tia. = T(Ti(a.-l»
:s; T(Tia.) = Ti(a.+l),
using the induction hypothesis and the monotonicity of T. If a. is a limit
ordinal, then Tia. =
lub{TiP: P<a.} :s; lub{Ti(p+l) : p<a.} :s; T(lub{Tip :
P<a.}) = Ti(a.+l), using the induction hypothesis and monotonicity of T.
(c) For all a.,p, a.<P implies Tia. :s; Tip:
If 13 is a limit ordinal, then Tia. :s; lub{Tiy : r<p} = Tip. If 13 is a successor
ordinal, then a. :s; 13--1 and so Tia. :s; Ti(13--1) :s; Tip, using the induction
hypothesis and (b).
(d) For all a.,p, if a.<P and Tia. = TiP, then Tia. = Ifp(T):
Now Tia. :s; Ti(a.+l) :s; Tip, by (c). Hence Tia. = Ti(a.+l) =T(Tia.) and so
Tia. is a fixpoint. Furthermore, Tia. = Ifp(T), by (a).
(e) There exists 13 such that y ~ 13 implies Tiy =Ifp(T):
Let a. be the least ordinal of cardinality greater than the cardinality of L.
Suppose that Tio :t= Ifp(T), for all o<a.. Define h:a.~L by h(o) = Tio. Then,
by (d), h is injective, which contradicts the choice of a.. Thus Tip = Ifp(T), for
some p<a., and the result follows from (a) and (c).
The proof for gfp(T) is similar.
l1li
The least a. such that Tia. = Ifp(T) is called the closure ordinal of T. The next
result, which is usually attributed to Kleene, shows that under the stronger
assumption that T is continuous, the closure ordinal of T is :s; roo
Proposition 5.4 Let L be a complete lattice and T : L~L be continuous. Then
Ifp(T) = Tiro.
Proof By proposition 5.3, it suffices to show that Tiro is a fixpoint. Note that
{Tin: nero} is directed, since T is monotonic.
Thus T(Tiro) = T(lub{Tin
nero}) =lub{T(Tin) : nero} = Tiro, using the continuity of T.
l1li
The analogue of proposition 5.4 for gfp(T) does not hold, that is, gfp(T) may
not be equal to T.!ro. A counterexample is given in the next section.
PROBLEMS FOR CHAPTER 1
1. Consider the interpretation I:
Domain is the non-negative integers
s is assigned the successor function x ~ x+1
a is assigned 0
b is assigned 1
p is assigned the relation {(x,y) : x>y}
q is assigned the relation {x : x>O}
r is assigned the relation {(x,y) : x divides y}
For each of the following closed formulas, determine the truth value of the formula
wrt I:
(a) \ix3yp(x,y)
(b) 3x \iyp(x,y)
(c) p(s(a),b)
(d) \ix(q(x)~p(x,a»
(e) \ix p(s(x),x)
(f) \ix \iy(r(x,y)~-p(x,y»
(g) \ix(3yp(x,y) v r(s(b),s(x»
~ q(x»
2. Determine whether the following formulas are valid or not:
(a) \ix3yp(x,y) ~ 3y\ixp(x,y)
(b) 3y\ixp(x,y) ~ \ix3yp(x,y)
3. Consider the formula
(\ixp(x,x) 1\ \ix\iy\iz [(P(x,Y)l\p(y,z»~p(x,z)]1\ \ix\iy [p(x,y)vp(y,x))) ~ 3y\ix p(y,x)
(a) Show that every interpretation with a finite domain is a model.
(b) Find an interpretation which is not a model.
4. Complete the proof of proposition 3.2.
5. Let W be a formula. Suppose that each quantifier in W has a distinct variable

32
Chapter 1. Preliminaries
Problems for Chapter 1
33
following it and no variable in W is both bound and free.
(This can be achieved
by renaming bound variables in W, if necessary.) Prove that W can be transformed
to a logically equivalent formula in prenex conjunctive normal form (called a
prenex conjunctive normal form of W) by means of the following transformations:
(a) Replace
all occurrences of Ff-G by Fv-G
all occurrences of F~G by (FV-G)A(-FvG).
(b) Replace
-\ixF by 3x-F
-3xF by \ix-F
-(FvG) by -FA-G
-(FAG) by -Fv-G
--F by F
until each occurrence of - immediately precedes an atom.
(c) Replace
3xF v G by 3x(FvG)
F v 3xG by 3x(FvG)
\ixF v G by \ix(FvG)
F v \ixG by \ix(FvG)
3xF AG by 3x(FAG)
FA 3xG by 3x(FAG)
\ixF AG by \iX(FAG)
FA \ixG by \iX(FAG)
until all quantifiers are at the front of the formula.
(d) Replace
(FAG)vH by (FVH)A(GvH)
FV(GAH) by (FVG)A(FvH)
until the formula is in prenex conjunctive normal form.
6. Let W be a closed formula. Prove that there exists a formula V, which is a
conjunction of clauses, such that W is unsatisfiable iff V is unsatisfiable.
7. Suppose a1 and a2 are substitutions and there exist substitutions 0"1 and 0"2 such
that a1 = a20"1 and a2 =a10"2' Show that there exists a variable-pure substitution
Ysuch that a1 = a2y.
8. A substitution a is idempotent if a=aa. Let a= {x1/tl'.",xitn} and suppose V
is the set of variables occurring in terms in {tl'".,tn}. Show that a is idempotent
iff {x1,...,xn} n V = 0.
9. Prove that each mgu produced by the unification algorithm is idempotent.
10. Let a be a unifier of a finite set S of simple expressions. Prove that a is an
mgu and is idempotent iff, for every unifier 0" of S, we have 0" = aO".
11. For each of the following sets of simple expressions, determine whether mgu's
exist or not and find them when they exist:
(a) {p(f(y),w,g(z», p(u,u,v)}
(b) {p(f(y),w,g(z», p(v,u,v)}
(c) {p(a,x,f(g(y»), p(z,h(z,w),f(w»}
12. Find a complete lattice L and a mapping T : L~L such that T is monotonic
but not continuous.
13. Let L be a complete lattice and T : L~L be monotonic.
(a) Suppose aeL and a::;;T(a). Define
TO(a) = a
TX(a) = T(TX-1(a», if Cl is a successor ordinal
TX(a) = IUb{T~(a) : ~<Cl}, if Cl is a limit ordinal.
Prove that there exists an ordinal ~ such that T~(a) is a fixpoint of T and a~T~(a).
(b) Suppose beL and T(b)~b. Define
~(b) = b
TCl(b) = T(TCl- 1(b», if Cl is a successor ordinal
TCl(b) = glb{T~(b): ~<Cl}, if Cl is a limit ordinal.
Prove th~t:Jhereexists an ordinal y such that TY(b) is a fixpoint of T and TY(b)~b.

DEFINITE PROGRAMS
This chapter is concerned with the declarative and procedural semantics of
definite programs. First, we introduce the concept of the least Herbrand model of
a definite program and prove various important properties of such models.. Next,
we define correct answers, which provide a declarative description of the desired
output from a program and a goal. The procedural counterpart of a correct answer
is a computed answer, which is defined using SLD-resolution.
We prove that
every computed answer is correct and that every correct answer is an instance of a
computed answer.
This establishes the soundness and completeness of SLD-
resolution, that is, shows that SLD-resolution produces only and all correct
answers.
Other
important results
established are
the
independence
of the
computation rule and the fact that any computable function can be computed by a
definite program.
Two pragmatic aspects of PROLOG implementations are also
discussed. These are the omission of the occur check from the unification
algorithm and the control facility, cut.
§6. DECLARATIVE SEMANTICS
This section introduces the least Herbrand model of a definite program. This
particular model plays a central role in the theory.
We show that the least
Herbrand
model
is
precisely
the
set of ground
atoms
which
are
logical
consequences of the definite program. We also obtain an important fixpoint
characterisation of the least Herbrand modeL Finally, we define the key concept of
correct answer.
First, let us recall some definitions given in the previous chapter.

36
Chapter 2.. Definite Programs
§6. Declarative Semantics
37
Definition A definite program clause is a clause of the form
A~Bl,···,Bn
which contains precisely one atom (viz. A) in its consequent. A is called the head
and Bl'...,Bn is called the body of the program clause.
Definition A definite program is a finite set of definite program clauses.
Definition A definite goal is a clause of the form
~Bl,···,Bn
that is, a clause which has an empty consequent.
In later chapters, we will consider more general programs, in which the body
of a program clause can be a conjunction of literals or even an arbitrary formula.
Later we will also consider more general goals. The theory of definite programs is
simpler than the theory of these more general classes of programs because definite
programs do not allow negations in the body of a clause. This means we can avoid
the theoretical and practical difficulties of handling negated subgoals.
Definite
programs thus provide an excellent starting point for the development of the
theory.
Proposition 6.1 (Model Intersection Property)
Let P be a definite program and {Mi}iEI be a non-empty set of Herbrand
models for P. Then '\EIMi is an Herbrand model for P.
Proof Clearly (\EIMi is an Herbrand interpretation for P. It is straightforward
to show that ''iEIMi is a model for P. (See problem 1.) III
Since every definite program P has Bp as an Herbrand model, the set of all
Herbrand models for P is non-empty. Thus the intersection of all Herbrand models
for P is again a model, called the least Herbrand model, for P. We denote this
model by Mp.
The intended interpretation of a definite program p can, of course, be different
from Mp. However, there are very strong reasons for regarding Mp as the natural
interpretation of a program. Certainly, it is usual for the programmer to have in
mind the "free" interpretation of the constants and function symbols in the
program given by an Herbrand interpretation. Furthermore, the next theorem shows
that the atoms in Mp are precisely those that are logical consequences of the
program. This result is due to van Emden and Kowalski [107].
Theorem 6.2 Let P be a definite program. Then Mp = {AEBp : A is a logical
consequence of Pl.
Proof We have that
A is a logical consequence of P
iff P u {-A} is unsatisfiable, by proposition 3.1
iff p u {-A} has no Herbrand models, by proposition3.3
iff -A is false wrt all Herbrand models of P
iff A is true wrt all Herbrand models of P
iff AEMp. III
We wish to obtain a deeper characterisation of Mp using fixpoint concepts. For
this we need to associate a complete lattice with every definite program.
Let P be a definite program.
Then
2Bp, which is the set of all Herbrand
interpretations of P, is a complete lattice under the partial order of set inclusion
l:;. The top element of this lattice is Bp and the bottom element is 0. The least
upper bound of any set of Herbrand interpretations is the Herbrand interpretation
which is the union of all the Herbrand interpretations in the set.
The greatest
lower bound is the intersection.
Definition
Let P be a definite program.
The mapping Tp : 2Bp ~ 2Bp is
defined
as
follows.
Let
I
be
an
Herbrand
interpretation.
Then
Tp(1) =
{AEBp : A~Al'...,An is a ground instance of a clause in P and {Al'...,An} l:; I}.
Clearly Tp is monotonic.
Tp provides the link: between the declarative and
procedural semantics of P. This definition was first given in [107].
Example Consider the program P
p(f(x»
~ p(x)
q(a) ~ p(x)
Put II =Bp, 12 =Tp(Il) and 13 =0. Then Tp(ll) = {q(a)} U {p(f(t» : tEUp },
Tp(~) = {q(a)} u {p(f(f(t») : tEUp} and Tp(I3) = 0.
Proposition 6.3 Let P be a definite program.
Then the mapping Tp is
continuous.
Proof Let X be a directed subset of 2BP. Note first that {Al,oo.,An} l:; lub(X)
iff {Al'...,An} l:; I, for some lEX. (See problem 3.) In order. to show Tp is
continuous, we have to show Tp(lub(X»
= lub(Tp(X», for each directed subset X.

38
Chapter 2. Definite Programs
§6. Declarative Semantics
39
Now we have that
AeTp(lub(X)
iff A+-Al'
,An is a ground instance of a clause in P and {Al'
,An} k lub(X)
iff A+-Al'
,An is a ground instance of a clause in P and {Al'
,An} k I, for
some leX
iff AeTp(I), for some leX
iff Aelub(Tp(X». I
Herbrand interpretations which are models can be characterised in terms of 'Ip.
Proposition 6.4
Let P be a definite
program and I
be
an
Herbrand
interpretation of P. Then I is a model for P iff T (I) c I
P -'
Proof I is a model for P iff for each ground instance A+-Al'...,A
of each
clause in P, we have {Al'...,An} k I implies AeI iff Tp(I) k 1. I
n
Now we come to the first major result of the theory. This theorem, which is
due to van Emden and Kowalski [107], provides a fixpoint characterisation of the
least Herbrand model of a definite program.
Theorem 6.S (Fixpoint Characterisation of the Least Herbrand Model)
Let P be a definite program. Then Mp = Ifp(Tp) = Tpteo.
Proof Mp = glb{I : I is an Herbrand model for P}
= glb{I : Tp(I) k I},
by proposition 6.4
= Ifp(Tp),
by proposition 5.1
= Tpteo,
by propositions 5.4 and 6.3. I
However, it can happen that gfp(Tp) ::F- TpJ-eo.
Example Consider the program P
p(f(x» +- p(x)
q(a) +- p(x)
Then TpJ-eo = {q(a)}, but gfp(Tp) = 0. In fact, gfp(Tp) = Tp J-(eo+1).
Let us now turn to the definition of a correct answer. This is a central concept
in logic programming
and provides much of the focus
for
the
theoretical
developments.
Definition Let P be a definite program and G a definite goal.
An answer for
p u {G} is a substitution for variables of G.
It is understood that the answer does not necessarily contain a binding for
every variable in G. In particular, if G has no variables the only possible answer is
the identity substitution.
Definition Let P be a definite program, G a definite goal +-AI,...,Ak and e an
answer for P u {G}.
We say that e is a correct answer for P u {G}
if
V«A1A...AAk)S) is a logical consequence of P.
Using
proposition
3.1,
we
see
that
e
is
a
correct
answer
iff
p u {-V«A1A...AAk)e)} is unsatisfiable.
The above definition of correct answer
does indeed capture the intuitive meaning of this concept. It provides a declarative
description of the desired output from a definite program and goal. Much of this
chapter will be concerned with showing the equivalence between this declarative
concept and the corresponding procedural one, which is defined by the refutation
procedure used by the system.
As well as returning substitutions, a logic programming system may also return
the answer "no". We say the answer "no" is correct if P u {G} is satisfiable.
Theorem 6.2 and the definition of correct answer suggest that we may be able
to
strengthen
theorem
6.2
by
showing
that
an
answer
e
is
correct
iff
V«A1A...AAk)S)
is
true
wrt
the
least
Herbrand
model
of
the
program.
Unfortunately, the result does not hold in this generality, as the following example
shows.
Example Consider the program P
p(a) +-
Let G be the goal +-p(x) and e be the identity substitution. Then Mp = {p(a)} and
so "Ix p(x)e is true in Mp. However, e is not a correct answer, since "Ix p(x)e is
not a logical consequence of P.
The reason for the problem here is that -"Ix p(x) is not a clause and hence we
cannot restrict attention to Herbrand interpretations when attempting to establish
the unsatisfiability of {p(a)+-} u {-"Ix p(x)}.
However, if we make a restriction
on e, we do obtain a result which generalises theorem 6.2.

40
Chapter 2. Definite Programs
§7. Soundness of SLD-Resolution
41
Theorem 6.6 Let P be a definite program and G a definite goal f--Al,...•Ak.
Suppose 8 is an answer for P u {G} such that (Al" ..."Ak)8 is ground. Then the
following are equivalent:
(a) 8 is correct.
(b) (Al " ..."Ak)8 is true wrt every Herbrand model of P.
(c) (Al ".·."Ak)8 is true wrt the least Herbrand model of P.
Proof Obviously. it suffices to show that (c) implies (a). Now
(AlA..."Ak)e is true wrt the least Herbrand model of P
implies (Al" "Ak)e is true wrt all Herbrand models of P
implies -(Al"
"Ak)8 is false wrt all Herbrand models of P
implies P u {-(A1" "Ak)8) has no Herbrand models
i~plies P u {-(Al"
"Ak)8) has no models. by proposition 3.3. II
§7. SOUNDNESS OF SLP.RESOLUTION
In this section. the procedural semantics of definite programs is introduced.
Computed answers are defined and the soundness of SLD-resolution is established.
The implications of omitting the occur check from the unification algorithm are
also discussed.
Although all the requisite results concerning SLD-resolution will
be discussed in this and subsequent sections, it would be helpful for the reader to
have a wider perspective on automatic theorem proving. We suggest consulting [9],
[14]. [64] or [66].
There are many refutation procedures based on the resolution inference rule.
which are refinements of the original procedure of Robinson [88]. The refutation
procedure of interest here was first described by Kowalski [48].
It was called
SW-resolution in [4]. (The term LUSH-resolution has also been used [46].) SLD-
resolution stands for SL-resolution for Definite clauses. SL stands for Linear
resolution with Selection function.
SL-resolution. which is due to Kowalski and
Kuehner [53]. is a direct descendant of the model elimination procedure of
Loveland [65]. In this and the next two sections, we will be concerned with SLD-
refutations. In §1O. we will study SLD-refutation procedures.
Definition Let G be f--AI'....Am.....Ak and C be Af--BI'...,Bq.
Then G' is
derived from G and C using mgu 8 if the following conditions hold:
(a) Am is an atom. called the selected atom, in G.
(b) 8 is an mgu of Am and A.
(c) G' is the goal f--(AI'....Am_l.BI'....Bq.Am+l.....Ak)8.
In resolution terminology. G' is called a resolvent of G and C.
Definition Let P be a definite program and G a definite goal.
An SW-
derivation of P u {G} consists of a (finite or infinite) sequence GO=O' Gl.... of
goals. a sequence CI' C2.... of variants of program clauses of P an~ a sequence 81'
82.... of mgu's such that each Gi+l is derived from Gi and Ci+l usmg 8i+l .
Each C. is a suitable variant of the corresponding program clause so that Ci
does not h~ve any variables which already appear in the derivation up to Gi_I"
This can be achieved. for example. by subscripting variables in G by 0 and
variables in C. by i. This process of renaming variables is called standardising the
1
variables apart.
It is necessary. otherwise. for example. we would not be able to
unify p(x) and p(f(x»
in f--p(x) and p(f(x»f--.
Each program clause variant CI'
C2.... is called an input clause of the derivation.
Definition An SW-refutation of P u {G}
is a finite SLD-derivation of
P u {G} which has the empty clause 0 as the last goal in the derivation. If Gn=o.
we say the refutation has length n.
Throughout this chapter. a "derivation" will always mean an SLD-derivation
and a "refutation" will always mean an SLD-refutation.
We can picture SLD-
derivations as in Figure 1.
It will be convenient in some of the results to have a slightly more general
concept available.
Definition An unrestricted SW-refutation is an SLD-refutation. except that we
drop the requirement that the substitutions 8i be most general unifiers.
They are
only required to be unifiers.
SLD-derivations may be finite or infinite. A finite SLD-derivation may be
successful or failed. A successful SLD-derivation is one that ends in the empty
clause. In other words. a successful derivation is just a refutation. A failed SLD-
derivation is one that ends in a non-empty goal with the property that the selected
atom in this goal does not unify with the head of any program clause. Later we
shall see examples of successful. failed and infinite derivations (see Figure 2 and
Figure 3).

42
Chapter 2. Definite Programs
§7. Soundness of SLD-Resolution
43
G
OfG/Cl'01
Gt/C2.02
G2
j
Fig. 1. An SLD-derivation
Definition Let P be a definite program. The success set of P is the set of all
AEBp such that P U {f-A} has an SLD-refutation.
The success set is the procedural counterpart of the least Herbrand model. We
shall see later that the success set of P is in fact equal to the least Herbrand model
of P. Similarly, we have the procedural counterpart of a correct answer.
Definition Let P be a definite program and G a definite goal.
A computed
answer S for P u {G} is the substitution obtained by restricting the composition
SI,,,Sn to the variables of G, where Sl'""Sn is the sequence of mgu's used in an
SLD-refutation of P u {G}.
Example If P is the slowsort program and G is the goal f-sort(17.22.6.5.nil,y),
then {y/5.6.l7.22.nil} is a computed answer.
The first soundness result is that computed answers are correct.
In the form
below, this result is due to Clark [16].
Theorem 7.1 (Soundness of SLD-Resolution)
Let P be a definite program and G a definite goal.
Then every computed
answer for P u {G} is a correct answer for P u {G}.
Proof
Let
G
be
the
goal
f-Al'...,Ak
and Sl'""Sn be the sequence of
mgu's
used
in
a
refutation
of
P u {G}.
We
have
to
show
that
.'d«AlA...AAk)Sl",Sn) is a logical consequence of P.
The result is proved by
induction on the length of the refutation.
Suppose first that n=1.
This means that G is a goal of the form f-Al , the
program has a unit clause of the form Af- and AlSl = ASI. Since AlSlf- is an
instance of a unit clause of P, it follows that 'd(AlSl) is a logical consequence of
P.
Next suppose that the result holds for computed answers which come from
refutations of length n-1.
Suppose Sl'""Sn is the sequence of mgu's used in a
refutation of P u {G} of length n. Let Af-Bl'...,B
(q~O) be the first input clause
and
A
the
selected
atom
of
G.
Byq the
induction
hypothesis,
m
'd«AlA...AAm_lAB lA
ABqAAm+lA...AAk)Sr"Sn) is a logical consequence of P.
Thus, if q>O, 'd«Bl A ABq)8l",Sn) is a logical consequence of P. Consequently,
'd(AmSl...Sn), which is the same as 'd(ASl...Sn), is a logical consequence of P.
Hence 'd«AlA...AAk)Sl",Sn) is a logical consequence of P. II
Corollary 7.2 Let P be a definite program and G a definite goal.
Suppose
there exists an SLD-refutation of P u {G}. Then P u {G} is unsatisfiable.
Proof Let G be the goal f-Al'...,Ak. By theorem 7.1, the computed answer S
coming from the refutation is correct.
Thus 'd«Al"...AAk)S) is a logical

44
Chapter 2. Definite Programs
§7. Soundness of SLD-Resolution
45
consequence of P. It follows that P u {G} is unsatisfiable. ..
Corollary 7.3 The success set of a definite program is contained in its least
Herbrand model.
Proof Let the program be P, let AeBp and suppose P u {f-A} has a
refutation. By theorem 7.1, A is a logical consequence of P. Thus A is,in the least
Herbrand model of P. ..
It is possible to strengthen corollary 7.3.
We can show that if AeBp and
P U {f-A} has a refutation of length n, then AeTpin. This result is due to Apt
and van Emden [4].
If A is an atom, we put [A] = {A'eBp : A'=Aa, for some substitution a}.
Thus [A] is the set of all ground instances of A. Equivalently, [A] is [A]J' where J
is the Herbrand pre-interpretation.
Theorem 7.4 Let P be a definite program and G a definite goal f-Al,...,A
k
.
Suppose that P U {G} has an SLD-refutation of length n and a1'...,a
is the
sequence
of
mgu's
of
the
SLD-refutation.
Then
we
hav~
that
uf=I[Ajel·..en] ~ Tpin.
Proof The result is proved by induction on the length of the refutation.
Suppose first that n=l. Then G is a goal of the form f-A1' the program has a unit
clause of the form Af-
and AIel
= Ael .
Clearly,
[A] ~ Tpil
and so
[AIel] ~ Tpil.
Next suppose the result is true for refutations of length n-l and consider a
refutation of p U {G} of length n. Let AJ. be an atom of G.
Suppose first that A.
.
h
J
IS not ~ e select~ atom of G. Then Ajel is an atom of G1' the second goal of the
refutation.
The mduction hypothesis implies that [Ajel e2..,en] ~ Tpi(n-l) and
Tpi(n-l) ~ Tpin, by the monotonicity of Tp.
~ow suppose that Aj is the selected atom of G. Let Bf-Bl'...,Bq (cP-0) be the
first mput clause.
Then Ajel is an instance of B. If q=O, we have [B] ~ Tpil.
Thus
[Ajel···en] ~ [Ajel] ~ [B] ~ Tpil ~ Tpin.
If
q>O,
by
the
induction
hypothesis, [Biel.·.en] ~ Tpi(n-l), for i=l,...,q. By the definition of Tp, we have
that [Ajel...en] ~ Tpin...
Next we turn to the problem of the occur check. As we mentioned earlier, the
occur check in the unification algorithm is very expensive and most PROLOG
systems leave it out for the pragmatic reason that it is only very rarely required.
While this is certainly true, its omission can cause serious difficulties.
Example Consider the program
test f- p(x,x)
p(x,f(x)) f-
Given the goal f-test, a PROLOG system without the occur check will answer
"yes" (equivalently, e is a correct answer)! This answer is quite wrong because
test is not a logical consequence of the program. The problem arises because,
without the occur check, the unification algorithm of the PROLOG system will
mistakenly unify p(x,x) and p(y,f(y)).
Thus we see that the lack of occur check has destroyed one of the principles
on which logic programming is based - the soundness of SLD-resolution.
Example Consider the program
test f- p(x,x)
p(x,f(x)) f- p(x,x)
. This time a PROLOG system without the occur check will go into an infinite loop
in the unification algorithm because it will attempt to use a "circular" binding
made in the second step of the computation.
These examples illustrate what can go wrong. We can distinguish two cases.
The first case is when a circular binding is constructed in a "unification", but this
binding is never used again. The first example illustrates this. The second case
happens when an attempt is made to use a previously constructed circular binding
in a step of the computation or in printing out an answer. The second example
illustrates this. The first case is more insidious because there may be no indication
that an error has occurred.
While these examples may appear artificial, it is important to appreciate that
we can easily have such behaviour in practical programs.
The most commonly
encountered situation where this can occur is when programming with difference
lists [21]. A difference list is a term of the form x-y, where - is a binary function
(written infix). x-y represents the difference between the two lists x and y. For
example, 34.56.l2.x-x represents the list [34, 56, 12]. Similarly, x-x represents the
empty list.

46
Chapter 2. Definite Programs
§8. Completeness of SLD-Resolution
47
Let us say two difference lists x-y and z-w are compatible if y=z. Then
compatible difference lists can be concatenated in constant time
using the
following definition which comes from [21]
concat(x-y,y-z,x-z) f-
For example, we can concatenate 12.34.67.45.x-x and 36.89.y-y in one step to
obtain 12.34.67.45.36.89.z-z. This is clearly a very useful technique. However, it
is also dangerous in the absence of the occur check.
Example Consider the program
test f- concat(u-u,v-v,a.w-w)
concat(x-y,y-z,x-z) f-
Given the goal f-test, a PROLOG system without the occur check will answer
"yes". In other words, it thinks that the concatenation of the empty list with the
empty list is the list [all
Programs which use the difference list technique normally do not have an
explicit concat predicate.
Instead the concatenation is done implicitly.
For
example, the following clause is taken from such a version of quicksort [93].
Example Consider the program
qsort(nil,x-x) f-
Given the goal f-qsort(nil,a.y-y), a PROLOG system without the occur check will
succeed on the goal (however, it will have a problem printing out its "answer",
which contains the circular binding y/a.y).
It is possible to minimise the danger of an occur check problem by using a
certain programming methodology. The idea is to "protect" programs which could
cause problems by introducing an appropriate top-level predicate to restrict uses of
the program to those which are known to be sound. This means that there must be
some mechanism for forcing all calls to the program to go through this top-level
predicate. However, with this method, the onus is still on the programmer and it
thus remains suspect. A better idea [82] is to have a preprocessor which is able to
identify which clauses may cause problems and add checking code to these clauses
(or perhaps invoke the full unification algorithm when these clauses are used).
§8. COMPLETENESS OF SLD.RESOLUTION
The major result of this section is the completeness of SLD-resolution.
We
begin with two very useful lemmas.
Lemma 8.1 (Mgu Lemma)
Let P be a definite program and G a definite goal. Suppose that P u {G} has
an unrestricted SLD-refutation. Then P u {G} has an SLD-refutation of the same
length such that, if al'...,an are the unifiers from the unrestricted SLD-refutation
and a'l'... ,a~ are the mgu's frOm the SLD-refutation, then there exists a substitution
y such that aI...an = ai...a~y.
Proof The proof is by induction on the length of the unrestricted refutation.
Suppose first that n=1. Thus P u {G} has an unrestricted refutation GO=G, G1= 0
with input clause CI and unifier a l . Suppose a'i is an mgu of the atom in G and
the head of the unit clause CI. Then a l = a'IY' for some y. Furthermore, P u {G}
has a refutation GO=O' GI= 0 with input clause CI and mgu a'i'
Now suppose the result holds for n-1. Suppose P u {G} has an unrestricted
refutation GO=O' G1,...,Gn= 0 of length n with input clauses CI,,,,,Cn and unifiers
al'...,an. There exists an mgu a'i for the selected atom in G and the head of CI
such that al = a'IP, for some p. Thus P u {G} has an unrestricted refutation
G =0 G'
G
G = 0 with input clauses CI,...,C
and unifiers a'I' pa2, a3,..·,an,
0-'
l'
2"'"
n
n
.
where
GI = Gip.
By
the induction hypothesis,
P u {G'I}
has
a refutatIOn
G'
G'
G' = 0 with mgu's e2'
. e'
such that pe2...a
= e2' ...e' y, for some y.
l'
2'"'' n
,.. , n
n
n
Thus P u {G} has a refutation GO=O' G'l'...,G~= 0 with mgu's e'l'... ,e~ such that
eI...an = eipe2..·en = ai...e~y.
II1II
Lemma 8.2 (Lifting Lemma)
Let P be a definite program, G a definite goal and e a substitution. Suppose there
exists an SLD-refutation of P u {Ge} such that the variables in the input clauses are
distinct from the variables in e and G.
Then there exists an SLD-refutation of
Pu {G} of the same length such that, if eI,...,en are the mgu's from the SLD-
refutation of P u {Ge} and e'l'... ,e~ are the mgu's from the SLD-refutation of
e'
a'
P u {G}, then there exists a substitution y such that eal'..an =
1'" ny.
Proof Suppose the first input clause for the refutation of P u {Ge} is Cl' the
first mgu is e
and G
is the goal which results from the first step. Now aal is a
1
1
unifier for the head of C1 and the atom in G which corresponds to the selected atom

48
Chapter 2. Definite Programs
§9. Independence of the Computation Rule
49
in Ga. The result ofresolving G and Cl using aal is exactly Gl. Thus we obtain a
(properly standardised apart) unrestricted refutation of P u {G}, which looks exactly
like the given refutation of P u {Ga}, except the original goal is different, of course,
and the first unifier is aal' Now apply the mgu lemma. I
The first completeness result gives the converse to corollary 7.3. This result is
due to Apt and van Emden [4].
Theorem 8.3 The success set of a definite program is equal to its least
Herbrand model.
Proof Let the program be P.
By corollary 7.3, it suffices to show that the
least Herbrand model of P is contained in the success set of P. Suppose A is in
the least Herbrand model of P.
By theorem 6.5, AeTpin, for some nero.
We
prove by induction on n that AeTpin implies that P u
{~A} has a refutation and
hence A is in the success set.
Suppose first that n=l. Then AeTpil means that A is a ground instance of a
unit clause of P. Clearly, P u
{~A} has a refutation.
Now suppose that the result holds for n-l. Let AeTpin. By the definition of
Tp, there exists a ground instance of a clause B~Bl'...,Bk such that A=Ba and
{Bla,...,Bka} !:: Tpi(n-l), for some e. By the induction hypothesis, P u
{~Bia}
has a refutation, for i=l,...,k. Because each Bia is ground, these refutations can be
combined into a refutation of P u
{~(Bl,...,Bk)a}.
Thus P u
{~A} has an
unrestricted refutation and we can apply the mgu lemma to obtain a refutation of
P u
{~A}. I
The next completeness result was first proved by Hill [46]. See also [4].
Theorem 8.4 Let P be a definite program and G a definite goal. Suppose that
P u {G} is unsatisfiable. Then there exists an SLD-refutation of P u {G}.
Proof Let G be the goal
~Al'...,Ak'
Since P u {G} is unsatisfiable, G is
false wrt Mp.
Hence some ground instance Ga of G is false wrt Mp.
Thus
{A1a,...,Aka} !:: Mp. By theorem 8.3, there is a refutation for P u
{~Aia}, for
i=l,...,k.
Since each Aia is ground, we can combine these refutations into a
refutation for P u {Ga}. Finally, we apply the lifting lemma. I
Next we turn attention to correct answers. It is not possible to prove the exact
converse of theorem 7.1 because computed answers are always "most general".
However, we can prove that every correct answer is an instance of a computed
answer.
Lemma 8.5 Let P be a definite program and A an atom. Suppose that V(A) is
a logical consequence of P.
Then there exists an SLD-refutation of P u
{~A}
with the identity substitution as the computed answer.
Proof Suppose A has variables xl""'xn. Let al'...,an be distinct constants not
appearing in P or A and let a be the substitution {xl/al'...,xian}· Then it is clear
that Aa is a logical consequence of P. Since Aa is ground, theorem 8.3 shows that
P u
{~Aa} has a refutation. Since the ai do not appear in P or A, by replacing ai
by x. (i=l,...,n) in this refutation, we obtain a refutation of P u {~A} with the
1
identity substitution as the computed answer. I
Now we are in a position to prove the major completeness result. This result
is due to Clark [16].
Theorem 8.6 (Completeness of SLD-Resolution)
Let P be a definite program and G a definite goal. For every correct answer a for
P u {G}, there exists a computed answer 0" for P u {G} and a substitution y such that
a and cry have the same effect on all variables in G.
Proof
Suppose
G
is
the
goal
~Al'...,Ak'
Since
a
is
correct,
V«A11\...AAk)a) is a logical consequence of P.
By l~mma. 8.5,. there
~xists a
refutation of P u {~Aia} such that the computed answer IS the Identity, for I=I,...,k.
We can combine these refutations into a refutation of P u {Ga} such that the
computed answer is the identity.
Suppose the sequence of mgu's of the refutation of P u {Ga} is al,..·,an· Then
Gaa
a =Ga. By the lifting lemma, there exists a refutation of P u {G} with mgu's
1''' n
,
,
a'
a'
such that aa ...a
= a' ...a' y, for some substitution y. Let 0" be a l ..·an
I'"'' n
1
n
1
n
.
.
restricted to the variables in G. Then a and cry have the same effect on all vanables In
G. I
§9. INDEPENDENCE OF THE COMPUTATION RULE
In this section, we introduce the concept of a computation rule, which is used
to select atoms in an SLD-derivation.
We show that, for any choice of
computation rule, if P u {G} is unsatisfiable, we can always find a refutation

50
Chapter 2. Definite Programs
§9. Independence of the Computation Rule
51
using the given computation rule. This fact is called the "independence"
of the
computation rule. We also prove that every computable function can be computed
by a definite program.
Definition A computation rule is a function from a set of definite goals to a
set of atoms such that the value of the function for a goal is an atom, called the
selected atom, in that goal.
Definition Let P be a definite program, G a definite goal and R a computation
rule.
An Sill-derivation of P u {G} via R is an SLD-derivation of P u {G} in
which the computation rule R is used to select atoms.
It is important to realise that using a computation rule to select atoms in an
SLD-derivation is actually a restriction, in the sense that, if the same goal occurs
in different places, then the computation rule will always select the same atom of
that goal.
In other words, there are SLD-derivations which are not SLD-
derivations via R, for any computation rule R.
Definition Let P be a definite program, G a definite goal and R a computation
rule.
An Sill-refutation of P u {G} via R is an SLD-refutation of P u {G} in
which the computation rule R is used to select atoms.
Definition Let P be a definite program, G a definite goal and R a computation
rule.
An R-computed answer for P u {G} is a computed answer for P u {G}
which has come from an SLD-refutation of P u {G} via R.
Now we are in a position to consider the independence result.
According to
theorem 8.4, if P u {G} is unsatisfiable, then there exists a refutation of P u {G}.
In fact, we will show that, for any computation rule R, there is actually a refutation
of P u {G} via R.
This result means that, in principle, a logic programming
system can use any computation rule it finds convenient.
We will explore the
practical consequences of this result in §10.
The key to the independence result is a technical lemma.
For this, it will be
convenient to introduce some new notation. If C is a definite program clause, then
C+ denotes the head of the clause and C- denotes the body.
Lemma 9.1 (Switching Lemma)
Let P be a definite program and G a definite goal. Suppose that P u {G} has
an
SLD-refutation
GO=O' Gl'...,Gq_1, Gq, Gq+1,...,Gn= 0
with
input
clauses
Cl'""Cn and mgu's al'...,an. Suppose that
Gq_1 is
~Al,
,Ai_l,Ai,..·,Aj_l,Aj"..,Ak
Gq
is
~(Al'
,Ai_l,C~, ,Aj_l,Aj,...,Ak)aq
Gq+1 is
~(Al,
,Ai_l,C~,
,Aj_l,C~+I,·..,Ak)aqaq+l·
Then there exists an SLD-refutation of P u {G} in which Aj is selected in Gq_1
instead of A and A. is selected in G
instead of A.
Furthermore, if 0" is the
1
1
q
J
,
computed answer for P u {G} from the given refutation and 0" is the computed
answer for P u {G} from the new refutation, then GO" is a variant of GO"'.
Proof We have A.a a
1 = c+ 1a
1 = c+ la a +1' Thus we can unify AJ.
J q q+
q+
q+
q+
q q
and C~+r
Let a~ be an mgu of Aj and C~+I'
Thus aqaq+1 = a~O", for some
substitution 0". Clearly, we can assume that a~ does not act on any of the variables
ofCq.
Furthermore C+0" = c+a' 0" = c+a a
1 = Aa a
1 = A.a' 0". Hence we can
,
q
q q
q q q+
1 q q+
1 q
unify C+ and A.a'
Suppose a'
1 is an mgu.
Thus 0" = a'q+lO"" for some 0"'.
q
1 q'
q+
Consequently, aqaq+1 =
a~a~+IO""
We have now shown that Ai and Aj can be
selected in the reverse order.
Next note that A.a' a'
1 = c+a' a'
l' but that aq is an mgu of Ai and c q+.
,
1 q q+
q q q+
, ,
B
A a
A a' a'
c+
a' a'
=
Thus aqaq+1 = aqy, for some y.
ut
j qY =
j q q+l =
q+l q q+l
C+ la Y= C+ lY' Thus Yunifies A.a
and Cq++1' and so Y= aq+10"", for some
q+
q
q+
J q
","
Consequently
a' a'
1
a a
10"" and so the (q+l)st goal in the new
v
•
,
q q+
q q+
refutation is a variant of Gq+1.
The remainder of the new refutation now proceeds in the same way as the
given refutation (modulo variants) and the result follows. II
Theorem 9.2 (Independence of the Computation Rule).
Let P be a definite program and G a definite goal. Suppose there is an SLD-
refutation of P u {G} with computed answer 0". Then, for any computation rule R,
there exists an SLD-refutation of P u {G} via R with R-computed answer cr' such
that Gcr' is a variant of GO".

52
Chapter 2. Definite Programs
§9. Independence of the Computation Rule
53
Proof Apply the switching lemma repeatedly. (See problem 15.)
l1li
We can use theorem 9.2 to strengthen theorems 8.3, 8.4 and 8.6.
Definition Let P be a definite program and R a computation rule.
The R-
success set of P is the set of all AEBp such that P U {f-A} has an SLD-refutation
via R.
Theorem 9.3 Let P be a definite program and R a computation rule. Then the
R-success set of P is equal to its least Herbrand model~
Proof The theorem follows immediately from theorems 8.3 and 9.2.
l1li
Theorem 9.4 Let P be a definite program, G a definite goal and R a
computation rule. Suppose that P u {G} is unsatisfiable. Then there exists an
SLD-refutation of P u {G} via R.
Proof The theorem follows immediately from theorems 8.4 and 9.2.
l1li
Theorem 9.S (Strong Completeness of SLD-Resolution)
Let P be a definite program, G a definite goal and R a computation rule. Then for
every correct answer e for P u {G}, there exists an R-computed answer
0" for
P u {G} and a substitution y such that e and cry have the same effect on all variables
inG.
Proof The theorem follows immediately from theorems 8.6 and 9.2.
l1li
Theorem 9.4 is due to Hill [46].
See also [4]. Theorem 9.5 is due to Clark
[16].
We now establish the important result that every computable function can be
computed by an appropriate definite program.
There are a number of ways of
establishing this result, depending on the definition of "computable" chosen.
For
example, Tarnlund [102] showed that every Turing computable function can be
computed by a definite program.
Shepherdson established the result
using
unlimited register machines to define computable functions [96].
Kowalski [52]
established the result by showing how to transform a set of recursive equations
into a definite program. Andreka and Nemeti [1] and Sonenberg and Topor [100]
show the adequacy of definite programs for computation over an Herbrand
universe. Here, we follow Sebelik and Stepanek [91] by showing that every partial
recursive function can be computed by a definite program.
The definition of a
partial recursive function and the basic results of computability are contained in
[23], for example. For a survey of these computability results, see [100].
Theorem 9.6 (Computational Adequacy of Definite Programs)
Let f be an n-ary partial recursive function. Then there exists a definite
program Pf and ~ (n+I)-~ predicate symbol Pf such tat all computed answers
for Pf u {f-Pf(s 1(0),...,s
(O),x)}
have the form
{xis (O)}
and, for all non-
negative integers kI,...,kn and k, we have f(kl'...,kn)=k iff {xlsk(O)} is a computed
answer for Pf u {f-Pf(b(O),...,s~(O),x)}.
Proof In the program Pf' a non-negative integer k is represented by the term
sk(O), where s represents the successor function.
By theorem 9.2, we can suppose
that all computed answers are R-computed, where R is the computation rule which
always selects the leftmost atom. The result is proved by induction on the number
q of applications of composition, primitive recursion and minimalisation needed to
define f.
Suppose first that q=O. Thus f must be either the zero function, the successor
function or a projection function.
Zero function
Suppose that f is the zero function defmed by f(x)=O.
Define Pf to be the
program Pf(x,O)f-.
Successor function
Suppose that f is the successor function defined by f(x)=x+1. Define Pf to be
the program Pf(x,s(x))f-.
Projection functions
Suppose that f is the projection function defined by f(xl""'xn)=xj' where
1S;jS;n. Define Pf to be the program Pf(xI,·..,xn,xj)f-.
.
Clearly, for each of the basic functions, the program Pf defined has the deSIred
properties.
Next suppose the partial recursive function f is defined by q (q>O) applications
of composition, primitive recursion and minimalisation.
Composition
Suppose that f is defined by f(xI,·..,xn) = h(gI(xI,·..,xn),..·,gm(xI,·..,xn)),
where gl'...,gm and h are partial recursive functions.
By the induction hypothesis,
corresponding to each g. there is a definite program P
and a predicate symbol Pg.
l'
g.
1
satisfying the properties of the theorem. Similarly, cohesponding to h, there is a

54
Chapter 2. Definite Programs
§10. SLD-Refutation Procedures
55
definite program Ph and a predicate symbol Ph satisfying the properties of the
theorem. We can suppose that the programs Pg ,...,Pg
and Ph do not have any
predicate symbols in common. Define Pf to tie themunion of these programs
together with the clause
Pf(xl""'xn,z) f- Pg1(xl'""xn'YI),···,Pgm(xl'...,xn'Ym)' Ph(Yl'''''Ym'z)
Clea:ly all
~ompute.ct
ans~ers for Pf U {f-plSk1(0),...}D(0),z)} have the form
{zls (O)}, usmg the mducllon hypothesis.
Now suppose that f(kl'...,kn)=k. Thus gi(kl'...,kn)=ni, say, for l~i~m. By the
induction
hypothesis,
{Y·/SDi(O)}
is
a
computed
answer
for
k
l).
1
Pg. U {f-Pg.(s l(O),...,s
(O)'Yi)}' Also, by the induction hypothesis, {zlsk(O)} is a
1
1
computed
answer
for
Ph U {f-Ph(sD1(0),...,sDm(0),z)}.
Hence
{z/sk(O)}
is
a
k
k
computed answer for Pf U {f-Pf(s l(O),...,s D(O),Z)}.
Converse~,
sup~ose
that
{zlsk(O)}
is
a
computed
answer
for
Pf U {f-Pf(s l(O),...,s
(O),z)}.
From the refutation giving this answer, we can
extract computed answers {y/s\O)} for Pg. U {f-pg.(Sk1(0),...}D(0)'Yi)}, for
1 .
k
lID
~l~m, and a computed answer {zls (O)} for Ph U {f-Ph(s l(O),...,sDm(O),z)}.
It
now follows from the induction hypothesis that gi(kl'...,kn)=ni, for
l~i~m, and
that h(nl'...,nm)=k. Hence f(kl'...,kn)=k.
Primitive recursion
Suppose that f is defined by
f(xl,·..,xn,O) = h(xl,·..,xn)
f(xl'''''xn,y+1) = g(xl'''''xn,y,f(xl,...,xn,y»,
where h and g are partial recursive functions.
By the induction hypothesis,
corresponding to h (resp., g), there is a definite program Ph (resp., P ) and a
predicate symbol Ph (resp., Pg) satisfying the properties of the theorem.gWe can
also suppose that Ph and Pg do not have any predicate symbols in common. Define
Pf to be the union of Ph and Pg together with the clauses
plxl""'xn,O,z) f- Ph(xI"",xn,z)
Pf(xl"",xn,s(y),z) f- Pf(xl"",xn,y,u), p (xl,...,xn,y,u,z).
An
.
'1
g
argument Slml ar to the one for composition shows that P
has the desired
.
f
propemes.
Minimalisation
Suppose that f is defined by f(xl,...,xn) = /-ly(g(xl,...,xn,y)=O), where g is a
partial recursive function.
That is, /-ly(g(xl,...,xn,y)=O) is the least y such that
g(xl,·..,xn,z) is defined for all
z~y and g(xl,...,xn,y)=O, if such a y exists;
otherwise,
/-ly(g(xl,...,xn,y)=O)
is
undefined.
By
the
induction
hypothesis,
corresponding to g, there is a definite program Pg and a predicate symbol pg
satisfying the properties of the theorem.
Define Pf to be Pg together with the
clauses
Pf(xl"",xn,y) f- Pg(xl,...,xn,O,u), r(xl,...,xn,O,u,y)
r(xl'''''xn,y,O,y) f-
r(xl,·..,xn,y,s(v),z) f- pg(xl ,...,xn,s(y),u), r(xl,...,xn,s(y),u,z).
An argument similar to the one for composition shows that Pf has the desired
properties. II
§10. SLD-REFUTATION PROCEDURES
In this section, we consider the possible strategies a logic programming system
might adopt in its search for a refutation.
We show that the use of a depth-first
search strategy has serious implications with regard to completeness. We also
briefly discuss the automatic generation of control.
The search space is a certain type of tree, called an SLD-tree.
The results of
§9 show that in building the SLD-tree, the system does not have to consider
alternative computation rules.
A computation rule can be fixed in advance and an
SLD-tree constructed using this computation rule.
This dramatically reduces the
size of the search space.
Definition Let P be a definite program and G a definite goal. An SW-tree for
P U {G} is a tree satisfying the following:
(a) Each node of the tree is a (possibly empty) definite goal.
(b) The root node is G.
(c) Let f-Al'...,Am,...,Ak (~l) be a node in the tree and suppose that Am is the
selected atom. Then, for each input clause Af-Bl,...,Bq such that Am and A are
unifiable with mgu e, the node has a child
f-(Al,..·,Am_l,Bl,..·,Bq,Am+l,..·,Ak)e
(d) Nodes which are the empty clause have no children.
Each
branch
of
the
SLD-tree
is
a
derivation
of P U {G}.
Branches
corresponding to successful derivations are called success branches, branches
corresponding to infinite derivations are called infinite branches and branches
corresponding to failed derivations are calledfai/ure branches.

56
Chapter 2. Definite Programs
§10. SLD-Refutation.Procedures
57
3
f-p(x,b)
A
f-q(x,y), p(y,b)
0
{xIb}
success
o
lx/a}
success
f-p(b,b)
failure
f-q(b,u),p(u,b)
Definition Let P be a definite program, G a definite goal and R a computation
rule.
The SW-tree for P u {G} via R is the SLD-tree for P u {G} in which the
atoms selected are those selected by R.
This example shows that the choice of computation rule has a great bearing on
the size and structure of the corresponding SLD-tree. However, no matter what the
choice of computation rule, if P u {G} is unsatisfiable, then the corresponding
SLD-tree does have a success branch. This is just a restatement of theorem 9.4.
Example Consider the program
1. p(x,z) f- q(x,y), p(y,z)
2. p(x,x) f-
3. q(a,b) f-
and the goal f-p(x,b). Figures 2 and 3 show two SLD-trees for this program and
goal. The SLD-tree .in Figure 2 comes from the standard PROLOG computation
rule (select the leftmost atom). The SLD-tree in Figure 3 comes from the
computation rule which always selects the rightmost atom. The selected atoms are
underlined and the success, failure and infinite branches are shown. Note that the
first tree is finite, while the second tree is infinite.
Each tree has two success
branches corresponding to the answers {x/a} and {xIb}.
Theorem 10.1
Let P be a definite program, G a definite goal and R a
computation rule.
Suppose that P u {G} is unsatisfiable. Then the SLD-tree for
P u {G} via R has at least one success branch.
Theorem 9.5 can also be restated.
Fig. 2. A finite SLD-tree
Proof Using the switching lemma, we can set up a bijection between the
success branches of any pair of SLD-trees. (See problem 17.) II
Theorem 10.2
Let P be a definite program, G a definite goal and R a
computation rule. Then every correct answer e for P u {G} is "displayed" on the
SLD-tree for P u {G} via R.
"Displayed" means that, given e, there is a success branch such that e is an
instance of the computed answer from the refutation corresponding to this branch.
While any two SLD-trees may have greatly different size and structure, they
are essentially the same with respect to success branches.
Theorem 10.3 Let P be a definite program and G a definite goal. Then either
every SLD-tree for P u {G} has infinitely many success branches or every SLD-
tree for P u {G} has the same finite number of success branches.
For example, in Figures 2 and 3, the respective success branches giving the
answer {x/a} can be transformed into one another by using the switching lemma.
Next we turn to the problem of searching SLD-trees to find success branches.
Definition A search rule is a strategy for searching SLD-trees to find success
branches. An SW-refutation procedure is specified by a computation rule together
with a search rule.
Standard PROLOG systems employ the computation rule which always selects
the leftmost atom in a goal together with a depth-first search rule. The search rule
is implemented by using a stack of goals. An instance of the goal stack represents
the branch currently being investigated.
The computation essentially becomes an

58
Chapter 2. Definite Programs
§10. SLD-Refutation Procedures
59
~p(x,b)
that PROLOG is primarily a programming language rather than a theorem prover.
Fig. 3. An infinite SLD-tree
Let us now consider the "completeness" of logic programming systems that
use a depth-first search rule combined with a fixed order for trying clauses given
by their ordering in the program. As well as standard PROLOG systems, let us
also consider systems, such as Ie-PROLOG [19], MU-PROLOG [73], [74] and
NU-PROLOG
[104],
[75],
which
allow
more
complex
computation
rules.
According to theorem 10.1, if P u {G} is unsatisfiable, no matter what the
computation rule, the corresponding SLD-tree will always contain a success
branch.
The question is this: will a logic programming system with a depth-first
search rule using a fixed order for trying program clauses and an arbitrary
computation rule, guarantee to always find the success branch? Unfortunately, the
answer is no. In other words, none of the earlier completeness results is applicable
to most current PROLOG systems because efficiency considerations have forced
the implementation of unfair search rules!
Naturally, we would prefer the search rule to be fair, that is, to be such that
each success branch on the SLD-tree will eventually be found.
For infinite SLD-
trees, search rules which do not have a breadth-first component will not be fair in
general.
However, a breadth-first component is less compatible with an efficient
implementation.
For a system that searches depth-first, the search rule reduces to an ordering
rule, that is, a rule which specifies the order in which program clauses are to be
tried. Standard PROLOG systems use the order of clauses in a program as the
fixed order in which they are to be tried.
This is very simple and efficient to
implement, but has the disadvantage that each call to a definition tries the clauses
in the definition in exactly the same order.
o
{x/b}
success
2
3
o
lx/a}
success
~q(x,b)
~q(x,y),p(y,b)
3
failure
~q(x,a)
~q(x,y), q(y,b)
~q(x,y), q(y,u), p(u,b)
,
\
\
\
\
\
,,,,,
infinite
~q(x,y),q(y,u), q(u,v), p(v,b)
1A2
Let us consider an example to make this clear.
interleaved sequence of pushes and pops on this stack. A push occurs when the
selected atom in the goal at the top of the stack is successfully unified with the
head of a program clause. The resolvent is pushed onto the stack. A pop occurs
when there are no (more) program clauses with head to match the selected atom in
the goal at the top of the stack. This goal is then popped and the next choice of
matching clause for the new top of stack is investigated. While depth-first search
rules
have
undeniable
problems
(see
below),
they
can
be
very
efficiently
implemented. This approach is entirely consistent with the view, which we share,
Example Let P be the program
1. p(a,b) ~
2. p(c,b) ~
3. p(x,z) ~ p(x,y), p(y,z)
4. p(x,y) ~ p(y,x)
and G be the goal
~p(a,c).
It is straightforward to show that P u {G} has a
refutation and, moreover, that if any clause of P is omitted, P u {G} will no

60
Chapter 2. Definite Programs
§10. SLD-Refutation Procedures
61
Thus a way to fix the problem is to change the deftnition of sort to
sort(x,y) f- perm(x,y), sorted(y)
This at least gives a program which runs, even if it is spectacularly inefftcient. It
sorts the given list by making random permutations of it and then using sorted to
check if the permutations are sorted.
Fig. 4. SLD-tree which illustrates the problem with depth-ftrst search
4
\
\
\
\
/\
,,,,
3
jf
3 1
4
I
\
I
\
I
\
I
\
\
o
success
;4
3.
4
I
\
I
\
I
\
I
\
f-p(b,c)
f-p(a,c)3/\
f-p(a,y), p(y,c)
f-p(c,a)
A
f-p(b,u), p(u,c)
f-p(c,b)
,
\
,
\
,
\
,
\
,
inftnite
~<.
f-p(b,w), p(w,u), p(u,C)
Now the ftrst thing to note about slowsort is that it does not run on standard
PROLOG systems! Consider the goal f-sort(17.22.6.5.nil,y). A standard PROLOG
system goes into an inftnite loop because sorted makes longer and longer incorrect
guesses for y. Of course, sorted has no business guessing at all. It is purely a test.
Finally, we discuss the importance of using appropriate computation rules.
It
would clearly be a substantial step towards purely declarative programming if we
were able to build systems which would automatically ftnd
an
appropriate
computation rule for each program run on the system. To illustrate what is
involved in this, consider once again the slowsort program.
sort(x,y) f- sorted(y), perm(x,y)
sorted(nil) f-
sorted(x.nil) f-
sorted(x.y.z) f- x:;;y, sorted(y.z)
perm(nil,nil) f-
perm(x.y,u.v) f- delete(u,x.y,z), perm(z,v)
delete(x,x.y,y) f-
delete(x,y.z,y.w) f- delete(x,z,w)
o:;;x f-
f(x):;;f(y) f- x:;;y
longer have a refutation.
We claim that no matter how the clauses of P are ordered and no matter what
the computation rule, a logic programming system using a depth-ftrst search with
the ftxed order for trying program clauses, will never ftnd a refutation.
This claim follows immediately from the fact that clauses 3 and 4 have
completely general heads. They will therefore always match any subgoal. Thus if
clause 3 is before clause 4 in the program, the system will never consider clause 4
and vice versa.
However, all the clauses are needed in any refutation. (See
problem 18.)
Figure 4 illustrates the situation. There we have given the SLD-tree resulting
from the use of the standard computation rule, which selects the leftmost atom, and
the order for trying clauses given by the order of the clauses in the above program.
As can be seen, the leftmost branch of this SLD-tree is inftnite and thus a depth-
ftrst search will never ftnd the success branch. In fact, for every computation rule
and every ftxed order for trying the program clauses, the leftmost branch of the
corresponding SLD-tree will be inftnite.

62
Chapter 2. Definite Programs
§11. Cuts
63
The attraction of the slowsort progranfis that it does give a very clear logic
component for a sorting program. The disadvantage for standard PROLOG systems
is that the only way to make it reasonably efficient is to substantially change the
logic. To keep the above simple logic what we require is a computation rule which
coroutines between perm and sorted. In this case, the list is given to perm which
generates a partial permutation of it and then checks with sorted to see if the
partial permutation is correct so far. If sorted finds that the partial permutation is
indeed sorted, perm generates a bit more of the permutation and then checks with
sorted again. Otherwise, perm undoes a bit of the partial permutation, generates a
slightly different partial permutation and checks with sorted again. Such a program
is clearly going to be a great deal more efficient than the one which generates an
entire permutation before checking to see if it is sorted.
Thus we can obtain a more efficient sorting program by adding clever control
to the simple logic. (Of course, much more efficient sorting programs are known,
but this is not the point of the discussion.) There are now a number of PROLOG
systems which allow the programmer to specify such control. For example, in
NU-PROLOG [104] the programmer could add the when declarations
?- sorted(nil) when ever
?- sorted(x.y) when y
to the program. If the argument of the call to sorted either is nil or has the form
s.t, where t is a non-variable, then the call proceeds. Thus the calls sorted(nil) and
sorted(3.2.x) will proceed. If the argument of the call to sorted does not unify
with nil or x.y, then the call proceeds (and then fails). If the argument of the call
to sorted has the form y or s.y, then the call to sorted delays.
Thus the call
sorted(3.y) will delay. When a call sorted(y) or sorted(s.y) is delayed, the variable
y is marked. When this variable is bound later, the delayed subgoal is resumed.
This simple mechanism achieves the desired behaviour.
In standard PROLOG systems, a "generator" subgoal should come before a
"test" subgoal. Thus perm should be put before sorted, if slowsort is to be run on
a standard PROLOG system. However, in NU-PROLOG, the "test" should be put
before the "generator".
This order, together with appropriate when declarations
on the "test", ensures proper coroutining between the "test" and the "generator".
The coroutining starts by delaying the "test". The "generator" is then run until it
creates a binding which causes the "test" to be resumed, and so on.
When declarations would not be of major interest if their addition always
required programmer intervention. However, NU-PROLOG has a preprocessor
which is able to automatically add when declarations to many programs in order to
obtain more sensible behaviour. For example, given the slowsort program as input,
the preprocessor outputs the above when declarations for sorted. (It also gives
when declarations for perm, delete and ::;;, but these are not needed for the use we
have made of slowsort.) It does this by finding clauses with recursive calls which
could cause infinite loops and generating sufficient when declarations to stop the
loops. The preprocessor is also able to recognise that sorted is a "test" and should
appear before perm in the first clause. It will reorder sorted and perm, if necessary.
An account of the automatic generation of control is given in [74].
By relieving
programmers of some of the responsibility for providing control in this way, NU-
PROLOG is a step towards the ideal of purely declarative programming.
§11. CUTS
In this section, we discuss the cut, which is a widely used and controversial
control facility offered by PROLOG systems. It is usually written as "!" in
programs, although some systems call it "slash" and write it as "I".
There has
been considerable discussion of the advantages and disadvantages of cut and, in
particular, whether it "affects the semantics" of programs in which it appears. We
argue that cut does not affect the declarative semantics of definite programs, but it
can introduce an undesirable form of incompleteness into the refutation procedure.
(In §15, we discuss the effect that cuts can have in a program which has negative
literals in the body of a program clause.)
First, we must be precise about what a cut actually does. Throughout this
discussion, we restrict attention to systems which always select the leftmost atom
in a goal. Cut is simply a non-logical annotation of programs which conveys
certain control information to the system. Although it is written like an atom in the
body of a clause, it is not an atom and has no logical significance at all. On the
other hand, for pedagogical reasons, it is sometimes convenient to regard it as an
atom which succeeds immediately on being called. The declarative semantics of a
program with cuts is exactly the declarative semantics of the program with the cuts
removed.
In other words, the cuts do not in any way modify the declarative
reading of the program.

64
Chapter 2. Definite Programs
§11. Cuts
65
~D,!,E,C
\
\
\
\
\
~A
~B,C
This part of subtree
with root ~B, C is not
searched because of the cut
\
\
\
\
\
~!,E,C
/
When cut is encountered
on backtracking, the search
is resumed here
~E,C
D
Failed subtree with
root ~E,C
So a cut "merely" prunes the SLD-tree. Is it possible that a cut can somehow
be harmful? The key issue is whether or not there is an answer to the (top level)
goal in the part of the SLD-tree pruned by the cut. If there is no answer in the
pruned part (that is, if the pruned part does not contain a success branch), then we
call such a use of cut safe. However, if a success branch gets pruned by the cut,
we call such a use of cut unsafe. Safe uses of cut are beneficial - they improve
efficiency without missing answers. Unsafe uses of cut are harmful to the extent
that a correct answer is missed.
To clarify this, consider the following program fragment
A~B,C
B~D,!,E
D~
What, then, is the nature of the control information conveyed by a cut? First,
we need some terminology. Let us call the goal which caused the clause containing
the cut to be activated, the parent goal. That is, the selected atom in the parent
matched the head of the clause whose body contains the cut. Now, when
"selected", the cut simply "succeeds" immediately. However, if backtracking
later returns to the cut, the system discontinues searching in the subtree which has
the parent goal at the root. The cut thus causes the remainder of that subtree to be
pruned from the SLD-tree.
where A, B, C, D and E are atoms. In Figure 5, we show part of the SLD-tree for
a call to this program. The selected atom B in the goal ~B,C causes the cut to be
introduced. The atom D is then selected and succeeds. The cut then succeeds, but
the subgoal E eventually fails and the system backtracks to the cut. At this point,
"deep" backtracking occurs. The system discontinues any further searching in the
subtree which has the root ~B,C and, instead, resumes the search with the next
choice for the goal ~A. This can be implemented very simply by popping goals
from the goal stack until the goal ~A becomes top of the stack.
Thus the harmful effect of cuts is that they can introduce a form of
incompleteness
into
the
SLD-resolution
implementation
of
correct
answer.
Theorem 9.5 assures us that in the absence of cuts every correct answer can be
computed. However, a cut in a program can destroy the completeness guaranteed
by this theorem.
Fig. 5. The effect of cut

66
Chapter 2. Definite Programs
67
Problems for Chapter 2
Note that this fonn of incompleteness is of a different nature from the fonn of
incompleteness mentioned in §1O, which occurs because a depth-fIrst search can
get lost down an infInite branch. A system which allows the search to become lost
down an infInite branch does not give any answer at all (only a stack overflow
message!). With an unsafe use of cut, a system can answer "no" when it should
have answered "yes". However you look at it, the system has given an incorrect
answer.
4. Let P be the program
p(a) f- p(x), q(x)
p(f(x)) f- p(x)
q(b) f-
q(f(x)) f- q(x)
Show
that
Tp..L.ro = {p(f\a)) : nero} U {q(f\b)) : nero}
Tp..L.ro2 =lfp(Tp) = {q(fl(b)) : nero}.
and
gfP(Tp)
=
But, there is a further, much more harmful, effect of cuts. This occurs when
programmers take advantage of cuts to write programs which are not even
declaratively correct. For example, consider the program
max(x,y,y) f- xS;y, !
max(x,y,x) f-
where max(x,y,z) is intended to be true iff z is the maximum of x and y.
Advantage has been taken of the effect of the cut to leave the test x>y out of the
second clause. Procedurally, the semantics of the above program is the maximum
relation. Declaratively, it is something else entirely.
Such programs severely
compromise the credibility of logic programming as declarative programming.
Admittedly, there are occasions when effIciency considerations force the use of
such aberrations. However, it is far better for programmers, whenever possible, to
make use of such higher level facilities as (sound implementations of) if-then-else,
negation and not equals, which are not only reasonably effIcient, but also lead to
programs whose declarative semantics more accurately reflects the relation being
computed.
PROBLEMS FOR CHAPTER 2
1. Complete the proof of proposition 6.1.
2. Find a fInite set S of clauses and a non-empty set {Mi}iel of Herbrand models
for S such that n ieIMi is not a model for S.
3. Let X be a directed subset of the lattice of Herbrand interpretations of a defInite
program. Show that {Al',..,An} ~lub(X) iff {Al'...,An} ~ I, for some leX.
S. Let P be the program
q(b) f-
q(f(x)) f- q(x)
p(f(x)) f- p(x)
p(a) f- p(x)
r(c) f- r(x), q(x)
r(f(x)) f- r(x)
Show that Tptro = {q(fl(b)) : nero}, Tp..L.ro =
{p(fl(a)): nero} u {:(fl(b)) ~
nero} u {r(fl(c)) : nero} and Tp..L.ro2 = {p(fl(a)) : nero} U {q(fl(b)) . nero} -
gfp(Tp)'
6. Let P be the program
PI(f(x)) f- PI(x)
P2(a) f- PI(x)
P2(f(x)) f- P2(x)
P3(a) f- P2(x)
P3(f(x)) f- P3(x)
pia) f- P3(x)
P4(f(x)) f- piX)
ps(a) f- plx)
ps(f(x)) f- PS(x)
Show that Tp..L.r04 "# gfp(T~, but Tp..L.roS =0 =gfp(Tp) =lfp(Tp)'
7. (a) Let P be a defInite program which contains no function symbols. Show that
Tp..L.ro = gfp(Tp)'
(b) Let P be a defInite program with the property that, for each clause, each
variable in the
body of the clause also appears in the head.
Show that
Tp..L.ro = gfp(Tp).

68
Chapter 2. Definite Programs
Problems for Chapter 2
69
8. Let P be a definite program with the following property: for each clause in P, if
the clause has variables in the body that do not appear in the head, then the set of
variables in the head is disjoint from the set of variables in the body. Prove that
gfp(Tp) = TpJ-ron, for some finite n depending on P.
9. Give an example of a correct answer which is not computed.
10. Let P be the slowsort program, G the goal f-Sort(1.0.nil,y) and R the
computation rule which always selects the leftmost atom.
Show directly that
P U {G} has an SLD-refutation via R.
11. Consider the program
leaves(tree(void,v,void),v.x_x) f-
leaves(tree(u,v,w),x_y) f- leaves(u,x-z), leaves(w,z-y)
Find a goal such that a PROLOG system without the occur check will answer the
goal incorrectly.
12. Show that if the occur check is omitted from the unification algorithm, one can
use SLD-resolution to "prove" that V'x3yp(x,y) ~ 3yV'xp(x,y) is valid.
(Hint: this problem requires the use of Skolem functions [66, p.126]).
13. Find an example to show that AeTpin, for some nero, does not necessarily
imply that there exists an SLD-refutation of length $,n for P U {f-A}.
14. Let P be a definite program and A an atom. Determine whether the following
statement is correct or not:
V(A) is a logical consequence of P iff [A] !:: Tpin, for some nero.
15. Complete the details of the proof of theorem 9.2.
16. Let P be the program
p(x) f- q(x), r(x)
q(a) f-
r(x) f- r1(x)
r1(a) f-
Let R be the computation rule which always selects the leftmost atom and R' be
the computation rule which always selects the rightmost atom. Use the switching
lemma to transform the refutation of P U {f-p(x)} via R into one via R'.
17. Complete the details of the proof of theorem 10.3.
18. Let P be the program
p(a,b) f-
p(c,b) f-
p(x,z) f- p(x,y), p(y,z)
p(x,y) f- p(y,x)
and G be the goal f-p(a,c). Show that, if any clause of P is omitted, P U {G} does
not have a refutation (no matter what the computation rule).
19. Find a definite program P and a definite goal G such that each SLD-tree for
P U {G} has two success branches, but no depth-first search will ever find both
success branches no matter what the computation rule and even if the program
clauses can be dynamically reordered for each call to each definition of the
program.
20. Let P be the slowsort program and G the goal f-Sort(1.0.2.nil,y).
Find an
SLD-refutation of P u {G} using a computation rule which suitably delays calls to
sorted.
21. What problems
arise in a PROLOG
system which
allows coroutining
computation rules and also has the cut facility? How might these problems be
solved?
22. Show that the condition in the lifting lemma that the variables in the input clauses
be distinct from the variables in eand G cannot be dropped.
23. Give an example of a definite program P, a definite goal G, and a correct answer e
for P U {G} such that there does not exist a computed answer 0" for P u {G} and a
substitution y for which e = cry.

Chapter 3
NORMAL PROGRAMS
In this chapter, we study various forms of negation.
Since only pOSItlve
information can be a logical consequence of a program, special rules are needed to
deduce negative information. The most important of these rules are the closed
world assumption and the negation as failure rule. This chapter introduces normal
programs, which are programs for which the body of a program clause is a
conjunction of literals.
The major results of this chapter are soundness and
completeness theorems for the negation as failure rule and SLDNF-resolution for
normal programs.
§12. NEGATIVE INFORMATION
The inference system we have studied so far is very specialised.
SLD-
resolution applies only to sets of Horn clauses with exactly one goal clause. Using
SLD-resolution, we can never deduce negative information. To be precise, let P be
a definite program and AeBp. Then we cannot prove that -A is a logical
consequence of P. The reason is that P U {A} is satisfiable, having Bp as a model.
To illustrate this, consider the program
studentGoe) f--
student(bill) f--
studentGim) ~
teacher(mary) ~
Now
suppose
we
wish
to establish
that
mary
is
not
a
student,
that is,
-student(mary).
As we have shown above, -student(mary) is not a logical
consequence of the program.
However, note that student(mary) is also not a
logical consequence of the program. What we can do now is invoke a special
inference rule: if a ground atom A is not a logical consequence of a program, then

72
Chapter 3. Normal Programs
73
§12. Negative Information
infer -A. This inference rule, introduced by Reiter [86], is called the closed world
assumption (CWA).
(Because of the approach taken here to the CWA, we would
have preferred it to have been called the closed world rule.) Under this inference
rule, we are entitled to infer -student(mary) on the grounds that student(mary) is
not a logical consequence of the program.
The CWA is often a very natural rule to use in a database context.
In
relational databases, this rule is usually applied - information not explicitly present
in the database is taken to be false.
Of course, in logic programs, the situation is
complicated by the presence of non-unit clauses.
The information content of a
program is not determined by mere inspection. It is now the set of all things which
can be deduced from the program.
Whether or not use of the CWA is justified
must be determined for each particular application. While it is often natural to use
the CWA, its use may not always be justified.
The CWA is an example of a non-monotonic inference rule. Such rules are
currently of great interest in artificial intelligence. (See, for example, [57] and the
references therein.) An inference rule is non-monotonic if the addition of new
axioms can decrease the set of theorems that previously held. As an example, if we
add sufficient clauses to the above program so as to be able to deduce
student(mary), then we will no longer be able to use the CWA to infer
-student(mary).
Now let us consider a program P for which the CWA is applicable. Let AEBp
and suppose we wish to infer -A. In order to use the CWA, we have to show that
A is not a logical consequence of P. Unfortunately, because of the undecidability
of the validity problem of first order logic, there is no algorithm which will take an
arbitrary A as input and respond in a finite amount of time with the answer
whether A is or is not a logical consequence of P.
If A is not a logical
consequence, it may loop forever. Thus, in practice, the application of the CWA is
generally restricted to those AEBp whose attempted proofs fail finitely.
Let us
make this idea precise.
For a definite program P, the SW finite failure set of P is the set of all AEBp
for which there exists a finitely failed SLD-tree for P U {f-A}, that is, one which
is finite and contains no success branches. By proposition 13.4 and corollary 7.2,
if A is in the SLD finite failure set of P, then A is not a logical consequence of P
and every SLD-tree for P U {f-A} contains only infinite or failure branches.
Now let us return to the CWA. In order to show that AEBp is not a logical
consequence of P, we can try giving f-A as a goal to the system. Let us assume
that A is not, in fact, in the success set of P.
Now there are two possibilities:
either A is in the SLD finite failure set or it is not.
If A is in the SLD finite
failure set, then the system can construct a finitely failed SLD-tree and return the
answer "no".
The CWA then allows us to infer -A.
In the other case, each
SLD-tree has at least one infinite branch.
Thus, unless the system has a
mechanism for detecting infinite branches, it will never be able to complete the
task of showing that A is not a logical consequence of P.
These considerations lead us to another non-monotonic inference rule, called
the negation as failure rule. This rule, first studied in detail by Clark [15], is also
used to infer negative information. It states that if A is in the SLD finite failure set
of P, then infer -A. Since the SLD finite failure set is a subset of the complement
of the success set, we see that the negation as failure rule is less powerful than the
CWA. However, in practice, implementing anything beyond negation as failure is
difficult.
The possibility of extending negation as failure closer to the CWA by
adding mechanisms for detecting infinite branches has hardly been explored.
Negation as failure is easily and efficiently implemented by "reversing" the
notions of success and failure. Suppose AEBp and we have the goal f- -A. The
system tries the goal f-A. If f-A succeeds, then f- -A fails, while if it fails
finitely, then f- -A succeeds.
Next we note that definite programs lack sufficient expressiveness for many
situations. The problem is that often a negative condition is needed in the body of
a clause. As an example, consider the definition
different(x,y) f- member(z,x), -member(z,y)
different(x,y) f- -member(z,x), member(z,y)
which defines when two sets are different.
Practical PROLOO programs often
require such extra expressiveness. Thus it is important to extend the definition of
programs to include negative literals in the bodies of clauses. This is done in §14,
where normal programs are introduced. These are programs for which the body of
a program clause is a conjunction of literals.
However, even though normal programs allow negative literals in the bodies of
program clauses, we still cannot deduce negative information from them.
As
before, the reason is that a normal program only contains the if halves of the

74
Chapter 3. Normal Programs
75
§13. Finite Failure
definitions of its predicate symbols, so that its Herbrand base is a model of the
program.
To deduce negative information from a normal program, we could
"complete" the program. This involves adding the only-if halves of the definitions
of the predicate symbols, together with an equality theory, to the program. In our
previous example, if we add the missing only-if half to the definition of student,
we obtain
\;;Ix (student(x)H(x=joe)v(x=bill)v(x=jim))
Adding appropriate axioms for =, we can now deduce -student(mary).
This
process of completion is another way of capturing the idea that information not
given by the program is taken to be false. The concept of a correct answer can be
extended to this context by defining an answer to be correct if the goal, with the
answer applied, is a logical consequence of the completion of the program.
Having given the definition of the appropriate declarative concept, it remains
to give the definition of a computed answer, which is the procedural counterpart of
a correct answer.
The mechanism usually chosen to compute answers is to use
SLDNF-resolution, which is SLD-resolution augmented by the negation as failure
rule.
In §15 and §16, we study soundness and completeness results for SLDNF-
resolution and the negation as failure rule for normal programs.
For additional discussion of the relationship between the CWA, the negation as
failure rule and the completion of a program, we refer the reader to papers by
Shepherdson [95], [97] and [98].
In [95], alternatives to the soundness theorems
15.4 and 15.6 below are presented, based on the idea of making explicit the
appropriate first order theory underlying the CWA. Problems 26-31 at the end of
this chapter are based on results from [95].
[98] contains a detailed discussion of
some of the forms of negation used in logic programming, which as well as the
approaches to negation oased on (classical) first order logic mentioned above, also
include the use of 3-valued logic, modal logic and intuitionistic logic.
In this
book, we concentrate on the approach to negation which is based on the
completion of a program and first order logic.
§13. FINITE FAILURE
The main results of this section are several characterisations of the finite
failure set of a definite program.
f
d fi .
gram
This
First, we give the definition of the finite failure set 0
a
e mIte pro
.
definition was first given by Lassez and Maher [54].
.
Th
--ti th
set of atoms in B
which
Definition Let P be a definIte program.
en ri?'
e
p
are finitely failed by depth d, is defined as follows:
(a) AeF~ if Ai:TpJ.1.
--ti
B
B'
P and each substitution e
(b) Aer;=:, for d>1, if for each clause B~ 1"'"
n m
h th P A-Be and B e
Beare ground, there exists k such that l~k~n and
suc
at
-
1 ,..., n
BkeeFi-1.
Th
fi 't
fiailure set F
of P is
Definition
Let P be a definite program.
e
Inl e
p
defined by Fp = u~lFi·
Note the following simple relationship between Fp and TpJ.ro.
(See problem
1.)
Proposition 13.1 Let P be a definite program. Then Fp = Bp\TpJ.ro.
•
C
ally the definition of the SLD finite failure set of a
We now gIve, more Lorm
,
definite program [4], [15].
Definition Let P be a definite program and 0 a definite goal. A finitely failed
SLD-tree for P u {O} is one which is finite and contains no success branches.
Definition Let P be a definite program. The SW finite failure set of p is the
set of all AeBp for which there exists a finitely failed SLD-tree for P u
{~A}.
.
.
ent that all SLD-
Note carefully in this last definition that there IS no reqmrem
trees fail finitely, only that there exists at least one.
. al
f F
and the SLD finite failure
Our main task is to establish the eqUIV ence 0
p
set.
We begin with two lemmas, due to Apt and van Emden [4], whose easy
proofs are omitted. (See problems 2 and 3.)
fi .
al and e a
Lemma 13.2 Let p be a definite program, 0
a de mIte go
substitution.
Suppose that P U {O} has a finitely failed SLD-tree of depth ~ k.
Then P U {Oe} also has a finitely failed SLD-tree of depth ~ k.
L
133 Let P be a definite program and AieBp' for i=l,...,m. Suppose
emma
•
h < k
Then there
h
P
{,--A
A} has a finitely failed SLD-tree of dept
-
.
t at
u..----
1'"'' m
f d
th < k
.
.
{1
m} such that P U
{~A.} has a finitely failed SLD-tree 0
ep
-
.
eXIsts Ie
,...,
1

76
Chapter 3, Normal Programs
§14, Programming with the Completion
77
The next proposition is due to Apt and van Emden [4].
Proposition 13.4 Let P be a definite program and AeB . If P u {f-A} has a
finitely failed SLD-tree of depth:;; k, then AiTpJ..k.
p
Proof Suppose first that P u {f-A} has a finitely failed SLD-tree of depth 1.
Then AiTpJ..1.
Now assume the result holds for k-1.
Suppose that P u {f-A} has a finitely
failed SLD-tree ~f depth:;; k.
Suppose, to obtain a contradiction, that AeTpJ..k.
Then
there
eXIsts
a
clause
Bf-Bl'...,Bn
in
P
such
that
A=B8
and
{BI8,...,Bn8} k TpJ..(k-I), for some ground substitution 8.
Thus there exists an
mgu y such that Ay=By and 8="(0", for some cr. Now f-(B I,...,B )y is the root of a
finitely failed SLD-tree of depth :;; k-1. By lemma 13.2, so als~ is f-(Bl'...,B )8.
By lemma 13.3, some f-Bi8 is the root of a finitely failed SLD-tree of dept~ :;;
k-1. By the induction hypothesis, Bi8iTpJ..(k-I), which gives the contradiction.
II1II
It is interesting that the (strict) converse of proposition 13.4 does not hold.
(See problem 4.) Next we note that SLD finite failure only guarantees the existence
~f o~e finitely failed SLD-tree - others may be infinite. It would be helpful to
Id~ntIfy exactly those ways of selecting atoms which guarantee to find a finitely
faIled SLD-tree, if one exists at all. For this purpose, the concept of fairness was
introduced by Lassez and Maher [54].
Definition An SLD-derivation is fair if it is either failed or, for every atom B
in the derivation, (some further instantiated version of) B is selected within a finite
number of steps.
Note that there are SLD-derivations via the standard computation rule which
are not fair. One can achieve fairness by, for example, selecting the leftmost atom
to the right of the (possibly empty set of) atoms introduced at the previous
derivation step, if there is such an atom; otherwise, selecting the leftmost atom.
Definition
An SLD-tree is fair if every branch of the tree is a fair SLD-
derivation.
ProPositio~ 13.5 Let P be a definite program and f-Al'...,Am a definite goal.
Suppose there IS a non-failed fair derivation f-A
A
=G
G
wI'th mgu's
1'"'' m
0'
1""
~1' 82,.... Then, given kero, there exists nero such that [Ai8r .8n] k TpJ..k, for
I=I,...,m.
Proof Theorem 7.4 shows that we can assume that the derivation is infinite.
Clearly it suffices to show that given ie {1,...,m} and kero, there exists nero such
that [Ai81...8n] k TpJ..k.
Fix ie{I,...,m}. The result is clearly true for k=O. Assume it is true for k-1.
Suppose Ai81,..8p-l is selected in the goal Gp-l' (By fairness, Ai must eventually
be selected.) Let Gp be f-Bl'...,Bq, where q~1. By the induction hypothesis, there
exists sero such that uCJ. I[B,8
1..,8
] c
TpJ..(k-l). Hence we have that
J=
J p+
p+s-
[Ai81...8p+s] k Tp(uf;:l[Bj8p+l...8p+sD k Tp(TpJ..(k-l» = TpJ..k.
II1II
Combining the results of Apt and van Emden [4] and Lassez and Maher [54],
we can now obtain the characterisations of the finite failure set.
Theorem 13.6 Let P be a definite program and AeBp' Then the following are
equivalent:
(a) AeFp'
(b) AiTpJ..ro.
(c) A is in the SLD finite failure set.
(d) Every fair SLD-tree for P u {f-A} is finitely failed.
Proof
(a) is equivalent to (b) by proposition 13.1. That (d) implies (c) is
obvious. Also (c) implies (b) by proposition 13.4.
Finally, suppose that (d) does not hold. Then there exists a non-failed fair
derivation for f-A. By proposition 13.5, AeTpJ..ro. Thus (b) does not hold.
II1II
Theorem
13.6 shows that fair SLD-resolution is a sound and complete
implementation of finite failure.
§14. PROGRAMMING WITH THE COMPLETION
In this section, normal programs are introduced. These are programs whose
program clauses may contain negative literals in their body. The completion of a
normal program is also defined. The completion will play an important part in the
soundness and completeness results for the negation as failure rule and SLDNF-
resolution. The definition of a correct answer is extended to normal programs.
Definition A program clause is a clause of the form
Af-L1,·..,Ln
where A is an atom and Ll'...,Ln are literals.

78
Chapter 3. Normal Programs
Definition A normal program is a finite set of program clauses.
§14. Programming with the Completion
Vx (p(x) ~ (3y«X=y)Aq(y)A-r(a,y)) v 3z«x=f(z))A-q(z)) v (x=b)))
79
where Ll,...,Ln are literals.
Definition A normal goal is a clause of the fonn
f-Ll,···,Ln
Definition The definition of a predicate symbol p in a nonnal program P is the
set of all program clauses in P which have p in their head.
Every definite program is a nonnal program, but not conversely.
In order to justify the use of the negation as failure rule, Clark [15] introduced
the idea of the completion of a nonnal program.
We next give the definition of
the completion.
Let p(tl'...,tn)f-Ll'...,Lm be a program clause in a nonnal program P.
We
will require a new predicate symbol =, not appearing in P, whose intended
interpretation is the identity relation. The first step is to transfonn the given clause
into
p(xl ,...,xn)f-(xl =tl)A...A(xn=tn)ALl A...AL
wh~re xl'""xn ar~ ~ariables not appearing in the clause.
The~, if Yl""'Yd are the
vanables of the ongmal clause, we transfonn this into
p(xl ,...,xn)f-3y1·..3yd «xl=tl)A...A(xn=tn)ALl A...AL
)
Now Suppose this transfonnation is made for each clause in themdefinition of p.
Then we obtain le1 transfonned fonnulas of the fonn
p(xl,..·,Xn)f-El
p(xl,..·,Xn)f-Ek
where each Ei has the general fonn
3y1·..3yd «xl=tl)A...A(xn=tn)ALl A...ALm)
The completed definition of p is then the fonnula
Vxl,,,Vxn (P(xl,,,,,xn)~Elv...VI\)
Example Let the definition of a predicate symbol p be
p(y) f- q(y), -r(a,y)
p(f(z)) f- -q(z)
p(b) f-
Then the completed definition of p is
Example The completed definition of the predicate symbol student from the
example in §12 is
Vx (student(x)~(x=joe)v(x=bill)v(x=jim))
Some predicate symbols in the program may not appear in the head of any
program clause. For each such predicate symbol q, we explicitly add the clause
Vxl···Vxn -q(xl,···,xn)
This is the definition of such q given implicitly by the program. We also call this
clause the completed definition of such q.
It is essential to also include some axioms which constrain =.
The following
equality theory is sufficient for our purpose. In these axioms, we use the standard
notation #- for not equals.
1. c#-d, for all pairs c,d of distinct constants.
2. V(f(xl,...,xn)#-g(Yl""'Ym))' for all pairs f,g of distinct function symbols.
3. V(f(xl""'xn)#-C), for each constant c and function symbol f.
4. V(t[x]#-x), for each tenn t[x] containing x and different from x.
5. V«xl#-Yl)v...v(xn#-Yn)~f(xl,...,xn)#-f(Yl'''''Yn))' for each function symbol f.
6. V(x=x).
7. V«xI=Yl)A
A(xn=Yn)~f(xl, ,xn)=f(Yl""'Yn))' for each function symbol f.
8. V«xI=Yl)A
A(xn=Yn)~(P(xl, ,xn)~P(Yl""'Yn)))'for each predicate symbol p
(including =).
Definition Let P be a nonnal program.
The completion of P, denoted by
comp(p), is the collection of completed definitions of predicate symbols in P
together with the equality theory.
Axioms 6, 7 and 8 are the usual axioms for first order theories with equality.
Note that axioms 6 and 8 together imply that = is an equivalence relation.
(See
problem 9.) The equality theory places a strong restriction on the possible
interpretations of =.
This restriction is essential to obtain the desired justification
of negation as failure.
Roughly speaking, we are forcing = to be interpreted as the
identity relation on Up' (See problem 10.)
Now, as Clark [15] has pointed out, it is appropriate to regard the completion
of the nonnal program, not the nonnal program itself, as the prime object of
interest. Even though a programmer only gives a logic programming system the

80
Chapter 3. Normal Programs
§14. Programming with the Completion
81
nonnal program, the understanding is that, conceptually, the nonnal program is
completed by the system and that the programmer is actually programming with
the completion. Corresponding to this notion, we have the concept of a correct
answer. The problem then arises of showing that SLD-resolution, augmented by the
negation as failure rule, is a sound and complete implementation of the declarative
concept of a correct answer. We tackle this problem in §15 and §16.
Definition Let P be a nonnal program and G a nonnal goal.
An answer for
P u {G} is a substitution for variables in G.
Definition Let P be a nonnal program, G a nonnal goal t-Ll,...,Ln, and e an
answer for P u {G}.
We say e is a correct answer for comp(p) u {G} if
'v'«L1",...I\Ln)e) is a logical consequence of comp(P).
It is important to establish that this definition generalises the definition of
correct answer given in §6. The first result we need to prove this is the following
proposition.
Proposition 14.1 Let P be a nonnal program. Then P is a logical consequence
of comp(P).
Proof Let M be a model for comp(P). We have to show that M is a model for
P. Let p(tl',..,tn)t-Ll,...,Lm be a program clause in P and suppose that Ll'...,Lm
are true in M, for some assignment of the variables y1,...,yd in the clause.
Consider the completed definition of p
'v'xl,..'v'xn (P(xl,,,,,xn)~Elv..,v~)
and suppose E, is
1
3yl,..3yd «Xl=tl )I\,..I\(xn=tn)I\Ll l\,..I\Lm)
Now let xj be tj
(l~j~n), for the same assignment of the variables y1,.."yd as
above, Thus Ei is true in M, since Ll,.."Lm are true inM and also since M must
satisfy axiom 6. Hence p(tl" ..,tn) is true in M.
III
We now define a mapping ~ from the lattice of interpretations based on some
pre-interpretation J to itself,
Definition Let J be a pre-interpretation of a nonnal program P and I an
interpretation based on J.
Then
~(I) = {AJ,V: At-Ll l\,..I\Ln E P, V is a
variable assignment wrt J, and Ll l\,..I\Ln is true wrt I and V}.
When J is the Herbrand pre-interpretation of P, we write Tp instead of ~,
This convention is consistent with our earlier usage of Tp'
Note that ~ is
generally not monotonic, For example, if P is the program
p t--p
then T
is not monotonic. However, if P is a definite program, then ~ is
monot;:ic, Many other properties of TP easily extend to ~,
Proposition 14.2 Let P be a nonnal program, J a pre-interpretation of P, and I
an interpretation based onJ. Then I is a model for P iff ~(I) !:: I.
Proof Similar to the proof of proposition 6.4. (See problem 11.) III
The next result shows that fixpoints of ~ give models for comp(p).
Proposition 14.3 Let P be a nonnal program, J a pre-interpretation of P, and I
an interpretation based on J. Suppose that I, together with the identity relation
assigned to =, is a model for the equality theory. Then I, together with the identity
relation assigned to =, is a model for comp(P) iff ~(I) = I.
Proof Suppose first that ~(I) = I. Since we have assumed that I, together with
the identity relation assigned to =, is a model for the equality theory, it suffices to
show that this interpretation is a model for each of the completed definitions of
comp(p),
Consider a completed definition of the fonn 'v'xl..·'v'xn -q(xl""'xn),
Since I is a fixpoint, it is clear that the interpretation is a model of this fonnula.
Now consider a completed definition of the fonn
'v'xl...'v'xn (P(xl'...,xn)~El v...vEk)
Since ~(I) !:: I, it follows that the interpretation is a model for the fonnula
'v'xl...'v'xn (P(xl',..,xn)~El v...vEk)
Also, since ~(I) :d I, it follows that the interpretation is a model for the fonnula
'v'xl..,'v'x
(P(xl,...,xn)~El v,..vEk)
n
.
Conversely, suppose that I, together with the identity relation assigned to =, IS
a model for the completion. Then using the fact that the interpretation is a model
for formulas of the fonn
'v'xl...'v'xn (P(xl,..·,xn)~Elv ...vEk)
it follows that ~(I) !:: I.
Similarly, using the fact that the interpretation is a
model for fonnulas of the fonn
'v'xl,..'v'xn (p(xl,...,xn)~El v...vEk)
it follows that ~(I) :d I.
III

82
Chapter 3. Normal Programs
§14. Programming with the Completion
83
Proposition 14.4 Let P be a definite program and AeBp' Then Aegfp(Tp) iff
comp(P) u {A} has an Herbrand model.
Proof Suppose Aegfp(Tp)' Then gfp(Tp) u {s=s : seUp } is an Herbrand
model for comp(P) U {A}, by proposition 14.3.
~onversely. Suppose comp(P) U {A} has an Herbrand model M. By the
equahty theory. the identity relation on Up must be assigned to = in the model M.
Thus M has the form I u {s=s : seUp }, for some Herbrand interpretation I of P.
Hence I=Tp(I), by proposition 14.3. and so Aegfp(Tp)'
III
Proposition 14.5
Let P be a definite program and A
A
b
t
If
1.·... mea oms.
'v'(A1"·..,,Am) is a logical consequence of comp(P). then it is also a logical
consequence of P.
Proof Let xl'...,xk be the variables in A1" ..."Am.
We have to show that
'v'x1·..'v'xk (AI" ..."Am)
is
a
logical
consequence
of
P,
that
is,
p u {-'v'x1·..'v'xk (AI" ..."Am)}
is
unsatisfiable
or.
equivalently.
S
p u {-~Iv...v-A~} is unsatisfiable. where Ai is Ai with xl'....xk replaced by
appropnate Skolem constants.
Since S is in clause form, we can restrict attention to Herbrand interpretations
of S. Let I be an Herbrand interpretation of S. We can also regard I as an
interpretation of P. (Note that I is not necessarily an Herbrand interpretation of P.)
~upp~se I is a model for P.
Consider the pre-interpretation J obtained from I by
19nonng the assignments to the predicate symbols in I. By proposition 14.2. we
have that ~(I) k I.
Since
~ is monotonic. proposition 5.2 shows that there
eXi~ts a fixpoint I' k I Of~.
Since I', together with the identity relation
assIgned to =. is obviously a model for the equality theory. proposition 14.3 shows
~at this i~terpretation ~s a model for comp(P). Hence -AIv...v-A~ is false in this
mte~retatlon.
Since I k I, we have that -AIv...v-A~ is false in I. Thus S is
unsatlsfiable.
III
Note that by combining propositions 14.1 and 14.5. it follows that the positive
information which can be deduced from comp(P) is exactly the same as the
positive information which can be deduced from P. To be precise, we have the
following result.
Theorem 14.6
Let P be a definite program, G a definite goal, and e an
answer for P u {G}. Then e is a correct answer for comp(P) u {G} iff e is a
correct answer for P u {G}.
Theorem 14.6 shows that the definition of correct answer given in this section
generalises the definition given in §6.
Every normal program is consistent. but the completion of a normal program
may not be consistent. (See problem 8.) We now investigate a weak syntactic
condition sufficient to ensure that the completion of a normal program is
consistent. The motivation is to limit the use of negation in recursive rules to keep
the model theory manageable.
Definition A level mapping of a normal program is a mapping from its set of
predicate symbols to the non-negative integers. We refer to the value of a predicate
symbol under this mapping as the level of that predicate symbol.
Definition A normal program is hierarchical if it has a level mapping such
that, in every program clause p(tl'...,tn) ~ Ll'....Lm• the level of every predicate
symbol occurring in the body is less than the level of p.
Definition A normal program is stratified if it has a level mapping such that,
in every program clause p(tl.....tn) ~ Ll.....Lm• the level of the predicate symbol
of every positive literal in the body is less than or equal to the level of p, and the
level of the predicate symbol of every negative literal in the body is less than the
level of p.
Clearly. every definite program and every hierarchical normal program is
stratified. We can assume without loss of generality that the levels of a stratified
program are O,l•...,k. for some k.
Stratified normal programs were introduced by
Apt. Blair and Walker [3] as a generalisation of a class of databases discussed by
Chandra and Harel [13]. and later. independently, by Van Gelder [109].
Other
papers on stratified programs are contained in [70].
Even though the mapping ~ is, in general. not monotonic. it does have an
important property similar to monotonicity for stratified normal programs.
This
result is due to Lloyd, Sonenberg and Topor [60].
Proposition
14.7 Let P be
a stratified normal program and J a pre-
interpretation for P.
(a)
Suppose P has only predicates of level O. Then P is definite and ~ is
monotonic over the lattice of interpretations based on 1.

84
Chapter 3. Normal Programs
§15. Soundness of SLDNF-Resolution
85
(b) Suppose P has maximum predicate level k+1.
Let Pk denote the set of
program clauses in P with the property that the predicate symbol in the head of the
clause has level $ k.
Suppose that Mk is an interpretation based on J for P
k
and
Mk is a fixpoint of -r:,k' Then A = {Mk uS: S !:: {p(d1'...,dn) : p is a level k+1
predicate symbol and each d. is in the domain of J} } is a complete lattice, under
1
set inclusion.
FUrthermore, A is a sublattice of the lattice of interpretations based
on J, and -r:" restricted to A, is well-defined and monotonic.
Proof Straightforward. (See problem 13.) III
Corollary 14.8 Let P be a stratified normal program.
Then comp(P) has a
minimal normal Herbrand model.
Proof (A normal model is one for which the identity relation is assigned to =.
Minimal means that there is no strictly smaller normal Herbrand model.) The proof
is by induction on the maximum level, k, of the predicate symbols in P. The case
k=O uses proposition 14.7(a) and proposition 5.1 to obtain the least fixpoint of Tp.
Proposition
14.3 yields the model.
The induction step uses proposition 5.1,
proposition 14.3 and proposition 14.7(b) with Mk as the fixpoint provided by the
induction hypothesis.
III
Corollary 14.8 is due to Apt, Blair and Walker [3].
§IS. SOUNDNESS OF SLDNF-RESOLUTION
In section §14, we introduced the fundamental concept of a correct answer for
comp(p) u {G}. Now iliat we have the appropriate declarative concept, let us see
how we can implement it. The basic idea is to use SLD-resolution, augmented by
the negation as failure rule (SLDNF-resolution). In this section, we prove the
soundness of the negation as failure rule and of SLDNF-resolution.
We give
conditions which are sufficient for a computation to avoid floundering.
We also
discuss the effect that cuts in a normal program can have on the soundness results.
Our first task is to give a precise definition of an SLDNF-refutation and a
finitely
failed
SLDNF-tree.
For iliis,
we first
give
the
mutually recursive
definitions of ilie concepts of SLDNF-refutation of rank k and finitely failed
SLDNF-tree of rank k.
In the definitions which follow, it will be necessary to select literals from
normal goals. The choice of which literal is selected is constrained in the following
way. There is no restriction on which positive literal can be selected; however,
only a ground negative literal can be selected. This condition is called the safeness
condition on ilie selection of literals. It is used to ensure the soundness of
SLDNF-resolution. Later we discuss the possibility of weakening this condition.
C be A
M
M
Then G' is
Definition Let G be ~L1,·..,Lm,..·,Lp and
~
1"'"
q'
derived from G and C using mgu 8 if the following conditions hold:
(a) Lm is an atom, called ilie selected atom, in G.
(b) 8 is an mgu of Lm and A.
(c) G' is the normal goal ~(L1'...,Lm_1,M1,...,Mq,Lm+1,...,Lp)8.
Definition Let P be a normal program and G a normal goal. An SWNF-
refutation of rank 0 of P u {G} consists of a sequence GO=G, G1''''' Gn =0 of
normal goals, a sequence C1,,,,,Cn of variants of program clauses of P
an~ a
sequence 81'...,8n of mgu's such that each Gi+1 is derived from Gi and Ci+1 usmg
8i+1·
Definition Let P be a normal program and G a normal goal. A finitely failed
SWNF-tree of rank 0 for P u {G} is a tree satisfying the following:
(a) The tree is finite and each node of ilie tree is a non-empty normal goal.
(b) The root node is G.
(c) Only positive literals are selected at nodes in ilie tree.
.
(d) Let ~L1,...,Lm,...,Lp be a non-leaf node in ilie tree and suppose iliat Lm IS an
atom and it is selected. Then, for each program clause (variant) A~M1,...,Mq such
that
L
and
A
are
unifiable
with
mgu
8,
this
node
has
a
child
m
~(L1,...,Lm_1,M1, ,Mq,Lm+1,...,Lp)8.
.
(e) Let ~L1'...,Lm,
,Lp be a leaf node in the tree and suppose that Lm IS an atom
and it is selected. Then there is no program clause (variant) in P whose head
unifies with Lm.
Definition Let P be a normal program and G a normal goal. An SWNF-
refutation of rank k+l of P u {G} consists of a sequence GO=G, G1''''' Gn =0 of
normal goals, a sequence C1,,,,,Cn of variants of program clauses of P or groun~
negative literals, and a sequence 81'...,8n of substitutions, such iliat, for each 1,
either
(i) Gi+1 is derived from Gi and Ci+1 using 8i+l' or

86
Chapter 3. Normal Programs
§15. Soundness of SLDNF-Resolution
87
(ii) Gi is f-Ll,···,Lm,...,Lp' the selected literal Lm in Gi is a ground negative
literal -Am and there is a finitely failed SLDNF-tree of rank k for P U if-Am}'
In this case, Gi+l is f-Ll'...,Lm_l,Lm+l,...,Lp'
ei+l is the identity substitution
and Ci+1 is -Am'
Definition Let P be a normal program and G a normal goal. A finitely failed
SLDNF-tree of rank k+1 for P U {G} is a tree satisfying the following:
(a) The tree is finite and each node of the tree is a non-empty normal goal.
(b) The root node is G.
(c) Let f-Ll,·..,L
,...,L
be a non-leaf node in the tree and suppose that L
is
m
p
m
selected. Then either
(i) Lm is an atom and, for each program clause (variant) Af-Ml'...,Mq such
that
Lm
and
A
are
unifiable
with
mgu
e,
the
node
has
a
child
f-(Ll ,...,Lm_l ,Ml ,...,Mq,Lm+1,...,Lp)e, or
(ii) Lm is a ground negative literal -Am and there is a finitely failed SLDNF-
tree
of
rank
k
for
P U {f-A
},
in
which
case
the
only
child
is
m
f-L l ,...,Lm_l ,Lm+1, ,Lp'
(d) Let f-Ll,..·,Lm,
,Lp be a leaf node in the tree and suppose that Lm is
selected. Then either
(i) Lm is an atom and there is no program clause (variant) in P whose head
unifies with L
, or
m
(ii) Lm is a ground negative literal -Am and there is an SLDNF-refutation of
rank k of P U {f-Am}.
Note that an SLDNF-refutation (resp., finitely failed SLDNF-tree) of rank k is
also an SLDNF-refutation (resp., finitely failed SLDNF-tree) of rank n, for all n~k.
Definition Let P be a normal program and G a normal goal. An SLDNF-
refutation of P U {G} is an SLDNF-refutation of rank k of P U {G}, for some k.
Definition Let P be a normal program and G a normal goal. A finitely failed
SLDNF-tree for P U {G} is a finitely failed SLDNF-tree of rank k for P U {G},
for some k.
Definition
Let P be a normal program and G a normal goal.
A computed
answer e for P U {G} is the substitution obtained by restricting the composition
el·..en to the variables of G, where el'...,en is the sequence of substitutions used
in an SLDNF-refutation of P U {G}.
Since only ground negative literals are selected, it follows that Lie must be
ground, for each negative literal Li in G. This definition extends the definition of a
computed answer given in §7.
Now that we have given the definition of a computed answer, we consider the
procedure a logic programming system might use to compute answers. The basic
idea is to use SLD-resolution, augmented by the negation as failure rule. When a
positive literal is selected, we use essentially SLD-resolution to derive a new goal.
However, when a ground negative literal is selected, the goal answering process is
entered recursively in order to try to establish the negative subgoal. We can regard
these negative subgoals as separate lemmas, which must be established to compute
the result.
Having selected a ground negative literal -A in some goal, an attempt
is made to construct a finitely failed SLDNF-tree with root f-A before continuing
with the remainder of the computation. If such a finitely failed tree is constructed,
then the subgoal -A succeeds. Otherwise, if an SLDNF-refutation is found for
f-A, then the subgoal -A fails.
Note that bindings are only made by successful
calls of positive literals. Negative calls never create bindings; they only succeed or
fail. Thus negation as failure is purely a test.
Next we give the definitions of SLDNF-derivation and SLDNF-tree.
Definition Let P be a normal program and G a normal goal. An SLDNF-
derivation of P u {G} consists of a (finite or infinite) sequence GO=G, Gl ,... of
normal goals, a sequence Cl , C2,... of variants of program clauses (called input
clauses) of P or ground negative literals, and a sequence e l, e2,... of substitutions
satisfying the following:
(a) For each i, either
(i) G.
is derived from G. and an input clause C1'+1 using ei+l , or
1+1
1
.
(1'1') G
l'S L-L
L
L
the selected literal L
in G. is a ground negatIve
i
-- 1,..., m"'"
p'
mI.
literal -A
and there is a finitely failed SLDNF-tree for P U if-Am}' In thIS
case
G
m l'S L-L
L
L
L
e. 1 is the identity substitution and
,
i+l
. -- 1"'"
m-l' m+l"'"
p'
1+
Ci+l is -Am'
(b) If the sequence GO' G l ,... of goals is finite, then either
(i) the last goal is empty, or
(ii) the last goal is f-Ll'...,Lm,...,Lp' Lm is an atom, Lm is selected and there
is no program clause (variant) in P whose head unifies with Lm, or
(iii) the last goal is f-Ll,...,Lm,...,Lp'
Lm is a ground negative literal -Ain,
L
is selected and there is an SLDNF-refutation of P U {f-Am }.
m

88
Chapter 3. Normal Programs
§15. Soundness of SLDNF-Resolution
89
Definition Let P be a normal program and G a normal goal. An SWNF-tree
for P u {G} is a tree satisfying the following:
(a) Each node of the tree is a (possibly empty) normal goal.
(b) The root node is G.
(c) Let f-LI'...,Lm,...,Lp (p~l) be a non-leaf node in the tree and suppose that L
m
is selected. Then either
(i) Lm is an atom and, for each program clause (variant) Af-M1,...,M
such
that
Lm
and
A
are
unifiable
with
mgu
e,
the
node
has
a q child
f-(L1,...,Lm_1,M1,...,Mq,Lm+I,...,Lp)e, or
(ii) Lm is a ground negative literal -Am and there is a finitely failed SLDNF-
tree for P u {f-Am }, in which case the only child is f-L1,...,L
I,L
1,...,L.
m-
m+
p
(d) Let f-LI'...,Lm,...,Lp (P~I) be a leaf node in the tree and suppose that L
m
is
selected. Then either
(i) Lm is an atom and there is no program clause (variant) in P whose head
unifies with L
, or
m
(ii) Lm is a ground negative literal -Am and there is an SLDNF-refutation of
P U if-A
}.
m
(e) Nodes which are the empty clause have no children.
The
concepts
of
SLDNF-derivation,
SLDNF-refutation
and
SLDNF-tree
generalise those of SLD-derivation, SLD-refutation and SLD-tree.
An SLDNF-
derivation is finite if it consists of a finite sequence of goals; otherwise, it is
infinite.
An SLDNF-derivation is successful if it is finite and the last goal is the
empty goal.
An SLDNF-derivation is failed if it is finite and the last goal is not
the empty goal.
Similarly, we define success, infinite and failure branches of an
SLDNF-tree. It is clear that a successful SLDNF-derivation is indeed an SLDNF-
refutation and an SLDNF-tree, for which every branch is a failure branch, is indeed
a finitely failed SLDNF-tree.
If a goal contains only non-ground negative literals, then, because of the
safeness condition, no literal is available for selection.
Let us formalise this
notion.
By a computation of P U {G}, we mean an attempt to construct an
SLDNF-derivation of P U {G}.
Definition Let P be a normal program and G a normal goal.
We say a
computation of P U {G} flounders if at some point in the computation a goal is
reached which contains only non-ground negative literals.
Example If G is f- -p(x) and P is any normal program, then the computation
of P u {G} flounders immediately.
We now give a condition under which we can be sure that SLDNF-resolution
never flounders.
Definition Let P be a normal program and G a normal goal.
We say a program clause Af-LI'...,Ln in P is admissible if every variable that
occurs in the clause occurs either in the head A or in a positive literal of the body
L 1,···,Ln·
We say a program clause Af-LI'...,Ln in P is allowed if every variable that
occurs in the clause occurs in a positive literal of the body LI'...,Ln.
We say G is allowed if G is f-LI'
,Ln and every variable that occurs in G
occurs in a positive literal of the body L1, ,Ln.
We say P u {G} is allowed if the following conditions are satisfied:
(a) Every clause in P is admissible.
(b) Every clause in the definition of a predicate symbol occurring in a positive
literal in the body of G or in a positive literal in the body of a clause in P is
allowed.
(c) G is allowed.
Note that an allowed unit clause must be ground and every allowed clause is
admissible.
These definitions generalise Clark's definition [15] of an allowed
query and Shepherdson's covering axiom [95]. The next result is due to Lloyd and
Topor [63] and Shepherdson [97].
Other results on allowedness are contained in
[97].
Proposition 15.1 Let P be a normal program and G a normal goal.
Suppose
that P u {G} is allowed. Then we have the following properties.
(a) No computation of P u {G} flounders.
(b) Every computed answer for P u {G} is a ground substitution for all variables
in G.
Proof (a) Since P u {G} is allowed, one can prove that every goal in an
SLDNF-derivation of P u {G} (including subsidiary derivations) is allowed.
The
result then follows as a goal containing only non-ground negative literals is not
allowed.
(b) Let G be f-LI'...,Lm and let 00=G, GI'...,Gn= 0 be an SLDNF-refutation

The next result of this section is the soundness of the negation as failure rule.
In preparation for the proof of this result, we establish two lemmas due to Clark
[15].
of P U {G} using substitutions 91,...,9n. Note that any input clause whose head is
matched against a positive literal in (the top level of) the refutation has the
property that each variable which occurs in the head also occurs in the body. It is
straightforward to prove by induction on the length n of the refutation that
(LIA...ALm)91...9n is ground. The result then follows. I
Lemma 15.2 Let p(sl'
,sn) and p(tl,...,tn) be atoms.
(a) If p(sl'...,sn) and p(tl'
,tn) are not unifiable, then -:3«sl=tl)A...A(Sn=tn» is a
logical consequence of the equality theory.
(b) If p(sl'...,sn) and p(tl'...,tn) are unifiable with mgu 9 = {xl/rI, ,xIlrk} given
by the unification algorithm, then \7'«sl=tl)A...A(Sn=tn) ~ (XI=rI)A
A(Xk=rk» is
a logical consequence of the equality theory.
Proof
Suppose that p(sl'...,sn) and p(tl,...,tn) are unifiable with mgu 9 =
{xl/rl'...,xIlrk}.
Then
it
follows
from
equality
axioms
6,
7
and
8
that
\7'«sl=tl)A...A(Sn=tn)f-(xI=rI)A...A(xk=rk»
is
a
logical
consequence
of the
equality theory.
The remainder of the lemma is proved by induction on the
number of steps k of an attempt by the unification algorithm to unify p(sl'...,sn)
and p(tl,...,tn).
Suppose first that k=l. If the unification algorithm finds a substitution {xl/rI},
say, which unifies p(sl'...,sn) and p(tl'...,tn), then equality axiom 5 can be used to
show that \7'«sl=tl)A...A(Sn=tn)~(xI =rI» is a logical consequence of the equality
theory. Otherwise, we use equality axiom 5 and one of the equality axioms I to 4
to conclude that -:3«sl=tl)A...A(Sn=tn»is a logical consequence of the equality
theory.
Suppose now that the result holds for k-l. Let p(sl'...,sn) and p(tl'...,tn) be
such that it takes the unification algorithm k steps to decide whether they are
unifiable or not.
Suppose that 81 = {x/r'l} is the first substitution made by the
unification algorithm. Then p(sl'...,sn)81 and p(t1'...,tn)81 are such that the
unification algorithm can discover in k-I steps whether they are unifiable or not.
Suppose that p(sl'...,sn)81 and p(tl'...,tn)81 are not unifiable.
Then the
induction
hypothesis
gives
that
-:3«sl=tl)8IA...A(Sn=tn)81)
is
a
logical
consequence of the equality theory. It then follows from this and the fact that 81
was
the
first
substitution
made
by
the
unification
algorithm
that
91
3y. 1...3y. d «xl=t1· I)A...A(xn=ti n)ALi IA...ALi m)
1,
1,i'
",
1
It follows that
G ~ Af=1 -3(MIA...AMj_IA(S I=ti,I)A...A(Sn=ti,n)ALi,IA...ALi,m{Mj+IA...AMq)
is a logical consequence of comp(p). If p(sl'...,sn) does not unify with the head of
any program clause in the definition of p, then it follows from lemma 15.Z(a) that
G is a logical consequence of comp(p).
On the other hand, suppose 8 is an mgu of p(sl'...,sn) and P(ti,I,·..,ti,n)· Then
we have that
:3(MIA...AMj_IA(SI=ti,1)A...A(Sn=ti,n)ALi,IA...ALi,m{Mj+IA...AMq) ~
:3«MIA...AMj_1ALi,IA...ALi,m.AMj+IA...AMq>8)
is a logical consequence of comp(p), using le~a 15.2(b) and the equality axi~ms
6, 7 and 8. Thus, if {Gl'...,Gr} is the set of derived goals, then G~G IA...AGr IS a
logical consequence of comp(P). I
where Ei is
The next result is due to Clark [15].
-:3«sl=tl)A...A(Sn=tn»is a logical consequence of the equality theory.
.
On the other hand, suppose that p(sl'...,sn)81 and p(tl'...,tn)81 are umfiable.
Then
the
induction
hypothesis
is
used
to
obtain
that
\7'«sl=tl)8IA...A(Sn=tn)81~(XZ=rZ)A...A(xk=rk» is a logical. con~equence of the
equality theory. It follows
from this,
the fact that rI
IS rIy,
where y =
{xirz,...,xIlrk},
and
equality
axioms
5,
6,
7
and
8
that
\7'«sl=tl)A...A(Sn=tn)~(xI=rI)A ...A(xk=rk»
is
a
logical
consequence
of the
equality theory. I
Lemma 15.3 Let P be a normal program and G a normal goal. Suppose the
selected literal in G is positive.
(a) If there are no derived goals, then G is a logical consequence of comp(P).
(b) If the set {Gl'...,Gr} of derived goals is non-empty, then G~GIA...AGr is a
logical consequence of comp(P).
Proof Suppose G is the normal goal f-Ml'...,Mq and the selected positiv~
literal M. is p(sl'...,sn)' If the completed definition for p is \7'(-p(xl""'xn», then It
is clear that G is a logical consequence of comp(P).
Next suppose that the completed definition of p is
\7'(p(xI,...,xn)~EI v...vEk)
§15. Soundness of SLDNF-Resolution
Chapter 3. Normal Programs
90

92
Chapter 3. Normal Programs
93
§15. Soundness of SLDNF-Resolution
Theorem 15.4 (Soundness of the Negation as Failure Rule)
Let P be a nonnal program and G a nonnal goal. If P u {G} has a finitely
failed SLDNF-tree, then G is a logical consequence of comp(P).
Proof The proof is by induction on the rank k of the finitely failed SLDNF-
tree for P u {G}. Let G be the goal ~LI,...,Ln'
Suppose first that k=O. Then the result follows by a straightforward induction
on the depth of the tree, using lemma 15.3.
Next suppose the result holds for finitely failed SLDNF-trees of rank k.
Consider a finitely failed SLDNF-tree of rank k+I for P u {G}. We establish the
result by a secondary induction on the depth of this tree.
Suppose first that the depth of this tree is 1. Suppose the selected literal in G
is positive. Then the result follows from lemma 15.3(a).
On the other hand,
suppose the selected literal Li in G is the ground negative literal -Ai' Since the
depth is 1, there is an SLDNF-refutation of rank k of P u
{~Ai}' Note that for a
goal whose selected literal is positive, the derived goal is a logical consequence of
the given goal and the input clause. Thus, using proposition 14.1 and applying the
induction hypothesis on any finitely f3.iled SLDNF-trees of rank k-I in this
refutation, we obtain that Ai is a logical consequence of comp(P). Hence
-3(LIA...ALn) is also a logical consequence of comp(P).
(This last step uses the
fact that Ai is ground.)
Now suppose that the finitely failed SLDNF-tree for P u {G} has depth d+1.
Suppose that the selected literal in G is positive.
Then the result follows from
lemma 15.3(b) and the secondary induction hypothesis.
Suppose the selected
literal in G is the ground negative literal L..
By the secondary induction
1
hypothesis, we obtain that -3(LIA...ALi_IALi+IA...ALn) is a logical consequence
of comp(P). Hence -3(LIA...ALn) is also a logical consequence of comp(P). II
Corollary ISS
Let P be a definite program. If AeFp' then -A is a logical
consequence of comp(p).
Now we come to the soundness of SLDNF-resolution. This result, which
generalises theorem 7.1, is essentially due to Clark [15].
Theorem 15.6 (Soundness of SLDNF-Resolution)
Let P be a nonnal program and G a normal goal.
Then every computed
answer for P u {G} is a correct answer for comp(p) u {G}.
L
d 8
8
be the sequence of
Proof Let G be the normal goal ~LI'"'' k an
1"'"
n
substitutions used in an SLDNF-refutation of P u {G}. We have t~ show that
\-I«L
L)8
8) is a lomcal consequence of comp(p). The result IS proved by
v
IA...A-k
1''' n
O'
•
induction on the length of the SLDNF-refutatlOn.
th
t:
L
We consider
Suppose first that n=1. This means that G has
e orm ~ l'
two cases.
(a) LI is positive.
8
.
Then P has a unit clause of the fonn A~ and LI81 = A8 I· Since LI Ir
IS
an instance of a unit clause of P, it follows that V(LI81) is a logical consequence
of P and, hence, of comp(p).
(b) L
is negative.
I
th
~
L
is ground 8
is the identity substitution and theorem 15.4
n
IS case,
1
'
1
shows that LI is a logical consequence of comp(P).
.
Next suppose that the result holds for computed answers WhICh com~ f~om
8
8
is the sequence of subsntunons
SLDNF-refutations of length n-1. Suppose
1"'"
n
f I
th
Let L
be the selected
used in the SLDNF-refutation of P u {G}
0
eng
n.
m
literal of G. Again we consider two cases.
(a) L
is positive.
.
Let :~M ,...,M
(q~O) be the first input clause. By the induction hypotheSIs,
1
q
L
A..AL )8 ...8 ) is a logical consequence of
V«LIA...AL
IAMIA...AMqA m+I'
kIn
f
comp(p).
Th~;fore, if q>O, V«MIA...AMq)8 I...8n) is a logical consequenc~ 0
t1
V(L 8
8) which is the same as V(A8I..·8n), IS a
comp(p). Consequen y,
m 1'" n'
8
8)'
logical consequence of comp(p).
Hence we have that V«LIA...A~) 1'" n
IS a
logical consequence of comp(P).
(b) L
is negative.
I
th~
L
is ground, 8
is the identity substitution and theorem 15.4
n
IS case,
m
1
th
. d
tion
shows that L
is a logical consequence of comp(p).
~sing
e m uc
m
L)8
8)'
a lOgical consequence of
hypothesis, we obtain that V«LIA...A k
1'" n
IS
comp(P). II
Finally we turn to the problem of weakening the safeness condition on the
selection o~ literals.
First we shOW that if the safeness condition is dropped, then
theorem 15.4 will no longer hold.
Example Consider the nonnal program P
p r
-q(x)
q(a) ~

94
Chapter 3. Normal Programs
§16. Completeness of SLDNF-Resolution
95
If we drop the safeness condition, then the literal -q(x) can be selected and we
obtain a "finitely failed SLDNF-tree" for P u
{~p}.
The subgoal _q(x) fails
because there is a refutation of ~q(x) in which x is bound to a. However, it is
easy to see that -p is not a logical consequence of comp(P).
It is possible to weaken the safeness condition a little and still obtain the
results. Consider the following weaker safeness condition. Non-ground negative
subgoals are allowed to proceed.
If the negative subgoal succeeds, then we
proceed as before. However, if the negative subgoal fails, a check is made to make
sure no bindings were made to any variables in the top-level goal of the
~orresponding refutation. If no such binding was made, then the negative subgoal
IS allowed to fail and we proceed as before. But, if such a binding was made then
a different literal is selected and the negative subgoal is delayed in the hop~ that
more of its variables will be bound later. Alternatively, a control error could be
generated and the program halted.
. The key point here is that the refutation which causes the negative subgoal to
fall must prove something of the form \::I(A) rather than only 3(A).
For this
weakened safeness condition, theorems 15.4 and 15.6 continue to hold. The only
change to their proofs is in the proof of theorem 15.4 at the place where we
remarked that use was made of the fact that A was ground.
The simplest way to implement the safeness condition in a PROLOG system is
to delay negative subgoals until any variables appearing in the subgoal have been
bound to ground terms.
For example, this is the method used by MU-PROLOG
[73] and NU-PROLOG [104]. Unfortunately, the majority of PROLOG systems do
not have a mechanism for delaying subgoals and so this solution is not available to
them. Worse still, most PROLOG systems do not bother to check that negative
subgoals are ground when called. This can lead to rather bizarre behaviour.
Example Consider the program
p(a) ~
q(b) ~
and the normal goal ~ -p(x),q(x). If this program and goal are run on a PROLOG
system which uses the standard computation rule and does not bother to check that
negative subgoals are ground when called, then it will return the answer "no"! On
the other hand, MU-PROLOG and NU-PROLOG will delay the first subgoal, solve
the second subgoal and then solve the first subgoal to give the correct answer
{x/b}. Of course, the problem with this particular goal can be fixed for a standard
PROLOG system by reordering the subgoals in the goal. However, that is not the
point. A problem similar to this could lie undetected deep inside a very large and
complex software system.
We now discuss the effect that cuts in a normal program can have on the
soundness results.
In §11, we showed that the existence of a cut in a definite
program
does
not
affect
the
soundness,
but
may
introduce
a
form
of
incompleteness
into
the
SLD-resolution
implementation
of
correct
answer.
However, for normal programs, it is possible for a cut to affect soundness.
Example Consider the subset program
subset(x,y) ~ -p(x,y)
p(x,y) ~ member(z,x), -member(z,y)
member(x, x.y) ~ 1
member(x, y.z) ~ member(x,z)
in which sets are represented by lists. The goal
~subset([1,2,3], [1]) succeeds for
this program! The reason is that the unsafe use of cut in the definition of member
causes a finitely failed tree for ~p([l,2,3],[I]) to be incorrectly constructed. Hence
the negated subgoal -p([1,2,3],[I]) incorrectly succeeds.
As before, the best solution to the problems of cut seems to be to replace its
use by higher level facilities, such as if-then-else and not equals.
§16. COMPLETENESS OF SLDNF·RESOLUTION
In this section, we prove completeness results for the negation as failure rule
for definite programs and SLDNF-resolution for hierarchical programs.
We also
present a summary of the main results of the chapter for definite programs.
The next result is due to Jaffar, Lassez and Lloyd [47]. The simpler definition
of the equivalence relation in the proof, which avoids most of the technical
complications of the original proof in [47], is due to Wolfram, Maher and Lassez
[112].
Theorem 16.1 (Completeness of the Negation as Failure Rule)
Let P be a definite program and G a definite goal.
If G is a logical
consequence of comp(p), then every fair SLD-tree for P u {G} is finitely failed.

96
Chapter 3. Normal Programs
§16. Completeness of SLDNF-Resolution
97
Pr~f ~t G be .the goal f-Al'...,Aq. Suppose that P U {G} has a fair SLD-
tree WhICh IS not fimtely failed.
We prove that comp(p) U {3(A
I
" ..."A )} has a
model.
q
~t BR be any non-failed branch in the fair SLD-tree for P U {G}.
Suppose
BR 1.S GO=G, GI,..· with mgu's 81, 82""
and input clauses C
1
, C
2
,.... The first
step IS to use BR to define a pre-interpretation J for P.
Suppose L is the underlying first order language for P. Naturally, L is assumed
to be rich enough to support any standardising apart necessary in BR. We define a
relation * on the set of all terms in L as follows.
Let s and t be terms in L. Then
s*t if there exists n~ 1 such that s8 ...8
= t8
8
that l'S 8
8'fi
d
.
.
.
1
n
1'"
n'
,
1'" n um 1es s an
1.
It IS clear that * IS mdeed an equivalence relation.
We then define the domain D
of the pre-interpretation J as the set of all *-equivalence classes of terms in L. If s
is a term in L, we denote the equivalence class containing s by [s].
.
Next we give the assignments to the constants and function symbols in L. If c
IS a constant in L, we assign [c] to c. If f is an n-ary function symbol in L we
~ssign the mapping fr~m ~n .into D defined by ([sl],...,[snD ~ [f(sl'...,sn)] to;. It
IS clear that the mappmg IS mdeed well-defined.
This completes the definition of
J.
The next task is to give the assignments to the predicate symbols in order to
extend J to an interpretation for comp(P) U {3(Al"..."A )}. First we define the
set 10 as fOllows:
q
10 = {p([t1],...,[tnD : p(tl'...,tn) appears in BR}.
:ve next s.how that 10 ~ r:,(IO)' where r:, is the mapping associated with the pre-
mt~retat1on J. Suppose that p([t1],...,[tnD e 10, where p(tl'...,t ) appears in some
Gi, lew. Because BR is fair and not failed, there exists jew suc~ that p(sl""'s ) =
p(t1,...,tn)8i+1..·8i+j appears in goal Gi+j and P(sl'''''s ) is the selected ator:; in
Gi+j' Suppose Ci+j+1 is p(rl'..·,Tn)f-B1,...,Bm. By the ~efinition of r:" it follows
that p([r18i+j+1],...,[rn8i+j+1D e ~(IO)'
Then, using the fact that, for each k,
81..·8k can be assumed to be idempotent, we have that
p([t1],...,[tnD
= p([t18i+1..·8i+j],..·,[tn8i+1·..8i+jD
= P([sl],...,[snD
= P([S18i+j+1],..·,[Sn8i+j+l])
= p([r18i+j+1],...,[rn8i+j+1D,
so that p([t1],...,[tnD e r:,(IO)' Thus 10 ~ r:,(Io)'
Now, by proposition 5.2, there exists I such that 10 ~ I and I = r:,(I).
I gives
the assignments to the predicate symbols in L. We assign the identity relation on D
to =.
This completes the definition of the interpretation I, together with the identity
relation
assigned
to
=,
for
comp(p) U {3(A1" ..."Aq)}.
Note
that
this
interpretation is a model for 3(A1" ..."Aq) because 10 ~ 1. Note
furthe~ ~at this
interpretation is clearly a model for the equality theory. Hence, propOSItIOn 14.3
gives that I, together with the identity relation assigned to =, is a model for
comp(p) U {3(A1" ..."Aq)}.
II1II
Corollary 16.2 Let P be a definite program and AeBp' If -A is a logical
consequence of comp(P), then AeFp'
The model constructed in the proof of theorem 16.1 is not an Herbrand model.
In fact, the next example shows that theorem 16.1 simply cannot be proved by
restricting attention to Herbrand models (based on the constants and function
symbols appearing in the program).
Example Consider the program P
p(f(y» f- p(y)
q(a) f- p(y)
Note that q(a)i:Fp'
Now gfp(Tp)=0 and hence q(a)i:gfp(Tp)'
According to
proposition 14.4, comp(P) U {q(a)} does not have an Herbrand model.
Problem 34 shows that theorem 16.1 generalises to stratified normal programs.
However, this generalisation is not really a completeness result because, as the next
example shows, the existence of a (fair) SLDNF-tree is not guaranteed, in cop.trast
to the definite case, where fair SLD-trees always exist.
To obtain a completeness
result for stratified normal programs, it will thus be necessary to impose further
restrictions to ensure the existence of a fair SLDNF-tree.
Example Consider the stratified normal program P
q f--r
rf-p
r f--p
pf-p
Then it is easy to show that -q is a logical consequence of comp(P), but that
P U {f-q} does not have an SLDNF-tree. (See problem 20.)

98
Now we can give the completeness result for hierarchical programs. Versions
of this result are due to Clark [15], Shepherdson [97], and Lloyd and Topor [63],
Theorem 16..3 (Completeness of SLDNF-Resolution for Hierarchical Programs)
Let P be a hierarchical normal program, G a normal goal, and R a safe
computation rule.
Suppose
that P u {G}
is
allowed.
Then
the
following
properties hold.
(a) The SLDNF-tree for P U {G} via R exists and is finite.
(b) If e is a correct answer for comp(p) u {G} and e is a ground substitution for
all variables in G, then eis an R-computed answer for P u {G}.
Definition Let P be a normal program, G a normal goal, and R a safe
computation rule.
An SWNF-derivation of P u {G} via R is an SLDNF-derivation of P u {G}
in which the computation rule R is used to select literals.
An SWNF-tree for P U {G} via R is an SLDNF-tree for P u {G} in which
the computation rule R is used to select literals.
An SWNF-refutation of P u {G} via R is an SLDNF-refutation of P u {G}
in which the computation rule R is used to select literals.
An R-computed answer for P U {G} is a computed answer for P u {G} which
has come from an SLDNF~refutation of P u {G} via R
Proof (a) By proposition 15.1(a), the computation of P u {G} via R does not
flounder.
To show that there are no infinite derivations, we use multisets. If M and M'
are finite multisets of non-negative integers, then we define M' < M if M' can be
obtained from M by replacing one or more elements in M by any finite number of
non-negative integers, each of which is smaller than one of the replaced elements,
It is shown in [28] that the set of all finite multisets of non-negative integers under
< is a well-founded set.
Now consider the multiset of levels of the predicate
symbols in the literals of the body of a goal G' in an SLDNF-derivation via R
Since P is hierarchical, the child of the goal G' has a smaller multiset than G',
Hence there are no infinite derivations.
Moreover, an induction argument on the levels of predicate symbols shows that
the SLDNF-tree for P u {G} via R does indeed exist.
(b)
Note
that,
by
corollary
14.8,
comp(P)
is
consistent because P is
99
ground negative literal, called the selected literal, in that goal.
§16. Completeness of SLDNF-Resolution
Example Consider the normal program P
r+-p
r +--p
P+-p
Then th 'd'
"
e 1 entlty subStItUtlon E is a correct answer for comp(P) u {+-r}
but E
cannot be computed. (See problem 21.)
,
These examples show that to obtain a completeness result it wI'll be
t
'
,
necessary
o Im:ose rather strong restrictions. We now show that for hierarchical programs
~ere IS ,such a completeness result. Sadly, this result is not very useful because th~
hIerarchIcal condition ban
.
,
s any recursIOn. For the statement of this result, we need
to generalIse the concept of a computation rule.
Chapter 3. Normal Programs
Next, we turn to the question of completeness of SLDNF-resolution.
Example Consider the program
p(x) +-
q(a) +-
r(b) +-
and the goal +-p(x),-q(x). Clearly, x/b is a correct answer
H
th'
can never be
.
owever,
IS answer
computed, nor can any more general version of it.
This simple example clearly illustrates one of the p"oblems
1
•
in obtaining a
comp eteness result for SLDNF-resolution
SLD-
l'
.
reso utIon returns most general
answers. In the above exampI
.
'II
e, It WI
return the identity substimtion ".co
th
subgoal
()
Wh
'"
1
1 r
e
,
. p x .
at we would like is for the negation as failure rule to further
mstantIate x by the binding x/b and th
,
us compute the correct answer.
However
n:~::~ as, failure is o~y a test and cannot make any bindings.
Unless it i~
P
. WIth a goal whIch already is the root of a finitely failed SLD-tree it has
no machmery for further'
t
"
,
bo
ms antlatIng the goal so as to obtain such a tree In the
a
ve example, +-q(x) is not the root of a finitely failed SLD tree
d
'.
fail
h
-
an
negatlon as
ure
as no way to find the appropriate binding x/b.
The next example illustrates another problem I'n obtaining a completeness
result for SLDNF-resolution.
Definition A Sofie co
t t'
I'
,
mpu a Lon ru e IS a functIOn from a set of normal g al
none of which consists entirely of non-ground negative literals, to a set of lit:r:~
such that the value of the function for such a goal is either a positive literal or a

100
Chapter 3. Normal Programs
§16. Completeness of SLDNF-Resolution
101
hierarchical. Let G be the goal f-Ll'...,Ln. The SLDNF-tree for P u {GS} via R
is
not
finitely
failed;
otherwise,
by
theorem
15.4,
we
would
have
that
-(L1A...ALn)S is
a logical
consequence of comp(P),
which
contradicts
the
consistency of comp(P) and the assumption that S is correct.
Hence there exists an SLDNF-refutation for P u {GS} via R. We now modify
the selection of literals in (the top level of) this refutation so that the first part of
the refutation contains goals in which the selected literal is positive and the last
part contains goals in which the selected literal is negative. We can now apply the
argument of lemma 8.2, the fact that S is a ground substitution for all the variables
in G, and the allowedness of P u {G} to obtain an SLDNF-refutation of P u {G}
in which the computed answer is S.
We next apply essentially the argument of lemma 9.1 so that the selection of
literals in (the top level of) this refutation is made using R. Since any subsidiary
finitely failed trees are not modified by these constructions, their literals are still
selected using R. Thus S is an R-computed answer for P u {G}. II
For further discussion and results on completeness the reader is referred to
[95], [97] and [98]. The completeness of the negation as failure rule and SLDNF-
resolution are of such importance that finding more general completeness results is
an urgent priority. The most interesting completeness results would be for classes
of stratified programs, which strictly include the class of hierarchical programs.
Finally, we summarise the main results for definite programs given in this
chapter. First we need one more definition.
The Herbrand rule is as follows: if
comp(p) u {A} has no Herbrand model, then infer -A.
We now have three possible rules for inferring negative information: the CWA,
the Herbrand rule and the negation as failure rule. If P is a definite program, then
we have the following results (see Figure 6):
{AeBp : -A can be inferred under the negation as failure rule} = Bp\TpJ-ro
{AeBp : -A can be inferred under the Herbrand rule} = Bp\gfp(Tp)
{AeBp : -A can be inferred under the CWA} = Bp\Tpiro
Since Tpiro ~ gfp(Tp) ~ TpJ-ro, it follows that the CWA is the most powerful
rule, followed by the Herbrand rule, followed by the negation as failure rule.
Since Tpiro, gfp(Tp) and TpJ-ro are generally distinct (see problem 5, chapter 2),
it follows that the rules are distinct.
-A inferred
under CWA
-A inferred under
negation as failure rule
Fig. 6. Relationship between the various rules

102
Chapter 3. Normal Programs
Problems for Chapter 3
103
We can combine theorem 13.6 with corollaries 15.5 and 16.2.
Theorem 16.4 Let P be
d fi .
a
e mIte program and AEBp. Then the following
are equivalent:
(a) AEFp.
(b) A~TpJ..ro.
(c) A is in the SLD finite failure set.
(d) Every fair SLD-tree for P U {f-A} is finitely failed.
(e) -A is a logical consequence of comp(P).
We can also combine theorems 15.4 and 16.1.
~heorem 16.5 Let P be a definite program and G a definite goal. Then G is
a logIcal consequence of comp(P) iff p u {G} has a finitely failed SLD-tree.
It is also worth emphasising the following facts, which highlight the difference
between (arbitrary) models and Herbrand models for comp(p) and between T J..ro
and gfp(Tp)' Let AEBp. Then we have the following properties:
p
(a) AEgfp(Tp) iff comp(P) U {A} has an Herbrand model.
(b) AETpJ..ro iff comp(P) u {A} has a model.
PROBLEMS FOR CHAPTER 3
1. Let P be a definite program. Show that R! = B \T J..d
f
d>1
P
pp
,or_.
2. Prove lemma 13.2.
3. Prove lemma 13.3.
4: Show that the .converse of proposition 13.4 does not hold.
In fact, show that,
gIVen k, there eXIsts a definite program p and AEBp such that A~TpJ..2 and yet
the depth of every SLD-tree for P u {f-A} is at least k.
5..Let P be a definite program and G a definite goal. Then G is called infinite
(w.Ith respect to P) if every SLD-tree for P u {G} is infinite.
Show that there
eXIsts a program P and AEBp such that f-A is infinite and yet A is in the Success
set of P.
6. Let P be a definite program, AEBp and A not be in the success set of P. Show
that f-A is infinite iff A is not in the SLD finite failure set.
7. Consider the program P
p(x) f- q(y), r(y)
q(h(y» f- q(y)
r(g(y» f-
Find two SLD-trees for P u {f-p(a)}, one of which is infinite and the other
finitely failed.
8. Give an example of a normal program P such that comp(P) is not consistent.
9. Use equality axioms 6 and 8 to show that, in any model of the equality theory,
the relation assigned to = is an equivalence relation.
10. Let P be a normal program and S,tE Up' Prove the following:
(a) s=s is a logical consequence of the equality theory.
(b) If s and t are syntactically different, then s=l=t is a logical consequence of the
equality theory.
(c) The domain of every model for comp(P) contains an isomorphic copy of Up
and the relation assigned to =, when restricted to Up' is the identity relation.
11. Prove proposition 14.2.
12. Show that proposition 14.5 does not hold for normal programs.
13. Prove proposition 14.7.
14. Show that lemma 15.2 (b) does not hold if we drop the phrase "given by the
unification algorithm" from its statement.
15. Show that corollary 15.5 no longer holds if we drop anyone of the equality
axioms 1 to 5 from the definition of comp(P).
16. Show that the safeness condition cannot be dropped from theorem 15.6.

104
Chapter 3. Normal Programs
Problems for Chapter 3
105
17. Consider the nonnal program P
p ~ -q(x)
q(a) ~
Show that -p is not a logical consequence of comp(p).
18. Consider the nonnal program P
p ~-r
r ~ q(x)
q(a) ~
Show that P u {~p} has a finitely failed SLDNF-tree and that _p is a 10 .cal
consequence of comp(P). Th'
gI
IS program looks equivalent to the one in problem 17.
Explain the difference.
Herbrand model (based on the constants and function symbols appearing in the
program).
23. Give an example of a nonnal program P and goal G such that the computation
of P u {G}
produces an infinite nested sequence of negated calls, but the
computation never flounders (in the sense of §15) and never produces an infinite
branch. Prove that, if P is stratified, there can never be an infinite nested sequence
of negated calls.
24. Let P be a nonnal program and G a nonnal goal. Suppose that P u {G} has a
finitely failed SLDNF-tree. Prove that there exists a safe computation rule R such
that P u {G} has a fmitely failed SLDNF-tree via R.
22. Give an example of anal
onn
program whose completion has a model, but no
21. Consider the nonnal program P
r~p
r~ -p
p~p
Show that the ide tit
b"
.
n
y su Stltutlon E IS a correct answer for comp(P) u
{~r}, but
that E cannot be computed.
19. Consider the definite program P
p(f(y»
~ p(y)
q(a) ~ p(y)
and let A be q(a). What is the model for comp(p) u {A} given by th
.
in th
e constructIOn
.
eor~m 16.1 for this program? Show that the domain of this model is
IsomorphIC to Up u Z, where Z is the integers.
20. Consider the nonnal program P
q ~-r
r~p
r~-p
p~p
Show that -q is a logical consequence of comp(P), but that P u
{~q}
have an SLDNF-tree.
does not
25. Let P be a nonnal program and G a nonnal goal. Suppose that P u {G} has a
computed answer 9.
Prove that there exists a safe computation rule R and an R-
computed answer cj> for P u {G} such that Gcj> is a variant of 09.
26. Let P be a nonnal program and G a nonnal goal. Suppose that P u {G} has a
computed answer 9.
Let y be a substitution.
Prove that P u {G9y} has the
identity substitution as a computed answer.
27. Let P be a nonnal program and G a nonnal goal. Suppose that P u {G} has a
finitely failed SLDNF-tree.
Let y be a substitution.
Prove that P u {Oy} has a
finitely failed SLDNF-tree.
28. Let P be a nonnal program and G a ground nonnal goal ~Ll'...,Ln' Suppose
that P u {G} has a finitely failed SLDNF-tree. Prove that there exists ie {l,...,n}
such that P u
{~Li} has a finitely failed SLDNF-tree.
29. Let P be a nonnal program and G a ground nonnal goal ~Ll'...,Ln' Suppose
that P u {G} has an SLDNF-refutation.
Prove that P u
{~Li} has an SLDNF-
refutation, for all ie {l,...,n}.
30. Let P be a nonnal program and G a nonnal goal.
Suppose that P u {G} has
an SLDNF-refutation.
Prove that P u {G}
does not have a finitely failed
SLDNF-tree.

106
Chapter 3. Normal Programs
31.. Let p.be a normal program. Define M = {AeBp : P U {f-A} does not have a
fimtely faIled SLDNF-tree}. Prove that M is a model for P.
Chapter 4
32. Let P be a norm Ia program and G a normal goal. Put p* = P U {-A: AeB
and
~ U {f-A}
has a finitely failed
SLDNF-tree}.
Determine whether
th~
followmg statements are correct or not:
(a) If P U {G} has a finitely failed SLDNF-tree then P U {G} .
.
(b
'IS conSIstent.
) If P U {G} has a finitely failed SLDNF-tree then G l'S
I
. al
of P*.
'
a OglC
consequence
PROGRAMS
37. Let R be any computation rule. Prove that there exists an SLD-den'
t'
. R
wh
O h .
f .
va IOn VIa
1C
IS not aIr.
:~~~ive an example of an infinite SLDNF-derivation which has subsidiary finitely
trees of unbounded rank. (In other words, the derivation does not have rank
k, for any k.)
35. Let P be a stratified no
al
I
.
rm
program and A a ground atom. Suppose that A is
a ogIcal consequence of c
(P)
Le P
.
omp
.
t
* be the definite program obtained from P
by deletmg all negative literals appearing in the bodies of
I.
Pr
.
program causes m P
ove that A IS a logical consequence of P*.
.
34. Let P be anal
.
.
.o~.
program and G a normal goal.
An SLDNF-derivation for
P ~ {~} IS fair If It IS either failed or, for every literal L in (the top level of) th
denvation
(some furth·.
.
e
,
er mstantiated versIOn of) L is selected within a finite
number of steps
An SLDNF tr
£
P
.
of the
...
- ee or
U (G} IS fair if every (top level) branch
th
tree IS a faIr SLDNF-derivation.
Prove the following generalisation of
eorem 16.1:
Let P be a stratified normal program and G a normal goal.
If G is a logical
consequence of comp(P), then every fair SLDNF-tree for P U (G} .
fi'
I
failed.
IS
mIte y
Definition A program statement is a first order formula of the form
Af-W
where A is an atom and W is a (not necessarily closed) first order formula.
The
formula W may be absent. Any variables in A and any free variables in W are
assumed to be universally quantified at the front of the program statement.
A is
called the head of the statement and W is called the body of the statement.
§17. INTRODUCTION TO PROGRAMS
This section introduces programs and goals.
A program is a finite set of
program statements, each of which has the form Af-W, where the head A is an
atom and the body W is an arbitrary first order formula.
Similarly, a goal has the
form f-W, where the body W is an arbitrary first order formula.
We argue that
PROLOG systems should allow the increased expressiveness of programs and
goals as a standard feature. The only requirement for implementing such a feature
is a sound form of the negation as failure rule.
Programs and goals were
introduced by Lloyd and Topor [61]. Special cases of them were studied earlier by
Clark [15] and Kowalski [49].
In this chapter, we study programs and goals. A program is a finite set of
program statements, each of which has the form Af-W, where the head A is an
atom and the body W is an arbitrary first order formula.
Similarly, a goal has the
form f-W, where the body W is an arbitrary first order formula.
We prove the
soundness of the negation as failure rule and SLDNF-resolution for programs and
goals. We also study an error diagnoser, which is declarative in the sense that the
programmer need only know the intended interpretation of an incorrect program to
use the diagnoser.
a
correct
answer
for
normal goal.
Determine
33. Let P be a definite program and G an allowed
Whether the following statement is correct or not:
If
comp(P) U {G}
is
unsatisfiable,
then
there
is
comp(p) U {G}.

108
Chapter 4. Programs
109
§17. Introduction to Programs
Note that a program clause is a program statement for which the body is a
conjunction of literals. TIrroughout, we make the assumption, as we may, that in
each formula each quantifier is followed by a distinct variable and no variable is
both bound and free.
Definition A program is a finite set of program statements.
Definition A goal is a first order formula of the form
(,-W
where W is a (not necessarily closed) first order formula. Any free variables in W
are assumed to be universally quantified at the front of the goal.
Example Consider the program statement
A (,- 'v'x1...'v'xn(3Y1...3YkW(,-W1",...1\Wm)
Often program statements have this form. Typically, W, W1'...,Wm are atoms and
the Yi are absent. For example, the well-ordered predicate can be defined as
follows.
well_ordered(x) (,- 'v'z(has1eastelt(z) (,- set(z) 1\ Zl::X 1\ nonempty(z»
nonempty(z) (,- 3u ue z
hasleastelt(z) (,- 3u (ue z 1\ 'v'v (u:5:v (,- ve z»
x l::Y (,- 'v'z (zey (,- zex)
The increased expressiveness of programs and goals is useful for expert
systems, deductive database systems, and general purpose programming. In expert
systems, it allows the statement of the rules in the knowledge base in a form closer
to a natural language statement, such as would be provided by a human expert.
This
makes
it
easier
to
understand
the
knowledge
base.
This
increased
expressiveness also has an application to deductive database systems, by providing
first order logic (known as domain relational calculus in database terminology
[25]) as a query language in a straightforward manner. (See chapter 5.) In general
purpose programming, applications like the example above occur often. If this
increased expressiveness is not available, it is only possible to express such
statements rather obscurely.
Furthermore, from a theoretical point of view, it makes no sense to stop at
normal programs and normal goals. As we will show in the next section, by means
of simple
transformations
it is
possible to
transform
any
program
to
an
"equivalent" normal program.
By means of this technique, we can extend the
b'trary programs in a straightforward way.
This
theory of normal pro~s alto ar 1
'd s
a
straightforward
implementation
of
~
.
techmque
so
proVl e
trans ormauodn
al
.
any PROLOG system which has a safe implementation of
Programs an
go s 10
"
d
.
.
NU-PROLOG [75], [104] provides thIS 10crease
the negaUon as fallure rule.
expressiveness as a standard feature.
P Thro ghout we assume that =
Next we define the completion of a program.
u
,
does not appear in P.
.
bol
appearing in a program P is
D fi 'tion The del'inition of a predicate sym
P
e 1m
ii'
• h
d
the set of all program statements in P which have p in therr ea.
. .
f
redicate symbol p in a program
Definition Suppose the defimuon 0
an n-ary p
is
Ak (,- Wk
.
Then the completed definition of P IS the formula
""'
""'x
(p(x
... x ) f-4 E1v...vEk)
v Xl'" v
n
1"
n
th
E .
3
3y
«x =t )1\...I\(x =t )1\W.), Ai is p(t1,·..,tn), y1,...,yd are
e
where
i IS
Y1'"
d lIn
n
1
are variables not
. bl
l'n A
and the free variables in Wi' and x1,..·,xn
vana es
i
appearing anywhere in the definition of p.
Example Let the definition of P be
p(y) (,- q(y)1\'v'z(r(y,z)(,-q(z»
p(f(z)) (,- -q(z)
Then the completed definition of P is
'v'x(p(x) f-4 (3y«x=y)l\q(y)1\'v'z(r(y,z)(,-q(z))) v 3z«x=f(z))I\-q(z)))
.
bol P appears in a program P, but
Definition Suppose the n-ary predicate sym
d d 'fi'(
of p
not in the head of any program statement in P. Then the complete
e In! IOn
is the formula
We will also require the equality theory given §14.
. .
P be a
rogram
The completion of P, denoted by comp(P), is
Defimbon Let
p.
.
.
P to ether with the
the collection of completed definitions of predicate symbols 10
g
equality theory.

110
Chapter 4. Programs
111
§17. Introduction to Programs
and I an
Next we introduce the declarative concept of a correct answer for a program
and goal. In this definition, if W is a formula and e is a substitution for some of
the free variables in W, then we is the formula obtained by simultaneously
replacing each
such
variable
by
its
binding in
e.
For example, if W
is
'v'x3y(p(z,f(x»f-q(y»
and e is {z/g(w)}, then we is 'v'x3y(P(g(w),f(x»f-q(y».
Note that it may be necessary to rename some bound variables in W before
applying e to avoid clashes with the variables in the terms of the bindings of e.
Definition Let P be a program and G a goal f-W.
An answer for P u {G} is
a substitution for free variables in W.
Definition Let P be a program and G a goal f-W.
A correct answer for
comp(P) u {G} is an answer e such that 'v'(We) is a logical consequence of
comp(P).
This definition, which generalises the previous definition of correct answer (see
§14), provides the appropriate declarative description of the output from a program
and goal.
We now investigate under what conditions the completion of a program will be
consistent. In a way similar to that in chapter 3, the concept of a stratified program
gives a satisfactory answer to this question.
Definition A level mapping of a program is a mapping from its set of
predicate symbols to the non-negative integers. We refer to the value of a predicate
symbol under this mapping as the level of that predicate symbol.
Definition A program is hierarchical if it has a level mapping such that, in
every program statement p(t1,...,tn) f- W, the level of every predicate symbol in
W is less than the level of p.
Definition A program is stratified if it has a level mapping such that, in every
program statement p(t1,...,tn) f- W, the level of the predicate symbol of every
atom occurring positively in W is less than or equal to the level of p, and the level
of the predicate symbol of every atom occurring negatively in W is less than the
level of p.
This definition generalises the definition of stratified normal programs given in
§14.
We can assume without loss of generality that the levels of a stratified
program are O,I,...,k, for some k.
Note that, at level 0, all atoms in the bodies of
..
I
but that these program statements need
program statements must occur pOSitiVe y,
not be definite program clauses.
Next we extend the definition of the mapping ~ to arbitrary programs.
.
P and I an interpretation
Definition Let J be a pre-interpretatiOn of a program
.
_T (I) _ { A
: Af-W E P, V is a variable aSSignment wrt J,
based on J. Then 1'p -
J,V
and W is true wrt I and V}.
J a pre-interpretation of P,
Proposition 17.1 Let P be a program,
._T
.
.
b
ed on J
Then I is a model for P iff 1'p(I) ~ I.
mterpretation
as
.
Proof Similar to the proof of proposition 6.4. II
Propo~ition 17.2 Let P be a P:o:~/ t:g~:~~;t:~:t:~:n i::n:~ya:~l~ti::
interpretation based on J. Suppos
h
·th the identity
.
ed to -
i'S a model for the equality theory. Then I, toget er Wi
aSSign
-,
. T!
-
relation assigned to =, is a model for comp(P) iff
p(I) - 1.
Proof Similar to the proof of proposition 14.3. II
d J
pre interpretation for P.
Proposition 17.3 Let P be a stratified program an
~T
-
.
h
I
I 0
Then 1';. is monotolllC over t e
(a)
Suppose P has only predicates of eve.
P
lattice of interpretations based on J.
d
th
set of
P has maximum predicate level k+1.
Let Pk
enote
e
(b) Suppose
.
P with the property that the predicate symbol in the head of
Program statements m
.
d
J f
h
M
is an interpretatiOn base
on
or
the statement has level ::;; k.
Suppose t at
k
{(d
d)' p is a
_1
Th
A - {M uS' S c
P
1"'"
n .
P
and M
is a fixpoint of 1'p '
en
-
k
'-
k
k
k.
in the domain of J} } is a complete
level k+1 predicate symbol and each di is A .s a sublattice of the lattice of
lattice,
u~der setedinclu;ion'
d
~rt~::::~ to~, is well-defined and monotonic.
interpretations bas
on, an
P'
Proof Straightforward. (See problem 1.) II
Then comp(P) has a minimal
Corollary 17.4 Let P be a stratified program.
normal Herbrand model.
Proof Similar to the proof of corollary 14.8. II
LI
d S
enberg and Topor [60].
The results of this section are due to
oy,
on

112
Chapter 4. Programs
§18. SLDNF-Resolution for Programs
113
(c) Replace A f- W1A
AWi_1A-'v'x1..·'v'xnWAWi+1A
AWm
by
A f- W1A
AWi_1A3x1·..3xn-WAWi+1A
AWm
(b) Replace A f- W1A
AWi_1A'v'x1..·'v'xnWAWi+1A...AWm
by
A f- W 1A
AWi_1A-3x1..·3xn-WAWi+1A...AWm
§18. SLDNF-RESOLUTION FOR PROGRAMS
In this section, we prove the soundness of the negation as failure rule and
SLDNF-resolution for programs and goals. We also give a completeness result for
hierarchical programs.
The soundness results are proved by fIrst transforming a
program and goal into a normal program and normal goal.
We then use the fact
that the negation as failure rule and SLDNF-resolution are known to be sound in
this case (theorems 15.4 and 15.6). This transformation technique can be used to
give a straightforward implementation of programs and goals.
(a) Replace
by
and
A f- W1A
AWi_1A-(VAW)AWi+1A...AWm
A f- W1A
AWi_1A-VAWi+1A
AWm
A f- W 1A
AWi_1A-WAWi+1A
AWm
(h) Replace A f- W1A
AWi_1A-WAWi+1A...AWm
by
A f- W1A
AWi_1AWAWi+1A...AWm
(g) Replace A f- W1A
AWi_1A-(VVW)AWi+1A
AWm
by
A f- W1A
AWi_1A-VA-WAWi+1A
AWm
(e) Replace A f- W1A
AWi_1A-(Vf-W)AWi+1A...AWm
by
A f- W1A
AWi_1AWA-VAWi+1A...AWm
A f- W1A
AWi_1A(VvW)AWi+1A...AWm
A f- W 1A AWi_lAVAWi+1A AWm
A f- W1A
AWi_1AWAWi+1A
AWm
A f- W 1A
AWi_1A(Vf-W)AWi+1A...AWm
A f- W1A
AWi_1AVAWi+1A...AWm
A f- W1A
AWi_1A-WAWi+1A...AWm
(f) Replace
by
and
(i) Replace A f- W1A
AWi_1A3x1·..3xnWAWi+1A...AWm
by
A f- W1A
AWi_1AWAWi+1A...AWm
(d) Replace
by
and
Proof Note that in the presence of equality axioms 6, 7, and 8
'v'zl..·'v'zn (answer(zl,...,zn) H 3x1..·3xn«zl=x1)A...A(zn=xn)AW»
is logically equivalent to
'v'x1...'v'xn (answer(x1,..·,xn)HW)
Hence we can assume that comp(P') is simply comp(P) together with the latter
formula (and an equality axiom 8 for the predicate symbol answer).
Both parts of
the lemma now follow easily from this. II
The next step is to transform a program P into a normal program P', called a
normal form of P, by means of the following transformations.
Lemma 18.1 Let P be a program, G a goal, and 8 an answer. Assume G has
the form f-W, where W has free variables x1'...,x
and answer is an n-ary
n
'
predicate symbol not appearing in P or G. Then we have the following properties.
(a) G is a logical consequence of comp(P) iff f-answer(x1,...,xn) is a logical
consequence of comp(p'), where p' is P u {answer(xl'...,xn)f-W}.
(b) 'v'(W8) is a logical consequence of comp(P) iff 'v'(answer(x1,...,xn)8) is a
logical consequence of comp(P').
The fIrst lemma justifIes the transformation of a goal to a normal goal.
Suppose P is a program and G is a goal. Let G have the form f-W, where W has
free variables xl'''''xn, Suppose answer is an n-ary predicate symbol not appearing
in P or G. The transformation replaces G by the normal goal
f- answer(x1,...,xn)
and adds the program statement
answer(x1,...,xn) f- W
to the program P.

114
Chapter 4. Programs
115
§18. SLDNF-Resolution for Programs
Note that, from a logical viewpoint, the various transfonnations for negation
cou~d be replaced by a single all-encompassing transfonnation for negation similar
to (j). However, the transfonnations for negation have been presented as above to
try to overcome the limitations of the negation as failure rule
F
I
.
.
or examp e,
WIthout (h), a subgoal of the fonn --A can flounder if A contains any variables
This problem disappears once the subgoal is transfonned to A.
Similar problem~
are overcome by (a), (c), (e), and (g).
Example Consider the program statement
A ~ V'xl",V'xn(3Yl...3YkW~WIA ...AWm)
If ul'...,us are the free variables in the body and wl'...,wd are the free variables in
3y1...3YkW, then the above program statement can be transformed to
A ~ -p(ul'...,us)
p(u1,···,us) ~ W1A...AWmA-q(wl ,···,wd)
q(wl""'wd) ~ W
Example The subset predicate (k) can be defined by the program statement
xQ ~ V'u(uey ~ uex)
A normal form of this program statement is
xQ ~ -p(x,y)
p(x,y) ~ -(uey) A uex
We apply transformations (a),...,(j) until no more such transformations are
possible.
The proposition below shows that this process terminates after a finite
~umber of steps and that the resulting nonnal fonn of the original program is
mdeed a nonnal program. Of course, the normal fonn is not unique.
Proposition 18.2 Let P be a program. Then the process of continually applying
~ansfonnations (a),...,O) to P terminates after a finite number of steps and results
m a normal program (called a normal form of P).
Proof If M and M' are finite multisets of non-negative integers then we define
M'
.
'
< M as m the proof of theorem 16.3. The basic idea of the proof is to define a
tennination function Il from programs into the well-founded set of all finite
multisets of non-negative integers under <.
Inductively define the mapping Il as follows:
Il(atom) = 1
Il(VAW) = Il(V) + 1l(W)
Il(-W) = 1l(3xW) = 1l(W) + 1
Il(V~W) = Il(V) + 1l(W) + 1
Il(VvW) = 1l(V) + 1l(W) + 2
1l(V'xW) = 1l(W) + 4
Il(program P) =
{J.i(W): A~W is a statement in P},
where {...} denotes a multiset.
It now suffices to remark that if Q' is obtained
from a program Q by a single transfonnation (a) or ... or 0), then Il(Q') < 1l(Q), so
the process terminates.
Furthermore, the resulting program is a normal program
since, otherwise, some further transformation would be possible. II
Lemma 18.3 Let P be a program and let Q be the program which results from
a single transformation (a) or .., or (i). Then P and Q are logically equivalent and
also comp(p) and comp(Q) are logically equivalent.
Proof Straightforward. (See problem 3.) II
The corresponding result for transfonnation (j) is more complicated, as the
following lemma shows.
Lemma 18.4 Let P be a program and p' a nonnal form of P. If U is a closed
formula which is a logical consequence of comp(P') and U only contains predicate
symbols which appear in P, then U is a logical consequence of comp(P).
Proof It follows from lemma 18.3 that we only have to prove the lemma for a
single application of transformation (j).
Suppose that P contains the program
statement
A~WlA...AWi_lA-WAWi+1A...AWm
and we apply transformation (j) to obtain
A~WlA...AWi_lA-P(xl'...,xn)AWi+lA...AWm
p(xl'
,xn)~W
where xl'
,x
n
are the free variables of Wand W has the form 3Yl···3YkV,. Let Q
be the program obtained from P
by replacing the
statement to whIch the
transformation was applied by these two statements.
Now comp(Q) contains the fonnula
V'zr"V'zn (p(zl'""zn) H
3xr ..3xn((zl=xl)A...A(zn=xn)AW))
As in the proof of lemma 18.1, we can assume that the latter formula is replaced in
comp(Q) by the formula

116
Chapter 4. Programs
§18, SLDNF-Resolution for Programs
117
It follows eas'l
fr
th'
1 Y
om
IS that if U is a closed formula which is a logical
consequence of comp(Q) and U contains only predicate symbols which
.
P thnU'
I
.
appear In
,
e
IS a oglCal consequence of comp(p).
IIlI
Now we are in a position to define computed answers for programs and goal
and to show that computed answers are correct.
s,
Definition Let P be a program
d G
an
a goal f-W, where W has free variables
xl'''''xn,
~ no.rmal form of P U {G} is a normal program and goal p' U {G'}
where
G
IS
f-ans
(
) '
'
~er x1"",xn
and
P
is
a
normal
form
of
P u {answer(xl'...,xn)f-W}.
Definition Let P be a program and G a goal.
An SWNF-derivation of P u {G} is an SLDNF d'
.
,
,
- envatlOn of p' u {G'},
where P u {G} is a normal form of P U {G}.
,
An ~U:NF-refutation of P U {G} is an SLDNF-refutation of p' U {G'}, where
P U {G} IS a normal form of P U {G}.
,
A c~m~uted answer for P U {G} is a computed answer for p' U {G'}, where
P U {G} IS a normal form of P U {G}.
An SWNF-tree
for
P U {G}
is
an
SLDNF-tree
for
p' U {G'}
where
p' U {G'} is a normal form of P U {G}.
'
A finitely failed SWNF-tree for P U {G} is a finitely failed SLDNF
&
p' U {G'}
h
p'
,
-tree ~or
, were
U {G} is a normal form of P u.{G}.
It is straightforward to sh
th
th
bo
' ,
.
,
ow
at
eave defimtIons essentially extend those
glVen In chapter 3 for normal programs and normal goals. (See problem 4.)
We now consider the problem of computations floundering.
Let P be
program and G a goal. By a computation of P U {G}
a
, we mean an attempt to
construct an SLDNF-derivation of p' U {G'}, where p' U {G'} .
P U {G}.
IS a normal form of
Definition Let P be a program and G a
al
W
'
P
,
go.
e say a computatton of
U
~G} flounders If at some point in the computation a goal is reached which
contaIns only non-ground negative literals.
Definition Let P be a program and G
al
a go . We say that P U {G} is allowed
if some normal form of P U {G} is allowed.
It is straightforward to show that if one normal form of P U {G} is allowed,
then every normal form of P U {G} is allowed. (See problem 5.)
Proposition 18.5 Let P be a program and G a goal f-W.
Suppose that
P U {G} is allowed. Then we have the following properties.
(a) No computation of P U {G} flounders.
(b) Every computed answer for P U {G} is a ground substitution for all free
variables in W.
Proof The proposition follows immediately from proposition 15.1. II
We now prove the soundness of the negation as failure rule and SLDNF-
resolution.
Theorem 18.6 (Soundness of the Negation as Failure Rule)
Let P be a program and G a goal. If P U {G} has a finitely failed SLDNF-
tree, then G is a logical consequence of comp(p).
Proof Note first that the result is known to hold when P is a normal program
and G is a normal goal (theorem 15.4). Suppose G is the goal (-W, where W has
free variables xl""'xn, Let p" be P U {answer(xl'...,xn)f-W}. Suppose P U {G}
has a finitely failed SLDNF-tree. By definition, p' U {G'} has a finitely failed
SLDNF-tree, where G' is (-answer(x1,...,xn) and p' is a normal form of P". Thus,
G' is a logical consequence of comp(P').
By lemma 18.4, G' is a logical
consequence of comp(p
lI
). Thus, by lemma 18.1(a), G is a logical consequence of
comp(p).
IIlI
Theorem 18.7 (Soundness of SLDNF-Resolution)
Let P be a program and G a goal. Then every computed answer for P U (G}
is a correct answer for comp(p) U {G}.
Proof Note first that the result is known to hold when P is a normal program
and G is a normal goal (theorem 15.6). Suppose G is the goal (-W, where W has
free variables xl'''''xn,
Let P"
be P U {answer(x1,...,xn)f-W}
and 0 be a
computed answer for P U {G}. By definition, 0 is a computed answer for
p' U {G'}, where G' is (-answer(xl'''''xn) and p' is a normal form of P". Hence, 0
is a correct answer for comp(p') U {G'}. By lemma 18.4, V(answer(x1,...,xn)O) is a
logical consequence of comp(P").
Thus, by lemma 18.1(b), V(WO) is a logical
consequence of comp(P). That is, 0 is a correct answer for comp(p) U {G}. II

118
Chapter 4. Programs
§19. Declarative Error Diagnosis
119
Theorems 18.6 and 18.7 are due to Lloyd and Topor [61].
Next, we shall prove a completeness result for hierarchical programs, which
extends theorem 16.3.
Lemma 18.8 Let P be a program and p' anormal form of P. Then comp(P) is
a logical consequence of comp(P').
~rOOf By lemma 18.3, we only have to prove the lemma when p' is a program
obtaI~ed from P by a single application of transformation (j).
Suppose that P
contaIns the program statement
A~W1/\···/\W. l/\-W/\W,
/\
/\W
1-
1+1'"
m
and we apply transformation (j) to obtain
A~W1/\"'/\W. 1/\-P(x1 ... x )/\W.
/\
/\W
1-
, , n
1+1'"
m
P(x1,..·,xn)~W
where x1,·..,xn are the free variables in W and W has the form 3y ...3y V. Let p'
be the
pr~gram obtained from P by replacing the statement1 to ~hich the
transformauon was applied by these two statements.
Now comp(P') contains the formula
.
'v'zl'" 'v'zn (p(zl'""zn) ~ 3x1..·3x «zl=x1)A.../\(z =x )/\W))
USIng equality ax'
6 7
d 8
n
n
n
.
,
loms,
an
, we can assume that the latter formula is replaced
In comp(P ) by the formula
'v'x1..·'v'xn(p(xl""'x )~W)
It follows easily from this that comp(P) is a log~al consequence of comp(P'). I
If P is a program and p' is a normal form of P, then it follows from lemmas
18.4 and 18.8 that comp(P') is a conservative extension [99] of comp(P).
Definition Let P be a progr
G
al
am,
a go , and R a safe computation rule.
.
~ SLDNF-deriva~ion of P U {G} via R is an SLDNF-derivation of P U {G}
In WhICh the computauon rule R is used to select literals.
An SLDNF-tree for P U {G} via R is an SLDNF-tree for P U {G} in which
the computation rule R is used to select literals.
.
A~ SLDNF-rejutation of P U {G} via R is an SLDNF-refutation of P U {G}
In WhICh the computation rule R is used to select literals.
An R-computed answer for P U {G} is a computed answer for P U {G} which
has come from an SLDNF-refutation of P U {G} via R.
Theorem 18.9 (Completeness of SLDNF-Resolution for Hierarchical Programs)
Let P be a hierarchical program, G a goal ~W, and R a safe computation rule.
Suppose that P U {G} is allowed. Then the following properties hold.
(a) For every normal form of P U {G}, the corresponding SLDNF-tree for
P u {G} via R exists and is finite.
(b) If e is a correct answer for comp(p) u {G} and e is a ground substitution for
all free variables in W, then e is an R-computed answer for P u {G}.
Proof (a) Let p' u {G'} be a normal form of P u {G}. Then p' is hierarchical
(see problem 8) and part (a) follows from theorem 16.3(a).
(b)
Since e
is a correct answer for comp(P) U {G}
that is a ground
substitution for all free variables in W, we have that we is a logical consequence
of comp(P).
By lemma 18.1(b), answer(xl'...,xn)e is a logical consequence of
comp(p u
(answer(xl'".,xn)~W}), By lemma 18.8, answer(xl'".,xn)e is a logical
consequence of comp(P'). The result now follows from theorem 16.3(b). I
§19. DECLARATIVE ERROR DIAGNOSIS
This section presents an error diagnoser which finds errors in programs that
use advanced control facilities
and the increased expressiveness of program
statements. The diagnoser is declarative, in the sense that the programmer need
only know the intended interpretation of an incorrect program to use the diagnoser.
In particular, the programmer needs no understanding whatever of the underlying
comp~tational behaviour of the PROLOG system which runs the program.
It is
argued that declarative error diagnosers will be indispensable components of
advanced logic programming systems, which are currently under development.
The results of this section are due to Lloyd [59].
One of the greatest strengths of logic programming is its declarative nature. To
a large extent, programmers need only concern themselves with a declarative
understanding of their programs, leaving much of the procedural aspect to the logic
programming system itself.
However, the ideal of purely declarative programming is still far from being
achieved. Current research aimed at attaining this ideal is proceeding on a number
of fronts. For example, some PROLOG systems have advanced control facilities to
overcome the severe limitations of the standard left to right computation rule (e.g.,

120
Chapter 4. Programs
§19. Declarative Error Diagnosis
121
[73], [74]). Improved fonns of negation are being introduced (e.g., [75], [104]).
There has been work on program transfonnation, which allows programmers to
write programs in a fonn closer to their specification (e.g., [101] and the references
therein).
The advanced logic programming systems, which will become available in the
near future, will be compiler systems exploiting all the above techniques.
Source
programs for these systems
will be written in a subset of fIrst order logic. This
subset will include at least the class of programs defIned in this chapter.
In the
first stage of compilation, source programs will be transformed into assembly
programs by the automatic addition of control infonnation and the application of
various transformation techniques.
These assembly language programs will be
similar to PROLOG programs as they are currently written for a coroutining
system.
In the second·stage of compilation, the assembly program will be further
compiled into a machine program, which can then be run on a coroutining version
of Warren's abstract PROLOG machine [110].
This second compilation stage is
now well understood. Note that, according to the above view, current versions of
PROLOG, which are now regarded as high level languages, will eventually be
regarded as low level machine languages.
Such systems will allow programmers to write in a more declarative style than
is currently possible and should ensure a great decrease in programmer effort.
However, there is a catch. The compiled program could be so different from the
source program and the control could be so complicated that debugging such
programs by conventional tracing techniques is likely to be extraordinarily diffIcult.
In other words, the programmer may only require an understanding of the intended
interpretation to write the program, but will need to know everything about the
computational behaviour of the system to debug the program! In fact, this problem
in a less extreme form also plagues current PROLOG systems.
For this reason, we argue that an indispensable component of future logic
programming systems will be a declarative debugging system, that is, one that can
be used without the need to understand the computational behaviour of the system.
The main purpose of this section is to present a declarative error diagnoser which
fInds errors in programs that use advanced control facilities and the increased
expressiveness of program statements.
Attention is confIned to errors which lead
to a wrong or missing solution.
In particular, errors which lead to infInite loops
are not discussed here.
Declarative error diagnosis was introduced into logic programming, under the
name algorithmic debugging, by Shapiro [92].
As well as an error diagnoser, he
also presented an error corrector (regarded as a kind of inductive program
synthesiser). Shapiro was mainly concerned with defInite programs using
~e
standard computation rule.
Av-Ron [6] studied top-down diagnosers for defImte
programs. Under the name rational debugging, Pereira [81] presented a diagnoser
for
arbitrary
PROLOG
programs,
including
the
non-declarative
features
of
PROLOG, such as cut. More recently, Ferrand [34] gave a mathematical analysis
of an error diagnoser for defInite programs.
Other work on debugging (not
necessarily declarative) is contained in [12],
[30],
[31], [32], [83]
and the
references therein.
We now give the defInitions of the concepts necessary for a foundation for
error diagnosis.
Definition Let P be a program. An intended interpretation for P is a nonnal
Herbrand interpretation for comp(P).
The restriction to Herbrand interpretations is not essential. However, in
practice, intended interpretations are usually Herbrand and the analysis is a li~tle
easier in this case. The foremost aim of a programmer is to write programs WhICh
have their intended interpretations as models.
This leads to the following
defInition.
Definition Let P be a program and I an intended interpretation for P. We say P
is correct wrt I if I is a model for comp(p); otherwise, we say that P is incorrect
wrtI.
Of course, the reason we want P to be correct wrt I is so that all answers
computed by P will be true wrt I.
Proposition 19.1
Let P be a program, G a goal ~W, and e a comput~d
answer for P u {G}. Let I be an intended interpretation for P and suppose that P IS
correct wrt I. Then we is valid in I.
Proof The result follows immediately from the soundness of SLDNF-resolution
(theorem 18.7), since I is a model for comp(P).
iii
However, even if P is correct wrt I, we cannot guarantee that P will compute
everything in I.

122
Chapter 4. Programs
123
§19. Declarative Error Diagnosis
Exa~Ple Suppose that P is a definite program such that lfp(T ) '# gfp(T ).'
Then P IS correct wrt gfp(T ) t
th
·th th"
P
P
P' oge er WI
e Idenuty relation assigned to =, but
P does not compute all atoms in gfp(Tp).
tha I~ ~th~r words, even .if p. is correctwrt I, P may still have a bug in the sense
t It. IS Incomplete. ThIS kind of bug is not detectable by the error diagnoser.
What It can detect is when P is incorrect wrt I.
An
erro~ in a program usually shows up because the program gives a wrong
answer or m1sse~ .an answer (more precisely, finitely fails when it should succeed).
The next proposlUon formalises this.
.
Proposition 19.2 Let P be a program, G a goal f-W, and I an intended
Interpretation for P.
(a) If e is a computed answer for P u {G} and we is not valid in I th
p'
.
'
en
IS
Incorrect wrt I.
~b) If P u {G} has a finitely failed SLDNF-tree and W is satisfiable in I, then P is
Incorrect wrt I.
Proof Part (a) follows directly from the soundness of SLDNF-resolution
(~eorem 18.7) and part (b) follows directly from the soundness of the negation as
faIlure rule (theorem 18.6). I
Now we define the two kinds of errors which the diagnoser can detect.
Definition Let P be a pro
d I'
.
.
gram an
an Intended Interpretauon for P. Let A be
:m atom with predicate symbol p. We say that A is an uncovered atom for P wrt I
If A'
al'd'
IS v
1
In I and, for every program statement A'f-W in the definition of p
such that A
d A'
'f
. h
an
um y WIt
mgu e, say, we have that we is unsatisfiable in I.
.Definition Let P be a program and I an intended interpretation for P. We say
an Instance Af-W of a program
t
. p'
.
s atement In
IS an zncorrect statement instance
for P wrt I if A is unsatisfiable in I and W is valid in I.
In case the pro
statement is a program cla
11 h
.
gram
.
use, we ca
t e Incorrect statement instance an incorrect
clause znstance.
N~te that every instance of an uncovered atom is uncovered and every instance
of an Incorrect statement instance is incorrect.
The next result gives the connection between the concepts of incorrect
program, uncovered atom, and incorrect statement instance.
Proposition 19.3 Let P be a program and I an intended interpretation for P.
Then P is incorrect wrt I iff there is an uncovered atom for P wrt I or there is an
incorrect statement instance for P wrt I.
Proof Suppose that there is an incorrect statement instance (in the definition of
p) for P wrt I. It is easy to see that I does not satisfy the if part
'itxl,,:vxn (P(xl'''''xn) f- E1v...vEk)
of the completed definition of p and hence that P is incorrect wrt I. Next suppose
that there is an uncovered atom P(sl,...,sn) for P wrt I. If there is no definition for
p, then it follows immediately that P is incorrect wrt I. Otherwise, I does not
satisfy the only if part
'itx1...'itxn (P(xl,...,xn) ~ E1v...vEk)
of the completed definition of p and hence P is incorrect wrt I.
Now suppose that P is incorrect wrt I.
Note that any normal Herbrand
interpretation for comp(P) is a model for the equality theory of comp(P) and thus I
can not be a model for the remainder.of comp(P). If I does not satisfy a completed
definition of the form
'itx1..·'itxn -p(xl""'xn)
then there is an uncovered atom. If I does not satisfy the only if part
'itxl...'itxn (P(xl'''''xn) ~ E1v...vEk)
of a completed definition, then there is an uncovered atom. Finally, if I does not
satisfy the if part
'itx1...'itxn (P(x1,...,xn) f- Elv...vEk)
of a completed definition, then there is an incorrect statement instance. I
Propositions 19.2 and 19.3 together show that if a program gives a wrong
answer or misses an answer, then there is an uncovered atom or an incorrect
statement instance. We now present a diagnoser which detects these errors.
The definitions below are those of the main predicates, wrong and missing.
The definitions of the predicates valid, unsatisfiable and clause need to be added.
If W is a formula, we let W' denote its image, which is a ground term, under the
representation scheme used by the diagnoser. This scheme uses "and" for
conjunction, "or" for disjunction, "not" for negation, "if' for implication,
"all(x',W')" for 'itxW, and "some(x',W')" for 3xW.

124
Chapter 4. Programs
§19. Declarative Error Diagnosis
125
Declarative Error Diagnoser
wrong(all(v, w), x) f- wrong(w, x)
wrong(some(v, w), x) f- wrong(w, x)
wrong(v if w, x) f- wrong(v, x)
wrong(v if w, x) f- missing(w, x)
wrong(v or w, x) f- wrong(v, x)
wrong(v or w, x) f- wrong(w, x)
wrong(not w, x) f- missing(w, x)
wrong(v and w, x) f- wrong(v, x)
wrong(v and w, x) f- wrong(w, x)
wrong(x, z) f- clause(x, xl if y) 1\ wrong(y, z)
wrong(x, xl if y) f- unsatisfiable(x, xl) 1\ clause(x, xl if y) 1\ valid(y, y)
missing(all(v, w), x) f- missing(w, x)
missing(some(v, w), x) f- missing(w, x)
missing(v if w, x) f- missing(v, x)
missing(v if w, x) f- wrong(w, x)
missing(v or w, x) f- missing(v, x)
missing(v or w, x) f- missing(w, x)
missing(not w, x) f- wrong(w, x)
missing(v and w, x) f- missing(v, x)
missing(v and w, x) f- missing(w, x)
missing(x, z) f- clause(x, xl if y) 1\ missing(y, z)
missing(x, xl) f- valid(x, xl) 1\ V'y(3x2clause(xl, x2 if y) -+ unsatisfiable(y, y»
The first argument of wrong is a goal (body).
The second argument is an
uncovered atom or incorrect statement instance returned by the diagnoser.
An
incorrect statement instance is actually found using the last statement of the
definition of wrong. The first argument of missing is a goal (body). Similarly, the
second argument is an uncovered atom or incorrect statement instance returned by
the diagnoser.
An uncovered atom is actually found using the last statement of the
definition of missing.
The definition of clause contains all facts of the form clause(A', B' if W')f-,
where A is an atom, B is an instance of A and Bf-W is an instance of a program
statement.
The definition of valid contains all facts of the form valid(W', Y')f-,
where W is a formula and Y is an instance of W valid in I.
The definition of
unsatisfiable contains all facts of the form unsatisfiable(W', Y')f-, where W is a
formula and Y is an instance of W unsatisfiable in 1
What we have presented above is the purely declarative part of the diagnoser.
It is important to isolate this declarative component, as we have done, for two
reasons. First, it clarifies the theoretical developments.
One can prove the
soundness and completeness of the diagnoser without the complication of coping
with some particular control component.
Second, it makes the challenge of
building practical error diagnosers clearer. This challenge is to find a sufficiently
clever control component to add to the above declarative component. Later we
show one way of adding this control.
The last four statements in the definition of wrong and the last four statements
in the definition of missing could be used together as a diagnoser for definite
programs. This diagnoser can be compared directly with the diagnosers of Shapiro
[92], Av-Ron [6] and Ferrand [34] for definite programs.
Later we compare
Shapiro's single-stepping and divide-and-query algorithms for diagnosing incorrect
answers with a top-down version of the diagnoser.
The main difference between
the diagnoser and Ferrand's is that we have dispensed with the statements in his
diagnoser which are concerned with returning the result that the error is undefined.
The seventh statement in the definition of wrong and the seventh statement in
the definition of missing together handle negated calls. These statements come
from [92], where they are attributed to McCabe. Their motivation is as follows. If
the negation of a goal has incorrectly succeeded (resp., incorrectly failed), then the
goal must have incorrectly failed (resp., incorrectly succeeded). The remainder of
the statements in the definitions handle the other connectives and quantifiers.
As
an example, we give the motivation for the statements for implication in the
definition of wrong: if the goal v if w has returned a wrong answer, then either v
has returned a wrong answer or w has missed an answer.
We now show a method for adding control information to obtain a more
practical declarative error diagnoser.
The idea is to ensure that the following
conditions are satisfied. In every call to wrong, the first argument is unsatisfiable.
Similarly, in every call to missing, the first argument is valid.
For this purpose,
we make sure that a top level call to wrong has its first argument unsatisfiable and
a top level call to missing has its first argument valid. Furthermore, we add calls to
valid and unsatisfiable to ensure that subsequent calls to wrong and missing satisfy

126
Chapter 4. Programs
§19. Declarative Error Diagnosis
127
the above conditions. (See problem 13.)
We also add calls to succeed and fail.
The definition of succeed contains all
facts of the form succeed(W', (We)')f-, where W is a formula and e is a computed
answer for P U {f-W}. The definition of fail contains all facts of the form
fail(W')f-, where W is a formula and P U {f-W} has a finitely failed SLDNF-
tree. These additional calls are used as heuristics to guide the search for an error.
We call this the top-down version of the diagnoser. For definite programs, the top-
down diagnoser for wrong answers was given by Av-Ron [6].
A different top-
down diagnoser for missing answers for definite programs was also given in [6].
Top-Down Version of the Declarative Error Diagnoser
wrong(all(v, w), x) f- unsatisfiable(w, WI) /\ wrong(wl , x)
wrong(some(v, w), x) f- wrong(w, x)
wrong(v if w, x) f- succeed(v, VI) /\ wrong(vl , x)
wrong(v if w, x) f- fail(w) /\ missing(w, x)
wrong(v or w, x) f- succeed(v, VI) /\ wrong(vl , x)
wrong(v or w, x) f- succeed(w, WI) /\ wrong(wl , x)
wrong(not w, x) f- missing(w, x)
wrong(v and w, x) f- unsatisfiable(v, VI) /\ wrong(vl , x)
wrong(v and w, x) f- unsatisfiable(w, wI) /\ wrong(wl' x)
wrong(x, z) f- clause(x, Xl if y) /\ succeed(y, y) /\ unsatisfiable(y, y) /\ wrong(y, z)
wrong(x, Xl if y) f- unsatisfiable(x, Xl) /\ clause(x, Xl if y) /\ valid(y, y)
missing(all(v, w), x) f- missing(w, x)
missing(some(v, w), x) f- valid(w, WI) /\ missing(wl , x)
missing(v if w, x) f- valid(v, VI) /\ missing(vl , x)
missing(v if w, x) f- unsatisfiable(w, WI) /\ wrong(wl , x)
missing(v or w, x) f- valid(v, VI) /\ missing(vl , x)
missing(v or w, x) f- valid(w, WI) /\ missing(wl , x)
missing(not w, x) f- wrong(w, x)
missing(v and w, x) f- fail(v) /\ missing(v, x)
missing(v and w, x) f- fail(w) /\ missing(w, x)
missing(x, z) f- clause(x, Xl if y) /\ fail(y) /\ valid(y, y) /\ missing(y, z)
missing(x, Xl) f- valid(x, Xl) /\ V'y(3x2clause(xl , x2 if y) ~ unsatisfiable(y, y»
Example Consider the following (incorrect) subset program in which sets are
represented by lists.
subset(x,y) f- V'z (member(z,y) f- member(z,x»
member(x,x.y) f-
member(x,y.z) f- member(y,z)
The goal f-subset(2.nil, 1.2.nil) incorrectly fails. The top-down algorithm produces
the following computation (in which some intermediate goals are not shown).
f- missing(subset(2.nil, 1.2.nil), x)
f- missing(all(z', member(z', 1.2.nil) if member(z', 2.nil», x)
f- missing(member(z', l.2.nil) if member(z', 2.nil), x)
f- missing(member(2, 1.2.nil), x)
o
The computed answer is x/member(2, 1.2.nil), that is, member(2, 1.2.nil) is an
uncovered atom.
The implementation of the top-down algorithm in MU-PROLOG and examp:es
of its use are given in [59].
(For examples of the use of various other declarauve
error diagnosers,
the reader should consult [6],
[34],
[81]
and
[92].)
~e
implementations of valid and unsatisfiable rely on an oracle to answer quesuons
abOut the intendedinterpretation. In practice, the oracle is usually the programmer.
Answers from the oracle are recorded so that the oracle is never asked the same
question twice. Also complex formulas are broken down so that the oracle is only
ever questioned about the validity of atoms.
Example For the previous example, the implementation in [59] of the top-
down algorithm produces the following sequence of oracle queries.
subset(2.nil, 1.2.nil) valid?
member(z,2.nil) valid?
z=2.
member(2, 1.2.nil) valid?
The following atoms are known to be valid:
member(2,2.nil)
member(z,2.nil) valid for other values? n
member(1,2.nil) valid? n
at which point the uncovered atom member(2, 1.2.nil) is printed. A return after the
? indicates yes, while an n followed by a return indicates no. The value z=2 was
given by the oracle after a prompt with the variable name.

128
Chapter 4. Programs
§19. Declarative Error Diagnosis
129
Note that, by means of the metacalls, succeed and fail, the top-down algorithm
has decoupled the diagnosis of the program from
whatever transformation,
compilation or advanced control was applied to the program. In other words, the
top-down algorithm is essentially independent of the underlying computational
behaviour of the logic programming system, which could therefore be changed or
improved without affecting the diagnoser.
We have tried to minimise the number of oracle calls made by the top-down
algorithm,
without being too concerned about its computational complexity.
Nevertheless, this algorithm makes rather extravagant use of metacalls and hence
could be prohibitively expensive for some programs.
It would be possible to
reduce this cost by building the erroneous refutation (or finitely failed tree) once at
the beginning of the diagnosis and then searching this refutation (or tree) for the
error. Wrong could be easily adapted to this approach, but missing would seem to
require more extensive changes, along the lines of [6].
The top-down algorithm for diagnosing missing answers for definite programs
is similar to Shapiro's algorithm for missing answers [92, p.55].
We now briefly
compare the top-down algorithm for diagnosing incorrect answers for definite
programs with the single-stepping and divide-and-query algorithms of Shapiro [92].
For this comparison, it is convenient to assume that, for all three algorithms, the
final computation tree of the erroneous computation is first constructed and the
algorithms search this tree for the incorrect clause instance. The final computation
tree is the AND-tree corresponding to the refutation obtained by applying all the
mgu's used in the refutation to all the nodes in the tree. For simplicity, we also
assume that the goal (body) is a single atom. Thus some instance of this atom is
the root of the final computation tree and its children are instances of atoms in the
body of the input clause invoked by the goal.
The single-stepping algorithm finds the error by doing a post-order traversal of
the final computation tree. Suppose the algorithm has just queried the oracle about
all the children of some node and found them to be valid.
It then queries the
oracle about the node itself. If this node is not valid, then an incorrect clause
instance has been found.
If this node is valid, then the algorithm continues the
post-order traversal.
This algorithm is essentially a bottom-up algorithm.
It has
the disadvantage that its worst case query complexity is equal to the number of
nodes in the tree. A version of the single-stepping algorithm is as follows.
wrong(v and w, x) ~ wrong(v, x)
wrong(v and w, x) ~ wrong(w, x)
wrong(x, z) ~ clause(x, Xl if y) 1\ succeed(y, y) 1\ wrong(y, z)
wrong(x, Xl if y) ~ unsatisfiable(x, Xl) 1\ clause(x, Xl if y) 1\ valid(y, y)
The divide-and-query algorithm is an improvement in that its query complexity
is optimal to within a constant factor. The idea of this algorithm is as follows. It
finds a node in the tree such that the weight of the subtree rooted at that node is as
close as possible to half the weight of the entire tree. It then queries the oracle
about this node. If this node is not valid, then the algorithm recursively enters the
subtree rooted at this node. If not, the algorithm calculates a new "middle" node
for the entire tree with this subtree deleted. It is shown in [92] that this algorithm
has logarithmic query complexity. Unfortunately, it is rarely possible to divide the
tree in half.
Usually, we must settle for a "middle" node which is the root of a
subtree with somewhat smaller weight. This detracts from the performance of the
divide-and-query algorithm.
If the tree has n nodes and branching factor b, then
the worst case query complexity is blog n (not log n, as a superficial analogy with
the binary search algorithm might suggest).
The top-down algorithm searches the final computation tree as follows.
First,
the oracle is queried about the root node, which is presumably not valid. It then
queries each child of the root node in turn. If they are all valid, then an incorrect
clause instance has been found.
Otherwise, it enters the subtree rooted at the
leftmost child which it finds to be not valid and continues the search in the same
way in this subtree. The top-down algorithm does indeed search the tree in a top-
down fashion.
Note that it would be easy to add the flexibility of querying the
children in some preferred order. If the final computation tree has branching factor
b and height h, then the worst case query complexity of the top-down algorithm is
bh.
We now compare in more detail the query complexity of the top-down and
divide-and-query algorithms.
First, the top-down algorithm can perform worse
than the divide-and-query algorithm.
Suppose the tree is linear and the error is
right at the bottom of the tree.
The top-down algorithm queries all nodes in the
tree, while the divide-and-query algorithm only queries the logarithm of this
number. On the other hand, suppose the tree has two subtrees, the one on the right
being very much greater than the one on the left, and the only error is in the left
subtree. The top-down algorithm will quickly find the error by immediately

130
Chapter 4. Programs
§20. Soundness and Completeness of the Diagnoser
131
searching the left subtree, while the divide-and-query algorithm will fruitlessly
search the right subtree before finally searching the left subtree.
Thus the top-
down algorithm can perform better than the divide-and-query algorithm.
Suppose the final computation tree is perfectly balanced (that is, every internal
node has b children and all leaf nodes are at the same level) with height hand
branching factor b (>1). In this case, the "middle" node will be the leftmost child
of the root node.
If this node is valid and b>2, the next "middle" node will be
the second from left child of the root node. Assuming the rightmost child is the
only child which is not valid, the divide-and-query algorithm will query all the
other children before searching the subtree rooted at the rightmost node. Thus, for
a perfectly balanced tree, the top-down and divide-and-query algorithms search the
tree in a very similar manner.
They both have worst case query complexity bh,
approximately.
The advantage of the divide-and-query algorithm is its logarithmic worst case
query complexity for any computation tree. However, its method of deciding which
node to query next is relatively inflexible and is dependent on a syntactic criterion
unrelated to the error. In this regard, the top-down algorithm is more flexible, as it
would be easy to add heuristics to suggest an order in which to query the children
of a node.
It would be interesting to compare these two algorithms on a large
variety of incorrect programs and also to see the effectiveness of various heuristics.
§20. SOUNDNESS AND COMPLETENESS OF THE DIAGNOSER
Let us now turn to the soundness and completeness of the (first version on
page 124 of the) diagnoser. In the following theorems, it is assumed that valid,
unsatisfiable and clause have the sound and complete definitions indicated above.
The results of this section are due to Lloyd [59].
Theorem 20.1 (Soundness of the Error Diagnoser)
Let P be a program, f-W a goal, and I an intended interpretation for P.
(a) If f-wrong(W', x) (resp., f-missing(W', x)) returns the answer x = Al if VI,
then Af-V is an incorrect statement instance for P wrt I.
(b) If f-wrong(WI, x) (resp., f-missing(W', x)) returns the answer x = AI, then A
is an uncovered atom for P wrt I.
In either case, P is incorrect wrt I.
Proof Parts (a) and (b) of the theorem are proved by induction on the total
number of calls to wrong and missing on the refutation produced by the diagnoser.
If there is only one such call, then either the last statement in the definition of
wrong or the (transformed version of the) last statement in the definition of
missing must be the single input clause used from either of these definitions. In the
first case, it is clear that Af-V is an incorrect statement instance.
In the second
case, it is clear that A is an uncovered atom.
Now suppose that parts (a) and (b) of the theorem are true when the total
number of calls to wrong and missing is n. Consider a refutation which has n+1
such calls. An examination of the definitions of wrong and missing shows that the
first such call can use any statement as an input clause, except the last statement in
either definition.
Thus the first call merely returns the result given by the
derivation starting from the second call to missing or wrong, which produces a
correct result, by the induction hypothesis. Parts (a) and (b) of the theorem follow
from this.
The last part of the theorem now follows from proposition 19.3.
III
Next we study the completeness of the diagnoser. For this, it is convenient to
define (inductively) the concept of a formula and an atom being connected wrt a
program.
Definition Let W be a formula, A an atom, and P a program.
We say A is connected positively (resp., negatively) to W in 0 steps wrt P if A
occurs positively (resp., negatively) in W.
We say A is connected positively (resp., negatively) to W in n steps wrt P
(n>O) if either there exists an atom B occurring positively in W and a statement
Cf-V in P such that B and C are unifiable with mgu e, say, and A is connected
positively (resp., negatively) to ve in n-l steps wrt P or there exists an atom B
occurring negatively in W and a statement Cf-V in P such that Band C are
unifiable with mgu e, say, and A is connected negatively (resp., positively) to ve
in n-l steps wrt P.
Definition Let W be a formula, A an atom, and P a program. We say that A
is connected positively (resp., negatively) to W wrt P if A is connected positively
(resp., negatively) to W in n steps wrt P, for some n~O.
Lemma 20.2 Let P be a program, f-W a goal, A an atom, and I an intended
interpretation for P. Let A be connected positively (resp., negatively) to W wrt P.

132
Chapter 4. Programs
§20. Soundness and Completeness of the Diagnoser
133
(a) If an instance of A is the head of an incorrect statement instance for P wrt I,
then there exists a computed answer for ~wrong(W', x) (resp., ~missing(W', x»
in which x is bound to the representation of this incorrect statement instance.
(b) If an instance of A is an uncovered atom for P wrt I, then there exists a
computed answer for ~missing(W', x) (resp., ~wrong(W', x» in which x is bound
to the representation of this uncovered atom.
Proof The proof is a straightforward induction argument on the number of
steps needed to connect Wand A. (See problem 14.) III
Lemma 20.3 Let P be a normal program, G a normal goal ~W, and I an
intended interpretation for P.
(a) If 8 is a computed answer for P U {G} and W8 is not valid in I, then either
there exists an atom A connected positively to W wrt P such that an instance of A
is the head of an incorrect clause instance for P wrt I or there exists an atom A
connected negatively to W wrt P such that an instance of A is an uncovered atom
for P wrt I.
(b) If P U {G} has a finitely failed SLDNF-tree and W is satisfiable in I, then
either there exists an atom A connected positively to W wrt P such that an instance
of A is an uncovered atom for P wrt I or there exists an atom A connected
negatively to W wrt P such that an instance of A is the head of an incorrect clause
instance for P wrt I.
Proof Let W be LII\..·I\Ln. Parts (a) and (b) are proved together by induction
on the number of calls k (including calls in subsidiary refutations and trees) in the
SLDNF-refutation for (a) and in the SLDNF-tree for (b), respectively. When k=l,
the result is obvious. Now suppose that (a) and (b) hold when there are at most
k-l calls.
(a) Suppose 8 is a computed answer for P U {G}, W8 is not valid in I and the
SLDNF-refutation has k calls.
We can assume that 8 is actually the composition
of the substitutions used in the SLDNF-refutation. Let L. be the selected literal in
G. We consider two cases.
1
Li is a negative literal
Suppose Li is -B. If B is satisfiable in I, then P u {~B} has a finitely failed
SLDNF-tree with < k calls and the result follows by the induction hypothesis.
Otherwise, B is unsatisfiable in I and hence Li is valid in I. Thus 8 is a computed
answer for P u
{~Lll\..·I\Li_lI\Li+II\...I\Ln} and (LII\...I\Li_II\Li+ll\...I\L )8 is
not valid in I. Hence the result follows from the induction hypothesis.
n
L. is a positive literal
1
Let
B~V
be
the
first
input
clause.
Suppose
that
(Lll\...I\Li_lI\VI\Li+ll\...I\Ln)8 is not valid in I. Then the result follows from the
induction hypothesis.
Otherwise, Li8 is not valid in I.
Hence B8~V8 has an
incorrect clause instance and the result follows.
(b) Suppose P u {G} has a finitely failed SLDNF-tree, W is satisfiable in I
and the SLDNF-tree has k calls. Let Li be the selected literal in G. We consider
two cases.
L. is a negative literal
1
Suppose Li is -B. Suppose first that Li fails. Then the identity substitution is
a computed answer for P u
{~B) and B is not valid in I. The result follows by
applying
the
induction
hypothesis.
Otherwise,
Li
succeeds.
Then
P u
{~Lll\...I\Li_lI\Li+ll\...I\Ln}
has
a
finitely
failed
SLDNF-tree
and
L 1\
I\L
I\L.
1\ I\L
is satisfiable in I.
Again, the result follows from the
1'"
i-I
1+1'"
n
induction hypothesis.
L. is a positive literal
1
Suppose there exists an input clause B~V with mgu 81' say, such that
(Lll\...I\Li_1I\VI\Li+11\...I\Ln)81 is satisfiable in I.
Then the result follows by
applying the induction hypothesis.
Otherwise, an instance of Li is an uncovered
atom and the result follows.
III
Next we generalise lemma 20.3 to arbitrary programs and goals.
Lemma 20.4 Let P be a program, G a goal
~W, and I an intended
interpretation for P.
(a) If 8 is a computed answer for P u {G) and W8 is not valid in I, then either
there exists an atom A connected positively to W wrt P such that an instance of A
is the head of an incorrect statement instance for P wrt I or there exists an atom A
connected negatively to W wrt P such that an instance of A is an uncovered atom
for P wrt I.
(b) If P u {G} has a finitely failed SLDNF-tree and W is satisfiable in I, then
either there exists an atom A connected positively to W wrt P such that an instance
of A is an uncovered atom for P wrt I or there exists an atom A connected
negatively to W wrt P such that an instance of A is the head of an incorrect
statement instance for P wrt I.
Proof (a) First, we show that we can reduce the lemma to the case that W is
an atom.
Suppose that W has free variables x1,...,xn. Let answer be a new n-ary

134
Chapter 4. Programs
§20. Soundness and Completeness of the Diagnoser
135
predicate
symbol.
Let
G'
be
~answer(x1,...,x)
and
p'
be
p u
{answer(x1,···,xn)~W},
Extend I to an interpretation ¥, for p' by defining
answer(tl'...,tn) to be true in I' if W{ x1/t1,...,x It } is true in I where t
t
"~e
n n
'
1,...,
<U.
ground terms. If e is a computed answer for P u {G} and we is not valid~n I
then it .is ~le~ that e is a computed answer for p' U {G'} and answer(xl'...,xn)e i~
not vahd mI.
Note also that no instance of the statement for answer is incorrect
for p' wrt I' and'
f
.
no mstance
0
answer(x1,...,xn) is uncovered for p' wrt I'.
Assurm~g the result is true for the case when the goal (body) is an atom, either
~ere eXIsts an .atom A connected positively to answer(x1,...,xn) wrt p' such that an
m~tance of A IS the head of an incorrect statement instance for p' wrt I' or there
~XIStS an atom A connected negatively to answer(x1,...,xn) wrt p' such that an
ms~ance of A is an uncovered atom for p' wrt 1'.
Part (a) of the lemma follows
easIly from this.
Let us now assume that W is an atom. We prove the result by induction on the
number of transformation steps k required to transform P into a normal form of P.
When k=O, P is already a normal program and the result follows from lemma 20.3.
Next Suppose that the result holds for programs which require at most k-1
~sformation steps. Let P be a program which requires k such steps. Suppose p'
IS the program obtained from P by applying the first such transformation step.
Note that if e is a computed answer for P u {G} the e'
ed
,
'
n
IS a comput
answer for
P U {G}
Suppose
that
the
first
transformation
used
is
one
of
the
first
nine
transformations, (a) to (i), given in §18. In this case, if B is an uncovered atom for
p'
I
th
.
.
wrt,
en B IS also an uncovered atom for P wrt I. Similarly, if B~V is an
~ncorrect statement instance for p' wrt I, then either B~V is an incorrect statement
mstance for P wrt I or the statement in P, which gave rise via the transformation to
the clause in p' whose instance'
B
V h
.
.
.
IS
~,
as a corresponding mcorrect statement
msta~ce. We can now obtain the result by applying the induction hypothesis to p'.
Fmally,
suppose
that
the
first
such
transformation
used
is
the
last
transformation (j) given in §18, that is,
Replace B ~ W1A...AW. 1A-3x1...3x YAW.
A AW
b
1-
n
1+1'"
m
y
B ~ W1A...AW. 1A-P(Y1
Y )AW
A AW
1-
,..., k
i+1'"
and
p(y1'''''Yk) ~ 3x1...3xnV
m
where Yl'''·'Yk are the free variables in 3x1...3xnV and p is a new predicate
symbol not already appearing in P. We extend I to I' for p' by defining p(t ,...,t )
to be true in I' 'f (3
3
V){
1
1k
1
Xl'" xn
Y1 t1,·..,yI!tk} is true in I, where tl'...,tk are ground
terms. Note that no instance of the statement for p is incorrect for p' wrt I' and no
instance of p(x1,...,xn) is uncovered for p' wrt I'. Note also that if an instance of
B ~ W1A...AWi_lA-P(Yl""'Yk)AWi+1A
AWm is incorrect for p' wrt I', then a
corresponding
instance
of
B ~ W1A
AWi_1A-3x1...3xnVAWi+1A...AWm
is
incorrect for P wrt I.
Furthermore, if q is the predicate symbol of B and some
atom C with predicate symbol q is uncovered for p' wrt I', then C is also
uncovered for P wrt I.
The result now follows by applying the induction
hypothesis to p'.
(b) The proof of part (b) is similar. II
Theorem 20.5 (Completeness of the Error Diagnoser)
Let P be a program, G a goal ~W, and I an intended interpretation for P.
(a) If e is a computed answer for P u {G} and we is not valid in I, then there
exists a computed answer for
~wrong(W', x) in which x is bound to the
representation of either an incorrect statement instance or an uncovered atom.
(b) If P u {G} has a finitely failed SLDNF-tree and W is satisfiable in I, then
there exists a computed answer for ~missing(W', x) in which x is bound to the
representation of either an incorrect statement instance or an uncovered atom.
Proof The theorem follows immediately from lemmas 20.2 and 20.4. II
The main advantages of the approach taken in this chapter to error diagnosis
are that the diagnoser itself has
a simple and elegant semantics, that the
programmer only needs to know the intended interpretation of the incorrect
program to debug it, and that the diagnoser can handle programs which use
advanced control facilities and the increased expressiveness of program statements.
However, a disadvantage of the approach is that it does not cope with the
non-declarative features of PROLOG, such as cut, assert and retract. At first sight,
this would appear to invalidate the approach, since practically every non-trivial
PROLOG program makes some use of these non-declarative features! However, the
outlook is more promising than that.
The first point to note in this regard is that well-written PROLOG programs
usually consist of a small number of definitions using non-declarative features
together with the remainder of the definitions which are purely declarative (except
possibly for safe uses of cut, which are only for efficiency and can be ignored for
the purposes of debugging). This means that the programmer can use a diagnoser

136
Chapter 4. Programs
137
Problems for Chapter 4
like the one above for debugging the major part of the program which is purely
declarative.
Second, as we pointed out earlier, there is a strong effort being put
towards making the new generation of PROLOG systems more declarative.
Advanced control facilities and better forms of negation allow the programmers to
write their programs in a more declarative style. In fact, it may even be possible to
avoid the overt use of cut entirely. All these advances in the design of PROLOG
systems make the job of debugging much easier.
They will also make the
declarative diagnoser more practically useful, since the proportion of programs to
which the pure approach above applies will increase.
Leaving aside the problem of the non-declarative features of PROLOG, we
now look at other ways in which the diagnoser could be improved. A useful way
of thinking about error diagnosers is that they are expert systems and a number of
recent papers (e.g. [31], [32]) have taken this approach. One can imagine the
diagnoser being augmented with expert knowledge about typical program errors
and all kinds of heuristics for quickly locating them.
Another interesting
possibility would be the incorporation of the intelligent backtracking ideas of [81].
This has been investigated in some detail for definite programs in [6]. These ideas
need to be extended to (arbitrary) programs.
The diagnoser also needs some method of locating errors which lead to infinite
loops [92].
The analysis of a looping program is complicated by the fact that it
may actually be correct wrt the intended interpretation, but get into an infinite loop
because of the deficiencies of the standard PROLOG computation rule.
The
employment of advanced control facilities, which are more likely to avoid infinite
loops [73], will help here.
Much more research needs to be done before we will be able to build truly
practical declarative error diagnosers.
We hope the results of this chapter will
provide a useful foundation for this research.
PROBLEMS FOR CHAPTER 4
1. Prove proposition 17.3.
2. Consider the following program
grandparent(x,y) ~ parent(x,z), parent(z,y)
parent(x,y) ~ mother(x,y)
parent(x,y) ~ father(x,y)
ancestor(x,y) ~ parent(z,y), ancestor(x,z)
ancestor(x,y) ~ parent(x,y)
father(Fred, Mary)
father(George, James)
father(John, Fred)
father(Albert, Jane)
mother(Sue, Mary)
mother(Jane, Sue)
mother(Liz, Fred)
mother(Sue, James)
(a) Write the following queries as goals.
(i) Who is the father of Jane?
(ii) Who has Sue as mother and John as grandfather?
(iii) Who are the ancestors of Mary?
(iv) Does every person with a mother also have a father?
(v) Are all Sue's children childless?
.
d
t in common WIth Mary.
(vi) Find everyone who has a gran paren
(vii) Find every mother who has no father.
.
·th George has
,
h
h
grandparent m common WI
(viii) Is it true that everyone w 0
as a
an ancestor in common with Mary?
a normal
b
For the above program and each of the goals in p~ (a), show
( )
d
al goal which result from the transformatIon process.
program an
norm
3. Prove lemma 18.3.
be a normal program and G a normal goal.
.
4. Let P
f
P
{G} in the sense of §18 iff e IS a
(a) Prove that e is a computed answer or
u
computed answer for P u {G} in t~else~s~l0: ~~~NF-tree in the sense of §18 iff
(b) Prove that P u {G} has a fimte yale
P u {G} has a finitely failed SLDNF-tree in the sense of §15.

138
Chapter 4. Programs
Problems for Chapter 4
139
(c) What is the relationship between SLDNF-derivations, SLDNF-refutations, and
SLDNF-trees in the sense of §18 and in the sense of §15?
5. Let P be a program and G a goal. Prove that if one nonnal fonn of P u {G} is
allowed, then every nonnal fonn of P u {G} is allowed.
6. Let P be a program and p' and p" nonnal fonns of P.
Let U be a closed
fonnula containing only predicate symbols which appear in P.
Prove that U is a
logical consequence of comp(P') iff U is a logical consequence of comp(P").
7. Give an example of a program P with a nonnal fonn p' such that P is not a
logical consequence of P'.
8. Let P be a hierarchical program, G a goal and p' u {G'} a nonnal fonn of
P u {G}. Prove that p' is hierarchical.
9. Let P be a program and W a closed fonnula.
(a) Prove that P u {f-W} has a finitely failed SLDNF-tree iff P u {f- -W} has
an SLDNF-refutation.
(b) Prove that P u {f-W} has an SLDNF-refutation iff P u {f- -W} has a finitely
failed SLDNF-tree.
What happens if W is not closed?
10. Let P be a program, G1 a goal f-W1, and G2 a goal f-W2. Suppose that WI
and W2 are logically equivalent. Detennine whether the following statements are
correct or not:
(a) e is a computed answer for P u {G1} iff e is a computed answer for
P u {G2 }.
(b) P u {G1} has a finitely failed SLDNF-tree iff P u {G2} has a finitely failed
SLDNF-tree.
11. Let P be the program
p(a) f-
and G the goal f- "iIx p(x).
Show that, if the safeness condition is dropped, the
identity substitution is a "computed answer", but that "iIx p(x) is not a logical
consequence of comp(P).
12. Let P be the program
p(a,a) f-
q(b,y) f-
r(a) f- \iy(q(x,Y)f-p(x,y»
and G the goal f-r(a).
Show that r(a) is a logical consequence of ~omp(p), but
that, if the safeness condition is dropped, P u {G} has a "finitely fmled SLDNF-
tree".
13. Consider the top-down version of the error diagnoser. Assume that a. to: level
call to wrong has its first argument unsatisfiable and a top level call to.ffilssmg has
its first argument valid. Prove that the top-down version of the error diagno.se~ has
the property that any subsequent call to wrong has its first.argument unsatlsflable
and any subsequent call to missing has its first argument valId.
14. Prove lemma 20.2.
15. Consider the following (incorrect) program for the Sieve of Eratosthenes.
primes(x,y) f- integers(2,x,z), sift(z,y)
integers(x,y,x.z) f- x~y, plus(x,l,w), integers(w,y,z)
integers(x,y,nil) f- x>y
sift(nil,nil)
sift(x.u,x.y) f- remove(x,u,z), sift(z,y)
remove(x,nil,nil)
remove(x,y.u,z) f- -(x div y), remove(x,u,z)
remove(x,y.u,y.z) f- x div y, remove(x,u,z)
The goal f-primes(lO,x) returns the incorrect answer x/2.4.8.nil.
.
.
(a) Show the oracle queries which would be asked by the single-steppmg dlagnoser
for the goal
f- wrong(primes(10,2.4.8.nil), x)
and hence determine an incorrect clause instance in the program.
(b) Repeat part (a) for the top-down diagnoser.
(c) Repeat part (a) for the divide-and-query diagnoser.
.
.
[Note that x div y is true if x divides y.
Also plus(x,y,z) IS true If x+y=z. You
may assume the system predicates >,
~, plus and div all
wo~k correctly.
Thus
oracle queries for these predicates can be avoided by simply callIng them.]

140
Chapter 4. Programs
16. Consider the following (incorrect) subset program
subset(x,y) f- "i/z (member(z,y) f- member(z,x))
member(x,y.z) f- member(x,z)
and the goal f-subset(1.2.3.nil,1.2.nil), which incorrectly succeeds.
For the top-
down diagnoser, show the computation and oracle queries that result from the goal
f-wrong(subset(1.2.3.nil, 1.2.nil), x)
Hence calculate the incorrect statement instance or uncovered atom.
Chapter 5
DEDUCTIVE DATABASES
This chapter provides a theoretical basis for deductive database systems.
A
deductive database consists of a finite number of database statements, which have
the form Af-W, where A is an atom and W is a. typed first order formula.
A
query has the form f-W, where W is a typed first order formula.
An integrity
constraint is a closed, typed first order formula.
Function symbols are allowed to
appear in formulas.
Such a deductive database system can be implemented using a
PROLOG system.
The main results of this chapter are the soundness and
completeness of the query evaluation process, the soundness of the implementation
of integrity constraints, and a simplification theorem for implementing integrity
constraints.
§21. INTRODUCTION TO DEDUCTIVE DATABASES
In this section, we introduce the important concepts of deductive database
systems, such as database, query, correct answer, and integrity constraint. We also
introduce several classes of databases, such as hierarchical and stratified databases.
In recent years, there has been a growing interest in deductive database
systems [24], [35] to [38], [51], [58], [60] to [63], [70], [87], [105], [111].
Such
systems have first order logic as their theoretical foundation.
This approach has
several desirable properties.
First, it provides an expressive environment for data modelling, since the use
of database statements allows a single general statement to replace many explicit
facts.

142
Chapter 5. Deductive Databases
§21. Introduction to Deductive Databases
143
Second, it allows a single language to be used for expressing databases,
queries, integrity constraints, views and programs. In particular, there is no need
for separate query and host programming languages as are commonly used in
relational database systems.
Third, logic itself has a well-understood and well-developed theory which
already provides much of the theoretical foundation required for database systems.
Fourth, logic allows the declarative expression of databases, queries, integrity
constraints and, especially, the key concept of a correct answer. The advantage to
the user of only having to deal with declarative concepts is obvious.
Finally, and this is most important, the approach encourages a clear separation
of the declarative and procedural concepts. For example, we can distinguish the
declarative concept of a correct answer from the query evaluation process used to
compute the answer. This contrasts with the standard relational database approach
in which the declarative concept is commonly either ignored or identified with the
implementation. The existence of a declarative definition provides an important
yardstick against which the correctness of an implementation can be measured.
Without it, we would not be able to even state the soundness and completeness
theorems.
As the collection of papers in [70] shows, there is currently a great deal of
research into the theoretical aspects of deductive database systems. There is even
more interest in the implementation of deductive database systems, especially in
the crucial area of query optimisation.
Most efforts have been put into finding
efficient ways of answering definite queries to (recursive) definite databases
without functions. For a recent survey of the techniques for this problem found so
far, the reader is referred to [7]. Unfortunately, little attention has so far been paid
to optimising normal queries, much less arbitrary queries.
However, given the
great
interest in
the
implementation problems,
there
is
every
chance
that
commercially competitive deductive database systems will become available in the
next couple of years.
Certainly, ten years from now, deductive database systems
will be the standard database systems in the same way as relational database
systems are standard now.
Underlying the theoretical developments of this chapter is a typed first order
theory.
(See §3 for a discussion of typed theories.) The reason for using a typed
theory is that types provide a natural way of expressing the domain concept of
relational databases. The requirement that formulas be correctly typed ensures that
important kinds of semantic integrity constraints are maintained. In this chapter,
we assume that the alphabet of the theory contains only finitely many constants,
function symbols and predicate symbols.
Also we assume that, for each type 't,
there is a ground term of type 'to
Next we turn to
the definitions of the main concepts.
The particular
formulation of these concepts presented in this chapter is due to Lloyd and Topor
[61], [62], [63].
Definition A database statement is a typed first order formula of the form
A~W
where A is an atom and W is a typed first order formula. The formula W may be
absent.
Any variables in A and any free variables in W are assumed to be
universally quantified at the front of the statement. A is called the head and W the
body of the statement.
Definition A database is a finite set of database statements.
Definition A query is a typed first order formula of the form
~W
where W is a typed first order formula and any free variables of W are assumed to
be universally quantified at the front of the query.
Example Consider a supplier-part-job database, whose predicate symbols have
types associated with them as follows:
supplier has type sno x sname x city
local_supplier has type sno
majocsupplier has type sno
part has type pno x pname x colour x weight
job has type jno xjname x city
spj has type snoxpnoxjnoxquantity
In a typical state, the database may contain the following statements:
supplier(S1, Smith, Adelaide) ~
supplier(S2, Jones, Sydney) ~
supplier(S3, James, Perth) ~
local_supplier(S1) ~

144
Chapter 5. Deductive Databases
§21, Introduction to Deductive Databases
145
locaCsupplier(s) ~ supplier(s,-,Melbourne)
major_supplier(s) ~ 'v'j/jno 3q/quantity (spj(s,_,j,q) 1\ q~100)
part(Pl, Screw, White, 10) ~
part(P2, Nut, Black, 20) ~
job(Il, Build, Melbourne) ~
job(J2, Repair, Sydney) ~
spj(Sl, PI, 11, 100) ~
spj(S2, P2, 13, 200) ~
In these database statements and in subsequent queries and integrity constraints,
each underscore ("_") in an argument position represents a unique variable
existentially quantified immediately before the atom containing it.
Constants are
denoted by names beginning with an upper case letter. Some possible queries that
may be asked of this database are the following:
(1) Find suppliers who supply the same part to all jobs in Perth:
~ 3p/pno 'v'j/jno (spj(s,p,k) ~ job(i.-,Perth»
(2) Find parts supplied by all suppliers who supply some red part:
~ 'v's/sno (spj(s,p,_,_) ~ 3p'/pno (spj(s,p',_,_)l\part(P',_,Red,_»)
(3) Find major suppliers such that if Sl supplies some part to some job then the
major supplier supplies either the part or the job:
~ major_supplier(s) 1\ 'v'p/pno'v'j/jno (spj(s,p,_,_) v spj(s,_,j,_) ~ spj(S l,p,j,_»
Definition Let D be a database and Q a query ~W, where W has free
variables xl"",xn' An answer for D u {Q} is a substitution for some or all of the
variables xI,,,,,xn'
It is understood that substitutions are correctly typed in that each variable is
bound to a term of the same type as the variable,
Definition An integrity constraint is a closed typed first order formula,
Example Some integrity constraints that may be imposed on the above
database are the following:
(1) No local supplier supplies part P2:
'v's/sno (-spj(s,P2,_,_) ~ local_supplier(s»
(2) Supplier S2 supplies every job in Sydney:
'v'j/jno (spj(S2,_j,_) ~ job(i.-,Sydney»
(3) Supplier S3 only supplies jobs in Adelaide or Perth:
'v'j/jno GobG,_,Adelaide) v jobG,_,Perth) ~ spj(S3,_j,_»
.
f
d t b se
This definition
Next we give the definition of the compleuon 0
a
a a a
,
.
edi
t
mbol -
of type 'tx't, for
requires the introduction of a typed equality pr
ca e sy
-'t
, , al
each type 't,
These predicate symbols are assumed not to
a~pear in ,the ong~n
language. In particular, no database, query or integrity constramt contams any -'t'
.
b I
pearing in a database D is
Definition The definition of a predicate sym 0 p ap
the set of all database statements in D which have p in their head.
edi
t
mbol p of type 'tlx...x't
in
Definition Suppose the definition of a pr
ca e sy
n
a database is
Al ~Wl
Example Let the definition of p be
p(x) ~ q(x,y)
pCb) ~
fi"
f
is
d
h
type cr Then the completed de lmtl0n or p
where x has type 't an
y
as
.
'Vz/'t (p(z) ~ (3x/'t 3y/cr «z='tx)l\q(x,y» v (z='tb»)
D fi 't·
Let D be a database and p a predicate symbol of type 'tlx...x'tn
e 1m IOn
.
D
. h
redicate
.
.
D
Suppose there is no database statement m
wIt
p
occumng m
.
.
I
symbol p in its head, Then the completed definition of p is the formu a
'VxI/'tI",'Vxn/'tn -p(xI,.."xn)
f all axioms of the following
The equality theory for a database consists 0
form:
where c and d are distinct constants of type 't,
1.
c:;C'td,
where f and g are distinct function symbols of
2.
V'(f(xl ,oo"xn):;C'tg(yI,.",ym»'
range type 't,

146
Chapter 5. Deductive Databases
§21. Introduction to Deductive Databases
147
3.
'v'(f(x1,...,xn):;l!:'tc), where c is a constant of type 't and f is a function symbol of
range type 'to
4.
'v'(t[x]:;l!:'tx), where t[x] is a term of type 't containing x and different from x.
5.
'v'«x1:;l!:'t/1) v ... v (xn:;l!:'t/n) ~ f(xl'...,xn):;l!:'tf(Yl""'Yn»'
where
f
is
a
function symbol of type 't1x...x'tn
~'t.
6.
'dx/'t (x='tx).
7.
'v'«x1='t/1) 1\ ••• 1\ (xn='t/n) ~ f(x1,...,xn)=i(Yl""'Yn»'
where
f
is
a
function symbol of type 't1x...x'tn
~'t.
8.
'v'«x1='t/1) 1\ ••• 1\ (xn='t/n) ~ (P(xl""'xn) ~ P(Y1""'Yn»)'
where
p
(including every ='t) is a predicate symbol of type 't1x...x'tn.
9.
'dx/'t «x='ta1) v ... v (x='tak) v (3xI/'t1...3xi'tn(x=i1(x1,...,xn))) v
... v (3Y1/0'1...3Ym/O'm(x='tf/Y1""'Ym»)))'
where al'...,ak are all the constants of type 't and fl'...,fr are all the function
symbols of range type 'to
Axioms 1 to 8 are the typed versions of the usual equality axioms for a
program.
(See §14.) The axioms 9 are the domain closure axioms, which were
introduced in the function-free case by Reiter [85].
Definition Let D be a database. The completion of D, denoted by comp(D), is
the collection of completed definitions of predicate symbols in D together with the
above equality theory.
Definition Let D be a database, Q a query ~W, and 8 an answer for
D u {Q}.
We say 8 is a correct answer for comp(D) u {Q} if 'v'(W8) is a
logical consequence of comp(D).
The concept of a correct answer gives a declarative description of the desired
output from a query to a database.
Next we give the definition of a database
satisfying or violating an integrity constraint.
Definition Let D be a database such that comp(D) is consistent and let W be
an integrity constraint.
We say D satisfies W if W is a logical consequence of
comp(D); otherwise, we say D violates W.
This definition is due to Reiter [87]. Intuitively, an integrity constraint should
be an invariant of the database.
There are two common views of databases, at least relational databases, which
have been called the model-theoretic view and the proof-theoretic view [51], [79],
[87].
In the model-theoretic view, a database is a model of its integrity constraints.
Furthermore, an answer to a query should make the query true in the model given
by the database.
This view is essentially that provided by conventional relational
database theory [25].
In the proof-theoretic view, the database is a first order theory and its integrity
constraints should be an invariant of the theory.
Furthermore, answering a query
involves proving the query to be a logical consequence of the database.
This
chapter takes a proof-theoretic view of databases.
The proof-theoretic view has a number of advantages over the model-theoretic
view, which are mainly concerned with the extension from relational databases to
more general databases.
For example, the model-theoretic view only works in a
natural way for relational databases because the facts in the database can equally
well be regarded as constituting an Herbrand interpretation. Once we move beyond
having just ground facts in the database, there is no natural way of regarding the
database as an interpretation any more.
The other advantages are related to the
fact that, if the database is regarded as a first order theory, then we have available
more
powerful
data
modelling
capabilities
for
the
treatment of incomplete
information and null values, and the incorporation of more real world semantics.
We refer the interested reader to [51] and [87] for a detailed discussion of these
matters.
Next, we give the definitions of several important classes of queries and
databases.
Definition A
normal query is a query of the form
~L11\...I\Ln' where
L1,...,Ln are literals.
Definition A definite query is a query of the form
~A11\...I\An' where
Al'...,An are atoms.

148
Chapter 5. Deductive Databases
§21. Introduction to Deductive Databases
149
Definition A database clause is a database statement that has the fonn
Af-Ll"···I'-Ln, where Ll'...,Ln are literals.
A normal database is a database that
consists of database clauses only.
Definition A definite database clause is a database clause that has the fonn
Af-Al"···,,An, where Al'...,An are atoms.
A definite database is a database that
consists of definite database clauses only.
Definition A level mapping of a database is a mapping from its set of
predicate symbols to the non-negative integers. We refer to the value of a predicate
symbol under this mapping as the level of that predicate symbol.
Definition A database is hierarchical if it has a level mapping such that, in
every database statement p(tl,...,tn) f- W, the level of every predicate symbol in
W is less than the level of p.
Definition A database is stratified if it has a level mapping such that, in every
database statement p(tl,...,tn) f- W, the level of the predicate symbol of every
atom occurring positively in W is less than or equal to the level of p, and the level
of the predicate symbol of every atom occurring negatively in W is less than the
level of p.
Clearly, every hierarchical database is
stratified and also every definite
database is stratified.
We can assume without loss of generality that the levels of a stratified
database are O,l,...,k, for some k, and we will nonnally assume this without
comment in what follows.
However, whenever we deal with stratified databases D
and Dr such that D k
Dr, it will be convenient to assume that D inherits the
stratification induced by Dr.
This implies that for the smaller database D, there
may not be predicate symbols of all levels O,l,...,k. Note that, at level 0, all atoms
in the bodies of database statements must occur positively, but that these database
statements need not be definite database clauses.
Since every fonnula can be transfonned into a logically equivalent fonnula in
prenex conjunctive nonnal fonn (see proposition 3.4), we can transform the body
of each statement in a database into this fonn.
The transfonned database is
logically equivalent to the original one, and the completion of the transfonned
database is logically equivalent to the completion of the original one. Also the
mapping T (defined below) associated with the transfonned database is equal to the
mapping associated with the original one.
Furthennore, if W' is a prenex
conjunctive nonnal fonn of W, then an atom occurs positively (resp., negatively)
in W iff it occurs positively (resp., negatively) in W'. (See problem 1.) Thus the
transfonned database is stratified iff the original database is stratified. Also the
transfonned database is hierarchical iff the original database is hierarchical.
To simplify the proofs in this chapter, we assume without loss of generality
that the body of each statement in a database is in prenex conjunctive nonnal fonn.
In this case, it is easy to identify positive and negative occurrences of atoms.
An
atom occurring in the body of a statement occurs positively if it appears in a
positive literal; otherwise, it occurs negatively.
We now define a mapping Th from the lattice of interpretations based on J to
itself.
Definition Let J be a pre-interpretation of a database D and I an interpretation
based on J. Then Th(I) = { AJ,V : Af-W E D, V is a variable assignment wrt J,
and W is true wrt I and V}.
It will be convenient to suppress the J and denote this mapping by TD' Let E
be u
[= (x,x)] .
Subsequent use of E ensures that all models considered are
't't
J
.
edi
nonnal, that is, assign an identity relation to each eqUalIty pr
cate.
The
following
propositions
and
corollary
are
the
database
versions
of
propositions 17.1 to 17.3 and corollary 17.4, and have the same proofs.
Proposition 21.1 Let D be a database, J a pre-interpretation of D, and I an
interpretation based on 1. Then I is a model for D iff TD(I) k I.
Proposition 21.2 Let D be a database, J a pre-interpretation of D, and I an
interpretation based on J.
Suppose that I u E is a model for the equality theory.
Then I u E is a model for comp(D) iff TD(I) = I.
Proposition 21.3 Let D be a stratified database and J a pre-interpretation for
D.
(a)
Suppose D has only predicates of level 0. Then TD is monotonic over the
lattice of interpretations based on J.
(b) Suppose D has maximum predicate level k+1.
Let Dk denote the set of
database statements in D with the property that the predicate symbol in the hel:id of

150
Chapter 5. Deductive Databases
§22. Soundness of Query Evaluation
151
the statement has level ~ k.
Suppose that Mk is an interpretation based on J for
Dk and Mk is a fixpoint of TDk. Then A = {Mk uS: S I:: {p(dl'...,dn) : p is a
level k+1 predicate symbol and each di is in the domain of J} } is a complete
lattice, under set inclusion. Furthermore, A is a sublattice of the lattice of
interpretations based on J, and TD, restricted to A, is well-defined and monotonic.
Corollary 21.4 Let D be a stratified database.
Then comp(D) has a minimal
normal Herbrand model.
The results of this section are due to Lloyd, Sonenberg and Topor [60].
§22. SOUNDNESS OF QUERY EVALUATION
In this section, we present the query evaluation process, and prove that it is
sound and never flounders.
These results are due to Lloyd and Topor [61], [62],
[63].
The first step of the query evaluation process transforms typed first order
formulas into corresponding type-free first order formulas.
For this, we use a
standard transformation [33].
Definition Let W be a typed first order formula. For each type 't, we associate
a new unary type predicate symbol also denoted by 'to Then the type-free form w*
of W is the first order formula obtained from W by applying the following
transformations to all subformulas of W of the form 'l:fx/'tV and ::lx/'tV:
(a) Replace 'l:fx/'tV by 'l:fx(Vf-'t(x)).
(b) Replace ::lx/'t V by ::lx(VI\'t(x)).
Example Let W be the database statement
p(x) f- ::ly/cr q(x,y)
where x has type 'to Then W* is the program statement
p(x) f- ::ly(q(x,y)l\cr(y)) 1\ 't(x)
If Q is the query
f-'l:fx/'t q(x,y)
then Q* is the goal
f-'l:fx(q(x,y)f-'t(x)) 1\ cr(y)
More generally, if Q is the query f-W, where W has free variables x1'...,x
and x.
n
1
has type 'ti (i=1,...,n), then Q* is the goal
f-W*1\'t1(x1)1\...I\'tn(xn)
We will also require the usual type theory [33].
Definition The type theory <1> consists of all axioms of the following form:
1. 't(a)f-, where a is a constant of type 'to
2. 'l:fx1...'l:fxn ('t(f(xl""'xn)) f- 't1(x1)1\...I\'tn(xn)), where f is a function symbol of
type 't1x...x'tn
~'t.
Since we are allowing functions, a query can have infinitely many answers.
However, under a reasonable restriction on the type theory <1>, we can ensure that
each query can have at most finitely many answers. If <1> is hierarchical, then there
are only finitely many ground terms of each type. (See problem 2.) Consequently,
each query can have at most finitely many answers. We emphasise that it is not so
much the presence of functions which causes queries to have infinitely many
answers, but rather the presence of a "recursive" type theory.
Now we are in a position to give the definitions of the appropriate procedural
concepts.
Definition Let D be a database, <1> its type theory, Q a query and R a safe
computation rule. Let D* and Q* be the type-free forms of D and Q. (That is, D*
is the set of type-free forms of each of its database statements.)
An SWNF-derivation of D u {Q)
(via R)
is
an
SLDNF-derivation of
D* u<1>u {Q*} (viaR).
An
SWNF-refutation
of D u {Q}
(via
R)
is
an
SLDNF-refutation
of
D* u
<1> u {Q*} (via R).
An
(R-)computed answer for
D U {Q)
is
an
(R-)computed answer for
D* U
<1> u {Q*}.
An SWNF-tree for D u {Q} (via R) is an SLDNF-tree for D* U
<1> u {Q*}
(via R).
A finitely failed SWNF-tree for D u {Q} (via R) is a finitely failed SLDNF-
tree for D* u
<1> u {Q*} (via R).
Thus, to answer a query Q to a database D, we first transform D and Q to their
type-free forms and then apply the techniques of §18 to the goal Q* and program
D* u
<1>.
Note that, due to the presence of the type predicate symbols, every
computed answer is a ground substitution for all the free variables in the body of
the query. (See problem 3.) Also every computed answer is correctly typed. The
next theorem shows that this implementation is sound.

152
Chapter 5. Deductive Databases
§22. Soundness of Query Evaluation
153
Lemma 22.1 Let D be a database, <1> its type theory, and W a closed typed
fIrst order fonnula. Let D* and W* be the type-free fonns of D and W. If W* is a
logical consequence of comp(D* u <1», then W is a logical consequence of
comp(D).
Proof The proof is rather long and requires some preparation. Given a model
M for comp(D), we construct a model M* for comp(D* u <1». The complexity of
the construction of M* which we use is needed to ensure that the equality axioms
are satisfIed.
Let M be a model for comp(D). Using (the typed version of) [69, p.83], we
can assume without loss of generality that M is normal, that is, the identity relation
on the domain C't is assigned to ='t' for each type 'to We can also assume that the
C't's are disjoint. Put C = u'tC't'
The underlying language L* for the interpretation M* includes all
the
constants, function symbols and (non-equality) predicate symbols of the underlying
language L for M. L* differs from L in that all type infonnation is suppressed, the
various typed equality predicate symbols =
are replaced by a single equality
edi
bol
't
pr
cate sym
= and there is a unary predicate symbol 't for each type 'to
Let F' be the set of mappings on the C assigned by M to the function symbols
.
't
III L. Let T be the set of all (free) tenns that can be fonned using elements of C as
primitive terms and elements of F' as function symbols. (Note that the type
restrictions are ignored in forming these terms.) The domain of M* will be the set
of equivalence classes of a particular equivalence relation 6 on T.
To
defIne
6,
we
introduce
a
reduction
operation
on
T.
We
write
f'(d1'...,dn) ~ d, if f has type 'tlx...x'tn~'t, f' is the mapping assigned to f by M,
diEC't.' dEC't' and f'(d1'...,dn)=d.
For s,tET, we write s:¢>t if t is the result of
1
replacing some (not necessarily proper) subterm f'(dl,...,d ) of s by d, where
f'(d1'...,dn) ~ d. We say that sET is irreducible if there is ~o tET such that s:¢>t.
Finally, for s,tET, we say that s reduces to t if there exist rO,r1'...,rnET such that
s=rO:¢>r1:¢>...:¢>rn=t.
Now we can defIne the equivalence relation 6 on T.
Let s,tET. Then Mt if
there exists UET such that s reduces to u and t reduces to u. To prove that 6 is an
equivalence relation, we use the following lemma.
Lemma 22.2 Let SET. Then there exists a unique irreducible tET such that s
reduces to t. (We say that t is the irreducible form of s.)
Proof of lemma 22.2 Clearly there exists an irreducible form of each SET,
since, in each reduction u:¢>v, v has fewer subtenns than u.
To prove that irreducible fonns are unique, fIrst note that if f'(s1'...,sn) reduces
to g'(t1'...,tm), then f'=g', and that the last step in any reduction of ['(s1'...,sn) to an
element dEC therefore has the fonn f'(d1'...,dn) :¢> d.
We then use induction on
the structure of s and a case analysis to show that if u and v are irreducible forms
of s, then u=v. II
Lemma 22.3 6 is an equivalence relation.
Proof of lemma 22.3 Clearly, 6 is reflexive and symmetric. That 6 is transitive
follows immediately from lemma 22.2. II
We now defIne the domain of the model M* to be T/6, the set of 6-
equivalence classes in T. If tET, we let [t] denote the 6-equivalence class
containing t. Note that T/6 contains a copy of C via the injective mapping d ~ [d].
Thus, in essence, we have simply enlarged C in a particular way to obtain a
domain for M*.
If c is a constant in L* and M assigns C'EC to c, then M* assigns [c'] in T/6 to
c. Let fEL* be an n-ary function symbol. Suppose M assigns the mapping f' to f.
Then M* assigns the mapping from (T/6)n into T/6 defined by ([t1],...,[tn)) ~
[f'(t1,...,tn)] to f. It is easy to see that this mapping is well-defIned. Note that this
mapping is an extension of f.
Suppose p is an n-ary predicate symbol in L*. If M assigns the relation p' to
p, then M* assigns the relation {([d1],...,[dn)) : (d1'...,dn)Ep'} on (T/6)n to p. To a
type predicate symbol 't, M* assigns the unary relation {[d] : dEC't}' Finally, M*
assigns the identity relation on T/6 to =.
This completes the defInition of the interpretation M* for comp(D* u <1». We
now check that M* is a model for comp(D* u <1».
Much of the verifIcation is
routine and we take the liberty of omitting some details.
We fIrst check that M* is a model for the equality theory of comp(D* u <1».
The eight axioms of the equality theory are given in §14.
Apart from axiom 4,
these axioms are easily seen to be satisfIed. Axiom 4 is

154
Chapter 5. Deductive Databases
§22. Soundness of Query Evaluation
155
V(t[x];t:x), where t[x] is a tenn containing x and different from x.
That this axiom is satisfied follows immediately from the next lemma.
Lemma 22.4 Let r,sET. If r is a proper subtenn of s, then rtl.s.
Proof of lemma 22.4 Suppose r~s. Then there exists an irreducible tET such
that r reduces to t and s reduces to t. Let UET be the result of replacing the
occurrence of r in s by t. Then t is a proper subtenn of u and u reduces to t. If
tEC, then we obtain a contradiction using axiom 4 of the equality theory for D.
Otherwise, t has the fonn f'(t1,...,tn), in which case we again have a contradiction
since it is impossible for u to reduce to t.
IlIII
The remainder of the verification that M* is a model for comp(D* U <I»
depends on another lemma. For this we need a definition.
A variable assignment
V wrt M is an assignment to each variable x in L of an element dEC't' where 't is
the type of x.
Corresponding to V, there is a variable assignment V* wrt M*
which assigns [d] to x.
Lemma 22.5 Let W be a (not necessarily closed) typed first order fonnula, V
a variable assignment wrt M, and V* the corresponding variable assignment wrt
M*. Then W is true wrt M and V iff W* is true wrt M* and V*.
Proof of lemma 22.5 The proof is a straightforward induction argument on the
structure of W. (See problem 5.)
IlIII
Using lemma 22.5, it can now be checked that M* is a model for the
remainder of comp(D* u <I». The domain closure axioms for comp(D) are used to
show that M* is a model for the only-if halves of the completed definitions of the
type predicate symbols.
We have now finally shown that M* is a model for comp(D* u <I». Since W*
is a logical consequence of comp(D* u <I», we have that M* is a model for W*.
Using lemma 22.5 again, we obtain that M is a model for W. Thus W is a logical
consequence of comp(D). This completes the proof of lemma 22.1.
IlIII
Theorem 22.6 (Soundness of Query Evaluation)
Let D be a database and Q a query.
Then every computed answer for
D U {Q} is a correct answer for comp(D) u {Q}.
Proof Let e be a computed answer for D u {Q}, where Q is f:-W, W has free
variables
xl'
,xn
and
Xi
has
type
'ti
(i=l,...,n).
By
theorem
18.:,
(W*A't1(x1)A
A'tn(xn))e is a logical consequence of comp(D* u <I», where <I> IS
the type theory of D. Thus (We)* is a logical consequence of comp(D* u <I». By
lemma 22.1, we is a logical consequence of comp(D). That is, e is a correct
answer for comp(D) u {Q}.
IlIII
As the following example shows, theorem 22.6 no longer holds if we omit the
domain closure axioms from the definition of comp(D).
Example Let D be the database
p(a) f:-
and Q be the query f:-Vx/'t p(x). Suppose that the type theory is just 't(a)f:-. Then
the identity substitution is a computed answer, but Vx/'t p(x) is not a logical
consequence of comp(D) if the domain closure axiom Vx/'t (x=a) is omitted from
comp(D).
Theorem 22.6 is the fundamental result which guarantees the soundness of the
query evaluation process.
The implementation of the query evaluation process is,
at least in principle, quite straightforward.
The main part of the implementation
concerns the 10 transfonnations given in §18. These can be implemented in a
PROLOG program which contains one clause for each transfonnation plus a short
procedure for locating free variables. Also, it is easy to avoid the explicit
introduction of new predicate symbols which is fonnally required. A direct
implementation of types would also be easy. However, such an implementation
would be inefficient and hence some optimisations would be required.
Next we show that the query evaluation process never flounders.
Let D be a
database, <I> its type theory, and Q a query.
By a computation of D u {Q}, we
mean a computation of D* u <I> u {Q*}.
Definition Let D be a database, <I> its type theory, and Q a query.
We say a
computation of D u {Q} flounders if at some point in the computation a goal is
reached which contains only non-ground negative literals.
Lemma 22.7 Let D be a database, <I> its type theory, and Q a query.
Then
D* U <I> u {Q*} is allowed.

156
Chapter 5. Deductive Databases
§23. Completeness of Query Evaluation
157
allOWed.
~roof The form of the 10 transformations in §18 and the presence of the type
predicate symbols ensures that every normal form of D* u <I> u {Q*} is allowed.
(See problem 8.)
II1II
Note that not every clause in a normal form of D* need be all
d
owe.
Example Let D be
p(x) ~ Vy/cr q(x,y)
where x is of type 'to Then a normal form of D* is
p(x) ~ -rex) 1\ 't(x)
rex) ~ -q(x,y) 1\ cr(y)
where r is a new predicate s
bol
Th
ym.
e second clause is admissible, but not
Proposition 22.8 Let D be a database and Q a query. Then no computation of
D u {Q} flounders.
Proof The result follows immediately from lemma 22.7 and proposition
18.5(a).
II1II
§23. COMPLETENESS OF QUERY EVALUATION
In §22, we proved that every computed answer for D u {Q} is a correct
answer for comp(D) u {Q}
W
ld lile
.
.
e wou
e to obtaIn the converse of this result.
Unfortunately, there is no hope of this because there is no general completeness
result even for normal programs.
However, we can prove that query evaluation is
complete for the special cases that the database is definite or hierarchical.
These
results are due to Lloyd and Topor [63].
We start by proving the converse of
lemma 22.1.
Lemma 23.1 Let D be a database, <I> its type theory, and W a closed typed
first order formula. Let D* and W* be the type-free forms of D and W. If W is a
logical
consequence
of
comp(D),
then
W*
is
a
logical
consequence
of
comp(D* u <I».
Proof Let M* be a normal model for comp(D* u <I». We construct a normal
model M for comp(D). Suppose M* has domain C. We define C
= {ceC : c is in
the relation assigned to 't}. M assigns to a constant the same el~ment of Cas M*
does.
Note that a constant of type 't is thus assigned an element of C't' since M*
satisfies <I>. If f is a function symbol of type 't1x...x'tn-+'t and M* assigns f' to f,
then M assigns f'I(C't x...x C't ) to f.
Note that the range of f'I(C't
X...X C't ) is
1
n
1
n
contained in C't' since M* satisfies <I>. Let P be a predicate symbol different from
= and 't, for each type't. If p is of type 't1x...x'tn and M* assigns p to p', then M
assigns p' n (C't x...xC't ) to p. Finally, M assigns the identity relation on C't to
1
n
='t' for each type 'to
We now show that M is a model for comp(D). It is easy to see that M is a
model for the equality axioms.
For the remainder of the proof, we require the
following lemma, whose proof is a straightforward induction argument on the
structure of W. (See problem 9.)
Lemma 23.2 Let W be a (not necessarily closed) typed first order formula, Y
a variable assignment wrt M, and y* the corresponding variable assignment wrt
M*. Then W is true wrt M and Y iff W* is true wrt M* and Y*.
Using lemma 23.2, one can establish that M is indeed a model for comp(D).
Hence M is a model for Wand, using lemma 23.2 again, M* is a model for W*.
Thus W* is a logical consequence of comp(D* u <I». This completes the proof of
lemma 23.1.
II1II
Lemma 23.3 Let D be a database, <I> its type theory, and Q a query ~W,
where xl'...,xn are the free variables in W and Xi has type'ti (i=l,...,n). Let e be a
correct answer for comp(D) u {Q} that is a ground substitution for xl'...,xn' Then
e is a correct answer for comp(D* u <I» u {Q*}.
Proof Since e is a correct answer for comp(D) u {Q} and since e is a ground
substitution for the free variables x1,...,xn in W, it follows that we is a logical
consequence of comp(D). By lemma 23.1, w*e is a logical consequence of
comp(D* u <I».
Hence (W*1\'t1(x1)1\...I\'tn(xn»e is a logical consequence of
comp(D* u <I». That is, e is a correct answer for comp(D* u <I» u {Q*}.
II1II
The next theorem is a database version of theorem 9.5.
Theorem 23.4 (Completeness of Query Evaluation for Definite Databases)
Let D be a definite database, Q a definite query ~W, and R a computation
rule. Let e be a correct answer for comp(D) u {Q} that is a ground substitution
for all variables in W. Then e is an R-computed answer for D u {Q}.

158
Chapter 5. Deductive Databases
§24. Integrity Constraints
159
Proof Let D have type theory <1>.
By lemma 23.3, e is a correct answer for
comp(D* u <1» u {Q*}.
By
theorem
14.6, e
is
a
correct
answer
for
D* u <I> u {Q*}.
By theorem 9.5, there exists an R-computed answer cr for
D* u <I> u {Q*} and a substitution
'Y such that e=cry.
Since cr is a ground
substitution for all the variables in W, it follows that e=cr.
That is, e is an R-
computed answer for D u {Q}. I
The requirement in theorem 23.4 that e be a ground substitution for all
variables in W cannot be omitted, since every computed answer for D u {Q} has
this property.
From a database viewpoint, theorem 23.4 is a rather weak
completeness result. It would be preferable to have conditions under which a query
had only finitely many answers and the query evaluation process was guaranteed to
find all these answers and then terminate.
One rather strong condition, which
ensures these properties hold, is that the database be hierarchical. We now present
this completeness result for hierarchical databases, which is the database version of
theorem 18.9.
Theorem 23.5 (Completeness of Query Evaluation for Hierarchical Databases)
Let D be a database,
<I> its type theory, Q a query f-W, and R a safe
computation rule. Suppose that both D and <I> are hierarchical. Then the following
properties hold.
(a) Each SLDNF-tree for D u {Q} via R exists and is finite.
(b) If e is a correct answer for comp(D) u {Q} and e is a ground substitution for
all free variables in W, then e is an R-computed answer for D u {Q}.
Proof By
lemma
22.7,
D* u <I> u {Q*}
is
allowed.
Also
D* u <I>
is
hierarchical.
By lemma 23.3, e is a correct answer for comp(D* u <1» u {Q*}.
Hence the result follows from theorem 18.9. I
§24. INTEGRITY CONSTRAINTS
In this section, we study integrity constraints in deductive database systems
and prove the correctness of a simplification method for checking integrity
constraints.
A number of proofs in this section use typed versions of results from earlier
chapters.
In each case, it will be clear from the context that the reference to the
earlier result is actually a reference to the appropriate typed version of the result.
The standard method of determining whether a database satisfies or violates an
integrity constraint W is by evaluating the query f-W.
The following two
theorems, due to Lloyd and Topor [61], [62], show that this method is sound.
Theorem 24.1 Let D be a database and W an integrity constraint.
Suppose
that comp(D) is consistent. If there exists an SLDNF-refutation of D u {f-W},
then D satisfies W.
Proof The theorem follows immediately from theorem 22.6. I
Theorem 24.2 Let D be a database and W an integrity constraint.
Suppose
that comp(D) is consistent. If D u {f-W} has a finitely failed SLDNF-tree, then
D violates W.
Proof The theorem follows easily from theorem 18.6 and lemma 22.1.
III
Now we turn to the simplification theorem for integrity constraint checking.
From a theoretical viewpoint, it is highly desirable for a database to satisfy its
integrity constraints at all times. However, from a practical viewpoint, there are
serious difficulties in finding efficient ways of checking the integrity constraints
after each update. The problem is especially difficult for deductive databases, since
the addition of a single fact can have a substantial impact on the logical
consequences of the database because of the presence of rules.
In spite of these difficulties, it is possible to reduce the amount of computation
if advantage is taken of the fact that, before the update was made, the database was
known to satisfy its integrity constraints. The simplification theorem shows that it
is only necessary to check certain instances of each integrity constraint. For a very
large database, this can lead to a dramatic reduction in the amount of computation
required. This idea is originally due to Nicolas [78] in the context of relational
database systems. A method related to the one given in this chapter was presented
by Decker [27].
An alternative "theorem proving" approach was given by Sadri
and Kowalski [90].
To cover the most general situation by a single theorem, we use the concept of
a transaction. A transaction is a finite sequence of additions of statements to a
database and deletions of statements from a database. If D is a database and t is a
transaction, then the application of t to D produces a new database D', which is

Suppose L is the typed language underlying the database D. We make the
assumption throughout that, whatever changes D may undergo, L remains fixed.
Thus, for example, adding a new statement to D does not introduce new constants
into the language.
Implementing the simplification method involves computing four sets of atoms,
computing two sets of substitutions by unifying atoms in the sets with atoms in an
integrity
constraint,
and
evaluating
corresponding
instances of the
integrity
constraint. We begin with the definitions of the appropriate sets of atoms.
Definition Let D and D' be databases such that D ~ D'.
We define the sets
posD,D' and negD,D' inductively as follows:
o
posD,D'
{A: Af-WED' \ D }
o
negD,D'
{}
161
D and D' be databases such that D ~ D' and J a pre-
We define
u
[A]
AEposDD'
J
,
u
[A] .
AEnegD,D'
J
Definition Let
interpretation of D.
posinstD,D',J
neginstD D' J
,
,
Proof (a) Recall that BJ,V denotes the J-instance of atom B wrt V.
Since
BJ,V E neginstD,D',J'
we
have
that
BJ,V
is
also
a
J-instance
of
some
C E negD,D"
By
lemma
15.2 (a),
B
and
C
are
unifiable
with
mgu
a = {xl/r1,...,xn/rm},
say.
Since C E negD,D'
and
Ba = ca,
we have
that
Aa E negD D"
By lemma 15.2 (b), the variable assignment, which we can
suppose without loss of generality to be V, that maps B and C to BJ,V also maps
To motivate the above definitions, consider the case when we add a fact Af-
to a database D to obtain a database D'.
An important task of the simplification
method is to capture the difference between a model for comp(D') and a model for
comp(D). In the case that D is a relational database, we see that posD,D' is {A},
which is precisely the difference between a model for comp(D) and a model for
comp(D'). (In this case, the models are essentially unique.) For a deductive
database, the presence of rules means that the difference between the models could
be larger. However, as we shall see, for stratified databases, posD D' and negD D'
,
,
can still be used to capture the differences between (suitably related) models of
comp(D) and comp(D'). Intuitively, posD,D' captures the part that is added to the
model for comp(D) when passing from D to D' and negD,D' captures th~ part that
is lost. (See lemma 24.4 below.) In the context of nonnal databases, p0So D' and
,
negD D' have been discussed by Topor et al [105].
,
Lemma 24.3 Let D and D' be databases such that D ~ D'.
Let J be a pre-
interpretation of D and V be a variable assignment wrt 1. Suppose there exists an
interpretation I based on J such that I u E is a model for the equality theory.
(a) If Af-W is in D, B occurs positively in W, and BJ,V E neginstD,D',J' then
AJ V E neginstD D' J'
,
,
,
(b) If Af-W is in D, B occurs positively in W, and BJ,V E posinstD,D',J' then
AJ,V E posinstD,D',J'
(c) If Af-W is in D, B occurs negatively in W, and BJ,V E posinstD,D',J' then
AJ,V E neginstD,D',J'
(d) If Af-W is in D, B occurs negatively in W, and BJ,V E neginstD,D',J' then
AJ,V E posinstD,D',J'
§24. Integrity Constraints
Chapter 5. Deductive Databases
{Aa : Af-W E D, B occurs positively in W, C E pos~ D' ,
and a is an mgu of B ~d C }
u {Aa
Af-W E D, B occurs negatively in W, C E neg~ D' ,
and a is an mgu of Band'C }
{Aa : Af-W E D, B occurs positively in W, C E neg~,D' ,
and a is an mgu of Band C }
u { Aa
Af-W E D, B occurs negatively in W, C E pos~ D' ,
and a is an mgu of Band' C }
n
un~OPosD,D'
n
un~O negD,D'
n+1
negDD,
,
n+l
posD,D'
negD,D'
posD D'
,
160
obtained by applying each of the deletions and additions in t in turn.
We assume
that, in any transaction, we do not have the addition and deletion of the same
statement. As the deletions and additions in a transaction can then be perfonned in
any order, we assume that all the deletions are perfonned before the additions.
With respect to integrity constraint checking, we regard a transaction as indivisible,
so we need only check the constraints at the end of the transaction.
Note that we
can use a single transaction to pass from any database D to any other database D'.

162
Chapter 5. Deductive Databases
§24. Integrity Constraints
163
xj and rj to the same domain element. for each j. Hence AJ•V is also a J-instance
of AS and so AJ•V E neginstD.D,,J'
The proofs of the other parts are similar.
II1II
Lemma 24.4 Let D and D' be stratified databases such that D k D' and let J
be a pre-interpretation of D.
(a) Let M' be an interpretation based on J for D' such that M' U E is a model for
comp(D'). Then there exists an interpretation M based on J such that M u E is a
model for comp(D).
M' \ M k posinstD.D,,J' and M \ M' k neginstD.D'.r
(b) Let M be an interpretation based on J for D such that M u E is a model for
comp(D). Then there exists an interpretation M' based on J such that M' U E is a
model for comp(D').
M' \ M k posinstD.D,,J' and M \ M' k neginstD.D'.r
Proof (a) The proof is by induction on the maximum level. k. of D'.
Base step, k=O.
By proposition 21.2. M' is a fixpoint of J?' and hence TD(M') k M'.
By
proposition 21.3(a). TD is monotonic and so TD(M') is defined. for every ordinal
a.
(See problem 13 of chapter 1.) We prove by transfinite induction that
M' \ Tg(M')
k posinstD.D'.J' for every ordinal a.
a is a limit ordinal.
The case a = 0 is trivial. Otherwise. M' \ Tg(M') = M' \ (lj3<aT~(M')
Uj3<a(M' \ T~(M')) k posinstD.D'.J' by the induction hypothesis.
a is a successor ordinal.
The case a = I is immediate from the definition of posinstD D' J' Otherwise.
note that M' \ Tg(M')
=
(M' \ TD(M')) u
(TD(M') \ Tg(M';).• Suppose that
BE TD(M') \ Tg(M'). Then one can prove that there exists a statement A~W in
D such that. for some variable assignment V wrt J and for some atom C in W. B is
AJ•V
and
CJ•V E M' \ Tg-I(M').
Thus.
by
the
induction
hypothesis.
CJ•V E posinstD.D'.J"
By lemma 24.3. we have that BE posinstD.D,,J'
This
completes the proof that M' \ ~(M')
k posinstD.D'.J' for every ordinal a.
Since TD is monotonic. there exists an ordinal y such that Tb(M') is a fixpoint
of TD.
(See problem 13 of chapter 1.) Put M = Tb(M').
By proposition 21.2.
M u E is a model for comp(D). Finally. note that M \ M' = 0 = neginstD.D'.r
Induction step.
Suppose the result holds for stratified databases of maximum level k and D'
has maximum level k+1. Let Di: (resp.• Dk) be the set of database statements in
D' (resp.. D) with the property that the predicate symbol in the head of the
statement has level s: k. Let Mi: be the set of all p(dl•.··.dn) in M' such that p h~s
level s: k. Then Mi:u E is a model for comp(Di:). By the induct~on hypothesIs.
there exists an interpretation Mk based on J such that Mk u E IS a model for
comp(DIJ. Mi:\ Mk k posinstDk.Dic,J' and Mk \ Mi: k neginstDk.Dic,J·
Put N = M u (M' \ M' ) u neginstD D' J1(k+I). where neginstD D' J1(k+l) is
k
k
•
•
•
•
the set of all p(dl'...•dn) in neginstD.D'.J such that p has level k+1. Then one. ~an
.prove that TD(N) k N. using the fact that Mk is a fixpoint of TDk• the defimtIon
of neginst
'. lemma 24.3. and the induction hypothesis.
D.D .J
.
.
A d f
d'
We now consider transfinite iterations of TD on N m the lattIce
e me
m
proposition 21.3(b). We claim the following properties hold:
(i) Ta(N) \ M' k neginstD D' J' for every ordinal a.
D
••
(ii) M' \ ~(N) k posinstD.D,.J' for every ordinal a.
For (i). note that. for all a. we have
~(N) \ M' k N\ M' k (Mk \ Mic) u neginstD•D'.J1(k+l) k neginstD.D'.J·
using the induction hypothesis on Mk \ Mic. and the definition of neginstD.D'.r
We prove (ii) by transfinite induction.
a is a limit ordinal.
Suppose 0.=0. Then we have
M' \ N k M' \ Mk k posinstD D' J k posinstD D' r
k
k' k'
••
Now suppose <DO. Then we have
M' \ ~(N) = M' \ (lA
T~ (N) = UA
(M' \ TD~(N)) k posinstD D' r
D
..,<0. D
..,<0.
•
•
a is a successor ordinal.
Suppose that B E M' \ ~(N). Then. as M' is a fixpoint of TD,. there ~xists a
statement A~W in D' such that. for some variable assignment V wrt J. BOIS AJ•V
and W is true wrt M' and V. If the statement is in D' \ D. then A E posD.D' and
so B E posinst
,immediately. Now suppose that the statement is in D. Since
D.D.J
.'
*
d
C
Bl/:Ta(N). one can prove that there exists a vanable assIgnment V
an
an atom
in ~ such that A
= A
* and either C occurs positively in Wand
I J.V
J.V
a-I(N) \ M'
C
E M' \ Ta- (N) or C occurs negatively in W and CJ V* E TD
.
J.V*
D
•
In the first case. by the induction hypothesis. CJ•V* E posinstD.D,.J'
By
lemma 24.3. we have that B E posinstD D' J'
In the second case. by (i).
C
E neo-inst
,
By lemma 24.3. V:e have that B E posinstD D' r
This
J V*
0'
D D J'
•
•
co~pletes the pr~f ~f (ii).
By proposition 21.3(b) and problem 13 of chapter 1. there exists an ordinal y

164
Chapter 5. Deductive Dati=1bases
§24. Integrity Constraints
165
such that Tb(N) is a fixpoint of TD restricted to A. Put M = Tb(N). Since M is
a fixpoint of TD, by proposition 21.2, we have that M u E is a model for
comp(D). This completes the proof of part (a).
(b) The proof is similar to part (a). We use a construction based on the set
N' = Mic u [(M \ Mk) \ neginstD D' J1(k+I)], for which it can be shown that
TD,(N') ::1 N'. (See problem 12.) .. '
Now we are in a position to state and prove the simplification theorem. This
theorem is due to Lloyd, Sonenberg and Topor [60], [62].
Theorem 24.5 (Simplification Theorem for Integrity Constraint Checking)
Let D and D' be stratified databases and t a transaction whose application to D
produces D'. Suppose t consists of a sequence of deletions followed by a sequence
of additions and that the application of the sequence of deletions to D produces the
intermediate database D". Let W be an integrity constraint 'ltx1...VxnW' in prenex
conjunctive normal form.
Suppose D satisfies W.
Let e = {a: a is the
restriction to x1'...,x
of either an mgu of an atom occurring negatively in Wand
n
.
an atom in posD" D' or an mgu of an atom occurring positively in W and an atom
in negD",D' } and'P = { \jI : \jI is the restriction to xl'...,xn of either an mgu of an
atom occurring positively in W and an atom in posD" D or an mgu of an atom
occurring negatively in W and an atom in negD" ~ }.
Then the following
properties hold.
'
(a) D' satisfies W iff D' satisfies \i(W'<I» for all <I> E e u 'P.
(b) If D' u
{~\i(W'<I>)} has an SLDNF-refutation for all
<I> E e u 'P, then D'
satisfies W.
(c) If D' u
{~\i(w'<I»} has a finitely failed SLDNF-tree for some <I> E e u 'P,
then D' violates W.
Proof (a) Suppose D' satisfies \i(W'<I», for all
<I> E e u 'P.
Note that the
formula W' is not necessarily quantifier free.
Let M' be an interpretation for D'
based on J such that M' u E is a model for comp(D'). By lemma 24.4(a), there
exists an interpretation Mil based on J such that Mil u E is a model for comp(D"),
M' \ M" !:; posinstD",D',J' and M" \ M' !:; neginstD",D',J'
Similarly. by lemma
24.4(b), there exists an interpretation M based on J such that M u E is a model for
comp(D). M \ Mil !:; posinstD" D J' and Mil \ M !:; neginstD" D J'
By supposition. W is true 'wrt M u E. Let V be a vari~bl~ assignment wrtJ.
We have to prove that W' is true wrt M' u E and V.
If V* is a variable
assignment that agrees with V on xl'....xn' then we say V* is compatible with V.
We consider the following two cases.
Case 1: For every atom A occurring negatively in Wand for every v*
compatible with V, the J-instance AJ•V* of A wrt V* is not in M' \ M, and for
every atom B occurring positively in W and for every v* compatible with V, the
J-instance BJ,V* of B wrt V* is not in M \ M'.
Let A be an atom occurring negatively in W and suppose that, for some V*
compatible with V, we have that AJ•V* rJ. M. By the condition of case 1. we have
that AJ,V* rJ. M' \ M. Hence AJ,V* rJ. M'.
Let B be an atom occurring positively in W and suppose that. for some V*
compatible with V, we have that BJ,V* E M. By the condition of case 1, we have
that BJ,V* rJ. M \ M'. Hence BJ,V* EM'.
It follows from this that W' is true wrt M' u E and V.
Case 2: Either (a) there exists an atom A occurring negatively in W and a V*
compatible with V such that the J-instance AJ•V* of A wrt V* is in M' \ M or (b)
there exists an atom B occurring positively in Wand a V* compatible with V such
that the J-instance BJ•V* of B wrt V* is in M \ M'.
Case 2(a):
Then
AJ,V* E (M' \ Mil) u (Mil \ M)
and,
hence,
either
AJ•V* E posinstD".D'.J or AJ,V* E neginstD",D,J' In the first case, AJ,V* is also
a J-instance of an atom F E posD".D"
By lemma 15.2 (a), A and F are unifiable
with mgu a', say.
Let a be the restriction of a' to xl'''''xn.
By supposition,
\i(W'a) is true wrt M' u E. It then follows from lemma 15.2 (b) that W' is true
wrt M' u E and V.
Similarly, in the second case, using 'P. we obtain that W' is
true wrt M' u E and V.
Case 2(b):
Then
BJ,V* E (M \ Mil) u (Mil \ M')
and.
hence.
either
BJ,V* E posinstD",D,J or BJ•V* E neginstD".D,.J' In the first case. BJ,V* is also
a J-instance of an atom G E posD".D' By lemma 15.2 (a). B and G are unifiable
with mgu \jI'. say.
Let \jI be the restriction of \jI' to xl'''''xn.
By supposition,
\i(W'\jI) is true wrt M' u E.
It then follows from lemma 15.2 (b) that W' is true
wrt M' u E and V.
Similarly, in the second case, using e. we obtain that W' is
true wrt M' u E and V.
(b) This part follows immediately from theorem 22.6 and part (a).
(c) Suppose D' u
{~\i(w'<I»} has a finitely failed SLDNF-tree, for some
<1> E e u 'P. By theorem 18.6 and lemma 22.1 -\i(w'<I» is a logical consequence
of comp(D').
By the consistency of comp(D'), W is not a logical consequence of
comp(D') and so D' violates W. I

166
Chapter 5. Deductive Databases
§24. Integrity Constraints
167
The theorem has an immediate corollary for the case when the transaction
consists of a single addition.
Corollary 24.6 Let D be a stratified database, C a database statement, and
D' = D u {C} a stratified database. Let W be an integrity constraint '<:Ix1'" '<:IxnW'
in prenex conjunctive normal form.
Suppose D satisfies W.
Let e = { 8.: 8 is the
restriction to xl'...,xn of either an mgu of an atom occurring negatively in Wand
an atom in posD D' or an mgu of an atom occurring positively in Wand an atom
,
in negD D' }. Then the following properties hold.
(a) D' s~tisfies W iff D' satisfies V(W'8) for all 8 E e.
(b) If D' u
{~V(W'8)} has an SLDNF-refutation for all 8 E e, then D' satisfies
W.
(c) If D' u
{~V(W'8)} has a finitely failed SLDNF-tree for some 8 E e, then D'
violates W.
Similarly, the theorem has a corollary\ for the case when the transaction
consists of a single deletion.
Corollary 24.7 Let D be a stratified database, C a database statement in D,
and
D' = D \ {C}
a
stratified
database.
Let
W
be
an
integrity
constraint
'<:Ixl···'<:IxnW' in prenex conjunctive normal form.
Suppose D satisfies W. Let 'P =
{ \jf: \jf is the restriction to xl,...,xn of either an mgu of an atom occurring
positively in W and an atom in posD',D or an mgu of an atom occurring negatively
in W and an atom in negD',D}' Then the following properties hold.
(a) D' satisfies W iff D' satisfies V(W'\jf) for all \jf E 'P.
(b) If D' u
{~V(W'\jf)} has an SLDNF-refutation for all \jf E 'P, then D' satisfies
W.
(c) If D' u
{~V(W'\jf)} has a finitely failed SLDNF-tree for some \jf E 'P, then D'
violates W.
Next
we
briefly
discuss
some
implementation
issues
related
to
the
simplification theorem.
The theorem shows that the implementation of the
simplification method involves calculating four atom sets posD" D"
negD" D"
,
,
posD" D' and negD" D' computing e and 'P, and then evaluating each query
~V(W'<l», where
<l> ~ e u \P'.
Note that the method is independent of the level
mappings used to show that the databases are stratified.
Some special cases of the theorem are of interest. If e u 'P is empty, then the
corresponding integrity constraint W can be eliminated from further consideration,
since the theorem shows that D' satisfies W.
If e u 'P contains the identity
substitution, then no simplification of W is possible.
Nicolas [78] also studied
various refinements of the basic idea which could lead to optimisations of the
implementation. We do not discuss these optimisations here except to note that all
of them are equally applicable to stratified databases.
The key to an efficient implementation of the simplification theorem is to find
an efficient way to calculate posD,D' and negD,D"
for D !:;;; D'. We emphasise that
this calculation only involves the rules and not the facts in D. This is an important
point because, even for a large deductive database, the number of rules is likely to
be very much smaller than the number of facts. In particular, the rules are likely to
be kept in main memory, so that access to the disk during the calculation of these
sets is obviated.
We now briefly consider some aspects of the computation of the atom sets. In
principle, this computation involves the calculation of infinitely many sets pos~,D'
and neg~ D" for n~O.
However, in practice, we can often use a stopping rule to
terminate 'the computation after only finitely many steps.
Application of one such
stopping rule involves computing sets of atoms pn and Nn rather than the sets
posn
,and nel
'.
pn and Nn are defined and used in much the same way as
D,D
D,D
po~
,and neg~
"except for the following additional (simplifying) step.
We
,D
,D
n
n...
.
_k
omit any atom from P
(resp., N ) which is an mstance of another atom m V-
(resp., Nk), for O$;k$;n.
The stopping rule is then as follows. If after deletions in this manner, some pn
and Nn both become empty, then terminate the computation and use the unions, P
and N, of the respective sets of atoms computed thus far in place of posD,D' and
negD D' .
The proof of the simplification theorem is valid for the sets P and N
used 'in place of posD D' and negD D"
A further refinement is to delete from P
(resp., N) any atom ~hich is an in'stance of another atom in P (resp., N).
The
example below illustrates the application of this stopping rule.
Example Let D be the database
no_male_descendant(x) ~ '<:Iy (female(y) ~ ancestor(x,y»
ancestor(x,y) ~ parent(x,z) /\ ancestor(z,y)
ancestor(x,y) ~ parent(x,y)

168
Chapter 5. Deductive Databases
Problems for Chapter 5
169
parent(x,y) ~ mother(x,y)
parent(x,y) ~ father(x,y)
together with facts for the predicate symbols mother, father, male and female.
If
we give no_male_descendant levelland all other predicate symbols level 0, then
we see that D is a stratified database. Let C be the clause
mother(Mary, Bill) ~
and let D' = D u {C}. Then we obtain
pos~,D' = (mother(Mary, Bill)} = pO
o
0
negD,D' = {} =N
posb,D' = (parent(Mary, Bill)} = pI
1
1
negD,D' = {} = N
po~,D' = {ancestor(Mary, Bill), ancestor(Mary, y)}
p2 = {ancestor(Mary, y)}
2
2
negD D' = {} =N
,
POS~,D' = {ancestor(x, Bill), ancestor(x, y)}
p3 = (ancestor(x, y)}
neg~,D' = (no_male_descendant(Mary)} = N3
posi"D' = (ancestor(x, Bill), ancestor(x, y)}
p4 = {}
negb,D' = (no_male_descendant(x)} =if
p5 = {}
N5 = {}
At
this point,
we can
apply
the stopping rule.
Thus,
when
applying
the
simplification theorem, in place of posD,D"
we can use the set P = (mother(Mary,
Bill), parent(Mary, Bill), ancestor(x, y)} and, in place of negD,D"
we can use the
set N = (no_male_descendant(x)}.
Another possibility in the computation of posD D' and negD D' is that one or
both of them may contain infinitely many "independent" atoms, in which case the
simplification method may require checking infinitely many instances of an
integrity constraint. For example, let D be the database
p(f(x),y) ~ p(x,y),
C the clause
p(a,b)~, and D' = D u {C}.
Then posD,D' is the infinite set
(p(a,b), p(f(a),b), p(f(f(a»,b), ...}.
In this case, the previous stopping rule is not
applicable.
However, we can add the instance, p(f(x),b), of the head of the
offending clause in D to posb D' instead of p(f(a),b). If we do this, we can use
(p(a,b), p(f(x),b)} in place of posD D"
This example suggests the existence of
another stopping rule, which replac~s an infinite set of atoms by a single more
general instance of a statement head.
The simplification method appears to be an essential ingredient of any efficient
method of checking integrity constraints.
The main issues which require further
research are finding more powerful stopping rules and investigating the various
techniques which will be required for a really practical implementation.
PROBLEMS FOR CHAPTER 5
1. Let W be a formula and W' a prenex conjunctive normal form of W obtained by
applying the transformations of problem 5 of chapter 1. Prove that an atom occurs
positively (resp., negatively) in W iff it occurs positively (resp., negatively) in W'.
2. Let <I> be a hierarchical type theory. Prove that there are only finitely many
ground terms of each type.
3. Let D be a database and Q a query ~W. Prove that every computed answer for
D u {Q} is a ground substitution for all the free variables in W.
4. Give an example to show that lemma 22.1 no longer holds if we omit the
domain closure axioms from the equality theory.
5. Prove lemma 22.5
6. (a) Consider the database D
p(a)~
q(a)~
q(b)~
r(a)~

170
Chapter 5. Deductive Databases
Problems for Chapter 5
171
and the query Q
~ '<:Ix/'t (q(x)~p(x))
1\ -r(y)
where p, q and r have type 't and the constants of type 't are a and b.
Show the
result of transforming D and Q into a normal program and goal, which is required
by the query evaluation process.
Hence compute the answer(s), if any, to the
query Q.
(b) Repeat (a) for the query
~ '<:Iy/'t (p(y) ~ '<:Ix/'t r(x))
7. Consider the supplier-part-job database of §21.
(a) The following query is ambiguous:
Is it true that each red part is supplied by a supplier located in Perth?
Find two possible meanings for the query and for each of these meanings write
down the corresponding (fIrst order logic) query ~W.
(b) For each of the (fIrst order logic) queries of part (a) show the normal program
and goal which results from the query transformation process.
(c) Write each of the (fIrst order logic) queries of part (a) in SQL [25].
(d) Compare fIrst order logic and SQL as query languages with regard to
expressiveness, semantic clarity, conciseness and simplicity.
8. Prove lemma 22.7.
9. Prove lemma 23.2.
10. Let D be a database and Q a query.
Suppose that D u {Q} has a fInitely
failed SLDNF-tree. Prove that Q is a logical consequence of comp(D).
11. Let D be a definite database and Q a defInite query.
Suppose that Q is a
logical consequence of comp(D).
Prove that every fair SLD-tree for D u {Q} is
fInitely failed.
12. Complete the details of the proof of lemma 24.4(b).
13. Let D be the database
no_male_descendant(x) ~ '<:Iy (female(y) ~ ancestor(x,y))
ancestor(x,y) ~ parent(x,z) 1\ ancestor(z,y)
ancestor(x,y) ~ parent(x,y)
parent(x,y) ~ mother(x,y)
parent(x,y) ~ father(x,y)
together with facts for the predicate symbols mother, father, male and female. Let
D' be the database obtained by adding to D the facts
father(John, Fred)~
mother(Jane, Fred)~
(a) Calculate posD D" negD D" P, and N.
.
(b) For each of th~ integrity constraints below, state which instances of them wIll
need to be checked when the database changes from D to D', assuming D satisfies
the integrity constraints.
(i) '<:Ix (male(x) ~ 3y father(x,y))
(ii) '<:Ix (-3y mother(x,y) v -3z father(x,z))
(iii) '<:Ix '<:Iy (no_male_descendant(y) ~ ancestor(x,y) 1\ no_male_descendant(x))
(iv) '<:Ix'<:ly (-parent(x,y) v -parent(y,x))

Chapter 6
PERPETUAL PROCESSES
A perpetual process is a definite program which does not terminate and yet is
doing useful computation, in some sense.
With the advent of PROLOG systems
for concurrent applications [18], [93], [106], especially operating systems, more
and more programs will be of this type. Unfortunately, the semantics for definite
programs developed in chapter 2 do not apply to perpetual processes, simply
because they do not terminate. In this chapter, starting from the pioneering work
of Andreka, van Emden, Nemeti and Tiuryn [2], we discuss the basic results of a
semantics for perpetual processes.
§25. COMPLETE HERBRAND INTERPRETATIONS
In this section, we introduce complete Herbrand interpretations. We define the
complete Herbrand universe and base and prove that they are compact metric
spaces under a suitable metric.
Some elementary notions from metric space
topology, all of which can be found in [29], for example, will be required.
The complete Herbrand universe for a definite program is the collection of all
(possibly infinite) terms which can be constructed from the constants and function
symbols in the program.
Thus our first task is to give a precise definition of a
(possibly infinite) term, which extends the definition given in §2 of a (finite) term.
Let ro* denote the set of all finite lists of non-negative integers.
Lists are
denoted by [il'...,ik], where il'".,ikero. If m,nero*, then [m,n] denotes the list
which is the concatenation of m and n. If nero* and iero, then [n,i] denotes the
list [n,[i]]. We let IXI denote the cardinality of the set X. Similarly, if nero*, then
Inl denotes the number of elements in n.

174
Chapter 6. Perpetual Processes
§25. Complete Herbrand Interpretations
175
Definition We say T !:; ro* is a tree if the following conditions are satisfied:
(a) For all nero* and for all i,jero, if [n,i]eT and j<i, then neT and [nj]eT.
(b) I{i : [n,i]eT}1 is finite, for all neT.
Definition A tree T is finite if T is a finite subset of ro*.
Otherwise, T is
infinite.
Example The finite tree ([], [0], [1], [2], [1,0], [1,1], [2,0], [2,1], [2,2]) can be
pictured as in Figure 7.
The infinite tree ([], [0], [1], [1,0], [1,1], [1,1,0], [1,1,1], [1,1,1,0], [l,l,l,l],...}
can be pictured as in Figure 8.
[]
[0]
[1,0]
[1,1]
[2,0] [2,1]
[2,2]
Fig. 7. A finite tree
[]
[1,1,1,0]
Fig. 8. An infinite tree
[1,1,1,1]
Intuitively, each neT is a node of the tree T. Condition (b) in the definition of
tree states that each node has bounded degree.
We let S be a set of symbols and ar be a mapping from S into ro, which
determines the arity of each symbol in S.
Definition A term (over S ) is a function t : dom(t) -7 S such that
(a) The domain of t, dom(t), is a non-empty tree.
(b) For all nedom(t), ar(t(n)) = I{i : [n,i]edom(t)}1.
We say the tree dom(t) underlies t. We let TermS denote the set of all terms
over S.
Intuitively, a term is a (possibly infinite) tree, whose nodes are labelled by
symbols in such a way that the arity of the label of each node is equal to the
degree of that node.
Definition The term t is finite if dom(t) is finite. Otherwise, t is infinite.
Definition Let t be a term. The depth, dp(t), of t is defined as follows:
(a) If t is infinite, then dp(t) = 00.
(b) If t is finite, then dp(t) = 1 + max{lnl : nedom(t)}.
It will be convenient to have available the concept of the truncation at depth n
(nero) of a term t, denoted by an(t). For this purpose, we introduce a new symbol
Q of arity 0, which will be used to indicate that a branch of the term t has been
cut off in the truncation. Thus an is a mapping from TermS into TermS u {Q}
defined as follows:

176
Chapter 6. Perpetual Processes
§25. Complete Herorand Interpretations
177
Ultrametric spaces have topological properties rather similar to discrete metric
spaces [5].
Definition
(X,d) is a metric space, if d is a metric on X.
If d IS an
ultrametric, then (X,d) is an ultrametric space.
Clearly, o.n(t) is a finite tenu with dp(o.n(t»
:=;; n+1.
TenuS can be made into a metric space in a natural way.
First, we recall the
definition of a metric space [29].
Now let s,~eTenuS' If s:¢:!:, then it is clear that o.n(s);t:o.n(t), for some n>O.
Consequently, If s;t:t, then {n : o.n(s);t:o.n(t)} is not empty.
We define o.(s,t) =
min{n: o.n(s);t:o.n(t)}. Thus o.(s,t) is the least depth at which s and t differ.
Proposition 25.1 (TenuS' d) is an ultrametric space, where d is defined by
d(s,t) = 0,
if s=t
= 2-<X.(s,t),
otherwise.
A crucial fact about TenuS is given by the following proposition [72].
Proposition 25.2 (TenuS' d) is compact iff S is finite.
Proof Suppose first that S is infinite.
Let {ts : se S} be any collection of
tenus with the property that ts(O)=s (that is, the root is labelled by s). If s1;t:s2'
then d(t
,t
) = 1/2. Thus TenuS is not compact.
s1 s2
Conversely, suppose that S is finite.
Let {tk}keco be a sequence in TenuS'
We consider two cases.
(a) There exists meco and peco such that, for all n"?p, we have dp(tn):=;;m.
Since S is finite, there are only a finite number of tenus over S of depth :=;; m.
Hence {tk}keco must have a constant and, hence, convergent subsequence.
(b) Given meco and peco, there exists n"?p such that dp(tn»m.
In this case, we can suppose without loss of generality that the sequence
{tk}keco is such that dp(tk»k, for keco. Note that every subsequence of {tk}keco
has the property that the depths of the tenus in the subsequence are unbounded.
We define by induction an infinite tenu teTenuS such that, for each n"?1, there
exists a subsequence {tkm}meco of {tk}keco with o.n(tkm) = o.n(t), for me co.
Suppose first that n=1.
Since S is finite, a subsequence
{~ }meco of
m
{tk}keco must have the same symbol, say s, labelling their root nodes. We define
t([]) = s.
Next suppose that t is defined up to depth n. Thus there exists a subsequence
{tk }
of {tk}k
such that a. (tk ) = a. (t), for meco.
Since S is finite,
m meco
eco
n
m
n
there exists a subsequence {~
}peco of {~ }meco such that the o.n+1(~
) are
m
m
mp
all equal, for peco. Define the n~es at depth n+1 for t in the same way as each of
the tk
. This completes the inductive definition.
m
Sin~e it is clear that t is an accumulation point of {tk }keco' we have shown
that TermS is compact.
I11III
Now we are in a position to define the complete Herbrand universe. Let P be
a definite program and F be the finite set of constants and function symbols in P.
We regard constants as function symbols of arity O.
~.
Thus t
~t
n
The closure of a
(a) dom(o.n(t» = {medom(t) : Iml:=;;n}.
(b) o.n(t) : dom(o.n(t»
~ S v in} is defined by
o.n(t)(m) = t(m),
if Iml < n
= n,
if Iml = n.
Definition Let X be a set.
A mapping d : X x X ~ non-negative reals is a
metric for X if
(a) d(x,y) = 0 iff x=y, for all x,yeX.
(b) d(x,y) = d(y,x), for all x,yex.
(c) d(x,z) :=;; d(x,y) + d(y,z), for all x,y,zeX.
d is an ultrametric [5] if
(d) d(x,z) :=;; max{d(x,y), d(y,z)}, for all x,y,zex.
Proof Straightforward. (See problem 1.)
I11III
Convergence in the topology induced by d is denoted by
means that the sequence {t }
converges to t in this topology
n neco
.
set A in this topology is denoted by A.
Definition A metric space (X,d) is compact if every sequence in X has a
subsequence which converges to a point in X.
Definition The complete Herbrand universe Up for P is TenuF. The elements
of Up are called ground terms.

178
Chapter 6. Perpetual Processes
§25. Complete Herbrand Interpretations
179
Thus Up is the set of all ground (possibly infinite) terms which can be formed
out of the constants and function symbols appearing in P.
It is straightforward to
show that "ground term", as defined in §3, can be identified with "finite ground
term", as just defined. (See problem 2.) This identification is taken for granted
throughout this chapter. Thus we have Up k;; Up. As long as P contains at least
one function symbol, it is clear that Up is a proper subset of Up.
We
adopt the convention throughout this
chapter that "term", without
qualification, will always mean a possibly infinite term.
If a term is finite, this
will always be explicitly stated.
Despite the fact that we have given a rather formal definition of term, in the
material which follows we will rarely make direct reference to this definition,
relying instead on the reader's intuitive understanding of a term.
All the
arguments presented could easily be formalised, if desired.
We will also find it
convenient to use a more informal notation for terms.
In particular, for finite
terms we will continue to use the old notation.
Example fff... is the infinite term pictured in Figure 9.
f(a,f(a,f(a,...») is the infinite term pictured in Figure 10.
Proposition 25.3 Let P be a definite program. Then Up is a compact metric
space, under the metric d introduced earlier.
Proof The result follows from proposition 25.2, since the set of constants and
function symbols in P is finite.
II1II
The proof of the next result is straightforward. (See problem 3.)
Proposition 25.4 Let P be a definite program. Then Up is dense in Up, under
the topology induced by d.
Up is called "complete" because it is the completion [29] of the metric space
Up'
We will also require the concept of a (possibly infinite) atom.
Let P be a
definite program, F be the set of constants and function symbols in P, R be the set
of predicate symbols in P and V be the set of variables in P (more precisely, the
first order language underlying P). All variables have arity O.
Definition An atom A is an element of TermVuFuR such that A(n)eR iff
n=[], for all nedom(A).
f
f
f
Fig. 9. The infinite term fff...
Thus an atom is a term with the root node (only) labelled by a predicate
symbol.
Just as we did for terms, we can identify "finite atom", as just defined,
with "atom", as defined in §2.
Whenever an atom is finite, this will always be
explicitly stated in this chapter.
Definition The complete Herbrand base Bpfor a definite program P is the set
of all terms A in TernL..
for which A(n)eR iff n=[], for all nedom(A).
The
ruR
elements of Bpare called ground atoms.
Thus B' is the set of all ground (possibly infinite) atoms which can be formed
P l '
out of the finite set of constants, function symbols and predicate symbo s appeanng
in P. Note that Bp k;; Bp.
Proposition 25.5 Let P be a definite program.
Then Bpis a compact metric
space, under the metric d introduced earlier.

180
Chapter 6. Perpetual Processes
§25. Complete Herbrand Interpretations
181
Fig. 10. The infinite term f(a,f(a,f(a,...»)
Proof Te~UR is compact, by proposition 25.2. It is easy to show that B' is
p
a closed and, therefore, compact subspace of Te~UR' l1li
Proposition 25.6 Let P be a definite program. Then Bp is dense in Bp, under
the topology induced by d.
Proof Straightforward.
l1li
The concept of a substitution applied to an atom in §4 can be easily
generalised to the present more general definition of atom and term.
We restrict
attention to ground substitutions applied to finite atoms, which is all that is needed
in this chapter.
Definition A ground substitution S is a finite set of the form {v It
v. It }
.
.
1 1"'"
k' k '
where each VI' IS a vanable, the variables are distinct and t.e U'
Dor 1'=1
k
1
p'
,..., .
Definition Let A
be a finite atom with variables
{vl""'vk} and S =
{vI/tl'...,vI!tk} be a ground substitution. Then AS is the ground atom defined as
follows:
(a) dom(AS) = dom(A) u {[m,n] : medom(A), A(m)=Vi and nedom(ti), for some
ie {I,...,k}}.
(b) AS : dom(AS) -+ FuR is defined by
AS(m)
A(m), if medom(A) and A(m)li {v1,...,vk}
AS([m,n]) = ti(n), if medom(A), A(m)=vi and nedom(ti), for some ie {I,...,k}.
We say AS is a ground instance of A. The collection of all ground instances
of the finite atom A is denoted by [[Al]. Note that [A] ~ [[All ~ Bp'
Proposition 25.7 Let P be a definite program and C = {Al'...,Am} be a set of
finite atoms with variables xl'''''xn, Consider the mapping
Sc : (Up)n -+ (Bp)m
defined by
SC(tI,···,tn) = (AIS,...,AmS),
where S = {xIltl'""xn/tn}' Then Sc is continuous, where (Up)n and (Bp)m are
each given the product topology.
Proof Suppose that {(tI,k,...,tn,k)}kero converges to (tl'...,tn) in the product
topology on (Up)n. Put Sk = {xI/tI,k"",xn/tn,k}' for kero.
Clearly AiSk -+ AiS,
for i=I,...,m, and hence Sc is continuous.
l1li
Proposition 25.8 Let A be a finite atom. Then [[Al] is a closed subset of Bp.
Proof Put C = {A}.
If A has n variables, then [[A]] = Sc<(Up)n). Since Sc
is continuous and Up is compact, SC«Up)n) is a compact and, therefore, closed
subset of Bp.
l1li
Proposition 25.9 Let A be a finite atom. Then [A] = [[A]].
Proof Since [A] ~ [[All and [[Al] is closed, [A] ~ [[Al]. On the other hand, if
C={A} and A has n variables, then [[Al] = SC<(Up)n) = SC«Up)n)
~ SC<(Up)n)
= [A], by propositions 25.4 and 25.7.
l1li
We
conclude
this
section
with
the definition of a complete Herbrand
interpretation and the mapping Tp'
Definition Let P be a definite program. An interpretation for P is a complete
Herbrand interpretation if the following conditions are satisfied:

182
Chapter 6. Perpetual Processes
§26. Properties of T'p
183
(a) The domain of the interpretation is the complete Herbrand universe Up'
(b) Constants in P are assigned themselves in Up'
(c) If f is an n-ary function symbol in P, then the mapping from (Up)n into Up
defined by (tl'...,tn) --? f(tl'...,tn) is assigned to f.
We make no restrictions on the assignment to the predicate symbols in P, so
that different complete Herbrand interpretations arise by taking different such
assignments.
In an analogous way to that in §3, we identify a complete Herbrand
interpretation with a subset of Bp' The set of all complete Herbrand interpretations
for P is a complete lattice under the partial order of set inclusion.
Definition Let P be a definite program. A complete Herbrand model for P is a
complete Herbrand interpretation which is a model for P.
We
also
define
a mapping Tp
from
the lattice of complete Herbrand
interpretations to itself as follows. Let I be a complete Herbrand interpretation.
Then Tp(I) = {AeBp : A~Bl"...,Bn is a ground instance of a clause in P and
{Bl'...,Bn} k I}.
Note that Tp is Ti, for the pre-interpretation J consisting of the domain Up and
the above assignments to constants and function symbols. It turns out that because
of the compactness of Up and Bp, Tp has an even richer set of properties than Tp'
We explore these properties in the next section.
§26. PROPERTIES OF Tp
In this section we establish various important properties of Tp, notably that
gfp(Tp) = Tp.J-ro.
We begin with four results, which are the analogues for Tp of propositions 6.1,
6.3 and 6.4 and theorem 6.5. The proofs of these results are essentially the same
as the earlier ones.
Proposition 26.1 (Model Intersection Property)
Let P be a definite program and {Mi}ieI be a non-empty set of complete
Herbrand models for P. Then (\eIMi is a complete Herbrand model for P.
We let Mp denote the least complete Herbrand model for P.
Thus Mp is the
intersection of all complete Herbrand models for P.
Proposition 26.2 Let P be a definite program.
Then the mapping Tp is
continuous (in the lattice-theoretic sense of§5).
Proposition 26.3
Let P be a definite program and I be a complete Herbrand
interpretation for P. Then I is a model for P iff Tp(I) k I.
Theorem 26.4 Let P be a definite program. Then Mp = Ifp(Tp) = Tpi roo
The next result is due to Andreka, van Emden, Nemeti and Tiuryn [2].
Theorem 26.5 (Closedness of Tp)
Let P be a definite program and I be a closed subset of Bp' Then Tp(I) is a
closed subset of Bp. Furthermore, Tp(J) k Tp(J), for J k Bp.
Proof Let I be a closed subset of Bp. We show Tp(I) is closed. It is sufficient
to consider the case when P consists of a single clause, say, A~Al'...,Am·
Suppose the clause has n variables.
Put C={A, Al'...,Am} and let Sc be the
associated mapping defined in §25.
Since Sc is continuous and Up is compact,
we have that Sd(Up)n) is a closed subset of (Bp)m+1.
Let 1t denote the
m+l
Th
T' (I)
projection
from
(Bp)
onto
its
first
component.
en
P
1t(Sd(Up)n) n(Bp x 1m» and thus Tp(I) is closed.
For the last part, it is straightforward to show that T'p maps closed sets to
closed sets iff Tp(J) k Tp(J), for J k Bp'
II1II
Corollary 26.6 Tp.J-k is closed, for kero. Furthermore, Tp.J-ro is closed.
Note
carefully that we do
not necessarily
have
the
opposite inclusion
Tp(J) ;;;:1 Tp(J), for J k Bp.
Example Let P be the program
q(a) ~ p(f(x),f(x»
_
Let J = {p(t,f(t» : teUp}. Then Tp(J)={q(a)}, but Tp(J)=0.
Next we establish an important weak continuity result for Tp.
For this we
need the concept of the limit superior of a sequence of subsets of a metric space
[5].
Definition Let (X,d) be a metric space and {Yn}ne ro be a sequence of subsets
of X
Then we define LS
(Y ) = {xeX : for every neighbourhood V of x and
.
nero
n
for every me ro, there exists ~m such that V n Yk:;c0}.

184
Chapter 6. Perpetual Processes
§26. Properties of Tp
185
Proof We have that
Tp( IlkeroIk)
= Tp(LSke ro(Ik))'
~ LSkero(Tp(Ik))'
= 11ke roTp(Ik)'
If {Yn}nero is a decreasing sequence of closed sets, it is easy to show that
LS
(Y)=11
Y
nero
n
ne ro n'
Theorem 26.7 (Weak Continuity of Tp)
Let P be a definite program and (Ik}kero be a sequence of sets in Bp' Then
LSkero(Tp(Ik)) ~ Tp(LSkero(Ik))'
Proof Suppose AeLSkero(TP(Ik))'
Then, for every neighbourhood V of A,
there exist infinitely many k such that V 11Tp(Ik);t0. Since P is finite, there exist'
a clause AOf-Al'...,Am in P, a subsequence {Ikp}pero of {Ik}kero and a sequence
{ep}pero of ground substitutions for the variables xl'...,xn of the clause such that
AOep~A and AjepeIk ' for j=l,...,m and pero.
p
Suppose ep is {x1/tl,p,...,xr/tn,p}'
Since Up is compact, we can assume
without
loss
of
generality
that
(tl p,...,t
)~(tl,...,t),
say.
Put
e
=
,
n,p
n
{x1/tl' ,xr/tn}·
By
proposition
25.7,
we
have
that
(AOep,
,Amep)~(AOe, ...,Ame).
Since
AOep~A,
we
have
that
AOe=A.
Furthermore, since Ajep~Aje, we have that AjeeLSkero(Ik)' for j=l,...,m. Hence
Ae Tp(LSke ro(Ik)). I
Note that we do not generally have LSkero(Tp(Ik)) = Tp(LSkero(Ik))'
Example Consider the program
q(a) f- p(f(x),f(x))
Pu
k
k+l
t
Ik={p(f (a),f
(a))},
for
kero.
Then
LSkero(Ik)={p(fff...,fff...)}.
Thus
Tp(LSkero(Ik))={q(a)}, but LSkero(Tp(Ik))=0.
Corollary 26.8 (Intersection Property for Tp)
Let P be a definite program and (Ik}kero be a decreasing sequence of closed
sets in Bp. Then Tp( Il keroIk) = IlkeroTp(Ik)'
since the Ik are closed and decreasing
by theorem 26.7
since the Tp(Ik) are closed and decreasing.
We cannot drop the requirement that each Ik be closed in corollary 26.8.
Example Consider the program
q(a) f- p(f(x))
Let Ik be (p(f\a)) : n~k}, for kero.
Then (Ik}kero is a decreasing sequence.
Furthermore, Il keroIk=0, so that Tp( Il keroIk)=0.
However, Tp(Ik) = (q(a)},
for ke roo Thus 11ke roTp(Ik)={q(a) }.
Part (a) of the next theorem is due to Andreka, van Emden, Nemeti and Tiuryn
[2]. Recall that it can happen that gfp(Tp);tTpJ.ro.
Theorem 26.9 Let P be a definite program. Then we have
(a) gfp(Tp) = TpJ.ro.
(b) Tp( Il keroTpJ.k);d Il keroTpJ.k.
Proof (a) It suffices to show that Tp(TpJ.ro)=TpJ.ro. Now we have
Tp(TpJ.ro)
= Tp( Il keroTPJ.k)
= IlkeroTP(TpJ.k),
by corollaries 26.6 and 26.8
= TpJ.ro.
(b) We have
Tp( IlkeroTpJ.k)
= 11keroTp(fpJ.k),
by corollary 26.8
;d 11ke roTp(TpJ.k),
by theorem 26.5
~ IlkeroTpJ.k. I
It is apparent that the essential reason that gfp(Tp)=TpJ.ro is because Up is
compact. We generally have gfp(Tp);tTpJ.ro precisely because limits of sequences
of finite terms are missing from Up'
In many respects, Tp, Up and Bp give a
more appropriate setting for the foundations of logic programming than Tp, Up
and Bp'

186
Chapter 6. Perpetual Processes
§26. Properties of Tp
187
Note that (")keolpJ..k may not be a fixpoint of Tp.
Example Let P be the program
q(a) f- p(x,f(x))
p(f(x),f(x)) f- p(x,x)
Then (")keolpJ..k = {p(fff...,fff...)}, but Tp( (")keclpJ..k) = {q(a), p(fff...,fff...)}.
Proposition 26.10 Let P be a definite program. Then we have
(a) TpJ..k = TpJ..k, for k=O, 1.
(b) TpJ..k
~ TpJ..k, for l.e2.
Proof By corollary 26.6, TpJ..k is closed, for keco. Also it is easy to show by
induction that TpJ..k ~ TpJ..k, for keco.
Thus we have TpJ..k ~ TpJ..k, for keco.
Furthermore, TpJ..O = Bp = Bp = TpJ..O.
Finally, we leave the proof that TpJ..l =
TpJ..l to problem 9. I
Note that TpJ..k may be a proper subset of TpJ..k, for l.e2. (See problem 10.)
Proposition 26.11
Let P be a definite program. Then TpJ..co
C (")k
T J..k
-
eco P
~ TpJ..co.
Proof We have
TpJ..co
= (")kecoTpJ..k
~ (")kecoTpJ..k
~ (")kecoTpJ..k,
by proposition 26.10
= TpJ..co. I
Note that both of the inclusions in proposition 26.11 may be proper.
(See
problem 11.)
Next, we prove a useful characterisation of (")
T 'k
keco p-.v .
Theorem 26.12 Let P be a definite program and Ae Bp. Then the following
are equivalent:
(a) Ae (")kecoTpJ..k.
(b) There exists a sequence {Ak}keco such that AkeTpJ..k, for keco, and Ak
~A.
(c) There exists a finite atom B and a non-failed fair derivation f-B=GO' G1,...
with mgu's aI' a2,... such that Ae (")keco[[Ba1...ak]].
(If the derivation is
successful, then the intersection is over the finite set of non-negative integers
which index the goals of the derivation).
Proof The equivalence of (a) and (b) is left to problem 12.
(c) implies (a).
Suppose (c) holds.
By proposition 25.9, we have that
Ae (")
co [Ba1·..a ]. By proposition 13.5, given keco, there exists neco such that
ne
n
----
[Ba1...an] ~ TpJ..k. Hence Ae (")kecoTpJ..k.
(b) implies (c). For this proof, we ensure fairness in all derivations by always
selecting atoms as follows.
We select the leftmost atom to the right of the
(possibly empty set of) atoms introduced at the previous derivation step, if there is
such an atom; otherwise, we select the leftmost atom.
Let {Ak}keco be a sequence such that AkeTpJ..k, for keco, and Ak~A. Since
AkeTpJ..k, proposition 13.4 shows that there is a derivation Dk beginning with
f-Ak, which is either successful (that is, Dk is a refutation of P v {f-Ak}) or has
length> k. We consider two cases.
(1) Given meco and peco, there exists n~p such that Dn has length> m.
In this case, by passing to an appropriate subsequence, we can assume without
loss of generality that the sequence {Ak}keco is such that AkeTpJ..k, for keco,
Ak~A and Dk has length > k.
We now prove by induction that there exists a finite atom B and an infinite
fair derivation f-B=GO' G1,... with input clauses Cl' C2,... such that, for each
neco, there exists a subsequence {Akm}meco of (Ak}keco' where Cl'""Cn+1 are
the same (up to variants) as the first n+1 input clauses of each of the Dk
and
m
Gn+1 is more general than the (n+l)th goal in Dkm, for meco.
Suppose first that n=O.
Since P contains only finitely many clauses, a
subsequence {Ak }
of {Ak}k co must use the same program clause, say E, in
m meco
e
the first step of Dk . We let B be the head of E and let C1 be a suitable variant of
m
E.
Next suppose the result holds for n-l. Thus there exists a finite atom B and a
fair derivation f-B=GO' Gl'...,Gn via R with input clauses Cl'""Cn such that there
exists a subsequence {Ak }
of {Ak}k co' where C1,...,C
are the same (up to
m meco
e
n
variants) as the first n input clauses of each of the Dk
and G
is more general
m
n
than the nth goal in Dk ' for me co. Note that as the lengths of the Dk
are
m
m
unbounded, the nth goal in each Dk
is not empty. Furthermore, the same atom is
m

188
Chapter 6. Perpetual Processes
§27. Semantics of Perpetual Processes
189
selected in the nth goal of each Ok
Since P contains only finitely many clauses,
m
a subsequence {Ak
}
co of {Ak
}
co must use the same program clause, say
m
pe
m me
F, as the (n+l)th inCut clause of the derivation Ok
. It is clear that (a suitable
m
variant of) F can be used as Cn+l' This completes th~ induction argument.
To finish off case (1), we have only to show that if 81, 82,,,, are the mgu's of
the derivation just constructed, then Ae [[B81...8n]]' for ne co.
However, this
follows from proposition 25.9, since, given neco, there exists a subsequence
{Ak }m co such that Ak
~A and Ak e[B81...8 ]. Thus A satisfies condition (c).
m
e
m
m
n
(2) There exists meco and peco such that, for all n~p, Dn has length S; m.
In this case, since each Ok is either successful or has length > k, we may
assume without loss of generality that there exists meco such that the sequence
{Ak}keco has the properties that Ak~A and each Ok is successful with length S;
m.
Because P is finite, there exists a subsequence {Ak }
co such that all the
m me
Ok
have exactly the same sequence of input clauses (up to variants). Suppose E
m
is the program clause used first in each of the Ok . We let B be the head of E and
m
construct a refutation of P U {f-B} of length S; m using the same sequence of
input clauses as each of the Ok . In a similar way to case (1), we can show that
m
A satisfies condition (c). I
§27. SEMANTICS OF PERPETUAL PROCESSES
As we stated above, a perpetual process is a definite program which does not
terminate and yet is doing useful computation, in some sense.
The problem is to
find the appropriate sense of an infinite computation being "useful".
We solve
this problem by introducing the concept of an infinite atom in Bp
being
"computable at infinity".
The set of all such atoms plays the role for perpetual
processes that the success set plays for programs which terminate.
The major
result of this section is that the set of all atoms computable at infinity is a subset
of gfp(Tp)'
Related results have been obtained by Nait Abdallah and van Emden
[76], [77], [108].
We begin with the key definition.
Definition Let P be a definite program and AeBp\Bp'
We say A is
computable at infinity if there is a finite atom B and an infinite fair derivation
f-B=GO' G1,... with mgu's 81' 82"" such that d(A,B81...8k)~0, as k~oo.
We put Cp = {AeBp\Bp : Ais computable at infinity}.
Example Let P be the program
p(f(x» f- p(x)
Since lfp(T )=0, this program does not compute anything in the sense of chapter
2.
Howev~r,
given the goal f-p(x),the atom p(fff...) can be "computed at
infinity". In fact, it is clear that Cp={p(fff...)}.
Example Let P be the program
fib(x) f- fib1(0.Lx)
fibl(x.y.z.w) f- plus(x,y,z), fibl(y.z.w)
plus(O,x,x) f-
plus(f(x),y,f(z» f- plus(x,y,z)
(Recall the convention that n stands for f"(0».
Clearly fib(L2.3.5.8. 13....)e Cp'
where the argument of fib is the Fibonacci sequence. We simply let B be fib(x)
and we obtain the approximating sequence fib(Lx1), fib(L2.x2)' fib(L2.3.x3),..· .
Example We consider Hamming's problem, which is to construct the sorted
sequence t of positive integers containing no prime factors other than 2, 3 or.5.
Thus the initial part of the sequence t is 2.3.4.5.6.8.9.10.12;15..... The followmg
program P to solve this problem appeared in [17] and [41].
hamming(x) f- seqprod(Lx,2,u), seqprod(Lx,3,v), seqprod(Lx,5,w),
merge(u,v,z), merge(z,w,x)
merge(x.u,y.v,x.w) f- y>x, merge(u,y.v,w)
merge(x.u,y.v,y.w) f- x>y, merge(x.u,v,w)
merge(x.u,x.v,x.w) f- merge(u,v,w)
seqprod(x.u,y,z.v) f- prod(x,y,z), seqprod(u,y,v)
f(x»f(y) f- x>y
f(x)>O f-
prod(x,O,O) f-
prod(x,f(y),z) f- prod(x,y,w), plus(w,x,z)
plus(O,x,x) f-
plus(f(x),y,f(z» f- plus(x,y,z)
Then it is clear that hamming(t)e Cpo

190
Chapter 6. Perpetual Processes
§27. Semantics of Perpetual Processes
191
Now we can give the main result of this chapter.
Theorem 27.2 (Soundness of SLD-Resolution for Perpetual Processes)
Let P be a definite program. Then Cp l:: gfp(Tp)'
We could have adopted a weaker definition of Cp in which we simply demand
that A e (l kero[[BS1'" Sk]]'
However, the following example shows that this
weaker definition doesn't properly capture the notion of "computable at infinity".
Example Let P be the program
p(f(x»
~ p(f(x»
Under the weaker definition, we would have p(fff...)eCp'
by theorem 26.12 and proposition 27.1
by proposition 26.11
by theorem 26.9. II
Proof We have
Cp
l:: (lkeroTp-l-k,
l:: Tp-l-ro,
= gfp(Tp),
Example Let P be the program
p(x,f(x»
~ p(x,x)
Then p(fff...,fff...)e gfp(Tp)\Bp, but p(fff...,fff...)iCpo The problem here is that no
matter what we choose for B in the definition of Cp' the computation will fail.
Note that p(fff...,fff...)e gfp(Tp)' because Tp does not respect the occur check.
In view of these developments, we propose the following setting for perpetual
processes. The intended interpretation of a perpetual process P is gfp(Tp)' This is
indeed a model for P.
gfp(Tp) is the analogue of the intended interpretation
Ifp(Tp) for (ordinary) definite programs. Cp is then the analogue of the success set
for
programs.
For
(ordinary)
definite
programs,
we
get
soundness
and
completeness, since Ifp(Tp) = success set. For perpetual processes, we only have
the soundness result Cp l:: gfp(Tp)'
As we have seen, completeness cannot be
achieved without further restrictions.
Taking a complete Herbrand model as the intended interpretation seems to be
the simplest and most natural way of providing a semantics for perpetual
processes. The results of this chapter suggest that gfp(Tp) should be the intended
Example Let P be the program
p(f(x»
~ p(f(x»
Then p(fff...)egfp(Tp)\Bp' but p(fff...)iCp'
Theorem 27.2 is the analogue for perpetual processes of theorem 8.3, which
states that the success set is equal to Ifp(Tp)'
Since Cp contains only infinite
atoms, it follows from theorem 27.2 that Cp l:: gfp(Tp)\Bp. It would be pleasant
if Cp=gfp(Tp)\Bp.
However, as the following examples show,
thi~. cannot be
achieved without some restrictions on P or modifications to the defimttons of Cp
and Tp or both.
Example Let P be the program
p(f(x» ~
Then p(fff...)egfp(Tp)\Bp' but p(fff...)iCp'
The next proposition gives a characterisation of Cp independent of the metric
Proof
We
have
to
show
that
d(A,BSl",Sk)~O,
as
k~oo,
iff
(lkero[[BS1...Sk]] = {A}.
We first suppose that (lkero[[BS1···Sk]] = {A}. Assume that there exists nero
such that, for all ke ro, we have
(Xn(A);tan(BS1",Sk)'
Then, for each ke ro,
(Xn(BSI...Sk) must have at least one node labelled by a variable.
Since (Xn(A) is
finite, it is clear that there exist a node in (X (A) and me ro such that, for ~m, the
n
corresponding node in BSI",Sk is labelled by a variable.
(The variable may
depend on k.) Consequently, (lkero[[BSr.Sk]] contains not just A, but infinitely
many ground infinite atoms. Thus our original assumption is incorrect and hence,
given
nero,
there
exists
kero
such
that
(Xn(A)=(Xn(BS1...Sk).
Then
d(A,BSI",Sk)~O, as k~oo.
Conversely, let us suppose that dCA, BSl",Sk)~O,
as
k~oo.
Since each
[[BSI··.Sk]]
is closed and
{[[BSI",Sk]]}kero is decreasing, it is clear that
Ae (lkero[[BSr'S~], Next suppose A'e (lkero[[BS1...Sk]].
Let E>O be given.
Choose m such that d(A,BS1...Sm)<E. Suppose A'=BSr.SmS, for some S. Thus
d(A, A')=d(A, BSr..SmS)<E.
Since E was arbitrary, we have that d(A,A')=O and
hence A=A'. Thus (lkero[[BSI",Sk]]={A}. II
d.
Proposition 27.1 Let P be a definite program and AeBp\Bp' Then AeCp iff
there is a finite atom B and an infinite fair derivation ~B=GO' 01"" with mgu's
SI' S2"" such that (lkero[[BS1...Sk]] = {A}.

192
Chapter 6. Perpetual Processes
193
Problems for Chapter 6
interpretation.
However, gfp(Tp) generally contains infinite atoms which are not
intuitively computable at infinity and thus we do not get completeness. For another
approach to this topic, we suggest the reader consult the paper by Levi and
Palamidessi [56].
This chapter leaves many questions unanswered.
Finding a satisfactory
semantics for perpetual processes and for communication and synchronisation
between concurrent processes is a current research problem.
We believe that the
appropriate setting in which to discuss such problems is the setting of Up, Bp and
T'p and that the basic results presented in this chapter will playa central role in
any satisfactory semantics.
PROBLEMS FOR CHAPTER 6
1. Prove proposition 25.1.
2. Prove that "finite ground term" as defined in §25 can be identified with
"ground term" as defined in §3.
3. Prove that Up is dense in Up'
4. Suppose I ~ Bp and AeBp' Prove that AeI iff AeI.
5. Find a definite program P and a complete Herbrand model I for P such that I is
not a model for P.
6. Show that we cannot drop the requirement that the sequence {Ik}keoo be
decreasing in corollary 26.8.
7. The set of all non-empty closed subsets of Bp can be made into a metric space
using the Hausdorff metric p defined by p(C,D)=max{h(C,D), h(D,C)}, where C
and D are non-empty closed subsets of Bp and h(C,D)=sup{d(x,D) : xeC}. (See
[29].)
(a) Show that, if A,BeBp' then p({A},{B}) = d(A,B).
(b) Show that, if {Cn}neoo is a decreasing sequence of closed subsets of Bp' then
{Cn}neoo is convergent in the topology induced by p and its limit is nneooCn'
(c) Restrict further attention to p such that Tp(0)~. This restriction and the fact
that Tp is closed imply that Tp is a well-defined mapping from the metric space of
non-empty closed subsets of Bp into itself.
Part (b) suggests that corollary 26.8
can be extended by proving that Tp is continuous in the topology induced by p.
Show that this conjecture is false.
8. Show that gfp(T' ) may no longer be equal to Tp.Loo if the definite program P is
allowed to consistPof an infinite number of clauses with an infinite number of
constants.
9. Prove that Tp.Ll = Tp.L1.
10. Find a definite program P such that Tp.L2 C Tp.L2.
11. Find a definite program P such that Tp.Loo C
nkeooTp.Lk C Tp.Loo.
A
T Ik l·ff the"e
l·S a sequence {Ak}keoo such that
12. Prove that
e n ke 00 p..v
•
AkeTp.Lk, for keoo, and Ak~A.
13. lllustrate theorem 26.12 with the program
p(f(x» f- p(x)
and with A = p(fff...).

REFERENCES
1.
Andreka, H.
and I. Nemeti,
"The Generalized Completeness of Hom
Predicate Logic as a Programming Language", Acta Cybernetica 4, 1 (1978),
3-10.
2.
Andreka, H., M. H. van Emden, I. Nemeti and J. Tiuryn, "Infinite-Term
Semantics for Logic Programs", draft manuscript, 1983.
3.
Apt, K. R., H. A. Blair and A. Walker, "Towards a Theory of Declarative
Knowledge",
in
Foundations
of
Deductive
Databases
and
Logic
Programming, Minker, 1. (ed.), Morgan Kaufmann, Los Altos, 1987.
4.
Apt, K. Ro and M. H. van Emden, "Contributions to the Theory of· Logic
Programming", J. ACM 29, 3 (July 1982), 841-862.
5.
Arnold, A. and M. Nivat, "The Metric Space of Infinite Trees: Algebraic
and Topological Properties", Fundamenta Informatica 3, 4 (1980), 445-476.
6.
Av-Ron, E., "Top-Down Diagnosis of Prolog Programs", MoSc. Thesis,
Weizmann Institute of Science, 1984.
7.
Bancilhon,
F.
and
R.
Ramakrishnan,
"An
Amateur's
Introduction
to
Recursive
Query
Processing
Strategies",
Proc.
ACM
Int.
Conf
on
Management of Data, Washington, D.C., 1986, 16-52.
8.
Battani, G. and H. Meloni, "Interpreteur du Language de Programmation
PROLOG", Groupe d'Intelligence Artificielle, Universite d'Aix-Marseille,
1973.
9.
Bibel, Wo, Automated Theorem Proving, Vieweg, Braunschweig, 1982.

196
References
197
References
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
Bowen, D. L., L. Byrd, D. Ferguson and W. Kornfeld, Quintus Prolog
Reference Manual, Quintus Computer Systems, Inc., May, 1985.
Bowen, K. A, "Programming with Full First-Order Logic", in Machine
Intelligence 10, Ellis Horwood, Chichester, 1982,421-440.
Byrd, L., "PROLOG Debugging Facilities", Working Paper, Department of
Artificial Intelligence, University of Edinburgh, 1980.
Chandra, A K and D. Harel, "Hom Clause Queries and Generalizations", J.
Logic Programming 2, 1 (1985), 1-15.
Chang, C. L. and R. C. T. Lee, Symbolic Logic and Mechanical Theorem
Proving, Academic Press, New York, 1973.
Clark, K. L., "Negation as Failure", in Logic and Data Bases, Gallaire, H.
and J. Minker (eds), Plenum Press, New York, 1978, 293-322.
Clark, K. L., "Predicate Logic as a Computational Formalism", Research
Report DOC 79/59, Department of Computing, Imperial College, 1979.
Clark,
K
L.
and
S.
Gregory,
"A
Relational
Language
for
Parallel
Pr
. "P
ogrammmg,
roc. ACM Corif'. on Functional Programming Languages
and Computer Architecture, Portsmouth, N.H., 1981, 171-178.
Clark, K
L. and S. Gregory, "PARLOG: A Parallel Logic Programming
Language", ACM Trans. on Prog. Lang. and Systems 8,1 (Jan. 1986), 1-49.
Clark, K L. and F. G. McCabe, "The Control Facilities of IC-PROLOG", in
Expert Systems in the Micro Electronic Age, Michie, D. (ed.), Edinburgh
University Press, 1979, 122-149.
Clark, K
L. and F. G. McCabe, micro-PROLOG: Programming in Logic,
Prentice-Hall, Englewood Cliffs, N.J., 1984.
Clark, KL. and s.-A. Tl1rnlund, "A First Order Theory of Data and
Programs", Information Processing 77, Toronto, North-Holland, 1977, 939-
944.
Colmerauer, A, H. Kanoui, P. Roussel and R. Pasero, Un Systeme de
Communication Homme-Machine en Francais, Groupe de Recherche en
23.
24.
25.
26.
27.
28.
29.
30.
31.
32.
33.
34.
35.
Intelligence Artificielle, Universite d'Aix-Marseille, 1973.
Cutland, N. J., Computability: An Introduction to Recursive Function Theory,
Cambridge University Press, Cambridge, 1980.
Dahl, V., "On Database Systems Development through Logic", ACM Trans.
on Database Systems 7, 1 (1982), 102-123.
Date, C. J., An Introduction to Database Systems, Vol. 1, Addison Wesley,
Reading, Mass., 4th Edition, 1986.
Davis, M. and H. Putnam, "A Computing Procedure for Quantification
Theory", J. ACM 7 (1960), 201-215.
Decker, H., "Integrity Enforcement in Deductive Databases", Proc. 1st Int.
Conf. on Expert Database Systems, Charleston, S.c., 1986.
Dershowitz,
N.
and
Z.
Manna,
"Proving
Termination
with
Multiset
Orderings", Comm. ACM 22, 8 (1979), 465-476.
Dugundji, J., Topology, Allyn and Bacon, Boston, 1966.
Edman, A and s.-A. Tll.rnlund, "Mechanization of an Oracle in a Debugging
System", IJCAl-83, Karlsruhe, 1983, 553-555.
Eisenstadt, M., "Retrospective Zooming: A Knowledge Based Tracing and
Debugging Methodology for Logic Programming", IJCAl-85, Los Angeles,
1985,717-719.
Eisenstadt,
M.
and
A.
Hasemer,
"An
Improved
User
Interface
for
PROLOG", Interact 84, 1984, 109-113.
Enderton, H. B., A Mathematical Introduction to Logic, Academic Press,
New York, 1972.
Ferrand, G., "Error Diagnosis in Logic Programming: An Adaptation of E.
Y. Shapiro's Method", Rapport de Recherche 375, INRIA, 1985.
Gallaire, H. and J. Minker (eds), Logic and Data Bases, Plenum Press, New
York,1978.

198
References
References
199
36.
Gallaire, H., J. Minker and J.-M. Nicolas (eds), Advances in Database
Theory, Vol. 1, Plenum Press, New York, 1981.
37.
Gallaire, H., J. Minker and J.-M. Nicolas (eds), Advances in Database
Theory, Vol. 2, Plenum Press, New York, 1984.
38.
Gallaire, H., l
Minker and J.-M. Nicolas, "Logic and Databases:
A
Deductive Approach", Computing Surveys 16, 2 (June 1984), 153-185.
39.
Gilmore, P. C., "A Proof Method for Quantification Theory", IBM J. Res.
Develop. 4 (1960),28-35.
40.
Green, C., "Applications of Theorem Proving to Problem Solving", IJCAl-
69, Washington, D.C., 1969, 219-239.
41.
Hansson, A,
S.
Haridi
and S.-A..
Tll.rnlund,
"Properties of a
Logic
Programming Language", in Logic Programming, Clark, K.L. and s.-A.
Tlirnlund (eds), Academic Press, New York, 1982, 267-280.
42.
Haridi, S. and D. Sahlin, "Evaluation of Logic Programs based on Natural
Deduction", TRITA-CS-8305 B, Royal Institute of Technology, Stockholm,
1983.
43.
Hayes,
P.
l,
"Computation
and
Deduction",
Proc.
MFCS
Con/.,
Czechoslovak Academy of Sciences, 1973, 105-118.
44.
Herbrand, l, "Investigations in Proof Theory", in From Frege to Godel: A
Source Book in Mathematical Logic, 1879-1931, van Heijenoort, J. (ed.),
Harvard University Press, Cambridge, Mass., 1967, 525-581.
45.
Hewitt, C., "Description and Theoretical Analysis (Using Schemata) of
PLANNER: A Language for Proving Theorems and Manipulating Models in
a Robot", AI. Memo 251, MIT, 1972.
46.
Hill,
R.,
"LUSH-Resolution and its
Completeness", DCL Memo 78,
Department of Artificial Intelligence, University of Edinburgh, 1974.
47.
Jaffar, J., J.-L. Lassez and J. W. Lloyd, "Completeness of the Negation as
Failure Rule", IJCAl-83, Karlsruhe, 1983, 500-506.
48.
Kowalski,
R.
A.,
"Predicate
Logic
as
a
Programming
Language",
Information Processing 74, Stockholm, North Holland, 1974,569-574.
49.
Kowalski, R. A, Logic for Problem Solving, North Holland, New York,
1979.
50.
Kowalski, R. A, "Algorithm = Logic + Control", Comm. ACM 22, 7 (July
1979), 424-436.
51.
Kowalski, R. A., "Logic as a Database Language", Research Report DOC
82/25 (Revised May 1984), Department of Computing, Imperial College,
1982.
52.
Kowalski, R. A, "The Relation Between Logic Programming and Logic
Specification", in Mathematical Logic and Programming Languages, Hoare,
C. A R. and J. C. Shepherdson (eds), Prentice-Hall, Englewood Cliffs, N.l,
1985, 11-27.
53.
Kowalski,
R.
A
and D.
Kuehner,
"Linear Resolution with Selection
Function", Artificial Intelligence 2 (1971), 227-260.
54.
Lassez, J.-L. and M. J. Maher, "Closures and Fairness in the Semantics of
Programming Logic", Theoretical Computer Science 29 (1984), 167-184.
55.
Lassez, J.-L., V. L. Nguyen and E. A Sonenberg, "Fixed Point Theorems
and Semantics: A 'Folk Tale", In/. Proc. Letters 14, 3 (1982), 112-116.
56.
Levi, G. and C. Palarnidessi, "Contributions to the Semantics of Logic
Perpetual
Processes",
Technical
Report,
Dipartimento
di
Informatica,
Universita di Pisa, 1986.
57.
Lifschitz, V., "Closed-World Databases and Circumscription", Artificial
Intelligence 27 (1985),229-235.
58.
Lloyd, J. W., "An Introduction to Deductive Database Systems", Australian
Computer J. 15, 2 (May 1983),52-57.
59.
Lloyd, J. W., "Declarative Error Diagnosis", New Generation Computing 5,
2 (1987).

200
References
References
201
60.
Lloyd, J. W., E. A
Sonenberg and R W. Topor, "Integrity Constraint
Checking in Stratified Databases", Technical Report 86/5, Department of
Computer Science, University of Melbourne, 1986.
To appear in J. Logic
Programming.
61.
Lloyd, J. W. and R W. Topor, "Making Prolog More Expressive", J. Logic
Programming 1, 3 (1984), 225-240.
62.
Lloyd, l W. and R W. Topor, "A Basis for Deductive Database Systems",
J. Logic Programming 2, 2 (1985),93-109.
63.
Lloyd, J. W. and R. W. Topor, "A Basis for Deductive Database Systems
II", J. Logic Programming 3, 1 (1986),55-67.
64.
Loveland, D. W., Automated Theorem Proving: A Logical Basis, North
Holland, New York, 1978.
65.
Loveland,
D.
W.,
"A Simplified Format for
the
Model
Elimination
Procedure", J. ACM 16,3 (July 1969),349-363.
66.
Manna, Z., Mathematical Theory of Computation, McGraw-Hill, New York,
1974.
67.
Martelli, A and U. Montanari, "Unification in Linear Time and Space: A
Structured Presentation", Nota Interna B76-16, Instituto di Elaborazione
della Informazione, Pisa, 1976.
68.
Martelli, A and U. Montanari, "An Efficient Unification Algorithm", ACM
Trans. on Prog. Lang. and Systems 4, 2 (April 1982),258-282.
69.
Mendelson, E., Introduction to Mathematical Logic, 2nd Edition, Van
Nostrand, Princeton, N.l, 1979.
70.
Minker, J. (ed.), Proc. Workshop on Foundations of Deductive Databases
and Logic Programming, Washington, D.C., 1986.
71.
Mota-Oka, T. (ed.), Fifth Generation Computer Systems: Proc. Int. Conf on
Fifth Generation Computer Systems, JIPDEC, North-Holland, 1982.
72.
Mycielski, J. and W. Taylor, "A Compactification of the Algebra of
Terms", Algebra Universalis 6 (1976), 159-163.
73.
Naish,
L.,
"Automating
Control
for
Logic
Programs",
J.
Logic
Programming 2, 3 (1985), 167-183.
74.
Naish, L., Negation and Control in PROLOG, Lecture Notes in Computer
Science 238, Springer-Verlag, 1986.
75.
Naish, L., "Negation and Quantifiers in NU-PROLOG", Proc. Third Int.
Conf. on Logic Programming, Lecture Notes in Computer Science 225,
Springer-Verlag, 1986, 624-634.
76.
Nait Abdallah, M. A, "On the Interpretation of Infinite Computations in
Logic Programming", ICALP 84, Lecture Notes in Computer Science 172,
Springer-Verlag, 1984,358-370.
77.
Nait Abdallah, M. A. and M. H. van Emden, "Algorithm Theory and Logic
Programming", draft manuscript, 1983.
78.
Nicolas, J.-M., "Logic for Improving Integrity Checking in Relational Data
Bases", Acta Informatica 18, 3 (1982),227-253.
79.
Nicolas, l-M. and H. Gallaire, "Data Base: Theory vs. Interpretation", in
Logic and Data Bases, Gallaire, H. and J. Minker (eds), Plenum Press, New
York, 1978,33-54.
80.
Paterson, M. S. and M. N. Wegman, "Linear Unification", J. Computer and
System Sciences 16, 2 (1978), 158-167.
81.
Pereira, L. M., "Rational Debugging in Logic Programming", Proc. Third
Int. Conf on Logic Programming, Lecture Notes in Computer Science 225,
Springer-Verlag, 1986, 203-210.
82.
Plaisted, D. A, "The Occur-Check Problem in PROLOG", IEEE Int. Symp.
on Logic Programming, Atlantic City, 1984,272-280.
83.
Plaisted, D. A., "An Efficient Bug Location Algorithm", Proc. Second Int.
Conf on Logic Programming, Uppsala, 1984, 151-157.
84.
Prawitz, D., "An Improved Proof Procedure", Theoria 26 (1960), 102-139.
85.
Reiter, R, "Deductive Question-Answering on Relational Data Bases", in
Logic and Data Bases, Gallaire, H. and J. Minker (eds), New York, 1978,

202
References
References
203
149-177.
86.
Reiter, R, "On Closed World Data Bases", in Logic and Data Bases,
Gallaire, H. and 1. Minker (eds), Plenum Press, New York, 1978,55-76.
87.
Reiter, R,
"Towards a Logical Reconstruction of Relational Database
Theory",
in
On
Conceptual
Modelling:
Perspectives
from
Artificial
Intelligence, Databases and Programming Languages, Brodie, M. L., J.
Mylopoulos and J. W. Schmidt (eds), Springer-Verlag, Berlin, 1984, 191-
233.
88.
Robinson, J. A, "A Machine-oriented Logic Based on the Resolution
Principle", J. ACM 12, 1 (Jan. 1965),23-41.
89.
Roussel,
P., PROLOG: Manuel de Reference et d' Utilization,
Groupe
d'Intelligence Artificielle, Universite d'Aix-Marseille, 1975.
90.
Sadri,
F.
and R
A
Kowalski,
"An Application of General
Purpose
Theorem-Proving to Database Integrity", in Proc. Workshop on Foundations
of Deductive
Databases
and
Logic
Programming,
Minker,
J.
(ed.),
Washington, D.C., 1986.
91.
Sebelik,
J.
and
P.
Stepanek,
"Horn
Clause
Programs
for
Recursive
Functions", in Logic Programming, Clark, K.L. and s.-A. Tllrnlund (eds),
Academic Press, New York, 1982,324-340.
92.
Shapiro, E. Y., Algorithmic Program Debugging, MIT Press, Cambridge,
Mass., 1983.
93.
Shapiro, E. Y., "A Subset of Concurrent PROLOG and its Interpreter",
Technical Report TR-003, ICOT, Tokyo, 1983.
94.
Shapiro,
E.
Y.
and
A.
Takeuchi,
"Object-Oriented
Programming
in
Concurrent PROLOG", New Generation Computing 1, 1 (1983),25-48.
95.
Shepherdson,
J. c.,
"Negation
as
Failure;
A
Comparison of Clark's
Completed Data Base and Reiter's Closed World Assumption", J. Logic
Programming 1, 1 (1984),51-79.
96.
Shepherdson, J. c., "Undecidability of Horn Clause Logic and Pure Prolog",
unpublished manuscript, 1985.
97.
Shepherdson, J. C., "Negation as Failure IT", J. Logic Programming 2, 3
(1985), 185-202.
98.
Shepherdson, J. C., "Negation in Logic Programming", in Foundations of
Deductive Databases and Logic Programming, Minker, 1. (ed.), Morgan
Kaufmann, Los Altos, 1987.
99.
Shoenfield, J., Mathematical Logic, Addison-Wesley, Reading, Mass., 1967.
100.
Sonenberg,
E.
A
and R.
W.
Topor,
"Computation in
the Herbrand
Universe", unpublished manuscript, 1986.
101. Tamaki, H. and T. Sato, "UnfoldIFold Transformation of Logic Programs",
Proc. Second Int. Conf. on Logic Programming, Uppsala, 1984, 127-138.
102.
Tl1rnlund, s.-A., "Horn Clause Computability", BIT 17, 2 (1977), 215-226.
103. Tarski, A, "A Lattice-theoretical Fixpoint Theorem and its Applications",
Pacific J. Math. 5 (1955), 285-309.
104. Thom, 1. A
and J. A
Zobel (eds), "NU-Prolog 1.0 Reference Manual",
Machine
Intelligence
Project,
Technical
Report
86/10,
Department
of
Computer Science, University of Melbourne, 1986.
105. Topor, R W., T. Keddis and D. W. Wright, "Deductive Database Tools",
Australian Computer J. 17,4 (Nov. 1985), 163-173.
106.
Ueda, K., "Guarded Horn Clauses", Ph.D. Thesis, University of Tokyo,
1986.
107. van Emden, M. H. and R. A Kowalski, "The Semantics of Predicate Logic
as a Programming Language", J. ACM 23, 4 (Oct. 1976),733-742.
108. van Emden, M. H. and M. A. Nait Abdallah, "Top-Down Semantics of Fair
Computations of Logic Programs", J. Logic Programming 2, 1 (1985), 67-
75.
109.
Van Gelder, A, "Negation as Failure using Tight Derivations for General
Logic Programs", Proc. 3rd IEEE Symp. on Logic Programming, Salt Lake
City, 1986, 127-138.

204
References
110.
Warren, D. H. D., "An Abstract PROLOG Instruction Set", Technical Note
309, SRI International, 1983.
111.
Warren, D. H. D. and F. C. N. Pereira, "An Efficient Easily Adaptable
System for Interpreting Natural Language Queries", DAI Research Paper No.
155, Department of Artificial Intelligence, University of Edinburgh, 1981.
112.
Wolfram, D. A., M. J. Maher and J.-L. Lassez, "A Unified Treatment of
Resolution Strategies for Logic Programs", Proc. Second Int. Conf. on Logic
Programming, Uppsala, 1984,263-276.
NOTATION
n
intersection
u
union
E
membership
{;;; improper subset
;;;;? improper superset
c
subset
::) superset
~, -7 implication
~ equivalence
1\ conjunction
v disjunction
-
negation
"if universal quantifier
:3 existential quantifier
\;f(F) universal closure of F
"3(F) existential closure of F
"if
universal quantifier of type 't
't
:3
existential quantifier of type 't
'to empty set
00 infinity
IXI cardinality of X
x\Y set difference
XXY cartesian product
o
empty clause
= equality predicate
=
equality predicate of type 't
't
IIiI end of proof
T
top element
..L
bottom element
co non-negative integers
2S set of all subsets of S
gfp(T) greatest fixpoint of T
Ifp(T) least fixpoint of T
glb(X) greatest lower bound of X
lub(X) least upper bound of X
P program
G goal
D database
Q query
comp(p) completion of a program P
comp(D) completion of a database D
! 63
2Bp 37
ar 174
AJ,V 12
BL 16
Bp 17
BS 17

183
206
B'
179
P
Cp
189
C't 152
C+ 50
C- 50
D* 151
dom(t) 174
dp(t) 175
fff...
178
Fp 75
~ 75
LSnero(Yn)
Mp 36
neginstD D' J 161
, ,
negD,D' 160
n
negD,D' 160
posinstD,D',J 161
posD,D' 160
n
posD,D' 160
Q*
151
S 174
Sc 181
TennS 174
TJ,a 29
Tia 29
TD 149
tn~t 176
Tp 37
~(a)
33
'rb 149
~ 80,111
T'
182
P
UL
15
Up 17
Us
17
Up 177
xRy 26
[Al 44
[AlJ 12
[n,il
173
[[All
181
{v1/t1,...,vn/tn} 20
Inl 173
an(t) 175
e 21
<I> 151
e
164
'¥ 164
't1X X'tn 19
't1x
x'tn
~'t 19
n 175
ro* 173
ro+n 29
ron 29
::; 27
"i/x/'tF 19
3x/'t F 19
/ 63
A 176
Notation
INDEX
admissible 89
algorithmic debugging 121
allowed 89, 116
alphabet 5
answer 39, 80, 110, 144
arity 174
atom 6, 178
based on 12, 20
binding 20
body 8, 36, 107, 143
bottom element 27
bound occurrence 6
clause 7
closed fonnula 7
closed world assumption 72
closure ordinal 30
compact metric space 176
compatible 164
compatible difference lists 46
complete Herbrand base 179
complete Herbrand interpretation 181
complete Herbrand model 182
complete Herbrand universe 177
complete lattice 27
completed definition 78, 79, 109, 145
completion 74, 79, 109, 146
composition 21
computable at infinity 189
computable function 52
computation 88, 116, 155
computation rule 50, 60
computed answer 43,86, 116, 151
conjunction 6
connected negatively 131
connected positively
131
connective 5
conservative extension 118
consistent 14
constant 5
continuous mapping 27
correct answer 39, 74, 80, 110, 146
correct program 121
cut 63,95
CWA72

208
database 143
database clause 148
database interpretation 3
database statement 143
declarative error diagnoser 119, 124
declarative semantics 10, 35, 37
definite database 148
definite database clause 148
definite goal 9, 36
definite program 8, 36
definite program clause 8, 36
definite query 147
definition 8, 78, 109, 145
depth of a term 175
derivation 41
derived goal 40, 85
difference list 45
directed set 27
disagreement set 23
disjunction 6
divide-and-query algorithm 125, 128
domain 12
domain closure axioms 146
domain of type 't
19
empty clause 10
equality theory 79, 109, 145
equivalence 6
error diagnoser 119, 124
existential closure 7
Index
existential quantifier 6
expression 20
failed SLD-derivation 41
failed SLDNF-derivation 88
failure branch 55, 88
fair search rule 59
fair SLD-derivation 76
fair SLD-tree 76
fair SLDNF-derivation 106
fair SLDNF-tree 106
Fibonacci sequence 189
finite failure set 75
finite SLD-derivation 41
finite SLDNF-derivation 88
finite term 175
finite tree 174
finitely failed by depth d 75
finitely failed SLD-tree 75
finitely failed SLDNF-tree 86, 116, 151
finitely failed SLDNF-tree of rank 0 85
finitely failed SLDNF-tree of rank k 86
finitely failed SLDNF-tree via R 151
first order language 6
first order theory 5
flounder 88, 116, 155
formula 6
free occurrence 6
free variable 6
function symbol 5
Index
goal 108
greatest fixpoint 28
greatest lower bound 27
ground atom 15, 179
ground instance 21, 181
ground substitution 20, 180
ground term 15, 177
Hamming's problem 189
head 8, 36, 107, 143
Herbrand base 16
Herbrand interpretation 16
Herbrand model 16
Herbrand pre-interpretation 16
Herbrand rule 100
Herbrand universe 15
hierarchical database 148
hierarchical normal program 83
hierarchical program 110
hierarchical type theory 151
Hom clause 10
Ie-PROLOG 59
idempotent substitution 33
identity substitution 21
implication 6
incorrect clause instance 122
incorrect program 121
incorrect statement instance 122
infinite branch 55, 88
209
infinite goal 102
infinite SLD-derivation 41
infinite SLDNF~derivation 88
infinite term 175
infinite tree 174
input clause 41, 87
instance 21
integrity constraint 144
intended interpretation 10, 36, 121
interpretation 12, 20
irreducible 152
irreducible form 153
I-instance 12
least fixpoint 28
least Herbrand model 36
least upper bound 27
length of a refutation 41
level 83, 110, 148
level mapping 83, 110, 148
limit ordinal 29
literal 7
logical consequence 14
logically equivalent 18
lower bound 27
LUSH-resolution 40
metric 176
metric space 176

210
mgu 23
minimal model 84
model 10, 13, 14
model-theoretic view 147
monotonic mapping 27
most general unifier 23
MU-PROLOG 59
negation 6
negation as failure rule 73
negative literal 7
non-monotonic inference rule 72
nonvalid 13, 14
normal database 148
normal form 112, 114, 116
normal goal 78
normal model 84, 149
normal program 78
normal query 147
NU-PROLOG 59, 62
occur check 24, 44
occurs negatively 7
occurs positively 7
oracle 127
ordering rule 59
ordinal powers 29
parent goal 64
partial order 26
Index
partial recursive function 52
perpetual process 173
positive literal 7
pre-interpretation 12, 19
predicate symbol 5
prenex conjunctive normal form 18, 32
procedural interpretation 2
procedural semantics 37, 40
process interpretation 3
program 108
program clause 77
program statement 107
PROLOG 1,11
proof-theoretic view 147
punctuation symbol 5
quantifier 5
query 143
R-computed answer 50,99, 118, 151
R-success set 52
range type 19
rational debugging 121
,reduces to 152
refutation 41
relation 12, 26
renaming substitution 22
representation scheme 123
resolvent 41
Index
safe computation rule 98
safe use of cut 64
safeness condition 85, 93, 94
satisfiable 13, 14
satisfy an integrity constraint 146
scope 6
search rule 57
selected atom 40, 50, 85
selected literal 99
simple expression 20
simplification method 158
single-stepping algorithm 125, 128
SLD finite failure set 72, 75
SLD-derivation 41
SLD-derivation via R 50
SLD-refutation 41
SLD-refutation procedure 57
SLD-refutation via R 50
SLD-resolution 40
SLD-tree 55
SLD-tree via R 56
SLDNF-derivation 87, 116, 151
SLDNF-derivation via R 99, 118, 151
SLDNF-refutation 86, 116, 151
SLDNF-refutation of rank 0 85
SLDNF-refutation of rank k 85
SLDNF-refutation via R 99, 118, 151
SLDNF-resolution 74
SLDNF-tree 88, 116, 151
SLDNF-tree via R 99, 118, 151
~l I
slowsort program 9
standard computation rule 56, 76
standard PROLOG system 57,59,60
standardising apart 41
stopping rule 167
stratified database 148
stratified normal program 83
stratified program 110
subgoal 9
substitution 20
success branch 55, 88
success set 42
successful SLD-derivation 41
successful SLDNF-derivation 88
successor ordinal 29
term 6, 174
term assignment 12
term of type 1: 19
top element 27
top-down error diagnoser 126
transaction 159
transfinite induction, principle of 29
tree 174
truncation at depth n 175
truth value 12
type 19
type predicate symbol 150
type theory 151
type-free form 150

212
typed existential closure 19
typed fIrst order language 19
typed fIrst order theory 19, 142
typed fonnula 19
typed universal closure 19
ultrametric 176
ultrametric space 176
uncovered atom 122
underlies 174
unifIcation 2
unifIcation algorithm 24
unifIer 22
unit clause 8
universal closure 7
universal quantifIer 6
. unrestricted SLD-refutation 41
unsafe use of cut 64
unsatisfIable 13, 14
upper bound 27
valid 13, 14
variable 5
variable assignment 12, 154
variable-pure substitution 20
variant 22
violate an integrity constraint 147
when declaration 62
Index
Springer Series
Artificial Intelligence
N. J. Nilsson: Principles of Artificial Intelligence. XV, 476 pages, 139 figs., 1982
J. H. Siekmann, G.Wrightson (Eds.): Automation of Reasoning 1. Classical
Papers on Computational Logic 1957-1966. XXII, 525 pages, 1983
J. H. Siekmann, G. Wrightson (Eds.): Automation of Reasoning 2. Classical
Papers on Computational Logic 1967-1970. XXII, 638 pages, 1983
L. Bole (Ed.): The Design of Interpreters, Compilers, and Editors for Augmented
Transition Networks. XI, 214 pages, 72 figs., 1983
M. M. Botvinnik: Computers in Chess. Solving Inexact Search Problems. With
contributions by A. I. Reznitsky, B. M. Sti1man, M. A. Tsfasman, A. D.Yudin.
Translated from the Russian by A. A. Brown. XIV, 158 pages, 48 figs., 1984
L. Bole (Ed.): Natural Language Communication with Pictorial Information
Systems. VII, 327 pages, 67 figs., 1984
R. S. Michalski, J. G. Carbonell, T. M. Mitchell (Eds.): Machine Learning.
An Artificial Intelligence Approach. XI, 572 pages, 1984
C. Blume, W. Jakob: Programming Languages for Industrial Robots.
XIII, 376 pages, 145 figs., 1986
J. W. Lloyd: Foundations of Logic Programming. Second, extended edition.
XII, 212 pages, 1987
L. Bole (Ed.): Computational Models of Learning. IX, 208 pages, 34 figs., 1987
L. Bole (Ed.): Natural Language Parsing Systems. XVIII, 367 pages, 151 figs.,
1987
N. Cercone, G. McCalla (Eds.): TheKnowledge Frontier. Essays in the
Representation of Knowledge. XXXV, 512 pages, 93 figs., 1987
G. Rayna: REDUCE. Software for Algebraic Computation. IX, 329 pages, 1987
D. D. McDonald, L. Bole (Eds.): Natural Language Generation Systems.
XI, 389 pages, 84 figs., 1988
L. Bole, M. J. Coombs (Eds.): Expert System Applications. IX, 471 pages,
84 figs., 1988

Springer Series
Artificial Intelligence
C.-H. Tzeng: A Theory of Heuristic Information in Game-Tree Search. X,
107 pages, 22 figs., 1988
H. Coelho, J. C. Cotta: Prolog by Example. How to Learn, Teach and Use It.
X, 382 pages, 68 figs., 1988
L. Kana1, V. Kumar (Eds.): Search in Artificial Intelligence. X, 482 pages,
67 figs., 1988
H. Abramson, V. Dahl: Logic Grammars. XIV, 234 pages, 40 figs., 1989
R. Hausser: Computation of Language. An Essay on Syntax, Semantics, and
Pragmatics in Natural Man-Machine Communication. XVI, 425 pages, 1989
P. Besnard: An Introduction to Default Logic. XI, 201 pages, 1989
A. Kobsa, W. Wahlster (Eds.): User Models in Dialog Systems. XI, 471 pages,
113 figs., 1989
B. D'Ambrosio: Qualitative Process Theory Using Linguistic Variables.
X, 156 pages, 22 figs., 1989
V. Kumar, P. S. Gopalakrishnan, L. N. Kanal (Eds.) Parallel Algorithms for
Machine Intelligence and Vision. XI, 433 pages, 148 figs., 1990
Y. Peng, J. A. Reggia: Abductive Inference Models for Diagnostic Problem-
Solving. XII, 284 pages, 25 figs., 1990
A. Bundy (Ed.): Catalogue of Artificial Intelligence Techniques. Third, revised
edition. XV, 179 pages, 1990
D. Navinchandra: Exploration and Innovation in Design. XI, 196 pages, 51 figs.,
1991
R. Kruse, E. Schwecke, J. Heinsohn: Uncertainty and Vagueness in Knowledge
Based Systems. Numerical Methods. XI, 491 pages, 59 figs., 1991
z. Michalewicz: Genetic Algorithms + Data Structures = Evolution Programs.
XVII, 250 pages, 48 figs., 1992
Springer-Verlag
and the Environment
We at Springer-Verlag firmly believe that an
international science publisher has a special
obligation to the environment, and our corpo-
rate policies consistently reflect this conviction.
We also expect our busi-
ness partners - paper mills, printers, packag-
ing manufacturers, etc. - to commit themselves
to using environmentally friendly materials and
production processes.
The paper in this book is made from
low- or no-chlorine pulp and is acid free, in
conformance with international standards for
paper permanency.

