
Undergraduate Topics in Computer Science

Undergraduate Topics in Computer Science (UTiCS) delivers high-quality instructional content for un-
dergraduates studying in all areas of computing and information science. From core foundational and
theoretical material to ﬁnal-year topics and applications, UTiCS books take a fresh, concise, and mod-
ern approach and are ideal for self-study or for a one- or two-semester course. The texts are all authored
by established experts in their ﬁelds, reviewed by an international advisory board, and contain numer-
ous examples and problems. Many include fully worked solutions.
For further volumes:
www.springer.com/series/7592

Gilles Dowek
Proofs
and Algorithms
An Introduction to Logic and
Computability

Gilles Dowek
École Polytechnique
Palaiseau
France
gilles.dowek@polytechnique.edu
Series editor
Ian Mackie
Advisory board
Samson Abramsky, University of Oxford, Oxford, UK
Chris Hankin, Imperial College London, London, UK
Dexter Kozen, Cornell University, Ithaca, USA
Andrew Pitts, University of Cambridge, Cambridge, UK
Hanne Riis Nielson, Technical University of Denmark, Lungby, Denmark
Steven Skiena, Stony Brook University, Stony Brooks, USA
Iain Stewart, University of Durham, Durham, UK
Based on course notes by Gilles Dowek, published simultaneously in French by École Poly-
technique with the following title: “Les démonstrations et les algorithmes”. The translator of
the work is Maribel Fernandez.
ISSN 1863-7310
ISBN 978-0-85729-120-2
e-ISBN 978-0-85729-121-9
DOI 10.1007/978-0-85729-121-9
Springer London Dordrecht Heidelberg New York
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
© Springer-Verlag London Limited 2011
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as per-
mitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced,
stored or transmitted, in any form or by any means, with the prior permission in writing of the publish-
ers, or in the case of reprographic reproduction in accordance with the terms of licenses issued by the
Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be sent to
the publishers.
The use of registered names, trademarks, etc., in this publication does not imply, even in the absence of a
speciﬁc statement, that such names are exempt from the relevant laws and regulations and therefore free
for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the information
contained in this book and cannot accept any legal responsibility or liability for any errors or omissions
that may be made.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

Acknowledgements
The author would like to thank René Cori, René David, Maribel Fernández, Jean-
Baptiste Joinet, Claude Kirchner, Jean-Louis Krivine, Daniel Lascar, Stéphane
Lengrand, Michel Parigot, Laurence Rideau and Paul Rozière.
v


Contents
Part I
Proofs
1
Predicate Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.1
Inductive Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.1.1
The Fixed Point Theorem . . . . . . . . . . . . . . . . . .
3
1.1.2
Inductive Deﬁnitions . . . . . . . . . . . . . . . . . . . . .
6
1.1.3
Structural Induction . . . . . . . . . . . . . . . . . . . . .
8
1.1.4
Derivations . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.1.5
The Reﬂexive-Transitive Closure of a Relation . . . . . . .
10
1.2
Languages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.2.1
Languages Without Variables . . . . . . . . . . . . . . . .
10
1.2.2
Variables . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
1.2.3
Many-Sorted Languages . . . . . . . . . . . . . . . . . . .
12
1.2.4
Substitution
. . . . . . . . . . . . . . . . . . . . . . . . .
13
1.2.5
Articulation
. . . . . . . . . . . . . . . . . . . . . . . . .
15
1.3
The Languages of Predicate Logic
. . . . . . . . . . . . . . . . .
16
1.4
Proofs
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
1.5
Examples of Theories . . . . . . . . . . . . . . . . . . . . . . . .
23
1.6
Variations on the Principle of the Excluded Middle . . . . . . . . .
30
1.6.1
Double Negation . . . . . . . . . . . . . . . . . . . . . . .
30
1.6.2
Multi-conclusion Sequents
. . . . . . . . . . . . . . . . .
30
2
Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.1
The Notion of a Model . . . . . . . . . . . . . . . . . . . . . . . .
35
2.2
The Soundness Theorem . . . . . . . . . . . . . . . . . . . . . . .
38
2.3
The Completeness Theorem . . . . . . . . . . . . . . . . . . . . .
39
2.3.1
Three Formulations of the Completeness Theorem . . . . .
40
2.3.2
Proving the Completeness Theorem . . . . . . . . . . . . .
40
2.3.3
Models of Equality—Normal Models . . . . . . . . . . . .
43
2.3.4
Proofs of Relative Consistency
. . . . . . . . . . . . . . .
44
2.3.5
Conservativity . . . . . . . . . . . . . . . . . . . . . . . .
46
vii

viii
Contents
2.4
Other Applications of the Notion of Model . . . . . . . . . . . . .
49
2.4.1
Algebraic Structures . . . . . . . . . . . . . . . . . . . . .
49
2.4.2
Deﬁnability
. . . . . . . . . . . . . . . . . . . . . . . . .
51
Part II
Algorithms
3
Computable Functions . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.1
Computable Functions . . . . . . . . . . . . . . . . . . . . . . . .
55
3.2
Computability over Lists and Trees . . . . . . . . . . . . . . . . .
58
3.2.1
Computability over Lists
. . . . . . . . . . . . . . . . . .
58
3.2.2
Computability over Trees . . . . . . . . . . . . . . . . . .
60
3.2.3
Derivations . . . . . . . . . . . . . . . . . . . . . . . . . .
61
3.3
Eliminating Recursion . . . . . . . . . . . . . . . . . . . . . . . .
62
3.4
Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
3.4.1
Undecidability of the Halting Problem
. . . . . . . . . . .
66
3.4.2
The Interpreter . . . . . . . . . . . . . . . . . . . . . . . .
66
4
Computation as a Sequence of Small Steps . . . . . . . . . . . . . . .
71
4.1
Rewriting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
4.2
The Lambda-Calculus . . . . . . . . . . . . . . . . . . . . . . . .
81
4.3
Turing Machines . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
Part III
Proofs and Algorithms
5
Church’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
5.1
The Notion of Reduction
. . . . . . . . . . . . . . . . . . . . . . 101
5.2
Representing Programs
. . . . . . . . . . . . . . . . . . . . . . . 102
5.3
Church’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.4
Semi-decidability
. . . . . . . . . . . . . . . . . . . . . . . . . . 111
5.5
Gödel’s First Incompleteness Theorem . . . . . . . . . . . . . . . 112
6
Automated Theorem Proving . . . . . . . . . . . . . . . . . . . . . . 117
6.1
Sequent Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
6.1.1
Proof Search in Natural Deduction
. . . . . . . . . . . . . 117
6.1.2
Sequent Calculus Rules . . . . . . . . . . . . . . . . . . . 118
6.1.3
Equivalence with Natural Deduction
. . . . . . . . . . . . 120
6.1.4
Cut Elimination . . . . . . . . . . . . . . . . . . . . . . . 126
6.2
Proof Search in the Sequent Calculus Without Cuts . . . . . . . . . 130
6.2.1
Choices
. . . . . . . . . . . . . . . . . . . . . . . . . . . 130
6.2.2
Don’t Care Choices and Don’t Know Choices
. . . . . . . 130
6.2.3
Restricting the Choices
. . . . . . . . . . . . . . . . . . . 131
7
Decidable Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
8
Constructivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143

Contents
ix
9
Epilogue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
Index
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153


Introduction
There are several ways to ﬁnd the area of the segment of parabola depicted above.
One method consists of covering the area with an inﬁnite number of small triangles,
proving that each of them has a speciﬁc area, then adding together all the areas of
the triangles. This is grosso modo the method that Archimedes used to show that this
area is equal to 4/3. Another method, which gives the same result, has been known
since the 17th century: the area can be obtained by computing
 1
−1(1 −x2)dx. To
integrate this polynomial function we do not need to build a proof, we can simply
use an algorithm.
Building a proof and applying an algorithm are two well-known mathematical
techniques; they have co-existed for a long time. With the advent of computers,
which allow us to implement algorithms at a scale that was unimaginable in the
past, there has been a renewed interest in algorithmic methods.
The co-existence of these two problem-solving techniques leads us to question
their relationship. To what extent the construction of a proof can be replaced by the
application of an algorithm? This book describes a set of results, some positive and
some negative, that provide a partial answer to this question. We start by giving a
precise deﬁnition of the notion of a proof, in the ﬁrst part of the book, and of the
notion of an algorithm, in the second part of the book. A precise deﬁnition of the
notion of proof will allow us to understand how to prove independence theorems,
which state that there are certain problems for which no proof can provide a solu-
tion. A precise deﬁnition of the notion of an algorithm will allow us to understand
how to prove undecidability theorems, which state that certain problems cannot be
xi

xii
Introduction
solved in an algorithmic way. It will also lead us to a better understanding of algo-
rithms, which can be written in different ways (for instance, as a set of rewriting
rules, as terms in the lambda-calculus, or as Turing machines), and to the discovery
that behind this apparent diversity there is a deep unifying notion: the idea that a
computation is a sequence of small steps.
The third part of the book focuses on the links between the notions of proof
and algorithm. The main result in this part is Church’s theorem, establishing that
provability is an undecidable problem in predicate logic; Gödel’s famous theorem
is a corollary of this result. This negative result will be counterbalanced by two
positive results. First, although undecidable, this problem is semi-decidable, and
this will lead us to the development of algorithms that search for proofs. Second,
by adding axioms to predicate logic we can, in certain cases, make the problem
decidable. This will lead us to the development of decision algorithms for speciﬁc
theories.
The ﬁnal chapter of the book will describe a different link between proofs and
algorithms: some proofs, those that are said to be constructive, can be used as algo-
rithms.
Over the next chapters we will explore the deep connections that exist between
the concepts of proof and algorithm, and unveil the complexity that hides behind the
apparently obvious notion of truth.

Part I
Proofs


Chapter 1
Predicate Logic
What are the conditions that a proposition should satisfy to be true? A possible
answer, deﬁning a certain notion of truth, could be that a proposition is true if it can
be proved. In this chapter, we will analyse this answer and give a deﬁnition of the
concept of provability. For this, we will ﬁrst deﬁne the set of propositions, and then
the subset of theorems, or provable propositions.
Since in both cases we will be deﬁning sets, we will start by introducing some
tools to deﬁne sets.
1.1 Inductive Deﬁnitions
The most basic tool to deﬁne a set is an explicit deﬁnition. We can, for example,
deﬁne explicitly the set of even numbers: {n ∈N | ∃p ∈N n = 2 × p}. However,
these explicit deﬁnitions are not sufﬁcient to deﬁne all the sets we need. A second
tool to deﬁne sets is the notion of an inductive deﬁnition. This notion is based on a
simple theorem: the ﬁxed point theorem.
1.1.1 The Fixed Point Theorem
Deﬁnition 1.1 (Limit) Let ≤be an ordering relation, that is, a reﬂexive, antisym-
metric and transitive relation, over a set E, and let u0,u1,u2,... be an increasing
sequence, that is, a sequence such that u0 ≤u1 ≤u2 ≤···. The element l of E
is called limit of the sequence u0,u1,u2,... if it is a least upper bound of the set
{u0,u1,u2,...}, that is, if it is an upper bound:
• for all i, ui ≤l
and it is the smallest one:
• if, for all i, ui ≤l′, then l ≤l′.
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_1, © Springer-Verlag London Limited 2011
3

4
1
Predicate Logic
If it exists, the limit of a sequence (ui)i is unique, and we denote it by limi ui.
Deﬁnition 1.2 (Weakly complete ordering) An ordering relation ≤is said to be
weakly complete if each increasing sequence has a limit.
The standard ordering relation over the real numbers interval [0,1] is an exam-
ple of a weakly complete ordering. In addition, this relation has a least element 0.
However, the standard ordering relation over R+ is not weakly complete since the
increasing sequence 0,1,2,3,... does not have a limit.
Let A be an arbitrary set. The inclusion relation ⊆over the set ℘(A) of all the
subsets of A is another example of a weakly complete ordering. The limit of an
increasing sequence U0,U1,U2,... is the set 
i∈N Ui. In addition, this relation has
a least element ∅.
Deﬁnition 1.3 (Increasing function) Let ≤be an ordering relation over a set E and
f a function from E to E. The function f is increasing if x ≤y ⇒f x ≤fy.
Deﬁnition 1.4 (Continuous function) Let ≤be a weakly complete ordering rela-
tion over the set E, and f an increasing function from E to E. The function f is
continuous if for any increasing sequence limi(f ui) = f (limi ui).
Proposition 1.1 (First ﬁxed point theorem) Let ≤be a weakly complete ordering
relation over a set E that has a least element m. Let f be a function from E to E. If
f is continuous then p = limi(f i m) is the least ﬁxed point of f .
Proof First, since m is the smallest element in E, m ≤f m. The function f is in-
creasing, therefore f im ≤f i+1m. Since the sequence f im is increasing, it has
a limit. The sequence f i+1m also has p as limit, thus, p = limi(f (f i m)) =
f (limi(f i m)) = f p. Moreover, p is the least ﬁxed point, because if q is an-
other ﬁxed point, then m ≤q and f im ≤f iq = q (since f is increasing). Hence
p = limi(f i m) ≤q.
□
The second ﬁxed point theorem states the existence of a ﬁxed point for increasing
functions, even if they are not continuous, provided the ordering satisﬁes a stronger
property.

1.1
Inductive Deﬁnitions
5
Deﬁnition 1.5 (Strongly complete ordering) An ordering relation ≤over a set E
is strongly complete if every subset A of E has a least upper bound, denoted by
sup A.
The standard ordering relation over the interval [0,1] is an example of a strongly
complete ordering relation. The standard ordering over R+ is not strongly complete
because the set R+ itself has no upper bound.
Let A be an arbitrary set. The inclusion relation ⊆over the set ℘(A) of all the
subsets of A is another example of strongly complete ordering. The least upper
bound of a set B is the set 
C∈B C.
Exercise 1.1 Show that any strongly complete ordering is also weakly complete.
Is the ordering
weakly complete? Is it strongly complete?
Proposition 1.2 If the ordering ≤over the set E is strongly complete, then any
subset A of E has a greatest lower bound, infA.
Proof Let A be a subset of E, let B be the set {y ∈E | ∀x ∈A y ≤x} of lower
bounds of A and l the least upper bound of B. By deﬁnition, l is an upper bound of
the set B
– ∀y ∈B y ≤l
and it is the least one
– (∀y ∈B y ≤l′) ⇒l ≤l′.
It is easy to show that l is the greatest lower bound of A. Indeed, if x is an element
of A, it is an upper bound of B and since l is the least upper bound, l ≤x. Thus, l is
a lower bound of A. To show that it is the greatest one, it is sufﬁcient to note that if
m is another lower bound of A, it is an element of B and therefore m ≤l.
□
The greatest lower bound of a set B of subsets of A is, of course, the set 
C∈B C.

6
1
Predicate Logic
Proposition 1.3 (Second ﬁxed point theorem) Let ≤be a strongly complete or-
dering over a set E. Let f be a function from E to E. If f is increasing then
p = inf{c | f c ≤c} is the least ﬁxed point of f .
Proof Let C be the set {c | f c ≤c} and c be an element of C. Then p ≤c because p
is a lower bound of C. Since the function f is increasing, we deduce that fp ≤f c.
Also, f c ≤c because c is an element of C, so by transitivity fp ≤c.
The element fp is less than all the elements in C, it is therefore also less than or
equal to its greatest lower bound: fp ≤p.
Since the function f is increasing, f (fp) ≤fp, thus fp is an element of C, and
since p is a lower bound of C, we deduce p ≤fp. By antisymmetry, p = fp.
Finally, by deﬁnition, all the ﬁxed points of f belong to C, and they are therefore
greater than p.
□
1.1.2 Inductive Deﬁnitions
We will now see how the ﬁxed point theorems can be used to deﬁne sets and rela-
tions.
Deﬁnition 1.6 (Closure) Let E be a set, f a function from En to E and A a subset
of E. The set A is closed under the function f if for all x1,...,xn in A such that f
is deﬁned in x1,...,xn, f x1 ... xn is also an element of A.
For example, the set of all the even numbers is closed under the function n 
→
n + 2.
Deﬁnition 1.7 (Inductive deﬁnition) Let E be a set. An inductive deﬁnition over E
is a family of partial functions f1 from En1 to E, f2 from En2 to E, ... This family
deﬁnes a subset A of E: the least subset of E that is closed under the functions
f1,f2,....

1.1
Inductive Deﬁnitions
7
For example, the subset of N that contains all the even numbers is inductively
deﬁned by the number 0, that is, the function from N0 to N that returns the value 0,
and the function from N to N deﬁned by n 
→n+2. The subset of the even numbers
is not the only subset of N that contains 0 and is closed under the function n 
→n+2
(the set N, for instance, also satisﬁes these properties), but it is the smallest one.
The subset of {a,b,c}∗containing all the words of the form anbcn is inductively
deﬁned by the word b and the function m 
→amc. In general, a context free gram-
mar can always be speciﬁed as an inductive set. We will see that in logic, the set of
theorems is deﬁned as the subset of all the propositions that is inductively deﬁned
by the axioms and deduction rules.
The functions f1,f2,... are called rules. Instead of writing a rule as x1 ...xn
→t,
we will use the notation
x1 ...xn
t
For example, the set of even numbers is deﬁned by the rules
0
n
n + 2
Let P be the set of even numbers. We will sometimes write the rules as follows:
0 ∈P
n ∈P
n + 2 ∈P
To show that Deﬁnition 1.7 makes sense, we will show that there is always a
smallest subset A that is closed under the functions f1,f2,....
Proposition 1.4 Assume E is a set and f1,f2,... are rules over the set E. There
exists a smallest subset A of E that is closed under the functions f1,f2,....
Proof Let F be the function from ℘(E) to ℘(E) deﬁned as follows.
FC = {x ∈E | ∃i∃y1 ...yni ∈C x = fi y1 ... yni}
A subset C of E is closed under the functions f1,f2,... if and only if FC ⊆C.
The function F is trivially increasing: if C ⊆C′, then FC ⊆FC′. The set A
is deﬁned as the least ﬁxed point of this function: the intersection of all the sets C
such that FC ⊆C, that is, the intersection of all the sets that are closed under the
functions f1,f2,....
By the second ﬁxed point theorem, this set is a ﬁxed point of F, FA = A, and
therefore FA ⊆A. Hence, it is closed under the functions f1,f2,... And by deﬁni-
tion, it is smaller than all the sets C such that FC ⊆C. It is therefore the smallest
set that is closed under these functions.
□

8
1
Predicate Logic
The ﬁrst ﬁxed point theorem gives us another characterisation of this set.
Proposition 1.5 Assume E is a set and f1,f2,... are rules over the set E. The
smallest subset A of E that is closed under the functions f1,f2,... is the set

k(F k∅) where the function F is deﬁned by
FC = {x ∈E | ∃i∃y1 ...yni ∈C x = fi y1 ... yni}
Proof We have seen that the function F is increasing. It is also continuous: if C0 ⊆
C1 ⊆C2 ⊆···, then F(
j Cj) = 
j(FCj). Indeed, if an element x of E is in
F(
j Cj), then there exists some number i and elements y1,...,yni of 
j Cj
such that x = fi y1 ... yni. Each of these elements is in one of the Cj. Since the
sequence Cj is increasing, they are all in Ck, which is the largest of these sets.
Therefore, the element x belongs to FCk and also to 
j(FCj). Conversely, if x is
in 
j(FCj), then it belongs to some FCk, and there is therefore a number i and
elements y1,...,yni of Ck such that x = fi y1 ... yni. The elements y1,...,yni are
in 
j Cj and therefore x is in F(
j Cj).
We have seen that the smallest subset A of E closed under the functions
f1,f2,... is the least ﬁxed point of the function F . By the ﬁrst ﬁxed point theo-
rem, we have A = 
k(F k∅).
□
1.1.3 Structural Induction
Inductive deﬁnitions suggest a method to write proofs. If a property is hereditary,
that is, if each time it holds for y1,...,yni, then it also holds for fi y1 ... yni, then
we can deduce that it holds for all the elements of A.
One way to show this, is to use the second ﬁxed point theorem and to observe
that the subset P of E containing all the elements that satisfy the property is closed
under the functions fi and thus it includes A. Another way is to use Proposition 1.5
and to show by induction on k that all the elements in F k∅satisfy the property.
1.1.4 Derivations
An element x is in the set A if and only if it belongs to some set F k∅, that is, if there
exists a function fi such that x = fi y1 ... yni where y1,...,yni are in F k−1∅. This
observation allows us to prove that an element x of E belongs to A if and only if
there exists a tree whose nodes are labelled with elements of E and whose root is
labelled with x, and such that whenever a node is labelled with an element y and
its children are labelled with elements z1,...,zn, there exists a rule fi such that
y = fi z1 ... zn. Such a tree is called a derivation of x.

1.1
Inductive Deﬁnitions
9
Deﬁnition 1.8 (Derivation) Let E be a set and f1,f2,... rules over the set E.
A derivation in f1,f2,... is a tree where the nodes are labelled with elements of E
such that if a node is labelled with an element y and its children are labelled with
elements z1,...,zn, then there is a rule fi, such that y = fi z1 ... zn.
If the root of the derivation is an element x of E, then this derivation is a deriva-
tion of x.
We can then deﬁne the set A as the set of elements of E for which there is a
derivation.
We will use a speciﬁc notation for derivations. The root of the tree will be written
at the bottom and the leaves at the top; moreover we will write a line over each node
in the tree and write its children over the line.
For example, the following derivation shows that the number 8 is in the set of
even numbers.
0
2
4
6
8
If we call P the set of even numbers, we can write the derivation as follows
0 ∈P
2 ∈P
4 ∈P
6 ∈P
8 ∈P
Instead of labelling the nodes of a derivation with elements of E, we can also
label them with rules.
Deﬁnition 1.9 (Derivation labelled with rules) Let E be a set and f1,f2,... rules
over the set E. A derivation labelled with rules f1,f2,... is a tree whose nodes are
labelled with f1,f2,... such that the number of children of a node labelled by f is
the number of arguments of f .
By structural induction we can associate an element of E to each derivation la-
belled with rules: if the root of the derivation is labelled with the rule fi and its
immediate subtrees are associated to the elements z1,...,zn, then we associate to
the derivation the element fi z1 ... zn. When an element is associated to a deriva-
tion, we say that the derivation is a derivation of this element.
We can then deﬁne the set A as the set of elements of E that have a derivation
labelled with rules.

10
1
Predicate Logic
1.1.5 The Reﬂexive-Transitive Closure of a Relation
The reﬂexive-transitive closure of a relation is an example of inductive deﬁnition.
Deﬁnition 1.10 (Reﬂexive-transitive closure) Let R be a binary relation on a set E.
The reﬂexive-transitive closure of the relation R is the relation R∗inductively de-
ﬁned by the rules
– t R∗t,
– if t R t′ and t′ R∗t′′, then t R∗t′′.
If t R∗t′, a derivation of the pair (t,t′) is a ﬁnite sequence t0,...,tn, such that
t0 = t, tn = t′ and for all i ≤n −1, ti R ti+1.
If we see R as a directed graph, then derivations are paths in the graph and R∗
is the relation that links two nodes when there is a path from one to the other in the
graph.
1.2 Languages
1.2.1 Languages Without Variables
In the previous section we introduced inductive deﬁnitions; we will now use this
technique to deﬁne the notion of a language. First we will give a general deﬁnition
that applies to programming languages and logic languages alike. Later we will
deﬁne the language of predicate logic.
The notion of language that we will deﬁne does not take into account superﬁ-
cial syntactic conventions, for instance, it does not matter whether we write 3 + 4,
+(3,4), or 3 4 +. This expression will be represented in an abstract way by a tree
Each node in the tree will be labelled with a symbol. The number of children of a
node depends on the node’s label—two children if the label is +, none if it is 3 or
4,....
A language is thus a set of symbols, each with an associated arity, which is a
natural number also called the number of arguments of the symbol. Symbols without
arguments are called constants.
The set of expressions of the language is the set of trees inductively deﬁned by
the following rule.
– If f is a symbol of arity n and t1,...,tn are expressions then f (t1,...,tn), that
is, the tree that has a root labelled with f and subtrees t1,...,tn, is an expression.

1.2
Languages
11
1.2.2 Variables
Suppose that we want to design a language of expressions, including for instance
expressions such as odd(3) or odd(3) ⇒even(3+1). We might also want to be able
to express the fact that for all natural numbers, if a natural number is odd then its
successor is even.
To build those expressions, natural languages such as English or French use in-
deﬁnite pronouns (for example all, any and some in English), but replacing expres-
sions by pronouns may produce ambiguities, in particular when several expressions
are replaced in a sentence. For instance, the sentence “There is some natural num-
ber greater than any given natural number” might be understood as a property that
holds for each natural number: for each natural number there is a greater one, which
is true; but it could also mean that there exists a natural number that is greater than
all natural numbers, which is false.
To avoid ambiguities, a more sophisticated mechanism is needed. We will intro-
duce variables and specify their meaning and scope using quantiﬁers ∀, for all, or
∃, there exists, to bind variables. In this way we can distinguish the propositions
∀x∃y (y ≥x) and ∃y∀x (y ≥x).
A quantiﬁer is a symbol that binds a variable in its argument. There are other
examples of binders, for instance the symbols 
→, ∂/∂,

d, , , ... We will
generalise the deﬁnition of language given above, to take into account the fact that
some symbols might bind variables.
The arity of a symbol f will no longer be a number n, instead, we will use a
ﬁnite sequence of numbers (k1,...,kn) that will indicate that the symbol f binds
k1 variables in its ﬁrst argument, k2 variables in the second, ..., kn variables in the
nth argument.
In this way, when a language is given, that is, when we have a set of symbols
with their arities, together with an inﬁnite set of variables, we can deﬁne the set of
expressions inductively as follows.
– Variables are expressions.
– If f is a symbol of arity (k1,...,kn), t1,...,tn are expressions and x1
1,...,x1
k1,
...,xn
1,...,xn
kn are variables, then f (x1
1 ...x1
k1t1,...,xn
1 ...xn
kntn) is an expres-
sion.
The notation f (x1
1 ...x1
k1t1,...,xn
1 ...xn
kntn) denotes the tree

12
1
Predicate Logic
For example, the expression
 u
t v dx denotes the tree
1.2.3 Many-Sorted Languages
In this book, we will sometimes use more general languages that are called many-
sorted languages. For instance, using the constants 0 and 1, a binary symbol +,
unary symbols even and odd and a binary symbol ⇒(none of these symbols binds
any variable), we can build the expressions 1, 1 + 1, even(1 + 1) and odd(1) ⇒
even(1 + 1). Unfortunately, we can also build the expressions odd(even(1)) and
1 ⇒(1 + even(1)). To exclude these expressions, we will distinguish two sorts of
expression: terms, which denote natural numbers, and propositions which express
properties of numbers. Thus, the symbol even takes an argument which should be a
term, and builds a proposition. The symbol ⇒takes two propositions as arguments
and builds a proposition.
We will therefore introduce a set {Term,Prop} and call its elements expression
sorts, and we will associate to the symbol even the arity (Term,Prop). This indicates
that in an expression of the form even(t), the expression t must be of sort Term, and
the whole expression even(t) is of sort Prop.
More generally, we introduce a set S of sorts, and deﬁne the arity of a symbol f
to be a ﬁnite sequence (s1,...,sn,s′) of sorts. This arity indicates that the symbol
f has n arguments, the ﬁrst one of sort s1,..., the nth one of sort sn, and that the
resulting expression is of sort s′.
When, in addition, there are bound variables, the arity of a symbol f is a ﬁ-
nite sequence ((s1
1,...,s1
k1,s′1),...,(sn
1 ,...,sn
kn,s′n),s′′) indicating that the sym-
bol f has n arguments, the ﬁrst one of sort s′1 and binding k1 variables of sorts
s1
1,...,s1
k1,..., and that the resulting expression is itself of sort s′′.
Formally, expressions are deﬁned as follows.
Deﬁnition 1.11 (Expressions in a language) Given a language L, that is, a set of
sorts and a set of symbols each with an associated arity, and a family of inﬁnite,
pairwise disjoint sets of variables, indexed by sorts, the set of expressions in L is
inductively deﬁned by the following rules.
– Variables of sort s are expressions of sort s.

1.2
Languages
13
– If f is a symbol of arity ((s1
1,...,s1
k1,s′1),...,(sn
1 ,...,sn
kn,s′n),s′′), x1
1,...,x1
k1,
...,xn
1,...,xn
kn are variables of sorts s1
1,...,s1
k1,...,sn
1 ,...,sn
kn and t1,...,tn are
expressions of sorts s′1,...,s′n then f (x1
1 ...x1
k1t1,...,xn
1 ...xn
kntn) is an expres-
sion of sort s′′.
Deﬁnition 1.12 (Variables of an expression) The set of variables of an expression
is deﬁned by structural induction, as follows.
– Var(x) = {x},
– Var(f (x1
1 ...x1
k1t1,...,xn
1 ...xn
kntn))
= Var(t1) ∪{x1
1,...,x1
k1} ∪··· ∪Var(tn) ∪{xn
n,...,xn
kn}.
Deﬁnition 1.13 (Free variables) The set of free variables of an expression is deﬁned
by structural induction, as follows.
– FV(x) = {x},
– FV(f (x1
1 ...x1
k1t1,...,xn
1 ...xn
kntn))
= (FV(t1) \ {x1
1,...,x1
k1}) ∪··· ∪(FV (tn) \ {xn
n,...,xn
kn}).
For example, Var(∀x (x = x)) = {x}, but FV (∀x (x = x)) = ∅.
An expression without free variables is said to be closed.
Deﬁnition 1.14 (Height) The height of an expression is also deﬁned by structural
induction:
– Height(x) = 0,
– Height(f (x1
1 ...x1
k1t1,...,xn
1 ...xn
kntn)) = 1 + max(Height(t1),...,Height(tn)).
1.2.4 Substitution
The ﬁrst operation that we need to deﬁne is substitution: indeed, the rôle of variables
is not only to be bound but also to be substituted. For example, from the proposition
∀x (odd(x) ⇒even(x + 1)), we might want to deduce the proposition odd(3) ⇒
even(3 + 1), obtained by substituting the variable x by the expression 3.
Deﬁnition 1.15 (Substitution) A substitution is a mapping from variables to expres-
sions, with a ﬁnite domain, such that each variable is associated to an expression of
the same sort. In other words, a substitution is a ﬁnite set of pairs where the ﬁrst
element is a variable and the second an expression, such that each variable occurs at
most once as ﬁrst element in a pair. We can also deﬁne a substitution as an associa-
tion list: θ = t1/x1,...,tn/xn.
When a substitution is applied to an expression, each occurrence of a variable
x1,...,xn in the expression is replaced by t1,...,tn, respectively.

14
1
Predicate Logic
Of course, this replacement only affects the free variables. For example, if we
substitute the variable x by the expression 2 in the expression x + 3, we should ob-
tain the expression 2 + 3. However, if we substitute the variable x by the expression
2 in the expression ∀x (x = x), we should obtain the expression ∀x (x = x) instead
of ∀x (2 = 2).
A ﬁrst attempt to describe the application of a substitution leads to the following
deﬁnition:
Deﬁnition 1.16 (Application of a substitution—with capture) Let θ = t1/x1,...,
tn/xn be a substitution and t an expression. The expression ⟨θ⟩t is deﬁned by induc-
tion as follows.
– ⟨θ⟩xi = ti,
– ⟨θ⟩x = x if x is not in the domain of θ,
– ⟨θ⟩f (y1
1 ...y1
k1 u1,...,yp
1 ...yp
kp up)
= f (y1
1 ...y1
k1 ⟨θ|(V\{y1
1,...,y1
k1})⟩u1,...,yp
1 ...yp
kp ⟨θ|(V\{yp
1 ,...,yp
kp })⟩up)
where we use the notation θ|V\{y1,...,yk} for the restriction of the substitution θ to
the set V \ {y1,...,yk}, that is, the substitution where we have omitted all the pairs
where the ﬁrst element is one of the variables y1,...,yk.
This deﬁnition is problematic, because substitutions can capture variables. For
example, the expression ∃x (x + 1 = y) states that y is the successor of some
number. If we substitute y by 4 in this expression, we obtain the expression
∃x (x + 1 = 4), which indicates that 4 is the successor of some number. If we sub-
stitute y by z, we obtain the expression ∃x (x + 1 = z), which again states that z is
the successor of some number. But if we substitute y by x, we obtain the expression
∃x (x +1 = x) stating that there is some number which is its own successor, instead
of the expected expression indicating that x is the successor of some number.
We can avoid this problem if we change the name of the bound variable: bound
variables are dummies, their name does not matter. In other words, in the expression
∃x (x +1 = y), we can replace the bound variable x by any other variable, except of
course y. Similarly, when we substitute in the expression u the variables x1,...,xn
by expressions t1,...,tn, we can change the names of the bound variables in u to
avoid capture. It sufﬁces to replace them by names that do not occur in x1,...,xn,
or in the variables of t1,...,tn, or in the variables of u.
We start by deﬁning, using the notion of substitution with capture deﬁned above,
an equivalence relation on expressions, by induction on their height. This relation is
called alphabetic equivalence and it corresponds to bound-variable renaming.
Deﬁnition 1.17 (Alphabetic equivalence) The alphabetic equivalence relation, also
called alpha-equivalence, is inductively deﬁned by the rules
– x ∼x,
– f (y1
1 ...y1
k1 t1,...,yn
1 ...yn
kn tn) ∼f (y′1
1 ...y′1
k1 t′
1,...,y′n
1 ...y′n
kn t′
n) if for all i,
and for any sequence of fresh variables z1,...,zki (that is, variables that do not
occur in ti or t′
i), ⟨z1/yi
1,...,zki/yi
ki⟩ti ∼⟨z1/y′i
1 ,...,zki/y′i
ki⟩t′
i.

1.2
Languages
15
For example, the expressions ∀x (x = x) and ∀y (y = y) are α-equivalent.
In the rest of the book we will work with expressions modulo α-equivalence, that
is, we will consider implicitly α-equivalence classes of expressions.
We can now deﬁne the operation of substitution by induction on the height of
expressions.
Deﬁnition 1.18 (Application of a substitution) Let θ = t1/x1,...,tn/xn be a substi-
tution and t an expression. The expression θt is deﬁned by induction on the height
of t as follows.
– θxi = ti,
– θx = x if x is not in the domain of θ,
– θf (y1
1 ...y1
k1u1,...,yp
1 ...yp
kpup)
=
f (z1
1 ...z1
k1θ⟨z1
1/y1
1,...,z1
k1/y1
k1⟩u1,...,
zp
1 ...zp
kpθ⟨zp
1 /yp
1 ,...,zp
kp/yp
kp⟩up) where z1
1,...,z1
k1,...,zp
1 ,...,zp
kp are vari-
ables that do not occur in f (y1
1 ...y1
k1 u1,...,yp
1 ...yp
kp up) or in θ.
For example, if we substitute the variable y by the expression 2 × x in the ex-
pression ∃x (x + 1 = y), we obtain the expression ∃z (z + 1 = 2 × x). The choice
of variable z is arbitrary, we could have chosen v or w, and we would have obtained
the same expression modulo α-equivalence.
Deﬁnition 1.19 (Composition of substitutions) The composition of the substitutions
θ = t1/x1,...,tn/xn and σ = u1/y1,...,up/yp is the substitution
θ ◦σ = {θ(σz)/z|z ∈{x1,...,xn,y1,...,yp}}
We can prove, by induction on the height of t, that for any expression t
(θ ◦σ)t = θ(σt)
1.2.5 Articulation
In the deﬁnitions given above, there were no restrictions on the number of symbols
in a language. However, we should take into account that, in ﬁne, expressions will
be written using a ﬁnite alphabet. If each symbol of the language is represented by a
letter in this alphabet, then the set of symbols of the language will be ﬁnite. However,
it would be possible to represent a symbol by a word built out of several symbols
from this ﬁnite alphabet, or more generally, a symbol could be represented by a
labelled tree, where the labels are elements of a ﬁnite set. For instance, in Geometry,
some symbols, such as π, are letters whereas others, such as “bisector”, are words.
The process could be iterated: we could represent the symbols of a language with
trees labelled with trees which are in turn labelled with the elements of a ﬁnite set.
This leads us to the following deﬁnition.

16
1
Predicate Logic
Deﬁnition 1.20 (Articulated set of trees)
– A set of trees is simply articulated, or 1-articulated, if all the nodes of trees in
this set are labelled with elements of a ﬁnite set.
– A set of trees is (n+1)-articulated, if all the nodes of trees in this set are labelled
with elements of an n-articulated set of trees.
A set of trees is articulated if it is n-articulated for some natural number n.
For example, the set of expressions without variables in a language consisting of
a ﬁnite set of symbols is a simply articulated set. However, since the set of variables
is inﬁnite, the set of expressions of a language is at least doubly articulated: an
inﬁnite set of variables, such as x,x′,x′′,x′′′,x′′′′,... can be represented by a set of
trees where nodes are labelled with symbols x or ′.
If a language is articulated, its set of symbols is ﬁnite or countable. In some cases,
languages with non-countable sets of symbols (thus non-articulated) are needed; we
will see an example in Sect. 2.4. However, we must keep in mind that this notion of
a language is more general the usual one, since expressions can no longer be written
using a ﬁnite alphabet.
Let E be a set and f1,f2,... rules over the set E. The set of derivations using
f1,f2,... is not always articulated. However, if E is an articulated set of trees, then
the set of derivations using f1,f2,... is articulated. Similarly, if each rule f1,f2,...
can be associated to an element of an articulated set, then the set of derivations
labelled with rules f1,f2,... is articulated.
1.3 The Languages of Predicate Logic
The concept of language introduced in the previous section is very general. In this
section we will focus in particular on the languages used in predicate logic. In these
languages, most symbols do not bind any variable. The only exceptions are the
quantiﬁers ∀and ∃. Moreover, these languages include terms, to denote objects,
and propositions, to express properties of these objects. Terms may be many-sorted.
Thus, a language is deﬁned by a non-empty set S of term sorts, a set F of function
symbols that are used to build terms, and a set P of predicate symbols to build
propositions.
The sorts of the language are the term sorts together with a distinguished sort
Prop for propositions. Since function symbols do not bind variables, their arities
have the form (s1,...,sn,s′) where s1,...,sn and s′ are term sorts. If a symbol f
has arity (s1,...,sn,s′) and t1,...,tn are terms of sorts s1,...,sn, respectively, then
the expression f (t1,...,tn) is a term of sort s′. Similarly, since predicate symbols
do not bind variables, their arities have the form (s1,...,sn,Prop), where s1,...,sn
are term sorts. Such an arity is written simply (s1,...,sn). If a symbol P has arity
(s1,...,sn) and t1,...,tn are terms of sorts s1,...,sn, respectively, then the expres-
sion P(t1,...,tn) is a proposition. In addition to these symbols, which are speciﬁc
to each language, there is a set of symbols which is common to all the languages of

1.3
The Languages of Predicate Logic
17
predicate logic: ⊤(read true), and ⊥(read false), with arity (Prop), ¬ (read not),
with arity (Prop,Prop), ∧(read and), ∨(read or), and ⇒(read implies), with arity
(Prop,Prop,Prop) and ﬁnally, for each element of S, two quantiﬁers ∀s, for all, and
∃s, there exists, with arity ((s,Prop),Prop). We do not need to introduce variables
of sort Prop because none of the symbols can bind those variables.
Deﬁnition 1.21 (Language of predicate logic) A language L is a tuple (S,F,P)
where S is a non-empty set of term sorts and F and P are sets whose elements
are called function symbols and predicate symbols, respectively. Each function sym-
bol has an associated arity, which is an (n + 1)-tuple of elements of S, and each
predicate symbol has an arity which is an n-tuple of elements of S.
Deﬁnition 1.22 (Term) Let L = (S,F,P) be a language and (Vs)s∈S a family of
inﬁnite, pairwise disjoint sets, indexed by term sorts, whose elements are called
variables. The set of terms of sort s of the language L, for a given family of sets of
variables (Vs)s∈S, is inductively deﬁned as follows.
– Variables of sort s are terms of sort s.
– If f is a symbol of arity (s1,...,sn,s′) and t1,...,tn are terms of sorts s1,...,sn,
then f (t1,...,tn) is a term of sort s′.
Deﬁnition 1.23 (Proposition) Let L = (S,F,P) be a language and (Vs)s∈S a fam-
ily of inﬁnite, pairwise disjoint sets, indexed by term sorts, whose elements are
called variables. The set of propositions of the language L, for a given family of
sets of variables (Vs)s∈S, is inductively deﬁned as follows.
– If P is a predicate symbol of arity (s1,...,sn) and t1,...,tn are terms of sort
s1,...,sn, then the expression P(t1,...,tn) is a proposition.
– ⊤and ⊥are propositions.
– If A is a proposition, then ¬A is a proposition.
– If A and B are propositions, then A ∧B, A ∨B and A ⇒B are propositions.
– If A is a proposition and x is a variable of sort s, then ∀sx A and ∃sx A are
propositions.
The notation A ⇔B will be used as an abbreviation for (A ⇒B) ∧(B ⇒A).
A proposition of the form P(t1,...,tn) is called atomic.
If S is a singleton, the language has only one term sort and the arity of a function
or predicate symbol can be simply speciﬁed by a number: the number of arguments
of the symbol.
Exercise 1.2 Let L be a language with only one term sort and symbols C, N, 0, =,
ˆ, ∈and #, where the symbol ˆ denotes exponentiation and # cardinal.
1. Represent the proposition
Any complex number different from 0 has n nth roots.
as a proposition in the language L.

18
1
Predicate Logic
2. Which symbols are function symbols and which symbols are predicate symbols?
3. Specify the arity of each symbol.
1.4 Proofs
We would like to distinguish propositions that can be proved, such as ∃x (x = 0+1),
from propositions that cannot be proved, such as ∃x (0 = x + 1).
We can distinguish them if we specify a set of rules and deﬁne inductively, us-
ing those rules, a subset of the set of propositions: the set of theorems or provable
propositions.
Exercise 1.3 Consider the language with one term sort and function symbols 0 of
arity zero, and S, successor, of arity 1, and a predicate symbol ≤of arity 2. We have
the following rules
∀x A
(t/x)A
A ⇒B A
B
A B
A ∧B
∀x∀y∀z ((x ≤y ∧y ≤z) ⇒x ≤z)
∀x (x ≤S(x))
Show that the proposition
0 ≤S(S(0))
can be proved.
This kind of proof is usually called a proof à la Frege and Hilbert. It is difﬁcult
to write a proof in this way because the rules force us to use the same hypotheses for
the whole proof. It is hard to translate a standard reasoning pattern: to prove A ⇒B,
assume A and prove B under this hypothesis. This observation led to the introduc-
tion of a notion of pair, consisting of a ﬁnite set of hypotheses and a conclusion.
Such a pair is called a sequent.
Deﬁnition 1.24 (Sequent) A sequent is a pair Γ ⊢A, where Γ is a ﬁnite set of
propositions and A is a proposition.

1.4
Proofs
19
Deﬁnition 1.25 (Natural deduction rules)
axiom A ∈Γ
Γ ⊢A
⊤-intro
Γ ⊢⊤
Γ ⊢⊥⊥-elim
Γ ⊢A
Γ ⊢A Γ ⊢B ∧-intro
Γ ⊢A ∧B
Γ ⊢A ∧B ∧-elim
Γ ⊢A
Γ ⊢A ∧B ∧-elim
Γ ⊢B
Γ ⊢A
∨-intro
Γ ⊢A ∨B
Γ ⊢B
∨-intro
Γ ⊢A ∨B
Γ ⊢A ∨B
Γ,A ⊢C
Γ,B ⊢C ∨-elim
Γ ⊢C
Γ,A ⊢B
⇒-intro
Γ ⊢A ⇒B
Γ ⊢A ⇒B
Γ ⊢A ⇒-elim
Γ ⊢B
Γ,A ⊢⊥¬-intro
Γ ⊢¬A
Γ ⊢A Γ ⊢¬A ¬-elim
Γ ⊢⊥
Γ ⊢A
∀-intro x not free in Γ
Γ ⊢∀x A
Γ ⊢∀x A ∀-elim
Γ ⊢(t/x)A
Γ ⊢(t/x)A ∃-intro
Γ ⊢∃x A

20
1
Predicate Logic
Γ ⊢∃x A Γ,A ⊢B ∃-elim x not free in Γ,B
Γ ⊢B
excluded middle
Γ ⊢A ∨¬A
The rules ⊤-intro, ∧-intro, ∨-intro, ⇒-intro, ¬-intro, ∀-intro and ∃-intro are
called introduction rules and the rules ⊥-elim, ∧-elim, ∨-elim, ⇒-elim, ¬-elim,
∀-elim and ∃-elim are elimination rules. Natural deduction rules are divided into
four groups: introduction rules, elimination rules, the axiom rule and the rule of the
excluded middle.
Deﬁnition 1.26 (Provable sequent) The set of provable sequents is inductively de-
ﬁned by the natural deduction rules.
Deﬁnition 1.27 (Proof) A proof of a sequent Γ ⊢A is a derivation of this sequent,
that is, a tree where nodes are labelled by sequents and where the root is labelled by
Γ ⊢A, and such that if a node is labelled by a sequent Δ ⊢B and its children are
labelled by sequents Σ1 ⊢C1,...,Σn ⊢Cn then there is a natural deduction rule
that allows us to deduce Δ ⊢B from Σ1 ⊢C1,...,Σn ⊢Cn.
Therefore, a sequent Γ ⊢A is provable if there exists a proof of Γ ⊢A.
Exercise 1.4 Consider a language with three sorts of terms: point, line and scalar,
two predicate symbols = with arity (scalar,scalar) and ∈with arity (point,line)
and two function symbols d, distance, with arity (point,point,scalar) and b, bisec-
tor, with arity (point,point,line). Let Γ be the set containing the propositions
∀x∀y∀z (x ∈b(y,z) ⇔d(x,y) = d(x,z))
∀x∀y∀z ((x = y ∧y = z) ⇒x = z)
and A a proposition stating that if two bisectors of the triangle xyz intersect at a
point w, then the three bisectors intersect at this point:
∀w∀x∀y∀z ((w ∈b(x,y) ∧w ∈b(y,z)) ⇒w ∈b(x,z))
Write a proof of the sequent Γ ⊢A.
The following a property shows that it is possible to add useless hypotheses in a
sequent.
Proposition 1.6 (Weakening) If the sequent Γ ⊢A is provable, then also the se-
quent Γ,B ⊢A is provable.
Proof By induction over the structure of a proof of Γ ⊢A.
□

1.4
Proofs
21
Proposition 1.7 (Double negation) The following propositions are equivalent.
1. The sequent Γ ⊢A is provable.
2. The sequent Γ,¬A ⊢⊥is provable.
3. The sequent Γ ⊢¬¬A is provable.
Proof
– (1.) ⇒(2.)
If the sequent Γ ⊢A is provable, then, by Proposition 1.6, so is Γ,¬A ⊢A. The
sequent Γ,¬A ⊢¬A is provable using rule axiom and thus the sequent Γ,¬A ⊢
⊥can be derived using rule ¬-elim.
– (2.) ⇒(3.)
If the sequent Γ,¬A ⊢⊥is provable, then the sequent Γ ⊢¬¬A is provable with
rule ¬-intro.
– (3.) ⇒(2.)
If the sequent Γ ⊢¬¬A is provable, then, by Proposition 1.6, so is Γ,¬A ⊢
¬¬A. The sequent Γ,¬A ⊢¬A is provable using rule axiom and thus the sequent
Γ,¬A ⊢⊥can be derived using rule ¬-elim.
– (2.) ⇒(1.)
If the sequent Γ,¬A ⊢⊥has a proof π, then the sequent Γ ⊢A has a proof
excl. middle
Γ ⊢A ∨¬A
axiom
Γ,A ⊢A
π
Γ,¬A ⊢⊥⊥-elim
Γ,¬A ⊢A ∨-elim
Γ ⊢A
□
Proposition 1.8 The sequent ⊢¬∃x¬A ⇒∀xA is provable.
Proof This sequent has a proof
excl. middle
¬∃x¬A ⊢A ∨¬A
axiom
¬∃x¬A,A ⊢A
axiom
¬∃x¬A,¬A ⊢¬∃x ¬A
axiom
¬∃x¬A,¬A ⊢¬A
∃-intro
¬∃x¬A,¬A ⊢∃x ¬A ¬-elim
¬∃x¬A,¬A ⊢⊥⊥-elim
¬∃x¬A,¬A ⊢A ∨-elim
¬∃x¬A ⊢A
∀-intro
¬∃x¬A ⊢∀x A
⇒-intro
⊢¬∃x¬A ⇒∀x A
□
Deﬁnition 1.28 (Theory) A theory is a ﬁnite or inﬁnite set of closed propositions;
the elements of a theory are called axioms.
If a theory T is ﬁnite, we say that a proposition A is a theorem in this theory, or
that the proposition can be proved in this theory, if the sequent T ⊢A is provable.
However, in the general case the pair T ⊢A is not a sequent. We need to give a
more general deﬁnition.

22
1
Predicate Logic
Deﬁnition 1.29 (Theorem)
A proposition A is a theorem in the theory T , or a
provable proposition in this theory, if there exists a ﬁnite subset Γ of T such that
the sequent Γ ⊢A is provable.
Deﬁnition 1.30 (Consistency, contradiction) A theory T is consistent if there exists
some proposition that is not provable in T . Otherwise it is contradictory.
Proposition 1.9 A theory is contradictory if and only if the proposition ⊥can be
proved in this theory.
Proof If a theory is contradictory all propositions are provable, in particular the
proposition ⊥. Conversely, if the proposition ⊥can be proved in a given theory,
then there exists a ﬁnite subset Γ of T such that the sequent Γ ⊢⊥has a proof π.
Let A be an arbitrary proposition. The sequent Γ ⊢A has a proof
π
Γ ⊢⊥⊥-elim
Γ ⊢A
and therefore the proposition A is provable in the theory T .
□
Proposition 1.10 A theory T is contradictory if and only if there exists a proposi-
tion A such that both A and ¬A are provable in this theory.
Proof If the theory is contradictory, all propositions are provable, therefore the
propositions ⊤and ¬⊤are provable.
Conversely, if the propositions A and ¬A are provable in the theory, there are two
ﬁnite subsets Γ and Γ ′ such that the sequents Γ ⊢A and Γ ′ ⊢¬A are provable.
By Proposition 1.6, the sequents Γ,Γ ′ ⊢A and Γ,Γ ′ ⊢¬A have proofs π1 and π2.
Therefore, the sequent Γ,Γ ′ ⊢⊥has a proof
π2
Γ,Γ ′ ⊢¬A
π1
Γ,Γ ′ ⊢A ¬-elim
Γ,Γ ′ ⊢⊥
Thus, the proposition ⊥is provable in the theory T and, by Proposition 1.9, the
theory T is contradictory.
□
Exercise 1.5 Show that if the sequent Γ ⊢A ⇔A′ is provable and x is not free
in Γ then so are the sequents Γ ⊢(A ∧B) ⇔(A′ ∧B), Γ ⊢(B ∧A) ⇔(B ∧A′),
Γ ⊢(A ∨B) ⇔(A′ ∨B), Γ ⊢(B ∨A) ⇔(B ∨A′), Γ ⊢(A ⇒B) ⇔(A′ ⇒B),
Γ ⊢(B ⇒A) ⇔(B ⇒A′), Γ ⊢(¬A) ⇔(¬A′), Γ ⊢(∀x A) ⇔(∀x A′) and Γ ⊢
(∃x A) ⇔(∃x A′).
Exercise 1.6 A many-sorted theory can be relativised, that is, transformed into a
theory with only one sort of terms. For this, to each function symbol f of arity
(s1,...,sn,s′) we associate a function symbol f ′ of arity n, and to each predicate

1.5
Examples of Theories
23
symbol P of arity (s1,...,sn) we associate a predicate symbol P ′ of arity n. For
each sort s, we introduce a unary predicate symbol Ss. Then, terms and propositions
can be translated as follows.
– |x| = x,
– |f (t1,...,tn)| = f ′(|t1|,...,|tn|),
– |P(t1,...,tn)| = P ′(|t1|,...,|tn|),
– |⊤| = ⊤,
– |⊥| = ⊥,
– |¬A| = ¬|A|,
– |A ∧B| = |A| ∧|B|, |A ∨B| = |A| ∨|B|, |A ⇒B| = |A| ⇒|B|,
– |∀sx A| = ∀x (Ss(x) ⇒|A|), |∃sx A| = ∃x (Ss(x) ∧|A|).
A theory is translated by translating each axiom and adding an axiom
∃x Ss(x)
for each sort s and an axiom
∀x1 ...∀xn ((Ss1(x1) ∧··· ∧Ssn(xn)) ⇒(Ss′(f ′(x1,...,xn))))
for each function symbol f of arity (s1,...,sn,s′).
Let T ′ be the theory consisting of an axiom Ss(x) for each variable of sort s.
Show that if the term t has sort s, then the proposition Ss(|t|) is provable in the
theory |T |, T ′.
Show that if the proposition A is provable in the theory T , then the proposition
|A| is provable in the theory |T |, T ′.
Show that if the closed proposition A is provable in the theory T , then the propo-
sition |A| is provable in the theory |T |.
1.5 Examples of Theories
Deﬁnition 1.31 (Equality axioms) Consider a language with predicates =s of sort
(s,s) for some sorts s. The axioms of equality for this language are the following.
For each sort s for which there is an equality symbol, we have the identity axiom
∀sx (x =s x)
For each function symbol f of arity (s1,...,sn,s′) such that the sort s′ has an
equality symbol and for each natural number i such that the sort si has an equality
symbol, we have the axiom
∀x1 ...∀xi∀x′
i ...∀xn (xi =si x′
i ⇒f (x1,...,xi,...,xn) =s′ f (x1,...,x′
i,...,xn))
For each predicate symbol P of arity (s1,...,sn) and each natural number i such
that the sort si has an equality symbol, we have the axiom
∀x1 ...∀xi∀x′
i∀xn (xi =si x′
i ⇒(P(x1,...,xi,...,xn) ⇒P(x1,...,x′
i,...,xn)))

24
1
Predicate Logic
Exercise 1.7 Give a proof for each of the following propositions in the theory of
equality.
∀sx∀sy∀sz (x =s y ⇒(y =s z ⇒x =s z))
∀sx∀sy (x =s y ⇒y =s x)
Deﬁnition 1.32 (The theory of classes) Consider a language with two term sorts:
ι for objects and κ for classes of objects, and with an arbitrary number of function
symbols of arity (ι,...,ι,ι) and predicate symbols of arity (ι,...,ι), as well as a
predicate symbol ϵ of arity (ι,κ).
The theory of classes for this language includes an axiom
∀x1 ...∀xn∃c∀y (y ϵ c ⇔A)
for each proposition A that does not contain the symbol ϵ and whose free variables
are included in x1,...,xn,y. This set of axioms is known as the comprehension
schema.
Deﬁnition 1.33 (Arithmetic) The language of arithmetic includes two term sorts ι
and κ, a constant 0 of sort ι, function symbols S, successor, of arity (ι,ι), + and
× of arity (ι,ι,ι) and predicate symbols ϵ of arity (ι,κ) and = of arity (ι,ι). In
addition to the equality axioms and the comprehension schema, we have the axioms
for successor
∀x∀y (S(x) = S(y) ⇒x = y)
∀x ¬(0 = S(x))
the induction axiom
∀c (0 ϵ c ⇒∀x (x ϵ c ⇒S(x) ϵ c) ⇒∀y y ϵ c)
and the axioms for addition and multiplication
∀y (0 + y = y)
∀x∀y (S(x) + y = S(x + y))
∀y (0 × y = 0)
∀x∀y (S(x) × y = (x × y) + y)
Exercise 1.8 (Induction schema) This exercise relies on Exercise 1.5, which should
be done prior to this one.

1.5
Examples of Theories
25
Show that, for each proposition A in the language of arithmetic that does not
contain the symbol ϵ and whose free variables are included in x1,...,xn,y, the
proposition
∀x1 ...∀xn ((0/y)A ⇒∀m ((m/y)A ⇒(S(m)/y)A) ⇒∀n (n/y)A)
is provable in the theory of arithmetic.
Deﬁnition 1.34 (Naive set theory) The language of the naive theory of sets has one
sort and a binary predicate symbol ∈. It contains an axiom of the form
∀x1 ...∀xn∃a∀y (y ∈a ⇔A)
for each proposition A with free variables in x1,...,xn,y.
Exercise 1.9 (Russell’s paradox) Show that the sequent
∀y (y ∈a ⇔¬y ∈y) ⊢⊥
is provable and then deduce that the naive theory of sets is contradictory. Why is it
that this paradox does not apply to the theory of classes?
Deﬁnition 1.35 (The theory of binary classes) Consider a language with two term
sorts ι for objects and σ for binary classes, with an arbitrary number of function
symbols of arity (ι,...,ι,ι) and predicate symbols of arity (ι,...,ι), as well as a
predicate symbol ϵ2 with arity (ι,ι,σ).
The theory of binary classes includes an axiom of the form
∀x1 ...∀xn∃r∀y∀z (y,z ϵ2 r ⇔A)
for each proposition A that does not contain the symbol ϵ2 and whose free variables
are in x1,...,xn,y,z. This set of axioms is usually called binary comprehension
schema.
Deﬁnition 1.36 (ZF: Zermelo-Fraenkel set theory)
The language of Zermelo-
Fraenkel set theory has two term sorts ι and σ, a predicate symbol ϵ2 of arity
(ι,ι,σ), a predicate symbol = of arity (ι,ι) and a predicate symbol ∈of arity (ι,ι)
(to represent that a set is a member of another set). In addition to the equality ax-
ioms and the binary comprehension schema, Zermelo-Fraenkel set theory has the
following axioms.
The axiom of extensionality postulates that two sets are equal if they have the
same elements,
∀x∀y ((∀z (z ∈x ⇔z ∈y)) ⇒x = y)
The axiom of union postulates that if we have a set x with elements v0,v1,..., then
we can build the union of the sets v0,v1,...
∀x∃z∀w (w ∈z ⇔(∃v (w ∈v ∧v ∈x)))

26
1
Predicate Logic
The axiom of the power set postulates that if we have a set x we can build a set
where the elements are all the subsets of x
∀x∃z∀w (w ∈z ⇔(∀v (v ∈w ⇒v ∈x)))
The axiom of inﬁnity postulates that we can build an inﬁnite set. Let Empty be the
proposition ∀y (¬(y ∈x)). We denote by Empty[t] the proposition (t/x)Empty. Let
Succ be the proposition ∀z (z ∈y ⇔(z ∈x ∨z = x)). We denote by Succ[t,u]
the proposition (t/x,u/y)Succ. Intuitively, this means that u is the set t ∪{t}. The
axiom of inﬁnity is
∃I (∀x (Empty[x] ⇒x ∈I) ∧∀x∀y ((x ∈I ∧Succ[x,y]) ⇒y ∈I))
The axiom of replacement postulates that if we have a set a and a functional binary
class r, we can build the set of the objects associated to an element of a by the
binary class r. Let functional be the proposition ∀y∀z∀z′ ((y,z ϵ2 r ∧y,z′ ϵ2 r) ⇒
z = z′). We denote by functional[t] the proposition (t/r)functional. The axiom of
replacement is
∀r (functional[r] ⇒∀a∃b∀z (z ∈b ⇔∃y (y ∈a ∧y,z ϵ2 r)))
Exercise 1.10 (Replacement Schema) This exercise relies on Exercise 1.5, which
should be done prior to this one.
Let A be a proposition that does not contain the symbol ϵ2 and with free variables
in x1,...,xn,y,z. We denote by A[t,u] the proposition (t/y,u/z)A. Show that the
proposition
∀x1 ...∀xm ((∀y∀z∀z′ ((A[y,z] ∧A[y,z′]) ⇒z = z′))
⇒∀a∃b∀z (z ∈b ⇔∃y (y ∈a ∧A[y,z])))
is provable in ZF.
Exercise 1.11 (Separation Schema) This exercise relies on Exercises 1.5 and 1.10,
which should be done prior to this one.
Let A be a proposition that does not contain the symbol ϵ2 and with free vari-
ables in x1,...,xn,y. We denote by A[t] the proposition (t/y)A. Show that the
proposition
∀x1 ...∀xn∀a∃b∀y (y ∈b ⇔(y ∈a ∧A[y]))
is provable in ZF.
Exercise 1.12 (Theorem of the empty set) This exercise relies on Exercise 1.11,
which should be done prior to this one.
Show that the proposition
∃b Empty[b]
is provable in ZF.

1.5
Examples of Theories
27
Exercise 1.13 (Theorem of pairing) This exercise relies on Exercise 1.10, which
should be done prior to this one.
Let One be the proposition ∀y (y ∈x ⇔Empty[y]). We denote by One[t] the
proposition (t/x)One. Intuitively, this means that t = {∅}. Let Two be the propo-
sition ∀y (y ∈x ⇔(Empty[y] ∨One[y])). We denote by Two[t] the proposition
(t/x)Two. Intuitively, this means that t = {∅,{∅}}.
Show that the propositions ∃x Empty[x], ∃x One[x], ∃x Two[x] and
∀x ¬(Empty[x] ∧One[x]) are provable in ZF.
Show that the proposition
∀x∀y∃z∀w (w ∈z ⇔(w = x ∨w = y))
is provable in ZF.
Exercise 1.14 (Pairing) This exercise relies on Exercise 1.13, which should be done
prior to this one.
In set theory, the ordered pair (a,b) is a set containing the elements {a} and
{a,b}. Write a proposition, using only the symbols = and ∈, to state that the pair
consisting of the elements x and y is equal to z. Write a proposition to state that the
ordered pair consisting of the elements x and y is an element of z.
Exercise 1.15 (Union of two sets) This exercise relies on Exercise 1.13, which
should be done prior to this one.
Show that the proposition
∀x∀y∃z∀w (w ∈z ⇔(w ∈x ∨w ∈y))
is provable in ZF.
Exercise 1.16 This exercise relies on Exercises 1.12 and 1.15, which should be
done prior to this one.
Show that the following propositions are provable.
∃x Empty[x]
∀x∃y Succ[x, y]
∀x∀y ((Empty[x] ∧Empty[y]) ⇒x = y)
∀x∀y∀y′ ((Succ[x,y] ∧Succ[x,y′]) ⇒y = y′)
∀x∀y ¬(Succ[x,y] ∧Empty[y])
Exercise 1.17 (Von Neumann’s natural numbers) This exercise relies on Exer-
cises 1.11 and 1.16, which should be done prior to this one.

28
1
Predicate Logic
In set theory, the natural numbers are deﬁned by the following sets 0 = ∅, 1 = {0},
2 = {0,1}, 3 = {0,1,2}, .... Thus, a set is a natural number if it belongs to all the
sets that contain 0 and are closed under successor. Write a proposition N with a free
variable x and using only the symbols = and ∈to state that x is a natural numbers.
We denote by N[t] the proposition (t/x)N. Note that all the natural numbers be-
long to the set I whose existence is postulated in the axiom of inﬁnity. Prove the
proposition
∃N (x ∈N ⇔N[x])
Write a proposition specifying the induction principle: if a set contains 0 and
is closed under successor, then it contains all the natural numbers. Show that this
proposition is provable in ZF.
Exercise 1.18 This exercise relies on Exercises 1.11, 1.13, 1.14, 1.16 and 1.17,
which should be done prior to this one.
Let succ be the functional binary class deﬁned by comprehension as follows:
x,y ϵ2 succ ⇔Succ[x,y]. The axiom of inﬁnity postulates the existence of a set
containing 0 and closed under the functional binary class succ. In this exercise we
will show that as a consequence of this axiom, if a is an arbitrary set and r an
arbitrary functional binary class, then there exists a set containing a and closed
under r. That is, we aim at proving the proposition
∀a∀r (functional[r] ⇒∃E (a ∈E ∧∀y∀y′ ((y ∈E ∧y,y′ ϵ2 r) ⇒y′ ∈E)))
To do this, we assume functional[r] and try to prove the proposition ∃E (a ∈E ∧
∀y∀y′ ((y ∈E ∧y,y′ ϵ2 r) ⇒y′ ∈E))).
Let A be the proposition
n ∈N ∧∀g (((∀p (Empty[p] ⇒(p,a) ∈g))
∧∀p∀p′∀y∀y′ ((p ∈n ∧(p,y) ∈g ∧Succ[p,p′] ∧y,y′ ϵ2 r) ⇒(p′,y′) ∈g))
⇒(n,x) ∈g)
We denote by A[t,u] the proposition (t/n,u/x)A
1. Prove the propositions
∀n (Empty[n] ⇒A[n,a])
∀n∀n′∀x∀x′ ((A[n,x] ∧Succ[n,n′] ∧x,x′ ϵ2 r) ⇒A[n′,x′])
2. We now want to prove the proposition
∀n∀x∀y ((A[n,x] ∧A[n,y]) ⇒x = y)
First, we will assume
∀p∀x∀y ((p ∈n ∧A[p,x] ∧A[p,y]) ⇒x = y)

1.5
Examples of Theories
29
and prove
∀x∀y ((A[n,x] ∧A[n,y]) ⇒x = y)
Let r′ be the binary class deﬁned by comprehension as follows:
p,c ϵ2 r′ ⇔∃y (c = (p,y) ∧((Empty[p] ∧y = a)
∨∃m∃w (m ∈n ∧A[m,w] ∧Succ[m,p] ∧w,y ϵ2 r)))
Show that the binary class r′ is functional. Let G be the image of successor of n
under the binary class r′, which can be built using the replacement axiom.
Prove the proposition ∀p∀x ((p,x) ∈G ⇒A[p,x]).
Prove the propositions
∀p (Empty[p] ⇒(p,a) ∈G)
∀p∀p′∀x∀x′ ((p ∈n ∧(p,x) ∈G ∧Succ[p,p′] ∧x,x′ ϵ2 r) ⇒(p′,x′) ∈G))
Deduce the proposition
∀x (A[n,x] ⇒(n,x) ∈G)
Prove the proposition
∀n∀x∀y (((n,x) ∈G ∧(n,y) ∈G) ⇒x = y)
Prove the proposition
∀n∀x∀y ((A[n,x] ∧A[n,y]) ⇒x = y)
Let C be the subset of N containing all n such that ∀p∀x∀y ((p ∈n ∧A[p,x] ∧
A[p,y]) ⇒x = y). Show that the set C contains 0 and is closed under successor.
Show that it contains all the natural numbers. Then deduce
∀n∀x∀y ((A[n,x] ∧A[n,y]) ⇒x = y)
3. Let s be the binary class deﬁned by comprehension using the proposition A.
Show that the binary class s is functional. Let E be the image of N under s, built
using the axiom of replacement. Prove the propositions
a ∈E
∀y∀y′ ((y ∈E ∧y,y′ ϵ2 r) ⇒y′ ∈E)

30
1
Predicate Logic
1.6 Variations on the Principle of the Excluded Middle
We deﬁned the principle of the excluded middle using the rule
excluded middle
Γ ⊢A ∨¬A
but there are many alternative deﬁnitions.
1.6.1 Double Negation
As a ﬁrst alternative, we could replace the rule shown above by the rule
Γ ⊢¬¬A double negation
Γ ⊢A
which deﬁnes an equivalent system.
Proposition 1.11 The sequents that can be proved in natural deduction and in the
system where the rule of the excluded middle is replaced by the double negation rule
are exactly the same.
Proof We need to show that if the sequent Γ ⊢¬¬A is provable in natural deduc-
tion, then the sequent Γ ⊢A is provable as well. This is a consequence of Proposi-
tion 1.7.
We also need to show that all sequents of the form Γ ⊢A ∨¬A are provable
in the system in which the rule of the excluded middle is replaced by the double
negation rule. The following derivation proves the sequent Γ ⊢A ∨¬A.
axiom
Γ,¬(A ∨¬A) ⊢¬(A ∨¬A)
axiom
Γ,¬(A ∨¬A),A ⊢¬(A ∨¬A)
axiom
Γ,¬(A ∨¬A),A ⊢A
∨-intro
Γ,¬(A ∨¬A),A ⊢A ∨¬A ¬-elim
Γ,¬(A ∨¬A),A ⊢⊥¬-intro
Γ,¬(A ∨¬A) ⊢¬A
∨-intro
Γ,¬(A ∨¬A) ⊢A ∨¬A ¬-elim
Γ,¬(A ∨¬A) ⊢⊥¬-intro
Γ ⊢¬¬(A ∨¬A) double negation
Γ ⊢A ∨¬A
□
1.6.2 Multi-conclusion Sequents
It may seem surprising that if we change the form of the sequents and consider
sequents with several conclusions then the principle of the excluded middle can be
expressed without introducing a new rule.

1.6
Variations on the Principle of the Excluded Middle
31
This can be explained by analysing the proof given above. If the context Γ is
empty and the proposition A is just a 0-ary predicate symbol, it boils down to prov-
ing the sequent ⊢A ∨¬A. Using the rule ∨-intro, we are left with the sequent
⊢A or the sequent ⊢¬A; neither of them is provable. The rule ∨-intro replaces
the conclusion A ∨¬A of the sequent to be proved by either the conclusion A or
the conclusion ¬A, and in doing so it destroys the proposition A ∨¬A. The dou-
ble negation rule and the ¬-intro rule allow us to save a copy of this proposition,
by memorising it in the hypothesis ¬(A ∨¬A). We can then use this hypothesis
as many times as we want, by moving it to the conclusion of the sequent using the
rules ¬-elim and axiom. In the proof given above, we use the proposition twice, in
order to use twice the rule ∨-intro and obtain ﬁrst ¬A and then A. The conclusion
¬A becomes the hypothesis A and since we have A both as an assumption and a
conclusion, we can use the rule axiom.
Another alternative would be to leave the proposition A ∨¬A in the conclusion
of the sequent, but of course this will require a syntax for sequents where not only
multiple hypotheses but also multiple conclusions are permitted. We will also need
a rule to duplicate conclusions
Γ ⊢A,A,Δ contraction
Γ ⊢A,Δ
In addition, sequents should be deﬁned as pairs of ﬁnite multiset instead of pairs of
ﬁnite sets.
Intuitively, a proposition in the conclusions of a sequent plays the same rôle
as its negation in the hypotheses of the sequent. Thus, the comma separating two
hypotheses in a sequent can be thought of as an and whereas the one separating the
conclusions behaves like an or.
The proof given above can be rewritten as follows.
axiom
Γ,A ⊢⊥,A
∨-intro
Γ,A ⊢⊥,A ∨¬A ¬-intro
Γ ⊢¬A,A ∨¬A
∨-intro
Γ ⊢A ∨¬A,A ∨¬A contraction
Γ ⊢A ∨¬A
This leads us to an alternative deﬁnition of natural deduction.
Deﬁnition 1.37 (Rules of system D′)
axiom A ∈Γ
Γ ⊢A,Δ
Γ ⊢A,A,Δ contraction
Γ ⊢A,Δ
⊤-intro
Γ ⊢⊤,Δ

32
1
Predicate Logic
Γ ⊢⊥,Δ ⊥-elim
Γ ⊢A,Δ
Γ ⊢A,Δ Γ ⊢B,Δ ∧-intro
Γ ⊢A ∧B,Δ
Γ ⊢A ∧B,Δ ∧-elim
Γ ⊢A,Δ
Γ ⊢A ∧B,Δ ∧-elim
Γ ⊢B,Δ
Γ ⊢A,Δ
∨-intro
Γ ⊢A ∨B,Δ
Γ ⊢B,Δ
∨-intro
Γ ⊢A ∨B,Δ
Γ ⊢A ∨B,Δ Γ,A ⊢C,Δ Γ,B ⊢C,Δ ∨-elim
Γ ⊢C,Δ
Γ,A ⊢B,Δ ⇒-intro
Γ ⊢A ⇒B,Δ
Γ ⊢A ⇒B,Δ Γ ⊢A,Δ ⇒-elim
Γ ⊢B,Δ
Γ,A ⊢⊥,Δ ¬-intro
Γ ⊢¬A,Δ
Γ ⊢A,Δ Γ ⊢¬A,Δ ¬-elim
Γ ⊢⊥,Δ
Γ ⊢A,Δ
∀-intro x not free in Γ,Δ
Γ ⊢∀x A,Δ
Γ ⊢∀x A,Δ ∀-elim
Γ ⊢(t/x)A,Δ
Γ ⊢(t/x)A,Δ ∃-intro
Γ ⊢∃x A,Δ
Γ ⊢∃x A,Δ Γ,A ⊢B,Δ ∃-elim x not free in Γ,Δ,B
Γ ⊢B,Δ
Proposition 1.12 A sequent Γ ⊢A is provable in natural deduction if and only if it
is provable in the system D′.

1.6
Variations on the Principle of the Excluded Middle
33
Proof If there is a proof for the sequent Γ ⊢A in natural deduction, we can prove
by induction over the structure of this proof that the sequent is provable in the sys-
tem D′. All the natural deduction rules are also rules in system D′, except for the
rule of the excluded middle, but we have already seen that sequents of the form
Γ ⊢A ∨¬A are provable in system D′.
To prove the converse, thanks to Proposition 1.7 it is sufﬁcient to show that if the
sequent Γ ⊢A is provable in the system D′, then the sequent Γ,¬A ⊢⊥is prov-
able in natural deduction. More generally, we can prove that if the sequent Γ ⊢Δ is
provable in the system D′, then the sequent Γ,¬Δ ⊢⊥is provable in natural deduc-
tion, where ¬Δ is the set containing the negations of all the propositions in Δ. This
can be shown by induction over the structure of the proof of Γ ⊢Δ in system D′. If
the proof has the form
π
Γ ⊢A,A,Δ′
contraction
Γ ⊢A,Δ′
then the sets Γ,¬A,¬A,¬Δ and Γ,¬A,¬Δ are identical, and by induction the
sequent Γ,¬A,¬Δ ⊢⊥is provable in natural deduction. If the proof has the form
π1
Γ1 ⊢A1,Δ′
...
πn
Γn ⊢An,Δ′
r
Γ ⊢B,Δ′
where r is a rule in the system D′ different from contraction, then by induction the
sequents Γ1,¬A1,¬Δ′ ⊢⊥, ..., Γn,¬An,¬Δ′ ⊢⊥are provable in natural deduc-
tion. The sequents Γ1,¬Δ′ ⊢A1, ..., Γn,¬Δ′ ⊢An are also provable, as a conse-
quence of Proposition 1.7. Using the natural deduction rule corresponding to r in D′,
we can then build a natural deduction proof for the sequent Γ,¬Δ′ ⊢B and using
the Proposition 1.7 again, we obtain a proof of the sequent Γ,¬B,¬Δ′ ⊢⊥.
□
The following property of system D′ is analogous to Proposition 1.6.
Proposition 1.13 (Weakening) If the sequent Γ ⊢Δ is provable in the system D′
then the sequents Γ,A ⊢Δ and Γ ⊢A,Δ are also provable.
Proof By induction over the structure of the proof of Γ ⊢Δ.
□
When a notion of truth is deﬁned, as we have done in this chapter, one cannot
avoid wondering whether the tools used in the deﬁnition are “legitimate”. On one
hand, it is not possible to start from scratch and assume that we know nothing. If
we do not have a language, a basic set of concepts, and an idea of truth, how could
we give a deﬁnition? On the other hand, if we already have a working notion of
mathematical truth, the deﬁnition is trivial: the proposition “Every vector space has
a basis” is true if every vector space has a basis.
In this chapter, we have given a deﬁnition that can be seen as a middle ground be-
tween the two extreme approaches mentioned above: the proposition “Every vector
space has a basis” is true if there is a proof π of this proposition.

34
1
Predicate Logic
To present this deﬁnition, we have relied on certain mathematical notions, such
as the notion of a natural number, ﬁnite set, or tree. However, a proof is built out of
a ﬁnite number of symbols and the fact that a sequence of symbols is, or is not, a
proof of a proposition can be easily veriﬁed: it is sufﬁcient to check that each step
in the proof consists of the application of a natural deduction rule. The proposition
“The sequence of symbols π is a proof of the proposition ‘Every vector space has a
basis”’ uses only ﬁnite objects and veriﬁable relations between these objects. This
kind of proposition is said to be combinatorial. The notion of truth that is needed
in order to understand the deﬁnitions given in this chapter is simply the elementary
notion of truth of combinatorial propositions.

Chapter 2
Models
After deﬁning the concept of proof in the previous chapter, we will now study in
this chapter some properties of proofs. In particular, we will introduce tools that
will allow us to prove independence results of the form: the proposition A is not
provable in the theory T .
To deﬁne the notion of proof we had to restrict ourselves to combinatorial propo-
sitions, but to study properties of proofs we will not need to impose any restriction.
Any mathematical tool can be used to show independence results.
2.1 The Notion of a Model
Deﬁnition 2.1 (Model) Let L = (S,F,P) be a language. A model of this language
is a structure M = ((Ms)s∈S,B,B+,( ˆf )f ∈F,( ˆP )P∈P, ˆ⊤, ˆ⊥, ˆ¬, ˆ∧, ˆ∨, ˆ⇒, ˆ∀, ˆ∃)
consisting of
– a non-empty set Ms for each sort s in S,
– a non-empty set B, and a subset B+ of B,
– a function ˆf from Ms1 × ··· × Msn to Ms′ for each function symbol f ∈F of
arity (s1,...,sn,s′),
– a function ˆP from Ms1 × ··· × Msn to B for each predicate symbol P ∈P of
arity (s1,...,sn),
– two distinguished elements ˆ⊤and ˆ⊥of B, and
– a function ˆ¬ from B to B, three functions ˆ∧, ˆ∨and ˆ⇒from B × B to B and
two functions ˆ∀and ˆ∃from ℘+(B) to B where ℘+(B) is the set of all non-empty
subsets of B.
Let L = (S,F,P) be a language and M a model of this language. We
will deﬁne a function J K associating to each term t of sort s an element JtK
of Ms, and to each proposition A an element JAK of B. In addition, this function
will be a morphism, that is, Jf (t1,...,tn)K = ˆf (Jt1K,...,JtnK), JP(t1,...,tn)K =
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_2, © Springer-Verlag London Limited 2011
35

36
2
Models
ˆP(Jt1K,...,JtnK), JA ∧BK = ˆ∧(JAK,JBK), ... It is well known that a morphism be-
tween vector spaces is fully deﬁned by the image of a basis. Similarly, a morphism
between a language and a model is fully deﬁned by the image of the variables.
Therefore, we have the following deﬁnition.
Deﬁnition 2.2 (Valuation) Let L = (S,F,P) be a language, M a model of this
language and (Vs)s∈S a family of sets of variables. A valuation is a function, with
a ﬁnite domain, that maps the variables x1,...,xn of sorts s1,...,sn to elements
a1,...,an of Ms1,...,Msn.
The valuation that associates the element a1 to the variable x1,...,an to the
variable xn will be written x1 = a1,...,xn = an. Let φ be a valuation, x a variable
and a an element of M, we denote by (φ,x = a) the valuation that coincides with
φ everywhere except on x where it has the value a.
A valuation can be extended into a morphism J Kφ between terms and propo-
sitions of the language L with free variables in the domain of φ, and the
model M. The extension is deﬁned as follows: JxKφ is φ(x), Jf (t1,...,tn)Kφ is
ˆf (Jt1Kφ,...,JtnKφ), .... The deﬁnition is more complicated for bound variables
and quantiﬁers. Indeed, the free variables of the proposition A are the free variables
of ∀x A and possibly x. To deﬁne J∀x AKφ we must ﬁrst consider all the values
JAKφ,x=a obtained by associating x to an arbitrary element a of Ms; we obtain in
this way a non-empty subset of B. We then apply the function ˆ∀(which is a function
from the set of all non-empty subsets of B to B) to this set.
Deﬁnition 2.3 (Denotation) Let L = (S,F,P) be a language, M a model of this
language, (Vs)s∈S a family of sets of variables, φ a valuation and t a term with free
variables in the domain of φ. The denotation of the term t in the model M under
the valuation φ is the element JtKφ of Ms deﬁned by induction over the structure of
t as follows.
– JxKφ = φ(x),
– Jf (t1,...,tn)Kφ = ˆf (Jt1Kφ,...,JtnKφ).
Let A be a proposition with free variables in the domain of φ. The denotation of
the proposition A in the model M under the valuation φ is an element JAKφ of B
deﬁned by induction over the structure of A as follows.
– JP(t1,...,tn)Kφ = ˆP(Jt1Kφ,...,JtnKφ),
– J⊤Kφ = ˆ⊤,
– J⊥Kφ = ˆ⊥,
– J¬AKφ = ˆ¬(JAKφ),
– JA ∧BKφ = ˆ∧(JAKφ,JBKφ),
– JA ∨BKφ = ˆ∨(JAKφ,JBKφ),
– JA ⇒BKφ = ˆ⇒(JAKφ,JBKφ),
– J∀x AKφ = ˆ∀({JAKφ,x=a | a ∈Ms}),
– J∃x AKφ = ˆ∃({JAKφ,x=a | a ∈Ms}).

2.1
The Notion of a Model
37
Proposition 2.1 (Substitution)
J(u/x)tKφ = JtKφ,x=JuKφ
J(u/x)AKφ = JAKφ,x=JuKφ
Proof By induction over the structure of t and the structure of A.
□
Deﬁnition 2.4 (Validity) Let L = (S,F,P) be a language, M a model of this lan-
guage, and (Vs)s∈S a family of sets of variables. A closed proposition is valid in the
model M if JAK∅is in the set B+. In this case we will also say that M is a model
of A.
A proposition A with free variables x1,...,xn is valid in the model M if the
closed proposition ∀x1 ...∀xn A is valid, that is, if for every valuation φ whose
domain includes the variables x1,...,xn, JAKφ belongs to the set B+.
A sequent A1,...,An ⊢B1,...,Bp is valid in the model M if the proposition
(A1 ∧··· ∧An) ⇒(B1 ∨··· ∨Bp) is valid.
A theory T is valid in a model if all of its axioms are valid.
Deﬁnition 2.5 (Two-valued model) Let L = (S,F,P) be a language. A two-valued
model of L is a model such that B = {0,1}, B+ = {1}, ˆ⊤= 1, ˆ⊥= 0 and ˆ¬, ˆ∧, ˆ∨,
ˆ⇒ˆ∀and ˆ∃are the functions
ˆ¬
0
1
1
0
ˆ∧
0
1
0
0
0
1
0
1
ˆ∨
0
1
0
0
1
1
1
1
ˆ⇒
0
1
0
1
1
1
0
1
ˆ∀
{0}
{0,1}
{1}
0
0
1
ˆ∃
{0}
{0,1}
{1}
0
1
1
All the models that we will consider in the rest of the book will be two-valued.
Exercise 2.1 Consider a language with one term sort, consisting of a binary func-
tion symbol + and a binary predicate =. Let M1 be the model consisting of the
set N, addition on N and the characteristic function of equality in N, that is, the
function ˆ= from N2 to {0,1} such that ˆ=(n,p) = 1 if n = p and ˆ=(n,p) = 0 other-
wise. Is the proposition ∀x∀y∃z (x + z = y) valid in this model?
Same question for the model M2 consisting of the set Z, addition and the char-
acteristic function of equality in Z.
Is the proposition ∀x∀y (x + y = y + x) valid in M1? And in M2? Give an
example of a model in which this proposition is not valid.

38
2
Models
2.2 The Soundness Theorem
One of the motivations for the study of models is that validity in a model is an invari-
ant of provability: provable sequents are valid in all models. Thus, if a proposition
is provable in a theory, then it is valid in all the models of the theory. This suggests
a method to show that a proposition is not provable in a given theory: it is sufﬁcient
to show that there is a model of the theory in which the proposition is not valid. The
second formulation of the soundness theorem given below states this principle.
Proposition 2.2 If a sequent A1,...,An ⊢B1,...,Bp is provable in natural de-
duction, then it is valid in all models.
Proof By induction over the structure of proofs.
□
The soundness theorem is a consequence of this proposition, and can be formu-
lated in three different (equivalent) ways.
Theorem 2.1 (Soundness) Let T be a theory and A a proposition.
1. If A is provable in T , then A is valid in all the models of T .
2. If there exists a model of T that is not a model of A, then A is not provable in T .
3. If T has a model, then T is consistent.
Proof Let M be a model of the theory T and let A be a proposition that is prov-
able in T . There exists a ﬁnite subset H1,...,Hn of T such that the sequent
H1,...,Hn ⊢A is provable. By Proposition 2.2, this sequent is valid in M, that
is, the proposition (H1 ∧··· ∧Hn) ⇒A is valid in this model. The propositions
H1,...,Hn are valid in M, therefore, also A is valid in M. This proves the ﬁrst
claim. The second claim is a trivial consequence of the ﬁrst. The third is a conse-
quence of the second taking A = ⊥.
□
Exercise 2.2 Consider the theory consisting of the axiom P(c) ∨Q(c). Show that
the proposition P(c) is not provable in this theory. Show that the proposition ¬P(c)
is not provable either. What can be said of proposition Q(c)?
We can use the soundness theorem to prove that the axiom of inﬁnity is not
provable from the other axioms in ZF.
Deﬁnition 2.6 (The set of hereditarily ﬁnite sets) Let Vn be a sequence of sets
deﬁned by induction: V0 = ∅and Vi+1 = ℘(Vi). Let Vω = 
i Vi.
Proposition 2.3 Let M = (Mι,Mσ, ˆϵ2, ˆ=, ˆ∈) be the model where Mι = Vω,
Mσ = ℘(Mι × Mι), ˆϵ2 is the function from Mι × Mι × Mσ to {0,1} such that
ˆϵ2(a,b,c) = 1 if (a,b) is in c and ˆϵ2(a,b,c) = 0 otherwise, ˆ= is the function from
Mι × Mι to {0,1} such that ˆ=(a,b) = 1 if a = b and ˆ=(a,b) = 0 otherwise, ˆ∈the

2.3
The Completeness Theorem
39
function from Mι × Mι to {0,1} such that ˆ∈(a,b) = 1 if a is in b and ˆ∈(a,b) = 0
otherwise.
Then M is a model of each of the axioms of ZF except the axiom of inﬁnity.
Proof We prove the case corresponding to the axiom of union. First, note that the
union of a family of subsets of Vj is also a subset of Vj, and the union of a family
of elements of Vj+1 is an element of Vj+1. We will show that, if c is an element of
Vω, the union 
b∈c b of the elements of c is also in Vω. Since c ∈Vω, by deﬁnition
of Vω there exists a natural number i different from zero such that c ∈Vi. If i = 1,
c = ∅and the union of the elements of c is also the empty set, therefore it is an
element of Vω. Otherwise, there exists some natural number j such that i = j + 2.
Since c ∈Vj+2, c ⊆Vj+1 and the elements of c are in Vj+1. Therefore, the union
of the elements of c is also in Vj+1, hence in Vω. Thus,
J∀w (w ∈z ⇔(∃v (w ∈v ∧v ∈x)))Kx=c,z=
b∈c b = 1
and therefore
J∀x∃z∀w (w ∈z ⇔(∃v (w ∈v ∧v ∈x)))K = 1
We can prove in the same way that the axiom of extensionality, the axiom of the
power set and the axiom of replacement are valid in this model.
The axioms of equality and the comprehension schema are trivially valid in this
model.
Finally, we show by contradiction that the axiom of inﬁnity is not valid in this
model. First, note that we can prove by induction on i that all the elements of Vi are
ﬁnite sets. As a consequence, all the elements of Vω are ﬁnite sets.
Assume the axiom of inﬁnity is valid in Vω, then there is a set a in Vω that
contains the empty set and if it contains the set b it contains also the set b ∪{b}.
Therefore, this set contains all the elements in the sequence deﬁned by induction as
follows: e0 = ∅,e1 = {e0},e2 = {e0,e1},e3 = {e0,e1,e2},...,ei+1 = ei ∪{ei}, ....
Since these elements are all different, the set a is inﬁnite (contradiction).
□
Proposition 2.4 The axiom of inﬁnity cannot be proved from the other axioms in ZF.
Proof All the axioms in ZF, except the axiom of inﬁnity, are valid in the model M
deﬁned in Proposition 2.3.
□
2.3 The Completeness Theorem
The soundness theorem tells us that if a proposition A is provable in a theory T then
it is valid in all the models of the theory. The completeness theorem, ﬁrst proved in
1930 by K. Gödel (although it should not be confused with Gödel’s famous theo-
rem), is the converse of the soundness theorem.

40
2
Models
2.3.1 Three Formulations of the Completeness Theorem
Similarly to the soundness theorem, the completeness theorem can be formulated in
three different (but equivalent) ways.
Theorem 2.2 (Completeness) Let T be a theory and A a proposition.
1. If A is valid in all the models of T then A is provable in T .
2. If A is not provable in T , then there exists a model of T which is not a model
of A.
3. If T is consistent then T has a model.
The ﬁrst two formulations are trivially equivalent. The third one is a consequence
of the second, taking A = ⊥. We will show that (2) is a consequence of (3). Consider
a theory T and a proposition A not provable in this theory. By Proposition 1.7, the
proposition ⊥is not provable in the theory T ,¬A. Therefore by (3) the theory
T ,¬A has a model. This model is a model of T but not a model of A.
2.3.2 Proving the Completeness Theorem
We will prove the third formulation of the completeness theorem, restricting our-
selves to the case of a ﬁnite or countable language.
Let L = (S,F,P) be such a language and T a consistent theory in this language.
We will build a model for this theory. The idea is to deﬁne the domain Ms as a set
of closed terms of sort s, the function ˆf as the function that associates to the closed
terms t1,...,tn the term f (t1,...,tn) and ˆP as the function that associates t1,...,tn
to 1 if the proposition P(t1,...,tn) is provable and 0 if it is not provable.
There is a problem though: even if we assume that the theory T is consistent,
this structure is not necessarily a model of the theory. For instance, if the theory T
consists of the axiom P(c) ∨Q(c), neither the proposition P(c) nor the proposition
Q(c) is provable—see Exercise 2.2. Thus, according to the construction above, we
have to deﬁne ˆP(c) = 0 and ˆQ(c) = 0, which means that the proposition P(c) ∨
Q(c) is not valid in this model.
To make sure that this construction works, ﬁrst we need to complete the theory:
if a proposition A is undetermined, that is, neither A nor ¬A is provable, we must
choose to add either the axiom A or the axiom ¬A. In our example, if we add the
axiom P(c) then when we build the model we will have ˆP (c) = 1 and thus the
proposition P(c)∨Q(c) is valid in the model. If we decide to add the axiom ¬P(c)
instead, then the proposition Q(c) becomes provable, and when we build the model
we have ˆQ(c) = 1, thus the proposition P(c) ∨Q(c) is again valid.
However, it is not sufﬁcient to complete the theory. For example, consider the
theory ¬P(c),∃x P(x). In this case, according to the construction described above,
we have to deﬁne M = {c} and ˆP(c) = 0. Therefore the proposition ∃x P(x) is not

2.3
The Completeness Theorem
41
valid in this model. The problem here is that no closed term can be used as a witness
of the fact that there is an object satisfying the property P . To solve this problem,
we need to add a constant d and an axiom P(d) before building the model. This
constant d is called Henkin’s witness for the proposition ∃x P(x).
To prove the completeness theorem we need to show ﬁrst the following property.
Proposition 2.5 Let L = (S,F,P) be a language and T a consistent theory in
this language. There exists a language L′ such that L ⊆L′, and a theory U in the
language L′, such that T ⊆U and the following properties hold.
1. The theory U is consistent.
2. For any closed proposition A in the language L′, either the proposition A or the
proposition ¬A is provable in U.
3. If the proposition ∃x A is provable in U, there exists a constant c such that
(c/x)A is provable in U.
To prove this proposition we proceed as in the proof of the theorem of the incom-
plete basis: we inspect all the propositions, one by one, in order to select some of
the them. When inspecting a proposition A, we check whether A or ¬A is provable
from the axioms in T and the propositions already retained. If A is provable, we
select it. If ¬A is provable, we select it. If neither A nor ¬A is provable, we choose
A to be retained (this is an arbitrary choice). Moreover, if A has the form ∃x B, then
we also retain the proposition (c/x)B where c is a new constant to be added to the
language.
Proof Let H = {cs
i } be a countable set containing an inﬁnite number of constants
cs
0,cs
1,cs
2,... for each sort s. Let L′ be the language (S,F ⊎H,P).
The language L′ and the sets Vs are countable, therefore the set of propositions in
this language is countable. Let A0,A1,A2,... be the elements in this set. We deﬁne
a family of theories Un as follows. We start by deﬁning U0 = T . If An is provable
in the theory Un, we deﬁne B = An; if ¬An is provable in the theory Un, we deﬁne
B = ¬An and if neither of them is provable in the theory Un, then we arbitrarily
deﬁne B = An. If B does not have the form ∃x C, then we deﬁne Un+1 = Un ∪{B};
if B has the form ∃x C, we deﬁne Un+1 = Un ∪{B,(cs
i /x)C}, where s is the sort of
x and i is the least natural number such that the constant cs
i is neither in Un nor in B.
Such a constant exists because each Ui contains only a ﬁnite number of constants
from H. Finally, we deﬁne U = 
i Ui.
We can show by induction on i that all the theories Ui are consistent. As a con-
sequence the theory U is also consistent. Indeed, if we assume that a proof for ⊥
exists in U we obtain a contradiction: If ⊥is provable, then there is a ﬁnite subset
B1,...,Bn of U such that the sequent B1,...,Bn ⊢⊥is provable. Each proposition
Bj belongs to one of the sets Uij and they all belong to Uk where k is the greatest of
the ij. This means that the theory Uk is contradictory (a contradiction).
Let A be an arbitrary closed proposition. There exists an index i such that Ai = A
and either A or ¬A is an element of Ui+1. Hence, the theory U contains the axiom
A or the axiom ¬A and one of these propositions is provable.

42
2
Models
Finally, if the proposition ∃x A is provable in U, then there exists an index i such
that Ai = ∃x A. Since the theory Ui is consistent and the proposition Ai is provable,
the proposition ¬Ai is not provable. Therefore, Ui+1 = Ui ∪{∃x A,(c/x)A} for
some constant c. This means that the theory U contains the axiom (c/x)A and this
proposition is provable.
□
Proposition 2.6 Let U be a theory satisfying the following properties:
1. The theory U is consistent.
2. For any closed proposition A, either A or ¬A is provable in U.
3. If the proposition ∃x A is provable in U, there exists a closed term t such that the
proposition (t/x)A is also provable in U.
Then
– The proposition ¬A is provable in U if and only if the proposition A is not prov-
able in U.
– The proposition A∧B is provable in U if and only if the proposition A is provable
in U and the proposition B is provable in U.
– The proposition A∨B is provable in U if and only if the proposition A is provable
in U or the proposition B is provable in U.
– The proposition A ⇒B is provable in U if and only if the proposition A is prov-
able in U, then so is the proposition B.
– The proposition ∀x A is provable in U if and only if for all closed term t, the
proposition (t/x)A is provable in U.
– The proposition ∃x A is provable in U if and only if there exists a closed term t
such that the proposition (t/x)A is provable in U.
Proof
– If the proposition A is provable in U then the proposition ¬A is not, because
the theory U is consistent. Conversely, the second condition implies that if the
proposition ¬A is not provable in U, then the proposition A is provable in U.
– If the propositions A and B are provable in U then the proposition A ∧B is also
provable, using the ∧-intro rule. Conversely, if the proposition A ∧B is provable
in U, then the propositions A and B are also provable, using the ∧-elim rule.
– If the proposition A or the proposition B is provable in U then so is the proposi-
tion A∨B, using the ∨-intro rule. Conversely, if the proposition A∨B is provable
in U, then, the second condition implies that the proposition A or the proposition
¬A is provable in U. In the ﬁrst case, the proposition A is provable in U, and in
the second, since the proposition A ∨B and ¬A are provable, the proposition B
is also provable in U using the rules axiom, ¬-elim, ⊥-elim and ∨-elim.
– Assume that if the proposition A is provable in U then the proposition B is prov-
able in U. The second condition implies that either the proposition A or the propo-
sition ¬A is provable in U. In the ﬁrst case, the proposition B is provable in U
and therefore the proposition A ⇒B is provable using the ⇒-intro rule. In the
second case, the proposition ¬A is provable and therefore the proposition A ⇒B

2.3
The Completeness Theorem
43
is provable using the rules ⇒-intro, ⊥-elim and ¬-elim. Conversely, if A ⇒B
is provable in U, then, if A is provable in U then B is provable in U using the
⇒-elim rule.
– Assume that for every closed term t the proposition (t/x)A is provable in U. If the
proposition ∃x ¬A is provable in U, then, according to the third condition, there
exists a closed term t such that ¬(t/x)A is provable. But then the theory U would
be contradictory, against our assumptions. Therefore the proposition ∃x ¬A is
not provable in U and ¬∃x ¬A is. The proposition ∀x A is thus provable, by
Proposition 1.8. Conversely, if the proposition ∀x A is provable in the theory U,
all the propositions (t/x)A are provable using the ∀-elim rule.
– If there exists a closed term t such that the proposition (t/x)A is provable in U
then the proposition ∃x A is provable using the ∃-intro rule. Conversely, if the
proposition ∃x A is provable in U then, according to the third condition, there
exists a closed term t such that (t/x)A is provable in U.
□
We are ﬁnally in a position to prove the completeness theorem.
Proof Let T be a consistent theory and U the theory built in Proposition 2.5. We
deﬁne the domain Ms to be the set of closed terms of sort s in the language L′,
the function ˆf to be the function associating to the closed terms t1,...,tn the term
f (t1,...,tn) and the function ˆP to be the function associating to t1,...,tn the num-
ber 1 if the proposition P(t1,...,tn) is provable in U and 0 otherwise.
Let A be a closed proposition. We show by induction over the structure of the
proposition A that A is provable in U if and only if A is valid in this model. If A
is an atomic proposition, the equivalence follows directly from the deﬁnition of the
functions ˆP . If A is a proposition of the form B ∧C, then the proposition A is prov-
able in U if and only if the propositions B and C are provable—Proposition 2.6—if
and only if the propositions B and C are valid in M—inductive hypothesis—if and
only if the proposition A is valid in M. The other cases are similar.
□
In this proof we have only considered ﬁnite or countable languages. The com-
pleteness theorem applies also to non-countable languages and the proof follows
the same lines. Only the proof of Proposition 2.5 differs. First, we need to add a
set of constants for each sort, which must have the same cardinal as the language.
Second, instead of enumerating the propositions, we need to well-order them using
the axiom of choice. Finally, the family of sets (Ui)i will no longer be indexed by
the natural numbers, we will need a greater ordinal.
2.3.3 Models of Equality—Normal Models
Deﬁnition 2.7 (Normal model) Let L be a language containing predicates =s of
sort (s,s) for some sorts s, and T be a theory containing at least the axioms of

44
2
Models
equality for these sorts. A normal model of the theory T is a model in which the
functions ˆ=s over Ms are deﬁned by ˆ=s(x,y) = 1 if x = y and ˆ=s(x,y) = 0 oth-
erwise.
Proposition 2.7 (Completeness of normal models) Let T be a theory containing at
least the axioms of equality. If T is consistent then it has a normal model.
Proof Since the theory is consistent, it has a model M. For every sort s for which
there is an equality predicate in the language, let Rs be the relation containing the
pairs of elements a and b such that ˆ=(a,b) = 1. This is an equivalence relation.
We deﬁne M′
s = Ms/Rs. Since the model M is a model of the equality axioms,
the functions ˆf and ˆP can be deﬁned on the quotient. In this way we can deﬁne a
normal model M′ that satisﬁes the same propositions as M. It is therefore a model
of T .
□
2.3.4 Proofs of Relative Consistency
The completeness theorem can be used to build proofs of relative consistency. The
model Vω deﬁned in Sect. 2.2 is a model of the theory ZFf , that is, the theory con-
sisting of the axioms of ZF except that the axiom of inﬁnity is replaced by its nega-
tion. It is possible to formalise the construction of this model in ZF. In other words,
the proposition “There exists a model of ZFf ” is provable in ZF. The soundness the-
orem allows us to deduce then that the proposition “The theory ZFf is consistent”
is provable in ZF.
This kind of result is not standard, it is in fact an exception. If instead of the
elementary theory ZFf we consider a more interesting theory, such as ZFC or
ZF¬C, which are obtained by adding to the axioms of ZF the axiom of choice
or its negation, respectively, then as a consequence of Gödel’s second incomplete-
ness theorem—which is out of the scope of this book, but shows that under general
conditions the consistency of a theory cannot be proved in the same theory—we
know that it is impossible to prove in ZF the consistency of ZF, and a fortiori that
of ZFC or ZF¬C.
Nevertheless, it is possible to prove in ZF relative consistency theorems. For
instance, K. Gödel proved that if the theory ZF is consistent, then so is the theory
ZFC, and A. Fraenkel and A. Mostowski proved that if the theory ZF is consistent
then so is the theory ZF¬C.
In other words, to prove the consistency of the theories ZFC and ZF¬C, we
add the axiom “The theory ZF is consistent” to the usual mathematical theories
formalised in ZF. Then, these proofs will use the completeness theorem to deduce
from the consistency of ZF the existence of a model of ZF and ﬁnally use this model
to build a model of ZFC or ZF¬C.
Exercise 2.3 In this exercise, inspired by the proof of relative consistency of ZF¬C
proposed by Fraenkel and Mostowski, we will show that if ZF is consistent then

2.3
The Completeness Theorem
45
ZF+ is consistent, where ZF+ is the theory obtained by adding to ZF the axiom
∃x (x ∈x). In other words, if ZF is consistent then the proposition ¬∃x (x ∈x) is
not provable.
1. Show that the following propositions are equivalent.
(a) If ZF is consistent then ZF+ is consistent.
(b) If ZF has a model then ZF+ has a model.
(c) If ZF has a normal model then ZF+ has a normal model.
Our aim is to prove the proposition (c). Let M = (M,C, ˆϵ2, ˆ∈) be a normal
model of ZF.
2. Show that there exists an element 0 in M such that none of the elements a of
M satisﬁes a ˆ∈0. Show that there exists an element 1 in M such that for every
element a in M, we have a ˆ∈1 if and only if a = 0.
Let f be the bijection from M to M deﬁned by f (0) = 1, f (1) = 0 and
f (a) = a if a is different from 0 and 1. Let M′ be the model (M,C, ˆϵ2, ˆ∈′)
where ˆ∈′ is the relation such that a ˆ∈′ b if and only if a ˆ∈f (b). The goal is to
prove that M′ is a normal model of ZF+.
3. Show that there exists a proposition Zero such that JZeroKM
x=a = 1 if and only if
a = 0. Show that there exists a proposition One such that JOneKM
x=a = 1 if and
only if a = 1. Show that there exists a proposition F such that JFKM
x=a,y=b = 1
if and only if b = f (a). Show that there exists a proposition E such that
JEKM
x=a,y=b = 1 if and only if a ˆ∈′ b. Show that M′ is a model of the binary
comprehension schema.
4. Show that the axiom of extensionality is valid in M′.
5. Let a be an element of M. Deﬁne a1 = f (a). Show that there exists an element
a2 of M such that x ˆ∈a2 if and only if there exists some y such that x = f (y)
and y ˆ∈a1. Show that there exists an element a3 of M such that x ˆ∈a3 if and
only if there exists some z such that x ˆ∈z and z ˆ∈a2. Let a4 = f −1(a3). Show
that x ˆ∈′ a4 if and only if there exists some y such that x ˆ∈′ y and y ˆ∈′ a. Show
that the axiom of union is valid in M′.
6. Let a be an element of M. Deﬁne a1 = f (a). Show that there exists an element
a2 of M such that x ˆ∈a2 if and only if for every z, z ˆ∈x implies z ˆ∈a1. Show
that there exists an element a3 of M such that x ˆ∈a3 if and only if f (x) ˆ∈a2.
Let a4 = f −1(a3). Show that x ˆ∈′ a4 if and only if for every z, z ˆ∈′ x implies
z ˆ∈′ a. Show that the axiom of the power set is valid in M′.
7. Let a be an element of M and r an element of C that is a functional binary class
(more precisely, if a,b ˆϵ2 r and a,b′ ˆϵ2 r then b = b′). Deﬁne a1 = f (a). Show
that there exists an element a2 of M such that x ˆ∈a2 if and only if there exists
some y such that y ˆ∈a1 and y,x ˆϵ2 r. Let a3 = f −1(a2). Show that x ˆ∈′ a3
if and only if there exists some y such that y ˆ∈′ a and y,x ˆϵ2 r. Show that the
axiom of replacement is valid in M′.
8. In this question we will assume that the following result is true (it was proved in
Exercise 1.18): If a is an element of M and r an element of C that is a functional
binary class, then there exists an element E of M such that a ˆ∈E and if x ˆ∈E
and x,x′ ˆϵ2 r then x′ ˆ∈E.
Show that there is no object a such that a ˆ∈′ 1.

46
2
Models
Let a be an element of M. Let S(a) be the element of M such that x ˆ∈S(a) if
and only if x ˆ∈a or x = a and let S′(a) be the element of M such that x ˆ∈′ S′(a)
if and only if x ˆ∈′ a or x = a. Show that if a is neither 0 nor 1, then S′(a) = S(a).
What is the object S′(0)? And the object S′(1)? Show that the binary class r such
that a,b ˆϵ2 r if b = S′(a) is in C and is functional.
Show that there exists a set I ′ that contains 1 and such that if a ˆ∈I′ then
S′(a) ˆ∈I ′.
Show that the axiom of inﬁnity is valid in M′.
9. Show that 0 ˆ∈′ 0. Show that the proposition ∃x (x ∈x) is valid in M′.
2.3.5 Conservativity
Deﬁnition 2.8 (Extension) Let L and L′ be two languages such that L ⊆L′. Let T
be a theory in the language L and T ′ a theory in L′. The theory T ′ is an extension
of T if every proposition that is provable in T is also provable in T ′.
Deﬁnition 2.9 (Conservative extension) Let L and L′ be two languages such that
L ⊆L′. Let T be a theory in the language L and T ′ a theory in L′. Assume that
T ′ is an extension of T . The theory T ′ is a conservative extension of T if every
proposition in L provable in T ′ is also provable in T .
For example, if the language L contains a constant c and a predicate symbol P ,
and if the theory T consists of the axiom P(c), then, by adding a constant d and the
axiom P(d) we obtain a conservative extension: although the proposition P(d) is
provable in T ′ but not in T , we will see that all the propositions of the language L—
note that P(d) is not one of them—that are provable in T ′ are also provable in T .
Note that if the language L contains a constant c and a predicate symbol P , and
if the theory T is empty, then by adding a constant d and the axiom P(d) we obtain
an extension which is not conservative. Indeed , the proposition ∃x P(x), which is
well formed in T , is provable in T ′ but not in T .
Although in a small example such as the one above it is possible to show that
an extension is conservative by showing that proofs in T ′ can be translated into
proofs in T , in the general case the situation is more complicated. The completeness
theorem is a useful tool to prove that a theory is a conservative extension of another
one.
Deﬁnition 2.10 (Extension of a model) Let L and L′ be two languages such that
L ⊆L′. Let M be a model of L and M′ a model of L′. The model M′ is an
extension of M if for every sort s of L we have Ms = M′
s and for every function
or predicate symbol f of L we have ˆf M = ˆf M′.
Proposition 2.8 Let L be a language and T a theory in this language. Let L′ be
a language such that L ⊆L′ and let T ′ be a theory in L′ such that T ⊆T ′. If for

2.3
The Completeness Theorem
47
every model M of T there exists an extension M′ of M that is a model of T ′, then
T ′ is a conservative extension of T .
Proof Let A be a proposition in the language L. Assume that A is provable in T ′.
Let M be an arbitrary model of T . There exists a model M′ of T ′ that is an exten-
sion of M. Since M′ is a model of T ′, the proposition A is valid in M′, therefore
its denotation in M′ is 1. Since M′ is an extension of M the denotation of A in
M is also 1. The proposition A is therefore valid in M. Since the proposition A is
valid in all the models of T , it is provable in T .
□
For example, if L contains c and P and the theory T consists of the axiom P(c),
then by adding a constant d and the axiom P(d) we obtain a conservative extension.
Indeed, any model M of T can be extended into a model of T ′ by deﬁning ˆd = ˆc.
Exercise 2.4 In Exercise 1.6, we showed that the propositions A and theories T
of a many-sorted language can be relativised to propositions |A| and theories |T |
in a single-sorted language. Then, if the closed proposition A is provable in T , the
proposition |A| is provable in |T |.
Show that the converse also holds: if |A| is provable in |T | then A is provable
in T .
When formulating arithmetic or set theory, we can avoid introducing classes, and
thus the sorts κ and σ and the symbols ϵ and ϵ2, if we replace each axiom that
uses classes by an axiom schema, that is, an inﬁnite set of axioms. For example, the
axiom of induction can be replaced by the induction schema, deﬁned as the set of
axioms
∀x1 ...∀xn ((0/y)A ⇒∀m ((m/y)A ⇒(S(m)/y)A) ⇒∀n (n/y)A)
for each proposition A, where x1,...,xn are the free variables of A that are different
from y. For example, for the proposition y + 0 = y we have the axiom
0 + 0 = 0 ⇒∀m (m + 0 = m ⇒S(m) + 0 = S(m)) ⇒∀n (n + 0 = n)
We obtain in this way the theory deﬁned below.
Deﬁnition 2.11 The language of arithmetic contains a constant 0, a unary function
symbol S, two binary function symbols + and × and a binary predicate symbol =.
In addition to the axioms of equality, we have the axioms
∀x∀y (S(x) = S(y) ⇒x = y)
∀x ¬(0 = S(x))
∀x1 ...∀xn ((0/y)A ⇒∀m ((m/y)A ⇒(S(m)/y)A) ⇒∀n (n/y)A)
∀y (0 + y = y)

48
2
Models
∀x∀y (S(x) + y = S(x + y))
∀y (0 × y = 0)
∀x∀y (S(x) × y = (x × y) + y)
We can now show that the single-sorted theory of classes is a conservative exten-
sion of this theory. More generally, for any theory that contains an axiom schema,
there is an alternative deﬁnition in the theory of classes where the schema is simply
replaced by one axiom. We will show this result only for the case of arithmetic, to
avoid having to formalise the notion of an axiom schema in the general case.
Proposition 2.9 The formulation of the theory of arithmetic given in Deﬁnition 1.33
is a conservative extension of the one given in Deﬁnition 2.11.
Proof Each instance of the induction schema can be proved in the theory given
in Deﬁnition 1.33. Therefore, this theory is an extension of the one presented in
Deﬁnition 2.11. To show that the extension is conservative, we show that every
model of the theory given in Deﬁnition 2.11 can be extended to a model of the
theory in Deﬁnition 1.33.
Let (M, ˆ0, ˆS, ˆ+, ˆ×, ˆ=) be a model of the theory given in Deﬁnition 2.11. A sub-
set E of M is deﬁnable in arithmetic if there exists a proposition A in the language
of the theory given in Deﬁnition 2.11, with free variables in x1,...,xn,y, and ele-
ments a1,...,an in M, such that b is in E if and only if
JAKx1=a1,...,xn=an,y=b = 1
Let ℘(M) be the set of all the deﬁnable subsets of M. We extend the model M, by
deﬁning Mκ = ℘(M) and ˆϵ(b,E) = 1 if b is an element of E and 0 otherwise.
The resulting structure is a model of the comprehencion schema. We now prove
that it is a model of the axiom of induction.
∀c (0 ϵ c ⇒∀m (m ϵ c ⇒S(m) ϵ c) ⇒∀n n ϵ c)
For this, we consider an arbitrary element E of Mκ and show that
J(0 ϵ c ⇒∀m (m ϵ c ⇒S(m) ϵ c) ⇒∀n n ϵ c)Kc=E = 1
The set E is deﬁnable; let A and a1,...,an be a proposition and elements of M,
respectively, deﬁning E. Then M is a model of the instance of the induction schema
corresponding to A, and therefore
J(0/y)A ⇒∀m ((m/y)A ⇒(S(m)/y)A) ⇒∀n (n/y)AKx1=a1,...,xn=an = 1
Since the denotations of the propositions t ϵ c and (t/y)A are exactly the same in a
valuation where φc = E, φx1 = a1,...,φxn = an, we deduce that
J(0 ϵ c ⇒∀m (m ϵ c ⇒S(m) ϵ c) ⇒∀n n ϵ c)Kc=E = 1
□

2.4
Other Applications of the Notion of Model
49
Exercise 2.5 Give a formulation of the theory ZF with an axiom schema. Show that
the theory deﬁned using binary classes is a conservative extension of this theory.
Using the axiom of the power set given in Deﬁnition 1.36
∀x∃z∀w (w ∈z ⇔(∀v (v ∈w ⇒v ∈x)))
we can show that if A is a set, then there exists a set containing all the subsets of A.
However, we do not have a notation (such as ℘(A)) for this set.
We could introduce a function symbol ℘and an axiom
∀x∀w (w ∈℘(x) ⇔(∀v (v ∈w ⇒v ∈x)))
and show that the theory obtained is a conservative extension of the theory of sets
previously deﬁned.
Theorem 2.3 (Skolem) Let T be a theory and A a proposition of the form
∀x1 ...∀xn∃y B, provable in T . Then the theory obtained by adding a function
symbol f and the axiom ∀x1 ...∀xn (f (x1,...,xn)/y)B is a conservative exten-
sion of T .
Proof Let M be a model of T . We show that it can be extended into a model of this
axiom. Let a1,...,an be arbitrary elements of M. There exists an element b of M
such that
JBKx1=a1,...,xn=an,y=b = 1
Therefore, we can deﬁne
ˆf to be the function that associates to each n-tuple
a1,...,an such an element b.
□
2.4 Other Applications of the Notion of Model
In this chapter, we have shown that the concept of model can be used to prove several
properties of proofs, for example properties of independence, consistency, relative
consistency, conservativity. However, in mathematics and in computer science, the
concept of model is not just a tool to study proofs: it has multiple applications. We
ﬁnish the chapter by giving some examples where models and languages are used
for various different purposes.
2.4.1 Algebraic Structures
It is not particularly interesting to write proofs in the theory consisting of the equal-
ity axioms and the axioms
∀x∀y∀z ((x + y) + z = x + (y + z))

50
2
Models
∀x (x + 0 = x ∧0 + x = x)
∀x∃y (x + y = 0 ∧y + x = 0)
However, normal models of this theory are interesting in their own right: they are the
groups. We can derive results in group theory by proving properties of the models
of this theory. Let us give an example.
Theorem 2.4 (Löwenheim-Skolem) Let L = (S,F,P) be a ﬁnite or countable lan-
guage, T a theory in this language and κ an arbitrary, inﬁnite set. If the theory T
has a ﬁnite model, it has a model of the same cardinality as κ.
Proof This theorem is a simple consequence of the completeness theorem for an
arbitrary cardinality.
Consider the language (S,F ⊎κ,P ⊎{=}) obtained by adding to our initial lan-
guage a symbol = and a constant for each element of κ, and the theory T ′ obtained
by adding to T the axioms of equality and the axioms ¬a = b for each pair (a,b)
of distinct elements in κ. Let M be an inﬁnite model of the theory T .
It is not difﬁcult to show that any ﬁnite subset of T ′ is consistent: a ﬁnite sub-
set of T ′ will only use a ﬁnite number of constants from κ; we can extend the
model M, associating to those constants different elements of M (this is always
possible because M is inﬁnite), and to the other constants in κ an arbitrary element.
We deduce that the theory T ′ is consistent. Indeed, assume it is not consistent,
then there is a ﬁnite subset Γ of T ′, such that the sequent Γ ⊢⊥is provable. This
contradicts our assumption that all ﬁnite subsets of T ′ are consistent.
Let M′ be the normal model of T ′ that we built in the proof of the completeness
theorem. This model has at least as many elements as κ because the elements of κ
are associated to different elements here. We can then show that since κ is inﬁnite,
there are as many closed terms in the language (S,F ⊎κ,P ⊎{=}) as elements in
κ and therefore the model has at most the number of elements of κ. It has therefore
exactly the same cardinality as κ.
□
From this result we can derive the following corollary.
Proposition 2.10 There are groups of every inﬁnite cardinality. Every inﬁnite set
can be endowed with a group structure.
Note that this theorem does not mention the concept of model. It is a well-known
result in group theory, obtained as a corollary of a result in logic.
Another interesting consequence of the theorem of Löwenheim-Skolem is the
existence of non-countable normal models of arithmetic, and more generally, of
any theory that admits N as a model. This result might seem surprising, since at
ﬁrst sight all normal models of arithmetic seem to have the same cardinal as N.
Indeed, consider a normal model M of arithmetic, and the function F from N to M
associating ˆSn(ˆ0) to n.

2.4
Other Applications of the Notion of Model
51
The image I of this function contains ˆ0, is closed under ˆS and M is a model of
the axiom of induction. It seems then that all the elements of M should be in I, and
therefore M should be countable. Where is the mistake?
The mistake stems from our assumption that if M is a model of the axiom of
induction, every set I containing ˆ0 and closed under ˆS must contain all the set M.
This is only true if I is in the set Mκ. But the comprehension schema requires Mκ
to contain all the subsets of M that are deﬁnable by a proposition A, and that is not
the case for the set I. In other words, amongst the subsets of N (and the power set of
N is uncountable), the comprehension schema says that there is a small number—
countable—of sets that are deﬁnable, and the axiom of induction says that if one of
these sets contains 0 and is closed under successor, then it contains all the natural
numbers. There is therefore a signiﬁcant degree of freedom.
Deﬁnition 2.12 (Standard model) A standard model of the theory of classes is a
model such that Mκ = ℘(Mι).
Exercise 2.6 Show that all the standard models of arithmetic have the same cardinal
as N.
In the same way we can show that although the ﬁelds that are totally ordered,
Archimedean and complete are isomorphic to R, there are non standard models of
this theory that are countable.
The notion of standard model is essential in the applications of model theory
to algebra. However, it is not really useful to study proofs, since the theorem of
Löwenheim-Skolem tells us that all the theories that can be deﬁned in a ﬁnite or
countable language have non-standard models.
2.4.2 Deﬁnability
Models can also be used to deﬁne the notion of deﬁnable set, or more generally,
deﬁnable relation.
Deﬁnition 2.13 Let M be a set and R1,...,Rn relations over this set. We will say
that a relation S over M is deﬁnable in the structure (M,R1,...,Rn) if there exists
a proposition A in the language that consists of the symbols P1,...,Pn and with
free variables x1,...,xp, such that the elements a1,...,ap are in the relation S if
and only if
JAKx1=a1,...,xn=an = 1
in the model (M,R1,...,Rn).
If R1 and R2 are two binary relations, their intersection is deﬁnable from R1 and
R2 using the proposition P1(x,y)∧P2(x,y). In general, if two relations of the same

52
2
Models
arity are deﬁnable, so is their intersection. The set of deﬁnable relations is therefore
closed under intersection. It is also closed under union and complement. However,
the set of deﬁnable relations contains more elements than the inductively deﬁned
set containing R1,...,Rn and closed under intersection, union and complement.
Indeed, since in a proposition the same variable can be used several times, and
variables can be permuted, it is possible to deﬁne for instance the set of objects that
relate to themselves, P(x,x), or the inverse of a relation, P(y,x). Moreover, the use
of quantiﬁers opens up a wealth of possibilities, since we can, for instance, deﬁne
the composition of two relations ∃z (P1(x,z) ∧P2(z,y)).
However, not all relations are deﬁnable. We can for instance prove that the
reﬂexive-transitive closure of a relation is not deﬁnable using the relation itself.
In database theory, deﬁnable relations correspond to deﬁnable queries.

Part II
Algorithms


Chapter 3
Computable Functions
In this chapter we will study algorithms that take n natural numbers p1,...,pn as
input and compute a natural number q. Each of these algorithms can be associated
to a function from Nn to N that maps the integers p1,...,pn to q. Functions that can
be associated to an algorithm are said to be computable. The notion of a computable
function, simpler and more abstract than the notion of an algorithm, turns out to be
an important concept when studying the limits of computability. In Chap. 4 we will
introduce a more operational approach to computation, but ﬁrst in this chapter we
will study computable functions.
3.1 Computable Functions
Let Fn be the set of partial functions from Nn to N and F the union of all the sets Fn.
Deﬁnition 3.1 (Computable functions) The set of computable functions is the sub-
set of F inductively deﬁned as the smallest set containing
• the projection functions
x1,...,xn →xi
• the zero functions
x1,...,xn →0
• the successor function
x →x + 1
and closed under
• composition, that is, the operation that associates to the functions h from Nm to
N and g1, ..., gm from Nn to N the function from Nn to N
x1,...,xn →h(g1(x1,...,xn),...,gm(x1,...,xn))
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_3, © Springer-Verlag London Limited 2011
55

56
3
Computable Functions
• recursive deﬁnitions, that is, the operation that associates to g from Nn−1 to N
and h from Nn+1 to N the function f from Nn to N deﬁned by
f (x1,...,xn−1,0) = g(x1,...,xn−1)
f (x1,...,xn−1,y + 1) = h(x1,...,xn−1,y,f (x1,...,xn−1,y))
• and minimisation, that is, the operation that associates to g from Nn+1 to N the
function f from Nn to N such that f (x1,...,xn) is the least natural number y
such that g(x1,...,xn,y) = 0.
We need to deﬁne more precisely the sets of numbers for which these func-
tions are deﬁned. The projections, the zero functions and the successor function
are total. The function x1,...,xn →h(g1(x1,...,xn),...,gm(x1,...,xn)) is de-
ﬁned for p1,...,pn if the functions g1,...,gm are deﬁned for p1,...,pn and the
function h is deﬁned for g1(p1,...,pn),...,gm(p1,...,pn). A function f that
is recursively deﬁned using the functions g and h is deﬁned for p1,...,pn−1,0
if g is deﬁned for p1,...,pn−1, and it is deﬁned for p1,...,pn−1,q + 1 if it
is deﬁned for p1,...,pn−1,q and in addition h is deﬁned for p1,...,pn−1, q,
f (p1,...,pn−1,q). The function f deﬁned as the minimisation of a function g
is deﬁned for p1,...,pn if there exists a natural number q such that g is deﬁned
and does not return 0 for p1,...,pn,r, for any r strictly less than q, and it returns
0 for p1,...,pn,q.
It is because of this last rule that the set of functions deﬁned above includes
partial functions. The ﬁrst three rules deﬁne total functions and the two that follow
preserve totality. However, minimisation transforms the total function x,y →x into
a partial function, which returns the value 0 for 0, and is undeﬁned for any other
natural number. Indeed, if p is a natural number different from 0 then there is no q
such that (x,y →x)(p,q) = 0.
We will see in Sect. 3.4.2 and in Chap. 4 that when a function f is undeﬁned
for a natural number p, its corresponding program is non-terminating. Indeed, if the
function f is deﬁned by minimisation of the function g, then to compute f we have
to compute the values of g at (p,0), (p,1), (p,2), ... until we ﬁnd a zero, if there
is one. If there is no zero, the computation will continue forever.
Proposition 3.1 (The predecessor function) The predecessor function, deﬁned by
f (n + 1) = n and f (0) = 0, is computable.
Proof It is a recursively deﬁned function.
□
Proposition 3.2 (The four arithmetic operations) Addition, multiplication, the
“subtraction” operation deﬁned by n ˙−p = n −p if n ≥p and n ˙−p = 0 oth-
erwise, the quotient and remainder of Euclidean division, are all computable func-
tions.
Proof The functions +, ˙−and × can be deﬁned using recursion. The quotient of a
division can be computed using minimisation, and the remainder can be computed
using quotient, multiplication and subtraction.
□

3.1
Computable Functions
57
Proposition 3.3 (The function χ≤) The characteristic function of the ordering re-
lation χ≤, deﬁned by χ≤(x,y) = 1 if x ≤y and χ≤(x,y) = 0 otherwise, is com-
putable.
Proof χ≤(x,y) = 1 ˙−(x ˙−y).
□
Proposition 3.4 (Test) Let f , g and h be three computable functions, and i
the function deﬁned by i(x1,...,xn) = g(x1,...,xn) if f (x1,...,xn) = 0 and
i(x1,...,xn) = h(x1,...,xn) otherwise. The function i, deﬁned for all the numbers
that are in the domains of deﬁnition of the three functions f , g and h, is computable.
Proof The function that maps the three natural numbers p,q,r to q if p = 0 and to
r otherwise can be deﬁned recursively as follows:
k(0,q,r) = q
k(p + 1,q,r) = r
and the function i can be deﬁned by composition using f , g, h and k.
□
Deﬁnition 3.2 (Decidable and semi-decidable sets) A subset A of N is decidable if
its characteristic function is computable, that is, if there exists a computable function
f such that f (x) = 1 if x ∈A and f (x) = 0 otherwise.
It is semi-decidable if there exists a computable function f such that f (x) = 1 if
x ∈A and f is undeﬁned for x otherwise.
Exercise 3.1 Show that any decidable set is also semi-decidable.
Deﬁnition 3.3 (Primitive recursive functions) The set of primitive recursive func-
tions is inductively deﬁned as the smallest set of functions that contains the projec-
tions, the zero functions and the successor function, and is closed under composition
and recursive deﬁnitions.
Exercise 3.2 Ackermann’s function is deﬁned as follows: A0(x) = 2x and An+1(x)
= An ◦··· ◦An



x times
(1). Alternatively, it can be deﬁned as
A0(x) = 2x
An+1(0) = 1
An+1(x + 1) = An(An+1(x))
1. Show that, for any i and any x, Ai(x) ≥x + 1.
2. Show that, for any i, the function x →Ai(x) is strictly increasing.
3. Show that, for any x, the function i →Ai(x) is increasing.
4. Show that, for any x, A0(x) ≥2x and, if x ≥2, then A0(x) ≥x + 2. Show that,
for any i and any x, Ai(x) ≥2x and, if x ≥2, then Ai(x) ≥x + 2.

58
3
Computable Functions
5. Show that, if x ≥2, then Ai+1(x + 2) ≥Ai(Ai(x + 2)). Show that, if x ≥4,
then Ai+1(x) ≥Ai(Ai(x)).
6. We will say that a function f of arity n is dominated by a unary function g if
for any x1,...,xn, f (x1,...,xn) ≤g(max(x1,...,xn,4)).
Show that the projections, the zero functions and the successor function are
all dominated by the function A0, that is, by the function x →2x.
7. Let g1,...,gm and h be functions dominated by the functions Ai1,...,Aim and
Aj, respectively. Let k be the greatest of the numbers i1,...,im and j. Show
that the composition of h and g1,...,gm is dominated by Ak+1.
8. Let g and h be two functions dominated by Ai and Aj, and let k be
the greatest of i and j. Let f be the function recursively deﬁned using
g and h. Show that f (x1,...,xn−1,y) ≤Ak+1(y + max(x1,...,xn−1,4)).
Show that f (x1,...,xn−1,y) ≤Ak+1(2max(x1,...,xn−1,y,4)). Show that
f (x1,...,xn−1,y) ≤Ak+1(Ak+1(max(x1,...,xn−1,y,4))).
Show that f is dominated by Ak+2.
9. Show that, for any primitive recursive function, there exists a natural number i
such that f is dominated by Ai.
10. Show that the function i →Ai(i) is not primitive recursive.
11. Show that Ackermann’s function is not primitive recursive.
3.2 Computability over Lists and Trees
3.2.1 Computability over Lists
The computable functions introduced in Deﬁnition 3.1 work on natural numbers.
We will now extend this deﬁnition to lists of numbers as follows. First, we associate
to each list l a natural number ⌜l⌝(the list’s index). Then, we say that a function
that maps a list l to the list F(l) is computable if the function that maps l’s index to
F(l)’s index, which is a function over the natural numbers, is computable.
To associate indices (i.e., numbers) to lists we use the following function.
Deﬁnition 3.4 The function ; is deﬁned by
p;q = (p + q)(p + q + 1)/2 + p + 1
Proposition 3.5 The function ; is a bijection from N2 to N∗.
Proof Let n be a natural number different from 0. Let k be the greatest natural
number such that k(k + 1)/2 ≤n −1 and p = n −1 −k(k + 1)/2. Since k is
the greatest such number, we deduce that n −1 < (k + 1)(k + 2)/2 and therefore
p < (k + 1)(k + 2)/2 −k(k + 1)/2 = k + 1, and p ≤k. Deﬁne q = k −p, then
n = k(k + 1)/2 + p + 1 = (p + q)(p + q + 1)/2 + p + 1 = p;q
Thus, the function ; is surjective.

3.2
Computability over Lists and Trees
59
Assume p;q = p′;q′, and let k be the greatest natural number such that k(k +
1)/2 ≤(p;q)−1. Then k(k+1)/2 ≤(p;q)−1 = (p+q)(p+q +1)/2+p < (p+
q)(p+q +1)/2+p+q +1 = (p+q +1)(p+q +2)/2, and therefore k < p+q +1,
that is, k ≤p +q. In addition, (p +q)(p +q +1)/2 ≤(p +q)(p +q +1)/2+p =
(p;q) −1 < (k + 1)(k + 2)/2 and therefore p + q < k + 1, that is, p + q ≤k.
We deduce p + q = k. Similarly, p′ + q′ = k and therefore p′ + q′ = p + q. Since
(p + q)(p + q + 1)/2 + p + 1 = (p′ + q′)(p′ + q′ + 1)/2 + p′ + 1, we deduce that
p = p′ and therefore q = q′. Thus, the function ; is injective.
□
Deﬁnition 3.5 The function hd, head, maps 0 to 0 and each natural number n dif-
ferent from 0 to the unique natural number p such that there exists some q satisfying
n = p;q. The function tl, tail, maps 0 to 0 and each natural number n different from
0 to the unique natural number q such that there exists some p satisfying n = p;q.
Proposition 3.6 The functions ;, hd and tl are computable.
Proof The function ; is deﬁned using arithmetic operations and the other functions
are deﬁned using arithmetic operations, the characteristic function of the ordering
relation, and minimisation. They are therefore computable functions.
□
Proposition 3.7 If n ̸= 0, then hd(n) < n and tl(n) < n.
Proof p;q > p and p;q > q.
□
Deﬁnition 3.6 (Indexing lists of natural numbers) We can associate an index to each
list l of natural numbers as follows:
⌜p1,...,pn⌝= p1;(p2;(...;(pn;0)...))
Proposition 3.8 The function sub that takes two natural numbers p and n as input
and returns the index associated to the list obtained by deleting the n ﬁrst elements
from the list with index p, if this list has at least n elements, or the index of the empty
list otherwise, is computable.
Proof This function is deﬁned by
sub(p,0) = p
sub(p,n + 1) = tl(sub(p,n))
□
Proposition 3.9 The function length that associates to a natural number p the
length of the list with index p is computable.
Proof The length of a list p is the least natural number n such that sub(p,n) = 0. □
Proposition 3.10 The function nth that associates to two natural numbers n and
p the nth element of the list with index p, if this element exists, and the number 0
otherwise, is computable.

60
3
Computable Functions
Proof This function is deﬁned by nth (p,n) = hd(sub(p,n)).
□
The induction schema used in Deﬁnition 3.1 might seem restrictive at ﬁrst sight,
because to deﬁne the value of h for y + 1 we can only use the value of h for y
(instead of all the values of h for z such that z < y + 1). For instance, it is not
obvious that the well-known Fibonacci function, usually deﬁned by well-founded
induction as f (0) = f (1) = 1 and f (n + 2) = f (n) + f (n + 1), is computable.
However, it is not difﬁcult to prove that if a function f is deﬁned by well-founded
induction, then the function F that associates x to ⌜f (0),f (1),...,f (x)⌝can be
deﬁned by standard induction, and therefore F, and also f , are computable.
3.2.2 Computability over Trees
It is also useful to extend the notion of computability to expressions in a language,
or more generally, to trees. In this way we can deﬁne computations over programs,
propositions, and proofs, amongst others.
To extend the notion of computable function, we will start by deﬁning a map-
ping between trees and natural numbers. Each tree will be associated to a natural
number—its index—and we will say that a function F that associates to a tree t
another tree F(t) is computable if the function that associates to t’s index F(t)’s
index (a function over natural numbers) is computable.
Deﬁnition 3.7 (Indexing trees) Let E be a set with an associated injective function
over N, such that each element f of E is associated to its index ⌜f ⌝. Given a
tree t with nodes labelled by elements of E, we deﬁne its index ⌜t⌝by structural
induction, as follows
⌜f (t1,...,tn)⌝= ⌜f ⌝;(⌜t1⌝;(⌜t2⌝;...(⌜tn⌝;0)...))
We have thus a mechanism to index the trees that are labelled by elements of a
ﬁnite set E: it sufﬁces to associate a natural number to each element of E, and it can
be shown that the set of computable functions does not depend on the function used
to associate indices to the elements of E.
However, the set E is often inﬁnite, and may itself be a set of trees. For instance,
we have seen that proofs are trees labelled by sequents, which are trees labelled
by propositions, which in turn are trees labelled by variables, function symbols and
predicate symbols, which again are trees labelled by the elements of a ﬁnite set. The
set of proofs is therefore an articulated set of trees.
If we associate an arbitrary natural number to each element of this ﬁnite set, Def-
inition 3.7 allows us to index ﬁrst all the variables, function symbols and predicate
symbols, then all the propositions, sequents and ﬁnally proofs.
The same methodology applies to any set of articulated trees. It is possible to
show that the set of computable functions does not depend on the function used to
associate numbers (i.e., indices) to the initial, ﬁnite set.

3.2
Computability over Lists and Trees
61
Proposition 3.11 The functions that associate to the index p of the tree a the label
of its root and the number of subtrees of the root node, respectively, as well as the
function that associates to p and i the index of the ith immediate subtree of a, are
all computable.
Proof If p is the index of the tree a, the root label is hd(p) and the number of
children of the root node is length(tl(p)). The index of the ith immediate subtree is
nth (tl(p),i).
□
Proposition 3.12 That function that associates to the natural number p the index
⌜Sp(0)⌝of the tree Sp(0) is computable. The function that associates to the index
⌜Sp(0)⌝of the tree Sp(0) the natural number p, and to all natural numbers that are
not of the form ⌜Sp(0)⌝the number 0 is computable.
Proof The ﬁrst function is deﬁned by induction, the second by well-founded induc-
tion.
□
3.2.3 Derivations
Deﬁnition 3.8 (Effective rules) Let E be an articulated set of trees and let f1,f2,...
be rules over the set E. The set of rules f1,f2,... is effective if the set G of indices
of lists b,a1,...,an such that there exists a rule fi satisfying b = fia1 ···an is
decidable, that is, if the union of the graphs of the functions f1,f2,... is a decidable
set.
Proposition 3.13 Let E be an articulated set of trees and f1,f2,... a set of effec-
tive rules. Then, the set of derivations using f1,f2,... is decidable.
Proof We show that there exists a computable function g that takes a list of trees
as argument and returns 1 if all the trees are derivations and 0 otherwise. First, note
that the function that associates to a list of trees the list of their roots is computable.
Indeed, it can be deﬁned by well-founded induction using computable functions. Let
l be a list of trees. If l is an empty list, we deﬁne g(l) = 1. Otherwise, let a = hd(l)
be the ﬁrst tree in the list, and l′ = tl(l) be the list containing the remaining trees in
the list. Let r = hd(a) be the root of a, l′′ = tl(a) the list of the immediate subtrees
of a and s the list of the roots of the trees in l′′. Then, if r;s is in G, g(l′) = 1 and
g(l′′) = 1 we deﬁne g(l) = 1, otherwise we deﬁne g(l) = 0. The function g is thus
deﬁned by well-founded induction, using computable functions, since by Proposi-
tion 3.7 the indices associated to the lists l′ and l′′ are natural numbers strictly less
than l’s index. It is therefore a computable function.
□
Note that the set A inductively deﬁned by the rules f1,f2,... is not always de-
cidable. It is semi-decidable in general. Let x be an element of E, we can enumerate

62
3
Computable Functions
all the trees and check each one of them to see whether it is a derivation with root x
or not. If x is an element of A, we will eventually ﬁnd the corresponding derivation,
otherwise the process of enumeration will continue forever.
Proposition 3.14 (Inductively deﬁned sets of trees) Let E be an articulated set of
trees and f1,f2,... an effective set of rules over the set E. Then, the subset A of E
inductively deﬁned by these rules is semi-decidable.
Proof Let g(x,y) be the computable function such that g(x,y) = 1 if x is the index
associated to a derivation of an element of E and the root of x is y, and g(x,y) = 0
otherwise. The function h such that h(y) is the least natural number x such that
1 ˙−g(x,y) = 0 composed with the constant function 1 is a semi-decision algorithm
for A. If y is in A then h(y) = 1, otherwise h is not deﬁned for y.
□
3.3 Eliminating Recursion
There is an alternative deﬁnition of the set of computable functions, which, although
less natural than Deﬁnition 3.1, will be useful in the next chapters of the book.
Deﬁnition 3.9 The set C is inductively deﬁned as the smallest set that contains
• the projection functions,
• the zero functions (i.e., constant functions that always return 0),
• the successor function,
• addition,
• multiplication and
• the characteristic function of the ordering relation χ≤, deﬁned by χ≤(x,y) = 1 if
x ≤y and χ≤(x,y) = 0 otherwise,
and closed under
• composition and
• minimisation.
This deﬁnition is similar to Deﬁnition 3.1, but note that we have replaced the
recursive closure by three basic functions: addition, multiplication and χ≤. Our goal
now is to prove that these two deﬁnitions are equivalent, that is, we want to prove
that a function is in the set C if and only if it is computable. In order to do this, we
need to prove that the set C is closed under recursive deﬁnitions; in other words, we
need to prove that if g and h are functions in C and f is recursively deﬁned using g
and h, then f is in C.
The function deﬁned recursively from g and h returns the value r for x1,...,
xn−1,y if there exists a ﬁnite sequence s0,...,sy such that s0 = g(x1,...,xn−1), for
all i strictly less than y, si+1 = h(x1,...,xn−1,i,si), and sy = r. We will represent
the ﬁnite sequence s0,...,sy by a natural number. As a ﬁrst attempt, we could try to

3.3
Eliminating Recursion
63
represent it by the natural number s0;(...;(sy;0)...), since it is easy to show that
the functions ;, hd and tl are in the set C. However, since we do not have recursive
deﬁnitions yet, we cannot show that the function nth is in the set C. Instead, we
will use another representation of ﬁnite sequences, which is based on the use of a
function known as Gödel’s function β.
Deﬁnition 3.10 Gödel’s function β is deﬁned by
β(k,l,i) = l mod (k(i + 1) + 1)
where x mod y is the remainder of the Euclidean division of x by y.
Proposition 3.15 For any ﬁnite sequence s0,...,sy, there are two natural numbers
k,l such that for any i less than y, si = β(k,l,i).
Proof Let m be a natural number strictly greater than y + 1,s0,...,sy. It is easy to
check that the numbers ei = m!(i + 1) + 1 for i less than y are pairwise coprimes:
if ei and ej have a prime common divisor c, then c divides also their difference
m!(i −j), and is therefore less than m, it divides m!(i + 1) and therefore it cannot
divide ei = m!(i + 1) + 1. We use now a well-known result in number theory, the
theorem of the Chinese remainders: if e0,...,ey is a sequence of pairwise coprime
numbers and s0,...,sy a sequence of arbitrary natural numbers, there exists a natu-
ral number z such that for all i, si ≡z[mod ei]. Thus, using this theorem we deduce
that there exists a number z such that si ≡z[mod ei]. We take k = m! and l = z.
Then, si ≡l[mod ei] and since si is less than m which is in turn less than k and
therefore less than k(i + 1) + 1, si is the remainder of the Euclidean division of l by
k(i + 1) + 1, that is, si = β(k,l,i).
□
The fact that a function recursively deﬁned using g and h produces the value r
for x1,...,xn−1,y is now expressed by the fact that there exist two numbers k and
l such that β(k,l,0) = g(x1,...,xn−1), for all i strictly less than y, β(k,l,i + 1) =
h(x1,...,xn−1,i,β(k,l,i)) and β(k,l,y) = r.
Instead of stating that for all i strictly less than y, β(k,l,i +1) = h(x1,...,xn−1,
i,β(k,l,i)), we can equivalently state that the least zero of the function f1 that
associates 1 to x1,...,xn−1,y,k,l,i if i < y and β(k,l,i + 1) = h(x1,...,xn−1,i,
β(k,l,i)) and 0 otherwise, is y. Nevertheless, it is not easy to show that the function
f1 is in C, since this function must be deﬁned and take the value 0 for y whether h
is deﬁned for x1,...,xn−1,y,β(k,l,y) or not. To avoid this problem, we will prove
a more general theorem: if the function f is computable, then the function f ∗is in
C, where the function f ∗is deﬁned as follows.
Deﬁnition 3.11 Let f be a function with n arguments. We denote by f ∗the func-
tion with n+1 arguments deﬁned by f ∗(0,x1,...,xn) = 0 and f ∗(w,x1,...,xn) =
f (x1,...,xn) if w ̸= 0.
Proposition 3.16 The set C contains the subtraction function ˙−, the quotient and
remainder of the Euclidean division, and the functions χN∗, χ< and χ=, which are,

64
3
Computable Functions
respectively, the characteristic functions of the set N∗and the relations < and =,
the function β and the functions ;, hd and tl.
Proof Subtraction, quotient and remainder can be deﬁned using addition, multipli-
cation, minimisation and the characteristic function of the ordering relation. The
functions χN∗, χ< and χ= can be deﬁned using subtraction. The function β can be
deﬁned using addition, multiplication and the remainder function. The function ; is
deﬁned using addition, multiplication and quotient. Finally, the functions hd and tl
can be deﬁned using addition, multiplication, quotient and minimisation.
□
Proposition 3.17 If f is a function deﬁned by recursion using two functions g and
h such that g∗and h∗are in C, then f ∗is in C.
Proof The function f ∗satisﬁes the properties
f ∗(w,x1,...,xn−1,0) = g∗(w,x1,...,xn−1)
f ∗(w,x1,...,xn−1,y + 1) = h∗(w,x1,...,xn−1,y,f ∗(w,x1,...,xn−1,y))
and it is therefore the function recursively deﬁned from g∗and h∗.
Let f1 be the function from C that associates the number χ<(i,y) × χ=(h∗(w ×
χ<(i,y),x1,...,xn−1,i,β(k,l,i)),β(k,l,i + 1)) to w,x1,...,xn−1,y,k,l and i.
If i ≥y then f ∗is deﬁned and it is equal to 0 for w,x1,...,xn−1,y,k,l,i and if
i < y then
f1(w,x1,...,xn−1,y,k,l) = χ=(h∗(w,x1,...,xn−1,i,β(k,l,i)),β(k,l,i + 1))
Let f2 be the function from C that maps w,x1,...,xn−1,y, k and l to the least
natural number i such that f1(w,x1,...,xn−1,y,k,l,i) = 0. The natural number
f2(w,x1,...,xn−1,y,k,l) is equal to y if and only if for all i strictly less than y,
h∗is deﬁned for w,x1,...,xn−1,i,β(k,l,i) and h∗(w,x1,...,xn−1,i,β(k,l,i)) =
β(k,l,i + 1).
As a consequence, we deduce that there exists a function f3 in C that maps
w,x1,...,xn−1,y, k, l and r to 0 if and only if the function g∗is deﬁned for
w,x1,...,xn−1 and returns the value β(k,l,0), for all i strictly less than y, the func-
tion h∗is deﬁned for w,x1,...,xn−1,i,β(k,l,i) and returns the value β(k,l,i +1)
and β(k,l,y) = r.
Let f4 be the function from C that maps w,x1,...,xn−1,y to the smallest j such
that f3(w,x1,...,xn−1,y,hd(hd(j)),tl(hd(j)),tl(j)) = 0 and f5 the function from
C that maps w,x1,...,xn−1,y to tl(f4(w,x1,...,xn−1,y)). By Proposition 3.15,
the function f5 associates the value r to x1,...,xn−1,y if and only if there ex-
ists a sequence s such that s0 = g∗(w,x1,...,xn−1), for all i strictly less than y,
si+1 = h∗(w,x1,...,xn−1,i,si) and sy = r. Thus, the function f5 turns out to be
the function f ∗, and therefore is in the set C.
□
Proposition 3.18 A function is in the set C if and only if it is computable.

3.4
Programs
65
Proof By Deﬁnition 3.1 and Propositions 3.2 and 3.3, the set of computable func-
tions is closed under all the rules in the inductive deﬁnition of C, and therefore it
contains all the functions in the set C.
To prove the other direction, we start by showing, by induction on the con-
struction of f , that if f is a computable function then f ∗is in C. If f is a
projection, a zero function or the successor function, then f ∗(w,x1,...,xn) =
χN∗(w) × f (x1,...,xn) and thus the function f ∗belongs to C. If f is de-
ﬁned as the composition of the functions h and g1,...,gm, then, by induc-
tion hypothesis, the functions h∗, g∗
1,...,g∗
m are in C and f ∗(w,x1,...,xn) =
h∗(w,g∗
1(w,x1,...,xn),...,g∗
m(w,x1,...,xn)). The function f ∗is the composi-
tion of a projection, g∗
1,...,g∗
m and h∗, therefore it is also in C. If f is recursively
deﬁned from the functions g and h, then, by induction hypothesis, the functions
g∗and h∗are in the set C and by Proposition 3.17, so is the function f ∗. If f is
deﬁned by minimisation of a function g, then the function g∗is in C by induction
hypothesis, and f ∗is the function that maps w,x1,...,xn to the smallest i such
that g∗(w,x1,...,xn,i) = 0; this is therefore the function deﬁned by minimisation
of g∗and thus it is in C.
Since the function f ∗is in C, so is the function that maps x1,...,xn to the natural
number f ∗(1,x1,...,xn), which is in fact the function f .
□
3.4 Programs
The set of computable functions is inductively deﬁned, therefore for each com-
putable function there is at least one derivation. These derivations are trees, usually
called programs.
The nodes in these trees are labelled by symbols that correspond to the eight
rules in Deﬁnition 3.9: πn
i , where i and n are natural numbers and 1 ≤i ≤n, in the
case of a projection rule, Zn for a rule corresponding to a zero function, Succ for
the successor rule, + for the addition rule, × for the multiplication rule, χ≤for the
rule corresponding to the characteristic function of the ordering relation, ◦n
m for the
composition rule, and μn for minimisation.
Programs are therefore trees where nodes are labelled by the symbols πn
i , Zn,
Succ, +, ×, χ≤, ◦n
m and μn, which are in turn trees labelled by elements of a ﬁnite
set.
Of course, if we use an alternative deﬁnition of computable functions, we get a
different deﬁnition of program: using Deﬁnition 3.1, programs are trees with nodes
labelled by the symbols πn
i , Zn, Succ, ◦n
m, μn and Recn for recursive deﬁnitions.
Deﬁnition 3.12 (Termination, value) A program is terminating for the inputs p1,
...,pn if the function f computed by the program is deﬁned for p1,...,pn. We say
that a program returns the value q for p1,...,pn if in addition f (p1,...,pn) = q.
Exercise 3.3 Which is the function computed by the program ◦1
1(Succ,Succ)?
Exercise 3.4 Which is the function computed by the program μ1(π2
1 )?

66
3
Computable Functions
3.4.1 Undecidability of the Halting Problem
Theorem 3.1 (Undecidability of the halting problem) The set of pairs of natural
numbers (p,q) such that p is the index associated to a program that is terminating
for the input q is undecidable.
Proof By contradiction. Suppose that there exists a program t such that t applied to
two natural numbers p and q always terminates and returns the result 1 if p is the
index of a terminating program for the input q, and the result 0 otherwise. Recall
that the program b = μ1(π2
1 ) is terminating when applied to the number 0 and non-
terminating when applied to a natural number different from 0. Now consider the
program u = ◦1
1(b,◦1
2(t,π1
1 ,π1
1 )). Each time we apply the program u to a number
p, we apply ﬁrst the program ◦1
2(t,π1
1 ,π1
1) to this number. We obtain the result
1 if p is the index of a program that is terminating on the input p and the result
0 otherwise. Therefore, the program u applied to the natural number p does not
terminate if p is the number of a program that is terminating on the input p, and
terminates otherwise.
Let m be the natural number ⌜u⌝. The program u does not terminate on the input
m if m is the number of a program that terminates on m, and it terminates otherwise.
In other words, the program u applied to m is not terminating if the program u is
terminating when applied to m, and it terminates otherwise. The program u applied
to m does not terminate if and only if it terminates—a contradiction.
□
3.4.2 The Interpreter
There exists nevertheless a computable function Gn that behaves as an interpreter,
that is, takes as arguments the number associated to a program u of arity n and
natural numbers p1,...,pn and returns the value of the computable function repre-
sented by the program u for the inputs p1,...,pn, if this value exists. Showing the
existence of this interpreter will allow us to generalise the theorem of undecidability
of the halting problem. This will lead us to a description of a computation as a se-
quence of small steps, that is, a view of computation as a process that unfolds over
time (we will come back to this idea in Chap. 4).
To deﬁne the function Gn, we need a language that can express programs and
their inputs (i.e., natural numbers). We will extend the language of programs to in-
clude the symbols 0 and S in order to represent the natural numbers (note that these
are different from the symbols Zn and Succ used in the language of programs). We
will write p as an abbreviation for the term S(S(...(S(0))...)) where the symbol S
occurs p times, representing the natural number p. We will then introduce a family
of symbols Appn to build terms of the form Appn(u,p1,...,pn) which will repre-
sent the application of the program u to the natural numbers p1,...,pn.
The problem now is to deﬁne a computable function F that associates to the
index of a term Appn(u,p1,...,pn), the index of the term q representing the natural

3.4
Programs
67
number q, which is the value of the computable function denoted by the program
u for the inputs p1,...,pn, assuming this value exists. The term q is called the
value of the term Appn(u,p1,...,pn). Once we have deﬁned the function F, we can
simply deﬁne the function Gn, using Proposition 3.12, as the function that associates
to the index of the term u and the natural numbers p1,...,pn the natural number q
such that ⌜q⌝= F(⌜Appn(u,p1,...,pn)⌝), if q exists.
If the program u has the form ◦n
m(w,v1,...,vm), we will ﬁrst compute the val-
ues q1,...,qm of the programs v1,...,vm for p1,...,pn, and then compute the
value of the program w for q1,...,qm. In order to achieve this, we ﬁrst build the
term Appm(w,Appn(v1,p1,...,pn),...,Appn(vm,p1,...,pn)), then compute the
values of the terms Appn(vi,p1,...,pn) obtaining q1,...,qm, and ﬁnally we com-
pute the value of the term Appm(w,q1,...,qm). However, to proceed in this way
we need to be able to apply the symbol Appm not only to terms representing natural
numbers but also to other terms containing the symbol Appn which are not yet eval-
uated. Thus, to compute the value of such a term, we need to start by computing the
values of its arguments.
To compute the result of a program that uses minimisation, we will also need
to introduce a family of symbols Mn and a symbol Ifz. The value of the term
Mn+1(u,p1,...,pn,q) is the least natural number r greater than or equal to q such
that f (p1,...,pn,r) = 0 where f is the function computed by the program u. The
value of the term Ifz(p,v,w) is the value of the term v if p = 0 and the value of the
term w otherwise.
We start by deﬁning a function F1 that associates to the index of each term of
the form Appn(u,p1,...,pn), Mn+1(u,v1,...,vn,w) or Ifz(p,v,w), the index of
a term that denotes an intermediate state in the computation.
Deﬁnition 3.13 (A step of computation at the root) The computable function F1 is
deﬁned by cases:
– if t is the index of a term of the form Appn(u,p1,...,pn), then
– if u is of the form πn
i , then F1(t) = ⌜pi⌝,
– if u is of the form Zn, then F1(t) = ⌜0⌝,
– if u = Succ, then F1(t) = ⌜S(p1)⌝, that is, ⌜S⌝;(⌜p1⌝;0), or, equivalently,
⌜S⌝;(hd(tl(tl(t)));0),
– if u = +, then F1(t) = ⌜p1 + p2⌝,
– if u = ×, then F1(t) = ⌜p1 × p2⌝,
– if u = χ≤, then F1(t) = ⌜χ≤(p1,p2)⌝,
– if u is of the form ◦n
m(w,v1,...,vm), then
F1(t) = ⌜Appm(w,Appn(v1,p1,...,pn),...,Appn(vm,p1,...,pn))⌝
– if u is of the form μn(v), then
F1(t) = ⌜Mn+1(v,p1,...,pn,0)⌝
– if t is the index of a term of the form Mn+1(u,v1,...,vn,w), then
F1(t) = ⌜Ifz(Appn+1(u,v1,...,vn,w),w,Mn+1(u,v1,...,vn,S(w)))⌝

68
3
Computable Functions
– if t is the index of a term of the form Ifz(p,v,w), then F1(t) = ⌜v⌝, if p = 0 and
F1(t) = ⌜w⌝otherwise,
– otherwise, we deﬁne F1(t) = 0.
The function F1 performs a step of computation from a term of the form
Appn(u,v1,...,vn) where the terms v1,...,vn are natural numbers p1,...,pn. If
instead these are terms that need to be computed, then the function F2 deﬁned below
performs a step of computation on those terms.
Deﬁnition 3.14 (A step of computation) The computable function F2 is deﬁned by
well-founded induction:
– if t is the index of a term of the form Appn(u,v1,...,vn), then if the terms
v1,...,vn are of the form p1,...,pn, we deﬁne F2(t) = F1(t), otherwise, let
vi be the ﬁrst term that is not of the form p and v′ the term with index F2(⌜vi⌝),
we deﬁne
F2(t) = ⌜Appn(u,v1,...,vi−1,v′,vi+1,...,vn)⌝
– if t is the index of a term of the form Mn+1(u,v1,...,vn,w), we deﬁne F2(t) =
F1(t),
– if t is the index of a term of the form Ifz(u,v,w), then if the term u is of the form
p, we deﬁne F2(t) = F1(t), otherwise let u′ be the term with index F2(⌜u⌝), we
deﬁne F2(t) = ⌜Ifz(u′,v,w))⌝,
– otherwise, we deﬁne F2(t) = 0.
Now in order to deﬁne an interpreter F it is sufﬁcient to iterate the function F2
on the term t until we obtain a term of the form q. For this, we will deﬁne a function
F3 to iterate the function F2 p times, a function F4 that will check whether F3(t,p)
is of the form q or not, a function F5 to count the number of steps that are needed
to obtain such a term, and ﬁnally the function F.
Deﬁnition 3.15 (The interpreter) Let F3 be the computable function such that
F3(t,p) = F p
2 (t). This function is deﬁned by
F3(t,0) = t
F3(t,p + 1) = F2(F3(t,p))
Let F4 be the computable function such that F4(t,n) = 0 if F3(t,n) is the index
of a term of the form q, otherwise F4(t,n) = 1. This function can be deﬁned by
composition, using F3 and the function that returns 0 for all the indices of terms
of the form q and 1 for any other input. Let F5 be the computable function such
that F5(t) is the number of steps that are needed to compute t. F5(t) can be deﬁned
by minimisation: it is the least natural number p such that F4(t,p) = 0. Let F be
the computable function deﬁned by F(t) = F3(t,F5(t)). Finally, Gn is computable
function that associates to t and p1,...,pn the natural number q such that ⌜q⌝=
F(⌜Appn(t,p1,...,pn)⌝).

3.4
Programs
69
If F3(t,n) never returns the index of a term representing a natural number, in
other words, if the iterations of F2 continue forever, then F5 and F are undeﬁned
for t: the interpreter does not terminate if the program to be interpreted is non-
terminating.
Proposition 3.19 Let f be a computable function, u the index of a program that
represents this function and p1,...,pn natural numbers. The function f is deﬁned
for p1,...,pn if and only if the function F is deﬁned for ⌜Appn(u,p1,...,pn)⌝, and
if
these
two
functions
are
deﬁned,
then
F(⌜Appn(u,p1,...,pn)⌝) =
⌜f (p1,...,pn)⌝.
Proof By induction on the construction of f .
□
Proposition 3.20 Let f be a computable function, u the index of a program rep-
resenting this function and p1,...,pn natural numbers. The function f is deﬁned
for p1,...,pn if and only if the function Gn is deﬁned for u,p1,...,pn and if these
two functions are deﬁned then Gn(u,p1,...,pn) = f (p1,...,pn).
Proof Consequence of Proposition 3.19.
□
Exercise 3.5 Show that the function F3 is primitive recursive.
Exercise 3.6 Deﬁne an interpreter for the programs written in the language gener-
ated by the symbols πn
i , Zn, Succ, ◦n
m, μn and Recn, corresponding to Deﬁnition 3.1.
As a corollary of the existence of this interpreter, we obtain a generalisation of
the theorem of undecidability of the halting problem.
Proposition 3.21 Let A be a decidable subset of the set of terminating programs.
There exists a computable, total function that is not represented by any program
in A.
Proof Let H be the computable function deﬁned as follows: if n is the index of a
unary program in A and p is a natural number then H(n,p) = G1(n,p), otherwise
H(n,p) = 0.
The function H is computable; it is an interpreter for unary programs in A and it
is total.
Let H ′ be the function such that H ′(p) = H(p,p) + 1. If A contains a term t
representing the function H ′, then H(⌜t⌝,p) = H ′(p) = H(p,p) + 1 for all p, but
then for p = ⌜t⌝we obtain H(⌜t⌝,⌜t⌝) = H(⌜t⌝,⌜t⌝) + 1, which is a contradic-
tion.
□
This result shows that a programming language in which all programs are termi-
nating is necessarily incomplete: it cannot express its own interpreter. For instance,
the imperative language consisting of variable declarations, assignment, sequence
and for loops is not complete.

70
3
Computable Functions
Using this result we could also give an alternative proof of the undecidability of
the halting problem: Assume that the set containing all the terminating programs is
decidable, then by the previous result we deduce that there exists a total function
that is not in this set (contradiction).
We could also prove that there exists a computable total function that is not prim-
itive recursive, since the set of programs that can be represented in the language πn
i ,
Zn, Succ, ◦n
m, Recn is decidable.

Chapter 4
Computation as a Sequence of Small Steps
The interpreter deﬁned in Sect. 3.4.2 suggests a new approach to the deﬁnition of
computation, where programs are expressions in a language L. Given a program t
and arguments p1,...,pn, we can build a term, that is an expression in a language
L′ that extends the language L; then, the execution of the program is deﬁned by a
computable total function from terms in L′ to terms in L′. This function describes a
small step of computation, but we can iterate it until we obtain a natural number, i.e.,
the result of the computation, or otherwise continue iterating forever if the program
t is non-terminating for the arguments p1,...,pn.
Thus, the notion of termination given in Deﬁnition 3.12 corresponds to the one
familiar to programmers: a program that does not terminate is a program that con-
tinues computing forever.
The languages L and L′ and the function that describes a small step of computa-
tion can be seen as the deﬁnition of a programming language, and a partial function
f is said to be representable in this language if there exists a program t such that
the term built out of the program t and the natural numbers p1,...,pn computes
a natural number f (p1,...,pn) when the function f is deﬁned for p1,...,pn and
does not terminate otherwise. It is easy to show that all the partial functions that can
be represented in such a language are computable.
Some programming languages, for instance the one deﬁned in Sect. 3.4.2, can
express all computable functions; these languages are said to be Turing complete.
Traditional programming languages such as Java, Caml, C, ... are Turing com-
plete, and so are a number of programming languages developed by researchers
to study programming language properties. These languages do not have the same
applications as traditional programming languages: it is more difﬁcult to express
algorithms in them because they have only a minimal number of primitive construc-
tions, but this makes them simpler to study. By simplifying the language in which
algorithms are expressed, one can better reason about algorithms, in particular if the
goal is to establish that an algorithm terminates, preserves some invariant or has a
given complexity.
In this chapter we will describe three of these minimalistic languages: term
rewriting, the lambda-calculus, and Turing machines.
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_4, © Springer-Verlag London Limited 2011
71

72
4
Computation as a Sequence of Small Steps
4.1 Rewriting
Rewriting is the simplest language that allows us to express computations as se-
quences of small steps. Terms are simply expressions in a language without binders,
and computation steps are deﬁned by a set of rules, called rewriting rules, which
specify the way in which terms are transformed. For instance, the rule
0 + y −→y
states that any term of the form 0 + t can be transformed into t.
Deﬁnition 4.1 (Rewriting rule) Let L be a language without binders. A rewriting
rule in the language L is a pair l, r of terms in L, written l −→r.
Deﬁnition 4.2 (Reduction step at the root) Let R be a set of rewriting rules.
An R-reduction step at the root is a pair of terms in the language L, written t −→u,
such that there exists a rewriting rule l −→r in R and a substitution σ such that
σl = t and σr = u.
Deﬁnition 4.3 (Redex) Let R be a set of rewriting rules. A term t is a redex if it
is reducible by the relation −→, that is, if there is a rewriting rule l −→r and a
substitution σ such that σl = t.
The relation −→can be extended to perform reductions in subterms.
Deﬁnition 4.4 (Reduction step) Let R be a set of rewriting rules. An R-reduction
step is the relation deﬁned inductively by
– if t →u then t ▷u,
– if t ▷u, then f (t1,...,ti−1,t,ti+1,...,tn) ▷f (t1,...,ti−1,u,ti+1,...,tn).
Deﬁnition 4.5 (Reduction) The reduction relation ▷∗is the reﬂexive-transitive clo-
sure of the relation ▷.
Exercise 4.1 Consider the following set of rewriting rules.
0 + y −→y
S(x) + y −→S(x + y)
Show that S(S(0)) + S(S(0)) ▷∗S(S(S(S(0)))).
Deﬁnition 4.6 (Irreducibility, termination) Let R be a binary relation. An element
t is irreducible by the relation R if there is no element u such that t R u.
An element t is terminating if there exists an irreducible element t′ such that
t R∗t′.

4.1
Rewriting
73
Deﬁnition 4.7 (Irreducibility and termination for terms) Let R be a set of rewriting
rules. A term t is irreducible if it is irreducible by the relation ▷, that is, if neither
of its subterms is a redex.
A term t is terminating if it is terminating for the relation ▷, that is, if there exists
some irreducible term t′ such that t ▷∗t′.
For example, if we have two rules f (x) −→a and ω −→ω, then the term ω is
non-terminating, since the only term that can be obtained by reduction is ω again.
However, the term f (ω) is terminating. Indeed, we can reduce the subterm ω and
obtain again f (ω) but we can also reduce at the root and obtain the irreducible
term a.
Deﬁnition 4.8 (Conﬂuence) A binary relation R is conﬂuent if for any u and v such
that t R∗u and t R∗v, there exists some w such that u R∗w and v R∗w.
If the relation ▷is conﬂuent, then each term u can be reduced to at most one
irreducible term: if t ▷∗u and t ▷∗v, and u and v are irreducible, then u = v. In
general, if t, u and v are three terms such that t ▷∗u and t ▷∗v, and v is irre-
ducible, then u ▷∗v. However, as we have seen with the term f (ω), some reduction
sequences might end with an irreducible term, whereas others are inﬁnite.
Deﬁnition 4.9 (Orthogonal set of rules) A set R of rewriting rules is orthogonal if
– for each rewriting rule l −→r in R, the variables occurring in r occur also in l,
– for each rewriting rule l −→r in R, each variable x occurs at most once in l,
– if l −→r and l′ −→r′ are two different rewriting rules in R, and l′′ is a non-
variable subterm of l′, then for any pair of substitutions σ and τ, σl ̸= τl′′,
– if l −→r is a rewriting rule in R, and l′′ is a strict subterm of l which is not a
variable, then for any pair of substitutions σ and τ, σl ̸= τl′′.
Exercise 4.2 Is the set consisting of the rule
c −→x
orthogonal?
Show that the term c can be reduced to two different irreducible terms.
Exercise 4.3 Is the set consisting of the rules
g(h(x)) −→a
f (g(x)) −→b
orthogonal?
Show that the term f (g(h(c))) can be reduced to two different irreducible terms.
Exercise 4.4 Is the set consisting of the rules
x −x −→0

74
4
Computation as a Sequence of Small Steps
S(x) −x −→1
∞−→S(∞)
orthogonal?
Show that the term ∞−∞can be reduced to two different irreducible terms.
This deﬁnition of orthogonality is motivated by the following result (the proof is
omitted).
Proposition 4.1 (Conﬂuence of orthogonal sets of rules) If R is an orthogonal set
of rewriting rules, then the relation ▷is conﬂuent.
Deﬁnition 4.10 (Representing natural numbers) If the language L contains a con-
stant 0 and a unary symbol S and if p is a natural number, we denote by p the term
S(S(...(S(0))...)) where the symbol S occurs p times.
Deﬁnition 4.11 (Representing functions) Let L be a language containing the sym-
bols 0 and S, and let R be a conﬂuent set of rewriting rules such that all the terms
of the form p are irreducible. Let F be a symbol in L and f a partial function. The
pair R,F represents the function f if for all p1,...,pn
– if f (p1,...,pn) = q then F(p1,...,pn) ▷∗q,
– if f is not deﬁned for p1,...,pn then F(p1,...,pn) is non-terminating.
This deﬁnition does not ﬁt properly in the framework that we gave in the intro-
duction to this chapter, because a term which contains several redexes might reduce
to several terms. However, we can use a speciﬁc reduction strategy: call by name
avoids this non-determinism if the set of rules is orthogonal.
Deﬁnition 4.12 (A reduction step under call by name) An R-reduction step under
call by name is deﬁned by induction
– if t −→t′, then t ≻t′,
– if f (t1,...,tn) is not a redex, t1,...,ti−1 are irreducible, and ti ≻t′
i then
f (t1,...,ti−1,ti,ti+1,...,tn) ≻f (t1,...,ti−1,t′
i,ti+1,...,tn).
In other words, given a term with several redexes, we give priority to the leftmost
one.
An irreducible term with respect to the relation ▷does not contain any redex; it
is therefore also irreducible with respect to the relation ≻. However, if a term can be
reduced by ▷, then it contains at least a redex, and it can be reduced by ≻. In this
case, if the set of rules is orthogonal, the call by name reduction strategy produces a
unique result.
Deﬁnition 4.13 (Call by name reduction) The reduction relation ≻∗is the reﬂexive-
transitive closure of the relation ≻, inductively deﬁned by

4.1
Rewriting
75
– t ≻∗t,
– if t ≻t′ and t′ ≻∗t′′, then t ≻∗t′′.
This strategy suggests another way to represent functions.
Deﬁnition 4.14 (Representation of functions under call by name) Let L be a lan-
guage that contains the symbols 0 and S. Let R be a set of rewriting rules such
that all terms of the form p are irreducible. Let F be a symbol in L and f a par-
tial function. The pair R,F represents the function f under call by name if for all
p1,...,pn,
– if f (p1,...,pn) = q, then F(p1,...,pn) ≻∗q,
– if f is not deﬁned for p1,...,pn, then F(p1,...,pn) is non-terminating under
call by name.
If we use call by name reduction, we are back in the framework deﬁned in the
introduction to this chapter. A program is simply a pair consisting of an orthogonal
set of rewriting rules and a function symbol. From the program (R,F) and the
natural numbers p1,...,pn we can build a pair consisting of a set R of rules and a
term F(p1,...,pn), and deﬁne a notion of computation where a computation step
corresponds to a reduction step under call by name using the rules in R.
Our aim now is to associate to each computable function f a set of rewriting
rules representing this function, both in general and under call by name.
The following example illustrates the main difﬁculty we face. If g is a function
undeﬁned for the argument 4 and h is the constant function equal to 0 then the func-
tion f = h◦g is not deﬁned for 4. However, if we simply write the rules H(x) −→0
and F(x) −→H(G(x)), then the term F(4) reduces to H(G(4)) and then to 0, in-
stead of producing a non-terminating computation. To solve this problem, we can
replace the rule H(x) −→0 by H(x) −→0&x and the rule F(x) −→H(G(x)) by
F(x) −→H(G(x))&x, introducing a binary symbol & such that t&u reduces to t if
u reduces to a natural number, and t&u is non-terminating if u is non-terminating.
This property can be obtained with the rules x&0 −→x and x&S(y) −→x&y,
which erase the term u step by step, provided that it represents a natural number.
Deﬁnition 4.15 (Representing computable functions) Let f be a computable func-
tion with n arguments. We associate to f a symbol F and a set of rewriting rules as
follows. All the sets contain the rules
x&0 −→x
x&S(y) −→x&y
Ifz(0,y,z) −→y
Ifz(S(x),y,z) −→z&x
To these rules we add speciﬁc rules depending on the function f , deﬁned by induc-
tion over its construction.

76
4
Computation as a Sequence of Small Steps
– If the function f is the ith projection, we add the rule
F(x1,...,xn) −→((((xi&x1)&...&xi−1)&xi+1)&...&xn)
– If the function f is a zero function, we add the rule
F(x1,...,xn) −→((0&x1)&...&xn)
– If the function f is the successor function, we add the rule
F(x) −→S(x)
– If the function f is addition, we add the rules
F(0,y) −→y
F(S(x),y) −→S(F(x,y))
– If the function f is multiplication, we add the rules
F(0,y) −→0&y
F(S(x),y) −→F ′(F(x,y),y)
F ′(0,y) −→y
F ′(S(x),y) −→S(F ′(x,y))
– If the function f is the characteristic function of the ordering relation, we add the
rules
F(0,y) −→S(0)&y
F(S(x),0) −→0&x
F(S(x),S(y)) −→F(x,y)
– If the function f is obtained by composition from h and g1,...,gm, then we take
the sets of rules associated to these functions, and rename the symbols so that the
sets share at most the symbols 0, S, & and Ifz; to the union of the sets of rules
obtained we add the rule
F(x1,...,xn) −→(H(G1(x1,...,xn),...,Gm(x1,...,xn)))&x1&...&xn
– If the function f is deﬁned by minimisation of the function g, then we consider
the set of rewriting rules associated to this function, and we add the rules
F(x1,...,xn) −→F ′(x1,...,xn,0)
F ′(x1,...,xn,y) −→Ifz(G(x1,...,xn,y),y,F ′(x1,...,xn,S(y)))
Proposition 4.2 The set of rules given in Deﬁnition 4.15 is conﬂuent.
Proof It is an orthogonal set, therefore by Proposition 4.1 it is conﬂuent.
□
Proposition 4.3 If f (p1,...,pn) = q and the terms u1,...,un reduce to p1,
...,pn under call by name, then the term F(u1,...,un) reduces to q under call
by name.

4.1
Rewriting
77
Proof By induction over the deﬁnition of f . If f is a projection F(u1,...,un)
reduces to ((((ui&u1)&...&ui−1)&ui+1)&...&un) which under call by name re-
duces to pi. The cases corresponding to a zero function, the successor function,
addition, multiplication and the characteristic function of the ordering relation are
similar.
If the function f is deﬁned by composition using h and g1,...,gm, then
F(u1,...,un) reduces to (H(G1(u1,...,un),...,Gm(u1,...,un)))&u1&...&un
under call by name. By induction hypothesis, this term reduces under call by name
to q&u1&...&un, then to q.
If the function f is obtained by minimising the function g, then g(p1,...,pn,r)
is deﬁned and its value is different from zero for all natural number r strictly less
than q, and g(p1,...,pn,q) = 0. The term F(u1,...,un) reduces under call by
name to F ′(u1,...,un,0), which reduces to F ′(u1,...,un,1)&v0,...,F ′(u1,...,
un,q)&vq−1&...&v0, where v0 reduces to g(p1,...,pn,0),...,vq−1 reduces to
g(p1,...,pn,q −1), and then to Ifz(G(u1,...,un,q),q,F ′(u1,...,un,q + 1))&
vq−1&...&v0, to Ifz(0,q,F ′(u1,...,un,q + 1))&vq−1&...&v0, to q&vq−1&...
&v0 and ﬁnally to q.
□
We will now prove that if the function f is undeﬁned for p1,...,pn then the term
F(p1,...,pn) is non-terminating. We start by proving the following proposition.
Proposition 4.4 If any of the terms u1,...,un is non-terminating, then F(u1,...,
un) is non-terminating. In other words, if F(u1,...,un) ▷∗t′, then t′ is not irre-
ducible.
Proof First, we remark that if a term S(u) is non-terminating, so is the term u. Then,
we deﬁne the set of strict subterms of a term t, denoted by SST(t), by induction over
the structure of t:
– if t = x, then SST(t) = {t},
– if f is a function symbol different from Ifz (that is, one of the symbols 0, S, &
or a symbol F representing a computable function) and t = f (u1,...,un), then
SST(t) = {t} ∪
i SST(ui),
– if t = Ifz(u1,u2,u3), then SST(t) = {t} ∪SST(u1).
First we show that for a set of rewriting rules as in Deﬁnition 4.15, if t −→t′
and SST(t) contains a non-terminating term, then so does SST(t′). Let u be a non-
terminating member of SST(t). If the term u is t itself, then t′ is non-terminating
and therefore SST(t′) contains a non-terminating element. If u is different from t,
then by inspection of the rules, we verify that either u is in SST(t′) and therefore this
set has a non-terminating element, or it is of the form S(u′) and SST(t′) contains u′
that is non-terminating by the remark above.
Similarly we can show by induction over the structure of t that if t ▷t′ and
SST(t) contains a non-terminating subterm, then so does SST(t′), and also if t ▷∗t′
and SST(t) contains a non-terminating subterm, then so does SST(t′).

78
4
Computation as a Sequence of Small Steps
As a consequence, we deduce that if one of the terms ui is non-terminating, and
F(u1,...,un) ▷∗t′, then SST(t′) contains a non-terminating term. This means that
a subterm of t′ is a redex, and therefore t′ is not irreducible.
□
We can now prove that if the function f is undeﬁned for p1,...,pn then the term
F(p1,...,pn) is non-terminating.
Proposition 4.5 If the terms u1,...,un reduce to p1,...,pn, respectively, and
f is undeﬁned for p1,...,pn, then F(u1,...,un) is non-terminating, that is, if
F(u1,...,un) ▷∗t′, then t′ is not irreducible.
Proof Let t′ be a term such that F(u1,...,un) ▷∗t′. We prove that t′ is not irre-
ducible by induction over the deﬁnition of f .
The projections, the zero functions, the successor function, addition, multiplica-
tion and the characteristic function of the ordering relation are all total.
If the function f is deﬁned by composition, using h and g1,...,gm, and if in
the sequence of reductions from F(u1,...,un) to t′ we never reduce a term at the
root, then t′ is itself a redex. If we do reduce a redex at the root, after some steps
we obtain the term H(G1(u′
1,...,u′
n),...,Gm(u′
1,...,u′
n))&u′
1&...&u′
n where
the u′
i are reducts of ui and t′ is a reduct of this term. By conﬂuence, u′
i reduces
to pi. If one of the functions gi is undeﬁned for p1,...,pn, then by induction
one of the terms Gi(u′
1,...,u′
n) is non-terminating and therefore so is the term
H(G1(u′
1,...,u′
n),...,Gm(u′
1,...,u′
n))&u′
1&...&u′
n by Proposition 4.4.
Otherwise, gi(p1,...,pn) = qi, and h is undeﬁned for q1,...,qm. In this case,
Gi(u′
1,...,u′
n) reduces to qi and H(G1(u′
1,...,u′
n),...,Gm(u′
1,...,u′
n)) is non-
terminating by induction.
Thus, the term H(G1(u′
1,...,u′
n),...,Gm(u′
1,...,u′
n))&u′
1&...&u′
n is non-
terminating. Since the term H(G1(u′
1,...,u′
n),...,Gm(u′
1,...,u′
n))&u′
1&...&u′
n
is non-terminating, t′ is not irreducible.
If f is deﬁned by minimisation of the function g, then either the function g is
deﬁned everywhere and never returns 0, or it gives a non-zero result up to a certain
value q −1 and is undeﬁned for q.
In the ﬁrst case, by induction if the terms u′
1,...,u′
n reduce to p1,...,pn and u′
reduces to a number, the term G(u′
1,...,u′
n,u′) reduces to a number different from
0. We build inductively a set of terms containing
– the terms of the form F(u′
1,...,u′
n) where the terms u′
1,...,u′
n reduce to
p1,...,pn,
– the terms of the form F ′(u′
1,...,u′
n,u′)&w1&...&ws where the terms u′
1,...,u′
n
reduce to p1,...,pn and u′,w1,...,ws to arbitrary natural numbers,
– the terms of the form Ifz(t,u,v)&w1&...&ws, where the term t reduces to a
number different from 0, u is arbitrary, v is in the set and w1,...,ws reduce to
arbitrary natural numbers.
We can show that this set is closed under reduction, and therefore the term t′ is in
this set, thus it is not irreducible.

4.1
Rewriting
79
In the second case, by induction if the terms u′
1,...,u′
n reduce to p1,...,pn and
u′ reduces to r for some r < q, the term G(u′
1,...,u′
n,u′) reduces to a number
different from 0. We build inductively a set of terms containing
– the terms of the form F(u′
1,...,u′
n) where the terms u′
1,...,u′
n reduce to
p1,...,pn,
– the terms of the form F ′(u′
1,...,u′
n,u′)&w1&...&ws where the terms u′
1,...,u′
n
reduce to p1,...,pn, u′ to r for some r < q and w1,...,ws reduce to arbitrary
natural numbers,
– the terms of the form Ifz(t,u,v)&w1&...&ws where the term t reduces to a
number different from 0, u is arbitrary, v is in the set and w1,...,ws reduce to
arbitrary natural numbers,
– the terms of the form Ifz(t,u,v)&w1&...&ws where the term t is non-
terminating, u and v are arbitrary and w1,...,ws reduce to arbitrary natural
numbers,
– the terms of the form v&t&w1&...&ws where the term t is non-terminating, v
is arbitrary and w1,...,ws reduce to arbitrary natural numbers.
We can show that this set is closed under reduction, and therefore the term t′ is in
this set, thus it is not irreducible.
□
We can ﬁnally conclude.
Theorem 4.1 Every computable function can be represented by a set of rewriting
rules in general and under call by name.
The converse of this theorem states that all the functions that can be represented
by a set of rewriting rules under call by name are computable. Indeed, the terms
in the language L are trees, and therefore can be enumerated. It is sufﬁcient then to
show that the function that describes a basic step of computation, that is the function
that associates to t the term u such that t ≻u, is computable.
Exercise 4.5 Give a direct proof of the fact that the set of functions that can be
represented by a set of rewriting rules is closed under recursive deﬁnitions.
Exercise 4.6 A relation R deﬁned over a set E is strongly conﬂuent if each time we
have t R u and t R v, there exists an element w such that (u R w or u = w) and
(v R w or v = w).
Show that a strongly conﬂuent relation is conﬂuent.
Exercise 4.7 This exercise relies on Exercise 4.6, which should be done prior to
this one.
The goal of this exercise is to show a particular case of the theorem that states that
a set of orthogonal rules deﬁnes a conﬂuent relation ▷. Consider the language built
out of the constants a and b, the unary function symbol f and the binary function
symbol g. Assume we have the set of rules
a −→b

80
4
Computation as a Sequence of Small Steps
f (x) −→g(x,x)
1. The relation ▷induced by this set of rules is inductively deﬁned by the rules
a ▷b
f (t) ▷g(t,t)
t ▷t′
f (t) ▷f (t′)
t1 ▷t′
1
g(t1,t2) ▷g(t′
1,t2)
t2 ▷t′
2
g(t1,t2) ▷g(t1,t′
2)
Is it the case that g(a,a) ▷g(b,b)? Is the relation ▷deﬁned by this set of rules
strongly conﬂuent?
2. Consider a variant of this relation, parallel reduction, inductively deﬁned by the
rules
t ▷∥t
a ▷∥b
f (t) ▷∥g(t,t)
t ▷∥t′
f (t) ▷∥f (t′)
t1 ▷∥t′
1
t2 ▷∥t′
2
g(t1,t2) ▷∥g(t′
1,t′
2)
Is it the case that g(a,a) ▷∥g(b,b)? Show that the relation ▷∥is strongly con-
ﬂuent. Show that the relation ▷∥is conﬂuent.
3. Show that if t ▷u then t ▷∥u. Show that if t ▷∗u then t ▷∥∗u. Show that if
t ▷∥u then t ▷∗u. Show that if t ▷∥∗u then t ▷∗u. Show that the relation ▷is
conﬂuent.
Exercise 4.8 (Noetherian Induction) Let R be a relation deﬁned over a set E. A re-
duction sequence for this relation is a ﬁnite or inﬁnite sequence x0,x1,x2,... such
that for all i, xi R xi+1. An element x in E is strongly terminating if every reduction
sequence out of x is ﬁnite.
The relation R is strongly terminating or well founded, also called Noetherian, if
every element is strongly terminating.
1. Show that a strongly terminating element is terminating.

4.2
The Lambda-Calculus
81
2. Give an example of a relation for which every element is terminating, but some
elements are not strongly terminating.
3. Let R be a relation over a set E. An element u is a reduct of t, t R+ u, if there
exists a ﬁnite reduction sequence with more than one step from t to u. Let A be
a subset of E such that
for every element x in E
if all the reducts of x are in A, then x is in A
Show that if x is not in A, it is not strongly terminating. Show that if x is strongly
terminating, it is in A. Show that if R is well founded then all the elements in E
are in A.
Exercise 4.9 (Newman’s theorem) This exercise relies on Exercise 4.8, which
should be done prior to this one.
A relation R over a set E is locally conﬂuent if whenever we have t R u and
t R v, there exists an element w such that u R∗w and v R∗w.
1. Consider a set with four elements a, b, c and d and the relation deﬁned by a R b,
b R a, a R c and b R d. Is this relation locally conﬂuent? Is it conﬂuent? Is every
locally conﬂuent relation also conﬂuent?
2. Show that a well founded and locally conﬂuent relation is conﬂuent.
4.2 The Lambda-Calculus
The goal of the lambda-calculus is to bring programming languages closer to the
language used in mathematics to express functions.
If e is a function associating to a natural number p the number 2p, then the
function that associates to p the number 22p can be represented in the language
deﬁned in Sect. 3.4.2 by the term ◦1
1(e,e) or by the term ◦1
1(e,◦1
1(e,π1
1 )). We can
also represent it simply as x →App(e,App(e,x)), or λxApp(e,App(e,x)), or even
fun x →App(e,App(e,x)), using a binary symbol App that does not bind any vari-
ables in its arguments, and a unary symbol →, also written λ or fun, that binds a
variable in its argument. If we write (t u) for the term App(t,u), the expression
above can be simply written fun x →(e (e x)).
There is no need to extend the notation fun to represent functions with more
than one argument: we can build such functions using functions with one argument,
thanks to the isomorphism (A × B) →C = A →(B →C). For example, the func-
tion that associates to x and y the number x × x + y × y is deﬁned as the function
that associates to x the function that associates to y the number x × x + y × y:
fun x →fun y →(x × x + y × y). We can now apply this function f to the num-
bers 3 and 4; we ﬁrst apply it to 3, that is, we build the term (f 3) representing the
function that associates to y the number 3 × 3 + y × y, and then to 4, obtaining the
term ((f 3) 4).

82
4
Computation as a Sequence of Small Steps
Deﬁnition 4.16 (The language of the lambda-calculus) The language of the
lambda-calculus is built out of a binary symbol App that does not bind any vari-
able, and a unary symbol fun that binds a variable in its argument.
If a function fun x →t is applied to a term u, we should be able to transform the
obtained expression into (u/x)t where the formal argument x is substituted by the
actual argument u. This transformation is a basic computation step in the lambda-
calculus.
Deﬁnition 4.17 (A beta-reduction step at the root) A beta-reduction step at the root
is a relation −→over lambda-calculus terms deﬁned by
((fun x →t) u) −→(u/x)t
Deﬁnition 4.18 (Redex) A redex is a term that can be reduced by −→, that is, a
term of the form ((fun x →t) u).
The relation −→can be extended in order to reduce terms of the form ((fun x →
t) u) inside subterms.
Deﬁnition 4.19 (A beta-reduction step) A beta-reduction step is a relation ▷over
lambda-calculus terms, inductively deﬁned by
– if t −→t′, then t ▷t′,
– if t ▷t′, then (t u) ▷(t′ u),
– if u ▷u′, then (t u) ▷(t u′),
– if t ▷t′, then (fun x →t) ▷(fun x →t′).
Deﬁnition 4.20 (Beta-reduction) The reﬂexive-transitive closure of the relation ▷
is called beta-reduction, and denoted by ▷∗.
Deﬁnition 4.21 (Irreducibility, termination) A term t is irreducible if it cannot be
reduced by the relation ▷, that is, if neither of its subterms is a redex.
A term t is terminating if it is terminating by the relation ▷, that is, if there exists
an irreducible term t′ such that t ▷∗t′.
For example, the term ((fun x →(x x)) y) is terminating since it can be reduced
to the irreducible term (y y). However, the term ω = ((fun x →(x x)) (fun x →
(x x))) is non-terminating, since the only term that can be obtained by reduction
is ω itself. The term ((fun x →y) ω) is also terminating, since it reduces to the
irreducible term y.
Since a term may contain several redexes, a priori it may seem that a term could
be reduced to several different irreducible terms. However, it can be shown that this
is not possible since the relation ▷is conﬂuent. This property can be proved by
showing that the parallel beta-reduction relation is strongly conﬂuent. The proof is
similar to the one in Exercise 4.7 and will be omitted here.

4.2
The Lambda-Calculus
83
Proposition 4.6 (Conﬂuence of beta-reduction) The relation ▷is conﬂuent.
Since the relation ▷is conﬂuent, a term u can be reduced to at most one irre-
ducible term: if t ▷∗u and t ▷∗v and u and v are irreducible, then u = v. In general,
if t, u and v are three terms such that t ▷∗u and t ▷∗v and v is irreducible, then
u ▷∗v. Notice that there are some terms, such as the term ((fun x →y) ω) men-
tioned above, that can be reduced to an irreducible term if we reduce one of the
redexes but produce an inﬁnite reduction sequence if we choose to reduce the other
redex.
The lambda-calculus cannot be seen as a particular case of the rewriting systems
studied in the previous section, since the symbol fun binds a variable (the languages
considered in the previous section did not include binders). Moreover, the right-hand
side of the beta-reduction rule uses an auxiliary operation: substitution. Note also
that the terms t and u mentioned in the left-hand side of the beta-reduction rule are
not variables to be instantiated using a substitution σ: substitutions avoid capture
of variables and this would mean that x cannot occur in the term t. For this, we
would need to distinguish variables such as x from variables such as t so that the
substitution for the variable t can capture x—the same mechanism is needed if we
extend predicate logic to permit the use of binders in terms. There are extensions of
the notion of rewriting to deal with languages with binders, but they are out of the
scope of this book.
Assume we associate to each natural number p an irreducible lambda-term p.
We can now represent functions in the lambda-calculus.
Deﬁnition 4.22 (Representing functions in the lambda-calculus) A term F in the
lambda-calculus represents a function f from natural numbers to natural numbers
if for all natural numbers p1,...,pn
– if f (p1,...,pn) = q, then (F p1 ... pn) ▷∗q,
– if f is undeﬁned for p1,...,pn, then the term (F p1 ... pn) is non-terminating.
As in the case of rewriting, this deﬁnition does not ﬁt properly in the framework
that we gave in the introduction to this chapter, because a term which contains sev-
eral redexes might reduce to several terms. However, we can use a speciﬁc reduction
strategy: call by name avoids this non-determinism. Moreover, the standardisation
theorem shows that no expressive power is lost by restricting reductions in this way.
Deﬁnition 4.23 (A beta-reduction step under call by name) A beta-reduction step
under call by name is deﬁned by the relation ≻over lambda-terms, inductively
deﬁned as follows
– if t −→t′, then t ≻t′,
– if (t u) is not a redex (that is, if t is not of the form fun) and if t ≻t′, then
(t u) ≻(t′ u),
– if (t u) is not a redex and no subterm of t is a redex and u ≻u′, then (t u) ≻(t u′),
– if t ≻t′, then (fun x →t) ≻(fun x →t′).

84
4
Computation as a Sequence of Small Steps
In other words, if a term contains several redexes, we give priority to certain
reductions. For a term of the form fun x →t, the priority redex is the one that has
priority in t. For a term of the form (t u), we give priority to the redex at the root if
there is one, otherwise we give priority to the reduction that has priority in t, if there
is one, otherwise to the priority redex in u. Thus, the priority redex is the leftmost
redex in the term.
Note that if a term is irreducible by ▷, it has no redexes and therefore it is also
irreducible by ≻. However, if a term can be reduced by ▷, then it contains at least
one redex and it can also be reduced by ≻. In the latter case, there exists a unique
reduct under call by name.
Deﬁnition 4.24 (Call-by-name beta-reduction) The beta-reduction relation ≻∗is
the reﬂexive transitive closure of the relation ≻, inductively deﬁned by
– t ≻∗t,
– if t ≻t′ and t′ ≻∗t′′, then t ≻∗t′′.
We have seen that some terms, such as ((fun x →y) ω), can be reduced to an
irreducible term if we choose to reduce one of the redexes but produce an inﬁnite
reduction sequence if we choose the other redex. The standardisation theorem states
that for those terms the call-by-name reduction is always terminating. We will not
give the proof of this theorem here.
Proposition 4.7 (Standardisation theorem) If t ▷∗t′ and t′ is irreducible, then
t ≻∗t′.
As a consequence of the standardisation theorem we deduce that if a term is
non-terminating under call by name, then it is non-terminating in general. We can
therefore consider only call-by-name reductions and give alternative deﬁnitions of
irreducibility, termination and the representation of functions.
Proposition 4.8
– A term is irreducible if and only if it cannot be reduced by the relation ≻.
– A term t is terminating if and only if there exists an irreducible term t′ such that
t ≻∗t′.
– A lambda-term F represents a function f from natural numbers to natural num-
bers if and only if for any tuple of natural numbers p1,...,pn
– if f (p1,...,pn) = q, then (F p1 ... pn) ≻∗q,
– if f is undeﬁned for p1,...,pn, then the term (F p1 ... pn) is non-terminating
under call by name.
Using call by name reduction we are back in the framework deﬁned in the intro-
duction to this chapter. A program is a lambda-calculus term; the term consisting
of a program F and the natural numbers p1,...,pn is simply (F p1 ... pn) and a
basic computation step corresponds to a reduction under call by name.

4.2
The Lambda-Calculus
85
We will now prove that all the computable functions can be represented in the
lambda-calculus. The representation of a natural number p by the term p, originally
motivated by the need to represent functions deﬁned using recursion, provides a new
answer to the question: what is a natural number? Instead of saying that the natural
number 3 is the property that all the sets with three elements share, which leads to
a deﬁnition of natural numbers as cardinals, we answer the question by saying that
the natural number 3 is an algorithm that iterates three times a function. This leads
us to the deﬁnition
3 = fun x →fun f →(f (f (f x)))
and more generally, to the following deﬁnition.
Deﬁnition 4.25 (Church numerals) The term p is deﬁned as
p = fun x →fun f →(f (f ... (f



p times
x)...))
If the term t is the Church numeral p and u and v are arbitrary terms, then
the term (t u v) reduces in two steps under call by name to the term w =
(v (v ... (v u)...)), where the term v occurs p times. However, if t reduces to
p under call by name but is not equal to p, we cannot prove that (t u v) reduces to
the term (v (v ... (v u)...)). This is because when we reduce (t u v) under call by
name, after reducing the term t to a term of the form fun, the priority redex is no
longer in t but at the root. However, we can prove that if the term t reduces to p then
the term (t u v) is in the set Iu,v
p ; the family of sets (Iu,v
p )p is deﬁned by induction
on p as follows.
Deﬁnition 4.26 The set Iu,v
0
is the set of terms that reduce to u under call by name,
and the set Iu,v
p+1 is the set of terms that reduce under call by name to a term of the
form (v w) where w ∈Iu,v
p .
Proposition 4.9 If the term t reduces to p under call by name then the term (t u v)
is in Iu,v
p .
Proof We show a more general property: there exists a term w in Iu,v
p
such that
the term (t u v) reduces to w under call by name in two steps. This is proved by a
double induction on p and on the length of the reduction from t to p.
If t = p then the term (t u v) reduces in two steps, under call by name, to the
term w = (v (v ... (v u)...)) with p occurrences of the term v, which is in Iu,v
p .
Otherwise, there exists a term t′ such that t ≻t′ and t′ reduces to p under call by
name with a shorter reduction. The case where the term t is not of the form fun is
easy because in this case the term (t u v) reduces to (t′ u v) under call by name and
the result follows directly by induction.
However, if t is of the form fun, more precisely, fun y1 →... fun yn →t1 where
t1 is not a term of the form fun and n ̸= 0, then since t reduces to a Church numeral

86
4
Computation as a Sequence of Small Steps
we have n = 1 or n = 2. Let us write t1 = (r s1 ... sm) where r is not an application.
The term r is either a variable or a term of the form fun.
If the term r is a variable, then the term t reduces to a Church numeral, but
since it is not irreducible, then n = 2, r = y2, m = 1. The term (t u v) is therefore
equal to ((fun y1 →fun y2 →(y2 s1)) u v) and reduces under call by name in
two steps to the term w = (v (u/y1,v/y2)s1). Deﬁne w′ = (u/y1,v/y2)s1. The
term fun y1 →fun y2 →s1 reduces to p −1 under call by name, and the term
((fun y1 →fun y2 →s1) u v) reduces to w′ under call by name in two steps. By
induction hypothesis, the term w′ is in Iu,v
p−1 and therefore w is in Iu,v
p .
If the term r is of the form fun z →r′, then t1 = ((fun z →r′) s1 ... sm)
and since this term is not of the form fun, m ̸= 0. The term t is thus of the
form fun y1 →fun y2 →... fun yn →((fun z →r′) s1 s2 ... sm) and the
term t′ obtained by one step of call by name reduction is fun y1 →fun y2 →
... fun yn →((s1/z)r′ s2 ... sm). If n = 1, the term (t′ u v) is equal to
((fun y1 →((s1/z)r′ s2 ... sm)) u v) and reduces in one step under call by name
to w = (((u/y1,(u/y1)s1/z)r′ (u/y1)s2 ... (u/y1)sm) v). By induction hypoth-
esis, this term is in Iu,v
p . The term (t u v) is equal to ((fun y1 →((fun z →
r′) s1 ... sm)) u v); it reduces in two steps under call by name to w, and we
have already proved that w is in Iu,v
p . If n = 2, the term (t′ u v) is equal to
((fun y1 →fun y2 →((s1/z)r′ s2 ... sm)) u v); it reduces in two steps under call by
name to b = ((u/y1,v/y2,(u/y1,v/y2)s1/z)r′ (u/y1,v/y2)s2 ...(u/y1,v/y2)sm).
By induction hypothesis, this term is in Iu,v
p . The term (t u v) is equal to ((fun y1 →
fun y2 →((fun z →r′) s1 ... sm)) u v); it reduces in three steps under call by name
to b. The term (t u v) reduces therefore in two steps to a term w that reduces to b.
We have already proved that the term b is in Iu,v
p , and so is the term w.
□
Proposition 4.10 If t and u are terms that reduce under call by name to Church
numerals n and p, and x, y and f are variables that do not occur in t and u, then
– the term fun x →fun f →(f (t x f )) reduces to the term n + 1 under call by
name,
– the term fun x →fun f →(t (u x f ) f ) reduces to the term n + p under call by
name,
– the term fun x →fun f →(t x (fun y →(u y f ))) reduces to the term n × p
under call by name,
– the term (t (K 1) T (u (K 0) T )), where K = fun x →fun y →x and T =
fun g →fun h →(h g), reduces to the term χ≤(n,p) under call by name.
Proof We ﬁrst prove an auxiliary lemma, by induction on n: if a term is in Iv,f
n
where f is a variable and v is an arbitrary term, then it reduces under call by name
to (f (f ... (f v)...)) with n occurrences of the symbol f . We then prove the four
propositions.
– The term (t x f ) reduces under call by name to (f (f ... (f x)...)) where the
symbol f occurs n times, the term (f (t x f )) to (f (f ... (f x)...)) where

4.2
The Lambda-Calculus
87
the symbol f occurs n + 1 times, and the term fun x →fun f →(f (t x f )) to
n + 1.
– By Proposition 4.9, the term v = (u x f ) is in Ix,f
p
and the term (t (u x f ) f )
is in Iv,f
p
. Using the lemma above, the term (t (u x f ) f ) reduces under call
by name to (f (f ... (f v)...)) where the symbol f occurs n times, then to
(f (f ... (f x)...)) where the symbol f occurs n + p times. Thus, the term
fun x →fun f →(t (t x f ) f ) reduces under call by name to n + p.
– We show by induction on n that if a term v is in Ix,fun y→(u y f )
n
, then it reduces
under call by name to (f (f ... (f x)...)), where the symbol f occurs n ×
p times. If n = 0, the term v reduces under call by name to x. Otherwise, it
reduces under call by name to ((fun y →(u y f )) v′) and then to (u v′ f ) where
v′ is in Ix,fun y→(u y f )
n−1
. By Proposition 4.9 this term is in Iv′,f
p
and, using the
lemma above, it reduces under call by name to (f (f ... (f v′)...)) where
the symbol f occurs p times. Therefore, by induction hypothesis, it reduces to
(f (f ... (f x)...)) where the symbol f occurs p + (n −1) × p = n × p times.
By Proposition 4.9, the term (t x (fun y →(u y f ))) is in Ix,fun y→(u y f )
n
, and
thus it reduces under call by name to (f (f ... (f x)...)) where the symbol f
occurs n × p times. Hence, the term fun x →fun f →(t x (fun y →(u y f )))
reduces under call by name to n × p.
– We show by induction on n + p that if a is a term in I(K α),T
n
and b a term
in I
(K β),T
p
, then (a b) reduces under call by name to α, if n ≤p, and to β, if
p + 1 ≤n. If n = 0, then the term a reduces under call by name to (K α) and
since this term is not of the form fun, the term (a b) reduces under call by name
to (K α b), which in turn reduces under call by name to α. Otherwise, the term
a reduces under call by name to (T a′), where a′ is an element of I(K α),T
n−1
, and
since this term is not of the form fun, the term (a b) reduces under call by name
to (T a′ b), which in turn reduces under call by name to (b a′). By induction, this
term reduces under call by name to β, if p ≤n −1, that is, if p + 1 ≤n, and to
α, if n ≤p. By Proposition 4.9, the term (t (K 1) T ) is in I(K 1),T
n
and the term
(u (K 0) T ) is in I(K 0),T
p
. The term (t (K 1) T (u (K 0) T )) reduces therefore
to 1, if n ≤p and to 0 otherwise, that is, to χ≤(n,p).
□
Deﬁnition 4.27 (Test) We deﬁne
Ifz(t,u,v) = (t u fun x →v)
where x is a variable that does not occur in v.
Proposition 4.11 Let t, u and v be three lambda-terms such that t reduces under
call by name to a Church numeral p. If p = 0, then Ifz(t,u,v) ≻∗u, and if p ̸= 0,
Ifz(t,u,v) ≻∗v.
Proof By Proposition 4.9.
□

88
4
Computation as a Sequence of Small Steps
As in the case of rewriting, if G is a term representing a function g that is unde-
ﬁned for the argument 4 and H is a term representing the function h, that returns 0
for all its arguments, then the term representing the function h ◦g should be non-
terminating if applied to 4. To achieve this, the function h cannot be represented by
the term fun x →0; as in the case of rewriting, it will be represented by a slightly
more complicated term, which checks that its argument reduces to a Church nu-
meral: fun x →0&x. In a similar way, the function f ◦g will be represented by the
term fun x →(H(G x))&x.
Deﬁnition 4.28 For all terms t and u,
t&u = Ifz(u,t,t) = (u t (fun x →t))
where x is a variable that does not occur in t.
Proposition 4.12 Let t and u be lambda-terms such that u reduces under call by
name to a Church numeral. Then t&u ≻∗t.
Proof By Proposition 4.11.
□
Finally, to represent in the lambda-calculus functions deﬁned by minimisation,
we need a mechanism allowing us to iterate a function and compute the values of
g(0), g(1), g(2), ... until the value 0 is obtained. In order to achieve this, we will
rely on the fact that in the lambda-calculus a function can be applied to itself.
Deﬁnition 4.29 (Fixed point) For any term t,
Yt = ((fun x →(t (x x))) (fun x →(t (x x))))
Proposition 4.13 Yt ≻(t Yt).
Now we are ready to deﬁne a representation in the lambda-calculus for each
computable function.
Deﬁnition 4.30 (Representing computable functions) Let f be a computable func-
tion with n arguments. The lambda-term associated to f is deﬁned by induction
over the deﬁnition of f .
If f is the ith projection, the term associated to it is
fun x1 →... fun xn →((((xi&x1)&...&xi−1)&xi+1)&...&xn)
If f is a zero function, the term associated to it is
fun x1 →... fun xn →((0&x1)&...&xn)
If f is the successor function, the term associated to it is
S = fun n →((fun x →fun f →(f (n x f )))&n)

4.2
The Lambda-Calculus
89
If f is addition, the term associated to it is
fun p →fun q →((fun x →fun f →(p (q x f ) f ))&p&q)
If f is multiplication, the term associated to it is
fun p →fun q →((fun x →fun f →(p x (fun y →(q y f ))))&p&q)
If f is the characteristic function of the ordering relation, the term associated to it is
fun p →fun q →((p (K 1) T (q (K 0) T ))&p&q)
where K = fun x →fun y →x and T = fun g →fun h →(h g).
If f is deﬁned as the composition of the functions h and g1,...,gm, then let
G1,...,Gm and H be the terms associated to these functions, the term associated
to f is
fun x1 →... fun xn →((H (G1 x1 ... xn) ... (Gm x1 ... xn))&x1&...&xn)
If f is deﬁned by minimisation of the function g, then let G be the term associated
to these function and G′ the term fun f →fun x1 →... fun xn →fun xn+1 →
(Ifz((G x1 ... xn xn+1),xn+1,(f x1 ... xn (S xn+1)))), the term associated to f is
fun x1 →... fun xn →((YG′ x1 ... xn 0)&x1&...&xn)
We will now show that these terms represent indeed the computable functions
associated to them.
Proposition 4.14 Let F be the lambda-term associated to the computable function
f and let p1,...,pn be natural numbers such that f (p1,...,pn) = q, then
(F p1 ... pn) ≻∗q
Proof We show a more general property, by induction over the deﬁnition of the
function f : if u1,...,un are terms that reduce under call by name to p1,...,pn,
then (F u1 ... un) ≻∗q.
If f is a projection, a zero function, the successor function, addition, multipli-
cation or the characteristic function of the ordering relation, the property follows
directly from Propositions 4.10 and 4.12.
If f is a function deﬁned by composition using functions h and g1,...,gm, then
there are natural numbers r1,...,rm such that g1(p1,...,pn) = r1,...,gm(p1,...,
pn) = rm and h(r1,...,rm) = q. By Proposition 4.12, the term (F u1 ... un) re-
duces to (H (G1 u1 ... un) ... (Gm u1 ... un)) under call by name. By induction
hypothesis, (G1 u1 ... un) reduces under call by name to r1,...,(Gm u1 ... un)
reduces under call by name to rm and (H (G1 u1 ... un) ... (Gm u1 ... un))
reduces under call by name to q.
If f is a function deﬁned by minimisation of the function g, then for all r strictly
less than q, g(p1,...,pn,r) is different from 0, and g(p1,...,pn,q) = 0. If u
reduces under call by name to a Church numeral r for some r strictly less than q,
then the term (YG′ u1 ... un u) reduces under call by name to
Ifz((G u1 ... un u),u,(YG′ u1 ... un (S u)))

90
4
Computation as a Sequence of Small Steps
By induction hypothesis, (G u1 ... un u) reduces under call by name to a non-
zero Church numeral, and therefore by Proposition 4.11 the term (YG′ u1 ... un u)
reduces under call by name to (YG′ u1 ... un (S u)). Thus, using Proposition 4.12,
the term (F u1 ... un) reduces under call by name to (YG′ u1 ... un 0), then to
(YG′ u1 ... un (S 0)), (YG′ u1 ... un (S (S 0))), ... (YG′ u1 ... un (Sq 0)). Finally,
this term reduces under call by name to
Ifz((G u1 ... un (Sq 0)),(Sq 0),(YG′ u1 ... un (S (Sq 0))))
By induction hypothesis, the term (G u1 ... un (Sq 0)) reduces under call by name
to 0 and therefore by Proposition 4.11, it reduces under call by name to (Sq 0) and
ﬁnally to q.
□
We now need to prove that if F is the lambda-term associated to a com-
putable function f and u1,...,un are terms that reduce under call by name to
Church numerals p1,...,pn such that f is undeﬁned for p1,...,pn, then the term
(F u1 ... un) is non-terminating. Unfortunately, non-termination is a property not
preserved by composition. For example, the term fun f →(f ω) is non-terminating,
but if we apply it to fun x →y we obtain a terminating term. We will therefore show
a stronger property, namely that the term (F u1 ... un) is isolated.
Deﬁnition 4.31 (Isolated term) A term t is isolated, if for any term t′ such that
t ≻∗t′, the term t′ is neither irreducible nor of the form fun.
Proposition 4.15 If t ≻∗u and u is isolated, then so is t.
Proof Let t′ be a term such that t ≻∗t′. Since t reduces under call by name both to
u and t′, either u ≻∗t′ or t′ ≻∗u. In the ﬁrst case, t′ is neither irreducible nor of the
form fun. In the second case, t′ is not irreducible and if it were of the form fun, then
the term u would also be of the form fun, a contradiction since it is isolated.
□
Proposition 4.16 If t is isolated then so are the terms (t u), Ifz(t,u,v) and u&t.
Proof If t is isolated then the sequence of call-by-name reductions t = t0,t1,...
contains only terms that have a redex and are not of the form fun. It follows that the
sequence of reductions starting from (t u) is (t0 u),(t1 u),... Indeed, for all i, ti
has a redex and is not of the form fun, therefore the priority redex in (ti u) is the one
in ti. Hence, (t u) is isolated.
The terms Ifz(t,u,v) and u&t are therefore isolated.
□
Proposition 4.17 Let F be a lambda-term associated to a computable function f .
Let u1,...,un be terms such that each ui reduces to a Church numeral or is isolated.
If at least one of the ui is isolated, then (F u1 ... un) is isolated.
Proof By case analysis: we consider the different cases for the function f , and use
Propositions 4.15 and 4.16 in each case.
□

4.2
The Lambda-Calculus
91
Proposition 4.18 Let F be the lambda-term associated to a computable function f
and p1,...,pn natural numbers such that f is undeﬁned for p1,...,pn. Then the
term (F p1 ... pn) is non-terminating.
Proof We will prove by induction over the deﬁnition of the function f a more gen-
eral property: if u1,...,un are terms that reduce under call by name to the Church
numerals p1,...,pn, then the term (F u1 ... un) is isolated.
The projections, zero functions, successor function, addition, multiplication and
the characteristic function of the ordering relation are total.
If the function f is deﬁned by composition using the functions h and g1,...,gm,
then, by Proposition 4.12, the term (F u1 ... un) reduces under call by name to
(H (G1 u1 ... un) ... (Gm u1 ... un))
and if any of the functions gi is undeﬁned for p1,...,pn, then by induction hypoth-
esis the corresponding term (Gi u1 ... un) are isolated and therefore by Propo-
sition 4.17 so is the term (H (G1 u1 ... un) ... (Gm u1 ... un)). By Proposi-
tion 4.15, the term (F u1 ... un) is also isolated. However, if there are natural
numbers r1,...,rm such that r1 = g1(p1,...,pn),...,rm = gm(p1,...,pn), then
h is undeﬁned for r1,...,rm. The terms (Gi u1 ... un) reduce to ri and by induc-
tion hypothesis the term (H (G1 u1 ... un) ... (Gm u1 ... un)) is isolated. Thus,
by Proposition 4.15, so is the term (F u1 ... un).
If the function f is deﬁned by minimisation of the function g, then if g returns
a non-zero value for (p1,...,pn,0), (p1,...,pn,1), ..., the term (F u1 ... un)
reduces under call by name to (YG′ u1 ... un 0), (YG′ u1 ... un (S 0)), ... and is
therefore isolated.
If the function g returns a non-zero value for (p1,...,pn,0), (p1,...,pn,1), ...,
(p1,...,pn,q −1) and is undeﬁned for (p1,...,pn,q), the term (F u1 ... un) re-
duces under call by name to Ifz((G u1 ... un (Sq 0)),(Sq 0),(YG′ u1 ... un (Sq 0)))
where the term (G u1 ... un (Sq 0)) is isolated. By Proposition 4.16, the term
Ifz((G u1 ... un (Sq 0)),(Sq 0),(YG′ u1 ... un (Sq 0))) is isolated. Therefore, by
Proposition 4.15, so is the term (F u1 ... un).
□
We can ﬁnally conclude.
Theorem 4.2 Every computable function can be represented in the lambda-
calculus.
The converse of this theorem states that all the functions that can be represented
in the lambda-calculus are computable. Indeed, lambda-terms are trees, and there-
fore they can be enumerated. It is sufﬁcient then to show that the function that de-
scribes a basic step of computation, that is the function that associates to t the term
u such that t ≻u, is computable.

92
4
Computation as a Sequence of Small Steps
4.3 Turing Machines
As the lambda-calculus brought the notation of programs closer to that of mathe-
matical functions, it could be said that Turing machines highlight the fact that com-
putations take place not only over time but also in a given space.
A Turing machine consists of a certain number k of tapes. Each tape contains an
inﬁnite number of cells, more precisely, each tape has a ﬁrst cell, followed by an
unlimited number of cells to the right of the ﬁrst one.
Each cell contains a symbol from a ﬁnite set Σ. This set contains, amongst oth-
ers, two distinguished symbols: b (blank) and × (cross). When the machine starts,
only a ﬁnite number of cells in each tape contain a symbol different from b, and this
property is an invariant of the machine. The crosses mark the ﬁrst cell of each tape.
Another ingredient in the deﬁnition of a Turing machine is the reading and writ-
ing head. At each moment in time, the head is in a certain position over the tapes
and in a certain state s (there is a ﬁnite set of states).
The ﬁnal ingredient is the transition table describing the evolution of the ma-
chine. At each computation step, the head reads the contents of the k tapes (in the
current position), and depending on the head’s state and the symbols read, the tran-
sition table speciﬁes a k-tuple of symbols to be written on the tapes, a new state, and
a new position for the head (−1: move to the left, 0: stay in the same position, +1:
move to the right). The head then writes the k symbols, changes state and position,
and performs the next step. The transition table is in fact a function from Σk × S to
Σk × S × {−1,0,+1}. We will assume that the transition table never speciﬁes that
the machine should write or erase a cross, and never speciﬁes a movement towards
the left if the machine has read k crosses.
When the machine starts, the head is always at the leftmost position, that is, over
the ﬁrst cell of each tape, and in a distinguished state, called initial state. There is
another distinguished state called ﬁnal state; if the machine reaches the ﬁnal state,
it stops the computation.
Summarising, a machine is deﬁned by a ﬁnite set Σ of symbols, a natural number
(the number of tapes it has), a ﬁnite set of states that contains two distinguished
states—the initial and ﬁnal states, and a transition table.
How can we compute with such a machine? We will assume that the set of sym-
bols Σ contains, in addition to the symbols b and ×, a symbol | (bar). A function f
from Nn to N will be computed using a machine with at least n + 1 tapes. To com-
pute the value of this function for the arguments p1,...,pn, we start the machine in

4.3
Turing Machines
93
an initial conﬁguration where the ﬁrst tape contains a cross followed by p1 bars, the
second tape contains a cross followed by p2 bars, ..., the nth tape contains a cross
followed by pn bars. All the other tapes contain simply a cross in the ﬁrst cell. The
machine’s head starts in the leftmost position, and in the initial state.
The machine’s execution is deﬁned as a series of small steps. When it stops, the
(n + 1)th tape should contain a cross followed by q bars and all the other tapes
should be as they were when the machine started. The integer q is the result of the
computation: f (p1,...,pn).
The language of Turing machines ﬁts well within the framework deﬁned in the
introduction to this chapter. A function is represented by a natural number k—the
number of tapes—, a set of states, and a transition table. Given a tuple (k,S,M)
and natural numbers p1,...,pn, a term can be built to represent the machine with
k tapes containing the numbers p1,...,pn and the other tapes containing simply a
crosses, with a set S of states and transition table M. The basic step of computation
is a transition, consisting of a reading operation, a writing operation, a change of
state and a movement of the head.
A function is representable by a Turing machine if there exists a machine that
computes it.
Let us deﬁne, for example, a machine to compute the successor of a natural num-
ber. The machine will have two tapes and three states: s0 (initial state), s1 and s2
(ﬁnal state). The machine starts by moving the head towards the right-hand side,
and writing a bar in the second tape for each bar read in the ﬁrst tape. When no
more bars are left, the machine writes a bar in the second tape, changes state, moves
the head towards the left, and moves to the ﬁnal state. The transition table is there-
fore as follows.
M((×,×),s0) = ((×,×),s0,1)
M((|,b),s0) = ((|,|),s0,1)
M((b,b),s0) = ((b,|),s1,−1)
M((|,|),s1) = ((|,|),s1,−1)
M((×,×),s1) = ((×,×),s2,0)
Of course, in order to have a complete deﬁnition of the machine we need to
complete the table so that it speciﬁes what the machine should do in all the other
conﬁgurations. However, since they are not reachable, it does not matter how we
complete the table.
To show that every computable function can be computed using a Turing ma-
chine, we need to show that the set of functions that can be computed using Turing
machines contains the projections, zero functions, successor, addition multiplica-
tion, the characteristic function of the ordering relation, and that it is closed under
composition and minimisation.
We start by showing how to compute the composition of functions, which re-
quires a combination of Turing machines.
First, notice that a machine that computes a function f from Nn to N can be
easily transformed by adding tapes whose contents do not change the evolution of

94
4
Computation as a Sequence of Small Steps
the machine and where the head does not write anything. We can transform it so
that the arguments are read from tapes b1,...,bn that are not necessarily the ﬁrst n
tapes and the result is left on the tape bn+1, which is not necessarily the (n + 1)th
tape.
After this remark, we can show that the set of functions that can be computed
using Turing machines is closed under composition. Let h, g1,...,gm be functions
computed by machines N and M1,...,Mm, respectively. These machines may use,
in addition to the tapes that contain the arguments and the tape where the result is
left, a certain number of auxiliary tapes for intermediate computations. We start by
modifying them so that all the machines work on n + m + 1 + r tapes, where r is
the greatest number of auxiliary tapes used by the machines M1,...,Mn,N, each
machine Mi reads its arguments from the tapes 1,...,n and writes the result on the
tape n+1+i, N reads its arguments from the tapes n+2,...,n+m+1 and writes
its result on the tape n + 1, and the remaining tapes (after the n + m + 1 ﬁrst tapes)
are the auxiliary tapes used by the machines.
We then build a machine whose set of states is the disjoint union of the sets of
states of these m+1 machines and an additional set of states speciﬁc to this machine,
containing an initial state and a ﬁnal state. The transition table is the union of the
tables of all these machines; this is still a function since the tables are functions
with disjoint domains. We add transitions so that when the machine is in the initial
state, it performs a transition to M1’s initial state and when it reaches M1’s ﬁnal
state it performs a transition to M2’s initial state, ..., when it reaches Mm’s ﬁnal
state it performs a transition to N’s initial state, and when it reaches N’s ﬁnal state
it performs a transition to its own ﬁnal state. In this way, we obtain a machine that,
starting in a conﬁguration with the numbers p1,...,pn in the ﬁrst n tapes, computes
q1 = g1(p1,...,pn), q2 = g2(p1,...,pn),...,qm = gm(p1,...,pn) and writes the
results on the tapes n + 2,...,m + n + 1, and ﬁnally computes h(q1,...,qm) and
leaves the result on the n + 1’th tape. It is now easy to modify this machine to erase
the numbers written in the tapes n + 2,...,n + m + 1 and move the head to the
leftmost position; we obtain in this way a machine that computes the composition
of h and g1,...,gm.
The machine to compute a function deﬁned by minimisation is built similarly:
ﬁrst it computes g(p1,...,pn,0), simulating the machine that computes the func-
tion g using the tapes 1,...,n,n + 1 to store the arguments and the tape n + 2 for
the result. If the second cell in the n + 2’th tape is b then the machine moves its
head to the left and reaches a ﬁnal state, otherwise it writes an additional bar on
the n + 1’th tape and re-starts the computation of g reading the arguments from the
tapes 1,...,n,n + 1,....
We have already built a machine to compute the successor function. The ma-
chines that compute projections can be built similarly. The machine that computes
πn
i consists of n + 1 bands; it starts by moving its head to the right and writing a
bar on the n + 1’th tape for each bar found in the i’th tape. When there are no more
bars, it moves the head towards the left and reaches a ﬁnal state.
It is even easier to deﬁne a machine that computes a zero function: it sufﬁces to
move directly from the initial state to the ﬁnal state.

4.3
Turing Machines
95
We now show the construction of a machine to compute addition. This machine
starts by copying the contents of the ﬁrst tape onto the fourth, and the contents of
the second tape onto the third. Then, it erases one by one the bars in the fourth tape,
adding a bar on the third tape for each erased bar.
To build a machine to compute multiplication we proceed as follows. The ma-
chine starts by copying the contents of the ﬁrst tape onto the fourth, then it erases
one by one the bars on the fourth tape, writing on the third tape as many bars as
there are in the second tape. To do this, it is sufﬁcient to copy the contents of the
second tape onto the ﬁfth, and then erase one by one the bars from the ﬁfth tape,
adding each time a bar on the third tape.
The machine that computes the characteristic function of the ordering relation
can be built as follows. While the ﬁrst two tapes contain bars, the machine moves its
head towards the right, if it ﬁnds a conﬁguration (b,|) or (b,b) it changes state to
s, if it ﬁnds the conﬁguration (|,b) it changes state to s′. In both cases, the machine
moves its head to the left. If it is in state s′ it moves to the ﬁnal state, and if it is in
state s it moves the head towards the right and writes a bar on the third tape, then it
moves to the left and reaches a ﬁnal state.
We can now conclude.
Theorem 4.3 Every computable function can be represented by a Turing machine.
The converse of this proposition states that all the functions that can be repre-
sented by a Turing machine are computable. Indeed, there are many ways to repre-
sent, using trees, the state of a Turing machine, more precisely, the contents of its
tapes, the position of the head and its state. For instance, we can represent each state
by a constant, and the elements of Σ can also be represented by constants. The part
of the tapes to the left-hand side of the head can be represented as a list of k-tuples—
the ﬁrst element of the list denotes the k-tuple of symbols that are just to the left of
the head—and, similarly, the right-hand side of the tapes can be represented as a
list of k-tuples—the ﬁrst element of the list denotes the k-tuple of symbols that are
just to the right of the head. Thus, a term is a tuple consisting of three elements: a
state, a k-tuple representing the cells at the current position of the head in the tapes,
and a pair of lists of k-tuples representing the left- and right-hand sides of the tapes.
These states can be indexed; it remains then to show that the function that describes
a basic computation step is computable.
Exercise 4.10 Give a direct proof of the fact that the set of functions that can be
computed using Turing machines is closed under recursive deﬁnitions.
Exercise 4.11 So far we have used the idea that trees can be indexed in order to
prove the existence of algorithms to solve certain problems. However, if instead of
focusing on the existence of an algorithm we want to study its complexity, the use of
tree encodings is not ideal: encodings can change the complexity of the algorithm.
In this exercise we consider Turing machines that compute directly on trees. For
this, we consider a set Σ of symbols containing, in addition to b and ×, an arbitrary

96
4
Computation as a Sequence of Small Steps
number of symbols. We can then represent a tree, from an articulated set, on a tape
using preﬁx or postﬁx notation.
If the ﬁrst tape of a machine contains a sequence u0,u1,... of symbols and the
second contains the number k represented by k bars, the pair of tapes describes a
marked sequence of symbols, that is, the sequence u0,u1,... where the element uk
is marked.
1. Show that there exists a Turing machine that reads a natural number n, repre-
sented by n bars on the ﬁrst tape, and writes 2n bars in the second tape.
2. Show that there exists a Turing machine that reads a natural number n in binary
notation (least signiﬁcative digit ﬁrst) from the ﬁrst tape, starting at the position k
indicated by the number of bars in the second tape, writes n bars on the third tape
and writes additional bars in the second tape until the corresponding position in
the ﬁrst tape is not a binary digit.
3. Show that there exists a Turing machine that reads a sequence of 0 and 1 on the
ﬁrst tape, erases the last two symbols and writes 1 at the end of the sequence
obtained if the two symbols are 1, and 0 otherwise.
Propositional logic is the fragment of predicate logic consisting of all the propo-
sitions built out of predicate symbols without arguments, called proposition sym-
bols, and symbols ⊤, ⊥, ¬, ∧, ∨and ⇒. For example,
P1 ⇒(P0 ∧P2)
is a proposition.
We will use the proposition symbols P0, P1, ..., Pn, and assume that the
indices of the symbols that occur in a proposition are an initial segment of the
set of natural numbers. Propositions will be written on a tape in postﬁx notation
using binary notation for the indices, with the least signiﬁcative digit ﬁrst. Thus,
the proposition shown above is written

4.3
Turing Machines
97
A model for a proposition is a function that associates a truth value 0 or 1 to each
propositional symbol. A model for a proposition can be written on the tape of a
Turing machine, for example, by writing the sequence of truth values associated
to P0, P1, P2,....
4. Show that there exists a Turing machine that reads a proposition symbol Pn writ-
ten on the ﬁrst tape starting from the position k indicated by the number of bars
in the second tape, and a model on the third tape, and writes the truth value of
this proposition symbol in the fourth tape.
5. Show that there exists a Turing machine that reads a proposition from the ﬁrst
tape and a model from the second and writes the truth value of the proposition
on the third tape.
6. Let n be the number of symbols in a proposition. Show that all the indices of
proposition symbols are bounded by n. Show that the length of the representation
of the proposition on a machine tape is a number between n and n(2 + log2(n)).

98
4
Computation as a Sequence of Small Steps
Let E be a set of trees labelled by elements of a ﬁnite set. The set E is in the
class P if there exists a Turing machine that always terminates and such that
– for any tree a, a is in E if and only if the execution of the machine on the tree
a gives the result 1, and
– there exists a polynomial f such that the number of computation steps of the
machine for a tree of size p is bounded by f (p).
7. Show that the set of pairs consisting of a proposition A and a model M such that
A is valid in M is in the class P .
Exercise 4.12 This exercise relies on Exercise 4.11, which should be done prior to
this one.
We extend Turing machines to introduce non determinism. The transition table of
a standard Turing machine speciﬁes, for each pair consisting of a sequence of sym-
bols and a state, a unique transition involving a writing operation, a change of state
and a movement of the head. In contrast, the transition table of a non-deterministic
Turing machine speciﬁes, for each pair, a ﬁnite set of transitions.
The table of a non-deterministic Turing machine is not a function from Σk × S
to Σk × S × {−1,0,+1} but a function that associates to each element in Σk × S a
ﬁnite and non-empty subset of Σk × S × {−1,0,+1}.
The initial conﬁguration of a standard machine determines a unique sequence of
transitions. In contrast, the initial conﬁguration of a non-deterministic machine de-
termines a set of sequences of transitions, where at each step the machine performs
one of the transitions speciﬁed in the table. These different sequences of transitions
may lead to different results. A non-deterministic Turing machine deﬁnes a function
that associates to the trees p1,...,pn a set of trees instead of just a tree.
Let E be a set of trees labelled by elements of a ﬁnite set. The set E is in the
class NP if there exists a non-deterministic Turing machine that always terminates
and such that
– for any tree a, a is in E if and only if one of the sequences of transitions of the
machine starting on the tree a gives the result 1, and
– there exists a polynomial f such that the length of all the sequences of transitions
of these machine on trees of size p are bound by f (p).
Show that the set SAT of all the consistent—also called satisﬁable—propositions,
that is, propositions that have a model, is in the class NP.
The notion of computability is robust, in the sense that the functions that can be
deﬁned in languages as diverse as Turing machines, the lambda-calculus, or term
rewriting, coincide: they are the computable functions.
However, this apparent diversity hides a deep unity: in all these languages the
execution of a computation is deﬁned as a sequence of small steps.

Part III
Proofs and Algorithms


Chapter 5
Church’s Theorem
The design of algorithms to solve mathematical problems, such as the algorithm that
computes the greatest common divisor of two integers, the algorithm that computes
the solution of a linear system of equations, or the algorithm that permits to compute
the primitive of a polynomial function, is an important mathematical activity without
requiring the construction of a proof. Up to which point can the search for a proof
be replaced by the execution of an algorithm? There is a set of results, some positive
and some negative, which provide answers to this question.
In this chapter we describe two results, one negative and one positive, which
show that the set of provable propositions in predicate logic is not decidable, but it
is semi-decidable.
Since propositions are trees, they can be indexed. More precisely, these results
show that the set of all the indices of provable propositions in predicate logic is not
decidable but it is semi-decidable.
5.1 The Notion of Reduction
We start by showing that the set of propositions that are provable in predicate logic
is not decidable. The proof is based on the following idea: it is possible to express
the termination property of a program f by the proposition “The program f is ter-
minating” and therefore, since the termination property is undecidable in general,
so is the provability of propositions of this kind, and thus the provability of proposi-
tions in predicate logic is undecidable in general. But what is the proposition “The
program f is terminating”?
To answer this question we need to associate to each program f a proposition that
is provable if and only if the program f terminates. As we shall see, the function T
that associates to the program f the proposition “The program f is terminating” is
computable. Therefore, if there exists a computable function F that decides whether
a proposition is provable or not, the function F ◦T is computable, contradicting the
theorem of undecidability of the halting problem.
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_5, © Springer-Verlag London Limited 2011
101

102
5
Church’s Theorem
This idea gives rise to a general method to show that a problem is undecidable: it
is sufﬁcient to build an algorithm that reduces the problem in question to a problem
that has already been shown to be undecidable (in this example, the halting prob-
lem). This method can be formulated in an abstract way: since the set of computable
functions is closed under composition, if T is computable and F ◦T is not, then F
is not computable either.
5.2 Representing Programs
Each program f of arity n will be associated to an arithmetic proposition A, with
free variables among x1,...,xn,y, representing the program f . This means that
the proposition (p1/x1,...,pn/xn,q/y)A, where p is the term Sp(0), is provable
if and only if f returns the value q for p1,...,pn. To simplify the notation, the
proposition (t1/x1,...,tn/xn,u/y)A will be written A[t1,...,tn,u].
If f = πn
i , we deﬁne A = (y = xi). If f = Zn, A = (y = 0). If f = Succ, A =
(y = S(x1)). If f = +, A = (y = x1 +x2). If f = ×, A = (y = x1 ×x2). If f = χ≤,
A = (x1 ≤x2 ∧y = 1) ∨(x2 < x1 ∧y = 0) where the proposition x ≤y abbreviates
∃z (z + x = y) and x < y abbreviates S(x) ≤y.
If f = ◦n
m(h,g1,...,gm), we ﬁrst build the propositions B1, ..., Bm and C,
representing the programs g1, ..., gm and h, and then deﬁne
A = ∃w1 ...∃wm (B1[x1,...,xn,w1] ∧··· ∧Bm[x1,...,xn,wm]
∧C[w1,...,wm,y])
Finally, if f = μn(g), we ﬁrst build the proposition B representing the program g
and then deﬁne
A = (∀z (z < y ⇒∃w (B[x1,...,xn,z,S(w)]))) ∧B[x1,...,xn,y,0]
We can prove that f maps p1,...,pn to the value q if and only if the arithmetic
proposition A[p1,...,pn,q] is provable, and conclude that provability in arithmetic
is undecidable.
However, before we prove this property we will extend the deﬁnition given
above. Indeed, this deﬁnition assumes that the language contains the symbols 0,
S, +, × and =, and it also assumes that the domain of discourse is limited to the set
of integers. These two assumptions are correct in the case of arithmetic, but will be
problematic when we try to generalise this result to other theories. For example, we
have seen that in the language of set theory there is no symbol S representing the
successor function, but there is a proposition with two free variables x and y stating
that y is the successor of x
∀z (z ∈y ⇔(z ∈x ∨z = x))
We will assume then that we have an arbitrary language allowing us to build
propositions N, Null, Succ, Plus, Mult and Eq. We will write N[t] for the propo-
sition (t/x)N, Succ[t,u] for the proposition (t/x,u/y)Succ,.... For example, in

5.2
Representing Programs
103
arithmetic, N is the proposition ⊤, Null the proposition x = 0, Succ the proposition
y = S(x), Plus the proposition z = x +y, Mult the proposition z = x ×y and Eq the
proposition x = y. In set theory, the proposition N is the one built in Exercise 1.17,
the proposition Succ is the proposition ∀z (z ∈y ⇔(z ∈x ∨z = x)),... .
The proposition Inf , for the ordering relation, is deﬁned as ∃z (N[z] ∧
Plus[z,x,y]) and InfS, for the strict ordering relation, as ∃x′ (N[x′]∧Succ[x,x′]∧
Inf[x′,y]).
In this language, we can associate a proposition to each program.
Deﬁnition 5.1 (Proposition representing a program) Let f be a program of arity n.
The proposition A representing f is deﬁned by induction over the construction
of f .
– If f = πn
i , then A = Eq[xi,y].
– If f = Zn, then A = Null[y].
– If f = Succ, then A = Succ[x1,y].
– If f = +, then A = Plus[x1,x2,y].
– If f = ×, then A = Mult[x1,x2,y].
– If f = χ≤, then A = (Inf[x1,x2] ∧∃z (Null[z] ∧Succ[z,y])) ∨(InfS[x2,x1] ∧
Null[y]).
– If f = ◦n
m(h,g1,...,gm), and B1,...,Bm and C are the propositions represent-
ing the programs g1, ..., gm and h, then
A = ∃w1 ...∃wm (N[w1] ∧··· ∧N[wm]
∧B1[x1,...,xn,w1] ∧··· ∧Bm[x1,...,xn,wm]
∧C[w1,...,wm,y])
– If f = μn(g), and B is the proposition representing the program g, then
A = (∀z (N[z] ∧InfS[z,y] ⇒∃w∃w′ (N[w′] ∧Succ[w′,w]
∧B[x1,...,xn,z,w]))) ∧(∀w (Null[w] ⇒B[x1,...,xn,y,w]))
We will now prove that f maps p1,...,pn to q if and only if the proposition
A relates the numbers p1,...,pn,q. However, it is not possible to express this
property simply by substituting variables by terms of the form Sp(0) in A—the
symbols 0 and S might not be in the language. Instead, we will deﬁne for each
natural number n a proposition Nn characterising n, more precisely: N0 = Null[x]
and Nn+1 = ∃y (Nn[y] ∧Succ[y,x]). If a proposition A contains a free variable x,
we can state that the property represented by A holds for the number n using the
proposition ∀x (Nn[x] ⇒A).
We can now prove that f associates the value q to p1,...,pn if and only if the
proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Nq[y]) ⇒A[x1,...,xn,y])
is provable. Of course, to prove this proposition we will need to rely on some prop-
erties of the propositions N, Null, Succ, Plus, Mult and Eq. Surprisingly, very few
properties are needed; they are given in the theory T0 below.

104
5
Church’s Theorem
Deﬁnition 5.2 (Theory T0) The theory T0 is composed of the following axioms.
Predicate N:
∀x (Null[x] ⇒N[x])
∀x∀y ((N[x] ∧Succ[x,y]) ⇒N[y])
Existence of natural numbers:
∃x Null[x]
∀x (N[x] ⇒∃y Succ[x,y])
Equality:
∀x Eq[x,x]
∀x∀y (Null[x] ⇒(Null[y] ⇔Eq[x,y]))
∀x∀y∀x′∀y′ ((N[x] ∧Succ[x,x′] ∧Eq[x,y]) ⇒(Succ[y,y′] ⇔Eq[x′,y′]))
Injectivity of successor:
∀x∀y∀x′∀y′ (Succ[x,x′] ∧Succ[y,y′] ∧Eq[x′,y′]) ⇒Eq[x,y])
Zero is not a successor:
∀x∀x′ (Succ[x,x′] ⇒¬Null[x′])
Every natural number is either zero or a successor:
∀x (N[x] ⇒(Null[x] ∨∃y (N[y] ∧Succ[y,x])))
Addition:
∀x∀y∀z ((Null[x] ∧N[y]) ⇒(Eq[y,z] ⇔Plus[x,y,z]))
∀x∀y∀z∀x′∀z′ ((N[x] ∧N[y] ∧Plus[x,y,z] ∧Succ[x,x′])
⇒(Succ[z,z′] ⇔Plus[x′,y,z′]))
∀x∀y∀x′∀y′ ((N[x] ∧N[y] ∧Succ[x,x′] ∧Succ[z,z′] ∧Plus[x′,y,z′])
⇒Plus[x,y,z])
∀x∀y∀y′∀z′ ((N[x] ∧N[y] ∧N[y′] ∧Succ[y,y′] ∧Plus[x,y′,z′])
⇒∃z (Plus[x,y,z] ∧Succ[z,z′]))
Multiplication:
∀x∀y∀z ((Null[x] ∧N[y]) ⇒(Null[z] ⇔Mult[x,y,z]))
∀x∀y∀z∀x′∀z′ ((N[x] ∧N[y] ∧Mult[x,y,z] ∧Succ[x,x′])
⇒(Plus[y,z,z′] ⇔Mult[x′,y,z′])

5.2
Representing Programs
105
Proposition 5.1 The following propositions are provable in the theory T0.
1. ∀x (Np[x] ⇒N[x])
2. ∃x Np[x]
3. ∀x∀y (Np[x] ⇒(Np[y] ⇔Eq[x,y]))
4. ∀x∀y∀z ((Np[x] ∧Nq[y]) ⇒(Np+q[z] ⇔Plus[x,y,z]))
5. ∀x∀y∀z ((Np[x] ∧Nq[y]) ⇒(Np×q[z] ⇔Mult[x,y,z]))
6. ∀x1∀x2 ((Np1[x1] ∧Np2[x2]) ⇒Inf[x1,x2]), où p1 ≤p2
7. ∀x1∀x2 ((Np1[x1] ∧Np2[x2]) ⇒InfS[x1,x2]), où p1 < p2
8. ∀x∀y∀y′ ((N[x] ∧Inf[x,y′] ∧Succ[y,y′]) ⇒(Eq[x,y′] ∨Inf[x,y]))
9. ∀x∀y∀y′ ((N[x] ∧InfS[x,y′] ∧Succ[y,y′]) ⇒(Eq[x,y] ∨InfS[x,y]))
10. ∀x∀y ((N[x] ∧InfS[x,y]) ⇒¬Null[y])
Proof
1. By induction on p, using the axioms for the predicate N.
2. By induction on p, using the axioms stating the existence of natural numbers
and (1.).
3. By induction on p, using the equality axioms and (1.).
4. By induction on p, using the ﬁrst two axioms of addition, (1.), (2.) and (3.).
5. By induction on p, using the axioms of multiplication, (1.), (2.) and (4.).
6. Since p1 ≤p2, there exists a natural number q such that q + p1 = p2. From
the assumptions Nq[z], Np1[x1] and Np2[x2] we can deduce the propositions
N[z] and Plus[z,x1,x2] using (1.) and (4.). Therefore Inf[x1,x2]. We can now
eliminate the assumption Nq[z] using (2.).
7. Since p1 < p2, we have p1 + 1 ≤p2. From the assumptions Np1[x1],
Succ[x1,w] and Np2[x2] we can deduce Np1+1[w] and then, using (1.) and (6.),
the propositions N[w] and Inf[w,x2] and hence InfS[x1,x2]. We can now elim-
inate the assumption Succ[x1,w] using ∃w Succ[x1,w], which can be proved
using the second axiom of existence of natural numbers.
8. The proposition Inf[x,y′] is ∃z′ (N[z′] ∧Plus[z′,x,y′]). We use the axiom
Every natural number is either zero or a successor to distinguish two cases: z′
equal to zero and z′ equal to the successor of a number z. In the ﬁrst case, the
ﬁrst axiom of addition implies Eq[x,y′]. In the second case, the third axiom of
addition implies Plus[z,x,y] and therefore Inf[x,y].
9. Consequence of (8.) and the axiom Injectivity of successor.
10. Consequence of the fourth axiom of addition and the axiom Zero is not a suc-
cessor.
□
Proposition 5.2 Let A be a proposition. We denote by A[t] the proposition (t/x)A.
If the propositions ∀x (N0[x] ⇒A[x]),∀x (N1[x] ⇒A[x]),...,∀x (Np−1[x] ⇒
A[x]) are provable in the theory T0, then so is the proposition ∀x∀y ((N[x] ∧
Np[y] ∧InfS[x,y]) ⇒A[x]).
Proof By induction on p using Proposition 5.1(9.).
□

106
5
Church’s Theorem
Deﬁnition 5.3 (N-model) Let L be a language and let N, Null, Succ, Plus, Mult be
propositions in L. A model M of this language is a N-model if
{a ∈M | JNKx=a = 1} = N
{a ∈N | JNullKx=a = 1} = {0}
{(a,b) ∈N2 | JSuccKx=a,y=b = 1} = {(a,b) ∈N2 | b = a + 1}
{(a,b,c) ∈N3 | JPlusKx=a,y=b,z=c = 1} = {(a,b,c) ∈N3 | c = a + b}
{(a,b,c) ∈N3 | JMultKx=a,y=b,z=c = 1} = {(a,b,c) ∈N3 | c = a × b}
{(a,b) ∈N2 | JEqKx=a,y=b = 1} = {(a,b) ∈N2 | a = b}
If T is a theory in the language L, an N-model of T is a N-model of L that is
also a model of T .
The axioms of the theory T0 are valid in all the N-models.
We can now prove the following proposition.
Proposition 5.3 Let L be a language, and N, Null, Succ, Plus, Mult and Eq propo-
sitions in the language L. Let T be a theory in L such that all the axioms of the
theory T0 are provable in T , and T has an N-model M. If f is a program and A a
proposition representing f , the following three propositions are equivalent
– f gives the value q for p1,...,pn,
– the proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Nq[y]) ⇒A[x1,...,xn,y])
is provable in the theory T ,
– this proposition is valid in the model M.
Proof Assuming that f gives the value q for p1,...,pn, we show by induction over
the structure of f that the proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Nq[y]) ⇒A[x1,...,xn,y])
is provable in T .
– If f = πn
i then A = Eq[y,xi] and the proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Npi[y]) ⇒Eq[xi,y])
is a consequence of Proposition 5.1(3.). We proceed in the same way for the
programs zero, successor, addition and multiplication, using Proposition 5.1(4.)
and (5.).

5.2
Representing Programs
107
– If f = χ≤, and p1 ≤p2, then by Proposition 5.1(6.), the proposition Inf[x1,x2]
is provable under the assumptions Np1[x1] and Np2[x2]. The proposition
∃z′ (Null[z′] ∧Succ[z′,y]) is provable under the assumption N1[y] and there-
fore the proposition A is provable assuming Np1[x1], Np2[x2] and N1[y]. We
proceed in the same way if p2 < p1, using Proposition 5.1(7.).
– If f = ◦n
m(h,g1,...,gm), then, since f is terminating for (p1,...,pn), g1, ...,
gm are terminating for (p1,...,pn), and if we call ri the number gi(p1,...,pn),
h is terminating for r1,...,rm and q = h(r1,...,rm). Let B1,...,Bm and C
be the propositions representing the programs g1,...,gm and h. By induction
hypothesis, under the assumptions Np1[x1],...,Npn[xn], Nr1[w1],...,Nrm[wm]
and Nq[y], the propositions B1[x1,...,xn,w1],...,Bm[x1,...,xn,wm] and
C[w1,...,wm,y] are provable, and by Proposition 5.1(1.), under the same
assumptions the propositions N[w1],...,N[wn] are provable. As a conse-
quence, the proposition A is provable. We can eliminate the assumptions
Nr1[w1],...,Nrm[wm] using Proposition 5.1(2.).
– If f = μn(g) then, since f is terminating for (p1,...,pn) and gives the value
q, g is terminating for (p1,...,pn,0),...,(p1,...,pn,q −1) and gives a value
which is not zero, and g is deﬁned for (p1,...,pn,q) and gives the value 0.
Therefore, there are numbers r0,...,rq−1 such that g(p1,...,pn,0) = r0 +
1,...,g(p1,...,pn,q −1) = rq−1 + 1.
Let B be the proposition representing the program g. By induction hypothesis,
under the assumptions Np1[x1],...,Npn[xn] and Nq[y], the propositions
∀v∀w ((Ni[v] ∧Nri+1[w]) ⇒B[x1,...,xn,v,w])
are provable for any i between 0 and q −1. Using Proposition 5.1(1.) and (2.),
we can deduce that the proposition
∀v (Ni[v] ⇒∃w∃w′ (N[w′] ∧Succ[w′,w] ∧B[x1,...,xn,v,w]))
is provable. Using Proposition 5.2, we can deduce that the proposition
∀v (InfS[v,y] ⇒∃w∃w′ (N[w′] ∧Succ[w′,w] ∧B[x1,...,xn,v,w]))
is provable, and, similarly, the proposition
∀w (Null[w] ⇒B[x1,...,xn,y,w])
is provable. We conclude that the proposition A is provable.
Since the model M is a model of the theory T , if the proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Nq[y]) ⇒A[x1,...,xn,y])
is provable in T then it is valid in the model M.
Finally, if the proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Nq[y]) ⇒A[x1,...,xn,y])

108
5
Church’s Theorem
is valid in M, there are numbers p1,...,pn,q such that
JA[x1,...,xn,y]Kx1=p1,...,xn=pn,y=q = 1
and, using the fact that M is an N-model, we can show by induction over the struc-
ture of f that f gives the value q for p1,...,pn.
□
5.3 Church’s Theorem
Deﬁnition 5.4 Let f be a program and A the proposition representing it. The propo-
sition “The program f is terminating for p1,...,pn” corresponds to the closed
proposition
∀x1 ...∀xn ((Np1[x1] ∧··· ∧Npn[xn]) ⇒∃y (N[y] ∧A[x1,...,xn,y]))
Proposition 5.4 Let L be a language, N, Null, Succ, Plus, Mult and Eq proposi-
tions in L, and T a theory in L such that the axioms of the theory T0 are provable
in T and T has an N-model M. If f is a program, the following three propositions
are equivalent.
– the program f is terminating for p1,...,pn,
– the proposition “The program f is terminating for p1,...,pn” is provable in T ,
– this proposition is valid in M.
Proof If the program f terminates for p1,...,pn then there exists a number q such
that f gives the value q for p1,...,pn. By Proposition 5.3, the proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Nq[y]) ⇒A[x1,...,xn,y])
is provable in T . Therefore, by Proposition 5.1(1.) and (2.), the proposition
∀x1 ...∀xn ((Np1[x1] ∧··· ∧Npn[xn]) ⇒∃y (N[y] ∧A[x1,...,xn,y])) is provable
in T .
Since the model M is a model of the theory T , if this proposition is provable in
T then it is valid in the model M.
Finally, if this proposition is valid in M, there exists a natural number q such
that
JA[x1,...,xn,y]Kx1=p1,...,xn=pn,y=q = 1
The proposition
∀x1 ...∀xn∀y ((Np1[x1] ∧··· ∧Npn[xn] ∧Nq[y]) ⇒A[x1,...,xn,y])
is therefore valid in M. By Proposition 5.3, f gives the value q for p1,...,pn and
is therefore terminating for p1,...,pn.
□
Proposition 5.5 The function T that maps

5.3
Church’s Theorem
109
– the index of a program f and p1,...,pn to the index of the proposition “The
program f is terminating for p1,...,pn”, and
– all the numbers that are not indices of a program to the value 0
is computable.
Proof The function T is deﬁned by well-founded induction.
□
We have thus a ﬁrst undecidability result for provability.
Proposition 5.6 Let L be a language, N, Null, Succ, Plus, Mult and Eq proposi-
tions in the language L and T a theory in the language L such that the axioms of the
theory T0 are provable and it has an N-model. Then the set of closed propositions
in L that are provable in T is undecidable.
Proof If there exists a computable function F that maps the index of a proposition
to 1 or 0 depending on whether the proposition is provable in T or not, then the
function F ◦T is computable. This contradicts the theorem of undecidability of the
halting problem.
□
We now generalise the result by dropping the assumption that the axioms of the
theory T0 can be proved in the theory T .
Proposition 5.7 Let L be a language, N, Null, Succ, Plus, Mult and Eq propo-
sitions in L and T a theory in L that has an N-model. Then, the set of closed
propositions in L that are provable in T is undecidable.
Proof The theory T ∪T0 can prove the axioms of T0 and has an N-model. By
Proposition 5.6, provability in this theory is undecidable.
We use again a reduction: let H be the conjunction of all the axioms of the
theory T0. The proposition H ⇒A is provable in the theory T if and only if the
proposition A is provable in the theory T ∪T0. Let T be the function that asso-
ciates the index of the proposition H ⇒A to the index of the proposition A. The
function T is computable and the proposition with index T (⌜A⌝) is provable in the
theory T if and only if the proposition A is provable in T ∪T0. If there exists a de-
cision algorithm F for the theory T , then F ◦T is a decision algorithm for T ∪T0,
contradicting the fact that T ∪T0 is undecidable.
□
Proposition 5.8 Let L be a language and N, Null, Succ, Plus, Mult and Eq propo-
sitions in L. If L has an N-model then the set of closed propositions in L that are
provable in the empty theory is undecidable.
Proof Consequence of Proposition 5.7, taking T = ∅.
□
Theorem 5.1 (Undecidability of arithmetic) The set of closed propositions that
are provable in arithmetic, or in any extension of arithmetic that has the model
(N,0,x →x + 1,+,×,=), is undecidable.

110
5
Church’s Theorem
Proof Deﬁne N = ⊤, Null = (x = 0), Succ = (y = S(x)), Plus = (z = x + y),
Mult = (z = x × y) and Eq = (x = y). The model N is an N-model. We can there-
fore apply Proposition 5.7.
□
This theorem can be generalised for any consistent extension of arithmetic, that
is, any extension of arithmetic that has a model (whether this model is N or not). In
this way, it is possible to prove the undecidability of exotic extensions of arithmetic
such as the ones that we built in the proof of Löwenheim-Skolem’s theorem, which
are consistent although N is not a model for them. We will not present this proof
here, but it is important to note that this result does not extend to extensions of arith-
metic that are contradictory. If we add for instance the axiom ⊥then all propositions
become provable and the theory is trivially decidable.
Theorem 5.2 (Church) Consider a language containing at least one binary predi-
cate symbol. The set of closed propositions in this language that are provable in the
empty theory is undecidable.
Proof We show that we can deﬁne the propositions N, Null, Succ, Plus, Mult and
Eq and an N-model M for the language, and the result follows from Proposition 5.8.
Let M = N ⊎(N × N) and ˆR = {(a,(a,b)) | a ∈N,b ∈N} ∪{((a,b),b) | a ∈N,
b ∈N} ∪{((a,b),(a + b,a × b)) | a ∈N,b ∈N}. We deﬁne the propositions
Eq = ∀z (x R z ⇔y R z)
N = ∃y1∃y2∃y3 (¬Eq[y1,y2] ∧¬Eq[y1,y3] ∧¬Eq[y2,y2]
∧x R y1 ∧x R y2 ∧x R y3)
Plus = N[x] ∧N[y] ∧N[z] ∧∃w∃w′ (x R w ∧w R y ∧w R w′ ∧z R w′)
Mult = N[x] ∧N[y] ∧N[z] ∧∃w∃w′ (x R w ∧w R y ∧w R w′ ∧w′ R z)
Null = N[x] ∧∀y (N[y] ⇒Plus[x,y,y])
One = N[x] ∧∀y (N[y] ⇒Mult[x,y,y])
Succ = ∃u (One[u] ∧Plus[x,u,y])
It is easy to show that JEq[x,y]Kx=u,y=v = 1 if and only if u = v by considering
ﬁrst the case where u is a number and then the case where it is a pair, and also that
JN[x]Kx=u = 1 if and only if u is a number, JPlus[x,y,z]Kx=p,y=q,z=r = 1 if and
only if p, q and r are numbers and p +q = r, JMult[x,y,z]Kx=p,y=q,z=r = 1 if and
only if p, q and r are numbers and p×q = r, JNull[x]Kx=p = 1 if and only if p = 0,
and JSucc[x,y]Kx=p,y=q = 1 if and only if p and q are numbers and p + 1 = q. □
If the language L contains a predicate of arity n, with n ≥2, the construction
of an N-model is easy to generalise. A language that contains at least one unary

5.4
Semi-decidability
111
predicate symbol P and a function symbol f of arity n ≥2 is also undecidable,
since using a unary predicate symbol P and an n-ary function symbol f we can
build the proposition P(f (x1,...,xn)) that simulates an n-ary predicate symbol.
The only remaining cases are the case where all predicate symbols have arity
zero—then it does not matter which function symbols we have, since they cannot
be used in the propositions—and the case where all function and predicate symbols
are at most unary. In both cases provability is decidable.
Church’s theorem highlights the huge leap in power introduced by G. Frege with
the use of binary predicates. All the previous logics—the logic of syllogisms deﬁned
by Aristotle, ...—where all symbols were at most unary—Man, Mortal, ...—are
decidable.
Note that although provability in predicate logic is undecidable if the language
contains at least one binary predicate symbol, it might become decidable if we add
axioms. For instance, it becomes trivially decidable if we add the axiom ⊥to make
the theory contradictory. It is also decidable if we add the axiom ∀x∀y (x R y)
which is consistent. Church’s theorem does not preclude research on algorithms for
speciﬁc theories a priori, even if the theories use binary predicate symbols, provided
that they do not have an N-model. For example, A. Tarski proved that elementary ge-
ometry is decidable, although it uses several binary predicates. We will see another
example of a decidable theory in Chap. 7.
We ﬁnish this section with a generalisation of the undecidability theorem for
arithmetic. We have already seen that when we have a program f and natural num-
bers p1,...,pn, we can build a closed proposition in arithmetic that is provable if
and only if the program f terminates for p1,...,pn. In 1970, Y. Matiyasevich built
a proposition of the form ∃z1 ...∃zm (t = u) for this purpose. As a consequence,
we can deduce that the set of propositions of the form ∃z1 ...∃zm (t = u) that are
provable in arithmetic is undecidable. Such a proposition states the existence of an
integer solution for the polynomial equation t = u where all the coefﬁcients are also
integers. This means that no algorithm can decide whether a polynomial equation
with integer coefﬁcients has an integer solution. This result solved negatively one of
the problems posed by D. Hilbert in 1900, known as Hilbert’s tenth problem: ﬁnd
an algorithm to decide whether a polynomial equation with integer coefﬁcients has
an integer solution or not. Building a proposition of the form ∃z1 ...∃zm (t = u)
is not easy: although a link between Church’s theorem and a negative solution to
Hilbert’s tenth problem had been suggested by M. Davis in 1953 (he had proposed a
ﬁrst simpliﬁcation for propositions representing programs), it was only in 1970 that
this result was proved, by Matiyasevich.
5.4 Semi-decidability
The set of provable propositions is undecidable for predicate logic, but the deduction
rules are effective. By Proposition 3.14, this means that the set of provable propo-
sitions is semi-decidable. This result holds for all the theories that have a ﬁnite

112
5
Church’s Theorem
number of axioms, and can be generalised to all the theories that have a decidable
set of axioms.
We give here the proof of this proposition starting from Proposition 3.13, which
paves the way for Proposition 5.10.
Proposition 5.9 Let T be a theory with a decidable set of axioms. The set of all the
propositions that are provable in T is semi-decidable.
Proof Since the deduction rules are effective, by Proposition 3.13 the set of proofs
is decidable. Since the set of axioms of the theory T is decidable, we can deﬁne a
computable function g that takes as arguments the index of a tree π and the index
of a proposition A, and checks that π is a well-formed proof and that its root is a
sequent Γ ⊢B such that B = A and such that all the elements of Γ are axioms in T .
The function h such that h(A) is the least natural number π such that 1 ˙−g(π,A) =
0 composed with the constant function 1 is a semi-decision algorithm for the set of
provable propositions in T . If A is provable in T , then h(A) = 1, otherwise h is
undeﬁned for A.
□
We have shown that the set of proofs is decidable, and the set of provable proposi-
tions is semi-decidable. These two results gave rise to two kinds of programs: proof
veriﬁcation programs and programs for automated theorem proving. The ﬁrst kind
of program takes as argument a tree π, and indicates whether π is a well-formed
proof or not (this kind of program always terminates). The second kind of program
takes as argument a proposition A and tries to ﬁnd a proof π for A. If the propo-
sition is not provable, this search may continue forever. We will see an example of
this kind of program in Chap. 6.
5.5 Gödel’s First Incompleteness Theorem
The deﬁnitions of the functions g and h in the proof of Proposition 5.9 could be
modiﬁed. Instead of the function h, we could deﬁne a function h′ that searches
simultaneously for proofs of the proposition A and the proposition ¬A in the the-
ory T , and returns 1 or 0 depending on which proof it ﬁnds. Since each of the
propositions can be provable or not provable, there are four different cases:
1. both A and ¬A are provable propositions,
2. the proposition A is provable but ¬A is not,
3. the proposition ¬A is provable but A is not,
4. neither A nor ¬A is provable.
If we assume that the theory T is consistent, case (1.) is not possible. In case (2.),
h′(A) = 1, in case (3.), h′(A) = 0 and in case (4.) h′ is undeﬁned for A.
It is easy to ﬁnd examples of propositions that satisfy case (2.) and also proposi-
tions that satisfy case (3.), but it is less clear whether there exists a proposition that

5.5
Gödel’s First Incompleteness Theorem
113
satisﬁes case (4.). Is there a proposition A such that neither A nor ¬A is provable in
the theory T ?
We show by contradiction that the answer to this question is positive for all the
theories in which the set of provable propositions is undecidable: if there exists
no proposition satisfying case (4.), the function h′ deﬁnes a decision algorithm for
provability in the theory T , contradicting our assumption that such an algorithm
does not exist.
Deﬁnition 5.5 (Complete theory) Let L be a language. A theory T in L is complete
if for each closed proposition A in L, either A is provable in T or ¬A is provable
in T .
Proposition 5.10 Let L be a language, N, Null, Succ, Plus, Mult and Eq propo-
sitions in L, and T a theory with a decidable set of axioms and an N-model. The
theory T is incomplete: there exists a closed proposition G such that neither G nor
¬G is provable in this theory.
Proof Let g be the computable function that associates to the index of a tree π and
the index of a closed proposition A the value 1 if π is a well-formed proof where
the root is a sequent Γ ⊢B such that B = A and all the elements of Γ are axioms
in T , and the value 0 otherwise. Let r be the computable function that associates to
a proof with root Γ ⊢B the proposition B. Let ˆ¬ be the function that associates the
index of the proposition ¬A to the index of the proposition A: ˆ¬(x) = ⌜¬⌝;(x;0).
Let | be the Boolean function or: x | y = x + y ˙−(x × y) and χ= the characteristic
function of equality. Let h1 be the computable function such that h1(A) is the least
natural number π such that 1 ˙−(g(π,A) | g(π, ˆ¬(A))) = 0. Let h′ be the function
h′(A) = χ=(r(h1(A)),A).
If the theory T is complete, h′ is a decision algorithm for provability in T , con-
tradicting Proposition 5.7.
□
Theorem 5.3 (Gödel’s ﬁrst incompleteness theorem) Arithmetic, and all its exten-
sions that have a model (N,0,x →x + 1,+,×,=) and a decidable set of axioms,
are incomplete.
Proof Deﬁne N = ⊤, Null = (x = 0), Succ = (y = S(x)), Plus = (z = x + y),
Mult = (z = x × y) and Eq = (x = y). The set of axioms of the theory is decid-
able and the model N is an N-model of the theory, therefore we can apply Proposi-
tion 5.10.
□
This theorem can be generalised to all consistent extensions of arithmetic, that
is, all the extensions of arithmetic that have a decidable set of axioms and a model,
be it N or not. It is possible to prove in this way the incompleteness of some exotic
extensions of arithmetic that are consistent even though N is not a model. We will
not do it here.
It is important to note that this result does not extend to contradictory extensions
of arithmetic. If we add the axiom ⊥, for instance, then all the propositions become

114
5
Church’s Theorem
provable and therefore the theory is trivially complete. This result does not extend
either to extensions of arithmetic where the set of axioms is undecidable. Thus, the
theory that has as axioms all the propositions that are valid in the model N is a
consistent and complete extension of arithmetic, but by Gödel’s theorem the set of
axioms in this theory is undecidable. Similarly, in the proof of Proposition 2.5, we
showed that any theory T has a consistent and complete extension U, but in general
the set of axioms of this theory is not decidable.
Exercise 5.1 (An example of an undetermined proposition) Proposition 5.10 shows
that there exists a closed proposition G such that neither G nor ¬G is provable in
the theory T , but it does not give us an example. In this exercise we will show how
to build such a proposition.
Let L be a language, N, Null, Succ, Plus, Mult and Eq propositions in L and T a
theory with a decidable set of axioms and with an N-model M. Let T ′ be the theory
T ∪T0.
Let f be the computable function such that f (n,p,q) = 1 if n = ⌜π⌝, p = ⌜A⌝
and the tree π is a proof of the proposition ∀w (Nq[w] ⇒A) in T ′, otherwise
f (n,p,q) = 0.
Let F be the proposition representing a program that implements this function.
We denote by F[t1,t2,t3,u] the proposition (t1/x1,t2/x2,t3/x3,u/y)F .
By Proposition 5.3, the following three propositions are equivalent
– f (n,p,q) = r,
– the proposition
∀x1∀x2∀x3∀y (Nn[x1] ∧Np[x2] ∧Nq[x3] ∧Nr[y] ⇒F[x1,x2,x3,y])
is provable in T ′,
– in the model M, JFKx1=n,x2=p,x3=q,x4=r = 1.
Let T be the proposition
∀x∀y ((N[x] ∧N1[y]) ⇒¬F[x,w,w,y])
m = ⌜T ⌝and G the closed proposition
∀w (Nm[w] ⇒T )
Show that if G is provable in T ′ then
1. JGK = 1,
2. for any natural number n, JFKx1=n,x2=m,x3=m,y=1 = 0,
3. for any n, f (n,m,m) = 0,
4. the proposition ∀w (Nm[w] ⇒T ) is not provable in T ′,
5. the proposition G is not provable in T ′.
Show that the proposition G is not provable in T ′ using the above.
Conclude that the proposition G is not provable in T .
Show that if ¬G is provable in T ′ then

5.5
Gödel’s First Incompleteness Theorem
115
1. J¬GK = 1,
2. there exists a natural number n such that JFKx1=n,x2=m,x3=m,y=1 = 1,
3. there exists a natural number n such that f (n,m,m) = 1,
4. the proposition ∀w (Nm[w] ⇒T ) is provable in T ′,
5. the proposition G is provable in T ′,
6. the theory T ′ is contradictory.
Show that the proposition ¬G is not provable in T ′ using the above.
Conclude that the proposition ¬G is not provable in T .
Exercise 5.2 In this exercise we will admit that Matiyasevich’s theorem holds, that
is, we will assume that the set of provable arithmetic propositions that have the form
∃x1 ...∃xm (t = u) is undecidable.
1. Show that there exists a closed proposition A of the form ∃x1 ...∃xm (t = u)
such that neither A nor ¬A is provable in arithmetic.
2. Show that the proposition ∀x1 ...∀xm ¬(t = u) is not provable.
3. Show that if a is a closed arithmetic term, then there exists an integer n such that
the proposition a = n is provable. Show that if n and p are two integers, then
either the proposition n = p or the proposition ¬(n = p) is provable. Show that
if a and b are two closed arithmetic terms, then the proposition a = b is provable
or the proposition ¬(a = b) is provable.
4. Consider an equation t = u with variables among x1,...,xm, and natural num-
bers p1,...,pm such that the proposition (p1/x1,...,pm/xm)(t = u) is prov-
able. Show that the proposition ∃x1 ...∃xm (t = u) is provable. Show that if
the proposition ∃x1 ...∃xm (t = u) is not provable, then for all p1,...,pm, the
proposition (p1/x1,...,pm/xm)(t = u) is not provable.
5. Show that if the proposition ∃x1 ...∃xm (t = u) is not provable, then for all
p1,...,pm, the proposition (p1/x1,...,pm/xm)¬(t = u) is provable.
6. Show that there exists a proposition A of the form ¬(t = u) with variables among
x1,...,xm such that
– for all p1,...,pm the proposition (p1/x1,...,pm/xm)A is provable,
– the proposition ∀x1 ...∀xm A is not provable.


Chapter 6
Automated Theorem Proving
We have seen in Chap. 5 that provability in predicate logic is not decidable; it is actu-
ally semi-decidable. There exists a computable function f such that f (⌜Γ ⊢Δ⌝) =
1 if the sequent Γ ⊢Δ is provable and f is undeﬁned for ⌜Γ ⊢Δ⌝otherwise. This
function proceeds by enumerating all the numbers, and checking, for each of them,
whether the number corresponds to the index of a proof of Γ ⊢Δ or not. If a proof
exists, its index will eventually come up in the enumeration, otherwise the process
will continue forever.
In this way one can show that provability in predicate logic is semi-decidable,
but this method is too inefﬁcient to be useful in practise. However, the underlying
idea of enumeration and test can lead to less inefﬁcient methods.
6.1 Sequent Calculus
6.1.1 Proof Search in Natural Deduction
We can try to ﬁnd a proof for a given a sequent by enumerating all the rules that can
be applied at each node in the proof tree, starting from the root. For example, if we
search for a proof of the sequent P ⊢Q ⇒(P ∧Q), we start by enumerating the
rules that could be used in the last step of the proof. For instance, one of the options
is ⇒-intro
Γ,A ⊢B,Δ ⇒-intro
Γ ⊢A ⇒B,Δ
and in this case we must have Γ = [P],A = Q,B = P ∧Q and Δ = [ ]. The
premisse of this rule is the sequent P,Q ⊢P ∧Q and we proceed by enumerating
all the rules that could be used in the last step of the proof of this sequent. For
instance, the last rule could be ∧-intro
Γ ⊢A,Δ
Γ ⊢B,Δ ∧-intro
Γ ⊢A ∧B,Δ
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_6, © Springer-Verlag London Limited 2011
117

118
6
Automated Theorem Proving
and in this case we must have Γ = [P,Q],A = P,B = Q and Δ = [ ]. The pre-
misses of this rule are the sequents P,Q ⊢P and P,Q ⊢Q. We look ﬁrst for a
proof of the ﬁrst sequent, by enumerating the rules that could be used in the last
step of the proof. For instance, the last rule could be the axiom rule, concluding the
proof. The same rule proves the second sequent, and we have thus a complete proof
axiom
P,Q ⊢P
axiom
P,Q ⊢Q ∧-intro
P,Q ⊢P ∧Q
⇒-intro
P ⊢Q ⇒(P ∧Q)
If we enumerate all the rules that could be used to prove the sequent P ⊢Q ⇒
(P ∧Q), we can see that the only introduction rule that could apply is ⇒-intro.
Indeed, the rule ∨-intro, for example, can only be applied to propositions of the form
A ∨B and cannot be used to prove an implication. However, any of the elimination
rules could be used, for instance, ∧-elim
Γ ⊢A ∧B,Δ ∧-elim
Γ ⊢A,Δ
Moreover, if we use this rule, the sequent P ⊢Q ⇒(P ∧Q) to be proved suggests
that we should take Γ = [P], A = Q ⇒(P ∧Q) and Δ = [ ], but we have no clue as
to which proposition we should take for B since it does not occur in the conclusion
of the rule. We have to choose a proposition B blindly, and if we make the wrong
choice, we have to keep trying with other propositions; in other words, we have
to enumerate all the possibilities for B. Thus, when we try to prove the sequent
P ∧Q ⊢P , nothing indicates that we should use the rule ∧-elim and choose B = Q
to obtain the proof
axiom
P ∧Q ⊢P ∧Q ∧-elim
P ∧Q ⊢P
6.1.2 Sequent Calculus Rules
In natural deduction, the form of the conclusion guides us in the choice of introduc-
tion rules, but it does not help us choose the right elimination rule. The idea behind
the sequent calculus is to keep the introduction rules of natural deduction, which
will now be called right-hand side rules, and replace the elimination rules by intro-
duction rules for the hypotheses of the sequent: left-hand side rules. For example,
the ∧-elim rule is replaced by the rule
Γ,A,B ⊢Δ ∧-left
Γ,A ∧B ⊢Δ
In this way, the proof for the sequent P ∧Q ⊢P is very different from the natural
deduction proof
axiom
P,Q ⊢P ∧-left
P ∧Q ⊢P

6.1
Sequent Calculus
119
and when we look for a proof of this sequent, the form of the hypothesis P ∧Q
guides us in the choice of left rule.
Each elimination rule in natural deduction is replaced by a left rule
⊥-left
Γ,⊥⊢Δ
Γ,A ⊢Δ Γ,B ⊢Δ ∨-left
Γ,A ∨B ⊢Δ
Γ ⊢A,Δ Γ,B ⊢Δ ⇒-left
Γ,A ⇒B ⊢Δ
Γ ⊢A,Δ ¬-left
Γ,¬A ⊢Δ
Γ,(t/x)A ⊢Δ ∀-left
Γ,∀x A ⊢Δ
Γ,A ⊢Δ
∃-left x not free in Γ,Δ
Γ,∃x A ⊢Δ
We also need to add a contraction rule on the left in order to be able to use the
hypotheses more than once.
As in natural deduction, the rule of the excluded middle can be expressed by a
deduction rule, or, as we have done it here, by the use of sequents with multiple
conclusions.
Finally, to show that the sequent calculus is equivalent to natural deduction we
will add a rule called cut
Γ ⊢A,Δ Γ,A ⊢Δ cut
Γ ⊢Δ
but we will later show that this rule is superﬂuous.
The following deﬁnition summarises the rules.
Deﬁnition 6.1 (Sequent calculus rules)
axiom
Γ,A ⊢A,Δ
Γ ⊢A,Δ Γ,A ⊢Δ cut
Γ ⊢Δ
Γ,A,A ⊢Δ contraction-left
Γ,A ⊢Δ
Γ ⊢A,A,Δ contraction-right
Γ ⊢A,Δ
⊤-right
Γ ⊢⊤,Δ
⊥-left
Γ,⊥⊢Δ
Γ,A,B ⊢Δ ∧-left
Γ,A ∧B ⊢Δ

120
6
Automated Theorem Proving
Γ ⊢A,Δ Γ ⊢B,Δ ∧-right
Γ ⊢A ∧B,Δ
Γ,A ⊢Δ Γ,B ⊢Δ ∨-left
Γ,A ∨B ⊢Δ
Γ ⊢A,B,Δ ∨-right
Γ ⊢A ∨B,Δ
Γ ⊢A,Δ Γ,B ⊢Δ ⇒-left
Γ,A ⇒B ⊢Δ
Γ,A ⊢B,Δ ⇒-right
Γ ⊢A ⇒B,Δ
Γ ⊢A,Δ ¬-left
Γ,¬A ⊢Δ
Γ,A ⊢Δ
¬-right
Γ ⊢¬A,Δ
Γ,(t/x)A ⊢Δ ∀-left
Γ,∀x A ⊢Δ
Γ ⊢A,Δ
∀-right x not free in Γ,Δ
Γ ⊢∀x A,Δ
Γ,A ⊢Δ
∃-left x not free in Γ,Δ
Γ,∃x A ⊢Δ
Γ ⊢(t/x)A,Δ ∃-right
Γ ⊢∃x A,Δ
Natural deduction sequents always have a unique conclusion whereas in system
D′ sequents can have one or several conclusions but they cannot have none. Indeed,
system D′ has rules that transform the conclusion of the sequents, as in natural de-
duction rules: something has to be transformed. In sequent calculus, hypotheses and
conclusions play symmetric roles: a sequent may have no hypothesis, and similarly
it may have no conclusion. Intuitively, the sequent Γ ⊢is simply a variant of the
sequent Γ ⊢⊥. In general, both in system D′ and in sequent calculus, the sequent
Γ ⊢Δ is provable if and only if the sequent Γ ⊢⊥,Δ is provable.
This explains the difference between the rule ¬-right in sequent calculus
Γ,A ⊢Δ ¬-right
Γ ⊢¬A,Δ
where the conclusion of the premisse may be empty when Δ is empty, and the
corresponding rule in system D′
Γ,A ⊢⊥,Δ ¬-intro
Γ ⊢¬A,Δ
6.1.3 Equivalence with Natural Deduction
We will now prove that a sequent Γ ⊢A is provable in natural deduction if and
only if it is provable in sequent calculus. Since we have deﬁned a sequent calculus

6.1
Sequent Calculus
121
where sequents may have multiple conclusions, we will show the equivalence with
the corresponding natural deduction system, namely system D′.
We start by proving a weakening property for sequent calculus, which corre-
sponds to Propositions 1.6 and 1.13.
Proposition 6.1 (Weakening) If the sequent Γ ⊢Δ is provable in sequent calculus
then the sequents Γ,A ⊢Δ and Γ ⊢A,Δ are also provable.
Proof By induction over the structure of the proof of Γ ⊢Δ.
□
Proposition 6.2 If the sequent Γ ⊢A is provable in system D′ then it is provable
in sequent calculus.
Proof We show a more general property: if the sequent Γ ⊢Δ is provable in system
D′, then it is provable in sequent calculus. We proceed by induction on the structure
of the proof for this sequent in system D′.
– If the proof has the form
π
Γ ⊢⊥,Δ′
⊥-elim
Γ ⊢A,Δ′
then, by induction hypothesis and Proposition 6.1, there exists a sequent calculus
proof π′ for the sequent Γ ⊢⊥,A,Δ′. We build the proof
π′
Γ ⊢⊥,A,Δ′
⊥-left
Γ,⊥⊢A,Δ′
cut
Γ ⊢A,Δ′
– If the proof has the form
π
Γ ⊢A ∧B,Δ′
∧-elim
Γ ⊢A,Δ′
then, by induction hypothesis and Proposition 6.1, there exists a sequent calculus
proof π′ for the sequent Γ ⊢A ∧B,A,Δ′. We build the proof
π′
Γ ⊢A ∧B,A,Δ′
axiom
Γ,A,B ⊢A,Δ′
∧-left
Γ,A ∧B ⊢A,Δ′
cut
Γ ⊢A,Δ′
The case for the other rule ∧-elim is similar.
– If the proof has the form
π1
Γ ⊢A ∨B,Δ′
π2
Γ,A ⊢C,Δ′
π3
Γ,B ⊢C,Δ′
∨-elim
Γ ⊢C,Δ′

122
6
Automated Theorem Proving
then, by induction hypothesis and Proposition 6.1, there are proofs π′
1, π′
2 and π′
3
in sequent calculus for the sequents Γ ⊢A ∨B,C,Δ′, Γ,A ⊢C,Δ′ and Γ,B ⊢
C,Δ′, respectively. We build the proof
π′
1
Γ ⊢A ∨B,C,Δ′
π′
2
Γ,A ⊢C,Δ′
π′
3
Γ,B ⊢C,Δ′
∨-left
Γ,A ∨B ⊢C,Δ′
cut
Γ ⊢C,Δ′
– If the proof has the form
π1
Γ ⊢A ⇒B,Δ′
π2
Γ ⊢A,Δ′
⇒-elim
Γ ⊢B,Δ′
then, by induction hypothesis and Proposition 6.1, there are proofs π′
1 and π′
2 in
sequent calculus for the sequents Γ ⊢A ⇒B,B,Δ′ and Γ ⊢A,B,Δ′, respec-
tively. We build the proof
π′
1
Γ ⊢A ⇒B,B,Δ′
π′
2
Γ ⊢A,B,Δ′
axiom
Γ,B ⊢B,Δ′
⇒-left
Γ,A ⇒B ⊢B,Δ′
cut
Γ ⊢B,Δ′
– If the proof has the form
π1
Γ ⊢¬A,Δ′
π2
Γ ⊢A,Δ′
¬-elim
Γ ⊢⊥,Δ′
then, by induction hypothesis and Proposition 6.1, there are proofs π′
1 and π′
2 in
sequent calculus for the sequents Γ ⊢¬A,⊥,Δ′ and Γ ⊢A,⊥,Δ′, respectively.
We build the proof
π′
1
Γ ⊢¬A,⊥,Δ′
π′
2
Γ ⊢A,⊥,Δ′
¬-left
Γ,¬A ⊢⊥,Δ′
cut
Γ ⊢⊥,Δ′
– If the proof has the form
π
Γ ⊢∀x A,Δ′
∀-elim
Γ ⊢(t/x)A,Δ′
then, by induction hypothesis and Proposition 6.1, there exists a proof π′ in se-
quent calculus for the sequent Γ ⊢∀x A,(t/x)A,Δ′. We build the proof
π′
Γ ⊢∀x A,(t/x)A,Δ′
axiom
Γ,(t/x)A ⊢(t/x)A,Δ′
∀-left
Γ,∀x A ⊢(t/x)A,Δ′
cut
Γ ⊢(t/x)A,Δ′

6.1
Sequent Calculus
123
– If the proof has the form
π1
Γ ⊢∃x A,Δ′
π2
Γ,A ⊢B,Δ′
∃-elim
Γ ⊢B,Δ′
then, by induction hypothesis and Proposition 6.1, there are proofs π′
1 and π′
2 in
sequent calculus for the sequents Γ ⊢∃x A,B,Δ′ and Γ,A ⊢B,Δ′. We build
the proof
π′
1
Γ ⊢∃x A,B,Δ′
π′
2
Γ,A ⊢B,Δ′
∃-left
Γ,∃x A ⊢B cut
Γ ⊢B,Δ′
– If the proof has the form
π
Γ,A ⊢⊥,Δ′
¬-intro
Γ ⊢¬A,Δ′
then, by induction hypothesis, there exists a proof π′ in sequent calculus for the
sequent Γ,A ⊢⊥,Δ′. We build the proof
π′
Γ,A ⊢⊥,Δ′
⊥-left
Γ,A,⊥⊢Δ′
cut
Γ,A ⊢Δ′
¬-right
Γ ⊢¬A,Δ′
– If the proof has the form
π
Γ ⊢A,Δ′
∨-intro
Γ ⊢A ∨B,Δ′
then, by induction hypothesis and Proposition 6.1, there exists a proof π′ in se-
quent calculus for the sequent Γ ⊢A,B,Δ′. We build the proof
π′
Γ ⊢A,B,Δ′
∨-right
Γ ⊢A ∨B,Δ′
The case for the other rule ∨-intro is similar.
– The remaining cases are trivial: all the remaining rules in system D′ are also
sequent calculus rules.
□
To show that if the sequent Γ ⊢A is provable in sequent calculus then it is
provable in system D′, we might want to prove that if the sequent Γ ⊢Δ is provable
in sequent calculus then it is provable in system D′. Unfortunately this property does
not hold if Δ is empty. We will show a weaker property: if the sequent Γ ⊢Δ is
provable in sequent calculus, then the sequent Γ ⊢⊥,Δ is provable in system D′.
We will then discard the proposition ⊥when the multiset Δ is a singleton.
We start by proving the following proposition.

124
6
Automated Theorem Proving
Proposition 6.3 If the sequents Γ,A ⊢Δ and Γ ⊢A,Δ are provable in system D′
then so is the sequent Γ ⊢Δ.
Proof We prove a more general property: if the sequents Γ,Σ,A ⊢Δ and Γ ⊢
A,Δ are provable in system D′, then the sequent Γ,Σ ⊢Δ is also provable. We
proceed by induction over the structure of the proof of Γ,Σ,A ⊢Δ. All the cases
are trivial except the one for the axiom. In this case, if the proposition shared by
Γ,Σ,A and Δ is an element of Γ,Σ, the sequent Γ,Σ ⊢Δ is provable using the
rule axiom. If it is A, then, by Proposition 1.13, the sequent Γ,Σ ⊢A,Δ is provable
and since the proposition A is in Δ, the sequent Γ,Σ ⊢Δ is provable using the rule
contraction.
□
Proposition 6.4 If the sequent Γ ⊢A is provable in sequent calculus then it is also
provable in system D′.
Proof We prove that if the sequent Γ ⊢Δ is provable in sequent calculus then
the sequent Γ ⊢⊥,Δ is provable in system D′. The result follows: if the sequent
Γ ⊢⊥,A has a proof π in system D′, then the sequent Γ ⊢A has the proof
π
Γ ⊢⊥,A ⊥-elim
Γ ⊢A,A contraction
Γ ⊢A
We proceed by induction over the structure of the sequent calculus proof for the
sequent Γ ⊢Δ.
– If the proof has the form
π1
Γ ⊢A,Δ
π2
Γ,A ⊢Δ cut
Γ ⊢Δ
then, by induction hypothesis, the sequents Γ ⊢⊥,A,Δ and Γ,A ⊢⊥,Δ are
provable in system D′. Therefore the sequent Γ ⊢⊥,Δ is provable by Proposi-
tion 6.3.
– If the proof has the form
π1
Γ ′,A,A ⊢Δ contraction-left
Γ ′,A ⊢Δ
then, by induction hypothesis, the sequent Γ ′,A,A ⊢⊥,Δ has a proof in system
D′. We show by induction over the structure of this proof that the sequent Γ ′,A ⊢
⊥,Δ has a proof in system D′.
– If the proof has the form
⊥-left
Γ ′,⊥⊢Δ
then, the sequent Γ ′,⊥⊢⊥,Δ is provable in system D′ using the rule axiom.

6.1
Sequent Calculus
125
– If the proof has the form
π
Γ ′,A,B ⊢Δ ∧-left
Γ ′,A ∧B ⊢Δ
then, by induction hypothesis and Proposition 1.13, the sequent Γ ′,A∧B,A,B ⊢
⊥,Δ is provable in system D′. The sequents Γ ′,A∧B,B ⊢A,⊥,Δ and Γ ′,A∧
B ⊢B,⊥,Δ are provable using the rules axiom and ∧-elim. The sequent Γ ′,A∧
B ⊢⊥,Δ is therefore provable, by Proposition 6.3.
– If the proof has the form
π1
Γ ′,A ⊢Δ
π2
Γ ′,B ⊢Δ ∨-left
Γ ′,A ∨B ⊢Δ
then, by induction hypothesis and Proposition 1.13, the sequents Γ ′,A ∨B,A ⊢
⊥,Δ and Γ ′,A ∨B,B ⊢⊥,Δ are provable in system D′. The sequent Γ ′,A ∨
B ⊢⊥,Δ is therefore provable with rules axiom and ∨-elim.
– If the proof has the form
π1
Γ ′ ⊢A,Δ
π2
Γ ′,B ⊢Δ ⇒-left
Γ ′,A ⇒B ⊢Δ
then, by induction hypothesis and Proposition 1.13, the sequents Γ ′,A ⇒B ⊢
⊥,A,B,Δ and Γ ′,A ⇒B,B ⊢⊥,Δ are provable in system D′. The sequent
Γ ′,A,A ⇒B ⊢B,⊥,Δ is provable using rules axiom and ⇒-elim. Hence, by
Proposition 6.3, the sequent Γ ′,A ⇒B ⊢⊥,Δ is provable.
– If the proof has the form
π
Γ ′ ⊢A,Δ ¬-left
Γ ′,¬A ⊢Δ
then, by induction hypothesis and Proposition 1.13, the sequent Γ ′,¬A ⊢
⊥,A,Δ is provable in system D′. The sequent Γ ′,¬A,A ⊢⊥,Δ is provable
using axiom and ¬-elim. Hence, by Proposition 6.3, the sequent Γ ′,¬A ⊢⊥,Δ
is provable.
– If the proof has the form
π
Γ ′,(t/x)A ⊢Δ ∀-left
Γ ′,∀x A ⊢Δ
then, by induction hypothesis and Proposition 1.13, the sequent Γ ′,∀x A,(t/x)A
⊢⊥,Δ is provable in system D′. The sequent Γ ′,∀x A ⊢(t/x)A,⊥,Δ is prov-
able using axiom and ∀-elim. Hence, by Proposition 6.3, the sequent Γ ′,∀x A ⊢
⊥,Δ is provable.

126
6
Automated Theorem Proving
– If the proof has the form
π
Γ ′,A ⊢Δ
∃-left
Γ ′,∃x A ⊢Δ
then, by induction hypothesis and Proposition 1.13, the sequent Γ ′,∃x A,A ⊢
⊥,Δ is provable in system D′. The sequent Γ ′,∃x A ⊢⊥,Δ is provable using
axiom and ∃-elim.
– If the proof has the form
π
Γ,A ⊢Δ′
¬-right
Γ ⊢¬A,Δ′
then, by induction hypothesis, the sequent Γ,A ⊢⊥,Δ′ is provable in system D′.
The sequent Γ ⊢¬A,Δ′ is therefore provable using rule ¬-intro and the sequent
Γ ⊢⊥,¬A,Δ′, by Proposition 1.13.
– If the proof has the form
π
Γ ⊢A,B,Δ′
∨-right
Γ ⊢A ∨B,Δ′
then, by induction hypothesis, the sequent Γ ⊢⊥,A,B,Δ′ is provable in system
D′. The sequent Γ ⊢⊥,A ∨B,Δ′ is therefore provable using rules contraction
and ∨-intro.
– The remaining cases are trivial since all the remaining sequent calculus rules are
also in system D′.
□
Theorem 6.1 The sequent Γ ⊢A is provable in sequent calculus if and only if it is
provable in system D′ if and only if it is provable in natural deduction.
Proof Consequence of Propositions 6.2, 6.4 and 1.12.
□
6.1.4 Cut Elimination
In sequent calculus, all the propositions that occur in premisses of left or right rules
occur also in the conclusions of the rules. This makes proof search easier since there
is no need to make a choice in order to apply a rule. However, the cut rule
Γ ⊢A,Δ Γ,A ⊢Δ cut
Γ ⊢Δ
used to prove the equivalence of sequent calculus and system D′ does not satisfy
this property: the proposition A occurs in the premisses of the rule but not in the
conclusion. Thus, to apply this rule we need to choose a proposition A.
Fortunately, this rule is redundant in sequent calculus, as shown below.

6.1
Sequent Calculus
127
Deﬁnition 6.2 (Sequent calculus without cuts) The sequent calculus without cuts
includes all the rules in Deﬁnition 6.1 except the cut rule.
Obviously, if a sequent Γ ⊢Δ is provable in the sequent calculus without cuts
then it is also provable in the sequent calculus. Our goal now is to prove the converse.
If a sequent Γ ⊢Δ is provable in the sequent calculus, then it is also provable in
the sequent calculus without cuts. For this, it is sufﬁcient to prove the following
property.
Proposition 6.5 If the sequents Γ,A ⊢Δ and Γ ⊢A,Δ are provable in the sequent
calculus without cuts, so is the sequent Γ ⊢Δ.
Proof We will prove a more general property: if the sequents Γ,An ⊢Δ and Γ ′ ⊢
Am,Δ′ have proofs π and π′ in the sequent calculus without cuts, then the sequent
Γ,Γ ′ ⊢Δ,Δ′ has a proof in the sequent calculus without cuts. The proposition we
aim to prove follows from the case n = m = 1, using the contraction rules.
The proof is by a double induction on the number of connectives and quantiﬁers
of the proposition A, and the sum of the sizes of the proofs π and π′.
We consider the last rules in π and π′. In the ﬁrst series of cases these two rules
are applied to a proposition A, in which case n ≥1 and m ≥1.
– If the last rule in π is the axiom rule, then the multiset Δ contains the proposi-
tion A. The sequent Γ ′ ⊢Am,Δ′ has a proof, and by Proposition 6.1, so does the
sequent Γ,Γ ′ ⊢Am,Δ,Δ′. From this proof we can build a proof for the sequent
Γ,Γ ′ ⊢Δ,Δ′ using the rule contraction-right. If the last rule of π′ is the axiom
the proof is similar.
– If the last rule in π or π′ is a contraction rule, we apply the induction hypothesis.
– In the other cases, if the last rule in π is ∧-left, then A = (B ∧C) and the last
rule in π′ is ∧-right. Therefore π is of the form
ρ
Γ,An−1,B,C ⊢Δ ∧-left
Γ,An−1,B ∧C ⊢Δ
and π′ of the form
ρ′
1
Γ ′ ⊢B,Am−1,Δ′
ρ′
2
Γ ′ ⊢C,Am−1,Δ′
∧-right
Γ ′ ⊢B ∧C,Am−1,Δ′
The induction hypothesis applied to π and ρ′
1 ﬁrst, then to π and ρ′
2, and ﬁ-
nally to ρ and π′ produces a proof of Γ,Γ ′ ⊢B,Δ,Δ′, Γ,Γ ′ ⊢C,Δ,Δ′ and
Γ,Γ ′,B,C ⊢Δ,Δ′. The induction hypothesis applied to B and C and the con-
traction rules produce a proof of Γ,Γ ′,C ⊢Δ,Δ′, and then Γ,Γ ′ ⊢Δ,Δ′.
– If the last rule in π is ∨-left, then A = (B ∨C) and the last rule in π′ is ∨-right.
Therefore π is of the form
ρ1
Γ,An−1,B ⊢Δ
ρ2
Γ,An−1,C ⊢Δ ∨-left
Γ,An−1,B ∨C ⊢Δ

128
6
Automated Theorem Proving
and π′ of the form
ρ′
Γ ′ ⊢B,C,Am−1,Δ′
∨-right
Γ ′ ⊢B ∨C,Am−1,Δ′
The induction hypothesis applied to π and ρ′ ﬁrst, then to ρ1 and π′, and ﬁ-
nally to ρ2 and π′ produces a proof of Γ,Γ ′ ⊢B,C,Δ,Δ′, Γ,Γ ′,B ⊢Δ,Δ′
and Γ,Γ ′,C ⊢Δ,Δ′. The induction hypothesis applied to B and C and the con-
traction rules produce a proof of Γ,Γ ′ ⊢C,Δ,Δ′, and then Γ,Γ ′ ⊢Δ,Δ′.
– If the last rule in π is ⇒-left, then A = (B ⇒C) and the last rule in π′ is ⇒-right.
Therefore π is of the form
ρ1
Γ,An−1 ⊢B,Δ
ρ2
Γ,An−1,C ⊢Δ ⇒-left
Γ,An−1,B ⇒C ⊢Δ
and π′ of the form
ρ′
Γ ′,B ⊢C,Am−1,Δ′
⇒-right
Γ ′ ⊢B ⇒C,Am−1,Δ′
The induction hypothesis applied to π and ρ′ ﬁrst, then to ρ1 and π′ and ﬁ-
nally to ρ2 and π′ produces a proof of Γ,Γ ′,B ⊢C,Δ,Δ′, Γ,Γ ′ ⊢B,Δ,Δ′
and Γ,Γ ′,C ⊢Δ,Δ′. The induction hypothesis applied to B and C and the con-
traction rules produce a proof of Γ,Γ ′ ⊢C,Δ,Δ′, then Γ,Γ ′ ⊢Δ,Δ′.
– If the last rule in π is ¬-left, then A = ¬B and the last rule in π′ is ¬-right.
Therefore π is of the form
ρ
Γ,An−1 ⊢B,Δ ¬-left
Γ,An−1,¬B ⊢Δ
and π′ of the form
ρ′
Γ ′,B ⊢Am−1,Δ′
¬-right
Γ ′ ⊢¬B,Am−1,Δ′
The induction hypothesis applied to π and ρ′, then to ρ and π′, produces a proof
of Γ,Γ ′,B ⊢Δ,Δ′ and Γ,Γ ′ ⊢B,Δ,Δ′. The induction hypothesis applied to
B and the contraction rules produce a proof of Γ,Γ ′ ⊢Δ,Δ′.
– If the last rule in π is ∀-left, then A = ∀x B and the last rule in π′ is ∀-right.
Therefore π is of the form
ρ
Γ,An−1,(t/x)B ⊢Δ ∀-left
Γ,An−1,∀x B ⊢Δ

6.1
Sequent Calculus
129
and π′ of the form
ρ′
Γ ′ ⊢B,Am−1,Δ′
∀-right
Γ ′ ⊢∀x B,Am−1,Δ′
Since x is not free in Γ ′, A or Δ′, by substituting the variable x by the term t
in the proof ρ′, we obtain a proof ρ′
1 of Γ ′ ⊢(t/x)B,Am−1,Δ′. The induction
hypothesis applied to π and ρ′
1, then to ρ and π′ produces a proof of Γ,Γ ′ ⊢
(t/x)B,Δ,Δ′, and Γ,Γ ′,(t/x)B ⊢Δ,Δ′. The induction hypothesis applied to
(t/x)B and the contraction rules produce a proof of Γ,Γ ′ ⊢Δ,Δ′.
– If the last rule in π is ∃-left, then A = ∃x B and the last rule in π′ is ∃-right.
Therefore π is of the form
ρ
Γ,An−1,B ⊢Δ
∃-left
Γ,An−1,∃x B ⊢Δ
and π′ of the form
ρ′
Γ ′ ⊢(t/x)B,Am−1,Δ′
∃-right
Γ ′ ⊢∃x B,Am−1,Δ′
Since x is not free in Γ , A or Δ, by substituting the variable x by the term t in the
proof ρ, we obtain a proof ρ1 of Γ,An−1,(t/x)B ⊢Δ. The induction hypothesis
applied to π and ρ′, then to ρ1 and π′ produces a proof of Γ,Γ ′ ⊢(t/x)B,Δ,Δ′,
and Γ,Γ ′,(t/x)B ⊢Δ,Δ′. The induction hypothesis applied to (t/x)B and the
contraction rules produce a proof of Γ,Γ ′ ⊢Δ,Δ′.
In a second series of cases, the last rule in π or π′ applies to a proposition differ-
ent from A. For example, if the last rule in π is ∧-left, then Γ = Γ1,B ∧C and π
is of the form
ρ
Γ1,An,B,C ⊢Δ ∧-left
Γ1,An,B ∧C ⊢Δ
we apply the induction hypothesis to ρ and π′ to obtain a proof of Γ1,Γ ′,B,C ⊢
Δ,Δ′. Using the same rule, that is, ∧-left, we obtain a proof of Γ1,Γ ′,B ∧C ⊢
Δ,Δ′, that is, Γ,Γ ′ ⊢Δ,Δ′. The other cases are similar.
□
Exercise 6.1 Show that the sequent P(c) ∨Q(c) ⊢P(c) does not have a proof in
the sequent calculus without cuts. Conclude that it has no proof in natural deduction.
Proposition 6.6 If we restrict the rule axiom to the case in which all the proposi-
tions in the sequent proved are atomic, we obtain a system equivalent to the sequent
calculus without cuts.
Proof We show, by induction on the number of connectives and quantiﬁers of Γ ⊢
Δ, that in the restricted system the sequents of the form Γ ⊢Δ, where Γ and Δ
share a proposition, are provable.
□

130
6
Automated Theorem Proving
6.2 Proof Search in the Sequent Calculus Without Cuts
In the sequent calculus without cuts, all the propositions occurring in premisses of
rules occur also in the conclusions, thus proof search in the sequent calculus without
cuts does not require choosing a proposition amongst the inﬁnite set of propositions
in the language. However, not all the choices have been eliminated, as we will see.
6.2.1 Choices
If we are looking for a proof of the sequent P ∧Q(c) ⊢P ∧∃x Q(x), for instance,
we can choose to apply a rule to the proposition P ∧Q(c) or to the proposition
P ∧∃x Q(x): we are faced with a proposition choice. If we choose the proposition
P ∧∃x Q(x), we can apply either the rule ∧-right or the rule contraction-right: we
are faced with a rule choice. If we decide to apply ∧-right, two new sequents need to
be proved: P ∧Q(c) ⊢P and P ∧Q(c) ⊢∃x Q(x). Again we have a choice: we can
start looking for a proof of the ﬁrst sequent or for a proof of the second, that is, we
have a sequent choice. Finally, if we try to prove the sequent P ∧Q(c) ⊢∃x Q(x)
by applying the rule ∃-right, we have to choose the term to be substituted for the
variable x; this is a term choice.
In general, at each step in the process of proof search, we have a set of sequents
to prove and we have to choose which one we prove ﬁrst. Afterwards, we have
to choose a proposition in this sequent, and once we have chosen the proposition,
two or three rules may apply: the rule that corresponds to the main quantiﬁer or
connective and to its side, the left- or right-contraction rule, and sometimes the
axiom rule. Finally, if the chosen rule is ∃-right or ∀-left, we also need to choose a
term to substitute.
6.2.2 Don’t Care Choices and Don’t Know Choices
If during a process of search we are faced with a choice (for example, take the path
A or the path B), two scenarios are possible. In the ﬁrst one, if we choose the path
A and it turns out that it is blocked, we have to backtrack and explore the path B.
This is a typical situation when we are searching for the way out of a labyrinth. If
the path A may be inﬁnite, we might start exploring the path B even if the path A is
not blocked. This is called a don’t know choice. In the other scenario, if the path A
leads to a failure, we might already know that the path B will also fail; in this case
we say that it is a don’t care choice. For example, to cook eggs mimosa style, we
can start by making a mayonnaise or by cooking the eggs. If we decide to start by
the mayonnaise and we fail, it is useless to cook the eggs since this will not help us
improve the mayonnaise.
In the search for a proof in sequent calculus, the choice of sequent is of
course a don’t care choice: the order in which the sequents P ∧Q(c) ⊢P and

6.2
Proof Search in the Sequent Calculus Without Cuts
131
P ∧Q(c) ⊢∃x Q(x) are proved is not important, each proof search is independent.
However, the other three choices are don’t know choices. The following example
illustrates a don’t know proposition choice. We search for a proof of the sequent
∃x P(x),∀y (P(y) ⇒Q) ⊢Q. If we start by applying rule ∃-left to proposition
∃x P(x), we obtain the sequent P(x),∀y (P(y) ⇒Q) ⊢Q and we can apply rule
∀-left to proposition ∀y (P(y) ⇒Q), choose the term x, and ﬁnish. But if we apply
ﬁrst rule ∀-left to proposition ∀y (P(y) ⇒Q), with the same term x, we obtain
the sequent ∃x P(x),P(x) ⇒Q ⊢Q, which is not provable. In particular, since
the variable x occurs free in the sequent, to apply the rule ∃-left to the proposi-
tion ∃x P(x) we need to rename the bound variable x to x′, obtaining the sequent
P(x′),P(x) ⇒Q ⊢Q, which is not provable.
The following is an example of a don’t know rule choice. We search for a proof
of the sequent ⊢∃x (P(x) ⇒P(f (x))). If we apply the rule contraction-right ﬁrst,
followed by two applications of the rule ∃-right with the terms c and f (c) we obtain
the sequent ⊢P(c) ⇒P(f (c)),P(f (c)) ⇒P(f (f (c))), which is easy to prove.
However, if we apply the rule ∃-right, we obtain a sequent of the form ⊢P(t) ⇒
P(f (t)), which is not provable.
A don’t know term choice is illustrated by the following example. To prove the
sequent P(f (f (c))) ⊢∃x P(f (x)), we must apply the rule ∃-right with the term
f (c), certainly not with c.
6.2.3 Restricting the Choices
One of the choices discussed above, term choice, requires choosing a term amongst
an inﬁnite set of terms. The other two choices (proposition choice and rule choice)
are both ﬁnite choices. It is therefore important to restrict ﬁrst the number of choices
for terms.
When looking for a proof of the sequent P(f (f (c))) ⊢∃x P(f (x)), if we apply
rule ∃-right to proposition ∃x P(f (x)), we can substitute the variable x by many
different terms: c, f (c), f (f (c)), f (f (f (c))),... . Of course, only the term f (c)
will lead to a success. Instead of enumerating all the terms that can be substituted
and trying them one by one, we can delay the choice by substituting x by a spe-
cial variable X. A comparison of the propositions in the resulting sequent, that is,
P(f (f (c))) and P(f (X)), will suggest the substitution f (c)/X in a second phase.
Thus, we will partition the variables into two inﬁnite sets: ordinary variables,
denoted by a lower case letter, and metavariables denoted by capital letters.
Deﬁnition 6.3 (Proof schema) A proof schema is a proof built in a variant of the
sequent calculus without cuts where
– the rules ∃-right and ∀-left are restricted so that the substituted term t is always a
metavariable,

132
6
Automated Theorem Proving
– the axiom rule is replaced by a rule axiom′ which will allow us to prove any
sequent where the propositions are atomic
axiom′ Γ,Δ atomic
Γ ⊢Δ
For example, the tree
axiom′
P(f (f (c))) ⊢P(f (X)) ∃-right
P(f (f (c))) ⊢∃x P(f (x))
is a proof schema.
Proposition 6.7 Let Γ ⊢Δ be a sequent and h a natural number. The sequent
Γ ⊢Δ has a ﬁnite number of proof schemas whose height is less than h.
Proof By induction on h.
□
Deﬁnition 6.4 If σ is a substitution and Γ a multiset of propositions, the multiset
σΓ is obtained by applying the substitution σ to each element of Γ .
If σ is a substitution and π a proof or proof schema, the proof or proof schema
σπ is obtained by applying the substitution σ to each node in π.
Deﬁnition 6.5 A substitution σ that associates the terms t1,...,tn to the metavari-
ables X1,...,Xn perfects a proof schema π if the tree σπ is a proof in the sequent
calculus without cuts where the rule axiom is restricted to sequents where all the
propositions are atomic, that is, if
– for each sequent Γ ⊢Δ, proved using the rule axiom′, the multisets σΓ and σΔ
share a proposition
– and each time a rule ∃-left or ∀-right is used in π, the freshness condition for the
variables is satisﬁed in σπ, this means that if a node in π is of the form
Γ ⊢A,Δ
∀-right
Γ ⊢∀x A,Δ
or
Γ,A ⊢Δ
∃-left
Γ,∃x A ⊢Δ
then the variable x is not free in σΓ or σΔ. In other words, x is not free in Γ,Δ
and if Y is free in Γ,Δ, then x is not free in σY.
For example, the substitution f (c)/X perfects the proof schema above and pro-
duces the proof
axiom
P(f (f (c))) ⊢P(f (f (c))) ∃-right
P(f (f (c))) ⊢∃x P(f (x))

6.2
Proof Search in the Sequent Calculus Without Cuts
133
Given a proof schema π, it is possible to decide whether or not there exists a
substitution that perfects it. Indeed, if sufﬁces to ﬁnd a substitution σ and, for each
sequent Γ ⊢Δ proved by the rule axiom′, a pair of an atomic proposition A in Γ
and an atomic proposition B in Δ such that σA = σB. Since in π there is only a
ﬁnite number of sequents proved by the rule axiom′, and for each of them there is
a ﬁnite number of pairs, we can enumerate all the possible choices of atomic pairs
for each sequent. Then, for each choice we need to ﬁnd out whether there exists a
substitution σ such that for each pair (A,B), σA = σB.
For example, in the schema above we have only one sequent proved by the rule
axiom′, and only one choice for the pair of atomic propositions from Γ and Δ. We
need to ﬁnd a substitution σ such that σ(P(f (X))) = σ(P(f (f (c)))), that is, a
substitution σ that solves the equation
P(f (X)) = P(f (f (c)))
This equation is a uniﬁcation problem. To solve this problem we proceed as follows.
The solutions of the problem
P(f (X)) = P(f (f (c)))
coincide with those of
f (X) = f (f (c))
which are the same as those of
X = f (c)
and this problem has a solution: the substitution f (c)/X.
Deﬁnition 6.6 A uniﬁcation problem is a system of equations of the form t = u.
A solution of a uniﬁcation problem is a substitution σ such that for each equation
t = u in the problem, the terms σt and σu are identical.
We can solve uniﬁcation problems using Robinson’s uniﬁcation algorithm, which
is similar in some respects to Gaussian elimination.
Deﬁnition 6.7 (Robinson’s uniﬁcation algorithm) Choose an equation in the sys-
tem.
– If the equation is of the form f (t1,...,tn) = f (u1,...,un) where f is a predicate
symbol, a function symbol or a variable, replace it with the equations t1 = u1, ...,
tn = un and solve the resulting system.
– If the equation is of the form f (t1,...,tn) = g(u1,...,um) where f and g are
different symbols, the algorithm fails.
– If the equation is of the form X = X, discard it and continue solving the remaining
equations.
– If the equation is of the form X = t or t = X, where X occurs in t and is different
from t, the algorithm fails.

134
6
Automated Theorem Proving
– If the equation is of the form X = t or t = X and X does not occur in t, substitute
X by t in the remaining equations and solve the resulting system, obtaining a
substitution σ; the result is then σ ∪{σt/X}.
The only non-trivial case is the fourth: an equation of the form X = f (X), for in-
stance, does not have a solution. This can be proved by contradiction: if we assume
that there is a solution, for example the term u, then u should be equal to f (u) and
the number of symbols in u should satisfy the equation n = n + 1. This is called
an occur check, it is essential to ensure the termination of the uniﬁcation algorithm.
Indeed, in the ﬁfth case, termination follows from the fact that the variable X disap-
pears when X is substituted by t and therefore the recursive calls to the algorithm
work on a system with less variables. This uniﬁcation algorithm always terminates.
It fails if the system does not have a solution, and returns a solution if the system is
solvable.
A uniﬁcation problem may have several solutions. For example, the equation
X = f (Y) has, amongst others, the solutions
f (c)/X,c/Y
f (f (c))/X,f (c)/Y
f (Z)/X,Z/Y
f (Y)/X
A solution σ is said to be most general if for each solution τ there exists a sub-
stitution η such that τ = η ◦σ. For example, the last two substitutions above are
most general solutions, but the ﬁrst two are not. It can be shown that any solvable
uniﬁcation problem has a most general solution, and the substitution returned by the
uniﬁcation algorithm is a most general solution. Also, if σ is a most general solu-
tion of a uniﬁcation problem and τ is an arbitrary solution, then the set of variables
in τX is included in the set of variables of σX. To decide whether there exists a
solution τ for a uniﬁcation problem such that some constraint of the form “x does
not occur in τY” holds, it is sufﬁcient to check whether the most general solution
σ, computed by the uniﬁcation algorithm, satisﬁes this constraint.
In this way, it is possible to decide whether there exists a substitution that perfects
a proof schema, which means that the set of sequents having a proof in the sequent
calculus without cuts of height less than h is decidable.
There are also many ways to restrict the choice of proposition and the choice of
rule. We give some examples in Exercise 6.4.
Deﬁnition 6.8 A prenex proposition is a proposition of the form Q1x1 ...Qnxn C
where Q1,...,Qn are quantiﬁers, ∀or ∃, and C is a proposition without quantiﬁers.
An existential proposition is a proposition of the form ∃x1 ...∃xn C where C is a
proposition without quantiﬁers. A universal proposition is a proposition of the form
∀x1 ...∀xn C where C is a proposition without quantiﬁers.
A proposition without quantiﬁers is in conjunctive normal form if it is of the form
⊤or C1 ∧(···∧Cn) where each proposition Ci is of the form ⊥or D1 ∨(···∨Dm)
where each Di is an atomic proposition or the negation of an atomic proposition.

6.2
Proof Search in the Sequent Calculus Without Cuts
135
Exercise 6.2 (Transforming sequents: quantiﬁers) This exercise relies on Exer-
cise 1.5, which should be done prior to this one.
1. Show that if the sequent ⊢A ⇔A′ is provable then the sequent Γ,A ⊢Δ is
provable if and only if the sequent Γ,A′ ⊢Δ is provable and the sequent Γ ⊢
A,Δ is provable if and only if the sequent Γ ⊢A′,Δ is provable.
2. Show that if x is not a free variable in B, the propositions ((∀x A) ∧B) ⇔
∀x (A ∧B), (B ∧(∀x A)) ⇔∀x (B ∧A), ((∃x A) ∧B) ⇔∃x (A ∧B), (B ∧
(∃x A)) ⇔∃x (B ∧A), ((∀x A) ∨B) ⇔∀x (A ∨B), (B ∨(∀x A)) ⇔∀x (B ∨
A), ((∃x A)∨B) ⇔∃x (A∨B), (B ∨(∃x A)) ⇔∃x (B ∨A), ((∀x A) ⇒B) ⇔
∃x (A ⇒B), (B ⇒(∀x A)) ⇔∀x (B ⇒A), ((∃x A) ⇒B) ⇔∀x (A ⇒B),
(B ⇒(∃x A)) ⇔∃x (B ⇒A), (¬(∀x A)) ⇔∃x ¬A and (¬(∃x A)) ⇔∀x ¬A
are provable.
Show that for any proposition A there exists a prenex proposition A′ such that
the proposition A ⇔A′ is provable.
Show that the sequent ⊢A is provable if and only if the sequent ⊢A′ is prov-
able.
3. Recall that, by Proposition 1.7, the sequent ⊢A is provable if and only if the
sequent ⊢¬¬A is provable.
Show that the sequent ⊢A is provable if and only if the sequent ¬A ⊢is
provable.
Show that for any proposition A there exists a prenex proposition A′ such that
the sequent A′ ⊢is provable if and only if the sequent ⊢A is provable.
4. Show that for any proposition A there exists a universal proposition A′ such that
the sequent A′ ⊢is provable if and only if the sequent ⊢A is provable. Hint: use
Skolem’s Theorem 2.3.
Show that for any proposition A there exists an existential proposition A′ such
that the sequent ⊢A′ is provable if and only if the sequent ⊢A is provable.
Exercise 6.3 (Transforming sequents: connectives) This exercise relies on Exer-
cise 6.2, which should be done prior to this one.
1. Show that the propositions (A ⇒B) ⇔(¬A ∨B), (¬⊤) ⇔⊥, (¬⊥) ⇔⊤,
(¬(A∧B)) ⇔((¬A)∨(¬B)), (¬(A∨B)) ⇔((¬A)∧(¬B)) and (¬¬A) ⇔A
are provable.
Show that for any proposition A without quantiﬁers there exists a proposition
A′ also without quantiﬁers and moreover without any occurrence of the symbol
⇒and with negation applied only to atomic propositions, such that the proposi-
tion A ⇔A′ is provable.
2. Show that the propositions ((A ∧B) ∧C) ⇔(A ∧(B ∧C)), ((A ∨B) ∨C) ⇔
(A ∨(B ∨C)), (A ∨(B ∧C)) ⇔(A ∨B) ∧(A ∨C), ((A ∧B) ∨C) ⇔(A ∨
C) ∧(B ∨C), (⊤∨A) ⇔⊤, (A ∨⊤) ⇔⊤, (⊥∨A) ⇔A and (A ∨⊥) ⇔A
are provable.
Show that for any proposition A without quantiﬁers there exists a proposition
A′ in conjunctive normal form such that the proposition A ⇔A′ is provable.

136
6
Automated Theorem Proving
3. Show that for any proposition A there exists a universal proposition A′ of the
form ∀x1 ...∀xn C, where C is a proposition in conjunctive normal form such
that the sequent A′ ⊢is provable if and only if the sequent ⊢A is provable.
Show that the proposition (∀x (A ∧B)) ⇔((∀x A) ∧(∀x B)) is provable.
Show that the sequent Γ,A ∧B ⊢Δ is provable if and only if the sequent
Γ,A,B ⊢Δ is provable.
Show that for any proposition A there are propositions C1,...,Cp of the form
⊥or ∀x1 ···∀xn (D1 ∨(... ∨Dm)), where each Di is an atomic proposition or
the negation of an atomic proposition, such that the sequent ⊢A is provable if
and only if the sequent C1,...,Cp ⊢is provable.
Exercise 6.4 This exercise relies on Exercise 6.2, which should be done prior to
this one.
1. Show that by restricting the contraction-left rule to propositions of the form ∀x A
and the contraction-right rule to propositions of the form ∃x A we obtain a sys-
tem which is equivalent to the sequent calculus without cuts.
2. Show that proofs of existential propositions in the sequent calculus without cuts
never use the rules ∃-left and ∀-right. Show that in the sequent calculus without
cuts and without the rules ∃-left and ∀-right the proposition choice is don’t care.
3. Write a program to search for proofs in the sequent calculus.
Exercise 6.5 (Herbrand’s Theorem) Let A be a closed prenex proposition of the
form Q1x1 ...Qnxn C. A closed instance of A is a closed proposition of the form
σC, where σ is a substitution with domain x1,...,xn.
Let A1,...,An be closed existential propositions, and Γ and Δ multisets of
closed propositions without quantiﬁers. Show that if the language contains at
least one constant then the sequent Γ ⊢A1,...,An,Δ is provable in the se-
quent calculus without cuts if and only if there are closed instances A1
1,...,Ap1
1
of A1,...,A1
n,...,Apn
n
of An, such that the sequent without quantiﬁers Γ ⊢
A1
1,...,Ap1
1 ,...,A1
n,...,Apn
n ,Δ is provable in the sequent calculus without cuts.
Let A1,...,An be closed existential propositions. Show that if the language
contains at least one constant then the sequent ⊢A1,...,An is provable in
the sequent calculus without cuts if and only if there are closed instances
A1
1,...,Ap1
1
of A1,...,A1
n,...,Apn
n
of An, such that the sequent without quan-
tiﬁers ⊢A1
1,...,Ap1
1 ,...,A1
n,...,Apn
n
is provable in the sequent calculus without
cuts.
Let A1,...,An be closed universal propositions. Show in the same way that if
the language contains at least one constant then the sequent A1,...,An ⊢is prov-
able in the sequent calculus without cuts if and only if there are closed instances
A1
1,...,Ap1
1
of A1,...,A1
n,...,Apn
n
of An, such that the sequent without quanti-
ﬁers A1
1,...,Ap1
1 ,...,A1
n,...,Apn
n ⊢is provable in the sequent calculus without
cuts.
Exercise 6.6 (Resolution) This exercise relies on Exercises 6.2, 6.3 and 6.5, which
should be done prior to this one.

6.2
Proof Search in the Sequent Calculus Without Cuts
137
A clause is a ﬁnite set of propositions where each proposition is either atomic or
it is the negation of an atomic proposition.
If C = {A1,...,An} is a clause, we denote by ∀C the proposition ∀x1 ...∀xp(A1
∨··· ∨An), where x1,...,xp are the free variables of A1,...,An and ∀∅= ⊥by
deﬁnition.
Let E be a set of clauses. Below we consider the set G of clauses inductively
deﬁned by the following three rules.
– if C is in E, then C is in G,
– if C is in G, then (t/x)C is in G,
– if C1 ∪{A} and C2 ∪{¬A} are in G, then C1 ∪C2 is in G.
The notation E ⇝C will be used to state that the clause C is in the set G.
1. Let E be a set consisting of four clauses
P(a,b)
P(b,c)
¬P(x,y),¬P(y,z),G(x,z)
¬G(a,c)
Give a derivation for E ⇝∅.
2. Show that for any proposition A, there exists a set C1,...,Cn of clauses, such
that the sequent ⊢A is provable if and only if the sequent ∀C1,...,∀Cn ⊢is
provable. Which set of clauses is associated to the following proposition?
(P(a,b) ∧P(b,c) ∧∀x∀y∀z ((P(x,y) ∧P(y,z)) ⇒G(x,z))) ⇒G(a,c)
3. Our aim is to prove that if C1,...,Cn ⇝∅, then the sequent ∀C1,...,∀Cn ⊢is
provable. We will prove a more general property: if C1,...,Cn ⇝D, then the
sequent ∀C1,...,∀Cn ⊢∀D is provable.
Show that if D = (t/x)C, then the sequent ∀C ⊢∀D is provable.
Show that if C1 = C′
1 ∪{A}, C2 = C′
2 ∪{¬A} and D = C′
1 ∪C′
2, then the
sequent ∀C1,∀C2 ⊢∀D is provable.
Let C1,...,Cn be a set of clauses. Show that if C1,...,Cn ⇝D, then the
sequent ∀C1,...,∀Cn ⊢∀D is provable.
Show that if the sequent Γ ⊢⊥is provable, then the sequent Γ ⊢is also
provable.
Show that if C1,...,Cn ⇝∅, then the sequent ∀C1,...,∀Cn ⊢is provable.
4. We now wish to prove the converse, that is, prove that if the sequent ∀C1,...,
∀Cn ⊢is provable, then C1,...,Cn ⇝∅.
Let E be a set of clauses and C and D two clauses. Show that if E ⇝C and
E ∪{C} ⇝D, then E ⇝D.
Let D be a closed clause, E = {C1,...,Cn} and E′ = {C′
1,...,C′
n} two sets
of closed clauses closes such that for all i, C′
i is either the clause Ci or the clause
Ci ∪D and C is a closed clause. Show that if E ⇝C, then either E′ ⇝C or
E′ ⇝C ∪D. Show that if E ⇝∅, then either E′ ⇝∅or E′ ⇝D. Show that

138
6
Automated Theorem Proving
if C and C′ are two closed clauses and E ∪{C} ⇝∅and E ∪{C′} ⇝∅, then
E,(C ∪C′) ⇝∅.
Let C1,...,Cn be closed clauses and P1,...,Pm closed atomic proposi-
tions. Show that if the sequent ∀C1,...,∀Cn ⊢P1,...,Pm is provable, then
C1,...,Cn,¬P1,...,¬Pm ⇝∅. Show that if the sequent ∀C1,...,∀Cn ⊢is
provable, then C1,...,Cn ⇝∅.
Let C1,...,Cn be arbitrary clauses. Show that if the sequent ∀C1,...,∀Cn ⊢
is provable, then C1,...,Cn ⇝∅. Hint: use Herbrand’s theorem.
Let C1,...,Cn be arbitrary clauses. Show that the sequent ∀C1,...,∀Cn ⊢is
provable if and only if C1,...,Cn ⇝∅.
5. The three rules given above cannot be used yet as a proof search algorithm,
because the second rule requires that we choose a term from an inﬁnite set. To
avoid this choice, we will introduce another set of rules, which will be called
resolution rules.
Let E be a set of clauses. We deﬁne the set G of clauses inductively, using the
following two rules.
– if C is in E, then C is in G,
– if C ∪{A1,...,An} and C′ ∪{¬B1,...,¬Bm} are two clauses in G that do
not share variables (it is always possible to rename their variables so that no
variable is shared), and σ is a most general solution of the uniﬁcation problem
A1 = ··· = An = B1 = ··· = Bm, then the clause σ(C ∪C′) is in G.
The notation E 
→C will be used to state that C is in the set G.
Let E be the set of clauses deﬁned in question (1.). Give a derivation of
E 
→∅.
Let E be a set of clauses. Show that if E 
→D, then E ⇝D. Show that if
E 
→∅, then E ⇝∅.
Show that if there exists a set E′ containing clauses of the form σC, where
C is a clause in E and σ a substitution, such that E′ ⇝D′, then there exists
a clause D and a substitution τ such that E 
→D and D′ = τD. Show that if
E ⇝∅, then E 
→∅.
Let E be a set of clauses. Show that E ⇝∅if and only if E 
→∅.
Let A be a proposition and C1,...,Cn a set of clauses, such that the sequent
⊢A is provable if and only if the sequent ∀C1,...,∀Cn ⊢is provable. Show that
the sequent ⊢A is provable if and only if C1,...,Cn 
→∅.
6. Write a resolution-based proof-search program.

Chapter 7
Decidable Theories
We have seen in Chap. 5 that provability in predicate logic is not decidable. How-
ever, not all is lost: provability in predicate logic is semi-decidable in general, and
by adding axioms it is sometimes possible to obtain a decidable theory.
In Chap. 6 we developed algorithms to search for proofs, which, since the prob-
lem is semi-decidable, sometimes do not terminate when the proposition that we are
trying to prove is not provable.
In this chapter we will study an example of an algorithm that can be used to
decide provability in a speciﬁc theory.
Several different methods can be used to decide provability within a theory. For
instance, one of the methods is based on the fact that if a proposition is not prov-
able in the theory, then there exists a ﬁnite model of the theory that invalidates the
proposition. Thus, by enumerating both the proofs and the models we can be sure
that we will eventually ﬁnd a proof, if the proposition is provable, or a model if it
is not. Another method, the so-called quantiﬁer elimination method relies on prov-
ing, ﬁrst, that for closed propositions without quantiﬁers provability can be decided
simply by analysing the proposition, and second, that any closed proposition can be
transformed into an equivalent closed proposition without quantiﬁers. We will use
this method to prove the decidability of the set of propositions in the language 0, 1,
+, −, ≤that are valid in Z. Once we prove that this set is decidable, we can use it to
deﬁne a theory where the axioms are the elements of this set. The resulting theory
is consistent, complete and decidable.
To prove this theorem we will extend the language adding unary predicates
Multn, for each natural number n different from 0, to characterise the multiples
of n.
Deﬁnition 7.1 Let L be the language consisting of the constants 0 and 1, binary
function symbols + and −, a binary predicate symbol ≤, and a unary predicate
Multn for each natural number n different from 0.
We will use the following shorthand notations: if n is a positive integer, we use
n to denote the integer 1 + 1 + ··· + 1 where the symbol 1 occurs n times, and if
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_7, © Springer-Verlag London Limited 2011
139

140
7
Decidable Theories
n is negative, we denote by n the integer 0 −1 −1 −··· −1 where the symbol
1 occurs −n times. Similarly, we write 1.x for the term x, 2.x for x + x, 3.x for
x + x + x,...,(−1).x for 0 −x, (−2).x for 0 −x −x,... and 0.x represents the
term 0.
Deﬁnition 7.2 (The model Z) The model Z consists of the set Z, the integers 0
and 1, the addition and subtraction operations on Z, the ordering relation over Z
and, for each natural number n different from 0, the characteristic function of the
set of multiples of n.
Let us start with an example. Consider the proposition 1 ≤3.x ∧x ≤7 −x,
which we will call A, with a unique free variable, x. Our goal is to decide whether
the proposition ∃x A is valid or not in Z. In order to do this, we transform each
inequation, so that all the x are on one side of the symbol ≤and the other terms on
the other. Then we multiply the ﬁrst inequation by 2 and the second by 3, to have
the same coefﬁcient for x in each inequation. We obtain the equivalent proposition
∃x (2 ≤6.x ∧6.x ≤21). Now we change the variable, and obtain the equivalent
proposition ∃x′ (2 ≤x′ ∧x′ ≤21 ∧Mult6(x′)). We have to decide whether there
exists a multiple of 6 in the interval between 2 and 21, and the answer is positive.
If the proposition A had other variables, we would not be able to decide whether
the proposition ∃x A, which has free variables, is valid or not, but we could trans-
form it into an equivalent proposition without quantiﬁers and with the same vari-
ables. Consider, for instance, the proposition 1 ≤3.x ∧x ≤y −x. We start as
before by moving all the x to one side of the symbol ≤and the other terms to
the other. Then we multiply each inequality to obtain the same coefﬁcient for x in
each inequation and we change the variable, obtaining a proposition equivalent to
∃x A, namely ∃x′ (2 ≤x′ ∧x′ ≤3.y ∧Mult6(x′)). Let us call A′ the proposition
2 ≤x′ ∧x′ ≤3.y ∧Mult6(x′).
Fix a value q for y and assume that there exists a natural number p that satisﬁes
this proposition. Two cases may arise. Either all the numbers greater than p and
congruents with p modulo 6 satisfy it too, or, as in this example, they do not. In
this case, there exists an integer p′ that satisﬁes the proposition and such that p′ + 6
does not. This means that there exists an inequation, here x′ ≤3.y, which changed
between p′ and p′ + 6. Therefore p′ ≤3.q < p′ + 6. There exists then a natural
number j between 0 and 5 such that 3.q = p′ + j and hence p′ = 3.q −j satisﬁes
the proposition give above. In other words, the proposition A′ where we substitute
y by q and x′ by 3.q −j for some j between 0 and 5 is valid in Z.
Let B be the proposition without quantiﬁers (3.y/x′)A′ ∨((3.y −1)/x′)A′ ∨
((3.y −2)/x′)A′ ∨((3.y −3)/x′)A′ ∨((3.y −4)/x′)A′ ∨((3.y −5)/x′)A′. The
proposition B, where we substitute y by q, is valid in Z. Conversely, if this propo-
sition is valid in Z, then so is ∃x′ A′.
The following proposition generalises this construction.
Proposition 7.1 Let A be a proposition without quantiﬁers in the language L. There
exists a proposition B without quantiﬁers such that the proposition (∃x A) ⇔B is
valid in the model Z.

7
Decidable Theories
141
Proof We start by replacing in A all propositions of the form C ⇒D (that is, all
the implications) by the equivalent proposition ¬C ∨D. Then we eliminate all the
negations by replacing the propositions of the form ¬⊤by ⊥, ¬⊥by ⊤, ¬(C ∧D)
by ¬C ∨¬D, ¬(C ∨D) by ¬C ∧¬D, ¬¬C by C, ¬ t ≤u by u + 1 ≤t and
¬ Multn(t) by Multn(t + 1) ∨··· ∨Multn(t + n −1) until the symbol ¬ disappears.
The resulting proposition can only contain the connectives ⊤, ⊥, ∧, ∨and atomic
propositions of the form t ≤u or Multn(t).
The next step consists of moving all the x to one side of the symbol ≤in each
inequation, leaving the other terms in the other side. We can then replace each propo-
sition of the form t ≤u by the equivalent proposition k.t ≤k.u, where k is a strictly
positive integer, and each proposition of the form Multn(t) by Multkn(k.t), in or-
der to obtain the same coefﬁcient s for x in all the atomic propositions. Then all the
terms of the form s.x can be replaced by a variable x′, adding the atomic proposition
Mults(x′). The result is a proposition of the form ∃x′ A′, equivalent to the proposi-
tion ∃x A, where A′ uses the connectives ⊤, ⊥, ∧, ∨and atomic propositions of the
form x′ ≤t, t ≤x′, 0 ≤t, Multn(x′ + t) and Multn(t) such that t does not contain
any occurrence of the variable x′.
Let r be a common multiple of all the integers n such that the atomic proposition
Multn(x′ + t) occurs in A′.
If we ﬁx the value of the variables different from x′, the truth value of such a
proposition is a function of the value of x′, which is periodic (with period r) from
a certain point. Indeed, there is a certain value such that for any greater value all
propositions of the form x′ ≤t are false and all propositions of the form t ≤x′ are
true, only those of the form Multn(x′ + t) change their value, with period r.
Let E be the set of terms t such that the atomic proposition x′ ≤t occurs in A′.
Let A′′ be the proposition obtained by replacing in A′ all the propositions of the
form x′ ≤t by ⊥and all the propositions of the form t ≤x′ by ⊤. Let B be the
disjunction of all the propositions of the form
– (i/x′)A′′ where i is an integer between 0 and r −1,
– ((t −j)/x′)A′ where t is a term in E and j an integer between 0 and r −1.
Let us now prove that the proposition (∃x′ A′) ⇔B is valid in Z.
Let y1,...,yn be the variables in A′ different from x′. We denote by A′[p,q1,...,
qn] the proposition (p/x′,q1/y1,...,qn/yn)A′, by A′′[p,q1,...,qn] the proposi-
tion (p/x′,q1/y1,...,qn/yn)A′′ and by B[q1,...,qn] the proposition (q1/y1,...,
qn/yn)B. We will show that for all q1,...,qn, there exists an integer p such that
A′[p,q1,...,qn] is valid if and only if B[q1,...,qn] is valid.
Assume that there exists an integer p such that A′[p,q1,...,qn] is valid. In this
case, either A′[p + vr,q1,...,qn] is valid for all v, or not.
In the ﬁrst case, there are integers p′ (arbitrarily large) such that A′[p′,q1,...,qn]
is valid, and for some p′ sufﬁciently large A′[p′,q1,...,qn] is equivalent to
A′′[p′,q1,...,qn]. Therefore, there exists an integer p′ such that A′′[p′,q1,...,qn]
is valid. Also, for all p A′′[p,q1,...,qn] is equivalent to A′′[p −r,q1,...,qn].
Thus, there exists an integer i between 0 and r −1 such that A′′[i,q1,...,qn] is
valid. The proposition B[q1,...,qn] is therefore valid.

142
7
Decidable Theories
In the second case, there exists an integer p′ such that A′[p′,q1,...,qn] is valid
but A′[p′ + r,q1,...,qn] is not. There exists an atomic proposition of the form
x′ ≤t satisﬁed by p′ but not by p′ + r. Let us write t[q1,...,qn] for the term
(q1/y1,...,qn/yn)t. We have p′ ≤t[q1,...,qn], but t[q1,...,qn] < p′ + r. There-
fore, there exists an integer j between 0 and r −1 such that p′ = t[q1,...,qn] −j.
The proposition B[q1,...,qn] is therefore valid.
Conversely, if B[q1,...,qn] is valid, then, either there exists an integer i such
that A′′[i,q1,...,qn] is valid or there exists an element t in E and a number j
such that A′[t[q1,...,qm] −j,q1,...,qn] is valid. In the second case, there exists
an integer p such that A′[p,q1,...,qn] is valid. In the ﬁrst case, for all p such
that A′′[p,q1,...,qn] is equivalent to A′′[p + r,q1,...,qn], there are integers p
arbitrarily large such that A′′[p,q1,...,qn] is valid, and for p sufﬁciently large
A′′[p,q1,...,qn] is equivalent to A′[p,q1,...,qn]. Therefore, there exists an inte-
ger p such that A′[p,q1,...,qn] is valid.
□
Proposition 7.2 Let A be a proposition in the language L. There exists a proposi-
tion B without quantiﬁers such that A ⇔B is valid in Z.
Proof The propositions of the form ∀x C can be replaced by the equivalent proposi-
tion ¬∃x¬C, and a proof by induction over the structure of the obtained proposition
allows us to conclude, using Proposition 7.1 in the case of the existential quanti-
ﬁer.
□
Theorem 7.1 The set of propositions in the language 0,1,+,−,≤that are valid in
Z is decidable.
Proof Validity of closed propositions without quantiﬁers is obviously decidable,
and for arbitrary propositions it can be derived from Proposition 7.2.
□
We can state a similar result for natural numbers.
Theorem 7.2 (Presburger) The set of propositions in the language 0,S,+,= that
are valid in N is decidable.
Proof To each proposition A in the language 0,S,+,= we associate a proposition
|A| in the language 0,1,+,−,≤such that for every closed proposition A, A is valid
in N if and only if |A| is valid in Z.
– |0| = 0, |x| = x, |S(t)| = |t| + 1, |t + u| = |t| + |u|,
– |t = u| = |t| ≤|u| ∧|u| ≤|t|,
– |⊤| = ⊤, |⊥| = ⊥, |¬A| = ¬|A|, |A ∧B| = |A| ∧|B|, |A ∨B| = |A| ∨|B|,
|A ⇒B| = |A| ⇒|B|,
– |∀x A| = ∀x (0 ≤x ⇒|A|), |∃x A| = ∃x (0 ≤x ∧|A|).
□

Chapter 8
Constructivity
If a set of natural numbers contains 0, but not 2, we can show that there exists a
natural number in this set such that its successor is not in the set. Indeed, if we
enumerate the natural numbers, at some point the sequence leaves the set. We can
even show that the natural number we are looking for is either 0 or 1, but we cannot
show that it is 0, or that it is 1, because we do not know whether the number 1 is in
the set or not.
In predicate logic, the corresponding sequent
Γ ⊢∃x (P(x) ∧¬P(S(x)))
where Γ = P(0),¬P(2) is provable
Γ ⊢P (1) ∨¬P (1)
...
Γ,P (1) ⊢P (1) ∧¬P (2)
Γ,P (1) ⊢∃x (P (x) ∧¬P (S(x)))
...
Γ,¬P (1) ⊢P (0) ∧¬P (1)
Γ,¬P (1) ⊢∃x (P (x) ∧¬P (S(x)))
Γ ⊢∃x (P (x) ∧¬P (S(x)))
However, for each term t, the sequent P(0),¬P(2) ⊢P(t) ∧¬P(S(t)) is not prov-
able. Indeed, take M = N; if we interpret 0 and S in the obvious way and P ﬁrst by
the characteristic function of the pair {0,1} and then by that of the singleton {0}, we
obtain two models in which the term t has the same denotation, and that refute the
sequent above (the ﬁrst in the case where the denotation of t is 0 and the second in
the case where it is different from 0).
Deﬁnition 8.1 (Witness Property) A set of propositions satisﬁes the witness prop-
erty if for each proposition of the form ∃x A in the set, there is also a proposition
(t/x)A, for some term t, in the set.
It follows from the discussion above that the set of propositions that are provable
in the theory P(0),¬P(2) does not satisfy this property. We can prove in a similar
way that the set of propositions that are provable in the empty theory does not have
the witness property either. For example, consider the proposition
∃x ((P(0) ∧¬P(2)) ⇒(P(x) ∧¬P(S(x))))
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_8, © Springer-Verlag London Limited 2011
143

144
8
Constructivity
Exercise 8.1 Show that the proposition ∃x (P(x)∨¬P(S(x))) is provable but there
is no term t such that P(t) ∨¬P(S(t)) is provable.
In the proof of the sequent P(0),¬P(2) ⊢∃x (P(x) ∧¬P(S(x))), it seems es-
sential to rely on the rule of excluded middle to prove the proposition P(1)∨¬P(1).
The question arises as to whether a proof can be built without using the rule of ex-
cluded middle. It turns out that the answer is negative, because the set of proposi-
tions that are provable in predicate logic without using the rule of excluded middle
have the witness property, as we will see below.
Deﬁnition 8.2 (Constructive proof) A natural deduction proof is constructive if it
does not use the rule of excluded middle. A proof in the system D′ is constructive
if it contains only sequents of the form Γ ⊢Δ where Δ is a singleton. A sequent
calculus proof is constructive if it contains only sequents of the form Γ ⊢Δ where
Δ is a singleton or the empty multiset. We eliminate from the sequent calculus the
rule contraction-right and we modify some of the other rules, as follows. The rule
∨-right is replaced by the rules
Γ ⊢A
∨-right
Γ ⊢A ∨B
Γ ⊢B
∨-right
Γ ⊢A ∨B
the rule ⇒-left by
Γ ⊢A Γ,B ⊢C ⇒-left
Γ,A ⇒B ⊢C
the rule ¬-left by
Γ ⊢A
¬-left
Γ,¬A ⊢B
and the rule cut by the rule
Γ ⊢A Γ,A ⊢B cut
Γ ⊢B
It can be shown that a sequent Γ ⊢A has a constructive proof in natural deduc-
tion if and only if it has a constructive proof in sequent calculus. The proof of this
property follows the same lines as the proofs given in Chap. 6.
Similarly, it can be shown that a sequent Γ ⊢A has a constructive proof in the
sequent calculus if and only if it has a constructive proof without cuts.
Proposition 8.1 If a sequent ⊢A has a proof without cuts in the sequent calculus,
then the last rule in the proof is a right rule.

8
Constructivity
145
Proof Since the left-hand side of the sequent is empty, none of the left rules can
apply, and neither can the axiom rule. Since the proof has no cuts, the last rule
cannot be a cut either. Therefore, it must be a right rule.
□
Proposition 8.2 The set of propositions that have a constructive proof has the wit-
ness property.
Proof If the sequent ⊢∃x A has a constructive proof in sequent calculus, it also has
a constructive proof without cuts. The last rule in this proof is a right rule, and since
the contraction-right rule is not part of the constructive sequent calculus, it can only
be the rule ∃-right. The proof has then the form
π
⊢(t/x)A ∃-right
⊢∃x A
and the proposition (t/x)A has a constructive proof.
□
In the proof above, the fact that the left-hand side of the sequent is empty is
crucial. The theorem does not hold in arbitrary theories. For example, the set of
propositions that have a constructive proof in the theory ∃x P(x) clearly does not
have the witness property. However, the theorem does extend to arithmetic and also
to some versions of set theory.
Thanks to the witness property, constructive proofs can be used as programs. For
example, the proposition
∀x∃y (x = 2 × y ∨x = 2 × y + 1)
has a constructive proof π in arithmetic. Using this proof it is easy to build a proof
of the proposition
∃y (25 = 2 × y ∨25 = 2 × y + 1)
π
Γ ⊢∀x∃y A[x,y]
axiom
Γ,∃y A[25,y] ⊢∃y A[25,y]
∀-left
Γ,∀x∃y A[x,y] ⊢∃y A[25,y] cut
Γ ⊢∃y A[25,y]
where A is the proposition x = 2 × y ∨x = 2 × y + 1 and where A[t,u] denotes
the proposition (t/x,u/y)A. By eliminating the cuts in this proof we obtain a wit-
ness: 12.
The proof π is therefore a program that divides its input 25 by 2, and cut elimina-
tion is the mechanism used to execute this program. By construction, this program
is correct with respect to the speciﬁcation
x = 2 × y ∨x = 2 × y + 1

146
8
Constructivity
Exercise 8.2 We will deﬁne types for the terms in the lambda-calculus. Types
are closed expressions in a language consisting of an inﬁnite set of constants
ρ0,ρ1,ρ2,... and a binary symbol →. A typing context is a ﬁnite set of declara-
tions of the form x : α where x is a variable and α a type, such that if x : α and
x : β are both in the set, then α = β. A typing judgement is a triple consisting of
a typing context Γ , a term t and a type α. The judgement Γ ⊢t : α states that the
term t has the type α in the context Γ . For example, the term funx →(f x x) has
the type ρ0 →ρ0 in the context f : ρ0 →ρ0 →ρ0. The set of derivable judgements
is inductively deﬁned by the following rules
if x : α is in Γ
Γ ⊢x : α
Γ,x : α ⊢t : β
Γ ⊢(funx →t) : α →β
Γ ⊢t : α →β
Γ ⊢u : α
Γ ⊢(t u) : β
1. Write a term of type ρ0 →ρ1 →ρ0 in the empty context, and a term of type
ρ0 →ρ1 →ρ1.
The fragment of predicate logic consisting of the proposition symbols
P0,...,Pn and implication is called minimal propositional logic.
2. Which natural deduction rules can be used to prove propositions in this fragment?
Write a proof for the proposition P0 ⇒P1 ⇒P0 and another for the proposition
P0 ⇒P1 ⇒P1.
The following function φ associates a lambda-calculus type to each proposi-
tion in minimal propositional logic.
φPi = ρi
φ(A ⇒B) = (φA) →(φB)
3. What is the type associated to the proposition P0 ⇒P1 ⇒P0?
4. Show that there exists a proof π for the sequent A1,...,Ap ⊢B if and only if
there exists a term t of type φB in the context x1 : φA1,...,xp : φAp.
5. Let Γ be the context A,A ⇒B,B ⇒C,C ⇒D. Give the term associated to
the proof
axiom
Γ,B ⊢C ⇒D
axiom
Γ,B ⊢B ⇒C
axiom
Γ,B ⊢B ⇒-elim
Γ,B ⊢C ⇒-elim
Γ,B ⊢D
⇒-intro
Γ ⊢B ⇒D
axiom
Γ ⊢A ⇒B
axiom
Γ ⊢A ⇒-elim
Γ ⊢B ⇒-élim
Γ ⊢D
Is this term terminating? What is its irreducible form? Which proof is associated
to this irreducible form?

8
Constructivity
147
6. What is the form of the proofs associated to redexes? And what is the proof
associated to the term obtained by reducing a redex?
Exercise 8.3 This exercise relies on Exercise 1.5 which should be done prior to this
one.
1. Let A be an arbitrary proposition. Give a sequent calculus proof—not necessarily
constructive—of the proposition
A ∨¬A
Give a constructive proof of the proposition
¬¬(A ∨¬A)
To each proposition A in predicate logic we associate a proposition |A| de-
ﬁned by induction over the structure of A as follows
– |P| = ¬¬P
– |⊤| = ¬¬⊤
– |⊥| = ¬¬⊥
– |A ∧B| = ¬¬(|A| ∧|B|)
– |A ∨B| = ¬¬(|A| ∨|B|)
– |A ⇒B| = ¬¬(|A| ⇒|B|)
– |¬A| = ¬¬¬|A|
– |∀x A| = ¬¬∀x |A|
– |∃x A| = ¬¬∃x |A|
2. Write down the proposition associated to |∃x (P(x) ∧¬P(S(x)))|.
3. To each proposition A in predicate logic we associate a proposition ∥A∥similar
to |A| except that negations at the root are eliminated
– ∥P∥= ¬P
– ∥⊤∥= ¬⊤
– ∥⊥∥= ¬⊥
– ∥A ∧B∥= ¬(|A| ∧|B|)
– ∥A ∨B∥= ¬(|A| ∨|B|)
– ∥A ⇒B∥= ¬(|A| ⇒|B|)
– ∥¬A∥= ¬¬|A|
– ∥∀x A∥= ¬∀x |A|
– ∥∃x A∥= ¬∃x |A|
Show that if the sequent Γ ⊢Δ has a proof—not necessarily constructive—in
the sequent calculus without cuts, then the sequent |Γ |∥Δ∥⊢has a constructive
proof without cuts.
4. Let A be a proposition. Show that if A has a proof—not necessarily constructive
—, then |A| has a constructive proof.

148
8
Constructivity
5. Show that for any proposition B, the proposition B ⇔¬¬B has a proof—not
necessarily constructive. Show that the proposition A ⇔|A| has a proof—not
necessarily constructive. Show that if the proposition |A| has a constructive proof
then the proposition A has a proof—not necessarily constructive.
Show that the proposition |A| has a constructive proof if and only if the propo-
sition A has a proof—not necessarily constructive.
6. Give a constructive proof of the sequent
|P(0)|,|¬P(2)| ⊢|∃x (P(x) ∧¬P(S(x)))|
7. Give a constructive proof of the sequent
P(0),¬P(2) ⊢¬¬∃x (P(x) ∧¬P(S(x)))

Chapter 9
Epilogue
In this book we have explored some of the links between proofs and algorithms,
through the theorem of undecidability of provability in predicate logic ﬁrst, then
through the decidability result for well-formedness of proofs (which ensures the
semi-decidability of provability in predicate logic and leads also to proof veriﬁca-
tion algorithms and to automated theorem proving), and also through some decid-
ability results in speciﬁc theories. Finally, the notion of contructivism highlights
another link between proofs and algorithms, which leads to methods to prove that
an algorithm satisﬁes a speciﬁcation, amongst other results.
On the way, we have discovered four main concepts that are central in contempo-
rary logic: the notions of proof, algorithm, model and set. These four notions deﬁne
the four branches of logic: proof theory, computability theory, model theory and set
theory. This classiﬁcation is useful, but we should not lose sight of the fact that all
these notions are used, in different degrees, in each of these branches.
Until the end of the 19th century, the notion of proof was quite rudimentary, the
notions of set and algorithm were informal, and there was no notion of model. Logic
underwent a total makeover when these four notions were clariﬁed in the 1870’s and
later in the 1930’s.
We have also described in this book a number of applications of logic in mathe-
matics, with independence and relative consistency results, and also in a more un-
expected way with results in algebra for which it was not obvious a priori that
logic tools would be necessary. However, it is in computer science where logic ﬁnds
its most prominent ﬁeld of application. For instance, we have seen applications
in programming language theory, where two new families of languages emerged:
functional languages, based on the lambda-calculus, and logic languages based on
automated theorem proving algorithms. There are also applications in machine ar-
chitecture, where circuits are represented as propositions in propositional logic, in
complexity theory, where we can cite for example the notion of non-deterministic
Turing machine, in database theory, where the notion of query language is based on
ﬁnite model theory, and also in veriﬁcation, more precisely, through the design of
tools to prove the correctness of circuits and programs with respect to their logic
speciﬁcation.
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9_9, © Springer-Verlag London Limited 2011
149

150
9
Epilogue
The central rôle of the notion of algorithm in logic could certainly make us
think that there should be applications in computer science, but nobody would have
thought that there would be so many applications and at the level we are seeing
nowadays. In a sense, logic seems to be for computer science what differential cal-
culus is for physics.
And it is not clear whether we have completely grasped yet the reasons why logic
is so unreasonably effective in computer science.

References
1. Cori, R., Lascar, D.: Mathematical Logic: A Course with Exercises. Oxford University Press,
London (2000)
2. David, R., Nour, K., Raffalli, C.: Introduction à la logique: théorie de la démonstration. Dunod,
Paris (2001)
3. Girard, J.-Y., Lafont, Y., Taylor, P.: Proofs and Types. Cambridge University Press, Cambridge
(1989)
4. Krivine, J.-L.: Lambda-Calculus, Types and Models. Ellis Horwood, Chichester (1993)
5. Krivine, J.-L.: Théorie des ensembles. Cassini, Paris (1998)
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9, © Springer-Verlag London Limited 2011
151


Index
A
Alpha-equivalence, 14
Alphabetic equivalence, 14
Arithmetic, 24, 47
Arity, 10
Articulated set of trees, 16
Axiom, 21
addition, 24
equality, 23
extensionality, 25
induction, 24
inﬁnity, 26
multiplication, 24
powerset, 26
replacement, 26
successor, 24
union, 25
B
Beta-reduction, 82
at the root, 82
under call by name, 83
C
Chinese remainders, 63
Choice
don’t care, 130
don’t know, 130
Class
NP, 98
P, 98
Closure, 6
Completeness
of a theory, 113
strongly complete ordering, 5
Turing, 71
Composition
of functions, 55
Conﬂuent, 73
locally, 81
strongly, 79
Consistency
relative, 44
Consistent, 22
Constant, 10
Contradictory, 22
Couple, 27
D
Decidable, 57
Deﬁnable, 51
in arithmetic, 48
Deﬁnition
explicit, 3
inductive, 6
Denotation, 36
Derivation, 9
labelled with rules, 9
E
Excluded middle, 20
Expression, 10, 12
closed, 13
Extension, 46
conservative, 46
of a model, 46
F
Fixed point
ﬁrst theorem, 4
second theorem, 6
Function
Ackermann, 57
G. Dowek, Proofs and Algorithms, Undergraduate Topics in Computer Science,
DOI 10.1007/978-0-85729-121-9, © Springer-Verlag London Limited 2011
153

154
Index
Function (cont.)
computable, 55
continuous, 4
Gödel’s beta, 63
increasing, 4
primitive recursive, 57
H
Halting problem, 66
Height, 13
Hereditary, 8
Hilbert’s tenth problem, 111, 115
I
Index
of a list, 59
of a tree, 60
Induction
structural, 8
Irreducibility, 72
L
Language, 10
of predicate logic, 17
Limit, 3
M
Metavariable, 131
Minimisation of a function, 56
Model, 35
normal, 44
of a proposition, 37
standard, 51
two-valued, 37
N
N-model, 106
Natural deduction, 19
Natural number
Von Neumann’s, 27
Noetherian, 80
Number of arguments, 10
Numeral
Church, 85
O
Ordering, 3
weakly complete, 4
Orthogonal, 73
P
Pair, 27
Perfection, 132
Predecessor, 56
Program, 65
automated theorem proving, 112
proof veriﬁcation, 112
Proof
à la Frege and Hilbert, 18
constructive, 144
in natural deduction, 20
in sequent calculus, 119
Proposition, 17
atomic, 17
conjunctive normal form, 134
existential, 134
prenex, 134
universal, 134
Provable
proposition, 22
sequent, 20
Q
Quantiﬁer elimination, 139
R
Reading and writing head, 92
Redex, 72, 82
Reduction, 72
at the root, 72
call by name, 74
parallel, 80
Reduction sequence, 80
Reﬂexive-transitive closure, 10
Relativisation, 22, 47
Representation
of a function
by a set of rewriting rules, 74
by a Turning machine, 93
in the lambda-calculus, 83
of a program by a proposition, 103
Rule, 7
axiom, 20
cut, 119
effective, 61
elimination, 20
introduction, 20
left, 118
resolution, 138
rewriting, 72
right, 118
Russell’s paradox, 25
S
SAT, 98
Satisﬁable, 98

Index
155
Schema
comprehension, 24
induction, 24
proof, 131
replacement, 26
separation, 26
Semi-decidable, 57
Sequent, 18
multi-conclusion, 30
Sequent calculus, 118
without cuts, 127
Set
empty, 26
hereditarily ﬁnite, 38
Sort
expression sort, 12
term sort, 16
State, 92
ﬁnal, 92
initial, 92
Substitution, 13
composition, 15
Symbol
function, 17
predicate, 17
T
Term, 17
isolated, 90
Termination, 72
in computability, 65
of a sequence of small steps, 71
strong, 80
Theorem, 22
Theory, 21
binary classes, 25
classes, 24
naive set theory, 25
Zermelo-Fraenkel set theory, 25
Turing machine, 92
non deterministic, 98
Typing context, 146
U
Uniﬁcation, 133
V
Valid, 37
Valuation, 36
Value of a program, 65
Variable, 11
capture, 14
free, 13
of an expression, 13
W
Well founded, 80
Witness
Henkin’s, 41
property, 143
Z
ZF, 25

