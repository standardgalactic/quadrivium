
Mobile SmartLife
via Sensing,
Localization, and
Cloud Ecosystems


Mobile SmartLife
via Sensing,
Localization, and
Cloud Ecosystems
Kaikai Liu and Xiaolin Li

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2018 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed on acid-free paper
Version Date: 20171108
International Standard Book Number-13:  978-1-4987-3234-5 (Hardback)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been 
made to publish reliable data and information, but the author and publisher cannot assume responsibility for the 
validity of all materials or the consequences of their use. The authors and publishers have attempted to trace the 
copyright holders of all material reproduced in this publication and apologize to copyright holders if permission to 
publish in this form has not been obtained. If any copyright material has not been acknowledged please write and 
let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or 
utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including 
photocopying, microfilming, and recording, or in any information storage or retrieval system, without written 
permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com 
(http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, 
Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for 
a variety of users. For organizations that have been granted a photocopy license by the CCC, a separate system of 
payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only 
for identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com
Library of Congress Cataloging-in-Publication Data
Names: Liu, Kaikai, author. | Li, Xiaolin, author.
Title: Mobile smartlife via sensing, localization, and cloud ecosystems / 
Kaikai Liu and Xiaolin Li.
Description: Boca Raton : CRC Press, 2017. | Includes bibliographical 
references and index.
Identifiers: LCCN 2016043423| ISBN 9781498732345 (hbk) | ISBN 9781498732369 
(ebk)
Subjects: LCSH: Ubiquitous computing. | Mobile computing. | Indoor 
positioning systems (Wireless localization) | Cloud computing. | Sensor 
networks.
Classification: LCC QA76.5915 .L56 2017 | DDC 004--dc23
LC record available at https://lccn.loc.gov/2016043423

Dedicated to my beloved
and everyone who has helped me along the way


Contents
List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
xv
List of Tables
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
xxi
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxiii
Author Bios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxvii
1
INTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . .
1
Kaikai Liu and Xiaolin Li
1.1
Mobile SmartLife: An Overview
. . . . . . . . . . . . . . . .
1
1.2
Location Matters
. . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
Application Scenarios
. . . . . . . . . . . . . . . . . . . . . .
3
1.3.1
Helping the Blind
. . . . . . . . . . . . . . . . . . . .
3
1.3.2
Context-Awareness Information Accessing . . . . . . .
5
1.3.3
Locating Lost Children
. . . . . . . . . . . . . . . . .
6
1.4
Research Challenges . . . . . . . . . . . . . . . . . . . . . . .
7
1.5
Book Organization . . . . . . . . . . . . . . . . . . . . . . . .
9
2
Overview of Mobile Systems . . . . . . . . . . . . . . . . . .
11
Kaikai Liu and Xiaolin Li
2.1
Overview of Location Sensing Techniques
. . . . . . . . . . .
12
2.2
Overview of TOA-Based Smartphone Localization Approaches
13
2.3
Architecture of the Proposed Localization System
. . . . . .
16
2.4
Hardware Design for Sensors, Anchor Nodes, and Wearables
18
2.4.1
Design Requirement and Overview . . . . . . . . . . .
18
2.4.2
Hardware Design and Architecture . . . . . . . . . . .
18
2.5
Cloud Architecture
. . . . . . . . . . . . . . . . . . . . . . .
20
vii

viii
■
Contents
3
Acoustic Ranging and Communication . . . . . . . . . . . .
23
Kaikai Liu and Xiaolin Li
3.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
24
3.2
System Architecture . . . . . . . . . . . . . . . . . . . . . . .
25
3.3
Transmitter Signal Design and Modeling
. . . . . . . . . . .
25
3.3.1
Signal Modeling
. . . . . . . . . . . . . . . . . . . . .
25
3.3.2
Acoustic Beacon Generation . . . . . . . . . . . . . . .
27
3.3.3
Signal and Interference . . . . . . . . . . . . . . . . . .
27
3.3.4
Realtime Filtering and Wavelet Denoising . . . . . . .
28
3.4
Acoustic Receiver Design
. . . . . . . . . . . . . . . . . . . .
29
3.4.1
Acoustic Receiver Signal Modeling . . . . . . . . . . .
29
3.4.2
Hypothesis Test for Symbol Synchronization
. . . . .
29
3.4.3
Symbol Synchronization . . . . . . . . . . . . . . . . .
30
3.5
TOA Estimation . . . . . . . . . . . . . . . . . . . . . . . . .
32
3.5.1
Spectrum Matching
. . . . . . . . . . . . . . . . . . .
32
3.5.2
Cluster Detection . . . . . . . . . . . . . . . . . . . . .
34
3.5.3
TOA Estimation Procedure . . . . . . . . . . . . . . .
35
3.5.4
Maximizing the Right Detection Probability . . . . . .
35
3.6
Acoustic Symbol Demodulation
. . . . . . . . . . . . . . . .
37
3.6.1
Challenges of Audible-Band Communication
. . . . .
37
3.6.2
Communication Demodulation
. . . . . . . . . . . . .
38
3.6.3
Dynamic Demodulation with Transmit Reference . . .
39
3.7
Performance Evaluation . . . . . . . . . . . . . . . . . . . . .
43
3.7.1
Experiment Setup
. . . . . . . . . . . . . . . . . . . .
43
3.7.2
Experimental Results
. . . . . . . . . . . . . . . . . .
44
3.7.3
Communication and Ranging Results
. . . . . . . . .
46
3.8
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
4
Localization Algorithms . . . . . . . . . . . . . . . . . . . . .
49
Kaikai Liu and Xiaolin Li
4.1
Trilateration via Relative Distance . . . . . . . . . . . . . . .
50
4.1.1
Relative Distance from Anchor Nodes
. . . . . . . . .
50
4.1.2
Joint Estimation of the Position and Unknown Bias
.
51
4.2
Mobile Phone Localization via Semideﬁnite Programming . .
55
4.2.1
Localization Measurement Model . . . . . . . . . . . .
55
4.2.2
Min-Max Criterion . . . . . . . . . . . . . . . . . . . .
56
4.2.3
Semideﬁnite Programming . . . . . . . . . . . . . . . .
57
4.3
Performance Bound and Anchor Network Coverage
. . . . .
58
4.3.1
Fisher Information Matrix . . . . . . . . . . . . . . . .
58
4.3.2
Cramer-Rao Low Bound . . . . . . . . . . . . . . . . .
58
4.3.3
Anchor Network Coverage . . . . . . . . . . . . . . . .
59
4.4
Position Reﬁnement
. . . . . . . . . . . . . . . . . . . . . . .
60
4.4.1
NLOS and Error Mitigation . . . . . . . . . . . . . . .
60
4.4.2
Steepest Descent Approach . . . . . . . . . . . . . . .
61
4.4.3
Coverage Constraint . . . . . . . . . . . . . . . . . . .
62

Contents
■
ix
4.5
Numerical Results
. . . . . . . . . . . . . . . . . . . . . . . .
62
4.6
Experimental Evaluation
. . . . . . . . . . . . . . . . . . . .
65
4.6.1
Experiment Setup for Localization . . . . . . . . . . .
65
4.6.2
Localization Results . . . . . . . . . . . . . . . . . . .
66
4.7
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
5
Guoguo: Enabling Fine-Grained Smartphone Localization
71
Kaikai Liu, Xinxin Liu, and Xiaolin Li
5.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
72
5.2
System Design
. . . . . . . . . . . . . . . . . . . . . . . . . .
74
5.2.1
Motivation
. . . . . . . . . . . . . . . . . . . . . . . .
74
5.2.2
Design Challenges and Considerations . . . . . . . . .
74
5.2.3
System Architecture . . . . . . . . . . . . . . . . . . .
76
5.3
Anchor Network Design . . . . . . . . . . . . . . . . . . . . .
76
5.3.1
Design Criterion
. . . . . . . . . . . . . . . . . . . . .
77
5.3.2
Anchor Node Hardware Design . . . . . . . . . . . . .
77
5.3.3
Transmitter Waveform Design and Modulation . . . .
78
5.3.4
High Density Pseudocode Sequence . . . . . . . . . . .
79
5.3.5
Anchor Network Synchronization . . . . . . . . . . . .
80
5.3.6
Symbol-Interleaved Beacon Structure . . . . . . . . . .
81
5.4
Smartphone Localization
. . . . . . . . . . . . . . . . . . . .
82
5.4.1
Design Workﬂow . . . . . . . . . . . . . . . . . . . . .
82
5.4.2
Symbol Detection and Demodulation . . . . . . . . . .
82
5.4.3
TOA Estimation . . . . . . . . . . . . . . . . . . . . .
83
5.4.4
Acoustic Beacon Synchronization and Code Matching
84
5.4.5
Distance Update . . . . . . . . . . . . . . . . . . . . .
85
5.4.6
Location Estimation . . . . . . . . . . . . . . . . . . .
86
5.5
Error Pruning Techniques . . . . . . . . . . . . . . . . . . . .
87
5.5.1
Signal Level Resistance
. . . . . . . . . . . . . . . . .
87
5.5.2
Track before Localization . . . . . . . . . . . . . . . .
87
5.5.3
Location Tracking
. . . . . . . . . . . . . . . . . . . .
89
5.6
Performance Evaluation . . . . . . . . . . . . . . . . . . . . .
89
5.6.1
Sound Pressure Level Measurement . . . . . . . . . . .
90
5.6.2
Maximum Operation Distance
. . . . . . . . . . . . .
90
5.6.3
Localization in Oﬃce Environments
. . . . . . . . . .
91
5.6.4
Localization in Classroom Environments . . . . . . . .
95
5.6.5
Impact of Anchor Numbers and Locations . . . . . . .
97
5.6.6
Moving Traces
. . . . . . . . . . . . . . . . . . . . . .
99
5.6.7
System Evaluation . . . . . . . . . . . . . . . . . . . .
100
5.7
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
101

x
■
Contents
6
Enhancing Location Accuracy and Robustness via Oppor-
tunistic Sensing . . . . . . . . . . . . . . . . . . . . . . . . . .
103
Kaikai Liu and Xiaolin Li
6.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
104
6.2
System Overview
. . . . . . . . . . . . . . . . . . . . . . . .
105
6.2.1
Motivation
. . . . . . . . . . . . . . . . . . . . . . . .
105
6.2.2
System Design
. . . . . . . . . . . . . . . . . . . . . .
106
6.3
Displacement and Motion Estimation
. . . . . . . . . . . . .
107
6.3.1
Principle of Inertial Navigation . . . . . . . . . . . . .
107
6.3.1.1
Coordinate System . . . . . . . . . . . . . . .
107
6.3.1.2
Rotation Estimation . . . . . . . . . . . . . .
108
6.3.1.3
Coordinate Transformation . . . . . . . . . .
109
6.3.2
Displacement Estimation
. . . . . . . . . . . . . . . .
109
6.3.3
Mitigating Displacement Estimation Error . . . . . . .
111
6.3.3.1
Apply Constraint via Activity Results . . . .
111
6.3.3.2
Gaussian Derivative Decomposition
. . . . .
112
6.4
Absolute Location Estimation with Fewer Anchors . . . . . .
112
6.4.1
Background and Basic Procedures
. . . . . . . . . . .
112
6.4.2
Improving the Location Accuracy via Constraints . . .
114
6.4.2.1
Initial Location
. . . . . . . . . . . . . . . .
114
6.4.2.2
Measurements
. . . . . . . . . . . . . . . . .
114
6.4.2.3
Location Optimization
. . . . . . . . . . . .
116
6.5
Trilateration via Semideﬁnite Programming . . . . . . . . . .
117
6.5.1
Min-Max Criterion . . . . . . . . . . . . . . . . . . . .
118
6.5.2
Delay-Constraint Robust Semideﬁnite Programming .
118
6.5.3
Improving Indoor Localization via Sensor Fusion . . .
120
6.6
Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . .
121
6.6.1
System Evaluation . . . . . . . . . . . . . . . . . . . .
121
6.6.2
Displacement Estimation
. . . . . . . . . . . . . . . .
121
6.6.3
Ranging Estimation
. . . . . . . . . . . . . . . . . . .
122
6.6.4
Improving Location Accuracy with Fewer Anchors . .
123
6.6.5
Trilateration via Semideﬁnite Programming . . . . . .
125
6.6.6
Location Fusion
. . . . . . . . . . . . . . . . . . . . .
125
6.7
Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . .
126
6.8
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
128
7
Pushing Location Awareness to Context-Aware Augmented
Reality
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
129
Kaikai Liu and Xiaolin Li
7.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
130
7.2
System Design
. . . . . . . . . . . . . . . . . . . . . . . . . .
132
7.2.1
Application Overview
. . . . . . . . . . . . . . . . . .
132
7.2.2
System Model and Terminology Deﬁnition . . . . . . .
132
7.3
Attitude and Location Trace Estimation
. . . . . . . . . . .
135
7.3.1
Attitude Estimation . . . . . . . . . . . . . . . . . . .
136

Contents
■
xi
7.3.1.1
State-of-the-Art Approaches
. . . . . . . . .
136
7.3.1.2
Attitude Error Reduction . . . . . . . . . . .
137
7.3.2
Displacement Estimation
. . . . . . . . . . . . . . . .
139
7.3.2.1
Challenges
. . . . . . . . . . . . . . . . . . .
139
7.3.2.2
Existing Approaches . . . . . . . . . . . . . .
140
7.3.2.3
Mitigating Displacement Error . . . . . . . .
141
7.3.3
Smartphone Localization
. . . . . . . . . . . . . . . .
143
7.4
Projecting and Tracking the AR View . . . . . . . . . . . . .
145
7.4.1
POI Detection and Relative Pose Estimation
. . . . .
145
7.4.1.1
POI Detection via Image Feature Detection
and Matching
. . . . . . . . . . . . . . . . .
145
7.4.1.2
Initial Relative Pose Estimation
. . . . . . .
145
7.4.1.3
Homography Relation . . . . . . . . . . . . .
146
7.4.2
Mapping the POI to the Screen . . . . . . . . . . . . .
147
7.4.3
Projecting the AR View . . . . . . . . . . . . . . . . .
148
7.4.4
AR View Tracking . . . . . . . . . . . . . . . . . . . .
148
7.4.4.1
Problems . . . . . . . . . . . . . . . . . . . .
148
7.4.4.2
Vision Tracking and Adaptive Rate Control .
149
7.5
Evaluation
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
149
7.5.1
Displacement Estimation
. . . . . . . . . . . . . . . .
150
7.5.2
Absolute Location Estimation . . . . . . . . . . . . . .
152
7.5.3
Attitude Estimation . . . . . . . . . . . . . . . . . . .
153
7.5.4
POI Image Matching and Relative Pose Estimation . .
153
7.5.5
Mapping the POI to the Screen . . . . . . . . . . . . .
154
7.5.6
On-Screen AR View Detection and Tracking
. . . . .
155
7.5.7
AR View Tracking via Adaptive Frame Rate
. . . . .
157
7.5.8
Comparison with Existing Apps
. . . . . . . . . . . .
158
7.6
Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . .
160
7.7
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
162
8
Towards Location-Aware Mobile Social Networks with Mis-
sions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
163
Kaikai Liu and Xiaolin Li
8.1
Application Description
. . . . . . . . . . . . . . . . . . . . .
164
8.2
Innovation and/or Uniqueness in Marketing . . . . . . . . . .
165
8.3
Key Design Features . . . . . . . . . . . . . . . . . . . . . . .
165
8.3.1
User Management
. . . . . . . . . . . . . . . . . . . .
166
8.3.2
Connecting Friends and Messaging . . . . . . . . . . .
166
8.3.3
Managing Social Groups . . . . . . . . . . . . . . . . .
166
8.3.4
Group Auto Check-In . . . . . . . . . . . . . . . . . .
168
8.3.5
Sensing and Tracking Nearby Friends
. . . . . . . . .
168
8.4
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
169

xii
■
Contents
9
Wearable Localization via Mobile Crowd Sensing
. . . . .
171
Kaikai Liu and Xiaolin Li
9.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
172
9.2
System Overview
. . . . . . . . . . . . . . . . . . . . . . . .
174
9.2.1
Design Considerations . . . . . . . . . . . . . . . . . .
174
9.2.2
System Design
. . . . . . . . . . . . . . . . . . . . . .
175
9.3
Mobile Crowd Sensing via Multi-Hop Assistance
. . . . . . .
177
9.3.1
Models and Protocols
. . . . . . . . . . . . . . . . . .
177
9.3.2
Balance the False-Alarm and Detection Rates . . . . .
178
9.3.3
Crowd Localization . . . . . . . . . . . . . . . . . . . .
179
9.4
Improving Crowd Sensing Accuracy via Semideﬁnite Program-
ming
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
182
9.4.1
Challenges
. . . . . . . . . . . . . . . . . . . . . . . .
182
9.4.2
Cases of Insuﬃcient Measurements . . . . . . . . . . .
183
9.4.3
Problem Formulation for Crowd Sensing SDP . . . . .
185
9.4.4
Location Optimization via Semideﬁnite Programming
185
9.4.5
Virtual Anchor Assistance . . . . . . . . . . . . . . . .
187
9.5
Evaluation
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
188
9.5.1
Simulation
. . . . . . . . . . . . . . . . . . . . . . . .
188
9.5.2
System Implementation . . . . . . . . . . . . . . . . .
189
9.5.3
Experiment . . . . . . . . . . . . . . . . . . . . . . . .
191
9.6
Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . .
193
9.7
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
196
10 Improving Location Services via Social Collaboration . . .
197
Kaikai Liu, Qiuyuan Huang, Jiecong Wang, Xiaolin Li, and Dapeng
Oliver Wu
10.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
198
10.2 Preliminary . . . . . . . . . . . . . . . . . . . . . . . . . . . .
200
10.2.1 Use Cases . . . . . . . . . . . . . . . . . . . . . . . . .
200
10.2.2 Relative Ranging . . . . . . . . . . . . . . . . . . . . .
201
10.3 System Design
. . . . . . . . . . . . . . . . . . . . . . . . . .
201
10.3.1 Design Consideration
. . . . . . . . . . . . . . . . . .
201
10.3.2 System Overview . . . . . . . . . . . . . . . . . . . . .
202
10.4 Crowd Sensing and Ranging Condition
. . . . . . . . . . . .
203
10.4.1 Crowd Cooperative Setting and Protocol
. . . . . . .
203
10.4.2 Geo-Coordinate . . . . . . . . . . . . . . . . . . . . . .
205
10.4.3 Mathematical Modeling . . . . . . . . . . . . . . . . .
206
10.4.4 Crowd Clustering and Co-Location Detection . . . . .
207
10.4.5 Necessary Conditions for Relative Ranging
. . . . . .
209
10.5 Cooperative Location Optimization
. . . . . . . . . . . . . .
211
10.5.1 Sparse Steepest Descent Optimization . . . . . . . . .
211
10.5.2 Weighting Center-Based Polar Optimization . . . . . .
213
10.6 Numerical Results
. . . . . . . . . . . . . . . . . . . . . . . .
214
10.7 Experimental Validation
. . . . . . . . . . . . . . . . . . . .
215

Contents
■
xiii
10.7.1 System Implementation . . . . . . . . . . . . . . . . .
215
10.7.2 Experiment Setup
. . . . . . . . . . . . . . . . . . . .
216
10.7.3 Case Study I: Stationary Users . . . . . . . . . . . . .
216
10.7.4 Case Study II: Moving Users
. . . . . . . . . . . . . .
218
10.8 Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . .
219
10.9 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
221
11 Hiding Media Data via Shaders: Enabling Private Sharing in
the Clouds . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
223
Kaikai Liu and Xiaolin Li
11.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
224
11.2 System Model
. . . . . . . . . . . . . . . . . . . . . . . . . .
225
11.2.1 Problem Statement . . . . . . . . . . . . . . . . . . . .
225
11.2.2 Threat Model and Assumption . . . . . . . . . . . . .
226
11.2.3 Compatible with Existing Cloud Services
. . . . . . .
226
11.2.4 Format-Compliant and Compression-Independent Solu-
tions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
226
11.3 System Design
. . . . . . . . . . . . . . . . . . . . . . . . . .
227
11.3.1 Design Objective . . . . . . . . . . . . . . . . . . . . .
227
11.3.2 Proposed Approach
. . . . . . . . . . . . . . . . . . .
227
11.4 Privacy Protection Algorithm Design
. . . . . . . . . . . . .
228
11.4.1 Design Principles . . . . . . . . . . . . . . . . . . . . .
228
11.4.2 Chaotic Mapping . . . . . . . . . . . . . . . . . . . . .
229
11.4.2.1 Pros and Cons of Chaotic Mapping
. . . . .
229
11.4.2.2 Generalized Low-Order Chaotic Mapping . .
229
11.4.3 Whitening and Probabilistic Transformation
. . . . .
231
11.4.4 Multi-Channel Block Substitution via Latin Square . .
232
11.4.5 Security Analysis . . . . . . . . . . . . . . . . . . . . .
233
11.5 Evaluation
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
233
11.5.1 System Evaluation . . . . . . . . . . . . . . . . . . . .
233
11.5.1.1 Media Sharing Process
. . . . . . . . . . . .
233
11.5.1.2 Computational Complexity . . . . . . . . . .
234
11.5.2 Security Analysis . . . . . . . . . . . . . . . . . . . . .
235
11.5.2.1 Whitening and Probabilistic Transformation
235
11.5.2.2 Multi-Channel Block Substitution . . . . . .
236
11.5.2.3 Overall Security Level . . . . . . . . . . . . .
237
11.5.3 Correlation Preserving and Noise Robustness . . . . .
237
11.6 Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . .
239
11.7 Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
240
12 CONCLUSION AND FUTURE DIRECTIONS
. . . . . .
243
Kaikai Liu and Xiaolin Li
12.1 Book Summary
. . . . . . . . . . . . . . . . . . . . . . . . .
243
12.2 Future Directions
. . . . . . . . . . . . . . . . . . . . . . . .
245

xiv
■
Contents
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
261

List of Figures
1.1
Envisioned smartlife ecosystem. . . . . . . . . . . . . . . . .
9
2.1
Related localization systems from academia. . . . . . . . . .
16
2.2
Related localization systems from companies. . . . . . . . .
17
2.3
System architecture. . . . . . . . . . . . . . . . . . . . . . .
18
2.4
The designed hardware node version 1. . . . . . . . . . . . .
19
2.5
The designed hardware node version 2. . . . . . . . . . . . .
20
2.6
The architecture of the cloud backend. . . . . . . . . . . . .
21
3.1
The system architecture. . . . . . . . . . . . . . . . . . . . .
26
3.2
Energy spectrum density for three diﬀerent cases: (a) no
acoustic beacon signal, (b) with acoustic beacon, and (c) with
sound interference and acoustic beacon. . . . . . . . . . . .
27
3.3
Time-domain waveform: (a) system input, (b) after normal
FIR and wavelet processing, (c) after FIR and wavelet pro-
cessing with boundary calibration. . . . . . . . . . . . . . .
28
3.4
The energy spectral density for the cases of (a) pure noises,
(b) interference, and (c) signal. . . . . . . . . . . . . . . . .
33
3.5
(a) Initial time-domain waveform of two clusters, (b) ESD of
the ﬁrst cluster, and (c) ESD of the second cluster. . . . . .
34
3.6
The SNR (a), NMSE (b) and BER (c) measurement results
with respect to the distance.
. . . . . . . . . . . . . . . . .
44
3.7
The relative range results (a) and beacon period estimation
results (b) when a smartphone is placed in Env1(1.68, 1.02)m. 47
4.1
Comparison of LS approaches to SDP and revised SDP algo-
rithms when the mobile phone is in ﬁxed position of [30, 20]
(a) and random position with x and y distributed between
(20, 80) (b). . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
xv

xvi
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
4.2
Cumulative distribution of LS approaches to SDP and revised
SDP algorithms when the mobile phone is in [30, 20], 1/σ2 =
−10dB (a) and 1/σ2 = 10dB (b). . . . . . . . . . . . . . . .
64
4.3
The CRLB of the position estimation with 8 anchor nodes
and 1/σ2 = 10dB when the mobile phone is placed at diﬀer-
ent positions. . . . . . . . . . . . . . . . . . . . . . . . . . .
65
4.4
The experiment environment. . . . . . . . . . . . . . . . . .
66
4.5
The CRLB of the position estimation for the experiment en-
vironment when the ranging accuracy is assumed as 2cm. .
66
4.6
Cumulative distribution of LS approaches to SDP and revised
SDP algorithms when the mobile phone is in [5.13, 1.08] (a)
and [5.5, 1.4] (b) by using experimental data. . . . . . . . .
67
4.7
The localization accuracy of diﬀerent algorithms with 80%
probability when the mobile phone is placed near Pos1
[5.13, 1.08]m and Pos2 [5.5, 1.4]m.
. . . . . . . . . . . . . .
68
4.8
The time series (a) and CDF (b) of localization error at dif-
ferent spots. . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
4.9
Three diﬀerent moving traces. . . . . . . . . . . . . . . . . .
69
5.1
Conceptual architecture of the Guoguo System. . . . . . . .
75
5.2
Guoguo anchor node vs. quarter. . . . . . . . . . . . . . . .
77
5.3
Ranging results for (a) stationary and (b) moving users. . .
88
5.4
(a) The perception level of human ears; (b) comparison of
sound pressure level in four scenarios.
. . . . . . . . . . . .
90
5.5
Signal level (dBA) in an aisle.
. . . . . . . . . . . . . . . .
91
5.6
Ranging accuracy in an aisle. . . . . . . . . . . . . . . . . .
91
5.7
Experiment setup in an oﬃce environment. . . . . . . . . .
92
5.8
The localization accuracy in an oﬃce environment under (a)
no SI; (b) with SI. . . . . . . . . . . . . . . . . . . . . . . .
93
5.9
Measured performance metrics of ranging rate (a), miss rate
(b), and average update time (c) for diﬀerent measurements
in an oﬃce environment. . . . . . . . . . . . . . . . . . . . .
94
5.10
1) Localization accuracy in diﬀerent cases; 2) obtained loca-
tion results as scatters.
. . . . . . . . . . . . . . . . . . . .
94
5.11
The experiment setup in a classroom environment. . . . . .
95
5.12
The scatters (a) and CDF (b) of the localization results in a
classroom environment.
. . . . . . . . . . . . . . . . . . . .
96
5.13
The CDF of the background sound (a) and localization error
(b) in a classroom environment. . . . . . . . . . . . . . . . .
96
5.14
Measured performance metrics of ranging rate (a), miss rate
(b), and average update time (c) for diﬀerent measurements
in a classroom environment. . . . . . . . . . . . . . . . . . .
97
5.15
Localization error for diﬀerent measurements in a classroom
environment. . . . . . . . . . . . . . . . . . . . . . . . . . .
98

List of Figures
■
xvii
5.16
(a) Ranging accuracy for 8 anchor nodes; (b) localization ac-
curacy with respect to anchor numbers. . . . . . . . . . . .
98
5.17
Pseudorange results from multiple anchors of a moving user:
a) without error-pruning; b) with error-pruning.
. . . . . .
99
5.18
Location traces of a moving user: a) without error-pruning;
b) with error-pruning. . . . . . . . . . . . . . . . . . . . . .
100
5.19
Energy consumption rate, CPU activity, and network activity
generated by Xcode Instrument.
. . . . . . . . . . . . . . .
100
6.1
System architecture. . . . . . . . . . . . . . . . . . . . . . .
106
6.2
Motion estimation result via conventional method: (a) accel-
eration, (b) velocity, (c) displacement. . . . . . . . . . . . .
110
6.3
Location estimation via single anchor. . . . . . . . . . . . .
115
6.4
TOA ranging results in two diﬀerent situations: (a) user is
moving away from the anchor; (b) user is moving close to the
anchor (bin is the sampling points).
. . . . . . . . . . . . .
116
6.5
Anchor deployment and experiment environment. . . . . . .
121
6.6
Motion estimation result via proposed method: (a) accelera-
tion, (b) velocity, (c) displacement. . . . . . . . . . . . . . .
122
6.7
Ranging rate and ranging error rate in an aisle environment.
123
6.8
Ranging accuracy.
. . . . . . . . . . . . . . . . . . . . . . .
124
6.9
The location error when the anchor number is m = 0 ∼2 in
(a) outdoor and (b) indoor environments. . . . . . . . . . .
124
6.10
Cumulative distribution of diﬀerent algorithms when the mo-
bile phone is in: (a) [5.13, 1.08] and (b) [5.5, 1.4] by using
experimental data with 6 anchors.
. . . . . . . . . . . . . .
125
6.11
(a) Ranging results; (b) localization results. . . . . . . . . .
126
6.12
The Kalman fusion results for location estimation in two
cases.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
7.1
Overview of the proposed AR application. . . . . . . . . . .
132
7.2
System model and coordinate system. . . . . . . . . . . . .
133
7.3
Camera mapping system. . . . . . . . . . . . . . . . . . . .
134
7.4
Moving trace and attitude estimation. . . . . . . . . . . . .
135
7.5
AR view projecting and tracking. . . . . . . . . . . . . . . .
136
7.6
Attitude under (a) large rotation; (b) small sway. . . . . . .
137
7.7
Attitude via IMM under (a) large rotation; (b) small sway.
139
7.8
Motion estimation result via conventional method: (a) accel-
eration, (b) velocity, (c) displacement. . . . . . . . . . . . .
140
7.9
Motion estimation result via ATAD: (a) acceleration, (b) ve-
locity, (c) displacement. . . . . . . . . . . . . . . . . . . . .
142
7.10
Motion estimation result via GDD: (a) acceleration, (b) ve-
locity, (c) displacement. . . . . . . . . . . . . . . . . . . . .
143
7.11
Indoor AR App and screenshots. . . . . . . . . . . . . . . .
150
7.12
Anchor deployment and experiment environment. . . . . . .
151

xviii
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
7.13
Estimated moving traces for line and rectangular moving pat-
terns.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
7.14
The attitude and AR view trace results. . . . . . . . . . . .
152
7.15
The fusion results for moving location estimation in two cases
(the ground truth is a rectangle). . . . . . . . . . . . . . . .
153
7.16
The comparision of a) initial Euler angle, and b) optimized
Euler angle. . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
7.17
Illustrating relative poses for diﬀerent images in 3D space. .
155
7.18
Displacement in vertical.
. . . . . . . . . . . . . . . . . . .
155
7.19
Displacement in horizontal. . . . . . . . . . . . . . . . . . .
156
7.20
The attitude and AR view tracking result. . . . . . . . . . .
156
7.21
a) Estimated AR view trace; b) execution time for each frame. 158
7.22
Energy and CPU activity proﬁle with high frame rate. . . .
158
7.23
a) Estimated AR view trace; b) execution time for each frame. 159
7.24
Energy and CPU activity proﬁle with adaptive frame rate.
159
7.25
The comparison of energy usage, and cpu activity for diﬀerent
apps. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
160
7.26
The drift problem of Layar, and the short distance problem
of Vuforia. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
160
7.27
AR view tracking results via diﬀerent methods. . . . . . . .
160
8.1
System architecture. . . . . . . . . . . . . . . . . . . . . . .
164
8.2
User management. . . . . . . . . . . . . . . . . . . . . . . .
166
8.3
Contacts and mobile messaging between friends.
. . . . . .
167
8.4
(a) Group detail; (b) add and search group; (c) new group;
(d) search groups.
. . . . . . . . . . . . . . . . . . . . . . .
167
8.5
(a) Enable group beacon; (b) enable auto check-in; (c) auto
post check-in to group; (d) sharing location. . . . . . . . . .
168
8.6
(a) Sense friend nearby; (b) friend received request; (c)
rReceived acknowledgement from friend; (d) tracking friend.
169
9.1
System architecture. . . . . . . . . . . . . . . . . . . . . . .
175
9.2
FindingNemo protocol.
. . . . . . . . . . . . . . . . . . . .
177
9.3
System conﬁguration.
. . . . . . . . . . . . . . . . . . . . .
180
9.4
The comparision of crowd sensing to trilateration and self-
localization. . . . . . . . . . . . . . . . . . . . . . . . . . . .
184
9.5
Localization accuracy via one-hop when Ma = 3 and Na =
3 for cases (a) without anchor error; (b) with anchor error
(σ2 = 2.25m). . . . . . . . . . . . . . . . . . . . . . . . . . .
188
9.6
Localization accuracy via one-hop when Ma = 2 and Na =
3 for cases (a) without anchor error; (b) with anchor error
(σ2 = 2.25m). . . . . . . . . . . . . . . . . . . . . . . . . . .
189
9.7
Localization accuracy via one-hop when Ma = 1 and Na =
3 for cases (a) without anchor error; (b) with anchor error
(σ2 = 2.25m). . . . . . . . . . . . . . . . . . . . . . . . . . .
190

List of Figures
■
xix
9.8
Localization accuracy via one-hop with anchor location error
(σ2 = 2.25m) for three cases. . . . . . . . . . . . . . . . . .
190
9.9
Basic functions of FindingNemo App.
. . . . . . . . . . . .
191
9.10
Developed system and experiment setting. . . . . . . . . . .
191
9.11
1) The CDF of the GPS error; 2) the ranging error with
distance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
192
9.12
Localization error for: 1) conventional SDP with diﬀerent
ranging sparse rates; 2) proposed SDP approach for crowd
sensing in diﬀerent cases.
. . . . . . . . . . . . . . . . . . .
193
9.13
Experimental localization accuracy via one-hop for two cases. 194
9.14
Experimental localization accuracy via one-hop for two cases. 195
9.15
Experimental localization accuracy via one-hop for three
cases.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
9.16
Experimental localization accuracy via one-hop for three
cases.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
196
10.1
System architecture. . . . . . . . . . . . . . . . . . . . . . .
202
10.2
System setting and protocol.
. . . . . . . . . . . . . . . . .
203
10.3
1. The input aﬃnity matrix of the clustering algorithms for
60 smartphone locations with three clusters; 2. the output of
normalized cuts clustering algorithm. . . . . . . . . . . . . .
208
10.4
(a) The relation between measurement variance and maxi-
mum allowable distance (peer-to-peer ranging is not neces-
sary). (b) The performance gains with regard to the relative
distance and variance. . . . . . . . . . . . . . . . . . . . . .
210
10.5
Numerical results with 12 users under σ = 1 and R = 2: (a)
initial positions, (b) reﬁned positions obtained by SSD with
γ = 0.73, and (c) reﬁned positions obtained by SSD γ = 0.
211
10.6
The 2-users case of using polar optimization, initial measure-
ment (a), after polar optimization (b) and CDF (c), σ = 0.3.
213
10.7
Numerical results with 12 users under σ = 1 and R = 2
(x and y-coordinates are in meters): (a) initial positions, (b)
reﬁned positions obtained by SSD, and (c) reﬁned positions
obtained by SSD+Polar. . . . . . . . . . . . . . . . . . . . .
215
10.8
The CDF of location accuracy under various processing types:
1. Using SSD with diﬀerent sparse rate of ranging; 2. using
joint optimization approaches of SSD and Polar. . . . . . .
216
10.9
The designed mobile social network. . . . . . . . . . . . . .
217
10.10
The comparison of energy usage, CPU activity, and network
activity before and after cooperation.
. . . . . . . . . . . .
218
10.11
Experimental results with 9 users (x and y-coordinate is in
meters): (a) initial positions obtained by GPS, (b) reﬁned
positions obtained by SSD, and (c) reﬁned positions obtained
by SSD+Polar. . . . . . . . . . . . . . . . . . . . . . . . . .
218

xx
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
10.12
1. The clustering results for the 9 users; 2. The CDF of loca-
tion accuracy under various processing types. . . . . . . . .
219
10.13
Experiment results of 4 user’s GPS trajectory when walking
around a parking lot.
. . . . . . . . . . . . . . . . . . . . .
220
10.14
Experiment results of 4 user’s GPS trajectory when walking
along a line. . . . . . . . . . . . . . . . . . . . . . . . . . . .
220
11.1
System Architecture. . . . . . . . . . . . . . . . . . . . . . .
228
11.2
Encrypted and decrypted image under diﬀerent orders of
chaotic map.
. . . . . . . . . . . . . . . . . . . . . . . . . .
230
11.3
The secure media sharing process.
. . . . . . . . . . . . . .
234
11.4
The execution time of diﬀerent approaches. . . . . . . . . .
235
11.5
Whitening via key image: 1) Key image; 2) Homogeneous
whitening via XOR mixing without PT; 3) non-homogenous
whitening via XOR mixing with PT. . . . . . . . . . . . . .
236
11.6
Color image after substition via diﬀerent color channels: 1)
red channel; 2) red and green channel; 3) all three channels.
236
11.7
The color histogram for (a) plaintext; (b) ciphertext. . . . .
237
11.8
The normalized correlation coeﬃcient for (a) encrypted im-
age; (b) decrypted image. . . . . . . . . . . . . . . . . . . .
238
11.9
The maximum normalized correlation coeﬃcient. . . . . . .
239
11.10
Robust to noise in transmission.
. . . . . . . . . . . . . . .
239

List of Tables
2.1
Comparison of Guoguo with existing localization techniques
15
3.1
Performance comparison with respect to diﬀerent methods
under speciﬁc probability . . . . . . . . . . . . . . . . . . .
45
3.2
BER and ranging NMSE results in diﬀerent distances
. . .
46
3.3
BER and ranging variance results for 4 anchor nodes
when a smartphone is placed in Env1(1.68, 1.02)m and
Env2(4.6, 1.03)m . . . . . . . . . . . . . . . . . . . . . . . .
46
4.1
The localization accuracy of diﬀerent algorithms with 80%
probability when the mobile phone is placed near Pos1
[5.13, 1.08]m and Pos2 [5.5, 1.4]m
. . . . . . . . . . . . . .
67
5.1
Notation
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
5.2
Experiment conﬁguration in an oﬃce environment (some an-
chors are not shown in the photo)
. . . . . . . . . . . . . .
92
5.3
Experiment conﬁguration in a classroom
. . . . . . . . . .
95
6.1
Notation
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
6.2
Performance comparison with respect to diﬀerent methods
under speciﬁc metrics
. . . . . . . . . . . . . . . . . . . . .
123
7.1
Performance comparison with respect to diﬀerent methods
under speciﬁc metrics
. . . . . . . . . . . . . . . . . . . . .
152
7.2
Comparison of execution time
. . . . . . . . . . . . . . . .
154
9.1
Experimental localization accuracy via one-hop when Ma = 0 194
xxi


Preface
Towards SmartLife Mobile Applications
Our lifestyle is changing dramatically with the ubiquity of mobile devices and
network connectivity. By seamlessly collecting advanced data related to human
activity, and providing responsive actions and services to users, developers can
maximize the functionality of mobile devices, thereby improving livability,
convenience and safety, and ultimately enabling a smart life. The spatial and
contextual data, i.e., users’ locations as well as their interaction with the cyber
and physical world, has been a decisive driver for the ongoing trend towards
smart and connected applications to date.
Context-aware location sensing is the cornerstone of this vision. Over the
past few years, a broad variety of services have been targeted to revolution-
ize how people sense and interact with everyday objects and locations to-
wards a smart life. For example, sensor networks provide realtime activity
data for heating/air conditioning systems and ﬁre and smoke detectors, GPS
and WLAN systems provide way-ﬁnding and coarse-grained location services,
RFID and short-range communication devices provide proximity detection
and awareness. However, these separate and usually proprietary systems are
far from satisfactory. The major metrics of these spatial enabling technolo-
gies, most notably accuracy, interoperability, and deployability performance,
are far from satisfactory. Signiﬁcant gaps exist in our understanding of how
a scalable location sensing system design could meet a multitude of smart
application demands. Moreover, no extensible and developer-friendly system
frameworks are available for location and smart applications. Developers do
not have any testbed or prototype system available for them to play with.
Senior developers are reluctant to extend and debug their existing prototype
infrastructures since the errors and software deﬁciencies are hard to identify
in the distributed manner. Large-scale deployment is rarely available and hard
to share with junior developers for partial or temporal development.
xxiii

xxiv
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Our overarching goal is to develop an intellectual framework and a location
infrastructure testbed to promote and guide the developers to realize the full-
ﬂedged smart applications for a smart lifestyle, to address societal challenges
in local communities. We aim to oﬀer a comprehensive book on a complete
mobile system design for SmartLife applications. This book is structured to
be a complete and updated guide for building the ecosystem step by step
from the hardware to mobile apps, to the cloud processing and service back-
end. Beginners can start from the initial introductory and tutorial chapters
while advanced readers can learn directly from the algorithms and prototype
design. Practitioners can ﬁnd inspiration for utilizing the proposed localization
techniques in a variety of mobile applications including shopping map, indoor
navigation, visitor guide, augmented reality, and location-based social-aided
sensing/sourcing.
We have tested and veriﬁed the information in this book to the best of
our ability, but you may ﬁnd that features have changed (which may in fact
resemble bugs). Please let us know about any errors you ﬁnd, as well as your
suggestions for future editions, by writing to the following address.
Please get in touch (kaikai.liu@sjsu.edu) if you know of services that are
missing, or have other questions or suggestions.
I hope this book will give you a good head start and that you have fun in
the process.
How This Book Is Organized
The main body of this book is divided into three parts: 1) ﬁne-grained smart-
phone indoor localization; 2) context-aware indoor augmented reality via sens-
ing and vision tracking; 3) large-scale localization via crowds and social col-
laboration.
In the ﬁrst part, we are focusing on ﬁne-grained localization techniques. We
design a complete indoor localization ecosystem (code-named Guoguo). The
Guoguo ecosystem consists of a set of indoor positioning satellites (IPS), an
app on a smartphone (iOS or Android) for opportunistic sensing (with IPS,
WiFi, BLE, and GPS), and a cloud server for oﬄoading heavy processing,
location services, and content management. Without any hardware burden or
attachment on a user’s smartphone, we could achieve centimeter-level ﬁne-
grained smartphone indoor localization.
In the second part, we push the ﬁne-grained indoor localization to context-
aware indoor augmented reality via sensor fusion and vision tracking. To re-
alize AR applications under various scales and dynamics, we propose a suite
of algorithms for ﬁne-grained AR view tracking, to improve the accuracy of
attitude and displacement estimation, reduce the drift, eliminate the marker,
and lower the computation cost. Instead of requiring extremely accurate abso-
lute locations, we propose multi-modal solutions according to mobility levels
without additional hardware requirements. Experimental results demonstrate

Preface
■
xxv
signiﬁcantly less error in projecting and tracking the AR view. These results
are expected to make users excited to explore their surroundings with enriched
content.
In the third part, we propose large-scale localization in social networks.
Leveraging the ubiquitousness of “crowds” of sensor-rich smartphones, we
design a cyber-physical mobile social network for smart life with the follow-
ing salient features: crowd sensing/sourcing, crowd localizing, cooperative lo-
calization, connecting friends socially and physically, dynamic location-based
check-in points, tracking nearby friends or team members or children/elders,
and mission-oriented groups.
Finally, Chapter 12 summarizes this book and points out some future work.
Acknowledgements
I would never have been able to ﬁnish this book without the guidance of
my advisor and Ph.d committee members, help from colleagues, co-authors
and friends, and support from my family. I would like to thank National Sci-
ence Foundation (NSF) for the funding support under the grant number CNS
1637371. I would like to express my deepest gratitude to my Ph.d advisor, Dr.
Xiaolin Andy Li, for his excellent assistance, encouragement, forward think-
ing, and providing me with an excellent research atmosphere that I can enjoy.
I would like to thank Dr. Yuguang Fang, who let me experience the research
in Wireless Networks Laboratory (WINET). I would also like to thank Dr.
Dapeng Wu for patiently correcting my writing, and helping me to develop
background in areas of wireless communication, network science, and com-
puter vision. I would also like to thank my co-authors, Xinxin Liu, Ze Yu,
Min Li, Qiuyuan Huang and Jiecong Wang for many valuable discussions.
Thanks for all the help I have received in writing and learning about this
book. I regret for errors or inadequacies that may remain in this work, and
the responsibility is entirely my own.
Last, and surely the most, I want to thank my family, for their love, self-
lessness, and sacriﬁce, not just this time, but so many times in my life. I would
thank them for their encouragement and letting me join the adventure and
the long lonely journey. I especially thank my wife Wenrong for being with
me in places that are far away from home, and going through all the hardness
in life together. I devote this book to all of you.


Author Bios
Dr. Kaikai Liu is an assistant professor in the Department of Computer En-
gineering since August 2015. His research interests include Mobile and Cyber-
Physical Systems (CPS), Smart and Intelligent Systems, Internet-of-Things
(IoT), Software-Deﬁned Computing and Networking. He has published over
20 peer-reviewed papers in journals and conference proceedings, 1 book, and
holds 4 patents (licensed by three companies). He developed several proto-
type systems that can potentially improve peoples lives, for example, emer-
gency communication system for smart city, Ultra-wideband communication
and detection for search and rescue victims, indoor localization and navigation
for the disabled. He is a recipient of the Outstanding Achievement Award at
UF (four times), the Apple WWDC Student Scholarship (2013 and 2014), the
Innovator Award from the Oﬃce of Technology Licensing at UF (2014), the
Top Team Award at NSF I-Corps Winter Cohort (Bay area, 2015), the 2015
Gator Engineering Attribute Award for Creativity at UF, IEEE SWC 2017
Best Paper Award, IEEE SECON 2016 Best Paper Award, ACM SenSys 2016
Best Demo - Runner up, 2016 CoE Kordestani Endowed Research Professor,
and 2017 CoE Research Professor Award. He served as the TPC member and
technical reviewers for many IEEE/ACM conferences and journals.
Dr. Xiaolin (Andy) Li is a Full Professor and University Term Professor
in Department of Electrical and Computer Engineering (ECE) and Depart-
ment of Computer & Information Science & Engineering (CISE, aﬃliated)
at University of Florida (UF). His research interests include Cloud Comput-
ing, Big Data, Deep Learning, Intelligent Platforms, HPC, and Security &
Privacy for Health, Precision Medicine, CPS/IoT, Science, Engineering, and
Business. He has published over 100 peer-reviewed papers in journals and
conference proceedings, 5 books, and 4 patents (three licensees). His team
has created many software systems and tools. He is the founding Director of
Large-scale Intelligent Systems Laboratory (Li Lab) and the founding Direc-
tor of National Science Foundation Center for Big Learning (CBL) with UF,
CMU, U. Oregon, and UMKC. His research has been sponsored by National
xxvii

xxviii
■Towards Mobile SmartLife via Sensing,Localization,& Cloud Ecosystems
Science Foundation (NSF), National Institutes of Health (NIH), Department
of Homeland Security (DHS), and others. He was a faculty member (with early
promotion and tenure) in the Computer Science Department at Oklahoma
State University (OSU), a visiting professor at Nokia Research Center Beijing
(NRC), a visiting scholar at University of Texas at Austin (UT), an Extreme
Blue intern at IBM, a graduate research assistant at Rutgers University (RU),
a research staﬀat Institute for Infocomm Research (I2R), a research scholar
at National University of Singapore (NUS), and a research assistant at Zhe-
jiang University (ZJU). He received a PhD degree in Computer Engineering
from Rutgers University under the direction of Professor Manish Parashar. He
is a recipient of the National Science Foundation CAREER Award in 2010,
the Internet2 Innovative Application Award in 2013, NSF I-Corps Top Team
Award (1 out of 24 teams, including Berkley, Harvard, and MIT) in 2015, Top
Team (DeepBipolar) in the CAGI Challenge on detecting bipolar disorder in
2016, and best paper awards (IEEE ICMLA 2016, IEEE SECON 2016, ACM
CAC 2013, and IEEE UbiSafe 2007).

Chapter 1
INTRODUCTION
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
1.1
Mobile SmartLife: An Overview .................................
1
1.2
Location Matters .................................................
2
1.3
Application Scenarios ............................................
3
1.3.1
Helping the Blind ........................................
3
1.3.2
Context-Awareness Information Accessing ..............
5
1.3.3
Locating Lost Children ..................................
6
1.4
Research Challenges ..............................................
7
1.5
Book Organization ...............................................
9
1.1
Mobile SmartLife: An Overview
Everyone interacts with the world diﬀerently — guided by their own attitudes,
their communities and families, and their smartphones with apps. Ever since
smartphones became a virtual assistant for us to interact with the world on the
move, mobile apps have never been proﬁcient at helping people gather together
virtually and informed of nearby and online updates and events. Mobile apps
such as Google Maps and FourSquare have long used location data to help us
sense and interact with our surroundings. These could be merely the tip of
the iceberg for our needs of location sensing. Our physical world, disconnected
1

2
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
from our devices, is waiting for smart connections to ﬁll the gap. Researchers
are excited about new technologies that could revolutionize how people sense
and interact with everyday objects and locations.
As one of the two most important contexts (time and location), location
is becoming a key entry for mobile Internet, which could navigate the elderly,
disabled, and children to their destination safely; welcome a customer into
a store with a personal message and recommendation; oﬀer an in-store deal
or deliver a coupon in the front of cereal boxes; deliver biographies or art
commentary on a speciﬁc object when visitors are wandering through a mu-
seum; remind users of social events in proximity. Ubiquitous smartphone and
location information are enabling these new mobile smartlife scenarios near a
certain object or location towards mobile smart life.
1.2
Location Matters
As one of the two key components of a mobile context (time and location),
localization has been the subject of extensive works ranging from algorithms,
models, supporting technologies, to systems and applications. Current coarse-
grained (room-level or meter-level) localization on a smartphone (based on
GPS) has enabled a lot of mobile services, such as location-based services,
maps, and navigation systems. Location information has inﬁltrated our ev-
eryday life in ways that we had not imagined at its start.
The vertical markets that are ripe for location have diﬀerent needs for
accuracy, cost, and speed. Diﬀerent Accuracy Requirements: Meter-
level (e.g., GPS with ﬁve-meter accuracy) localization is suﬃcient to navigate
a car (meter-level footprint), on a street (several-meter footprint); but it is
far from suﬃcient to navigate a user (foot-level footprint) in a library (with
half-meter-wide isles and inch-level books) or a shopping mall (with inch-level
items). With infrastructure already installed throughout the great indoors, the
easiest solution may appear to be Wi-Fi triangulation. While the cost may be
attractive, the accuracy is not precise enough for many apps. Various Costs:
With infrastructure already installed throughout the great indoors, the easiest
solution for shopping mall navigation may appear to be Wi-Fi ﬁngerprinting
approaches. While the cost may be attractive, the accuracy is barely suﬃcient
for diﬀerentiating diﬀerent stores. In-store navigation, e.g., shelf-to-shelf, re-
quires high-density deployment of location anchor nodes, which increases the
installation and operation cost signiﬁcantly. Speed in Terms of Latency
or Refresh Rate: Tens of seconds delay for outdoor navigation could lead
to wrong turn decision for drivers. Second-level delay still makes it hard to
get the complete moving trace of a basketball player for performance analysis
and evaluation.
Various promising location applications that are emerging include indoor
navigation, retail, advertising, manufacturing, asset tracking, gaming, intelli-
gence, and public safety. The indoor location market will be more enormous

INTRODUCTION
■
3
than the outdoor, since we spend more than 80% of time indoors in our daily
activities, e.g., working, shopping, eating, at the oﬃce, at home. However,
these services are severely limited when applying existing localization solu-
tions due to low accuracy, high cost, and low speed.
1.3
Application Scenarios
The ultimate aim of this work is to enable real-life applications that help
people live independently and conveniently in a smart way. Speciﬁcally, this
work narrows down the enabling techniques to three example applications:
1) helping the blind or other disabled to live independently; 2) accessing the
information automatically via context-awareness; 3) locating lost children or
other group members. These three applications require the assistance tech-
nique, safety guidance, and information recommendation, which pave the way
to the future smartlife mobile applications.
1.3.1
Helping the Blind
It is estimated that over one million persons in the U.S. are blind, and each
year 50,000 more will become blind [77]. China has the world’s top population
of the blind, about 5 million. Studies show that blindness, AIDS and cancer
are the top three fears of the people in the world [77].
The blind and visually impaired person faces two lifelong challenges: 1) ac-
cessing information; 2) navigating through space [118]. The second challenge,
which we are addressing in this work, links one’s ability to independently move
through the world. The blind face a multitude of challenges every day that
can prevent them from getting where they want to go, and even make the give
up places that are essential to their life, e.g., schools, clinics, retail stores, and
city facilities. The journey to public places is very daunting and leaves them
stressed and anxious.
Helping the blind and visually impaired people back to the mainstream
and employment has signiﬁcant social importance for the whole society. Mul-
tiple approaches are already proposed to help the blind live independently
like normal people. For example, the Americans with Disabilities Act (ADA)
requires places of public accommodation to ensure that everyone regardless
of disability has an equal opportunity to enjoy their services and facilities [3].
More speciﬁcally, some countries are requiring the construction of sidewalks
for the blind in urban planning. Using Beijing as an example, it owns the
longest sidewalk for the blind in the world, i.e., nearly 1600 km. The gov-
ernment and the whole society have a high motivation for creating an urban
environment that is suitable for everyone, including the disabed. However,
the blind sidewalk requires a vast investment in terms of construction and
maintenance. In Los Angeles, for example, 4,600 of the city’s 10,750 miles

4
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
of sidewalks need some degree of repair at an estimated cost of $1.2 billion
[2]. Even with the sidewalk in place, the coverage and utilization are still low.
Studies show that most of the blind sidewalks cannot connect the most visited
places for the blind, i.e., the hospital, the residence community, the school,
and most of the indoor area [100]. People spend most of their time indoors,
which is particularly true for the blind. However, most of the indoor places
do not have sidewalks or other related accessibility assistance techniques for
helping the blind.
Only using the sidewalk is not enough. With the advance of mobile tech-
nology, people are designing navigation devices or solutions for helping the
blind to visit unknown public places. When visiting outdoor places, e.g., city
streets, blind people can utilize existing GPS devices for navigation assis-
tance. There have been many attempts to integrate GPS technology into a
navigation-assistance system for blind and visually impaired people. Trekker
Breeze handheld talking GPS [36], as an example, verbally announces the
names of streets, intersections, and landmarks as blind people walk. It also
provides information on all street intersections and stops when the blind are in
a vehicle, which allows them to know where they are without missing the next
stop. With the popularity of GPS-enabled smartphones, multiple solutions
are proposed to leverage the general purpose device for navigation instead
of expensive stand-alone devices. MIPsoft’s BlindSquare is a GPS navigation
software for iPhone and iPad. It uses Foursquare for points of interest (POI)
and OpenStreetMap for street info [121]. However, these solutions are far from
practical enough due to various constraints: 1) the routes in Trekker Breeze
need to be recorded before they can be used, which limits the usability when
blind and people visiting some unknown public places; 2) the error of GPS
in city blocks may reach 28 meters for 95% of the time due to the so-called
“Urban Canyon” eﬀect [72]; 3) the nearby POI information is mostly static
without dynamic traﬃc and road blockage information; 4) verbal navigation
instructions are farless accurate than vision and maps due to positional am-
biguity, insuﬃcient interpretation, and missing ﬁne-grained context.
Once blind people move indoors, the GPS navigation device carried will
lose access to the required satellite signals, which becomes a nightmare for
them especially in unknown places. No matter how good the systems are out-
doors, their accuracy, coverage, and quality deteriorate signiﬁcantly in small-
scale indoor places. We spend more than 80% of our time indoors in our daily
activities, e.g., working, shopping, eating, at the oﬃce, at home. Practical,
robust, and accurate indoor location solutions are largely missing. In indoor
places, technology that can help the blind navigate with foot-level accuracy
is convenient. This has signiﬁcant implications for ﬁnding the door, restroom,
stair, entrance, and other key places. However, it is very hard to get the
ﬁne-grained location and sense the nearby objects in a room. Technologically,
outdoor localization techniques cannot be directly moved indoors. Current
GPS, cellular, and Wi-Fi-based localization techniques [6, 8, 15] are not re-
liable and ﬁne-grained enough when it comes to pinpointing an individual’s

INTRODUCTION
■
5
whereabouts, especially indoors. Despite signiﬁcant eﬀorts on indoor localiza-
tion in both academia and industry in the past two decades, highly accurate
and practical indoor localization remains an open problem. Alternative solu-
tions require barcode or RFID to be strategically placed around buildings,
and it is currently unrealistic to expect to ﬁnd such systems installed in many
places. Even with wide adoption, these technologies have their inherent limi-
tations. Existing devices like the omniscanner could help the blind record the
route and voice via UPC labels. This could add additional information for the
blind to remember diﬀerent places. However, scanning the UPC labels is not
convenient. Using RFID could have more freedom, but the resolution is very
low.
After the localization process, the blind’s navigation system should start
by establishing their location within the building, and on the map. It will
require voice input for the destination or purpose, and then determines the
best route or action to get them done, and guides them along it via verbal
cues and feedback. However, indoor navigation and interaction are far more
complex than outdoor GPS navigation via voice assistance, where the road
is clear and predeﬁned. There are so many obstacles, blockages, ﬂoors, and
routes in indoor places, e.g., door, staircase, elevator, and restricted areas.
The limitation of physical freedom caused by vision loss has the greatest
negative impact on human life. Our work aims to increase their conﬁdence in
visiting public place and taking new routes via our assistive technology. We
propose mobile solutions to help the blind navigate, socialize, and explore the
physical world better. It is a unique multi-modal eco-system with the follow-
ing salient features: ﬁne-grained step-by-step navigation, indoor navigation-
speciﬁc voice interaction, and a participatory social network for assistance.
With centimeter-level resolution for mapping their steps in the physical world,
we hope our technology can improve their independence to a new level, and
gradually help them to recover the hope of life and welcome the unknown
world.
1.3.2
Context-Awareness Information Accessing
Locating and digitizing of the physical world has become the next battle
for big brothers. Industry leaders are sketching out their forward vision for
computing and how we relate to our physical world by playing around with
context, especially locations. Major tech players are working in the context-
awareness approaches to bring users even more information super quickly,
without tedious manual typing and searching. Google Now and Apple Siri
are all context-awareness examples. In addition to we you are talking, Google
pushes context-awareness to the next level by proposing “Now on Tap” in
Google I/O 2015.
Even when our conﬁdence with smartphones as the “all-controlling” hub
continues to gather steam, wearable devices, e.g., Google Glass and Smart
Watches, are another revolution ready to shake things up. According to re-

6
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
search conducted by PwC’s Consumer Intelligence Series, 20% of the adults in
the United States already own a wearable device [131]. It is the more complex
sensing sphere where wearable technology can truly emerge as the driving force
for future context-aware applications. For example, imagine if customers are
visiting a mall or museum that is equipped with ﬁne-grained localization and
navigation techniques, all information displayed right through the wearable
camera/device on their route at the right physical place. This augmented-
reality (AR) method is a huge beneﬁt for customers who can save on precious
time in information accessing with hands free.
One key challenge in context-aware application is how to sense and inter-
act with the real physical location in a ﬁne-grained manner. To improve the
location sensing accuracy of mobile device, Apple purchased WiFiSLAM in
2013, and Coherent Navigation in 2015. In 2013, Apple launched iBeacon, i.e.,
the Apple-certiﬁed version of a BLE beacon, which represents programming
interface for proximity sensing for smartphone [5]. High-proﬁle retailers such
as Macy’s and American Eagle Outﬁtters, along with major league baseball
and the National Football League, are actively testing them for location-aware
services around local navigation, augmented reality, retail recommendation,
proximity social networking, and location-aware advertising. However, most
of these solutions only rely on proximity detection, and provide services like
pushing coupon, indoor check-in, far from the augmented reality way.
Existing augmented reality relies highly on the location sensing or com-
puter vision techniques [7, 110]. However, both worlds have their own draw-
backs and limitations. Computer-vision-based solutions are highly accurate
and ﬁne grained, but the distance and coverage are very small in addition to
their high computational power requirement. Location-sensing-based solutions
are lightweight, but only achieve coarse-grained resolution and only apply to
position-of-interests (PoIs) at far distance (hundreds of meters away). How to
balance the two worlds with ﬁne-grained location, low power consump-
tion, and better coverage is the motivation of our work on this part.
1.3.3
Locating Lost Children
Losing their beloved child is the worst nightmare of every parent. Sometimes
after you turn around for just a few seconds, your child is gone when you turn
back. If you are at home or some less-crowded small area, you probably can
ﬁnd your child in some corner or in the immediate vicinity. But for public
areas, like shopping malls, streets, or even your child’s favorite Disney World,
it is hard to ﬁnd your child in crowds when lost.
There are so many reasons for your child to get distracted and wander,
then get lost. In places like Disney theme parks, there is simply so much to
see, and so many people attend, especially for events like fast-paced parades.
Even if your child doesn’t typically wander, kidnapping could happen, making
it even harder to ﬁnd your child. Guarding a child in crowded places full of
attractions is nontrivial; locating your lost child is mission impossible.

INTRODUCTION
■
7
Normal approaches include writing your phone number on a shoe tag or
sticker for your child, or going to your designated meeting place, if you have
one or your child could do that. You also can look at the closest locations that
are of interest, or go to the baby center to locate a lost child found by others.
However, it is not eﬃcient for this manually blind searching. Giving your “big
kids” a cell phone could be a high-tech approach, but in most cases they are
not old enough to carry one.
To ﬁnd your child quickly if you are separated, lots of systems and ap-
proaches have been developed. One kind of approach is using a GPS locator
that is installed on your child’s shoes or clothes, e.g., Amber Alert GPS, Pock-
etFinder, AT&T Family Locator [21]. This kind of device includes GPS and
cellular communication modules. One problem for this kind locator is that it
is high cost and bulky. GPS and cellular communication are all expensive and
power hungry, especially when it works in continuous mode. Providing suﬃ-
cient battery life for one day’s use could result in a bulky and heavy device,
and is not suitable for little kids to carry. For indoor places like castles and
shopping malls, GPS may suﬀer signiﬁcant performance degradation, or even
not work due to the signal blockage.
Another category of approaches relies on devices with peer-to-peer com-
munication capabilities. The transmitter and receiver pair, or smartphone and
peripheral pair, is carried by parents and child, respectively. If the child goes
out of the communication range or predetermined threshold, parents will get
an alert. These kinds of approaches leverage the existing low-power communi-
cation standard and could be made with high eﬃciency in power, and portable
in size, e.g., Toddler Tag Child Locator, Keeper 4.0, Chipolo [17]. A drawback
of this approach lies in its lacking absolute location information, e.g., GPS
location. It is impossible for parents to locate their child when the child goes
out of the communication range.
It is very hard to balance between the coverage, accuracy, device complex-
ity, and power consumption. Using simple and popular wearable devices for
kids to carry is attractive; however, how to achieve better accuracy and
coverage of localization without power-hungry GPS and cellular devices
are the research problems that we need to solve.
1.4
Research Challenges
The three technical requirements for our envisioned application scenarios in
Section 1.3 are: 1) smartphone localization and navigation technology with
foot-level resolution; 2) indoor augmented reality with ﬁne-grained location,
low power consumption, and better coverage; 3) better accuracy and coverage
of wearable device localization.
The biggest obstacle has been technical, i.e., ﬁne-grained localization. Cur-
rent coarse-grained (room-level or multi-meter-level) localization solutions can
hardly meet the requirements of many smart life applications. For exam-

8
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
ple, foot-level resolution is required for step-by-step navigation for the blind.
Satellite-based localization, e.g., GPS, has been one of the most important
technological advances of the last half century. No matter how good the sys-
tems get outdoors, their accuracy, coverage and quality deteriorate signiﬁ-
cantly in small-scale indoor places. We spend more than 80% of our time
indoors in our daily activities, e.g., working, shopping, eating, at the oﬃce,
at home. Practical, robust, and accurate indoor location solutions are largely
missing. It is very hard for our smartphone to get the ﬁne-grained location
and sense the nearby object in a room. Technologically, outdoor localization
techniques cannot be directly moved indoors. Current GPS, cellular, and Wi-
Fi-based localization techniques [6, 8, 15] are not reliable and ﬁne-grained
enough when it comes to pinpointing an individual’s whereabouts, especially
indoors. Despite signiﬁcant eﬀorts on indoor localization in both academia and
industry in the past two decades, highly accurate and practical smartphone-
based indoor localization remains an open problem.
When pushing the ﬁne-grained location awareness to context-awareness,
there are two more pieces that are missing in addition to the vision track-
ing and ﬁne-grained localization. These two pieces are: 1) High-Accuracy
Attitude Requirement: Compared with almost invisible remote POIs, line-
of-sight indoor AR views are more sensitive to the attitude estimation result.
The attitude estimation error of the camera would introduce visible drift and
bias between the “rendered” objects and the actual objects due to the short
distance. 2) Displacement Matters: The displacement of a user’s camera
is ignored in outdoor AR applications, since its moving distance is far shorter
than the POI distance. For indoor AR applications with short-range POIs,
the movement even in a small hand shake would have signiﬁcant impact for
the screen location of the AR view. All these pieces need to be integrated
together with the vision tracking and ﬁne-grained localization approaches for
lower computational power, higher tracking accuracy, and faster response.
For locating a lost child using low-power and miniature wearable devices
without high cost cellular and GPS module. Although the required resolution
is lower, the coverage requirement is signiﬁcantly higher. Most of the environ-
ments are uncontrolled without any infrastructure. To solve the coverage and
localization problems of wearable devices without infrastructure, we focus on
the investigation of nearby “crowds” of smartphones for transparent ranging
and locating via peer collaboration. State-of-the-art approaches leverage con-
nection information to detect the presence of wearable devices in a speciﬁc
region near to one participator. However, the resulting searching area of the
obtained location resolution still makes it hard for parents to pinpoint their
children in crowds, e.g., 20-meter peer-to-peer distance could exaggerate the
initial location error surface to thousands of square meters.

INTRODUCTION
■
9
1.5
Book Organization
This book surveys the state-of-the-art techniques, describes future mobile ap-
plications, and presents original technologies in this rapidly moving ﬁeld. It
represents a comprehensive and updated book in this ﬁeld, covering a com-
plete system design and implementation via sensing, localization, and a cloud
ecosystem. The envisioned smartlife ecosystem is shown in Fig. 1.1. Using oﬀ-
the-shelf smartphones with a developed cloud ecosystem (anchors, wearable
tags, mobile apps, and cloud server), the proposed solution could revolutionize
various smartlife applications such as indoor navigation, near-ﬁeld advertis-
ing, augmented-reality, mobile education/campus/health and entertainment,
and shopping/tour guides.
Figure 1.1: Envisioned smartlife ecosystem.
This book presents a prototype system to ﬁll the long-lasting gap of
smartphone-based indoor localization. This system consists of a constella-
tion of low-complexity anchor networks that enable ﬁne-grained localization
with accuracy up to centimeter-level without any hardware/attachment bur-
den on users’ smartphones. A hybrid mobile social network is proposed for
location-based social and crowd missions. Speciﬁc applications include social
cooperative localization, locating your lost child via crowd sensing, and help-
ing users coming, keeping, and working together.


Chapter 2
Overview of Mobile
Systems
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
2.1
Overview of Location Sensing Techniques .......................
12
2.2
Overview of TOA-Based Smartphone Localization Approaches .
13
2.3
Architecture of the Proposed Localization System ..............
16
2.4
Hardware Design for Sensors, Anchor Nodes, and Wearables ...
18
2.4.1
Design Requirement and Overview ......................
18
2.4.2
Hardware Design and Architecture ......................
18
2.5
Cloud Architecture ...............................................
20
Modern smartphones and location-based services and apps are poised to trans-
form our daily life. However, current smartphone-based localization solutions
are limited mainly to the outdoors mostly missing practical, robust, and ac-
curate indoor location solutions. Despite signiﬁcant eﬀorts on indoor local-
ization in both academia and industry in the past two decades, highly ac-
curate ones and practical smartphone-based indoor localization remains an
open problem. To enable indoor location-based services (ILBS), there are sev-
eral stringent requirements for an indoor localization system: highly accurate
11

12
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
that can diﬀerentiate massive users’ locations (foot-level); no additional hard-
ware components or extensions on users’ smartphones; scalable to massive
concurrent users. Current GPS, Radio RSS (e.g. WiFi, Bluetooth, ZigBee),
or Fingerprinting-based solutions can only achieve meter-level or room-level
accuracy.
In this chapter, we provide an overview of location sensing systems and
localization approaches. To address the challenges in existing systems, we
propose a practical and accurate solution that ﬁlls the long-lasting gap of
smartphone-based indoor localization. Speciﬁcally, we design and implement
an indoor localization ecosystem called Guoguo. Guoguo consists of an an-
chor network with a coordination protocol to transmit modulated localization
beacons using high-band acoustic signals, a realtime processing app in a smart-
phone, and a backend server for indoor contexts and location-based services.
The overview architecture of our proposed system is given in this chapter. The
detailed system design and implementation will be elaborated in the following
chapters.
2.1
Overview of Location Sensing Techniques
Localization schemes can be classiﬁed into three categories of methods: angle-
based, ﬁngerprinting-based, and ranging-based. An angle-based approach re-
lies on the directional antenna scan to achieve angle resolution. But a narrow-
beam directional antenna is very expensive and unsuitable for consumer ap-
plications. Fingerprinting-based approaches [8, 15, 6] or other proximity ap-
proaches [78, 38, 18, 99] feature lowest complexity without any requirement
for additional infrastructure. However, they achieve only room-level resolution
and require the site-survey to build ﬁngerprinting databases at the cost of in-
tensive labor. A ranging-based approach is more straightforward. Measuring
the radio signal strength (RSS) and time-of-arrival (TOA) are the two typical
ranging solutions. Compared with TOA, RSS information is widely available
and lots of work has been dedicated to using the RSS of WiFi, Bluetooth, or
cellular signals, for indoor localization [127, 20, 44, 50]. However, the need for
the prior information of the radio attenuation model, and the time-varying
features of channel make these approaches only suitable for applications with
low location accuracy needs.
From the measurement signal perspective, smartphone-based indoor local-
ization could be summarized into the following categories: RSS-based rang-
ing using propagation attenuation of radio (WiFi, cellular, and Bluetooth)
[20, 44], ﬁngerprinting-based matching using surround sound [6, 103] or ra-
dio proﬁles [114, 15, 19], and TOA-based ranging [53, 59, 74, 52, 133, 48].
Diﬀerent applications may have diﬀerent requirements as to the complexity,
cost, and resolution. For ﬁne-grained indoor localization application with high
resolution requirements, TOA-based ranging is preferred.

Overview of Mobile Systems
■
13
TOA-based ranging is more accurate and robust. The Cram´er-Rao Low
Bound (CRLB) of TOA ranging is inversely propositional to the eﬀective
bandwidth of signal, it is also why ultra-wideband (UWB) signal received
special attention for its high accuracy on ranging and localization. However,
current UWB techniques are still under development and not available on
current smartphones. Another option is to use the acoustic signal for TOA
ranging due to its low transmission speed. MIT Cricket [85], Active Bat [113]
and DOLPHIN [70] are well-known systems that use ultrasound for localiza-
tion. However, normal smartphones cannot receive ultrasound. In addition,
they require radio signal for synchronization, e.g., ZigBee for Cricket. Depen-
dence on special devices and non-applicability on smartphones greatly limits
their adoption in daily indoor activities.
Recent research on leveraging the ubiquitous microphone sensors in a
smartphone introduces a convenient and low-complexity approach. A. Mandal
et al. [62] used a PDA to transmit annoying 4kHz acoustic signal. C. Peng et
al. [81] proposed to transmit low-attenuation 2-6kHz acoustic signal for better
coverage, but their solution causes sound pollution due to the audible signal.
H. Liu et al. [52] used a smartphone to transmit high-band audible sound, but
the achieved ranging coverage is only three meters. Authors in [74] performed
localization using desktop PCs and laptops, achieving location accuracy of
several meters. In addition, these solutions are not scalable and feature low
location update rates. Due to the use of two-way ranging and simple acoustic
“Beep” signal, only one user can be handled and localized at a time. Adopting
time-divided coordination among users could be a partial solution. However,
random concurrent access patterns of many users in real situations makes it
hard for their solutions to support multiple users.
2.2
Overview of TOA-Based Smartphone Lo-
calization Approaches
We divide existing TOA-based localization solutions into four diﬀerent cate-
gories according to their operation mode, i.e., two-way active mode [74, 52,
133], one-way active mode [74, 62, 10, 34], assisted passive mode [85,
106, 107], and no-assisted passive mode [53, 48]. The meaning of “two-way”
and “one-way” relates to the communication modes between the smartphone
and the anchor node; “active” means the smartphone needs to transmit sig-
nals; “passive” means the smartphone only receives signals. The “assisted”
mode represents approaches that use additional signal for the transmitter and
receiver synchronization or timing comparison.
Two-way active mode is a typical way to solve the peer-to-peer synchro-
nization problem during ranging. C. Peng et al. [81, 82] proposed a solution of
self recording between peer-to-peer devices and achieved maximum operation
distance around 4 meters. H. Liu et al. [52] utilized the acoustic ranging to

14
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
assist the WiFi localization, and achieved 1 ∼2m accuracy with 3m operation
distance and 7s latency. Two-way active mode involves the time-consuming
process of transmitting and receiving, which limits the refresh rate. This is
especially serious for acoustic signal. One-way active mode features a re-
duced transmission delay by relying on a synchronized anchor network. A.
Mandal et al. [62] used PDA to transmit noticeable 4kHz acoustic signals
to a WiFi-enabled sensor network for sound source localization. Nandaku-
mar et al. [74] proposed DeafBeep, which locates a laptop or desktop with
only speakers. They also proposed a hybrid RF-and-AR-based approach with
meter-level accuracy and second-level delay. However, both two-way and one-
way active mode suﬀer from limited scalability for multi-users, since signals
from other users cause signiﬁcant interference. Moreover, active mode requires
the speaker in the smartphone to transmit the acoustic beacon, which covers
a shorter range compared with the specialized speaker in the anchor node.
Thus, one-way passive mode contributes to better user capacity and longer
coverage.
MIT Cricket [85] is a classic system of assisted passive mode by us-
ing specialized devices (Zigbee radio assists simple unmodulated Ultrasound
pulse). However, current radio modules (WiFi, cellular, and Bluetooth) em-
bedded in a smartphone have random access delay with inadequate timing ac-
curacy (> 3ms) for ranging assistance. Mostafa et al. proposed RF-Beep and
SpyLoc [106, 107] by leveraging the radio signal interface at the kernel-level
of the smartphones for assisted ranging with 30 ∼70cm accuracy. However,
they need to modify the oﬀ-the-shelf smartphone OS, i.e., Android or iOS,
and the achieved accuracy is still insuﬃcient for some ﬁne-grained location
applications.
The Guoguo and other systems [48] fall into the category of non-assisted
passive mode localization. Lazik et al. [48] used smartphones as anchor nodes
to generate Chirp signal for one-way ranging. However, the generation of Chirp
signal requires devices containing DAC, e.g., smartphones. Low-complexity
sensors cannot generate Chirps. Moreover, [48] rely on frequency-based f mod-
ulation with long duration of signal in the time-domain (t ∝1/f). Long time
duration reduces the refresh rate of localization and increases power consump-
tion. We utilize our own low-complexity anchors to transmit low duty cycle
(≈1.92%) sharp pulse by 2-PAM modulation. Our scheme reduces power
emission, increases refresh rate, and resists interference.
To compare the performance of Guoguo with other existing indoor local-
ization approaches, we summarize their key features in terms of principle, ac-
curacy, cost, smartphone applicability and training requirements in Table 2.1.
The multi-user refers to how many end users can be supported simultaneously.
From Table 2.1, we observe that Guoguo achieves better balance in terms of
cost and performance over other acoustic/ultrasound-based approaches. Com-
pared with other low-cost approaches (mainly smartphone-based), e.g., RSS
and ﬁngerprinting-based approaches, Guoguo signiﬁcantly outperforms other
approaches in accuracy. Guoguo is outstanding as a practical smartphone-

Overview of Mobile Systems
■
15
Table 2.1: Comparison of Guoguo with existing localization techniques
System
Signal Type
Technique
Accuracy
Cost
Multi
User
Smart-
phone
Training
Guoguo
Modulated
acoustic signal
(17-20kHz)
Passive
ranging
High (6 ∼15cm)
Low
High
Yes
No
Cricket [85],
RF-Beep,
SpyLoc
[106, 107]
Acoustic, Radio
Assisted
Ranging
High (centi- meter)
Medium
High
Hard
No
Beep [62],
BeepBeep [82]
Acoustic signal
(Low-band)
Active-mode
ranging
High (centi- meter)
Medium
Limited
Yes
No
Active Bat
[113],
DOLPHIN [70]
Ultrasound
Active-mode
ranging
High (centi- meter)
Medium
Limited
No
No
Ultra wideband
[49, 54]
Ultra wideband
radio
Ranging-
based
High
High
High
No
No
Radio RSS
[20, 44]
WiFi,
Bluetooth, or
cellular signal
Ranging-
based
Low
Lowest
High
Yes
Yes
Fingerprinting
[6, 8, 10, 15]
WiFi, Cellular,
Bluetooth, FM
and ambient
sound
Fingerprint
matching
Low (room- level)
Lowest
High
Yes
Yes
Proximity
[99, 18, 78]
RFID, NFC,
and acoustic
signal
Proximity-
based
Lowest
Medium
High
Depends No

16
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
based solution with centimeter-level accuracy without special hardware ex-
tensions on users’ phones.
Figure 2.1: Related localization systems from academia.
2.3
Architecture of the Proposed Localization
System
The architecture of the Guoguo localization system is shown in Fig. 2.3.
Wireless Anchor Network: We designed the anchor node from scratch
and keep the BOM price as low as $10 per node. The inter-node communica-
tion and synchronization have been implemented and achieved at a very highly
accurate level. The transmitted beacon signal has been tuned to be unnotice-
able to humans, with low-power and low-duty-cycle features. To enable passive
sensing for multiple smartphone users, we designed the transmission waveform
with wide-band modulation, and a transmission scheme of the acoustic beacon
that follows the high-density pseudo-codes. We propose a symbol-interleaved
beacon structure to overcome the drawback of the low transmission speed of
acoustic signal and improve the location update rate [57].
Smartphone Processing: We perform preprocessing for the received
acoustic beacon signal, e.g., adaptive ﬁltering and wavelet decomposing, be-
fore signal detection. Transmit reference approach is utilized for the matched-
ﬁlter estimation on the smartphone side [53]. The signal detection module is

Overview of Mobile Systems
■
17
Figure 2.2: Related localization systems from companies.
designed with better robustness by applying cluster detection and spectrum
matching to identify signal-like interference. The demodulated information bit
could be used to extract the pseudo ID for each node. The synchronization
is realized by tracking the demodulated signal in the time-domain, where the
convergence of the tracking ﬁlter means the success of the synchronization.
We propose a dynamic TOA estimation scheme to obtain accurate ranging
results by maximizing the TOA detection probability, along with a multiple-
threshold backward approach to ensure the detection of TOA path. To mini-
mize the NLOS bias eﬀects, we propose approaches for NLOS mitigation.
Server Processing: To minimize the computation cost in a smartphone,
we oﬄoad localization and tracking process into the back-end server. To mit-
igate the outliers and missing data in the ranging measurement, we propose
track-before-localization for the ranging results of each station. We further
propose semideﬁnite programming (SDP) for global optimal location estima-
tion by leveraging the computational power of the server. To utilize the linear
time varient feature of the unknown delay, we add delay-constraint into the
location estimation for better robustness.
Achieved Performance: For the prototype of the Guoguo system, cur-
rent experiment results demonstrated the promising features of our solution:
low power and unnoticeable acoustic beacon, low-complexity anchor node
(BOM price < $15 per node), high precision in anchor network synchroniza-
tion (< 10µs), large coverage (15 ∼20m), centimeter-level accuracy (< 10cm),
high refresh rate (> 1Hz), robust under sound interference (up to 110dBA).
When compared with commercial apps, the Guoguo app shows modest CPU
utilization and network traﬃc (lower than Google Chrome) without inter-

18
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 2.3: System architecture.
rupting normal phone usage. This practical and robust ecosystem promises
enormous new possibilities for novel indoor location-based services and appli-
cations.
2.4
Hardware
Design
for
Sensors,
Anchor
Nodes, and Wearables
2.4.1
Design Requirement and Overview
General Purpose Hardware. Whether to opt for specialized or general
purpose hardware solutions is the ﬁrst decision we are faced with, and it’s
not an easy choice. Although both technologies go on diﬀerent paths, they
do have diﬀerent economical features and must be evaluated carefully before
implementation. The architecture of the specialized hardware could be very
simple for one special application without considering the extension to other
applications.
2.4.2
Hardware Design and Architecture
Leveraging our wireless anchor network prototype, our indoor localization
system consists of an app in a smartphone that adopts the non-assisted passive
mode to avoid random-access interference and multi-user division issues in the
system. A plurality of sensor nodes as preconﬁgured anchor constellation to
broadcast acoustic beacon. Because of the non-assisted passive mode of the
system, the location system can be highly scalable to support hundreds of users
simultaneously in a large indoor space, e.g., museums, job fairs, and shopping
centers. Moreover, the position information can be calculated locally on a

Overview of Mobile Systems
■
19
smartphone without reporting to the third-party servers, making it privacy-
proof if desired.
To meet our long-term objective, we designed the low-complexity anchor
node from scratch using the TI MSP430 microcontroller and CC2533 Zigbee
chip. An app on a smartphone (e.g., an iOS or Android mobile device) is
designed to perform signal detection, ranging, and localization (the localiza-
tion step can be optionally oﬄoaded to the server). The architecture of the
localization system is shown in Fig. 2.3.
We designed our own hardware as the low-complexity anchor node based
on TI’s MSP430 Microcontroller and the CC2533 Zigbee single-chip solution,
and use a standard smartphone (e.g., Apple iOS platform) to perform signal
detection, ranging and localization. The architecture of the localization system
is shown in Fig. 2.3.
Figure 2.4: The designed hardware node version 1.

20
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 2.5: The designed hardware node version 2.
2.5
Cloud Architecture
To enable a full-ﬂedged mobile sensing system, we provide cloud back-end for
the sensing data from smartphones or other mobile devices. One key important
requirement is data oﬄoading and processing. To facilitate joint sensing data
processing with high energy eﬃciency, we implemented the time-sensitive al-
gorithms, e.g., data sensing, pre-processing, detection, TOA estimation, code
matching, and NLOS mitigation, into the smartphone app. All the processing
was put in the iOS Grand Central Dispatch (GCD) queue to enable concur-
rency with the mobile application without slowing down the smartphone’s
responsiveness. To ensure eﬃciency of the smartphone processing, we used
the vDSP portion of the Accelerate framework in iOS. Other complex com-
putation was executed in the server to minimize the computation cost in the
smartphone. We designed a pub/sub framework based on the open-source Re-
dis NoSQL server [92] as shown in Fig. 2.6. Once the smartphone publishes
a preprocessed result to the server, the subscriber on the server side per-
forms localization and returns the result to the smartphone asynchronously.
Such conﬁguration balanced the communication and computation cost. For

Overview of Mobile Systems
■
21
our acoustic-based localization approach, the smartphone extracts ranging in-
formation from the audio raw data and greatly reduces communication over-
heads; the pub/sub server handles concurrency and serves multiple localiza-
tion requests from smartphones. We leverage the scalable and robust features
of the Redis server. Other features of our provided server include push noti-
ﬁcation support for social networks, big data processing back-end, and API
servers for location-based services and user management. The details of the
cloud backend will be elaborated in the following chapters.
Figure 2.6: The architecture of the cloud backend.


Chapter 3
Acoustic Ranging and
Communication
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
3.1
Introduction ......................................................
24
3.2
System Architecture .............................................
25
3.3
Transmitter Signal Design and Modeling ........................
25
3.3.1
Signal Modeling .........................................
25
3.3.2
Acoustic Beacon Generation ............................
27
3.3.3
Signal and Interference ..................................
27
3.3.4
Realtime Filtering and Wavelet Denoising ..............
28
3.4
Acoustic Receiver Design ........................................
29
3.4.1
Acoustic Receiver Signal Modeling ......................
29
3.4.2
Hypothesis Test for Symbol Synchronization ...........
29
3.4.3
Symbol Synchronization .................................
30
3.5
TOA Estimation .................................................
32
3.5.1
Spectrum Matching ......................................
32
3.5.2
Cluster Detection ........................................
34
3.5.3
TOA Estimation Procedure .............................
35
3.5.4
Maximizing the Right Detection Probability
...........
35
23

24
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
3.6
Acoustic Symbol Demodulation .................................
37
3.6.1
Challenges of Audible-Band Communication ...........
37
3.6.2
Communication Demodulation ..........................
38
3.6.3
Dynamic Demodulation with Transmit Reference ......
39
3.7
Performance Evaluation ..........................................
43
3.7.1
Experiment Setup .......................................
43
3.7.2
Experimental Results ....................................
44
3.7.3
Communication and Ranging Results ...................
46
3.8
Conclusion ........................................................
47
3.1
Introduction
Accurate indoor localization utilizing low-complexity devices promises a wide
spectrum of applications, especially when the GPS signal is inaccessible due to
the blockage of the satellite signal [80]. If sub-meter resolution can be achieved,
it will fundamentally change and improve the way that current location-based
services are delivered.
TOA estimation based on the communication channel can obtain the signal
ﬂight distance as pseudorange [80]. The ranging-based trilateration method
utilizes these pseudoranges to calculate location information. For location-
aware techniques, communication and accurate TOA estimation capabilities
are two important prerequisites. Mainly, two categories of approaches have
been proposed to solve this problem. The ﬁrst type of solutions utilizes im-
pulse radio ultra-wideband (UWB) technique for indoor TOA-based ranging,
because ranging precision directly depends on the bandwidth of the operating
signal. Using UWB signal has attracted signiﬁcant research interest and has
become a standard as IEEE 802.15.4a. However, the full-digital coherent IR-
UWB system requires the bandwidth of several GHz to guarantee sub-meter
ranging accuracy, which increases the overall hardware cost and processing
power dramatically [130]. Some techniques, e.g., energy receiver and ﬁnite-
resolution digital receiver, have been proposed to lower the overall complexity
[130, 54]. Although much lower complexity can be achieved, it is still very
expensive and requires additional special hardware.
The second kind of solutions utilizes the ultrasound signal to perform ac-
curate ranging. Compared with electromagnetic signal used in a UWB device,
the aerial acoustic signal is more pervasive and can achieve ranging accuracy
with much lower hardware cost. Due to slower transmission speed of acous-
tic signal, even several KHz signal bandwidth can result in centimeter-level
ranging accuracy. Yang et al. [128] used the acoustic approach to detect the
position of a phone using car speakers. However, they only need to detect the
relative region in a car. The Cricket localization system developed by MIT
[85] using ultrasound for ranging achieved centimeter-level accuracy. They
used the radio signal for synchronization and performed inter-node ranging

Acoustic Ranging and Communication
■
25
by using their developed devices. The requirements of the dedicated device
impede its widespread adoption by ordinary users.
In this chapter, we propose to directly utilize the existing hardware of con-
sumers to achieve accurate ranging, i.e., the microphone sensor. We address
the problem of ranging and communication by using the aerial acoustic signal
over the microphone channel. Our scheme helps users achieve indoor localiza-
tion by using their smartphones. Even the pre-placed anchor node providing
the ranging beacon signal can be implemented with very low cost, i.e., a small
speaker with a microcontroller is suﬃcient. We designed a joint symbol de-
tection and TOA estimation method to achieve robust and accurate ranging
results. We derived the TOA threshold by maximizing the TOA right detection
probability that can be adaptively tuned in diﬀerent environments. We also
propose a dynamic demodulation method based on direct frequency discrim-
ination and amplitude matching with transmit reference to address a worse
communication channel condition than UWB and ultrasound signal. The ex-
perimental results show that our proposed TOA and communication scheme
achieve very good mean-square error and bit-error rate with high probability.
3.2
System Architecture
To facilitate the indoor localization, we introduce an acoustic ranging and
communication technique that leverages the existing low-complex anchor node
infrastructure and microphone sensor in a mobile target (MT), e.g., a smart-
phone. An anchor node sends its unique acoustic beacon signal periodically.
The beacon signal contains the ID or position information of its transmit-
ter. On the receiver side, the microphone searches and captures the existing
beacons and performs TOA estimation and communication decisions. After
receiving beacon information from more than 3 anchor nodes, the target posi-
tion can be determined by combing the information from the TOA estimation
process and anchor positions. The simpliﬁed architecture of our audible-band
acoustic localization system is shown in Fig. 3.1. In this paper, we focus on the
two important prerequisites of localization, i.e., ranging and communication,
and present in detail design goals, the signal modeling, symbol synchroniza-
tion, TOA estimation, and communication decision.
3.3
Transmitter Signal Design and Modeling
3.3.1
Signal Modeling
Driven by the speciﬁc design goal of only using the microphone on the receiver
side, we need to choose an appropriate transmitter signal band to match the
capabilities of a user’s smartphone. The acoustic signal band of the micro-
phone is very limited; the typical band of a microphone is in the audible range,

26
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 3.1: The system architecture.
i.e., 200Hz–20KHz. To reduce interference between beacon signals and daily
environmental noises, we choose the high frequency side of 17KHz–20KHz
as the operating band. By keeping the power spectrum density (PSD) lower
than the perception level of human ears, and selecting an appropriate band-
pass speaker to minimize the useless low-frequency part, the acoustic beacon
can be unnoticeable even in very short distances.
The transmitted signal can be modeled as
gt(t) = √ε
Np−1
X
j=0
Ns−1
X
i=0
gi,j(t −jTp −iTs)
(3.1)
where gi,j(t) is the transmitted signal for the ith symbol in the jth period;
ε is the signal energy; Tp is the beacon period, with total beacon numbers of
Np; Ts is the symbol duration; Ns is the symbol number, each information bit
with values of ±1. Some spaces are left between beacon periods to avoid the
inter-beacon interference, i.e., Ns × Ts < Tp. The information bits are carried
by gi,j(t).
The acoustic beacon signal is captured by the microphone and converted to
the electrical domain after propagation through the free space with distortion.
Passing through the analog-to-digital convertor (ADC), the received signal will
be digitalized as r(k) with the sampling frequency of Fs, and k ∈[1, . . . , Nk],
where Nk = Ts × Fs. The digital version of the transmitted signal is gi,j(k);
every symbol contains Nk sampling points. The digital result that we get is
ri,j(k) =
ξi,j−1
X
l=0
Al
i,j · gt(k −kl
i,j) + ni,j(k)
(3.2)
where ξi,j is the total number of propagation paths, with Al
i,j, kl
i,j = τ l
i,j × Fs
representing the digital version of the multi-path delay. The term ni,j(t) is
independent white Gaussian noise in the ith symbol of jth period. Nb = Tp×Fs
means the number of sampling points in one beacon period.

Acoustic Ranging and Communication
■
27
3.3.2
Acoustic Beacon Generation
The generation of acoustic beacon relies on a plurality of sensor nodes with
low-complexity and low-power consumption. To trade oﬀbetween the goal of
making the acoustic signal unnoticeable and the constraint of the microphone
bandwidth, we choose 17kHz-20kHz as the operating band.
To lower the complexity of the anchor node, a low-cost microcontroller
(MSP430) is utilized to drive an audio chip with conﬁgurable gain. The audio
chip generates the acoustic beacon signal and performs 2-PAM (pulse am-
plitude modulation) to carry the information bit pj. We use low-duty-cycle
transient acoustic pulse for high timing resolution and low-power transmission
(below the perception level of the human ear). The Zigbee chip connected
to the microcontroller enables the wireless synchronization among M anchor
nodes.
3.3.3
Signal and Interference
The environmental sound noise and interference is uncontrollable, making
the acoustic beacon signal hard to detect in this crowded band. Fig. 3.2(a)
shows the sound spectrum in a normal environment without acoustic beacon
signal; Fig. 3.2(b) shows the spectrum of the same environment with acoustic
beacon signal generated. From the high frequency side of Fig. 3.2(b), we see
the acoustic signal working in the band near 17 ∼20kHz. Fig. 3.2(c) shows
the energy spectrum density (ESD) of the received acoustic beacon under
interference, e.g., human talking, or video/music. From Fig. 3.2(c), we know
that normal sound interference has a very strong frequency component even
in the high frequency band, where our generated acoustic beacon has been
completely submerged. Such high dynamic and wideband interference poses
stringent challenges for acoustic localization systems.
0
0.5
1
1.5
2
x 10
4
−80
−60
−40
−20
0
20
40
60
Frequency [Hz]
ESD
(a) Normal, no signal
0
0.5
1
1.5
2
x 10
4
−80
−60
−40
−20
0
20
40
60
Frequency [Hz]
ESD
Signal Region
(b) Normal, with signal
0
0.5
1
1.5
2
x 10
4
−80
−60
−40
−20
0
20
40
60
Frequency [Hz]
ESD
(c) Interference, with signal
Figure 3.2: Energy spectrum density for three diﬀerent cases: (a) no
acoustic beacon signal, (b) with acoustic beacon, and (c) with sound
interference and acoustic beacon.

28
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
3.3.4
Realtime Filtering and Wavelet Denoising
To ﬁlter out out-band interference and noise, a frame-based ﬁnite impulse
response (FIR) ﬁlter is used for its low complexity and high stability. To min-
imize spectrum leakage, we utilize an overlap-and-add approach for calibrating
speciﬁc boundary results.
Filtering before detecting the beacon signal under noisy background is nec-
essary, but not a perfect solution. Fig. 3.2(c) shows that the acoustic signal
is still submerged by interference and noise; even out-band frequency compo-
nents can be perfectly ﬁltered out.
Wavelet approaches that utilize the localizing and concentrating proper-
ties of the wavelet transform allow eﬀective ﬁltering of noise from a signal. For
example, some signal’s energy could concentrate in a small number of wavelet
coeﬃcients, allowing denoise by thresholding wavelet coeﬃcient. The rationale
is that our generated beacon signal is local in time-domain and also local in
the frequency-domain. Wavelets, concentrated in time, oﬀer an ideal means
to process signal that is localized in both time and frequency, whereas Fourier
transform is localized only in frequency. Using the combined time and fre-
quency locality, wavelet could provide better anti-noising and anti-interference
performance.
The assumption used in wavelet transform need the whole batch of sig-
nal. Processing signal in a batch-based form is incompatible with the realtime
feature of a localization and tracking system. Performing wavelet for small seg-
ments of signal and using overlap-and-add as in frame-based FIR is impossible.
Unlike the linear process of FIR, wavelet performs non-linear processing, di-
rectly using overlapping segments of signal after wavelet transform introduces
signiﬁcant errors.
0.5
1
1.5
2
2.5
3
3.5
x 10
4
−1
−0.5
0
0.5
1 x 10
−3
Sample Points
Amplitude
(a) Initial
0.5
1
1.5
2
2.5
3
3.5
x 10
4
−2
−1
0
1
2 x 10
−4
Sample Points
Amplitude
Signal
leakage
Signal
(b) No boundary cali-
bration
0.5
1
1.5
2
2.5
3
3.5
x 10
4
−2
−1
0
1
2 x 10
−4
Sample Points
Amplitude
signal
signal
(c) Boundary calibra-
tion
Figure 3.3: Time-domain waveform: (a) system input, (b) after normal
FIR and wavelet processing, (c) after FIR and wavelet processing with
boundary calibration.

Acoustic Ranging and Communication
■
29
We adopt border extension and calibration for each frame as proposed in
[90]. Fig. 3.3(a) shows the initial received acoustic signal in a normal indoor
environment. After performing the frame-based FIR and wavelet denoising,
the signal could be easily captured as shown in Fig. 3.3(b) and Fig. 3.3(c)
with signiﬁcant improvement in signal to noise ratio (SNR). As shown in
Fig. 3.3(b), the spectrum leakage could cause small pulses and may result in
high false detection rate. To avoid the spectrum leakage, we further propose
frame-based realtime processing with the boundary calibration. The enhanced
result is shown in Fig. 3.3(c).
3.4
Acoustic Receiver Design
3.4.1
Acoustic Receiver Signal Modeling
After propagation through the free space and distortion, the acoustic beacon
signal captured by the microphone is converted to the electrical domain. The
acoustic signal received can be represented as
r(t) =√ε
Np−1
X
j=0
Ns−1
X
i=0
ξi,j−1
X
l=0
Al
i,j · gi,j(t −τ l
i,j −jTp −iTs)
(3.3)
+ Ii,j(t) + ni,j(t)
where ξi,j is the total number of propagation paths, with Al
i,j and τ l
i,j as
the amplitude and delay of the l-th path in the ith symbol of jth period,
respectively. The term ni,j(t) is independent white Gaussian noise process
in the ith symbol of jth period with spectral density of N0/2; Ii,j(t) is the
frequency interference caused by the environmental sound noise.
After being received, the beacon signal of (3.3), r(t) will be digitalized
as r(k) with the sampling frequency of Fs, and k ∈Nk, where Nk denotes
the sampling points in every symbol, and can be written as Nk = Ts × Fs.
The digital version of the transmitted signal is gi,j(k), while kl
i,j = τ l
i,j × Fs
represents the digital version of the multi-path delay. Nb = Tp × Fs means
the number of sampling points in one beacon period. ni,j(k) is the digital
representation of Gaussian noise ni,j(t).
3.4.2
Hypothesis Test for Symbol Synchronization
The symbol synchronization is a prerequisite for ranging with the duty of
detecting the signal start region. To better illustrate the symbol synchroniza-
tion theoretically, we can rewrite the model ri,j(k) as rj(k) = √εA0
j · gj(k −
kτ
j ) + nj(k), i = 0 in the j-th beacon period estimation, where kτ
j is the TOA
sampling point. For notation convenience, we deﬁne vector rj,k = [rj(k) · · · ],
sj,k = [gj(k −kτ
j ) · · · ], nj,k = [nj(k) · · · ]. Assuming the length of signal un-
der observation is Mo, the signal length equals the beacon duration, i.e.,

30
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Mp = NkNs. The two conditions of the hypothesis for detecting the signal
are





H0 : rj,k = nj,k
k = 1 · · · Mo
H1 :
(
rj,k = √εsj,k + nj,k
k = kτ
j · · · kτ
j + Mp −1
rj,k = nj,k
k = 1 · · · kτ
j −1, kτ
j + Mp · · · Mo
(3.4)
where the signal is only presented with length of Mp in H1 condition with
its starting point as kτ
j . The symbol synchronization process is to detect the
signal region in the noise background, i.e., detect H1 condition out of H0,
while the TOA estimation is to detect the ﬁrst path of signal and its delay
kτ
j .
To detect the signal region (H1 condition), the receiver structure can be
obtained by generalized likelihood ratio test (GLRT) as
Λ(rj,k) = p(rj,k|H1, kτ
j )/p(rj,k|H0)
(3.5)
where p(rj,k|H1, kτ
j ) is the likelihood function of the received data vector con-
ditioned on the maximum likelihood (ML) estimate of the TOA sample kτ
j .
The decision variable can be written as
zj,i = arg max
k

1
Ms
iNk+Ms
X
k=iNk
(rj,k · tj,k)
 , k ∈{1, Mo}
(3.6)
where the | · | operation in (3.6) is due to the unknown sign of the received
signal, Ms is the length of signal under detection. i = ⌊k/Nk⌋; and tj,k is the
template of the received signal term. (3.6) is performed for every Nk points
to speed up the detection. tj,k = sj,k when the signal term sj,k is known. If
sj,k is unknown, tj,k can be simpliﬁed as a rectangular signal for non-coherent
detection. The value of Ms can be chosen as Ms = (1/f0) × Fs, i.e., covering
the whole period for the highest frequency component. Denoting the detection
threshold as ηsyn, the symbol synchronization process can be written as
ˆi = arg min
i
{(zj,i > ηsyn)&(zj,i+Ns−1 > ηsyn)}
(3.7)
where the ﬁrst term (zj,i > ηsyn) indicates that the ﬁrst symbol of a beacon
signal is detected; the length of a beacon period is Ns; & is the “and” oper-
ation. If and only if the ﬁrst symbol and the length of the beacon period is
detected and validated, the symbol synchronization can be asserted.
3.4.3
Symbol Synchronization
The ﬁrst path of the multipath signal (τ l
i,j, i = 0, l = 0) in one beacon is
often called the TOA path, which can be used to characterize the line-of-
sight distance [31]. To lower the overall system complexity and exploit the
similarity feature of the symbol synchronization (SS) and TOA, we use the

Acoustic Ranging and Communication
■
31
Neyman Pearson (NP) criterion in SS to detect the signal region with a ﬁxed
false-alarm rate. We then use the result of SS to improve the reliability and
accuracy of the TOA estimation, and perform TC-based TOA estimation by
maximizing our derived right detection probability.
To detect the i-th symbol that the beacon signal starts, we choose to
extract continuous Ms points in every Nk interval to speed up the detection;
Nk interval equals to the symbol rate Ts. Due to the bandpass properties
of the received signal, we need suﬃcient length of samples to cover the whole
period of the high frequency signal, e.g., choosing Ms to cover the whole period
for the highest frequency component that Ms = ⌈(1/f0) × Fs⌉. The decision
process for symbol detection can be expressed as
ˆis = min
i

1
Ms
(iNk+Ms)
X
k=iNk
|ri,j(k)| > ˆηsyn


(3.8)
where min(·) is the function that selects the ﬁrst i that the decision vector
crossing the threshold; ˆηsyn is the threshold for synchronization; | · | is the
absolute function to extract the amplitude information. For simplicity, we
deﬁne decision vector as zi =
1
Ms
P(iNk+Ms)
k=iNk
|ri,j(k)|.
An important parameter involved in (3.8) is the synchronization threshold
ˆηsyn. To determine this parameter, hypothesis tests can be used to minimize
error detection probability. The process of (3.8) is to detect the signal from
the noise component ni,j(k) with variance of σ2. Since each individual sample
ri,j(k) is a Gaussian random variable, the ﬁrst moment of ri,j(k) when signal
is present (H1 condition) can be written as E(ri,j(k); H1) = √εEl(Al
i,j) ≜
√ε ˆA = µ, Var(ri,j(k); H1) = σ2, where ˆA is the estimated mean value of the
multi-path amplitude (Al
i,j). In the noise region where signal is not present
(H0 condition), the statistical parameters of ri,j(k) are E(ri,j(k); H0) = 0,
Var(ri,j(k); H0) = σ2. The decision vector zi is the mean absolute value of
|ri,j(k)|, and has a folded normal distribution. The probability density function
(PDF) of zi is given by
f(zi; ˆA, σ) =
1
√
2πσ2 exp
 
−(−zi −√ε ˆA)2
2σ2
!
(3.9)
+
1
√
2πσ2 exp
 
−(zi −√ε ˆA)2
2σ2
!
where zi ≥0. The moment can be simpliﬁed under H0 condition that ˆA = 0,
as E(zi) =
p
2/πσ, Var(zi) = (π −2)/πσ2.
After performing the absolute function | · | in (3.8), the probability that
the sample crosses the threshold ˆηsyn in the noise region (H0 condition) can
be shown as
Pfa(|ri,j(k)|) = Pr(|ri,j(k)| > ˆηsyn; H0) = 2Q (ˆηsyn/σ)
(3.10)

32
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
where σ is an unknown parameter; Q(x) is the Gaussian Q function.
Pfa(|ri,j(k)|) is the false alarm rate that detected the wrong sampling point.
To estimate σ, one method is directly using ˆσ =
p
E(ri,j(k))2 in the noise
region. However, using the ﬁrst moment of the folded normal distribution can
lead to a more simpliﬁed method as ˆσ =
p
π/2E(zi; H0), where it does not
need to perform complex (·)2 and
p
(·) in estimation and is really suitable for
real-time situations.
With the unknown a prior information, using the Neyman Pearson (NP)
criterion can achieve optimal performance by maintaining a constant false-
alarm rate γfa. Thus, the detection threshold (ˆηsyn) can be determined by
(3.10) as
ˆηsyn =
p
π/2E(zi; H0)Q−1(Pfa(|ri,j(k)|)/2)
(3.11)
where Pfa(|ri,j(k)|) is the constant false alarm rate that should be pre-set
according to application demands; high requirement on Pfa(|ri,j(k)|) is often
achieved at the sacriﬁce of detection probability. In the ﬁrst step detection,
Pfa(|ri,j(k)|) should be set slightly higher to ensure no information loss, while
the second step in TOA estimation can help keep the overall Pfa(|ri,j(k)|) at
a lower level.
With the threshold (ˆηsyn) available, the probability that the correct signal
is detected in the signal region (H1 condition) is given by
Pd(|ri,0(k)|) = Pr(|ri,j(k)| > ˆηsyn; H1)
(3.12)
= Q
 
(ˆηsyn −√ε ˆA)
ˆσ
!
+ Q
 
(ˆηsyn + √ε ˆA)
ˆσ
!
where √ε ˆA is the signal parameter that can be estimated in the signal region
as √ε ˆA = E(ri,j(k); H1). By using the detection threshold (3.11) with a ﬁxed
false alarm rate in (3.8), the signal start region (ˆis) can be detected at the
probability of (3.12) and the communication synchronization can be asserted.
3.5
TOA Estimation
3.5.1
Spectrum Matching
To eliminate the large error that misdetected the interference as signal during
the symbol synchronization process, distinct features of the signal and the
interference should be extracted. However, the acoustic waveform is directly
generated by low-complexity anchor nodes; sophisticated waveform design or
pulse compression approaches are not applicable.
The common way to diﬀerentiate two signals is to perform matching by
utilizing their time-domain or frequency-domain feature. However, the remain-
ing interferences after the preprocessing could be very similar to the normal

Acoustic Ranging and Communication
■
33
acoustic signal. The reason is that the interferences were sharpened similar to
the beacon by the FIR ﬁlter. It is also the reason that in-band interference is
hard to mitigate.
Our solution is to calculate the energy spectral density (ESD) of the square
root of the acoustic signal power. By comparing the feature of the ESD of
received signal to the pre-stored feature of the beacon, interferences with dif-
ferent ESD features could be mitigated. The rationale is that the spectral
diﬀerences would be enlarged when performing non-linear transform. The cal-
culation of the square root of the signal power is a kind of nonlinear process
by which the spectrum of the initial signal is changed. If the initial spectrum
of the interference looks similar to the signal and is hard to diﬀerentiate, the
transformed spectrum has a decreased probability of similarity.
0
0.5
1
1.5
2
2.5
x 10
4
−260
−240
−220
−200
−180
−160
−140
−120
Frequency [Hz]
ESD
(a) Noise
0
0.5
1
1.5
2
2.5
x 10
4
−100
−80
−60
−40
−20
0
Frequency [Hz]
ESD
(b) Interference
0
0.5
1
1.5
2
2.5
x 10
4
−90
−80
−70
−60
−50
−40
−30
−20
Frequency [Hz]
ESD
(c) Signal
0
0.5
1
1.5
2
2.5
x 10
4
−240
−220
−200
−180
−160
−140
−120
Frequency [Hz]
ESD
(d) Noise
0
0.5
1
1.5
2
2.5
x 10
4
−120
−100
−80
−60
−40
−20
Frequency [Hz]
ESD
(e) Interference
0
0.5
1
1.5
2
2.5
x 10
4
−110
−100
−90
−80
−70
−60
−50
−40
Frequency [Hz]
ESD
(f) Signal
Figure 3.4: The energy spectral density for the cases of (a) pure noises,
(b) interference, and (c) signal.
Fig. 3.4 lists the examples of the energy spectrum density (ESD) for three
kinds of signals: noise, interference, and beacon signal. From Fig. 3.4, we
know that the ESD of the signal features three peaks in the center region that
diﬀers the noise and interference. Detecting the three peaks (local extrema)
by adjusting the kurtosis, slope threshold, and amplitude threshold can be
an eﬀective noise and interference mitigation approach. The solution that we

34
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
propose here is not perfect for solving the problem of in-band interference
mitigation, but works surprisingly well in real situations with carefully tuned
parameters of thresholds.
3.5.2
Cluster Detection
When considering interference, one symbol duration could contain multiple
pulses and at most one of them is the real signal. If the wrong pulse is detected
as the signal, signiﬁcant ranging error would be introduced. To address this
problem, we utilize the high timing resolution property of the low-duty-cycle
acoustic beacon, i.e., the interference and the signal are separable in the time-
domain for most of the cases. First, detect the existence of multiple pulses;
second, cluster the signal regions by the detection result; and ﬁnally, perform
the spectrum matching for each cluster. In this way, individual pulses could
be examined and interference mitigated, making the detection probability of
the signal signiﬁcantly improved.
Fig. 3.5(a) shows an example of two pulses in one frame duration. Initially,
no distinct feature exists in the time-domain, and it is hard for the TOA
estimation module to determine which one is the true signal.
0
1000
2000
3000
4000
0
2
4
6
8 x 10
−4
Sampling Points
Amplitude
Cluster1: Interference
Cluster2: Signal
(a) Time-domain
0
0.5
1
1.5
2
2.5
x 10
4
−120
−100
−80
−60
−40
−20
Frequency [Hz]
ESD
(b) ESD of the ﬁrst
cluster
0
50
100
150
200
−120
−100
−80
−60
−40
Frequency [Hz]
ESD
(c) ESD of the second
cluster
Figure 3.5: (a) Initial time-domain waveform of two clusters, (b) ESD of
the ﬁrst cluster, and (c) ESD of the second cluster.
We propose to perform feature extraction, then cluster feature values de-
tected in the frame using the K-nearest approach, where K could be chosen as
the length of transmitted pulse duration. In Fig. 3.5(a), two clusters without
overlap are obtained. In the next step, spectral clustering could be utilized
for each cluster. Fig. 3.5(b) and Fig. 3.5(c) are the ESD features for the two
clusters during the spectrum matching process. By matching ESD, the second
cluster is identiﬁed as the true TOA path.

Acoustic Ranging and Communication
■
35
3.5.3
TOA Estimation Procedure
When ˆis is obtained in (3.8), we perform precise detection for the TOA path
in the symbol region near ˆis. Jump-back and search-forward (JBSF) [49] is
a method that is suitable for precise TOA searching after coarse detection.
We deﬁne zk = |ris,j(isNk −Jb, . . . , isNk + Ms)| as the subtracted decision
sequence for TOA estimation, and Jb is the number of sampling points that
jumped back in JBSF; the length of zk is Mk = Jb + Ms + 1. The decision
process in this part can be written as
ˆτ T OA
j
=
(3.13)
Ts · [min(k|zk > ˆηT OA) +ˆisNk −Jb] −1
2Ts
k < Mk
Re-estimate ˆis
k ≥Mk
where ˆηT OA is the precise TOA estimation threshold; ˆis obtained in the pre-
vious detection stage indicates the symbol period; Jb can be set the same as
the step size in the ﬁrst step detection; i.e., Jb = Nk. The second part of
(3.13) means that we need to re-estimate the signal region when the decision
process cannot obtain a TOA value in zk and k ≥Mk, that is, no sampling
point crossed the threshold. This problem is often due to the false detection in
symbol synchronization; a suitable way to solve this problem is to re-estimate
ˆis. From such a process, we know that the overall false alarm rate in SS (3.8)
can be lowered in TOA estimation.
3.5.4
Maximizing the Right Detection Probability
In (3.13), the TOA threshold ˆηT OA should be determined before the deci-
sion process. The decision vector zk also follows the folded normal distri-
bution in (3.9) and with the same statistical parameters. Then the prob-
ability that sample zk crosses the threshold in the noise and signal region
can be calculated as in (3.10) and (3.12); shown as Pfa(zk) and Pd(zk),
respectively. The probability that detected the right TOA path can be de-
noted as Prt, the two kinds of TOA estimation errors are the early detection
Ped and late detection Pld. Ped is caused by selecting the incorrect cross-
ing samples earlier than the true TOA path due to noise interference; Pld
is the probability is that the TOA estimator missed the true TOA path,
and detected a wrong sample in the signal region later due to channel fad-
ing. Assume the true TOA path kT OA
j
is uniformly distributed in the re-
gion of the estimation area (isNk −Jb, . . . , isNk + Ms) with total length of
Mk = Jb + Ms + 1. The probability that the true TOA path in any sampling
point is ptoa = 1/Mk. The early detection probability that detected one point
in the noise region is Ped(kT OA
j
) = 1−(1−Pfa(zk))kT OA
j
, which means at least
one sample crossed the threshold before the TOA path. The late detection
Pld(kT OA
j
) = (1 −Pd(zk))(1 −Pfa(zk))kT OA
j
shows the TOA point is missed.
The right detection probability is Prt(kT OA
j
) = Pd(zk)(1 −Pfa(zk))kT OA
j
,

36
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
where P (Ped(kT OA
j
) + Prt(kT OA
j
) + Pfa(kT OA
j
)) = 1. Since kT OA
j
is uni-
formly distributed with probability ptoa, the expectation for the error esti-
mation probability over kT OA
j
is
P T OA
err
= EkT OA
j
 Ped(kT OA
j
) + Pfa(kT OA
j
))

(3.14)
=
Mk
X
kT OA
j
=0
 1
Mk
[1 −(1 −Pfa(zk))kT OA
j
]

+
Mk
X
kT OA
j
=0
 1
Mk
[(1 −Pd(zk))(1 −Pfa(zk))kT OA
j
]

= 1 −
Pd(zk)
MkPfa(zk)[1 −(1 −Pfa(zk))M
k ]
where the last part of (3.14) is the correct detection probability P T OA
rt
=
Pd(zk)[1 −(1 −Pfa(zk))M
k ]/MkPfa(zk). Performing Taylor expansion of (1 −
Pfa(zk))M
k , we have (1 −Pfa(zk))M
k ≈1 −MkPfa(zk) + C2
Mk(Pfa(zk))2. Then
P T OA
rt
can be simpliﬁed as
P T OA
rt
≈
Pd(zk)
MkPfa(zk)(MkPfa(zk) −C2
Mk(Pfa(zk))2)
(3.15)
= Pd(zk)[1 −1
2(Mk −1)Pfa(zk)]
From (3.15), we know that increasing Pd(zk) or decreasing Pfa(zk) of the
single sampling point can contribute a better P T OA
rt
. Small Mk also helps to
improve the performance in that less sampling points are detected.
To achieve a better TOA estimation scheme, selecting an appropriate TOA
threshold by maximizing P T OA
rt
provides a feasible way. Since Pd(zk) and
Pfa(zk) is a function of ˆηT OA, P T OA
rt
can be written as P T OA
rt
(ˆηT OA). The
maximum value of P T OA
rt
can be achieved when ˆηT OA = ˆηoth
T OA, as
ˆηoth
T OA = arg max
ˆηT OA(P T OA
rt
(ˆηT OA))
(3.16)
For simpliﬁcation, we can use the Maclaurin series of the error function
erf(x) =
2
√π
P∞
n=0[(−1)nx2n+1]/[n!(2n+1)] to express the approximate func-
tion of Q(x) as
Q(x) ≈1
2 −1
2erf(x/
√
2)
(3.17)
= 1
2 −
1
√π (x/
√
2 −(x/
√
2)3
3
+ . . .)
when x is very small; even the ﬁrst-order term of (3.17) can well represent
Q(x) as Q(x) ≈1/2 −x/
√
2π. Let’s deﬁne z = ˆηsyn/ˆσ and s = √ε ˆA/ˆσ.

Acoustic Ranging and Communication
■
37
If you only consider s > 0, then Pd(zk) and Pfa(zk) can be simpliﬁed as
Pd(zk) ≈1/2 −(z −s)/
√
2π and Pfa(zk) ≈1 −2z/
√
2π.
By substituting Pd(zk) and Pfa(zk) into (3.15), and deﬁning w = 1
2(Mk −
1), P T OA
rt
can be written as
P T OA
rt
(z) = [1/2 −(z −s)/
√
2π][1 −w(1 −2z/
√
2π)]
(3.18)
= −w
π z2 + (2w −1
2
√
2π + ws
π )z + 1 −w
√
2π s + 1 −w
2
where (3.18) is a convex function with its maximum achieved when z = s
2 +
√π
2
√
2(1 −
1
2w). Then, ˆηoth
T OA can be written as
ˆηoth
T OA = 1
2
√ε ˆA +
√π
2
√
2(1 −
1
Mk −1)ˆσ
(3.19)
where √ε ˆA and ˆσ can be estimated the same as in (3.11). By using (5.10) in
TOA estimation of (3.13), the optimized TOA performance can be achieved
under the criterion of maximum right detection probability as shown in (3.16).
3.6
Acoustic Symbol Demodulation
3.6.1
Challenges of Audible-Band Communication
For frequency-modulated signal, we can model gi,j(k) = √ε cos(2πfdk +
φ), d = 0, 1, where φ is the unknown phase information between the local tem-
plate and received carrier wave, fd = f1 represents the symbol “1”; fd = f0
represents the symbol “0.” Using an audible band microphone receiver poses
two additional challenges for communication decisions. The ﬁrst challenge is
hardware limitation. Conventional receivers often perform orthogonal down-
conversion to the baseband, and such a process can estimate both the fre-
quency and phase information; i.e., jointly using sin and cos to estimate the
φ. The reason that we cannot use orthogonal demodulation is due to the
limitation of our hardware structure. In an audio system, the acoustic signal
captured by a microphone is directly sampled by the analog digital converter
(ADC) at the frequency of Fs. When the signal is sampled to the digital
domain, there is no orthogonal down-conversion process for the typical pro-
cessing unit. Such a process is quite simple since the microphone receiver is
designed for normal voice and music, which is already in the baseband. With
no down-conversion and frequency discriminator circuit, the conventional FSK
demodulation method is not suitable. For such a reason, we need to design
a new communication decision scheme to derive the information bits carried
by the acoustic signal. The second challenge is caused by the poor channel
condition of audible band acoustic signal compared with microwave and ul-
trasound signal. Assuming the channel coherent bandwidth is Bco, the system

38
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
bandwidth B = 1.48KHz is B ≪Bco for microwave signal. Such a channel
condition can be assumed as ﬂat for f1 and f0. However, 1.48KHz should be
viewed as wideband for acoustic signal, i.e., B > Bco. Thus the channel-fading
eﬀect should be considered for better demodulation performance.
3.6.2
Communication Demodulation
Assume the received multi-path frequency-modulated signal is ri,j(k) =
Pξi,j−1
l=0
√ε cos(2πfbk + φ + ϕl(fb)), b = 0, 1; ϕl(fb) is a function of fb due to
the frequency selective channel where f0 and f1 may suﬀer diﬀerent fading; f0
and f1 represent the symbol “0” and “1.” Construct the local correlation tem-
plate v0(k) = cos(2πf0k) and v1(k) = cos(2πf1k) to demodulate the symbol
“0” and “1.” Then, use the constructed local templates to perform correlation
and information extraction. For symbol representation, the correlation process
can be shown as
a0
i,j = Ek{gi,j(k) · v0(k)} + w0
i,j,
(3.20)
a1
i,j = Ek{gi,j(k) · v1(k)} + w1
i,j
where wb
i,j = E{ni,j(k) · vb(k)}; b = 0, 1; k ∈[ktoa
j
+ iNk, ktoa
j
+ (i + 1)Nk],
i = 0, . . . , Ns −1. Deﬁne sb
F = [Ek{gi,j(k) · v0(k)}, Ek{gi,j(k) · v1(k)}]T , a =
[a0
i,j, a1
i,j]T , and w = [w0
i,j, w1
i,j]. The process of E(·) performs ﬁltering and
averaging. Use symbols “0,” for example. When the signal is presented with
two multi-paths (ξi,j = 2), frequency demodulation of s0
F can be rewritten as
s0
F
(3.21)
= sup
φ
1
⌈Fs/B⌉
⌈Fs/B⌉
X
k=1
ξi,j−1
X
l=0
√ε cos(2π∆f · k + φ + ϕl(fb))
= sup
φ
mean
k
[2√ε cos(2π∆f · k + φ + ϕ+(fb)) cos(ϕ−(fb))]
where ϕ+(fb) = (ϕ0(fb)+ϕ1(fb))/2, ϕ−(fb) = (ϕ0(fb)−ϕ1(fb))/2 for l = 0, 1;
∆f = fb−f0; the bandwidth is B = (f0−f1). supφ calculates the super-bound
of the function with the parameter of φ, i.e., the envelope. When symbol “0”
is transmitted (fb = f0, ∆f = 0), we have
s0
F (0) = sup
φ
2√ε cos(2πk0 + φ + ϕ+(fb)) cos(ϕ−(fb))
(3.22)
= 2√ε cos(ϕ−(fb))
When the opposite symbol is transmitted (fb = f1, ∆f = B), (3.21) can be
shown as
s1
F (0) = sup
φ
2√ε cos(2πkB + φ + ϕ+(fb)) cos(ϕ−(fb))
(3.23)

Acoustic Ranging and Communication
■
39
From (3.22) and (3.23), we know that decision vector s0
F = [2√ε cos(ϕ−(f0)), 0]T
when symbol “0” is transmitted; s1
F = [0, 2√ε cos(ϕ−(f1))]T when symbol
“1” is transmitted. With the equal prior probability P(b = 0, 1) = 1/2, the
maximum-likelihood (ML) is the optimal decision rule, resulting in
ˆdml = sgn[log P(a|b = 1)
P(a|b = 0)] = sgn[Λ]
(3.24)
where P(a|b = 1) is the likelihood function of the received data vector sF
conditioned on the symbol “1” transmitted; P(a|b = 0) is for symbol “0.” Λ
is the log-likelihood ratio (LLR).
For the frequency demodulation of (3.20), we deﬁne the decision vector as
y. The decision process can be written as
y = a(1) −a(0) = dδ + wF (1) −wF (0) ≷1
0= ηd
(3.25)
where dδ = s1
F −s0
F . From (3.22) and (3.23), we can calculate dδ =
[2√ε cos(ϕ−(f1)), −2√ε cos(ϕ−(f0))]T , where ηd is the communication deci-
sion threshold. When y is larger than the threshold, we can declare the infor-
mation bit “1” is transmitted, and vice versa.
3.6.3
Dynamic Demodulation with Transmit Reference
Only using FSK for demodulation may suﬀer signiﬁcant performance loss due
to the multi-path fading eﬀect. To deal with such a problem, we should utilize
additional diﬀerence in symbol “0” and “1” to facilitate demodulation. From
ri,j(k), we know that f0 and f1 have the same amplitude when the channel is
ﬂat enough, i.e., ϕl(f0) = ϕl(f1). Conventional FSK is constant-amplitude de-
modulation for narrow bandwidth signal, but B = 1.48KHz can be considered
wideband for acoustic signal. These frequency-selective phenomena do cause
some problems when using FSK demodulation, but allow the signal amplitude
to be diﬀerent for f0 and f1. Utilizing the amplitude diﬀerence can help to
compensate the attenuation when ϕ−(fb) ≈π/2. Considering the envelope of
ri,j(k), and only calculating two multi-paths, we have
sA(b) = sup
φ
ξi,j−1
X
l=0
√ε cos(2πfbk + φ + ϕl(fb))
(3.26)
= sup
φ
2√ε cos(2πkfb + φ + ϕ+(fb)) cos(ϕ−(fb))
= 2√ε cos(ϕ−(fb))
Since ϕ−(f1) ̸= ϕ−(f0), the amplitude of symbol “1” and “0” is also
diﬀerent, i.e., sA(0) ̸= sA(1). If the FSK result for one symbol is equal to
zero, we can assume its probability is pF = Pr{ϕ−(f0) ≈π/2}. Then, the
probability that another symbol also has ϕ−(f1) ≈π/2 is (pF )2, and (pF )2 ≪

40
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
pF < 1. For such a reason, we can assume that the ϕ−(fb) for symbol “1”
and “0” is diﬀerent and can be used for detection when the FSK result of one
symbol shows signiﬁcant small-scale fading.
Assuming the equal prior probability P(b = 0, 1) = 1/2, and the ML is the
optimal decision rule, has
ˆdml = sgn[log P(a|b = 1)
P(a|b = 0)] = sgn[Λ]
(3.27)
where P(a|b = 1) is the likelihood function of the received data vector condi-
tioned on the symbol “1” transmitted; P(a|b = 0) is for symbol “0.” Λ is the
log-likelihood ratio (LLR).
For the frequency demodulation of (3.34), we deﬁne the decision vector as
yF , the decision process can be written as
yF = sF (1) −sF (0) = ±√ε + wF (1) −wF (0) ≷1
0 0
(3.28)
when yf is larger than “0,” then we can declare the information bit “1” is
transmitted, and vice versa.
For the amplitude detection when one symbol shows signiﬁcant small-scale
fading, the diﬀerence between the received signal amplitude and the reference
value can be used as the decision vector, as
sA =
h
|sA(b) −sref
A (0)|, |sA(b) −sref
A (1)|
iT
(3.29)
where sref
A (0) and sref
A (1) served as prior information are the known ampli-
tude for symbol “0” and “1.” These two parameters can be obtained by using
transmit reference (TR), e.g., transmit two bit of “1” and “0” at the beginning
of the beacon period. At the receive side, we can assume that these TR bits
suﬀer the same attenuation as other bits in the same beacon period. Calcu-
lating the amplitude of TR bit can provide sref
A (0) and sref
A (1) in amplitude
demodulation of (3.37). Such a TR scheme is a simpliﬁed method for channel
estimation, and can be used as a ﬁngerprint to characterize the channel eﬀect
to the received information bit. From (3.26), we can know that sref
A (b) is also
equal to sref
A (b) = 2√ε cos(ϕ−(fb)).
By comparing the amplitude diﬀerence in (3.37), the symbol that is most
likely transmitted will be declared. Substituting (3.26) into (3.37), we have
sA = [√εδ, 0]T when the information bit b = 1; sA = [0, √εδ]T when b = 0,
where √εδ = 2√ε| cos(ϕ−(f1)) −cos(ϕ−(f0))|. We deﬁne the decision vector
as yA, then we have the decision process as
yA = sA(1) −sA(0) = ±√εδ + wA(1) −wA(0) ≷1
0 0
(3.30)
where wA is the noise vector when symbol “1” or “0” is transmitted.
Combining (3.28) and (3.30) together, we can obtain a joint ASK/FSK
decision rule as
yjoint = sF (1) −sF (0)
√ε
(1 −µ) + sA(1) −sA(0)
√εδ
µ ≷1
0 0
(3.31)

Acoustic Ranging and Communication
■
41
where µ is the weighting coeﬃcient. The joint demodulation of (3.38) is only
needed when one symbol suﬀers signiﬁcant attenuation; otherwise, using the
amplitude in demodulation with no envelope distinction may provide negative
eﬀects. Thus, we should set µ according to
µ =
( |sref
A
(0)−sref
A
(1)|
(sref
A
(0)+sref
A
(1)),
ξ ̸= 0
0,
ξ ≈0
(3.32)
where ξ = (sref
A (0) −snoise) · (sref
A (1) −snoise), snoise =
p
2/πˆσ is the ampli-
tude value of the noise and can be estimated by using ˆσ =
p
π/2E(zi; H0).
(3.32) shows that when one of the symbols is seriously attenuated, joint de-
modulation should be used to prevent performance degradation; when the
amplitude of symbols does not show diﬀerence, only using frequency demod-
ulation is suﬃcient and should set µ in (3.38).
The decision error can be written as
Perror = P(b = 0)P(y > 0|b = 0) + P(d = 1)P(y < 0|b = 1)
(3.33)
= 1
2
Z ∞
0
1
√
2πσ2 exp(−(x +
p
Eb)2/(2σ2))dx
+ 1
2
Z 0
−∞
1
√
2πσ2 exp(−(x −
p
Eb)2/(2σ2))dx
= ˆQ(−
p
Eb/Nb)
where the σ2 = N0 in (3.40) is noise variance of the decision vector.
After the symbol synchronization and TOA estimation, we can perform
symbol demodulation for every Nk points from kT OA
j
to obtain the information
bit. For the frequency modulated signal of gi,j(k), we can model gi,j(k) =
√ε cos(2πfdk + φ), d = 0, 1, where φ is the ﬁxed unknown phase information
between the local template and received carrier wave, fd = f1 represents the
symbol “1”; fd = f0 represents symbol “0.”
One feasible way to demodulate the information is to construct the local
correlation template v0(k) = cos(2πf0k) and v1(k) = cos(2πf1k) for symbol
“0” and “1,” respectively. The constructed local template is used to perform
correlation and information extraction. For symbol representation, the deci-
sion vector can be shown as sF = [Ek{gi,j(k) · v0(k)}, Ek{gi,j(k) · v1(k)}]T ,
the process of E(·) performs ﬁltering and averaging. Using symbol “0” for
example, and assuming the bandwidth is B = (f0 −f1), then
sF (0) = Ek{√ε cos(2πfdk + φ) cos(2πf0k)}
(3.34)
= sup
φ
1
⌈Fs/B⌉
⌈Fs/B⌉
X
k=1
√ε cos(2π(fd −f0)k + φ)
where the high frequency part fd + f0 has been ﬁltered out; ⌈·⌉is to calculate

42
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
the minimum integer that is larger than the input value; supφ is used to cal-
culate the super-bound of the function with the parameter of φ, i.e., calculate
the envelope of the input signal. When fd = f0, then (3.34) can be written as
sF (0) = sup
φ
√ε cos(2πk0 + φ) = √ε
(3.35)
When fd ̸= f0, the result of (3.34) is
sF (0) = sup
φ
1
⌈Fs/B⌉
⌈Fs/B⌉
X
k=1
√ε cos(2πBk + φ)
(3.36)
= sup
φ
E
θ∈[0∼2π][cos(θ + φ)] ≈0
where Eθ[·] approximates to obtain the mean value of cos(·) in a whole period,
which is equal to zero and irrelevant to the phase φ. From (3.35) and (3.36),
we can know that the same local template can obtain distinct values (0 and
√ε) when the input signal is diﬀerent. Using these distinct values will map
the input signal to the information domain. Deﬁne the decision vector for
frequency demodulation as sF , and sF = [√ε, 0]T when the information bit
b = 0; sF = [0, √ε]T when b = 1, ε is the transmitted bit energy.
Only using frequency for demodulation may suﬀer signiﬁcant performance
loss due to the multi-path fading eﬀect. For microwave signal, the channel can
be assumed as ﬂat for several KHz, but not for acoustic signal. Frequency f1
and f0 may suﬀer diﬀerent attenuation; such a channel fading eﬀect should be
considered for better demodulation performance. To deal with such problems,
the amplitude diﬀerence of symbols “1” and “0” can help to compensate the
performance loss when we perform joint frequency and amplitude detection.
For the amplitude detection when one symbol shows signiﬁcant small-scale
fading, the diﬀerence between the received signal amplitude and the reference
value can be used as the decision vector, as
sA =
h
|sA(b) −sref
A (0)|, |sA(b) −sref
A (1)|
iT
(3.37)
where sref
A (0) and sref
A (1) are the prior information of amplitude for symbol
“0” and “1,” sA(b) is the amplitude of the received signal. The parameters of
sref
A (0) and sref
A (1) can be obtained by using transmit reference (TR), e.g.,
transmit two bit of “1” and “0” at the beginning of the beacon period. At the
receive side, we can assume that these TR bits suﬀer the same attenuation
as other bits in the same beacon period. Calculating the amplitude of TR bit
provides sref
A (0) and sref
A (1) in amplitude demodulation of (3.37). Such a TR
scheme is a simpliﬁed method for channel estimation, and is used as ﬁngerprint
to characterize the channel eﬀect. For the decision vector, and sA = [√εδ, 0]T
when the information bit b = 0; sA = [0, √εδ]T when b = 1, εδ is the energy
diﬀerence.

Acoustic Ranging and Communication
■
43
We can obtain the dynamic decision rule as
yjoint = sF (1) −sF (0)
√ε
(1 −µ) + sA(1) −sA(0)
√εδ
µ ≷1
0 0
(3.38)
where µ is the weighting coeﬃcient. The joint demodulation of (3.38) is only
needed when one symbol suﬀers signiﬁcant attenuation; otherwise, using the
amplitude in demodulation with no envelope distinction may provide negative
eﬀects. Thus, we set µ according to
µ =
( |sref
A
(0)−sref
A
(1)|
(sref
A
(0)+sref
A
(1)),
ξ ̸= 0
0,
ξ ≈0
(3.39)
where ξ = (sref
A (0) −snoise) · (sref
A (1) −snoise), snoise =
p
2/πˆσ is the ampli-
tude value of the folded noise. (3.39) shows that when one of the symbols is
seriously attenuated, joint demodulation should be used.
If the decision vector yjoint is larger than 0, symbol “1” can be declared;
otherwise symbol “0” is detected. After demodulating the information bit
carried by the acoustic beacon signal, we can decode these bits to obtain
the position information of the anchor node for the localization purpose. The
decision error can be written as
Perror = P(d = 0)P(y > 0|d = 0) + P(d = 1)P(y < 0|d = 1)
(3.40)
1
2
Z ∞
0
1
√
2πσ2 exp(−(x +
p
Eb)2/(2σ2))dx
+ 1
2
Z 0
−∞
1
√
2πσ2 exp(−(x −
p
Eb)2/(2σ2))dx
= ˆQ(−
p
Eb/Nb)
where the σ2 = N0 in (3.40) is noise variance of the decision vector.
3.7
Performance Evaluation
3.7.1
Experiment Setup
We conducted the measurement in an oﬃce environment to test the signal-to-
noise ratio (SNR), bit-error-rate (BER), and TOA normalized mean square
error (NMSE) at diﬀerent communication distances to evaluate the system
performance of TOA estimation and communication. We moved the anchor
node away from the microphone from 0.254m to 7.366m, and conducted mea-
surement for every 0.1m with more than 400s sampling data acquired in each
measurement, Np = 400. The beacon period is Tp = 0.9710s, while symbol du-
ration is Ts = 0.0205s. The symbol number in one beacon period is Ns = 17,
with 15 information bits as the unique ID of each anchor, and 2 bits (“1” and

44
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
0
2
4
6
8
0
10
20
30
40
Distance [m]
SNR [dB]
 
 
f1
f0
(a) SNR
0
2
4
6
8
0
0.05
0.1
0.15
0.2
0.25
Distance [m]
NMSE
 
 
OTH−DD
OTH−FD
FD
(b) NMSE
0
2
4
6
8
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Distance [m]
BER
 
 
OTH−DD
OTH−FD
FD
(c) BER
Figure 3.6: The SNR (a), NMSE (b) and BER (c) measurement results
with respect to the distance.
“0”) for transmit reference. The sampling rate is Fs = 44.1KHz, with the
symbols modulated in the frequency of f1 = 17.72KHz and f2 = 19.2KHz.
To observe the signal attenuation with distance change, we measure
the SNR value of symbols “1” and “0” with respect to the communica-
tion distance. The empirical SNR calculation equation used is SNR(b) =
20 log10[(S(b)/snoise)], where S(b) is the signal mean absolute value for infor-
mation bit b, and snoise =
p
2/πˆσ is the mean absolute value of noise.
For the evaluation of the TOA estimation and communication perfor-
mance, three diﬀerent methods are evaluated and compared. The ﬁrst one
uses the conventional two-step TOA estimation without the threshold opti-
mization and frequency demodulation (“FD”) method; the second one uses the
optimized threshold in TOA estimation, called “OTH-FD”; the last one uses
both the TOA optimized threshold and our proposed dynamic demodulation
(DD), called “OTH-DD.”
The normalized mean square error (NMSE) is used in this paper to char-
acterize the accuracy of the TOA result by using NMSE = [(ˆτ T OA −
τ T OA)/τ T OA]2. We measure the BER value by comparing the demodu-
lated information bit (ˆbi) to the real transmitted data (bi) by BER =
PNs−1
i=0
|ˆbi −bi|/Ns.
3.7.2
Experimental Results
The measurement results of SNR degradation vs. distance are shown in
Fig. 3.6(a). The results show that the small-scale fading of the acoustic signal
is strong, while f0 and f1 suﬀered diﬀerent attenuation. For most distances,
the attenuation of the frequency f0 is stronger than f1 due to its slightly
higher frequency.
The results of NMSE with respect to distance are shown in Fig. 3.6(b).
The x-coordinate is the distance between the transmitter and the receiver, and
the y-coordinate is the measured NMSE. For smaller distances (< 4.4m), the

Acoustic Ranging and Communication
■
45
Table 3.1: Performance comparison with respect to diﬀerent methods
under speciﬁc probability
Methods
Metrics
70%
80%
OTH-DD
NMSE
0.0005
0.0031
Range Error (m)
0.0864
0.5270
BER
0.0055
0.0099
OTH-FD
NMSE
0.0041
0.0259
Range Error (m)
0.69
4.4
BER
0.0083
0.0152
FD
NMSE
0.0812
0.1142
Range Error (m)
13.8107
19.4062
BER
0.2303
0.4267
NMSE values for the three methods are all very low, showing that the TOA
estimation is very accurate when SNR is strong. For larger distances (> 4.4m),
the estimation error is increased due to the attenuation of the signal. Using
our proposed optimized TOA threshold, “OTH-FD” and “OTH-DD” achieved
better performance than the “FD” case. While using dynamic demodulation,
some erroneous TOA estimation results can be identiﬁed and ﬁltered by its
BER value, thus making the TOA estimation accuracy of “OTH-DD” slightly
better than “OTH-FD” due to its better BER performance.
The BER experiment results are shown in Fig. 3.6(c), with its y-coordinate
as the measured BER. Using our optimized TOA threshold, “OTH-FD” and
“OTH-DD” achieve better performance than the “FD” case, while using dy-
namic demodulation can even lower the error rate as shown in “OTH-DD.”
For Fig. 3.6(b) and Fig. 3.6(c), the most interesting point is near 4.11m; the
performance of TOA estimation and communication for all the three methods
are really worse at that point. From the echo in that distance, it shows that the
waveform has been seriously attenuated both for symbol “1” and “0.” There
may be several multi-path signals arrived at for the receiver, with negative
phase and canceling with each other. Such a dead zone may aﬀect the ﬁnal
position result, but using more redundant anchor nodes can compensate the
performance loss.
To evaluate the performance at speciﬁc probability, we write the maxi-
mum TOA estimation error and BER under a given probability as shown in
Table 3.1. The metric of range error is calculated by NMSE to characterize the
ranging accuracy. This table illustrates that 70% or 80% of the total results
are less than the given value, e.g., the value 0.0005 means 70% of the NMSE
results are less than 0.0005. From Table 3.1, we know that the maximum range
error is less than 0.0864m with 70% probability when using “OTH-DD,” such
ranging accuracy is much higher than other existing schemes based on perva-
sive hardware; it is suﬃcient to guarantee a precise indoor localization result.

46
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
3.7.3
Communication and Ranging Results
The metric for assessing the performance of communication is bit-error-rate
(BER); the metric for ranging accuracy is the estimation variance deﬁned by
σrange = c
p
E[(ˆτ T OA −τ T OA)]2, where c is the speed of acoustic signal. To
test the communication and ranging performance under diﬀerent operating
distances, we conducted experiments for measuring the BER and variance
when putting the smartphone at diﬀerent distances from 2.18m ∼7.26m.
The BER and variance results obtained by detecting the beacon signal for
one anchor node are shown in Table 3.2. From Table 3.2, we know that some
distance region, e.g., near 5.2m, has high BER and variance due to the blockage
or interference of the beacon signal. When the distance between anchor node
and smartphone reaches 7.26m, the ranging and communication results are
still acceptable. Such a result demonstrates that the operating distance of our
proposed system is suﬃcient for indoor localization.
Table 3.2: BER and ranging NMSE results in diﬀerent distances
Distance(m)
2.1844
3.2004
4.2164
5.2324
6.2484
7.2644
BER
0.0015
0
0.0016
0.0202
0.0020
0.0095
Variance(m)
0.021
0.016
0.035
4.637
0.015
0.067
Table 3.3: BER and ranging variance results for 4 anchor nodes when a
smartphone is placed in Env1(1.68, 1.02)m and Env2(4.6, 1.03)m
Index
Metrics
m=1
m=2
m=3
m=4
Env1
BER
0.0049
0.0040
0.0011
0.0015
Range Variance (m)
0.0521
0.9597
0.0747
0.5004
Env2
BER
0.0043
0.0029
0.0031
0.0029
Range Variance (m)
0.9433
0.6917
0.2488
1.2249
To test the BER and variance in real localization scenarios, the communi-
cation and ranging results from 4 anchor nodes when a smartphone is placed
in two positions are shown in Table 3.3. From Table 3.3, we know that the
communication performance is suﬃcient for localization, with the largest BER
less than 0.49%. The ranging variance from diﬀerent anchor nodes is hard to
compare due to the various propagation blockages or interference. The average
ranging variance in Env2 is slightly larger than in Env1.
To better evaluate the relative ranging performance of ˆrm with the refer-
ence node of f = 1, we calculate the CDF of the measured relative distance
from node 2 to 1 (“RD2-1”), node 3 to 1 (“RD3-1”), and node 4 to 1 (“RD4-

Acoustic Ranging and Communication
■
47
0
0.2
0.4
0.6
0.8
0
0.2
0.4
0.6
0.8
1
Range Error (m)
CDF
 
 
RD2−1
RD3−1
RD4−1
RD2−1
RD3−1
RD4−1
(a) relative range
0
50
100
150
0.97650
0.97655
0.97660
0.97665
Beacon Period
Estimated Period (s)
 
 
Node 1
Node 2
Node 3
Node 4
(b) beacon period
Figure 3.7: The relative range results (a) and beacon period estimation
results (b) when a smartphone is placed in Env1(1.68, 1.02)m.
1”) as shown in Fig. 3.7(a). The results show that the ranging result of node
4 is less accurate than those for nodes 2 and 3. If choosing 80% probability as
standard, the accuracy of relative distance of “RD2-1” and “RD3-1” is near
0.17 meters, while the “RD4-1” case can achieve accuracy of 0.32 meters in
Env1.
The beacon period Tp in (4.4) is another important parameter that needs
to be estimated before the localization process. Due to the imperfect clock
used in hardware, diﬀerent anchor nodes may have slightly diﬀerent oﬀsets.
The estimated period from four anchor nodes is shown in Fig. 3.7(b), with
very small noise variance. Estimating Tp periodically in real-time is a suitable
approach to compensate the oﬀset and improve accuracy.
3.8
Conclusion
We developed a TOA estimation and communication scheme that utilizes per-
vasive microphone channels and low-complex anchor nodes. Using the acoustic
signal for ranging and localization can achieve high accuracy with no addi-
tional hardware requirement for users. To facilitate the ranging and commu-
nication under the restriction of the speaker/microphone pair, an optimized
TOA estimation method and a dynamic demodulation scheme have been pro-
posed. The experiment results show that the TOA ranging accuracy can be
achieved within 0.0864 meters with 70% probability; the communication BER
can be less than 0.55% for 70% distances in the range of 0.254 ∼7.366 meters.
Such results of ranging and communication are suﬃcient for accurate indoor
localization applications.


Chapter 4
Localization Algorithms
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
4.1
Trilateration via Relative Distance ..............................
50
4.1.1
Relative Distance from Anchor Nodes ..................
50
4.1.2
Joint Estimation of the Position and Unknown Bias ...
51
4.2
Mobile Phone Localization via Semideﬁnite Programming ......
55
4.2.1
Localization Measurement Model .......................
55
4.2.2
Min-Max Criterion ......................................
56
4.2.3
Semideﬁnite Programming ..............................
57
4.3
Performance Bound and Anchor Network Coverage .............
58
4.3.1
Fisher Information Matrix ...............................
58
4.3.2
Cramer-Rao Low Bound .................................
58
4.3.3
Anchor Network Coverage ...............................
59
4.4
Position Reﬁnement ..............................................
60
4.4.1
NLOS and Error Mitigation .............................
60
4.4.2
Steepest Descent Approach ..............................
61
4.4.3
Coverage Constraint .....................................
62
4.5
Numerical Results ................................................
62
4.6
Experimental Evaluation .........................................
65
4.6.1
Experiment Setup for Localization ......................
65
4.6.2
Localization Results .....................................
66
49

50
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
4.7
Conclusion ........................................................
69
4.1
Trilateration via Relative Distance
4.1.1
Relative Distance from Anchor Nodes
In our design mode for localization, the microphone in the mobile phone only
receives beacons broadcasted by the anchor nodes passively. Such a broadcast
mode can ease the network design and support inﬁnite users at the same
time. The drawback is that two-way ranging cannot be performed. Thus, the
unknown delay needs to be solved during the estimation process.
The obtained ranging results in a passive ranging process are the pseudo-
ranges with unknown delay. Using the pseudo-range in localization, the timing
delay should be resolved in positioning estimation. For 2-D localization, the
three unknown parameters are coordinates (x, y) and the timing delay (δb). To
discriminate between diﬀerent beacon signals, every anchor node modulates
its unique pseudo-code in the beacon signal. For the multi-anchor operation,
we choose the time division multiplexing (TDM) technique. One anchor serves
as the control node and sends synchronization commands and tokens to other
nodes in the network periodically. The period of the control node is also the
beacon period (Tp) of the whole network, where Ts × Ns < Tp. It shows that
every beacon period has some free space in case of inter-beacon interference.
Assuming there are a total of M anchor nodes with each index as m, the
beacon information will be repeated for every M beacons in the j-th symbol,
have m ≡j( mod M) and j = m + ⌊j/M⌋× M, gi,j(k) = gi,m(k). The TOA
value ˆτ T OA
m
is obtained from the mth anchor node periodically. For one round
beacon, the TOA value from the m-th anchor can be written as
ˆτ toa
m
= δb + (m −1)Tp + tm
(4.1)
where m ∈[1, . . . , M], and δb is the unknown beginning time. Tp is the period
time; tm is the ﬂight time of the beacon signal to the microphone. The real
distance rm can be represented by tm as
ˆrm = ctm = c(ˆτ toa
m
−δb −(m −1)Tp)
(4.2)
where δb + (m −1)Tp, diﬀerent from beacon to beacon, is the unknown delay.
To minimize the eﬀect of δb, we substrate the same distance from every mea-
surement to obtain a relative distance value. By selecting one anchor node
with minimum ranging variance as reference, i.e., m = f. By setting ˆrf = 0,
the relative distance of other nodes to this reference point can be written as
ˆrm = [ˆτ toa
m
−ˆτ toa
f
−(m −f)Tp]c + nm −nf
(4.3)
In (4.3), nm and nf are the measurement noise for ˆτ toa
m
and ˆτ toa
f
. Tp is the
preset beacon period with the known initial value. For the distributed system,

Localization Algorithms
■
51
physical clocks are not synchronized between the anchor nodes and the micro-
phone. To improve the accuracy of ranging estimation in (4.3), Tp should be
updated when a new beacon period is received. Deﬁne mt = ⌊j/M⌋as period
index parameter to label the total ⌊Np/M⌋times beacon round. For mt-th
round, Tp can be estimated by
ˆTp(mt) = 1
M
 M
X
m=1
ˆτ toa
m+M(mt+1) −ˆτ toa
m+M(mt)
!
(4.4)
when only consider one round time that the position result is calculated, we
can simplify ˆTp = ˆTp(mt) in the following analysis.
4.1.2
Joint Estimation of the Position and Unknown
Bias
With the measured distance from M anchor nodes, trilateration can be per-
formed to localize the position of the microphone. Assume the real position of
the microphone is p = (x, y). The real distance from the microphone to the
anchor nodes can be assumed as rm =
p
(x −xm)2 + (y −ym)2. The obser-
vation equation for the pseudorange ˆrm is
ˆrm =
p
(x −xm)2 + (y −ym)2 + δ + enm
(4.5)
where m = 1, . . . , M, ˆrf = 0; ˆrm is obtained by (4.3). δ is the unknown
ﬁxed delay for every anchor node, which has been modiﬁed to δ = −rf. enm =
nm−nf is the error of the pseudorange in (4.3). nm is a i.i.d Gaussian random
parameter with noise variance of σ2
m. The variance of enm is σ2
m + σ2
f due to
the substraction made in (4.3). In vector notations, (4.5) can be expressed as
ˆr = f(x, y, δ) + en
(4.6)
where ˆr = [ˆr1, · · · , ˆrM]T , f(x, y, δ) = [r1 + δ, · · · , rm + δ]T , and en =
[n1, · · · , nm]T .
The localization process via the traditional maximum a posteriori (MAP)
estimator can be written as
ˆθMAP = arg max
θ
P(ˆr|θ)g(θ)
(4.7)
where g(θ) is the probability density function (pdf) of parameter θ; P(ˆr|θ) is
the pdf of the measurement vector ˆr conditioned on θ. The conditional pdf of
ˆr can be expressed as
P(ˆr|θ) =
1
p
2π det(σ)
exp

−QT σ−1Q
2

(4.8)
where Q = (ˆr−f(x, y, δ)). σ is the covariance matrix for ˆr as σ = {Cov(ˆri, ˆrj)},

52
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
i, j = 1, . . . , M. det(σ) calculates the determinant of σ. For the Gaussian noise
component in (4.23), it has n ∼N(0, σ) with
σ =


σ2
m + σ2
f
σ2
f
· · ·
σ2
f
σ2
f
σ2
m + σ2
f
...
...
...
...
...
σ2
f
σ2
f
· · ·
σ2
f
σ2
m + σ2
f


(4.9)
After obtaining the conditional pdf of P(ˆr|θ), we should know the distribution
θ before performing MAP estimation.
From f(x, y, δ), we deﬁne the vector of unknown parameters as θ =
[x
y
δ]T . The localization purpose is to estimate (x, y) from measurements.
Diﬀerent approaches like Bayesian or ML estimation techniques can be applied
depending on the prior information about θ. If the prior probability distribu-
tion of θ is known, a maximum a posteriori (MAP) estimator can be applied.
For the case where the distribution of the unknown parameter θ is unknown,
uniform distribution can be assumed. Then, MAP can be simpliﬁed to a max-
imum log-likelihood (ML) estimator as
ˆθML = arg max
θ
log P(ˆr|θ)
(4.10)
where P(ˆr|θ) is the pdf of the measurement vector ˆr conditioned on θ. The
conditional pdf of ˆr can be expressed as
P(ˆr|θ) =
1
p
2π det(σ)
exp

−QT σ−1Q
2

(4.11)
where Q = (ˆr−f(x, y, δ)). σ is the covariance matrix for ˆr as σ = {Cov(ˆri, ˆrj)},
i, j = 1, . . . , M. det(σ) calculates the determinant of σ with
σ =


σ2
m + σ2
f
σ2
f
· · ·
σ2
f
σ2
f
σ2
m + σ2
f
...
...
...
...
...
σ2
f
σ2
f
· · ·
σ2
f
σ2
m + σ2
f


(4.12)
For the Gaussian noise component in (4.23), it has en ∼N(0, σ), where σ is
the error covariance matrix with diagonal entries of σ2
m + σ2
f, other elements
of σ2
f. Using uniform distribution in ML estimation is sort of the worst-case
scenario, while achieving optimal performance under worst-case instead of
global optimal is practical and reasonable.
The result of (4.24) can be achieved by searching over possible parame-
ters that maximize the log-likelihood. For real system implementation, such
a searching process is very computationally intensive and can drain the bat-
tery life of your smartphone quickly. To make this problem even simpler, we

Localization Algorithms
■
53
can assume that all the measurements are independent. Such a special case
is understandable in that all the pseudoranges for anchors are measured in-
dependently and in diﬀerent beacon periods. With such an assumption, the
noise distribution with zero mean and a known covariance matrix (4.24) can
be simpliﬁed as
ˆθML = arg min
θ
(ˆr −f(x, y, δ))T σ−1(ˆr −f(x, y, δ))
(4.13)
where (ˆr −f(x, y, δ)) represents the estimation error, and σ−1 can be repre-
sented as the weighting coeﬃcient for each independent measurement. (4.26)
is also the form of non-linear least-squares (NLS) estimator for which steepest
descent, Gauss-Newton, and Taylor series based methods can be used to solve
the problem [30]. These kinds of methods are all complicated and require a
good initial value in calculation to avoid converging to the local minima of
(4.26).
With the TOA value from M anchor nodes to the reference point ob-
tained, we can perform trilateration to localize the position of the micro-
phone. Assume the real position of the microphone is p = (x, y); each anchor
node has its known position as pm = (xm, ym), and m ∈[1, . . . , M]. The
real distance from the microphone to the anchor node can be assumed as
rm =
p
(x −xm)2 + (y −ym)2. Assume the measured distance between the
anchor node to the smartphone is ˆrm, and can be shown as
ˆrm = cˆτ T OA
m
= rm + cδt, m = 1, . . . , M
(4.14)
where the c is the speed of the acoustic signal, δt is the unknown ﬁxed timing
delay for every anchor node. For simplicity, we set δ = cδt, and every measure-
ment from the anchor node has nearly the same δ. In real systems, δ may be a
very large number of value, and diﬀerent from beacon to beacon. To minimize
the eﬀect of δ, we can substrate the same distance from every measurement
to obtain a relative distance value. By selecting a reference point of m = f,
and setting δ = −rf, we have ˆrf = 0. Then the relative distance of other node
to this reference point can be written as
dm(f) = [ˆτ T OA
m
−ˆτ T OA
f
−(m −f)Tp]c
(4.15)
where m ̸= f, {m, f} ∈[1, . . . , M].
If the reference anchor is f, then the relative distance obtained in (4.15)
can be expressed in terms of ˆrm as dm(f) = ˆrm−ˆrf. Choose one anchor as the
reference node m = f, and other equations in (4.17) subsidize the reference
measurement.
Rather than solving (4.26) directly, we use the properties of (4.3) to cancel
out the nonlinear term. In (4.3), we only care about the relative distance to the
reference point, with the ﬁxed delay of δ = −rf. Such a process can avoid the
non-linear term in (4.26). To better illustrate this process, we can substitute
rm into (4.5), and squaring both sides of (4.5) yields
(x −xm)2 + (y −ym)2 = (ˆrm −δ −enm)2, m = 1, . . . , M
(4.16)

54
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
where enm = nm −nf. Simplifying both sides of (4.16) gives
2xmx + 2ymy −2δˆrm + δ2 −x2 −y2 −2(ˆrm −δ)enm
(4.17)
= x2
m + y2
m −ˆr2
m
where en2
m = 0 has been eliminated in (4.17) due to independent properties
of the noise. δ2 −x2 −y2 is the non-linear term for the unknown parameter
θ, and the same for m = 1, . . . , M. By utilizing the reference point (f), i.e.,
ˆrf = rf + δ = 0 + nf, the simpliﬁcation can be made as
δ2 −x2 −y2 = x2
f −2xxf + y2
f −2yfy + 2nfδ
(4.18)
The non-linear term in (4.17) can be canceled out by subsidizing (4.18) into
(4.17) as
[(x2
m + y2
m −ˆr2
m) −(x2
f + y2
f −ˆr2
f)] + 2ˆrmenm −2δnm
(4.19)
= 2(xm −xf)x + 2(ym −yf)y −2δ(ˆrm −ˆrf)
Equation (5.15) can be expressed in matrix form as
Aθ = ν + pn
(4.20)
where A =


xm −xf
ym −yf
ˆrf −ˆrm
· · ·
· · ·
· · ·

, θ =


x
y
δ

and ν = 1
2[(x2
m + y2
m −
ˆr2
m) −(x2
f + y2
f −ˆr2
f)](M−1)×3, m = 1, . . . , M when m ̸= f. ˆrm is the measured
distance obtained from (4.3) and ˆrf = 0. pn = 2ˆrmenm −2δnm is the noise
term with its ﬁrst moment as E(pn) = 0 and the covariance matrix of vector
pn as eσ = Cov(pn). The diagonal elements of the covariance matrix are
2ˆrm(σ2
m + σ2
f) + 2δσ2
m, with other elements in the matrix as 2ˆrmσ2
f. Note
that δ is not available in practice; it can be set to 0 at the ﬁrst snapshot of
localization to simplify the solution. For the following snapshots, δ can be
replaced by the calculated value to improve accuracy.
Then (4.26) can be written as a least-square (LS) problem [30], as
minθ ∥Aθ −ν∥2. It is equivalent to ﬁnd θ, which minimizes the sum squares
of M independent error vector with ∥e∥2 = (ν −Aθ)T eσ−1(ν −Aθ). By mini-
mizing this quadratic function, we can obtain the solution of
ˆθ = (AT eσ−1A)−1AT eσ−1ν
(4.21)
Assuming all the noise variances are identical and replacing σ2
m = 1, the
common part 2ˆrm can be ignored. In such a case, eσ is equivalent to σ. The
diagonal element of eσ−1 is (M −2)/(M −1) with other elements of 1/(M −1).
The estimated position of the target can be obtained by selecting the ﬁrst two
parameters (x, y) of ˆθ. The obtained δ in each result of ˆθ can be used as a
constraint such that δ ≈rf =
p
(x −xf)2 + (y −yf)2. By calculating rf and

Localization Algorithms
■
55
using the obtained (x, y), the diﬀerence between the estimated δ can be shown
as ˆe =
q
(ˆθ(1) −xf)2 + (ˆθ(2) −yf)2 −ˆθ(3). Small ˆe indicates good position
results. Such delay-constraint (DC) can be used as the self-evaluation of the
position results and can ﬁlter out some incorrect estimated positions.
4.2
Mobile Phone Localization via Semideﬁ-
nite Programming
4.2.1
Localization Measurement Model
Assume the real position of a mobile phone is y ∈Rd, i.e., the 2-D coordinate
(d = 2) of y is y = [x, y]T . Denote the known anchor position vector as
xm ∈Rd, where m is the anchor index with total M anchors. Using d = 2 as an
example, each element of xm is a 2-D coordinate as [xm, ym]T , m = 1, . . . , M.
The objective of localization is to estimate y from distance measurements of
ˆrm, where ˆrm denotes the measured distance from the target (y) to anchor
node m. The real distance rm from the mobile phone to the m-th anchor
node can be written as rm = ||y −xm||2, where || · ||2 calculates the 2-norm
and obtains the Euclidean distance. Then, the distance measurement from the
m-th anchor can be written as
ˆrm = ||y −xm||2 + δr + nm
(4.22)
where δr is the unknown ﬁxed bias for the whole anchor network due to the
unknown access time of the mobile phone. The random access time of the
mobile phone to the anchor network is unavoidable. Using the appropriate
algorithm to estimate δr during the localization process is necessary. In vector
notations, (4.22) can be expressed as
ˆr = f(θ) + n
(4.23)
where ˆr = [ˆr1, · · · , ˆrM]T , n = [n1, · · · , nm]T . We deﬁne the unknown pa-
rameter vector as θ = [y, δr]T , then f(θ) = [r1 + δr, · · · , rm + δr]T . The
localization process is to estimate θ by using approaches like Bayesian or
maximum-likelihood (ML) estimation techniques.
To estimate the unknown parameter θ, maximum a posteriori (MAP) es-
timator is optimal when the prior probability distribution g(θ) is known. For
most cases, the distribution g(θ) of the unknown parameter θ is unknown.
Using uniform distribution instead of the g(θ) is like achieving optimal per-
formance under the worst-case scenario. Such simpliﬁcation is practical and
reasonable, and can simplify the MAP estimator to the maximum likelihood
(ML) estimator as
ˆθML = arg max
θ
log P(ˆr|θ)
(4.24)

56
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
where P(ˆr|θ) is the pdf of the measurement vector ˆr conditioned on unknown
parameter θ. The conditional pdf of ˆr can be expressed as
P(ˆr|θ) =
1
p
2π det(σ)
exp

−QT σ−1Q
2

(4.25)
where Q = (ˆr −f(θ)). σ is the covariance matrix for ˆr as σ = {Cov(ˆri, ˆrj)},
i, j = 1, . . . , M. det(σ) calculates the determinant of σ. For the Gaussian noise
component in (4.23), it has n ∼N(0, σ).
The result of (4.24) can be achieved by searching over possible parameters
that maximize the log-likelihood. For noise distribution with zero mean and
a known covariance matrix, (4.24) can be simpliﬁed as
ˆθML = arg min
θ
(ˆr −f(θ))T σ−1(ˆr −f(θ))
(4.26)
where (ˆr −f(θ)) represents the estimation error, and σ−1 can be represented
as the weighting coeﬃcient for each independent measurement. (4.26) is also
the form of a non-linear least-squares (NLS) estimator. The steepest descent,
Gauss-Newton, and Taylor-series-based method can be used to solve the prob-
lem. These kinds of methods require a good initial value in calculation to avoid
converging to the local minima of (4.26), or need to calculate the computa-
tional complex of the matrix inverse operation [64].
4.2.2
Min-Max Criterion
To prevent the algorithm from converging to the local optimal values, the
concept of relaxation onto convex sets has been proposed and demonstrated as
tight bound to the initial non-convex problem [117]. Among existing relaxation
criteria, using minimax approximation and semideﬁnite relaxation can ﬁnd the
global minimum value without the “inside convex hull” requirement [68].
The solution of (4.26) by using the NLS estimator is a nonconvex opti-
mization problem, while a semideﬁnite programming (SDP) technique can be
used to relax the initial nonconvex problem into a convex one, and has been
proven to have a tight bound to the original problem. To utilize the SDP
relaxation, we can modify the problem formulation by rewriting (4.23) into
ˆr−δr = ||y−xm||2 +n. Performing square operation in both sides will lead to
(ˆr −δr)T σ−1(ˆr −δr) = (||y −xm||2 + n)2
(4.27)
where the right side of (4.27) will lead to ||y−xm||2
2+2nT ||y−xm||2+nT n. n is
the variance vector of the ranging error. Assuming every ranging measurement
is independent, we will have nT n = 0; 2n||y−xm||2 will be the new noise term
as n′. By adopting the min-max criterion [68, 98], (4.27) can be formulated as
y = arg min
y
max
m=1,...,M
||y −xm||2
2 −(ˆr −δr)T σ−1(ˆr −δr)

|
{z
}
ξ
(4.28)
where the term ξ can be viewed as the residual error. (4.28) calculates y by
minimizing the maximum residual error. Compared with (4.26), (4.28) remains
nonconvex, but it is comfortable for the following semideﬁnite relaxations.

Localization Algorithms
■
57
The ﬁrst term in (4.28) can be written into a matrix form of
||y −xm||2
2 =

yT
1
  Id
−xm
−xT
m
xT
mxm
  y
1

(4.29)
= trace
 y
1
 
yT
1
  Id
−xm
−xT
m
xT
mxm

= trace
 Y
y
yT
1
  Id
−xm
−xT
m
xT
mxm

where Y = yyT , trace{·} calculates the trace of the matrix, and Id is an
identity matrix of order d. Using the same process in (4.29), the second term
in (4.28) can be written into
(ˆr −δr)T σ−1(ˆr −δr)
(4.30)
= trace
 δ
δr
δT
r
1
  σ−1Id
−σ−1ˆr
−ˆrT σ−1
ˆrT σ−1ˆr

where δ = δrδT
r .
4.2.3
Semideﬁnite Programming
The objective function of ξ can be converted to minimize ϵ at the constraint
of an inequality expression −ϵ < ξ < ϵ, while ξ can be written as the form
of (4.29) and (4.30). The constraints form of (4.29) and (4.30) are convex,
but the equality constraints of Y = yyT and δ = δrδT
r are nonconvex. Using
semideﬁnite relaxation, these two equalities can be relaxed to inequality con-
straints of Y ⪰yyT and δ ⪰δrδT
r , respectively. The matrix form of these two
equalities is
 Y
y
yT
1

⪰0,
 δ
δr
δT
r
1

⪰0
(4.31)
where ⪰means a positive deﬁnite (semideﬁnite) matrix, which is diﬀerent
from ≥.
Accordingly, the initial problem of (4.26) can be relaxed to a semideﬁnite
programming form as
min{y,Y,δr,δ} ϵ
s.t.
−ϵ < trace
 Y
y
yT
1
  Id
−xm
−xT
m
xT
mxm

−trace
 δ
δr
δT
r
1
  σ−1Id
−σ−1ˆr
−ˆrT σ−1
ˆrT σ−1ˆr

< ϵ,
m = 1, . . . , M,
 Y
y
yT
1

⪰0,
 δ
δr
δT
r
1

⪰0

58
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
The mobile phone position y can be extracted from the optimal solution of
{y, Y, δr, δ}. The SDP problem can be solved by some standard convex opti-
mization packages, e.g., the SeDuMi and CVX package [28].
4.3
Performance Bound and Anchor Network
Coverage
4.3.1
Fisher Information Matrix
The measured distance in (4.23) is a set of stochastic variables ˆr = [ˆr1 · · · ˆrM]T .
The probability density function of ˆr can be expressed by using P(ˆr; θ) instead
of the conditional form of P(ˆr|θ). For simplicity, we use the joint log-probability
density function q(ˆr; θ) = log P(ˆr; θ) for the following analysis.
Fisher information is often used as a metric to compare the performance
of diﬀerent estimation schemes and investigate the theoretical upper bound
(extreme performance) for a particular algorithm. The Fisher score vector sθ
of the stochastic variable ˆr can be deﬁned as the partial derivatives of q(ˆr; θ),
with respect to the parameter θ, as
sθ = ∂q(ˆr; θ)
∂θ
= ∂f T (θ)
∂θ
σ−1(ˆr −f(θ))
(4.32)
where the expectation of sθ is E(sθ) = 0 under suitable regularity con-
ditions [109]. Then the covariance matrix of sθ
yields Cov(sθ, sθ)
=
E

(sθ −E(sθ))(sθ −E(sθ))T 
= E[sθsT
θ ]. The Fisher information matrix of
the observations ˆr is described by
Jθ = E[sθsT
θ ] = E
∂q(ˆr; θ)
∂θ
∂q(ˆr; θ)
∂θT

(4.33)
= E
∂f T (θ)
∂θ
σ−1(ˆr −f(θ))(ˆr −f(θ))T σ−1 ∂f(θ)
∂θ

= ∂f T (θ)
∂θ
σ−1 ∂f(θ)
∂θ
where Jθ is actually a covariance matrix and positive semideﬁnite. It is positive
deﬁnite if and only if the elements of sθ are linearly independent random
variables.
4.3.2
Cramer-Rao Low Bound
To evaluate the position accuracy, the Cram´er-Rao low bound (CRLB) is often
used as a theoretical optimal value from any unbiased estimator. The CRLB
can be written as the reciprocal of the Fisher information. For an estimate of
ˆθ obtained, we have the CRLB as
Er{(ˆθ −θ)(ˆθ −θ)T } ⪰J−1
θ
(4.34)

Localization Algorithms
■
59
where (4.34) is in the form of a covariance matrix, the right part of (4.34) is
CRLB = J−1
θ , and this means the variance of the estimated parameter could
not be lower than the CRLB under the given estimator. The term A ⪰B
expresses that the diﬀerence A −B of the real symmetric matrices A and B
is positive semideﬁnite. ⪰will be reduced to ≥if θ is a scalar [11].
In the unknown parameter θ, the position of the mobile phone is y ∈
Rd, d = 2 for the 2-D coordinate. Thus, θ = [y, δr]T ∈R(d+1) and Jθ is a
(d + 1) × (d + 1) matrix. To characterize the position estimation accuracy σp,
only the ﬁrst d × d terms in Jθ should be utilized as
CRLBy = σp =
q
trace(Er{(ˆy −y)(ˆy −y)T })
(4.35)
≥
q
trace(J−1
θ|(d×d))
The elements of Fisher information Jθ is deﬁned in (4.33), where ∂f(θ)/∂θ
can be obtained as a d × 1 vector. Using 2-D coordinate, i.e., d = 2. And
∂f(θ)/∂θ =
(x −xm)/||y −xm||
(y −ym)/||y −xm||
1
, if only the ac-
curacy of (x, y) is considered in unknown parameter θ. Assume the ranging
variance from all the anchor nodes are the same as σ2
r, thus σ = σ2
r.
For the 2-D coordinate, denote the unit vector from the m-th anchor node
to target as αm = (x −xm)/rm in x domain; βm = (y −ym)/rm in y domain,
where rm = ||y −xm||. Jθ|(2×2) can be shown as
Jθ|(2×2) =
"
PM
m=1 αm2/σ2
r
PM
m=1 αmβm/σ2
r
PM
m=1 αmβm/σ2
r
PM
m=1 βm
2/σ2
r
#
(4.36)
4.3.3
Anchor Network Coverage
Relying on the anchor network for mobile phone localization, the placement
of anchor nodes is very important in achieving high resolution results. To
evaluate the eﬀect caused by the geometric layout of anchor nodes, the term
of geometric dilution of precision (GDOP) is often used. GDOP can be deﬁned
as GDOP = σp/σr, where σp and σr indicates the variance of position and
ranging results, respectively. σp is the variance of localization results obtained
in (4.35). The GDOP quantiﬁes the ampliﬁcation of the ranging error in the
position result when passing through the position calculating unit.
For an unbiased estimator, GDOP can be written as
GDOP =
q
trace(J−1
θ|(2×2))/σr =
q
trace(˜J−1
θ|(2×2))
(4.37)
=
v
u
u
u
ttrace


"
PM
m=1 αm2
PM
m=1 αmβm
PM
m=1 αmβm
PM
m=1 βm
2
#−1

where αm and βm are the unit vector in the x and y directions.

60
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
(4.37) only depends on the positions of the anchor node xm and mobile
phone y; it is independent of the ranging noise variance. The diﬀerence be-
tween GDOP (4.37) and CRLB (4.35) lies in the ranging variance σr.
The GDOP calculated by (4.37) can be used as a metric for evaluating the
anchor network coverage. The value of GDOP is determined by the relation
between the position of mobile phone (y) and anchor network (xm). Smaller
value of GDOP means good coverage. If the location estimation result (ˆy) is
available, the corresponding GDOP value of (4.37) can be calculated. If the
GDOP value for ˆy is higher than a threshold, then the conﬁdence level of ˆy
should be lowered. Such a scheme could be used as a post-position constraint
to ﬁlter out the localization results. If the ranging variance is available or set
as a constant, using CRLB in (4.34) as the metric for evaluating the coverage
is equivalent to GDOP. The detailed process is elaborated in Subsection 4.4.3.
4.4
Position Reﬁnement
4.4.1
NLOS and Error Mitigation
Most of the existing literature on mobile phone localization focuses on the
case where the ranging measurements are known with some slight perturba-
tions, i.e., using zero-mean Gaussian noise to represent the ranging error. This
assumption is only eﬀective when all the ranging results are in line-of-sight
(LOS) condition with no bias or large error. However, in practice, a signiﬁcant
portion of the ranging results contain outliers.
If the large bias errors of ranging are not accounted for, the localization
results could result in signiﬁcant errors or even diverge. The challenge of the
problem arises from the unknown a priori information about the bias or NLOS
condition. There has been some work in the literature that addresses this case
and performs NLOS identiﬁcation and mitigation. However, these approaches
focus on mitigating the NLOS ranging measures by using the channel identi-
ﬁcation results. One drawback of these kinds of approaches lies their require-
ment on the additional channel measurement.
For NLOS ranging measurements, (4.22) could be written as a new form
of
ˆrm = rm + δr + δm + nm
(4.38)
where δm is the biased term for M anchors, m = 1, · · · , M. For NLOS condi-
tions, δm > 0.
The result of {y, Y, δr, δ} obtained from (4.32) contains the position (y)
of the mobile phone, and the system bias (δr). For most cases, the number of
NLOS ranging measurements in one location calculation should be less than
M/2; otherwise, the location calculation result is problematic. If we ignore
the value of δm in (4.32), the obtained relaxed result is still acceptable due
to the robustness of the SDP approach. However, the accuracy of the relaxed

Localization Algorithms
■
61
result could be further improved by using post-position processing. Using the
estimated result of ˆy, the distance between each pair of anchor nodes could
be calculated by ¯rm = ||ˆy−xm||2. The diﬀerence between ¯rm and the ranging
result ˆrm is the estimated value of δm as
ˆδm = ˆrm −||ˆy −xm||2
(4.39)
where ˆδm is the estimated NLOS bias value, which is a byproduct of the
SDP result of (4.32). If the value of (4.39) for the m-th anchor is larger
than a threshold ηnlos, the m-th ranging result should be mitigated in the
post-position process. Using the NLOS mitigated ranging results to perform
position reﬁnement will be illustrated in Subsection 4.4.2. Unlike the con-
ventional NLOS identiﬁcation approach that relies on channel measurement,
using (4.39) for NLOS identiﬁcation does not require additional information.
4.4.2
Steepest Descent Approach
The calculated mobile phone position y from Section 4.2 is a global optimal
solution ensured by the SDP approach. SDP relaxes the initial non-convex
problem to convex and achieves global optimal value. Although the SDP ap-
proach has been approved such that the relaxation has a tight bound to the
original problem, performing a local search near the global optimal value can
further improve the accuracy.
With the ﬁxed starting point δr available, additional gains in position
reﬁnement can be achieved by relying on the unchanged feature of δr. Using
the sliding-window approach, denote the iterative weighted value of δr as ¯δr,
as ¯δr := a¯δr + bδr, where a = 0.7, b = 0.3. According to (4.22), the position
reﬁnement can be achieved by minimizing the term of
y : = arg min
y (e(y))
(4.40)
= arg min
y
X
m∈ξM
 ||y −xm||2 −(ˆrm −¯δr)
2
where e(y) is the sum of distance errors between the mobile phone and all
the anchor nodes. ξM is the set of all the anchor nodes that are used in the
position reﬁnement. If all the ranging measurements are LOS, and ˆδm = 0,
then ξM = {1, · · · , M}. If there exist some NLOS measurements, then ξM is
the ranging set with NLOS measures mitigated by using (4.39).
Performing the gradient operation ∇to the error residues e(y) with respect
to the anchor node m, and we have
∇e(y) = 2
X
m∈ξM
 ||y −xm||2 −(ˆrm −¯δr)

y −xm
||y −xm||2
(4.41)
= 2
X
m∈ξM

1 −
ˆrm −¯δr
||y −xm||2

(y −xm)

62
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
where
∇
 ||y −xm||2 −(ˆrm −¯δr)

= ∇(||y −xm||2)
(4.42)
= (y −xm)/||y −xm||2
When the gradient function of (4.41) is available, the reﬁned position can be
updated by
y := y + α∇e(y)
(4.43)
where α ∈(0, 1] is the update step size.
By using the steepest descent approach in (4.43), the objective function of
(4.40) can be minimized by performing a local optimization above the global
optimized value obtained by SDP. The overall performance of (4.43) can be
guaranteed by providing an initial value y from SDP results.
4.4.3
Coverage Constraint
The obtained mobile phone position y of (4.43) could still be aﬀected by
interference or large bias error. Using some criterion to ﬁlter out the error
result is the last step before delivering the ﬁnal result to the user.
The GDOP value of (4.37) can be calculated by inserting y of (4.43).
If the GDOP value is higher than a threshold, then the result ˆy should be
mitigated. Speciﬁcally, if the calculated position result falls outside of the
anchor network coverage, the conﬁdence of the result is low (high GDOP
value). The threshold is determined by the minimum acceptable resolution
and calculated by experiment. Using the GDOP as the coverage constraint, the
problematic localization results could be ﬁltered out. If the ranging variance
is available, using CRLB of (4.34) instead of GDOP is equivalent. The ﬁltered
result of ˆy is the ﬁnal calculated position of the mobile phone, and deliver to
the user for other location-based-services (LBS).
4.5
Numerical Results
In Section 4.2, we derive the pseudorange (PR)-based SDP algorithm to obtain
the position with relaxed global optimal value. Due to the unknown system
parameter δr, the obtained ranging result is not the true distance between
an anchor and a phone but a pseudorange. To reﬁne the position results, the
steepest descent (SD) approach based on local search and mitigated NLOS
ranges is proposed in Section 4.4. For simplicity, we name the pseudorange-
based SDP algorithm “SDP-PR”; “SDP-PR-SD” is the SD reﬁned version in
additional to “SDP-PR.”
To illustrate the eﬀectiveness of the SDP algorithm, we compare our pro-
posed “SDP-PR” with other least-square (LS) approaches, e.g., classic TOA-

Localization Algorithms
■
63
based LS (“LS-Classic”) [16], and revised LS approach for pseudorange mea-
surements (“LS-PR”) [95]. Regarding the position reﬁnement, classic LS can
also be applied after the semideﬁnite relaxation instead of our SD approach,
denoted as “SDP-PR-LS.” Using LS along with SPD has higher computa-
tional complexity than the steepest descent (SD) due to the inverse matrix
calculation requirement in LS. To compare the performance of the low com-
plexity reﬁnement approach “SDP-PR-SD,” we compare it with more complex
“SDP-PR-LS” in terms of achievable performance.
We use root mean squared error (RMSE) of the position result as the
performance metric, and conduct 1000 Monte Carlo simulations with 1/σ2 =
−30 ∼30dB, where σ is the ranging noise variance. Eight anchor nodes are
simulated, and the position matrix in the 2D plane is
xm =
0
0
80
80
0
40
80
40
0
80
0
80
40
0
40
80
T
(4.44)
where m = 1, . . . , 8.
−30
−20
−10
0
10
20
30
0
5
10
15
20
25
30
1/σ2 (dB)
RMSE (m)
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
(a) Fixed Position
−30
−20
−10
0
10
20
30
0
5
10
15
20
25
30
35
1/σ2 (dB)
RMSE (m)
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
(b) Random Position
Figure 4.1: Comparison of LS approaches to SDP and revised SDP al-
gorithms when the mobile phone is in ﬁxed position of [30, 20] (a) and
random position with x and y distributed between (20, 80) (b).
When the mobile phone is placed at y = [30, 20]T , the RMSE performance
comparisons of these ﬁve approaches are shown in Fig. 4.1(a). The RMSE
results when the mobile phone is randomly placed in a region are shown in
Fig. 4.1(b). From Fig. 4.1(a) and Fig. 4.1(b), we observe that SDP-based ap-
proaches outperform LS-based approaches in almost all the 1/σ2 regions. In
terms of the postprocessing reﬁnement, using LS and steepest descent after
SDP processing can all improve the localization performance. From the re-
sults of “SDP-PR-LS” and “SDP-PR-SD,” we observe that “SDP-PR-SD”

64
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
outperforms more complex “SDP-PR-LS,” especially when the ranging noise
variance is high. These results demonstrate the eﬀectiveness of the proposed
SDP approach along with the steepest descent post-processing.
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
RMSE (m)
CDF
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
(a) 1/σ2 = −10dB
0
1
2
3
4
5
6
0
0.2
0.4
0.6
0.8
1
RMSE (m)
CDF
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
SDP−PR
SDP−PR−LS
SDP−PR−SD
LS−Classic
LS−PR
(b) 1/σ2 = 10dB
Figure 4.2: Cumulative distribution of LS approaches to SDP and revised
SDP algorithms when the mobile phone is in [30, 20], 1/σ2 = −10dB (a)
and 1/σ2 = 10dB (b).
Fig. 4.2(a) and Fig. 4.2(b) show the cumulative distribution function
(CDF) of the calculated position RMSE when 1/σ2 = −10dB and 1/σ2 =
10dB, respectively. The CDF results show the similar relative performance
as in Fig. 4.1(a) and Fig. 4.1(b). SDP approaches outperform LS with larger
relative gains when the ranging error decreases. “SDP-PR-SD” performs best
among these ﬁve approaches. Although the performance gains of “SDP-PR-
SD” over “SDP-PR-LS” is relatively small in Fig. 4.2(b), the low complexity
property of “SDP-PR-SD” makes it more applicable for real systems.
The CRLB of the position estimation with 8 anchor nodes and 1/σ2 =
10dB is shown in Fig. 4.3 when the mobile phone is placed at diﬀerent posi-
tions. This ﬁgure can be used to illustrate the theoretical performance bound
with respect to the ranging variance and the geometric placement of the an-
chor nodes. If not using the assumed ranging variance, CRLB is equivalent
to the metric of GDOP in (4.37). Moreover, if the estimated mobile phone
position is substituted into the CRLB, the obtained value of CRLB or GDOP
can be used as the metric to evaluate the coverage. If the position result lies
outside of the coverage, then this position result should be mitigated. Using
this post-position ﬁlter in position reﬁnement of “SDP-PR-SD,” the obtained
localization accuracy can be further improved.

Localization Algorithms
■
65
0
20
40
60
80
0
20
40
60
80
0.22
0.24
0.26
0.28
0.3
X (m)
Y (m)
CRLBy (m)
Figure 4.3: The CRLB of the position estimation with 8 anchor nodes
and 1/σ2 = 10dB when the mobile phone is placed at diﬀerent positions.
4.6
Experimental Evaluation
To make the real system work eﬃciently, a lot of interferences and abnormal
conditions should be handled. A good algorithm should be superior in theory
and simulation and also superior with robustness in real-world experiments.
4.6.1
Experiment Setup for Localization
To evaluate and compare the performance of diﬀerent localization algorithms,
we deployed the anchor network in a typical oﬃce environment as shown in
Fig. 4.4. The mobile phone performs ranging and calculates its own posi-
tion by demodulating the beacon information transmitted from anchor nodes.
This environment is polluted with normal voice sound and other acoustic in-
terference, e.g., the sound noise from the fan in a computer. To evaluate the
various localization algorithms, we conducted the measurements and drove
these localization algorithms with experimental data. The CRLB of the posi-
tion estimation for the experiment environment is shown in Fig. 4.5 when the
ranging accuracy is assumed as 2cm. Fig. 4.5 can be used to illustrate the the-
oretical performance lower bound with diﬀerent ranging accuracies. Without
the assumed ranging variance, CRLB is equivalent to the metric of GDOP in
(4.37). Moreover, the obtained value of CRLB or GDOP can be used as the
metric to evaluate the coverage and perform post-position ﬁltering.

66
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 4.4: The experiment environment.
0
2
4
6
8
10
0
0.5
1
1.5
2
2.5
0.01
0.02
0.03
X (m)
Y (m)
CRLBy
Figure 4.5: The CRLB of the position estimation for the experiment
environment when the ranging accuracy is assumed as 2cm.
4.6.2
Localization Results
Performance Comparison. Similar to Section 4.5, we use the CDF results
to compare the performance of diﬀerent algorithms. The algorithms compared
are still the same as in Section 4.5, i.e., “LS-Classic,” “LS-PR,” “SDP-PR,”
“SDP-PR-LS,” and “SDP-PR-SD.” Unlike Section 4.5, the RMSE results with
a variable of 1/σ2 are not available in experiments, due to the uncontrollability
of the ranging variance.

Localization Algorithms
■
67
0.1
0.2
0.3
0.4
0.5
0.6
0
0.2
0.4
0.6
0.8
RMSE (m)
CDF
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
LS−Classic
LS−PR
SDP−PR
SDP−PR−SD
SDP−PR−LS
(a) 5.13, 1.08
0
0.2
0.4
0.6
0.8
0.2
0.4
0.6
0.8
1
RMSE (m)
CDF
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
(b) 5.5, 1.4
Figure 4.6: Cumulative distribution of LS approaches to SDP and revised
SDP algorithms when the mobile phone is in [5.13, 1.08] (a) and [5.5, 1.4]
(b) by using experimental data.
Table 4.1: The localization accuracy of diﬀerent algorithms with 80%
probability when the mobile phone is placed near Pos1 [5.13, 1.08]m and
Pos2 [5.5, 1.4]m
LS-Classic
LS-PR
SDP-PR
SDP-PR-LS
SDP-PR-SD
Pos1
0.083
0.097
0.09
0.105
0.06
Pos2
0.32
0.30
0.082
0.069
0.065
Fig. 4.6(a) and Fig. 4.6(b) show the CDF of the position error when the
mobile phone is placed near [5.13, 1.08]m and [5.5, 1.4]m, respectively. The
SDP-based approaches perform better than the LS-based approaches in these
two cases. By performing position reﬁnement after the SDP results, “SDP-
PR-LS” and “SDP-PR-SD” are superior than other approaches. Using the
steepest descent (SD) as post-processing is less complex than the LS approach,
and “SDP-PR-SD” even outperforms “SDP-PR-LS” in most situations with
diﬀerent performance gains, e.g., the available gain in Fig. 4.6(a) is larger than
in Fig. 4.6(b).
For more detailed comparison, we created Fig. 4.7 by listing the localization
accuracy that is achieved by 80% measurements. From Fig. 4.7, we know that
the localization accuracy of “SDP-PR-SD” is near 6cm, i.e., 80% of position
results within 6cm of error. Achieving such a high-accuracy position is low-
cost and only relies on the normal mobile phone at the user’s side. With such
high precision at low cost, we expect our localization algorithm will enable a
large spectrum of indoor location-based services in museums, stores, libraries,
and hospitals, just to name a few.

68
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
LS−Classic
LS−PR
SDP−PR
SDP−PR−LSSDP−PR−SD
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Different Approaches
Location Accuracy
 
 
Pos1
Pos2
Figure 4.7: The localization accuracy of diﬀerent algorithms with 80%
probability when the mobile phone is placed near Pos1 [5.13, 1.08]m and
Pos2 [5.5, 1.4]m.
0
10
20
30
40
50
60
0
0.1
0.2
0.3
0.4
Elapsed Time
Error (m)
 
 
Env1
Env2
Env3
Env4
Env5
Env6
(a) Time Series
0
0.1
0.2
0.3
0.4
0
0.2
0.4
0.6
0.8
1
RMSE (m)
CDF
 
 
Env1
Env2
Env3
Env4
Env5
Env6
(b) CDF
Figure 4.8: The time series (a) and CDF (b) of localization error at dif-
ferent spots.
Performance Comparison at Diﬀerent Spots. To demonstrate the
overall localization performance at diﬀerent spots, we calculated the localiza-
tion accuracy of “SDP-PR-SD” when its user stands still at diﬀerent spots.
In this case study, to support quantitative analysis, we used the time series
(Fig. 4.8(a)) and CDF (Fig. 4.8(b)) of the localization error to illustrate the

Localization Algorithms
■
69
performance. If using 80% probability, the localization error for all the spots is
in the range between 4cm and 10cm. These results are very accurate for indoor
mobile phone-based localization. Localization traces of three moving subjects
are illustrated in Fig. 4.9. The moving traces demonstrate the localization
accuracy and real-time feature of our system.
0
1
2
3
4
5
6
7
8
9
−0.5
0
0.5
1
1.5
2
2.5
X (m)
Y(m)
 
 
Anchor Node
Trace1
Trace2
Trace3
Figure 4.9: Three diﬀerent moving traces.
4.7
Conclusion
To address the challenges of utilizing the audible-band acoustic signal, i.e.,
small coverage and NLOS sensitivity, we propose semideﬁnite programming to
ensure global optimal position values, along with steepest descent reﬁnement
and NLOS mitigation. The metric of GDOP is introduced to quantify the cov-
erage and evaluate the quality of estimated position value of a mobile phone.
By comparing it with other classic localization algorithms and post-processing
techniques, our proposed “SDP-PR-SD” method achieves best performance in
diﬀerent simulation and experiment scenarios.


Chapter 5
Guoguo: Enabling
Fine-Grained Smartphone
Localization
Kaikai Liu
Assistant Professor, San Jose State University
Xinxin Liu
Privacy Engineer, Google Inc
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
5.1
Introduction ......................................................
72
5.2
System Design ....................................................
74
5.2.1
Motivation ...............................................
74
5.2.2
Design Challenges and Considerations ..................
74
5.2.3
System Architecture .....................................
76
5.3
Anchor Network Design ..........................................
76
5.3.1
Design Criterion .........................................
77
5.3.2
Anchor Node Hardware Design ..........................
77
5.3.3
Transmitter Waveform Design and Modulation .........
78
5.3.4
High Density Pseudocode Sequence .....................
79
5.3.5
Anchor Network Synchronization .......................
80
71

72
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
5.3.6
Symbol-Interleaved Beacon Structure ...................
81
5.4
Smartphone Localization .........................................
82
5.4.1
Design Workﬂow .........................................
82
5.4.2
Symbol Detection and Demodulation ...................
82
5.4.3
TOA Estimation .........................................
83
5.4.4
Acoustic Beacon Synchronization and Code Matching .
84
5.4.5
Distance Update .........................................
85
5.4.6
Location Estimation .....................................
86
5.5
Error Pruning Techniques ........................................
87
5.5.1
Signal Level Resistance ..................................
87
5.5.2
Track before Localization ................................
87
5.5.3
Location Tracking .......................................
89
5.6
Performance Evaluation ..........................................
89
5.6.1
Sound Pressure Level Measurement .....................
90
5.6.2
Maximum Operation Distance ..........................
90
5.6.3
Localization in Oﬃce Environments ....................
91
5.6.4
Localization in Classroom Environments ...............
95
5.6.5
Impact of Anchor Numbers and Locations ..............
97
5.6.6
Moving Traces ...........................................
99
5.6.7
System Evaluation .......................................
100
5.7
Conclusion ........................................................
101
5.1
Introduction
As one of the two key components of a mobile context (time and location),
localization has been the subject of extensive works ranging from algorithms,
models, and supporting technologies, to systems and applications. Current
coarse-grained (room-level or meter-level) localization on a smartphone has
enabled a lot of mobile services, such as location-based services, maps, and
navigation systems. However, these services are severely limited when applied
in more pervasive indoor environments due to low resolution. Indoor users can
hardly navigate like those using outdoor GPS services. The major diﬀerence
is as follows: meter-level (e.g. GPS with ﬁve-meter accuracy) localization is
suﬃcient to navigate a car (meter-level footprint) on a street (several-meter
footprint); but it is far from suﬃcient to navigate a user (foot-level footprint)
in a library (with half-meter-wide isles and inch-level books) or a shopping
mall (with inch-level items). Smartphone-based accurate “indoor GPS” or
IPS (indoor positioning system) have been long awaited to improve indoor
mobile services and enable new services. Despite signiﬁcant eﬀorts on indoor
localization in both academia and industry in the past two decades [6, 8, 10, 15,
85, 113], highly accurate and practical smartphone-based indoor localization
remains an open problem. Some accurate localization solutions cannot be
readily converted to smartphone-based ones due to various constraints.
The technology that enables centimeter- or decimeter-level location accu-

Guoguo: Enabling Fine-Grained Smartphone Localization
■
73
racy and integrates with context-aware mobile services has the potential to
revolutionize users’ mobile experiences. Using ranging, angle, displacement, or
ﬁngerprinting-based sensing is required for accurate indoor localization. How-
ever, none of the existing solutions could achieve the desired performance
at low cost and low complexity. Time-of-arrival (TOA)-based ranging ap-
proaches, e.g., special devices using ultra-wideband or ultrasound signals, are
more reliable and accurate. However, the increased complexity and additional
devices make them not practically useful for conventional users. Other low-
complexity approaches rely on existing sensors in smartphones to infer current
location, e.g., WiFi, ﬁngerprinting, compasses, and accelerometers. However,
their low accuracy and prerequisites like site survey or pairing limit their
applications.
Recent research on leveraging ubiquitous microphone sensors in a smart-
phone introduces a convenient approach to ranging by using the audible band
acoustic signal (less than 20kHz). A microphone sensor is inexpensive and
has potential for highly accurate ranging due to the low transmission speed
of acoustic signals. However, the limited bandwidth of a microphone, strong
attenuation of aerial acoustic signals, as well as various interferences in the
audible band, pose signiﬁcant challenges in using acoustic signals for indoor
localization. Although using acoustic signal to perform ranging-based localiza-
tion suﬀers from various issues, such as short operation distance, low update
rate, and sound pollution, the potential of centimeter-level localization accu-
racy motivates us to design better solutions to overcome its drawbacks.
In
this
chapter,
we
propose
an
indoor
localization
system
called
“Guoguo,”1 and further improve its performance in terms of coverage, ac-
curacy, update rate, and sound pollution [57]. We make its acoustic beacons
imperceptible to humans and improve detection sensitivity for better location
coverage. Rather than simply using “Beep” signals to enable passive sensing
for multiple smartphone users, we designed transmission waveform, wide-band
modulation, and one-way synchronization and ranging schemes. We designed
a transmission scheme of the acoustic beacon that follows the high-density
pseudo-codes to enable anchor node identiﬁcation without radio assistance on
a smartphone. We propose a symbol-interleaved beacon structure to overcome
the drawback of the low transmission speed of acoustic signal and improve the
location update rate. To improve the accuracy of ranging, we propose a ﬁne-
grained adaptive time-of-arrival (TOA) estimation approach that exploits the
details of the beacon signal and perform non-line-of-sight (NLOS) identiﬁca-
tion and mitigation. By combining all these techniques together, we implement
the prototype system with anchor nodes and a localization processing app in
a smartphone, and make it work in a realistic environment.
The rest of the chapter is organized as follows. Section 10.8 summarizes
the related work. Section 5.2 introduces the design consideration and system
1“Guoguo” means katydid/bush-cricket in Mandarin Chinese. Guoguo, famous for its
beautiful sound, has represented a pet culture in ancient China for thousands of years

74
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
architecture. Section 5.3 presents the acoustic beacon and anchor network
design. Section 5.4 presents the ranging and localization approaches by using
smartphone. Section 5.6 presents the experimental evaluation of our proposed
approach. Section 5.7 concludes this chapter.
5.2
System Design
5.2.1
Motivation
Various existing localization solutions rely on diﬀerent assumptions and are
dedicated to speciﬁc applications. For most existing solutions using only built-
in sensors in a smartphone, rough position information can be obtained for
building- or room-level navigation. For indoor mobile services like shelf-to-shelf
navigation, location-aware and context-aware information recommendation,
and virtual-reality interaction, ﬁned-grained indoor localization with foot-level
accuracy is critical.
In terms of system complexity, the users’ side is more stringent, especially
in hardware requirements. It is very hard to persuade consumers to purchase
special devices for indoor localization. Even with special devices, the inte-
gration with the mobile services provided by smartphones is also a diﬃcult
problem. To enable centimeter- or decimeter-level localization accuracy, and
only require a smartphone on the user side, the investment in indoor infras-
tructure is necessary and has potential for other interesting applications, e.g.,
surveillance and monitoring. For normal retail stores, several hundred dollars’
investment in indoor infrastructure to enable indoor “smart” shopping could
attract more consumers to enjoy mobile services, and in turn boost business.
With these two points in mind, we focus on developing a ﬁne-grained
smartphone-based indoor localization system leveraging an indoor low-
complexity anchor network.
5.2.2
Design Challenges and Considerations
To meet the localization accuracy, TOA-based ranging is more appropriate
[80]. Limited by the smartphone, using acoustic signal for TOA-based ranging
is an appropriate solution. However, making the acoustic signal for ranging
and localization in real situations has a lot of challenges.
First, the coverage of the anchor network should be suﬃcient for a room
or a retail store with less than 10 anchor nodes placed to minimize the in-
frastructure cost. The possible solution is to increasing the transmit power or
detection sensitivity. However, increase the transmit power could cause sound
pollution and high energy cost. [62, 81] all suﬀer from sound pollution caused
by the audible signal. H. Liu et al. [52] achieves less pollution, but only works
within 3 meters. Maintaining a low transmit power and keeping the acoustic
beacon unnoticeable are the two prerequisites in the anchor network design.

Guoguo: Enabling Fine-Grained Smartphone Localization
■
75
Thus, improving the detection sensitivity in the smartphone by using an ad-
vanced signal processing technique is the feasible solution to ensure suﬃcient
coverage.
Second, suﬃcient update rate is required to track users’ movement. If
the localization update rate is too sluggish, no user could be patient enough
to await their location results. There are also not enough time margins for
mobile services. The existing acoustic ranging solution proposed in [52] shows
7.8s delay in one location calculation; authors in [74] perform localization for
desktop and calculate the running time for 5 nodes in the range of 3.7s to 285s.
Possible solutions for improving the location update rate include better design
of the anchor network protocol, real time implementation of the algorithm,
and eliminating the use of WiFi assistance (it takes about 2s for one scan).
Figure 5.1: Conceptual architecture of the Guoguo System.
Third, the system should support multiusers simultaneously. However, so-
lutions used in [81, 52, 74] utilize the two-way approach for ranging. Two-way
ranging eliminates the synchronization requirement, but suﬀers from the lim-
itation of only allowing one user to access it at one time. Sound source local-
ization [108] is another way to eliminate the synchronization by using active
transmit mode for users; however, the random access time of the user making
the sensor network could only handle limited users at the same time. One-way
passive ranging should be utilized to maximize the multiuser capacity, which
could support unlimited number of users in theory.

76
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
5.2.3
System Architecture
In order to meet the requirements mentioned in Section 5.2.1 and 5.2.2, we
propose to the develop an anchor network with better coverage and make
the beacon unnoticeable. With several low-complexity anchor nodes mounted
on indoor places, the smartphone can localize itself by receiving more than
three beacon signals from the anchor nodes. The simpliﬁed architecture of our
proposed localization system is shown in Fig. 5.1. On the receiver side, we im-
plement advanced signal processing and a ranging algorithm in a smartphone
to achieve accurate localization in passive mode. The cloud server provides
mobile services for potentially massive users in real-time response mode, e.g.,
localization, navigation, and location-based services, minimizing computation
and storage cost in a smartphone. We adopt the NoSQL database to han-
dle massive user concurrent access and big data services in the future, e.g.,
business analytics and intelligence, mobile social network dynamics and evo-
lutions.
Speciﬁcally, the anchor network periodically transmits modulated acoustic
beacon signals based on the token of the controller. By detecting and extract-
ing the desired information bits embedded in beacon signals, the smartphone
demodulates the symbols and calculates the relative TOA. The algorithm in
the smartphone eliminates erroneous measurements using statistical pruning
methods, and accesses the anchor position by matching the pseudocodes. Fi-
nally, the smartphone can be aware of its ﬁne-grained position by accessing
the localization results.
5.3
Anchor Network Design
The key notations are listed in Table 5.1.
Table 5.1: Notation
M
Number of anchor nodes (m = 1, . . . , M)
L
Pseudocode length
pm
Pseudocode sequence for m-th anchor node
Fs
Sampling rate of smartphone
Ts
Symbol duration of acoustic beacon
vs
Speed of the acoustic signal

Guoguo: Enabling Fine-Grained Smartphone Localization
■
77
5.3.1
Design Criterion
The timing accuracy of existing radios, e.g., Bluetooth or Wi-Fi, on a smart-
phone, is not accurate enough for TOA-based localization. The mobile OS
(Android/iOS) introduces additional random delay in radio processing. More-
over, using Wi-Fi for localization would impact the Internet connection and
battery life. We eliminate the use of radio signal in a smartphone, and only
require a microphone to participate in the passive acoustic beacon sensing.
Such a low hardware requirement on the user’s side can help us simply extend
our system to other devices that contain a microphone and computation re-
sources rather than limiting ourselves to the smartphone platform. All anchor
nodes are synchronized by Zigbee radio and transmit the acoustic beacon sig-
nal to broadcast its unique location. We propose approaches to jointly solve
the one-way anchor–smartphone synchronization during the location estima-
tion process. Compared with systems using active ranging or radio-assisted
ranging, e.g., Cricket [85] and Beep [62], our solution features the following
salient advantages: no need for a special radio signal (e.g., ZigBee) that is not
available on a smartphone; no need of special devices for ranging assistance;
one-way passive ranging to support massive numbers of users.
5.3.2
Anchor Node Hardware Design
Targeting ﬁne-grained indoor location-based services, e.g., retail store, mu-
seum, oﬃce, and classroom, several hundred dollars investment in the an-
chor infrastructure to enable centimeter-level location-related services could
be proﬁtable. To minimize the infrastructure cost and promote the real sys-
tem deployment, we designed our own hardware for the anchor node with low-
complexity and additional features, e.g., solar powered, battery charging, plug-
gable sensor board, remote program upload, wireless speaker/microphone. The
comparison of our “Guoguo” hardware vs. two quarters is shown in Fig. 5.2.
The total BOM price for the anchor node is less than $10. With one anchor
Figure 5.2: Guoguo anchor node vs. quarter.
covering every 10–20 meters in an indoor space (e.g. museum, shopping cen-
ter), it is feasible and cost eﬀective to deploy such systems in many indoor

78
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
environments. For example, with marginal investment in the indoor infrastruc-
ture, a retail store can enable “smart” shopping experiences for smartphone
users with ﬁne-grained shelf-to-shelf navigation, location-aware recommenda-
tion and advising, and physical item-searching and navigation.
5.3.3
Transmitter Waveform Design and Modulation
Using audible-band acoustic signal as a beacon for ranging and communica-
tion, we must contend with a variety of noises to ensure its accurate ranging
due to the highly populated frequency band below 20kHz. The ranging accu-
racy directly depends on the signal-to-noise ratio (SNR) and eﬀective band-
width. However, higher transmitter signal bandwidth and power will generate
noise that disturbs users. The standard microphone in a mobile phone can
only support bandwidth of 200Hz ∼20kHz. To minimize the sound while per-
form ranging, we choose 15kHz ∼20kHz as the operating band. The reason
is that our ear is less sensitive to the high frequency signal, while the mi-
crophone in a smartphone could still receive signal in this boundary band.
With well-controlled transmitter signal power, the acoustic beacon could be
unnoticeable to humans while still detectable for smartphones. We use spread-
spectrum and ultra low-duty-cycle pulse sharpening techniques to ensure the
proper operation of the acoustic beacon under realistic environments, as well
as improving the ranging accuracy. Unlike the less-sophisticated acoustic sig-
nal used in Cricket and Beep, the beacon signal used in Guoguo is wide-band
modulated with short duration in the time-domain and unnoticeable to hu-
mans.
The task of the anchor nodes that transmit modulated acoustic sharp
pulse to the mobile receiver is to realize synchronization and ranging, as well
as to inform its unique pseudocode p = [pm,i], m = 1, . . . , M, i = 1, . . . , L,
where M is the number of the anchor nodes; L is the pseudocode length. The
pseudocode pm,i = 0, 1 is also the information bits carried by the beacon
signal. For the symbol waveform, we chose to use the second derivative of
the Gaussian (Doublet) Pulse [104] and multiply it to the carrier wave. The
waveform could be written as
g(t) = A
τ
"
1 −4π
 t
τ
2#
exp
"
−2π
 t
τ
2#
cos(2πfct)
(5.1)
where τ is the pulse width parameter, fc is the carrier wave frequency. We
truncate the Doublet pulse by their 3τ to approach the real-time condition.
The short duration of the Doublet pulse in the time-domain could contribute
to smaller symbol duration, higher ranging rate, and better location update
rate.
The center frequency fc of the modulated pulse is controlled by the on-chip
timer and working at 18kHz. In addition to fc, τ is tuned to ensure the eﬀective
bandwidth of (5.1) lies in between 15kHz ∼20kHz. The multiplication with

Guoguo: Enabling Fine-Grained Smartphone Localization
■
79
the carrier wave in (5.1) is also a spread spectrum process that extends the
initial narrow band fc to wide band signal g(t) by using the Gaussian Doublet
Pulse sharping. The use of ultra low-duty cycle pulse (5.1) has the feature of
higher data rate, higher location refresh rate, better multipath resolution,
lower energy consumption, and smaller sound pollution. To balance between
the system complexity and the sophisticated modulation scheme, we chose to
perform 2-PAM modulation with symbol duration as Ts; i.e., transmit sharp
pulse g(t) represents symbol “1,” no pulse for symbol “0.”
5.3.4
High Density Pseudocode Sequence
One design challenge faced in selecting the pseudocode is to utilize the proper
pseudo-codes with enough code distance redundancy to separate diﬀerent an-
chor nodes, e.g., utilize orthogonal codes. In addition to communication, every
symbol “1” in p will contribute to one ranging measurement, thus the high
density bit “1” could improve the location update rate.
The conventional communication process relies on the preamble part of a
frame to perform synchronization, then follows the data bits. For our designed
anchor network, the beacon signal should only contain the pseudocodes, and
transmits cyclically to save round time for higher location update rate. The
stringent requirement on eﬃciency making the removal of unnecessary parts
of bits is especially important for Guoguo due to the low transmission speed
of acoustic signal. However, most orthogonal pseudo-codes are not cyclic or-
thogonal; it will lose orthogonality due to the cyclical transmission. Using
Walsh-Hadamard codes, for example, only L + 1 codes with length L are
orthogonal to each other in all phases among Hadamard Matrix H(2L, L).
Moreover, the balanced “1” and “0” in these pseudo-codes does not comply
with our requirement on high “1” density sequence.
In order to meet the special requirement of pseudocode for our anchor
network, we select three distinct maximum sequences as [ms1, ms2, ms3] with
length of 2L, while L is the pseudocode length. To increase the “1” density,
we perform the plus and decision process to combine these three m-sequences
as a new sequence ms′, as
ms′ = [ms1 + ms2 + ms3] ≷1
0 0.5
(5.2)
where the length of ms′ is 2L. The reason that we choose three maximum
sequence is to balance the “1” density and the number of available new se-
quences. Reshape ms′ into a (L′, L) matrix as m = [ma,b], with L′ = 2(L−1)/L,
a = {1, . . . , L′}, b = [1, . . . , L]. L is the code length, and total L′ sequences
in ma,b. To maintain the minimum code distance dtol between each sequence,
we only select sequences in m that satisfy the conditions in any phases such

80
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
that
pm,i = argˆa{pˆa,i| min ||ma,i −pk,i+△i||1 ≥dtol},
(5.3)
∀k = {1, . . . , m −1}, ∀△i = {1, . . . , L}
ˆa ∈{1, . . . , 2(L−1)/L}, m = m + 1
where || · ||1 calculates the code distance between ma,i and the selected se-
quences pk,i+△i, while i + △i performs cyclic phase change for the sequence.
(5.3) ﬁlters sequences in m that meet minimum distance dtol among se-
lected sequence sets and adds into pm,i. When L = 16, among a total of
2(L−1)/L = 2048 sequences, only 12 sequences satisfy (5.3). These sequences
can be assigned to M anchors, where M = 9 for a micro-cell in our system.
5.3.5
Anchor Network Synchronization
There are two kind of beacons transmitted by the anchor nodes in Guoguo.
The ﬁrst kind of beacon is a radio beacon, which synchronizes all the anchor
nodes to the controller’s clock based on message passing; the second kind of
beacon is transmitted by the anchor nodes from the acoustic speaker, which
provide ranging and synchronization information to the smartphone. In this
sub-section, we mainly focus on the radio beacon, which synchronizes the
whole anchor network.
Anchor Network Synchronization. To enable the trilateration in a
smartphone based on the TOA acoustic ranging results, all these TOA results
should be based on the same timing-pace, i.e., synchronized. The accuracy
of the synchronization between anchors directly aﬀects the overall ranging
accuracy. For example, the transmission speed of the acoustic signal is near
340m/s; if the synchronization error is around 10 micro seconds, the resulting
ranging error is at least 3.4 meters. Thus, sub-micro-second-level synchroniza-
tion accuracy is the prerequisite of the Guoguo system.
The anchor network structure features several anchor nodes and one con-
troller (which could also be one of the anchor nodes). The controller provides
basic timing via radio beacon passing for the whole network, and all the an-
chor nodes are synchronized to the controller by receiving the radio beacon
passively and periodically. Such a scheme can guarantee that the transmitted
signals from anchor nodes are synchronized to a common timing source. The
controller beacon is realized by using the existing radio chips, e.g., Zigbee
radio. The data domain of the radio beacon contains the anchor token, and
current beacon index. The anchor node performs its own processing when the
anchor token is received, i.e., estimate the received beacon period, transmit
its own acoustic beacon according to the estimated timing pace. Denote the
controller beacon interval is Tp, every anchor node executes the similar pro-
cessing, the delay can be viewed as ﬁxed and making the acoustic beacon
timing equals to Tp.

Guoguo: Enabling Fine-Grained Smartphone Localization
■
81
Acoustic Beacon and Multiplexing. Due to the reason that there is
no commercial acoustic communication physical layer in mobile devices, we
need to design our own processing to realize the communication capability.
The ranging and synchronization capabilities of the anchor–smartphone pair
are all based on the acoustic communication channel, while a good beacon
structure can enable multiplex of anchors and improve the overall throughput
and data rate.
To enable suﬃcient signal-to-noise ratio when detecting the acoustic bea-
con signal, we designed such that the smartphone only detects one acoustic
beacon at one frame duration. The guard time between each beacon is Tg;
the frame duration is Tf = LTs + Tg. One beacon period of anchor can be
written as Tp := Tf = LTs +Tg. Multiple anchors should be synchronized and
transmit their own acoustic beacon sequence (length L) using the time divi-
sion multiple access (TDMA) approach to avoid the collision between each
beacon. The total round period Tr equals to Tr = MTp = M(LTs + Tg).
The mobile phone can diﬀerentiate all the anchor nodes after Tr, thus
the synchronization time between the anchor network and smartphone is
Tsyn = M(LTs+Tg). The localization process after synchronization also needs
M beacons to obtain ranging information from all the anchors, i.e., update
rate is Tup = Tsyn = M(LTs + Tg). When M = 9, L = 16, Ts = 0.0781s,
assume Tg = Ts, then Tup = Tsyn = 11.9493s. Such a long time of syn-
chronization and position update is caused by the low transmission speed of
acoustic signal, and it is not fast enough for tracking the movement of hu-
mans. One possible way to increase the update rate is to lower the symbol
duration Ts, with faster symbol transmission rate. However, symbol duration
is restricted by the delay spread or coherence bandwidth of the channel, and
could not be further reduced without sacriﬁcing the multipath resistance. To
improve the speed of localization without relying on the compression of the
symbol interval, a new beacon structure should be developed.
5.3.6
Symbol-Interleaved Beacon Structure
One possible solution is interleaving the L length symbols into diﬀerent beacon
periods, and sending the received adjacent symbols from diﬀerent anchors.
In this way, the round time for one location calculation can be signiﬁcantly
reduced; we call this symbol-interleaved acoustic beacon structure. Unlike the
conventional TDMA that transmits the whole frame within a beacon period,
i.e., Tp := Tf = LTs+Tg, we divide the whole frame into symbols and transmit
one symbol in each beacon period without Tg; the beacon period Tp can be
decreased to Tp := Ts.
To enable code matching under reduced frame length, the receiver main-
tains L length pipeline, and performs code matching in an iterative way. When
the symbols in the pipeline are matched with one sequence in p, the anchor
node can be identiﬁed. Using symbol-interleaved beacon structure, the initial
synchronization time Tsyn cannot be lowered, but the following update time

82
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
interval can be reduced to Tup = MTs = 0.7029s. The refresh of the location
data for every 0.7029 seconds is suﬃcient for tracking slow-moving humans.
The transmitted beacon sequence from the anchor network in the j-th
period can be written as pc(j)(a(j), b(j)), where a(j) ≡[j mod M] is the
index of the anchor node; b(j) ≡⌊j/L⌋is the index of the pseudocode in one
frame; c(j) ≡⌊j/(ML)⌋is one round measurement. The transmitted beacon
from the anchor network can be modeled as
gt(t) = √ε
Ns−1
X
j=0
pc(j)(a(j), b(j)) · g(t −jTs)
(5.4)
g(t) is the acoustic sharp pulse designed in (5.1); ε is the signal energy. The
number of total transmitted symbols is Ns.
5.4
Smartphone Localization
5.4.1
Design Workﬂow
In the smartphone, the Signal Detection and Demodulation module performs
audio signal recording and ﬁltering, detecting and extracting the embedded
beacon signal. The detection result is the digital symbols. The Code Matching
module matches the demodulated digital symbols to determine the anchor
ID and its predeﬁned location. The TOA Estimation module obtains pseudo-
ranges by measuring the arrival time of the signal. The Relative Distance
module accumulates all the distance from diﬀerent anchor nodes until a suf-
ﬁcient number of measurements is available for localization. The Localization
module performs location calculation by using the measured pseudo-distance
pairs and available anchor positions. The technical details of all these modules
are elaborated in the following subsections.
5.4.2
Symbol Detection and Demodulation
In the receiver side, i.e., the smartphone, we need to detect the signal and de-
modulate the information bits in the received signal r(k). The received signal
constitutes ξj multi-paths, and these multi-paths can be utilized to extract
the symbol. Thus, the detection problem can be written so as to detect the
signal that is present or not in the j-th symbol. The received signal waveform
in the j-th symbol period could be written as
rj(k) = √ε
ξj−1
X
l=0
Al
jgj(k −kl
j) + nj(k)
(5.5)
Assuming the sampling rate is Fs, for symbol duration Ts, the total sampling
point in one symbol is Mo = Ts × Fs. For the low-duty-cycle pulse used in

Guoguo: Enabling Fine-Grained Smartphone Localization
■
83
(5.1) as the symbol waveform, the actual signal length is shorter than the
total symbol length. Assuming the multi-path delay spread coeﬃcient is α,
the average sampling points for the signal region is Mp = α×(3τ)×Fs. Thus,
the two conditions of the hypothesis for detecting the signal can be written as





H0 : rj,k = nj,k
k = 1 · · · Mo
H1 :
(
rj,k = √εsj,k + nj,k
k = k0
j · · · k0
j + Mp −1
rj,k = nj,k
k = 1 · · · k0
j −1, k0
j + Mp · · · Mo
(5.6)
where nj,k is the matrix form of the noise nj(k) and sj,k is the k-th sampling
point for the signal in the j-th symbol. The symbol synchronization process is
to detect the signal region in the noise background, i.e., detect H1 condition
out of H0, while the TOA estimation is to detect the ﬁrst path of the signal
and its delay k0
j.
To detect the signal region (H1 condition), the decision vector zj can be
obtained by using the generalized likelihood ratio test (GLRT) [42]. The deci-
sion vector could be derived as the form of zj,k > ηsyn, with the j-th symbol
declared present if the inequity condition is satisﬁed and returns an estimated
value of the signal region kp. The threshold ηsyn is chosen to maintain a
constant false alarm rate (CFAR) [42], and written as the form of βσ where
σ is the noise variance, and β is calculated in the experiment by using the
given false alarm rate. Then ˆpc(j)(a(j), b(j)) in the receiver will be set to “1,”
otherwise ˆpc(j)(a(j), b(j)) = 0, where c ≡⌊j/(ML)⌋. ˆpc(j)(a(j), b(j)) is one
estimated version of p(a(j), b(j)), and c is one round measurement.
5.4.3
TOA Estimation
After detecting the symbols in Section 5.4.2, more detailed time-of-arrival
(TOA) estimation should be performed to estimate the ﬁrst path sample k0
j in
the whole symbol duration. The TOA estimation provides ranging information
that is needed for localization, and its accuracy directly aﬀects the overall
position resolution. The TOA estimation problem can be written so as to
detect k0
j in the j-th symbol of (5.5) as
ˆk0
j = min
k (k|rj(k) > ηtoa), k ∈[kp −Jp, Kp + Mo]
(5.7)
where kp is the rough signal region obtained during signal detection; Jp is the
step length used for jump-back-and-search-forward (JBSF) [22]; ηtoa is the
TOA estimation threshold; ˆk0
j is the estimated TOA path of k0
j. The TOA
estimation threshold ηtoa can be dynamically adapted to balance the false
alarm and misdetection probability. Based on our previous work [53], we can

84
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
write the TOA detection probability as
P toa
d
≈
Pd(zk)
NkPfa(zk)(NkPfa(zk) −C2
Nk(Pfa(zk))2)
(5.8)
= Pd(zk)[1 −1
2(Nk −1)Pfa(zk)]
where Pd(zk) and Pfa(zk) are the detection probability and false-alarm prob-
ability for the single sampling point. From (5.8), we know that increasing
Pd(zk) or decreasing Pfa(zk) of the single sampling point can contribute a
better P toa
d
. Small Nk also helps to improve the performance such that less
sampling points are detected.
Since Pd(zk) and Pfa(zk) is a function of ˆηtoa, P toa
d
can be written as
P toa
d
(ˆηtoa). The maximum value of P toa
d
can be achieved when ˆηtoa = ˆηoth
toa, as
ˆηoth
toa = arg max
ˆηtoa (P toa
d
(ˆηtoa))
(5.9)
Then, ˆηoth
toa can be written as
ˆηoth
toa = 1
2
√ε ˆA +
√π
2
√
2(1 −
1
Nk −1)ˆσ
(5.10)
where √ε ˆA and ˆσ are the estimated signal and noise value. By using (5.10)
in TOA estimation, the optimized TOA performance can be achieved under
the criterion of maximum TOA detection probability, as shown in (5.9).
With ˆk0
j available, the distance can be obtained by multiplying the speed
of acoustic signal c as ˆrm,j = c × ˆk0
j/Fs. The practical formula of sound speed
in air can be written as c = 20
√
ϑ + 273.15m/s, where ϑ is the temperature
in the air and can be measured by the anchor nodes.
5.4.4
Acoustic
Beacon
Synchronization
and
Code
Matching
Performing code matching between predeﬁned pseudo-codes pm,i and the es-
timated information bits ˆpc(j)(a(j), b(j)), the m-th anchor node can be iden-
tiﬁed if these two sequences match. When symbols with total M × L length
have been received, the code matching process can be utilized to synchronize
between the anchor node and the smartphone, by
[∆a, ∆b] =
(5.11)
arg min
∆a,∆b
||ˆpc(j)(a(ˆj) + ∆a, b(ˆj) + ∆b) −pm,i||1 < dtol
where the beacon period index j ∈[j0, j0 + ML], j0 = c(j) × (ML) is the
starting index of the symbol sequence, ML is the total length of symbols that

Guoguo: Enabling Fine-Grained Smartphone Localization
■
85
are used to perform (5.11), and ˆj = j −j0, c(j) can be used to illustrate the
index number of code matching. a(j) + ∆a and b(j) + ∆b is the cyclic shifting
in ˆpc(j)(·). dtol is the detection threshold illustrating the tolerance for bit error.
With the oﬀsets ∆a and ∆b available for the anchor node index and pseu-
docode sequence index, the mobile phone can aware the anchor node index
( ˆm) and sequence index (ˆi) of the current received symbol j as
ˆm = [(j −j0)
mod M] + ∆a
(5.12)
ˆi = [(j −j0)
mod L] + ∆b
where j0 = ⌊j/ML⌋× (ML).
5.4.5
Distance Update
After the synchronization in Section 5.4.4, and obtaining ˆm and ˆi in (5.12),
then every M symbol can obtain one distance measurement group with the
same pseudo sequence index ˆi. Such a group of measurements is the minimum
tuple of ranging for one position update, and every measurement in such a
group is from diﬀerent anchor nodes. For the j-th symbol, the index of the
group is jg = ⌊j/M⌋, with each element representing the TOA value ˆrm,j.
Denote the TOA estimation matrix as r = rm,jg, m = [1, M]. For notation
convenience, one group of measurements from all anchor nodes can be rep-
resented as rg = rm,jg, where jg is a ﬁxed value, and rg is a measurement
vector.
Due to some symbol-miss in real situations and none distance measure
during “0” symbols, the TOA value is not fully available for all M anchor
nodes in one round time, i.e., the obtained ranging value rg is a sparse vector.
To improve the reliability of ranging results, we perform robust regression for
the TOA estimation matrix r with an appropriate length of W, and obtain
a new version of rg. The rationale for the robust regression is to use the
outliers-ﬁltered historical data to estimate current sparse measurement. Since
the diﬀerent TOA value corresponds to its own symbol period, the latest W
column of the matrix r, rg = [rg(m)] can be calibrated by
rg(m) =
1
Nd(m)
W −1
X
∆g=0

rm,(jg−∆g) + ∆g × Nk

(5.13)
where rm,(jg−∆g) only counts when it contains TOA measurement, Nd(m) is
the total number of eﬀective measurements available in the W length matrix r,
and m represents the m-th row. Thus, vector rg(m) can be used as the current
distance measurement, with each TOA value indicating the pseudo-range from
the m-th anchor to the mobile device.
The measured pseudo-ranges between the anchor nodes and the mobile
phone are ˆrm = C × rg(m), where C is the speed of the aerial acoustic signal.

86
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Denoting the true distances as rm, m = [1, . . . , M], the unknown starting
point as δr, ˆrm can be written as
ˆrm = rm + δr + nm
(5.14)
where nm is the distance measurement noise for ˆrm.
5.4.6
Location Estimation
With the measured distance from M anchor nodes available, multilateration
can be performed to localize the smartphone. Assuming the real position of the
smartphone is p = (x, y), the position of the anchor node is pm = (xm, ym),
then the real distance from the smartphone to the anchor node m can be
written as rm =
p
(x −xm)2 + (y −ym)2. We deﬁne the vector of unknown
parameter as θ = [x
y
δr]T . The localization purpose is to obtain the esti-
mated value of θ from observations, where [ˆx, ˆy] in ˆθ is the estimated position.
However, (5.14) contains the nonlinear term. Rather than estimate θ di-
rectly, we select one of the M measurements as the reference f, and use this
reference to cancel out the nonlinear term. The selection of this reference could
be random or based on the code-matching quality (the mismatch residues). To
better illustrate this process, we can square both sides of (5.14) and subtract
the reference measurement f as
[(x2
m + y2
m −ˆr2
m) −(x2
f + y2
f −ˆr2
f)] + 2ˆrmenm −2δrnm
(5.15)
= 2(xm −xf)x + 2(ym −yf)y −2δr(ˆrm −ˆrf)
where enm is the diﬀerential noise term of nm −nf. Equation (5.15) can be
expressed in matrix form as
Aθ = ν + pn
(5.16)
where A =


xm −xf
ym −yf
ˆrf −ˆrm
· · ·
· · ·
· · ·

, θ =


x
y
δr

and ν =
1
2[(x2
m +
y2
m −ˆr2
m) −(x2
f + y2
f −ˆr2
f)](M−1)×3, m = 1, . . . , M when m ̸= f. ˆrm is the
measured distance obtained from (5.14). pn = 2ˆrmenm −2δrnm is the noise
term with its ﬁrst moment as E(pn) = 0 and the covariance matrix of vector
pn as eσ = Cov(pn). The diagonal elements of the covariance matrix are
2ˆrm(σ2
m + σ2
f) + 2δrσ2
m, with other elements in the matrix as 2ˆrmσ2
f.
Then (5.16) can be formulated as a least-square (LS) problem, and we can
obtain the solution as
ˆθ = (AT eσ−1A)−1AT eσ−1ν
(5.17)
Initially, the value of the covariance matrix eσ is unknown, and we could ini-
tialize eσ with all “1s” in its diagonal and “0s” for other elements. For the
following snapshots, eσ could be estimated, and we can substitute eσ into (5.17)
to improve estimation accuracy.

Guoguo: Enabling Fine-Grained Smartphone Localization
■
87
5.5
Error Pruning Techniques
Error pruning techniques are essential for the correct operation of the indoor
localization system, especially in sound interference. The source of potential
errors could be the noise and interference, blockage, indoor non-light-of-sight
(NLOS) transmission, anchor network failure.
5.5.1
Signal Level Resistance
To deal with the signal noise issues, we perform spread spectrum in trans-
mission and correlation processing in the receiver to obtain noise resistance.
We use the Gaussian second derivative pulse as the waveform, which has the
properties of high multipath and timing resolution, low energy consumption,
robustness to noise, and low spectrum emission.
Compared with noise, harsh indoor environments with blockage and high-
density multi-paths are more challenge. The blocked localization beacon could
either be attenuated or introduce additional delay that prolongs the obtained
ranging distance; we call this NLOS bias eﬀects. Using these problematic rang-
ing results could cause over-ﬁtting in localization calculation, or even make
the ﬁnal results diverge. Thus, how to identify and mitigate these prolonged
or problematic ranging measurement is crucial in localization.
One of the advantages of using acoustic signal for ranging lies in its high
timing resolution and the full access of the acoustic channel information. Ex-
tracting features from estimated channel condition, the goodness of transmis-
sion could be evaluated. For example, if the delay spread of the estimated
channel is signiﬁcantly larger than normal conditions, the ranging result from
this channel has a high probability of blockage, i.e., NLOS condition. By lower-
ing the weighting eﬃciency of these ranging measurements during localization,
overall location result could be more stable. We use the combined metrics of
RMS delay spread, Kurtosis, and mean excess delay to identify the NLOS
channel condition, and assign lower weight for the measurements from the
NLOS channel during localization processing.
5.5.2
Track before Localization
TOA ranging results km from M anchor nodes are the prerequisite for ranging-
based localization. In this section, we analyze the sources of ranging errors and
design new approaches to optimize the TOA ranging results ˆrm.
The obtained pseudorange rm can be written as
ˆrm = δr +

vm + vs(floc −fm)
Fs
+ vs

tm + amt2
m
(5.18)
where δr is the unknown delay that maps the pseudorange to the real dis-
tance; tm is the TOA vector for the m-th anchor; (floc −fm) is the clock drift
between the smartphone floc and anchor node fm; vm and am are the relative

88
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
moving speed and acceleration of the smartphone relative to the m-th anchor.
Denote rm = tmvs, as the real distance from the m-th anchor to the smart-
phone when the acoustic beacon is transmitted. If ignoring the movement of
the user and clock drift, i.e., vm, am ≪vs, tm and (floc −fm) are all small,
then the slope of ˆrm is ignored and ˆrm ≈rm.
To study the time series of the pseudorange ˆrm in an experiment, Fig. 5.3
shows the results from four diﬀerent anchor nodes when a user is standing still
and moving. When the user is standing still, the time series of ˆrm is linear as
shown in Fig. 5.3(a), where the slope is vs(floc −fm)/Fs. ˆrm increases over
time due to the clock diﬀerence (floc > fm). From Fig. 5.3(a), we can calculate
the clock diﬀerence floc −fm = 1.4Hz, and the equivalent moving speed of the
drift is 0.01m/s.
(a) Stationary
0
20
40
60
80
3.78
3.785
3.79
3.795
3.8
3.805
3.81
3.815x 10
4
Ranging Point
Pseudorange
Sta 1
Sta 2
Sta 3
Sta 4
(b) Moving
Figure 5.3: Ranging results for (a) stationary and (b) moving users.
Fig. 5.3(b) shows the pseudorange results when a user is moving. The time
series of ˆrm becomes a curve with the ﬁrst derivative as the eﬀective velocity
(vm) to the anchor node m, whereas the second derivative is the acceleration
am.
Tracking ˆrm before localization could provide more robust and smoothed
ranging results for the location calculation step. From Fig. 5.3(a), we also
know that some of the ranging points are missing or become outliers due to
detection errors. Conventional tracking approaches, e.g., a Kalman ﬁlter, could
not provide satisfactory results. The real measurement with missing data and
outliers does not follow Gaussian distribution and could make the Kalman
ﬁlter diverge.
Our proposed solution is to estimate the health status of each station by
monitoring ˆrm, and perform smoothing and tracking for the healthy stations.

Guoguo: Enabling Fine-Grained Smartphone Localization
■
89
If the measurement from one station has a high probability of error, it is better
to mitigate the ranging measurements from this station in this round. For the
missing data in healthy stations, a spline interpolation process is utilized.
After the outlier mitigation and missing data interpolation, a modiﬁed robust
Kalman ﬁlter is applied for further smoothing the ranging observations [84].
5.5.3
Location Tracking
The location of y is estimated via batch processing in DC-SDP. The high
correlation feature of adjacent y could be utilized for smoothing and tracking
the ﬁnal location results. A 2D robust Kalman ﬁlter [84] is applied for its
outlier robustness.
The state of the smartphone could be stationary, moving, or in the tran-
sition (from stationary to moving or the reverse). Without considering the
status of y, the Kalman ﬁlter can achieve limited performance because diﬀer-
ent coeﬃcients of the Kalman ﬁlter should be applied for diﬀerent states.
To make the tracking algorithm adaptive to the state of the target (smart-
phone), we perform stationary detection concurrently with the tracking pro-
cess. From Fig. 5.3(a) and Fig. 5.3(b), when the target is stationary, the
trend of the pseudorange ˆrm increases over time with constant slope of
(vs(floc −fm)/Fs). The clock of the anchor nodes is synchronized through
Zigbee radio, i.e., fm = fconst, m = 1, . . . , M, thus the slope of ˆrm has the
same value for each station. By performing common slope detection, the state
of the target is identiﬁed, and distinct coeﬃcients of the tracking ﬁlter could
be tuned for best performance in each state.
5.6
Performance Evaluation
In this section, we perform system performance evaluation by using Apple’s
iPhone 4S and iPod Touch 5 (iTouch5) without any modiﬁcation of the hard-
ware or jailbreak of the operating system.
The 3dB pulse width of the transmitted signal as in (5.1) is chosen with
Tw = 1.5ms to meet the bandwidth constraint. A sharper pulse results in
better multipath robustness and time-domain resolution, but with increased
bandwidth occupancy. Restricted by the bandwidth of a microphone, the ef-
fective pulse energy and operating distance would be decreased when more
frequency components are outside the receiver band. The symbol duration is
chosen as Ts = 0.0781s, resulting in the pulse duty cycle of R = 1.92%. Shorter
symbol duration leads to a higher data rate and location refreshing rate, but
restricted by the multipath environment. The choice of these parameters is a
tradeoﬀbetween the achievable resolution and maximum operating distance.

90
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
5.6.1
Sound Pressure Level Measurement
The Guoguo System uses audible-band signal as a beacon. However, users
might be concerned about the noise eﬀect of the acoustic signals in indoor
environments.
0
0.5
1
1.5
2
2.5
x 10
4
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Frequency (Hz)
A−Weighting
(a) A-weighting curve
1
2
3
4
0
20
40
60
80
Environment
Sound Pressure Level (dBA)
 
 
Normal
Beacon
+0.17dBA+0.80dBA
+0.89dBA
+0.05dBA
(b) Sound Pressure Level
Figure 5.4: (a) The perception level of human ears; (b) comparison of
sound pressure level in four scenarios.
To make our transmitted acoustic signal unperceptible to users, we de-
signed the waveform of the beacon signal with appropriate transmission power.
To quantify the results, from the perception curve of human ears (A-weighting
coeﬃcients), we derive the sound pressure level (SPL) value as a metric of
sound level. We place four anchor nodes very close to a smartphone (the most
noisy case), and measure the diﬀerence of SPL. The normal sound background
case is named “Normal”; the environment that ﬁlled with our beacon signal
is called “Beacon”. The SPL values for these two conditions in four diﬀerent
environments are shown in Fig. 5.4(b). The maximum diﬀerence of the SPL
caused by the “Beacon” is 0.85dBA, which is below the perception level of the
human ear. Therefore, we can conclude that our transmitted acoustic beacon
signal is completely ignorable and disturbance-free even in extreme cases.
5.6.2
Maximum Operation Distance
Limited by the available maximum distance in a room, we move the evaluation
of the maximum operation distance in an aisle environment from 1.8 ∼24.4m
under two conﬁgurations: no sound interference (SI) and with sound interfer-
ence (SI), where the SI cased is simulated by playing video sound near the
mobile device. The quantiﬁed signal level is shown in Fig. 5.5, where higher
signal level means stronger SI.

Guoguo: Enabling Fine-Grained Smartphone Localization
■
91
(a) no SI
(b) with SI
Figure 5.5: Signal level (dBA) in an aisle.
The ranging accuracy in Fig. 6.8 shows the maximum operation distance for
our proposed scheme is around 15 ∼20m. Even with SI, the ranging accuracy
at the maximum operation distance between 15 ∼20m is still satisfactory.
(a) no SI
(b) with SI
Figure 5.6: Ranging accuracy in an aisle.
5.6.3
Localization in Oﬃce Environments
Experiment Setup. We deploy 9 anchor nodes in a typical oﬃce environment
to evaluate the performance of Guoguo, as shown in Fig. 5.7.
A total of 12 cases have been tested: 6 of them were tested in a quiet
environment for theoretical performance; the other 6 cases were tested under

92
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 5.7: Experiment setup in an oﬃce environment.
SI. The experiment conﬁguration is summarized in Table 5.2. The last term
is the eﬀective number of accessed anchor nodes (Neff) during localization
calculation. The number of Neff is less than the total number of deployed
anchors. This is often caused by interference, blockage, and NLOS during the
localization process.
Table 5.2: Experiment conﬁguration in an oﬃce environment (some an-
chors are not shown in the photo)
ID
Use Cases
Length (s)
Background
Neff
1
Env1
60.91
Quiet
6.86
2
Env2
60.97
Quiet
6.15
3
Env3
60.61
Quiet
8
4
Env4
60.64
Quiet
7.77
5
Env5
60.53
Quiet
8.24
6
Env6
60.64
Quiet
8.72
7
P4snoise1
522.97
Sound
5.03
8
P4snoise2
300.48
Sound
6.11
9
P4snoise3
346.35
Sound
5.99
10
Touchnoise1
398.79
Sound
5.97
11
Touchnoise2
461.03
Sound
6.13
12
Touchnoise3
582.14
Sound
6.07
Localization Accuracy in Quiet Environment. In this case study, to
support quantitative analysis, we localize a smartphone when its user stands
still at diﬀerent spots. The location error (LE) is evaluated via Root Mean
Square Error (RMSE) between the ground truth and the calculated location
value. The cumulative distribution function (CDF) of the localization error
is shown in Fig. 5.8(a). If using 80% probability, the localization error for all
the cases is in the range between 4cm and 8cm. These localization results are
very accurate and suﬃcient for ﬁne-grained indoor location-based services.

Guoguo: Enabling Fine-Grained Smartphone Localization
■
93
0
0.05
0.1
0.15
0.2
0.25
0
0.2
0.4
0.6
0.8
1
Error (m)
CDF
 
 
Env1
Env2
Env3
Env4
Env5
Env6
Env6
Env5
Env1
Env3
Env4
Env2
(a) no SI
0
0.05
0.1
0.15
0
0.2
0.4
0.6
0.8
Error (m)
CDF
 
 
P4s−noise1
P4s−noise1
P4s−noise1
Touch−noise1
Touch−noise2
Touch−noise3
P4s−noise1
Touch−noise2
Touch−noise3
Touch−noise1
P4s−noise2
P4s−noise3
(b) SI
Figure 5.8: The localization accuracy in an oﬃce environment under (a)
no SI; (b) with SI.
Localization Accuracy under SI. To evaluate the localization perfor-
mance in a realistic environment, we add artiﬁcial sound to evaluate the ro-
bustness of our proposed system. The SPL level of the added sound is around
40 ∼90dBA. The measured sound pressure level (dBA) is calculated from the
received acoustic signal at a smartphone during localization.
Fig. 5.8(b) shows the CDF of the localization error (LE) in an oﬃce en-
vironment. In these six cases with background sound, the ﬁnal localization
accuracy is still within 10cm, with less than 10% of results slightly aﬀected.
From another point of view, the number of eﬀective accessed anchors under
background sound is slightly lower than the normal cases from the Neff value
in Table 5.2 because some of the acoustic beacons have been mitigated. Since
we use more anchors than the minimum requirement (three anchors), these
additional anchors can improve our system’s robustness under a realistic en-
vironment.
Localization Metrics. Other metrics that are used to evaluate the sys-
tem performance are the localization Miss Rate, and location Average Update
Time.
The localization Miss Rate evaluates the quality of obtained location val-
ues. The deﬁnition of Miss Rate is Nloc/Npos, where Nloc is the number of
obtained location results; Npos is the number of reﬁned location results after
the post-processing module. Lower Miss Rate means better localization re-
sults. The Miss Rates for all the cases in Fig. 5.9(a) show very small value,
i.e., the localization results are of very good quality.
Another important metric is the Average Update Time, representing the
refreshing rate of the localization process. If the refreshing rate is too slow,
it is hard to keep up with the moving traces of subjects. Due to the low
transmission speed of acoustic signal, minimizing Average Update Time is
nontrivial. From Fig. 5.9(b), we observe that the Average Update Time for

94
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
(a) Miss Rate
(b) Average Update Time
Figure 5.9: Measured performance metrics of ranging rate (a), miss rate
(b), and average update time (c) for diﬀerent measurements in an oﬃce
environment.
1
2
3
4
5
6
7
8
9
10 11 12
0
0.02
0.04
0.06
0.08
0.1
Use Cases
Localization Error (m)
 
 
50−Percentile
80−Percentile
90−Percentile
(a) Location Accuracy
0
2
4
6
8
−0.5
0
0.5
1
1.5
2
2.5
X (m)
 
 
Y (m)
Anchor Node
Env1
Env2
Env3
Env4
Env5
Env6
(b) Location Scatters
Figure 5.10: 1) Localization accuracy in diﬀerent cases; 2) obtained loca-
tion results as scatters.
Guoguo is less than one second, suﬃcient for capturing the traces of moving
subjects at modest speed. This rate is signiﬁcantly faster than other existing
approaches that also use acoustic signal for localization.
Overall Localization Accuracy. Using 50-percentile, 80-percentile, and
90-percentile probability to evaluate the localization accuracy, the results of
all 12 cases are shown in Fig. 5.10(a). The achieved localization accuracy is in
the centimeter-level even for the cases with added interference. Such results
could push the current coarse-level LBS into ﬁne-grained level in an eﬀective
way. The scatters of the localization results for users in 6 diﬀerent locations

Guoguo: Enabling Fine-Grained Smartphone Localization
■
95
Figure 5.11: The experiment setup in a classroom environment.
in an oﬃce environment are shown in Fig. 5.10(b). The error surface of the
scatter is very small and demonstrates the highly accurate location result.
5.6.4
Localization in Classroom Environments
Experiment Setup. Similar to Subsection 5.6.3, we deploy 9 anchor nodes in
a multimedia classroom environment to evaluate the performance of Guoguo,
as shown in Fig. 5.11, with maximum distance larger than 15 meters.
The experiment conﬁguration in this classroom environment is summarized
in Table 5.3.
Table 5.3: Experiment conﬁguration in a classroom
ID
Use Cases
Length (s)
Background
Neff
1
Env1
590.43
Quite
6.98
2
Env2
408.70
Quite
6.80
3
Env3
459.76
Quite
7.0
4
Env4
676.39
Quite
6.99
5
Env5
270.49
Quite
5.9
6
Env6
599.47
Quite
7.0
7
P4snoise1
279.38
Sound
6.94
8
P4snoise2
641.74
Sound
7.96
9
P4snoise3
240.40
Sound
7.72
10
Touchnoise1
599
Sound
7.0
11
Touchnoise2
88.79
Sound
5.38
12
Touchnoise3
347.5
Sound
5.0
Localization Accuracy under Quiet Environment. The scatters of
the localization results for users in diﬀerent locations in a classroom environ-
ment are shown in Fig. 5.12(a). Similar to Fig. 5.10(b), the error surface of
achieved location results is very small. The CDF of the localization results
for the measurements in Fig. 5.12(a) is shown in Fig. 5.12(b). For most of the

96
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
(a) Scatters
0
0.05
0.1
0.15
0.2
0.25
0
0.2
0.4
0.6
0.8
Error (m)
CDF
 
 
Env1
Env2
Env3
Env4
Env5
Env6
Env3
Env5
Env6
Env4
Env1
Env2
(b) LE
Figure 5.12: The scatters (a) and CDF (b) of the localization results in
a classroom environment.
50
55
60
65
70
75
0
0.2
0.4
0.6
0.8
1
dBA
CDF
 
 
P4s−noise1
P4s−noise1
P4s−noise1
Touch−noise1
Touch−noise2
Touch−noise3
Touch−noise2
Touch−noise3
P4s−noise1
P4s−noise2
P4s−noise3
Touch−noise1
(a) Background Sound
0
0.2
0.4
0.6
0.8
0.2
0.4
0.6
0.8
Error (m)
CDF
 
 
P4s−noise1
P4s−noise2
P4s−noise3
Touch−noise1
Touch−noise2
Touch−noise3
Touch−noise3
Touch−noise2
P4s−noise1
Touch−noise1
P4s−noise2
P4s−noise3
(b) LE
Figure 5.13: The CDF of the background sound (a) and localization error
(b) in a classroom environment.
cases, e.g., using 80% probability, the localization accuracy is very high and
in the range from 5cm to 10cm.
Localization Accuracy under Background Sound. To evaluate the
localization performance under interference, we added artiﬁcial sound in the
classroom environment by playing the lecture videos. The CDF of the added
diﬀerent background sound is shown in Fig. 5.13(a). The CDF of the localiza-
tion results under background sound in a classroom environment is shown in
Fig. 5.13(b). One interesting observation from Fig. 5.13(b) is that the iPhone4s

Guoguo: Enabling Fine-Grained Smartphone Localization
■
97
achieves much better performance than the iTouch5. The reason could be the
built-in multi-microphones and noise-canceling mechanisms in iPhone4s, while
the iTouch5 is only equipped with one microphone and no noise-canceling
hardware.
Localization Metrics. The Ranging Rate for the measurements in a
classroom environment is shown in Fig. 5.14(a), while two cases of iTouch5
suﬀer from low Ranging Rate under background sound. The Miss Rates in
Fig. 5.9(a) show very small value. The Average Update Time for the envi-
ronment of a classroom is near 0.8 seconds and suﬃcient for mobility cases.
1
2
3
4
5
6
7
8
9
10 11 12
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Use Cases
Ranging Rate
(a) Ranging Rate
1
2
3
4
5
6
7
8
9
10 11 12
0
0.1
0.2
0.3
0.4
0.5
Use Cases
Location Miss Rate
(b) Miss Rate
1
2
3
4
5
6
7
8
9
10 11 12
0
0.5
1
1.5
2
Use Cases
Average Update Time (s)
(c)
Average
Update
Time
Figure 5.14: Measured performance metrics of ranging rate (a), miss
rate (b), and average update time (c) for diﬀerent measurements in a
classroom environment.
Overall Localization Accuracy. The 50-percentile, 80-percentile, and
90-percentile localization accuracy results are summarized in Fig. 5.10(a). Ex-
cepts the iTouch5 under background sound, other cases achieve localization
accuracy under 10cm for most cases. The localization results of iPod Touch5
are slightly worse than iPhone4’s, but still suﬃcient for indoor location-based
services.
5.6.5
Impact of Anchor Numbers and Locations
To evaluate the impact of anchor numbers and location distributions to the
location results, we utilize the ranging results from 8 anchors and disable
some of the anchors in location estimation. The ranging accuracy of all these
8 anchors are shown in Fig. 5.16(a). There are multiple choices when selecting
diﬀerent numbers of anchors, and the resulting localization accuracy is also
diﬀerent, which depends on the geometric dilution of precision (GDOP) of
the anchor network. By selecting all the combinations exclusively, we could

98
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
1
2
3
4
5
6
7
8
9
10
11
12
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Use Cases
Localization Error (m)
 
 
50−Percentile
80−Percentile
90−Percentile
Figure 5.15: Localization error for diﬀerent measurements in a classroom
environment.
Sta1 Sta2 Sta3 Sta4 Sta5 Sta6 Sta7 Sta8
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Different Anchors
Ranging Error (m)
 
 
50 Percentile
80 Percentile
95 Percentile
(a) Ranging Accuracy
8
7
6
5
4
3
0
0.2
0.4
0.6
0.8
Anchor Numbers
Localizatin Error (m)
 
 
X−direction
Y−direction
(b) Location Accuracy
Figure 5.16: (a) Ranging accuracy for 8 anchor nodes; (b) localization
accuracy with respect to anchor numbers.
calculate the average localization accuracy (using the 80 percentile as an ex-
ample) and the variance. The result is shown in Fig. 5.16(b), where the error
bar shows the value of variance. With the decrease of the anchor numbers,
the accuracy also decreases with larger variance. When the anchor number is
small, the locations of the available anchor nodes become more important (a
biased-placed anchor network could increase the location error signiﬁcantly).

Guoguo: Enabling Fine-Grained Smartphone Localization
■
99
In Fig. 5.16(b), we show that the location error increases signiﬁcantly when
there are only three anchors. We need at least three measurements to solve
the three unknown parameters in (5.17), i.e., location (x and y) and unknown
delay (δr). The large error is understandable since the LS approach needs
redundancy to tolerate the ranging errors.
5.6.6
Moving Traces
We used stationary localization cases to evaluate and quantify the accuracy
of the Guoguo system. To improve the dynamic performance when tracking
a moving user, we proposed error-pruning techniques, e.g., signal level resis-
tance, track before localization, and location tracking, to improve the robust-
ness and accuracy. To compare the contributed performance improvement, we
calculate the moving trace of a user by performing simultaneousness real-time
computation using two diﬀerent approaches: with and without error pruning.
To keep the moving trace intact and easy to compare, we perform moving in a
v-shape with modest speed (peak speed around 50cm/s). The calculated rang-
ing results (pseudorange) and ﬁnal location traces are illustrated in Fig. 5.17
and Fig. 5.18. From Fig. 5.17, we know that the obtained pseudorange is
signiﬁcantly better after applying the error pruning techniques. The location
trace in Fig. 5.18(b) also shows clear and accurate results compared with the
scattered trace in Fig. 5.18(a) without error pruning.
0
20
40
60
80
100
120
9200
9400
9600
9800
10000
10200
10400
Ranging Point
 
 
Pseudorange
Sta1Sta2 and Sta3
Sta4
Sta5 Sta6
(a) Without error-pruning
0
20
40
60
80
100
120
9200
9400
9600
9800
10000
10200
10400
Ranging Point
Pseudorange
Sta1Sta2 and Sta3
Sta4
Sta5 Sta6
(b) With error-pruning
Figure 5.17: Pseudorange results from multiple anchors of a moving user:
a) without error-pruning; b) with error-pruning.

100
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
0
200
400
600
800
0
50
100
150
200
250
X (cm)
Y (cm)
 
 
Anchor Node
Calculated Position
(a) Without error-pruning
0
200
400
600
800
0
50
100
150
200
250
X (cm)
Y (cm)
 
 
Anchor Node
Calculated Position
(b) With error-pruning
Figure 5.18: Location traces of a moving user: a) without error-pruning;
b) with error-pruning.
5.6.7
System Evaluation
For the app, we implemented the signal detection and ranging algorithm in
a smartphone leveraging the iOS Grand Central Dispatch (GCD) and vDSP
Accelerate framework for better responsiveness and eﬃciency. To save the bat-
tery life of the smartphone, we oﬄoad the computation intensive localization
and tracking to the server. Leveraging the open-source Redis NoSQL database,
we designed a pub/sub framework [92]. Such conﬁguration balances the com-
munication and computation cost. Fig. 5.19 compares our app “Guoguo” to
“Chrome” and “Temple Run2” in terms of the energy consumption rate, CPU
activity, and network activity on the iOS platform. Guoguo features a stable
CPU utilization around 28% (Apple iPhone4S), which is lower than the pop-
ular game Temple Run 2, and much lower than Google’s iOS version web
browser Chrome. The delay caused by the network communication and com-
putation is in the micro-second level, which is ignorable compared with the
location update rate.
Figure 5.19: Energy consumption rate, CPU activity, and network activ-
ity generated by Xcode Instrument.

Guoguo: Enabling Fine-Grained Smartphone Localization
■
101
5.7
Conclusion
We proposed the Guoguo algorithm and ecosystem to realize the smartphone-
based ﬁned-grained indoor localization. For the ﬁrst time, we can locate a
smartphone user at the centimeter-level, which has signiﬁcant implications
for potential indoor location services and applications compared with existing
meter-level localization solutions. To address the challenges of utilizing the
audible-band acoustic signal in smartphone localization, i.e., strong attenua-
tion, interference-rich, high sound disturbance, and diﬃculty in synchroniza-
tion, we proposed comprehensive schemes to improve the localization accuracy
and extend coverage without sound disturbance. Signiﬁcant improvements
were achieved in terms of accuracy, cost, and scalability, compared with other
existing approaches. Experimental results demonstrated that the achieved av-
erage localization accuracy is about 6 ∼15cm in typical indoor environments.
Guoguo represents a leap of progress in smartphone-based indoor localiza-
tion, opening enormous new opportunities for indoor location-based services,
positioning and navigation systems, and other commercial, educational, or
entertainment applications.


Chapter 6
Enhancing Location
Accuracy and Robustness
via Opportunistic Sensing
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
6.1
Introduction ......................................................
104
6.2
System Overview .................................................
105
6.2.1
Motivation ...............................................
105
6.2.2
System Design ...........................................
106
6.3
Displacement and Motion Estimation ...........................
107
6.3.1
Principle of Inertial Navigation .........................
107
6.3.1.1
Coordinate System .........................
107
6.3.1.2
Rotation Estimation .......................
108
6.3.1.3
Coordinate Transformation ................
109
6.3.2
Displacement Estimation ................................
109
6.3.3
Mitigating Displacement Estimation Error .............
111
6.3.3.1
Apply Constraint via Activity Results ....
111
6.3.3.2
Gaussian Derivative Decomposition .......
112
6.4
Absolute Location Estimation with Fewer Anchors .............
112
103

104
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
6.4.1
Background and Basic Procedures ......................
112
6.4.2
Improving the Location Accuracy via Constraints ......
114
6.4.2.1
Initial Location
............................
114
6.4.2.2
Measurements ..............................
114
6.4.2.3
Location Optimization .....................
116
6.5
Trilateration via Semideﬁnite Programming .....................
117
6.5.1
Min-Max Criterion ......................................
118
6.5.2
Delay-Constraint Robust Semideﬁnite Programming ...
118
6.5.3
Improving Indoor Localization via Sensor Fusion .......
120
6.6
Experiment .......................................................
121
6.6.1
System Evaluation .......................................
121
6.6.2
Displacement Estimation ................................
121
6.6.3
Ranging Estimation .....................................
122
6.6.4
Improving Location Accuracy with Fewer Anchors .....
123
6.6.5
Trilateration via Semideﬁnite Programming ............
125
6.6.6
Location Fusion ..........................................
125
6.7
Related Work ....................................................
126
6.8
Conclusion ........................................................
128
6.1
Introduction
Ubiquitous smartphone and location information are enabling new features
of location-based services (LBS) around local navigation, retail recommenda-
tion, proximity social networking, and location-aware advertising. Recently,
the focus is also shifting geographically from outdoor to indoor, where we
spend the most money, meet friends, work, and do business.
The indoor location market will be more enormous than the outdoor, since
we spend more than 80% of our time indoors in our daily activities, e.g., work-
ing, shopping, eating, at the oﬃce, at home. Technologically, outdoor localiza-
tion techniques cannot be directly moved indoors. Satellite-based localization,
e.g., GPS, has been one of the most important technological advances of the
last half century. No matter how good the systems get for outdoors, their
accuracy, coverage, and quality deteriorate signiﬁcantly in small-scale indoor
places. Emerging techniques using existing infrastructure, e.g., WiFi access
point, cellular tower, could only achieve limited accuracy, or need extensive
war-driving and calibration [6, 8, 15]. Other accurate approaches rely on the
deployment of additional infrastructure [48, 57, 81, 85], e.g., dense anchor
nodes. These approaches have a high requirement for the minimum anchor
number, e.g., at least three anchors for 2-D trilateration. Accessing multiple
Wi-Fi access points at the same channel simultaneously, or getting beacon
signals from at least 3 deployed anchor nodes, are harsh prerequisites for
indoor localization that are hard to meet in real environments. The highly
dynamic and mobile setting, where humans are essentially moving, presents
further challenges for existing solutions either using existing infrastructure

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
105
or self-deployed anchor networks. There exist inherent tradeoﬀs between the
localization accuracy and the deployment complexity. Existing low-accurate
or high-complexity indoor localization solutions in a mobile phone call for
signiﬁcant innovations in balancing the accuracy and complexity.
In this chapter, we propose a highly accurate and scalable mobile phone lo-
calization system via opportunistic anchor access. Unlike [57] which requires
a minimum of three anchors, our designed approach works under diﬀerent
“anchor” coverage and scales from only one “anchor.” For applications with a
limited budget for anchor deployment, deploying only one anchor node could
achieve signiﬁcantly better accuracy than non-anchor based approaches, and
greatly lower the deployment cost. When the number of deployed anchors
increases, our proposed algorithms can adapt to highly accurate results con-
tributed by the additional anchors. With this ﬂexibility, location service op-
erators could select conﬁgurations that suit various resolution requirements.
Transforming the high level system design goal into a practical working sys-
tem poses signiﬁcant challenges: (1) How can we improve the location ac-
curacy signiﬁcantly even with only one or two anchor nodes? (2) Will our
system adapt to higher accuracy with better anchor accessibility? This pa-
per addresses these challenges, and prototypes the system via opportunistic
anchor sensing. Testbed results conﬁrm that our design goals could adapt to
diﬀerent deployment budget and service quality requirements with high scal-
ability, e.g., from only one node to multiple nodes, and achieve signiﬁcantly
higher accuracy than anchor-free systems. We believe this could be a practi-
cal approach to achieve accurate localization results with very low hardware
requirement and deployment costs, also scalable for applications with ﬁne-
grained resolution demand. To that end, we outline several conﬁgurations and
propose solutions that hold promise in this new sensing paradigm.
The rest of the chapter is organized as follows. Section 6.2 introduces a sys-
tem overview. Section 6.3 presents the displacement and direction estimation
via INS. Section 6.4 proposes the location optimization approaches for less
anchors. Section 6.5 investigates the ﬁne-grained mobile phone localization
via delay-constraint robust semideﬁnite programming. Section 6.6 evaluates
the system performance via experiment. Section 6.7 summarizes related work.
Section 6.8 concludes this paper.
6.2
System Overview
6.2.1
Motivation
Achieving high accuracy and high robustness in location estimation, anchor
nodes (existing or needing deployment) need to be utilized to provide loca-
tion reference. Our previous approaches [57] need at least three synchronized
anchors for trilateration, which is hard to meet in real cases without dense

106
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
deployment. Lowering the minimum anchor number requirement is
essential for system scalability and low-complexity.
If one anchor-based system could adapt to diﬀerent deployment budgets
with high scalability, e.g., from only one node to multiple nodes, and achieve
signiﬁcantly higher accuracy than an anchor-free system, service operators
would have very high enthusiasm to deploy this system for various service
quality requirements. The potential application of this proposed system could
include indoor check-in, proximity, and location detection services if only one
anchor is deployed; multiple anchors could be useful for shopping mall man-
agers, factory administrators, and hospital doctors to monitor the ﬂow of prod-
uct, equipment, and inventory movement, or to trace patients’ movement. It
could also be used to provide turn-by-turn guides with foot-level accuracy to a
destination, such as a book in a library, a toy in a store, or a butterﬂy sample
in a museum.
6.2.2
System Design
The overview of our proposed solution is illustrated in Fig. 6.1.
Figure 6.1: System architecture.
Fewer Anchors. For the most simple case, one anchor node provides ba-
sic check-in services, and coarse-grained location estimation. If, however, the
sensing data contains: 1) the ranging information for the anchor node and
smartphone pair; 2) displacement and moving direction of the smartphone, a
much better accuracy could be obtained by leveraging these measurements.
We utilize the acoustic RSS and TOA ranging for distance measure, INS for
displacement and direction estimation, and leverage the activity measurement
for error mitigation. To support multiple users simultaneously, all the ranging
process is in one-way passive mode, in which the smartphone only needs to
receive beacons. Thus, the highly accurate TOA result is the pseudorange be-

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
107
tween the smartphone and anchor pair. The inertial sensors, i.e., accelerometer
and gyroscope, are utilized for accurate displacement and direction estimation.
If multiple anchor nodes could be sensed by smartphone, i.e., multiple
ranging and relative direction results, the accuracy of the location estimation
result could be further improved.
Trilateration via Semideﬁnite Programming. When the TOA mea-
surements from accessed anchors are suﬃcient for trilateration (N A > 3),
a more accurate algorithm should be utilized. To solve the practical problem
that some available anchors contain large ranging errors, and avoid over-ﬁtting
in conventional least square (LS) based approaches, we use semideﬁnite re-
laxation to convert the original localization problem into a convex problem.
The delay-constraint and Huber penalty function is applied with semideﬁnite
programming (SDP) for better accuracy and robustness. The global optimal
solution of the mobile phone position can be ensured by using SDP along with
post-position fusion with displacement results.
Powerful Cloud-Based Algorithms with Low Cost. Using the beacon
data gleaned from the smartphone, the device works with an app and performs
complex calculations to ﬁgure out where it is within the map. However, current
powerful cloud-based processing architecture makes complex computation not
a problem. All this could encourage us to utilize advanced algorithms for better
accuracy, with less worrying about the implementation detail.
6.3
Displacement and Motion Estimation
The recent advances in the construction of micro-machined electromechanical
systems (MEMS) sensor chips have now made it a reality to embed IMUs
in almost every smartphone. Although MEMS sensors are not as accurate
as the large mechanical or optical devices used in military applications, they
are signiﬁcantly cheaper, portable, and durable, thus making this technology
ubiquitously available. The IMUs built in current smartphones typically con-
tain three orthogonal gyroscopes, accelerometers, and magnetometers. Typical
mobile platforms, e.g., iOS, Android, have the complete framework/package
support for programming and accessing all these sensors. Industry’s strong
emphasis on the IMUs could stimulate future context-ware applications, and
this chapter also falls into this category.
6.3.1
Principle of Inertial Navigation
6.3.1.1
Coordinate System
We model the smartphone as a rigid body in the body coordinate (b-frame),
with three axes (x, y, z) perpendicular with each other, and the origin point
O(0, 0, 0) is deﬁned in the mass center of the smartphone. The x-axis is deﬁned
as horizontal and points to the right (a.k.a. horizontal-right); the y-axis is

108
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
deﬁned in the vertical-up direction; the z-axis is pointing to the user and
perpendicular to the screen.
The body coordinate is a local coordinate of the smartphone with its orien-
tation and displacement changes when we move the smartphone. We assume
all the INS measurements in a smartphone are resolved in the b-frame.
To characterize the absolute movement of the smartphone with respect
to the indoor/outdoor environment, we deﬁne the navigation coordinate (n-
frame) as a local geographic frame that we want to navigate, e.g., stationary
with respect to the indoor/outdoor map that is presented to the user. For most
cases, especially for navigation over small areas, the navigation coordinate is
ﬁxed to the east-north-up (ENU) coordinate with shifted origin over reference
point OR, where x is the east axis, north is y, and Up is z.
6.3.1.2
Rotation Estimation
The attitude, or orientation, of a smartphone relative to a local reference
frame can be tracked by integrating its angular velocity measured by Gyros.
The quantity results from Gyros is the rotation rate in radians/second, and
can be denoted as ωb
t = (ωbx
t , ωby
t , ωbz
t )T , where t is the sample timestamp;
bx, by and bz means the 3-axis component in the body framework. The sign
follows the right hand rule. To calculate the rotation angle (θb
t) within the
body coordinate, the integration process could be utilized as θb
t =
R t
0 ωb
t.
Current Mobile Operation System all provide direct access to the attitude
and rotation value in terms of Euler angles (roll, pitch, yaw), quaternions and
direction cosine matrix (DCM). We could use the DCM as the rotation matrix
R, since the elements of this matrix are the cosines of the unsigned angles
between the body axes and the navigation axes. The obtain R is actually
The orientation of the device can be speciﬁed by using several diﬀerent
representations, including Euler angles (roll, pitch, yaw), quaternions and di-
rection cosine matrix (DCM). All these diﬀerent representations can be con-
verted from each other. For better illustration, we utilize the Euler angles, i.e.,
roll (φ), pitch (θ), yaw (ψ), in the body coordinate to illustrate the smart-
phone attitude. We also use the DCM as the rotation matrix R, since the
elements of this matrix are the cosines of the unsigned angles between the
body axes and the navigation axes.
To derive the Euler angles, the Euler rates (

φ
˙θ
˙ψ

) based on the initial
Euler angles and angular velocity (ωb
t) can be derived as


˙φ
˙θ
˙ψ

=


1
tan θ sin ψ
tan θ cos ψ
0
cos φ
−sin θ
0
sin ψ sec θ
cos ψ sec θ




ωbx
t
ωby
t
ωbz
t


(6.1)
With the Euler rates available, a linear integration scheme can be used to

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
109
calculate the Euler value in the current time slot as
φ = φ + ˙φ · Tins
(6.2)
θ = θ + ˙θ · Tins
ψ = ψ + ˙ψ · Tins
where Tins is the update time interval of the INS sensor. When the smartphone
stands still, i.e., without undergoing any rotation, the output of the Gyros is
not perfect zeros. Assume the constant bias error is ϵ, the random noise is
a zero-mean uncorrelated random variable with a ﬁnite variance of σ2. The
result of integrating the random noise in (6.2) is a random walk in angle,
whose mean value is zero but with increasing standard deviation. The error
model of the Gyros measurement can be formulated as
ε = εb + εr + wg
(6.3)
where εb is the constant bias error, where ˙εb = 0; εr is the random walk
error, where ˙εr =
1
Tg εr + wr; Tg is the correlation time of the Gyros. For the
bias error, it causes an angular error that grows linearly when integrated in
the rotation angle calculation. In system calibration, εb can be subtracted via
the estimated value after taking a long term average when the Gyros is not
undergoing rotation.
6.3.1.3
Coordinate Transformation
When a smartphone is placed in the initial reference frame, the z-axis is
perpendicular to the body of the device, with its origin at the center of gravity
and directed toward the bottom of the device.
Rotation and relative translation, i.e., R and t, describe the relative motion
of the smartphone body to the initial reference.
For one POI xn
i in the navigation coordinate, its relative position in the
body coordinate can be written as
xb
i = Rb
nxn
i + t
(6.4)
(6.4) relates the conversion between b-frame and the real physical world, i.e.,
n-frame.
6.3.2
Displacement Estimation
To estimate the relative translation (t) of the smartphone, we could utilize
the Accelerometer on board by measuring its acceleration force, and infer the
displacement by double integrating the acceleration. The quantity result from
the Accelerometer is the acceleration rate in m/s2, and can be denoted as
f b
t = (f bx
t , f by
t , f bz
t )T , where f bx,y,z
t
is the measured force in 3-axis directions
in the body frame.

110
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
5
10
15
20
25
30
−4
−2
0
2
4
6
8
Time (s)
Acceleration (m/s2)
 
 
ax
ay
(a) Acceleration
5
10
15
20
25
30
−1
0
1
2
3
Time (s)
Velocity (m/s)
 
 
vx
vy
(b) Velocity
5
10
15
20
25
30
0
5
10
15
20
25
30
Time (s)
Displacement (m)
 
 
x−North
y−East
(c) Displacement
Figure 6.2: Motion estimation result via conventional method: (a) accel-
eration, (b) velocity, (c) displacement.
Direct integrating f b
t obtains the displacement in the body coordinate,
which is not related to the real geodesic displacement. To convert the ob-
tained acceleration of the smartphone to the local navigation coordinate, we
could apply rotation and translation over f b
t by
f n
t = Rn
b f b
t + en
(6.5)
where en is the error of the force that is applied to the smartphone. To obtain
the acceleration caused by the applied forces, gravity should be subtracted
by an
t = f n
t −g, where g = [0, 0, g] is the gravity vector. The measured
acceleration result after gravity subtraction is shown in Fig. 6.2(a).
After the denoising process, the velocity of the smartphone can be obtained
by vn
t = vn
0 +
R t
0 an
t as shown in Fig. 6.2(b). From Fig. 6.2(b), we know that
the velocity is drift even when the user is stationary.
The displacement can be calculated by sn
t = sn
0 +
R t
0 vn
t , where vn
0 , and sn
0
are the initial velocity and displacement. The result of estimated displacement
in the x and y directions is shown in Fig. 6.2(b) with large drift.
The process of obtaining relative displacement sn
t is contributed by double
integration, in which the measurement noise, i.e.,
R R
en, is also integrated and
ampliﬁed. The white noise in acceleration measurements is integrated twice
and causes a second-order random walk in displacement of the smartphone.
As a result, bias errors cause errors in position that grow proportional to t2.
The error of the accelerometer measurement can be modeled as
˙δ = −1
Ta
δ + wa
(6.6)
where Ta is the correlation time of the accelerometer. The value of the Ta
diﬀers from diﬀerent devices, and needs to be estimated prior to calibration.
wa is the modeled Gaussian white noise.

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
111
6.3.3
Mitigating Displacement Estimation Error
6.3.3.1
Apply Constraint via Activity Results
One signiﬁcant problem of using integration is that the estimated displacement
is drifting even when the smartphone is stationary. As shown in Fig. 6.2,
the estimated velocity and displacement from the noisy acceleration contains
signiﬁcant bias and drift.
Performing activity detection before integration, and using the estimation
results as a constraint, could be feasible approaches to calibrating the drift.
To estimate the smartphone’s activity before direct integration, we
could perform decision-based detection for the acceleration data with multi-
hypothesis tests, where the activity level H0 means stationary, and H1 to Hj
means diﬀerent activity levels (j = 1, . . . , J). The activity detection process
can be modeled so as to detect the Hj level from the noisy measurements.
Since each individual sample of acceleration an
t can be modeled as a Gaus-
sian random variable with the noise component as ng
t , the ﬁrst moment of
an
t when the smartphone is stationary (H0 condition) can be written as
E(an
t ; H0) = εb. We use the mean absolute value of |an
t | as the decision vector,
which has a folded normal distribution.
The probability that the sample crosses the threshold ˆηact when the smart-
phone is stationary (H0 condition) is the false alarm rate P j
fa (j = 0). Using
the Neyman-Pearson criterion, we set a constant value of P j
fa and perform
CFAR detection. The CFAR threshold can be determined by
ˆηj
act =
p
π/2E(zi; Hj)Q−1(P j
fa/2)
(6.7)
For other activity levels, we need to set diﬀerent P j
fa. One key component in
CFAR detection is the value of E(zi; Hj), i.e., the estimated ground truth.
We know that the adjacent samples from the accelerometer have strong cor-
relation, and E(zi; Hj) could not obtain an accurate value without suﬃcient
sampling points. Here we construct two detection-aided windows to estimate
E(zi; Hj), i.e., the forward window (wf) and backward window (wb). The
adaptive threshold could be obtained by estimating the future and history
trends via wf and wb. The decision process could be realized by comparing
the adaptive threshold to the cell under test. We call it adaptive-threshold
based activity detection (ATAD).
Using the detected activity level Hj, we could map each activity level to
one weighting coeﬃcient wj. During the integration process of displacement
calculation, we could apply wj for the acceleration value an
t . This process
could minimize the error during integration, and obtain signiﬁcantly better
accuracy. For example, if the smartphone is kept stationary, we need to force
the velocity component to zero instead of performing integration of the noisy
acceleration measurements. For diﬀerent activity levels, applying diﬀerent wj
could be very eﬀective in drift reduction.

112
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
6.3.3.2
Gaussian Derivative Decomposition
After using ATAD and denoising, the moving trace could become signiﬁcantly
better than direct integration. However, inaccurate traces still exist due to the
imperfect denoising or thresholding, especially for small movements.
Performing moving pattern extraction before integration could be a feasible
way. The normal movement model could not be applied for estimating the
human’s moving, e.g., we cannot walk at constant velocity (CV) or constant
acceleration (CA) like a vehicle or a plane. Human walking or movement has its
own pattern, and we need to “accelerate” and “decelerate,” then “accelerate”
for another footstep. Here we use the “start-moving-stop” movement model.
Performing “start-moving-stop” pattern decomposition could help us esti-
mate the displacement in a more meaningful way. Using start, acceleration, de-
celeration, and stop as one basic step, the velocity changes (from zero to top to
zero) can be modeled as a Gaussian shape gv(µ, σ) = ± exp{−(x−µ)2/(2σ2)},
where + means moving forward; −means backward. The acceleration is the
derivative of the velocity, i.e., ga(µ, σ) = ±(x −µ)/σ2 exp{−(x −µ)2/(2σ2)}.
Using ga(µ, σ) as the kernel function, we can decompose the acceleration mea-
surement an
t into a series of ηga(µ, σ) with diﬀerent parameters η, µ, and σ.
Then the decomposed series of acceleration is Pn
i=1 ηiga(µi, σi), ηi is the am-
plitude of each Gaussian derivative pulse. The ﬁtting process can be modeled
as
{ηi, µi, σi} =
min
{ηi,µi,σi} ||an
t −ηiga(µi, σi)||
(6.8)
To reduce the number of parameters during the ﬁtting process, we extract the
feature points of an
t , e.g., peak position and width, by thresholding the peak
maximum and rising edge. Then we use the number of peaks found and the
peak positions and widths to ﬁt the speciﬁed peak model. This combination
yields better and faster computation, and deals with overlapped peaks as well.
During the decomposition and ﬁtting process, the sign of ηi is determined by
comparing the remaining error of using positive and negative results.
6.4
Absolute Location Estimation with Fewer
Anchors
For convenience, the key notations used in this section are listed in Table 6.1.
6.4.1
Background and Basic Procedures
In our previous approach [57], we designed an acoustic anchor-based indoor
localization system from scratch with centimeter-level accuracy. However, the
trilateration process needs at least three anchors for 2D location estimation.

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
113
Table 6.1: Notation
M
number of anchor nodes
am
location for the m-th anchor node (m = 1, . . . , M)
N
number of mobile phones
ˆp(k)
n
the k-th initial location for the n-th mobile phone
p(k)
n
the k-th optimized location for n-th mobile phone
ˆr(k)
n,m
the k-th RSS ranging result for n-th mobile phone
˜r(k)
n,m
the k-th TOA relative distance for the n-th phone
If the anchors are deployed at diﬀerent heights, at least four anchors need to
be accessed for proper pseudo 3D localization.
To enable location estimation with fewer anchors, we revisit several key
steps of the acoustic-based indoor localization system.
Signal Detection. The total number of anchor nodes is MA, where m is
the index with m = 1, . . . , MA. Each anchor node broadcasts its own unique
pseudocode sequence pm = [pj] with length L for the m-th anchor node
(j = 1, . . . , L). The symbol duration of the acoustic beacon is Ts, i.e., the
total time for each beacon is LTs.
Assume the sampling rate of the smartphone is Fs, and the received acous-
tic signal sample is g(k). Decode the ˆpj associated with the current symbol
(ˆpj is the estimated version of pj, with the vector term as ˆp). Performing code
matching with the pre-stored pseudocode sequence pm, we could obtain the
station id m for the j-th symbol.
Ranging. The basic process of ranging is to measure the ﬂight delay (tj)
of the ﬁrst one in all multipaths, i.e., r = vs×tj, where vs is the acoustic sound
speed. In the discrete sample domain, we estimate the sampling point of TOA
path ˆkj for the j-th symbol as a TOA value of ˆtj = ˆkj/Fs. In this process, we
associate the TOA measurement ˆkj to the m-th anchor node and l-th index
of the pseudocode pm. We also convert ˆtj into the base symbol time (j = 1)
and add it into the vector of TOA measurement km = [ˆkj −jTsFs, . . .], and
obtain ranging measurements as ˆrm = kmvs/Fs.
Due to the one-way passive ranging mode utilized for multi-user simulta-
neous access, the distance measured by TOA estimation is pseudorange, with
unknown bias δr. To solve this unknown bias, we need to synchronize all the
M anchor nodes, and make the δr ﬁxed for every node.
Localization: Deﬁne yn, xn
m as the positions of the smartphone and m-
th anchor in the n-frame. Using M pseudoranges ˆrm and the preconﬁgured
coordinates of anchor nodes xn
m, we could estimate the 3D position of the
smartphone yn by minimizing the quadric term of the remaining error
εm = ||ˆrm −(||yn −xn
m||2 + δr)||2
(6.9)
where δr is the unknown delay that compensates the diﬀerence between the

114
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
pseudorange and real distance. The unknown bias (δr) can be estimated during
the localization process with suﬃcient anchor numbers, e.g., solving a 3D
location (x, y, z) needs four equations (anchor nodes) instead of three.
6.4.2
Improving the Location Accuracy via Constraints
With the acoustic ranging results and the displacement and direction esti-
mation in Section 6.3, we could perform location optimization to the initial
location even with a single anchor.
6.4.2.1
Initial Location
The initial location of the smartphone could be accessed by using the API
provided by the mobile operating system. The obtained initial location is in
geodetic coordinates (latitude φ, longitude λ, height h), e.g., WGS 84 datum.
To convert the geodetic coordinates to the navigation coordinate, we ﬁrst con-
vert it to the earth-centered earth-ﬁxed (ECEF) coordinate, then convert the
ECEF to the ENU frame. By subtracting the reference point OR, the GPS
location is mapped to the navigation coordinate (n-frame) for more intuitive
and practical analysis. Deﬁne the POI’s 3D position as xn
i = [xn
i , yn
i , zn
i ]T ,
where the superscript n denotes the position value in the navigation coordi-
nate; i denotes the i-th POI in M POIs (i = 0, M −1). The current location
of the smartphone is deﬁned as pn = [xn, yn, zn]T .
6.4.2.2
Measurements
Assume the position coordinate of the anchor node is am ∈Rd, where m
is the index of total M anchor nodes. For 2-D coordinate (d = 2), am is
[xm, ym]T , m = 1, . . . , M. Denote the location coordinate of the n-th user as
pn, n = 1, . . . , N.
To reﬁne the user’s location, ranging information is utilized as a constraint.
Assume the initial position coordinate of a user obtained by smartphone is ˆpn,
which is direct from location API and low-accurate compared to the location
of anchor nodes (am). Deﬁning the RSS ranging measurement between the
user and anchor pair is ˆrn,m; the estimated relative TOA distance is ˜rn,m.
The real distance rn,m from the n-th mobile phone to the m-th anchor node is
written as rn,m = ||pn −am||2, where || · ||2 calculates the 2-norm and obtains
the Euclidean distance. The vector form of the RSS ranging observation from
m-th anchor to n-th mobile phone can be written as
ˆrn,m = ||pn −am||2 + ˆnn,m
(6.10)
where ˆnn,m is the measurement noise; m = 1, · · · , N B. Then, the TOA dis-
tance measurement from m-th anchor to n-th mobile phone is
˜rn,m = ||pn −am||2 + δn,m + nn,m
(6.11)

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
115
where nn,m is the TOA measurement noise, which is lower than ˆnn,m in (6.10).
m = 1, · · · , N A, where N A ≤N B. δn,m is the unknown bias between the m-th
anchor and n-th mobile phone pair due to the unsynchronized clock. Thus,
TOA result (6.11) is the relative distance measured between the smartphone
and anchor.
Figure 6.3: Location estimation via single anchor.
Fig. 6.4(a) and Fig. 6.4(b) show the TOA ranging results when the user
is moving away (from 1.5 to 17 meters) and moving close to the anchor,
respectively. The unit of the coordinate in Fig. 6.4(a) is the sampling point
(bin) of the distance and time, respectively. When the user is standing still,
the slope of ˜rn,m can be approximated as the clock drift between the mobile
phone and anchor node. When the user is moving away, the slope of ˜rn,m in
Fig. 6.4(a) shows increased distance trend, while Fig. 6.4(b) shows decreased
trend. The slightly increased ranging variance when the user is far away from
the anchor is caused by the signal attenuation and distortion.
The obtained displacement could be another measurement that contributes
to the location optimization. For k and k +1 measurements, the displacement
can be written as
sk,k−1
n
= ||p(k)
n
−p(k−1)
n
||2 + ns
(6.12)
The direction of the motion trace obtained from the attitude value is as-
sumed as αn as shown in Fig. 6.3. With the RSS ranging results and TOA
relative ranging results from the anchor to the smartphone, the anchor-related

116
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
200
400
600
800
1000
1200
7500
8000
8500
9000
Time (bin)
Distance (bin)
Moving
Far, Stationary
Near, Stationary
(a) Moving Away
0
200
400
600
800
1000
6000
6200
6400
6600
6800
Time (bin)
Distance (bin)
Far, Stationary
Near, Stationary
Moving
(b) Moving Close
Figure 6.4: TOA ranging results in two diﬀerent situations: (a) user is
moving away from the anchor; (b) user is moving close to the anchor (bin
is the sampling points).
measurement could be written as
ˆrk−1
n,m cos(θn,m) −ˆrk
n,m cos(θn,m + βn,m)
(6.13)
= sk,k−1
n
sin(αn) + nA
where the angle βn,m could be calculated by the law of cosines. The geometric
relation is shown in Fig. 6.3. θn,m can be estimated by the location diﬀerence
of pn = [px, py] and am = [ax, ay], with its x and y coordinates related by
px = ax + ˆrk−1
n,m sin(θn,m) and py = ay −ˆrk−1
n,m cos(θn,m).
6.4.2.3
Location Optimization
Thus, the location optimization problem when the anchor node number is
insuﬃcient for trilateration can be deﬁned by using (6.10), (6.11), (6.12), and
(6.13) to obtain a reﬁned result of pn.
For the k-th iteration, the position reﬁnement process is achieved by min-
imizing the error term of adjacent measurements p(k)
n,m and p(k−1)
n,m
for all the
received anchor nodes as
p(k)
n
:= arg min
p(k)
n ∈R
X
m∈ξM
e

p(k)
n , p(k−1)
n

(6.14)
where ξM is the set of all the received anchor nodes; when there is only one
anchor node in the coverage area, then m = 1. The error term e(p(k)
n , p(k−1)
n
)
illustrates the residual error between the measured distance and the calcu-
lated distance of the position coordinates (anchor and mobile phone). The
introduced term p(k−1)
n
is to improve accuracy by leveraging the highly accu-
rate relative TOA measurements and estimated moving direction. By reﬁning

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
117
the search region of pk
n within the region R, some local optima values that are
outside the real region could be avoided. Such reﬁnement could signiﬁcantly
minimize large errors caused by insuﬃcient and inaccurate measurements.
Considering all the available measurements, the error constraints between
the current and previous (k −1)-th term e(p(k)
n , p(k−1)
n
) can be written as
e(p(k)
n , p(k−1)
n
) = (γ1eS + γ2eD + γ3eM + γ4eA)
(6.15)
where eS and eD means the remaining error term of the RSS and relative
TOA in (6.10) and (6.11). eM and eA are the remaining errors of (6.12) and
(6.13), respectively. γ1, γ2, γ3, and γ4 are weighting coeﬃcients that control
the contribution of diﬀerent measurements.
Performing the gradient operation ∇to the error residues e(p(k)
n,m, p(k−1)
n,m )
with respect to the anchor node m, the reﬁned position can be updated via
the steepest descent approach by
p(k)
n
: = ˆp(k)
n
+ α∇
X
m∈ξM
(γ1eS + γ2eD + γ3eM + γ4eA)
(6.16)
where α ∈(0, 1] is the update step size to control the convergence rate; ξM is
the total received anchor nodes, where the number is insuﬃcient for trilater-
ation.
Substituting measurements into (6.16), p(k)
n
can be optimized and updated
by leveraging the RSS and TOA ranging measurements. (6.16) starts with the
initial coarse-grained location result ˆp(k)
n , and optimizes the location result by
substituting the initial value of p(k)
n
with ˆp(k)
n .
6.5
Trilateration
via
Semideﬁnite
Program-
ming
When there are suﬃcient TOA measurements for trilateration calculation, a
ﬁne-grained location result could be obtained by leveraging the TOA mea-
surements from multiple anchors.
To prevent the location estimation algorithm from converging to the lo-
cal optimality, the concept of relaxation onto convex sets has been proposed
[68]. Without the requirement of performing inverse operation on the Jaco-
bian matrix in LS-based approaches, the SDP-based approach achieves better
computational eﬃciency by leveraging existing SDP packages, which is espe-
cially important when the Jacobian matrix in the LS problem is badly scaled
or close to singular. In this section, we propose an optimized real-time SDP
algorithm in mobile phone location estimation. The proposed algorithm is ro-
bust in the presence of outliers by leveraging the delay-constraint and Huber
M-estimator [102].

118
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
6.5.1
Min-Max Criterion
The location estimation process is a nonconvex optimization problem, while
the semideﬁnite programming (SDP) technique can be used to relax the initial
nonconvex problem into convex one. Among existing relaxation criteria, min-
max approximation and semideﬁnite relaxation can ﬁnd the global minimum
value without the “inside convex hull” requirement [68]. To utilize the SDP
relaxation, we modify the problem formulation by rewriting (6.9) into ˆr−δr =
||p −am||2 + n. Performing square operations on both sides leads to
(ˆr −δr)T Σ−1(ˆr −δr) = (||p −am||2 + n)2
(6.17)
where the right side of (6.17) is ||p−am||2
2+2nT ||p−am||2+nT n. By adopting
the min-max criterion [68, 98], (6.17) can be formulated as
p = arg min
p
max
m=1,...,M
||p −am||2
2 −(ˆr −δr)T Σ−1(ˆr −δr)

|
{z
}
ξ
(6.18)
where the term ξ can be viewed as the residual error. (6.18) calculates y, which
corresponds to the minimum value of the maximum residual error. Compared
with (6.9), (6.18) remains nonconvex, but it is comfortable for the following
semideﬁnite relaxations.
The ﬁrst term in ξ can be written into a matrix form of
||p −am||2
2 =

pT
1
  Id
−am
−aT
m
aT
mam
  p
1

(6.19)
= trace
 p
1
 
yT
1
  Id
−am
−aT
m
aT
mam

= trace
 P
p
pT
1
  Id
−am
−xT
m
aT
mam

where P = ppT , trace{·} calculates the trace of the matrix, and Id is an
identity matrix of order d. Following the same process as in (6.19), the second
term in ξ can be written into
(ˆr −δr)T Σ−1(ˆr −δr)
(6.20)
= trace
 δ
δr
δT
r
1
  Σ−1Id
−Σ−1ˆr
−ˆrT Σ−1
ˆrT Σ−1ˆr

where δ = δrδT
r .
6.5.2
Delay-Constraint Robust Semideﬁnite Program-
ming
From (6.9), we know that the unknown parameter δr incorporates the un-
known clock drift. The trend of δr is known as a line (the stationary region in

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
119
Fig. 6.4) and the future value can be directly estimated, e.g., by linear ﬁtting.
Using such prior information, the location estimation accuracy can be further
improved by substituting this pre-estimated delay δr as a constraint; we call
this approach the delay constraint (DC).
The objective function of ξ can be converted to minimize ϵ at the constraint
of an inequality expression −ϵ < ξ < ϵ, while ξ can be written in the form of
(6.19) and (6.20). However, the outliers could not be ignored during location
estimation. One possible solution is to apply a penalty function to the residual
error rather than only using the quartic term (l2-norm) in (6.9). Speciﬁcally,
we still apply l2-norm on any residual smaller than a preset threshold σth,
but put a linear weight (reverts to l1-like linear growth) on any residual larger
than σth. Using l1-norm for large errors would lower the weight for outliers
and improve the robustness. We choose Huber function θhub(ε) as the penalty
function [11]. This penalty function can be considered as a convex approxi-
mation of other outlier penalty functions. The constraints form of (6.19) and
(6.20) are convex, but the equality constraints of P = ppT and δ = δrδT
r are
nonconvex. Using semideﬁnite relaxation, these two equalities can be relaxed
to inequality constraints of P ⪰ppT and δ ⪰δrδT
r , respectively. The matrix
form of these two equalities is
 P
p
pT
1

⪰0,
 δ
δr
δT
r
1

⪰0
(6.21)
where ⪰means a positive deﬁnite (semideﬁnite) matrix, which is diﬀerent
from ≥.
Accordingly, the initial localization problem can be relaxed to a semideﬁ-
nite programming form as
min{p,P,δr,δ} θhub(ϵ)
s.t.
−θhub(ϵ) < trace
 P
p
pT
1
  Id
−am
−aT
m
aT
mam

−
trace
 δ
δr
δT
r
1
  Σ−1Id
−Σ−1ˆr
−ˆrT Σ−1
ˆrT Σ−1ˆr

< θhub(ϵ),
m = 1, . . . , M,
 P
p
pT
1

⪰0,
 δ
δr
δT
r
1

⪰0
ˆδr(1 −α) < δr < ˆδr(1 + α)
where ˆδr is the estimated delay value based on historical data of δr; α is pre-
deﬁned and used to relax the delay-constraint (DC). The n-th mobile phone
position p can be extracted from the optimal solution of {p, P, δr, δ}. This
delay-constraint robust SDP problem can be solved by some standard con-
vex optimization packages, e.g., SeDuMi and CVX package [28]. By using the
steepest descent approach in (6.16), the estimation error can be further re-
duced by performing a local search above the global optimized value obtained
by SDP.

120
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
6.5.3
Improving Indoor Localization via Sensor Fusion
Compared with INS measurement, the localization result from acoustic an-
chors is an absolute result and does not drift over time. However, the result
is only available under suﬃcient anchor coverage, and suﬀers from sound in-
terference and blockage in normal environments.
Based on the distinct features of INS and acoustic-based localization, we
propose a sensor fusion approach, and demonstrate that the error during es-
timation could be signiﬁcantly minimized.
To fuse the INS sensor with the indoor absolute location estimator (ALE),
we can write all the measurements into one state-space model, and utilize the
model in Kalman ﬁlter for the fusion process. The position estimation result
from the INS sensor is sn
t , the second-order moving model can be written as
sn
t+1 = sn
t + ˙sn
t Tins + ¨sn
t
T 2
ins
2
(6.22)
˙sn
t+1 = ˙sn
t + ¨sn
t Tins
where ˙sn
t and ¨sn
t are the moving velocity and acceleration, which are derived
from the obtained displacement; Tins is the sampling time of the INS. Its rela-
tionship with the gyros and accelerometer measurements can be summarized
as
¨sn
t = Rn
b,t(f b
t −εb −εrwg) −g
(6.23)
where Rn
b,t denotes the rotation matrix from the body coordinate to the navi-
gation coordinate. Assuming the output of the gyros is ˆωb
t, the update function
is
ωb
t = ˆωb
t −δ −wa
(6.24)
From (6.22), (6.23), and (6.24), we can summarize the state vector as
XI(t) = [θb
t , vn
t , sn
t , εb, εr, δ]
(6.25)
where θb
t is the rotation angle obtained from the gyros; vn
t is the velocity from
accelerometer; sn
t is the location of the smartphone; εb, εr are the bias and
drift of the gyros; δ is the drift of the accelerometer in (6.6).
The location estimation of the smartphone is pn. Thus, the observation
function can be written as Z(t) = pn. Specially, the Kalman fusion process
can be viewed as using the measurement from acoustic localization module
(ALE) to calibrate the INS results.
The Kalman ﬁlter handles the diﬀerent sample rates from INS and ALE
by running at a high data rate (same as INS) and only updates when mea-
sures from ALE are available. After the fusion process, the update rate of the
localization module has been improved to the same level as the INS sensor,
while the bias problem of the INS is calibrated.

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
121
6.6
Experiment
6.6.1
System Evaluation
To quickly deploy the developed algorithm, we designed a back-end server for
processing complex algorithms without worrying about the limited resources
on a mobile platform. A Redis server [92] is used as a cloud key-value store for
the smartphone; A Java server performs computation for the structural data in
the Redis server. The smartphone performs sensing and estimation of the raw
data, with result data (small size) uploaded to the server for complex algorithm
processing. This approach balances computation and network consumption in
a smartphone, and the introduced delay is less than 100ms, which is ignorable
for the sub-second level location update rate.
Besides the implementation in a smartphone, we designed the acoustic an-
chor node for indoor localization purposes. The maximum operation distance
for one anchor node is nearly 20 meters. In the following system evaluation,
we deployed 8 anchor nodes in one large exhibition room of our campus Art
Museum as shown in Fig. 6.5. Enriching visiting experience in a museum is
one of the promising applications of indoor localization.
Figure 6.5: Anchor deployment and experiment environment.
6.6.2
Displacement Estimation
To evaluate the drift reduction performance of our proposed INS displacement
estimation algorithm, we will compare our proposed approaches, i.e., denois-
ing (DN), adaptive threshold activity detection (ATAD), and Gaussian deriva-
tive decomposition (GDD). The performance metrics includes total drift, drift
speed (drift per second), and drift rate (drift per meter).

122
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Drift Reduction. After applying the denoising, ATAD, and GDD ap-
proaches for the results in Fig. 6.2, we could obtain better acceleration, ve-
locity, and displacement results, as shown in Fig. 6.6. The ground truth of
the moving path is like a rectangle, where the starting point and ending point
are overlapped. The velocity is calibrated as a Gaussian pulse; the drift of
the estimated displacement is signiﬁcantly reduced (the starting point and
end point show the same location value). With the x and y estimated to-
gether, the moving direction of the user in the 2-D navigation coordinate is
also known.
5
10
15
20
25
30
−3
−2
−1
0
1
2
3
Time (s)
Acceleration (m/s2)
 
 
ax
by
(a) Acceleration
5
10
15
20
25
30
−1.5
−1
−0.5
0
0.5
1
1.5
Time (s)
Velocity (m/s)
 
 
vx
vy
(b) Velocity
5
10
15
20
25
30
−1.5
−1
−0.5
0
0.5
1
Time (s)
Displacement (m)
 
 
x−North
y−East
(c) Displacement
Figure 6.6: Motion estimation result via proposed method: (a) accelera-
tion, (b) velocity, (c) displacement.
Drift Metrics and Experiments. To reduce the randomness in perfor-
mance evaluation, we tested more than 150 cases. The average and median
value of all the metrics are shown in Table 6.2. Our proposed GDD approach
achieves best performance in all metrics. The drift rate of 5.5cm per meter is
signiﬁcantly better than existing approaches.
6.6.3
Ranging Estimation
Utilizing TOA for ranging, we deﬁne a metric ranging rate (αr) to evaluate
the TOA miss-detection probability. To evaluate the false-detection, we use
two metrics: ranging error rate and ranging accuracy. The rationale of using
two metrics instead of a single accuracy is that our approaches could detect
and mitigate error measurement automatically. The obtained ranging rate and
ranging error rate are shown in Fig. 6.7. We observe that our proposed ranging
scheme works well within 19.5m, i.e., with no apparent decline of the ranging
rate and ranging error rate. The ranging accuracy in Fig. 6.8 also shows the
maximum operation distance for our proposed scheme is around 15 ∼20m.

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
123
0
5
10
15
20
25
0
0.2
0.4
0.6
0.8
Distance (m)
Ranging Rate
 
 
no SI
SI
(a) Ranging Rate
0
5
10
15
20
25
0
0.2
0.4
0.6
0.8
1
Distance (m)
Ranging Error Rate
 
 
no SI
SI
(b) Ranging Error Rate
Figure 6.7: Ranging rate and ranging error rate in an aisle environment.
Table 6.2: Performance comparison with respect to diﬀerent methods
under speciﬁc metrics
Methods
Metrics
Average
Median
Basic
Total Drift (m)
16.51
12.47
Drift Speed (m/s)
0.47
0.40
Drift Rate (m/m)
3.92
3.73
ATAD
Total Drift (m)
1.26
1.02
Drift Speed (m/s)
0.04
0.04
Drift Rate (m/m)
0.31
0.26
DN+ATAD
Total Drift (m)
0.72
0.55
Drift Speed (m/s)
0.023
0.013
Drift Rate (m/m)
0.18
0.15
DN+ATAD+GDD
Total Drift (m)
0.23
0.14
Drift Speed (m/s)
0.006
0.0045
Drift Rate (m/m)
0.055
0.043
6.6.4
Improving Location Accuracy with Fewer An-
chors
To evaluate the performance improvement of our proposed algorithm when
the anchor nodes are insuﬃcient for trilateration, we conducted experiments
using Apple iPhone4S in both outdoor and indoor environments. We utilized
the default location management module in iOS (mainly from GPS) to obtain
the initial location results without war-driving. A total of 7 diﬀerent position
spots are utilized to quantify the performance improvement. The ground truth
of these 7 stationary position spots is aligned in a line with the step length
of 4m. The coordinates of these spots are pn = [4 × n, 0]T , n = 1, · · · , 7.

124
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
(a) Case 1
(b) Case 2
Figure 6.8: Ranging accuracy.
1
2
3
4
5
6
7
0
5
10
15
20
Position Spots
Location Error(m)
 
 
initial
m=1,Static
m=2,Static
m=2,Dynamic
(a) Outdoor Results
1
2
3
4
5
6
7
0
10
20
30
40
Position Spots
Location Error(m)
 
 
initial
m=1,Static
m=2,Static
m=2,Dynamic
(b) Indoor Results
Figure 6.9: The location error when the anchor number is m = 0 ∼2 in
(a) outdoor and (b) indoor environments.
The ﬁrst anchor is placed at a1 = [0, 0]T ; the coordinate of the second anchor
is a2 = [19, 15]T . The size of the area is around 30 × 35 meters. The initial
location update rate obtained by smartphone location API is around 1 second.
By applying (6.16) for all these 9 position spots, the performance improvement
is shown in Fig. 6.9(a) and Fig. 6.9(b) for outdoor and indoor environments,
respectively. When the anchor number is m = 1, 2, our proposed approach
could improve the location accuracy signiﬁcantly, especially for the indoor
cases with larger initial location errors. Applying the dynamic part of (6.16) by
leveraging the relative TOA distance measurement and moving direction, the
performance could even be improved as shown in the case of “m=2, Dynamic.”

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
125
From Fig. 6.9, we know that the accuracy improvement ranges from 2 to 11
times over the initial results.
6.6.5
Trilateration via Semideﬁnite Programming
To evaluate and compare the performance of diﬀerent localization algorithms
when the anchor number is suﬃcient for trilateration, we deployed the an-
chor network in a typical oﬃce environment with a total of 6 anchors. This
environment is polluted with voice sound and other acoustic interference.
Performance Comparison. The algorithms compared are: “LS-Classic”
[74], “LS-PR” [57], “SDP-PR” [9], “SDP-PR-DC,” and “SDP-PR-DCR.”
Fig. 6.10(a) and Fig. 6.10(b) show the CDF of the position error when the
mobile phone is placed near [5.13, 1.08]m and [5.5, 1.4]m, respectively. The
SDP-based approaches perform better than the LS-based approaches in these
two cases. By performing delay-constraint (DC) and the robust (R) approach
(using Huber Estimator) during the SDP optimization, “SDP-PR-DCR” out-
performs other approaches in most situations with diﬀerent performance gains.
0.1
0.2
0.3
0.4
0.5
0.6
0
0.2
0.4
0.6
0.8
RMSE (m)
CDF
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−LS
SDP−PR−SD
LS−Classic
LS−PR
SDP−PR
SDP−PR−SD
SDP−PR−LS
(a) (5.13, 1.08)
0
0.2
0.4
0.6
0.8
0.2
0.4
0.6
0.8
1
RMSE (m)
CDF
 
 
LS−Classic
LS−PR
SDP−PR
SDP−PR−DC
SDP−PR−DCR
LS−Classic
LS−PR
SDP−PR
SDP−PR−DCR
SDP−PR−DC
(b) (5.5, 1.4)
Figure 6.10: Cumulative distribution of diﬀerent algorithms when the
mobile phone is in: (a) [5.13, 1.08] and (b) [5.5, 1.4] by using experimental
data with 6 anchors.
6.6.6
Location Fusion
Ranging and Localization Results Fig. 6.11(a) shows the ranging accu-
racy (cm) of smartphones from diﬀerent anchor nodes (a total of 8 nodes) in
50%, 80%, and 95% percentile probability. For the 8 group bars, the left bar
is the result of initial acoustic localization, while the right bar shows our im-

126
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
proved result using Attitude and Displacement (AD) for ranging and location
tracking. From the ranging error, we show signiﬁcant reduction in all cases
under diﬀerent probability. Fig. 6.11(b) shows CDF results of the position
error without AD. The achieved improvement is more than three times that
of the initial result. The smartphone localization accuracy is near 2.7cm with
80% probability.
1
2
3
4
5
6
7
8
0
5
10
15
Anchor Nodes
Ranging Error (cm)
 
 
Initial, 50%
Initial, 80%
Initial, 95%
AD, 50%
AD, 80%
AD, 95%
Initial
Initial
AD
AD
(a) Ranging Error
0
10
20
30
40
50
0
0.2
0.4
0.6
0.8
1
Error (cm)
CDF
 
 
Initial
AD
2.7cm
10cm
(b) Localization Error
Figure 6.11: (a) Ranging results; (b) localization results.
Kalman Fusion Experiment. Fig. 6.12(a) shows the estimated displace-
ment from INS results, the obtained smartphone location via acoustic anchors,
and the Kalman fusion results. As expected, the INS result has a very high
update rate, but the displacement result in unknown bias to the true loca-
tion. The location result via acoustic anchors (ALE) is unbiased to the ground
truth, but suﬀers from measurement noise and outliers. After Kalman fusion,
the achieved results contain no bias and show better variance in accuracy.
Moreover, the fusion results show the same update rate as INS results, which
is signiﬁcantly higher than for ALE. Thus, the fusion process could improve
the accuracy and update rate simultaneously. To test the robustness of the
fusion process, we utilize the INS result with strong bias and drift as shown
in Fig. 6.12(b). The fusion result is still satisfactory, with higher update rate
and no bias to the true location.
6.7
Related Work
Localization without anchor nodes: Low complexity localization tech-
niques are more convenient and popular since they do not rely on the deploy-

Enhancing Location Accuracy and Robustness via Opportunistic Sensing
■
127
0
1
2
3
4
5
6
−1
−0.5
0
0.5
1
1.5
2
x−East (m)
y−South (m)
 
 
INS
ALE
After Fusion
(a) Case 1
−2
0
2
4
6
8
−0.5
0
0.5
1
1.5
2
x−East (m)
y−South (m)
 
 
INS
ALE
After Fusion
(b) Case 2
Figure 6.12: The Kalman fusion results for location estimation in two
cases.
ment of additional anchor nodes, e.g., inertial sensor (INS)-based approaches
[18, 129], ﬁngerprinting-based approaches [8, 132, 15, 6], and radio signal
strength (RSS)-based ranging approaches [20, 44, 50].
Solutions based on pervasive WiFi systems have remained the most pop-
ular theme of indoor localization without anchor node deployment, but come
at the cost of accuracy and need meticulous war-driving. Recent approaches
trying to eliminate the war-driving via crowdsourcing or other techniques are
proposed in [19, 89, 129], but still suﬀer low accuracy and lack of clear incen-
tive for crowdsourcing.
Another important issue of a WiFi-based localization system lies in its high
energy consumption and long delay. Experiments show that WiFi scanning is
very high cost both in time and energy, e.g., Liu et al. [52] show more than
4.5s delay for only 5 WiFi samples. Apple has even banned WiFi RSS scanner
apps in its App Store since 2010.
Localization
via
anchor
nodes:
Conventional
highly
accurate
infrastructure-based localization systems rely on dense anchor nodes for trilat-
eration computations, and require special devices on the user side for ranging
purposes, e.g., ultrasound [85, 10], UWB devices [54]. The inconvenience intro-
duced by requiring additional hardware makes these approaches impractical,
at least in the near future.
Recent approaches relying on the high-band of the microphone sensor in-
troduces a convenient approach for trilateration without additional hardware
attachment on a user’s smartphone [81, 74, 48, 57]. Liu et al. [57] utilized low-
complexity anchor nodes for broadcasting unnoticeable acoustic beacon with
high accuracy. However, at least three anchor nodes are needed for one loca-
tion calculation with 2-D coordinates, and more nodes are needed for covering
large areas, which inhibits wide deployment.

128
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Localization via hybrid approaches: Leveraging multiple sensors in a
mobile phone and optimizing the location accuracy via moving traces with-
out anchor nodes are proposed in [18, 129]. However, the moving traces ob-
tained by accelerometer and compass are inaccurate and highly dependent
on the prior information of the foot-step length. Authors [52, 55] proposed
a localization optimization approach via peer-to-peer ranging. However, the
two-way ranging process among all user-pairs is too time-consuming and in-
convenient. Rajalakshmi et al. [74] proposed systems named EchoBeep and
DeafBeep that fuse RF and acoustic-based techniques into a single framework.
However, all these scenarios are based on ﬁxed desktops without any mobility
considerations and are not direct applicable to smartphones. Moreover, the
requirement on the two-way ranging for EchoBeep and the triangular ranging
for DeafBeep would limit the user numbers (they only support one user) and
introduce complex ranging protocol and long delay, which is impractical in a
smartphone-based mobile system. SAIL [65] combines physical layer (PHY)
information and human motion for indoor localization using a single Wi-Fi
AP. However, the required Wi-Fi AP with PHY information is not ubiquitous,
and the achieved accuracy is only at the meter level.
Proximity detection without localization: Relying on the proximity
detection, one anchor node can provide location references to the user whose
accuracy depends on the density of the anchor deployment. The RFID network
and the recently introduced BLE network, e.g., Apple’s iBeacon [5] and Qual-
comm’s Gimbal proximity beacons [86], and Estimote [24], are examples of
using proximity detection approaches. However, proximity-based approaches
are simple but inaccurate; purely relying on the anchor density to improve
accuracy is not an eﬃcient and economic method.
6.8
Conclusion
We proposed location optimization approaches in a mobile phone via op-
portunistic anchor sensing. Using the obtained coarse-grained absolute and
ﬁne-grained relative ranging information from accessible anchors, the loca-
tion accuracy achieved signiﬁcant improvement even with only one or two
anchors. When suﬃcient anchors are available for trilateration, we proposed
delay-constraint robust semideﬁnite programming to ensure robustness in the
presence of ranging outliers. The achieved results show 2 to 11 times greater
performance with limited anchors and sub-second delay for supporting unlim-
ited users, plus they achieve 80 percentile accuracy of 8cm with suﬃcient an-
chors. The ﬂexibility and accuracy of the proposed approaches provide strong
incentives for service operators to deploy this low-complexity system with
various location resolution demands.

Chapter 7
Pushing Location
Awareness to
Context-Aware Augmented
Reality
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
7.1
Introduction ......................................................
130
7.2
System Design ....................................................
132
7.2.1
Application Overview ....................................
132
7.2.2
System Model and Terminology Deﬁnition .............
132
7.3
Attitude and Location Trace Estimation ........................
135
7.3.1
Attitude Estimation .....................................
136
7.3.1.1
State-of-the-Art Approaches ...............
136
7.3.1.2
Attitude Error Reduction ..................
137
7.3.2
Displacement Estimation ................................
139
7.3.2.1
Challenges ..................................
139
7.3.2.2
Existing Approaches .......................
140
129

130
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
7.3.2.3
Mitigating Displacement Error ............
141
7.3.3
Smartphone Localization ................................
143
7.4
Projecting and Tracking the AR View ...........................
145
7.4.1
POI Detection and Relative Pose Estimation ...........
145
7.4.1.1
POI Detection via Image Feature
Detection and Matching ...................
145
7.4.1.2
Initial Relative Pose Estimation ...........
145
7.4.1.3
Homography Relation ......................
146
7.4.2
Mapping the POI to the Screen .........................
147
7.4.3
Projecting the AR View .................................
148
7.4.4
AR View Tracking .......................................
148
7.4.4.1
Problems ...................................
148
7.4.4.2
Vision Tracking and Adaptive Rate
Control .....................................
149
7.5
Evaluation ........................................................
149
7.5.1
Displacement Estimation ................................
150
7.5.2
Absolute Location Estimation ...........................
152
7.5.3
Attitude Estimation .....................................
153
7.5.4
POI Image Matching and Relative Pose Estimation ....
153
7.5.5
Mapping the POI to the Screen .........................
154
7.5.6
On-Screen AR View Detection and Tracking ...........
155
7.5.7
AR View Tracking via Adaptive Frame Rate ...........
157
7.5.8
Comparison with Existing Apps
........................
158
7.6
Related Work ....................................................
160
7.7
Conclusion ........................................................
162
7.1
Introduction
Augmented Reality (AR), as a new form of connections between the virtual
and physical worlds, is emerging as an innovative way of expressing and pre-
senting information to users [7, 110]. Via estimating and displaying relevant
information of the user’s immediate surroundings in the physical world, AR
applications present highly contextualized, spatially relevant information that
enhances users’ experience of mobile lives.
Although AR has been used recently to overlay digital information, e.g.,
websites, notes, videos, or photos, directly on top of items or point-of-interests
(POIs) around us via camera view, the promise of AR is far more ambitious
and transformative. Although AR technology is very desireable for wearable
devices like Google Glass, smartphones are more practical, aﬀordable, and
pervasive. The popularity of these smart devices equipped with cameras, GPS,
WiFi, and inertial and other sensors, has lowered the hardware requirement,
making it unnecessary to build expensive special head-mounted devices from
scratch.

Pushing Location Awareness to Context-Aware Augmented Reality
■
131
Existing solutions of AR applications fall into two distinct directions: geo-
graphic or marker scale. Geographic-scale AR applications focus on location-
based services (LBS) by adding location-related information on top of the
camera view [71, 29]. They utilize GPS for location tracking, and inertial sen-
sors (INS) for attitude estimation. The marker-scale AR applications focus on
computer vision techniques, e.g., marker or non-marker based. For example,
ARToolKit displays and attaches a virtual character on the top of a marker
image [41]. However, marker-based solutions are only suitable for small-scale
problems that do not consider mobility. Non-marker based approaches allow
using a normal image template as a marker, but entail higher computational
costs and even exceed the power of current smartphones. Leveraging the cloud
infrastructure could lower the computation cost on the mobile side, but suﬀers
from high-latency in AR view tracking.
More attractive line-of-sight, median scale, or indoor AR applications are
largely missing due to several challenges: 1) High-Accuracy Location Re-
quirement: GPS with 10-meter accuracy outdoors is unable to diﬀerentiate
POIs in ﬁne-grained environments and its performance is degraded dramati-
cally in indoor environments. 2) High-Accuracy Attitude Requirement:
Compared with almost invisible remote POIs, the line-of-sight AR view is
more sensitive to the attitude estimation result. The attitude estimation error
of the camera would introduce visible drift and bias between the “rendered”
objects and the actual objects due to the short distance. 3) Displacement
Matters: The displacement of a user’s camera is ignored in outdoor AR ap-
plications, since its moving distance is far shorter than the POI distance. For
indoor AR applications with short-range POIs, the movement would have
signiﬁcant impact for the screen location of the AR view.
Using only a smartphone on the user’s side without any additional hard-
ware to realize indoor AR poses signiﬁcant challenges. In this chapter, we pro-
pose solutions to enable AR applications in a smartphone for various scales
and mobilities. We propose activity identiﬁcation, pattern decomposition, in-
teracting multiple models, and vision fusion approaches to reduce the dis-
placement and attitude estimation error, drift, and distortion. Leveraging our
previous work on high-precision smartphone indoor localization [58], we ob-
tain the absolute location of the smartphone via the deployed anchor network,
and estimate the nearby candidate POIs to minimize the POI image match-
ing complexity. We utilize the epipolar geometry of the image feature pairs to
estimate the initial relative rotation (R) and translation (t) between the POI
and the smartphone. We derive the AR view projecting process by utilizing
the intrinsic and extrinsic matrix of the smartphone camera. Computer vision
approaches are combined with INS results to improve the accuracy and sensi-
tivity of the AR view tracking under various mobility levels and POI-camera
relations. Through a suite of optimization and fusion approaches, we demon-
strate that innovative indoor augmented reality applications are emerging on
the horizon.

132
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
7.2
System Design
7.2.1
Application Overview
Figure 7.1: Overview of the proposed AR application.
A complete AR application involves localization, estimation, tracking to
AR view rendering, and even 3D visualization. The localization problem alone
is hard to solve. Instead of targeting all the existing harsh challenges directly,
we focus on solving practical AR view tracking problems via attitude, dis-
placement, and vision estimation. Leveraging the features of AR application
itself, we redesign the AR application procedure by making it feasible and still
meet the application demand.
The key procedures of our envisioned AR application are shown in Fig. 7.1.
When the user pulls out the smartphone and points the camera to the POI,
he intends to know the background information related to current context.
The software in the smartphone would initiate the location, attitude and can-
didate POIs detection process as shown in step 2 of Fig. 7.1. In step 3, a) the
smartphone performs image matching for the sensed camera view to detect
the actual POI; b) the relative position of the POI to the smartphone will be
calculated; c) the AR view will be projected near the real physical POI ac-
cording to the estimated mapping relations. To minimize the high-cost image
matching process, the displacement and attitude of the smartphone will be
tracked under various mobilities, e.g., small shaking, or large movement. In
step 4, the smartphone estimates moving displacement and performs AR view
tracking via INS and vision fusion. At the same time, we can view the world
in an additional dimension and makes the “projected” objects and the actual
objects indistinguishable to the user. More interactive applications could be
built on top of this prototype.
7.2.2
System Model and Terminology Deﬁnition
Body coordinate. The body coordinate is a local coordinate of the smart-
phone with its orientation and displacement changes when we move the smart-
phone.

Pushing Location Awareness to Context-Aware Augmented Reality
■
133
Figure 7.2: System model and coordinate system.
Navigation Coordinate. To characterize the absolute movement of the
smartphone with respect to the indoor/outdoor environment, we deﬁne the
navigation coordinate (n-frame) as a local geographic frame that we want
to navigate, e.g., stationary with respect to the indoor/outdoor map that is
presented to the user.
Points-of-Interest (POI). POIs (xn
i ) are speciﬁc location points that
someone may ﬁnd interesting and helpful, which we should present to users
in terms of a virtual layer over the camera view. We use the term POI to
refer an outdoor building, or a small painting in a museum, even a virtual
note or comment. The generating of POI could be manually input or via
crowdsourcing, and each POI will be associated with a unique ID, a location,
and other related information. The unique ID could be a random 64bit UUID;
the location could be stored in terms of geodetic coordinates (latitude and
longitude), or relative coordinate.
Smartphone Attitude. The attitude of a smartphone is the scientiﬁc
term “pose,” which means the orientation of an object with respect to an in-
ertial frame of reference or another entity (the celestial sphere, nearby objects,
etc.). The attitude or orientation of the device, i.e., smartphone or camera,
can be speciﬁed by using several diﬀerent representations, including Euler an-
gles (roll (φ), pitch (θ), yaw (ψ)), quaternions, and direction cosine matrix
(DCM), a.k.a. the rotation matrix R. All these diﬀerent representations can
be converted from each other [125].

134
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 7.3: Camera mapping system.
Euler Angles. Euler angles, i.e., roll (φ), pitch (θ), yaw (ψ), could be
used to illustrate the attitude in a more direct way. Roll, pitch, and yaw are
deﬁned in the body coordinate to quantify the smartphone attitude as shown
in Fig. 7.2. A roll (φ) is a rotation around a longitudinal axis (Y ) that passes
through the device from its top to bottom. A pitch (θ) is a rotation around a
lateral axis (X) that passes through the device from side to side. A yaw (ψ)
is a rotation around an axis (Z) that runs vertically through the device.
Rotation Matrix. Euler angles are simple and intuitive. On the other
hand, Euler angles are limited by a phenomenon called “Gimbal lock.” Due
to this reason, we use the DCM, a.k.a. the rotation matrix R, to compute
the orientation and coordinate transformation. The elements of matrix R are
the cosines of the unsigned angles between the body axes and the navigation
axes. When the attitude or other INS measurement information needs to be
converted from the body coordinate to the local navigation frame, a 3 × 3
rotation matrix Rn
b representation is used for such transformation. Converting
a vector quantity vb in the body frame to the local navigation frame vn, we
can apply vn = Rn
b vb. Assuming rigid motion, two important properties of
the rotation matrix are det R = 1 and R−1 = RT . When the rotation matrix
multiplies with a vector, the vector rotates while preserving its length. Thus,
the inverse transformation from navigation coordinate to body is given by
vb = Rb
nvn = (Rn
b )−1vn = (Rn
b )T vn.

Pushing Location Awareness to Context-Aware Augmented Reality
■
135
The relation between the direction cosine matrix (rotation matrix) and
Euler angles can be derived as
R =


cos θ cos ψ
α sin φ −cos φ sin ψ
α cos φ + sin φ sin ψ
cos θ sin ψ
β sin φ + cos φ cos ψ
β cos φ −sin φ cos ψ
−sin θ
sin φ cos θ
cos φ cos θ


(7.1)
where α = sin θ cos ψ, β = sin θ sin ψ. θ, ψ, and φ are the rotation angles
around the axis of y, z, and x, respectively.
Translation Matrix. A translation t is a function that moves every point
a constant distance in a speciﬁed direction in Euclidean geometry, a.k.a. dis-
placement. Translation can be utilized to shift the origin of one coordinate
system, i.e., x′ = x + t, where t = [x, y, z]T .
7.3
Attitude and Location Trace Estimation
One essential problem in this paper is to have ﬁne-grained and eﬃcient camera
location and moving estimation, preferably without additional hardware on
the users’ side. In this section, we utilize the inertial sensor (INS) to estimate
the relative attitude and motion of a smartphone, and propose approaches to
reduce the drift and error. To get the absolute location results, we leverage our
previous work for smartphone indoor localization and propose INS-assisted ap-
proaches to improve its dynamic performance. The overview of the algorithm
structure is illustrated in Fig. 7.4.
Figure 7.4: Moving trace and attitude estimation.

136
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 7.5: AR view projecting and tracking.
7.3.1
Attitude Estimation
7.3.1.1
State-of-the-Art Approaches
The INS, e.g., gyros, accelerometer, and magnetometer, are used for rotation
and attitude estimations. Current mobile platforms, e.g., iOS, Android, have
the complete framework/package support for programming and accessing all
these sensors for attitude estimation [4]. However, the major disadvantages
of current MEMS INS is that they are far less accurate than mechanical and
optical devices.
State-of-the-art approaches utilize the magnetometer (compass) to oppor-
tunistically calibrate the drift. The magnetometer measures the magnetic ﬁeld
observed by the smartphone and derives the angle with respect to the global
inertial coordinate frame (ﬁxed in the space, i.e., it does not accelerate or
rotate with respect to the rest of the universe). Both the A3 in [134] and Ap-
ple’s solution in [4] utilized this principle and achieved good result in heading
estimation and compass applications.
The rationale is that gyroscopes and accelerometers belong to the cate-
gory of strapdown inertial systems that measure the angular velocity and the
speciﬁc force acted upon the smartphone, respectively. Unlike the gyroscopes
and accelerometers where all measurements are made in the smartphone’s own
frame of reference, magnetometers measure the magnetic ﬁeld observed by the
smartphone and derive the angle with respect to the global inertial coordinate
frame (ﬁxed in the space, i.e., it does not accelerate or rotate with respect to
the rest of the universe). Both the A3 in [134] and Apple’s solution in [4]
utilized this principle and achieved better accuracy in heading estimation.
However, these solutions are not satisfactory for moving conditions in AR
applications. The basic requirement of calibration is the identiﬁcation of a
“good” opportunity [134], i.e., when the measurement is stable. If the smart-
phone kept moving (the common case), there would be no opportunity for

Pushing Location Awareness to Context-Aware Augmented Reality
■
137
60
70
80
90
100
110
120
−150
−100
−50
0
50
100
150
Time (s)
Euler Angle (o)
 
 
Roll
Pitch
Yaw
Pitch
Roll
Yaw
Moving
(a) Large Rotation
60
80
100
120
0
20
40
60
80
Time (s)
Euler Angle (o)
 
 
Roll
Pitch
Yaw
Pitch
Roll
Stationary
Stationary
Yaw
Moving
(b) Small Sway
Figure 7.6: Attitude under (a) large rotation; (b) small sway.
calibration. Fig. 7.6 shows the obtained attitude via Apple’s solution under
two diﬀerent moving cases. Fig. 7.6(a) is the case where the smartphone is
stationary in the initial stage, then performs four large rotations (360o), back
to the initial location with the same ground-truth attitude. The attitude drift
is well controlled in the stationary stage, but not good after rotations. As
shown in Fig. 7.6(a), every rotation introduces several degrees of drift (yaw
angle). Fig. 7.6(b) contains stationary and small back-and-forth sway (with
the same degree) in the moving part. The attitude suﬀers strong drift during
the small movement. Overall, the existing state-of-the-art approach works well
in stationary cases, but is still not good for movement due to the insuﬃcient
“good” opportunity for calibration.
7.3.1.2
Attitude Error Reduction
The traditional attitude calibration approach uses the 6-state EKF to estimate
the current attitude and gyro biases simultaneously [66]. When the sensor
misalignment is considered, there will be a total of 12 calibration parameters.
A paramount issue of the attitude accuracy is the precision of the EKF
model. If assuming the bias is constant and the resulting drift is linear, the
performance of EKF will be downgraded if the assumption is not true. The
worst case is the diverging of the EKF. From the experimental results shown
in Fig. 7.6, the bias sometimes really changes, especially in diﬀerent moving
modes. For military or spacecraft applications, a higher order model, e.g., a
15-state model, is often derived to solve this nonlinear problem. However, a
higher-order model does not work for low-accuracy MEMS INS in the smart-
phone. Estimating more unknown parameters will make the result worse in
real cases.
Gyros Error Modeling. The output of the gyros contains small bias
and random noises. Assuming the constant bias error is ϵ, the random noise

138
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
is a zero-mean uncorrelated random variable with a ﬁnite variance of σ2. The
error model of the gyros measurement can be formulated as ε = εb + εr + wg,
where εb is the constant bias error, where ˙εb = 0; εr is the random walk error
(result of integrating the random noise), where ˙εr =
1
Tg εr + wr; Tg is the
correlation time of the gyros [66]. When calculating attitude, the error term
causes an angular error that grows linearly when performing integration. Even
when the smartphone stands still, i.e., without undergoing any rotation, the
output of the gyros is not perfect zero, i.e., it is drifting.
Accelerometer Error Modeling. Diﬀerent from the gyros, the white
noise in acceleration measurements is integrated twice and causes a second-
order random walk in displacement. As a result, position errors grow propor-
tional to t2. The error of the accelerometer measurement can be modeled as
˙δ = −1
Ta δ + wa, where Ta is the correlation time of the accelerometer. The
value of Ta diﬀers from diﬀerent devices, and needs to be estimated prior to
calibration. wa is the modeled Gaussian white noise.
The integration process causes the most important problem of estimating
the displacement. The measurement noise will be accumulated and the dis-
placement is drifting even when the smartphone is stationary. Thus, simply
performing integration will cause signiﬁcant errors in real situations.
Interacting Multiple Model (IMM). Instead of estimating all the bias
and scale factors (εb, εr, δ) continuously and simultaneously, we change the
EKF model in moving conditions, i.e., Interacting Multiple Model (IMM).
The basic principle is to smooth the result, i.e., reduce the noise, instead of
estimating more unknown parameters in worse cases, e.g., moving cases. We
estimate the bias and scale factors when the smartphone is stationary; when
the smartphone is moving, we reduce the unknown parameters and directly
utilize the scale factors and misalignment that were estimated in the stationary
stage. The state vector of the EKF model is written as
XI(t) = [θb
t , vn
t , sn
t , εb, εr, δ]
(7.2)
where θb
t is the rotation angle obtained from the gyros; vn
t is the velocity from
the accelerometer; sn
t is the location of the smartphone; εb, εr are the bias
and drift of the gyros; δ is the drift of the accelerometer. We reduce the XI(t)
by removing the drift parameters εr and δ when the smartphone is moving,
i.e., change the model via IMM.
Another improvement is to reduce the noise. The relationship of the gyros
and accelerometer measurements can be written as
¨sn
t = Rn
b,t(f b
t −εb −εrwg) −g
(7.3)
where Rn
b,t denotes the rotation matrix from the body coordinate to the navi-
gation coordinate. Thus, leveraging the adaptive-threshold-based activity de-
tection (ATAD) results via accelerometer as stated in Section 7.3.2.3 smooths
the gyros result.

Pushing Location Awareness to Context-Aware Augmented Reality
■
139
60
70
80
90
100
110
120
−150
−100
−50
0
50
100
150
Time (s)
Euler Angle
 
 
Roll
Pitch
Yaw
Pitch
Roll
Yaw
Moving
(a) Large Rotation
50
60
70
80
90
100
110
120
0
20
40
60
80
Time (s)
Euler Angle
 
 
Roll
Pitch
Yaw
Yaw
Moving
Roll
Stationary
Pitch
Stationary
(b) Small Shaking
Figure 7.7: Attitude via IMM under (a) large rotation; (b) small sway.
Utilizing (7.3), we perform real-time wavelet denoising [90] for the update
function of the gyros (ωb
t = ˆωb
t −∆−wa), where ˆωb
t is the gyros output.
After the smoothing process, the optimized attitudes of Fig. 7.6 are shown
in Fig. 7.7. Both Fig. 7.7(a) and Fig. 7.7(b) show reduced noise with clear
movement trace. Note that our approach does not reduce the drift, since we
used a low-order model during movement. Our purpose is to reduce the noise.
The drift reduction is achieved via INS and vision fusion as stated in Sec-
tion 7.4.4.2.
7.3.2
Displacement Estimation
The movement and location of a smartphone or camera is critical in presenting
the AR view to the right place. However, a highly accurate indoor localization
approach is still missing, and remains a hot research topic. Instead of directly
utilizing the absolute location of a smartphone, we leverage coarse-grained
location, POI image matching, and displacement estimation to map the AR
view to the right place in the physical world.
7.3.2.1
Challenges
To estimate the displacement (t) of the smartphone, double integrating the
acceleration via movement model, or counting the step number from accel-
eration features (pedometer) are two typical approaches [97, 114]. However,
step-counting requires the prior knowledge of step size, and is only suitable for
applications when the number of steps are large. For indoor and small-scale
AR applications, people usually linger around and do not walk with their nor-
mal step size. For example, museum visitors often take photos, record videos
or stare at exhibitions, which is very subtle in movement with no apparent

140
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
footsteps. Thus, ﬁne-grained double integration is more preferred than coarse-
grained step counting.
The quantity result from the accelerometer is the acceleration rate in m/s2,
and can be denoted as f b
t = (f bx
t , f by
t , f bz
t )T , where f bx,y,z
t
is the measured force
in 3-axis directions in the body frame. Direct integrating f b
t obtains the dis-
placement in the body coordinate, which is not related to the real geodesic
displacement. Moreover, the user’s moving path is not a line. Turns and rota-
tions should also be estimated.
7.3.2.2
Existing Approaches
To obtain the complete moving paths and turns, we convert the obtained ac-
celeration of the smartphone to the local navigation coordinate (apply rotation
and translation over f b
t ) by
f n
t = Rn
b f b
t + en
(7.4)
where en is the error of the force applied to the smartphone. f n
t is the esti-
mated force of the smartphone in the navigation coordinate. To obtain the
acceleration caused by the applied forces, gravity should be subtracted by
an
t = f n
t −g, where g = [0, 0, g] is the gravity vector.
Using Fig. 7.8 as an example, the ground truth of moving is a rectangle
with stationary stays during movements. The measured acceleration result
after gravity subtraction is shown in Fig. 7.8(a). The four strong non-zero
regions demonstrate the four edge movement for a rectangular shape.
After the denoising process, the velocity of the smartphone can be obtained
by vn
t = vn
0 +
R t
0 an
t as shown in Fig. 7.8(b), where vn
0 is the initial velocity.
From Fig. 7.8(b), we know that the velocity drifts even when the user is in
stationary.
The displacement can be calculated by sn
t = sn
0 +
R t
0 vn
t , where sn
0 is the
initial displacement. The result of the estimated displacement is shown in
Fig. 7.8(c) with large drift. We apply diﬀerent colors in Fig. 7.8(c) for diﬀerent
15
20
25
30
35
40
45
50
−4
−2
0
2
4
6
Time (s)
Acceleration (m/s2)
 
 
ax
ay
ax
ay
(a) Acceleration
15
20
25
30
35
40
45
50
−2
−1
0
1
2
Time (s)
Velocity (m/s)
 
 
vx
vy
vx
vy
(b) Velocity
−1
0
1
2
3
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
x−North (m)
y−North (m)
Start Position
Estimated Trace
Ground
Truth
End Position
(c) Displacement
Figure 7.8: Motion estimation result via conventional method: (a) accel-
eration, (b) velocity, (c) displacement.

Pushing Location Awareness to Context-Aware Augmented Reality
■
141
time periods during the movement, which provides an additional views of the
temporal information.
The process of obtaining relative displacement sn
t is contributed by double
integration, in which the measurement noise, i.e.,
R R
en, is also integrated and
ampliﬁed. The white noise in acceleration measurements is integrated twice
and causes a second-order random walk in displacement of the smartphone.
7.3.2.3
Mitigating Displacement Error
The portable and inexpensive features, in addition to the fast response time
and low power consumption, motivates us to design better approaches to com-
pensate for the error introduced in INS. The major disadvantages of current
MEMS INS in smartphones is that they are far less accurate than mechanical
and optical devices. The integration process causes the most important prob-
lem of using INS measurement to estimate the displacement. Thus, simply
performing integration will cause signiﬁcant errors in real situations.
Adaptive-Threshold-based Activity Detection (ATAD). Perform-
ing signal denoising [90] and activity detection before integration, and using
the estimation results as a constraint, could be a feasible approach to calibrat-
ing the drift. One signiﬁcant problem of using integration is that the estimated
displacement is drifting even when the smartphone is stationary.
One important problem in activity detection is the dynamic setting of
the threshold for various environments and conditions. We propose to uti-
lize forward and backward window-aided CFAR detectors for high detection
probability with constant false-alarm rate [58]. Each individual sample of ac-
celeration an
t can be modeled as a Gaussian random variable with the noise
component as ng
t . Using the Neyman-Pearson criterion, we set a constant
value of false-alarm rate Pfa and perform CFAR detection. Relying on the
fact that the adjacent samples from the accelerometer have strong correla-
tion, here we construct two detection-aided windows (wf and wb) to estimate
the environment noise and the detection threshold. The adaptive threshold is
obtained by
ˆηact =
p
π/2E(zi)Q−1(Pfa/2)
(7.5)
where E(zi) is the similar term for the signal-to-noise ratio, i.e., the normalized
decision vector with regard to the values estimated by wf and wb. The activity
decision process is realized by comparing the adaptive threshold to the cell
under test. We call it adaptive-threshold-based activity detection (ATAD).
Using the detected activity level as shown in Fig. 7.9(a), we map the ac-
tivity level to one weighting coeﬃcient wt via low-pass ﬁlter for boundary
smoothness, as shown in Fig. 7.9(b). During the integration process of dis-
placement calculation, we multiply wt to the velocity value vn
t as shown in
Fig. 7.9(b). This process minimizes the error during integration and improves
the boundary continuity. The estimated displacement is shown in Fig. 7.9(c)
with signiﬁcantly reduced drift compared with the initial version in Fig. 7.8(c).

142
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
15
20
25
30
35
40
45
50
−4
−3
−2
−1
0
1
2
3
4
Time (s)
Acceleration (m/s2)
 
 
ax
ay
Activity
ax
ay
(a) Acceleration
15
20
25
30
35
40
45
50
−2
−1
0
1
2
Time (s)
Velocity (m/s)
 
 
vx
vy
wt
vx
vy
wt
(b) Velocity
−0.5
0
0.5
1
−0.5
0
0.5
1
x−North (m)
y−North (m)
Start Position
End Position
Ground
Truth
Estimated Trace
(c) Displacement
Figure 7.9: Motion estimation result via ATAD: (a) acceleration, (b) ve-
locity, (c) displacement.
Gaussian Derivative Decomposition (GDD). After performing de-
noising and using ATAD, the moving trace becomes signiﬁcantly better than
direct integration. However, inaccurate traces still exist due to the imperfect
denoising or thresholding. Purely detecting the signal from noisy background
without prior information of the signal pattern would not guarantee better
results.
Performing moving pattern extraction before integration could be a feasi-
ble method. The normal movement model could not be applied for estimating
the human’s moving, e.g., we cannot walk at constant velocity (CV) or con-
stant acceleration (CA) like a vehicle or a plane. Human walking or movement
has its own pattern, and we need to “accelerate” and “decelerate,” and then
“accelerate” for another footstep. Thus, the acceleration pattern for one move-
ment should look like a pulse. Here we use the “start-moving-stop” movement
model.
Performing “start-moving-stop” pattern decomposition helps us estimate
the displacement in a more meaningful way. Using start, acceleration, and
deceleration as one basic step, the velocity changes (from zero to top to zero)
can be modeled as a Gaussian shape gv(µ, σ) = ± exp{−(x −µ)2/(2σ2)},
where + means moving forward; −means backward. The acceleration is the
derivative of the velocity, i.e., Gaussian derivative pulse, as
ga(µ, σ) = ±(x −µ)/σ2 exp{−(x −µ)2/(2σ2)}
(7.6)
Using ga(µ, σ) as the kernel function, we decompose the acceleration measure-
ment an
t into a series of ηga(µ, σ) with diﬀerent parameters η, µ, and σ. The
decomposed series of acceleration is Pn
i=1 ηiga(µi, σi), where ηi is the ampli-
tude of each Gaussian derivative pulse. The ﬁtting process can be modeled
as
{ηi, µi, σi} =
min
{ηi,µi,σi} ||an
t −ηiga(µi, σi)||
(7.7)
To reduce the number of parameters during the ﬁtting process, we extract the

Pushing Location Awareness to Context-Aware Augmented Reality
■
143
feature points of an
t , e.g., peak position and width, by thresholding the peak
maximum and rising edge. Then we use the number of peaks found and the
peak positions and widths to ﬁt the speciﬁed peak model. This combination
yields better and faster computation, and deals with overlapped peaks as well.
During the decomposition and ﬁtting process, the sign of ηi is determined by
comparing the remaining error of using positive and negative results.
After the GDD-based ﬁtting, the ﬁtted acceleration result is shown in
Fig. 7.10(a). We calibrate the measured acceleration and mitigate the outliers
by relying on the “start-moving-stop” model. The estimated velocity and dis-
placement results after using GDD are shown in Fig. 7.10(b) and Fig. 7.10(c),
respectively. Compared with the result in Fig. 7.9, Fig. 7.10 demonstrates
a very clear and accurate moving rectangle (almost the same as the ground
truth), which is signiﬁcantly better in terms of estimation accuracy.
15
20
25
30
35
40
45
50
−3
−2
−1
0
1
2
3
Time (s)
Acceleration (m/s2)
 
 
vx
vy
Activity
ax
ay
(a) Acceleration
15
20
25
30
35
40
45
50
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time (s)
Velocity (m/s)
 
 
vx
vy
Activity
vx
vy
(b) Velocity
−0.5
0
0.5
0
0.2
0.4
0.6
0.8
1
x−North (m)
y−North (m)
Start Position
End Position
Ground
Truth
Estimated Trace
(c) Displacement
Figure 7.10: Motion estimation result via GDD: (a) acceleration, (b) ve-
locity, (c) displacement.
The GDD approach also works for overlapped steps or situations when
the steps are continuous. We do not assume users fully stop during the move-
ment. Continuous movement will result in several overlapped pulses, and the
process of (7.7) also works. As shown in the second and fourth movement in
Fig. 7.10(a), the GDD ﬁtting process is eﬀective when two pulses are over-
lapped together.
7.3.3
Smartphone Localization
One important problem of the AR application is to predict which POI is in the
camera view, and map the physical POI into camera coordinates, rendering
and tracking the AR view in an appropriate screen location. This process
requires an accurate location estimation result of the camera with real-time
response. However, smartphone indoor location estimation is still the subject
of extensive works [74, 52, 48].

144
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
To relax this demanding requirement, we utilize a coarse-grained location
result and combine it with the POI image matching to obtain the relative
location. The coarse-grained location result could narrow down the searching
space of the POI candidates, which signiﬁcantly reduces the matching com-
plexity. The image matching process detects which POI is in the camera view.
Based on our previous work [58], we leverage a plurality of acoustic sensor
nodes as a preconﬁgured anchor constellation to broadcast an unnoticeable
acoustic beacon. The smartphone captures the location beacon, demodulates
the beacon symbol, and performs time-of-arrival (TOA) estimation. To dif-
ferentiate diﬀerent anchor nodes, i.e., station i.d. the decoded sequence of
symbols is utilized to match with the pre-stored pseudocode sequence pm.
Deﬁne pn, xn
m as the position of the smartphone and the m-th anchor
in the n-frame. Using M pseudoranges ˆrm and the preconﬁgured coordinates
of anchor nodes xn
m, we estimate the 3D position of the smartphone pn by
minimizing the quadric term of the remaining error
εm = ||ˆrm −(||pn −xn
m||2 + δr)||2
(7.8)
where δr is the unknown delay that compensates for the diﬀerence between
the pseudorange and real distance. The value of δr is estimated by adding an
additional measurement, e.g., solving 3D location (x, y, z) needs four equations
(anchor nodes) instead of one. The superscript n in pn denotes the position
value in the navigation coordinate (deﬁned in Fig. 7.2).
Range and Location Fusion via Activity Detection. Measurements
obtained from the indoor absolute location estimator (ALE) contain various
kinds of jitters and outliers due to the ambient noise and multipath. Things
will get even worse when blockage occurs with no ranging information at all.
To solve this problem, we create two steps of Kalman ﬁltering to eliminate
the outliers and smooth the data via the activity detection result in Section
7.3.2.3. The ﬁrst step is to process the ranging data from multiple anchors
before location computation, in other words, tracking before localization; the
second step is to smooth and track the coordinates after location computation,
i.e., location tracking.
To fuse the INS sensor with the ALE, we can write all the measurements
into one state-space model, and utilize the model in the Kalman ﬁlter for the
fusion process. The position estimation results from the INS sensor is sn
t , the
second-order moving model can be written as
sn
t+1 = sn
t + ˙sn
t Tins + ¨sn
t
T 2
ins
2
(7.9)
˙sn
t+1 = ˙sn
t + ¨sn
t Tins
where ˙sn
t and ¨sn
t are the moving velocity and acceleration, which is derived
from the obtained displacement; Tins is the sampling time of the INS.
The relationship with the INS result (7.9) and the estimated location result
(7.8) can be summarized as sn
t+1 = pn
τ+1 −pn
0 +εp, where εp is the error term,

Pushing Location Awareness to Context-Aware Augmented Reality
■
145
and τ is the update time period for the localization result, which is longer
than Tins.
The Kalman ﬁlter handles the diﬀerent sample rates from INS (t) and
ALE (τ) by running at a high data rate (same as INS) and only calibrating
an INS result when the measurements from ALE are available. After the fusion
process, the update rate of the localization module has been improved to the
same level as the INS sensor, while the bias problem of the INS is calibrated.
7.4
Projecting and Tracking the AR View
The process of projecting the AR view is summarized in Fig. 7.3. Basically,
it involves four steps: 1) detect the POI; 2) map the POI into the camera
view space; 3) convert to the canonical view volume, i.e., NDC (normalized
device coordinate); 4) present the AR point in screen coordinate. The overall
algorithm processing structure is illustrated in Fig. 7.5.
7.4.1
POI Detection and Relative Pose Estimation
7.4.1.1
POI Detection via Image Feature Detection and Matching
Using the smartphone’s location to estimate a rough region for the POI image
matching, the matching database is signiﬁcantly reduced. When the activity
detection module triggers the image feature detection process, we perform
ORB feature detection [94] for current image frame Iv
k as ρv
k = f ORB
Av
k
(Iv
k).
To ﬁnd the best transform between two sets of feature points, the RANdom
SAmple Consensus (RANSAC) approach is applied to reject outliers [32]. To
determine whether two images match, the inlier rate of the matched points
after RANSAC is utilized. Assuming the feature point for the POI is ρm,
the inlier rate for ρv
k is pm
k = Match(ρv
k, ρm). If the maximum pm
k among all
the images in the database exceeds the threshold, the POI is matched to the
smartphone’s camera view. We get the POI’s augmented information and its
pre-stored coordinate xn
i = (xn
i , yn
i , zn
i )T expressed in terms of the navigation
coordinate.
7.4.1.2
Initial Relative Pose Estimation
With the detected POI and its pre-stored information, we estimate the relative
rotation R and translation matrix t =
tx
ty
tz

between the POI and
the smartphone. According to the epipolar geometry, the fundamental matrix
can be written as F = K−T ˆTRK−1 [32], where t =

tx
ty
tz

, K is the
camera intrinsic matrix. Using the result of image matching, we obtain the
fundamental matrix F. With F available, relative rotation R and translation
matrix t are inversely calculated. The ambiguity values of R and t can be

146
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
ruled out via the frustum constraints, i.e., the POI is faced to the camera and
cannot be in the back of the camera view (depth value zndc
i
< 0).
The estimated matrix from fundamental matrix F are actually camera’s
initial rotation Ro and translation t0 that relative to the POI in the navi-
gation coordinate. When the camera moves, further readings of attitude and
displacement from INS, i.e., the rotation matrix Rb
n and the translation ma-
trix tb
n, reﬂect the physical dynamics. Combing the initial Ro and t0 with Rb
n
and t, the POI’s location in the smartphone’s body coordinate is written as
xb
i = Rb
n(R0xn
i + t0) + tb
n
(7.10)
(7.10) relates the conversion between the b-frame and the real physical world,
i.e., n-frame. Converting the POI location into the smartphone’s body coordi-
nate is the prerequisite for the POI projection process in Fig. 7.3.
7.4.1.3
Homography Relation
For two consecutive image frames, using homogeneous representation could
represent the projective transformation by means of simple matrix multiplica-
tions [32]. Epipolar geometry holds when translation exists, i.e., the baseline
of two cameras is larger than 0. For our continuous video frame capture,
the translation between each frame is small. For this zero epipolar geom-
etry condition, homography holds [32]. Assuming a pinhole camera model,
the feature points in consecutive planar images ρv
k and ρv
k+1 are related by
a 3 homography matrix [32]. For a single feature point ρv
k = [xv
k, yv
k, 1]T and
ρv
k+1 = [xv
k+1, yv
k+1, 1]T , the homography relation can be modeled by
ρv
k = Hk+1
k
(w′ρv
k+1)
(7.11)
where w′ is the added dimension in homogeneous coordinates [32]. The ho-
mography relation Hk+1
k
is calculated by ﬁnding the best matched transform
between two sets of points ρv
k and ρv
k+1 after RANSAC [32].
The camera rotation (Rk+1
k
) and translation (tk+1
k
) between two images
can be extracted from an estimated homography matrix Hk+1
k
. This infor-
mation is useful for rendering the correct AR perspective in the next frame
(k + 1) and appear to have been part of the POI point (scene).
The predicted POI point in image k is pndc
i,k , and its related pixel point in
the v-frame will be pv
i,k via f v
ndc. Then, the predicted next position of the POI
point via homography is
pv
i,k+1 = Rk+1
k
(pv
i,k −C) = Rk+1
k
pv
i,k + tk+1
k
(7.12)
where C is the original location of image k. The related screen coordinate can
be calculated by ps
i,k+1 = f s
ndcf ndc
v
pv
i,k+1. If iterate via (7.12) from k = 1, we
could obtain the whole moving trace of the POI point in the image plane.

Pushing Location Awareness to Context-Aware Augmented Reality
■
147
7.4.2
Mapping the POI to the Screen
To address the problem of how and where to present the overlay view to the
right position on the screen, the mapping process between the rendered AR
view and real physical POI should be derived.
To model the process of calculating the screen point position xπ
i for the
POI point (xb
i), the projection process can be modeled as xπ
i = Tπ
b xb
i, where
the image point is xπ
i = (xπ
i , yπ
i , zπ
i )T , and Tπ
b determines the relationship
between a point in the image plane and a POI point. Converting xπ
i to the
point in pixel format xp involves two steps. The ﬁrst step is to change the
scale from metric units to pixels. The second step is to translate the origin of
the coordinate frame from the principal point to the video capturing (v-frame)
original point as shown in Fig. 7.3. Thus the transformation can be described
as xp
i = Tp
πTπ
b xb
i = Kxb
i.
For AR applications, we need to render a synthetic scene in the screen via
OpenGL. While the world of OpenGL is slightly diﬀerent, our 3 × 3 intrin-
sic camera matrix K needs three modiﬁcations to make it compatible with
OpenGL. Thus, the intrinsic and extrinsic matrix combined could illustrate
the full-perspective model that describes the relationship between a 3D point
xn
i expressed in the navigation frame and its projection on the screen. The
overall relationship is written as


xp
i
yp
i
1

= KGD


xn
i
yn
i
zn
i
1

=


f/α
0
0
0
0
f
0
0
0
0
−far+near
far−near
−2far×near
far−near
0
0
−1
0



Rb
n
t
0
1



xn
i
yn
i
zn
i
1


= P


xn
i
yn
i
zn
i
1


(7.13)
where D is the camera’s extrinsic matrix that describes the camera’s loca-
tion coordinate transformation. The added one dimension is to utilize the
homogeneous representation [32]. KG is the new projection matrix, where
f = cot(fovy/2); fovy = 2 arctan(height/2(nyf)); pixel aspect ratio α =
(nywidth)/(nxheight); near and far is the near and far plane of the OpenGL
camera system. Using Apple iPhone 5S as an example, the fovy = 60 degrees;
near = 0.25 meters; far = 1000 meters; width = 320 pixels; height = 180
pixels. The projection matrix KG allows you to represent all of the intrinsic
camera parameters, e.g., focal length, principal point, pixel aspect ratio, and
axis skew. The matrix P denotes the perspective projection matrix, which
transforms a POI point in the navigation coordinate to the screen of a smart-
phone as shown in the ﬁrst step of Fig. 7.3.

148
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
7.4.3
Projecting the AR View
To summarize the procedures of projecting the AR view to the smartphone
screen, there are several basic steps:
■
Get the initial absolute location of the smartphone via Section 7.3.3;
query all the nearby POI positions.
■
Detect the actual POI on screen via the image matching; estimate the
initial relative pose via fundamental matrix in Section 7.4.1.2.
■
Obtain the smartphone body attitude in rotation matrix Rb
n and rel-
ative translation matrix t via INS.
■
Update the camera projection matrix P via (7.13); iterate over all
the local POI positions, and calculate their projected homogeneous
position [xp
i
wp
i ] in view frustum as shown in step 1 of Fig. 7.3.
■
Collapse the 4 component vector xp
i in view frustum to 3-dimensional
space. The achieved normalized device coordinate (NDC) is xndc
i
,
where xndc
i
= xp
i /wp
i , yndc
i
= yp
i /wp
i , zndc
i
= zp
i /wp
i . Through this pro-
cess, the POI position is mapped into the NDC coordinate as shown in
step 2 of Fig. 7.3, where x, y, z is in the range of [−1, 1] for the points
on the screen. Since x and y coordinates are being biased from the
range [−1, 1], to match up with the UIKit coordinate system in iOS,
we convert it to range [0, 1] by xndc
i
= (xndc
i
+1)/2, yndc
i
= (yndc
i
+1)/2.
■
The z component, zndc
i
, should be checked to see if it is greater than 0.
If zndc
i
< 0, then the POI is in the ﬁrst half of the projection frustum,
i.e., in front of the camera.
■
After the third step in Fig. 7.3, the overlay view location in screen
coordinate for the i-th POI is obtained via f s
ndc as

xs
i
ys
i

= f s
ndc


xndc
i
yndc
i
1

=

W s
0
0
0
−Hs
Hs
 

xndc
i
yndc
i
1


(7.14)
where Hs and W s are the height and width of the screen frame.
7.4.4
AR View Tracking
7.4.4.1
Problems
Users’ movement is highly dynamic, from hand vibration to fast walking.
They may hold their smartphones to view the AR with slight hand movement
or vibration. The relative displacement estimation obtained in Section 7.3
is accurate for major movement, but cannot detect vibration or other slow
changes. Only using INS to estimate the displacement and rotation is not
suﬃcient.

Pushing Location Awareness to Context-Aware Augmented Reality
■
149
7.4.4.2
Vision Tracking and Adaptive Rate Control
It is possible to perform feature detection in the same order as the refresh rate
of the AR view, and then apply the matching process between two consecutive
image frames. However, the computation demand of performing high rate fea-
ture detection will kill the battery of smartphones very quickly and slow down
the update frame rate. To balance the tracking accuracy and eﬃciency, the
feature detection process should only be performed when necessary. The low-
complexity optical ﬂow tracking approach should be applied for consecutive
frames.
Optical Flow Tracking. KLT (Kanade-Lucas-Tomasi) feature tracking
has been extensively studied and applied [112, 47]. For the k-th frame (Iv
k) in
the video source, KLT uses image alignment, and solves image displacement
via nonlinear optimization by minimizing the remaining error of
ev
k =
X h
f ORB
Av
k
(Iv
k) −(f ORB
Av
k
(Iv
k) + dv
k)
i2
(7.15)
Using window Av
k to represent the major region rather than detecting and
searching the whole image frame can lower the computation complexity. dv
k
is the pixel displacement between two video frames. After the KLT tracking
process, the feature points (ρv
k+1) in the next image frame are estimated.
Adaptive Rate Control for AR View Tracking. Not every image
frame is needed for feature detection and matching, since users may shake
their smartphone with no purpose. Utilizing the activity detection results,
we only need to perform feature detection for images when the smartphone
detected the POI, which means the user is intended to know the POI in its
camera.
During the KLT feature tracking process, the frame rate could also be
controlled. If the frame rate is too high, and the smartphone is not under-
going movement, performing KLT feature tracking for all the frames is not
economical. However, the frame rate cannot be too low since KLT tracking is
vulnerable to complex movement.
7.5
Evaluation
We implemented all the proposed algorithms on the iOS platform. Several li-
braries are utilized for fast implementation, e.g., OpenCV [12], CMMotion [4],
and OpenGL. The ﬁrst photo in Fig. 7.11 illustrates the indoor AR application
scenario: when a user wants to know the details about one painting, he could
just point the camera view to the painting. The second ﬁgure demonstrates
feature detection and matching, and the retrieval of the information and POI
coordinate of the painting. If the POI is detected, the augmented information
is presented and aligned to the real painting, e.g., the name of the painting.
The third ﬁgure shows the tracking of the POI when the camera moves with-
out repeating the image matching process. For simpliﬁcation, the rendered

150
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
AR information for the painting is just one text label; the POI database is
small, i.e., matching 10 POI images. More complex views and realistic POI
databases will be included in our future work.



Figure 7.11: Indoor AR App and screenshots.
Besides the implementation in the smartphone, we deployed 8 anchor nodes
in one large exhibition room of our campus Art Museum, as shown in Fig. 7.12.
Enriching visiting experience in a museum is one of the promising applications
of our proposed AR application. Based on our previous work [58], we leveraged
the deployed anchor network for indoor location estimation.
7.5.1
Displacement Estimation
To evaluate the drift reduction performance of our proposed INS displacement
estimation algorithm, we compared our proposed approaches, i.e., adaptive
threshold activity detection (ATAD), and Gaussian derivative decomposition
(GDD).
Fig. 7.13 shows the INS displacement estimation results in diﬀerent cases
when moving in line (forward and backward style) patterns. The ground truth
is like a rectangle, the start point and end point are overlapped. These esti-
mated moving traces show very small drift after series of movements.
To quantify the performance of drift reduction, we utilize the metrics of:
total drift (meters), drift speed (drift per second), and drift rate (drift per
meter). To reduce the randomness in performance evaluation, we tested more
than 150 cases of moving trace from one point to another, and then moving
back. We calculate the drift by measuring the diﬀerence between the estimated

Pushing Location Awareness to Context-Aware Augmented Reality
■
151
Figure 7.12: Anchor deployment and experiment environment.
−0.2
0
0.2
0.4
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
x−East (m)
y−South (m)
Start Position
End Position
(a) 1
−0.5
0
0.5
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
x−East (m)
y−South (m)
Start Position
End Position
(b) 2
0
0.2
0.4
0.6
0.8
−0.2
−0.1
0
0.1
0.2
0.3
0.4
x−East (m)
y−South (m)
Start Position
End Position
(c) 3
−1
−0.5
0
0.5
0
0.2
0.4
0.6
0.8
1
1.2
x−East (m)
y−South (m)
Start Position
End Position
(d) 4
−1.5
−1
−0.5
0
−0.2
0
0.2
0.4
0.6
0.8
x−East (m)
y−South (m)
Start Position
End Position
(e) 5
0
0.5
1
1.5
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
x−East (m)
y−South (m)
Start Position
End Position
(f) 6
Figure 7.13: Estimated moving traces for line and rectangular moving
patterns.
end point and the ground truth. The average and median value of all the
metrics are shown in Table 7.1. Our proposed GDD approach achieves best
performance in all metrics. The drift rate of 5.5cm per meter is signiﬁcantly
better than rates for existing approaches.

152
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Table 7.1: Performance comparison with respect to diﬀerent methods
under speciﬁc metrics
Methods
Metrics
Average
Median
Basic
Total Drift (m)
16.51
12.47
Drift Speed (m/s)
0.47
0.40
Drift Rate (m/m)
3.92
3.73
ATAD
Total Drift (m)
1.26
1.02
Drift Speed (m/s)
0.04
0.04
Drift Rate (m/m)
0.31
0.26
GDD
Total Drift (m)
0.23
0.14
Drift Speed (m/s)
0.006
0.0045
Drift Rate (m/m)
0.055
0.043
Displacement Estimation via Vision. Displacement estimation via vi-
sion is highly sensitive, and suitable for slow movement when the INS is im-
possible to detect. Fig. 7.14 shows the estimated moving trace for POI using
vision tracking. The smartphone moves (translates) to the left, and then moves
back without rotation. By decomposing the homography matrix into rotation
and translation matrix, we could get the full movement trace of the POI point
in screen coordinate as shown in Fig. 7.14(b). The clear moving path demon-
strates the AR view displacement estimation capability.
0
10
20
30
40
50
60
−1
0
1
2
Euler Angle (π)
 
 
Roll
Pitch
Yaw
0
10
20
30
40
50
60
−0.5
0
0.5
1
Time (s)
Quaternion
 
 
x
y
z
w
Yaw
Roll
Pitch
X
W
Z
Y
(a) Attitude from INS
0
10
20
30
40
50
60
−500
−400
−300
−200
−100
0
100
Time (s)
Pixels
 
 
x
y
Moving Left
Moving Right
Stationary
(b) AR View Trace from Vision
Figure 7.14: The attitude and AR view trace results.
7.5.2
Absolute Location Estimation
Fig. 7.15(a) shows the estimated displacement from INS results; the obtained
smartphone location via acoustic anchors (ALE), and the fusion results. As

Pushing Location Awareness to Context-Aware Augmented Reality
■
153
0
1
2
3
4
5
6
−1
−0.5
0
0.5
1
1.5
2
x−East (m)
y−South (m)
 
 
INS
ALE
After Fusion
(a) Case 1
−2
0
2
4
6
8
−0.5
0
0.5
1
1.5
2
x−East (m)
y−South (m)
 
 
INS
ALE
After Fusion
(b) Case 2
Figure 7.15: The fusion results for moving location estimation in two
cases (the ground truth is a rectangle).
expected, the INS result has a very high update rate, but the displacement
result has an unknown bias to the true location. The location result via ALE is
unbiased to the ground truth, but suﬀers from measurement noise and outliers.
After fusion, the achieved results show better variance in accuracy with higher
update rate. To test the robustness of the fusion process, we utilize the INS
result with strong bias and drift as shown in Fig. 7.15(b). The fusion result is
still satisfactory with higher update rate and no bias to the true location.
7.5.3
Attitude Estimation
The greatest problem of state-of-the-art approaches in attitude estimation
lies in the moving conditions. To demonstrate the error and noise reduction
performance of our proposed approach, we perform small sway with equal
amplitudes. As shown in Fig. 7.16(a), the Euler Angle is noisy and the overall
trend is drifting. After using noise-reduction and vision fusion, Fig. 7.16(b)
shows clear moving angle change with no apparent drifting.
7.5.4
POI Image Matching and Relative Pose Estima-
tion
Table 7.2 illustrates the measured average execution time of image matching
and relative pose estimation. The training process in Table 7.2 can be done
oﬄine and does not impact the real-time performance. For the image matching
process, the iPhone5S takes nearly 0.055 seconds for one image frame, which
can only reach 18 frames per second (FPS) for real-time processing. To enable
real-time image matching, we utilize the rate control module in Fig. 7.5 to

154
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
20
40
60
80
100
120
140
160
−100
−50
0
50
100
150
200
Time (s)
Euler Angle (o)
 
 
Roll
Pitch
Yaw
Pitch
Roll
Yaw
Moving
Sway
(a) Initial Euler Angle
20
40
60
80
100
120
140
160
−150
−100
−50
0
50
100
150
Time (s)
Euler Angle (o)
 
 
Roll
Pitch
Yaw
Moving
Roll
Pitch
Yaw
Sway
(b) Optimized Euler Angle
Figure 7.16: The comparision of a) initial Euler angle, and b) optimized
Euler angle.
Table 7.2: Comparison of execution time
Device
Training (s) Matching (s) Reﬁned Match (s) Estimate Pose (s)
iPhone5S
0.232
0.055
0.128
0.003
Server
0.055
0.027
0.050
0.001
lower the frame rate to < 18FPS and only perform image matching when the
detected activity level is stationary. The reﬁned image matching takes longer
than the normal matching process; however, the reﬁned matching does not
impact the real-time performance since this process is only performed once
for the initial relative pose estimation. Compared with the execution time
of the iPhone5S and the server, the diﬀerence is not signiﬁcant, especially
considering the network delay. That’s why we choose local processing instead
of using the delay-unbounded server for computation oﬄoading.
Fig. 7.17 shows the relative pose estimation results via epipolar geometry
proposed in Section 7.4.1.2. The template image is illustrated as “0”; the esti-
mated rotation and translation matrix from the sensed image (i = 1 ∼6) are
Ri and ti, respectively. The relative 3D viewpoint locations for the 6 images
in Fig. 7.17 are estimated via Rix + ti. The estimated viewpoint relations
in Fig. 7.17 are consistent with the real image view, which demonstrates the
accuracy of our proposed approach in initial pose estimation.
7.5.5
Mapping the POI to the Screen
When the smartphone moves, the AR view of the POI should be dynamically
rendered at screen locations that make the AR view attached to the real
physical object. This process requires mapping the POI to the appropriate

Pushing Location Awareness to Context-Aware Augmented Reality
■
155
Figure 7.17: Illustrating relative poses for diﬀerent images in 3D space.
0
20
40
60
80
−80
−60
−40
−20
0
20
40
60
80
Time (s)
Euler Angle (ο)
 
 
Roll
Pitch
Yaw
Roll
Pitch
Yaw
(a) Euler Angle
0
20
40
60
80
−80
−60
−40
−20
0
20
40
60
80
Time (s)
Angle (o)
 
 
α−Roll
β−Pitch
γ−Yaw
β−Pitch
α−Roll
γ−Yaw
(b) Vision Angle
0
20
40
60
80
−150
−100
−50
0
50
100
Time (s)
Pixel
 
 
x
y
x
y
(c) Displacement
Figure 7.18: Displacement in vertical.
screen location by utilizing the estimated attitude and displacement. Fig. 7.18
and Fig. 7.19 show two cases of moving the smartphone forward and back
in vertical and horizontal direction, respectively. We intentionally move the
smartphone at a very low speed to test the sensitivity of the proposed POI
tracking approach. As shown in Fig. 7.18(a) and Fig. 7.19(a), the euler angle
of the smartphone shows very small movement, i.e., vertical and horizontal.
The relative vision angles between the POI and the smartphone axis are shown
in Fig. 7.18(b) and Fig. 7.19(b) with very apparent and clear changes during
movement. The screen location changes (x and y coordinates) of the POI
are shown in Fig. 7.18(c) and Fig. 7.19(c), which is consistent with the real
physical movement.
7.5.6
On-Screen AR View Detection and Tracking
When there is no POI covered by the camera view, we only utilize the INS
for the attitude and displacement estimation to save energy. Speciﬁcally, the
high-cost vision processes (feature detection, matching, and tracking) are only

156
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
10
20
30
40
50
−40
−20
0
20
40
60
80
Time (s)
Euler Angle (o)
 
 
Roll
Pitch
Yaw
Pitch
Roll
Yaw
(a) Euler Angle
10
20
30
40
50
−60
−40
−20
0
20
40
60
80
Time (s)
Angle (o)
 
 
α−Roll
β−Pitch
γ−Yaw
β−Pitch
α−Roll
γ−Yaw
(b) Vision Angle
10
20
30
40
50
−100
0
100
200
300
400
500
600
Time (s)
Pixel
 
 
x
y
x
y
(c) Displacement
Figure 7.19: Displacement in horizontal.
launched when detected within the on-screen POI, i.e., the NDC coordinates
of the POI are located within [0, 1]. However, only using the INS results of the
estimated NDC coordinates for launching the vision processes is not reliable.
In a real system, we add two engineering treatments: 1) Calibrate the INS
results periodically via magnetometer [93], which reduces large drifts; 2) leave
headroom α, i.e., change the on-screen NDC coordinates range to [0−α, 1+α],
where the value of α balances the accuracy and energy cost (we choose α = 0.1
in our implementation).
0
20
40
60
80
100
120
−1
0
1
2
3
Euler Angle (π)
 
 
0
20
40
60
80
100
120
0.3
0.4
0.5
0.6
0.7
Time (s)
Quaternion
 
 
x
y
z
w
Roll
Pitch
Yaw
Yaw
Roll
Pitch
A
B
C
A
B
C
Z
Y
X
W
(a) Attitude from INS
0
20
40
60
80
100
120
−2
−1.5
−1
−0.5
0
0.5
1
Time (s)
NDC
 
 
onScreen
xi
ndc
yi
ndc
A
B
C
INS Result
Calibration
Vision Tracking Result
(b) AR View Tracking
Figure 7.20: The attitude and AR view tracking result.
Fig. 7.20 shows the complete evaluation process by moving the camera
view. During the 0 ∼40s time period, i.e., the period labelled A in Fig. 7.20,
the POI is outside the camera view. We sway the smartphone via tripod
with the same angle to test its attitude and displacement drift. The esti-
mated attitude results (Fig. 7.20(a)) and POI’s locations (Fig. 7.20(b)) show

Pushing Location Awareness to Context-Aware Augmented Reality
■
157
near periodical movement but with apparent drift over time. The two sudden
jumps of the NDC location near 15s and 33s are caused by the magnetometer
calibration process (to prevent the POI drift into the screen).
At the time point near 42 ∼47s (period B), we moved the smartphone,
and the POI is covered by the camera view. When the NDC location value
of POI is within [0, 1], i.e., on-screen, the vision tracking process is started
immediately for better accuracy. We still perform the same periodical move-
ment (50s and later) as with the 0 ∼40s period (period C). Fig. 7.20(b) shows
very stable and accurate estimation of the POI’s ndc location; while the INS
results of the attitude in Fig. 7.20(a) suﬀer from apparent drift. The whole
process illustrates the accurate detection of the AR view within the camera’s
viewpoint, and performs vision tracking to improve the accuracy.
7.5.7
AR View Tracking via Adaptive Frame Rate
We propose solutions for the AR view tracking and make it suitable for var-
ious movements from small hand shakes to large rotations, with high energy
eﬃciency. After detected on-screen POI, i.e., there exists one NDC coordi-
nates that located within [0 −α, 1 + α], vision processes (feature detection,
matching, and tracking) are launched for better accuracy. Due to the inaccu-
racy of the INS estimation, errors exists in detecting the on-screen POI. The
cost of the error detection is mainly the computational power. Thus, we add a
self-stop scheme to terminate the vision processes after the feature matching
stage when no POI feature matches.
To further reduce the computation cost and energy consumption in the
vision processes, we propose an adaptive frame scheme to select critical video
frames that are necessary for the overall performance. To evaluate the eﬀec-
tiveness, we conduct two real-time experiments with similar movement. The
whole movement is divided into diﬀerent stages: 1) A and E: equal-angle sway
via tripod when POI is not under the camera view; 2) B: large movement
when the POI is not on-screen; 3) C: equal-angle sway when POI is under the
camera view; 4) D: large movement when the POI is on-screen.
When using all the image frames, the AR view trace and execution time for
each frame are shown in Fig. 7.21(a) and Fig. 7.21(b), respectively. Fig. 7.22
shows the logged energy trace of the smartphone via Apple’s Xcode Instru-
ment. When the POI is not on-screen, the execution time is very low since
only INS is utilized. In stage “C,” i.e., when POI is on-screen with small
movement, the execution time is small since only vision tracking is needed. In
stage “D,” there is a large movement with multiple POIs entering and leaving
the camera view, and the execution time is longer due to the frequent image
feature detection and matching process.
After performing adaptive frame selection, the performance of Fig. 7.23 is
similar to Fig. 7.21 with no apparent diﬀerence. When comparing the logged
energy trace as shown in Fig. 7.24, the reduction in terms of energy usage and
CPU activity is signiﬁcant.

158
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
0
50
100
150
−2
−1
0
1
2
Time (s)
NDC
 
 
x
y
y
A
B
C
D
E
x
(a) ARView Trace
0
50
100
150
0
0.01
0.02
0.03
0.04
0.05
Time (s)
Execution Time (s)
 
 
INS
Vision
A
B
C
D
E
INS
INS
Vision
(b) Execution Time
Figure 7.21: a) Estimated AR view trace; b) execution time for each
frame.
Figure 7.22: Energy and CPU activity proﬁle with high frame rate.
Several narrow peaks in Fig. 7.21(b) and Fig. 7.23(b) are caused by the
image matching process that takes longer. The execution time of the nor-
mal image matching and reﬁned image matching for initial pose estimation is
illustrated in Table 7.2.
7.5.8
Comparison with Existing Apps
Energy Consumption. Fig. 7.25 shows the proﬁled results of our indoor AR
App (InAR) vs. other competitors in terms of energy usage, and CPU activ-
ity via Apple’s Xcode Instruments running on an iPhone5S [75]. We launch
diﬀerent apps at diﬀerent time slots: 1) “InAR” (30FPS); 2) An app performs
ORB feature detection at full frame rate (30FPS); 3) An app performs SURF
feature detection (near 20FPS); 4) iPhone-AR-Toolkit [120]; 5) Mixare [71];
6) Layar [29]; 7) Qualcomms Vuforia [87]. Our app is less resource intensive
than others. For cases 2 and 3, the smartphone’s CPU activity is nearly 100%;
the powerful iPhone5S cannot run in full frame rate (< 30FPS).

Pushing Location Awareness to Context-Aware Augmented Reality
■
159
0
50
100
150
200
−2
−1
0
1
2
Time (s)
NDC
 
 
x
y
y
x
A
B
C
D
E
(a) ARView Trace
0
50
100
150
200
0
0.01
0.02
0.03
0.04
0.05
Time (s)
Exection Time (s)
 
 
INS
Vision
INS
INS
A
B
C
Vision
D
E
(b) Execution Time
Figure 7.23: a) Estimated AR view trace; b) execution time for each
frame.
Figure 7.24: Energy and CPU activity proﬁle with adaptive frame rate.
Accuracy. Among existing solutions, e.g., iPhone-AR-Toolkit, Mixare,
and Layar, all these are focused on AR applications and directly utilized the
system-provided API for attitude and location estimation, i.e., the Apple’s
solution that we compared in Section 7.3 and Section 7.5. We select the Layar
(INS-based) [29] and Vuforia (vision-based) [87] as two representative exam-
ples. The screen-shots of the tracking results are presented in Fig. 7.26. From
Fig. 7.26, the problem of Layar is drift after movement (the same AR view
is displayed in diﬀerent screen positions); vision-based solutions like Vuforia
suﬀer from short distance when the letter-sized image template is slightly
far away (the rendered teapot has disappeared). Our proposed solution, i.e.,
InAR, does not have these problems and achieves the best accuracy in AR
view tracking under diﬀerent movements.
Fig. 7.27 shows the AR view estimation results from INS-based, vision-
based, and our proposed approach. The movement pattern is the same in all
three cases, i.e., small sway and large rotation. Our proposed solution, i.e.,
InAR, does not drift during small sways, and also supports large movements.

160
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 7.25: The comparison of energy usage, and cpu activity for diﬀer-
ent apps.
Figure 7.26: The drift problem of Layar, and the short distance problem
of Vuforia.
0
20
40
60
80
100
120
−100
−50
0
50
Time (s)
Position
 
 
x
y
x
y
Small Sway
Large Rotation
(a) INS-based
0
20
40
60
80
100
120
−100
−50
0
50
Time (s)
Position
 
 
x
y
data missing
x
y
Small Sway
Large Rotation
(b) Vision-based
0
20
40
60
80
100
120
−100
−50
0
50
Time (s)
Position
 
 
x
y
x
y
Small Sway
Large Rotation
(c) Our proposed ap-
proach
Figure 7.27: AR view tracking results via diﬀerent methods.
7.6
Related Work
Related AR Applications. AR applications put a childlike spin on the
world and help users interact with the AR-enabled physical world. Dating
back to 2001, a special head-mounted device was built by Newman to enable
AR applications [76]. Although the device looks bulky and is not ready for
massive adoption, the pursuit of AR devices and applications never stops.
With the wide popularity of sensor-enabled smartphones, the device required
for enabling the AR application is ready. Layar and Wikitude are good ex-
amples of geo-AR applications using GPS [29]. Golfscape GPS Rangeﬁnder is

Pushing Location Awareness to Context-Aware Augmented Reality
■
161
an AR range ﬁnder for Golf lovers; Cyclopedia adds Wikipedia information to
your camera view.
Another category of AR applications is using computer vision techniques
to render a character or a model on top of a reference image (marker), e.g.,
ARToolKit [41]. SnapShop Showroom provides a preview when you select fur-
niture or redecorate a room. Authors in [73] even use markers for localization
purposes. However, marker-based approaches focus on short distance appli-
cations (you can clearly see the marker in the camera view), and are not
scalable to handle large-scale navigation. Thus, using marker a is not suitable
for our intended application for displaying POI information in indoor/outdoor
environments with high freedom.
Attitude Estimation. The estimation of the camera attitude/pose could
be INS-based [125] or vision-based [14]. Chandraker et al. [14] proposed a
fully mobile, purely vision-based attitude tracking system using artiﬁcial land-
marks. The most strongly related works of attitude estimation via INS in the
literature are based on an extended Kalman ﬁlter (EKF) for military or space-
ship applications [125, 66], where the device and movement model is accurate
and stable. For less-accurate MEMS INS sensors embedded in a smartphone,
a high-order EKF model may make things worse since users’ mobility is highly
dynamic and unpredictable. Zhou et al. [134] presented A3 for smartphone-
based attitude estimation via opportunistic calibration. They achieved signif-
icant performance improvement in applications like heading estimation. As
we discussed in Section 7.3.1.1, the calibration performance is downgraded
when the smartphone constantly moves. For AR applications, we are more
interested in the dynamic performance of attitude estimation.
Displacement
Estimation.
Existing
displacement
estimation
ap-
proaches are mostly in the area of indoor localization and navigation. UnLoc
[114] leverages distinct pattern on a smartphone’s accelerometer for indoor
localization; Walkie-markie [97] realizes indoor pathway mapping via INS and
Wi-Fi. Most of these solutions for localization rely on step counting of the ac-
celerometer signatures. Step counting works in cases when the step size could
be averaged over time. For AR applications, small-scale movement is common;
ﬁne-grained model-based double integration is more appropriate. However, the
double integration process causes severe drifts and errors.
Visual odometry (VO) could be another sensing solution for displacement
[25]. Authors in [63] proposed object localization via structure-from-motion
(SfM).
Indoor Localization Smartphone/camera localization techniques, es-
pecially indoors, remain an open problem. Radio-ﬁngerprinting-based ap-
proaches [129, 52] are not suﬃcient for ﬁne-grained indoor AR applications.
The authors in [35] leveraged ultra-wideband (UWB) and INS for sensor fu-
sion. However, it is not suitable for the smartphone application, since UWB
devices are not available and too expensive. Solutions using acoustic anchors
[58] could achieve high resolution in indoor localization, but are missing essen-
tial attitude estimation and tracking techniques needed for AR application.

162
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Sensor Fusion Approach Hybrid approaches using sensors and vision
would allow us to alleviate the shortcomings of individual approaches. The
authors in [67, 43] utilized IMU-Vision synchronisation for egomotion esti-
mation in autonomous unmanned aerial vehicle (UAV) navigation. In [37],
an improved KLT feature tracking via INS assistance is proposed. A depth-
camera could also be combined with INS for tracking [23]. Authors in [83]
proposed a hybrid tracking system consisting of an active marker made by an
infrared (IR) light-emitting diode (LED), and two Nintendo Wii Remotes as
vision tracking devices. Ribo et al. [93] presented a hybrid system combing
gyro, compass, and vision sensors for self-contained tracking.
Summary of Diﬀerences With the popularity of smartphones, our by
using low-complexity sensor nodes and oﬀ-the-shelf smartphones for local-
ization and viewpoints tracking is more convenient. To further improve its
location accuracy in diﬀerent mobilities, i.e., small vibration or large moving,
we propose INS and vision fusion approaches with adaptive frame rate for
high-energy eﬃciency. Based on existing state-of-the-art solutions for image
matching and attitude estimation, we complete the whole loop of the indoor
AR application with improved smoothness and sensitivity in AR view track-
ing.
7.7
Conclusion
One of the most exciting aspects of indoor AR is that it stirs the curiosity of
customers. Service operators could create a situation in which customers will
keep looking and exploring wherever they get excited about the hidden infor-
mation. Leveraging the distinct features of the sensor-based and vision-based
approaches, we present a hybrid approach for AR applications with better ac-
curacy and eﬃciency for various mobilities. Experimental results demonstrate
signiﬁcantly reduced AR view tracking errors with modest CPU utilization.
Our future work is to address other essential problems in AR applications that
are not covered in this paper, e.g., POI database generation, impact of the POI
number, various moving speed, information visualization, camera calibration
(intrinsic matrix) for diﬀerent devices, and enabling apps for Google Glasses.
With all these key components readily available, AR applications can be re-
alized, which has signiﬁcant implications for potential innovative AR-related
applications.

Chapter 8
Towards Location-Aware
Mobile Social Networks
with Missions
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
8.1
Application Description ..........................................
164
8.2
Innovation and/or Uniqueness in Marketing ....................
165
8.3
Key Design Features .............................................
165
8.3.1
User Management .......................................
166
8.3.2
Connecting Friends and Messaging ......................
166
8.3.3
Managing Social Groups .................................
166
8.3.4
Group Auto Check-In ...................................
168
8.3.5
Sensing and Tracking Nearby Friends ...................
168
8.4
Conclusion ........................................................
169
163

164
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
8.1
Application Description
The ToGathor App and mobile social network platform is designed for users
coming, keeping, and working together. The hybrid cyber-physical social group
formed could enable interactive, reactive, and proactive interaction/activities
beyond pure physical or online social networks. We focus on two important
features of being together, i.e., location and communication, which highly
relate to the “mobile” and “social.”
The location tag, either absolute or relative, will be dynamically created
and updated according to users’ mobility and intention. Leveraging device-
to-device communication and opportunistic sensing, location-based check-in
services could be universally available in both an active and a passive way.
Check-in will not just be limited to static places like stores or restaurants,
or need intentional manual operation; any social group or user could ﬁnish
the check-in process hands-free. The only thing you need to do is to enable
the location beacon in the app, and you can be a check-in point for your
social groups or families. The app will push immediate feedback when your
member joined or got lost. You could also perform automatic attendance check
for your social group without special attendance check devices; for example,
checking students attending classes or monitoring employees’ daily arrival and
departure times to the oﬃce. You will never be too busy staring to prevent
the loss of a friend, child, or pet.
Figure 8.1: System architecture.

Towards Location-Aware Mobile Social Networks with Missions
■
165
The communication between group members could be realized in an op-
portunistic way. You can even share and communicate with your nearby friend
without Internet connection. We combine device-to-device communication and
Internet communication in an opportunistic way, such that you can send and
receive message/media or any other information with your nearby friends with-
out worrying about the intermediate Internet connection loss. Your friend
status will be extended from simple “online” and “oﬄine” to multiple levels:
nearby active, nearby inactive, online and nearby, online but not nearby, oﬄine
with meet notiﬁcation, nearby with lost notiﬁcation, and other combinations.
Sharing your business card with a new friend, reminding you of the nearby
old friend, or exchanging photos/videos taken during events will become super
easy with the nearby “sense” of the app. The messaging module will keep you
and your friends connected before/during/after the event; the cloud storage
module will memorize all of your exciting moments.
8.2
Innovation and/or Uniqueness in Market-
ing
■
Check-In-Related Apps: Foursquare, ShopKick, Gowalla, Google
Latitude, et al. These are mobile apps that allow users to check in
to any ﬁxed locations — cafes, stadiums, shopping malls, restaurants.
Sometimes they oﬀer game-like “rewards” for users who perform check-
in. Our app extends the check-in concept for any places and groups
with/without real location information. You can create a check-in
point, and your friends or families could check-in to join social events
together; schoolteachers could open the app and set up a check-in point
in class for the students who attend; company managers could monitor
their employees’ arrival and departure times.
■
Mobile Message Apps: Whats-App, iMessage, Google Talk, Skype,
WeChat, et al. These messaging apps connect you with your friends, for
sharing your exciting moments. We extend Internet-based messaging to
nearby location, and enable ﬁne-grained status checks for your friends.
We deliver your exciting news in a best-eﬀort way; we store your happy
moments in the cloud for you to access at any time.
8.3
Key Design Features
ToGathor is designed from the ground up to help you socialize and interact
with friends better. It is a unique hybrid cyber-physical mobile social network
with the following salient features: connecting friends socially and physically,
mission-oriented groups, tracking nearby friends or team members, or chil-
dren/elders.

166
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
8.3.1
User Management
The ﬁrst part of the ToGathor App is user management. We provide interface
to easily sign people up to our cloud service. In the Sign Up view, as shown in
Fig. 8.2, we only need a user’s email address and user name information for
registration.
Figure 8.2: User management.
8.3.2
Connecting Friends and Messaging
We provide a dedicated Contact view for users to manage their contacts, as
shown in the ﬁrst page of Fig. 8.3. To add or search for friends, we only need
to click the upper-right button to explore online friends.
By clicking the friend cell in the Contact view, more details of the friend
will be presented. We could click friends with similar interests, and click “add”
to add a friend into our contact list. We also could click “Start Conversation”
to start messaging with friends via opportunistic ad hoc links that can survive
without WiFi/4G connections. Currently, we could send text message and
location data to our friends. Other media data, e.g., audio, video, photo, ﬁle,
will be implemented later. A timeline view of events will also be implemented
in the near future.
8.3.3
Managing Social Groups
Coming together is not only for two friends, but for a group. The concept of
group is not limited to online social groups, but also for physically co-located

Towards Location-Aware Mobile Social Networks with Missions
■
167
Figure 8.3: Contacts and mobile messaging between friends.
groups, e.g., company employees, students attending the same class. The group
detail view as shown in Fig. 8.4 contains group members, and other group
properties. Adding and removing a group is easy and just requires clicking
the ﬁrst button on the bottom. Users can search groups online and create a
new group.
When creating a new group, the group can have a password, and request
other users to enter the password when joining the group. One important
feature is to enable auto check-in and create location-enabled groups. A normal
group without auto check-in is similar to current online groups.
Figure 8.4: (a) Group detail; (b) add and search group; (c) new group;
(d) search groups.

168
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
8.3.4
Group Auto Check-In
For location-enabled groups, the group owner could enable beacon broadcast
to advertise the existence of this group by turning on the switch as shown
in Fig. 8.5. Group members can enable group auto check-in by enabling the
“Auto Check-in” switch in the group detail view page.
When the “Auto Check-in” switch is turned on, the user’s smartphone
would perform low-power and low-cost Bluetooth-Low-Energy (BLE) scanning
by following the Apple iBeacon speciﬁcation. This enables beacon detection
even when the smartphone is in the background. When the user’s smartphone
has detected the group owner’s beacon signal, it will push notiﬁcation to the
user and automatic send a remote check-in message to the group’s owner so
that users and the group owner could know who is already checked in to the
group, i.e., nearby members in proximity.
The applications of the group auto check-in can be automatic member
check-in for students in a class, tourists in a group, friends at a party, or any
other scenarios that involve a group of friends, making our life smarter.
Figure 8.5: (a) Enable group beacon; (b) enable auto check-in; (c) auto
post check-in to group; (d) sharing location.
8.3.5
Sensing and Tracking Nearby Friends
ToGathor not only connects you with friends online, but also provides physical
proximity and location sensing capability. Imagine when we go outside with
our friends or family members, we have to pay attention to our group members’
locations to prevent members getting lost, especially for children who are more
likely to wander around. With this design goal in mind, we enable BLE ranging
and tracking in a smartphone, and trigger alerts when a member is just about

Towards Location-Aware Mobile Social Networks with Missions
■
169
out of sight. One important requirement is that the ranging and tracking
process should also work when ToGathor is not active, and without Internet
connection.
As shown in Fig. 8.6, we designed and implemented the BLE background
tracking functionality into ToGathor. We can scan our nearby friends via BLE
beacon, and request friend tracking by sending a request via the BLE commu-
nication channel. After receiving acceptance from the friend, our smartphone
tracks our friend and pushes notiﬁcation when our friend is lost. Ranging in-
formation, e.g., the BLE RSS, is utilized to estimate the distance and perform
lost alerts.
Figure 8.6: (a) Sense friend nearby; (b) friend received request; (c)
rReceived acknowledgement from friend; (d) tracking friend.
8.4
Conclusion
The ToGathor app is designed from the ground up for users coming, keep-
ing, and working together with common interests or missions. The ﬁve ba-
sic functionalities of the current version are user management, connecting
friends and messaging, managing social groups, group auto check-in, and
sensing and tracking friends. ToGathor-enabled hybrid cyber-physical social
groups could dramatically enhance interactive, reactive, and proactive interac-
tion/activities, e.g., sensing and auto-check-in, that are beyond current online
social networks. Focusing on two important features of being together, i.e.,
location and communication, we provide basic modules that are dedicated
for “mobile” and “social.” ToGathor acts as a platform for future mobile so-
cial network applets (through in-app “purchase” or third-party plugins) with
support in terms of friend and group management, in-app messaging and no-
tiﬁcation, and location-based auto-check-in and nearby sensing.


Chapter 9
Wearable Localization via
Mobile Crowd Sensing
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
9.1
Introduction ......................................................
172
9.2
System Overview .................................................
174
9.2.1
Design Considerations ...................................
174
9.2.2
System Design ...........................................
175
9.3
Mobile Crowd Sensing via Multi-Hop Assistance ................
177
9.3.1
Models and Protocols ....................................
177
9.3.2
Balance the False-Alarm and Detection Rates ..........
178
9.3.3
Crowd Localization ......................................
179
9.4
Improving Crowd Sensing Accuracy via Semideﬁnite
Programming ....................................................
182
9.4.1
Challenges ...............................................
182
9.4.2
Cases of Insuﬃcient Measurements .....................
183
9.4.3
Problem Formulation for Crowd Sensing SDP ..........
185
9.4.4
Location Optimization via Semideﬁnite Programming .
185
9.4.5
Virtual Anchor Assistance ...............................
187
9.5
Evaluation ........................................................
188
171

172
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
9.5.1
Simulation ...............................................
188
9.5.2
System Implementation .................................
189
9.5.3
Experiment ..............................................
191
9.6
Related Work ....................................................
193
9.7
Conclusion ........................................................
196
9.1
Introduction
Losing their beloved child is the worst nightmare for every parent. Sometimes
after you turn around for just a few seconds, your child is gone when you turn
back. If you are at home or some less-crowded small regions, you probably can
ﬁnd your child in some corner or in the immediate vicinities. But for public
areas, like shopping malls, streets, or even your child’s favorite Disney World,
it is hard to ﬁnd your child in crowds when lost.
There are so many reasons for your child to get distracted and wander,
then get lost. In places like Disney theme parks, there is simply so much to see,
and so many people attending, especially for events like fast-paced parades.
Even if your child doesn’t typically wander, kidnapping could happen, making
it even harder to ﬁnd your child. Guarding a child in crowded places full of
attractions is nontrivial; locating your lost child is mission impossible.
Normal approaches include writing your phone number on a shoe tag or
sticker of your child; or go to your designated meeting place, if you have one
or your child could do that. You also can look at the closest locations that
are of interest, or go to the baby center to locate a lost child found by others.
However, this manually blind searching is not eﬃcient. Giving your “big kids”
a cell phone could be a high-tech approach, but most cases they are not old
enough to carryone.
To ﬁnd your child quickly if you are separated, lots of systems and ap-
proaches have been developed. One kind of approach is using GPS locator
that is installed on your child’s shoes or clothes, e.g., Amber Alert GPS,
PocketFinder, AT&T Family Locator [21]. This kind of device includes GPS
and cellular communication modules. One problem for this kind of locator is
that it is high cost and bulky. GPS and cellular communication are all ex-
pensive and power hungry, especially when they work in continuous mode.
Providing suﬃcient battery life for one day’s use could result in a bulky and
heavy device, not suitable for little kids to carry. For indoor places like castles
and shopping malls, GPS may suﬀer signiﬁcant performance degradation or
even not work due to the signal blockage.
Another category of approaches relies on devices with peer-to-peer com-
munication capabilities. The transmitter and receiver pair, or smartphone and
peripheral pair, are carried by parents and child, respectively. If the child goes
out of the communication range or predetermined threshold, parents will get
an alert. This kind of approach leverages the existing low-power communica-
tion standard and could be made with high eﬃciency in power, and portable

Wearable Localization via Mobile Crowd Sensing
■
173
in size, e.g., Toddler Tag Child Locator, Keeper 4.0, Chipolo [17]. A drawback
of this approach lies in its lacking absolute location information, e.g., GPS
location. It is impossible for parents to locate their child when the child goes
out of the communication range.
In this chapter, we propose crowd sensing solutions for locating the lost
child, using low-power and miniature wearable devices without high cost cellu-
lar and GPS modules. To solve the coverage and localization problems of wear-
able devices, we focus on the investigation of nearby “crowds” of smartphones
for transparent ranging and locating via peer collaboration. State-of-the-art
approaches leverage connection information to detect the presence of wearable
devices in a speciﬁc region near to one participator. However, the resulting
searching area of the obtained location resolution still makes it hard for par-
ents to pinpoint their children in crowds, e.g., 20-meter peer-to-peer distance
could exaggerate the initial location error surface to thousands of square me-
ters. Instead of just relying on the single connection information, we propose
opportunistic localization approaches to derive the absolute location of the
wearable tag via multi-hop assistance for covering more participators. Even
with no suﬃcient measurements from the immediate surroundings, joint esti-
mation solutions via semideﬁnite programming (SDP) could achieve a global
relaxed optimal solution for the lost child (wearable tag). To solve the bias
error and unsolvable problems caused by sparse crowd measurements, con-
ventional SDP problems are reformulated by jointly optimizing the multi-hop
ranging and coarse-grained location measurements. We introduce a virtual an-
chor from participators with better measurements, and utilize this “anchor”
location to assist the localization of the true target, i.e., wearable tag on a
child. Detailed simulation and experimental results are presented to evaluate
the performance. In summary, our main contributions are as follows:
■
We propose a system architecture for smartphone-based transparent
crowd localization with high-energy eﬃciency and location resolution;
we develop a portable and low-cost wearable tag based on Bluetooth
Low Energy (BLE) that could be embedded in kids’ clothing or shoes
with long operating time.
■
To solve the problem of insuﬃcient measurements available among im-
mediate nearby collaborators, we perform joint location optimization
via multi-hop opportunistic communication and ranging.
■
We propose semideﬁnite relaxation for location optimization under var-
ious unreliable sources in crowd sensing, which could overcome the
over-ﬁtting problem and large errors, and ensure best-eﬀort solutions.
■
By evaluating the connection topology of the wearable tag (target) and
nearby peers, we identify the localizable peers as virtual anchor, and
perform back propagation to assist the target localization.

174
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
9.2
System Overview
9.2.1
Design Considerations
Despite substantial research on the localization, why is locating a
child still an unsolved problem? The popularity of GPS-enabled devices
and smartphones makes us take locating any object for granted, although
we have been somewhat surprised and exhausted when we cannot locate our
beloved ones. When the GPS and cellular communication-enabled devices are
not cost-eﬀective and prevalent, tracking any objects without bulky devices
and a cellular subscription fee is impossible. Tiny devices based on peer-to-peer
communication, e.g., BLE, Zigbee, WiFi, cannot obtain location information
without infrastructure or ﬁngerprinting data from site survey.
From the literature, most papers on localization have attempted to solve
this problem in terms of accuracy improvement under speciﬁc settings, i.e.,
without infrastructure. Both settings have their distinct drawbacks, especially
when the measurement comes from various unreliable sources. Solutions us-
ing acoustic anchors [58] could achieve centimeter-level resolution at low cost,
but only work in small areas with infrastructure. For real cases without in-
frastructure, the central server cannot even collect suﬃcient measurements,
not to mention perform localization via trilateration. Fingerprinting-based ap-
proaches [129, 52] cannot work without site survey, and suﬀer the problem of
collecting RSS ﬁngerprinting data when the child is already lost. Liu et al.
[56] propose location optimization approaches via peer-to-peer ranging with-
out infrastructure. However, this approach requires initial location from the
GPS module, which does not exist in our application.
Why not give kids GPS-enabled smartphones? For most cases, GPS-
enabled smartphones with cellular subscription to prevent them from getting
lost are expensive. Even if you can purchase one for your child, it is not
practical for every family member including your pets. Current smartphones
are still too bulky for embedding in your kid’s clothing or shoes. Your child
may not be old enough to carry one, or cannot perform correct operations
when they get lost.
Why use BLE tags; what about other devices? BLE seems; like it
is becoming the most promising solution for connecting peripherals to your
smartphone with low-cost and high energy eﬃciency. WiFi or Cellular solu-
tions are too heavy for low-data-rate applications. Zigbee and RFID are also
low-cost solutions, but not popular in current smartphones.
Why do you need crowd sensing; what’s the incentive for people
participating in ﬁnding lost children? For locating a lost child in crowds
without infrastructure and site survey, collecting measurement data via nearby
ubiquitous sensor-rich smartphones becomes a ﬂexible and cost-eﬀective so-
lution. The powerful computing/communication capacities of nearby smart-
phones, huge population in crowds, and the inherent mobility makes mobile
crowd sensing (MCS) a fast-growing consumer-centric sensing paradigm.

Wearable Localization via Mobile Crowd Sensing
■
175
Incentive mechanism design is one of the key components in MCS. Par-
ticipatory sensing should be performed in a transparent, energy- and privacy-
preserving way; otherwise users are reluctant to release sensor data. We pro-
pose solutions for the background processing of sensory data only for a limited
time period. The uploaded data from a smartphone utilizes pseudo-ID that is
irrelevant to users’ personal identiﬁcation. Moreover, helping others locate a
lost child earns “credit,” which you can spend when you need crowd sensing
services in the future. This could be a beneﬁcial environment for locating the
child, and in turn provides incentives for participation.
Why do you need multi-hops and opportunistic connection? We
cannot assume that there are enough participators nearby with suﬃcient mea-
surements, e.g., GPS location and ranging results. To enable target localiza-
tion in real cases, we need to leverage multiple sources and perform oppor-
tunistic connection. One-hop or multi-hop assistance could make the target
localizable and provide suﬃcient performance improvement.
9.2.2
System Design
Fig. 9.1 shows the key building blocks and connections underlying the “Find-
ingNemo” system for kids or other family members, including pets. The overall
“FindingNemo” system has three main modules, namely: (1) Wearable Tag
installed on the child’s belongings, (2) Smartphone App for social networking
and crowd sensing, and (3) Cloud Server for aggregating all the crowd-sensed
measurements and performing global location optimization.
Figure 9.1: System architecture.

176
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Leveraging the low-power and portable features of the wearable tag, par-
ents could place one tag on their beloved ones, paired with their smartphone.
If the child goes outside of the warning threshold, the smartphone could wake
up automatically and post an alert immediately to prevent the child from
getting lost. If the child is already lost, our developed App “FindingNemo”
installed in nearby users’ smartphones could receive notiﬁcations when the
“lost” child is passing or nearby. To locate the child, opportunistic communi-
cation and ranging is performed with nearby peers without GPS location in
a transparent way, without disturbing the users. Depending on the available
measurements, one-hop or multi-hop conﬁguration is automatically selected
for the best-eﬀort localization.
Wearable Tag. We designed a wearable tag from scratch based on the
BLE technique, as shown in Fig. 9.1, which is dedicated for child or family
member tracking and locating. BLE devices could directly communicate with
users’ smartphones without additional hardware attachments. It is convenient
for users to use their personal smartphones to locate the BLE peripherals at-
tached to their child’s clothing or shoes. The energy eﬃciency and miniatur-
ization of BLE peripherals make it perfect for tracking the child continuously
without signiﬁcant degradation of the battery life of parents’ smartphones.
Compared with existing solutions, e.g., Keeper 4.0, Chipolo [17], we provide
additional features that include loss detection, dual mode operation (connec-
tion and broadcast), heterogeneous power source, portability, low-power via
auto-sleep, UUID hiding for preserving privacy, and secure pairing and au-
thentication.
FindingNemo App. We designed a mobile social network from the
ground up to enable social crowd sensing. The user base and incentive are
the two major problems of crowd sensing/sourcing. With a better-designed
mobile social network app or framework that could be embedded in other
apps, e.g., Disney’s oﬃcial app, or Facebook, suﬃcient users could be accu-
mulated and leveraged to enable crowd sensing. The dedicated mobile social
network could make the social collaboration process more convenient.
The FindingNemo App continuously tracks the wearable tag even in sleep
mode, with a low-duty cycle for better energy eﬃciency. If the feedback signal
from a wearable tag is lost for a period of time, the app will be launched to the
front and the “lost” alert will be sent to the user. Performing background BLE
scan and tracking in an app is lightweight. Evenif the app is switched oﬀfrom
the background, the OS could still launch the app automatically when the BLE
notiﬁcation is received. The native support from modern mobile OS provides
an essential reason for using BLE for child tracking. This feature could make
the participatory sensing process transparent to users, and perform all the
tasks in the background when necessary and as notiﬁed by the beacon. We
apply constraints in terms of total active interval and power cost when the
participator’s app is being woken up, and perform localization.
Cloud Server. Due to the inconsistent, error-prone, and opportunistic
features of crowd sensing, one central cloud server for optimizing all the avail-

Wearable Localization via Mobile Crowd Sensing
■
177
able measurements is necessary. Most algorithms proposed in this chapter
run on this cloud server. The cloud server consists of the pub/sub messaging
module (Kafka), the stream processing module (Storm), and the persistent
datastore with eﬃcient writing/reading and ﬂexible query mechanisms (Cas-
sandra) [101, 39, 13].
9.3
Mobile Crowd Sensing via Multi-Hop As-
sistance
9.3.1
Models and Protocols
Figure 9.2: FindingNemo protocol.
Family Group As shown in Fig. 9.1, we deﬁne the family group as a virtu-
ally connected unit via peer-to-peer communication channels. The smartphone
and the wearable tag are necessary components for connecting this group. The
family’s leader could initialize this group by adding all of its nearby devices
via pairing. The family leader needs to use the smartphone with BLE func-
tionality, and install our mobile social network app. The family member could
use either a smartphone (with BLE functionality and “FindingNemo” app)
or a wearable tag. Users could give big kids a smartphone, and give wearable
tags to little kids and pets.
Normal Mode In the initial stage, each group member advertises its
unique UUID and waits to be connected, as shown in Fig. 9.3. The group
leader could add all of its members via BLE connection and authentication.
After all the members are joined in the group created by the group leader, all
the members will transmit its unique UUID along with meta data as the “heart

178
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
beat” signal to the leader via BLE connection mode. The smartphone of the
group leader could receive this “heart beat” signal and reply with a response.
The received signal strength (RSS) is monitored as the closeness indication.
If the RSS value is higher than the predeﬁned threshold, no members are lost.
The RSS monitoring will continue and the system state is kept in normal
mode.
Prevention Mode If the RSS value is lower than the threshold, the “Find-
ingNemo” app will enter into prevention mode. The wireless environment is
highly unstable, and the RSS value’s being low or lost does not necessary
mean one of the group members is lost. The app needs further information
to determine the current status of the family member. Outlier detection with
RSS historical values is performed to minimize false alarms. If the RSS value
continues to decrease or even is lost, the app running in the group leader’s
smartphone will push alert notiﬁcation to prevent the member from being lost
as shown in Fig. 9.3. This immediate alert could remind the leader to check
their members around, and prevent some members going further away.
SOS Mode For the wearable tag or the member’s smartphone, it will re-
scan the nearby BLE beacon and try to re-connect to the leader’s smartphone.
If the lost BLE connection to the group leader could not be re-established, and
none of the other members’ BLE heartbeats scanned and captured within a
pre-deﬁned time period, it will enter into SOS mode to broadcast its existence
using special SOS UUID.
9.3.2
Balance the False-Alarm and Detection Rates
Early Losts Prevention. In Fig. 9.3, the leader’s smartphone would push
alert notiﬁcation if one of its members’ BLE beacons is lost or the RSS is too
weak. However, such alerts should not be too frequent since the highly unstable
BLE communication channel may cause false alarms. It will be very annoying
for users when a false-alarm happens. To minimize false alarms while at the
same time keeping the detection rate, low-complexity detection approaches
should be applied.
Predict current RSS value (ˆri) and conﬁdence interval αi, if the measured
RSS value (ri) is outside the range of [ˆri −αi, ˆri + αi], then the current
measured RSS is an outlier, further measurement is needed to determine the
closeness of group members instead of direct push alert.
Enter, Delay, and Cancel the SOS Mode For the wearable tag or
group member’s smartphone, the software program needs to determine when
to enter the SOS mode and search for help. The SOS mode could trigger nearby
participators’ smartphones to perform assistance. This triggering process in-
volves a high cost and could waste the battery power of nearby participators.
If the tag or smartphone is not highly conﬁdent that it is lost, the SOS mode
should be re-examined by using further information.
If the reply message from the leader’s smartphone is missing or the con-
nection is lost, the tag or smartphone should perform scanning again and wait

Wearable Localization via Mobile Crowd Sensing
■
179
for re-connection. Only after a pre-set timeout without any connection from
the group leader will it enter into SOS mode, and broadcast an SOS beacon.
One issue of the wearable tag is its lack of Internet connection. If the
group leader did not report the child/pet/tag lost, the transmission frequency
of the SOS beacon should be lowered to minimize the energy cost both to itself
and nearby participators. If the group leader canceled the searching/ﬁnding
process, we need to design one mechanism to make the lost tag aware of the
situation even without Internet connection and direction communication from
group leader and other members.
As shown in Fig. 9.3, we designed a crowd sensing approach that let nearby
participators relay the message from the server. When the wearable tag is in
the SOS mode, it also accepts connection from nearby participators. If one
participator received the SOS beacon, the mobile OS will wake up the Find-
ingNemo App and report the SOS beacon to the server. If the identiﬁcation
of this SOS beacon matches one item in the “Finding” table, i.e., the group
owner reported the member as lost, the participator will get a response from
the server to begin the localization process to locate the lost tag. Other cases
are: 1) If the group owner does not report the member loss, the participator
will get a response and send this information to the detected wearable tag
and let it decrease the frequency of the SOS beacon. 2) If the participator
received a “cancel” command from the server, it will connect to the tag and
send “shutdown” information to this tag. For the wearable tag, if the infor-
mation from the nearby participator is veriﬁed, it will follow the instruction
to delay or cancel the SOS beacon.
9.3.3
Crowd Localization
When the wearable tag enters into SOS mode, the nearby users with the
“FindingNemo” app will receive the SOS beacon and wake up to assist the tag
localization process. The crowd localization process is illustrated in Fig. 9.3.
The lost tag tries to reach as many participators as possible, especially the
participators with GPS information, so that the location of the tag (child)
could be estimated and reported to the server and the group leader (parent).
User Participatory Model Participators can choose to allow GPS lo-
calization assistance, or only allow communication assistance. The communi-
cation consumes far less energy than the GPS involvement. It is up to the user
whether to allow GPS to participate in the crowd sensing process. As shown
in Fig. 9.3, the users with “location” icon means the GPS location is available
for this participator, a.k.a., Anchor. Other users without the “location” icon
could participate via communication and ranging, and the sensed information
could upload to the central server opportunistically.
We model the smartphone as a navigator in the navigation coordinate
(n-frame). The n-frame is used to characterize the absolute movement of the
smartphone with respect to the indoor/outdoor environment, which is a local
geographic frame. The location from the GPS module of a smartphone is at

180
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
geodetic coordinates (latitude φ, longitude λ, height h), e.g., WGS 84 datum.
To convert the geodetic coordinates to the navigation coordinate, we ﬁrst
convert it to the earth-centered earth-ﬁxed (ECEF) coordinate, then convert
the ECEF to the ENU frame via the formula in [56]. By subtracting the
reference point OR, the GPS location is mapped to the navigation coordinate
(n-frame) for more intuitive and practical analysis.
Assume the position of the wearable tag in the n-frame is yn ∈Rd, i.e.,
2-D coordinate (d = 2) of yn. For notation simplicity, we refer to y = [x, y]T
as yn in the navigation coordinate without the superscript. When the child
is lost, the wearable tag will broadcast the BLE beacon in “SOS” mode with
the communication range as RB. Assume the nearby m-th participator within
the range RB is am, where m is the index number in total M participators.
The location of the m-th participator (a.k.a. the smartphone’s location) are
denoted as xm ∈Rd. For most of the cases, the dimension could be simpliﬁed
as d = 2, thus each element of xm is a 2-D coordinate as [xm, ym]T , m =
1, . . . , M. The location of other participators xm is unknown for most cases.
If the participator allows the app to access the GPS location, then xm could
be estimated by the GPS result as ˆxm, with the total number as Ma. Since
the GPS module is power hungry, and computationally heavier than the BLE
communication, we could not require every participator to open their GPS
location. Thus, the location of the m-th participator is denoted as ˆxm only if
available, and the set of GPS-enabled participators is deﬁned as a subset of
Rd as Rd
a.
Figure 9.3: System conﬁguration.
Accuracy Requirement for Localization. The objective of ﬁnding the
lost child via crowd sensing is to estimate y if the BLE tag goes out of the

Wearable Localization via Mobile Crowd Sensing
■
181
range of the parents’ smartphone. The high accuracy of y is more desirable,
which could result in a smaller searching region for parents. The measurements
available are the BLE RSS distance measure and the GPS location available
in the subset of participators Rd. Since the wearable tag is only equipped with
radio communication, the estimation of y without GPS is challenging.
If the wearable tag could reach one participator with location information
(xm), the value of y could be roughly estimated via the xm and the ranging
value ˆrm, where rm denotes the ground truth distance; ˆ· denotes the estimated
value. The accuracy of y depends on the distance and the accuracy of ranging
and location. For example, if the GPS location accuracy of xm is 8 meters,
the resulting search area is around 201m2. For the lost child, if rm = 20m and
the ranging accuracy of ˆrm is around 5m, the resulting search area is around
3421m2, which is a huge area for parents to search.
To narrow down the search area and make it acceptable in terms of eﬀorts,
signiﬁcantly higher accuracy of y should be obtained. Multiple participators
should be leveraged to improve the location estimation. The detailed accuracy
requirement depends on the speciﬁc environment. Typically, the accuracy of
y within several meters of tens of meters should be suﬃcient for parents to
perform manual search.
To improve the localization accuracy, multiple participators should be uti-
lized to locate the lost child, e.g., via trilateration. The distance measure from
multiple participators can be written as
ˆrm = ||y −xm||2 + δm + nm
(9.1)
where δm is the drift or bias for the BLE tag and smartphone ranging pair,
nm is the measurement noise. Each element of rm is rm = ||y −xm||2, i.e.,
from the BLE tag to the m-th participator, where || · ||2 calculates the 2-
norm and obtains the Euclidean distance. Since rm should be non-negative,
we use ˆrm = |ˆrm| to prevent the negative value due to the noise. We deﬁne the
unknown parameter vector as θ = [y]T . The localization process of relying on
multiple participators is to estimate θ by using approaches like Bayesian or
maximum-likelihood (ML) estimation techniques.
For 2-d coordinates, the number of participants with GPS location should
be Mp ≥3 for localization, a.k.a. trilateration. Since the BLE communication
only covers limited areas, the available participants with GPS location may
not meet this requirement. For the extreme cases, if none of the participants
allows releasing GPS location, the lost child could never be located. How to
locate the child with suﬃcient accuracy without enough measurements poses
a stringent challenge.
Reaching More Participators via Multi-Hop Assistance. We need
to reach more participators to get a better location accuracy, e.g., larger than
three for trilateration; however, it is hard to obtain enough measurements in
crowd sensing, especially when the nearby participators are sparse.
One possible solution is using multiple hops of communication and con-
nection to cover more participants. Speciﬁcally, if the immediate surroundings

182
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
of the BLE tag does not have enough participants with location information,
relying on the participants’ nearby as one-hop could provide a higher proba-
bility of location access. More hops could be involved for better localization
probability. Using one-hop via m′-th participant as an example, the accessible
participants with locations for the m′-th participant can be denoted as am′,n,
where n = 1, · · · , Na. The available location measurements for these Na par-
ticipants is included in vector xm′,n. Among all these second-hop participants,
the set of participants with GPS location can be written as Rd
a,m′. Thus the
measurement model can be rewritten as
ˆrm −||y −xm||2 = δm + nm,
m ∈Rd
a
(9.2)
ˆrm′ −||y −xm′||2 = δm′ + nm′,
m′ ̸∈Rd
a, m′ ∈Rd
ˆrm′,n −||xm′ −xm′,n||2 = δm′,n + nm′,n,
n ∈Rd
a,m′
where the second added equation in (9.2) means the ranging between the
BLE tag and the m′-th participant that does not contain GPS location; the
third added equation means the ranging measurements between the m′-th
participant and its own nearby accessed participants with locations. Through
this one-hop via am′, more location-enabled participants are available; the
probability of locating the target y is increased.
9.4
Improving Crowd Sensing Accuracy via
Semideﬁnite Programming
To improve the localizability and accuracy of the lost child y, we obtain more
sensing results of (9.2) by leveraging multi-hop assistance to reach more par-
ticipators. However, using all these new measurements in the localization pro-
cess is more complex than the conventional trilateration process. The involved
multi-hop assistance and sparse ranging measurement make the location esti-
mation problem highly nonlinear, nonconvex, and hard to solve.
9.4.1
Challenges
Solving Non-Convex Problem. Solving the localization problem via multi-
hop measurements in (9.2) is diﬀerent from the conventional trilateration ap-
proaches that use least squares (LS)-based methods. As shown in Fig. 9.4,
LS-based trilateration utilized the known location of anchor nodes and an-
chor in relation to mobile node ranging measurements to obtain approximate
solutions of maximum likelihood (ML) by linearizing the initial non-linear
problem. However, crowd sensing-based localization does not have enough
one-hop anchor nodes, and the available anchor locations are not accurate.
When the problem becomes complex, i.e., a self-localization application,
as shown in Fig. 9.4, LS-based approaches may converge to the local optimal

Wearable Localization via Mobile Crowd Sensing
■
183
solutions when the measurement noise is not Gaussian or the initial value in
iteration is not good. Converting the initial non-convex problem to a convex
one is a typical solution to avoid the local optimal. Among existing solutions,
semideﬁnite programming (SDP) has been demonstrated to have a tight bound
with the initial non-convex problem and tends to achieve optimal global re-
sults [117]. The SDP approach has been widely used in the sensor network
localization areas, i.e., self-localization as shown in Fig. 9.4, where the dense
inter-node ranging information is utilized to infer the location relative to the
anchor node. Usually two anchor nodes are need to resolve the 2D coordinates
of the whole network without ambiguity.
For the crowd sensing-based localization as shown in Fig. 9.4, the avail-
able ranging measurements are signiﬁcantly sparser than in conventional self-
localization problems. The available distance constraint is not suﬃcient when
applying the conventional SDP for localization.
Beyond Conventional Semideﬁnite Programming. Although con-
ventional SDP is not suitable for crowd sensing scenarios, it does provide
a technical tool for solving this non-convex localization problem. Diﬀerent
from the LS-based method that linearizes the initial non-linear problem and
requires a good initial value to ensure convergence, the SDP approach is in-
sensitive to large errors and could eliminate the problem of converging to
the local optimal. However, two stringent challenges should be solved: 1) In-
suﬃcient ranging information may render the SDP problem unsolvable; 2)
ampliﬁed location bias error when mapping back to the physical space due to
the requirement of two accurate anchor locations as base-line.
To solve the problem of insuﬃcient ranging information when applying
SDP to the crowd sensing setting, we reformulate the SDP problem by jointly
leveraging the available sparse ranging and coarse-grained location informa-
tion. Instead of relying on two anchor locations as baseline, we derive the
mapping during the location estimation by optimizing the global bias between
all the available participator locations.
The unknown location of the assistant xm′ in multi-hop relay is jointly
estimated with the target y. Denote the residue vector in (9.2) as εm = [δm +
nm, · · · ], εm′ = [δm′ + nm′, · · · ], and εm′,n = [δm′,n + nm′,n, · · · ], respectively.
We deﬁne ε as a summation of ε = [εm, εm′, εm′,n]. The vector of unknown
parameter is θ = [y, xm′].
9.4.2
Cases of Insuﬃcient Measurements
For one extreme case, if the number of participators with GPS location near
the lost child is zero, then it is unable to obtain the location y via conventional
approaches. This case can be denoted as Rd
a = ∅, and the ﬁrst constraint in
(9.10) cannot be used. If there are no participators am′ in Rd that accessed
GPS-enabled participators, i.e., Rd
a,m′ = ∅, y via (9.10) is unsolvable. Only
when Ma+Na ≥1, could y be located. Here we focus on the case of Ma+Na ≥
1, and improve the location accuracy.

184
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 9.4: The comparision of crowd sensing to trilateration and self-
localization.
Diﬀerent value of Ma. If Ma = 0, the BLE Tag is only localizable via
participator am′, which has Na ≥1. In (9.10), only the measurements ˆrm′,n
and ˆrm′ are actually utilized.
The lowest resolution case is Na = 1, assuming xm′,n1 has location avail-
able with accuracy as σGP S
m′,n1. Then the achievable accuracy of y is on the
order of
σy = σGP S
m′,n1 + ˆrm′,n1 + σr
m′,n1 + ˆrm′ + σr
m′
(9.3)
where σr
m′,n1,σr
m′ is the ranging accuracy between am′ and am′,n1, y and am′,
respectively. Through this one-hop cooperation via am′, we could locate y.
However, the accuracy of (9.3) is very high, but not suﬃcient for ﬁnding a
lost child in crowds.
Increasing the number Ma, the accuracy of y could be signiﬁcantly im-
proved. When Ma = 1, the σy could be reduced to σy = σGP S
m
+ ˆrm + σr
m.
When Ma = 2, the possible positions of y are reduced to two spots, with the
accuracy in each spot depending on σGP S
m
+ σr
m. When Ma ≥3, y could be
localized even without the one-hop assistance, where the accuracy depends on
σGP S
m
and σr
m.
Diﬀerent value of Na. If Na = 0, there will be no beneﬁt from using
this one-hop assistance. If 0 < Na < 3, the performance improvement from
this one-hop assistance is signiﬁcant when Ma is insuﬃcient for trilateration.
If Na ≥3, am′ could be localized by trilateration that is more reliable, which

Wearable Localization via Mobile Crowd Sensing
■
185
could in turn provide performance improvement, especially for cases when
Ma < 3.
9.4.3
Problem Formulation for Crowd Sensing SDP
The location objective function of θ for jointly estimating the vector of un-
known parameter θ = [y, xm′] could be written as
ˆθML = arg min
θ (
X
∀m,m′,(m′,n)
ε2)
(9.4)
= arg min
θ



X
∀m∈Rd
a
ε2
m +
X
∀m′∈Rd∩¯Rd
a
ε2
m′ +
X
∀n∈Rd
a,m′
ε2
m′,n



where the three diﬀerent constraints leverage all the sparse ranging and coarse-
grained location information. The solution ˆθML of (9.4) is optimal in the ML
sense and highly nonlinear with constraints in (9.2). Instead of using the
square errors in (9.4) that result in a non-linear problem, we modify the error
formulation as a matrix linear operation before SDP relaxation. Using the ﬁrst
equation in (9.2) as an example, we can rewrite it as ˆrm = ||y −xm||2 + εm.
Performing square operation on both sides will lead to ˆr2
m = (||y−xm||2+εm)2,
where the right side is ||y−xm||2
2+2εmT ||y−xm||2+εmT εm. εm is the variance
vector of the ranging error. Assuming ranging measurements are independent,
we will have εmT εm = 0; 2εm||y−xm||2 will be the new noise term as ε′. Thus,
for all three equations in (9.2), the location objective function can be rewritten
as
y = arg min
y
max
m,m′
||y −xm||2
2 −ˆr2
m
 +
||y −xm′||2
2 −ˆr2
m′
	
|
{z
}
ξ1
(9.5)
+ arg min
y max
m′,n
||xm′ −xm′,n||2
2 −ˆr2
m′,n

|
{z
}
ξ2
(9.5) calculates y by minimizing the maximum residual error, where the P
in (9.4) becomes max operation. Minimax approximation plays a key role in
linearizing the initial problem into linear matrix operations for semideﬁnite
relaxation.
9.4.4
Location Optimization via Semideﬁnite Program-
ming
The objective function in (9.5) can be converted to minimize ϵ at the constraint
of an inequality expression −ϵ < ξ1 + ξ2 < ϵ, while ξ1 and ξ2 are the residual
error in (9.5) for the ﬁrst and second term.

186
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
The term ||y −xm||2
2 in ξ1 of (9.5) can be written into a matrix form of
||y −xm||2
2 =

yT
1
  Id
−xm
−xT
m
xT
mxm
  y
1

(9.6)
= tr
 y
1
 
yT
1
  Id
−xm
−xT
m
xT
mxm

= tr
 Y
y
yT
1
  Id
−xm
−xT
m
xT
mxm

where Y = yT y, tr{·} calculates the trace of the matrix, and Id is an identity
matrix of order d. From step 1 to step 2 in (9.6), we utilized the property of
matrix trace tr{xxT A} = xT Ax.
Using the same process in (9.6), ||xm′ −xm′,n||2
2 in ξ2 of (9.5) can be
written into
||xm′ −xm′,n||2
2 = (xm′ −xm′,n)T (xm′ −xm′,n)
(9.7)
=
 01×d
1
−1 


Id
xm′
xm′,n
xT
m′
Ym′
Ym′,n
xT
m′,n
Yn,m′
Yn,n




0d×1
1
−1


= tr







0d×1
1
−1




0d×1
1
−1


T 

Id
xm′
xm′,n
xT
m′
Ym′
Ym′,n
xT
m′,n
Yn,m′
Yn,n







= Ym′ −Ym′,n −Yn,m′ + Yn,n
where Ym′ = xT
m′xm′, Yn,n = xT
m′,nxm′,n, Ym′,n = xT
m′xm′,n.
The forms of (9.6) are convex, but the equality constraints of Y = yT y
are nonconvex. Using semideﬁnite relaxation, these equalities can be relaxed
to inequality constraints of Y ⪰yyT . The matrix forms can be written as
 Y
y
yT
1

⪰0
(9.8)
where ⪰means a positive deﬁnite (semideﬁnite) matrix, which is diﬀerent
from ≥.
For the constraint of (9.7), equality constraints of Ym′ = xT
m′xm′, Yn,n =
xT
m′,nxm′,n, Ym′,n = xT
m′xm′,n are nonconvex. In (9.7), Ym′, Yn,n, and Ym′,n
are coupled together. Thus, the matrix forms of the SDP relaxation for the
constraint ξ2 are


Id
xm′
xm′,n
xT
m′
Ym′
Ym′,n
xT
m′,n
Yn,m′
Yn,n

⪰0
(9.9)
Using the form of (9.6), (9.7), (9.8), and (9.9), the initial problem of (9.5)

Wearable Localization via Mobile Crowd Sensing
■
187
can be formulated to a semideﬁnite programming form. The unknown param-
eter vector could be summarized as θ = [y, xm′, Ym′, Yn,n, Ym′,n]. (9.5) can
be equivalently reformulated as
minθ ϵ
s.t.
−ϵ < tr
 Y
y
yT
1
  Id
−xm
−xT
m
xT
mxm

−ˆr2
m < ϵ,
−ϵ < tr
 Y
y
yT
1
  Id
−xm′
−xT
m′
xT
m′xm′

−ˆr2
m′ < ϵ,
−ϵ < Ym′ −Ym′,n −Yn,m′ + Yn,n −ˆr2
m′,n < ϵ
 Y
y
yT
1

⪰0,


Id
xm′
xm′,n
xT
m′
Ym′
Ym′,n
xT
m′,n
Yn,m′
Yn,n

⪰0
(9.10)
where m ∈Rd
a, m′
∈Rd ∩¯Rd
a, and n ∈Rd
a,m′. The location of the
lost child (wearable tag) y can be extracted from the solution of θ =
[y, xm′, Ym′, Yn,n, Ym′,n], where y is optimal in terms of all the available
measurements.
9.4.5
Virtual Anchor Assistance
During the SDP optimization of (9.10), the location of am′ is used as an
unknown parameter in θ as xm′. To utilize the feature that xm′ is accurate
and reliable when Na ≥3, the estimated result of ˆxm′ from (9.10) could be
used as a virtual anchor that optimizes the location result of ˆy, and obtains
an optimized value of ˆyop.
After the process of (9.10), the obtained ˆxm′ could be used to con-
struct a new vector of nearby anchor points as zma = [xm
ˆxm′], where
ma = 1, · · · , Ma +1. The ranging measurement vector could be reconstructed
as rma = [ˆrm
||ˆy −ˆxm′||2]. Another step of optimization via the newly con-
structed anchor vector zma could be executed by relying on the minimization
of residual error ϵ with the unknown parameter as θ = [yop
Yop], where
Yop = yT
opyop. The constraint of this reﬁnement could be written as
−ϵ < tr
Yop
yop
yT
op
1
  Id
−zma
−zT
ma
zT
mazma

−r2
ma < ϵ
(9.11)
For some cases, the reﬁned result of yop may suﬀer performance degradation
than the initial result of ˆy due to the large error of the virtual anchor. Thus, a
threshold-based detection process needs to be applied to mitigate the virtual
anchor with low-conﬁdence.

188
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
9.5
Evaluation
To illustrate the eﬀectiveness of our proposed approach, we compare our pro-
posed SDP-based cooperative location optimization proposed in (9.10) (“SDP-
C”) with a conventional LS-based approach (“Initial”). Approaches that using
virtual anchor via LS and SDP are denoted as “SDP-C-VAL” and “SDP-C-
VAS,” respectively. We use average location error (ALE) as the performance
metric. Simulation and experimental evaluation are conducted.
9.5.1
Simulation
Suﬃcient for trilateration. When the number of nearby participators with
GPS location (anchors) is suﬃcient for trilateration, i.e., Ma ≥3, we con-
duct simulation to evaluate the performance improvement contributed by the
one-hop assistance. Fig. 9.5(b) shows the simulation results when the anchor
error is added by σ2 = 2.25m. In this case, the performance improvement con-
tributed by the one-hop assistance is limited. Therefore, if Ma ≥3, we could
directly utilize the location of participators without leveraging multi-hops.
−10
0
10
20
30
0
1
2
3
4
5
6
1/σ2 (dB)
ALE (m)
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(a) No Anchor Error
−10
0
10
20
30
0
1
2
3
4
5
6
7
1/σ2 (dB)
ALE (m)
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(b) With Anchor Error
Figure 9.5: Localization accuracy via one-hop when Ma = 3 and Na = 3
for cases (a) without anchor error; (b) with anchor error (σ2 = 2.25m).
Insuﬃcient for trilateration. When the number of anchors near the
BLE tag is suﬃcient for trilateration, i.e., Ma < 3, the location of the BLE
tag cannot be determined without ambiguity as in the case of “Initial” shown
in Fig. 9.6 and Fig. 9.7. No matter how accurate the ranging result is, the
accuracy shows no improvement due to the ambiguity in determining the
location. After using one-hop assistance, the location of the BLE tag could be
determined and the accuracy improves with better ranging results.

Wearable Localization via Mobile Crowd Sensing
■
189
In Fig. 9.6, where Ma = 2 and Na = 3, the performance improvement of
our proposed SDP-based approaches over the “Initial” is signiﬁcant. When
Na = 3, the location estimation result for the assistant node is reliable, and it
could be utilized as a virtual anchor for further performance improvement.
−10
0
10
20
30
1
2
3
4
5
6
7
1/σ2 dB
ALE (m)
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(a) No Anchor Error
−10
0
10
20
30
0
2
4
6
8
1/σ2 dB
ALE (m)
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(b) With Anchor Error
Figure 9.6: Localization accuracy via one-hop when Ma = 2 and Na = 3
for cases (a) without anchor error; (b) with anchor error (σ2 = 2.25m).
No virtual anchor available. When the number of accessed anchors of
the assistant m′ is Na < 3, i.e., insuﬃcient for trilateration. The performance
improvement is only contributed by leveraging all the measurements in SDP
optimization. Fig. 9.8 shows the localization accuracy under diﬀerent cases
via one-hop assistance with anchor location errors. The achieved improvement
over the “Initial” case is huge, and in turn demonstrates the eﬀectiveness of
SDP optimization even without virtual anchor assistance.
9.5.2
System Implementation
The fundamental requirement of crowd sensing is the suﬃcient user base. In-
corporating the crowd sensing functionality into the mobile social network
could be a feasible solution to improve the number of participators. We im-
plement the FindingNemo functionality into the mission-based mobile social
network ToGathor. As shown in Fig. 9.9, we implemented the social func-
tions of: 1) add nearby wearable tag or smartphone; 2) friend lost and ﬁnd
friend again; 3) location-aware social groups; 4) track group members and
sense nearby. Adding these modules on top of the existing functions of a mo-
bile social network, e.g., basic user proﬁle/account, message, could push the
crowd sensing/sourcing task to the large scale societal level.

190
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
−10
0
10
20
30
0
5
10
15
20
1/σ2 (dB)
ALE (m)
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(a) No Anchor Error
−10
0
10
20
30
0
5
10
15
20
1/σ2 (dB)
ALE (m)
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(b) With Anchor Error
Figure 9.7: Localization accuracy via one-hop when Ma = 1 and Na = 3
for cases (a) without anchor error; (b) with anchor error (σ2 = 2.25m).
−10
0
10
20
30
0
5
10
15
1/σ2 (dB)
ALE (m)
 
 
SDP−nR
SDP−C
(a) Ma = 1, Na = 1
−10
0
10
20
30
0
5
10
15
1/σ2 (dB)
ALE (m)
 
 
Initial
SDP−C
(b) Ma = 1, Na = 2
−10
0
10
20
30
0
2
4
6
8
1/σ2 (dB)
ALE (m)
 
 
Initial
SDP−C
(c) Ma = 2, Na = 2
Figure 9.8: Localization accuracy via one-hop with anchor location error
(σ2 = 2.25m) for three cases.
To improve the incentive for users’ participation, one possible direction is
to lower the user participating cost and improve the convenience. We propose
to realize transparent participation in that all the tasks are done when the
smartphone is in the background. Performing a background BLE scan and
tracking in an app is lightweight. The latest version of iOS can handle this
process via the OS, i.e., through iBeacon API. Evenif the app is switched oﬀ
from the background, the OS could still launch the app automatically when
the BLE notiﬁcation is received. Google also released this nearby notiﬁcation
functionality in 2014 Google I/O. The native support of the nearby notiﬁca-
tion from modern mobile OS provides an essential foundation for transparent
mobile crowd sensing. When the BLE connection is lost, the background app
could be waked up and send notiﬁcation to the group leader. This native OS
support also enables transparent crowd sensing for locating the child. If the

Wearable Localization via Mobile Crowd Sensing
■
191
Figure 9.9: Basic functions of FindingNemo App.
child is lost, nearby peers’ smartphones installed with “FindingNemo,” even
in sleep mode, could be notiﬁed when the SOS alert is nearby. The app will
be launched automatically after receiving this beacon, and the opportunistic
communication and ranging via BLE will be performed in the background.
After ﬁnishing the crowd sensing process, the participating smartphone will
sleep again to save the battery life.
9.5.3
Experiment
Experiment Setting. Similar to the conﬁgurations in a simulation evalua-
tion, we conducted an experiment to evaluate the system performance with
diﬀerent connectivity of nearby participators in diﬀerent environments, as
shown in Fig. 9.10. The location accuracy of participators is measured in
diﬀerent locations with diﬀerent smartphones. As shown in Fig. 9.11(a), the
obtained location error ranges from 2 meters to 15.4 meters with heteroge-
Figure 9.10: Developed system and experiment setting.

192
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
0
5
10
15
20
25
0
0.2
0.4
0.6
0.8
1
Error (m)
CDF
 
 
1
2
3
4
5
6
7
2
4.4
3.2
15.4
8.3
(a) GPS Error
0
5
10
15
20
25
0
2
4
6
8
10
Distance (m)
Error (m)
 
 
Front
Right
Left
(b) Ranging Error
Figure 9.11: 1) The CDF of the GPS error; 2) the ranging error with
distance.
neous error distribution. The BLE ranging error versus the distance is shown
in Fig. 9.11(b). We put the wearable tag in diﬀerent angle directions, i.e.,
front, right, and left, for comparing the ranging performance. The overall lo-
cation and ranging error is very large, and insuﬃcient to locate the lost child
if it only relies on one participator.
To emulate the situation of ﬁnding the lost child via multiple participators,
we let one volunteer wearing the wearable tag perform random walking. Other
volunteers acted as participators, and randomly moved around. We deﬁned the
number of participators with one-hop to the wearable tag as Ma; the number
of participators with two-hop communication to the wearable tag via assistant
as Na. Various experiment conﬁgurations of Ma and Na were conducted.
The BLE RSS ranging is performed similar to [56], where the accuracy is
in the meter-level. The key problem of our proposed “FindingNemo” is relying
on these inaccurate ranging results to localize the “unlocalizable” target, or
solving the location ambiguity problem. Our goal is to achieve large accuracy
improvement rather than struggling to slightly improve the ranging accuracy,
since several meters of ranging diﬀerence does not matter too much when
searching for the child.
Suﬃcient for Trilateration. When the number of nearby anchors is suf-
ﬁcient for trilateration, i.e., Ma ≥3, the experimental results under diﬀerent
cases are as shown in Fig. 9.13. Similar to the conclusion obtained in simula-
tion, performance improvement in this case is minimal. But it is still beneﬁcial
to utilize the one-hop assistance when Ma ≥3. When the number of Na is
reduced from 6 to 3, the performance diﬀerence is not apparent when Na ≥3.
Insuﬃcient for Trilateration. When Ma < 3, we cannot localize the
BLE tag without ambiguity via conventional methods. In real applications

Wearable Localization via Mobile Crowd Sensing
■
193
0.9
0.7
0.5
0.3
0.1
0
5
10
15
20
25
30
Sparse Rate
Error (m)
 
 
50% Error
80% Error
95% Error
(a) Conventional SDP
1
2
3
4
5
0
1
2
3
4
5
Cases
Error (m)
 
 
50% Error
80% Error
95% Error
(b) Proposed Approach
Figure 9.12: Localization error for: 1) conventional SDP with diﬀerent
ranging sparse rates; 2) proposed SDP approach for crowd sensing in
diﬀerent cases.
of locating the lost child, Ma is actually small for most of the cases. Lever-
aging the multi-hop and SDP-based optimization, we could make the target
localizable and dramatically reduce the location error.
Fig. 9.14 shows the CDF of the ALE results when Ma = 2, Na = 3 for
diﬀerent cases when the virtual anchor is utilized. The proposed “SDP-C-
VAS” achieves best performance over most cases.
Fig. 9.15 shows the CDF of the ALE results when Ma = 2, Na = 2 for
diﬀerent cases, where the virtual anchor cannot be utilized. Even without a
virtual anchor, the performance improvement of using SDP optimization is
still apparent.
When the number of accessed anchors Ma is reduced to 1, the error of
“Initial” is very large, as shown in Fig. 9.16. When the number of Na increases
from 1 to 3, we can clearly see the performance improvement of using one-hop
assistance, especially when the virtual anchor can be utilized.
When Ma = 0, the location of the target cannot be determined via “Ini-
tial,” i.e., “NaN” for the ALE as shown in Table. 9.1. When leveraging one-
hop assistance, the target could be localized. Table. 9.1 shows the ALE results
when the number Na is changed from 6 to 1. Due to very limited measure-
ments, the achieved accuracy of around 15m to 4.9m is suﬃcient, and really
helps when searching for the child.
9.6
Related Work
To prevent your child from getting lost or to ﬁnd your lost child if already
separated, lots of systems and approaches have been developed. Conventional

194
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
5
10
15
20
25
30
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(a) Ma = 3, Na = 6
5
10
15
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(b) Ma = 3, Na = 3
Figure 9.13: Experimental localization accuracy via one-hop for two cases.
Table 9.1: Experimental localization accuracy via one-hop when Ma = 0
Initial
SDP-C (m)
SDP-C-VAL (m)
SDP-C-VAS (m)
Na = 6
NaN
6.9105
6.9105
4.9471
Na = 3
NaN
7.0643
7.0643
4.9710
Na = 2
NaN
9.7185
9.7185
9.7185
Na = 1
NaN
15.0772
15.0772
15.0772
approaches include guarding your child carefully or continuously keeping an
eye on your child. But none of us could make sure that we would never get dis-
tracted, especially in places full of attractions. If the child is already lost, call-
ing 911 or manually searching is labor-intensive. High-tech approaches include
purchasing a GPS locator, and subscribing to a cellular service, e.g., Amber
Alert GPS, PocketFinder, or AT&T Family Locator [21]. However, GPS and
cellular are high cost in terms of energy consumption and hardware/service
investment. Low-cost peer-to-peer communication devices with transmit and
receive pairs are utilized to prevent child or pet loss, e.g., Toddler Tag Child
Locator, Keeper 4.0, Chipolo [17]. However, all these approaches work only
when the tag is within the communication range. If the tag is already lost,
these approaches fail to provide any location or direction information to ﬁnd
the lost tag.
For open places without infrastructure, using crowds of mobile smart-
phones as the virtual localization infrastructure could be a feasible approach
for ﬁnding the lost child. Crowd sensing is suitable for tasks that are hard,
costly, or infeasible to ﬁnish without collaboration [46, 27]. When extended
to mobile areas, the sensor-rich personal smartphone becomes the central of
future MCS applications. Unleashing the potential of large-scale sensing, re-
searchers propose solutions in terms of system architecture and algorithms to

Wearable Localization via Mobile Crowd Sensing
■
195
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
(a) Ma = 2, Na = 3
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
SDP−C
Initial
SDP−C−VAL
SDP−C−VAS
(b) Ma = 2, Na = 3
Figure 9.14: Experimental localization accuracy via one-hop for two cases.
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
SDP−C
Initial
(a) Ma = 2, Na = 2
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
Initial
SDP−C
(b) Ma = 2, Na = 2
0
10
20
30
40
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
Initial
SDP−C
(c) Ma = 2, Na = 2
Figure 9.15: Experimental localization accuracy via one-hop for three
cases.
enable various speciﬁc applications. For example, mCrowd [126] is a system
architecture for continuously sensing with high energy eﬃciency; the authors
in [61] balance the performance needs of the application and the resource
demands of continuous sensing on the phone. Wang [116] proposed a frame-
work for an energy-eﬃcient sensing strategy to recognize user states as well
as to detect state transitions by powering only a minimum set of sensors.
Crowd sensing-based applications are also emerging, e.g., the authors in [135]
developed an application to predict the bus arrival time with mobile phone-
based participatory sensing. Sensing the user’s activity or surroundings via
accelerometer, microphone- and GPS sensors becomes a hot topic of crowd
sensing in [60, 69]. However, all these proposed sensing tasks are individual-
based monitoring and loosely coupled between diﬀerent participators.
Locating the lost child via MCS requires high coupling and collaboration
between participators, in which the peer-to-peer measurements are key to the

196
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
0
10
20
30
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
SDP−C
Initial
(a) Ma = 1, Na = 1
0
10
20
30
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
Initial
SDP−C
(b) Ma = 1, Na = 2
0
10
20
30
0
0.2
0.4
0.6
0.8
1
ALE (m)
CDF
 
 
Initial
SDP−C
SDP−C−VAL
SDP−C−VAS
SDP−C−VAL
SDP−C−VAS
SDP−C
Initial
(c) Ma = 1, Na = 3
Figure 9.16: Experimental localization accuracy via one-hop for three
cases.
success and high accuracy of localization. Moreover, continuous sensing appli-
cations on a smartphone is challenging because of the high resource demands
and limited battery capacity. Our proposed approach leverages highly eﬃcient
BLE notiﬁcation for starting the sensing task, and lasts only a few seconds
for demand-based transparent participation with low cost.
9.7
Conclusion
The ubiquitous availability, mobility, eﬃcient computing and communication
capacities of sensor-rich smartphones make mobile crowd sensing (MCS) a
much more ﬂexible and cost-eﬀective localization and sensing method at scale.
We designed “FindingNemo” for locating family members via MCS. The ap-
plication requirements, incentive schemes, and design considerations are elab-
orated. We propose SDP-based cooperative location optimization via one-hop
or multi-hop assistance to cover more participators. The proposed solution
could locate the “unlocalizable” target with an ambiguous location, and sig-
niﬁcantly improve the location accuracy over conventional approaches. Further
optimization via virtual anchors is proposed to leverage assistants with suﬃ-
cient measurements for trilateration. The diﬀerent conﬁgurations and accessi-
bility of participators are analyzed via simulations and experiments, along
with the comparison of performance improvement. The ﬂexibility and ac-
curacy of these proposed approaches may boost the rapid emergence of a
consumer-centric participatory MCS.

Chapter 10
Improving Location
Services via Social
Collaboration
Kaikai Liu
Assistant Professor, San Jose State University
Qiuyuan Huang
Ph.D. Student, University of Florida
Jiecong Wang
Master Student, University of Florida
Xiaolin Li
Associate Professor, University of Florida
Dapeng Oliver Wu
Professor, University of Florida
CONTENTS
10.1
Introduction ......................................................
198
10.2
Preliminary .......................................................
200
10.2.1
Use Cases ................................................
200
10.2.2
Relative Ranging ........................................
201
197

198
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
10.3
System Design ....................................................
201
10.3.1
Design Consideration ....................................
201
10.3.2
System Overview ........................................
202
10.4
Crowd Sensing and Ranging Condition ..........................
203
10.4.1
Crowd Cooperative Setting and Protocol ...............
203
10.4.2
Geo-Coordinate ..........................................
205
10.4.3
Mathematical Modeling .................................
206
10.4.4
Crowd Clustering and Co-Location Detection ..........
207
10.4.5
Necessary Conditions for Relative Ranging .............
209
10.5
Cooperative Location Optimization .............................
211
10.5.1
Sparse Steepest Descent Optimization ..................
211
10.5.2
Weighting Center-Based Polar Optimization ............
213
10.6
Numerical Results ................................................
214
10.7
Experimental Validation .........................................
215
10.7.1
System Implementation .................................
215
10.7.2
Experiment Setup .......................................
216
10.7.3
Case Study I: Stationary Users ..........................
216
10.7.4
Case Study II: Moving Users ............................
218
10.8
Related Work ....................................................
219
10.9
Conclusions .......................................................
221
10.1
Introduction
Most new models of smartphones have built-in global positioning system
(GPS) receivers. The GPS on board enables a host of location-aware applica-
tions. According to a study published by the Pew Internet and American Life
Project [1], more than 55% of smartphone owners use their phones to ﬁnd
directions, recommendations, or other information related to their present
locations. In addition, geo-social “check-in” services such as Foursquare or
Gowalla are very popular among young adults [1]. New digital cameras or
smartphones are equipped with geo-tagging features [111], making it easy to
group photos by location or track the user’s footprint.
Obtaining the GPS position information incurs a high cost; the whole
process includes many complex calculations, e.g., correlation, demodulation,
tracking, ranging, and positioning. Moreover, satellite signals are hard to ac-
cess, especially in indoor and harsh environments, due to the strong atten-
uation of the radio caused by building materials. The process of constantly
searching and capturing the very weak beacon signal consumes a lot of power,
and the estimated position is often inaccurate or even unavailable.
The rapid growth in people-centric mobile computing applications and
location-based services has called for improved localization techniques. Energy
eﬃciency and accuracy are the two main objectives of such improvements.
Authors in [20, 44, 50] have paid attention to tradeoﬀbetween energy and
location accuracy. They try to use low-power WiFi/GSM-based schemes to

Improving Location Services via Social Collaboration
■
199
lower the frequency of GPS startups, but at the expense of lower accuracy
and update rates. Other approaches utilize dedicated devices for localization
when a GPS signal is unavailable [85, 81, 54, 57]. However, a lot of anchor
nodes need to be placed at a very high density with known coordinates.
One compelling technique for improving the performance of localization is
cooperative localization [80]. By exchanging the anchor node information and
performing relative ranging between nodes, the position estimation for each
node becomes possible and more accurate [49, 115]. However, existing cooper-
ative localization techniques [79, 49, 115] require access to raw GPS ranging
measurements. The GPS/WiFi position is the only information accessible by
a user/application in a commercial smartpone. Therefore, the existing co-
operative localization techniques [79, 49, 115] are not directly applicable to
GPS-enabled smartphones. To deal with this inconvenience, the authors in
[52, 74] propose practical approaches for optimizing the smartphone location
results by leveraging the inter-node distance estimation. H. Liu et al. [52]
map users’ locations jointly against a WiFi signature map subject to ranging
constraints, but show signiﬁcant delay (> 7s) caused by TDMA-based peer-to-
peer ranging and WiFi scanning. Nandakumar et al. [74] utilize the acoustic
signal transmitted by desktop to assist the WiFi localization; however, not
considering the mobile situation would limit its application in a smartphone.
In this chapter, we propose a cooperative location optimization (Coloc)
scheme in a social network via crowd sensing. Unlike conventional coopera-
tive localization that utilizes physical-layer information fusion, our proposed
social-aided location optimization performs data fusion for nearby crowds of
smartphones when coarse positions are already known. This social-aided fu-
sion can achieve practical performance improvement at a lower cost with min-
imum added complexity. The rationale is that when a group of people in a
common location all carry smartphones with GPS capability, the accuracy of
localization can be signiﬁcantly improved by fusing the GPS positions of the
smartphones in this group. Theoretically, this performance gain is ascribed
to the law of large numbers and location diversity. Adjacent samples of GPS
results have high correlation with limited new information, while the location
from peers contributes to diversity gains. Thus, GPS update rate as well as
the power consumption could be lowered without sacriﬁcing the accuracy if
peer-assisted information is available. To further improve the accuracy, we per-
form peer-to-peer ranging via acoustic time-of-arrival (TOA) measurements.
The achieved high-accuracy ranging results could be applied as distance con-
straints to optimize the overall group location accuracy. For utilizing the rang-
ing information eﬀectively, we derived the necessary condition and eliminated
unnecessary ranging measurements. Two algorithms, i.e., sparse steepest de-
scent optimization and polar optimization, are proposed to improve the overall
location accuracy in a mobile environment. We want to emphasize that the
driving forces of cooperative crowd localization are fast-improving smartphone
technology and people-centric pervasive social computing.

200
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
The rest of this chapter is organized as follows. Section 10.2 summarizes
our proposed use cases and previous work on smartphone-based ranging. Sec-
tion 10.3 discusses our system design. Section 10.4 describes mathematical
models, cooperative protocol, and the necessary condition for inter-node rang-
ing. Section 10.5 presents the Coloc scheme for the case that relative dis-
tances between smartphones in a neighborhood are known. Section 10.6 and
Section 10.7 present numerical results and experimental results, respectively.
Section 10.8 summarizes related works. Section 10.9 concludes this chapter.
10.2
Preliminary
10.2.1
Use Cases
Our proposed social-aided crowd localization scheme can be applied to two
scenarios. The ﬁrst scenario is that when you go outside with your friends,
you and your friends are in the same route or bus, and many of you use
smartphones to take geo-tagging photos occasionally. Without cooperation,
every time you open your camera application, the smartphone starts up the
GPS to perform localization. Even if your group is in the same place, anyone
who wants to take photos needs to start up the GPS again, which slows
down the response of the camera and drains the battery. Moreover, using
one snapshot GPS measurement for localization is inaccurate. You may have
experienced that some of your photos in your album show some places that
you had never been before due to inaccurate GPS results. To reduce energy
consumption and improve position accuracy, your group only needs to perform
localization the ﬁrst time. Using everyone’s position result to do re-positioning
cooperatively, a more precise position result is obtained and shared among
your group members. When you are moving or stay stationary for a period of
time, only one smartphone in your group needs to perform localization and
update your group position automatically. Other smartphones in the group
can just use the shared position, which is more accurate and power eﬃcient
than direct calculation by themselves.
The second scenario is journaling your location or moving traces when jog-
ging with your friends. Running or jogging with friend is full of fun and can
make you motivated to run. Journaling or logging workout locations, traces, or
calories using a ﬁtness app becomes a habit for many users. However, recording
your GPS location continuously in the background could kill your smartphone
battery quickly. If you only record signiﬁcant changes of location to save en-
ergy, you could hardly see your complete moving traces. Only several dots of
locations recorded in your path cannot satisfy your needs in recording your
workout. Collaborating with your friend in journaling the location could save
your smartphone energy and improve the location accuracy if needed. It could
eliminate redundancy measurements and improve the location measurement
rate in critical paths.

Improving Location Services via Social Collaboration
■
201
10.2.2
Relative Ranging
In cooperative localization, the relative distances between peers are the addi-
tional information input to optimize the overall location accuracy. Realizing
relative ranging on a smartphone is crucial for the Coloc scheme. Using acous-
tic time-of-arrival (TOA)-based ranging has been demonstrated to have sig-
niﬁcantly better accuracy than received-signal-strength (RSS)-based ranging
using WiFi/GSM/Bluetooth signals [52, 74, 53, 57].
Transmitting a simple acoustic beep and measuring its ﬂight delay is a
practical way to implement the accurate ranging on a smartphone [52, 74].
However, using a simple acoustic signal may cause the problem that there is
no way to tell which smartphone emitted which signal, i.e., it causes ambiguity
due to using an un-modulated signal. Resolving the problem by performing
time-division multiple access and using a radio signal for assistance would
increase the overall delay, which is especially serious for the acoustic signal (low
transmission speed), e.g., for N peers, total N(N −1)/2 relative distances need
to be measured. For tracking users when they are walking around, suﬃcient
ranging rate is required.
Based on our prior work [53, 57], we performed 2-PAM modulation for the
acoustic signal and combine ranging and information bit transmission at the
same time. With the information bits directly available in the ranging sig-
nal, we could identify the smartphone after signal demodulation. When one
smartphone broadcasts its ranging beacon, other peers could all identify this
beacon. Instead of performing transmit and reply for each ranging pair, we
could achieve pair-wise ranging through one transmit and multiple replies.
Thus, the signiﬁcant amount of time used in round-robin ranging could be re-
duced. Moreover, we apply a cluster-based ranging approach to only estimate
the user clusters with suﬃcient distance, i.e., the necessary condition for rang-
ing presented in Section 10.4. This way, only several ranging measurements
need to be performed, and the ranging delay could be minimized for tracking
moving targets.
10.3
System Design
Fig. 10.1 illustrates the Coloc system architecture and major functional com-
ponents. In this section, we sketch an overview of the design consideration,
then elaborate on some important components in the system.
10.3.1
Design Consideration
In terms of accuracy, GPS is preferred over its alternatives, especially in out-
door environments, e.g., GSM/WiFi based approaches. However, GPS is ex-
tremely power hungry due to the inevitable complex computations. When
the location information is demanded less, reducing the location update rate
is one possible way to provide accurate position information while spending

202
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 10.1: System architecture.
minimal energy. As the basic way to save energy, we also use reduced update
rate for the GPS module, but we focus on balancing the GPS consumption
to the network cost by applying the constraint that suﬃcient update rate is
needed for tracking a moving target.
Using relative ranging information to improve the overall localization ac-
curacy is the basic idea of our proposed Coloc scheme [52, 74]. The problem
lies in how and when to utilize the ranging information. If the localization
error surface of two peers is larger than their relative distance, the perfor-
mance improvement contributed by this ranging measurement would be lim-
ited. Utilizing the ranging information when needed is essential in designing
a cooperative scheme for location optimization.
10.3.2
System Overview
To realize the Coloc scheme, we proposed approaches for the smartphone to
collect GPS data, report to the server, and use the reﬁned results calculated
by the server. The Coloc scheme consists of the following three key compo-
nents: Coloc Software Middleware in a Smartphone: Each smartphone
obtains position by its own GPS receiver during the start-up period. Three
basic modules in a smartphone are utilized: the GPS module for coarse lo-
cation estimation; the network module for communicating with the server
and coarse-grained co-location detection; the acoustic module for peer detec-
tion and ranging. On top of the smartphone software middleware, cooperative
location-based applications are supported, e.g., recording or tagging GPS tra-
jectories when hanging out with friends; obtaining optimized location when
multiple smartphones are in the same vehicle; tracking multi-users with a high
accuracy and reliability requirement.

Improving Location Services via Social Collaboration
■
203
Server Processing for Position Optimization: The server receives all
the GPS location information from all the users that checked in via our ser-
vices. According to their coarse locations (same WiFi/BLE coverage), users
could be divided into groups. Only the users in the same group could coop-
erate with each other for location optimization, where the size of the group
is constrained by the maximum ranging distance. In each group we apply our
Coloc scheme with relative ranging. Users in one group could also be clustered
into small clusters. Widely-used clustering algorithms include K-means, un-
normalized spectral clustering, the G-cut algorithm, and the normalized cuts
algorithm. The reason that we perform clustering is that peer-to-peer ranging
could be eliminated within one cluster to minimize the overall ranging cost
and delay.
The server will send ranging coordination beacons to users for relative
distance estimation. With all the information available, the server invokes
the position optimization algorithm (i.e., neighborhood-based weighted least-
squares estimation algorithm) to reﬁne the position of each user by utilizing
users’ (coarse) GPS position information and the relative distances obtained
in an iterative mode.
10.4
Crowd Sensing and Ranging Condition
10.4.1
Crowd Cooperative Setting and Protocol
The whole system setting is shown in Fig. 10.2. To realize crowd coopera-
tive localization via social collaboration, we proposed a Coloc scheme for the
smartphone to collect data and use the reﬁned results calculated by the server.
The Coloc scheme consists of the following ﬁve steps:
Figure 10.2: System setting and protocol.

204
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
1. Group Creation:
When a user wants to hang out with their friends, they can create a
group for all the group members and privately share their location in-
formation in this group. Then, the cooperative localization scheme is
performed within this created group with privacy preserving. Another
mode is crowd cooperation with nearby unknown participators. Users
report their location and nearby network identiﬁcation to the server;
the server will perform co-location detection and automatically form
a group for co-located users. In the following analysis, the meaning of
“group” could be private or public.
2. Initialization:
Each smartphone obtains its position by accessing its own OS location
framework during the start-up period. Modern OS fuses GPS location
and WiFi/Cellular location to the users when available. When we men-
tion the initial location of the smartphone, we mean the obtained fused
location results provided by OS. Assuming that there are WiFi access
points near each smartphone or the group leader could broadcast BLE
beacon to its members, this information (wireless ID and radio signal
strengths (RSS)) could be used as coarse-grained co-location informa-
tion. Then, each smartphone reports the following to the server: its initial
position, IDs of its nearby WiFi or BLE beacon, and the corresponding
RSS.
3. Clustering and Co-Location Detection:
The server gets all the reported information and creates a group for
crowded sensing results according to the co-location information. When
the group is created, the server will further perform clustering to form
clusters of co-located smartphones as shown in Fig. 10.2, i.e., partition
all the smartphones into micro-groups according to their positions and
Radio RSS. These micro-groups/clusters could be used as an closeness
indication and evaluate the necessary condition for ranging.
4. Distance Estimation:
When the user requests better location accuracy, relative ranging would
be performed to optimize the overall localization accuracy. We estimate
the relative distance between smartphones via acoustic TOA ranging.
Not all peer-to-peer ranging is necessary, considering the balance of con-
tribution, relative measurement delay, and energy cost.
If the acoustic ranging is not available, the relative distance between
any two smartphones is approximated from the GPS positions of the
two smartphones and the BLE RSS if available.

Improving Location Services via Social Collaboration
■
205
5. Position Optimization:
The server invokes the position optimization algorithm (i.e., neighborhood-
based weighted least-squares estimation algorithm) to reﬁne the position
of each user by utilizing users’ co-location information, the (coarse) GPS
position information obtained in step 2, and the relative distances ob-
tained in step 4. The position reﬁnement works for the case without
relative distances. If the acoustic TOA ranging result is available, higher
positioning accuracy can be achieved.
6. Position Updating:
The server sends the reﬁned position back to each smartphone, and each
smartphone updates its position with the received value. When one user
wants to be a free-rider, and he is co-located with other participators,
the other’s location can be shared anomalously. In this way, signiﬁcant
power saving can be achieved since this user does not need to calculate
the position value, at least not all the time.
10.4.2
Geo-Coordinate
We considered a social network consisting of m collaborators in Rd, where
d is the coordinate dimension, i.e., d = 3 for ellipsoidal space; d = 2 for the
Cartesian space. Let Ng = 1, 2, . . . , m denote the set of collaborators.
Assume the ground truth position of each collaborator is pi, i ∈Ng. With
ellipsoidal coordinates, pi can be written as a form of latitudes (radians), E
longitudes (radians), and heights (m), i.e., pi = (lati, loni, hi)T . To simplify
the process, we can change the ellipsoidal coordinates to the Cartesian coor-
dinate under the standard of Geodetic Reference System 1980 (GRS80) by
function pi(x, y, z) = fell(pi(lat, lon, h)) as
v = a/
p
(1 −e(sin(lat))2)
(10.1)
x = (v + h) cos(lat) cos(lon)
y = (v + h) cos(lat) sin(lon)
z = (v(1 −e) + h) sin(lat)
where a and e are the references of ellipsoid major semi-axis and eccentricity
squared parameters deﬁned in GRS80.
For small-scale geographic space, we can focus on the 2D Cartesian coordi-
nate without the heights (h) information. By subtracting a pre-deﬁned refer-
ence point pref = (xf, yf)T , a local coordinate obtained by the GPS module
in the smartphone is ˆpi = ˆpi −ˆpref = (ˆxi, ˆyi)T , i ∈Ng for plane-coordinate.
The estimation error is ei = |ˆpi −pi|. Assuming that the position estimate
is unbiased, ei follows a zero-mean Gaussian distribution as ei ∼N(0, Σi),
where Σi is the error covariance matrix and is assumed to be a diagonal ma-
trix with diagonal entries of (σx
i )2 and (σy
i )2. Then, the position matrix of
each collaborator can be written as ˆP = [ˆp1
ˆp2
. . .
ˆpm] ∈Rd×m.

206
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
10.4.3
Mathematical Modeling
The estimation error of the location can be written as ei = |ˆpi −pi|. Assum-
ing that the position estimated is unbiased, ei follows a zero-mean Gaussian
distribution as ei ∼N(0, Σi). So, the probability density function of ˆpi can
be written as
f(ˆpi) =
1
p
2π det(Σi)
exp

−DT Σ−1
i D
2

(10.2)
where D = (ˆpi −pi), and det(Σi) calculates the determinant of Σi. Σi is the
error covariance matrix and is assumed to be a diagonal matrix with diagonal
entries of (σx
i )2 and (σy
i )2. Then, the position matrix of each collaborator can
be written as ˆP = [ˆp1
ˆp2
. . .
ˆpm] ∈Rd×m.
The problem of social-aided cooperative localization can be modeled so
as to reﬁne the estimated positions (ˆpi) obtained by GPS. The additional
information that we utilize to optimize the accuracy of GPS position are the
co-location or relative distances (D) between collaborators.
For a pair of collaborators pi and pj, their Euclidean distance can be
denoted as dij = ||pi −pj|| =
p
(xi −xj)2 + (yi −yj)2, where || · || is the 2-
norm of the vector. Considering the measurement error, the estimated distance
between collaborators is the noised version of dij as ˆdij = dij + nij, where
nij is a Gaussian noise component with nij ∼N(bij, σ2
ij). The term of bij is
a range bias induced by non-line-of-sight (NLOS) propagation, and bij = 0
when the measurement is in line-of-sight (LOS) condition. In real situations,
the inter-node distance information is not fully available, i.e., some of the
measurements are missing or unavailable. To deal with such conditions, we
deﬁne the distance measurement matrix as D = {dij : (i, j) ∈Ng} with
dij = 0 representing the unavailable measurements. The matrix D is a sparse
matrix with sparse rate γ deﬁned as the number of dij = 0 terms divided by
the total number of m(m −1)/2.
Fisher information J (the reciprocal of CRLB) is often used as a metric to
assess the accuracy of a particular position estimation. Hence, parameters to
be estimated are the collaborator’s reﬁned position ˆpk = (ˆxk, ˆyk)T , k ∈Ng by
using their initial position and relative distance. For notational convenience,
we denote the unknown parameter as θ = [ˆpk], where 1 ≤k ≤Ng. Let ˆθ
denote an estimation of the parameter θ. The error covariance matrix of ˆθ
satisﬁes information inequality as
Er{(ˆθ −θ)(ˆθ −θ)T } ≥J−1
θ
(10.3)
where Jθ is the Fisher information matrix (FIM) of non-random parameter θ.
The joint likelihood ratio of the discrete random vector r of the received
signal and random parameter θ can be shown as f(r, θ) = f(r|θ) · g(θ), where
f(r|θ) is the conditional pdf, and g(θ) is the a priori probability density func-
tion of θ. The generalized Fisher Information Matrix (FIM) for θ is given
by
Jθ ≜Er,θ{[ ∂
∂θlnf(r, θ)] · [ ∂
∂θlnf(r, θ)]T }
(10.4)

Improving Location Services via Social Collaboration
■
207
(10.4) can be further decomposed,
Jθ =
Jf(r,θ)|j=i
|
{z
}
GPS position info
+
Jf(r,θ)|j̸=i
|
{z
}
Info. from cooperation
+
Jg(θ)
|{z}
Prior Infor.
(10.5)
where the ﬁrst term indicates the position information from a collaborator
using GPS; the second term indicates the inter-ranging information between
collaborator i and j; and the third term denotes a priori information on θ.
From (10.5), we know that the cooperative localization contributes to the
second term; the resulting FIM can be much better than conventional local-
ization methods that just use a prior information and j = i term. By using
the initial GPS position result and inter-note information as a prerequisite,
performing post-decision optimization can obtain a more accurate position
result, ˆpk = (ˆxk, ˆyk)T , k ∈Ng.
10.4.4
Crowd Clustering and Co-Location Detection
In the step of grouping, we use a distributed clustering algorithm to form clus-
ters, i.e., partition all the co-located smartphones (within the same WiFi/BLE
coverage) into clusters. Widely-used clustering algorithms include K-means,
un-normalized spectral clustering, the G-cut algorithm, and the normalized
cuts algorithm.
The K-means algorithm, a.k.a. the Lloyd algorithm is based on the near-
est neighbor criterion and the centroid criterion. However, the K-means algo-
rithm cannot be used for grouping smartphones if the GPS positions of the
smartphones are not available due to signiﬁcant signal attenuation in indoor
environments, high rise building environments, or dense forest.
Even if the GPS position is available, it is still not accurate enough. We
propose the following method to obtain distances or aﬃnity measures between
any pair of smartphones. Suppose the network under consideration consists of
N smartphones. When a smartphone (say group leader, Node i) has Internet
access, it sends a BLE beacon signal. Any smartphone (say, Node j (j ̸= i))
that is able to detect the beacon signal records the power Pij of the received
BLE beacon, and Pij will be regarded as an aﬃnity measure between Node i
and Node j; for any node k that is not able to detect the beacon signal, we
set Pik = 0. Note that given a path loss model and transmission power P (t)
i
,
we can convert Pij to a rough distance dij between Node i and Node j, up to
a constant scaling factor. For example, assume the path loss is proportional
to the n-th power of distance, i.e., P (t)
i
/Pij = κ × dn
ij, where κ is a constant;
then dij = κ−1
n × (P (t)
i
/Pij)
1
n .
Once other smartphones also get a chance to send a beacon signal, we
can obtain an aﬃnity matrix S (where S ∈RN×N) and the entry at the i-th
row and the j-th column of S is Pij. We assume that the transmission power
P (t)
i
is the same for all i. In the case that P (t)
i
are diﬀerent for diﬀerent i,
the aﬃnity matrix S will not be symmetric; then we will use Ssym = S + ST

208
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
as the aﬃnity matrix, which is symmetric. Un-normalized spectral clustering
and the normalized cuts algorithm are able to group smartphones, given an
aﬃnity matrix.
The following shows the procedure of the normalized cuts algorithm.
Input: Aﬃnity matrix S (where S ∈RN×N), number K of clusters to
construct.
1. Compute the unnormalized Laplacian L.
2. Compute the ﬁrst K generalized eigenvectors u1, · · · , uK of the gener-
alized eigenproblem Lu = λDu.
3. Let U (U ∈RN×K) be the matrix containing the vectors u1, · · · , uK as
columns.
4. For i = 1, · · · , N, let yi (yi ∈RK) be the vector corresponding to the
i-th row of U.
5. Cluster the N points {yi (i = 1, · · · , N)} in RK with the K-means
algorithm into clusters C1, · · · , CK.
6. Run the above procedure 50 times with diﬀerent randomly permuted
matrix S.
7. Choose the clusters C1, · · · , CK with minimum distortion as output.
Output: Clusters A1, · · · , AK with Ai = {j|yj ∈Ci}. Using 60 smartphone
locations as an example, the input aﬃnity matrix and the clustering result is
shown in Fig. 10.3(a) and Fig. 10.3(b), respectively.
Affinity matrix
10
20
30
40
50
60
10
20
30
40
50
60
(a) Aﬃnity matrix
Partitioning of permuted affinity matrix under ncut
10
20
30
40
50
60
10
20
30
40
50
60
(b) Clustering result
Figure 10.3: 1. The input aﬃnity matrix of the clustering algorithms for
60 smartphone locations with three clusters; 2. the output of normalized
cuts clustering algorithm.

Improving Location Services via Social Collaboration
■
209
10.4.5
Necessary Conditions for Relative Ranging
Performing pair-wise ranging for a large amount of peers may cause substan-
tial energy consumption and delay. In reality, some of these ranging pairs are
unnecessary or only contribute to limited performance improvement. Selecting
the ranging pairs that are necessary could be an eﬀective solution to balance
the performance improvement and ranging cost. In this subsection, we derive
the necessary condition for ranging based on the error probability distribution.
The rationale is that we analyze the performance gains contributed by directly
fusing the location of co-location users, while these performance gains would
be decreasing for larger relative distance. By analyzing the maximum allow-
able distance for performance gains of location fusion without using distance
information, we can set this maximum allowable distance as the necessary con-
dition of ranging. If the pair-wise distance is within the maximum allowable
distance, directly fusing the co-located users could also improve the location
accuracy, with no need for a costly ranging process. Consider the extreme case
ﬁrst: If all the collaborators are co-located in the same place, this co-location
information of collaborators can be utilized to improve the overall localization
accuracy due to the correlation between diﬀerent estimated positions. For the
co-location clusters C1, . . . , CK, the mixture of the position information of
cluster Ck can be written as
ˆpk = 1
Nk
X
i∈Ck
γiˆpi
(10.6)
where γi is the weighting coeﬃcient of initial location for users in cluster Ck,
and can be calculated by the historical position variance of user i.
To illustrate the performance gains with regard to the maximum al-
lowable distance, we focus on the location fusion of a two-users case with
ˆpi,j = γiˆpi + γjˆpj. The probability density function of the mixed ran-
dom variable ˆpi,j is f(ˆpi,j) = γif(ˆpi) + γjf(ˆpj). If the equal weighting
method is used for information fusion, the coeﬃcients are γi = γj =
1
2.
The location estimation result ˆpi,j still follows a Gaussian distribution as
(ˆpi + ˆpj)/2 ∼N ((pi + pj)/2, Σi,j), where Σi,j is a diagonal matrix with
diagonal entries of ((σx
i )2 + (σx
j )2)/4 and ((σy
i )2 + (σy
j )2)/4.
The mean square error (MSE) is often used as a characteristic metric
to illustrate the accuracy of the result. The MSE of the estimation of ˆpi is
MSEi = (σx
i )2 + (σy
i )2. Deﬁne (σp
i )2 = (σx
i )2 + (σy
i )2. The MSE of ˆpi,j is
ˆ
MSEi = E[||pi −ˆpi,j||2]
(10.7)
= E[||pi −(ˆpi + ˆpj)/2||2]
= 1
4||pj −pi||2 + 1
4(σp
i )2 + 1
4(σp
j )2
where ||pj −pi||2 is the 2-norm of the distance diﬀerence, i.e., the biased
value of the estimator. The MSE for the initial position estimation result is

210
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
MSEi = (σp
i )2. The ˆpi,j can be deﬁned as the diﬀerence of the MSE value, as
δMSEi = 1
4||pj −pi||2 + 1
4(σp
i )2 + 1
4(σp
j )2 −(σp
i )2
(10.8)
= 1
4||pj −pi||2 + 1
4(σp
j )2 −3
4(σp
i )2
In order to achieve performance gains for user i when using the position of
user j for information fusion, the condition δMSEi < 0 should be satisﬁed.
Deﬁne the performance gain of user i using the position information from i
and j as Gi(i, j) = −δMSEi. The maximum allowable distance constraint
can be shown as
||pj −pi||2 < 3(σp
i )2 −(σp
j )2
(10.9)
(10.9) means the condition that the performance gains can be achieved by
using co-location information fusion. Only if the condition (10.9) is satisﬁed
can two users be called “co-location.” If the initial measurement variance of
users i and j are approximately the same, i.e., σp
i = σp
j = σp, then (10.9) can
be simpliﬁed as dp
ij <
√
2σp, where dp
ij = ||pj −pi|| is the relative distance
calculated by using the measured GPS position. Since σp =
p
(σx)2 + (σy)2,
if σx = σy = σ, then dp
ij <
√
2
√
2σ2 = 2σ.
1
1.5
2
2.5
3
2
3
4
5
6
Measurement Variance σ
Maximum Allowable Distance
 
 
Simulated Value
Thoretical Value
(a) Maximum Allowable Dis-
tance
0
50
100
0
5
10
15
20
25
−3
−2
−1
0
1
2
Noise Variance
Distance
Performance Gain of Co−location
(b) Performance Gains
Figure 10.4: (a) The relation between measurement variance and maxi-
mum allowable distance (peer-to-peer ranging is not necessary). (b) The
performance gains with regard to the relative distance and variance.
The relation between measurement variance and maximum allowable dis-
tance when peer-to-peer ranging is not necessary is shown in Fig. 10.4(a); the
performance gains with regard to the relative distance and variance is shown
in Fig. 10.4(b). Note that dp
ij is diﬀerent from the ranging measurement ˆdij;

Improving Location Services via Social Collaboration
■
211
dp
ij is obtained by fusing GPS positions of smartphones, while ˆdij is obtained
by inter-user ranging. Using the initial measured coarse GPS location infor-
mation, dp
ij can be estimated. In addition, dij is the unknown true distance
between Node i and Node j.
If dp
ij does not meet the constraint of (10.9), then we can call it a necessary
condition for ranging, since the pair-wise ranging is needed for improving the
location accuracy.
10.5
Cooperative Location Optimization
If the estimated dp
ij violates (10.9), i.e., meets the necessary condition for rang-
ing, then pair-wise ranging should be conducted. To improve the positioning
accuracy in this condition, we develop a cooperative localization scheme that
leverages relative distances among the smartphones.
10.5.1
Sparse Steepest Descent Optimization
(a) Initial
(b) Sparse Rate γ =
0.73
(c) Sparse Rate γ = 0
Figure 10.5: Numerical results with 12 users under σ = 1 and R = 2: (a)
initial positions, (b) reﬁned positions obtained by SSD with γ = 0.73, and
(c) reﬁned positions obtained by SSD γ = 0.
With two independent measurements ˆpi and ˆdij available, the problem can
be described so as to reﬁne the position ˆpi by utilizing the relative ranging
information ˆdij. Typically, the ranging accuracy of ˆdij is more accurate than
the GPS positioning accuracy due to the short distance between users. We
use the following neighborhood-based weighted least-squares estimation to
improve the positioning accuracy of ˆpi, ∀i, i.e., minimizing the squared error

212
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
between the calculated distance and the measured distance:
ˆP := arg min
ˆP
e(ˆP) = arg min
ˆP
X
(i,j)∈Ng
µij(||ˆpi −ˆpj|| −ˆdij)2
(10.10)
where e(ˆP) is the total sum of distance errors between all the users, and µij
is a weight that is inversely proportional to the variance σd
ij. ˆP is a matrix
whose columns are ˆpi, i ∈Ng, where Ng is the set of all the collaborators in
a neighborhood.
The objective function of (10.10) achieves the minimum value when the
total distance calculated by GPS position is equal to the measured distance,
i.e., more accurate results of position are achieved at the level of the ranging
accuracy. To solve the optimization problem of (10.10), we apply steepest
descent method to reduce the error function and calculate the updated version
of user position.
Performing the gradient operation ∇of the error function e(ˆP)
=
P
(i,j)∈Ng µij(||ˆpi −ˆpj|| −ˆdij)2 with respect to the user i has
∇ie(ˆP) = 2
X
(i,j)∈Ng
µij(||ˆpi −ˆpj|| −ˆdij)∇i(||ˆpi −ˆpj|| −ˆdij)
(10.11)
where ˆdij is a measurement value, ∇i ˆdij = 0. ||ˆpi−ˆpj|| represents the distance
from ˆpi to ˆpj, i.e., ||ˆpi−ˆpj|| =
p
(xi −xj)2 + (yi −yj)2. The gradient of such
a distance can be written as ∇i||ˆpi−ˆpj|| = (ˆpi −ˆpj)/||ˆpi −ˆpj||. Then (10.11)
can be calculated as
∇ie(ˆP) = 2
X
(i,j)∈N +
g
µij(||ˆpi −ˆpj|| −ˆdij) ˆpi −ˆpj
||ˆpi −ˆpj||
(10.12)
= 2
X
(i,j)∈N +
g
µij(1 −ˆdn
ij)(ˆpi −ˆpj)
where ˆdn
ij = ˆdij/||ˆpi −ˆpj|| is the normalized relative distance; it also char-
acterizes the diﬀerence between measured distance and calculated distance
from position. After optimization, ˆdn
ij should approach 1. N +
g represents the
sparse set that ˆdij ̸= 0. The relative ranging results between users are not
fully available such that some measurements of ˆdij are missing, i.e., ˆdij = 0.
The sparse property of the distance matrix D = {dij : (i, j) ∈Ng} causes the
performance gains contributed by distance restraint to be not fully available
especially when the sparse rate γ is high. However, such a sparse feature can
be utilized to speed up the processing by using a sparse matrix operation.
After obtaining the gradient function of the error function e(ˆP), the new
position can be updated by using
ˆP := ˆP + α∇ie(ˆP)
(10.13)

Improving Location Services via Social Collaboration
■
213
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
X
Y
(a) Initial
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
X
Y
(b) Optimized
0
0.5
1
1.5
2
2.5
3
0
0.2
0.4
0.6
0.8
1
Error
CDF
 
 
No−Col, R=0.5, σ=0.3
Col, R=0.5, σ=0.3
Polar, R=0.5, σ=0.3
Polar, R=2, σ=0.3
No−Col, R=2, σ=1
Polar, R=2, σ=1
(c) CDF
Figure 10.6: The 2-users case of using polar optimization, initial mea-
surement (a), after polar optimization (b) and CDF (c), σ = 0.3.
where α is the iterative step size and α ∈(0, 1]. Eq. (10.13) should be inter-
preted column-wisely as ˆpi := ˆpi + α∇ie(ˆP), ∀i with ˆpi = (ˆxi, ˆyi)T .
The steepest descent approach is a local optimization method with strong
requirement of the initial value selection. However, for our application where
GPS position results can be used as the initial value, the overall performance
of steepest descent can be guaranteed to provide an optimized value.
10.5.2
Weighting Center-Based Polar Optimization
In the previous subsection, the optimized position results are achieved by
minimizing the error between ||ˆpi −ˆpj|| and measured distance ˆdij. The op-
timization process utilizes the gradient iteration. Another feasible approach
is to assume the measured distance is accurate and replace the true relative
distance with ˆdij. The weighting center between two users’ positions is more
accurate than the individual results. Then, update ˆpi := f(ˆpi, ˆdij) with the
relative distance and weighting center.
The relation to the positions of users i and j can be expressed as d ≡||pi−
pj||. For the measured relative distance ˆdij, d can be replaced by d ≜ˆdij. The
initial position measurement ˆpi follows Gaussian distribution with mean value
of pi. The weighting center of position ˆpi and ˆpj is theoretically more stable
because random deviation can be canceled out with high probability. Denote
the weighting center pw
ij = (ˆpi + ˆpj)/2, which can be viewed as more accurate
than ˆpi and ˆpj, where pw
ij = (ˆxw
ij, ˆyw
ij)T , ˆpi = (ˆxi, ˆyi)T , ˆpj = (ˆxj, ˆyj)T . The
angle from the position of node i to node j is estimated as
ˆθ = arctan(yi −yj)/(xi −xj)
(10.14)
With the weighting center and θ available, the node positions i and j can be
re-estimated in the polar-coordinate domain. The position of user j can be

214
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
calculated by transferring the polar-coordinate to Cartesian coordinate by
ˆxi := ˆxw
ij + axd/2 · cos(ˆθ)
(10.15)
ˆyi := ˆyw
ij + ayd/2 · sin(ˆθ)
ˆxj := ˆxw
ij −axd/2 · cos(ˆθ)
ˆyj := ˆyw
ij −ayd/2 · sin(ˆθ)
where ax and ay are the unit vector from the direction of node i to j, with
the equation as ax = (xi −xj)/|xi −xj| and ay = (yi −yj)/|yi −yj|.
For every iteration process, we need to use the measured position results
of ˆpi and ˆpj to update the weighting centering pw and θ. The coeﬃcient of
updating is chosen as (Wm + n −1)/(Wm + n), where Wm is the window
length, n is the iteration step. Then, substituting pw
ij and θ in (10.15) with
new estimated, the optimized position results for node i and j are obtained.
Diﬀerent from the calculation of (10.11) that performs over all the available
nodes of P
(i,j)∈N +
g , (10.15) only processes for two users, i.e., users i and j.
Through performing such pair-wise optimization over the whole sparse set
N +
g , the positions for all the users can be optimized.
10.6
Numerical Results
To illustrate the performance gains contributed by the Coloc scheme, we con-
duct Monte Carlo simulation to calculate the error cumulative distribution
funnction (CDF) by changing the noise variance of initial position results. The
(x, y) coordinates of the positions of twelve users (smartphones) are shown
as a scatter ﬁgure in Fig. 10.7(a); the positions of each user follow the same
two-dimensional Gaussian distribution and are shown by diﬀerent colors.
The mean CDF curves for twelve users of various approaches and diﬀerent
sparse rates are shown in Fig. 10.8(a) with initial measurement variance of
σ = 0.3. The “MA” represents the conventional moving average method used
for the initial measurements, while “SSD” represents our proposed sparse
steepest descent optimization approach. Even when the ranging sparse rate is
very high (γ = 0.73), i.e., only several ranging pair measurements are utilized,
the performance superiority over “MA” is still suﬃcient. Another interesting
point lies in there being no apparent performance degradation when sparse
rate is lower than γ = 0.4. Such a property can help reduce the overall ranging
costs and delay while maintaining desired performance gains.
The performance of the Coloc scheme using ranging information can even
be improved when our proposed sparse steepest descent optimization and
weighting center-based polar optimization are combined together. Since polar-
based optimization is performed for two users, i.e., in a local way, we execute
the polar method after the global SSD approach. The measurement results are
shown in Fig. 10.7. “Initial” is the initial position measurement; the “SSD”

Improving Location Services via Social Collaboration
■
215
−4
−3
−2
−1
0
1
2
3
4
−4
−3
−2
−1
0
1
2
3
4
(a) Initial
−4
−3
−2
−1
0
1
2
3
4
−4
−3
−2
−1
0
1
2
3
4
(b) SSD
−4
−3
−2
−1
0
1
2
3
4
−4
−3
−2
−1
0
1
2
3
4
(c) SSD+Polar
Figure 10.7: Numerical results with 12 users under σ = 1 and R = 2 (x and
y-coordinates are in meters): (a) initial positions, (b) reﬁned positions
obtained by SSD, and (c) reﬁned positions obtained by SSD+Polar.
case uses our proposed sparse steepest descent optimization; “SSD+Polar”
uses the polar optimization after the SSD processing. The CDF ﬁgure is shown
in Fig. 10.8(b). We can know that using polar and SSD optimization, the
performance gains are larger than when using the conventional moving average
method. When combining SSD and polar together, the performance can even
be improved, as shown in Fig. 10.8(b).
10.7
Experimental Validation
10.7.1
System Implementation
We designed a mobile social network from the ground up to enable social crowd
sensing, to improve the location services as shown in Fig. 10.9. With a better-
designed mobile social network app or framework that could be embedded
in other apps, users could easily invite their friends to hang out and enable
crowd sensing for localization. The dedicated mobile social network make the
social collaboration process more convenient. In terms of usage, we make the
cooperative sensing process transparent to users, and perform all the tasks in
the background when necessary.
As shown in Fig. 10.9, users can create location groups and invite friends to
join. Nearby friends could be scanned via BLE beacon and invited to cooper-
ative localization, tracking, and sharing locations. Only friends that accepted
your request could share locations with you and let you do tracking and free-
ride. The BLE RSS is continuously monitored between you and your friends.
Using location journaling application as an example. Fig. 10.10 is the log
trace analysis result using Apple Xcode Instrument for a ﬁfteen-minute work-
out. Before cooperation, recording location trace continuously consumes a lot
of energy and CPU cycle, i.e., the energy usage and CPU activity are high.

216
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
0
0.5
1
1.5
2
2.5
0
0.2
0.4
0.6
0.8
1
Error
CDF
 
 
Init
MA
SSD, γ=0.73
SSD, γ=0.4
SSD, γ=0
Init
MA
SSD
(a) Diﬀerent Sparse Rate
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
Error
CDF
 
 
Init
MA
Polar
SSD
SSD+Polar
Init
Polar
SSD
SSD+Polar
MA
(b) Joint Approach
Figure 10.8: The CDF of location accuracy under various processing
types: 1. Using SSD with diﬀerent sparse rate of ranging; 2. using joint
optimization approaches of SSD and Polar.
When performing cooperative localization, the GPS startup time period could
be signiﬁcantly reduced, and only launches GPS when necessary. Under similar
location trace accuracy, the energy usage and CPU activity after cooperation
is reduced, as shown in Fig. 10.10. If recording the location for longer time,
the improvement in terms of energy savings is more apparent.
10.7.2
Experiment Setup
We conducted experiments by using smartphones to collect location data,
and validated our proposed cooperative localization technique by using these
real measured results. The data is collected by using Apple iOS smartphones
(iPhone4, iPhone4S, and iPhone5 are used in the experiment). The location is
obtained via the default module in iOS location management, which combines
the GPS and WiFi location results. Two cases of situations are tested: sta-
tionary situation for accuracy test; moving situation for tracking and dynamic
performance test.
10.7.3
Case Study I: Stationary Users
To evaluate the performance of our proposed cooperative location optimiza-
tion approach for multi-users in real environments, we conducted measure-
ments for nine users with random positions in a campus environment. The
initial measurement results are shown in Fig. 10.11(a). Diﬀerent from the
simulation results, the obtained GPS results show strong correlation among
adjacent measurements. That’s also why lowering the GPS update rate is
possible, to save energy without sacriﬁcing the accuracy. For convenience, we

Improving Location Services via Social Collaboration
■
217
Figure 10.9: The designed mobile social network.
denote “Init” as the initial position results; “Col” is the result obtained by
only utilizing the co-location information without ranging; “Polar,” “SSD,”
and “Polar+SSD” are our proposed schemes that uses the ranging-based in-
formation for collaboration. We follow the same terms/notations used in Sec-
tion 10.6.
We applied the normalized cuts algorithm to the aﬃnity matrix corre-
sponding to Fig. 10.11(a), and obtained the clustering results of four clusters
as shown in Fig. 10.12(a), i.e., the positions with large similarity measures are
grouped together. By clustering nine users into four clusters with co-location,
we can perform location fusion without relative ranging. This approach is
labeled as “Col.” The CDF results of using diﬀerent algorithms are shown
in Fig. 10.12(b). We observe that the conventional moving average “MA”
approach does not show performance improvement over the initial position
results due to the dependency between adjacent measurements. By clustering
nine users into four clusters with co-location, the location accuracy of “Col”
is much better than “MA” as shown in Fig. 10.12(b).
If the relative distance information can be obtained, the accuracy can even
be improved by using “Polar” and “SSD” approaches. The scatter ﬁgure of
using “SSD” is shown in Fig. 10.11(b). After performing joint optimization
of “SSD+Polar,” the more accurate results are shown in Fig. 10.11(c). By

218
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Figure 10.10: The comparison of energy usage, CPU activity, and network
activity before and after cooperation.
−40
−30
−20
−10
0
10
20
30
−15
−10
−5
0
5
10
15
20
(a) Initial
−40
−30
−20
−10
0
10
20
30
−15
−10
−5
0
5
10
15
20
(b) SSD
−40
−30
−20
−10
0
10
20
30
−15
−10
−5
0
5
10
15
20
(c) SSD+Polar
Figure 10.11: Experimental results with 9 users (x and y-coordinate is
in meters): (a) initial positions obtained by GPS, (b) reﬁned positions
obtained by SSD, and (c) reﬁned positions obtained by SSD+Polar.
comparing the results to the initial measurement results in Fig. 10.11(a), the
performance improvement of using “SSD+Polar” is signiﬁcant.
From the statistical results of Fig. 10.12(b), and using 80% probability as
an example, the initial GPS accuracy is around 5m. After fusing the co-located
users without ranging, the achieved accuracy is about 4m. When using our
proposed ranging-based optimization approach “SSD+Polar,” the positioning
accuracy is approximately 1.2m.
10.7.4
Case Study II: Moving Users
To evaluate the performance improvement of the Coloc scheme in moving sce-
narios, we conducted experiments for moving users. Users carry GPS-enabled

Improving Location Services via Social Collaboration
■
219
(a) Clustering Results
0
2
4
6
8
10
12
0
0.2
0.4
0.6
0.8
1
Error (m)
CDF
 
 
Init
MA
Col
Polar
SSD
SSD+Polar
MA
Init
Col
Polar
SSD
SSD+Polar
(b) CDF Results
Figure 10.12: 1. The clustering results for the 9 users; 2. The CDF of
location accuracy under various processing types.
smartphones and perform cooperative localization with peers when walking
in a campus parking lot. The GPS update time interval is tG; we use lower
tG when applying the Coloc scheme to save energy. Fig. 10.13(a) shows the
initial measurement of a GPS trajectory of 4 users when walking around a
parking lot, where tG = 0.997s. Using low-update GPS data (tG = 1.994s),
and after performing our proposed “SSD” approach, the devision of the GPS
trajectory has been greatly suppressed as shown in Fig. 10.13(b). After apply
the “Polar” approach in addition to “SSD,” the trajectory is more smooth as
shown in Fig. 10.13(c), which is much better than the initial high update rate
data. To test the eﬀectiveness of the Coloc scheme when users are walking
in two separate groups with certain distance, we conduct an experiment by
letting three users form a group and walk in parallel with another user. The
walking traces of these four users are shown in Fig. 10.13(a). After “SSD”
and joint “SSD” and “Polar” optimization, the accuracy of walking traces im-
proved signiﬁcantly as shown in Fig. 10.13(b) and Fig. 10.13(c). These results
demonstrate the energy eﬃciency and accuracy of our proposed Coloc scheme.
10.8
Related Work
Optimizing the GPS localization goes a long way back — more than one
decade, from improving the RF component design, signal processing, ranging,
and localization algorithm, to a diﬀerential GPS system, and assisted-GPS
[40, 115]. However, the inherent complexity of the localization problem makes
the further improvement of the GPS system hard to achieve.
When smartphones became an important personal companion, researchers
proposed to use other auxiliary sensors embedded in a smartphone to improve
the accuracy of GPS. Hybrid approaches have been proposed to balance the

220
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
−50
0
50
−20
−10
0
10
20
X (m)
Y (m)
 
 
User1
User2
User3
User4
(a) Initial, tG = 0.997s
−50
0
50
−20
−10
0
10
20
X (m)
Y (m)
 
 
User1
User2
User3
User4
(b) SSD, tG = 1.994s
−50
0
50
−20
−10
0
10
20
X (m)
Y (m)
 
 
User1
User2
User3
User4
(c) SSD+Polar, tG =
1.994s
Figure 10.13: Experiment results of 4 user’s GPS trajectory when walking
around a parking lot.
−40
−20
0
20
5
10
15
20
X (m)
Y (m)
 
 
User1
User2
User3
User4
(a) Initial, tG = 0.997s
−40
−20
0
20
5
10
15
20
X (m)
Y (m)
 
 
User1
User2
User3
User4
(b) SSD, tG = 1.994s
−40
−20
0
20
5
10
15
20
X (m)
Y (m)
 
 
User1
User2
User3
User4
(c) SSD+Polar, tG =
1.994s
Figure 10.14: Experiment results of 4 user’s GPS trajectory when walking
along a line.
power and accuracy of GPS, e.g., using WiFi ﬁngerprinting, or an accelerom-
eter [50, 20].
Recent approaches that use the microphone sensor in a smartphone for
accurate ranging demonstrate a practical way for achieving accurate auxiliary
measurements [52, 74]. H. Liu et al. [52] improved the accuracy of WiFi-based
localization subject to ranging constraints. The problem is that the error of
WiFi is even larger than the maximum ranging distance of the acoustic signal;
the performance gains contributed by peer-wise ranging would be limited.
The CDF results demonstrated in [52] only show improvement in overall error
(most contributed by reduced bias), but the slope (determines the resolution)
remains the same after their peer-assisted localization approach. Nandakumar
et al. [74] utilized the acoustic signal transmitted by desktop to assist the WiFi
localization, however, the authors do not consider the mobile situation, which
would limit their application in real scenarios. These two approaches also
suﬀer slow update time for the localization (> 7s) due to the time-divided

Improving Location Services via Social Collaboration
■
221
multiple pair-wise ranging and the inherent low transmission speed of the
acoustic signal. For N peers, a total of N(N −1)/2 ranging pairs need to be
measured, and resulting at least N(N −1) times acoustic signal transmission
for two-way ranging mode. Reducing the ranging complexity and improving
the performance gains of the location optimization algorithm are the two key
challenges.
10.9
Conclusions
To address the positioning inaccuracy and power ineﬃciency of current smart-
phone localization, in this chapter we proposed a social-aided Coloc scheme.
Speciﬁcally, we use neighborhood-based weighted least-squares estimation
when relative distances between smartphones are available. The energy ef-
ﬁciency is achieved by sharing location information among co-located users
and lower the GPS update rate. Numerical and experimental results conclu-
sively demonstrate that our proposed cooperative localization schemes can
achieve considerable performance gain in both indoor and outdoor environ-
ments. In the experiments of nine users with random positions, the positioning
accuracy of our scheme was 1.2m with a conﬁdence level of 80%. In contrast, a
regular GPS receiver has an accuracy of 4.7m. The optimized GPS trajectory
also demonstrates the eﬀectiveness of the Coloc scheme for tracking moving
targets.


Chapter 11
Hiding Media Data via
Shaders: Enabling Private
Sharing in the Clouds
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
11.1
Introduction ......................................................
224
11.2
System Model ....................................................
225
11.2.1
Problem Statement ......................................
225
11.2.2
Threat Model and Assumption ..........................
226
11.2.3
Compatible with Existing Cloud Services ...............
226
11.2.4
Format-Compliant and Compression-Independent
Solutions .................................................
226
11.3
System Design ....................................................
227
11.3.1
Design Objective
........................................
227
11.3.2
Proposed Approach ......................................
227
11.4
Privacy Protection Algorithm Design ............................
228
11.4.1
Design Principles ........................................
228
11.4.2
Chaotic Mapping ........................................
229
11.4.2.1
Pros and Cons of Chaotic Mapping .......
229
223

224
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
11.4.2.2
Generalized Low-Order Chaotic Mapping .
229
11.4.3
Whitening and Probabilistic Transformation ...........
231
11.4.4
Multi-Channel Block Substitution via Latin Square ....
232
11.4.5
Security Analysis ........................................
233
11.5
Evaluation ........................................................
233
11.5.1
System Evaluation .......................................
233
11.5.1.1
Media Sharing Process .....................
233
11.5.1.2
Computational Complexity ................
234
11.5.2
Security Analysis ........................................
235
11.5.2.1
Whitening and Probabilistic
Transformation ............................
235
11.5.2.2
Multi-Channel Block Substitution .........
236
11.5.2.3
Overall Security Level .....................
237
11.5.3
Correlation Preserving and Noise Robustness
..........
237
11.6
Related Work ....................................................
239
11.7
Conclusion ........................................................
240
11.1
Introduction
In the era of cloud and big data, the sharing and storing of massive quan-
tities of various types of data is prevalent. Our smartphones can store the
transmitted/received media messages in ever-expanding social networks, e.g.,
Facebook, WhatsApp, and iMessage. Our photos, videos and other media
data are stored and synced in media storage services like Flickr and YouTube.
When enjoying the disruptive reform of cloud services via all kinds of free
storage and message channels, you may be aware that your private data are
assaulted from all sides. Attracted by the big opportunities of monetizing
your data, the Internet’s big brothers have hoarded your personal data and
sold it for billions. Even with some cloud service providers who really respect
users’ privacy, eavesdropping or hacking may still happen, e.g., 2014 celebrity
photo leakage from Apple iCloud. While some service providers claim they
have deleted your data, e.g., Snapchat, hackers can still steal 100,000 sen-
sitive photos in “the Snappening.” Due to the potential leakage of sensitive
information, many users are reluctant to share/store their data to clouds.
Pressure from users’ privacy awareness following these leakage events are
encouraging many more privacy-preserving behaviors, products, and solutions.
Using the law to sue these service providers is one approach. There are also
technical approaches that could help you to prevent the leakage. The direct
solution is encryption, i.e., encrypt all of our data. The advanced encryption
standard (AES) is widely expected to become the de facto standard for en-
crypting all forms of electronic data. However, encryption could not solve all
the problems due to its inherent limitations.
Most importantly, encryption is typically incompatible with existing clouds
and mobile clients; e.g., YouTube, Flickr, Facebook, and Google+ do not allow

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
225
you to upload media in an encrypted format. Alternatively, format-compliant
and low-complexity encryption techniques have become popular for media
data. Authors in [88, 105] proposed encryption approaches along with the
standard JPEG compression. The basic idea is to perform encryption and
JPEG compression jointly, so that the photo is perceptually encrypted but
still in JPEG format. Thus, the encrypted photo is acceptable to existing so-
cial networks or cloud services, while the true content is invisible to eavesdrop-
pers. However, joint encryption with compression has the drawback of format
limitation, e.g., it is only suitable for the JPEG format. Another practical
problem is that these approaches need to break down the existing hardware-
accelerated codecs for compression and decompression, which is hard to access
and ineﬃcient to re-implement via software. Encryption after compression via
selective binary processing could maintain the format [119]. However, this
scheme requires fairly deep parsing into the bit stream to identify necessary
parts of the bit stream to be encrypted [51], resulting in signiﬁcant processing
overheads [136].
Placing the encryption before the compression stage can be inherently com-
pliant to the syntax format without bit stream identiﬁcation because the im-
age/video is processed before the compression process. Encryption approaches
via chaotic mapping belong to this category [124, 122]. However, one signiﬁ-
cant challenge is the loss of correlation between continuous video frames when
disordering the inherent redundancy, resulting in lower compression ratios
with high communication cost. Further, a small amount of pixel error of en-
crypted image during transmission would make the data undecryptable even
with the same key.
We propose a low-complexity privacy-preserving scheme for big media data
with the following salient features: 1) Format-compliant and compression-
independent, putting the encryption before compression without modifying
the existing eﬃcient hardware-accelerated codecs; 2) correlation-preserving
and transmission error robustness, minimizing the communication overhead
and risk; 3) low-complexity and easy programming interface, leveraging
hardware-acceleration without signiﬁcant modiﬁcation of existing software
stacks.
11.2
System Model
11.2.1
Problem Statement
Media data sharing is becoming popular on mobile devices due to multitudes
of advantages of the cloud services, such as the cloud storage and ﬂexible
multimedia message. However, this paradigm shift results in the loss of con-
trol over media data as well as new security and privacy issues. Users’ pri-
vacy fully depends on the provider’s reliability and security guarantees. Cloud
storage providers may assure the data privacy via database encryption. Mo-
bile device providers may guarantee the security level of local data on disk.

226
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
However, cloud storage, service, communication network, and mobile device
are provided separately by diﬀerent vendors. Existing protection approaches
have not covered the full path from end to end. When the privacy leakage
happens, it is hard to know which part cause the problem. This is in opposi-
tion to the data protection requirement that customers know where and what
happens to their data.
11.2.2
Threat Model and Assumption
In this paper, we focus on three types of threats to privacy that result from
sharing users’ media data via the cloud. 1) The fragility of local software and
hardware on mobile clients. Users’ devices can be stolen or accessed. The lo-
cal data on disk can be accessed by others via the software bugs or device
jail-breaking. 2) The eavesdropping on the communication links, e.g., unpro-
tected WiFi. The communication path is very complex from the mobile de-
vice to the cloud server with multiple independent physical links and vendors.
Security risks that threaten the communication include eavesdropping, inter-
ception, man-in-the-middle attacks, and DNS spooﬁng. 3) The untrustable
cloud service providers. They may leak users’ privacy, either by commission
or omission. Inadequate storage protection, attacking or hacking the server,
and unauthorized server access are all possible ways of privacy breach.
11.2.3
Compatible with Existing Cloud Services
The key point we keep in mind is that we cannot overthrow the existing
cloud backend and mobile client, which is the essential part of the current
media-rich social networks. Few will like privacy-preserving products with less
functionality; few will try a new product that is completely incompatible with
their existing software or subscribed services. For example, users are lured to
use free terabyte-level photo storage services like Flickr, although they are still
concerned with the privacy of their posted photos even with a “lock” icon;
users are attracted to sharing their videos and photos with their families or
friends, but still concerned about eavesdropping or privacy leakage.
The goal of this chapter is to design a full privacy protection scheme that
enables users to protect the privacy of their media data in a transparent way,
while still beneﬁting from the existing cloud services, e.g., Flickr, Facebook,
YouTube. One possible solution is to keep the media format with perceptual
encryption, i.e., format-compliant.
11.2.4
Format-Compliant and Compression-
Independent Solutions
Privacy-persevering algorithms should not aﬀect the operation of image/video
codecs, and the need to preserve the format. Mobile devices usually apply a

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
227
standardized video codec with hardware acceleration for image/video com-
pression and decompression, which is often packed into a stand-alone module
and not accessible to developers. Standardized video codec technologies like
MPEG-1, MPEG-2 (ISO/IEC, 2000), MPEG-4, and H.26X AVC (advanced
video coding) are widely applied in current mobile devices for eﬃciently trans-
mitting/storing videos over bandwidth-limited networks via compression. Al-
gorithms with joint compression and encryption are proposed to achieve secu-
rity/privacy and compression rate at the same time [88]. However, these ap-
proaches need to break down the existing hardware-accelerated codecs, which
are hard to access, and it is ineﬃcient to realize all the standard formats in cur-
rent mobile devices. Thus, compression-independent algorithms are preferred
to joint compression and encryption approaches, with no need to modify the
existing codec.
11.3
System Design
11.3.1
Design Objective
Compared with text or small binary data, media data is characterized by a
number of peculiarities, such as large data size, various resolution/rate ver-
sions, real-time requirements for video, the use of standardized hardware-
accelerated codecs, high compression-rate requirement, standardized data for-
mats, and user-speciﬁc privacy requirements. These peculiarities raise a couple
of speciﬁc requirements for privacy-persevering techniques.
Hardware Acceleration: Leveraging the existing cloud and mobile so-
lutions, we propose approaches that perform chained media transform via the
OpenGL Shader. The superior of the Shader is its full parallel computation ar-
chitecture leveraging GPU. We utilize the Fragment Shaders in the OpenGL
rendering pipeline (after Rasterizer) for the pixel manipulation required in
our proposed algorithm. The size covered by a fragment is related to the pixel
area. The current Shader program could perform pixel-level computation at
full frame rate.
Keep Existing Code Intact: Although GPU is faster, it is still not
compatible with existing solutions in the mobile client. Most of the apps are
built upon normal picture and video framework that does not have OpenGL
canvas. Our solution is to build our transform-based media cipher as an image
ﬁlter. Developers only need minimum change to their existing code base, i.e.,
add one ﬁlter to the photo or video.
11.3.2
Proposed Approach
The proposed privacy protection architecture is shown in Fig. 11.1. In terms
of encryption algorithm, our objective is to jointly achieve format-compliance,
compression-independence, and correlation-preserving. However, it seems that

228
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
these goals conﬂict with each other, and there is no solution yet available that
could meet all these criteria for our application demand. Putting the encryp-
tion before compression, e.g., image scrambling and permutation approaches
via chaotic map, could be format-compliant and compression-independent,
but inherently conﬂict with correlation-preserving.
We propose a privacy-preserving scheme based on encryption before com-
pression, and solving its inherent problems of correlation loss and transmission
error sensitiveness. We also propose an additional feature that allows users to
choose arbitrary photos as the encryption keys instead of remembering a long
password. The algorithm detail will be illustrated in Section 11.4.
Figure 11.1: System Architecture.
11.4
Privacy Protection Algorithm Design
11.4.1
Design Principles
The proposed privacy-preserving scheme puts encryption before compres-
sion, and jointly achieve format-compliance, compression-independence, and
correlation-perserving via three core steps: 1) Chaotic Mapping; 2) Whitening;
3) Block Substitution.
Unlike traditional Chaotic Mapping approaches [122], we utilize general-
ized low-order chaotic mapping to minimize the correlation loss, and make
the decryption process insensitive to the transmission noise of the encrypted
media. The reduced security level is compensated by the Whitening and Block
Substitution stages.

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
229
The Whitening process is diﬀerent from the traditional random noise-based
approach. Instead of using a random bit map for XOR operation [51], we
allow users to select any photo as the random key map. The XOR process is
generalized from the bit operation to image pixel operation. This step enhances
the security level by using the users’ own photo as a perceptual key instead
of a long password.
The Block Substitution stage further enhances the security level via
random-like pre-deﬁned patterns.
11.4.2
Chaotic Mapping
11.4.2.1
Pros and Cons of Chaotic Mapping
Among existing encryption methods, the chaos map-based image encryption
method is a family of methods that are good for encryption purposes due to
its high sensitivities to its parameters and initial values, the mixing property
and the ergodicity [122]. Chaos-based image encryption methods have been re-
searched for years since Fridrich’s ﬁrst approach for digital image encryption
[26]. Many existing chaotic image encryption algorithms have good crypto-
graphical properties, but they also have defects when compared with normal
cryptosystems. The most signiﬁcant problem when applying the chaotic map-
ping in our proposed application is its round-oﬀerror, which may make the
decrypted image/video blurred especially after multiple rounds or higher or-
ders. The nonreversible problem is caused by the real number deﬁnition of
chaotic systems, i.e., inﬁnite scale, while a normal cryptosystem is deﬁned on
ﬁnite numbers. The round-oﬀerror in real number quantization is small but
intolerable for current high deﬁnition image/video requirements.
To deal with the round-oﬀproblem, several nonchaotic image encryp-
tion methods were researched by using various random-like patterns [124].
Although these nonchaotic approaches eliminate round-oﬀerrors by using
random-like patterns, their confusion and diﬀusion properties are not good
enough. To overcome the round-oﬀproblem of chaotic image encryption and
improve the confusion and diﬀusion properties of the nonchaotic approach, we
propose a chained solution under the guideline of the Markov cipher by using
generalized low-order chaotic mapping and multi-channel block substitution
via a nonchaotic random pattern.
11.4.2.2
Generalized Low-Order Chaotic Mapping
Deﬁne the chaotic mapping as Γ. Using Γ for image encryption, it should be
invertible. There are lots of chaotic maps available, e.g., Arnold’s cat map,
Baker’s map, logistic map, tent map. Using the Arnold’s cat map as an exam-
ple, the transform of Γ could be written as Γ : (x, y) →(2x+y, x+y) mod N,
where N is the pixel dimension. The initial coeﬃcient of the Arnold mapping
is ar = [2
1; 1
1]; its higher order O-th could be written as aO
r . We encrypt
the image frame with diﬀerent orders of Arnold transform. The encrypted

230
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
images are shown in Fig. 11.2. It is clear to see that higher order contributes
a better encryption property with higher randomization. However, higher or-
ders show pixel blur due to the ampliﬁcation of the round-oﬀerror as stated
before.
Figure 11.2: Encrypted and decrypted image under diﬀerent orders of
chaotic map.
To minimize the round-oﬀerror, a low-order chaotic map should be uti-
lized. However, a low-order chaotic map has a poor encryption property. An-
other problem for existing chaotic maps is the limited unknown parameters,
i.e., coeﬃcients for a chaotic map is well deﬁned. Using the coeﬃcients and
initial values as the encryption key is not secure enough.
Our solution is to generalize the chaotic map by maintaining its basic
properties, and eliminate other unused properties, e.g., periodic property (re-
turning to its original state after a number of steps). The basic requirement

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
231
for the chaotic mapping Γ is det(Γ) = ±1 and therefore its inverse has inte-
ger entries, where det· calculates the determinant of the matrix. The initial
coeﬃcient of the Arnold mapping is [2
1; 1
1], which is well known and less
secure. By generalizing the Arnold mapping, we could have Γ = [a
b; c
d],
where ad −bc = ±1. The ﬁrst few orders of Γ also satisfy our requirements.
11.4.3
Whitening and Probabilistic Transformation
In cryptography, key whitening is a common technique to increase the security
level of a cipher by mixing the data with the key, e.g., in DES and AES [124].
The most common form of whitening is using XOR (exclusive or) bit operation
between a plaintext message and a key. For image data where each pixel is
bytes instead of the bit, typical solutions could include iteratively applying the
XOR to each bit from the most signiﬁcant bit (MSB) to the least signiﬁcant bit
(LSB). However, such XOR operation via multi-iteration becomes ineﬃcient
for a color image.
As stated in [124], the XOR operation could be generalized to transposition
in the ﬁnite ﬁeld by y = (x+s) mod 255, where x is the input, y is the output,
and s is the corresponding byte in the key matrix. Instead of using generated
matrix as the key, we provide a scheme that could allow users to deﬁne the key
matrix by just selecting their own image/photo. Using the user’s own image
data could result in a very long key and help users to remember their own
passwords easily. Motivated by using a personal photo as a key, we have the
pixel-level encryption process as
C(i, j, k) = (RF(I(i, j, k)) + RF( ˆS(i, j, k))) mod 255
(11.1)
where RF(I(i, j, k)) and RF( ˆS(i, j, k)) are the transformed input image and
key image, respectively. The transformation process depends on the value of
k = 1, 2, 3 for the color space. RF(·) could ﬂip the row up to down, ﬂip the
column left to right, or perform matrix transposition. The selection of all these
transformations is determined by a random probability ρ ∈[0, 1]. RF(·) could
be written as
RF(I(i, j, k)) =
(11.2)



IT (i, j, 1) + Fx(I(i, j, 2)) + Fy(I(i, j, 2))
if ρ ∈[0, 0.1]
Fy(I(i, j, 1)) + Fx(I(i, j, 2)) + IT (i, j, 3)
if ρ ∈(0.1, 0.2]
· · ·
if ρ ∈(0.2, 0.3]
Where Fx(·) is ﬂip the column left to right; Fy(·) is ﬂip the row up to down.
The determined ρ is also one part of the key and should be transmitted to the
receiver side. The added transformation of RF(·) is to improve the randomness
of image whitening, and make it perceptually unrecognizable.

232
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
11.4.4
Multi-Channel
Block
Substitution
via
Latin
Square
Non-chaotic mapping approaches via random-like pattern in the integer do-
main could eliminate the round-oﬀerror in chaotic approaches. However, the
drawback lies in its weak random properties that would not guarantee a suf-
ﬁcient security level, i.e., do not have good confusion and diﬀusion.
In this subsection, we propose to utilize the Latin square as the random-
like pattern, and enhance its security level via these approaches: 1) multi-
channel processing in the color domain; 2) normalized block substitution for
scale-independence.
Latin
Square. For dimension N, deﬁne the symbol set as S
=
{S0, S1, · · · , Sk, · · · , SN−1},
the
indicator
function
of
Latin
square
is
fLatin(i, j, k). A Latin square L(i, j) is a square matrix that each sym-
bol in S appears exactly once in each row and each column, where the
indicator function is fLatin(i, j, k)
=
1 when L(i, j)
=
Sk; otherwise
fLatin(i, j, k) = 0. For each row, we have PN−1
i=0 fLatin(i, j, k) = 1; for each
column, PN−1
j=0 fLatin(i, j, k) = 1, which implies that symbol Sk is occurred
once in each row and column.
Multi-channel and Normalized Block Substitution. In general, the
permutation procedure is to ﬁnd a bijective mapping for bit/pixel. The prop-
erty of the Latin square matrix is a permutation of the integer number se-
quence of length N, which naturally becomes a one-to-one bijective mapping
for pixel locations. Assume the input image frame is I(i, j) with size as Nr×Nc.
The Latin square size is N × N. To make the proposed approach suitable for
various frame sizes, we perform normalization for the input frame I(i, j) via
N{I(i, j)}. For pixel ((i, j)) in I(i, j), the new indexes for the row and column
after normalization are ¯i = i/Nr ∈[0, 1] and ¯j = j/Nc ∈[0, 1], respectively.
For color images, each pixel of I(i, j) or I(¯i, ¯j) is a tuple (red, green, blue)
on a 0 to 255 scale. For better randomization, we divide the tuple into three in-
dependent channels as Ired(¯i, ¯j), Igreen(¯i, ¯j), and Iblue(¯i, ¯j), Latin square sub-
stitution could be performed for each color space with diﬀerent Latin squares
(Lred, Lgreen, Lblue) as keys.
For each substitution via Latin square, the row and column could be per-
formed independently. Using column substitution for the red channel as an
example, the new obtained pixel position could be written as
¯js
red = f S
j (Lred,¯i, ¯j) = Lred(⌊¯i × N⌋, ⌊¯j × N⌋) + ¯j −⌊¯j × N⌋
(11.3)
where ⌊¯i × N⌋and ⌊¯j × N⌋calculate the block position in the Latin square
matrix (N) of the current normalized pixel (¯i, ¯j); ¯j −⌊¯j × N⌋calculates the
remainder pixel position within the block for column. The row substitution
could be written as
¯is
red = f S
i (Lred,¯i, ¯j) = Lred(⌊¯i × N⌋, ⌊¯j × N⌋) +¯i −⌊¯i × N⌋
(11.4)
(11.3) and (11.4) combined and performed for the three RGB channels with

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
233
diﬀerent Latin squares could be the forward encryption process via random-
like pattern substitution. The input pixel (¯i, ¯j) of (11.3) and (11.4) con-
structs the plaintext of the input image frame in red space, where the output
(¯is
red, ¯js
red) is the pixel of the ciphertext in red space.
The inverse process for (¯is
red, ¯js
red) in the row and column direction, i.e.,
the encryption, could be written as
¯i = arg
max
z=⌊¯is
red×N⌋(fLatin(¯is
red, z, ¯js
red)) +¯is
red −⌊¯is
red × N⌋
(11.5)
¯j = arg
max
z=⌊¯js
red×N⌋(fLatin(z, ¯js
red,¯is
red)) + ¯js
red −⌊¯js
red × N⌋
where fLatin(·) is the indicator function of Latin square Lred. The element of
fLatin(i, j, k) is most zero with only one ‘1’ element (fLatin(i, j, k) = 1 when
L(i, j) = Sk), i.e., the maximum is equal to 1. This process implements the
inverse searching over the Latin Square and decrypts the image pixel row and
column location, and recovers the plaintext from the ciphertext.
11.4.5
Security Analysis
To ensure security level, the cipher scheme should be robust enough for a
brute-force attack, or exhaustive key searching. Hackers may crack any en-
crypted image ﬁle by searching all possible keys in the key space until the
right key is found. The key length plays an important role in an encryption
system, and determines the feasibility of attack. Bigger key space means more
diﬃculties in terms of time complexity.
The proposed encryption process contains three parts: 1) Chaotic Map-
ping, where the total available mapping number determines the security level;
2) Whitening and Probability Transformation, where the key image and the
number of transformations are the key for the high security; 3) Latin Square,
where the size of the Latin square matters. The low-order chaotic mapping
number is in the range of p1 = 100; the number of transformations is in the
range of p2 = 10, while the size of the Latin square is 256 × 256. The total
number of these spaces is near pt = 256! × 256! × 100! × 10!. In addition to
the encryption key space, we also utilized the custom image as the key with
a size of 256 × 256. Combing the pt and the custom image key, the key space
becomes very large and cannot be easily attacked via brute force.
11.5
Evaluation
11.5.1
System Evaluation
11.5.1.1
Media Sharing Process
Fig. 11.3 shows our designed secure media sharing process to open social media
channels. We leverage the image key in addition to the normal key for better

234
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
security. To meet the design objective of easy-to-use and low-complexity com-
putation, we integrate our proposed privacy-preserving techniques into one
customized image ﬁlter. The image ﬁlter works in the raw image domain and
does not require image format compliance. A highly integrated block could
simplify the integration process to existing code. To improve the eﬃciency for
the pixel-wise computation in our approach, we design and implement this
customized image ﬁlter in the GPU via the OpenGL Shader. Shader is a pro-
gram designed to run on some stage of a graphics processor, and written in the
OpenGL Shading Language. We utilize the Fragment Shaders in the OpenGL
rendering pipeline (after Rasterizer) for the pixel manipulation required in
our proposed algorithm. The size covered by a fragment is related to the pixel
area. Thus, the computationally intensive pixel-by-pixel operation could be
converted to fragment processing with highly paralleled implementation in
GPU. The reason that we utilize normalization and block-based processing
in algorithm design is to ﬁt the GPU Shader processing framework for high
computation eﬃciency.
Figure 11.3: The secure media sharing process.
The encrypted image/video ﬁle, i.e., the ciphertext, can be shared with
open media channels, e.g., Facebook, Twitter. The eavesdropper or other
unauthorized users cannot get the real meaning of the ciphertext. On the
receiver-side, the encrypted image can be decrypted via the key image and
the normal key.
11.5.1.2
Computational Complexity
To evaluate the computational eﬃciency and execution time, we compare the
combination of our proposed approaches with standard AES 256 cipher and
joint JPEG encryption and compression approaches [88, 105]. Since we do not
have the implementation of the joint JPEG encryption and compression, we
utilize the software module of JPEG compression to emulate the approaches
in [88, 105]. The rationale is: 1) Adding encryption to the JPEG compression

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
235
module should take longer computation time; 2) Changing the JPEG com-
pression requires the use of software implementation, which cannot utilize the
existing hardware accelerated version.
In Fig. 11.4, we compare 1) Chaotic Mapping; 2) Chaotic Mapping
+ Whitening; 3) Chaotic Mapping + Whitening+ Block Substitution; 4)
Hardware-Accelerated AES256; 5) Software-Based Compression. All these
cases include the complete process from reading the data, encryption, and
compression, whereas cases 1–4 utilize the standard hardware-accelerated
compression module. The results are obtained from the Apple iPhone5S via
diﬀerent image/video sizes. The three test cases are: 1) 48KB image; 2) 4.2MB
image; 3) 32.9MB video. From Fig. 11.4, we observe at least threefold improve-
ment in the execution time when compared with the standard highly optimized
AES 256 cipher. The software solution of compression is even slower than the
AES cipher. Adding more steps to our Shader-based approach does not in-
crease the execution time signiﬁcantly, i.e., cases 1–3 do not diﬀer too much.
48KB
4.2MB
32.9MB
0
1
2
3
4
5
6
7
8
9
Execution Time (s)
 
 
Mapping
Mapping+Whitening
Mapping+Whitening+Substition
AES256
Soft Compression
Figure 11.4: The execution time of diﬀerent approaches.
11.5.2
Security Analysis
11.5.2.1
Whitening and Probabilistic Transformation
Fig. 11.5(a) shows the utilized sample key image in the whitening process.
After performing the operation in (11.1), the XOR mixed ciphertext without
probabilistic transformation (PT) is shown in Fig. 11.5(b). One problem of

236
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
the normal XOR process is the potential leakage of the key image if the input
image is monochrome. As shown in the lower part of Fig. 11.5(b), we could
see the coarse outline of the key image. This problem could be solved by
leveraging the probabilistic transformation as shown in Fig. 11.5(c), which
adopts diﬀerent transforms in the three color channels.
(a) Key Image
(b) without PT
(c) with PT
Figure 11.5: Whitening via key image: 1) Key image; 2) Homogeneous
whitening via XOR mixing without PT; 3) non-homogenous whitening
via XOR mixing with PT.
11.5.2.2
Multi-Channel Block Substitution
Fig. 11.6(a) shows the row substitution result with the only color channel. The
obtained noisy image is still perceptually visible. Even for the two-channels
result Fig. 11.6(b), it is still insuﬃcient for concealing the details. After using
three channel substitution, Fig. 11.6(c) shows the ﬁnal encrypted image with
high randomness.
(a) One Channel
(b) Two Channels
(c) Three Channels
Figure 11.6: Color image after substition via diﬀerent color channels: 1)
red channel; 2) red and green channel; 3) all three channels.

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
237
The image histogram for the encrypted image in Fig. 11.6(c) is shown in
Fig. 11.7(b). Compared with the initial plaintext in Fig. 11.7(a), the histogram
of the ciphertext is ﬂattened via the multi-channel block substitution process,
which implies a high security level.
50
100
150
200
250
0
200
400
600
800
1000
1200
1400
RGB Value
Histogram
(a) Plaintext
50
100
150
200
250
0
50
100
150
200
250
300
RGB Value
Histogram
(b) Ciphertext
Figure 11.7: The color histogram for (a) plaintext; (b) ciphertext.
11.5.2.3
Overall Security Level
We propose approaches to preserve the correlation via low-order chaotic map-
ping. The reduced security level of chaotic mapping is compensated by the
whitening and block substitution processes. The homogeneous problem of
block substitution is also solved by the non-homogeneous transform in the
chaotic mapping process and the whitening process. Fig. 11.8(a) shows the
correlation result between the ciphertext and plaintext; the resulting correla-
tion is almost zero in most areas, i.e., higher randomness and better security
level. Fig. 11.8(b) shows the correlation result between the decrypted image
and plaintext with a very high peak correlation, i.e., perfect recovery. This
chained solution balances complexity and security level, and meets our objec-
tive for correlation-preserving.
11.5.3
Correlation Preserving and Noise Robustness
Our proposed privacy-preserving scheme preserves the input format, inde-
pendent of the existing compression module. For video data, the correlation
between frames is also preserved. The rationale is as follows: 1) The utilized
chaotic mapping is low-order and only performs one iteration, making the im-
age frame with the same context to produce similar output rather than the

238
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
(a) Encrypted
(b) Decrypted
Figure 11.8: The normalized correlation coeﬃcient for (a) encrypted im-
age; (b) decrypted image.
random output in true chaotic mapping. 2) The whitening and block substi-
tution process are invertible, consistent according to the key, and no random
noise is added.
To quantify the correlation between diﬀerent image frames, we utilize the
maximum normalized correlation coeﬃcient (MNCC) as a metric [91]. We
randomly change the pixel of the initial image/video frame in terms of pixel
diﬀerence in percentage (the x-axis of Fig. 11.9(a)). The calculated MNCC
of the initial frame is shown in Fig. 11.9(a) with decreasing trends. From
Fig. 11.9(a), the normal encryption process via chaotic mapping results in a
very low correlation, which is intentional in terms of protecting the plaintext.
However, we need to preserve the correlation between adjacent image frames
for better compression ratio to save the communication cost. As shown in
Fig. 11.9(a), our proposed chained approaches could preserve the correlation
when the pixel diﬀerence is low.
Another important requirement for our cipher system is the noise robust-
ness when sharing and transmitting the media over the lossy channel. To
evaluate the noise robustness, we randomly add noise to the encrypted media
data. Fig. 11.9(b) shows the MNCC with regard to the diﬀerent percentage
of pixel error when the noise is added. When the noise becomes strong, i.e.,
more pixels are aﬀected, the MNCC of our proposed approach decreases slowly,
which demonstrates strong robustness over the transmission error. However,
the normal approach shows very quick decreasing of MNCC due to the high-
order chaotic mapping.
To get a perceptual feeling of the noise robustness, we set the same pixel
error for the encrypted image. Fig. 11.10(a) shows the decrypted image via the
normal approach; Fig. 11.10(b) shows the decrypted image using our proposed

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
239
0
0.02
0.04
0.06
0.08
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Pixel Difference (Percentage)
Normalized Correlation Coefficient
 
 
Initial Frame
Encrypted (Normal)
Encrypted (Proposed)
(a) Correlation Preserving
0
0.02
0.04
0.06
0.08
0.1
0.4
0.5
0.6
0.7
0.8
0.9
1
Pixel Difference (Percentage)
Normalized Correlation Coefficient
 
 
Encrypted Frame
Decrypted (Normal)
Decrypted (Proposed)
(b) Robust to Noise in Transmission
Figure 11.9: The maximum normalized correlation coeﬃcient.
chained approach. Apparently, our proposed approach achieves better image
quality under the same transmission error.
(a) Normal Approach
(b) Proposed Approach
Figure 11.10: Robust to noise in transmission.
11.6
Related Work
Protecting media data privacy without sacriﬁcing the services provided by
cloud service providers requires format-compliant encryption solutions. The
format-compliant encryption technique can be divided into three diﬀerent
parts according to the relative position of the encryption and compression
module.

240
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
Encryption after Compression. Putting the encryption after compres-
sion could minimize the processing data size. Authors in [119] proposed solu-
tions to place it after compression and maintain the format compliance. The
core idea is to only encrypt the information-carrying ﬁelds, and leave the syn-
tax part unencrypted. The selective encryption scheme could also be applied
according to the various privacy requirements. However, the encrypted code
words may not be the valid code words deﬁned in the MPEG standard [45].
This scheme also requires fairly deep parsing into the bit stream to identify
the parts of the bit stream to be encrypted [51]. This incurs a signiﬁcant pro-
cessing overhead. Zhu et al. [136] state that this scheme is even slower than
naive algorithm.
Joint Compression and Encryption. Joint compression and encryp-
tion could solve this problem and be inherently compliant with the syntax for-
mat without bit stream identiﬁcation because the syntax is formatted before
the compression process. Authors in [88] proposed solutions that threshold the
coeﬃcient of DCT transform of photos into two parts. The main part is stored
in a JPEG-compliant format to leverage the cloud services; the other part is
encrypted and transmitted via diﬀerent service providers, e.g., Dropbox. How-
ever, this process only suits the DCT-based photo compression format, e.g.,
JPEG, not other formats. The transmission of two parts per-photo is not con-
venient. Another practical problem is that the solution needs to break down
the photo DCT and compression loop. Re-implementing the whole process
is not eﬃcient and fast enough compared to the native hardware-accelerated
versions.
Encryption before Compression. Putting the encryption before com-
pression and making it compression-independent could comply with the for-
mat syntax. Most image scrambling and permutation approaches belong
to this category. For example, using chaotic mapping could be a good
format-compliant cipher [122, 124, 123]. One signiﬁcant challenge for these
compression-independent approaches is the correlation loss between contin-
uous video frames [124, 122]. Encryption algorithms disorder the inherent
redundancy of the input plaintext using cryptographic operations, and make
it independent for two plaintexts even with the same key. As a result, the fol-
lowing compression ratio will be very low since there is much less inter-frame
redundancy to compress. Another problem is the pixel error sensitivity. When
some transmission error happens, the initial image cannot be decrypted even
with the same key.
11.7
Conclusion
In this chapter, we aimed to overhaul cloud media sharing by letting users
assure themselves that no one can eavesdrop or understand what they are
watching, posting, and communicating. To meet the objective of designing
a format-compliant, compression-independent, and correlation-preserving ci-

Hiding Media Data via Shaders: Enabling Private Sharing in the Clouds
■
241
pher, we proposed chained approaches via chaotic mapping, image-based key
whitening, and Latin square pattern-based substitution. Users can choose their
favorite image as the key instead of remembering a long password. To lower
the computational cost and encryption delay, we propose to utilize the GPU
Shader for parallel pixel processing. We integrate all the proposed approaches
into a customized image ﬁlter for easy use without modifying the existing code
base. Experimental results demonstrate a suﬃcient security level for cloud me-
dia data.


Chapter 12
CONCLUSION AND
FUTURE DIRECTIONS
Kaikai Liu
Assistant Professor, San Jose State University
Xiaolin Li
Associate Professor, University of Florida
CONTENTS
12.1
Book Summary ...................................................
243
12.2
Future Directions ................................................
245
12.1
Book Summary
In this book, we proposed a complete location ecosystem for future mobile
smart life application, including hardwares (anchor nodes, wearable tags),
ﬁrmwares (DSP in RTOS, Zigbee/BLE/Audio), algorithms (ﬁne-grained lo-
calization, social cooperative localization), Smartphone Apps (crowd sensing,
mobile social networks), and cloud servers (algorithm oﬄoading, streaming
processing, messaging, and datastore).
In the ﬁrst part, we proposed a practical and accurate multi-modal step-
by-step navigation eco-system, codenamded Guoguo, that assists the blind
and visually impaired towards an independent and digniﬁed lifestyle when
navigating indoors (e.g., navigating to the bathroom without assistance). The
prototype eco-system utilizes various software and hardware components to
243

244
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
ﬁll the long-lasting gap of indoor localization. Guoguo consists of an anchor
network with a coordination protocol to transmit modulated localization bea-
cons using high-band acoustic signals. To address the challenges of utilizing
the audible-band acoustic signal in smartphone localization, i.e., strong at-
tenuation, interference-richness, high sound disturbance, and diﬃculty in syn-
chronization, we proposed comprehensive schemes to improve the localization
accuracy and extend coverage without sound disturbance. For the ﬁrst time,
we can locate a smartphone user at the centimeter-level, which has signiﬁcant
implications for potential indoor location services and applications compared
with existing meter-level localization solutions. We further propose approaches
to improve its coverage, accuracy, and location update rate with low-power
consumption. Experimental results demonstrated that the achieved average
localization accuracy is about 3 ∼10cm in a typical indoor environments.
Guoguo represents a leap in progress in smartphone-based indoor localiza-
tion, opening enormous new opportunities for indoor location-based services,
positioning and navigation systems, and other commercial, educational, or
entertainment applications. The location approaches described here are the
prototype eco-system that will eventually fuse several complementary assis-
tance softwares together towards accessibility assistance and navigation for
the blind, disabled, and ultimately the elderly.
In the second part, we focused on the application of accessing the infor-
mation automatically via context-awareness. Based on the location estimation
approach in the ﬁrst part, we pushed location awareness to context-aware aug-
mented reality (AR). AR aims to render the world that users see and overlay
information that reﬂects the real physical dynamics. The digital view could
be potentially projected near the Point-of-Interest (POI) in a way that makes
the virtual view attached to the POI even when the camera moves. Achieving
smooth support for movements is a subject of extensive studies. One of the
key problems is where the augmented information should be added to the
ﬁeld of vision in real time. Existing solutions either leverage GPS location for
rendering outdoor AR views (hundreds of kilometers away) or rely on image
markers for small-scale presentation (only for the marker region). To realize
AR applications under various scales and dynamics, we proposed a suite of
algorithms for ﬁne-grained AR view tracking to improve the accuracy of atti-
tude and displacement estimation, reduce the drift, eliminate the marker, and
lower the computation cost. Instead of requiring extremely highly accurate
absolute locations, we proposed multi-modal solutions according to mobility
levels without additional hardware requirements. Experimental results demon-
strated signiﬁcantly less error in projecting and tracking the AR view. These
results are expected to make users excited to explore their surroundings with
enriched content.
In the previous two parts, we focused on the infrastructure-based ﬁne-
grained approach. However, in some applications, e.g., locating lost children
or other group members in an open and uncontrolled area, infrastructure is
not always available. To solve this problem, we move from infrastructure-

CONCLUSION AND FUTURE DIRECTIONS
■
245
based solutions to crowd sensing in the third part, and further push the lo-
cation sensing solution for broader impact via participatory social networks.
For applications like guarding a child or pet in crowded places full of attrac-
tions, conventional location tracking approaches require ﬁxed anchor networks,
ﬁngerprinting points as references, or bulky devices with GPS and cellular
connections. The newly proposed miniature wearable devices are attractive
in terms of cost, size, and portability. However, locating a lost child/pet in
open and uncontrolled areas without the high-cost cellular and GPS track-
ers is mission impossible due to the limited communication coverage of the
miniature wearable devices. To overcome this limitation, we proposed mobile
crowd sourcing/sensing (MCS)-based collaborative localization via nearby op-
portunistically connected participators with smartphones. To obtain suﬃcient
measurements for better location resolution, we utilized one-hop and multi-
hop assistants to reach more participators for transparent sensing assistance.
To overcome the bias and unsolvable problem caused by insuﬃcient measure-
ments in crowd sensing, we proposed global optimization approaches based on
semideﬁnite programming (SDP) via sparse measurement constraints. Multi-
hop opportunistic ranging and coarse-grained location information are lever-
aged to jointly optimize the location of the wearable tag and assistant with
unknown locations. We conducted extensive experiments and simulations in
various scenarios. Compared with other classic algorithms, our proposed ap-
proach achieves signiﬁcant accuracy improvement and could locate the “unlo-
calizable” child. Utilizing the ubiquitousness of “crowds” of sensor-rich smart-
phones, our proposed approach has enormous potential to truly unleash the
power of collaborative locating and searching at a societal scale.
12.2
Future Directions
The new generation of smartphones has almost realized the early vision of
Mark Weiser’s vision/dream from a human-computer interaction perspective:
computing everywhere, personal computing, the social dimension of comput-
ing, and privacy implications [96]. Multiple technical approaches are moving
towards these envisioned mobile smart life applications. One of the key ap-
proaches is context-awareness that facilitates real-world interaction of com-
puting, whereas the location plays the key role in context conﬁgurations.
In this book, we proposed enabling techniques for three envisioned mobile
smart life applications: 1) helping the blind or other disabled to live inde-
pendently via step-by-step navigation; 2) accessing the information automat-
ically via context-awareness; 3) locating lost children or other group mem-
bers via mobile crowd sensing. The next step is facilitating the real-world
impact of more complex location and context recognition, moving towards
next-generation opportunistic context-awareness and large-scale ensembles of
crowd sensing interacting with social entities. For example, with ﬁne-grained
location/pose/activity sensing, context-aware information can be pushed to

246
■
Towards Mobile SmartLife via Sensing, Localization, & Cloud Ecosystems
you automatically without any keyword typing in explicit search engines. Your
mobile device, e.g., smartphone or wearable tag, could be your assistant cov-
ering both online and oﬄine. Your group members will not only include online
“friends” but also entities with whom a person has a relationship (e.g., chil-
dren, elders, pets) with a wearable tag; they can interact with each other in
a transparent, reactive, and proactive manner beyond the conventional online
social networks (where users perform common interactions such as manually
typing, searching, and posting).
The results of the techniques studied in this book, with both their lim-
itations and their promises, are moving towards these environed smart life
scenarios. However, there are many research directions waiting to be explored.
Rehabilitation Technology for the Blind. People who are visually
impaired face a multitude of challenges every day that can prevent them from
getting where they want to go, even giving up places that are essential to their
life, e.g., school, clinic, retail store, and city facilities. The journey to public
places is very daunting and leaves them stressed and anxious. We proposed
a system architecture and enabling techniques for smartphone based step-by-
step navigation for the blind. To fully enable the freedom of mobility for the
blind, signiﬁcant eﬀorts in the areas of sensing, voice interaction, and social as-
sistance is needed. The blind’s navigation system should start by establishing
their location within the building, and on the map. It will require voice input
for the destination or purpose, and then determines the best route or action to
get them done, and guides them along it via verbal cues and feedbacks. This is
because visually impaired people would have diﬃculty using the smartphone’s
display to understand where they are located, and what’s nearby. Everything
should be done verbally. Speech recognition approaches via the smartphones or
any other wearable device’s microphone are necessary. The speech recognition
engine should not only understand what they need, but also needs to per-
form related actions. However, indoor navigation and interaction is far more
complex than outdoor GPS navigation via voice assistance, where the road
is clear and predeﬁned. There are so many obstacles, blockages, ﬂoors, and
routes in indoor places, e.g., door, staircase, elevator, and restricted areas. The
voice interpretation is inaccurate and not rich enough when compared with
normal people’s vision. Existing speech recognition and interaction engines
highly rely on their knowledge set or database, whereas special commands
and voice-related map interactions should be deﬁned speciﬁcally for complex
indoor navigation purposes.
Context-Awareness and Augmented Reality. Augmented reality
(AR) has been in science ﬁction for decades [33]. Thanks to the power of
smartphones, the technology is almost here to make it happen, e.g., existing
GPS location-based AR for nearby Points-of-Interest (POI), image marker-
based solutions for rendering additional information. Mobile tech keeps mov-
ing toward AR, but it is still far from perfect in terms of object recognition
and AR view tracking with various mobilities. We proposed one approach via
sensor fusion to achieve eﬃcient AR view tracking, and this gives us an insight

CONCLUSION AND FUTURE DIRECTIONS
■
247
into the exciting future possibilities for AR applications. To really achieve the
dreamed of AR potentials, lots of barriers must be overcome. Possible exten-
sions include energy eﬃcient vision sensing; highly reliable attitude and loca-
tion sensing; sensor fusion via INS and computer vision; realtime processing
back for recognition; machine learning back-end for context recommendation.
All these techniques are expected to have high impact in the future smart life
applications and our daily activities.
Wearable and Cyber-Physical Social Networking. The recent tran-
sition to smart wearables opens up a slew of new opportunities for vendors,
developers, researchers, and manufactrures. Growth in the smart wearables
points to an emerging battleground for future smart life applications. In this
dissertation, we proposed solutions for wearable-based group member tracking
and localization via mobile crowd sensing. The demand for other innovative
applications related to security or other areas has been absolutely astound-
ing, e.g., ﬁtness, identiﬁcation, notiﬁcation. These will raise the expectations
of what a smart wearable can do. We are not there yet, but we are seeing
the building blocks of what is to come. Several key challenges associated with
smart wearables include portable hardware design with longer battery life,
energy eﬃcient localization approaches, context-awareness, and wireless con-
nectivity via multi-hop assistance. When the wearable devices are ubiquitously
available for everyone, a new way of social interaction could be designed via
nearby sensing and interaction that mimics the real physical encounters. Par-
ticipatory crowd missions could be conducted in a transparent way without
disturbing the users. Incentive mechanism design is the key for these mobile
crowd applications.


References
[1] Geosocial and location-based services on smartphones. 2011.
[2] AccessMagazine. Fixing broken sidewalks, 2015.
[3] ADA. Americans with Disabilities ACT: Guide for places of lodging,
2015.
[4] Apple. Cmattitude class reference, 2014.
[5] Apple. ibeacon, 2014.
[6] M. Azizyan, I. Constandache, and R. Roy Choudhury. Surroundsense:
mobile phone localization via ambience ﬁngerprinting. In Proceedings
of the 15th annual international conference on mobile computing and
networking, pages 261–272. ACM, 2009.
[7] Ronald Azuma, Yohan Baillot, Reinhold Behringer, Steven Feiner, Si-
mon Julier, and Blair MacIntyre. Recent advances in augmented reality.
Computer Graphics and Applications, IEEE, 21(6):34–47, 2001.
[8] P. Bahl and V.N. Padmanabhan. Radar: An in-building rf-based user
location and tracking system. In INFOCOM 2000. Nineteenth Annual
Joint Conference of the IEEE Computer and Communications Societies.
Proceedings. IEEE, volume 2, pages 775–784. IEEE, 2000.
[9] P. Biswas, T.C. Liang, K.C. Toh, Y. Ye, and T.C. Wang.
Semideﬁ-
nite programming approaches for sensor network localization with noisy
distance measurements.
Automation Science and Engineering, IEEE
Transactions on, 3(4):360–371, 2006.
[10] Gaetano Borriello, Alan Liu, Tony Oﬀer, Christopher Palistrant, and
Richard Sharp. Walrus: wireless acoustic location with room-level res-
olution using ultrasound. In Proceedings of the 3rd international con-
249

250
■
References
ference on mobile systems, applications, and services, pages 191–203.
ACM, 2005.
[11] S.P. Boyd and L. Vandenberghe. Convex optimization. Cambridge Uni-
versity Press, 2004.
[12] BSD. Opencv, 2014.
[13] Cassandra. The apache cassandra project, 2014.
[14] Manmohan Krishna Chandraker, Christoph Stock, and Axel Pinz. Real-
time camera pose in a room. Springer, 2003.
[15] Y. Chen, D. Lymberopoulos, J. Liu, and B. Priyantha. Fm-based in-
door localization. In Proceedings of the 10th international conference on
mobile systems, applications, and services, pages 169–182. ACM, 2012.
[16] K.W. Cheung, H.C. So, W.K. Ma, and Y.T. Chan. Least squares al-
gorithms for time-of-arrival-based mobile location. Signal Processing,
IEEE Transactions on, 52(4):1121–1130, 2004.
[17] Chipolo. Chipolo :: Nothing is lost, 2014.
[18] I. Constandache, X. Bao, M. Azizyan, and R.R. Choudhury. Did you
see bob?: human localization using mobile phones. In Proceedings of
the sixteenth annual international conference on mobile computing and
networking, pages 149–160. ACM, 2010.
[19] I. Constandache, R.R. Choudhury, and I. Rhee. Towards mobile phone
localization without war-driving.
In INFOCOM, 2010 Proceedings
IEEE, pages 1–9. IEEE, 2010.
[20] I. Constandache, S. Gaonkar, M. Sayler, R.R. Choudhury, and L. Cox.
Enloc: Energy-eﬃcient localization for mobile phones. In INFOCOM
2009, IEEE, pages 2716–2720. IEEE, 2009.
[21] Cozi. Child tracking: What parents should know, 2014.
[22] D. Dardari, C.C. Chong, and M. Win. Threshold-based time-of-arrival
estimators in UWB dense multipath channels. IEEE Transactions on
Communications, 56(8):1366–1378, 2008.
[23] Bas des Bouvrie. Improving rgbd indoor mapping with imu data. Ph.D.
thesis, Masters thesis, Delft University of Technology, 2011.
[24] Estimote. Estimote beacons real world context for your apps.
[25] Friedrich Fraundorfer and Davide Scaramuzza. Visual odometry: Part
ii: Matching, robustness, optimization, and applications.
Robotics &
Automation Magazine, IEEE, 19(2):78–90, 2012.

References
■
251
[26] Jiri Fridrich.
Image encryption based on chaotic maps.
In Systems,
Man, and Cybernetics, 1997. Computational Cybernetics and Simula-
tion, 1997 IEEE International Conference on, volume 2, pages 1105–
1110. IEEE, 1997.
[27] Raghu K. Ganti, Fan Ye, and Hui Lei.
Mobile crowdsensing: cur-
rent state and future challenges.
Communications Magazine, IEEE,
49(11):32–39, 2011.
[28] M. Grant and S. Boyd. Cvx: Matlab software for disciplined convex
programming. Available at httpstanford edu boydcvx, 2008.
[29] Blippar group. Layar, 2014.
[30] I. Guvenc, C.C. Chong, and F. Watanabe. Analysis of a linear least-
squares localization technique in los and nlos environments. In Vehic-
ular Technology Conference, 2007. VTC2007-Spring. IEEE 65th, pages
1886–1890. IEEE, 2007.
[31] I. Guvenc and Z. Sahinoglu. Threshold-based TOA estimation for im-
pulse radio UWB systems. In IEEE International Conference on Ultra-
Wideband, pages 420–425, 2005.
[32] Richard Hartley and Andrew Zisserman.
Multiple view geometry in
computer vision. Cambridge University Press, 2003.
[33] Simon Hill. Get past the gimmicks and gaze upon the future of aug-
mented reality apps, 2014.
[34] Fabian Hoﬂinger, Rui Zhang, Joachim Hoppe, Amir Bannoura, Leon-
hard M. Reindl, Johannes Wendeberg, Manuel Buhrer, and Christian
Schindelhauer. Acoustic self-calibrating system for indoor smartphone
tracking (assist). In Indoor Positioning and Indoor Navigation (IPIN),
2012 International Conference on, pages 1–9. IEEE, 2012.
[35] J.D. Hol. Sensor fusion and calibration of inertial sensors, vision, ultra-
wideband and gps. Link¨oping Studies in Science and Technology. Dis-
sertations, (1368), 2011.
[36] Humanware. Trekker Breeze+ handheld talking gps, 2015.
[37] Myung Hwangbo, Jun-Sik Kim, and Takeo Kanade. Inertial-aided klt
feature tracking for a moving camera. In Intelligent Robots and Systems,
2009. IROS 2009. IEEE/RSJ International Conference on, pages 1909–
1916. IEEE, 2009.
[38] G. Jin, X. Lu, and M.S. Park. An indoor localization mechanism using
active rﬁd tag. In Sensor Networks, Ubiquitous, and Trustworthy Com-
puting, 2006. IEEE International Conference on, volume 1, pages 4–pp.
IEEE, 2006.

252
■
References
[39] Kafka. Apache kafka: A high-throughput distributed messaging system,
2014.
[40] E.D. Kaplan and C.J. Hegarty.
Understanding GPS: principles and
applications. Artech House Publishers, 2006.
[41] Hirokazu Kato. Artoolkit: library for vision-based augmented reality.
IEICE, PRMU, pages 79–86, 2002.
[42] S.M. Kay.
Fundamentals of Statistical Signal Processing, Volume 2:
Detection Theory. Prentice Hall PTR, 1998.
[43] Bernd Kitt, Andreas Geiger, and Henning Lategahn.
Visual odome-
try based on stereo image sequences with ransac-based outlier rejection
scheme. In Intelligent Vehicles Symposium (IV), 2010 IEEE, pages 486–
492. IEEE, 2010.
[44] M.B. Kjærgaard, J. Langdal, T. Godsk, and T. Toftkjær. Entracked:
energy-eﬃcient robust position tracking for mobile devices. In Proceed-
ings of the 7th international conference on mobile systems, applications,
and services, pages 221–234. ACM, 2009.
[45] Rob
Koenen.
Overview
of
the
mpeg-4
standard.
ISO/IEC
JTC1/SC29/WG11 N, 1730:11–13, 2002.
[46] Nicholas D. Lane, Emiliano Miluzzo, Hong Lu, Daniel Peebles, Tanzeem
Choudhury, and Andrew T. Campbell. A survey of mobile phone sens-
ing. Communications Magazine, IEEE, 48(9):140–150, 2010.
[47] Tobias Langlotz, Claus Degendorfer, Alessandro Mulloni, Gerhard
Schall, Gerhard Reitmayr, and Dieter Schmalstieg. Robust detection
and tracking of annotations for outdoor augmented reality browsing.
Computers & graphics, 35(4):831–840, 2011.
[48] Patrick Lazik and Anthony Rowe. Indoor pseudo-ranging of mobile de-
vices using ultrasonic chirps. In Proceedings of the 10th ACM Conference
on Embedded Network Sensor Systems, pages 99–112. ACM, 2012.
[49] J.Y. Lee and R.A. Scholtz. Ranging in a dense multipath environment
using an UWB radio link. IEEE Journal on Selected Areas in Commu-
nications, 20(9):1677–1683, 2002.
[50] K. Lin, A. Kansal, D. Lymberopoulos, and F. Zhao. Energy-accuracy
trade-oﬀfor continuous mobile device location. In Proceedings of the 8th
international conference on mobile systems, applications, and services,
pages 285–298. ACM, 2010.
[51] Fuwen Liu and Hartmut Koenig. A survey of video encryption algo-
rithms. Computers & Security, 29(1):3–15, 2010.

References
■
253
[52] Hongbo Liu, Yu Gan, Jie Yang, Simon Sidhom, Yan Wang, Yingying
Chen, and Fan Ye. Push the limit of wiﬁbased localization for smart-
phones. In Proceedings of the 18th annual international conference on
mobile computing and networking, pages 305–316. ACM, 2012.
[53] K. Liu, X. Liu, and X. Li. Acoustic ranging and communication via
microphone channel. In Proc. IEEE Globecom ’12, Anaheim, California,
USA, IEEE, 2012.
[54] K. Liu, H. Yin, and W. Chen. Low complexity tri-level sampling receiver
design for uwb time-of-arrival estimation. In Communications (ICC),
2011 IEEE International Conference on, pages 1–5. IEEE, 2011.
[55] Kaikai Liu, Qiuyuan Huang, Jiecong Wang, Xiaolin Li, and Dapeng Wu.
Improving gps service via social collaboration.
In Mobile Adhoc and
Sensor Systems (MASS), 2013 IEEE 10th International Conference on.
IEEE, 2013.
[56] Kaikai
Liu,
Qiuyuan
Huang,
Jiecong
Wang,
Xiaolin
Li,
and
Dapeng Oliver Wu. Improving gps service via social collaboration. In
Mobile Ad-Hoc and Sensor Systems (MASS), 2013 IEEE 10th Interna-
tional Conference on, pages 393–401. IEEE, 2013.
[57] Kaikai Liu, Xinxin Liu, and Xiaolin Li. Guoguo: Enabling ﬁne-grained
indoor localization via smartphone. In Proceedings of the 11th interna-
tional conference on mobile systems, applications, and services. ACM,
2013.
[58] Kaikai Liu, Xinxin Liu, and Xiaolin Li. Guoguo: Enabling ﬁne-grained
indoor localization via smartphone. In Proceedings of the 11th annual
international conference on mobile systems, applications, and services,
pages 235–248. ACM, 2013.
[59] Kaikai Liu, Xinxin Liu, Lulu Xie, and Xiaolin Li. Towards accurate
acoustic localization on a smartphone. In INFOCOM, 2013 Proceedings
IEEE, pages 495–499. IEEE, 2013.
[60] Hong Lu, Wei Pan, Nicholas D. Lane, Tanzeem Choudhury, and An-
drew T. Campbell. Soundsense: scalable sound sensing for people-centric
applications on mobile phones. In Proceedings of the 7th international
conference on mobile systems, applications, and services, pages 165–178.
ACM, 2009.
[61] Hong Lu, Jun Yang, Zhigang Liu, Nicholas D. Lane, Tanzeem Choud-
hury, and Andrew T. Campbell. The jigsaw continuous sensing engine
for mobile phone applications.
In Proceedings of the 8th ACM Con-
ference on Embedded Networked Sensor Systems, pages 71–84. ACM,
2010.

254
■
References
[62] A. Mandal, C.V. Lopes, T. Givargis, A. Haghighat, R. Jurdak, and
P. Baldi. Beep: 3d indoor positioning using audible sound. In Consumer
Communications and Networking Conference, 2005. CCNC. 2005 Sec-
ond IEEE, pages 348–353. IEEE, 2005.
[63] Justin Gregory Manweiler, Puneet Jain, and Romit Roy Choudhury.
Satellites in our pockets: an object positioning system using smart-
phones. In Proceedings of the 10th international conference on mobile
systems, applications, and services, pages 211–224. ACM, 2012.
[64] G. Mao, B. Fidan, and B. Anderson. Wireless sensor network localiza-
tion techniques. Computer Networks, 51(10):2529–2553, 2007.
[65] Alex T. Mariakakis, Souvik Sen, Jeongkeun Lee, and Kyu-Han Kim.
Sail: Single access point-based indoor localization. In Proceedings of the
12th annual international conference on mobile systems, applications,
and services, pages 315–328. ACM, 2014.
[66] F. Landis Markley and John L. Crassidis. Fundamentals of Spacecraft
Attitude Determination and Control. Springer, 2014.
[67] Lorenz Meier, Petri Tanskanen, Lionel Heng, Gim Hee Lee, Friedrich
Fraundorfer, and Marc Pollefeys. Pixhawk: A micro aerial vehicle de-
sign for autonomous ﬂight using onboard computer vision. Autonomous
Robots, 33(1-2):21–39, 2012.
[68] C. Meng, Z. Ding, and S. Dasgupta. A semideﬁnite programming ap-
proach to source localization in wireless sensor networks. Signal Pro-
cessing Letters, IEEE, 15:253–256, 2008.
[69] Emiliano Miluzzo, Nicholas D. Lane, Shane B. Eisenman, and Andrew T.
Campbell. Cenceme–injecting sensing presence into social networking
applications. In Smart Sensing and Context, pages 1–28. Springer, 2007.
[70] M. Minami, Y. Fukuju, K. Hirasawa, S. Yokoyama, M. Mizumachi,
H. Morikawa, and T. Aoyama. Dolphin: a practical approach for imple-
menting a fully distributed indoor ultrasonic positioning system. Ubi-
Comp 2004: Ubiquitous Computing, pages 347–365, 2004.
[71] Mixare. Mix augmented reality engine, 2011.
[72] Marko Modsching, Ronny Kramer, and Klaus ten Hagen. Field trial
on gps accuracy in a medium size city: The inﬂuence of built-up. In
3rd Workshop on Positioning, Navigation and Communication, pages
209–218, 2006.
[73] Alessandro Mulloni, Daniel Wagner, Istvan Barakonyi, and Dieter
Schmalstieg. Indoor positioning and navigation with camera phones.
Pervasive Computing, IEEE, 8(2):22–31, 2009.

References
■
255
[74] R. Nandakumar, K.K. Chintalapudi, and V.N. Padmanabhan. Centaur:
locating devices in an oﬃce environment. In Proceedings of the 18th
annual international conference on mobile computing and networking,
pages 281–292. ACM, 2012.
[75] Rob Napier and Mugunth Kumar.
iOS 7 Programming Pushing the
Limits. John Wiley & Sons, 2014.
[76] Joseph Newman, David Ingram, and Andy Hopper. Augmented real-
ity in a wide area sentient environment. In Augmented Reality, 2001.
Proceedings. IEEE and ACM International Symposium on, pages 77–86.
IEEE, 2001.
[77] NFB. National Federation of the Blind, 2015.
[78] L.M. Ni, Y. Liu, Y.C. Lau, and A.P. Patil. Landmarc: indoor location
sensing using active rﬁd. Wireless networks, 10(6):701–710, 2004.
[79] A. Nosratinia, T.E. Hunter, and A. Hedayat. Cooperative communica-
tion in wireless networks. Communications Magazine, IEEE, 42(10):74–
80, 2004.
[80] N. Patwari, J.N. Ash, S. Kyperountas, A.O. Hero III, R.L. Moses, and
N.S. Correal. Locating the nodes: cooperative localization in wireless
sensor networks. Signal Processing Magazine, IEEE, 22(4):54–69, 2005.
[81] C. Peng, G. Shen, Y. Zhang, Y. Li, and K. Tan.
Beepbeep: a high
accuracy acoustic ranging system using cots mobile devices. In Proceed-
ings of the 5th international conference on embedded networked sensor
systems, pages 1–14. ACM, 2007.
[82] Chunyi Peng, Guobin Shen, and Yongguang Zhang. Beepbeep: A high-
accuracy acoustic-based system for ranging and localization using cots
devices. ACM Transactions on Embedded Computing Systems (TECS),
11(1):4, 2012.
[83] William Russell Pensyl, Daniel Keith Jernigan, Tran Cong Thien Qui,
Hsin Pei Fang, and Lee Shang Ping. Large area robust hybrid track-
ing with life-size avatar in mixed reality environment: for cultural and
historical installation. In Proceedings of the 7th ACM SIGGRAPH Inter-
national Conference on Virtual-Reality Continuum and Its Applications
in Industry, page 9. ACM, 2008.
[84] Ian R. Petersen and Andrey V. Savkin. Robust Kalman ﬁltering for
signals and systems with large uncertainties. Birkh¨auser Boston, 1999.
[85] N.B. Priyantha, A. Chakraborty, and H. Balakrishnan.
The cricket
location-support system. In Proceedings of the 6th annual international
conference on mobile computing and networking, pages 32–43. ACM,
2000.

256
■
References
[86] Qualcomm. Qualcomm gimbal proximity beacon.
[87] Qualcomm. Vuforia, 2015.
[88] Moo-Ryong Ra, Ramesh Govindan, and Antonio Ortega. P3: Toward
privacy-preserving photo sharing. In NSDI, pages 515–528, 2013.
[89] Anshul Rai, Krishna Kant Chintalapudi, Venkata N. Padmanabhan, and
Rijurekha Sen. Zee: Zero-eﬀort crowdsourcing for indoor localization.
In Proceedings of the 18th annual international conference on mobile
computing and networking, pages 293–304. ACM, 2012.
[90] Pavel Rajmic. Method for real-time signal processing via wavelet trans-
form. Nonlinear Analyses and Algorithms for Speech Processing, pages
368–378, 2005.
[91] K. Ramamohan Rao and Ping Yip. Discrete cosine transform: algo-
rithms, advantages, applications. Academic Press, 2014.
[92] Redis. Redis.io, 2014.
[93] Miguel Ribo, Markus Brandner, and Axel Pinz.
A ﬂexible software
architecture for hybrid tracking. Journal of Robotic Systems, 21(2):53–
62, 2004.
[94] Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb:
an eﬃcient alternative to sift or surf. In Computer Vision (ICCV), 2011
IEEE International Conference on, pages 2564–2571. IEEE, 2011.
[95] A.H. Sayed, A. Tarighat, and N. Khajehnouri. Network-based wireless
location: challenges faced in developing techniques for accurate wireless
location information. Signal Processing Magazine, IEEE, 22(4):24–40,
2005.
[96] Albrecht Schmidt, Bastian Pﬂeging, Florian Alt, Alireza Sahami Shirazi,
and Geraldine Fitzpatrick.
Interacting with 21st-century computers.
IEEE Pervasive Computing, (1):22–31, 2011.
[97] Guobin Shen, Zhuo Chen, Peichao Zhang, Thomas Moscibroda, and
Yongguang Zhang. Walkie-markie: indoor pathway mapping made easy.
In Proceedings of the 10th USENIX conference on Networked Systems
Design and Implementation, pages 85–98. USENIX Association, 2013.
[98] A.M.C. So and Y. Ye. Theory of semideﬁnite programming for sensor
network localization. Mathematical Programming, 109(2):367–384, 2007.
[99] Sonitor. Sonitor system website. http://www.sonitor.com/, 2014.
[100] Kenneth Southall and Walter Wittich. Barriers to vision rehabilitation:
a qualitative approach, 2008.

References
■
257
[101] Storm. Storm - the apache software foundation, 2014.
[102] Guo-Lin Sun and Wei Guo. Bootstrapping m-estimators for reducing
errors due to non-line-of-sight (nlos) propagation. Communications Let-
ters, IEEE, 8(8):509–510, 2004.
[103] S.P. Tarzia, P.A. Dinda, R.P. Dick, and G. Memik.
Indoor localiza-
tion without infrastructure using the acoustic background spectrum. In
Proceedings of the 9th international conference on mobile systems, ap-
plications, and services, pages 155–168. ACM, 2011.
[104] J.D. Taylor. Ultra-wideband radar technology. CRC, 2001.
[105] Matt Tierney, Ian Spiro, Christoph Bregler, and Lakshminarayanan
Subramanian. Cryptagram: Photo privacy for online social media. In
Proceedings of the ﬁrst ACM conference on online social networks, pages
75–88. ACM, 2013.
[106] Mostafa Uddin and Tamer Nadeem. Rf-beep: A light ranging scheme for
smart devices. In Pervasive Computing and Communications (PerCom),
2013 IEEE International Conference on, pages 114–122. IEEE, 2013.
[107] Mostafa Uddin and Tamer Nadeem. Spyloc: a light weight localization
system for smartphones. In Proceedings of the 19th annual international
conference on mobile computing & networking, pages 223–226. ACM,
2013.
[108] J.M. Valin, F. Michaud, J. Rouat, and D. L´etourneau. Robust sound
source localization using a microphone array on a mobile robot.
In
Intelligent Robots and Systems, 2003.(IROS 2003), Proceedings, 2003
IEEE/RSJ International Conference on, volume 2, pages 1228–1233.
IEEE, 2003.
[109] A. Van den Bos.
Parameter estimation for scientists and engineers.
Wiley Online Library, 2007.
[110] DWF Van Krevelen and R Poelman. A survey of augmented reality tech-
nologies, applications and limitations. International Journal of Virtual
Reality, 9(2):1, 2010.
[111] W. Viana, J. Bringel Filho, J. Gensel, M. Villanova-Oliver, and H. Mar-
tin. Photomap: from location and time to context-aware photo annota-
tions. Journal of Location Based Services, 2(3):211–235, 2008.
[112] Daniel Wagner, Gerhard Reitmayr, Alessandro Mulloni, Tom Drum-
mond, and Dieter Schmalstieg. Real-time detection and tracking for aug-
mented reality on mobile phones. Visualization and Computer Graphics,
IEEE Transactions on, 16(3):355–368, 2010.

258
■
References
[113] R. Wand, A. Hopper, V. Falcao, and J. Gibbons. The active bat loca-
tion system. ACM Transactions on Information Systems, pages 91–102,
1992.
[114] He Wang, Souvik Sen, Ahmed Elgohary, Moustafa Farid, Moustafa
Youssef, and Romit Roy Choudhury. No need to war-drive: unsuper-
vised indoor localization. In Proceedings of the 10th international con-
ference on mobile systems, applications, and services, pages 197–210.
ACM, 2012.
[115] Ning Wang and Liuqing Yang. Further results on cooperative localiza-
tion via semideﬁnite programming. In Information Sciences and Systems
(CISS), 2011 45th Annual Conference on, pages 1–6. IEEE, 2011.
[116] Yi Wang, Jialiu Lin, Murali Annavaram, Quinn A. Jacobson, Jason
Hong, Bhaskar Krishnamachari, and Norman Sadeh. A framework of
energy eﬃcient mobile sensing for automatic user state recognition. In
Proceedings of the 7th international conference on mobile systems, ap-
plications, and services, pages 179–192. ACM, 2009.
[117] Z. Wang, S. Zheng, Y. Ye, and S. Boyd.
Further relaxations of
the semideﬁnite programming approach to sensor network localization.
SIAM Journal on Optimization, 19(2):655–673, 2008.
[118] Wayﬁnding. The future of blind navigation, 2015.
[119] Jiangtao Wen, Mike Severa, Wenjun Zeng, Max H. Luttrell, and Weiyin
Jin. A format-compliant conﬁgurable encryption framework for access
control of video.
Circuits and Systems for Video Technology, IEEE
Transactions on, 12(6):545–557, 2002.
[120] Zac White. iphone-ar-toolkit, 2012.
[121] Wikipedia. Gps for the visually impaired, 2015.
[122] Yue Wu, Gelan Yang, Huixia Jin, and Joseph P. Noonan. Image en-
cryption using the two-dimensional logistic chaotic map.
Journal of
Electronic Imaging, 21(1):013014–1, 2012.
[123] Yue Wu, Yicong Zhou, Joseph P. Noonan, and Sos Agaian. Design of
image cipher using latin squares. Information Sciences, 264:317–339,
2014.
[124] Yue Wu, Yicong Zhou, Joseph P. Noonan, Karen Panetta, and Sos Aga-
ian.
Image encryption using the sudoku matrix.
In SPIE Defense,
Security, and Sensing, pages 77080P–77080P. International Society for
Optics and Photonics, 2010.
[125] Roni Yadlin. Attitude determination and bias estimation using kalman
ﬁltering, 2009.

References
■
259
[126] Tingxin Yan, Matt Marzilli, Ryan Holmes, Deepak Ganesan, and Mark
Corner. mcrowd: a platform for mobile crowdsourcing. In Proceedings
of the 7th ACM Conference on Embedded Networked Sensor Systems,
pages 347–348. ACM, 2009.
[127] J. Yang and Y. Chen.
Indoor localization using improved rss-based
lateration methods. In Global Telecommunications Conference, 2009.
GLOBECOM 2009. IEEE, pages 1–6. IEEE, 2009.
[128] J. Yang, S. Sidhom, G. Chandrasekaran, T. Vu, H. Liu, N. Cecan,
Y. Chen, M. Gruteser, and R.P. Martin. Detecting driver phone use
leveraging car speakers. In Proceedings of the 17th annual international
conference on mobile computing and networking, pages 97–108. ACM,
2011.
[129] Zheng Yang, Chenshu Wu, and Yunhao Liu.
Locating in ﬁngerprint
space: wireless indoor localization with little human intervention. In
Proceedings of the 18th annual international conference on mobile com-
puting and networking, pages 269–280. ACM, 2012.
[130] H. Yin, Z. Wang, L. Ke, and J. Wang. Monobit digital receivers: design,
performance, and application to impulse radio. Communications, IEEE
Transactions on, 58(6):1695–1704, 2010.
[131] YourStory. Wearable technology poised to surge: things all CEOs CIOs
must know., 2015.
[132] Moustafa Youssef and Ashok Agrawala. The horus wlan location deter-
mination system. In Proceedings of the 3rd international conference on
mobile systems, applications, and services, pages 205–218. ACM, 2005.
[133] Zengbin Zhang, David Chu, Xiaomeng Chen, and Thomas Moscibroda.
Swordﬁght: enabling a new class of phone-to-phone action games on
commodity phones. In Proceedings of the 10th international conference
on mobile systems, applications, and services, pages 1–14. ACM, 2012.
[134] Pengfei Zhou, Mo Li, and Guobin Shen. Use it free: Instantly knowing
your phone attitude. In ACM MobiCom, volume 2014, 2014.
[135] Pengfei Zhou, Yuanqing Zheng, and Mo Li. How long to wait?: pre-
dicting bus arrival time with mobile phone based participatory sensing.
In Proceedings of the 10th international conference on mobile systems,
applications, and services, pages 379–392. ACM, 2012.
[136] Bin B. Zhu, Chun Yuan, Yidong Wang, and Shipeng Li. Scalable pro-
tection for mpeg-4 ﬁne granularity scalability. Multimedia, IEEE Trans-
actions on, 7(2):222–233, 2005.


Index
A
Acceleration, 110, 140, 143
Accelerometer, 109, 136, 140
Accelerometer error modeling, 138
Accuracy requirement, 2
diﬀerent, 2
for localization, 180–181
Acoustic anchors, 161
Acoustic-based localization, 120
Acoustic Beacon
generation, 27
and multiplexing, 81
synchronization and code
matching, 84–85
Acoustic ranging and communication
acoustic receiver design, 29–32
acoustic symbol demodulation,
37–42
communication and ranging
results, 46–47
introduction to, 24–25
performance evaluation, 43–47
system architecture, 25
TOA estimation, 32–37
transmitter signal design and
modeling, 25–29
Acoustic receiver design, 29–32
signal modeling, 29
symbol synchronization, 30–32
test for symbol synchronization,
29–30
Acoustic receiver signal modeling, 29
Acoustic symbol demodulation,
37–42
audible-band communication
challenges, 37–38
communication demodulation,
38–39
dynamic demodulation with
transit reference, 39–43
Acoustic time-of-arrival
(TOA)-based ranging, 201
Activity, of smartphone, 111
ADA (Americans with Disabilities
Act), 3
Adaptive rate control, for AR view
tracking, 149
AD (Attitude and Displacement),
126
ADC (analog digital converter), 37
AES (advanced encryption
standard), 224, 234
ALE (Absolute location estimation),
152–153
ALE (absolute location estimator),
120
Amber Alert GPS, 7, 172
Anchor network coverage, 59–60
261

262
■
Index
Anchor network design, Guoguo,
design criterion, 77
Anchor network synchronization,
Guoguo design of, 80–82
Anchor node hardware design,
Guoguo, 77–78
Anchor nodes
hardware design for, 18–20
relative distance from, 50–51
smartphones and, 106–107
Anchor number
and locations, impact of, 97–99
requirement, lowering minimum,
106
Angle-based approach, 12
Apple iCloud, 224
Apple’s iBeacon, 128, 168
Apple Siri, 5
Apple Xcode Instruments, 158
AR (augmented reality), 130–131,
244
anchor deployment and
experiment environment,
151
attitude estimation, 136–139,
150–152
comparison with existing apps,
158–160
context awareness and, 246–247
displacement estimation,
139–143
evaluation of, 149–162
indoor application, 131, 150
mapping the POI to the screen,
147
method, 6
on-screen AR view detection
and tracking, 155–157
projecting and tracking view of,
145–149
projecting the view of, 148
proposed application, 132
related applications, 160–162
smartphone localization,
143–145
system model and terminology
deﬁnition, 132–135
tracking the POI, 151
tracking the view of, 148–149
view projecting and tracking,
136
view tracking, 157–158
Architecture
acoustic ranging and
communication system, 25,
26
cloud, 20–21
Coloc system, 202
for enhancing location accuracy
and robustness, 106–107
Guoguo system, 76
hardware design, 18–20
for mobile social networks,
164–165
privacy protection system,
227–228
of proposed localization system,
16–18
ARToolKit, 131, 161
Assisted passive mode, in TOA-based
localization solution, 13, 14
ATAD (adaptive threshold activity
detection), 111, 121, 123,
138, 141, 150–152
AT&T Family Locator, 7, 172
Attitude error reduction, 137–139
Attitude estimation, AR, 131,
135–139, 153, 161
Audible-band communication
challenges, 37–38
Auto check-in, in mobile social
network, 168
AVC (advanced video coding ), 227
Average Update Time, 93–94
B
Beijing, blind sidewalk in, 3
BER (biit-error-rate), 43–47
BLE beacon, 6

Index
■
263
BLE (bluetooth-low-energy), 168,
169, 173
BLE (bluetooth-low-energy)
network, 128
BLE (bluetooth-low-energy) tags,
174
Blind, helping the, 3–5
Blind, rehabilitation technology for,
246
Bluetooth, 12
Body coordinate
in coordinate system, 108
of smart phone, 132–133
BOM price, 16
C
CA (constant acceleration), 112, 142
Camera mapping system, 134
Case study, social collaboration
moving users, 218–219
stationary users, 216–218
CC2533 Zigbee chip, 19
CDF (cumulative distribution
function), 46–47, 92, 95–96,
192, 193, 214, 216
Cellular tower, 104
CFAR detectors, 141
Chaos-based image encryption
methods, 229
Chaos map-based image encryption
method, 229
Chaotic Mapping, 228–231, 235
encrypted and decrypted image
under, 230
generalized low-order, 229–231
pros and cons of, 229
Check-in concept, to locations, 165
Children, lost
crowd sensing and, 174–175
locating, 6–7, 244–245
works related to, 194–196
Chirp signal, 14
Classroom environment
localization error for diﬀerent
measurement sin, 98
localizations in, 95–97
Cloud architecture, 20–21
Cloudbased algorithms with low
cost, 107
Cloud server, 176–177
Cluster detection, 34
Clustering and co-location detection,
in Coloc scheme, 204
CMMotion, 149
Code matching module, 82
Coherent Navigation, 6
Coloc (cooperative location
optimization) scheme, 199,
201, 202
improving performance of,
214–215
steps of, 203–205
Coloc software middleware in
smartphone, 202
Communication
between group members, 165
and ranging results, 46–47
Communication demodulation, 38–39
Compression
encryption after, 240
encryption before, 240
joint, encryption and, 240
Compression independent solutions,
226–227
Computational eﬃciency, in private
sharing in the clouds,
234–235
Computer vision techniques, 161
Computer vision techniques,
augmented reality, 6
Connecting friends and messaging, in
mobile social network, 166
Constraint via activity results,
applying, 111
Contacts management, in mobile
social networking, 155
Context-awareness information
accessing, 5–6
Conventional cooperative
localization, 199

264
■
Index
Cooperative localization, 199, 201
Cooperative location optimization,
211–214
Correlation preserving, noise
robustness and, 237–239
Costs, 2
CPU activity proﬁle, energy and,
158–160
Cricket localization system, 24–25
CRLB (Cramer-Rao Low Bound),
13, 58–59, 64
Crowd clustering and co-location
detection, 207–208
Crowd cooperative setting and
protocol, 203–205
Crowd localization, 179–182
Crowd sensing SDP, problem
formulation for, 185
CV (constant velocity), 112, 142
CVX package, 118
Cyber-physical social networking,
247
D
DC (delay constraint), 118–119
DeafBeep, 128
Dense anchor nodes, 104
Design
Guoguo system, 74–75
of mobile phone localization
system via opportunistic
sensing, 106–107
of private sharing in clouds,
227–228
workﬂow, in smartphone
localization, 82
Detection rates, balancing, 178–179
Direction cosine matrix (DCM), 108
Displacement
calculating, 110
error, mitigating, 141–143
horizontal, 156
motion estimation and, 107–109
relative, 110
in vertical, 155
Displacement estimation. see also
Displacement estimation
error
augmented reality, 139–145,
150–152, 161
via vision, 152
Displacement estimation error,
111–112
applying constraint via activity
results, 111
Gaussian-derivative
decomposition, 112
Displacement Matters, 8, 131
Distance estimation, in Coloc
scheme, 204
Distance update, in smartphone
localization, 85–86
DN (denoising), 121, 123
DN (denoising) process, 110, 112,
121, 122, 140
Drift matrics and experiments, 122
Drift rate, 150
Drift reduction, 122, 150–151
Drift speed, 150
Dynamic demodulation with transit
reference, 39–43
E
ECEF (earth-centered earth-ﬁxed),
114, 180
EchoBeep, 128
EKF (extended Kalman ﬁlter), 161
EKF (extended Kalman ﬁlter)
model, 137
Encryption
after compression, 240
with clouds and mobile clients,
224–225
before compression, 240
methods, 229
Energy consumption, indoor AR
App (InARE), 158
Energy-eﬃcient sensing strategy, 195
ENU (east-north-up), 108

Index
■
265
Error model of Gyros measurement,
109
Error pruning techniques, in Guoguo
system, 87–89
ESD (energy spectrum density), 27,
33–34
Euler angles, 108, 134, 153, 154, 155
Euler rates, 108
Euler value, 109
Executiion time, in private sharing in
the clouds, 234–235
F
Facebook, 224
False-alarm, balancing, 178–179
False-detection evaluation, 122
Family Group, mobile crowd sensing
via, 177
FD, 45
FIM (Fisher information matrix),
206–207
FindingNemo protocol, 177, 179
“FindingNemo” system, 175, 176,
191
Fingerprinting-based approaches, 12
Fingerprinting-based solutions, 12
FIR (ﬁnite impulse response) ﬁlter,
28
Fisher information matrix, 58
Flickr, 224, 226
Foot-level resolution, 8
Format compliant, in private sharing
in the clouds, 226–227
FourSquare, 1, 165, 198
Fragment Shaders, 234
Fragment Shaders, in OpenGL, 227
Friends, sensing and tracking,
168–169
FSK demodulation method, 37,
39–40
G
Gaussian random variable, 31
GCD (iOS Grand Central Dispatch),
20, 100
G-cut algorithm, 203
GDD (Gaussian derivative
decomposition), 112, 121,
122, 123
ATAD vs., 150–152
based ﬁtting, 143
motion estimation result via,
143
GDOP (geometric dilution of
precision), 59, 97
Geo-AR application, 160
Geo-coordinate, in crowd sensing
and ranging condition, 205
Geographic-scale AR, 131
Geo-tagging photos, 200
Gimbal lock, 134
Golfspace GPS Rangeﬁnder,
160–161
Google+, 224
Google Glass, 5
Google Latitude, 165
Google Maps, 1
Google Now, 5
Google Talk, 165
Gowalla, 165, 198
GPS
locator, 7
in outdoor environment,
201–202
utilization by blind, 4, 8
GPS-enabled smartphones, kids and,
174
Group auto check-in, in mobile social
network, 168
Group creation, in Coloc scheme, 204
GRS80 (Geodetic Reference System
1980), 205
Guoguo system, 14–15, 17–18
anchor network design, 76–82
error pruning techniques, 87–89
evaluation, 100
vs. localization techniques,
14–15
overview and challenges of, 244
performance evaluation, 90–100

266
■
Index
smartphone localization, 82–86
system design, 74–76
Gyroscopes, 136
Gyros error modeling, 137–138
H
Hadarmard Matrix, 79
Hardware acceleration, in private
sharing in clouds system,
227
Hardware design for sensors, anchor
nodes and wearables, 18–20
High-accuracy attitude requirement,
8, 131
High-accuracy location requirement,
131
High density pseudocode sequence,
Guoguo design of, 79–80
Homogeneous relation, augmented
reality review and, 146
Hybrid cyber-physical social group,
164, 165
Hypothesis test for symbol
synchronization, 29–30
I
iBeacon (Apple), 6
Image matching, POI, 153–154
iMessage, 165, 224
InAR (indoor AR App), energy
consumption of, 158–160
Indoor AR applications, 131
Indoor localization, 161
Indoor localization system. see
Guoguo
Indoor location-based services
(ILBS), 11
Indoor location market, 2–3, 104
Indoor location solutions, 2–3, 8
Indoor positioning system (IPS), 72
Inertial navigation, Principle of,
107–109
Inertial sensor (INS), 135
Initialization, in Coloc scheme, 204
Innovation, mobile social network,
165
INS sensor, 120
Interacting multiple model (IMM),
138–139
iPhone-AR-Toolkit, 158, 159
J
Java server, Redis server and, 121
Joint estimation of the position and
unknown bias, 51–55
JPEG, 225, 234
Jumb-back and search-forward
(JBSF), 35
K
Kalman ﬁlter, 120, 144–145
Kalman fusion experiment, 126
Keeper 4.0, 176
KLT (Kanade-Lucas-Tomasi), 149
K-means, 203
K-means algorithm, 207
L
Latin Square, 232
Layar, 158–160
LED (light-emitting diode), 162
LE (localization error), 93, 193
Lioyd algorithm, 207
LLR (log-likelihood ratio), 39
Localization, 113–114. see also
Localization accuracy;
Smartphone localization
acoustic-based, 120
in classroom environments,
95–97
conventional cooperative, 199
cooperative, 199
crowd, 179–182
experiment setup for, 65–66
indoor, 161
in oﬃce environments, of
Guoguo system, 91–95
proximity detection without, 128

Index
■
267
in quiet environment, 92–93
track before, 87–89
via anchor nodes, 127
without anchor nodes, 126–127
Localization accuracy
under background sound, 96–97
under quiet environment, 95–96
requirement for, 180–181
under SI, 93
via one-hop, 190
via one-hope, experimental, 194
Localization algorithms
mobile phone localization via
semideﬁnite programming,
55–58
performance bound and anchor
network coverage, 58–60
position reﬁnement, 60–68
trialteration via relative
distance, 50–55
Localization measurement model,
55–56
Localization metrics, 93, 96
Localization module, 82
Localization results, 125–126
Localization via hybrid approaches,
128
Location. see also Location accuracy;
Location optimization;
Location sensing
applications, 2
journaling, 200, 215–216
for mobile Internet, 2–3
tracking, in error pruning, 89
Location accuracy
anchors and, 123
initial location, 114
location optimization, 116–117
measurements, 114–116
via constraints, improving,
114–117
Location-aware advertising, new
features of, 104
Location-based services (LBS), 104,
131, 198
Location error, in indoor and
outdoor environment, 124
Location estimation
absolute, AR, 152–153
process, 118
in smartphone localization, 86
via single anchor, 115
Location estimation with fewer
anchors
background and basic
procedures, 112–113
location accuracy via
constraints, 114–117
Location fusion, 125–126
via activity detection, 144–145
Location optimization
with fewer anchors, 116–117
via SDP (semideﬁnite
programming), 185–187
Location sensing
augmented reality and, 6
techniques, 12–13
Location tag, mobile social network,
164–165
Location update rate, 16
Los Angeles, sidewalks of, 3–4
LSB (least signiﬁcant bit), 231
M
Magnetometer, 136
MA (moving average) method, 214,
217
MAP (maximum a posteriori), 52, 55
Marketing, mobile social network,
165
Market-scale AR, 131
Mathematical modeling, in crowd
sensing and ranging
condition, 206–207
Maximum operation distance, of
Guoguo system, 90–91
mCrowd, 195
Media data sharing, 225–226
Media sharing process, 233–234
MEMS INS sensors, 161

268
■
Index
Messaging apps, 165
Metric ranging rate, 122–123
Microphone sensor, 73, 220
Min-max criterion, 56–57, 118
MIP soft BlindSquare, 4
Miss Rates, 93
Mixare, 158, 159
Mobile apps, 1
Mobile context components, 72–73
Mobile crowd sensing
accuracy improvement via SDP,
182–187
design consideration, 174–175
evaluation of, 188–193
introduction to, 172–173
system design, 175–177
via multi-hop assistance,
177–182
Mobile message app, 165
Mobile phone, standard microphone
in, 78
Mobile SmartLife. see also Mobile
SmartLife applications
location, 2–3
overview of, 1–2
research challenges, 7–8
Mobile SmartLife applications, 3–7
context-awareness information
accessing, 5–6
for helping the blind, 3–5
locating lost children, 6–7
Mobile social network
application description, 164–165
group auto check-in, 168
innovation and or marketing,
165
key design features, 165–168
Mobile systems
architecture of proposed
localization system, 16–18
cloud architecture, 20–21
hardware design for sensors,
anchor nodes and
wearables, 18–20
locations sensing techniques,
12–13
overview of, 11–12
TOA-based smartphone
localization approaches,
13–16
Models and protocols, mobile crowd
sensing, 177–178
Motion estimation result
via ATAD, 142
via conventional method, 110,
140
via GDD, 143
Moving users (case study), 218–219
MPEG (moving picture experts
group), 240
MSE (mean square error), 209–210
MT (mobile target), 25
Multi-channel block substitution,
232–233, 236–237
Multi-hop assistance, mobile crowd
sensing via, 177–182
Multi-hops, need for, 175
N
Navigation, local, new features of,
104
Navigation coordinate, 133, 140,
179–180
Nintendo Wii Remotes, 162
NLOS (Non-line-of-sight), 206
bias eﬀects, 87
and error mitigation, 60–61
NMSE (normalized mean square
error), 43– 45, 46
No-assisted passive mode, in
TOA-based localization
solution, 13, 14
Noise robustness, correlation
preserving and, 237–239
Non-chaotic mapping, 232
Nonconvex optimization, 118
Normalized block substitution,
232–233

Index
■
269
Normalized cuts algorithm, 203, 208
Normal Mode, mobile crowd sensing
via, 177–178
NoSQL server, 20
“Now on Tap,” in Google I/O 2015, 5
NP (Neyman-Pearson) criterion, 31,
111, 141
O
Oﬃce environment, localization in,
91–95
One-way active mode, in TOA-based
localization solution, 13, 14
OpenCV, 149
OpenGL, 149
OpenGL Shader, 227, 234
OpenStreetMap, 4
Opportunistic anchor access, 104–128
displacement and motion
estimation, 107–112
displacement estimation,
109–110, 121–122
experiment, 121–125
location estimation with fewer
anchors, 112–116, 123–125
location fusion, 125–126
mitigating displacement
estimation error, 111–112,
122–123
system overview, 105–107, 121
trilateration via semideﬁnite
programming, 117–120, 125
Opportunistic connection, need for,
175
Optical ﬂow tracking, for AR, 149
OTH-DD, 44–45
OTH-FD, 44–45
Outdoor environment, GPS in,
201–202
Outdoor localization techniques, 2, 4,
8
Outdoor location market, 104
Overall localization accuracy, 94–95,
97
P
PDA, 13
Peer-to-peer ranging, 199
People-centric mobile computing
applications, 198
Performance bound and anchor
network coverage, 58–60
anchor network coverage, 59–60
Cramer-Rao Low Bound
(CRLB), 58–59
Fisher information matrix, 58
Performance evaluation
acoustic ranging and
communication, 43–47
of Guoguo system, 89–100
PocketFinder, 7
POI (Points of interest), 4
detection and relative pose
estimation, 145–146
detection via image feature, 145
image matching and relative
pose estimation, 153–154
information, 4
location-sensing-based solutions
and, 6
mapping to the screen, 147,
154–155
of smartphone, 133
Polar optimization, 199
Pose estimation
AR, 153–154
initial relative, 145–146
Position and unknown bias, joint
estimation of, 51–55
Position optimization, in Coloc
scheme, 205
Position reﬁnement
coverage constraint, 62
NLOS and error mitigation,
60–61
numerical results, 63–65
steepest descent approach, 61–62
Position updating, in Coloc scheme,
205

270
■
Index
Prevention Mode, mobile crowd
sensing via, 189
Principle of inertial navigation,
107–109
coordinate system, 107–108
coordinate transformation, 109
rotation estimation, 108–109
Privacy, threats to, 226
Privacy-preserving algorithms,
226–227
Privacy-preserving scheme, in private
sharing in the clouds
system, 228
Privacy protection algorithm design,
228–233
Privacy sharing in the clouds
correlation preserving and noise
robustness, 237–239
evaluation of, 233–237
related work, 239–240
Private sharing in the clouds
conclusion, 240–241
correlation preserving and noise
robustness, 237–239
introduction to, 224–225
privacy protection algorithm
design, 228–233
related work, 239–240
security analysis, 233, 235–237
system design, 227–228
system evaluation, 233–235
system model, 225–227
Proximity social networking, new
features of, 104
PwC’s Consumer Intelligence Series,
6
Q
Qualcomm’s Gimbal proximity
beacons, 128
Quaternions, 108
R
Radio-ﬁngerprinting-based
approaches, 161
Radio RSS, 12
Radio signal strength (RSS), 12
Random noise-based approach, 229
Range via activity detector, 144–145
Ranging, acoustic signal for, 87
Ranging accuracy, 122, 124
Ranging error rate, 122–123
Ranging estimation, 122–123
Ranging process, 113
Ranging results, 125–126
RANSAC (RANdom SAmple
Consensus), 143
Reaching more participators, via
multi-hop assistance,
181–182
Realtime ﬁltering and wavelet
denoising, 28–29
Redis server, 121
Relative Distance Module, 82
Relative ranging
necessary conditions for,
209–211
on smartphone, 201, 202, 203
Retail recommendation, new features
of, 104
RFID network, 128
RFID (radio frequency
identiﬁcation), 5
Right Detection Probability,
maximizing, 35–37
RMSE (root mean squared error),
63–64, 92
Rotation matrix, 134
RSS (received signal strength ), 178
S
Satelitte-based localization, 104
SDP-PR-LS, 64, 67
SDP-PR-SD, 63–64, 67
SDP (semidenﬁnite programming),
245
conventional, 193
crowd sensing accuracy
improvement via, 182–188
delay-constraint robust, 118–119

Index
■
271
localization measurement model,
55–56
location optimization via,
185–187
min-max criterion, 56–57
proposed approach, 193
semideﬁnite programming,
57–58
trilateration via, 118–119
SD (steepest descent) approach,
61–62
Security analysis, in privacy
protection algorithm design,
233, 235–237
SeDuMi, 118
Self-localization, crowd sensing vs.,
184
Sensor fusion approach, 162
Sensors, hardware design for, 18–20
Server processing, 17
Server processing for position
optimization, 203
ShopKick, 165
Signal and interface, 27
Signal detection, 113
Signal detection and demodulation
module, 82
Signal level resistance, in error
pruning, 87
Signal modeling, 25–26
Simulation, mobile crowd sensing
and, 188
Single anchor, location estimation
via, 115
Skype, 165
Smartphone
activity of, 111
for ﬁnding locations, 198
geo-tagging features in, 198
Smartphone attitude, 133
Smartphone-based indoor
localization, 12
Smartphone localization
augmented reality, 143–145
Guoguo, 82–86
Smartphone processing, 16–17
Smart Watches, 5
Snapchat, 224
SnapShop Showroom, 161
SNR (signal-to-noise ratio), 43–45,
78
Social-aided cooperative localization,
206
Social-aided crowd localization
scheme, 200
Social collaboration
case studies, 216–219
cooperative location
optimization, 211–214
crowd sensing and ranging
condition, 203–211
experimental validation, 215–219
introduction to, 198200
numerical results, 214–215
related work, 219–221
relative ranging, 201, 202, 203
system design and overview,
201–203
use cases, 200
Social group management, in mobile
social network, 166–167
Social networking
designed mobile, 217
wearable and cyber-physical, 247
SOS Mode, mobile crowd sensing
via, 178–179
Sound pressure level measurement,
of Guoguo system, 90
Spectrum matching, 32–34
Speed, in terms of latency or refresh
rate, 2
SSD (Sparse steepest descent)
optimization, 199, 211–213,
215
“Start-moving-stop” pattern, 142,
143
Stationary localization, for
evaluating Guoguo system,
99–199

272
■
Index
Stationary users (case study),
216–218
Symbol detection and demodulation,
82–83
Symbol-interleaved beacon, 73
Symbol-interleaved Beacon structure,
Guoguo design of, 81–82
Symbol synchronization (SS), 29–30
System architecture, acoustic ranging
and communication, 25
System implementation, crowd
sensing, 189–191
T
TDMA (Time division multiple
access), 81
Time, for mobile Internet, 2
Time division multiplexing (TDM),
50
TI MSP 430 microcontroller, 19
TOA-based smartphone localization
approaches, 13–16
TOA estimation, 32–37
based on communication
channel, 24–25
cluster detection, 34
maximizing the Right Detection
Probability, 35–37
module, 82
procedure, 35
in smartphone localization,
83–84
spectrum matching, 32–34
TOA path, 30
TOA ranging results, 116
TOA (Time-of-arrival), 12
Toddler Tag Child Locator Keeper
4.0 Chipolo, 7
ToGathor App, 164, 165
contact management, 166
sensing and tracking nearby
friends, 168–169
social group management in,
166–167
user management, 166
Trace and attitude estimation,
moving, 136
Track before localization, in error
pruning, 87–89
Tracking AR view, 148–149
Transit reference (TR), 40
Translation matrix, 135
Transmitter signal design and
modeling, 25–29
acoustic beacon generation, 27
realtime ﬁltering and wavelet
denoising, 28–29
signal and interface, 27
signal modeling, 25–26
Transmitter waveform design and
modulation, in smartphone
localization, 78–79
Trekkker Breeze, 4
Trilateration via semideﬁnite
programming, 107
delay-constraint robust
semideﬁnite programming,
118–119
min-max criterion, 118
Trilatertion, crowd sensing vs., 184
Trilatration via relative distance,
50–55
exprimental evaluation, 65–69
joint estimation of the position
and unknown bias, 51–55
relative distance from anchor
nodes, 50–51
2-D navigation coordinate, 122
2-PAM modulation, 14, 201
Two-way active mode, in TOA-based
localization solution, 13–14
U
UAV (Unmanned aerial vehicle), 162
Ultrasound for localization, systems
using, 13
Unknown bias and position, joint
estimation of, 51–55
Unnormalized spectral clustering,
203

Index
■
273
“Urban Canyon” eﬀect, 4
User management feature, in mobile
social network, 166
User Participatory Model, 179–189
UWB (ultra-wideband), 13, 161
UWB (ultra-wideband) technique, 24
V
vDSP, 20
Velocity, 140, 143
Velocity, of smartphone, 110
Vertical markets, needs for, 2
Virtual anchor assistance, for
improving crowd sensing
accuracy, 187
Vision angle, 155
Vision tracking, augmented reality,
149
Visually impaired, helping, 3–5
VO (visual odometry), 161
Vuforia, 159–160
W
Walsh-Hadamard codes, 79
Waveform, time-domain, 28
Wavelet approaches, 28
Wearable localization, 171–196
Wearables, hardware design for,
18–20
Wearable social networking, 247
Wearble tag, 176
WeChat, 165
Weighting center-based polar
optimization, 213–214
WGS 84 datum, 180
WhatsApp, 165, 224
Whitening and probabilistic
transformation, 231,
235–236
Whitening process, 229
Wiﬁ, 12
WiFi access point, 104
Wi-Fi-based localization techniques,
4
WiFiSLAM, 6
Wikitude, 160
Wireless anchor network, 16
X
x-axis, in coordinate system, 107
XOR operation, 231
XOR process, 229
Y
y-axis, in coordinate system, 107–108
YouTube, 224
Z
ZigBee, 12, 13, 14


