Alessandro Chiuso, Augusto Ferrante,
Stefano Pinzoni (Eds.)
Modeling, Estimation and
Control
Festschrift in Honor of Giorgio Picci on the
Occasion of his Sixty-Fifth Birthday
ABC

Series Advisory Board
F. Allgöwer, P. Fleming, P. Kokotovic,
A.B. Kurzhanski, H. Kwakernaak,
A. Rantzer, J.N. Tsitsiklis
Editors
Prof. Alessandro Chiuso
Dipartimento di Tecnica e Gestione dei
Sistemi Industriali
Università di Padova
sede di Vicenza
stradella San Nicola, 3
I-36100 Vicenza, Italy
E-mail: chiuso@dei.unipd.it
Prof. Stefano Pinzoni
Dipartimento di Ingegneria
dell’Informazione
Università di Padova
via Gradenigo, 6/B
I-35131 Padova, Italy
E-mail: pinzoni@dei.unipd.it
Prof. Augusto Ferrante
Dipartimento di Ingegneria
dell’Informazione
Università di Padova
via Gradenigo, 6/B
I-35131 Padova, Italy
E-mail: augusto@dei.unipd.it
Library of Congress Control Number: 2007930050
ISSN print edition: 0170-8643
ISSN electronic edition: 1610-7411
ISBN-10 3-540-73569-0 Springer Berlin Heidelberg New York
ISBN-13 978-3-540-73569-4 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microﬁlm or in any other way, and storage in data banks. Duplication of this publication or
parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in
its current version, and permission for use must always be obtained from Springer. Violations are liable for
prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springer.com
c⃝Springer-Verlag Berlin Heidelberg 2007
Printed in Germany
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply,
even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and
regulations and therefore free for general use.
Typesetting: By the authors and SPS using a Springer LATEX macro package
Printed on acid-free paper
SPIN: 11777557
89/SPS
5 4 3 2 1 0

To Giorgio Picci
on the occasion of his sixty-ﬁfth birthday

Preface
This Festschrift is intended as a homage to our esteemed colleague, friend and maestro
Giorgio Picci on the occasion of his sixty-ﬁfth birthday.
We have known Giorgio since our undergraduate studies at the University of Padova,
where we ﬁrst experienced his fascinating teaching in the class of System Identiﬁcation.
While progressing through the PhD program, then continuing to collaborate with him
and eventually becoming colleagues, we have had many opportunities to appreciate the
value of Giorgio as a professor and a scientist, and chieﬂy as a person. We learned
a lot from him and we feel indebted for his scientiﬁc guidance, his constant support,
encouragement and enthusiasm. For these reasons we are proud to dedicate this book
to Giorgio.
The articles in the volume will be presented by prominent researchers at the “In-
ternational Conference on Modeling, Estimation and Control: A Symposium in Honor
of Giorgio Picci on the Occasion of his Sixty-Fifth Birthday”, to be held in Venice on
October 4-5, 2007.
The material covers a broad range of topics in mathematical systems theory, estima-
tion, identiﬁcation and control, reﬂecting the wide network of scientiﬁc relationships
established during the last thirty years between the authors and Giorgio. Critical dis-
cussion of fundamental concepts, close collaboration on speciﬁc topics, joint research
programs in this group of talented people have nourished the development of the ﬁeld,
where Giorgio has contributed to establishing several cornerstones.
We are happy and honored that these distinguished contributors have joined us in
paying tribute to Giorgio as a token of esteem and friendship. We heartily thank them,
with a special acknowledgment to Chris Byrnes, Anders Lindquist and Sanjoy Mitter
for writing Giorgio’s Laudatio.
With these feelings of gratitude and recognition, we all together wish the best to
Giorgio for a happy birthday and many more to come.
Padova, May 2007
Alessandro Chiuso
Augusto Ferrante
Stefano Pinzoni
The book editors would like to gratefully thank the Department of Information Engineering, University of Padova for gener-
ously sponsoring the Conference and Springer-Verlag for publishing this book as a volume in the prestigious “Lecture Notes
in Control and Information Sciences” Series.

Laudatio
Giorgio Picci has made profound contributions to several important topics in systems
and control, notably stochastic realization theory, statistical theory of identiﬁcation,
image processing and dynamic vision.
The seminal paper [1] by Giorgio on splitting subspaces became the impetus for a
whole ﬁeld of stochastic systems theory. One of us (AL) had the privilege of long and
fruitful collaboration with Giorgio in this direction, leading to contributions to stochas-
tic realization theory [2], geometric theory of linear stochastic systems [3,4,5] and the
geometric structure of matrix Riccati inequalities [6]. This research turned out to be
timely and important as the system identiﬁcation community turned their interest in
the 90’s toward a new class of identiﬁcation procedures known as subspace methods,
which turned out to be based on the same principles as those in the geometric theory of
Markovian representations [7,8].
Giorgio also applied the geometric theory of Markovian representations to statis-
tical physics [9] and, together with Pinzoni, to factor analysis models [10, 11]. In a
completely different direction, he has also studied different aspects of stochastic aggre-
gation [12, 13] as well as positive Markov chains [14, 15]. In [16] he investigated the
connections between the theory of sufﬁcient statistics and the identiﬁability problem.
Among some of Giorgio’s more recent contributions to subspace identiﬁcation, we
would like to mention [17], the follow-up papers [18,19] co-authored with Katayama,
and [20], which introduced oblique splitting subspaces as a tool for modeling systems
with inputs. This is a key idea for understanding the geometry of subspace identiﬁca-
tion with inputs. The paper [21] together with Chiuso provides an in-depth analysis
of the plethora of various subspace identiﬁcation methods, showing that they are es-
sentially all equivalent. This analysis, based on fundamental principles of stochastic
realization theory, also provides simple expressions for the asymptotic variance of sub-
space identiﬁcation estimates [22] and tools for understanding closed-loop subspace
identiﬁcation [23, 24]. These problems had remained open for a long time. Giorgio
has also made important contributions to smoothing together with Ferrante [25] and the
structure of stochastic systems together with Ferrante and Pinzoni [26].
In a quite different direction, Giorgio made a signiﬁcant contribution to Dynamic
Vision, especially through his students. The ﬁrst problem is in “Structure from Mo-
tion,” that is the reconstruction of the three-dimensional motion of the camera as well
as the three-dimensional structure of the scene. Although there were prior attempts to
use Kalman ﬁlters and their extended versions for this problem, Giorgio was the driv-
ing force behind its proper deployment, which led to a series of papers starting from

X
Laudatio
the CDC 1994 paper “motion estimation via dynamic vision” [27]. The problem can be
cast as a ﬁltering problem where the state space is the product of a quotient space (the
shape space of points in Euclidean space, in the sense of Kendall) and the Lie group of
rigid motions. It is, however, a non-standard ﬁltering problem, because the model is not
observable (there is an ambiguous Gauge transformation), the state-space is variable
(points can appear and disappear due to occlusions), and non-linear. Giorgio was the
ﬁrst to point out that there were observability issues to be studied, and that a proper
model had to take into account the geometry of the state-space.
The second problem is in the study of “Dynamic Textures” [28] that are essentially
stochastic realizations of video signals. The idea is to think of a video sequence as a re-
alization of a linear system driven by white noise. The model colors the noise, and with
a simple identiﬁcation algorithm one can identify some 20-dimensional models that can
be used to (a) simulate novel sequences, for instance of moving foliage, smoke, steam,
fog etc. by just feeding Gaussian white noise to a linear system, and (b) to recognize
these processes from video, for instance to detect smoke, ﬁre etc. using distances be-
tween observability spaces. These ideas are straightforward, and in principle one would
not need a background in identiﬁcation theory or stochastic realization to have them.
However, it is only because of Giorgio’s work that his former students were able to
apply these ideas to a different context. Although Giorgio was not an author in the ﬁrst
paper that appeared at ICCV 2001, his inﬂuence is direct and immediately visible in
that paper, as well as in the many papers that followed from research groups in the US,
Europe and Asia.
In image processing, as in the stochastic realization of signals with only ﬁnitely
many known covariance lags, one needs to deal with ﬁnite sequences of data. In this
case, however, the data are pixels and there are nontrivial boundary effects. As Giorgio
has recently observed, this produces a problem far more complex than the traditional
stochastic modeling problem, but one which Giorgio is currently researching using his
wonderful ability to develop novel insights into elegant formalisms.
The University of Padova has today one of the strongest groups in Systems and
Control in the world. There is no doubt whatsoever that this is primarily due to the
scientiﬁc leadership of Giorgio Picci, a great researcher and teacher.
We congratulate Giorgio Picci – a great friend and a great scholar – on the occasion
of his 65th birthday.
St. Louis, Stockholm, and Cambridge, May 2007
Christopher I. Byrnes
Anders Lindquist
Sanjoy K. Mitter

Laudatio
XI
References
1. Picci G. (1976), Stochastic realization of Gaussian processes. Proc. IEEE 64: 112–122.
2. Lindquist A., Picci G. (1979), On the stochastic realization problem. SIAM J. Control Optim.
17: 365–389.
3. Lindquist A., Picci G. (1985), Realization theory for multivariate stationary Gaussian pro-
cesses. SIAM J. Control Optim. 23: 809–857.
4. Lindquist A., Picci G. (1985), Forward and backward semimartingale models for Gaussian
processes with stationary increments. Stochastics 15: 1–50.
5. Lindquist A., Picci G. (1991), A geometric approach to modelling and estimation of linear
stochastic systems. J. Math. Systems Estim. Control 1: 241–333.
6. Lindquist A., Michaletzky Gy., Picci G. (1995), Zeros of spectral factors, the geometry of
splitting subspaces and the algebraic Riccati inequality. SIAM J. Control Optim. 33: 365–
401.
7. Lindquist A., Picci G. (1996), Canonical correlation analysis, approximate covariance exten-
sion, and identiﬁcation of stationary time series. Automatica 32: 709–733.
8. Lindquist A., Picci G. (1996), Geometric methods for state space identiﬁcation. In: S. Bit-
tanti and G. Picci (eds), Identiﬁcation, Adaptation, Learning: The Science of Learning Mod-
els from Data, Nato ASI Series (Series F, Vol. 153): 1–69, Springer.
9. Picci G. (1986), Application of stochastic realization theory to a fundamental problem of
statistical physics. In: C.I. Byrnes and A. Lindquist (eds), Modelling, Identiﬁcation and
Robust Control: 211–258, North-Holland, Amsterdam.
10. Picci G., Pinzoni S. (1986), Factor analysis models for stationary stochastic processes. Anal-
ysis and optimization of systems, Lecture Notes in Control and Inform. Sci., 83: 411–424,
Springer, Berlin.
11. Picci G. (1989), Parametrization of factor analysis models. J. Econometrics 41: 17–38.
12. Picci G. (1988), Stochastic aggregation. Linear Circuits, Systems and Signal Processing:
Theory and Application: 493–501, North-Holland, Amsterdam.
13. Picci G., Taylor T.J. (1990), Stochastic aggregation of linear Hamiltonian systems with mi-
crocanonical distribution. Realization and modelling in system theory (Amsterdam, 1989),
Progr. Systems Control Theory 3: 513–520, Birkh¨auser, Boston.
14. Picci G., van Schuppen J. H. (1984), On the weak ﬁnite stochastic realization problem. Fil-
tering and control of random processes (Paris, 1983), Lecture Notes in Control and Inform.
Sci., 61: 237–242, Springer, Berlin.
15. Picci G., van den Hof J. M., van Schuppen J. H. (1998), Primes in several classes of the
positive matrices. Linear Algebra Appl. 277: 149–185.
16. Picci G. (1977), Some connections between the theory of sufﬁcient statistics and the identi-
ﬁability problem. SIAM J. Appl. Math. 33: 383–398.
17. Picci G. (1997), Oblique splitting subspaces and stochastic realization with inputs. In: U.
Helmke, D. Pr¨atzel-Wolters and E. Zerz (eds), Operators, Systems and Linear Algebra: 157–
174, Teubner, Stuttgart.
18. Picci G., Katayama T. (1996), Stochastic realization with exogenous inputs and subspace
identiﬁcation methods. Signal Processing 52: 145–160.
19. Katayama T., Picci G. (1999), Realization of stochastic systems with exogenous inputs and
subspace identiﬁcation methods. Automatica 35: 1635–1652.
20. Picci G. (1997) Stochastic realization and system identiﬁcation. In: T. Katayama and S.
Sugimoto (eds), Statistical Methods in Control and Signal Processing: 1–63, M. Dekker.
21. Chiuso A., Picci G. (2004), On the ill-conditioning of subspace identiﬁcation with inputs.
Automatica 40: 575–589.

XII
Laudatio
22. Chiuso A., Picci G. (2004), Asymptotic variance of subspace estimates. Journal of Econo-
metrics 118: 257–291.
23. Chiuso A., Picci G. (2005), Prediction error vs. subspace methods in closed loop identiﬁca-
tion. Proc. of the 16th IFAC World Congress, Prague.
24. Chiuso A., Picci G. (2005), Consistency analysis of some closed-loop subspace identiﬁcation
methods. Automatica 41: 377-391.
25. Ferrante A., Picci G. (2000), Minimal realization and dynamic properties of optimal
smoothers. IEEE Trans. Automatic Control 45: 2028–2046.
26. Ferrante A., Picci G., Pinzoni S. (2002), Silverman algorithm and the structure of discrete-
time stochastic systems. Linear Algebra Appl. 351-352: 219–242.
27. Soatto S., Perona P., Frezza R. and Picci G. (1994), Motion estimation via dynamic vision.
Proc. CDC94, Orlando, pp. 3253–3258.
28. Soatto S., Doretto G. and Wu Y. (2001), Dynamic textures. Proc. of the Intl. Conf. on Com-
puter Vision, 2001, pp. 439–446.

Contents
Coefﬁcients of Variations in Analysis of Macro-policy Effects:
Masanao Aoki . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
2
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
3
Asymptotic Properties of the Number of Sectors . . . . . . . . . . . . . . . . . . . . . . . .
2
4
The Coefﬁcients of Variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
4.1
The Number of Sectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
4.2
The Number of Sectors of Speciﬁed Size . . . . . . . . . . . . . . . . . . . . . . . . .
3
5
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
How Many Experiments Are Needed to Adapt?
Sergio Bittanti, Marco C. Campi, Maria Prandini . . . . . . . . . . . . . . . . . . . . . . . . .
5
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2
Worst-Case Approach to Adaptation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.1
Worst-Case Performance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.2
Adaptive Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
3
The Experimental Effort Needed for Adaptation . . . . . . . . . . . . . . . . . . . . . . . .
9
4
A Numerical Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
5
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
A Mutual Information Based Distance for Multivariate Gaussian Processes
Jeroen Boets, Katrien De Cock, Bart De Moor . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2
Model Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
3
Principal Angles, Canonical Correlations and Mutual Information . . . . . . . . .
19
3.1
Principal Angles and Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
3.2
Canonical Correlations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
3.3
Mutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
An Example of Two-Parameter Poisson-Dirichlet Distributions
3.4
Application to Stochastic Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21

XIV
Contents
4
A Distance Between Multivariate Gaussian Processes . . . . . . . . . . . . . . . . . . .
25
4.1
Deﬁnition and Metric Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
4.2
Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
5
Special Case of Scalar Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
5.1
Relation with Subspace Angles Between Scalar Stochastic Processes. .
27
5.2
Relation with a Cepstral Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
6
The Cepstral Nature of the Mutual Information Distance . . . . . . . . . . . . . . . . .
28
6.1
Multivariate Power Cepstrum and Cepstral Distance . . . . . . . . . . . . . . . .
28
6.2
The Cepstral Nature of the Mutual Information Distance . . . . . . . . . . . .
29
7
Conclusions and Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
7.1
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
7.2
Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
Differential Forms and Dynamical Systems
Christopher I. Byrnes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
2
Planar Dynamical Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
3
The Principle of the Torus for Autonomous Systems . . . . . . . . . . . . . . . . . . . .
40
4
Lyapunov-Like Differential Forms for the Existence of Cross Sections . . . . .
41
5
Necessary and Sufﬁcient Conditions for Existence of Periodic Orbits . . . . . .
42
6
Stability and Robustness of Periodic Orbits . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
An Algebraic Framework for Bayes Nets of Time Series
Peter E. Caines, Henry P. Wynn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
2
Conditional Independence and Stochastic Realization . . . . . . . . . . . . . . . . . . .
46
3
Lattice Conditionally Independence and Stochastic Realization . . . . . . . . . . .
48
3.1
Lattices of Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
3.2
Lattice Conditionally Orthogonal Stochastic Hilbert Spaces . . . . . . . . .
49
4
Spatially Patterned Inﬁnite Bayes Nets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
A Birds Eye View on System Identiﬁcation
Manfred Deistler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
2
Structure Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
3
Estimation for a Given Subclass . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
4
Model Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
5
Linear Non-mainstream Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
6
Nonlinear Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
7
Present State and Future Developments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70

Contents
XV
Augusto Ferrante, Michele Pavon, Federico Ramponi . . . . . . . . . . . . . . . . . . . . . .
73
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
2
A Generalized Moment Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
3
Kullback-Leibler Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
4
Optimality Conditions and the Dual Problem. . . . . . . . . . . . . . . . . . . . . . . . . . .
76
5
An Existence Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
6
A Descent Method for the Dual Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
Factor Analysis and Alternating Minimization
Lorenzo Finesso, Peter Spreij . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
2
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
3
Lifting of the Original Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
3.1
The First Partial Minimization Problem . . . . . . . . . . . . . . . . . . . . . . . . . .
88
3.2
The Second Partial Minimization Problem . . . . . . . . . . . . . . . . . . . . . . . .
89
3.3
The Link to the Original Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
4
Alternating Minimization Algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
4.1
The Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
4.2
Proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
A
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
A.1
Multivariate Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
A.2
Partitioned Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
Tensored Polynomial Models
Paul A. Fuhrmann, Uwe Helmke . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
2
Tensored Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
2.1
Preliminaries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
2.2
Tensored Polynomial and Rational Models. . . . . . . . . . . . . . . . . . . . . . . .
99
2.3
Module Structures on Tensored Models . . . . . . . . . . . . . . . . . . . . . . . . . . 101
2.4
Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
2.5
Homomorphisms of Tensored Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
3
Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
3.1
The Space of Intertwining Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
3.2
The Polynomial Sylvester Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
3.3
Solving the Sylvester Equation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
3.4
Invariant Factors of the Sylvester Map . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
Distances Between Time-Series and Their Autocorrelation Statistics
Tryphon T. Georgiou . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
2
Interpretation of the L1 Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
Further Results on the Byrnes-Georgiou-Lindquist Generalized
Moment Problem

XVI
Contents
3.1
An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
4
Approximating Sample Covariances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
4.1
Comparison with the von Neumann Entropy . . . . . . . . . . . . . . . . . . . . . . 120
4.2
Structured Covariances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Global Identiﬁability of Complex Models, Constructed from Simple
Submodels
Markus Gerdin, Torkel Glad, Lennart Ljung . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
123
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
2
The Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
3
A Simple Example of Interconnected Modules . . . . . . . . . . . . . . . . . . . . . . . . . 126
4
Preliminary Considerations and Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
5
Identiﬁability Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
6
A Formal Theorem on Identiﬁability from Sub-models . . . . . . . . . . . . . . . . . . 131
6.1
Global Identiﬁability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
6.2
Local Identiﬁability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
7
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
Identiﬁcation of Hidden Markov Models - Uniform LLN-s
L´aszl´o Gerencs´er, G´abor Moln´ar-S´aska. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
135
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
2
Hidden Markov Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
3
L-Mixing Processes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
4
Asymptotic Properties of the Log-Likelihood Function . . . . . . . . . . . . . . . . . . 139
5
The Case of Primitive Q-s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
6
The Derivative of the Predictive Filter. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
7
Uniform Laws of Large Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
8
Estimation of Hidden Markov Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
Identiﬁability and Informative Experiments in Open and
Closed-Loop Identiﬁcation
Michel Gevers, Alexandre Sanfelice Bazanella, Ljubiˇsa Miˇskovi´c . . . . . . . . . . . . .
151
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
2
The Prediction Error Identiﬁcation Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
3
Identiﬁability, Informative Data, and All That Jazz . . . . . . . . . . . . . . . . . . . . . . 154
4
Analysis of the Information Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
4.1
Expressions of the Pseudoregression Vector . . . . . . . . . . . . . . . . . . . . . . . 157
4.2
The Range and Kernel of Rank-One Vector Processes . . . . . . . . . . . . . . 158
4.3
Regularity Conditions for I(θ): A First Analysis . . . . . . . . . . . . . . . . . . . 159
4.4
Rich and Exciting Signals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
5
Regularity of I(θ) for ARMAX and BJ Model Structures . . . . . . . . . . . . . . . . 166
6
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
3
A Distance Between Covariance Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115

Contents
XVII
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
2
Interpolation Conditions as Matrix Equations . . . . . . . . . . . . . . . . . . . . . . . . . . 172
3
The Connection with the Kimura-Georgiou Parametrization . . . . . . . . . . . . . . 177
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
The Control of Error in Numerical Methods
Daniel Holder, Lin Huo, Clyde F. Martin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
183
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
2
A Simple Example. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
3
Four-Step Adams-Bashforth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
4
Statistical Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
5
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
Contour Reconstruction and Matching Using Recursive Smoothing Splines
Maja Karasalo, Xiaoming Hu, Clyde F. Martin . . . . . . . . . . . . . . . . . . . . . . . . . . .
193
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
2
Problem Formulation and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
3
Some Theoretical Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
3.1
Proper Periodicity Conditions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
3.2
Continuous Time, Continuous Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
3.3
Continuous Time, Discrete Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
3.4
Continuous Time, Discrete Data Iterated . . . . . . . . . . . . . . . . . . . . . . . . . 200
4
Data Set Reconstruction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200
5
Evaluation of Recursive Spline Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
6
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
Role of LQ Decomposition in Subspace Identiﬁcation Methods
Tohru Katayama . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
2
State-Input-Output Matrix Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
3
MOESP Method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
4
N4SID Method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
4.1
Zero-Input Responses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
4.2
Relation to Ho-Kalman’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
4.3
State Vector and Zero-State Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
4.4
Zero-State Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
5
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
Canonical Operators on Graphs
Matthias Kawski, Thomas J. Taylor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
221
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
2
Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
On Interpolation and the Kimura-Georgiou Parametrization
Andrea Gombani, Gy¨orgy Michaletzky . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
171

XVIII
Contents
3
Differences, Divergences, Laplacians and Dirac Operators . . . . . . . . . . . . . . . 227
4
Operators on Weighted Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
5
The Incidence Operator and Its Kin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
6
The Drift of a Digraph. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
Prediction-Error Approximation by Convex Optimization
Anders Lindquist . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
2
Prediction-Error Approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
3
Prediction-Error Approximation in Restricted Model Classes . . . . . . . . . . . . . 241
4
The Kullback-Leibler Criterion and Maximum-Likelihood Identiﬁcation . . . 245
5
Prediction-Error Approximation by Analytic Interpolation . . . . . . . . . . . . . . . 246
6
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
Patchy Solutions of Hamilton-Jacobi-Bellman Partial Differential Equations
Carmeliza Navasca, Arthur J. Krener. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
251
1
Hamilton Jacobi Bellman PDEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
2
Other Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
3
New Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
4
One Dimensional HJB PDEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
5
One Dimensional Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
6
HJB PDEs in Higher Dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
7
Two Dimensional Example. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
8
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
A Geometric Assignment Problem for Robotic Networks
Stephen L. Smith, Francesco Bullo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
271
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
2
Geometric and Stochastic Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
2.1
The Euclidean Traveling Salesperson Problem. . . . . . . . . . . . . . . . . . . . . 273
2.2
Bins and Balls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
2.3
Random Geometric Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
3
Network Model and Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
3.1
Robotic Network Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
3.2
The Target Assignment Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
3.3
Sparse and Dense Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
4
Sparse Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
4.1
Assignment-Based Algorithms with Lower Bound Analysis . . . . . . . . . 275
4.2
The ETSP ASSGMTAlgorithm with Upper Bound Analysis . . . . . . . . . 276
5
Dense Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
5.1
The GRID ASSGMTAlgorithm with Complexity Analysis . . . . . . . . . . . 279
5.2
A Sensor Based Version . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
5.3
Congestion Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
2.1
The Geometry of Graphs and Digraphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
2.2
Operator Theory on Graphs and Digraphs . . . . . . . . . . . . . . . . . . . . . . . . 224

Contents
XIX
6
Conclusion and Extensions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
On the Distance Between Non-stationary Time Series
Stefano Soatto . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
2
Formalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
2.1
Introducing Nuisances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
2.2
Dynamic Time Warping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
2.3
Dynamics, or Lack Thereof, in DTW . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
3
Time Warping Under Dynamic Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
3.1
Going Blind . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
3.2
Computing the Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
4
Correlation Kernels for Non-stationary Time Series . . . . . . . . . . . . . . . . . . . . . 294
5
Invariance Via Canonization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
6
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
Stochastic Realization for Stochastic Control with Partial Observations
Jan H. van Schuppen. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
2
Problem Formulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
3
The Classical Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
4
The Stochastic Realization Approach to Stochastic Control with Partial
Observations
305
5
Special Cases
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
306
6
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312
Experiences from Subspace System Identiﬁcation - Comments from
Process Industry Users and Researchers
Bo Wahlberg, Magnus Jansson, Ted Matsko, Mats A. Molander . . . . . . . . . . . . . .
315
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
2
Questions and Answers from the User . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
3
Comments from the Researchers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320
4
Input Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
5
Merging Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322
6
Merging of Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
7
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326
Recursive Computation of the MPUM
Jan C. Willems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
2
Problem Statement. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
3
Subspace Identiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
4
State Construction by Past/Future Partition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334

XX
Contents
7
Recursive Computation of a Module Basis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
8
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
8.1
Subspace ID . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
8.2
State Construction by Shift-and-Cut . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
8.3
Return to the Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
8.4
Approximation and Balanced Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . 343
8.5
The Complementary System. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
New Development of Digital Signal Processing Via Sampled-Data
Control Theory
Yutaka Yamamoto . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
1
Foreword. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
2
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
3
The Shannon Paradigm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
3.1
Problems in the Shannon Paradigm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
4
Control Theoretic Formulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349
5
Application to Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352
6
Concluding Remarks and Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
5
The Hankel Structure and the Past/Future Partition . . . . . . . . . . . . . . . . . . . . . . 336
6
The Left Kernel of a Hankel Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338

List of Contributors
Masanao Aoki
Department of Economics, University of California, Los Angeles,
Los Angeles, CA 90095-1477, USA.
aoki@econ.ucla.edu
Alexandre Sanfelice Bazanella
Electrical Engineering Department, Universidade Federal do Rio Grande do Sul,
Av. Osvaldo Aranha 103, 90035-190 Porto Alegre-RS, Brazil.
bazanela@ece.ufrgs.br
Sergio Bittanti
Dipartimento di Elettronica e Informazione, Politecnico di Milano,
Piazza Leonardo da Vinci 32, I-20133 Milano, Italy.
bittanti@elet.polimi.it
Jeroen Boets
Department of Electrical Engineering (ESAT-SCD), Katholieke Universiteit Leuven,
Kasteelpark Arenberg 10, B-3001 Leuven, Belgium.
jeroen.boets@esat.kuleuven.be
Francesco Bullo
Department of Mechanical Engineering, Center for Control, Dynamical Systems and
Computation, University of California, Santa Barbara, CA 93106-5070, USA.
bullo@engineering.ucsb.edu
Christopher I. Byrnes
Department of Electrical and Systems Engineering, Washington University in St. Louis,
One Brookings Drive, St. Louis, MO 63130, USA.
chrisbyrnes@wustl.edu
Peter E. Caines
Department of Electrical and Computer Engineering, McGill University,
3480 University Street, Montreal, QC H3A 2A7, Canada.
peterc@cim.mcgill.ca

XXII
List of Contributors
Marco C. Campi
Dipartimento di Elettronica per l’Automazione, Universit`a di Brescia,
Via Branze 38, I-25123 Brescia, Italy.
marco.campi@ing.unibs.it
Katrien De Cock
Department of Electrical Engineering (ESAT-SCD), Katholieke Universiteit Leuven,
Kasteelpark Arenberg 10, B-3001 Leuven, Belgium.
katrien.decock@esat.kuleuven.be
Manfred Deistler
Institut f¨ur Wirtschaftsmathematik, Forschungsgruppe ¨Okonometrie und System-
theorie, Technische Universit¨at Wien, Argentinierstraße 8, A-1040 Wien, Austria.
Manfred.Deistler@tuwien.ac.at
Bart De Moor
Department of Electrical Engineering (ESAT-SCD), Katholieke Universiteit Leuven,
Kasteelpark Arenberg 10, B-3001 Leuven, Belgium.
bart.demoor@esat.kuleuven.be
Augusto Ferrante
Dipartimento di Ingegneria dell’Informazione, Universit`a di Padova,
Via Gradenigo 6/B, I-35131 Padova, Italy.
augusto@dei.unipd.it
Lorenzo Finesso
Institute of Biomedical Engineering, CNR-ISIB, Padova,
Corso Stati Uniti 4, I-35127 Padova, Italy.
lorenzo.finesso@isib.cnr.it
Paul A. Fuhrmann
Department of Mathematics, Ben-Gurion University of the Negev,
P.O.B. 653, Beer Sheva 84105, Israel.
fuhrmannbgu@gmail.com
Tryphon T. Georgiou
Department of Electrical and Computer Engineering, University of Minnesota,
200 Union Street S.E., Minneapolis, MN 55455, USA.
tryphon@umn.edu
Markus Gerdin
NIRA Dynamics AB, Gothenburg, Sweden.
markus.gerdin@gmail.com
L´aszl´o Gerencs´er
MTA SZTAKI (Computer and Automation Institute, Hungarian Academy of Sciences),
Kende u. 13-17, H-1111 Budapest, Hungary.
gerencser@sztaki.hu

List of Contributors
XXIII
Michel Gevers
CESAME, Universit´e Catholique de Louvain,
Avenue Georges Lemaˆıtre 4, B-1348 Louvain-la-Neuve, Belgium.
gevers@csam.ucl.ac.be
Torkel Glad
Automatic Control, Department of Electrical Engineering, Link¨oping University,
SE-58183 Link¨oping, Sweden.
torkel@isy.liu.se
Andrea Gombani
Institute of Biomedical Engineering, CNR-ISIB, Padova,
Corso Stati Uniti 4, I-35127 Padova, Italy.
gombani@isib.cnr.it
Uwe Helmke
Institut f¨ur Mathematik, Universit¨at W¨urzburg,
D-97074 W¨urzburg, Germany.
helmke@mathematik.uni-wuerzburg.de
Daniel Holder
Department of Mathematics and Statistics, Texas Tech University,
2500 Broadway, Lubbock, TX 79409-1042, USA.
daniel.holder@ttu.edu
Xiaoming Hu
Optimization and Systems Theory, Department of Mathematics, Royal Institute of
Technology, SE-10044 Stockholm, Sweden.
hu@kth.se
Lin Huo
Department of Mathematics and Statistics, Texas Tech University,
2500 Broadway, Lubbock, TX 79409-1042, USA.
lin.huo@ttu.edu
Magnus Jansson
Signal Processing, School of Electrical Engineering, Royal Institute of Technology,
SE-10044 Stockholm, Sweden.
magnus.jansson@ee.kth.se
Maja Karasalo
Optimization and Systems Theory, Department of Mathematics, Royal Institute of
Technology, SE-10044 Stockholm, Sweden.
karasalo@math.kth.se

XXIV
List of Contributors
Tohru Katayama
Faculty of Culture and Information Science, Doshisha University,
KyoTanabe, Kyoto 610-0394, Japan.
tokataya@mail.doshisha.ac.jp
Matthias Kawski
Department of Mathematics and Statistics, Arizona State University,
Tempe, AZ 85287-1804, USA.
kawski@asu.edu
Arthur J. Krener
Department of Applied Mathematics, Naval Postgraduate School,
Monterey, CA 93943-5216, USA.
ajkrener@nps.edu
Anders Lindquist
Optimization and Systems Theory, Department of Mathematics, Royal Institute of
Technology, SE-10044 Stockholm, Sweden.
alq@math.kth.se
Lennart Ljung
Automatic Control, Department of Electrical Engineering, Link¨oping University,
SE-58183 Link¨oping, Sweden.
ljung@isy.liu.se
Clyde F. Martin
Department of Mathematics and Statistics, Texas Tech University,
2500 Broadway, Lubbock, TX 79409-1042, USA.
clyde.f.martin@ttu.edu
Ted Matsko
ABB USA.
ted.matsko@us.abb.com
Gy¨orgy Michaletzky
Department of Probability Theory and Statistics, E¨otv¨os Lor´and University,
P´azm´any P´eter s´et´any 1/C, H-1117 Budapest, Hungary.
michgy@ludens.elte.hu
Ljubiˇsa Miˇskovi´c
CESAME, Universit´e Catholique de Louvain,
Avenue Georges Lemaˆıtre 4, B-1348 Louvain-la-Neuve, Belgium.
miskovic@csam.ucl.ac.be
Sanjoy K. Mitter
LIDS, Massachusetts Institute of Technology,
77 Massachusetts Avenue, Cambridge, MA 02139-4307, USA.
mitter@mit.edu

List of Contributors
XXV
Mats A. Molander
ABB Corporate Research, V¨aster˚as, Sweden.
mats.a.molander@se.abb.com
G´abor Moln´ar-S´aska
Morgan Stanley Hungary Analytics, Budapest,
De´ak Ferenc u. 15, H-1052 Budapest, Hungary.
gabor.molnar-saska@morganstanley.com
Carmeliza Navasca
ETIS Lab - UMR CNRS 8051,
Avenue du Ponceau 6, F-95014 Cergy-Pontoise, France.
cnavasca@gmail.com
Michele Pavon
Dipartimento di Matematica Pura ed Applicata, Universit`a di Padova,
Via Trieste 63, I-35131 Padova, Italy.
pavon@math.unipd.it
Maria Prandini
Dipartimento di Elettronica e Informazione, Politecnico di Milano,
Piazza Leonardo da Vinci 32, I-20133 Milano, Italy.
prandini@elet.polimi.it
Federico Ramponi
Dipartimento di Ingegneria dell’Informazione, Universit`a di Padova,
Via Gradenigo 6/B, I-35131, Padova, Italy.
rampo@dei.unipd.it
Stephen L. Smith
Department of Mechanical Engineering, Center for Control, Dynamical Systems and
Computation, University of California, Santa Barbara, CA 93106-5070, USA.
stephen@engineering.ucsb.edu
Stefano Soatto
Computer Science Department, University of California, Los Angeles,
3531 Boelter Hall, Los Angeles, CA 90095-1596, USA.
soatto@ucla.edu
Peter Spreij
Korteweg-de Vries Institute for Mathematics, Universiteit van Amsterdam,
Plantage Muidergracht 24, 1018 TV Amsterdam, The Netherlands.
spreij@science.uva.nl
Thomas J. Taylor
Department of Mathematics and Statistics, Arizona State University,
Tempe, AZ 85287-1804, USA.
tom.taylor@asu.edu

XXVI
List of Contributors
Jan H. van Schuppen
CWI, P.O. Box 94079, 1090 GB Amsterdam, The Netherlands.
J.H.van.Schuppen@cwi.nl
Bo Wahlberg
Automatic Control, School of Electrical Engineering, Royal Institute of Technology,
SE-10044 Stockholm, Sweden.
bo.wahlberg@ee.kth.se
Jan C. Willems
Department of Electrical Engineering (ESAT-SISTA),Katholieke Universiteit Leuven,
Kasteelpark Arenberg 10, B-3001 Leuven, Belgium.
Jan.Willems@esat.kuleuven.be
Henry P. Wynn
Department of Statistics, London School of Economics and Political Science,
Houghton Street, London WC2A 2AE, UK.
h.wynn@lse.ac.uk
Yutaka Yamamoto
Department of Applied Analysis and Complex Dynamical Systems, Graduate School
of Informatics, Kyoto University, Kyoto 606-8501, Japan.
yy@i.kyoto-u.ac.jp

Coefﬁcients of Variations in Analysis of Macro-policy
Effects: An Example of Two-Parameter
Poisson-Dirichlet Distributions
Masanao Aoki⋆
Department of Economics, Univ. California, Los Angeles
aoki@econ.ucla.edu
Summary. A class of two-parameter Poisson-Dirichlet distributions have non-vanishing coefﬁ-
cient of variation. This phenomenon is also known as non-self averaging stochastic multi-sector
endogenous growth model. This model is used to raise questions on the use of means in assessing
effectiveness of macroeconomic or other macro-policy effects. The coefﬁcients of variations of
the number of total sectors, and of sectors of a given size all remain positive as the model size
grows unboundedly.
Keywords: random combinatorial structure, self-averaging, thermodynamic limit, coefﬁcients of
variation.
1
Introduction
This paper discusses a new class of simple stochastic multi-sector growth models in
which macroeconomic variables such as the number of sectors or gross outputs have
non-vanishing coefﬁcients of variations. This is called non-self averaging in physics
literature. For example, as the sizes of models grow as time passes1, the coefﬁcients of
variation of the number of sectors in the model does not converge to zero, but remain
positive. This indicates that the model is inﬂuenced by history, and is non self-averaging
in the language of statistical physics. We show that the class of one-parameter Poisson-
Dirichlet models, also known as Ewens models in population genetics, is self-averaging,
that is, its coefﬁcient of variations tends to zero as time passes, but its extension to two-
parameter Poisson-Dirichlet models by Pitman [6] is not self-averaging.
This fact has an important implication on the effectiveness of macroeconomic poli-
cies based on the expected values of model performances, because the actual values of
some performance index do not cluster around the expected values when the macroe-
conomic variable is not self-averaging.
⋆Fax number 1-310-825-9528, Tel. no. 1-310-825-2360, aoki@econ.ucla.edu. The author
thanks M. Sibuya for useful discussions.
1 Thus, this model is different from those models which are inhabited by an inﬁnite number of
agents from the beginning.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 1–4, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

2
M. Aoki
2
The Model
Consider an economy composed of several sectors. Different sectors are made up of
different types of agents or productive units. The model sectors are thus heterogeneous.
Counting the sizes of sectors in some basic units, when the economy is of size n, there
are Kn sectors, that is Kn types of agents or productive units in the economy. The
number Kn as well as the sizes of individual sectors, ni, i = 1, . . . , Kn, are random
variables.
Time runs continuously. Over time, one of the existing sectors grows by one unit at
a rate which is proportional to (ni −α)/(n + θ), i = 1, . . . Kn, where α is a parameter
between 0 and 1, and θ is another parameter, θ + α > 0. The rate at which a new sector
emerges in the economy is equal to 1 −k
i=1(ni −α)(n + θ) = (θ + kα)(n + θ).2
The probability that a new sector emerges is expressible then as
qα,θ(n + 1, k) = n −kα
n + θ qα,θ(n, k) + θ + (k −1)α
n + θ
qα,θ(n, k −1).
(1)
where qα,θ(n, k) := Pr(Kn = k).
Eq. (1) states that the economy composed of k sectors increases in size by one unit
either by one of the existing sectors growing by one unit, or by a new sector of size one
emerging. We assume that a new sector always begins its life with a single unit. We can
restate it as
Pr(Kn+1 = k + 1|Kn = k) = kα + θ
n + θ , and Pr(Kn+1 = k|Kn = k) = n −kα
n + θ .
(2)
Note that more new sectors are likely to emerge in the economy as the numbers of
sectors grow.
3
Asymptotic Properties of the Number of Sectors
We next examine how the number of sectors behaves as the size of the model grows
unboundedly. We know how it behaves when α is zero. It involves Stirling number of
ﬁrst kind, see [1], for example. With positive α, the generalized Stirling number of the
ﬁrst kind, c(n, k; α), is involved in its expression. Dropping the subscripts α, θ from
Pr, we write
Pr(Kn = k) = θ[k,α]
αkθ[n] c(n, k; α),
(3)
where θ[k,α] := θ(θ+α) · · · (θ+(k−1)α), and θ[n] := θ[n,1] = θ(θ+1) · · · (θ+n−1).
See [3] or [8] for their properties.
Deﬁne Sα(n, k) = c(n, k; α)/αk. It satisﬁes a recursion equation
Sα(n, k) = (n −kα)Sα(n, k) + Sα(n, k −1).
(4)
This function generalizes the power-series relation for θ[n] = n
1 c(n, k)θk, to θ[n] =
 Sα(n, k)θ[k,α]. See [1] for example.
2 Our θ is β −α in [5].

Coefﬁcients of Variations in Analysis of Macro-policy Effects
3
4
The Coefﬁcients of Variation
4.1
The Number of Sectors
Yamato and Sibuya [8] have calculated the moments of Kr
n, r = 1, 2, . . ., recursively.
For example they derive a recursion relation
E(Kn+1) =
θ
n + θ + (1 +
α
n + θ)E(Kn)
from which they obtain
E[Kn
nα ] ∼Γ(θ + 1)
αΓ(θ + α)
(5)
by applying the asymptotic expression for the Gamma function
Γ(n + a)
Γ(n)
∼na.
(6)
They also obtain the expression for the variance of Kn/nα as
var(Kn/nα) ∼Γ(θ + 1)
α2
γ(α, θ),
(7)
where γ(α, θ) := (θ + α)/(Γ(θ + α)) −Γ(θ + 1)/[Γ(θ + α)]2.
The expression for the coefﬁcient of variation of Kn normalized by nα then is given
by
limC.V.(Kn/nα) = Γ(θ + α)
Γ(θ + 1)

γ(α, θ).
(8)
Note that the expression γ(α, θ) is zero when α is zero, and positive otherwise. We
state this result as
Proposition. The limit of the coefﬁcient of variation is positive with positive α, and it
is zero only with α = 0.
In other words, models with o < α < 1 are non self-averaging. Past events inﬂuence the
path of the growth of this model, i.e., the model experiences non ergodic growth path.
4.2
The Number of Sectors of Speciﬁed Size
Let aj(n) be the number of sectors of size j when the size of the economy is n. From
the deﬁnitions, note that Kn = 
j aj(n), and 
j jaj(n)n, where j ranges from 1 to n.
The results in [8] can be used to show that the limit of the coefﬁcient of variation of
aj(n)/nα as n goes to inﬁnity has the same limiting behavior as Kn/nα, i.e., zero for
α = 0, and positive for 0 < α < 1.
5
Discussion
This short note shows that the one-parameter Poisson-Dirichlet model, known as Ewens
model in the population genetics literature, is self-averaging, but its extension,

4
M. Aoki
two-parameter Poisson-Dirichlet models are not. The behavior of the latter models is
history or sample-path dependent. Given such macroeconomic models, the usual prac-
tice of minimizing the means of some performanceindex is not satisfacotry. Performance
indices of such models may be fat-tailed, and minimizing the means may not be satis-
factory.
We discuss how this type of models is important in macroeconomics and ﬁnance
modeling.
The two-parameter models are signiﬁcant because their moments are related to those
of the Mittag-Lefﬂer distribution in a simple way, and as Darling-Kac theorem implies,
[4], any analysis involving ﬁrst passages, occupation times, waiting time distributions
and the like are bound to involve the Mittag-Lefﬂer functions. In other words, Mittag-
Lefﬂer functions are generic in examining model behaviors as the model sizes grow
unboundedly.
One straightforward way to link the moments of Kn/nα to the generalized Mittag-
Lefﬂer function gα,θ(x) :=
Γ(θ+1)
Γ(µ+1)xµgα(x), where µ := θ/α, and where gα is a
probability density with moments
 ∞
0
xpgα(x)dx = Γ(p + 1)
Γ(pα + 1),
(9)
for p = 0, 1, . . ., is to apply the method of moments, [2].
Using the Laplace transform of the Mittag-Lefﬂer function, Mainardi and his asso-
ciate and colleagues have discussed fractional calculus, and fractional master equations,
with applications to ﬁnancial problems in mind, Mainardi et al. For example see [7].
The class of models in this note may thus turn out to be important not only in ﬁnance
but also in macroeconomics.
References
1. Aoki, M., (2002) Modeling Aggregate Behavior and Fluctuations in Economics : Stochastic
Views of Interacting Agents, (Cambridge Univ. Press, New York).
2. Breiman, L., (1992) Probability, (Siam, Philadelphia).
3. Charalambides,
Ch.,
(2002)
Enumerative
Combinatorics,
(Chapman
&
Hall/CRC,
London).
4. Darling, D. A., and M. Kac (1957) On occupation-times for Markov processes, Transactions
of American Mathematical Society, 84, 444-458.
5. Feng, S., and F. M. Hoppe, (1998) Large deviation principles for some random combinatorial
structures, The Annals of Applied Probability, 8, 975–994.
6. Pitman, J., (1999) Characterizations of Brownian motion, bridge, meander and excursion by
sampling at independent uniform times, Electronic J. Probability 4, Paper 11, 1–33.
7. Scalas, E., (2006) The application of continuous-time random walks in ﬁnance and economics,
Physica A 362, 225-239.
8. Yamato, H., and M. Sibuya, (2000) Moments of some statistics of Pitman Sampling formula,
Bulletin of Informatics and Cybernetics, 32, 1–10, 2000.

How Many Experiments Are Needed to Adapt?⋆
Sergio Bittanti1, Marco C. Campi2, and Maria Prandini1
1 Dipartimento di Elettronica e Informazione - Politecnico di Milano,
piazza Leonardo da Vinci 32, 20133 Milano, Italia
{bittanti,prandini}@elet.polimi.it
2 Dipartimento di Elettronica per l’Automazione - Universit`a di Brescia,
via Branze 38, 25123 Brescia, Italia
marco.campi@ing.unibs.it
Summary. System design in presence of uncertainty calls for experimentation, and a question
that arises naturally is: how many experiments are needed to come up with a system meeting
certain performance requirements?
This contribution represents an attempt to answer this fundamental question. Results are con-
ﬁned to a speciﬁc set-up where adaptation is performed according to a worst-case perspective,
but many considerations and reﬂections are central to adaptation in general.
1
Introduction
Given a system S, consider the problem of designing a device D that achieves some
desired behavior when interacting with S. The speciﬁcation of the ‘desired behav-
ior’ depends on the intended use of the device, and is usually expressed in terms of
some signal sD(ω), with reference to certain operating conditions ω ∈Ωof interest
(Figure 1).
Fig. 1. Characterization through signal sD(ω) of device D while interacting with system S in the
operating condition ω
Example 1 (simulator). Suppose that the device should act as a simulator of the system
when the system input u takes on value in a given class of signals U. In this case, ω = u
and the desired behavior for the device can be expressed in terms of the multidimen-
sional signal sD(u) = (y(u), yD(u)), where yD(u) and y(u) represent the outputs of
⋆This work is supported by MIUR (Ministero dell’Istruzione, dell’Universit`a e della Ricerca)
under the project Identiﬁcation and adaptive control of industrial systems and by CNR - IEIIT.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 5–14, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

6
S. Bittanti, M.C. Campi, and M. Prandini
the device and of the system fed by the same input signal u ∈U (see Figure 2). Signal
sD(u) should be such that yD(u) ≃y(u), for every operating condition of interest, that
is for every u ∈U.
Fig. 2. Device D acting as a simulator of system S
Example 2 (disturbance compensator). Suppose that the output of system S is affected
by some additive disturbance and the device D is introduced for compensating the dis-
turbance according to the feedforward scheme in Figure 3. In this case the operating
condition is deﬁned by the disturbance realization d. If we denote by yD(d) the con-
trolled output of the system when the disturbance realization is d, then the desired
behavior can be expressed in terms of the signal sD(d) = yD(d) and sD(d) should be
small for every d in some set D.
Fig. 3. Device D acting as a disturbance compensator for system S
Devising a suitable D for a system S requires knowledge of some sort on S. Most litera-
ture in science and engineering relies on a model-based approach, namely it is assumed
that a mathematical model for S is a-priori available. Alternatively, the knowledge on
S can be accrued through experimentation. This latter approach, considered herein, is
referred to as ‘adaptive design’, [1, 2, 3, 4, 5], since the problem is to adapt D on the
basis of experiments in the face of the lack of a-priori knowledge on system S.
In adaptive design, one fundamental question to ask is:
How extensively do we need to experiment in order to come up with a
device meeting certain performance requirements?

How Many Experiments Are Needed to Adapt?
7
This fundamental –and yet largely unanswered– question is the theme this contribution
is centered around.
In this paper, a worst-case perspective with respect to the possible operating condi-
tions is adopted, and we provide an answer to the above question in this speciﬁc set-up.
For one answer, many more are the answers that this contribution is incapable to pro-
vide, which will also be enlightened along our way.
2
Worst-Case Approach to Adaptation
2.1
Worst-Case Performance
Suppose that the performance of device D operating in condition ω is quantiﬁed by
a cost c(sD(ω)). Then, the worst-case performance achieved by D over the set Ωof
operating conditions is
max
ω∈Ωc(sD(ω)),
and, correspondingly, one wants to design
D⋆= arg min
D max
ω∈Ωc(sD(ω)).
(1)
c⋆denotes the worst-case performance of device D⋆, that is c⋆=maxω∈Ωc(sD⋆(ω)).
In e.g. the simulator Example 1, ω = u and one can take c(sD(u)) = ∥y(u) −
yD(u)∥2, the 2-norm of the error signal y(u) −yD(u). c⋆can then be interpreted as
an upper bound to the largest 2-norm discrepancy between the system behavior and the
behavior of the simulator D⋆in the same operating condition:
∥y(u) −yD⋆(u)∥2 ≤c⋆, ∀u ∈U.
In the disturbance compensator Example 2, a sensible cost is the 2-norm c(sD(d)) =
∥yD(d)∥2. Then, the best disturbance compensator D⋆satisﬁes:
∥yD⋆(d)∥2 ≤c⋆, ∀d ∈D.
In many cases, the device D is parameterized by a vector γ ∈ℜk, in which case we
write Dγ to indicate device D with parameter γ, and hence designing a device corre-
sponds to selecting a value for γ. Then, with the shorthand
Jγ(ω) := c(sDγ(ω)),
the min-max optimization problem (1) can be rewritten as the following robust opti-
mization program with k + 1 optimization variables:
RP :
min
γ,c∈ℜk+1 c
subject to:
(2)
Jγ(ω) ≤c, ∀ω ∈Ω.
Note that, given a γ, the slack variable c represents an upper bound on the cost Jγ(·)
achieved over Ωby the device with parameter γ. By solving (2) we seek that γ⋆that
corresponds to the smallest upper bound c⋆.

8
S. Bittanti, M.C. Campi, and M. Prandini
2.2
Adaptive Design
In model-based design, the cost Jγ(ω) can be evaluated based on the model, and then
γ⋆is found by solving the robust optimization program (2). Instead, when system S
is unknown or only partially known, the cost Jγ(ω) cannot be explicitly computed so
that the constraints in (2) are not known. However, one can conceive of evaluating the
constraints experimentally. What exactly this means is discussed in the sequel.
Each constraint is associated with an operating condition ω ∈Ω. To evaluate exper-
imentally a constraint in a speciﬁc condition, say ˆω ∈Ω, that is to determine experi-
mentally the domain of feasibility in the (γ, c)’s space where the constraint Jγ(ˆω) ≤c
holds, one should run a set of experiments, all in the ˆω condition, each of which per-
formed with a different device Dγ, γ ∈ℜk. In this way sDγ(ˆω) is measured for every
γ and Jγ(ˆω) can be computed. An objection to this way of proceeding is that it would
require in principle to test the performance achieved with every and each device Dγ in
place. It is an interesting fact that in many situations the overwhelming experimental
effort involved in testing many times with different Dγ’s can be avoided, and just one
single experiment is enough for the purpose of computing Jγ(ˆω).
Take e.g. the simulator Example 1. In this example, if ˆu is injected into S, signal
ˆy = S[ˆu] can be collected, along with signal ˆu itself. Based on this single experiment,
one can then compute y(ˆu) −yDγ(ˆu) = ˆy −Dγ[ˆu] for all γ’s, where Dγ[ˆu] is obtained
by ﬁltering ˆu with Dγ, an operation that can be executed as an off-line post-process of
signal ˆu. After y(ˆu) −yDγ(ˆu) has been computed, the constraint ∥y(ˆu) −yDγ(ˆu)∥2 =
Jγ(ˆu) ≤c is evaluated.
The same conclusion that one experiment is enough can also be drawn for Example 2
whenever both the system and the device are linear. Indeed, swapping the order of S
and Dγ, we have:
yDγ(d) = S[Dγ[d]] + d = Dγ[S[d]] + d.
(3)
If we run an experiment in which disturbance ˆd is measured and this disturbance is also
injected as input to the system (i.e. D is set to 1 during experimentation in the scheme
of Figure 3), from the measured system output ˆy = S[ ˆd] + ˆd and from ˆd itself we can
then determine
yDγ( ˆd) = Dγ[S[ ˆd]] + ˆd
(using (3))
= Dγ[ˆy −ˆd] + ˆd,
where computation of Dγ[ˆy −ˆd] is executed off-line similarly to the simulator example.
By computing ∥yDγ( ˆd)∥2 = Jγ( ˆd) constraint Jγ( ˆd) ≤c is then evaluated.
In the sequel we shall assume that one single experiment in condition ˆω sufﬁces to
determine constraint Jγ(ˆω) ≤c. This assumption is not fulﬁlled in all applications of
the adaptive scheme, and further discussion on this point is provided in Section 5.
Remark 1. The reader may have noticed that lack of knowledge, for which adaptation
is required, can enter the problem in different ways. In Example 1, it was system S to
be unknown. In the disturbance compensator Example 2, again uncertainty stayed with
the system S, but even the set D for d could be unknown.

How Many Experiments Are Needed to Adapt?
9
The seemingly different nature of the uncertainty in S and in D can be leveled off
by adopting a more abstract behavioral perspective, [6], where the system is just seen
as a set of behaviors, i.e. of possible realizations of system signals. In such framework,
uncertainty simply corresponds to say that the set of behaviors deﬁning the system is
not a-priori known.
We are now facing the central issue this contribution is centered around, that is: an
exact solution of the robust optimization program (2) requires to consider as many ex-
periments as the number of elements in Ω, normally an inﬁnite number. The impos-
sibility to carry out this task suggests introducing approximate schemes where only a
ﬁnite number of ω’s, that is a ﬁnite number of experiments, is considered. Thus, we
can at this point more precisely spell out the question we posed at the end of Section 1,
and ask:
How many experiments do we need to perform to come up with a
design that approximates the solution D⋆of (2) to a desired level of
accuracy?
3
The Experimental Effort Needed for Adaptation
The fact that one concentrates on a ﬁnite number of operating conditions only may ap-
pear naive. The interesting fact is that this way of proceeding can be cast within a solid
mathematical theory providing us with guarantees on the level of accuracy obtained.
Fix an integer N, and let ω(1), ω(2), . . . , ω(N) ∈Ωbe the operating conditions of
N experiments run on the system to evaluate the N corresponding constraints for the
robust program (2). The robust optimization problem restricted to the N experienced
scenarios ω(i), i = 1, 2, . . . , N, reduces to the following ﬁnite optimization problem
referred in the sequel to as ‘scenario program’:
SPN :
min
γ,c∈ℜk+1 c
subject to:
(4)
Jγ(ω(i)) ≤c, i = 1, 2, . . ., N.
As for the selection of the scenarios ω(i), i = 1, 2, . . ., N, we suppose that they are
extracted from set Ωaccording to some probability distribution P that reﬂects the
likelihood of the different ω situations. This is naturally the case in the disturbance
compensator Example 2, assuming the environment randomly selects the disturbance
realizations according to an invariant scheme. If the scenarios are selected by the de-
signer of the experiment, like u in Example 1, probability P is artiﬁcially introduced to
describe the likelihood of the different operating conditions.
Let (γ⋆
N, c⋆
N) be the solution of SPN. c⋆
N quantiﬁes the performance of the device
with parameter γ⋆
N over the extracted operating conditions ω(1), ω(2), . . . , ω(N). More-
over, we clearly have c⋆
N ≤c⋆, the optimal cost with all the constraints in place, that
is, for the extracted scenarios, we have designed a very efﬁcient device, in actual ef-
fects one that even outperforms device D⋆. We cannot be satisﬁed with this sole result,
however, since, due to the limited number of scenarios, there is no guarantee whatsoever

10
S. Bittanti, M.C. Campi, and M. Prandini
with respect to the much larger multitude of possible operating conditions, all those that
have not been seen when performing the design of γ⋆
N. Hence, the following question
arises naturally: what can we claim regarding the performance of the designed device
for all other operating conditions ω ∈Ω, those that were not experienced while doing
the design according to SPN in (4)? Answering this question is necessary to provide
accuracy guarantees and to pose the method on solid grounds.
The posed question is of the ‘generalization type’ in a learning-theoretic sense: we
want to know how the solution (γ⋆
N, c⋆
N) generalizes from experienced operating con-
ditions to unexperienced ones. For ease of explanation, we shall henceforth concentrate
on robust optimization problems of convex-type, since this case can be handled in the
light of a powerful theory that has recently appeared in the literature of robust optimiza-
tion, [7,8]. The non-convex case can be dealt with along a more complicated approach
and is not discussed herein.
RESULT: Select a ‘violation parameter’ ϵ ∈(0, 1) and a ‘conﬁdence parameter’
β ∈(0, 1).
If N satisﬁes
k

i=0
 N
i

ϵi(1 −ϵ)N−i ≤β,
(5)
then, with probability no smaller than 1 −β, the solution (γ∗
N, c∗
N) to (4) satisﬁes
all constraints of problem (2) with the exception of those corresponding to a set of
operating conditions whose probability is at most ϵ.
Bound (5) can be found in [9], a contribution still in the general vein of the theoret-
ical approach opened up in [7,8].
Let us try to understand in detail the meaning of this result. If we neglect for a mo-
ment the part associated with the conﬁdence parameter β, then, the result simply says
that, by extracting a number N of operating conditions as given by (5) and running the
corresponding N experiments to evaluate the constraints appearing in (4), the solution
(γ∗
N, c∗
N) to (4) violates the constraints corresponding to other, unexperienced, operat-
ing conditions with a probability that does not exceed a user-chosen level ϵ. This means
that the so-determined c∗
N provides an upper bound for the cost Jγ⋆
N(ω) valid for every
operating condition ω ∈Ωwith the exclusion of at most an ϵ-probability set.
As for the probability 1 −β, one should note that (γ∗
N, c∗
N) is a random quantity be-
cause it depends on the randomly extracted operating conditions ω(1), ω(2), . . . , ω(N).
It may happen indeed that these conditions are not representative enough (one could
even extract N times the same operating condition!). In this case no generalization is
expected, and the fraction of operating conditions violated by (γ∗
N, c∗
N) will be larger
than ϵ. Parameter β controls the probability of extracting unrepresentative operating
conditions, and the ﬁnal result that (γ∗
N, c∗
N) violates at most an ϵ-fraction of operating
conditions holds with probability 1 −β. One important practical fact is that, due to the
structure of the equation in (5), β can be set to be so small (say β = 10−6) that it is
virtually zero for any practical purpose, and this does not lead to a signiﬁcant increase
in the value of N (see also the numerical example in Section 4).

How Many Experiments Are Needed to Adapt?
11
For the reader’s convenience, the discussion in this section is summarized in a recipe
for a practical implementation of the overall adaptive design scheme.
PRACTICAL RESULT: Select a violation parameter ϵ ∈(0, 1), let β = 10−6,
and compute the least integer N satisfying (5). Run N random experiments and
compute the corresponding N constraints for problem (4).
Then, the solution γ⋆
N of (4) achieves performance c⋆
N on all operating conditions
but an ϵ fraction of them, and, moreover, c⋆
N is ‘better than the best’, in the sense
that c⋆
N ≤c⋆.
Before closing the section, the following ﬁnal remark is worth making in the light of
equation (5):
The number of experiments N that are needed to adapt the device
does not depend on the system complexity; it instead only depends
on the complexity of the device Dγ through the size k of its
parametrization γ.
Thus reality can be any complex and still we can evaluate the experimental effort by
only looking at the device being designed.
4
A Numerical Example
We consider the problem of inverting the nonlinear characteristic between input u
and output y(u, d) of a system affected by an additive output disturbance d
(Figure 4), over the range of values U = [0, 1] for u (input-output equalization).
The device is fed by y(u, d) and produces output yDγ(u, d) = γ1y(u, d)2 +
γ2y(u, d) + γ3. The performance of the device with parameter γ = (γ1, γ2, γ3) ∈ℜ3
is given by maxu,d∈U×D Jγ(u, d), where Jγ(u, d) = |yDγ(u, d) −u| and D is the (un-
known) range of values for d. In words, this performance expresses the largest deviation
off the perfect equalization line yD = u.
We chose ϵ = 0.1, β = 10−6, and according to (5) N was 205.
The scenario program (4) is in this case
min
γ,c∈ℜ4 c
subject to:
(6)
|γ1y(u(i), d(i))2 + γ2y(u(i), d(i)) + γ3 −u(i)| ≤c, i = 1, 2, . . ., 205,
where u(1), u(2), . . . , u(205) are random values for u independently extracted from
U according to the uniform distribution Pu over [0, 1], and d(1), d(2), . . . , d(205) are
random values for d independently created by the environment during experimentation
according to some (unknown) stationary distribution Pd.
The 205 constraints in (6) can be evaluated by running 205 experiments on the sys-
tem where the output samples y(i) = y(u(i), d(i)), i = 1, 2, . . ., 205, are collected
together with u(i), i = 1, 2, . . . , 205. Figure 5 shows the outcomes of the experiments.

12
S. Bittanti, M.C. Campi, and M. Prandini
Fig. 4. Inverting a nonlinear characteristic through a device
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
u
y
Fig. 5. Outcome of the experiments: samples of input u and output y(u, d)
Note that the collected output data present some dispersion due to the presence of the
additive disturbance d.
By solving (6) we obtained γ⋆
205 = (0.424, 0.650, −0.081) and c⋆
205 = 0.108.
c⋆
205 is the maximum equalization error for the extracted scenarios. In Figure 6, we
plot the input and equalized output pairs (u(i), yDγ⋆
205(u(i), d(i))), i = 1, 2, . . . , 205,
and the region u ± c⋆
205 := {(u, y) : u −c⋆
205 ≤y ≤u + c⋆
205, u ∈U}. u ± c⋆
205 is
the strip of minimum width centered around the perfect equalization line yD = u that
contains all the 205 input and equalized output pairs.
In the light of the practical result at the end of the previous section, device γ⋆
205
carries a guarantee that the equalized output yDγ⋆
205 (u, d) differs from u of at most
c⋆
205 = 0.108 for all u’s and d’s except for a subset of probability P = Pu × Pd smaller
than or equal to 0.1; moreover, the region of equalization u ± c⋆
205 is contained within
u±c⋆. This result holds irrespectively of D and Pd, which are unknown to the designer
of the device.

How Many Experiments Are Needed to Adapt?
13
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
u
yDγ⋆
205
Fig. 6. Input u and equalized output yDγ⋆
205 (u, d) for the extracted scenarios, and the region of
equalization u ± c⋆
205
Fig. 7. Actual nonlinear characteristic and disturbance characteristics, along with the designed
device
The actual nonlinear characteristic and disturbance d used to generate the data in
Figure 5 are shown in Figure 7 together with the designed device with parameter γ⋆
205.
In this example, the parameter of the device could have been designed so as to exactly
invert the nonlinear characteristic. However, the obtained γ⋆
205 is different from such a
choice, because the device aims at inverting the nonlinear characteristic between u and
y while also reducing the effect of d on the reconstructed value for the input u.
5
Conclusions
The main goal of this contribution is that of attracting the reader’s attention to the fun-
damental issue of evaluating the experimental effort needed to perform adaptive design,
and some answers have been provided in a speciﬁc worst-case context.

14
S. Bittanti, M.C. Campi, and M. Prandini
Many are the aspects that our discussion has left unsolved, and open to further
investigation:
•
it is not always the case that one experiment provides all the information needed
to evaluate a constraint. In the disturbance compensator example, for instance, if
either the system or the device are not linear it is not possible to swap their order, and
constraint evaluation calls for many experiments with virtually all possible devices
in place. More generally, more experiments are needed when the input to the system
depends on the device being designed.
•
a perspective different from the worst-case approach can be used for adaptive de-
sign. For example, device quality could be assessed by its average performance,
[10,11,12], rather than its worst-case performance over the set of operating condi-
tions of interest.
Addressing these problems is a difﬁcult task that requires much additional effort.
References
1. Sastry S., Bodson M. (1994) Adaptive Control: Stability, Convergence, and Robustness.
Prentice-Hall.
2. Astrom K.J., Wittenmark B. (1994) Adaptive Control. Addison-Wesley.
3. Bittanti S., Picci G. eds. (1996) Identiﬁcation, Adaptation, Learning. The science of learning
models from data. Springer-Verlag, Berlin, Computer and Systems Science Series, Vol. 153.
4. Landau I.D., Lozano R., M’Saad M. (1998) Adaptive Control. Springer-Verlag.
5. Haykin S. (2002) Adaptive Filter Theory. Prentice Hall.
6. Polderman J.W., Willems J.C. (1998) Introduction to Mathematical Systems Theory: A Be-
havioral Approach. Springer Verlag, New York.
7. Calaﬁore G., Campi M.C. (2005) Uncertain convex programs: randomized solutions and
conﬁdence levels. Math. Program., Ser. A 102: 25–46.
8. Calaﬁore G., Campi M.C. (2006) The scenario approach to robust control design. IEEE
Trans. on Automatic Control 51(5):742–753.
9. Campi M.C., Garatti S. (2007) The exact feasibility of randomized solutions of convex pro-
grams. Internal report, University of Brescia, Italy.
10. Vapnik V.N. (1998) Statistical Learning Theory. John Wiley & Sons.
11. Vidyasagar M. (2001) Randomized algorithms for robust controller synthesis using statistical
learning theory. Automatica 37(10):1515-1528.
12. Campi M.C., Prandini M. (2003) Randomized algorithms for the synthesis of cautious adap-
tive controllers. Systems & Control Letters 49(1):21-36.

A Mutual Information Based Distance for Multivariate
Gaussian Processes⋆
Jeroen Boets, Katrien De Cock, and Bart De Moor⋆⋆
K.U.Leuven, Dept. of Electrical Engineering (ESAT-SCD)
Kasteelpark Arenberg 10, B-3001 Leuven, Belgium
{jeroen.boets,katrien.decock,bart.demoor}@esat.kuleuven.be
Dedicated to Giorgio Picci on the occasion of his 65th birthday.
Summary. In this paper a new distance on the set of multivariate Gaussian linear stochastic pro-
cesses is proposed based on the notion of mutual information. The deﬁnition of the distance is
inspired by various properties of the mutual information of past and future of a stochastic pro-
cess. For two special classes of stochastic processes this mutual information distance is shown
to be equal to a cepstral distance. For general multivariate processes, the behavior of the mu-
tual information distance is similar to the behavior of an ad hoc deﬁned multivariate cepstral
distance.
1
Introduction
This paper is concerned with realization and identiﬁcation of linear stochastic proces-
ses, topics that are central in Giorgio Picci’s research interests. With his work in the
last decennia he is one of the great inspirators for the development of subspace identi-
ﬁcation for stochastic processes, to which he also contributed several papers [24, 27].
Within our research group quite some work was done in subspace identiﬁcation in the
nineties [33,34]. Through this way, Giorgio, we would like to thank you for the count-
less interesting insights you shared with us and other researchers, but especially for
your great friendship. Ad multos annos!
⋆Research supported by Research Council KUL: GOA AMBioRICS, CoE EF/05/006 Opti-
mization in Engineering (OPTEC), several PhD/postdoc & fellow grants; Flemish Govern-
ment: FWO: PhD/postdoc grants, projects, G.0407.02 (support vector machines), G.0197.02
(power islands), G.0141.03 (Identiﬁcation and cryptography), G.0491.03 (control for intensive
care glycemia), G.0120.03 (QIT), G.0452.04 (new quantum algorithms), G.0499.04 (Statis-
tics), G.0211.05 (Nonlinear), G.0226.06 (cooperative systems and optimization), G.0321.06
(Tensors), G.0302.07 (SVM/Kernel), research communities (ICCoS, ANMMM, MLDM);
IWT: PhD Grants, McKnow-E, Eureka-Flite2; Belgian Federal Science Policy Ofﬁce: IUAP
P6/04 (DYSCO, Dynamical systems, control and optimization, 2007-2011) ; EU: ERNSI.
⋆⋆Jeroen Boets is a research assistant with the Institute for the Promotion of Innovation through
Science and Technology in Flanders (IWT-Vlaanderen) at the K.U.Leuven, Belgium. Dr. Ka-
trien De Cock is a postdoctoral researcher at the K.U.Leuven, Belgium. Prof. Dr. Bart De
Moor is a full professor at the K.U.Leuven, Belgium.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 15–33, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

16
J. Boets, K. De Cock, and B. De Moor
In some of our recent work [8, 9] we have established a nice framework with in-
teresting relations between notions from three different disciplines: system theory, in-
formation theory and signal processing. These relations are illustrated in a schematic
way in Figure 1. The processes considered in the framework are scalar Gaussian linear
time-invariant (LTI) stochastic processes. Centrally located in Figure 1 are the principal
angles and their statistical counterparts, the canonical correlations. These notions will
be explained in Section 3. Through a ﬁrst link in the ﬁgure, expressions are obtained for
the mutual information of past and future of a process as a function of its model param-
eters, by computing the canonical correlations between past and future of the process.
Secondly, the notion of subspace angles between two stochastic processes allows to ﬁnd
new expressions for an existing cepstral distance as a function of the model description
of the processes. And ﬁnally, the deﬁnition of a distance between scalar stochastic pro-
cesses based on mutual information was proven to result in exactly this same cepstral
distance.
subspace angles between
stochastic processes
mutual information distance
canonical correlations
between past and future
INFORMATION
THEORY
mutual information
SYSTEM THEORY
linear stochastic
processes
SIGNAL
PROCESSING
cepstral distance
GEOMETRY
principal angles
between subspaces
STATISTICS
canonical correlation
analysis
Fig. 1. A schematic representation of the relations between system theory, information theory
and signal processing for scalar stochastic processes

A Mutual Information Based Distance for Multivariate Gaussian Processes
17
In this paper we wish to give a start to the extension of the framework in Figure 1
to multivariate processes. We mainly focus on one aspect of the ﬁgure, namely the
mutual information distance. More speciﬁcally, we deﬁne in this paper a new mutual
information based distance on the set of multivariate Gaussian LTI stochastic processes.
The idea of deﬁning a distance for this kind of processes is not new. Many distances
have been considered in the past, both for scalar and multivariate processes. Speciﬁcally
for scalar processes a lot of distances are deﬁned directly on the basis of the power
spectrum, the log-power spectrum or the power cepstrum of the processes [3,13,14,18].
A difﬁculty with these distances is that some of them can not be generalized in a trivial
manner to multivariate processes. Cepstral distances for instance in their deﬁnition
involve some deﬁnition of the logarithm of the power spectrum of the processes.
Several of the distances deﬁned for both scalar and multivariate stochastic processes
are based on information-theoretic measures. By considering a stochastic process as
an inﬁnite-dimensional random variable, one can deﬁne e.g. the (asymptotic) Kullback-
Leibler (K-L) divergence, Chernoff divergence and Bhattacharyya divergence of two
processes [22, 25, 29, 30, 31, 32]. Often, the processes are assumed to be Gaussian, in
which case computationally tractable formulas can be derived.
Mutual information is an information-theoretic measure too. However, it is not ap-
plicable in the same sense as the above measures. The difference is that the mutual
information of two random variables does not measure the similarity (or dissimilarity)
of their probability densities. Instead it is a measure for the dependence of two random
variables. Since the goal in this paper is to achieve a distance on the set of stochastic
processes (without assuming information on their mutual dependencies), several inter-
mediate steps must be taken. These steps are explained in the paper and are inspired by
previous work in [6,8,9] (see Figure 1).
Distances between stochastic processes or time series have been used in many dif-
ferent areas. Among the most common are speech recognition [3, 13, 14], biomedical
applications [2,12,23] and video processing [4,11]. The distances are typically applied
in a clustering or classiﬁcation context.
The paper is organized as follows. In Section 2 we describe the model class we
work with: Gaussian LTI stochastic dynamical models. Section 3 recalls the notions of
principal angles between two subspaces, canonical correlations and mutual information
of two random variables, and applies these notions in the context of stochastic proces-
ses. In Section 4 a new distance between multivariate Gaussian processes is proposed
based on the notion of mutual information, and its properties are investigated. Section 5
shows several additional relations that hold in the case of scalar processes. In Section 6
we investigate whether the newly deﬁned distance admits a cepstral nature by deﬁning
an ad hoc power cepstrum and cepstral distance for multivariate stochastic processes.
Section 7 states the conclusions of the paper and some remaining open problems.
2
Model Class
In this paper we consider stochastic processes y = {y(k)}k∈Z whose ﬁrst and second
order statistics can be described by the following state space equations:

18
J. Boets, K. De Cock, and B. De Moor
 x(k + 1) = Ax(k) + Bu(k) ,
y(k) = Cx(k) + Du(k) ,
(1)
E {u(k)} = 0 , E

u(k)u⊤(l)
	
= Ipδkl .
(2)
with Ip the identity matrix of dimension p and δkl the Kronecker delta, being 1 for k = l
and 0 otherwise. The variable y(k) ∈Rp is the value of the process at time k and is
called the output of the model (1)-(2). The state process {x(k)}k∈Z ∈Rn is assumed
to be stationary, which implies that A is a stable matrix (all of its eigenvalues lie strictly
inside the unit circle). The unobserved input process {u(k)}k∈Z ∈Rp is a stationary
and ergodic (normalized) white noise process. Both x and u are auxiliary processes
used to describe the process y in this representation. The matrix D ∈Rp×p is assumed
to be of full rank. We assume throughout this paper that u and consequently also y is a
Gaussian process. This means that the process y is fully described by (1)-(2).
The inﬁnite controllability and observability matrix of the model (1) are deﬁned as:
C =

 B AB A2B · · ·
,
Γ =

C⊤(CA)⊤(CA2)⊤· · ·
⊤,
respectively. The model (1) is assumed to be minimal, meaning that C and Γ are of full
rank n. The Gramians corresponding to C and Γ are the unique and positive deﬁnite
solution of the controllability and observability Lyapunov equation, respectively:
CC⊤= P = APA⊤+ BB⊤,
Γ ⊤Γ = Q = A⊤QA + C⊤C .
(3)
The controllability Gramian P is also equal to the state covariance matrix, i.e. P =
E

x(k)x⊤(k)
	
.
The model (1) is further assumed to be minimum-phase, meaning that its zeros
(eigenvalues of A −BD−1C) lie strictly inside the unit circle. The inverse model
can then be derived from (1) by rewriting it as

x(k + 1) = (A −BD−1C)x(k) + BD−1y(k) ,
u(k) =
−D−1Cx(k) +
D−1y(k) ,
(4)
and is denoted with a subscript (·)z:
(Az, Bz, Cz, Dz) = (A −BD−1C, BD−1, −D−1C, D−1).
Analogously, the controllability and observability matrices and Gramians of the inverse
model (4) are denoted by Cz, Γz, Pz and Qz. The matrix Qz, for instance, is the solution
of
Qz = (A −BD−1C)⊤Qz(A −BD−1C) + C⊤D−⊤D−1C .
(5)
Along with the descriptions (1) and (4), a transfer function can be deﬁned from u to
y and from y to u, respectively:
h(z) = C(zI −A)−1B + D ,
(6)
h−1(z) = −D−1C(zI −(A −BD−1C))−1BD−1 + D−1 .

A Mutual Information Based Distance for Multivariate Gaussian Processes
19
Modulo a similarity transformation of the state space model (A, B, C, D) into (T −1AT,
T −1B, CT, D) with nonsingular T , there is a one-to-one correspondence between the
descriptions (1) and (6). From each of both descriptions, augmented with (2), the sec-
ond order statistics of the process y can be derived, i.e. its autocovariance sequence
Λ(s) = E

y(k)y⊤(k −s)
	
=
⎧
⎪
⎨
⎪
⎩
CPC⊤+ DD⊤
s = 0 ,
CAs−1G
s > 0 ,
G⊤(A⊤)|s|−1C⊤
s < 0 ,
(7)
with G = E

x(k + 1)y⊤(k)
	
= APC⊤+ BD⊤, or equivalently its spectral density
function
Φ(z) =
+∞

s=−∞
Λ(s)z−s = h(z)h⊤(z−1) .
(8)
As stated before, Gaussian processes (which we assume) are fully described by their
ﬁrst and second order statistical properties. Therefore a zero-mean process {y(k)}k∈Z
is also fully described by (7) or (8). From equation (8) it can thus be seen that h(z) is
not uniquely deﬁned for the process y since the transfer functions h(z) and h(z)V with
V a unitary p × p matrix correspond to the same spectral density function Φ(z). This is
the only non-uniqueness in h(z) under the given assumptions and must be kept in mind
while we denote a process in this paper by one of its foursomes (A, B, C, D) or one of
its transfer functions h(z).
We also deﬁne doubly inﬁnite block Hankel matrices of data:
Y =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
...
...
...
...
y(−2) y(−1) y(0) · · ·
y(−1) y(0) y(1) · · ·
y(0)
y(1) y(2) · · ·
y(1)
y(2) y(3) · · ·
...
...
...
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
=
Yp
Yf

,
(9)
corresponding to the processes y = {y(k)}k∈Z, yp = {y(−k)}k∈N0 and yf
=
{y(k)}k∈N, where the subscript p stands for ‘past’ and f for ‘future’. The block Hankel
matrices U, Up and Uf are analogously deﬁned for the processes u, up and uf.
3
Principal Angles, Canonical Correlations and Mutual
Information
In this section the deﬁnitions of principal angles between two subspaces, canonical
correlations of two random variables and their mutual information are recalled in Sec-
tions 3.1, 3.2 and 3.3 respectively. In Section 3.4 these notions are applied in the context
of the stochastic processes deﬁned in the previous section. Attention is drawn in partic-
ular to the mutual information of past and future of the output process y.

20
J. Boets, K. De Cock, and B. De Moor
3.1
Principal Angles and Directions
The principal angles between two subspaces [21] are a generalization of the angle be-
tween two vectors. Suppose we are given two linear subspaces S1 and S2 of the ambient
vector space Rn of dimension d1 < n and d2 < n, respectively. A natural extension
of the one-dimensional case is to choose a unit vector u1 from S1 and a unit vector v1
from S2 such that the angle between u1 and v1 is minimized. The vectors u1 and v1 so
obtained, are called the ﬁrst principal directions and the angle between them is the ﬁrst
principal angle θ1. Next, choose a unit vector u2 ∈S1 orthogonal to u1 and v2 ∈S2
orthogonal to v1 such that the angle θ2 between them is minimized. This is the second
principal angle and u2 and v2 are the corresponding principal directions. Continue in
this way until min(d1, d2) angles and corresponding principal vectors have been found.
This informal description is now formalized.
Deﬁnition 1. Principal angles and directions
The principal angles 0 ≤θ1 ≤θ2 ≤. . . θmin(d1,d2) ≤π/2 between the subspaces S1
and S2 of the ambient space Rn of dimension d1 and d2, respectively, and the corre-
sponding principal directions ui ∈S1 and vi ∈S2 are deﬁned recursively as
cos θ1 = max
u∈S1
v∈S2
u⊤v = u⊤
1 v1 ,
cos θk = max
u∈S1
v∈S2
u⊤v = u⊤
k vk , for k = 2, . . . , min(d1, d2) ,
subject to ∥u∥= ∥v∥= 1 and for k > 1: u⊤ui = 0 and v⊤vi = 0, where i =
1, . . . , k −1.
Let A ∈Rp×n be of rank d1 and B ∈Rq×n of rank d2. Then, the ordered set of
min(d1, d2) principal angles between the row spaces of A and B is denoted by

θ1, θ2, . . . , θmin(d1,d2)

= [A ∢B] .
In case A and B are of full row rank with p ≤q, the squared cosines of the principal
angles between row(A) and row(B) are equal to the eigenvalues of (AA⊤)−1AB⊤
(BB⊤)−1BA⊤:
cos2 [A ∢B] = λ

(AA⊤)−1AB⊤(BB⊤)−1BA⊤
.
(10)
3.2
Canonical Correlations
In canonical correlation analysis [16] the interrelation of two sets of random variables
is studied. It is the statistical interpretation of the geometric tool of principal angles
between and principal directions in linear subspaces. The aim is to ﬁnd two bases of
random variables, one in each set, that are internally uncorrelated but that have maximal
correlations between the two sets. The resulting basis variables are called the canonical
variates and the correlation coefﬁcients between the canonical variates are the canonical
correlations.

A Mutual Information Based Distance for Multivariate Gaussian Processes
21
Let V be a zero-mean p-component and W a zero-mean q-component real random
variable with joint covariance matrix Q = E

V
W
 
V ⊤W ⊤
=

Qv Qvw
Qwv Qw

. In
case Qv and Qw are full rank matrices, and p ≤q, the p squared canonical correlations
of V and W, which we denote by cc2(V, W), can be obtained as the eigenvalues of
Q−1
v QvwQ−1
w Qwv:
cc2(V, W) = λ(Q−1
v QvwQ−1
w Qwv) .
(11)
3.3
Mutual Information
Let V be a zero-mean p-component and W a zero-mean q-component random variable.
If V and W are mutually dependent, then observing W reduces the uncertainty (or
entropy) in V . Otherwise formulated, we gain information about V by observing W.
Thus, the variable W must contain information about V . For the same reason V must
also contain information about W. Both amounts of information are equal and are
quantiﬁed as the mutual information of V and W, denoted by I(V ; W).
Deﬁnition 2. The mutual information of two continuous random variables [7]
Let V and W be random variables with joint probability density function f(v, w) and
marginal densities fV (v) and fW (w), respectively. Then, the mutual information of V
and W is deﬁned as
I(V ; W) =

f(v, w) log
f(v, w)
fV (v)fW (w) dv dw ,
if the integral exists.
In case of two zero-mean jointly Gaussian random variables and denoting the covari-
ance matrix of

V
W

by Q =

Qv Qvw
Qwv Qw

, this expression can be rewritten as
I(V ; W) = −1
2 log
det Q
det Qv det Qw
,
under the assumption that Qv and Qw are of full rank.
In this case I(V ; W) is
also related to the canonical correlations of V and W, here denoted by σk (k =
1, . . . , min(p, q)), as can be derived using equation (11):
I(V ; W) = −1
2 log
min(p,q)

k=1
(1 −σ2
k) .
(12)
3.4
Application to Stochastic Processes
In this section we apply the notions deﬁned in the previous sections to the stochas-
tic processes yp, yf, up and uf. A stochastic process, e.g. {y(k)}k∈Z, can be seen as
an inﬁnite-dimensional random variable consisting of the (ordered) concatenation of the

22
J. Boets, K. De Cock, and B. De Moor
random variables ..., y(−2), y(−1), y(0), y(1), ...We can thus associate with the
process y the random variable
Y =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
...
y(−2)
y(−1)
y(0)
y(1)
...
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
=
Yp
Yf

,
Yp and Yf being associated with the processes yp and yf, and analogously U, Up and
Uf for the processes u, up and uf. This way we can compute the canonical correlations
and the mutual information for any pair of these processes.
Canonical Correlations
Since we are dealing with stationary and ergodic zero-mean processes, it is readily seen
from equations (10) and (11) that the canonical correlations between any two of the pro-
cesses u, up, uf, y, yp and yf are equal to the cosines of the principal angles between
the row spaces of the corresponding block Hankel matrices deﬁned in (9), e.g.:
cc(Uf, Yf) = cos ([Uf ∢Yf]) .
(13)
In [8, Chap. 3] the canonical correlations of each pair of these processes were computed.
Formulas were derived for the canonical correlations between the past and future output
process:
cc2(Yp, Yf) = λ

P(Q−1
z
+ P)−1
, 0, 0, . . . ,
as well as for the canonical correlations between uf and yf:
cc2(Uf, Yf) = λ

(In + QzP)−1
, 1, 1, . . . ,
where P and Qz each follow from a Lyapunov equation (see (3)-(5)). We denote the
non-trivial correlations of yp and yf by ρk, and those of uf and yf by τk, as follows:
ρ2
k = λ

P(Q−1
z
+ P)−1
(k = 1, . . . , n) ,
τ 2
k = λ

(In + QzP)−1
(k = 1, . . . , n) .
(14)
It can be shown that ρ2
k + τ 2
k = 1, for k = 1, . . . , n. These results together with the
canonical correlations of the other pairs of processes are summarized in Table 1.
Mutual Information of Past and Future of a Process
Using the relation (12) for Gaussian processes, we can compute from Table 1 the mu-
tual information of each pair of processes. A pair of processes that has at least one
canonical correlation equal to 1 does not have a ﬁnite amount of mutual information.

A Mutual Information Based Distance for Multivariate Gaussian Processes
23
Table 1. Overview of the canonical correlations of each pair of processes, where k goes from 1
to n
Up
Yp
Uf
Yf
Up
1, 1, . . .
1, 1, . . .
0, 0, . . .
ρk, 0, 0, . . .
Yp
1, 1, . . .
1, 1, . . .
0, 0, . . .
ρk, 0, 0, . . .
Uf
0, 0, . . .
0, 0, . . .
1, 1, . . .

1 −ρ2
k, 1, 1, . . .
Yf
ρk, 0, 0, . . .
ρk, 0, 0, . . .

1 −ρ2
k, 1, 1, . . .
1, 1, . . .
Looking at relation (13) between canonical correlations and principal angles we can
say that these processes intersect, since they have a principal angle equal to zero. Con-
versely, processes that are orthogonal to each other (all canonical correlations equal to
0 or all principal angles equal to π/2) have mutual information equal to zero. This
is for instance the case for up and uf, past and future of the white noise process u.
However, processing this white noise u through the ﬁlter h(z) (in general) introduces a
time correlation in the resulting process y, which appears as a certain amount of mutual
information between its past yp and future yf, denoted interchangeably by Ipf, Ipf{y}
or Ipf{h(z)}:
Ipf = I(yp; yf) = −1
2 log
n

k=1
(1 −ρ2
k) = −1
2 log
n

k=1
τ 2
k = 1
2 log det (In + QzP) .
(15)
Note that ρk, τk (k = 1, . . . , n) and consequently also Ipf are unique for a given sto-
chastic process, since P and Qz do not change when h(z) is right-multiplied by a
unitary matrix, and a similarity transformation of the state space model does not al-
ter the eigenvalues of the product QzP. So if we write Ipf {h(z)} or ρk {h(z)}, this
must not be understood as a characteristic of the transfer function h(z) but rather as a
characteristic of the process y with spectral density Φ(z) = h(z)h⊤(z−1).
Properties of Ipf
The mutual information Ipf of past and future of a stochastic process y is the amount
of information that the past provides about the future and vice versa. Through (15)
it is closely connected to the canonical correlations of yp and yf. The problem of
characterizing this dependence of past and future of a stationary process has received a
great deal of attention because of its implications for the prediction theory of Gaussian
processes (see [17, 19, 20]). Inspired by the use of canonical correlation analysis in
stochastic realization theory [1], a stochastic model reduction technique based on the
mutual information of the past and the future has been proposed by Desai and Pal [10],
which is also used in stochastic subspace identiﬁcation [27, 34]. Li and Xie used the
past-future mutual information for model selection and order determination problems
in [26]. We now state some of the properties of Ipf.

24
J. Boets, K. De Cock, and B. De Moor
(a) Ipf = 0 ⇔h(z) = D (see (1))
Since y is Gaussian, Ipf = 0 is equivalent with yp and yf being uncorrelated, thus
Λ(s) = 0p for s ̸= 0. From stochastic realization theory then follows that h(z) has
order zero.
(b) Ipf ∈[0, +∞)
This follows from relation (15) and the fact that ρk ∈[0, 1). Indeed, in [15] it is
shown that the number of unit canonical correlations of yp and yf is equal to the
number of zeros of h(z) on the unit circle. Since h(z) is assumed to be minimum-
phase (see Section 2), this number is zero.
(c) Ipf (strictly) increases with each increase of a canonical correlation ρk (k =
1, . . . , n).
This follows immediately from relation (15) and property (b).
(d) Ipf{h(z)} = Ipf{Th(z)} for a nonsingular constant matrix T ∈Rp×p.
This follows from the deﬁnition of canonical correlations or principal angles, since
left-multiplying the output variables y(k) (k ∈Z) with T does not change the row
spaces of Yp and Yf. Consequently, the canonical correlations ρk and the mutual
information Ipf do not change.
(e) Ipf{h(z)} = Ipf{h−⊤(z)}
Equation (14) shows that the past-future canonical correlations ρk (k = 1, . . . , n)
only depend on the eigenvalues of the product matrix QzP. Noting that the state
space description of the transpose of the inverse model is given by h−⊤(z) =
(A⊤
z , C⊤
z , B⊤
z , D⊤
z ), it can be seen from (3) that the controllability Gramian of
h−⊤(z) is given by Qz, while the observability Gramian of its inverse model
h⊤(z) = (A⊤, C⊤, B⊤, D⊤) is equal to P. Consequently, the canonical correla-
tions ρk and the mutual information Ipf are equal for the transfer functions h(z) and
h−⊤(z). This invariance property does not, in general, hold for h(z) and h−1(z)
since the eigenvalues of QzP are usually not equal to those of QPz.
(f) For Φ(z) =
 Φ1(z) 0p1×p2
0p2×p1
Φ2(z)

, it holds that Ipf{y} = Ipf{y1} + Ipf{y2}.
In this case the p1-variate process y1 and the p2-variate process y2, constituting
the process y, are completely uncorrelated. Therefore, the canonical correlations
of yp and yf are on the one hand the canonical correlations between y1p and y1f ,
and on the other hand the canonical correlations between y2p and y2f : ρk{y} (k =
1, . . . , n1+n2) is the union of ρk{y1} (k = 1, . . . , n1) and ρk{y2} (k = 1, . . . , n2),
with n1 and n2 the orders of the processes y1 and y2. The result then follows from
relation (15).
Properties (a)-(c) indicate that Ipf measures the amount of correlation that exists be-
tween yp and yf, being zero for a white noise process and increasing with each increase
of a correlation ρk between yp and yf. This suggests that Ipf can be used as a measure
for the amount of dynamics in the process y where dynamics are deﬁned in terms of the

A Mutual Information Based Distance for Multivariate Gaussian Processes
25
correlation or the dependence that exists between all future values and all past values of
the process at any time instant.
4
A Distance Between Multivariate Gaussian Processes
In this section we deﬁne a new distance between multivariate Gaussian processes based
on the notion of mutual information. In Section 4.1 the distance is deﬁned and its metric
properties are investigated, while in Section 4.2 we show a way to compute the distance.
4.1
Deﬁnition and Metric Properties
We propose as a new distance on the set of multivariate Gaussian processes: the mutual
information distance, denoted by dmi(y1, y2).
Deﬁnition 3. The mutual information distance between two Gaussian processes
The mutual information distance between two Gaussian linear stochastic processes y1
and y2 with transfer function descriptions h1(z) and h2(z) is denoted by dmi(y1, y2)
and is deﬁned as
d2
mi(y1, y2) = Ipf {h12(z)} ,
with h12(z) =
h−1
1 (z)h2(z)
0p
0p
h−1
2 (z)h1(z)

.
The ﬁrst thing to note is that the mutual information distance dmi(y1, y2) is a property
of the processes y1 and y2, and not of the particular transfer functions h1(z) and h2(z).
Indeed, substituting {h1(z), h2(z)} by the equivalent {h1(z)V1, h2(z)V2} with V1, V2
constant unitary matrices (see (8)), corresponds to left- and right-multiplying h12(z)
by a constant unitary matrix. This has no inﬂuence on Ipf {h12} (see property (d) in
Section 3.4).
Following the discussion at the end of Section 3.4, dmi(y1, y2) can be interpreted as
a measure for the amount of dynamics in the process y12 associated with the transfer
function h12(z). It is clear that dmi{y1, y1} = 0 since h12(z) is in that case a constant
matrix and y12 is consequently white noise. This also clariﬁes why the ‘ratio’ of h1(z)
and h2(z) is found in h12(z), instead of for instance the difference. From Deﬁnition 3 it
is also immediately seen that dmi(y1, y2) = dmi(g(z)y1, g(z)y2) for arbitrary transfer
functions g(z) satisfying the conditions stated in Section 2 (e.g. being square, stable
and minimum-phase). Filtering the processes y1 and y2 by a common ﬁlter g(z) does
not change their mutual information distance.
The following properties hold for the mutual information distance:
1. dmi(y1, y2) ≥0
2. dmi(y1, y2) = 0 ⇔h2(z) = h1(z)T with T a constant square nonsingular matrix.
This follows from property (a) in Section 3.4.
3. dmi(y1, y2) = dmi(y2, y1) is symmetric.
This follows immediately from Deﬁnition 3.

26
J. Boets, K. De Cock, and B. De Moor
Examples have shown that dmi(y1, y2) does not in general satisfy the triangle
inequality1. The distance thus satisﬁes only two of the four properties of a true metric
(non-negativity and symmetry). However, if we deﬁne a set of equivalence classes of
stochastic processes, where two processes with transfer functions h1(z) and h2(z) are
equivalent if and only if there exists a constant square nonsingular matrix T such that
h2(z) = h1(z)T , then the mutual information distance dmi(y1, y2) deﬁned on this set
of equivalence classes, satisﬁes all metric properties but the triangle inequality. It is
then called a semimetric.
4.2
Computation
From property (f) in Section 3.4 it follows that
d2
mi(y1, y2) = Ipf

h−1
1 (z)h2(z)
	
+ Ipf

h−1
2 (z)h1(z)
	
.
(16)
Using this property we now show a way to compute dmi(y1, y2) making use of the
state space descriptions of h1(z) and h2(z) of orders n1 and n2 respectively. Equa-
tions (15) and (16) show that we need to compute the controllability and observability
Gramians of both h−1
1 (z)h2(z) and h−1
2 (z)h1(z). This can be easily done by solving
the Lyapunov equations (3) from the state space descriptions of both transfer functions.
As an example we give a possible state space description of h−1
1 (z)h2(z) denoted by
(A12, B12, C12, D12):
A12 =

A2
0n2×n1
Bz1C2
Az1

, B12 =

B2
Bz1D2

, C12 = 
Dz1C2
Cz1

, D12 = Dz1D2 ,
with (Az1, Bz1, Cz1, Dz1) = (A1 −B1D−1
1 C1, B1D−1
1 , −D−1
1 C1, D−1
1 ). The pro-
cedure concerning h−1
2 (z)h1(z) is analogous. Afterwards it remains to compute (16)
using (15) and (3).
5
Special Case of Scalar Processes
The only relation in Figure 1 that holds for both scalar and multivariate Gaussian
processes is the one between the mutual information distance and the past-future ca-
nonical correlations, which can be seen in (15).
In the case of scalar processes
y1 and y2 it follows from property (e) in Section 3.4 that (16) can be rewritten as
d2
mi(y1, y2) = 2Ipf

h1(z)
h2(z)

= 2Ipf

h2(z)
h1(z)

. In this case the mutual information
distance is also related to so-called subspace angles between stochastic processes and
to a cepstral distance, as was mentioned in the introduction (see Figure 1). We will
shortly recall these two results in Sections 5.1 and 5.2. Based on these relations, sev-
eral additional expressions for dmi(y1, y2) can be derived for the scalar case. For more
details on this we refer to [8, Chap. 6].
1 In the case of scalar processes or processes with diagonal spectral density function Φ(z),
however, it can be shown that the triangle inequality is satisﬁed (see Sections 5.2 and 6.1
respectively).

A Mutual Information Based Distance for Multivariate Gaussian Processes
27
5.1
Relation with Subspace Angles Between Scalar Stochastic Processes
Consider the situation in Figure 2 where the single-input single-output models h1(z)
of order n1 and h2(z) of order n2 are driven by a common white noise source
{u(k)}k∈Z ∈R. It can be shown that in this case only n1 + n2 canonical correla-
tions between the future y1f and y2f of the processes y1 and y2 can be different from 1.
If we denote these correlations by νk (k = 1, . . . , n1 + n2), then the following relation
was proven in [8]:
d2
mi(y1, y2) = −log
n1+n2

k=1
ν2
k = −log
n1+n2

k=1
cos2 ψk ,
(17)
where the angles ψk (k = 1, . . . , n1 + n2) are the n1 + n2 largest principal angles
between the row spaces of the block Hankel matrices Y1f and Y2f . They are called
the subspace angles between h1(z) and h2(z), denoted by [h1(z) ∢h2(z)]. They can
be expressed as the principal angles between subspaces immediately derived from the
models:
[h1(z) ∢h2(z)] =

C(1)
O(2)⊤
z

∢

O(1)⊤
z
C(2)

.
(18)
u
h1(z)
h2(z)
y1
y2
Fig. 2. Setup for the deﬁnition of subspace angles between two scalar processes
5.2
Relation with a Cepstral Distance
The power cepstrum of a scalar process y is deﬁned as the inverse Fourier transform of
the logarithm of the power spectrum of y:
log Φ(ejθ) =
+∞

k=−∞
c(k)e−jkθ ,
(19)
where c(k) is the kth cepstral coefﬁcient of y. The sequence {c(k)}k∈Z contains the
same information as Φ(z) and thus also fully characterizes the zero-mean Gaussian
process y. The sequence is real and even, i.e. c(k) = c(−k), and can be expressed in
terms of the model parameters:
c(k) =
⎧
⎪
⎨
⎪
⎩
log D2
k = 0 ,
n

i=1
α|k|
i
|k| −
n

i=1
β|k|
i
|k|
k ̸= 0 ,
(20)

28
J. Boets, K. De Cock, and B. De Moor
where the poles of h(z) are denoted by α1, . . . , αn and the zeros by β1, . . . , βn. Based
on the cepstral coefﬁcients, a weighted cepstral distance was deﬁned in [28]:
d2
cep(y1, y2) =
+∞

k=0
k(c1(k) −c2(k))2 ,
(21)
with c1 and c2 the cepstra of the processes y1 and y2 and ‘cep’ referring to ‘cepstral’.
Based on (18), this distance dcep was proven in [8, Chap. 6] (and differently also in [20])
to be equal to the mutual information distance dmi, i.e.:
dmi(y1, y2) = dcep(y1, y2) .
(22)
This obviously proves that dmi for scalar processes satisﬁes the triangle inequality. Re-
ferring to the discussion in Section 4.1 we can thus say that dmi is a true metric on the
set of equivalence classes of scalar stochastic processes, where two processes y1 and y2
are equivalent if and only if h2(z) = ah1(z) for a non-zero real number a.
6
The Cepstral Nature of the Mutual Information Distance
The equality (22) of dmi and dcep was formulated for scalar stochastic processes. In
the case of multivariate processes, one would ﬁrst need a deﬁnition of the power cep-
strum of a multivariate process. No such deﬁnition is known to the authors of this paper.
Therefore, we introduce in Section 6.1 a multivariate power cepstrum and a correspond-
ing weighted cepstral distance, denoted by dcep.
Even with this new deﬁnition, the relation (22) does not hold for general multivariate
processes. However, it turnes out experimentally that dmi has a cepstral character. This
is explained in Section 6.2.
6.1
Multivariate Power Cepstrum and Cepstral Distance
No deﬁnition of the power cepstrum of a multivariate process y is known to the authors
of this paper. Therefore, in analogy with (19), we propose to deﬁne the power cepstrum
of a multivariate process y as the inverse Fourier transform of the matrix logarithm of
the power spectrum of y:
log Φ(ejθ) =
+∞

k=−∞
c(k)e−jkθ ,
(23)
where c(k) ∈Rp×p is the kth cepstral coefﬁcient matrix of y. The sequence {c(k)}k∈Z
is real and even, and again contains the same information as Φ(z) and thus also fully
characterizes the zero-mean Gaussian process y. However, no analytical expressions as
in (20) are known to us for these multivariate cepstral coefﬁcients, although in principle
they could be calculated from the state space description (8) of Φ(z) by expanding the
Laurent series of log Φ(z) around the origin.

A Mutual Information Based Distance for Multivariate Gaussian Processes
29
We now deﬁne in analogy with (21) a multivariate weighted cepstral distance as
d2
cep(y1, y2) =
+∞

k=0
k∥c1(k) −c2(k)∥2
F ,
(24)
with c1 and c2 the cepstra of the multivariate processes y1 and y2, and ∥· ∥F the Frobe-
nius norm of a matrix. For scalar processes this distance coincides with the previ-
ously deﬁned distance (21). No relation with the mutual information distance as in (22)
for scalar processes holds for multivariate processes, except for diagonal Φ1(z), Φ2(z)
where it is easily shown that
d2
mi(y1, y2) =
p

i=1
d2
mi(y1,i, y2,i) =
p

i=1
d2
cep(y1,i, y2,i) = d2
cep(y1, y2) ,
with y1,i (i = 1, . . . , p) the uncorrelated scalar processes constituting y1, and analo-
gously for y2,i (i = 1, . . . , p). The ﬁrst equality follows from Deﬁnition 3 and property
(f) in Section 3.4. The second equality follows from relation (22) for scalar processes.
The distance (24) can be computed based on the model descriptions of the processes
y1 and y2. These allow to compute exact values of log Φ(ejθ) where θ varies over a
discretization of the interval [0, 2π]. After applying the inverse fast Fourier transform
(IFFT) to obtain estimates of the cepstral coefﬁcients, one can further approximate (24)
by replacing +∞in the formula by a ﬁnite L.
6.2
The Cepstral Nature of the Mutual Information Distance
For scalar processes, several simulation experiments were performed in [5] in order
to compare the behavior of the cepstral distance dcep, which is equal to dmi because
of (22), with the behavior of the H2 distance, denoted by dh2:
d2
h2(h1(z), h2(z)) = ∥h1(z) −h2(z)∥2
h2 = 1
2π
 2π
0
∥h1(ejθ) −h2(ejθ)∥2
Fdθ . (25)
In order to make dh2 a distance between processes instead of between transfer functions,
we agree to ﬁx the transfer function description of a stochastic process. We always
choose the D-matrix of a model (1) or (6) to be Dchol, the unique Cholesky factor of
DD⊤, which is invariant for a given stochastic process.
In this section we focus on two aspects that showed in the scalar case a difference in
behavior between the cepstral distance and the H2 distance:
1. The inﬂuence of poles of h1(z) and h2(z) approaching the unit circle.
2. The inﬂuence of poles of h2(z) approaching the unit circle (with ﬁxed zeros), com-
pared to the inﬂuence of zeros of h2(z) approaching the unit circle (with ﬁxed
poles). Poles and zeros of h1(z) are kept ﬁxed.
In order to understand why we choose these two experimental settings, one should
notice an important difference between dh2 in (25) and dcep in (21) and (24), namely the
presence of the logarithm of the power spectrum in the deﬁnition of the cepstrum (19)
and (23). For the scalar case this has the following consequences:

30
J. Boets, K. De Cock, and B. De Moor
1. High peaks in the spectrum of hi(z) (corresponding to poles close to the unit circle)
have a greater inﬂuence on dh2(h1, h2) than on dcep(h1, h2).
2. Deep valleys in the spectrum of hi(z) (corresponding to zeros close to the unit
circle) have a greater inﬂuence on dcep(h1, h2) than on dh2(h1, h2).
It can be shown that cepstral distances in the scalar case are equally dependent on the
poles and zeros of hi(z): the distance between two models is equal to the distance be-
tween the inverses of the two models. The distance dh2, on the other hand, is much less
sensitive to the depth of a valley than to the height of a peak in the spectrum of hi(z).
It turns out that, in the multivariate case, the mutual information distance dmi and the
cepstral distance dcep have several characteristics in common, whereas the H2 distance
dh2 behaves very differently:
1. The distance dh2(h1, h2) grows much faster than dcep(h1, h2) and dmi(h1, h2) as
the poles of h1(z) and h2(z) approach the unit circle. This means that dh2 is more
sensitive to high peaks in the spectrum of hi(z) than dcep and dmi. The distances
dcep and dmi evolve quite similarly to each other.
2. The distance dh2(h1, h2) grows much faster in case h2(z) has ﬁxed zeros but poles
approaching the unit circle, than in case h2(z) has ﬁxed poles but zeros approaching
the unit circle. For both the distances dcep(h1, h2) and dmi(h1, h2), on the other
hand, the evolution of the distance in case of poles approaching the unit circle is
very similar to the evolution in case of zeros approaching the unit circle. This
means that dh2 is much more sensitive to high peaks than to deep valleys in the
spectrum of hi(z), whereas dcep and dmi are more or less equally sensitive. The
distances dcep and dmi also evolved quite similarly to each other.
With these conclusions we do not claim that one of the distances is better than the
others. We only wish to point out some differences between them. On the basis of these
differences one can choose which distance to use in a speciﬁc application.
7
Conclusions and Open Problems
7.1
Conclusions
In this paper we deﬁned the mutual information distance on the set of multivariate Gaus-
sian linear stochastic processes, based on the notion of mutual information of past and
future of a stochastic process and inspired by the various properties of this notion. We
demonstrated how it can be computed from the state space description of the processes
and showed that it is a semimetric on a set of equivalence classes of stochastic processes.
For two special classes of stochastic processes, namely scalar processes and processes
with diagonal spectral density function, a link exists between the mutual information
distance and a previously deﬁned scalar cepstral distance.
The mutual information distance shows a behavior similar to an ad hoc deﬁned mul-
tivariate cepstral distance and dissimilar from the H2 distance: it does not inﬂate when
poles of the models are approaching the unit circle and it is more sensitive to differences
in zeros than the H2 distance.

A Mutual Information Based Distance for Multivariate Gaussian Processes
31
7.2
Open Problems
In this paper a possible extension for multivariate processes was considered of the the-
ory for scalar processes described in Section 5 and Figure 1. The proposed Deﬁnition 3
of a multivariate distance however only involves the notion of mutual information and
not the notions of subspace angles or cepstral distances between stochastic processes.
Thus there remain quite some challenges and issues to be investigated concerning a
comparable theory for multivariate stochastic processes.
Furthermore, it would be nice to have more rigorous evidence for the conclusions
drawn in Section 6.2.
Multivariate Power Cepstrum and Cepstral Distance
No deﬁnition of the power cepstrum of a multivariate process is known to the authors
of this paper. Therefore, we introduced an ad hoc deﬁnition (23) in Section 6.1. For
these cepstral coefﬁcients, however, no analytical expressions are known comparable to
e.g. (20) for the scalar coefﬁcients. This topic needs further investigation.
Based on the deﬁnition of a multivariate power cepstrum one can deﬁne distances
in the cepstral domain. In this paper one possible approach was considered in (24) in
analogy with (21). But this is clearly not the only possibility.
Subspace Angles Between Multivariate Stochastic Processes
The deﬁnition of subspace angles between scalar stochastic processes based on Fig-
ure 2 is not readily extendable to multivariate processes. The non-uniqueness of the
transfer function description of a multivariate process (see the discussion below (8))
also causes non-uniqueness in the deﬁnition of the subspace angles between two multi-
variate processes. Further investigation is necessary to ﬁnd a good way to circumvent
this problem.
Relations Between System Theory, Information Theory and Signal Processing
Looking at Figure 1 for scalar processes, it is very tempting to look for similar rela-
tions in the case of multivariate processes. The two previous topics described the lack
of a deﬁnition of subspace angles and cepstral distances between multivariate proces-
ses. A possible guideline in the search for these deﬁnitions could be the attempt to
establish a relation with the distance dmi similar to (17) and (22) for scalar stochastic
processes. Alternatively, the search for deﬁnitions of subspace angles and cepstral dis-
tances between multivariate processes could also be guided by the search for a direct
link between both, not necessarily through dmi.
References
1. H. Akaike. Markovian representation of stochastic processes by canonical variables. SIAM
Journal on Control, 13(1):162–173, 1975.
2. C. W. Anderson, E. A. Stolz, and S. Shamsunder.
Multivariate autoregressive models
for classiﬁcation of spontaneous electroencephalograﬁc signals during mental tasks. IEEE
Transactions on Biomedical Engineering, 45(3):277–286, March 1998.

32
J. Boets, K. De Cock, and B. De Moor
3. M. Basseville. Distance measures for signal processing and pattern recognition.
Signal
Processing, 18(4):349–369, December 1989.
4. A. Bissacco, A. Chiuso, Y. Ma, and S. Soatto. Recognition of human gaits. In Proceedings
of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR
01), volume II, pages 52–58, Kauai, Hawaii, December 2001.
5. J. Boets, K. De Cock, and B. De Moor. Distances between dynamical models for clustering
time series. In Proceedings of the 14th IFAC Symposium on System Identiﬁcation (SYSID
2006), pages 392–397, Newcastle, Australia, March 2006.
6. J. Boets, K. De Cock, M. Espinoza, and B. De Moor.
Clustering time series, subspace
identiﬁcation and cepstral distances. Communications in Information and Systems, 5(1):69–
96, 2005.
7. T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley Series in Telecom-
munications. Wiley, New York, 1991.
8. K. De Cock.
Principal Angles in System Theory, Information theory and Signal
Processing.
PhD thesis, K.U.Leuven, Leuven, Belgium, May 2002.
Available as
“ftp://ftp.esat.kuleuven.be/pub/SISTA/decock/reports/phd.ps.gz”.
9. K. De Cock and B. De Moor. Subspace angles between ARMA models. Systems & Control
Letters, 46(4):265–270, July 2002.
10. U. B. Desai, D. Pal, and R. D. Kirkpatrick. A realization approach to stochastic model
reduction. International Journal of Control, 42(4):821–838, 1985.
11. G. Doretto, A. Chiuso, Y. N. Wu, and S. Soatto. Dynamic textures. International Journal of
Computer Vision, 51(2):91–109, 2003.
12. W. Gersch. Nearest neighbor rule in classiﬁcation of stationary and nonstationary time series.
In D. F. Findley, editor, Applied Time Series Analysis II, pages 221–270. Academic Press,
New York, 1981.
13. R. M. Gray, A. Buzo, A. H. Gray, Jr., and Y. Matsuyama. Distortion measures for speech pro-
cessing. IEEE Transactions on Acoustics, Speech, and Signal Processing, ASSP–28(4):367–
376, August 1980.
14. A. H. Gray, Jr. and J. D. Markel. Distance measures for speech processing. IEEE Transac-
tions on Acoustics, Speech, and Signal Processing, ASSP–24(5):380–391, October 1976.
15. E. J. Hannan and D. S. Poskitt. Unit canonical correlations between future and past. The
Annals of Statistics, 16(2):784–790, June 1988.
16. H. Hotelling. Relations between two sets of variates. Biometrika, 28:321–372, 1936.
17. I. A. Ibragimov and Y. A. Rozanov. Gaussian Random Processes. Springer, New York,
1978.
18. F. Itakura and T. Umezaki. Distance measure for speech recognition based on the smoothed
group delay spectrum. In Proceedings of the IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP87), volume 3, pages 1257–1260, 1987.
19. N. P. Jewell and P. Bloomﬁeld. Canonical correlations of past and future for time series:
deﬁnitions and theory. The Annals of Statistics, 11(3):837–847, 1983.
20. N. P. Jewell, P. Bloomﬁeld, and F. C. Bartmann. Canonical correlations of past and future
for time series: bounds and computation. The Annals of Statistics, 11(3):848–855, 1983.
21. C. Jordan. Essai sur la g´eom´etrie `a n dimensions. Bulletin de la Soci´et´e Math´ematique,
3:103–174, 1875.
22. Y. Kakizawa, R. H. Shumway, and M. Taniguchi. Discrimination and clustering for multi-
variate time series. Journal of the American Statistical Association, 93:328–340, 1998.
23. K. Kalpakis, D. Gada, and V. Puttagunta.
Distance measures for effective clustering of
ARIMA time-series. In Proceedings of the 2001 IEEE International Conference on Data
Mining (ICDM’01), pages 273–280, San Jose, CA, November-December 2001.
24. T. Katayama and G. Picci. Realization of stochastic systems with exogenous inputs and
subspace identiﬁcation methods. Automatica, 35(10):1635–1652, 1999.

A Mutual Information Based Distance for Multivariate Gaussian Processes
33
25. D. Kazakos and P. Papantoni-Kazakos. Spectral distance measures between Gaussian pro-
cesses. IEEE Transactions on Automatic Control, 25(5):950–959, 1980.
26. L. Li and Z. Xie. Model selection and order determination for time series by information
between the past and the future. Journal of time series analysis, 17(1):65–84, 1996.
27. A. Lindquist and G. Picci. Canonical correlation analysis, approximate covariance extension,
and identiﬁcation of stationary time series. Automatica, 32(5):709–733, 1996.
28. R. J. Martin. A metric for ARMA processes. IEEE Transactions on Signal Processing,
48(4):1164–1170, April 2000.
29. M. S. Pinsker. Information and Information Stability of Random Variables and Processes.
Holden–Day, San Francisco, 1964. Originally published in Russian in 1960.
30. F. C. Schweppe. On the Bhattacharyya distance and the divergence between Gaussian pro-
cesses. Information and Control, 11(4):373–395, 1967.
31. F. C. Schweppe. State space evaluation of the Bhattacharyya distance between two Gaussian
processes. Information and Control, 11(3):352–372, 1967.
32. R. H. Shumway and A. N. Unger. Linear discriminant functions for stationary time series.
Journal of the American Statistical Association, 69:948–956, December 1974.
33. P. Van Overschee and B. De Moor. Subspace algorithms for the stochastic identiﬁcation
problem. Automatica, 29:649–660, 1993.
34. P. Van Overschee and B. De Moor. Subspace Identiﬁcation for Linear Systems: Theory –
Implementation – Applications. Kluwer Academic Publishers, Boston, 1996.

Differential Forms and Dynamical Systems
Christopher I. Byrnes
Electrical and Systems Engineering, Washington University in St. Louis
chrisbyrnes@wustl.edu
Summary. One of the modern geometric views of dynamical systems is as vector ﬁelds on a
manifold, with or without boundary. The starting point of this paper is the observation that,
since one-forms are the natural expression of linear functionals on the space of vector ﬁelds, the
interaction between the two makes some aspects of the study of equilibria and periodic orbits
more tractable, at least in certain cases.
1
Introduction
“For Bourbaki, Poincar´e was the devil incarnate. For students of chaos and fractals,
Poincar´e is of course God on Earth.” – M.H. Stone
Stone knew the Bourbaki well; during WWII he was entrusted by A. Weil with all
of the volumes written by Bourbaki at that time.
He also shared, to some extent,
their view that all of mathematics should be deducible in a uniﬁed way form a small
number of basic principles. On the other hand, he was a student of G. D. Birkhoff
who researched dynamical systems in a fashion much closer to Poincar´e than to
Bourbaki.
Nonlinear dynamics and nonlinear control are both full of great concepts, great con-
structions and an amazing array of more special methods. However, in both ﬁelds it is
typically true that the more general a result is, the less often one can use it directly -
despite the fact that in some cases a general result at least shifts the burden of analysis
to something a bit more tractable. Personally, however, I still wonder what dynamical
systems would look like had Poincar´e known about Lyapunov theory.
Of course, one of the great general feats is the Poincar´e-Bendixson Theory for planar
dynamical systems, classifying limit sets, i.e. either an ω−limit or an α−limit, as
containing either an equilibrium or being a periodic orbit. In Section 2, we review
criteria for the existence of equilibria or periodic orbits for planar dynamical systems,
in the context of differential forms and their calculus.
In Section 3, we brieﬂy discuss the Principle of the Torus, which can be thought of as
a higher dimensional analogue of the existence of periodic orbits for dynamical systems
evolving on a Poincar´e annulus containing no equilibrium. The hypotheses, however,
are a little onerous - especially the assumption that there should exist a cross-section
for the ﬂow that is homeomorphic to the disk.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 35–44, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

36
C.I. Byrnes
G.D. Birkhoff, in his 1927 book entitled “Dynamical Systems” and reprinted in 1996
as [1], gave necesssary and sufﬁcient conditions for the existence of a cross-section. In
modern terminology, it amounts to the existence of closed one-form having a property
that can be checked inﬁnitesimally, just as in Lyapunov theory. We review and refor-
mulate this in Section 4, paying special attention to the kinds of domains which support
the hypotheses.
In Section 5, we summarize these observations, yielding the recent result by Brockett
and the author on necessary and sufﬁcient conditions for the existnece of periodic orbits
in autonomous systems. In Section 6, we present results concerning the stability and
robustness of periodic orbits. Both sections rely heavily on the use of differential forms.
I want to conclude by congratulating mio fratello, Giorgio Picci, on his 65th birthday.
I hope that this paper is a modest tribute to his work, especially how natural the ideas
underlying his work are and the consequent elegance.
2
Planar Dynamical Systems
Suppose ˙x = f(x) is a differential equation, deﬁning a dynamical system evolving in
the plane R2. Following the Poincar`e-Bendixson Theorem, we are interested in results
concerning either existence of equilibria or, in case of the lack thereof, existence of
periodic orbits. The following well-known result can, in fact, be used for both provided,
of course, the invariance hypothesis is satisﬁed.
Theorem 1 (Brouwer’s Fixed Point Theorem). If a continuous map f leaves a disk Dn
invariant, then f has a ﬁxed point, f(x0) = x0, for some x0 ∈Dn.
In the ﬁgure below we depict this situation for n = 2.
There are many well known proofs of Theorem 1, with our favorite being based on
a theorem of M. Hirsch, see [2]. For general n, if f is C1 then the ﬂow Φt of the
differential equation of the dynamical system also leaves Dn invariant and the ﬁxed
points of the time-t map, for t << ∞can be shown to be equilibrium.
Corollary 1. If a C1 map f leaves a disk Dn invariant, then the vector ﬁeld f has an
equilbrium, f(x0) = 0, for some x0 ∈Dn.
Since we will state and prove a more general theorem in our present case of interest,
n = 2, we need not give proofs of these statements

Differential Forms and Dynamical Systems
37
Indeed, consider a bounded (open) domain M0 in R2 with a smooth boundary ∂M0.
We then deﬁne M = M0
 ∂M0 consisting of an outer boundary ∂Mo and the inner
boundaries ∂Mi, 0 ≤i ≤g, of g holes as depicted below.
Motivated by classical reasons, we shall call g the genus of M.
We shall state this as an equilibrium theorem, and prove it in the case that the vector
ﬁeld has hyperbolic equilibiria.
Theorem 2 (Birkhoff’s Fixed Point Theorem). If M has genus g and if the C1 vector
ﬁeld f points inward on the boundary ∂M of M, then f has at least |1 −g| equilibria.
Proof. Let C ⊂M be an oriented closed curve. Write f =
f1
f2

and deﬁne the
Poincar´e index relative to C and f as
indC(f) = 1
2π

C
f2df1 −f1df2
∥f∥2

 !
"
d(
)=0
As a matter of fact , if we set
ω = f2df1 −f1df2
∥f∥2
and consider the Gauss map F =
f
∥f∥on C deﬁned by f, then F : C →S1 and
ω = F ∗dθ
2π
so that, in particular, the the Poincar´e index is integer valued and dω = 0 (see [3] esp.
pp. 50 −51).
Now, Gauss made the observation that if the vector ﬁelds f1, f2 always point out-
wards (or inwards), then λf1 + (1 −λ)f2 is a jointly continuous deformation of one
ﬁeld into the other, which is never zero on C, and therefore the integer value of the
index will be constant. In particular, since f points in the direction of the negative of
the outward normal n on ∂M0, we have
ind∂Mo(f) = −1.
Similarly, f points in the outward normal direction on each of the interior boundaries
∂Mi so that
ind∪∂Mi(f) = g.

38
C.I. Byrnes
Now suppose f has isolated equilibria x1, · · · , xN. Consider the closed curves Ci =
{x : ∥x −xi∥= ϵ}, where ϵ << ∞so that each Ci and its interior lie in Mo.Then f
is deﬁned on M −∪N
i=1Ci and therefore so is ω and dω.
Recall that Green’s Theorem states that if α is a smooth-one form on an oriented two
manifold N with smooth boundary ∂N, then

N
dα =

∂N
α
Taking N = M and α = ω, we have
ind∂M(f) −
n

i=1
indCi(f) =

M−∪N
i=1Ci
dω = 0.
Therefore
|g −1| =
#####
N

i=1
indCi(f)
##### ≤
N

i=1
| indCi(f)| = N.
.
The case of g = 1 hole is special, since there does not have to be an equilibrium. The
corresponding closed domain with one hole is usually called a Poincar´e annulus, A2, if
there in fact no equilibrium. In this case, the Poincar´e-Bendixson Theorem implies the
following result.
Theorem 3. Suppose f points inward on ∂A2. If f has no equilibria, then f has a
periodic orbit.
While we will take this as a given, we are also very interested in the construction, and
topology, of cross-sections for such a ﬂow.Recall that a cross-section is, in this case, a
curve C, homeomorphic to a closed interval for which the ﬂow is transverse and returns
in ﬁnite time. The following ﬁgure depicts a ﬂow on a Poincar´e annulus and several
cross-sections.
Choosing a cross-section C, let t1 = inf{t > 0 : x(t; x0) ∈C} and deﬁne the
Poincar´e map P : C →C via
P(x0) = x(t1, x0).
By Theorem 1, P has a ﬁxed point, which of course implies f has a periodic orbit.
Actually, as the following ﬁgure suggests

Differential Forms and Dynamical Systems
39
For n = 1, there is are many elementary proofs. For example, if graph(f) does
not intersect the diagonal then, because it is connected, it must lie in one of the two
connected sets we obtain by removing the diagonal, ∆, from C×C. If it lies in the upper
“triangle,’ then f is undeﬁned at one end-point of C. If it lies in the lower “triangle,”
then f is undeﬁned at the other end-point.
Actually, there is a nice exercise in ( [4], p.247) which considers the annulus bounded
by the circles of radius 1 and 2, positively invariant under a vector ﬁeld f which is
everywhere transverse to the cross-sections θ = constant, and asks for a proof of the
existence of a periodic orbit. This of course is a very convenient family of (foliation
by) cross-sections for the ﬂow and one would like to know whether, in general, crosss-
sections are the level sets of some Lyapunov-like function. The answer is no, as we can
deduce in the plane using Poincar´e’s Method of Tangential Curves [5].
Poincar´e’s Method assumes a bounded domain D, on which is deﬁned a family of
curves, P(x, y) = constant, and a vector ﬁeld which is tranverse to these cross-sections
at most points and tangent at all others (we will actually make this precise in higher
dimensions). The set of points at which f is tangent is called the tangent locus.
The Method of Tangential Curves asserts that if the tangent locus contains no equi-
librium or periodic orbits then D contains no periodic orbits. There are two aspects of
Poincar´e’s Method that are particularly noteworthy.
The ﬁrst is that, by writing V instead of P, and thinking about ˙V = 0 instead of
the tangent locus, Poincar´e’s Method can be seen as a precursor to LaSalle’s Theorem,
which is its higher dimensional generalization. More explicitly, consider ˙x = f(x),
x ∈Rn, and a compact subset D ⊂Rn. Suppose there exists V such that LfV (x) ≥0.
Then, for any trajectory remaining in D any ω-limit x∗remains in D and satisﬁes
LfV (x∗) = 0. For P = V and n = 2, this would imply that the tangent locus
contains ω−limits and hence either equilibria or periodic orbits, contrary to hypothesis,
/therefore every trajectory must leave D.

40
C.I. Byrnes
The second is that this shows that a family of cross-sections in a Poincar´e annu-
lus, such as the family θ = constant discussed above, can never be the level sets of
a Lyapunov-like function, or any function, because periodic orbits do exist. Indeed,
for example, θ is not a single-valued function. Rather, we should be using the closed,
not exact, one form dθ which gives rise to cross-sections described by dθ = 0. In fact,
thinking about both equilibria and periodic orbits, one observes that exact one-forms are
very useful for analyzing equilibria, while closed, non-exact one-forms can be shown
to be extremely useful for the study of periodic orbits.
3
The Principle of the Torus for Autonomous Systems
The quest for ﬁnding a higher dimensional generalization of the Poincar´e -Bendixson
Theorem, or the the existence of the right analogue of the Poincar´e annulus, has had
to deal with more complicated limiting behavior and more complicated topology. One
such generalization, the Principle of the Torus [6], is worth mentioning as a gateway
to a more general approach and because it has found a fair amount of application in
engineering and science [7], and also captures some of the features encountered in
forced oscillations of hyperbolically stable autonomous systems.
Given a dynamical system ˙x = f(x)in Rn, the Principle assumes the existence of
an invariant toroidal region R and a cross-section C for the vector ﬁeld f, with C is
homeomorphic to a disk. this situation is depicted below.
In particular, ∀x0 ∈C ∃t > 0 so that x(t; x0) ∈C. Then, the Poincar´e map
P : C →C is deﬁned and is continuous because f is transverse to C.
By Theorem 1, P has a ﬁxed point x0, i.e., x(t1, x0) = x0 and therefore x(·, x0) is
periodic.
While it does sometime occur in practice, the hypothesis that there is a cross-section,
which is also homeomorphic to a disk, is quite strong and hard to check. Supressing,
for the moment, the topological properties of C, one should ask whether there are cri-
teria for the existence of cross-sections. As we saw in the previous section, the cross-
sections will not in general be level sets of smooth functions. This can be seen again
in this context for a standard solid n -torus, with coordinates (ρ.θ), with differential
equation
˙ρ = 0, ˙θ = 1
for which a family of cross-sections is deﬁned by dθ = 0. In particular, this family
cannot be deﬁnd as the level sets of a smooth real-valued function. That this situation
is indeed the general case will be addressed in the next section.

Differential Forms and Dynamical Systems
41
4
Lyapunov-Like Differential Forms for the Existence of Cross
Sections
Again, we consider ˙x = f(x) evolving in Rn. In his 1927 classic [1], G. D. Birkhoff
shows that a necessary condition for a local cross-section C to exist is that C should be
part of a family of cross-section deﬁned by an angular variable φ = constant, which he
constructs from the ﬂow and which should be increasing along the ﬂow (see esp. pp.
143 −145). He expresses this in terms of the pair of constraints
˙φ =
i=n

i=1
aifi > 0 and ∂ai
∂xj
= ∂aj
∂xi
, i, j = 1, 2, · · · , n
and claims that their existence will deﬁne a cross-section by setting φ to be equal to the
constant 0.
In modern terminology, the functions ai are the components of a 1-form ω =
n
i=1 aidxi such that
⇔dω = 0
⇔⟨ω, f⟩> 0.
ω = 0 deﬁnes a cross-section.
Some care, however has to be given as to the domain of these objects, especially ω.
We ﬁrst consider the planar case, following the notation set in Section 2.
If the genus of M is not 1 then, by Theorem 2, f has at least |g −1| zeros, so
that ⟨ω, f⟩> 0 is untenable and there cannot be an increasing angular variable. From
the classiﬁcation of compact orientable two dimensional manifolds by their genus, we
deduce the same conclusion for compact 3-dimensional manifolds-with-boundary in
R3. Therefore, angular variables in the sense of Birkhoff will only exist on the solid
2-torus.
This low-dimensional analysis gives some credence to standard assumptions con-
cerning a positively invariant manifold which is a “toroidal” region. We shall take a
more general approach.
Deﬁnition 1. Consider a compact orientable manifold M, perhaps with smooth bound-
ary. We call M a circular manifold provided M is contractible to a simple closed curve
γ ⊂M.
Examples: circles, compact cylinders, solid tori.
Remark: A circular manifold is connected, since it is contractible to a connected space.
More generally, A circular manifold is a K(Z; 1); i.e., an Eilenberg-Maclane space with
π1(M) = (γ) = Z and πi(M) = {0} for i ≥2.
Remark: If n = 1, then either M ≃[a, b] or M ≃S1. Only the latter is contractible
to a circle. In particular, in this case, M has nonempty boundary. Suppose conversely
that M is a circular manifold without boundary. If M is orientable then the volume
form on M represents a nonzero class in Hn
dR(M), by Stokes’ Theorem, and therefore
M is only a circular manifold when n = 1. If M is not orientable , applying the same

42
C.I. Byrnes
reasoning to its orientable double cover $
M we ﬁnd that M ≃RP 1 and is therefore also
a circle. Summarizing, a circular manifold has ∂(M) ̸= ∅if, and only if, n ≥2.
5
Necessary and Sufﬁcient Conditions for Existence of Periodic
Orbits
Theorem 4 (Brockett-Byrnes). A necessary and sufﬁcient condition for the existence
of a periodic orbit of a smooth vector ﬁeld f is:
1. existence of a positively inverse circular manifold M n,
2. a closed one form ω for which ⟨ω, f⟩> 0 on M n and for which ω never vanishes
on ∂M n.
Proof.
Necessity: If γ exists then there exists a closed one-form dθ on γ such that

γ
α = 1
Sufﬁciency: Choose a generator γ1 for π1(M) ≃Z. We can assume
%
γ1 w = 1. We
now construct the “period map” J : M →S1. Fix P ∈M. For any Q ∈M choose
a path γ2 from P to Q and consider
&Jγ2(Q) =

γ2
w.
If γ3 is another such path
γ3 −γ2 ∼ℓγ1 so &Jγ3(Q) = &Jγ2(Q) + ℓ.
That is, in R,
&Jγ3(Q) ≡&Jγ2(Q) mod Z. Therefore we may deﬁne
J : M →S1 = R/Z via J(Q) =
 Q
P
w.
It will turn out that J−1(θ) is connected (because
%
γ1 w = 1) and is therefore a leaf of
w = 0. Choose θ0 ∈S1 L0 = J−1(θ0). Choose x0 ∈L0. Since
⟨w, f⟩> 0 we have

J(Φt(x0))
dθ > 0
and so there exists T > 0 such that
P(X0) = ΦT (x0) ∈L0.
Therefore L0 is a cross-section for the ﬂow.
We conclude by proving that P has a ﬁxed point, using the homotopy of L0 ⊂M →
S1 and the Lefschitz ﬁxed point theorem.

Differential Forms and Dynamical Systems
43
6
Stability and Robustness of Periodic Orbits
Our proof of the existence of periodic orbits computed the Lefschitz number of P using
the Lefschitz Fixed Point Theorem in homology. This theorem can also be proved using
differential forms.
In fact, the Lefschetz number computes the oriented intersection number of the graph
of P(x) with the diagonal (the graph of the identity map) in L0 × L0.
For C∞objects, a transverse (hyperbolic) intersection number is computed as
det(I −DP(x0))
at an intersection point (x0, P(x0)). Therefore, if we have only hyperbolic intersec-
tions, then we must have
Corollary 2 (An index formula). Under the hypotheses above, if P has only hyperbolic
ﬁxed points then they are ﬁnite in number and

γ
sign det(I −DPγ) = 1
where the sum is over distinct periodic orbits.
We note that, if x0 is asymptotically stable (and hyperbolic)
sign det(I −DP(x0)) = 1.
Corollary 3. The local exponential stability of every orbit implies the global uniqueness
of a single stable orbit.
Proof. If each periodic orbit is exponentially orbitally stable, the index formula
reduces to
#γ · 1 = 1 or #γ = 1.
Because our conditions are open in the C∞topology, they are also robust with respect
to sufﬁciently small perturbations.
Corollary 4. Suppose ˙x = f0(x), x ∈Rn, has an asymptotically stable periodic orbit
γ0. Then, for any jointly continuous perturbation
˙x = f(x, µ)
where for some µ0, f(x, µ0) = f0(x), there must exist a periodic solution, for each
µ ∼µ0.

44
C.I. Byrnes
Corollary 5 (Averaging). If 0 is a locally exponentially stable equilibrium for the sys-
tem ˙x = f(x) + ϵg(x, t, ϵ) when ϵ = 0, and g(x, t + T, ϵ) = g(x, t, ϵ) then for ϵ ≪∞
there exists a locally exponentially stable periodic orbit γϵ(t) of period T whose ampli-
tude is O(ϵ).
References
1. Birkhoff, (1966) G.D. Dynamical systems, 2nd edition. American Mathematical Society Col-
loquium Publications, Vol. IX, Providence, R.I.
2. Milnor J.(1997) Topology from the differentiable viewpoint. Princeton University Press,
Princeton
3. Guckenheimer J. and Holmes P. (1983) Nonlinear oscillations, dynamical systems, and bifur-
cations of vector ﬁelds, Springer-Verlag, Berlin Heidelberg New York
4. Hirsch, M. and Smale, S. (1974) Differential equations, dynamical systems, and linear alge-
bra. Academic Press, New York London.
5. Yanqian, Ye et al. (1986) Theory of limit cycles, Trans. Math. Monographs 66, AMS Provi-
dence.
6. Pliss V.A. (1966) Nonlocal problems of the theory of oscillations. Academic Press, New York
London.
7. B. Li (1981) Periodic Orbits of Autonomous Ordinary Differential Equations: Theory and
Applications, Nonlinear Analysis, Theory, Methods and Applications, Vol. 5, 931-958.

An Algebraic Framework for Bayes Nets of Time Series
Peter E. Caines1 and Henry P. Wynn2
1 Department of Electrical and Computer Engineering, McGill University, 3480 University
Street, Montreal, QC H3A 2A7, Canada
peterc@cim.mcgill.ca
2 Department of Statistics, London School of Economics and Political Science, London, UK
h.wynn@lse.ac.uk
Summary. Graphical models in which every node holds a time-series were analysed in
Caines et al. [13], [14] using the notion of lattice conditional independence (LCI) due to
Anderson et al. [1], [2]. Under certain feedback free (or causality) conditions, LCI imposes a
special zero structure on the stochastic realizations of those processes generated by state space
systems; this structure comes directly from the transitive directed acyclic graph (TDAG) which
is in one-to-one correspondence with the Boolean Hilbert lattice of the LCI formulation. In this
paper, these properties of sets of stochastic processes are generalized to the setting of inﬁnite
Bayes nets of time series; this formulation contains as a special case conditionally independent
processes embedded in chain recurrent spatial structures.
Keywords: Bayes nets, stochastic processes, time series, conditional independence, feedback
free conditions, causality, stochastic realization, chained systems, recurrence.
1
Introduction
The subject of this paper is the construction Bayes nets, or graphical models, in which
every node is a time series. Among the ﬁrst work in this growing ﬁled is that of
Dahlhouse [15] and Eichler [12].
The key condition for the whole theory of graphical models is conditional inde-
pendence, so this is necessarily the starting point for any extension to inﬁnite di-
mensional processes. The theory presented in (Caines et al. [13], [14]) and in this
paper provides a dynamic version of static conditions for conditional independence
since the basic deﬁnition in the process case requires the conditional independence
property to hold recursively in time up to time t. As will be seen in the next sec-
tion, the viewpoint adopted in this paper is that the theory of stochastic realiza-
tion developed by Akaike [8], [9], Lindquist and Picci [4], [5], [3], and others (see
e.g.
Caines [7], Chapter 4), forms an appropriate framework to capture the prop-
erties of the conditional independence of groups of process.
But this is the case
only if the so-called feedback free, or causality, relations hold pairwise between each
conditioning process and each of the members of the set of processes it renders condi-
tionally independent.
However conditional independence is only half the story. The next step is to ﬁnd
a structure which preserves the utility of the state space formulations but allows one
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 45–57, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

46
P.E. Caines and H.P. Wynn
to ﬁrst build reasonably complex graphical models, and, second, to capture both time
dependence and the cross-process dependence. Broadly speaking, the Lattice Condi-
tionally Independence (LCI) in the Gaussian case (or, the Lattice Conditionally Or-
thogonality (LCO) property in the more general second order case) is most appropriate
for expressing such properties since it respects a generalized “arrow of time” both in
the space orderings of a given family of processes and with respect to time.
In this paper, Section 2 introduces the notions of conditional independence, the feed-
back free property and gives the ﬁrst stochastic realization theorem; Section 3 presents
the relevant lattice projectors and introduces the notion of a transitive directed acyclic
graph (TDAG) of a set of processes; then, in Section 4, a class of countably inﬁnite
TDAG structures is presented which has sufﬁcient regularity to permit the construction
of what may be termed spatio-temporal stochastic realizations.
2
Conditional Independence and Stochastic Realization
For a stochastic process X, the process up to time t is deﬁned as the ﬁnite or inﬁnite
segment of the process given by X(t) = {. . . , Xt−1, Xt}.
Deﬁnition 2.1 (Caines et al. [13], [14]). A triple of multivariate stochastic proces-
ses {Xt, Yt, Zt; t = . . . −1, 0, 1, . . ...} is said to be conditionally independent up to
time t if
X(t) ⊔Y (t) | Z(t),
and is said to be conditionally independent if this relation holds for all t.
□
We motivate this notion with the following simple example.
Example 2.1.
Consider the unique stationary trivariate Gaussian process {Xt, Yt,
Zt} generated by the AR(1) linear system:
Xt −a11Xt−1 −a12Yt−1 −a13Zt−1 = ε1,t
Yt −a21Xt−1 −a22Yt−1 −a23Zt−1 = ε2,t
Zt −a31Xt−1 −a32Yt−1 −a33Zt−1 = ε3,t
where (i) {εt} = {ε1,t, ε2,t, ε3,t} is a white noise process, that is to say, is a Gaussian,
zero mean, unit variance process independent over time and index, and (ii) the system
is asymptotically stable in the sense that (in an obvious notation) the eigenvalues of A
are asymptotically stable (i.e. have absolute value strictly less than 1).
It is straightforward to check that if a21 = a31 = a32 = a12 = 0, the processes
up to time t for all t are conditionally independent. There are several ways to show
this: (i) via conditional expectations, (ii) via the covariance generating functions (i.e.
the spectral density matrix for the joint process {Xt, Yt, Zt}), and (iii) via the explicit
construction of the semi-inﬁnite projections, which are the analogues of the projections
PJ described in Section 3.2 below.
A fourth method is to explicitly solve for Xt and Yt using the shift operator z deﬁned
on any process V via zVt = Vt−1:

An Algebraic Framework for Bayes Nets of Time Series
47
Xt = ε1,t+a13zZt
1−a11z
Yt = ε2,t+a23zZt
1−a22z
Now if Zs, s ≤t, is ﬁxed we see that Xt and Yt only depend on ε1,s, s ≤t, and
ε2,s, s ≤t, respectively, which are mutually independent and are independent of
Zs, s ≤t, which is a function only of ε3,s, s ≤t. We note that in this example,
Z at the instant t does not appear in the expressions above for Xt and Yt.
□
To generalise these facts we assume ﬁrst that {X1, . . . , Xd} = {{X1,t, . . . , Xd,t}, t ∈
Z} is a collection of multivariate zero mean second order stochastic processes.
Deﬁnition 2.2. A pair of second order processes (Xi, Xj), i ̸= j, is said to be feed-
back free if and only if Xt,i|Xj = Xt,i|X(t)
j , t ∈Z, where “|” represents orthogonal
projection. In case the equality holds with |X(t)
j
replaced by |X(t−1)
j
, (Xi, Xj), i ̸= j,
is said to be (strongly) feedback free.
□
(Note that orthogonal projection is identical to conditional expectation in the zero mean
Gaussian case).
It follows (see Theorem 2.1, Chapter 10, Caines [7] for this and other characteri-
zations) that a pair of wide sense stationary processes (Xi, Xj), i ̸= j, (assumed to
possess a spectral density) is feedback free if and only if the spectral density matrix
has a factorization where the ﬁrst matrix factor is asymptotically stable and inverse
asymptotically stable:
GXi,Xj(z) =
' A B
0 C
( ' A∗0
B∗C∗
(
(z),
(1)
where A∗is the conjugate of A, etc. The strongly feedback free case corresponds to the
additional condition B(0) = 0.
Let the feedback free property hold between the conditioning process and each of
the other processes in a conditional independence triple; then a temporal dependence is
imposed on the conditional independence structure as is shown in the next result where
Xi denotes the whole process which, in the doubly inﬁnite case would be {Xi,t}∞
−∞.
Theorem 2.1 (Caines et al. [13]). Subject to the assumption that the pairs {Xi, Xk}
and {Xj, Xk} are feedback free, the following two types of conditional independence
are equivalent,
1. Xi ⊔Xj| Xk,
2. X(t)
i
⊔X(t)
j
| X(t+s)
k
, s ∈{0, 1, . . .}, t = . . . −1, 0, 1, . . ..
Subject to the strong feedback free condition, (t + s) above is replaced by
(t + s −1).
□
The next result shows that under the condition that the pairs of processes under consid-
eration are feedback free, it is the case that processes generated by state-space systems

48
P.E. Caines and H.P. Wynn
are conditionally independent if and only if they have a stochastic realization with a
speciﬁc structure.
Theorem 2.2 (Caines et al. [14]). Let the three jointly full rank Gaussian stochas-
tic processes {Xi,t, Xj,t, Xk,t; t ≥0} be such that the joint process possesses a ﬁ-
nite dimensional stochastic realization on t = 0, 1, . . . . Then (i) each pair {Xi, Xk}
and {Xj, Xk} is feedback free, and (ii) the conditional independence relations X(t)
i
⊔
X(t)
j
| Xt+s
k
, s = 0, 1, . . .; t = 0, 1, . . ., hold if and only if {Xi,t, Xj,t, Xk,t} has a
(not necessarily time invariant) stochastic state-space realization on t = 0, 1, . . . of the
form:
⎡
⎣
si,t+1
sj,t+1
sk,t+1
⎤
⎦=
⎡
⎣
Fii
0
Fik
0 Fjj Fik
0
0
˜Fkk
⎤
⎦
⎡
⎣
si,t
sj,t
sk,t
⎤
⎦+
⎡
⎣
Mii
0
Mik
0
Mjj Mjk
0
0
Mkk
⎤
⎦
⎡
⎣
ui,t
uj,t
uk,t
⎤
⎦
⎡
⎣
Xi,t
Xj,t
Xk,t
⎤
⎦=
⎡
⎣
Hii
0
Hik
0 Hjj Hjk
0
0
Hkk
⎤
⎦
⎡
⎣
si,t
sj,t
sk,t
⎤
⎦+
⎡
⎣
Nii
0
Nik
0 Njj Njk
0
0
Nkk
⎤
⎦
⎡
⎣
ui,t
uj,t
uk,t
⎤
⎦,
where (i) the joint system input and observation noise process ut; t = 0, 1, . . . is a
full rank zero mean orthogonal Gaussian process with block diagonal (instantaneous)
covariance (ii) u is independent of the Gaussian zero mean initial condition s0, and
(iii) s(0) has a covariance matrix Σ which possesses a factorization Σ = Σ
1
2 Σ
T
2 ,
where Σ
1
2 has the same block structure as the system matrices. The replacement of the
feedback free condition by the strong feedback free condition is obtained by imposing
the additional constraints that the matrices Hik, Hjk, Nik, Njk are zero and Σ is block
diagonal.
□
3
Lattice Conditionally Independence and Stochastic Realization
3.1
Lattices of Subspaces
One of the purpose of this paper, as mentioned in the introduction, is to describe an
algebraic framework which is suitable for the extension of the notion of ﬁnite Bayes
nets of time series to the case of inﬁnite but countable sets of nodes. We will see
that there are a number of essentially isomorphic structures by which this framework
can be described. It turns out, ﬁrst, that the state-space formulation of conditional
independence given in the last section is a special case of this structure and, second, that
we can build stochastic realizations of a more general class of graphical models of time
series using an extension deriving from one of a set of equivalent algebraic structures.
This is the transitive directed acyclic graph (TDAG) structure and its implementation
will be given in the next section.
We now give a brief summary of some relevant, closely related, algebraic
structures.
Boolean Lattices of Subspaces. let H be a separable Hilbert space with a countable
basis {εi}, i ∈N. We shall call the index set for the basis the basis index set.

An Algebraic Framework for Bayes Nets of Time Series
49
Let U and V be a two subspaces of a separable Hilbert space H and let PU and PV
be the associated projectors. Then we have that the projector for U ∩V is the product
PUPV if and only if PU and PV commute: PUPV = PV PU. Taking U ∪V to mean
span(U, V ) = U + V the corresponding projection is then
PU∪V = PU + PV −PU∩V = PU + PV −PUPV
(2)
(see Kadison and Ringrose [10]).
We are interested in the special Boolean lattice of subspaces of H is a countable
collection of subspaces {UJ|J ∈L} closed under ∩and ∪. In our case each subspace
is uniquely indexed by its representation in terms of a countable basis {ei}, and we write
UJ = span{ei, i ∈J}, where J is a possibly inﬁnite, but countable set of indices.
Countable Subset Lattice. By the Stone representation theorem, any complete, atomic
Boolean lattice is isomorphic to a lattice of subsets of some set (Johnstone [16]). In our
case, these sets are simply subsets of the index set J under the union and intersection
operations. We call this lattice B(L). Thus for any countable set J of indices
VJ = ∪i∈JUi →J,
and for index sets J and K
UJ ∪UK →J ∪K, UJ ∩UK →J ∩K
We can simplify the notation somewhat by writing PJ for the projector PUJ, associated
with the subspace UJ.
Countable Transitive Acyclic Directed Graphs. To each Boolean lattice, and the equiv-
alent subset lattice, we associate a transitive directed acyclic graph (TDAG), G(E, V ).
The vertex set E is the basic index set, deﬁned above. There is a directed chain from
vertex i to vertex j if every index set J in B(L) which contains j contains i. Then
we have the edge i →j if there is a chain from i to j with no intermediate vertices.
Transitivity follows from the fact that i →j and j →k implies that any K containing
k contains j and therefore contains i. The inverse construction is also straightforward.
Conditional Orthogonality.
If I, J and K are disjoint sets of integers such that
PI∪KPJ∪K = PJ∪KPI∪K we write I ⊥J|K. Thus the Boolean lattice gives a
collection of conditional orthogonality statements. These can be written in terms of
projections also as
(PI∪K −PK)(PJ∪K −PK) = 0,
The projections PI∪K −PK and PJ∪K −PK may be termed the “innovation” subspaces
associated to the pairs of spaces (I, K) and(J, K).
3.2
Lattice Conditionally Orthogonal Stochastic Hilbert Spaces
Consider a full rank collection of multivariate zero mean second order stochastic pro-
cesses {X1,t, . . . , Xd,t} and consider its associated Hilbert space. In case {X1, . . . , Xd}

50
P.E. Caines and H.P. Wynn
is Gaussian the projections are conditional expectations. We initially consider the case
where each Xi,t is univariate. An orthonormal basis corresponds to a basis of uncor-
related unit variance random variables {ei,t;
t = . . . , −1, 0, 1, . . .; i = 1, . . . , d}
and these are independent in the Gaussian case. Associated with such a basis is a
family of rank 1 projectors {Pi,t; i = 1, . . . , d}; for instance, if Xi,t = aT
i et, then
Pi,t = ai[aT
i ai]−1aT
i . Of course, the orthonormal basis is not unique and a special ba-
sis may play a special role so that the projectors of interest may depend on the basis
of interest; this is the situation with the innovations basis which appeared implicitly in
Theorem 2.1.
The ﬁnite dimensional Lattice Conditional Orthogonality (LCO) condition is straight-
forward to deﬁne. We can consider it here ﬁrst in the case of a single time point. There
are many equivalent statements and here we simply list some of them. We take ﬁrst take
the case d = 3 and consider conditional independence. The condition X1 ⊥X2|X3,
which we read as X1 conditionally orthogonal to X2 given X3, then has the following
equivalent statements:
1. {Γ −1}12 = 0
2. If P13 and P23 are the orthogonal projectors onto span(X1, X3) and span(X2,
X3), respectively, then P13P23 = P23P13.
3. If I is the identity projection in span(X1, X2, X3) and P3 is the projector on
span(X3) then
P13 + P23 −P3 = I
4. (P13 −P3)(P23 −P3) = 0
5. There is an orthornormal basis for span(X1, X2, X3) such that in this basis P13 and
P23 take the form
P13 =
⎡
⎣
1 0 0
0 0 0
0 0 1
⎤
⎦,
P23 =
⎡
⎣
0 0 0
0 1 0
0 0 1
⎤
⎦
It is interesting, even in this simple case, to see the subset lattice at work on the diagonal
elements of the projectors. In binary arithmetic
101 + 011 −001 = 111,
or in terms of the indicator, that is Boolean variables:
I13∪23 = I13 + I23 −I3
The LCO condition is attributed to an index sets J ⊂{1, . . . , d} such that all the
corresponding projectors PJ commute. Then by an identical argument as used above
the subspace lattice can be read off from the subset lattice of indices. The associated
TDAG is then exactly as describe above and the random variables form a special acyclic
Bayesian graphical model with the global Markov property. For the conditional inde-
pendence of X1, X2 given X3, the lattice has elements 123, 13, 23, 3 and we adjoin ∅.
The TDAG is
3 →1, 3 →2.
We shall say that the collection of jointly wide sense stationary zero mean Gaus-
sian processes X1, . . . , Xd is LCI-G -compatible if the conditions associated with the
procedure below are satisﬁed:

An Algebraic Framework for Bayes Nets of Time Series
51
1. For the given TDAG G(E, V ), or the equivalent distributive Boolean lattice L,
associate to every vertex Vi a stochastic process Xi.
2. For every conditional independence statement that can written down from G, or
the corresponding Boolean lattice L, require that the corresponding feedback free
condition holds. Note that we need to group processes together according special
index sets. Thus, for an index set J we say XJ = {Xj,t, j ∈J}. If our conditional
independence is to be
XJ ⨿XK|XJ∩K, J, K ∈L,
then we require that pairs (XJ, XJ∩K) and (XK, XJ∩K) are each feedback free.
3. Finally, verify that each of the up-to-t version of conditional independence state-
ments given by the graph G holds (or the equivalent condition in Theorem 2.2).
With an obvious notation: for every J, K ∈L
X(t)
J
⨿X(t)
K |X(t)
J∩K
To summarize: for X1, . . . , Xd to be LCI-G-compatible all those pairs of feedback
free conditions and conditional independence conditions must hold which can be listed
from the original TDAG, G, or equivalently the Boolean lattice L. To complete the anal-
ysis we need to generalize Theorem 3.2 to the LCO/LCI case. We do this by extending
the zero structures of the representations in Theorem 2.2.
Deﬁnition 3.1. A square matrix A is said to be of block form if it can be partitioned
into blocks Bij, (i, j = 1, ..., d), such that Bij is ni × nj, (i, j = 1, . . . , d) and
the blocks are stacked in standard index order: larger i means lower position, larger j
means further to the right. We say that a square matrix A has a zero structure compatible
with a transitive directed graph G(E, V ) with d vertices if A is of block form such that
Bij = 0 whenever j →i is not in the edge set E of G.
□
Looking at the structure of the stochastic realization in Theorem 2.2, we see that the
upper triangular form with zero blocks in the requisite positions is compatible with the
graph 1 ←3 →2, because the zero blocks are the blocks 21, 31, 32, 12, corresponding
to the missing directed edges. It is evident how this structure generalizes to a collec-
tion of processes X1, . . . , Xd and we shall term as G-compatible the corresponding
Gaussian stochastic realization generalizing that which appears in Theorem 2.2. This
terminology also clearly extends to spectral factors and to their inverses, when they
exist.
We state the main result in a brief form to avoid cumbersome notation and omit the
proof, which is an extension of that for Theorem 2.2.
Theorem 3.1. Let {X1, . . . , Xd} be a set of zero mean jointly full rank Gaussian
stochastic processes generated by a ﬁnite dimensional state space system and let G
be a TDAG with d vertices. Then X1, . . . , Xd is LCI-G-compatible if and only if
{X1, . . . , Xd} has a Gaussian stochastic realization which is G-compatible.
□
In the light of Theorem 3.1, the nature of the lattice of projectors associated with a set
of processes {X1, . . . , Xd} satisfying the hypotheses of the theorem above becomes

52
P.E. Caines and H.P. Wynn
evident. Precisely as stated earlier, the projector associated with any subset S of the
processes {X1, . . . , Xd} up to a given instant t will be an orthogonal projection into
the span of the (linear functions of the) innovations processes up to the instant t which
are mapped into S by the dynamical transitions of the stochastic realization.
In the particular case of three processes as presented in Theorem 2.2, the projectors
can be directly read off from the stochastic realization. For example, in the simple case
of the projector P{Xi,0,Xk,0;Xi,1,Xk,1} associated with the indicated argument processes,
it can be seen to be a 6 × 6 block with identity matrices in the ﬁrst, third, fourth and
sixth block positions on the diagonal and zeroes elsewhere. This corresponds, for two
time instants, to the static scalar three dimensional case in item 5 of Section 3.2.
In case {X1, . . . , Xd} is a set of jointly wide-sense stationary Gaussian stochastic
processes we may state the following version of Theorem 3.1.
Theorem 3.2. Let G be a TDAG with d vertices and let {X1, . . . , Xd} be a set of jointly
stationary zero mean Gaussian stochastic processes which possesses a rational spectral
density matrix {Φ(z); z ∈C}, which is non-singular together with its inverse on the
unit circle.
Then X1, . . . , Xd is LCI-G-compatible if and only if {X1, . . . , Xd} possesses an
asymptotically stable and inverse asymptotically stable Gaussian stochastic realization
which is G-compatible and for which the state space process is stationary.
Furthermore, this is the case if and only if {Φ(z); z ∈C} possesses spectral
factors which are (i) asymptotically stable and inverse asymptotically stable, (ii)
G-compatible.
□
In the strong feedback free case, the stochastic realization is further restricted in anal-
ogy with the specialization in Theorem 3.1 and the spectral factor property (1) has the
additional condition: (iii) {Ψ(z); z ∈C} has off diagonal terms vanishing at z = 0.
The last part of this theorem may be paraphrased as stating that for a set X1, . . . ,
Xd of wide sense stationary Gaussian processes satisfying the standing hypotheses of
the theorem, if X1, . . . , Xd is LCI-G-compatible then the zero structure arising from
G is displayed by the zero structure of speciﬁc spectral factors Ψ
G(z) = ΨΨ ∗(z)
(3)
of the spectral density of the joint process.
In both of the examples below each node represents a univariate AR(1) process:
X(t) = ΦX(t−1) + ε(t)
and we use Theorem 3.2 to claim a particular form for Φ.
Example 3.1. Consider the graph {4 →1, 4 →2, 4 →3, 2 →1, 3 →1}, then
Φ =
⎡
⎢⎢⎣
a11 a12 a13 a14
0 a22 0 a24
0
0 a33 a34
0
0
0 a44
⎤
⎥⎥⎦

An Algebraic Framework for Bayes Nets of Time Series
53
Example 3.2. In this case we take the graph:
5 →3, 5 →1, 3 →1, 5 →4, 5 →2, 4 →2
The form of Φ is then
Φ =
⎡
⎢⎢⎢⎢⎣
a11 0 a13 0 a15
0 a22 0 a24 a25
0
0 a33 0 a35
0
0
0 a44 a45
0
0
0
0 a55
⎤
⎥⎥⎥⎥⎦
We can conﬁrm the conditional independence of the up-to-t series by elimination. For
example to conﬁrm
X1 ⊔X2 | (X3, X4, X5)
we eliminate ε3, ε4, ε5 from the equation
X = (I −zΦ)−1ε
(4)
to obtain equations for X1,t and X2,t in terms of X3,t, X4,t, X5,t, ε1,t, ε2,t.
X1,t = a13zX3,t+a15zX5,t+ε1,t
1−a11z
X2,t = a24zX4,t+a25zX5,t+ε2,t
1−a22z
When the matrix appearing in the AR(1) representation is asymptotically stable the
relevant spectral factorization can be easily written down since Ψ(z) = (I −zΦ)−1 is
itself the required strong spectral factor. We note that the zero structure of Ψ is the same
as that of Φ. This is a generic fact: the G compatible matrices (with non-zero diagonals
and prescribed dimensions) form a group in that the product of any two such matrices
is of the same form and so are the inverses. In the simple examples given here we see
that the inﬁnite moving average, which derives from an AR(1) in the LCI class, has a
structure in which X(i) is a function only of present and past innovations which can be
traced backwards from its node in the TDAG.
As an example we compute the Moving Average representation for X3,t in
Example 3.2 as
X3,t = e3,t + z(−a55e3,t + a35e5,t)
(1 −a33z)(1 −a55z)
,
conﬁrming the dependence only on e3,t and e5,t: the innovations reachable by reverse
arrows.
4
Spatially Patterned Inﬁnite Bayes Nets
Evidently, combining the “spatial” dependence of the TDAG with the linearly ordered
nature of time (a linear TDAG) for each separate process gives a “super” TDAG, which
might be regarded as a generalized time structure. This leads to the notion that the
TDAG/LCI is an appropriate setting to carry out a generalisation of the theory presented

54
P.E. Caines and H.P. Wynn
so far; this in turn leads to an algebraic Bayes net theory for certain spatially countably
inﬁnite conﬁgurations of processes.
We initiate such investigations in this paper by introducing one particularly simple
structured system which we shall be termed a chain recurrent TDAG. The constituent
elements of such a system are triples {(Xk,t, Yk,t, Zk,t; t ≥0); k ∈Z} of jointly dis-
tributed zero mean Gaussian multivariate processes attached to the nodes of a countably
inﬁnite TDAG identiﬁed with the integers, Z. The “root” process Zk is placed at the
node k ∈Z; a directed edge connects it to a node bearing the “leaf” process Yk and ﬁ-
nally a distinct edge from k leads to the node bearing the “leaf” process Xk. Henceforth
we shall not distinguish between a node and the process attached to it.
The sequential structure of the spacial conﬁguration is obtained in the following way:
for each integer k ∈Z, the leaf process Xk is identiﬁed with the root process Zk+1 of
the subsequent triple; on the other hand there is no directed edge leading from the node
Yk. Clearly, the generalization with respect to the theory in Section 3 is that the ﬁnite
TDAGs of that section are now replaced by a countably inﬁnite tree structure.
In order to formulate the appropriate notions of the feedback free and condi-
tional independence properties on a chained recurrent TDAG we make the following
deﬁnitions.
For a process Qj ∈{(Xk, Yk, Zk); k ∈Z} the spatial antecedents Qa
j consist of Qj
itself together with all nodes (i.e. processes) of the same type (i.e. X, Y or Z) which
may connected to Qj by ﬁnite connected paths of directed edges; correspondingly, the
spatial future Qf
j consists of all nodes (i.e. processes) of the same type to which Qj
may be linked by ﬁnite connected paths of directed edges.
For example, the set of spatial antecedents of Zk, k ∈Z, is the set {Zj; j ≤k, j ∈
Z}, while that of Yk is {Yj; j ≤k, j ∈Z}.
Then the triple of processes P, Q, R ∈{(Xk, Yk, Zk); k ∈Z} in a chained recurrent
TDAG is said to be spatially conditionally independent at node k if
P a
k ⊔Qa
k | Ra
k,
and is said to be spatially conditionally independent if this relation holds for all k ∈Z.
Furthermore, a pair of zero mean Gaussian stochastic processes
P, Q ∈{(Xk, Yk, Zk); k ∈Z},
in a chained recurrent TDAG is said to be spatially feedback free if and only if, for all
k ∈Z,
Pk|Qa
k ∪Qf
k = Pk|Qa
k,
where “|” represents conditional expectation in the Gaussian case.
□
Next we deﬁne the space
/
H ≡
/
{H{(X, Y, Z)k; k ∈Z}}∞
j=−∞.
which is the space of doubly inﬁnite sequences of copies of the Hilbert space spanned
by the second order processes X, Y, Z.

An Algebraic Framework for Bayes Nets of Time Series
55
Taking the deﬁnitions above, and employing analogous proof methods to those used
for Theorems 3.1, 3.2, we may link the notions developed so far in the following way.
Consider the family F of zero mean Gaussian processes {(Xk,t, Yk,t, Zk,t;
t ≥0); k ∈Z} indexed by {k ∈Z} associated to the chained recurrent TDAG T(F).
Assume the temporal process {(Xk,t, Yk,t, Zk,t); t ≥0} is full rank and wide sense
stationary for each k ∈Z and that the spatial process {(Xk,t, Yk,t, Zk,t); k ∈Z} is full
rank wide sense stationary for each t ≥0.
Then the family F satisﬁes the spatial feedback free and conditional indepen-
dence conditions if and only if it possesses a spatially indexed inﬁnite impulse re-
sponse (equivalently inﬁnite moving average) representation in the chained recurrent
form shown in (5) below; in (5) the vector entries and the operator entries in the
spatio-temporal operator W are the formal z transforms of (i) processes, and (ii) non-
anticipative impulse responses respectively, and the innovations processes (εx, εy, εz)
are mutually independent for all values of the space and time variable. Furthermore, the
block-zero pattern of the spatial impulse response operator W in (5) is in one-to-one
relation with that of the chain recurrent TDAG T(F) and W is Toelpitz with respect to
diagonal shifts respecting the zero structure.
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∗
Yl+1(z)
Zl+1(z)
Yl(z)
Zl(z)
Yl−1(z)
Zl−1(z)
∗
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
≡
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∗
Yl+1(z)
Xl(z)
Yl(z)
Xl−1(z)
Yl−1(z)
Xl−2(z)
∗
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
= W(z)ε(z)
(5)
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∗∗
0
∗
0
∗
0
∗
0 ∗
∗0 W y
l+1(z) W yx
l
(z)
0
W yx
l−1(z)
0
W yx
l−2(z) 0 ∗
∗0
0
W x
l (z)
0
W x
l−1(z)
0
W x
l−2(z) 0 ∗
∗0
0
0
W y
l (z) W yx
l−1(z)
0
W yx
l−2(z) 0 ∗
∗0
0
0
0
W x
l−1
0
W x
l−2(z) 0 ∗
∗0
0
0
0
0
W y
l−1 W yx
l−2(z) 0 ∗
∗0
0
0
0
0
0
W x
l−2(z) 0 ∗
∗0
0
0
0
0
0
0
∗∗
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∗
∗
εy
l+1(z)
εx
l (z)
εy
l (z)
εx
l−1(z)
εy
l−1(z)
εx
l−2(z)
∗
∗
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
In case the formal transfer functions in the operator above are all rational, then there
exists a stochastic realization of the temporal process {(Xt, Yt, Zt); t ≥0} (taking val-
ues in R2n+m for each k component) whose state space is a shift invariant subspace
of 0 H and whose inﬁnite input matrix, and inﬁnite (diagonal block wise asymptoti-
cally stable) state transition matrix and inﬁnite output matrix all possess the block zero
pattern of (5) and hence of the TDAG T(F).
As is to be expected from the role of Teoplitz matrices in theory of wide sense sta-
tionary time series, the spatio-temporal operator W has a Teoplitz form. In (5) the

56
P.E. Caines and H.P. Wynn
diagonal shift invariance of the operator W corresponds to the stationarity of the spa-
tial process on the chain recurrent TDAG T(F). We may take the formal ω transform
of the representation (5) of the family F so that powers of ω index spatial shifts of the
triple of temporal processes {(Xk,t, Yk,t, Zk,t); t ≥0} and to spatial shifts in the action
of the spatial impulse response matrix of W. This permits us to write (5) in the compact
form
' Y (z, ω)
Z(z, ω)
(
≡
' Y (z, ω)
X(z, ω)
(
=
' W y(z, ω) W yx(z, ω)
0
W x(z, ω)
( ' εy(z, ω)
εx(z, ω)
(
(6)
The representation (6) clearly reveals the feedback free structure of the spatio-
temporal processes (Y, Z) ≡(Y, X) associated to the chain recurrent TDAG T(F).
It may be seen that, subject to conditions ensuring that the operator W is invertible, the
transformation between the inﬁnite moving average and inﬁnite autoregressive space-
time representations of (Y, Z) ≡(Y, X) becomes evident and is susceptible to analysis.
(We note that in the ﬁnite TDAG case the invertibility condition was made explicit in
terms of the full rank condition on the (rational) spectral density matrix on the unit cir-
cle of the vector of all processes on the TDAG.) Furthermore, the sequential operation
of linear operations on the processes attached to T(F) may be formalized using repre-
sentations of the form (6) in the manner of the Concatenation Theorem of Caines ( [7],
Chapter 2).
Projectors and the Subset Lattice
It is possible using the Teoplitz structures above to describe the algebraic machinery
of the Boolean lattice L and the subset lattice B(L). The association is that the struc-
ture of the observation space, and its conditional independence structure subject to the
feedback free condition, is given by the associated TDAG T. Hence the associated
set of projectors has the subset lattice B(L) derived from T as described in Section
3. Evidently, for arbitrary countably inﬁnite TDAGs there will not necessarily be any
particular structure to exploit. However, as has been illustrated in the chain recurrent
TDAG case with its associated Toeplitz structure, there exist inﬁnite TDAGs with reg-
ularity properties for which the analysis and computation of the lattice of projectors
could well be tractable.
References
1. Andersson S. A. and Perlman M. D., Lattice models for conditional independence in a mul-
tivariate normal distribution, Ann. Statist. 21 (1993), 1318–1358.
2. Andersson S. A. and Madsen J., Symmetry and lattice conditional independence in a multi-
variate normal distribution, Ann. Statist. 26 (1998), 525–572.
3. Lindquist A. and Picci G., A hardy space approach to the stochastic realization problem,
Proceedings of the 1978 Conference Decision and Control (1978), 933–939.
4.
, On the stochastic realization problem, SIAM J. Control Optim. 17 (1979), no. 3,
365–389.
5.
, State space models for Gaussian stochastic processes in Stochastic Systems: The
Mathematics of Filtering and Identiﬁcation and Applications, pp. 169–204, Pub: Reidel,
Dordrecht, 1981, Ed: M. Hazewinkel and J. C. Willems.

An Algebraic Framework for Bayes Nets of Time Series
57
6. Perlman M. D. Andersson S. A., Madigan D. and Trigg C. M., On the relationship be-
tween conditional independence models determined by ﬁnite distributive lattices and directed
acyclic graph, J. Stat. Plan. Inf 48 (1995), 25–46.
7. Caines P. E., Linear Stochastic Systems, New York; Chichester: Wiley, 1988.
8. Akaike H., Stochastic theory of minimal realization, IEEE Trans. Autom. Control 19 (1974),
667–674.
9.
, Markovian representation of stochastic processes by canonical variables, SIAM J.
Control Optim. 13(1) (1975), 162–173.
10. R.V. Kadison and J.R Ringrose, Fundamentals of the theory of operator algebras, volume 1,
Graduate studies in mathematics, vol. 15, American Mathematical Society, San Diego, 1983.
11. L. Lauritzen, Graphical Models, Clarendon Press, Oxford, 1996.
12. Eichler M, A graphical approach for evaluating effective connectivity in neural systems, Phil.
Trans. Roc. Soc. B 360 (2005), 953–967.
13. Caines P. E. Deardon R. and Wynn H., Conditional orthogonality and conditional stochastic
realization, Directions in Mathematical Systems Theory and Optimization, Lecture Notes in
Control and Inform. Sc, A.Rantzer and C.I. Byrnes (Eds.) 286 (2003), 71–84.
14.
, Bayes nets of time series: stochastic realisations and projections, Optimal Design
and Related Areas in Optimization and Statistics, Springer Lecture Notes, L. Pronzato and
A. Zhigljavsky (Eds.) (2007), 153–164.
15. Dahlhaus R., Graphical interaction models for time series, Metrika 51 (2000), 151–72.
16. Johnstone P. T., Stone Spaces, Cambridge studies in advanced mathematics, vol. 3, American
Mathematical Society, Cambridge, 1982.

A Birds Eye View on System Identiﬁcation
Manfred Deistler
Institut f¨ur Wirtschaftsmathematik
Forschungsgruppe ¨Okonometrie und Systemtheorie
Technische Universit¨at Wien
Argentinierstraße 8 / 105-2 A-1040 Wien
Manfred.Deistler@tuwien.ac.at
Summary. System identiﬁcation is concerned with obtaining good models from data, i.e. with
data driven modeling. In this contribution the aim is to explain and discuss ideas, general ap-
proaches and theories underlying identiﬁcation of linear systems. Identiﬁcation of linear systems
is a nonlinear problem and is “prototypical” also for many parts of identiﬁcation of nonlinear
systems.
1
Introduction
The art of identiﬁcation is to ﬁnd a good model from, in general, noisy data. This is
an important problem in many areas of application. Often the task of identiﬁcation is
so complex, that it cannot be performed with the naked eye and systematic approaches
have to be used. This is done, partly under quite different perspectives, in statistics,
econometrics, system theory and the ﬁeld of inverse problems.
The main steps in identiﬁcations are:
•
Speciﬁcation of the model class, i.e. of the class of all a priori feasible candidate
systems. In this step the a priori information concerning the phenomenon to be
modeled is incorporated. This typically includes, for instance, the selection of (can-
didates for) the input-variables or assumptions on the relation between the variables.
•
Speciﬁcation of the class of observations, data preprocessing.
•
Identiﬁcation in the narrow sense: An identiﬁcation procedure is a rule, in the auto-
matic case a function, attaching a system from the model class to the data. In this
step the emphasis is on the development of procedures and algorithms on one side
and on their evaluation on the other side.
Here only identiﬁcation from equally spaced, discrete time, time series data yt =
(y(i)
t )i=1...s ∈R, t = 1 . . . T is considered. For explanation of time series data, dy-
namic systems are often natural candidates.
In this contribution the focus is on what we call the main stream theory for identiﬁca-
tion of linear systems (see [6], [7]). We add a few remarks on alternative model classes
and approaches for identiﬁcation of linear systems and on identiﬁcation of nonlinear
systems.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 59–71, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

60
M. Deistler
The mainstream theory of identiﬁcation deals with the following setting:
•
The model class consists of linear, time-invariant, ﬁnite dimensional, causal and
stable systems only. The classiﬁcation of the variables into inputs and outputs is
given a priori.
•
Uncertainty is modeled by the use of stochastic models for noise. In particular here
the noise is assumed to be stationary with a rational spectral density. These assump-
tions on the noise are in a sense standard, but are nevertheless not innocent. The
have been criticized on grounds of not being justiﬁed in a number of applications
(see e.g. [25]). In our opinion, stochastic noise models are at least an important ”test
bed“ for evaluating identiﬁcation procedures.
•
The observed inputs are free of noise and uncorrelated with the noise process.
•
The approach to estimation is semi-nonparametric in the following sense: In general
the parameter space for describing system- and noise parameters will be not ﬁnite-
dimensional, since e.g. systems of arbitrarely high orders are considered. In this
approach the model class is broken down into subclasses such that each subclass
has a ﬁnite- dimensional parameter- space. Estimation then consists of two steps:
The model selection step, where the subclass is estimated by a vector of integers,
characterizing this subclass. Once the subclass is obtained, its parameter-space is a
subset of a suitable Euclidian space and estimation is concerned with estimating a
parameter, which is a vector of real-valued entries, in this space.
•
For the statistical analysis, emphasis is laid on asymptotic properties (consistency,
asymptotic normality and asymptotic efﬁciency), mainly because ﬁnite sample
properties are hard to obtain analytically.
We consider the following three “modules” in the theory of system identiﬁcation:
•
Structure theory: Here an idealized problem is considered, as we commence from
the stochastic processes generating the data or their population second moments
rather than from the data. In the ergodic case one could also say that we com-
mence from an inﬁnite, rather than from a ﬁnite data string. The relation between
“external behavior” (as described e.g. by the population second moments of the
observations) and “internal” (system and noise-) parameters is analysed.
Iden-
tiﬁabilty, realization- and parametrization theory are important parts of structure
theory.
•
Estimation of real-valued parameters for a given subclass: Here we commence from
a given subclass whose parameter space is a subset of an Euclidean space and in ad-
dition contains a non-void open subset of this space. Estimators are often found
from general principles, here in particular from optimizing a likelihood-type crite-
rion function over the parameter-space.
•
Model selection: In general the orders or the relevant inputs are not known a priori
and have to be determined from the data. One way of doing this is e.g. estimation
of integers characterizing the orders by information criteria like AIC or BIC, or,
more generally by using a criterion deﬁning a trade-off between the quality of ﬁt
to the data achievable in a certain model-subclass and the complexity of this sub-
class.

A Birds Eye View on System Identiﬁcation
61
2
Structure Theory
As has been stated already, structure theory is concerned with an analysis of the rela-
tion between external behavior and internal parameters. Such an analysis turns out to be
important for a deeper understanding of many identiﬁcation procedures. For the linear
mainstream case, the relation between the population second moments of the obser-
vations or equivalently the transfer-functions (and noise covariance matrices) and the
system (and noise) parameters is considered.
Main model classes for linear systems are:
•
AR(X) models
•
ARMA(X) models
•
State space models
In many applications AR(X) systems still dominate for a number of reasons. Main
advantages of (unrestricted), AR(X) models are:
•
There are no problems of non-identiﬁability; in more general terms structure theory
is so simple, that for standard situations it does not have to be considered separately.
•
Least squares estimators are of maximum likelihood type; they are explicitly given,
fast to calculate and asymptotically efﬁcient.
Things are different in case of “structural” a priori restrictions (i.e. if restrictions on
the parameter space are imposed by a priori knowledge); but nevertheless, also then
AR(X) system identiﬁcation is “easier” compared to the ARMA(X) or state space
case.
On the other hand AR(X) models are less ﬂexible than ARMA(X) and state space
models in the sense that, in general, more parameters are needed to achieve the same
quality of approximation.
In this contribution, we will mainly consider the case where we have no observed
inputs.
Here the focus is on state space systems, but we also consider the ARMA(X) case.
A state space system in innovations representation is of the form
xt+1 = Axt + Bϵt(+Lzt)
(1)
yt = Cxt + ϵt(+Dzt)
(2)
where yt are the s-dimensional outputs, xt is the n-dimensional state, (ϵt) is, in general
unobserved, s-dimensional white noise (i.e. Eϵt = 0, Eϵsϵ
′
t = δstΣ, where E denotes
expectation and δst is the Kronecker symbol) and zt are the m-dimensional observed
inputs. The random variables yt, xt, ϵt and zt are deﬁned over an underlying probability
space (Ω, A, P). A ∈Rn×n, B ∈Rn×s, L ∈Rn×m, C ∈Rs×n and D ∈Rs×m are
parameter matrices.
Throughout we assume that the stability condition
|λmax(A)| < 1
(3)
where λmax denotes an eigenvalue of maximum modulus, and the miniphase
condition

62
M. Deistler
|λmax(A −BC)| ≤1
(4)
hold. The steady state solution of (1) (2) is given by
yt = C(Iz−1 −A)−1(Bϵt(+Lzt)) + ϵt(+Dzt)
(5)
Here z is used for a complex variable as well as for the backward shift on the integers
Z, i.e. z(yt|t ∈Z) = (yt−1|t ∈Z).
In addition, throughout we assume that Ezsϵ
′
t
=
0 holds and that Σ is
nonsingular.
ARMA(X) systems are (vector-) difference equations of the form
a(z)yt = b(z)ϵt(+d(z)zt)
(6)
where
a(z) = Σp
j=0ajzj
;
b(z) = Σq
j=0bjzj
;
d(z) = Σr
j=0djzj
;
aj; bj ∈Rs×s
;
dj ∈Rs×m
We assume that the stability condition
det a(z) ̸= 0
|z| ≤1
(7)
and the miniphase condition
det b(z) ̸= 0
|z| < 1
(8)
hold, and again we assume
Ezsϵ
′
t = 0
and that Σ is nonsingular. The steady state solution then is given by
yt = a−1(z)[b(z)ϵt(+d(z)zt)]
(9)
Note that by (3) or (7) (and by assuming stationarity for (zt)) the inﬁnite sums in (5)
and (9) respectively, i.e.
yt = Σ∞
j=0kjϵt−j(+Σ∞
j=0ljzt−j)
(10)
where, e.g,
kj = CAj−1B
,
j > 0
,
k0 = I
(11)
and
k(z) = Σ∞
j=0kjzj = a−1(z)b(z)
(12)
converge e.g. in the mean squares sense. In addition (yt) and (xt) are stationary pro-
cesses.
From now onwards, we will, for the sake of brevity of notation, unless the contrary
is stated explicitly, restrict ourselves to the case, where there are no observed inputs.
Then the external behavior of (1), (2) or (6) is described by the covariance function

A Birds Eye View on System Identiﬁcation
63
γ : Z →Rs×s, γ(t) = Eyty′
0 of the process (yt) or equivalently by its spectral density
f : [−π, π] →Cs×s deﬁned by
f(λ) = (2π)−1Σ∞
t=−∞e−iλtγ(t)
(13)
From (10), f is given by
f(λ) = (2π)−1k(e−iλ)Σk∗(e−iλ)
(14)
where ∗denotes the conjugate transpose. Throughout we assume k(0) = I. This
implies no restriction for f and establishes a one-to-one relation between f and (k, Σ).
Under our assumptions,
•
Every state space system (1) (2) and every ARMA system (6) has a rational transfer
function k(z) which is analytic in a disk containing the closed unit disk (and thus is
causal and stable) and which satisﬁes det k(z) ̸= 0, |z| < 1.
•
Conversely, for every rational transfer function k(z) which is analytic in a disk
containing the closed unit disk and which satisﬁes det k(z) ̸= 0, |z| < 1 and
k(0) = I there is a stable and miniphase state space -, and a stable and miniphase
ARMA representation.
Thus, in particular, state space- and ARMA representations are two alternative ways
to describe the same class of external (input/output) behaviors k(z). Note that the as-
sumption k(0) = I is a normalizing condition deﬁning Σ. We have ( [14], chapter 1):
Any rational and a.e. nonsingular spectral density matrix f may be uniquely factor-
ized as in (14) where k(z) is rational, analytic whithin a circle containing the closed
unit disk, det k(z) ̸= 0, |z| < 1 and k(0) = I and where Σ > 0.
Consider the following set of s×s transfer functions: UA = {k|k is rational, k(0) =
I, k(z) has no poles for |z| ≤1 and no zeros for |z| < 1}. By M(n) ⊂UA we denote
the set of all transfer functions of order n (to be more precise, the set of all transfer
functions corresponding to minimal state space systems with state dimension n). By TA
we denote the set of all triples (A, B, C), where s is ﬁxed but n is arbitrary, satisfying
(3) and (4), by S(n) ⊂TA the subset of all (A, B, C) for ﬁxed n and by Sm(n) ⊂S(n)
the subset of all minimal (A, B, C). We deﬁne the mapping π : TA →UA such that
π(A, B, C) = C(Iz−1 −A)−1B + I (also deﬁned by (11)).
Now, TA is not a “good” parameter space because:
•
TA is not ﬁnite dimensional.
•
π is (surjective but) not injective, i.e. we do not have identiﬁability.
•
There exists no continuous selection, in the sense that there is no continuous map-
ping attaching to every k ∈UA a unique element from the equivalence class
π−1(k).
Here UA is endowed with the so called pointwise topology Tpt [14] which corresponds
to the relative topology in the product space (Rs×s)N for the coefﬁcients (kj|j ∈N).
In order to obtain “good” parameter spaces, UA and TA are broken into bits, Uα and
Tα say, α ∈I such that
•
π restricted to Tα, π/Tα : Tα →Uα is bijective. Injectivity of π/Tα implies identi-
ﬁability.

64
M. Deistler
•
Uα is ﬁnite dimensional in the sense that Uα ⊂∪n
i=1M(i) for some n. Usually,
taking into account the restrictions in Tα, Tα is reparametrized by expressing the
(A, B, C) ∈Tα by their “free” parameters, τ say. We use Tα also for this set of
free parameters τ and we assume that this Tα contains an open set in an embedding
Euclidian space Rdα. The mapping Ψα : Uα →Tα: Ψα(π(τ)) = τ ∀τ ∈Tα is
called a parametrization.
•
The parametrization Ψα : Uα →Tα is a homeomorphism; this is an assumption of
well-posedness.
•
Uα is Tpt-open in its closure U α
•
∪α∈I Uα is a cover of UA
Usually, I is a set of vectors of integers (multiindices) characterizing the bits Uα and
Tα. Note that not all approaches used have the desirable properties listed above.
Completely analogous statements hold for the ARMA case, where (using the same
symbols) the mapping π is deﬁned by π(a, b) = a−1b.
The most common approaches are:
•
Canonical forms deﬁning decompositions of M(n), such as echelon forms [14]
or balanced realizations.
Here M(n) is decomposed into sets Uα of different
dimension. Echelon forms for state space and ARMA systems have “nice” free
parameters in terms of elements of (A, B, C), and of (a, b) and deﬁne a very sim-
ple bijection between state space and ARMA parameters. Balanced realizations
(which only exist for state space systems) have “nice” parameter spaces, but the free
parameters are rather complicated transformations of the elements of (A, B, C).
•
The overlapping description of the manifold M(n) by local coordinates ( [14]).
•
The “full parametrization”for state space systems. Here S(n) ⊂Rn2+2ns or Sm(n)
are used as parameter spaces for M(n) (the closure of M(n) in UA) or M(n) re-
spectively. Clearly in this case we do not have identiﬁability. For k ∈M(n), the
classes of observationally equivalent (A, B, C), π−1(k)∩S(n) are n2-dimensional
manifolds.
•
Data driven local coordinates, DDLC, for state space systems. Here Sm(n) is
reparametrized in terms of coordinates that separately describe the tangent space to
the manifold of observationally equivalent (minimal) systems corresponding to an
initial estimator at a suitably chosen point and its 2ns-dimensional orthocomple-
ment [18], [20]. The orthocomplement then is taken as the new parameter space.
•
ARMA systems with prescribed column-degrees ( [5])
•
ARMA parametrizations commencing from writing k as c−1p where c is a least
common denominator polynomial for k and where the degrees of c and p serve as
integer valued parameters.
3
Estimation for a Given Subclass
Here we commence from the data yt, t = 1 . . . T and we assume that Uα is given. We in
addition assume that we have identiﬁability and that the parametrization Ψα : Uα →Tα
has the desirable properties listed above.

A Birds Eye View on System Identiﬁcation
65
Let τ ∈Tα ⊂Rdα denote the vector of free parameters for Uα and let σ ∈Σ ⊂
R
n(n+1)
2
denote the vector formed by the on and above diagnonal elements of Σ. Σ
corresponds to the set of symmetric positive deﬁnite matrices. We assume that the
overall parameter space is of the form Θ = Tα × Σ.
Many identiﬁcation procedures, at least asymptotically, commence from the sample
second moments of the observations:
ˆγ(s) = T −1ΣT −s
t=1 yt+syt
′,
s ≥0
Now, ˆγ can be directly realized as an MA system, “typically” of order T.s. By ˇkT we
denote the corresponding transfer function. Clearly, in many cases, its order is too high.
“Typical” identiﬁcation procedures therefore consist of two steps:
•
A “projection” or model reduction step, where e.g. ˇkT is approximated by an el-
ement ˆkT say, in Uα (Uα). From a statistical point of view, this is the essential
information concentration step and the statistical properties depend on the way the
approximation is deﬁned.
•
A realization step, where ˆkT ∈Uα is realized by τ ∈Tα. This step is important for
a number of reasons, for instance from a numerical point of view, however certain
statistical properties do not depend on this step.
One may distinguish between two types of estimation procedures, namely:
•
Optimization based procedures (M-estimators), which are obtained from optimiz-
ing a criterion function over the parameterspace and where the estimators are not
given explicitly
and
•
Direct procedures, such as instrumental variable methods or subspace methods,
where the estimators are explicit functions of the data
The most common criterion function is the Gaussian (log) likelihood function, which
(when multiplied by −2T −1) is (up to a constant) of the form
ˆLT (θ) = T −1logdetΓT (θ) + T −1y′(T )ΓT (θ)−1y(T )
(15)
where y(T ) = (y′
1, . . . , y′
T )′ is the stacked vector of observations, θ = (τ′, σ′)′ is the
vector of system and noise parameters, y(T ; θ) is a stacked vector of random variables
formed from the outputs of systems with system and noise parameters θ, (in an anal-
ogous way as y(T )) and ﬁnally ΓT (θ) = Ey(T ; θ)y(T ; θ)′. The Gaussian maximum
likelihood estimator (MLE) then is deﬁned by
ˆθT = argminθ∈Θ ˆLT(θ)
It is well known that, although the likelihood is written down as if the observations were
Gaussian the asymptotic properties of the MLE do not depend on the Gaussianity of the
observations. In addition, for the likelihood (15), the Gaussian distribution is assumed
to come from a stationary process; transients in the observations do not inﬂuence the
asymptotic properties of the MLE.

66
M. Deistler
There exist a number of alternative criterion functions such as the Whittle Likelihood
of Ljung’s prediction error criterion [17] which (in most cases) give asymptotically
equivalent estimators. The Whittle likelihood is of the form:
ˆLw,T(k, σ) = logdetΣ + (2π)−1
 π
−π
tr[(k(e−iλ)Σk∗(e−iλ))−1I(λ)]dλ
(16)
where tr denotes the trace and I is the periodogramm, i.e. the Fourier transform of ˆγ.
Formula (16) shows the approximation of I by k ∈Uα in a clear way.
In maximum likelihood estimation a number of observations are important:
•
For “natural” parameter spaces, the likelihood function is not necessarily semi-
continuous and thus the existence of its optimum is not guaranteed (see [10]).
•
In general, the MLE is not given by an explicit function of the data; thus the esti-
mators are obtained by a numerical optimization procedure.
•
ˆLT depends on τ only via the corresponding transfer function k, thus (with a
slight sloppyness in notation) we may deﬁne a “coordinate-free” likelihood func-
tion ˆLT (k, σ).
•
Neither Tα nor Uα are closed sets and boundary points may occur in optimizing the
likelihood function (see [14]).
As far as consistency of the MLE’s is concerned, the ﬁrst correct proofs have been
given in [12] (for the univariate case) and [11], [8], for a general result see also [14].
Coordinate free consistency says that for k0 ∈U α (where k0 denotes the true system)
and if limT −1ΣT −s
t=1 εt+sε
′
t = δ0,sΣ0 a.e. we have for the MLE’s ˆkT →k0 a.e. and
ˆΣT →Σ0 a.e. The proof uses the basic idea of [24] developed for the i.i.d. case.
The speciﬁc additional difﬁculties are not only due to the fact that the observations are
dependent, but also due to the fact that the “natural” parameter spaces are not compact.
As can be shown
limT →∞ˆLT (k, σ) = L(k, σ) =
(17)
logdetΣ + (2π)−1
 π
−π
tr[(k(e−iλ)Σk∗(e−iλ))−1
(k0(e−iλ)Σ0k∗
0(e−iλ))]dλ
a.e.
holds, where the subscript 0 again denotes the true quantities and the asymptotic likeli-
hood L has a unique minimum at k0, Σ0. (Note the similarity of (16) and L). Clearly
pointwise convergence in (17) alone does not ensure convergence of the optima, but in
our case, the latter can be shown, in particular since (ˆkT , ˆΣT ) can be shown to enter a
compact set. For a detailed proof of the consistency result, see [14], chapter 4.
Even for k0 ̸∈U α, the MLE’s have a “generalized consistency” property, as they
converge a.e. to the set D of minimizes of L over Uα × Σ.
Now consistency “in coordinates”, i.e. for the parameter estimators ˆτT = ψα(ˆkT )
follows directly from the consistency of ˆkT and the continuity of ψα (and from the
openness of Uα in U α), if τ0 ∈Tα holds.

A Birds Eye View on System Identiﬁcation
67
Under additional assumptions (see [14]) asymptotic normality can be shown by using
the idea explained in [4], extended to the stationary case.
For actual calculation of estimators, the usual procedure consists of a consistent ex-
plicit estimator, e.g. a subspace procedure, to obtain an initial estimator in the ﬁrst step
and one Gauß-Newton step is order to obtain an asymptotically efﬁcient estimator.
If Tβ denotes a parameterspace obtained by a diffeomorphic mapping from Tα, then
the transformation of the asymptotic distributions of the MLE’s is straightforward;
nevertheless the choice of parameterspaces turns of to be important from a numerical
point of view, where it is taken into account that optimization has to be performed over
a grid.
Explicit estimation procedures are usually numerically fast and reliable, but are in
many cases not asymptotically efﬁcient. Recently so called subspace identiﬁcation pro-
cedures [1], [15], [23] have attracted a lot of attention. Subspace estimators are for
state space systems and they are based on a realization algorithm combined with a
model reduction step. Usually the model reduction step is performed by omitting the
smaller eigenvalues in a singular value decomposition. For the case of observed inputs,
subspace procedures turn out be more intricate. The statistical properties of classes
subspace procedures have been investigated e.g. in [9], [3] and [2].
4
Model Selection
Here we conﬁne our discussion to the problem of estimating the model order n. In many
cases information criteria deﬁning a trade-off between the quality of ﬁt achievable in a
certain model-subclass and the complexity of this subclasses are used for this purpose.
Note that we here have a situation which is “closure nested”, i.e. n1 < n2 implies
M(n1) ⊂M(n2) and the dimension of M(n1) is smaller than the dimension of M(n2).
In particular criteria of the form
A(n) = logdet ˆΣT(n) + 2ns.c(T )T −1
(18)
where ˆΣT (n) is the MLE of Σ0 over M(n) × Σ and c(T ) is a prescribed positive
function of T , are frequently used. For c(T ) = 2 we obtain the AIC, for c(T ) = logT ,
the BIC criterium. The corresponding order estimate ˆnT is obtained by minimizing
A(n) (in a certain range of integers).
The statistical properties of such estimators have been analysed by Hannan [13],
see also [14], chapter 5. In particular (under suitable additional assumptions) ˆnT is
(strongly) consistent if
limT →∞
c(T )
T
= 0
and
liminfT →∞
c(T )
loglogT > 0
hold (and thus BIC gives consistent estimators) and AIC does not give consistent
estimators, and asymptotically leads to overestimation of the true order n.
Taking a closer look, things turn out to be more subtle. One may argue, as has
been done, e.g. in [22], that in most cases order estimation is only an intermediate

68
M. Deistler
goal. Shibata showed that under certain assumptions, in particular if the true system
is of inﬁnite order, an autoregressive spectral estimate based on AIC and MLE is
asymptotically optimal.
Here we concentrate on two issues. The ﬁrst one may be entitled “decomposition into
subclass is in the eye of the beholder”. Consider e.g. AR models for s = 1 of the form
yt + a1yt−1 + a2yt−2 = ϵt
Then, considering only the system parameters, “usually” we have the following param-
eterspaces:
T = {(a1, a2) ∈R2|1 + a1z + a2z2 ̸= 0|z| ≤1}
T0 = {(0, 0)}
T1 = {(a1, 0)||a1| < 1, a1, a1 ̸= 0}
T2 = T −(T0 ∪T1)
and we want to make a data driven choice between T0, T1 and T2.
Now, from the Bayesian derivation of BIC [21] we see that, in order to obtain BIC,
T0, T1 and T2 must have strictly positive prior probabilities; thus BIC has to be justiﬁed
by some kind of a priori knowledge. For instance a ﬂat prior on T would suggest just
to use the MLE over T , rather than to do model selection in a ﬁrst step. In addition
other prior distributions may give positive prior probabilities to other low dimensional
subsets of T and thus result in an other decomposition of T .
The second issue is concerned with properties of post model selection estimators,
i.e. with properties of estimators for real-valued parameters taking into account the
uncertainty coming from model selection. One may argue, that, if a (strongly) con-
sistent model selection criterion is used, then the true model order is known from a
certain sample size onwards and thus the asymptotic variance of the estimators for τ
after model selection is the same as in the case where the true order is a priori known.
As has been shown in [16] this argument is grossly misleading, because it is pointwise
in the parameterspace and does not hold uniformly there.
5
Linear Non-mainstream Cases
In a number of important cases, the systems are linear, but the models or their identiﬁ-
cation is not in the mainstream setting. We do not intend to give a survey on such cases
here, but we only make a few remarks. Important special cases are:
•
Linear systems with time-varying parameters. There several different approaches to
this problem, such as systems with slowly varying parameters, where the variation
of coefﬁcients is described by an autoregression, or systems with structural changes,
which may be triggered by a random mechanism, such as Markov switching models,
or smooth transition models.
•
Identiﬁcation in closed loop.
•
The wide area of symmetric modeling, where no a priori distinction between inputs
and outputs is made, errors-in-variables and linear dynamic factor models; the latter
are used in particular for high dimensional time series.

A Birds Eye View on System Identiﬁcation
69
•
Unstable systems, in particular integration and cointegration, which is of great im-
portance for econometrics.
•
Long memory
6
Nonlinear Systems
Of course there is a wide range of nonlinear systems and identiﬁcation of nonlinear
systems is a word like “non-elephant zoology” (also in the sense that linear systems are
“huge animals”). Again, as in section 5, we do not intend to give a survey on this topic,
we only make a few remarks on this ﬁeld. Identiﬁcation of nonlinear systems consists
of a number of only weakly connected subareas. The most important of these subareas
are:
•
The asymptotic theory for M-estimation for parametric classes of nonlinear dy-
namic systems, see e.g. [19]. Identiﬁcation of linear systems is a nonlinear problem,
since the mapping from data to parameters is nonlinear. Identiﬁcation of nonlinear
systems uses partly the same ideas as identiﬁcation of linear systems. The main
problem in the setting of nonlinear systems is, that there is no general structure
theory available, and thus, for instance identiﬁability is often assumed rather than
shown.
•
Neural nets are a frequently used model class also for time series. Recurrent neural
nets are a particular class of dynamic nonlinear models. Identiﬁcation of neural nets
is a semi-nonparametric problem.
•
Nonparametric estimation for nonlinear time series models, e.g. estimation of non-
linear autoregressions
yt = g(yt−1, . . . , yt−p) + ϵt
(19)
by kernel methods is, an area which has received substantial attention in the last
two decades. The systems (19) can be generalized by replacing ϵt by a model for
the conditional variance of yt. Another important class in this area are so called ad-
ditive models, which are MISO models, where the effects of the single inputs are
nonlinear but additive, i.e. there is no interaction effect of different single inputs.
Of central interest for nonparametric estimation is the choice of design parameters,
such as the bandwidth of a kernel, and, in asymptotic theory e.g. the rates of con-
vergence.
•
Special classes of nonlinear systems, justiﬁed by “physical” a priori knowledge
or “stylized facts” in data, such as GARCH-type models or stochastic volatility
models for explaining or forecasting conditional variances, in particular for ﬁnance
data, have attracted a substantial number of researchers recently.
•
Chaotic systems and their identiﬁcation have been considered in the last 25 years,
but the number of convincing success stories in applications seems to be limited.
7
Present State and Future Developments
Theory and methods in system identiﬁcation have reached a certain state of maturity.
There is a large body of methods and theory available serving the needs for many

70
M. Deistler
applications, but nevertheless, in many cases, identiﬁcation is still not a standard task
and needs a special design by an expert.
On the other hand, the areas and the number of applications, are increasing rapidly.
Application ﬁelds like medicine, biology or ﬁnance are “boom areas” and pose a num-
ber of new and interesting questions.
The development of system identiﬁcation now is more driven by demand from appli-
cations than by developments in theory, i.e. there is “demand pull” rather than “theory
push”.
One can also observe an increasing fragmentation corresponding to different data
structures, model classes and prior knowledge in different ﬁelds of application. The
development of theory and methods is also done by different, not very much interacting
communities, like econometrics, system- and control theory or signal processing.
System identiﬁcation is in a certain sense an enabling technology and in many cases
not visible for non-experts.
There are still major open problems in system identiﬁcation, such as
•
large parts of identiﬁcation of nonlinear systems
•
Identiﬁcation of spatio-temporal systems
•
Identiﬁcation for large data sets data and for high dimensional time series
•
Improved model selection and regularization procedures
•
Further automatization
•
Hybrid procedures
•
The use of symbolic computation
Summing up, system identiﬁcation is still an interesting area, in particular new appli-
cations pose new challenges. The ﬁeld has shifting boundaries and the question arises,
whether in the future there will be still a substantial common body of theory and meth-
ods. Besides the danger of fragmentation, for certain parts of the ﬁeld, there is also the
danger of becoming selfreferential and not relevant for applications.
References
1. H. Akaike, Canonical Correlations Analysis of Time Series and the Use of an Information
Criterion, in: R.H. Mehra and D.G. Lainiotis, eds., System Identiﬁcation: Advances and
Case Studies, Academic Press, New York, 27 −96, 1976.
2. D. Bauer, Comparing the CCA Subspace Method to Pseudo Maximum Likelihood Methods
in the Case of No Exogenous Inputs, Journal of Time Series Analysis, 26, 631-668, 2005.
3. A. Chiuso and G. Picci, The Asymptotic Variance of Subspace Estimates, Journal of Econo-
metrics, 118, 292-312, 2003.
4. H. Cramer, Mathematical Methods of Statistics, Princeton University Press, Princeton, 1946.
5. M. Deistler, The Properties of the Parametrization of ARMAX Systems and Their Rel-
evance for Structural Estimation and Dynamic Speciﬁcation,
Econometrica 51, 1983,
1187 −1208.
6. M. Deistler, System Identiﬁcation - General Aspects and Structure, in G. Goodwin (ed.)
System Identiﬁcation, and, Adaptive Control (Festschrift for B.D.O. Anderson), Springer,
London, 2001, 3 −26.
7. M. Deistler, Linear Models for Multivariate Time Series Analysis,, in: ”Handbook of Time
Series Analysis”, Matthias Wintherhalder, Bjoern Schelter, Jens Timmer, eds., Wiley-VCH,
Berlin, 2006, 283 −306.

A Birds Eye View on System Identiﬁcation
71
8. M. Deistler, W. Dunsmuir and E.J. Hannan, Vector Linear Time Series Models: Corrections
and Extensions, Adv. Appl. Probab., 10,1978, 360 −372.
9. M. Deistler, K. Peternell and W. Scherrer, Consistency and Relative Efﬁciency of Subspace
Methods, Automatica, 31, 1865-1875, 1995.
10. M. Deistler and B.M. Poetscher,
The Behaviour of the Likelihood Function for ARMA
Models, Adv. Appl. Probab., 16, 1984, 843 −865.
11. W. Dunsmuir and E.J. Hannan, Vector linear time series models, Adv. Appl. Probab., 8,
1976, 339 −364.
12. E.J.Hannan, The Asymptotic Theory of Linear Time Series Models, J. Appl. Probab. 10,
1973, 130 −145.
13. E.J.Hannan, Estimating the dimension of a linear system, J. Multivariate Anal. 11, 459-473,
1981.
14. E.J. Hannan and M. Deistler, The Statistical Theory of Linear Systems, Wiley, New York,
1988.
15. W.E. Larimore, System Identiﬁcation, Reduced Order Filters and Modeling via Canonical
Variate Analysis,
in: H.S. Rao and P. Dorato, eds., Proceedings of the 1983 American
Control Conference, 445-451, 1983.
16. H. Leeb and B.M. Poetscher, Model Selection and Inference: Facts and Fiction, Econometric
Theory, 21, 21 −59.
17. L. Ljung, System Identiﬁcation. Theory for the User, Prentice Hall; 2nd ed., 1998.
18. T. McKelvey and A. Helmersson, System Identiﬁcation using an Over-Parametrized Model
Class - Improving the Optimization Algorithm, in: Proceedings 36th IEEE Conference on
Decision and Control, San Diego, USA, 2984-2989, 1997.
19. B.M. Poetscher and I. Prucha, Dynamic Nonlinear Econometric Models: Asymptotic Theory,
Springer, New York, 1993
20. T. Ribarits, M. Deistler and McKelvey, An Analysis of the Parametrization by Data Driven
Local Coordinates for Multivariable Linear Systems, Automatica, 40, 789-803, 2004.
21. G. Schwarz, Estimating the dimension of a model, Ann. Statist., 6, 461-464, 1978.
22. R. Shibata, An optimal autoregressive spectral estimate, Ann. Statist., 9, 300-306, 1981.
23. P. Van Overschee and B. De Moor, Subspace Identiﬁcation for Linear Systems: Theory,
Implementation, Applications, Kluwer Academic Press, Boston, 1996.
24. A. Wald, Note on the consistency of the maximum likelihood estimate, Ann. Math. Stast.,
20, 595 −601, 1949.
25. J.C. Willems, Thoughts on System Identiﬁcation, in: B.A. Francis and J.C. Willems, eds.
Control of Uncertain Systems: Modelling, Approximation and Design (Festschrift for K.
Glover), Springer Lecture Notes in Control and Information Sciences, 389 −417, 2006.

Further Results on the Byrnes-Georgiou-Lindquist
Generalized Moment Problem⋆
Augusto Ferrante1, Michele Pavon2, and Federico Ramponi1
1 Dipartimento di Ingegneria dell’Informazione, Universit`a di Padova,
via Gradenigo 6/B, 35131 Padova, Italy
augusto@dei.unipd.it, rampo@dei.unipd.it
2 Dipartimento di Matematica Pura ed Applicata, Universit`a di Padova,
via Trieste 63, 35131 Padova Italy
pavon@math.unipd.it
Summary. In this paper, we consider the problem of ﬁnding, among solutions of a moment
problem, the best Kullback-Leibler approximation of a given a priori spectral density. We present
a new complete existence proof for the dual optimization problem in the Byrnes-Lindquist spirit.
We also prove a descent property for a matricial iterative method for the numerical solution of
the dual problem. The latter has proven to perform extremely well in simulation testbeds.
1
Introduction
The concept of positive real function, originating in Networks Theory with Brune in
1930, has proven to be one of the deepest and most unifying ones of electrical en-
gineering. Names such as Foster, Cauer, Bode, Darlington, Youla, Popov, Kalman,
Yakubovich, Faurre, B.D.O. Anderson, J.C. Willems spring to mind. The quest ﬁrst
posed by Kalman in 1964 for a realization theory for stochastic systems could rely
on these precious foundations. The strict sense version of the stochastic realization
problem (also called Markovian representation problem) has roots also in the theory of
Markov processes and in mathematical statistics (Bahadur transitive sufﬁcient statistics,
etc.). Giorgio Picci was one of the pioneers (together with McKean [39], Akaike [1,2]
and Ruckebusch [46]) in the early-mid seventies in this ﬁeld. Perhaps, among the fore-
runners, he was the only one that drew equal inspiration from both of these areas, due
to the fact that he had equal interest in the concepts of Systems Theory and of Math-
ematical Statistics [43, 44, 45]. Perhaps, this can be recognized as one of the main
characteristics of all of Giorgio’s rather diversiﬁed scientiﬁc production, which lays at
the interface between stochastic systems theory and mathematical statistics. Another
salient aspect of his research work is the taste for profound, foundational questions that
continues today, for instance, in his work on subspace methods identiﬁcation.
One of us (M.P.) had the privilege to witness the early days of the great Lindquist-
Picci collaboration [33]- [38], and to receive continuous, generous help from Giorgio
⋆Work partially supported by the MIUR-PRIN Italian grant “New Techniques and Applications
of Identiﬁcation and Adaptive Control”.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 73–83, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

74
A. Ferrante, M. Pavon, and F. Ramponi
both as a student and as a young researcher. The best way I can pay a personal tribute
to Giorgio as a scientist is to observe that, although I have interacted and continue
to interact with a large number and spectrum of colleagues, whenever there is a deep
question on the table, I still go or address people to Giorgio, precisely as I did more
than thirty years ago.
It is a joy to celebrate his devotion to science and research per se that continues
unabated to this day, and his manifold, benchmark contributions to stochastic systems
theory.
In this paper, we study a generalized moment problem for spectral densities in the
spirit of Byrnes-Georgiou-Lindquist [4, 6, 7, 8, 9, 10, 11, 17, 21, 22, 23, 24, 25, 26, 27,
40].
This problem includes as special case the covariance extension problem and
Nevanlinna-Pick interpolation for positive real functions. It also includes as special
case a maximum entropy problem which has been shown to be related to a special one-
step ahead Wiener-Kolmogorov prediction problem [27]. It features a Kullback-Leibler
type index. It lays, therefore, very much in the center of the ﬁeld in which Giorgio has
been active for some forty years.
In the Byrnes-Georgiou-Lindquist approach, the smooth parametrization of the solu-
tions to the generalized moment problem occurs in a convex optimization setting. The
Kullback-Leibler criterion, where optimization is performed with respect to the second
argument, is employed as cost index. Other distances between spectra have been re-
cently investigated in [18, 19, 28, 29]. The contribution of this paper is twofold: On
the one hand we provide a detailed and complete existence proof for the dual optimiza-
tion problem (Section 5) in the Lindquist-Byrnes spirit [11]. On the other hand, we
show that the matricial algorithm proposed in [41] for the numerical solution of the
dual problem may be viewed as a modiﬁed steepest descent method (Section 6).
2
A Generalized Moment Problem
Let S+(T) be the family of bounded, coercive, spectral density functions on the unit
circle. Thus, a measurable, bounded function Φ belongs to S+(T) if the values of Φ
are real and bounded away from zero. Notice that Φ ∈S+(T) if and only if Φ−1 ∈
S+(T). Let Ψ ∈S+(T) represent an a priori estimate of the spectrum of an underlying
zero-mean, wide-sense stationary stochastic process {y(k), k ∈Z}. Suppose we can
estimate the asymptotic covariance Σ of the n-dimensional stationary process {xk; k ∈
Z} satisfying
xk+1 = Axk + Byk,
k ∈Z,
(1)
where A is a stability matrix and the pair (A, B) is reachable. The rational transfer
function
G(z) = (zI −A)−1B,
A ∈Cn×n, B ∈Cn×1,
(2)
models a bank of ﬁlters. When Ψ is not consistent with Σ, we need to ﬁnd Φ ∈S+(T)
that is closest to Ψ in a suitable sense among spectra satisfying

G(eiϑ)Φ(eiϑ)G∗(eiϑ) = Σ,
(3)

Further Results on the Byrnes-Georgiou-Lindquist Generalized Moment Problem
75
where star denotes transposition plus conjugation. The Hermitian matrix Σ is assumed
to be positive deﬁnite and integration takes place on [−π, π] with respect to the normal-
ized Lebesgue measure dϑ/2π.
The question of existence of Φ ∈S+(T) satisfying (3) and, when existence is
granted, the parametrization of all solutions to (3), may be viewed as a generalized
moment problem. We refer to [30] and references therein for a full discussion on the
importance and on the manifold applications of such problem. Here, we only mention
that, by suitably choosing the matrices A and B, this problem reduces the celebrated
covariance extension problem, see [30] for details. Existence of Φ ∈S+(T) satisfying
constraint (3) is a nontrivial issue. It was shown in [23,24] that such family is nonempty
if and only if there exists H ∈C1×n such that
Σ −AΣA∗= BH + H∗B∗.
(4)
For simplicity of notation, we reformulate the constraint by normalizing Σ to the iden-
tity. Indeed, the set of solutions to (3) does not change if we replace (Σ, A, B) with
(I, A′ = Σ−1/2AΣ1/2, B′ = Σ−1/2B). Notice that in this way G is replaced by
G′ := Σ−1/2G. Thus constraint (3) from now on reads

GΦG∗= I.
(5)
3
Kullback-Leibler Criterion
In [30], the following problem is considered:
Problem 1. Given Ψ ∈S+(T), ﬁnd ˆΦ that solves
minimize
S(Ψ∥Φ)
(6)
over

Φ ∈S(T) |

GΦG∗= I

,
(7)
where S(Ψ∥Φ) is the Kullback-Leibler index:
S(Ψ∥Φ) =

Ψ log
Ψ
Φ

.
As is well known, this pseudo-distance originates in hypothesis testing, where it repre-
sents the mean information for observation for discrimination of an underlying proba-
bility density from another [32, p.6]. It also plays a central role in information theory,
identiﬁcation, stochastic processes, etc., see e.g. [3,12,13,15,20,31,42,48] and refer-
ences therein. It is also known in these ﬁelds as divergence, relative entropy, informa-
tion distance. etc. If

Φ =

Ψ,
we have S(Ψ∥Φ) ≥0. The choice of S(Ψ∥Φ) as a distance measure, even for spec-
tra that have different zeroth moment, is discussed in [30, Section III]. This choice is

76
A. Ferrante, M. Pavon, and F. Ramponi
essentially based on the possibility of rescaling Ψ. Clearly, in this way the optimiza-
tion problem amounts to approximating the “shape” of the a priori spectrum. In this
spirit, Georgiou has recently investigated other distances between rays of power spectra,
[28,29]. This is of course sensible to pursue in several engineering applications such as
speech processing or prediction problems.
4
Optimality Conditions and the Dual Problem
The variational analysis in [30] is outlined as follows (see also [41]). Let
L′
+ := {Λ = Λ∗∈Cn×n : G∗ΛG > 0, ∀eiϑ ∈T}.
(8)
For Λ ∈L′
+ consider the Lagrangian function
L(Φ, Λ) = S(Ψ∥Φ) + tr

Λ

GΦG∗−I

= S(Ψ∥Φ) +

G∗ΛGΦ −tr (Λ),
(9)
where “tr ” denotes the trace operator. Consider the unconstrained minimization of the
strictly convex functional L(Φ, Λ):
minimize{L(Φ, Λ)|Φ ∈S(T)}
(10)
This is a convex optimization problem.
Theorem 1. Suppose ˆΛ ∈L′
+ is such that

G
Ψ
G∗ˆΛG
G∗= I.
(11)
Then ˆΦ given by
ˆΦ =
Ψ
G∗ˆΛG
(12)
is the unique solution of Problem 1.
Thus, the original Problem 1 is now reduced to ﬁnding ˆΛ ∈L′
+ satisfying (11). We
deﬁne the linear operator Ξ : H →C(T) by Ξ(Λ) = G∗ΛG, where H is the set of
Hermitian matrices of dimension n × n and C(T) is the set of continuous functions on
T. Observe that if Λ ∈L′
+ satisﬁes (11), then, for all ΛK ∈ker Ξ, the sum Λ + ΛK
also belongs to L′
+ and satisﬁes (11). Hence, we may restrict the search for ˆΛ to the
orthogonal complement of ker Ξ i.e. to the range of the adjoint operator Γ := Ξ∗. It is
easy to see that the operator Γ is deﬁned by
Γ(Φ) =

GΦG∗,
Φ ∈C(T).
(13)

Further Results on the Byrnes-Georgiou-Lindquist Generalized Moment Problem
77
Thus, by setting
L+ := L′
+ ∩[ker(Ξ)]⊥= L′
+ ∩Range(Γ)
(14)
we are reduced to ﬁnd ˆΛ ∈L+ satisfying (11). This is accomplished via duality theory.
Consider the dual functional
Λ →inf{L(Φ, Λ)|Φ ∈S(T)}.
For Λ ∈L+, the dual functional takes the form
Λ →L

Ψ
G∗ΛG, Λ

=

Ψ log G∗ΛG −tr (Λ) +

Ψ.
(15)
Consider now the maximization of the dual functional (15) over the set L+. Let, as
in [30],
JΨ(Λ) := −

Ψ log G∗ΛG + tr (Λ).
(16)
The dual problem is then equivalent to
minimize
{JΨ(Λ)|Λ ∈L+}.
(17)
The dual problem is a strictly convex optimization problem [30]. Byrnes and Lindquist
have shown in [11] that JΨ has a unique minimum point in L+. This result implies that,
under assumption (4), there exists a (unique) ˆΛ ∈L+ satisfying (11). Such a ˆΛ then
provides the optimal solution of the primal problem (6)-(7) via (12). In the next section,
we provide a new detailed proof of this result inspired by that of [11].
5
An Existence Theorem
Let us consider the closure of L+, given by
L+ = {Λ = Λ∗∈Cn×n : Λ ∈Range(Γ), G∗ΛG ≥0, ∀eiϑ ∈T}.
(18)
On the convex set L+, we deﬁne the sequence of functions
Jn
Ψ(Λ) := tr (Λ) −

Ψ log

G∗ΛG + 1
n

.
(19)
Lemma 1. The pointwise limit J∞
Ψ (Λ) = limn Jn
Ψ(Λ) exists and deﬁnes a lower semi-
continuous, convex function on L+ with values in the extended reals.
Proof. For each n, Jn
Ψ is a continuous, convex function on the closed convex set L+.
Hence epi (Jn
Ψ), the epigraph of Jn
Ψ, is a closed, convex subset of Cn×n×R. Moreover,
for Λ ∈L+, Jn
Ψ(Λ) < Jn+1
Ψ
(Λ). Hence, J∞
Ψ is well deﬁned and in fact J∞
Ψ (Λ) =
supn Jn
Ψ(Λ). It follows that epi (J∞
Ψ ) = ∩nepi (Jn
Ψ) is also closed and convex. We
conclude that J∞
Ψ is lower semicontinuous and convex on L+.

78
A. Ferrante, M. Pavon, and F. Ramponi
Lemma 2. Assume (4). Then,
1. J∞
Ψ is bounded below on L+;
2. J∞
Ψ (Λ) = JΨ(Λ) on L+;
3. J∞
Ψ (Λ) is ﬁnite on all of L+ \ {0}.
Proof. By (4), there exists Φ1 ∈S+(T) satisfying (5), namely
%
GΦ1G∗= I. Hence,
tr (Λ) can be written as tr (Λ
%
GΦ1G∗) =
%
G∗ΛGΦ1, and we get
Jn
Ψ(Λ) =
 '
G∗ΛGΦ1 −Ψ log

G∗ΛG + 1
n
(
=

Φ1
'
G∗ΛG −Ψ
Φ1
log

G∗ΛG + 1
n
(
.
Since the function x −β log(x + 1
n) with β > 0 attains its minimum at x = β −1
n, we
get
Jn
Ψ(Λ) =

Φ1
'
G∗ΛG −Ψ
Φ1
log

G∗ΛG + 1
n
(
≥

ψ −1
n

Φ1 −S(Ψ||Φ1).
We conclude that J∞
Ψ ≥% ψ −S(Ψ||Φ1) on all of L+. To establish 2, notice that, by
Beppo Levi’s theorem,
J∞
Ψ (Λ) := tr (Λ) −

lim
n→∞Ψ log

G∗ΛG + 1
n

,
Λ ∈L+.
(20)
To prove 3, observe that for 0 ̸= Λ ∈∂L+, the boundary of L+, G∗ΛG is a nonzero
rational spectral density so that log G∗ΛG is integrable over T [47, pag. 64]. Since Ψ
is bounded, also Ψ log G∗ΛG is integrable.
In view of these lemmata, we extend JΨ(Λ) to all of L+ by setting JΨ(Λ) := J∞
Ψ (Λ)
on ∂L+. Notice that, by (20), JΨ is ﬁnite and given by (16) on L+ \ {0}, and it is +∞
in Λ = 0.
Lemma 3. Assume (4). Then
lim
∥Λ∥→+∞JΨ(Λ) = +∞.
(21)
Proof. Recall that by (4), there exists Φ1 ∈S+(T) satisfying (5), and, consequently,
tr (Λ) =
%
G∗ΛGΦ1 > 0, ∀Λ ∈L+. Suppose Λk is a sequence of matrices in L+ such
that limk→∞||Λk|| = +∞. Deﬁne the normalized sequence Λ0
k :=
Λk
||Λk|| (of course,
we can assume Λk ̸= 0, ∀k). Since tr Λ0
k > 0,
η := lim inf
k→+∞tr Λ0
k ≥0.
Consider a sub-sequence such that the limit of its trace is η. This subsequence contains
a convergent sub-subsequence {Λ0
km} since Λ0
k belongs to the surface of the unit ball,
which is compact. Let Λ∞:= limm→∞Λ0
km. Since G∗Λ0
nG > 0 on T, G∗Λ∞G ≥0

Further Results on the Byrnes-Georgiou-Lindquist Generalized Moment Problem
79
on T. Moreover, Λ∞∈Range Γ, since Range Γ is ﬁnite-dimensional, and hence
closed. This implies that G∗Λ∞G cannot be identically zero. In fact, if so, Λ∞∈
L+ = ker(Ξ) = Range Γ ⊥. Then Λ∞∈Range Γ ∩Range Γ ⊥= {0}, which is a
contradiction since ∥Λ∞∥= 1. Thus
η = lim
n→∞tr Λ0
n = tr Λ∞=

G∗Λ∞GΦ1 > 0
(22)
Hence, there exists a K such that tr Λ0
k > η/2 for all k ≥K. Finally, since G∗Λ0
kG ≤
G∗G, we obtain:
lim inf
k→∞JΨ(Λk) = lim inf
k→∞||Λk||tr Λ0
k −

Ψ log ||Λk||G∗Λ0
kG
= lim inf
k→∞||Λk||tr Λ0
k −(∫Ψ) log ||Λk|| −

Ψ log G∗Λ0
kG
≥lim inf
k→∞||Λk||tr Λ0
k −(∫Ψ) log ||Λk|| −

Ψ log G∗G
≥lim inf
k→∞||Λk||η
2 −(∫Ψ) log ||Λk|| −

Ψ log G∗G
= lim inf
k→∞
η
2

||Λk|| −∫Ψ
η/2 log ||Λk||

−

Ψ log G∗G
= +∞.
Theorem 2. Assume that the feasibility condition (4) is satisﬁed. Then the problem of
minimizing the functional JΨ(Λ) = tr Λ −% Ψ log G∗ΛG over L+ admits a unique
solution ˆΛ ∈L+.
Proof. In view of Lemma 1, Lemma 2 and Lemma 3, the functional JΨ is inf-compact
on the closed set L+, and therefore it admits a minimum point ˆΛ there. We show
next that ˆΛ ∈L+. Of course, ˆΛ is not the zero matrix since JΨ(0) = +∞. Let
0 ̸= Λ ∈∂L+. By Lemma 2, JΨ(Λ) is ﬁnite. Observe that, by (4), I ∈L+. By
convexity of L+, it then follows that Λ + ϵ(I −Λ) ∈L+, ∀ϵ ∈[0, 1]. We compute the
one-sided directional derivative or hemidifferential
J
′
Ψ+(Λ; I −Λ) := lim
ϵ↘0
'JΨ(Λ + ϵ(I −Λ)) −JΨ(Λ)
ϵ
(
= tr (I −Λ) +

Ψ −
 G∗GΨ
G∗ΛG = −∞.
(23)
Hence, Λ cannot be a minimum point. We conclude that ˆΛ ∈L+.
6
A Descent Method for the Dual Problem
In general, the optimal solution of the dual problem needs to be computed numerically.
This is a delicate problem because of the unboundeness of the gradient of JΨ at the

80
A. Ferrante, M. Pavon, and F. Ramponi
boundary of L+, see (23). The approaches proposed in [30] and references therein
involve some preliminary reparametrization of L+, which may imply loss of global
convexity.
In [41], a different matricial iterative method was proposed that appears to be very
fast and numerically robust. This method does not restrict the search of ˆΛ to L+ and
indeed it normally converges to a ˆΛ ̸∈Range(Γ). We show below that this method may
be viewed as a modiﬁed gradient descent method with ﬁxed step size. This method is
described as follows.
Let
M := {M ∈L′
+ : 0 ≤M ≤I, tr [M] = 1},
(24)
M+ := {M ∈M : M > 0}.
(25)
For M ∈M, deﬁne the map Θ by
Θ(M) :=

M 1/2G
'
Ψ
G∗MG
(
G∗M 1/2.
(26)
Theorem 3. [41]. The map Θ maps M into M and M+ into M+.
Consider the following iterative algorithm.
Algorithm. Let M0 = 1
nI. Note that M0 ∈M+. Deﬁne the sequence {Mk}∞
k=0 by
Mk+1 := Θ(Mk).
(27)
Notice that, by Theorem 3, Mk ∈M+ for all k. Moreover, since Mk ∈M, ∀k, the
sequence is bounded. Hence it has at least one accumulation (limit) point in the closure
M of M.
Theorem 4. Suppose that the sequence {Mk}∞
k=0 has a limit ˆ
M ∈M+. Then ˆ
M ∈L′
+
and satisﬁes (11), and therefore provides the optimal solution of the approximation
problem via (12).
Notice that even when the sequence generated by (27) converges to a singular matrix
ˆ
M ∈M, it is still possible, though not guaranteed, that such a matrix solves the original
problem. We next show that the algorithm may be viewed as a modiﬁed gradient descent
method. To this aim, rewrite (27) as
Mk+1 = Mk + M 1/2
k
'
GΨG∗
G∗MkG −I
(
M 1/2
k
.
(28)
Proposition 1. Deﬁne
∆Mk := M 1/2
k
'
GΨG∗
G∗MkG −I
(
M 1/2
k
,
(29)
so that (28) reads Mk+1 = Mk + ∆Mk. Then, ∆Mk is a descent direction at Mk
for JΨ.

Further Results on the Byrnes-Georgiou-Lindquist Generalized Moment Problem
81
Proof. Let
∇JΨ(Mk) = I −

GΨG∗
G∗MkG
denote the “gradient” of JΨ at Mk. Then,
< ∇JΨ(Mk), ∆Mk >= tr (∇JΨ(Mk)∆Mk) = −tr
1
M 1/4
k
∇JΨ(Mk)M 1/4
k
22
.
By Theorem3, Mk > 0, for all k. It follows that tr (∇JΨ(Mk)∆Mk) < 0, unless
∇JΨ(Mk) = 0 in which case Mk is a ﬁxed point of the iteration which solves the dual
problem by Theorem(4).
One could implement the matricial iteration as
Mk+1 = Mk + αk∆Mk,
(30)
where 0 < αk ≤1 is determined through backstepping, see e.g. [5]. Our extensive
simulation (see e.g. [41]), however, shows that convergence in fact occurs with αk ≡1!
Indeed, the algorithm appears to perform numerically very well. In fact, at each step
the integral (26) may be computed very precisely and efﬁciently via a spectral factoriza-
tion technique that only requires to solve an algebraic Riccati equation and a Lyapunov
equation, both of dimension n. We have performed an extensive number of simula-
tions where the sequence generated by (27) never failed to converge. In a very small
number of cases, we have observed convergence toward a singular matrix which, how-
ever, satisﬁed (11), and therefore provided the optimal solution of the approximation
problem.
References
1. H. Akaike, Markovian representation of stochastic processes by canonical variables, SIAM
J. Contr. vol. 13, pp. 162-173, 1975
2. H. Akaike, Stochastic theory of minimal realization, IEEE Trans. Aut. Contr. vol. AC-19,
pp. 667-674, 1974
3. A. Barron, Entropy and the central limit theorem, Ann. Probab. vol. 14, pp. 336-342, 1986.
4. A.Blomqvist, A.Lindquist and R.Nagamune, Matrix-valued Nevanlinna-Pick interpolation
with complexity constraint: An optimizaiton approach, IEEE Trans. Aut. Control vol. 48, pp.
2172-2190, 2003.
5. S. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, Cambridge,
UK, 2004.
6. C. I. Byrnes, T. Georgiou, and A. Lindquist, A new approach to spectral estimation: A
tunable high-resolution spectral estimator, IEEE Trans. Sig. Proc. vol. 49, pp. 3189-3205,
2000.
7. C. I. Byrnes, T. Georgiou, and A. Lindquist, A generalized entropy criterion for Nevanlinna-
Pick interpolation with degree constraint, IEEE Trans. Aut. Control vol. 46, pp. 822-839,
2001.
8. C. I. Byrnes, T. Georgiou, A. Lindquist and A. Megretski, Generalized interpolation in H-
inﬁnity with a complexity constraint, Trans. American Math. Society vol. 358(3), pp. 965-
987, 2006 (electronically published on December 9, 2004).

82
A. Ferrante, M. Pavon, and F. Ramponi
9. C. I. Byrnes, S. Gusev, and A. Lindquist, A convex optimization approach to the rational
covariance extension problem, SIAM J. Control and Opimization vol. 37, pp. 211-229, 1999.
10. C. I. Byrnes, S. Gusev, and A. Lindquist, From ﬁnite covariance windows to modeling ﬁlters:
A convex optimization approach, SIAM Review vol. 43, pp. 645-675, 2001.
11. C. I. Byrnes and A. Lindquist, The generalized moment problem with complexity constraint,
Integral Equations and Operator Theory vol. 56(2), pp. 163-180, 2006 (published online
March 29, 2006).
12. E. Carlen and A. Soffer, Entropy production by convolution and central limit theorems with
strong rate information, Comm. Math. Phys. vol. 140, pp. 339-371, 1991.
13. T. M. Cover and J. A. Thomas, Information Theory, Wiley, New York, 1991.
14. H. Cram´er, Mathematical methods of statistics, Princeton Univ. Press, Princeton, 1946.
15. I. Csisz´ar, Maxent, mathematics and information theory, in Proc. 15th Inter. Workshop on
Maximum Entropy and Bayesian Methods, K.M. Hanson and R.N. Silver eds., Kluver Aca-
demic, pp. 35-50, 1996.
16. J. C. Doyle, B. A. Francis and A. R. Tannenbaum, Feedback Control Theory, Macmillan,
New York, 1992.
17. P. Enquist, A homotopy approach to rational covariance extension with degree constraint,
Int. J. Appl. Math. and Comp. Sci. vol. 11, pp. 1173-1201, 2001.
18. A. Ferrante, M. Pavon and F. Ramponi, Constrained spectrum approximation in the
Hellinger distance, preprint Oct. 2006. To appear in Proc. of ECC07 Conf. 2007.
19. A. Ferrante, M. Pavon and F. Ramponi, Hellinger vs. Kullback-Leibler multivariable spec-
trum approximation, submitted. 2007.
20. H. F¨ollmer, Random ﬁelds and diffusion processes, in ´Ecole d’´Et´e de Probabilit´es de Saint-
Flour XV-XVII, edited by P. L. Hennequin, Lecture Notes in Mathematics, Springer-Verlag,
New York, vol. 1362, pp. 102-203, 1988.
21. T. Georgiou, Realization of power spectra from partial covariance sequences, IEEE Trans.
on Acoustics, Speech, and Signal Processing vol. 35, pp. 438-449, 1987.
22. T. Georgiou, The interpolation problem with a degree constraint, IEEE Trans. on Aut. Con-
trol vol. 44, pp. 631-635, 1999.
23. T. Georgiou, Spectral estimation by selective harmonic ampliﬁcation, IEEE Trans. Aut. Con-
trol vol. 46, pp. 29-42, 2001.
24. T. Georgiou, The structure of state covariances and its relation to the power spectrum of the
input, IEEE Trans. Aut. Control vol. 47, pp. 1056-1066, 2002.
25. T. Georgiou, Spectral analysis based on the state covariance: the maximum entropy spec-
trum and linear fractional parameterization, IEEE Trans. Aut. Control vol. 47, pp. 1811-
1823, 2002.
26. T. Georgiou, Solution of the general moment problem via a one-parameter imbedding, IEEE
Trans. Aut. Control vol. 50, pp. 811-826, 2005.
27. T. Georgiou, Relative entropy and the multivariable multidimensional moment problem,
IEEE Trans. Inform. Theory vol. 52, pp. 1052-1066, 2006.
28. T.
Georgiou,
Distances
between
power
spectral
densities,
arXiv
e-print
math.OC/0607026.
29. T. Georgiou, An intrinsic metric for power spectral density functions, arXiv e-print
math.OC/0608486.
30. T. Georgiou and A. Lindquist, Kullback-Leibler approximation of spectral density functions,
IEEE Trans. Inform. Theory vol. 49, pp. 2910-2917, 2003.
31. E. T. Jaynes, Papers on Probability, Statistics and Statistical Physics, R.D. Rosenkranz ed.,
Dordrecht, 1983.
32. S. Kullback, Information Theory and Statistics 2nd ed., Dover, Mineola NY, 1968.
33. A. Lindquist and G.Picci, On the stochastic realization problem, SIAM J. Control and Opti-
mization 17 (1979), 365-389.

Further Results on the Byrnes-Georgiou-Lindquist Generalized Moment Problem
83
34. A. Lindquist and G. Picci, Forward and backward semimartingale models for Gaussian pro-
cesses with stationary increments, Stochastics 15 (1985), 1-50.
35. A. Lindquist and G. Picci, Realization theory for multivariate stationary Gaussian processes,
SIAM J. Control and Optimization 23 (1985), 809-857.
36. A. Lindquist and G. Picci, A geometric approach to modeling and estimation of linear sto-
chastic systems, J. Mathematical Systems, Estimation, and Control 1 (1991), 241-333.
37. A. Lindquist and G. Picci, Geometric methods for state space identiﬁcation, in Identiﬁcation,
Adaptation, Learning: The Science of Learning Models from Data, S. Bittanti and G. Picci
(editors), Nato ASI Series (Series F, Vol 153), Springer, 1996, 1–69.
38. A. Lindquist and G. Picci, Canonical correlation analysis, approximate covariance extension,
and identiﬁcation of stationary time series, Automatica 32 (1996), 709–733.
39. H. P. McKean Jr., Brownian motion with a several-dimensional time, Th. Probab. Applic.
vol. 8, pp. 335-354, 1963
40. R. Nagamune, A robust solver using a continuation method for Nevanlinna-Pick interpola-
tion with degree constraint, IEEE Trans. Aut. Control vol. 48, pp. 113-117, 2003.
41. M. Pavon and A. Ferrante, On the Georgiou-Lindquist approach to constrained Kullback-
Leibler approximation of spectral densities, IEEE Trans. Aut. Control vol. 51, pp. 639-644,
2006.
42. M. Pavon and F. Ticozzi, On entropy production for controlled Markovian evolution, J. Math.
Phys., vol. 47, 063301, 2006.
43. G. Picci, Stochastic realization of Gaussian processes, Proc. IEEE vol. 64, pp. 112-122,
1976.
44. G. Picci, Some connections between the theory of sufﬁcient statistics and the identiﬁability
problem, SIAM J. Appl. Math. vol. 33, pp. 383-398, 1977.
45. G. Picci, On the internal structure of ﬁnite-state stochastic processes, in Recent develope-
ments in Variable Structure Systems, R. Mohler and A. Ruberti Eds. eds., Springer Lecture
Notes in Economics and Mathematical Systems, vol. 162, pp. 288–304, 1978.
46. G. Ruckebush, Representations markoviennes de processus gaussiens stationnaires, Th`ese
3`eme cycle, Paris VI, 1975.
47. Yu. A. Rozanov, Stationary Random Processes, Holden-Day, San Francisco, 1967.
48. V. Vedral, The role of relative entropy in quantum information theory, Rev. Mod. Phys vol.
74, pp. 197-, 2002.

Factor Analysis and Alternating Minimization
Lorenzo Finesso1 and Peter Spreij2
1 Institute of Biomedical Engineering, CNR-ISIB, Padova, Italy
lorenzo.finesso@isib.cnr.it
2 Korteweg-de Vries Institute for Mathematics, Universiteit van Amsterdam,
Amsterdam, The Netherlands
spreij@science.uva.nl
Dedicated to Giorgio Picci on the occasion of his 65th birthday.
Happy Birthday Giorgio!
1
Introduction
Factor analysis, in its original formulation, deals with the linear statistical model
Y = HX + ε
(1)
where H is a deterministic matrix, X and ε independent random vectors, the ﬁrst with
dimension smaller than Y , the second with independent components. What makes
this model attractive in applied research is the data reduction mechanism built in it.
A large number of observed variables Y are explained in terms of a small number of
unobserved (latent) variables X perturbed by the independent noise ε. Under normality
assumptions, which are the rule in the standard theory, all the laws of the model are
speciﬁed by covariance matrices. More precisely, assume that X and ε are zero mean
independent normal vectors with Cov(X) = P and Cov(ε) = D, where D is diagonal.
It follows from (1) that Cov(Y ) = HPH⊤+ D.
Building a factor analysis model of the observed data requires the solution of a difﬁ-
cult algebraic problem. Given Σ0, the covariance matrix of Y , ﬁnd the triples (H, P, D)
such that Σ0 = HPH⊤+ D. Due to the structural constraint on D, which is assumed
to be diagonal, the existence and unicity of a factor analysis model are not guaranteed.
As it turns out, the right tools to deal with this situation come from the theory of sto-
chastic realization, see [5] (trying to spot the master’s hand) for an early contribution
on the subject.
In the present paper we make a ﬁrst attempt at understanding how to build an optimal
approximate factor analysis model. The criterion we have chosen to evaluate the dis-
tance between covariances is the I-divergence between the corresponding normal laws.
The algorithm that we propose for the construction of the best approximation is inspired
by the alternating minimization procedure of [4] and [6].
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 85–96, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

86
L. Finesso and P. Spreij
2
The Model
Consider two independent, zero mean, normal vectors X and ε of respective dimensions
k and n. We will assume that Cov(X) = I, the identity matrix, and Cov(ε) = D > 0,
a diagonal matrix. Let H be an n × k matrix (in this paper k < n) and let the random
vector Y be deﬁned by
Y = HX + ε.
(2)
Under these assumptions (2) is called a factor analysis (FA) model of size k for the
vector Y . Notice that allowing Cov(X) = P > 0 does not produce a more general
model, as a square root of P can always be absorbed in H. We will say that a normal
vector Y admits a FA model of size k if it is equal in distribution to HX + ε for
some X and ε as above, i.e. if its covariance Σ0 can be written as Σ0 = HH⊤+ D.
Not every normal vector Y admits a FA model, the hard constraint being imposed by
the diagonal structure of D. A probabilistic interpretation stems from Cov(Y |X) =
D (see equation (28) of the Appendix) i.e. the n components of Y are conditionally
independent given the k < n components of some vector X. In Remark 1 of the next
section the condition for the existence of a FA model is slightly reformulated.
Although the construction of an exact FA model is not always possible, one can
search for a best approximate model, according to some criterion. In this paper we
opt for minimizing the I-divergence (Kullback-Leibler distance) between normal laws.
Recall that given two probability measures P1 and P2, deﬁned on the same measurable
space, such that P1 ≪P2, the I-divergence of P1 with respect to P2 is deﬁned as
D(P1||P2) = E P1 log dP1
dP2
.
If P1 and P2 are normal measures on the same space Rn, with zero means and strictly
positive covariance matrices Σ1 and Σ2 respectively, the I-divergence D(P1||P2) takes
the explicit form
D(P1||P2) = 1
2 log |Σ2|
|Σ1| + 1
2 tr(Σ−1
2 Σ1) −n
2 .
(3)
Since the I-divergence only depends on the covariance matrices, we usually write
D(Σ1||Σ2) instead of D(P1||P2).
The approximate factor analysis problem can be posed as follows:
Problem 1. Given the positive covariance matrix Σ0 ∈Rn×n and the integer k < n
minimize
D(Σ0||HH⊤+ D) = 1
2 log |HH⊤+ D|
|Σ0|
+ 1
2 tr((HH⊤+ D)−1Σ0) −n
2 .
over all pairs (H, D) where H ∈Rn×k and D > 0 is of size n and diagonal.
Notice that D(Σ1||Σ2), computed as in (3), can be considered as a divergence between
two positive deﬁnite matrices, without referring to normal distributions. Hence Prob-
lem 1 also has a meaning, when one refrains from assumptions like normality.

Factor Analysis and Alternating Minimization
87
Existence of the minimum is guaranteed by the following
Proposition 1. There exist matrices H∗∈Rn×k and D∗> 0 of size n and diagonal
minimizing the I-divergence in Problem 1.
The proof is deferred to section 4.2, since it uses later results.
In order to construct an algorithm for the solution of Problem 1 we will imitate the
approach of [6]. The algorithm will therefore be derived by a relaxation technique, lift-
ing the original minimization problem to a higher dimensional space. In the larger space
a double minimization problem equivalent to Problem 1 can be formulated, leading in
a natural way to an alternating minimization algorithm.
3
Lifting of the Original Problem
In this section we will embed Problem 1 into a higher dimensional space. First we
introduce the relevant sets of covariances. Given k < n we denote by
Σ = {Σ ∈R(n+k)×(n+k) : Σ =

Σ11 Σ12
Σ21 Σ22

> 0}.
(4)
where Σ11 is n × n. Two subsets of Σ will play a special role.
Σ0 = {Σ ∈Σ : Σ11 = Σ0}.
(5)
where Σ0 is a given covariance. We also consider the subset
Σ1 = {Σ ∈Σ : Σ =

HH⊤+ D
HQ
(HQ)⊤
Q⊤Q

},
(6)
where H ∈Rn×k, Q ∈Rk×k invertible, D > 0 diagonal. Elements of Σ1 will often
be denoted by Σ(H, D, Q).
Remark 1. Notice that a normal vector Y , with Cov(Y ) = Σ0, admits a FA model of
size k iff Σ0 ∩Σ1 ̸= ∅. Supposing that this is the case, take Σ ∈Σ0 ∩Σ1 then, for
some (H, D, Q), one has
Σ =

Σ0
HQ
(HQ)⊤
Q⊤Q

=
HH⊤+ D
HQ
(HQ)⊤
Q⊤Q

> 0.
is a bonaﬁde covariance of a normal vector V of dimension n + k. Partition V ⊤=
(Y ⊤, Z⊤)⊤. It is easy to verify that Cov(Y ) = Σ0 = HH⊤+ D is the same as
Cov(HX + ε) for some X standard normal and ε normal, independent from X, and
with diagonal covariance D.
The lifted minimization problem can be posed as follows
Problem 2
min
Σ′∈Σ0,Σ1∈Σ1
D(Σ′||Σ1)

88
L. Finesso and P. Spreij
which can be viewed as an iterated minimization problem over each of the variables.
The two resulting partial minimization problems will be investigated in the following
sections. In section 3.3 we will show the connection between Problems 1 and 2. More
precisely, we will prove
Proposition 2. Let Σ0 be given. It holds that
min
H,D D(Σ0||HH⊤+ D) =
min
Σ′∈Σ0,Σ1∈Σ1
D(Σ′|Σ1).
3.1
The First Partial Minimization Problem
In this section we consider the ﬁrst of the two partial minimization problems. Here
we minimize, for a given positive deﬁnite matrix Σ ∈Σ, the divergence D(Σ′||Σ)
over Σ′ ∈Σ0. The unique solution to this problem can be computed analytically and
follows from
Lemma 1. Let (Y, X) be a random vector distributed according to some Q = QY,X
and let P the set of all distributions P = P Y,X whose marginal P Y = P0, for some
ﬁxed P0 ≪QY . Then minP ∈P D(P||Q) = D(P ∗||Q) where P ∗is given by the
Radon-Nikodym derivative
dP ∗
dQ = dP0
dQY .
Moreover,
D(P ∗||Q) = D(P0||QY ).
(7)
and, for any other P ∈P, one has the Pythagorean law
D(P||Q) = D(P||P ∗) + D(P ∗||Q).
(8)
Proof. First we show that (7) holds. Recall that Y has law P0 under P ∗, then
D(P ∗||Q) = E P ∗log dP ∗
dQ = E P ∗log dP0
dQY = E P0 log dP0
dQY = D(P0||QY ).
To show that P ∗is a minimizer it is clearly sufﬁcient to prove that (8) holds.
D(P||Q) = E P log dP
dP ∗+ E P log dP ∗
dQ
= D(P||P ∗) + E P log dP0
dQY
= D(P||P ∗) + E P0 log dP0
dQY = D(P||P ∗) + D(P ∗||Q),
where we used the fact that all P ∈P have marginal P Y = P0.
□
Remark 2. The law P ∗is easily characterized in terms of the problem data P0 and Q
noticing that the marginal P ∗Y = P0 and the conditional P ∗X|Y = QX|Y .

Factor Analysis and Alternating Minimization
89
We now apply Lemma 1 to the case of normal laws and solve the ﬁrst partial minimiza-
tion. See also [2] for a different proof.
Proposition 3. Let Q and P0 be zero mean normal laws with strictly positive covari-
ances Σ ∈Σ and Σ0 ∈Rn×n respectively. Then, minΣ′∈Σ0 D(Σ′||Σ) is attained by
the zero mean normal law P ∗with covariance
Σ∗=

Σ0
Σ0Σ−1
11 Σ12
Σ21Σ−1
11 Σ0
Σ22 −Σ21Σ−1
11 (Σ11 −Σ0)Σ−1
11 Σ12

> 0.
Moreover,
D(Σ∗||Σ) = D(Σ0||Σ11).
Proof. This follows from Remark 2. A direct computation gives
Σ∗
12 = EP ∗XY ⊤= EP ∗(EP ∗[X|Y ]Y ⊤)
= EP ∗(EQ[X|Y ]Y ⊤) = EP ∗(Σ21Σ−1
11 Y Y ⊤)
= Σ21Σ−1
11 EP0Y Y ⊤= Σ21Σ−1
11 Σ0.
Likewise, we have
Σ∗
22 = EP ∗XX⊤= CovP ∗(X)
= CovP ∗(X|Y ) + EP ∗(EP ∗[X|Y ]EP ∗[X|Y ]⊤)
= CovQ(X|Y ) + EP ∗(EQ[X|Y ]EQ[X|Y ]⊤)
= Σ22 −Σ21Σ−1
11 Σ12 + EP ∗(Σ21Σ−1
11 Y (Σ21Σ−1
11 Y )⊤)
= Σ22 −Σ21Σ−1
11 Σ12 + EP0(Σ21Σ−1
11 Y Y ⊤Σ−1
11 Σ12)
= Σ22 −Σ21Σ−1
11 Σ12 + Σ21Σ−1
11 Σ0Σ−1
11 Σ12.
Notice that, since Σ > 0 by assumption,
Σ∗
22 −Σ∗
21(Σ∗
11)−1Σ∗
12 = Σ22 −Σ21Σ−1
11 Σ12 > 0
which, together with the assumption Σ0 > 0, shows that Σ∗> 0.
The last relation, D(Σ∗||Σ) = D(Σ0||Σ11), reﬂects equation (7).
□
3.2
The Second Partial Minimization Problem
In this section we turn to the second partial minimization problem. Here we minimize,
for a given positive deﬁnite matrix Σ ∈Σ, the divergence D(Σ||Σ1) over Σ1 ∈Σ1.
Clearly this problem cannot have a unique solution in terms of the matrices H and
Q. Indeed, if U is a unitary k × k matrix and H′ = HU, Q′ = U ⊤Q, then H′H′⊤=
HH⊤, Q′⊤Q′ = Q⊤Q and H′Q′ = HQ. Nevertheless, the optimal matrices HH⊤,
HQ and Q⊤Q are unique, as we will see in Proposition 4. First we need to introduce
some notation and conventions. If P is a positive deﬁnite matrix, we denote by P 1/2
any matrix satisfying (P 1/2)⊤(P 1/2) = P, and by P −1/2 its inverse. If M is any
square matrix, we denote by ∆(M) the diagonal matrix
∆(M)ii = Mii.
Recall that we denote by Σ(H, D, Q) a typical element of Σ1.

90
L. Finesso and P. Spreij
Proposition 4. Given Σ ∈Σ the minΣ1∈Σ1 D(Σ||Σ1) is attained at a Σ∗
1 such that
Σ1 ∈Σ1 is solved by
Q∗= Σ1/2
22 ,
H∗= Σ12Σ−1/2
22
,
D∗= ∆(Σ11 −Σ12Σ−1
22 Σ21).
Thus the minimizing matrix Σ∗
1 = Σ(H∗, D∗, Q∗) becomes
Σ∗
1 =

Σ12Σ−1
22 Σ21 + ∆(Σ11 −Σ12Σ−1
22 Σ21)
Σ12
Σ21
Σ22

.
(9)
Moreover, the Pythagorean law
D(Σ||Σ(H, D, Q)) = D(Σ||Σ∗
1) + D(Σ∗
1||Σ(H, D, Q))
(10)
holds for any Σ(H, D, Q) ∈Σ1, and therefore Σ∗
1 is unique.
Proof. It is sufﬁcient to show the validity of (10). We ﬁrst compute
2D(Σ||Σ(H, D, Q)) −2D(Σ||Σ∗
1).
It follows from Lemma A.2 that |Σ(H, D, Q)| = |D|×|Q⊤Q|. In view of equation (3)
the above difference becomes
log |D|+log |Q⊤Q|−log |D∗|−log |Q∗⊤Q∗|+tr

Σ(H, D, Q)−1Σ

−tr

Σ∗−1
1
Σ

.
(11)
Using Corollary A.1, we compute
Σ(H, D, Q)−1 =

D−1
−D−1HQ−⊤
−Q−1H⊤D−1
Q−1(H⊤D−1H + I)Q−⊤

,
(12)
and hence we get that
tr

Σ(H, D, Q)−1Σ

= tr

D−1(Σ11 −HQ−⊤Σ21)

+ tr

−Q−1H⊤D−1Σ12 + Q−1(H⊤D−1H + I)Q−⊤Σ22

= tr

D−1(Σ11 −2HQ−⊤Σ21) + Q−1(H⊤D−1H + I)Q−⊤Σ22

.
(13)
Apply now Lemma A.2 to (9) and write ∆= ∆(Σ11 −Σ12Σ−1
22 Σ21), to get
Σ∗−1
1
=Σ(H∗, D∗, Q∗)−1 =

∆−1
−∆−1Σ12Σ−1
22
−Σ−1
22 Σ21∆−1
Σ−1
22 Σ21∆−1Σ12Σ−1
22 + Σ−1
22

.
Therefore
tr

Σ∗−1
1
Σ

= tr

∆−1 × (Σ11 −Σ12Σ−1
22 Σ21)

+ tr Ik = tr

∆−1∆) + k = n + k.
(14)

Factor Analysis and Alternating Minimization
91
Combining equations (11), (13), and (14), we ﬁnd that
D(Σ||Σ(H, D, Q)) −D(Σ||Σ∗
1) =
log |D| + log |Q⊤Q| −log |D∗| −log |Q∗⊤Q∗|
+ tr

D−1(Σ11 −HQ−⊤Σ21)

+ tr

−Q−1H⊤D−1Σ12 + Q−1(H⊤D−1H + I)Q−⊤Σ22

−(n + k).
(15)
We proceed with the computation of 2D(Σ∗
1||Σ(H, D, Q)).
2D(Σ(H∗, D∗, Q∗)||Σ(H, D, Q)) =
log |D| + log |Q⊤Q| −log |D∗| −log |Q∗⊤Q∗| −(n + k)
+ tr

Σ(H, D, Q)−1Σ(H∗, D∗, Q∗)

.
(16)
Combining equations (9), (12), and tr

D−1(Σ12Σ−1
22 Σ21 + ∆)

= tr

D−1Σ11

, we
obtain
tr

Σ(H, D, Q)−1Σ(H∗, D∗, Q∗)

= tr

D−1Σ11

−2tr

D−1HQ−⊤Σ21

+ tr

Q−1(H⊤D−1H + I)Q−⊤Σ22

.
(17)
Insertion of (17) into (16) and a comparison with (15) yields the result.
□
Remark 3. Notice that the matrix H∗H∗⊤is strictly dominated by Σ11 (in the sense of
positive matrices). This easily follows from Σ11 −H∗H∗⊤= Σ11 −Σ12Σ−1
22 Σ21 > 0,
and the assumption Σ > 0. By the same token D∗> 0.
3.3
The Link to the Original Problem
We now establish the connection between the lifted problem and the original
Problem 1.
Proof of Proposition 2. Let Σ1 = Σ(H, D, Q) and denote by Σ∗= Σ∗(Σ1), the
solution of the ﬁrst partial minimization over Σ0. We have, for all Σ′ ∈Σ0,
D(Σ′||Σ1) ≥D(Σ∗||Σ1)
= D(Σ0||HH⊤+ D)
≥min
H,D D(Σ0||HH⊤+ D),
where we used Proposition 1 to write min on the RHS. It follows that
inf
Σ′∈Σ0,Σ1∈Σ1
D(Σ′||Σ1) ≥min
H,D D(Σ0||HH⊤+ D).
Conversely, let (H∗, D∗) be the minimizer of (H, D) →D(Σ0||HH⊤+ D), pick
an arbitrary invertible Q∗, and let Σ∗= Σ(H∗, D∗, Q∗) be the corresponding element

92
L. Finesso and P. Spreij
in Σ1. Furthermore, let Σ∗∗∈Σ0 be the minimizer of Σ →D(Σ||Σ∗) over Σ0.
Then
min
H,D D(Σ0||HH⊤+ D) = D(Σ0||H∗H∗⊤+ D∗)
≥D(Σ∗∗||Σ∗)
≥
inf
Σ′∈Σ0,Σ1∈Σ1
D(Σ′||Σ1),
which shows the opposite inequality. Finally, to show that we can replace the inﬁma
with minima also in the lifted problem, notice that (see Proposition 3) D(Σ∗∗||Σ∗) =
D(Σ0||H∗H∗⊤+ D∗).
□
4
Alternating Minimization Algorithm
In this section we combine the two partial minimization problems above to derive an
iterative algorithm for Problem 1. It turns out that this algorithm is also instrumental in
proving the existence of a solution to Problem 1.
4.1
The Algorithm
We suppose that the given matrix Σ0 is strictly positive deﬁnite. Pick the initial values
H0, D0, Q0 such that H0 is of full rank, D0 > 0 is diagonal, Q0 and H0H⊤
0 + D0 are
invertible.
At the t-th iteration the matrices Ht, Dt and Qt are available. Start solving the ﬁrst
partial minimization problem with Σ = Σ(Ht, Dt, Qt). Use the resulting matrix as
data for the second partial minimization, the solution of which gives the update rules
Qt+1 =
1
Q⊤
t Qt −Q⊤
t H⊤
t (HtH⊤
t + Dt)−1HtQt
+ Q⊤
t H⊤
t (HtH⊤
t + Dt)−1Σ0(HtH⊤
t + Dt)−1HtQt
21/2
,
(18)
Ht+1 = Σ0(HtH⊤
t + Dt)−1HtQtQ−1
t+1,
(19)
Dt+1 = ∆(Σ0 −Ht+1H⊤
t+1).
(20)
In (18) there is some freedom in computing the square root that determines Qt+1. Prop-
erly choosing the square root will result in the disappearance of Qt from the algorithm.
This is an attractive feature, since Qt only serves as an auxiliary variable. One can write
the RHS of equation (18), before taking the square root, as
Q⊤
t (I −H⊤
t (HtH⊤
t + Dt)−1(HtH⊤
t + Dt −Σ0)(HtH⊤
t + Dt)−1Ht)Qt
and denoting
Rt = I −H⊤
t (HtH⊤
t + Dt)−1(HtH⊤
t + Dt −Σ0)(HtH⊤
t + Dt)−1Ht
(21)

Factor Analysis and Alternating Minimization
93
a possible square root is given by
R1/2
t
Qt.
Notice that Rt only involves the iterates Ht and Dt. The update equation (18) can
therefore be rewritten as
Ht+1 = Σ0(HtH⊤
t + Dt)−1HtR−1/2
t
.
(22)
The ﬁnal version of the algorithm is given by equations (20),(21), and (22) which, for
clarity, we present as
Algorithm 1
Rt = I −H⊤
t (HtH⊤
t + Dt)−1(HtH⊤
t + Dt −Σ0)(HtH⊤
t + Dt)−1Ht,
(23)
Ht+1 = Σ0(HtH⊤
t + Dt)−1HtR−1/2
t
,
(24)
Dt+1 = ∆(Σ0 −Ht+1H⊤
t+1).
(25)
In order to avoid taking a square root at each step one can introduce the matrices Kt =
HtQt and Pt = QT
t Qt and write the updates for Kt and Pt. Equations (18), (19), and
(20) easily give
Algorithm 2
Kt+1 =Σ0(KtP −1
t
K⊤
t + Dt)−1Kt,
(26)
Pt+1 =Pt −K⊤
t (KtP −1
t
K⊤
t +Dt)−1(KtP −1
t
K⊤
t +Dt −Σ0)(KtP −1
t
K⊤
t + Dt)−1Kt,
Dt+1 =∆(Σ0 −Kt+1P −1
t+1K⊤
t+1).
After the ﬁnal iteration, the T -th say, one can take HT = KTQ−1
T , where QT is a
square root of PT .
Notice that in both Algorithm 1 and 2 it is required to invert n × n matrices (like e.g.
(HtH⊤
t +Dt)−1). Applying corollary A.1 one gets (HtH⊤
t +Dt)−1Ht = D−1
t Ht(I +
H⊤
t D−1
t Ht). Hence, we can replace e.g. (22) with
Ht+1 = Σ0D−1
t
Ht(I + H⊤
t D−1
t
Ht)−1R−1/2
t
.
(27)
By the same token one can write
Kt+1 = Σ0D−1
t Kt(Pt + K⊤
t D−1
t
Kt)−1Pt
to replace (26).
Some properties of the algorithm are summarized in the next proposition.
Proposition 5. For Algorithm 1 the following hold for all t.
(a) Dt > 0 and (Dt)ii ≤(Σ0)ii.
(b) Rt is invertible.
(c) If H0 is of full column rank, so is Ht.
(d) HtH⊤
t ≤Σ0.

94
L. Finesso and P. Spreij
(e) If Σ0 = H0H⊤
0 + D0 then the algorithm stops.
(f) The objective function decreases at each iteration. More precisely, let Σ0,t be the
solution of the ﬁrst partial minimization with data Σt = Σ(Ht, Dt, Qt). Then
D(Σ0||Ht+1H⊤
t+1) −D(Σ0||HtH⊤
t ) = −
1
D(Σt+1||Σt) + D(Σ0,t||Σ0,t+1)
2
.
(g) The limit points (H, D) of the algorithm satisfy the relations
H = (Σ0 −HH⊤)D−1H,
D = ∆(Σ0 −HH⊤).
Proof. (a) This follows from Remark 3.
(b) Use the identity I −H⊤
t (HtH⊤
t + Dt)−1Ht = (I + H⊤
t D−1
t Ht)−1 and the as-
sumption Σ0 > 0.
(c) Use the assumption Σ0 > 0, (a), and (b).
(d) Again from Remark 3 and the construction of the algorithm as a combination of the
two partial minimization problems.
(e) This is a triviality upon noticing that one can take Rt = I in this case.
(f) It follows from a concatenation of Lemma 1 and Proposition 4. Notice that we can
express the decrease as the sum of two I-divergences, since the Pythagorean law
holds for both partial minimizations.
(g) We consider Algorithm 2 ﬁrst. Assume that all variables converge. Then, from (26),
the limit points K, P, D satisfy the relation K = Σ0D−1K(P + K⊤D−1K)−1P.
Postmultiplication by P −1(P + K⊤D−1K) yields, after rearranging terms, K =
(Σ0 −KP −1K⊤)D−1K. Let now Q be a square root of P and H = KQ−1 to get
the ﬁrst relation. The rest is trivial.
□
4.2
Proof of Proposition 1
Let D0 and H0 be arbitrary and perform one step of the algorithm to get matrices D1
and H1. It follows from Proposition 5 that D(Σ0||H1H⊤
1 + D1) ≤D(Σ0||H0H⊤
0 +
D0). Moreover, H1H⊤
1 ≤Σ0 and D1 ≤∆(Σ0). Hence the search for a minimum
can be conﬁned to the set of matrices (H, D) satisfying HH⊤≤Σ0 and D ≤∆(Σ0).
Next, we claim that it is also sufﬁcient to restrict the search for a minimum to all ma-
trices (H, D) such that HH⊤+ D ≥εI for some sufﬁciently small ε > 0. Indeed,
if the last inequality is violated, then HH⊤+ D has an eigenvalue less than ε. Write
the Jordan decompositions HH⊤+ D = UΛU ⊤, and let ΣU = U ⊤Σ0U. Then
D(Σ0||HH⊤+ D) = D(ΣU||Λ), as one easily veriﬁes. Denoting by λi the eigen-
values of HH⊤+ D and letting σii be the diagonal elements of ΣU, we can write
D(ΣU|Λ) = −1
2 log |ΣU|+ 1
2

i log λi −n
2 + 1
2

i
σii
λi . Let λi0 be a minimum eigen-
value and take ε smaller than the minimum of all σii, which is positive, since Σ0 is
strictly positive deﬁnite. Then the contribution for i = i0 in the summation to the diver-
gence D(ΣU||Λ) is at least log ε+1, which tends to inﬁnity for ε →0. This proves the
claim. So, we have shown that a minimizing pair (H, D) has to satisfy HH⊤≤Σ0,
D ≤∆(Σ0), and HH⊤+ D ≥εI, for some ε > 0. In other words we have to mini-
mize the I-divergence over a compact set on which it is clearly continuous. This proves
Proposition 1.
□

Factor Analysis and Alternating Minimization
95
References
1. T.W. Anderson (1984), An introduction to multivariate statistical analysis, Second ed., Wiley.
2. E. Cramer (1998), Conditional iterative proportional ﬁtting for Gaussian distributions, J. Mul-
tivariate Analysis, 65(2), 261–276.
3. E. Cramer (2000), Probability measures with given marginals and conditionals: I-projections
and conditional iterative proportional ﬁtting, Statistics & Decisions, 18(3), 311–329.
4. I. Csisz´ar and G. Tusn´ady (1984), Information geometry and alternating minimization proce-
dures, Statistics & Decisons, supplement issue 1, 205-237.
5. L. Finesso and G. Picci (1984), Linear statistical models and stochastic realization theory.
Analysis and optimization of systems, Part 1 (Nice, 1984), 445–470, Lecture Notes in Control
and Inform. Sci., 62, Springer, Berlin.
6. L. Finesso and P. Spreij (2006), Nonnegative matrix factorization and I-divergence alternating
minimization, Linear Algebra and its Applications, 416, 270–287.
A
Appendix
For ease of reference we collect here some standard formulas for the normal distribution
and some matrix algebra.
A.1
Multivariate Normal Distribution
Let (X⊤, Y ⊤)⊤be a zero mean normal vector with covariance matrix
Σ =

ΣXX ΣXY
ΣY X ΣY Y

.
Assume that ΣY Y is invertible. The conditional law of X given Y is normal with
E [X|Y ] = ΣXY Σ−1
Y Y Y and
Cov[X|Y ] = ΣXX −ΣXY Σ−1
Y Y ΣY X.
(28)
A.2
Partitioned Matrices
Lemma 2. Let A, D be square matrices. Assume invertibility where required.

A C
B D

=

I
CD−1
0
I
 
A −CD−1B
0
0
D
 
I
0
D−1B
I

,

A C
B D

=

I
0
BA−1
I
 
A
0
0
D −BA−1C
 
I
A−1C
0
I

,

A C
B D
−1
=

(A −CD−1B)−1
−(A −CD−1B)−1CD−1
−D−1B(A −CD−1B)−1
D−1B(A −CD−1B)−1CD−1 + D−1

.

96
L. Finesso and P. Spreij
Corollary 1
(D −BAC)−1 = D−1 + D−1B(A−1 −CD−1B)−1CD−1.
Proof. For Lemma 2 a check will sufﬁce. The Corollary follows using the two decom-
positions of the Lemma with A replaced by A−1 and comparing the two expressions of
the lower right block of the inverse matrix.
□

Tensored Polynomial Models
Paul A. Fuhrmann⋆and Uwe Helmke
1 Department of Mathematics
Ben-Gurion University of the Negev
Beer Sheva, Israel
2 Universit¨at W¨urzburg
Institut f¨ur Mathematik
W¨urzburg, Germany
Dedicated to Giorgio Picci on his 65th birthday
Summary. The theme of the present paper is the study of two different versions of tensor prod-
ucts of functional models and present some applications to various problems related to system
theory. Among those are stability of higher order systems, tangent spaces, spaces of intertwin-
ing maps, invariant factors of tensor products of linear transformations and the solvability of
Sylvester equations.
Keywords: Tensor products, polynomial models, Sylvester equation, invariant factors.
1
Introduction
The theory of polynomial and rational models, initiated by the author in Fuhrmann
[1976], proved to be a very powerful tool for a variety of system problems as well as for
unifying various approaches to linear system theory. Recently, there has been growing
interest in a variety of multilinear problems, including potential extensions to bilinear
systems, Yang-Mills instantons from physics, and structured linear matrix equations.
The latter include the analysis of classes of linear equations of which the Sylvester,
Lyapunov and Stein equations are special cases. To meet these challenges, our intention
in the present paper is to extend the theory to tensored polynomial and rational models.
The original motivation for this stemmed from an algebraic approach to the derivation of
classical stability criteria, using polynomials in two variables, see Kalman [1969] which
was extended in Willems and Fuhrmann [1992] to the multivariable case. Another study
in which tensored models were studied is the characterization of the tangent space of the
space of rational functions given in Helmke and Fuhrmann [1998]. Further motivation
comes from recent work on quadratic differential forms, see Willems and Trentelman
[1998].
Because of space limitations, we only describe some of the principal results con-
cerning two types of tensored models. In the last section we give some applications,
in particular to Sylvester and Lyapunov equations. These results are then applied tothe
⋆Partially supported by the ISF under Grant No. 1282/05.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 97–112, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

98
P.A. Fuhrmann and U. Helmke
analysis of the classic case. The results described are not new, see de Souza and S.P.
Bhattacharyya [1981] and Heinig and Rost [1984] and the further references therein.
However, the method of proof is new and has the advantage of greater clarity. The full
details will appear in a subsequent publication.
2
Tensored Models
2.1
Preliminaries
In the following, the focal point of our interest will be the study of tensor products
of polynomial and rational models. Now both models carry two structures, one being
that of a vector space over a ﬁeld F, the other of a module over the polynomial ring
F[z]. Since the tensor product depends very much on the ring used, the result is that we
have to study both tensor products, each leading to different applications. If M1, M2
are modules over a commutative ring R, we will denote by M1 ⊗R M2 the R-module
deﬁned by the relevant tensor product.
We specialize our discussion to polynomial modules. Given the ﬁeld F the polyno-
mial ring F[z] is a rank 1 module over itself but an inﬁnite dimensional vector space
(module) over F. The module of polynomial vectors F[z]p itself is isomorphic to the
tensor product F[z] ⊗Fp. In this situation we have F[z]p ⊗F F[z]m ≃F[z]p×m, as well
as F[z]p ⊗F[z] F[z]m ≃F[z]p×m. In the following we will actually use these isomor-
phisms as identifying the above tensor products. In the case of the tensor product taken
over the ﬁeld F, the product is that of two vector spaces and there is no collapsing. It
will prove fruitful to consider this tensor product as that of two polynomial modules
with different variables, and have F[z]p ⊗F F[w]m = F[z, w]p×m.
In the following, we will need several more spaces. By F((z−1, w−1)) we denote
the ﬁeld of truncated Laurent series in the variables z, w and by F((z−1, w−1))p×m the
module of all p × m matrices with entries in F((z−1, w−1)), i.e. the set of all series
s
i=−∞
t
j=−∞Qijziwj. We shall routinely use the isomorphism F((z−1, w−1))p×m
≃Fp×m((z−1, w−1)). By F[z, w] we denote the ring of polynomials in the commut-
ing variables z, w and by F[[z−1, w−1]] the ring of formal power series in z−1, w−1.
We denote by F[z, w]p×m the space of p × m polynomial matrices. We will ﬁnd it
useful to use F[[z−1, w]p×m to denote the subspace of F((z−1, w−1))p×m of matrices
whose entries are formal power series in z−1 and polynomial in w. F[z, w−1]]p×m is
similarly deﬁned. In the same vein, F((z−1, w−1]]p×m denotes the space of p × m
matrix functions whose entries are truncated Laurent series in the variable z and for-
mal power series in the variable w, i.e. have the representation, with s an integer,
s
i=−∞
0
j=−∞Qijziwj.
The direct sum F((z−1))m = F[z]m ⊕z−1F[[z−1]]m is replaced in this setting by
the following direct sum representation.
F((z−1, w−1))p×m = F[z, w−1))p×m ⊕z−1F[[z−1, w−1))p×m
= F((z−1, w]p×m ⊕F((z−1, w−1]]p×mw−1
= F[z, w]p×m ⊕z−1F[[z−1, w]p×m
⊕F[z, w−1]]p×mw−1 ⊕z−1F[[z−1, w−1]]p×mw−1
(1)

Tensored Polynomial Models
99
To these direct sum representations correspond, respectively, the following projection
identities.
I = πz
+ ⊗I + πz
−⊗I = I ⊗πw
+ + I ⊗πw
−
= πz
+ ⊗πw
+ + πz
−⊗πw
+ + πz
+ ⊗πw
−+ πz
−⊗πw
−
(2)
Throughout, we will use ˜A to denote the transpose of a matrix A.
2.2
Tensored Polynomial and Rational Models
A one variable polynomial model XD with D(z) ∈F[z]p×p nonsingular is isomorphic
to the quotient module F[z]p/DF[z]p, see Fuhrmann [1976] and subsequent papers.
Thus, to begin with, our interest will focus on the study of the tensor products of quo-
tient modules. In general, if M1, M2 are R modules, with R a commutative ring and
Ni ⊂Mi are submodules, then the quotient spaces Mi/Ni have a natural R mod-
ule structure. Let N be the submodule generated in M1 ⊗R M2 by N1 ⊗R M2 and
M1 ⊗R N2. Then we have M1/N1 ⊗R M2/N2 ≃(M1 ⊗R M2)/N. Because the
tensor product is taken over a ring, considerable collapsing can occur. As an exam-
ple, consider the ring of polynomials F[z] and the quotient modules F[z]/diF[z]. Since
dF[z] = d1F[z] + d2F[z], with d is the greatest common divisor of d1 and d2, we have
F[z]/d1F[z] ⊗F[z] F[z]/d2F[z] = F[z]/(d1F[z] + d2F[z]) = F[z]/dF[z].
Let now D1 ∈F[z]p×p and D2 ∈F[z]m×m be nonsingular polynomial matrices. Not-
ing that D1(z)F[z]p×m + F[z]p×mD2(z) is the submodule of F[z]p×m generated by
D1(z)F[z]p×m and F[z]p×mD2(z), this generalizes to the vectorial case as
(F[z]p/D1(z)F[z]p) ⊗F[z] (F[z]m/F[z]mD2(z)) ≃
≃F[z]p×m/(D1(z)F[z]p×m + F[z]p×mD2(z))
(3)
However, if we take the tensor product of the two polynomial models over the ﬁeld F,
then we consider only the vector space structure, there is no collapsing and we have
dim F[z]p/D1(z)F[z] ⊗F F[z]m/D2(z)F[z]m = deg det D1 · deg det D2.
(4)
Equivalently, using the isomorphism XD ≃F[z]p/D(z)F[z]p, we have
dim(XD1(z) ⊗F XD2(z)) = deg det D1 · deg det D2.
Next, we analyze the tensor products of quotient modules of polynomial modules
in two distinct variables, i.e. we consider F[z]p/D1(z)F[z] and F[w]m/D2(w)F[w]m.
Since there is no common ring to these modules, we take the tensor product over the
underlying ﬁeld F. The submodule, or rather subspace, generated by D1(z)F[z]p and
F[w]mD2(w) in F[z, w]p×m = F[z]p ⊗F F[w]m, is clearly
D1(z)F[z]p ⊗F F[w]m + F[z]p ⊗F F[w]mD2(w) = D1(z)F[z, w]p×m + F[z, w]p×mD2(w).
which implies
(F[z]p/D1(z)F[z]p) ⊗F (F[w]m/F[w]mD2(w)) ≃
≃F[z, w]p×m/(D1(z)F[z, w]p×m + F[z, w]p×mD2(w)).

100
P.A. Fuhrmann and U. Helmke
Now the quotient module F[z, w]p×m/(D1(z)F[z, w]p×m + F[z, w]p×mD2(w)) can
be represented in a concrete way as a two variable polynomial model. To this end,
we introduce tensored module structures on the module of truncated matrix Laurent
series in two variables z, w, i.e. on F((z−1, w−1)). For A(z) ∈F((z−1))p×p and
A(w) ∈F((w−1))m×m, we deﬁne the Kronecker product of A and A by (A(z) ⊗
A(w))F(z, w) = A(z)F(z, w)A(w). Clearly A(z) ⊗A(w) is an F-linear map. There
are many derivatives to this deﬁnition. In particular, we will look at the restriction to
polynomial spaces i.e. to maps D(z) ⊗D(w) : F[z, w]p×m −→F[z, w]p×m, where
D(z), D(z) are nonsingular polynomial matrices.
We deﬁne now two maps πD(z)⊗FD(w)
:
F[z, w]p×m
−→
F[z, w]p×m and
πD(z)⊗D(z)
:
F[z]p×m
−→
F[z]p×m by πD(z)⊗D(w)F(z, w)
=
(D(z) ⊗
D(w))(πz
−⊗πw
−)(D(z) ⊗D(w))−1F(z, w)
=
(πD(z) ⊗πD(w))F(z, w), and
πD(z)⊗D(z)F(z)
=
(D(z) ⊗D(z))π−(D(z) ⊗D(z))−1F(z)
=
(πD(z) ⊗
πD(z))F(z) = D(z)[π−(D(z)−1F(z)D(z)−1)]D(z), respectively. Clearly, πz
−⊗πw
−
is a projection map in F((z−1, w−1))p×m and π−a projection map in F((z−1))p×m.
Hence πD(z)⊗D(w) is a projection map in F[z, w]p×m.
Proposition 1
1. Let D(z) ∈F[z]p×p and D(w) ∈F[w]m×m be nonsingular polynomial matrices.
Then
a) The maps πD(z)⊗I, πI⊗D(w) and πD(z) ⊗πD(w) are all projections and we
have
πD(z)⊗IπI⊗D(w) = πI⊗D(w)πD(z)⊗I = πD(z) ⊗πD(w) = πD(z)⊗D(w). (5)
b) We have
Ker πD(z)⊗I = D(z)F[z, w]p×m
Ker πI⊗D(w) = F[z, w]p×mD(w)
Ker πD(z)⊗D(w) = D(z)F[z, w]p×m + F[z, w]p×mD(w)
(6)
c) A polynomial matrix Q(z, w) is in XD(z)⊗D(w) if and only if
D(z)−1Q(z, w)D(w)−1
is strictly proper in both variables.
d) We have the isomorphism
XD(z)⊗D(w) ≃XD(z) ⊗F XD(w)
(7)
e) We have
dim XD(z)⊗D(w) = deg det D · deg det D.
(8)

Tensored Polynomial Models
101
2. Let D(z) ∈F[z]p×p and D(z) ∈F[z]m×m be nonsingular. Then
a) We have Q(z) ∈XD(z)⊗D(z) if and only if D(z)−1Q(z)D(z)−1 is strictly
proper.
b) We have
Ker πD(z)⊗D(z) = D(z)F[z]p×mD(z).
(9)
c) Given two nonsingular polynomial matrices D(z) ∈F[z]p×p and D(w) ∈
F[w]m×m. Let d1, . . . , dp be the invariant factors of D ordered so that di|di−1
and d1, . . . , dm, the invariant factors of D similarly ordered. Let δi = deg di,
= 1, . . . , p and δi = deg di. If n = deg det D and n = deg det D then it is
clear that n = p
i=1 δi and n = m
i=1 δi.
Then we have
dim XD(z)⊗D(z) = m deg det D + p deg det D.
(10)
Deﬁnition 1. Let D(z) ∈F[z]p×p and D(w) ∈F[w]m×m be nonsingular polynomial
matrices.
1. We deﬁne the tensored polynomial model XD(z)⊗D(w) by
XD(z)⊗D(w) = Im πD(z)⊗D(w)
(11)
2. We deﬁne the Kronecker product polynomial model XD(z)⊗D(z) by
XD(z)⊗D(z) = Im πD(z)⊗D(z)
(12)
Proposition 1 says that a tensored polynomial model, in the sense of (11), is the tensor
product of polynomial models. As a result the dimension formula (8) is multiplicative.
This is no longer true if we use Kronecker tensored polynomial models in the sense of
(12). We note that det(D(z) ⊗D(z)) = (det D)m(det D)p implies deg det(D(z) ⊗
D(z)) = p deg det D + m deg det D. Hence, the dimension formula is additive.
In analogy with the introduction of tensored polynomial models, we introduce
next the tensored rational models.
Given two nonsingular polynomial matrices
D(z) ∈F[z]p×p and D(w) ∈F[w]m×m, we deﬁne a map πD(z)⊗D(w) : z−1F[[z−1,
w−1]]p×mw−1 −→z−1F[[z−1, w−1]]p×mw−1 by
πD(z)⊗D(w)H(z, w)=(πz
−⊗πw
−)(D(z) ⊗D(w))−1(πz
+ ⊗F πw
+)(D(z) ⊗D(w))H(z, w)
(13)
We deﬁne the tensored rational model XD(z)⊗D(w) by
XD(z)⊗D(w) = Im πD(z)⊗D(w).
Clearly, we have H(z, w) ∈XD(z)⊗D(w) if and only if D(z)H(z, w)D(w) ∈
F[z, w]p×m, i.e. it is a polynomial in both variables.
2.3
Module Structures on Tensored Models
So far, on F[z]p ⊗F F[w]m = F[z, w]p×m we have only the vector space structure.
Of course, given any linear transformation X in F[z, w]p×m, there exists an induced
F[ζ]-module structure deﬁned by
ζ · F(z, w) = XF(z, w)
(14)

102
P.A. Fuhrmann and U. Helmke
and hence
p(ζ) · F(z, w) = p(X)F(z, w),
p ∈F[ζ].
(15)
two interesting special cases are given by
XF(z, w) = (z ⊗I −I ⊗w)F(z, w) = zF(z, w) −F(z, w)w,
(16)
and
XF(z, w) = (z ⊗w)F(z, w) = zF(z, w)w.
(17)
These special module structures are signiﬁcant as they lead eventually to the analysis
of the Sylvester and Stein equations.
The F[z, w]-module structure on XD(z)⊗D(w) is deﬁned, for
p(z, w) =
k

i=1
l

j=1
pijzi−1wj−1 ∈F[z, w]
by
p(z, w) · Q(z, w) = k
i=1
l
j=1 pijπD(z)⊗D(w)zi−1Q(z, w)wj−1
(18)
This implies that for p(z, w) = s
i=1 pi(z)qi(w) ∈F[z, w], we have
p(z, w) · Q(z, w) =
s

i=1
πD(z)⊗D(w)[(pi(z)Q(z, w)qi(w)]
(19)
It is easily shown that this is independent of the representation
p(z, w) =
s

i=1
pi(z)qi(w).
Similarly, we deﬁne an F[z, w]-module structure on the tensored rational model
XD(z)⊗D(w) by letting, for p(z, w) = k
i=1
l
j=1 pijzi−1wj−1 ∈F[z, w] and
H(z, w) ∈XD(z)⊗D(w)
p(z, w) · H(z, w) = πD(z)⊗D(w)[k
i=1
l
j=1 pijzi−1H(z, w)wj−1]
(20)
With the F[z, w]-module structure on XD(z)⊗D(w) and XD(z)⊗D(w), the multiplication
map D(z)⊗D(w) : XD(z)⊗D(w) −→XD(z)⊗D(w) is an F[z, w]-module isomorphism,
i.e. we have XD(z)⊗D(w) ≃XD(z)⊗D(w).
If we specialize deﬁnition (18) to the polynomial p(z, w) = z −w, we get, with
Q(z, w) ∈XD(z)⊗FD(w) ,
(z −w) · Q(z, w) = πD(z)⊗FD(w)(zQ(z, w) −Q(z, w)w).
(21)

Tensored Polynomial Models
103
We refer to this as the generalized Sylvester operator. In fact, with A ∈Fp×p and
A ∈Fm×m, if D(z) = zI −A and D(w) = wI −A then Q(z, w) ∈XD(z)⊗D(w) if
and only if Q(z, w) ∈Fp×m, i.e. Q(z, w) is a constant matrix. In that case we have
XD(z)⊗FD(w) = Fp×m and
(z −w) · Qπ(zI−A)⊗(wI−A)(z −w)Q = AQ −QA,
(22)
which is the standard Sylvester operator. The equation (z−w)·Q = R reduces in this
case to the Sylvester equation AQ −QA = R. An extensive study of the Sylvester
equation and its solution by polynomial methods will be undertaken in Section 3.
2.4
Duality
We extend now to the context of tensored models the duality theory for polynomial
models as developed in Fuhrmann [1981], which was based on the identiﬁcation of the
dual space to F[z]m with z−1F[[z−1]]m.
In analogy with (F[z]m)∗≃z−1F[[z−1]]m, we can identify the dual space of
F[z]p×m with the space z−1F[[z−1]]p×m by letting, for H ∈z−1F[[z−1]]p×m and
P ∈F[z]p×m,
[H, P] = (trace ˜HP)−1 = trace ( ˜HP)−1.
(23)
Here (X)−1 denotes the residue of a Laurent series of X, i.e. for X(z) = n
i=−∞xizi
we let (X)−1 = x−1 The availability of this pairing allows us to prove the following.
Proposition 2. Let D1(z) ∈F[z]p×p and D2(z) ∈F[z]m×m be nonsingular. Then we
have the identiﬁcation
(X ˜
D1(z)⊗˜
D2(z))∗≃(F[z]p×m/D1(z)F[z]p×mD2(z))∗= X
˜
D1(z)⊗˜
D2(z),
(24)
where the dual space is deﬁned with respect to the pairing deﬁned for H
∈
XD1(z)⊗D2(z) and P(z) ∈F[z]p×m by (23).
We proceed to extend the duality theory to the context of polynomial spaces in two
variables. To this end, we introduce in F((z−1, w−1))p×m a bilinear form by deﬁning,
for G, H ∈F((z−1, w−1))p×m
[H, G] = trace ∞
i=−∞
∞
j=−∞˜H−i−1,−j−1Gij
= ∞
i=−∞
∞
j=−∞trace ˜H−i−1,−j−1Gij
(25)
Note that the sum deﬁning [H, G] contains only a ﬁnite number of nonzero terms.
Clearly the form deﬁned in (25) is nondegenerate. It is easy to see that
(F[z, w]p×m)⊥= F[z, w−1]]p×m + F[[z−1, w]p×m.
(26)
In particular, we have F[z, w]p×m ⊂(F[z, w]p×m)⊥. The next result gives a concrete
representation of the dual space of F[z, w]p×m.

104
P.A. Fuhrmann and U. Helmke
Proposition 3. The dual space of F[z, w]p×m can be identiﬁed with
(z−1F[[z−1, w−1]]w−1)p×m.
We proceed to give a concrete representation of the dual space to a tensored polynomial
model. Given a subspace V of a linear space X, we use the isomorphism (X/V)∗≃
V⊥, as well as the identity (U + V)⊥= U⊥∩V⊥.
Proposition 4. Let D(z) ∈F[z]p×p and D(w) ∈F[w]m×m be nonsingular polynomial
matrices. We have
X∗
D(z)⊗D(w) = X
˜
D(z)⊗&
D(w).
(27)
2.5
Homomorphisms of Tensored Models
The central result in the theory of polynomial and rational models is the characteriza-
tion of the module homomorphisms. Given D(z) ∈F[z]p×p and D(z) ∈F[z]m×m
nonsingular. With D(z) we associate a polynomial model XD and similarly for D(z).
The homomorphisms from XD −→XD, are the maps intertwining SD and SD, i.e.
satisfy ZSD = SDZ are of the form
Zf = πDNf,
f ∈XD
(28)
where for some polynomial matrices N, N ∈F[z]p×m we have the intertwining rela-
tion ND = DN. The polynomial matrices N and N are uniquely determined by the
homomorphism Z if we require that D−1N = ND
−1 be strictly proper. Moreover
Z is injective if and only if D, N are right coprime and Z is surjective if and only if
D, N are left coprime. This can be extended to the characterization of homomorphism
between tensored models XD1(z)⊗FD2(w) and XD1(z)⊗FD2(w).
Theorem 1. Given
the
two
tensored
polynomial
models
XD1(z)⊗FD2(w)
and
XD1(z)⊗FD2(w), then
1. A map Z : XD1(z)⊗FD2(w) −→XD1(z)⊗FD2(w) is an F[z, w]-homomorphism if
and only if there exist appropriately sized polynomial matrices N1, N 1, N2, N 2
satisfying
N 1(z)D1(z) = D1(z)N1(z)
D2(w)N 2(w) = N2(w)D2(w)
(29)
in terms of which Z is given, for Q(z, w) ∈XD1(z)⊗FD2(w), by
ZQ(z, w) = πD1(z)⊗FD2(w)(N 1(z) ⊗F N2(w))Q(z, w)
= πD1(z)⊗FD2(w)N1(z)Q(z, w)N2(w)
(30)
2. The map Z deﬁned by (29) and (30) is
a) injective if and only if D1, N1 are right coprime and D2, N2 are left coprime.
b) surjective if and only if D1, N 1 are left coprime and D2, N 2 are right coprime.
c) bijective if and only if both sets of coprimeness conditions hold.

Tensored Polynomial Models
105
The availability of isomorphisms for tensored models allows us a reduction in the com-
plexity of their analysis. This is done by reducing both D and D to their respective
Smith forms ∆and ∆, and leads to the isomorphism XD(z)⊗D(w) ≃X∆(z)⊗∆(w).
The tensored model X∆(z)⊗∆(w) can be written symbolically as (Xdi(z)⊗dj(w)). Over
an algebraically closed ﬁeld F, the irreducible monic polynomials are of the form
p(z) = (z −α). Thus, taking the primary decomposition of the invariant factors, we
can further reduce the analysis to tensor products of the form X(z−α)p⊗(w−α)m. Using
translations, this can be further reduced to the study of tensor products of nilpotent mod-
els. Clearly, the Sylvester map in Xzp⊗wm is nilpotent and the cyclic decompositions
of the two Sylvester maps are isomorphic as vector spaces. Thus it sufﬁces to study the
cyclic decomposition of Xzp⊗wm. Here we refer also to the closely related work of Dirr,
Helmke and Kleinsteuber [2006] that describes such tensor product decompositions via
the Clebsch-Gordan decomposition from representation theory.
3
Applications
3.1
The Space of Intertwining Maps
Given linear transformations A and B, acting in linear spaces X, Y respectively, we
say that a linear transformation Z : X −→Y intertwines A and B if ZA = BZ.
The set of all linear transformations intertwining A and B is a linear space which we
denote by Intw (A, B). Thus an intertwining map Z is an F[z]-module homomorphism
with the module structures in X, Y being those induced by A and B respectively. A
special case of intertwining maps is the commutant C(T ) of a linear transformation
T , namely the set of all operators Z commuting with T , i.e. satisfying ZT = TZ.
Thus C(T ) = Intw (T, T ). If A, B transform by similarity to PAP −1, RBR−1, then
ZA = BZ transforms into (RZP −1)(PAP −1) = (RBR−1)(RZP −1), i.e. we have
Intw (PAP −1, RBR−1) = R Intw (A, B)P −1. Now the map SD is isomorphic to
S∆where ∆is the Smith form of D. We can assume without loss of generality that
D = diag(d1, . . . , dp) and D = diag(d1, . . . , dm), where the di are the invariant
factors of D ordered so that di|di−1 and similarly for D.
We have the following theorem.
Theorem 2. Given nonsingular D(z) ∈F[z]p×p and D(z) ∈F[z]m×m. Let d1, . . . , dp
be the invariant factors of D(z) ordered so that di|di−1 and d1, . . . , dm, the invariant
factors of D(z) similarly ordered. Let δi = deg di and δj = deg dj, n = p
i=1 δi =
deg det D, n = m
j=1 δj = deg det D and eij = di ∧dj = g.c.d.(di, dj). Then
1. There exists a linear isomorphism
XD(z)⊗D(z)/(D(z)XI⊗D(z) + XD(z)⊗ID(z)) ≃Intw (SD, SD).
(31)
2. We have
dim XD(z)⊗D(z) = m deg det D + p deg det D.
(32)
3.
dim[D(z)XI⊗D(z) ∩XD(z)⊗ID(z)] =
p

i=1
m

j=1
deg eij.
(33)

106
P.A. Fuhrmann and U. Helmke
4.
dim[D(z)XI⊗D(z) + XD(z)⊗ID(z)] = nm + pn −
p

i=1
m

j=1
deg eij.
(34)
5. We have
dim Intw (SD, SD) =
p

i=1
m

j=1
deg eij.
(35)
Corollary 1
1. Given nonsingular D(z) ∈F[z]p×p and D(z) ∈F[z]m×m have the same nontriv-
ial invariant factors di, ordered so that di|di−1. Let δi = deg di. Then we have
dim Intw (SD, SD) =

i
(2i −1)δi.
(36)
2. Let A ∈Fn×n have invariant factors d1, . . . , dn ordered so that di|di−1. Then
dim C(A) =

i
(2i −1)δi.
(37)
3. Given two linear transformations A, B then Intw (A, B) = {0}, i.e. there exist
no nontrivial intertwining maps, if and only if the minimal polynomials, or equiva-
lently the characteristic polynomials, of A, B are coprime.
3.2
The Polynomial Sylvester Equation
We proceed now to a more detailed study of the Sylvester equation in the tensored poly-
nomial model framework. We saw, in Section 2, that the classical Sylvester equation
AX −XA = C corresponds to the equation
Sz−wQ(z, w) = R(z, w),
(38)
with Q, R ∈X(zI−A)⊗F(wI−A) necessarily constant matrices.
Theorem 3. Let D(z) ∈F[z]p×p and D(w) ∈F[w]m×m be nonsingular. Deﬁning
the Sylvester operator S : XD(z)⊗D(w) −→XD(z)⊗D(w) by (21), then for R(z, w) ∈
XD(z)⊗D(w), we have
1. The Sylvester equation
Sz−wQ(z, w) = R(z, w)
(39)
is solvable if and only if there exists polynomial matrices P(z), P(w) for which
D(z)P(z) −P(z)D(z) −R(z, z) = 0.
(40)
We will refer to (40) as the polynomial Sylvester equation. In that case, the solu-
tion is given by
Q(z, w) = D(z)P(w) −P(z)D(w) + R(z, w)
z −w
.
(41)
2. The Sylvester equation (40) has a unique solution for every R(z, w)
∈
XD(z)⊗D(w) if and only if d∧d=1, where d(z)=det D(z) and d(z)=det D(z).

Tensored Polynomial Models
107
3.3
Solving the Sylvester Equation
Our aim now is to use the analysis of the polynomial Sylvester equation in order to
solve the standard Sylvester equation AX −XB = C under the assumption that the
characteristic polynomials of A and B are coprime. Most of the results presented in
this section are not new, see de Souza and S.P. Bhattacharyya [1981] or Heinig and
Rost [1984] and the further references in these papers. However, the method of proof
seems to be new and has greater clarity as far as the presentation is concerned. Some of
the technique employed, especially the analysis of the relation between Bezoutians and
ﬁnite section Hankel matrices, have been obtained in Fuhrmann and Helmke [1989],
see also Fuhrmann [1996].
Before proceeding, we introduce some notation and recall some known results. We
will denote by Eij ∈Fp×m the matrix whose ij entry is one and all other entries are
zero. Given a polynomial q(z) = zn + qn−1zn−1 + · · · + q0, we deﬁne the companion
matrices, using Kalman’s notation, by
C♯
q =
⎛
⎜
⎜
⎜
⎜
⎝
0
−q0
1
·
.
·
.
·
1 −qn−1
⎞
⎟
⎟
⎟
⎟
⎠
,
C♭
q =
⎛
⎜
⎜
⎜
⎜
⎝
0
1
.
·
.
1
−q0 . . . −qn−1
⎞
⎟
⎟
⎟
⎟
⎠
.
(42)
For the polynomial model Xq we single out two bases, the standard basis, namely
Bst = {1, z, . . ., zn−1} and the control basis, namely Bco = {e1, . . . , en}, where the
polynomials ei are deﬁned by
ei(z) = zn−i + qn−1zn−i−1 + · · · + qi.
The control basis for Xq will be denoted by Bco. It is known, see Fuhrmann [1996],
that the companion matrices in (42) are the matrix representations of Sq with respect
to the standard basis and the control basis respectively, i.e. we have C♯
q = [Sq]st
st and
C♭
q = [Sq]co
co. Given the monic polynomial q(z) = zn + qn−1zn−1 + · · · + q0 and
q(z) = zn + qn−1zn−1 + · · ·+ q0, we deﬁne the upper triangular Hankel matrix Hq by
Hq = B(q, 1) = [I]st
co =
⎛
⎜
⎜
⎜
⎜
⎝
q1
. . qn−1 1
.
. .
.
.
. .
qn−1 .
1
⎞
⎟
⎟
⎟
⎟
⎠
.
(43)
The Hankel matrix Hq is analogously deﬁned.
Given the Sylvester equation AX −XB = C which we want to solve, we begin by
solving a special Sylvester equation, namely
C♯
qY −Y C♭
q = E11
(44)
To begin with, we assume that q, q are coprime polynomials of the same degree n. Thus
Y ∈Fn×n. Using the isomorphism
Fn×n ≃Xq(z)⊗q(w),
(45)

108
P.A. Fuhrmann and U. Helmke
given by
(aij) →
n

i=1
n

j=1
aijzi−1wj−1
(46)
we can rewrite equation (44) as
πq(z)⊗q(w)(z −w)f(z, w) = 1.
(47)
If p, p solve the polynomial Sylvester equation (40), i.e. q(z)p(z) −p(z)q(z) + 1 = 0,
then this is equivalent to the Bezout equation
p(z)q(z) −q(z)p(z) = 1.
(48)
Since y(z, w) ∈Xq(z)⊗q(w), we have an expansion
y(z, w) = q(z)p(w) −p(z)q(w) + 1
z −w
=
n

i=1
n

j=1
ηijzi−1wj−1.
(49)
With Y = (ηij), we have a solution of (44).
We recall that, given a polynomial a(z) of degree n, the reverse polynomial is
deﬁned by a♯(z) = a(z−1)zn.
We state now the main result on the solvability of the Sylvester equation.
Theorem 4. Let q, q be coprime polynomials of degree n. Let p, p be the unique solu-
tions of the scalar polynomial Sylvester equation
q(z)p(z) −p(z)q(z) + 1 = 0,
(50)
satisfying deg p < deg q and deg p < deg q. Then
1. Let Y = (ηij) be deﬁned by
q(z)p(w) −p(z)q(w) + 1
z −w
=
n

i=1
n

j=1
ηijzi−1wj−1,
(51)
then Y is the unique solution of the Sylvester equation
C♯
qY −Y C♭
q = E11
(52)
2. We have the following identiﬁcation of the matrix Y solving (52), namely
Y = [p(Sq)]st
co.
(53)
3. Let Z = (ζij) be deﬁned by
q(z)p(w) −p(z)q(w) + 1
z −w
=
n

i=1
n

j=1
ζijei(z)ej(w),
(54)
then Z is the unique solution of the Sylvester equation
C♭
qZ −ZC♯
q = Enn.
(55)

Tensored Polynomial Models
109
Moreover, we have
Z = [p(Sq)]co
st.
(56)
4. The solutions Y and Z of (54) and (55) respectively are related via
Y = HqZHq.
(57)
5. Let p, p be the solutions of the polynomial Sylvester equation (50).
Writing
p(z)
q(z) = ∞
i=1
gi
zi and similarly p(z)
q(z) = ∞
i=1
gi
zi , we deﬁne the ﬁnite section Hankel
matrices by
H(n)
p/q =
⎛
⎜
⎜
⎜
⎜
⎝
g1 . . .
gn
. . . .
.
. . . .
.
. . . .
.
gn . . . g2n−1
⎞
⎟
⎟
⎟
⎟
⎠
,
H(n)
p/q =
⎛
⎜
⎜
⎜
⎜
⎝
g1 . . .
gn
. . . .
.
. . . .
.
. . . .
.
gn . . . g2n−1
⎞
⎟
⎟
⎟
⎟
⎠
(58)
Then we have
H(n)
p/q = H(n)
p/q.
(59)
6. The matrix Z deﬁned by (54) is an n × n Hankel matrix having the representations
Z = B(q, q)−1 = H(n)
p/q = H(n)
p/q.
(60)
and
Z = H−1
q p(C♯
q) = p(C♭
q)H−1
q .
(61)
With Z the solution of (55),
7. We deﬁne the n × n shift S and transposition matrix J by
S =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0 1 . . . 0
. . 1 . . .
. . . . . .
. . . . 1 0
. . . . . 1
0 . . . . 0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
J =
⎛
⎜
⎜
⎜
⎜
⎝
0 . . . 1
0 . . 1 0
0 . . . 0
0 1 . . 0
1 . . . 0
⎞
⎟
⎟
⎟
⎟
⎠
(62)
Then, for the solution Y of (52), we have the following representation
Y = −
3
q( ˜S)p♯(S) −p( ˜S)q♯(S)
4
J
(63)
We will refer to this as the Gohberg-Semencul formula.
3.4
Invariant Factors of the Sylvester Map
We saw already that the study of the generalized Sylvester map is reducible to the study
of nilpotent scalar tensored polynomial models of the form Xzp⊗wm. This allows us to
study the Sylvester map by polynomial techniques.

110
P.A. Fuhrmann and U. Helmke
Theorem 5. Given integers p, m with p ≤m.
Deﬁne Sz+w : Fp,m[z, w] −→
Fp,m[z, w] by
Sz+wf(z, w) = zf(z, w) + f(z, w)w
mod (zp, wm),
(64)
for f(z, w) ∈Fp,m[z, w]. Then
1. We have
dim Ker Sz+w = p.
(65)
and a basis for Ker Sz+w is given by the vectors h(1), . . . , h(p) deﬁned by
h(k) =
p−k

ν=0
(−1)νzk−1+νwm−1−ν.
(66)
2. Sz+w has p nontrivial invariant factors.
3. Let α1, . . . , αk be a nonzero solution of the equation Pα = 0, where P is the full
rank (k −1) × k matrix deﬁned by
Pij =

p + m −2k + 1
(p −k + 1) −(i −1) + (j −1)

(67)
Deﬁne, for k = 1, . . . , p,
g(k) =
k

i=1
αizi−1wk−i
(68)
Then
Vk = span {Si
z+wg(k)|i = 0, . . . , p + m −2k + 1}
(69)
is a cyclic invariant subspace of dimension p + m −2k + 1, i.e. we have
Sp+m−2k+1
z+w
g(k) = 0
(70)
and
Sp+m−2k
z+w
g(k) ̸= 0.
(71)
4. A basis for Fp,m[z, w] is given by {Sj
z+wg(k)|k=1, . . . , p;j =0, . . . , p+m−2k}.
5. We have the direct sum decomposition
Fp,m[z, w] = V1 ⊕· · · ⊕Vp.
(72)
6. The invariant factors of Sz+w are zp+m−2j+1, j = 1, . . . , p.
The analysis of the Sylvester map based on a square p × p nilpotent matrix Np is of
course a special case of Theorem 5. However, in this case the space Fp×p decomposes
into the subspace of symmetric matrices Fp×p
sym and the subspace of antisymmetric ma-
trices Fp×p
asym, respectively. Each of these subspaces is invariant under the Sylvester
map. The following theorem analyses these direct sum decompositions. We use again
the isomorphism (45) to go over from matrix to polynomial equations which are easier
to handle. The Sylvester map is now represented by Sz+w acting in Fp,p[z, w].

Tensored Polynomial Models
111
Theorem 6
1. Deﬁne the vectors h(1), . . . , h(p) by
h(k)(z, w) =
p−k

ν=0
(−1)νzk−1+νwp−1−ν,
(73)
then h(k) is a symmetric polynomial if and only if p−k is even and an antisymmetric
polynomial if and only if p −k is odd.
2. The vectors h(1), . . . , h(p) form a basis for Ker Sz+w.
3. Deﬁne the vectors g(k), k = 1, . . . , p by
g(k) =
⎧
⎨
⎩
z
k−1
2 w
k−1
2
k odd
z
k
2 w
k
2 −1 −z
k
2 −1w
k
2
k even
(74)
Then the subspaces Vk = span {Sj
z+wg(k)|j = 0, . . . , 2p−2k} are cyclic invariant
subspaces.
4. The subspaces V1, V3, . . . contain only even polynomials whereas V2, V4, . . . con-
tain only odd polynomials
5. We have the direct sum decomposition
Fp,p[z, w] = Fsym
p,p [z, w] ⊕Fasym
p,p
[z, w].
(75)
Furtermore, we have the ﬁner direct sum decompositions
Fsym
p,p [z, w] =
⎧
⎪
⎨
⎪
⎩
⊕
p+1
2
i=1 V2i−1
p odd
⊕
p
2
i=1V2i−1
p even
(76)
and
Fasym
p,p
[z, w] =
⎧
⎪
⎨
⎪
⎩
⊕
p−1
2
i=1 V2i
p odd
⊕
p
2
i=1V2i
p even
(77)
6. The invariant factors of the sylvester map are z2j−1, j = 1, . . . , p.
Theorem 5 leads directly to the analysis of a special case, namely that of the Lyapunov
map. Let Fp×p
sym, Fp×p
asym be the subspaces of Fp×p of symmetric and antisymmetric matri-
ces respectively. Given A ∈Fp×p, we deﬁne the Lyapunov map LA : Fp×p
sym −→Fp×p
sym
by LA = SA, ˜
A|Fp×p
sym or equivalently by
LA(X) = AX + X ˜A,
X ∈Fp×p
sym
(78)
and the complementary Lyapunov map KA : Fp×p
asym −→Fp×p
asym by KA=SA, ˜
A|Fp×p
asym
or equivalently by
KA(X) = AX + X ˜A,
X ∈Fp×p
asym.
(79)

112
P.A. Fuhrmann and U. Helmke
We have the following.
Theorem 7. Let Np ∈Fp×p be the nilpotent matrix deﬁned above. Then
1. We have
dim Ker LN =
⎧
⎨
⎩
p
2
p even
p+1
2
p odd
(80)
2. We have
dim Ker KN =
⎧
⎨
⎩
p
2
p even
p−1
2
p odd
(81)
3. The Lyapunov map LN has p/2 invariant factors when p is even and (p + 1)/2
invariant factors when p is odd and they are given by
⎧
⎪
⎨
⎪
⎩
{z4j−1}p/2
1
p even
{z4j−3}(p+1)/2
1
p odd
(82)
4. The complementary Lyapunov map KN has p/2 invariant factors when p is even
and (p −1)/2 invariant factors when p is odd and they are given by
⎧
⎪
⎨
⎪
⎩
{z4j−3}p/2
1
p even
{z4j−1}(p−1)/2
1
p odd
.
(83)
References
[2006] G. Dirr, U. Helmke and M. Kleinsteuber, ”Lie algebra representations, nilpotent matrices
and the C-numerical range”, Lin. Alg. Appl., 413, 534-566.
[1976] P.A. Fuhrmann, ”Algebraic system theory: An analyst’s point of view”, J. Franklin Inst.
301, 521-540.
[1981] P.A. Fuhrmann, ”Duality in polynomial models with some applications to geometric con-
trol theory”, IEEE Trans. Aut. Control, AC-26, (1981), 284-295.
[1996] P.A. Fuhrmann, A Polynomial Approach to Linear Algebra, Springer Verlag, New York.
[1984] G. Heinig and K. Rost, Algebraic Methods for Toeplitz-like Matrices and Operators,
Akademie-Verlag, Berlin.
[1989] U. Helmke and P.A. Fuhrmann, ”Bezoutians”, Lin. Alg. Appl., vols. 122-124, 1039-1097.
[1998] U. Helmke and P.A. Fuhrmann, ”Tangent spaces of rational functions”, Lin. Alg. Appl.,
vol. 271, 1-40.
[1969] R.E. Kalman, ”Algebraic characterization of polynomials whose zeros lie in algebraic
domains”, Proc. Nat. Acad. Sci., 64, 818-823.
[1981] E. de Souza and S.P. Bhattacharyya, ”Controllability, observabiliy and the solution of
AX −XB = C”, Lin. Alg. Appl., vol. 39, 167-181.
[1992] J.C. Willems and P.A. Fuhrmann, ”Stability theory for high order systems”, Lin. Alg.
Appl., 167, 131-149.

Distances Between Time-Series and Their
Autocorrelation Statistics
Tryphon T. Georgiou
Department of Electrical and Computer Engineering,
University of Minnesota Minneapolis, MN 55455
tryphon@umn.edu
This paper is dedicated to Giorgio Picci on the occasion of his sixty-ﬁfth birthday
Summary. We begin with an interpretation of the L1-distance between two power spectral den-
sities and then, following an analogous rationale, we develop a natural metric for quantifying
distance between respective covariance matrices.
1
Introduction
Consider two discrete-time, stationary, zero-mean, (real-valued for notational conve-
nience) random processes yk and ˆyk (k ∈Z) having power spectral densities fy(θ)
and fˆy(θ) (θ ∈[−π, π]), and autocorrelation functions Rℓand ˆRℓ(ℓ∈Z), respec-
tively, i.e.,
Rℓ= E{ykyk+ℓ} = 1
2π
 π
−π
f(θ)e−jℓθdθ,
and similarly for the “hatted” quantities. When the power spectrum contains a singular
part, then f(θ)dθ needs to be replaced by a non-negative ﬁnite spectral measure dµ(θ).
We are interested in quantifying the distance between respective spectra and statistics
for two such random process yk and ˆyk. When two vectors
Rn :=
5
R0 R1 . . . Rn−1
6
, and
ˆRn :=
5
R0 R1 . . . Rn−1
6
of autocorrelation samples are available and need to be compared, one may use any
metric in Rn for that purpose, as for instance ∥Rn −ˆRn∥2 =
7
k(Rk −ˆRk)2.
However, we are not aware of any signiﬁcance that can be attached to such a distance
other than the fact that it is a metric in Rn. Our goal in this paper, is to seek a metric
which can be physically motivated.
Similarly, if we are to compare fy(θ) and fˆy(θ), it appears difﬁcult to motivate the
use of an L2-distance ∥fy(θ) −fˆy(θ)∥2. For one thing, the L2-distance cannot be
generalized to deal with spectral measures when singular parts are present. There are
certainly other alternatives. In the speech processing literature in particular there is
a plethora of distances that, however, are not metrics [6] but have been motivated by
speciﬁc needs. Function theoretic alternatives that one can use (e.g., Lp-norms, etc.)
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 113–122, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

114
T.T. Georgiou
including Wasserstein-like transportation measures typically lack a physical interpreta-
tion. In a recent study [4,5] a pseudometric was constructed as a geodesic between spec-
tral densities/measures with respect to a rather natural Riemannian metric —this metric
quantiﬁes the degradation of predictive-error variance when the predictor is designed
based on the wrong choice between two alternatives and the geometry is, in essence,
Euclidean but only after we transform spectral densities using the logarithmic map.
In the current paper we focus on the L1 distance
∥fy(θ) −fˆy(θ)∥1 := 1
2π
 π
−π
|fy(θ) −fˆy(θ)| dθ
which has also a rather natural interpretation. After a brief discussion of the relevance
of the L1-distance, following a similar rationale, we will develop an analogous metric
between ﬁnite partial covariance data of the corresponding random processes.
2
Interpretation of the L1 Distance
Given yk and ˆyk we postulate that there exist two random processes ψk and ˆψk so that
yk + ψk = ˆyk + ˆψk.
(1)
Alternatively, we postulate that there exists a random process zk and that the two origi-
nal random processes relate to zk via
yk = zk −ψk
ˆyk = zk −ˆψk.
It is natural to seek such perturbations of minimal total combined variance
E{ψ2
k} + E{ ˆψ2
k}
(2)
that is sufﬁcient to “reconcile” the two processes. The combined variance E{ψ2
k} +
E{ ˆψ2
k} represents the minimal amount of “energy” of perturbations in the two time-
series that is needed to render the two indistinguishable.
Intuitively, the minimal
combined variance which is consistent with the available data quantiﬁes the distance
between the two.
Given fy, fˆy, the optimal choice consists of random processes ψk and ˆψk such that
yk and ˆψk are independent, ˆyk and ˆψk are also independent, and
fψ(θ) =
8
fˆy(θ) −fy(θ) if fˆy(θ) −fy(θ) ≥0,
0
otherwise,
(3a)
f ˆ
ψ(θ) =
8
fy(θ) −fˆy(θ) if fˆy(θ) −fy(θ) ≤0,
0
otherwise.
(3b)
Then, the power spectrum of the “sum”
zk := yk + ψk = ˆyk + ˆψk

Distances Between Time-Series and Their Autocorrelation Statistics
115
is simply
fz(θ) := max{fy(θ), fˆy(θ)}, θ ∈[−π, π],
and
d(fy, fˆy) := E{ψ2
k} + E{ ˆψ2
k}
(4)
=
1
2π
 π
−π
(fψ(θ) + f ˆ
ψ(θ))dθ
=
1
2π
 π
−π
|fy(θ) −fˆy(θ)| dθ
= ∥fy −fˆy∥1.
(5)
Obviously, this construction extends in the obvious way to the case of not-necessarily
absolutely continuous power spectra as well, and the metric includes the measure of
any discrepancies between the singular parts of the two spectral measures.1 Clearly,
d(fy, fˆy) is a metric as seen from (5). Building on a similar rationale, in the next
section, we develop a metric for covariance matrices.
3
A Distance Between Covariance Matrices
It is often the case that only a ﬁnite segment of the autocorrelation function of time-
series yk and ˆyk is available (and even then, possibly uncertain). Thus, it is of interest
to consider distances between the partial autocorrelation statistics R and ˆR. To this
end, we follow the dictum of the previous section and deﬁne as a distance measure
the minimal combined variance of random processes ψk and ˆψk for which (1) holds.
Naturally, since only partial covariance samples are available, the random processes
ψk, ˆψk and (1) need to be consistent with these data.
First denote by
Rn :=
⎡
⎢⎢⎢⎣
R0
R1
. . . Rn−1
R−1
R0
. . . Rn−2
...
...
...
...
R−(n−1) R−(n−2) . . .
R0
⎤
⎥⎥⎥⎦
the n×n covariance matrix corresponding to yk and the covariance samples in Rn and,
similarly, ˆRn for the Toeplitz matrix based on ˆRn. If Qn, ˆQn denote the corresponding
ﬁnite Toeplitz covariances of the random processes ψk and ˆψk, respectively, for which
(1) holds, then
Rn + Qn = ˆRn + ˆQn
(6)
1 It will be interesting to explore the practical signiﬁcance of other possibilities for quantifying
distance such as
% π
−π(fψ(θ) + f ˆ
ψ(θ))dθ
% π
−π fz(θ)dθ
or
 π
−π
fψ(θ) + f ˆ
ψ(θ)
fz(θ)
dθ
2π .

116
T.T. Georgiou
and the minimal sum Q0 + ˆQ0 of the respective variances can serve as a metric quanti-
fying the distance between R and ˆR.
The computation of Qn, ˆQn minimizing the sum Q0 + ˆQ0, or equivalently
minimizing
1
ntrace (Qn + ˆQn),
is a convex problem –since the positivity constraints are convex. The Toeplitz structure
is peripheral, and the idea of deﬁning such metrics extends equally well to non-negative
deﬁnite Hermitian matrices and to more general positive operators. For notational con-
venience we develop the framework in the context of real symmetric matrices.
So, we let
M := {M ∈Rn×n | M = M ′ ≥0}
be the cone of non-negative symmetric n × n-matrices and
Tn := {R ∈M | R is a Toeplitz matrix}
be the cone of non-negative Toeplitz matrices in M. We address the case of matrices in
M and deﬁne a suitable metric, which is then specialized to Tn.
Proposition 1. Let M1, M2 ∈M and
τ(M1, M2) := min
 1
ntrace (M) | M ∈M,
M ≥M1 and M ≥M2} .
Then
δ(M1, M2) := 2τ(M1, M2) −trace (M1) −trace (M2)
(7)
deﬁnes a metric on M.
Proof. Given M1, M2 ∈M,
C(M1, M2) := {M | M ≥M1 and M ≥M2}
is a (convex) cone of non-negative deﬁnite matrices. It follows that there is an element
M12 ∈C(M1, M2) having minimal trace.
Clearly δ(M1, M2) is symmetric in its arguments and takes positive values unless
M1 = M2, in which case δ(M1, M2) = 0. Thus, we only need to prove the triangle
inequality. Given Mi ∈M for i ∈{1, 2, 3}, we denote by Mik corresponding minimal
elements as above for i, k ∈{1, 2, 3}, and we let
∆ik := Mik −Mk.
These matrices are non-negative by construction, the identities
Mi + ∆ki = Mk + ∆ik
hold, and
δ(Mi, Mk) = 1
ntrace (∆ik + ∆ki)

Distances Between Time-Series and Their Autocorrelation Statistics
117
for i, k ∈{1, 2, 3}. But then,
M1 + ∆21 −∆12 = M2
= M3 + ∆23 −∆32,
and hence,
M1 + ∆21 + ∆32 = M3 + ∆23 + ∆12.
From the minimal property of ∆13 and of ∆31 with regard to having the least value for
the combined trace so that M1 + ∆31 = M3 + ∆13, it follows that
trace (∆13 + ∆31) ≤trace (∆21 + ∆32 + ∆23 + ∆12).
Therefore,
δ(M1, M2) + δ(M2, M3) = δ(M1, M3),
which completes the proof.
2
We now observe that the steps of the proof of Proposition 1 permit incorporating linear
constraints on the structure of elements of M, such as the constraint of all matrices be-
ing Toeplitz. Hence, whereas δ(·, ·) may be used directly as a distance measure between
elements of Tn, the corresponding minimal-trace perturbations ∆ik may not belong to
Tn in general. But, since the Toeplitz property is a linear constraint, we may deﬁne a
completely analogous distance measure enforcing such perturbations (if so desired) to
be Toeplitz.
Proposition 2. Let M1, M2 ∈Tn and
τT (M1, M2) := min
 1
ntrace (M) | M ∈Tn, and
M ≥M1, M ≥M2

.
Then
δT (M1, M2) := 2τT (M1, M2) −trace (M1) −trace (M2)
(8)
deﬁnes a metric on Tn.
Proof. The proof follows the steps of the proof of Proposition 1 verbatim, except for
the fact that we now constraint all matrices to belong to Tn.
2
Proposition 3. Let fy, fˆy be power spectral densities, i.e., nonnegative and integrable
on [−π, π]. Let as before Rn, ˆRn denote the corresponding Toeplitz covariance ma-
trices, and let n ∈{1, 2, . . .}. Then
lim
n→∞δT (Rn, ˆRn) = ∥fy −fˆy∥1.

118
T.T. Georgiou
Proof. Clearly
lim
n→∞δT (Rn, ˆRn) ≤∥fy −fˆy∥1
since a choice of ψk and ˆψk with power spectra as in (3a-3b) gives rise to partial co-
variance matrices Qn, ˆQn, for all n, for which (6) holds. The respective 0th elements
Q0 and ˆQ0 remain the same for all n and the left hand side is
∥fy −fˆy∥1 = Q0 + ˆQ0
since the power spectra in (3a-3b) have no overlap in their support.
To show the converse inequality, consider the sequence of minimizing Qn, ˆQn.
These are Toeplitz matrices with bounded entries (since their corresponding 0th ele-
ment is bounded by ∥fy −fˆy∥1). Each can be extended to an inﬁnite Toeplitz matrix,
and thereby, gives rise to power spectral densities qn and ˆqn such that the ﬁrst n Fourier
coefﬁcients of fy + qn and fˆy + ˆqn coincide. The spectral densities qn and ˆqn can be
obtained from Qn, ˆQn by any particular positive extension, for instance a “maximum
entropy” one. We can take those as pairs, and since they are bounded there exists a
subsequence weakly convergent to possibly non-negative measures, dµ and dˆµ, such
that
fydθ + dµ = fˆydθ + dˆµ
since their Fourier coefﬁcients must coincide. If dµ, dˆµ do have singular parts then
these should be identical and the absolutely continuous parts must balance as well, so
there exist power spectral densities q and ˆq such that
fy + q = fˆy + ˆq.
(9)
But then,
lim
n→∞δT (Rn, ˆRn) ≥lim
n→∞
1
2π
 π
−π
(qn(θ) + ˆqn(θ))dθ
= 1
2π
 π
−π
(dµ + dˆµ)
≥1
2π
 π
−π
(q + ˆq)dθ
≥∥fy −fˆy∥1,
the last inequality from (9).
2
3.1
An Example
The metric δT (Rn, ˆRn) of the previous section admits no simple expression in terms of
the respective eigenvalues. This should be contrasted with its limiting value d(fy, fˆy)
which is the L1 distance between the corresponding power spectral densities. We high-
light this with an example.

Distances Between Time-Series and Their Autocorrelation Statistics
119
Let
R3 =
⎡
⎣
1
1
1
1
1
1
1
1
1
⎤
⎦
and
ˆR3 =
⎡
⎣
1
1/2 1/2
1/2 1
1/2
1/2 1/2
1
⎤
⎦.
Then, clearly,
Q3 =
⎡
⎣
x
y
y
y
x
y
y
y
x
⎤
⎦
and
ˆQ3 =
⎡
⎣
x
v
v
v
x
v
v
v
x
⎤
⎦
where
1 + y = 1/2 + v
and x is minimal subject to Q3 ≥0 as well as ˆQ3 ≥0. The last two inequalities imply
that
0 ≤x
as well as
−1
2x ≤y, v ≤x.
It follows that the optimal choice (minimal x) is
x =
1/3
y = −1/6
v =
1/3.
Then
δT (R3, ˆR3) = 2x = 2/3,
while the respective eigenvalues are
spec(R3) = {3, 0, 0} and
spec( ˆR3) = {1, 1, 1/2}.
There is no simple expression for δT (R3, ˆR3) based solely on knowledge of
spec(R3) and spec( ˆR3), although δT (R3, ˆR3) can actually be expressed as the ab-
solute sum of the eigenvalues of the difference R3 −ˆR3.
The covariance R3 has a unique extension and corresponds to a measure with unit
weight at θ = 0, i.e., a spectral line (Dirac delta) at θ = 0. Assuming that ˆR3 originates

120
T.T. Georgiou
from a spectral measure which has a similar weight of amplitude 1/2 at θ = 0 and a
uniform absolutely continuous part of amplitude 1/2, then
∥dµ −dˆµ∥1 = 1/2 + 1/2 = 1
adding the L1-norm of the difference of the absolutely continuous parts with the abso-
lute integral of the discrepancy between the two measures. We leave it as an exercise to
the reader to verify that if ˆRn is as we just assumed, namely ˆRk = 1/2 for k ≥1, and
similarly, Rk = 1 for all k, then δT (Rn, ˆRn) →1 as n →∞.
4
Approximating Sample Covariances
It is often the case that the autocovariance matrix Rn of a random process yk is es-
timated in a way that does not guarantee this to be Toeplitz. For instance, it is quite
common for Rn to be estimated by averaging observation samples
ˆRn =
1
N + 1
N

ℓ=0
⎡
⎢⎣
y1+ℓ
...
yn+ℓ
⎤
⎥⎦
5
y1+ℓ. . . yn+ℓ
6
The estimate ˆRn is non-negative deﬁnite by construction, but may not be Toeplitz. Yet,
for purposes of analysis it is often beneﬁcial to approximate Rn by a Toeplitz one,
or possibly, by one with additional structure (e.g., corresponding to a moving average
process or, more generally, to the state of a known dynamical system). The problem of
seeking such an approximant which is closest to Rn in δ(·, ·), is readily solvable via
convex optimization.
4.1
Comparison with the von Neumann Entropy
In [1], the question was raised as to what are appropriate ways to approximate a given
sample covariance with one that abides by a known linear structure. It was proposed
that the Kullback-Leibler-von Neuman distance
S( ˆR∥R) := trace
1
ˆR
1
log ˆR −log R
22
provides a convenient convex functional for which the optimal approximant is uniquely
deﬁned. An academic example was presented in [1] which is recapitulated here as it
helps underscore differences with approximation in the sense of minimizing δ( ˆR, R).
Consider the positive-deﬁnite matrix below as the estimated value for a covariance
matrix
ˆR3 = 1
3
⎡
⎣
1.1 .9 1.05
.9
.8
.9
1.05 .9 1.1
⎤
⎦.
The minimizer of
{S( ˆR, R) | R being Toeplitz, R > 0, trace(R) = trace( ˆR)}

Distances Between Time-Series and Their Autocorrelation Statistics
121
is unique (see [1]) and given by
R3,vN = 1
3
⎡
⎣
1
.942 .957
.942
1
.942
.957 .942
1
⎤
⎦.
It is interesting to point out the the closest Toeplitz matrix to ˆR in the least-squares sense
fails to be positive-deﬁnite ( [1], cf. [2]). On the other hand, the optimal approximant
in δ(·, ·)-sense can be obtained by observation and is equal to
R3,δ = 1
3
⎡
⎣
1.1
.9 1.05
.9
1.1
.9
1.05 .9
1.1
⎤
⎦.
In the above, a second subscript indicates the sense in which the matrix approximates
ˆR3. Obviously the traces of R3,δ and ˆR3 are not the same, in general. However,
equality of the traces can be easily imposed as an added linear constraint.
4.2
Structured Covariances
For purposes of illustration, consider a moving average process
yk = wk + wk−1 + wk−2
where wk is a zero-mean, unit-variance, Gaussian white noise process. The autocorre-
lation sequence of yk is
5R0 R1 R2 R3 0 . . .6
=
53 2 1 0 0 . . .6
.
Simulating yk over a window k ∈{0, 1, . . ., 100}, and based on a particular such
realization, the corresponding n×n sample covariance matrix, for n = 5, was computed
to be
ˆR5 =
⎡
⎢⎢⎢⎢⎣
4.0362 2.9053 1.8043 0.4042 0.1718
2.9053 4.0547 2.9268 1.7945 0.3800
1.8043 2.9268 4.0792 2.9143 1.7733
0.4042 1.7945 2.9143 4.0819 2.9421
0.1718 0.3800 1.7733 2.9421 4.0237
⎤
⎥⎥⎥⎥⎦
.
Obviously, this matrix is not Toeplitz due to the ﬁniteness of the observation record.
The closest Toeplitz approximant to ˆR5, in the sense of the metric δ(·, ·), turns out to
be
R5,Toeplitz =
⎡
⎢⎢⎢⎢⎣
4.0677 2.9237 1.7912 0.3979 0.1822
2.9237 4.0677 2.9237 1.7912 0.3979
1.7912 2.9237 4.0677 2.9237 1.7912
0.3979 1.7912 2.9237 4.0677 2.9237
0.1822 0.3979 1.7912 2.9237 4.0677
⎤
⎥⎥⎥⎥⎦
for which
δ( ˆR5, R5,Toeplitz) = 0.0308.

122
T.T. Georgiou
Interestingly, R5,Toeplitz does not correspond to a moving average process of order 2
(or even, of order 3, 4) as it can be readily veriﬁed by the fact that the trigonometric
polynomials, e.g.,
4

k=−4
Rkejkθ
takes negative values.
The set of covariance matrices which are generated by moving average processes of a
given order, is convex and admits a characterization via a set of linear matrix inequalities
( [8, 3]). Thus, the closest approximant to ˆR which corresponds to a moving average
process of any given order can be readily computed. In particular, if we specify the
order to be 2, then the optimal approximant to ˆR5 becomes
R5,MA(2) =
⎡
⎢⎢⎢⎢⎣
4.1184 2.7678 1.3497
0
0
2.7678 4.1184 2.7678 1.3497
0
1.3497 2.7678 4.1184 2.7678 1.3497
0
1.3497 2.7678 4.1184 2.7678
0
0
1.3497 2.7678 4.1184
⎤
⎥⎥⎥⎥⎦
for which
δ( ˆR5, R5,MA(2)) = 0.5017.
References
1. T.T. Georgiou (2003) Toeplitz covariance matrices and the von Neumann relative entropy. In:
K. Hashimoto, Y. Oishi, and Y. Yamamoto (eds) Control and Modeling of Complex Systems:
Cybernetics in the 21st Century. MA: Birkhauser, Boston
2. T.T. Georgiou (2006) Relative Entropy and the multi-variable multi-dimensional Moment
Problem, IEEE Trans. on Information Theory, 52(3): 1052-1066.
3. T.T. Georgiou (2006) Decomposition of Toeplitz matrices via convex optimization, IEEE Sig-
nal Processing Letters, 13: 537-540.
4. T.T. Georgiou (2007) Distances and Riemannian metrics for spectral density functions,
IEEE Trans. on Signal Processing, to appear. Preprint available at: http://arxiv.org/abs/
math/0608486/
5. T.T. Georgiou (2007) An intrinsic metric for power spectral density functions, IEEE Signal
Processing Letters, to appear. Preprint available at: http://arxiv.org/abs/math/0607026/
6. R. Gray, A. Buzo, A. Gray, and Matsuyama (1980) Distortion measures for speech processing,
IEEE Trans. on Acoustics, Speech, and Signal Proc., 28(4): 367-376.
7. P. Stoica and R. Moses (2005) Introduction to Spectral Analysis. Prentice Hall
8. P. Stoica, T. McKelvey, and J. Mari (2000) MA estimation in polynomial time, IEEE Trans.
on Signal Processing, 48: 1999-2012.

Global Identiﬁability of Complex Models, Constructed
from Simple Submodels⋆
Markus Gerdin1, Torkel Glad2, and Lennart Ljung2
1 NIRA Dynamics AB, Gothenburg, Sweden
markus.gerdin@gmail.com
2 Link¨oping University, S-58183 Link¨oping Sweden
{torkel,ljung}@isy.liu.se
To Giorgio, with admiration, on the occasion of his 65th birthday
Summary. It is a typical situation in modern modeling that a total model is built up from simpler
submodels, or modules, for example residing in a model library. The total model could be quite
complex, while the modules are well understood and analysed. A procedure to decide global
parameter identiﬁability for such a collection of model equations of differential-algebraic nature
is suggested. It is shown how to make use of the natural modularization of the model structure.
Basically, global identiﬁability is obtained if and only if each module is identiﬁable, and the
connecting signals can be retrieved from the external signals, without knowledge of the values of
the parameters.
1
Introduction
Identiﬁability is a crucial concept in System Identiﬁcation. It concerns the question of
whether the parameters in a model structure can be uniquely retrieved from input-output
data. Clearly, being able to assess the identiﬁability of a structure beforehand, without
going through all the estimation labor would be a very helpful technique.
The literature on identiﬁability and techniques to check identiﬁability is extensive,
see, e.g. [3], Chapter 4, [7, 8], [4]. Identiﬁability of linear black-box models in terms
of canonical forms etc, is basically a solved problem. However even for linear models
physically parameterized structures form a highly non-trivial challenge, see e.g. [5],
and there are no efﬁcient techniques other than in certain subclasses of problems. The
idea of [4] to use differential algebra leads to a well deﬁned algorithm for quite general
structures, but it suffers from too high computational complexity in many realistic cases.
In this contribution we shall consider a common situation in deﬁning model struc-
tures: Suppose that the model is made of from several interconnected modules. Each of
these modules are simple and have well deﬁned identiﬁability properties, in case they
are encountered on their own. The modules are interconnected in well deﬁned ways, but
the interconnecting signals are not necessarily measured. The question is then how the
⋆This work has been supported by the Swedish Foundation for Strategic Research (SSF)
through VISIMOD and ECSEL and by the Swedish Research Council (VR) which is gratefully
acknowledged.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 123–133, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

124
M. Gerdin, T. Glad, and L. Ljung
identiﬁability of the total model can be studied in terms of the module properties and
their interconnections. This way of dealing with model structures is typical in modular-
based (or object-oriented) modeling environments, such as MODELICA, see e.g. [1]. A
more complete discussion on identiﬁablity of modular models described by algebraic
differential equations (DAEs) is given in [2].
2
The Problem
Consider a model structure built up from a collection of sub-models, or modules,
Mk, k = 1, . . . , m. Each module is a model that describes the relationship between
a number of connecting signals wk,i(t), i = 1, . . . , nk.
This relationship involves
also a number of internal signal ℓk,i(t), 1 = 1, . . . , pk and a number of parameters
θk,i, i = 1, . . . , qk. The relations may be expressed as a collection of algebraic or dif-
ferential equations. With p denoting the differentiation operator, the model for module
Mk can be written
fk,i(ℓk,1(t), . . . , ℓk,pk(t), wk,1(t), . . . , wk,nk(t),
. . . , θk,1, . . . θk,qk, p) = 0, i = 1, . . . , rk
With obvious “vectorization” of ℓk,·, wk,·, θk,· and fk,· we will write the above equa-
tion as
fk(ℓk(t), wk(t), θk, p) = 0
(1a)
The modules are then connected by describing how the connecting signals wk inter-
connect and relate to globally external signals z(t) (“inputs” and “outputs”)
g(z(t), w1(t), . . . , wm(t)) = 0
(1b)
Typically the inputs and outputs will be equal to some of the connecting signals wk,i.
The distinction between inputs and outputs is immaterial for the present discussion. See
Figure 1.
As a simple case, the reader may picture Mk as resistors, capacitors and inductors,
with well known relationships (1a) between voltage drops, currents (ℓk(t), wk(t)) and
component parameters θk (resistance, capacitance, inductance). An arbitrary RLC-
circuit can then be deﬁned by the interconnections (1b) between voltages and currents
wk(t) following Kirchhoff’s laws.
Now, the total model is given as (1) with z(t) as external signals, also depicted in
Figure 1. The identiﬁability question for this total model is
•
Given the external signals z(t), t ∈T , is it possible to uniquely determine all the
parameters θk, k = 1, m?. That is, can the equations (1) be satisﬁed for different
parameter values for a given z(t), t ∈T ?
If it indeed is possible to uniquely retrieve the parameter values, we say that the
model is globally identiﬁable for the given external signal. (See, e.g. [4] and [2] for
more strict deﬁnitions).

Global Identiﬁability of Complex Models
125
Fig. 1. Interconnected modules of submodels. wk,i is the i:th external connecting signal in mod-
ule k and z are the global external signals. ℓk,iand θk,i (with a strange font) are internal signals
and parameters in the modules.
The following result is plausible
Result 1. The model (1) is globally identiﬁable if and only if
a) The external signals wk(t) can be uniquely retrieved from z(t) and (1), without
knowledge of the parameter values θk.
b) Each module Mk is globally identiﬁable for retrieved external signal wk(t)
A formal version of this result will be proved in the course of this contribution, but the
result is not difﬁcult to appreciate and understand intuitively. Clearly a) and b) will im-
ply global identiﬁability, since with retrieved interconnecting signals wk identiﬁability
of the modules will guarantee that all parameters can be found uniquely. Conversely, if
a module is not identiﬁable with known signals wk it is clear that its parameters cannot
be found when the signals are not known (or reconstructed). It is perhaps somewhat less
obvious to realize that wk can be uniquely retrieved for a globally identiﬁably model
structure. However, the argument is as follows: Suppose the model structure is well
deﬁned, so that the model can be simulated for any set of parameter values. Then with
the globally identiﬁed parameters inserted and the (input part of the) external signals
z(t) well deﬁned, all interconnecting signals wk will be generated in a unique way by
such a simulation.

126
M. Gerdin, T. Glad, and L. Ljung
3
A Simple Example of Interconnected Modules
To illustrate the role of the interconnecting signals, let us consider an almost trivial
example. Take a module as an integrator with unknown gain. The input to the integrator
is w1 and its output is w2:
˙w2(t) = θ1w1(t)
(2a)
Clearly this module is globally identiﬁable with known external signals w1, w2. Let us
now cascade two such modules:
˙w4(t) = θ2w3(t)
(2b)
For the cascaded system, we have input z1(t) = w1(t) and output z2(t) = w4(t) so
the interconnecting equations are
z1(t) = w1(t)
(3a)
w3(t) = w2(t)
(3b)
z2(t) = w4(t)
(3c)
The model structure obtained by cascading these two identiﬁable modules is however
not identiﬁable: From measuring only z(t) we can ﬁnd out the product θ1·θ2 but not the
individual values. In view of Result 1 in the previous section, this must mean that the
interconnecting signal w3 = w2 cannot be uniquely retrieved from z(t), even knowing
that the signals relate via integrators. In fact, we will know that w2 is proportional to
˙z2(t) but have no way to ﬁnd the coefﬁcient of proportionality.
Now, if, say θ1 is known to be θ1 = 1, the global structure should be identiﬁable.
That means that w2(t) can be uniquely retrieved, but it is instructive to realize that it
has to be done with care. Knowing the double integrator structure and the input z1(t)
we can only conclude that
w2(t) =

z1(s)ds + Constant
where the constant is due to initial conditions. So w2 cannot be uniquely retrieved.
However, knowing also z2(t) gives the relation
θ2w2(t) = ˙z2(t)
(4)
From this we may obtain (differentiate (4), use ˙w2 = z1 and eliminate θ2 from the
obtained two equations):
¨z2(t)w2(t) = z1(t) ˙z2(t)
(5)
so, as long as ¨z2(t) is nonzero we can ﬁnd w2(t) uniquely. Here are no unknown
constants nor initial conditions involved. The simple example also shows that some
care must be exercised when examining the retrieval of the interconnecting signals.
The condition that ¨z2 is nonzero means that z1 and θ1 ˙θ2 must be nonzero. This is
an example of an excitation condition on the (input) signals, and particular parameter
values that typically is required to assure identiﬁability.

Global Identiﬁability of Complex Models
127
4
Preliminary Considerations and Tools
Our goal is to use Result 1 to study identiﬁability of complex model structures (1) in
terms of identiﬁability of the modules Mk. In many applications these modules will be
standardized in model libraries so the identiﬁability of these can be examined once and
for all. The crux then is to establish condition a) in the Result, that the interconnecting
signals can be uniquely retrieved from the external signals z(t), and the model equations
without knowledge of the parameter values. An obvious way is to ﬁnd a parameter-free
relation, such as (5) from which w can be determined from z. How can that be done?
For that we will use the tools of differential algebra, [6] as applied to identiﬁability
in [4]. In short, the idea is that the original set of model equations can be transformed to
a new set by differentiating, and performing simple algebraic operations. Under certain
conditions the solutions to the new equation set will be identical to the solutions of the
original one. So the identiﬁability analysis can be applied to the new set instead. It is
then a matter to let the new set be as well suited as possible for such analysis.
Remark: Strictly speaking the formal result is limited to the case that the fk are poly-
nomial expressions. However, more general cases can also be handled. Such a case is
given in Example 3 below.
More speciﬁcally, consider a module (1a):
fk(ℓk(t), wk(t), θk, p) = 0
(6)
where fk is a vector, so that the expression covers several model equations. By manip-
ulating these equations with differential algebraic tools, they can be transformed to the
following set
Ak,1(wk, p), . . . , Ak,nAk (wk, p),
(7a)
Bk,1(wk, θk,1, p), Bk,2(w, θk,1, θk,2, p),
(7b)
Bk,nθk (wk, θk,1, θk,2, . . . , θk,nθk , p),
Ck,1(wk, θk, ℓk, p), . . . , Ck,nlk (wk, θk, ℓk, p).
(7c)
The A-equations are then just relationships between (derivatives of) the interconnecting
signals wk, not involving the internal variables ℓk nor the parameters. The B-equations
will reveal whether the parameters θk are identiﬁable. The main result in [4] is that
the module Mk is globally identiﬁable if and only if the B-equations have a linear
regression form:
Bk = Pk(wk, p)θk −Qk(wk, p),
(8)
The excitation condition (see the end of Section 3) on wk is then that Pk is invertible.
Example 1. Capacitor: Consider a capacitor described by the voltage drop w1, current
w2 and capacitance θ1. It is then described by (1a) with
f1 =
θ1 ˙w1 −w2
˙θ1

.
(9)

128
M. Gerdin, T. Glad, and L. Ljung
If we consider only situations where ˙w1 ̸= 0 we get the following series of equivalences.
θ1 ˙w1 −w2 = 0,
˙θ1 = 0,
˙w1 ̸= 0
⇔
θ1 ˙w1 −w2 = 0,
θ1 ¨w1 −˙w2 = 0,
˙w1 ̸= 0
⇔
θ1 ˙w1 −w2 = 0,
θ1 ˙w1 ¨w1 −˙w1 ˙w2 = 0,
˙w1 ̸= 0
⇔
θ1 ˙w1 −w2 = 0,
w2 ¨w1 −˙w1 ˙w2 = 0,
˙w1 ̸= 0
(10)
With the notation (7) we thus have
A1,1 = w2 ¨w1 −˙w1 ˙w2
(11a)
B1,1 = θ1 ˙w1 −w2
(11b)
The capacitor is thus globally identiﬁable, provided ˙w1 ̸= 0.
This gives an idea of how to handle condition a) in Result 1: If we work with previously
analyzed modules Mk in a model library, we have already their A-equations, (7a). We
can dispense with the remaining B and C-equations. For global identiﬁability of the
whole model we need to consider the total collection of A-equations together with the
connecting equations (1b) and check whether all the interconnecting signals w can be
retrieved from this set of equations,
A1,1(w1, p), . . . , Am,nAm(wm, p)
(12a)
g(z(t), w(t)) = 0
(12b)
knowing the external variables z(t). Here (12b) is a more compact way of writing (1b).
5
Identiﬁability Analysis
In this section we shall illustrate how to use Result 1 for identiﬁability analysis based
on submodels in a model libraray. We will use a minimal model library consisting of a
resistor model, an inductor model, and a capacitor model. Note that these components
have corresponding components for example within mechanics and ﬂuid systems. Bond
graphs make full use of such analogies: it follows that our simple model library is quite
representative of more general cases. A capacitor model was described in Example 1.
Similarly, we have
Example 2. Inductor: Next consider an inductor where w2 is the current, w1 the volt-
age and θ1 the inductance. It is described by
θ1 ˙w2 = w1,
˙θ1 = 0
(13)
Calculations similar to those of the previous example show that this is equivalent to
θ1 ˙w2 = w1,
¨w2w1 = ˙w2 ˙w1
(14)
provided ˙w2 ̸= 0.

Global Identiﬁability of Complex Models
129
As discussed earlier, the transformation to (7) can always be performed for polynomial
DAE. To show that calculations of this type in some cases also can be done for non-
polynomial models, we consider a nonlinear resistor where the voltage drop is given by
an arbitrary function.
Example 3. Nonlinear Resistor: Consider a nonlinear resistor with the equation
w1 = R(w2, θ1)
(15)
where it is assumed that the parameter θ1 can be uniquely solved from (15) if the voltage
w1 and the current w2 are known, so that
θ1 = φ(w1, w2).
(16)
Differentiating (15) once with respect to time and inserting (16) gives
˙w1 = Rw2

w2, φ(w1, w2)

˙w2
(17)
which is a relation between the external variables w1 and w2. We use the notation Rx
for the partial derivative of R with respect to the variables x. In the special case with a
linear resistor, where R = θ1 · w2, this reduces to
˙w1 = w1
w2
˙w2
(18a)
⇔w2 ˙w1 = w1 ˙w2
(18b)
(assuming w2 ̸= 0).
We shall here examine the identiﬁability of different connections of the components.
Fig. 2. A resistor and an inductor connected in series
Example 4. Consider a nonlinear resistor and an inductor connected in series where the
current w2 = f and total voltage u are measured as shown in Fig. 2. Denote the voltage
over the resistor with w1 and the voltage over the inductor with w3. Using Examples 2
and 3 we get the equations
˙w1 = Rw2

w2, φ(w1, w2)

˙w2
(19a)
¨w2w3 = ˙w2 ˙w3
(19b)
for the components and the equation
w1 + w3 = u
(19c)

130
M. Gerdin, T. Glad, and L. Ljung
for the connections. Differentiating the last equation once gives
˙w1 + ˙w3 = ˙u.
(19d)
The system of equations (19) (with w1, ˙w1, w3, and ˙w3 as unknowns) has the Jacobian
⎛
⎜
⎜
⎝
−Rw2,w1 ˙w2 1 0
0
0
0 ¨w2 −˙w2
1
0 1
0
0
1 0
1
⎞
⎟
⎟
⎠
(20)
where
Rw2,w1 =
∂
∂w1

Rw2

w2, φ(w1, w2)

.
(21)
The Jacobian has the determinant −Rw2,w1 · ˙w2
2 + ¨w2, so the system of equations
is solvable for most values of the external variables. This means that the system is
identiﬁable.
Fig. 3. Two capacitors connected in series
Example 5. Now consider two capacitors connected in series where the current w2 = f
and total voltage u are measured as shown in Fig. 3. Denote the voltages over the
capacitors with w1 and w3 respectively. Using Example 1 we get the equations
w2 ¨w1 = ˙w1 ˙w2
(22a)
w2 ¨w3 = ˙w3 ˙w2
(22b)
for the components. The connection is described by the equation
w1 + w3 = u.
(23)
These equations directly give that if
w1(t) = φ1(t)
(24a)
w3(t) = φ3(t)
(24b)
is a solution, then so are all functions of the form
w1(t) = (1 + λ)φ1(t)
(25a)
w3(t) = φ3(t) −λφ1(t)
(25b)
for scalar λ. Since (11b) implies that the capacitance is an injective function (i.e. no
two arguments give the same function value) of the derivative of the voltage, this shows
that the system is not identiﬁable.

Global Identiﬁability of Complex Models
131
6
A Formal Theorem on Identiﬁability from Sub-models
We shall in this section prove a formal version of Result 1.
Consider a model structure consisting of m interconnected modules Mk, (1a). As-
sume that the different modules do not have common parameters, and that the differ-
ential algebraic equations (1) are polynomial in their arguments. Assume also that all
modules are identiﬁable if their connecting variables wi are measured. This means, that
given measurements of
wi
i = 1, . . . , m
(26)
the unknown parameters θ can be computed uniquely from the B-polynomials in (7b).
When examining identiﬁability of the connected system it is not a big restriction to
assume that the individual components are identiﬁable since information is removed
when not all wi are measured.
When the components have been connected, the only knowledge available about the
wi is the A-polynomials in (7a) and the equation
g

z(t), w(t)

= 0.The connected system is thus identiﬁable if the wi can be computed
from (12):
Aij

wi(t), p

= 0
8
i = 1, . . . , m
j = 1, . . . , nAi
(27a)
g

z(t), w(t)

= 0.
(27b)
Note that this means that all w(t) are algebraic variables (not differential), so that no
initial conditions can be speciﬁed for any component of w(t). If, on the other hand,
there are several solutions to the equations (27) then these different solutions can be
inserted into the B polynomials, so there are also several possible parameter values. In
this case the connected system is therefore not identiﬁable. Note again that measured
inputs and outputs lead to equations of the form wi(t) = u(t), where the function u is
included in the time-variability of g.
The result is formalized in the following theorems. Note that the distinction between
global and local identiﬁability was not discussed above, but this will be done below.
6.1
Global Identiﬁability
Global identiﬁability means that there is a unique solution to the identiﬁcation problem,
given that the measurements are informative enough. For a subsystem (1a) that can be
rewritten in the form (7) global identiﬁability means that the Bi,j can be solved uniquely
to give the θi,j. In other words there exist functions ψ, that can in principle be calculated
from the Bi,j, such that
θi = ψi(wi, p).
(28)
We then have the following formal result on identiﬁability.
Theorem 1. Consider a modular model structure where the modules (1a) are globally
identiﬁable and thus can be described in the form (28). A sufﬁcient condition for the
total model structure to be globally identiﬁable is that (27) can be solved uniquely for
the wi. If all the functions ψi of (28) are injective then this condition is also necessary.

132
M. Gerdin, T. Glad, and L. Ljung
Proof: If (27) gives a global solution for w(t), then this solution can be inserted into
the B polynomials to give a global solution for θ since the components are globally
identiﬁable. The connected system is thus globally identiﬁable. If there are several
solutions for wi and the functions ψi of (28) are injective, then there are also several
solutions for θ, so the system is not globally identiﬁable since the identiﬁcation problem
has more than one solution.
6.2
Local Identiﬁability
Local identiﬁability of a model structure means that locally there is a unique solutions
to the identiﬁcation problem, but globally there may be more than one solution. This
means that the description (28) is valid only locally. We get the following result on
local identiﬁability.
Theorem 2. Consider a modular model structure where the modules (1a) are locally
identiﬁable and thus can be locally described in the form (28). A sufﬁcient condition
for the total model to be locally identiﬁable is that (27) can be solved locally uniquely
for the wi. If all the functions ψi of (28) are locally injective then this condition is also
necessary.
Proof: If (27) gives a locally unique solution for w(t), then this solution can be in-
serted into the B polynomials to give a local solution for θ since the components are
locally identiﬁable. The connected system is thus locally identiﬁable. If there locally
are several solutions for wi and the functions ψi of (28) are injective, then there are also
several local solutions for θ, so the system is not locally identiﬁable since the identiﬁ-
cation problem locally has more than one solution.
7
Conclusions
This paper has shown how a modular structure of a large model can be used to simplify
examination of identiﬁability. For modules in model libraries, the transformation to
the form (7) is computed once and for all and stored with the module. This makes it
possible to only consider a smaller number of equations when examining identiﬁability
for a model composed of such modules. Although the method described in this paper
may suffer from high computational complexity (depending, among other things, on the
method selected for deciding the number of solutions for (12)), it can make the situation
much better than when trying to use to use the differential-algebra approach described
in [4] on a complete model.
The technique could be included in tools for object-oriented modeling such as DY-
MOLA and OPENMODELICA. Preferably, this could be part of a complete set of sys-
tem identiﬁcation routines linked to the modeling software. The identiﬁcation routines
could either be included directly in the modeling software, or as external software that
interacts with the modeling software.
Future work could include to examine if it is possible to make the method fully auto-
matic, so that it can be included in modeling tools and to examine if other system anal-
ysis or design methods can beneﬁt from the modularized structure in object-oriented

Global Identiﬁability of Complex Models
133
models. It could also be interesting to examine the case when several components share
the same parameter. This could occur for example if the different parts of the system
are affected by environmental parameters such as temperature and ﬂuid constants.
References
1. Peter Fritzson. Priciples of Object-Oriented Modeling and Simulation with Modelica 2.1.
Wiley IEEE, New York, 2004.
2. Markus Gerdin. Identiﬁcation and Estimation for Models Described by Differential-Algebraic
Equations. PhD thesis, Link¨oping University, Link¨oping, Sweden, 2006. Dissertation No
1046.
3. L. Ljung. System Identiﬁcation - Theory for the User. Prentice-Hall, Upper Saddle River,
N.J., 2nd edition, 1999.
4. Lennart Ljung and Torkel Glad. On global identiﬁability of arbitrary model parameterizations.
Automatica, 30(2):pp 265–276, Feb 1994.
5. P. Parrilo and Lennart Ljung. Initialization of physical parameter estimates. In P. van der Hof,
B. Wahlberg, and S. Weiland, editors, Proc. 13th IFAC Symposium on System Identiﬁcation,
pages 1524 – 1529, Rotterdam, The Netherlands, Aug 2003.
6. J.F. Ritt. Differential Algebra. American Mathematical Society, Providence, R.I., 1950.
7. E. Walter. Identiﬁcation of State Space Models. Springer Verlag, Berlin, 1982.
8. E. Walter, editor. Identiﬁability of Parametric Models. Pergamon Press, Oxford, 1987.

Identiﬁcation of Hidden Markov Models
- Uniform LLN-s
L´aszl´o Gerencs´er1 and G´abor Moln´ar-S´aska2
1 MTA SZTAKI (Computer and Automation Institute,
Hungarian Academy of Sciences), 13-17 Kende u., Budapest 1111, Hungary
Tel.: (36-1)-279-6138, (36-1)-279-6190; Fax: (36-1)-466-7503
gerencser@sztaki.hu
2 Morgan Stanley Hungary Analytics, Budapest, 15 De´ak Ferenc u., Budapest 1052, Hungary
Tel.: (36-1)-880-45-11
gabor.molnar-saska@morganstanley.com
Summary. We consider hidden Markov processes in discrete time with a ﬁnite state space X and
a general observation or read-out space Y. The identiﬁcation of the unknown dynamics is carried
out by the conditional maximum-likelihood method. The normalized log-likelihood function is
shown to satisfy a uniform law of large numbers over certain compact subsets of the parameter
space. Two cases are covered: ﬁrst, when the running value of the transition probability matrix,
denoted by Q is positive, second, when Q is primitive, but the read-out densities are strictly
positive.
Keywords: hidden Markov models, maximum-likelihood estimation, predictive ﬁlters, gradient
ﬁlters, L-mixing, uniform laws of large numbers.
1
Introduction
We consider Hidden Markov Models (HMM) or hidden Markov processes with a ﬁnite
state space X, |X| = N, and a general observation or read-out space Y, which is
assumed to be a Polish space, i.e. a complete, separable metric space, or a measurable
subset of it. We will identify X with {1, . . ., N}.
We consider the problem of estimating the unknown true transition probability ma-
trix and the unknown true read-out probability densities, which may or may not belong
to a parametric family. The true transition probability matrix, denoted by Q∗, is as-
sumed to be primitive, i.e (Q∗)r > 0 for some positive integer r.
The ﬁrst results for ﬁnite state-space X and ﬁnite read-out space Y are due to Baum
and Petrie, [2]. The case of binary readouts has been studied by Arapasthotis and Mar-
cus, [1], using different techniques. The extension of these results to continuous read-
out space requires new techniques.
The identiﬁcation of the unknown dynamics is carried out by the conditional
maximum-likelihood method, the condition being the unknown initial state. The ﬁrst
step in proving consistency of the maximum likelihood method would be to show the
validity of the strong law of large numbers for the log-likelihood function. This has
been investigated in the literature using basically three different methods in our con-
text. Leroux [14] used the subadditive ergodic theorem, LeGland and Mevel used the
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 135–150, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

136
L. Gerencs´er and G. Moln´ar-S´aska
theory of geometric ergodicity, see [13], [12], and [15], ﬁnally in [10] and [9] the the-
ory of L-mixing processes has been used. The advantage of the latter approach is that it
enables us to adapt a variety of techniques developed for the statistical theory of linear
stochastic systems for HMM-s.
The main advance of the present paper is the outline of the derivation of a uniform
law of large numbers (ULLN), with rate of convergence in Lq, for the normalized log-
likelihood function over compact subsets of the parameter space, satisfying two fairly
weak technical conditions. These results will be derived under the condition that the
running or assumed value of the transition probability matrix, denoted by Q is primitive,
but the assumed read-out densities are strictly positive. It is not required that the true
system belongs to the model class, see [15].
The main technical tools have been developed in [9] and [8], see also [7]. In addi-
tion we provide a simple derivation of the exponential stability of the gradient ﬁlter as
opposed to the rather complicated derivation given in [13]. The basic idea for prov-
ing ULLN-s with rate of convergence has been borrowed from [4]. The results of the
present paper can be directly applied to extend a basic strong approximation theorem
given for ARMA-processes in [5] to HMM-s with primitive transition probability ma-
trices and positive read-out probabilities.
2
Hidden Markov Models
Deﬁnition 2.1. The stochastic process (Xn, Yn), n ≥0 taking its values in X × Y will
be called a hidden Markov process, if the state process (Xn) is a homogenous, strictly
stationary Markov process with state space X, and the observations or read-outs (Yn)
are conditionally independent and identically distributed given (Xn). It is assumed that
the observations Yk have a conditional density given Xk = x: for any Borel-set A we
have
P(Yk ∈A|Xk = x) =

A
b∗x(y)λ(dy),
where λ is a ﬁxed nonnegative, σ-ﬁnite measure on Y.
The upper index ∗indicates that we take the true value of the corresponding, unknown
read-out densities, as opposed to some assumed value that shows up in the estimation
problem.
Example 1. Gaussian read-outs. In this case the observations are of the form
Yn = h(Xn) + σ(Xn) ϵn,
n ≥0
where (ϵn) is a Gaussian i.i.d. sequence in Rm, independent of (Xn), and h : X →Rm
and σ : X →Rm×m are arbitrary mappings. If (Xn) itself is i.i.d., then we get a
Gaussian mixture.
Deﬁne the vector b∗(y) with its components being the read-out probabilities, and the
diagonal matrix B∗(y) its diagonal elements being (b∗i(y)), i = 1, . . . , N:
b∗(y) = (b∗1(y), . . . , b∗N(y))T ,
B∗(y) = diag(b∗i(y)).

Identiﬁcation of Hidden Markov Models - Uniform LLN-s
137
The transition probability matrix of the Markov process (Xn) will be denoted by Q∗,
i.e.
Q∗
ij = P(Xn+1 = j|Xn = i).
We write Q∗> 0 if all the elements of the transition probability matrix are strictly
positive.
We consider the problem of estimating the unknown transition probability matrix Q∗
and the unknown read-out probability densities b∗x(y) from a sequence of observations
y0, . . . yn using a given class of parametric models. For this consider a parametric fam-
ily of transition probability matrices Q(θ), and a parametric family of read-out proba-
bility densities bx(y; θ), where θ ∈D ⊂Rr, with D being a measurable set of feasible
parameters. The set D, to be speciﬁed later, can be arbitrary at this point. It is not
required that the true system belongs to the model class. If it does, the true parameter
will be denoted by θ∗∈D, thus we have
b∗x(y) = bx(y; θ∗)
and
Q∗= Q(θ∗).
To develop a maximum-likelihood method let θ ∈D be any parameter-value, and
let us write
bx(y) = bx(y; θ)
and
Q = Q(θ).
Let the set of probability vectors q = (q1, . . . , qN) be denoted by P, and let P(ϵ) ⊂P
be the set of q-s such that qi ≥ϵ > 0 for all i. Write the conditional log-likelihood
function, with condition P(X0 = i) = qi, with q ∈P as
log p(y0, . . . yn; θ, q) =
n−1

k=1
log p(yk|yk−1, . . . y0; θ, q) + log p(y0; θ, q).
(1)
Express the k-th term as
log p(yk|yk−1, . . . y0; θ, q) = log

i
bi(yk; θ)P(Xk = i|yk−1, . . . , y0; θ, q).
It is seen that a basic entity is the predictive ﬁlter, deﬁned as
pj
n+1 = pj
n+1(θ, q) = P(Xn+1 = j|yn, . . . , y0; θ, q).
Writing pn+1 = (p1
n+1, . . . , pN
n+1)T it is known that the ﬁlter process satisﬁes the
so-called Baum-equation, see [2], which is a discrete time version of the celebrated
Duncan-Mortensen-Zakai equation, see [3,16,22]:
pn+1 = π(QT B(yn)pn),
(2)
with initial condition p0 = q, where π is the normalizing operator: for x ≥0, x ̸= 0
set π(x)i = xi/ 
j xj, see [2]. A shorthand notation for the Baum-equation will be
pn+1 = f(yn, pn),
(3)

138
L. Gerencs´er and G. Moln´ar-S´aska
or, in a more explicit form:
pn+1(θ, q) = f(yn, pn(θ, q); θ).
(4)
With this notation the k-th term in (1) can be written as
log p(yk|yk−1, . . . y0; θ, q) = log

i
bi(yk; θ)pi
k(θ, q).
Introduce the function of the pair of variables (y, p) with p = (p1, . . . , pN), parameter-
ized by θ:
g(y, p ; θ) = log

i
bi(y; θ)pi.
(5)
Then we can write, with pk = pk(θ, q) and p0 = q,
log p(y0, . . . , yn; θ, q) =
n

k=0
g(yk, pk ; θ).
(6)
A standard step in proving consistency of the maximum likelihood is to show that
lim
n→∞
1
n log p(Y0, . . . Yn; θ, q) = W(θ)
(7)
exists almost surely, with the limit being independent of q. The existence of the limit
in (7) has been investigated in the literature using basically three different methods as
described in the introduction. In this paper we focus on [10] and the yet unpublished
paper [9], where we used the theory of L-mixing processes. The advantage of the latter
approach is that it enables us to adapt a variety of techniques developed for the statistical
theory of linear stochastic systems for the present context. The basic deﬁnitions will be
given in the next section.
3
L-Mixing Processes
In this short section we summarize the basic deﬁnitions related to L-mixing, as devel-
oped in [4]. L-mixing has been used extensively in the statistical analysis of linear
stochastic systems, see [4]. It is a concept which, in its motivation, strongly exploits the
stability and the linear algebraic structure of the underlying stochastic system. A major
advance of [9] is that the applicability of this concept in the framework of HMM-s have
been shown. First of all we need the deﬁnition of M-boundedness.
Deﬁnition 3.1. A stochastic process (Xn) (n ≥0) taking its values in an Euclidean
space is M-bounded if for all q ≥1
Mq(X) = sup
n≥0
E1/q∥Xn∥q < ∞.
(8)
If (Xn) is M-bounded we shall also write Xn = OM(1). Similarly if cn is a positive
sequence we write Xn = OM(cn) if Xn/cn = OM(1).
Let (Fn) and (F+
n ) be two sequences of monotone increasing and monotone de-
creasing σ-algebras, respectively, such that Fn and F+
n are independent for all n.

Identiﬁcation of Hidden Markov Models - Uniform LLN-s
139
Deﬁnition 3.2. A stochastic process (Xn) taking its values in a ﬁnite-dimensional Eu-
clidean space is L-mixing with respect to (Fn, F+
n ), if it is M-bounded, Fn-adapted,
and with
γq(τ) = sup
n≥τ
E1/q∥Xn −E(Xn|F+
n−τ)∥q
(9)
we have
Γq =
∞

τ=0
γq(τ) < ∞.
(10)
The usefulness of L-mixing is that its veriﬁcation is often much easier than the veriﬁ-
cation of other notions of mixing.
The above deﬁnitions extend to parameter-dependent processes as follows: let θ ∈
D ⊂Rr, with D being a measurable set of feasible parameters, and let (Xn(θ)), with
n ≥0, θ ∈D, be a measurable stochastic process deﬁned over Z × D. Then in the
deﬁnitions above we take
Mq(X) =
sup
n≥0,θ∈D
E1/q∥Xn∥q,
γq(τ) =
sup
n≥τ,θ∈D
E1/q∥Xn −E(Xn|F+
n−τ)∥q,
and we say that (Xn(θ)) is L-mixing with respect to (Fn, F+
n ), uniformly in θ.
The relevance of L-mixing in the context of Markov-processes has been established
in [9] and [10]. For this a convenient visualization of a Markov process is used, namely
the dynamics of the process is described by
Xi = f(Xi−1, Ui),
where (Ui) is a sequence of i.i.d. random variables over some probability space with
values in a measurable space U, which is independent also of X0, and f is a measurable
mapping. The existence of such a representation is well-known, see Kifer [11].
In particular we can assume that Ui is distributed uniformly over [0, 1]. With this
representation at hand let
Fi = σ{X0, Us : 0 ≤s ≤i},
and
F+
i = σ{Us : s ≥i + 1}.
L-mixing in the rest of the paper will always mean L-mixing with respect to (Fn, F+
n )
given above.
4
Asymptotic Properties of the Log-Likelihood Function
In this section we summarize some recent results on the asymptotic properties of the
log-likelihood function. First we consider the case when Q is positive, i.e. Q > 0,
irrespective of whether Q∗itself is positive. The essential ingredients of the following
result of [9] have been given already in [10].
Proposition 4.1. Consider a hidden Markov process (Xn, Yn) as speciﬁed in
Deﬁnition 2.1, and consider the Baum-equation (2). Assume that the transition prob-
ability matrix Q∗is primitive, and that the assumed transition probability matrix Q is

140
L. Gerencs´er and G. Moln´ar-S´aska
positive, Q > 0. Furthermore, suppose that the assumed read-out probabilities are all
positive: for all x ∈X and λ almost all y ∈Y we have
bx(y) > 0.
(11)
Furthermore assume that for all q ≥1 and for all i, j ∈X

| log bj(y)|q b∗i(y)λ(dy) < ∞.
(12)
Let q ∈P be any initial distribution, and let pn = pn(θ, q) denote the solution of the
Baum-equation (2) with yn = Yn. Then the process
g(Yn, pn) = log p(Yn|Yn−1, . . . Y0; θ, q)
is L-mixing. Furthermore, the limit
lim
n→∞Eg(Yn, pn) = W(θ)
exists, and is independent of the initial value q.
Note that condition (12) is satisﬁed for Gaussian read-outs with state-dependent
covariance.
Corollary 4.1. Under the conditions of Theorem 4.1 we have
1
n log p(Y0, . . . Yn; θ, q) −W(θ) = OM(n−1/2).
(13)
The corollary is obtained by a direct application of Theorem 1.1. of [4]. From here we
get by a Borel-Cantelli argument that
lim
n→∞
1
n log p(Y0, . . . Yn; θ, q) = W(θ)
a.s.
(14)
A key step in establishing Theorem 4.1 is the veriﬁcation of the exponential stability
of the Baum equation with respect to its initial condition q. This has been proven by
LeGland and Mevel, [13] for continuous read-outs. A similar result for hidden Markov
processes with binary read-outs were given by Araposthatis and Marcus, [1]. We for-
mulate an improved version of this result for the case of positive Q-s, which is obtained
by a slight modiﬁcation of the methods of [13], using simple inequalities for projective
products in a different way:
Proposition 4.2. Consider a hidden Markov process (Xn, Yn) satisfying the conditions
of Theorem 4.1, except (12). Then there exists a constant δ with 0 < δ < 1 depending
only on Q, and for any ϵ > 0 there exists a constant C > 0 depending only on Q and
ϵ, such that for any q, q′ ∈P(ϵ), for all n ≥0, and for any sequence of observations
(y0, . . . , yn−1) we have
∥pn(q) −pn(q′)∥T V ≤C(1 −δ)n∥q −q′∥T V ,
(15)
where ∥· ∥T V denotes the total variation norm.

Identiﬁcation of Hidden Markov Models - Uniform LLN-s
141
A key point of the above result is that it is completely independent of the underlying
probabilistic structure, it is in fact a result of linear algebra, moreover δ and C do not
depend on the readout densities.
An extension: an important corollary is that Proposition 4.1 remains true if the pos-
itivity condition on the read-outs, (11), is removed, and q, q′ > 0. This extension is
obtained by a simple limiting argument. Thus important examples, such as read-outs
obtained by quantization are also covered.
5
The Case of Primitive Q-s
In extending the results of the previous section to primitive Q-s the ﬁrst step is to extend
Proposition 4.2 to the case when the assumed value Q is primitive. First we restate
Theorem 2.1 of [13]. Let bx(y) denote the read-out density and let Q(x, x′) denote the
transition probability matrix used in the Baum-equation (2), and let
δ(y) =
max
x
bx(y)
min
x bx(y)
(16)
and
ϵ = min
x,x′
+Q(x, x′),
(17)
where min+ denotes the minimum taken over positive elements only.
Proposition 5.1. Consider a hidden Markov process (Xn, Yn) as speciﬁed in Deﬁni-
tion 2.1, and consider the Baum-equation (2). Assume that the transition probability
matrices Q∗, Q are primitive. Furthermore, assume that the assumed read-out proba-
bilities are all positive, see (11). Let q, q′ ∈P be any two initializations. Then for any
sequence of observations (y0, . . . , yn−1) ∈Yn with n ≥r we have
∥pn(q) −pn(q′)∥T V ≤ϵ−rδ(y0) . . . δ(yr−1)
·
⌊n/r⌋

k=1
(1 −ϵrδ−1(ykr−r+1) . . . δ−1(ykr−1))∥q −q′∥T V ,
where ∥· ∥T V denotes the total variation norm.
In [8] we have proven the following signiﬁcant addition to the above result:
Proposition 5.2. Consider a hidden Markov process (Xn, Yn) such that it satisﬁes the
conditions of Proposition 5.1. In addition assume that for all q ≥1

|δ(y)|qb∗i(y)λ(dy) < ∞.
(18)
Then for any s ≥1 there exist constants 0 < δ < 1, and a random variable C(ω) > 0,
with
ECs(ω) < ∞,
(19)
so that for any two initial distributions q, q′ we have
∥pn(q) −pn(q′)∥T V ≤C(ω)(1 −δ)n∥q −q′∥T V .
(20)

142
L. Gerencs´er and G. Moln´ar-S´aska
If bx(y) is bounded, then condition (18) can be formulated in the following equivalent
form: for any i, j and any q ≥1 we have with
δj(y) = 1/(bj(y))
(21)
the inequality

|δj(y)|qb∗i(y)λ(dy) < ∞.
(22)
Consider now again a parametric family of transition and read-out probabilities Q =
Q(θ) and bx(y) = bx(y; θ), respectively, with θ ∈D.
Condition 5.1. We assume that Q(θ) is primitive for all θ ∈D. Furthermore, for any
x ∈X and θ ∈D we have
bx(y; θ) > 0
for λ-almost all y ∈Y.
Condition 5.2. Assume that the transition probability matrices Q(θ) are continuous in
θ for θ ∈D. Similarly, assume that that for all ﬁxed x ∈X the read-out probability
bx(y; θ) is measurable in (y, θ), and it is continuous in θ for θ ∈D for λ-almost all y.
In addition, for any x ∈X and for any compact set D0 ⊂D, and θ ∈D0 the densities
bx(y; θ) are uniformly bounded in y. More precisely: there exists a ﬁnite K such that
for any x ∈X, and θ ∈D0 we have
|bx(y; θ)| ≤K
for λ-almost all y ∈Y.
A minor modiﬁcation of the proof given in [8] yields the following uniform version of
the Proposition 5.2:
Theorem 5.1. Consider
a
hidden
Markov
process
(Xn, Yn)
as
speciﬁed
in
Deﬁnition 2.1, and consider the Baum-equation (2) with yn = Yn. Assume that the
transition probability matrix Q∗is primitive. Consider a parametric family of tran-
sition and read-out probabilities Q = Q(θ) and bx(y) = bx(y; θ), respectively, with
θ ∈D satisfying Conditions 5.1 and 5.2. Finally, assume that for any compact set
D0 ⊂D, any i, j, and any q ≥1 we have with
δ
j(y) = 1/( min
θ∈D0 bj(y; θ))
(23)
the inequality

|δ
j(y)|qb∗i(y)λ(dy) < ∞.
(24)
Then (20) holds with a constant 0 < δ < 1 that is independent of θ, and a random
variable C(ω; θ) > 0 such that
sup
θ∈D0
ECs(ω; θ) < ∞.
(25)

Identiﬁcation of Hidden Markov Models - Uniform LLN-s
143
For the proof we need two remarks. For the ﬁrst remark, we quote the following result
of [8], given as Theorem V.3: Let (ξk) be a sequence of i.i.d random variables such that
ξk ≤0, and P(ξk < 0) > 0. Then for any s > 1 there exist an α > 0 such that with
σ∗= sup
n
n

k=1
(ξk + α)
(26)
we have E(esσ∗) < ∞. See also see e.g. [17,20]. Now it is easy to see that if a family
of random variables (ξk(θ)) is such that (ξk(θ)) ≤s ξ∗for all θ, where the symbol ≤s
denotes stochastically less than or equal, and ξ∗satisﬁes the conditions of the theorem,
then there is a single, common α > 0 with which the theorem is true.
The second remark is that if a family of transition probabilities P(x, A; θ) is such
that they satisfy a minorization condition uniformly in θ in the sense that there exists a
probability measure ν on X, a δ > 0 such that
P(x, A; θ) ≥δν(A)
is valid for all x ∈X, A ∈B(X) and all θ, then P(x, A; θ) can be realized on a single
probability space as a mixture of a single i.i.d. sequence and some Markov processes.
More precisely:
Xn(θ) = δnξn + (1 −δn)X′
n(θ),
with (δn) being an i.i.d Bernoulli sequence taking the value 1 with probability δ, and
(ξn) being an i.i.d. sequence with distribution ν.
A major application of the above result is given in the following extension of
Proposition 4.1.
Theorem 5.2. Consider a hidden Markov process (Xn, Yn) satisfying the conditions of
Theorem 5.1. Let q ∈P be any initial distribution and let pn = pn(θ, q) denote the
solution of the Baum-equation (2) with yn = Yn. Then the process
g(Yn, pn; θ) = log p(Yn|Yn−1, . . . Y0; θ, q)
is L-mixing uniformly in θ for θ ∈D0. Furthermore, the limit
lim
n→∞Eg(Yn, pn; θ) = W(θ)
exists, uniformly in θ for θ ∈D0, and is independent q.
Discussion. Condition (18) is used with q = 1 in Theorem of [13]. This condition is
quite restrictive, though, even in the case of q = 1, in particular it is not satisﬁed for
Gaussian read-outs. However, the validity of the condition can be enforced at the price
of a small loss in information. A simple way of doing this is to replace our observations
Yn ∈Rm by Y ′
n = g(Yn) where
g(y) = y
|y| h(|y|),
h(r) = min ( r
R, 1),
r ≥0,
where R is a large positive number. Then g maps the open ball of radius R, denoted
by SR into S1, and it is a continuously differentiable homeomorphism there, while it

144
L. Gerencs´er and G. Moln´ar-S´aska
maps Rm\SR, onto the boundary of S1, say C1. Deﬁning λ inside S1 as the Lebesgue-
measure in Rm, and on C1 as the (m −1) dimensional Lebesgue-measure on C1, it is
easy to see that condition (18) will be satisﬁed.
A ﬁnal remark: note that condition (18) with q = 1 implies condition (12) with any
q, under the assumed boundedness condition on bx(y; θ).
6
The Derivative of the Predictive Filter
In order to derive uniform laws of large numbers we need to analyze the derivatives of
the likelihood function. Our attention will be restricted to the analysis of ﬁrst deriva-
tives, but results for higher order derivatives will also be stated. For the sake of sim-
plicity assume that D is open. We need to strengthen Condition 5.2 so that continuity
is replaced by ﬁrst order smoothness:
Condition 6.1. Assume that the transition probability matrices Q(θ) are continuously
differentiable in θ for θ ∈D. Similarly, assume that for all ﬁxed x ∈X the read-
out probability bx(y; θ) is measurable in (y, θ), and continuously differentiable in θ for
θ ∈D for λ-almost all y. In addition, for any x ∈X and for any compact set D0 ⊂D,
and θ ∈D0 the densities bx(y; θ) are uniformly bounded in y, together with their ﬁrst
derivatives (see Condition 5.2).
Taking into account the recursion given by the Baum-equation it is easy to see that
p(yn|yn−1, . . . , y0; θ, q) is continuously differentiable in θ for θ ∈D. Differentiating
log p(yn|yn−1, . . . , y0; θ, q) = log bT (yn, θ)pn,
with respect to θ we get with
Wn = Wn(θ, q) = ∂pT
n(θ, q)
∂θ
and
β(yn) = β(yn; θ) = ∂bT (yn; θ)
∂θ
the expression
∂
∂θ log p(yn|yn−1, . . . , y0, ; θ, q) = β(yn)pn + Wnb(yn)
b(yn)T pn
.
(27)
Introducing the function of three variables
g(y, p, W) = β(y)p + Wb(y)
bT (y)p
(28)
we can write the gradient of the log-likelihood function with pk = pk(θ, q) and Wk =
Wk(θ, q) as
∂
∂θ log p(y0, . . . , yn; θ, q) =
n

k=1
g(yk, pk, Wk ; θ).
(29)
Note that since p0 = p0(θ, q) does not depend on θ, the summation starts with k = 1.

Identiﬁcation of Hidden Markov Models - Uniform LLN-s
145
In order to prove a strong law of large numbers for the gradient we follow the general
theory given in [10] and [9]. Thus the ﬁrst step is to prove exponential stability of
the gradient process with respect to initial perturbations. Let θ be ﬁxed, and write
pn(q) = pn(θ, q). Obviously, pn(q) is a continuously differentiable function of q.
Thus from Proposition 4.2 we get by elementary arguments the following result:
Theorem 6.1. Under the condition of Proposition 4.2 there exists a constant δ with
0 < δ < 1 depending only on Q, and for any ϵ > 0 there exists a constant C > 0,
depending only on Q and ϵ, such that for any q ∈P(ϵ), for all n ≥0, and for any
sequence of observations (y0, . . . , yn−1) we have
∥∂
∂qpn(q)∥op ≤C(1 −δ)n
with ∥.∥op denoting the operator norm.
This theorem can be reinterpreted if we consider the dynamics of
Vn = Vn(q) = ∂
∂qpn(q).
Differentiating the Baum-equation (4) with respect to q it is easy to see that Vn satisﬁes,
with pn = pn(q), the matrix-equation
Vn+1 = ∂
∂pf(yn, pn)Vn,
(30)
with initial condition V0 = I. Setting
An = ∂
∂pf(yn, pn)
and taking into account that Q > 0 implies that pn(q) ∈P(ϵ) for all n ≥1 for
some ϵ > 0, and the resulting shift-invariance of Proposition 4.2 we get the following
corollary:
Theorem 6.2. Under the condition of Proposition 4.2 we have for any 0 ≤m ≤n
||An...Am|| ≤C(1 −δ)(n−m).
Let us now return to the parametric case. To avoid the complexity of tensor calcula-
tions, let us now assume that θ(t) ∈D, 0 ≤t < t0 with θ = θ(0) is a continuously
differentiable curve with tangent η at t = 0. Then bx(y; θ(t)) and Q(θ(t)) are continu-
ously differentiable functions of t, and thus pn(θ(t); q) is a continuously differentiable
function of (t, q). Set
wn = wn(θ, q) = ∂
∂tpn(θ(t), q)|t=0.
The dynamics of (wn) is obtained by differentiating the Baum-equation (4) with respect
to t, to get, with pn = pn(θ, q),

146
L. Gerencs´er and G. Moln´ar-S´aska
wn+1 = ∂
∂pf(yn, pn; θ)wn + ∂
∂θf(yn, pn; θ)η,
(31)
with initial condition w0 = 0. We need to strengthen Condition 6.1 so that ﬁrst order
smoothness is replaced by second order smoothness:
Condition 6.2. Assume that the transition probability matrices Q(θ) are twice contin-
uously differentiable in θ for θ ∈D. Similarly, assume that that for all ﬁxed x ∈X
the read-out probability bx(y; θ) is measurable in (y, θ), and twice continuously differ-
entiable in θ for θ ∈D, for λ-almost all y. In addition, for any x ∈X and for any
compact set D0 ⊂D, and θ ∈D0 the densities bx(y; θ) are uniformly bounded in y,
together with their ﬁrst and second derivatives, (see Condition 5.2).
Differentiating with respect to q, solving it for
∂
∂qwn(q), and taking into account The-
orems 6.1 and 6.2 we get the following result:
Theorem 6.3. Assume that the conditions of Proposition 4.2, and Condition 6.2 are
satisﬁed. Then there exists a constant δ with 0 < δ < 1 depending only on Q, and for
any ϵ > 0 there exists a constant C > 0, depending only on Q and ϵ, such that for any
q ∈P(ϵ), and for all n ≥0 we have
∥∂
∂qwn(q)∥op ≤C(1 −δ)n.
Corollary 6.1. Assume that the conditions of Proposition 4.2, and Condition 6.2 are
satisﬁed. Then with the notations of Theorem 6.3 we have for any q, q′ ∈P(ϵ), and for
all n ≥0
∥wn(q) −wn(q′)∥T V ≤C(1 −δ)n∥q −q′∥T V .
(32)
In short, the derivative process forgets its initial condition exponentially fast.
To ensure the exponential stability of the joint dynamics of (pn(q), wn(q)) we have to
allow the initial condition of wn(q), as deﬁned by in (31), vary, say write w0 = u with
1T u = 0, and get a process wn(q, u). It is easily seen that the above two results extend
to partial derivatives and ﬁnite variations with respect to u.
An extension: the above corollary remains true if the positivity condition on the read-
outs, (11), is removed. This extension is obtained by a simple limiting argument, just as
in the remark following Proposition 4.2. Thus, we reiterate, that important examples,
such as read-outs obtained by quantization are also covered.
Note that the above argument is signiﬁcantly simpler than the one given in [13]. True,
their result is given for the general case, when Q is primitive. Can we extend the above
argument to the general case? The answer is yes: the key point in such an extension is
to control the constants in the inequalities stating exponential stability, written as
∥pn(q) −pn(q′)∥T V ≤C(ω)(1 −δ)n∥q −q′∥T V .
This is exactly the content of Theorem 5.2. It is easy to see that the results of this section
can be extended to the general case. In the extension of Theorem 6.2 the constant C′ on
the right hand side will be replaced by a strictly stationary sequence C′
m(ω) satisfying
what is stated in Proposition 5.2, i.e. (19). Altogether ﬁnally we get the following
result:

Identiﬁcation of Hidden Markov Models - Uniform LLN-s
147
Theorem 6.4. Consider a hidden Markov process (Xn, Yn) satisfying the conditions of
Theorem 5.1 and Condition 6.2. Then for any s ≥1 there exist a constant 0 < δ < 1,
and a random variable C(ω, θ) > 0, satisfying
sup
θ∈D0
ECs(ω; θ) < ∞,
(33)
such that for any two initial distributions q, q′ ∈P, and for all n ≥0 we have
∥wn(θ, q) −wn(θ, q′)∥T V ≤C(ω; θ)(1 −δ)n∥q −q′∥T V .
(34)
A non-trivial result, that follows directly from the arguments given in [9] is that the
above exponential stability implies the existence of a unique stationary distribution for
the process (Xn, Yn, pn, Wn).
7
Uniform Laws of Large Numbers
In view of Theorem 6.4 we can now extend Proposition 4.1 to the gradient process. To
prove that the process g(Yn, pn, Wn) is L-mixing, with g given as
g(y, p, W) = β(y)p + Wb(y)
bT (y)p
,
see (28), we follow the proof given in [9]. To ensure an appropriate integrability condi-
tion on g we impose a lower bound for the denominator. Noting that
bT(y)p ≥min
x bx(y)
it is not surprising that condition (22) will play a role in the theorem below, even for the
case of positive Q-s.
Theorem 7.1. Consider
a
hidden
Markov
process
(Xn, Yn)
as
speciﬁed
in
Deﬁnition 2.1, such that Q∗is primitive. Consider the associated Baum equation (2)
with yn = Yn. Assume that the conditions of Theorem 6.4 are satisﬁed. Let q ∈P be
any initial distribution. Then
g(Yn, pn, Wn) = ∂
∂θ log p(Yn|Yn−1, . . . Y0; θ, q)
is L-mixing, uniformly in θ for θ ∈D0, where D0 ⊂D is an arbitrary compact domain.
Moreover the limit
lim
n→∞E ∂
∂θ log p(Yn|Yn−1, . . . Y0; θ, q)
exists w.p.1, and is equal to
∂
∂θW(θ).
Conditions (18) or (22) with q = 2 are equivalent to condition used in Theorem 4.6
of [13] to establish exponential stability of the gradient process with respect to initial
conditions. See also Example 3.3 and 4.4 in [13]. Mevel and Finesso use essentially
(18) with ”sufﬁciently large q”, see Assumption C on page 1124 in [15].

148
L. Gerencs´er and G. Moln´ar-S´aska
The above theorem remains true if D is not necessarily an open set, but (31) makes
sense, and Wn is replaced by a directional derivative wn, see the discussion preceding
(31). To derive a uniform law of large numbers we follow [4]. In particular we need to
extend Theorem 3.4 of [4]. For this we need the following condition:
Condition 7.1. Let D0 ⊂D be a restricted compact set of feasible parameters, such
that there exist a h0 > 0, and a compact set D1 ⊂D such that for any θ, θ′ ∈D0 with
|θ −θ′| ≤h ≤h0 there exist a smooth arc θt ∈D1, 0 ≤t ≤1, connecting θ and θ′
such that its length is at most ch, with some constant c.
Deﬁne the process (∆(n, θ, θ′)) for θ ̸= θ′ ∈D:
∆(n, θ, θ′) = (log p(Yn|pn−1, . . . p0; θ′, q) −log p(Yn|pn−1, . . . p0; θ, q))/|θ′ −θ|.
Theorem 7.1 and Condition 7.1 imply that ∆(n, θ, θ′) is L-mixing. Thus, after sum-
mation and by the application of Theorem 1.1 of [4] we arrive at the following result:
Corollary 7.1. Assume that the conditions of Theorem 7.1 and Condition 7.1 are satis-
ﬁed. Then we have that
1
n(log p(Y0, . . . Yn; θ, q) −log p(Y0, . . . Yn; θ′, q)) −
1
|θ′ −θ|(W(θ) −W(θ′))
is of the order OM(n−1/2) uniformly for θ ̸= θ′ ∈D0 with |θ −θ′| ≤h ≤h0.
To derive a uniform law of large numbers we need the following condition:
Condition 7.2. The restricted set of feasible parameters D0 is such that there exists a
0 < h1 ≤h0 such that for all θ ∈D0 we have
µS(θ, h1) ∩D1 > 0,
where S(θ, h1) denotes the sphere with center at θ and radius h1.
The heuristic content of this condition is that we exclude cusps and hyper-surfaces from
our set of parameters D0. It is easily seen that under Condition 7.2 the arguments of
Section 3 [4] carry over, and thus we get the following main result:
Theorem 7.2. Assume that the conditions of Theorem 7.1 are satisﬁed, and in addition
assume the validity of Conditions 7.1 and 7.2. Then we have
sup
θ∈D0
| 1
n log p(Y0, . . . Yn; θ, q) −W(θ)| = OM(n−1/2).
(35)
We note in passing that in this theorem D is not necessarily open, and then
Condition 6.1 and 6.2 have to be reformulated in terms of directional derivatives.
In order to extend the techniques if [5] to HMM-s we need a uniform law of large
numbers even for the second order derivatives of the log-likelihood function. For this
Condition 6.2 will have to be strengthened to requiring that Q(θ) and bx(y; θ) are four-
times continuously differentiable in θ, and that the densities bx(y; θ) are uniformly
bounded in y, together with their ﬁrst four derivatives. In our setup the same inte-
grability condition (24) is required for all higher order derivatives. (This is in contrast
with [13] or [15], where the exponents q for which integrability is required depends on
the order of the derivatives).

Identiﬁcation of Hidden Markov Models - Uniform LLN-s
149
8
Estimation of Hidden Markov Models
As pointed out in [5] uniform laws of large number with rate of convergence for the
moments play a key role in deriving strong approximation theorems for off-line esti-
mators ARMA-processes. The purpose of the present paper was to develop the tools
that are needed for the extension of these results from ARMA to HMM. The usefulness
of strong approximation theorems for HMM-s in adaptive encoding has been demon-
strated in [6].
A major difference between the two model classes is that for ARMA-processes stan-
dard parametrizations are available, and the set of feasible parameters is typically an
open set (assuming no zeros on the unit circle). A similar assumption for general
HMM-s is much too restrictive. However, the tools for handling these cases as well
have been developed. Applications will be described in a subsequent paper.
An important issue that has not been discussed here is parametrization of HMM-s.
In the extreme case when the readouts are known, a natural parametrization of Q would
be to take any N −1 entries of each row as coordinates of the parameter vector. In
this case the parameter-set is a closed, convex, bounded polyhedron. If it is known a
priori that Q∗> 0, then the parameter-set is an open, convex, bounded polyhedron.
An intermediate case is when some elements Q∗> 0 are known to be positive or zero.
Obviously this is a very simplistic parametrization.
A more conceptual approach is to relate parametrization issues with realization the-
ory of HMM-s, in which fundamental contributions are due to Picci and Van Schuppen,
see [18], [19]. A more recent signiﬁcant advance is due to Vidyasagar, see [21]. In
spite of all these basic contributions the parametrization problem of HMM-s is far from
being completely settled, and we look forward to further progress.
Acknowledgment
This research was supported by the National Research Foundation of Hungary, OTKA,
under grant no. T 047193.
References
1. A. Arapostathis and S.I. Marcus. Analysis of an Identiﬁcation Algorithm Arising in the
Adaptive Estimation of Markov Chains. Math. Control Signals Systems, 3:1–29., 1990.
2. L.E. Baum and T. Petrie.
Statistical inference for probabilistic functions of ﬁnite state
Markov chains. Ann. Math. Stat., 37:1559–1563, 1966.
3. T. E. Duncan. Probability densities for diffusion processes with applications to nonlinear
ﬁltering theory. Technical report, PhD thesis, Standford, 1967.
4. L. Gerencs´er. On a class of Mixing Processes. Stochastics, 26:165–191, 1989.
5. L. Gerencs´er. On the martingale approximation of the estimation error of ARMA parameters.
Systems & Control Letters, 15:417–423, 1990.
6. L. Gerencs´er and G. Moln´ar-S´aska. Adaptive encoding and prediction of Hidden Markov
processes. In Proceedings of the European Control Conference, ECC 2003, Cambridge.
7. L. Gerencs´er, G. Moln´ar-S´aska, and Gy. Michaletzky. Improved estimation of the exponen-
tial stability of the predictive ﬁlter in Hidden Markov models. In Proceedings of the 2006
American Control Conference, Minneapolis, pages 5177–5182, 2006.

150
L. Gerencs´er and G. Moln´ar-S´aska
8. L. Gerencs´er, G. Moln´ar-S´aska, and Gy. Michaletzky. An improved bound for the exponen-
tial stability of predictive ﬁlters of Hidden Markov models. Communications in Information
and Systems. Special Volume Dedicated to the 65th Birthday of Tyrone Duncan (guest eds.:
A. Bensoussan, S. Mitter and B. Pasik-Duncan), 7, 2007. Accepted for publication.
9. L. Gerencs´er, G. Moln´ar-S´aska, Gy. Michaletzky, and G. Tusn´ady. A new approach for the
statistical analysis of Hidden Markov Models. IEEE Transactions on Automatic Control,
under revision.
10. L. Gerencs´er, G. Moln´ar-S´aska, Gy. Michaletzky, and G. Tusn´ady. New methods for the
statistical analysis of Hidden Markov Models. In Proceedings of the 41th IEEE Conference
on Decision & Control, Las Vegas, pages WeP09–6 2272–2277, 2002.
11. Y. Kifer. Ergodic Theory of Random Transformation. Progress in Probability and Statistics,
10, 1986.
12. F. LeGland and L. Mevel. Basic Properties of the Projective Product with Application to
Products of Column-Allowable Nonnegative Matrices. Mathematics of Control, Signals and
Systems, 13:41–62, 2000.
13. F. LeGland and L. Mevel.
Exponential Forgetting and Geometric Ergodicity in Hidden
Markov Models. Mathematics of Control, Signals and Systems, 13:63–93, 2000.
14. B.G. Leroux. Maximum-likelihood estimation for Hidden Markov-models. Stochastic Pro-
cesses and their Applications, 40:127–143, 1992.
15. L. Mevel and L. Finesso. Asymptotical statistics of misspeciﬁed hidden Markov models.
IEEE Transactions on Automatic Control, 49:1123 – 1132, 2004.
16. R. E. Mortensen. Optimal control of continuous time stochastic systems. Technical report,
PhD thesis, University of California, Berkeley, CA, USA, 1966.
17. H.H. Panjer and G.E. Willmot. Insurance Risk Models. Society of Actuaries, 1992.
18. G. Picci. On the internal structure of ﬁnite state stochastic processes, recent developments
in variable structure systems, Economics and Biology. In Lecture notes in Economics and
Mathematical Systems (editors R.R. Mohler and Ruberti), pages 288–304. Springer-Verlag,
1978.
19. G. Picci and J. H. van Schuppen. On the weak ﬁnite stochastic realization problem. In
Lecture Notes in Control and Information Sciences, pages 237–242. Springer, New York,
1984.
20. E. Sparre Andersen. On the collective theory of risk in the case of contagation between the
claims. In Transactions of the XV-th International Congress of Actuaries, pages 219–229,
1957.
21. M. Vidyasagar. The realization problem for Hidden Markov Models: The complete realiza-
tion problem. In Proceedings of the 44th IEEE Conference on Decision and Control, pages
6632–6637, 2005.
22. M. Zakai. On the optimal ﬁltering of diffusion processes. Zeitschrift f¨ur Wahrscheinlichkeit-
stheorie und verwandte Gebiete, 11:230–243, 1969.

Identiﬁability and Informative Experiments in Open
and Closed-Loop Identiﬁcation⋆
Michel Gevers1, Alexandre Sanfelice Bazanella1,2, and Ljubiˇsa Miˇskovi´c1
1 CESAME, Universit´e Catholique de Louvain, Louvain-la-Neuve, Belgium
{bazanela,gevers,miskovic}@csam.ucl.ac.be
2 On leave from Electrical Engineering Department, Universidade Federal do Rio Grande do
Sul, Porto Alegre-RS, Brazil
bazanela@ece.ufrgs.br
To Giorgio, who to our great surprise has not solved the rather fundamental
problems raised in this chapter, we hope to offer some food for thought.
1
Introduction
This chapter takes a new look at the concept of identiﬁability and of informative ex-
periments for linear time-invariant systems, both in open-loop and in closed-loop iden-
tiﬁcation. Some readers might think that everything has been said and written about
these concepts, which were much studied all through the 1970’s. We shared the same
view . . . until recently. The motivation for our renewed interest into these very funda-
mental questions is the recent surge of interest in the question of experiment design,
itself triggered by the new concept of least costly identiﬁcation experiment for robust
control [3, 4, 5, 6]. Brieﬂy speaking, least costly experiment design for robust control
refers to achieving a prescribed accuracy at the lowest possible price, which is typically
measured in terms of the duration of the identiﬁcation experiment, the perturbation in-
duced by the excitation signal, or any combination of these. In this context, questions
like the following become relevant:
1. what is the smallest amount of external excitation that is required to achieve iden-
tiﬁability (or to achieve a given accuracy level)?
2. assuming that the system operates in closed-loop, is noise excitation sufﬁcient to
guarantee identiﬁability?
3. if noise excitation is not sufﬁcient to guarantee identiﬁability in a closed-loop ex-
periment, then how much additional reference excitation is required?
4. assuming that excitation can be applied at different entry points of a multi-input
system operating in closed loop, is it necessary to excite each input to achieve
identiﬁability (or to achieve a given accuracy level)?
Sufﬁcient conditions for identiﬁability using noise excitation only (question 2) have
been given, under different sets of assumptions, in [4, 11, 12]. The key condition for
⋆This chapter presents research results of the Belgian Programme on Interuniversity Attrac-
tion Poles, initiated by the Belgian Federal Science Policy Ofﬁce. The second author is also
partially supported by the Brazilian Ministry of Education through CAPES.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 151–170, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

152
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
identiﬁability using noise excitation only is in terms of the complexity of the feedback
controller; this complexity condition relates the controllability (or observability) indices
of the controller to the controllability (or observability) indices of the plant. Question 4
has been addressed in [2] where it is shown that, when identiﬁability cannot be achieved
using noise excitation only, this does not imply that all reference inputs must be excited.
In attempting to address questions 1 and 3 above, we discovered to our surprise that
these questions do not seem to have been addressed (or at least solved) before. As is
well-known, besides the choice of an identiﬁable model structure, the key ingredient
to achieve identiﬁability is the informativity of the experiment. In open-loop identiﬁ-
cation, and in all closed-loop identiﬁcation experiments where the noise excitation by
itself does not make the experiment informative, the informativity is achieved by apply-
ing a sufﬁciently rich input signal. The degree of richness of a signal is a concept that is
precisely deﬁned; a signal is said to be sufﬁciently rich of degree n if its spectral density
is nonzero in at least n distinct frequency points in the interval (−π, π]. But whereas
the scientiﬁc literature abunds with sufﬁcient conditions on input signal richness, there
appear to be no result on the smallest possible degree of richness that delivers informa-
tive data in a given identiﬁcation setup. In other words, necessary conditions on input
richness that will guarantee an informative experiment are strangely lacking.
The purpose of this contribution is to attempt to ﬁnd the smallest possible degree of
richness of the excitation signal that makes an experiment informative with respect to
a chosen model structure, both in open-loop and in closed-loop identiﬁcation. More
precisely, we address the following two questions:
•
assuming open-loop identiﬁcation, what is the smallest degree of input signal rich-
ness that is necessary to achieve an informative experiment with respect to a chosen
model structure?
•
assuming closed-loop identiﬁcation with a controller that is not sufﬁciently complex
to yield identiﬁability using noise excitation only, what is then the smallest degree
of reference signal excitation that is necessary to achieve an informative experiment
with respect to a chosen model structure?
In addressing these questions, we shall introduce a new framework that allows one
to handle in the same way the range space spanned by stationary stochastic vectors and
that spanned by vectors of rational transfer functions. We believe this new framework to
be a convenient tool to establish results on the transfer of excitation from input signals
to regression vectors through linear time-invariant ﬁlters. Our analysis and results will
be established for single-input single-output (SISO) systems, but the framework we
develop lends itself easily to extensions to multi-input multi-output (MIMO) systems.
The chapter is organized as follows. In Section 2 we set up the notations and the
key tools of the prediction error identiﬁcation framework. In Section 3, we recall the
basic concepts of identiﬁability and informative experiments. The body of our results
are in Section 4 which focuses on the key role of the information matrix. Our main
results concern the derivation of necessary and sufﬁcient conditions on the input signal
that make a regressor persistently exciting. This allows us to formulate necessary and
sufﬁcient conditions on input signal richness that makes the information matrix have
full rank. Finally, in Section 5 we apply these results to some widely utilized model
structures.

Identiﬁability and Informative Experiments
153
2
The Prediction Error Identiﬁcation Setup
Consider the identiﬁcation of a linear time-invariant discrete-time single-input-single-
output process
S : y(t) = G0(z)u(t) + H0(z)e(t)
(1)
In (1) z is the forward-shift operator, G0(z) and H0(z) are the process transfer func-
tions, u(t) is the control input and e(t) is white noise with variance σ2
e. Both transfer
functions, G0(z) and H0(z), are rational and causal (proper); furthermore, H0(∞) = 1,
that is the impulse response h(t) of the ﬁlter H0(z) satisﬁes h(0) = 1.
This true system may be under feedback control with a causal rational stabilizing
controller K(z):
u(t) = K(z)[r(t) −y(t)].
(2)
The system (1) is identiﬁed using a model structure parametrized by a vector θ ∈Rd:
M(θ) : y(t) = G(z, θ)u(t) + H(z, θ)ε(t)
(3)
The set of models M(θ), for all θ in some set Dθ ∈Rd, deﬁnes the model set M:
M ≜{M(θ) | θ ∈Dθ}. The true system is said to belong to this model set, S ∈M,
if there is a θ0 such that M(θ0) = S. In a prediction error identiﬁcation framework,
a model [G(z, θ) H(z, θ)] uniquely deﬁnes the one-step-ahead predictor of y(t) given
all input/output data up to time t:
ˆy(t|t −1, θ) = Wu(z, θ)u(t) + Wy(z, θ)y(t),
(4)
where Wu(z, θ) and Wy(z, θ) are stable ﬁlters obtained from the model
[G(z, θ) H(z, θ)]
as follows:
Wu(z, θ) = H−1(z, θ)G(z, θ), Wy(z, θ) =[I −H−1(z, θ)].
(5)
Since there is a 1 −1 correspondance between [G(z, θ), H(z, θ)] and [Wu(z, θ),
Wy(z, θ)], the model M(θ) will in the future refer indistinctly to either one of these
equivalent descriptions. For later use, we introduce the following vector notations:
W(z, θ) ≜[Wu(z, θ) Wy(z, θ)],
z(t) ≜
'
u(t)
y(t)
(
(6)
We shall also consider throughout this chapter that the vector process z(t) is quasista-
tionary [9], so that the spectral densitiy matrix Φz(ω) is well deﬁned.
The one-step-ahead prediction error is deﬁned as:
ε(t, θ) ≜y(t) −ˆy(t|t −1, θ)
(7)
= W(z, θ)z(t) = H−1(z, θ) [y(t) −G(z, θ)u(t)]
Using a set of input-output data of length N and a least squares prediction error criterion
yields the estimate ˆθN [9]:

154
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
ˆθN = arg min
θ∈Dθ
1
N
N

t=1
ε2(t, θ).
(8)
Under reasonable conditions [9], ˆθN
N→∞
−→θ∗≜arg minθ∈Dθ V (θ), with
V (θ) ≜E[ε2(t, θ)].
(9)
If S ∈M and if ˆθN
N→∞
−→θ0, the parameter error converges to a Gaussian random
variable:
√
N(ˆθN −θ0)
N→∞
−→N(0, Pθ),
(10)
where
Pθ = [I(θ)]−1 |θ=θ0,
(11)
I(θ) = 1
σ2e
E
5
ψ(t, θ)ψ(t, θ)T 6
,
(12)
ψ(t, θ) = −∂ε(t, θ)
∂θ
= ∂ˆy(t|t −1, θ)
∂θ
= W(z, θ)z(t)
(13)
The matrix I(θ0) is called the information matrix, and will be much coveted in this
chapter.
3
Identiﬁability, Informative Data, and All That Jazz
Several concepts of identiﬁability have been proposed in the scientiﬁc literature, and
these deﬁnitions have evolved over the years.
They can be broadly classiﬁed into
consistency-oriented deﬁnitions, which focus on whether the parameter estimate ˆθN
converges to the ‘true’ parameter θ0 in some stochastic sense, and uniqueness-oriented
deﬁnitions, which deal with the question of whether the model structure is such that
the identiﬁcation criterion has a unique global minimum. Here we adopt a uniqueness-
oriented deﬁnition proposed in [9].
Deﬁnition 1 (Identiﬁability). A parametric model structure M(θ) is locally identiﬁ-
able at a value θ1 if ∃δ > 0 such that, for all θ in || θ −θ1 ||≤δ:
[Wu(z, θ) Wy(z, θ)] = [Wu(z, θ1) Wy(z, θ1)] ∀ω
⇐⇒
θ = θ1.
The model structure is globally identiﬁable at θ1 if the same holds for δ →∞. Finally,
a model structure is globally identiﬁable if it is globally identiﬁable at almost all θ1. ■
We now introduce the matrix Γ(θ) ∈Rd×d:
Γ(θ) ≜
 π
−π
∇θW(ejω, θ) ∇θW H(ejω, θ) dω
(14)
where ∇θW(ejω, θ) ≜∂W(ejω,θ)
∂θ
, and for any M(ejω), the notation M H(ejω) denotes
M T (e−jω). The following result is then an alternative deﬁnition for local identiﬁability
of a model structure; see problem 4G.4 in [9].

Identiﬁability and Informative Experiments
155
Proposition 1. A parametric model structure M(θ) is locally identiﬁable at θ1 if Γ(θ)
is nonsingular at θ1.
■
Most commonly used model structures (except ARX) are not globally identiﬁable, but
they are globally identiﬁable at all values θ that do not cause pole-zero cancellations:
see Chapter 4 in [9]. For the existence of a unique global minimum of V (θ), it is
required that the model structure is globally identiﬁable at θ0. We illustrate the loss of
rank of Γ(θ) at a pole-zero cancellation with the following example.
Example 1. Consider the OE (Output-Error) model structure: y(t) =
B(z−1)
F (z−1)u(t) +
e(t), where B(z−1) = b1z−1 + b2z−2 and F(z−1) = 1 + f1z−1 + f2z−2, with
θ = (b1 b2 f1 f2)T . Then
∇θW(ejω, θ) = 1
F 2
⎛
⎜
⎜
⎝
Fz−1
Fz−2
−Bz−1
−Bz−2
⎞
⎟
⎟
⎠= 1
F 2
⎛
⎜
⎜
⎝
1 f1
f2
0
0
1
f1
f2
0 −b1 −b2
0
0
0
−b1 −b2
⎞
⎟
⎟
⎠

 !
"
SBF
⎛
⎜
⎜
⎝
z−1
z−2
z−3
z−4
⎞
⎟
⎟
⎠
(15)
The matrix SBF is called a Sylvester matrix [7]: it is nonsingular if and only if the
polynomials B and F have no common factor. Thus, Γ(θ) is nonsingular at all values
θ except those that cause a pole-zero cancellation in B
F .
The deﬁnition of identiﬁability (local, or global) is a property of the parametrization of
the model [G(z, θ), H(z, θ)] or, equivalently, [Wu(z, θ), Wy(z, θ)]. It tells us that if
the model structure is globally identiﬁable at some θ1, then there is no other parameter
value θ ̸= θ1 that yields the exact same predictor as M(θ1). However, it does not tell us
that if the true system is in the model set for some parameter value θ0, then θ0 will be the
unique global minimum of the identiﬁcation criterion. This requires, additionally, that
the data set is informative enough to distinguish between different predictors, which
leads us to the deﬁnition of informative data with respect to a model structure.
Deﬁnition 2 (Informative data). [9] A quasistationary data set z(t) is called infor-
mative with respect to a parametric model set {M(θ), θ ∈Dθ} if, for any two models
W(z, θ1) and W(z, θ2) in that set,
E{[W(z, θ1) −W(z, θ2)]z(t)}2 = 0
(16)
implies
W(ejω, θ1) = W(ejω, θ2) ∀ω
(17)
■
By Parseval’s theorem, we can rewrite:
E{[W(z, θ1) −W(z, θ2)]z(t)}2 = 1
2π
 π
−π
|W(ejω, θ1) −W(ejω, θ2)|2Φz(ω)dω
(18)

156
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
It is easy to see that an experiment that yields Φz(ω) > 0 for almost all ω is informative
for all model structures, but such condition is of course unnecessarily strong.
The deﬁnition of informative data is with respect to a given model set, not with
respect to the true system, which may or may not belong to the model set. In an iden-
tiﬁcation experiment, one typically ﬁrst selects a globally identiﬁable model structure;
this is a user’s choice. Experimental conditions must then be selected that make the
data informative with respect to that structure; this is again a user’s choice. However,
the data are generated by the true system, in open or in closed loop. Thus, the condi-
tions that make a data set z(t) informative with respect to some model structure depend
on the true system and on the possible feedback conﬁguration. The information ma-
trix (12) combines, as we shall see, information about the identiﬁability of the model
structure and about the informativity of the experiments. In addition, as we have seen
in (11), its inverse characterizes the precision with which we can estimate the model
parameters from data. We thus rewrite the information matrix in a way that will make
the connections with model structure and data much more transparent.
Combining (12) and (13) yields:
I(θ) = 1
2π
 π
−π
∇θW(ejω, θ)Φz(ω)∇θW H(ejω, θ)dω
where Φz(ω) is the power spectrum of the data z(t) generated by an identiﬁcation
experiment. Comparing this expression with Γ(θ) in (14), we have the following result.
Proposition 2. Consider an identiﬁcation experiment that generates data with spectrum
Φz(ω) and assume that a model structure W(z, θ) is used. Then the information matrix
is nonsingular at θ1 if the following two conditions hold:
(i) the model structure is locally identiﬁable at θ1;
(ii) Φz(ω) > 0 for almost all ω.
■
We introduce the following deﬁnition.
Deﬁnition 3 (Regularity). We say that the information matrix I(θ) is regular at θ1 if
I(θ1) ≻0.
■
While the identiﬁability of the model structure at θ1 is a necessary condition for the
regularity of the information matrix, the positivity of the joint spectrum Φz(ω) > 0 at
almost all ω is again unnecessarily strong. A major contribution of this chapter will be
to describe the weakest possible richness conditions on the input signal u(t) (in open-
loop identiﬁcation) or r(t) (in closed-loop identiﬁcation) that make the information
matrix full rank for a given model structure. This turns out to be a remarkably difﬁcult
problem. We shall examine this problem in the situation where the system is in the
model set. Thus, we make the following assumption.
Assumption 1. The true system (1) belongs to the model set M, that is M(θ0) = S for
some θ0 ∈Dθ.
Under Assumption 1 we have the following classical result [9].

Identiﬁability and Informative Experiments
157
Proposition 3. Consider a model structure that obeys Assumption 1, let this model
structure be globally identiﬁable at θ0, and let the data be informative with respect
to this model structure. Then θ0 is the unique global minimum of V (θ) deﬁned by (9),
and in addition I(θ0) > 0.
■
4
Analysis of the Information Matrix
Convergence of an identiﬁcation algorithm to the exact θ0 when S ∈M rests on the
satisfaction of two different conditions:
•
the use of a model structure that is identiﬁable, at least at the global minimum θ0 of
the asymptotic criterion V (θ);
•
the application of experiments that are informative with respect to the model struc-
ture used.
These two conditions depend essentially on the used model structure. They depend on
the true system only via the generation of the data. Indeed, the data z(t) must be infor-
mative w.r.t. the model structure, but they are generated by the true system. As noted
in Proposition 2, the information matrix combines information on the model structure
and information on the data generated by the experiment. I(θ) can be regular only at
values of θ that are (at least) locally identiﬁable, i.e. where Γ(θ) > 0. At those values,
the regularity of the information matrix depends additionally on the informativity of the
data set, i.e. on Φz(ω).
Thus the focus of our attention, from now on, will be to seek conditions under which
the information matrix I(θ) is regular at all values of θ at which Γ(θ) > 0, and in
particular at the true θ0, assuming that the system is globally identiﬁable at θ0. To
simplify all expressions, we shall assume that σe = 1. The information matrix is then
deﬁned as I(θ) = E[ψ(t, θ)ψ(t, θ)] where ψ(t, θ) = W(z, θ)z(t) is the gradient of the
predictor, which we shall call the pseudoregression vector: see (13). We ﬁrst examine
the expressions of this gradient.
4.1
Expressions of the Pseudoregression Vector
The pseudoregression vector can be written:
ψ(t, θ) = [∇θWu(z, θ) ∇θWy(z, θ)]
'
u(t)
y(t)
(
= ∇θW(z, θ)z(t)
(19)
We rewrite this gradient in terms of the external excitation signals, u and e in the case
of open-loop data, r and e in the case of closed-loop data. To improve readability, we
delete the explicit dependence on the variables z and θ whenever it creates no confusion.
Open-Loop Identiﬁcation Setup
In open-loop identiﬁcation, the data are generated as
'
u(t)
y(t)
(
=
'
1
0
G0 H0
( '
u(t)
e(t)
(

158
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
The pseudoregressor is then expressed in terms of the external signals as
ψ(t, θ) = [∇θWu + G0∇θWy
H0∇θWy]
'
u(t)
e(t)
(
(20)
≜Vuol(z, θ)u(t) + Veol(z, θ)e(t)
(21)
Closed-Loop Identiﬁcation Setup
In closed-loop identiﬁcation, the data are generated as
'
u(t)
y(t)
(
= S
'
K
−KH0
KG0
H0
( '
r(t)
e(t)
(
where K = K(z) is the controller, and S = S(z) =
1
1+K(z)G0(z) is the sensitivity
function. The pseudoregressor is then expressed in terms of the external signals as
ψ(t, θ) = [SK (∇θWu + G0∇θWy)
SH0 (∇θWy −K∇θWu)]
'
r(t)
e(t)
(
(22)
≜Vrcl(z, θ)r(t) + Vecl(z, θ)e(t)
(23)
4.2
The Range and Kernel of Rank-One Vector Processes
We observe that in both cases the pseudoregressor ψ(t, θ) that “feeds” the information
matrix is made up of ﬁltered versions of quasistationary scalar signals, where the ﬁlters
are d-vectors of rational transfer functions. In order to study the rank of the matrix I(θ)
that results from taking the expectation of these rank-one processes, we introduce the
following deﬁnitions.
Deﬁnition 4. Let V (z) : C →Kd(z) be a d-vector of proper stable rational functions.
The left-kernel of V (z), denoted Ker{V (z)}, is the set spanned by all real-valued
vectors α ∈ℜd such that αT V (z) = 0 ∀z ∈C. Its dimension is called the nullity and
annotated νV . The rank of V (z) is deﬁned as ρV = d −νV , and V (z) is said to have
full rank if ρV = d.
■
Deﬁnition 5. Let ψ(t) : ℜ→ℜd be a d-vector of quasi-stationary processes. The
left-kernel of ψ(t), denoted Ker{ψ(t)}, is the set spanned by all real-valued vectors
α ∈ℜp such that E[αT ψ(t)]2 = 0, or alternatively αT Φψ(ω)α = 0 ∀ω where Φψ(ω)
is the spectral density matrix of ψ(t). Its dimension is called the nullity and annotated
νψ. The rank of ψ(t) is deﬁned as ρψ = d −νψ, and ψ(t) is said to have full rank if
ρψ = d.
■
Observation. A d-vector V (z) of proper stable rational functions has full rank if V (z)
is output reachable. A d × m transfer function matrix H(z) = ∞
k=0 Hkz−k is called
output reachable if ∄α ∈Rd such that αT H(z) = 0 ∀z ∈C or, equivalently, αT Hk =
0 ∀k: see e.g. [10].
With these deﬁnitions under our belt, we are now ready to analyze the rank of the
information matrix I(θ) as a function of the signals u and e (in an open-loop setup),
or r and e (in a closed-loop setup). The following result follows immediately from the
deﬁnitions.

Identiﬁability and Informative Experiments
159
Lemma 1. The rank of the information matrix I(θ1) at some value θ1 is the rank
of ψ(t, θ1).
In particular, the information matrix is regular at θ1 if and only if
Ker{ψ(t, θ1)} = {0}; equivalent statements are νψ(θ1) = 0 and ρψ(θ1) = d.
■
The analysis of the rank of I(θ) thus reduces to the analysis of the rank of ψ(t, θ)
which itself is composed of the sum of two vector ﬁlters of scalar stationary stochastic
processes: see (21) and (23). For the white noise driven terms, the analysis is very
simple: we have the following theorem.
Theorem 1. Let ψe(t, θ) = Ve(z, θ)e(t), where Ve(z, θ) is a d-vector of stable proper
rational ﬁlters and e(t) is white noise. Then Ker{ψe(t, θ)} = Ker{Ve(z, θ)}, and
hence ρψe = ρVe.
Proof. The result follows immediately by observing that, for any α ∈Rd:
0 = αT E[ψe(t, θ)ψT
e (t, θ)]α
= 1
2π
 π
−π
αT Ve(ejω, θ)V H
e (ejω, θ)α dω
■
This proof shows the coherence and the usefulness of our apparently disconnected deﬁ-
nitions of kernels for vectors of stationary stochastic processes and for vectors of proper
stable transfer functions.
4.3
Regularity Conditions for I(θ): A First Analysis
We now exploit the deﬁnitions we have just introduced to produce some ﬁrst conditions
on the regularity of the information matrix.
Theorem 2. With the notations introduced in (21) and (23), the information matrix I(θ)
is regular
• in open-loop identiﬁcation if and only if
Ker{Vuol(z, θ)u(t) + Veol(z, θ)e(t)} = Ker{Vuol(z, θ)u(t)} ∩Ker{Veol(z, θ)}
= {0}
(24)
• in closed-loop identiﬁcation if and only if
Ker{Vrcl(z, θ)r(t) + Vecl(z, θ)e(t)} = Ker{Vrcl(z, θ)r(t)} ∩Ker{Vecl(z, θ)}
= {0}
(25)
Proof. Consider the case of open-loop identiﬁcation. It follows from (21) and the inde-
pendence of the signals u and e that
αT E[ψ(t, θ)ψT (t, θ)]α = E[αT Vuol(z, θ)u(t)]2 + E[αT Veol(z, θ)e(t)]2.
(26)
Therefore α ∈Ker{ψ(t, θ)} if and only if α belongs to the left-kernels of both
Vuol(z, θ)u(t) and Veol(z, θ)e(t), and hence to their intersection. Next, it follows from
Theorem 1 that Ker{Veol(z, θ)e(t)} = Ker{Veol(z, θ)}. The proof is identical for the
closed-loop case.
■

160
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
Observe that the conditions (24) and (25) use the two distinct but compatible notions of
kernel, deﬁned in Deﬁnitions 4 and 5, respectively, in the same statement. These con-
ditions show how the regularity of I(θ) depends on both the model structure through
Vuol(z, θ) and Veol(z, θ) (respectively, Vrcl(z, θ) and Vecl(z, θ)) and the excitation sig-
nal u(t) (respectively r(t)). We now elaborate on these conditions, separately for the
open-loop and for the closed-loop identiﬁcation setup.
Open-Loop Identiﬁcation
In open-loop identiﬁcation, the ﬁlters Vuol(z, θ) and Veol(z, θ) are given by (20) and
(21). Simple calculations show that they are expressed in terms of the model transfer
functions G(z, θ) and H(z, θ) as follows1.
Vuol(z, θ) = ∇θWu + G0∇θWy =
1
H2(θ) [H(θ)∇θG(θ) + (G0 −G(θ))∇θH(θ)]
Veol(z, θ) = H0∇θWy =
H0
H2(θ)∇θH(θ)
We then have the following result.
Theorem 3. Let NH denote the left-kernel of ∇θH(z, θ). Then I(θ) is regular either if
NH = {0} or if for each non-zero d-vector α ∈NH we have
E[αT ∇θG(z, θ)u(t)]2 ̸= 0.
(27)
Proof. First note that the set of vectors {α ∈NH ⊆Rd} spans Ker{∇θWy} =
Ker{Veol(z, θ)}. Therefore, by Theorem 2, I(θ) > 0 if and only if either NH = {0}
or, for each nonzero α ∈NH, we have E[αT (∇θWu + G0∇θWy)u(t)]2 ̸= 0. Since
αT ∇θH(z, θ) = 0, this is equivalent with E[αT ∇θG(z, θ)u(t)]2 ̸= 0.
■
Closed-Loop Identiﬁcation
In closed-loop identiﬁcation, the ﬁlters Vrcl(z, θ) and Vecl(z, θ) are given by (22) and
(23). They are expressed in terms of the model transfer functions G(z, θ) and H(z, θ)
as follows.
Vrcl(z, θ) = KS(∇θWu + G0∇θWy)
= KS{
1
H2(θ) [H(θ)∇θG(θ) + (G0 −G(θ))∇θH(θ)]}
Vecl(z, θ) = H0S(∇θWy −K∇θWu)
= H0S
H2(θ){∇θH(θ) −K [H(θ)∇θG(θ) −G(θ)∇θH(θ)]}
For the closed-loop identiﬁcation setup we have the following result.
Theorem 4. Let NVecl denote the left-kernel of Vecl(z, θ). Then I(θ) is regular either
if NVecl = {0} or if for each non-zero d-vector α ∈NVecl we have
E[αT ∇θWy(z, θ)r(t)]2 = E[αT K(z)∇θWu(z, θ)r(t)]2 ̸= 0.
(28)
1 We omit the argument z here for reasons of brevity.

Identiﬁability and Informative Experiments
161
Proof. First note that for each α ∈NVecl ⊆Rd we have αT ∇θWy(z, θ) = αT K(z)
∇θWu(z, θ). By Theorem 2, I(θ) > 0 if and only if either NVecl = {0} or if, for
each non-zero α ∈NVecl we have E[αT KS(∇θWu + G0∇θWy)r(t)]2 ̸= 0. Now
observe that αT KS(∇θWu + G0∇θWy) = αT S(1 + KG0)∇θWy = αT ∇θWy =
αT K∇θWu. This proves the result.
■
4.4
Rich and Exciting Signals
In Theorem 1 we have seen that a regressor ψ(t) obtained by ﬁltering a white noise
signal e(t) through a vector ﬁlter V (z) has the same left-kernel as V (z), i.e. white
noise causes no drop of rank. The same is actually true for any input signal that has
a continuous spectrum. For the parts of ψ(t, θ) driven by the controlled signals u(t)
or r(t) (see (21) and (23)), we want to consider input signals (u(t) or r(t)) that have
discrete spectra, such as multisines. In order to analyze the rank properties of regressors
obtained by ﬁltering such signals with discrete spectra, we need to introduce the concept
of richness of a signal. We ﬁrst deﬁne a persistently exciting regression vector.
Deﬁnition 6. A quasistationary vector signal ψ(t) is called persistently exciting (de-
noted PE) if E[ψ(t)ψT (t)] > 0.
■
Whether a quasistationary vector signal ψ(t) obtained as a ﬁltered version (by a vector
V (z) of transfer functions) of a quasistationary scalar signal u(t) is PE or not depends
not only on whether Ker{V (z)} = {0} but also on the degree of richness of the input
u(t). The richness of a scalar signal is deﬁned as follows.
Deﬁnition 7. A quasistationary scalar signal u(t) is sufﬁciently rich of order n (de-
noted SRn) if the following regressor is PE:
φ1,n(t) ≜
⎡
⎢⎢⎢⎣
u(t −1)
u(t −2)
...
u(t −n)
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
z−1
z−2
...
z−n
⎤
⎥⎥⎥⎦u(t)
(29)
■
The vector φ1,n(t) serves as a basis for all regression vectors that are obtained as
(vector)-ﬁltered versions of a scalar signal u(t). For future use, we introduce the nota-
tion:
Bk,n(z) ≜
5
z−k z−k−1 . . . z−n6T , for k ≤n.
(30)
Observe that, by our assumption of quasistationarity, u(t) is SRn if Bk+1,k+n(z)u(t) is
PE for any k. We denote by Un the set of all SRn processes.
Deﬁnition 8. A scalar signal u(t) is sufﬁciently rich of order exactly n (denoted SREn)
if φ1,n(t) is PE, but φ1,n+1(t) is not.
■
This deﬁnition is equivalent with many other classically used deﬁnitions, except that
nowadays the most common terminology is to say that a signal is PE of order n rather

162
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
than SR of order n. At the risk of being considered old-fashioned, we prefer the term
sufﬁciently rich because sufﬁcient intuitively reﬂects the notion of degree of richness
while persistent does not. The following are commonly used deﬁnitions that are equiv-
alent with Deﬁnitions 7 and 8.
Proposition 4. A scalar quasistationary signal u(t) is SRn if
• its spectral density is nonzero in at least n frequency points in the interval (−π, π].
• it cannot be ﬁltered to zero by a FIR ﬁlter of degree n: α1z−1 + . . . αnz−n.
A scalar signal u(t) is SREn if its spectral density is nonzero in exactly n frequency
points in the interval (−π, π].
■
The equivalence comes by observing that
αT E[φ1,n(t)φT
1,n(t)]α = 1
2π
 π
−π
|α1e−jω + . . . + αne−jnω|2Φu(ω)dω.
The question of interest here is how the richness of a scalar signal u(t) transfers into
the persistence of excitation of a regression vector ψ(t) when this regression vector is
obtained as a (vector)-ﬁlter of u(t), i.e. ψ(t) = V (z)u(t), where the components of
V (z) are stable proper transfer functions. More precisely, we would like to determine
the smallest possible degree of richness of u(t) that will make ψ(t) PE. To help us
in solving this problem, we have . . . . . . not much. As it happens, the only available
results, as far as we know, are sufﬁciency results. We brieﬂy recall here the main
available results.
Proposition 5. [12] Let u(t) be SRn and let y(t) = G(z)u(t); then y(t) is SRn if the
ﬁlter G(z) has no zeroes on the unit circle, i.e. if G(ejω) ̸= 0 for all ω.
Proof. Since Φy(ω) = |G(ejω)|2Φu(ω), it follows immediately that if G(ejω) is
nowhere zero on the unit circle, then the frequency points where Φy(ω) ̸= 0 and where
Φu(ω) ̸= 0 are identical.
■
Proposition 6. [1] Let ψ(t) ∈Rd be a vector that has the state-space model
ψ(t + 1) = Aψ(t) + Bu(t)
(31)
with A ∈Rd×d. Then ψ(t) is PE if u(t) is SRd and the pair [A, B] is completely
reachable.
■
Proposition 7. [10] Let ψ(t) ∈Rd be the output of a vector V (z) of proper stable
ﬁlters driven by u(t):
ψ(t) = V (z)u(t),
(32)
and let δV ≜McMillan degree of V (z). Then ψ(t) is PE if the following two conditions
hold:
• the system (32) is output reachable, i.e. ∄α ∈Rd, α ̸= 0, such that αT V (z) = 0 ∀z;
• u(t) is SRn with n ≥δV + 1.
■

Identiﬁability and Informative Experiments
163
We now attempt to relate the left-kernel of ψ(t), the left-kernel of V (z) and the richness
of u(t). We ﬁrst state the trivial lemma.
Lemma 2. The trivial lemma. Let ψ(t) = V (z)u(t) with ψ(t) ∈Rd, u(t) quasista-
tionary, and all components of V (z) proper and stable. Then
Ker{V (z)} ⊆Ker{ψ(t)}.
(33)
■
The question we address now can be stated as follows.
What are the necessary and sufﬁcient conditions on the richness of u(t) such that
Ker{ψ(t)} = Ker{V (z)} when ψ(t) = V (z)u(t)?
V (z) can always be written as
V (z) = N(z−1)
d(z−1) =
z−m
d(z−1)RB0,k−1(z)
(34)
where d(z−1) = 1 + d1z−1 + . . . + dpz−p, with dp ̸= 0, where R ∈Rd×k is the
matrix of real coefﬁcients of the expansion of the numerator matrix N(z−1) into powers
of z−1, and m is a possible common delay in all elements of N(z−1). A necessary
condition for V (z) to be output reachable (i.e. Ker{V (z)} = 0) is that k ≥d. As we
shall see, in many cases of interest for the transfer of excitation from the signal u, or r,
to the pseudo-regression vector ψ, it so happens that R is square, i.e. k = d. Thus, we
ﬁrst handle this important (and much easier) special case.
Theorem 5. Let ψ(t) = V (z)u(t) with ψ(t) ∈Rd, u(t) quasistationary, V (z) proper
and stable, and let V (z) be decomposed as in (34) with d = k. Then ρψ = d if and only
if ρV = d and u(t) is SRd. (Stated otherwise: ψ(t) has full rank if and only if V (z) has
full rank and u(t) is SRd).
Proof. Using the decomposition (34) with k = d, we can write
E[αT ψ(t)]2 = 1
2π
 π
−π
|αT RB1,d(ejω)|2 Φu(ω)
|d(ejω)|2 dω,
(35)
where we have used the fact that |e−mjωαT RB0,d−1(ejω)|2 = |αT RB1,d(ejω)|2. If
ρV = d, and since k = d, it follows that R is nonsingular. Therefore αT R ̸= 0 for
all nonzero α, and αT R spans the space of all vectors in Rd. If in addition u(t) is
SRd, then by Proposition 4 the integral on the right hand side is nonzero for all α ̸= 0.
Conversely, if ρV < d then there exists α ̸= 0 such that αT R = 0, and if u(t) is SREn
with n < d, then there exists α ̸= 0 such that |αT RB1,d(ejω)|2Φu(ω) = 0 for all ω. ■
Example 2. Let
V (z) =
1
z3(z + 0.5)
⎡
⎣
z + 1
z2
1
⎤
⎦=
z−2
1 + 0.5z−1
⎡
⎣
z−1 + z−2
1
z−2
⎤
⎦
=
z−2
1 + 0.5z−1 RB0,2 with R =
⎡
⎣
0 1 1
1 0 0
0 0 1
⎤
⎦

164
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
The McMillan degree of V (z) is δV = 4, but ψ(t) ≜V (z)u(t) will be PE if u(t) is
SR3, since R has full rank.
In the more general situation where k > d, it is clear that u(t) = SRk is a sufﬁcient
condition to guarantee that Ker{ψ(t)} = Ker{V (z)}. However, we shall now show
that Ker{ψ(t)} = Ker{V (z)} for almost all u(t) ∈UN if and only if N ≥ρV ; recall
that UN is the set of u(t) that are SRN, and ρV is the rank of V (z). To show this, we
need a preliminary lemma.
Lemma 3. Let ψ(t) = V (z)u(t) with ψ(t) ∈Rd, u(t) quasistationary, V (z) proper
and stable, and let V (z) be decomposed as in (34) with ρV = c. Let the rows of
Q ∈Rc×k be a basis for the rowspace of R, and deﬁne the c-vectors W(z) =
z−m
d(z−1)QB0,k−1(z) and φ(t) = W(z)u(t).
Then, for any u(t), Ker{ψ(t)} =
Ker{V (z)} if and only if Ker{φ(t)} = Ker{W(z)} = 0.
Proof. Since the rows of Q form a basis for the rowspace of R we can write
R = T
' Q
0
(
(36)
for some nonsingular matrix T ∈Rd×d. Then for any α ∈Rd we have:
αT R = αT T
'
Q
0
(
= βT Q
(37)
where β is uniquely deﬁned by αT T ≜(βT
γT ) with β ∈Rc and γ ∈Rd−c. It
follows from (37) that
αT ψ(t) =
z−m
d(z−1)αT RB0,k−1(z)u(t) =
z−m
d(z−1)βT QB0,k−1(z)u(t) = βT φ(t)
Therefore the following four statements are all equivalent:
•
Ker{ψ(t)} = Ker{V (z)}
•
E[αT ψ(t)]2 = 0 if and only if αT R ∈Ker{B0,k−1(z)u(t)}
•
E[βT φ(t)]2 = 0 if and only if βT Q ∈Ker{B0,k−1(z)u(t)}
•
Ker{φ(t)} = Ker{W(z)}
Finally, since Q has full rank, Ker{W(z)} = 0.
■
Theorem 6. Let ψ(t) = V (z)u(t) with ψ(t) ∈Rd, u(t) quasistationary, V (z) proper
and stable, and let V (z) be decomposed as in (34). Then Ker{ψ(t)} = Ker{V (z)}
for almost all u(t) ∈UN if and only if N ≥ρV .
Proof. If ρV < d, we can replace ψ(t) = V (z)u(t) by φ(t) = W(z)u(t) with W(z)
deﬁned from V (z) as in Lemma 3 above, where W(z) has full rank. Thus, using
Lemma 3, we can assume without loss of generality that ρV = d.

Identiﬁability and Informative Experiments
165
Using Parseval’s Theorem and (34) we can write
E[αT ψ(t)]2 = E[αT z−m
d(z−1)RB0,k−1(z)u(t)]2
= αT R
 1
2π
 π
−π
Φu(ω)
| d(e−jω) |2 B0,k−1(e−jω)BH
0,k−1(e−jω)dω

RT α
Let u(t) be SRN with ﬁnite N.
Its spectrum can then be written as Φu(ω) =
N
i=1 λiΦu(ωi) with ωi ̸= ωj, i ̸= j.
Deﬁne its support as the vector z =
[ejω1 ejω2 . . . ejωN ] ∈ΩN, where ΩN ⊂CN is the set of all supports z which result
in an SRN signal, that is those z such that ωi ̸= ωj ∀i ̸= j. ΩN is an N-dimensional
subset of CN which deﬁnes the class of signals u(t) that we consider. Then we can
write
E[αT ψ(t)]2 = αT R

1
2π
N

i=1
λ′
iB0,k−1(e−jωi)BH
0,k−1(e−jωi)

RT α
where λ′
i =
λiΦu(ωi)
|d(e−jωi )|2 . Hence
E[αT ψ(t)]2 = αT RZ(z)ΛZH(z)RT α
(38)
with
Z(z) =
5B0,k−1(e−jω1) B0,k−1(e−jω2) . . . B0,k−1(e−jωN ) 6
and Λ = diag{λ′
1, λ′
2, . . . , λ′
N}; note that ρ(Z(z)) = N whenever N ≤k.
But ψ(t) is full-rank if and only if P(z)
∆= RZ(z)ΛZH(z)RT has rank equal to d,
which is equivalent to det(P(z)) ̸= 0. Suppose that N < d; then ρ(Z(z)) = N <
d which, noting that ρ(P(z)) ≤ρ(Z(z)), implies det(P(z)) = 0, thus proving the
necessity of N ≥d.
For N ≥d, the determinant det(P(z)) is a nontrivial polynomial in the vector
variable z and ψ(t) loses rank exactly at the roots of this polynomial. Since the roots of
a polynomial deﬁne a set of measure zero in the space of its variable, ψ(t) is full-rank
for almost all z ∈ΩN.
■
Our Theorem above completely characterizes the required signal richness of u(t) that
keeps the range of the regressor vector V (z)u(t) identical to the range of V (z). Yet, it
is worth specifying what happens for different levels of excitation, which is given in the
following theorem.
Theorem 7. Let ψ(t) = V (z)u(t) with ψ(t) ∈Rd, u(t) quasistationary, V (z) proper
and stable, and let V (z) be decomposed as in (34) with rank(V ) = ρV .
•
If u(t) is not SR of order ρV , then Ker(ψ(t)) ⊂Ker(V (z)).
•
If u(t) is SRk then Ker(ψ(t)) = Ker(V (z)).
Proof. This result follows immediately from Sylvester’s inequality:
ρ(R) + ρ(Z) −k ≤ρ(RZ) ≤min(ρ(R), ρ(Z))
which yields ρ(RZ) < ρ(R) for N < ρV and ρ(RZ) ≥ρ(R) for N ≥k.
■

166
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
The following example illustrates the results of our theorems.
Example 3. Consider the regressor ψ(t) = V (z)u(t), with
V (z) = R
5
1 z−1 z−2 z−3 z−46T
where R =
⎡
⎣
0 1 0 0 1
0 0 1 0 0
1 0 0 0 1
⎤
⎦
Consider ﬁrst u(t) = λ1 + λ2 sin(ωt), which is SRE3. For such signal, RZ is a
3 × 3 matrix, whose determinant is det(RZ) = −2j[3 sin(ω) −2 sin(2ω) −sin(3ω) +
sin(4ω)]. Its roots in (−π, π] are at −π
3 , 0, π
3 and π, but ω = 0 and ω = π do not
keep u(t) ∈U3. Thus, ψ(t) will have rank 3 for all u(t) ∈U3 except for u(t) =
λ1 + λ2 sin( π
3 t), i.e. for ω = π
3 .
Now let u(t) = λ1 sin(ω1t) + λ2 sin(ω2t) which is SRE4. From Theorem 7 we
know that the richness of this signal is in between the “necessary” richness (SR3) and
the sufﬁcient richness (SR5). We have
RZ =
⎡
⎣
ejω1 + ej4ω1 ejω2 + ej4ω2 e−jω1 + e−j4ω1 e−jω2 + e−j4ω2
ej2ω1
ej2ω2
e−j2ω1
e−j2ω2
1 + ej4ω1
1 + ej4ω2
1 + e−j4ω1
1 + e−j4ω2
⎤
⎦
It is rather easy to see that RZ will have full rank for all values of ω1 and ω2, ω1 ̸= ω2
except those for which ω1 + ω2 = π.
5
Regularity of I(θ) for ARMAX and BJ Model Structures
We now combine the results of Theorem 3 with those on the transfer of sufﬁciently rich
input signals to regression vectors in order to produce necessary and sufﬁcient richness
conditions on the input signal that guarantee regularity of the information matrix at all
θ at which the model structure is identiﬁable, i.e. Γ(θ) > 0. We do this for ARMAX
and Box-Jenkins (BJ) model structures in an open-loop identiﬁcation setup.
ARMAX Model Structure
Consider the ARMAX model structure
A(z−1)y(t) = B(z−1)u(t) + C(z−1)e(t)
(39)
where A(z−1) = 1 + a1z−1 + . . . + anaz−na, B(z−1) = b1z−1 + . . . + bnbz−nb, and
C(z−1) = 1 + c1z−1 + . . . + cncz−nc. We have the following result.
Theorem 8. For the ARMAX model structure (39), the information matrix I(θ) is reg-
ular at a θ at which the model structure is identiﬁable if and only if u(t) is SRk, where
k = nb + nu(θ) and nu(θ) is the number of common roots of the polynomials A(z−1)
and C(z−1) at that θ. I(θ) is regular at all θ at which the model structure is identiﬁable
if and only if u(t) is SRk with k = nb + min{na, nc}.

Identiﬁability and Informative Experiments
167
Proof. We ﬁrst comment that for ARMAX model structures, common roots between
the polynomials A and B, as well as between A and C, must be considered, because
they can generically occur. However, the three polynomials A, B and C must be co-
prime at any identiﬁable θ. For the ARMAX model structure, we have:
∇θG(z, θ) = 1
A2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
−Bz−1
...
−Bz−na
Az−1
...
Az−nb
0
...
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
∇θH(z, θ) = 1
A2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
−Cz−1
...
−Cz−na
0
...
0
Az−1
...
Az−nc
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
(40)
Let αT = (αT
A | αT
B | αT
C) denote any vector in the left-kernel of ∇θH(z, θ), and let
γA(z−1) ≜αT
AB1,na, γB(z−1) ≜αT
BB1,nb, and γC(z−1) ≜αT
CB1,nc. Then
αT ∇θH(z, θ) = 0 ⇔zγA(z−1)C(z−1) = zγC(z−1)A(z−1)
(41)
At all values of θ at which the polynomials A and C are coprime, it follows from
the theory of Diophantine equations (see e.g. [8]) that αA = 0 and αC = 0, be-
cause deg(zγA(z−1)) < deg(A(z−1)) and deg(zγC(z−1)) < deg(C(z−1)). Consider
now a θ at which there are common factors between A and C and let U(z−1) denote
the Greatest Common Divisor (GCD) of A and C, with deg(U(z−1)) = nu. Then
A = A1U and C = C1U for some coprime polynomials A1 and C1. Then (41) is
equivalent with zγA(z−1)C1(z−1) = zγC(z−1)A1(z−1) where deg(zγA) = na −1
and deg(zγC) = nc −1. The set of all solutions of this equation is described by
zγA = αT
AB0,na−1 = A1T,
zγC = αT
CB0,nc−1 = C1T
(42)
where T (z−1) is an arbitrary polynomial of degree nu−1. The left-kernel of ∇θH(z, θ)
is thus deﬁned by those vectors αT = (αT
A | αT
B | αT
C) such that αA and αC are solution
of (42), while αB is arbitrary. As stated earlier, we consider values of θ at which
Γ(θ) > 0. At these values of θ, αT ∇θG(z, θ) ̸= 0 for all vectors α deﬁned above and,
by Theorem 3, I(θ) > 0 if u(t) is such that E[αT ∇θG(z, θ)u(t)]2 ̸= 0 for all such α.
For such α, we have:
αT ∇θG(z, θ)u(t) = 1
A2 [−αT
AB1,naB + αT
BB1,nbA]u(t)
= 1
A2 [−z−1A1TB + αT
BB1,nbA1U]u(t)
=
1
AU [−z−1TB + αT
BB1,nbU]u(t)
(43)

168
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
where the coefﬁcients of the polynomial T , of degree nu −1, as well as the coefﬁcients
of αB are completely free. Therefore E[αT ∇θG(z, θ)u(t)]2 ̸= 0 if and only if the
following pseudoregressor has full rank:
ψ(t) =
1
AU
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
−Bz−1
...
−Bz−nu
Uz−1
...
Uz−nb
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
u(t) =
1
AU RB1,nb+nuu(t)
(44)
with R ∈R(nb+nu)×(nb+nu). Since A, B, C are coprime at all θ, and U is the com-
mon factor of A and C, it follows that B and U are coprime, and hence R in (44) is
nonsingular. Therefore, by Theorem 5, ψ(t) in (44) is PE (and hence I(θ) > 0) if and
only if u(t) is sufﬁciently rich of degree nb + nu(θ), where nu(θ) represents the num-
ber of common roots between A and C. Since the maximum number of such common
roots is min{na, nc}, I(θ) is regular at all identiﬁable θ if and only if u(t) is SRk with
k = nb + min{na, nc}.
■
BJ Model Structure
Consider now the BJ model structure:
y(t) = B(z−1)
F(z−1)u(t) + C(z−1)
D(z−1)e(t)
(45)
where B(z−1) and C(z−1) are as above, with F(z−1) = 1 +f1z−1 +. . . fnf z−nf and
D(z−1) = 1 + d1z−1 + . . . dndz−nd.
Theorem 9. For the BJ model structure (45), the information matrix I(θ) is regular
at a θ at which the model structure is identiﬁable if and only if u(t) is SRk, where
k = nb + nf.
Proof. The gradient vectors Vuol(z, θ) and Veol(z, θ) deﬁned in (21) are now parti-
tioned into 4 blocks corresponding, successively, to the parameters of the polynomials
B, F, C, and D. It is easy to see that the left-kernel of Veol(z, θ) (i.e. of ∇θH(z, θ))
is spanned by the set of vectors αT = (αT
B | αT
F | 0 . . . 0 | 0 . . . 0). Therefore, by
Theorem 3, I(θ) > 0 if and only if the following pseudoregressor is PE:
ψB,F (t) ≜1
F 2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
Fz−1
...
Fz−nb
−Bz−1
...
−Bz−nf
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
u(t)
(46)

Identiﬁability and Informative Experiments
169
= 1
F 2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1 f1
. . .
fnf
0
. . .
0
0
1
f1
. . .
fnf . . .
0
0
0
. . .
...
...
0
0 . . .
. . .
1
f1
. . . fnf
0 −b1 . . . −bnb
0
. . .
0
0
0
−b1
. . . −bnb 0
. . .
0
0
. . .
...
...
0
0 . . .
. . .
0
−b1 . . . −bnb
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠

 !
"
SBF
B1,nb+nf (z)u(t)
(47)
SBF is a Sylvester matrix, with dimensions (nb + nf) × (nb + nf). It is nonsingular
for all values of θ at which the polynomials B and F are coprime. Applying Theorem 5
again, we conclude that I(θ) > 0 at all values of θ at which the polynomials are coprime
if and only if u(t) is SRk, where k = nb + nf.
■
Just in the same vein, one can apply the results of Theorem 4 to the identiﬁcation of
closed-loop systems using ARMAX or BJ model structures. The results for these two
closed-loop setups, which are quite illuminating, will be presented at Giorgio Picci’s
next 65th birthday celebration.
6
Conclusions
The information matrix plays a fundamental role in system identiﬁcation, given that
it combines information about the identiﬁability of the model structure and about the
informativity of the data set. We have illustrated these connections, and we have pro-
vided conditions on the richness of the input signals that make the information matrix
full rank at all values of the parameter space where the model structure is identiﬁable.
Our objective has been to ﬁnd the smallest possible degree of richness of the input signal
that delivers a nonsingular information matrix. In deriving these conditions, we have
presented some new results on the degree of richness required to produce a persistently
exciting regressor.
Acknowledgements
We wish to thank the organizers of the Giorgio Picci workshop for giving us the oppor-
tunity to contribute this chapter. We also thank Roland Hildebrand and Luc Haine for
some useful hints for the proof of Theorem 6.
References
1. E. W. Bai and S. S. Sastry. Persistence of excitation, sufﬁcient richness and parameter con-
vergence in discrete time adaptive control. Systems and Control Letters, 6:153–163, 1985.
2. A.S. Bazanella, M. Gevers, and L. Miˇskovi´c. Closed-loop identiﬁcation of MIMO systems:
a new look at identiﬁability and experiment design. In To appear, European Control Confer-
ence, Kos, Greece, July 2007.

170
M. Gevers, A.S. Bazanella, and L. Miˇskovi´c
3. X. Bombois, G. Scorletti, M. Gevers, R. Hildebrand, and P.M.J. Van den Hof. Cheapest
open-loop identiﬁcation for control. In CD-ROM Proc. 33rd IEEE Conf on Decision and
Control, pages 382–387, The Bahamas, December 2004.
4. X. Bombois, G. Scorletti, M. Gevers, P.M.J. Van den Hof, and R. Hildebrand. Least costly
identiﬁcation experiment for control. Automatica, 42(10):1651–1662, October 2006.
5. M. Gevers, L. Miˇskovi´c, D. Bonvin, and A. Karimi. Identiﬁcation of multi-input systems:
variance analysis and input design issues. Automatica, 42(4):559–572, April 2006.
6. H. Jansson and H. Hjalmarsson. Optimal experiment design in closed loop. In 16th IFAC
World Congress on Automatic Control, paper 04528, July 2005.
7. T. Kailath. Linear Systems. Prentice-Hall, Englewood Cliffs, New Jersey, 1980.
8. V. Kuˇcera. Discrete linear control: the polynomial approach. John Wiley, 1979.
9. L. Ljung. System Identiﬁcation: Theory for the User, 2nd Edition. Prentice-Hall, Englewood
Cliffs, NJ, 1999.
10. I.M.Y. Mareels and M. Gevers. Persistence of excitation criteria for linear, multivariable,
time-varying systems. Mathematics of Control, Signals and Systems, 1(3):203–226, 1988.
11. T. S. Ng, G. C. Goodwin, and B. D. O. Anderson. Identiﬁability of MIMO linear dynamic
systems operating in closed loop. Automatica, 13:477–485, 1977.
12. T. S¨oderstr¨om and P. Stoica.
System Identiﬁcation.
Prentice-Hall International, Hemel
Hempstead, Hertfordshire, 1989.

On Interpolation and the Kimura-Georgiou
Parametrization
Andrea Gombani1 and Gy¨orgy Michaletzky2
1 ISIB-CNR, Corso Stati Uniti 4, 35127 Padova, Italy
gombani@isib.cnr.it
2 E¨otv¨os Lor´and University, H-1111 P´azm´any P´eter s´et´any 1/C,
Computer and Automation Institute of HAS, H-1111 Kende u. 13-17, Budapest, Hungary
michgy@ludens.elte.hu
Summary. We show how the Kimura-Georgiou parametrization for interpolating a function and
its derivatives at 0 is independent of the particular choice of basis of Szeg¨o-polynomials of ﬁrst
and second kind, but only on the map between these two polynomial bases. This leads to a more
general parametrization, which extends to different interpolation points and multivariable setup.
1
Introduction
We consider here the connection between a parametrization recently obtained by the
authors in [5] and [6] in the context of constrained Schur-interpolation and the Kimura–
Georgiou-parametrization (see [3,7]) for interpolating functions of a given degree n.
Historically, the problem arises in the constrained degree Schur- or Pick-Nevan-
linna-interpolation problems. The unconstrained problem has been studied exten-
sively by means of Linear Fractional Transformations (LFT) (see e.g. [1, 2] and
references therein). In this setup, the degree of the interpolating function Q is – in
general – the sum of the number of interpolating conditions and the degree of a
parameter function S; that is, if n is the number of interpolating conditions, we
have deg(Q) = n + deg(S). Kimura in [7] posed the problem of characterizing
all interpolating functions which are Schur (or Positive Real) with the constraint
that they have degree n. Although the Positive Realness was hard to characterize,
the parametrization of constrained degree interpolating functions in terms of Szeg¨o-
polynomials of the ﬁrst and second kind described in that paper became quite impor-
tant and is known as Kimura–Georgiou-parametrization (Georgiou had independently
derived the same parametrization in another context in his thesis, see [3]). We show
here how the Szeg¨o-polynomials do not play a particular role in this problem and how
this parametrization can easily be generalized to the multivariable case and different
interpolation points.
Let Q be a rational p × m matrix of McMillan degree n. If M is a complex matrix,
Tr shall denote its trace, M T its transpose and M ∗its transpose conjugate. For a
rational function Q , we set Q∗(z) := Q(−z)T . If we assume that we are given a set of
interpolation points z1, ..., zn in the plane CI
and interpolating conditions
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 171–182, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

172
A. Gombani and G. Michaletzky
U =
⎡
⎢⎢⎢⎣
u1
u2
...
un
⎤
⎥⎥⎥⎦
V =
⎡
⎢⎢⎢⎣
v1
v2
...
vn
⎤
⎥⎥⎥⎦
(1)
with ui, vi row vectors in CI p, and we want to ﬁnd the solutions Q to the problem
uiQ(zi)∗= vi
i = 1, ..., n.
(2)
(we will, in fact, impose the further condition that Q(∞) = D), then the above condi-
tions can be reformulated in a more general manner: set
A := diag{−z1, −z2, ..., −zn},
we can now write the problem as ﬁnding the rational functions Q such that:

(Q(z)U ∗−V ∗) (sI + A∗)−1
is analytic on σ(−A∗)
Q(∞) = D .
(3)
2
Interpolation Conditions as Matrix Equations
Our ﬁrst result is to express the interpolation conditions in Problem 3 in terms of matrix
equations for a given realization for Q. Although quite simple, the following conditions
do not seem to have appeared in the literature (the ﬁrst formulation presented here was
derived independently for the discrete time case by Marmorat and Olivi, see [8]). This
result was mainly used in [5,6] in connection with Schur-function, but it can be stated
in a quite general setting.
Proposition 1. Let Q be a rational function analytic in σ(−A∗) admitting a minimal
realization
Q =

AQ BQ
CQ D

.
Then (Q(z)U ∗−V ∗) (zI + A∗)−1 is analytic in σ(−A∗) if and only if there exists a
matrix Y such that
DU ∗−V ∗= CQY
(4)
and
BQU ∗= Y A∗+ AQY .
(5)
Proof. First suppose that (Q(z)U ∗−V ∗) (zI + A∗)−1 is analytic in σ(−A∗); then, it
can only have poles at the eigenvalues of AQ, and it vanishes at ∞; thus the observabil-
ity of (CQ, AQ) implies the existence of the matrix Y in
(Q(z)U ∗−V ∗) (zI + A∗)−1 = CQ (zI −AQ)−1 Y .
(6)

On Interpolation and the Kimura-Georgiou Parametrization
173
We can thus evaluate the identity
Q(z)U ∗−V ∗= DU ∗−V ∗+ CQ (zI −AQ)−1 BQU ∗
= CQ (zI −AQ)−1 Y (zI + A∗)
at ∞obtaining the equation
DU ∗−V ∗= CQY
Subtraction from the previous equation yields:
CQ (zI −AQ)−1 BQU ∗= CQ (zI −AQ)−1 (Y (zI + A∗) −(zI −AQ)Y )
= CQ (zI −AQ)−1 (Y A∗+ AQY ) .
Observability of (CQ, AQ) implies that
BQU ∗= Y A∗+ AQY .
Conversely, if a realization of Q satisﬁes (4) and (5), by backtracking the above ar-
gument, we see that (Q(z)U ∗−V ∗) (zI + A∗)−1 = CQ (zI −AQ)−1 Y is analytic
in σ(−A∗) using that the assumed minimality of the realization of Q guarantees that
σ(AQ) and σ(−A∗) are disjoint.
It is worth pointing out that for the ﬁrst part of the proof only the observability of
(CQ, AQ) was needed while for backward direction the controllability of (AQ, BQ) is
enough.
Notice also that, to obtain the equations (4)-(5), we have exploited the fact that the
function Q cannot have poles at the interpolation nodes. In fact this assumption is not
necessary, as it is shown in [5]. Namely, if the realization of Q is observable and the
interpolation condition (3) holds then there exists a matrix Y such that equations (4) (5)
are satisﬁed.
We would like now to parametrize all functions of degree n satisfying (3). In the
scalar case – i.e. when p = m = 1 – this can be formulated as solutions with McMillan-
degree exactly n or in other words as solutions in the form of ratio of two coprime
polynomials with degree n (see [7]). In this case exactly n parameters are needed to
express all the solutions. This type of formulation can be applied in the multivariate case
as well, although some care is needed. In fact, in this case, saying that a function has
degree n is not enough. To see this, assume that Q1 is an interpolant of degree k strictly
less than n. Then it can be shown that, under suitable conditions, there exist functions
Q2 analytic in σ(−A∗) of degree n −k such Q2(s)U ∗(sI + A∗)−1 is still analytic in
σ(−A∗), so that Q = Q1 + Q2 has degree less that or equal to n. By construction it
is also interpolating. On the other hand, it poses the same parametrization problems as
interpolants of lower degree in the scalar case. An example of how to construct such
functions is given below.
In conclusion, the functions Q we want to exclude from our parametrization are not
only the functions of degree strictly less than n, as in the scalar case, but also those
which can be reduced to a lower degree by subtraction of a suitable function having the
same state space as Q and vanishing on the the interpolation nodes.

174
A. Gombani and G. Michaletzky
To this end, we make the following deﬁnition.
Deﬁnition 1. Let Q be a solution of McMillan-degree n to problem formulated in (3)
and let Q =

AQ BQ
CQ D

be a minimal realization of Q: then we say that Q is irreducible
if the solution Y to the Sylvester-equation:
AQY + Y A∗−BQU ∗= 0
(7)
has full rank.
We will therefore restrict ourselves to the set of interpolants which are irreducible; this
is not a very restrictive assumption. In fact, it is quite easy to see that the excluded func-
tions form an algebraic set. So, we can reformulate the problem in (3) more precisely as:
Problem 1. Given the matrix A of size n×n, matrices U, V of size n×p and a constant
matrix D of size p × p, parametrize all functions Q, for which
(i)

(Q(s)U ∗−V ∗) (sI + A∗)−1
is analytic in σ(−A∗)
Q(∞) = D .
(8)
(ii) Q is rational of McMillan-degree exactly n ,
(iii) Q is irreducible,
(iv) Q is analytic in σ(−A∗).
For any given matrix B of size n × p, denote by
F ∗
B =

−A∗B
−U ∗I

,
G∗
B =

−A∗B
−V ∗D

.
Theorem 1. The rational function Q of McMillan-degree n is a solution of the interpo-
lation Problem 1 if and only if it has the realization
Q =

−A∗+ BU ∗B
DU ∗−V ∗D

(9)
for some matrix B.
Especially, in this case
Q = G∗
B (F ∗
B)−1 .
Proof. Assume that Q is an interpolating irreducible function of degree n; then, in view
of Proposition 1, any realization

A B
C D

of Q satisﬁes equations (4) and (5) for some

On Interpolation and the Kimura-Georgiou Parametrization
175
matrix Y . Since Q is irreducible, Y is invertible and therefore, equations (4) and (5)
can be rewritten as:
DU ∗−V ∗= CQY
(10)
and
Y −1AQY = −A∗+ Y −1BQU ∗
(11)
that is, Q =

−A∗+ Y −1BQU ∗Y −1BQ
DU ∗−V ∗
D

; setting B := Y −1BQ, we immediately
get (9).
Conversely, if Q has the minimal realization (9), then it is an interpolating function
(in view of Proposition 1); it is irreducible because Y = I and thus has trivial kernel.
Finally, the calculation
G∗(F ∗)−1 =

−A∗B
−V ∗D
 
−A∗+ BU ∗B
U ∗
I

=
⎛
⎝
−A∗+ BU ∗
0
B
BU ∗
−A∗B
DU ∗
−V ∗D
⎞
⎠
=

−A∗+ BU ∗B
DU ∗−V ∗D

= Q
concludes the proof.
The last form of the interpolating functions are already very similar to the one provided
by the Kimura–Georgiou-parametrization, where – in the scalar case – the solutions
are described as ratio of two polynomials. So it is worth pointing out the converse
statement, as well.
Proposition 2. Assume that the rational function Q has the following properties:
(i) Q is analytic on σ (−A∗) ;
(ii) Q satisﬁes condition (8)
(iii) for some matrix B the function Q has the form
Q = G∗(F ∗
B)−1 ,
where the set of the poles of the rational functions G∗and Q are disjoint.
Then G is uniquely determined by the matrix B, as well. Namely,
G∗= G∗
B .
Proof. The function standing on the right hand side of the following identity
G∗−
1
D −V ∗(zI + A∗)−1 B
2
= QF ∗−
1
D −V ∗(zI + A∗)−1 B
2
= Q −D −(QU ∗−V ∗) (zI + A∗)−1 B

176
A. Gombani and G. Michaletzky
is analytic on σ (−A∗), thus its poles should form a subset of the poles of Q while the
set of poles of the function on the left hand side should be disjoint from the poles of
Q. Consequently, they are constant functions. Evaluating at inﬁnity, we obtain that this
constant should be zero. I.e.
G∗= G∗
B ,
concluding the proof of the proposition.
Notice that the form of the function does not guarantee that its McMillan-degree is
exactly n, only it is no greater than n.
It is now easy to see how to construct an interpolation problem together with an
interpolating function of lower degree. Assume that for some matrices the equation
Y A∗+ B1U ∗= −A11Y
(12)
holds, where A11 and −A∗have no common eigenvalues and Y is a ﬂat full row-rank
matrix of dimension n1×n. (Its right inverse will be denoted by Y −R). Then obviously
A11 := −Y AY −R + B1U ∗Y −R. Consider any matrix C1 of size p × n1 for which
the pair (C1, A11) is observable. Deﬁne V ∗as V ∗= DU ∗−CY . Then equations
(5), (4) are satisﬁed and the full row-rank property of Y implies that (A11, B1) is a
controllable pair. Thus Proposition gives that Q1 =

A11 B1
C1
D

is an interpolating
function of degree n1.
This gives a starting point how to construct – in some cases – an interpolant of
degree n which is not irreducible. The above condition on Y means that the subspace
V := span{Y ∗ξ; ξ ∈CI n1} is a controlled invariant subspace for the pair (A, U)
(see [10]). Set U = span{Uξ; ξ ∈CI
m} If V ∩U ̸= {0}, then the equation
B2U ∗= −A21Y
(13)
has a solution, where B2 and A21 are of dimensions (n −n1) × m and (n −n1) × n1,
respectively, and not identically 0.
Thus (12) can be extended to
'
Y
0
(
A∗+
'
B1
B2
(
U ∗= −
'
A11 A12
A21 A22
( '
Y
0
(
where A12 and A22 are arbitrary. In particular, we can choose A12 = 0 and A22 such
that σ(A22)∩(σ(A11) ∨σ(−A∗)) = ∅and (A22, B2) is controllable. But then also the
pair (A, B) :=
' A11
0
A21 A22
(
,
' B1
B2
(
is controllable. If we now set C = [C1, C2],
with C2 arbitrary, we obtain that the equality
C
' Y
0
(
= −DU ∗+ V ∗
is satisﬁed and therefore, since (C1, A11) was observable, we can always choose
C2 so that also (C, A) is observable. Proposition 1 implies that the function Q =
⎛
⎝
A11 A12 B1
A21 A22 B2
C1
C2 D
⎞
⎠satisﬁes (i), (ii), (iv) in the Problem 1 but it is not irreducible.

On Interpolation and the Kimura-Georgiou Parametrization
177
3
The Connection with the Kimura-Georgiou Parametrization
We would like to show here how the Kimura–Georgiou-parametrization (see [7, 3])
overlaps with our framework; to this end, we consider the problem of interpolating
the ﬁrst n + 1 coefﬁcients of an expansion around 0 for scalar valued functions. The
starting point is the form Q = G∗
B (F ∗
B)−1 of the interpolating functions provided by
Theorem 1. Our setup works both in discrete and continuous time; but the original
parametrization was done for discrete time systems considering an expansion around
inﬁnity, (and the connection is easier to describe in this setup): therefore, in order to
make the connection precise, we consider parahermitian conjugation with respect to the
unit circle. That is, Z∗(z) = Z(1/z)
T . Following tradition, the interpolating functions
will be denoted by Z.
To get an idea of how this works, let us ﬁrst consider the following case:
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
−1 0
−1 ...
... ...
−1 0
⎤
⎥⎥⎥⎥⎥⎥⎦
U =
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
...
...
0
⎤
⎥⎥⎥⎥⎥⎥⎦
V =
⎡
⎢⎢⎢⎢⎢⎢⎣
v1
v2
...
...
vn
⎤
⎥⎥⎥⎥⎥⎥⎦
Then, the above is a classical interpolation problem of matching the value of the func-
tion and its n derivatives at 0.
(zI + A∗)−1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
z −1
z −1
... ...
... −1
z
⎤
⎥⎥⎥⎥⎥⎥⎦
−1
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
z−1 z−2 . . . . . . z−n
z−1 z−2
...
... ...
...
...
z−1
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
Thus we have
V ∗(zI + A∗)−1 = [v1z−1, v1z−2 + v2z−1, ..., v1z−n + v2zn−1 + ... + vnz−1]
U ∗(zI + A∗)−1 = [z−1, z−2, ..., z−n]
Choosing for example B = [0, 0, ..., 1]T and D = vn+1 + v1, we get
G∗= V ∗(zI + A∗)−1B + D = vn+1 + v1 + v1z−n + v2zn−1 + ... + vnz−1
F ∗= U ∗(zI + A∗)−1B + 1 = z−n + 1 = z−n(1 + zn) = z−n
1
1−zn+z2n−...
In conclusion,
G∗F −∗=

(vn+1 + v1)zn + v1 + v2z + ... + vnzn−1
(1 −zn + z2n −...)
= v1 + v2z + ... + vnzn−1 + vn+1zn + ...

178
A. Gombani and G. Michaletzky
as wanted. (Note that the special choice of D made it possible to interpolate the next
coefﬁcient, as well.) This interpolant was easy to calculate because of the choice of B.
Nevertheless, we are going to see that the general case is not much more complicated.
Let c0, c1, ..., cn be given; the above parametrization describes all the functions in-
terpolating the ﬁrst n conditions at 0 and having value D at inﬁnity. Now, a suitable
choice of D will allow us to interpolate also the (n + 1)-st coefﬁcient cn. So, we set
V ∗:= [c0, c1, ..., cn−1]
and let B = [b1, b2, ..., bn]T , with bn ̸= 0 so that −A∗and −A∗+ BU ∗have disjoint
spectra. Then, deﬁning G, F as above, the function Z = G∗F −∗will have expression
G∗F −∗= c0 + c1z + c2z2 + ... + cn−1zn−1 + O(zn)
(14)
independently of the choice of D. So, if we impose that also the (n + 1)-st coefﬁ-
cient cn to be matched, we will obtain an equation for D. Now, setting for notational
convenience b0 = 1 we have that
F ∗(z) = 1 + U ∗(zI + A∗)−1B
= 1 + [1, 0, ..., 0]
⎡
⎢⎢⎢⎣
z−1 z−2 . . . z−n
z−1
zn−1
...
...
z−1
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
b1
b2
...
bn
⎤
⎥⎥⎥⎦=
n

i=0
biz−i
Similarly,
G∗(z) = D + V ∗(zI + A∗)−1B
= D + [c0, c1, ..., cn−1]
⎡
⎢⎢⎢⎣
z−1 z−2 . . . z−n
z−1
zn−1
...
...
z−1
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
b1
b2
...
bn
⎤
⎥⎥⎥⎦
= D +
n

l=1
z−l
n

i=l
bici−l
(15)
On the other hand, if Z interpolates the ﬁrst (n + 1)-st coefﬁcients,
Z(z)F ∗(z) =
⎛
⎝
n

j=0
cjzj + O(zn+1)
⎞
⎠
n

i=0
biz−i =
n

l=0
z−l
n

i=l
bici−l+O(z) . (16)
Now, equation G∗= ZF ∗gives that this should be compared to (15); in order for
the equality to be satisﬁed, O(z) must vanish and the constant coefﬁcient in (16) must
be equal to D. This yields
D =
n

i=0
bici = [c0, c1, ..., cn−1, cn]
⎡
⎢⎢⎢⎢⎢⎣
b0
b1
b2
...
bn
⎤
⎥⎥⎥⎥⎥⎦
(17)

On Interpolation and the Kimura-Georgiou Parametrization
179
Therefore, putting together (15) and (17), G∗can be written as:
G∗(z) = [c0, c1, ..., cn−1, cn]
⎡
⎢⎢⎢⎢⎢⎣
0 z−1
z−2
. . . z−n
0
z−1
zn−1
... ...
...
0
z−1
0
⎤
⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
b0
b1
b2
...
bn
⎤
⎥⎥⎥⎥⎥⎦
+[c0, c1, ..., cn−1, cn]
⎡
⎢⎢⎢⎢⎢⎣
b0
b1
b2
...
bn
⎤
⎥⎥⎥⎥⎥⎦
= [c0, c1, ..., cn−1, cn]
⎡
⎢⎢⎢⎢⎢⎣
1 z−1
z−2
. . . z−n
1
z−1
zn−1
... ...
...
1
z−1
1
⎤
⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
b0
b1
b2
...
bn
⎤
⎥⎥⎥⎥⎥⎦
(18)
Similarly, since b0 = 1, the representation of F ∗can be extended to
F ∗(z) = [1, 0, ..., 0, 0]
⎡
⎢⎢⎢⎢⎢⎣
1 z−1
z−2
. . . z−n
1
z−1
zn−1
... ...
...
1
z−1
1
⎤
⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
b0
b1
b2
...
bn
⎤
⎥⎥⎥⎥⎥⎦
(19)
To make the connection with the Kimura–Georgiou-parametrization, let now
c0, c1, ..., cn be given (we assume, w.l.o.g. that c0 = 1) and suppose we want to
parametrize all functions Z(z) of McMillan-degree n which have the expansion at
inﬁnity:
Z∗(z) = c0 + c1z−1 + c2z−2 + ... + cnz−n + O(z−n−1)
(20)
The solution is given by the Kimura–Georgiou- parametrization: deﬁne recursively the
Szeg˝o-polynomials φk, ψk as:
'
φ0 −ψ0
φ∗
0 φ∗
0
(
:=
'
1 −1
1 1
(
and, for k > 0,
γk+1 := −φk(0)
' φk+1 −ψk+1
φ∗
k+1 φ∗
k+1
(
:=
'
z
−γk+1
−zγk+1
1
( ' φk −ψk
φ∗
k φ∗
k
(
(21)
Observe that φk and ψk are monic polynomials.
Then, the Kimura–Georgiou-
parametrization reads as follows: any Z∗(z) of the form (20) can be written as:

180
A. Gombani and G. Michaletzky
Z∗(z) = ψn + β1ψn−1 + ... + βnψ0
φn + β1φn−1 + ... + βnφ0
= Ψβ(z)
Φβ(z)
(22)
We will show that this is a special case of (9)
It is well known (see [4]) that, for 1 ≤k ≤n, the function Z∗
k(z)
Z∗
k(z) = ψk
φk
(23)
satisﬁes the relation
Z∗
k(z) = c0 + c1z−1 + cz2z−2 + ... + ckz−k + o(z−k−1)
(24)
(it is the maximum entropy solution for the interpolation problem (20) with n = k).
Therefore, writing
φk(z) = φk,kzk + φk,k−1zk−1 + φk,k−2zk−2 + ... + φk,0
ψk(z) = ψk,kzk + ψk,k−1zk−1 + ψk,k−2zk−2 + ... + ψk,0
(24) becomes:
ψk(z) = φk(z)Z∗(z) =
k

i=0
zi
k−i

j=0
φk,i+jcj
which, in matrix terms can be written as:
[ψk,0, ψk,1, . . . , ψk,k]
⎡
⎢⎢⎢⎣
1
z
...
zk
⎤
⎥⎥⎥⎦= [φk,0, φk,1, . . . , φk,k]
⎡
⎢⎢⎢⎣
c0
c1
c0
...
...
ck ck−1 . . . c0
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
1
z
...
zk
⎤
⎥⎥⎥⎦(25)
Writing relation (25) for all k ≤n we have the following matrix equality connecting
the coefﬁcients of the polynomials φ0, . . . , φn and ψ0, . . . , ψn:
⎡
⎢⎢⎢⎣
ψ0,0
ψ1,0 ψ1,1
...
...
ψn,0 ψn,1 . . . ψn,n
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
φ0,0
φ1,0 φ1,1
...
...
φn,0 φn,1 . . . φn,n
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
c0
c1
c0
...
...
cn cn−1 . . . c0
⎤
⎥⎥⎥⎦
(26)
It is important to point out only this equation will be needed to show that the form
Ψβ/Φβ given by the Kimura–Georgiou-parametrization is essentially the same as G/F
given in Theorem 1.
Notice now that the denominator of (22) can be written as:
Φβ(z) = [βn, βn−1, . . . β1, 1]
⎡
⎢⎢⎢⎣
φ0
φ1
...
φn
⎤
⎥⎥⎥⎦
= [βn, βn−1, . . . β1, 1]
⎡
⎢⎢⎢⎣
φ0,0
φ1,0 φ1,1
...
...
φn,0 φn,1 . . . φn,n
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
1
z
...
zn
⎤
⎥⎥⎥⎦

On Interpolation and the Kimura-Georgiou Parametrization
181
Setting
ˆB∗:= [βn, βn−1, . . . β1, 1]
⎡
⎢⎢⎢⎣
φ0,0
φ1,0 φ1,1
...
...
φn,0 φn,1 . . . φn,n
⎤
⎥⎥⎥⎦
we have that the denominator Φβ(z) of (22) is ˆB∗[1, z, ..., zn]T . Setting the n + 1
dimensional vector ξ := [1, 0, ..., 0]T, this can be written as:
Φβ(z) = ˆB∗
⎡
⎢⎢⎢⎣
1
z
...
zn
⎤
⎥⎥⎥⎦= ˆB∗
⎡
⎢⎢⎢⎣
1
z
1
...
...
zn zn−1 . . . 1
⎤
⎥⎥⎥⎦ξ
(27)
Similarly, in view of (26) and setting η := [c0, c1, ..., cn]T , the numerator Ψβ of (22)
becomes
Ψβ(z) = [βn, βn−1, . . . β1, 1]
⎡
⎢⎢⎢⎣
ψ0
ψ1
...
ψn
⎤
⎥⎥⎥⎦
(28)
= [βn, βn−1, . . . β1, 1]
⎡
⎢⎢⎢⎣
φ0,0
φ1,0 φ1,1
...
...
φn,0 φn,1 . . . φn,n
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
c0
c1
c0
...
...
cn cn−1 . . . c0
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
1
z
...
zn
⎤
⎥⎥⎥⎦
= ˆB∗
⎡
⎢⎢⎢⎣
1
z
1
...
...
zn zn−1 . . . 1
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
c0
c1
...
cn
⎤
⎥⎥⎥⎦= ˆB∗
⎡
⎢⎢⎢⎣
1
z
1
...
...
zn zn−1 . . . 1
⎤
⎥⎥⎥⎦η
A simple comparison of (18) with (28) and (19) with (27) shows that ˆB = B/bn and
thus
F/bn = Φβ
G/bn = Ψβ
Z∗= G
F = Ψβ
Φβ
Notice that, in principle, our parametrization does not coincide with that of Kimura and
Georgiou, because we require b0 to be 1. This means, essentially, that it leaves out the
polynomials. This is not surprising, since it was designed to represent interpolants as
proper rational functions and thus match interpolation conditions at any points of the
disk (for this section) and the constant term at inﬁnity. It should be noted, however, that
formulas (19) and (18) do make sense also for b0 = 0. This implies that there is no
special reason to choose the Szeg˝o-polynomials in the parametrization: any two basis
connected by the matrix

182
A. Gombani and G. Michaletzky
⎡
⎢⎢⎢⎣
c0
c1
c0
...
...
cn cn−1 . . . c0
⎤
⎥⎥⎥⎦
will do. A generalization of this fact to the Nevanlinna-Pick problem can be found
in [9].
Acknowledgements. We would like to thank Professor Paul Fuhrmann for asking us to
see the details of our claim that our parametrization and that of Kimura and Georgiou
were connected. Trying to answer his question led us to write the present paper.
References
1. J. A. Ball, I. Gohberg, and L. Rodman (1988) Realization and interpolation of rational matrix
functions. Operator Theory, Advances and Applications, 33:1–72.
2. H. Dym (1989) J-Contractive Matrix Functions, Reproducing Kernel Hilbert Spaces and
Interpolation, CBMS Regional Conference Series in Mathematics, No. 71, Amer. Math. Soc.,
Providence, R.I.
3. T. Georgiou (1983) Partial realization of covariance sequences. Ph.D.. Thesis.
4. Y.L. Geronimus, (1960) Polynomials orthogonal on a circle and interval, Pergamon Press.
5. A. Gombani and Gy. Michaletzky, On the Nevanlinna-Pick interpolation problem: analysis
of the McMillan-degree of the solutions, to appear on Linear Algebra and Applications.
6. A. Gombani and Gy. Michaletzky, On the parametrization of Schur and Positive Real func-
tions of degree n with ﬁxed interpolating conditions, submitted.
7. H. Kimura (1986) Positive partial realization of covariance sequences. In C. I. Byrnes and
A. Lindquist, editors, Modelling, Identiﬁcation and Robust Control, pages 499–513. Elsevier
Science.
8. J.P. Marmorat and M. Olivi, Nudelman Interpolation, parametrization of lossless functions
and balanced realizations, submitted.
9. Gy. Michaletzky, Stochastic approach to Nevanlinna-Pick interpolation, in preparation.
10. W.M. Wonham (1984) Linear Multivariable Control, 3rd ed., Springer Verlag, New York.

The Control of Error in Numerical Methods
Daniel Holder1, Lin Huo2, and Clyde F. Martin3
1 Texas Tech University
daniel.holder@ttu.edu
2 Texas Tech University
lin.huo@ttu.edu
3 Texas Tech University
clyde.f.martin@ttu.edu
1
Introduction
Differential equations are types of equations that arise from the mathematical mod-
elling, or simulation, of physical phenomena or from engineering applications; for
example: the ﬂow of water, the decay of radioactive substances, bodies in motion, elec-
trical circuits, chemical processes, etc. When we cannot solve differential equations
analytically, we must resort to numerical methods. Unfortunately, numerical methods
do not give us an exact solution, and an amount of error is introduced in the answer. It
is our goal to utilize concepts from Control Theory in order to minimize this error. For
our study, we shall focus on ordinary differential equations (ODEs).
Without going into details, we state that ODEs may be solved analytically by meth-
ods such as: substitution, by using an integrating factor, or by separation of variables, to
name a few. However, there are times when the differential equation is too complicated
to be solved analytically; it is then when we need to use numerical methods to obtain
an approximation to the solution.
Numerical methods may be single-step, in which case, in order to calculate the next
point of the solution function of the differential equation, it is only necessary to have
information of the preceding point. Examples are Euler’s method, Taylor’s method,
or Runge-Kutta method. Or they can be multi-step, where information of at least two
preceding points is necessary in order to calculate the next point of the solution function.
Examples are Adams-Bashforth method or Adams-Moulton method [3].
As mentioned earlier, numerical methods can only give us an approximation of the
solution, and the difference with the exact solution is referred to as the error. This
error is of varying magnitude for each method. It is the motivation of this work to
apply robust and optimal control concepts to these methods to reduce the error of the
solution [1]; in contrast to other control theoretical techniques which look to regulate
the stepsize selection in the solution of the ordinary differential equation [4]. Figure 1
is a block diagram of the complete ordinary differential equation solver.
The Plant consists of the Predictor and Corrector blocks. The Predictor generates an
approximation to the solution of the ODE, while the Corrector improves this approxi-
mation. The Model contains the exact solution of the ODE for comparison purposes,
from which an error is generated from the difference between the approximation and
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 183–192, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

184
D. Holder, L. Huo, and C.F. Martin
Fig. 1. Control Theoretic Model of an ODE Solver
the exact solution. Our work will focus on the error term en+1 and the design of the
Regulator, whose function is to minimize the error further. For the statistical analy-
sis, we will focus on the study of error distribution for the four-step Adams-Bashforth
method. We develop a model with a term which has a mean zero and a constant vari-
ance. Then we will compare these two models developed by control theory and by time
series theory.
2
A Simple Example
In order to illustrate the technique. We shall begin with a simple test ODE,
dx
dt = λx,
0 ≤t ≤1,
y(0) = 1,
with its well known solution x(t) = eλt and we shall use Euler’s method for the nu-
merical computation of this solution. Euler’s method is not sufﬁciently accurate to be
used in real applications but it is simple enough for illustration purposes.
The Euler algorithm is given by
xn+1 = hf(tn, xn)
for
n = 0, 1, . . ., N −1,
where N is a positive integer and the approximate value of x, xn, is found at given
points tn (called mesh points),
tn = a + nh
for
n = 0, 1, . . . , N,
where h is the step size given by h = b −a
N
= tn+1 −tn, on the interval [a,b].
Thus we have,
xn+1 = xn + λhxn
(1)
xn+1 = (1 + λh)xn
(2)
And the error can be found from
en = xn −eλhn
(3)

The Control of Error in Numerical Methods
185
0
20
40
60
80
100
−5
0
5
10
15
20
25
30
35
40
n
error value
Euler error e and corrected error ec
e
ec
Fig. 2. Comparison of the numerical error and the minimized error over the interval [0,1] with h
= 0.01
0
200
400
600
800
1000
−1200
−1000
−800
−600
−400
−200
0
200
n
error value
Euler error e and corrected error ec
e
ec
Fig. 3. Comparison of the numerical error and the minimized error over the interval [0,10] with
h = 0.01
We increment (3) to n+1, insert (2) and use the expression for xn that we get from
(3) to get the following:
en+1 = xn+1 −eλhneλh
(4)
= (1 + λh)xn −eλhneλh
(5)
en+1 = (1 + λh)en + (1 + λh −eλh)eλhn
(6)
We are now ready to apply the control un to (6) to get
en+1 = (1 + λh)en + un + sn
(7)
where sn = (1 + λh −eλh)eλhn is a forcing term.
We may now use the techniques presented by Anderson and Moore in [1] to optimize
the cost function
J(u) =
N+1

n=1
e2
n + δ
N+1

n=1
u2
n−1,
subject to (7); that is, ﬁnd the control sequence {un} that will minimize J(u).

186
D. Holder, L. Huo, and C.F. Martin
Thus, we ﬁrst ﬁnd Pn recursively from
Pn = A′{Q + Pn+1
−(Q + Pn+1)B[B′(Q + Pn+1)B + R]−1
B′(Q + Pn+1)}A,
with
PN = 0,
then we ﬁnd the optimal un from
un = −[B′(Q + Pn+1)B + R]−1B′(Q + Pn+1)A,
where Q = R = 1 for our case; and for our simple example A = (1 + λh) and B = 1.
We can now compute our minimized error en+1 with equation (7). Figures 2 and 3
depict the behavior of the minimized error (labelled “ec” in the ﬁgures).
3
Four-Step Adams-Bashforth
We shall now study a Four-step Adams-Bashforth procedure
yn+1 = yn + h
24[55f(yn) −59f(yn−1) + 37f(yn−2) −9f(yn−3)]
as we apply it to our linear control system
yn+4 −yn+3 = 55
24un+3 −59
24un+2 + 37
24un+1 −3
8un.
By taking z-transforms, we obtain
(z4 −z3)ˆyn = (55
24z3 −59
24z2 + 37
24z −3
8)ˆun.
Hence, the transfer function
H(z) =
(55
24z3 −59
24z2 + 37
24 z −3
8)
(z4 −z3)
and the observability realization
xn+1 = Axn + bun
yn = cxn,
where
A =
⎡
⎢⎢⎣
0 0 0 0
1 0 0 0
0 1 0 0
0 0 1 1
⎤
⎥⎥⎦, c =
50, 0, 0, 16
,
b =
5−3
8, 37
24, −59
24, 55
24
6T .

The Control of Error in Numerical Methods
187
We use the test ordinary differential equation as before
˙y = λy
and we apply the control un = λhyn + vn to obtain the following:
xn+1 = (A + λhbc)xn + bvn = ˆAxn + bvn
yn = cxn
Just as in the Two-step Adams-Bashforth method, the expression for the error between
the computed solution of the ODE and its exact solution is found:
en = yn −eλhn = cxn −eλhn
(8)
en+1 = cxn+1 −eλheλhn = c ˆAxn + cbvn
−eλheλhn
(9)
en+2 = c ˆA2xn + c ˆAbvn + cbvn+1 −e2λheλhn
(10)
en+3 = c ˆA3xn + c ˆA2bvn + c ˆAbvn+1 + cbvn+2
(11)
−e3λheλhn
en+4 = c ˆA4xn + c ˆA3bvn + c ˆA2bvn+1 + c ˆAbvn+2
+ cbvn+3 −e4λheλhn
(12)
now ˆA is of the form
ˆA =
⎡
⎢⎢⎣
0 0 0 −τ0
1 0 0 −τ1
0 1 0 −τ2
0 0 1 −τ3
⎤
⎥⎥⎦
and, by the Cayley-Hamilton Theorem, it satisﬁes its characteristic polynomial ˆA4 +
τ3 ˆA3 + τ2 ˆA2 + τ1 ˆA + τ0I = 0.
Hence,
τ0en + τ1en+1 + τ2en+2 + τ3en+3 + en+4 =
c( ˆA4 + τ3 ˆA3 + τ2 ˆA2 + τ1 ˆA + τ0I)xn
+ (c ˆA3b + τ3c ˆA2b + cτ2 ˆAb + τ1cb)vn
+ (c ˆA2b + τ3c ˆAb + τ2cb)vn+1
+ (c ˆAb + τ3cb)vn+2
−(τ0 + τ1eλh + τ2e2λh + τ3e3λh + e4λh)
eλhn
(13)
τ0en + τ1en+1 + τ2en+2 + τ3en+3 + en+4 =
(c ˆA3b + τ3c ˆA2b + cτ2 ˆAb + τ1cb)vn
+ (c ˆA2b + τ3c ˆAb + τ2cb)vn+1
+ (c ˆAb + τ3cb)vn+2
−(τ0 + τ1eλh + τ2e2λh + τ3e3λh + e4λh)
eλhn
(14)

188
D. Holder, L. Huo, and C.F. Martin
Take the z-transform of (14) to get:
ˆen =
'τ1cb + τ2c ˆAb + τ3c ˆA2b + c ˆA3b
z4 + τ3z3 + τ2z2 + τ1z + τ0
+
(c ˆA2b + τ3c ˆAb + τ2cb)z
z4 + τ3z3 + τ2z2 + τ1z + τ0
+
(c ˆAb + τ3cb)z2
z4 + τ3z3 + τ2z2 + τ1z + τ0
+
cb
z4 + τ3z3 + τ2z2 + τ1z + τ0
(
ˆvn
−
1
z4 + τ3z3 + τ2z2 + τ1z + τ0
Z{(τ0 + τ1eλh + τ2e2λh + τ3e3λh + e4λh)
eλhn}
(15)
Same as in the previous section, we seek a realization of the form
zn+1 = Fzn + gvn + g(forcing term)
en = ˆhzn
(16)
The cost function to be minimized does not change:
J(v) =
N+1

n=1
e2
n + δ
N+1

n=1
v2
n−1.
Calculate Pn recursively as before, with PN = 0 from
Pn = F ′{Q + Pn+1
−(Q + Pn+1)g[g′(Q + Pn+1)g + R]−1
g′(Q + Pn+1)}F
and ﬁnd the optimal control law from
K′
n = −[g′(Q + Pn+1)g + R]−1g′(Q + Pn+1)F
(17)
with the associated closed-loop system being
zn+1 = (F + gK′
n)zn
(18)
where Q =
⎡
⎢⎢⎣
1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1
⎤
⎥⎥⎦, R = [1], ˆh =
50, 0, 0, 16
,

The Control of Error in Numerical Methods
189
g =
⎡
⎢⎢⎣
τ1cb + τ2c ˆAb + τ3c ˆA2b + c ˆA3b
τ2cb + τ3c ˆAb + c ˆA2b
τ3cb + c ˆAb
cb
⎤
⎥⎥⎦, and F =
⎡
⎢⎢⎣
0 0 0 −τ0
1 0 0 −τ1
0 1 0 −τ2
0 0 1 −τ3
⎤
⎥⎥⎦.
Calculate the minimized error en with equation (16). Given the values obtained for
en, calculate the Four-step Adams-Bashforth error with error = ∥en∥∞. Figure 4
shows the graph of the f Four-step Adams-Bashforth error. Figure 5 is the semilog plot
of the Four-step Adams-Bashforth error (with the necessary adjustments in order to be
able to take logarithms); as before, observe that the sequence is increasing for n = 0
to 100. Figure 6 is a semilog plot of the corrected error. We see a very large transient
behavior but the sequence {ecn} converges to 0 as n goes to 100 (the value of ecn is
not plotted at n = 100 since the log 0 is undeﬁned).
0
20
40
60
80
100
0
1
2
3
4
5
6
7
8
n
Function value
y = exp(0.01*x) compared to xn+1 = xn + 0.01 * xn
y
xn
Four−step A−B error
Fig. 4. Comparison of the exact solution of the ODE with the numerical approximation;
with h = 0.01
0
20
40
60
80
100
−10
0.3
−10
0.4
−10
0.5
−10
0.6
n
error value
4−step Adams−Bashforth error en
Fig. 5. Four-Step Adams-Bashforth error over the interval [0,1]; with h = 0.01

190
D. Holder, L. Huo, and C.F. Martin
0
20
40
60
80
100
10
0
10
50
10
100
10
150
10
200
10
250
10
300
n
error value
Corrected error ecn
Fig. 6. Four-Step Adams-Bashforth corrected error; with h = 0.01
4
Statistical Analysis
Based on the simple example given before, we shall now study the statistical distribution
of the error. For Four-Step Adams-Bashforth method, Figure 7 depicts the behavior of
the error distribution.
Fig. 7. Four-Step Adams-Bashforth error distribution; with h = 0.01 and λ = 1
The error distribution indicates a linear pattern. To reduce the linear effect, next we
will ﬁt a second-order regression model to the data then study the residuals of the model
instead. The second-order regression model takes the following form:
en = β0 + β1n + β2n2 + ηn,
(19)
where β0, β1 and β2 are the parameters we need to estimate [5]. ηn is the residual.
Figure 8 shows the distribution of the residual of the regression model.
The pattern of the residual distribution indicates that the data is a stationary process.
We employ the second-order autoregressive model to study the residual since this model

The Control of Error in Numerical Methods
191
Fig. 8. Four-Step Adams-Bashforth residual distribution; with h = 0.01 and λ = 1
introduce a ”white noise” term, which is assumed to have a normal distribution. The
second-order autoregressive model [2] is given by:
˜ηn = φ1˜ηn−1 + φ2˜ηn−2 + an,
(20)
where ˜ηn is the deviation from µ, for example, ˜ηn = ηn −µ; ak is the ”white noise”,
usually assumed having a normal distribution; and φ1 and φ2 are the parameters can be
estimated.
By combining the second-order regression model and second-order autoregressive,
we obtain a new form of the model, which is given by:
en = β0 + β1n + β2n2 + µ
+ φ1(ηn−1 −µ) + φ2(ηn−2 −µ) + an.
(21)
Then with two equations obtained from second-order regression model:
en−1 = β0 + β1(n −1) + β2(n −1)2 + ηn−1
and
en−2 = β0 + β1(n −2) + β2(n −2)2 + ηn−2,
we can simplify the new form of the model by the following:
en = c0 + c1n + c2n2 + φ1en−1 + φ2en−2 + an,
(22)
where
c0 = β0 + µ + φ1(−β0 + β1 −β2 −µ)
+ φ2(−β0 + 2β1 −4β2 −µ),
c1 = β1 + φ1(−β1 + 2β2) + φ2(−β1 + 4β2),
c2 = (1 −φ1 −φ2)β2.
In equation (22), all the parameters c0, c1, c2, φ1 and φ2 can be estimated. According
to this new form of the model, the error en is not only related to the value of n, it is

192
D. Holder, L. Huo, and C.F. Martin
also related to the previous two values of the process. With our simple example, the
estimated parameters are: c0 = −2.49 × 10−10, c1 = −6.56 × 10−12, c2 = −7.60 ×
10−13, φ1 = 0.146 and φ2 = −0.087.
We observe the control theoretical error, ec, and the statistical error, es, side-by-
side in Figure 9 and we ﬁnd that the error corrected by the control theory technique
converges to a minimum much faster than the statistical error.
0
20
40
60
80
100
10
0
10
50
10
100
10
150
10
200
10
250
10
300
n
error
Control Error ec vs. Statistical Error es
ec
es
Fig. 9. Comparison of the control error with the statistical error
5
Conclusion
We approximated the solution of an Ordinary Differential Equation by using Euler’s
method and a Four-Step Adams-Bashforth method. It was demonstrated that the re-
sulting error from the numerical approximations of the solution can be minimized with
optimal and robust control techniques. After very high transients, the corrected error
from the Adams-Bashforth method converged to the desired minimum. We developed
a second-order autoregressive time series model based on the data generated from the
Four-Step Adams-Bashforth method. A ”white noise” term, symmetrically distributed
with mean zero and constant variance, was introduced in the autoregressive model. It
was shown that the minimized error converges faster than the statistical error, to the
desired value.
References
1. Brian D. O. Anderson and John B. Moore. Linear Optimal Control. Prentice-Hall, Inc.,
Englewood Cliffs, New Jersey, c1971, 1971.
2. Jenkins G. M. Box, G. E. P. and G. C. Reinsel. Time Series Analysis: Forecasting and Control.
Prentice-Hall, New Jersey, c1994, 3 edition, 1994.
3. Richard L. Burden and J. Douglas Faires. Numerical Analysis. Thomson, Belmont, California,
c2005, 8 edition, 2005.
4. Kjell Gustafsson. Control theoretic techniques for stepsize selection in explicit runge-kutta
methods. ACM Transactions on Mathematical Software, 17(4):533–554, 1991.
5. C. R. Rao. Linear Statistical Inference and Its Applications. Wiley, New York, c1973, 1973.

Contour Reconstruction and Matching Using
Recursive Smoothing Splines
Maja Karasalo1, Xiaoming Hu1, and Clyde F. Martin2
1 Optimization and Systems Theory, Royal Institute of Technology, 100 44 Stockholm, Sweden
2 Mathematics and Statistics, Texas Tech University, Lubbock, Texas 79409-1042
Summary. In this paper a recursive smoothing spline approach is used for reconstructing a
closed contour. Periodic splines are generated through minimizing a cost function subject to
constraints imposed by a linear control system. The ﬁltering effect of the smoothing splines al-
lows for usage of noisy sensor data. An important feature of the method is that several data sets
for the same closed contour can be processed recursively so that the accuracy can be improved
meanwhile the current mapping can be used for planning the path for the data-collecting robot.
1
Introduction
In this paper we focus on the problem of reconstructing closed contours in a clustered
environment. Our method is based on the so-called smoothing splines, both regular and
periodic, constructed from sensor data. The underlying assumption is that a robot will
be sent out repeatedly to collect data on the contours using range sensors. Since the
data collected will be noisy, some smoothing technique has to be applied.
Data smoothing has been a classical problem in system and control history [2,3]. It
has been further shown in [8] that control theoretic smoothing splines, where the curve
is found through minimizing a cost function, act as a ﬁlter and are better suited for
noisy measurements. It is also noted in [16] that smoothing splines are in some sense
band limited so that small changes in one data point will mainly affect the spline in a
neighborhood of that point.
We note that recursive approaches to constructing splines have been investigated in
[6] and [11]. In the ﬁeld of robotics recursive cubic B-spline methods for path planning
have been presented in [10] and [9]. Our approach differs from the previous work in this
ﬁeld by using control-theoretic smoothing splines that enable simultaneous planning,
mapping and data ﬁltering.
The point-to-point LQ optimal control problem has also recently been investigated
in for instance [17] and [18], where [17] treats the optimal output-transition problem for
linear systems while [18] considers LTI continuous-time systems with afﬁne constraints
in initial and terminal states.
This paper investigates a similar LQ problem but the important distinctions are
mainly that we optimize over all periodic solutions to the LQ problem and introduce
an iterative algorithm that enables the use of early contour estimates for localization
and path planning while collecting new data for the reﬁnement of the estimate.
The paper is organized as follows. In Section 2 we formulate the contour estimation
problem; in Section 3 we discuss some theoretic properties of the periodic smoothing
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 193–206, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

194
M. Karasalo, X. Hu, and C.F. Martin
splines; in Section 4 we discuss how to handle the inconsistence in two consecutive data
sets caused by the drifting error of the data-collecting robot. Finally, in Section 5 some
experimental results are shown and discussed.
2
Problem Formulation and Motivation
We are given a data set D = {(ti, zi) : i = 1, ..., N}, where t1 = 0 rad, . . ., tN =
T = 2π rad is the polar coordinate angle and zi is the radius in polar coordinates. The
data in D are noise contaminated measurements from a closed continuous curve. How
to ﬁnd the curve y(t) that best represents the data in some sense?
The solution is found by solving the following polar second derivative L2 smoothing
problem:
Problem 1
min
u,x0 J = 1
2xT
0 P −1
0
x0 + 1
2
 T
0
u(t)T Q−1u(t)dt+
N

i=1
(ti −ti−1)(zi −Cx(ti))T R−1
0 (zi −Cx(ti))
(1)
˙x = Ax + Bu
x0 = x(0) = x(T ).
(2)
The constraints (2) consist of an n-dimensional ODE with relative degree n and periodic
boundary condition. The resulting smoothing spline is given by y(t) = Cx(t). We refer
to the system
˙x = Ax + Bu,
y = Cx
(3)
as the spline generator of (1). For the purpose of ﬁnding a curve in R2 it sufﬁces to
choose a 2-dimensional spline generator.
As the data is noise contaminated, the resulting spline from one data set D will
give a poor map of the obstacle. Thus we let the robot servo several times around the
same obstacle, collecting sets of data that are used recursively to update and reﬁne the
map. We introduce a recursive smoothing spline method, where the optimal solution
(xk−1(t), uk−1(t)) from the previous iteration is used in iteration k together with the
new data zk
i .
Problem 2
min
uk,xk
0
Jk = 1
2(xk
0 −xk−1
0
)T P −1
0
(xk
0 −xk−1
0
)+
1
2
 T
0
(uk(t) −uk−1(t))T Q−1(uk(t) −uk−1(t))dt+
N

i=1
(ti −ti−1)(zk
i −Cxk(ti))T R−1
0 (zk
i −Cxk(ti))
(4)

Contour Reconstruction and Matching
195
˙xk = Axk + Buk
xk
0 = xk(0) = xk(T ).
(5)
Using a recursive method has the advantage of getting a better spline approximation for
each iteration, improving the map stepwise so that the previous map can be used for
path planning in each iteration. Also, if for some reason new data is obtained only for
one part of the curve, we can modify that part of the spline separately by performing
the next recursion using new data for that part of the curve and old data for the rest.
Due to the periodicity of the investigated curves we use polar coordinates. Thus, the
interpretation of the spline generator (3) is the following:
x1(t) = r(θ)
x2(t) = ˙x1(t) = dr(θ)
dθ
˙x2(t) = d2r(θ)
dθ2
= u
y(t) = x1(t) = r(θ).
(6)
We take
P −1
0
=
'
δ1 0
0 δ2
(
, Q = 1, R0 = 1/ε2,
(7)
where ε > 0 determines how much emphasis to put on measurement data. A large value
brings the spline close to the data points while a small value yields a smoother spline.
Consequently, we refer to the spline at iteration k as rk(θ). For this formulation we
require that the origin is placed inside the closed curve. Should this not be the case we
make a simple translation, compute the spline and translate back. Finally, for clarity, we
state the two problems using the polar parameterization. Equations (1) and (2) become
min
r
J(r) = δ2
1r(0)2 + δ2
2r′(0)2 +
 2π
0
u2(θ)dθ + ε2
N

i=1
wi(r(ti) −zi)2
(8)
r(0) = r(2π)
r′(0) = r′(2π)
(9)
while Equations (4) and (5) become
min
˜rk J(˜rk) = δ2
1˜rk(0)2+δ2
2˜rk′(0)2+
 2π
0
(˜uk)2(θ)dθ+ε2
N

i=1
wi(˜rk(tk
i )−˜zk
i )2 (10)
˜rk(0) = ˜rk(2π)
˜rk′(0) = ˜rk′(2π),
(11)
where
˜zk
i = zk
i −rk−1(tk
i )
˜rk(θ) = rk(θ) −rk−1(θ)
˜uk = uk −rk−1(θ)′′.
(12)

196
M. Karasalo, X. Hu, and C.F. Martin
Here (zk
i , tk
i ) are the data points from iteration k, rk−1(tk
i ) is the resulting spline of
iteration k −1 evaluated at the angle measurements of the new data set and rk(θ) is the
spline output of iteration k, found through
rk(θ) = ˜rk(θ) + rk−1(θ).
(13)
As seen from Equations (8) and (10) the particular choice of system matrices yields a
minimization over only one parameter, r. By choosing an appropriate discretization of
the system both problems can be implemented as unconstrained quadratic programming
problems, as is discussed in detail in [1]. Note also that Equations (10) and (11) are
identical to Equation (8) and (9) except for the new variable name ˜rk and input data ˜zk.
Hence the solution methods for both problems are identical except that the input to the
former is (ti, zi) and to the latter, at iteration k, is (ti, ˜zk
i ).
In the next section we will review and discuss some theoretical properties of the
optimal smoothing problems formulated in this section.
3
Some Theoretical Properties
The studied smoothing problem is a continuous time problem with discrete data and pe-
riodic boundary conditions. Such problems, without the periodic constraint, have been
widely studied in the literature, see for example the books by Bryson and Ho [2] and
Jazwinski [3]. However, as far as we know, it is difﬁcult to ﬁnd results concerning the
periodic case. For the sake of completeness, we investigate the conditions for solving
this problem. We begin by studying the proper periodicity conditions.
3.1
Proper Periodicity Conditions
In this section, we adopt the notations used in [5]. Suppose (u∗, x∗) is optimal within
the class of constant solutions of Problem 1. Namely the optimal steady state for the
dynamical constraints. Let J
∗denote the cost at the optimal steady state.
Deﬁnition 1. The optimal control problem is said to be proper if there exists an admis-
sible control u(·) such that
J(u(·)) < J
∗.
If we consider the polar coordinates (6), then it is easy to see that all steady states are
circles. The problem (8) becomes proper if we can ﬁnd a better curve than a circle. Here
we only consider the case where δ1 and δ2 are set to zero, for the sake of simplicity.
We believe that this problem is proper as long as the data set is nontrivial, namely, there
exist at least two points (θi, r(θi)) and (θj, r(θj)), such that r(θi) ̸= r(θj). However,
with the applications in mind, we will only show a weaker result here.
Theorem 1. Consider the periodic control problem (8). Suppose δ1 = δ2 = 0. Then
problem (8) is proper generically, namely, the data sets that make the problem not
proper are contained in an algebraic set.
Proof. By fairly straight forward but tedious calculation we can show that the optimal
control for problem (8) is the solution of the following problem:

Contour Reconstruction and Matching
197
min
u C(u) =
 2π
0
u2dθ + ϵ2
N

i=1
wi( θi
2π
 2
0
π(2π −s)u(s)ds
−
 θi
0
(θi −s)u(s)ds −ri)2
−ϵ2 (N
i=1 wi( θi
2π
% 2
0 π(2π −s)u(s)ds −% θi
0 (θi −s)u(s)ds −ri))2
N
i=1 wi
s.t.
 2π
0
u(s)ds = 0.
(14)
In particular, C(0) = J
∗, the optimal steady state cost (least square solution) for (8).
Now we consider only the following class of feasible control
u = α sin(mt + θ0),
where m is a positive integer. One can easily show that for large enough m and properly
chosen θ0, the optimal α for (14) is generically non-zero.
2
Next we review the optimality conditions. We ﬁrst consider the continuous time, con-
tinuous data problem, then use the solution of that case to analyze the discrete data case.
The ﬁnal step is to study how the iterated discrete data case relates to the continuous
data case.
3.2
Continuous Time, Continuous Data
The continuous time, continuous data formulation is the following: Find x0, u(t) so
that J is minimized, where
J = 1
2(x0 −ˆx0)T P −1
0
(x0 −ˆx0) + 1
2
 T
0
[(u(t) −ˆu(t))T Q−1(u(t) −ˆu(t))+
(z(t) −Cx(t))T R−1(z(t) −Cx(t))]dt
(15)
˙x =
Ax + Bu
x0 =
x(0) = x(T ).
(16)
For our setup, ˆx and ˆu are previous estimations of the state and control and z is the
measurement data, which for now is assumed continuous. For investigating (15) our
starting point will be the smoothing problem solved in [2], which is the same as above
except without the periodicity constraint. The Euler-Lagrange equations without the
periodicity constraint (16) are
˙
'x
λ
(
=
'
A
−BQBT
−CT R−1C
−AT
( 'x
λ
(
+
'
Bˆu
CT R−1z
(
(17)
x0 = ˆx0 −P0λ(0)
λ(T ) = 0
u(t) = ˆu −QBT λ(t).
(18)

198
M. Karasalo, X. Hu, and C.F. Martin
The solution can be found using sweep methods, either starting at the terminal con-
straint (backward sweep) or at the initial constraint (forward sweep). The solution of
our system (15) can be derived along the same lines, given that the particular system
meets some speciﬁcations that will be deﬁned in this section. We start out by deriv-
ing the Euler-Lagrange equations. They are the same as in the above, except for the
boundary conditions. Obviously the terminal condition for λ must be replaced. For our
system it holds that x(0) = x(T ). If we integrate (17) using this periodicity constraint
and the unchanged initial constraint (18), we get
'
x(t)
λ(t)
(
= eHt
'
x(0)
λ(0)
(
+
 t
0
eH(t−s)g(s)ds
(19)
where H is the Hamiltonian matrix and g(t) is the vector on the left hand side of (17).
We rewrite this system as
'
x(t)
λ(t)
(
= E(t)
'
x(0)
λ(0)
(
+
 t
0
E(t −s)g(s)ds.
(20)
Let G(t) =
% t
0 E(t −s)g(s)ds, then
x(t) =
E11(t)x(0) + E12(t)λ(0) + G1(t)
λ(t) =
E21(t)x(0) + E22(t)λ(0) + G2(t).
(21)
Now we can use the fact that x(T ) = x(0) to derive
λ(T ) =
E21(T )(I −E11(T ))−1(E12(T )λ(0) + G1(T ))+
E22(T )λ(0) + G2(T ).
(22)
This is our terminal constraint on λ. As seen from (22) we need to require that the
matrix (I −E11(T )) is not singular in order to have a solution. Apparently (I −E11(t))
is generically invertible in most cases. We will investigate this matrix for our particular
system, where the matrices are deﬁned by (7). Thus we get
H =
⎡
⎢⎢⎣
0
1 0
0
0
0 0 −1
−ε2 0 0
0
0
0 −1 0
⎤
⎥⎥⎦.
(23)
The expression for E(T ) = eHT is tedious and will not be displayed here, but it is
straight forward to show that (I −E11(2π)) is invertible when ε is small. Thus we
can solve the problem using the same forward sweep method but altering the terminal
constraint for λ. Denote by F(λ(0), T ) the right hand side of (22), so that
λ(T ) = F(λ(0), T ).
(24)
Then our terminal constraint on x can be derived by forward sweep as
x(T ) = ˆx(T ) −P(T )F(λ(0), T ).
(25)

Contour Reconstruction and Matching
199
Now recall that λ(0) is given by x(0) in (18), so (24) is really a function of x(0) =
x(T ). Thus
x(T ) = ˆx(T ) −P(T )F(P −1
0
(ˆx0 −x(T )), T )).
(26)
In order to have (26) well posed, we need
E21(T )(I −E11(T ))−1E12(T ) + E22(T ) −P −1(T )P0
(27)
to be invertible. With the double integrator system, which represents a general con-
trollable second order system, this should be true generically. Now (17) can be solved
by backwards integration for the case with periodicity constraint. Note that the period-
icity will only affect boundary values, the Riccati equations are the same for the two
problems.
3.3
Continuous Time, Discrete Data
The continuous time, discrete data formulation is the following: Find x0, u(t) so that J
is minimized, where
J = 1
2(x0 −ˆx0)T P −1
0
(x0 −ˆx0)+
1
2
 T
0
(u(t) −ˆu(t))T Q−1(u(t) −ˆu(t))dt+
N

i=1
(ti −ti−1)(zi −Cx(ti))T R−1
0 (zi −Cx(ti))
(28)
˙x =
Ax + Bu
x0 =
x(0) = x(T ).
(29)
Here, zi are the sampled data at times ti. In this section we show that the solution to
(28) approaches the solution to the continuous data problem as N →∞. Since the
Riccati equations do not depend on the terminal constraints, following the treatment
in [2,3] we have
˙ˆx =
Aˆx + Bˆu + Ki(zi(t+
i ) −Cˆx)δ(t −ti)
˙P =
AP + PAT + BQBT −KiCP(t−
i )δ(t −ti)
(30)
ˆx(0) = ˆx0
P(0) = P0,
where Ki = (ti −ti−1)P(t−
i )CT [(ti −ti−1)CP(t−
i )CT + R0]−1. It is easy to show
that as
N

i=1
(ti −ti−1)zi →
 T
0
z(t)dt,
(31)
the discrete problem also converges to the continuous problem.

200
M. Karasalo, X. Hu, and C.F. Martin
3.4
Continuous Time, Discrete Data Iterated
We can write down the Riccati equations for the iterated case (4) as
˙ˆxk =
Aˆxk + Buk−1 + Kk
i (zk
i (t+
i ) −Cˆxk)δ(t −ti)
˙P k =
AP k + P kAT + BQBT −Kk
i CP k(t−
i )δ(t −ti)
(32)
ˆxk(0) = xk−1
0
P k(0) = P0,
where Kk
i = (ti −ti−1)P k(t−
i )CT [(ti −ti−1)CP k(t−
i )CT + R0]−1 and xk−1
0
is the
optimal solution from iteration k −1. It remains to be shown under what conditions the
iterative case will converge to the continuous data case. Experimental results presented
in this paper and simulations in for instance [20] do however suggest convergence for
a large family of contours. In the rest of the paper, we will focus on two applications
of periodic smoothing splines. First we present a method for data set reconstruction
despite drifting error using the closed form spline formulation (Problem 1) and then a
converging contour estimation using the recursive method (Problem 2). Both applica-
tions have been experimentally evaluated.
4
Data Set Reconstruction
The reconstruction algorithm is described for a nonholonomic platform using odometry
for localization. Data points are generated by combining drifting odometry data with
range measurements, which have a white noise error but no drift. The principles are
however general and can be used for any system where the output is contaminated with
a linearly drifting noise.
φ
L
y
x
heading
SICK sensor
platform
Fig. 1. Robot platform, sensor position and parameters
We call the robot state (x, y, φ). The agent is equipped with a range sensor located
at a distances L from (x, y) as shown in Figure 1. Then a point (xw,yw) on the target
object is obtained as follows:
xw = x + L cosφ + Si cos(φ + vi)
(33)
yw = y + L sin φ + Si sin(φ + vi),
(34)
Here vi ∈[−π/2, π/2] is the angle of the sensor ray and Si is the range measurement
associated with it. Due to the drifting odometry error the set (xw, yw) yields a skew
representation of the environment, see Figure 2.

Contour Reconstruction and Matching
201
To determine and compensate for the odometry drift we utilize two consecutive data
sets, D1 and D2. The problem to address is to ﬁnd the right translation, rotation and
scaling between the two sets. We should take the following facts into consideration
when developing such a method:
•
We want to determine the drift in every time step as well as the rotation, translation
and scaling between D1 and D2.
•
We assume no knowledge of the true contour of the object.
•
We cannot compare the sets pointwise since point number k of D1 might not corre-
spond to point number k of D2. We might even have sets of different size.
Our method can be sketched as follows.
1. Translate D1 and D2 so that their respective mass centers coincide with the origin
to prepare for a closed spline curve computation.
2. Transform the sets to polar coordinates in the new frames.
3. Compute smoothing splines (r1, θ1), (r2, θ2) for the sets respectively.
4. Translate D1 and D2 and the splines z1 = r1eθ1i and z2 = r2eθ2i back to the
original positions of the sets.
5. Find the translation, rotation and scaling between D1 and D2 by obtaining the least
square solution to z1 = az2 + b for complex scalars a and b. We note that the best
ﬁt might not be found by matching z2(k) to z1(k). Therefore the computation is
made for every permutation of z1 and the solution that yields the smallest residue
is chosen.
6. Denote by Nj the number of data points in Dj, j = 1, 2. Transform each point
zj(t) in both sets by reversing the pointwise drift:
zj(t) →

1 −(1 −a)t
Nj

z(t) + (t −1)b
Nj
(35)
We call the transformed sets ˜D1 and ˜D2,
7. The sets ˜D1 and ˜D2 quite accurately represent the true shape, but they differ by a
translation and rotation. This transform is found again by using the same method:
z2 →az2 + b.
(36)
In the above procedure, if the contour cannot be well deﬁned in polar coordinates or
if they do not represent a closed contour the splines will not resemble the true curve at
all. But by comparing the two splines we can still ﬁnd the transformation between the
two sets, the only requirement is that the investigated terrain is servoed along the same
path twice and that we can assume a linear odometry drift.
The contour might not be of a kind that is ideally described in polar coordinates.
This affects the discretization of the splines z1 and z2. For instance, a square will
have more points around the center of each side than around the corners since the latter
are farther away from the origin. This will affect the comparison between two curves
since more emphasis will be put on matching segments with more discretization points.
Should this be the case one can remove some discretization points so that the distance
between two consecutive points lies within some tolerance interval for the entire vector.
In Figure 2 – Figure 4 we show some results for experimental data sets from a square
object.

202
M. Karasalo, X. Hu, and C.F. Martin
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
Fig. 2. Odometry drift: The resulting data from two consecutive revolutions along a circular path
around a square object with sidelength 1 m
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
Fig. 3. Odometry drift: The two data sets have been pointwise transformed to compensate for the
drift during one revolution
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Fig. 4. Odometry drift: The second data set is ﬁnally transformed to coincide with the ﬁrst set
5
Evaluation of Recursive Spline Method
We use the PowerBot from ActivMedia Robotics. It has unicycle dynamics and uses
odometry data for localization. The robot is provided with two SICK laser scanners

Contour Reconstruction and Matching
203
mounted one in front and one on the left side of the chassis. The scanners give range
measurements on the interval [−π/2, π/2] rad from the center of the scanner and with
a resolution of 0.5o, or 361 measurements each time step.
The robot servos the target object following a circular path. This minimizes odome-
try drift and allows the robot to return to the same starting position for every revolution
without the use of landmarks. The algorithm was evaluated using three different target
contours:
1. Single circle - the simplest possible test contour for a polar coordinate algorithm
2. Square - not ideal for polar coordinates and a quadratic smoothing cost function
3. Three circles - a non convex contour which can only be described in polar coordi-
nates if the origin of coordinate frame is chosen carefully.
The relative error between the curve generated by the smoothing spline algorithm at
iteration k and the true shape is deﬁned as |rk−rtrue|/|rtrue| where rk is the smoothing
spline output and rtrue is the real curve contour in polar coordinates. Ideally we expect
the error to decrease as 1/
√
k due to the quadratic nature of the spline cost function.
0
2
4
6
8
10
12
14
16
4
5
6
7
8
9
10
x 10
−3
Error circle, M = 500, d = 0, e1 = 100, e2 = .1, dk = 37
iterations
|rk − rtrue|/|rtrue|
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Circle it 16,  M = 500, d = 0, e1 = 100, e2 = .1, dk = 37
Fig. 5. Convergence of the algorithm for the circular object

204
M. Karasalo, X. Hu, and C.F. Martin
This behavior is apparent for the circular shapes while the challenging square shape
displays more of a linear convergence.
Single Circle
As expected, convergence is fast for the circular object and even the initial error is
small. This validates the assumption that the algorithm is ideal for convex contours that
are naturally deﬁned in polar coordinates.
Square
The smoothing spline algorithm has difﬁculty handling sharp edges, which yields larger
errors and slower convergence than for the circular shapes.
0
2
4
6
8
10
12
14
16
0.0445
0.045
0.0455
0.046
0.0465
0.047
0.0475
0.048
0.0485
0.049
0.0495
Error square,  M = 500, d = 0, e1 = 30, e2 = .1, dk = 15
iterations
|rk − rtrue|/|rtrue|
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Square it 16, M = 500, d = 0, e1 = 30, e2 = .1, dk = 15
Fig. 6. Convergence of the algorithm for the square object

Contour Reconstruction and Matching
205
Three Circles
When dealing with non convex contours the performance of the algorithm varies much
over the curve. For high curvature parts of the contour we would need a dense data set,
or a lot of iterations, to retrieve all of the needed information. The error convergence is
quadratic for this test object although it displays a noisier behavior than for the single
circle.
0
2
4
6
8
10
12
14
16
0.075
0.08
0.085
0.09
0.095
0.1
Error bins, M = 200, d = 0, e1 = 200, e2 = .0001, dk = 200
iterations
|rk − rtrue|/|rtrue|
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Bins it 16, M = 200, d = 0, e1 = 200, e2 = .0001, dk = 200
Fig. 7. Convergence of the algorithm for the non-convex object
6
Conclusions
In this paper we discussed a recursive smoothing spline approach to contour reconstruc-
tion. We derived periodic smoothing splines recursively from noisy data by solving an
optimal control problem for a linear system. To complete the framework we proposed
also a method for compensating the drifting error. Our experiments showed that the
splines converge to the true contours we have chosen and that parts of the spline can be
modiﬁed separately as new data becomes available.

206
M. Karasalo, X. Hu, and C.F. Martin
References
1. G. Piccolo, M. Karasalo, D. Kragic, X. Hu Contour Reconstruction using Recursive Smooth-
ing Splines - Experimental Validation to appear in Proceedings of IROS 2007, 2007 .
2. Arthur E. Bryson, Yu-Chi Ho Applied Optimal Control, Optimization estimation and control
Halsted Press, 1975 .
3. Andrew Jazwinski. Stochastic Processes and Filtering Theory Academic Press, 1970.
4. C.T Leondes Advances in Control Systems, vol 16 Academic Pr, 1965 .
5. S. Bittanti, G. Fronza and G. Guardabssi, Periodic Control: A Frequency Domain Approach,
IEEE Trans. Aut. Control, vol. 18, no. 1, 1973.
6. A.Z. Averbuch, A.B. Pevnyi, and V.A. Zheludev. Butterworth wavelet transforms derived
from discrete interpolatory splines: recursive implementation. Signal Processing, 81:2363–
2382, 2001.
7. M.W.M.G. Dissanayake, P. Newman, S. Clark, H.F. Durrant-Whyte, and M. Csorba. A solu-
tion to the simultaneous localization and map building (slam) problem. IEEE Transactions
on Robotics and Automation, 17(3):229 – 241, 2001.
8. Magnus Egerstedt and Clyde F. Martin.
Statistical estimates for generalized splines.
ESAIM:Control, Optimisation and Calculus of Variations, 9:553–562, 2003.
9. R. Frezza and G. Picci. “On Line Path Following by Recursive Spline Updating”. In Pro-
ceedings of the 34th Conference of Decision and Control, pages 367–393, 1995.
10. R. Frezza, S. Soatto, and G. Picci. “Visual Path Planning by Recursive Spline Updating”. In
Proceedings of the 36th Conference of Decision and Control, pages 367–393, 1997.
11. S. Isotani, A. de Albuquerque, M. Muratore, and N. Brasil Filho. A recursive spline-based
algorithm for sensor calibration design. Industrial Electronics, Control and Instrumentation,
3:1952–1954, 1994.
12. H. Kano, H. Fujioka, M. Egerstedt, and C.F Martin. Optimal smoothing spline curves and
contour synthesis. In Proceedings of the 16th IFAC World Congress, July 2005.
13. M. Karasalo, X. Hu, L. Johansson, and K. Johansson. “Multi-Robot Terrain Servoing with
Proximity Sensors”. Proc. Int. Conf. Robotics and Aut., 2005, 367–393, 2005.
14. C. F. Martin and J. Smith. Approximation, interpolation and sampling. differential geometry,
the interface between pure and applied mathematics. Contemp. Math., 68:227–252, 1987.
15. C. F. Martin S. Sun, M. Egerstedt. Control theoretic smoothing splines. IEEE Transactions
on Automatic Control, 45:2271–2279, 2000.
16. Y. Zhou, W. Dayawansa, and C.F. Martin. Control theoretic smoothing splines are approxi-
mate linear ﬁlters. Communications in Information and Systems, 4:253–272, 2004.
17. H. Perez and S. Devasia. Optimal output-transitions for linear systems. Automatica, 39(2),
181–192, 2003.
18. A. Ferrante, G. Marro,and L. Ntogramatzidis. A parameterization of the solutions of the
ﬁnite-horizon LQ problem with general cost and boundary condition. Automatica, 41(8),
1359–1366, 2005.
19. M. Egerstedt C. F. Martin, S. Sun. Optimal control, statistics and path planning. Math.
Comput. Modelling, 33:237–253, 2001.
20. M. Karasalo, X. Hu, and C.F. Martin. Localization and Mapping using Recursive Smoothing
Splines To appear in Proc of ECC 2007, 2007.

Role of LQ Decomposition in Subspace Identiﬁcation
Methods⋆
Tohru Katayama
Faculty of Culture and Information Science,
Doshisha University KyoTanabe, Kyoto 610-0394, Japan
tokataya@mail.doshisha.ac.jp
Summary. We revisit the deterministic subspace identiﬁcation methods for discrete-time LTI
systems, and show that each column vector of the L-matrix of the LQ decomposition in MOESP
and N4SID methods is a pair of input-output vectors formed by linear combinations of given
input-output data. Thus, under the assumption that the input is persistently exciting (PE) of sufﬁ-
cient order, we can easily compute zero-input and zero-state responses by appropriately dividing
given input-output data into past and future in the LQ decomposition. This reveals the role of
the LQ decomposition in subspace identiﬁcation methods. Also, a related issue in stochastic
realization is brieﬂy discussed in Appendix.
1
Introduction
It is well known that the LQ decomposition (transpose of the QR decomposition), to-
gether with the singular value decomposition (SVD), has played a key role in subspace
system identiﬁcation methods [9,12,13,14,15]. The LQ decomposition has extensively
been used as a numerical tool of pre-processing or reducing given data without loss
of information. In [10], we have also employed the LQ decomposition for performing
a preliminary orthogonal decomposition of the output process into deterministic and
stochastic components, for which realization algorithms have been developed. In this
paper, we clarify a system theoretic meaning of the LQ decomposition in subspace iden-
tiﬁcation methods, motivated by the fundamental lemma due to Markovsky et al. [8].
Consider a discrete-time LTI system described by
x(t + 1) = Ax(t) + Bu(t)
(1a)
y(t) = Cx(t) + Du(t),
t = 0, 1, · · ·
(1b)
where x ∈Rn is the state vector, u ∈Rm the control input, y ∈Rp the output vector,
and A ∈Rn×n, B ∈Rn×m, C ∈Rp×n, D ∈Rp×m are constant matrices. In the
following, we assume that (A, B) is reachable and (C, A) is observable; in this case,
we say that (A, B, C) is minimal.
From (1), the transfer matrix is given by
G(z) = D + C(zI −A)−1B
(2)
⋆The earlier version of this paper was presented at the International Symposium on Mathemat-
ical Theory of Networks and Systems, Kyoto, July 2006.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 207–220, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

208
T. Katayama
and the impulse responses are
Gt =
8
D,
t = 0
CAt−1B,
t = 1, 2, · · ·
(3)
where {Gt, t = 0, 1, · · · } are also called the Markov parameters. We see that given
(A, B, C, D), the transfer matrix and impulse response matrices are uniquely deter-
mined by (2) and (3), respectively; but the converse is not true.
The subspace identiﬁcation problem considered is to identify the system matrices
(A, B, C, D), up to similarity transformations, based on the given input-output data
{u(t), y(t), t = 0, 1, · · · , N −1}.
2
State-Input-Output Matrix Equation
Suppose that k > n. According to [9], we deﬁne the stacked vectors as
yk(t) :=
⎡
⎢⎢⎢⎣
y(t)
y(t + 1)
...
y(t + k −1)
⎤
⎥⎥⎥⎦∈Rkp,
uk(t) :=
⎡
⎢⎢⎢⎣
u(t)
u(t + 1)
...
u(t + k −1)
⎤
⎥⎥⎥⎦∈Rkm
Then, the stacked vectors satisfy the following augmented equation
yk(t) = Okx(t) + Tkuk(t)
(4)
where Ok and Tk are respectively the extended observability matrix and the block lower
triangular Toeplitz matrix deﬁned by
Ok =
⎡
⎢⎢⎢⎣
C
CA
...
CAk−1
⎤
⎥⎥⎥⎦∈Rkp×n,
Tk =
⎡
⎢⎢⎢⎣
D
0
CB
D
...
...
...
CAk−2B · · · CB
D
⎤
⎥⎥⎥⎦∈Rkp×km
In terms of input-output data, we further deﬁne block Hankel matrices
U0|k−1 =
⎡
⎢⎢⎢⎣
u(0)
u(1) · · ·
u(N −1)
u(1)
u(2) · · ·
u(N)
...
...
...
...
u(k −1) u(k) · · · u(k + N −2)
⎤
⎥⎥⎥⎦∈Rkm×N
and
Y0|k−1 =
⎡
⎢⎢⎢⎣
y(0)
y(1) · · ·
y(N −1)
y(1)
y(2) · · ·
y(N)
...
...
...
...
y(k −1) y(k) · · · y(k + N −2)
⎤
⎥⎥⎥⎦∈Rkp×N

Role of LQ Decomposition in Subspace Identiﬁcation Methods
209
Since
U0|k−1 = [uk(0) uk(1) · · · uk(N −1)]
Y0|k−1 = [yk(0) yk(1) · · · yk(N −1)]
it follows from (4) that
Y0|k−1 = OkX0 + TkU0|k−1
(5)
where X0 = [x(0) x(1) · · · x(N −1)] ∈Rn×N is the initial state matrix. We see that
(5) is the state-input-output matrix equation relating the initial state X0 and the inputs
U0|k−1 to the output Y0|k−1. In the following, the ﬁrst term in the right-hand side of (5)
is called the zero-input response, while the second term the zero-state response.
Post-multiplying (5) by a vector ζ ∈RN, we get
Y0|k−1ζ = OkX0ζ + TkU0|k−1ζ
Thus, referring to (4), we have the following lemma [8].
Lemma 1. (Principle of superposition)
For any ζ ∈RN, it can be shown that
U0|k−1ζ ∈Rkm, Y0|k−1ζ ∈Rkp and X0ζ ∈Rn, linear combinations of the input
vectors, output vectors and state vectors, are a pair of input-output vectors and the
unknown initial state vector satisfying (4), respectively.
□
3
MOESP Method
Suppose that the LQ decomposition used in the MOESP method be given by [14,13]
'
U0|k−1
Y0|k−1
(
=
'
L11
0
L21 L22
( '
QT
1
QT
2
(
(6)
where Q1 ∈RN×km, Q2 ∈RN×kp are orthogonal, i.e. QT
1 Q1 = Ikm, QT
2 Q2 = Ikp,
QT
1 Q2 = 0km×kp, and L11 ∈Rkm×km, L22 ∈Rkp×kp are lower triangular. Then, we
have the following result, clarifying a system theoretic meaning of L-matrix in the LQ
decomposition of (6).
Lemma 2. ([6]) Suppose that for the deterministic system of (1), the following condi-
tions are satisﬁed.
(i) (A, B, C) are minimal.
(ii) The input u satisﬁes the PE condition of order k, i.e. rank(U0|k−1) = km.
(iii) The input satisﬁes rank
' U0|k−1
X0
(
= mk + n, implying that the input-output data
are obtained from an open-loop experiment.
Then it follows that
rank
' U0|k−1
Y0|k−1
(
= mk + n
(7)
Moreover, each column of L-matrix is a pair of input-output vectors of length k gen-
erated from given input-output data. In particular, each column vector of L22 is a
zero-input response of length k, so that rank(L22) = n.

210
T. Katayama
Proof. Equation (7) is well known [9]. Rewriting (6), we have
' L11
0
L21 L22
(
=
'U0|k−1
Y0|k−1
(
[Q1 Q2]
(8)
We see from Lemma 1 that column vectors of [L11 0] and [L21 L22] in the left-hand
side of the above equation are respectively a linear combination of column vectors of
U0|k−1 and Y0|k−1, implying that each column vector of the L-matrix is an input-output
pair generated by column vectors of given U0|k−1 and Y0|k−1. It also follows that each
column vector of L22 is a zero-input response, since L12 is a zero matrix. It follows
from (7) that the left-hand side of (8) has rank km + n and rank(L11) = km, so that
we have dim Im(L22) = n, the number of independent zero-input responses. This
completes a proof of lemma.
□
From (5) and (6), it follows that
L21QT
1 + L22QT
2 = OkX0 + TkU0|k−1
(9)
It should be noted that the two terms in the left-hand side are orthogonal, while those
in the right-hand side are not. But, we see that the right-hand side is a direct sum
decomposition of Y0|k−1 by the assumption (iii) in Lemma 2. Noting that U0|k−1 =
L11QT
1 , and post-multiplying (9) by Q1 and Q2 respectively yield
L21 = OkX0Q1 + TkL11
(10a)
L22 = OkX0Q2
(10b)
where X0Q1 ∈Rn×km and X0Q2 ∈Rn×kp are unknown initial state matrices, so
that the ﬁrst term in the right hand side of (10a) is the zero-input response with the
initial state X0Q1, whereas the second term is the zero-state response, and the term in
the left-hand side is the corresponding output matrix. We see that (10b) is the zero-
input response with the initial state X0Q2, so that Im(L22) = Im(Ok) holds since
rank(X0Q2) = n. This also shows that rank(L22) = n, since the system is assumed
to be minimal.
We easily observe that the LQ decomposition gives the state-input-output equations
(10) with column dimensions smaller than those of the original state-input-output equa-
tion (5). This implies that the LQ decomposition (6) plays a role of data compression
as in the least-squares methods.
Let the SVD of L22 be given by
L22 = [U1 U2]
'Σ 0
0 0
( 'V T
1
V T
2
(
,
Σ = diag(σ1, · · · , σn)
(11)
where U1 ∈Rkp×n and U2 ∈Rkp×(kp−n). Then, we can recover the extended observ-
ability matrix as Ok = U1Σ1/2. By using the shift invariant property of Ok, we can
readily ﬁnd the system matrices A and C.
Moreover, we see from (10a) that if the effect of the zero-input response therein is
removed, then it will be possible to recover the zero-state response TkL11, and hence

Role of LQ Decomposition in Subspace Identiﬁcation Methods
211
the impulse response matrix Tk. In order to eliminate the term of zero-input response,
we pre-multiply (10a) by U T
2 ∈Rkp×(kp−n) to get
U T
2 L21 = U T
2 Tk(B, D)L11
(12)
where U T
2 Ok = U T
2 U1Σ1/2 = 0 is used. Since Tk(B, D) is linear with respect to
(B, D) given Ok, we can estimate (B, D) from (12) by using the least-squares method;
see the MOESP method [14].
4
N4SID Method
We now consider the LQ decomposition employed in the N4SID method. Let k > n.
Deﬁne Up := U0|k−1, Yp := Y0|k−1, Xp := X0 and Uf := Uk|2k−1, Yf := Yk|2k−1,
Xf := Xk, where the subscripts p and f denote the past and future, respectively. We
also write Wp =
' Up
Yp
(
and Wf =
' Uf
Yf
(
.
We recall two state-input-output matrix equations
Yp = OkXp + TkUp
(13)
Yf = OkXf + TkUf
(14)
where Xi = [x(i) x(i + 1) · · · x(i + N −1)] with i = 0, k.
4.1
Zero-Input Responses
Consider the LQ decomposition used in [12,15], i.e.
⎡
⎢⎢⎣
Uf
Up
Yp
Yf
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
L11
0
0
0
L21 L22
0
0
L31 L32 L33
0
L41 L42 L43 L44
⎤
⎥⎥⎦
⎡
⎢⎢⎣
QT
1
QT
2
QT
3
QT
4
⎤
⎥⎥⎦
(15)
where Q1, Q2 ∈RN×km, Q3, Q4 ∈RN×kp are orthogonal. Since the L-matrix is
block lower triangular, we see that L11, L22 ∈Rkm×km, L33, L44 ∈Rkp×kp are lower
triangular, and that L12 = 0, L13 = 0, L14 = 0, L23 = 0, L24 = 0, L34 = 0.
From Lemma 2, each column of the L-matrix of (15) is a vector of input-output pair.
Thus we have the following result, an earlier version of which is given in [6].
Lemma 3. Suppose that for the deterministic system of (1), the following conditions
are satisﬁed.
(i) (A, B, C) is minimal.
(ii) The input u satisﬁes the PE condition of order 2k, i.e. rank(U0|2k−1) = 2km.
(iii) The condition rank
'
U0|2k−1
X0
(
= 2mk + n holds.

212
T. Katayama
Then, for the LQ decomposition of (15), it follows that
rank(L33) = n,
rank(L42) = n,
rank(L43) = n
rank[L42 L43] = n,
rank
'
L33
L43
(
= n
(16)
and that L44 = 0. Also, the following relations hold:
Ker
'L22
L32
(
⊂KerL42,
KerL33 ⊂KerL43
(17)
Proof. Since the system is minimal, and since the past input-outputs are zero (L24 = 0,
L34 = 0) and the future inputs are zero (L14 = 0), we see that the future outputs are
identically zero, i.e. L44 = 0. We prove the rank conditions of (16). It follows from
(13) and (15) that
Yp = OkXp + TkUp
Up = L21QT
1 + L22QT
2
Yp = L31QT
1 + L32QT
2 + L33QT
3
Post-multiplying three equations above by Q1, Q2, Q3 successively, we get
L31 = OkXpQ1 + TkL21
L32 = OkXpQ2 + TkL22
(18)
L33 = OkXpQ3
Since, by the assumption, XpQ3 has full rank, we see that each column vector of L33
is a zero-input response of length k and that Im(L33) = Im(Ok) holds. Thus we have
rank(L33) = n since Im(Ok) = n by the minimality.
Similarly, it follows from (14) and (15) that
Yf = OkXf + TkUf
Uf = L11QT
1
Yf = L41QT
1 + L42QT
2 + L43QT
3
Post-multiplying by three equations above by Q1, Q2, Q3 successively yields
L41 = OkXfQ1 + TkL11
L42 = OkXfQ2
(19)
L43 = OkXfQ3
so that [L42 L43] = OkXf[Q2 Q3]. Thus we ﬁnd that each column vector of L42, L43
is a zero-input response of length k. Moreover, the images of L42, L43, [L42 L43] coin-
cide with Im(Ok) if rank(Xf) = n. To prove this latter condition, we write from (1a)
x(k + i) = Akx(i) + Ckuk(i)

Role of LQ Decomposition in Subspace Identiﬁcation Methods
213
where Ck = [Ak−1B · · · AB B] is the reversed extended reachability matrix. Thus it
follows that
Xf = AkXp + CkUp,
k > n
Since rank(CkUp) = n and span(Xp) ∩span(Up) = {0}, we see that rank(Xf) ≥n.
But, by deﬁnition, rank(Xf) ≤n, so that we have rank(Xf) = n.
Moreover, combining (13), (14) and (15), we have the following equations
' Yp
Yf
(
= O2kXp + T2k
' Up
Uf
(
' Up
Uf
(
=
' L21
L11
(
QT
1 +
' L22
0
(
QT
2
' Yp
Yf
(
=
' L31
L41
(
QT
1 +
' L32
L42
(
QT
2 +
'L33
L43
(
QT
3
Similarly to the derivation of (19),
'
L31
L41
(
= O2kXpQ1 + T2k
'
L21
L11
(
' L32
L42
(
= O2kXpQ2 + T2k
' L22
0
(
(20)
'
L33
L43
(
= O2kXpQ3
Hence each column vector of
' L33
L43
(
is a zero-input response of length 2k with
Im
'
L33
L43
(
= Im(Ok). This completes a proof of (16). Moreover, the statement in
(17) is proved by noting that each column of L-matrix is a vector of input-output pair.
□
Since the images of L33, L42, L43, [L42 L43] coincide with Im(Ok), we can use any
one of these matrices, or a combination of them, to recover Im(Ok).
In the PO-MOESP [15], the following relations are used for obtaining the system
matrices A, B, C, D:
Im(Ok) = Im([L42 L43])
O⊥
k Tk(B, D)[L21 L22 L11] = O⊥
k [L31 L32 L41]
Though the above relations are derived via a different route, the validity of them are
easily seen from (18) and (19).
Also, in [10, 6], we have derived the ORT (orthogonal decomposition based) algo-
rithm that identiﬁes the systems subjected to both deterministic and stochastic inputs,
in which the deterministic subsystem is identiﬁed by using the following relations
Im(Ok) = Im(L42)
O⊥
k Tk(B, D)L11 = O⊥
k L41

214
T. Katayama
6
- t
0
yf
uf
up
yp
−1
−2
−3
−4
1
2
3
4
Fig. 1. Input-output response of an LTI system
4.2
Relation to Ho-Kalman’s Method
It is instructive to consider the diagram of Fig. 1 to introduce the Hankel operator used
in Ho-Kalman’s method [5]. Let up be the input that assumes non-zero values up to
time t = −1 and let uf be the future input which is ﬁxed to zero, i.e.
u = (up, uf) = ( · · · , u(−3), u(−2), u(−1), 0, 0, 0, · · · )
(21)
Applying the input u to a discrete-time LTI system, we observe the future outputs
yf(0), yf(1), · · · , where the past output yp is shown by the dotted line. For the input
sequence of (21), the future output is expressed as
yf(t) =
−1

i=−∞
Gt−iup(i) = CAtx(0),
t = 0, 1, · · ·
(22)
where x(0) = −1
i=−∞A−i−1Bu(i) is the initial state excited by the past inputs. Thus
we see that yf is a zero-input response.
Thus, by the discussion above, we see that between the past and future inputs-outputs
up, yp, uf, yf in Fig. 1 and the block matrices Lij of (15), there exists the following
correspondences:
up ∼L22,
yp ∼L32,
uf ∼L12 (= 0),
yf ∼L42
Hence, the ﬁrst k future free-responses of (22) can easily be computed by the LQ de-
composition from given input-output data, if the conditions (i)-(iii) in Lemma 3 are
satisﬁed.
4.3
State Vector and Zero-State Response
We now consider the state vector and the zero-state response of the LTI system. For
convenience, we rewrite (15) as
⎡
⎣
Uf
Wp
Yf
⎤
⎦=
⎡
⎣
R11
0
R21 R22
R31 R32
⎤
⎦

QT
1
QT
2:3

(23)

Role of LQ Decomposition in Subspace Identiﬁcation Methods
215
where we see that R11 = L11, R21 =
'L21
L31
(
, R22 =
'L22
0
L32 L33
(
, R31 = L41,
R32 = [L42 L43] and Q2:3 = [Q2 Q3]. Since R22QT
2:3 = Wp −R21QT
1 , there exists
a matrix Ξ ∈Rk(p+m)×N such that
QT
2:3 = R†
22(Wp −R21QT
1 ) + (Ik(p+m) −R†
22R22)Ξ
where R†
22 is the pseudo-inverse. It follows from (17) that Ker(R22) ⊂Ker(R32).
Also, since Π := Ik(p+m) −R†
22R22 is the orthogonal projection onto Ker(R22), we
ﬁnd that R32

Ik(p+m) −R†
22R22

= 0. Thus, from (23),
Yf = R32R†
22Wp + (R31 −R32R†
22R21)R−1
11 Uf
(24)
where span(Uf) ∩span(Wp) = {0} since the input-output data are obtained from an
open-loop experiment; see the condition (iii) of Lemma 3. It thus follows that the right-
hand side of (24) is a direct sum of the oblique projections of Yf onto span(Wp) along
span(Uf) and of Yf onto span(Uf) along span(Wp). Since span(Xf) ⊂span(Wp)
[9,6], comparing the right-hand sides of (14) and (24) yields
OkXf = R32R†
22Wp
(25)
Tk(B, D)Uf = (R31 −R32R†
22R21)R−1
11 Uf
(26)
We see that (25) and (26) are the zero-input and zero-state responses, respectively.
Let the SVD of R32R†
22 in (25) be given by
R32R†
22 = [U1 U2]
'
Σ1 0
0 0
( 
V T
1
V T
2

= U1Σ1V T
1
Let the extended observability matrix be Ok = U1Σ1/2
1
. Then the state vector is given
by
Xf = O†
kR32R†
22Wp = Σ1/2
1
V T
1 Wp
which can be employed in the direct N4SID method [13]. Also, since Uf has full rank,
it follows from (26) that
Tk(B, D) = (R31 −R32R†
22R21)R−1
11
(27)
so that the ﬁrst k impulse responses G0:k−1 := col [G0 G1 · · · Gk−1] are given by the
ﬁrst block column of the right-hand member of (27), where col(·) denotes the stacked
block matrix. In [8], the impulse responses are derived by using a slightly different
idea.
4.4
Zero-State Response
We consider another method of computing zero-state responses of the system based
on a related LQ decomposition. Rearranging the data matrices, we consider the block
matrix

216
T. Katayama
' Wp
Wf
(
∈R2k(m+p)×N
which was employed in [9] to show that the state vector Xf is a basis of the intersection
Wp ∩Wf of the past and future subspaces.
Consider the following LQ decomposition
' Wp
Wf
(
=
⎡
⎢⎢⎣
Up
Yp
Uf
Yf
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
L11
0
0
0
L21 L22
0
0
L31 L32 L33
0
L41 L42 L43 L44
⎤
⎥⎥⎦
⎡
⎢⎢⎢⎣
Q
T
1
Q
T
2
Q
T
3
Q
T
4
⎤
⎥⎥⎥⎦
(28)
where Q1, Q3 ∈RN×km, Q2, Q4 ∈RN×kp are orthogonal, and L11, L33 ∈Rkm×km,
L22, L44 ∈Rkp×kp are lower triangular.
We see from (28) that
YfQ3 = L43,
UfQ3 = L33
(29)
On the other hand, post-multiplying (14) by Q3 yields
YfQ3 = OkXfQ3 + TkUfQ3
(30)
Since the system is minimal and since the past input-output pair is zero, i.e. L13 = 0,
L23 = 0, we see that each column vector in
' L33
L43
(
is a future input-output pair with
the zero initial states, i.e. XfQ3 = 0 in (30). Hence, from (29) and (30), we have
L43 = TkL33, so that
Tk(B, D) = L43L
†
33
(31)
This is another representation of the block Toeplitz matrix of (27).
5
Conclusions
In this paper, we have clariﬁed the special role of LQ decomposition in subspace identi-
ﬁcation methods. In particular, we have shown that each column vector of the L-matrix
of LQ decomposition is a pair of input-output vectors generated by a linear combination
of given input-output data. Thus it reduces the given data so that the state-input-output
matrix equation with a smaller dimension than the original one is derived.
It will be of interest to study the stochastic realization methods due to Faurre [4],
Akaike [1] and the extension by Desai et al. [3] from the point of view of LQ decom-
position. A preliminary analysis can be found in Appendix.
Acknowledgments
I would like to express my sincere thanks to Giorgio Picci who taught me several key
issues in stochastic realization theory. I have enjoyed our fruitful collaboration over

Role of LQ Decomposition in Subspace Identiﬁcation Methods
217
ten years for solving some stochastic realization problems in the presence of exogenous
inputs and developing novel subspace identiﬁcation methods, resulting in joint publi-
cation of several journal and conference papers. I am also grateful to Hideyuki Tanaka
for his valuable comments on this paper.
References
1. H. Akaike (1975), “Markovian representation of stochastic processes by canonical vari-
ables,” SIAM J. Control, vol. 13, no. 1, pp. 162–173.
2. K. S. Arun and S. Y. Kung (1990), “Balanced approximation of stochastic systems,” SIAM
Journal on Matrix Analysis and Applications, vol. 11, no. 1, pp. 42–68.
3. U. B. Desai, D. Pal and R. D. Kirkpatrick (1985), “A realization approach to stochastic model
reduction,” Int. J. Control, vol. 42, no. 4, pp. 821–838.
4. P. Faurre (1976), “Stochastic realization algorithms,” In System Identiﬁcation: Advances and
Case Studies (R. Mehra and D. Lainiotis, eds.), Academic, pp. 1–25.
5. R. E. Kalman, P. L. Falb and M. A. Arbib (1969), Topics in Mathematical System Theory,
McGraw-Hill.
6. T. Katayama (2005), Subspace Methods for System Identiﬁcation, Springer.
7. A. Lindquist and G. Picci (1996), “Canonical correlation analysis, approximate covariance
extension, and identiﬁcation of stationary time series,” Automatica, vol. 32, no. 5, pp. 709–
733.
8. I. Markovsky, J. C. Willems, P. Rapisarda and B. L. M. De Moor (2005), “Algorithms for
deterministic balanced subspace identiﬁcation,” Automatica, vol. 41, no. 5, pp. 755–766.
9. M. Moonen, B. De Moor, L. Vandenberghe and J. Vandewalle (1989), “On- and off-line
identiﬁcation of linear state-space models,” Int. J. Control, vol. 49, no. 1, pp. 219–232.
10. G. Picci and T. Katayama (1996), “Stochastic realization with exogenous inputs and ‘sub-
space methods’ identiﬁcation,” Signal Processing, vol. 52, no. 2, pp. 145–160.
11. H. Tanaka and T. Katayama (2006), “A stochastic realization algorithm via block LQ decom-
position in Hilbert space,” Automatica, vol. 42, no. 5, pp. 741–746.
12. P. Van Overschee and B. De Moor (1994), “N4SID - Subspace algorithms for the identiﬁca-
tion of combined deterministic - stochastic systems,” Automatica, vol. 30, no. 1, pp. 75–93.
13. P. Van Overschee and B. De Moor (1996), Subspace Identiﬁcation for Linear Systems,
Kluwer Academic.
14. M. Verhaegen and P. Dewilde (1992), “Subspace model identiﬁcation, Part 1: The output-
error state-space model identiﬁcation class of algorithms & Part 2: Analysis of the elemen-
tary output-error state space model identiﬁcation algorithm,” Int. J. Control, vol. 56, no. 5,
pp. 1187–1210 & pp. 1211–1241.
15. M. Verhaegen (1994), “Identiﬁcation of the deterministic part of MIMO state space models
given in innovations form from input-output data,” Automatica, vol. 30, no. 1, pp. 61–74.
Appendix: LQ Decomposition in Stochastic Realization
The stochastic realization is to construct Markov models from given covariance matri-
ces, or inﬁnite sequence of data [1,4]. In this appendix, we brieﬂy discuss a role of LQ
decomposition in stochastic realization based on Tanaka and Katayama [11].

218
T. Katayama
A.1 Stochastic Realization
Suppose that {y(t), t = 0, ±1, · · · } is a regular full rank p-dimensional stationary
process. We assume that the mean of y is zero and the covariance matrix is given by
Λ(l) = E{y(t + l)yT(t)},
l = 0, ±1, · · ·
(32)
Suppose that the covariance matrices satisfy the summability condition
∞

l=−∞
∥Λ(l)∥< ∞
(33)
Then, the spectral density matrix of y is deﬁned by
Φ(z) =
∞

l=−∞
Λ(l)z−l
(34)
where it is assumed that the spectral density matrix is positive deﬁnite on the unit circle,
i.e., Φ(z) > 0, |z| = 1.
Let t be the present time. We deﬁne inﬁnite dimensional future and past vectors
f(t) :=
⎡
⎢⎢⎢⎣
y(t)
y(t + 1)
...
⎤
⎥⎥⎥⎦,
p(t) :=
⎡
⎢⎢⎢⎣
y(t −1)
y(t −2)
...
⎤
⎥⎥⎥⎦
Then, the cross-covariance matrix of the future and past is given by
H = E{f(t)pT(t)} =
⎡
⎢⎢⎢⎣
Λ(1) Λ(2) Λ(3) · · ·
Λ(2) Λ(3) Λ(4) · · ·
Λ(3) Λ(4) Λ(5) · · ·
...
...
...
...
⎤
⎥⎥⎥⎦
and the covariance matrices of the future and the past are respectively given by
T+ = E{f(t)f T(t)} =
⎡
⎢⎢⎢⎣
Λ(0) ΛT(1) ΛT(2) · · ·
Λ(1) Λ(0) ΛT(1) · · ·
Λ(2) Λ(1)
Λ(0) · · ·
...
...
...
...
⎤
⎥⎥⎥⎦
and
T−= E{p(t)pT(t)} =
⎡
⎢⎢⎢⎣
Λ(0)
Λ(1) Λ(2) · · ·
ΛT(1) Λ(0) Λ(1) · · ·
ΛT(2) ΛT(1) Λ(0) · · ·
...
...
...
...
⎤
⎥⎥⎥⎦

Role of LQ Decomposition in Subspace Identiﬁcation Methods
219
It should be noted that H is an inﬁnite block Hankel matrix, and T± are inﬁnite block
Toeplitz matrices, where we assume that T+ (or equivalently T−) is positive deﬁnite.
As in [3,7], we compute the SVD of the normalized block Hankel matrix
T −1/2
+
HT −T/2
−
= UΣV T
(35)
and deﬁne the extended observability and reachability matrices as
O = T 1/2
+ UΣ1/2,
C = Σ1/2V TT T/2
−
It therefore follows that the block Hankel has a canonical decomposition H = OC.
Moreover, in terms of some A ∈Rn×n, C ∈Rp×n, C ∈Rp×n, we can express O and
C as
O =
⎡
⎢⎣
C
CA
...
⎤
⎥⎦,
C = [C
T AC
T · · · ]
so that the covariance matrix has a decomposition Λ(k) = CAk−1C
T, k = 1, 2, · · · .
We now deﬁne a state vector as ˆx(t) = CT −1
−p(t). Thus from [3, 7], we can show
that the output process y has a stochastic realization of the form
' ˆx(t + 1)
y(t)
(
=
' A K
C I
( ' ˆx(t)
e(t)
(
(36)
where e is the innovation process deﬁned by e(t) = y(t) −Cˆx(t). We can show that
the covariance matrices of ˆx and e are respectively given by
E{ˆx(t)ˆxT(t)} = C(T−)−1CT = Σ
E{e(t)eT(t)} = Λ(0) −CΣCT
where Σ is a stabilizing solution of the Riccati equation of the form
Σ = AΣAT + (C
T −AΣCT)(Λ(0) −CΣCT)−1(C −CΣAT)
(37)
A.2 LQ Decomposition
Deﬁne the inﬁnite matrices as
Y −
t
=
⎡
⎢⎣
...
...
...
y(t −2) y(t −1) · · ·
y(t −1)
y(t)
· · ·
⎤
⎥⎦,
E−
t =
⎡
⎢⎣
...
...
...
e(t −2) e(t −1) · · ·
e(t −1)
e(t)
· · ·
⎤
⎥⎦
Y +
t
=
⎡
⎢⎣
y(t)
y(t + 1) · · ·
y(t + 1) y(t + 2) · · ·
...
...
...
⎤
⎥⎦,
E+
t =
⎡
⎢⎣
e(t)
e(t + 1) · · ·
e(t + 1) e(t + 2) · · ·
...
...
...
⎤
⎥⎦

220
T. Katayama
It has been shown in [11] that the LQ decomposition yields
'
Y −
t
Y +
t
(
=
'
L−0
S L+
( '
E−
t
E+
t
(
(38)
where
L−=
⎡
⎢⎢⎢⎣
...
· · · L0
· · · L1 L0
· · · L2 L1 L0
⎤
⎥⎥⎥⎦, S =
⎡
⎢⎢⎢⎣
· · · L3 L2 L1
· · · L4 L3 L2
· · · L5 L4 L3
...
...
...
...
⎤
⎥⎥⎥⎦, L+ =
⎡
⎢⎢⎢⎣
L0
L1 L0
L2 L1 L0
...
...
... ...
⎤
⎥⎥⎥⎦
and where L0 = Ip, Lj = CAj−1K, j = 1, 2, · · ·.
Rearranging block matrices in (38) yields
'
E+
t
Y +
t
(
=
'
I
0
L+ S
( '
E+
t
E−
t
(
(39)
where I = block-diag(I, I, · · · ). We can easily see a similarity between the decompo-
sition of (39) and the LQ decomposition of (6). Also, it follows from (39) that
Y +
t
= SE−
t + L+E+
t
(40)
Since S in (39) is formed by zero-input responses, we see that the ﬁrst term in the
right-hand side of the above equation is the zero-input response and the second term the
zero-state response.
Moreover, the ﬁrst term of the right-hand side of (40) is expressed as [11]
SE−
t = ˇS ˇE−
t = O[ˆx(t) ˆx(t + 1) · · · ] = OXt
where
ˇS =
⎡
⎢⎢⎢⎣
L1 L2 L3 · · ·
L2 L3 L4 · · ·
L3 L4 L5 · · ·
...
...
... ...
⎤
⎥⎥⎥⎦,
ˇE−
t =
⎡
⎢⎣
e(t −1)
e(t)
e(t + 1) · · ·
e(t −2) e(t −1)
e(t)
· · ·
...
...
...
...
⎤
⎥⎦
Thus, the extended observability matrix O can be determined by exploiting the fact that
Im(O) = Im(S). In fact, in [11], the following decomposition is obtained:
ˇS = OCK,
CK = [K AK · · · ]
so that we have Xt = CK ˇE−
t . Thus the zero-input response of the stochastic system is
expressed as OXt = OCK ˇE−
t , so that (40) is rewritten as
Y +
t
= OXt + L+E+
t
(41)
This is a stochastic analog of (5), since L+ is block Toeplitz and E+
t
is the future
stochastic input; see also Arun and Kung [2] for a scalar case.

Canonical Operators on Graphs
Matthias Kawski⋆and Thomas J. Taylor⋆⋆
Arizona State University
kawski@asu.edu
tom.taylor@asu.edu
Dedicated to our friend and mentor Giorgio Picci on the occasion of his 65th birthday
Summary. This paper studies canonical operators on ﬁnite graphs, with the aim of characterizing
the toolbox of linear feedback laws available to control networked dynamical systems.
1
Introduction
There is widespread current interest in distributed control of networked systems, e.g.
[4], [5], [6], [12], [13], [15]. Much of the work to date centered on linear control laws,
and has taken advantage the last twenty years of development in spectral graph theory.
In particular the graph Laplacian, in various incarnations, has seen use as a stabilizing
feedback. The property of the Laplacian used in these works has been essentially the
fact that it is the generator of a reversible continuous time ergodic Markov chain: it has
one zero eigenvalue and all others are strictly positive. The study we wish to propose is
broader. We wish to ask which linear feedback laws are possible for actors which must
communicate on a (possibly directed) network.
The coarse grain answer to this question is: those laws which respect the network
structure. The present work, in initiating this study, precisely deﬁnes and characterizes
in some detail classes of canonical (di)graph operators constructed from the incidence
relations. These ideas are implicit or glossed over in a number of earlier publications;
we felt that there will be those readers who, like us, beneﬁt from the careful codiﬁcation
of properties. Our methods have a pronounced geometric and functorial ﬂavor. There is
a literature which has also taken this perspective; see e.g. [8], [11], [19]. We then turn
to characterizing the graph Laplacian as constructed from differences of these canoni-
cal operators using basic linear algebraic operations. This section is remarkable in that
it touches only tangentially the wide and profound literature of spectral graph theory.
However, building on our foundation of properties of the fundamental operators and
pursuing analogies with algebraic topological and differential geometric constructs, we
are able to characterize operators previously little considered in the spectral graph the-
ory literature. These include the Laplace-deRham operator on the edge space and Dirac
operators. We show that these contain much the same graph theoretic information as
the Laplacian.
⋆M. Kawski was supported in part by NSF Grant DMS 05-09039.
⋆⋆T. Taylor was supported in part by the EU project RECSYS.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 221–237, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

222
M. Kawski and T.J. Taylor
The next section discusses the properties of Laplacians on weighted (di)graphs, and
bears considerable relationship, and some differences in perspective, with constructions
of Bensoussan and Menaldi [1] and Chung [3]. We include this section because we are
able to turn this machinery to a geometric context for the Laplacian of Chung [3]. Early
on this operator had mystiﬁed us and we hope that this section may provide an entry
point for other readers. From these we turn to characterize the properties of operators
based on other combinations of the canonical operators. In the former instance, we
consider properties related to the undirected incidence operator. Here we note the prior
contribution of Van Nuffelen [18] and Grossman et al [9]. Lastly we consider complex
combinations of the canonical operators. There is a mathematical physics literature
which touches such objects, but there the operators may be considered Laplacians on
weighted graphs with complex weights [14], [16], [17]. In our situation this does not
seem to be the case. In these latter sections, some of our results recapitulate the litera-
ture, and in some instances we have not yet been able to discover close analogs of our
results. The literature in these areas seems to be relatively poorly developed, perhaps
there are new results. We ask indulgence of the knowledgeable reader to direct us to
related publications.
2
Graphs
2.1
The Geometry of Graphs and Digraphs
In this section we will make contact with graph theory, and describe our somewhat
ideosyncratic perspective on the geometry of these objects. The objects of spectral
graph theory tend to be described in terms of one of several matrices; as our perspec-
tive has been formed by contact with functorial constructions in differential geometry,
operator theory and probability, our discussion will bear a marked resemblance to these
areas of mathematics.
Deﬁnition 1
1. A digraph (or directed graph) is a pair G = (V, E) where V is a ﬁnite set called
the vertex set and E is a subset of V × V called the edge set.
2. A graph is a pair G = (V, E) where V is a ﬁnite set and E is a subset of V ⊙
V , where ⊙denotes the symmetric cartesian product; e.g. V ⊙V consists of all
unordered pairs of elements of V , i.e. equivalence classes of the relation (u, v) ∼
(v, u) on V × V .
3. A multi-graph is a pair G = (V, E) where V is a ﬁnite set and E is a subset of the
disjoint union of an ﬁnite number of copies of V ⊙V .
Note that we allow self edges unless otherwise stated. A more standard and visual
set of deﬁnitions are: a digraph is a set of points in which some pairs of points are
connected by arrows, while a graph is a set of points connected by lines. The order
of a graph (resp. digraph) is the number of vertices, |V |. The size of a graph (resp.
digraph) is the number of edges, |E|. A digraph is speciﬁed by its transition matrix
M(G), which is a |V | × |V | binary-valued matrix in which the entries mi,j(G) = 1
iff (vi, vj) ∈E. The out-degree of a vertex v ∈V of a digraph is the cardinality

Canonical Operators on Graphs
223
do(v) = |{e ∈E : ∃u ∈V s.t. e = vu}|, the in-degree is the cardinality di(v) =
|{e ∈E : ∃u ∈V s.t. e = uv}| and the degree of v is d(v) = do(v) + di(v). The de-
grees of the digraph are deﬁned as di(G) = maxv∈V di(v), do(G) = maxv∈V do(v),
d(G) = maxv∈V (di(v) + do(v)). For a (multi)graph there is only one kind of edge,
so only one kind of order. A symmetric transition matrix M(G) speciﬁes a digraph
in which every edge is doubled by an edge in the opposite direction, the same data
also speciﬁes a graph subject to the understanding that (u, v) ∼(v, u). The forgetful
morphism Φ maps a digraph G = (V, E) to the graph ˜G = (V, ˜E) of the same order
in which each edge e = (u, v) ∈E ⊂V × V is mapped to its equivalence class
[u, v] ∈V ⊙V .
Associated to each digraph are a canonical pair of mappings,
σ, τ : E →V,
the source map and the target map. To be precise:
Deﬁnition 2
1. The source map σ : E →V is deﬁned by σ ((u, v)) = u, for (u, v) ∈E.
2. The target map τ : E →V is deﬁned by τ ((u, v)) = v, for (u, v) ∈E.
The diagram that describes this is:
E
σ

τ







V
V
In the same way, associated to each graph is a canonical map, the incidence map:
Deﬁnition 3. The incidence map of a graph is ι : E →2V deﬁned by ι([u, v]) =
{u, v} ⊂V .
Given two digraphs (resp. graphs) G = (V, E) and H = (U, F) a digraph homomor-
phism (resp. graph homomorphism) φ : G →H is a pair of maps φV : V →U and
φE : E →F such that the source and target maps (resp. incidence map) commute
with φ: σφE(e) = φV (σ(e)) and τφE(e) = φV (τ(e)) (resp. ιφE(e) = φV (ι(e))).
A digraph homomorphism is surjective if both φV and φE are surjective, and injec-
tive if both φV and φE are injective. A digraph homomorphism is vertex surjective
(resp. vertex injective, resp. edge surjective, resp. edge injective) in case that φV is
surjective (resp. φV is injective, resp. φE is surjective, φE is injective). A forgetful
homomorphism of digraphs φ : G →H is a homomorphism φ : ΦG →ΦH of the
associated graphs. A forgetful homomorphism maps edges to edges without specifying
their direction.
We can use homomorphismsto capture properties of (di)graphs in terms of properties
of simpler (di)graphs. Most important of these simpler (di)graphs are line segments and
circles.

224
M. Kawski and T.J. Taylor
Deﬁnition 4
•
The line segment In is a digraph (resp. graph) in which the vertex set is the ﬁnite set
of integers {1, 2, · · · , n}, and the edges are the pairs of adjacent integers {(i, i+1) :
i = 1, · · · , n −1} in increasing order, respectively without order.
•
A circle is a digraph (resp. graph) in which the vertex set is Zk for some k, and in
which the edge set is the pairs of adjacent integers mod k in increasing order mod
k, resp. the pairs of adjacent integers mod k without order.
A ﬁnite path in a graph G is a forgetful homomorphism φ : Ik →G of a line segment
into G, i.e. a sequence {v1, v2, . . . , vk} in V such that ∀i, vivi+1 ∈E or vi+1vi ∈E;
edges of the former type are called sense and the latter type are called antisense. A di-
rected path is a homomorphism of I into G; in a directed path every edge is sense. The
ﬁrst and last vertices of a path are called the starting vertex and ending vertex, respec-
tively. We call a path vertex which is not starting or ending is called an interior vertex.
Recall from the theory of Markov chains that a directed graph is called irreducible if
for every ordered pair (u, v) ∈V × V there is a directed path for which u is the start-
ing point and v is the endpoint. For digraphs irreducible implies only one connected
component, but the converse is not true. We will call a vertex v such that di(v) = 0
(resp. do(v) = 0) germinal (resp. terminal) (more commonly these are called source
and sink). A graph has no germinal or terminal verticies; in this case irreducible is
equivalent to connected.
2.2
Operator Theory on Graphs and Digraphs
It is common to consider a pair of vector spaces associated to a graph;
Deﬁnition 5
1. The vertex space LV is the free linear span of V , i.e. the vector space of all real
(resp. complex) valued functions deﬁned on V .
2. The edge space LE is the free linear span of E, i.e.the vector space of all real (resp.
complex) valued functions deﬁned on E.
3. If W is a subset of V or E we denote its free linear space by LW .
4. The support of a function f ∈LV (resp. g ∈LE) is the subset supp(f) = {v ∈
V : f(v) ̸= 0} (resp. supp(g) = {e ∈E : g(e) ̸= 0}).
For W ⊂V , we will regard LW as a subset of LV by use of the convention that
functions in LW are extended to all of V by zero. For F ⊂E, LF ⊂LE. Likewise if
supp(f) = W then f ∈LW and if supp(g) = F then g ∈LF .
Deﬁnition 6. Given the constructions above, there are canonically deﬁned linear map-
pings, the source and target operators, obtained as the pullback of the source and tar-
get maps. Namely, we may deﬁne linear maps S, T : LV →LE by Sf = f ◦σ and
Tf = f ◦τ. In other words , Sf(e) = f(e−) and Tf(e) = f(e+). where we introduce
the notation e+ = τ(e) and e−= σ(e).

Canonical Operators on Graphs
225
Of course, to do computations with speciﬁc examples of these transformations it is
sometimes useful to express them as matrices. (However, we will avoid doing so for
the present in order to emphasize the underlying geometric structures).
We will need to bring into sharper focus certain types of localization of E over V .
Each edge of E has a unique source. If v is not terminal, it is the source of an edge
of E. Thus for every vertex, the set valued mapping σ−1 : V →2E may be regarded
as assigning v to the subset Eσ
v = σ−1{v} ⊂E, which is the empty subset if v is a
terminal vertex. This association may be viewed as a generalized localization of points
of E over V (in that Eσ
v ∩Eσ
u = ∅if v ̸= u), which is a true localization over Vσ,
the set of nonterminal vertices (in that Eσ
v ̸= ∅). Similarly Eτ
v = τ −1{v} ⊂E may
be viewed as a (complementary) generalized localization of E over V by τ, which is a
true localization over Vτ, the set of nongerminal vertices. Thus we may write E as a
disjoint union:
E =
9
v∈Vσ
Eσ
v =
9
v∈Vτ
Eτ
v ,
E =
9
v∈V
Eσ
v =
9
v∈V
Eτ
v ,
although in the latter equations some terms may be the empty set. For irreducible
digraphs there are no germinal or terminal vertices, in this case Vσ = Vτ = V .
Denote the free linear span of Eσ
v (resp. Eτ
v ) by Lσ
v (resp. Lτ
v). Some of these vector
spaces may be {0}. Nevertheless the set :
v∈V Lσ
v (resp. :
v∈V Lτ
v) may be regarded
as a sort of generalized vector bundle over V , with the obvious projection map ξ →v
for ξ ∈Lσ
v (resp. ξ ∈Lτ
v). Then
LE =
/
v
Lσ
v =
/
v
Lτ
v,
so that LE may be regarded as the space of sections both of these vector bundles.
Lemma 1. ker(S) = LV −Vσ, ker(T ) = LV −Vτ .
We may identify some distinguished subspaces in LE.
Deﬁnition 7. Cσ(E) is the set of functions which are constant on each subset Eσ
v , i.e.
Cσ(E) = 0
v C1Eσ
v (we will restrict ourselves to consideration only of vector spaces
over the complex numbers). Likewise Cτ(E) is the set of functions which are constant
on each subset Eτ
v , i.e. Cτ(E) = 0
v C1Eτ
v .
Lemma 2. Range(S) = Cσ(E), Range(T ) = Cτ(E)
Now, if we give the vector spaces LV , LE inner products, we may consider the adjoint
maps S∗, T ∗: LE →LV . Different choices of inner product give rise to different
operators, which is an issue we shall consider in the following sections. Now, since
LV , LE are free vector spaces, we consider the special cases of the dot product on these
spaces, i.e. the L2 inner products induced by the counting measures on V , respectively
E. Note that for these inner products Lσ
v ⊥Lσ
v′ and Lτ
v ⊥Lτ
v′ for v ̸= v′.

226
M. Kawski and T.J. Taylor
Deﬁnition 8. M σ
v ⊂Lσ
v is the subspace of functions on Eσ
v which are orthogonal to the
constants. M τ
v ⊂Lτ
v is the subspace of functions on Eτ
v which are orthogonal to the
constants. Mσ(E) = 0
v M σ
v . Mτ(E) = 0
v M τ
v (where in this context ⊕denotes
the orthogonal direct sum).
Lemma 3. Lσ
v = C1Eσ
v ⊕M σ
v , Lτ
v = C1Eτv ⊕M τ
v , Cσ(E)⊥= Mσ(E), Cτ(E)⊥=
Mτ(E).
Lemma 4. For an element g ∈LE,
S∗g(v) =

e:e−=v
g(e), and T ∗g(v) =

e:e+=v
g(e).
Proof. Let 1v ∈LV denote the indicator function of the point v ∈V . Then
S∗g(v) = ⟨1v, S∗g⟩= ⟨S1v, g⟩=

e
S1v(e)g(e) =

e
1v(e−)g(e) =

e:e−=v
g(e).
The case for T ∗is analogous.
2
Lemma 5. We have
1. ker(S∗) = Cσ(E)⊥= Mσ(E), ker(T ∗) = Cτ(E)⊥= Mτ(E).
2. Range(S∗) = LVσ, Range(T ∗) = LVτ .
We may regard the operators S, T as canonical operators associated with the digraph,
as the operators S∗, T ∗are also canonically associated with the digraph and our choice
of inner product on LV and LE. Moreover, operators constructed from algebraic com-
binations of these operators may also be regarded as canonical. The following results
will be useful.
Proposition 1. The operators S∗S and T ∗T satisfy: ∀f ∈LV , ∀v ∈V , S∗Sf(v) =
do(v)f(v) and T ∗Tf(v) = di(v)f(v).
Proof. Sf(e) = f(e−), so S∗Sf(v) =

e:e−=v
f(e−) = f(v)

e:e−=v
1. The case for
T ∗T is analogous.
Corollary 1. ∥S∥2 = do(G) and ∥T ∥2 = di(G)
Proof.
∥S∥2 = sup
f∈LV
⟨Sf, Sf⟩
⟨f, f⟩
= sup
f
⟨f, S∗Sf⟩
⟨f, f⟩
= sup
v do(v),
since the S∗S is diagonal. The situation for T is symmetric.
Proposition 2. The operators S∗T and T ∗S satisfy
1. S∗Tf(v) = 
e:e−=v f(e+)
2. T ∗Sf(v) = 
e:e+=v f(e−)

Canonical Operators on Graphs
227
Proposition 3. The operators SS∗and TT ∗satisfy:
1. SS∗g(e) = do(e−)g(e) for g ∈Cσ(E) and SS∗g = 0 for g ∈Cσ(E)⊥.
2. TT ∗g(e) = di(e+)g(e) for g ∈Cτ(E) and TT ∗g = 0 for g ∈Cτ(E)⊥.
Deﬁnition 9. the incidence operator of a graph G = (V, E) is IG : LV →LE is
deﬁned by IGf([u, v]) = f(u) + f(v).
Lemma 6. Let G be a digraph. Then IΦGf(e) = Sf(˜e) + Tf(˜e), where ˜e is any
element of Φ−1e.
Remarks. Unlike the source and target operator, the incidence operator is not a pull-
back, e.g. of the incidence mapping. It is more common in the literature (e.g. [2], [3])
to discuss instead with the directed incidence operator, discussed below, for an arbi-
trary choice of direction to each edge. The additional ease in using D may based on
a morphism with differential geometry, as has been remarked by a number of authors
( [2], [3], [10]).
3
Differences, Divergences, Laplacians and Dirac Operators
One fundamental family of operators is founded on the difference operator. A funda-
mental reference for this section is Bollabas [2].
Deﬁnition 10. The difference operator (i.e. directed incidence operator) D : LV →
LE is deﬁned by Df(e) = Tf(e) −Sf(e).
Deﬁnition 11. A cut is a partition of the vertex set into two pieces V = W ∪W c;
equivalently a cut is an indicator function 1W ∈LV . The cut vector of W is the
function g ∈LE such that g(e) = 1 if e+ ∈W but e−/∈W, g(e) = −1 if e−∈W but
e+ /∈W and g(e) = 0 otherwise. The cut space is the span of all cut vectors.
Note that the indicator functions span LV , and that each cut vector is equal to D1W for
some subset W ⊂V . From this it is an easy step (since {1{v} : v ∈V } spans LV ) to
Proposition 4. The cut space is equal to Range(D).
Clearly the value of a cut vector on any self edge is zero.
Deﬁnition 12. A cycle is a forgetful homomorphism of a circle into G, i.e. a path
in which the endpoint vertices are equal, and a simple cycle is an injective forgetful
homomorphism of a circle into G, i.e. a cycle in which only the endpoint vertices are
repeated. By abuse of notation an edge vector g ∈LE which is zero except on the edges
of a simple cycle and assigns the value which assigns the value +1 to sense edges, −1
to antisense edges is also referred to as a simple cycle. The cycle space is the linear
span of the simple cycles in LE.
Note that we might also consider the self cycle space linear span of the set of self cycles.
For the following, denote the self cycle space by K(G), the cycle space by Z(G) and
the cut space by B(G).

228
M. Kawski and T.J. Taylor
Deﬁnition 13. A connected component of a (di)graph is a maximal subset of V having
the property that every two vertices are contained in a path. A function in LV is called
locally constant if f(v) = f(u) for any v, u such that vu ∈E or uv ∈E.
Lemma 7. Locally constant functions are constant on each path, hence are constant
on each connected component of G. Locally constant functions are a vector subspace
of LV .
Let C(G) denote the vector space of locally constant functions in LV . Clearly the
dimension of C(G) is equal the number of connected components of G.
Proposition 5. ker(D) = C(G), dim (B(G)) = Order(G) −dim (C(G)).
Proof. Clearly Df(e) = 0 iff f takes the same value on both sides of e. Thus Df = 0
iff f is constant on every path, i.e. is locally constant.
Deﬁnition 14. The divergence operator is D∗: LE →LV , the dual operator of D.
The following is a direct consequence of Lemma 4
Lemma 8. The divergence operator satisﬁes
D∗g(v) = T ∗g(v) −S∗g(v) =

e:e+=v
g(e) −

e:e−=v
g(e)
Lemma 9. ker(D∗) = B(G)⊥. Range(D∗) = C(G)⊥.
Proof. For g ∈ker(D∗) and for all f ∈LV , 0 = ⟨f, D∗g⟩= ⟨Df, g⟩. The result fol-
lows since B(G) = Range(D). Clearly Range(D∗) ⊂C(G)⊥, since for f ∈C(G),
g ∈LE, ⟨f, D∗g⟩= ⟨Df, g⟩= 0. Now suppose that Range(D∗) is a proper subspace
of C(G)⊥. Then there exists a nonzero f ∈C(G)⊥which is also in the orthogonal
complement of Range(D∗), so Df ̸= 0, and for all g ∈LE, 0 = ⟨f, D∗g⟩= ⟨Df, g⟩.
In particular this is true for g = Df, which implies 0 = ⟨Df, Df⟩, of Df = 0, which
is a contradiction.
The proof of the following follows easily from [2], p. 53.
Proposition 6. B(G)⊥= Z(G) ⊕K(G).
Deﬁnition 15. The Laplacian of G is the operator ∆= D∗D deﬁned on LV . The
Laplace-de Rham operator of G is the operator 2 = D∗D⊕DD∗deﬁned on LV ⊕LE,
where ⊕denotes the orthogonal direct sum.
Proposition 7
1. ∆= S∗S + T ∗T −S∗T −T ∗S.
2. ker(∆) = C(G) and Range(∆) = C(G)⊥.
3. 0 ≤⟨f, ∆f⟩≤
1
d(G) + 2

do(G)di(G)
2
⟨f, f⟩≤2d(G) ⟨f, f⟩.

Canonical Operators on Graphs
229
Proof.
1. Item 1 follows from the deﬁnition of D.
2. u ∈ker(∆) iff
0 = ⟨u, ∆u⟩= ⟨Du, Du⟩,
i.e. iff u ∈ker(D) = C(G). Since ∆is self adjoint, both ker∆and ker(∆)⊥are
ﬁnite dimensional invariant subspaces, so ∆|ker(∆)⊥is an isomorphism.
3. Note that
⟨f, ∆f⟩= ⟨f, S∗Sf⟩+ ⟨f, T ∗Tf⟩−⟨f, (S∗T + T ∗S)f⟩
≤maxv (di(v) + do(v)) ⟨f, f⟩+ 2∥Sf∥∥Tf∥
=
1
d(G) + 2

do(G)di(G)
2
⟨f, f⟩
≤2d(G) ⟨f, f⟩,
where the inequality follows from Theorem 1, the triangle inequality and the
Cauchy-Schwartz inequality, and the succeeding equality follows from Corollary 1.
Note that the latter inequality in item 3 is an equality for the case of the graph which
consists of a single directed cycle of even order, and f is the function which alter-
nates between +1 and −1 on successive vertices; f is an eigenfunction of ∆with
eigenvalue 4, d(G) = 2 and do(G) = di(G) = 1. In particular the inequalities in
item 3 are tight.
Proposition 8
1. DD∗= SS∗+ TT ∗−ST ∗−TS∗.
2. ker(DD∗) = B(G)⊥and Range(DD∗) = B(G).
3. The eigenvalues of DD∗are the same as those of ∆, with the same multiplicity. If
∆f = λf for λ ̸= 0 a constant, then Df is an eigenvector for DD∗with the same
eigenvalue.
Thus the Laplace-deRham operator contains only a little additional information about
the graph geometry beyond that contained in the Laplacian. The term ’Dirac opera-
tor’ refers generally to a square root of the Laplacian, although by custom not to the
symmetric square root of the Laplacian. Hence:
Deﬁnition 16. The Dirac operator of G is the operator ∂=

0 D∗
D 0

deﬁned on
LV ⊕LE.
Proposition 9
1. ∂2 = 2.
2. ∂is self adjoint.
3. ker(∂) = C(G) ⊕B(G)⊥and Range(∂) = C(G)⊥⊕B(G).
4. The eigenvalues of ∂are the (positive and negative) square roots of those of ∆,
with the same multiplicity. If ∆f = λf for λ ̸= 0 a constant, then the eigenvector
of
√
λ (resp. -
√
λ) is
 √
λf
Df

(resp.
 √
λf
−Df

).

230
M. Kawski and T.J. Taylor
Remarks: We have taken the convention that the Laplacian is a nonnegative operator.
The other common convention is, of course, that the Laplacian is nonpositive. This
perspective has the net effect of replacing eigenvalues of the Laplacian and Laplace-
deRham operators by their negatives, and replacing the Dirac operator by the skew-
adjoint operator

0 −D∗
D
0

, for which the eigenvalues are imaginary.
4
Operators on Weighted Graphs
Consider a function w : E →C on E, and a function ρ : V →C on V , which we
will call weight functions. Although some literature considers cases in which w, rho
are complex, [14], [16], [17], we will suppose that w and ρ are both positive real func-
tions. Then the bilinear function ⟨f1, f2⟩ρ = 
v ρ(v)f1(v)f2(v)∗on LV deﬁnes an
inner product. Likewise the inner product ⟨g1, g2⟩w = 
e w(e)g1(e)g2(e)∗deﬁnes an
inner product on LE. Clearly there is a wide latitude of choice of weight functions,
and they inﬂuence properties of the canonical operators. We may take as fundamental
the deﬁnition of the operators S, T . Then the discussion of section B is valid in its en-
tirety through Lemma 1.3 provided that orthogonality in LE is understood to be in the
weighted sense. However, Lemma 1.4 now takes the form
Lemma 10. For a element g ∈LE,
S∗g(v) =
1
ρ(v)

e:e−=v
w(e)g(e), and T ∗g(v) =
1
ρ(v)

e:e+=v
w(e)g(e).
Proof. Let 1v ∈LV denote the indicator function of the point v ∈V . Then
S∗g(v) =
1
ρ(v) ⟨1v, S∗g⟩=
1
ρ(v) ⟨S1v, g⟩
=
1
ρ(v)

e w(e)S1v(e)g(e)
=
1
ρ(v)

e w(e)1v(e−)g(e) =
1
ρ(v)

e:e−=v
w(e)g(e).
The case for T ∗is analogous.
2
Lemma 1.5 is valid in the weighted case as stated. We will revise our deﬁnitions as
follows.
Deﬁnition 17. The out-degree of a vertex v ∈V of a digraph is the sum do(v) =
1
ρ(v)

e−=v
w(e), the in-degree is the sum di(v) =
1
ρ(v)

e+=v
w(e) and the degree of
v is d(v) = do(v) + di(v).
The degrees of the digraph are deﬁned as di(G) =
maxv∈V di(v), do(G) = maxv∈V do(v), d(G) = maxv∈V (di(v) + do(v)). For a
graph there is only one kind of edge, so one kind of degree.
Note that the degrees are positive real numbers, but need no longer be integers.
Proposition 10. The operators S∗S and T ∗T satisfy: S∗Sf(v) = do(v)f(v) and
T ∗Tf(v) = di(v)f(v).

Canonical Operators on Graphs
231
Proof. Sf(e) = f(e−), so
S∗Sf(v) =
1
ρ(v)

e:e−=v
w(e)f(e−) = f(v) 1
ρ(v)

e:e−=v
w(e).
The case for T ∗T is analogous.
2
With the above deﬁnitions of vertex degrees, the following takes the same form as in
the unweighted case.
Corollary 2. ∥S∥2 = do(G) and ∥T ∥2 = di(G)
Proof.
∥S∥2 = sup
f∈LV
⟨Sf, Sf⟩
⟨f, f⟩
= sup
f
⟨f, S∗Sf⟩
⟨f, f⟩
= sup
v do(v),
since the S∗S is diagonal. The situation for T is symmetric.
Proposition 11. The operators T ∗S and S∗T satisfy:
1. T ∗Sg(v) =
1
ρ(v)

e:e−=v
w(e)f(e+)
2. S∗Tg(v) =
1
ρ(v)

e:e+=v
w(e)f(e−)
Proposition 12. The operators SS∗and TT ∗satisfy:
1. SS∗g(e) = do(e−)g(e) for g ∈Cσ(E) and SS∗g = 0 for g ∈Cσ(E)⊥.
2. TT ∗g(e) = di(e+)g(e) for g ∈Cτ(E) and TT ∗g = 0 for g ∈Cτ(E)⊥.
The deﬁnition of the difference operator D remains the same in this weighted situa-
tion, and it’s range is still the space of cut vectors B(G), and its kernel is still the
space of locally constant functions C(G). The orthogonal complement B(G)⊥, and
the divergence operator D∗are generally different, since they deﬁned in terms of the
inner product on LE. Let W denote the operator on LE of multiplication by the weight
function w. The following lemma is immediate, given that WK(G) = K(G)
Lemma 11. B(G)⊥= W −1Z(G) ⊕K(G).
Lemma 12. ker(D∗) = B(G)⊥and Range(D∗) = C(G)⊥
The following theorem takes the same form as the non-weighted case.
Proposition 13
1. ∆w
ρ f(v) = (S∗S + T ∗T −S∗T −T ∗S)f(v)
2. ∆w
ρ f(v) = d(v)f(v) −
1
ρ(v)
 
e:e−=v
w(e)f(e+) +

e:e+=v
w(e)f(e−)

3. ker(∆w
ρ ) = C(G) and Range(∆w
ρ ) = C(G)⊥ρ
4. 0 ≤
;
f, ∆w
ρ f
<
≤
1
d(G) + 2

do(G)di(G)
2
⟨f, f⟩

232
M. Kawski and T.J. Taylor
Of particular recent interest are weighted graph Laplacians in the case that ρ(v) = d(v)
and w(e) = 1 for all edges in the graph. In this case the Laplacian has the represen-
tation ∆df(v) = f(v) −
1
d(v) (
e:e−=v f(e+) + 
e:e+=v f(e−)), and is self adjoint
on LV with respect to the inner product ⟨f, g⟩d = 
v f(v)g(v)d(v). It will be a little
easier to see the self adjointness of ∆d if we express it in a unitarily equivalent form
on a different inner product space. Speciﬁcally, note that the multiplication operator
Uf(v) =
1
√
d(v)f(v) is a unitary map from the inner product space (LV , ⟨·, ·⟩1) to
the inner product space (LV , ⟨·, ·⟩d). Thus ∆d is unitarily equivalent to the operator
U −1∆dU = d(v)−1/2∆d(v)−1/2 on (LV , ⟨·, ·⟩1). But on this inner product space self
adjointness is just symmetry, and the symmetry of d(v)−1/2∆d(v)−1/2 is manifest. But
the latter is just the Laplacian preferred by Chung [3] because its spectrum is so closely
tied to graph geometry.
5
The Incidence Operator and Its Kin
Recall that the incidence operator I : LV →LE is deﬁned by If(e) = Tf(e)+Sf(e).
If a function f is in ker(I) it must have values of equal magnitude but opposite sign at
the vertices on either side of every edge. From this follows the fact that the values taken
by f on a connected component of the (di)graph are determined by its value at a single
vertex. Moreover, f(v) = 0 for v in any cycle of odd order, hence in the connected
component of a cycle of odd order. This is basically everything that needs to be known
about the kernel of the incidence operator.
Lemma 13. ker(I) is the space of functions on V which alternate sign across every
edge. If G is connected, ker(I) is zero or one dimensional according to whether G
has cycles of odd order or not. In general the dimension of ker(I) is the number of
connected components without cycles of odd order.
Remarks: Since a connected graph is bipartite iff it has no odd cycles, dimker(I) is
the number of bipartite components. More generally the kernel contains the span of the
isolated vertices. This result may be originally due to Van Nuffelen [18] in the context
of graphs. A vertex with a self edge is a cycle of odd order, hence on any component
containing a self edge one has ker(I) = {0}.
Note that I1v = 1Eσ
v ∪Eτ
v . The set Eσ
v ∪Eτ
v seems to us the shadow of v on the
edge set, so we will call such a vector 1Eσ
v ∪Eτv a shadow, and call a vector in the span
of such vectors a shadow vector. Denote the set of shadow vectors by Υ(G). Clearly
Range(I) = Υ(G).
Lemma 14. Assume G is connected. If G has cycles of odd order, {1Eσ
v ∪Eτv : v ∈V }
is basis of Range(I). Conversely, if G has no cycles of odd order, then for any u ∈
V ,{1Eσ
v ∪Eτv : v ∈V −{u}} is a basis of Range(I).
Lemma 15
I∗g(v) =

e:e−=v
g(e) +

e:e+=v
g(e).

Canonical Operators on Graphs
233
Proof. This follows directly from Lemma 4.
Another way of saying the same thing, is that I∗g(v) =
;
1Eσ
v ∪Eτv , g
<
. Of course
ker(I∗) = Range(I)⊥. The geometry of this statement is the following. Suppose
that Z2k is a circle of even order, and that ˆg ∈LE(Z2k) is the alternating function:
ˆg ((i, i + 1)) = (−1)i, where the addition ”i + 1” is interpreted as mod 2k. Suppose
that c : Z2k →G is a cycle in G. Deﬁne a function g ∈LE with support contained
in c (Z2k) by g(e) = 
i:e=c((i,i+1)) ˆg ((i, i + 1)). Then g ∈ker(I∗). We will call g
an alternating cycle. Let A(G) ⊂LE denote the span of the alternating cycles. Then
A(G) ⊆ker(I∗).
Deﬁnition 18. Suppose that g ∈LE and that |supp(g) ∩(Eσ
v ∪Eτ
v )| = 1. Then we
will call e ∈supp(g) ∩(Eσ
v ∪Eτ
v ) a hanging edge.
Lemma 16. Suppose that I∗g(v) = 0 and that supp(g) ∩(Eσ
v ∪Eτ
v ) ̸= ∅. Then there
are at least two elements of e, e′ ∈supp(g) ∩(Eσ
v ∪Eτ
v ) which satisfy g(e)g(e′) < 0.
(In other words, supp(g) has no hanging edges)
Proof. supp(g)∩(Eσ
v ∪Eτ
v ) ̸= ∅implies 
e:e−=v |g(e)|+
e:e+=v |g(e)| ̸= 0. Since
I∗g(v) = 0 implies cancellation, there exists at least at least two edges e, e′ ∈Eσ
v ∪Eτ
v
with g(e) > 0 and g(e′) < 0.
2
Deﬁnition 19. Let φ : Ik →G be a path, let ˆh ((i, i + 1)) = (−1)i be a function
ˆh ∈LE(Ik). Deﬁne h ∈LE(G) by h(e) = 
i:e=φ((i,i+1)) ˆh ((i, i + 1)) if e ∈φ(Ik)
and h(e) = 0 otherwise. We will call h the alternating path built on φ. If φ is the
restriction of a path φ′ : Ik+n →G for n > 0 and h′ is the alternating path built on φ′
we shall say that h is a restriction of h′.
Lemma 17. Assume that the alternating path h has no self edges and let v be an interior
vertex of h. Then I∗h(v) = 0.
Proof. We have:
I∗h(v) = 
e:e−=v h(e) + 
e:e+=v h(e)
= 
e:e−=v

i:e=φ((i,i+1)) ˆh ((i, i + 1))
+ 
e:e+=v

i:e=φ((i,i+1)) ˆh ((i, i + 1)) .
But, in the latter expression each summand is of magnitude one and uniquely paired
with another such of opposite sign. Indeed, since v is an internal vertex, for every i
such that v = φ(i), both edges e = φ ((i −1, i)) and e′ = φ ((i, i + 1)) are coincident
with v, hence in the sum, while ˆh ((i, i + 1)) = −ˆh ((i −1, i)).
2
Lemma 18. An alternating path of even order cannot belong to ker(I∗).
Proof. Such a path either has a hanging edge, or in the case that the initial and terminal
vertex are equal has the initial and terminal edges of equal sign, so that I∗h(v) ̸= 0
when v is the initial vertex.
2
Lemma 19. Let h be an alternating path of odd order. Then h ∈ker(I∗) iff vk =
φ(2k + 1) = φ(1) = v1. In other words, an alternating path is in ker(I∗) iff it is of
odd order and an alternating cycle.

234
M. Kawski and T.J. Taylor
Proof. If v2k+1 ̸= v1 then h has a hanging edge, hence cannot be in ker(I∗). Con-
versely, if v2k+1 = v1 then φ deﬁnes a cycle of even order, and h is an alternating
cycle.
2
Theorem 1. Suppose G is a multigraph. Then ker (I∗) = A(G).
Remark: This result seems to be ﬁrst due to Grossman et al [9], and then again by
ourselves some thirteen years later.
Lemma 20. Range(I∗) is the orthogonal complement of the space of alternating func-
tions in LV . If G has no bipartite components or isolated vertices, i.e. there is a cycle
of odd order in every component, then Range(I∗) is all of LV .
Lemma 21. I∗I = T ∗T + S∗S + S∗T + T ∗S.
Remark: Grossman et al [9] call I∗I the Unoriented Laplacian .
Proposition 14. Suppose that G is bipartite. Then I∗I is unitarily equivalent to ∆, the
Laplacian of G.
Proof. Let m ∈ker (I∗I) be real valued and unimodular (which exists by Lemma
13), and let M be the operator of multiplication by m. Then M is unitary and it’s
own inverse. According to Bollobas [2] p.264, (T ∗S + S∗T )M = −M(T ∗S + S∗T ).
Since T ∗T + S∗S is a multiplication operator, it commutes with M. Thus M −1I∗IM
= ∆.
2
Remarks: This result is known to the algebraic graph theory community [7], although
we are unaware of a speciﬁc reference. For a regular graph I∗I is a linear function of
the Laplacian.
The following proposition is proved in exactly as Theorem 7.
Proposition 15
1. ker(I∗I) = ker(I) is the space of alternating functions on V .
2. Range(I∗I) = Range(I∗), the orthogonal complement of the alternating func-
tions. When G has no isolated verticies or bipartite components, Range(I∗I) is
all of LV .
3. 0 ≤⟨f, I∗If⟩≤
1
d(G) + 2

di(G)do(G)
2
⟨f, f⟩.
Proposition 16
1. II∗= TT ∗+ SS∗+ ST ∗+ TS∗
2. ker(II∗) = ker(I∗) = A(G), Range(II∗) = Range(I) = Υ(G).
3. II∗has the same spectrum as I∗I, and, with the possible exception of the eigen-
value 0, with the same multiplicity. If u is an eigenvector of I∗I, the Iu is an
eigenvector of II∗.
Remark: It would be nice to have a characterization of the spectrum in the non-bipartite
case. We are unaware of progress in this arena since Grossman et al [9], 1994.

Canonical Operators on Graphs
235
6
The Drift of a Digraph
In this section we discuss a family of fundamental operators on graphs which seems
not to have been discussed in the literature. So far we have considered differences
and sums of the canonical operators, S, T . At this point we will consider the operator
S + iT, mapping LV into LE. The adjoint operator is S∗−iT ∗, so the operator
(S∗−iT ∗)(S + iT) = S∗S + T ∗T + i(S∗T −T ∗S) is self adjoint and positive
semideﬁnite. We can also consider the same construction using the other square root of
−1 to deduce that (S∗+ iT ∗)(S −iT) = S∗S + T ∗T + i(T ∗S −S∗T ) is self adjoint
and positive semideﬁnite.
Our experience with the difference and incidence operators makes the following
lemma a triviality.
Lemma 22. In a connected digraph G, S +iT (resp. S −iT) has a trivial kernel unless
the only cycles are of order divisible by 4. In this case there is a one dimensional kernel
spanned by complex functions in which the which the magnitude is locally constant and
the phase rotates by a factor if i (resp. −i) across every edge in traversing from source
to target.
Corollary 3. (S∗−iT ∗)(S + iT) (resp. (S∗+ iT ∗)(S −iT)) is invertible unless the
only cycles in G have order divisible by 4. In this case there is a one dimensional kernel
spanned by complex functions in which the which the magnitude is locally constant and
the phase rotates by a factor if i (resp. −i) across every edge in traversing from source
to target.
Deﬁnition 20. We will call the operator Γ(G) = T ∗S −S∗T the drift operator of the
graph.
Proposition 17. The drift operator satisﬁes the following properties.
1. Γ is skew adjoint and real.
2. The eigenvalues of Γ are imaginary. For each eigenvector f, Γf = λf implies
Γf = −λf, i.e. the eigenvalues and eigenvectors come in complex conjugate
pairs.
3. Γ generates a one parameter unitary group t →etΓ on LV (in fact a group of
rotations).
4. ∥Γf∥≤d(G)∥f∥.
5. Γf(v) = 
e:e+=v f(e−) −
e:e−=v f(e+)
Proof.
1. Since (S∗+ iT ∗)(S −iT) and S∗S + T ∗T are self adjoint, so is i(S∗T −T ∗S),
hence S∗T −T ∗S is skew symmetric. It also maps real functions to real functions.
2. Since i(S∗T −T ∗S) is self adjoint, it’s eigenvalues are real, hence those of (S∗T −
T ∗S) are imaginary. Since Γ is real taking the complex conjugate of the eigenvalue
equation yields complex conjugate eigenvalues and eigenvectors.
3. This is just the Stone’s theorem on generators of unitary groups; since Γ is real,
this unitary group is also real, hence a group of rotations.

236
M. Kawski and T.J. Taylor
4. For f a complex function:
0 ≤⟨f, (S∗± iT ∗)(S ∓iT)f⟩
0 ≤±i ⟨f, (S∗T −T ∗S)f⟩+ ⟨f, S∗Sf⟩+ ⟨f, T ∗Tf⟩
|⟨f, (S∗T −T ∗S)f⟩| ≤⟨f, S∗Sf⟩+ ⟨f, T ∗Tf⟩
|⟨f, (S∗T −T ∗S)f⟩| ≤d(G) ⟨f, f⟩.
But since (S∗T −T ∗S) is skew adjoint, its norm is the maximum of the magnitude
of its numerical range.
5. This follows from Proposition 2.
2
Recall that a regular graph is a graph in which the vertex degree d(v) is independent of
v and d(v) = d(G). The same condition is less restrictive for digraphs, since di(v) and
do(G) may vary subject to the constraint di(v) + do(v) = d(G).
Corollary 4. If the vertex-wise degree d(v) = d(G) is constant then the eigenvectors
of Γ are also eigenvectors of (S∗∓iT ∗)(S ± iT). In particular, if the only cycles in
G are of order divisible by 4, then Γ has eigenvalues ±d(G), and (S∗∓iT ∗)(S ± iT)
has eigenvalue 2d(G).
Note that while the operators ∆and I∗I are insensitive to the choice of direction in
an edge e = uv, changing the sense of an directed edge results in a different Γ by a
change of sign in one pair of entries: Γ ′
uv = −Γuv. Moreover, in general this change
of a direction in a single edge also results in a change of the eigenvalues. However, Γ
is insensitive to the addition or deletion of self loops e = vv. The following lemma
follows from basic properties of rotations.
Lemma 23. Order(G) ≡2 dimker(Γ). In particular, when the order of G is odd, Γ
has a nonzero kernel.
Generally the adjacency matrix of a (weighted) graph is given by a symmetric matrix.
This data may also be taken as the data of a digraph in which every edge is accompanied
by an edge in the opposite direction (of the same weight). We have
Proposition 18. When the adjacency matrix is symmetric, the drift is zero, i.e. Γ = 0.
In this sense the drift operator measures the deviation of a digraph G from a graph.
References
1. Bensoussan A and Menaldi JL (2005) Difference Equations on Weighted Graphs, Journal of
Convex Analysis (Special issue in honor of Claude LeMarechal), 12:13–44 .
2. Bollobas B (1998)Modern Graph Theory, Springer, New York.
3. Chung, F. (1997) Spectral Graph Theory, CBMS Lecture Notes. AMS, Philadelphia.
4. Ferrari-Trecate G , Buffa A, and Gati M (2005) Analysis of coordination in multi-agent
systems through partial difference equations. Part I: The Laplacian control. 16th IFAC World
Congress on Automatic Control
5. Ferrari-Trecate G , Buffa A, and Gati M (2005) Analysis of coordination in multi-agent
systems through partial difference equations. Part II: Nonlinear control. 16th IFAC World
Congress on Automatic Control

Canonical Operators on Graphs
237
6. Ferrari-Trecate G , Buffa A, and Gati M (2006) Analysis of Coordination in Multi-Agent
Systems through Partial Difference Equations, IEEE Trans. Automatic Control, 5(6): 1058–
1063.
7. Godsil C.(2007), Private communication.
8. Gross J and Tucker T (1987) Topological Graph Theory, Wiley Interscience, New York
9. Grossman, J., Kulkarni D. and Schochetman, I. (1994) Algebraic Graph Theory Without
Orientation, Linear Algebra and Its Applications 212/213: 289-307.
10. Hatcher A (2002) Algebraic Topology, Cambridge University Press Cambridge, U.K. ; New
York.
11. Imrich W and Pisanski T Multiple Kronecker Covering Graphs, arXiv:math.CO/050513 v1
8 May 2005
12. Jadbabiaie A, Lin J, Morse A S (2003) Coordination of groups of mobile autonomous agents
using nearest neighbor rules, IEEE Transactions on Automatic Control, 48(6): 988–1001.
13. Ji M, Egerstedt M, Ferrari-Trecate G, and Buffa A (2006) Hierarchical Containment Control
in Heterogeneous Mobile Networks, Mathematical Theory of Networks and Systems, Kyoto,
Japan: 2227-2231
14. Lieb E and Loss M (1993) Fluxes, Laplacians and Kesteleyn’s Theorem, Duke Mathematical
Journal, 71(2): 337-363
15. Muhammad A and Egerstedt M (2005) Connectivity Graphs as Models of Local Interactions,
Journal of Applied Mathematics and Computation, 168(1):243-269
16. Shubin MA (1994) Discrete Magnetic Laplacian, Commun. Math. Phys. 164:259-275
17. Sunada T (1994) A Discrete Analogue of Periodic Magnetic Schrodinger Operators, Con-
temporary Mathematics, 173:283-299
18. Van Nuffelen C (1976) On the incidence matrix of a graph, IEEE Transactions on Circuits
and Systems, 23(9):572 - 572
19. S. Vigna, The Graph Fibrations Home Page,
http://vigna.dsi.unimi.it/ﬁbrations/, (as viewed November 2006)

Prediction-Error Approximation by Convex
Optimization
Anders Lindquist
Optimization and Systems Theory,
Department of Mathematics, Royal Institute of Technology. SE-10044 Stockholm, Sweden
alq@math.kth.se
This paper is dedicated to Giorgio Picci on the occasion of his 65th birthday. I have
come to appreciate Giorgio not only as a great friend but also as a great scholar. When
we ﬁrst met at Brown University in 1973, he introduced me to his seminal paper [29]
on splitting subspaces, which became the impetus for our joint work on the geometric
theory of linear stochastic systems [23,24,25,26]. This led to a life-long friendship and
a book project that never seemed to converge, but now is close to being ﬁnished [27].
I have learned a lot from Giorgio. The present paper grew out of a discussion in our
book project, when Giorgio taught me about the connections between prediction-error
identiﬁcation and the Kullback-Leibler criterion. These concepts led directly into the
recent theory of analytic interpolation with complexity constraint, with which I have
been deeply involved in recent times. I shall try to explain these connections in the
following paper.
1
Introduction
Prediction error methods for ARMA modeling play a major role in system identiﬁca-
tion [28, 30], but in general they lead to nonconvex optimization problems for which
global convergence is not guaranteed. In fact, although these algorithms are computa-
tionally simple and quite reliable, as pointed out in [32, p. 103], there is so far no theo-
retically satisfactory algorithm for ARMA parameter estimation. Convex optimization
approaches have been proposed [7, 17] for the approximation part, but it remains to
verify their practical applicability and statistical accuracy.
In this paper we identify certain classes of ARMA models in which prediction
error minimization leads to convex optimization.
It has been shown [2, 33] that
model approximation via prediction error identiﬁcation leads to an optimization prob-
lem that is related to the minimization of the Kullback-Leibler divergence criterion
[18, 21].
This, in turn, leads naturally to the theory of analytic interpolation and
generalized moment problems with complexity constraints developed in recent years
[8, 9, 10, 11, 12, 13, 14, 16]. This has already been observed, at least in the context of
covariance extension, in [4,6].
The paper is outlined as follows. In Section 2 we review some pertinent facts on
prediction error approximation and set notations. In Section 3 we deﬁne model classes
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 239–249, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

240
A. Lindquist
in terms of a ﬁnite number of, not necessarily rational, basis functions and show that
the corresponding prediction-error minimizers can be obtained as the solution of a
pair of dual convex optimization problems. In the rational case we can even compute
the minimizer in closed form. The connections to the Kullback-Leibler criterion and
maximum-likelihood identiﬁcation is described in Section 4. In Section 5 we provide
prediction-error approximants in model classes determined by interpolation conditions
on the spectral density and its positve real part.
For simplicity this paper will only deal with the scalar case, but multivariable exten-
sions are straightforward, given multivariable versions of the the theory of generalized
moment problems with degree constraints [5,22].
2
Prediction-Error Approximation
Let {y(t)}Z be a zero-mean stationary stochastic process with a spectral density
{Φ(eiθ); θ ∈[−π, π]} that may be rational or nonrational but is zero only in isolated
points θ. Let w be a normalized minimum-phase spectral of Φ; i.e.,
Φ(eiθ) = ρ|w(eiθ)|2,
θ ∈[−π, π],
where w(0) = 1 and ρ > 0 is a suitable normalizing factor. Then the process y can be
modeled by passing a white noise e with covariance lags E{e(t)e(s)} = ρδts through
a ﬁlter with a transfer function
w(z) =
∞

k=0
wkz−k.
Since w0 = 1,
y(t) = e(t) + y(t|t−1),
where
y(t|t−1) = w1e(t −1) + w2e(t −2) + . . .
is the one-step ahead linear predictor of y(t) given {y(s); s ≤t −1}. Hence y(t|t−1)
can be represented by passing e through a ﬁlter with transfer function w −1 as shown
in the block diagram
y(t)
y(t|t−1)
e(t) -
w−1
-
w −1
-
In particular,
y(t) −y(t|t−1) = e(t).
Now, let ˆw be a normalized ( ˆw(0) = 1), stable minimum-phase function belonging
to some model class W to be speciﬁed later. We shall regard ˆw as an approximation of
w, from which we can form an approximate predictor, denoted by ˆy(t|t−1), as in the
ﬁgure

Prediction-Error Approximation by Convex Optimization
241
y(t)
ˆy(t|t−1)
ε(t) -
ˆw−1
-
ˆw −1
-
Then
ε(t) = y(t) −ˆy(t|t−1);
i.e., ε(t) is the prediction error, which is not a white noise. Indeed, it is easy to see that
it has the variance
r := E{ε(t)2} =
 π
−π
| ˆw(eiθ)|−2Φ(eiθ) dθ
2π .
(1)
Since ε(t) = e(t) + [y(t|t−1) −ˆy(t|t−1)] and e(t) and [y(t|t−1) −ˆy(t|t−1)] are
uncorrelated,
r = ρ + E{|y(t|t−1) −ˆy(t|t−1)|2} ≥ρ.
The idea is now to ﬁnd a ˆw ∈W that minimizes the prediction error variance (1). To
this end, deﬁne the class F of spectral densities
ˆΦ(eiθ) = ˆρ| ˆw(eiθ)|2,
(2)
where ˆw ∈W and ˆρ > 0. Then the prediction error takes the form
r := ˆρ
 π
−π
ˆΦ(eiθ)−1Φ(eiθ) dθ
2π .
(3)
The purpose of the coefﬁcient ˆρ in (3) is merely to normalize ˆΦ. Once an optimal
ˆΦ ∈F has been determined, ˆρ and ˆw ∈W are obtained by outer spectral factorization
and normalzation so that ˆw(0) = 1.
3
Prediction-Error Approximation in Restricted Model Classes
We begin by deﬁning the model class F. To this end, let
g0, g1, g2, . . . , gn
(4)
be a linearly independent sequence of Lipschitz continuous functions on the unit circle
with zeros only in isolated points, and let the model class F be the set of all functions
ˆΦ such that
ˆΦ(eiθ)−1 = Q(eiθ) := Re
8 n

k=0
qkgk(eiθ)
=
,
(5)
for some q0, q1, . . . , qn ∈C such that Q(eiθ) ≥0 for all θ ∈[−π, π]. In addition, let Q
the class of all such functions Q.
As a simple example, consider the case gk = zk, k = 0, 1, . . ., n. Then the model
class W is the family of all AR(n) models. However, more general choices of rational
basis functions (4) yield model classes of ARMA models. Even more generally, we
may choose basis functions that are not even rational.

242
A. Lindquist
Theorem 1. Let the spectral density Φ have the property that the generalized moments
ck :=
 π
−π
gk(eiθ)Φ(eiθ) dθ
2π ,
k = 0, 1, . . . , n,
(6)
exist, and deﬁne the functional J : Q →R as
J(Q) =
 π
−π
5
Φ(eiθ)Q(eiθ) −log Q(eiθ)
6 dθ
2π.
(7)
Then the functional (7) has a unique minimum Qopt, which is an interior point in Q.
Moreover,
 π
−π
gk(eiθ)
1
Qopt(eiθ)
dθ
2π = ck,
k = 0, 1, . . ., n.
(8)
Proof. Since the functions g0, g1, . . . , gn are Lipschitz continuous, hypothesis H1 in
[14] is satisﬁed [14, Remark 1.1]. Moreover, since both Q ∈Q and Φ are nonnegative
on the unit circle with zeros only in isolated points,
 π
−π
QΦ dθ
2π > 0
for all Q ∈Q ∖{0}. Hence the sequence c = (c1, c2, . . . , cn) is positive in the sense
prescribed in [14].
The functional J : Q →R is strictly convex on the convex set Q, and hence, if a
minimum does exist, it must be unique. However, it is shown in [14, Theorem 1.5] that J
has a unique minimizer, Qopt, which lies in the interior of Q, provided the sequence c =
(c1, c2, . . . , cn) is positive and hypthesis H1 holds, which is what we have established
above. Since the minimizer Qopt is an interior point, the gradient of J must be zero
there, and hence (8) follows.
Theorem 2. Let Φ be an arbitrary spectral density such that the generalized moments
(6) exist. Then, there is a unique spectral density ˆΦ in the model class F that minimizes
the prediction error variance (3), and it is given by
ˆΦopt := Q−1
opt,
(9)
where Qopt is the unique minimizer in Theorem 1.
Proof. By Theorem 1, ˆΦopt is the unique minimizer of
J( ˆΦ−1) =
 π
−π
3
Φ(eiθ) ˆΦ−1(eiθ) + log ˆΦ−1(eiθ)
4 dθ
2π .
(10)
However, by (3),
 π
−π
Φ(eiθ) ˆΦ−1(eiθ) dθ
2π = r
ˆρ.

Prediction-Error Approximation by Convex Optimization
243
Moreover, in view of (2)
 π
−π
log ˆΦ dθ
2π = log ˆρ + 2
 π
−π
log | ˆw| dθ
2π
= log ˆρ + 2 log ˆw(0) = log ˆρ,
where we have used Jensen’s formula [1, p.184] and the facts that ˆw is outer and ˆw(0) =
1. Consequently,
J( ˆΦ−1) = r
ˆρ + log ˆρ.
(11)
Now, for any ﬁxed r > 0, (11) has a unique minimum for ˆρ = r, and hence
J( ˆΦ−1
opt) = 1 + min
r
log r.
Therefore log r, and hence the prediction error r, takes it unique minimum value for
ˆΦ = ˆΦopt, as claimed.
Now, in view of (8) and (9),
 π
−π
gk(eiθ) ˆΦopt(eiθ) dθ
2π = ck,
k = 0, 1, . . ., n.
(12)
However, ˆΦopt is not the only spectral density that satisﬁes these moment conditions.
In fact, following [14,12], we can prove that, among all such solutions, ˆΦopt is the one
maximizing the entropy gain.
Theorem 3. The optimal prediction-error approximation ˆΦopt of Theorem 2 is the
unique maximizer of the entropy gain
I( ˆΦ) :=
 π
−π
log ˆΦ(eiθ) dθ
2π
(13)
subject to the moment constraints
 π
−π
gk(eiθ) ˆΦ(eiθ) dθ
2π = ck,
k = 0, 1, . . ., n.
(14)
Let us stress again that the basis functions g0, g1, . . . , gn need not be rational. Although,
in general, we want the model class W to consist of rational functions of low degree,
there may be situations when it is desirable to include nonrational components, such as,
for example, exponentials.
Identiﬁcation in terms of orthogonal basis functions is a well studied topic
[19,34,35]. The most general choice is
gk(z) =

1 −|ξk|2
z −ξk
k−1

j=0
1 −ξ∗
j z
z −ξj
,
where ξ0, ξ1, ξ2, . . . are poles to be selected by the user. The functions g0, g1, g2, . . .
form a complete sequence in the Hardy space H2(Dc) over the complement of the unit

244
A. Lindquist
disc D provided ∞
k=0(1 −|ξk|) = ∞. In [19] the problem to determine a minimum-
degree rational function of the form
ˆF(z) = 1
2c0g0(z) +
∞

k=1
ckgk(z),
where c0, c1, . . . , cn are prescribed, was considered.
In our present setting, in order for ˆΦ := Re{ ˆF} to be a spectral density, ˆF needs
to be positive real, leading to a problem left open in [19]. Let c0, c1, . . . , cn be given
by (6). Then, by Theorem 3, the problem of determining the minimum prediction-error
approximant of Φ in the model class deﬁned by g0, g1, . . . , gn amounts to ﬁnding the
function ˆΦ that maximizes the entropy gain
 π
−π
log ˆΦ dθ
2π ,
subject to
 π
−π
gk ˆΦ dθ
2π = ck,
k = 0, 1, . . . , n.
Alternatively, we may solve the convex optimization problem of Theorem 1.
Theorem 1 enables us to determine, under general conditions, the minimum
prediction-error in closed form. Here, following [16], we state such a result under
the assumption that the basis functions are rational.
Proposition 1. Suppose that the basis functions g0, g1, . . . , gn are rational and analytic
in the unit disc D. Then,
Qopt(z) = |g∗(z)P −1g(0)|2
g∗(0)P −1g(0) ,
(15)
where
g(z) :=
⎡
⎢⎢⎢⎣
g1
g2
...
gn
⎤
⎥⎥⎥⎦,
P :=
 π
−π
g(eiθ)Φ(eiθ)g(eiθ)∗dθ
2π.
Proof. Clearly the basis functions g0, g1, . . . , gn belong to the Hardy space H2(D), and
g := (g0, g1, . . . , gn)′ has a representation
g(z) = (I −zA)−1B,
where (A, B) is a reachable pair. Then
ϕ(z) = det(zI −A∗)
det(I −zA)
is an inner function, and it can be shown that the basis functions g0, g1, . . . , gn span the
coinvariant subspace K := H2 ⊖ϕH2. Moreover, for any Q ∈Q, there is an outer

Prediction-Error Approximation by Convex Optimization
245
function in a ∈K such that Q = a∗a ( [13, Proposition 9]). Consequently (7) can be
written
J(a) =
 π
−π
a∗Φa dθ
2π −
 π
−π
2 log |a| dθ
2π .
Here the second term can be written 2 log |a(0)| by Jensen’s formula [1, p.184], and
since a ∈K, there is a vector a ∈Cn+1 such that a(z) = g∗(z)a, so the second term
be written a∗Pa. Hence the optimization problem is reduced to determining the a that
minimizes
˜J(a) = a∗Pa −2 log |a∗g(0)|.
Setting the gradient equal to zero, we obtain a = P −1g(0)/|a(0)| and hence a(z) =
g∗(z)P −1g(0)/|a(0)|. Then |a(0)|2 = g∗(0)P −1g(0), and therefore the optimal a
becomes
a(z) =
g∗(z)P −1g(0)

g∗(0)P −1g(0)
,
from which (15) follows.
Remark 1. The pair of dual optimization problems in Theorems 1-3 are special cases of
a more general formulation [8,9,10,11,12,13,14,16] where (7) is replaced by
JΨ(Q) =
 π
−π
5
Φ(eiθ)Q(eiθ) −Ψ(eiθ) log Q(eiθ)
6 dθ
2π ,
(16)
with Ψ is a parahermitian function that is positive on the unit circle and available for
tuning; and (13) is replaced by
IΨ( ˆΦ) :=
 π
−π
Ψ(eiθ) log ˆΦ(eiθ) dθ
2π .
(17)
The particular choice Ψ = I, corresponding to the minimum prediction-error approxi-
mation, is called the central or maximum entropy solution. As suggested by Blomqvist
and Wahlberg [4,6] in the context of covariance extension, a nontrivial Ψ corresponds to
a particular choice of preﬁltering that may lead to better results; cf, page 249preﬁltering.
4
The Kullback-Leibler Criterion and Maximum-Likelihood
Identiﬁcation
The optimization problem of Theorem 1 is intimately connected to the Kullback-Leibler
divergence [21,18]
D(y∥z) := lim sup
N→∞
1
N D(pN
y | pN
z )
from one stationary, Gaussian stochastic processes z to another y, where pN
y and pN
z
are the N-dimensional density functions of y and z respectively, and where
D(p1 | p2) :=

Rn p1(x) log p1(x)
p2(x) dx.

246
A. Lindquist
In fact, it was shown in [33] that, if y and z have spectral densities Φ and ˆΦ, respectively,
then
D(y∥z) = 1
2
 π
−π
3
(Φ −ˆΦ) ˆΦ−1 −log(Φ ˆΦ−1)
4 dθ
2π.
(18)
Consequently,
D(y∥z) = 1
2J( ˆΦ−1) −1
2
'
1 +
 π
−π
log Φ dθ
2π
(
,
(19)
where the last integral is constant.
Given the process y, consider the problem to ﬁnd the minimum divergence D(y∥z)
over all z with a spectral density ˆΦ ∈F. Then we have established that this minimum is
attained precisely when ˆΦ−1 is the unique minimizer of J in Theorem 1, which in turn
is the minimum prediction-error estimate in the model class F.
Next, suppose that we have a ﬁnite sample record
{y0, y1, . . . , yN}
(20)
of the process y and an estimate ΦN of Φ based on (20) that is consistent in the sense
that limN→∞ΦN(eiθ) = Φ(eiθ) with probability one for almost all θ ∈[−π, π]. The
periodogram
ΦN(eiθ) = 1
N
#####
N

t=0
e−iθtyt
#####
2
.
is one such estimate of Φ. Then, under some mild technical assumptions,
JN( ˆΦ) := 1
2
 π
−π
3
ΦN(eiθ) ˆΦ(eiθ)−1 + log ˆΦ(eiθ)
4 dθ
2π
(21)
tends to J( ˆΦ−1) as N →∞. The functional JN(Ψ) is known as the Whittle log-
likelihood, and it is a widely used approximation of −log LN, where LN( ˆΦ) is the like-
lihood function. In fact, JN( ˆΦ) and LN( ˆΦ) tend to the same limit J( ˆΦ−1) as N →∞.
5
Prediction-Error Approximation by Analytic Interpolation
Let Φ be the given (or estimated) spectral density deﬁned as above. Then, by the Her-
glotz formula,
F(z) =
 π
−π
eiθ + z
eiθ −z Φ(eiθ) dθ
2π
(22)
is the positive real part of Φ. More precisely, F is the unique function in H(D) such
that F(0) is real and
Φ(eiθ) = Re{F(eiθ)}.
(23)
Now, let us select a number of points
z0, z1, . . . , zn
(24)

Prediction-Error Approximation by Convex Optimization
247
in the unit disc D. Then, in view of (22),
F(zk) =
 π
−π
gk(z)Φ(eiθ) dθ
2π ,
where
gk(z) = z + zk
z −zk
.
(25)
Therefore, if the points (24) are distinct, we may choose g0, g1, . . . , gn as our basis
functions, and then
F(zk) = ck,
k = 0, 1, . . ., n,
where
ck :=
 π
−π
gk(eiθ)Φ(eiθ) dθ
2π ,
k = 0, 1, . . . , n.
(26)
If (24) are not distinct, we modify g0, g1, . . . , gn in the following way to make them lin-
early independent. If zk = zk+1 = · · · = zk+m−1, then gk, . . . , gk+m−1 are replaced
by
gk(z) = z + zk
z −zk
,
gk+1(z) =
2z
(z −zk)2 ,
. . . ,
gk+m−1(z) =
2z
(z −zk)m . (27)
Then, differentiating (22), we have the modiﬁed interpolation conditions
F(zk) = ck,
dF
dz (zk) = ck+1,
. . . ,
1
(m −1)!
d(m−1)F
dz(m−1) (zk) = ck+m−1.
Now, given the points (24), let F(z0, z1, . . . , zn) be the class of all spectral densi-
ties ˆΦ with positive real part ˆF of degree at most n and satisfying the interpolation
conditions
ˆF(zk) = ck
(28a)
for distinct points and
ˆF(zk) = ck,
d ˆF
dz (zk) = ck+1,
. . . ,
1
(m −1)!
d(m−1) ˆF
dz(m−1) (zk) = ck+m−1, (28b)
if zk = zk+1 = · · · = zk+m−1, where c0, c1, . . . , cn are given by (26). In particular,
ˆΦ(zk) = Φ(zk),
k = 0, 1, . . ., n
(29)
for all ˆΦ ∈F(z0, z1, . . . , zn), where some of the conditions (29) may be repeated (in
case of multiple points).
With the basis (4) chosen as above, the minimum prediction-error approximation
in the model class F(z0, z1, . . . , zn) deﬁned by these functions is as described in the
following theorem, which now is a direct consequence of Theorems 1 and 2.
Theorem 4. The minimum prediction-error approximation of Φ in the class F(z0,
z1, . . . , zn) is the unique ˆΦ ∈F(z0, z1, . . . , zn) that minimizes the entropy gain

248
A. Lindquist
 π
−π
log ˆΦ dθ
2π ,
or, dually, the ˆΦ that minimizes (7), where g0, g1, . . . , gn are given by (25), or (27) for
multiple points.
It follows from Theorem 1 that all ˆΦ ∈F(z0, z1, . . . , zn), and in particular the optimal
one, has (spectral) zeros that coincide with z0, z1, . . . , zn and hence with the interpo-
lation points. Recently, Sorensen [31] has developed an efﬁcient algorithm for solving
large problems of this type. In [15] we point out the connection between this approach,
initiated by Antoulas [3], and our theory for analytic interpolation with degree con-
straints [10, 11, 12, 13, 14, 16]. We show that a better spectral ﬁt can often be obtained
by choosing a nontrivial weight P in the objective function (16). This corresponds to
preﬁltering; see Remark 1.
An important question in regard to the application of Theorem 4 to system identiﬁ-
cation is how to choose the interpolation points z0, z1, . . . , zn. Here (29) could serve as
an initial guide. However, a more soﬁsticated procedure is proposed in [20].
6
Conclusion
In this paper we have shown that in large model classes of ARMA models, as well as
in some model classes of nonrational functions, prediction-error approximation leads
to convex optimization. The connections to Kullback-Leibler and maximum-likelihood
criteria have been described. Model classes deﬁned in terms of interpolation conditions
have also been considered, connecting to literature in numerical linear algebra. Gen-
eralizations to the multivarable case should be straight-forward relying on mutivarable
versions [5,22] of the theory of analytic interpolation and generalized moment problems
with complexity constraints.
References
1. Ahlfors LV (1953) Complex Analysis. McGraw-Hill,
2. Anderson BDO, Moore JB, Hawkes RM (1978) Automatica 14: 615–622
3. Antoulas AC (2005) Systems and Control Letters 54: 361–374
4. Blomqvist, A (2005) A Convex Optimization Approach to Complexity Constrained Ana-
lytic Interpolation with Applications to ARMA Estimation and Robust Control. PhD Thesis,
Royal Institute of Technology, Stockholm, Sweden
5. Blomqvist A, Lindquist A, Nagamune R (2003) IEEE Trans Autom Control 48: 2172–2190
6. Blomqvist A, Wahlberg B (2007) IEEE Trans Autom Control 55: 384–389
7. Byrnes CI, Enqvist P, Lindquist A (2002) SIAM J. Control and Optimization 41: 23–59
8. Byrnes CI, Gusev SV, Lindquist A (1998) SIAM J. Contr. and Optimiz. 37: 211–229
9. Byrnes CI, Gusev SV, Lindquist A (2001) SIAM Review 43: 645–675
10. Byrnes CI, Georgiou TT, Lindquist A (2001) IEEE Trans Autom Control 46: 822–839
11. Byrnes CI, Georgiou TT, Lindquist A (2000) IEEE Trans. on Signal Processing 49: 3189–
3205

Prediction-Error Approximation by Convex Optimization
249
12. Byrnes CI, Lindquist A (2003) A convex optimization approach to generalized moment prob-
lems. In: Hashimoto K, Oishi Y, Yamamoto Y (eds) Control and Modeling of Complex
Systems: Cybernetics in the 21st Century. Birkh¨auser, Boston Basel Berlin
13. Byrnes CI, Georgiou TT, Lindquist A, Megretski (2006) Trans American Mathematical So-
ciety 358: 965–987
14. Byrnes CI, Lindquist A (2006) Integral Equations and Operator Theory 56: 163–180
15. Fanizza G, Karlsson J, Lindquist A, Nagamune R (2007) Linear Algebra and Applications.
To be published
16. Georgiou TT, Lindquist A (2003) IEEE Trans. on Information Theory 49: 2910–2917
17. Georgiou TT, Lindquist A (2007) IEEE Trans Autom Control. To be published
18. Good, IJ (1963) Annals Math. Stat. 34: 911–934
19. Heuberger PSC, Van den Hof PMJ, Szab´o Z (2001) Proc. 40th IEEE Conf. Decision and
Control, Orlando, Florida, USA: 3673–3678
20. Karlsson J, Lindquist A (2007) Submitted for publication
21. Kullback S (1959) Information Theory and Statistics. John Wiley, New York
22. Kuroiwa Y, Lindquist A (2007) Proc 2007 Decision and Control Conference. Submitted for
publication
23. Lindquist A, Picci G (1985) SIAM J Control Optim 23: 809–857
24. Lindquist A, Picci G (1995) Stochastics 15: 1–50
25. Lindquist A, Picci G (1991) J Math Systems Estim Control 1: 241–333
26. Lindquist A, Picci G (1996) Automatica 32:709–733
27. Lindquist A, Picci G (2007) Linear Stochastic Systems: A Geometric Approach to Modeling,
Estimation and Identiﬁcation. To appear
28. Ljung L (1987) System Identiﬁcation: Theory for the User. Prentice Hall, Englewood Cliffs
29. Picci G (1976) Proc. IEEE 64: 112–122
30. S¨oderstr¨om T, Stoica P (1989) System Identiﬁcation. Prentice Hall, New York
31. Sorensen DC (2005) Systems and Control Letters 54: 347-360
32. Stoica P, Moses R (1997) Introduction to Spectral Analysis. Prentice Hall, Upper Saddle
River, NJ
33. Stoorvogel AA, van Schuppen JH (1996) System identiﬁcation with information theoretic
criteria. In: Bittanti S, Picci G (eds) Identiﬁcation, Adaptation, Learning: The Science of
learning Models from Data. Springer, Berlin Heidelberg
34. Wahlberg B (1991) IEEE Trans Autom Control 36: 551–562
35. Wahlberg B (1994) IEEE Trans Autom Control 39: 1276–1282

Patchy Solutions of Hamilton-Jacobi-Bellman Partial
Differential Equations
Carmeliza Navasca1 and Arthur J. Krener2,⋆
1 ETIS Lab - UMR CNRS 8051, 6, avenue du Ponceau, 95014 Cergy-Pontoise, France
cnavasca@gmail.com
2 Department of Applied Mathematics, Naval Postgraduate School,
Monterey, CA 93943-5216, USA
ajkrener@nps.edu
This paper is dedicated to our esteemed colleague and good friend Giorgi Picci on the
occasion of his sixty ﬁfth birthday.
1
Hamilton Jacobi Bellman PDEs
Consider the optimal control problem of minimizing the integral
 ∞
0
l(x, u) dt
(1)
of a Lagrangian l(x, u) subject to the controlled dynamics
˙x = f(x, u)
x(0) = x0
(2)
where f, l are smooth and l is strictly convex in u ∈IRm for all x ∈IRn.
Suppose the dynamics and Lagrangian have Taylor series expansions about
x = 0, u = 0 of the form
˙x = Fx + Gu + f [2](x, u) + f [3](x, u) + . . .
(3)
l(x, u) = 1
2 (x′Qx + u′Ru) + l[3](x, u) + l[4](x, u) + . . .
(4)
where [d] indicates terms of degree d in the power series. We shall say that the optimal
control problem is nice if F, G is stabilizable and Q
1
2 , F is detectable.
A special case of this optimal control problem is the linear quadratic regulator
(LQR) where one seeks to minimize a quadratic cost
 ∞
0
1
2 (x′Qx + u′Ru) dt
⋆Research supported in part by NSF grant 0505677.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 251–270, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

252
C. Navasca and A.J. Krener
subject to linear dynamics
˙x = Fx + Gu
If this is nice then there is a unique nonnegative deﬁnite solution to the algebraic
Riccati equation
0 = F ′P + PF + Q −PGR−1G′P
(5)
that gives the optimal cost
π(x0) = 1
2(x0)′Px0 = min
 ∞
0
1
2 (x′Qx + u′Ru) dt
(6)
Furthermore the optimal control is given in feedback form
u(t) = κ(x(t)) = Kx(t)
where
K = −R−1G′P
(7)
and the closed loop dynamics
˙x = (F + GK) x
(8)
is exponentially stable.
Returning to the nonlinear problem, it is well-known that if it admits a smooth
optimal cost π(x) and a smooth optimal feedback u = κ(x) locally around x = 0 then
they must satisfy the Hamilton Jacobi Bellman (HJB) PDE
0 = min
u
∂π
∂x(x)f(x, u) + l(x, u)
κ(x) = arg min
u
∂π
∂x(x)f(x, u) + l(x, u)
We shall assume that ∂π
∂x(x)f(x, u) + l(x, u) is strictly convex in u locally around
x = 0, u = 0 then the HJB PDE can be rewritten as
0 = ∂π
∂x(x)f(x, κ(x)) + l(x, κ(x))
0 = ∂π
∂x(x)∂f
∂u(x, κ(x)) + ∂l
∂u(x.κ(x))
(9)
Al’brecht [1] has shown that for nice optimal control problems, the Hamilton Jacobi
Bellman PDE can be approximately solved by Taylor series methods locally around
the origin. Lukes [14] showed that under suitable conditions this series expansion
converges to the true solution. The method has been implemented on examples by
Garrard and Jordan [7], Yoshida and Loparo [22], Spencer, Timlin, Sain and Dyke [20]

Patchy Solutions
253
and others.
We have implemented it in the Nonlinear Systems Toolbox [11], a
MATLAB based package.
Assume the dynamics and Lagrangian have power series expansions (3, 4). We as-
sume that the unknowns,the optimal cost and optimal feedback,have similar expansions.
π(x) = 1
2x′Px + π[3](x) + π[4](x) + . . .
κ(x) = Kx + κ[2](x) + κ[3](x) + . . .
(10)
We plug these into the HJB PDE (9) and extract terms of lowest degree to obtain the
equations
0 = x′ (F ′P + PF + Q −K′RK) x
0 = x′ (PG + K′R)
Notice the ﬁrst equation is quadratic x and the second is linear in x. More importantly
the ﬁrst equation is linear in the unknown P but quadratic in the unknown K while the
second is linear in both the unknowns. They lead to the familiar equations (5, 7) .
Having found P, K, we extract the next lowest terms from (9) and obtain
0 = ∂π[3]
∂x (x)(F + GK)x + x′Pf [2](x, Kx) + l[3](x, Kx)
0 = ∂π[3]
∂x (x)G + x′P ∂f [2]
∂u (x, Kx) + ∂l[3]
∂u (x, Kx) +
1
κ[2](x)
2′
R
(11)
Notice several things. The ﬁrst equation is cubic in x and the second is quadratic.
The equations involve the previously computed P, K. The unknowns π[3](x); κ[2](x)
appear linearly in these equations. The equations are triangular, κ[2](x) does not appear
in the ﬁrst one. If we can solve the ﬁrst for π[3](x) then clearly we can solve the second
for κ[2](x) as R is assumed to be invertible.
To decide the solvability of the ﬁrst we study the linear operator
π[3](x) →∂π[3]
∂x (x)(F + GK)x
(12)
from cubic polynomials to cubic polynomials.
Its eigenvalues are of the form
λi + λj + λk where λi, λj, λk are eigenvalues of F + GK. A cubic resonance occurs
when such a sum equals zero. But all the eigenvalues of F + GK are in the open left
half plane so there are no cubic resonances. Hence the linear operator (12) is invertible
and (11) is solvable.
The higher degree terms are found in a similar fashion. Suppose that π(x) and
κ(x) are the expansions of the optimal cost and optimal feedback through degrees d
and d −1 respectively. We wish to ﬁnd the next terms π[d+1](x) and κ[d](x). We
plug π(x) + π[d+1](x) and κ(x) + κ[d](x) into the HJB PDEs (9) and extract terms of
degrees d + 1 and d respectively to obtain

254
C. Navasca and A.J. Krener
0 = ∂π[d+1]
∂x
(x) (F + GK) x +
∂π
∂x(x)f(x, κ(x))
[d+1]
+ x′PGκ[d](x)
+ (l(x, κ(x)))[d+1] + x′K′Rκ[d](x)
0 = ∂π[d+1]
∂x
(x)G +
∂π
∂x(x)∂f
∂u(x, κ(x))
[d]
+
 ∂l
∂u(x, κ(x))
[d]
+
1
κ[d](x)
2′
R
where (·)[d] is the degree d part of the enclosed.
Because of (7) κ[d](x) drops out of the ﬁrst of these equations yielding
0 = ∂π[d+1]
∂x
(x) (F + GK) x +
∂π
∂x(x)f(x, κ(x))
[d+1]
+ (l(x, κ(x)))[d+1]
(13)
Consider the linear operator from degree d+1 polynomials to degree d+1 polynomials
π[d+1](x) →∂π[d+1]
∂x
(x) (F + GK) x
Its eigenvalues are of the form λi1 +. . .+λid+1 where λj is an eigenvalue of F +GK. A
resonance of degree d + 1 occurs when such a sum equals zero. But all the eigenvalues
of F +GK are in the open left half plane so there are no resonances of degree d+1 and
we can solve (13) for π[d+1](x). Then the second equation can be solved for κ[d](x)
κ[d](x) = −R−1

∂π[d+1]
∂x
(x)G +
1
∂π
∂x(x) ∂f
∂u(x, κ(x))
2[d]
+

 ∂l
∂u(x, κ(x))
[d]′
(14)
We have developed MATLAB based software to compute the series solutions to the
HJB PDE [11]. In principle the computation can be carried out to any degree in any
number of variables but there are practical limitations in execution time and memory.
This is the familiar curse of dimensionality. There are n+d−1 choose d monomials of
degree d in n variables. Still the software is quite fast. For example we are able to solve
an HJB PDE in six states and one control to degree six in the optimal cost and degree
ﬁve in optimal feedback in less than 30 seconds on a ﬁve year old laptop (500 MHz)
with limited memory (512 MB). There are 462 monomials of degree 6 in 6 variables.
The main problem with the power series approach is that is local in nature. The
power series solution to the HJB PDE is very close to the true solution in some neigh-
borhood of the origin. Increasing the degree of the approximation may increase the
accuracy but does not necessarily yield a larger domain of validity of the approximation.
Complicating this is the fact that in general HJB PDEs do not have globally smooth
solutions. The underlying optimal control problem may have conjugate points or focal
points. It is for this reason that the theory of viscosity solutions was developed [4], [5].

Patchy Solutions
255
2
Other Approaches
There are several other approaches to solving HJB PDEs, and a large literature, for
example see [3], [6], [13], [9], [10], [16], [18], [19], [21] and their references. One
approach is to discretize the underlying optimal control problem and convert it into a
nonlinear program in discrete time and space. But the curse of dimensionality rears its
ugly head. Consider the optimal control problem generating the above mentioned HJB
PDE. If each of the six states is discretized into 10 levels then there would 1,000,000
discrete states.
Other approaches involve discretizing the HJB PDE with subtle tricks so that the
algorithm converges to its viscosity solution. This also suffers from the curse of dimen-
sionality. The fast sweeping and marching method (Tsitsiklis [21], Osher et al. [16],
[9], [10] and Sethian [19]) are ways to lessen this curse. It takes advantage of the fact
that an HJB PDE has characteristics. These are the closed loop optimal state trajectories
that converge to the origin as t →∞. The fast marching method grows the solution out
from the origin discrete state by discrete state in reverse time by computing the solution
at new discrete states that are on the boundary of the already computed solution.
3
New Approach
The new approach that we are proposing is a extension of the power series method
of Al’brecht [1],
the Cauchy-Kovalevskaya technique [8],
the fast marching
method [21], [19] and the patchy technique of Ancona and Bressan [2].
It is
similar to that of Navasca and Krener [15]. Suppose we have computed a power series
solution to some degree d + 1 of an HJB PDE in a neighborhood of the origin by the
method of Al’brecht. We verify that this power series solution is valid in some sublevel
set of the computed optimal cost function by checking how well it satisﬁes the HJB
PDE on the level set that is its boundary. At the very least it should be a valid Lyapunov
function for the dynamics with the computed optimal feedback on the sublevel set.
Also the computed closed loop dynamics should point inward on the boundary of the
sublevel set, in other words, the computed backward characteristics of the HJB PDE
should radiate outward. This sublevel set is called the zeroth patch.
Then we pick a point on the boundary of the zeroth patch and assume the optimal
cost and optimal feedback have a power series expansion around that point. We already
know the partial derivatives of these in directions tangent to the boundary of the patch.
Using a technique similar to that of Cauchy-Kovalevskaya, we can compute the other
partial derivatives from the HJB PDE because we have assumed that the computed
closed loop dynamics is not tangent to the level set, it points inward. In this way
we compute the solution in a patch that overlaps the zeroth patch. Call this the ﬁrst
patch. Again we can estimate the size of this patch by how well the computed solution
satisﬁes the HJB PDE.
It is not essential that the dynamics f and Lagrangian l be smooth at the boundary
of zeroth patch (or other patches). If they are not smooth at the boundary we use their
derivatives to the outside of the zeroth patch. This is a form of upwind differentiation
We do assume that they are smooth at the origin but they can have discontinuities

256
C. Navasca and A.J. Krener
or corners elsewhere. If they do, we choose the patches so that these occur at patch
boundaries. In this way it is an upwinding scheme because the closed loop dynamics,
the characteristic curves of the PDE point inward on the boundary of the zeroth patch.
When computing the solution on the second patch we use the derivative information in
the backward characteristic direction.
Then we choose another point that is on the boundary of the zeroth patch but not in
the ﬁrst patch and repeat the process. In this way we grow a series of patches encircling
the sublevel set. The validity of the computed solution on each patch is veriﬁed via
how well it solves the HJB PDE. On the boundary between adjacent patches we may
have two possible closed loop vector ﬁelds.
If the angle between them is obtuse,
the two trajectories are diverging, then there is no problem and we can choose either
when on the boundary between the patches. If the angle is acute then there may be a
sliding regime and another patch in between may be needed. Another possibility is to
blend the computed costs across the patch boundary. This will cause a blending of the
computed feedback. (These are research questions.)
After the original sublevel set has been completely encircled by new patches we
have piecewise smooth approximations to the optimal cost and optimal feedback. We
choose a higher sublevel set of the computed cost that is valid for all the patches and
repeat the process.
The patches are ordered and the approximate solution to the problem at x is deﬁned
to be the approximate solution in the lowest ordered patch containing x.
The patches can also be deﬁned a priori, this would simplify the method but might
lead to unsatisfactory solutions if they are chosen too large or long computation times
if they are chosen too small.
Of course there is the problem of shocks caused by conjugate or focal points. The
assumptions that we make ensure that these do occur at the origin, the true solution
is smooth around there. But that does not mean they will not occur elsewhere. When
possible we will choose the patches so that they occur at patch boundaries. Not a lot is
known about the types of singularities that can occur and how they affect the optimal
feedback. One of the goals of our future research project is to better understand these
issues.
We expect most of the time to compute the expansions to degree four for the optimal
cost and degree three for the optimal feedback. But if the dynamics and/or Lagrangian
is not sufﬁciently smooth we might compute to degrees two and one respectively.
As we noted before in many engineering problems stability of the closed loop
dynamics is the principle goal. There may be considerable freedom in choosing the
Lagrangian and so a smooth Lagrangian may be chosen. In many problems there are
state and/or control constraints. Then the Lagrangian can be chosen so that the solution
does not violate the constraints.
In the following sections we discuss the method in more detail.
4
One Dimensional HJB PDEs
For simplicity we consider an optimal control problem (1, 2) where the state dimension
n = 1 and the control dimension m = 1. Occasionally to simplify the calculations we

Patchy Solutions
257
shall assume that the dynamics is afﬁne in the control and the Lagrangian is quadratic
in the control
f(x, u) = f(x) + g(x)u
l(x, u) = q(x) + s(x)u + 1
2r(x)u2
(1)
with r(x) > 0. The method works for more general f, l but it is more complicated. In
any case we shall assume that l(x, u) = 0 iff x = 0, u = 0.
We assume that the degree d + 1 polynomial π0(x) and the degree d polyno-
mial κ0(x), computed by the power series method of Al’brecht described above,
approximately solves this problem in a neighborhood of x = 0. We plug the power
series expansions of π0, κ0 into the right side of the ﬁrst HJB equation with the exact
dynamics f and exact Lagrangian l and compute the local error
ρ0(x) = ∂π0
∂x (x)f(x, κ0(x)) + l(x.κ0(x))
(2)
or relative local error
ρ0
r(x) = ρ0(x)
π0(x).
(3)
Of course the local error and some of its derivative will (nearly) vanish at x = 0 but
it will generally be nonzero for x ̸= 0. Suppose ρ0
r(x) is small on some interval [0, x1]
then we accept the power series solution π0(x), κ0(x), on this interval. We would
like to continue the solution to the right of x1. Let π1(x), κ1(x) denote this continued
solution. We have an approximation to the optimal cost π0(x1) and optimal feedback
κ0(x1) at x1, we accept the former by setting π1(x1) = π0(x1) but not the latter. We
shall compute u1 = κ1(x1).
We evaluate the HJB PDE (9) at x1 using the assumption (1) to obtain
0 = ∂π1
∂x (x1)f(x1, u1) + q(x1) + s(x1)u1 + 1
2r(x1)

u12
(4)
0 = ∂π1
∂x (x1)g(x1) + s(x1) + r(x1)u1
(5)
We can solve the second equation for u1 and plug it into the ﬁrst to obtain a quadratic
in ∂π1
∂x (x1). We set u1 to be the root nearer to κ0(x1). In this way we ﬁnd ∂π1
∂x (x1)
and u1.
If assumption (1) does not hold then we must solve a coupled pair of nonlinear
equations for the unknowns ∂π1
∂x (x1) and u1. This can be done by a couple of iterations
of Newton’s method as we already have good starting guesses, ∂π0
∂x (x1) and κ0(x1).
Since we assumed that l(x, u) = 0 iff x = 0, u = 0 we conclude from (4) that
f(x1, u1) ̸= 0.
To ﬁnd ∂2π1
∂x2 (x1) and ∂κ1
∂x (x1) we proceed as follows. Differentiate the HJB PDEs
(9) with respect to x at x1 to obtain

258
C. Navasca and A.J. Krener
0 = ∂2π1
∂x2 (x1)f(x1, u1) + ∂π1
∂x (x1)
∂f
∂x(x1, u1) + ∂f
∂u(x1, u1)∂κ
∂x(x1)

+ ∂l
∂x(x1, u1) + ∂l
∂u(x1, u1)∂κ
∂x(x1)
(6)
0 = ∂2π1
∂x2 (x1)∂f
∂u(x1, u1) + ∂π1
∂x (x1) ∂2f
∂x∂u(x1, u1) +
∂2l
∂x∂u(x1, u1)
+
∂π1
∂x (x1)∂2f
∂u2 (x1, u1) + ∂2l
∂u2 (x1, u1)
 ∂κ1
∂x (x1)
(7)
Because of (4), the ﬁrst equation (6) reduces to
0 = ∂2π1
∂x2 (x1)f(x1, u1) + ∂π1
∂x (x1)∂f
∂x(x1, u1) + ∂l
∂x(x1, u1)
(8)
Notice the unknown ∂κ1
∂x (x1) does not appear in this equation so we can easily solve
for the unknown ∂2π1
∂x2 (x1) since f(x1, u1) ̸= 0. Because of the assumptions (1) the
second equation reduces to
0 = ∂2π1
∂x2 (x1)g(x1) + ∂π1
∂x (x1)∂g
∂x(x1)
+ ∂s
∂x(x1) + ∂r
∂x(x1)u1 + r(x1)∂κ1
∂x (x1)
By assumption r(x1) > 0 so we can solve the second equation for other unknown
∂κ1
∂x (x1).
To ﬁnd the next unknowns ∂3π1
∂x3 (x1) and ∂2κ1
∂x2 (x1) we proceed in a similar fashion.
We differentiate HJB PDEs (9) twice with respect to x and evaluate at x1 assuming (1)
to obtain two equations,
0 = ∂3π1
∂x3 (x1)f(x1, u1) + 2∂2π1
∂x2 (x1)∂f
∂x(x1, u1)
+∂π1
∂x (x1)∂2f
∂x2 (x1, u1) + ∂2l
∂x2 (x1, u1)
+

∂2π1
∂x2 (x1)∂f
∂u(x1, u1) + ∂π1
∂x (x1) ∂2f
∂x∂u(x1, u1) +
∂2l
∂x∂u(x1, u1)

∂κ1
∂x (x1)
0 = ∂3π1
∂x3 (x1)∂f
∂u(x1, u1) + 2∂2π1
∂x2 (x1) ∂2f
∂x∂u(x1, u1)
+∂π1
∂x (x1) ∂3f
∂x2∂u(x1, u1) +
∂3l
∂x2∂u(x1, u1)
+2

∂2π1
∂x2 (x1)∂2f
∂u2 (x1, u1) + ∂π1
∂x (x1) ∂3f
∂x∂u2 (x1, u1) +
∂3l
∂x∂u2 (x1, u1)

∂κ1
∂x (x1)
+

∂π1
∂x (x1)∂3f
∂u3 (x1, u1) + ∂3l
∂u3 (x1, u1)
 
∂κ1
∂x (x1)
2
+

∂π1
∂x (x1)∂2f
∂u2 (x1, u1) + ∂2l
∂u2 (x1, u1)

∂2κ1
∂x2 (x1)

Patchy Solutions
259
The unknown ∂2κ1
∂x2 (x1) does not appear in the ﬁrst equation because of (4). Since
f(x1, u1) ̸= 0 we can solve this equation for the unknown ∂3π1
∂x3 (x1) The second is
linear in both unknowns. Under the assumptions (1) the second equation reduces to
0 = ∂3π1
∂x3 (x1)g(x1) + 2∂2π1
∂x2 (x1)∂g
∂x(x1)
+∂π1
∂x (x1)∂2g
∂x2 (x1) + ∂2s
∂x2 (x1) + ∂2r
∂x2 (x1)u1
+2 ∂r
∂x(x1)∂κ1
∂x (x1) + r(x1)∂2κ1
∂x2 (x1)
and because r(x1) > 0 it is readily solvable for the other unknown ∂2κ1
∂x2 (x1).
To ﬁnd the next unknowns ∂4π1
∂x4 (x1) and ∂3κ1
∂x3 (x1) we differentiate HJB PDE (9)
three times with respect to x and evaluate at x1 assuming (1) to obtain the two equations,
0 = ∂4π1
∂x4 (x1)f(x1, u1)) + 3∂3π1
∂x3 (x1)∂f
∂x(x1, u1) + 3∂2π1
∂x2 (x1)∂2f
∂x2 (x1, u1)
+∂π1
∂x (x1)∂3f
∂x3 (x1, u1) + ∂3l
∂x3 (x1, u1)
+2

∂3π1
∂x3 (x1)∂f
∂u(x1, u1) + 2∂2π1
∂x2 (x1) ∂2f
∂x∂u(x1, u1)
+∂π1
∂x (x1) ∂3f
∂x2∂u(x1, u1) +
∂3l
∂x2∂u(x1, u1)

∂κ1
∂x (x1)
+

∂2π1
∂x2 (x1)∂2f
∂u2 (x1, u1) + ∂π1
∂x (x1) ∂3f
∂x∂u2 (x1, u1)
+
∂3l
∂x∂u2 (x1, u1)

∂κ1
∂x (x1)
2
+

∂2π1
∂x2 (x1)∂f
∂u(x1, u1) + ∂π1
∂x (x1) ∂2f
∂x∂u(x1, u1)
+ ∂2l
∂x∂u(x1, u1)

∂2κ1
∂x2 (x1)
0 = ∂4π1
∂x4 (x1)∂f
∂u(x1, u1) + 3∂3π1
∂x3 (x1) ∂2f
∂x∂u(x1, u1) + 3∂2π1
∂x2 (x1) ∂3f
∂x2∂u(x1, u1)
+∂π1
∂x (x1) ∂4f
∂x3∂u(x1, u1) +
∂4l
∂x3∂u(x1, u1)
+3

∂3π1
∂x3 (x1)∂2f
∂u2 (x1, u1) + 2∂2π1
∂x2 (x1) ∂3f
∂x∂u2 (x1, u1)
+∂π1
∂x (x1)
∂4f
∂x2∂u2 (x1, u1) +
∂4l
∂x2∂u2 (x1, u1)

∂κ1
∂x (x1)
+3

∂2π1
∂x2 (x1)∂2f
∂u2 (x1, u1) + ∂π1
∂x (x1) ∂3f
∂x∂u2 (x1, u1) +
∂3l
∂x∂u2 (x1, u1)

∂2κ1
∂x2 (x1)

260
C. Navasca and A.J. Krener
+3

∂2π1
∂x2 (x1)∂3f
∂u3 (x1, u1) + ∂π1
∂x (x1) ∂4f
∂x∂u3 (x1, u1) +
∂4l
∂x∂u3 (x1, u1)
 
∂κ1
∂x (x1)
2
+3

∂π1
∂x (x1)∂3f
∂u3 (x1, u1) + ∂3l
∂u3 (x1, u1)

∂κ1
∂x (x1)∂2κ1
∂x2 (x1)
+

∂π1
∂x (x1)∂4f
∂u4 (x1, u1) + ∂4l
∂u4 (x1, u1)
 
∂κ1
∂x (x1)
3
+

∂π1
∂x (x1)∂2f
∂u2 (x1, u1) + ∂2l
∂u2 (x1, u1)

∂3κ1
∂x3 (x1)
We expect to stop at degree four most of the time, The assumptions (1) greatly
simplify the last equation,
0 = ∂4π1
∂x4 (x1)g(x1) + 3∂3π1
∂x3 (x1)∂g
∂x(x1) + 3∂2π1
∂x2 (x1)∂2g
∂x2 (x1)
+∂π1
∂x (x1)∂3g
∂x3 (x1) + ∂3s
∂x3 (x1) + ∂3r
∂x3 (x1)u1 + r(x1)∂3κ1
∂x3 (x1)
Notice the similarities with Al’brecht’s method.
We successively solve for
∂d+1π
∂xd+1 (x1) and ∂dκ1
∂xd (x1) for d = 0, 1, 2, . . .. At the lowest level the equations are
coupled and if (1) holds we must solve a quadratic equation similar to a Riccati
equation. At the higher levels the equations are linear and triangular in the unknowns.
Once we have computed a satisfactory approximate solution on the interval [x1, x2]
we can repeat the process and ﬁnd an approximate solution to the right of x2.
5
One Dimensional Example
Consider the simple LQR of minimizing
1
2
 ∞
0
z2 + u2 dt
subject to
˙z = z + u
Here both z and u are one dimensional.
The Riccati equation (5) is
0 = 2P + 1 −P 2
and its unique nonnegative solution is P = 1 +
√
2. Therefore the optimal cost and
optimal feedback are
π(z) = 1 +
√
2
2
z2
κ(z) = −(1 +
√
2)z

Patchy Solutions
261
The optimal closed loop dynamics is
˙z = −
√
2z
After the change of coordinates
z = sin x
then the LQR become the nonlinear optimal control problem of minimizing
1
2
 ∞
0
sin2 x + u2 dt
subject to
˙x = sin x + u
cos x
We know that the optimal cost and optimal feedback is
π(x) = 1 +
√
2
2
sin2 x
κ(z) = −(1 +
√
2) sin x
Notice that the optimal cost is even and the optimal feedback is odd. We can compare
it with the solution computed by the method described above.
The computed solution on the interval [0, 0.9] is the one of Al’brecht.
As we
compute the solution for larger x, the size of the patches decreases because the change
of coordinates is becoming more nearly singular as we approach π
2 . There are 15
patches. The relative error tolerance is 0.5.
6
HJB PDEs in Higher Dimensions
In this section we generalize the proposed scheme to higher dimensional state spaces
n ≥1. For notational simplicity we shall assume that the control is one dimensional
m = 1, generalizing to higher control dimensions causes no conceptual difﬁculty. We
also make the simplifying assumptions that the dynamics is afﬁne in the control and
the cost is quadratic in the control of the form
˙x = f(x) + g(x)u
l(x, u) = q(x) + r(x)u2/2
The method does not require these assumptions but they do greatly simplify it.
Suppose we have computed the Al’brecht solution π0(x), κ0(x) to the HJB PDE (9)
in some neighborhood of the origin. We check the local error ρ0(x) (2) or relative local
error (3) and decide that it is a reasonable solution in some sublevel set

x : π0(x) ≤c
	
which we call the zeroth patch P0. We choose x1 on the level set π(x1) = c and seek
to extend the solution in a patch around x1. To do so we need to estimate the low
degree partial derivatives of the optimal cost and optimal feedback at x1.

262
C. Navasca and A.J. Krener
Fig. 1. True cost (solid) and the computed cost (dash-dot)
Fig. 2. Relative error between true cost and the computed cost
We assume that the Al’brecht closed loop dynamics is transverse to the boundary of
the sublevel set and points inward
∂π0
∂x (x1)f(x1, κ0(x1)) < 0
We accept that π1(x1) = π0(x1) but we will compute a new u1 = κ1(x1) probably
different from κ0(x1).
The HJB equations become
0 = ∂π
∂xσ
(x) (fσ(x) + gσ(x)κ(x)) + q(x) + r(x) (κ(x))2 /2
(1)
0 = ∂π
∂xσ
(x)gσ(x) + r(x)κ(x)
(2)

Patchy Solutions
263
Fig. 3. True feedback (solid) and the computed feedback (dash-dot)
Fig. 4. Relative error between the true feedback and the computed feedback
We choose the index k that maximizes
|fk(x1) + gk(x1)κ0(x1)|
For notational convenience we assume that k = n.
We assume that
π1(x1) = π0(x1)
∂π1
∂xσ
(x1) = ∂π0
∂xσ
(x1)
for 1 ≤σ < n. Then we can solve the second HJB equation for κ(x1) and plug it into
the ﬁrst to get a quadratic equation in the other unknown
0 = a
∂π1
∂xn
(x1)
2
+ b ∂π1
∂xn
(x1) + c

264
C. Navasca and A.J. Krener
where
a =
1
2r(x1)(gn(x1))2
b =
1
r(x1)gn(x1)
n−1

σ=1
∂π1
∂xσ
(x1)gσ(x) −fn(x1)
c =
1
2r(x1)
n−1

σ=1
n−1

τ=1
∂π1
∂xσ
(x1)gσ(x1)∂π1
∂xτ
(x1)gτ(x1)
−q(x1) −
n−1

σ=1
∂π1
∂xσ
(x1)fσ(x1)
Assuming this equation has real roots, we set ∂π1
∂xn (x1) to be the root closest to
∂π0
∂xn (x1) and we solve for κ(x1),
κ(x1) = −
1
r(x1)
n

σ=1
∂π1
∂xσ
(x1)gσ(x1)
The next unknowns in a power series expansion of the optimal cost and feedback
around x1 are
∂2π1
∂xi∂xj (x1) and ∂κ1
∂xi (x1) for 1 ≤i ≤j ≤n. We assume that
∂2π1
∂xi∂xj
(x1) =
∂2π0
∂xi∂xj
(x1)
for 1 ≤i ≤j ≤n −1 and we take the partials of (1, 2) with respect to xi to obtain 2n
equations
0 =
∂2π1
∂xi∂xσ
(x1)

fσ(x1) + gσ(x1)κ1(x1)

(3)
+∂π1
∂xσ
(x1)
∂fσ
∂xi
(x1) + ∂gσ
∂xi
(x1)κ1(x1)

∂q
∂xi
(x1) + 1
2
∂r
∂xi
(x1)(κ1(x1))2
0 =
∂2π1
∂xi∂xσ
(x1)gσ(x1) + ∂π1
∂xσ
(x1)∂gσ
∂xi
(x1)
(4)
+ ∂r
∂xi
(x1)κ1(x1) + r(x1)∂κ1
∂xi
(x1)
for the remaining 2n unknowns. Because of the second HJB equation (2), the ﬁrst n
equations do not contain the unknowns ∂κ1
∂xi (x1) for 1 ≤i ≤n. Moreover the ﬁrst n
equations are decoupled and can be solved one by one

Patchy Solutions
265
∂2π1
∂xi∂xn
(x1) =
−1
fn(x1) + gn(x1)κ1(x1)
×
n−1

σ=1
∂2π1
∂xi∂xσ
(x1)

fσ(x1) + gσ(x1)κ1(x1)

+∂π1
∂xσ
(x1)
∂fσ
∂xi
(x1) + ∂gσ
∂xi
(x1)κ1(x1)

∂q
∂xi
(x1) + 1
2
∂r
∂xi
(x1)(κ1(x1))2

We invoke the summation convention when the range of the sum is from 1 to n,
otherwise we explicitly show the sum.
The remaining n equations are also solvable one by one,
∂κ1
∂xi
(x1) =
−1
r(x1)
 ∂2π1
∂xi∂xσ
(x1)gσ(x1) + ∂π1
∂xσ
(x1)∂gσ
∂xi
(x1) + ∂r
∂xi
(x1)κ1(x1)

Next we ﬁnd the third partials of π1 at x1. We assume that
∂3π1
∂xi∂xj∂xk
(x1) =
∂3π0
∂xi∂xj∂xk
(x1)
for 1 ≤i ≤j ≤k ≤n −1. Equations for the other third partials are obtained by
differentiating the ﬁrst HJB equation (1) with respect to xi and xj for 1 ≤i ≤j ≤n
and evaluating at x1 yielding
0 =
∂3π1
∂xi∂xj∂xσ
(x1)

fσ(x1) + gσ(x1)κ1(x1)

(5)
+ ∂2π1
∂xi∂xσ
(x1)
∂fσ
∂xj
(x1) + ∂gσ
∂xj
(x1)κ1(x1)

+ ∂2π1
∂xj∂xσ
(x1)
∂fσ
∂xi
(x1) + ∂gσ
∂xi
(x1)κ1(x1)

+∂π1
∂xσ
(x1)
 ∂2fσ
∂xi∂xj
(x1) +
∂2gσ
∂xi∂xj
(x1)κ1(x1)

+
∂2q
∂xi∂xj
(x1) + 1
2
∂2r
∂xi∂xj
(x1)(κ1(x1))2
−r(x1)∂κ1
∂xi
(x1)∂κ1
∂xj
(x1)
These are (n + 1)n/2 equations in the (n + 1)n/2 unknowns
∂3π1
∂xi∂xj∂xn (x1) for
1 ≤i ≤j ≤n. They can be solved one by one in lexographic order. The unknowns
∂2κ1
∂xi∂xj (x1) do not appear because of (2) and they are simpliﬁed by (4).
Then we differentiate the second HJB equation (3) with respect to xi and xj for
1 ≤i ≤j ≤n to obtain the (n + 1)n/2 equations

266
C. Navasca and A.J. Krener
0 =
∂3π1
∂xi∂xj∂xσ
(x1)gσ(x1) +
∂2π1
∂xi∂xσ
(x1)∂gσ
∂xj
(x1)
(6)
+ ∂2π1
∂xj∂xσ
(x1)∂gσ
∂xi
(x1) + ∂π1
∂xσ
(x1) ∂2gσ
∂xi∂xj
(x1)
+
∂2r
∂xi∂xj
(x1)κ1(x1) + ∂r
∂xi
(x1)∂κ1
∂xj
(x1)
+ ∂r
∂xj
(x1)∂κ1
∂xi
(x1) + r(x1) ∂2κ1
∂xi∂xj
(x1)
which can be solved one by one for the (n + 1)n/2 unknowns
∂2κ1
∂xi∂xj (x1),
1 ≤i ≤j ≤n.
To ﬁnd the fourth partials of π1 at x1, we assume that
∂4π1
∂xi∂xj∂xk∂xl
(x1) =
∂4π0
∂xi∂xj∂xk∂xl
(x1)
for 1 ≤i ≤j ≤k ≤l ≤n −1. We differentiate the ﬁrst HJB equation (1) with
respect to xi, xj, xk to obtain
0 =
∂4π1
∂xi∂xj∂xk∂xσ
(x1)

fσ(x1) + gσ(x1)κ1(x1)

(7)
+
∂3π1
∂xi∂xj∂xσ
(x1)
∂fσ
∂xk
(x1) + ∂gσ
∂xk
(x1)κ1(x1)

+
∂3π1
∂xi∂xk∂xσ
(x1)
∂fσ
∂xj
(x1) + ∂gσ
∂xj
(x1)κ1(x1)

+
∂3π1
∂xj∂xk∂xσ
(x1)
∂fσ
∂xi
(x1) + ∂gσ
∂xi
(x1)κ1(x1)

+ ∂2π1
∂xi∂xσ
(x1)
 ∂2fσ
∂xj∂xk
(x1) +
∂2gσ
∂xj∂xk
(x1)κ1(x1)

+ ∂2π1
∂xj∂xσ
(x1)
 ∂2fσ
∂xi∂xk
(x1) +
∂2gσ
∂xi∂xk
(x1)κ1(x1)

+ ∂2π1
∂xk∂xσ
(x1)
 ∂2fσ
∂xi∂xj
(x1) +
∂2gσ
∂xi∂xj
(x1)κ1(x1)

+∂π1
∂xσ
(x1)

∂3fσ
∂xi∂xj∂xk
(x1) +
∂3gσ
∂xi∂xj∂xk
(x1)κ1(x1)

+
∂3q
∂xi∂xj∂xk
(x1) + 1
2
∂3r
∂xi∂xj∂xk
(x1)(κ1(x1))2
−∂r
∂xi
(x1)∂κ1
∂xj
(x1)∂κ1
∂xk
(x1)
−∂r
∂xj
(x1)∂κ1
∂xi
(x1)∂κ1
∂xk
(x1)

Patchy Solutions
267
−∂r
∂xk
(x1)∂κ1
∂xi
(x1)∂κ1
∂xj
(x1)
−r(x1) ∂2κ1
∂xi∂xj
(x1)∂κ1
∂xk
(x1)
−r(x1) ∂2κ1
∂xi∂xk
(x1)∂κ1
∂xj
(x1)
−r(x1) ∂2κ1
∂xj∂xk
(x1)∂κ1
∂xi
(x1)
These (n+2)(n+1)n/6 equations can be solved one by one in lexograhic order for the
(n+2)(n+1)n/6 unknowns
∂4π1
∂xi∂xj∂xk∂xn (x1) for 1 ≤i ≤j ≤k ≤n. The unknowns
∂3κ1
∂xi∂xj∂xk (x1) do not appear because of (2) and they are simpliﬁed by (4) and (7).
Then we differentiate the second HJB equation (3) with respect to xi, xj, xk for
1 ≤i ≤j ≤n to obtain the (n + 2)(n + 1)n/6 equations
0 =
∂4π1
∂xi∂xj∂xk∂xσ
(x1)gσ(x1)
(8)
+
∂3π1
∂xi∂xj∂xσ
(x1)∂gσ
∂xk
(x1)
+
∂3π1
∂xi∂xk∂xσ
(x1)∂gσ
∂xj
(x1)
+
∂3π1
∂xj∂xk∂xσ
(x1)∂gσ
∂xi
(x1)
+ ∂2π1
∂xixσ
(x1) ∂2gσ
∂xj∂xk
(x1)
+ ∂2π1
∂xjxσ
(x1) ∂2gσ
∂xi∂xk
(x1)
+ ∂2π1
∂xkxσ
(x1) ∂2gσ
∂xi∂xj
(x1)
+∂π1
∂xσ
(x1)
∂3gσ
∂xi∂xj∂xk
(x1)
+
∂3r
∂xi∂xj∂xk
(x1)κ1(x1)
+
∂2r
∂xi∂xj
(x1)∂κ1
∂xk
(x1)
+
∂2r
∂xi∂xk
(x1)∂κ1
∂xj
(x1)
+
∂2r
∂xj∂xk
(x1)∂κ1
∂xi
(x1)

268
C. Navasca and A.J. Krener
+ ∂r
∂xi
(x1) ∂2κ1
∂xj∂xk
(x1)
+ ∂r
∂xj
(x1) ∂2κ1
∂xi∂xk
(x1)
+ ∂r
∂xk
(x1) ∂2κ1
∂xi∂xj
(x1)
+r(x1)
∂3κ1
∂xi∂xj∂xk
(x1)
which can be solved one by one for the (n + 2)(n + 1)n/6 unknowns
∂3κ1
∂xi∂xj∂xk (x1),
1 ≤i ≤j ≤k ≤n.
7
Two Dimensional Example
We consider the optimal control problem of driving a planar pendulum of length 1 and
mass 1 to the upright condition by a torque u at its pivot. The dynamics is
˙x1 = x2
˙x2 = sin x1 + u
We choose the Lagrangian
l(x, u) = 1
2

|x|2 + u2
We computed the Al’brecht solution around the origin to degree 4 in the cost and
degree 3 in the optimal feedback. We accepted it on the sublevel set π0(x) ≤0.5.
Then using the method described above we computed the solution at four points in the
eigenspaces of the quadratic part of the cost where π0(x) = 0.5. There is one in each
quadrant. These outer solutions were also computed to degree 4 in the cost and degree
3 in the feedback.
Fig. 5. Optimal cost computed on ﬁve patches. The outer patches are bounded in part by the axes.

Patchy Solutions
269
Fig. 6. Contour plot of ﬁve patch cost. The inner 4 contours are within the central patch. Notice
that there is a slight mismatch of the outer contours when they meet at the axes.
8
Conclusion
We have sketched out a patchy approach to solving Hamilton Jacobi Bellman equations
for nice optimal control problems and applied it to one and two dimensional examples.
We were deliberately vague about some aspects of the proposed algorithm such as how
to choose the boundary between outer patches. Further research is needed to clarify
these issues and this can come only with extensive computation.
References
1. E. G. Al’brecht, On the optimal stabilization of nonlinear systems, PMM-J. Appl. Math.
Mech., 25:1254-1266, 1961.
2. F. Ancona and A. Bressan, Nearly Time Optimal Stabilizing Patchy Feedbacks, preprint
available at http://cpde.iac.rm.cnr.it/preprint.php
3. M. Bardi and I. Capuzzo-Dolcetta Optimal Control and Viscosity Solutions of Hamilton-
Jacobi-Bellman Equations, Birkh¨auser, Boston, 1997.
4. M. G. Crandall and P. L. Lions Viscosity Solutions of Hamilton-Jacobi Equations,
Transactions of the American Mathematical Society, 227:1–42, 1983.
5. L. C. Evans, Partial Differential Equations. American Mathematical Society, Providence,
1998.
6. W. H. Fleming and H. M. Soner, Controlled Markov Processes and Viscosity Solutions.
Springer-Verlag, New York, 1992.
7. W. L. Garrard and J. M. Jordan. Design of nonlinear automatic ﬂight control systems,
Automatica, 13:497-505, 1977.
8. F. John, Partial Differential Equations. Springer-Verlag, New York, 1982.
9. C. Y. Kao, S. Osher and Y. H. Tsai. Fast Sweeping Methods for Hamilton-Jacobi Equations,
SIAM J. Numerical Analysis, 42:2612–2632, 2005.
10. C. Y. Kao, S. Osher and J. Qian. Lax-Friedrichs Sweeping Scheme for Static Hamilton-Jacobi
Equations, J. Computational Physics, 196:367–391, 2004.

270
C. Navasca and A.J. Krener
11. A. J. Krener. Nonlinear Systems Toolbox V. 1.0, 1997, MATLAB based toolbox available by
request from ajkrener@ucdavis.edu
12. A. J. Krener. The existence of optimal regulators, Proc. of 1998 CDC, Tampa, FL,
3081–3086.
13. H. J. Kushner and P. G. Dupuis, Numerical Methods for Stochastic Control Problems in
Continuous Time, Springer-Verlag, New York, 1992.
14. D. L. Lukes. Optimal regulation of nonlinear dynamical systems, SIAM J. Contr., 7:75–100,
1969.
15. C. L. Navasca and A. J. Krener. Solution of Hamilton Jacobi Bellman Equations, Proceedings
of the IEEE Conference on Decision and Control, Sydney, 2000, pp. 570-574.
16. S. Osher and C. W. Shu. High-order Essentially Nonoscillatory Schemes for Hamilton
Jacobi Equations, SIAM J. Numerical Analysis, 28:907-922, 1991.
17. H. M. Osinga and J. Hauser. The geometry of the solution set of nonlinear optimal control
problems , to appear in Journal of Dynamics and Differential Equations.
18. W. Prager. Numerical computation of the optimal feedback law for nonlinear inﬁnite horizon
control problems, CALCOLO, 37:97-123, 2000.
19. J. A. Sethian. Level Set Methods and Fast Marching Methods, Cambridge University Press,
1999.
20. B. F. Spencer Jr., T. L. Timlin, M. K. Sain and S. J. Dyke. Series solution of a class of
nonlinear regulators, Journal of Optimization Theory and Applications, 91:321-345, 1996.
21. J. Tsitsiklis, Efﬁcient algorithms for globally optimal trajectories IEEE Trans. Auto. Con.,
40:1528-1538, 1995.
22. T. Yoshida and K. A. Loparo. Quadratic regulator theory for analytic non-linear systems
with additive controls, Automatica 25:531-544, 1989.

A Geometric Assignment Problem for Robotic Networks
Stephen L. Smith and Francesco Bullo
Department of Mechanical Engineering
Center for Control, Dynamical Systems and Computation
University of California, Santa Barbara, CA 93106-5070, USA
stephen@engineering.ucsb.edu, bullo@engineering.ucsb.edu
Summary. In this chapter we look at a geometric target assignment problem consisting of an
equal number of mobile robotic agents and distinct target locations. Each agent has a ﬁxed com-
munication range, a maximum speed, and knowledge of every target’s position. The problem is
to devise a distributed algorithm that allows the agents to divide the target locations among them-
selves and, simultaneously, leads each agent to its unique target. We summarize two algorithms
for this problem; one designed for “sparse” environments, in which communication between
robots is sparse, and one for “dense” environments, where communication is more prevalent. We
characterize the asymptotic performance of these algorithms as the number of agents increases
and the environment grows to accommodate them.
1
Introduction
Consider a group of n mobile robotic agents, equipped with wireless transceivers for
limited range communication, dispersed in an environment E ⊂R2. Suppose the envi-
ronment also contains n target locations, and each agent is given a list containing their
positions (these positions may be given as GPS coordinates). We would like each target
location to be occupied be an agent as quickly as possible. Since no a priori assignment
of target-agent pairs has been given, the agents must solve the problem through com-
munication and motion. We call this the target assignment problem. Such a problem
could arise in several applications, such as UAV’s on a surveillance mission, where the
targets are the centers of their desired loitering patterns.
The centralized problem of simply assigning one agent to each target is known in the
combinatorial optimization literature as the maximum matching problem [1]. There are
several polynomial time algorithms for solving this problem, the best known being [2]
by Hopcroft and Karp. To efﬁciently assign agents to targets, we may be interested in
ﬁnding a maximum matching (i.e., an assignment of one agent to each target) which
minimizes a cost function. If the cost function is the sum of distances from each agent
to its assigned target, then the problem is known as the assignment problem, or the
minimum weight maximum matching problem, [1]. This problem can be written as an
integer linear program and optimal solutions can be computed in polynomial time [3].
Another choice of cost function is to minimize the maximum distance between agents
and their assigned targets. This problem is commonly referred to as the bottleneck as-
signment problem [4], and although the cost function is not linear, there still exist several
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 271–284, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

272
S.L. Smith and F. Bullo
polynomial time algorithms for its solution. There has also been work on developing
algorithms for the assignment problem which can be implemented on parallel comput-
ing systems. One example is the auction algorithm [5], which can be implemented with
one processor for each agent.
There is set of problems, commonly referred to as decentralized task allocation, that
are closely related to our target assignment problem, see for example [6,7,8]. In these
problems the goal is generally to assign vehicles to spatially distributed tasks while
maximizing the “score” of the mission. Most works on this problem develop advanced
heuristic methods, and demonstrate their effectiveness through simulation or real world
implementation. In [9] the auction algorithm was adapted to solve a task allocation
problem in the presence of communication delays. There has also been prior work on
the target assignment problem [10,11,12,13,14]. For example, an algorithm based on
hybrid systems tools is developed in [10]. The algorithm performance is characterized
by a bound on the number of switches of the hybrid system; however, no analysis of the
time complexity is provided.
In this chapter we summarize our recent investigations [12, 13] into the minimum-
time task assignment problem and its scalability properties. We are interested in char-
acterizing the completion time as the number of agents, n, grows, and the environment,
E(n) := [0, ℓ(n)]2, grows to accommodate them. In Section 4 we describe the ETSP
ASSGMT algorithm with worst-case completion time in O(√nℓ(n)). In addition, in
“sparse” environments, i.e., when ℓ(n)/√n →+∞, the ETSP ASSGMT algorithm is
asymptotically optimal among a broad class of algorithms in terms of its worst-case
completion time. Then, in Section 5 we describe the GRID ASSGMT algorithm with
worst-case completion time in O(ℓ(n)2). We also characterize the stochastic properties
of the GRID ASSGMT algorithm in “dense” environments, i.e., when ℓ(n)/√n →0.
If the agents and targets are uniformly randomly distributed, then the completion time
belongs to O(ℓ(n)) with high probability. Also, if there are n agents and only n/ log n
targets, then the completion time belongs to O(1) with high probability.
The two algorithms are complementary: ETSP ASSGMT has better performance in
sparse environments, while GRID ASSGMT has better performance in dense environ-
ments.
2
Geometric and Stochastic Preliminaries
In this section we review a few useful results on the Euclidean traveling salesperson
problem, occupancy problems, and random geometric graphs. To do this, we must ﬁrst
brieﬂy review some notation. We let R denote the set of real numbers, R>0 denote
the set of positive real numbers, and N denote the set of positive integers. Given a
ﬁnite set A, we let |A| denote its cardinality. For two functions f, g : N →R>0, we
write f(n) ∈O(g) (respectively, f(n) ∈Ω(g)) if there exist N ∈N and c ∈R>0
such that f(n) ≤cg(n) for all n ≥N (respectively, f(n) ≥cg(n) for all n ≥N).
If f(n) ∈O(g) and f(n) ∈Ω(g) we say f(n) ∈Θ(g). We say that event A(n)
occurs with high probability (w.h.p.) if the probability of A(n) occurring tends to one
as n →+∞.

A Geometric Assignment Problem for Robotic Networks
273
2.1
The Euclidean Traveling Salesperson Problem
For a set of n points, Q ∈R2, we let ETSP(Q) denote the length of the shortest closed
path through all points in Q. The following result characterizes the length of this path
when Q ⊂[0, ℓ(n)]2.
Theorem 1 (ETSP tour length, [15]). For every set of n points Q ⊂[0, ℓ(n)]2, we
have ETSP(Q) ∈O(√nℓ(n)).
The problem of computing an optimal ETSP tour is known to be NP-complete. How-
ever, there exist many efﬁcient approximation algorithms.
For example, the
Christoﬁdes’ algorithm [16], computes a tour that is no longer than 3/2 times the opti-
mal in O(n3) computation time.
2.2
Bins and Balls
Occupancy problems, or bins and balls problems, are concerned with randomly dis-
tributing m balls into n equally sized bins. The two results we present here will be
useful in our analysis.
Theorem 2 (Bins and balls properties, [17, 18]). Consider uniformly randomly dis-
tributing m balls into n bins and let γn be any function such that γn →+∞as
n →+∞. The following statements hold:
1. if m = n, then w.h.p. each bin contains O
1
log n
log log n
2
balls;
2. if m = n log n + γnn, then w.h.p. there are no empty bins, and each bin contains
O(log n) balls;
3. if m = n log n −γnn, then w.h.p. there exists an empty bin;
4. if m = Kn log n, where K > 1/ log(4/e), then w.h.p. every bin contains Θ(log n)
balls.
We will be interested in dividing a square environment into equally sized and openly
disjoint square bins, such that the side length ℓ(B), of each bin is small in some sense.
To do this, we require the following simple fact.
Lemma 1 (Dividing the environment). Given n ∈N and r > 0, consider an environ-
ment E(n) := [0, ℓ(n)]2. If E(n) is partitioned into b2 equally sized and openly disjoint
square bins, where
b := ⌈
√
5ℓ(n)/r⌉,
(1)
then ℓ(B) ≤r/
√
5. Moreover, if x, y ∈E(n) are in the same bin or in adjacent bins,
then ∥x −y∥≤r.
2.3
Random Geometric Graphs
For n ∈N and r ∈R>0, a planar geometric graph G(n, r) consists of n vertices in R2,
and undirected edges connecting all vertex pairs {x, y} with ∥x−y∥≤r. If the vertices
are randomly distributed in some subset of R2, we call the graph a random geometric
graph.

274
S.L. Smith and F. Bullo
Theorem 3 (Connectivity of random geometric graphs, [19]). Consider the ran-
dom geometric graph G(n, r) obtained by uniformly randomly distributing n points
in [0, ℓ(n)]2. If
π
 r
ℓ(n)
2
= log n + c(n)
n
,
then G(n, r) is connected w.h.p. if and only if c(n) →+∞as n →+∞.
This theorem will be important for understanding some of our results. If we randomly
deploy n agents with communication range r > 0 in an environment [0, ℓ(n)]2, then
the communication graph is connected if ℓ(n) ≤r

n/ log n.
3
Network Model and Problem Statement
In this section we formalize our agent and target models and deﬁne the sparse and dense
environments.
3.1
Robotic Network Model
Consider n agents in an environment E(n) := [0, ℓ(n)]2 ⊂R2, where ℓ(n) > 0 (that
is, E(n) is a square with side length ℓ(n)). The environment E(n) is compact for each
n but its size depends on n. A robotic agent, A[i], i ∈I := {1, . . . , n}, is described by
the tuple
A[i] := {UID[i], p[i], r, u[i], M [i]},
where the quantities are as follows: Its unique identiﬁer (UID) is UID[i], taken from
the set IUID ⊂N. Note that, each agent does not know the set of UIDs being used
and thus does not know the order. Its position is p[i] ∈E(n). Its communication
range is r > 0, i.e., two agents, A[i] and A[k], i, k ∈I, can communicate if and only
if ∥p[i] −p[k]∥≤r. Its continuous time velocity input is u[i], corresponding to the
kinematic model ˙p[i] = u[i], where ∥u[i]∥≤vmax for some vmax > 0. Finally, its
memory is M [i] and is of size |M [i]|. From now on, we simply refer to agent A[i] as
agent i. We assume the agents move in continuous time and communicate according to
a discrete time schedule {tk}k∈N. We assume |tk+1 −tk| ≤tmax, for all k ∈N, where
tmax ∈R>0. At each communication round, agents can exchange messages of length
O(log n).1
3.2
The Target Assignment Problem
Let Q := {q1, . . . , qn} be a set of distinct target locations, qj ∈E(n) for each j ∈I.
Agent i’s memory, M [i], contains a copy of Q, which we denote Q[i]. To store Q[i]
we must assume the size of each agents’ memory, |M [i]|, is in Ω(n). We refer to the
assumption that each agent knows all target positions as the full knowledge assumption
(for a more detailed discussion of this assumption see [12]). Our goal is to solve the
(full knowledge) target assignment problem:
1 Ω(log n) bits are required to represent an ID, unique among n agents.

A Geometric Assignment Problem for Robotic Networks
275
Determine an algorithm for n ∈N agents, with attributes as described above,
satisfying the following requirement. There exists a time T > 0 such that for
each target qj ∈Q, there is a unique agent i ∈I, with p[i](t) = qj for all
t ≥T .
3.3
Sparse and Dense Environments
We wish to study the scalability of a particular approach to the target assignment prob-
lem; that is, how the completion time increases as we increase the number of agents, n.
The velocity vmax and communication range r of each agent are independent of n.
However, we assume that the size of the environment increases with n in order to ac-
commodate an increase in agents. Borrowing terms from the random geometric graph
literature [19], we say the environment is sparse if, as we increase the number of agents,
the environment grows quickly enough that the density of agents (as measured by the
sum of their communication footprints) decreases; we say the environment is critical,
if the density is constant, and we say the environment is dense if the density increases.
Formally, we have the following deﬁnition.
Deﬁnition 1 (Dense, critical and sparse environments). The environment E(n) :=
[0, ℓ(n)]2 is sparse if ℓ(n)/√n →+∞as n →+∞, critical if ℓ(n)/√n →C ∈R>0
as n →+∞, and dense if ℓ(n)/√n →0, as n →+∞.
It should be emphasized that a dense environment does not imply that the communica-
tion graph between agents is dense. On the contrary, from Theorem 3 we see that the
communication graph at random agent positions in a dense environment may not even
be connected.
4
Sparse Environments
We begin by studying the case when the environment is sparse, and thus there is very
little communication between agents. We introduce a natural approach to the problem in
the form of a class of distributed algorithms, called assignment-based motion. We give
a worst-case lower bound on the performance of the assignment-based motion class.
Next, we introduce a control and communication algorithm, called ETSP ASSGMT. In
this algorithm, each agent precomputes an optimal tour through the n targets, turning
the cloud of target points into an ordered ring. Agents then move along the ring, looking
for the next available target. When agents communicate, they exchange information on
the next available target along the ring. We show that in sparse or critical environments,
the ETSP ASSGMT algorithm is an asymptotically optimal among all algorithms in the
assignment-based motion class.
4.1
Assignment-Based Algorithms with Lower Bound Analysis
Here we introduce and analyze a class of deterministic algorithms for the target assign-
ment problem. The assignment-based motion class can be described as follows.

276
S.L. Smith and F. Bullo
Outline of assignment-based motion class
Initialization: In this class of algorithms agent i initially selects the closest
target in Q[i], and sets the variable curr[i] (agent i’s current target), to the
index of that target.
Motion: Agent i moves toward the target curr[i] at speed vmax.
Communication: If agent i communicates with an agent k that is moving to-
ward curr[k] = curr[i], and if agent k is closer to curr[i] than agent i, then
agent i “removes” curr[i] from Q[i] and selects a new target.
For this class of algorithms it is convenient to adopt the following conventions: we say
that agent i ∈I is assigned to target qj ∈Q, when curr[i] = j. We say that agent i ∈I
enters a conﬂict over the target curr[i], when agent i receives a message, msg[k], with
curr[i] = curr[k]. Agent i loses the conﬂict if agent i is farther from curr[i] than agent k,
and wins the conﬂict if agent i is closer to curr[i] than agent k, where ties are broken by
comparing UIDs. Note that if an agent is assigned to the same target as another agent,
it will enter a conﬂict in ﬁnite time.
Theorem 4 (Time complexity lower bound for target assignment). Consider n
agents, with communication range r > 0, in an environment [0, ℓ(n)]2. If ℓ(n) > r√n,
then for all algorithms in the assignment-based motion class, the time complexity of the
target assignment problem is in Ω(√nℓ(n)).
In other words, the target assignment time complexity is lower bounded when the envi-
ronment grows faster than some critical value, that is, when the environment is sparse
or critical.
4.2
The ETSP ASSGMT Algorithm with Upper Bound Analysis
In this section we introduce the ETSP ASSGMT algorithm—an algorithm within the
assignment-based motion class. We will show that when the environment is sparse or
critical, this algorithm is asymptotically optimal. In the following description of ETSP
ASSGMT it will be convenient to assume that the target positions are stored in each
agents memory as an array, rather than as an unordered set. That is, we replace the
target set Q with the target n-tuple q := (q1, . . . , qn), and the local target set Q[i] with
the n-tuple q[i]. The algorithm can be described as follows.
For each i ∈I, agent i computes a constant factor approximation of the optimal
ETSP tour of the n targets in q[i], denoted tour(q[i]). We can think of tour as a map
which reorders the indices of q[i]; tour(q[i]) = (q[i]
σ(1), . . . , q[i]
σ(n)), where σ : I →I
is a bijection. This map is independent of i since all agents use the same method. An
example is shown in Fig. 1(a). Agent i then replaces its n-tuple q[i] with tour(q[i]).
Next, agent i computes the index of the closest target in q[i], and calls it curr[i]. Agent
i also maintains the index of the next target in the tour which may be available, next[i],
and ﬁrst target in the tour before curr[i] which may be available, prev[i]. Thus, next[i] is
initialized to curr[i]+1 (mod n) and prev[i] to curr[i]−1 (mod n). In order to “remove”
assigned targets from the tuple q[i], agent i also maintains the n-tuple, status[i]. Letting
status[i](j) denote the jth entry in the n-tuple, the entries are given by

A Geometric Assignment Problem for Robotic Networks
277
status[i](j) =
8
0,
if agent i knows q[i]
j is assigned to another agent,
1,
otherwise.
(2)
Thus, status[i] is initialized as the n-tuple (1, . . . , 1). The initialization is depicted in
Fig. 1(b).
1
5
3
2
6
4
1
5
3
2
6
4
tour
7
7
(a) The map tour orders the given targets
curr[i] = 7
next[i] = 1
prev[i] = 6
p[i]
5
3
2
4
(b) Initialization of agent i
Fig. 1. Initialization of ETSP ASSGMT
Finally, at each communication round agent i executes the algorithm COMM-RD de-
scribed below.
Outline of COMM-RD algorithm for agent i
1: Broadcast msg[i], consisting of the targets, prev[i], curr[i], and next[i], the
distance to the current target d[i], and UID[i].
2: for all messages, msg[k], received do
3:
Set status[i](j) to assigned (‘0’) for each target j from prev[k]+1 (mod n)
to next[k] −1 (mod n) not equal to curr[i].
4:
if prev[k] = next[k] = curr[k] ̸= curr[i], then set the status of curr[k] to 0
because it was missed in the previous step.
5:
if curr[i] = curr[k] but agent i is farther from curr[i] than agent k (ties
broken with UIDs) then
6:
Set the status of curr[i] to assigned (‘0’).
7:
if curr[i] = curr[k] and agent i is closer than agent k then
8:
Set the status of next[i] and next[k] to assigned (‘0’).
9: Update curr[i] to the next target in the tour with status available (‘1’), next[i]
to the next available target in the tour after curr[i], and prev[i] to the ﬁrst
available target in the tour before curr[i].
In summary, the ETSP ASSGMT algorithm is the triplet consisting of the initializa-
tion of each agent, the motion law (move toward curr[i] at speed vmax), and the COMM-
RD algorithm executed at each communication round.
Fig. 2 gives an example of COMM-RD resolving a conﬂict between agents i and k,
over curr[i] = curr[k].
The proposed algorithm enjoys plenty of useful properties,
which are valid for any communication graph which contains the geometric graph with
parameter r as a subgraph. A complete discussion is contained in [12]. Based on a
careful application of Theorem 1, one can derive the following key result.

278
S.L. Smith and F. Bullo
curr[k] = curr[i] = 7
2
prev[k] = 5
next[k] = next[i] = 1
prev[i] = 6
p[k]
3
4
p[i]
(a) Setup prior to a conﬂict
curr[i] = 7
2 = next[k] = next[i]
prev[k] = prev[i] = 5
curr[k] = 1
6
3
4
p[k]
p[i]
(b) Setup after resolution of the conﬂict
Fig. 2. The resolution of a conﬂict between agents i and k over target 7. Agent i wins the conﬂict
since it is closer to target 7 than agent k.
Theorem 5 (Correctness and time complexity for ETSP ASSGMT). For any n ∈N,
ETSP ASSGMT solves the target assignment problem. Furthermore, consider an envi-
ronment [0, ℓ(n)]2. If tmax < r/vmax, then ETSP ASSGMT solves the target assignment
problem in O(√nℓ(n) + n) time. If, in addition, ℓ(n) > r√n, then the time complexity
is in Θ(√nℓ(n)), and ETSP ASSGMT is asymptotically optimal among algorithms in
the assignment-based motion class.
The above theorem gives a complexity bound for the case when r and vmax are ﬁxed
constants, and ℓ(n) grows with n. An equivalent setup is to consider ℓﬁxed and allow
the robots’ attributes, r and vmax, to vary inversely with the n, speciﬁcally, r and v
proportional to √n.
Corollary 1 (Complexity with congestion). Consider n agents moving with speed
&vmax(n) = n−1/2 and communication radius &r(n) = r0n−1/2, with r0 < 1, in the
environment [0, 1]2. Then ETSP ASSGMT solves the target assignment problem with
time complexity in Θ(n).
For simplicity we have presented our time complexity results in the planar environ-
ment [0, ℓ(n)2]. However, in [12] we derive bounds for the more general environment
(a) Initial conﬁguration
(b) Positions at time 30
(c) Complete assignment
Fig. 3. Simulation for 15 agents, vmax = 1, r = 15 in E = [0, 100]3. The targets are spheres.
The agents are cubes. An edge is drawn when two agents are communicating.

A Geometric Assignment Problem for Robotic Networks
279
[0, ℓ(n)]d, d ≥1. A simulation in [0, 100]3 ⊂R3 with r = 15 and v = 1 is shown
in Fig. 3. To compute the ETSP tour we have used the concorde TSP solver.2 The
initial conﬁguration shown in Fig. 3(a) consists of uniformly randomly generated target
and agent positions.
5
Dense Environments
In the previous section we presented the ETSP ASSGMT algorithm which has prov-
ably good performance in sparse environments. In this section we introduce the GRID
ASSGMT algorithm for dense environments in which communication is more prevalent.
We will show that it has better worst-case performance than ETSP ASSGMT in dense
environments, and that it possesses very good stochastic performance.
5.1
The GRID ASSGMT Algorithm with Complexity Analysis
In the GRID ASSGMT algorithm we assume that each agent knows the target positions,
Q, and the quantity ℓ(n) which describes the size of the environment. With this infor-
mation, each agent partitions the environment into b2 equally sized square cells, where
b ∈N. It then labels the cells like entries in a matrix, so cell C(w, c) resides in the wth
row and cth column. This is shown in Fig. 4(b). Since the agents started with the same
information, they all create the same partition.
(a) 35 targets in E(n).
C(1, 1)
C(2, 1)
C(3, 1)
C(1, 2)
C(2, 2)
C(3, 2)
C(1, 3)
C(2, 3)
C(3, 3)
(b) E(n) divided into b2 = 9 cells.
Fig. 4. Dividing the environment into 9 cells
In light of Lemma 1, we see that when b is given by ⌈
√
5ℓ(n)/r⌉, as in equation (1),
the communication graph between agents in a cell is complete, and communication
between agents in adjacent cells is also possible. With this in mind, an outline of the
GRID ASSGMT algorithm is as follows.
2 The concorde TSP solver is available for research use at http://www.tsp.
gatech.edu/concorde/index.html

280
S.L. Smith and F. Bullo
Outline of the GRID ASSGMT algorithm
Initialization: Each agent partitions the environment into b2 equally sized
square cells, where b is given in Lemma 1, and the cells are labeled as
in Fig. 4(b).
All agents: In each cell, all agents in the cell ﬁnd a maximum matching be-
tween agents and targets occupying the cell. Accordingly, agents are la-
beled assigned or unassigned.
Assigned agents: In each cell, all assigned agents elect a leader among them.
All assigned agents, except the leaders, send their assignment information
to their respective leader and then go silent.
Cell leaders: The leader in each cell communicates to the leader in the cell
directly above. As a result, each leader obtains an estimate of the number
of available targets in all cells below it, in its column.
Unassigned agents: First, each unassigned agent seeks a free target in its col-
umn by entering cells and querying the corresponding leader.
Second, if all targets in the unassigned agent’s column are assigned, then
the agent moves to the top of its column and along the top row. The agent
gathers from each leader in the top row the number of available targets in
the leader’s column. When the agent ﬁnds a column with available targets,
it travels down that column to ﬁnd the free target.
To implement this algorithm agent i maintains the following variables in its memory.
The variable currcell[i] which keeps track of the cell which agent i currently occupies.
The set Q[i](w, c) which contains the targets in cell C(w, c). The variable leader[i]
which is set to C(w, c) if agent i is the leader of C(w, c), and null otherwise. The
array colstatus[i], where colstatus[i](c) is set to full if column c contains no available
targets, and notfull if agent i thinks column c may contain an available target. The
variable dircol[i] ∈{down, up} which contains the direction of travel in a column and
dirrow[i] ∈{left, right} which contains the direction in the ﬁrst row. Finally, the
variable curr[i] which contains agent i’s assigned target, or the entry null.
After initializing these variables, each agent runs an algorithm which allows the
agents to compute a local maximum matching, and elect a leader, in each cell. Since the
communication graph in each cell is complete, this can be done in one communication
round by receiving the UIDs of each agent in the cell [13].
After the maximum matching and leader election the agents have been separated
into three roles; assigned leader agents, assigned non-leader agents, and unassigned
agents. The unassigned agents run an algorithm in which they try to ﬁnd a free tar-
get. The leader of each cell runs an algorithm in which they update their estimates
of available targets in various parts of the grid, and assigns unassigned targets in its
cell. The leader of cell C(w, c), agent i, maintains the following quantities to assign
targets in its cell, and estimate the number of available targets in cells below. Agent
i maintains: diff[i](w, c), which records the difference between the number of targets
and agents in cell C(w, c); diffbelow[i](w, c) which records agent i’s estimate of the
difference between the number of agents and targets in cells C(w + 1, c), . . . , C(b, c);
and taravail[i](w, c) which contains the available targets in C(w, c). Finally, if agent

A Geometric Assignment Problem for Robotic Networks
281
i is the leader of C(1, c) in the ﬁrst row, it maintains diffright[i](c) which is agent i’s
estimate of the number of available targets in columns c + 1, . . . , b.
In summary, The GRID ASSGMT algorithm is the 4-tuple consisting of the initial-
ization, the maximum matching and leader election algorithm, the unassigned agent
algorithm, and the leader algorithm.
We can now state the main results on the GRID ASSGMT algorithm.
Theorem 6 (Correctness and worst-case upper bound). For any initial positions of n
targets and n agents in [0, ℓ(n)]2, GRID ASSGMT solves the target assignment problem
in O((ℓ(n))2) time.
Remark 1 (GRID ASSGMT vs. ETSP ASSGMT). The worst-case bound for ETSP ASS-
GMT in Theorem 5 was O(√nℓ(n)). Thus, in sparse environments, when ℓ(n) grows
faster than √n, ETSP ASSGMT performs better, and in dense environments GRID ASS-
GMT performs better. In critical environments, the bounds are equal. Thus, the two
algorithms are complementary. In practice, if n, ℓ(n) and r are known, each robot in
the network can determine which algorithm to run based on the following test: ETSP
ASSGMT is run if ℓ(n)/√n > r and GRID ASSGMT is run if ℓ(n)/√n < r.
•
In the following theorem we will see that for randomly placed targets and agents, the
performance of GRID ASSGMT is considerably better than in the worst-case. The proofs
of the following theorems utilize the results on bins and balls problems in Section 2.
Theorem 7 (Stochastic time complexity). Consider n agents and n targets, uniformly
randomly distributed in [0, ℓ(n)]2. If ℓ(n) ≤r/
√
5

(n/K log n), where K > 1,
then GRID ASSGMT solves the target assignment problem in O(ℓ(n)) time with high
probability.
Remark 2 (Generalization of Theorem 7). The bound in Theorem 7 holds for any initial
positions such that every cell contains at least one target and at least one agent.
•
Theorem 8 (Stochastic time complexity: More agents than targets). Consider n
agents and n/ log n targets, uniformly randomly distributed in [0, ℓ(n)]2. If ℓ(n) ≤
r/
√
5

(n/K log n), where K > 1/ log(4/e), then w.h.p., GRID ASSGMT solves the
target assignment problem in O(1) time.
A representative simulation of GRID ASSGMT for 65 agents and targets uniformly ran-
domly distributed in a dense environment is shown in Fig. 5(a)–(c). In Fig. 5(c) a dashed
blue trail shows the trajectory for the ﬁnal agent as it is about to reach its target in cell
C(1, 1). Fig. 5.1 contains a Monte Carlo simulation for uniformly randomly gener-
ated agents and targets. The side length ℓ(n) satisﬁes the bound in Theorem 7, and the
agents move at unit speed. Each data point is the mean completion time of 30 trials,
where each trial was performed at randomly generated agent and target positions. Error
bars show plus/minus one standard deviation. The mean completion time lies between
2ℓ(n) and 3ℓ(n). This agrees with the O(ℓ(n)) bound in Theorem 7 and gives some
idea as to the constant in front of this bound.

282
S.L. Smith and F. Bullo
(a) Initial agent and target po-
sitions, and grid
(b) Maximum assignment and
leader election
(c) Final agent reaching target
Fig. 5. A simulation of 65 agents in a dense environment. Targets are black disks and agents are
blue squares. Red lines are drawn when two agents are communicating.
0
200
400
600
800
1000
0
5
10
15
20
25
30
35
40
Number of agents
Time
Mean completion time
3 l(n)
2 l(n)
Fig. 6. A Monte Carlo simulation. Each data point is the mean of 30 trials.
5.2
A Sensor Based Version
In describing the GRID ASSGMT algorithm, we assumed that each agent knows the
position of all targets. The algorithm also works when each agent does not know the
position of any targets, but has a sensing range rsense, with which it can sense the posi-
tions of targets in range. If each agent can partition the environment as in Fig. 4, and if
rsense ≥

2/5r so that each agent can sense the position of all targets in its current cell,
then GRID ASSGMT (with minor modiﬁcations) solves the target assignment problem,
and the completion time results still hold.
5.3
Congestion Issues
Since wireless communication is a shared medium, simultaneous messages sent in close
proximity will collide, resulting in dropped packets. In fact, clear reception of a signal

A Geometric Assignment Problem for Robotic Networks
283
requires that no other signals are present at the same point in time and space. As the
density of agents increases (as measured by their communication footprints), so does
wireless communication congestion. Thus, in dense environments, one would ideally
account for the effects of congestion. In the design of GRID ASSGMT we have tried to
limit the amount of simultaneous communication. To this end we introduced a leader in
each cell, who sent messages (of size O(log n)) only to its adjacent cells, and all other
assigned agents were silent. However, to fully take wireless congestion into account,
we would require a more sophisticated communication model than the geometric graph.
6
Conclusion and Extensions
In this chapter we have discussed two complementary algorithms for the target assign-
ment problem, ETSP ASSGMT and GRID ASSGMT. We have shown that ETSP ASS-
GMT has better performance in sparse environments, where as, GRID ASSGMT has
better performance in dense environments. There are many future research directions
such as extensions to vehicles with motion constraints, or to the case when targets are
dynamically appearing and disappearing. Another area of future research is to develop
a communication framework which adequately models congestion and media access
problems that are inherently present in wireless communications.
Acknowledgments: In Giorgio’s Honor
The second author dedicates this work to Giorgio Picci. I am honored to have had
him as my Laurea advisor where he introduced me to the exciting world of scientiﬁc
research. His passion for control theory, applied mathematics and geometry was highly
contagious and continues to be a part of my life today. I am honored to be able to
dedicate this work to a man I consider an inspiration. Grazie di cuore!
References
1. B. Korte and J. Vygen, Combinatorial Optimization: Theory and Algorithms. New York:
Springer Verlag, 3 ed., 2005.
2. J. E. Hopcroft and R. M. Karp, “An n5/2 algorithm for maximum matchings in bipartite
graphs,” SIAM Journal on Computing, vol. 2, no. 4, pp. 225–231, 1973.
3. H. W. Kuhn, “The Hungarian method for the assignment problem,” Naval Research Logis-
tics, vol. 2, pp. 83–97, 1955.
4. R. Burkard, “Selected topics on assignment problems,” Discrete Applied Mathematics,
vol. 123, pp. 257–302, 2002.
5. D. P. Bertsekas and J. N. Tsitsiklis, Parallel and Distributed Computation: Numerical Meth-
ods. Belmont, MA: Athena Scientiﬁc, 1997.
6. M. F. Godwin, S. Spry, and J. K. Hedrick, “Distributed collaboration with limited communi-
cation using mission state estimates,” in American Control Conference, (Minneapolis, MN),
pp. 2040–2046, June 2006.
7. M. Alighanbari and J. P. How, “Robust decentralized task assignment for cooperative UAVs,”
in AIAA Conf. on Guidance, Navigation and Control, (Keystone, CO), Aug. 2006.

284
S.L. Smith and F. Bullo
8. C. Schumacher, P. R. Chandler, S. J. Rasmussen, and D. Walker, “Task allocation for wide
area search munitions with variable path length,” in American Control Conference, (Denver,
CO), pp. 3472–3477, 2003.
9. B. J. Moore and K. M. Passino, “Distributed task assignment for mobile agents,” IEEE Trans-
actions on Automatic Control, 2006. to appear.
10. M. Zavlanos and G. Pappas, “Dynamic assignment in distributed motion planning with local
information,” in American Control Conference, (New York), July 2007. To appear.
11. G. Arslan and J. S. Shamma, “Autonomous vehicle-target assignment: a game theoretic
formulation,” IEEE Transactions on Automatic Control, Feb. 2006. Submitted.
12. S. L. Smith and F. Bullo, “Target assignment for robotic networks: Asymptotic performance
under limited communication,” in American Control Conference, (New York), July 2007. To
appear.
13. S. L. Smith and F. Bullo, “Target assignment for robotic networks: Worst-case and stochastic
performance in dense environments,” in IEEE Conf. on Decision and Control, (New Orleans,
LA), Dec. 2007. Submitted.
14. D. A. Casta˜n´on and C. Wu, “Distributed algorithms for dynamic reassignment,” in IEEE
Conf. on Decision and Control, (Maui, HI), pp. 13–18, Dec. 2003.
15. K. J. Supowit, E. M. Reingold, and D. A. Plaisted, “The traveling salesman problem and
minimum mathcing in the unit square,” SIAM Journal on Computing, vol. 12, pp. 144–156,
1983.
16. N. Christoﬁdes, “Worst-case analysis of a new heuristic for the traveling salesman problem,”
Tech. Rep. 388, Carnegie-Mellon University, Apr. 1976.
17. R. Motwani and P. Raghavan, Randomized Algorithms. Cambridge, UK: Cambridge Univer-
sity Press, 1995.
18. F. Xue and P. R. Kumar, “The number of neighbors needed for connectivity of wireless
networks,” Wireless Networks, vol. 10, no. 2, pp. 169–181, 2004.
19. M. Penrose, Random Geometric Graphs. Oxford Studies in Probability, Oxford, UK: Oxford
University Press, 2003.

On the Distance Between Non-stationary Time Series
Stefano Soatto
Computer Science Department
University of California, Los Angeles
soatto@ucla.edu
1
Introduction
Comparing time series is a problem of critical importance in a broad range of
applications, from data mining (searching for temporal “patterns” in historical data),
to speech recognition (classifying phonemes from acoustic recordings), surveillance
(detecting unusual events from video and other sensory input), computer animation
(concatenating and interpolating motion capture sequences), just to mention a few.
The problem is difﬁcult because the same event can manifest itself in a variety of
ways, with the data subject to a large degree of variability due to nuisance factors
in the data formation process. For instance, the presence of a person walking in a
video sequence can vary based on the individual, his gait, location, orientation, speed,
clothing, illumination etc. And yet, if I see Giorgio Picci, I can recognize him from
one hundred yards away by the way he walks, regardless of what he is wearing, or
whether it is a sunny or a cloudy day. One could conjecture that there must exist some
statistics of my retinal signals that are invariant, or at least insensitive, to such nuisance
factors and are instead Giorgio-Speciﬁc (GS). The information ought to be encoded
in the temporal evolution of the retinal signals, for one can strip the images of their
pictorial content by attaching light bulbs to one’s joints and turning off the lights (or
use a state-of-the-art motion capture system, for instance one made by E-motion/BTS);
one can still tell a great deal from just the moving dots [6].
To be sure, searching for invariant GS statistics is not the only way to get rid of the
nuisances: One can also eliminate them as part of the matching process when compar-
ing two time series. Let us consider, for example, the nuisance of the initial observation
instant, t0. If we observe the temporal evolution of joint positions and think of them as
trajectories {y1(t)}t∈R in, say, L2, we could compare it to a sample sequence from a
database, {y2(t)}t∈R, by sliding one on top of the other until the L2 norm of the differ-
ence is minimized: d0(y1, y2) = mint0
%
∥y1(t) −y2(t −t0)∥2dt. A more elegant and
efﬁcient solution is to seek for a statistic of each time series, i.e. a deterministic func-
tion Σi .= φ(yi), that is invariant with respect to t0, and then to compare such statistics
directly. For the case of sequences that admit statistics that are invariant with respect to
t0, a.k.a. stationary, this can be done, and the resulting realization theory is a success
story of Systems Theory, one where Giorgio Picci and his collaborators have played
a key role [11]. Endowing the space of realizations with a metric and a probabilistic
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 285–299, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

286
S. Soatto
structure is the key to enabling a new level of ﬁnesse in the applications cited above,
where we are not simply trying to detect the presence of a person and whether he is
walking, but also to tell gender, identity, even state of mind. Some preliminary steps in
this direction have shown promise in the recognition of stationary human motion [2].
In this work, I wish to extend the formulation of the problem to more general
classes of nuisances for time series that are not stationary. In the spirit of realization
theory, I will forgo the prevailing approach where sequences are compared via their
likelihood. In this approach, the similarity between two sequences is measured by how
well the model of one (say a realization Σ1 = φ(y1)) “explains” the other, for instance
quantiﬁed by the covariance of the innovation process of y2. In this approach, the more
data are available, the better the estimate of Σ1, the worse the classiﬁcation error is,
an apparent paradox induced by the fact that the generalization model underlying this
approach is trivial: Each realization models one sequence and noisy versions of it,
without regard for the structure of the intrinsic variability that different realizations of
the same process exhibit. I will also not go as far as invoking the full power of chaotic
non-linear models as customary in the physics literature [7], because the processes of
interest are usually observed on short time-scales and do not exhibit chaotic behavior.
Instead, I will attempt to deﬁne distances between processes that are invariant, or at
least insensitive, to speciﬁc classes of nuisances. Once these are available, one can
attempt to construct probability distributions and therefore deﬁne priors in the space of
time series, compute likelihoods, perform optimal decisions etc. in the way one would
do if nuisances were absent. For instance, in L2 one can deﬁne a distance
d0(y1, y2) =
 T
0
∥y1(t) −y2(t)∥2dt
(1)
and from this, with some caveats, deﬁne a probabilistic structure dP(y).
In our
case, we can think of events of interest as equivalence classes under the action of a
nuisance group, and therefore we need to deﬁne a suitable quotient space (or base)
to perform the comparison.
Although ideally one would want a true Riemannian
metric (homogeneous spaces are in general not ﬂat) and integrate it along geodesics
to compute distances, we will limit ourselves to deﬁning cord distances directly. We
will do so in steps, ﬁrst introducing nuisances in general, then describing a variety of
distances. For simplicity we will assume that sequences are observed over a common
ﬁnite interval [0, T ], although most of the considerations can be extended to the case
where the initial time and the duration are also included among the nuisances.
2
Formalization
The ﬁrst step to introduce nuisances is to re-write (1) in a slightly different way as
d0(y1, y2) = min
h
 T
0
∥y1(t) −h(t)∥2 + ∥y2(t) −h(t)∥2dt.
(2)
Note that the two expressions (1) and (2) are identical up to a factor of two, as the right
hand-side of (2) is bounded from below by (1), and from above by the same quantity

On the Distance Between Non-stationary Time Series
287
by choosing ˆh = (y1 + y2)/2. Note also that we have been deliberately vague as to the
space where h lives, which we will indicate by H; despite it being inﬁnite-dimensional,
we do not need to impose regularization on h to solve the optimization above, which
is trivially done in closed form. The reason for introducing such an auxiliary variable
h ∈H will become clear shortly, but already one can see that this writing highlights
the underlying data-formation model: Both time series are generated from some
(deterministic but) unknown function h, corrupted by two different realizations of
additive “noise” (here the word noise lumps all unmodeled phenomena, not necessarily
associated to sensor errors)
yi(t) = h(t) + ni(t) i = 1, 2; t ∈[0, T ]
(3)
where, for instance, ni(t)
iid
∼N(0, Σ) ∀t ∈[0, T ]; i = 1, 2. Under this model, the
distance is obtained by ﬁnding the (maximum-likelihood) solution for h that minimizes
φdata(y1, y2|h) .=
2

i=1
 T
0
∥ni(t)∥2dt
(4)
subject to (3). Note that an obvious interpretation of h is that of the average of the two
time series. This will become handy later. Although not necessary at this stage, one
could consider regularized distances, for instance
dreg(y1, y2) = min
h∈H φdata(y1, y2|h) + φreg(h)
(5)
where, for instance, φreg(h) =
% T
0 ∥∇h∥dt. Once a distance is available, one can
perform classiﬁcation in a number of ways, for instance using simple k-nearest
neighbors [2].
2.1
Introducing Nuisances
Let us now consider some simple nuisances of the data collection process, and how
to eliminate them in computing a meaningful notion of distance between time series.
We have already discussed the role of the initial condition t0 = β, corresponding
to a model y(t) = h(t + β) + n(t). Another common accident of data collection
is a different sampling frequency, which translates into an afﬁne deformation of the
temporal axis y(t) = h(αt + β) + n(t). A slightly more elaborate model is a projective
transformation of the temporal axis y(t) = h( αt+β
γt+δ ) + n(t). In order to generalize this
model, we have to resort to inﬁnite-dimensional groups of domain diffeomorphisms of
the interval [0, T ] [14]; the data formation model (3) above then becomes
yi(t) = h(xi(t)) + ni(t) i = 1, 2.
(6)
Correspondingly, the data term of the cost functional we wish to optimize is
φdata(y1, y2|h, x1, x2) .=
2

i=1
 T
0
∥ni(t)∥2dt
(7)

288
S. Soatto
from which it is clear that the model is over-determined, and we must therefore impose
regularization [9] in order to compute
d1(y1, y2) =
min
h∈H,xi∈U φdata(y1, y2|h, x1, x2) + φreg(h).
(8)
The functions xi ∈U are called time warpings, and in order for τ .= x(t) to be a viable
temporal index, x must satisfy a number of properties. The ﬁrst is continuity (time, alas,
does not jump); in fact, it is common to assume a certain degree of smoothness, and for
the sake of simplicity we will assume that xi is inﬁnitely differerentiable. The second is
causality: The ordering of time instants has to be preserved by the time warping, which
can be formalized by imposing that xi be monotonic. Additional constraints can be
imposed that either are speciﬁc to a particular application, or to make the mathematical
treatment simpler. A common choice is to impose xi(0) = 0; xi(T ) = T so that the
interval [0, T ] is ﬁxed by the warping function. These regularization constraints on xi
are implicit in the notation xi ∈U and will be made explicit in Sect. 3. In the absence
of additional constraints, the solution of this problem leads to a well-known technique
which we describe next.
2.2
Dynamic Time Warping
The solution of (8) (or the determination of the minimizers ˆh, ˆxi) is called dynamic time
warping (DTW) and is standard practice in speech processing as well as in temporal
data mining. Making the constraints more explicit, we can re-write the distance above as
d2(y1, y2) =
min
h∈H,xi∈U
2

i=1
 T
0
∥yi(t) −h(xi(t))∥2 + λ∥∇h(t)∥dt
(9)
where λ is a tuning parameter for the regularizer that is not strictly necessary for this
model, and can be set equal to zero, for instance, by choosing h(t) = y1(x−1
1 (t))
(or, similarly to what we have done earlier h(t) = (y1(x−1
1 (t)) + y2(x−1
2 (t))/2) and
x(t)
.= x2(x−1
1 (t)).
This yields a “reduced” optimization problem with only one
(functional) variable,
 T
0
∥y1(t) −y2(x(t))∥dt + µφreg(x)
(10)
where we have assumed that U can be deﬁned algebraically as {x | φreg(x) = 0} .= U,
as we will make explicit in Sect. 3. In this simpliﬁed model, x matches data-to-data,
rather than each xi matching each data yi to a common underlying template h. This
distance relates to the Skorohod topology introduced for time-of-arrival processes to
account for small temporal jittering [1]. The reason for solving a seemingly more
complex problem (9), rather than (10), is because, in the presence of noise in the
measurements y1, y2, the warping x in (10) will attempt to ﬁt the noise, causing the
minimizer ˆx to be highly irregular. This is usually addressed by enforcing heavy reg-
ularization (large µ ∈R+.) The advantage of the auxiliary variables xi, h, as discussed

On the Distance Between Non-stationary Time Series
289
in detail in [17], is to avoid warping the (noisy) data yi, but instead to warp the (smooth)
template h; because in general DTW is non-linear and one has to resort to gradient al-
gorithms based on the ﬁrst-order (Euler-Lagrange) optimality conditions, the presence
of an explicit model h allows one to “push” the derivatives onto the model, arriving at
gradient-based algorithms that do not involve differentiation of the (noisy) data [22].
Before we elucidate the structure of the space of warping functions U, we pause to
note that in general it is an inﬁnte-dimensional group of diffeomorphisms [4]), as it is
(at least locally) invertible. Under the action of this group we can now distinguish two
scenarios:
•
U acts transitively on H: For any given y1, y2, there exists at least a ˆh ∈H (a
“template” in Grenander’s nomenclature) and ˆx1, ˆx2 ∈U such that the data term
φdata(y1, y2|ˆh, ˆx1, ˆx2) is identically zero. In other words, with a group action x
one can reach any y from some h. In this case, the data term of the distance is
zero, and the actual distance reﬂects the amount of “energy” or “work” necessary
to reach it. This is quantiﬁed by the regularization terms φreg(x).
•
U is restricted (for instance, it belongs to a parametric class of functions), in which
case it can only bring h “close” to y, and their proximity is reﬂected in the distance.
In either case, the minimizer ˆh can be interpreted as the “average” of the data,
in the sense elucidated in [16].
As we have mentioned, the equivalence classes
[y] .= {yi ◦x−1
i
|xi ∈U} represent the objects of interest, and the quotient space can
be thought of as the space where comparison is to be performed [20].
2.3
Dynamics, or Lack Thereof, in DTW
It is important to note that there is nothing “dynamic” about dynamic time warping.1
There is no requirement that the warping function x be subject to physical constraints,
such as the action of forces, the effects of inertia etc.
However, some notion of
dynamics can be coerced into the problem by characterizing the set U in terms of the
solution of a differential equation. Following [15], as shown by [12], one can represent
allowable x ∈U in terms of a small, but otherwise unconstrained, scalar function u:
U = {x ∈H2([0, T ]) |¨x = u ˙x; u ∈L2([0, T ])} where H2 denotes a Sobolev space.
If we deﬁne ρi .= ˙xi then ˙ρ = uρ; we can then stack the two into ξ .= [x, ρ]T , and
C = [1, 0], and write the data generation model as
8 ˙ξi(t) = f(ξi(t)) + g(ξi(t))ui(t)
yi(t) = h(Cξi(t)) + ni(t)
(11)
as done by [12], where ui ∈L2([0, T ]). Here f, g and C are given, and h, xi(0), ui are
nuisance parameters that are eliminated by minimization of the data term
φdata(y1, y2|h, x1(0), x2(0), u1, u2) .=
2

i=1
 T
0
∥ni(t)∥2dt
(12)
1 The name comes from the fact that a discretized version of this problem can be solved using
dynamic programming, since the integral in (8) can be decomposed into a sum of cost-to-go
terms due to the monotonicity constraint.

290
S. Soatto
subject to (11), with the addition of a regularizer λφreg(h) and an energy cost for ui,
for instance φenergy(ui) .=
% T
0 ∥ui∥2dt. Writing explicitly all the terms, the problem
of dynamic time warping can be written as
d3(y1, y2) =
min
h∈H,ui∈L2,xi(0)
2

i=1
 T
0
∥yi(t) −h(Cξi(t))∥+ λ∥∇h(t)∥+ µ∥ui(t)∥dt
(13)
subject to ˙ξi = f(ξi) + g(ξi)ui. Note, however, that this differential equation does not
arise out of the desire to enforce dynamic constraints exhibited in the data, but it is only
an expedient to (softly) enforce causality by imposing a small “time curvature” ui.
Fig. 1. Time series are points along equivalence classes (ﬁbers), where the nuisance acts as a
group that moves points along their ﬁbers. A proper distance in the homogeneous space of
equivalence classes is independent of the position of points on the ﬁbers: This can be achieved
by minimization, for instance by ﬁnding the minimum distance among the ﬁbers (dotted line),
or by canonization, by ﬁnding a base of the ﬁber bundle where comparisons are made (dashed
lines). The distance proposed in [13] only moves one of the two points (or their average) along
the ﬁber. One of the byproducts of the computation of the distance is the average between the
data, a concept that extends to any number N ≥2 time series.
Note also that the solution of the minimization above is not tantamount to a
nonlinear system identiﬁcation task. In fact, in system identiﬁcation one is given one
time series y, with the task of inferring the model parameters h, possibly along with
the state, input and initial condition (here f, g and C are given). If that were the case,
we could always choose h = y for any state, input and initial condition, making the
problem trivial. Here instead we are given two time series, and we want to jointly
estimate the unknown parameters of a model h that, under suitable inputs ui, can
generate the data with minimal discrepancy, measured by φdata.
3
Time Warping Under Dynamic Constraints
In this section we introduce a notion of time warping that respects the dynamic structure
of the data. Some preliminary progress towards this goal has been made by [8], who

On the Distance Between Non-stationary Time Series
291
Fig. 2. Traditional dynamic time warping (DTW) assumes that the data come from a common
function that is warped in different ways to yield different time series. In time warping under
dynamic constraints (TWDC), the assumption is that the data are output of a dynamic model,
whose inputs are warped versions of a common input function.
extended the warping function to include derivatives. However, no speciﬁc model or
assumption, other than small velocity difference, is made between the two time series.
Instead, we look for warpings that are compatible with the dynamics imposed by the
forces and inertias of the physical processes that generated the data yi. We will address
this issue by considering a generalization of the model (11). The basic idea is illustrated
in Figure 2: Rather than the data being warped versions of some common function, as in
(6), we will assume that the data are outputs of dynamical models driven by inputs that
are warped versions of some common function. In other words, given two time series
yi, i = 1, 2, we will assume that there exist suitable matrices A, B, C, state functions
xi of suitable dimensions, with their initial conditions, and a common input u such that
the data are generated by the following model, for some warping functions wi ∈U:
8
˙xi(t) = Axi(t) + Bu(wi(t))
yi(t) = Cxi(t) + ni(t).
(14)
Our goal is to ﬁnd the distance between the time series by minimizing with respect to
the nuisance parameters the following data discrepancy:
φdata(y1, y2|u, wi, xi(0)) .=
2

i=1
 T
0
∥ni(t)∥2dt
(15)
subject to (14), together with regularizing terms φreg(u) and with wi ∈U. Notice
that this model is considerably different from the previous one, as the state ξ earlier
was used to model the temporal warping, whereas now it is used to model the data,
and the warping occurs at the level of the input. It is also easy to see that the model
(14), despite being linear in the state, includes (11) as a special case, because we can
still model the warping functions wi using the differential equation in (11). In order to
write this time warping under dynamic constraint problem more explicitly, we will use
the following notation:
y(t) = CeAtx(0) +
 T
0
CeA(t−τ)Bu(w(τ))dτ .= L0(x(0)) + Lt(u(w))
(16)

292
S. Soatto
in particular, notice that Lt is a convolution operator, Lt(u) = F ∗u where F is the
transfer function. We ﬁrst address the problem where A, B, C (and therefore Lt) are
given. For simplicity we will neglect the initial condition, although it is easy to take
it into account if so desired. In this case, we deﬁne the distance between the two time
series
d4(y1, y2) = min
2

i=1
 T
0
∥yi(t) −Lt(ui(t))∥+ λ∥ui(t) −u0(wi(t))∥dt
(17)
subject to u0 ∈H and wi ∈U. Note that we have introduced an auxiliary variable u0,
which implies a possible discrepancy between the actual input and the warped version
of the common template. This problem can be solved in two steps: A deconvolution,
where ui are chosen to minimize the ﬁrst term, and a standard dynamic time warping,
where wi and u0 are chosen to minimize the second term. Naturally the two can be
solved simultaneously.
3.1
Going Blind
When the model parameters A, B, C are common to the two models, but otherwise
unknown, minimization of the ﬁrst term corresponds to blind system identiﬁcation,
which in general is ill-posed barring some assumption on the class of inputs ui. These
can be imposed in the form of generic regularizers, as common in the literature of blind
deconvolution [3]. This is a general and broad problem, but beyond our scope here,
so we will forgo it in favor of an approach where the input is treated as the output of
an auxiliary dynamical model, also known as exo-system [5]. This combines standard
DTW, where the monotonicity constraint is expressed in terms of a double integrator,
with TWDC, where the actual stationary component of the temporal dynamics is
estimated as part of the inference. The generic warping w, the output of the exo-system
(see Figure 3), satisﬁes
8
˙wi(t) = ρi(t),
i = 1, 2
˙ρi(t) = vi(t)ρi(t)
(18)
and wi(0) = 0, wi(T ) = T . This is a multiplicative double integrator; one could
conceivably add layers of random walks, by representing vi are Brownian motion.
Combining this with the time-invariant component of the realization yields the
generative model for the time series yi:
Fig. 3. TWDC can be modeled as comparison of the output of two dynamical models driven by
two exo-systems that are in charge of time-warping a common input u

On the Distance Between Non-stationary Time Series
293
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
˙wi(t) = ρi(t),
i = 1, 2
˙ρi(t) = vi(t)ρi(t)
˙xi(t) = Axi(t) + Bu(wi(t))
yi(t) = Cxi(t) + ni(t).
(19)
Note that the actual input function u, as well as the model parameters A, B, C, are com-
mon to the two time series. A slightly relaxed model, following the previous subsection,
consists of deﬁning ui(t)
.= u(wi(t)), and allowing some slack between the two;
correspondingly, to compute the distance one would have to minimize the data term
φdata(y1, y2|u, wi, A, B, C) .=
2

i=1
 T
0
∥ni(t)∥2dt
(20)
subject to (19), in addition to the regularizers
φreg(vi, u) =
2

i=1
 T
0
∥vi(t)∥2 + ∥∇u(t)∥2dt
(21)
which yields a combined optimization problem
d5(y1, y2) =
min
u,∈L2,A,B,C
2

i=1
 T
0
(∥yi(t) −Cxi(t)∥2 + ∥vi(t)∥2 + ∥∇u(t)∥2)dt
(22)
subject to (19).
3.2
Computing the Distance
In order to compute the distance for the various cases deﬁned above we have to solve
what is in effect an optimal control problem. Speciﬁcally, for the following model2
8
˙x = v x(0) = 0; x(T ) = T
˙v = uv
(23)
relative to the cost function
J =
 T
0
∥y −h(x)∥2 + u2dt
(24)
we are looking for min J subject to (23). The Hamiltonian is given by
H(x, u, λ) = ∥y −h(x)∥2 + u2 + λT [v, uv]T
(25)
and the value function (optimal cost) V should satisfy the Hamilton-Jacobi-Bellmann
equation
2 We use the simpliﬁed version where y1 = y, y2 = h, but all considerations can be easily
extended to the more general case, where ui, vi, xi have i = 1, 2.

294
S. Soatto
∂V
∂t (x, t) + min
u H

x, u, ∂V
∂x

= 0
(26)
with suitable boundary conditions.
A discretized version of this equation can be
computed on a sample time sequence
V (x, t) = min
u
 t+∆
t
∥y −h(x)∥2 + u2dτ + V (x(t + ∆), t + ∆)
(27)
with boundary conditions for x to satisfy (23) using Dynamic Programming. If we
are content with a (faster) local gradient algorithm based on the ﬁrst-order (Euler-
Lagrange) optimality conditions, then we simply update iteratively u, starting from an
initial estimate, in the direction opposite to the gradient of the Hamiltonian.
In the case of TWDC, the additional (ﬁnite-dimensional) unknowns due to the model
parameters (A, B, C) can be easily incorporated. Note that the quotient structure of
the parameter space of realizations is not an issue here since all that matters is the
minimum value (distance), rather than the minimizer (realization).
4
Correlation Kernels for Non-stationary Time Series
In this section we explore a distinctly different approach to deﬁning a distance between
time series. Instead of computing the data term φdata in terms of the L2 distance
between the time series, an alternative consists in deﬁning an inner product between
the two, via correlation, from which a cord distance can be easily computed. This has
been done for the case of time-invariant models in [21]. In this section we illustrate
how these concepts can be generalized to allow of time-warpings of the input. Using
the notation in (16), we deﬁne the (symmetric, positive-deﬁnite) kernel
K(y1, y2|u) .= Ev1,v2

trace
 T
0
y1(t)yT
2 (t)dµ(t)

= Ev1,v2

trace
 T
0
Lt(u(w1(t)))LT
t (u(w2(t)))dµ(t)

(28)
where dµ(t) ∼e−λt
t
includes an exponential discounting term and the expectation is
computed with respect to the joint density of v1, v2, subject to (18). We can make the
functional explicit by exploiting the calculations leading to equation (6.11) of [15], to
obtain
Lt = C
 T
0
eA(t−τ)Bu

K0 + K1
 τ
0
exp
 τ ′
0
v(τ ′′)dτ ′′dτ ′

dτ.
(29)
This can be substituted into the previous equation and integrated against the joint
density of v1 and v2. Several simplifying assumptions are possible for this density:
One can assume, as in [21], that the two are independent, or that they are identical.
One could also assume that v1, v2 are small an independent, an assumption implicit in

On the Distance Between Non-stationary Time Series
295
the choice of regularizer in (22) (the second term in the integral). This can be enforced
in practice by choosing a joint density for discretized versions of v1, v2 proportional to
exp(−(∥v1∥2 + ∥v2∥2)). The two constants K0, K1 can be set by imposing the bound-
ary conditions. Note that the kernel depends upon the model parameters {A, B, C},
hidden in the operator Lt, as well as on the unknown input u ∈U. Note also that
the initial condition can be used to deﬁne an additive kernel, identically to what done
in [21]. The kernel above satisﬁes Mercer’s condition, and because the sum of Mercer
kernels is also Mercer, this procedure yields a viable kernel in a straightforward manner.
The non-straightforward part of this program is the computation of the expectation
above, for which no better strategy than general Monte Carlo is currently available.
However, assuming that it can be done, one can use the kernel to deﬁne a distance via
φdata(y1, y2|u, A, B, C) .= K(y1, y1|u) + K(y2, y2|u) −2K(y1, y2|u)
(30)
and then optimize with respect to the unknowns u ∈U, A, B, C. As an alternative, one
could marginalize the unknowns to compute
d6(y1, y2) =

(φdata + λφreg(u))dP(u)
(31)
as an alternative to extremization when a measure on U is available.
5
Invariance Via Canonization
In previous sections we have explored various alternative distances where the nuisances
were eliminated by extremization (i.e. solving an optimization, or “search,” problem),
or by marginalization. In either cases, the computation of the distance entails the solu-
tion of a difﬁcult computational problem. As we have pointed out at the beginning, an
alternative way to endow a homogenous space with a metric structure is to reduce it to
its base, that is to deﬁne for each class a canonical representative, and then to compute
a distance in the base space that respects its geometry. For the case of stationary pro-
cesses, a variety of canonical realizations has been deﬁned. In our case, the canonical
representative would have to be a diffeomorphism of the domain [0, T ], and “canoni-
cal” refers to the fact that given a certain time series {y(t)}t∈[0,T ] and its associated
equivalence class [y] = {y(w(t)), w ∈U}, a canonical representative ˆy .= y( ˆw) must
be computed solely from [y], i.e. without resorting to comparison with other ﬁbers.
For simplicity, we illustrate the canonization process for the simple case of afﬁne
domain deformations ﬁrst, although the construction can be extended to arbitrary
diffeomorphisms as shown in [18] (see also Figure 4 for an illustration on this
procedure). For domain transformations of the form w(t) = αt + β we have to relax
the ﬁxed boundary conditions w(0) = 0 (lest β = 0) and w(T ) = T (lest α = 1).
Assuming the boundaries of observation of the two sequences to be undetermined, we
can canonize each sequence by choosing α and β that generate statistics of {y(w(t))}
that have a prescribed value. For instance, we can take some differential statistics,
of the form φ(y) =
dky
dtk , and impose that they take a prescribed value in uniquely
identiﬁable positions. For instance, t1 can be the ﬁrst position where dy
dt = 0, assigned

296
S. Soatto
Fig. 4. Simple canonization for comparing time series: Extrema of the warped function (or a
scale-space of it) are assigned to ﬁxed value in increasing order. The back-warped time series is
then, by construction, invariant to domain warpings.
to a ﬁxed value on the axis, say t = 0. This ﬁxes the translation group β. We can
then take the second point where dy
dt = 0, and assign it to a ﬁxed value, say t = 1.
This ﬁxes the linear scaling group α. The procedure can be extended to more general
warpings, for different statistics, including integral ones (moments) of higher order.
Note that if the data y are such that such distinct points do not exist (for instance if
y(t) is constant), then any α and β would do. So, in other words, where we can ﬁnd
statistics that depend on w, we can ﬁx them to canonize w; where the statistics do not
depend on w, these are already, by deﬁnition, invariant!
We now extend this construction more formally. Consider a set of data (time series)
{yi ∈M}i=1,...,n undergoing the action of a nuisance group wi ∈U, to yield their
irked versions ˜yi = wiyi
.= yi(wi(t)). The ambient space, where the irked data
live, is the set of orbits N .= M U. Now, suppose that there exists a “feature,” i.e. a
function φ : N →Rl, where l is the dimension of U, such that φ(w−1˜y) = 0 uniquely
determines u up to a set of measure zero K ⊂N.3 Then, we can eliminate the effect
of the nuisance by pre-processing each irked datum via ˆy .= ˆw−1˜y | φ( ˆw−1˜y) = 0
to obtain a canonical element ˆy ∈M. The choice of ˆy is canonical in the sense of
conforming to the rule φ(ˆy) = 0.4 The function φ is called a pontiﬁcal feature since
it is the feature (i.e. the statistic) that determines how ˜y is to be canonized. If the data
space M, undergoing the action of the nuisance group U, admits a pontiﬁcal feature, it
is called sanctiﬁable. We write the canonization process more succinctly as
ˆy .= φ−1(0|˜y) = ˆw−1˜y | φ( ˆw−1˜y) = 0
(32)
or, with an unholy abuse of notation, as ˆy = φ−1(˜y). It is easy to construct examples
that show that not all spaces are sanctiﬁable [18]. Note, however, that whether a space
is sanctiﬁable depends on the base M as well as on the nuisance U. In general, the
larger the nuisance, the more difﬁcult it is for the space to be sanctiﬁed. Sometimes it
is possible for the space to be sanctiﬁable, but with only one canonical element. That
is, the quotient is zero-dimensional, and the entire irked population {˜yi} is equal under
the law φ = 0. In this case we say that the space N collapses under the nuisance U.
3 Such a set of measure zero is the set of data that is invariant under a subgroup H ⊆U, i.e. the
symmetry set of H: K .= {˜y | φ(w−1˜y) = φ(˜y) ∀u ∈U}.
4 The choice of zero in the rule φ = 0 is arbitrary, and any other value φ = k ̸= 0 would
work just as well, yielding a different set of canonical representatives ˆy ∈N/U. Therefore, in
general the base space N/U where the canonical representatives live is not necessarily equal
to M, but it is related to it by a parallel translation ˜w ∈U, so that the “true” space is given by
M = ˜wN/U. Since any value k ̸= 0 can be incorporated into the deﬁnition of φ, the choice
of the zero level set in (32) is without loss of generality.

On the Distance Between Non-stationary Time Series
297
Example 1. In Grenander’s “Deformable templates” [4] the objects of interest (“target
shapes”) are obtained from a common generator (the “template”) under the action of an
inﬁnite-dimensional group. Because of the assumption that the group acts transitively,
the entire world of objects of interest is equivalent under the action, and therefore the
space collapses under the nuisance.
To construct a simple pontiﬁcal feature, consider simply the function φ(˜y) .= d˜y
dt , and
let t1, . . . , tN be the N local extrema of ˜y:
ti .= t | φ(˜y) = 0, i = 1, . . . , N
(33)
Because d˜y
dt =
dy
dt
dw
dt and by assumption w ∈U we have that dw
dt > 0, t ∈[0, T ],
we have that the values ˜y(ti) are independent of w. We can then choose a canonical
representative for w by imposing
ˆw(ti) =
i
N + 1T
(34)
where we have assumed t0 = 0 and tN+1 = T . The canonical representative of ˜y is
then simply given by
ˆy(t) = ˜y( ˆw−1(t)),
t ∈[0, T ].
(35)
Finally, the distance between canonical elements can be simply computed in L2:
d7(y1, y2) =
 T
0
∥y1( ˆw−1
1 (t)) −y2( ˆw−1
2 (t))∥2dt =
 T
0
∥ˆy1(t) −ˆy2(t)∥2dt
(36)
Note that this solution is the canonization counterpart of DTW presented in Sect. 2.2.
In order to extend this to TWDC as presented in Sect. 3 one would have to canonize
v(t), rather than w(t), which can be done at the expense of additional notation, and we
will therefore forgo it in this venue.
As we have already observed, the choice of canonical element is arbitrary, so that
the effects of canonization in classiﬁcation largely depend on the ﬁne art of choosing
a pontiﬁcal feature. Such a feature is, by design, invariant to the nuisances we have
modeled explicitly: The art consists in making it also robust, or “insensitive,” to other
factors that we do not have explicitly modeled. In particular, canonization is sensitive
to missed detections or spurious detections in the pontiﬁcal feature. For instance, in
the illustrative case just discussed, in the presence of noise one would have different
realization produce different numbers and location of local minima.
This can be
minimized by deﬁning a scale-space of features, rather than considering the signal only
at the resolution deﬁned by the sample frequency of the sensor [10], and [19] for a
more thorough discussion on this issue.
6
Discussion
The impact of the system-theoretic approach to dynamic data analysis has yet to be felt
in important areas of applications such as data mining or computer vision. In order for

298
S. Soatto
this to happen, more general and ﬂexible models have to be introduced. In this work we
have made a modest step in this direction, by introducing Time Warping under Dynamic
Constraints (TWDC), a method to compare time series that respects their dynamics. We
have also introduced, albeit in a purely formal manner, a correlation kernel between pro-
cesses that would respect their dynamic structure, if one could afford the time to com-
pute the expectation with respect to the joint density of the driving noises. Finally, we
have illustrated how one could, in principle, construct time-deformation-invariantstatis-
tics from time series to arrive at canonical representatives that are not affected by nui-
sances. These hold the promise for more efﬁcient comparison, for each sequence can be
pre-processed and comparison is performed by the simple computation of an L2 norm.
Acknowledgments
This work has beneﬁted from extended discussions with Alessandro Chiuso, Andrea
Vedaldi, Gregorio Guidi, Michalis Raptis, and Ren´e Vidal. Anything good there might
be in it, it has been inﬂuenced – directly or indirectly – by Giorgio Picci’s work. All the
rest is sole responsibility of the author. The support of AFOSR and ONR is gratefully
acknowledged.
References
1. P. Billingsley. Convergence of Probability Measures. Wiley, 1968.
2. A. Bissacco, A. Chiuso, and S. Soatto. Classiﬁcation and recognition of dynamical models:
the role of phase, independent components, kernels and optimal transport.
IEEE Trans.
Pattern Anal. Mach. Intell., in press, 2007.
3. B. Giannakis and J. Mendel. Identiﬁcation of nonminimum phase systems using higher order
statistics. IEEE Trans. on Acoustic, Speech and Signal Processing, 37(3):360–377, 1989.
4. U. Grenander. General Pattern Theory. Oxford University Press, 1993.
5. A. Isidori. Nonlinear Control Systems. Springer Verlag, 1989.
6. G. Johansson.
Visual perception of biological motion and a model for its analysis.
Perception and Psychophysics, 14:201–211, 1973.
7. H. Kantz and T. Schreiber. Nonlinear Time Series Analysis. Cambridge University Press,
2004.
8. E. J. Keogh and M. J. Pazzani.
Dynamic time warping with higher order features.
In
Proceedings of the 2001 SIAM Intl. Conf. on Data Mining, 2001.
9. A. Kirsch. An introduction to the mathematical theory of inverse problems. Springer-Verlag,
New York, 1996.
10. T. Lindeberg. Scale space for discrete signals. IEEE Trans. Pattern Anal. Mach. Intell.,
12(3):234–254, 1990.
11. A. Lindquist and G. Picci. The stochastic realization problem. SIAM J. Control Optim. 17,
pages 365–389, 1979.
12. C. F. Martin, S. Sun, and M. Egerstedt. Optimal control, statistics and path planning. 1999.
13. R. Martin. A metric for arma processes. IEEE Trans. on Signal Processing, 48(4):1164–
1170, 2000.
14. P. J. Olver. Equivalence, Invariants and Symmetry. Cambridge University Press, 1995.
15. J. O. Ramsey and B. W. Silverman. Functional Data Analysis. Springer Verlag, 2005.

On the Distance Between Non-stationary Time Series
299
16. S. Soatto and A. Yezzi.
Deformotion: deforming motion, shape average and the joint
segmentation and registration of images. In Proc. of the Eur. Conf. on Computer Vision
(ECCV), volume 3, pages 32–47, 2002.
17. S. Soatto, A. J. Yezzi, and H. Jin. Tales of shape and radiance in multiview stereo. In Intl.
Conf. on Comp. Vision, pages 974–981, October 2003.
18. A. Vedaldi and S. Soatto. Features for recognition: viewpoint invariance for non-planar
scenes. In Proc. of the Intl. Conf. of Comp. Vision, October 2005.
19. A. Vedaldi and S. Soatto.
Viewpoint induced deformation statitics and the design of
viewpoint invariant features: singularities and occlusions. In Eur. Conf. on Comp. Vision
(ECCV), pages II–360–373, 2006.
20. A. Veeraraghavan, R. Chellappa, and A. K. Roy-Chowdhury.
The function space of an
activity. In IEEE, editor, Proc. IEEE Conf. on Comp. Vision and Pattern Recogn., 2006.
21. S.V.N. Vishwanathan, R. Vidal, and A. J. Smola.
Binet-cauchy kernels on dynamical
systems and its application to the analysis of dynamic scenes.
International Journal of
Computer Vision, 2005.
22. A. Yezzi and S. Soatto. Stereoscopic segmentation. In Proc. of the Intl. Conf. on Computer
Vision, pages 59–66, 2001.

Stochastic Realization for Stochastic Control
with Partial Observations
Jan H. van Schuppen
CWI, P.O.Box 94079, 1090 GB Amsterdam, The Netherlands
J.H.van.Schuppen@cwi.nl
The paper is dedicated to Giorgio Picci on the occasion of his 65th birthday for his
inspiring contributions to stochastic realization and to system identiﬁcation.
1
Introduction
The purpose of this paper is to present a novel way to formulate control problems with
partial observations of stochastic systems. The method is based on stochastic realization
theory.
The contribution of the paper is the stochastic realization approach to stochastic con-
trol with partial observations. The motivation for the paper are the weaknesses of con-
trol with partial observations based on the separation principle. The separation property
holds for the stochastic control problem with a Gaussian system and a quadratic cost
function (LQG), but does not hold for at least one optimal stochastic control problem,
LEQG, and may not hold for most other stochastic control problems. Moreover, control
of decentralized stochastic systems or control of stochastic dynamic games becomes
unsolvable or unnatural in the existing approaches in the literature. Therefore a novel
approach may be explored.
The stochastic realization approach to stochastic control with partial observations
proceeds by the following steps. (1) A stochastic realization of the input-output process
is selected such that the state space is ﬁnite or ﬁnite-dimensional and at any time the
state is a measurable function of the past outputs and the past inputs. (2) An optimal sto-
chastic control problem with complete observations is solved by the existing stochastic
control theory. The advantage of this approach is that the stochastic realization selected
has a state set which is ﬁnite or ﬁnite-dimensional. According to the classical control
theory one has to solve a ﬁltering problem of which the state set of the ﬁlter system is
not necessarily ﬁnite or ﬁnite-dimensional. This difﬁculty is avoided in the proposed
approach.
The contents of the paper is described below. The next section contains the problem
formulation. The classical approach to stochastic control with partial observations is
summarized in Section 3. The stochastic realization approach to stochastic control with
partial observations is presented in Section 4. Several special cases are discussed in
Section 5. Concluding remarks are stated in the last section.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 301–314, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

302
J.H. van Schuppen
2
Problem Formulation
The problem of control with partial observations of stochastic systems is formulated
in this section and the approach is summarized. The approach is developed in the
subsequent sections.
The notation of this paper is in accordance with the literature on control of stochastic
systems. A probability space, denoted by (Ω, F, P), consists of a sample set Ω, a σ-
algebra F of subsets of Ω, and a probability measure P : F →[0, 1]. The set of the
integers is denoted by Z, the natural numbers by N = {0, 1, 2, . . .}, the strictly positive
integers by Z+ = {1, 2, 3, . . .}, and for n ∈Z+, Zn = {1, 2, . . ., n}. In this paper
attention is restricted to discrete-time stochastic control systems hence the time index set
is denoted by either T = {0, 1, . . .} = N ⊂Z, or T = {0, 1, . . ., t1} ⊂N. For a strictly
positive integer n ∈Z+, (Rn, B(Rn)) denotes the n-fold Cartesian product of the real
numbers with the Borel σ-algebra generated by the open subsets of Rn. A Gaussian
probability measure on Rn is denoted by G(m, Q) where the parameter corresponding
to the mean value is m ∈Rn and the parameter corresponding to the variance is Q ∈
Rn×n satisfying Q = QT ≥0. Denote by F x0 the σ-algebra generated by the random
variable x0. A Gaussian random variable is a random variable x : Ω→Rn with a
Gaussian probability measure, denoted by x ∈G(m, Q).
A discrete-time Gaussian white noise process with variance Qv is a stochastic pro-
cess v : Ω× T →Rmv such that {v(t), t ∈T } is a sequence of independent random
variables and for each t ∈T , the random variable v(t) : Ω→Rmv has a Gaussian
distribution with v(t) ∈G(0, Qv) where Qv ∈Rmv×mv, Qv = QT
v ≥0. The ﬁltration
generated by a stochastic process v : Ω×T →Rmv is denoted by {F v
t , t ∈T ∪{∞}}.
The open unit disc of the complex plane is denoted by Do = {c ∈C| |c| < 1}.
The main concept of stochastic system theory is that of a stochastic control system.
Distinguish an input process to be determined by the controller, an output process which
is observed, and a state process. A state process of a stochastic control system is such
that at any time moment the conditional distribution of future states and of future out-
puts conditioned on the past of the output and the past and future of the input process at
that particular time depend only on the current state and the future inputs. It is a result of
stochastic realization theory that there are in general several stochastic control systems
which describe the same processes and any of these systems will be termed a stochastic
realization. Attention has to be restricted to that stochastic realization of which at any
time the state is measurable with respect to the past outputs and the past inputs.
The problem of control with partial observations is now formalized in terms of
words, not in terms of mathematical notation. In Section 3 the problem will be formal-
ized mathematically. Consider then a stochastic control system and a set of control laws
or controllers. The interconnection of the stochastic control system and a controller is
termed the corresponding closed-loop system. A control objective is a property of the
closed-loop system which a control designer strives to attain. Examples of control ob-
jectives for the control problem include: stochastic stability, minimization of a perfor-
mance criterion, robustness of the performance with respect to disturbance signals often
the variance, and adaptation to long term changes in the stochastic control system.
Problem 1. Stochastic control with partial observations. Consider an input and out-
put process. Determine a controller which speciﬁes at each time which input to apply

Control with Partial Observations
303
based on the past output and the past input values such that a set of prespeciﬁed control
objective is met as well as possible.
The approach to the problem proposed in this paper is to ﬁrst select a stochastic realiza-
tion in the form of a stochastic system of the input and the output process of which the
associated state is measurable in terms of the past outputs and the past inputs. Second,
the stochastic control problem for this stochastic realization is solved. Note that the
latter problem is a control problem with complete observations! For the latter problem
there are many approaches including optimal control theory. The approach is formu-
lated in Section 4, special cases are described in Section 5, but only after the classical
approach is summarized in Section 3.
3
The Classical Approach
In this section the classical approach to stochastic control with partial observations is
sketched brieﬂy so as to contrast it with the to be proposed approach.
The theoretical framework for stochastic control with partial observations was mainly
formulated during the 1960’s. At the early 1960’s there were available the theory for op-
timal control of deterministic systems based on the maximum principle and the dynamic
programming approach. Moreover, the Kalman ﬁlter was published as an alternative to
the Wiener ﬁlter theory. The control objective of suppression of disturbance signals
focused attention on the control of stochastic systems later on called the problem of
stochastic control.
The solution of the discrete-time stochastic control problem with a Gaussian stochas-
tic control system and a quadratic cost function is credited to [13, 15]. The theoretical
framework is due to C. Striebel and W.M. Wonham. C. Striebel formulated the concept
of an information system for stochastic control, the concept of a sufﬁciently informative
statistic for the control cost, and formulated the dynamic programming approach to sto-
chastic control with partial observations, see [20]. The continuous-time framework was
developed by W.M. Wonham who observed that in general the conditional distribution
of the state depends on the control law used but that for the case of a Gaussian sto-
chastic control system the conditional distribution does not depend on the control law.
The stochastic control problem then exhibits the separation property, the problem sep-
arates into a ﬁltering problem and a control problem with complete observations. This
property has later on been used to formulate the separation principle of control with
partial observations of nonlinear systems. Thus, according to the separation principle,
one proceeds under the hypothesis that the problem of control with partial observations
separates into a ﬁltering problem and a control problem with complete observations re-
gardless of whether the problem at hand has the separation property. The achievements
of the 1960’s still stand out as major contribution of control theory. Further exten-
sions to stochastic control with partial observations for nonlinear systems with Gaussian
disturbance signals were published by Ray Rishel, Pravin Varaiya, Mark H.A. Davis,
Charlotte Striebel, V.E. Benes and I. Karatzas, see [2,
8
,7
,
2
1
,2 ,
]. By now the topic
of stochastic control with partial observations is covered well in the text books [4], its
latest edition [5,6], and [12,17].
19
2

304
J.H. van Schuppen
The approach of separation was extended to control with partial observations in
case of decentralized control and of stochastic dynamic games. Hans Witsenhausen
formulated several results and conjectures on separation of ﬁltering and control, see
[25,26,27].
Below the classical approach to stochastic control with partial observations is
sketched brieﬂy for Gaussian stochastic control systems to contrast it later with the
stochastic realization approach.
Deﬁnition 1. Consider a Gaussian stochastic control system of the form
x(t + 1) = Ax(t) + Bu(t) + Mv(t), x(t0) = x0,
(1)
y(t) = Cx(t) + Du(t) + Nv(t).
(2)
The remaining conditions are formulated in Deﬁnition 3 except that the rank condition
on the matrix N is not imposed in this deﬁnition.
A control law for the above system is a map g : T × Y T × U T →U. Denote the set of
control laws by (with abuse of notation)
G =
 g : T × Y T × U T →U|g is a measurable function
g is causal g(t, y|[0,t], u|[0,t]) = g(t, y, u)

.
Deﬁne the closed-loop system associated with the above Gaussian stochastic control
system and a control law g ∈G as the stochastic system
xg(t + 1) = Axg(t) + Bg(t, yg|[0,t), ug|[0,t)) + Mv(t), xg(t0) = x0,
(3)
yg(t) = Cxg(t) + Dg(t, yg|[0,t), u|[0,t)) + Nv(t),
(4)
ug(t) = g(t, yg|[0,t), u|[0,t)).
(5)
To emphasize the dependence of the state and the output process on the control law
g, the control law is used as a super index. Deﬁne a cost function for any control law
g ∈G as
J(g) = E[
t1−1

s=0
b(xg(s), ug(s)) + b1(xg(t1))],
(6)
J : G →R+, b : X × U →R+, b1 : X →R+.
The problem of optimal stochastic control with partial observations for the above sys-
tem, the set of control laws, and the cost function is then to solve the problem
inf
g∈G J(g).
(7)
This amounts to determining the inﬁmal value, establishing the existence of an optimal
control law g∗∈G if one exists (thus J(g∗) = infg∈G J(g)), and establishing whether
or not an optimal control law is unique.
The classical approach to stochastic control with partial observations for the above
formulated problem as sketched below is due to W.M. Wonham. First solve the ﬁl-
tering problem for the Gaussian stochastic control system: determine the conditional
distribution of the state conditioned on the past outputs and the past inputs

Control with Partial Observations
305
E[exp(iwT xg(t))|F yg
t−1 ∨F ug
t−1], ∀t ∈T, ∀g ∈G.
(8)
As ﬁrst observed by Wonham, the conditional distribution depends on the control law
used. The reader may want to note that in case the control law g ∈G is nonlinear
then the state process xg is not even a Gaussian stochastic process in general hence
the Kalman ﬁltering approach cannot be applied. The achievement of Wonham was to
prove that the conditional distribution does not depend on the control law used. Then the
ﬁltering problem can be solved by the Kalman ﬁlter theory. The resulting equations are
ˆx(t + 1) = Aˆx(t) + Bu(t) + K(t)[y(t) −Cˆx(t) −Du(t)], ˆx(t0) = 0,
K(t) = [AQ(t)CT + MV N T ][CQ(t)CT + NV N T ]−1,
and where the function Q : T →Rn×n is the solution of the forward ﬁlter Riccati dif-
ference equation. The reader will easily ﬁnd that ﬁlter Riccati equation in the literature.
The second step of the classical approach is to solve a stochastic control problem
with complete observations. The stochastic system is now that of the ﬁlter system but
notice that now the state of the system is a function of the past outputs and the past
inputs hence available to the control law. The latter problem can be solved by the
existing control theory of stochastic control with complete observations. The resulting
equations are
GX = {g : T × X →U|g measurable function}
g ∈GX a control law,
J(g) = E[
t1−1

s=t0
b(xg(s), ug(s)) + b1(xg(t1))],
b(x, u) =
x
u
T  L11 L12
LT
12 L22
  x
u

, b1(x) = xT L1x,
L =
L11 L12
LT
12 L22

= LT ≥0, L22 > 0, L1 = LT
1 ≥0;
inf
gx∈GX J(gx),
g∗(t, x) = F(t)ˆxg∗the optimal control law,
u∗(t) = F(t)ˆxg∗(t) the optimal input trajectory,
ˆxg∗(t + 1) = Aˆxg∗(t) + BF(t)ˆxg∗(t) +
+K(t)[yg∗(t) −Cˆxg∗(t) −DF(t)ˆxg∗(t)],
F(t) = −[BT P(t + 1)B + L22]−1[AT P(t + 1)B + L12]T ,
where P : T →Rn×n is the solution of the backward control Riccati difference equa-
tion not displayed here.
4
The Stochastic Realization Approach to Stochastic Control with
Partial Observations
Deﬁnition 2. The stochastic realization approach to stochastic control with partial ob-
servations. Determine a weak stochastic realization of the input-output process in the

306
J.H. van Schuppen
form of a stochastic control system such that (1) the joint input-output process of this
system equals the considered input-output process in terms of their families of ﬁnite-
dimensional probability distributions (this amounts to the system being a weak stochas-
tic realization), and (2) at any time the state of the system is measurable with respect to
the σ-algebra generated by the past of the output and the past of the input process. Thus
the stochastic control problem has become one with complete observations in stead of
being one with partial observations.
Then solve the stochastic control problem for the above deﬁned stochastic realization
by a method of stochastic control with complete observations.
The approach is illustrated by several special cases in Section 5.
What needs to be established and proven according to the proposed approach?
1. Formulate a stochastic system.
2. Prove that the stochastic control system is a stochastic realization with the required
measurability properties.
3. Solve the stochastic control problem with complete observations.
4. Assemble the control law from the stochastic realization and the solution of the
stochastic control system.
As with algebraic approaches to control, the most difﬁcult step is the formulation of a
stochastic system which has the required measurability properties. This step is a choice
rather than the end product of a ﬁltering problem.
The reader may expect a discussion on stochastic controllability of the stochastic
realization. In stochastic control theory the stochastic controllability enters via the cost
function, it plays a role only to produce ﬁniteness of the cost function on an inﬁnite
horizon. For limitations of space this issue is not discussed further in this paper.
The advantages of the stochastic realization approach to stochastic control with par-
tial observations are:
•
The state space of the stochastic realization mentioned above is ﬁnite or ﬁnite-
dimensional by formulation. This condition refers to the state space of the stochastic
realization.
•
The stochastic control problem in the stochastic realization approach is one with
complete observations for which theory is well developed.
•
No ﬁltering problem needs to be solved in the proposed approach while it has to
be solved in the classical approach. Note that for nonlinear stochastic systems the
ﬁltering problem will in many cases not admit a ﬁnite or a ﬁnite-dimensional ﬁlter
system. Therefore the difﬁculties of deriving a ﬁnite-dimensional ﬁlter system are
avoided.
For an exposition of stochastic realization see [23] or [18].
5
Special Cases
The stochastic realization approach to control with partial observations is detailed for
several special cases. The ﬁrst special case is that of a Gaussian stochastic control
system and a quadratic cost function, often referred to as the LQG case. The example

Control with Partial Observations
307
is rather elementary because of several particularities of this stochastic control system.
In fact, the LQG case is such that the resulting control law according to the stochastic
realization approach is identical to that of the classical approach. But the subsequent
examples show that the situation can be completely different.
A Gaussian Stochastic Control System and a Quadratic Cost Function
Deﬁnition 3. A Gaussian stochastic control system. Consider an input process and a
Gaussian output process. The stochastic realization in the form of a Gaussian stochastic
control system is described by the equations
x(t + 1) = Ax(t) + Bu(t) + Kv(t), x(0) = x0,
(9)
y(t) = Cx(t) + Du(t) + Nv(t),
(10)
n, m, mv, p ∈Z+,
x0 : Ω→Rn, F x0 ⊂F y
0 ∨F u
0 , x0 ∈G(0, Q0),
(11)
v : Ω× T →Rp, is Gaussian white noise with,
v(t) ∈G(0, Qv), Qv = QT
v > 0,
u : Ω× T →Rm = U, the input process,
F x0, F v
∞are independent σ-algebras,
F u(t) ⊆F y
t−1, ∀t ∈T,
x : Ω× T →Rn = X, the state process,
y : Ω× T →ru(ω) = Y, the output process,
A ∈Rn×n, B ∈Rn×m, K ∈Rn×p,
C ∈Rp×n, D ∈Rp×m, N ∈Rp×p,
rank (N) = p, spec(A) ⊂Do, spec(A −KN −1C) ⊂Do.
(12)
such that the joint input-output process (u, y) of the stochastic control system equals
the considered input-output process in distribution.
Proposition 1. The deﬁned system is a stochastic realization of the input-output pro-
cesses and has the speciﬁed measurability properties.
Proof. The system is a stochastic realization by construction. Note further that
v(t) = N −1[y(t) −Cx(t) −Du(t)], where (12) is used,
x(t + 1) = Ax(t) + Bu(t) + KN −1[y(t) −Cx(t) −Du(t)]
= [A −KN −1C]x(t) + [B −KN −1N]u(t) + Ky(t), x(0) = x0,
x0 is F y
0 ∨F u
0 measurable where (11) is used,
and by induction one can prove that for all t ∈T \{t0}, x(t) is F y
t−1 ∨F u
t−1 measurable
hence F x
t ⊂F y
t−1 ∨F u
t−1, ∀t ∈T .
On purpose the state process of the above stochastic realization is denoted by x and not
by ˆx so as to avoid analogy with the classical approach. Note however that the state
process has the imposed measurability property.

308
J.H. van Schuppen
The stochastic control problem can now be solved using the theory of stochastic
control with complete observations. The resulting problem and the result are stated
below for future reference.
Problem 2. The stochastic control problem with partial observations according to
the stochastic realization approach.
Consider the Gaussian stochastic system of
Deﬁnition 3. Consider the cost function,
J(g) = E[
t1−1

s=t0
b(x(s), u(s)) + b1(x(t1))], J : G →R+,
(13)
b(x, u) =

x
u
T 
L11 L12
LT
12 L22
 
x
u

, b1(x) = xT L1x,
L =
 L11 L12
LT
12 L22

= LT ≥0, L22 > 0, L1 = LT
1 ≥0.
Solve the problem
inf
g∈G J(g).
Theorem 1. Consider the stochastic control problem deﬁned above. The solution to the
optimal stochastic control problem is
g∗(t, x) = F(t)x, the optimal control law,
(14)
ug∗(t) = F(t)xg∗(t), the optimal input process,
(15)
xg∗(t + 1) = Axg∗(t) + BF(t)xg∗(t) +
+K[yg∗(t) −Cxg∗(t) −DF(t)xg∗(t)], xg∗(t0) = x0,
(16)
F(t) = −[BT P(t + 1)B + L22]−1[AT P(t + 1)B + L12]T ,
(17)
where P : T →Rn×n is the solution of the backward control Riccati difference equa-
tion not displayed in this paper.
A proof of the solution to the optimal stochastic control problem with complete obser-
vations may be found in [4, Section 3.1].
Note that the optimal control law consists of the proper control law Equation (14)
and the system Equation (16). The latter system is the stochastic realization rewritten as
a ﬁlter. The optimal control law is identical to that of the classical approach described
in Section 3 except for the time invariance of the ﬁlter.
LEQG
The LEQG stochastic control problem with partial observations. The classical approach
to solving the stochastic control problem with partial observations for a Gaussian sto-
chastic system with an expected value of an exponential cost function is unsatisfactory.
The conditional mean of the state based on past observations is not a sufﬁcient informa-
tion state as understood in stochastic control theory. Therefore the classical approach
cannot proceed. A solution has been published of this problem in discrete-time and

Control with Partial Observations
309
the proof is not based on the classical approach, see [24]. In continuous-time the corre-
sponding problem has a solution, see [3], but the conditional mean is not the information
state of the conditional distribution.
The stochastic realization approach to stochastic control with partial observations
then proceeds according to Deﬁnition 2.
Deﬁnition 4. Consider a Gaussian stochastic system
x(t + 1) = Ax(t) + Bu(t) + Kv(t), x(t0) = x0,
y(t) = Cx(t) + Du(t) + Nv(t),
with the conditions of Deﬁnition 3 and in addition Qv > 0.
Problem 3. Consider the Gaussian stochastic system of Deﬁnition 4. Consider the op-
timal stochastic control problem
J(g) = E[c exp(c
t1−1

s=t0
b(x(s), u(s)) + b1(x(t1))], c ∈R\{0},
(18)
b(x, u) =

x
u
T 
L11 L12
LT
12 L22
 
x
u

, b1(x) = xT L1x,
(19)
L =
 L11 L12
LT
12 L22

= LT ≥0, L22 > 0, L1 = LT
1 ≥0,
inf
g∈G J(g).
(20)
Theorem 2. Consider the above formulated optimal stochastic control problem. The
solution to the optimal stochastic control problem is
g∗(t, x) = F(t)xg∗, the optimal control law,
(21)
u∗(t) = F(t)xg∗(t), the optimal input trajectory,
(22)
xg∗(t + 1) = Axg∗(t) + BF(t)xg∗(t) +
+K[yg∗(t) −Cxg∗(t) −DF(t)xg∗(t)], xg∗(t0) = x0,
(23)
F(t) = −[BT P1(t)B + L22]−1[AT P1(t)B + L12]T ,
(24)
P(t1) = L1, P, P1 : T →Rn×n
(25)
P1(t) = P(t + 1) +
cP(t + 1)M[Q−1
v
−cMP(t + 1)M]−1MP(t + 1),
(26)
P(t) = AT P1(t)A + L11 +
(27)
−[AT P1(t)B + L12][BT P1(t)B + L22]−1[AT P1(t)B + L12],
and the conditions are imposed that,
0 < Q−1
v
−cM TP(t + 1)M, 0 < BT P1(t)B + L22, ∀t ∈T.
(28)
The proof follows from the paper by D.H. Jacobson [14]. The conditions (28) represent
stochastic controllability conditions because they assure ﬁniteness of the cost function.
The corresponding result for the classical approach to stochastic control with partial
observations is not in the literature. What is in the literature is a result of P. Whittle but
that is for the nonstandard system representation in discrete-time of the form,

310
J.H. van Schuppen
x(t + 1) = Ax(t) + Bu(t) + Kv(t), x(t0) = x0,
y(t + 1) = Cx(t) + Du(t) + Nv(t).
The result for Whittle’s system representation and the result for the standard form used
in this paper are not comparable. The result of the classical approach for the continuous-
time case is available in [3].
The conclusion for this LEQG case is that the solution is completely different
from the solution to the classical approach as described in [24]. For the result of the
continuous-time classical approach see [3,16].
Finite Stochastic Systems
Stochastic control with partial observations of a ﬁnite stochastic system. A ﬁnite sto-
chastic system is a stochastic system as deﬁned earlier in the paper of which both the
state set and the output set are ﬁnite sets.
First the classical approach of solving this stochastic control problem is sketched.
The stochastic system is speciﬁed by the probability distribution of the initial state and
by the stochastic transition function according to the formulas
n, m, p ∈Z+,
X = {x1, x2, . . . , xn}, the state set,
U = {u1, u2, . . . , um}, the input set, Y = {y1, y2, . . . , yp}, the output set,
P({x0 = xi}), ∀i ∈Zn,
the probability distribution of the initial state,
P({x(t + 1) = xi, y(t) = yk}|F y
t−1 ∨F u
t−1), ∀i ∈Zn,
the stochastic transition function.
The representation of the ﬁnite stochastic system is such that the state, input, and output
sets are ﬁnite while the state, the input, and the output process are such that the state at
time t equals one of the values of the state set. An alternative representation often used
in the literature is to take as state space Rn
+ and then the state takes the value of the i-the
unit vector if it equals the i-th element of the state set.
The ﬁltering problem for such a ﬁnite stochastic system has been known since the
early 1960’s. The ﬁlter system has as stated vector
ˆxi(t + 1) = P({x(t + 1) = xi}|F y
t−1 ∨F u
t−1) ∈[0, 1], ∀i ∈Zn.
Note that the state set of the ﬁlter system is [0, 1]n and is thus not a ﬁnite set. The sto-
chastic control problem with partial observations can then be solved using the classical
theory with as stochastic system the ﬁlter system. No analytic solutions to this optimal
stochastic control problem are known to the author of this paper. References on the
classical approach are [1,9,10,11].
The stochastic realization approach to stochastic control with partial observations is
to ﬁrst take a stochastic realization of the input-output process with as state process a
process which is a measurable function of the past outputs and the past inputs. This
selection of a stochastic realization turns out to be a major step of the approach.

Control with Partial Observations
311
Deﬁnition 5. The stochastic realization is taken to be,
n, m, p ∈Z+,
X = Rn
+, X = {x1, x2, . . . , xn}, the state set,
U = Rm
+, U = {u1, u2, . . . , um}, the input set,
Y = Rp
+, Y = {y1, y2, . . . , yp}, the output set,
ei ∈Rn
+, the i-the unit vector of Rn
+,
x0 : Ω→Rn, F x0 ⊆F y
0 ,
x : Ω× T →Rn
+, u : Ω× T →U, y : Ω× T →Rp
+,
deﬁne for all i ∈Zn,
x(t + 1) = ei,
(29)
if Si(x(t), u(t), y(t)) > Sj(x(t), u(t), y(t)), ∀j ∈Zn,
(30)
or if i is the smallest element of Zn such that
Si(x(t), u(t), y(t) ≥Sj(x(t), u(t), y(t)), ∀j ∈Zn,
(31)
S : Rn
+ × U × Rp
+ →Rn,
S(x(t), u(t), y(t)) = Ax(t) + Bu(t) + K[y(t) −Cx(t)],
(32)
A ∈Rn×n
+
, B ∈Rn×m
+
, C ∈Rp×n
+
,
spec(A −KC) ⊂Do.
(33)
The choice of the above deﬁned stochastic realization requires comments. The stochas-
tic realization has to be such that the state is a measurable function of the past outputs
and the past inputs. Hence the dependence on y(t) and u(t) in the transition function
of the stochastic system.
The particular form of taking x(t+1) = ei if Si(.) > Sj(.) is a choice. The choice is
reasonable because if the output process is constant than one wants the state to approach
the state component which generates this particular output. This choice is in accordance
with the concept of a stochastic realization of which the state is a measurable function
of the past outputs and the past inputs. There is the difﬁculty when there exist i, j ∈Zn
with i ̸= j such that Si(x(t), u(t), y(t)) = Sj(x(t), u(t), y(t)). The above choice is
to take as next state the index of the lowest integer i in case two or more equal Si
values. This choice is not invariant with respect to ordering. However, one cannot take
a random choice because that would not meet the required measurability property.
The matrices A and C relate directly to the probabilistic interpretation of the ﬁnite-
state stochastic system. There remains the choice of the matrix K ∈Rn×p
+
. The
suggestion is to take K = sCT ∈Rn×p
+
for a constant s ∈R+ such that Equation (33)
is met.
Further research is required into the appropriateness of the above deﬁned stochastic
realization.
Proposition 2. The ﬁnite stochastic system deﬁned above is such that
F x(t) ⊆F y
t−1 ∨F u
t1, ∀t ∈T \{t0},

312
J.H. van Schuppen
hence the stochastic system has the measurability property of the stochastic realization
approach.
Proof. The statement follows directly from the condition on the initial state F x0 ⊂F y
0
and from the Equations (29,32).
Problem 4. The optimal stochastic control problem for a ﬁnite stochastic system where
the system is deﬁned in Deﬁnition 5. Solve the optimal stochastic control problem with
complete observations
inf
g∈G J(g),
(34)
G = {g : T × X →U|g measurable function},
J(g) = E[
t1−1

s=t0
b(xg(s), ug(s)) + b1(xg(t1))],
(35)
b : X × U →R+, b1 : X →R+.
The optimal stochastic control problem formulated above can now be solved numeri-
cally with the well known algorithms of value and policy iteration, see the books [4,17].
The conclusion of the stochastic realization approach to stochastic control with par-
tial observations is that it is feasible, the computations can be done with available al-
gorithms and software, and that the resulting control law is easily implementable. The
approach avoids the road via the optimal stochastic control problem with the ﬁlter sys-
tem with as state set the space [0, 1]n.
6
Concluding Remarks
The paper presents the stochastic realization approach to stochastic control problems
with partial observations. The approach prescribes: (1) to formulate a stochastic real-
ization of the input-output process in which the state is measurable on the past of the
input and the past of the output process; (2) to prove that the stochastic realization has
the required measurability property; (3) to solve the optimal stochastic control problem
with complete observations; and (4) to assemble the control law. For the special case of
a Gaussian stochastic control system and a quadratic cost function, the stochastic real-
ization approach yields the same control law as the classical approach. For the special
cases of LEQG and of a ﬁnite stochastic system the resulting control laws are different
from the classical approach.
Further research is required to explore the usefulness of the stochastic realization
approach to stochastic control with partial observations. An extension to be formulated
is to decentralized control of stochastic systems and to stochastic dynamic games. In
these cases each of the players has his private system and a private system which models
the controllers of the other players. That approach restricts the complexity of dynamic
games problems considerably.

Control with Partial Observations
313
References
1. A. Arapostathis, V.S. Borkar, E. Fern´andez-Gaucherand, M.K. Ghosh, and S.I. Marcus.
Discrete-time controlled Markov processes with average cost criterion: A survey. SIAM
J. Control & Opt., 31:282–344, 1993.
2. V.E. Benes and I. Karatzas. Filtering of diffusions controlled through their conditional mea-
sures. Stochastics, 13:1–23, 1984.
3. A. Bensoussan and J.H. van Schuppen. Optimal control of partially observable stochas-
tic systems with an exponential-of-integral performance index. SIAM J. Control Optim.,
23:599–613, 1985.
4. D.P. Bertsekas. Dynamic programming and stochastic control. Academic Press, New York,
1976.
5. D.P. Bertsekas. Dynamic programming and optimal control, Volume I. Athena Scientiﬁc,
Belmont, MA, 1995.
6. D.P. Bertsekas. Dynamic programming and optimal control, Volume II. Athena Scientiﬁc,
Belmont, MA, 1995.
7. R.K. Boel and P.Varaiya. Optimal control of jump processes.
SIAM J. Control Optim.,
15:92–119, 1977.
8. M.H.A. Davis and P. Varaiya. Dynamic programming conditions for partially observable
stochastic systems. SIAM J. Control, 11:226–261, 1973.
9. E. Fernandez-Gaucherand and A. Arapostathis. On partially observable Markov decision
processes with an average cost criterion. In Proceedings of the 28th IEEE Conference on
Decision and Control (CDC.1989), pages 1267–1272, New York, 1989. IEEE, IEEE Press.
10. E. Fern´andez-Gaucherand, A. Arapostathis, and S.I. Marcus. On the average cost optimal-
ity equation and the structure of optimal policies for partially observed Markov decision
processes. Ann. Oper. Res., 29:439–470, 1991.
11. E. Fernandez-Gaucherand and S.I. Marcus. Risk-sensitive optimal control of hidden markov
models: Structural results. IEEE Trans. Automatic Control, 42:1418–1422, 1997.
12. W.H. Fleming and R.W. Rishel. Deterministic and stochastic optimal control. Springer-
Verlag, Berlin, 1975.
13. T.L. Gunckel. Optimum design of sampled-data systems with random parameters. Technical
Report SEL TR 2102-2, Stanford Electron. Lab., Stanford, 1961.
14. D.H. Jacobson. Optimal stochastic linear systems with exponential performance criteria and
their relation to deterministic differential games. IEEE Trans. Automatic Control, 18:124–
131, 1973.
15. P.D. Joseph and J.T. Tou. On linear control theory. AIEE Trans. (Appl. Ind.), 80:193–196,
1961 ( Sep.).
16. P.R. Kumar and J.H. van Schuppen. On the optimal control of stochastic systems with an
exponential-of-integral performance index. J. Math. Anal. Appl., 80:312–332, 1981.
17. P.R. Kumar and P. Varaiya. Stochastic systems: Estimation, identiﬁcation, and adaptive
control. Prentice Hall Inc., Englewood Cliffs, NJ, 1986.
18. A. Lindquist and G. Picci. A geometric approach to modelling and estimation of linear
stochastic systems. J. Math. Systems, Estimation, and Control, 1:241–333, 1991.
19. R. Rishel. Necessary and sufﬁcient dynamic programming conditions for continuous time
stochastic optimal control. SIAM J. Control & Opt., 8:559–571, 1970.
20. C. Striebel. Sufﬁcient statistics in the optimum control of stochastic systems. J. Math. Anal.
Appl., 12:576–592, 1965.
21. C. Striebel. Optimal control of discrete time stochastic systems, volume 110 of Lecture Notes
in Economic and Mathematical Systems. Springer-Verlag, Berlin, 1975.

314
J.H. van Schuppen
22. C. Striebel.
Martingale conditions for the optimal control of continuous time stochastic
systems. Stoc. Proc. Appl., 18:329–347, 1984.
23. J.H. van Schuppen.
Stochastic realization problems.
In J.M. Schumacher H. Nijmeijer,
editor, Three decades of mathematical system theory, volume 135 of Lecture Notes in Control
and Information Sciences, pages 480–523. Springer-Verlag, Berlin, 1989.
24. P. Whittle. Risk-sensitive Linear/Quadratic/Gaussian control. Adv. Appl. Prob., 13:764–777,
1981.
25. H. Witsenhausen. Separation of estimation and control for discrete time systems. Proc.
IEEE, 59:1557–1566, 1971.
26. H.S. Witsenhausen. On information structures, feedback and causality. SIAM J. Control,
9:149–160, 1971.
27. H.S. Witsenhausen. A standard form for sequential stochastic control. Math. Systems Theory,
7:5–11, 1973.

Experiences from Subspace System Identiﬁcation -
Comments from Process Industry Users and
Researchers
Bo Wahlberg1, Magnus Jansson2, Ted Matsko3, and Mats A. Molander4
1 Automatic Control, KTH, Stockholm, Sweden
bo@ee.kth.se
2 Signal Processing, KTH, Stockholm, Sweden
magnus.jansson@ee.kth.se
3 ABB USA
ted.matsko@us.abb.com
4 ABB Corporate Research, V¨aster˚as, Sweden
mats.a.molander@se.abb.com
Summary. Subspace System Identiﬁcation is by now an established methodology for experi-
mental modelling. The basic theory is well understood and it is more or less a standard tool
in industry. The two main research problems in subspace system identiﬁcation that have been
studied in the recent years are closed loop system identiﬁcation and performance analysis.
The aim of this contribution is quite different. We have asked an industrial expert working
in process control a set of questions on how subspace system identiﬁcation is used in design of
model predictive control systems for process industry. As maybe expected, it turns out that a
main issue is experiment/input design. Here, the difference between theory and practice is rather
large mainly due to implementation constraints, but also lack of knowledge transfer. Motivated
by the response from the expert, we will discuss several important user choices problems, such
as optimal input design, merging of data sets and merging of models.
1
Introduction
System identiﬁcation concerns the construction and validation of models of dynamical
systems from experimental data. All advanced control and optimization methods, as
model predictive control, require a reliable model of the process. System identiﬁcation
is thus a key technology for industry to beneﬁt from powerful control methods. Mod-
elling and system identiﬁcation techniques suitable for industrial use and tailored for
control design applications are of utmost importance The ﬁeld of system identiﬁcation
is well developed with excellent textbooks, e.g. [12,17], and software packages.
Subspace system identiﬁcation is a class of methods for estimating state space mod-
els based on low rank properties of certain observability/prediction sets. The area was
pioneered by researchers as Larimore, de Moor & van Overschee, Verhaegen and oth-
ers, and was early adopted by industry. The theoretical foundation was established
by for example Picci, Bauer and Jansson, and more recently by Chiuso. The industry
was an early adopter. One of the ﬁrst comercially available tools, released 1990, was
ADAPTx from Adaptics Inc. It was based on the CVA method developped by Larimore.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 315–327, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

316
B. Wahlberg et al.
Nowadays, several vendors of Process Automation systems offer modeling tools based
on subspace system identiﬁcation. Examples are aspenOne from Aspen Technologies
and Proﬁt SensorPro from Honeywell.
ABB released its MPC product Predict & Control in 2000 (called 3dMPC at the
time). It uses state-space models combined with Kalman-style state estimators for
the predicions. The included system identiﬁcation package is based on a two-step
procedure where an initial model is obtained through subspace system identiﬁcation,
and a reﬁned model can be obtained through the minimization of a Prediction Error
criterion.
Let us now review some basic facts about subspace system identiﬁcation. The ma-
trices of a linear system in state space form
x(t + 1) = Ax(t) + Bu(t)
y(t) = Cxt(t) + Du(t)
(1)
can efﬁciently be estimated from observations of the input signal u(t) and the output
signal y(t) without any prespeciﬁed parametrization using subspace system identiﬁca-
tion methods. The basic idea is that if the state vectors x(t), and the input u(t) and the
output y(t) are known, least squares linear regression techniques can be used to directly
estimate the state-space matrices A, B, C and D. The key observation is that the state
x(t) actually can be reconstructed from input output data using certain multiple-step
ahead prediction formulas combined with low rank matrix factorizations. Combining
these two ideas leads to a family of subspace system identiﬁcation methods such as
CVA, N4SID, and MOESP variations.
A great advantage of subspace system identiﬁcation is that there is no difference
between multi-input-multi-output system identiﬁcation, where the input and output are
vectors, and ordinary single-input single output identiﬁcation. This is in contrast to e.g.
prediction error methods, where the choice of model structures and corresponding pa-
rameterizations is most important. Other advantages of subspace identiﬁcation are that
the methods are based on robust numerical methods and avoid problem with optimiza-
tion and possible local minima. The main disadvantages have been a potential perfor-
mance loss compared to statistically efﬁcient methods, as the prediction error method,
and potential bias problems in identiﬁcation of systems operated in closed loop. These
two shortcomings have at least partly been eliminated by recent research [3,10,11,14].
There are mainly three design parameters in a subspace system identiﬁcation method.
We will here use the notation in [12]. The maximum prediction horizon is denoted by
r, the number of past outputs used in the predictors is denoted by sy, and the number of
past inputs used in the predictors by su. A common choice is su = sy = s. The model
order n is also important, but it is often estimated. It is often difﬁcult to pre-specify r
and s. One common way in practice is to evaluate a set of combinations and then use
model validation to determine the best values.
Subspace system identiﬁcation was early used in industry since it ﬁts very well with
model predictive control. It is by now almost a standard technology and hence it is of
interest to see how it is used in industry and how this relates to the state-of-the-art in
more theoretical academic research.

SSI
317
2
Questions and Answers from the User
It is important to understand some of the more typical modelling problems in process
industry. The plants are often very complex and it could be very expensive or even dan-
gerous to do experiments with too large excitations. The process dynamics is slow, and
the time constants are often around minutes or hours. This means that experiments of-
ten take long time. The process noise has often low frequency characteristics, e.g. drifts
and random walks.
Notation
The notation MV is used for Manipulated Variable, i.e. input signals which then will
be used to control the systems. Control variables are denoted by CV , i.e. output signals
which will be used for feedback control, while PV denotes process variables i.e. mea-
surable output signals.
We have formulated a set of questions to Ted Matsko, who is an expert at ABB
in implementation of control systems, and, in particular, design of model predictive
controllers using subspace system identiﬁcation as a tool for modelling.
First, we think it would be interesting if you could put down some kind of step by step
list of actions describing your typical routine for the modelling part of a model predic-
tive control commissioning. Preferably also with time estimates (relative or absolute)
for the different steps. Also, notes on steps where special care has to be taken to not run
into problems would be very interesting.
Data Collection: This averages one day per MV for reﬁning and petrochemical pro-
cesses, which have longer time constants.
Powerhouse is typically two MVs
per day. There tends to be a greater level of unmeasured disturbance in reﬁn-
ing/petrochem than in power, except for coal ﬁred units where coal quality can
vary. A typical experiment takes around 4 hours. The rest of the time concerns de-
sign of experiments and is often done in collaboration with an operator. A typical
input signal is series of steps (4-8), which is manually implemented by the operator.
Some of these are shorter than others and the amplitude and the sign may change.
Data Review and Organization: This typically takes 2-4 hours per data set. Typically
we try to step one MV at a time. This never happens (operator needs to move
another MV), so we need to organize the data and merge data ﬁles together. I
have had bad experience with full MIMO ID using old tools from about 12 years
ago. With a dense model matrix, the package simply did not work that well with a
PRBS input. This may have worked better if the system had been more diagonal.
I typically import data into an ABB tool and do a lot of plotting. Then I clean and
merge data ﬁles in Excel, add calculated data points.
Subspace System Identiﬁcation, First Pass: Specify a fairly small range of possible
models by setting the design parameters to r = s rather small and check different
model orders. This usually gives around 150 models. Pick 3 or 4 with low open
loop error, usually with different n. My experience is that higher model orders tend
to result in a step response with oscillation. Evaluate against data set, look at step

318
B. Wahlberg et al.
response (and impulse response if integrating process). Use prediction error plots
to conﬁrm what your eyes see.
Subspace System Identiﬁcation, 2nd, 3rd ...Passes: If best models are on edge of
n/r/s boundaries, expand the range. Push to low n, very low s and high r, gives
best results in my experience.
Merge Models: Paste things together with the Merge and Connect tools (ABB tool).
Use model order reduction to reduce the order of the overall system. Sometimes
we convert to Laplace transfer functions before merging. This gives us a little more
control over the shape, dead time, gain, ability to zero out certain MV/CV pairs.
May also run subspace system identiﬁcation on 1 CV x 3 or 4 MVs to control, then
merge to control placing of null relationships.
I like to break things down to /actuator-to-process output/ and /control loop-to-
actuator/ models and then merge. Going actuator-to-output provides a physical,
intuitive model. Sometimes the base controls can cloud the issue and hide a bad
job from visual inspection.
Modeling and Constraint design are the two most important steps in creating good MPC
applications. Our subspace system identiﬁcation tool is the best modeling tool I have
used. Our Data Processing tools are almost good, but the latest release makes them dif-
ﬁcult to use in some circumstances. Data manipulation and pre-processing can consume
a lot of time if you make mistakes in data collection.
How do you set up the identiﬁcation experiments? Do you try to disturb as many as
possible of the MVs simultaneously? If not all MVs are disturbed simultaneously, what
considerations control the splitting of the experiments? How do you typically decide
the step amplitudes for the excitation?
We ﬁrst create a large taglist. It is better to collect any data related to the process. If
you ﬁnd some inexplicable behavior, going through data for ancillary tags may allow
you to save the data ﬁle and avoid doing additional tests. Additional tests may require
another trip to site. We try to step one MV at a time. If the process is large and we
can step variables that do not overlap in the model matrix, we may step two at the same
time. An important part of working with any modeling package is looking at how well
the model ﬁts the data visually. In a full 5x5 MIMO ID with all MVs moving randomly,
it is very hard to tell how good a model ﬁt really is. To determine step test amplitudes,
we monitor the noise level and talk to the operators about the process gains and settling
time. The operator will be able to give you a reasonable feel for the gain and time
constant. As a minimum, I want the step tests to move the PV twice as far as the noise
does. After a few steps, we may adjust.
Are the identiﬁcation experiments always performed in open-loop, or is it common to
have the MV excitations as additions to the outputs of a running controller? If you com-
monly perform both types of experiments, what are your experience of the differences?
Before commissioning, most data is open loop. Infrequently the MPC will include
a distillation column temperature that is controlled in the distributed control system
(DCS) with a cascade loop. In the powerhouse, the pressure is always controlled. In
these cases we may do some or all of the initial testing with that PV in closed loop. To

SSI
319
ﬁne tune a model during commissioning, we may use some closed loop data. I do not
have a lot of experience with closed loop data and subspace system identiﬁcation, but
the header pressure models seem to work better when at least some of the data is under
closed loop control. That may be a special case where the models are integrating (or
very long time constants). I seem to recall that other model predictive control system
identiﬁcation packages discouraged the use of closed loop data.
Do you ﬁnd the time needed for the identiﬁcation experiments to be a main hurdle?
Data collection time is about 1/3 of the total time spent on building dynamic models.
Sometimes we are able to get people at the plant to do some of the data collection under
our guidance. There is also time for functional speciﬁcation, conﬁguring controller,
conﬁguring DCS, adding DCS graphics, FAT, commissioning, ﬁnal documentation. So
data collection time is signiﬁcant, but not the majority of time.
Compared to other MIMO control systems you commissioned earlier, do you save a
lot of time in the modelling phase by using the subspace system identiﬁcation tools? If
so, in what stages of the modelling, and how much?
Time is about the same. Quality is better and that saves time commissioning. Ca-
pability and ﬂexibility is better (merge, connect). Better models make commissioning
much easier. Biggest place for time savings would be improving our data preprocessing
tools. We handle some big data sets, 100 tags by 17,500 records is a typical ﬁle (merged
4 days testing into one ﬁle in this example).
In the ABB modelling tool we have the two step procedure of a Subspace identi-
ﬁcation, followed by a Prediction Error Model identiﬁcation. How important is the
second PEM step? Is it always important, or have you identiﬁed situations where it is
not important and others where it is? (Theoretically, one would suspect that it is more
important if the identiﬁcation experiment was performed in closed loop)?
I have not found that the PEM step makes much improvement. The feature to force
a zero relationship does work that well (I have a recent example).
How about size restrictions? How large problems do you typically model, in number
of model inputs/outputs? When do you normally run into problems regarding size?
I have had no problem with MV x PV size, but I do not stretch the limits. Even with
a big controller, the biggest subset I work with is around 4x4. I use some very long
ﬁles with breaks in time. This may make the subspace system identiﬁcation slow, but
the results are usually good. When I plot the model predictions when using data sets
with breaks, I still get some strange initialization occasionally, but I am not very well
educated on how the calculations work here so user error is not unlikely.
How large models (in number of states) do you normally end up with? Is it very
coupled to the input/putput size, or do you normally ﬁnd models with a reasonably
small number of states even if the number of inputs/outputs are large?
I usually end up with models that have a low number of states from subspace system
identiﬁcation. Some of the models used for control, that are merged, are pretty large.

320
B. Wahlberg et al.
On the small powerhouse project we just ﬁnished, individual models were n = 2 to 6.
ﬁnal merge was n = 44 (5 PVs x 4 MVs). On a prior project with many MVs, I had a
plant model with n = 166, but the order reduction tool pared that to 65.
How do you normally conclude that a model is good enough? What evaluation
methods are most important?
Visual examination of prediction versus actual data. Of course if you made some
mistakes that can still look good, even if the model is not. If you have problems com-
missioning, the ﬁrst thing to re-examine are the models. There we take new closed loop
data ﬁles and import them into the identiﬁcation tool and look at the predictions versus
actual output.
Do you consider the existing evaluation tools sufﬁcient, or do you sometimes expe-
rience that a model that looks perfectly good, still does not work well for the MPC?
Yes, as I said above this happens. Usually it is some user error. Something that
one overlooks in the data ﬁle. Recent example was a delay on one signal due to the
communication system in the DCS. The delay did not exist for process control, just
data collection. All my models were slightly off, but gains were good. This caused a
nice limit cycle.
Do you always use separate identiﬁcation and evaluation data sets, or do you
sometimes/occassionally/always use the same data set for both identiﬁcation and
evaluation?
Always use the same in the identiﬁcation step. Sometimes I will use another ﬁle for
plotting predictions, usually data gathered from a later time period. Unless we start to
do long PRBS runs, I don’t think there is typically enough data to split.
As a last point, do you have speciﬁc wishes for improvements of the modelling tools?
Better results from the PEM step (a.) gains set to 0 ( b.) conversion, Order reduction
tool introduces some small gains where 0 gains may have existed before. A tool to
convert to low order Laplace transfer functions from state space models. An online tool
to monitor model performance.
3
Comments from the Researchers
The responses and answers from the process control expert are very interesting and open
up a lot of very interesting research issues. Our objective, however, is not to provide a
“solutions manual,” but instead to relate the comments of the expert to the current status
in research. We are well aware of the difﬁcult trade-offs in real applications, and that
academic examples often are severe simpliﬁcations. However, they can provide insight
and results which then can be tailored real problems to the intended application. We
will, in particular, discuss input design, merging of data sets and merging of estimated
models.

SSI
321
4
Input Design
Input design for linear dynamic systems started out around 1960 and in the 1970’s
there were a lot of activities in this area, for which [6] acts as an excellent survey.
The classical approach is to minimize some scalar measure function of the asymptotic
parameter covariance matrix (e.g. the determinant or the trace) with constraints on input
and/or output power.
Let Φu be the power spectral density of the input. The more recent approaches to
optimal experiment design problems are typically posed in the form
min
u
1
2π
 π
−π
Φu(ω)dω
(2)
subject to model quality constraints, and signal constraints
(3)
i.e., formulated as optimization problems that include some constraints on the model
quality together with signal constraints. It is also possible to minimize a weighted ver-
sion of the input signal or the output signals. The signal constraints have to be included
to obtain well-posed problems, e.g., to prevent the use of inﬁnite input power. Powerful
methods have been developed to solve a variety of such problems. Notice that the solu-
tion will be an input spectral density, and that the time domain realization problem then
can be solved in different ways. We refer to [8,2,1] for overviews of recent methods.
System identiﬁcation for control is a very important application of input design. Here
the model quality constraints reﬂect robust performance and stability. It is very impor-
tant to obtain input signals that then can be reliably implemented, while the optimal
solution often only refers to frequency domain properties. To stress this issue [15] have
introduced the concept of “plant-friendly” identiﬁcation.
Optimal Input Design for Subspace Methods
Most of the input design methods make use of asymptotic variance analysis based on the
Prediction Error identiﬁcation Method (PEM) framework, [12]. Very few results have
been presented for optimal input design for subspace system identiﬁcation methods.
A natural idea would be to do input design for PEM methods and then apply it for
subspace system identiﬁcation. Our conjecture is that optimal inputs for PEM would
give good results for subspace system identiﬁcations methods since subspace methods
often give results with quality properties close to those of PEM.
From theory it is known that subspace system identiﬁcation requires that the input
signal is persistently exciting of order n + r or higher [9,4], and that white noise input
signals often give good performance. This is in contrast to the experiments described
by the expert, which essentially are of step response type. The signal to noise ratio is,
however, quite high. It would be of interest to do performance analysis of subspace
system identiﬁcation model estimates from step response data with high signal to noise
ratio. Of course, a noise free step response contains all information about a linear
system, but it is very sensitive to disturbances. Early subspace system identiﬁcation
techniques made use of the Hankel matrix constructed from impulse response data.

322
B. Wahlberg et al.
An interesting input design problem is the following. Assume that you are only
allowed to change the input signal d times over a given interval with prespeciﬁed am-
plitude levels. What are the optimal choices of times to change the signal?
Example
Some insight can be obtained by the following simple example. Consider the problem
of estimating the parameters of a ﬁrst order ARX model
y(t) = −ay(t −1) + bu(t −1) + e(t),
a = 0.5, b = 1
under the assumption of zero initial conditions and only the choices u = 1 or u = −1
are allowed and that one only is allowed to change the input from 1 to −1 once.
Assume that you have four measured samples.
Possible input sequences are then
(1, −1, −1, −1), (1, 1, −1, −1), (1, 1, 1, −1) and (1, 1, 1, 1). Since this concerns very
small data records, we have used Monte Carlo computer simulations to study the qual-
ity of the estimated parameters. For the estimation of a, it turns out the ﬁrst sequence
is the best one and it gives a performance that is almost twice as good as the second
best one. The accuracies of the estimates of b are approximately the same for the ﬁrst
and the third sequences. The fourth sequence is of course bad in terms of persistence of
excitation. The example shows that it is important to design the input sequence even if
one has hard constraints.
MIMO Systems
Identiﬁcation of MIMO systems has recently been an active area of research. In partic-
ular variance analysis and input design issues. A main question is if one should excite
the various inputs simultaneously or separately? From a pure performance perspective
it is always better to excite all inputs simultaneously [5]. However, in the case where
the output power is constrained, the conclusion is that it is possible to obtain nearly the
same performance by exciting one input at a time, i.e. the strategy used by the expert.
See page 25 in [5].
In case the process has strong interactions, i.e. ill conditioned systems, the dynamics
of the high-gain directions tends to dominate the data and it is difﬁcult to estimate a
reliable model for the low-gain direction. This problem is discussed in e.g. [7]. An
interesting approach for iterative input design of gene regulatory networks is described
in [13]. The idea is to excite the inputs to obtain a uniform output excitation. It is a good
idea to pre-compensate the plant to make it as diagonal as possible before identiﬁcation.
For a completely diagonal plant the MIMO identiﬁcation problem of course simpliﬁes
to a number of SISO problems. It is of course difﬁcult to do pre-compensation without
a good model, and it could also create problems with large inputs if the plant is ill
conditioned. A better solution is then to use partial decoupling as e.g. described in [21].
The idea is to transform the system to a triangular structure.
5
Merging Data
Assume that data have been collected from a series of SIMO experiments. The problem
of merging data sets is discussed in details in Section 14.3 in [12]. One important aspect

SSI
323
is that it is common that one has to remove parts of bad data, which means that data
records have to then be merged.
For linear dynamical systems the main problem when merging data is to take the
different initial conditions into account. In case of periodic input signals it is possible
to use averaging as a means to merge data.
We will illustrate some of the issues by a simple example.
Example
Consider the model
y(t) = bu(t −k) + e(t)
i.e. a time delayed linear relation with unknown gain b. Assume that we have two data
sets of equal length
{y1(t), u1(t), t = 1, 2, . . ., N/2},
{y2(t), u2(t), t = 1, 2 . . . , N/2}
The least squares (PEM) estimate minimizes
min
b
N/2

t=1+k
(y1(t) −bu1(t −k))2 +
N/2

t=1+k
(y2(t) −bu2(t −k))2
and thus equals
ˆbN =
N/2
t=1+k(y1(t)u1(t −k) + y2(t)u2(t −k))
N/2
t=1+k(u2
1(t −k) + u2
2(t −k))
(4)
Notice that this does not correspond to just concatenating the data
yc(t) =
 y1(t)
t = 1, . . . , N/2
y2(t −N/2), t = N/2 + 1, . . . , N
uc(t =

u1(t),
t = 1, . . . , N/2
u2, (t −N/2), t = N/2 + 1, . . . , N
which would yield
ˆbc
N =
N
t=1+k yc(t)uc(t −k)
N
t=1+k u2c(t −k)
̸= ˆbN
since the transient has to be taken into account.
An observation is however that in case u1 = u2, i.e. the same input is used in both
experiments, we have
ˆbN =
N/2
t=1+k(y1(t) + y2(t))(u1(t −k) + u2(t −k))
N/2
t=1+k 0.5(u2
1(t −k) + u2
1(t −k))
which just corresponds to adding the signals y = y1 + y2 and u = u1 + u2 and then
use the ordinary PEM estimate
ˆbN =
N/2
t=1+k y(t)u(t −k))
N/2
t=1+k u2(t −k)

324
B. Wahlberg et al.
The summation approach only works for repeated input signals and will help reducing
noise contributions by averaging. Notice that we only work with data records of length
N/2 instead of N when concatenating the data. This result holds for general models
with repeated signals.
6
Merging of Models
It is easy to combine parameter estimates from different data sets by assuming that they
can be regarded as independent. The minimum variance estimate is obtained by weight-
ing the individual estimates with their inverse covariance matrix, see Equation (14.15)
in [12]. It is also noted that the same result can be obtained by solving a combined least
squares problem using the merged set of data.
Expression (4) in the example in the previous section illustrates exactly this. The
least squares estimate from the individual data records equals
ˆb1
N/2 =
N/2
t=1+k(y1(t)u1(t −k))
N/2
t=1+k u2
1(t −k)
,
ˆb2
N/2 =
N/2
t=1+k(y2(t)u2(t −k))
N/2
t=1+k u2
2(t −k)
with covariances
Covˆb1
N/2 =
λo
N/2
t=1+k u2
1(t −k)
,
Covˆb2
N/2 =
λo
N/2
t=1+k u2
2(t −k)
Hence, the combined minimum variance estimate becomes
ˆbN =
ˆb1
N/2/ Covˆb1
N/2 + ˆb2
N/2/ Covˆb2
N/2
1/ Covˆb1
N/2 + 1/ Covˆb2
N/2
which equals (4). The observation is that it is most important to take the quality of
the estimates into account when merging different models. Hence, it is not trivial to
combine model estimates from subspace system identiﬁcation methods, and the best
idea seems to be to instead merge the data sets. One problem is that the state space
realization of the estimate depends on the data, and hence it is not just to combine the
different state space matrices. Instead one has to work with canonical forms such as
transfer functions or frequency responses.
Consider the problem of merging two frequency response estimates ˆG1(eiω) and
ˆG2(eiω), possibly of different orders, estimated by e.g. subspace methods. Assume that
the corresponding variances of the two estimates are given by W1(eiω) and W2(eiω),
respectively. These variance expressions can be quite complicated to obtain. However,
a reasonable approximation based on the high model order theory of Ljung [12], is
Wi = ni
Ni
>Φi
v(eiω)
>Φiu(eiω)
,
i = 1, 2
where >Φi
v is an estimate of the noise power spectrum, >Φi
u is an estimate of the input
power spectrum, ni is the model order and Ni is the number of data used in experi-
ment i.

SSI
325
The optimally merged estimate will then be
ˆG3 =
ˆG1/W1 + ˆG2/W2
1/W1 + 1/W2
with resulting variance W3 = 1/(1/W1+1/W2). In order to obtain a low order transfer
function estimate the following H2 model reduction problem can be solved
min
θ
1
2π
 π
−π
| ˆG3(eiω) −G(eiω, θ)|2
W3(eiω)
dω
where G((eiω, θ) is a set of parameterized transfer functions. This approach was pro-
posed in [20] and has more recently been studied in [19].
Further insight can be obtained if the noise properties in both experiments are iden-
tical and the model orders n1 = n2. Let ˆΦi
yu = ˆGi >Φi
u, i.e. an estimate of the cross-
spectra. Then
ˆG3 = N1 ˆΦ1
yu + N2 ˆΦ2
yu
N1 ˆΦ1u + N2 ˆΦ2u
which can be viewed as averaging the individual spectra
ˆΦ3
yu = N1 ˆΦ1
yu + N2 ˆΦ2
yu
N1 + N2
,
ˆΦ3
u = N1 ˆΦ1
u + N2 ˆΦ2
u
N1 + N2
and then taking ˆG3 = ˆΦ3
yu/ ˆΦ3
u. From a non-parametric estimation point of view this
makes a lot of sense. Even further insight can be obtained by the following simple
example. Let
y3 = y1 + y2,
u3 = u1 + u2
and assume that u1 and u2 are independent. Then
Φy3u3 = Φy1u1 + Φy2u2,
Φu3 = Φu1 + Φu2
for the cross spectra and the input spectra. Hence, the merging of models corresponds
in some sense to merging of data, while enforcing the independence assumption.
Combining Sub-models
Consider the following problem
z1(t) = G1(q)u(t)
z2(t) = G2(q)z1(t)
y1(t) = z1(t) + e1(t)
y2(t) = z2(t) + e2(t)
Given observations of the input u(t) and the outputs y1 and y2 we would like to estimate
the transfer functions G1 and G2. There are at least three different ways to approach this
problem. The optimal way is to use this structure in a single input two outputs (SITO)

326
B. Wahlberg et al.
prediction error identiﬁcation method. Another way is to estimate a state space model
with one input and two outputs using subspace identiﬁcation. The transfer functions
G1 and G2 can then be estimated from the state space model estimates. A problem is,
however, that the order of these two transfer functions will in general be of the same
order as the total system. One way is to apply a model order reduction method, but then
it is important to take the statistical properties of the model estimates into account.
As mentioned by the expert a common approach is to estimate individual sub-models,
i.e. G1 from observations of u and y1 and G2 as the transfer function from y1 to y2. The
second problem is an error-in-variables problem, see [16], and care has to be taken in
order to avoid problems caused by the noise e1. In case the signal z1 is of low frequency
character or have a special structure due to the choice of input u this information can be
used to pre-process the signal before applying the identiﬁcation method.
A third way is to estimate the transfer function G1 from u and y1 and then G3 =
G1G2 from u to y2. The transfer function G2 can then be obtained as ˆG2 = ˆG3/ ˆG1,
but will in general be of high order and could also be unstable due to non-minimum
phase zeros. A better solution is to solve
min
G2
1
2π
 π
−π
| ˆG3(eiω) −ˆG1(eiω)G2(eiω)|2
W3(eiω)
dω
where the weighting W3(eiω) should reﬂect the variance of the error. One way is to
calculate
Cov
ˆG3(eiω)
ˆG1(eiω)
= W4(eiω)
and use W3(eiω) = | ˆG1(eiω)|2W4(eiω). This is very closely related to indirect PEM
discussed in [18].
The conclusion is that one should take the statistical properties of the model estimates
into account when merging and combining sub model estimates.
7
Conclusion
The objectives of this paper have been to study how subspace system identiﬁcation can
be used in industrial applications and the corresponding supporting theoretical results.
One very interesting area is input signal design, and in particular methods that take
practical experiences and limitations and into account. Based on the input from an
industrial user, we have discussed some theoretical results that can be useful for merging
of data and models.
References
1. M. Barenthin, H. Jansson, H. Hjalmarsson, J. M˚artensson, and B. Wahlberg. A control per-
spective on optimal input design in system identiﬁcation. In Forever Ljung in System Iden-
tiﬁcation, chapter 10. Forever Ljung in System Identiﬁcation, Studentlitteratur, September
2006.
2. M¨arta Barenthin. On input design in system identiﬁcation for control. Technical report,
Royal Institute of Technology (KTH), June 2006. Licentiate Thesis.

SSI
327
3. A. Chiuso and G. Picci. Prediction error vs. subspace methods in open and closed-loop
identiﬁcation. In 16th IFAC World Congress, Prague, Czech Republic, Jul. 2005.
4. N. L. C. Chui and J. M. Maciejowski. Criteria for informative experiments with subspace
identiﬁcation. International Journal of Control, 78(5):326–44, Mar. 2005.
5. M. Gevers, L. Miskovic, D. Bonvin, and A. Karimi. Identiﬁcation of multi-input systems:
variance analysis and input design issues. Automatica, 42(4):559–572, April 2006.
6. G. Goodwin and R.L. Payne. Dynamic System Identiﬁcation: Experiment Design and Data
Analysis. Academic Press, New York, 1977.
7. E. W. Jacobsen. Identiﬁcation for control of strongly interactive plants. In AIChE Annual
Meeting, January 1994.
8. H. Jansson. Experiment design with applications in identiﬁcation for control. PhD thesis,
KTH, December 2004. TRITA-S3-REG-0404.
9. M. Jansson. On Subspace Methods in System Identiﬁcation and Sensor Array Signal Pro-
cessing. PhD thesis, October 1997.
10. M. Jansson. Subspace identiﬁcation and ARX modeling. In IFAC Symp. on System Identiﬁ-
cation, Rotterdam, The Netherlands, Aug. 2003.
11. M. Jansson. A new subspace identiﬁcation method for open and closed loop data. In 16th
IFAC World Congress, Prague, Czech Republic, Jul. 2005.
12. L. Ljung. System Identiﬁcation - Theory For the User, 2nd ed. PTR Prentice Hall, Upper
Saddle River, N.J, 1999.
13. T. E. M. Nordling and E. W. Jacobsen. Experiment design for optimal excitation of gene
regulatory networks, October 2006. Poster.
14. Joe S. Qin, Weilu Lin, and Lennart Ljung. A novel subspace identiﬁcation approach with
enforced causal models. Automatica, 41(12):2043–2053, December 2005.
15. D.E. Rivera, H. Lee, M.W. Braun, and H.D. Mittelmann. Plant-friendly system identiﬁcation:
a challenge for the process industries. In Proceedings of the 13th IFAC Symposium on System
Identiﬁcation, pages 917–922, Rotterdam, The Netherlands, 2003.
16. T. S¨oderstr¨om.
Errors-in-variables methods in system identiﬁcation.
Automatica, 2007.
Survey paper, to appear.
17. T. S¨oderstr¨om and P. Stoica. System identiﬁcation. Prentice Hall International, Hertfordshire,
UK, 1989.
18. T. S¨oderstr¨om, P. Stoica, and B. Friedlander. An indirect prediction error method. Automat-
ica, 27:183–188, 1991.
19. F. Tj¨arnstr¨om. Variance Expressions and Model Reduction in System Identiﬁcation. PhD
thesis, Feb 2002.
20. B. Wahlberg. Model reduction of high-order estimated models: The asymptotic ML ap-
proach. International Journal of Control, January 1989.
21. S.R. Weller and G.C. Goodwin. Controller design for partial decoupling of linear multivari-
able systems. Int. J. Control, 63(43):535–556, 1996.

Recursive Computation of the MPUM
Jan C. Willems
ESAT-SISTA, K.U. Leuven, B-3001 Leuven, Belgium
Jan.Willems@esat.kuleuven.be
www.esat.kuleuven.be/∼jwillems
Summary. An algorithm is presented for the computation of the most powerful unfalsiﬁed model
associated with an observed vector time series in the class of dynamical systems described by
linear constant coefﬁcient difference equations. This algorithm computes a module basis of the
left kernel the Hankel matrix of the data, and is recursive in the elements of the basis. It is readily
combined with subspace identiﬁcation ideas, in which a state trajectory is computed ﬁrst, directly
from the data, and the parameters of the identiﬁed model are derived from the state trajectory.
1
Introduction
It is a pleasure to contribute an article to this Festschrift in honor of Giorgio Picci on the
occasion of his 65-th birthday. In the 35 years since our original acquaintance, I have
learned to appreciate Giorgio as a deep thinker and a kind friend. As the topic of this
paper, I chose a subject that has dominated Giorgio’s research throughout his scientiﬁc
career: system identiﬁcation.
My paper is purely deterministic in nature, whereas the usual approach to system
identiﬁcation (SYSID) is stochastic. It has always bafﬂed me that so many subjects in
systems and control — and in other scientiﬁc endeavors as well — immediately pass
to a stochastic setting. Motivated by the thought that in the end uncertainty will have
to be dealt with, a stochastic framework is adopted ab initio, and the question of how
the problem would look in a deterministic setting is not even addressed. Moreover,
it is considered evident that uncertainty leads to stochasticity. My belief is that from a
methodological point of view, it is more reasonable to travel from exact deterministic, to
approximate deterministic, to stochastic, and end with approximate stochastic SYSID.
See [14] for a more elaborate explanation of my misgivings for using stochastics as
basis for SYSID.
This brings up the question what we should mean by ‘the’ exact deterministic model
identiﬁed by an observed vector time series. The concept that ﬁts this aim is the most
powerful unfalsiﬁed model (MPUM), the model in the model class that explains the
observations, but as little else as possible. The purpose of this article is to develop an
algorithm to pass from an observed vector time series to the MPUM in the familiar
model class of systems described by linear constant coefﬁcient difference equations.
We start the development with the well-known state construction based on the in-
tersection of the row spaces of a past/future partition of the Hankel matrix of the data.
By scrutinizing this algorithm, using the Hankel structure, we deduce that this state
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 329–344, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

330
J.C. Willems
construction can be done without the past/future partition, and requires only the com-
putation of the left kernel of the Hankel matrix itself. However, this left kernel is inﬁnite
dimensional, but it has the structure of a ﬁnitely generated module, and the state con-
struction can be done using a module basis. It therefore sufﬁces to compute a ﬁnite
number of elements of the left kernel.
This computation can be done recursively, as follows. Truncate the Hankel matrix
at consecutive rows, until an element in the left kernel of the Hankel matrix is found.
Next, consider the system deﬁned by this element, and construct a direct complement
of it. Subsequently, compute the error deﬁned by a kernel representation of this com-
plement, applied to the original time series. This error has lower dimension than the
original one. This is recursively repeated until the error is persistently exciting. This
leads to an algorithm that computes the MPUM. It readily also gives the state trajectory
corresponding to the observed trajectory. The algorithm is therefore very adapted to
be used in concordance with subspace identiﬁcation, in which also a state model of the
MPUM is computed, with all the advantages thereof, for example for model reduction.
We present only the ideas underlying this algorithm. Proofs and simulations will
appear elsewhere.
A couple of words about the notation used. N denotes the set of natural numbers, and
R the reals. R [ξ] denotes, as usual, the ring of polynomials with real coefﬁcients, and
R (ξ) the ﬁeld of real rational functions, with ξ the indeterminate. Occasionally, we use
the notation R [ξ]•×w for polynomial matrices with w columns but an unspeciﬁed (ﬁnite)
number of rows. The backwards shift is denote by σ, and deﬁned, for f : N →F, by
σf : N →F,
σf(t) := f(t + 1).
2
Problem Statement
The problem discussed in this paper may be compactly formulated as follows.
Given an observed vector time series
˜w = ( ˜w(1), ˜w(2), . . . , ˜w(t), . . .)
with ˜w(t) ∈Rw and t ∈N, ﬁnd the most powerful unfalsiﬁed
model associated with ˜w in the model class of dynamical systems
consisting of the set of solutions of linear constant coefﬁcient
difference equations.
In section 8 we discuss how the ideas can be adapted to deal with more realistic
situations: ﬁnite time series, missing data (due to erasures or censoring), multiple time
series, approximate modeling, etc. In the present section, the terminology used in the
problem statement is explained.
We consider discrete time systems with time set N and with signal space a ﬁnite
dimensional real vector space, say Rw. With a dynamical model, we mean a family of
trajectories from N to Rw, a behavior B ⊆(Rw)N. B is
[[ unfalsiﬁed by ˜w ]] :⇔[[ ˜w ∈B ]].

Recursive Computation of the MPUM
331
Let B1, B2 ⊆(Rw)N. Call
[[ B1 more powerful than B2 ]] :⇔[[ B1 ⊂B2 ]].
Modeling is prohibition, and the more a model forbids, the better it is. A model class
is a set of behaviors. The most powerful unfalsiﬁed model (MPUM) associated with ˜w
in a model class is a behavior that is unfalsiﬁed by ˜w and more powerful than any other
unfalsiﬁed model in this model class. In other words, the MPUM explains the data ˜w,
but as little else as possible. Obviously, for a general model class, the MPUM may not
exist. We now describe a model class for which the MPUM does exist.
This model class is a very familiar one. It consists of the behaviors that are the set of
solutions of linear constant coefﬁcient difference equations. Explicitly, each behavior
B in this model class is deﬁned by a real polynomial matrix R ∈R [ξ]•×w as
B = {w : N →Rw | R(σ)w = 0}.
Since B = kernel (R(σ)), with R(σ) viewed as a map from (Rw)N to (Rrowdim(R))N,
we call
R(σ)w = 0
(K)
a kernel representation of the corresponding behavior.
We denote this model class by Lw. The many ways of arriving at it, and various
equivalent representations of its elements are described, for example, in [14, section
3]. Perhaps the simplest, ‘representation free’, way of characterizing Lw is as follows.
B ⊆(Rw)N belongs to Lw if and only if it has the following three properties:
(i) B is linear,
(ii) shift-invariant (σB ⊆B), and
(iii) closed in the topology of point-wise convergence.
Consider R [ξ]w. Obviously it is a module over R [ξ]. Let Mw denote the set of R [ξ]-
submodules of R [ξ]w. It is well known that each element of Mw is ﬁnitely generated,
meaning that for each M ∈Mw, there exist g1, g2, . . . , gp such that
M={r ∈R [ξ]w | ∃α1, α2, . . . , αp ∈R [ξ] such that r = α1g1 + α2g2 + · · · + αpgp}.
There exists a 1 ↔1 relation between Lw and Mw. This may be seen as follows.
Call
[[ r ∈R [ξ]w an annihilator for B ]] :⇔[[ r⊤(σ)B = 0 ]].
Denote the set of annihilators of B by B⊥. Clearly B⊥∈Mw. This identiﬁes the
map B ∈Lw →B⊥∈Mw. It can be shown that this map is surjective (not totally
trivial, but true). When B has kernel representation (K), then B⊥is the R [ξ]-module
generated by the transposes of the rows of R. To travel the reverse route and associate
an element B ∈Lw with a module M ∈Mw, take the behavior of the system with kernel
representation (K) generated by the polynomial matrix R with as rows the transposes
of a set of generators of M.

332
J.C. Willems
The module of annihilators is a more appropriate way of thinking about an element
B ∈Lw than the speciﬁc, but less intrinsic, difference equation (K) which one happens
to have chosen to deﬁne B.
The special case of (K) given by the overly familiar
P(σ)y = Q(σ)u, w = (u, y)
(i/o)
with P ∈R [ξ]p×p , Q ∈R [ξ]p×m , det(P) ̸= 0, and with proper transfer function G =
P −1Q ∈R (ξ)p×m , is called an input/output (i/o) system, with u : N →Rm the input
and y : N →Rp the output. The conditions imposed on P, Q ensure that u is free, and
that y does not anticipate u, the usual requirements on an input/output system. Clearly
(i/o) deﬁnes an element of Lm+p. Conversely, for every B ∈Lw, there exists a system
(i/o) with m + p = w, that has, up to a mere reordering of the components, behavior
B. With this reordering, we mean that there exists a permutation matrix Π ∈Rw×w
(depending on B, of course), such that (i/o) has behavior ΠB. In the sequel, we often
silently assume that the permutation that makes the inputs the leading, and the outputs
the trailing components of w has been carried out already.
As in all of system theory, controllability plays an important role also in the theory
surrounding the MPUM. We recall the behavioral deﬁnition of controllability.
[[ B ∈Lw is controllable]]
:⇔[[ ∀w1, w2 ∈B and t1 ∈N, ∃w ∈B and t2 ∈N, t2 ≥t1, such that
wW(t) = w1(t) for 1 ≤t ≤t1, and w(t) = w2(t −t1 −t2) for t > t1 + t2 ]].
Various characterizations of
controllability may
be found,
for example,
in
[14, section 5].
It is easy to see that there exists an MPUM in Lw associated with ˜w. Denote it by ˜B.
The most convincing proof that this MPUM exists, is by showing what it is:
˜B = linear span ({ ˜w, σ ˜w, . . . , σt ˜w, . . .}),
where the right hand side means the closure in the topology of point-wise convergence
of the linear span of the elements in the set. Obviously, this linear span is linear, it is
shift invariant since it is constructed from ˜w and its shifts, and after taking the closure,
it is closed in the topology of point-wise convergence. Consequently it belongs to Lw. It
is also unfalsiﬁed, since ˜w ∈˜B, and clearly any unfalsiﬁed element in Lw must contain
all the σt ˜w’s and hence their linear span, and be closed in the topology of point-wise
convergence. This proves that ˜B is indeed the MPUM in Lw associated with ˜w.
(K) is unfalsiﬁed by ˜w iff R(σ) ˜w = 0. It follows that among all polynomial matri-
ces R ∈R [ξ]•×w such that R(σ) ˜w = 0, there is one whose behavior is more powerful
than any other. And, of course, this MPUM allows an i/o representation. Our aim are
algorithms to go from the observed time series ˜w to a representation of its associated
MPUM in Lw. The most direct way to go about this is to compute, from ˜w, a polyno-
mial matrix R such that (K) is a kernel representation of this MPUM. Equivalently, to
compute a set of generators for B⊥. In [11] several such algorithms are described.
The ‘consistency’ problem consists of ﬁnding conditions so that the system that has
generated the data is indeed the one that is identiﬁed by the system identiﬁcation algo-
rithm. In our deterministic setting this comes down to checking when the system that

Recursive Computation of the MPUM
333
has generated ˜w is actually the MPUM in Lw associated with ˜w. Persistency of excita-
tion, but also controllability, are the key conditions leading to consistency. The vector
time series f : N →Rk is
[[ persistently exciting ]] :⇔[[ the MPUM in Lk associated with f equals

RkN ]].
Consider B ∈Lw, with i/o partition w = (u, y). Assume that ˜w = (˜u, ˜y) is parti-
tioned accordingly. Then B is the MPUM in Lw associated with ˜w if
1. ˜w ∈B,
2. ˜u is persistently exciting,
3. B is controllable.
In [13] a more general version of this consistency result is proven. Note that the ﬁrst
two conditions are clearly also necessary for consistency.
This result provides additional motivation for making the MPUM the aim of deter-
ministic system identiﬁcation.
3
Subspace Identiﬁcation
In addition to looking for a kernel representation of this MPUM, we are even more
interested in obtaining a state space representation of it. We ﬁrst explain what we mean
by this.
Let m, p, n be nonnegative integers, A ∈Rn×n, B ∈Rn×m, C ∈Rp×n, D ∈Rp×m,
and consider the ubiquitous system
σx = Ax + Bu, y = Cx + Du, w = (u, y).
(S)
In this equation, u : N →Rm is the input, y : N →Rp the output, and x : N →Rn the
state trajectory. The behavior
{(u, y) : N →Rm × Rp | ∃x : N →Rn such that (S) holds}
is called the external behavior of (S). It can be shown that this external behavior be-
longs to Lm+p. The (u, y, x)-behavior is obviously an element of Lm+p+n. This implies
that the (u, y)-behavior, what we call the external behavior, is an element of Lm+p.
This is due to the fact than the projection onto a subset of the components of a linear
shift-invariant closed subspace of (Rw)N is again linear, shift-invariant, and closed. This
result is called the ‘elimination theorem’, and is an important element in the behavioral
theory of systems. It implies, for example, that Lw is closed under addition.
So, the external behavior of (S) belongs of to Lm+p. Conversely, for every B ∈Lw,
there exists a system (S), with m + p = w, that has, up to a mere reordering of the
components (u, y), external behavior B. With this reordering, we mean that there exists
a permutation matrix Π ∈Rw×w such that (S) has external behavior ΠB. In the sequel,
we again often silently assume that the permutation that makes the inputs the leading,
and the outputs the trailing components of w has been carried out already.
(S) is called an input/state/output (i/s/o) representation of its external behavior. (S)
is called minimal if its state has minimal dimension among all i/s/o systems with the

334
J.C. Willems
same external behavior. It can be shown that minimal is equivalent to state observable,
meaning that if (u, y, x′) and (u, y, x′′) both satisfy (S), then x′ = x′′. In other words,
observability means that the state trajectory x can be deduced from the input and output
trajectories (u, y) jointly. As is very well-known, observability holds iff the (np × n)
matrix col

C, CA, · · · , CAn−1
has rank n. Minimality does not imply controllabil-
ity. But a minimal i/s/o representation is state controllable iff its external behavior is
controllable, in the sense we have deﬁned controllability of behaviors.
As explained in the previous section, we are looking for algorithms that pass from
the observed time series ˜w to its MPUM in Lw, for example, by computing a kernel
representation (K) of this MPUM. There is, however, another way to go about this, by
ﬁrst computing the state trajectory corresponding to ˜w in the MPUM, and subsequently
the system parameters (A, B, C, D) corresponding to an i/s/o representation. Explicitly,
assume that we had somehow found the MPUM. We could then compute a minimal i/s/o
representation for it, and obtain the (unique) state trajectory ˜x corresponding to ˜w. Of
course, for every T ∈N, there holds (assuming that the reordering of the components
discussed before such that ˜w = (˜u, ˜y) has been carried out)
' ˜x(2) ˜x(3) · · · ˜x(t + 1) · · ·
˜y(1) ˜y(2) · · ·
˜y(t)
· · ·
(
=
' A B
C D
( ' ˜x(1) ˜x(2) · · · ˜x(t) · · ·
˜u(1) ˜u(2) · · · ˜u(t) · · ·
(
.
($)
So, if
' ˜x(1) ˜x(2) · · · ˜x(T )
˜u(1) ˜u(2) · · · ˜u(T )
(
is of full row rank, ($), truncated at column T , provides an equation for computing
A, B, C, D, and yields an i/s/o representation of the MPUM.
As we explained it, this approach appears to be a vicious circle. For in order to
compute ˜x, we seem to need the MPUM to start with. But, if we could somehow
compute ˜x, directly from the data ˜w, without deriving it from the MPUM, then ($)
gives a viable and (see section 8) attractive way to compute an i/s/o representation of
the MPUM. In section 8 we shall explain that even when we deduce ˜x from a kernel
representation of the MPUM, it is advantageous to return to ($) for the purpose of
system identiﬁcation because of its built-in model reduction.
The SYSID methods that ﬁrst compute the state trajectory from the data, and then
derive the system model from the state trajectory have become known as subspace
identiﬁcation algorithms. Before the emergence of these methods, state space represen-
tations played a somewhat secondary role in system identiﬁcation. The purpose of this
paper is to take a closer look at (the deterministic version of) these algorithms.
4
State Construction by Past/Future Partition
The question is:
How can we compute the state trajectory ˜x
directly from ˜w, without ﬁrst computing the MPUM ˜B?

Recursive Computation of the MPUM
335
The doubly inﬁnite matrix
H :=
⎡
⎢⎢⎢⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
...
...
... ... ...
...
... ... ...
˜w(t′) ˜w(t′ + 1) · · · ˜w(t + t′ −1) · · ·
...
...
...
...
...
...
...
...
...
⎤
⎥⎥⎥⎥⎥⎥⎦
(H)
is called the Hankel matrix of the data ˜w. It holds the key to the state construction.
The earliest subspace algorithms are based on the intersection of the span of the
rows of a past/future partition of this Hankel matrix, and deduce the state trajectory as
the common linear combinations of the past and the future. This proceeds as follows.
Partition a row truncation of H as

Hp
Hf

=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
...
...
... ... ...
...
... ... ...
˜w(Tp)
˜w(Tp + 1)
· · ·
˜w(Tp + t −1)
· · ·
˜w(Tp + 1)
˜w(Tp + 2)
· · ·
˜w(Tp + t)
· · ·
...
...
...
...
...
...
...
...
...
˜w(Tp+Tf −1)
˜w(Tp + Tf)
· · · ˜w(Tp+Tf +t−2) · · ·
˜w(Tp + Tf)
˜w(Tp+Tf +1) · · · ˜w(Tf +Tp+t−1) · · ·
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(Hp/Hf)
and refer to Hp as the ‘past’, and to Hf as the ‘future’ of the Hankel matrix. Tp and
Tf are sufﬁciently large nonnegative integers. Actually, it is possible to proceed after
truncating these Hankel matrices also column-wise at a sufﬁciently large column T . We
do not enter into details about what ‘sufﬁciently large’ exactly means in these statements
— those issues are glossed over here.
Consider the intersection of the linear space spanned by the rows of Hp and the
linear space spanned by the rows of Hf. Let n be the dimension of this intersection.
This means that there are n linearly independent linear combinations of the rows of Hp
that are equal to linear combinations of the rows of Hf. These linear combinations can
be stacked into a matrix with n rows,
˜X =
5
˜x(Tp + 1) ˜x(Tp + 2) · · · ˜x(Tp + t) · · ·
6
It turns out that, under suitable conditions which are spelled out in [11], the dimension
of this intersection equals the dimension of the state space of a minimal i/s/o repre-
sentation of the MPUM in Lw associated with ˜w. Moreover, as the notation suggests,
the columns of ˜X form the state trajectory corresponding to ˜w in the MPUM ˜B (more
precisely, corresponding to a minimal i/s/o representation of ˜B). This then leads, by
equation ($), to an algorithm to compute the matrices A, B, C, D and to an identiﬁca-
tion procedure for the MPUM.

336
J.C. Willems
In [11] this intersection algorithm is applied to a variety of situations, including
classical realization theory. These algorithms have been given good numerical linear
algebra based implementations in [8].
In the purely deterministic case the state trajectory can be obtained, as we have just
seen, as the intersection of the linear span of the rows of the past with the linear span
of the rows of the future of the Hankel matrix of the data. This is, in a sense, analogous
to the fact that in the purely stochastic case the state trajectory can be obtained as the
orthogonal projection of the linear span of the rows of the past onto the linear span of the
rows of the future of the Hankel matrix of the data, as noted in [1]. This idea was used in
[6] for the purposes of stochastic SYSID. The resulting subspace methods in the context
of the purely stochastic case have been followed up by many authors, see, in particular,
[5] and [4]. The combined deterministic/stochastic case is a signiﬁcant generalization
of the purely deterministic case and the purely stochastic case individually. It has been
studied in [7, 8]. Similar algorithms have been developed in [10]. In the mean time,
many articles dealing with subspace algorithms for the combined case have appeared,
for instance [2,3].
5
The Hankel Structure and the Past/Future Partition
Let us now take a closer look at the intersection of the spaces spanned by the rows of Hp
and by the rows of Hf. How can we obtain this intersection? Consider this question
ﬁrst for a general partitioned matrix
M =
' M ′
M ′′
(
.
The common linear combinations of the row span of M ′ and the row span of M ′′ can
be computed from the left kernel of M. Indeed,
[[ k M = 0 ↔
5k′ k′′6 ' M ′
M ′′
(
= 0 ]] ⇔[[ k′ M ′ = −k′′ M ′′ ]],
and hence the common linear combinations of the span of the rows of M ′ and M ′′
follow immediately from a set of vectors that span the left kernel of M, by truncating
these vectors conformably with the partition of the matrix M, to k′, and multiplying by
M ′. This can be applied to the partitioned Hankel matrix (Hp/Hf), and we observe
that the state construction amounts to computing the left kernel of the partitioned matrix
(Hp/Hf).
We shall now argue that, because of the Hankel structure, the left kernel of (Hp/Hf)
can be deduced from the left kernel of Hp all by itself, and so, there is no need to use
the past/future partitioning in order to construct the left kernel and the state. To see this,
assume that
5
k1 k2 · · · kTp
6
is in the left kernel of Hp, i.e. k Hp = 0. Notice that, because of the Hankel structure
of H, the vectors

Recursive Computation of the MPUM
337
5 0 · · · 0 k1 k2 · · · kTp 0 · · · 0 6
,
obtained by putting in total Tf zeros in front and in back of
5
k1 k2 · · · kTp
6
, are all
contained in the left kernel of (Hp/Hf). It can be shown that, provided Tp is sufﬁ-
ciently large (but it need not be larger that what was required to validate the intersection
argument of the row spans of Hp and Hf of the previous section), we obtain this way,
from a set of vectors that span the left kernel of Hp, a set of vectors that span the whole
left kernel of (Hp/Hf). After truncation to its ﬁrst Tp elements,
5 0 · · · 0 k1 k2 · · · kL
6
,
this leads to a set of vectors that, when multiplied from the right with Hp, span the
intersection of the spaces spanned by the rows of Hp and the rows of Hf. Note that this
truncation results from applying repeatedly the shift-and-cut operator to the row vector
5 k1 k2 · · · kTp
6
, i.e. putting a zero in the ﬁrst element and deleting the last element of
this row vector, so as to obtain a vector of length Tp. In other words, from the vector
5 k1 k2 · · · kTp
6
in the left kernel of Hp, we obtain the vectors
[ 0 k1 k2 · · · kTp−2 kTp−1 ]
[ 0 0 k1 · · · kTp−3 kTp−2 ]
...
[ 0 0 0 · · ·
k1
k2
]
[ 0 0 0 · · ·
0
k1
]
that are truncations of elements from the left kernel of

Hf
Hp

Using the ideas explained in the previous section, this leads to the construction of the
state trajectory associated with ˜w in the MPUM, by computing a basis of the left kernel
of Hp, stacking these vectors as the rows of the matrix
5
K1 K2 · · · KTp−1 KTp
6
,
and repeatedly applying the shift-and-cut operator to obtain the state trajectory
5 ˜x(Tp + 1) ˜x(Tp + 2) · · · ˜x(Tp + t) · · · 6
=
⎡
⎢⎢⎢⎢⎣
0 K1 K2 · · · KTp−2 KTp−1
0 0 K1 · · · KTp−3 KTp−2
...
...
...
...
...
...
...
...
0 0
0
· · ·
K1
K2
0 0
0
· · ·
0
K1
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
˜w(3)
˜w(4)
· · ·
˜w(t + 2)
· · ·
...
...
...
...
...
...
...
...
...
˜w(Tp −1)
˜w(Tp)
· · · ˜w(Tp + t −2) · · ·
˜w(Tp)
˜w(Tp + 1) · · · ˜w(Tp + t −3) · · ·
⎤
⎥⎥⎥⎥⎥⎥⎦
.

338
J.C. Willems
Actually, it turns out that we can also apply the shift-and-cut backwards, leading to
5
˜x(1)
˜x(2)
· · · ˜x(t) · · ·
6
=
⎡
⎢⎢⎢⎢⎣
K2
K3
· · · KTp−1 KTp
K3
K4
· · ·
KTp
0
...
...
...
...
...
...
...
KTp−1 KTp · · ·
0
0
KTp
0
· · ·
0
0
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
...
...
...
...
...
...
...
...
...
˜w(Tp −2) ˜w(Tp −1) · · · ˜w(Tp + t −3) · · ·
˜w(Tp −1)
˜w(Tp)
· · · ˜w(Tp + t −2) · · ·
⎤
⎥⎥⎥⎥⎦
.
This then yields the desired state trajectory to which the subspace algorithm ($) can be
applied in order to obtain an i/s/o representation of the MPUM.
6
The Left Kernel of a Hankel Matrix
In the previous section, we have seen the relevance to the problem at hand of computing
the left kernel of the doubly inﬁnite Hankel matrix H. We are interested in character-
izing the inﬁnite vectors in its left kernel that have ‘compact support’, i.e. the inﬁnite
vectors of the form
k =
5 k1 k2 · · · kt · · · 0 · · · 0 · · · 6
,
kt ∈R1×w, t ∈N,
with k H = 0. Denote the set of compact support elements in the left kernel by N. For
simplicity, we call N the left kernel of H.
In general, N is inﬁnite dimensional. In fact, N equals {0}, or it is inﬁnite di-
mensional. However, we shall now argue that by considering the left kernel of H as
a module, N is effectively ﬁnite dimensional, of dimension ≤w. Observe that N is
closed under addition (obvious), scalar multiplication (obvious), and under the right
shift (also obvious, using the Hankel structure):
[[
5 k1 k2 · · · kt 0 0 · · · 0 · · · 6
∈N ]] ⇒[[
5 0 k1 · · · kt−1 kt 0 · · · 0 · · · 6
∈N ]].
This implies (identify elements k ∈N with polynomial vectors k1 + k2ξ + · · · +
Ktξt−1 + · · · ∈R [ξ]1×w, and the right shift with multiplication by ξ) that N has
the structure of a module (a submodule of R [ξ]1×w, viewed as an R [ξ]-module). This
submodule is ﬁnitely generated (all R [ξ]-submodules of R [ξ]1×w are ﬁnitely generated,
with at most w generators). This means that there exist elements n1, n2, . . . , np ∈N,
with p ≤w, such that all other elements of N can be obtained as linear combinations
of these elements and their repeated right shifts.
It turns out that for the construction of the state trajectory, we need only these gen-
erators. In other words, rather that compute the whole left kernel of Hp, it sufﬁces to
obtain a set of generators of the left kernel of H in the left kernel of Hp. We assume
that Lp is sufﬁciently large, so that the left kernel of Hp contains a set of generators of
the left kernel of H.
This leads to the following state construction algorithm. Let n1, n2, · · · , np of N be
a set of generators of the left kernel of H. Truncate these vectors at their last non-zero
element:
ni ∼=
5 ni,1 ni,2 · · · ni,Li
6
,
ni,t ∈R1×w.

Recursive Computation of the MPUM
339
Now apply the shift-and-cut to the i-th generator.
This leads to the ‘partial’ state
trajectory
5
˜xi(1)
˜xi(2) · · · ˜xi(t) · · · 6
=
⎡
⎢⎢⎢⎢⎣
ni,2
ni,3
· · · ni,Li−1 ni,Li
ni,3
ni,4
· · ·
ni,Li
0
...
...
...
...
...
...
...
ni,Li−1 ni,Li · · ·
0
0
ni,Li
0
· · ·
0
0
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
...
...
...
...
...
...
...
...
...
˜w(Li −2) ˜w(Li −1) · · · ˜w(Li + t −3) · · ·
˜w(Li −1)
˜w(Li)
· · · ˜w(Li + t −2) · · ·
⎤
⎥⎥⎥⎥⎦
.
Now, stack the ˜xi’s. This leads to the state trajectory
⎡
⎢⎢⎢⎣
˜x1(1)
˜x2(1)
...
˜xp(1)
⎤
⎥⎥⎥⎦,
⎡
⎢⎢⎢⎣
˜x1(2)
˜x2(2)
...
˜xp(2)
⎤
⎥⎥⎥⎦, · · · ,
⎡
⎢⎢⎢⎣
˜x1(t)
˜x2(t)
...
˜xp(t)
⎤
⎥⎥⎥⎦, · · ·
to which the subspace algorithm ($) can be applied.
In conclusion, from a set of generators of N viewed as a module, we obtain, by
repeatedly using the shift-and-cut, and matrix which multiplied by the Hankel matrix
of the data, yields the state trajectory ˜x. In the next section, we provide a recursive way
of computing a set of generators.
7
Recursive Computation of a Module Basis
Consider the left kernel N of H. Call a minimal set of elements n1, n2, . . . , np ∈N
that generate all of N, through linear combinations of these elements and their repeated
right shifts, a module basis of N. In the present section, we set up a recursive algorithm
to compute a module basis of N from ˜w.
Assume henceforth that the MPUM in Lw associated with ˜w is controllable. This
assumption is made for reasons of exposition. The algorithm can be generalized without
this assumption, but it becomes considerably more involved to explain.
We start with a brief digression about controllability. The following basic property
characterizes controllable behaviors in Lw:
[[ B ∈Lw is controllable]] ⇔[[ ∃B′ ∈Lw such that B ⊕B′ = (Rw)N ]].
Evidently, B′ is also controllable. In other words, a behavior has a direct complement
iff it is controllable. This property of controllable behaviors can be translated in terms
of a kernel representation (K) of B, with R of full row rank (every B ∈Lw allows such
a full row rank representation). It states that
[[ kernel (R (σ)) ∈Lw is controllable]]
⇔[[ ∃R′ ∈R [ξ]•×w such that
' R
R′
(
is unimodular]].
In fact, R′(σ)w = 0 is a kernel representation of the direct complement B′.

340
J.C. Willems
We now return to the construction of the MPUM. Start with the data ˜w. Consider the
associated Hankel matrix H, and its consecutive truncations
5 ˜w(1)
˜w(2)
· · ·
˜w(t)
· · · 6
,
' ˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
(
,
...
⎡
⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
...
...
...
...
...
...
...
...
...
˜w(L) ˜w(L + 1) · · · ˜w(t + L −1) · · ·
⎤
⎥⎥⎥⎦,
until a vector in the left kernel is obtained. Denote this element by
5 k1 k2 · · · kL
6
∈R1×wL.
Now consider the corresponding vector polynomial
n(ξ) = k1 + k2ξ + · · · + kLξL−1 ∈R [ξ]1×w .
It can be shown that, because of the assumed controllability of the MPUM, the system
with kernel representation n(σ)w = 0 is also controllable. Consequently, there exists
N ∈R [ξ](w−1)×w such that the polynomial matrix
' n
N
(
is unimodular. The system described by n(σ)w = 0 is unfalsiﬁed by ˜w, but, of course,
N(σ)w = 0 need not be. Compute the ‘error’ vector time series
˜e = N(σ) ˜w = (˜e(1), ˜e(2), . . . , ˜e(t), . . .) ,
Now apply the above algorithm again, with ˜w replaced by ˜e, and proceed recursively.
Note that ˜e(t) ∈Rw−1: the dimension of the time series that needs to be examined goes
down by one at each step.
Recursively this leads to the algorithm
˜w 
→n1 
→N1 
→˜e1 
→n2 
→N2 
→˜e2 
→· · · 
→˜ep−2 
→np−1 
→Np−1 
→˜ep−1 
→np.
This algorithm terminates when there are no more vectors in the left kernel of the as-
sociated Hankel matrix, i.e. when the error ˜e is persistently exciting. If we assume that
the MPUM has m input and p output components, then ˜ep will be the ﬁrst persistently
exciting error time series obtained.
Now consider the polynomial vectors
r1 = n1, r2 = n2N1, r3 = n3N2N1, · · · , rp = npNp−1Np−2 · · · N2N1.

Recursive Computation of the MPUM
341
Deﬁne
˜R =
⎡
⎢⎢⎢⎣
r1
r2
...
rp
⎤
⎥⎥⎥⎦.
It can be shown that
˜R(σ)w = 0
is a kernel representation of ˜B, the MPUM in Lw associated with ˜w. The intermediate
calculations of r1, r2, . . . , rp lead to the state trajectory in a similar way as explained in
section 6. Let
ri(ξ) = ri,1 + ri,2ξ + · · · + ri,LiξL1−1 ∈R [ξ]1×w .
Form the vector
ri ∼=
5
ri,1 ri,2 · · · ri,Li
6
,
ri,t ∈R1×w.
Now apply the shift-and-cut. This leads to the ‘partial’ state trajectory
5 ˜xi(1)
˜xi(2) · · · ˜xi(t) · · · 6
=
⎡
⎢⎢⎢⎢⎣
ri,2
ri,3
· · · ri,Li−1 ri,Li
ri,3
ri,4
· · ·
ri,Li
0
...
...
...
...
...
...
...
ri,Li−1 ri,Li · · ·
0
0
ri,Li
0
· · ·
0
0
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
...
...
...
...
...
...
...
...
...
˜w(Li −2) ˜w(Li −1) · · · ˜w(Li + t −3) · · ·
˜w(Li −1)
˜w(Li)
· · · ˜w(Li + t −2) · · ·
⎤
⎥⎥⎥⎥⎦
.
Now, stack the ˜xi’s, and obtain the state trajectory
⎡
⎢⎢⎢⎣
˜x1(1)
˜x2(1)
...
˜xp(1)
⎤
⎥⎥⎥⎦,
⎡
⎢⎢⎢⎣
˜x1(2)
˜x2(2)
...
˜xp(2)
⎤
⎥⎥⎥⎦, · · · ,
⎡
⎢⎢⎢⎣
˜x1(t)
˜x2(t)
...
˜xp(t)
⎤
⎥⎥⎥⎦, · · ·
to which the subspace algorithm ($) can be applied.
8
Concluding Remarks
8.1
Subspace ID
Solving equation ($) as the basis for system identiﬁcation has many appealing features.
We can begin by reducing the number of rows of
˜X =
5
˜x(1) ˜x(2) · · · ˜x(t) · · ·
6
by numerically approximating this matrix by one with fewer rows. This leads to a
reduction of the state dimension and hence of the model complexity. Of course, ($)

342
J.C. Willems
will then no longer be exactly solvable, even when the observed data is noise free, but
since this equation is linear in the unknown matrices A, B, C, D, it is very amenable
to a least-squares (LS) solution. Introducing the state in a sense linearizes the SYSID
problem. Solving equation ($) using (LS) also accommodates for noisy data and for
numerical errors in the intermediate calculations.
Missing data can be dealt with by deleting columns in the equation ($). If multiple
time series are observed (this is the case in classical realization theory), then equation
($) can readily be extended with the vectors ˜u, ˜y, ˜x replaced by matrices.
8.2
State Construction by Shift-and-Cut
The state construction that permeates sections 5, 6, and 7 is actually well-known, and
our presentation of it via the past/future partition and the left kernel of the Hankel matrix
H to some extent hides the simplicity and generality of the ideas behind it.
Indeed, in [9], a state construction algorithm based on the shift-and-cut operator has
been presented as a very direct and general method for constructing state representa-
tions, starting from a variety of other system representations. Let p ∈R [ξ] and deﬁne
the shift-and-cut operator σ∗: R [ξ] →R [ξ] by
σ∗: p0 + p1ξ + · · · + pLξL →p1 + p2ξ + · · · + pLξL−1.
By applying the operator σ∗element-wise, it is readily extended to polynomial vectors
and matrices.
We now explain how this state construction works, starting with a kernel representa-
tion (K). Associate with
R(ξ) = R0 + R1ξ + · · · + RLξL
the stacked polynomial matrix
X(ξ)=
⎡
⎣
σ∗R
σ∗2R
...
⎤
⎦(ξ)=
⎡
⎢⎢⎢⎢⎢⎣
R1 + R2ξ + R3ξ3 + · · · + RL−1ξL−2 + RLξL−1
R2 + R3ξ + · · · + RL−1ξL−3 + RLξL−2
...
RL−1 + RLξ
RL
⎤
⎥⎥⎥⎥⎥⎦
(ξ),
obtained by repeatedly applying σ∗to R until we get the zero matrix. It can be shown
that X(σ) is a state map: it associates to w ∈kernel(R(σ)) the corresponding state
trajectory x = X(σ)w of a (in general non-minimal) state representation of (K). In
other words, as soon as we have a kernel representation of the MPUM, the shift-and-cut
operator gives us the underlying state.
This shift-and-cut state construction is precisely what is done in sections 5, 6, and 7.
Starting from the MPUM as
˜B = linear span ({ ˜w, σ ˜w, . . . , σt ˜w, . . .}),
we construct annihilators for ˜B. These annihilators are, of course, exactly the elements
of the left kernel of the Hankel matrix H. By subsequently applying the shift-and-cut
operator, we obtain the state trajectory ˜x corresponding to ˜w.

Recursive Computation of the MPUM
343
8.3
Return to the Data
One of the attractive features of subspace methods, is that after construction of ˜x, the
model is obtained using equation ($) which involves ˜w and ˜x. In other words, it al-
lows to return to the original observed time series ˜w in order to ﬁt the ﬁnal parameter
estimates of the identiﬁed system to the data.
The shift-and-cut state construction shows how to obtain a state trajectory from any
kernel representation of the MPUM. We originally posed the question of how to con-
struct the state trajectory by avoiding the intermediate computation of a kernel repre-
sentation of the MPUM. But, we have come full circle on this. We demonstrated that
the state construction based on the intersection of the row spans of Hp and Hf actually
amounts to ﬁnding a module basis of a kernel representation of the MPUM. It is an
interesting matter to investigate to what extent these insights can also be used in the
purely stochastic or in the mixed deterministic/stochastic case.
8.4
Approximation and Balanced Reduction
The algorithm proposed in section 7 lends itself very well for approximate implemen-
tation. Checking whether the consecutive truncations of the Hankel matrix have, up to
reasonable level of approximation, a non-trivial element in the left kernel, and ﬁnding
the optimal element in the left kernel, are typical decisions that can be made using SVD
based numerical linear algebra computations.
It is of interest to combine our recursive algorithms with model reduction. In partic-
ular, it ought to be possible to replace the state construction based on the shift-and-cut
operator applied to an annihilator by an alternative set of low order polynomial vectors
that lead to a balanced state model. Some ideas in this direction have been given in [12].
8.5
The Complementary System
The most original feature of this article is the recursive computation of a basis of the
module of annihilators of a given behavior in section 7. In the controllable case, this
may be done by complementing a kernel representation to a unimodular polynomial
matrix. It is of interest to explore if the recursive computation of the module basis
explained in section 7, combined with the shift-and-cut map, can also be used in the
general constructions of a state map, starting from a kernel, an image, or a latent variable
representation of a behavior.
The ﬁner features and numerical aspects of this recursive computation and extension
of a polynomial matrix to a unimodular one is a matter of future research. In particular,
one is led to wonder if the ℓ2 (N, Rw)-orthogonal complement of B ∩ℓ2 (N, Rw) can
play a role in obtaining a complement of a B. Or if the singular value decomposition of
the truncated Hankel matrix
⎡
⎢⎢⎢⎣
˜w(1)
˜w(2)
· · ·
˜w(t)
· · ·
˜w(2)
˜w(3)
· · ·
˜w(t + 1)
· · ·
...
...
...
...
...
...
...
...
...
˜w(L) ˜w(L + 1) · · · ˜w(t + L −1) · · ·
⎤
⎥⎥⎥⎦

344
J.C. Willems
can be used for complementing n with N to obtain a unimodular polynomial matrix.
The left singular vector corresponding to the smallest singular value should serve to
identify the element n in the left kernel, and the others somehow to ﬁnd the comple-
ment N.
Acknowledgments
This research is supported by the Research Council KUL project CoE EF/05/006 (OPTEC),
Optimization in Engineering, and by the Belgian Federal Science Policy Ofﬁce: IUAP P6/04
(Dynamical systems, Control and Optimization, 2007-2011).
References
1. H. Akaike, Markovian representation of stochastic processes by canonical variables, SIAM
Journal on Control, volume 13, pages 162–173, 1975.
2. A. Chiuso and G. Picci, Asymptotic variance of subspace estimates, Journal of Economet-
rics, volume 118, pages 257–291, 2004.
3. A. Chiuso and G. Picci, Consistency analysis of certain closed-loop subspace identiﬁcation
methods, Automatica, volume 41, pages 377–391, 2005.
4. D. Bauer, Comparing the CCA subspace method to pseudo maximum likelihood methods in
the case of no exogenous inputs, Journal of Time Series Analysis, volume 26, pages 631–668,
2005.
5. M. Deistler, K. Peternell, and W. Scherrer, Consistency and relative efﬁciency of subspace
methods, Automatica, volume 31, pages 185–1875, 1995.
6. W.E. Larimore, System identiﬁcation, reduced order ﬁlters and modeling via canonical vari-
ate analysis, Proceedings of the American Control Conference, pages 445-451, 1983.
7. P. Van Overschee and B. L. M. De Moor, N4SID: Subspace algorithms for the identiﬁcation
of combined deterministic-stochastic systems, Automatica, volume 30, pages 75-93, 1994.
8. P. Van Overschee and B. L. M. De Moor, Subspace Identiﬁcation for Linear Systems: Theory,
Implementation, Applications, Kluwer Academic Press, 1996.
9. P. Rapisarda and J.C. Willems, State maps for linear systems, SIAM Journal on Control and
Optimization, volume 35, pages 1053-1091, 1997.
10. M. Verhaegen, Identiﬁcation of the deterministic part of MIMO state space models given in
innovations form from input-output data, Automatica, volume 30, pages 61–74, 1994.
11. J. C. Willems, From time series to linear system, Part I. Finite dimensional linear time invari-
ant systems, Part II. Exact modelling, Part III. Approximate modelling, Automatica, volume
22, pages 561-580 and 675-694, 1986, volume 23, pages 87-115, 1987.
12. J.C. Willems and P. Rapisarda, Balanced state representations with polynomial algebra, in
Directions in Mathematical Systems Theory and Optimization, (edited by A. Rantzer and
C.I. Byrnes), Springer Lecture Notes in Control and Information Sciences, volume 286,
pages 345-357, 2002.
13. J.C. Willems, P. Rapisarda, I. Markovsky, and B. De Moor, A note on persistency of excita-
tion, Systems & Control Letters, volume 54, pages 325-329, 2005.
14. J.C. Willems, Thoughts on system identiﬁcation, in Control of Uncertain Systems: Mod-
elling, Approximation and Design (edited by B.A. Francis, M.C. Smith, and J.C. Willems),
Springer Verlag Lecture Notes on Control and Information Systems, volume 329, pages 389–
416, 2006.

New Development of Digital Signal Processing Via
Sampled-Data Control Theory
Yutaka Yamamoto
Department of Applied Analysis and Complex Dynamical Systems
Graduate School of Informatics
Kyoto University
Kyoto 606-8501, Japan
yy@i.kyoto-u.ac.jp
www-ics.acs.i.kyoto-u.ac.jp/˜yy/
1
Foreword
It is a great pleasure to contribute this article to the special issue in honor of Giorgio
Picci on the occasion of his 65th birthday. Throughout his career, stochastic methods
in modeling and ﬁltering have been central to Giorgio’s research. This article intends
to describe a new idea in digital ﬁlter design, but from a deterministic point of view. I
hope that it can provide a contrasting viewpoint on noise and signals in some speciﬁc
contexts.
2
Introduction
Digital signals are all around us: Jpeg and other format still images, MPEG2 format in
moving images, CD, MP3 music sources, etc., just to name a few.
What is the advantage of digital? Why are they so prevailing?
First, they are inexpensive and very portable, due to the uniform quality that they
guarantee. They are easy to copy, distribute, without worrying much about deteriora-
tion. This is in marked contrast to analog formats. One can easily see this by iterating
analog photocopying three consecutive times. The quality will be noticeably deteri-
orated. In digital copying, this is hardly of concern. Highest quality analog signal
processing, e.g., analog audio records, may still outperform digital processing, but it is
more expensive, delicate, and often vulnerable.
What guarantees this high-quality reproduction? This is precisely due to the nature
of digital. One represents the original analog signals via digital data which are
1. sampled, often in uniformly separated time and space,
2. quantized, and
3. saturated.
Such characteristics allow us to represent the original data via discrete set of numbers
(digits), and this assures more ﬂexibility in processing and high-quality reproduction
precision.
A. Chiuso et al. (Eds.): Modeling, Estimation and Control, LNCIS 364, pp. 345–355, 2007.
springerlink.com
c⃝Springer-Verlag Berlin Heidelberg 2007

346
Y. Yamamoto
Thus, while digital processing often yields the impression of high-precision, we im-
mediately see that quality deterioration is in a sense inevitable in the three steps above.
To state it differently, it is this deterioration (and simpliﬁcation) that guarantees the high
reproduction performance and versatility in processing.
Thus digital signal processing is not an all-win game, as opposed to the common
understanding of otherwise. We certainly lose some information contents in the digi-
tization process above. One should therefore make a judicious choice in sampling and
digitizing.
This article attempts to analyze some pertinent problems mainly in relation to
sampling. This has been predominantly settled through the sampling theorem—the
paradigm proposed by Shannon [6, 7, 13]. But this is not necessarily the best solution
when signals are not nearly band-limited. We start with a somewhat critical overview
of the current signal processing paradigm, and show how control/system theory can
contribute to this situation.
3
The Shannon Paradigm
Suppose we are given a continuous-time signal f(t), t ∈R.
Sampling reads out
its values with a discrete timing, mostly with a uniformly spaced time sequence
t = nh, n = . . . , −1, 0, 1, . . ., etc. The period h is called the sampling period, and
{f(nh)}∞
n=−∞sampled values.
Given the sampled values {f(nh)}∞
n=−∞, we wish to reconstruct the original
continuous-time signal f(t) as much as possible, with high precision. But what do
we mean by high precision? We obviously wish to mean that it is close to the original
signal with respect to a certain performance measure. But then where is the original
signal here?
In tracking systems in control, reference signals are measured and the error with the
system output is available through measurement. In signal processing, such signals (to
be tracked) are never available. Recovering such signals is precisely the objective of
signal processing. This is a fundamental difference between control and signal process-
ing. Then how can we apply control methodology to signal processing? Is it possible
at all?
Before answering this question, let us review the common framework in the current
theory of digital signal processing. We start with the sampling theorem.
The sampling theorem, usually attributed to Shannon1, answers this question under
the hypothesis of band-limited signals. That is, we assume that the frequency contents
are limited to the frequency range lower than π/h:
Theorem 1 (Whittaker-Shannon). Suppose that f ∈L2 is fully band-limited, i.e.,
there exists ω0 ≤π/h such that the Fourier transform ˆf of f satisﬁes
ˆf(ω) = 0,
|ω| ≥ω0, .
(1)
1 The history of repeated discoveries of the sampling theorem is quite involved. Shannon him-
self did not claim originality in this fact itself [6], although his name is very popularly attached
to the theorem. The reader is referred to [13].

Digital Signal Processing Via Sampled-Data Control Theory
347
Then the following formula uniquely determines f:
f(t) =
∞

n=−∞
f(nh)sin π(t/h −n)
π(t/h −n)
.
(2)
This theorem says that if the original signal f contains no frequency components be-
yond π/h [rad/sec] (known as the Nyquist frequency), then f can be uniquely recovered
from its sampled values.
Fig. 1. Aliasing effect
Fig. 1 shows a typical situation. Consider the sine wave on the upper ﬁgure; its
sampled values are indicated by black dots. The lower ﬁgure shows that these sam-
pled values are compatible with a lower frequency sinusoid shown by the dotted curve.
That is, the sampling period here does not have sufﬁcient resolution that enables us to
distinguish these two sinusoids. This phenomenon is called the aliasing effect, and the
distortion induced by this lack of resolution is called an aliasing distortion. In other
words, if the original signal does not contain high frequency components inducing such
a behavior, it is recoverable from sampled values. The sampling theorem states that the
Nyquist frequency π/h, which is the half of the sampling frequency, gives the limit of
this faithful recovery.
This is essentially the content of the sampling theorem and is accepted as virtually the
only guiding principle in digital signal processing for modeling analog characteristics.
3.1
Problems in the Shannon Paradigm
The principle above can however involve many problems. First, real signals are not nec-
essarily band-limited as in Theorem 1. One may then wish this to hold approximately.
However, in practice, the margin is mostly too small; for example, in the case of CD,
the Nyquist frequency is 22.05kHz while the alleged audible limit is 20kHz: the margin

348
Y. Yamamoto
is only 10%. Whether this is enough or not has been a long-lasting issue, but there are
quite a few people who are against this format [5].
In any event, the spectra of musical sounds generally distribute very widely, way
over 20kHz. If we sample them as they are, it will induce the aliasing distortion as the
sampling theorem says, and hence one usually inserts an analog low-pass ﬁlter before
sampling (called an anti-aliasing ﬁlter), with a very sharp cut-off characteristic, to avoid
aliasing from high-frequency components.2
0
5
10
15
−1.5
−1
−0.5
0
0.5
1
1.5
Fig. 2. Ringing due to the Gibbs phenomenon
This sharp roll-off characteristic however induces an unpleasant side-effect. For
example, it induces a large amount of overshoot against square waves. This is called
ringing, and is a result of the well-known Gibbs phenomenon in Fourier analysis. See
Fig. 2 which shows a response of such a low-pass ﬁlter against a square wave. The
common criticism against CD that it is often too metallic and harsh is probably due
to this effect. To circumvent this effect, one needs more high-frequency components
introducing a slower decay curve. The problem here is how we can sensibly accomplish
this. To the best of author’s knowledge, this time-domain Gibbs phenomenon3 does not
seem to have been an issue in signal processing.
2 Ideally, it is desired that this ﬁlter cuts off from 1 to 0 at the cut-off frequency. This is called
the (Shannon) ideal ﬁlter, but it is known not to be physically realizable.
3 Oddly enough, the Gibbs phenomenon in the frequency domain has been a major issue in sig-
nal processing, because it was regarded harmful to realize an ideal low-pass characteristic, and
various window-functions have been proposed. While the true performance should be mea-
sured in the signal domain, this preposterous attitude occurred from the objective of blindly
pursuing the precision of the ideal low-pass ﬁlter.

Digital Signal Processing Via Sampled-Data Control Theory
349
Another problem here is that the reconstruction formula (2) is not causal. It requires
inﬁnitely many future samples to recover the current signal value. To circumvent this
defect, one usually introduces a certain amount of delay in reconstruction, and allows
to use ﬁnitely many future samples to reconstruct the present value. However, the con-
vergence of this ﬁlter coefﬁcients is slow, and it requires a large number of delays. This
amounts to approximating the ideal low-pass ﬁlter that cuts off at or before the Nyquist
frequency from 1 to 0. This ideal ﬁlter is not physically realizable, and approximation
in the current signal processing techniques requires many, often ad hoc, techniques.
4
Control Theoretic Formulation
The Shannon paradigm may be summarized as follows:
•
Given a sampling period h, we conﬁne ourselves to the class of ideally band-limited
functions whose spectrum is zero beyond the Nyquist frequency π/h.
•
To force real signals into this class, one introduces a low-pass ﬁlter with a sharp
cut-off characteristic.
•
Once this class is ﬁxed, one attempts to approximate the Shannon ideal low-pass
ﬁlter that
1. passes all frequency components below the Nyquist frequency, and
2. stops all components beyond this frequency.
As we discussed already, the perfect band-limiting hypothesis is not a realistic as-
sumption, and furthermore, the approximation problem as above leads to a ﬁlter of a
long tail. Also, it introduces distortions as shown in Fig. 2. In addition, in approxi-
mating the ideal low-pass ﬁlter, one inevitably introduces a phase distortion around the
cut-off frequency. The error due to this effect is often not evaluated.
To repeat, due to this unrealistic hypothesis, one introduces some artifacts, which
in practice result in undesirable consequences not conceived in the ideal situation. In
other words, we need to guarantee the performance when we are disturbed to a non-
ideal situation. This is the question of robust control theory. Can control theory help?
First of all, we should ﬁnd a way to reasonably conﬁne our signal class to a more
realistic class than perfectly band-limited functions.
Second, we should be able to set up a design block diagram that allows us to handle
error signals. This will raise a problem, since we do not have the original signal to be
compared with.
It is certainly not possible to measure a particular incoming signal. However, it is
possible to conceive that a class of signals are fed into our digital ﬁlter to be designed,
and consider the class of ﬁctitious errors against all such signals. Suppose we have
taken a class of functions L, and let f be a signal in this class.
As a ﬁrst step, consider the following abstract problem:
Consider f ∈L and sample it with sampling period h to obtain Sf. Design a
digital ﬁlter K such that, with a suitable hold device H, the error f −HKSf
is as small as possible.
This is meaningless if we do not know f, but we can still discuss the family of errors
corresponding to all such f. That is, we consider the worst case error gain:

350
Y. Yamamoto
sup
f∈L,f̸=0
∥f −HKSf∥
∥f∥
(3)
and require that it be minimized. We are here not concerned with an individual f, but
rather the worst case amongst all such f ∈L. Hence this is not a problem of minimizing
the error for each speciﬁc (but unknown) signal but rather a problem formulated for the
class L. The disadvantage of unavailability of the error now disappears.
Of course, this abstract meta-problem is not guaranteed to be feasible. A remarkable
accomplishment of modern sampled-data control theory is that this type of problem is
solvable for a suitably deﬁned class L, in particular for L2.
Let us now present a more concrete formulation. Consider, for example, the FFT
(fast Fourier transform) readout of an orchestral music piece shown in Fig. 3. As this
graph shows, the lower frequency range has more energy while the high frequency
slowly decays. Suppose for the moment that this decay is governed by a proper rational
function F(s), and we take as L the set of all L2 functions that are semi-band-limited
by the decay curve governed by F(s).
Fig. 3. FFT Bode plot of an orchestral music piece
Depending on each input signal, the output of F(s) varies, but its high frequency de-
cay is governed by F(s). This analog signal is then sampled, and stored or transmitted
as digital data. In CD this will be the recorded digital signal. The objective is to recover
the original analog signal.
Let us express the signal reconstruction process in this process, allowing some
amount of delay in the form of Fig. 4.
The block diagram 4 says the following: the external signal wc ∈L2 is band-limited
by going through the analog low-pass ﬁlter F(s). As already noted, F(s) is not an
ideal ﬁlter and hence its bandwidth distributes beyond the Nyquist frequency. One can
interpret F(s) as a musical instrument, and wc a driving signal. The obtained signal is
sampled by the sampler Sh and becomes a digital signal. The objective here is how we
can recover the original analog signal yc as closely as possible. To make this possible,
one needs to take a faster sampling period: the upsampler ↑L makes the sampling
period h/L by inserting L −1 zeros between the original sampled points. The digital
ﬁlter K(z) is the one to be designed. The processed discrete-time signal then goes

Digital Signal Processing Via Sampled-Data Control Theory
351
-
6
?
-
-
-
-
-
-
-
e−mhs
F(s)
Sh
↑L
K(z)
Hh/L
P(s)
−
+
ec
wc
yc
Fig. 4. Error system of a sampled-data design ﬁlter
through the hold device Hh/L and becomes a continuous-time signal. It is then further
processed by an analog low-pass ﬁlter P(s) to become the ﬁnal analog output. This is
the process of the lower part of the diagram. The design objective here is to make the
difference between this output and the original analog signal yc as small as possible.
Since the processing via this digital ﬁlter inevitably induces a certain amount of delay,
it is reasonable to compare the processed signal with delayed original signal e−mhsyc,
rather than yc itself. This is the idea of Fig. 4.
As a performance index, we take the L2 induced norm from wc to ec (or the sampled-
data H∞norm):
J :=
sup
wc∈L2,wc̸=0
∥ec∥2
∥wc∥2
(4)
Then this problem becomes a sampled-data H∞control problem. A problem here is
that the delay here makes the problem inﬁnite-dimensional, but it can be suitably ap-
proximated by the fast-sample/fast-hold approximation method [11,10].) Characteristic
features here are
1. we can explicitly deal with the error signal ec by setting up a class of input signals,
and
2. the formulated problem is a sampled-data control problem, which is already known
to be solvable.
For the solution of this problem, see [1,3,10,11,12], etc.
As we have noted already, the ﬁrst point was not explicitly discussed previously,
partly obscured by the perfect band-limiting assumption. Only by the procedure above,
one can explicitly discuss the error and its performance level. It is exactly the second
feature that enables us to solve the ﬁltering problem that optimizes analog character-
istics. The advantage of this feature cannot be more emphasized, because the current
digital signal processing techniques can deal only with discrete-time problems, sup-
ported mainly by the ﬁction of the perfect band-limiting assumption.
Fig. 5 now shows the response to a square wave of a ﬁlter designed by the method
here. We see that the Gibbs phenomenon is reduced to the minimum.
This can be applied to varied areas such as sound compression, sample-rate con-
version etc. In sound compression, the bandwidth is often limited to a rather narrow
range (e.g., only up to 12kHz), and this technique makes it possible to expand this to
the original range by upsampling and ﬁltering. This is patented [8,9] and already being
marketed as sound processing LSI chips by Sanyo Semiconductors, and used in mobile
phones and MP3 players; their cumulative total exceeds 2 million chips so far.

352
Y. Yamamoto
0
5
10
15
−1.5
−1
−0.5
0
0.5
1
1.5
Fig. 5. Response of a sampled-data design ﬁlter against a square wave
5
Application to Images
The same idea can be applied to images. However, since images are two-dimensional,
we should be careful about how our (essentially) one-dimensional method can be ap-
plied. There is no universal recipe for this, and the simplest is to apply this in two steps:
ﬁrst in the horizontal direction, save the temporary data in buffer memories, and then
process in the vertical direction.
Fig. 6. The center of the Lena image

Digital Signal Processing Via Sampled-Data Control Theory
353
Fig. 7. Lena twice downsampled
Fig. 8. Midpoint interpolation of Fig. 7
We can interpolate lost intersample data by the present framework. For example,
take the well-known sample picture of Lena, Fig. 6. The next picture Fig. 7 shows its
twice downsampled4 (and degraded) image.
To recover the original resolution, we ﬁrst upsample by the factor of 2. An obvious
idea is to take the midpoint interpolation. This leads to the result of Fig. 8. However, the
processed image still has jaggy boundaries, and the pupils look totally different from the
4 I.e., decimated once every two points.

354
Y. Yamamoto
Fig. 9. Lena (via sampled-data ﬁlter)
original image. On the other hand, the sampled-data ﬁlter designed with a second order
F(s) resulted in Fig. 9. It is interesting to observe that some high frequency components
are well interpolated around the pupils and the nose, and show a much smoother image.
This is precisely the effect of interpolation beyond the Nyquist frequency.
6
Concluding Remarks and Related Work
We have shown a basic idea of applying sampled-data control theory to digital signal
processing. While this is a very natural idea in that it enables us to interpolate the in-
tersample behavior optimally, it also raises a fundamental difﬁculty in that reference
(target) signals are not available. The key here is to set up a class of signals we want to
track or reconstruct, and sampled-data H∞control theory provides an ideal framework
for this purpose. That is, F(s) in Fig. 4 models the high frequency roll-off, and consid-
ering all L2 inputs to F(s), one can discuss the possible error signals ec derived out of
this framework. This point has been quite implicit, or not even considered at all, in the
digital signal processing literature.
Let us make a few remarks on related work. Chen and Francis [2] gave a ﬁrst effort
on applying sampled-data theory to signal processing, but as a discrete-time problem.
The present author and co-workers have pursued the idea presented in this article in a
number of papers; see, e.g., [3,4,8,9,12].
What does this theory suggest on signals and noise? As we see from the FFT Bode
plot Fig. 3, the ﬂuctuations are quite large in signals we process. We did not assume a
noise model in our problem setting Fig. 4; instead, we have assumed an a priori energy
decay curve governed by F(s) there. In a sense, ﬂuctuations from this assumption may
be regarded as “noise.” I hope that this would provide an auxiliary viewpoint on noise
and signals, from a deterministic point of view.

Digital Signal Processing Via Sampled-Data Control Theory
355
References
1. Chen T., Francis B. A. (1995) Optimal Sampled-Data Control Systems. Springer, Berlin
Heidelberg New York
2. Chen T., Francis B. A. (1995) Design of multirate ﬁlter banks by H∞opimization. IEEE
Trans. Signal ProcessingSP-43: 2822–2830
3. Khargonekar P. P., Yamamoto Y. (1996) Delayed signal reconstruction using sampled-data
control. Proc. 35th IEEE CDC: 1259–1263
4. Nagahara M., Yamamoto Y. (2000) A new design for sample-rate converters. Proc. 39th
IEEE CDC: 4296–4301
5. Oohashi T., et al. (2000) Inaudible high-frequency sounds affect brain activity: hypersonic
effect. Proc. Amer. Phisiological Soc.: 3548–3558
6. Shannon C. E. (1949) Communication in the presence of noise. Proc. IRE 37-1: 10-21; also
reprinted in (1998) Proc. IEEE 447–457
7. Unser M. (2000) Sampling—50 years after Shannon. Proc. IEEE 88-4: 569–587
8. Yamamoto Y. (2006) Digital/analog converters and design method for pertinent ﬁlters.
Japanese patent No. 3820331
9. Yamamoto Y. (2006) Sample-rate converters. Japanese patent No. 3851757
10. Yamamoto Y., Anderson B. D. O., Nagahara M. (2002) Approximating sampled-data sys-
tems with applications to digital redesign. Proc. 41st IEEE CDC: 3724–3729
11. Yamamoto Y., Madievski A. G., Anderson B. D. O. (1999) Approximation of frequency
response for sampled-data control systems. Automatica: 35-4: 729-734
12. Yamamoto Y., Nagahara M., Fujioka H. (2000) Multirate signal reconstruction and ﬁlter
design via sampled-data H∞control. Proc. MTNS 2000, Perpgnan, France
13. Zayed A. I. (1996) Advances in Shannon’s Sampling Theory. CRC Press, Boca Raton

Lecture Notes in Control and Information Sciences
Edited by M. Thoma, M. Morari
Further volumes of this series can be found on our homepage:
springer.com
Vol. 364: Chiuso A.; Ferrante A.;
Pinzoni S. (Eds.)
Modeling, Estimation and Control
356 p. 2007 [978-3-540-73569-4]
Vol. 363: Besançon G. (Ed.)
Nonlinear Observers and Applications
250 p. 2007 [978-3-540-73502-1]
Vol. 362: Tarn T.-J.; Chen S.-B.;
Zhou C. (Eds.)
Robotic Welding, Intelligence and Automation
562 p. 2007 [978-3-540-73373-7]
Vol. 361: Méndez-Acosta H.O.; Femat R.;
González-Álvarez V. (Eds.):
Selected Topics in Dynamics and Control of
Chemical and Biological Processes
320 p. 2007 [978-3-540-73187-0]
Vol. 360: Kozlowski K. (Ed.)
Robot Motion and Control 2007
452 p. 2007 [978-1-84628-973-6]
Vol. 359: Christophersen F.J.
Optimal Control of Constrained
Piecewise Afﬁne Systems
190 p. 2007 [978-3-540-72700-2]
Vol. 358: Findeisen R.; Allgöwer F.;
Biegler L.T. (Eds.):
Assessment and Future Directions of Nonlinear
Model Predictive Control
642 p. 2007 [978-3-540-72698-2]
Vol. 357: Queinnec I.; Tarbouriech
S.; Garcia G.; Niculescu S.-I. (Eds.):
Biology and Control Theory: Current Challenges
589 p. 2007 [978-3-540-71987-8]
Vol. 356: Karatkevich A.:
Dynamic Analysis of Petri Net-Based Discrete
Systems
166 p. 2007 [978-3-540-71464-4]
Vol. 355: Zhang H.; Xie L.:
Control and Estimation of Systems with
Input/Output Delays
213 p. 2007 [978-3-540-71118-6]
Vol. 354: Witczak M.:
Modelling and Estimation Strategies for Fault
Diagnosis of Non-Linear Systems
215 p. 2007 [978-3-540-71114-8]
Vol. 353: Bonivento C.; Isidori A.; Marconi L.;
Rossi C. (Eds.)
Advances in Control Theory and Applications
305 p. 2007 [978-3-540-70700-4]
Vol. 352: Chiasson, J.; Loiseau, J.J. (Eds.)
Applications of Time Delay Systems
358 p. 2007 [978-3-540-49555-0]
Vol. 351: Lin, C.; Wang, Q.-G.; Lee, T.H., He, Y.
LMI Approach to Analysis and Control of
Takagi-Sugeno Fuzzy Systems with Time Delay
204 p. 2007 [978-3-540-49552-9]
Vol. 350: Bandyopadhyay, B.; Manjunath, T.C.;
Umapathy, M.
Modeling, Control and Implementation of
Smart Structures
250 p. 2007 [978-3-540-48393-9]
Vol. 349: Rogers, E.T.A.; Galkowski, K.;
Owens, D.H.
Control Systems Theory
and Applications for Linear
Repetitive Processes
482 p. 2007 [978-3-540-42663-9]
Vol. 347: Assawinchaichote, W.; Nguang, K.S.;
Shi P.
Fuzzy Control and Filter Design
for Uncertain Fuzzy Systems
188 p. 2006 [978-3-540-37011-6]
Vol. 346: Tarbouriech, S.; Garcia, G.; Glattfelder,
A.H. (Eds.)
Advanced Strategies in Control Systems
with Input and Output Constraints
480 p. 2006 [978-3-540-37009-3]
Vol. 345: Huang, D.-S.; Li, K.; Irwin, G.W. (Eds.)
Intelligent Computing in Signal Processing
and Pattern Recognition
1179 p. 2006 [978-3-540-37257-8]
Vol. 344: Huang, D.-S.; Li, K.; Irwin, G.W. (Eds.)
Intelligent Control and Automation
1121 p. 2006 [978-3-540-37255-4]
Vol. 341: Commault, C.; Marchand, N. (Eds.)
Positive Systems
448 p. 2006 [978-3-540-34771-2]
Vol. 340: Diehl, M.; Mombaur, K. (Eds.)
Fast Motions in Biomechanics and Robotics
500 p. 2006 [978-3-540-36118-3]
Vol. 339: Alamir, M.
Stabilization of Nonlinear Systems Using
Receding-horizon Control Schemes
325 p. 2006 [978-1-84628-470-0]
Vol. 338: Tokarzewski, J.
Finite Zeros in Discrete Time Control Systems
325 p. 2006 [978-3-540-33464-4]

Vol. 337: Blom, H.; Lygeros, J. (Eds.)
Stochastic Hybrid Systems
395 p. 2006 [978-3-540-33466-8]
Vol. 336: Pettersen, K.Y.; Gravdahl, J.T.;
Nijmeijer, H. (Eds.)
Group Coordination and Cooperative Control
310 p. 2006 [978-3-540-33468-2]
Vol. 335: Kozłowski, K. (Ed.)
Robot Motion and Control
424 p. 2006 [978-1-84628-404-5]
Vol. 334: Edwards, C.; Fossas Colet, E.;
Fridman, L. (Eds.)
Advances in Variable Structure and Sliding Mode
Control
504 p. 2006 [978-3-540-32800-1]
Vol. 333: Banavar, R.N.; Sankaranarayanan, V.
Switched Finite Time Control of a Class of
Underactuated Systems
99 p. 2006 [978-3-540-32799-8]
Vol. 332: Xu, S.; Lam, J.
Robust Control and Filtering of Singular Systems
234 p. 2006 [978-3-540-32797-4]
Vol. 331: Antsaklis, P.J.; Tabuada, P. (Eds.)
Networked Embedded Sensing and Control
367 p. 2006 [978-3-540-32794-3]
Vol. 330: Koumoutsakos, P.; Mezic, I. (Eds.)
Control of Fluid Flow
200 p. 2006 [978-3-540-25140-8]
Vol. 329: Francis, B.A.; Smith, M.C.; Willems,
J.C. (Eds.)
Control of Uncertain Systems: Modelling,
Approximation, and Design
429 p. 2006 [978-3-540-31754-8]
Vol. 328: Loría, A.; Lamnabhi-Lagarrigue, F.;
Panteley, E. (Eds.)
Advanced Topics in Control Systems Theory
305 p. 2006 [978-1-84628-313-0]
Vol. 327: Fournier, J.-D.; Grimm, J.; Leblond, J.;
Partington, J.R. (Eds.)
Harmonic Analysis and Rational Approximation
301 p. 2006 [978-3-540-30922-2]
Vol. 326: Wang, H.-S.; Yung, C.-F.; Chang, F.-R.
H∞Control for Nonlinear Descriptor Systems
164 p. 2006 [978-1-84628-289-8]
Vol. 325: Amato, F.
Robust Control of Linear Systems Subject to
Uncertain
Time-Varying Parameters
180 p. 2006 [978-3-540-23950-5]
Vol. 324: Christoﬁdes, P.; El-Farra, N.
Control of Nonlinear and Hybrid Process Systems
446 p. 2005 [978-3-540-28456-7]
Vol. 323: Bandyopadhyay, B.; Janardhanan, S.
Discrete-time Sliding Mode Control
147 p. 2005 [978-3-540-28140-5]
Vol. 322: Meurer, T.; Graichen, K.; Gilles, E.D.
(Eds.)
Control and Observer Design for Nonlinear Finite
and Inﬁnite Dimensional Systems
422 p. 2005 [978-3-540-27938-9]
Vol. 321: Dayawansa, W.P.; Lindquist, A.;
Zhou, Y. (Eds.)
New Directions and Applications in Control
Theory
400 p. 2005 [978-3-540-23953-6]
Vol. 320: Steffen, T.
Control Reconﬁguration of Dynamical Systems
290 p. 2005 [978-3-540-25730-1]
Vol. 319: Hofbaur, M.W.
Hybrid Estimation of Complex Systems
148 p. 2005 [978-3-540-25727-1]
Vol. 318: Gershon, E.; Shaked, U.; Yaesh, I.
H∞Control and Estimation of State-multiplicative
Linear Systems
256 p. 2005 [978-1-85233-997-5]
Vol. 317: Ma, C.; Wonham, M.
Nonblocking Supervisory Control of State Tree
Structures
208 p. 2005 [978-3-540-25069-2]
Vol. 316: Patel, R.V.; Shadpey, F.
Control of Redundant Robot Manipulators
224 p. 2005 [978-3-540-25071-5]
Vol. 315: Herbordt, W.
Sound Capture for Human/Machine Interfaces:
Practical Aspects of Microphone Array
Signal Processing
286 p. 2005 [978-3-540-23954-3]
Vol. 314: Gil’, M.I.
Explicit Stability Conditions for
Continuous Systems
193 p. 2005 [978-3-540-23984-0]
Vol. 313: Li, Z.; Soh, Y.; Wen, C.
Switched and Impulsive Systems
277 p. 2005 [978-3-540-23952-9]
Vol. 312: Henrion, D.; Garulli, A. (Eds.)
Positive Polynomials in Control
313 p. 2005 [978-3-540-23948-2]
Vol. 311: Lamnabhi-Lagarrigue, F.; Loría, A.;
Panteley, E. (Eds.)
Advanced Topics in Control Systems Theory
294 p. 2005 [978-1-85233-923-4]
Vol. 310: Janczak, A.
Identiﬁcation of Nonlinear Systems Using Neural
Networks and Polynomial Models
197 p. 2005 [978-3-540-23185-1]

