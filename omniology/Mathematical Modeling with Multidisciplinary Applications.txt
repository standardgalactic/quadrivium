
Mathematical Modeling with 
Multidisciplinary Applications 

Mathematical Modeling with 
Multidisciplinary Applications 
Edited by 
Xin-She Yang 
School of Science and Technology 
Middlesex University 
United Kingdom 
Mathematics and Scientific Computing 
National Physical Laboratory 
United Kingdom 
)WILEY 
A JOHN WILEY & SONS, INC., PUBLICATION 

Cover Image: © diane555/iStockphoto 
Copyright © 2013 by John Wiley & Sons, Inc. All rights reserved. 
Published by John Wiley & Sons, Inc., Hoboken, New Jersey. 
Published simultaneously in Canada. 
No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or 
by any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as 
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior 
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to 
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax 
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should 
be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 
07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permission. 
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in 
preparing this book, they make no representation or warranties with respect to the accuracy or 
completeness of the contents of this book and specifically disclaim any implied warranties of 
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales 
representatives or written sales materials. The advice and strategies contained herein may not be 
suitable for your situation. You should consult with a professional where appropriate. Neither the 
publisher nor author shall be liable for any loss of profit or any other commercial damages, including 
but not limited to special, incidental, consequential, or other damages. 
For general information on our other products and services please contact our Customer Care 
Department within the United States at (800) 762-2974, outside the United States at (317) 572-3993 or 
fax (317) 572-4002. 
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print, 
however, may not be available in electronic formats. For more information about Wiley products, visit 
our web site at www.wiley.com. 
Library of Congress Cataloging-in-Publication Data: 
Yang, Xin-She. 
Mathematical modeling with multidisciplinary applications / Xin-She Yang. 
pages cm 
Includes bibliographical references and index. 
ISBN 978-1-118-29441-3 
1. Differential equations. 2. Mathematical models. I. Title. 
QA371.Y28 2013 
510.Γ1—dc23 
2012020899 
Printed in the United States of America. 
10 9 8 7 6 5 4 3 2 1 

CONTENTS 
List of Figures 
xv 
Preface 
xxiii 
Acknowledgments 
xxvii 
Editor and Contributors 
xxix 
PART I 
INTRODUCTION AND FOUNDATIONS 
1 
Differential Equations 
3 
Xin-She Yang 
1.1 
Ordinary Differential Equations 
4 
1.1.1 
First-Order ODEs 
5 
1.1.2 
Higher-Order ODEs 
6 
1.1.3 
Linear System 
8 
1.1.4 
Sturm-Liouville Equation 
8 
1.2 
Partial Differential Equations 
10 
1.2.1 
First-Order PDEs 
11 
1.2.2 
Classification of Second-Order PDEs 
12 
1.3 
Classic Mathematical Models 
12 
1.4 
Other Mathematical Models 
14 
v 

CONTENTS 
1.5 
Solution Techniques 
15 
1.5.1 
Separation of Variables 
15 
1.5.2 
Laplace Transform 
18 
1.5.3 
Similarity Solution 
19 
1.5.4 
Change of Variables 
20 
Exercises 
21 
Mathematical Modeling 
23 
Xin-She Yang 
2.1 
Mathematical Modeling 
23 
2.2 
Model Formulation 
25 
2.3 
Parameter Estimation 
28 
2.4 
Mathematical Models 
31 
2.4.1 
Differential Equations 
31 
2.4.2 
Functional and Integral Equations 
36 
2.4.3 
Statistical Models 
36 
2.4.4 
Rule-based Models 
40 
2.5 
Numerical Methods 
40 
2.5.1 
Numerical Integration 
40 
2.5.2 
Numerical Solutions of PDEs 
41 
Exercises 
43 
Numerical Methods: An Introduction 
45 
Xin-She Yang 
3.1 
Direct Integration 
46 
3.1.1 
Euler Scheme 
46 
3.1.2 
Leap-Frog Method 
47 
3.1.3 
Runge-Kutta Method 
48 
3.2 
Finite Difference Methods 
49 
3.2.1 
Hyperbolic Equations 
50 
3.2.2 
Second-Order Wave Equation 
51 
3.2.3 
Parabolic Equation 
52 
3.2.4 
Elliptical Equation 
54 
Exercises 
55 
Teaching Mathematical Modeling in Teacher Education: Efforts 
and Results 
57 
Thomas Lingefjärd 
vi
2
3
4

CONTENTS 
VÜ 
4.1 
Introduction 
57 
4.2 
Theoretical Frameworks Connected to Mathematical 
Modeling 
60 
4.2.1 
Instrumental Competence 
61 
4.2.2 
The Importance of Variation 
63 
4.3 
Mathematical Modeling Tasks 
64 
4.4 
Conclusions 
77 
Exercises 
77 
PART II 
MATHEMATICAL MODELING WITH 
MULTIDISCIPLINARY APPLICATIONS 
5 
Industrial Mathematics with Applications 
83 
Alfredo Bermudez and Luz M. Garcia Garcia 
5.1 
Industrial Mathematics 
84 
5.2 
Numerical Simulation of Metallurgical Electrodes 
84 
5.2.1 
The Industrial Problem: Metallurgy of Silicon 
84 
5.2.2 
Mathematical Modeling 
88 
5.2.3 
Numerical Solution 
95 
5.2.4 
Numerical Results 
98 
5.3 
Numerical Simulation of Pit Lake Water Quality 
99 
5.3.1 
Introduction to the Problem 
99 
5.3.2 
A Stirred Tank Model to Predict Pit Lake Water 
Quality 
102 
5.3.3 
Mathematical Models for Chemical Reaction 
Systems 
106 
5.3.4 
Numerical Solution of the Model 
115 
5.3.5 
Numerical Results: A Simplified Chemical 
Problem. 
116 
Exercises 
120 
6 
Binary and Ordinal Data Analysis in Economics: Modeling and 
Estimation 
123 
Ivan Jeliazkov and Mohammad Arshad Rahman 
6.1 
Introduction 
123 
6.2 
Theoretical Foundations 
124 
6.2.1 
Binary Outcomes 
125 
6.2.2 
Ordinal Outcomes 
129 
6.3 
Estimation 
132 

viii 
CONTENTS 
6.3.1 
Maximum Likelihood Estimation 
132 
6.3.2 
Bayesian Estimation 
135 
6.3.3 
Marginal Effects 
143 
6.4 
Applications 
145 
6.4.1 
Women's Labor Force Participation 
145 
6.4.2 
An Ordinal Model of Educational Attainment 
146 
6.5 
Conclusions 
147 
Exercises 
148 
Inverse Problems in ODEs 
151 
H. Kunze and D. La Torre 
7.1 
Banach's Fixed Point Theorem & The Collage Theorem 
152 
7.2 
Existence-Uniqueness of Solutions to Initial Value 
Problems 
157 
7.3 
Solving Inverse Problems for ODEs 
160 
Exercises 
166 
References 
167 
Estimation of Model Parameters 
169 
Robert Piche 
8.1 
Estimation is an Inverse Problem 
169 
8.2 
The Multivariate Normal Distribution 
171 
8.3 
Model of Observations 
174 
8.3.1 
Deterministic Model and its Linearization 
174 
8.3.2 
Probabilistic Model 
177 
8.4 
Estimation 
178 
8.4.1 
Bayesian Inference 
178 
8.4.2 
Moment Matching 
178 
8.4.3 
Estimation by Optimization 
184 
8.5 
Conclusion 
188 
Exercises 
189 
Linear and Nonlinear Parabolic Partial Differential Equations in 
Financial Engineering 
191 
L. A. Boukas, K. I. Vasileiadis, S. Z. Xanthopoulos, A. N. Yannacopoulos 
9.1 
Financial Derivatives 
191 
9.2 
Motivation for a Model for the Price of Stocks 
194 
9.3 
Stock Prices Involving the Wiener Process 
195 
7
8
9

CONTENTS 
IX 
9.4 
Connection Between the Wiener Process and PDEs 
199 
9.5 
The Black-Scholes-Merton Equation 
201 
9.6 
Solution of the Black-Scholes-Merton Equation 
203 
9.7 
Free Boundary-Value Problems 
204 
9.8 
The Hamilton-Jacobi-Bellman Equation 
208 
9.8.1 
The Hamilton-Jacobi-Bellman Equation 
211 
9.8.2 
An Explicitly Worked Example 
216 
9.8.3 
Viscosity Solutions 
218 
9.9 
Numerical Methods 
220 
9.9.1 
The Crank-Nicholson Method 
220 
9.9.2 
Numerical Treatment of Variational Inequalities 
224 
9.9.3 
Numerical Treatment of HJB Equations 
225 
9.10 
Conclusion 
226 
Exercises 
226 
10 
Decision Modeling in Supply Chain Management 
229 
Huajun Tang 
10.1 
Introduction to Decision Modeling 
229 
10.1.1 The Origin of Decision Modeling 
229 
10.1.2 
Definition of Decision Modeling 
230 
10.1.3 Data in Decision Modeling 
230 
10.1.4 
Role of Spreadsheets in Decision Modeling 
230 
10.1.5 Types of Decision Models 
231 
10.1.6 
Steps of Decision Modeling 
231 
10.2 
Mathematical Programming Models 
234 
10.2.1 Introduction of Linear Programming Models 
234 
10.2.2 
Properties of a Linear Programming Model 
234 
10.2.3 Assumptions of a Linear Programming Model 
235 
10.2.4 
Other Mathematical Programming Models 
236 
10.3 
Introduction of Supply Chain Management 
236 
10.3.1 Importance of Supply Chain Management 
237 
10.3.2 
Activities in Supply Chain Management 
238 
10.4 
Applications in Supply Chain Management 
238 
10.4.1 Manufacturing Applications 
238 
10.4.2 
Transportation Applications 
242 
10.4.3 Assignment Applications 
248 
10.5 
Summary 
252 
Exercises 
253 

X 
CONTENTS 
11 
Modeling Temperature for Pricing Weather Derivatives 
257 
Fred Espen Benth 
11.1 
Introduction 
257 
11.2 
Stochastic Temperature Modeling 
259 
11.2.1 Simple Stochastic Mean Reverting Processes 
261 
11.3 
Continuous-Time Autoregressive Processes 
267 
11.3.1 An Empirical Study 
274 
11.4 
Pricing of Temperature Futures Contracts 
277 
Exercises 
283 
12 
Decision Theory under Risk and Applications in Social Sciences: 
I. Individual Decision Making 
285 
E. V. Petracou and A. N. Yannacopoulos 
12.1 
Introduction 
285 
12.2 
The Fundamental Framework 
286 
12.3 
A Brief Introduction to Theory of Choice 
290 
12.4 
Collective Choice 
292 
12.5 
Preferences Under Uncertainty 
293 
12.6 
Decisions Over Time 
299 
12.7 
The Problem of Aggregation 
301 
12.7.1 Aggregation of Time Preferences 
301 
12.7.2 
Aggregation of Beliefs 
303 
12.8 
Conclusion 
304 
Exercises 
305 
13 
Fractals, with Applications to Signal and Image Modeling 
307 
H. Kunze and D. La Torre 
13.1 
Iterated Function Systems 
308 
13.2 
Fractal Dimension 
310 
13.3 
More on the Definition of Iterated Function System 
312 
13.4 
The Chaos Game 
314 
13.5 
An Application to Image Analysis 
320 
References 
327 
14 
Efficient Numerical Methods for Singularly Perturbed Differential 
Equations 
329 
S. Natesan 

CONTENTS 
XI 
14.1 
Introduction 
329 
14.2 
Characterization of SPPs 
331 
14.3 
Numerical Approximate Solution 
333 
14.3.1 Failure of Classical Finite Difference Schemes on 
Uniform Meshes 
333 
14.3.2 
Exponentially Fitted Difference Scheme 
335 
14.4 
SPPs Arising in Chemical Reactor Theory 
337 
14.4.1 Initial-Value Technique 
338 
14.4.2 
Boundary-Value Technique 
340 
14.4.3 
Shooting Method 
343 
14.4.4 
Booster Method 
345 
14.4.5 
Semilinear Problems 
347 
14.5 
Layer-Adapted Nonuniform Meshes 
349 
14.5.1 Bakhvalov Meshes 
349 
14.5.2 
Shishkin Meshes 
350 
14.5.3 Equidistribution Meshes 
351 
PART III 
ADVANCED MODELING TOPICS 
15 
Fractional Calculus and its Applications 
357 
Ivo Petras 
15.1 
Introduction 
357 
15.2 
Fractional Calculus Fundamentals 
359 
15.2.1 
Special Functions 
359 
15.2.2 
Definitions of Fractional Operator 
359 
15.2.3 
Grünwald-Letnikov Fractional Derivatives 
360 
15.2.4 
Riemann-Liouville Fractional Derivatives 
360 
15.2.5 
Caputo Fractional Derivatives 
360 
15.2.6 
Laplace Transform Method 
361 
15.2.7 
Some Properties of Fractional Calculus 
361 
15.2.8 
Numerical Methods for Fractional Calculus 
362 
15.3 
Fractional-Order Systems and Controllers 
370 
15.3.1 Fractional LTI Systems 
370 
15.3.2 
Fractional Nonlinear Systems 
373 
15.3.3 
Fractional-Order Controllers 
373 
15.4 
Stability of Fractional-Order Systems 
374 
15.4.1 
Stability of Fractional LTI Systems 
379 
15.4.2 
Stability of Fractional Nonlinear Systems 
382 
15.5 
Applications of Fractional Calculus 
385 

CONTENTS 
15.5.1 Control of Electrical Heater 
385 
15.5.2 
Memristor-Based Chua's Circuit 
387 
15.5.3 Viscoelastic Models of Cells 
391 
Exercises 
393 
The Goal Programming Model: Theory and Applications 
397 
Belaid Aouni, Cinzia Colapinto, and Davide La Torre 
16.1 
Multi-Criteria Decision Aid 
397 
16.2 
The Goal Programming Model 
399 
16.3 
Scenario-based Goal Programming 
402 
16.4 
Applications 
404 
16.4.1 A Goal Programming Model for Portfolio Selection 404 
16.4.2 
A Goal Programming Model for Media 
Management and Planning 
407 
16.4.3 A Goal Programming Model for Site Selection 
410 
16.4.4 
A Goal Programming Model for the Next Release 
Problem 
412 
Exercises 
416 
Decision Theory under Risk and Applications in Social Sciences: 
II. Game Theory 
421 
E. V. Petracou and A. N. Yannacopoulos 
17.1 
Introduction 
421 
17.2 
Best Replies and Nash Equilibria 
422 
17.3 
Mixed Strategies and Minimax 
428 
17.4 
Nash Equilibria and Conservative Strategies 
430 
17.5 
Zero-Sum Games and the Minimax Theorem 
432 
17.6 
Nash Equilibria for Mixed Strategies 
438 
17.7 
Cooperative Games 
440 
17.8 
Conclusion 
446 
Exercises 
446 
Control Problems on Differential Equations 
449 
Chuang Zheng 
18.1 
Introduction 
449 
18.2 
Ordinary Differential Equations 
451 
18.2.1 Model Formulation 
451 
18.2.2 
Controllability 
454 
xii
16
17
18

CONTENTS 
xiii 
18.2.3 Kalman's Rank Condition 
457 
18.3 
Partial Differential Equations 
460 
18.3.1 Model Formulation 
460 
18.3.2 
Controllability 
463 
18.3.3 Adjoint System and Observability 
465 
Exercises 
469 
19 
Markov-Jump Stochastic Models for Tropical Convection 
471 
Boualem Khouider 
19.1 
Introduction 
471 
19.2 
Random Numbers: Theory and Simulations 
475 
19.2.1 Random Variables 
475 
19.2.2 
Mean, Variance, and Expectation 
478 
19.2.3 
Conditional Probability 
479 
19.2.4 
Law of Large Numbers 
480 
19.2.5 
Monte Carlo Integration 
481 
19.2.6 
Inverse Transform Method 
483 
19.2.7 Acceptance-Rejection Method 
485 
19.3 
Markov Chains and Birth-Death Processes 
486 
19.3.1 Discrete-Time Markov Chains 
487 
19.3.2 
The Poisson Process 
489 
19.3.3 
Continuous-Time Markov Chains 
491 
19.4 
A Birth-Death Process for Convective Inhibition 
495 
19.4.1 The Microscopic Stochastic Model for CIN: Ising 
Model 
495 
19.4.2 
The Coarse-Grained Mesoscopic Stochastic Model: 
Birth-Death Process 
499 
19.4.3 Acceptance-Rejection Algorithm for the Birth-
Death Markov Process 
502 
19.4.4 
Gillespie's Exact Algorithm 
503 
19.4.5 Numerical Tests 
503 
19.5 
A Birth-Death Process for Cloud-Cloud Interactions 
504 
19.5.1 The Stationary Distribution, Cloud Area 
Fractions, and the Equilibrium Statistics of the 
Lattice Model 
510 
19.5.2 
Coarse-Grained Birth-Death Stochastic Model 
and the Mean-Field Equations 
512 

xiv 
CONTENTS 
19.5.3 The Deterministic Mean-Field Equations and 
Numerical Simulations 
516 
19.6 
Further Reading 
517 
Exercises 
519 
Problem Solutions 
525 
Index 
555 

LIST OF FIGURES 
1.1 
Flow through a pipe under pressure gradient. 
10 
2.1 
Mathematical modeling. 
24 
2.2 
Representative element volume (REV). 
26 
2.3 
Settling velocity of a spherical particle. 
31 
2.4 
Heat transfer through a semi-infinite medium near a dyke in 
geology. 
34 
2.5 
Distribution of u(x, t)/uo with κ = 0.25. 
35 
2.6 
Random walk and the path of 100 consecutive steps staring at 
position 0. 
38 
2.7 
Brownian motion in 2D: random walk with a Gaussian step-size 
distribution and the path of 100 steps starting at the origin 
(0,0) (marked with ·). 
39 
2.8 
Naive numerical integration. 
42 
2.9 
Pattern formation of reaction-diffusion equation (2.45) 
43 
xv 

XVI 
LIST OF FIGURES 
3.1 
First-order hyperbolic equation and its traveling wave solution 
ut + ux = 0. 
51 
3.2 
Traveling wave solution of the wave equation: utt — c2uxx = 0. 
52 
3.3 
The ID time-dependent diffusion equation: ut — KUXX = 0. 
53 
5.1 
Silicon production. 
86 
5.2 
The ELSA electrode. 
87 
5.3 
Sketch of a reduction furnace. 
88 
5.4 
Sketch of domain Ω. 
90 
5.5 
Boundary conditions: a) electromagnetic; b) thermal. 
92 
5.6 
Flow chart of the algorithm. 
99 
5.7 
Temperature evolution. 
100 
5.8 
Temperature in clamp's zone. 
101 
5.9 
Real part of current density. 
101 
5.10 
Heat released by the Joule effect. 
102 
5.11 
Stirred tank conceptual model. 
103 
5.12 
Functions H(x) and Ηχ(χ) 
112 
5.13 
Functions Q{x) and G\{x) 
114 
5.14 
Flow diagram for the iterative algorithm. 
117 
5.15 
Time evolution of: A: concentration of Fe2+, 
B: 
concentration of Fe3+ and C: pH. 
120 
6.1 
Log-densities for the standard normal, scaled logistic and 
Student's t with 4 degrees of freedom. 
129 
6.2 
Outcome probabilities in an ordinal data model. 
130 
6.3 
Parameter identification in ordinal data models. 
131 
6.4 
Behavior of the density f{ni\zi,ß) 
relative to /κ{κί)- 
142 
7.1 
A contractive map T moves points closer together. 
154 
7.2 
Banach's Theorem: Repeated iteration of T takes us to its 
fixed point. 
156 
7.3 
Collage Theorem: The true error can be controlled by the 
collage distance. 
157 

LIST OF FIGURES 
xvii 
7.4 
Target solutions for the Lotka-Volterra system 
165 
8.1 
Mathematical model seen as a system with inputs 
(parameters) and outputs (observations). 
170 
8.2 
Geometry of positioning by triangulation 
176 
8.3 
Geometry of the triangulation problem 
182 
8.4 
Position estimated by triangulation. The headings are 
shown as lines from the (distant) landmarks; the large 
ellipse centered at m[l] is the 95% ellipse for the position 
estimate based on the first two headings; the small ellipse 
centered at m[2] is the 95% ellipse for the position estimate 
based on all three headings. 
184 
8.5 
Floor plan for Exercise 8.2. 
189 
10.1 
The decision modeling process. 
232 
10.2 
One Example of the Supply Chain 
237 
10.3 
Excel layout and solver entries for Prada skirt. 
241 
10.4 
Excel layout and solver entries for a make-or-buy decision 
model. 
243 
10.5 
Excel layout and solver entries for DHL transportation. 
245 
10.6 
Sensitivity report of DHL transportation. 
246 
10.7 
Excel layout and solver entries for allocation problem. 
248 
10.8 
Excel layout and solver entries for HSBC staffing with LP. 
251 
10.9 
Excel layout and solver entries for HSBC staffing with IP. 
251 
11.1 
Daily average temperatures (in gray) from Stockholm, 
Sweden, together with the seasonal mean function (in 
black). Temperatures are ranging from May 25, 1996 until 
May 24, 2006. 
260 
11.2 
The partial autocorrelation function of de-seasonalized 
temperature data. 
275 
11.3 
The autocorrelation function of squared residuals. 
276 
11.4 
The seasonal variance with the fitted σ2(ί). 
277 
13.1 
Start with the unit line segment and 1. delete the middle 
third, or 2. replace the middle third by the other two sides 
of the corresponding equilateral triangle. 
308 

XVÜi 
LIST OF FIGURES 
13.2 
The middle-thirds Cantor set and the von Koch curve. 
309 
13.3 
Box counting for the von Koch curve. 
311 
13.4 
The Sierpinski gasket. 
314 
13.5 
A sequence of approximating sets for the Sierpinski gasket. 
314 
13.6 
Play the chaos game to draw the Twin Dragon: 11 points, 
1000 points, 3000 points, and many more points. 
316 
13.7 
Box counting for the the Twin Dragon curve. 
317 
13.8 
Barnsley's spleenwort fern consists of four shrunken copies 
of itself. 
319 
13.9 
Box counting for the Barnsley's spleenwort fern. 
319 
13.10 
The signal approximation process. 
320 
13.11 
Make two shrunken copies on fi(X) 
and f2(X)- 
321 
13.12 
Adjust and combine the shrunken copies to get y = v(x). 
321 
13.13 
(Left) The target image y = u(x) = ^/x and (right) the 
shrunken copies on Xi. 
323 
13.14 
The target signal y = u(x) = yfx and the fractal transform 
y = (Tu)(x) consisting of four shrunken and distorted 
copies of u. 
325 
13.15 
Iterating the fractal transform T (consisting of four 
functions) on the initial function y = UQ(X) = 0. 
325 
13.16 
Iterating the fractal transform Γ (consisting of eight 
functions) on the initial function y = UQ(X) — 0. 
326 
13.17 
The LIFSM algorithm for images. 
327 
13.18 
The peppers input image and some parent-child pairs 
identified by the algorithm. 
328 
13.19 
Iterating the peppers fractal transform on the initial image 
of a frog. 
328 
14.1 
Exact solution and the approximate solution obtained by 
the central difference scheme for Example 14.1 for h = 0.05. 334 
14.2 
Exact solution and the approximate solution obtained by 
the upwind difference scheme for Example 14.1 for h = 0.05. 335 
14.3 
Numerical solution and error plots of EFD scheme for 
Example 14.1, for ε = le - 02, h = 0.05. 
336 

LIST OF FIGURES 
XIX 
14.4 
Plots of the exact and approximate solution obtained by 
shooting method for Example 14.2 for ε = 10~3, k\ = 10ε, 
k2 = 0.02, hx = ε, and h2 = 0.01. 
345 
15.1 
Characteristics of approximated fractional-order 
differentiator (15.22). 
367 
15.2 
Characteristics of approximated fractional-order integrator 
(15.27). 
369 
15.3 
Branch cut (0, —oo) for branch points in the complex plane. 375 
15.4 
Correspondence between the s-plane and the w-plane. 
377 
15.5 
Correspondence between the w-plane and the Riemann sheets.378 
15.6 
Stability regions of the fractional-order system. 
379 
15.7 
Double-scroll attractor of Chen's system (15.72) projected 
into 3D state space for simulation time 30 s. 
384 
15.8 
Unit-step response of controlled object. 
385 
15.9 
General SISO feedback loop system. 
386 
15.10 
Chua's circuit with memristor and negative conductance. 
387 
15.11 
Strange attractor of the memristor-based Chua's system 
(15.91) in w — x — y state space, for parameters a = 10, 
β = 13, 
7 = 0.1, ζ = 1.5, a = 0.3, b = 0.8, and orders 
q1=q2= 
0.98, q3 = 0.99, qA = 0.97. 
390 
15.12 
Strange attractor of the memristor-based Chua's system 
(15.91) in x — y — z state space, for parameters a = 10, 
β = 13, 
Ί = 0.1, C = 1.5, a = 0.3, b = 0.8, and orders 
q1=q2= 
0.98, q3 = 0.99, q4 = 0.97. 
391 
15.13 
Comparison of analytical and numerical solutions of 
fractional-order viscoelastic models of cell (15.97) for 
simulation time 5 s, step h = 0.001, and v = 1 in (15.99). 
392 
18.1 
RLC series circuit with controller ei(t). 
452 
18.2 
Vibrating string. 
461 

XX 
LIST OF FIGURES 
19.1 
Left: Path followed by a hypothetical parcel of air rising 
from the surface through the atmospheric column (solid 
line). The dashed line represents the environmental virtual 
temperature. The green area represents the convective 
available potential energy (CAPE) while the red area is 
the negative energy (CIN) that the rising parcel needs to 
overcome in order to reach its level of free convection and 
become freely buoyant. The dotted lines show the LCL and 
LFC levels. Right: A cartoon of a hot tower cumulus cloud 
formed by air parcels rising from the mixed boundary layer. 473 
19.2 
A cartoon of the three cloud types showing congestus (c), 
deep convective (d), and a decaying deep convective tower 
with a lagging large stratiform anvil (s), with stratiform 
rain falling into a dry region below it where it eventually 
evaporates and cools the environment (hatched area). The 
arrows indicate convective motion within the cloud. 
474 
19.3 
Schematic of the inverse method: P({a < U < b}) = 
P({F^(a)<X<F^(b)}). 
485 
19.4 
A Cartoon of a deep penetrative hot-tower cloud represented 
at a PAC site. The order parameter takes values 0 or 1 on 
a given site according to whether it is a CIN site or there is 
potential for deep convection. 
496 
19.5 
Evolution in time of the random process rit/Q- Top: 
single realization, bottom: average over 100 realizations, 
rj = 3 hours, q = 5. 
505 
19.6 
Same as in Figure 19.5 but for q = 10. 
506 
19.7 
Same as in Figure 19.5 but for q = 40. 
507 
19.8 
Lattice cloud model. A given lattice site is either clear sky 
(0) or occupied by a congestus cloud (1), a deep convective 
cloud (2), or a stratiform anvil cloud (3). 
508 
19.9 
An example of Monte Carlo simulation of stochastic 
multicloud model with n = 20, C = 0.25, D = 0.75, and 
the cloud time scales are as in Table 19.1, Case 1. (A) A 
snapshot picture of one typical lattice configuration and (B) 
time series of the total coverages associated with each cloud 
type with the equilibrium values overlaid (dashed lines). 
512 

LIST OF FIGURES 
XXI 
10 
Equilibrium eigenvalues of the mean-field equations. Panels 
(A), (B), and (C) represent the contours of the real parts of 
the three eigenvalues, respectively, as CAPE C (horizontal 
axis) and dryness D (vertical axis) are varied from 0 to 
2, Panel (D) shows the imaginary part of the complex 
conjugate pair, and Panel (E) displays the ratio of the 
frequency over the damping rate. 
518 
11 
Stochastic oscillations for both (a) when the frequency to 
damping ratio is small and (b) when it is large for the 
parameter values D = 0.4 and C — 0.1 and C = 1.5, 
respectively, and the T^'S are as in Table 19.1. 
518 
19
19

PREFACE 
Mathematical modeling is a multidisciplinary endeavor that applies mathe-
matical techniques to study real-world phenomena such as physical, chemical, 
biological, and economical processes. The quantities of a process of interest 
are often expressed as variables, while their interactions are often expressed as 
mathematical relationships or model equations, based on fundamental phys-
ical laws such as mass and energy conservation. Such mathematical models 
can be partial differential equations (PDEs), statistical relationships, or rule-
based descriptions, though PDEs are mostly widely used. 
Once of the main objectives of mathematical modeling is to model the 
process and mechanism of interest accurately so as to gain insight and make 
reasonably accurate predictions. This is a challenging, multidisciplinary task. 
Often, modeling is an interactive, iterative, time-consuming process. It is 
rarely the case that a first simple mathematical model will work well; more 
often, a modeler has to construct a series of mathematical models based on 
further assumptions, simplifications, adjustments, and improvement so that 
the revised/improved model can provide better predictions than initial crude 
models. 
Even with the right mathematical models or a right set of differential equa-
tions, the task could be even more challenging. First, most mathematical mod-
els are highly nonlinear, and their mathematical analysis is often intractable. 
xxii! 

XXIV 
PREFACE 
Even with some simplified models, analysis is possible, but the mathemati-
cal techniques involved are still not straightforward. In most cases, no an-
alytical solution or solutions of any closed form is possible. Secondly, some 
approximation techniques have to be employed to get some estimates to the 
true solutions. Approximation methods can be very diverse, though some 
common techniques such as asymptotic analysis, perturbation methods, and 
model reduction are often used. In most cases, mathematical analysis and ap-
proximations still do not provide sufficient information to construct the exact 
solutions of the mathematical model. Numerical methods are usually used to 
provide a fuller picture of the solution characteristics. Numerical methods are 
also a diverse subject. Solutions of PDEs can be achieved by finite difference 
methods, finite element methods, finite volume methods, boundary element 
methods, and spectral methods among others. These topics can fill several 
books in computational methods if they are described in detail. However, nu-
merical methods are not the main focus of this book, though we will introduce 
the basics of the numerical methods in relevant chapters. 
The aims of this book are twofold: model formulation and analysis, and 
multidisciplinary applications. We will mainly focus on how to formulate 
mathematical models for a given process or phenomenon. For a given prob-
lem of interest, we will show to build a workable mathematical model, then we 
will show to do mathematical analysis to obtain solutions (analytical, approxi-
mation, or numerical). Another emphasis will be on the diverse mathematical 
models arisen from multidisciplinary applications such as physics, chemistry, 
climate, environment, finance, and economics. Though applications are mul-
tidisciplinary, key mathematical equations can be the same for different pro-
cesses. For example, a parabolic PDE can be used to model mass diffusion, 
heat transfer, reaction-diffusion, pattern formation, and many other phenom-
ena. Similarly, a random walk model can also be used to describe diffusion, 
search optimization, option pricing, and random samplings in Monte Carlo 
methods. Therefore, we will demonstrate the above key features throughout 
this book. 
The basic requirement for this book is the good knowledge of basic calculus 
and mathematical foundations at university level. However, we will briefly 
review the key concepts of calculus and partial differential equations as well 
as the fundamental nature of mathematical modelling in the first few chapters. 
This makes it possible for readers to read all the relevant chapters without 
much difficulty. 
This book strives to provide diverse coverage of multidisciplinary applica-
tions with a major focus on mathematical modeling. It divides into three 
parts. Part I reviews the fundamental of mathematics required for this book. 
Part II provides the basics of mathematical modeling and numerical methods. 
Part III covers a diverse range of multidisciplinary applications. Due to the 
multidisciplinary nature of this book, contributed by multiple authors who 
are leading experts in their fields, we have strived to make all chapters self-
contained with enough background information and further reading materials, 

PREFACE 
XXV 
and consequently some chapters are more suitable for advanced graduates. A 
major advantage of this diverse coverage is that readers can choose topics and 
chapters of their own interest, while skipping some chapters without inter-
rupting the flow and main scheme of modeling and applications. We hope to 
provide a solid foundation for readers to pursue further studies and research 
in their chosen area. The other advantage of this book is that all chapters 
are provided with exercises and answers so that readers can consolidate what 
they have learned. Thus, this book serves well as a textbook or reference for 
mathematical modeling courses as well as for self-study. 
XIN-SHE YANG 
Cambridge and London, UK 
December, 2012 

ACKNOWLEDGMENTS 
I would like to thank all contributing authors for their enthusiastic support 
for this book. Without their professional contributions, this book would not 
be possible. 
I also would like to thank my Editor, Susanne Steitz-Filler, Associate Edi-
tor, Jacqueline Palmieri, Production Editor, Melissa Yanuzzi, Copyeditor, Liz 
Belmont, and staff at Wiley for their help and professionalism. I also thank my 
students, Aman Atak, Osaseri O. I. Guobadia and Qichen Xu, at Cambridge 
University for their help in proofreading some chapters of this book. 
Last but not least, I thank my wife and son for their support and help. 
X. S. Y. 
xxvii 

Editor and Contributors 
Editor 
Xin-She Yang 
School of Science and Technology, Middlesex University, United Kingdom. 
(x.yang@mdx.ac.uk) 
Contributors 
Belaid Aouni 
School of Commerce and Administration, Faculty of Management, Laurentian 
University, Sudbury, Ontario, Canada. (baouni@laurentian.ca) 
Fred Espen Benth 
Center of Mathematics for Applications, University of Oslo, Blindern, Oslo, 
Norway, (fredb@math.uio.no) 
Alfredo Bermudez 
Departamento de Matemätica Aplicada, Universidade de Santiago de Com-
postela, Spain, (alfredo.bermudez@usc.es) 
L. A. Boukas 
Department of Information and Communication Systems Engineering, Uni-
versity of the Aegean, Greece. 
Cinzia Colapinto 
Department of Management, Ca' Foscari University of Venice, San Giobbe 
Cannaregio, Italy, (cinzia.colapinto@unive.it) 
Luz M. Garcia Garcia 
Instituto Espanol de Oceanografia, Spain. 
Ivan Jeliazkov 
Department of Economics, University of California, Irvine, 3175 Social Sci-
ence Plaza A, Irvine, CA, USA. (ivan@uci.edu) 
Boualem Khouider 
Mathematics and Statistics University of Victoria, Victoria, B.C., Canada. 
(khouider@math.uvic.ca) 
Herb Kunze 
Department of Mathematics and Statistics, University of Guelph, Guelph, 
Ontario, Canada. (hkunze@uoguelph.ca) 

XXX 
EDITOR AND CONTRIBUTORS 
Davide La Torre 
Department of Economics, Business and Statistics, University of Milan, via 
Conservatorio, Milan, Italy, (davide.latorre@unimi.it) 
Thomas Lingefjärd 
Department of pedagogical, curricular and professional studies, 
University of Gothenburg, Gothenburg, Sweden. (Thomas.Lingefjard@gu.se) 
S. Natesan 
Department of Mathematics, Indian Institute of Technology Guwahati, Guwa-
hati, India. (natesan@iitg.ernet.in) 
E. V. Petracou 
Department of Geography, University of the Aegean, Greece. 
Ivo Petras 
Technical University of Kosice, Faculty of BERG, URalVP, Kosice, Slovak 
Republic, (ivo.petras@tuke.sk) 
Robert Piche 
Department of Mathematics, Tampere University of Technology, Tampere, 
Finland, (robert.piche@tut.fi) 
Mohammad Arshad Rahman 
Department of Economics, University of California, Irvine, CA, USA. 
Huajun Tang 
Faculty of Management and Administration, Macau University of Science and 
Technology, Macau, (hjtangcyw@gmail.com) 
K. I. Vasileiadis 
Laboratory for Financial and Actuarial Mathematics, Department of Statis-
tics and Actuarial - Financial Mathematics, University of the Aegean, Greece. 
S. Z. Xanthopoulos 
Laboratory for Financial and Actuarial Mathematics, Department of Statis-
tics and Actuarial - Financial Mathematics, University of the Aegean, Greece. 
Xin-She Yang 
School of Science and Technology, Middlesex University, London, UK. 
(x.yang@mdx.ac.uk) 

EDITOR AND CONTRIBUTORS 
XXXI 
A. N. Yannacopoulos 
Department of Statistics, Athens University of Economics and Business, Greece. 
(ayannaco@aueb.gr) 
Chuang Zheng 
School of Mathematical Science, Beijing Normal University, Beijing, China. 
(chuang.zheng@bnu.edu.cn) 

PART I 
INTRODUCTION AND 
FOUNDATIONS 
Mathematical Modeling with Multidisciplinary Applications.
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

CHAPTER 1 
DIFFERENTIAL EQUATIONS 
XIN-SHE YANG 
School of Science and Technology, Middlesex University, London, UK 
Also Mathematics and Scientific Computing, National Physical Laboratory, UK 
The main requirement for this book is the basic knowledge of calculus 
and statistics as covered by most undergraduate courses in engineering and 
science subjects. However, we will provide a brief review of mathematical 
foundations in the first few chapters so as to help readers to refresh some of 
the most important concepts. 
Most mathematical models in physics, chemistry, biology and many other 
applications are formulated in terms of differential equations. If the variables 
or quantities (such as velocity, temperature, pressure) change with other in-
dependent variables such as spatial coordinates and time, their relationship 
can in general be written as a differential equation or even a set of differential 
equations. 
Mathematical Modeling with Multidisciplinary Applications. 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 
3

4 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
1.1 
ORDINARY DIFFERENTIAL EQUATIONS 
An ordinary differential equation (ODE) is a relationship between a function 
y(x) of an independent variable x and its derivatives y', y", ..., jp n'. It can 
be written in a generic form 
V(x,y,y',y",...,yW)=0, 
(1.1) 
where Φ is a function of x, y,..., 
and j / n ) . The solution of the equation is 
a function y = f(x), satisfying the equation for all a; in a given domain Ω. 
The order of the differential equation is equal to the order n of the highest 
derivative in the equation. Thus, the so-called Riccati equation 
y' + a(x)y2 + b(x)y = c(x), 
(1.2) 
is a first-order ODE, and the following equation of Euler-type 
x2y" + alXy'+ 
a0y = 0, 
(1.3) 
is a second order. The degree of an equation is defined as the power to which 
the highest derivative occurs. Therefore, both the Riccati equation and the 
Euler equation are of the first degree. 
An equation is called linear if it can be arranged into the form 
an(x)y(n) 
+ ... + αι(χ)|/' + a0(x)y = φ{χ), 
(1.4) 
where all the coefficients depend on x only, not on y or any of its derivatives. 
If any of the coefficients is a function of y or any of its derivatives, then the 
equation is nonlinear. If the right-hand side is zero or φ(χ) = 0, the equation 
is homogeneous. It is called nonhomogeneous if φ(χ) φ 0. 
To find a solution of an ordinary differential equation is not always easy, 
and it is usually very complicated for nonlinear equations. Even for linear 
equations, solutions can be found in a straightforward way for only a few 
simple cases. The solution of a differential equation generally falls into three 
types: closed form, series form and integral form. A closed form solution is the 
type of solution that can be expressed in terms of elementary functions and 
some arbitrary constants. Series solutions are the ones that can be expressed 
in terms of a series when a closed form is not possible for certain types of 
equations. The integral form of solutions or quadrature is sometimes the 
only form of solution that is possible. If all these forms are not possible, the 
alternatives are to use approximate and numerical solutions. 

l.l ORDINARY DIFFERENTIAL EQUATIONS 
5 
1.1.1 
First-Order ODEs 
1.1.1.1 Linear ODEs A first-order linear differential equation can generally 
be written as 
y' + a(x)y = b(x), 
(1.5) 
where a(x) and b(x) are the known functions of x. Multiplying both sides of 
the equation by exp[J a(x)dx], called the integrating factor, we have 
y ' e l a.{x)dx + a(x)yeJ 
a(x)dx = 
b^eJ 
a(x)dx^ 
(j 
g) 
which can be written as 
[ye$ «(*)**]' = b(x)ef a(x)dx. 
(1.7) 
By simple integration, we have 
„ e / ^ = / M * ) e / ^ + a 
(1.8) 
So its solution becomes 
where C is an integration constant. 
■ EXAMPLE 1.1 
For example, from y'(x) — y(x) — e~x, we have a(x) = —1 and b = e~x, 
so the solution is 
y{x) = e~/(-1>Λ: 
ί e-'eH-V** + 
Ce~S^dx 
= ex ίe~2xdx 
+ Cex = -^e~x 
+ Cex. 
(1.10) 
1.1.1.2 Nonlinear ODEs For some nonlinear first-order ordinary differential 
equations, sometimes a transform or change of variables can convert it into 
the standard first-order linear equation (1.5). This is better demonstrated by 
an example. 
The Bernoulli's equation can be written in the generic form 
y' + p(x)y = q(x)yn, 
ηφ\. 
(1.11) 
In the case of n — 1, it reduces to a standard first-order linear ordinary 
differential equation. By dividing both sides by yn and using the change of 

6 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
variables 
Φ) 
= - ^ , 
u > = { ^ ^ , 
(1.12) 
we have 
u'+ (1 - n)p(x)u = (l-n)q(x), 
(1.13) 
which is a standard first-order linear differential equation whose general solu-
tion is given earlier in (1.9). 
■ EXAMPLE 1.2 
In the simpler case when p(x) = 2x, q(x) = — 1 and n = 2, we have 
u — 2xu = 1, 
u(x) 
For the initial condition y(0) = 1, we have w(0) = 1. Using solution 
(1.9), we have 
u(x) = ^—ex2eri(x) 
+ Ae*2, 
where A is the integration constant to be determined. 
If we further set u(0) = 1 as an initial condition, we have A = 1. 
Thus, the solution for y(x) becomes 
2ε~χ2 
y(x) = (y/ir erf (a;) + 2)' 
In general, such transformations are not always possible. 
1.1.2 
Higher-Order ODEs 
Higher-order ODEs are more complicated to solve even for the linear equa-
tions. For the special case of higher-order ODEs where all the coefficients 
an,..., a±, do are constants, 
any(-n) + --- + a1y' + a0y = f{x), 
(1.14) 
its general solution y(x) consists of two parts: a complementary function yc(x) 
and a particular integral or particular solution yp(x)- We have 
y{x)=yc(x)+y;{x). 
(1.15) 
The complementary function which is the solution of the linear homoge-
neous equation with constant coefficients can be written in a generic form 
a„yin) + fln-i^71-1) + · · · + aiy'c + a0 = 0. 
(1.16) 

1.1 ORDINARY DIFFERENTIAL EQUATIONS 
7 
Assuming y = AeXx where A is a constant, we get the characteristic equation 
as a polynomial 
α„λ" + α„_ιλ ( η- 1 } + · ■ · + αχλ + α0 - 0, 
(1.17) 
which has n roots in the general case. Then, the solution can be expressed as 
the summation of various terms yc(x) = Σ£=ι ck£XkX if the polynomial has n 
distinct zeros λι, ...λ„. For complex roots, and complex roots always occur in 
pairs λ = r ± ϊω, the corresponding linearly independent terms can then be 
replaced by erx[Acos(u>x) + Bsin(u)x)]. 
The particular solution y*(x) is any y(x) that satisfies the original inho-
mogeneous equation (1.14). Depending on the form of the function f(x), the 
particular solutions can take various forms. For most of the combinations of 
basic functions such as sinx,cosx, ekx, and xn, the method of the undeter-
mined coefficients is widely used. For /(x) = sin(o!x) or cos(ax), then we can 
try Vp ~ ^4 sin ax + .B sin ax. We then substitute it into the original equation 
(1.14) so that the coefficients A and B can be determined. For a polynomial 
f(x) = xn where n = 0,1, 2,...., N, we then try y* = A + Bx + ... + Qxn 
(polynomial). For f(x) = ekxxn, 
we can try y* = (A + Bx + 
...Qxn)ekx. 
Similarly, for f(x) 
= efcxsinax or f(x) 
= ekxcosax, 
we can use y* — 
ekx(Asinax 
+ B cos ax). 
More general cases and their particular solutions 
can be found in various textbooks. 
A very useful technique is to use the method of differential operator D. A 
differential operator D is defined as 
Since we know that DeXx = \eXx and DneXx = \neXx, 
so they are equivalent 
to D I—> λ, and Dn >—► λ™. Thus, any polynomial P{D) will map to a corre-
sponding Ρ(λ). On the other hand, integral operator D~x = J dx is just the 
inverse of differentiation. The beauty of the differential operator form is that 
one can factorize it in the same as for a polynomial, then solve each factor 
separately. The differential operator is very useful in finding out both the 
complementary functions and particular integral. This method also works for 
sinx,cosx,sinha; and others, and this is because they are related to eXx via 
sin0 = i ( e i e - e~ie) and coshx = (ex + 
e~x)/2. 
Higher-order differential equations can conveniently be written as a system 
of differential equations. In fact, an nth-order linear equation can always 
be written as a linear system of n first-order differential equations. A linear 
system of ODEs is more suitable for mathematical analysis and numerical 
integration. 

8 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
1.1.3 
Linear System 
For an nth order linear equation (1.16), it can always be written as a linear 
system 
dy 
dyi 
dyn-i 
= 
111 
— 
- ' 
dx 
dx 
V2, -
dx 
Vn-l, 
-an{x)y'n-i 
= an-i(x)yn-i 
+ ··· + ai(x)yi + a0(x)y + φ(χ), 
(1.19) 
which is a system for u = [y yi j/2 ··· 2/η-ι]τ· If the independent variable x 
does not appear explicitly in j/i, then the system is said to be autonomous 
with important properties. For simplicity and in keeping with the convention, 
we use t = x and ύ = du/dt in our following discussion. A general linear 
system of nth order can be written as 
Ü2 
fan 
ai2 
d21 
θ22 
θ 2 η 
O-nn/ 
u2 
\UnJ 
or 
ύ = Au. 
If we u = vexp(Ai), then this becomes an eigenvalue problem, 
(A - AI)v = 0, 
which will have non-null solution only if 
det(A - AI) = 0. 
(1.20) 
(1.21) 
(1.22) 
(1.23) 
1.1.4 
Sturm-Liouville Equation 
One of the commonly used second-order ordinary differential equations is the 
Sturm-Liouville equation in the interval x e [a, b] 
d_ 
dx 
dv~\ 
p{x)— 
+ q(x)y + Xr(x)y = 0, 
dxi 
with the boundary conditions 
y(a) + ay'(a) = 0, 
y(b)+ßy'(b) 
= 0, 
(1.24) 
(1.25) 
where the known function p(x) is differentiable, and the known functions 
q(x),r(x) 
are continuous. The parameter λ to be determined can only take 
certain values λ„, called the eigenvalues, if the problem has solutions. For the 
obvious reason, this problem is called Sturm-Liouville eigenvalue problem. 

l.l ORDINARY DIFFERENTIAL EQUATIONS 
9 
Sometimes, it is possible to transform a nonlinear equation into a standard 
Sturm-Liouville equation, and this is better demonstrated by an example. 
■ EXAMPLE 1.3 
The Riccati equation can be written in the generic form 
y' = p(x) + q(x)y + r(x)y2, 
r(x) φ Q. 
If r(x) = 0, then it reduces to a first-order linear ODE. By using the 
transform 
u'(x) 
r(x)u(x) 
or 
u{x) = e~ $ 
rWy{x)dx, 
we have 
u" - P(x)u' + Q(x)u = 0, 
where P(x) = —r'(x)/r(x) 
+ q(x) and Q(x) = r(x)p(x). 
For each eigenvalue λ„, there is a corresponding solution tp\n, called an eigen-
function. The Sturm-Liouville theory states that for two different eigenvalues 
Am φ λ„, their eigenfunctions are orthogonal. That is 
/•b 
/>b 
/ V'Am(a;)V'An(a;)r(x)cix = 0, 
or / ipxm(x)ipXn(x)r(x)dx 
= Smn, 
Ja 
Ja 
where 8mn = 1 if m = n, otherwise Smn = 0 if m φ η. It is possible to arrange 
the eigenvalues in an increasing order 
λι < λ2 < ... < Xn< ... —> oo. 
Now let us study a real-world problem using differential equations. Many 
fluid flow problems are related to flow through a pipe, including the water 
flow through a pipe, oil in an oil pipeline. Let us look at the Poiseuille flow 
in a cylindrical pipe. 
■ EXAMPLE 1.4 
The laminar flow of a viscous fluid through a pipe with a radius r = a 
is under a constant pressure gradient (see Fig. 1.1) 
Vp = AP/L = (P0 - 
Pi)/L, 
where Pi and P0 (< Pi) are the pressures at inlet and outlet, respectively. 
L is the length of the pipe. The drag force is balanced by pressure 
change, and this leads to the following second-order ordinary differential 

10 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
pressure gradient (Vp) 
Figure 1.1 
Flow through a pipe under pressure gradient. 
equation 
L 
r dr 
' dv(r) 
r 
Δ Ρ 
1 d 
r-
dr 
where η is the viscosity of the fluid. This equation implies that the flow 
velocity v is not uniform, it varies with r. Integrating the above equation 
twice, we have 
Δ Ρ o 
v(r) = —-r z + A In r + B, 
where A and B are integrating constants. The velocity must be finite at 
r = 0, which means that A = 0. The no-slip boundary v = 0 at r = a 
requires that 
Δ Ρ 
, 
— - a 2 + B = 0. 
Thus, the velocity profile is 
v{r) 
= ~4^L{a 
~ r ) · 
Now the total flow rate Q down the pipe is given by integrating the flow 
over the whole cross section. We have 
/"" 
. , , 
π Δ Ρ fa. 
2 
o, , 
π Δ Ρ 
4 
Q= 
2nrv(r)dr = ——— / (a2r - r3)dr =-——a4. 
(1. 
Here the negative sign means the flow down the pressure gradient. 
26) 
We can see that the flow rate is proportional to the pressure gradient, inversely 
proportional to the viscosity. Double the radius of the pipe, and the flow rate 
will increase to 16 times. 
1.2 
PARTIAL DIFFERENTIAL EQUATIONS 
Partial differential equations are much more complicated compared with or-
dinary differential equations. There is no universal solution technique for 

1.2 PARTIAL DIFFERENTIAL EQUATIONS 
11 
nonlinear equations, even numerical simulations are usually not straightfor-
ward. Thus, we will mainly focus on the linear partial differential equations 
and equations of special interest. 
A partial differential equation (PDE) is a relationship containing at least 
one partial derivative. Similar to the ordinary differential equation, the high-
est nth partial derivative is referred to as the order n of the partial differential 
equation. The general form of a partial differential equation can be written 
as 
, / 
du du d2u d2u d2u \ 
n^'^-'&'^^'v'^'··^0· 
(L27) 
where u is the dependent variable, and x, y,... are the independent variables. 
A simple example of partial differential equations is the linear first-order 
partial differential equation, which can be written as 
a(x,y)^+b(x,y)^=f(x,y). 
(1.28) 
for two independent variables and one dependent variable u. If the right-hand 
side is zero or simply f(x, y) = 0, then the equation is said to be homogeneous. 
The equation is said to be linear if a, b and / are functions of x, y only, not u 
itself. 
For simplicity in notation in the studies of PDEs, compact subscript forms 
are often used in the literature. They are 
du 
_ 
_ du 
_ d2u 
_ d2u 
—, 
Uy=oyU=— 
, UXX = ^ J , 
UXy=-^, 
and thus we can write (1.28) as 
aux + buy = /. 
(1.30) 
1.2.1 
First-Order PDEs 
A first-order linear partial differential equation can be written as 
a(x,y)ux 
+ b(x,y)uy = f(x,y), 
(1.31) 
which can be solved using the method of characteristics in terms of a param-
eter s 
dx 
du , du , 
,„ „ . 
Ts=a> Is=b> dS=f> 
i
1·
32) 
which essentially forms a system of first-order ordinary differential equations. 
The simplest example of first-order linear partial differential equations is the 
first-order hyperbolic equation 
ut +cux = 0, 
(1.33) 

12 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
where c is a constant. It has a general solution 
u = ip(x- ct), 
(1.34) 
which is a travelling wave along the x-axis with a constant speed c. If the 
initial shape is u(x, 0) = 4>{x), then u(x, t) = ψ(χ — et) at time t, therefore the 
shape of the wave does not change with time though its position is constantly 
changing. 
1.2.2 
Classification of Second-Order PDEs 
A linear second-order partial differential equation can be written in the generic 
form in terms of two independent variables x and y, 
auxx + buxy + cUyy + gux + huy + ku = f, 
(1.35) 
where a, b, c, g, h, k and / are functions of x and y only. If f(x, y, u) is also a 
function of u, then we say that this equation is quasi-linear. 
If Δ = b2 — Aac < 0, the equation is elliptic. One famous example is the 
Laplace equation uxx + uyy = 0. 
If Δ > 0, it is hyperbolic. A good example is the wave equation uu = c2uxx. 
If Δ = 0, it is parabolic. Diffusion and heat conduction are of the parabolic 
type ut = KUXX. 
1.3 
CLASSIC MATHEMATICAL MODELS 
Three types of classic partial differential equations are widely used and they 
occur in a vast range of applications. In fact, almost all books or studies on 
partial differential equations will have to deal with these three types of basic 
partial differential equations. 
Laplace's and Poisson's Equation: In heat transfer problems, the steady 
state of heat conduction with a source is governed by the Poisson equation 
kV2u = f(x,y,t), 
(ι,ϊ)εΠ, 
(1.36) 
or 
uxx + uyy = q(x,y,t), 
(1-37) 
for two independent variables x and y. Here k is thermal diffusivity and 
f(x,y,t) 
is the heat source. Ω is the domain of interest, usually a physical 
region. If there is no heat source (q = f/κ = 0), it becomes the Laplace 
equation. The solution of a function is said to be harmonic if it satisfies 
Laplace's equation. 
In order to determine the temperature u completely, the appropriate bound-
ary conditions are needed. A simple boundary condition is to specify the tem-

1.3 CLASSIC MATHEMATICAL MODELS 
13 
perature u = uo on the boundary <9Ω. This type of problem is the Dirichlet 
problem. 
On the other hand, if the temperature is not known, but the gradient du/dn 
is known on the boundary where n is the outward-pointing unit normal, this 
forms the Neumann problem. Furthermore, some problems may have a mixed 
type of boundary conditions in the combination of 
ndu 
au + β— 
= 7 , 
which naturally occurs as a radiation or cooling boundary condition. 
Parabolic Equation: Time-dependent problems, such as diffusion and tran-
sient heat conduction, are governed by the parabolic equation 
lit = kuxx. 
(1.38) 
Written in the n-dimensional case x\ = x,X2 = y,X3 = z,..., it can be ex-
tended to the reaction-diffusion equation 
ut = kS72u + f(u, xi,..,xn,t). 
(1.39) 
Wave Equation: The vibration of strings and travelling seismic waves are 
governed by the hyperbolic wave equation. 
The ID wave equation in its simplest form is 
utt = c2uxx, 
(1-40) 
where c is the velocity of the wave. Using a transformation of the pair of 
independent variables 
ξ = χ + α, 
(i.4i) 
and 
η = χ-(±, 
(1.42) 
for t > 0 and — oo < x < oo, the wave equation can be written as 
uin = 0. 
(1.43) 
Integrating twice and substituting back in terms of x and t, we have 
u(x,t) = f(x + ct)+g(x-ct), 
(1.44) 
where / and g are functions of x + ct and x — ct, respectively. We can see 
that the solution is composed of two independent waves. One wave moves to 
the right and one travels to the left at the same constant speed c. 

14 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
1.4 
OTHER MATHEMATICAL MODELS 
We have shown examples of the three major equations of second-order linear 
partial differential equations. There are other equations that occur frequently 
in engineering and science. We will give a brief description of some of these 
equations. 
Elastic Wave Equation: A wave in an elastic isotropic homogeneous solid 
is governed by the following equation in terms of displacement u, 
p ^ = M V 2 u + ( A + M)V(V-u) + f, 
(1.45) 
where p is density, λ and μ are Lame constants, and f is body force. Such 
an equation can describe two types of wave: transverse wave (S wave) and 
longitudinal or dilatational wave (P wave). The speed of the longitudinal 
wave is 
vp = λ/(λ + 2μ)/ρ, 
(1.46) 
and the transverse wave has the speed 
vs = ,/μ~/ρ~. 
(1.47) 
Reaction-Diffusion Equation: The reaction-diffusion equation is an exten-
sion of heat conduction with a source / 
ut = DV2u + f(x,y,z,u), 
(1.48) 
where D is the diffusion coefficient and / is the reaction rate. One example 
is the combustion equation 
«t = Duxx + Que~x/U, 
(1.49) 
where Q and λ are constants. 
Navier-Stokes Equations: The Navier-Stokes equations for incompressible 
flow in the absence of body forces can be written, in terms of the velocity u 
and the pressure p, as 
V · u = 0, 
p[ut + (u · V)u] = /uV2u - Vp, 
(1.50) 
where p and μ are the density of the fluid and its viscosity, respectively. In 
computational fluid dynamics, most simulations are mainly related to these 
equations. We can define the Reynolds number as Re = pUL/μ where U is 
the typical velocity and L is the length scale. 
In the limit of Re <C 1, we have the Stokes flow governed by 
MV2u = Vp. 
(1.51) 

1.5 SOLUTION TECHNIQUES 
15 
In the other limit of Re ^> 1, we have the inviscous flow 
V - u = 0, 
p[ut + (u · V)u] = -Vp, 
(1.52) 
where there is still a nonlinear term (u · V)u. 
Groundwater Flow. The general equation for three-dimensional groundwa-
ter flow is 
Sa^ 
= ^p-S<7B% 
+ Q, 
(1.53) 
at 
μ 
at 
where σ = σ*^/3 is the mean stress, p is the pore water pressure, and Q 
is source or sink term. 5 σ is the specific storage coefficient and B is the 
Skempton constant, k is the permeability of the porous medium and μ is the 
viscosity of water. This can be considered as the inhomogeneous diffusion 
equation for pore pressure. 
1.5 
SOLUTION TECHNIQUES 
Each type of equation usually requires different solution techniques. However, 
there are some methods that work for most of the linearly partial differen-
tial equations with appropriate boundary conditions on a regular domain. 
These methods include separation of variables, method of series expansion 
and transform methods such as the Laplace and Fourier transforms. 
1.5.1 
Separation of Variables 
The separation of variables attempts a solution of the form 
u = X(x)Y(y)Z(z)T(t), 
(1.54) 
where X(x), Y{y), Z(z), T(t) are functions of x, y, z, t, respectively. By deter-
mining these functions that satisfy the partial differential equation and the 
required boundary conditions in terms of eigenvalue problems, the solution of 
the original problem is then obtained. 
As a classic example, we now try to solve the ID heat conduction equation 
in the domain x € [0, L] and t > 0 
ut — kuxx, 
(1.55) 
with the initial value and boundary conditions 
u(0,i)=0, 
Ms,*) 
= 0 ) 
u(x,0) = -ψ(χ). 
(1.56) 
OX 
x=L 

16 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
Letting u(x,t) = X(x)T(t), 
we have 
X"(x) 
_ T'(t) 
X 
kT ■ 
(1.57) 
As the left-hand side depends only on x and the right-hand side only depends 
on t, therefore, both sides must be equal to the same constant, and the con-
stant can be assumed to be — λ2. The negative sign is just for convenience 
because we will see below that the finiteness of the solution T(t) requires that 
eigenvalues λ2 > 0 or λ are real. Hence, we now get two ordinary differential 
equations 
X"{x) + \2X{x) 
= 0, 
T'(t) + k\2T(t) 
= 0, 
(1.58) 
where λ is the eigenvalue. The solution for T(t) is 
T = Ane~x2kt. 
(1.59) 
The basic solution for X(x) is simply 
X(x) = acosXx + ßsinXx. 
(1.60) 
So the fundamental solution for u is 
u(x,t) = (acosAa;-l-/3sinAa;)e"'Si2fct, 
(1.61) 
where we have absorbed the coefficient An into a and ß because they are the 
undetermined coefficients anyway. As the value of λ varies with the boundary 
conditions, it forms an eigenvalue problem. The general solution for it should 
be derived by superposing solutions of (1.61), and we now have 
^2xnTn 
= ^2(ancos\nx 
+ ßnsmXnx)e 
x*kt. 
(1.62) 
n=l 
n—1 
From the boundary condition w(0, t) = 0 at x = 0, we have 
oo 
0 = ^ a n e - A " f c t , 
(1-63) 
n=l 
which leads to an — 0 since exp(—X2ki) > 0. 
0, we have 
Fromf 
x—L 
XncosXnL 
= 0, 
(1-64) 
which requires 
XnL= 
C 2 " - 1 ) 7 ^ 
(n=l,2,...). 
(1.65) 

1.5 SOLUTION TECHNIQUES 
17 
Therefore, λ cannot be continuous, and it only takes an infinite number of 
discrete values, called eigenvalues. 
Each eigenvalue λ = λ„ = ' n^L 'π, (η = 1,2,...) has a corresponding eigen-
function Xn = sin(A„a;). Substituting into the solution for T(t), we have 
[(2n-lWl 2 , . 
Tn(t) = Ane~^-^kt. 
(1.66) 
By expanding the initial condition into a Fourier series so as to determine the 
coefficients, we have 
oo 
n=l 
ßn = | | % ( x ) s i n [{2η~1)πΧ]άχ. 
(1.67) 
EXAMPLE 1.5 
In the special case when initial condition u(x, t = 0) = φ = uo is con-
stant, the requirement for u — UQ at t — 0 becomes 
Σ
Λ 
. (2n — 1)πχ 
,Η 
. 
ßn*™- 
ψΓ—· 
(1-68) 
2L 
n=l 
Using the orthogonal relationships 
and 
f 
. τηπχ 
, ηπχ 
, 
„ 
. 
/ 
sin —-— sin ——ax = 0, 
πιψη, 
Jo 
Li 
L 
f , . ηπχ.ο , 
L 
/ 
(Sm~L~' 
= 2"' 
( n = i' 2'···). 
and multiplying both sides of Eq.(1.68) by sin[(2n — l)nx/2L], we have 
the integration 
n L 
fL 
. (2n - 1)πχ 
, 
2u0L 
. 
Λ „ 
. 
ßn2=J0
Sm 
2L 
UodX = J*T^> 
(» = 1.2,..·). 
which leads to 
^" = Τ^ 
ΓΤ' 
η=1,2,..., 
(2n — 1)π 

18 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
and thus the solution becomes 
u = — - > 
— 
—e 
ϊ ί 2 s i n ^ 
—r1—. 
(1.69) 
π ^ W 2 n - 1) 
2L 
^ 
; 
This solution is essentially the same as the classical heat conduction problem 
discussed by Carslaw and Jaeger in 1959. This same solution can also be 
obtained using the Fourier series of UQ in 0 < x < L. 
1.5.2 
Laplace Transform 
The integral transform can reduce the number of the independent variables. 
For the ID time-dependent case, it transforms a partial differential equation 
into an ordinary differential equation. By solving the ordinary differential 
equation and inverting it back, we can obtain the solution for the original 
partial differential equation. As an example, we now solve the heat conduction 
problem over a semi-infinite interval [0, oo), 
ut = kuxx, 
u(x,0) = 0, u{0,t)=T0. 
(1.70) 
■ EXAMPLE 1.6 
Let ü(x, s) = JQ u(x, t)e~stdt be the Laplace transform of u(x, t), then 
Eq.(1.70) becomes 
- _ ud2ü 
- 
_ 
To 
SU — K-j—z, 
UX=Q 
— 
, 
dxz 
s 
which is an ordinary differential equation whose general solution can be 
written as 
ü = Ae~^x 
+ 
Be^x. 
The finiteness of the solution as x —» oo requires that B = 0, and the 
boundary condition at x = 0 leads to 
s 
By using the inverse Laplace transform, we have 
u = r0erfc(—■= ), 
where erfc(cc) is the complementary error function. 
The Fourier transform works in a similar manner to the Laplace transform. 

1.5 SOLUTION TECHNIQUES 
19 
1.5.3 
Similarity Solution 
Sometimes, the diffusion equation 
ut = KUXX, 
(1-71) 
can be solved by using the so-called similarity method by denning a similar 
variable 
o 
X 
X 
'-75' - <S- 
(1'72) 
One can assume that the solution to the equation has the form 
By substituting it into the diffusion equation, the coefficients a and β can be 
determined. For most applications, one can assume a = 0 so that u = /(C)· 
In this case, we have 
4Cu" + 2«' + ζβΐκί)0-1^ 
= 0, 
(1.74) 
where u' = du/άζ. In deriving this equation, we have used the chain rules of 
differentiations 
d_=d_(K 
d_=d_<K 
(λ7,, 
dx 
θζθχ' 
dt 
θζθί' 
{ ' 
j 
Since the original equation does not have time-dependent terms explicitly, 
this means that all the exponents for any t-terms must be zero. Therefore, 
we have 
ß = l. 
(1.76) 
Now, the diffusion equation becomes 
C/"(C) = - ( i + £ ) / ' · 
(1.77) 
Using (In / ' ) ' — / " / / ' and integrating the above equation once, we get 
Integrating it again and using the substitution ζ = Αξ2, we obtain 
u = A 
ε-ζ2άξ - Cerf (-^=) + D, 
(1.79) 
Jo 
W4«;i' 
where C and D are constants that can be determined from appropriate bound-
ary conditions. 

20 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
For the same problem as (1.70), the boundary condition as x —> oo implies 
that C + D = 0, while u(0, t) = T0 means that D =-C 
= TQ. Therefore, we 
finally have 
u = Toll- 
erf (-ß=)] 
= T 0erfc(-f=Y 
1.5.4 
Change of Variables 
In some cases, the partial differential equation cannot be written in any stan-
dard form; however, it can be converted into a known standard equation by 
a change of variables. For example, the following simple reaction-diffusion 
equation 
du 
, d2u 
.„ „ . 
- 
= k—2-au, 
(1.80) 
describes the heat conduction along a wire with a heat loss term — au. Carslaw 
and Jaeger show that it can be transformed into a standard equation of heat 
conduction using the following change of variables 
(1.81) 
where v is the new variable. By simple differentiations, we have 
du 
dv _at 
_at 
dv _at 
d2u 
d2v 
_at 
- 
= - e 
- ave 
= - e 
- au, 
~2 
= —,e 
«-, 
(1.82) 
we have 
| 
= §V- 
-au = k^-au 
= k~e^ 
-au, 
(1.83) 
which becomes 
After dividing both sides by e~at > 0, we have 
dv 
, d2v 
, „,, 
di = kW> 
( 1· 8 5) 
which is the standard heat conduction equation for v. 
For given initial (usually constant) and boundary conditions (usually zero), 
we can use all the techniques for solving the standard equation to get solutions. 
However, for some boundary conditions such as u = uo, a more elaborate form 
of change of variables is needed. Crank introduced Danckwerts's method by 
using the following transform 
u = a [ ve~aTdT + ve~at. 
(1.86) 
Jo 

EXERCISES 
2 1 
Noting that ^f = ave 
at — ave 
at + ^ e 
at, it is straightforward to show 
9u 
, d2u 
,, n_. 
M+aU 
= kM- 
( L 8 7 ) 
For the boundary condition u = uo, we have v = vo = uo, and this is because 
u = u0 = av0 / e~aTdr + v0e~at = v0 ~ v0e~at + v0e~at = v0, 
(1.88) 
which is the same boundary condition as that for u. 
There are other important methods for solving partial differential equa-
tions. These include Green's function, series methods, asymptotic methods, 
approximate methods, perturbation methods and naturally the numerical 
methods. 
EXERCISES 
1.1 
The so-called Coriolis force or effect exists in a rotational system, which 
makes the falling object lands slightly to the east (without considering air 
resistance). Assume the falling height is h, estimate the distance deviation 
to the east due to this Coriolis acceleration a = 2ων where ω is the angular 
velocity of the Earth's rotation and v is its falling velocity. 
1.2 
Find the general solution x2y" — y = 0 for x > 0. 
1.3 
The governing equation for the damped simple harmonic motion can be 
written as a general second-order ordinary differential equation 
ü + 2ηωνύ + ω%ιι = 0, 
where u>o is the so-called undamped frequency, and η is called damping coef-
ficient. Show that η > 1 and η < 1 will lead to different characteristics in the 
system. 
1.4 
The Laplace equation is often written as Au = 0 or ^ 
+ | - | = 0 
in 2D case. Define a polar coordinate system (r, Θ) so that x = r cos Θ and 
y = rsin#, and then write the Laplace equation in the polar coordinates. 
1.5 
The FitzHugh-Nagumo equation occurs in many applications such as 
biology, genetics and heat transfers. In the ID case, it can be written as 
du 
d2u 
. 
.,, 
. 
m = 
dx-*+u{u-1){x-u)> 
where λ is a constant. Show that this equation supports a traveling wave 
solution 
^exp(?7i) + Agexp(7?2) 
U[X' ' 
Aexp(i?i) + ßexp(r?2) + K' 

22 
CHAPTER 1. DIFFERENTIAL EQUATIONS 
where 
and A, B and K are arbitrary constants. 
1.6 
The Klein-Gordon equation ^jf = a2f^r — bu occurs in quantum field 
theory and other applications. 
Verify that u{x,t) 
= sin(Aa;) [A cos(u;f) + 
Bsin(wt)] is a solution if b = —α2λ2 + ω2. If u(x, t) = exp(±Ax) [A cos(wf) + 
ßsin(wi)] is also a solution, what is the relationship between a, b, λ and ω. 
1.7 
In many applications, partial differential equations can be rewritten in 
other forms so that they can be linked with other well-known equations. For 
example, the so-called telegraph equation 
d2u 
du 
292u 
W+V-di=adx-*+bU' 
υ > 0 ' 6 < 0 ' 
can be transformed into the Klein-Gordon equation by a transform u(x, t) = 
exp(—^vt)w(x,t). Show that this is true. 
1.8 
The Burgers equation in one-dimensional case is often written as 
du _ d2u 
du 
dt 
dx2 
dx 
Show that it can be transformed into the standard linear diffusion equation 
by the so-called Hopf-Cole transformation u(x, t) = f ff · 
REFERENCES 
1. Berger, A. L., Long term variations of the Earth's orbital elements, Celestial 
Mechanics, 15, 53-74 (1977). 
2. Carrrier, G. F. and Pearson, C. E., Partial Differential Equations: Theory and 
Technique, 2nd Edition, Academic Press (1988). 
3. Carslaw, H. S. and Jaeger, J. C, Conduction of Heat in Solids, 2nd Edition, 
Oxford University Press, Oxford (1986). 
4. Crank, J., Mathematics of Diffusion, Clarendon Press, Oxford (1970). 
5. Fowler, A. C, Mathematical Models in the Applied Sciences, Cambridge Uni-
versity Press, Cambridge (1997). 
6. Jeffrey, A., Advanced Engineering Mathematics, Academic Press, Waltham, MA 
(2002). 
7. Kreyszig, E., Advanced Engineering Mathematics, 6th Edition, Wiley & Sons, 
New York (1988). 
8. Riley, K. F., Hobson, M. P., and Bence, S. J., Mathematical Methods for Physics 
and Engineering, Cambridge University Press, Cambridge (2006). 
9. Selby, S. M., Standard Mathematical Tables, CRC Press, Cleveland, Ohio (1975). 

CHAPTER 2 
MATHEMATICAL MODELING 
XIN-SHE YANG 
School of Science and Technology, Middlesex University, London, UK 
Also Mathematics and Scientific Computing, National Physical Laboratory, UK 
2.1 
MATHEMATICAL MODELING 
Mathematical modeling is the process of formulating an abstract model in 
terms of mathematical language to describe the complex behavior of a real 
system. Mathematical models are quantitative models and often expressed 
in terms of ordinary differential equations and partial differential equations. 
Mathematical models can also be statistical models, fuzzy logic models and 
empirical relationships. In fact, any model description using mathematical 
language can be called a mathematical model. Mathematical modeling is 
widely used in natural sciences, computing, engineering, meteorology, and in-
dustrial applications. For example, theoretical physics is essentially all about 
the modeling of real world processes using several basic principles (such as the 
Mathematical Modeling with Multidisciplinary Applications.
 
23 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

24 
CHAPTER 2. MATHEMATICAL MODELING 
( Realworld problem 
1 
Physical model 
(Idealisation) 
Mathematical model 
(PDEs,statistics,etc) 
Analysis/Validation 
(Data, benchmarks) 
Figure 2.1 
Mathematical modeling. 
conservation of energy, momentum) and a dozen important equations (such as 
the wave equation, the Schrödinger equation, the Einstein equation). Almost 
all these equations are partial differential equations (PDEs). 
An important feature of mathematical modeling and numerical algorithms 
is its interdisciplinary nature. It involves applied mathematics, computer sci-
ences, physical and biological sciences, and others. Mathematical modeling in 
combination with scientific computing is an emerging interdisciplinary tech-
nology. Many international companies use it to model physical processes, to 
design new products, to find solutions to challenging problems, and increase 
their competitiveness in international markets. 
The basic steps of mathematical modeling can be summarized as meta-
steps shown in Figure 2.1. The process typically starts with the analysis of 
a real world problem so as to extract the fundamental physical processes by 
idealization and various assumptions. Once an idealized physical model is 
formulated, it can then be translated into the corresponding mathematical 
model in terms of partial differential equations (PDEs), integral equations, 
and statistical models. Then, the mathematical model should be investigated 
in great detail by mathematical analysis (if possible), numerical simulations 
and other tools so as to make predictions under appropriate conditions. Then, 
these simulation results and predictions will be validated against the existing 
models, well-established benchmarks, and experimental data. If the results 
are satisfactory (which they rarely are at first), then the mathematical model 
can be accepted. If not, both the physical model and mathematical model 
will be modified based on the feedback, and then the new simulations and 
prediction will be validated again. After a certain number of iterations of 
the whole process (often many), a good mathematical model can properly be 
formulated, which will provide great insight into the real-world problem and 
may also predict the behavior of the process under study. 

2.2 MODEL FORMULATION 
25 
For any physical problem in physics, chemistry and biology, for example, 
there are traditionally two ways to deal with it by either theoretical approaches 
or field observations and experiments. The theoretical approach in terms of 
mathematical modeling is an idealization and simplification of the real prob-
lem and the theoretical models often extract the essential or major charac-
teristics of the problem. The mathematical equations obtained even for such 
oversimplified systems are usually very difficult for mathematical analysis. On 
the other hand, the field studies and experimental approach are usually expen-
sive if not impractical. Apart from financial and practical limitations, other 
constraining factors include the inaccessibility of the locations, the range of 
physical parameters, and time for carrying out various experiments. As com-
puting speed and power have increased dramatically in the last few decades, a 
practical third way or approach is emerging, which is computational modeling 
and numerical experimentation based on the mathematical models. It is now 
widely acknowledged that computational modeling and computer simulations 
serve as a cost-effective alternative, bridging the gap or complementing the 
traditional theoretical and experimental approaches to problem solving. 
Mathematical modeling is essentially an abstract art of formulating the 
mathematical models from the corresponding real-world problems. The mas-
tery of this art requires practice and experience, and it is not easy to teach 
such skills as the style of mathematical modeling largely depends on each 
person's own insight, abstraction, type of problems, and experience of dealing 
with similar problems. Even for the same physical process, different models 
could be obtained, depending on the emphasis of some part of the process, 
say, based on your interest in certain quantities in a particular problem, while 
the same quantities could be viewed as unimportant in other processes and 
other problems. 
2.2 
MODEL FORMULATION 
Mathematical modeling often starts with the analysis of the physical process 
and attempts to make an abstract physical model by idealization and approx-
imations. From this idealized physical model, we can use the various first 
principles such as the conservation of mass, momentum, energy and Newton's 
law to translate into mathematical equations. Let us look at the example of 
the diffusion process of sugar in a glass of water. We know that the diffusion 
of sugar will occur if there is any spatial difference in the sugar concentra-
tion. The physical process is complicated and many factors could affect the 
distribution of sugar concentration in water, including the temperature, stir-
ring, mass of sugar, type of sugar, how you add the sugar, even geometry of 
the container and others. We can idealize the process by assuming that the 
temperature is constant (so as to neglect the effect of heat transfer), and that 
there is no stirring because stirring will affect the effective diffusion coefficient 
and introduce the advection of water or even vertices in the (turbulent) water 

26 
CHAPTER 2. MATHEMATICAL MODELING 
Figure 2.2 
Representative element volume (REV). 
flow. We then choose a representative element volume (REV) whose size is 
very small compared with the size of the cup so that we can use a single value 
of concentration to represent the sugar content inside this REV (if this REV 
is too large, there is considerable variation in sugar concentration inside this 
REV). We also assume that there is no chemical reaction between sugar and 
water (otherwise, we are dealing with something else). If you drop the sugar 
into the cup from a considerable height, the water inside the glass will splash 
and thus the fluid volume will change, and this becomes a fluid dynamics 
problem. So we are only interested in the process after the sugar is added 
and we are not interested in the initial impurity of the water (or only to a 
certain degree). With these assumptions, the whole process is now idealized 
as the physical model of the diffusion of sugar in still water at a constant tem-
perature. Now we have to translate this idealized model into a mathematical 
model, and in the present case, a parabolic partial differential equation or 
diffusion equation. Let us look at an example. 
■ EXAMPLE 2.1 
Let c be the averaged concentration in a representative element volume 
with a volume dV inside the cup, and let Ω be an arbitrary, imaginary 
closed volume Ω (much larger than our REV but smaller than the con-
tainer, see Figure 2.2). We know that the rate of change of the mass of 
sugar per unit time inside Ω is 

2.2 MODEL FORMULATION 
27 
where t is time. As the mass is conserved, this change of sugar content 
in Ω must be supplied in or flow out over the surface Γ = <9Ω, enclosing 
the region Ω. Let J be the flux through the surface, thus the total mass 
flux through the whole surface Γ is 
a 
J-dS. 
Thus the conservation of total mass in Ω requires that 
δ1+δ2= 
0, 
or 
This is essentially the integral form of the mathematical model. Using 
the Gauss's theorem (discussed later in this book) 
Jl
jds=JJL
vjdv· 
/Γ 
JJJQ 
we can convert the surface integral into a volume integral. We thus have 
d 
dt ΙΙΙ^
ν+ΙΙί
νΜν=ο 
Since the domain Ω is fixed (independent of t), we can interchange the 
differentiation and integration in the first term, we now get 
JJJn dt 
JJJn 
JJJQ 
dV = 0. 
Since the enclosed domain Ω is arbitrary, the above equation should be 
valid for any shape or size of Ω, therefore, the integrand must be zero. 
We finally have 
This is the differential form of the mass conservation. It is a partial 
differential equation. As we know that diffusion occurs from the higher 
concentration to lower concentration, and the rate of diffusion is propor-
tional to the gradient Vc of the concentration. The flux J over a unit 
surface area is given by Fick's law 
J = -DVc, 
where D is the diffusion coefficient which depends on the temperature 
and the type of materials. The negative sign means the diffusion is 

28 
CHAPTER 2. MATHEMATICAL MODELING 
opposite to the gradient. Substituting this into the mass conservation, 
we have 
| - V . ( D V c ) = 0, 
or 
| - V . ( D V « ) . 
In the simplified case when D is constant, we have 
%-D*C 
(2.1) 
which is the well-known diffusion equation. This equation can be applied to 
study many phenomena such as heat conduction, pore pressure dissipation, 
groundwater flow and consolidation if we replace D by the corresponding 
physical parameters. This will be discussed in greater detail in the related 
chapters this book. 
2.3 
PARAMETER ESTIMATION 
Another important topic in mathematical modeling is the ability to estimate 
the orders (not the exact numbers) of certain quantities. If we know the order 
of a quantity and its range of variations, we can choose the right scales to 
write the mathematical model in the nondimensional form so that the right 
mathematical methods can be used to tackle the problem. It also helps us to 
choose more suitable numerical methods to find the solution over the correct 
scales. The estimations will often give us greater insight into the physical 
process, resulting in more appropriate mathematical models. 
■ EXAMPLE 2.2 
We now try to carry out an estimation of the Earth's surface temperature 
assuming that the Earth is a spherical black body. The incoming energy 
from the Sun on the Earth's surface is 
Ein = (1 - a)7Tr%S, 
(2.2) 
where a is the albedo or the planetary reflectivity to the incoming solar 
radiation, and a « 0.3. In addition, the total solar irradiance on the 
Earth's surface (S) is about S = 1367 W/m2. TE is the radius of the 
Earth. Here the effective area of receiving sunlight is equivalent to the 
area of a disk nrE as only one side of the Earth is constantly facing 
the Sun. A body at an absolute temperature T will have black-body 
radiation and the total energy Eb emitted by the object per unit area 

2.3 PARAMETER ESTIMATION 
29 
per unit time obeys the Stefan-Boltzmann law 
Eb = σΤ\ 
(2.3) 
where σ = 5.67 x 10 - 8 J/K4 s m2 is the Stefan-Boltzmann constant. 
For example, we know a human body has a typical body temperature of 
Th = 36.80C or 273 + 36.8 = 309.8 K. An adult in an environment with a 
constant room temperature T0 = 2O0C or 273 + 20 = 297 K will typically 
have a skin temperature Ts « (Th + Γ0)/2 = (36.8 + 20)/2 = 28.40C or 
273 + 28.4 = 301.4 K. In addition, an adult can have a total skin surface 
area of about A = 1.8 m2. Therefore, the total energy per unit time 
radiated by an average adult is 
E = A(aTf - σΤ2) = Ασ(Γ4 - Γ4) 
= 1.8 x 5.67 x 10 - 8 x (301.44 - 2974) « 90 J/s, 
(2.4) 
which is about 90 watts. This is very close to the power of a 100-watt 
light bulb. 
For the Earth system, the incoming energy must be balanced by the 
Earth's black-body radiation 
Eout = ΑσΤΕ = 4πΓ|σΓ|, 
(2.5) 
where TE is the surface temperature of the Earth, and A = 4nrE is the 
total area of the Earth's surface. Here we have assumed that outer space 
has a temperature TO ~ 0 K, though we know from the cosmological 
background radiation that it has a temperature of about 4 K. However, 
this has little effect on our estimations. 
From Em = -E0ut, we have 
(1 - a)7tr2
ES = 4irr2
EaTE, 
(2.6) 
or 
4σ 
Plugging in the typical values, we have 
Ts=ti^. 
(2-7) 
_ 
(1 - 0.3) x 1367 _ 
TE ~ V 4X5.67X10- 8 * 2 5 5 K ' 
(2"8) 
which is about — 180C. This is too low compared with the average tem-
perature 90C or 282 K on the Earth's surface. The difference implies that 
the greenhouse effect of the CO2 is in the atmosphere. The greenhouse 
gas warms the surface by about 270C. 

30 
CHAPTER 2. MATHEMATICAL MODELING 
You may argue that the difference may also come from the heat flux from the 
lithosphere to the Earth surface, and the heat generation in the crust. That 
is partly true, but the detailed calculations for the greenhouse effect are far 
more complicated, and still form an important topic of active research. 
Let us look at an example of Stokes' law which is very important for mod-
eling physical processes such as sedimentation and viscous flow. 
■ EXAMPLE 2.3 
For a sphere of radius r and density ps falling in a fluid of density pj (see 
Fig. 2.3), the frictional/viscous resistance or drag is given by Stokes' law 
F u p = βπμυτ, 
(2.9) 
where μ is the dynamic viscosity of the fluid, v is the velocity of the 
spherical particle. The driving force Fdown of falling is the difference 
between the gravitational force and the buoyant force or buoyancy. That 
is the difference between the weight of the sphere and the weight of the 
displaced fluid by the sphere (with the same volume). We have 
4npsgr3 
4npfgr3 
4π(ρ3 - 
pf)gr3 
-fdown = — Ö 
Ö — — 
Ö 
, 
( Λ ι υ ; 
where g is the acceleration due to gravity. 
The falling particle will reach a uniform velocity vs, called the termi-
nal velocity or settling velocity, when the drag F u p is balanced by id o w n, 
or F u p = Fdown- We have 
4n(ps - 
pf)gr3 
6wpvsr = 
™ 
, 
(2.11) 
which leads to 
Vs = 2(ps-pf)gr* = (p. - pf)g<P 
9μ 
18μ 
where d — 2r is the diameter of the particle. 
We know that the typical size of sand particles is about 0.1 mm 
=10 - 4 m. Using the typical values of ps = 2000 kg/m3, pf = 1000 
kg/m3, g = 9.8 m/s2, and μ = 10~3 Pa s, we have vs « 0.5 x 10~2 
m/s = 0.5 cm/s. Any flow velocity higher than vs will result in sand 
suspension in water and long-distance transport. 
Stokes' law is valid for laminar steady flows with very low Reynolds 
number Re, which is a dimensionless number, and is usually defined as 
Re = pfvd/μ = vd/v, where μ is the viscosity or dynamic viscosity, and 
v = μ/ρ/ is called the kinematic viscosity. 
Stokes' law is typically for 
a flow with Re < 1, and such flow is often called the Stokes flow. 

2.4 MATHEMATICAL MODELS 
31 
Figure 2.3 
Settling velocity of a spherical particle. 
Prom (2.12), we can see that if ps < p/, then the particle will move up. 
When you pour some champagne or sparkling water in a clean glass, you 
will notice a lot of bubbles of different sizes moving up quickly. The size 
of a bubble will also increase as it moves up; this is due to the pressure 
decrease and the nucleation process. Large bubbles move faster than 
smaller bubbles. If we consider a small bubble with negligible change in 
size, we can estimate the velocity of the bubbles. The dynamic viscosity 
and density of champagne are about 1.5 x 10~3 Pa s and 1000 kg/m3, 
respectively. For simplicity, we can practically assume the density of the 
bubbles is zero. For a bubble with a radius of r — 0.1 mm or diameter 
d = 0.2 mm =2 x 10~4 m, its uprising velocity can be estimated by 
-4\2 
(1000 - 0) x 9.8(2 x 1Q-4) 
18 x 1.5 x 10-3 
0.015 m/s = 1.5 cm/s. 
(2.13) 
Of course the choice of typical values is important in order to get a valid 
estimation. Such a choice will depend on the physical process and the scales 
of interest. The right choice will be perfected by expertise and practice. We 
will give many worked examples like this in this book. 
2.4 
MATHEMATICAL MODELS 
2.4.1 
Differential Equations 
The first step of the mathematical modeling process produces some mathe-
matical equations, often partial differential equations. The next step is to 
identify the detailed constraints such as the proper boundary conditions and 
initial conditions so that we can obtain a unique set of solutions. For the sugar 
diffusion problem discussed earlier, we cannot obtain the exact solution in the 
actual domain inside the water-filled glass, because we need to know where 
the sugar cube or grains were initially added. The geometry of the glass also 
needs to be specified. In fact, this problem needs numerical methods such as 
finite element methods or finite volume methods. The only possible solution is 

32 
CHAPTER 2. MATHEMATICAL MODELING 
the long-time behavior: when t —> oo, we know that the concentration should 
be uniform c(z, t —■> oo) —> CQO (=mass of sugar added/volume of water). 
You may say that we know this final state even without mathematical equa-
tions, so what is the use of the diffusion equation? The main advantage is 
that you can calculate the concentration at any time using the mathematical 
equation with appropriate boundary and initial conditions, either by numer-
ical methods in most cases or by mathematical analysis in some very simple 
cases. Once you know the initial and boundary conditions, the whole system 
history will be determined to a certain degree. The beauty of mathematical 
models is that many seemingly diverse problems can be reduced to the same 
mathematical equation. For example, we know that the diffusion problem 
is governed by the diffusion equation | | = DV2c. 
The heat conduction is 
governed by the heat conduction equation 
S 
= KV2T, 
κ=—, 
(2.14) 
at 
pcp 
where T is temperature and κ is the thermal diffusivity. K is thermal con-
ductivity, p is the density and cp is the specific heat capacity. Similarly, the 
dissipation of the pore pressure p in poroelastic media is governed by 
^ 
= cvV2
P, 
(2.15) 
where cv = k/(Sp) 
is the consolidation coefficient, k is the permeability of 
the media, μ is the viscosity of fluid (water), and S is the specific storage 
coefficient. 
Mathematically speaking, whether it is concentration, temperature or pore 
pressure, it is the same dependent variable u. Similarly, it is just a constant κ 
whether it is the diffusion coefficient D, the thermal diffusivity a or the con-
solidation coefficient cv. In this sense, the above three equations are identical 
to the following parabolic partial differential equation 
^ 
= KV2U. 
(2.16) 
Suppose we want to solve the following problem. For a semi-infinite domain 
shown in Figure 2.4, the initial condition (whether temperature or concentra-
tion or pore pressure) is u(x, t = 0) = 0. The boundary condition at x = 0 
is that u(x — 0, t) = UQ =const at any time t. Now the question what the 
distribution of u versus x at t is? 
Let us summarize the problem. As this problem is one-dimensional, only 
the x-axis is involved, and it is time-dependent. So we have 
9u 
d2u 
ln n _. 
l
H
=
^
 
( 2 ·
1 7 ) 

2.4 MATHEMATICAL MODELS 
33 
with an initial condition 
and the boundary condition 
u(x,t = 0) = 0, 
u(x = 0,t) = UQ. 
(2.18) 
(2.19) 
Let us start to solve this mathematical problem. How should we start and 
where to start? Well, there are many techniques to solve these problems, in-
cluding the similarity solution technique, Laplace's transform, Fourier's trans-
form, separation of variables and others. 
Similarity variable is an interesting and powerful method because it neatly 
transforms a partial differential equation (PDE) into an ordinary differential 
equation (ODE) by introducing a similarity variable ζ, then you can use the 
standard techniques for solving ODEs to obtain the desired solution. We first 
define a similar variable 
< = £· 
(220) 
so that u(x,t) = η(ζ) = /(C)· Using the chain rules of differentiations 
d__ _d_ac _ ^_d_ 
dx ~ θζοχ ~ 2κί3ζ' 
d2 _ (^_\2&_ 
J_d_ 
C d2 
+ i a 
dx2 
\2KtJ 
δζ2 
2κίθζ 
KtdC,2 
2ntdQ 
d __ d 3ζ _ 
x2 
Θ _ 
ζ d 
dt ~ dQdt ~ 
4κί2δζ 
~ 
t θζ' 
we can write the PDE (2.17) for u as 
c / ' 
Lt» + -Lf' 
KtJ 
2KV . 
where / ' = df/άζ. Multiplying both sides by t/ζ, 
-r - /"(o + γζί', 
or 
r 
/' 
■(ι+έ)· 
(2.21) 
(2.22) 
(2.23) 
Using (In / ' ) ' = / " / / ' a nd integrating the above equation once, we get 
ln/' = -C-£ln< + C, 
(2.24) 
where C is an integration constant. This can be written as 
Κβ~ζ 
r 
vc 
(2.25) 

34 
CHAPTER 2. MATHEMATICAL MODELING 
U=UQ 
it(Ä,i=d>=o 
Figure 2.4 
Heat transfer through a semi-infinite medium near a dyke 
in geology. 
where K = ec. Integrating it again, we obtain 
u = /(C) = Αβτϊ (y/ξ) +B = Aed(-ß=) 
+ B, 
where 
erf(s) 
_2 
7* 
π Jo 
άξ, 
(2.26) 
(2.27) 
is the error function and ξ is a dummy variable. A = K^pn and B are constants 
that can be determined from appropriate boundary conditions. This is the 
basic solution in the infinite or semi-infinite domain. The solution is generic 
because we have not used any of the boundary conditions or initial conditions. 
■ EXAMPLE 2.4 
For the heat conduction problem near a magma dyke in a semi-infinite 
domain, we can determine the constants A and B. Let x = 0 be the 
center of the rising magma dyke so that its temperature is constant at 
the temperature uo of the molten magma, while the temperature at the 
far field is u = 0 (as we are only interested in the temperature change 
in this case). 
The boundary condition at x = 0 requires that 
i4erf(0) + S = u0· 
We know that erf(O) = 0, this means that B 
condition u(x, t = 0) = 0, we have 
UQ. From the initial 
A lim erf ( , 
) + u0 = 0. 

2.4 MATHEMATICAL MODELS 
35 
>u/u0 
i = 50 
0 
1
2 
3 
4 
5 
Figure 2.5 
Distribution of u(x, i)/uo with κ = 0.25. 
Since Χ/Λ/ΑΚΪ 
—* co as t —» 0 and erf(oo) = 1, we get ^4 + UQ = 0, or 
Λ = — UQ. Thus the solution becomes 
u = uo 1 — erf (—== ) = uoerfc ( 
V \/4κ,ί / J 
V 
X 
lint' 
where erfc(a;) = 1 — erf(x) is the complementary error function. The 
distribution of U/UQ is shown in Fig. 2.5. 
From the above solution, we know that the temperature variation becomes 
significant in the region of x = d such that d/λ/κϊ « 1 at a given time t. That 
is 
d = V/ci, 
(2.28) 
which defines a typical length scale. Alternatively, for a given length scale d 
of interest, we can estimate the time scale t = τ at which the temperature 
becomes significant. That is 
d2 
τ = — . 
(2.29) 
This means that it will take four times longer if the size of the hot body d is 
doubled. 
Now let us see what it means in terms of typical cooling time of a geological 
object. We know that the thermal conductivity is K « 3 W/m K for rock, 
its density is p w 2700 kg/m3 and its specific heat capacity cp « 1000 J/kg 
K. Thus, the thermal diffusivity of solid rock is 
K_ 
pcp 
2700 x 1000 
1.1 x 10"6 m2/s. 
(2.30) 

36 
CHAPTER 2. MATHEMATICAL MODELING 
For d « 1 m, the time scale of cooling is 
d2 
1 
T = — « 
s sa 8.8 x 105 seconds « 10 days. 
(2.31) 
K 
1.1 x 10"6 
J 
v 
; 
For a larger hot body d = 100 m, then that time scale is r = 105 days or 
270 years. This estimate of the cooling time scale is based on the assumption 
that no more heat is supplied. However, in reality, there is usually a vast 
magma reservoir below to supply hot magma constantly, and this means that 
the cooling time is at the geological time scale over millions of years. 
2.4.2 
Functional and Integral Equations 
Though most mathematical models are written as partial different equations, 
however, sometimes it might be convenient to write them in terms of integral 
equations, and these integral forms can be discretized to obtained various 
numerical methods. For example, the Fredholm integral equation can be 
generally written as 
u{x) + λ f K(x, η)ν{η)άη = v{x)y{x), 
(2.32) 
Ja 
where u{x) and v(x) are known functions of x, and λ is constant. The kernel 
Κ(χ,η) 
is also given. The aim is to find the solution y{x). 
This type of 
problem can be extremely difficult to solve and analytical solutions exist in 
only a few very simple cases. 
Sometimes the problem you are trying to solve does not give a mathematical 
model in terms of dependent variance such as u which is a function of spatial 
coordinates (x, y, z) and time t, rather they lead to a functional (or a function 
of the function u); this kind of problem is often linked to the calculus of 
variations. 
For example, finding the shortest path between any given points on the 
Earth's surface is a complicated geodesic problem. If we idealize the Earth's 
surface as a perfect sphere, then the shortest path joining any two different 
points is a great circle through both points. How can we prove this is true? 
Well, the proof is based on the Euler-Lagrange equation of a functional ψ{ιι) 
δφ 
d dip 
du 
dx du' 
where u a function of x, u' = du/dx, and ψ a function of u{x). Interested 
readers can refer to more advanced literature. 
2.4.3 
Statistical Models 
Both differential equations and integral equations are the mathematical mod-
els for continuum systems. Other systems are discrete and different math-
(2.33) 

2.4 MATHEMATICAL MODELS 
37 
ematical models are needed, though they could reduce to certain forms of 
differential equations if some averaging is carried out. On the other hand, 
many systems have intrinsic randomness, thus the description and proper 
modeling require statistical models. 
For example, in order to describe a drop of ink in a water tank or sugar in 
a tea cup, we can use a diffusion equation discussed earlier. Alternatively, we 
can also use Brownian motion which is a random walk. 
A random walk is a random process which consists of taking a series of 
consecutive random steps. Mathematically speaking, let SN denotes the sum 
of each consecutive random step Xi, then SN forms a random walk 
N 
SN = J2xi = X1 + ... + XN, 
(2.34) 
i=l 
where Xi is a random step drawn from a random distribution. This relation-
ship can also be written as a recursive formula 
J V - l 
SN = 22 +XN = SN-I + XN, 
(2.35) 
2 = 1 
which means the next state SN will only depend the current existing state 
SN-I 
and how the motion or transition XN from the existing state to the 
next state. This is typically the main property of a Markov chain. 
Here the step size or length in a random walk can be fixed or varying. Ran-
dom walks have many applications in physics, economics, statistics, computer 
sciences, environmental science and engineering. 
Consider a scenario: A drunkard walks on a street. At each step, he can 
randomly go forward or backward. This forms a one-dimensional random 
walk. If this drunkard walks on a football pitch, he can walk in any direction 
randomly. This becomes a 2D random walk. Mathematically speaking, a 
random walk is given by the following equation 
St+i=St+wt, 
(2.36) 
where St is the current location or state at t, and wt is a step or random 
variable with a known distribution. 
A particle can jump to the right or the left with equal probability 1/2, and 
each jump can only take one step only. This jump probability, often called 
transition probability, can be written as 
fl/2 ifS = +l 
wt = < 1/2 if S = - l . 
(2.37) 
10 
otherwise 

38 
CHAPTER 2. MATHEMATICAL MODELING 
Figure 2.6 
Random walk and the path of 100 consecutive 
steps staring at position 0. 
A particle starting at So = 0 jumps along a straight line; let us follow its 
first few steps. Suppose if we flip a coin, the particle moves to the right (or 
up) if it is a head; otherwise, the particle moves to the left (or down) when 
the coin is a tail. First, we flop the coin, and we get, say, a head. So the 
particle moves to the right by a fixed unit step. So Si = So + 1 = 1. Then, 
a tail leads a move to the left, that is, S2 = Si — 1 — 0. By flipping the coin 
again, we get a tail. So S3 = S2 — 1 = — 1. We continue the process in the 
similar manner, and the path of 100 steps or jumps is shown in Figure 2.6. It 
has been proved theoretically that the probability of returning to the origin 
or reaching any point approaches 1 when the number N of steps approaches 
infinity. 
Suppose the probability of moving to the right is p, and thus the probability 
of moving to the left is q = 1 — p. The probability of taking k steps to the 
right among N steps obeys the binomial distribution 
p{k-N,p)=(^jpk{l-p)N-k. 
(2.38) 
It leaves as exercises to show that the mean number of steps to the right is 
the mean 
(k) = pN, 
(2.39) 
which means the mean number of steps to the left is simply N — pN = 
(1 — p)N — qN. The variance associated with k is 
σ\ = p(l - p)N = pqN. 
(2.40) 

2.4 MATHEMATICAL MODELS 
39 
Figure 2.7 
Brownian motion in 2D: random walk with 
a Gaussian step-size distribution and the path of 100 steps 
starting at the origin (0,0) (marked with ·). 
As time increases, the number of steps also increases. That is N = t if each 
step or jump takes a unit time. This means that the variance increases linearly 
with t, or 
σ2 ex t. 
(2.41) 
If each step or jump is carried out in the n-dimensional space, the random 
walk discussed earlier 
N 
SN = J2Xi, 
(2.42) 
i=\ 
becomes a random walk in higher dimensions. In addition, there is no reason 
why each step length should be fixed. In fact, the step size can also vary 
according to a known distribution. If the step length obeys the Gaussian 
distribution, the random walk becomes the Brownian motion (see Figure 2.7). 
Similar to the one-dimensional case, the variance σ2 also increases linearly 
with time t or the total number of steps N. 
In theory, as the number of steps N increases, the central limit theorem im-
plies that the random walk (2.42) should approaches a Gaussian distribution. 
As the mean of particle locations shown in Figure 2.7 is obviously zero, their 
variance will increase linearly with t. Therefore, the Brownian motion B(t) 
essentially obeys a Gaussian distribution with zero mean and time-dependent 
variance. That is, 
Β(ί)~7ν(0,σ 2 = ί), 
(2.43) 

40 
CHAPTER 2. MATHEMATICAL MODELING 
where ~ means the random variance obeys the distribution on the right-hand 
side, or samples should be drawn from the distribution. The diffusion process 
can be viewed as a series of Brownian motion, and the motion obeys the 
Gaussian distribution. For this reason, standard diffusion is often referred to 
as the Gaussian diffusion. If the motion at each step is not Gaussian, then 
the diffusion is called non-Gaussian diffusion. 
2.4.4 
Rule-based Models 
Sometimes, a mathematical model can be more conveniently expressed as a set 
of rules. For example, cellular automata are a class of rule-based models. In 
a very simple case, a cellular automaton can be represented on a 2D grid, and 
each cell has 8 neighbor cells. The state (say, 0 or 1) of each cell will depend 
on a set of rules, and thus depends on the states of its neighbor cells and its 
current state. The well-known "game of life" often used in many computer 
Screensavers, is a cellular automaton. In fact, it has been proved that a cellular 
automaton can act as a universal computing machine, capable of carrying out 
very complex computations and simulating real-world phenomena. 
In physics and fluid dynamics, the so-called Lattice-Boltzmann method is 
an extension of the basic cellular automaton ideas. In modern metaheuris-
tics, rule-based algorithms can solve complex optimization problems using 
inspiration from nature.1 
2.5 
NUMERICAL METHODS 
2.5.1 
Numerical Integration 
In the solution (2.26) of problem (2.17), there is a minor problem in the 
evaluation of the solution u. That is the error function erf(x) because it is 
a special function whose integral cannot be expressed as a simple explicit 
combination of basic functions, and it can only be expressed in terms of a 
quadrature. In order to get its values, we have to either use approximations 
or numerical integration. You can see that even with a seemingly precise 
solution of a differential equation, it is quite likely that it may involve some 
special functions. 
Let us try to evaluate erf (1). From advanced mathematics, we know its ex-
act value is erf(l) = 0.8427007929..., but how do we calculate it numerically? 
■ EXAMPLE 2.5 
1Xin-She Yang, Nature-Inspired Metaheuristic Algorithms, Luniver Press, UK. First Edi-
tion (2008), 2nd Edition (2010). 

2.5 NUMERICAL METHODS 
41 
In order to estimate erf(l), we first try to use a naive approach by 
estimating the area under the curve f(x) = -j=e~x in the interval [0,1] 
shown in Figure 2.8. We then divide the interval into 5 equally spaced 
thin strips with h = Ax = Xi+\ — Xi = 1/5 = 0.2. We have six values of 
fi — f(xi) at Xi = hi(i = 0,1,..., 5), and they are 
/o = 1.1284, h = 1.084, f2 = 0.9615, 
h = 0.7872, U = 0.5950, / 5 = 0.4151. 
Now we can either use the rectangular area under the curve (which 
underestimates the area) or the area around the curve plus the area 
under curve (which overestimates the area). Their difference is the tiny 
area about the curve which could still make some difference. If we use 
the area under the curve, we have the estimation of the total area as 
Αχ « 0.2(/i + h + h + h + h) w 0.7686. 
The other approach gives 
A2 « 0.2(/0 + /i + h + h + h) « 0.91125. 
Both are about 8% from the true value erf(l) « 0.8247. If we take the 
average of these two estimates, we get 
A, « ^ ± ^ 
« 0.8399, 
which is much better, but still 0.3% from the true value. This average 
method is essentially equivalent to using /, = (/j_i + /i)/2 to approxi-
mate the value of f(x) in each interval. 
As you can see from this example, the way you discretize the integrand to 
estimate the integral numerically can have many variants, subsequently af-
fecting the results significantly. There are much better ways to carry out the 
numerical integration, notably the Gaussian integration which requires only 
seven points to get the accuracy of about 9th decimal place or 0.0000001%. 
As this book focuses mainly on the model formulation, interested readers can 
refer to an advanced book on numerical methods for more details. 
2.5.2 
Numerical Solutions of PDEs 
The diffusion equation (2.1) is a relatively simple parabolic equation. If we 
add a reaction term (source or sink) to this equation, we get the classical 
reaction-diffusion equation 
^ = £ > V 2 u + 7 u ( l - u ) , 
(2.44) 

42 
CHAPTER 2. MATHEMATICAL MODELING 
f(*)=lke~ 
- 1 
0 
1 
Figure 2.8 
Naive numerical integration. 
where u can be concentration and any other quantities. ηη{\ — u) is the re-
action term and 7 is a constant. This seemingly simple partial differential 
equation is in fact rather complicated for mathematical analysis because the 
equation is nonlinear due to the term — -yu2. However, a numerical technique 
can be used and it is relatively straightforward to obtain solutions. This math-
ematical model can produce intriguing patterns due to its intrinsic instability 
under appropriate conditions. 
In the two-dimensional case, we have 
du _ nfd2u 
d2u 
dt 
\ dx2 
dy2 } +7u(l —u). 
(2.45) 
Using the finite difference method to be introduced in the next chapter, we 
can solve this equation on a 2D domain. Figure 2.9 shows the stable pattern 
generated by Eq.(2.45) with D = 0.2 and 7 = 0.5. The initial condition is 
completely random, say, u(x, y, t=Q) =rand(n, n) £ [0,1] where n x n is the size 
of the grid used in the simulations. The function rand() is a random number 
generator and all the random numbers are in the range of 0 to 1. 
We can see that a beautiful and stable pattern forms automatically from 
an initially random configuration. This pattern formation mechanism has 
been used to explain many pattern formation phenomena in nature, including 
patterns on zebra skin, tiger skin and sea shell, zebra leaf (green and yellow), 
and zebra stones. For example, the zebra rocks have reddish-brown and white 
bands first discovered in Australia. It is believed that the pattern is generated 
by dissolution and precipitation of mineral bands such as iron oxide as mineral 
in the fluid percolating through the porous rock. 
In the second part of this book, we will introduce in detail various math-
ematical model formulations and analysis of many processes and phenomena 
in real-world applications. 

EXERCISES 
43 
Figure 2.9 
Pattern formation of reaction-diffusion equation (2.45) 
with D = 0.2 and 7 = 0.5. 
EXERCISES 
2.1 
From the first principle and theory of gravitation, estimate the escape 
velocity of a satellite. 
2.2 
Estimate the velocity of a rain drop, assuming the size of a drop is 
between 0.1 mm to 0.55 cm. 
2.3 
For water waves in a lake or ocean, the phase speed or velocity v in 
most cases is governed by 
where h is the water depth, λ is the wavelength of the waves, and g is the 
acceleration due to gravity. Estimate the velocity of a typical tsunami. 
2.4 
Assume the air pressure is hydrostatic and air is an ideal gas, estimate 
the pressure variations versus altitude. 

44 
CHAPTER 2. MATHEMATICAL MODELING 
REFERENCES 
1. Fowler, A. C , Mathematical Models in the Applied Sciences, Cambridge Uni-
versity Press, Cambridge (1997). 
2. Gershenfeld, N., Nature of Mathematical Modeling, Cambridge University Press, 
Cambridge (1998). 
3. Kardestruncer, H. and Norrie, D. H., Finite Element Handbook, McGraw-Hill, 
New York (1987). 
4. Kreyszig, E., Advanced Engineering Mathematics, 6th Edition, Wiley & Sons, 
New York (1988). 
5. Murch, B. W. and Skinner, B. J., Geology Today - Understanding Our Planet, 
John Wiley & Sons, New York (2001). 
6. Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P., Numerical 
Recipes in C++: The Art of Scientific Computing, 2nd Edition, Cambridge 
University Press, Cambridge (2002). 
7. Smith, G. D., Numerical Solution of Partial Differential Equations, Oxford Uni-
versity Press, Oxford (1974). 
8. Wang H. F., Theory of Linear Poroelasticity: With Applications to Geomechan-
ics and Hydrogeology, Princeton University Press, New Jersey (2000). 

CHAPTER 3 
NUMERICAL METHODS: AN 
INTRODUCTION 
XIN-SHE YANG 
School of Science and Technology, Middlesex University, London, UK 
Because it is not always possible to solve differential equations analyti-
cally, numerical methods have become an important tool in modeling and 
simulation. In fact, computational modeling has become the so-called third 
paradigm, complementing the tradition theoretical and experimental approaches 
to problem solving. Among many powerful numerical methods, the finite dif-
ference method is one of the most popular methods that are used commonly 
in computer simulations. It has the advantage of simplicity and clarity, espe-
cially in ID configurations and other cases with regular geometry. The finite 
difference method essentially transforms an ordinary differential equation into 
a coupled set of algebraic equations by replacing the continuous derivatives 
with finite difference approximations on a grid of mesh or node points that 
span the domain of interest based on the Taylor series expansions. In general, 
the boundary conditions and boundary nodes need special treatment. 
Mathematical Modeling with Multidisciplinary Applications. 
45 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

46 
CHAPTER 3. NUMERICAL METHODS: AN INTRODUCTION 
3.1 
DIRECT INTEGRATION 
The second-order or higher-order ordinary differential equations can be writ-
ten as a first-order system of ODEs. Since the technique for solving a system 
is essentially the same as that for solving a single equation 
| 
= /(*,y), 
(3-D 
we shall focus on the first-order equation in the rest of this section. In prin-
ciple, the solution can be obtained by direct integration, 
y(x)=Vo+ 
f(x,y(x))dx, 
(3.2) 
but in practice it is usually impossible to do the integration analytically as 
it requires the solution of y(x) to evaluate the right-hand side. Thus, some 
approximations shall be utilized. Numerical integration is the most common 
technique for obtaining approximate solutions. There are various integration 
schemes with different orders of accuracy and convergent rates. These schemes 
include the simple Euler scheme, Runge-Kutta method, relaxation method, 
and many others. 
3.1.1 
Euler Scheme 
Using the notation h = Ax = xn+\ — xn, yn = y(xn), xn = xo + nAx (n = 
0,1,2, ...,N), 
and ' = d/dx for convenience, then the explicit Euler scheme 
can simply be written as 
pXn + l 
yn+i =yn+ 
f(x, y)dx « yn + hf(xn, yn). 
(3.3) 
This is a forward difference method as it is equivalent to the approximation 
of the first derivative 
y'n = ^
^
· 
(3-4) 
The order of accuracy can be estimated using the Taylor expansion 
h2 
2/n+i =yn + hy'\n + y2/"|n + ... « yn + hf(xn, yn) + 0(h2). 
(3.5) 
Thus, the Euler method is first-order accurate. 
For any numerical algorithms, the algorithm must be stable in order to 
reach convergent solutions. Thus, stability is an important issue in numerical 
analysis. Defining 6y as the discrepancy between the actual numerical solution 

3.1 DIRECT INTEGRATION 
47 
and the true solution of the Euler finite difference equation, we have 
6yn+1 = [1 + hf'{y)} = ξδνη. 
(3.6) 
In order to avoid the discrepancy to grow, it requires the following stability 
condition \ξ\ < 1. The stability restricts the size of interval h, which is usually 
small. 
One alternative that can use larger h is the implicit Euler scheme, and 
this scheme approximates the derivative by a backward difference y'n = (yn — 
yn-i)/h 
and the right-hand side of (3.2) is evaluated at the new yn+\ location. 
Now the scheme can be written as 
J/n+i = yn + hf(xn+i,yn+i). 
(3.7) 
The stability condition becomes 
which is always stable if f'(y) = g < 0- This means that any step size is 
acceptable. However, the step size cannot be too large as the accuracy reduces 
as the step size increases. 
Another practical issue is that, for most problems such as nonlinear ODEs, 
the evaluation of y' and f'{y) requires the value of yn+\ which is unknown. 
Thus, an iteration procedure is needed to march to a new value yn+\, and the 
iteration starts with a guess value which is usually taken to be zero for most 
cases. The implicit scheme generally gives better stability. 
3.1.2 
Leap-Frog Method 
The leap-frog scheme is the central difference 
which leads to 
Vn+l = J/n-1 + 2/l/(x„, J/„). 
(3.10) 
The central difference method is second-order accurate. In a similar way as 
Eq. (3.6), the leap-frog method becomes 
itfn+i = fyn-i + 2hf'(y)6yn, 
(3.11) 
or 
6yn+i =ξ Syn-i, 
(3.12) 

48 
CHAPTER 3. NUMERICAL METHODS: AN INTRODUCTION 
where ξ2 = 1 + 2/i/'(y)£. This scheme is stable only if |ξ| < 1, and a special 
case is \ξ\ = 1 when f'(y) is purely imaginary. Therefore, the central scheme 
is not necessarily a better scheme than the forward scheme. 
3.1.3 
Runge-Kutta Method 
We have so far seen that stability of the Euler method and the central dif-
ference method is limited. The Runge-Kutta method uses a trial step to the 
midpoint of the interval by central difference and combines with the forward 
difference at two steps 
yn+i/2 = yn + -^f(xn, yn), 
(3.13) 
Vn+i =yn + hf (xn+i/2, y„+i/2)· 
(3.14) 
This scheme is second-order accurate with higher stability compared with 
previous simple schemes. One can view this scheme as a predictor-corrector 
method. In fact, we can use multisteps to devise higher-order methods if the 
right combinations are used to eliminate the error terms order by order. The 
popular classical Runge-Kutta method can be written as 
a = 
hf(xn,yn), 
b = hf(xn + h/2,yn + a/2), 
c=hf(xn 
+ h/2,yn + b/2), 
d = hf(xn 
+ h,yn + c), 
, a + 2{b + c) + d 
yn+i = yn + 
7 
, 
(3.15) 
which is fourth-order accurate. 
■ EXAMPLE 3.1 
Let us solve the following nonlinear equation numerically 
g + , * = -!, 
*e[0,2] 
with the initial condition 
1/(0) = 1. 
We know that it has an analytical solution 
y(x) = - t a n (a:- - J . 

3.2 FINITE DIFFERENCE METHODS 
49 
On the interval [0,2], let us first solve the equation using the Euler 
scheme for h = 0.5. There are five points Xi = ih(i = 0,1,2,3,4). As 
dy/dx = f(y) = —1 — y2, we have the Euler scheme 
2/n+i = 2/n + hf(y) =yn-h- 
hy2
n. 
From the initial condition 2/0 = 15 we now have 
2/i = 2/o - h - hyl = 1 - 0.5 - 0.5 x l2 = 0, 
2/2 « -0.5, 
2/3 « -1.125, 
2/4 « -2.2578. 
These are significantly different (about 30%) from the exact solutions 
y* = i, 
y* « 0.2934079, 2/2 = -0.21795809, 
2/1 = -0.86756212, y\ = -2.68770693. 
Now let us use the Runge-Kutta method to solve the same equation to 
see if it is better. Since f(xn, 2/n) = — 1 — 2/n> w e have 
a = hf{xn, 2/n) = -h{\ + yl), 
b = -h 1 + (yn + -) 
c = —h 
and 
l + O / n + g ) 2 ] . 
d = - Ä [ l + (y„+c) 2], 
a + 2(6 + c) + d 
2/n+l = 2/n "I 
^ 
· 
From 2/o = l and h = 0.5, we have 
2/i « 0.29043, 
1/2 « -0.22062, 
2/3 = -0.87185, 
t/4 w -2.67667. 
These values are within about 1% of the analytical solutions y*. We can 
see that even with the same step size, the Runge-Kutta method is much 
more efficient and accurate than the Euler scheme. 
Generally speaking, higher-order schemes are better than lower-order schemes, 
but not always. 
3.2 
FINITE DIFFERENCE METHODS 
Numerical solutions of partial differential equations are more complicated than 
that of ODEs because they involve time and space variables and the geometry 
of the domain of interest. Usually, boundary conditions are more complex. 
In addition, nonlinear problems are very common in real-world processes. 

50 
CHAPTER 3. NUMERICAL METHODS: AN INTRODUCTION 
We start with the simplest first-order equations and then move onto more 
complicated cases. 
3.2.1 
Hyperbolic Equations 
For simplicity, we first look at the one-dimensional scalar equation of hyper-
bolic type, 
du 
du 
9i + CSi = °'
 
( 3·
1 6 ) 
where c is a constant or the velocity of advection. By using the forward Euler 
scheme for time and central scheme for space, we have 
u n+l 
At 
+ c \^±1 
*3-l 
2h 
= 0, 
(3.17) 
where t = nAt,n 
= 0,1,2,..., x = x0 + jh,j 
= 0,1,2,..., and h = Ax. 
In 
order to see how this method behaves numerically, we use the von Neumann 
stability analysis. 
Assuming the independent solutions or eigenmodes, also called Fourier 
modes, in spatial coordinate x in the form of u™ = ^ne%kh^ where k is the 
equivalent wavenumber, and substituting into Eq. (3.17), we have 
cAt 
ξ = 1 — i—— sm(kh). 
h 
The stability criteria \(\ < 1 require 
i — J sin2fc/i<0. 
(3.18) 
(3.19) 
However, this inequality is impossible to satisfy and this scheme is thus un-
conditionally unstable. 
To avoid the difficulty of instability, we can use other schemes such as 
the upwind scheme and Lax scheme. For the upwind scheme, the equation 
becomes 
At 
ui ~ 
ui-i 
h 
0, 
whose stability condition is 
\ξ\ = 
which is equivalent to 
cAt 
1 
— [1 — cos(kh) + isin(kh)] 
r, 
CAt 
0< -— < 1. 
h 
< 1 , 
(3.20) 
(3.21) 
(3.22) 

initial wave 
3.2 FINITE DIFFERENCE METHODS 
51 
traveling wave 
/ \ 
/ 
\ 
Figure 3.1 
First-order hyperbolic equation and its traveling 
wave solution ut + ux = 0. 
This the well-known Courant-Priedrichs-Lewy stability condition, often re-
ferred to as the Courant stability condition. Thus, the upwind scheme is 
conditionally stable. 
The wave propagation of the first-order hyperbolic equation can be demon-
strated by the following simple case, 
ut + ux = 0, 
0 < x < L, 
with an initial condition 
u(x, 0) 
-l(x-i)/L] 2 
-[(z-ij/L] 2 
(3.23) 
(3.24) 
and boundary conditions u(0, t) — u(L, t) = 0. 
Figure 3.1 shows the wave propagation where the dashed curve corresponds 
to the initial wave profile while the solid curve corresponds to the traveling 
wave. We can see that the wave profile does not change with time but moves 
with a constant velocity. 
3.2.2 
Second-Order Wave Equation 
Higher-order equations such as the second-order wave equation can be writ-
ten as a system of hyperbolic equations and then be solved using numerical 
integration. They can also be solved by direct discretization using the finite 
difference scheme. The wave equation 
d2u 
,d2u 
dt2 
° dx2' 
(3.25) 
consists of second derivatives. If we approximate the first derivatives at each 
time step n using 
Ax 
u{ i-l 
U'( - U, 
Ax 
i-l 
(3.26) 

52 
CHAPTER 3. NUMERICAL METHODS: AN INTRODUCTION 
initial wave 
/ 
\ 
reflected wave 
Figure 3.2 
Traveling wave solution of the wave equation: 
utt — c2uxx = 0. 
then we can use the following approximation for the second derivative 
< + 1 - 2 < + < _ ! 
Ax 
i-l 
(Ax)2 
(3.27) 
This is in fact a central difference scheme of second-order accuracy. If we use 
the similar scheme for time-stepping, then we get a central difference scheme 
in both time and space. 
Thus, the numerical scheme for this equation becomes 
<+1 - 2< + <_^ 
= c 2 < + 1 - 2 < + uU 
(At)2 
(Ax)2 
(3.28) 
This is a two-level scheme with a second-order accuracy. The idea of solving 
this difference equation is to express (or to solve) u"+1 at time step t = n + 1 
in terms of the known values or data u" and u" _ 1 at two previous time steps 
t = n and t = n — 1. 
Solving the wave equation (3.25) with the initial condition 
u(x,0) 
(3.29) 
and wave reflection boundary conditions at both ends u(—L, t) = u(L, t) — 0, 
we have the solution shown in Figure 3.2. We can see that the initial profile 
is split into two traveling waves: one travels to the left and one to the right. 
3.2.3 
Parabolic Equation 
For the parabolic equation such as the diffusion or heat conduction equation 
9u> 
du 
~dt 
d_ 
dx ( * ! ) · 
(3.30) 

3.2 FINITE DIFFERENCE METHODS 
53 
Figure 3.3 
The ID time-dependent diffusion equation: ut 
a simple Euler method for the time derivative and centered second-order ap-
proximations for space derivatives lead to 
ul+l = «? + ^ K + 1 - 2< + <_!). 
h2 
(3.31) 
From the application of von Neumann stability analysis by assuming w™ — 
£netkhj ^ ^.ne above equation becomes 
ί = ι -
4DAt sin2 I 
)· 
h2 
V 2 
The stability requirement \ξ\ < 1 leads to the constraint on the time step 
h2 
(3.32) 
Δί < 2D' 
(3.33) 
This scheme is thus conditionally stable. 
For simplicity, we consider a ID heat conduction equation 
with 
an initial condition 
u(x, 0) = [H{x - L/5) - H(x)} 
where H{x) is a Heaviside function. 
H(x) = 1, x > 0, 
H(x) = 0 
x < 0. 
The evolution of the temperature profile is shown in Figure 3.3 where the 
initial profile is plotted as a dashed curve. We can see that the profile is 
gradually smoothed out as time increases and this is the typical behavior of 
the diffusive system. The time-stepping scheme we used limits the step size 
of time as larger time steps will make the scheme unstable. There are many 
ways to improve this, and one of the most widely used schemes is the implicit 
scheme. 

54 
CHAPTER 3. NUMERICAL METHODS: AN INTRODUCTION 
To avoid the limitation due to very small time steps, we now use an implicit 
scheme for time derivative differencing, and thus we have 
DM 
*3 
~ "J 
- 
~^2~^ί"+1 
u7+1 - u7 = -T2-Wi + K + 1 + <-i)· 
(3·34) 
Applying the stability analysis, we have 
£ = -I i 4DAt„:JTkh> 
(3·35) 
1"+" h2 
S l n Ύ 
whose norm is always less than unity (\ξ\ < 1). This means the implicit 
scheme is unconditionally stable for any size of time steps. That is why 
implicit methods are more desirable in simulations. However, there is one 
disadvantage of this method, which requires more programming skills because 
the inverse of a large matrix is usually needed in implicit schemes. 
3.2.4 
Elliptical Equation 
In the parabolic equation, if the time derivative is zero or u does not change 
with time Ut — 0, then we reach a steady-state problem that is governed 
by the elliptic equation. For the steady-state heat conduction problem, we 
generally have the Poisson problem, 
V ■[«(«, a;)»,i)Vu] = / ) 
(3.36) 
If K is a constant, this becomes 
V2u = q, 
< ? = - . 
(3.37) 
K 
There are many methods available to solve this problem, such as the boundary 
integral method, the relaxation method, and the multigrid method. Two 
relevant methods are the long-time approximation of the transient parabolic 
diffusion equations, and the other includes the iteration method. 
The long-time approximation method is essentially based on the fact that 
the parabolic equation 
^ 
+ KV2U = / , 
(3.38) 
evolves with a typical scale of y/κϊ. If Λ/ΚΪ 3> 1, the system is approaching its 
steady state. Assuming t —> oo and κ » 1, we then have 
f 
1 
V2u = - - -ut -> 0. 
(3.39) 
K 
K 
In the case of κ — const, it degenerates into the above steady-state equation 
(3.36) because Ut —> 0 as t —> oo. This approximation becomes better if 

EXERCISES 
55 
« » I . 
Thus, the usual numerical methods for solving parabolic equations 
are valid. However, other methods may obtain the results more quickly. 
The iteration method uses the second-order scheme for space derivatives, 
and Eq. (3.37) in the 2D case becomes 
Ui+i,j ~ 2ujtj + Mj-i,j 
Ujij+1 -2uij+ui,j-1 
_ 
(Δχ)2 
+ 
(Ay)^ 
~*' 
{ 
' 
If we use Ax = Ay = h, then the above equation simply becomes 
(uij+i + Uij-i + tti+ij + Ui-ij) - 4uij = h2q, 
(3-41) 
which can be written as 
Au = b. 
(3.42) 
This equation can be solved using the various methods such as the Gauss-
Seidel iteration. 
EXERCISES 
3.1 
Use a four-step Runge-Kutta method to solve the following equation: 
^ 
= (x* + ex)e~*x\ 
j/(0) = 0. 
ax 
Then, compare your solution with the analytical solution 
, 5 , 
y(x) = \n(ex + 
^-), 
at x = 1. 
3.2 
Sometimes, seemingly simple equations may lead to complex behavior. 
For example, the so-called logistic differential equation 
dw/dt = aw — bw2, 
a, b > 0, 
can lead to chaotic behavor. Using an explicit Euler scheme to solve this 
equation and try to vary a and b and see what happens. 
3.3 
The Lorentz equations 
ύ = 10(υ — u), 
v = u(20 — w) — v, 
w = uv — 8w/3, 
can produce a butterfly-shaped attr actor if you plot u versus w. Write a 
simple program to solve this ODE system and plot the trajectory of u vs tu 
evolving with time. 
3.4 
Implicit schemes work better than explicit schemes. One of the well-
known schemes is the Crank-Nicolson method, which uses the central differ-

56 
CHAPTER 3. NUMERICAL METHODS: AN INTRODUCTION 
ences. For the simple heat conduction equation u t = Xuxx, 
this method can 
be written as 
" Γ
1 
- »? 
A / i f f i - 2 ^ " + 1 + u f f 
u? + 1 - 2Uj" + u U 
x 
Δ ί 
2 V 
(Ax)2 
(Ax)2 
) ' 
Show that this scheme is numerical stable and the resulting matrix system is 
tridiagonal. 
3.5 
Using an explicit finite difference method to solve the following 2D 
partial differential equation 
du 
^fd2u 
d2u\ 
., 
. 
¥ = ßte
 + v)
+7u(1"
u)· 
Visualize your solutions as a 3D landscape for the case of D — 0.2 and 7 = 0.5 
and observe what happens. 
REFERENCES 
1. Bathe, K. J., Finite Element Procedures in Engineering Analysis, Prentice Hall, 
New Jersey (1982). 
2. Cook, R. D., Finite Element Modeling For Stress Analysis, Wiley & Sons, New 
York (1995). 
3. Langtangen, H. P., Computational Partial Differential Equations: 
Numerical 
Methods and Diffpack Programming, Springer, Heidelberg (1999). 
4. Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P., Numerical 
Recipes in C++: The Art of Scientific Computing, 2nd Edition, Cambridge 
University Press, Cambridge (2002). 
5. Strang, G. and Fix, G. J., An Analysis of the Finite Element Method, Prentice-
Hall, Englewood Cliffs, New Jersey (1973). 
6. Yang, X. S., Introduction to Computational Mathematics, World Scientific Pub-
lishing, Singapore (2008). 
7. Zienkiewicz, O. C. and Taylor, R. L., The Finite Element Method, Vol. I/II, 
4th Edition, McGraw-Hill, New York (1991). 

CHAPTER 4 
TEACHING MATHEMATICAL MODELING 
IN TEACHER EDUCATION: EFFORTS 
AND RESULTS 
T H O M A S L I N G E F J Ä R D 
University of Gothenburg, Sweden 
Can mathematical modeling serve as a vehicle for the learning of math-
ematics? Mathematical modeling is mentioned in most countries' curricula, 
yet it is not as valued either in the teaching of school mathematics or in 
most of the teacher training programs the author knows of. Nevertheless, in 
mathematical modeling processes, the mathematics really comes into play and 
many mathematical modeling exercises show the importance of mathematics 
in many different ways. The purpose of this chapter is to show that also 
in mathematics education there are many different modeling activities that 
could be used. 
4.1 
INTRODUCTION 
There are many reasons to give a course on mathematical modeling to lower 
secondary and upper secondary prospective teachers. To start with, the teach-
Mathematical Modeling with Multidisciplinary Applications. 
57 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

58 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
ing of mathematical modeling might allow students to take more responsibility 
over their own learning and the teaching might be changed into a more undi-
rected teaching manner. 
The heart of applied mathematics is the injunction "Here is a situation; 
think about it." The heart of our usual mathematics teaching, on the 
other hand, is: "Here is a problem; solve it" or "Here is a theorem; 
prove it." We have very rarely, in mathematics, allowed the student to 
explore a situation for himself and find out what the right theorem to 
prove or the right problem to solve might be. [26, p. 328] 
Second, the concept of models exists in our daily language. Model and 
modeling are common expressions with many seemingly different meanings. 
We are introduced to new car models that we are supposed to feel attracted 
to, to picture ourselves in possession of the new car. Architects use models of 
a landscape or a house to illustrate a product they want to sell. In the fashion 
industry, a model is a person who wears clothes that other people watching 
can imagine themselves wearing. Fashion models are selected because they 
possess certain idealized human characteristics, which change from time to 
time but always refer to ideals such as thinness, height, skin color, and atti-
tude. Children use many models of reality in their toy cars, dolls, trains, and 
so forth. All modeling activities have at least two aspects in common: They 
use a model in order to think about or introduce the related reality, and the 
model is something more or less idealized or simplified. 
Third, the concept of mathematical modeling is mentioned in most coun-
tries' curricula as something which should be taught at least in secondary 
schools. 
The Swedish school should, in its teaching of mathematics, strive for 
that students in projects and in group discussion develop their con-
ceptual capacity and that they learn how to formulate and motivate 
different methods for solving mathematical problems. 
They should also develop their aptitude to give shape to, refine, and use 
mathematical models together with a critical estimation of the model's 
conditions, possibilities and limitations. [27, p. 2, my translation] 
A national statement like this addresses many questions, including how to 
prepare prospective secondary school mathematics teachers to function in an 
environment where teaching and learning are characterized by processes and 
activities. The statement further gives a reflection in how to look upon teach-
ing and learning in mathematics. More and more policy documents around 
the globe talk about quality in mathematical knowledge and of mathematical 
competencies. For example, Ref. [28] emphasizes that our thinking on learn-
ing maybe rooted simultaneously in two different conceptual domains: 

4.1 INTRODUCTION 
59 
"On the one hand, there is the view of learning as an acquisition of 
some property: and on the other hand there is the idea of learning as 
becoming a participant in a certain practice or discourse". [28, p. 120, 
italics in original]. 
For many teachers mathematical modeling is probably easy to confuse with 
problem solving. Problem solving in mathematics can be seen as applying 
to either specific problems within mathematics, so-called pure mathematics, 
or to problems outside mathematics where the field often is called applied 
mathematics. The process of mathematical modeling also has a variety of 
definitions. As used in secondary mathematics, it ordinarily entails taking a 
situation, usually one from the real world, and using variables and one or more 
elementary functions that fit the phenomena under consideration to arrive at 
a conclusion that can then be interpreted in light of the original situation. 
Ref. [28] argued that we seldom challenge students to study a situation and 
try to make a model of it for analyzing the situation. 
A carefully organized course in mathematics is sometimes too much like a 
hiking trip in the mountains that never leaves the well-worn trails. The tour 
manages to visit a steady sequence of the "high spots" of the natural scenery. 
It carefully avoids all false starts, dead-ends, and impossible barriers, and 
arrives by five o'clock every afternoon at a well-stocked cabin. The order 
of difficulty is carefully controlled, and it is obviously a most pleasant way 
to proceed. However, the hiker misses the excitement of risking an enforced 
camping out, of helping locate a trail, and of making his way cross-country 
with only intuition and a compass as a guide. "Cross-country" mathematics 
is a necessary ingredient of a good education. (26, p. 329) 
Prospective teachers need to understand a great variety of topics and ap-
proaches in mathematics. Today these topics include concepts, principles, 
methods, and procedures that were not traditionally part of school or college 
mathematics but that many secondary school students may now address very 
well through the use of computers and graphing calculators. Applied math-
ematics as a field, and the process of mathematical modeling in particular, 
is one part of the mathematical curriculum that may be broadened and en-
hanced through the use of technology. Henry Pollak's vision of cross-country 
mathematics may very well be helped by the presence of technology, since so 
much of the tedious routine calculations today can be done by the technology 
and much more open-ended problems can be modelled. 
For at least three decades, many authors with different perspectives have 
discussed the role of applications and modeling in the curriculum. The 1979 
yearbook of the National Council of Teachers of Mathematics (NCTM), Ap-
plications in School Mathematics, contains articles illustrating the variety of 
those perspectives [22]. In recent years, interest in mathematical modeling 
has increased among mathematics educators. The Curriculum and Evaluation 
Standards for School Mathematics (NCTM, 1989), for example, stressed its 
importance [23]. Given the potential value of technology for enhancing learn-

60 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
ing, students can undertake some realistic modeling problems and thereby de-
velop their ideas about and their understanding of mathematics. The intent 
of the NCTM's recommendations regarding the curriculum is that through 
a consideration of real-world problems—problems that capture students' in-
terest and that might readily arise in daily life—students will gain both an 
appreciation of the power of mathematics and some essential mathematical 
skills. In the report Heeding the Call for Change (Steen, 1992), published by 
the Mathematical Association of America, a group of collegiate mathematics 
educators suggested that "the key [in selecting such problems] is to have the 
contexts relate to students' interest, daily life, and likely work settings" [30, 
p. 100]. 
There are obviously various arguments as to why applications and modeling 
belong in the curriculum. Blum and Niss ([1], p. 5) define five arguments 
that I have termed as follows: formative, critical, practical, cultural, and 
instrumental. 
Applications and modeling should be part of the mathematics curriculum 
in order to: 
1. Foster among students general creative and problem solving attitudes, 
activities and competences. 
2. Generate, develop and qualify a critical potential in students towards 
the use (and misuse) of mathematics in extra-mathematical contexts. 
3. Prepare students to being able to practice applications and modeling—in 
other teaching subjects; as private individuals or as citizens, at present 
or in the future; or in their professions. 
4. Establish a representative and balanced picture of mathematics, its char-
acter and role in the world. Such a picture must encompass all essential 
aspects of mathematics, and the application of mathematics and math-
ematical modeling in other areas do form one such aspect. 
5. Assist students' acquisition and understanding of mathematical con-
cepts, notions, methods, results and topics, either to give a fuller body 
to them, or to provide motivation for the study of certain mathematical 
disciplines. [1, pp. 23-24] 
4.2 
THEORETICAL FRAMEWORKS CONNECTED TO 
MATHEMATICAL MODELING 
There are of course almost unlimited numbers of different theoretical frame-
works which could be used to analyze and evaluate learning when students are 
involved in a mathematical modeling process. Since nearly every mathemat-
ical modeling process is accompanied or supported by technology, there are 

4.2 THEORETICAL FRAMEWORKS 
61 
good reasons why we could start with sociocultural theory. One of the funda-
mental concepts of sociocultural theory is the claim that the human mind is 
mediated. Vygotsky [32] claimed that tools play a significant role for humans' 
understanding of the world and advocated that humans do not act directly 
on the physical world without the intermediary of tools. We use symbolic 
tools or signs, and tools are artifacts created by humans under specific cul-
tural (culture specific) and historical conditions, and as such they carry with 
them the characteristics of that culture. Tools and artifacts are used as aids 
in solving problems that cannot be solved in the same way in their absence. 
Furthermore, they also exert an influence on the individuals who use them in 
that they give rise to previously unknown activities and previously unknown 
ways of conceptualizing phenomena in the world. 
4.2.1 
Instrumental Competence 
The rapid development of new technologies manufactures sophisticated, com-
plex instruments that offer quite new challenges and possibilities to their users. 
Consequently, we think of technology in new and more theoretical ways. When 
technological tools become more and more sophisticated, the relation between 
a user and the tool (the instrument) also becomes more and more complicated 
and sophisticated. That relation might be seen as a manifestation of what the 
tool offers (affordance) but also of the tool's limits (constraints). Imagine a 
normal hammer with a hammerhead. The most common use for a hammer is 
for driving nails, fitting parts, forging metal and breaking up objects. No one 
would think about a hammer for making a telephone call. So when we see 
the hammer, we think about it in the frame of affordances and constraints. 
Gibson [5] defined affordances as all the "action possibilities" latent in the en-
vironment, objectively measurable, and independent of the individual's ability 
to recognize those possibilities. 
Obviously, action possibilities related to a tool are dependent on the capa-
bilities of the user and should always be measured in relation to the relevant 
users. Norman [24] talked about perceived affordance, as distinct from ac-
tual affordance. This distinction makes the concept dependent not only on 
the physical (body related) capabilities of the users but also on their goals, 
plans, values, beliefs, and past experiences. Effectively, Norman's conception 
of affordance "suggests" how an object can be interacted with. But when we 
start to interact with a tool, we also change the way we look at the tool, we 
adjust the way we understand the tool, and we accordingly adjust the way we 
use the tool. The concept of instrumental genesis is based on the distinction 
between artefact and instrument (tool) with the latter having a psychologi-
cal component (sometimes called scheme), indicating a dialectic relationship 
between activity and implicit mathematical, or any other type of, knowledge. 
The activity that employs and is shaped by the use of instruments (instru-
mented activity) is directed towards the artefact, eventually transforming it 
for specific aims (instrumentalization): 

62 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
The subject has to develop the instrumental genesis and efficient procedures 
in order to manipulate the artefact. During this interaction process, he or she 
acquires knowledge, which may lead to a different use of it. Similarly, the 
specific features of instrumented activity are specified: firstly, the constraints 
inherent to artifacts; secondly, the resources artifacts afford for action; and 
finally, the procedures linked to the use of artifacts. The subject is faced with 
constraints imposed by the artefact to identify, understand and manage in the 
course of this action: some constraints are relative to the transformations this 
action allows and to the way they are produced. Others imply, more or less 
explicitly, a prestructuration of the user's action. [6, p. 201] 
Let us take an example. A modern technological tool is GeoGebra; see 
www.geogebra.org. GeoGebra is free and multi-platform dynamic mathemat-
ics software for all levels of education that joins geometry, algebra, tables, 
graphing, statistics and calculus in one easy-to-use package. It has received 
several educational software awards in Europe and the USA. 
When working with a highly complex and sophisticated tool as GeoGe-
bra, the tool itself is a significant part of a complex learning process. We 
therefore need to bridge the theory of affordances with the perspective of the 
complex construction of instrumental genesis [31, 3, 6]. In this framework, 
it is important to distinguish between the utilization of instrumentation— 
how the tool influences and shapes the thinking of the user—and the mental 
instrumentalization—where the tool is shaped by the user. A user working 
with GeoGebra will be affected and behave accordingly in both these ways. 
Instrumentation is an evolutionary theoretical construct, and can be char-
acterized as the concept of mental schemes that emerge when users execute 
a task such as constructing a circle and dragging it around in a dynamical 
geometry program such as GeoGebra. During that process the user creates 
some mental schemata. But GeoGebra is also an instrument created with 
specific utilities that allow the user to engage in activities within the con-
straints of the artifact. Without much reflective effort, the user would drag 
the circle around since he or she already knows that GeoGebra allows such 
flexible manipulations. 
Instrumentalization is a psychological process that leads to an internaliza-
tion of the uses and roles of an artifact; it can be viewed as an organization 
of the mental schemes, but also includes a personalization and perhaps trans-
formation of the tool, and a differentiation between the complex processes 
that constitute instrumental genesis and those that are critical for teachers to 
master [6]. An example of this is when a teacher uses the option to create a 
new tool in GeoGebra or to save a construction in GeoGebra for later use in 
her or his teaching of geometry. 
The competence Instrumental Genesis occurs when a user with specific 
knowledge and methods acts on a tool with specific affordances and con-
straints. The tool brings instrumentation to the user, while the user brings 
instrumentalization to the instrument. Instrumental genesis can be viewed as 
occurring in the combination of these two processes. It seems to the author 

4.2 THEORETICAL FRAMEWORKS 
63 
that the presence of dynamic geometry systems has opened up for almost un-
limited instrumental genesis to be developed. Consequently, new knowledge 
is to be developed when students use the tool in their own way. 
One of the main characteristics of the instrumental approach, as we 
see it, is that it stresses the effort and time that the nontrivial process 
of instrumental genesis requires. A second important aspect of this 
approach is the importance of the bilateral relationship between the 
artifact and the user: while the student's knowledge guides the way 
the tool is used and in a sense shapes the tool (this is called instrumen-
talization), the affordances and the constraints of the tool influence the 
student's problem solving strategies and the corresponding emergent 
conceptions (this is called instrumentation). In short, the student's 
thinking is shaped by the artifact, but also shapes the artifact. [9, pp. 
205, 206] 
4.2.2 
The Importance of Variation 
Where instrumental genesis or competence covers technology as a whole, an-
other theory is more suitable for dynamic geometry systems where the user 
can vary different parts of an object. Discernment, variation and simultane-
ity are the central concepts in the phenomenographic research approach in 
which learning and awareness are interpreted under a theoretical framework 
of variation (see for example Ref. [18]). In short, phenomenography is about 
categorizing the limited number of qualitatively different ways of seeing or 
experiencing, a phenomenon in a hierarchical fashion. In particular, 
To discern an aspect is to differentiate among the various aspects and 
focus on the one most relevant to the situation. Without variation there 
is no discernment 
Learning in terms of changes in or widening in 
our ways of seeing the world can be understood in terms of discernment, 
simultaneity and variation [18, 19]. 
But variation is of course nothing new, and teachers of all times have most 
likely varied aspects of concepts when teaching different subjects. Kaput [8] 
phrased it as: 
One very important aspect of mathematical thinking is the abstraction 
of invariance. But of course, to recognize invariance—to see what stays 
the same—one must have variation. Dynamic media inherently make 
variation easier to achieve. [8, p. 525, italics in the original] 
Many technological systems but perhaps most dynamical geometry systems 
(DGS) are built around the possibility of variation. It is a system where math-
ematical concepts can be given visual dynamic forms subject to our actions, 
powerful or not. DGS are a natural experimental ground for one to experi-

64 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
ence the theory of variation since it has the built-in mechanism that enables 
us qualitatively different ways of literally seeing a geometrical phenomenon in 
action. DGS also enables a mathematics teacher to encourage the students to 
explore mathematical problems in new ways. 
Inspired by the old Roman expression "Repetitio Est Mater 
Studiorum" 
- repetition is the mother of learning—one may be able to summarize what 
has been said so far about phenomenography as Marton & Trigwell [18] ti-
tled their paper: "Variatio Est Mater Studiorum"—variation 
is the mother of 
learning. Another way to see this is to think about the possibility to learn 
something as a function of the possibility of variation. All aspects of varia-
tion are important when we look at what students experience and learn when 
working with technology and experimental mathematical investigations. 
4.3 
MATHEMATICAL MODELING TASKS 
Not all mathematical modeling topics need to be correlated to all the criteria 
in Blum & Niss [1], but it could be nice to have these criteria or other criteria 
at hand when one select topics or particular problems. Let us look at a simple 
problem in which we enable technology to help with the calculations. I do 
not consider this a mathematical modeling problem, but it is a good start for 
conjecturing, hypothesis, pattern seeking and investigations. 
■ EXAMPLE 4.1 
The Four Number Challenge Problem: Place any four natural 
numbers you choose in the first row of an array. You might prefer to 
use a spreadsheet for this exercise. In the second row, in the first three 
columns you should write the difference of the two numbers just above 
and to the right in the first row (the larger minus the smaller). In the 
fourth column you write the difference of the number above and the one 
in the first column of that row (again the larger minus the smaller). In 
other words, each entry is the absolute value of the difference of the two 
terms in the previous row. 
Repeat this procedure for each row, in terms of the numbers in the 
row just above. Implement it on a spreadsheet by using the command 
ABS. See Table 4.1. Will every choice of the four numbers you begin 
with eventually lead to rows of zeros? 
Investigation: Can you find four beginning numbers that let you generate 
more than 10 rows with nonzero values? Can you find four numbers that 
generates more than 20 rows with nonzero values? What is the underlying 
structure here? (Note: I am grateful to Jim Wilson, University of Georgia, 
Athens, Georgia, who showed me this activity many years ago.) 
Discussion: Where is this problem present in the list above [1]? I believe 
that 1) is related. Furthermore, the problem is easy to introduce, explain, 

4.3 MATHEMATICAL MODELING TASKS 
65 
Table 4.1 
The four number challenge in Excel, starting with 2, 7, 15, 35. 
12 
15 
13 
19 
18 
16 
12 
1 ° 
7 
8 
12 
1 
14 
4 
2 
0 
15 
20 
13 
15 
10 
6 
2 
0 
25 
33 
28 
25 
16 
8 
2 
0 
and implement. It most likely leads the investigator to making conjectures 
and testing them (e.g., "Let's try four prime numbers as a start"). I assume 
that you, who read this, have tried out some values already? A proof that the 
sequence always goes to a row of zeroes is quite elusive. The same methodology 
does work for decimal values (subject to some minor issues with rounding). 
Expansion could be done by trying with 2 columns (trivial), 3 columns, 5 
columns, and/or 6 columns. It appears that the sequence will go to a row 
of zeros for an even number of columns and oscillates between a row of zeros 
and ones for an odd number of columns. If the four numbers are related by 
a function f(x), for some functions the number of nonzero rows can be very 
limited for a very narrow range of x values. 
In terms of theory, I would say that the spreadsheet implementation of this 
problem enables us to vary and therefore we might see results we otherwise 
would have missed. 
■ EXAMPLE 4.2 
If we want students to explore and relate to a larger amount of Blum & 
Niss' criteria, we need to broaden the concept of mathematical modeling 
and perhaps collect data or problems from the real world. One issue 
then is that we will have several more concepts to deal with. Real-life 
problems easily get very complicated. 
Problem: Due to many different factors, it is more and more inter-
esting to use natural gas to heat homes. It is not hard to find figures for 
weekly gas consumption (m3) and average outside temperature (°C) for 
a house before the installation of cavity wall insulation. 
The students are provided with data for gas consumption related to outdoor 
temperature. A rather straightforward problem but one experience from try-

66 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
ing this problem with teacher program students is that students easy get lost 
in a complicated modeling process. We can see this as if the instrumental 
genesis is examined and that the students have not yet developed efficient 
procedures in order to manipulate the artifact. Most students I have met do 
not have any specific problems with finding the first two linear models that 
are required to solve the problem, but then many students find it difficult 
to finish the problem because they need a periodic model over one year to 
illustrate the temperature changes. How do you do that? 
Attempt 1: One student: / / / enter the values in CurveExpert and use curve 
fitting of a model as y = a + bcos(cx + d), and define c — 2π/12 which will 
force a periodicity of 12 months, then I get y = 8 + 4-9 cos(0.62 + π/6). 
Attempt 2: Other students selected a model based on the calendar year, 
meaning that they ordered the monthly averages of the outside temperature 
from January to December, resulting in a different output. 
In the process of mathematical modeling it is crucial that the modeler 
relates to how a modeling problem might be encountered within the real 
world. It seems as if some students learn to do this by instinct which helps 
them to become careful mathematical modeler. 
Another student: When I see the graph and that the curve is "empty" 
during the warmest months of the summer, then I realize that it would be very 
stupid to use gas for heating when it is warmer outside than inside. And I 
just exclude this interval from my calculation. 
Of course the problem can be analyzed through simple arithmetic. From 
Table 4.1 we get that the mean temperature 8 months is approximately 7°C, 
and we also get that the amount of saved gas for that temperature is about 35 
m3 a week. We could guess that the amount of gas saved over a year probably 
does not exceed 1200 m3. Further, the information in Table 4.1 shows that 5 
months have an average temperature under 7°C so the amount of saved gas 
is probably not below 700 m3. 
Some students stay out of the modeling process a while, which is a good 
strategy sometimes. 
A third student: Since I know that the amount of gas saved should be 
somewhere around 1200 m3, I can check my models in order to "fit" the model 
to the real-world solution, instead of the other way around. 
In my experience, prospective teachers do not always appreciate complex 
problems as perhaps engineering students do. It seems as if the students' 
views of open-ended tasks in general are intertwined with their views of the 
responsibility they have for their learning; similar connections might very 
well exist between these views and their views about sources of authority. 
You probably need a critical mind in order to force yourself to sit back and 
mainly do mental arithmetic before you employ some advance technology in 
a modeling process. In general, most students seem to very unaware of the 
concept of authority or where its sources might be. Sometimes they just are 
swept off by all figures which can be delivered so easily by all sorts of advanced 
technology. Read more about theories for authority and students believes in 

4.3 MATHEMATICAL MODELING TASKS 
67 
computer generated results in Ref. [11], and in Ref. [12]. For more details 
about this problem, readers can refer to Ref. [13]. 
■ EXAMPLE 4.3 
During the many years I have taught mathematical modeling to prospec-
tive teachers, I have also learned that different students appreciate dif-
ferent modeling situations differently. This is of course very logical; we 
are all different from each other. It is, at least for me, hard to say that 
there is any winner in that contest, but mathematical modeling within 
the field of medicine seems rather popular among the students I have met 
over the years. Somewhat all humans can relate to medical treatment 
either personally or through some relative. 
There are different ways to select mathematical modeling problems in 
medicine; it can for instance be related to measurement inside medical 
standard procedures or related to measuring of medical treatment for 
diseases. I will illustrate with one example, although there are quite 
many more which I have tried in teaching mathematical modeling over 
the years. 
A Problem From Anaesthesiology: To put it simply, we can say 
that the function of the heart is to pump blood throughout the body. 
The blood, in turn, transports oxygen (O2) from the lungs to various 
tissues of the body and transport carbon dioxide (CO2) from the tissues 
back to the lungs. When constructing a mathematical model of the 
circulatory system, we also consider it to be a closed loop, and assume 
that the blood is incompressible. Consequently the total volume V of 
blood (measured in liters) in the system is constant. 
Naturally, it is important at what rate the blood flows around the cir-
culatory loop. The flow rate is (in principle) measurable (in liters/minute) 
past any given point in the system. Ordinarily most attention is focused 
on the heart's condition and the concept cardiac output CO is the rate at 
which blood is pumped out of the heart. The cardiac output of the heart 
is the product of the stroke volume SV—the volume of blood pumped 
per beat - and the heart rate HR—number of beats per minute. Typ-
ical values for a 70-kg man are: SV = 70 to 80 cm3/beat = 0.070 to 
0.080 liters/beat, HR = 70 to 80 beats/minute, CO = 5 to 6.5 liters/ 
minute. 
To enable a comparison of patients with different body sizes, cardiac 
output is often considered relative to the body surface area BSA (in 
square meters). The cardiac index is the ratio CI = CO/BSA mea-
sured in litres per minute per square meter. 
A typical value of CI 
for a 70 kg man with a body surface area of about 2 m2 is 2.5 to 3.5 
liters/minute/m2, which is equal to about 5.6 liters/minute for a human 
male. However, it should be noted that a normal person has a large 

68 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
"reserve capacity" that allows the cardiac output to increase to as much 
as 25 to 30 liters/minute during strenuous exercise over a short time. 
Cardiac output is often monitored during and after surgery (especially 
in the case of heart surgery). Serial measurements are used to assess 
the general status of the circulation and to determine the appropriate 
hemodynamic therapy and estimate its efficacy. Several other useful 
variables—such as the stroke volume, the left ventricular stroke work 
index, the systemic vascular resistance, and the stroke index—can be 
determined once the cardiac output is known. 
Cardiac output can be measured by several techniques, all based on 
the same idea for measuring the flow rate in a fluid loop. A measurable 
indicator is injected into the fluid, and its subsequent concentrations 
at various points in the flow loop are measured. Such a method was 
first proposed in 1870 by the German physiologist Adolph Fick, who de-
scribed a means of determining blood flow by measuring overall oxygen 
intake and content in the blood. 
One determines how much oxygen an animal takes out of the air in a 
given time.... During the experiment one obtains a sample of arterial 
and a sample of venous blood. In both the content of oxygen is to be 
determined. The difference in oxygen content tells us how much oxygen 
each cubic centimeter of blood takes up in its course through the lungs, 
and since one knows the total quantity of oxygen absorbed in a given 
time, one can calculate how many cubic centimeters of blood passed 
through the lungs in this time [20]. 
The indicator dilution method is a variant of Fick's technique in which 
a known amount / of an indicator substance is injected into the blood 
stream and its concentration C(t) (in liters per cubic meter) is measured 
as a function of time t at a single downstream location. This dilution 
method was first introduced by the British physician Stewart who, to-
gether with a colleague Hamilton, developed the dye solution method 
and the Stewart-Hamilton 
formula 
c o 
i 
which gives the corresponding cardiac output CO (See Ref. 
[20], p. 
1059). 
For a much more extended and throughout derivation of the Stewart-Hamilton 
formula, please see Ref. [14]. Let me just briefly point out the mathemat-
ical complexity in the standard procedures of cardiac output. The Stewart-
Hamilton formula says simply that what goes in (at the injection site) must 
eventually be measured at the downstream sensor site. 
(4.1) 

4.3 MATHEMATICAL MODELING TASKS 
69 
Because a definite integral of a positive-valued function gives the area under 
its graph, the Stewart-Hamilton formula says that the equation is that the 
cardiac output equals the quantity of the indicator injected divided by the 
area under the concentration-versus-time curve C = C(t) in the iC-plane. At 
this point in the analysis, the (constant) parameters CO and 7, the variables 
t and C, and the Stewart-Hamilton formula relating them constitute a simple 
mathematical model for the process of circulation and dilution that ensues 
upon the injection of the indicator into the circulatory system. 
Complications in the Model: It should be noted that today the dye 
solution method has been almost entirely replaced by variants of a thermod-
ilution method. Originally (around 1954) the thermodilution method used 
an iced or room temperature solution of salt or dextrose in water. Today 
the method uses a small heating thermistor on the Swan-Ganz catheter (a 
lung artery catheter). The temperature Tß(t) of the blood at the sensor is 
measured (rather than the injectate concentration), and the simple Stewart-
Hamilton formula discussed above is replaced with the formula [20] 
c o - 
f0°°TB(t)dt' 
( 4 · 2 ) 
where Tg — Tj is the initial blood-injectate temperature difference (Tg = 
TB(0), and K is an empirical constant depending on the catheter size, specific 
heat and volume of the injectate, and the rate of injection. 
This mathematical modeling assignment concentrates the attention to-
wards the original Stewart-Hamilton formula and method. Here we see that 
a significant complication results from the fact that the circulatory system is 
a closed loop. Before the indicator concentration curve returns to zero (i.e., 
when the entire indicator has passed the censor), the indicator concentra-
tion exhibits a secondary peak due to recirculation. There are two ways to 
evaluate cardiac output in the presence of recirculation. One could develop 
theoretical equations to account explicitly for recirculation, but this approach 
would require a detailed analysis of the indicator washout curve, rather than 
simply finding the area under the curve. A simpler and more effective method 
to account for recirculation is to remove its effect from the observed indicator 
"washout curve." 
The way the circulatory system washes out drugs and anaesthetics from the 
tissues by means of the blood flow is quite similar to the way a muddy bathtub 
can clear itself. The mud can be cleaned out by running water in from the tap 
and draining water out of the tub simultaneously at the same rate of flow. For 
simplicity, let us assume that the bath water in the tub is constantly stirred 
so that the concentration of the mud is always uniform. If Q(t) denotes the 
amount (kg) of mud in the tank at time t, then the concentration at time t is 
given by c(i) = Q(t)/V 
(kg/liter) where V is the (constant) volume of bath 
water in the tub. Hence the change dQ in Q during the short time interval 

70 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
dt is given by 
dQ = -rc{t)dt = -r ■ Q/V ■ dt = -kQdt. 
(4.3) 
Thus Q(t) satisfies the simple differential equation 
dt " 
kQ' 
with the familiar exponential decay solution 
Q(t) = Q0e~kt, 
(4.5) 
where k = Q/V and QQ is the initial amount of mud in the tank. 
For the purpose of a preliminary analysis of the indicator dilution curve, 
let us assume that the initial decreasing part of the indicator dilution curve-
before recirculation sets in—is similarly exponential in character. Then sup-
pose this dilution curve is plotted on semi-log paper—paper on which the 
vertical (Q) scale is logarithmic and the horizontal (<) scale is linear. This 
exponentially decreasing part of the curve then looks like 
lnQ = lnQo-A;i. 
(4.6) 
Thus the initial "down stroke" is a straight line on this semi-log plot. With 
the help of suitable software or modern graphing calculators, we may even 
use measured values of the concentration to fit an exponential curve to the 
washout part. 
With this background, a possible examination task in a mathematical mod-
eling course could be the following: The cardiac output as monitoring devices 
present it is normally traced out on a paper slip where the paper shows the 
change in dye concentration as a deflection from zero. Normally the measured 
CO is also printed on the paper. 
Student task: Calculate the cardiac output for the patient whose mea-
sured data are present in Table 4.2. The dye injection was 5.68 mg. Observe 
that 55 mm of deflection equals a change in dye concentration of 5 mg/liter. 
This is a mathematical modeling situation with a richness of mathematical 
objects and methods, with mathematical depth and exploring possibilities. 
For a more extensive and detailed discussion of student's attitudes, attempts, 
reactions, and accomplishments when handling the cardiac output assignment: 
please see Ref. [11]. Please also see Ref. [16] for a study of how students 
handle the treatment of asthma in a mathematical modeling process. Please 
read more about this problem in Ref. [11]. 
Besides medicine, the environmental issue is often of high importance for 
students. Therefore I have decided to select a problem from that area. 
(4.4) 

4.3 MATHEMATICAL MODELING TASKS 
71 
■ EXAMPLE 4.4 
Imagine a small lake. Although any lake is receiving and losing water 
in different ways, we simplify the situation and say that water flows in 
through a stream A and out through a stream B. Imagine that A and B 
are at opposite sides of the lake. 
At a certain time of the day, as a result of a road accident, a petrol 
truck overturns and spills a toxic chemical into the stream A at a po-
sition X. Thirty minutes later the police and emergency services have 
brought the situation under control, and an unknown amount z (m3) 
of the toxic chemical has leaked into the lake. Develop a mathematical 
Table 4.2 
A patient's cardiac output, measured over time. 
1 Time (sec) 
1 
° 
1 
2 
1 
4 
1 
6 
1 
8 
1 
10 
1 
12 
1 
14 
1 
16 
1 
18 
| 
20 
| 
22 
| 
24 
Deflection (mm) 
0 
20 
88 
122 
100 
66 
41 
29 
20 
15 
12 
14 
16 
Time (sec) 
1 
3 
5 
7 
9 
11 
13 
15 
17 
19 
21 
23 
25 
Deflection (mm) 
5 
50 
115 
118 
80 
53 
35 
24 
17 
13 
13 
15 
18 
model that you can use to predict the concentration of the pollutant in 
the lake at any time and use it to estimate (for a range of possible initial 
pollution amounts z): 
1. The maximum pollution level in the lake and the time at which the 
maximum is reached. 
2. The time it will take for the pollution to fall below the safe level of 
0.05%. 
3. How will your results be affected if a constant rain starts at the 
same time as the accident? The rain covers the whole geographic area. 

72 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
Here we have an open and therefore demanding mathematical modeling situ-
ation, with not much data given. Instead it has to be invented or gathered by 
the students. With an open mind and curiosity, they must investigate what 
kind of accident there was and what amount of toxic substance could possibly 
leak out in 30 minutes. Students must set up conjectures and a hypothe-
sis and combine their efforts into a mathematical model that will be quite 
complicated. 
The resulting discussions took place with students in groups or in pairs since 
the examinations were integrated in the process of learning. The following 
quotations illustrate different results from this exam. 
Student 1: My data is: The flow in and out =0.1 m3/s, equal to 6 m3/min. 
My assumption is that the flow out of the lake will be unchanged, but the flow 
into the lake increases (z/30 m3 /min) during the time the toxic pollution pours 
into the lake. A small enlargement of the lake when the pollution flows in, but 
no increased outflow. 
Student 2: When the toxic pollution has poured into the lake through A, 
no polluted water has yet managed to flow out of the lake through creek B. 
After 30 minutes fresh water begins to flow into the lake again through A 
while polluted water starts to flow out of the lake through creek B. Inflow = 6 
+ z/30 m3/min — Outflow... then there is 19 m3 toxic chemical pollution in 
the lake after 30 minutes. Reasonable, since I thought that 20 m3 had leaked 
out of the petrol truck. The missing m3 probably have disappeared between X 
and A, or in the lake. 
Student 3: Inflow = 6 + z/30 = Outflow. I have added the original flow 
of water to and from the lake to the toxic leak from the petrol truck evenly 
spread out over the thirty minutes. I have chosen to keep the volume of the 
lake constant, so the Outflow also increases with z/30. 
The first two student responses are based on an interpretation of how flow 
and water level are affected by the discharge. Many of the students described 
the alteration as a "tidal wave," an additional amount of fluid like a pulse 
through the system. That led to difficulties when the mathematical model 
and its behavior are evaluated. Since this line of reasoning was common in 
the group, we regarded it as a result of the discussions among students in 
the group during the modeling process. The third student is one of the few 
students who expressed a more reliable reasoning depending on assumptions 
made in the modeling process. The instructors' concluded that this student 
was one of the strong students in the group. 
When students respond to open mathematical modeling problems, several 
components of that student's view of mathematics become visible. Fischbein 
[14] mentions three different components of mathematics as a human activity: 
the formal aspect, the algorithmic component, and intuition. In a mathe-
matical modeling process the formal aspect could be the student's knowledge 
of required mathematical theories, the algorithmic component could be the 

4.3 MATHEMATICAL MODELING TASKS 
73 
skills needed in the solving procedures, and the intuition component could be 
the possibility for the student to validate a complicated mathematical model. 
There are obviously both interactions and conflicts between these aspects and 
components in a students' mathematical modeling activity. 
There is also a risk that some students might work too hard in an ambition 
to make the mathematical model "complete," thereby aiming that it should 
describe and control every single detail of the pollution accident: 
Student 4: The pollution in the lake is affected the most by the size of the 
flow of toxic chemicals from the petrol truck, and that in turn is related to the 
cross-sectional area of the aperture. 
This statement was written by a mathematical student, who constructed 
her mathematical model at a fairly sophisticated level. Her model was detailed 
over of how the geometrical properties of the aperture in the petrol truck 
direct the pollution of the lake, which in turn prevented her from making a 
free validation of the model. This student also divided the lake into 18 discrete 
zones with a certain cross-sectional area. That detailed solution resulted in 
the following statement concerning the concentration of pollution in the lake: 
Student 4: The concentration is directly proportional to the cross-sectional 
area, which yields the highest concentration at the inflow and outflow positions 
in the lake. 
The impossible aim for such a detailed mathematical model that it has a 
full correlation with reality, and the search for a "general" algorithmic solu-
tion seems to have annihilated this student's intuitive interpretation. This 
phenomenon is balanced by the following summary by another student, ex-
pressing a more balanced view when looking back on how the results of the 
mathematical model would be affected if a constant rain starts: 
Student 5: When the inflow becomes larger than the outflow, the result 
will be a rise in the surface level in the lake. The meaning of this is hard 
to interpret. 
Will the surface of the water attract more chemicals and then 
how much? What is a lake's potential to store more water? If the surface 
level rises, it might result in new streams of outflow. 
When validating my 
mathematical model against all assumptions, I realize that my mathematical 
results may in fact be doubtful. 
Discussion: One conclusion from the coursework is that also when stu-
dents solve a mathematical modeling problem using data points generated 
from their "own model," they can yet become confused. Sometimes led by a 
desire to deliver a sophisticated solution, they become somewhat blind, almost 
unable to see simple, elegant solutions. 
According to Ref. [4], there are situations in which the intuitive under-
standing prevents or otherwise disturbs formal understanding. However, the 
instructors argued that they saw that the formal component of the students' 
mathematical ability sometimes creates an obstacle for the intuitive interpre-
tation of the process that is modeled. Obviously it is essential to find a good 
balance between solid formal knowledge and insight in how to use this formal 
knowledge and how to develop a good intuitive capacity. Perhaps this is extra 

74 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
important for prospective teachers, who should be trained to guide their own 
students towards the goals proposed in the mathematics curriculum. 
One result of an open-ended problem as this is that students will come up 
with different solutions and by sharing these solutions with each other they 
will become more experienced in the mathematical modeling process. Readers 
can refer to Ref. [7] for more details. 
■ EXAMPLE 4.5 
Let me show you one last problem where the possibility to vary dynami-
cal objects led to a surprising result. This is, once again, a mathematical 
modeling exercise entirely inside mathematics. The possibility of visu-
alizing mathematical concepts and experimenting with numerical and 
graphical tools allow us to go beyond traditional deductive reasoning 
methods and to use geometrical modeling for solving geometrical prob-
lems. The problem, Walters Theorem, is a rather famous problem, since 
it, in fact, encouraged a ninth grader to discover new mathematical 
knowledge. 
Walter's Theorem: Walter's Theorem is named after Marion Walter, 
professor of mathematics at the University of Oregon. It seems as if 
it first was presented in the Mathematics Teacher (November 1993) in 
Reader Reflections [2]. The theorem says: 
Take any triangle and trisect the sides. Connect the trisection points 
to the opposite vertices. The resulting hexagon has an area equal to 
one-tenth the area of the original triangle. 
Two and a half year later, in the May 1996 issue of the Mathematics 
Teacher, Walter's Theorem was mentioned again. This time it was in an 
article about Morgan's theorem [33]. In the article, the 9th grader Ryan 
Morgan's mathematical investigations were described. The article told 
that Ryan Morgan's mathematics teacher (Frank Nowosielski) presented 
Walter's Theorem to his class in the fall of 1993. The school bestows 
the students with computers and the GSP for the investigation. 
Ryan Morgan was interested in investigating what would happen if 
the sides of the triangles were partitioned into more than three congruent 
segments (see Figure 4.5). Ryan and his teacher called the process "n-
secting", and Ryan experimented with different n-sections using GSP 
[33, p. 420]. Inspired by Ryan Morgan's results, we challenged a group 
of prospective mathematics teachers at the University of Gothenburg 
with Walter's Theorem in 2001. The students were asked to investigate 
what happens with the ratio between the inner constructed hexagon and 
the outer triangle if the outer triangle's sides were n-sectioned, where n 
is odd. See [15, pp. 123-124] for a description of the problem and of 
student's accomplishments. 

4.3 MATHEMATICAL MODELING TASKS 
75 
Figure 4.1 A method for seven sectioning 
a triangle side with GeoGebra. 
Results and conclusions: Not all students managed to reach the 
solution of Ryan Morgan. But most students got fascinated with the 
problem and in the connections they discovered: 
When I divided every side in the triangle in n sections, the relation be-
tween the two areas becomes surprisingly (9n2 - l)/8. 
This is amazing, 
but I cannot prove it. 
DGE in a way invites the user to prove things, yet a strict formal con-
cept of proof seems not to be possible in dynamic geometry software. 
As King and Schattschneider (1997) put it, "While dynamic geometry 
software cannot actually produce proofs, the experimental evidence it 
provides users with produces strong conviction, which can motivate the 
desire for proof" (Ref. [10], p. xiii). In a complicated modeling process, 
it is also quite easy to almost get lost and perhaps unable to see what 
is expected: 
/ have really investigated a large variety of triangles, but I still don't 
see any relation. Yes, the larger triangle is larger and larger compared 
to the hexagon when n-secting more and more. But what's the big deal 
with that? 
An important part of this inquiry based teaching experiment was that 
there was a: 
1. possibility to learn—an open investigation. 
2. possibility to use the technological tool, GPS, for the investigation. 

76 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
3. possibility to seek patterns and making conjectures. 
The surprising result illustrating the connection between algebra and geom-
etry can be illustrated by any curve fitting tool or by calculation by hand 
once you have the ratios. I challenge you, dear reader, to find them by for 
instance using the free software GeoGebra. The work of Ryan Morgan did 
actually lead to that he was invited to present the results at a mathematics 
colloquium at Towson State University in 1994. Interested readers can refer 
to [15] for more details. 
■ EXAMPLE 4.6 
My last example has just recently been tried out and I have yet no 
students' reports to quote from. It is an interesting example of how 
students can generate the data themselves and thereby perhaps become 
even more involved in the modeling process, especially since the data 
comes from inside their own bodies. The responses from the students 
who tried this a week ago was overwhelming positive. 
The target group is once again prospective teachers for secondary 
school. In my experience, a suitable group size is 3 or 4 students in 
each group and they should work on the following phenomena under 
the conditions that one in the group is responsible for filming (by smart 
phone or a small digital camera) the first part of the exercise which the 
other students do: 
Measure your pulse rate at rest. Then exercise (such as run stairs 
up and down, run outside, etc.) until your pulse rate has risen to ap-
proximately 190 bpm. Stop exercising, rest and measure your pulse rate 
every minute until it is back to normal. This should be done by more 
than one person in each group, preferable by all who not are filming. 
1. Describe how your pulse rate varies over time with a diagram. 
2. Determine average values for every individual in the group for 
every moment in time, and visualize these in a diagram. 
3. Try to determine a mathematical model which describes how the 
pulse varies with time. Do one or several screen cast movies of your 
work at the computer. 
4. Evaluate the validity of the model 
5. Prepare a presentation for the whole student group, in which you 
present both a film from the gathering of the data and a screen cast 
generated movie from the mathematical modeling process. 
Presentation: The students will be asked to present their activities 
with a short film (filmed by their cell phones) together with their solution 
strategies (captured by screen cast technology) as a presentation to the 
whole class. Part of the activity is an assessment procedure in which 
the students try to grade their peer's presentations and thereby learn 

4.4 CONCLUSIONS 
77 
how to grade their future students if involved in similar inquiry based 
exercises. 
Assessment: Both the mathematical correctness in terms of mea-
suring techniques and modeling performance, together with presentation 
techniques, will be measured. The student's communicative skills will be 
evaluated. The students will, assisted by the professors, create an eval-
uation matrix for the assessment of the student's performance on each 
task and, as well, the students will be asked to report an assessment on 
their peer's performance. 
4.4 
CONCLUSIONS 
It is evident that several of the examples in this chapter are hard to investigate 
the way I have described them without technology. The work in technological 
tools goes very well in hand with learning theories as the variation theory. 
The possibility to vary and see visually how objects change is an important 
feature with technology. Noss, Healy and Hoyles [25] explored the relation-
ship between learners' actions, visualizations and the means by which these 
are articulated in a computer dynamic environment. According to them, 
A central challenge for the design of mathematical learning environ-
ments is to make visible that which is normally visible only to the 
mathematical cognoscenti, (p. 231) 
Technology not only has the power to make visible, but even to amplify our 
dynamic imagination that often contributes significantly to the development 
of mathematical knowledge. Presmeg [27] remarked that: 
Software facilitates visualization processes ... which may clarify and 
further the solution to a mathematical problem by providing insight, 
thus suggesting productive paths for reason and logic." (p. 220) 
The possibility to allow students to explore manipulable dynamic objects 
has a vast potential for the learning of mathematics at several levels in edu-
cational systems. The object of learning in these five examples is not entirely 
to find the correct answer, but more to be part of an investigation. That in 
turn is related to the fact that mathematics can be thought of and learned in 
several different ways. 
EXERCISES 
4.1 
Following Example 1, you should try by yourself, which is the purpose 
of this activity. This one is a nice attempt: 
1 60 
168 367 

78 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
How many nonzero (not all zero) rows are generated for each of these sets of 
start values? 
0 
941 
2672 
5856 
0 
155 
440 
964 
1000 
2550 
5400 
10642 
1000 
7000 
18037 
38338 
0 
10000000 
28394732 
62229538 
4.2 
In Example 2, change the values for heating to more modern figures. 
Leave the values for heating for the students to find out. 
4.3 
In Example 3, the only possibility to alter anything in this mathematical 
modeling activity is to change the values for the patient's Cardiac Output over 
time measured in mm of deflection or to change the dye injection. 
4.4 
For details about Example 4, please refer to Ref. [7]. Since this is such 
an open problem, there are as many paths to walk as there are students. You 
could of course give details or construct constraints for the initial values which 
the students have to find. 
4.5 
In Example 5, what happens if you do not do the n-secting for odd 
numbers for n? Show that once you have the areas, you can do the curve 
fitting part by paper or pencil or by Excel. 
4.6 
Following Example 6, compare the variables of size, weigh, gender, fit-
ness, and age with the models. 
REFERENCES 
1. Blum, W., & Niss, M. (1989). Mathematical problem solving, modeling, appli-
cations, and links to other subjects — state, trends and issues in mathematics 
instruction. In W. Blum, M. Niss, & I. Huntley (Eds.), Modeling, 
Applications 
and Applied Problem Solving: Teaching Mathematics in a Real Context (pp. 
1-21). London: Ellis Horwood. 
2. Cuoco, A., Goldenberg, P., & Mark, J. (1993). Reader reflections: Marion's 
theorem. Mathematics Teacher 86(8), 619. 
3. Drijvers, P. (2003). 
Learning Algebra in a Computer Algebra 
Environment. 
Doctoral dissertation. Utrecht: Freudenthal Institute. 
4. Fischbein, E. (1994). The interaction between the formal, the algorithmic, and 
the intuitive components in a mathematical activity. In R. Bielhler, R. W. 
Scholtz, R. Strasser, & B. Winkelmann (Eds)., Didactics of Mathematics as a 
Scientific Discipline (pp. 231-245). Dordrecht: Kluwer. 

EXERCISES 
79 
5. Gibson, J. J. (1977). The theory of affordances. In R. E. Shaw & J. Bransford 
(Eds.), Perceiving, Acting, and Knowing: 
Toward an Ecological Psychology. 
Hillsdale, NJ: Lawrence Erlbaum. 
6. Guin, D., & Trouche, L. (1999). The complex process of converting tools into 
mathematical instruments: The case of calculators. International 
Journal of 
Computers for Mathematical Learning, 3(3), 195-227. 
7. Holmquist, M., k. Lingefjrd, T. (2003). Mathematical modeling in teacher ed-
ucation. In Q. Ye, W. Blum, S. K. Houston, & Q. Jiang (Eds.), Mathematical 
Modeling in Education and Culture ICTMA 
10: Applications in Science and 
Technology (pp. 197-208). Horwood: Chichester. 
8. Kaput, J. (1992). Technology and mathematics education. In D. Grouws (Ed.), 
Handbook of Research on Mathematics 
Teaching and Learning, (pp. 515-556). 
New York.: Macmillian. 
9. Kieran, C., & Drijvers, P. (2006). The co-emergence of machine techniques, 
paper-and-pencil techniques, and theoretical reflection: A study of CAS use in 
secondary school algebra. International Journal of Computers for Mathematical 
Learning, 11(2), 205-263. 
10. King, J., & Schattschneider, D. (1997). Preface: Making geometry dynamic. 
In J. R. King & D. Schattschneider (Eds.), Geometry Turned On!: 
Dynamic 
Software in Learning, Teaching, and Research (pp. ix-xiv). Washington, D.C.: 
The Mathematical Association of America. 
11. Lingefjrd, T., & Kilpatrick, J. (1998). Authority and responsibility when learn-
ing mathematics in a technology-enhanced environment. In D. Johnson & D. 
Tinsley (Eds.), Information and Communications 
Technologies in Mathematics 
(pp. 233-236). London: Chapman & Hall. 
12. Lingefjärd, T (2000). Mathematical Modeling by Prospective Teachers Using 
Technology. Ph.D. Thesis at University of Georgia. 
13. Lingefjärd, T. & Holmquist, M. (2001). Mathematical modeling and technology 
in teacher education—Visions and reality. In J. Matos, W. Blum, K. Houston, S. 
Carreira (Eds.), Modeling and Mathematics Education ICTMA 9: Applications 
in Science and Technology (pp. 205-215). Horwood: Chichester. 
14. Lingefjärd, T. (2002). Mathematical modeling for preservice teachers: A prob-
lem from anesthesiology. The International 
Journal of Computers for Mathe-
matical Learning 7(2), pp. 117-143. 
15. Lingefjärd, T. & Holmquist, M. (2003). Learning mathematics using dynamic 
geometry tools. In S. J. Lamon, W. A. Parker, & S. K. Houston (Eds.), Math-
ematical Modeling: A Way of Life. 
ICTMA 
11 (pp. 119-126). 
Horwood: 
Chichester. 
16. Lingefjärd, T. (2009). Challenges with international collaboration regarding 
teaching of mathematical modeling. 
In Blomh0j, M. & S. Carreira, (Eds.) 
(2009). Different Perspectives on Research in Teaching and Learning Math-
ematical Modeling. 
Proceeding from Topic Study Group 21 at ICME-11 in 
Monterrey, Mexico. IMFUFA-text no. 461, Department of science, systems and 
models, Roskilde University. 
17. Marton, F., & Booth, S. (1997). Learning and Awareness. Mahwah, N.J.: Law 
Earlbaum. 

80 
CHAPTER 4. TEACHING MATHEMATICAL MODELING 
18. Marton, F., & Trigwell, K. (2000). Variatio Est Mater Studiorum. 
Higher 
Education Research & Development, 19, pp. 381-395. 
19. Marton, F., Runesson, U., & Tsui, A. B. (2004). The space of learning. In 
F. Marton, & A. B. Tsui, Classroom Discourse and the Space of Learning (pp. 
3-40). Mahwah, N.J.: Lawrence Erlbaum Associates. 
20. Miller, R. D. (Ed.) (1982). Anesthesia. New York, N.Y.: Churchill Livingstone. 
21. Microsoft Co. Microsoft Excel. Stockholm, Sweden. Microsoft Corporation. 
22. NCTM (1979). Applications in School Mathematics (Yearbook - NCTM: 1979). 
Reston: NCTM. 
23. NCTM (1989). The Curriculum and Evaluation Standards for School Mathe-
matics. Reston: NCTM. 
24. Norman, D. (1988). The Design of Everyday Things. New York: Basic Books. 
25. Noss, R., Healy, L. & Hoyles, C. (1997). The construction of mathematical 
meanings: connecting the visual with the symbolic. Educational Studies in 
Mathematics 33(2), 203-233. 
26. Pollak, H. O. (1970). Applications of mathematics. In E. Begle (Ed.), The 
Sixty-Ninth 
Yearbook of the National Society for the Study of Education (pp. 
311-334). Chicago: University of Chicago Press. 
27. Presmeg, N. (2006) Research on visualization in learning and teaching mathe-
matics. In A. Gutirrez &; P. Boero (Eds.), Handbook of Research on the Psychol-
ogy of Mathematics Education: Past, Present and Future,(pp.205-235), Sense 
Publishers: Rotterdam/Taipei. 
28. Sfard, A. (1997). From acquisitionist to participationist framework: putting 
discourse at the heart on learning mathematics. In T. Lingefjrd & G. Dahland 
(Eds.), Research in Mathematics Education (pp. 109-136). Report 1998:02. 
Gothenburg: University of Gothenburg. 
29. Skolverket (2000). [Swedish Board of Education]. 
30. Steen, Lynn A., (Ed.), Heeding the Call for Change: Suggestions for Curricular 
Action, MAA Notes No. 22, 1992. 
31. Verillon, P., & Rabardel P. (1995). Cognition and artifacts: A contribution to 
the study of thought in relation to instrument activity. European Journal of 
Psychology of Education, 10(1), 77-101. 
32. Vygotsky, L. S. (1934/1962). Thought and Language. Cambridge, MA: MIT 
Press. 
33. Watanabe, T., Hanson, R., & Nowosielski, F. (1996). Morgan's theorem. Math-
ematics Teacher, 89(5), 420-423. 

PART II 
MATHEMATICAL MODELING 
WITH MULTIDISCIPLINARY 
APPLICATIONS 
Mathematical Modeling with Multidisciplinary Applications.
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

CHAPTER 5 
INDUSTRIAL MATHEMATICS WITH 
APPLICATIONS 
ALFREDO BERMUDEZ1 AND LUZ M. GARCIA GARCIA2 
1Departamento de Matemätica Aplicada, Universidade de Santiago de Compostela, 
Spain 
Institute» Espafiol de Oceanografia, Spain 
The introduction of computers in the middle of the last century and the 
continuous and spectacular increasing in their power is a key issue in the 
scientific and technological revolution of the last decades. Computers have 
created needs of mathematical expertise in almost all fields. Close interaction 
between mathematicians, computer scientists and application field experts 
is necessary to correctly and fully exploit the enormous potential that the 
computer has brought. This is true not only for mathematical applications to 
other sciences but for industrial applications as well. 
Mathematical Modeling with Multidisciplinary Applications. 
83 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

84 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
5.1 
INDUSTRIAL MATHEMATICS 
Mathematical modeling is nowadays a key tool for innovation in almost every 
industrial sector (see [10] for a wide variety of examples). By using computer 
simulation-based on mathematical models, industry is able to create new prod-
ucts and processes and introduce them into the market in much shorter times 
than by using the conventional trial and error experiment-based methodol-
ogy. Building a prototype is done by making virtual essays in a computer 
before it is effectively manufactured and is subjected to the tests required by 
its specifications sheet. Thus, not only is the time to market considerably 
reduced but also are the development costs, allowing the company to increase 
its competitiveness. 
Having a mathematical model is also a first step to optimize a product or 
a process. While some degree of improvement can be achieved by manually 
changing the design parameters and performing a new simulation, optimiza-
tion theory and algorithms allow us to do that in an automatic way. Defining 
new design parameters is done in a rational mathematical way by introducing 
an objective or cost function of them and then computing its gradient to get 
a descent direction. 
In this chapter two industrial applications of mathematical modeling are 
described. The first one concerns the metallurgical industry, more specifically, 
obtaining silicon in electric arc furnaces is considered. The second part deals 
with the numerical simulation of environmental engineering problems arising 
from studies of water quality in artificial lakes occupying the space left after 
exploiting a coal open pit mine. Both parts are structured as follows: firstly, 
a detailed description of the industrial problem is given. Then, appropriate 
mathematical models are introduced. Next numerical methods are proposed 
and, finally, numerical results from real situations are shown. 
5.2 
NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
In this section we introduce a thermoelectrical model for numerical simulation 
of electrodes used in metallurgical electric arc furnaces. First we describe the 
industrial problem motivating the study. Then we introduce the models and 
the numerical methods for solving them in a computer. Numerical simulations 
of real industrial electrodes are presented. 
5.2.1 
The Industrial Problem: Metallurgy of Silicon 
Silicon (Si) is the second most abundant element in the Earth's crust after 
oxygen. In natural form, it can be found mainly as silicon dioxide (silica, 
S1O2) and silicates (silicon combined with other elements). In particular, 
quartz and sand are two of the most common forms. 

5.2 NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
85 
Silicon is produced industrially by the reduction of silicon dioxide with 
carbon by a reaction which can be written in a simple way as follows: 
S i 0 2 + 2C—>Si + 2CO. 
(5.1) 
Depending on its purity, silicon has a wide variety of applications: 
• Ferrosilicon (silicon steels, it can contain more than 2% of other mate-
rials) 
• Metallurgical silicon (e.g. silicon-aluminum alloys, it contains about 1% 
of other elements) 
• Chemical silicon (silicones) 
• Solar silicon (solar cells) 
• Electronic silicon (semiconductors, the purest silicon, "9N" — 99.9999999 
of purity) 
The reaction (5.1) takes place in reduction furnaces similar to those used for 
calcium carbide, iron and some others (see Figure 5.1 for a sketch of the overall 
process). More specifically, silicon is obtained in submerged "arc" furnaces 
that use three-phase alternating current (see Figure 5.3). A submerged arc 
furnace is a large furnace loaded with selected raw materials. During the 
process, these raw materials melt and chemically react. The liquid silicon 
leaving the furnace is cooled and further processed into an appropriate size 
depending on different applications. A reference book for silicon metallurgy 
is [13]. 
Electrodes are the main components of reduction furnaces. The typical 
diameter of the electrodes is one or two meters while their length is more 
than ten meters, their weight being greater than 10 Mt. Electric current enters 
each electrode through copper contact clamps which completely embrace the 
column approximately one meter above the charge level. Current goes down, 
crossing the column length comprised between the contact clamps and the 
lower end of the column generating heat by the Joule effect. At the tip of the 
electrode an electric arc is produced, reaching temperatures of about 2500 °C. 
Classical electrodes extensively used in industry include pure graphite, pre-
baked and S0derberg electrodes. The latter are used for ferrosilicon production. 
Its advantages with respect to pure graphite or prebaked electrodes are that 
they are built in larger sizes and cost less. However, as the electrode is con-
sumed it has to be slipped, typically 0.5 m per day. New sections of casing 
are welded at the top when needed and S0derberg paste is replenished in the 
electrode center. In this way, the steel casing moves with the carbon body 
so it melts and pollutes silicon: the iron contribution of the electrode casing, 
in addition to the iron rendered from the carbon ash and the impurities in 
the quartz, give in all cases an iron content in excess of 1%. This is why 

86 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
they cannot be used to obtain silicon with metallurgical quality (for short, 
silicon metal) to be used, for instance, to produce aluminum-silicon alloys. 
Accordingly, prebaked electrodes were for many years the only alternative for 
commercial silicon metal production until the arrival of the ELSA electrode 
into the market. The ELSA electrode (see Figure 5.2) consists of a central 
column of baked carbonaceous material, graphite or similar, surrounded by a 
S0derberg-like paste. There is a steel casing that contains the paste until it 
is baked. 
Figure 5.1 
Silicon production. 
The furnace has two different slipping systems: one for the casing and 
another one for the central column. The combination of both systems is nec-
essary so as to slip the casing as little as possible and also to carry out the cor-
rect extrusion of the carbon electrode with the central column slipping rings. 
Contrary to S0derberg electrodes, the casing is not necessarily consumed and 
then it is possible to produce non-polluted silicon with so-called metallurgical 
quality, which can be used, for instance, to produce aluminum-silicon alloys. 
The result is that the furnace operation is similar to prebaked electrodes, 
but the compound electrode is less expensive. Moreover, unlike S0derberg 
electrodes, the inside of the casing is absolutely smooth so as to allow the 
slippage of the electrode. Thus, the casing only acts as an extrusion sleeve. 
Another important advantage of the ELSA electrode is the supply of raw 
materials because there are many more factories in the world making graphite 
and S0derberg paste than making prebaked electrodes whose transport costs 

5.2 NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
87 
Motion system 
Graphite core 
Nipple 
Support 
system 
Pre-baked paste 
Casing-
Clamps 
Liquid paste 
Solid paste 
Figure 5.2 
The ELSA electrode. 
have always been very important. The disadvantage is that slipping velocity 
is not free as in prebaked electrodes, because the paste has to be baked before 
leaving the casing so it is necessary to have a minimum period of time be-
tween two consecutive slippings. Thus, as we noticed for S0derberg electrodes, 
baking of the paste is a crucial point in the working of this type of electrode. 
More precisely, the paste baking should be a continuous process for a suc-
cessful operation. The paste is baked in the contact clamps zone between 
100°C and 500°C, where it suffers several changes of state. The baking of 
the paste is closely related to the electrode current and slipping rate. Indeed, 
the electrode has to be slipped downwards to compensate its consumption 
on the tip, but slipping has to be done in small increments in order to avoid 
breakages in the soft paste. During normal operation, the baking zone is sta-
bilized within the lower part of the holder. If the baking zone comes below 
the clamps it can cause a leakage of soft paste. Then, the lower part of the 
electrode may slide into the furnace pot, causing a volatile species and the 
paste to catch fire. Therefore it is important to know the relation between 
electric current and slipping rate, and other parameters like temperature in 
the surroundings, temperature of the cooling-water, properties of the paste, 
etc., which can affect the position of the baking zone. 

88 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Figure 5.3 
Sketch of a reduction furnace. 
5.2.2 
Mathematical Modeling 
Since we are dealing with electromagnetic and heat transfer problems, mathe-
matical modeling of the ELSA electrode needs two coupled submodels. Firstly, 
we have to compute the electromagnetic field and, more specifically, the dis-
tribution of electric current represented by the current density field. This can 
be done by solving the quasi-static Maxwell equations, which are also called 
the eddy current model. From this field it is possible to determine the heat 
released by the electric current at each volume element of the electrode and 
then to compute the temperature field by solving a heat transfer model. No-
tice that several nonlinearities come to place arising from the change of state 
of the paste (Stefan's problem), from the dependency of thermo-physical pa-
rameters on temperature and from the radiative heat transfer. Moreover, the 
electromagnetic and thermal models are coupled together because electric cur-
rent is the heat source and, conversely, the electric conductivity of materials 
depends on temperature. 
Neglecting the proximity effect, we can consider axisymmetric models as a 
first step, in order to reduce the computational cost for solving the involved 
partial differential equations. 
Once the temperature is known, it could be also used in a thermo-elasticity 
model in order to determine the mechanical stresses which give us information 
on the structural behavior of the electrodes in order to prevent breakages. 

5.2 NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
89 
Each furnace has three cylindrical electrodes. Electric current enters through 
halfway each electrode through eight clamps made of copper that completely 
embrace the column (see Figure 5.3). Inside the clamps, water is flowing for 
cooling purposes. As electric current goes down, crossing the lower half of the 
electrode, it generates heat by the Joule effect. At the tip of the electrode an 
electric arc is produced, reaching temperatures of about 2500 °C. 
The paste surrounding the graphite starts baking at 350 °C in the contact 
clamp zone. From the top of the electrode to this level, the paste is held by 
a casing made of steel with a thickness of several millimeters. 
5.2.2.1 
The Electromagnetic Submodel. 
Neglecting the effects due to the 
proximity of the other two electrodes, we can assume axisymmetry in the 
problem and write the equations in cylindrical coordinates on a vertical sec-
tion Ω of the electrode (see Figure 5.4). For this purpose it is assumed that 
the input current does not depend on the meridian section and that it remains 
on this section. Moreover we also include the casing and the contact clamps 
in the domain Ω. 
To calculate the electromagnetic field, we must solve the Maxwell equa-
tions. Industrial current alternates with frequency / = 50 Hz. In this situa-
tion, the time scale for variation of the electromagnetic field is much smaller 
than the one for variation of temperature. Thus, we may consider the eddy 
current model to compute the electromagnetic field in the frequency domain, 
and then the heat source due to the Joule effect is determined by taking the 
mean value on a cycle. 
The eddy current model is obtained from Maxwell's equations (see, for 
instance, [9]) by neglecting the term involving the electric displacement in 
Ampere's equation. This can be done because the geometrical length scale in 
our situation is much lower than the typical wavelength of the current source. 
Moreover, assuming the current source is harmonic and all materials have 
linear electromagnetic behavior, all fields can be written in the form 
g{x,t) = Re{eMtG{x)), 
(5.2) 
where G is a complex field (vector or scalar, depending on the nature of Q) 
called complex amplitude or phasor and ω is the angular frequency. 
Using this expression in the time-domain eddy current model we get the 
frequency-domain eddy current model, 
iwB + curlE = 0, 
(5.3) 
curlH = J, 
(5.4) 
divB = 0, 
(5.5) 
B = μΗ, 
(5.6) 
J = σΕ, 
(5.7) 

90 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Graphife 
More than 
10 m. 
Air zone 
Water zone 
n«—Clamps 
Mixture height 
Mixture zone 
Aprox. 1 m. 
Figure 5.4 
Sketch of domain Ω. 
where μ is the magnetic permeability, σ is the temperature dependent electri-
cal conductivity, and B, E and H are the complex amplitudes associated with 
the magnetic induction, the electric field and the magnetic field, respectively. 
Straightforward computations from (5.3)-(5.7) allow us to obtain a single 
equation for the magnetic field in conductors, namely, 
ίωμΆ + curl ( —:—— curl H ) 
\σ(χ,Τ) 
) 
0, 
(5.8) 
where T denotes temperature. 
The assumption of axisymmetry of the input current leads to the indepen-
dency on the angular variable Θ of all fields and to a null azimuthal component 
of the current density, namely, 
J(r, Θ, z) = Jr(r, z)er + Jz(r, 
z)ez, 
where (r,z) belongs to the two-dimensional domain Ω (see Figure 5.4). It 
is useful to recall the expression of the curl of a vector field in cylindrical 
coordinates: 
curl F(r, 0,2) = -r 
er 
ee 
ez 
A. 
JL 
JL 
dr 
ΘΘ 
dz 
Fr 
rFe 
Fz 
(5.9) 

5.2 NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
91 
The above expression for J, together with (5.3), (5.6) and (5.7), imply that 
the magnetic field only has tangential component: 
H(r,9,z) 
= He(r,z)ee. 
(5.10) 
Using (5.10), Eq. (5.8) reduces to 
dz \σ dz ) 
dr\ar 
dr 
) 
In the computational domain, cooling water tubes are also included. Taking 
into account that water is a dielectric material, J — 0 in it. Then Eq. (5.7) 
must be rewritten in the form 
J = σΕ on C, 
(5.12) 
J = 0 on D, 
(5.13) 
where D is the region corresponding to water in the domain Ω and C — Q\D. 
Hence, Eq. (5.4) becomes 
curlH = 0 on£> 
(5.14) 
in the water. In order to handle this equation, we can use a so-called penalty 
method. The idea is to consider water as a conductor but with an electrical 
conductivity much smaller that the ones for the other conductors involved in 
the model. In other words, Eq. (5.14) is approximated by 
-(5E + curlH = 0 o n D , 
for δ very small compared with σ. In this way, equation (5.11) also holds in 
the water but with σ replaced by δ. 
5.2.2.2 
Electromagnetic Boundary Conditions According to the differential 
operators involved in the model, so-called essential and natural boundary 
conditions for the above problem consists of prescribing the values of 
a) H x n, 
b) J x n = curl H x n, 
respectively, where n denotes an outward unit normal vector to the boundary. 
In our case, due to cylindrical symmetry, the first condition means that He is 
given, which is a Dirichlet boundary condition for partial differential equation 
(5.11). In order to determine Hg on the boundary we proceed as follows: by 
the axial symmetry we know that 
J · n = curlH · n = 
, 
r 
or 

92 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Figure 5.5 
Boundary conditions: a) electromagnetic; b) thermal. 
where r is a unit vector tangent to the boundary (see Fig. 5.5). 
If we take a piece of boundary Γ# of the two-dimensional domain, between 
P and Q (see Figure 5.5) and denote j P Q the surface generated by its rotation, 
it is possible to determine H at a point Q if the intensity of current crossing 
7 P Q, to be called i(7PQ), is given. Indeed, by Stokes' theorem we have 
*(7pg) = !lpQ J · n d 7 = j i p Q curlH · n d 7 = /Γ?>υΓ^ Η · r d r 
= / Γ. ΗθΓάθ- 
Le 
Ηβτάθ, 
•Ί Q 
J 1 p 
Τθ
ρ and TQ being the boundary curves of 7 P Q. Since He does not depend on 
Θ we finally get 
i(7pJ = 27r((ri/ e)(Q)-(rJ/ e)(P)) 
and therefore 
In its turn, the natural boundary condition b) is suitable for the part of 
the boundary in contact with the electric arc, TE, because we may assume 
that the current gets out of the electrode perpendicular to this surface. 
5.2.2.3 
The Thermal Submodel 
As previously said, electric current dissi-
pates heat inside conductors that is responsible for increasing the temperature 
of the electrode. This temperature can be obtained by solving the following 

5.2 NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
93 
partial differential equation (it is the energy conservation equation which is 
also called "heat equation") 
p{x,T)c(x,T) 
(^+v(x,t)-&adT\-oiv(k(x,T)gtadT) 
= Q(x), (5.15) 
where p is density, c is specific heat, v is velocity, k is thermal conductivity 
and Q is the heat source, in our case due to the Joule effect. Temperature T 
depends on point x and time t. 
Electrode slipping is vertical and serves to make up for the wear suffered 
at its bottom due to high temperatures and chemical reactions. While this 
movement is very slow (several centimeters per hour) it is enough to determine 
that electrodes never are in a thermal steady state. The constitutive materials 
are restored in the upper zone. All of this allows us to suppose that v(a;, t) = 
V(t)ez, 
where ez denotes the unit vector along the axial direction, and that 
domain Ω does not depend on time. 
The heat source is the time average of Joule effect along a cycle, namely 
Q(x) = -f 
2W0 
J{x,t) 
■ E(x,t)dt. 
Taking into account the expression of a harmonic field (5.2) and Eq. (5.7) 
we get (see Exercise 5.4) 
Q(x) 
1 
Re(J(x) · E(x)) = 
-\J(x)\* 
σ 
1 |curIiJg(x) 
σ 
2 
Paste undergoes a change of state (generically denominated as "baking") 
at a temperature between 100°C and 550°C to be denoted by Tb. 
Then, 
Eq. (5.15) must be corrected to take into account the latent heat involved in 
this process by introducing an enthalpy function. More precisely, the heat 
transfer equation is rewritten in the form 
de 
Oe 
^ + V(i)—-div(fcgradT) 
Q, 
(5.16) 
where e denotes the enthalpy density which is expressed as a function of 
temperature by 
e e H(T), 
where 
H(T) = < 
JoP(s) Φ ) ds, 
r^, 
rTb 
j^p(s) 
c(s) ds, J^p(s) c(s) ds + p(Tb) L 
. SoP(s) Φ ) ds + p(Tb) L, 
T<Tb, 
τ = η, 
T>Tb. 
(5.17) 

94 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Taking into account axisymmetry, Eq. (5.16) becomes 
. 
1 d f,dT\ 
d f,dT\ 
Λ 
/r ,n. 
e--rd-r{k^)~ä-Z{k^)=Q>
 
( 5·
1 8 ) 
where e =: |f + V(i)|§ denotes the material time derivative of enthalpy. 
5.2.2.4 
Thermal Boundary Conditions Let us assume that the temperature 
on the surface of the electrode submerged in the mixture is given and equal 
to TM- This means that we have a Dirichlet boundary condition on ΓΆί· Be-
sides, on TR, a radiation-convection boundary condition is prescribed. More 
precisely, we write 
dT 
k-7— = g(Tc,Tr,T) 
on TR, 
where the nonlinear function g is defined by 
g(Tc, Tr, T) := h(Tc -T)+ 
7(Tr
4 - T4). 
(5.19) 
In (5.19), h is the coefficient of convective heat transfer, Tc and Tr are the 
external convection and radiation temperatures, respectively, and coefficient 
7 is the product of the Stefan-Boltzman constant, 5.669 x 10 - 8 
W/m2K4, 
times a parameter related to the emissivity of the surface of the electrode. 
With respect to convective heat transfer, let us introduce the Nusselt num-
ber which is the nondimensional number defined by 
Nu = IT' 
C being the characteristic length of the cooled surface and ka is the thermal 
conductivity of air. 
The convection coefficient for air has been obtained by using standard for-
mulas. For free convection on a vertical plane surface the following correlations 
for the Nusselt number can be found in the literature (see, for instance, [11]): 
Nu = 0.59 (GrPr)1/4, 
104 < Gr Pr < 109, 
Nu = 0.13(GrPr)1/3, 
109 < GrPr < 1012. 
where Pr and Gr are the Prandtl and Grashoff nondimensional numbers. 
For free convection on horizontal plates, Ref. [6] collects several formulas of 
various authors. For a heated plate facing up (or a cooled plate facing down) 
we have 
Nu = 0.54(GrPr)1/4, 
105 < GrPr < 2 x 107, 
Nu = 0.15 (GrPr)1/3, 
2 x 107 < GrPr < 3 x 1010. 

5.2 NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
95 
For a heated plate facing down (or a cooled plate facing up) 
Nu = 0.27 (GrPr)1/4, 
3 x 105 < Gr Pr < 3 x 1010. 
On the internal surface in contact with cooling water, only convective heat 
transfer is considered. The corresponding coefficient of convective transfer 
has been obtained by evaluating the heat transfer rate from the electrode to 
water. An average value of the latter quantity is given by 
H = pwcwq(T0-Ti), 
(5.20) 
where pw and cw are, respectively, the mean density and specific heat of water 
in the range of temperatures under consideration; Τί and T0 are the input and 
output temperatures of water in the cooling pipes and q is the water flow rate. 
Then a mean value for h can be calculated as 
""sprbä·
 
( 5 ·
2 1 > 
Ts being an average temperature of the cooled surface inside the contact 
clamps and S the area of this inner surface. 
In fact, since Ts is unknown, we cannot use this expression to obtain h di-
rectly. Therefore, we have adjusted h using numerical results. More precisely, 
we have first solved for different values of h the coupled problem; then we 
have calculated the total heat exchange between electrode and water, that is, 
L 
h(T - To) dr, 
and finally we have selected the value of h such that the corresponding total 
heat is closest to the theoretical value according to (5.20). 
5.2.3 
Numerical Solution 
Since the model is time dependent, for numerical solution we perform two 
successive discretizations in time and in space. 
5.2.3.1 
Time Discretization. Let [0, f/] be the time interval for simulation 
and Π = {to,. ■ ■ ,ti} a mesh consisting of I equally spaced points. Let us 
denote by Δί, the corresponding time step. 
To integrate the equation in time, we use an Euler implicit scheme. We ap-
proximate the value of the total derivative of enthalpy e((r, z), t) at (r, z ) £ f i 
and t = i n +i by the two-point finite difference formula: 
en+1(r,z)-en(Xn(r,z)) 
e{{r,z),tn+i) 
« 
— 
, 

96 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
where Xn(r, z) represents the position occupied at time tn by the material 
point which is at position (r, z) at time tn+\. Since the velocity field is space 
independent, X" is simply given by 
Xn(r,z) 
= (r,z- 
f"+1Vn(t)dt). 
Jtr, 
Multiplying Eq. (5.18) discretized in time by a test function and integrating 
in the meridian section Ω, we obtain, after using a Green's formula and tak-
ing boundary conditions into account, the following weak formulation of the 
discretized thermal problem: 
(WTP): For each tn+1 G Π, find a function Tn+1 such that T n + 1 = TM on 
TM and furthermore 
f 1 
/* 
/βΤ η + 1 dW 
dTn+1 
8W\ 
-J 
g(Tc,Tr,Tn+1)WrdT 
= j 
^ 
|curl 
H^+1\2Wrdrdz 
(5.22) 
for all test function W which is null on TM ■ 
Similarly, an approximation of the magnetic field at time fn+i, H^+ 
is 
determined as the solution of the following weak formulation of the electro-
magnetic problem 
(WEP): Find a function H£+1 such that Η#+1 — g onTH and 
[ iu>ßm+1Grdrdz+ 
[ 
, } ... 
Ja 
θ 
Jno-(Tn+1) 
dH£+1 dG 
) \ 
dz 
dz 
for all test function G null on TM ■ 
5.2.3.2 
Space Discretization. 
Problems (5.22)and (5.23) can be spatially dis-
cretized by a standard finite element method. More precisely, let us consider a 
mesh of domain Ω consisting of triangles. Then we approximate both temper-
ature and magnetic field by continuous piecewise linear finite elements defined 
on this mesh. 
5.2.3.3 
Solving the Discrete Problem: An Iterative Algorithm. 
We notice that 
a coupled nonlinear system must be solved at each time step, because heat 

5.2 NUMERICAL SIMULATION OF METALLURGICAL ELECTRODES 
97 
source depends on the solution of the electromagnetic problem and param-
eters k and σ depend on temperature. A fixed point algorithm has been 
used to solve this system which is described below. Moreover, enthalpy has 
been defined as a multivalued function of temperature preventing the use 
of Newton-like methods. Fortunately, Ή. as defined in (5.17) is monotonous 
and it is maximal in that its graph cannot be strictly included into another 
monotonous graph. Thus, in order to solve the nonlinear problem at each 
time step, we can use an iterative algorithm introduced in a general setting 
in Ref. [4]. This algorithm is based on the following result: 
Lemma 5.2.1 Let Ή be a maximal monotone operator. Then the following 
statements are equivalent: 
• e € H(T), 
• p — H"(T + λρ), with a, X > 0 such that Xa < 1, 
where Ή'χ is the so-called Yosida approximation of the shifted operator Ή — al 
that is defined as follows, 
? g ( j ) ) = [ / - ( / + A(7i-aDn(a)> 
s e R j 
qeQ 
A 
This result leads us to use the following algorithm, sketched in Fig. 5.6. 
Initial step.— Let T° be given. H° is calculated as the solution of the linear 
equation, 
f ■ ττθ^ 
. . 
f 
1 
/ 1 Ö - 
r r (ul d , =, 
dH°dG\ 
. , 
n 
(5.24) 
for all test function G null on TM-
Step n+1.— Let us suppose Tn and Hn are known. Then, at time £n+i, 
functions Tn+l and Hn+1 are obtained as the limit of sequences T" + 1, i7™+1 
constructed with the following iterative algorithm: 
1. Initialization. Let T£+1,HQ+1 
be given by, for instance, T£+1 = Tn and 
Hn+1 
= 
Hn 
2. Iteration s. Let us suppose T™^,H™^ 
are known. We successively 
determine H"+1 and T™+1 as follows: 

98 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
H™+1 is the solution of 
l^H^ärä^ 
+ l -φ^ (ί | W ) ^ > 
dz 
dz 
for all test function G null on TM-
T™+1 is the solution of the problem 
+ ^—^-)rdrdz 
= 0, 
(5.25) 
-£- / Ts
n+1 W r dr dz + f k (l^Ji1) S^d (Ts"+1) · grad W r dra dz 
= - f 
9(Tc,Tr,Ts"+1 
Wr dT + -J- / (en o X " - p? + 1) W r dr tfo 
+ / 
,Λ 
| c u r l ( H . " + 1 ) | V r d r d z , 
Ju σ (Ts_! J 
(5.26) 
for all test function W null on TM-
p™+1 is calculated by 
pn+l 
= n * (τ;ί+1 + λρη+1) _ 
5.2.4 
Numerical Results 
A computer code implementing the above numerical methods has been writ-
ten. It has been applied to simulate the evolution of temperature in a single 
ELSA electrode under industrial-like working conditions. In particular, slip-
ping and switching off have been considered. 
As an initial temperature we have taking the one corresponding to the 
steady state which has also been determined numerically. 
It can be seen in Figure 5.7 that, in a real situation in the factory, an 
electrode never reaches its thermal steady state. Moreover, a global look at 
this figure shows that temperature does not change too much along the time. 
In Figure 18.26, one can see how temperature decreases near the bound-
ary due to water and air cooling and increases again about one meter below 
the contact clamps, where the mixture of quartz and carbonaceous materials 
protect the column from heat losses. 
Electric current enters the electrode through a very small area in the lower 
part of the clamps. Current intensity is a datum for the model. The real part 
of the current density is shown in Figure 5.9 which serves to check that the 
major part of it goes to the graphite through the lower zone of the clamps. 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
99 
(Program initialization) 
Construction of the initial temperature 
(steady problem) 
Time Step 
Loop 
Motion update: X" 
Loop (iterations 
of the coupled problem) 
Resolution of the 
electromagnetic problem 
-Ϊ 
Loop (iterations in 
the multiplier/?) 
τ 
Resolution of the 
1 
Post-processing and 
results writing 
Figure 5.6 Flow chart of the algorithm. 
Accordingly, the production of heat is more important in this zone (see the 
Joule heating in Figure 5.10). 
The heat necessary for paste baking comes from the graphite, which is a 
better heat conductor, and it is also produced by the Joule effect at the lower 
end of the clamps. The interaction between this heat and the refrigeration 
due to water produces high gradients of temperature in this zone. 
5.3 
NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
5.3.1 
Introduction to the Problem 
In the last years, one common strategy for the environmental and landscape 
recuperation of open pit mines after their closure consists of filling the mining 
void with water. Diverting a neighboring river to fill the pit has been a 
frequently used technique to accomplish this task. Since mining lakes are 
generally in contact with natural rivers or streams, they must accomplish 
certain water standards set by the corresponding authorities. 

100 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Temperatures Temperature in C o l u m n 
^ s t e a d y state 
despents 
Electrical 
switch off 
M 
I I I t I I I I I 
I I 1 I I I I I I 
I I 
+000 
+2QQ0JQO 
+10000] 
+30GO.OO 
Time (minutes) 
Figure 5.7 
Temperature evolution. 
In the context of this problem, numerical modeling constitutes a unique 
tool to predict the water quality of a pit lake, not only at its maximum level, 
but also at each stage of the flooding period. Thus, it allows for the application 
in advance of any remediation strategy aimed at obtaining acceptable water 
quality conditions at the end of the flooding period. 
Modeling the water quality of a future pit lake requires, at a first stage, 
knowing which are the main factors that affect it. In this sense, the most 
important environmental problem associated with mining lakes is related to 
the presence of iron sulfides at the pit walls. The oxidation of these materials 
release acidity and heavy metals that might constitute a source of pollution 
of the pit lake (see [5], [8]). Waters of this type are very hazardous for the 
environment. They are also highly reactive, generally triggering a chain of 
chemical reactions whose relative importance will determine the final lake 
water quality. 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
101 
—± 
♦1(0 
.ISO 
r-axis(m) 
Figure 5.8 
Temperature in clamp's zone. 
Figure 5.9 
Real part of current density. 

102 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Oiradoiio d» Mbajo:PRUEBA 
Clamps 
Zone of maximum 
Joule heating 
FECHA: UJun-99 
Diam elect: 
990.(mm) 
Diim. grtltt.. 
490. (mm) 
AIL t elect 
30. (on) 
AH c. 
torn. 
63 (cm) 
Irrtemidad: 
70000. (A) 
F w e i t n t i i 
SO. (adeabtj)) 
CALOR 0ISIPADO Joalt (Wm*3) 
0. IT 
2889 HOOPS, 6492 TRIAHG. 
t4D5(W)7 
+ 3 7 1 W P 
+ 338Mt7 
»3040*07 
+ 270D+Q7 
+ 236D+07 
»202D+07 
™
„ 
+169D+07 
+.135D+07 
t101DtO7 
+G76D+06 
».33B0+O6 
Figure 5.10 
Heat released by the Joule effect. 
The input of water sources of different natures (different degrees of pollu-
tion) and the vertical circulation patterns of the lake contribute to an increase 
the complexity of this modeling work. 
Some hints to the way in which an environmental problem as the one intro-
duced here must be treated from a mathematical point of view are provided 
in the next sections. 
5.3.2 
A Stirred Tank Model to Predict Pit Lake Water Quality 
Any model aimed at predicting the water quality of a pit lake should take into 
account all the factors that were introduced in the previous section. There 
exist conceptual models of different complexity that integrate all these factors 
trying to provide a reliable water quality estimation, either analyzing extreme 
situations (conservative approach) or keeping them more realistic. 
In this section the focus will be posed on a stirred tank model that consists 
of assuming that the pit lake is completely mixed. This is equivalent to 
considering the whole lake as a water mass whose concentration is the same 
at each point. 
Complete mixing is a rather unlikely hypothesis in the particular case of pit 
lakes, either due to their characteristic morphology (the ratio lake depth/lake 
diameter is higher than in natural lakes) that is not prone to experiment 
mixing events that affect the whole water column (see [5]), or as a consequence 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
103 
or their geochemistry. Sometimes a denser and more polluted water layer 
occupies the lake bottom and does not mix with the upper ones. If complete 
mixing occurred, we would be considering the most pessimistic situation in 
terms of water quality: the more polluted water layers at the lake bottom 
would mix up with the cleaner ones at the surface and then the last ones, which 
are generally in contact with rivers, streams, etc., would be more polluted. 
In this sense, the stirred tank model, based on the hypothesis of complete 
mixing, constitutes a valuable tool for decision makers. 
The following sections will be devoted to formulate mathematically a stirred 
tank model—a zero-dimensional model—whose water quality will depend on 
the geochemistry of the water sources that feed the lake as well as the chemical 
reactions that were mentioned in Section 5.3.1. Therefore, its development 
mainly consists of setting the suitable volume and mass conservation equa-
tions. 
5.3.2.1 
Notation 
Related to the Lake Morphology. 
The conceptualization of the stirred tank 
model is represented in Figure 5.11. 
qNs (t) 
Figure 5.11 
Stirred tank conceptual model. 
Frequently, the water quality of pit lakes is studied from the beginning of 
the lake flooding to its end but, for the sake of simplicity, in this presentation 
we will focus on an already flooded lake. In this way, Ω denotes the region of 
the space that is occupied by the lake and V is its (constant in time) volume. 
The boundary of Ω, named Γ, is such that 
Γ = Γ 6 υ Γ α , 
(5.27) 
with Γ6 and Γ α the parts of the boundary that represent the pit wall/water 
interface and the air/water interface, respectively. 
At each time, the lake receives water from different sources: river water, 
rain, subterranean water, infiltration water, etc. The number of these water 

104 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
sources is represented by iVs and qj(t), j = 1,... ,NS is used to refer to their 
respective flow rate in m3/s. Since the lake volume remains constant, all the 
water inputs must be compensated by an equivalent output. In this sense, if 
we take into account that the water inputs intercept Ω at certain places of 
the boundary Γ, it can also be defined as 
Γ = Γ ι υ · · · υ Γ ν υ Γ ° υ Γ / , 
(5.28) 
with Tj, j = l,...,Ns 
the part of Γ through which the j-th water source 
enters Ω, Γ°, the part of Γ through which the completely mixed waters of the 
lake leave and Γ1 the impervious part of Γ. 
It must be mentioned that the lake morphology data, such as its volume V, 
the area of the air/water interface Sa, the area of the pit wall/water interface 
Sb, etc., are generally known, as they are usually provided by the mining 
companies. 
Related to the Water Quality. The water quality of a pit lake is determined by 
the presence of certain chemical species Ei,i = l,...,N 
whose concentration 
at each time are expressed by yi(t), i = 1,...,N. 
As it was already men-
tioned, the time evolution of the concentration of each chemical species will 
depend on the geochemistry of the water sources that enter the pit but also 
on the chemical reactions that occur in its interior. Focusing on the chemical 
reactions, the notation that will be considered to represent their effect is as 
follows: 
• rf (t,yi(t),... 
,yjv(i)) is the production rate in mol/(s m2) of species E\ 
from the chemical reactions that take place at Γ°. 
• r%(t, 2/i (i),... ,j/jv(i)) is the production rate in mol/(s m3) of species Ei 
from the chemical reactions that take place in the water column. 
• r^(t,yi(t),... 
,yjv(i)) is the production rate in mol/(s m2) of species Ei 
from the chemical reactions that occur at Γ*, j = 1,..., Mr. Since each 
mineral presents its own reaction rate, notation r j , j = 1,..., Mr is used 
to refer to the part of the boundary Tb that the j'-th mineral occupies, 
MT being the total number of reacting minerals at this surface whose 
effect on the pit lake water quality will be considered. 
5.3.2.2 
Conservation Equations 
Volume Conservation Equations. If we denote by n the normal unit vector 
pointing outwards the lake domain Ω, by v,·, j = 1,..., Ns the velocity of the 
water sources that enter the pit and by v the velocity of the pit lake outflow, 
it follows that 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
105 
dV(t) 
dt 
Y / 
Vj(x,t).n(x)dSx 
+ / 
v(x,t).n(x)dSx 
=Yyqj(t)-q0(t). 
(5.29) 
Notice that the sign of the first integral is negative because we are dealing 
with inputs and n is defined to be pointing outwards. A similar argument is 
applied to explain the positive sign of the second integral. 
Since our model assumes that the lake is already flooded, dV(t)/dt 
= 0. 
Therefore, qo(t), which is the water flow rate outside the lake, verifies 
Na 
9b(t) = £ > ( * ) · 
(5.30) 
3=1 
Mass Conservation Equations. The amount of substance in moles m,i(t), i = 
1,...,N 
of the ith chemical species in Ω is given by 
m. (t)= f yi(t)dVx = yi(t)V, 
(5.31) 
being its time evolution calculated as 
M 
dm,i{t) 
dt 
[ r'(t,y(t))dVx+Σ [ rb
zj(t,y(t))dTx+ [ rf{t,y{t))dTx 
N° 
y2 
a.ij(t)vj(x,t)-n(x)drx+ 
Vi(t)\{x,t) 
■ n(x)dTx 
„·_ι JTH 
if" 
j=lJT. 
Vr?(i,y(i)) + 50ff(i,y(i)) +535^.(i,y(i)) +Σα«(ί)?,·(ί) -
3=1 
3=1 
Vi(t)qo{t), 
(5.32) 
where y(i) = (yi(t),... 
,yN(t)), 
α^(ί), i - Ι,.,.,Ν, 
j = 1,...,NS 
is the 
concentration of the i-th chemical species in the jth water entrance to the 
lake at time t, Sa is the area of the air/water interface and Sj, j = 1,..., Mr 
is the area occupied by the jth mineral at the pit wall. 
If we take the time derivative of Eq. (5.31), we get 
dmjjt) 
dyi{t) 
-dr 
= v-dT·
 
( 5 ·
3 3 ) 

106 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
The time evolution of the concentration of each chemical species can be easily 
obtained by combining equations (5.30), (5.32) and (5.33). Namely, 
1 
+v 
dt 
Mr 
N 
j=l 
.7 = 1 
(5.34) 
By now we have just mentioned the way in which the chemical reactions 
must be taken into consideration but nothing has been said about the kinetics 
of these reactions, i.e., about terms r\, rf and r\y This will be the objective 
of the next section. 
5.3.3 
Mathematical Models for Chemical Reaction Systems 
The chemical species whose concentrations determine the pit lake water qual-
ity are involved in a set of chemical reactions that are occurring at different 
places within the lake, as it was explained in Section 5.3.2.2. Depending on 
the velocity at which these reactions proceed with respect to the time scale of 
the problem, two basic theories are applied: finite rate chemical kinetics and 
equilibrium. If the velocity of the chemical reactions is fast when compared 
to the time scale of the problem, the system could be considered to reach 
equilibrium. On the other hand, if the reaction rate is similar to the selected 
time scale, reactions should be kinetically described (see Ref. [12]). 
In this section we will introduce the formal mathematical framework to de-
scribe the evolution of the concentration of a set of chemical species according 
to the theories of chemical kinetics and equilibrium. Notation is based on Ref. 
[2]· 
Let us start by considering that the chemical reactions in which the N 
chemical species of interest, Ei, i — 1,..., N are involved, can be represented 
by 
i/iE1 + ... + JNEN^>)iLEi 
+ ... + \l
NEN, 
\<1<L, 
(5.35) 
with v\ and λ' the stoichiometric coefficients, that are always positive. In the 
following, they will also be assumed to be integers. 
5.3.3.1 
Finite Rate Chemical Kinetics. According to this theory, the evolu-
tion of the concentration of the ith chemical species is governed by an ordinary 
differential equation system (ODE) of the form 
dyi(t) = J2(X\-vl
iMy1,...,yN), 
(5.36) 
dt 
/=i 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
107 
where δι is the velocity of the Z-th chemical reaction, its expression being 
dependent on the complexity of the reaction. In this sense, 
• If the reactions are elementary, meaning that they proceed in a single 
step, δι is written as 
N 
Si = kiY[yi(tf*, 
(5.37) 
i=l 
with ki the rate constant, that depends on the temperature through the 
Arrhenius law (see, for instance, Ref. [12]). 
• In most of the literature sources 
N 
δι = kiYlyiit)^, 
(5.38) 
where v\ is the partial reaction order with respect to the i-th reactant 
and Σ% ν\ 1S the total reaction order. In general, v\ has nothing to do 
with the stoichiometric coefficient of the ith reactant. 
• In complex reactions, the mathematical expression for δι does not follow 
any rule, as the ones above, its formula being empirically obtained in 
most of the cases. Therefore, in general, δι will be a function 
<*i =/I(2/I,...,2/JV). 
(5·39) 
If we assume, for simplicity, that all the chemical reactions are elementary, 
the problem that must be solved to obtain the water quality consists of the 
following system of ODEs 
r ägiii = Ef=1(^-^)fclniL1%(i)"i, 
i = i,...,N, 
( 5 4 0 ) 
\ 2/i(0) 
=yi,init, 
which is obtained by using (5.37) in Ref. (5.36). 
A proof on the existence and uniqueness of solution to problem (5.40) can 
be found in [3]. 
5.3.3.2 
Chemical Equilibrium. From a thermodynamic point of view, a sys-
tem in chemical equilibrium is a steady state characterized by a minimum in 
the Gibbs free energy. Consequently, one of the available methods to obtain 
the equilibrium concentration of a set of chemical species consists of mini-
mizing the Gibbs free energy subjected to certain restrictions (see Refs. [2], 
[12], [12], etc.). However, in this chapter we will exploit the existing rela-
tionship between the kinetic theory and equilibrium. In this sense, we will 
keep the same notation for the set of chemical species Ei, i — 1,..., N, being 
involved in a set of chemical reactions such as those in Eq. (5.35), but this 

108 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
time I = 1,..., 2 J representing a set of J reversible couples of reactions that 
are characterized by the fact that the stoichiometric coefficients satisfy 
V; 2 j - i _ \2j 
X?, 
j = l,...,J. 
(5.41) 
Before going into further details of this method, let us introduce the following 
definition. 
Definition 5.3.1 We will denote by rii, i = 1,... ,N the molinity of species 
Ei, i.e., the number of kmol of the ith chemical species per kg of solution. 
Thus, 
rn = - , 
(5-42) 
P 
where p is the solution mass density in kg/m3. 
In order to keep the explanation of this method as simple as possible, only 
one of the reversible reactions in (5.35) will be considered, namely, 
νχΕχ + ... + vNEN ^ λι£Ί + ... + \NEN. 
(5.43) 
2 
We define 
X i : = u f = Xl, 
(5.44) 
Vi:=\\ = v\. 
(5.45) 
By assuming that both the forward and backward reactions in (5.43) are 
elementary, the reaction velocities <5i and 62 can be written according to Eq. 
(5.37) as 
N 
N 
Si=kiY[y? 
and 
52=k2\{y^. 
(5.46) 
*=1 
t = l 
Thus, the ODE system in Eq. (5.40) becomes 
dyjjt) 
dt 
with 
= (Xi-Vi)S*{t), 
(5.47) 
S*=(kif[y?-k2f[yA. 
(5.48) 
V 
i=l 
i=l 
/ 
Since yi = n^p (after Definition 5.3.1), equation (5.47) can be rearranged 
in such a way that we obtain 
1 ~/^=nt). 
(5-49) 
(Xi - Ui) 
dt 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 109 
By integrating this system of equations 
Ttl(t) - Tiding _ 
_ njy(i) - 
riN,init 
(λι - I/i) 
(XN - I/JV) 
with ξ(ί), the reaction extent, given by 
: £(i), 
(5.50) 
i r* 
ξΗ) = - / S*(s)ds. 
(5.51) 
From Eq. (5.50), n», i = 1,..., N can be written in terms of the reaction 
extent as 
rii(t) = nitinit + {Xi - νί)ξ(ί). 
(5.52) 
Let us go back for a moment to the definition of equilibrium as a steady 
state. In this sense, it is characterized by the fact that dyi(t)/dt = 0, which 
is equivalent to δ* = 0 in Eq. (5.48) and, hence, 
Y=f[y-'~Ui=^, 
(5.53) 
i=l 
where Ke is called the equilibrium constant for reaction (5.43). 
Equation (5.53) expresses the relationship between the equilibrium con-
stant and the forward and backward rate constants. 
By taking into account in Eq. (5.53) that yi = prii and replacing rii by its 
expression as a function of the reaction extent in (5.52), we obtain 
N 
Ke(6) = ρΣί1ι(λ*-*) J](nMmt + (Ai - Vi)0Xi-Vt, 
(5.54) 
which is an algebraic equation that must be solved for ξ to obtain the equi-
librium concentration or, in other words, the water quality when equilibrium 
conditions are applicable. 
5.3.3.3 
Coexistence of Slow and Fast Chemical Reactions. There exist prob-
lems in which the chemical species Ei, i = 1,... ,N are involved in chemical 
reactions that proceed at different time scales, some of them being very fast 
in the time frame of interest, some others being slower. 
In this section, the notation for the chemical reactions in Eq. (5.35) is 
conserved, although 1 = 1,... ,L + 2J, with the first L slow chemical reactions 
and the last 2 J, J couples of reversible reactions that satisfy 
vf+V-1 = X^+2j, 
(5.55) 
^f+2i-i = 
f+2i5 
j = i ; . . . , j . 
(5.56) 

110 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
From Eq. (5.36) and by considering a kinetic description of the equilibrium 
reactions [see Eqs. (5.47) and (5.48)] we obtain 
dVi{t) 
dt 
: j^{\\ - vi)5,(t,y(t)) + Σ ^ -
1 - 
Vi
L+2^)[5L+2j^{t,y{t)) 
1=1 
3 = 1 
-6L+2j(t,y(t))), 
(5.57) 
where δι, I = 1,..., L are the velocities of the slow chemical reactions and 
SL+2J-I 
and 6L+2J, j = 1, · · ·, J are the velocities of the fast forward and fast 
backward reactions, respectively. 
Under the assumption of elementary reactions [see Eq. (5.37)], (5.57) is 
transformed into 
dyjjt) 
dt 
1=1 
i=l 
j=l 
L+2J-1 
_ 
vL+2j-l 
N 
L-
i=l 
N 
-kL+2j'[[yi
i 
i=l 
(5.58) 
In Eq. (5.58), all the rate constants present different units. In this sense, 
it is not possible to compare them in a homogeneous way and, hence, it is 
difficult to define by means of a numerical value what is a slow reaction or 
what is a fast one. In order to overcome this problem, it is necessary to scale 
(5.58); thus, all the magnitudes would be in the same units and, hence, they 
could be compared. For this purpose, the following dimensionless variables 
are defined 
Vi(t) 
, 
f 
t 
Vitf) = 
and 
t = r 
(5.59) 
where Yi and T are the typical scales for concentration and time in the prob-
lem. The scaled problem is obtained by writing the original one in terms of 
the dimensionless variables (5.59) . Namely, 
Yjdjjj 
T dt 
L+2J 
N 
Σ (λ' - ^k IK 4+Σί^*- 1 -1^*-1) 
1=1 
i=l 
j=l 
N 
i=l 
L + 2J-1 
N 
~ h+23 Π Vi* 
(5.60) 
i=l 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
111 
where 
ki = kiY[Yl'i, 
I = 1,...,L, 
(5.61) 
i=l 
N 
kL+2i-i 
= kL+tj^JlY? 
, 
(5.62) 
t = l 
Now, in Eq. (5.60) all the rate constants are given in the same units, so we 
are able to compare them in order to reach to the limit. 
Let us assume that ε > 0 is a small positive parameter describing the ratio 
of fast time scales to slow ones. More precisely, let us assume the following 
properties: 
ki = 0(l), 
l = l,...,L, 
(5.64) 
Cie" 1 < kL+2j-i 
< C2e-\ 
(5.65) 
Cie-1 < kL+2j < C2e~\ 
(5.66) 
for j = 1,..., J, for small enough e, and for some positive constants C\ and 
C2, and 
Kj = ——-—, 
j — 1,..., J 
are independent of ε. 
(5.67) 
kL+2j 
Under assumptions (5.65) to (5.67), the model can be written as 
Ά 
= f (i, y(i)) + -Age (t, y(i)), 
(5-68) 
at 
e 
with f = (/i,..., /JV) being the function that involves the slow chemical re-
actions, fi(t,y(t)) 
= § Σι1ι(λί - v\)h n i l i yf\ and ±A&(t,y(t)) 
the term 
that represents the contribution of the fast reversible reactions. In this last 
term, Λ is a N x J matrix of components Aij = ψ{\ 
+ 3~ — i>i + J~ ) 
and g£ = (gl,...,9%), 
with g?(t,y(t)) 
= ekL+2jgj(t,y(t)), 
being ^ ( y ) = 
Passing to the limit when ε —> 0 in the nondimensional scaled model (5.68) 
yields the dimensional limit model, 
y'(t)=f(t,y(t))+Aep%t), 
g(i,y(t)) = 0, 
} 
(5.69) 
y(0) = yinit, 

112 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
where Afj 
(the complete development of this limit model 
yL+2j-\ _ 
L+2J-1 
can be found in Ref. [3]). 
Functions p e = {p\,... ,pej) can be considered as Lagrange multipliers as-
sociated with restrictions g(i, y(i)) = (gi,·· -,gj)· 
Since p?, j = 1,..., J 
can be either positive, negative or zero, these restrictions are equivalent to 
Pj € W(öj), Vj = 1,..., J, with Ή the multi-valued maximal monotone func-
tion, 
, . 
ί 0 
if x < 0 and 
x > 0, 
, 
. 
n ^ 
= { (-00,00) 
if 
x = 0, 
( 5' 7 0 ) 
where 0 denotes the empty set. In addition, p? e "H(gj) & Pj = T~lx(gj + 
^Pi) — Pj + jgji 
VA > 0 and not necessarily a small number. This equivalence 
which is trivial in the present case, is a general result for maximal monotone 
operators such as H, with Ηχ its Yosida approximation (see Lemma 5.2.1). 
Functions H(x) and H\(x) are shown in Fig. 5.12. 
W(x) 
lHx{x) 
Figure 5.12 
Functions H(x) and H\{x) 
The Particular Case of Solubility Equilibria. Solubility equilibria are particular 
cases of equilibrium reactions in which certain dissolved chemical species are 
in equilibrium with a solid that contains them. These reactions may advance 
in the sense of precipitation, meaning solid formation, which occurs when the 
concentration of the dissolved species exceeds a certain threshold, or in the 
sense of dissolution, implying a decrease in the concentration of the solid and 
an increase in the concentration of the dissolved chemical species. 
In this section we will deal with problems in which slow chemical reac-
tions coexist with solubility equilibria. Moreover, solubility equilibria will be 
treated only in the sense of precipitation in such a way that, when a solid has 
formed, it will irreversibly disappear from the dissolved phase. 
Again, the general set of reactions in Eq. (5.35) will be considered, although 
this time I = 1,... ,L + M, L being the number of slow chemical reactions and 
M the number of solubility equilibria. Solubility equilibria increase by M the 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
113 
number of chemical species, thus Ei, i = 1,..., N+M, with Εχ+ι,..., 
EN+M 
the precipitated solids . 
Since the solubility reactions are only considered in the sense of precipi-
tation (a kind of unilateral equilibrium) and precipitates are generally repre-
sented as reactants (the species for which v — λ > 0), a solubility reaction will 
be written as 
uL+mEi 
+ _ _ + uL+mEN 
+ U^EN+1 
+ ... + 
v^EN+M 
^\f+mE1 
+ ... + \%+mEN 
+ \j^EN+1 
+ ... + \L
N
+™MEN+M, 
1 < m < M, 
(5.71) 
where the bigger arrow points to the left, indicating that just the precipitation 
way is important, although a smaller arrow pointing to the right still exist to 
represent that solubility is an equilibrium and thus requires information both 
from reactants and products. 
On the basis of the information above, the time evolution of a chemical 
species that is involved both in slow and solubility equilibrium reactions is 
written as 
dyjjt) 
dt 
M 
fi(t,y(t)) + E ( - ^ L + m + 
^+m)kL+, 
m=\ 
N 
N 
j=l 
i + 
i = l,...,N 
+ M, 
(5.72) 
where fi(t,y(t)) 
denotes the contribution of the slow chemical reactions, 
kL+m, m = 1,..., M is the rate constant in the sense of precipitation and 
K^, m = 1,..., M is the solubility equilibrium constant for the mth precipi-
tation reaction. The solubility equilibrium constants include the concentration 
of the precipitated solids because they are considered to be constant. 
Notice that just the positive part of the term in squared brackets in Eq. 
(5.72) is taken into account, meaning that just the displacement of the chem-
ical reaction (5.72) from right to left is accounted for. Recall that a+ = 0 if 
a < 0 and a+ = a otherwise. 
The limit of (5.72) is obtained by applying a similar procedure as for Eq. 
(5.58), which is 
dy(t) 
f(t,y(t))+Asps(t), 
dt 
gs(t,y(t))<0, 
Ps(t) > 0, 
Es(tMt))Ps(t) = o, 
y(0) =y»„it, 
(5.73) 
(5.74) 
(5.75) 
(5.76) 
(5.77) 

114 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
where As is the (N + M) x M matrix of components A\m = {-Xf+m + 
v^+m), 
ps(i) = (pf(i), ·.. ,P%i(t)) is the vector of Lagrange multipliers associated 
with the inequality restriction functions gs(i, y(i)) < 0 and the product 
gs(i>y(*))ps(i) refers to the vector (gfpf,... ,9SMPSM)- The m-th component 
of g (t,y(t)) 
is given by 
N 
N 
9
s
m(tMt)) = -κ'ηγ[υί{φ+m 
+ Unit)**' 
m = l , . . . , M . 
(5.78) 
i = l 
Conditions (5.74)-(5.76) are equivalent to ps
m e £(#„), Vm = 1,...,M, 
with ^ the multi-valued function 
( 0, 
x < 0, 
g{x) = { Q, 
x>0, 
[0, oo), x = 0, 
(5.79) 
Pm = Q\{9S
m + 
where 0 denotes the empty set. Moreover, ps
m e G{g^n) 
Xps
m) = max{Q,ps
m + jg!^} VA > 0 and not necessarily a small number (see 
again Lemma 5.2.1). We recall that function Q\ is the Yosida approximation of 
the maximal monotone operator Q, both of them being represented in Figure 
5.13. 
g(x) 
J0x(x) 
Figure 5.13 
Functions Q{x) and Qx(x) 
5.3.3.4 
The Complete Stirred Tank Problem. Once the mathematical treat-
ment of chemical reactions that proceed at different velocities has been ex-
plained in detail, we can go back to Section 5.3.2 to complete the formal 
mathematical writing of the stirred tank model. In particular, we will fo-
cus on Eq. (5.34). First of all, it will be assumed that the contributions 
of the chemical reactions that occur at the air/water [rf(t, y(i))] and at the 
pit wall/water interfaces [ί"^·(ί,γ(ί))] are slow, as it normally occurs. On the 
other hand, the chemical reactions that take place in the water column may 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
115 
be slow or fast, the latter considered to be in equilibrium. Solubility equilibria 
are also allowed. 
On the basis of the notation in (5.69) we consider that: 
• r?(i,y(i)) = /f(i,y(i)) + E/=i^P?(i,y(i)) + Ef=1A^(i,y(i)). i = 
1,..., N+M, with /? the slow chemical reactions occurring at the water 
column, p? the Lagrange multiplier associated with the jth equilibrium 
reaction and ps
k the Lagrangre multiplier associated with the fcth solu-
bility reaction. 
Ser-(t,y(t)) =/?(*, y(i)). 
E?=iSb^(t,y(t)) 
= fHtMt)). 
Therefore, the complete stirred tank model would be written as 
dyi(t) 
= JiVhy^)) -r 
j=\ 
fc=l 
dt 
J 
M 
1 
mtMt)) 
+ f!(t,y(t)) 
Ns 
+ 
Y,(aij(t)-yi(t))qj(t) 
3 j
e(i,y(i))=0, 
j = 
l,...,J, 
Si(i,y(i))<0, 
k = 
l,...,M, 
ps
k(t) > o, 
gmPk(t) 
= 0, 
K 2/t(0) = Vi,init-
, 
i = l,...,N 
+ M, 
(5.80) 
(5.81) 
(5.82) 
(5.83) 
(5.84) 
(5.85) 
5.3.4 
Numerical Solution of the Model 
5.3.4.1 
Numerical methods. 
This section concerns the numerical solution of 
the chemical model involving Lagrange multipliers (5.69). 
Two main elements are proposed in order to carry out this task: 
1. A Euler implicit scheme for the time discretization of the problem. 
2. An iterative algorithm to solve the discrete problem. 
Time discretization of the problem. The time interval of interest (0, tf) is uni-
formly partitioned, the approximate solution of the problem being calculated 
at each tn = nAt, with Δί = tf/N and 0 < n < N. 

116 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
The approximate solution of the problem at each tn is obtained by consid-
ering an Euler implicit scheme. The discrete version of (5.69) is as follows 
If n = 0, 
y° = Yinit, 
(5.86) 
If n > 0, 
y " + 1 = y " + A i [ f ( i „ + 1 , y " + 1 ) + i p " + 1 ] , 
(5.87) 
g ( i „ + 1 , y " + 1 ) = 0 , 
(5.88) 
where y™ denotes the approximation to y(t„), as it is usually done. 
Thus, the nonlinear system of numerical equations (5.87) and (5.88) must 
be solved at each time step in order to obtain y™+1 and p n + 1 from yra. 
The Iterative Algorithm. 
The proposed iterative algorithm consists of two 
nested loops: 
• An external loop to create the sequence p™+1 that converges to the 
multiplier solution of the problem. 
• An internal loop to solve the nonlinear system regarding y n + 1. 
Figure 5.14 shows the flow diagram of the algorithm. Notice that the 
curved-edge rectangles are not themselves steps of the algorithm, but the 
task that will be carried out in the loop afterwards. It mainly comprises four 
steps: 
1. Initial guess for the Lagrange multipliers: p™+1 = p". 
2. Calculation o/y™+1, by solving the non-linear system in (5.87), where 
the Lagrange multiplier provided in the previous step is used. 
The 
numerical solution of this nonlinear system must be obtained iteratively 
by applying, for example, Newton's method. This iterative algorithm 
constitutes the "internal loop." 
3. Updating p™+1 once yP + 1 has been obtained as [see the comments after 
Eq. (5.70)] 
P" + 1 = Ρ?±ί + ^g(tn+i,y? + 1)- 
(5-89) 
4. Applying a suitable convergence test for the Lagrange multipliers. 
The successive repetition of the external loop (and the nested internal loop) 
provides the approximate solution of the problem at time tn+\. 
5.3.5 
Numerical Results: A Simplified Chemical Problem. 
The above numerical methods have been applied to simulate the water quality 
of the pit lake that is now being flooded in the open pit coal mine of the 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
117 
Solution at tn 
I 
( Lagrange multipliers calculation j 
( Computation of y" + 1 J 
Initialization: y^Q1 
JeL 
Updating: yji 
ΊΖ 
Convergence test 
YES 
NO 
Updating p " + 1 
X 
Convergence test 
tYES 
Solution at tn+\ 
m = m + \ 
■■ r+ 1 
Figure 5.14 
Flow diagram for the iterative algorithm. 
Spanish company LIMEISA, in Cerceda (A Coruna, Spain). The geochemical 
model retained is very complex and can be found in Ref. [7] where numerical 
results are extensively shown. 
A simplification of this model has been chosen to illustrate the way in 
which a water quality problem can be stated and subsequently solved. For 
this purpose, we will consider that the lake has no water inputs/outputs and 
that no chemical reactions at the air/water or pit wall/water interfaces are 
taking place. These assumptions imply that only the first three terms after 
the equal sign in Eq. (5.80) are non-null. In other words, we will deal with 
a fictitious example in which a set of chemical reactions are occurring at the 
water column. These reactions, although real, are treated in a fictitious way 
because the reaction velocities, equilibrium constants and solubility constants 
do not have to do with the ones that can be found in the literature for the 
same chemical reactions. 
Problem statement. 
The water quality of our stirred tank model will be de-
fined by six chemical species, five of them dissolved (N = 5, i = 1,..., 5 in 
Table 5.1) and a solid one (M = 1, i = 8 in Table 5.1). These species are 
involved in four chemical reactions: one is slow (L — 1, / = 1 in Table 5.2), 
two homogeneous equilibria (J = 2, I = 2,3 in Table 5.2) and a solubility 
equilibrium (M = 1, I = 4 in Table 5.2). 
Notice that δχ in Table 5.2 denotes the velocity of the slow chemical reac-
tions, K\ and K2 the equilibrium constants and Ks the solubility constant. It 
must also be mentioned that, in reaction I = 1 the concentration of dissolved 

118 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Table 5.1 
Chemical species. 
i 
1 
2 
3 
4 
5 
6 
Ei 
FeOH2+ 
OH-
Fe3+ 
H+ 
Fe2+ 
Fe(OH)3{s) 
Table 5.2 
Chemical reactions. 
Chemical reaction 
Reaction velocity or equilibrium constant 
Fe2+ + H+ + \02{aq) 
— Fe 3 + + 
\H20 
Fe3+ + H20 ^ FeOH2+ + H+ 
H20 — H+ + OH~ 
Fe{OH)3(s) 
+ 3H+ ^ Fe3+ + 3H20 
δι 
Ki 
K2 
K" 
oxygen is considered to be enough for the reaction to proceed. In general, the 
reaction velocity δ\ depends on the oxygen and Fe2+ 
concentrations, but for 
simplicity we will assume that it is constant. 
The homogeneous equilibria I = 2,3 impose restrictions on the concentra-
tion of the chemical species. Namely, 
5i = -2/1 + — 
= 0, 
(5.90) 
92 = -V2 + — 
= 0, 
(5.91) 
2/4 
where yi,- ■ ■ ,ye are the concentrations of the chemical species in Table 5.1. 
The concentration of Fe3+ 
(species E3 in Table 5.1) is also constrained by 
the solubility equilibrium / = 4, which is the associated restriction function 
given by 
9s = 2/3 - ^ 
< 0. 
(5.92) 
2/4 

5.3 NUMERICAL SIMULATION OF PIT LAKE WATER QUALITY 
119 
Thus, the problem that must be solved to obtain the concentration of the 
chemical species along time in the stirred tank model is 
»ί(*)=Ρί(*), 
ί^(*)=^(*). 
y'3(t)=öi-Pt(t)-P
s(t), 
y'i(t) = -S1+Pt(t)+pe
2(t) 
+ 3ps, 
Ι/6(*) = -*ι. 
y'6(t)=Ps, 
9i = -2/1 + J f = 0, 
52 = -V2 + % = 0, 
(5.93) 
Kr < 0 , 
9 = 2/3 
Ps>0, 
PS9S = 0, 
Υ(0) = Yinit-
where pf, pf a r e * n e Lagrange multipliers associated with equilibria I = 2,3 
and p s is the Lagrange multiplier associated with solubility equilibrium I = 4. 
Numerical results. The proposed example is solved by considering the data 
summarized in Table 5.3, regarding reaction velocities and equilibrium con-
stants, and Table 5.4 that compiles the initial conditions for the problem. 
The initial conditions are obtained by considering that the slow and solubility 
reactions are frozen at t = 0 and that the initial pH = 6.5 (pH = —log(yi)). 
The algorithm in 5.3.4.1 has been considered to carry out the numerical so-
Table 5.4 
Initial conditions. 
Table 5.3 
Data for the example. 
Reac. vel or eq. cte. 
Value 
δι 
Ki 
κ2 
Ks 
10"8 
10~7 
1 0 - 1 4 
1012 
2/i(0) (mol/l) 
1 
2 
3 
4 
5 
6 
0 
1 0 - 7 . 5 
0 
1 0 - 6 . 5 
10"4 
0 
lution of the example, although in this case it will not be necessary to solve 
a nonlinear system of equations at each iteration of the external loop r to 
obtain y™+1 because δ\ is constant. 
The λ value in Eq. (5.89) was selected to be 0.1 both for the Lagrange multi-
pliers associated with homogeneous equilibria and the ones related to solubility 
reactions. The convergence criterium for the external loop is 
maz(10-3||p?+1||,(10-3)2). 
■»"+1. -p-iil < 

120 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
Figure 5.15 shows the obtained results for Fe2+, Fe3+ and pH both when 
solubility equilibrium is considered (purple line) and when it is not (green 
line). The precipitation of Fe{OH)z, which starts less than five seconds after 
the beginning of the simulation, brings as a consequence a decrease in the pH 
(see Figure 5.15 C) because H+ is released in reaction / = 4. The solubility 
reaction also constrains the concentration of Fe 3 +, as it can be seen in Figure 
5.15 B. Finally, Figure 5.15 A shows that the solubility equilibrium has no 
influence on the concentration of Fe2+, as it is only involved in reaction I = 1 
that proceeds at a constant rate. 
0 
10 
2
0
3
0
4
0
5
0
6
0
7
0
8
0
9
0 
1«) 
Time 
Figure 5.15 
Time evolution of: A: concentration of Fe 
, B: concentration of 
Fe3+ and C: pH. 
EXERCISES 
5.1 
Obtain Eq. (5.8). 

EXERCISES 
121 
5.2 
From the expression of the curl operator in cylindrical coordinates (5.9) 
and assuming that 
A = 
Ae(r,z)ee 
obtain successively, 
• curlA, 
• curlcurlA. 
5.3 
Obtain Eq. (5.11). 
5.4 
Assume that that A and B are harmonic fields with angular frequency ω 
and complex amplitudes A and C, respectively [see (5.2)]. Prove the equality, 
2π J0 
1. 
A(x, t) ■ C(x, t) at = -Re(A(x) · C(x)). 
5.5 
In Section 5.3.2, the equation that allows for the calculation of the water 
quality of a pit lake according to the stirred tank model was derived. Extend 
this calculation to the period that ranges from the beginning of flooding to 
the moment in which it is full. 
5.6 
The calculation of the water quality of a system that is considered to be 
in equilibrium was done in Section 5.3.3.2 for a unique equilibrium reaction. 
Extend this calculation to the full set of equilibrium reactions. 
REFERENCES 
1. Bermudez, A., Continuum Thermomechanics, Birkhäuser, (2005). 
2. Bermudez, A., Bullon, J., Pena, F. and Salgado, P., A numerical method for 
transient simulation of metallurgical compound electrodes, Finite Elements in 
Analysis and Design, 39, 283-299 (2003). 
3. Bermudez, A. and Garcia-Garcia, L. M., Mathematical modeling in chemistry. 
Application to water quality problems, Applied Numerical Mathematics (DOI: 
10.1016/j.apnum.2011.05.002) (2011). 
4. Bermudez, A. and C. Moreno, C, Duality methods for solving variational in-
equalities, Computers and Mathematics with Applications, 7, 43-58 (1981). 
5. Castro, J. M. and Moore, J. N., Pit lakes: their characteristics and the potential 
for their remediation. Environmental Geology, 39, n. 11, 1254-1260 (2000). 
6. Chapman, A. J., Fundamentals of Heat Transfer, Collier McMillan, London 
(1987). 
7. Garcia Garcia, Luz M., Numerical resolution of water quality models: applica-
tion to the closure of open pit mines, Ph.D. thesis, University of Santiago de 
Compostela, Spain (2010). 

122 
CHAPTER 5. INDUSTRIAL MATHEMATICS WITH APPLICATIONS 
8. Davis, A., Lyons, W. B. and Miller, G. C , Understanding the water quality of 
pit lakes, Environmental Science and Technology, 30, n. 3, 118A-123A (1996). 
9. Johnk, C. T. A., Engineering Electromagnetic 
Fields and Waves, Springer, 
Berlin (2001). 
10. Lery, T., Primicerio, M., Esteban, M.J., Fontes, M., Maday, Y., Mehrmann, V., 
Quadros, G., Schilders, W., Schuppert, A., Tewkesbury, H. (Eds.) 
European 
Success Stories in Industrial Mathematics, Springer, Heidelberg (2011). 
11. McAdams, W. H., Heat transmission, McGraw-Hill, New York (1954). 
12. Morel, F. M. M. and Hering, J. G., Principles and applications of Aquatic Chem-
istry, John Wiley and Sons, New York (1993). 
13. Schei, A., Tuset, J.K., and Tveit, H., Production of High Silicon Alloys. Tapir 
Forlag, Trondheim (1998). 
14. Smith, W. R. and Missen, R. W., Chemical Reaction Equilibrium 
Analysis: 
Theory and Algorithms, Wiley, New York (1982). 

CHAPTER 6 
BINARY AND ORDINAL DATA ANALYSIS 
IN ECONOMICS: MODELING AND 
ESTIMATION 
IVAN JELIAZKOV AND MOHAMMAD ARSHAD RAHMAN 
Department of Economics, University of California, Irvine 
6.1 
INTRODUCTION 
This chapter is concerned with the analysis of statistical models for binary 
and ordinal outcomes. Binary data arise when a particular response variable 
of interest j/j can take only two values, i.e., yi € {0,1}, where the index i = 
1,..., n refers to units in the sample such as individuals, families, firms, and 
so on. Such dichotomous outcomes are widespread in the social and natural 
sciences. For example, to understand socio-economic processes, economists 
often need to analyze individuals' binary decisions such as whether to make a 
particular purchase, participate in the labor force, obtain a college degree, see 
a doctor, migrate to a different country, or vote in an election. By convention, 
xji = 1 typically indicates the occurrence of the event of interest, whereas the 
occurrence of its complement is denoted by yi — 0. 
Mathematical Modeling with Multidisciplinary Applications.
 
123 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley L· Sons, Inc. 

124 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
We also examine modeling and estimation issues related to another type 
of data, called ordinal data, where yi can take one of J ordered values, j = 
1,..., J. The defining feature of ordinal data is that even though the outcomes 
are monotone, the scale on which they are measured is not assumed to be 
cardinal and differences between categories are not directly comparable. For 
instance, in quantifying survey responses on consumer satisfaction, 1 could 
be assigned to "very unhappy," 2 to "not too happy," 3 to "happy," and 4 to 
"very happy," but even though the scale tells us that 4 implies more happiness 
than 2, this does not mean that 4 implies twice as much happiness as 2, or 
that the difference in happiness between 1 and 3 is the same as that between 
2 and 4. Even though ordinal data models were developed primarily for the 
analysis of data on rankings, they offer a flexible modeling framework that 
can also be very useful in the analysis of certain types of count data. 
In this chapter we pursue several goals. We briefly review relevant results 
from the theory of choice which formalize the link between economic theory 
and empirical practice in binary and ordinal data analysis. We then turn our 
attention to the topic of estimation and highlight the identification issues that 
arise in binary and ordinal models. We review both classical and Bayesian 
approaches to estimation, and introduce a new simulation-based estimation 
algorithm for logit models based on data augmentation. Even though the 
theoretical foundations for this algorithm have been available for decades, the 
approach has remained unexploited until now. Our estimation approach re-
moves important obstacles that have hindered extensions of logistic regression 
to multivariate and hierarchical model settings. 
Another topic that we examine here is covariate effect estimation, which al-
lows us to evaluate the impact of particular covariates on the outcome of inter-
est and gives concrete practical meaning to the parameters of the model. The 
techniques are illustrated in two applications in economics including women's 
labor force participation and educational attainment. The methods discussed 
here form a foundation for studying other more complex recent developments 
in the literature such as extensions to panel data, multivariate and multino-
mial outcomes, dynamics, mixed models, and copula models. 
6.2 
THEORETICAL FOUNDATIONS 
There exist a number of statistical models for binary and ordinal data, but 
they share a common foundation in which the observed discrete outcomes 
can be represented by the crossing of particular thresholds by an underlying 
continuous latent variable. This latent variable threshold-crossing formulation 
can in turn be related to the theory of choice in economics to form an elegant 
link between behavioral and statistical models. Because of this link, models 
for discrete data in econometrics are also frequently referred to as discrete 
choice models. The derivations are important because the latent variable 
representation turns out to be particularly useful not only in theory, but 

6.2 THEORETICAL FOUNDATIONS 
125 
also in estimation. It also helps clarify the relationship between empirical 
models based on different distributional assumptions and provides a basis 
for the calculation of important quantities in economics, such as consumer 
surplus or willingness to pay. Note, however, that the econometric techniques 
are fully general and can be used to represent various phenomena that do 
not necessarily entail references to utility or choice (e.g., weather patterns, 
accident probabilities, volcanic eruptions, etc.). 
In order for the decision problem to be well-posed, the set of available 
alternatives, or choice set, must be defined so that alternatives are (i) mu-
tually exclusive, i.e., they represent distinct non-overlapping outcomes, and 
(ii) exhaustive, so that all possible outcomes are fully accounted for. These 
criteria are easily satisfied in the context of binary and ordinal data where 
the dependent variable yi is simply an indicator variable for the occurrence of 
a particular event. One should keep in mind, that while in some contexts the 
dichotomy can be a natural feature of the data (e.g., medical tests, welfare 
program participation, home ownership, criminal recidivism, etc.), in other 
cases it can be introduced subjectively by the researcher to study a particular 
socio-economic phenomenon. For example, in studying market participation, 
a researcher may set y, = 1 for producers whose sales in a given market are 
positive and yi = 0 for all others. At first glance this discretization may seem 
unreasonable as it leads to loss of information on magnitudes (since both small 
and large sellers are treated alike). However, economic theory suggests that 
the presence of fixed costs leads firms to treat market entry and exit differ-
ently than the problem of how much to produce conditionally on being in 
the market. For this reason, the delineation of firms into market participants 
(regardless of sales volume) and non-participants (those with zero sales) can 
be an important first step in studying market outcomes. In the case of ordi-
nal data, the outcomes will easily satisfy the first criterion if the dependent 
variable j/j G { 1 , . . . , J} is defined as the sum of indicator variables over a par-
ticular monotone set of events. The second criterion, on the other hand, can 
either be satisfied naturally if outcomes are measured on a finite scale (as in 
surveys, or bond and stock ratings) or may have to be imposed by specifying 
a composite category that captures all possible outcomes beyond a certain 
value (as is common in the analysis of count data). Therefore, the nature 
of the choice set in binary and ordinal data models is in sharp contrast with 
standard models for continuous dependent variables, such as consumption or 
growth. 
6.2.1 
Binary Outcomes 
The roots of the random utility framework that underlies discrete choice mod-
els in econometrics can be traced back to the pioneering work of Refs. [15], [16], 
and [17]. A detailed recent review with applications to problems in modern 
econometrics is given in Ref. [25]. The basic setup involves utility maximizing 
decision makers, who choose among competing alternatives associated with 

126 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
certain levels of utility. The theory is quite general and can handle a variety of 
possible choices; the same ideas apply in our binary data context where there 
are only two possible alternatives. Specifically, individual i has two levels of 
utility, Un and UM, that are associated with t/j = 1 or ?/, = 0, respectively. 
The utility maximizing agent then selects the option providing the higher of 
the two utilities: 
f 1, if^ii >Ui0, 
y% 
\ 0, 
otherwise. 
The utilities Un and Uio are known to the decision maker but are unknown 
to the researcher, who can only observe a vector Xi of characteristics of the 
decision maker that can be related to utility through Uij = x\ßj + ε^ for 
j — 0,1. The term x\ßj is sometimes referred to as representative utility, 
whereas ε^ captures unobserved factors that affect utility but are not included 
in x'ißj. In essence, x\ßj is a systematic component and ε^ is a stochastic 
(from the point of view of the researcher) part of individual utility. 
This theoretical setup will be used to make probabilistic statements about 
the observed choices yi conditionally on Xi. In the remainder of this chapter, 
conditioning of one variable on another will be denoted by a vertical bar ' |', 
for example, Ρτ(Α\Β) will represent the conditional probability of A given B. 
Similarly, if s is a continuous random variable f(s\t) will be used to denote 
the conditional density of s given t. In some contexts, when it is important 
to make clear the link between a random variable and its density, we may use 
notation such as s\t to emphasize that we are interested in a random variable 
with density f(s\t), i.e., s\t ~ f{s\t), as opposed to a random variable s with 
density f(s), i.e., s ~ f(s). 
To develop a model for the observed choices, note that given Xi and the 
parameters ßo and ß\, the conditional probability of observing t/i = 1 can be 
expressed as an exceedance probability between the two utility levels 
Prfo = l\Xi,ßo,ßi) 
= PT(UU > Ui0) 
= Pr(x'ißi + εα > x% + εΜ) 
(6.1) 
= 
Pt[(eiO-eil)<x'i(ß1-ß0)]. 
The model is operationalized by specifying a density for the random variable 
(ε,ο —ffii), but before we consider specific cases, we need to address the impor-
tant topic of parameter identification. From Eq. (6.1) we see that the choice 
probability depends only on the differences in utilities between alternatives, 
not on the absolute level of utilities. Specifically, because the probability in 
(6.1) depends on the difference (βι — ßo), it will not change if we add an 
arbitrary constant c to both ß0 and βι, i.e., x'i{ß\ — ßo) = x'i(ßi — ßo), where 
ßi = ßi + c and ,9ο = /?o + c. Second, the scale of utility is not identified be-
cause the probability is unchanged if both sides of (6.1) are multiplied by an 
arbitrary constant c > 0, i.e., Pr[(ejo — e»i) < x'iißi — ßo)} = Pr[c(ejo - en) < 
cx'iiß! - ßo)}. 

6.2 THEORETICAL FOUNDATIONS 
127 
To deal with these problems, we need to fix both the location and scale 
of utility. The location is fixed by measuring utility relative to that of the 
baseline category, C/,o- In other words, we work with the differenced form 
zi=x'iß 
+ vi, 
i-l,...,n, 
(6.2) 
where Zi = Un — UM, ß = ß\ — ßo, and u% = ε%\ — ε,ο· As a result, the 
relationship between the observed outcome yi and the latent z\ is given by 
J 1, if z» >0, 
. 
. 
Vi ~ \ 0, otherwise, 
^Λ) 
which can alternatively be written as yi = l{zi > 0} using the indicator 
function 1{·} that takes the value 1 if its argument is true and 0 otherwise. 
The scale of utility is normalized by fixing the variance of Vi and treating 
it as given rather than as a parameter to be estimated; doing so is only a 
normalization that does not restrict the underlying flexibility of the model. 
(One should keep in mind that the value at which the variance of Vi is fixed 
will be model specific.) In the following examples, we review the three most 
common model specifications used in empirical analysis — probit, logit, and 
t-link or robit. 
■ EXAMPLE 6.1 
The probit model is obtained by assuming that the errors in (6.2) follow 
a standard normal distribution Vi ~ N(0,1) with probability density 
function (pdf) and cumulative distribution function (cdf) given by 
<t>{Vi) = (27r)- 1 / 2e-^ / 2 
and 
Φ(ι/<) = f ' 4>{t)dt. 
J — oo 
Note that the pdf φ(-) is symmetric and the variance of i/j is fixed at 
1 as a normalization. In addition, even though the expression for the 
Gaussian cdf Φ(·) does not have a closed form solution, it is readily 
available in most statistical software packages. 
■ EXAMPLE 6.2 
The logit model is obtained by assuming that the errors in (6.2) follow a 
logistic distribution whose cdf FL(·) and pdf / L ( · ) are explicitly available 
(see Exercise 6.1 for a derivation of / L ( · ) from 
FL(·)): 
FL(i/i) = ( H - e - ' " ) " 1 
and 
fL(Vi) 
= FL(Vi)[l - 
FL(^)\. 

128 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
The logistic distribution is symmetric with mean 0, variance π 2/3, and 
heavier tails than the normal distribution. The tail mass makes it more 
likely to observe "nonconforming" behavior such as choosing j/i = 0 for 
large positive χ'φ or y» = 1 for large negative x\ß. In Exercise 6.2, we 
derive another well known result (see Refs. [16] and [18]) that the logit 
choice probabilities are obtained if the errors ε^ and en in (6.1) follow 
an extreme value type I distribution. 
■ EXAMPLE 6.3 
The f-link or "robit" model is obtained by assuming that the errors in 
(6.2) follow a standard Student's f distribution with τ degrees of freedom. 
The distribution is symmetric around 0, has variance τ/(τ —2) for r > 2, 
and its pdf /τ χ (·) and cdf FTT (·) are given by 
frT M = r ( \ * r - 
1 + -*- ) 
and 
FTr {Vi) = / 
fTr (s)ds, 
l(2)V r 7 r V 
T J 
JO 
where T(s) = J0°° ts~1e~tdt 
denotes the gamma function (which equals 
(s — 1)! for positive integer values of s). Note that the variance of the f 
distribution is larger than in the probit case but approaches 1 for τ->οο. 
Also, the cdf FTT(·) 
does not have a closed form solution, but is readily 
available in most statistical software packages. 
An appealing feature of the f-link model is its flexibility: low values 
of r produce heavier tails than the logistic distribution, setting r fa 8 
approximates the logit model, and as r —► oo, the t distribution approx-
imates the standard normal. Figure 6.1 shows the log-densities for the 
standard normal, scaled logistic and scaled t with 4 degrees of freedom 
(the scaling is done so that all three variances are 1). Because the i-link 
offers a modeling approach that is robust to variations in the tail be-
havior of the latent Zj, it has also been referred to by the portmanteau 
word "robit" ("robust" + the suffix "-it" to resemble probit and logit). 
Given the three specifications we have just considered, we can now obtain 
the outcome probabilities Pr(j/j = l|/3) and Pr(j/j = 0|/3) = 1 — Pr(j/i = 
1\β) (we suppress the dependence of these probabilities on x^ for notational 
convenience). In particular, from (6.2) and (6.3) and under the assumption 

6.2 THEORETICAL FOUNDATIONS 
129 
Figure 6.1 
Log-densities for the standard normal, scaled logistic and Student's t 
with 4 degrees of freedom. 
that the density of i/j is symmetric, we have that 
Pr(j/, = l| i9)=Pr(z i>0) 
= Prföß + Vi > 0) 
= 1 - Pr(i/i < 
-χ'φ) 
= 1 - [1 - Pr(i/i < x'M 
= Pr(i/i < *;/?) = F(^/3), 
where F(-) is the assumed cdf of z/, - as before, F(·) = Φ(·) produces the 
probit model, F(-) = FL(·) leads to logit, and F(-) = FTT(·) 
gives the i-link 
model. Symmetry is used in obtaining the second to last line, and while all 
models considered here involve symmetric distributions, readers are cautioned 
to be careful in general. 
6.2.2 
Ordinal Outcomes 
We now turn attention to models for ordinal data, where the alternatives are 
inherently ordered or ranked. Common applications that involve ordered out-
comes include sentiment or opinion surveys, quality tests, health assessment 
studies, the level of employment (unemployed, part-time, full-time), the level 
and usage of insurance, and others. 

130 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
η 
γ2 
χ.β 
γ3 
Figure 6.2 
Outcome probabilities in an ordinal data model. 
Similarly to the models studied in Section 6.2.1, ordinal data models can 
be motivated by an underlying latent variable threshold-crossing framework. 
In particular, as in (6.2) we assume that a continuous latent random variable 
Zi depends on a k-vector of covariates Xi through the relationship Zi — χ\β + 
Vi, i = l,...,n, but with the difference that the observed outcomes yi € 
{ 1 , . . . , J} arise according to 
yi=j 
if 
7 j - i < 
Zi<lj, 
(6.4) 
where —oo = 7o < 7i < ··· < 7J-1 < 7 J = oo are cutpoint parameters 
that determine the discretization of the data into J ordered categories. An 
alternative way of writing (6.4) is to let yi = Σή=ι ^{zi > 7j-i}· Given this 
representation and a particular cdf F(i/i), the probability of observing yi = j , 
conditional on β and 7 = (71,..., 7 J - I ) , is given by 
Pr (yi = m 
l) = F (7i - χ[β) - F (7j_i - x'iß) 
(6.5) 
Figure 6.2 depicts the probabilities of yi falling in category j as determined 
by (6.5) in a four-category setting. As before, various choices of the cdf F (·) 
are possible—e.g., F{·) = Φ(·), F(-) = FL(·), F(-) = FTr(·), and so on—but 
the ordinal probit model is one of the most practical because it is tractable 
in univariate cases and can be easily generalized to flexible multivariate and 
hierarchical settings. In contrast, the logistic distribution can not handle 
correlations in multivariate settings. 
As with models for binary data, we require both location and scale re-
strictions in order to identify the parameters. To see the need for doing so, 
note that the probabilities in (6.5) are invariant to shifting and rescaling the 
parameters by some arbitrary constants c and d > 0 because 
F{lj-x'iß)=F{lj+c-(x'iß 
+ c)) 

6.2 THEORETICAL FOUNDATIONS 
131 
f(z) 
Yi 
Ύ2 Χ , β 
χ,β 
f(z) 
Ύι=° 
\ 
x|ßY2 
Ύ3 x|P* 
Figure 6.3 
Parameter identification in ordinal data models. 
and 
F( 7 j--a:{/9)=F 
jj-id 
— χ'φά 
which can be applied to both terms in (6.5) without affecting Pr (y* = 
j\ß,7). 
The first identification problem is easily corrected by fixing a cutpoint - in 
particular, letting 71 = 0 removes the possibility for shifting the distribution 
without changing the probability of observing ί/j. As in binary data models, 
we resolve the possibility for rescaling (our second identification problem) by 
fixing the variance of Vi. The variance equals 1 in the probit case, π 2/3 in the 
logit case, and τ/(τ — 2) in the ί-link model. 
Figure 6.3 illustrates these identification considerations. The first panel 
in the figure illustrates that shifting the density and all cutpoints leaves the 
probability unaffected; the second panel shows that even if one sets 71 = 0, 
in the absence of a scale restriction, one can simultaneously rescale F (■), the 
mean, and the remaining cutpoints without affecting Pr($/j = 
j\ß,7). 
In addition to fixing one cutpoint and the variance of i/j, there are other 
possible ways to achieve parameter identification. For example, as an alter-
native to letting 71 = 0, it is possible to identify the parameters by dropping 
the intercept term from χ'φ. Moreover, instead of fixing the variance of i/j, 
one can impose a scale restriction by fixing two cutpoints (e.g., 71 = 0 and 
7 J _ I = 1). The presence and effectiveness of these alternative approaches has 
been examined in Ref. [13] and the references therein, however, these alter-

132 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
natives will not be examined here because they are primarily of interest in 
multivariate models. 
6.3 
ESTIMATION 
This section reviews both classical and Bayesian methods for estimating the 
models considered in Section 6.2. Classical estimation in this class of models 
typically employs the method of maximum likelihood, which requires numer-
ical optimization of the log-likelihood function. Bayesian estimates, on the 
other hand, are generally obtained by Markov chain Monte Carlo (MCMC) 
simulation methods such as Gibbs sampling or the Metropolis-Hastings algo-
rithm. 
In addition to reviewing existing estimation methods, this chapter also in-
troduces a new estimation algorithm for logit models that has been overlooked 
in the literature. The method not only supplements our toolkit for dealing 
with logistic regression, but also lays a foundation for estimating important 
extensions of the logit model to multivariate and hierarchical settings. 
6.3.1 
Maximum Likelihood Estimation 
Consider a set of observations y = (j/i,... ,2/n)' that comes from some sta-
tistical model with sampling density f(y\6) written in terms of a parameter 
vector Θ. Because f(y\0) provides a mathematical description of the proba-
bilistic phenomenon that generates the observed data sample y given Θ, it is 
called the data generating process. Note that the data generating process is 
a function of the data conditionally on the parameters, and indeed we can 
think of it as the mathematical model by which, given Θ, nature generates 
y. In practice, empirical researchers see the sample y generated from 
f(y\ö), 
but do not know the value of Θ. When f(y\9) is viewed as a function of the 
parameter vector Θ given the sample y, it is called the likelihood function. 
Although the two functions refer to the same object, f(y\9), they emphasize 
(and take as arguments) its two different components. A thorough review 
of likelihood inference can be found in standard statistics and econometrics 
references such as [11]. 
The maximum likelihood estimator (or MLE) is defined as the value of Θ 
that maximizes the log-likelihood function 
QMLE = argmaxln/(y|0), 
(6.6) 
Θ 
or heuristically, it is the value of Θ that makes the observed sample y as "likely" 
as possible within the confines of the assumed data generating process. Note 
that because the logarithmic transformation is monotone, the value 
9MLE 
that maximizes ln/(y|0) also maximizes f(y\9), 
however, it is common to 
work with In f(y\6) because it is more stable and easier to evaluate than 

6.3 ESTIMATION 
133 
f(y\9), and also because the most important statistical properties of OMLE 
are associated with features of ln/(j/|0). Specifically, it is known that under 
mild regularity conditions, the maximum likelihood estimator QMLE defined 
in (6.6) is consistent and asymptotically normally distributed. Consistency 
means that as the sample size n —> oo, the probability limit (or plim) of QMLE 
is the true value θο, i.e., plim#MLE = #0- Asymptotic normality means that 
in large samples, as n —► oo, 
OMLE ~ N 
(θο,ν-1), 
where V is the Fisher information defined as the negative of the expected 
value of the second derivative (or Hessian) matrix of the log-likelihood 
V 
=-E d2ln/(j/|0) 
οθδθ' 
evaluated at #o and the expectation is taken with respect to /(t/|öo). Be-
cause it is typically impossible to evaluate this expectation, it is common to 
approximate V by the observed Hessian 
a 2 i n / ( # ) 
ΘΘΘΘ' 
' 
which is evaluated at the maximum likelihood value Θ = OMLE ■ The standard 
errors of the individual elements of 9MLE are given by the square root of the 
diagonal entries of V - 1, and those can be used in testing and constructing 
confidence intervals. Next, we consider the likelihood functions for the models 
studied in Section 6.2. 
For the binary data models that we considered in Section 6.2.1, the likeli-
hood function can be written as 
f(y\ß)=PT(yi,y2,...,yn\ß) 
n 
= Y[pT(yi\ß) 
- { Π pun \\ Π i1 - nm\l 
(6'7) 
i:yi = l 
I 
l i : j i i = 0 
niiwr [i-*w)] 
( l - l / i ) 
i=\ 
where the second line follows by assuming independence among the obser-
vations and the last line is simply a convenient expression for picking the 
relevant probability. This likelihood function captures all three binary data 
models discussed in Section 6.2.1 — probit, logit, and ί-link — which could 

134 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
be obtained by using the appropriate cdf in place of F(-) as discussed in 
Section 6.2.1. 
In order to find the maximum likelihood estimate $MLE: we maximize the 
log-likelihood function 
n 
In f(y\ß) = Σ 
{ViFtäß) 
+ (1 - yi)[l - F{x'M) 
, 
which is typically done iteratively using standard hill climbing algorithms such 
as Newton-Raphson or BHHH (see Ref. [3]) because the first-order condition 
for maximization 
dß 
~ £-> 
\ l 
Vi)~ 
F{x[ß) 
" 
»l'l-F{x>fi)\ 
0 
does not admit an explicit analytical solution even though the log-likelihood 
is typically well behaved (unimodal and concave) in this class of models. 
Turning attention to ordinal outcomes, Eq. (6.5) and the assumption of 
independent sampling give the following likelihood function for the ordinal 
data model 
/ ( 2 / | / ? , 7 ) = 
Π
Ρ
Γ ^ Ι ^ ) 
*;' 
(6-8) 
= 
l[[F(lj-x'iß)-F(7j.1-x'iß)}, 
»=ι 
where the index j on the cutpoints in the second line is determined by the 
realization of ?/, (recall that because y\ takes values in { 1 , . . . , J}, it can be 
used for indexing the cutpoints, i.e. jj = ηυί and 7j_i = 7yi_i). 
A minor complication arises in maximizing In/ (y\ß,7) because the values 
of the free cutpoints must satisfy an ordering constraint: 71 = 0 < 72 < 
... < 7,7-1. In order to avoid the computational complexities associated with 
constrained optimization, it is useful to reparameterize the problem in order 
to remove those constraints. For example, optimization can be simplified by 
transforming the cutpoints 7 so as to remove the ordering constraint by the 
one-to-one map 
Sj = ln(7j - 7 j_i), 2 < j < J - 1, 
(6.9) 
and rewriting the likelihood as a function of ß and δ — ((52,..., Sj-i)', 
i.e. 
drawing inferences from f(y\ß, δ). Other transformations have been consid-
ered in Ref. [4] and comparisons have been drawn in Ref. [13], but these 
transformations relate to alternative identification restrictions of the scale of 
the model and will not be examined here. 

6.3 ESTIMATION 
135 
6.3.2 
Bayesian Estimation 
In contrast to classical (or frequentist) inference, which only involves the like-
lihood function f{y\9), Bayesian analysis rests on Bayes' theorem 
f ί(ν\θ)π(θ)άθ' 
and inference is based on the posterior density n(6\y), which is proportional 
to the product of the likelihood and the prior density π{θ). There are im-
portant theoretical advantages of Bayesian analysis over classical inference, 
which have been carefully reviewed in [10], [14], [21], and [23]. For example, 
the posterior density allows for finite sample inferences about the unknown 
parameter vector Θ that incorporates information from the observed sample 
(which enters through the likelihood) and non-sample information (e.g., from 
previous studies, theoretical considerations, the researcher's experience, etc.), 
which enters through the prior. In addition to their finite sample properties, 
Bayesian estimators also have desirable asymptotic properties (as n —> oo). 
An important practical benefit of Bayesian estimation is that inference is 
possible even in models where the likelihood f(y\0) is difficult to evaluate and 
hence maximum likelihood estimation is infeasible. In those cases, progress 
has been made possible by recent advances in simulation-based estimation 
and data augmentation which allow sampling from n(9\y) without requiring 
evaluation of f(y\0). Such simulation methods, based on MCMC theory, have 
enabled inference in previously intractable applications. Once a sample of 
draws {Θ} from n(6\y) is available, those draws can be used to summarize fea-
tures of the posterior (such as mean, variance, quantiles, etc.) and construct 
point and interval estimates. 
For the binary and ordinal data models we have examined in this chapter, 
Bayes' theorem will lead to a posterior density 
π(β|») ex ί(ν\θ)π(θ) 
that typically does not belong to a known family of distributions and cannot 
be sampled directly. This is because even if the prior π(θ) is selected from 
a well-known class of distributions (e.g., Gaussian), the parameters enter the 
likelihood f{y\6) in such a way [note the nonlinearity in Eqs. (6.7) and (6.8)] 
that the posterior n(6\y) does not have a recognizable analytical representa-
tion. 
In this section we present tools for dealing with this problem in two ways. 
First, we discuss a general MCMC simulation technique, called the Metropolis-
Hastings algorithm, that can be employed to produce draws from intractable 
distributions. Second, we review a method that circumvents the problem by 
augmenting the sampling scheme with an additional vector of variables in a 
way that restores tractability. The benefit of this approach, called data aug-
mentation, is that it enables estimation by Gibbs sampling (another MCMC 

136 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
simulation technique). In the remainder of this Section, we review all of these 
methods and propose a new data augmentation algorithm for the logit model 
which has not appeared elsewhere in the literature. 
6.3.2.1 Metropolis-Hastings Algorithm. 
The Metropolis-Hastings (MH) al-
gorithm [19], [12], [24], [5] is a versatile Markov chain simulation method for 
non-standard distributions. Denoting the current value of Θ by θ°, it proceeds 
by generating a proposed value θρ ~ q(6\y) from the proposal density q(-). In 
principle q(-) can depend on 9C (e.g., in random walk proposal densities), but 
in this chapter we examine a version of the MH algorithm, called indepen-
dence chain MH, in which the proposal density does not vary with θ°. The 
proposed draw θρ is accepted with probability 
and if θρ is rejected, 6C is repeated as the next value of Θ in the Markov chain. 
As shown by [12] (also see [24], [5]), the limiting distribution of the draws of Θ 
coming from the MH algorithm is n(6\y). In practice, this means that after a 
transient phase (called the burn-in period), draws obtained by MH simulation 
can be viewed as coming from n(6\y). 
To apply the independence chain MH algorithm in our context, we note 
that a suitable proposal density can be obtained by employing the MLE results 
from Section 6.3.1. In particular, for any of the models studied in Sections 
6.2.1 and 6.2.2, the proposal density can be constructed as a multivariate t 
density 
9(%)=/τ„(0|ΜΦ), 
with mean Θ = OMLE and scale matrix οΦ, where Φ is given by the inverse of 
the negative Hessian of the log-likelihood 
Φ 
d2\nf(y\e) 
οθθθ' 
evaluated at Θ = 6MLE, a is a scalar tuning parameter, and ω is the degrees of 
freedom of the proposal density. The tuning parameter a is typically taken to 
be a > 1 and ω is usually set at a small value, both of which are intended to 
ensure that the proposal has sufficiently heavy tails to explore the space more 
thoroughly. In the examples in this chapter, we use ω — 10 and a = 1.25. 
The independence chain MH algorithm can then be employed to estimate 
probit, logit and robit models for binary data using the likelihood in (6.7) 
with parameter vector Θ = β, or ordinal models using likelihood (6.8) written 
in terms of the transformed cutpoints in (6.9) whereby the parameter vector 
Θ is given by Θ = (/?', δ')'. 
6.3.2.2 Gibbs Sampling and Data Augmentation. 
Gibbs sampling (see Ref. 
[9]) is an MCMC method for simulation from a distribution when its full 

6.3 ESTIMATION 
137 
conditional densities have known form. To review the approach, suppose there 
are three parameter blocks 6\, 62, and Ö3 with joint density π(θι,62,63^). 
The 
Gibbs sampler produces draws {6\,62,63} 
~ π(θι,62,63^) 
by sequentially 
drawing from the set of full conditional densities n(6\\y, 62,63), 1^(62^,61,63) 
and 7r(Ö3|j/, 61,62)- Under mild conditions, it can be shown that the Markov 
chain formed by the Gibbs sampler has a limiting invariant distribution that is 
the distribution of interest π(θι, 62, 6z\y). This means that draws obtained by 
Gibbs sampling after the initial burn-in period, can be viewed as coming from 
^(61,62,6s\y). 
Some authors have likened the way in which the Gibbs sampler 
traverses the parameter space to the way a rook moves in chess. In addition, 
the particular order in which the full conditional densities are sampled does 
not affect the limiting distribution. A thorough review of the method and its 
applications in econometrics is offered in [6]. 
The application of Gibbs sampling to models for binary and ordinal data 
is complicated by the fact that the posterior and its full conditional densities 
are not of known form. However, a method known as data augmentation can 
be used to overcome this problem. 
The idea behind data augmentation is simple. Instead of focusing on the 
intractable posterior density 
π ( % ) oc f(y\6)n(6), 
we choose to work with π(θ, w\y), a density judiciously augmented with w 
in such a way that the full-conditionals ir(6\y,w) and n(w\y, 6) are tractable 
and can be sampled directly. As a result, a Gibbs sampler constructed using 
sequential sampling from ir(6\y, w) and n(w\y, 6) will produce draws {6, w} ~ 
n(6,w\y). 
But how do we relate the draws {6, w} from π(θ, w\y) to our original goal 
of sampling 6 ~ ir(6\y)? This is easily done by only collecting the draws of 
Θ and simply ignoring w. The approach works because by the properties of 
cdfs, given two vectors of constants a$ and aw conformable with 6 and w, 
respectively, the marginal cdf is obtained from the joint cdf as 
F(ao) = Pr(0 < αθ) = lim F(ae, aw) = Ρτ(θ <C αθ, w < 00), 
aw —>oo 
where "<C" is used to denote element-by-element weak inequality comparison. 
The condition w C o o always holds and in this sense we "simply ignore" w 
to obtain draws 6 ~ n(6\y) from {6, w} ~ 
n(6,w\y). 
Having presented the theory behind data augmentation, we now discuss its 
specific application to the models considered in this chapter. 
■ EXAMPLE 6.4 
The binary probit model can be estimated easily, as shown in [1], if 
we were to introduce the latent z = (z\,..., 
zn)' from Eq. (6.2) into 

138 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
our MCMC simulation algorithm. Specifically, instead of working with 
n(ß\y), we specify a Gibbs sampler to simulate the augmented posterior 
π(/3, z\y), which can be written as 
ir(ß,z\y)<xf(y\ß,z)f(ß,z) 
= 
f(y\ß,z)f(z\ß)n(ß) 
f n 
>| 
(6-10) 
= 
Ulf(Vi\zi)\f(*\ß)*(ß)-
Note that the last line of (6.10) involves terms that are easy to evaluate. 
In particular, / (j/j|zi) = l{zi € Bi}, where 
ft = {i 0 , O°ni ΐ * = n 
^6·11) 
\ (-oo,0J 
if yi = 0 , 
which follows from the relationship between yi and z% in binary data 
models. Note that conditionally on Zi, yi does not depend on ß. In 
addition, f(z\ß) = fx{z\Xß, 
In), where X — (x[,..., x'n)' is the matrix 
of covariates and In denotes the n x n identity matrix; this follows 
from the latent variable representation of the probit model, namely z^ = 
x'iß + Ui with Vi ~ N(0,1) for i = 1,... ,n. Finally, π (β) is the prior 
distribution on β which we assume to be fN{ß\ßo, Bo), i.e., ß is assumed 
to be a priori normally distributed, i.e., β ~ Ν(βο,Βο)-
A Gibbs sampler now can be easily constructed to explore π (β, z\y) 
because the full conditional densities n(ß\y,z) 
and n(z\y,ß) 
are of 
known form. Specifically, π (ß\y, z) is proportional to the terms in (6.10) 
that involve ß so that π (ß\y, z) oc / (ζ\β) π (β), which technically does 
not depend on y. Because both / (ζ\β) and π (β) are normal, the full 
conditional is also normal and therefore we draw 
ß\y,z~N(ß,B), 
where B = (B^1 + X'X)'1 
and β = Β{Β^ιβ0 
+ X'z). 
Details of the 
derivation are considered in Exercise 6.3. 
The density π (z\y,ß) is proportional to the terms in (6.10) that in-
volve z so that 
n(z\y,ß) 
oc 
ll[l{zteBi}\fN(z\Xß,In) 
n 
= 
H[i{zieBi}Mzi\x'iß,i)], 
i=l 

6.3 ESTIMATION 
139 
whereby z\y,ß is easily sampled by drawing Zi, i = 1,... ,n, from ap-
propriately truncated normal densities 
Zi\yi,ß 
~TNBitfißA), 
where the region of truncation Bi is defined in (6.11). 
■ EXAMPLE 6.5 
The ί-link (robit) model can be estimated by extending the data aug-
mentation approach presented in Example 6.4. The discussion follows 
[1] and rests on the result (see, e.g., [2]) that the t distribution can be 
represented as a scale mixture of normals. Specifically, if for i = 1,..., n, 
Xi has a gamma distribution 
Xi~G{T/2,T/2), 
(6.12) 
and conditionally on λ^, we have 
Zi\Xi ~ Nfäß, 
I/A*), 
(6.13) 
then marginally of λί, ζ% is distributed 
Zi~TT{J$,\). 
Therefore, letting λ = (λχ,... ,λ„)', we can consider the augmented 
posterior 
n(ß,z,X\y)Kf(y\ß,z,X)f(ß,z,X) 
= 
f(y\ß,z,\)f(z\ß,X)ir(ßM\) 
t n 
Λ 
(6-14) 
= 
<Ylf{Vi\zi)\f(z\ß,*U(ßM*), 
where / (yi\zi) = 1{ζ» G Bi} as before, / {ζ\β, X) = fN(z\Xß, 
A - 1) with 
A = diag(A) which follows from (6.13), π(β) = JN{ß\ßo, BQ) is the prior 
on ß, and π(λ) is given by the product of n independent gamma densities 
stemming from (6.12) 
n 
π ( λ ) = Π / σ ( λ < | τ / 2 , τ / 2 ) . 

140 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
It is then quite straightforward to show that the Gibbs sampler for 
simulating from π(/3, ζ, \\y) can be constructed by sequentially drawing 
from the following full conditionals 
β\ζ,λ~Ν(β,Β), 
with B = (Bö1 + X'Az)-1 
and ß = BiB^ßo 
+ 
X'Az), 
«ill/,ß, Xi ~ TNBi(x'A 
λΓ1), 
ί = 1,... ,n, 
and 
\ i 
« 
^ , / r + l T+(Zi-x'^)2\ 
. 
EXAMPLE 6.6 
The logit model can be estimated by pursuing a new data augmentation 
scheme that has not been exploited in the literature. Because the logistic 
distribution can be written as a scale mixture of normals with respect 
to the Kolmogorov distribution [2,22], we can write that 
/L(s|/i) = J /Ν(8\μ,4κ2)/Κ(κ)<1κ, 
(6.15) 
where /£,(β|μ) denotes the density of a random variable that has a logis-
tic distribution around μ and variance π 2/3, and //f(/t) represents the 
Kolmogorov density /κ(κ) = SK^^i-l)^1 
j2e~2j 
K . This implies, 
analogously to Example 6.5, that if Ki has a Kolmogorov distribution 
and conditionally on m, Zi\ni ~ N(x'iß,^K1), 
then marginally of Ki, Zi 
has logistic density 
f^z^x'ß). 
Therefore, letting κ = (κχ,... ,κη)', 
we can consider the augmented 
posterior 
π(β, z, K\y) oc / (y\ß, z, κ) f (/?, z, κ) 
= 
ί(υ\β,ζ,κ)/(ζ\β,κ)π(β)π(κ) 
f n 
Ί 
(6-16) 
= lUf 
(yi\zi)\ f 
(ζ\β,κ)π(β)π(κ). 
where f (yi\zi) = l{Zi 
e S*}, ί(ζ\β,κ) 
= fN{z\Xß,K) 
with K = 
diag(4/i2), π(/3) = fN(ß\ßo,B0), 
and π(κ) = ΠΓ=ι /*(«*)■ 

6.3 ESTIMATION 
141 
The resulting Gibbs sampler for simulating from π(β, ζ, n\y) is con-
structed by sequentially drawing from the following full conditionals 
β\ζ,κ~Ν0,Β), 
with B = {Bö1 + X'K^z)-1 
and ß = B{Bälßo + 
X'K~lz), 
Zi\y, β, Ki ~ TNBi {χ'φ, 4/s?), 
i = 
l,...,n, 
and 
Ki\y,ß,Zi ~f(Ki\zi,ß), 
i = l,...,n, 
(6-17) 
where f(ni\zi,ß) 
does not belong to a known family of distributions. 
However, a very convenient result can be obtained by representing this 
distribution in terms of Bayes' formula as 
f(* I» 
ff\ 
f(zi\ß,Ki)f(*i) 
j(Ki\Zi,P) 
= J 
f(zi\ß,Ki)f(Ki)dKi 
fN(ZiMß,4K?)fK(Ki) 
(6·!8) 
fUziKß) 
The last line in (6.18) follows by recognizing that the numerator densities 
are Gaussian and Kolmogorov, and the denominator, by Eq. (6.15), is 
simply the logistic density. Therefore, the unknown /(KJ|ZJ,/3) can now 
be represented very simply in terms of other well-known densities. 
The fact that f(iii\zi,ß) 
can be evaluated explicitly means that one 
can also evaluate the corresponding cdf 
FK\zAKi\Zi>ß)= 
f{s\Zi,ß)ds. 
Jo 
In turn, FK\Ziß(Ki\zi,ß) 
can be utilized to produce the draws needed 
in (6.17) by solving «j = F~} „{u), where u ~ U(0,1) is a uniform 
random variable on the unit interval. The latter technique is known as 
the inverse cdf method and follows because 
Pr(Ki < a) = PT(F-10(U) 
< a) = Pr(u < FK^ß{a)) 
= 
FK\Ziß(a). 
This completes the proposed Gibbs sampling scheme for logit models. 
However, to provide additional intuition about the behavior of f(ni\zi, ß) 
and compare it to the Kolmogorov distribution /κ-(κ,), Figure 6.4 plots 
f(ni\zi, β) for two settings of z, — χ\β. The figure reveals that when Zi is 
close to the mean χ\β the mass of the distribution is closer to the origin 
than when Zi is far (in absolute terms) from χ\β. This is to be expected 
because K; enters the conditional variance of ζ·. 

142 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
Figure 6.4 
Behavior of the density /(κί|ζ;,/3) relative to /κ(κ;)· 
EXAMPLE 6.7 
The analysis of the ordinal probit model is similar to the cases considered 
in the preceding examples. In particular, given the priors β ~ Ν (βο, Bo) 
and δ ~ N (do, Do), the augmented posterior distribution is given by 
π (β, δ, z\y) <x / (y\ß, δ, ζ) 
β(ζ\β)π(β)π(δ) 
= 
\ΐ[ί(ν\δ,ζΛί(ζ\β)π(β)π(δ), 
(6.19) 
.i=l 
where f(y%\S,Zi) = l{7j-i < Zi < 7^}, the correspondence between 
7 and δ is determined by (6.9), and the cutpoint index j is given by 
the realization of ί/j. Furthermore, f(z\ß) 
= fti(z\Xß,In), 
π(β) = 
fN(ß\ßo,B0), 
and π(δ) = 
fN(ö\d0,D0). 
It has been noted in the literature that in order to design an efficient 
MCMC sampler for the ordinal probit model, δ and z must be simulated 
jointly, not conditionally on each other. The reason that conditional 
sampling does not mix well is that z and δ (which determines the values 
of 7) constrain each other through the restrictions {7J/[i]_i < Zi < 7^(1]}, 
whereby the sampler can only slowly explore the posterior distribution. 
Several alternatives for joint sampling are reviewed in [13], and the fol-
lowing simulation scheme is suggested. 
1. Sample δ, z\y,ß in one block as follows: 

6.3 ESTIMATION 
143 
(a) Sample 6\y, ß marginally of z by drawing δρ ~ q(S\y,ß) from a 
proposal density q(S\y,ß) = /τω(δ\δ,Σ>), where 
Λ 
y ft \ftx\ 
A 
h 
^hifiy^Sy-1 
o = arg max In/(y |/3, o) 
and 
D = -
s 
δδθδ' 
Accept δρ with probability 
f(y\ß,öp)*(öp)q(öc\y,ß) 
<5=Ä 
οΐΜΗ(δ,δρ) =min {'·' f(v\ß,S°MS°)q(SP\y,ß)J' 
otherwise repeat the current value δ°. 
(b) Sample Zi\y,β, δ ~ ΤΝ^_ιηί) 
{χ'φ, 1) for i = 1,..., ra, where 7 is 
obtained by the one-to-one mapping relating 7 and δ. 
2. Sample β\ζ ~ Λ^(/3, Β) with 
ß = (S 0 + Χ'Χ)'1 
and 
4 = B^B^ßo 
+ X'z). 
In Step 1 of this algorithm, the degrees of freedom parameter ω is taken 
to be a low number such as 5 or 10 to ensure that the proposal density 
has sufficiently heavy tails. Grouping δ and z into a single sampling 
block dramatically improves the mixing of the Markov chain. 
We complete the discussion of data augmentation by emphasizing its practical 
appeal. For instance, data augmentation is often the only viable estimation 
approach in a variety of multivariate and hierarchical models. 
Maximum 
likelihood estimation becomes infeasible in those settings owing to the in-
tractability of the likelihood function. However, data augmentation allows us 
to circumvent this difficulty by simulating from well-known distributions with-
out having to evaluate the likelihood. This has enabled inference in difficult 
settings such as multivariate and multinomial probit, mixed logit, multivari-
ate ordinal probit, copula models, panel data models, models with incidental 
truncation, treatment models, and many others. 
6.3.3 
Marginal Effects 
Having estimated the parameters of a model, one is typically interested in 
the practical implications of those estimates. However, interpretation of the 
parameter estimates is complicated by the nonlinearity of the models we 
have considered. In binary data models, for example, E(yi\xi,ß) 
= Pr(yj = 
l\xi,ß) 
= Ffäß). 
Therefore, the marginal effect of changing some continuous 
covariate in a;,, say Xh, is not simply given by ßh- This can be easily seen by 

144 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
taking the derivative of Pr(t/i = l\xi,ß) 
with respect to Xh 
dVT{3n = l\xi,ß) 
dFfäß) 
dxh 
dxh 
f{x'iß)ßh, 
and hence the marginal effect of Xh depends on ßh, but also on all of the 
covariates in Xi, all of the parameters in ß, and will differ with the choice of 
cdf F(-) and respective pdf /(·). Table 6.1 gives the choice probability and 
marginal effects for the three commonly used binary data models. 
Table 6.1 
Marginal effects in binary data models. 
Model 
Probability P(j/< = l\x,,ß)) 
Marginal Effect of Xh 
Logit 
FL{x'^) = -
^ 
h(x'iß)ßk 
1+e ΐ^ 
Probit 
Φ{χ'φ) = /f *f φ(ζ)άζ 
ct>(x'iß)ßh 
t-link 
FTT (x'iß) = /:if fTr (t)dt 
fTr {χ'φ)βκ 
Given a specific model, there are several approaches to compute the average 
marginal effect of covariate Xh- One approach is to evaluate the marginal 
effect using the sample average of the regressors x^ and the point estimate 
β, i.e. /(xfflßh- 
However, this average effect may not represent the effect 
in the population well because /(·) is a nonlinear function and by Jensen's 
inequality ί{χ'φ) φ f(x'iß). 
Therefore, a more reasonable approach would be 
to calculate the sample average of the marginal effects 
f{x'iß)ßh=n-lYjf{x'iß)ßh. 
Even though this quantity is better than computing f{öt!iß)ßh as suggested in 
Ref. [26], it has an important drawback: it does not account for the variability 
in ß. For this reason, Refs. [8] and [13] suggest that the average covariate effect 
should be computed by averaging over both the covariates and parameters. 
If estimation is done by MCMC simulation, one can use draws β^ 
- 
n(ß\y) 
to construct the average covariate effect as follows 
M 
m) 
^Μ^ΣΣ/Μ^ 
i=\ 
m=l 
Note that unlike the earlier quantities we considered, f{x'iß)ßh produces an 
estimate of the average effect that accounts for variability in both Xi and ß. 

6.4 APPLICATIONS 
145 
6.4 
APPLICATIONS 
6.4.1 
Women's Labor Force Participation 
We apply the techniques of this chapter to study the determinants of women's 
labor force participation, a topic that has been extensively studied because of 
the large increases in women's participation and hours of work in the post-
war period. For instance, there has been a sevenfold increase in the partic-
ipation rate of married women since the 1920's. Understanding labor force 
participation and entry and exit decisions is a fundamental prerequisite for 
understanding wages because wages are not observed for women who do not 
work. 
The data set used in this application has been studied in [20] and [7]. The 
sample consists of 753 married women, 428 of whom were employed. The 
variables in the data set are summarized in Table 6.2. 
Table 6.2 
Covariates in the women's labor supply example. 
Covariate 
KLT6 
KGE6 
NWINC 
MEDU 
FEDU 
HEDU 
AGE 
EXPER 
Explanation 
Number of kids under 6 years old 
Number of kids 6-18 years old 
Estimated nonwife income (1975, : 
Mother's years of schooling 
Father's years of schooling 
Husband's years of schooling 
Woman's age in years 
Actual labor market experience in 
in $10,000) 
years 
Mean 
0.28 
1.35 
2.01 
9.25 
8.81 
12.49 
42.54 
10.63 
SD 
0.52 
1.32 
1.16 
3.37 
3.57 
3.02 
8.07 
8.07 
We implemented the techniques developed in this chapter to estimate pro-
bit, logit, and ί-link models of the binary participation decision. Estimation 
was carried out by the MCMC simulation methods discussed in Section 6.3.2 
and our results are summarized in Table 6.3. 
The estimates in Table 6.3 are consistent with the predictions of economic 
theory. For example, having young children reduces labor force participation 
as evidenced by the negative mean and a 95% credibility interval that lies 
below zero, but older children have little impact on the mother's decision to 
work. Again, consistent with economic theory, higher nonwife income and 
lower parents' and husband's schooling reduce participation. The table also 
shows that age has a strong negative effect, which is consistent with cohort and 
life-cycle effects, whereas experience has a strong positive effect on probability 
of working, which is consistent with increases in productivity as experience 
grows. 

146 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
Table 6.3 
Parameter estimates in the women's labor force participation 
application. 
Covariate 
1 
KLT6 
KGE6 
NWINC 
MEDU 
FEDU 
HEDU 
AGE 
EXPER 
Mean 
1.1758 
-0.7964 
0.0346 
-0.0773 
0.0320 
0.0143 
0.0251 
-0.0517 
0.0745 
SD 
0.4358 
0.1115 
0.0415 
0.0484 
0.0184 
0.0175 
0.0188 
0.0078 
0.0074 
Mean 
1.1737 
-0.8285 
0.0362 
-0.0817 
0.0339 
0.0158 
0.0265 
-0.0534 
0.0796 
SD 
0.4586 
0.1210 
0.0443 
0.0531 
0.0197 
0.0189 
0.0207 
0.0083 
0.0084 
Mean 
1.3931 
-1.2476 
0.0763 
-0.1384 
0.0580 
0.0250 
0.0476 
-0.0769 
0.1270 
SD 
0.6188 
0.1847 
0.0695 
0.0825 
0.0306 
0.0300 
0.0326 
0.0117 
0.0138 
6.4.2 
An Ordinal Model of Educational Attainment 
We now consider the ordinal probit model of educational attainment studied 
in [13]. Educational attainment has been the subject of a large literature be-
cause of its implications for earnings, economic growth, and social well-being. 
The setting is suitable for ordinal modeling because the dependent variable 
is naturally categorized by measurable thresholds into a number of distinct 
groups. This application considers the following four ordered outcomes: (1) 
less than a high school education, (2) high school degree, (3) some college or 
associate's degree, and (4) college or graduate degree. The data are obtained 
from the National Longitudinal Survey of Youth (NLSY79). 
In this study it is of interest to examine the effect of family background 
and individual variables on educational attainment. The family background 
variables included in the data set are: the highest grade completed by the 
individual's father and mother, whether the mother worked, square root of 
family income, an indicator for whether the youth lived in an urban area, 
and an indicator for whether the youth lived in the South. The individual 
variables include gender and race, as well as three indicator variables that 
control for age cohort affects. The sample is restricted to those cohorts that 
were between 14 and 17 years old in 1979. The sample is restricted to include 
only individuals whose records have all relevant variables. Additionally, the 
sample excludes disabled individuals and those who report more than 11 years 
of education at age 15. The resulting sample consists of 3923 individuals. 
The model was estimated by the MCMC simulation techniques discussed in 
Section 6.3.2. The results are presented in Table 6.4. The coefficient estimates 
in the table are consistent with other findings in the literature. Parental edu-
cation and income have a positive effect on educational attainment, as might 
be expected. A priori, the effect of mother's labor force participation is the-
oretically ambiguous — on the one hand, a mother's work force participation 

6.5 CONCLUSIONS 
147 
could be detrimental due to reduced parental supervision, but on the other, it 
provides a positive example for her children to follow. The empirical findings 
in Table 6.4 indicate that the net effect is positive, although it is not precisely 
estimated. Conditionally on the remaining covariates, we also see that blacks 
and individuals from the South have higher educational attainment. 
Covariate 
Intercept 
Family income (sq. rt.) 
Mother's education 
Father's education 
Mother worked 
Female 
Black 
Urban 
South 
Age cohort 2 
Age cohort 3 
Age cohort 4 
(transformed cutpoint) 
(transformed cutpoint) 
Mean 
-1.34 
0.14 
0.05 
0.07 
0.03 
0.16 
0.15 
-0.05 
0.05 
-0.03 
0.00 
0.23 
0.08 
-0.28 
SD 
0.09 
0.01 
0.01 
0.01 
0.04 
0.04 
0.04 
0.04 
0.04 
0.05 
0.06 
0.06 
0.02 
0.03 
Table 6.4 
Parameters estimates in the educational attainment application. 
Following [13], we computed the effect of an increase in family income 
on educational outcomes following the discussion in Section 6.3.3. For the 
overall sample, the effect of a $1000 increase in family income is to lower 
the probability of dropping out of high school by approximately 0.0050, lower 
the probability of only obtaining a high school degree by 0.0006, but increase 
the probability of having some college or associate's degree by 0.0020 and 
increase the probability of getting a college or graduate degree by 0.0036. 
We also computed these effects for specific subsamples that are of interest. 
For the subsample of females, the effects of an income increase on the four 
outcome probabilities were comparable at approximately —0.0048, —0.0009, 
0.0019, and 0.0038, respectively. For the subsample of blacks, the effects of 
income change were somewhat stronger - in that subsample, an increase of 
$1000 in family income changed the four educational outcome probabilities 
by -0.0060, -0.0009, 0.0026, and 0.0043, respectively. 
6.5 
CONCLUSIONS 
This chapter has introduced the theory behind binary and ordinal models 
in economics, and has examined their estimation by both maximum likeli-
hood and Bayesian simulation methods. We have reviewed several existing 

148 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
MCMC algorithms and have proposed a new data augmentation method for 
the estimation of logit models. The ability to implement data augmentation 
techniques makes it possible to extend these techniques and estimate models 
in which the likelihood function is intractable. 
The methods are examined in two applications dealing with labor force 
participation and educational attainment. The applications illustrate that 
the models and estimation methods are practical and can uncover interesting 
features in the data. 
EXERCISES 
6.1 
The cdf of the logistic distribution is given by 
W = C + 
' T ' ~ -
Show that the logistic pdf, / L ( ^ ) , can be written as 
fL(v)=FL{v)[l-F(V)]. 
6.2 
Suppose the random utility model is given by 
Uij=x'ißj+eij, 
i = l,...,n, 
.7=0,1. 
Starting with Eq. (6.1), show that if ε« and ε»ι are independent and identically 
distributed as extreme value type I with density 
fEv(e) 
= 
e-'e-e" 
and cumulative distribution function 
FEV(S) 
= e~e~', 
then (6.1) gives rise to the logistic outcome probability 
Prfo = l\ß) = . * , « , 
1 + e x*p 
where β = β\ — ßo-
6.3 
Consider the probit model and assume the prior β ~ Ν(βο,Βο). 
Show 
that given the latent data z, the full conditional distribution for β is 
ß\y,z~N(ß,B), 
where B = (ß0
_1 + X'X)'1 
and ß = BiB^ßo 
+ X'z). 

EXERCISES 
149 
REFERENCES 
1. Albert, J. and Chib, S., "Bayesian Analysis of Binary and Polychotomous Re-
sponse Data," Journal of American Statistical Association, Vol. 88, No. 422, 
pp. 669-679, (1993). 
2. Andrews, D. F. and Mallows, C. L., "Scale Mixtures of Normal Distributions," 
Journal of the Royal Statistical Society, Series B, Vol. 36, No. 1, pp. 99-102, 
(1974). 
3. Berndt, E., Hall, B., Hall, R., and Hausman J., "Estimation and Inference in 
Nonlinear Structural Models," Annals of Economic and Social 
Measurement, 
Vol. 3, pp. 653-665 (1974). 
4. Chen, M.-H. and Dey, D. K., "Bayesian Analysis for Correlated Ordinal Data 
Models," in D. Dey, S. Ghosh, and B. Mallick (eds.), Generalized Linear Models: 
A Bayesian Perspective, pp. 133-157. New York: Marcel-Dekker. 
5. Chib, S. and Greenberg, E., "Understanding the Metropolis-Hastings Algo-
rithm," The American Statistician, Vol. 49, No. 4, pp. 327-335 (1995). 
6. Chib, S. and Greenberg, E., "Markov Chain Monte Carlo Simulation Methods 
in Econometrics," Econometric Theory, Vol. 12, No. 3, pp. 409-431 (1996). 
7. Chib, S., Greenberg, E., and Jeliazkov, I., "Estimation of Semiparametric Mod-
els in the Presence of Endogeneity and Sample Selection," Journal of Compu-
tational and Graphical Statistics, Vol. 18, pp. 321-348 (2009). 
8. Chib, S. and Jeliazkov, I., "Inference in Semiparametric Dynamic Models for 
Binary Longitudinal Data," Journal of the American Statistical 
Association, 
Vol. 101, pp. 685-700 (2006). 
9. Gelfand, A. E. and Smith, A. F. M., "Sampling Based Approaches to Calculating 
Marginal Densities," Journal of the American Statistical Association, 85, 398-
409 (1990). 
10. Greenberg, E., Introduction to Bayesian Econometrics, Cambridge University 
Press, Cambridge (2007). 
11. Greene, W. H., Econometric Analysis, 7th edition, Prentice Hall, New Jersey 
(2011). 
12. Hastings, W. K., "Monte Carlo Sampling Methods using Markov Chains and 
Their Applications," Biometrika, Vol. 57, pp. 97-109 (1970). 
13. Jeliazkov, I., Graves, J., and Kutzbach, M., "Fitting and Comparison of Mod-
els for Multivariate Ordinal Outcomes," Advances in Econometrics: 
Bayesian 
Econometrics, Vol. 23, pp. 115-156 (2008). 
14. Koop, G. and Poirier, D.J. and Tobias, J.L., Bayesian Econometric 
Methods, 
Cambridge University Press, Cambridge (2007). 
15. Luce, R. D., Individual Choice Behavior. John Wiley & Sons, New York (1959). 
16. Luce, D. and Suppes, P., "Preferences, Utility and Subjective Probability," 
Handbook of Mathematical Psychology, R. D. Luce, R. Bush, and E. Galanter 
(eds.), John Wiley & Sons, New York (1965). 

150 
CHAPTER 6. BINARY & ORDINAL DATA ANALYSIS 
17. Marschak, J., "Binary-Choice Constraints and Random Utility Indicators," 
Mathematical Methods in the Social Sciences, K. J. Arrow, S. Karlin, and P. 
Suppes (eds.), Stanford University Press, pp. 312-329 (1960). 
18. McFadden, D., "Conditional Logit Analysis of Qualitative Choice Behavior," 
Frontiers in Econometrics, P. Zarembka (ed.), pp. 105-142, Academic Press, 
New York (1974). 
19. Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, 
E., "Equations of State Calculations by Fast Computing Machines," Journal of 
Chemical Physics, Vol. 21, pp. 1087-1092 (1953). 
20. Mroz, T. A., "The Sensitivity of an Empirical Model of Married Women's Hours 
of Work to Economic and Statistical Assumptions," Econometrica, Vol. 55, pp. 
765-799 (1987). 
21. O'Hagan, A., Kendalls Advanced Theory of Statistics: Bayesian Inference. John 
Wiley & Sons, New York (1994). 
22. Poirier, D. J., "A Curious Relationship between Probit and Logit Models," 
Southern Economic Journal, Vol. 40, pp. 640-641 (1978). 
23. Poirier, D. J., Intermediate Statistics and Econometrics: 
A Comparative Ap-
proach, Cambridge, MA: MIT Press (1995). 
24. Tierney, L., "Markov Chains for Exploring Posterior Distributions," (with dis-
cussion), Annals of Statistics, Vol. 22, pp. 1701-1762 (1994). 
25. Train, K., Discrete Choice Methods with Simulation, 
Cambridge University 
Press, Cambridge (2009). 
26. Verlinda, J. A., "A comparison of two common approaches for estimating marginal 
effects in binary choice models," Applied Economics Letters, Vol. 13, pp. 77-80 
(2006). 

CHAPTER 7 
INVERSE PROBLEMS IN ODEs 
H. KUNZE 1 AND D. LA TORRE 2 
Department of Mathematics and Statistics, University of Guelph, Canada 
Department of Economics, Business and Statistics, University of Milan, Italy 
Early undergraduate courses in differential equations typically focus on 
solution methods, mathematical modeling, and interpretation of solutions and 
models. Seeking the solution of a given differential equation or system is often 
called the "direct problem." On the other hand, the "inverse problem" asks 
us to find an appropriate model (differential equation or system), the solution 
of which agrees well with some experimental or real-world observations. 
For example, we might believe that a particular predator-prey system of 
differential equations models the interactions between the rabbits and foxes 
in a given region, and we can gather some population data over some period 
of time. From this data, the inverse problem might ask us to estimate the 
parameters (the coefficients) in the model. Many questions may come to mind. 
Some are: 
Mathematical 
Modeling with Multidisciplinary 
Applications. 
151 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

152 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
1. Since the differential equations are nonlinear, we cannot solve them 
explicitly, and we can only solve them numerically if we pick values for 
the coefficients. So, how do we solve the inverse problem? 
2. If we only gather population data every week, say, and there are surely 
measurement errors, our method for solving the inverse problem needs 
to be pretty robust. Is it possible to construct such a method? 
3. The method should be mathematically sound. Can we build the theory 
as well as a practically useful method? 
In this chapter, we will formulate one approach to solving this sort of inverse 
problem. The mathematical theory will be based on Banach's fixed point 
theorem, and, in particular, a simple corollary named the collage theorem 
(because of its original usefulness in fractal imaging). We will see many prac-
tical examples and develop an appreciation for the robustness of the general 
method. This approach to solving inverse problems in differential equations 
first saw light in 2000: as we learn how some older mathematical theory can be 
used to build new theory and tools, we reinforce how mathematics is vibrant 
and always growing. 
7.1 
BANACH'S FIXED POINT THEOREM & THE COLLAGE 
THEOREM 
Banach's Fixed Point Theorem, also called the Contraction Mapping Princi-
ple, is a central component of most first courses in real analysis. (For greater 
details on the ideas presented in this section, see Ref. [4], a standard text used 
in such a course.) The two key ingredients of the theorem are a "complete 
metric space" and a "contraction map" that send the space into itself. 
The first ingredient can be quite challenging. A space consists of the same 
type of elements: the space of real numbers contains real numbers, a vector 
space contains vectors, an image space contains images, and a function space 
contains functions, for example. Loosely, a metric space is a space along with 
a way to measure distance between elements in the space. For example, the 
distance between real numbers might be taken to be the absolute value of their 
difference; and we might use the Euclidean metric to measure distance between 
(finite) vectors, square rooting the sum of the squares of the differences of the 
components of the vectors. There are many ways to measure the distance 
between functions in a function a space. We will see some choices in the other 
sections of this chapter. A metric must satisfy these properties: 
1. d(x, y) > 0 for all x, y £ X, and d(x, y) = 0 if and only if x = y; 
2. d(x, y) = d(y, x) for all x, y € X; 
3. d(x, z) < d(x, y) + d(y, z) for all x,y,z 
€ X. 

7.1 BANACH'S FIXED POINT THEOREM & THE COLLAGE THEOREM 
153 
The final property is the familiar triangle inequality. All of the properties 
make sense when you thing of d as a distance between familiar objects. 
In general, we denote a space by the letter X, a metric by the letter d, and 
the corresponding metric space by the ordered pair (X, d). 
A complete metric space has a special property that only rears its head 
in this section, where we present proofs of the fundamental results we use in 
subsequent sections. We capture this property in the following definition. 
Definition 1 Let (X,d) be a metric space. The sequence {xn}'^L1 is Cauchy 
if for every ε > 0 there is an M such that 
d(xm, xn) < ε whenever n> M and m> 
M. 
The metric space (X,d) is called complete when every Cauchy sequence con-
verges to some element x € X. That is, 
d(xn, x) —► 0 as n —» oo. 
The second ingredient also has its complications, but an easy interpretation 
brings comfort. 
Definition 2 A map T : X —► X is a contraction map (with respect to the 
metric d) if there exists a c E [0,1) such that 
d(Tx, Ty) < cd(x, y) for all x, y € X. 
The smallest value of c for which this inequality holds is called the contraction 
factor of the contraction map T. 
In order to understand Definition 2, first observe that x and y get sent to 
Tx and Ty, respectively, by the map T. As a result, the inequality in the 
definition says that T moves points in X closer together: since c € [0,1), the 
distance between Tx and Ty is smaller than the distance between the original 
points, x and y. In order for T to be contractive on (X, d), the preceding 
statement must be true for every choice of x and y. See Figure 7.1. 
■ EXAMPLE 7.1 
Let X = [0,1], the unit interval of real numbers, and d(x,y) = \x — y\ 
for x, y S X. We consider some choices for T : X —> X. 
1. If Tx = \x, then we see that for x,y e X 
x 
y 
2 
2 
1, 
, 
1 
d(Tx,Ty)= 
- - * 
=^\x-y\ 
= 
-d{x,y) 
21 
"' 
2 
The map T is contractive on (X, d) with contraction factor | . 

154 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
Figure 7.1 
A contractive map T moves points closer together. 
2. If Tx = \x+ | , note that T does send X to itself and for x, y € X 
d(Tx,Ty) 
y 
x 
2 
3 + 3 
3 
3 = 3^-2/1 = ^d(x,y). 
The map T is contractive on (X, d) with contraction factor | . 
3. If Tx = ax + ß, then provided 0 < ß < 1 and 0 < a + ß < 1, we see 
T :X -Λ X. We calculate that 
d(Tx,Ty) 
= \ax + ß- 
(ay + ß)\ = \a\\x-y\ 
= 
\a\d(x,y). 
The map T is contractive provided that |a| < 1. 
Banach's Fixed Point Theorem states the remarkable fact that when a con-
traction map acts on a complete metric space there is exactly one element of 
the space that does not move when the map acts upon it. This special point 
that does not move is rather appropriately called the fixed point of the map. 
We state and prove the theorem. 
Theorem 1 (Banach's Fixed Point Theorem) Let (X, d) be a complete metric 
space and T : X —> X be a contraction map with contraction factor cG [0,1). 
Then 
1. there is a unique x £ X such that Tx — x; 
2. for any xo € X, the sequence defined by xn+i = Txn converges (in the 
metric d) to x; that is, d(xn,x) 
—> 0 as n —> oo. 
Proof: To prove existence, pick an arbitrary XQ € X. Define the sequence 
xn+1 
= Txn, n = 0,1,2,3, 
We will prove that the sequence is Cauchy 
in (X, d). By the completeness of the space this will mean that the sequence 

7.1 BANACH'S FIXED POINT THEOREM & THE COLLAGE THEOREM 
155 
converges to a point x E X; that is, d(xn,x) 
—* 0 as n —» oo. We are then 
able to conclude that 
lim xn+i 
= 
lim Txn 
n—*oo 
n—»oo 
= 
T lim xn, 
n—>oo 
because contraction maps are continuous (see Exercise 7.1). Taking the limits, 
we arrive at x = Tx, and we see that x is a fixed point of T. 
To prove that the sequence is Cauchy, based on Definition 1, for n > m > 2, 
we consider 
UyEm-i^Cn) 
— 
&\1 Xm—1; ·* *^n — 1) 
< 
cd(xm-i,xn-i) 
= 
cd(Txm-2,Txn-2) 
< 
C2 
d{xm-2,Xn-2)-
We see the pattern. We can continue the process m times, until the first 
argument in d is XQ. We conclude that 
d(Xm,Xn) 
< Cmd(x0, (Xn-m) ΐθΤ Π > ΤΠ > 0. 
This result motivates us to consider 
d(x0,Xk) 
< d(x0,xi)+ 
d(xi,x2)+ 
d{x2,xs) ~\ 
\-d(xk-i,Xk) 
< 
d(x0,xi) 
+cd(x0,xi) 
+ c2 d(xo,xi) -\ 
l· 
ck~1d(xo,xi) 
< 
(l + c + c2 + 
---+ck-1)d{x0,xi) 
1 - cfc 
< 
d{x0,xi) 
1 — c 
< 
d(a;0,a;i), 
1 — c 
where we sum the geometric series in the second-last line. Putting things 
together, we conclude that 
cm 
drxm,xn) 
< 
c?(a;o,a;i) for n > m > 0. 
1 — c 
Since c e [0,1), when m (and hence n) become large enough, the bound on 
the right-hand side gets arbitrarily small. We conclude that the sequence is 
Cauchy in (X, d). As presented earlier, this means that the first conclusion of 
the theorem holds. 

156 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
Figure 7.2 
Banach's Theorem: Repeated iteration of T takes us to its fixed point. 
To prove uniqueness, assume the opposite. Suppose that there are two 
distinct points x,y £ X with Tx = x and Ty = y. Then 
d(x,y) = 
d(Tx,Ty)<cd(x,y). 
Since x φ y, we know that d(x, y) φ 0, using a property of metrics. So we 
can divide by this quantity to obtain 1 < c, a contraction. We conclude that 
the fixed point is unique. 
■ 
The second conclusion of Banach's fixed point theorem is illustrated in Fig-
ure 7.2. Note that a map can have a fixed point without being contractivity, 
but that none of the theory in this chapter will apply. 
■ EXAMPLE 7.2 
Let X = [0,1], the unit interval of real numbers, and d(x,y) = \x — y\ 
for x,y £ X. Each of the maps in Example 7.1 is contractive. We can 
find the unique fixed point by solving x = Tx. 
1. When Tx = ^x, we find that x = Tx = \x has solution x = 0. This 
makes sense, as we see that Tnx = ^x 
—» 0 as n —» oo regardless of the 
choice of x. 
2. Solving Tx = |:r + | = x, we get | x — | , with solution x = 1. 
3. Solving Tx = ax + β = x, we find that β = (1 — a)x with solution 
x = γζ^- 
Recall from Example 7.1 that |a| < 1 and, combining the 
other inequalities, 0 < β < 1 — a. Together these inequalities tell us 
that x £ [0,1]. 
Banach's Fixed Point Theorem has a simple corollary called the Collage The-
orem. The name of this result comes from its usefulness in fractal imaging, a 
topic removed from the current discussion. 

7.2 EXISTENCE-UNIQUENESS OF SOLUTIONS TO INITIAL VALUE PROBLEMS 
157 
Figure 7.3 
Collage Theorem: The true error can be controlled by the collage 
distance. 
Theorem 2 (Collage theorem) 
Let (X,d) be a complete metric space and 
T : X —> X be contractive with contractivity factor c € [0,1). Denote by x 
the unique fixed point of T, as guaranteed by Banach 's Fixed Point Theorem. 
Then, for any x e X, 
d(x,x) < 
d(x,Tx). 
1 — c 
Proof: Using the triangle inequality, we have 
d(x,x) 
< 
d(x,Tx)+d(Tx,x) 
= 
d(x, Tx) + d(Tx, Tx) 
< 
d(x, Tx) + c d(x, x) 
^(l-c)d(x,x) 
< 
d(x,Tx). 
Dividing by 1 — c, which is nonzero, gives the desired result. 
■ 
If we think of d(x, x) as the error in approximating x by the fixed point x, 
we see that the inequality in the Collage Theorem says that this approxima-
tion error can be controlled by minimizing the collage distance d(x,Tx). 
We 
illustrate the theorem in Figure 7.3. 
7.2 
EXISTENCE-UNIQUENESS OF SOLUTIONS TO INITIAL VALUE 
PROBLEMS 
We use Banach's fixed point theorem to prove that under suitable conditions 
the ODE initial value problem (IVP) 
x'{t) 
= 
f(x,t), 
(7.1) 
x(to) 
= 
xQ, 
(7.2) 

158 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
has a unique solution in some neighborhood of t = to- Proofs of this result can 
be found in [1] and [3], two often-used texts for introductory and advanced 
differential equations courses, respectively, but the proofs in most references 
do not use Banach's fixed point theorem. The nice (and accessible) book on 
metric spaces by Copson [2] presents a proof similar to the one we present 
here. 
Notice that the solution to (7.1) and (7.2) may well not exist for all real t 
values. In general, we do not have global existence of a solution, but we can 
prove that we do have local existence. With this in mind, we define 
I 
= 
[io — a, to + a] for some a > 0, 
X = C(I) 
= 
{space of continuous functions x(t) on / . } , 
and doo(a;,2/) 
= 
\\x - y||oo = max|x(i) - y(t)\. 
Note that the max in the definition of doo exists because \x(t) — y(t)\ is a con-
tinuous function. By the Extreme Value Theorem from calculus, a continuous 
function on a closed interval achieves an absolute maximum and an absolute 
minimum. 
Now, we merely state that the space (X,d) = (C(I),doo) is a complete 
metric space. This statement says that doo is in fact a metric on C(I). This 
claim is not hard to prove, since it mostly takes advantage of properties of 
absolute value. But the statement also says that the metric space is complete. 
This is a harder claim to prove, requiring an argument involving Cauchy 
sequences of functions in C(I). The proof is a standard part of a real analysis 
course. It involves first proving that the sequence converges pointwise and 
then proving that the convergence is actually uniform, so that the limit of the 
sequence inherits the continuity of the sequence terms. 
We want to introduce a contraction map on (C(/),d0o). Integrating the 
ODE with respect to t from t = 0 to t = t, we get 
/ x'(s)ds 
= 
f 
f(x(s),s) 
Jt0 
Jto 
x(t)-x(0) 
= 
[ 
f(x(s),s) 
Jtn 
ds 
to 
=> 
x(t) 
= 
xo+ 
f(x(s),s)ds. 
(7.3) 
Jt0 
Here, we use the Fundamental Theorem of Calculus to get to line two, and 
then we rearrange and use the initial condition (7.2) to get the final line. The 
resulting integral equation features the function x(t) on both sides. It sits 
on the left-hand side, but it also appears inside / on the right-hand side. In 
Exercise 7.3, you are asked to prove that x(t) is a solution to the IVP if and 
only if it satisfies the integral equation. Based upon the integral equation 

7.2 EXISTENCE-UNIQUENESS OF SOLUTIONS TO INITIAL VALUE PROBLEMS 
159 
(7.3), we define the Picard operator 
(Tx)(t) =x0+ 
[ f{x(s), s) ds. 
(7.4) 
Jt0 
Using the result of Exercise 7.3, we see that x(t) is a fixed point of T if and 
only if it is a solution to the IVP. It would be nice if T was a contraction map 
on (X, d), since that is the focus of our discussion. 
First, for convenience, we note that if ίο Φ 0 or XQ φ 0, we can let s = t — to 
and y(s) = x(s) — xo so that y(s) satisfies y(0) = 0 and the transformed ODE. 
Hence, without loss of generality, in the remainder of this section, we assume 
that our IVP takes the form 
x'(t) 
= 
f(x,t), 
(7.5) 
x(0) 
= 0, 
(7.6) 
Note that this means that I = [—a, a}. We define 
D 
= 
{(x,t)\\x\ <b, \t\ <a} 
c(i) = {*€σ(/)ΐΝΐοο<δ}. 
The metric space (C(I), doo) is complete. We also assume that / is continuous 
and satisfies max \f(x, t) I < b/a, and a Lipschitz condition on D: there exists 
(x,t)eD 
a constant K > 0 such that 
\f(xi,t) 
- f(x2,t)\ 
<K\x1-x2\ 
ίοτ all (Xi,t) e D, 
such that c = Ka < 1. If necessary, we can adjust the value of a > 0 to make 
it small enough so that Ka < 1. 
Now we prove two results. 
Theorem 3 With the preceding definitions, T : C(I) —► C(I). 
Proof: We must prove that Tx £ C(I) when x € C(I). Since / is continuous 
and x is continuous, the composition in the integral is continuous. That means 
that the integral produces a continuous function. We only need to show that 
IIT^Hoo < b. Since io = 0 and xo = 0, we find that 
Halloo = 
< 
< 
I f 
max / 
f(x(s),s)ds\ 
tei \Jo ' 
I /"* I 
max|/(x(s),s)| · max / ds\ 
sei 
tei \J0 
| 
max |/(a:, i)l · rnaxltl 
b 
, 
- · a = o, 
a 

160 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
proving the result. 
■ 
Theorem 4 With the preceding definitions, 
rfoo(Ta;,Ty) < cdx{x,y), 
for x,y e C(I), 
where c = Ka < 1. 
Proof: For x,y e <?(/), we calculate that 
ά^Τχ,Τν) 
= 
< 
< 
< 
< 
as required. 
■ 
The contractivity of T on (C(I), d<x>) implies the existence of a unique element 
x € C(I) such that Tx = x, using Banach's Fixed Point Theorem. 
By 
Exercise 7.3, this fixed point is therefor the unique solution to the IVP (7.5) 
and (7.6). 
7.3 
SOLVING INVERSE PROBLEMS FOR ODEs 
The inverse problem of interest to us is: Given a solution curve x(t) for t € 
[0,1], perhaps the interpolation of experimental data points, find an ODE 
x'(t) = f(x,t) 
that admits x(t) as an approximate solution, where / may be 
restricted to a particular family of functions based on understanding of the 
underlying model. 
Based on the discussion in Section 7.2, we can rephrase the inverse prob-
lem as: Given a solution curve x(t) for t € [0,1], perhaps the interpolation 
of experimental data points, find a Picard operator that admits x(t) as an 
approximate fixed point, where / may be restricted to a particular family of 
functions based on understanding of the underlying model. 
We call x(t) the target solution. The second formulation of the inverse 
problem makes it clear that we are seeking to approximation x(t) by a fixed 
max 
tei 
max 
*€ 
/ f(x{s),s)ds- 
/ 
f(y(s),s)ds 
Jo 
Jo 
I r* 
ix / (/(x(s), s) - f{y(s), s)) ds 
1 \Jo 
[ 
\f(x(s),s)-f(y(s),s)\ds 
Jo 
max 
I f* 
max / K \x(s) — y(s)\ ds 
t€l 
\Jo 
K max \x(s) — y(s) I ■ max 
Kd00(x(s), 
y(s)) ■ max |i| 
Kad00(x(s),y(s)), 
f 
Jo 
ds 

7.3 SOLVING INVERSE PROBLEMS FOR ODEs 
161 
point x(t) of some Picard operator T. By restricting the form of f(x, t), typi-
cally defining it in terms of some coefficients, we similarly restrict the possible 
Picard operators. In general, we cannot express the possible fixed points in 
terms of these coefficients, so direct minimization of the true approximation 
error doo(x, x) (with x defined by the coefficients) is not possible. Instead, we 
call on the Collage Theorem, minimizing the collage distance ά^χ,Τχ) 
in 
order to control the true approximation. But it is troublesome to work with 
the doo metric. We switch to a different metric for functions, called the C2 
metric, given by 
d2{x,y) -if, 
(x(t)-y(t))2 
There is a technical catch: (C(I),d2) is not complete. The functions in C2(I) 
are those that satisfy d2(x,0) < oo. It can be shown that 
C(I) C C(I) C C2{I). 
We know that the fixed point of T lies in C(I), so it will be in C2(I). We still 
have to prove that T is contractive with respect to d2. We state the result as 
a theorem. 
Theorem 5 With the preceding definitions, 
d2(Tx,Ty) 
< —d2(x,y), 
forx,y 
€ C{I), 
where c = Ka < 1. 
Proof: For x, y G C(I), we calculate that 
d2(Tx,Ty) 
= J\J 
f(x(s),s)ds- 
J 
f(y(s),s)ds 
= f\f 
(f«sls)~f(y(sls))ds 
- I I I 
l/W*)'
s)-/(»(*)'
s)l
ds 
dt 
*I,\L 
K\x{s)-y{s)\ds 
dt. 
(7.7) 
For convenience, consider t > 0 only; a similar argument applies for t < 0. 
The Cauchy-Schwarz inequality in this setting says that 
Jo 
g(s)h(s)ds 
< f \g(s))2 dsV 
\[\h(s)) 
Jo 
J 
Uo 
1 ds 

162 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
We apply the inequality with g(s) = 1 and h(s) = \x(s) — y(s)\. Then 
J 
1 · \x(s) - y(s)\ ds 
< 
i y 1 ds\' 
U 
\x(s) - y(s)\2 ds 
< 
t* \J 
\x(s) - y{s)\2 ds 
Plugging (7.8) into (7.7) gives 
d\{Tx,Ty) 
< 
K2^ 
ti\J 
\x(s) - 
y(s)\2ds 
= 
K2 [ 
[ t\x(s) - y(s)\2 dsdt 
Jo Jo 
/•a 
pa 
= 
K2 
t\x(s) - y(s)\2 dtds 
pa 
pa 
= 
K2 
tdt 
\x(s) - y(s)\2 ds 
Js 
Jo 
Y)£\x(8)-y(s)\2ds 
fa\x(s)-y(s)\2ds, 
Jo 
= 
K2 
K2a 
2„2 
ra 
(7.8) 
and square rooting gives the result. Upon combining with the argument for 
t < 0, the theorem is proved. 
■ 
EXAMPLE 7.3 
Let x{t) — AeBt + C be the target solution, where A, B, and C are real 
numbers, with B ^ O . This is the exact solution of the linear IVP 
x'(t) 
= 
-BC + Bx, 
x(0) 
= 
A + C. 
Given the target solution x(t), we seek an IVP of the form 
x'(t) 
= 
Co + CiX, 
x(0) 
= 
XQ, 

7.3 SOLVING INVERSE PROBLEMS FOR ODEs 
163 
where CQ, C\, and XQ are parameters. We construct the Picard operator 
(Tx)(t) 
= 
xo+ 
(co + cix(s)) ds 
Jo 
[\co 
Jo 
xo+ I (co + ciAe*s + ciC)ds 
= 
a;o + (co + c 1 C ) i + ^ ( e B t - l ) 
= 
x o - ^ - + (co + c i C ) i + ^ - e B t . 
The squared collage distance on [0,1] is 
d2
2(x,Tx) = f1 UeBt 
+ C - ( x 0 - ^ 
+ (co + ClC)t + ^ e B t \ \ 
dt. 
Notice that the integrand is a linear function of x$, Co, and c\. Squaring 
and integrating leads to the expression 
4(x,Tx) 
= 
- ^ Ux2B3 
+ 9c2 A2 + 3A2e2BB2 
+ 3c?A2e2B 
-\2AB2C 
- 3A2B2 + 6C2B3 + 
12AeBB2C 
-12χ0ΒαΑ 
- YIABCQ + 12coCiA + \2c\AC 
+\2AB2xQ - 6A2BCl - 6C2B3
Cl 
- 12CB3x0 - 
6CB3CQ 
+6x0B3c0 + Qc\A2B + 2c\C2B3 + 
\2CB2c1A 
-12x0B2aA 
+ 6x0B3ciC 
- 6aAc0B2 
- 
§c\ACB2 
+AcQB3c1C + 12x0Bc1AeB 
+ 
12cJACeBB 
+12coCiAeBB - \2CB2cxAeB 
+ 2c2
0B3 - 
\2c\A2eB 
-l2AeBB2x0 
+ 12A2eBBci 
- 12AB2coeB + 12ABcoeB 
-\2c\ACeB 
- 12cQClAeB - 
6A2e2BBCl 
We display the expression to stress that solving such problems is really 
not work for pencil and paper. Using calculus, we differentiate with 
respect to XQ, CO, and c\, setting the first partial derivatives equal to zero. 
We implement these steps using mathematical software on a computer. 
As we would hope, the result is that the squared collage distance is 
minimized when 
x0 = A + C, c0 = -BC, 
c\ = B. 

164 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
EXAMPLE 7.4 
Let x(t) = t2 be the target solution on J = [0,1]. We see that x'(t) = 
2£ = 2y/x for > 0, so the true DE satisfied by x(t) is not linear. However, 
looking for a linear IVP 
x'(t) 
= 
Co + CiX, 
x(0) 
= 
xo, 
we follow the same process: define the Picard operator and calculate 
the square collage distance d\{x,Tx). 
Minimizing this distance with 
computer software, we obtain the IVP 
5 
35 
At) 
= Ϊ2 + Ϊ8*. 
*(0) 
= 
" ^ 
with corresponding (minimized) collage distance άϊ(χ,Τχ) 
= 0.0124. 
The solution to this IVP is 
ω
67 
35i__3_ 
— 7^^els 
14-
378 
We can calculate that dz(x, x) — 0.0123. Note that x(0) φ χ(0). We can 
impose the condition that XQ = x(0) = 0, to find the minimal-collage 
IVP 
us 
5 
35 
At) = Ή + ΰ*> 
x(0) 
= 
0, 
with corresponding collage distance d2(x, Tx) = 0.0186 and solution 
1 
x{t) = -e 1 6 t-i 
As expected, the distance d?.{x, x) = 0.0463 is larger than in the previous 
case where XQ was not constrained. 
If we allow / to be quadratic and leave XQ unconstrained, we obtain 
the IVP 
., , 
35 
105 
231 , 
X{t) 
= Ϊ28 + 
Ί2Χ-Ή8Χ^ 
*<°> = -h 
with corresponding collage distance d2(x,Tx) 
= 0.0047 and true error 
d2(x,x) = 0.0049. 

7.3 SOLVING INVERSE PROBLEMS FOR ODEs 
165 
Figure 7.4 
Target solutions for the Lotka-Volterra system 
■ EXAMPLE 7.5 
Given the parametric representation of a curve x = x(t), y = y{t), t > 0, 
we can look for a two-dimensional system of ODEs of the form 
x(t) 
= 
f(x,y), 
x(0) = xo, 
(7.9) 
y(t) 
= 
g(x,y), 
y(0) = y0, 
(7.10) 
with conditions on / and g to be specified below. We consider the 
Lotka-Volterra system 
x(t) 
= 
x-2xy, 
z(0) = i , 
(7.11) 
y(t) 
= 
2xy-y, 
y(0) = ^, 
(7.12) 
the solution of which is a periodic cycle. We solve the system numeri-
cally. We can determine that the periodic cycle has period 6.35. Sam-
pling the numerical solution with At = 0.3, we gather 21 data points 
for both x and y. We fit eighth-degree polynomials to each data set. To 
four decimal places, the result is 
x{t) 
= 
0.2497 + 0.6565i - 1.0696i2 + 1.0191i3 - 0.4384i4 + 0.0847*5 
- 0.0050i6 - 0.0007t7 + Ο.ΟΟΟΙί8, 
y(t) 
= 
0.3401 - 0.3477ί + 0.7872*2 - 0.8188*3 + 0.4183ί4 - 0.0950*5 
+ 0.0054ί6 + 0.0014ί7 - 0.0002ί8. 
These polynomials are our target solution to the system of ODEs. See 
Figure 7.4. We look for a system of the form 
x(t) 
= 
CQX + c\xy, x{0) = XQ, 
y(t) 
= 
c2xy + 
c3y,y(0)=y0. 

166 
CHAPTER 7. INVERSE PROBLEMS IN ODEs 
We build the squared collage distances d\(x, TXX) and d%(y, TyY), where 
Tx and Ty are the usual Picard operators, for the respective component. 
Minimizing the collage distances yields the system 
x(t) 
= 
1.0349a; - 2.0471xy, z(0) =0.3241, 
y{t) 
= 
-0.9943XJ/ + 1.9839y, j/(0) =0.3388. 
This algorithm for solving ODE inverse problems is robust. 
When low-
amplitude noise is added to the sample values, we see small changes in the 
minimal-collage ODE. This effect occurs because of a continuity result for 
contractive maps and their fixed points. 
As an exercise, use Maple, Mathematica, or other mathematical software 
to program the algorithm for the preceding examples. 
EXERCISES 
7.1 
Prove that any contraction map is continuous. 
7.2 
Prove that άχ, is a metric on C(I). 
7.3 
Prove that x(t) is a solution to the IVP (7.1) and (7.2) if and only if it 
satisfies the integral equation (7.3). 
7.4 
Consider the IVP 
x'(t) 
= 
x, 
x{0) 
= 
1. 
(a) Verify that the IVP satisfies the properties required for the exis-
tence of a unique (local) solution. 
(b) Verify that x(t) = et is a solution of the IVP (and therefore the 
unique solution). 
(c) Starting with XQ — 1, use the Picard operator T to construct the 
sequence xn+i = Txn, for n = 1, 2, 3, and 4. Are you convinced 
that the sequence approaches the Taylor series of et centered at 
i = 0? 
7.5 
Consider the IVP 
x'{t) 
= 
x2 
x{0) 
= 
1. 
(a) Verify that x(t) = -^ 
is a solution of the IVP. 
(b) Starting with Xo = 1, use the Picard operator T to construct the 
sequence xn+i = Txn, for n = 1, 2, 3, and 4. Are you convinced 

7.3 REFERENCES 
167 
that the sequence approaches the Taylor series of γ ^ centered at 
i = 0? 
7.6 
Give the argument for the proof of Theorem 5 in the case t < 0. 
7.7 
Prove that the Picard operator T is contractive with respect to the 
metric d\{x,y) = Jj \x(t) — y(t)\dt. 
REFERENCES 
1. Boyce, W. E. and DiPrima, R. C, Elementary Differential Equations and Bound-
ary Value Problems, Wiley, Ninth Edition (2008). 
2. Copson E. T., Metric Spaces, Cambridge University Press, Cambridge (1988). 
3. Perko, L., Differential Equations and Dynamical Systems, Springer, Third Edi-
tion (2006). 
4. Rudin, W., Real and Complex Analysis, McGraw-Hill, Third Edition, New York 
(1986). 

CHAPTER 8 
ESTIMATION OF MODEL PARAMETERS 
ROBERT PICHE 
Tampere University of Technology, Tampere, Finland 
8.1 
ESTIMATION IS AN INVERSE PROBLEM 
Mathematical models are created to help understand real-world data. Estima-
tion is the process of determining the values of parameters of a mathematical 
model by comparing real-world observations with the corresponding results 
predicted by the model. Estimation might be done to improve the model's 
usability as a tool for prediction or for "what if" scenarios; this is sometimes 
called model calibration. The estimated values of the parameters are typically 
of interest too, because they represent important quantities, for example, ve-
locity, population, market volatility. 
In other chapters of this book, mathematical modeling procedures are pre-
sented for setting up and solving questions of the form: "with given param-
eters, what observations would result?" In this phase of modeling, we seek 
to set up a mathematical problem whose solutions exist, are unique, and are 
continuous with respect to the parameters. In estimation, the question is dif-
Mathematical Modeling with Multidisciplinary Applications. 
169 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

170 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
ferent: "what do the observations tell me about the parameters?" Estimation 
is, in this sense, an inverse problem (Figure 8.1). 
model 
Figure 8.1 
Mathematical model seen as a system with inputs (parameters) and 
outputs (observations). 
This chapter introduces a probability-theory based approach to estimation 
known as Bayesian estimation. This approach is nowadays widely applied in 
many areas of science and technology [1,2]. This chapter presents some basic 
versions of the method that could, in principle, be applied to many mathe-
matical models. To give the discussion a concrete and familiar setting, the 
method is illustrated by using the problem of estimating your position us-
ing observations such as angles between landmarks (triangulation) or ranging 
signals from satellites (trilateration). 
The chapter is organized as follows. We start with a very condensed re-
view of facts and formulas about the multivariate normal distribution that 
will be needed in this chapter. In Section 8.3, the notation for the observation 
model is introduced, and it is shown how linearization is used to obtain models 
that are more tractable for estimation computations. Basic models for posi-
tioning via triangulation and via trilateration are presented. In Section 8.4, 
the Bayesian estimation problem with nonlinear observations and multivari-
ate normal distributions is set up. Two solutions methods for computing key 
features of the Bayesian estimate are presented. The first method is computa-
tion of the posterior distribution's mean and covariance by using the moment 
matching approximation. The second method is computation of the posterior 
distribution's mode by using a numerical optimization algorithm. The two 
methods are illustrated by the detailed solution of a triangulation problem. 
Notation: In this chapter, real vectors are denoted with lowercase italic 
font, real matrices with uppercase italic, and random vectors with lowercase 
bold, The symbol 0 denotes a zero scalar, vector, or matrix, according to 
context. The expectation operator is denoted E. (In this chapter, it is under-
stood that whenever this operator is used, the random variable's probability 
distribution is such that the expectation exists.) Abbreviations used include 
pdf (probability density function), and spd (symmetric positive definite). A 
dot is used to indicate an approximate relation: = for equality and ~ for 
probability distribution specification. 

8.2 THE MULTIVARIATE NORMAL DISTRIBUTION 
171 
8.2 
THE MULTIVARIATE NORMAL DISTRIBUTION 
Definition 8.1 The mean of a random vector x is the vector Ex. The co-
variance of x, denoted varx, is the square matrix 
varx = E((x - Ex)(x - Ex)T). 
When x is a scalar, varx is called its variance. 
Fact 8.1 varx is symmetric and non-negative definite, and varx = E(xxT) — 
(Ex)(Ex)T. 
A linear transformation is a mapping of the form x i—> Ax, and an affine 
transformation is a mapping of the form x H-> b + Ax. 
Fact 8.2 The mean and covariance of an affine transformation of a random 
variable are E(b + Ax) = b + A Ex and var(6 -I- Ax.) = 
A(varx)AT. 
A standard normal random vector is characterized by the fact that its 
components are independent standard normal random variables, as follows: 
Definition 8.2 An n-variate random vector u is said to have a standard 
normal distribution, denoted u ~ N(0, /), when its probability density function 
(pdf) is 
pu(u) = (2π)-"/ 2β-5« τ" 
= 
(—e-WV..fJ-e-Κή 
Fact 8.3 The mean of a standard normal random vector u is Eu = 0 and its 
covariance is varu = I. 
A normal random vector can be characterized as an affine transformation of 
a standard normal random vector: 
Definition 8.3 A random vector x is said to have a normal distribution, 
denoted x ~ N(6, AAT), 
if x = b + Au for some standard normal random 
vector u, vector b, and matrix A. 
The following facts from matrix algebra relate the normal distribution's 
second parameter and the affine transformation's matrix. 
Fact 8.4 For any matrix A, the product AAT is symmetric and non-negative 
definite. If the columns of A are linearly independent, the product AAT 
is 
symmetric positive definite (spd). For any symmetric non-negative matrix C, 
there exists a matrix A such that C = AAT. 
For any spd matrix C, there 
exists a matrix A having linearly independent columns such that C = 
AAT; 
such a matrix A can be computed using the Cholesky factorization 
algorithm. 

172 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
The parameters of the normal probability distribution are the mean and 
covariance of the random vector: 
Theorem 8.1 J/x ~ N(6, C) then Ex — b and varx = C. 
Proof. Let C = AAT. Then Ex = E(6 + Au) = b + AE(u) = b + A ■ 0 = b and 
varx = var(6 + Au) = var(Au) = A(vaxu)AT 
= AIAT 
— AAT = C. 
■ 
In the characterization of the normal distribution in Definition 8.3, the 
covariance matrix is not required to be invertible. When the covariance matrix 
is invertible, the distribution is nondegenerate, that is, the pdf exists: 
Fact 8.5 7/x ~ N(i>, C) is an n-variate random vector with invertible C, then 
its pdf is 
Px(x) = (2^-"/ 2(detC)- 1 / 2e-i( x- 6) T c" 1( x- 6). 
The following theorem states that normally distributed random vectors 
remain normal under affine transformations. In particular, the marginal dis-
tributions of x are normal. 
Theorem 8.2 7/ x ~ N(6, C) and y = d + Bx then y ~ N(d + Bb, 
BCBT) 
and xi..fc ~ N(6i..fe, Ci.-fc.i.-fe). 
Proof Let C = AAT. 
Then y = d + B(b + Au) = d + Bb + BAu, so (by 
Definition 8.3) we have y ~ N(d + Bb, (BA){BA)T). 
The first assertion then 
follows from the fact that (BA)(BA)T 
= BAATBT 
= BCBT. 
The second 
assertion follows from the fact that the subvector is a linear transformation 
of the full vector, x1:fc = [7fc,0]x, and so xi:fc ~ N([Jfc)0]6, [Ik,0}C[Ik,0]T) 
= 
N(i>l:fc,C1:fc,1:fc). 
■ 
The following Definition and two Facts apply to a random vector having 
any distribution, provided only that the covariance exists. 
Definition 8.4 The off-diagonal blocks of the covariance matrix 
var( 
y 
z 
) 
Cyy 
CyZ 
Czy 
Czz 
are called cross-covariances and are denoted cov(y, z) = Cyz and cov(z, y) = 
Czy. 
The random vectors y and z are said to be uncorrelated if cov(y, z) = 0. 
Fact 8.6 (Chebyshev inequality) For any λ > 0, 
Ρ(χ τχ > λ) < 5 ^ * , 
Λ 

8.2 THE MULTIVARIATE NORMAL DISTRIBUTION 
173 
Consequently, for any a G [0,1), the sphere centered at Ex and having radius 
/tracevarx coniains 
af ieast a of the probability o/x, that is, 
™/„ 
^, „9 
tracevarx, 
P(||x - Ex||2 < —- 
) > a. 
Fact 8.7 Ify, z are statistically independent then y, z are uncorrelated. 
The converse of Fact 8.7 is true for random vectors that are jointly normal: 
Fact 8.8 // the random vector 
is normally distributed with uncorrelated 
y, z then y, z are statistically 
independent. 
The equal-density contours of the pdf of a nondegenerate normal random 
vector are ellipsoids: 
Fact 8.9 Let chi2inv( ·, n) denote the inverse cumulative distribution func-
tion of the chi-squared distribution with n degrees of freedom. If x ~ N(6, C) 
is an n-variate non-degenerate normal random vector and a € (0,1), then the 
ellipsoid 
S = {x:{x- 
6)TC_1(a; - b) < chi2inv(a, n)} . 
contains a of the probability of x, that is, P(x s £) = a. 
In particular, 
because chi2inv(0.95,1) = 1.962, an interval containing 95% of the probability 
of a univariate non-degenerate normal x is 
£=L: 
{X ~c
b)2 < 1.962 j = b± l W C . 
Also, because chi2inv(0.95,2) = 5.99, 95% of the probability of a bivariate 
non-degenerate normal x is contained in the ellipse 
ε={χ:{χ- 
b)TC-l{x 
-b)< 
5.99} . 
In MATLAB or Octave, this ellipse can be plotted with the code 
[u,s,v]=svd(5.99*C); t=0:0.02:2*pi; 
e=u*sqrt(s)*[cos(t);sin(t)]; 
p l o t ( b ( l ) + e ( l , : ) , b ( 2 ) + e ( 2 , : ) ) ; axis equal 
If 
is a random vector and y is a real vector such that py{y) > 0, then 
x 
yj 
y = y) denotes the random vector, called the conditional distribution of 
x given y = y, whose pdf is 
P 
p*\y{x\y) 
■= -
Γ l ( M ) 
x 
V y ) 
Py(y) 

174 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
For jointly normal random vectors, conditional distributions are normal: 
Theorem 8.3 // 
x 
. y 
with nonsingular Cy, then 
x I (y = V) ~ N (mx + CxyC~1{y - my), Cx - 
CXyC~lCyX). 
Proof. Let 
z = x-mx-CXyCy1(y-my) 
= CxyCy1my-mx+[ 
I, 
-CxyCy
x 
] 
This random vector is an affine transformation of a normal random vector 
and so is normal. Its mean is Ez = E(x — my — CxyCy1(y 
— my)) = 0 and 
its covariance is 
Cz = [ -<> 
~CxyCy 
The random vectors y and z are independent, because they are jointly normal 
and their cross-covariance is 
E(y - Ey)(z - Ez)T = E(y - m,)(x -mx- 
C^C'^y 
- my))T 
= 0. 
Thus 
x I (y = y) = (z + mx + CxyCyl{y 
- my)) \{y = y) 
= mx + CxyCy1^ 
- my) + z | (y = y), 
~N(0,Cz) 
that is, the conditional random vector is the sum of a constant and a zero-
mean normal random vector whose covariance is Cz. 
m 
8.3 
MODEL OF OBSERVATIONS 
8.3.1 
Deterministic Model and its Linearization 
A deterministic model for how an observation (ny-vector y) depends on input 
data or model parameters (nx-vector x) has the form 
■N 
mx 
CX 
C-
Xy 
yyx 
CX 
C: xy 
yx 
Ly 
I 
-c~la 
yx 
: ^x 
^-/xy^~/y 
^yx· 
y = h(x), 
(8.1) 

8.3 MODEL OF OBSERVATIONS 
175 
where h : Rn* —► Rn» is a known function. This model, illustrated in Fig-
ure (8.1), is very general, describing any mathematical model of a determin-
istic system having a finite number of inputs and outputs. The deterministic 
model will be the foundation on which the probabilistic model, used for esti-
mation, will be constructed in the next section. 
The computational methods that will be introduced later in the chapter 
all make use of an approximation of the deterministic model; this approxi-
mation is obtained as follows. In the neighborhood of a given fixed vector 
x, the deterministic model (8.1) can be linearized using a first-order Taylor 
polynomial 
h(x) = h(x) + H(x-x), 
(8.2) 
where the matrix H is the Jacobian of h, evaluated at the reference point: 
dhi(x) 
υ 
dxj 
(8.3) 
Denoting b = h(x) — Hx, the linearized model can be written in the form 
y = b + Hx. 
(8.4) 
When there are rik observation vectors, the models are denoted 
y[k] = h[k\(x)±b[k] 
+ H[k]x 
(fc = l,...,n f c). 
(8.5) 
Here are two examples of observation models drawn from the field of sur-
veying and navigation. 
■ EXAMPLE 8.1 
Triangulation 
During a cross-country ski trek in Lapland, you take out your map and 
recognize some landmarks around you: a ski lift, a cellphone network 
mast, a lake in the distance, etc. With your magnetic compass, you 
measure the headings of the landmarks. Denoting y as the heading (in 
radians, clockwise from north) to a landmark, x as your position (a;i is 
the northing, xi is the easting), and s as the landmark's position, the 
geometry (Figure 8.2) can be modeled as 
si — x\ = rcosy, 
S2 — X2 = rsmy, 
(8.6) 
where r = \\s — x\\. 
Using the two-argument arctangent function, the observation model 
can be written in the form of (8.1) with 
h(x) = atan(s2 — %2, si — xi) £ (—τ, τ]· 

176 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
>M 
2 
(xi, xi) 
(S\, S2) 
Figure 8.2 
Geometry of positioning by triangulation 
Differentiating (8.6) gives 
— Axi = dr · cos y — r sin y ■ Ay, 
— Ax2 = dr · sin y + r cos y ■ Ay 
Solving for the differentials ay and dr gives 
Ay = r _ 1 siny · Ax\ — r _ 1 cosy ■ Ax2, 
Ar = (formula not needed) 
Comparing terms with the total derivative formula Ay = -g^- Ax\ + 
o£- AX2 , it follows that 
dh 
dx\ = r 
sin y, 
dh 
dx2 
cosy 
Substituting r = \\s — x\\ and (8.6), the linearized model is obtained in 
the form of (8.4) with the 1 x 2 Jacobian matrix 
H = 
S2 
-X2 
Si 
-X\ 
EXAMPLE 8.2 
GNSS Pseudo-range 
The previous example might seem rather dated to the modern reader, 
because positioning nowadays is mostly done using devices that process 
data from global navigation satellite systems (GNSS) such as GPS and 
GLONASS. These satellites periodically transmit coded messages from 
which a receiver can recover the satellite's current position and the time 
difference between the satellite's atomic clock and the receiver's clock. 
This time difference, multiplied by c, the speed of radio waves, is called 
the pseudo-range and is denoted y. If the 3-vectors s and xi-3 denote 
the position of the satellite and of the receiver, Χ4 denotes the amount 
added to y due to the lack of synchronization, and d denotes the part of y 
that is due to other effects (including atmospheric delays and relativity), 
then a simple deterministic model for the pseudo-range is 
y = ||^i:3 - s | | +X4 + d, 

8.3 MODEL OF OBSERVATIONS 
177 
This is a model of the form of (8.1), with h(x) being the expression on 
the right-hand side of the equation. The linearized model is (8.4) with 
the 1 x 4 Jacobian matrix 
H 
(xv.3 ~ s)T
 
1 
11*1:3 - S | | ' 
8.3.2 
Probabilistic Model 
Because of the various idealizations and approximations that are made during 
the modeling process, we don't expect real-world observations to agree exactly 
with the model. Indeed, observations differ even when the same experiments 
are repeated with all the conditions, as far as we can determine, identical. 
In probabilistic (statistical) approaches to estimation, this variability is taken 
into account by modeling the observation as a random variable. 
In Bayesian estimation, the quantities being estimated are also modeled as 
random variables. This approach is based on the idea that the laws of proba-
bility serve as a logically consistent way of modeling one's state of knowledge 
(and ignorance) about these values. 
A general probabilistic version of the observation model (8.1) is a specifica-
tion of a conditional probability distribution for y given the parameters, that 
is, a specification of the random variable y | (x = x). In the case of continuous 
random variables, the specification of y | (x = x) can be in the form of a pdf, 
and this pdf is denoted 
Py\x(y\x), 
(8-7) 
In this chapter, we consider a specific instance of (8.7) that is obtained 
by adding a zero-mean multivariate normally distributed (i.e. Gaussian) term 
v ~ N(0, R), independent of x, to the deterministic observation function h 
evaluated with random argument: 
y = /i(x) + v. 
The term v is sometimes called "observation error" or "noise"; the amount of 
uncertainty of the observation is represented by the covariance matrix R. In 
the case where the observation is scalar-valued, R is a scalar and is called the 
variance. 
Because v is independent of x, we have 
y | (x = x) = h(x.) | (x = x) + v | (x = x) = h(x) + v, 
and so using Theorem 8.2 our "additive Gaussian noise" observation model 
can be written 
γ | ( χ = χ)~Ν(Λ(α;),Α). 
(8.8) 

178 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
8.4 
ESTIMATION 
8.4.1 
Bayesian Inference 
You could think of the probabilistic observation model (8.7) as a computer 
simulation program. Given certain parameter values, the program uses a 
random number generator to produce simulated observations that follow a 
certain probability distribution. From this point of view, estimation is the 
inverse problem: determine (the probability distribution of) the parameters, 
given the realized observation values. 
In principle, the estimation problem is entirely solved by Bayes' formula. If 
the pdf px(x) models your state of knowledge about x before being informed 
of the observation values, then the pdf px\y(x | y) is a model of your state of 
knowledge that incorporates this additional information. This pdf is given by 
Bayes' formula 
p*\y(x\y) <χ Py\*(y I χ)ρ*{χ) 
(8-9) 
and is the pdf of the random variable x | (y = y), which is known as the 
posterior. 
The pdf p y| x is the observation model (8.7) and the pdf p x is 
known as the prior pdf. The proportionality symbol in Bayes' formula is used 
to represent the fact that the expression on the right-hand side needs to be 
scaled by a constant (not depending on x) in order to be a proper pdf; the 
constant is determined by the fact that the integral with respect to x should 
be unity. 
With Bayes' formula we can compute (up to a scaling factor) the values 
of the posterior density at any point x, but this is not particularly useful by 
itself. One is typically interested in summarizing statistics of the distribution, 
such as the mean, the mode, the covariance matrix, or a sphere containing 
95% of the probability. Because of the nonlinearity of the observation function 
h, there are usually no formulas for these summarizing statistics, and some 
numerical methods and approximations are needed. 
In the next two subsections, two methods are presented to compute sum-
marizing statistics of the posterior distribution: moment matching and opti-
mization. 
8.4.2 
Moment Matching 
The moment-matching approach is as follows: compute (approximately) the 
mean and covariance of the joint distribution of (x, y), then approximate the 
joint distribution by a normal distribution having that mean and covariance. 
(Notice that two approximations are introduced!) The mean and covariance 
of the posterior that corresponds to this normal joint distribution are then 
given by the formulas of Theorem 8.3. 
The moment-matching method's first approximation arises in the compu-
tation of the moments μ, 5, and C, denned as follows. 

8.4 ESTIMATION 
179 
Fact 8.10 7/x ~ N(m, P) and v ~ N(0, R) are independent and y = /i(x)+v 
then 
μ — Ey = E/i(x), 
S := vary = R + E(/i(x) - μ)(/ι(χ) - 
μ)τ, 
C := cov(x,y) = E(x - m)(h(-x) - 
μ)τ. 
The method's second approximation arises when the joint distribution is 
assumed to be a multivariate normal: 
X 
. y 
~ N ( 
m 
ΐ 
P 
C ' 
_cT 
s 
Theorem 8.3 then gives the approximation of the posterior as x | (y = y) ~ 
N(g, Q) with 
q = m + CS-l{y-ß), 
Q = P-CS~1CT 
(8.10) 
provided that S is invertible. 
There still remains the question of how to compute the moments in Fact 8.10. 
One alternative is to make use of the linearization approximation of the ob-
servation model, Eq. (8.4), with x = m. When h(x) = b + Hx, the moments 
are 
μ = /ι(τη), 
S = R + HPHT, 
C = PHT. 
Substituting these into (8.10), and introducing 
K = PHT{R + HPHT)-1, 
(8.11) 
the posterior mean and covariance are obtained as 
q = m + K(y-h(m)), 
Q = P-KHP. 
(8.12) 
If P is invertible, then by applying the Woodbury matrix identity2 the 
update formulas (8.12) can be written as 
Q = {HTR-lH 
+ P " 1 ) - 1 , 
q = QHTR~l{y 
-b) + QP~xm. 
The limiting case P~l —> 0 can be interpreted as a model of "infinite" uncer-
tainty about the prior x. Even though the prior with P~l —► 0 is not a proper 
probability distribution, the corresponding limiting value of the approximate 
posterior is a proper distribution, namely x | (y — y) ~ Ν(ς, Q) with 
Q = (HTR~1H)-1, 
q = QHTR-1(y-b), 
(8.13) 
2{A + BDC)~l = A-1 - A^BiD-1 
+ 
CA^B^CA-1. 

180 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
provided that the inverses exist. 
A convenient feature of moment matching is that the posterior is (approxi-
mated to be) a normal distribution. Then, if further observations are obtained 
that are conditionally independent of the earlier observations given x, they 
can be assimilated into the posterior by updating it. That is, if m\k — 1] and 
P[k — 1] denote the mean and covariance after observations y[l:k— 1] have been 
obtained, and y[k] | (x = x) ~ N(/i[fc](x),J?[fc]) with h[k](x) = b[k] + H[k]x, 
then x | (y[l:fc] = y[l:k]) ~ N(m[k], P[k]) with 
K[k] = P[k - l]H[k]T(R[k) + H[k]P[k - l]if[A;]T)-1, 
m[k] = m[k - 1] + K[k](y[k] - h[k](m[k - 1])), 
(8.14) 
P[k] = P[k - 1] - K[k]H[k]P[k - 1]. 
This recursive one-observation-at-a-time updating procedure can be justified 
using Bayes' formula, as follows: 
Px|y[i:2](z I 2/[l:2]) oc py[1:2]|x(y[l:2] | x)px(x) 
= Py[2]|x(y[2] | x)py[i]\x(y[i] | χ)ρχ(χ) 
oc Py[2]|x(i/[2] I a;)px|y[i](a; | y[l}), 
and similarly for y[l:3], y[l:4], etc. 
To summarize, given 
• independent observation vectors y[k] for k = 1,2,... 
,n 
• observation functions x i—> /i[fc](a;) 
• additive zero-mean normal observation noises with covariance R[k] 
• a normal prior distribution with mean m[0] and covariance P[0] 
then the mean m[n] and covariance P[n] of the normal approximation of the 
posterior distribution x | (y[l:n] = j/[l:n]) can be computed as follows: 
1. Initialize k <— 1 
2. Find the mapping x i-> b[k] + H[k]x by linearizing h about m[k — 1]. 
3. Compute m[k] and P[k] using (8.14). 
4. If k = n, stop, otherwise increment k <— k + 1 and go to 2. 
If P[0] _ 1 = 0, then the update in step 3 for k = 1 is computed using 
P[l] - 
(HllfRlH-iHll])-1 
m[l]^P[l]H[l]TR[l]-\y[l]-b[l]) 
provided that the inverses exist. 
■ EXAMPLE 8.3 
The Deep Chasm 
Frodo and his companions come to the edge of a chasm. Frodo fearfully 
peers over the edge and gasps: the chasm appears to be between 100 

8.4 ESTIMATION 
181 
and 200 m deep! He drops a pebble and hears it hit the bottom 5 to 6 
seconds later. How does Prodo revise his belief about the depth of the 
chasm in light of the result of the pebble-dropping experiment? 
Let us model the prior distribution as a normal distribution that has 
95% of the probability lying in the interval [100,200]. Using Fact 8.9, a 
prior of the form x ~ N(m, P) has 95% of its probability in the interval 
m ± l.96y/P, so we set m = 150 and P = ( ^ ) 2 = 651. 
Assuming zero initial velocity and constant acceleration g = 9.81 m/s2, 
the distance fallen by the pebble in time y is \gy2 ■ Assuming instan-
taneous sound travel, a deterministic model of the time observation is 
therefore 
[2x 
y= \ — =: h(x). 
V 9 
The linearization of this model about x = x is (8.4) with 
dh(x) 
H = 
dx 
The observation [5,6] = 5.5±0.5 is interpreted as a realization y = 5.5 
of an observation of the form (8.8) with variance R = ( y ^ ) 2 = 0.0651. 
Using (8.11 and 8.12), we compute 
H = - = L = = 
1 
= 0.01843, 
V2gm 
y/2 · 9.81 · 150 
K _ P f f T i R , 
ffpffrri 
_ 
651 · 0.01843 
_ 
K-PH(R 
+ HPH) 
- 0.065!+ 6 5 1 ( 0 . 0 1 8 4 3 ) a -41.91, 
q = m + K(y - h{m)) = 150 + 41.91(5.5 - J2' ^ ) = 149.91, 
V 9.81 
Q = P- KHP = 147.97. 
The posterior distribution is thus approximated to be x | (y = y) ~ 
N(149.91,147.97). Frodo is 95% certain that the chasm depth (in meters) 
is a number in the interval 149.91 ± 1.96\/147.97 = [126,174]. 
EXAMPLE 8.4 
Triangulation (Continued) 
Given a prior estimate x = [500,1000]T, and the data in Table 8.1 and 
Figure 8.3, what is your location? 
In order to illustrate the use of recursive formulas, in this solution the 
first two headings will be treated as a single observation, and then the 
estimate will be updated using the third heading as a new observation. 

182 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
Table 8.1 
Data for the triangulation problem. 
landmark 
no. 
1 
2 
3 
northing 
(m) 
1126 
1643 
443 
easting 
(m) 
370 
2478 
2173 
angle 
(deg) 
-45 
52 
91 
std. dev. 
(deg) 
1 
2 
1 
Figure 8.3 
Geometry of the triangulation problem 
The observation model for the first observation is y[l]|(x = x) 
N(h[l]{x),R[l}) 
with 
Λ[1](χ) = atan ( 
370 
2478 
X2, 
1126 
1643 
■a*), 
Α[1]=σ§ 
l2 
0 
0 
22 
and σο = ^ 
(this is 1 degree in radians). The atan function with vector 
arguments is evaluated element-wise. 
The realized value of the observation is 
y[1] 
= 180 
-45 
52 
-0.7854 
0.9076 
The linearized model is ft[l](x) = b[l] + H[l]x with 
370-1000 
1126-500 
H[l] = 
(1126-500)2 + (370-1000)2 
2478-1000 
(1643-500)2 + (2478-1000)2 
(1126-500)2 + (370-1000)2 
1643-500 
(1643-500)2 + (2478-1000)2 
= 10" 
-798.71 
-793.63 
423.38 
-327.42 

8.4 ESTIMATION 
183 
and 
b[l] = h[l](x) - H[l]x 
370 
= atan I 
10" 
2478 
-798.71 
423.38 
1000, 
1126 
1643 
500 
-793.63 
-327.42 
500 
1000 
0.404 
1.0283 
Assuming a prior with mean x and "infinite" covariance, we apply the 
formula (8.13) and obtain the approximate posterior x|(y[l] = y[l]) ~ 
N(m[l],P[l]) with 
2241 
-2045 
P[l] = mifRil]-^^])-1 
= 
m[l}=P[l}H[i}TR[l}-\y[l}-b[l}) 
= 
-2045 
2330 
491.7 
1004.4 
The approximate posterior distribution's mean is shown in Figure 8.4; it 
lies on the intersection of the lines of sight to the landmarks. Also shown 
is an ellipse containing 95% of the probability; the ellipse is computed 
using Fact 8.9. 
Next, we update this estimate using the third heading as the new 
observation. The observation model for the observation is y[2]|(x = 
χ)~Ν(Λ[2](χ),Η[2]) with 
h[2](x) = atan(2173 - x2,443 - χχ), 
R[2] = σ\. 
The realized value of the observation is y[2] = 91 180 
1.5882. 
The model linearized about m[l] is /i[2](:r) = b[2] + H[2]x with 
H[2) 
2173-1004.4 
(2173-1004.4)2 + (443-491.7)2 
443-491.7 
(2173-1004.4)2 + (443-491.7)2 
= 10 - 6 [ 854.24 35.60 ] . 
Applying the updating formulas (8.14), we obtain the new posterior 
x|(y[l:2] = y[l:2]) ~ N(m[2],P[2]) with 
K[2] = P{1}H[2}T{R[2] + H[2]P[1]H[2]T)-1 
= 
P[2] = P[l] - K[2]H[2]P[1] = 
m[2]=m[l]+K[2]{y[2]-h[2](m[l])) 
1012.7 
-915.0 
376.1 
-359.9 
359.9 
807.5 
467.2 
1026.5 

184 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
The posterior mean and an ellipse containing 95% of its probability are 
shown in Figure 8.4. An interval for the northing that contains 95% of 
the posterior probability is 
467.2 ± 1.96^376.1 = [429., 505.2]. 
An interval for the easting is 
1026.5 ± 1.96^807.5 = [970.8, 1082.2]. 
In this solution, the observations were processed in two batches, and 
the linearization reference point was updated between batches. If all 
three observations had been processed in a single batch, with a single 
linearization about the prior mean, the answer would be (slightly) dif-
ferent. 
Figure 8.4 
Position estimated by triangulation. The headings are shown as lines 
from the (distant) landmarks; the large ellipse centered at m[l] is the 95% ellipse for 
the position estimate based on the first two headings; the small ellipse centered at 
m[2] is the 95% ellipse for the position estimate based on all three headings. 
8.4.3 
Estimation by Optimization 
Up to this point we have assumed a normal prior x " 
normal conditional observation y | x ~ 
N(h(x),R). 
N(m, P) with spd P and 
Here we further assume 

8.4 ESTIMATION 
185 
that R is spd. By Bayes' formula (8.9), the posterior density is 
px\y(x\y) 
ocpy\x{y\x)px(x) 
Qie-i(h(x)-y)TR-1(h(x)-y)e-i(x-m)Tp-1(x-m) 
oce-*W, 
where 
φ(χ) = \{h(x) - y)TR-\h(x) - y) + \{x - πι)τρ-\χ 
- m) 
(8.15) 
Instead of seeking the mean of the posterior, as in the previous section, let us 
seek the mode of the posterior, that is, the point of maximum density. This 
is called the maximum a-posteriori (MAP) estimate, and it can be computed 
by using numerical optimization algorithms to find the minimizer of the "cost 
function" φ. 
According to Fact 8.4, the covariance matrices can be factorized as P = 
AAT 
and R = BBT. Then the cost function can be written as a sum of 
squares 
φ{χ) = \\\ί{χ)\\\ 
(8.16) 
with the (weighted) residual 
A~1(x - m) 
B-1(Hx)-y) 
. · 
Minimization of a cost function of the form (8.16) is called a nonlinear least 
squares problem. There exist several algorithms for this class of optimization 
problems; in the following we present the algorithm known as the Gauss-
Newton method. 
The "Gauss" part of the method's name comes from the use of the theory 
of least squares, which is summarised as follows. 
Fact 8.11 (Least squares) For any matrix A, there exists a unique solution 
to the equation set 
AX A = A, XAX = X, (AX)T = AX, {XA)T = XA. 
This solution is called the Moore-Penrose pseudoinverse and is denoted A+. 
For any compatible-sized vectors b and x, there holds 
\\b - Axf = \\b - AA+b\\2 + \\A(x - A+b)\\2. 
Consequently, x = A+b is a minimizer of \\b—Ax\\2. If A has linearly indepen-
dent columns then A+ = {A7 A)~lAT 
and the minimizer x = 
(ATA)~1ATb 
is unique. 
/(*) = 

186 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
The "Newton" part of the method's name comes from the linearization of 
the residual function, similarly to what is done in the Newton method for 
finding the zero of a function. The linearization about a given reference point 
is 
f{x + d)= f(x) + Jd, 
where J is the Jacobian of /, evaluated at the reference point: 
A'1 
' 
The linearization of the residual function corresponds to the approximation 
of the cost function as 
<l>{x + d) = \\\f{x + d)\\2±\\\f{x) 
+ 
Jdf. 
Invoking Fact 8.11, and noting that J has linearly independent columns, the 
approximated cost function is minimized by taking d to be 
dsn = 
-{JTJ)-lJTf{x) 
= -{^R^H 
+ p - ^ - ^ F - ^ x - m) + HTR~l{h{x) 
- y)) 
= m — x + K(y — h(x) — H ( r o - x ) ) , 
(8.17) 
where 
K = PHT(R 
+ 
HPHT)~\ 
The Gauss-Newton algorithm for finding the minimizer of (8.15) consists 
of assigning the initial value x, then repeatedly updating x <— x + dgn using 
and (8.3) and (8.17) until ||dgn|| is sufficiently small. 
Notice that if the initial value is taken to be x = m, then the first Gauss-
Newton update m + dgn coincides exactly with the posterior mean found by 
the method of moment matching with linearization that was described in 
Section 8.4.2. 
In the case of a prior with P _ 1 —> 0, and provided that H has linearly 
independent columns, in place of (8.17) one can use the formula 
dgn = -(HTR-lH)~lHTR-l{h{x) 
- j/)). 
(8.18) 
Sometimes the Gauss-Newton step dgn may be so large that the cost func-
tion actually increases. In order to avoid this, one can take a smaller step by 
scaling dgn if necessary to ensure that the cost function is decreasing. The 
following theorem establishes that this is always possible, because the Gauss-
Newton step dgn is a "descent direction." 
Theorem 8.4 There exists a positive a such that the inequality <p(x+adgn) < 
φ{χ) holds for all a € (0,Q). 
dx 

8.4 ESTIMATION 
187 
Proof. The Taylor expansion of the objective function is 
φ(χ + ad) = φ(χ) + αφ'(χ)ά + 
0(a2), 
so d is a descent direction if φ'{χ)ά < 0. For φ(χ) = ^\\f(x 
dx. 
Z ^ / ' W ^ ' 
and for the Gauss-Newton step we have 
<£'(£)dgn = f(x)TJdgn 
= -d£1(jrr.7)-1dgn) 
which is < 0 because JTJ is spd. 
■ 
In each iteration of the "descending" Gauss-Newton method, initialize a <— 1, 
repeat the "line search" 
while (/»(i + adgn) > φ(χ) : 
a <— — 
to determine a suitable scale factor a, and update x <— cc + acign· (A computer 
implementation in floating point arithmetic should of course include a limit 
on the number of line search steps, to avoid an infinite loop.) 
To summarize, given 
• a vector of observations y 
• an observation function x >—► h{x) 
• additive zero-mean normal observation noises with covariance R 
• a normal prior distribution with mean m and covariance P 
then the MAP estimate x, that is, the mode of the posterior distribution 
x | (y = y), can be computed using the descending Gauss-Newton algorithm 
as follows: 
1. Initialize x «— m. 
2. Find the mapping x *-+ b + Hx by linearizing h about x. 
3. Compute dgn using (8.17) [or (8.18) if P _ 1 = 0] and set a <- 1. 
4. Compute φ(χ) using (8.15) with x <— x. 
5. Compute φ(χ + adgn) using (8.15) with x <— x + adgn. 
6. If φ(χ + adgn) > φ(χ), set a <— \a and go to 5. 
7. Update x <— x + adgn. 
8. If ||dgn|| is small enough, stop; otherwise, go to 2. 
The ordinary Gauss-Newton algorithm is obtained by omitting steps 4-6. 
■ EXAMPLE 8.5 
Triangulation (Continued) 
Let's find the MAP estimate of position for the data in Example 8.4. 
The Gauss-Newton iteration may be started from the posterior mean 

188 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
found earlier: 
467.2 
1026.5 
The observation function evaluated at this point is 
h(x) = atan ( 
370 
2478 
2173 
- 1026.5, 
" 1126 " 
1643 
443 
- 467.2) = 
' -0.7836 
0.8900 
1.5919 
This is very close to the realized observations 
-0.7854 
0.9076 
1.5882 
and so it can be expected that further iterations will not change the 
answer much. However, for the sake of demonstration of the algorithm, 
let's carry out the computations. 
The observation function's Jacobian is 
370-1026.5 
(1126-467.2)2 + (370-1026.5)2 
Γ , / Μ _ 
2478-1026.5 
n\x) 
— 
(1643-467.2)2 + (2478-1026.5)2 
2173-1026.5 
(2173-1026.5)2 + (443-467.2)2 
" -758.95 
-761.61 " 
10 - 6 
415.98 
-336.97 
871.83 
18.40 
1126-467.2 
(1126-467.2)2 + (370-1026.5)2 
1643-467.2 
" (1643-467.2)2+(2478-1026.5)2 
443-467.2 
(2173-1026.5)2 + (443-467.2)2 
Applying the formula (8.18), we obtain the correction step 
dgn = 10 - 1 2 
-0.1557 
-0.1471 
This step is very small (less than a millionth of a micron!), so the itera-
tion was indeed unnecessary. 
8.5 
CONCLUSION 
This chapter has presented a basic version of Bayesian estimation in which 
normally distributed noise is added to a nonlinear observation model. This 
basic framework can be used to estimate parameters for a wide variety of 
models, and it can be extended further: 

EXERCISES 
189 
• Besides the Gauss-Newton method presented here, optimization liter-
ature and software packages offer many alternative methods, of which 
the Levenberg-Marquardt algorithm is one of the most popular. 
• In this chapter the noise covariance was assumed to be known. It is 
possible to treat the covariance matrix as an additional unknown pa-
rameter that is then estimated from the data using Bayes' rule, along 
with the other parameters. For linear observation models, closed-form 
formulas are given for example in Ref. [3]. 
• The moment matching method described in Section 8.4.2 can be ex-
tended to estimate parameters of models of dynamic (time-varying) phe-
nomena. This estimator is called the Extended Kaiman Filter, and is 
described in detail for example in Refs. [4,5]. 
• Outliers tend to be much more common in real-world data than in 
random samples from a normal distribution. Instead of normally dis-
tributed noise, one could use a heavy-tailed probability distribution such 
as the Student-ί. For a linear (or linearized) observation model, the pos-
terior mean and covariance can be computed using the MATLAB code 
provided in Ref. [6]. 
EXERCISES 
8.1 
This exercise is a continuation of Example 8.3. Suppose now that one 
of Frodo's companions, the sharp-eared Legolas, drops a pebble and says that 
the sound of its striking the ground came back 5.45-5.60s later. Update the 
probability distribution that models Frodo's belief about the depth. 
8.2 
A hall has a floor plan that is an equilateral triangle (Figure 8.5). 
(0,0) 
(12m,0) 
Figure 8.5 
Floor plan for Exercise 8.2. 
Find the observation function yi:3 = /i(x) + v when y, is the in-plane 
distance between the ith wall and the in-plane position xi:2 of a point in the 
hall. Assume the observations have independent zero-mean errors. 
Standing in the hall, you measure your distance to walls 1, 2, and 3 to be 
2 m, 4 m, and 6 m, respectively. Where are you? 
Suppose each observation has a standard deviation of 50 cm. Using the 
Chebyshev inequality, find the radius of a disk that, with 95% probability, 
contains your position. Also, plot the smallest ellipse that, with 95% proba-
bility, contains your location. 

190 
CHAPTER 8. ESTIMATION OF MODEL PARAMETERS 
8.3 
The in-plane position of a robot has prior x ~ N([0,0] T,30 2/). 
The 
observations y = [108, 46] T are the distances from the robot to two infrared 
ranging devices located at s[l] = [100, 0] T and s[2] = [0, 50] T. Each range 
observation has a zero-mean error with standard deviation 10. 
Plot some level curves of φ(χ) = — logp x | y(x \ y) in the region [—50,70] x 
[-20,100]. 
Find the posterior mode using the Gauss-Newton method. 
REFERENCES 
1. Bertsch McGrayne, S., The Theory That Would Not Die: How Bay es' Rule 
Cracked the Enigma Code, Hunted Down Russian Submarines, 
and Emerged 
Triumphant from Two Centuries of Controversy, Yale University Press, 2011. 
2. Jaynes, E. T., Probability Theory: The Logic of Science, Cambridge University 
Press, 2003. 
3. Koch, K-R., Introduction to Bayesian Statistics, 2nd ed., Springer, 2007. 
4. Maybeck, P. S., Stochastic Models, Estimation, 
and Control, Vol. 1, Academic 
Press, 1979; Navtech, 1994. 
5. Challa, S., Morelande, M. R., Musicki, D., and Evans, R. J., Fundamentals of 
Object Tracking, Cambridge University Press, 2011. 
6. Piche, R., MVSREGRESS — Robust multivariate linear regression based on the 
Student-t distribution, http: //www. mathworks. com/matlabcentral/f ileexchange/ 
31230-mvsregress 

CHAPTER 9 
LINEAR AND NONLINEAR PARABOLIC 
PARTIAL DIFFERENTIAL EQUATIONS IN 
FINANCIAL ENGINEERING 
L. A. BOUKAS1, K. I. VASILEIADIS2, S. Z. XANTHOPOULOS2, A. N. YANNACOPOULOS· 
Department of Information and Communication Systems Engineering, University of 
the Aegean, Greece 
Laboratory for Financial and Actuarial Mathematics, Department of Statistics and 
Actuarial - Financial Mathematics, University of the Aegean, Greece 
Department of Statistics, Athens University of Economics and Business, Greece 
9.1 
FINANCIAL DERIVATIVES 
Financial markets are mechanisms that facilitate the trading (buying and 
selling) of various assets, as, for example, financial securities (e.g., stocks 
and bonds), commodities (e.g., precious metals or agricultural products), etc. 
Among the various types of financial markets (e.g., capital markets, money 
markets, commodities markets, etc.), the market for derivative securities has 
seen an enormous growth during the last 30 years. One could say that the 
main role of the derivatives market is to facilitate the transfer of the financial 
risk that is inherent in other assets. 
Mathematical Modeling with Multidisciplinary Applications. 
191 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley &; Sons, Inc. 

192 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
Generally speaking, a derivative security (or derivative contract or simply 
derivative) is a contract, the value of which depends on a reference value of 
some other underlying asset (s). 
Usually, the underlying asset, to which a derivative refers, is a tradable 
financial security or a commodity, and the reference value is the price of this 
underlying asset. However, the reference value could be more complex, like, 
for example, the average price of the underlying asset during the life of the 
derivative contract or the maximum price of a basket of underlying assets, 
etc. On top of this, a derivative may refer to more "exotic" underlying assets, 
like, for example, the height of snow in a skiing resort, the number of CO2 
molecules in the city center or the value of other derivatives, etc. 
Each derivative contract has two counter parties, usually referred to as the 
"buyer" and the "seller" of the contract. Accordingly there are two opposite 
positions in a derivative, the one of the buyer (the long position) and the one 
of the seller (the short position). 
The most simple examples of derivative securities are the so-called Forwards 
and Options. 
■ EXAMPLE 9.1 
Forwards 
A forward contract (or simply forward) is an agreement according to 
which the two counter parties agree that they will perform a trade in 
the future as follows: the buyer of the contract is obliged to buy from 
the seller of the contract (and the seller of the contract is obliged to sell 
to the buyer of the contract), a prespecified quantity of an underlying 
asset at a prespecified future time and at a prespecified price. 
The prespecified future time at which the future trade will take place 
is called time of maturity of the forward contract, while the prespecified 
price at which the future trade will take place is called delivery price of 
the forward contract. 
Obviously, a variable that affects decisively the value of the forward 
contract is the current price (spot price) of the underlying asset. Usually 
at the time that the two counter parties enter the forward contract, the 
delivery price of the underlying asset is selected in a way that the forward 
contract has zero value to the two counter parties. After this time, the 
value of the forward contract changes, becoming positive for one of the 
counter parties and equally negative for the other counter party. The 
delivery price for which a forward contract has zero value is called the 
forward price of the forward contract. 
One can see directly that at maturity, the value (to the buyer) of a 
forward with delivery price K is given by fr — S{T) — K, where S(T) 
denotes the price of the underlying asset at the time of maturity of the 
forward. Obviously, the value (to the seller) of the forward with delivery 
price K is given as —fr = K — S(T). 

9.1 FINANCIAL DERIVATIVES 
193 
■ EXAMPLE 9.2 
Options 
Options are contracts that give to their holder the right to perform a 
future trade according to prespecified terms. In contrast to forwards the 
holder of an option is not obliged to perform this future trade. Therefore 
an option is exercised only if it is profitable to its holder. 
Depending on the flexibility to exercise an option, there are two main 
types of options, European and American. The options of European 
type can be exercised only at the end of the life of the option (expiry) 
while the options of American type can be exercised at any time until 
the end of the life of the option. 
Depending on the type of the future transaction (buying or selling the 
underlying asset) that an option offers to its holder, we distinguish two 
basic kinds of options: the call option and the put option (sometimes 
referred to as the plain vanilla options). 
► A call option (of European type), on an underlying asset A, with 
exercise price K and expiry T, is a contract between two counter parties 
(the buyer and the seller) that gives to the buyer of the option, the right 
to buy the underlying asset A at time T and price K. 
► A put option (of European type), on an underlying asset A, with 
exercise price K and expiry T, is a contract between two counter parties 
(the buyer and the seller) that gives to the buyer of the option, the right 
to sell the underlying asset A at time T and price K. 
The buyer of an option pays a premium to the seller of the option 
and acquires the right to exercise the option (without being obliged to 
do so) during the exercise time. We say that the buyer of an option 
has a long position on the option. The seller of the option receives the 
premium of the option in advance and has the obligation to satisfy the 
buyer according to the contractual terms of the option in the case that 
the buyer decides to exercise the option. We say that the seller of the 
option has a short position on the option. 
Therefore we notice that there exist four different basic positions on 
options, namely: long call, short call, long put, short put. 
One can see directly that the value of a call option at expiration is 
given as CT = max(5(T) — K, 0), while that of a put option is given as 
PT = max{K - S(T), 0). 
However, the value of an option at a time before expiration is not so 
easy to determine, as we will see in the following sections. 

194 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
9.2 
MOTIVATION FOR A MODEL FOR THE PRICE OF STOCKS 
Before we can say anything of some importance about the valuation of a 
derivative security, we need a model describing the behavior of the price of 
the underlying asset. This is equivalent to assuming a model that describes 
the returns of the underlying asset in various periods of time. 
So we will start by explaining briefly why it is plausible to assume that the 
return of an asset is a normally distributed random variable. 
It is very convenient in finance to work with the geometric (or logarithmic) 
return of an asset instead of the arithmetic return.3 
From now on (and without loss of generality) we will assume that the 
underlying asset is a (nondividend paying) stock. The simplest "realistic" 
model describing the behavior of the price of stocks is the geometric Brownian 
motion. 
The geometric (or logarithmic) return of the stock during some time pe-
riod [ii, £2] is defined as R[t1,t2] = m ( sff) )· This *s equivalent to Sfo) 
= 
5(ii)exp(i?[il;t2]), which amounts to continuous compounding of the return. 
Notice the nice property R[tut2] + R[t2,t3\ = R[ti,t3}-
Let us consider a very small time period Δί measured in years (for example, 
At = 1/101000 of a year). Let us consider the times to = 0 and U = i ■ At 
for i 6 N. We denote by S(ti) the random variable that represents the price 
of the stock at time U as it is perceived at time 0. For each i = 1,2,... let 
RAH = ·β[ίΐ_ι,ίί] = m ( sit- 
)) denote the random variables representing the 
return of the asset during the time period [ti_i, t»]. 
The only assumption that we will make is that the returns RAU are in-
dependent and identically distributed random variables with mean value μΑί 
and variance 
σ\ν 
Let us consider now the time T = 1 year (i.e., tn = 1 for some n or 
equivalently Δί = 1/n). Let μ — E[i?[01j] denote the expected return and 
σ2 = Var(R[0^) 
denote the variance of the return of the stock during the 
forthcoming year. 
Clearly, -R[o,i] = RAU +--- + RAtn- But then μ = η·μΔί => ßAt = A»· 1/n => 
ΜΔί = μ ■ At and 
σ2 = n · a\t => o\t = σ2 ■ 1/n => a\t = σ2 · Δί. 
Let us consider now an arbitrary time T — ijv — N · At for some large 
enough N e N and denote by RT = R[O,T] = In ( Ί4^) ) the random variable 
representing the return of the stock during the time period [0, T\. 
3Let S{t) denote the price of a stock at some time t. The arithmetic return of the stock 
during some time period ii, ti is defined as rj t l t2] = 
s(t ) 
This is equivalent to 
S(i 2) = S ( t i ) ( l + r[ t l i t 2]). Notice however that r [ t l i t 2] +η ί 2,ί 3] 
¥=r[tut3]. 

9.3 STOCK PRICES INVOLVING THE WIENER PROCESS 
195 
Obviously, RT = RAtl+-+RAtN- 
But thenE[i?T] = Ν·μΑί 
= μ-N-At = μ·Τ 
and 
Var{RT) 
= N ■ a2
At = σ2 ■ N ■ At = σ2 -Τ. 
Then, the Central Limit Theorem implies that RT —> Ν(μΤ, σ2Τ), i.e., RT 
is asymptotically distributed as a normal with mean μΤ and variance σ2Τ. 
Therefore, if μ is the expected one-year return of the stock and σ2 is the 
variance of the one-year return of the stock, then the random variable S{T) 
that represents the price of the stock at some time T is lognormally distributed 
since 
Thus, in order to model the price of the stock with a stochastic process we 
would like a process that would result into S(t) = 5(0) · exp(Z) where Z is a 
normal distribution with mean μί and variance a2t. Moreover, we would like 
the returns that are produced by this process at non-overlapping intervals 
to be independent random variables. By the properties of the lognormal 
distribution it follows that 
E[S(T)|S(0)] = S(0) exp 
[μΤ+^f). 
Such a class of processes, which also allows to describe the model in a 
dynamic fashion, can be effectively produced by using the properties of the 
so-called Brownian motion or Wiener process. This is the topic of the next 
section. 
9.3 STOCK PRICES INVOLVING THE WIENER PROCESS 
As argued in Section 9.2 above, the simplest "realistic" model for the price of 
stocks is geometric Brownian motion. According to this model the logarith-
mic returns of the stocks follow the normal distribution. Let S(t) be the price 
of the stock at time t. This is a random variable, depending on the state of 
the economy, i.e. the contingencies that have occurred till time t. These con-
tingencies are assumed to have formed the prices of the stock via the market 
forces of supply and demand (if you believe the fable of general equilibrium) or 
by oligopolistic processes (if you do not). Being mathematicians and leaving 
theoretical economics aside, we assume that 
ν"
:="'(ϋ)~"
(Α'·
Λ)' 
or in other words 

196 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
This model, simple as it may be, is still a credible model for the price of stocks 
and gives rise to the lognormal distribution. Under certain circumstances this 
model serves as a good model for the time series of stock prices observed in 
some markets. 
An alternative way of seeing this model is in a dynamic fashion. To do 
this we need to introduce a stochastic process, which is called the Brownian 
motion or the Wiener process. So as not to get into the intricacies of stochastic 
process theory, we will content ourselves with the working definition of a 
stochastic process as a collection of random variables (indexed by t 6 K+). 
For an excellent mathematical introduction to the Wiener process and its 
applications in finance, see Refs. [5] and [6]. 
Definition 3 The Wiener process {W(t)}tes.+ 
is a collection of random vari-
ables with the following properties: 
1. The random variables W(U) — W(U-i) 
and W{U-\) — W(U-2) are in-
dependent random variables for allti,..., 
tn, f,_i <U, i = 
2,...,n. 
2. When considered as a (random function) of time t, the function 
W(t) 
is a continuous function (almost surely4) such that W(0) = 0. 
3. 
W(t)-W(s)~ßS(0,t-s) 
By the properties of the normal distribution and the above definition it 
may be seen that 
ßt + aW{t) ~ Af(ßt, σΗ) 
so that our model for the logarithmic returns can be expressed equivalently 
as 
S(t) = S(0) exp(/xi + aW{t)). 
To obtain a dynamic version of this model we need to associate the change of 
the value of the stock in the time interval [t,t + dt) with the observed value 
of the stock at time t. This reminds us of connecting the temporal derivative 
of the random function S(t) with its value S(t) at time t, i.e., setting up a 
differential equation for the evolution of the stock value. However, life is not 
all that rosy! One of the intriguing properties of the Wiener process is that it 
is a function which may be continuous but is nowhere differentiable. In fact it 
is a function presenting variation in all scales, a property inherited either by 
its construction as a scaled random walk or as a random Fourier series, and 
this shows up in the observation that it is a function of infinite variation, i.e., 
n 
svpY/\W(ti)-W{ti-i)\=o°, 
4i.e., for all realizations of the random process apart from some of measure zero. 

9.3 STOCK PRICES INVOLVING THE WIENER PROCESS 
197 
where {£1,^2, · · ■ ,tn} is a partition of [0,i] and the supremum is taken over 
all partitions of [0, t]. This tells us that when we observe the absolute value of 
the variation of the Wiener process at the finest scale we may take, and then 
add it all up, the variation is infinite. 
All seems to be lost, but the following observation comes to rescue. If we 
take the quadratic variation of the Wiener process, then this is finite and in 
particular 
n 
8upY/\W(U)-W(U-i)\2 
= t, 
i=l 
where again the supremum is taken over all possible partitions of [0, t]. The 
above observations, i.e., the connection of a finite square variation with an 
infinite variation is very deep and intimately related with the random walk 
nature of the Wiener process.5 
The infinite variation of the Wiener process does not allow us to interpret 
the integral J0 f(s, w)dW(s) as a Stieltjes integral. We should rather interpret 
it as a "new" integral called the Itö integral which is defined as the limit as 
n —► 00, in the L2(Q, T, P) sense of the sequence of random variables 
n 
in:=X)/(ti,ü;)(W(i i +i)-W(ii)), 
t=l 
where {U} is a partition of [0, t]. Recall that as sequence of random variables 
{ξη} converges to a random variable £ in the L2{£l,T,P) 
sense, if E[(£n — 
ξ)2] —> 0 as n —> 00. It can be shown that this limit exists, giving rise to a 
new random variable denoted by / 0 f(s, ω) dW(s) with the properties 
E 
E 
J f(s,Lj)dW(s) 
J f(s, ω) dW(s)\ 
= E \J (f(a, ω))2 ds 
= 0 
2 
It may further be shown that the second property is crucial in developing this 
theory as the class of stochastic processes for which the Itö integral is defined 
as simply those for which the right-hand side of this equality (called the Itö 
isometry) makes sense. 
Based on this new concept of integration, which was proposed by Kyoshi 
Itö, a new calculus was developed, bearing his name, that allows us to bypass 
the absence of derivatives of the Wiener process and understand and model 
the changes of S(t) in a generalized fashion under an integral sign. Absence 
5 Any square integrable continuous martingale can be shown to have this property. 

198 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
of space does not allow us to give full credit to this elegant theory so we only 
summarize Itö's lemma that allows us to monitor changes in the value of a 
function calculated on the Wiener process. 
Proposition 1 Let f : R + x R —> R be a C1'2 function. Define the process 
Y(t) := S{0) + μί + σ W{t). 
Then, 
f(t,Y(t))-f(0,Y(0)) 
There are versions of Itö's lemma covering more complicated stochastic 
processes than the process Y(-) considered above. For instance, it may be 
useful to consider a stochastic process X(-) such that at any time t £ [0, Γ] it 
holds that 
X(t) = X0 + ί μ(3,Χ(3))σΐ3+ 
ί a(s,X(s))dW{s), 
(9.1) 
Jo 
Jo 
where the last integral is understood as an Itö integral and the functions μ 
and σ are known functions. Such a process is called an Itö process. Equation 
(9.1) is an integral equation which involves the Itö integral of the unknown 
process X(-). It is also common to encounter this equation in a (shorthand) 
differential form as 
dX(t) = μ(ί, X(t))dt + a(t, X(t))dW(t), 
(9.2) 
with initial condition X(0) = XQ. Such differential equations are called 
stochastic differential equations, and there is a rich mathematical theory cov-
ering their existence and uniqueness properties as well as their qualitative 
behavior. We content here to say that the above equation is well posed un-
der, e.g., Lipschitz type conditions for μ and σ. 
A version of Itö's lemma for solution of stochastic differential equations is 
given in the following: 
Proposition 2 Let f : R + x R —> R be a C1'2 function. Define the process 
X(-) as the solution of the stochastic differential equation [9.1) (equivalently 
(9.2)]. Then, 
f(t,X(t))-f(0,X(0)) 
where of course now μ and σ are functions of x. 

9.4 CONNECTION BETWEEN THE WIENER PROCESS AND PDEs 
199 
9.4 
CONNECTION BETWEEN THE WIENER PROCESS AND PDEs 
There is an intimate connection between the Wiener process and functionals 
of the Wiener process with the solutions of linear partial differential equations 
of the parabolic type. This connection can already be made apparent by the 
version of Itö's lemma presented in Proposition 2 which involves a partial 
differential operator in the drift term, but we would like to devote some more 
time to this important part of the theory. 
By definition the Wiener process is distributed by the normal (Gaussian) 
distribution. This means that if one wishes to calculate the moments of the 
random variable X = f(W(t)) 
where / is a Borel function defined on the 
reals, then 
If on the other hand we assume that we start our Wiener process at the initial 
point x rather than 0 and then we wish to calculate the moments of the 
random variable X = f(x + W{t)) then a similar calculation will give us 
E[f(x + W(t))} = | ^ / ( a ; + 2/)^L=exp(-0 dy 
f{y)-^exP[-{-^^-)dy. 
If we thus define the function U : M+ x R -> R by U(t, x) := E[f(x + W(t))} 
we see by the above calculation that 
^
-
^
^
-
"
"
(
-
^
)
*
· 
( 9 · 3 ) 
The last integral rings a familiar bell. It is nothing else but the integral 
representation of the solution of the heat equation 
dJL = \d^L 
(94) 
at 
2 ot2 
[ 
' 
subject to the initial condition U(0, x) = f{x). Therefore the interpretation of 
the integral in Eq. (9.3) is as the solution of the initial value problem (Cauchy 
problem) (9.4) with the stated initial condition. This is very important as it 
leads to the fundamental relation between the solutions of the heat equation 
and the Wiener process that can be stated as 
The solution of the heat equation (9.4) with the initial condition 
£/(0, a;) = f(x) can be expressed in terms of the expectation 
U(t,x) = Ex[f(W(t))}, 
(9.5) 

200 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
where by Ex[] we denote the expectation over the paths of the (general-
ized) Wiener process6 W(t) which is a Wiener process that has started 
its path at point x (rather than at point 0). 
The interpretation of this formula is very clear. If you want to find the solution 
of the heat equation at time t and at the position x, then you have to start 
a path of the Wiener process at x and run it for time t. Then calculate your 
initial condition (the function / at the point that this Wiener process has 
reached by time t. This gives you a random variable f(W(t)) 
= 
f(xw(t))-
The expectation of this random variable is the function we seek. This can be 
approximated as follows: Repeat the above procedure for as many paths as you 
can and then approximate the expectation of the random variable f(W(t)) 
= 
f(xw{t)) 
by the standard estimator for the expectation, the sample mean. 
This will give us an approximation of the solution of the heat equation at 
(t,x). 
The above connection between the heat equation and the Wiener process 
is not just a coincidence. It is a fact that holds in general for any Itö process 
and is related to properties of these processes such as the Markov property 
and the semi-martingale property, which unfortunately we may not introduce 
here at length due to space limitations. At any rate this connection, known 
as the celebrated Feynman-Kac representation formula, connects solutions 
of general linear parabolic partial differential equations with expectations of 
functionals of Itö processes. The basic quantity connecting these two notions 
is the generator operator of the Itö process which for a general process of the 
form (9.2) is the operator C : C2(M) -»· C(R) defined by 
£/(*):= M*)g+,(*)»ig. 
Then the general result (which is of course connected with Itö's lemma) is 
that if we start the Itö process defined by Eq. (9.2) at point x and leave the 
process running for time t, and calculate the expectation of the functional 
f(X(t), 
then 
E[f(X(t))} 
= U(t,x), 
where U(t, x) is the solution of the linear parabolic partial differential equation 
with initial condition {7(0, x) = f(x). 
This result can be extended for Itö 
processes in Mn (see the forthcoming section on dynamic programming) or 
even for Itö processes taking values in infinite dimensional spaces. 
6By the properties of the Wiener process we can see that W(t) = x + W(t) where W(t) is the 
standard Wiener process. Furthermore, W(t) ~ Af{x, t) whereas W(t + s) — W(t) ~ Λ/"(0, s). 

9.5 THE BLACK-SCHOLES-MERTON EQUATION 
201 
9.5 
THE BLACK-SCHOLES-MERTON EQUATION 
Consider a financial option with payoff Φ(£(Τ)) at expiry T, where Φ : R —■> M. 
is a given function. If the option is a European call, then Φ(χ) = (x — K)+, 
whereas if it is a European put then Φ(χ) = (K — x)+. 
The value of the 
financial option at time t is considered to be a function of the value of the 
underlying asset at time t. Therefore, we assume7 the existence of a function 
y : [0, Γ] x R —> R+ such that V(t,S(t)) 
provides the price of the option in 
the market at time t. This function must have the property V(T, S(T)) 
= 
Φ(5(Γ)). 
If we manage to specify this function V then we have a nice way to price 
the option. All we need is to know the price of the stock at time t, S(t), this 
is easy to obtain from the market, and we substitute this value in the function 
to provide the price an investor will pay at time t to acquire this option and 
thus guarantee the payoff Φ(5(Τ)) upon expiry T. It is the aim of this section 
to show that if such a function exists, then it must be the solution of a linear 
parabolic PDE. 
We now consider a portfolio consisting of the option and a position of Δ 
units in the underlying asset (the stock). The total value of this portfolio at 
time t, given that the underlying asset has value S(t) will be 
U(t,S(t)) = 
AS(t)-V(t,S(t)). 
This portfolio corresponds to the writer of the option (short position in the 
option), i.e. to the agent that guarantees Φ(5(Τ)) upon expiry. 
The value of this portfolio [being a function of S(t)] is a random function 
that fluctuates with the price of the underlying asset. Can we choose its 
composition, in other words Δ, so that the total value of this portfolio is 
unaffected by the fluctuations of the underlying asset. This effectively means 
that Δ is chosen so that if, e.g., the fluctuations of S(t) are such that the 
value of the option rises, then the position in the underlying asset suppresses 
this rise. The choice of Δ can be made with the aid of Itö's lemma. Since 
dS(t) = ßS(t)dt + 
aS(t)dW(t), 
a straightforward application of Itö's lemma (see Proposition 2) gives us that 
cfll(t, S(t)) = &{ßS{t)dt + 
aS{t)dW{t)) 
~%dt 
+ %^S^dt 
+ °S(t)dW(t)) + 
\^a2S{tfdt, 
7This assumption can be proved using the Markov property for the Wiener process. 

202 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
where the function V and its derivatives are calculated at (t,S(t)). 
Collecting 
alike terms together we rewrite the above as 
dH(t, S(t)) = (A - ψλ 
aS(t)dW(t) 
The underbraced terms are those giving rise to the fluctuations, therefore they 
may be suppressed by choosing 
dV 
Δ = - ( ί , ^ ) ) 
for every pair (t, S(t)). These pairs may be interpreted as alternative scenaria 
for the behavior of the market. Therefore, the composition of this portfolio 
may be given by a function Δ : R+ x R —> K, which is defined by the function 
V as Δ := ^ j . With this choice the value of the portfolio changes as 
dn(t,s(t)) = - ( ^ + \ ^ < * s ® 2 ) dt 
and is not subject to the fluctuations of the underlying asset. 
Such a portfolio must therefore appreciate in value with the return of the 
riskless asset r. If this were not true then there would be opportunities for 
riskless profit in the market. Such opportunities (called arbitrage) are not 
compatible with the theory of general equilibrium. Therefore, absence of 
arbitrage gives us that 
dU = rTldt 
and upon substituting in this fundamental equation the expression for Π, dU 
and Δ we obtain that the function V must satisfy the following equation: 
dV 
dV 
1 o 2d2V 
Λτ 
η 
/ Λ Λ. 
_
+
Γ
β _ 
+ . σ 2 β » _ _ Γ ν = 0. 
(9.6) 
This is a partial differential equation of the parabolic type for the unknown 
function V, called the Black-Scholes-Merton (BSM) equation. If we manage 
to solve this equation with the final value V(T, s) — Φ(β) (and show that the 
solution has the required regularity properties), then we have completed our 
program for pricing the option. At the same time we have also managed to 
find the necessary position Δ in the underlying asset, needed by the writer 
of the option in order to make her portfolio insensitive to the fluctuations of 
the underlying assets. This is called hedging in the financial world and is a 

9.6 SOLUTION OF THE BLACK-SCHOLES-MERTON EQUATION 
203 
very important step toward the management of the risks incurring due to the 
various financial assets. 
9.6 
SOLUTION OF THE BLACK-SCHOLES-MERTON EQUATION 
Since its derivation in the 1970's many alternative ways for the resolution of 
the BSM equation have been proposed. In practice all possible methods for 
writing down explicit solutions of this equation have been tried, from integral 
transforms to semigroup methods or transformation techniques. 
It is an easy exercise in intermediate calculus to see that if V is to be 
understood as a function of r, x instead of t, s where 
S = Kexp(x), ί = Γ-Ηΐ, 
q=?L, 
(9.7) 
then U(t,x) = K~l exp(±(q - l)x + {\(q - l) 2 + q)r)V(r,x) 
solves the heat 
equation (see, e.g., Ref. [8]) 
au 
d2u 
dt ~ dx2 
with initial condition U(0,x) = Κ~λ exp(^(q— 1)χ)Φ(Κexp(x)). 
Note that in 
the new coordinates t = T corresponds to r = 0, therefore, the final condition 
of the original equation is turned to an initial condition of the transformed 
equation. This equation is well known to be solvable in terms of the integral 
formula 
1 
f°° 
U(t,x) = —j= 
t/(0,2/)exp 
dy, 
At 
which when transformed back into the original coordinates gives 
V(t,s)=-^=exp(-r(T-t)) 
ν ζ π ί 
χ ^ 
Φ (s exp (Jyr - y ) (T - t) + a j / j j x exp ( - ^ y ^ ) dy. 
Since Φ is known that is needed is to complete this integration and obtain 
the function V which is the pricing function. For certain choices of Φ this 
calculation is feasible in closed form. For example, if we wish to price a call 
option then Φ(χ) = (x — K)+ and by elementary calculus we obtain the value 

204 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
of the call option in the following form 
V(t, s) = s N(di) - Kexp(-r(T 
- t)) N(d2), 
= Hs/K) 
+ 
(r-^/2)(T-t)) 
d2 = d\ — ay/T — t, 
where N is the cumulative distribution function for the standard normal. 
Similarly, for a put option we have 
V{t, S) = -s iV(-di) + /sTexp(-r(T - *)) 
N(-d2), 
Hs/K) 
+ {r + 
a*/2){T-t)) 
dl = 
^vr=t 
' 
( 9· 9 ) 
d2 = d\— σ ν Τ - ί . 
The above formulas may be used for providing a benchmark price for these 
financial options. Futhermore, observe the connection with the Feynman-Kac 
representation. 
9.7 
FREE BOUNDARY-VALUE PROBLEMS AND VALUATION OF 
AMERICAN OPTIONS 
An important class of options are American options which differ from the 
European type that we have encountered so far by their feature that allows 
them to be exercised not only at expiry but whenever it is considered as 
suitable by the holder. Suppose that we have an American option whose payoff 
when exercised at time r is a given function of the value of the underlying at 
this time S(T), 
and let us call it Φ(τ, S(T)). 
The exact form of the function 
Φ depends on the type of the option, e.g., for a call option exercised at τ the 
payoff will be exp(—rr) (5(r) — K)+, where K is the strike of the call and 
the factor exp(—rr) corresponds to a discounting factor which transfers the 
value of the payoff which will be obtained at time r to its value at time t = 0. 
An important observation is that the time r is a random time, the holder of 
the option does not know its value beforehand and also its value depends on 
the contingencies of the market. However, it is not just any random time. It 
must have the property that the holder of the option may know whether this 
time has arrived by time t, only by her knowledge of the market by this time. 
In other words, the holder of the option may decide of when it is the best 
time to exercise the option only by her prior knowledge of what has passed 
(the history of the market) and not from any future insights concerning the 
market. This introduces the notion of the stopping time which is a very 
important notion in stochastic processes. 
The optimal time at which you should exercise the option must be a stop-
ping time, otherwise you must have access to some inside information con-

9.7 FREE BOUNDARY-VALUE PROBLEMS 
205 
cerning the market. This is not allowed in the theory since it may lead to 
arbitrage opportunities. Therefore the time r must be decided only by the 
history of the market. The answer to the question r < t must be decided for 
only by knowledge of {<S(tt), u < t} (or rather by having access to the smallest 
σ-algebra that makes these random variables measurable). 
Proposition 3 The price of the American option is given by a function V : 
K+ x R - > M+ that solves the variational inequality 
mzxi-^ 
+rs^ 
+ ^a2s2^- 
-rV,<i>(s) ~v\ 
=0. 
(9.10) 
An alternative (and more compact way) of writing this, is as a free boundary-
value problem. Define the operator £ by 
,„ \/ 
N 
du 
du 
l o o d 2 u 
,„ ., ^ 
(£«)(«,*) := -
Έ + r s - 
+ -M— 
- ru, 
(9.11) 
in terms of this operator. 
Proposition 4 Consider the solution of the free boundary-value problem 
CV = 0, V > Φ, onV 
£V<0, 
ν = Φ, 
onM.2
+\V 
where T> := {(t, s) € M+ : 0 < s < d(t)} where d is to be determined by the 
solution of the problem. Then the solution V is the pricing function and the 
optimal exercise time is the first time that the price process leaves T>. 
The above problem is called a free boundary-value problem since it is a 
boundary-value problem on a domain which is not prescribed a priori but 
is determined by the solution of the problem. It is a version of the famous 
Stefan problem which among other things determines the boundary between, 
e.g., ice and water while the ice is melting in the water. 
Free boundary-value problems cannot be solved in closed form except in 
certain very simple cases. In general they may be solved only numerically. 
Of course there is a well-developed analytical theory which provides existence 
and uniqueness results as well as important qualitative results. 
An important version of the American option is the perpetual American 
option which does not expire. Its expiration time T can be considered as 
T —» oo. For such an option the price function V will not depend on t, 
therefore we obtain the following version of the variational inequality 
Proposition 5 The price of the perpetual American option is given by a func-
tion V : M+ x R —> K+ that solves the variational inequality. 
max \rs-^- 
+ ^
2 s
2 ^ - rV, Φ(β) -V}=0. 
(9.12) 
ds2 

206 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
The following comments may clarify why the above free boundary-value 
problems may provide us with the pricing methodology for American options. 
While the American option is kept and not exercised it is equivalent to a 
European option, therefore its value is given by the same equation as that of 
a European option. Thus, in the continuation region (when the option is not 
to be exercised) we have that 
dV 
——l· CV = 0, continuation region. 
What happens when we enter the exercise region (stopping region)? Then 
in that case we expect that the value of holding the option is smaller than 
the value of exercising it, therefore, we should no longer treat the option as 
a European one since its value is now lower than that of a European option. 
How would this show in terms of the differential operator C1 To understand 
that we need to invoke a general property of parabolic equations which gives 
rise to a very useful comparison principle. 
Lemma 9.7.1 Suppose that we have two functions φι and φι, where the first 
one solves the differential equation 
9Φι , r , 
n 
whereas the second one solves 
f^<°· 
Then φι < φ\. 
Using this lemma we see that in the stopping region the value of the option 
must satisfy the differential inequality 
dV 
„ 
——l· CV < 0, stopping region. 
Indeed, consider for example the American put option. When we are in the 
stopping region, we exercise the option and V becomes V = {K — S)+. Sub-
stituting this function into the Black-Scholes operator we see that S^+CV 
= 
—rK < 0. However, the above argument holds for more general options. 
To summarize, we see that in general the value of the American option 
satisfies the differential inequality 
where the equality holds in the continuation region and the inequality holds 
in the stopping region. 

9.7 FREE BOUNDARY-VALUE PROBLEMS 
207 
The form of the stopping region depends on the particular type of option. 
For example if we consider an American put option,8 then we expect the 
holder to exercise the option whenever the price of the underlying falls below 
a given threshold s* (since then it is of benefit to the holder of the option to 
exercise and sell the underlying for K). Therefore, the continuation region 
for the American put will be the region s > s*, where of course s* is to be 
determined. For the American put its price satisfies 
— +£V = 0, 
s>s*, 
V = K-s, 
s<s*. 
How can we obtain s*? This may be obtained by the continuity property of 
the first derivative | j at s = s* (smooth pasting condition). 
We now formulate this problem as a linear complementarity problem. Re-
write the above as 
dV 
if V(t,s)>1>{s) 
— + £V = 0, 
αν(ί,3) = Φ(3) ^ + cv<o, 
where Φ(«) is the payoff the holder of the option will acquire if she chooses 
to exercise at time t when the value of the underlying is equal to s. We note 
that we may rewrite the above as an equality of the form 
dV 
\ 
- 
+ ^) (ν-Φ) = ο, 
dV 
\ 
— + CV) > 0 , 
ν - Φ > 0 . 
This formulation is very useful for the numerical solution of free boundary 
value problems. 
Further, an alternative formulation is as 
dV 
max{# - V, — + CV] = 0, 
or equivalently 
and V = Φ on dD. 
dV 
η ι ΐ η ^ - Φ , - — -£V} 
= 0, 
The American call on a non-divident paying asset is never optimal to exercise early. 

208 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
Consider the set of functions 
fC:={veC°, 
ν>Φ} 
This is a convex set. Consider any v € K. so that v — Φ > 0. Since —^-—CV > 
0 we have upon integrating that 
|(_^_ £ν) („_ Φ )>ο 
Furthermore, since (— ^ 
— CV) (V — Φ) = 0 for all i, s and integrating and 
subtracting we obtain that 
/ ( -
^--CV) 
( v - V ) > 0 , Vve/C. 
Interpreting the integral as an inner product we rewrite the problem as a 
variational inequality 
dV 
\ 
- — -CV,v-V)>0, 
VweiC. 
at 
I 
9.8 
THE HAMILTON-JACOBi-BELLMAN EQUATION 
We now consider another important class of nonlinear equations in financial 
engineering, the Hamilton-Jacobi-Bellman equations. These are fully nonlin-
ear equations in the sense that the higher derivatives of the unknown function 
appear in a highly nonlinear function. This type of equations is one of the 
most difficult partial differential equations (PDEs), however, they appear in 
a variety of applications which are related to stochastic optimal control. It 
is the aim of this section to introduce the Hamilton-Jacobi-Bellman equation 
and motivate its use in a variety of applications in mathematical finance (for 
a more thorough discussion, see Refs. [6] or [3]). 
Consider the following example to motivate the discussion. 
■ EXAMPLE 9.3 
Assume that an investor creates a portfolio which consists of the riskless 
asset B with return r, i.e., dB = rBdt and the risky asset S with drift 
μ and volatility σ, i.e., dS = ßSdt + aSdW. 
The investor's relative 
weights between these two titles at time t are denoted by ü° and ü\ 
for the riskless and risky asset, respectively, and her consumption rate 
by c(t). The value X(t) of this self-financing portfolio at time t will be 
given by the solution of the stochastic differential equation (SDE) 
dX (i) = X(t)(ü°tr + ü\ß)dt - c(t)dt + 
aü\X{t)dW{t). 

9.8 THE HAMILTON-JACOBI-BELLMAN EQUATION 
209 
We see that the portfolio's value at time t depends on the choice of 
portfolio weights and the consumption process, therefore we must recall 
at all times that X(t) = X(t,ν?,ϋ},ό). 
The portfolio weights and the 
consumption process will be called the control variables of the problem, 
while the portfolio value will be called the state variable. There is also 
a number of control constraints, which we will see below. 
Investors will choose the control processes in order to achieve a specific 
purpose. In this particular case, this purpose will be to maximize a 
utility function of intertemporary consumption and a utility function of 
the final wealth, 
J(c,x) 
: = E / 
U1(t,c(t))dt + U2(X(T)) 
Jo 
where Ui is the instantaneous utility function for consumption, whereas 
U2 is a "legacy" function which measures the utility of having a portion 
of the wealth left at the end of the period. An example of U\(t,c(t)) 
could be Ui(t,c{t)) = e~H ln(c(t)) and of U2i{X{t)) = -(X(T) 
- A)2, 
which means that the investor wants to maximize a logarithmic utility 
function of consumption discounted during the whole time period [0, T] 
and to minimize the mean quadratic distance of final wealth from a 
target A that she has set. The selection of the control variables ü°, ü1, c 
will be made so that the selected target is reached. Control variables will 
be subject to the natural constraint ü°+ü\ = 1, Vi > 0 and consumption 
must follow the condition c(t) > 0, Vt > 0. These constraints can be 
modeled geometrically, considering that the process üt — (ü°, ü\, ct) will 
belong to a set G C K3. 
The portfolio problem thus becomes 
max E 
Jo 
U1(t,c(t))dt + U2(X(T)) 
subject to 
dX (t) = X(t)(ü°tr + ü\ß)dt - c{t)dt + 
aü]X{t)dW{t), 
and X(0) = x0, ül
0 + ü\ = 1, c(i) > 0 for all t > 0. 
A problem of this kind is called a stochastic optimal control problem. In the 
next sections we will study a fairly general class of stochastic optimal control 
problems. 

210 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
Now, we will set the formal problem, stating a fairly general class of optimal 
control problems. To this end, consider the functions 
μ 
: E + x l " x R * ^ R", 
σ 
: R+ x R" x Rk -> R" x d. 
where μ(ί, χ, u) and a(t, χ, u) denote the drift and diffusion coefficient of a 
stochastic process, given that the control variable u is exerted on the system 
while being at state x and time t. For a given point XQ € R™, we will consider 
the following controlled stochastic differential equation: 
dX (t) = μ(ί, X(t), u(t))dt + a{t, X(t), u(t))dW(t), 
(9.13) 
X(0) = x0. 
(9.14) 
We view the n-dimensional process X as a state process, which we are try-
ing to "control." We can (partly) control the state process X, by choosing 
the fc-dimensional control process u in a suitable way. W is a d-dimensional 
Wiener process, and we must now try to give a precise meaning to the formal 
expressions (9.13) and (9.14). 
Our first modeling problem concerns the class of admissible control pro-
cesses. In most concrete cases it is natural to require that the control process 
u is adapted to the X process. One way to guarantee that is to assume the 
control process to be a functional of the observed values of the state process 
up to the time under consideration. A particular case of that is to assume that 
u(t) = g(t,X(t)), 
where g : R+ x Rn —» Rfc is a deterministic Borel function 
that remains to be specified. 
Such a control procedure is called a feedback control law. In the sequel we 
will restrict our attention to only such control laws. 
Suppose that we have chosen a fixed control law u, specified by u(t) = 
g(t,X(t)). 
Then we can insert u into (9.13) to obtain the standard SDE: 
dX(t) 
= 
ß(t,X(t),g(t,X(t)))dt 
+ a(t,X(t),g(t,X(t)))dW(t). 
(9.15) 
Therefore, once an appropriate feedback control law has been established, 
then the optimal path is obtained by the solution of the standard SDE. 
Definition 4 A control law called admissible 
if 
• u(t) = g(t,X(t)) 
€ U for all t € R+ and x e Rn, where U C Rk, the 
geometric set modeling the constraints. 
• For any given initial point (t,x), and for any s € [t,T\, the SDE 
dX(s) = μ(8, X(s),g(s, 
X(s)))ds + a(s,X(s),g(s, 
X(s)))dW(s), 
X{t) = x, 
has a unique solution. 

9.8 THE HAMILTON-JACOBI-BELLMAN EQUATION 
211 
The class of admissible control laws is denoted by U. 
For a given control law u we will denote the corresponding solution of (9.13) 
b y l u . 
We now go on to the objective function of the control problem, and there-
fore we consider as given a pair of functions 
C/i 
: R+ x Rn x Rfc -> R, 
U2 
: R" -> R. 
Now we define the objective function of our problem as the functional J : 
U -> R, defined by 
J{u) 
= 
E / 
U1(t,Xu(t),u(t))dt 
+ 
U2(Xu(T)) 
Jo 
where Xu is the solution to (9.13) with the given initial condition XQ = XQ. 
Thus, our formal problem can be written as that of maximizing J over all 
u £U. We define the optimal value J by 
J 
= 
sup J(u). 
u&A 
This is an optimization problem in infinite dimensions since U is a set of 
stochastic processes. If there exists an admissible control law ü with the 
property that 
J(u) 
= 
J, 
then we say that ü is an optimal control law for the given problem. Note 
that, as for any optimization problem, the optimal law may not exist, i.e. 
the supremum may not necessarily be achieved. For a given concrete control 
problem our main objective is of course to find the optimal control law (if it 
exists), show the existence of an optimal control law and then find explicitly 
or approximate its form. 
9.8.1 
The Hamilton-Jacobi-Bellman Equation 
The Hamilton-Jacobi-Bellman (HJB) equation is based on the principle of dy-
namic programming that allows us to determine the feedback law for the opti-
mal control by solving an appropriate finite dimensional optimization problem 
in lieu of the original infinite dimensional optimization problem. This leads 
to a fully nonlinear PDE, the HJB equation, the solution of which provides 
of both the value function and the optimal control law. 

212 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
To obtain a H JB equation we need to employ the embedding procedure which 
is described as follows. We choose a point t (fixed) in time, with 0 < t < T. 
We also choose a point x (fixed) in the state space, i.e., x € R™. 
Definition 5 For a fixed pair (t,x) 
as above, define the control problem 
W,x): 
maxi Et,* ί 
U1{s,Xu(s),u(s))ds 
+ U2(Xu(T)) 
) 
(9.16) 
subject to the constraints 
dXu(s) = μ (s, Xu(s), 
u(s, Xu{s))) ds + σ (s, Xu(s), u(s, Xu(s))) 
dW(s), 
Xu(s) 
= x, 
(9.17) 
where by EtjX we will denote the expectation with respect to the probability law 
defined by the process (9.17). 
Clearly the problem φ(0, XQ) corresponds to the original problem under 
consideration. If we manage to solve the general problem ^3(i, x) for every 
(t, x) 6 R+ x W1, then by substituting t = 0 and x = xo we obtain the solution 
of our original problem. We have therefore "embedded" our original problem 
into a general class of related problems. As it turns out it is simpler to solve 
the general class of problems than the specific one. 
We note that in terms of the definition above, our original problem is the 
problem ?P(0, XQ). A somewhat drastic interpretation of the problem ^3(£, x) is 
that the investor stopped keeping track of her portfolio at time zero. Suddenly 
she starts keeping track again of her portfolio, noticing that the time now is 
t and that her state process has moved to the point x. She now tries to do as 
well as possible under the circumstances, so she wants to maximize her utility 
over the remaining time, given the fact that she starts at time t in the state 
x. 
Now we define the optimal value function. 
Definition 6 The optimal value function V : R+ x R™ —> R is defined by 
V(t,x) = sup J(u), 
ueu 
on the solution of problem Vß(t,x). 
Therefore, the optimal value function gives us the optimal expected utility, 
given that we start at state x at time t. 
Our main objective is to derive a PDE for the value function V. For the 
sake of simplicity we present the derivation of the PDE in a heuristic way 
which of course can be turned into a fully rigorous mathematical argument 
under the necessary technical assumptions. 

9.8 THE HAMILTON-JACOBI-BELLMAN EQUATION 
213 
To this end, assume the existence of an optimal control law and sufficient 
regularity (at least C1'2) of the optimal function V: 
We perturb the optimal control law ü, to u*: 
(s,y) - { : 
s,y), 
(s,y)e[t,t 
+ 
h)xl 
(s,y), 
(s,y)e[t 
+ 
h,T}x 
where h is sufficiently small and u is any control. 
Clearly u* is suboptimal leading to smaller values for the expected utility 
than VL. In full analogy with Fermat's rule for maximization of real valued 
functions, as taught in first year calculus classes, in this infinite dimensional 
problem we expect the control law u to be optimal if the variation of the 
expected utility for the control laws u and any "small" 9 perturbations of ü, u*, 
vanishes. This simple observation leads to a generalization of the derivative, 
the Gateaux derivative, which allows us to define first-order conditions for 
the solution of infinite dimensional optimization problems in full analogy with 
what happens for real valued functions. 
The expected utility for the time interval [t,T], if the control procedure u* 
is adopted is given by 
E, t,x Ϊ 
U1(s,Xu'(s),u*(s))ds 
We divide the time interval [t, T] into two parts, the intervals [t, t + h) and 
(t + h,T}. 
Clearly the control u* coincides with u in the first interval and 
with the optimal control ü in the second. The expected utility, for the interval 
[t, t + h) is given by 
Et, 
rt+h 
Jt 
U1(s,Xu{s),u{s))ds 
In the interval [t + h, T] we observe that at time t+h we will be in the (stochas-
tic) state Xu(t + h). Since, by definition, we will use the optimal strategy 
during the entire interval [t + h, T] we see that the remaining expected utility 
at time t + h is given by V (t + h, Xu(t + h)). This observation follows by the 
fact that the controlled process has the markov property. Thus the expected 
utility over the interval [t + h,T], conditional on the fact that at time t we 
are in state x, is given by 
Et,x[V(t + h,Xu(t + h))]. 
In terms of the appropriate norm. 

214 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
Thus the total expected utility for the control procedure u* is 
rt+h 
It 
E, 
rt+h 
/ 
Ui(s, Xu(s), 
u{s))ds + V(t + h, Xu(t + h)) 
Clearly if u* consisted solely of ü the above expression would coincide with 
V(t, x), and since by definition the control law u is the optimal one, we have 
the inequality 
V(t,x) 
>Et, x 
/
t+h 
C/i(s, Xu(s), 
u(s))ds + V(t + h, Xu(t + h)) , (9.18) 
with equality sign if and only if u* = ü for all s € [t,T]. 
Definition 7 In what follows, we will use the notation ξη for the generator 
operator with action defined by 
n 
d 
d 
d2 
ζ^υ-ί := Ύ^μί{χ,υ)—-\J\ 
+ ^ 
^ o - i k ( x , u ) a k j ( x , u ) ^ 
^ 
Ui, 
i=\ 
% 
i,j=lk=l 
dxidxj 
where μί are the coordinates of the vector μ and σ^ are the elements of the 
matrix σ. 
Since, by assumption, V is smooth, we now use the Ito formula to obtain 
/
t+h 
VxV{s,Xu(s))audW(s) 
+ 
from which the first integral vanishes upon application of the expectation 
operator E ( x (given the assumed smoothness of the value function). We can 
then insert the resulting equation into the inequality (9.18). The term V(t, x) 
will cancel, leaving us with the inequality 
Ef,x 
rt+h 
Jt 
U,{s,Xu{s),u{s)) 
+ ^ 
{s,X"(s))+eV(s,Xu(s)) ds 
<0. 
(9.19) 
Now we divide by h, move h within the expectation and let h tend to zero. We 
further assume that u{t) can be expressed in feedback form as u(t) = g(t, X(t)) 
for a suitable deterministic function g. Assuming enough regularity to allow 
us to take the limit within the expectation, using the fundamental theorem 

9.8 THE HAMILTON-JACOBI-BELLMAN EQUATION 
215 
of integral calculus, and recalling that X(t) = x, we get 
dV 
U^t, x, ü) + -^-(t, x) + eV{t, x) < 0, 
(9.20) 
where ü denotes the value of the law u evaluated at (t,x), i.e., ü = 
g(t,x). 
Since the control law u{t) = g(t,X(t)) 
was arbitrary, this inequality will hold 
for all choices of u £ U, and we will have equality if and only if ü = g(t, x) 
where g corresponds to the optimal feedback law. We thus have the following 
equation: 
— (ί,χ) + sup {Ui(t,x,ü) 
+ξ?ν(ί,χ)} 
= 0. 
ot 
neu 
During the discussion the point (t, x) was fixed, but since it was chosen as an 
arbitrary point we see that the equation holds in fact for all (t, x) £ (0, T)xM.n. 
Thus the above equation can be considered as a PDE the solution of which 
will give us the value function. We obviously need some boundary conditions. 
One such condition is easily obtained, since we have V(t, x) = Φ(χ) for all 
x £ M.n. We have now arrived at, our goal, namely the derivation of the 
Hamilton-Jacobi-Bellman equation. 
Theorem 6 (Hamilton-Jacobi-Bellman equation) Assuming solvability 
of the optimal control problem and under sufficient regularity assumptions the 
value function V satisfies the HJB equation 
— (t,x) + sup {ΕΜί,χ,ΰ) +CV{t,x)} 
= 0, 
(9.21) 
Ct 
neu 
with final condition V(T,x) = U2(x)-
Remark 9.8.1 Note that the optimization problem in (9.21) is considered as 
a static, finite dimensional optimization problem 
We now proceed as follows: 
1. Consider the HJB equation as a PDE for an unknown function V. 
2. Fix an arbitrary point ((t, x) £ [0, Γ] x M.n and solve, for this fixed choice 
of (t,x), the static optimization problem 
max.{Ui(t,x,u) 
+ CV(t,x)} 
. 
In this problem ü is the only variable, whereas t and x are considered 
to be fixed parameters. The functions U\, μ, σ and V are considered as 
given. 
3. The optimal choice of ü, denoted by u, will of course depend on our 
choice of t and x, but it will also depend on the function V and its 

216 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
various partial derivatives (which are hiding under the sign ξ"). To 
highlight these dependencies we write ü as: 
ü = ü(t,x,V,Vx,Vxx). 
(9.22) 
4. The function u(t,x, V, Vx, Vxx) is our candidate for the optimal control 
law, but since we do not know V this description is incomplete. There-
fore we substitute the expression for ü in (9.22) into the PDE (9.21), 
giving us the PDE 
^{t,x) 
+ U?(t,x)+rV{t,x)=0, 
(9.23) 
which is to be solved with the final condition V(T, x) = Φ(χ). 
5. If we can solve the above PDE we can put the solution V into expression 
(9.22) and identify V as the optimal value function, and ü as the optimal 
control law. 
The above procedure was based on very heuristic arguments, however, it 
may be shown that under conditions it holds in a rigorous manner. An im-
portant problem concerning the HJB equation is the lack of solutions which 
are smooth enough for the above arguments to hold, except for very simple 
models. However, this difficulty can be surpassed with the notion of weak 
solutions for the HJB equation, called viscosity solutions. Most of the above 
steps can be generalized using the notion of viscosity solutions in lieu of the 
notion of classical solution. 
9.8.2 
An Explicitly Worked Example 
We will now analyze the problem introduced in Example 9.3. We first notice 
that we can get rid of the constraint ö° + ΰ\ = 1 by defining a new control 
variable w as w = ü1, and then substituting 1 — w for ü°. This gives us the 
state dynamics 
dX (t) = w(t) [μ - r] X(t)dt + (rX(t) - c(t)) dt + w(t)aX(t)dW(t), 
(9.24) 
and the corresponding HJB equation is 
9V 
(TT , 
. 
, 
,dV 
, 
,dV 
1 2 
2 2d2V\ 
n 
dt 
C>O.WCR 
dx 
dx 
2 
dx1 
c>o,t»eR 
We assume for simplicity that Ό-2 = 0 therefore this provides us with the final 
condition V(T, x) = 0. 
We now consider the case where U\ is of the form 
Ui(t,c)=e-6tc1, 

9.8 THE HAMILTON-JACOBI-BELLMAN EQUATION 
217 
where 0 < 7 < 1 and δ is a discount factor. The economic reasoning behind 
this is that we now have an infinite marginal utility at c = 0. This will force 
the optimal consumption plan to be positive throughout the planning period, 
a fact which will facilitate the analytical treatment of the problem. 
The static optimization problem to be solved with respect to c and w is 
thus that of maximizing 
e otc< + ινχ(μ - r) — + (rx - c) — + 
-xzw2a2-s-v, 
ox 
ox 
2 
ox2 
and, assuming an interior solution, the first order conditions are 
7 C T - I = e-StVx, 
(9.25) 
-
^
■
^
· 
<
^
> 
We again see that in order to implement the optimal consumption-investment 
plan (9.25) and (9.26) we need to know the optimal value function V. We 
therefore suggest a trial solution, and in view of the shape of the instantaneous 
utility function it is natural to try a solution of the form 
V(t,x) = e-Sth(t)x~<, 
(9.27) 
where, because of the final conditions, we must demand that 
h(T) = 0. 
(9.28) 
Given a V of this form we have (using · to denote the time derivative) 
O T T " 
— = eT^hx"1 - Se-^hxi, 
(9.29) 
at 
^=je-Sthxi-\ 
(9.30) 
^ 
= 7(7 - 1)β-ΛΛ*ϊ-2. 
(9.31) 
Inserting these expressions into (9.25) and (9.26) we get 
ώ(ί,χ) = ^ Π ^ ) ' 
(9·32) 
έ(ί,ι) = χΛ(*)"1/(1-7)· 
(9-33) 

218 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
This looks very promising: we see that the candidate optimal portfolio is 
constant and that the candidate optimal consumption rule is linear in the 
wealth variable. We now want to show that a function of the form (9.27) 
actually solves the HJB equation. We therefore substitute the expressions 
(9.29)-(9.33) into the HJB equation. This gives us the equation 
χΊ ih(t) + Ah(t) + £/ι(ίΓ7/(1-7)} = 0> 
where the constants A and B are given by 
_ 
Ί{μ-τ)2 
ΐΊ{μ~τ? 
g 
~ 
σ 2 ( 1 - 7 ) + 
7 
2 σ 2 ( 1 - 7 ) 
' 
B 
= 
I - 7 . 
If this equation is to hold for all x and all t, then we see that h must solve 
the Ordinary Differential Equation (ODE) 
h{t) + Ah{t) + Bhityii^-^ 
= 0, 
(9.34) 
with final condition h{T) = 0. An equation of this kind is known as a Bernoulli 
equation, and it can be solved explicitly. 
Summing up, we have shown that if we define V as in (9.27) with h defined 
as the solution to (9.34), and if we define w and c by (9.32) and (9.33), then 
V satisfies the HJB equation, and w, c attain the supremum in the equation. 
9.8.3 
Viscosity Solutions 
The HJB equation very seldom has classical solutions and even more seldom 
we may find closed-form analytic solutions. In fact the above examples are 
probably the only available examples for which a closed-form solution ex-
ists. To alleviate these difficulties a new notion of weak solutions has been 
proposed, the notion of viscosity solutions, see, e.g., Ref. [4] and references 
therein. 
The following example (taken from [2]), for simplicity illustrates this point 
in a problem similar to the HJB equation, the Hamilton-Jacobi equation, 
which is valid for the optimal control of deterministic differential equations 
(rather than Itö processes). 
■ EXAMPLE 9.4 
Assume that the state of the system is given by the equation 
dX = udt, 
u e {-1,1}, 

9.8 THE HAMILTON-JACOBI-BELLMAN EQUATION 
219 
such that X(0) = x. This can be considered as a "singular" limit of an 
Itö process with vanishing diffusion coefficient. Assume that we wish to 
minimize the functional 
/»oo 
J(x,a)= 
/ 
U(X{t),u(t))e-rtdt, 
where u(t) is the control protocol used (in this case it is a function 
consisting of alternating l's and — l's). The function U is assumed to 
depend only on x and to be smooth and symmetric around 0, and such 
that U(x) = x and xll (x) < 0 for \x\ > R. Since the minimization 
of J is equivalent to the maximization of - J we can formally write the 
HJB equation [which will now be a first-order and not a second-order 
equation as the diffusion term is missing and therefore it is called simply 
a Hamilton-Jacobi (HJ) equation] as 
rV(x) + |V"(x)|-£/(a:) = 0. 
There is no explicit time dependence in the value function and no tem-
poral derivatives in the HJ equation, since the problem is an infinite 
horizon problem. To make the link with the HJB equation we have 
studied here, simply assume the temporal dependence of the value func-
tion as V(t, x) — e~rtV{x) and substitute that in the temporal derivative 
to obtain the term rV. 
On the other hand, one may easily figure out what the optimal control 
protocol would look like. It is such that u{t) = sgn(x(t)) as long as 
i / 0 . 
At x = 0 then u(t) can either be 1 or — 1. That means the 
feedback control function at x — 0 is not single valued! This is a familiar 
phenomenon in optimal control. A quick calculation shows that the value 
function is 
V{x) 
/0°° U{x + sgn{x)t)e~rtdt, 
x φ 0, 
/0°° U(-t)e~rtdt 
= |0°° U(t)ertdt, 
x = 0. 
Clearly, the value function, though continuous, it is not differentiable at 
x = 0. That means that the Hamilton-Jacobi equation we have written 
formally above makes no sense. How can we interpret the Hamilton-
Jacobi equation so that it can be of use in situations such as the one 
presented in this example? 
A more general interpretation of the HJB equation is in terms of viscosity 
solutions. 
Definition 8 A continuous function ψ is called a viscosity sub (super)-solut-
ion of the HJB equation if for all φ € C°° 
-^(ίο,χο) 
+sup{-£u4>(t0,x0) 
- L(t0,xo,u)} 
< (>)0 

220 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
at every (to,xo) which is a local maximum (minimum) of the difference φ — φ. 
A continuous function ψ which is at the same time a viscosity sub- and 
super-solution of the HJB equation is called a viscosity solution. 
This definition is motivated by the observation that if ψ is a C1'2 solution 
of the HJB equation, then it satisfies this property. In fact it can be shown 
that the "classical" solution of the HJB equation is also a viscosity solution 
(of course this does not work the other way around). However, even if the 
value function does not have the necessary regularity so as to qualify as a 
classical solution of the HJB equation, then an application of the dynamic 
programming principle and the use of test functions φ, which are as smooth as 
possible, allow us to derive a "version" of the HJB equation, which is modified 
in the sense that all derivatives are to be calculated on the smooth test function 
rather than on the actual value function, which may not have the required 
smoothness properties. Furthermore, the terminology viscosity solutions is 
motivated by the approximation properties of such notions of solutions, for 
example, under certain conditions we add a small artificial viscosity term in 
the HJB equation and we let the magnitude of this term tend to zero, then 
the solution of the perturbed HJB equation will tend to its viscosity solution. 
As for the inequalities involved in the definition of viscosity solutions, these 
are inspired by the maximum principle that holds for parabolic operators. 
For more on these, one may consult the specialized literature on viscosity 
solutions. We simply emphasize here that the numerical treatment of HJB 
equations makes important use of the concept of viscosity solutions. 
9.9 
NUMERICAL METHODS 
In general the analytical treatment of the PDEs encountered in financial en-
gineering is not possible and it is thus necessary to obtain numerical solutions 
of the equations. In this section we present some numerical methods which 
may be used for this purpose. Since the Black-Scholes-Merton equation is re-
ducible to the heat equation, for the purpose of presentation, we will present 
the numerical methods in terms of the heat equation and leave to the reader 
the extension to more generall parabolic equations. 
9.9.1 
The Crank-Nicholson Method 
The Crank-Nicholson method is a general method for the numerical treatment 
of parabolic equations. It is a discretization method, according to which we 
calculate U(t,x) at a discrete grid in space and time, {iSt}, i = l,...,N 
and 
{jSx}, j = 1,...,M. We then identify U(iSt,j6x) 
by W. The assumption 
behind this is that the solution of the heat equation is a smooth enough 
function U so that it may be well approximated by its value at specific grid 
points. 

9.9 NUMERICAL METHODS 
221 
Using the Taylor expansion theorem we approximate the derivatives of the 
function with finite differences. For example, we approximate 
f\TT 
— 
(iSt,j6x) 
1_ 
St (u;+1 - u}) 
^(istjs^^liui-u^, 
d2U 
dx2 i6t,jSx) 
(δχ) Ψ: 
J'+1 
2U] + U]. -:)· 
It is a simple exercise in calculus (applying the Taylor expansion theorem 
with a remainder) to show that if U € C1'3 then the above approximation 
for the first derivative in time holds to order 0(6t2). 
If U € C1'3 then the 
above approximation for the first derivative in space holds to order 
0{δχ2). 
If U £ C1'4 the above approximation for the second derivative in space holds 
to order 
0(δχ2). 
If we substitute the above approximations in the heat equation this gives 
us a difference equation of the form 
m
+l 
u} = a{u;+1-2U} + u;_1), 
where a = 
st 
In this difference equation we know Uj for all j (this is 
simply our initial condition), therefore iterating in i we may obtain W for all 
i = 2,...,N. 
This difference equation is more compactly written in matrix 
form as 
Ui+1 = AU\ 
where Ü% = (U[,..., Ul
N)tT and A is the tridiagonal matrix 
/ 1 - 2a 
a 
0 
· · · 
0 
\ 
a 
0 
A = 
a 
1 
-2a 
\ 
0 
0 
0 
I-2a 
a 
a 
1 - 2Q / 
This is the simplest possible numerical method, called the explicit method, 
since knowledge of Ü1 alone provides us, upon iteration, the solution at any 
time 
Uz 
AU\ 
Ua = AZU 
2TT1 
t)N = 
AN-lÜK 

222 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
This method, even though it is simple, has certain drawbacks. One of the 
major drawbacks is regarding its stability properties, since a must be chosen 
rather small. 
An alternative method would be to approximate the heat equation as 
U)+l - U* = a (U}+\ - 2t/j + 1 + U}±\) , 
i.e., we approximate the second-order derivative in space using the value of 
the function at time i + 1 rather than with the value of the function at time i 
as we did before in the explicit method. The drawback of this method is that 
knowing Ü1 we may only find Ül+1 by solving a system of linear equations. 
For this reason this method is called the implicit method. 
Writing this equation in compact form we obtain 
Üi = 
BÜi+1, 
where 
/ l + 2a 
-a 
0 
··· 
0 
\ 
-a 
l + 2a 
'■■ 
'·■ 
: 
B= 
0 
'·· 
'·· 
' · . 
0 
: 
'·· 
'·· 
1 + 2Q 
-a 
V 
0 
· · · 
0 
-a 
1 + 2a / 
If the matrix B is invertible (which it is) then the implicit method gives 
Üi+1 = ß-1 
Ü\ 
The implicit method is unconditionally stable, in the sense that it displays 
stability properties for any value of a. 
The Crank-Nicholson method is a combination of the explicit and the im-
plicit method (see, e.g., Refs. [11], [12]). We add the implicit and explicit 
method and divide by 2, so as to approximate the solution by the mean result 
of the two methods. This yields 
UJ+1 - UJ = f (^+ι - 2Uli + UJ-I + UJXI - 2UJ+1 + uj-l) ■ 

9.9 NUMERICAL METHODS 
223 
We now write this in a more compact form using matrices. Define the 
matrices 
/ 
1 - Q 
A = 
2 
l - a 
0 
and 
B 
V 0 
/ 1+a 
-f 
"f 
1 + a 
0 
V o 
l - a 
a 
2 
0 
1 + a 
a 
2 
0 
2 
l - a 
/ 
0 
\ 
0 
a 
2 
1 + a / 
In terms of these matrices the Crank-Nicholson method assumes the compact 
form 
BU i+l _ AU\ 
(9.35) 
Iteration of (9.35) yields the solution of the heat equation at all times 
i = 2, · · · , N. 
One way of iterating is to invert the matrix B, form the 
product B~1Ä and then iterate. A better and more efficient way is to use the 
LU decomposition from numerical linear algebra. To use this method suppose 
that we known Ü1. Then by a matrix multiplication we calculate the vector 
cl := ÄÜ1. To obtain Uz+1 we must solve the system of linear equations 
BÜi+1 = c \ 
This can be done fast and efficiently using the LU decomposition. We decom-
pose B as B = LU, where L and U are lower and upper diagonal matrices, 
respectively. This requires first solving the lower diagonal system Lyx = Ü1 for 
yx and then the upper diagonal system UUi+l — yl for Ul+1. This completes 
the Crank-Nicholson method. 
A generalization of the Crank-Nicolson method is 
ψι -in 
a [Θ (U]+l -2U} + U)^) + (1 - Θ) {U)X\ - 2U}+1 + U, 
i + l I)] 
where Θ G [0,1]. In the special case where Θ = 1/2 we recover the Crank-
Nicolson method. In the case where Θ = 0 we obtain the implicit method and 
when Θ = 1 we obtain the explicit method. All other cases are in between. 
The general method may be written in compact matrix form using similar 

224 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
arguments as above, and the resolution of the problem may be provided using 
the LU decomposition. The details are left as an exercise to the interested 
reader. 
The Crank-Nicolson method may be written directly for the original form 
of the Black-Scholes equation (exercise). 
9.9.2 
Numerical Treatment of Variational Inequalities 
We now give a short introduction to the numerical treatment of variational 
inequalities, with special emphasis on the study of the pricing of American 
options. To facilitate the treatment we assume that we have transformed 
the Black-Scholes-Merton equation to the heat equation and then study the 
relevant variational inequality for the heat equation. Of course the analysis 
may go through for the original version of the Black-Scholes-Merton equation 
or any parabolic equation, but we will only sketch this in the end of the 
section. 
Applying the transformation (9.7) the variational inequality for the pricing 
of American options assumes the form 
max | φ -U,-^- 
+ C0u\ 
= 0 
or equivalently 
mm {"-*.-f-4,tf}=0, 
and U = Φ on dD, where CQ is the operator CQU = -f^r-
To solve this problem we must work with a discretized version. To this end 
we choose to use the Crank-Nicolson discretized version of the heat equation 
(9.35), which in terms of the differential inequality becomes 
B Üi+1 - Ä ΪΡ > 0, 
(9.36) 
where the inequality is to be understood componentwise. Therefore, in terms 
of the discretized approximation, the linear complementarity problem becomes 
Given cl := ÄÜ1 find the vector Ül+1 such that 
B Üi+1 - c* > 0, Üi+1 - Φ > 0, (B Üi+1 - j) (Üi+1 - Φ) = 0. 
This is repeated for alii = 2,..., N. 
This problem is far from being simple. In fact, it is an interesting problem in 
linear algebra that may be treated using an iterative algorithm, the projected 
SOR algorithm. 
We consider the auxiliary problem: 

9.9 NUMERICAL METHODS 
225 
Given a vector b, find vectors x, y such that 
Bx-y 
= b, x>0, 
y>0 
xtry = 0 
(9.37) 
This problem is equivalent to the original problem if we set x = Ul+l — Φ, 
y = B Üi+1 - c\ b = cl - ΒΦ. Then Üi+1 = x + Φ is the solution of the 
original problem. 
The auxiliary problem (9.37) is solved by the following iterative method: 
We solve the problem Bx = b by the iterative procedure 
(fe) 
(fe-1) , 
c) = x) 
+ω 
„(fc) 
bu 
e-i 
M 
rf 
= be - y ^ atjX) 
- buxf 
x) + ^ 
bijx) 
(fc-l) 
i=i 
j=e+i 
where ω is a relaxation parameter which is chosen by the user for the best 
convergence of the method. The iterative method starts with an initial choice 
χ(°) > 0 and continues trying to ensure that x^ 
> 0 at all levels of the 
iteration. This is effected by modifying the SOR algorithm so that 
(fc) 
in 
(fc-!) , 
Te I 
x\ ' = max < 0, x\ 
+ ω-τ— > , 
e-i 
M 
rf] = be -^atjx^ 
- beexf_1) 
+ J^ btixf~l). 
j=i 
j=e+i 
We then need to find the vector y. This is done as follows 
(fe) 
(fe) . , 
/ (fc) 
(fe-l)\ 
VI =-r\ 
'+bu(x\ 
-x] 
')■ 
Undoing the transformations we obtain the solution to the original problem. 
9.9.3 
Numerical Treatment of HJB Equations 
The numerical treatment of the HJB equation is a very interesting but also 
complicated task, due to the high nonlinearity of the equation. One of the 
most important methods for the resolution of such equations is through the 
use of viscosity solutions; we refer the interested reader to the relevant lit-
erature (see, e.g., the appendix by Falcone in Ref. [2], or Refs. [10], [7] for 
some applications and references therein). Other methods are through the 
discretization of the Itö equation to a Markov chain and the use of dynamic 
programming techniques for the approximation of the value function and the 
optimal control (see, e.g., [9] and references therein). 

226 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
9.10 
CONCLUSION 
In this chapter we have tried to present a brief introduction to the use of par-
tial differential equations, linear and nonlinear, in financial engineering. We 
have tried to motivate their use through a simple yet fundamental model in 
financial mathematics, the Black-Scholes model, and have presented how this 
model leads in a natural way to a linear parabolic PDE, the Black-Scholes 
equation. The solution of this equation provides a way of pricing a deriva-
tive asset, given the current value of the fundamental asset this derivative is 
based on. We have then introduced stopping problems related to the pricing 
of American-type derivative assets and have shown how these lead to free 
boundary-value problems, introducing in this manner the concept of varia-
tional inequality which is very useful in a number of problems of financial 
engineering. We then moved to fully nonlinear PDEs that were motivated 
by their occurrence in optimal control problems when treated through dy-
namic programming. We have shown how the treatment of optimal control 
problems may lead to the Hamilton-Jacobi-Bellman equation for the value 
function, which is a fully nonlinear second-order PDE. After providing some 
examples in which the HJB admits solutions in closed form, we consider the 
case of weak solutions, called viscosity solutions, which are more widely ap-
plicable and furthermore are important to numerical applications. We close 
the chapter with an introduction to the numerical treatment of PDEs arising 
in financial mathematics, including variational inequalities. 
Needless to say, there are many important aspects of the theory that were 
not possible to be included in this chapter for lack of space. To mention 
just a few; the problem of pricing and hedging derivatives in incomplete mar-
kets has been and remains a problem of fundamental importance (see Ref. 
[6] for an excellent treatment; see also Ref. [14] for an alternative approach 
and references therein). There are also important applications of this basic 
methodology presented here to other types of assets, e.g., energy derivatives 
(see, e.g., Ref. [13] and references therein), insurance or reinsurance model-
ing (see, e.g., Ref. [1] and references therein), etc. However, we hope that 
this very brief first encounter will motivate some of the readers of the present 
volume to further explore the exciting fields of stochastic analysis and its con-
nections with applied mathematics, as well as stochastic control theory and 
mathematical finance. 
EXERCISES 
9.1 
Apply Itö's lemma to show that the solution of the SDE dS = μβάί + 
aSdW with initial condition S(0) = s is the stochastic exponential 
2 
S(t) = sexp^-^y 
+ aW(t)). 

EXERCISES 
227 
9.2 
Complete the integrations involved in the derivation of the pricing for-
mulae for the put and the call options and verify the stated results. 
9.3 
Verify that the Black-Scholes-Merton equation can be reduced to the 
heat equation with the stated coordinate change. 
9.4 
Using the properties of the Wiener process or of the Itö integral calculate 
the first two statistical moments of 
S(t). 
9.5 
Write down the HJB equation for the portfolio optimization example if 
the utility function U\{c) = e~St lnc and try to find a solution. 
REFERENCES 
1. Baltas, I., Prangos, N. E. and Yannacopoulos, A. N., Optimal reinvestment and 
reinsurance policies in insurance markets under the effect of inside information, 
Applied Stochastic Models in Business and Industry, Vol. 27, 203-217 (2011). 
2. Bardi, M. and Capuzzo-Dolcetta, I. Optimal Control and Viscosity Solutions of 
Hamilton-Jacobi-Bellman 
Equations, Birkäuser, Boston (1997). 
3. Björk, T., Arbitrage theory in continuous time, Oxford University Press, Oxford 
(1999). 
4. Bardi, M., Crandall, M. G., Evans, L. C , Soner, H. M., and Souganidis, P. E., 
Viscosity Solutions and Applications, Lecture Notes in Mathematics, Volume 
1660, Springer (1997). 
5. Karatzas, I. and Shreve, S., Brownian motion and Stochastic Calculus, 2nd Ed., 
Springer, Berlin (1991). 
6. Karatzas, I. and Shreve, S., Methods of Mathematical Finance, Springer, Berlin 
(1998). 
7. Kossioris, G., Plexousakis, M., and Yannacopoulos, A. N., A Hamilton-Jacobi-
Belman approach to the control of trapping time of a soliton in an external 
potential, Quarterly of Applied Mathematics 63, no. 2, 309-324 (2005). 
8. Kreyszig, E., Advanced Engineering Mathematics, 6th Edition, Wiley & Sons, 
New York (1988). 
9. Kushner, H. P., and Dupuis, P. G., Numerical Methods for Stochastic Control 
Problems in Continuous Time, Springer, New York (2000). 
10. Nikolopoulos, C. and Yannacopoulos, A. N., A model for optimal stopping in 
advertisement, Nonlinear Analysis: Real World Applications, Vol. 11, 1129-
1242 (2010). 
11. Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P., Numerical 
Recipes in C++: The Art of Scientific Computing, 2nd Edition, Cambridge 
University Press, Cambridge (2002). 
12. Smith, G. D., Numerical Solution of Partial Differential Equations, Oxford Uni-
versity Press, Oxford (1974). 

228 
CHAPTER 9. PARABOLIC PDEs IN FINANCIAL ENGINEERING 
13. Tsitakis, D., Xanthopoulos, S., and Yannacopoulos, A. N., A closed form solu-
tion for the price of cross commodity electricity derivatives, Physica A: Econo-
physics Section, Vol. 371, 543-551 (2006). 
14. Xanthopoulos, S. and Yannacopoulos, A. N., Scenarios for price determina-
tion in incomplete markets, International Journal of Theoretical and Applied 
Finance, Vol. 11, 415-445 (2008). 

CHAPTER 10 
DECISION MODELING IN SUPPLY CHAIN 
MANAGEMENT 
HUAJUN TANG 
Faculty of Management and Administration, Macau University of Science and Tech-
nology, Macau 
10.1 
INTRODUCTION TO DECISION MODELING 
10.1.1 The Origin of Decision Modeling 
Decision modeling has been widely used since Fredrick W. Taylor, in the early 
1900's, applied the principles of the scientific approach to management. Dur-
ing World War II, numerous novel quantitative and scientific methods were 
developed to support the military. These new developments became so suc-
cessful that many companies started to apply similar methods in managerial 
decision making and planning after World War II. Recently, more and more 
companies recruit staffs in the field of operations research or management 
Mathematical Modeling with Multidisciplinary Applications.
 
229 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

230 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
science to use the principles of scientific management to solve real business 
problems. 
10.1.2 
Definition of Decision Modeling 
There are varying definitions for decision modeling. Here it is defined as a 
scientific approach to managerial decision making. Decision modeling is also 
usually referred to as operations research, management science or quantitative 
analysis. In this chapter, we adopt the term decision modeling since we will 
discuss some modeling techniques in a managerial decision making context. 
10.1.3 
Data in Decision Modeling 
Any decision modeling process begins with data. Like raw materials for a 
manufacturer, these data are processed into information, which is important to 
the decision making. The processing of raw data into meaningful information 
is the heart of decision modeling. 
In dealing with a decision-making problem, managers would have to con-
sider both qualitative and quantitative factors. For instance, suppose that we 
are considering supplier alternatives of CPU products, such as Intel, AMD, 
and IBM. We can use quantitative factors such as price, capacity, and trans-
portation cost in our decision model to assist our ultimate decision. However, 
in addition to these factors, we may also have to consider qualitative factors 
such as quality, lead time, and credit. It could be difficult to quantify these 
qualitative factors. 
Because of the presence of qualitative factors, quantitative decision model-
ing can play different roles in the decision-making process. When the problem, 
model and input data remain stable over time without qualitative factors, a 
decision model can make the decision-making process automatic. For instance, 
some corporations use quantitative inventory models to determine automati-
cally when to order and how much to order. However, in most cases, decision 
modeling would be only one of several aids to the decision-making process. 
The outputs of decision modeling should be combined with qualitative infor-
mation while making decisions in reality. 
10.1.4 
Role of Spreadsheets in Decision Modeling 
To keep with the fast development of technology in the last three decades, 
computers have become a fundamental part of the decision modeling process 
in today's business environments. Until 1990's, many modeling techniques 
discussed in this chapter required specialized software packages. However, 
widely available spreadsheet packages such as Microsoft Excel have been in-
creasingly used to set up and solve most of the decision modeling techniques 
in practical situations. Hence the current trend in many university courses 
in decision modeling focuses on spreadsheet-based instruction. In keeping 

10.1 INTRODUCTION TO DECISION MODELING 
231 
with this trend, we will discuss the role and use of spreadsheets (specifically 
Microsoft Excel's Solver add-in) during the study of the different decision 
modeling techniques in this chapter. 
10.1.5 
Types of Decision Models 
According to the type and nature of the problem environment under consider-
ation, decision models can be classified into two components: (1) deterministic 
models and (2) probabilistic models. In the following we define each of these 
two types of models. 
Deterministic models assume that all the relevant input data are known 
with certainty. That is to say, all the information related to modeling the 
decision-making problem environment is available, with known values. For 
example, ABC corporation manufactures several different types of PC prod-
ucts (e.g., desktops, laptops), all of which compete for the same resources 
(e.g., hard disks, chips, labor). Suppose ABC knows the specific amounts of 
each resource required to make one unit of each type of PC. In such an envi-
ronment, if ABC determines a specific production plan, it is easy to compute 
the quantity required of each resource to satisfy this production plan. For 
instance, if ABC plans to ship 2,000 units of a specific model and each unit 
includes two speakers, then ABC will need 4,000 speakers. Perhaps the most 
common and popular deterministic modeling technique is linear programming 
(LP). In this chapter, most of the models can be set up and solved by LP. 
Compared to deterministic models, probabilistic models assume that some 
input data are not known with certainty. That is to say, the values of some 
important variables will not be known before decisions are made. Hence it is 
important to incorporate this uncertainty into the model. An example of this 
type of model would be the decision of when to order and how many CPU 
products to order when ABC managers face random demand. Probabilistic 
modeling techniques take uncertainty into account by using probabilities on 
these random variables. Because of space limit, we mainly focus on determin-
istic models in this chapter. 
10.1.6 
Steps of Decision Modeling 
Regardless of the size and complexity of the decision-making problem at hand, 
the decision modeling process involves three distinct steps: (1) formulation, 
(2) solution, and (3) interpretation. Figure 10.1 (Balakrishnan et al., 2007) 
provides a schematic overview of these steps along with the components of 
each step. In the following we will discuss each of these steps. 
It is fundamental to recognize that an iterative process (shown as dotted 
lines in Figure 10.1) usually occurs between these three steps before the final 
solution is obtained. For instance, during the solution step it may be realized 
that the model is incomplete or that some of the input data are erroneous. 

232 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
Formulation 
Solution 
p 
* 
Interpretation 
Defining 
thp PiQ,t>lem__ | 
Developing 
L 
a Model 
| 
Acquinm· 
Input Data 
• 
Develop nm 
d Solution 
1 
» 
Testing 
theSuluiiun 
1 
. i 
Anal\ /lag. Result!) 
and Sensitiv il\ 
j
— 
J 
Anah Mt 
1 
Implemenung 
the Rosulis 
Figure 10.1 The decision modeling process. 
This suggests that the formulation needs to be modified, which causes all of 
the subsequent steps to be changed. 
Formulation is the process by which each of the problem scenario is trans-
lated and expressed in terms of a mathematical model. This is perhaps the 
most important and challenging step in decision modeling. Since the results 
of a posed built problem will certainly be wrong, it is important for the de-
cision maker to analyze the problem rationally. The objective in formulation 
is to ensure that the mathematical model completely presents all the issues 
that are relevant with respect to the problem. Formulation can be divided 
into three components: (a) defining the problem, (b) developing a model, (c) 
acquiring input data. 
Defining the problem, which means the development of a clear, concise de-
scription of the problem, can be the most important part of formulation. This 
description will give direction and meaning to all the parts following it. Once 
we define the problem to be analyzed, the next part is to develop a decision 
model. The models we develop in this chapter are mathematical. A math-
ematical model is a set of mathematical relationships. In most cases, these 
relationships are expressed as equations, and inequalities. All models should 
be built carefully. They must be solvable, realistic, and easy to understand 
and modify, and the input data should be available. Once we have developed 
a model, we must obtain the input data to be used in the model. It is nee-

10.1 INTRODUCTION TO DECISION MODELING 
233 
essary to obtain accurate data, since incorrect data may result in misleading 
decisions, even if the model is an excellent presentation of reality. 
The Solution step is to identify the optimal solution by solving the math-
ematical expressions resulting from the formulation step. The solution step 
could be further classified into two components: (a) developing a solution and 
(b) testing the solution. 
Developing a solution focuses on processing the model to arrive at the best 
solution to the problem. In some cases, we may find the optimal solution 
by applying a systematic algorithm to solve a set of mathematical expres-
sions. In other cases, we could use a trial and error method to find the best 
decision among a set of alternatives. Before a solution can be analyzed and 
implemented, it must be tested completely. As we know, the solution depends 
on the input data and the model, both of which require testing. There exist 
ways to test the data. One is to collect additional data from a different sample 
source and use statistical tests to contrast these new data with the original 
data. If there are significant differences, we should make more efforts to ob-
tain accurate input data. If the data are accurate but the model's outputs 
are not consistent with the problem, we have to modify the model to make 
sure that it is logical and represents the real situation. 
Supposing that the formulation is correct and has been successfully carried 
out and solved, we have to consider the implications of the results. We will 
discuss this step in two parts: (a) analyzing the results and their sensitivity 
analysis and (b) implementing the results. Analyzing the results starts with 
determining the implications of the solution. In most cases, a solution to the 
problem will lead to some changes in the way a company is operating. The 
implications of these changes must be determined and analyzed before the 
results are implemented. Considering that a model is only an approximation 
of reality, the sensitivity of the solution to changes in the model and input data 
is an important issue of analyzing the results. This type of analysis is called 
sensitivity analysis. Sensitivity analysis identifies how much the solution will 
vary if there are changes in the model or the input data. If the optimal 
solution is very sensitive to changes in the input data and the model, then 
additional testing must be performed to make sure that the model and input 
data are valid. 
The final part is to implement the results. This could be much more difficult 
than you might imagine. You need to be able to present and explain the results 
of your study to management. If the manager rejects the new solution, the 
model is of no value, even if the optimal solution might have results in millions 
of dollars in additional profits. If and when the new solution is implemented, 
the supply chain should be closely monitored. 

234 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
10.2 
MATHEMATICAL PROGRAMMING MODELS 
10.2.1 
Introduction of Linear Programming Models 
Since the mid-twentieth century, linear programming (LP) has been applied 
extensively to typical problems in supply chain management such as manu-
facturing, transportation, scheduling, assignment, and operational problems. 
Regardless of the size and the complexity of the decision-making problem 
in these applications, the development of all LP models can be divided into 
three distinct steps as defined above: (1) formulation, (2) solution, and (3) 
interpretation. We now briefly discuss each step with respect to LP models. 
Formulation is the process by which each aspect of the problem scenario is 
expressed in terms of mathematical expressions. The aim is to make sure 
that the set of mathematical expressions present all the issues relevant to the 
problem. The solution step is to solve the mathematical expressions resulting 
from the formulation process to identify an optimal solution. In this chapter 
we mainly focus on solving LP models and other mathematical programming 
models with spreadsheets. Supposing that the formulation is correct and can 
be solved with an LP software package, the manager can carry out a sensitiv-
ity analysis by using the software to evaluate the impact of several different 
types of what-if questions. 
10.2.2 
Properties of a Linear Programming Model 
All LP models have some common properties as listed below. 
1. All problems aim to maximize or minimize some quantity, usually profit 
or cost, which is refereed to as the objective function of an LP problem. 
For instance, a typical manufacturer usually seeks to maximize profits. 
In a trucking distribution system, the objective could be to minimize 
shipping costs. 
2. There are usually some constraints on the allowable values of variables in 
LP models. For instance, we are restricted by the available raw materials 
and machinery time when we try to decide how many units of each 
product in a company's product line should be produced. Furthermore, 
LP models usually include a set of constraints known as nonnegativity 
constraints, which make sure that the variables in the model take on 
only nonnegative values. This is feasible and reasonable since negative 
values of physical quantities are impossible, and we cannot produce a 
negative number of computers. 
3. There must be alternatives among which we can choose. For example, if 
a factory produces three different products, the manager could use LP to 
decide how to allocate his limited production resources (e.g., labor and 
machine hours, raw material) among these products. Should it devote 

10.2 MATHEMATICAL PROGRAMMING MODELS 
235 
all manufacturing capacity to only the first product, or equal amounts 
to each product, or some other ratios. If there are no alternatives to 
select from, we do not have a decision problem and do not need LP. 
4. The objective and constraints in LP models must be expressed in terms 
of linear functions of the variables. This means that all terms in the 
objective function and in the constraint equations and inequalities are 
of the first degree. Hence the equation A + B = 10 is a valid linear 
equation, while the equation A2 + B + C = 10 is not linear because the 
variable A is squared. Examples of linear inequalities are A + B < C or 
A + B > C. 
One example of LP models is presented in the following. 
■ EXAMPLE 10.1 
This LP model is to maximize the objective function subject to some 
constraints. 
Maximized 
= 
10A + 5B, 
(10.1) 
subject to 
4A + 3B 
< 200, 
2A + B 
> 60, 
A, B 
> 0. 
The constraint A, B > 0 (the notation means "A > 0 and B > 0") is called a 
non-negative constraint. 
10.2.3 
Assumptions of a Linear Programming Model 
Technically, there are four basic assumptions in an LP model. These are listed 
below. 
1. Certainty. Numbers used in the objective function and constraints are 
known with certainty and do not change during the period being studied. 
2. There exists proportionality in the objective function and constraints. 
For instance, if the production of 1 unit of a product need 4 labor hours, 
then making 10 units of that product should need 40 labor hours. 
3. Additivity. The total of all the activities equals the sum of the individual 
activities. For instance, when the profit is $10 per unit of the first 
product and $5 per unit of the second product, and 1 unit of each 
product is manufactured, then the resulting profit should $15. 
4. Divisibility. The solutions need not necessarily be in integers. That is, 
they could take any fractional (i.e., real-number) value. 

236 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
10.2.4 
Other Mathematical Programming Models 
The LP models discussed above have three characteristics: 
(1) the decision variables are allowed to have fractional values, 
(2) there is a single objective function, and 
(3) all expressions (objective function and constraints) are linear. 
However, there exist other important mathematical programming models 
that relax these LP conditions: integer programming (IP), goal programming 
(GP), and nonlinear programming (NLP). 
Integer programming is the extension of LP that deals with problems requir-
ing integer solutions, and has two types of variables: general integer variables 
and binary variables. General integer variables are those taking on any non-
negative integer values. Binary variables are a special type of integer variables 
taking values 0 or 1. IP problems can be classified into four types as below. 
1. Pure IP problems are problems in which all decision variables must have 
integer values. 
2. Mixed IP problems are problems in which some, but not all, decision 
variables must have integer values. The noninteger variable could have 
fractional values. 
3. Pure binary IP problems are problems in which all decision variables are 
binary. 
4. Mixed binary IP problems are problems in which some decision variables 
are binary and other decision variables are either general integers or 
continuous values. 
Goal programming considers optimization problems having several objec-
tive functions, instead of forcing the decision maker to focus on only a single 
objective as in LP. Nonlinear programming is the extension of LP to problems 
in which the objective or the constraints are nonlinear. For example, if the 
objective function in (10.1) is changed to be Z = 10A + 5B2, then the model 
is a nonlinear programming model. 
In the following, we briefly introduce the discipline of supply chain manage-
ment (SCM), and then apply the above mathematical programming models, 
especially LP models, to deal with typical problems in SCM. 
10.3 
INTRODUCTION OF SUPPLY CHAIN MANAGEMENT 
A supply chain is the flow of products and services from raw material man-
ufacturers to intermediate product manufacturers, end product manufactur-
ers, wholesalers, distributors, and retailers. The supply chain is connected 
by transportation and storage activities, and integrated through information, 
planning and integration activities. Supply chain management is a set of 

10.3 INTRODUCTION OF SUPPLY CHAIN MANAGEMENT 
237 
Figure 10.2 
One Example of the Supply Chain 
approaches to efficiently integrate suppliers, manufacturers, warehouses, and 
stores, so that commodities are produced and distributed at the right quanti-
ties in the right locations at the right time. One example of the supply chain 
is presented in Figure 10.2 . 
Supply chain management was first proposed by a U.S. industry consultant 
in the early 1980's, and developed through the 1990's with the introduction 
of electronic data interchange (EDI), and enterprise resource planning (ERP) 
systems. It developed in the 21st century with the expansion of Internet-
based collaborative systems over national boundaries. In the 1990's, indus-
tries began to focus on core competencies and adopted a specialization model. 
Companies abandoned vertical integration, sold off non-core operations, and 
outsourced those functions to third-party companies. This led to the rise of 
companies specializing in outsourced manufacturing and distribution. 
10.3.1 
Importance of Supply Chain Management 
During the past decades, globalization, outsourcing and information tech-
nology have enabled many organizations, such as Dell, Hewlett Packard, 
and Wall-mark to successfully operate solid collaborative supply networks, 
in which each specialized business partner focuses on only a few key strategic 
activities. This inter-organizational supply network can be acknowledged as 
a new form of organization. Traditionally, companies in a supply network 
concentrate on the inputs and outputs of the processes, with little concern 
for the internal management of other individual co-operators. In the 21st 
century, two changes in the business environment have contributed to the de-
velopment of supply chain networks. Firstly, as an outcome of globalization 
and the proliferation of multinational companies, joint ventures, strategic al-
liances and business partnerships, significant success factors were identified, 
complementing the earlier "Just-In-Time," "Lean Manufacturing" and "Ag-
ile Manufacturing" practices. Secondly, technological changes, particularly 
the dramatic fall in information communication costs, which are a significant 

238 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
component of transaction costs, have led to changes in coordination among 
the members of the supply chain network. 
10.3.2 
Activities in Supply Chain Management 
Supply chain activities can be grouped into strategic, tactical, and operational 
levels. We present them as below. 
The strategic level usually covers the following activities: strategic network 
optimization, including the number, location, and size of warehousing, distri-
bution centers, and facilities; strategic partnerships with suppliers, distribu-
tors, and customers, creating communication channels for critical information 
and operational improvements such as cross docking, direct shipping, and 
third-party logistics; product life cycle management, so that new and exist-
ing products can be optimally integrated into the supply chain and capacity 
management activities; and where-to-make and make-or-buy decisions. 
The tactical level often includes: sourcing contracts and other purchasing 
decisions; production decisions, including contracting, scheduling, and plan-
ning process definition; inventory decisions, including quantity, location, and 
quality of inventory; and transportation strategy, including frequency, routes, 
and contracting. 
Operational level usually covers: daily production and distribution plan-
ning, including all nodes in the supply chain; production scheduling for each 
manufacturing facility in the supply chain; sourcing planning, including cur-
rent inventory and forecast demand, in collaboration with all suppliers; in-
bound operations, including transportation from suppliers and receiving in-
ventory; production operations, including the consumption of materials and 
flow of finished goods; outbound operations, including all fulfillment activi-
ties, warehousing and transportation to customers; and order promising, in-
cluding all suppliers, manufacturing facilities, distribution centers, and other 
customers. 
In the following, we apply LP and other mathematical programming mod-
els with spreadsheet to investigate some typical problems in supply chain 
managment. 
10.4 
APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
10.4.1 
Manufacturing Applications 
Manufacturing issues are the most common and important in supply chain 
management, because they impact on the later activities, such as transporta-
tion, inventory management, and final marketing. 
10.4.1.1 
Product Mix Problem A popular use of an LP is to solve product 
mix problems. Most corporations have to meet a number of constraints, rang-
ing from financial concerns to sales demands to material contracts to union 

10.4 APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
239 
labor demands. The corporation's primary goal is to generate the largest 
profit possible. In the following we consider a simple product mix problem. 
Prada corporation, a manufacturer of women's-wear, produces four types 
of skirts. One is an expensive, all-silk skirt, one is an all-polyester skirt, and 
two are "blends" made of pieces of polyester and cotton. Table 10.1 illustrates 
the cost and availability (per monthly production period) of three materials 
used in the production process. In addition, the labor cost is $0.80 per skirt. 
The company has fixed contracts with several major department store chains 
Table 10.1 
The cost and availability of the three materials. 
Material 
Silk 
Polyester 
Cotton 
Cost Per Yard ($) 
18 
9 
12 
Material Available Per Month (Yards) 
780 
2,800 
1,600 
to supply skirts. The contracts require that Prada supply a minimum and 
a maximum of monthly quantity of each skirt. Table 10.2 summarizes the 
contract information for each of the four styles of skirts, the selling price per 
skirt, and the fabric requirements of each skirt. Prada's goal is to maximize 
Table 10.2 
Product data for Prada skirt. 
Variety 
of skirt 
All silk 
All polyester 
Poly-cotton 
blend 1 
Sellin 
price 
skirt 
7.80 
4.25 
5.20 
per 
($) 
Monthly 
minimum 
6,000 
11,500 
13,000 
Monthly 
maximum 
7,000 
15,000 
17,000 
Material 
per skirt 
(Yards) 
0.12 
0.09 
0.12 
Material 
Requirements 
100% silk 
100% polyester 
50% polyester-
50% cotton 
Poly-cotton 
5.80 
6,500 
8,800 
0.10 
30% polyester-
blend 2 
70% cotton 

240 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
its monthly profit. It must decide upon a policy for product mix. Let 
5 
= 
number of all-silk skirts produced per month 
P 
= 
number of polyester skirts produced per month 
B\ 
= 
number of blend 1 poly-cotton skirts produced per month 
i?2 
= 
number of blend 2 poly-cotton skirts produced per month 
To determine the objective function, the unit profits must be first calculated. 
We illustrate the net profit calculation for all-silk skirts (5). Each all-silk skirt 
requires 0.12 yards of silk at a cost of $18 per yard, resulting in a material cost 
of $2.16. The selling price per all-silk skirt is $7.80, leading to a net profit of 
$7.80 - $2.16 - $0.80 = $4.84 per skirt. Similarly, we find that the remain net 
unit profits are $2.64, $3.14, and $3.89, for all-polyester, poly-cotton blend 1, 
and poly-cotton blend 2 skirts, respectively. 
The objective function could be presented as 
$4,845 + S2.64P + $3.14Bi + $3,895^10.2) 
780 (yards of silk), 
0.09P + O.O6.B1 + 0.03ß2 
< 
2,800 (yards of polyester), 
1,600 (yards of cotton), 
7,000 (min. and max. of all silk), 
15,000 (min. and max. of all polyester), 
17,000 (min. and max. of blend 1), 
8,800 (min. and max. of blend 2), 
0 (non-negativity). 
In implementing the model in Excel, we have split the objective function 
into three components: a revenue components, a labor cost component and a 
material cost component. The Excel layout and Solver entries for this model 
are shown in Figure 10.3. Cell F5 defines the revenue component, cells F6 
and F7 define the labor cost and material cost components. Cell F8 is the 
difference between cell F5 and the sum of cells F6 and F7. Figure 10.3 shows 
that the optimal solution is to produce 6,500 all-silk skirts, 15,000 all-polyester 
skirts, 16,400 poly-cotton blend 1 skirts, and 8,800 poly-cotton blend 2 skirts. 
This results in a total revenue of $250,770 and a net profit of $156,788. 
10.4.1.2 
Make-Or-Buy Decision Problem In make-or-buy decision problems, 
a company manager could satisfy the demand for a product by making some 
of it in-house and by outsourcing the remainder to another company. For each 
product, the manager needs to determine how much of the product to make 
in-house and how much of it to outsource to another firm. Let's continue the 
product-mix problem in Section 10.4.1.1. Now the Prada manager would like 
Maximize profit 
subject to 
0.125 
0.06Bi + 0.03ß2 
0.06ßi + 0.07ß2 
6,000 
< 
5 
11,500 
< 
P 
13,000 
< 
£i 
6,500 
< 
B2 
S, P, B\, E>2 
= 
< 
< 
< 
< 
< 
< 
< 
> 

10.4 APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
241 
1 
2 
3 
4 
5 
6 
7 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
26 
29 
30 
31 
32 
!< 
Prada Skirt 
Number of units 
Selling price 
.abor cost 
Material cost 
3rofit 
Constraints: 
Yards of silk 
Yards of polyester 
Yards of cotton 
Maximum all silk 
Maximum all poly 
Maximum blend-1 
Maximum blend-2 
Vlinimum all silk 
vlmimum all poly 
Minimum blend-1 
Minimum blend-2 
R I 
s 
All silk 
6500.0; 
$7 80 
S06O 
$2.16 ■ 
$4.64 
0.12 
1 
1 
c 
P 
All poly 
15000 0 
$4.25 
$0.80 
$081 
$2.64 
0.09 
1 
1 
n 
Bi 
Blend-1 
16400.0 
$5.20 
$0.80 
$1.26 
$3.14 
0.06 
0.06 
1 
1 
F 
B, 
Blend-2 
68000 
1580 
1080 
J1.11 
S3 89 
003 
0 07 
1 
1 
StfTwgetCel: 
|*F*8 
Equal To; 
. ® g £ [ 
Q l ^ 
By Change Cefc-
|$β*:*Ε*4 
Su>ject to the GonstraMS! 
jtF$10:tF$16<-tHilO:tH(16 
; tF$17:$F$20>-$Htl7:iH*2u 
N 
to of; 
N 
1 
m?&m G I 
H 
$250 770 00 
$37 36000 
$56 622 00 
$156 788 0C 
<--Revenue 
<-Labor Cost 
<-Material C 
*-Objective 
780 00 
<= 
780 
2596 00 
<= 
2800 
1600 00 
<= 
1600 
6500 00 
<= 
7000 
15000 00 
<= 
15000 
16400 00 
<= 
17000 
8800 00 
<= 
8800 
6500 00 
>= 
6000 
1500000 
>= 
11500 
16400 00 
>= 
13000 
8800 00 
>= 
6500 
LHS 
Sign* 
— 
t if** ) 
J 
| Λ» 
| 
I 
&«** 1 
■- ' · ; | earns 
I 
1 * w ] 
RHS 
1 
Mt 
CMfYd 
$18 
$9 
$12 
Figure 10.3 
Excel layout and solver entries for Prada skirt. 
Table 10.3 
Outsourcing price from Skirt unlimited 
Variety of skirt 
Outsourcing price 
All Silk 
$4.20 
All Polyester 
$1.60 
Blend 1 
$2.10 
Blend 2 
$2.20 
to consider the make-or-buy decision, that is, satisfy the demand by making 
some of it in house and by outsourcing the remainder to another corporation, 
named Skirt Unlimited. Skirt Unlimited would sell skirts to Prada with the 
price information in Table 10.3. 
To build a make-or-buy decision model, in addition to the variables defined 
in Section 10.4.1.1, we should define some additional variables as below. 
SO 
= 
number of all-silk skirts to buy per month 
P0 
= 
number of polyester skirts to buy per month 
Bio 
= 
number of blend 1 poly-cotton skirts to buy per month 
B20 — number of blend 2 poly-cotton skirts to buy per month 
Then the objective function is to maximize profit=revenue-labor cost-material 
cost-outsourcing cost, in which revenue = $7.80(5 + S0) + $4.25(P + P0) + 
$5.20(ßi + Βίο) + $5.80(£2 + B2o), labor cost = $0.80(5 + P + Bi + B2), 
material cost = $2.165+$0.81P+$1.26ßi + $l.llS 2, and Outsourcing cost = 

242 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
$4.20So + $1.60Po + $2.10Bio + $2.20B2o- Hence the model could be stated 
as follows. 
Maximize profit 
= 
$4,845 + S2.64P + $3.145i + $3.89_B2 
+$3.60So + $2.65P0 + $3.10ßio + $3.60B2o 
subject to 
0.125 
0.09P + 0.06B! + 0.03P2 
0.06^! + 0.07Ö2 
s + s0 
P + Po 
B\ + B\0 
J32 + B20 
So, P, Po, Βχ,Βΐο, ß 2, ß 2 o 
< 
< 
< 
< 
< 
< 
< 
> 
780 (yards of silk), 
2,800 (yards of polyester), 
1,600 (yards of cotton), 
7,000 (demand of all silk), 
15,000 (demand of all polyester), 
17,000 (demand of blend 1), 
8,800 (demand of blend 2), 
0 (non-negativity). 
The Excel layout and Solver entries for the make-or-buy decision model is 
shown in Figure 10.4. As we can see, the optimal solution is to produce 
6,500 all-silk skirts, 16,400 poly-cotton blend 1 skirts, and 8,800 poly-cotton 
blend 2 skirts; buy 500 all-silk skirts, 15,000 all-polyester skirts, and 600 poly-
cotton blend 1 skirts, respectively. This results in total net profit of $160,598, 
which is much more than the optimal net profit ($156,788) in the product-mix 
problem, since the company is now able to satisfy more of the demand. 
10.4.2 
Transportation Applications 
A transportation or shipping problem focuses on determining the amount of 
goods or items to be transported from a number of origins to a number of 
destinations. The objective is usually to minimize total transportation costs 
or maximize the total value of goods loaded. Constraints usually deals with 
capacities or supplies at each origin and demand at each destination. 
10.4.2.1 
Vehicle Loading Problem The vehicle loading problem mainly fo-
cuses on deciding which items to load onto a vehicle (e.g., truck, ship, plane) 
so as to maximize the value of a load shipped from the origin to the desti-
nation. In the following example, we consider a vehicle loading problem for 
a shipment by DHL from its warehouse to Asia Airfreight Terminal in Hong 
Kong. One of its trucks, with a weight capacity of 16,000 pounds and a volume 
capacity of 1,400 cubic feet, is ready to be loaded. Awaiting transportation 
are the items shown in Table 10.4. Each of the six items has an associated 
total dollar value, available weight, and volume per pound that the item takes 
up. The objective is to maximize the total value of the items loaded on the 
truck without exceeding the truck's weight and volume capacities. 

10.4 APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
243 
1 
2 
3 
4 
5 
6 
7 
B 
9 
D 
11 
12 
13 
14 
IS 
16 
17 
1Θ 
19 
20 
21 
22 
23 
24 
26 
77 
26 
79 
A 
I s l e 
Prada Skirt (Make-Buy) 
Number of units 
Selling price 
Labor cost 
Material cost 
Outsourcing cost 
Profit 
Constraints: 
Yards of silk 
Yards of polyester 
Yards of cotton 
Al| silk demand 
Alipory demand 
Blend;' demand 
ΒΪβηΪ2 demand 
S 
i 
P 
All silk All poly to 
to make: 
make 
6,500.0! 
*
8 
(7.X 
: 
(425 
S0.80 : 
» 8 0 
"CTlfi"' 
«im 
(4.84 : (2.64 
0.Ϊ2 ' * 
" 
" 
009 
D 
B, 
Blend-1 to 
make 
16.4000 
(5 20 
SO 80 
( 1 2 6 
13.14 
Ö Ü 6 " " 
0.06 
E 
| 
F 
| 
G 
| 
H 
Bt 
Blend-2 
to make 
8 £000 
(580 
(0 30 
(111 
(3.B9 
007 
1 
1 
~ 
: 
~ ™Ί 
»Tarnet CM: 
itJiio 
& a 
EqualTo: 
© j g g 
O l * 
Oialueof: 
fö" 
rflyCharsghgCefc:- 
- 
- -
|(8*S:$I$5 
SllJecttotheCoretraWs: -
| » 1 Z : * 4 1 » < - »l»12:)L$l« 
, | » » 1 5 : $ J « i a < . « I 5 : « 1 8 
m i 
-| I 
S. 
' 
P. 
B,„ 
Ml silk All poly to Blend-1 
to bur 
buy 
to buy 
5000 
15HI00 
6000 
(780 
(425 
(520 
(4 20 
(Ϊ60 
(210 
S3 60 . 
(2.65 
(3.10 
1 
Bt. 
Blend-2 to 
buy 
00 
(5 80 
(2 20 
(3.60 
1 
T --"f—:"~ 
I 
! ϊ " 
I 
Suess 
add 
1 sK 1 
1 
Oose 
| 
1 SPOors ] 
: 
:.;::::: 
1 
ΞΞ 
._ 
K:| 
(257 790.X 
(25 3ΒΪΧ 
(44 472 00 
(27 360.X 
(160^96.00' 
7Θ0.Χ 
L 
| 
M 
<= 
ί24Β.00! <= : 
ϊεοσοοΐ '"-=7 
7000.X; <= 
I50COC0 
17X0.00 
88X.X <= 
LHS 
Sian 
i 
: 
- ;-
icosl/Yd 
780Ϊ (18 
28X| 
(9 
1600] (12 
7000| 
15ÖM 
17000Γ 
6B0ÖT 
RHS 
| 
y 
-
Figure 10.4 
Excel layout and solver entries for a make-or-buy decision model. 
Table 10.4 
Shipments for DHL. 
Item 
1 
2 
3 
4 
5 
6 
Value 
$16,000 
$15,000 
$11,000 
$14,825 
$13,800 
$9,820 
Weight (pounds) 
5,500 
5,000 
3,500 
4,000 
4,500 
4,000 
Volume (cubic feet per pound) 
0.128 
0.068 
0.166 
0.462 
0.046 
0.022 
The decision variables in this problem are defined as the number of pounds 
of each item that should be loaded on the truck. There are six decision 
variables (one for each item) in the model. In this problem, the dollar value 
of each item should be scaled for use in the objective function. For instance, 
if the total value of the 5,500 pounds of item 1 is $16,000, then the value per 
pound equals $16,000/5,500=$2.91. Similarly, the values per pound of items 
2 through 6 are $3.00, $3.14, $3.71, $3.07, and $2.46, respectively. 
Let Wi be the weight in pounds of each item i loaded on the truck. The 
LP model could be formulated as below. 

244 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
Maximize load value 
= 
$2.91Wi + $3.00W2 + $3.14W3 
+$3.71 W4 + $3.07^5 + $2.46W6 
subject to 
W1+W2 + W3 + W4 + W5 + W6 
< 
16,000 (weight limit of truck), 
0.128ΗΊ + 0.068 W2 + O.I66W3+ 
0.462^4 + 0.046W5 + 0.022We 
< 
1,400 (volume limit of truck), 
W\ 
< 5,500 (volume item 1 availability), 
W2 
< 
5,000 (volume item 2 availability), 
Wz 
< 
3,500 (volume item 3 availability), 
Wi 
< 
4,000 (volume item 4 availability), 
W5 
< 
4,500 (volume item 5 availability), 
W& 
< 
4,000 (volume item 6 availability), 
Wi,W2,W3,W4,W5,W6 
> 
0 (non-negativity). 
According to the Excel layout and solver entries in Figure 10.5, the optimal 
solution yields a total value of $48,047.48, and requires DHL to ship 1,943.40 
pounds of item 1, 5,000 pounds of item 2, 3,500 pounds of item 3, 4,500 pounds 
of item 5 and 1,056.60 pounds of item 6. The truck is fully loaded from both 
weight and volume perspectives. It is interesting to note that, the only item 
that is not included for loading is item 4, which has the highest dollar value 
per pound. However, its relative high volume makes it unattractive as cargo. 
10.4.2.2 
Sensitivity Analysis of The DHL Vehicle Loading Problem As we 
know, the above LP model of the DHL vehicle loading problem is solved 
under deterministic assumptions. That is, the load value and weight limit 
of each item are fixed, and the weight and volume limits of the truck also 
remain unchanged. DHL managers may be interested in studying the impact 
of changes in these values. In this case, we can make use of Sensitivity Report 
from Solver to analyze how sensitive the optimal solution is to changes in the 
input parameters, and determine a range of values within which the current 
optimal solution will remain optimal. The Sensitivity Report of the DHL ve-
hicle loading problem is presented in Figure 10.6. As we can see, Sensitivity 
Report has two distinct parts: a part titled Adjustable Cells and a part ti-
tled Constraints. These parts permit us to answer several what-if questions 
regarding the problem solution. 
Sensitivity analysis focuses on the changes in an objective function coef-
ficient (OFC) and changes in a right-hand side (RHS) value of a constraint. 
Here are some properties of changes in OFC and RHS. 
One Change in OFC. An OFC change has no effect on the feasible region. 
There is a range for each OFC where the current optimal solution re-

10.4 APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
245 
1 
2 
3 
A 
5 
-7 
8 
8 
10 
Π 
12 
13 
14 
15 
A 
B 
| 
C 
| 
D 
| 
DHL Transportation 
Weight in pounds 
Load value 
Constraints: 
Weight limit 
Volume limit 
Item 1 limit [pounds! 
(Λ' (Λ' C/li (Λ ΙΛ 
C! C! C! C| C 
3! 31 3: 3 
3 
E E - Ε · ε ΐ ε 
E j E i E l E j E 
w, 
w2 
w3 
, 
Sem 1 
Item 2 ' Item 3 , 
1,943 40] δ,ΟΟΟΟθ! 3,500 001 
$2 91 
$3 00 
$3 14 , 
""' 1 
1 
Ί 
* 
0 12B 
0 068 
0 166 
1 
1 
E 
1 
F 
w„ 
w5 
Item 4 
Item 5 
0 00 ,4,500 0C 
$3 71 
$3 07 
1 
1 
0462 __0_MB 
Γ" 
1 G mmm * ι J 
' 
w0 
1 Item 6 
M.05BBÖ 
, $2 46 
1 
" 0 022 
-
; 
1 
16 
mammmmmmmmammmmm^m 
17 
te 
18 
20 
21 
22 
23 
24 
(•»»»^»»»»»»»»»■■»»»»»»»»■■■■s^»»»»»»»»»»»^»»»« 
Set Tare* eel: 
jSHfc 
@ftj 
EquiTo: 
®ijaxl 
O f * 
OWueof: 
|θ 
^ByOiangtoflCels: 
.l«S:»G$5 
[Ml 
| 
Suess 
1 SjJijKt to the Constraints! 
|$H»:$K*15 <-«»■< »15 
»1 | 
add 
L_S*= 
1 
-1 
1 do» 1 
D 
1 SPtions 
| 
3 ■ 
$48,047 48j 
1BÖÖ0 00" <= "" ΪΒΟΟθ" 
1400 00" <="" 1400 
1343 40 <= 
5500 
5000 00, <= 
5000 
3500 00* <= 
3500' 
0 00 <="" 4000" 
4500 00 <= ' "45OO 
1056 60 <= 
4000 
LHS ""'sTgn RHS 
- - ~ 7 ; 
. _. 
... ,. ._ . 
" - -
" 
.. 
Figure 10.5 
Excel layout and solver entries for DHL transportation. 
mains optimal. If the OFC change is beyond the allowable range, then 
a new solution will become optimal. 
One Change in RHS. Constraints are classified into binding constraints (those 
with LHS=RHS at the optimal solution) and nonbinding constraints. 
For a binding constraint, the impact of one change in RHS is related to 
the Shadow Price (i.e., the change in the objective function value per 
one-unit increase in the RHS of the constraint). For each nonbinding 
constraint, there is an allowable range where the corresponding shadow 
price remains unchanged if its RHS change is within the range. In this 
case, the change of objective value equals the corresponding shadow 
price times the RHS change. However, the optimal solution must vary. 
(2) There is an allowable range for each nonbinding constraint where 
the optimal solution and objective value remain unchanged if its RHS 
change is within the range. 
Simultaneous Changes in OFCs or RHS. The current information in Sensi-
tivity Report is still valid if ^(change/allowable change) < 1. 
In the following we use the above Sensitivity Report of the DHL vehicle 
loading problem (Figure 10.6) to analyze some possible what-if cases. 
Case 1. What is the impact on the optimal solution if the load value of item 
6 increases by $0.15? 
A: According to Sensitivity Report, the increase $0.15 of item 6 is within the 
allowable increase $0.20, so the current optimal solution remains optimal. 

246 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
Microsoft Excel 11.0 Sensitivity Report 
Worksheet: [DHL Transportation.xls|3 7A 
Report Created: 2011-12-31 15:37:19 
Adjustable Cells 
Cell 
$BJ5 
JC15 
$Dt5 
ΪΕΪ5 
$Ft5 
JGJ5 
Name 
Weight in pounds Item 1 
Weight in pounds Item 2 
Weiqht in pounds Item 3 
Weight in pounds Item 4 
Weight in pounds Item 5 
Weight in pounds Item 6 
Final 
Value 
1,943.40 
5,000.00 
3,500.00 
0.00 
4,500.00 
1,056.50 
Reduced 
Cost 
0.00 
0.00 
0.00 
-0.63 
0.00 
0.00 
Objective 
Coefficient 
2.909090909 
3 
3.142857143 
3.70625 
3.066666667 
2.455 
Allowable 
Increase 
0.052248377 
1E+30 
1E+30 
0.63365566 
1E+30 
0.201100299 
Allowable 
Decrease 
0.152653409 
0.347941681 
0.070978927 
1E+30 
0.508853631 
0.197993848 
Constraints 
Cell 
ΪΗΪ8 
JHJ9 
JHJ10 
$H$11 
ΪΗΪ12 
$H$13 
ΙΗΪ14 
IHJ15 
Name 
Weight limit 
Volume limit 
Item 1 limit (pounds) 
Item 2 limit (pounds) 
Item 3 limit (pounds) 
Item 4 limit (pounds) 
Item 5 limit (pounds) 
Item 6 limit (pounds) 
Final 
Value 
16000.00 
1400.00 
1943.40 
5000.00 
3500.00 
0.00 
4500.00 
1056.60 
Shadow 
Price 
2.36 
4.28 
0.00 
0.35 
0.07 
0.00 
0.51 
0.00 
Constraint 
R.H. Side 
16000 
1400 
5500 
5000 
3500 
4000 
4500 
4000 
Allowable 
Increase 
2437.5 
112 
1E+30 
1866.666667 
1430.555556 
1E+30 
1365.853659 
1E+30 
Allowable 
Decrease 
875 
206 
3556.603774 
5000 
2618.055556 
4000 
3804.878049 
2943.396226 
Figure 10.6 
Sensitivity report of DHL transportation. 
Case 2. What is the impact on the objective value if the volume limit of the 
truck decreases by 180 cubic feet? 
A: As we see, the constraint of volume limit is binding. And a decrease of 180 
in the truck volume is within the allowable decrease 206. Hence the shadow 
price $4.28 is valid, and the objective value will decrease by $4.28 x 180 = 
$770.4. 
Case 3. What is the impact on the objective and the optimal solution if the 
upper limit of item 1 decrease by 3000? 
A: According to Sensitivity Report, the upper limit of item 1 is non-binding, 
and a decrease of 3000 is also within the allowable decrease 3556.6. Thus this 
change has no impact on either the objective or the optimal solution. 
Case 4. What is the impact on the objective if we simultaneously decrease 
the load value of item 1 and item 6 by $0.08 and $0.12, respectively? 
A: Since the allowable decreases of item 1 and item 6 are 0.153 and 0.197, 
respectively, we have 0.08/0.153 + 0.12/0.19 > 1, which suggests that the 
optimal objective would vary. 
10.4.2.3 Allocation Problem In the example of Section 10.4.2.1, DHL has 
only one truck and needs to load all the items onto the same truck. However, 
in the reality, DHL usually has many different trucks in its warehouse. Let 
us consider the case of 2 trucks where DHL has the option of replacing its 

10.4 APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
247 
single truck (with a weight capacity of 16,000 pounds and a volume capacity 
of 1,400 cubic feet) with two smaller trucks (each with a weight capacity of 
11,000 pounds and a volume capacity of 950 cubic feet). We still use the data 
in Table 10.4. If DHL uses two trucks, DHL requires that they are loaded 
with the same total weight. However, total volumes in the two trucks could 
be different. If the fixed cost of operating the two smaller trucks is $6,000 
more than the current cost of operating just a single truck, which alternative 
should be chosen? In this problem, DHL has to decide how to allocate the six 
items between the two trucks. Note that it is possible for the total quantity 
of an item to be split between the two trucks. 
To formulate this problem, the decision variables need to specify how much 
of each item should be loaded on each truck. Let the double-subscripted 
variable Wn represent the weight of the ith item on the first truck, and W^ 
the weight of the ith item on the second truck. Then the LP model can be 
stated in the following. 
Maximize load value 
subject to 
Wii + W2X + W31 + W41 + W51 + W6i 
0.128Wn + O.O68W21 + O.I66W31 + 
0.462W41 + 0.046W5i + 0.022W6i 
W12 + W22 + W32 + Wi2 + W52 + W62 
0.128W12 + O.O68W22 + O.I66W32+ 
0.462W42 + 0.046W52 + 0.022W62 
Wn + W12 
W21 + W22 
W31 + W32 
W41 + W42 
W51 + W52 
W6l + W62 
Wn + W21 + W31 + Wn + W51 + Wei 
Wu + W22 + W32 + W42 + W52 + W62 
Wn,W2i,W3uWil,W5UW6U 
W12, W22, W32, W42, W52, 1^62, 
= 
$2.91(Wn + W12) + $3.00(W2i 
+ W22) + $3.U(W31 + W32) 
+$3.71(W4i + Wi2) + $3.07(^51 
+W52) + $2.46(W6i + W52) 
< 
11,000 (weight limit of truck 1), 
< 
950 (volume limit of truck 1), 
< 
11,000 (weight limit of truck 1), 
950 (volume limit of truck 1), 
5,500 (availability of item 1), 
5,000 (availability of item 2), 
3,500 (availability of item 3), 
4,000 (availability of item 4), 
4,500 (availability of item 5), 
4,000 (availability of item 6), 
(same weight in both trucks), 
> 
0 (non-negativity). 
< 
< 
< 
< 
< 
< 
< 
Figure 10.7 shows the Excel layout and solver entries for DHL's allocation 
problem. For the constraint that makes sure that the same total weight is 

248 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
t 
2 
3 
4 
5 
I 
B 
S 
M 
It 
12 
13 
14 
15 
18 
17 
ii 
19 
20 
21 
22 
3 
24 
25 
28 
27. 
A 
| 
B 
| C 
| 
0 
1 E 
DHL Transporation (Allocation) 
Weight m pounds 
Loadvafoe 
Constraints: 
Weight limit truck #1 
Volume limit truck #1 
Weight limit truck #2 
Volume limit truck #2 
jtem 1 IOTIII (pounds) 
(tern 2 limit founds) 
item 3 limit (poundsj 
jtem 4 knit [pounds) 
Item 5 »mit (pounds) 
Item β Imit [pounds) 
Sameweuiht 
W „ 
W21 
W3, 
W41 
Item 1 Item 2 ten 3 tern 4 
Truck 1 Truck 1 Truck 1 Truck 1 
5.41509: O.OD i 716 67 | OHO 
»2 91 
$3 00 
»3 14 
$3 71 
1 
1 
' 
1 
' 
1 
0128 
0 060. 0 166 
0462 
1 
1 
F 
| ■ e' 
w„ 
w„ 
tern 5 ttem 6 
Truck 1 Truck 1 
!1.2B3J3'3.5M.ei 
$3 07 
$246 
1 
1 
0 046 
0 022 
1
1
1
1
1 
1 
ITS 
OMU Otttorf' 1» 
! 
Mttfstnfs 
ß&l 1 SMKS 1 
;5Wtot»!»»C0«traMK 
|1WH-«18 
M 
*" 1 
1 5 ^ 1 
C « . 
| 
£f*ion* 
| 
H 
Wo 
tern 1 
Truck 2 
O.00 
$2 91 
D 128 
1 
1 
J 
W a 
WJJ 
tern 2 ttem 3 
Truck 2 Truck 2 
5.000 0012,783.33 
$3 00 
S3 14 
1 
1 
0 06B 
0 166 
1 
K 
t 
L 
W«, 
W,i 
tern 4 
Item 5 
Truck 2 Truck 2 
0.00 3.21667 
$3 71 
$3 07 
1 
1 
0462 
0 046 
M 
w„ 
Kern 6 
Truck 2 
000 
$2 46 
0 022 
1 
« W ^ r 
$64,35335] 
11000 Οθ' «= 
950 00 <= 
11000 00* <= 
950 00 <= 
5415 09' <= 
5000 00, « 
35D0 00 <= 
0 00 <= 
4500 00" <= 
3584 91 <= 
1100000· = 
p 
11000 
950 
11000 
950 
5500 
5000 
3500 
4000 
4500 
4000 
11.00000 
Figure 10.7 
Excel layout and solver entries for allocation problem. 
loaded on both trucks, the Excel layout includes formulas for both the LHS 
(cell N18) and RHS (cell P18) entries. Cell N18: =sum(B5:G5), and cell P18: 
=sum(H5:M5). 
According to Figure 10.7, the optimal solution to DHL Transportation's 
allocation problem yields a total value of $63,353.95. This is $16306.5 more 
than the load value of $48047.48 that is achievable with just a single truck. 
Since this increase is more than the increased $6,000 operating cost, DHL 
should replace its single truck with the two smaller ones. From both weight 
and volume perspectives, the two trucks are fully loaded. Furthermore, all 
available quantities of items 2, 3 and 5 are loaded. Most of items 1 and 6 are 
loaded, while none of item 4 is loaded. 
10.4.3 
Assignment Applications 
Assignment problems focus on determining the most efficient assignment of 
people to jobs, machines to tasks, police cars to city sectors, salespeople to 
territories, and so on. The assignments are made on a one-to-one basis. For 
instance, in a person-to-job assignment problem, each person is assigned to 
exactly one job, and each job is assigned to exactly one person. Fractional 
assignments are not allowed. The objective could be to minimize the total 
cost of the assignments or maximize the total effectiveness or benefit of the 
assignments. 
10.4.3.1 
Labor Planning Problem with LP Labor planning problems focus on 
satisfying staffing needs over a specific planning horizon such as a day, week, 
month, or year. The ability to solve labor planning problems is particulary 

10.4 APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
249 
useful when staffing needs are different during the different time periods in 
the planning horizon. In addition, managers have some flexibility in assigning 
workers to jobs that require overlapping or interchangeable talents. 
The main branch of HSBC (Hong Kong and Shanghai Banking Corpora-
tion) in Hong Kong is a busy bank that has requirements for between 9 and 19 
tellers, depending on the time of day. The afternoon period, from noon to 3 
p.m. is usually the busiest. Table 10.5 shows the numbers of workers needed 
at various time periods. Now HSBC employs 10 full-time tellers and several 
part-time staffs. A part-time employee must put in exactly 4 hours per day 
but can start anytime between 9 a.m. and 1 p.m. Part-time tellers are paid 
relatively little without retirement and lunch benefits. Pull-time tellers, work 
from 9 a.m. to 5 p.m., but are allowed one hour for lunch. Half of the full-time 
tellers take their lunch break at 11 a.m., and the other at noon. Each full-
time teller provides 35 hours per week of productive labor time. According 
to HSBC policy, the bank limits part-time hours to a maximum of 50% of the 
day's total requirement. Part-time tellers earn $35 per day on average, and 
full-time tellers earn $100 per day in salary and benefits, on average. Now 
HSBC would like to determine a schedule that would minimize its total salary 
costs. It is allowed to release one or more of its full-time employees if it is 
cost-effective to do so. 
In this labor planning problem, we should determine how many employees 
need to start their work at the different starting times allowed. For instance, 
in the case of HSBC, we have full-time tellers who all start at 9 a.m., and 
part-time tellers who can start at anytime between 9 a.m. and 1 p.m.. Define 
F 
= 
number of full-time tellers to use (all start at 9 a.m.) 
Pi 
= 
number of part-time tellers to start at 9 a.m. and leave at 1 p.m. 
P2 = 
number of part-time tellers to start at 10 a.m. and leave at 2 p.m. 
P3 = 
number of part-time tellers to start at 11 a.m. and leave at 3 p.m. 
P4 
= 
number of part-time tellers to start at noon and leave at 4 p.m. 
P5 = 
number of part-time tellers to start at 1 p.m. and leave at 5 p.m. 
Then the objective function could be stated as 
Minimize total daily personnel cost = $100F + $35(PX +P2 + P3 + P4 + P5). 
In the following we investigate the constraints. For each hour, the available 
number of tellers must be no less than the required number. It is simple to 
count how many different tellers are working during each time period. On the 
other hand, we should notice that half of the full-time tellers break for lunch 
between 11a.m. and noon, and the other half break between noon and 1p.m.. 

250 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
Table 10.5 
Tellers required for HSBC. 
Time Period 
9 a.m.-10 a.m. 
10 a.m.-ll a.m. 
11 a.m.-Noon 
Noon-1 p.m. 
1 p.m.-2 p.m. 
2 p.m.-3 p.m. 
3 p.m.-4 p.m. 
4 p.m.-5 p.m. 
Number Required 
9 
11 
15 
17 
19 
18 
16 
12 
Hence we could present the constraints as below. 
F + Pi 
> 
9 (9 a.m.-10 a.m. ), 
F + P1+P2 
> 
11 (10 a.m.-ll a.m. ), 
1/2F + Pi + P2 + P 3 
> 
13 (11 a.m.-noon ), 
1/2F + P1+P2 + P3 + P4 > 
17 (noon-1 p.m. ), 
F + P2 + P3 + P4 + P5 
> 
19 (1 p.m.-2 p.m. ), 
F + P3 + PA + P5 
> 
18 (2 p.m.-3 p.m. ), 
F + P4 + P5 > 
16 (3 p.m.-4 p.m. ), 
F + P5 
> 
12 (4p.m.-5p.m. ). 
Furthermore, at most 10 full-time tellers can be available, so F < 10. 
In addition, part-time working hours cannot exceed 50% of the total hours 
required each day, which is the sum of the tellers needed during each hour. 
That is, 4(Pi+P 2+P 3+P 4+P 5) < 0.5(9+11 + 13+17+19+18+16+12) = 57.5. 
Also, remember to add the constraint of nonnegativity, F, Pi, P2, P3, P4, P5 > 
0. Excel layout and solver entries for this model are presented in Figure 10.8. 
According to Figure 10.8, the optimal solution has fractional values, which 
is possible because this model is an LP model. Because only integer solutions 
can be implemented, a possible recourse at this stage is to round off the 
fractional values to the nearest integers. In this case, the nearest integer 
solution is to employ 10 full-time tellers, 5 part-time tellers at 9 a.m., 1 part-
time teller at 10 a.m., 2 part-time tellers at 11 a.m., 4 part-time tellers at 
noon, and 2 part-time tellers at 1 p.m. for a total cost of $1,490 per day, 

10.4 APPLICATIONS IN SUPPLY CHAIN MANAGEMENT 
251 
1 
2. 
3 
4 
,5· 
Hi 
.7 
8 
9 
10 
11 
ia: 
13; 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
A 
I 
B 
| 
C 
HSBC Staffing 
Number of tellers 
Cost 
Constraints: 
9am-10am needs 
10am-11am needs 
11am-Noon needs 
Noon-1pm needs 
1pm-2pm needs 
2jfjm-3rjm needs 
3j>m-4pm needs 
4pnv5pm needs 
Max full time 
Part-time limit 
F 
j 
P| 
FT 
i 
PT 
tellers i 6>9arn 
;9.7 
| 5.1 
$100.00 | $35.00 
' " 1 
1 
Ϊ 
1 
05 
1 
05 
1 
1 
1 
1 
~1 
1 
i 
Γ 4~ 
'Set Target Cd: 
j*H$6 
[ S ] 
EqualTo: 
Oöax 
©ISO! 
O » 
;iy Changing Cels: 
i lff$S:$G$5 
rSybject to the Constraints: 
i$H$16:$H$17 <= $J*16:$J$17 
!|$Ηί8:}Η$15>-$3$8:$315 
D 
| 
E 
| 
P2 
P3 
PT 
@10am 
1.0 
$35.00 
PT 
©11 am 
2.0.. 
$35.00 
"1 
1 
1 
1 
1 
1 
1 
- J 
F 
P4 
PT 
@Noon 
4:0. 
$35.00 
1 
1 
1 
G 
P5 
PT 
@1pm 
2.3 
$35.00 
1 ~ 
1 
1 
1 
4 
: 
4 
4 
„ 
I 
-J r 
m 
1 Suess 
| 
·[ 
^ 
I 
Add 
I ' 
4 
I 
$1,478.13, 
-
14.9 >= J 
15.9 
13.0 
17.0 
-
190 
18.0 
16.0J 
12.0 
9.7 
57.5 
>= 
>= 
>= 
>= 
>= 
>= 
>= 
<= 
LHS Tsiqn 
Solve 
I 
dose 
j 
Options ] 
J I 
_ 
11 
13 
__7 
19 
18 
16 
12 
10 
r57.<i 
RHS 
i 
; 
■ 
i— 
I 
T - 
- 
i-
' 
.-
r -
Figure 10.8 
Excel layout and solver entries for HSBC staffing with LP. 
1 
_2_ 
3 
4 
5 
1 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
IB 
21 
22 
23 
24 
25 
26 
27 
28 
29 
A 
B 
f 
C 
HSBC Staffing 
«umber of tellers 
:ost 
CoMtraintK 
9artvlbam needs 
W*??-l I.3. Γ"1...".6.?!* ?.. 
liam-Noon needs 
Yoon-tpm needs 
1pnv2pm needs 
2pm-3prn needs 
3pm-4pm needs 
4pnv5pm needs 
Mai full lime 
3art-time limit 
F 
: 
Pi 
π 
: PT 
tellers -09am 
,:&$ 
\ W. 
1100.00:135 00 
b 1 E 1 
Pi 
P3 ■ 
PT 
: 
PT 
; 
©10amO11am, 
-ΛΛ i mi 
135.00 $35.00 
F 
P« 
1 β 
P) 
PT 
PT 
©Noon; ßlpm 
°k 
ΐ ; 2 Λ ' 
(35.00 135.00 
Ϊ 
-" ' 1 
1
:
1
1 
""""0.5"'":'" Ί ' " : " ϊ " 
. " " 1 " " ' 
■■ 
"0.5 
" 1 " "' 
1 ' " ' 
Ί 
1 " ' :" 
i 
:" Ϊ ' 
' 1' *'' "Γ ' ί" Ϊ " 
1 
' 
' 
1 
1 " ' 
i 
1 
■
-
: 
T ,.. _ . .......... 
""4 . .^... 
Set Tenet«* 
j w ^ g 
«·■"* 
OB« Θ@ Ο Ϊ 
<&a>an0ngC«is: 
- ■·- 
■ 
;SlMKttotheC(ntb«hti: 
:|«a*5:*G*S-«eger 
|*Htl6:$Htl7 <- $J$16r$J*17 
i tH$S:*HtlS>-tJ$a:titl5 
*erf: 
10 
„ ß n l I &**1 
1 
ftdd 
1 
1: 
1 
| Otanoo J 
W.430.00]. 
ioo 
110-
13.Ö: 
17Ό-' 
240: 
230 
16 θί 
120 
100 
560 
LHS ^ 
LA-* 
1 a~ 1 
i OP»»« I 
■ 
, 
1 1 J 
> = ' ; " 9 
>= 
11 
>= ' :' 13 
>= ". 17 
>= 
1£ 
>= 
1ί 
>= ' 
16 
>= 
12 
<= 
10 
<= y57£ 
Siqn RHS 
Figure 10.9 
Excel layout and solver entries for HSBC staffing with IP. 

252 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
which is slightly more than the optimal cost $1,478.13 that is obtained in the 
LP model. 
10.4.3.2 
Labor Planning Problem with IP In the previous example, a natural 
question will arise: is the round-off solution optimal with respect to inte-
ger solutions? To answer this question, we solve an integer programming 
(IP) problem for the same model, that is, the same objective function and 
constraints but with the additional constraint that all decision variables be 
integers. In the Excel/Solver software, it is easy to convert an LP model into 
an IP model. Excel layout and solver entries for IP are presented in Figure 
10.9. In Solver Entries, we use the Add option to include an integer constraint. 
According to Figure 10.9, we find that the optimal cost is also $1,490, which 
indicates that the round-off solution that was found earlier is optimal. How-
ever, Figure 10.9 shows a different optimal solution (having the same same 
cost), which is to arrange 10 full-time tellers, 1 part-time teller at 10 a.m., 
7 part-time tellers at 11 a.m., 4 part-time tellers at noon, and 2 part-time 
tellers at 1 p.m. 
Comparing the labor planning problem with IP to the one with LP, we ob-
serve that the integer restriction results in an objective function value ($1,490 
of cost) that is no better than the optimal LP solution ($1,478 of cost). It 
is easy to understand why this inequality is a general feature of IP vs. LP 
models. The feasible region (i.e., the set of decision variables that satisfy the 
constraints) of the original LP problem includes all the points in the feasible 
region of the IP problem, but not vice versa: fractional points in the LP feasi-
ble region are not feasible in the IP problem. The LP problem corresponding 
to the IP problem is called the relaxed problem. At best, the two solutions 
could be equal when the optimal LP solution is integer-valued. 
The HSBC staffing problem focuses on the labor planning during the dif-
ferent time periods of a single day. In fact, in many other labor planning 
problems, the planning horizon may consist of a week, a month, or even a 
year, which correspond to operational, tactical, and strategic decisions from 
the hierarchical perspective. In addition, the time period may include specific 
shifts. For instance, if there are two shifts per day (day shift and night shift), 
then there are total 14 time periods in the problem. Worker requirements 
need to be specified for each of these 14 time periods. In this case, the work 
schedules need to specify the exact days and shifts. In addition, in many real-
world problems, they typically have hundreds or even thousands of decision 
variables. 
10.5 
SUMMARY 
In this chapter we firstly introduced the decision model, including its origin, 
definition, data types and steps involved in it. We then briefly described linear 
programming models and more general programming models, the definition 
and activities of supply chain management. Finally, we used decision modeling 

EXERCISES 
253 
to deal with typical problems in supply chain management, such as product 
mix problems, make-or-buy problems, vehicle loading problems, allocation 
problems, and labor planning problems. 
EXERCISES 
10.1 
A furniture manufacturer produces two different types of china cabi-
nets: a European model and a Chinese model. Each cabinet produced must 
go through three departments: carpentry, painting, and finishing. Table 10.6 
contains all relevant information concerning production times (hours per cab-
inet), production capacities for each operation per day, and revenue ($ per 
unit). The firm has a contract with a distributor to produce a minimum of 
58 cabinets of each type per day. The manufacturer would like to determine 
the product mix that maximizes the daily revenue. Formulate the problems 
in an LP model and solve it using Excel. (Answer: $3,428.) 
Table 10.6 
Information for Exercise 10.1. 
Type 
European 
Chinese 
Capacity(hours) 
Carpentry 
2.80 
2.60 
330 
Painting 
1.4 
1.2 
220 
Finishing 
0.70 
0.70 
130 
Revenue 
30 
26 
10.2 
A manufacturer company produces three different types of bicycles: 
Bl, B2 and B3. It has a fixed order from another distributor for 2,100 Bl, 
3,820 B2 and 1,820 B3 bicycles. Between now and when the order is due to 
delivered, it has 16,800 fabrication hours and 1,800 inspection hours, which 
are not enough to manufacture the total quantity ordered. The time required 
in each department by the various bicycles are shown in Table 10.7. Also 
shown are the costs to manufacture the bicycles in house and the costs to 
outsource them. For labeling considerations, the company wants to manufac-
ture in-house at least 65% of each type of bicycle that will be shipped to the 
distributor. How many bicycles of each type should be made in-house and 
how many should be outsourced? (Hint: fractional solutions are not allowed.) 
What will be the total cost to fill the distributor's order? (Answer: $153,797.) 
10.3 
A tramp freighter's cargo officer wants to determine the mix of cargo 
to be carried on the next trip. The ship's volume limit for cargo is 110,000 
cubic meters, and its weight capacity is 2,450 tons. The cargo officer has five 
different types of cargo from which to select and wishes to maximize the value 
of the selected shipment. However, to make sure that none of the customers 

254 
CHAPTER 10. MODELING IN SUPPLY CHAIN MANAGEMENT 
Type 
Bl 
B2 
B3 
Table 10.7 
Fabrication Hours 
2.4 
3.3 
3.9 
Time required and costs for Exercise 10.2. 
i 
Inspection Hours 
0.26 
0.32 
0.48 
In-house cost 
$16.5 
$19.0 
$22.5 
Outsource Cost 
$20.40 
$20.85 
$24.76 
Table 10.8 
Specifications of five cargoes 
Cargo Type 
A 
B 
C 
D 
E 
Tons Available 
980 
880 
1,980 
2,300 
3,680 
Value per Ton 
$1,400 
$1,780 
$1,280 
$920 
$1,380 
for Exercise 10.3. 
Volume per Ton (CU.M.) 
28 
56 
32 
48 
38 
Table 10.9 
Min. number of workers for Exercise 10.4. 
Period 
1 
2 
3 
4 
5 
6 
Time 
3 a.m.-7 a.m. 
7 a.m.-ll a.m. 
11 a.m.-3 p.m. 
3 p.m.-7 p.m. 
7 p.m.-ll p.m. 
11 p.m.-3 a.m. 
Workers Required 
4 
12 
17 
10 
14 
5 
are ignored, the officer would like to make sure that at least 22% of each 
cargo's available weight is selected. The specifications for the five cargoes are 
shown in Table 10.8. What mix of cargo should the load master carry on the 
next trip? What is the optimal shipment's value? (Answer: $3,302,272.) 

EXERCISES 
255 
10.4 
An Italian restaurant is open 24 hours a day. Waiters and busboys 
report for duty at 3 a.m., 7 a.m., 11 a.m., 3 p.m., 7 p.m., or 11 p.m., and 
each works an 8-hour shift. Table 10.9 shows the minimum number of workers 
needed during the six periods into which the day is divided. How should the 
restaurant schedule its workers so that the total staff (number of workers) 
required for one day's operation is minimized? (Answer: 35.) 
REFERENCES 
1. Balakrishnan, N., Render, B. and Stair, Jr. R. M., Managerial Decision Mod-
eling with Spreadsheets, Pearson Education, New Jersey (2007). 
2. Dantzig, G.B., Linear Programming and Extensions, Princeton University Press, 
New Jersey (1963). 
3. Peterso,n R., and Silver, E., Decision Systems for Inventory Management and 
Production Planning, John Wiley & Sons, New York (1985). 
4. Shapiro, J.F., Modeling the Supply Chain, Duxbury Press, Duxbury: MA (2007). 
5. Simchi-Levi, D., Kaminsky, P., and Simchi-Levi, E., Designing and Managing 
the Supply Chain: Concepts, Strategies and Case Studies, McGraw-Hill, New 
York (2010). 
6. Tayur, S., Ganeshar, R., and Magazine, M., Quantitative Models for Supply 
Chain Management, Kluwer, Boston (1999). 
7. Winston, W.L., Introduction to Mathematical Programming, Duxbury Press, 
Duxbury: MA (1995). 
8. Winston, W.L., and Albright, S.C., Practical Modeling and Applications: Spread-
sheet Modeling and Applications, Duxbury Press, Duxbury: MA (1997). 
9. Westphal, C., and Blaxton, T., Data Mining Solution: Methods and Tools for 
Solving Real-World Problems, John Wiley & Sons, New York (1998). 

CHAPTER 11 
MODELING TEMPERATURE FOR 
PRICING WEATHER DERIVATIVES 
FRED ESPEN BENTH 
Center of Mathematics for Applications, University of Oslo, Blindem, Oslo, Norway 
11.1 
INTRODUCTION 
In this chapter we will analyze stochastic models for the dynamics of the 
surface air temperature in a given location. Our motivation comes from the 
financial market for so-called weather derivatives, where one can buy and sell 
weather. The Chicago Mercantile Exchange has for some years organized a 
trade in financial contracts where one can earn (or lose...) money on weather 
events. The exchange offers contracts on temperature, snowfall and hurri-
canes. We shall focus on the temperature contracts here. 
The most popular temperature derivatives are the futures contracts. A 
futures contract on temperature can be thought of as fixing the temperature 
financially, in the sense that one is securing a fixed temperature over a period 
rather than a varying one as observed in nature. In fact, such a contract 
Mathematical Modeling with Multidisciplinary Applications.
 
257 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

258 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
gives the owner money every time the temperature goes above a threshold, 
while the owner must pay when the observed temperature is below. The 
contracts are not specified on temperature directly, but on a temperature 
index. The indices are cooling degree days (CDD), heating degree days (HDD) 
and cumulative average temperature (CAT). These indices are measured for 
various cities worldwide, including several US, Canadian, European and Asian 
cities. 
A CDD index is essentially providing a measure for the demand of air-
condition cooling. In a pre-defined period of time, the index is computed as 
the aggregated temperatures above a threshold, defined to be 18° C in the 
market. Mathematically, one writes 
CDD(n,T2) = ] T max(T(i) - 18,0), 
(11.1) 
t=Tl 
where τ\ and τ2 are, resp., the start and end of the measurement period, and 
t ranges over the days in this period. Moreover, T(t) is the daily average 
temperature, defined as the average of the maximum and minimum temper-
ature of day t. The HDD index measures the aggregated temperatures when 
heating is required, and is analogously defined as 
T2 
HDD(n,T 2)= ^ m a x ( 1 8 - T ( i ) , 0 ) . 
(11.2) 
t=Tl 
Most futures are written on these two indices. The CAT index is used for tem-
peratures measured in European cities in the summer period, and is defined 
as 
CAT(T!,7*)=f;T(t). 
(11.3) 
t=Tl 
For example, we can buy a CAT index futures measured in the city of Stock-
holm, Sweden, for the period of July. Then we will aggregate the daily average 
temperatures of July, and get that amount paid in cash at the end of July. In 
return we have to pay the fixed (futures) price F(t, Julyl, July31) agreed at 
the entry of the contract at time t < Julyl. 
The typical measurement periods for temperature futures are the months 
in the year, but one can also trade in futures on indices measured over a 
season (consisting of two or more months). 
The temperature market offers a financial tool to hedge weather risk. For 
example, a holiday resort may suffer large losses in case of unfavorable weather 
in their high season. Thinking about a summer holiday resort in the Mediter-
ranean, it would face large losses if the summer turns out to be too cold. They 
could use temperature contracts to insure themselves against this risk. For 
example, buying an HDD futures measured over their high season would result 
in an income in case of low temperatures, and an expense when temperatures 

11.2 STOCHASTIC TEMPERATURE MODELING 
259 
are high. But high temperatures would on the other hand result in profits 
from tourism, so this expense could be viewed as an insurance premium. 
The main actors in this market is naturally the energy sector. Producers 
and retailers of energy, say, face large volume risk impacted from weather 
changes. For example, a producer of electricity knows that mild temperatures 
in the summer, or warm winters lead to low demand for power, and thus re-
duces the income of the producers. They have a natural need for temperature 
hedging tools. 
The Chicago Mercantile Exchange also offers call and put options written 
on the various futures. For example, a call option on the July CAT futures 
with strike price K and exercise time r < Julyl, will pay the owner 
max (F(T, Julyl, July31) - K,0) . 
(11.4) 
In fact, such an option gives the owner the right to enter a CAT contract with 
a futures price K rather than the market futures price at time τ. This right 
can be abandoned if it is not favorable to the owner of the option. 
In this chapter we will introduce a class of stochastic processes which are 
suitable for modeling the temperature dynamics in time at a given location. A 
stochastic process is a family of random variables indexed over time. We will 
back up our temperature model with an empirical example. We next apply 
probability theory to derive CAT futures prices and to valuate options. When 
trading in such instruments in the market, one must have a clear knowledge 
on the relationship between prices and temperature evolution. We provide a 
framework for this. 
11.2 
STOCHASTIC TEMPERATURE MODELING 
The surface air temperature at a given geographical location evolves dynam-
ically in time according to complex physical laws for weather. The observed 
temporal variations in temperature are governed by wind, cloud density, sun, 
exchange of heat with the sea, topology of the location, etc., and can be mod-
eled by highly complex partial differential equations. In Figure 11.1 we have 
plotted the daily average temperatures observed in Stockholm, Sweden rang-
ing from May 25, 1996 until May 24, 2006. The daily average temperature is 
computed as the mean of the maximum and minimum temperature observed 
over the day. We observe the gray curve varying apparently randomly around 
a seasonal mean, which is plotted as a black curve in the figure. 
We will in this chapter apply a so-called stochastic reduced-form approach 
in modeling the temperature evolution at a specific location, based on stochas-
tic processes. From the temperature series plotted in Figure 11.1, it seems 
natural to separate the dynamics of temperature into a seasonal deterministic 
component measuring the average temperature, and a stochastic component 
modeling the "random" fluctuations around this mean. Thus, we assume that 

260 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
30 r 
ς is 
CO 
<" 
i n 
Q. 
10 
E 
CD 
a> 
5 
σ> 
CO 
% n 
CO 
>> 
CO 
C 
■o 
_ 0 
-10 
-15 
-20 
11 
1 
1 
-
500 
1000 
1500 
2000 
time 
2500 
3000 
3500 
Figure 11.1 
Daily average temperatures (in gray) from Stockholm, Sweden, 
together with the seasonal mean function (in black). Temperatures are ranging from 
May 25, 1996 until May 24, 2006. 
the temperature at time t > 0 is given by the model 
T(t) = A(t) + X(t), 
(11.5) 
with A being a real-valued continuous and bounded function on [0, oo). As 
temperature is evolving continuously in time, it is natural to state its dynamics 
for all t > 0, and not only for discrete times t = 0,1,2,3,.... 
For the specific case of Stockholm data as shown in Figure 11.1, it turned 
out that a seasonal function of the form 
A(i) — ao + a\t + θ2 cos 
2n(t - q3) 
365 
(11.6) 
was appropriate. Here, a* for i = 0, ..,3 are constants. Such a seasonal 
function explains, via the trigonometric term, the yearly cycles of cold and 
warm seasons. The trend ao + a\t may be interpreted as global warming, or 
effects from urbanization. One expects an increase in temperature from global 
warming. Arguably, such an increase is not necessarily linear, but in the short 
term this provides a good approximation. As buildings and traffic within a 

11.2 STOCHASTIC TEMPERATURE MODELING 
261 
city create a local urban climate warmer than outside the city borders, one 
may experience a temperature increase when looking at a long time series of 
measurement of temperature at a given location. The measurement station 
could in the old days be placed outside the city, but over the years the city 
has grown to include the station as well. The seasonal function in (11.6) 
seems appropriate for temperatures measured in many locations, but other 
specifications are of course also possible and relevant. The black curve in 
Figure 11.1 is the best estimate of (11.6) in the least squares sense on a more 
than 40 year long data series of daily temperature recordings in Stockholm. 
We shall come back to this later. 
After explaining the seasonality of temperature, we move our attention to 
the much more difficult task of presenting a model for the stochastic com-
ponent X(t). 
From Figure 11.1 it seems that the temperature is randomly 
fluctuating around its mean, but not drifting too far away. In view of the 
physical laws of energy conservation, one actually expects the temperature to 
be pushed back towards its mean value. We present in the next subsection a 
simple stochastic model with such a feature. This model, frequently referred 
to as an Ornstein-Uhlenbeck process, could be used for temperature model-
ing. But as it turns out, a more general class of stochastic processes are more 
appropriate. We analyze Ornstein-Uhlenbeck processes first in order to set 
ideas without having to involve too many technicalities. 
11.2.1 
Simple Stochastic Mean Reverting Processes 
A typical model for mean reversion is the first-order ordinary differential equa-
tion 
ψ 
= -au(t), 
(11.7) 
with an initial value u(0) = uo and a > 0. The solution of this equation can 
be found to be 
u(t) = u0exp(—at). 
(H-8) 
Note that by inspecting the differential equation for u, we see that if u(t) < 0, 
then the derivative du(t)/dt 
becomes positive, and hence the value of u(t) 
is pushed upwards towards the origin. On the other hand, if u(t) > 0, the 
derivative becomes negative, giving a push down towards the origin. We have 
a reversion to the "mean value" zero, and any deviation from this will be 
dampened. From the solution, we get an exponentially decaying function to 
zero as long as uo > 0, and the opposite if UQ < 0. Obviously, u(t) has zero 
as its asymptotic limit. 
We find the half life of u{t) to be 
ln2 
r = 
, 
11.9 
a 

262 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
being the time it takes before the u(t) is equal to uo/2, that is, the time it takes 
before a deviation from zero, uo is halved in value. This is a measure of how 
fast the dynamics is reverting to its mean. Note that the ordinary differential 
equation (11.7) is often used for modeling population growth, then with a < 0. 
In that case, we get a dynamics drifting away from zero. 
Obviously, from the time series data we have looked at, the dynamics of 
temperature is far more volatile than the smooth exponential curves implied 
by the model (11.7). A way to get stochastic fluctuations and mean reversion 
at the same time, is to add noise to the dynamics in (11.7). Heuristically, we 
write 
m& 
= -aX{t)dt + aW{t), 
(11.10) 
at 
where W is white noise and σ > 0 is a parameter scaling the size of noise, 
frequently called the volatility of temperature. 
White noise is often interpreted as the derivative of a Brownian motion 
B(t), that is, W(t) = dB(t)/dt. 
A Brownian motion is a family of random 
variables parametrized by time, {B(t)}t>o, with the three properties 
1. For each t > s >u > v > 0, B(t) — B(s) is independent of B(u) — B(v). 
2. For each t > s > 0, B(t) — B(s) is normally distributed, with mean zero 
and variance t — s. 
3. B(0) = 0 
By Kolmogorov's extension theorem (see Oksendal [7], Theorem 2.1.5), we 
are ensured that there exists a probability space (Ω, T, P)10 and a family of 
random variables with the three properties above. Moreover, by Kolmogorov's 
continuity theorem (see Oksendal [7], Theorem 2.2.3), Brownian motion has 
continuous paths, that is, for almost every ω € Ω, 11—► B(t,u>) is a continuous 
function. Brownian motion is an example of a stochastic process, that is, a 
parametric family of random variables in time. 
Brownian motion can be viewed as a random walk in continuous time. Let 
Zi = B(U) for a uniform partition {ij}i==0>... of the time line. Then, letting 
Δ := ij+i — ti, we have from the properties of Brownian motion that 
{Zi}^ 
is a sequence of independent and identically distributed random variables, 
where Zi ~ Af(0, Δ), that is, centered normally distributed with variance Δ. 
We note that the random variable 
B{t) - B(s) 
t - s 
will be normally distributed, with mean zero and variance \/t — s, for t > s > 
0. But then, letting s —> t, the limit will not exist as the variance explodes. 
10A probability space is a set Ω equipped with a σ-algebra T and a probability P, that is, 
a measure with the property Ρ(Ω) = 1. 

11.2 STOCHASTIC TEMPERATURE MODELING 
263 
This shows that the time derivative of Brownian motion does not exist, and 
so does not W{t) as we have defined it above. Apparently, the definition of a 
stochastic dynamics in (11.10) is not meaningful. 
This is true in a strict sense, however, we can change our intepretation of 
(11.10) slightly to get something meaningful. Integrating both sides informally 
with respect to time, and using dB(t) = W(t)dt gives us 
X{t) = X(0) - a [ X(s) ds + aB{t). 
(H-H) 
Jo 
Thinking about integration as summation, we have used the natural property 
that / 0 dB(s) = B(t) — B(0) = B(t). 
As Brownian motion is a meaningful 
object, we may pose the question whether there exists a stochastic process 
X(t) solving the integral equation (11.11), and if so, if this process is unique 
or not. Here, X(0) is a given real number being the initial condition of the 
dynamics. 
The integral equation in (11.11) is a special case of a so-called stochastic 
differential equation, and frequently one presents it on a differential form as 
dX(t) = -aX(t)dt 
+ adB(t). 
(H-12) 
The precise meaning of (11.12) is nothing but (11.11). 
Let us investigate the existence and uniqueness of a solution of (11.12). We 
have the following Lemma: 
Proposition 1 Let Xi(t) for i = 1,2 be two solutions of (11.12) with Xi(0) = 
Xi. If Xi(t) has finite variance, then 
E[\X1(t)-X2(t)\2]1/2<\x1-x2\eat, 
for every t > 0. 
Proof: It holds from (11.11) that 
Xi(t) - X2(t) = xi - x2 - a ί 
Λ Ί ( β ) - Χ 2 ( β ) ώ . 
Jo 
But, by the triangle and Minkowski's inequalities (see Folland [5]), it follows 
Γ /"* 
1 1 / 2 
Έ[\Χ1(ί)-Χ2(ί)\2]1/2 
< 
\xi-x2\+aEUj 
X^s) 
- X2(s) ds)2 
< 
\Xl-x2\ 
+ a [ E [!*!(*)-X 2(a)| 2] 1 / 2 de. 
./o 
The Lemma follows by Gronwall's inequality. 
■ 

264 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
This result immediately gives uniqueness of solutions of (11.12) in the class 
of stochastic processes with finite variance. 
Not unexpectedly, there exists an explicit solution to (11.12). We may 
derive the solution candidate by the means of assuming W(t) in (11.10) being 
a regular continuous function. If this would be the case, the variation of 
parameters would give the solution (see Exercise 11.1) 
X(t) = X(0)e-at 
+ σ ί 
e~a^s^W{s)ds. 
Jo 
As we already know, W(s) does not exist, but by exchanging W(s)ds by 
dB(s), we may get something which makes sense, namely 
X(t) = X(0)e-at 
+ σ ί 
e - a ( i - s ) dB(s). 
(11.13) 
Jo 
In order to prove that this is the solution, we first must understand the precise 
meaning of the stochastic integral. 
As integration is summation, consider the sum 
n - 1 
/ n ( i ) ^ e a s ' A B ( S l ) , 
i=0 
where {si}i=o,...,n is a partition of the interval [0, t], with so = 0 and sn = t, 
and AB(si) 
= B(si+i) — B(si). 
By the independence of the increments of 
Brownian motion, and the fact that AB(si) ~ 7V(0, Sj+i — Si), we find that 
In(t) is normally distributed with mean zero and variance 
Var(In(t)) = ]Te 2 ö S i(s i + 1 - β <). 
i=0 
Choosing nested partitions, we see that 
lim Var(/„(*))= / e2as ds. 
rwoo 
JQ 
Indeed, we find that In{t) is a Cauchy sequence of random variables with 
finite variance, hence a Cauchy sequence in the Hubert space L2{Q,,!F, P). 
Since this is a complete space, there exists a random variable I(t) with finite 
variance such that In{t) —» I(t) as n —> oo. We use this as the definition of 
the stochastic integral, that is, 
/ easdB(s)= 
lim In(t), 
(H-14) 
Jo 
"-*°° 

11.2 STOCHASTIC TEMPERATURE MODELING 
265 
where the limit is taken in Σ2(ίϊ,Τ,Ρ). 
It is easily seen that the stochastic 
integral becomes normally distributed, with mean zero and variance 
Var(f easdB(s))= 
[ e2a3 ds. 
(11.15) 
Jo 
Jo 
This integral is sometimes called the Wiener integral, which is a special case 
of the more general Ito integral. The latter allows for stochastic processes as 
integrands. The term exp(—at) can be moved in or out of the integral by 
linearity. Hence, this defines the stochastic integral term in (11.13). 
Since we have 
n—1 
n—1 
n—1 
] T eaSiAB(Si) 
= 
Σ {eaSi+1B(si+1) 
- eas<B(Si)} 
- ] T 
B(si+1)Aeas* 
i=0 
ra-1 
= 
eatB(t)-J2B(si+i)Ae° 
i=0 
i=0 
i=0 
i=0 
it holds that 
/ eas dB(s) = eatB(t) - a [ B(s)eas ds. 
(11.16) 
Jo 
Jo 
Sometimes, one actually defines the Wiener integral by this integration-by-
parts formula. 
Of course, we can repeat the derivations above for a general measurable 
function f(t) as integrand rather than exp(ai). The condition for the stochas-
tic integral J0 f(s) dB(s) to exist will in this case be that 
I 
t 
2 
f (s)ds < oo. 
Under this condition, the stochastic integral J0 f(s) dB(s) can be defined as a 
limit of partial sums following the same procedure as above. The integral will 
be normally distributed, with mean zero and variance given by the / 0 / 2(s) ds. 
If in addition / is continuously differentiable, we can derive the integration-
by-parts formula 
/ f(s)dB(s) 
= f(t)B(t)- 
[ 
B(s)f'(s)ds. 
Jo 
Jo 
These more general considerations will become useful in the next section. 
We can now prove that (11.13) is the (unique) solution of (11.12). 
Proposition 2 The stochastic process X(t) defined in (11.13) is the unique 
solution to the stochastic differential equation (11.12). 

266 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
Proof: For simplicity, let X(0) — 0. By the integration-by-parts formula in 
(11.16) we find 
/ X{s)ds 
= 
f σ [ e-a{s-u) 
dB(u) ds 
Jo 
Jo 
Jo 
pt 
pt 
PS 
= 
σ 
B(s)ds-aa 
e~as 
B(u)eaududs. 
Jo 
Jo 
Jo 
Using the Fubini Theorem (see Folland [5]) on the double integral yields 
/ X(s)ds 
= 
σ f B{s)ds-aa 
f 
[ e~as dsB(u)eau 
du 
Jo 
Jo 
Jo 
Ju 
= 
σ f B{u)e-a{t~u) 
du. 
Jo 
But then, again using integration-by-parts in (11.16), 
X{t) + a [ X(s) ds 
= 
σ [ e " ^ - ^ dB(s) + ασ [ B(s)e-a{t-s) 
ds 
Jo 
Jo 
Jo 
= 
aB(t) -σα 
ί B(s)e-a(t-s) 
ds 
Jo 
+ασ [ B(s)e-a^-^ 
ds 
Jo 
= 
aB{t). 
This shows that X(t) is a solution. Uniqueness follows from the fact that 
X(t) has finite variance. This proves the proposition. 
■ 
We end this section with a study of the stationary properties of X(t). For 
x being an arbitrary real number, let ^x(t){x) 
denote the cumulant function 
oiX(t), 
φχ(φ) 
= lnE[exp(LrA-(t))] , 
(11.17) 
with i = y/^ϊ being the imaginary unit. Inserting X(t) from (11.13) into the 
defintion of X(t) we find from the normality of the stochastic integral: 
Ψχ(φ) 
= 
izX(0)e- a t+lnE exp (\χσ ( e-^s) 
dB(sU 
ixX(0)e~at 
- — 
(1 - e~2at) . 
4a 
v 
' 

11.3 CONTINUOUS-TIME AUTOREGRESSIVE PROCESSES 
267 
See Exercise 11.2 for the computation of the expectation. Letting time go to 
infinity, we see that the cumulant will converge. In fact, we easily see that 
But this is the cumulant function of a normally distributed random variable 
with mean equal to zero and variance given by σ2/2α. We therefore say 
that X(t) is stationary, since its distribution has a limit. Note that in the 
deterministic case as we started off with, the limit of the solution was sim-
ply zero. In the stochastic case, X{t) is not zero in the limit, but normally 
distributed. This means in practice that X{t) in stationarity will randomly 
fluctuate around the mean zero, where the fluctuations are distributed ac-
cording the normal distribution. The Brownian motion will constantly kick 
X(t) away from its mean, while the mean reversion a will force the process 
back to its zero level. As we see, these two forces balance out in the long run. 
We remark that the process X(t) is called an Ornstein-Uhlenbeck process 
driven by Brownian motion. The study of such processes are important for 
modeling energy markets and not only temperatures. Indeed, by considering 
jump processes as the stochastic driver rather than Brownian motion, one can 
develop realistic models for the prices of electricity, gas, oil, etc. We refer the 
interested reader to the monograph by Benth et cd. [2]. 
11.3 
CONTINUOUS-TIME AUTOREGRESSIVE STOCHASTIC 
PROCESSES 
The simple stochastic mean reversion dynamics we analyzed in the previous 
section turns out to be a special case of a much wider class of stationary 
stochastic processes. Moreover, for the accurate modeling of temperature, 
the simple mean reversion process is not sufficient for explaining all the prob-
abilistic features of the temperature dynamics. 
The basic stochastic dynamics for modeling the time evolution of temper-
ature is the so-called continuous-time autoregressive process. We shall refer 
to these models as CAR processes and define them following the introduction 
in Benth et cd. [2]. 
For each time t > 0, let X(i) be a random variable with values in RP, 
for p > 1 a natural number, defined as the unique solution of the stochastic 
differential equation 
dX(t) = AX(t) dt + epa(t) dB{t), 
(11.18) 
with X(0) = XQ. Here, a(t) is a positive continuous volatility function and e^, 
for k = 1,... ,p is the canonical basis in Rp. Furthermore, A is a p x p-matrix 

268 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
on the specific form 
1 
0 
0 
1 
0 
0 
0 
-ap 
-dp-i 
-CKp_2 
1 
-Oil 
(11.19) 
The constants a*,, for k = 1,... ,p are all positive. We define the continuous 
autoregressive process X{t) of order p by 
X{t) = elX(t), 
(11.20) 
where we have used * to denote matrix transposition. Such a dynamics X(t) 
is frequently referred to as a CAR(p) process. Note that tradtionally, one 
assumes a constant volatility function σ(ί), but we extend the definition here 
since temperatures possesses an interesting seasonal pattern in the volatility. 
■ EXAMPLE 11.1 
Note that by letting p = 1, we recover the simple Ornstein-Uhlenbeck 
process studied in the previous section as long as a(t) = σ, a constant. 
Indeed, for p = 1 we have that the matrix A collapses into a real value 
A = —αχ. Then, X(t) is a stochastic process with values on the real line 
solving the equation 
dX(t) = -c*iX(i) dt + 
adB(t). 
Trivially, ei = 1 in the case p = 1, and therefore the CAR(l) process 
X(t) = eJX(i) solves the same stochastic differential equation as our 
Ornstein-Uhlenbeck process in the previous section. There is no big 
difficulty in extending the analysis of the Ornstein-Uhlenbeck process in 
the previous section to time-dependent σ(ί). 
As for the simple Ornstein-Uhlenbeck process, our first question is if there 
exists such a CAR(p) process? We need to have existence and uniqueness of 
X(f) solving (11.18), which we now study. For uniqueness, we proceed as in 
Proposition 1: 
Proposition 3 Let X,(i) for i = 1,2 be two solutions of (11.18) with Xj(0) = 
Xj. TjfXj(i) has finite variance, then 
E [|Χ!(ί) - X2(t)\2
2]1/2 
< | X l - x2|2ellA»2i, 
for every t > 0. Here, | · |2 is the vector 2-norm on Rp and \\ ■ ||2 is the 
associated matrix (operator) norm. 

11.3 CONTINUOUS-TIME AUTOREGRESSIVE PROCESSES 
269 
Proof: Prom the definition of the matrix norm and triangle inequality, we 
find 
| X 1 ( i ) - X 2 ( i ) | 2 < | x 1 - x 2 | 2 + ||J4||2 / 
\X1(s)-X2(s)\2ds. 
Jo 
The rest of the argument is similar to the proof of Proposition 1. 
■ 
Note that 
i,j 
i=l 
from the definition of A, with α^ being the elements of the matrix. 
The above Proposition ensures uniqueness of the solution of (11.18), if 
there exists such in the space of all processes with finite variance. Motivated 
from the considerations on the simple Ornstein-Uhlenbeck process, we guess 
a solution of the form 
X(i) = exp(,4i)Xo + / exp(A(t - s))epa(s) dB{s). 
(H-21) 
Jo 
Here, exp(^4) is the matrix exponential, defined in the usual way as the pxp-
matrix 
^ 
An 
exp{A) = V - r . 
n=0 
Note that we have 
°° Mil™ 
| | e x P ( A ) | | 2 < ^ L p = e x p ( P | | 2 ) 
n=0 
which shows that this exponential is well-defined. Moreover, the stochastic 
integral is defined as the vector in Rp with coordinates given by 
t 
{exp(-A(t 
- s))ep}ia(s) 
dB(s) 
for i = Ι,.,.,ρ, where we use the notation {x}i for the ith coordinate of 
a vector x. Each coordinate of the stochastic integral is thus a real-valued 
stochastic integral of the form we defined in the previous section. We must 
check that the integrand is square integrable in order for this to be well-
defined. To this end, we note that 
L 
|exp(A(i - s))ep|2 < exp(||A||2(* - β)), 

270 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
and since σ(ί) is supposed continuous we find 
f e\WM*-)o*(8)ds< 
oo, 
Jo 
for every t < oo. Hence, we conclude that the vector-valued stochastic integral 
in (11.21) is well-defined. Moreover, each coordinate is a normally distributed 
random variable with mean zero. We next compute its cumulant function in 
order to show that this becomes a p-variate Gaussian random variable. 
We define the cumulant ψ(χ) of the stochastic integral in (11.21) as 
ψ(χ) =1ηΕ exp (ix* [ eA{t-s)epa{s) 
dB{s) 
Since 
x* f eA{t-s)epa(s) 
dB{s) = [ x*eA^-^epa(s) 
dB(s). 
Jo 
Jo 
we find by normality of the stochastic integral that 
φ{χ) 
= 
InElexp 
(i f 
x.*eA{t-s)epa(s)dB(s)\ 
1 
f* 
= 
- - x * / eAsepe*eAsa{s) 
ds. 
2 
Jo 
This shows that the stochastic integral is a p-variate Gaussian random variable 
with a mean zero and variance-covariance matrix defined by 
/ ' eAsepeteAsa{s) 
ds 
In particular, X(£) has finite variance. 
Let us discuss the stationarity of the process X(i) in (11.21). First, if λ,, 
i = l,...,p 
are the eigenvalues of A with respective eigenvectors v,, then we 
find 
P 
p 
exp(Ai)Xo = 2_] xi exp(Af )VJ = \_. xi exp(Aji)vj 
i=l 
i=l 
with Xo = Y%=i XiVi- As long as the real part of the eigenvalues is negative, 
we have that 
lim exp(^4f)Xo = 0. 
t—>oo 

11.3 CONTINUOUS-TIME AUTOREGRESSIVE PROCESSES 
271 
In addition, under this condition on the eigenvalues, Ichihara and Kunita [6], 
Proposition 6.2, prove that the integral 
/»OO 
/ 
eAsepe*peAs ds 
Jo 
is finite, showing that X(i) has a stationary distribution in the case of constant 
volatility σ. We are interested in stationary models, so from now on we assume 
that the eigenvalues of the matrix A all have negative real part. 
We now prove that the explicit dynamics in (11.21) solves the stochastic 
differential equation (11.18). 
Proposition 4 Suppose that σ is continuously differentiable. Then the pro-
cess X(£) defined in (11.21) is the unique solution to (11.18). 
Proof: Let us assume for simplicity that X(0) = 0. Using the integration-
by-parts formula for the stochastic intergral, we find 
/ X(s)ds 
= 
f 
[ 
(eA^-^ep)a(u)dB(u)ds 
Jo 
Jo Jo 
= 
I epa(s)B(s)ds+ 
[ 
[ 
AeA{s-u)epa{u)B(u)duds 
Jo 
Jo Jo 
- i f 
eA{s-u)epa'(u)B(u)duds 
Jo Jo 
= 
[ epa(s)B(s)ds+ 
[ 
[ 
AeA{s-u)epdsa{u)B(u)du 
Jo 
Jo Ju 
- i f 
eA{s-u)epdsa'(u)B(u)du. 
Jo Ju 
In the last equality we have applied the Fubini Theorem (see Folland [5]). 
Hence, after integrating the inner integrals in the last two terms, we find 
f X(s)ds 
= 
ί eA^-^epa(u)B{u)du- 
f 
A-leA{t-u)epa'{u)B{u)du 
Jo 
Jo 
Jo 
+ / 
(A-1ep)a'(u)B(u)du. 
Jo 
Again appealing to integration-by-parts for the stochastic integral, we get 
X(t) - A [ X(s)ds = epa(t)B{t) 
+ f 
AeA{t-u)epa(u)B(u)du 
Jo 
Jo 
_ f 
eMt-u)ep(j/^B^du_ 
ί 
AeA{t-u)epa{u)B{u)du 
Jo 
Jo 

272 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
+ / eA^-^epa'(u)B(u)du- 
[ 
epa'(u)B(u)du 
Jo 
Jo 
= ep (a{t)B(t) 
- I a'(u)B(u)duj 
= I epa(u)dB(u) 
(11.22) 
This concludes the proof. 
■ 
One may wonder if we need to assume that A is invertible in the above 
proof. However, one can show that 
det(A) = —ap > 0, 
so invertibility follows by the definition of the matrix A. 
We continue our analysis of CAR(p) processes with the goal to understand 
the connection with autoregressive time series. Let us spell out the coordinates 
of the vector stochastic differential equation in (11.18). We find the system 
dXi(t) 
= 
X2(t)dt 
dX2(t) 
= 
Xz{t)dt 
dXp-i(t) 
= 
Xp(t)dt 
p 
dXp{t) 
= 
-^akXk{t)dt 
+ 
a{t)dB{t). 
fe=l 
Here we let the fcth coordinate of X(i) be denoted by Xk(t), 
or in other 
words, Xk(t) 
— e£X(i) for k = I,...,p. 
Consider the ordinary pth order 
linear differential equation 
U(P)(t) = - £ 
aku(k-V(t) 
+ ξ(ί) 
(11.23) 
fc=l 
where u(t) is a real-valued function and u^ 
denotes its fcth order derivative. 
We use the short-hand notation £(i) = a(t)B'(t). 
To have (11.23) well-defined, 
we need to have ξ(ί) reasonably smooth. However, from our definition of ξ(ί), 
it is not even existing as we recall that the paths of a Brownian motion are 
not differentiable. However, at this stage we bluntly assume this to be the 
case. 
The standard approach to solve such a higher-order linear ordinary differen-
tial equation is to associate recursively functions to each of the derivatives and 
create a linear system of a first-order differential equation. To this end, define 
vk(t) = u^k^^(t) 
for k = 1,... ,p, where we see that Vi(t) = u^(t) 
= u(t). 

11.3 CONTINUOUS-TIME AUTOREGRESSIVE PROCESSES 
273 
Inserting this into (11.23) yields the equation 
p 
"ρ(ί) = -Σα*«*(*)+ξ(*)· 
fc=l 
But we also have that v'k(t) = Vk+i{t) for k = 1,.. .p — 1. Using the vector 
notation v(t) = (v\(t),..., 
vp(t))* then yields the first-order linear system of 
an ordinary differential equation 
ν'(ί) = Λν(ί)+βρξ(ί). 
(11.24) 
We notice, not unsurprisingly, that this equation in fact is nothing but (11.18), 
where we informally have differentiated Brownian motion with respect to time 
in the term ζ(ί). 
Suppose we want to solve the differential equation (11.23) numerically. A 
discretization of (11.23) will be based on finite differences approximating the 
derivatives. Using forward differencing, we have that the approximation of 
u<fc)(i) is 
k 
t=0 
^ 
' 
for a given time step h > 0. Applying these differences on the differential 
equation (11.23) yields a linear sum of u(t + (p — i)h) for i = 0,... ,p on the 
left-hand side, and a linear combination of u(t + kh) for k = 0,... ,p— 1 on the 
right-hand side. Additionally, we will have the term £(t) on the right-hand 
side. Solving this linear equation with respect to u(t +ph), we see that we 
will find 
p - l 
u(t +ph) = ^2 aiu(t +ih) + ύρξ(ή , 
i=0 
where α^, i = 0,... ,p — 1 are expressible in terms of linear combinations of 
afc, k = 1,... ,p. Note that we may approximate the term ξ(ί) if we interpret 
this as £(t) = a(t)B'(t) 
again using finite differences. Indeed, for a given h 
we find 
P(t\ ~ Mf,B{t 
+ h)-B{t) 
_ a(t) 
ξ{ί) « σ(ί) 
= 
—7re^)' 
where e(t) is standard normally distributed and the equality is in distribution. 
Here we have used the fact that B(t + h) — B(t) is normally distributed, 
with mean zero and variance h. Hence, letting time t run on a discrete grid 
t = 0, h, 2h, 3h,.... and denoting x(k) := u(kh), we find the time series 
p - l 
x(k +p)=J2 
aiX{k + i) + hp-1/2a(k)e(k). 
(11.26) 
i=0 

274 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
We note that e(fc) are independent random variables, since the increments of 
Brownian motion are independent. In conclusion, we have linked the CAR(p) 
process Xi(t) = e*X(i) to an autoregressive time series of order p with time 
dependent variance. Knowing the exact relationship between a, and afc will 
enable us to identify the afc's from a time series estimation of an autoregressive 
model. 
■ EXAMPLE 11.2 
Consider the case p = 2. We find that 
i=0 
^ 
' 
_ 
u(t + 2/t) - 2u(t + h) + u(t) 
h? 
' 
and 
u'w « i D - W 
I )«(*+(Ι-ΟΛ) 
_ 
tt(t + h) - u(t) 
h 
' 
Hence, from the differential equation we find the relationship 
u(t + 2h) - 2u(t + h) + u(t) 
= 
-a2hu(t 
+ 
h)+a2hu(t)-a1h2u(t) 
+h3/2a(t)e(t), 
or, after reorganization, 
x(k + 2) = (2 - a2h)x(k + 1) + (a2h - arf 
- l)x(fc) + 
h3/2a{k)e(k). 
Therefore, we see that the CAR(2) process X(t) = e5X(i) for p = 2 is 
associated with an autoregressive time series of order 2. The regression 
coefficients are 2 — a2h for lag 1 and a2h — a\h2 — 1 for lag 2. These 
coefficients depend naturally on the spacing of the discretization h. 
It is an exercise (see Exercise 11.3) to perform this for the case p — 3. As we 
shall see next, p = 3 is the relevant case for modeling temperatures. 
11.3.1 
An Empirical Study 
We report here the empirical analysis on Stockholm temperature data from 
Chapter 10 in Benth et al. [2]. Our aim is to demonstrate that the proposed 
temperature dynamics fits data very well. For details on the statistical anal-
ysis, we refer to Benth et al. [2]. 

11.3 CONTINUOUS-TIME AUTOREGRESSIVE PROCESSES 
275 
We had available daily average temperatures from Stockholm over a period 
ranging from 1 January 1961 to 25 May 2006, resulting in 16,581 records. The 
measurements on February 29 were removed from the sample in each leap 
year, resulting in a time series of 16,570 observations. As already mentioned 
and shown in Figure 11.1, we first estimate a seasonal function with trend 
Λ(ί). After removing the fitted A(i) from the temperature observations, we 
have a data set of so-called de-seasonalized temperatures that we claim can 
be modeled accurately by a CAR(p) process X(t). 
In Figure 11.2 we have plotted the partial autocorrelation function of the 
de-seasonalized temperatures. The partial autocorrelation at lag k of a time 
series z(t) is defined as the correlation between z(t) and z(t + k) not accounted 
for by the lags 1 up to k — 1. The partial autocorrelation function was in-
o 
k_ o 
Ü o 
I 
100 
Figure 11.2 
The partial autocorrelation function of de-seasonalized temperature 
data. 
troduced by Box and Jenkins (see Box, Jenkins and Reinsel [4] for a recent 
account) to identify the order of an autoregressive process, and we clearly see 
from Figure 11.2 that the three first lags seem to be significantly different than 
zero. From lag four and higher, the partial autocorelation function wiggles 
around zero, pointing to an autoregressive process of order 3 as appropriate. 
After fitting the regression parameters in an autoregressive time series of 
order 3 for the de-seasonalized data, we obtained the estimates Si = 2.043, 

276 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
S2 = 1.339 and 03 = 0.177. In Exercise 11.4 the reader is asked to compute 
the eigenvalues of the matrix A, and it turns out that these values have 
negative real parts, thus yielding a stationary model. 
Removing the autoregressive part of the time series of de-seasonalized data 
leaves us with the residuals. Interestingly, the autocorrelation function of 
these residuals are essentially wiggling around zero, but looking at the au-
tocorrelation function for their squares shows a clear seasonal pattern. Fig-
ure 11.3 shows a seasonally varying autocorrelation function for squared resid-
uals. This points towards a seasonality in the volatility, which we model by 
100 
200 
300 
400 
500 
600 
700 
800 
Figure 11.3 
The autocorrelation function of squared residuals. 
σ(ί). 
Since we have approximately 45 years of daily data, we will have about 
45 observations of residuals at each day in the year. Taking the variance of 
the 45 residual observations on each day gives us the empirical seasonality of 
the volatility observed over a year. We have depicted the seasonal variance in 
Figure 11.4 along with the fitted function σ2(ί) assumed to be 
σ
2(ί) =α+Σ 
{c2k cos(2knt/365) + c2fc+i sin(2fc7rf/365)} . 
(11.27) 
fc=l 

11.4 PRICING OF TEMPERATURE FUTURES CONTRACTS 
277 
T 
1 
1 
1 
r 
J 
1 
1 
1 
1 
L 
0 
50 
100 
150 
200 
250 
300 
350 
days 
Figure 11.4 
The seasonal variance with the fitted σ2(ί). 
We used nonlinear least squares to fit the parameters of σ2(ί) to the daily 
variances. Note that the function a2(t) is periodic, with a yearly cycle. From 
the figure, we note that the variation in temperatures is highest in the winter, 
but interestingly, it is lowest in the early spring and autumn, while it rises up 
in the summer again. The most stable temperatures are therefore observed 
usually in the spring and autumn. 
Using the estimated function σ(ί), we are able to explain the seasonal 
variance, and the remaining residuals show no pattern. In conclusion, we 
have shown that the daily average temperature data observed in Stockholm 
can be fitted using our proposed model. 
11.4 
PRICING OF TEMPERATURE FUTURES CONTRACTS 
We will investigate the pricing of temperature futures contracts in this section. 
As we discussed in the Introduction, there are three different temperature 
indices on which there are written futures contracts at the Chicago Mercantile 
Exchange. We will focus on the simpler one here, namely, the CAT futures. 
Recall that a CAT futures contract is settled on the observed cumulative 
average temperature over a time period [τι,Τ2], that is, the owner of the 
g 6 
.53 
ra 
c 
o 
C/> 
CD 
4 
CO 

278 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
contract receives an amount of money proportional to the index 
I(T1,T2)=JTT(S), 
where s are running over the days in the measurement period. The amount 
of money is received at time r2, after one has measured the index. The value 
of the index times a money conversion factor c > 0 is the amount paid to the 
owner. In return, she has to pay the CAT futures price F(t,T\,T2), 
that is, 
the price agreed at time t < ΤΊ when entering the futures contract. Hence, 
the owner of the CAT futures contract experiences at time τ2 a profit/loss of 
size 
cI(Ti,T2)-F(t,T1,T2). 
It is to be noted that a futures contract is organized so that it is costless to 
buy, but at time of purchase one agrees on a price to be paid at the end of 
the measurement period. This agreed price is referred to as the futures price 
of the contract. The question we want to investigate is what this price should 
be. 
In finance theory, one approach to fix the futures price is by the rational 
expectation hypothesis, which states that at time t < τι, the futures price 
should be so that the profit/loss function has zero expectation, 
E [ c 7 ( r 1 , r 2 ) - F ( i , r 1 , r 2 ) | X ( i ) ] = 0 . 
(11.28) 
Note that we have conditioned on X(t) in the expectation, which is simply 
a mathematical way to express that we include the information about the 
temperatures up until today. When the contract is entered, both the seller and 
the buyer will take into account this information when agreeing on the price, 
so F(t,Ti,T2) 
naturally becomes a function of X(i). Thus, by a reorganization 
of (11.28) we obtain the equation 
F(t,n,T2) 
=οΕ[/(η,τ 2)|Χ(ί)] 
(H.29) 
for the CAT futures price. After commuting expectation and the finite sum 
in the definition of 1{τχ, τ2), we get 
F(t,rUT2) 
= c J 
{Λ(β) + E[e;X(s) |X(t)]} . 
(11.30) 
Thus, to find the CAT futures price we need to compute the conditional 
expectations in the sum above. By normality of our CAR(p) process, this is 
feasible to do analytically. We derive this in the next Proposition: 

11.4 PRICING OF TEMPERATURE FUTURES CONTRACTS 
279 
Proposition 5 For s >t>0, 
it holds that 
E [eiX(s) | X(t)] - eie A ( s- t )X(i). 
Proof: First, we observe that the solution X(s) for s > t to the stochastic 
differential equation (11.18), when starting at time t with the initial condition 
X(t), is 
X(a) = eA(e-t}X(i) + Γ 
eA{s-u)epa(u)dB(u). 
Hence, 
E [eIX(s) | X(t)] = βϊβΑ<θ-*>Χ(ί) + E ί 
eleA^-^epa(u)dB{u) 
= 
eie A ( s- f )X(i). 
This shows the result. 
■ 
We may express the CAT futures price as 
F(t,TUT2) = cYiA(s)+ceU 
£ eAs \ e~AtX(t). 
(11.31) 
Hence, the stochastic dynamics of t H-+ F(t, τχ, τ2) is driven by X(i). Note that 
the futures price is dependent on the vector process X(i), and not only on 
the first component, which would be the CAR(p) process, or, in other words, 
the temperature less the seasonal function. 
Therefore, it is not sufficient 
to observe only today's temperature (today meaning at time t) to find the 
futures price, but one must recover all the coordinates of the vector X(i). 
This is equivalent to saying that the futures price is depending not only on 
today's temperature [which would mean eJX(i)], but also the p—1 previous 
day's temperatures. Autoregressive models has a memory, which we clearly 
see the effect of here. 
If p = 1, then X(i) = e^X(i) = X(t) = T(t) - Λ(ί), and the futures price 
becomes 
F(t, n , 7i) = c J 
A(s) + c { £ 
e- Q l S 1 eQlt(T(i) - A(i)) ■ 
S=Tl 
I. s=Ti 
J 
In this case we have a dependency on the current temperature, and no memory 
in the price dynamics in the sense that the temperatures on previous days do 
not influence the futures price. 

280 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
Let us return back to the general case, and analyze the dynamics of the 
futures price. Since 
eieA("-*)X(t) 
= 
eie A (* _ t ) |e A tX(0) + f 
eA^-^epa{u)dB(u)\ 
= 
e{eAsX(0)+ 
f 
eleA{s-u)epa(u)dB(u). 
Jo 
This implies that 
F(i,r 1,r 2) = F(0,r 1,r 2) + c / ej T 
eA{s-u)epa{u)dB{u), 
Jo 
, = T I 
where 
F(0,TI,T2) 
= c Σ 
A(s) + ce{ £ 
eAsX(0). 
S=Ti 
S = Ti 
But this means that we can write the dynamics as 
T2 
dF(t,ri,n) 
= eel Σ 
eA{s't]epa(t)dB(t). 
(11.32) 
Intepreting dF(t,Ti,T2) 
as the incremental change in the futures price from 
time t to t + dt, we see that this moves as the change in Brownian motion, 
scaled by the temperature volatility σ(ί) and the function 
g(t) = eel £ 
e ^ - ^ e p , 
with t < T\. 
Define the function 
and observe that 
/(«) = eleAvep 
(11.33) 
9(t) = c j / ( » - i ) . 
Since exp(AO) = Jp, with I p being the p x p identity matrix, we have 
H0)=elep = {l> 
H\ 
On the other hand, due to the negative real parts of the eigenvalues of A, 
f(v) 
—> 0 as v —> oo. We have f(v) 
= exp(—ctiv) for p = 1, which is 
an exponentially decaying function. The behavior is completely different for 
p > 1, since then /(0) = 0 and not 1. The scaling of the temperature volatility 

11.4 PRICING OF TEMPERATURE FUTURES CONTRACTS 
281 
σ(ί) will be very different for p = 1 and p > 1. We refer to Benth et al. [2] 
for more discussions of this feature, which can be related to the so-called 
Samuelson effect for futures prices. 
We next consider the problem of pricing a call option written on the CAT 
futures. We suppose that the option has strike price K, at the exercise time 
T <τ\. 
The option will then pay the owner at time τ 
max(F(T,T1,T2)-K,0) 
. 
(11.34) 
The price of this option is given as the present expected value of the payoff 
function in (11.34), that is, 
C{T,K) 
= e " r T E [max(F{T,T1,T2) - K,0)] . 
(11.35) 
Here, r is the risk-free rate of return on a bank deposit. As the CAT futures 
price is explicit in terms of X(i), we can derive a reasonably explicit expression 
for C(T, K). However, we want first to discuss briefly the rationale behind the 
price (11.35). 
From the theory of options (see, for example, Benth [1] for a basic intro-
duction, or Björk [3] for a more advanced treatment), one finds that the price 
of an option is given as the cost of replication. A replicating portfolio, vaguely 
spoken, is defined as a dynamical investment strategy in the underlying (here 
the CAT futures) and a bank account yielding an interest rate r (or, a trea-
sury bond, if one likes), with the value being equal to the option's payoff at 
the exercise time r. As it turns out, there exists a probability Q such that the 
cost or replication can be expressed as a present expected value of the payoff. 
The expectation is computed with respect to the probability Q. Noteworthy is 
that this probability turns the underlying instruments into martingales. The 
expected future value of a martingale is equal to its current value, which is 
the key defining property of such processes. 
As we have derived a price for our CAT futures as an expected value condi-
tional on the current information X(t), it will be a martingale. This means, in 
accordance with the option pricing theory, that we can use P as the so-called 
pricing measure Q above. This validates our pricing rule (11.35) as the cost 
of hedging the call option. 
In order to compute the price C(r, K), let us represent the CAT futures 
price in (11.31) as 
F(t,Tl,T2) 
= X(T1,T2)+a(r1,T2)e-AtX(t), 
(11.36) 
where 
A ( T 1 , T 2 ) - C ^ A ( S ) 
(11.37) 
8=T\ 

282 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
and 
T2 
a(ri,r 2)=ce* J^eAs. 
(11.38) 
S = T l 
We have the following result for the option price: 
Proposition 6 The call option price C(T, K) is given by 
where Φ is the cumulative standard normal distribution function and 
Μ = λ(η,τ 2) + α(τι,τ2)Χ(0), 
for λ(τι,Τ2) and Ά{Τ\,Τ2) 
given in (11.37) and (11.38), resp. Finally, 
Σ2(τ) = 
[T(a(n,T2)e-Asep)2a2(s)ds. 
Jo 
Proof: Since 
X(r) = eATX(0) + [ e^T-s>epa(s) dB(s), 
Jo 
we find 
ίΧτ,Τ!,τ2) 
= 
A(r 1,r 2)+a(r 1,r 2)e-^X(r) 
= 
λ(τι,τ2) + &(τι,τ 2)Χ(0)+ / 
a(TUT2)e-Asepa(s)dB(s). 
Jo 
As we have shown, the stochastic integral is normally distributed, with mean 
zero and variance Σ2(τ). Hence, we have 
i1(r,r1,T2) = /z + E(r)e 
where e is standard normal random variable, and the equality is in distribu-
tion. We have 
erTC(r,K) 
= 
E[max(F(r,ri,r 2)-ii,0)] 
= 
Ε\πΐΆχ(μ-Κ 
+ Σ,(τ)€,0)] 
— f 
1 
fSTFJ _^2 
1 
f°° 
_s2 
( μ - Κ ) ^ ^ = / 
e 
2 ώ + Σ(τ)—p= / 
xe 
^ dx. 
(/ί-/Τ + Σ ( Γ ) ) β _ τ ώ 

EXERCISES 
283 
A direct calculation using the definition of the cumulative probability distri-
bution yields the result. 
■ 
One may price CDD and HDD futures as well, and options on these. How-
ever, they will not give as explicit results as the CAT futures. We refer to 
Benth et al. [2] for a detailed account on the pricing of temperature futures 
and options. 
Acknowledgement: Financial support for the project "Managing Weather 
Risk in Electricity Markets (MAWREM" funded by the Norwegian Research 
Council under grant RENERGI 216096 is kindly acknowledged." 
EXERCISES 
11.1 
Solve the ordinary differential equation 
u'(t) = -au(t) + g(t) ,t > 0, 
with u(0) = «o- Here, g is a continuous function and Q,uo constants. 
11.2 
Compute the characteristic function of the stochastic integral J0 eas dB(s). 
11.3 
Find the associated autoregressive time series to a CAR(3) process 
X{t) = efX(i). 
11.4 
Find the eigenvalues of the matrix 
A = 
Conclude that the corresponding CAR(3) model is stationary. 
REFERENCES 
1. Benth, F. E., Option Theory with Stochastic Analysis - An Introduction to 
Mathematical Finance, Springer Verlag, Berlin (2004). 
2. Benth, F. E., Saltyte Benth, J., and Koekebakker, S. Stochastic Modelling of 
Electricity and Related Markets, World Scientific (2008). 
3. Björk, T., Arbitrage Theory in Continuous Time, Oxford University Press, Ox-
ford (2004). 
4. Box, G. E. P., Jenkins, G. M., and Reinsei, G. C. Time Series Analysis, Fore-
casting and Control, (4th ed.), Wiley, New York (2008). 
5. Folland, G. B., Real Analysis, Wiley Interscience, New York (1984). 
6. Ichihara, K., and Kunita, H., A classification of the second order elliptic operator 
and its probabilistic characterization. Z. Wahrsch. Verw. Geb., 30, pp. 235-
254, (1974). 
0 
0 
0.177 
1 
0 
-1.339 
0 
1 
-2.043 

284 
CHAPTER 11. MODELING PRICING WEATHER DERIVATIVES 
7. Oksendal, B., Stochastic Differential Equations - An Introduction with Appli-
cations (6th ed.), Springer Verlag, Berlin (2005). 

CHAPTER 12 
DECISION THEORY UNDER RISK AND 
APPLICATIONS IN SOCIAL SCIENCES: I. 
INDIVIDUAL DECISION MAKING 
E. V. PETRACOU1 AND A. N. YANNACOPOULOS2 
Department of Geography, University of the Aegean, Greece 
Department of Statistics, Athens University of Economics and Business, Greece 
// the facts do not fit the theory change the facts—A. 
Einstein 
12.1 
INTRODUCTION 
It is the aim of this chapter to provide a very brief and first encounter with 
mathematical modeling in the social sciences. This is a very exciting field, 
combining solid mathematics (ranging from pure to the applied) with funda-
mental concepts from philosophy, political and social theory, in an attempt 
to provide benchmarks for human behavior and understanding motives and 
patterns for human actions. A large part of this field has been developed 
into an independent discipline, that of decision theory in mathematical eco-
nomics, and is now the dominant tool in understanding the phenomena of the 
Mathematical Modeling with Multidisciplinary Applications.
 
285 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

286 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
economy. On the other hand, there is a lot of interest in developing these 
techniques to understand social phenomena not directly related to the econ-
omy, such as human action and institutions, voting patterns etc. This is now 
a very active field, blending techniques from mathematics and statistics (e.g., 
game theory, decision analysis, probability models, optimization techniques, 
differential equations, etc.), physics and engineering (e.g., particle systems, 
mean field theory, etc.) and social sciences (e.g., economics, political science 
and international relations, psychology, sociology, etc.). 
This short introduction covers some fundamental aspects of decision the-
ory, starting from decision theory for single agents, moving to noncooperative 
game theory and finally introducing basic concepts from cooperative game 
theory. We try to motivate the mathematics with examples from the social 
sciences, which in some cases have been the driving force for the creation of 
the mathematical theory. In this effort we introduce important concepts such 
as the concept of utility, expected utility and its maximization as a tool for 
individual decision making. These mathematical tools have universal validity 
and are useful in other branches of applied or pure mathematics as well. 
12.2 
THE FUNDAMENTAL FRAMEWORK 
You cannot expect to start a book on the mathematical theory of the Navier-
Stokes equation without an introduction to fluid mechanics. You cannot ex-
pect to start a book on the mathematical theory of Maxwell's equations with-
out an introduction to elementary electromagnetic theory. You cannot start a 
book on symplectic manifolds and Hamiltonian dynamics without mentioning 
at some point Newton's laws. It is equally impossible to start a chapter on 
the decision theory in the social sciences without a brief introduction to the 
fundamental theoretical concepts of choice theory which at the same time in-
troduce the intricacies and specificities of the subject. This should be a word 
of caution to any student wishing to embark into mathematical modeling of 
any sort: First approach with respect the science that calls for modeling, 
understand the basic concepts (including possible problems and critiques in-
volved) and then offer the mathematics. To paraphrase General Jack Ripper's 
lines from Dr. Strangelove: If in doubt ask questions and read first and shoot 
your equations later! 
In general, decision making is an action based on judgments. Decisions 
are made in certain social and historical contexts, under certain and specific 
conditions and have intended as well as unintended outcomes. As a result, 
decision making both in theory and practice is heavily influenced by the par-
ticular social and historical situations and contexts involved and thus it is 
impossible to separate it from them. It is important to realize that the ways 
in which theories are constructed in social science are always influenced by the 
vantage point of the scientist involved in stating them; there is no such thing 
as the impartial observer in social sciences you are trying to understand and 

12.2 THE FUNDAMENTAL FRAMEWORK 
287 
make scientific statements about a system in which you are heavily involved 
and it is even worse than that: your actions influence the system and may 
well change its state. 
Decision theory, game theory and utility theory constitute mathematical 
theories and normative11 disciplines concerning rational behavior of individu-
als and their interaction. These theories have been developed in connection to 
economics, mainly in the 20th century. The main assumption of rational the-
ory is that human activity is based on reason and individuals make a choice 
among possible actions in order to fulfill their own interest. Then, depart-
ing from this major assumption, we may formulate rules governing human 
decision making, "predict" or explain modes or patterns of behavior, etc. 
Rationality is a major issue in social science. According to the great soci-
ologist Max Weber, there are different kinds of rationalities; these are ideal 
types such as purposive or instrumental, value-oriented, emotional and habit-
ual rationality. Individuals are rational in the sense that they can choose the 
most appropriate or optimal means to fulfill their ends or goals. Logical con-
duct ä la Pareto is: appropriate means for ends, both from the standpoint of 
an individual—subjective—and from other persons—objective. However, the 
dominion of rationality as axiomatic foundations for decision theory should 
neither be taken for granted, nor should be globally acceptable. Rational-
ity reflects a particular type of logic that was developed in Western thought 
especially after the Enlightenment. It can be argued that it is a theoretical 
assumption, a hypothesis made by scientists concerning beliefs, preferences, 
intentions, actions and ends and as an assumption it is subject to criticism. 
Especially, instrumental rationality presupposes that the individual has pref-
erences and because of her knowledge or sufficient information may choose 
the best means in order to achieve her end, which is denned by her own (ex-
pected) utility. Clearly, one may argue against that and construct an equally 
interesting theory, refuting the axiom of rationality. In fact, there are very 
interesting and popular theories starting from this vantage point; the the-
ory of bounded rationality, proposed by the eminent political philosopher and 
economist Herbert Simon,12 is a very good example of that. 
The science of understanding and modeling human decision making can 
be divided into two major parts: individual decision making (decision the-
ory) and game theory and ethics. While the division is sometimes not very 
clearcut, one can generally say that decision theory refers to individual ra-
tional behavior while game theory and ethics refers to the theory of rational 
behavior in a social setting [7]. Individual rational decision theory can be: 
(i) under certainty—the outcome of an action is uniquely predictable, (ii) un-
der risk—objective probabilities with alternative possible outcomes, and (iii) 
11A normative discipline or theory is one that provides rules on how things should be and 
thus forms an idealized view of the world. This in contrast with a descriptive or a positive 
theory, which tries to provide an explanation of how things are. 
12Nobel Laureate in Economics, 1978. 

288 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
under uncertainty—a number of objective probabilities are unknown. Game 
theory refers to individuals who try to maximize their own interests in a ra-
tional way against all the other (rational) individuals while ethics refer to 
individuals which try to promote a common interest even though they have 
different interests [7]. In this short presentation we will try to provide an 
overview of all these aspects, that is, individual decision theory under risk 
and uncertainty, game theory and cooperative game theory (which is an ap-
proximation of what Harsanyi calls ethics). 
One can argue that the whole construction of decision and game theory 
is based upon the philosophical movement of utilitarianism. Utilitarianism 
is a philosophical school of thought of normative ethics whose main claim is 
that the morally appropriate action is the action which produces the overall 
good. The right action is determined by the consequent result (which is 
maximization of utility, satisfaction and welfare). Each individual's well being 
is equally important and the overall well being is a result of all individuals' well 
being. Utilitarianism developed in the 18th and the 19th centuries in Britain 
and the main classical thinkers of utilitarian ethics were Jeremy Bentham, 
John Stuart Mill and Henry Sidgwick. The way to evaluate an action in 
moral terms is Bentham's greatest happiness principle for the greatest number 
of people. 
Utilitarianism has at least two different forms. It is divided into act utili-
tarianism and rule utilitarianism [10]. 
► Act utilitarianism: The right act is the act that produces the most well 
being, i.e., maximizes welfare. 
► Rule utilitarianism: It is a code of moral rules, that if each individual 
follows then she is going to maximize her utility (welfare). 
Act utilitarianism has been the subject of critique, and has been accused 
of promoting injustice and immorality. Rule utilitarianism has also been the 
subject of critique as an unnecessary concept since it is very closely related 
to act utilitarianism. An important question is whether politics and morality 
may be combined in order to contribute to human welfare. 
Utilitarianism has had equally ardent followers as well as opponents. It 
has inspired many philosophical studies, and leading moral philosophers (such 
John Rawls, John Harsanyi, Amartya Sen, etc.) have spent a lot of effort in 
unraveling the perplexing issues arising from the above simple ideas. This 
chapter is by no means the appropriate place to develop this discourse. Since 
a large part of positive political and social theory follows the basic notions of 
utilitarianism we will adopt them here, as a working hypothesis, and present 
their ways of thinking, theorizing and modeling social phenomena. 
A very important difficulty of the general theory of rational behavior is 
how we can turn from individual action to a collective one since collectivity 
cannot be defined as a mere aggregation of individual acts. This is a result of 
the development of rational theory which treats individuals outside of social 

12.2 THE FUNDAMENTAL FRAMEWORK 
289 
and historical contexts and it is based on the concept of homo economicus, a 
selfish individual as an abstract and universal man, ignoring homo sociologus 
(according to Hollis see, e.g., Ref. [2]). The problem of aggregation is very 
important, has led to the development of a branch of decision theory called 
social choice theory and is still under very active consideration. 
As mentioned above, in social sciences the way you construct a theory con-
cerning phenomena may depend strongly on the school of thought with which 
you are affiliated. It is thus important to mention that there are different 
theoretical schools in social sciences. These schools deviate in fundamental 
issues connected with questions such as "what is it possible to know," "how 
and under which procedures is it possible to know," etc. One important school 
of thought is the positivist school, which was developed in the 19th century. 
Positivism is a philosophical approach that argues that there is a unity of the 
scientific method in all sciences and the goal of natural and social sciences 
alike is verification by experiment and prediction. The focus is on systematic 
observation in a deterministic point of view of the world (through scientific 
laws). However, this viewpoint is not universally acceptable. Other schools 
of thought propose different approaches, such as structuralism and humanism 
[8], and reject this unity and these assumptions for the social sciences. Dif-
ferent approaches mean different perceptions of science and interpretations of 
the world and also the reasons for adoption of a certain perspective. 
We hope that the above thoughts have made clear to the reader that in-
dividuals are not alone but they are agents in interactions and groups. Fur-
thermore, they are not self-defined entities but the products of specific condi-
tions. Actors or agents, and that includes scientists and modelers, are shaped 
by and shape social relations in the processes of social becoming and their 
relations are constructed by unequal power relations, domination, coercion, 
enforcement, consensus, cooperation, struggles, plurality and different iden-
tities. So, actors internalize norms and rules; furthermore, this happens not 
in an "one-dimensional" or calculable way. Preferences, information, utility 
maximization, cost and benefit analysis are concepts that are not neutral, but 
bear a very specific ideological meaning: that of accepting the notion of agents 
as selfish maximizers who are free and equal by nature or contract. Clearly 
this is a major, and for some perhaps a simplistic, assumption. 
Based on the above comments and concerns many social scientists have 
refuted the assumptions of rational theory and have raised a serious critique 
against rational choice theory and its significance as well as against decision 
modeling theoretically and empirically [11], [1], [13]. This critique leads us 
to the important conclusion that in order to improve understanding of social 
action under mathematical lenses, we need more elaboration on the social 
theoretical concepts and more empirical research that will play the role of 
experimental facts upon which we can start building more realistic theories. 
However, this word of caution does not diminish the importance of deci-
sion theories as a means of modeling and understanding in social sciences. 
We can, and we should, explore some social phenomena under the prism of 

290 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
decision theories as long as we always keep in mind that what we propose is 
just a model, which at best may provide benchmarks for understanding and 
quantifying some aspects of social life. Surely we cannot expect from math-
ematical modeling in the social sciences the triumphs and global acceptance 
it has in physics or engineering. We have to come to terms with the fact that 
there is not a unique and commonly accepted standpoint from which to start 
our modeling endeavor, and that the results should be treated accordingly. 
However, this does not mean that mathematical modeling in the social sci-
ences is a pointless exercise. On the contrary it may provide very important 
insights as well as very challenging mathematical problems to work on. To 
support the second point we should do no more than mention the extensive 
list of brilliant mathematicians that devoted their careers to such issues. To 
support this point, let us just quote the words of the famous philosopher and 
social scientist Michel Foucault [3]: 
"...like any other domain of knowledge, these sciences (human) may, in 
certain conditions, make use of mathematics as a tool; some of their 
procedures and a certain number of their results can be formalized. 
It is undoubtedly of the greatest importance to know those tools, to 
be able to practice those formalizations and to define the levels upon 
which they can be performed; it is no doubt of interest historically to 
know how Condorcet was able to apply the calculation of probabilities 
to politics." 
12.3 
A BRIEF INTRODUCTION TO THEORY OF CHOICE 
Suppose we wish to choose between two wallets containing a sum of money, 
one containing x euros and one containing y euros, with y > x. Which one 
should we choose? Of course the one containing y. In this simple case our 
choice criterion is easy: count the money in each wallet, see which one contains 
the biggest sum and choose this. Therefore our decision criterion reduces to 
checking an inequality. 
Can life be that easy? No, since our choice decisions are never so simple as 
to reduce to the comparison of two real numbers. Consider the next level of 
difficulty in such a problem: suppose we wish to choose between two baskets 
of goods (say, apples and pears to fix ideas) and let us assume that the first 
basket contains (χχ, £2) kilos of each good and that the second basket contains 
(2/1) 2/2) kilos of each good. Which one should you prefer? The situation is 
even worse if, e.g., x\ > y\ and #2 < 2/2· In this case we need to know which 
of the two fruit we prefer, do we prefer apples to pears and if yes "how much" 
do we prefer one fruit to the other so that we may make our mind up of how 
much more apples shall we have in a basket so that this excess makes up for 
the less pears in this basket? Clearly a simple comparison of two numbers is 
no longer enough, and we need to think of something better! 

12.3 A BRIEF INTRODUCTION TO THEORY OF CHOICE 
291 
Suppose that we need to choose between two baskets of n goods each mod-
eled by two vectors x = (an, ■ ■ ■ , xn) and y — (yi, ■ ■ ■ ,y n). If prefer x to y 
we denote it as x >- y. If we prefer x at least as much as y then we denote it 
as x >z y. But which criterion may be used to make this choice up? The set 
where our choices live is X :— R™ (since the quantities involved are positive 
quantities). We may not define the operation of inequality in X as we have 
done in R+. One way around that is to define a function U : X —> R+ such 
that 
(xi,··· 
,xn) >- (2/1,··· ,2/n) if and only if [/(an,··· ,xn) > U(yi,-·· 
,2/n). 
This function is called a utility function. The use of the utility function is 
to transfer the preference relation >- on X to the operation of inequality > 
on R+. This function contains all the necessary information concerning our 
choice between the two baskets, e.g., it contains the information of how much 
we prefer one fruit to the other and if yes how much so as to decide between 
the various baskets. 
The existence of a utility function is not always guaranteed. There are 
certain properties that a preference relation must display so that a utility 
function may exist. These are the properties of rationality and continuity: 
Definition 9 A preference relation is called rational if 
• For every x € X, x >; x. 
• For all x, y G X either x>zy or y >z x. 
• For all x,y,z 
€ X such that x hy and y >z z we have that x >: z. 
To define continuity we need to define some way of checking when two el-
ements in X are close enough. This requires either a topology, or not wishing 
this level of generality at this stage, just a metric. If we consider X to be a 
metric space, with metric d : X x X —> R+ then continuity of the preference 
relation means that for two elements ι , ΐ ί Χ such that d(x,x) < e, if x > y 
then it also holds that x h V- In the case where X = R™ the metric d can be 
chosen as the Euclidean metric. Not all preference relations are continuous! 
An example of noncontinuous preference relation is the lexicographic prefer-
ence relation which chooses out of every bundle the one that contains most in 
the earliest possible coordinate. E.g., if n — 3 we choose x = (x\, X2, X3) from 
V = (2/1,2/2,2/3) if ari > 2/1 or if an = 2/1 and x2 > 2/2 or if on = 2/1, xi = 2/2 and 
χ3 > 2/3· This reminds us of the way that words are being classified in dic-
tionaries, hence the term lexicographic preference relation. It may be shown 
that the lexicographic preference relation may not be represented by a utility 
function! If it did then we would have an one to one correspondence between 
the rational numbers and the real numbers which of course is not possible! 
We thus have the following important theorem: 

292 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
Theorem 7 
(i) A preference relation which is represented by a utility function is ratio-
nal. 
(ii) A rational and continuous preference relation can be represented by a 
utility function. 
The proof of the first claim is more or less trivial. The proof of the second 
claim is more involved and requires topological tools that may not be presented 
within the scope of the present book. 
12.4 
COLLECTIVE CHOICE 
In certain situations of interest a group rather than an individual must make 
a choice. Eventhough the theory of individual choice is well understood, the 
theory of collective choice is more delicate and complicated. 
Consider the following simple example. Assume that we have 3 individuals 
wishing to make up their minds between 3 choices x,y,z 
£ X. Each individual 
i has a rational preference relation hi that may be represented by a utility 
function Ui- Suppose that the preference relations are as follows: 
individual 1 i hi y hi z 
individual 2 y h2 z h2 x 
individual 3 z h3 x h3 2/ 
Let us assume that the 3 individuals decide to use the majority rule in making 
up their collective preference h· Voting so as to decide between x and y we 
see that there are 2 against 1 which prefer x to y, therefore, the collective 
preference is x h y. Voting between y and z there are 2 votes against 1 which 
prefer y to z, therefore, the collective preference is y h z. Finally, when voting 
between x and z there are 2 votes against 1 that prefer z to x, therefore z h x-
But if we look at the collective preference 
group 
x h j / , y h z, z >zx 
The collective preference is no longer rational! Therefore rationality is a frag-
ile property that may not be satisfied by the group decision. Even though 
the individuals are rational beings, the collective may act irrationally (and 
therefore cannot have a utility function). This example is a very old one, first 
written down by Condorcet, who made this observation in the 18th century, 
and this is a paradox that bears his name. 
The transition from individual preferences to collective preferences is not 
a trivial task. In fact it is a field of very active research since the 1950's 
when Kenneth Arrow proved an important theorem, the Arrow impossibility 

12.5 PREFERENCES UNDER UNCERTAINTY 
293 
theorem. This theorem states that even though individual preferences may be 
rational, this is not necessarily true for collective preferences. This theorem 
has started the very important field of social choice theory which is still an 
active research field. 
12.5 
PREFERENCES UNDER UNCERTAINTY 
In real life we very seldom know the exact content of a bundle x. Depending 
on contingencies, the value of a bundle will vary. For example a ton of oil 
will have different value depending on contingencies, it will have higher value 
under adverse circumstances, e.g., if there is rough political circumstances in 
the Middle East and lower value if not. We would like to extend our theory 
of preferences for the case of uncertainty. 
Our model will be as follows. We consider, to start with, two time instances 
t = 0 and t = 1. At time t = 1 only one of S different states of the world 
will materialize but at t = 0 when we wish to make our minds up we do not 
know exactly which. All we know is the probability of occurrence of each state 
P(State = s) = ps, 5Z s = 1p s = 1, ps E [0,1]. Depending on the state of the 
world each choice made at t = 0 will deliver a different payoff at time t = 1. 
We call xs the payoff of choice x if the state of the world s materializes. We 
will write that as the vector x = (xi, ■ ■ ■ , xs)- One way of considering x is as 
a discrete random variable such that P(x = xs) = ps, s = 1, · · · ,S. 
Suppose now that we have to make up our minds at t = 0 between two 
choices x = (x\, ■ ■ ■ , xs) and y = (yi,··· 
,ys)· Which one should we choose? 
Clearly the probability of occurrence of different payoffs at t = 1 should play 
a role in this decision process. For instance, suppose that we want to choose 
between two lotteries; one paying 30 euros with probability 1/3, 10 euros 
with probability 1/3 and 0 with probability 1/3 and one paying 100 euros 
with probability 1/6, 20 euros with probability 1/6 and 0 with probability 
2/3. Which one is preferable? 
To answer this question we need to define a utility function U : X := Rs —> 
R+ such that 
x y y if and only if U(xi, ■ ■ ■ ,xs) > U(yi, ■ ■ ■ ,ys)-
The existence of this utility function is covered by Theorem 7. However, we 
may do better than that. 
The simplest idea that crosses our mind when trying to compare two lot-
teries is to compare their average payoff (the mathematical expectation of the 
payoff). This is defined as follows: 
s 
E N 
:= ^2PSXS-
s=l 

294 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
We would then pick the lottery which has the highest average payoff, 
x >z y if and only if E[x] > E[y\. 
However, this simple idea has certain drawbacks, coming from the observation 
that there are well-defined random variables that do not have a well-defined 
expectation. One classic example is the St. Petersburg paradox, in which a 
game is defined whose average payoff is infinite so that the above scheme may 
not go through. 
An extension of the above simple and intuitive idea is that of expected 
utility. This idea was introduced by Bernoulli in the 18th century in an 
attempt to explain the St. Petersburg paradox. However, the existence of 
such a concept was only proved mathematically much later, in the 1940's, by 
Von Neumann and Morgenstern in their study of the theory of games. 
Definition 10 A utility function is said to have the expected utility property 
ifU{x) = Yfs=1psU{xs). 
Therefore, if we consider x as the random variable X such that P(X = xs) = 
ps the expected utility function is such that U(x) = E[C/(X)]. 
A very important concept is that of risk aversion. This quantifies how 
much one is willing to undertake risk. This is shown in the properties of the 
expected utility function. 
Definition 11 An agent is said to be risk averse if she chooses a certain 
payoff of value equal to the expected payoff of a lottery rather than the lottery 
itself, i.e., a risk averse agent has an expected utility function such that 
U{E[X])>U(x)=E\U(X)}. 
Functions with the above property are called concave functions. Therefore, 
the expected utility function of a risk averse agent is a concave function. 
Since more is always better this function must also be an increasing function. 
Examples of functions with this property are U\ (w) = ^-\—, 
U2 {w) = ln(w) 
and Uz{w) = ^—, 7 < 1. The coefficients λ and 7 play an important röle in 
these functions. Observe that — ,},,{ 
— λ, and —w
T7?,vl = 7, constant for 
any w. These numbers, called Arrow's measure of absolute and relative risk 
aversion respectively characterize the risk preferences of the agent. 
Expected utility has been the subject of criticism and there are indications 
that the axioms leading to the existence of expected utility may not hold 
for certain circumstances (see, e.g., the discussion of the Allais paradox, or 
the discussion and experimental data leading to alternative theories such as 
prospect theory, etc.) see, e.g., Ref. [12]. Furthermore, other popular descrip-
tion of choice are random utility models, in which it is considered that the 
utility function is perturbed by random terms. Such models lead to interest-
ing descriptions that some time may also lead to parametric models which 

12.5 PREFERENCES UNDER UNCERTAINTY 
295 
are subject to empirical tests. Concerning random utility theory and discrete 
choice theory see e.g. [9]. 
■ EXAMPLE 12.1 
Should I Break the Law or Not? 
Suppose that your morals being weak your only inhibition in committing 
a minor misdemeanor is the fear of getting caught and paying a fine. 
Suppose for instance that you may avoid honoring an obligation that 
will cost you C but if you are caught doing that then you will have to 
pay a fine F. Of course there is a probability of getting caught π and a 
probability 1 — π of getting away with it. What should you do? 
Well, suppose you are utility maximizer and your preferences can be 
modeled by an expected utility U. Suppose your initial wealth is W. In 
trying to figure out whether you will break the law or not you essentially 
face the following lotteries. If you do break the law then you face 
_ J 
W 
with probability 1 — π 
Lcheat -
\
W
_
p 
w i t h probability 7Γ. 
If you don't you face Lhonest — W — C with certainty. You will cheat if 
-^cheat ^ i-^honestf I.e., II 
(1 - TT)U(W) 
+ nU(W 
-F)> 
U(W 
- 
C), 
and choose to be honest otherwise. Clearly, this will depend on your 
personal profile (the utility function U), the sum you are about to escape 
C, the fine you will be subjected to F and of course the probability of 
being caught π. If for instance U{x) = ax + b (a risk neutral agent) then 
a quick calculation shows that you will cheat as long as nF < C. If on 
the other hand the agent is a risk averse agent with U(x) = —e~Xx then 
a quick calculation shows that the agent will cheat as long as ne*F < 
exc — (1 — π). Certain observations of a qualitative nature can be made: 
the more risk averse the agent is the less the fine required, the higher 
the probability to get caught the less is the required fine, etc. 
■ EXAMPLE 12.2 
A Utility Approach to the Theory of Voting 
Utility theory has been extensively used in the theory of voting. In this 
example we give an idea of how the concept of utility may be used to 
model and understand voters' behavior. 
A candidate's program can be thought of as a point in a possibly 
high-dimensional space, called policy space, V. In most models, it is 
considered that V C M.d for some d € N. A policy x then is a point 

296 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
in V c Kd, meaning that a policy x can be represented as a vector 
x = (xi,··· 
,Xd)- Each component of this vector corresponds to the 
candidate's position on one of d issues, e.g., x\ can be public expendi-
tures for health, χ<χ for education, £3 for armaments, etc. 
Consider a set of voters. Each voter i has her personal attitudes 
towards the ideal policy that a candidate should follow. This will again 
be a point in policy space V, denoted by x^ 
= (a^ , · · · ,xd
% ) . A 
voter will be happier with the program of a candidate the closer the 
candidate's program x is to her ideal view a;W. There are many ways to 
measure distance. An obvious choice can be the Euclidean distance on 
Rd, d(x, a;W) = ( ^ · (XJ — Xj )2) 
. This essentially means that for the 
voter, all issues are of equal importance. Of course, it may well be that 
certain issues are of more importance than others. This situation could 
1 /2 
be modeled by using the distance dw (x, x^) 
= ( V ■ Wj (XJ — x?' )2 1 
, 
where w = (tui,··· ,Wd) is a set of weights such that 0 < Wj < 1, 
j = 1, · · · ,d and JZ7=1 Wj = 1, which measure the relative importance 
of the various issues for the voter. Clearly, these weights may depend 
upon the voter, but we avoid the notation w = w^ so as not to clutter 
too much the notation. 
Having denned the notion of distance in policy space, we may now 
define the concept of utility that voter i will enjoy if the candidate is 
elected. We may assume this to be of the form m(x) = 
Ui(dw(x,x^)), 
where Ui : M.+ —> K is a decreasing function. This representation means 
that the utility that voter i will enjoy if the candidate with policy x is 
elected is decreasing as long as the distance of the candidate's policy 
from the voters ideal policy is increasing. Such preferences are called 
Euclidean preferences because they are expressed in terms of a Euclidean 
type distance in policy space. 
Consider now that there are two candidates to choose from: one can-
didate has policy x £ V whereas the other candidate has policy y € V. 
Which one is voter i likely to support? This decision can be modeled as 
comparing policy x with policy y. Under the assumption that the pref-
erence relation can be expressed in terms of the utility function above, 
we can say that 
x >- y if and only if υ^ά^χ,χ^)) 
> i/j(d„,(i/,a;(l))), 
therefore, since Ui is a decreasing function 
x >- y if and only if dw(x,x^) 
< dw{y,x^1'). 
That means that voter i will support the candidate that is closer to 
her perception in policy space. This finding is very intuitive and is 
sometimes (but not always!) supported by empirical findings. 

12.5 PREFERENCES UNDER UNCERTAINTY 
297 
The next level of complication is to add some uncertainty to this 
model. A voter does not always know very well what she wants. Fur-
thermore, there is no certainty that a candidate will abide to her pro-
posed program, in fact, experience often points to the opposite direc-
tion. Therefore, we may modify our utility model to Ui(x) = e,i + 
Ui(dw(x,x^)), 
where en is a random variable, related to the credibility 
of candidate 1 as perceived by voter i, and ut{y) = e^ + 
Ui(dw(y,x^)) 
where 6J2 is a random variable related to the credibility of candidate 2 
as perceived by voter 2. Since a voting decision is reduced to compar-
ing utilities, but now utility itself is a random variable, the decision of 
choosing between the two is an event that has a probability assigned to 
it. In particular, 
Pi(x >- y) := P(voter i prefers 1 to 2) 
= P(en + Ui(dw(x,x{i))) 
> ei2 + 
Ui(dw(y,x{i)))) 
= P(en - ei2 > Ui(dw(y,x^)) 
- 
Ui(dw(x,x(i))) 
= 
l-F(Ui(dw(y,x(i)))-Ui(dw(x,x(i)))), 
where F is the cumulative distribution function of the random variable 
Cji — £ι2· A common assumption is that the distribution of the error is 
Gaussian. Then this model will provide an expression for the probability 
that voter i prefers candidate 1 to candidate 2 in terms of the weights w 
and the opinion of the voter χΜ (these are the personal characteristics 
of the voter) and the proposed policies of the two candidates x and y, 
similar to the probit model. Based on that surveys can be, and are, 
constructed, trying to parameterize the model and fit it to survey data, 
using techniques from statistics. Of course, other choices for either the 
distribution of the error or the utility of the voters are possible and are 
being used. 
■ EXAMPLE 12.3 Willingness to Pay 
Suppose that you have a common good, say, a park, for example, and 
you want to evaluate it. Of course there is no reason why you should, 
but if you must assign a pecuniary value to it, then a reasonable question 
to ask is "if one was not allowed the use of this good how much would 
she be willing to pay in order to use it." 
To answer this question, assume that an agent has certain character-
istics (e.g., age, sex, education level, etc.) which can be summarized in 
the vector z. This vector has as many coordinates as the characteristics 
we take into account for the agent. Furthermore, this agent is charac-
terized by an income, which we call y. This agent derives utility from 

298 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
her income, and we may assume that this utility function is of the form 
u(y) = a-z + ß(y) + e, 
where a is a vector the components of which give some information on 
how the change in characteristics may change the utility level, b is a 
known function and e is a random term. This random term is useful 
in our modeling, since we may not expect all individuals sharing some 
characteristics (as included in z) having similar behavior. Therefore, 
e takes care of possible variability of the utilities of individuals with 
common characteristics z. 
It is very reasonable to assume that the utility of an agent depends 
on the particular state of the world that she is in. If state of the world 
1 is the state of the world in which she has full access to the park then 
her utility level will be of the form 
ui(y) = αι ■ z + ßi(y) + e1, 
where as above a\ is a vector modeling the effect of attributes to the 
utility functions, b\ is a known deterministic function and e\ is a random 
variable. Similarly, if state of the world 2 is the state of the world in 
which she is denied access to the park then her utility level will be of 
the form 
U2(y) = a2 ■ z + ß2{y) +e 2, 
where a2, b2 and e2 have similar meaning as oi, 6i and ei but in general 
αι φ 02, b\ φ b2 and t\ φ e2. 
Suppose now that this agent may gain access to the common good by 
paying an admission fee of W. How much would she be willing to pay 
in order to access the common good? This sum is called willingness to 
pay (WTP) and of course depends on the individual's characteristics z 
as well as on other parameters of the utility function. 
The calculation of W is obtained by a simple utility calculation. If 
she accepts to pay W to access the common good, then her income is 
lowered by that sum and becomes y — W but she is compensated by the 
use of the common good. That means that by lowering her income to 
y — W at state 2 she gets the same utility level that she enjoyed at state 
1 when her income was y. This gives us the equality 
a2-z + ß2(y-W) 
+ e2=a1-z 
+ 
ß1{y)+e1, 
which upon a simple rearrangement gives 
W = y-ß^1(a-z 
+ ß1(y) + e), 

12.6 DECISIONS OVER TIME 
299 
where a — a\ — 0,2, e = t\ — t^· Clearly, willingness to pay is a random 
variable whose distribution depends on the distribution of e. Certain 
choices are possible. For instance, if bi(y) — ln(?/), i = 1,2 then the 
willingness to pay is given by 
W = y (1 — exp (—(a ■ z + e)). 
Then depending on the distribution of e we obtain different models that 
can be quite useful for statistical investigation. If the error terms are 
normally distributed, e ~ λί(0,σ2) 
where σ2 is an unknown variance, 
then we obtain the so-called probit model according to which 
E[W \a,z,y]=y 
ί 1 - exp ( -a ■ z + -σ2 
In the above by E\W \ a, z, y] we denote the expected willingness to pay 
given the values of the characteristics α, ζ and y of the agent. This is 
a very useful result, because since it is a simple parametric formula it 
can be used in questionnaires and surveys, and using the data obtained 
calibrate the model, i.e., find values of the parameters a, such that the 
willingness to pay obtained from a sample with known z and y matches 
this model. Another common choice is to assume that e is logistically 
distributed, in which case we obtain the logit model. Models of this type 
are frequently used in marketing, environmental science, etc., see, e.g., 
Ref. [6]. 
12.6 
DECISIONS OVER TIME 
In many cases of interest we must make a decision and choose between bundles 
received at different time instances. For instance, should I get one euro now 
or should I get it next year? Humans by nature13 are impatient. They will 
rather prefer to have the euro now than wait and get it next year. If for some 
reason an agent B (e.g., the bank) wishes to postpone the payment of the euro 
to agent A until next year there must be some incentive offered by B to A so 
as to persuade her to wait. This incentive will be a higher payment than 1 
euro if paid on the next year, say, 1(1 + r) where r > 0. This is nothing else 
but the concept of interest. 
How can we model this impatience effect within our utility function ap-
proach? Suppose that we have different time instances, t and certain payoffs 
(a sequence of payoffs) (χχ, χ<ι, · · · , xt, · · ·). To set ideas consider two different 
13It is extremely dangerous to invoke arguments concerning the human nature, especially 
in a chapter bearing social science on its title. Human behavior is formed by the society 
the agents live in, however, we ask the reader to allow us this slip of the tongue (especially 
since our work is embedded in a volume on mathematics). 

300 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
payment streams (1,0) and (0,1) The first corresponds to one euro being paid 
at t = 0 and nothing at t = 1, whereas the second corresponds to nothing 
being paid at t = 0 and one euro being paid at t — 1 (i.e., we postpone the 
payment of the euro for one time period). A utility function for the first pay-
ment can be given as U\ := U(l) + <5f/(0) whereas for the second payment 
JJ-2 := U(0) + <5(7(1). Without loss of generality let us assume that i/(0) = 0. 
Then Ui > U? if δ < 1 and this means that we prefer the payment now to the 
payment in the next year. The factor δ < 1 is called a discount factor and its 
presence is very important in choice theory over time. This δ is related to the 
interest rate r, by δ = (1 + r ) _ 1 . 
This discussion may be generalized to any number of time instances. To 
evaluate a payment stream x = (xo,xi, X2, ■ · ■) we may use the intertemporal 
utility function 
oo 
U{x) = ^2slU(xt), 
δ<1. 
(12.1) 
t=o 
This utility function has the property that the relative preference between, 
e.g., (1,0,0, · · ·), (0,1,0, · · ·), (0,0,1, · · ·) is equal to δ, i.e., at all times in 
the life of an individual there is a relative preference of δ between payments 
delayed by one time unit. The intertemporal utility function (12.1) is used 
very often for decision making over time. A fruitful way to understand this 
utility function is to understand it as a functional, i.e., as a mapping that 
maps sequences into the space of real numbers. 
An alternative is to assume that time is continuous and that the payment 
stream is approximated by a continuous function x such that x(t)dt gives the 
payment in the interval [ί,ί + dt). Then the intertemporal utility function is 
given by 
/»OO 
U(x) = / 
e-rtU(x{t))dt. 
(12.2) 
Jo 
This is considered again as a functional, i.e., as a mapping from the space of 
continuous functions to the real numbers. 
The exponential form of the intertemporal utility functions (12.1) or its 
continuous version (12.2) is used extensively in the modeling of preferences 
over time. In fact, it is a form of intertemporal utility function that leads 
to temporally consistent decisions. However, the exponential intertemporal 
utility function is of limited use when decisions over long time periods have 
to be taken. There is support by experimental evidence that when humans 
or animals make decisions over large periods of time, there is not a constant 
ratio of the utility between different time periods. In fact agents tend to be 
more patient in the beginning of the time period than towards the end of the 
horizon. This effect is called hyperbolic discounting. An intertemporal utility 

12.7 THE PROBLEM OF AGGREGATION 
301 
function displaying this hyperbolic discounting effect is 
oo 
U({xs}Zt)=u(xt)+ßY,STu(xt+T), 
/Je (0,1], ί € ( 0 , 1 ) . 
(12.3) 
When ß — 1 this utility function is the exponential utility function. 
■ EXAMPLE 12.4 
The Cost of Climate Change 
Climate change will lead to long term effects that may affect a number 
of generations to come. However, if something is to be done to fight it, 
action should be taken today. Is that worth or not? 
One way to answer this question is to estimate the future costs of 
climate change to the future generations. Let us denote by a the cost 
(losses) incurred to generation ί as an effect of climate change. If we 
assume an exponential discounting scheme, with constant discount factor 
δ per generation, then the value of the future costs calculated in today's 
units is 
N 
i = l 
How should a politician decide whether to engage in action against cli-
mate change or not? Simply by comparing the amount of money she is 
willing to spend on measures, Rw, with R. A very simple decision rule 
would be to decide to take action if Rw "> R and not otherwise. 
Cynical as it may sound this is the way political decision is often 
made. However, this decision rule is not robust since the discount factor 
δ that enters the calculation is to be interpreted as some sort of social (or 
aggregate) discount factor and this is quite difficult to measure! What 
makes things worse is that the value R is very sensitive with respect to 
the choice of δ. The choice of discount factor has sparked a great debate 
among economists, moral philosophers, mathematicians, environmental 
scientists, etc., and has led to the theory of hyperbolic discounting. 
12.7 
THE PROBLEM OF AGGREGATION 
12.7.1 Aggregation of Time Preferences 
One of the important problems in going from the individual to the collective 
is the aggregation of time preferences [4]. The problem is a very natural one 
(see, e.g., Example 12.4). 

302 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
The problem has a nice optimization interpretation. Consider a group of 
agents J, each member of the group having intertemporal utility function 
Ui(x) = / 
Ui(t,x(t))dt, 
Jo 
i e l , 
where the discount type is taken into acount in the definition of the function m. 
For instance, if all the agents have an exponential discount function each with 
discount rate rj, then Ui(t,x(t)) = e~ritüi(x(t)). 
The group is endowed by an 
intertemporal consumption flow X which is to be divided among the group, 
each member of the group getting a portion Xi. Obviously the constraint 
*(*) = £ > ( * ) 
(12.4) 
»ex 
must hold for all t G R+. We are interested in Pareto efficient allocations, 
i.e., in allocations {xi}, i € I of the group endowment process so that all 
available resources of the group are divided between the group.14 In this case, 
if one member of the group increases her income by some amount, another 
member of the group must suffer a decrease in her income. Such a Pareto 
efficient allocation (which may be far from being a fair allocation) can be 
characterized in terms of the following variational problem, 
max.y^ 
\iUi(xj) 
«€X 
subject to the constraint (12.4), for a given choice of weights λ = {Xi}, i e l 
such that Xi € [0,1] and ^2ieIXi 
= 1- This corresponds to an allocation of 
the common resource (consumption flow) X to the members of the group so 
that each member i receives a portion a;,. This would not be the member's 
choice for consumption if she were alone, i.e., it does not maximize Ui. But 
it is the member's choice if the other members of the group are taken into 
account, with a relative weight λ,. In some sense the weighted sum of utilities 
is some sort of social welfare function for the whole group. 
To define the utility function of the representative agent we need to define 
the utility function Ug of a single agent, which is consistent with this Pareto 
efficient allocation. In particular, according to Ref. [4] the group utility func-
tion is such that 
ug(t,X) 
:= 
maxS^XiUi(t,Xi), 
for some choice of Xi € [0,1] such that X)jSi λ» = 1, subject to the constraint 
(12.4). The group intertemporal utility function Ug is given in terms of ug 
Though not necessarily in an equal fashion! 

12.7 THE PROBLEM OF AGGREGATION 
303 
as Ug(X) = /0°° ug(t,X(t))dt 
and of course depends on the allocation {A*}, 
i e l . 
This is a resource sharing problem. By concavity the solution of the 
problem is unique. The sharing of the individual consumption is given by ug 
as 
Xl(t,x(t))=
 
Ti{t
T
xf}) 
2_.ieITi{t,Xi(t)) 
where Ti(t, Xi) := — g i " * / ^ · The group's rate of impatience is given in terms 
of the functions T, according to the rule 
Therefore, the group impatience is a weighted average of the individual dis-
count rates, and the weighting factors are related to the optimum consump-
tion of each individual in the chosen allocation. An important consequence 
of the above result is that even though all individuals may have exponential 
discounting with constant in time discount functions r^, the group discount-
ing may be hyperbolic with increasing (decreasing) in t, rg(t) depending on 
whether the individual utility functions üi are decreasing (increasing) with 
respect to Xi [4]. This gives rise to fluctuations in rg{t) which are driven by 
fluctuations on the consumption Xi(t). 
12.7.2 
Aggregation of Beliefs 
In certain circumstances of interest a group of agents presents inhomogeneous 
beliefs. How can we obtain an estimate for the belief of the group? This is 
a problem which is very intriguing and has been dealt with by a number of 
authors. We present a recent approach to this problem by Golier [5]. The 
basic idea is similar to that employed in the problem of aggregation of time 
preferences, i.e. use of a Pareto optimal allocation through which the collective 
utility function is defined. 
Consider as above a group of agents I, each agent denoted by i. Each agent 
has her own idea concerning the future states of the world s € < S : = { l , · · · ,S}, 
Pi '■= {Pi,s}f=i- The agents derive utility from the consumption of the sharing 
of a common good X = {X(t)}, 
according to a sharing rule {xi(t)}: 
i e l . 
We assume that this allocation is a Pareto efficient allocation, so that there 
exists a vector A = {K}, i ε ΐ , \ € [0,1], Y^ieI \ = 1, such that 
max J^ XiJ^Pi,sUi(xi(t)), 
(12-5) 
subject to the sharing rule ^iejXi{t) 
= X{t). Since X(t) and x,(i) are ran-
dom variables this equation is considered as an equation of random variables, 

304 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
i.e., holding for every s € <S. This allocation of risk is considered as the socially 
optimum according to the chosen sharing rule. 
This problem may be decomposed into S problems, 
max 
y^ \ipisUi(xi(t;s)), 
seS 
subject to the constraint ^2iejXi(t; 
s) = X(t;s) 
one for each state of the 
world.15 Solving the problem for each s € S we denote the maximum by 
v(X(t;s);{p}), 
where by {p} we denote the set of beliefs of the group of 
agents. The solution of problem (12.5) is expressed as the weighted sum 
W = ^2seSv(X(t;s);{p}). 
The quantity W measures the welfare of the 
representative agent. 
It is important to characterize the utility function that represents the repre-
sentative agent. The properties of this utility function depend on the proper-
ties of the function v, which encompasses all the individual subjective beliefs. 
For instance, the utility function of the representative agent has the expected 
utility property if v is such that d QX = 0. The probability of the group, pg 
may be defined via the following relationship: 
Pg,s ^ 
dvg(X(s);P(s))/dX 
pg,a. 
dvg(X(s');P(s'))/dX' 
where of course the condition ^ZsesPg,s 
= 1 must hold, and by P we denote 
the vector of the beliefs (subjective probabilities) of the individuals in the 
group. As before, we assume that this Pareto efficient allocation is compatible 
with a group expected utility function Ug, which is generated by a common 
belief pg = {pg,s}, s e S. 
12.8 
CONCLUSION 
In this chapter we have introduced some basic concepts of decision theory, 
focusing on individual decision theory. In particular, after introducing the 
fundamental theoretical framework of rationality and utilitarianism, we have 
developed the concept of utility theory as a decision tool. We have further 
discussed decision theory under uncertainty, and in particular the theory of 
expected utility and random utility. Their use as a decision making tool in 
the social sciences was illustrated through a number of examples. 
15We have introduced s explicitly into the equations to stress the contingency dependence 
of the state variables. 

EXERCISES 
305 
Acknowledgments 
The authors wish to thank Professor Nicholas Yannacopoulos for his con-
structive comments and enjoyable conversations that maximized their utility 
(in the Benthamian use of the concept). They also acknowledge the useful 
comments of the three referees that led to considerable improvement of this 
chapter. They also wish to thank Dr. Yang for putting this effort together 
and offering them the tribune from which to present this first introduction to 
this exciting subject. 
EXERCISES 
12.1 
(St. Petersbourg paradox) Suppose you wish to participate in the 
following game: You bet 1 euro on a fair coin. If the coin lands tails up in the 
first time you bet 2 euros. If the coin lands again tails up you bet 4 euros. 
It the coin land tails up in the nth play you bet 2™ euros. You win the sum 
of your last bet (and stop) the first time that the coin lands head up. How 
much should you pay as an entrance fee to the game? Show that the expected 
winning from this game is infinite (hence you should not pay this sum as an 
entrance fee) but the expected logarithmic utility of the winnings is finite. 
12.2 
An agent has intertemporal utility u{y\,y2) = 1*0(2/1) + ^0(2/2) with 
δ < 1 and UQ a strictly increasing function. Suppose that this agent has two 
options. One to consume 1 unit now and 0 in the second (2/1,2/2) = (1)0) and 
one to consume 0 now and consume p in the second (2/1,2/2) = (0,p). How 
much should p be so that the second option is preferred? 
REFERENCES 
1. Archer, M. and Tritter J. (eds.), Rational Choice Theory: Resisting Colonisa-
tion, Routledge, London (2000). 
2. Bermudez, J. L., Decision Theory and Rationality, Oxford University Press, 
Oxford (2009). 
3. Foucault, M., The Order of Things. An Archaeology of the Human Sciences, 
Routledge, London (1989). 
4. Gollier, C. and Zeckhauser, R., Aggregation of heterogeneous time preferences, 
Journal of Political Economy, Vol. 113, 878-896 (2005). 
5. Gollier, C, Whom should we believe? Aggregation of heterogeneous beliefs, J. 
Risk Uncertainty, Vol. 35, 107-127 (2007). 
6. Haab, T. C. and McConnel, K. E., Valuing Environmental and Natural Re-
sources, Edward Elgar Publishing, (2002). 
7. Harsanyi, J., Game and decision theoretic models in ethics, in: Aumann R. and 
Hart, S. (Eds.), Handbook of Game Theory with Economic Applications, Vol. 
1, Elsevier, (1992). 

306 
CHAPTER 12. DECISION THEORY IN SOCIAL SCIENCES 
8. Johnston, R. J., Philosophy and human geography: An introduction to contem-
porary approaches. 2nd Ed. Edward Arnold, (1986). 
9. Manski, C. F., The structure of random utility models, Theory and decision, 
Vol. 8, 229-254 (1977). 
10. Mulgan, T., Understanding Utilitarianism, Acumen, (2007). 
11. Shapiro, I., The Flight from Reality in the Human Sciences, Princeton Univer-
sity Press, 2005. 
12. Starmer, C , Developments in Non-expected Utility Theory: The Hunt for a 
Descriptive Theory of Choice under Risk, Journal of Economic Literature, Vol. 
38(2), 332-382 (2000). 
13. Taylor, M., Rationality and the Ideology of Disconnectedness, Cambridge Uni-
versity Press, Cambridge (2006). 

CHAPTER 13 
FRACTALS, WITH APPLICATIONS TO 
SIGNAL AND IMAGE MODELING 
H. KUNZE 1 AND D. LA TORRE 2 
department of Mathematics and Statistics, University of Guelph, Canada 
Department of Economics, Business and Statistics, University of Milan, Italy 
Looking for the definition of "fractals" on the internet, you find fractals 
are sets whose Hausdorff-Besicovitch dimension exceeds their topological di-
mension. 
That description seems very heavy, so we will write instead that fractals 
are complicated, often irregular, sets generally produced by iteration of some 
kind of operation. 
In the next section, we'll see how to construct fractal sets through iterated 
function systems and we will develop an understanding of some odd facts 
about their dimension or size. In the subsequent section, we will see some 
modeling uses of fractals. 
Mathematical Modeling with Multidisciplinary Applications. 
307 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

308 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
1. delete the 
middle third 
4 
2. replace the 
middle third by the other two 
sides of an equilaterial triangle 
2 
3 
Figure 13.1 
Start with the unit line segment and 1. delete the middle third, or 
2. replace the middle third by the other two sides of the corresponding equilateral 
triangle. 
13.1 
ITERATED FUNCTION SYSTEMS 
We develop the ideas through two examples, in parallel. In each case, we 
consider the line segment of length one lying on the interval [0,1] along the 
s-axis. We think of two operations: 
delete the open middle third of the line segment, (§,§), leaving behind 
1. Delete the middle third of the line segment. To be careful, we mean 
delete the open middle third of the line seg 
the closed set [θ, 5] U [|, l] on the :r-axis. 
2. Replace the middle third of the line segment by the other two sides 
of the corresponding equilateral triangle. Introducing the y-axis, our 
object now has corners at the points (|,0), (|,0), and, using some 
geometry, the raised point ( | , 5 ) · 
We illustrate the result in Figure 13.1. A very interesting thing occurs when 
we iterate. That is, repeatedly apply operation 1 to the collection of line 
segments (or sets) produced by the previous application of operation 1. Keep 
deleting middle thirds. At first, you might think you delete everything. That 
is not the case, since the endpoints 0 and 1 will never be in the middle of a 
segment. Similarly, looking at Figure 13.1, after the first iteration, the points 
I and I are endpoints, so they will never be deleted in future steps. In fact, 
an infinite number of points survive the process, for example, all points of 
the form ^ , where n is a nonnegative integer. Similarly, when we repeatedly 
apply operation 2 to the four line segments produced by the first application 
of operation 2, we get a "kinkier" curve. Think about iterating forever. 
Approximations of the objects that result from iterating forever are pre-
sented in Figure 13.2. The object on the left in the figure, produced by 

13.1 ITERATED FUNCTION SYSTEMS 
309 
■■ ■)■ 
■■ 
I M ■■■ 
■■ ■■■ 
Λ\. J
1 «Lc^ 
,J\3 
\»/Y,. 
Figure 13.2 
The middle-thirds Cantor set and the von Koch curve. 
operation 1, is called the (middle-thirds) Cantor set. The object on the right, 
produced by operation 2, is called the von Koch curve. A little thought about 
the figure and the two operations will convince you that the Cantor set is 
precisely the set of points at which the von Koch curve touches the a;-axis. 
These objects feature the hallmark characteristic of fractal sets: self-similarity. 
The Cantor set consists of two shrunken copies of itself, as labeled in Fig-
ure 13.2. If we shrink the entire set by a factor of | , keeping x = 0 fixed, 
we get the left "half" of the Cantor set. If we translate that shrunken copy 
by | units along the x axis, we get the right half. The function that shrinks 
lengths on the z-axis by | without moving x = 0 is given by |a;. To translate 
by | unit, we just add | . The resulting system of functions is 
h{x) 
= 
\x+\ 
Letting S denote some set of points on the a;-axis, we can consider 
MS) = {Mx)\x€S}, 
i = l,2, 
the set-valued analogues of the two maps. Finally, if we denote the Cantor set 
by C, then our initial observation that the Cantor set consists of two shrunken 
copies of itself is expressed as 
C = /i(C)U/ 2(C). 
(13.1) 
We can perform similar work for the von Koch curve, which consists of four 
shrunken copies of itself, as labeled in Figure 13.2. Copy 1 is produced by 
shrinking both x and y by a factor of | , and copy 4 adds a translation by 
| units in x afterwards. Copies 2 and 3 also shrink by | , but involve a 
rotation as well as a translation. For copy 2, for example, we must shrink by 
first, keeping the origin fixed, then rotate by 60° counterclockwise, and finally 
translate by | in the x direction. Notice the order of the shrinking and the 

310 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
rotation when we write down the function: 
Similarly, copy 3 involves a counterclockwise rotation by —60° and a trans-
lation by | unit in x and ^ψ units in y. The resulting system of functions 
is 
Let K be all points in the plane that lie on the von Koch curve. Then we 
conclude that 
4 
K=\jMK). 
(13.2) 
13.2 
FRACTAL DIMENSION 
When you need to find the distance between two objects in the same room, 
you might walk heel to toe and count how many of your feet are needed to 
span the distance. If your foot has size e > 0 and the number you need is 
N(e), then you approximate the distance by N(e) ■ e. Typically, you only 
obtain an approximation because the last little bit of the distance does not 
exactly equal the length of your foot. In order to be able to measure any 
distance, you would need to calculate lim£_>o N(e) ■ e. This notion is similar 
to the calculation of an area via a definite integral, where we approximate the 
area by the sum of areas of rectangles, needing to take a limit to make sure 
that the approximation error approaches zero. In fact, in grade school, we are 
often asked to find the area of a leaf gathered in the school yard. We trace 
it on graph paper, count squares that contain some of the leave, and then 
multiply the area of a grid square e2 by the number of squares N(e) to get 
our approximation. We can combine these two observations in one equation, 
writing 
Size = 
N(e)-eD, 

13.2 FRACTAL DIMENSION 
311 
J k i i * , 
j x i t n , 
- ι ν ί \ η , 
Figure 13.3 Box counting for the von Koch curve. 
where D = 1 if we are finding length and D = 2 if we are finding area, and 
we need a limit to make the equal sign hold. Rearranging, we have 
N(e) 
= 
(Size) · e~D 
ln(Size) + D 
ln(W(e)) 
ln(Size) 
ln(JV(e)) 
= 
ln(Size) + U l n - 
(13.3) 
D 
Ini 
In A ' 
e 
e 
Since In A —> oo as e —> 0 + and ln(Size) is a constant, we get 
D = l i m ^ 2 . 
ε^ο+ 
In A 
This formula for the dimension D is not very helpful to calculate the dimension 
of C and K, since we can only obtain approximations of these objects. Instead, 
we use (13.3), which tells us that a plot of \η(Ν(ε)) versus In A should be a 
straight line with slope D. This observation presents a practical method for 
calculating the value of D, 0 < D < 2: just like the leaf exercise in grade 
school, superimpose grids of with squares of side length e, count square, plot 
(in A,1η(./ν(ε))), and repeat, letting ε get smaller. Fit a line to the plotted 
points, with the slope approximating D. 
Using a computer, we perform the box counting exercise for the von Koch 
curve. See Figure 13.3, and Table 13.1. When we plot the points and fit a 
line, we determine that our approximation of the dimension of the von Koch 
curve is D « 1.306. It turns out that when all of the copies have the same 

312 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
Table 13.1 Box counts for the von Koch curve; see Figure 13.3. 
ε 
I Ν(ε) 
1. 
128 
256 
2 
6 
14 
32 
88 
202 
512 
1204 
shrinking or contraction factor, the dimension can be exactly calculated as 
D = In (number of copies) 
ln(contraction factor)' 
which in this case gives that the fractal dimension of the von Koch curve is 
D = In 4 
ΪΪΪ3 
1.26, 
not far from our box counting result. On the other hand, we can calculate 
that the dimension of Cantor set is D = ^4 ~ 0.63. 
In Ö 
We can summarize, in order to connect to the heavy definition that opened 
this chapter. 
The von Koch curve, even though it lives in the plane, is just a kinky 
line; we say it has "topological" dimension one. The fractal dimension we 
calculated, 1.26, is also called the Hausdorff-Besicovitch dimension (see Ref. 
[1])· 
The Cantor set, even though it lives on a line, is just a bunch of "dust"; is 
has topological dimension zero. The fractal dimension we calculated is 0.63. 
In both cases, we see that the fractal dimension exceeds the topological 
dimension, as stated in that opening definition. 
13.3 
MORE ON THE DEFINITION OF ITERATED FUNCTION 
SYSTEM 
From the examples at the beginning of Section 13.1 we can now draw a more 
general definition of Iterated Function System. Suppose that X is a closed 
and bounded (and then compact) subset of R2; an Iterated Function System 
(briefly IFS) is a finite collection of maps fi : X —> X, i = 1,.. .n, which 

13.3 MORE ON THE DEFINITION OF ITERATED FUNCTION SYSTEM 
313 
satisfy the inequality 
\\Mx)-Mv)\\<Ci\\x-y\\ 
(13.4) 
for certain Cj G [0,1) (see Refs. [1-3]). When a function fi holds the property 
shown in (13.4), we say that fi is a contraction and that Ci is its contraction 
factor. Roughly speaking, when a function /, is a contraction then it "shrinks" 
the distance between the vectors x and y and the one between the images /, (x) 
and fi(y). The following theorem shows how it possible to construct fractals 
and self-similar objects starting from an IFS. 
Theorem 8 Given an Iterated Function System {/i, /2, · · ·, /«} there exists 
a unique compact subset A C X which satisfy the equation 
n 
A=\J 
fi(A). 
(13.5) 
i=l 
The set A is called the attractor and (13.5) states that it is a self-similar object, 
that is it is union of shrunken and distorted copies of itself. The examples 
showed in Section 13.1, namely, the Cantor set C and the Sierpinski gasket 
K, are two examples of attractors of an IFS. We see that (13.1) and (13.2) 
are just particular cases of (13.5). 
Of course a crucial question is how to determine, once an IFS is fixed, its 
attractor (or at least an approximation of it). The algorithm to reconstruct 
A consists of a list of steps which, as result, generates a sequence of sets 
approximating A: starting with any set AQ C X, let us construct the set A\ 
by taking the union of all images fi(Ao), i — 1... n, that is, 
n 
A1 = \J MAo). 
(13.6) 
i=l 
It is now possible to repeat the same calculations starting from A\ and gen-
erating the set A?, in the following manner: 
n 
A2 = {Jfi(A1). 
(13.7) 
i=l 
In general we can construct the sequence 
n 
At+i = U fi(At), 
(13.8) 
i=l 
and a theorem says that the goodness of the approximation of A by At in-
creases when t tends to +oo. 

314 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
Figure 13.4 
The Sierpinski gasket. 
ΔΑ 
Figure 13.5 
A sequence of approximating sets for the Sierpinski gasket. 
■ EXAMPLE 13.1 
A well-known example in real applications is the Sierpinski gasket shown 
in Figure 13.4. The Sierpinski gasket A is self-similar with respect to 
the IFS {Λ,/2,/3} acting on R2, where fi(x,y) 
= \{{x,y) - P) + Pi, 
i = 1,2,3, and the points Pi, Ρ2, Ρ3 are the vertices of the outer triangle. 
Figure 13.5 shows the first four steps of a sequence of sets approximating 
the Siepinski gasket A. 
Reconstructing the attractor A of an IFS is, in general, time-consuming and 
inefficient from a computational point of view. At each step a new figure 
is constructed by applying each fi to the current figure and then taking the 
union of all the results. The next section shows how to use the so-called chaos 
game to determine an approximation of the attractor A. This requires the 
notion of Iterated Function System with Probabilities. 
13.4 
THE CHAOS GAME 
We are now going to extend the previous definition of Iterated Function Sys-
tems to a more general settings. As in the previous section, let us consider 
a set of contraction mappings /» : X —► X, i = 1... n, where Cj is the con-
traction factor and X is a compact subset of R™. With respect to the above 
definition, let us suppose that to each map fi there is associated a probability 
Pi G [0,1], i = 1.. .n, Y™=xPi = 1; in other words, in this context we add 

13.4 THE CHAOS GAME 
315 
"weights" to each function fi through the set of probabilities pi. The union of 
a collection of contractions fi together with associated probabilities pi defines 
an Iterated Function System with Probabilities (briefly IFSP). The introduc-
tion of a set of probabilities enriches the mathematical complexity, providing 
then the possibility to represent more complex objects. 
Given a vector xo € X, consider the random dynamical system generated 
through the sequence 
xt+i = fi{xt), 
(13.9) 
where the map fi is taken from the set {/i,/2, · ■ ■ fn} according to the set 
of corresponding probabilities {pi,P2, ■■■,pn}- At each step the choice of one 
fi depends only on the set of probabilities and it is independent from the 
previous choices; given xt the next value x i + 1 of the sequence is obtained by 
applying only one map fi which is chosen according to the set of probability 
Pi, independently from the previous steps. 
The process of producing the sequence (13.9) is called the chaos game and 
the use of the word chaos is justified by the fact that the set of probabilities 
affects the behavior of xt. The union of all xt, that is UtJ^i2-*} ' s called the 
orbit; it is worthwhile to notice that different sequences of probabilities gen-
erate different element xt and, therefore, different orbits. Once the sequence 
of probabilities Pi is fixed, then the elements of the sequence xt are deter-
mined and this allows us to pose the question whether or not this sequence is 
convergent to a limit I. 
Unfortunately, there are infinite orbits associated with the chaos game 
and this implies, for those sequences which are convergent, the existence of 
several limit points. It is, in general, misleading to talk about the convergence 
of an orbit toward a limit—because this is not unique and depends on the 
probabilities pi—and it is more correct to take all possible limit points of 
all possible converging paths. Some of them will occur more frequently than 
others and this means that, associated with the set of all possible limit points 
li, there is a set of frequencies &. Each frequency & describes how many orbits 
will tend to Zj when t —> 4-co. This allows us to conclude that a reasonable 
definition of limit of a chaos game can not be merely reduced to a number, 
but involves the construction of the set of all possible limits with associated 
frequencies. 
There is a strong relationship between one orbit and the invariant set A of 
the Iterated Function System {/i, /2,... /„}; it is possible to prove that each 
orbit is dense in A, allowing the possibility to reconstruct the attractor A of 
an IFS by simulating just one orbit of the above random process (13.9). 
■ EXAMPLE 13.2 

316 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
Figure 13.6 
Play the chaos game to draw the Twin Dragon: 11 points, 1000 points, 
3000 points, and many more points. 
We define theIFSP 
h(*,y) = (£5 "o°55)(^) + ( _o 1)' P l = 0· 5' and 
/*(-» - (£^)(;Μί)·*=-
To understand the transformation, write the matrix as 
(s^)-(ri)(*Ä) 
^ 
-v—1· 
"^ 
v 
* 
rotate CCW 
shrink 
by 45° 
by ^ 
In this case, the probabilities each equal 0.5, so when we play the chaos 
game, we choose either of the maps with equal likelihood. The IFS acts 
on S = [—3,3] x [—3,3]. Starting with XQ = (0,0), we generate the 
sequence of points xt via the chaos game. In Figure 13.6, we illustrate 
the result, drawing small circles centered at the point x^. The light gray 
circles correspond to points that were plotted by the function f\ and the 
darker gray circles correspond to points that were plotted by the function 
/2- As we move from left to right across the first four pictures in the 
figure, the number of plotted points increases. Some form appears after 
just 1000 points (the second picture). After 100000 points have been 
plotted, we essentially see the attractor (the fourth picture). Thanks 
the coloring, we see that the attractor indeed consists of two shrunken 
copies of itself. By reading the above description of the action of the 
matrix in /1 and /2, you should be able to verify that the light gray 
copy is /1 applied to the entire attractor, and the dark gray copy is /2 
applied to the entire attractor. This attractor is called the Twin Dragon. 
We can approximate the dimension of the Twin Dragon by using box 
counting. The process is illustrated in Figure 13.7 with the box counts, 
obtained from a computer, tabulated in Table 13.2. 
When we fit a 

13.4 THE CHAOS GAME 
317 
Figure 13.7 
Box counting for the the Twin Dragon curve. 
Table 13.2 
Box counts for the Twin Dragon; see Figure 13.7. 
ε 
| ΛΓ(ε) 
1 
I 
I 
I 
16 
1 
32 
1 
6i 4 
128 
256 
4 
13 
33 
112 
388 
1380 
4987 
18427 

318 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
line to the computer-obtained box counts in Table 13.2, we find that 
the slope is 1.739 « D. If we discard the points corresponding to larger 
boxes (since we are more interested in small values of e), we can nudge 
the approximation higher. Of course, the true fractal dimension of the 
Twin Dragon is 
ln(#copies) = 
ln(2) 
= 
ln(i) 
ln(V2) 
' 
which should make sense because the Dragon has no holes in it. We say 
it is a space-filling curve. 
■ EXAMPLE 13.3 
We define the IFSP 
, Pi = 0.01, 
χ
0
6 Y 
P2 = 0.07, 
0 14 ) ' P3= 
°· 0 7' 
a n d 
n „ ) , PA = 0.85, 
acting on the unit square [0,1] x [0,1]. The functions in this IFSP are 
much stranger looking than those in earlier examples, and we lose all 
ability to interpret them geometrically. We can readily verify that the 
entries in the matrices are such that each fa is contractive. We play the 
chaos game again and produce the remarkable attractor in Figure 13.8, 
called (Michael) Barnsley's spleenwort fern. Since the IFSP has consists 
of four functions, the fern must be the union of four shrunken copies 
of itself. The first function, with only one non-zero entry, collapses 
the entire fern to the stem. Notice that this function is chosen with 
probability 0.01; this choice means that we do not visit the stem so 
much when we play the chaos game. The fourth function is selected 
85% of the time. This choice is made because, as we see from the figure, 
we need the most points to plot this largest copy. The fern has holes. 
Its fractal dimension is less than 2. Figure 13.9 and Table 13.3 present 
the plots and counts. When we fit the box counts to a line, we find that 
the fractal dimension of the fern is D ~ 1.715. 
*(-) = (s a
0
M)(;)
+(s) 
f2(x,y) = (0°2
2
3 ~ 0°f 2
6)(y) + ( 
fs(x,y) = (~^Jf °0f4)(x
y) 
+ ( 
Mx,y) = (_°^5
4 Π5 ) ( * ) + ( 

13.4 THE CHAOS GAME 
319 
Figure 13.8 
Barnsley's spleenwort fern consists of four shrunken copies of itself. 
4 
4 
Figure 13.9 
Box counting for the Barnsley's spleenwort fern. 
ε 
1 
I 
Ϊ 
I 
\6 
Ψ 
64 
1 
128 
256 
N(s) 
4 
9 
28 
94 
316 
1113 
3975 
13989 
Table 13.3 
Box counts for the spleenwort fern; see Figure 13.9. 

320 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
v=Tu 
U(X) 
target 
signal 
3 shrunken 
and distorted 
copies 
v(x) 
combine 
somehow 
Figure 13.10 
The signal approximation process. 
13.5 
AN APPLICATION TO IMAGE ANALYSIS 
Remembering (13.5), suppose that a target set S is very close to the attractor 
A. Then we expect that each fi(S) « fi(A), which means 
n 
n 
n 
S « A = (J MA) « (J MS) => S « U Λ(5). 
We interpret the final equation as saying that S1 is approximated by shrunken 
and distorted copies of itself. 
We first think about a signal u(x). We could write "function" instead of 
"signal," but we want to start thinking in terms of images, and a signal is a 
one-dimensional image. We are motivated to pursue the following idea: create 
some shrunken copies of the signal, adjust the copies somehow, and try to 
recover an approximation of the original signal, as in Figure 13.10. The full 
process is described by v = Tu, where T is called the fractal transform. We 
flesh things out with some numbers by considering a particular situation. We 
pick the two-function IFS {/i, fa} = { jgz, j^x + ^ } o n l = [0,l]. We see 
that 
Wl : [0,1] -» [0,0.6] and w2 : [0,1] -► [0.4,1], 
so both functions are contractive. Shrink a signal u(x) to produce two copies, 
one sitting on fi(X) 
= [θ, ^ ] and the other on fa(X) = [^, l], as depicted 
in Figure 13.11. The equations for the shrunken copies in the picture are 
ai(a;) 
= 
«(/Γ 1^)), 
z e / i p O , 
a2(x) 
= u(f2\x)), 
x€f2(X). 
Now, we modify the "gray values of the signals" (just think "function values") 
by using gray level maps. For example, we might multiply all values a\{x) 

13.5 AN APPLICATION TO IMAGE ANALYSIS 
321 
target signal 
y=u(x) 
\ 
y=a,(x) 
^ 
Copy 1 
1— 
\ v = a 2 ( x ) 
Copy 2 
" ' 
'1 
*-
.4 
.6 
1 
X 
Figure 13.11 
Make two shrunken copies on fi(X) and h{X)-
y=v(x) 
deal with overlap 
somehow! 
Figure 13.12 
Adjust and combine the shrunken copies to get y = v(x). 
by | and add | , and multiply all values 02(2;) by | . Then we combine the 
shrunken copies, dealing with overlaps. In Figure 13.12, we just add values 
on the overlap region. The adjusted copies of the signal have equations 
61 (x) 
= 
φι(αι(χ))=φ1(υ,(/ϊ1{χ))), 
χ € 
fi(X), 
b2(x) 
= 
φ2(α2(χ))^φ2(η(^\χ))), 
x € 
f2(X), 
where 
1
1 
3 
ViW = 2t+ 2 a n d 
φ2^ 
" 1L 
The function v{x) = (Tu)(x) is produced by the two-function IFS with gray 
level Maps = IFSM. T is called a fractal transform. 

322 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
When T is iterated on some initial signal uo(x) defined on [0,1] we obtain 
a sequence of signals {un(x)} 
that converges to a signal u, the attractor and 
unique fixed point of T. 
We can construct a general T in this fashion, using functions fi(x) = SiX + 
dl, with Ci — \si\ < 1 so fi is contractive, and gray level maps φί{ί) = atf + ßi, 
i = 1,..., n. In this case, we can prove that T is contractive (with respect to 
the "£2 metric") when Σ " = 1 \^i\ai 
< 1-
The inverse problem for function approximation using IFSM is stated as fol-
lows. 
Inverse Problem: Given a target function (or image) u and ε > 0, find an 
TV-map IFSM (w,§L) (N = N(e) < oo) with associated fractal transform Τε 
such that 
/ (u(x) — (Tsu)(x))2dx 
<ε. 
Jx 
The expression on the left of the inequality is the squared C2 distance between 
u(x) and (Teu)(x), so the inequality says that we want these two signals to 
be arbitrarily close together (with distance measured in this way). 
■ EXAMPLE 13.4 
Consider the function u{x) = y/x for x in X = [0,1]. Suppose we plan 
to use a four-function IFS. We define 
1" 
°'4 , X2 = 
"1 2' 
.4'4 
, χ3 = 
'2 3' 
.4'4. , X2 = 
'3 
Ϊ'1. 
Then we want to define our maps so that 
fi-.X^Xi, 
i = 1,2,3,4, 
and 
4 
\Jfi(X)=X. 
i=l 
If we stick to affine maps, there are two choices for each map fi{x): it 
either flips X around or not. The formulas are given in Table 13.4 
The left picture in Figure 13.13 illustrates u(x) = y/x and the four 
subintervals Xi, i = 1,2,3,4. The right picture illustrates 
u(f~l(x)), 
i = 1,2,3,4, the shrunken copies of u(x) on each of the subintervals X{. 
The green curves are the "no flip" choices, and the brown curves are the 
"flip" choices. Next, we add in the affine gray level maps 
<t>i(t) = atf + ßi, i = 1,2,3,4, 

13.5 AN APPLICATION TO IMAGE ANALYSIS 
323 
Table 13.4 
The candidates for the functions in our IFS. 
No Flip 
Flip 
Action 
fi(x) 
Mx) 
Mx) 
1 r 
1 
1 
4 
4 
1 
2 
4 
4 
1 
3 
4 
4 
Mx) 
Mx) 
1 
1 
x 
4 
4 
2 
1 
4 " 4 X 
3 
1 
4-r 
4X 
fi:X^Xi 
/ 3 : X H-+ X3 
/ 4 : X h-+ X 4 
0.4 
06 
0 
0.2 
04 
0.6 
0.8 
1 
Figure 13.13 
(Left) The target image y = u(x) = y/x and (right) the shrunken 
copies on Xi. 

324 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
Table 13.5 
Subinterval 
Xl 
Xl 
Xi 
Xi 
X3 
X3 
X* 
XA 
Minimizing values of the gray 
Minimal Collage Distance 
0.000000000 
0.000459942 
0.000022730 
0.000050309 
0.000016374 
0.000026039 
0.000012571 
0.000017450 
level map parameters a, and ßi 
Best on 
0.500000000 
-0.465708264 
0.249142477 
-0.245125030 
0.191245540 
-0.189417620 
0.161160270 
-0.160063020 
Best ßi 
0.000000000 
0.643805510 
0.443380723 
0.772892391 
0.661744743 
0.915520170 
0.827175681 
1.041324530 
Flip? 
No 
Yes 
No 
Yes 
No 
Yes 
No 
Yes 
0 
to get an IFSM. Although we wrote it as a sum last time, on each 
subinterval Xi the fractal transform of u(x) is 
(Tu)(x) = φί{η{^\χ))) 
= aiU{fr\x)) 
+ ßu 
x € X,. 
The distances of interest are 
Ai= 
[ ((Tu)(x) - u{x)f dx = [ 
(a iu(/r 1(a;))+/3 i-u(x)) 2dx. 
JXi 
JXi 
Notice that Δ, is a quadratic function of the two unknown gray level 
map parameters cti and ßi. So, when we use calculus to minimize Δ^, 
the equations 
dAi 
dAi 
-=— = 0 and —r-
oon 
dßi 
give a linear system of two equations in the two unknowns on and /?,. 
Using a computer, we get the results in Table 13.5. For each subinterval, 
the best choice is the "unflipped" fi\ why does this make sense for this 
example? In Figure 13.14, we present the graphs of y = u(x) and y = 
(Tu)(x). 
Notice that the four pieces comprising Tu(x) are shrunken and 
distorted copies of u(x). The whole point of all of this is we can pick any 
function UQ{X) on [0,1] and iterate Γ: un(x) = (T°nuo) (x). The iterates 
should get closer to u(x). Figure 13.15 shows what happens when we 
start with uo(x) = 0. If we repeat the entire process, increasing the 
number of IFS maps to 8, say, then all errors decrease, as illustrated in 
Figure 13.16. 
Note that this process works well because the the original signal is a monotone 
function. If you repeat the same exercise with the nice function u(x) = sin^a;) 
on [0,1], the results are terrible. This fact leads to the modified algorithm: 
• Divide X into parent intervals Jj. 

13.5 AN APPLICATION TO IMAGE ANALYSIS 
325 
0.4 
0 i 
Figure 13.14 
The target signal y = u(x) = yfx and the fractal transform y 
(Tu)(x) consisting of four shrunken and distorted copies of u. 
Figure 13.15 
Iterating the fractal transform T (consisting of four functions) on 
the initial function y = uo(x) = 0. 

326 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
Figure 13.16 
Iterating the fractal transform T (consisting of eight functions) on 
the initial function y = uo(x) = 0. 
• Divide X into child intervals Jj. The child intervals are smaller 
than the parent intervals. 
• Each parent ij is mapped to each child Jj by two known contrac-
, · 
flip 
j 
no flip 
tion maps, w\j y and w^ 
J 
F. 
• For each child, consider each parent with both the "flip" and "no 
flip" case, finding the gray level map φί that minimizes each collage 
distance. 
• For each child, the minimum of all collage distances considered 
determines the "best" parent, a, β, and whether it is flipped or 
not. The collection of these four parameters for all children defines 
a fractal transform that gives the minimal collage distance for this 
parent/child partitioning. 
The method is call Local Iterated Function Systems with gray level Maps: 
LIFSM. 
The LIFSM algorithm can do remarkable things with two-dimensional pic-
tures. The entire process can be explained in three pictures, a few words, 
and one equation. Pick a target image u(x,y). 
Divide the image into parent 
blocks and child blocks, and let fij take parent Pj to child Cj, as described in 
the three pictures of Figure 13.17. There are eight ways for /y : Pj —> Cj, 4 
rotations x 2 flips. For each child C, we consider each parent and each choice 
of /, finding a and β that minimize 
Δ = [ 
( a U ( / - 1 ( x , 2 / ) ) + / 3 - « ( ^ y ) ) 2 d A 
Jc 
For each child, we store the parent number, orientation for /, a and β; this 
collection of values defines the fractal transform T. 
When we repeatedly 
apply T to any initial image, the iterates approach an image that resembles 
the target image u(x,y). 

13.5 REFERENCES 
327 
Parent 
~-\ f 
V 
_...£] 
Child, 
Divide image into 
parent blocks 
Divide image into 
(smaller) child blocks 
Send Parent P, 
to Child d 
Figure 13.17 
The LIFSM algorithm for images. 
EXAMPLE 13.5 
We perform the LISFM algorithm on a 256 x 256 grayscale image, using 
parent blocks that are 8 x 8 pixel2 in size and child blocks that are 4 x 4 
pixel2 in size. To repeat, for each child, we store the best parent number, 
the orientation change, and the a and ß values in the gray level map 
4>{t) = at + ß. On the left in Figure 13.18, we present the input image 
of an assortment of peppers. On the right, we show some parent-child 
pairs that are identified in the process. Each row on the right shows 
the parent shrunk to child size ( 4 x 4 pixels2), the orientation change 
and gray level map applied to the shrunken parent, and the child. The 
transformed parent and the child look very close, which is the essence of 
our discussion. Finally, in Figure 13.19, we start with a different image, 
this time of a frog, and iterate the fractal transform T on it. We show 
the first four iterations. 
REFERENCES 
1. Barnsley, M.F., Fractals Everywhere, Academic Press, New York (1989). 
2. Hutchinson, J., Fractals and self-similarity, Indiana Univ. J. Math., Vol. 30, 
713-747 (1981). 
3. Kunze, H., La Torre, D., Mendivil, F., and Vrscay, E.R., Practal-Based Methods 
in Analysis, Springer, New York (2012). 

328 
CHAPTER 13. FRACTALS IN SIGNAL AND IMAGE MODELING 
Shrunken 
Parent 
Transformed 
Parent 
Child 
flip+rotate 270 
£»=0.92 
rotate 180 
a=1.00 
ß =0.00 
flip+rotate 90 
or=0.73 
£=0.03 
Figure 13.18 
the algorithm. 
The peppers input image and some parent-child pairs identified by 
Figure 13.19 
Iterating the peppers fractal transform on the initial image of a frog. 

CHAPTER 14 
EFFICIENT NUMERICAL METHODS FOR 
SINGULARLY PERTURBED 
DIFFERENTIAL EQUATIONS 
S. NATESAN 
Department of Mathematics, Indian Institute of Technology Guwahati, India 
14.1 
INTRODUCTION 
Singular perturbation problems (SPPs) arise in several branches of applied 
mathematics which include fluid dynamics, quantum mechanics, elasticity, 
chemical reactor theory, gas porous electrodes theory, etc. The presence of 
small parameter (s) in these problems prevents us from obtaining satisfactory 
numerical solutions. It is a well known fact that the solutions of SPPs have a 
multiscale character. That is, there are thin layer(s) where the solution varies 
very rapidly, while away from the layer(s) the solution behaves regularly and 
varies slowly. Even in the case where only the approximate solution of the 
singularly perturbed boundary-value problem is required, classical numerical 
methods, such as finite difference schemes and finite element methods exhibit 
unsatisfactory behavior. This arises because the accuracy of the approximate 
Mathematical Modeling with Multidisciplinary Applications.
 
329 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

330 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
solution depends inversely on the perturbation parameter value and thus it 
deteriorates as the parameter decreases. Therefore, the numerical treatment 
of SPPs gives major computational difficulties. 
Various finite difference schemes have been proposed in the literature to 
guarantee stability of the schemes for all values of the perturbation parame-
ter. Careful examination of numerical results from such schemes on uniform 
grids shows that, for fixed (small) values of the perturbation parameter, the 
maximum pointwise error usually increases as the mesh is refined, because 
of the presence of the boundary or interior layer, until the mesh diameter is 
comparable in size to the parameter. This behavior is clearly unsatisfactory. 
Therefore, a separate treatment is necessary to deal with such problems. 
It is well known that most of the incompressible fluid flow problems in 
fluid dynamics are modeled by the Navier-Stokes equations. Consider the 2D 
Navier-Stokes equations: 
( 
clii 
1 
— --Au 
+ (u-V)u 
+ Vp = 0, 
Ω = (0,1) 2χ(0,Τ], Τ > 0, 
< V - u = 0, 
(14·!) 
u = 0, 
on the boundary 9Ω, 
where R is the Reynolds' number. The velocity u(x, y, t) of the fluid is nonzero 
in the interior of the domain Ω as well as close to the boundary, whereas it 
will become zero on the boundary. That is, the nonzero velocity will become 
zero within the small region closer to the boundary, which is referred as the 
boundary layer. More precisely, the boundary layer is defined as the region of 
the independent variable, in which the dependent variable changes rapidly in 
order to satisfy the prescribed boundary conditions. The linearized version 
of the stationary boundary-value problem (BVP) corresponding to (14.1) is 
given by 
f -sAu 
+ a-Vu + bu = f, 
Ω = (0, l) 2, 
{ 
(14-2) 
[ u = 0, 
on the boundary 9Ω, 
where 0 < ε <C 1 denotes the viscosity of the fluid. The sign of the convection 
coefficient a determines the location of the boundary layers. In general, the 
boundary layers locate at the outflow boundaries. Here, the convection coef-
ficient a dominates the viscosity coefficient (diffusion parameter) ε, therefore, 
these problems are classified as convection-dominated BVP. In general, in dif-
ferential equations the highest-order derivative is more significant than the 
lower-order derivatives, whereas this phenomenon does not hold for SPPs. If 
one assumes that the diffusion parameter ε = 0, then the second-order elliptic 
BVP (14.2) becomes a first-order hyperbolic PDE and it does not satisfy all 
the boundary conditions. This causes difficulties in finding asymptotic as well 
as numerical solutions. 

14.2 CHARACTERIZATION OF SPPs 
331 
The rest of the chapter is organized in the following manner: Section 14.2 
studies special characteristics of SPPs, and the asymptotic approximate so-
lution. The difficulties in obtaining uniformly convergent numerical approx-
imate solutions and the exponentially fitted difference scheme are studied in 
Section 14.3. Four efficient numerical techniques, namely the initial-value 
technique, boundary-value technique, shooting method and booster method 
are presented in Section 14.4 for a special type of SPPs arising in chemical 
reactor theory; also semilinear SPPs are studied in this section. Numerical 
experiments are carried to show the efficiency and accuracy of these numerical 
methods. Boundary layer adapted nonuniform meshes for SPPs of the form 
(14.3) are discussed in Section 14.5. 
14.2 
CHARACTERIZATION OF SPPs 
To understand the concepts of various solution techniques clearly, we deal 
with the one-dimensional SPP of the following form: 
f eu"(x) + a(x)u'(x) - b(x)u(x) = fix), 
x € Ω = (0,1), 
I 
(14.3) 
[ u(0) = A, 
u(l) = B, 
where 0 < ε < 1 is a small parameter, a(x), b(x) and f(x) are sufficiently 
smooth functions (infinitely differentiable functions) such that a(x) > a > 0, 
and b(x) > 0, x € Ω = [0,1]. The SPP (14.3) admits a unique solution u(x), 
which exhibits a boundary layer of width 0(ε) at x = 0. 
The main interest of the SPP (14.3) is to study the analytical and numerical 
behavior of the solution as the diffusion parameter ε —> 0. 
The existence, uniqueness and asymptotic approximate solution of the SPP 
(14.3) are studied by various authors, for example, one can refer the books of 
[7], [13], [18] and [19]. 
■ EXAMPLE 14.1 
Consider the following constant coefficient two-point BVP: 
f eu"{x) + u'(x) = 0 , 
i e ! l , 
1 u(0) = l, 
u(l) = 0. 
(14.4) 
The exact solution is given by 
u(x) = A + B exp(-x/e), 
(14.5) 
where 
A= 
ex^-H£) 
, B 
-1 
exp(—1/ε) — 1' 
exp(—1/ε) — 1 

332 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
In the BVP (14.4) the diffusion coefficient e is too small in comparison with 
the convection coefficient. 
These problems are also called as convection-
dominated BVPs. 
The derivative(s) of the solution (14.5) contains negative power of the dif-
fusion parameter e, therefore it has a steep gradient in the neighborhood of 
x = 0, which is known as the boundary layer region and the width of the 
boundary layer is of 0(ε). 
In fact, u(x) behaves non-uniformly near x = 0, 
which can be seen from the following result: 
0 = lim lim exp(—χ/ε) φ lim lim exp(—xle) = 1. 
x—>0ε->0 
£—>0 x—»0 
The region of nonuniformity causes various difficulties in solving the BVP 
(14.4) analytically as well as numerically. 
Generally, the diffusion coefficient models the viscosity of the fluid which is 
too small in comparison with other quantities. If suppose one assumes that of 
neglecting this small viscosity term, that is, e = 0, then the second-order ODE 
(14.3) get reduced to a first-order ODE. This is called the order-reduction of 
the ODE. Since, the second-order ODE becomes a first-order ODE, it is not 
possible to impose boundary conditions at both the ends. Therefore, one has 
to drop one of the boundary conditions, this is known as the loss of boundary 
conditions. 
Another important characteristics of SPPs is that a straightforward asymp-
totic expansion (also known as the outer expansion) does not satisfy the DEs 
along with both the boundary conditions. 
Consider the straightforward asymptotic expansion 
u(x,e) = uo(x) +eui(x) 
+e2u2(x) 
+ ..., 
(14-6) 
where UQ{X) is the solution of the reduced problem (first-order ODE) obtained 
by setting ε = 0 in the DE (14.4): 
u'0(x) = 0, 
«o(l) = 0, 
and Ui(x) for i = 2,... satisfy the following problems: 
<{x) = 0, 
Ui(l) = 0. 
The left boundary condition of the BVP (14.4) is not taken into account 
with the straightforward asymptotic expansion (14.6). Therefore, one more 
asymptotic expansion is required to deal with the boundary layer region, and 
it is known as the inner expansion or boundary layer correctors. The inner 

14.3 NUMERICAL APPROXIMATE SOLUTION 
333 
expansion is given in a suitable stretching variable τ = χ/ε: 
ν(τ,ε) = ν0{τ) + ενι(τ) + ε2υ2{τ) + ..., 
(14.7) 
where ι>ο(τ) is the solution of the second-order ODE: 
<Ρν0 
dvQ 
^ 
+ — = 0 , 
τ6(0,οο), 
wo(0) = 1, 
and Vi{r) for i = 1,2,... satisfy the following second-order ODEs with one-
sided boundary condition: 
d2Vi 
dvi 
„ 
.„ 
. 
^ 
+ ^ = 0 , 
r€(0,oo), 
Vi(0) = 0. 
The second arbitrary constant of integration for υ,(τ) for i = 0,1,... will 
be determined from the Prandtl's matching condition (refer, for example, the 
book by Bush [3]). 
14.3 
NUMERICAL APPROXIMATE SOLUTION 
14.3.1 
Failure of Classical Finite Difference Schemes on Uniform 
Meshes 
Assume that the domain Ω = (0,1) is divided by N number of intervals with 
uniform step-size h = 1/N, and the mesh points are given by Xj = ih, for 
i = 0,1,.. .,N. 
We define the first-order finite difference operators on the 
uniform mesh by 
D+Ui=Ui+1~Ui, 
D-Ui=Ui-?i-1, 
&>Ui=Ui+1-Ui-1. 
h 
h 
2n 
Assume that we are replacing the derivatives in the ODE (14.4) by the 
following central difference scheme: 
^(Ui+i 
- 2Ui + Ui-i) + ^(Ui+i 
-Ui-i) 
= 0, 
(14.8) 
where t/j ~ u{xi). If we solve the difference equation (14.8), we obtain that 
Since the solution of the ODE (14.4) is of monotonically decreasing, we 
expect the same behavior in the numerical approximate solution (14.9) as 

334 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
well. In order to have a stable (nonoscillatory) numerical solution, one has 
to restrict the step-size h < 2ε (refer [21]). This condition is too stringent 
because the diffusion parameter is too small, for example, ε ~ 10 - 4, in that 
case, one has to solve a very large system of linear algebraic equations, even 
in the one-dimensional case. If one goes for higher dimensions it is almost im-
possible to meet this stringent condition on the step-size. Figures 14.1(a) and 
14.1(b) show the exact and numerical solution obtained by the central differ-
ence scheme (14.8) for the SPP (14.4) with h = 0.05. The stability condition 
is satisfied for Figure 14.1(a), and therefore there is no non-physical oscilla-
tions, whereas this condition is violated in Figure 14.1(b), and the numerical 
solution is having spurious oscillations. 
(a) ε = le - 01. 
(b) ε = le - 03. 
Figure 14.1 
Exact solution and the approximate solution obtained by the central 
difference scheme for Example 14.1 for h = 0.05. 
To obtain a nonoscillatory numerical approximate solution, one can replace 
the first-order derivative in the ODE (14.4) by the forward difference (upwind) 
scheme, which gives the second-order difference equation 
^(Ui+i 
- 2Ui + Ui-!) + i(£/i+i - Ui) = 0. 
(14.10) 
By solving the difference equation (14.10), one can obtain the solution 
υ* = Λί+*(ϊϊϊΪ· 
(14Λ1) 
Although the solution of the upwind difference is oscillation-free [21], it 
won't provide any information about the solution inside the boundary layer 
region, which is of width 0(ε). In order to study the behavior of the solution 
inside the boundary layer, one has to take smaller step-size in relation with 
the diffusion parameter ε, otherwise, the first mesh point itself will go outside 
the boundary layer region. These observations can be depicted from Figures 
14.2(a) and 14.2(b). In fact, Figure 14.2(b) clearly indicates the need of 

14.3 NUMERICAL APPROXIMATE SOLUTION 
335 
a smaller step-size in relation with e to have some mesh points inside the 
boundary layer region. 
0.9 
0.8 
0.7 
0.6 
0.5 
0.4 
0.3 
0.2 
0.1 
0.2 
0.4 
0.6 
I-B-Exact I 
| -*— Upwind (· 
-
-
-
-
-
-
™8 
0.9 
0.8 
0.7 
0.6 j 
3 0.5 
0.411 
0.3 I I 
1
; 
0.4 
-»-Upwindt 
-
" 
■ 
-
-
' 
" * d! * " 
(ft 
" ~ T 
(a) ε = le - 01. 
(b) ε = le - 03. 
Figure 14.2 
Exact solution and the approximate solution obtained by the upwind 
difference scheme for Example 14.1 for h = 0.05. 
Let u{x) be the solution of the BVP (14.4) and Ui be the numerical solution 
of either (14.10) or (14.8). Then, the consistency constant C of the following 
error estimate: 
sup 
0<ε<1 
\u{xi)-Ui\\ 
< ChP, 
p = l o r 2 
(where || · || is any suitable norm, throughout this chapter, we consider the 
maximum norm) depends on the inverse powers of the diffusion parameter e. 
Therefore, one has to keep on reducing the step-size h with respect to ε in 
order to have a meaningful error bound. But in practice it is not possible to 
have smaller step-sizes than ε. 
Definition 12 Let u(x) be the exact solution of a SPP, and let Ui be the 
numerical solution of the corresponding discrete problem. We say Ui converges 
uniformly to u(xi), if for some fixed No > 0 the following condition holds: 
sup \\u{xi)-Ui\\ 
< CN~P, 
forN>N0, 
0 < e « l 
where NQ, C are independent of ε. 
14.3.2 
Exponentially Fitted Difference Scheme 
Applied mathematicians and engineers are interested in finding uniformly con-
vergent numerical approximate solution for SPPs. As we have seen that the 
classical finite difference schemes fail to provide uniformly convergent numer-
ical solution on uniform grids, one has to look for alternate ways to overcome 

336 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
this difficulty. Allen-Southwell [1] and Il'in [9] proposed the following expo-
nentially fitted difference (EFD) scheme for the SPP (14.3) 
f eaiD+D-Ui+aiD0Ui-biUi 
= fu 
0<i<N, 
< 
(14.12) 
[ u0 = A, 
uN = B, 
where the fitting factor σ, is given by 
·-(£)"*(%)■
 
( 1 4·
1 3 ) 
The following theorem provides the uniform convergence of the EFD scheme 
(14.12). 
Theorem 9 [6] Let u(x) and Ui be respectively the solution of the continuous 
problem (14-3) and (14-12). Then, the error satisfies the following bound 
\\u(xi)-Ui\\ 
< Ch, 
where the constant C is independent of Xi, h and ε. 
To see the efficiency of the EFD scheme (14.12), we applied it to the SPP 
(14.4) given in Example 14.1. The approximate solution along with the exact 
solution and the corresponding error for ε = le — 02, h = 0.05 are plotted in 
Figures 14.3(a) and 14.3(b), respectively. These plots reveal the accuracy of 
the EFD scheme. 
(a) Exact and Approximate Solutions. 
(b) Error. 
Figure 14.3 
Numerical solution and error plots of EFD scheme for Example 14.1, 
for e = le - 02, h = 0.05. 

14.4 SPPs ARISING IN CHEMICAL REACTOR THEORY 
337 
14.4 
SPPs ARISING IN CHEMICAL REACTOR THEORY 
In this section, we consider a class of SPP for second-order ODEs with a special 
type of mixed boundary conditions which arises in the theory of chemical 
reactions [5]. Consider the following two-point BVP: 
Pu{x) = eu"(x) + a{x)u'{x) — b{x)u{x) = f(x), 
x €. Ω, 
B0u(0) = -u'(O) = A, 
Biu(l) = u(l) + su'(l) = B, 
(14.14) 
where 0 < ε <iC 1 is a small parameter, a(x), b(x) and f(x) are sufficiently 
smooth functions such that a(x) > a > 0, and b(x) > 0, x € Ω, L = 
(P,B0,Bl)T, 
F = (f(x),A,B)T. 
Under these assumptions the BVP (14.14) 
admits a unique solution. For these problems the asymptotic solution con-
verges to the solution of the reduced problem throughout the domain [0,1] 
while the derivatives generally converge nonuniformly as ε —* 0 at the left 
boundary x = 0. These problems are classified as weak layer problems. This 
nonuniformity in the convergence of the derivatives prevents us from obtain-
ing satisfactory numerical approximate solution by classical finite difference 
or finite element methods on uniform meshes. 
The following lemma states that the solution of the SPP (14.14) satisfies the 
maximum principle. Further, it shows that the solution is uniformly stable. 
Lemma 14.4.1 Let u(x) be any smooth function satisfying Pu{x) < 0, x G 
Ω, BQU(0) > 0 and Biu(l) 
> 0, then, u(x) > 0 for all x e Ω. Further, the 
following stability estimate holds: 
\u(x)\ < C[|Bou(0)| + |Biu(l)|+max|Pu(y)|]. 
yen 
Proof. The proof of this lemma can be found in Doolan et al. [6]. 
The derivatives of the solution of the SPP (14.14) will satisfy the following 
bound (for the detailed proof refer the article [17]): 
\u{i)(x)\ 
< C[l + e~i+1exp(-ax/e)}, 
for i = 1(1)j + 1, for some fixed j . 
In this section, we provide four efficient numerical methods to solve the 
SPP (14.14), namely initial-value technique (IVT), boundary-value technique 
(BVT), shooting method and booster method. The methods are described 
in the following subsections, and a numerical example is solved by all these 
methods to show the efficiency and accuracy of these methods. The numerical 
results are presented in the form of tables or figures for the approximate 
solution or for the errors. 
Lu(x) 
F& 

338 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
14.4.1 
Initial-Value Technique 
In initial-value technique, the numerical solution of the SPP (14.14) is ob-
tained by solving some suitable initial-value problems (IVPs) of first-order 
ODEs obtained through the asymptotic approximate solution. The asymp-
totic approximate solution is given by 
u{x) = u0{x) +e[ui(x) + p(x)v0(x)], 
(14.15) 
where 
ρ{χ)_ 
aHO)(A + u>0(0)) 
a(x)(a2(0) - e[6(0) - α'(0)])' 
and uo(x), u\(x) and VQ(X) are respectively the solutions of the following first 
order IVPs: 
_ 
[ a(x)u'0(x) — b(x)uo(x) = f(x), 
x € Ω, 
and 
[ uo(l) = B, 
ί
α(ι)ϋΊ(ϊ:) — b(x)ui(x) = —U'Q(X), 
i € i l , 
U l(l) = 
-u'0(l), 
εν'0(χ) — [a(x) — eb(x)/a(x)]vo{x) 
= 0 , 
i G i l , 
MO) = 1. 
(14.16) 
(14.17) 
(14.18) 
The asymptotic expansion given in (14.15) provides a second-order approx-
imation to the solution u{x) of the SPP (14.14). That is, 
\u{x)-u{x)\ 
< Ce2, 
provided that (a2(0) - e0[6(0) + |o'(0)|]) > v > 0, for 0 < ε < ε0 < 1. By 
using the barrier function technique one can prove this result; for details refer 
to Ref. [16]. 
The first-order derivatives in the IVPs (14.16) and (14.17) are without 
multiplied by the small parameter ε, therefore, one can apply any classical 
numerical scheme to solve these IVPs. Here, we apply the fourth-order explicit 
Runge-Kutta method to solve these problems. 
Consider the most general first-order IVP 
j u'(x) = f(x,u), 
i € ( 0 , l ) , 
ΜΑΐαΛ 
1 u(0) = A. 
U 4 a y j 

14.4 SPPs ARISING IN CHEMICAL REACTOR THEORY 
339 
The fourth-order Runge-Kutta method for the above IVP is given as 
Ui+1 = Ui + hK1+2K2 
+ 2K3 + K4], 
i>0, 
o 
Kl=hf{xi,Ui), 
K2=hf 
(xi + -,Ui + -Ki) 
, 
(14.20) 
K3 = hf (Xi + \,Ui + ^κλ 
, 
Κ4 = hf(Xi + h,Ui + K3). 
The error of the Runge-Kutta method satisfies the following bound 
\u (xi)-Ui\ 
< 
Ch\ 
where u(x) and Ui are respectively the solutions of (14.19) and (14.20). 
In order to solve the singularly perturbed IVP (14.18), we apply the EFD 
schemes of Doolan et al. [6], [16]. The explicit EFD scheme is given by 
f eaiD+Vi - (a, - eh/a^V 
= 0, 
i > 0 
i 
(14.21) 
1 Vo = 1, 
where the fitting factor is σ^ = (hai/e)/(l 
— exp(—aih/ε)). 
Let vo(xi) be the solution of the singularly perturbed IVP (14.18), and Vi 
be the numerical solution of (14.21), then the error satisfies 
\vo{xi)-Vi\ 
< Ch. 
To solve the singularly perturbed IVP (14.18), one can also apply the fol-
lowing implicit EFD scheme ( [6]): 
(
eai+1D+Vi 
- (ai+i - ebi+i/ai+i)Vi+i 
= 0 , 
i > 0, 
(14.22) 
V0 = 1, 
where the fitting factor is σ, = (hai/e)/(exp(aih/e) 
— 1). 
The error of the implicit EFD scheme (14.22) satisfies the following bound 
\vo{xi)-Vi\ 
< 
Cmm(h,e). 
The following theorem provides the error bounds for the numerical approx-
imate solution of the SPP (14.14), here the singularly perturbed IVP (14.18) 
is solved by using the explicit EFD scheme (14.21). 
Theorem 10 [16] Let u(x) be the solution of the SPP (14-14)· Let Uoi and 
U\i be respectively the numerical solutions of the IVPs (14-16) and (14-17) 
obtained by the classical Runge-Kutta method, and VQI be the solution of the 
singularly perturbed IVP (14-18) obtained by the explicit EFD scheme (14-21), 

340 CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
then the error satisfies 
\u{Xi) - [U0i + s{Uu + PiV0i)}\ 
< <7(ε 2+/ι 4+ε/ι 4 + ε/ι). 
When the implicit EFD (14.22) is used to solve the singularly perturbed 
IVP (14.18), one can have the following error estimate. 
Theorem 11 [16] Let u(x) be the solution of the SPP (14-14)- Let Uoi and 
Uu be respectively the numerical solutions of the IVPs (14-16) and (14-17) 
obtained by the classical Runge-Kutta method, and Vbi be the solution of the 
singularly perturbed IVP (14-18) obtained by the implicit EFD scheme (14-22), 
then the error satisfies 
\u(xi) - [Uoi + s(Uu + piV0i)}\ < C(e2+ h4 + eh4 + 
emin(h,e)). 
■ EXAMPLE 14.2 
Consider the following linear two-point BVP: 
eu"(x) + u'(x) -u(x) = 0, 
i e i l , 
(14.23) 
-u'(0) = 0, 
u(l) + eu'(l) = l. 
Since it is a constant coefficient linear BVP, one can easily obtain the 
exact solution as 
exp(—mi)[m2 exp(mia;) — mi exp(m2x)] 
m2(l + επΐι) - mi(l +em 2)exp(m 2 — mi)' 
where mii2 = (—1 ± \/l + 4ε)/2ε. 
The asymptotic approximate solution of the BVP (14.23) is given by 
u(x) = UQ + ενο = exp(x — 1) — ε exp(—1) exp(—χ/ε). 
To validate the theoretical error estimates of the initial-value technique, we ap-
ply it to the SPP (14.23). Basically, we have to solve two first-order terminal-
value problems without ε (by the fourth-order Runge-Kutta method) and 
one singularly perturbed initial-value problem [by the explicit EFD scheme 
(14.21)]. The numerical results are presented in Table 14.1 for Example 14.2. 
14.4.2 
Boundary-Value Technique 
Roberts [20] proposed a non-overlapping domain decomposition method to 
solve SPP of the form (14.3). The BVPs of the subdomains are solved by the 
classical finite difference schemes. In [11], the authors solved SPPs arising 
in chemical reactor theory by the boundary-value technique. In this method, 

14.4 SPPs ARISING IN CHEMICAL REACTOR THEORY 
341 
Table 14.1 
Exact solution and error of the IVT for Example 14.2. 
Mesh 
points 
ε = 10-Λ, 
Exact 
solution 
h = 1(TJ 
Error 
e = 10 - 5, 
Exact 
solution 
h = 10"ü 
Error 
0*e 
3*ε 
5 * e 
7 *ε 
9*ε 
10 *ε 
0.20 
0.40 
0.60 
0.80 
1.00 
0.367883 
0.369002 
0.369724 
0.370461 
0.371202 
0.371573 
0.448790 
0.548045 
0.669250 
0.817260 
0.999890 
3.7e - 04 
3.7e - 04 
3.6e - 04 
3.6e - 04 
3.6e - 04 
3.6e - 04 
2.4e - 04 
5.5e - 04 
9.2e - 04 
1.4e - 03 
2.0e - 03 
0.367883 
0.367990 
0.368027 
0.368137 
0.368211 
0.368248 
0.449283 
0.548755 
0.670249 
0.818642 
0.999890 
3.7e - 06 
3.7e - 06 
3.7e - 06 
3.7e - 06 
3.7e - 06 
3.7e - 06 
4.3e - 05 
5.5e - 05 
7.0e - 05 
8.8e - 05 
Lie - 04 
the inner region (boundary layer region) problem is solved by an EFD scheme 
and the outer region problem is solved by the classical upwind finite difference 
scheme. The domain Ω = [0,1] is divided into two non-overlapping subdo-
mains as [0, ke] and [ke, 1], for k > 0 and ke <C 1 is the width of the boundary 
layer (inner) region near x = 0. Two boundary-value problems are obtained 
for these subdomains, and the boundary condition at x = ke is obtained from 
the asymptotic approximate solution. More precisely, 
1. The inner region (boundary layer) problem is given by 
(
eu"(x) + a(x)u'(x) — b(x)u(x) = f(x), 
x e (0,ke), 
-u'(0) = A, 
u(ke) = 1, 
and 
2. The outer region problem is given as 
{
eu"{x) + a(x)u'(x) — b(x)u(x) = f(x), 
x e (ke, 1), 
u(ke) = A~, u(l)+eu'(l) 
= B, 
(14.24) 
(14.25) 
where A is solution of the reduced problem calculated at ke, that is, 
A = u0(ke). 
The reduced problem solution is obtained by solving the following first-
order ODE: 
{
a(x)u'0(x) — b(x)uo(x) = f(x), 
x € Ω, 
«ο(1) = B. 
( 1 4' 2 6 ) 

342 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
If one wants to have a better approximation at the transition point ke, then 
the following asymptotic approximate solution can be used: 
u(x) — uQ{x) + e(u\(x) + VQ(T)), 
where r = χ/ε, 
(14.27) 
and tii {x) and VQ (T) are respectively the solution of the following problems: 
(
a{x)u'Ax) — b(x)uAx) = -u'n(x), 
i f i l , 
(14.28) 
«i(l) = 0, 
and 
d?v0 
dv0 
, 
. 
-J-Ö- + -j— = 0, 
x e (0,oo), 
dT* 
dT
 
J 
(14.29) 
ατ 
ax 
It is worthwhile to note that the asymptotic approximation given in (14.27) 
is of second-order approximation for u(x), that is, \u(x) — u(x)\ < Ce2. 
Here, we use only the reduced problem solution to determine the boundary 
value at the transition point ke, that is, 
A = u0(ke). 
(14.30) 
Now, the boundary layer problem and the outer region problem can be 
solved numerically. To solve these problems we apply the following numerical 
schemes, the boundary layer problem is solved by an exponentially fitted 
difference scheme and the classical finite difference scheme to solve the outer 
region problem. 
To solve the boundary layer problem (14.24) we apply the following expo-
nentially fitted difference scheme as given in Doolan et al. [6]: 
eaiD+D-Ui 
+ aiD°Ui-biUi 
= fu 
0<i<N, 
where σ» is as given in (14.13). Also one can obtain the following error estimate 
for the boundary layer region problem. 
If u is the solution of the original SPP (14.14) and Ui is the numerical 
solution of (14.31). Then the error satisfies the bound 
\\u{xi)-Ui\\ 
< C(h + e), 
(14.32) 
where the constant C is independent of ε, Xi and h. 
Since the outer region problem is away from the boundary layer, the clas-
sical upwind finite difference scheme performs well, the BVP (14.25) is solved 

14.4 SPPs ARISING IN CHEMICAL REACTOR THEORY 
343 
by the following upwind scheme: 
' eD+D-Ui + aiD+Ui - hUi = fi, 
0<i<N, 
UN 
—UN-I 
i/o 
UN+e 
h 
B. 
(14.33) 
Following the proof error estimate given in Ref. [12], one can have the 
following error estimate for the outer region problem (14.25). Let u(x) be the 
solution of the SPP (14.14), and Ui be the solution of (14.33), then 
\\u(xi) — Ui\\ < C(s + h + he 
1 βχρ(-7^/ε)), 
h<e, 
\\u(xi) — Ui\\ < C (ε + h + exp(—axi/(e + ah))), 
h>e, 
(14.34) 
where 7 G (Ο,α). 
By increasing the value of k (thus widening the boundary layer region), 
we keep on solving the inner region BVP (14.24) by the EFD scheme (14.31) 
until the solution profiles do not differ materially from iteration to iteration. 
For computational purposes, we use the following absolute error criteria for 
any suitable tolerance bound: 
\wr
+l-ur\\ 
< Toi, 
where U™ is the mth-iteration of the inner region solution. Once, the solution 
stabilizes in the inner region, keeping that particular value of k, we solve the 
outer region problem (14.33) and combine both the solutions to obtain the 
numerical approximation for the whole domain Ω. 
14.4.3 
Shooting Method 
In this method, the domain of computation Ω = [0,1] is divided into two 
non-overlapping subdomains as [0, k\] (inner region with fci as the width of 
the boundary layer) and [k^, 1] (outer region) with 0 < k\ < k^ < 1. In the 
inner region [0, fci], the second-order SPP (14.14) is converted into a system 
of two first-order ODEs as 
u'i — U2 = 0, 
x € [0, k\], 
eu'2 + a(x)u2 — b(x)u\ = f(x), 
_ u1(0)=A 
= uo(k1), 
u2(0) = -A. 
(14.35) 
To solve the system of first-order ODEs (14.35), we apply the following 
difference scheme which uses the classical finite difference scheme and an EFD 

344 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
Table 14.2 Exact solution and error of the B V T for Example 14.2. 
Mesh 
Points 
0.000 
0.001 
0.002 
0.003 
0.004 
0.005 
0.006 
0.007 
0.008 
0.009 
0.010 
0.200 
0.300 
0.400 
0.500 
0.600 
0.700 
0.800 
0.900 
1.000 
Numerical 
fc = l 
0.36798861 
0.36811217 
0.36896646 
0.36982076 
0.37067506 
0.37152935 
0.37238365 
0.37323794 
0.37409224 
0.37494653 
0.37580083 
0.45508026 
0.50264254 
0.55517575 
0.61319942 
0.67728738 
0.74807344 
0.82625763 
0.91261316 
0.99901000 
solution 
k = 10 
0.36826893 
0.36839259 
0.36867096 
0.36900644 
0.36936312 
0.36972784 
0.37009575 
0.37046506 
0.37083512 
0.37120568 
0.37157667 
0.45102504 
0.49816350 
0.55022859 
0.60773521 
0.67125209 
0.74140736 
0.81889486 
0.90448088 
0.99901000 
A; = 20 
0.36827264 
0.36839630 
0.36867468 
0.36901016 
0.36936685 
0.36973157 
0.37009948 
0.37046879 
0.37083885 
0.37120943 
0.37158042 
0.45102504 
0.49816350 
0.55022859 
0.60773521 
0.67125209 
0.74140736 
0.81889486 
0.90448088 
0.99901000 
Exact 
solution 
0.36824640 
0.36838188 
0.36866461 
0.36900167 
0.36935895 
0.36972388 
0.37009186 
0.37046119 
0.37083126 
0.37120183 
0.37157281 
0.44923906 
0.49643640 
0.54859232 
0.60622777 
0.66991844 
0.74030049 
0.81807693 
0.90402460 
0.99901000 
Error 
2.6241e -
1.4415e 
1.0074e 
8.4828e 
7.9027e 
7.6940e 
7.6220e 
7.6001e 
7.5966e 
7.6000e 
7.6058e 
1.7860e 
1.7271e -
1.6363e -
1.5074e ■ 
1.3336e 
1.1069e 
8.1793e 
4.5628e 
9.8521e 
-05 
-05 
-05 
-06 
-06 
-06 
-06 
-06 
-06 
-06 
-06 
-03 
-03 
-03 
-03 
-03 
-03 
-04 
-04 
-06 
scheme 
' D+Uhi -U2,i 
= 0, 
0<i<N 
eaD+U2,i + aiU2,i+i - hU^ 
= /<, 
(14.36) 
_ Uifi = A, 
U2,o = A, 
where σ = (ha(Ö)/e)exp(-a{0)h/e)/[l 
- exp(-a(0)/i/e)]. 
One can obtain the following error estimate for the numerical solution of 
the inner region problem (14.36) 
HzO-UiH < Ch, 
(14.37) 
where u = (u\,u2)T 
and U = {U\,U2)T 
are respectively the solutions of the 
continuous system (14.35) and the discrete system (14.36). Here the error 
constant C is independent of ε, h, Xi, the resultant scheme is of ε-uniform 
convergent method. 
By using the uniqueness of the solution of the BVP (14.14), and the system 
of IVPs (14.35) one can have the error estimate. Let u(x) be the solution of 
the original SPP (14.14), further, U = (t/i,t/ 2) T be the solution of (14.36), 

14.4 SPPs ARISING IN CHEMICAL REACTOR THEORY 
345 
then 
Ιϊφ^-Ε/ι,ίΙ < C(e + h), 
^ € [ 0 , 4 
The outer region problem is given by the BVP: 
eu"(x) + a(x)u'(x) — b(x)u(x) — f{x), 
x € (k2,1), 
_ 
(14.38) 
u{k2) =B = u0(k2), 
u(l) + eu'(l) = B. 
The above BVP (14.38) is solved by the classical upwind finite difference 
scheme as given in (14.33), and error estimate given in (14.34) holds true for 
this BVP also. 
Since the inner region problem (14.36) defined in the subdomain [0, k\] 
and the outer region problem (14.38) defined in the interval (&2,1) [by the 
difference scheme (14.33)] are independent of each other, this opens the door 
for parallel computing. By this way, one can reduce the computation time. 
(a) Exact and Approximate solutions. 
(b) Error. 
Figure 14.4 
Plots of the exact and approximate solution obtained by shooting 
method for Example 14.2 for e = 10"3, fci = 10ε, k2 = 0.02, hi = ε, and h2 = 0.01. 
14.4.4 
Booster Method 
To obtain better approximate numerical solutions to SPPs of the form (14.3), 
Israeli and Ungarish [10] proposed a numerical method, in which an asymp-
totic approximate solution is incorporated into a suitable numerical scheme 
to improve the accuracy of the numerical approximate solution. The basic 
properties of the numerical scheme will remain as it is, and the accuracy will 
be improved by this method. 
Let U be the numerical solution of (14.14) obtained through the following 
difference scheme: 
Lh(U) = Fh, 
(14.39) 

346 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
where Lh is a suitable difference operator obtained by replacing the derivatives 
in L by finite difference quotients. Then, the truncation error T(u) of the 
difference operator Lh is defined as 
T(u) = Lh(u) - L{u) = Lh{u) - 
Lh{U). 
Since the differential operator L and the difference operator Lh are linear, one 
can rewrite the truncation error as 
T{u) = Lh{u - U), 
(14.40) 
and it can be taken as 
\\u-U\\ 
= 
\\L^T(u)\\. 
In the booster method, we use an asymptotic approximate solution ΰ to 
the original solution u{x) in order to reduce the truncation error. The im-
proved numerical solution, denoted by UB , is obtained by applying the Booster 
operator LhB, defined by 
LHB{UB) 
= Lh(UB) - Lfc(u) + L{u) = Fh. 
(14.41) 
Then, the truncation error of the booster method TB(U) can be given as 
TB(u) 
= 
\Lh{u)-Lh{u) 
+ 
L(u)}-L(u) 
= 
\Lh(u) - Lh(u)} - [L(u) - L(u)} 
= 
[Lh(u) - L(u)} - [Lh(u) - L(u)} = T(u) - T{u). (14.42) 
Thus, if the approximation is such that 
||TB(u)|| = ||T(u)-T(5)|| < εΒ||Γ(ϋ)||, 
where EB is small, then UB is expected to be a better approximation to u than 
U. From the truncation errors given in (14.40) and (14.42), we can obtain 
that 
Lh(u-UB) 
= [Lh(u) - L{u)] - \Lh(u) - L(u)} = 
TB(u), 
and therefore, 
\\u-UB\\ 
= \\L^TB(u)\\ 
< KEBWL^TB^W 
= Α-ε Β||«-^||. (14.43) 
From the above inequality one can notice that, if SB is small, then the error 
estimate of the booster scheme is much smaller than the original error. This is 
possible because of the incorporation of the asymptotic approximation inside 
the numerical scheme. 

14.4 SPPs ARISING IN CHEMICAL REACTOR THEORY 
347 
Further, let us note that TB(U) = T(u — u). The essence of the Booster 
method is to make use of the equation (14.41) instead of the regular numerical 
scheme (14.39), and therefore, one can obtain the better numerical solution 
UB, than the original numerical approximation U. For example, if one applies 
the EFD scheme (14.12) to solve the SPP (14.14), then from Theorem 9 the 
following error estimate holds: 
\\u(xi)-Ui\\ 
< Ch. 
The corresponding error of the booster method (after incorporating an 0(e)-
asymptotic approximate solution) satisfy the following bound 
\\u{xi)-UBi\\ 
< Ceh. 
Whenever ε is too small, one can obtain better results. One can see the 
article by Natesan and Ramanujam [17], for further details about the booster 
method, and for numerical results. 
To show the efficiency of the booster method, we apply it to the SPP 
(14.44) given in Example 14.3. 
■ EXAMPLE 14.3 
Consider the following nonhomogenous BVP: 
eu"(x) + u'(x) = -(1 + 2x), 
x € Ω, 
(14.44) 
-u'(0) = l, 
u(l) + eu'(l) = 0. 
the exact solution of the above BVP can be calculated as 
u(x) = 2-x(l 
+ x)+ e[l - 2(e[l - exp{-x/e)} 
- x)]. 
Table 14.3 presents the error of the EFD scheme and the corresponding 
booster method for Example 14.3. From this table one can notice the ac-
curacy of the booster method. The errors of the booster method reveals the 
effect of the incorporation of an 0(s)-asymptotic approximation into the EFD 
scheme. The booster method can be applied to any type of scheme, and here 
we applied it only to the EFD scheme. 
14.4.5 
Semilinear Problems 
This section deals with the numerical solution of semilinear singularly per-
turbed BVPs. These problems arise in various applications, including chemi-
cal reactions, gas porous electrodes theory, etc. Generally, semilinear problems 
admit multiple solutions, and it is difficult to obtain ε-uniformly convergent 
numerical solutions. 

348 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
Table 14.3 
Error for the EFD scheme and the corresponding Booster 
method for Example 14.3. 
Nodes 
H = 0.05 
0.00 
0.10 
0.20 
0.30 
0.40 
0.50 
0.60 
0.70 
0.80 
0.90 
1.00 
Error 
ε = 10- 5 
EFD 
4.8100e -
4.3298e -
3.8498e -
3.3698e -
2.8898e -
2.4098e -
1.9298e -
1.4498e -
9.6980e -
4.8980e -
9.8000e -
-02 
-02 
-02 
-02 
-02 
-02 
-02 
-02 
-03 
-03 
-05 
Booster 
9.8000e -
1.1102e-
4.4409e -
2.2204e -
0 
2.2204e -
6.6613e -
3.3307e -
1.1102e -
5.5511e -
4.3368e -
-05 
-15 
-16 
-16 
-16 
-16 
-16 
-16 
-17 
-19 
ε = 10"5 
EFD 
4.9981e -
4.4983e -
3.9985e -
3.4987e -
2.9989e -
2.4991e -
1.9993e -
1.4995e -
9.9970e -
4.9990e -
9.9980e -
-02 
-02 
-02 
-02 
-02 
-02 
-02 
-02 
-03 
-03 
-07 
Booster 
9.9980e -
6.6613e -
6.6613e -
0 
2.2204e -
4.4409e -
6.6613e -
4.4409e -
1.1102e -
5.5511e-
3.3881e -
-07 
-16 
-16 
-16 
-16 
-16 
-16 
-16 
-17 
-21 
Consider the semilinear two-point BVP: 
i
£uxx + a(x)ux — b(x, u) = 0, 
ι ε Ω , 
-ux(0) 
= A, 
u(l) + eux(l) = B, 
(14.45) 
where a(x) and b(x,u) are sufficiently smooth functions such that a(x) > 
a > 0, bu(x,u) > 0, (x,u) e Ω x K. Here, the notation uxx is used instead 
of u"(x) mainly for the sake of convenience to denote the sequence of linear 
problems. Analytic results such as existence, uniqueness and the asymptotic 
approximate solutions can be seen in the classical books of Chang and Howes 
[4] and O'Malley [19]. 
To solve the semilinear BVP (14.45) numerically, the Newton's method of 
quasilinearization is applied to obtain a sequence {wm}o° of approximations 
with a proper choice of initial approximation u°(x). 
For each non-negative 
integer m, we define um+1 to be the solution of the following linear problem: 
εω™+1 + a(x)u™+1 - bm(x)um+1 
= fm(x), 
x <= Ω, 
-u™+1(0)=A, 
um+1(l) 
+ eu™+1(l) = B, 
(14.46) 
where bm{x) = bu(x,um) 
and fm{x) 
= b{x,um) - 
bu(x,um)um. 
If the initial approximation u°(x) is sufficiently close to the solution u(x) 
of (14.45), then the sequence of approximate solutions {um}o° converge to the 
solution u{x) of the given problem. For each fixed m, the BVP (14.46) is a 
linear BVP of the form (14.14), and hence this problem can be solved by all 
the methods discussed above. 

14.5 LAYER-ADAPTED NONUNIFORM MESHES 
349 
The solution of the reduced problem of (14.45) will be taken as the initial 
approximation u°(x). For the numerical computations, we use the following 
stopping criteria: 
jjym+l _ Vrn\ < T o l j 
\<i<N, 
JTI>0, 
where U™ is the mth-iteration solution at the ith mesh point for any pre-
scribed tolerance bound. 
14.5 
LAYER-ADAPTED NONUNIFORM MESHES 
The extension of the EFD scheme (14.12) to higher-dimensional problems are 
computationally expensive and in several cases it is not possible. One of the 
main alternate ways to obtain an e-uniformly convergent numerical solution is 
to use classical finite difference/element schemes on nonuniform meshes, which 
are condensed inside the boundary layer and coarse in the rest of the domain. 
Let the mesh points in an arbitrary nonuniform mesh with N subintervals be 
denoted by Ω = {xi}™, then the mesh width be denoted by hi = Xi — Xi-i 
for 1 < i < N. 
Before proceeding further, we define the finite difference 
operators on the nonuniform meshes as 
h 
h 
hi + hi+i 
) 
\hi + hi+i 
14.5.1 
Bakhvalov Meshes 
Bakhvalov [2] was the first person to introduce the nonuniform meshes for 
solving SPPs numerically. Assume that the solution of an SPP is having 
a boundary layer at the left end x = 0, and therefore, the boundary layer 
function is u = exp(—αχ/ε), for some a > 0. His idea is to use an equidistant 
u-mesh near u = 1 (which corresponds to x = 0), then to map this mesh back 
to the a>axis by means of the boundary layer function. This defines the mesh 
points near to x = 0 by 
/ ax\ 
i 
ε 
which is equivalent to define the mesh points as 
a 
V 
N 

350 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
The Bakhvalov meshes are obtained from the following mesh generating func-
tion: 
f 4>{t) := -ΐε ln(l - t/η), 
for t e [0, r], 
λ(ί) = < 
(14.47) 
I V(t) := <H*) + ^(ί)(ί - τ), 
for t = [r, 1], 
where 7 and 77 are positive constants, and the transition point τ is obtained 
by solving the nonlinear equation 
φ(τ)+φ'(τ)(1-τ) 
= 1. 
Here, one has to solve a nonlinear problem to obtain the nonuniform 
Bakhvalov meshes even to solve a linear SPP of the form (14.3). Further, 
the mathematical proof of the uniform convergence is too difficult. 
In order to obtain an ε-uniformly convergent numerical solution to SPP 
(14.3), we use the classical upwind finite difference scheme on the layer-
adapted nonuniform meshes. Define the following upwind finite difference 
scheme on nonuniform meshes as 
f ePUi + aiD+Ui - hUi = fi, 
0<i<N, 
{ 
(14.48) 
[ u0 = A, 
uN = B. 
Theorem 12 Let u{x) be the solution of the SPP (14-3), let Ui be the numer-
ical solution of the scheme (14-48) applied on the Bakhvalov meshes defined 
in (14-4V- Then, the error satisfies the following bound 
max \\u(xi) - Ui\\ < 
CN~l, 
0<i<N 
where the constant C is independent of Xi and e. 
14.5.2 
Shishkin Meshes 
Shishkin [22] proposed piecewise-uniform meshes to obtain the uniform con-
vergent numerical solutions for SPPs of the form (14.3). Assume that the 
boundary layer is on the left boundary x = 0, then the domain [0,1] is di-
vided into two subdomains as [0, r] and [τ, 1], and 7V/2 mesh intervals are 
placed in each of the subdomains, and the transition parameter r is defined 
by 
= min< - , - l n i V \. 
\2'a 
/ 

14.5 LAYER-ADAPTED NONUNIFORM MESHES 
351 
The piecewise-uniform meshes are given by 
2(1 - r) 
(14·49) 
Xi-i+ 
N 
, N/2<i. 
There is no need to solve any nonlinear equation to obtain the piecewise-
uniform Shishkin meshes. Extension of Shishkin meshes to higher-dimensional 
rectangular domain problems is easy. Also, one can obtain the error estimates 
by decomposing the solution into regular and singular components of the 
solution. More details about the Shishkin meshes for various DEs and the 
error estimates can be found in the books of Farrell et al. [8], Miller et al. [15] 
and Roos et al. [21]. 
Theorem 13 [15] Let u(x) be the solution of the SPP (14-3), let Ui be the 
numerical solution of the scheme (14-48) applied on the piecewise-uniform 
Shishkin meshes defined in (14-49). 
Then, the error satisfies the following 
bound 
max \\u(xi)-Ui\\ 
< CAT1 InΛΓ, 
0<i<N 
where the constant C is independent of Xi and e. 
It is worthwhile to note that the error estimate obtained in the above 
theorem is first-order up to a logarithmic factor, and it is not an optimal 
bound. 
14.5.3 
Equidistribution Meshes 
This is the most general way of generating layer-adapted nonuniform meshes, 
by equidistributing a positive monitor function which depends on the deriva-
tives of the solution over the domain of differential equation. The underlying 
idea of the equidistribution meshes is given by the following identity: 
/ 
M(u(x),x)dx 
= — / 
M(u(x),x)dx, 
i = l,---,N, 
(14. 
Jxi-i 
N Jo 
50) 
where M(u(x),x) 
> 0 is called the monitor function. Equidistribution can 
also be thought of giving rise to a mapping x = χ(η), relating a computational 
coordinate η € [0,1] to the physical coordinate x G [0,1], defined by 
rx(n) 
i·1 
/ 
M(u(s),s)ds = T/ / 
M(u(s),s)ds. 
(14.51) 
Jo 
Jo 

352 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
The identity given in (14.50) can be written in the following form as well: 
/ 
M(u{x),x)dx 
= 
M(u{x),x)dx, 
i = l,---,N. 
(14.52) 
Jxi-l 
JXi 
Since the solution u{x) of the SPP (14.3) has steep gradients, the monitor 
function contains either the first-order or the second-order derivatives or any 
suitable combination of both. Some examples of monitor functions are: 
(i) M(u(x),x) 
= \u'(x)\. 
(ii) M(u(x),x) 
= \/a + |u'(:r)|2, where a > 0. 
(iii) M(u(x),x) 
= 1 + a\u'(x)\p, where a > 0 and p £ (0,1). 
(iv) M(u(x),x) 
= a+ \u"(x)\m, 
where a > 0 and m e (0,1) are user chosen 
parameter. 
To obtain the equidistribution meshes, one has to solve the following non-
linear system of equations, obtained by discreting the identity given in (14.52): 
M^iixi-Xi-i) 
=Mi+i(xi+1 
-Xi), 
(14.53) 
where Μέ_ι « Μ ( Μ ( ^ _ Ι ),a;i_i). 
This is an iterative process: to start the iteration, one has to use the 
uniform meshes, and solve the discretized BVP (14.48) to obtain numerical 
approximate solution Ui. By using this Ui in (14.53), one has to solve the non-
linear equations (14.53). This process has to be repeated until some suitable 
stopping criteria holds. The following theorem provides an error estimate for 
the numerical solution. 
Theorem 14 [14] Let u(x) be the solution of the SPP (14-3), let Ui be the 
numerical solution of the scheme (14-48) applied on the equidistributed meshes 
defined in (14-53). Then, the error satisfies the following bound 
max-Juix^-UiW 
< 
CN~\ 
where the constant C is independent of x^ and ε. 
As like in the Bakhvalov meshes case, here also one has to solve a system 
of nonlinear equations to obtain the nonuniform meshes for the solution of a 
linear SPP. Further, it is an iterative process, therefore, it is computationally 
expensive. This method does not require any a priori information about the 
location and the width of the boundary layers. Therefore, several real appli-
cation problems in higher-dimensions can be solved on these equidistribution 
meshes. 

14.5 LAYER-ADAPTED NONUNIFORM MESHES 
353 
REFERENCES 
1. Allen, D.N. and Southwell, R. V., Relaxation methods applied to determine the 
motion in 2D of a viscous fluid past a fixed cylinder. Quater. J. Mech. and 
Appl. Math., VIII(2): 129-145 (1955). 
2. Bakhvalov, A. S., On the optimization of methods for solving boundary value 
problems with boundary layers. Zh. 
Vychisl. 
Mat. i Mat. Fis., 9:841-859 
(1969). (In Russian). 
3. Bush, A. W., Perturbation Methods for Engineers and Scientists. 
CRC Press, 
Boca Raton (1992). 
4. Chang, K.W. and Howes, F.A., Nonlinear Singular Perturbation 
Phenomena: 
Theory and Applications. Springer, New York (1984). 
5. Cohen D.S., Multiple stable solutions of nonlinear boundary-value problems 
arising in chemical reactor theory. SIAM J. Math. Anal., 20:1-13 (1973). 
6. Doolan, E. P., Miller J. J. H., and Schildres, W. H. A., Uniform 
Numerical 
Methods for Problems with Initial and Boundary Layers. Boole Press, Dublin 
(1980). 
7. Eckhaus, W., Asymptotic 
Analysis of Singular Perturbations. 
Noth-Holland, 
Amsterdam (1979). 
8. Farrell, P. A., Hegarty, A. F., Miller, J. J. H., O'Riordan, E. and Shishkin, G.I., 
Robust Computational Techniques for Boundary Layers. Chapman & Hall/CRC 
Press (2000). 
9. Il'in A.M., Differencing schemes for a differential equation with a small param-
eter affecting the highest derivative. Math. Notes, 6:596-602 (1969). 
10. Israeli, M. and Ungarish, M., Improvement of numerical solution of boundary 
layer problems by incorporation of asymptotic approximations. Numer. 
Math., 
39:309-324 (1982). 
11. Jayakumar, J. and Ramanujam, N., A numerical method for singular pertur-
bation problems arising in chemical reactor theory. Comput. 
Math. 
Applic, 
27(5):83-99 (1994). 
12. Kellogg, R. B. and Tsan, A., Analysis of some difference approximations for 
a singular perturbation problem without turning points. 
Math. 
Comput, 
32(144): 1025-1039 (1978). 
13. Lagerstrom, P. A., Matched Asymptotic Expansions. Springer, New York (1988). 
14. Mackenzie, J., Uniform convergence analysis of an upwind finite-difference ap-
proximation of a convection-diffusion boundary value problem on an adaptive 
grid. IMA J. Numer. Anal., 19:233-249 (1999). 
15. Miller, J. J. H., O'Riordan, E. and Shishkin, G.I., Fitted Numerical Methods for 
Singular Perturbation Problems. World Scientific, Singapore (1996). 
16. Natesan, S. and Ramanujam, N., Initial-value technique for singularly perturbed 
boundary-value problems for second-order ordinary differential equations arising 
in chemical reactor theory. J. Optim. Theory Appl., 97(2):455-470 (1998). 

354 
CHAPTER 14. NUMERICAL METHODS FOR PERTURBED DEs 
17. Natesan, S. and Ramanujam, N., A "booster method" for singular perturbation 
problems arising in chemical reactor theory. Appl. Math. Comput., 100:27-48 
(1999). 
18. Nayfeh, A. H., Perturbation Methods. John Wiley & Sons, New York (1973). 
19. O'Malley, R.E., Introduction to Singular Perturbations. 
Academic Press, New 
York (1974). 
20. Roberts, S.M., A boundary value technique for singular perturbation problems. 
J. Math. Anal. Appl., 87:489-508 (1982). 
21. Roos, H.-G. , Stynes, M. and Tobiska, L., Numerical Methods for Singularly 
Perturbed Differential Equations. 
Springer-Verlag, Berlin, (2008), Second edi-
tion. 
22. Shishkin, G. I., A difference scheme on a nonuniform mesh for a differential 
equation with a small parameter in the highest derivative. U.S.S.R. 
Comput. 
Maths. Math. Phys., 23:59-66 (1983). 

PART III 
ADVANCED MODELING 
TOPICS 
Mathematical Modeling with Multidisciplinary Applications.
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

CHAPTER 15 
FRACTIONAL CALCULUS AND ITS 
APPLICATIONS 
I v o 
P E T R A S 
Technical University of Kosice, Slovakia 
15.1 
INTRODUCTION 
It is well-known that an important part of mathematical modeling of objects 
and processes is a description of their dynamics. In this manner we obtain 
a dynamical mathematical model, usually in the form of differential equations. 
In such equations we are able to use a mathematical phenomenon, so-called 
"fractional calculus." 
The term fractional calculus is more than 300 years old. It is a generaliza-
tion of the ordinary differentiation and integration to noninteger (arbitrary) 
order. The subject is as old as the calculus of differentiation and goes back 
to times when Leibniz, Gauss, and Newton invented this kind of calculation. 
In a letter to L'Hopital in 1695 Leibniz raised the following question: "Can 
the meaning of derivatives with integer order be generalized to derivatives 
Mathematical Modeling with Multidisciplinary Applications. 
357 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

358 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
with noninteger orders?" The story goes that L'Hopital was somewhat curi-
ous about that question and replied with another question to Leibniz. "What 
if the order will be 1/2?" Leibniz in a letter dated September 30, 1695 replied: 
"It will lead to a paradox, from which one day useful consequences will be 
drawn." The question raised by Leibniz for a fractional derivative was an on-
going topic for the last 300 years. Several mathematicians contributed to this 
subject over the years. People like Liouville, Riemann, and Weyl made major 
contributions to the theory of fractional calculus. The story of the fractional 
calculus continued with contributions from Fourier, Leibniz, Grünwald, and 
Letnikov. Nowadays, fractional calculus attracts many scientists and engi-
neers. There are several applications of this mathematical phenomenon in 
mechanics, physics, chemistry, electrical circuits, control theory, chaos, and 
so on [3,5,14,16,21,22,25,27,35,38,43,50]. Those applications prove that the 
fractional calculus is a calculus of the 21st century and in present days should 
be consider as a basic mathematical tool. 
In the past, the main reason for using integer-order models was the absence 
of solution methods for fractional differential equations. At present there are 
many methods for the approximation of the fractional derivative and integral 
and fractional calculus can be easily used in wide areas of applications. 
Currently, the number of applications of fractional calculus rapidly grows. 
These mathematical phenomena allow us to describe and model a real object 
more accurately than the classical "integer" methods. The real objects are 
generally fractional [28,38,51], however, for many of them, the fractionality is 
very low. A typical example of a noninteger (fractional) order system is the 
voltage-current relation of a semi-infinite lossy transmission line or diffusion 
of heat through a semi-infinite solid, where the heat flow is equal to the half-
derivative of the temperature [38]. 
It is important to note, what is the main reason for using fractional calculus 
in mathematical modeling. It is not correct, if we just replace integer-order 
derivative with a fractional one without any good reason. There are several 
reasons which lead to the fractional-order models, not necessarily constant but 
also variable and of distributed order. We can summarize them as follows: 
• Memory of the modeled processes or systems, e.g., heat transfer, or 
inductor hysteresis, where for a general current in the inductor the volt-
age is V(t) = L 
dlX', and where L is inductance of the inductor and 
constant a (order) is related to the "proximity effect." 
• Hereditary behavior of the process or systems, e.g., viscoelasticity. 
• Porous or rough materials, e.g., capacitor electrode. For a general input 
voltage V(t) the current is I(t) = C 
dt^ ' , where C is capacitance of 
the capacitor. It is related to the kind of dielectric. Another constant 
a (order) is related to the losses of the capacitor. 

15.2 FRACTIONAL CALCULUS FUNDAMENTALS 
359 
• Recursivity and selfsimilarity (fractality), e.g., RC ladder network, con-
nection of n series (parallel) RC branches, with recursive parameters 
Rk+i = aRk, Cfc+i = bCk, k = 1,..., n, where 0 < a < 1 and 0 < b < 1. 
• Chaotic behavior of the system, e.g., Brownian motion, diffusion, etc. 
In this chapter we bring basic information on fractional calculus, fractional-
order systems, and examples of the applications used fractional-order models. 
15.2 
FRACTIONAL CALCULUS FUNDAMENTALS 
15.2.1 
Special Functions 
Here, we should mention the most important function used in fractional cal-
culus, Euler's Gamma function, which is defined as 
/•OO 
Γ(χ)= / 
r ' e - ' d i . 
(15.1) 
Jo 
This function is generalization of a factorial in the following form: 
T(x) = (x - 1)! 
(15.2) 
Another function which plays a very important role in the fractional cal-
culus, was in fact introduced by Humbert and Agarwal in 1953. It is a two-
parameter function of the Mittag-Leffler type defined as [38] 
0 0 
k 
There are some relationships (given, e.g., in Ref. [38]) 
Ei,1{z) = ez, -E1/2>1(v^) = 4 = e " Z e r f c ( - ^ ) ' E2A(-z2)=coS(z). 
(15.4) 
For the numerical evaluation of the Mittag-Leffler function the Matlab 
routine mlf () written by Podlubny and Kacenak can be used [42]. 
15.2.2 
Definitions of Fractional Operator 
Fractional calculus is a generalization of integration and differentiation to 
noninteger-order fundamental operator aDf, 
where a and t are the bounds 
of the operation and a £ R. The continuous integro-differential operator is 
defined as 
£, 
: a > 0, 
aDt
Q = { 1 
: a = 0, 
£(άτ)-° 
:a<0. 

360 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
The three most frequently used definitions for the general fractional differ-
integral are: the Grünwald-Letnikov (GL) definition, the Riemann-Liouville 
(RL) and the Caputo definition [24,26,38]. Other definitions are connected 
with well-known names as, for instance, Weyl, Fourier, Cauchy, Nishimoto, 
etc. 
In this chapter we will consider mainly the GL, the RL, and the Caputo's 
definitions. This consideration is based on the fact that, for a wide class 
of functions, the three best known definitions—GL, RL, and Caputo—are 
equivalent under some conditions [38]. 
15.2.3 
Grünwald-Letnikov Fractional Derivatives 
If we consider n = ^jp, where a is a real constant, which expresses a limit 
value, we can write 
\t~a\ 
aD?f(t)= limi- ^i-iyfyfit-jh), 
(15.5) 
where \x] means the integer part of x, a and t are the bounds of operation for 
aD?f(t). 
For binomial coefficients calculation we can use the relation between Euler's 
Gamma function and factorial, defined as 
^
- 
a[ 
- 
Γ < Ω + 1) — 
for (
"
W 
(15.6) 
j) 
JKa-JV- 
r(j + l ) r ( a - j + l) 
\0 
15.2.4 
Riemann-Liouville Fractional Derivatives 
Formula for the Riemann-Liouville definition of fractional derivative of the 
order a has the following form: 
•^w-RsWspjföi^BT*.
 
(15·
7) 
for (n — 1 < a < n), where a and t are the limits of operation 
aD"f(t). 
15.2.5 
Caputo Fractional Derivatives 
The Caputo definition of fractional derivatives can be written as 
•*™ = l^)fa(t-lT^dT> 
fOT {n~l <a<n)-
 
( 1 5·
8 ) 

15.2 FRACTIONAL CALCULUS FUNDAMENTALS 
361 
Let us denote the Riemann-Liouville fractional derivative as ^LD^f(t) 
and 
the Caputo definition as ^D"f(t), 
then the relationship between them is 
RLD?f{t) 
= °D?f(t) + 
^§k\a^1/kHa), 
for /(fc)(a) = 0, (fc = 0 , l , . . . , n - l ) . 
The initial conditions for the fractional-order differential equations with 
the Caputo derivatives are in the same form as for the integer-order differen-
tial equations. It is an advantage because applied problems require definitions 
of fractional derivatives, where there are clear interpretations of initial condi-
tions, which contain f(a), f (a), f (a), ..., 
f^n~^(a). 
15.2.6 
Laplace Transform Method 
The Laplace transform method is a very frequently used tool for solving en-
gineering problems. 
For zero initial conditions, the Laplace transform of fractional derivatives 
of order a (Grünwald-Letnikov, Riemann-Liouville, and Caputo's) reduces to 
J?{oD?f{t)} 
= saF(s). 
(15.9) 
Moreover, the Laplace transform of the Riemann-Liouville fractional deriva-
tive is well-known. However, its practical applicability is limited by the ab-
sence of the physical interpretation of the limit values of fractional derivatives 
at the lower bound t = 0. So far, such an interpretation was partially solved 
only in Ref. [13]. 
15.2.7 
Some Properties of Fractional Calculus 
The main properties of fractional derivatives/integrals are as follows [26]: 
1. If f(t) is an analytical function of t, then its fractional derivative oD"f(t) 
is an analytical function of t, a. 
2. For a = n, where n is integer, the operation oDff{t) 
gives the same 
result as classical differentiation of integer order n. 
3. For a = 0 the operation §Df f(t) is the identity operator: 
0D°J(t) = f(t). 
4. Fractional differentiation and fractional integration are linear opera-
tions: 
aD? (λ/(ί) + μ9(ί)) = λ aD?f(t) 
+ μ aD?g(t). 
(15.10) 

362 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
5. The additive index law (semigroup property) 
0D?0D?f(t) 
= 0D?oD?f(t) 
= 
oD?+0f(t) 
holds under some reasonable constraints on the function 
f(t). 
The fractional-order derivative commutes with integer-order derivative 
§;{aDlf{t)) = aDl ^Μ^ 
= aD^f(t), 
(15.11) 
under the condition i = owe have/(fc)(o) = 0, (A; = 0,1,2,. ..,n - 1). 
The relationship above says the operators ^ 
and aD[ commute. 
The geometric and physical interpretation of fractional integration and 
fractional differentiation was clearly explained in Podlubny's work [40]. 
Some other important properties of fractional derivatives and integrals as 
for example Leibniz's rule, translation, chain rule, behavior and dependence 
on limit and so on, can be found in several other works (e.g., [24,26,38], etc.). 
15.2.8 
Numerical Methods for Fractional Calculus 
For practical implementation of the fractional calculus in engineering appli-
cations we need a good approximation techniques. 
A description and overview of the various approximation methods and tech-
niques for continuous and discrete fractional-order models in form of IIR and 
FIR filters can be found in [48]. Besides the mentioned methods, some other 
approaches were described in [33]. Last but not least, we should mention the 
matrix approach proposed by Podlubny [39,41]. 
The frequency domain approximation methods are not always reliable, es-
pecially in detecting chaos behavior in nonlinear systems [44,46]. As has been 
shown, due to an error of approximation, numerical simulation may result 
in wrong conclusions, e.g., fake chaos is produced due to the implementa-
tion of the frequency domain approximation methods [45]. Simulation of the 
fractional-order system using the time-domain methods is complicated and 
due to long memory characteristics of these systems requires a very long sim-
ulation time but on the other hand it is more accurate. Applying some ideas 
as, for instance, the short memory principle [38], we can reduce the computa-
tional cost of time-domain methods. Results obtained by these methods are 
more reliable than those determined using the frequency-based approximation 
[46]. 
15.2.8.1 
Grünwald-Letnikov Method 
For numerical calculation of fractional-
order derivatives we can use the relation (15.12) derived from the GL definition 
(15.5). This approach is based on the fact that for a wide class of functions, 
three definitions—GL (15.5), RL (15.7), and Caputo's (15.8)—are equivalent. 

15.2 FRACTIONAL CALCULUS FUNDAMENTALS 
363 
The relation for the explicit numerical approximation of qth derivative at the 
points kh, (k = 1,2,...) has the following form [10,38,49]: 
M m / M ^ / ( t ) « r ' ^ ( - i W 
/ ( i H ) , 
(15.12) 
j=o 
u
/ 
where Lm is the "memory length," tk = kh, h is the time step of calculation 
and (—1)J (?) are binomial coefficients c^' (j = 0,1,...). 
For their calculation 
we can use the following expression [10]: 
0 
1, 
cf = ( i - i ± l ) £ V 
(15.13) 
Then, the general numerical solution of the fractional differential equation 
aDly(t)=f(y(t),t), 
can be expressed as 
k 
y{tk) = f (y(tk), tk) h'-Σ 
cfy(tk.j). 
(15.14) 
For the memory term expressed by the sum, a "short memory" principle can 
be used. Then the lower index of the sums in relations (15.14) will be v = 1 
for k < (Lm/h) 
and υ = k — (Lm/h) 
for k > (Lm/h), 
or without using the 
"short memory" principle, we put v = 1 for all k. 
Obviously, for this simplification we pay a penalty in the form of some 
inaccuracy. If f(t) < M, we can easily establish the following estimate for 
determining the memory length Lm, providing the required accuracy e: 
M 
N 1 / 9 
€ | Γ ( 1 - ς ) | 
(15.15) 
An evaluation of the short memory effect and convergence relation of the error 
between short and long memory were clearly described and also proved in [38]. 
The described numerical method is the so-called Power Series Expansion 
(PSE) of a generating function. It is important to note that PSE leads to an 
approximation in the form of polynomials, that is, the discretized fractional 
operator is in the form of a FIR filter, which has only zeros. 
The resulting discrete transfer function, approximating fractional-order op-
erators, can be expressed in the ^-domain as follows: 
(15.16) 

364 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
where T is the sample period, PSE{u} denotes the function resulting from 
applying the power series expansion to the function u, Y(z) is the Z transform 
of the output sequence y(kT), F(z) is the Z transform of the input sequence 
f(kT), 
n is the order of the approximation, and R is the polynomial of degree 
n, respectively, in the variable z~x, z = exp(sT), and k = 1,2, 
Matlab 
routine df od2 () of this method can be downloaded from the Math Works, Inc. 
website [30]. 
15.2.8.2 
Continuous- and Discrete-Time Approximation Techniques 
Another 
approach can be realized by Continued Fraction Expansion (CFE) of the 
generating function and then the approximated fractional operator is in the 
form of an IIR filter, which has poles and zeros [48]. 
Taking into account that our aim is to obtain equivalents to the fractional 
integrc-differential operators in the Laplace domain, s±r, the result of such an 
approximation for an irrational function, G(s), can be expressed in the form 
G(») 
= οο(«)+ 
h{') 
. ,,Λ , Ms) 
W 
b3(s) 
η ^ ΐ 7 ϊ 
= 
ao(s) H 
;—r 
7~r 
r^— · · · > 
(15.17) 
ai(s)+ a2(s)+ a3(s)+ 
v 
where a^s and b^s are rational functions of the variable s, or are constants. 
The application of the method yields a rational function, which is an approx-
imation of the irrational function G(s). 
In other words, for evaluation purposes, the rational approximations ob-
tained by CFE frequently converge much more rapidly than the PSE and have 
a wider domain of convergence in the complex plane. On the other hand, the 
approximation by PSE and the short memory principle is convenient for the 
dynamical properties consideration. 
For interpolation purposes, rational functions are sometimes superior to 
polynomials. This is, roughly speaking, due to their ability to model func-
tions with poles. These techniques are based on the approximations of an 
irrational function, G(s), by a rational function defined by the quotient of 
two polynomials in the variable s in frequency s-domain 
n( \ ~ D 
Pf(s) 
Po+Pis + 
...+pßs» 
G(s) * Riii+1)..,i+m) 
= ^
= 
qo + q
i
S
+
+
q
i
/
S „ , 
(m+1 = M+^ + D 
(15.18) 
passing through the points (SJ,G(si)), ..., 
(si+m,G(si+m)). 

15.2 FRACTIONAL CALCULUS FUNDAMENTALS 
365 
The resulting discrete transfer function, approximating fractional-order op-
erators, can be expressed as [49]: 
V 
J 
ρ,η 
(15.19) 
where T is the sample period, CFE{u} denotes the function resulting from 
applying the continued fraction expansion to the function u, Y(z) is the Z 
transform of the output sequence y(kT), F(z) is the Z transform of the input 
sequence f(kT), 
p and n are the orders of the approximation, and P and 
Q are polynomials of degrees p and n, respectively, in the variable z~l, and 
k = 1,2, 
Matlab routine df odl() can be downloaded from MathWorks, 
Inc. web site [31]. 
In general, the discretization of fractional-order differentiator/integrator 
s±r ^r g j ^ c a n b e e xp r e s s e ci by the generating function s « ω(ζ~λ). 
This 
generating function and its expansion determine both the form of the approx-
imation and the coefficients [20]. 
In this section, for directly discretizing sr, (0 < r < 1), we shall concentrate 
on the IIR form of discretization where as a generating function we will adopt 
an Al-Alaoui idea on a mixed scheme of Euler and Tustin operators, but 
we will use a different ratio between both operators. The mentioned new 
operator, raised to power ±r, has the form [31] 
._,,, ±, 
, 1+α 1 
^ ■Ι Τ Γ Ϊ Ρ Γ
 
( 1 5·
2 0 ) 
where a is the ratio term and r is the fractional order. The ratio term a is the 
amount of phase shift and this tuning knob is sufficient for most engineering 
problems being solved. 
In expanding the above in rational functions, we will use the CFE. It 
should be pointed out that, for control applications, the obtained approxi-
mate discrete-time rational transfer function should be stable. Furthermore, 
for a better fit to the continuous frequency response, it would be of high in-
terest to obtain discrete approximations with poles and zeros interlaced along 
the line z € (—1,1) of the z plane. The direct discretization approximations 
proposed in this chapter enjoy the desired properties. 
The result of such approximation for an irrational function, G{z~x), 
can 
be expressed by G(z~1) in the CFE form [48] 
Giz-1) 
~ 
α0(ζ-')+ 
6 l ( z _ 1 ) 
a\{z~ 
- 1) 
a2(z-
b2(z 
b2(z-
^ + Ζ 
r1) 
-1) 
<>3(* -1) 
b3(z- -1) 
a°{Z 
) + αι(ζ-ΐ)+ α2(ζ~η+ 
---α3(ζ-η-

366 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
where a* and bi are either rational functions of the variable z~x or constants. 
The application of the method yields a rational function, G{z~1), which is an 
approximation of the irrational function 
G(z~1). 
The resulting discrete transfer function, approximating fractional-order op-
erators, can be expressed as 
- l \ \ ± r 
(ω(ζ-1)) 
(15.21) 
<7o + qiz~L H 
\- qnz' 
where CFE{u} denotes the continued fraction expansion of u; p and q are the 
orders of the approximation and P and Q are polynomials of degrees p and 
q. Normally, we can set the order of approximation p = q = n. 
■ EXAMPLE 15.1 
Here we present some results for fractional order r = 0.5 (half-order 
derivative). The value of approximation order n is truncated to n — 5 
and weighting factor a was chosen a = 1/3. Assume sampling period 
T = 0.001 s. The approximation of the fractional half-order derivative 
obtained by routine dfodlO is [37] 
! 
985.9 - 1315z-1 + 328.6Z~2 + 36.51z-3 
G{Z 
) = 
2 7 - 1 8 z - i - 3 z - » + z-»
 
( 1 5 ·
2 2 ) 
The Bode plots and unit step response of the digital fractional-order 
differentiator (15.22) and the analytical continuous solution of a frac-
tional semiderivative are depicted in Figure 15.1. Poles and zeros of the 
transfer function (15.22) lie in a unit circle. 
For simulation purpose, here we also present the Oustaloup's Recursive Ap-
proximation (ORA) algorithm [28,29]. The method is based on the approxi-
mation of a function of the form 
H{s) = sr, 
r e R, 
re [-1; 1] 
(15.23) 
for the frequency range selected as (ωι,,ωπ) by a rational function: 
H{s) = C0 Π 
°-±^, 
(15.24) 

15.2 FRACTIONAL CALCULUS FUNDAMENTALS 
367 
-50 
Bode plots 
io 
io 
Frequency [Hz] 
s ' : continuous analytical solution 
s 
: approximated discrete solution 
10 
10 
Frequency [Hz] 
(a) Bode plots for r = 0.5, n = 5, a = 1/3, and T = 0.001 s in 
(15.21). 
1 
100 
80 
60 
40 
2 0 
Step response 
■ 
^ ^ - s ' : continuous analytical solution 
s ' : approximated discrete solution 
-
-
. 
0.02 
0.04 
0.06 
Time [sec] 
0.08 
(b) Unit step responses for r = 0.5, n = 5, a = 1/3, and T 
0.001s in (15.21). 
Figure 15.1 
Characteristics of approximated fractional-order differentiator (15.22). 
using the following set of synthesis formulas for zeros, poles and the gain: 
uk 
=u)b 
Ub 
k+N%irr) 
üJk 
= U > 6 
Uh, 
fc + W + 0 . 5 ( l - r ) 
2ΛΓ + 1 
Wb , 
N 
UJh\ 
' Ti °±k 
Co = p 
Π ^ 
(15.25) 

368 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
where α^, ω^ are the high and low transitional frequencies. An implementation 
of this algorithm in Matlab as a function ora_f oc() is given in [6]. 
■ EXAMPLE 15.2 
Using the described Oustaloup's Recursive Approximation (ORA) method 
with 
wh = 103, 
tjb = 1(T3, 
(15.26) 
the obtained approximation for fractional function H(s) = s~05 is [37] 
jj- 
s5 + 74.97s4 + 768.5s3 + 1218s2 + 298.5a + 10 
s ( s ) _ 10s5 + 298.5s4 + 1218s3 + 768.5s2+ 74.97s+l' 
*· ' 
' 
The Bode plots and the unit step response of the approximated fractional-
order integrator (15.27) are depicted in Figure 15.2. 
15.2.8.3 Adams-Bashforth-Moulton Method For numerical simulation of the 
fractional-order system a method on the basis of the Adams-Bashforth-Moulton 
type predictor-corrector scheme has also been proposed [9]. It is suitable for 
Caputo's derivative because it just requires the initial conditions and for an 
unknown function it has clear physical meaning. The method is based on the 
fact that the fractional differential equation 
Dq
ty{t) = f(y(t), t), i/<*>(0) = y{
0
k\ k = 0 , 1 , . . . , m - 1 
is equivalent to the Volterra integral equation 
I«]-1
 
fk 
i 
rt 
V(t) = Σ 
*>ofc)^! +f{q)J0
{t~ 
^9_1/(τ,2/(τ))(ίτ. 
(15.28) 
Discretizing the Volterra equation (15.28) for a uniform grid tn = nh (n — 
0,1,...,N), h = TSim/N 
and using the short memory principle (fixed or 
logarithmic) we obtain a good numerical approximation of the true solution 
y{tn) of fractional differential equation while preserving the order of accuracy. 
Assume that we have calculated approximations yh(tj), j = 1,2,..., n and we 
want to obtain yh{tn+i) by means of the equations 
yh(tn+1) - 
Eiryo f c ) + f(^^y/(Wi,^(in+i)) 
hq 
n 
+ r ( a + 2 ) ^ a J > + ^ f e ^ " f e ) ) ' 
(15·29) 

15.2 FRACTIONAL CALCULUS FUNDAMENTALS 
369 
Bode plots 
10 
10 
Frequency [Hz] 
(a) Bode plots for r = —0.5 and N = 5. 
Step response 
0 
500 
1000 
1500 
2000 
2500 
3000 
3500 
Time [sec] 
(b) Unit step response for r = —0.5 and JV = 5. 
Figure 15.2 
Characteristics of approximated fractional-order integrator (15.27). 
where 
n« + 1 - (n - q){n + 
l)q, 
o i i n +i = { 
(n-j 
+ 2)«+1 + (n- 
j ) 9 + 1 + 2(n -j 
+ 1)«+1 
if j = 0, 
if 1 < j < n, 
if j = n + 1. 
The preliminary approximation j/^(i n+i) is called a predictor and it is given 
by 
m — 1 ,fc 
- 
n 
J/E(*»+i) = Σ " T T ^ + fTrEW/fe-Wnitj)). 
(15-30) 
fe=0 
Γ(9) j=o 

370 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
where 
hq 
bjin+1 = — ((n + 1 - j) 9 - (n - j)9)· 
(15.31) 
15.3 
FRACTIONAL-ORDER SYSTEMS AND CONTROLLERS 
15.3.1 
Fractional LTI Systems 
A general fractional-order system can be described by a fractional differential 
equation of the form 
anDa"y(t) 
+ an^Da^y(t) 
+ ... + 
a0Da°y(t) 
= bmDß™u(t) + bm-iDßm-1u(t) 
+ ... + b0Dßou(t), 
(15.32) 
where ΌΊ = oD] denotes the Grünwald-Letnikov, the Riemann-Liouville or 
the Caputo's fractional derivative [38]. The corresponding transfer function 
of incommensurate real orders has the following form [38]: 
= bmsß™ + ... + b^+boSß° 
= Q£Ä) 
w 
ansa" + ... + ais Q l + a0sa° 
P(sai<) 
or in the frequency domain it has the form 
GW=bjjT+-+bjjT+6f f° =
 Q S T \ , (15.34) 
an{ju))a» + ... + ai(jw)Ql + α 0(.Η"° 
P((jW)a<=)' 
where ak (fc = 0,... n), bk (k — 0,... m) are constant, and α^ (k = 0,... n), 
/3fc (fc = 0,... m) are arbitrary real or rational numbers and without loss of 
generality they can be arranged as an > αη_ι > ... > a0> and ßm > ßm-\ 
> 
The incommensurate order system (15.33) can also be expressed in com-
mensurate form by the multivalued transfer function [2] 
H(s> = —I^ÄTT 
7 
ΓΑΓΤ—' 
w > !)■ 
(15.35) 
ansn'v 
H 
h aisi'v 
+ a0 
Note that every fractional-order system can be expressed in the form (15.35) 
and the domain of the H(s) definition is a Riemann surface with v Riemann 
sheets [18]. 
In the particular case of commensurate-order systems, it holds that, Qfe = 
ak,ßk = ak, (0 < a < 1), Vfc € Z, and the transfer function has the following 
form: 
"<"-*!£££-*·?£!■ 
(15-36) 

15.3 FRACTIONAL-ORDER SYSTEMS AND CONTROLLERS 
371 
With TV > M, the function G(s) becomes a proper rational function in the 
complex variable sa which can be expanded in partial fractions of the following 
form: 
G{s) = K0 
N 
y-sa + \i 
(15.37) 
where λ* (i = 1,2,.., N) are the roots of the pseudo-polynomial P(sa) or the 
system poles which are assumed to be simple without loss of generality. The 
analytical solution of the system (15.37) can be expressed as 
y(t) = X-1 { K0 
N 
y-
i = l Sa + \i 
N 
KoyAitaEa,a{-\ita), 
(15.38) 
i = l 
where Εμ^ν{ζ) is the Mittag-Leffler function denned as (15.3). 
A fractional-order plant to be controlled can be described by a typical 
n-term linear homogeneous fractional-order differential equation (FODE) in 
time domain 
an Df"y(t) + ■ ■ ■ + ai Dfly(t) 
+ a0 Df°y(t) = 0 
(15.39) 
where ak (k = 0,1,··· ,n) are constant coefficients of the FODE; ak (k = 
0,1,2, · · · , n) are real numbers. Without loss of generality, assume that an > 
α„_ι > ... > a0 > 0. 
The analytical solution of the FODE (15.39) is given by a general formula 
in the form [38] 
i 
°° 
y(t) = f Σ 
(-1Γ 
m! 
y 
(m;k0,ki,... 
,fc„_2) 
m-0 
n-2 
, 
x ki 
k0 + k1+... 
+ k7l_2 = rr 
k0>0;... 
, k „ _ 2 > 0 
η — Δ 
y 
\ 
Ki 
Π Ι 2±\ 
e (+ 
Q " - i . 
_ 
=0 
n-2 
y{<*n-l 
~ Otj)kj + 1), 
j=0 
(15.40) 
where (m; ko,k\,... 
, fcn_2) are the multinomial coefficients and 8K(t, X; μ, u) is 
the function of Mittag-Leffler type introduced by Podlubny [38]. The function 
is defined by 
Sk(t, λ; μ, ν) = ί"*+"-1Μ*0 (At"), 
(k = 0,1, 2,...), 
(15.41) 
where Ejxtl(z) is fcth derivative of the Mittag-Leffler function of two parame-
ters given by 

372 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
* g M = g
i
!
r i ; ^ ; „ . 
<* = 0.1,2,...). 
(15.42, 
The Laplace transform of the function 8k (t, ±λ; a, β) is [38] 
k\sa-ß 
Jtf{£k(t,±X;a,ß)} 
(sa ψ A)fe+! 
for s > \X\Va. 
The Laplace transforms for several other Mittag-Leffler type functions are 
summarized as follows [21]: 
J?{Ea(-Xta)} 
= 
sa-l 
Sa + X' 
afit^E^i-Xt«)} 
= 
— ! — , 
(15.43) 
S 
T A 
SfitP-iEafi-Xt")} 
sa + X' 
Consider a control function which acts on the FODE system (15.39) as 
follows: 
an D?»y(t) + ■ ■ ■ + ai D^y(t) 
+ a0 D?°y(t) = u(t). 
(15.44) 
By Laplace transform, we can get a fractional transfer function: 
Y(t) 
1 
G(s) = - f ( = 
. 
(15.45) 
w 
U{s) 
ansa» + ■ ■ ■ + aisai + a0sa<> 
v 
' 
The fractional-order linear time-invariant (LTI) system can also be repre-
sented by the following state-space model (see, e.g., Ref. [23]) 
0D?x(t) 
= 
Ax(t) + Bu(t) 
y(t) 
= 
Cx(t), 
(15.46) 
where x G Rn, u G Rr and y G Rp are the state, input and output vectors of 
the system and A G R"x", B G R n x r, C G Rpx", and q = [qi,q2,.. 
.,qn]T 
are the fractional orders. If q\ = q2 = .. .qn = Q, system (15.46) is called a 
commensurate-order system, otherwise it is an incommensurate-order system. 

15.3 FRACTIONAL-ORDER SYSTEMS AND CONTROLLERS 
373 
15.3.2 
Fractional Nonlinear Systems 
In this chapter, we will consider the general incommensurate fractional-order 
nonlinear system represented as follows: 
0Dfxi(t) 
= 
fi(x1(t),x2(t),...,xn(t),t), 
Xi(0) 
= 
a, i = l,2,...,n, 
(15.47) 
where Cj are initial conditions. The vector representation of (15.47) is 
£>qx = f(x), 
(15.48) 
where q = [qi, q2,..., qn)T for 0 < ς, < 2, (i = 1,2,..., n) and x € R™. 
The equilibrium points of system (15.48) are calculated via solving the 
following equation: 
f(x) = 0 
(15.49) 
and we suppose that E* = (x*, x^,..., 
x*) is an equilibrium point of system 
(15.48). 
15.3.3 
Fractional-Order Controllers 
15.3.3.1 
Definition of Fractional-Order Controllers The fractional-order PIXDS 
(a.k.a. ΡΙχϋμ 
controller) controller (FOC) was proposed in [38] as a general-
ization of the PID controller with integrator of real order λ and differentiator 
of real order δ. The transfer function of such controller in the Laplace domain 
has this form: 
C(s) = ^-=Kp 
+ TiS-x+Tdss, 
(\,S>0), 
(15.50) 
&(s) 
where Kp is the proportional constant, Tj is the integration constant and T<j 
is the differentiation constant. 
The internal structure of the fractional-order controller consists of the par-
allel connection, the proportional, integration, and derivative part [11]. The 
transfer function (15.50) corresponds in time domain to a fractional differen-
tial equation 
u(i) = Kp e(t) + Ti 0D^xe(t) 
+ Td 0D5
te(t), 
(15.51) 
or a discrete transfer function given in the following expression: 
C^ = W)=Kp 
+ R^F + Wz"1))Ä'
 
( 1 5·
5 2 ) 
where ω(ζ_1) denotes the discrete operator, expressed as a function of the 
complex variable z or the shift operator ζ~λ. 

374 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
Taking λ = 1 and δ = 1, we obtain a classical PID controller. If λ = 0 
and Tj = 0, we obtain a PDS controller, etc. All these types of controllers 
are particular cases of the fractional-order controller, which is more flexible 
and gives an opportunity to better adjust the dynamical properties of the 
fractional-order control system. 
It can also be mentioned that there are many another considerations of the 
fractional-order controller [7,25,35]. For example we can mention several of 
them: three generations of CRONE controller, TID compensator, fractional 
lead-lag compensator, etc. 
It can be expected that PIXDS controller (15.50) may enhance the systems 
control performance due to more tuning knobs introduced. For a wide class 
of controlled objects we recommend the fractional PInDs 
controller, which 
is a particular case of PIXDS 
controller, where λ = n, n € N and δ € R. 
The integer-order integrator is important for steady-state error cancellation 
but on the other hand the fractional integral is also important for obtaining 
a Bode's ideal loop transfer function response with a constant phase margin 
for a desired frequency range [4]. 
15.4 
STABILITY OF FRACTIONAL-ORDER SYSTEMS 
Stability as an extremely important property of the dynamical systems can 
be investigated in various domains [11]. The usual concept of bounded input-
bounded output (BIBO) or external stability in time domain can be defined 
via the following general stability conditions [23]: 
A causal LTI system with impulse response h(t) will be BIBO stable if the 
necessary and sufficient condition is satisfied 
/•OO 
/ 
||/»(T)||dT<oo, 
Jo 
where the output of the system is defined by convolution 
/>00 
y(t) = h{t) * u(t) = / 
h(r)u(t - τ)άτ, 
Jo 
where u,y € L^ and h e L\. 
Another very important domain is frequency domain. In the case of a fre-
quency method for evaluating the stability we transform the s-plane into the 
complex plane G0(ju) and the transformation is realized according to the 
transfer function of the open loop system G0(JLO). 
During the transforma-
tion, all roots of the characteristic polynomial are mapped from the s-plane 
into the critical point (—l,j'0) in the plane G0{jw). 
The mapping of the s-
plane into the G0{jw) plane is conformal, that is, the direction and location 
of points in the s-plane is preserved in the G0(.7'a>) plane. A frequency investi-

15.4 STABILITY OF FRACTIONAL-ORDER SYSTEMS 
375 
gation method and utilization of the Nyquist frequency characteristics based 
on argument principle were described in Ref. [25]. 
However, we cannot directly use algebraic tools as, for example, Routh-
Hurwitz criteria for the fractional-order system, because we do not have 
a characteristic polynomial but pseudo-polynomial with a rational power-
multivalued function. 
When dealing with incommensurate fractional-order systems (or, in gen-
eral, with fractional-order systems) it is important to bear in mind that P (sa), 
a € R is a multivalued function of sa, a — —, the domain of which can be 
viewed as a Riemann surface with a finite number of Riemann sheets v, where 
the origin is a branch point and the branch cut is assumed at R~ (see Fig-
ure 15.3). Function sa becomes holomorphic in the complement of the branch 
cut line. It is a fact that in multivalued functions only the first Riemann sheet 
has its physical significance [18]. Note that each Riemann sheet has only one 
edge at the branch cut and not only poles and singularities originated from 
the characteristic equation, but branch points and branch cuts of given mul-
tivalued functions are also important for the stability analysis [35]. 
Figure 15.3 
Branch cut (0, —oo) for branch points in the complex plane. 
In this chapter the branch cut is assumed at R 
and the first Riemann 
sheet is denoted by Ω and defined as (see also Figure 15.3) 
n : = { r e J ' * | r > O , - 7 r < 0 < 7 r } . 
(15.53) 
It is well-known that an integer-order LTI system is stable if all the roots 
of the characteristic polynomial P(s) are negative or have negative real parts 
if they are complex conjugate (e.g., Ref. [11]). This means that they are 
located on the left of the imaginary axis of the complex s-plane. System 
G(s) = Q(s)/P(s) 
is BIBO stable if 
3, 
\\G(s)\\ < M < oo, M > 0, Vs, H(s) > 0. 

376 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
A necessary and sufficient condition for the asymptotic stability is 
Kmt^WgWW 
= 0. 
■ EXAMPLE 15.3 
Let us investigate the transfer function of fractional-order system (mul-
tivalued function) defined as 
G(s) = —!—, 
(15.54) 
where a <E R (0 < a < 2) and b € R (b > 0). 
The analytical solution of the fractional-order system (15.54) obtained 
according to relation (15.40) has the following form: 
g(t)=So(t,-b\a,a). 
(15.55) 
The Riemann surface of the function (15.54) contains an infinite num-
ber of sheets and infinitely many poles in positions 
s = bi e3("+°"n), 
n = 0 , ± l , ± 2 , . . . 
,for {a > 0)and(6 > 0). 
The sheets of the Riemann surface are all different if a is irrational. 
For 1 < a < 2 we have two poles corresponding to n = 0 and n = — 1, 
and the poles are 
j ,
1 
±iJL 
s — oae 
a . 
However, for 0 < a < 1 in (15.54) the denominator is a multivalued 
function and the singularity of the system can not be defined unless it 
is made single valued. Therefore we will use the Riemann surface. Let 
us investigate transfer function (15.54) for a = 0.5 (half-order system), 
then we get 
G(s) = -jl—, 
(15.56) 
S2 + 0 
and by equating the denominator to zero we have 
si +b = 0. 
Rewriting the complex operator s^ in exponential form and using the 
well-known relation ej* + 1 — 0 (or e
J(±7r+2fc7r) + 1 — 0) we get the 
following formula: 
rieM/2+kn) 
= aej(±n+2kn)_ 
^
^ 

15.4 STABILITY OF FRACTIONAL-ORDER SYSTEMS 
377 
From relationship (15.57) it can be deduced that the modulus and phase 
(arg) of the pole are 
r = b2 and φ = ±2π(1 + k) for k = 0,1,2,.... 
However, the first sheet of the Riemann surface is defined for range of 
—π < φ < +7Γ, the pole with the angle φ = ±2π does not fall within 
this range but the pole with the angle φ = 2π falls to the range of the 
second sheet defined for π < φ < 2π. Therefore this half-order pole with 
magnitude b2 is located on the second sheet of the Riemann surface that 
consequently maps to the left side of the ιυ-plane (see Figure 15.4). On 
this plane the magnitude and phase of the single valued pole are b2 and 
7Γ, respectively [18]. 
Figure 15.4 
Correspondence between the s-plane and the w-plane. 
Generally, for the multivalued function defined as follows 
w = si, 
(15.58) 
where v € N (v = 1,2,3,...) we get the v sheets in the Riemann surface. In 
Figure 15.5 is shown the relationship between the u;-plane and the v sheets 
of the Riemann surface where sector — π/υ < arg(w) < π/ν corresponds to Ω 
(first Riemann sheet). 
Mapping the poles from the s9-plane into the w-plane, where q £ Q is such 
that q = — for k, m € N and |arg(u>)| = \φ\, can be done by the following rule: 

378 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
(a) Riemann surface 
hn(w) 
shect2 
sheet v 
(b) Complex tu-plane 
Figure 15.5 
Correspondence between the w-plane and the Riemann sheets. 
If we assume fc = 1, then the mapping from s-plane to w-plane is independent 
of fc. Unstable region from the s-plane transforms to sector \φ\ < ^ 
and the 
stable region transforms to sector ^ 
< \φ\ < ^ . The region where \φ\ > ^ is 
not physical. Therefore, the system will be stable if all roots in the ω-plane lie 
in the region \φ\ > ^ . Stability regions depicted in Figure 15.6 correspond 
to the following propositions: 
1. For fc < m (q < 1) the stability region is depicted in Figure 15.6(a). 
2. For fc = m (q = 1) the stability region corresponds to the s-plane. 

15.4 STABILITY OF FRACTIONAL-ORDER SYSTEMS 
379 
3. For k > m (q > 1) the stability region is depicted in Figure 15.6(b). 
(a) 0 < q < 1 
(b) 1< q < 2 
Figure 15.6 
Stability regions of the fractional-order system. 
15.4.1 
Stability of Fractional LTI Systems 
As we can see in previous subsection, in the fractional case, the stability is 
different from the integer case. It is interesting that a stable fractional system 
may have roots in the right half of the complex w-plane (see Figure 15.6). 
Since the principal sheet of the Riemann surface is defined for —π < arg(s) < 
7Γ, by using the mapping w = sq, the corresponding w domain is defined by 
—qn < arg(w) < qir, and the ω-plane region corresponding to the right half 
plane of this sheet is defined by —qn/2 < arg(u;) < qn/2. 
Consider the fractional-order pseudo-polynomial 
Q(s) = ais91 + a2sq2 +... + ansqn = alS
Cl/dl 
+ a2sC2/d2 + ...+ 
ansCn/dn, 
where qi are rational numbers expressed as Ci/di and ai are real numbers for 
i = 1,2,..., n. If for some i, a = 0 then di = 1. Let v be the least common 
multiple (LCM) of d\, d2,... dn denoted as v = LCM{di, d2, ■. ■ dn}, then [12] 
Q(s) = ais » + a2s » + ... + ans » 
= ai(si)Vi 
+ a2{si)V2 
+... + an(si)v". 
(15.59) 
The fractional degree (FDEG) of the polynomial Q(s) is defined as [12] 
FDEG{<2(s)} = max{wi,u2,. 
..,vn}. 
The domain of definition for (15.59) is the Riemann surface with v Riemann 
sheets where the origin is a branch point of order v — 1 and the branch cut is 

380 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
assumed at R . The number of roots for fractional algebraic equation (15.59) 
is given by the following proposition [1]: 
Let Q(s) be a fractional-order polynomial with FDEG{Q(s)} 
= n. Then 
the equation Q(s)=0 has exactly n roots on the Riemann surface. 
The fractional-order polynomial 
Q(s) = ais^ + a2s~^~ + ... + ans» + an+i 
is minimal if FDEG{Q(s)} = n. We will assume that all fractional-order 
polynomials are minimal. This ensures that there is no redundancy in the 
number of the Riemann sheets [12]. 
On the other hand, it has been shown, by several authors and by using 
several methods, that for the case of fractional-order LTI system of commen-
surate order, a geometrical method of complex analysis based on the argument 
principle of the roots of the characteristic equation (a polynomial in this par-
ticular case) can be used for the stability check in the BIBO sense (see, e.g., 
Refs. [23,35]). The stability condition can then be stated as follows [23]: 
A commensurate-order system described by a rational transfer function (15.36) 
is stable if and only if 
|arg (Xi)| >αψ 
for all i 
(15.60) 
with Xj being the ith root of 
P(sa). 
For the fractional-order LTI system with commensurate order where the 
system poles are in general complex conjugate, the stability condition can also 
be expressed as follows [23]: 
A commensurate-order system described by a rational transfer function 
GM = m, 
(1,6I) 
where w = sq, q 6 R+, (0 < q < 2), is stable if and only if 
|arg(ii>i)| 
>q-, 
with Vwi e C being the ith root of P{w) = 0. 
When w = 0 is a single root (singularity at the origin) of P, the system 
cannot be stable. For q = 1, this is the classical theorem of pole location in 
the complex plane: P has no pole in the closed right half plane of the first 
Riemann sheet. The stability region suggested by this theorem tends to the 
whole s-plane when q tends to 0, corresponds to the Routh-Hurwitz stability 
when q = 1, and tends to the negative real axis when q tends to 2. 

15.4 STABILITY OF FRACTIONAL-ORDER SYSTEMS 
381 
It also has been shown that commensurate system (15.46) is stable if the 
following condition is satisfied (also if the triplet A, B, C is minimal) 
\arg(eig(A))\ > <?|, 
(15.62) 
where 0 < q < 2 and eig(A) represents the eigenvalues of matrix A. 
Consider the following autonomous system for internal stability definition 
0D?x(t) = Ax(t), 
x(0) = x0, 
(15.63) 
with q = [qi,q2,- ■ ■, Qn]T and its n-dimensional representation: 
0Dfxi{t) 
= 
ona;i(i)+ai2ar2(i)H 
\-ainxn(t), 
QDfx2{t) 
= 
a2ixi(t) 
+ a22X2(t) + 
l·a2nxn{t), 
0Dlnxn{t) 
= 
a„ixi(t) + an2x2(t) H 
\-annxn{t), 
(15.64) 
where all q^s are rational numbers between 0 and 2. Assume m to be the 
LCM of the denominators Uj's of q^s , where qt = Vi/ui, Vi,Ui € Z + for 
i = 1,2,..., n and we set 7 = 1/m. Define 
det 
/ λ™» - au 
-a12 
... 
-aln 
\ 
-021 
A m « - a 2 2 
... 
-a2n 
\ 
-o„i 
-an2 
... 
\mqn - ann 
) 
0. 
(15.65) 
The characteristic equation (15.65) can be transformed to an integer-order 
polynomial equation if all ^'s are rational number. Then the zero solution of 
system (15.64) is globally asymptotically stable if all roots X^s of the charac-
teristic (polynomial) equation (15.65) satisfy 
7Γ 
|arg(Ai)| > 7 - for alii. 
Denoting λ by s7 in Eq. (15.65), we get the characteristic equation in the 
form det(s77 - A) = 0. 
Suppose q\ = q2 = ..., qn = q, q £ (0,2), all eigenvalues λ of matrix A in 
(15.64) satisfy |arg(A)| > qn/2, the characteristic equation becomes det(s97 — 
A) = 0 and all characteristic roots of the system (15.64) have negative real 
parts. 
■ EXAMPLE 15.4 

382 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
Let us consider two examples of certain class of the fractional-order 
systems [17]. The first of them has the following form: 
oA1 
1.1 
Xl(t) 
a*(t) 
- 1 
0.5 
y(t) 
[ 0 0 
2 
- 3 " 
-2 
0.2 
-1 
- 2 
i ] 
" xi(t) 
Xi(t) 
x3(t) 
Xl(t) ' 
X2(t) 
x3{t) _ 
+ 
" 1 " 
1 
1 
" 
5 
u(t), 
(15.66) 
where x € R . For the system matrix A of the system (15.66) we 
get the following eigenvalues λι,2 = -2.2719 ± 0.8119j,A3 = -7.4562. 
All eigenvalues satisfy the stability conditions (15.60), where |arg(Ai,2)| 
= 2.7984 and |arg(A3)| = π, thus |arg(ei#(A))| > 
system (15.66) is stable. 
The second of them has the following form: 
1.11 and therefore 
oDt 1.2 
Xl(t) 
X2(t) 
x3(t) 
y(t) 
= 
[ o o i 
1 " 
1 
1 
] 
X i(t)] 
X2(t) 
. x3(t) . 
' Xi{t) ' 
X2{t) 
. x ϊθ 0 J 
+ 
' 0 " 
0 
1 
u{t), 
(15.67) 
For the system matrix A of the system (15.67) we get the following 
eigenvalues λι — 1.8284, λ2 = —4, and λ3 = -3.8284. The eigenvalue 
λι does not satisfy the stability condition (15.60), where |arg(Ai)| = 0 
and |arg(Ä2,3)| = π, thus |arg(Ai)| < 1.2^ and therefore system (15.67) 
is unstable. 
15.4.2 
Stability of Fractional Nonlinear Systems 
Stability of the fractional-order nonlinear system is very complex and is dif-
ferent from the fractional-order linear system. The main difference is that 
for a nonlinear system it is necessary to investigate steady states and there 
are two types of them: equilibrium point and limit cycle. Nonlinear systems 
may have several equilibrium points. For nonlinear systems, there are many 
definitions of stability (asymptotic, global, local, orbital, etc.). The basic idea 
was formulated by A. M. Lyapunov. 
As mentioned in Ref. [23], exponential stability cannot be used to charac-
terize asymptotic stability of fractional-order systems. 

15.4 STABILITY OF FRACTIONAL-ORDER SYSTEMS 
383 
Trajectory x(t) = 0 of the system (15.47) is t~q asymptotically stable if 
there is a positive real q such that 
V||a;(i)|| with t < t0, 3N(x(t)), 
such that Vi > t0, \\x(t)\\ < Nt~Q. 
The fact that the components of x(t) slowly decay towards 0 following t~q 
leads to fractional systems sometimes being called long memory systems. 
Power law stability t~g is a special case of the Mittag-Leffler stability [19]. 
According to stability theorem defined in [47], the equilibrium points are 
asymptotically stable for q\ = q^ = ■ ■ ■ = qn = q if all the eigenvalues Aj, (i = 
1,2,...,n) of the Jacobian matrix J = di/dx, 
where f = [/i, /2, · · ·, 
fn]T, 
evaluated at the equilibrium E*, satisfy the condition [44,45] 
|arg(eig(J))| = |arg(Ai)| > ς | , i = 1,2,..., n. 
(15.68) 
Figure 15.6 shows stable and unstable regions of the complex plane for such 
a case. 
When we consider the incommensurate fractional-order system q\ φ qi φ 
■ ■ ■ φ qn and suppose that m is the LCM of the denominators Uj's of qi's, 
where % = Vi/ui, Vi,Ui € Z+ for i = 1,2,..., n and we set 7 = 1/m. System 
(15.48) is asymptotically stable if 
|arg(A)| > 7 | 
(15-69) 
for all roots λ of the following equation: 
det(diag([Am91 Xmq2 ... A7"9"]) - J) = 0. 
(15.70) 
A necessary stability condition for fractional-order systems (15.48) to re-
main chaotic is keeping at least one eigenvalue A in the unstable region [45]. 
The number of equilibrium points and eigenvalues for one-scroll, double-scroll 
and multi-scroll attractors was exactly described in Ref. [46]. Assume that 
a 3D chaotic system has only three equilibria. Therefore, if the system has 
a double-scroll attractor, it has two saddle-focus points surrounded by scrolls 
and one additional saddle point. 
Suppose that the unstable eigenvalues of scroll focus points are λχ^ = 
c*i,2 ^jßi,2- 
The necessary condition to exhibit a double-scroll attractor of 
system (15.48) is the eigenvalues Ai,2 remaining in the unstable region [46]. 
The condition for commensurate derivatives order is 
g > - a t a n f — ) , i = l,2. 
(15.71) 
7Γ 
V ai J 
This condition can be used to determine the minimum order for which a non-
linear system can generate chaos [45]. In other words, when the instability 
measure π/2πι — min(|arg(A)|) is negative, the system cannot be chaotic. 

384 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
EXAMPLE 15.5 
Let us investigate Chen's system with a double-scroll attractor in 3D 
state space. The fractional-order form of such system can be described 
as [47] 
οΑ°'8ζι(ί) = 
0Dl0x2(t) 
= 
0D™x3(t) 
--
= 35[χ2(ί)-χι(ί)], 
= 
-7a:i(i)-xi(i)a;3(i) 
= 
α;ι(ί)χ2(ί)-3χ3(*). 
28x2 (i), 
(15.72) 
The system has three equilibria at (0,0,0), (7.94,7.94,21), and (-7.94, 
—7.94, 21). The Jacobian matrix of the system evaluated at equilibrium 
E 
— \x\ix2i 
x3) 
l s 
-35 
35 
0 
-7-x% 
28 
~x\ 
(15.73) 
The two last equilibrium points are saddle points and are surrounded by 
a chaotic double-scroll attractor. For these two points, equation (15.70) 
becomes as follows: 
λ27 + 35λ19 + 3λ18 - 28λ17 + 105λ10 - 21λ8 + 4410 = 0 
(15.74) 
The characteristic equation (15.74) has unstable roots λι^ = 1.2928 ± 
0.2032J, |arg(Aii2)| = 0.1560 and therefore system (15.72) satisfies the 
necessary condition for exhibiting a double scroll attractor. The insta-
bility measure is 0.0012. 
Figure 15.7 
Double-scroll attractor of Chen's system (15.72) projected into 3D 
state space for simulation time 30 s. 

15.5 APPLICATIONS OF FRACTIONAL CALCULUS 
385 
Numerical simulation of the system (15.72) for initial conditions (—9, —5,14) 
is depicted in Figure 15.7. 
15.5 
APPLICATIONS OF FRACTIONAL CALCULUS 
15.5.1 
Control of Electrical Heater 
The mathematical model used for the system to be controlled is a two-term 
differential equation of the fractional-order of the form 
b1Dfy(t) + 
b0y(t)=u(t), 
(15.75) 
for which the parameters b\, όο and β were obtained by an identification 
method based on the measured step response of the system (see Figure 15.8) 
and the minimization of the quadratics criteria 
1 
M 
J = ΜΤΪ Σ W " » 
i=0 
2 
(15.76) 
being y* the measured values, j/j the model values and M + 1 the number of 
measurements. 
Figure 15.8 
Unit-step response of controlled object. 
In this case, the obtained parameters are [5,35] 
h = 39.69; 
60 = 0.598; 
β = 1.25. 
So, the continuous transfer function used for controller design is 
G(s) = 
1 
39.69s1-25 + 0.598' 
(15.77) 

386 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
This mathematical model was used in Refs. [5,35] for fractional controller 
design, and an alternative integer-order model was used for traditional PD 
controller design with comparison purposes. 
The alternative integer-order model has the form of first-order system rep-
resented by the following transfer function: 
G(s) 
1 
20.14s+ 0.598 
(15.78) 
This integer-order system was used for comparison of control performance 
between classical PD controller and fractional PDS controller with transfer 
function: 
C(s) =K + Tds5, 
(15.79) 
where K, Td and δ are controller parameters. 
The controller design was done in Refs. [5,35], according to the method 
(poles placement [11]) described in Ref. [32], for obtaining a stability measure 
St « 2.0. The obtained fractional-order PDS controller designed for the 
fractional-order model (15.77) has the continuous transfer function: 
C(s) = 64.47 + 48.99s' ,0.5 
(15.80) 
The parameters of the integer-order PD controller were designed by the 
same method and the controller has the following transfer function: 
C(s) = 64.47+ 12.46s. 
(15.81) 
Let us consider the single input—single output (SISO) feedback control 
system shown in Fig. 15.9, where W is required value, E is control error, U is 
control value and Y is actual value. 
F. 
Ί 
1 
F 
Controller 
IT 
Actuator 
Process 
e 1 
Y 
Figure 15.9 
General SISO feedback loop system. 
The fractional differential equation of a closed control loop, depicted in 
Figurel5.9, with a fractional model of a controlled system and a fractional 
PDS controller, has the following form: 
h0D?y(t) 
+ Td0Ds
ty{t) + {b0 + K)y(t) = K w(t) + Td0Ds
tw{t). 
(15.82) 

15.5 APPLICATIONS OF FRACTIONAL CALCULUS 
387 
15.5.2 
Memristor-Based Chua's Circuit 
The fractional-order Chua's system was described and investigated in many 
works. Similar to the classical one, it contains a capacitor C, an inductor L, 
a resistor R and a nonlinear resistor, known as the Chua's diode. Since the 
memristor was postulated by professor L. 0. Chua in 1971 and discovered 
by R. Williams etal. (HP laboratory) in 2008, it becomes the fourth circuit 
element. This fact allow us use a memristor as a nonlinear element in a circuit 
which exhibits chaos. In the case of Chua's circuit, the nonlinear resistor is 
replaced by a memristor (M). 
R 
A/W 
v. 
c, 
Figure 15.10 
Chua's circuit with memristor and negative conductance. 
The memristor in Figure 15.10 is a flux-controlled memristor whose char-
acteristic is given by [8]: 
iM(t) = w(</>(t))v1(t), 
(15.83) 
where W(4>(t)) is called the incremental memductance. For the flux-controlled 
memristor it was assumed to have a monotone-increasing piecewise-linear 
characteristic [15]. The memristor constitutive relation is expressed as 
q(<P) = b<j> + 0.5(a - b) x (\φ +1\-\φ- 
1|), 
(15.84) 
where a, b > 0. The memductance function that is obtained from the q(<f>) 
function is 
ΜΦ) f a : 
\φ\<1, 
άφ 
\ b 
: 
\φ\ > 1. 
The dynamic of the Chua's circuit with a passive memristor (flux-controlled 
memristor and negative conductance) depicted in Figure 15.10 is given by the 
\Υ(φ) = 
(15.85) 

388 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
following set of differential equations: 
dVijt) 
dt 
dV2(t) 
dt 
dldt) 
dt 
d<j>{t) 
dt 
1 
\{V2{t)-Vi{t)) 
d [ 
R 
1 
\(V1(t)-V2(t)) 
+ 
Vl(t)(G-W(<P(t))) 
Co 
R 
+ iL(t) 
I[-V2(t)-RLIL(t)}, 
= Kit), 
(15.86) 
where functions q(<f>) and \¥(φ) are given by (15.84) and (15.85), respectively. 
When we set 
x 
= 
Vu 
y = V2, 
z = IL, 
w = <t>, C2 = l, 
(15.87) 
a 
= 
1/Ci, 
ß = l/L, 
l = RL/L, 
C = G, 
R=l, 
then Eq.(15.86) can be transformed into the dimensionless form [15]: 
dx(t) 
dt 
dy(t) 
dt 
dz(t) 
dt 
dw(t) 
dt 
a (y(t) - x{t) + C*(i) - 
W(w)x(t)), 
x{t)-y(t) 
+ z(t), 
-ßy{t)-1Z{t), 
x(t), 
where piecewise-linear function W(w) is given as 
w(w) = | I ; 
w\ < 1, 
w\ > 1. 
(15.88) 
(15.89) 
The equilibrium points of the system (15.88) are given by setting the left 
side of equations to 0 except last one. We set w=constant, which corresponds 
to the w-axis [15]. The Jacobian matrix at this equilibrium state E* is 
>w 
' α(-1 + 
ζ-]Υ(υ))) 
1 
0 
1 
a 
- 1 
-ß 
0 
0 
1 
- 7 
0 
0 
0 
0 
0 
(15.90) 
If we consider a fractional-order model for each electrical element in the 
circuit depicted in Figure 15.10, we can write a more general mathematical 
model for this circuit. As it was already mentioned in introduction, the real 
capacitor and real inductor are "fractional" and for the real memristor we 

15.5 APPLICATIONS OF FRACTIONAL CALCULUS 
389 
postulated a fractional-order model as well (da<f)(t)/dta = V(t)). By using a 
technique of fractional calculus we obtain the following equations [34]: 
0Dqix{t) 
= 
a{y(t)-x(t)+Cx(t)-W{w)x(t)), 
0D?y(t) 
= 
x(t)-y(t) 
+ z(t), 
0D?z{t) 
= 
-ßy(t)-1Z(t), 
0Dq
t
lw{t) 
= 
x{t), 
(15.91) 
where function W(w) is given by (15.89) and where qi, q-z, q%, and q± are 
the fractional orders of real electrical elements (memristive systems), namely: 
capacitor C\, capacitor C2, inductor L, and memristor M, respectively. 
The stability of the new fractional-order memristor-based Chua's system 
can be investigated by using a condition (15.69). 
In the case of piecewise-nonlinearity (15.84), we should investigate a char-
acteristic equation for a linear part with slope a and for a linear part with 
slope b, respectively. 
A necessary stability condition for fractional-order systems (15.91) to re-
main chaotic is keeping at least one eigenvalue λ in the unstable region. Ac-
cording to condition (15.71), we can also determine a minimal order q for 
which a nonlinear system has chaotic behavior. 
Because the frequency approximation techniques are unreliable in recogniz-
ing chaos in fractional-order nonlinear systems [44], for simulation purposes 
we use a numerical solution of the memristor-based Chua's equations (15.91) 
obtained by the method described in [35]. That is a time domain method 
derived by using the relationship (15.12), which leads to equations in the 
form 
x(tk) 
= 
(a(j/(tfc_i) - x{tk-i) 
+ C*(*fc-i) - 
W{w(tk^1))x(tk-1)))hqi 
i=v 
k 
y(tk) = (z(tfe) - y(tk-i) + z{tk-x)) Λ* - J^Vtfe-i), 
i=v 
k 
z(tk) 
= 
(-ßy(tk) 
- 7z(tfc-i)) h<* - Σ 
c^zitk-i), 
i=v 
k 
(tfc) = x(tfc)fc" - $>j , 4Mtk-i), 
(15.92) 
w 
where 
W(w{tk-i)) 
= 
a for 
M*fc_i)| < 1, 
W{w{tk-i)) 
= 
b for 
Mtfc_i)| > 1, 
(15.93) 

390 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
and where Ts;m is the simulation time, k = 1,2,3... 
,N, for N — [TSim/h], 
and (x(0), j/(0), z(0), w(0)) is the start point (initial conditions). The binomial 
coefficients cf' are calculated according to relation (15.13). 
■ EXAMPLE 15.6 
Let us consider the following parameter set: 
a = 10, ß = 13, 7 = 0.1, ζ = 1.5, a = 0.3, b = 0.8. 
(15.94) 
When we consider real orders of capacitor models [51]: qi = qi = 0.98, 
a real order of an inductor model [51]: q$ = 0.99, and we assume a real 
order of the memristor model: q\ = 0.97; for the parameters (15.94) the 
initial conditions: x(0) = 0.8, y(0) = 0.05, z(0) = 0.007, w(0) = 0.6, 
simulation time TSjm = 100 s, and time step h = 0.005, we get the 
chaotic double-scroll attractor for the total system order 3.92. 
Figure 15.11 
Strange attractor of the memristor-based Chua's system (15.91) in 
w — x — y state space, for parameters a = 10, /3 = 13, 7 = 0.1, ζ = 1.5, a = 0.3, 
6 = 0.8, and orders qi = q2 = 0.98, 93 = 0.99, q4 = 0.97. 
In Figure 15.11 and Figure 15.12 are depicted chaotic attractors in 3D 
state space for TSim = 100 s. The simulations were performed without 
using the short memory principle (v = 1) for time step h = 0.005. Sim-
ulations show the double-scroll attractors and we can observe a chaotic 
behavior. 

15.5 APPLICATIONS OF FRACTIONAL CALCULUS 
391 
Figure 15.12 
Strange attractor of the memristor-based Chua's system (15.91) in 
x — y — z state space, for parameters a = 10, ß = 13, 7 = 0.1, ζ = 1.5, a = 0.3, 
b = 0.8, and orders qi = q2 = 0.98, 93 = 0.99, <?4 = 0.97. 
15.5.3 
Viscoelastic Models of Cells 
Cells have essential biological roles and often change shape, attach and detach 
from a surface, and sometimes divide. Such activities require the deformation 
in response to local stress. The rheological behavior of these cells can be 
modeled with the following fractional differential equation [21]: 
a(t) = Gs6(t) + \oD?0(t) + μ*Ά, 
at 
(15.95) 
where σ is stress, Θ is strain, Gs is the static elastic modulus, λ is fractional 
relaxation time constant, and μ is the viscosity. 
If we apply the Laplace transform to system (15.95), assuming that the 
initial conditions are all zeros, we obtain 
G(s) = ^ \ 
= Gs + 
Xsa+ßs. 
0(s) 
(15.96) 
As it was mentioned in Ref. [21], the parameter Gs can be neglected. For 
a step function u(t) in applied stress, a(t) = aou(t), the creep response can 
be written as 
θ ( β ) = 
Σ ° 
= 
^S{1~a)~] 
,. 
(15.97) 
w 
s(/is + As") 
^(si1-«) + λ/μ) 
V 
' 
The inverse Laplace transform of this expression can be written by using a 
Laplace transform of the Mittag-Leffler function [38]: 
^{t^E^-zf)} 
-
*i-ß 
s'r 

392 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
and we obtain an analytical solution in the form 
μ 
\ 
μ 
(15.98) 
For numerical solution of the fractional differential equation (15.95) for 
G, = 0 we can use relations (15.12) and (15.13). The resulting difference 
equation has the form [36] 
.(<*)/ 
0(tfc) -
Xh-a + μ/ΐ"1 
(15.99) 
where tk ='kh for k = 1,2,3,... N, where TV = [TSim/h\ and h is a time step 
of calculation, and #(io) is obtained from an initial condition, e.g., θ(ίο) = 0 
for a zero initial condition. 
■ EXAMPLE 15.7 
Let us assume the following model parameters: λ = μ = Σο = 1, zero 
initial condition, TSjTO = 5 s, h = 0.001, and v = 1. 
Figure 15.13 
Comparison of analytical and numerical solutions of fractional-order 
viscoelastic models of cell (15.97) for simulation time 5 s, step h = 0.001, and v = 1 
in (15.99). 
Comparison of the analytical solution (15.98) and the numerical so-
lution (15.99) of the fractional differential equation (15.95) for the pa-
rameters Gs = 0, λ = μ — Σο = 1, zero initial condition, TSjm = 5 s, 
h = 0.001, and v = 1 is depicted in Figure 15.13. As we can observe, 
the numerical solution fits the analytical solution and we can say that 
both solutions are consistent. 

EXERCISES 
393 
EXERCISES 
15.1 
Find the analytical solution (impulse response) for zero initial condi-
tions of a closed loop system consisting of an electrical heater and integer PD 
controller as described in Section 15.5.1. 
15.2 
Investigate the stability of a closed loop system consisting of an elec-
trical heater and integer PD controller as described in Section 15.5.1. 
15.3 
Investigate the stability of the fractional memristor-based Chua's sys-
tem described in Section 15.5.2. 
15.4 
For the fractional-order Chen system described by Eq.(15.72) find a 
numerical solution. 
REFERENCES 
1. Bayat F. M., Afshar, M. and Ghartemani, M. K., Extension of the root-locus 
method to a certain class of fractional-order systems, ISA Transactions, Vol. 
48, pp. 48-53 (2009). 
2. Bayat, F. M. and Afshar, M., Extending the root-locus method to fractional-
order systems, Journal of Applied Mathematics, Article ID 528934 (2008). 
3. Baleanu, D., Guvenc, Z. B. and Tenreiro, Machado, J. A. (Eds.), New Trends in 
Nanotechnology and Fractional Calculus Applications, Springer, London (2010). 
4. Bode, H. W., Network Analysis and Feedback Amplifier Design, Tung Hwa Book 
Company (1949). 
5. Caponetto, R., Dongola, G., Fortuna, L. and Petras, I., Fractional Order Sys-
tems: Modeling and Control Applications, World Scientific, Singapore (2010). 
6. Chen, Y. Q., Oustaloup-Recursive-Approximation for Fractional Order Differ-
entiators, Matlab Central File Exchange, MathWorks, Inc. (2003), url: 
http: //www. mathworks. 
com/matlabcentral/fileexchange/3802. 
7. Chen, Y. Q., Petras, I. and Xue, D., Fractional Order Control - A Tutorial, Proc. 
of the American Control Conference, Hyatt Regency Riverfront, St. Louis, MO, 
USA, June 10-12 (2009). 
8. Chua, L. O., Memristor - the missing circuit element, IEEE Transaction on 
Circuit Theory, vol. CT-18, pp. 507-519 (1971). 
9. Deng, W., Short memory principle and a predictorcorrector approach for frac-
tional differential equations, Journal of Computational and Applied 
Mathemat-
ics, Vol. 206, pp. 174-188 (2007). 
10. Dorcäk, L., Numerical Models for the Simulation of the Fractional-Order Con-
trol Systems, UEF-04-94, The Academy of Sciences, Inst. 
of 
Experimental 
Physic, Kosice, Slovakia (1994). 

394 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
11. Dorf, R. C. and Bishop, R. H., Modern Control Systems, Addison-Wesley, New 
York (1990). 
12. Ghartemani, M. K. and Bayat, F. M., Necessary and sufficient conditions for 
perfect command following and disturbance rejection in fractional order systems, 
Proc. of the 17th World Congress IFAC, Soul, Korea, July 6-11, pp. 364-369 
(2008). 
13. Heymans, N. and Podlubny, I., Physical interpretation of initial conditions for 
fractional differential equations with Riemann-Liouville fractional derivatives. 
Rheologica Ada, vol. 45, no. 5, pp. 765-772 (2006). 
14. Hilfer, R., Applications of Fractional Calculus in Physics, World Scientific Pub-
lishers, Singapore (2000). 
15. Itoh, M. and Chua, L. O., Memristor oscillation, International 
Journal of Bi-
furcation and Chaos, vol. 18, pp. 3183-3206 (2008). 
16. Kaczorek, T., Selected Problems of Fractional Systems Theory, Springer, Berlin 
(2011). 
17. Kheirizad, I., Tavazoei, M. S. and Jalali, A. A., Stability criteria for a class of 
fractional order systems, Nonlinear Dyn., Vol. 61, no. 1-2 (2009). 
18. LePage, W. R., Complex variables and the Laplace transform for engineers, 
McGraw-Hill (1961). 
19. Li, Y., Chen, Y. Q., and Podlubny, I., Mittag-Leffler stability of fractional order 
nonlinear dynamic system, Automatica, Vol. 45, no. 8, pp. 1965-1969 (2009). 
20. Lubich, Ch., Discretized fractional calculus, SIAM J. Math. 
Anal, 
Vol. 17, 
no. 3, pp. 704-719 (1986). 
21. Magin, R. L., Fractional Calculus in Bioengineering, Begell House Publishers 
(2006). 
22. Mainardi, F., 
Fractional Calculus and Waves in Linear Viscoelasticity: 
An 
Introduction to Mathematical Models, Imperial College Press, Singapore (2010). 
23. Matignon, D., Stability properties for generalized fractional differential systems, 
Proc. of Fractional Differential Systems: Models, Methods and App., Vol. 5, 
pp. 145-158 (1998). 
24. Miller, K. S. and Ross, B., An Introduction 
to the Fractional Calculus and 
Fractional Differential Equations, John Wiley & Sons. Inc., New York (1993). 
25. Monje, C. A., Chen, Y. Q., Vinagre, B. M., Xue, D. and Feliu, V., Fractional 
Order Systems and Control - Fundamentals and Applications, Advanced Indus-
trial Control Series, Springer, London (2010). 
26. Oldham, K. B. and Spanier, J., The Fractional Calculus, Academic Press, New 
York (1974). 
27. Ortigueira, M. D., Fractional Calculus for Scientists and Engineers, Lecture 
Notes in Electrical Engineering, Springer, London (2011). 
28. Oustaloup, A., La Derivation Non Entiere: Theorie, Synthese et Applications, 
Hermes, Paris (1995). 
29. Oustaloup, A., Levron, F., Mathieu, B., and Nanot, F. M., Frequency-band 
complex noninteger differentiator: characterization and synthesis, IEEE Trans. 

EXERCISES 
395 
on Circuits and Systems I: Fundamental 
Theory and Applications I, vol. 47, 
no. 1, pp. 25-39 (2000). 
30. Petras, I., Digital Fractional Order Differentiator/integrator - FIR type, Matlab 
Central File Exchange, MathWorks, Inc. (2003), url: 
http: //www. mathworks. 
com/matlabcentral/fileexchange/3673. 
31. Petras, I., Digital Fractional Order Differentiator/integrator - IIR type, Matlab 
Central File Exchange, MathWorks, Inc., (2003) url: 
http://www. mathworks. 
com/matlabcentral/fileexchange/3672. 
32. Petras, I., The fractional-order controllers: methods for their synthesis and 
application, Journal of Electrical Engineering, Vol. 50, pp. 284-288 (1999). 
33. Petras, I., Podlubny, I., O'Leary, P., Dorcäk, L., and Vinagre, B. M., Analogue 
Realization of Fractional Order Controllers, FBERG, Technical University of 
Kosice (2002). 
34. Petras, I., Fractional-order memristor-based Chua's circuit, IEEE 
Transactions 
on Circuits and Systems II-Express Briefs, Vol. 57, no. 12, pp. 975-979 (2010). 
35. Petras, I., Fractional-Order Nonlinear Systems: Modeling, Analysis and Simu-
lation, Springer, Berlin (2011). 
36. Petras, I., An effective numerical method and its utilization to solution of frac-
tional models used in bioengineering applications, Advances in Difference Equa-
tions, Vol. 2011, pp. 1-14 (2011). 
37. Petras, I., Fractional derivatives, fractional integrals, and fractional differential 
equations in Matlab, In: A. Assi (Eds.) Engineering Education and Research 
Using MATLAB, 
InTech, Rijeka, chapter 10 (2011). 
38. Podlubny, I., Fractional Differential Equations, Academic Press, San Diego 
(1999). 
39. Podlubny, I., Matrix approach to discrete fractional calculus, Fractional Calcu-
lus and Applied Analysis, Vol. 3, no. 4, pp. 359-386 (2000). 
40. Podlubny, I., Geometric and physical interpretation of fractional integration 
and fractional differentiation, Fractional Calculus and Applied Analysis, Vol. 5, 
no. 4, pp. 367-386 (2002). 
41. Podlubny, I., Chechkin, A., Skovranek, T., Chen, Y. Q., and Vinagre, B. M., 
Matrix approach to discrete fractional calculus II: Partial fractional differential 
equations, Journal of Computational Physics, Vol. 228, no. 8, pp. 3137-3153 
(2009). 
42. Podlubny, I. and Kacenak, M., Mittag-Lefner function, Matlab Central File 
Exchange, MathWorks, Inc. (2005), url: 
http://www. mathworks. 
com/matlabcentral/fileexchange/8738. 
43. Sabatier, J., Agrawal, O. P. and Tenreiro Machado, J. A. (Eds.), Advances in 
Fractional Calculus: Theoretical Developments and Applications in Physics and 
Engineering, Springer, Berlin (2007). 
44. Tavazoei, M. S. and Haeri, M., Unreliability of frequency-domain approximation 
in recognizing chaos in fractional-order systems, IET Signal Proc, Vol. 1, no. 4, 
pp. 171-181 (2007). 

396 
CHAPTER 15. FRACTIONAL CALCULUS AND ITS APPLICATIONS 
45. Tavazoei, M. S. and Haeri, M., A necessary condition for double scroll attractor 
existence in fractional - order systems, Physics Letters A, Vol. 367, pp. 102-113 
(2007). 
46. Tavazoei, M. S. and Haeri, M., Limitations of frequency domain approximation 
for detecting chaos in fractional order systems, Nonlinear Analysis, Vol. 69, 
pp. 1299-1320 (2008). 
47. Tavazoei, M. S. and Haeri, M., Chaotic attractors in incommensurate fractional 
order systems, Physica D, Vol. 237, pp. 2628-2637 (2008). 
48. Vinagre, B. M., Podlubny, I., Hernandez, A., and Feliu, V., Some approxi-
mations of fractional order operators used in control theory and applications, 
Fractional Calculus and Applied Analysis, Vol. 3, no. 3, pp. 231-248 (2000). 
49. Vinagre, B. M., Chen, Y. Q., and Petras, I., Two direct Tustin discretization 
methods for fractional-order differentiator/integrator, Journal of Franklin In-
stitute, Vol. 340, pp. 349-362 (2003). 
50. West, B., Bologna, M., and Grigolini, P., Physics of Fractal Operators, Springer, 
New York (2003). 
51. Westerlund, S., Dead Matter Has Memory!, Causal Consulting, Kalmar, Sweden 
(2002). 

CHAPTER 16 
THE GOAL PROGRAMMING MODEL: 
THEORY AND APPLICATIONS 
B E L A I D A O U N I 1 , CINZIA C O L A P I N T O , 2 AND DAVIDE L A T O R R E 3 
School of Commerce and Administration, Laurentian University, Canada 
Department of Management, Ca' Foscari University of Venice, Italy 
Department of Economics, Management and Quantitative Methods, University of 
Milan, Italy 
16.1 
MULTI-CRITERIA DECISION AID 
In any kind of organization, managers are frequently challenged with com-
plex decision making situations which involve several, and often conflicting, 
objectives and priorities. In fact, the decision setting is unstable because of 
corporate politics, market conditions or regulations' changes. The decision-
making is central within organizations, and managers have to make the best 
choices, substituting objective issues for casual judgments. The classical and 
easiest formulation of a decision-making model usually involves an objective 
function / , which has to be optimized, depending on a set of decision variables 
and subject to some constraints. The model can be mathematically stated as 
Optimize/(x), 
(16-1) 
Mathematical Modeling with Multidisciplinary Applications. 
397 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

398 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
subject to 
x e D, 
(16.2) 
where the set D describes in compact form the set of all possible constraints. 
D is called the feasible set and, in general, it is a subset of Rm (that is the 
set of all m-tuples of real numbers). For instance, in many real applications 
/ represents the profit or the cost while the set D is the budget constraint. 
However there are several decision-making situations in which different and 
conflicting aspects and objectives have to be considered simultaneously and 
they cannot merely reduced to a single criterion. Keeney and Howard [15] 
state that "in complex value problems consequences cannot be adequately 
described objectively by a single attribute." 
In general an agent's utility is a vector, having components such as: cost, 
life expectancy, profit and quality of life. For instance, in environmental 
economics and management the Decision Maker (DM) has to plan the use 
of natural resources (fisheries, forestry, water and land) in a complex process 
which inevitably involves several incommensurable and conflicting objectives 
(for instance the level of emissions of a power plant to prevent deaths and 
disabilities against the benefits of the power); in public economics when a 
new airport has to be sited the DM has to consider conflicting criteria as 
the noise of flight operation, safety issues, cost of land, and distance from 
communities [21]. 
The Multi-Criteria Decision Aid (MCDA) considers several conflicting and 
incommensurable objectives or attributes which are optimized simultaneously. 
If D C Rm is the set of feasible solutions, the general formulation of MCDA 
is as follows [24]: 
Optimize/(z) := (h(x), f2(x), 
. ·. /„(a;)), 
(16.3) 
subject to 
x <= D, 
(16.4) 
where /j represents the ith objective function. The function / is a vector-
valued function defined on Rm and it assigns values in Rn. We suppose Rn 
being ordered by the usual Pareto cone i?" which means a > b if and only if 
a-beR^ 
for all a,b e Rn. 
Definition 13 In the case that f is to be maximized, a vector x € D is 
said to be a Pareto optimal solution or an efficient solution to (16.3) if it is 
not dominated, that is there is not a y € D such that fi(x) < fi{y) for all 
i = l...n 
and fj(x) < fj(y) for at least one j . 
For necessary and sufficient conditions which characterize Pareto optimal 
solutions to (16.3) one can see Refs. [24,26]. 
Stochastic or Scenario-based Multi-Criteria Decision Aid (SMCDA) rep-
resents the natural extension of deterministic multi-criteria programming to 
stochastic context. There are several decision-making situations where the 

16.2 THE GOAL PROGRAMMING MODEL 
399 
DM wishes to optimize objectives which depend on some random parame-
ters (see, for instance, Refs. [2,3]). In literature many approaches have been 
proposed to deal with such situations (see, for instance, Refs. [7,9,10,25]). 
The fact that the objectives depend on random parameters makes the ob-
jectives random variables too; so a point in the domain could be a Pareto 
optimal solution of the problem only when some realizations of the random 
parameters occur. Several definitions of Pareto optimality have been intro-
duced; the solution of such problems usually involves the transformation into 
its deterministic equivalent. 
16.2 
THE GOAL PROGRAMMING MODEL 
The Goal Programming (GP) model is a well-known and the most popular 
model within the field of Multi-Criteria Decision Aid; this takes into account 
simultaneously many objectives which can be conflicting and provides an ag-
gregating procedure to simplify the model and reduce it to a single-criterion 
program. Thus, the obtained solution through the GP procedure represents 
the best compromise that can be made by the DM. The GP model can be 
considered as a special case of the "Distance Function Model" where the de-
viations between the achievement and aspiration levels have to be minimized. 
In fact, both positive and negative deviations are unwanted. The deviations 
will be positive if the goal is surpassed, otherwise negative. 
The first GP formulation was developed by Charnes et al. [12] and Charnes 
and Cooper [13] and then used by Lee [17] and Lee and Clayton [18]. The GP 
models have received a lot of attention and they are so widespread because of 
their applications in practical decision-making situations such as accounting 
and financial aspects of stock management, marketing, quality control, hu-
man resources, and production (see Refs. [1,22]). In recent years, numerous 
variants of the GP model have been studied including, for instance, Weighted 
GP, Lexicographical GP, Integer GP, Imprecise GP, Fuzzy GP, and so on. 
According to Aouni and Kettani [5] the GP is still alive and supported by a 
well-established network of researchers and practitioners. The popularity of 
the GP is due to the fact that it is a model that is simple and easy to un-
derstand and to apply. Moreover, the GP formulation can be solved through 
some powerful mathematical programming software such as LINDO, LINGO 
and CPLEX. 
However, it is worth mentioning that the GP model is based on a satisfying 
philosophy. This means that the obtained solution is the best compromise. 
When efficiency is a required property by the DM, a GP model has to be 
integrated with optimality tests in order to check whether the obtained solu-
tion is nondominated (see Ref. [16]). In any case, the GP approach provides 
a solution to a MCDA program with a given level of satisfaction. 

400 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
The standard mathematical formulation of the GP model (see Ref. [12]) is 
as follows: 
n 
mmJ2(St+S-), 
(16.5) 
subject to 
fi{x) + δ~ - δ? = gu 
i = l,2,... n, 
xeD, 
(16.6) 
<5~Λ +>0, 
ί = 
1,2,...η. 
where δ* and δ~ are, respectively, the positive and the negative deviations 
with respect to the aspiration levels (goals) <?j. 
■ EXAMPLE 16.1 
Solve the following GP model: 
min Z = δ? + δ f + δ£ + δ^, 
subject to 
ί 2χλ +χ2 + 2χ3 + δϊ - δ^ = 50, 
3χι + 6x2 + 3x3 + <5^~ — <52~ = 150, 
2:1,2:2,2:3 > 0, 
_ δ+,δϊ,δ+,δϊ>0. 
The solution can be computed by using LINGO which provides the 
following solutions: x\ = 0, X2 = 16.66667, X3 = 16.66667, δ^ = 0, 
δ+ = 0, &Γ = 0, and δ£ = 0. 
In the Weighted Goal Programming (WGP) model each deviation is multiplied 
by a weight or scaling factor Wi as follows: 
n 
rmaY^iwfSf 
+ wrSr), 
(16.7) 
i=l 
subject to 
fi(x) + δϊ - δ+ =gi, 
i=l,2,...n, 
xeD, 
(16.8) 
<5-,<5+>0, 
i=l,2,...n. 
EXAMPLE 16.2 
Solve the following WGP model: 
minZ = 0.2öt + 0.25Γ + 0 . 3 ^ + 0.3&Γ, 

16.2 THE GOAL PROGRAMMING MODEL 
401 
subject to 
2x! -x2+ 
2x3 + if - if = 50, 
3^1 — 6a;2 — 3^3 + i^~ — δ% = 150, 
Χ\,Χ·2,ΧΖ 
> 0, 
[ 
δ+,δϊ,δ+,δϊ>0. 
The solution can be computed by using LINGO which provides the 
following solutions: x\ = 50, x-i = 0, X3 = 0, if = 0, if = 50, i^~ — 0, 
and 62 = 0. 
The above GP formulation does not include the DM's preferences. Martel 
and Aouni [20] introduced the concept of satisfaction functions in the goal 
programming model where the DM can explicitly express his/her preferences 
for any deviation between the achievement and the aspiration level of each 
objective. In general, given three positive numbers ξί,ξά and ξυ which will 
be called, respectively, the indifference threshold, the dissatisfaction threshold 
and the veto threshold in the sequel, a satisfaction function F : [0, ξυ] —► [0,1] 
satisfies the following properties: 
• F(x) = 1, for all i e [0,&], 
• F(x) = 0 for all x G [&,&,], 
• F is continuous and descreasing. 
Depending on the thresholds' values, positive and negative deviations might be 
penalized in a different manner and thus affect the probability of reaching the 
goals. In fact, the threshold values depend on the DM preferences regarding 
the dispersion of the deviations. The GP model with satisfaction function is 
formulated as follows: 
n 
m a x £ {w±F(S+) + wrF(Sr)) 
, 
(16.9) 
i = l 
subject to 
.71, 
fi(x) + Si - δ+ = gt, i = 1, 2,... 1 
x G D, 
(16.10) 
δ+,δ'β[0,ξν], 
i = l,2,...n. 
Let us notice that the GP model (16.9) admits a solution because of the 
continuity of fi and F, and the compactness of D. 
■ EXAMPLE 16.3 
Solve the following GP model with a satisfaction function: 
0.3 
0.3 
0.2 
0.2 
max Z = 
-Γ-— H 
: 
τζτττ Η 
:—zj-77: + 
1 + (0.01<5+)2 
l + (0.01Jf)2 
1 + (10£T)2 
l + (10ij) 2' 

402 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
subject to 
' 0.9xi + 0.99x2 + 0.21x3 + 0.178x4 + 0.5724x5 + 0.102x6+ 
1.527x7 + 0.996x8 + 0.3x9 + 0.0711xi0 + 0.45xn + 0.9306xi2+ 
0.942xi3 + 0.504x14 + 0.5888x15 + <5+ - J+ = 2.82 
0.84x! + 0.95x2 + 0.93x3 + 0.94x4 + 0.93x5 + 0.94x6+ 
0.95x7 + 0.9x8 + 0.94x9 + 0.93xi0 + 0.94xn + 0.94xi2+ 
0.94xi3 + 0.93xi4 + 0.9xi5 + δ£ - δ£ = 5.63, 
Xl + X2 + X3 + X4 + %5 + Χβ + %7 + X8 + #9 + 
< Xio + Xll + Xl2 + Xl3 + Xl4 + #15 < = 7, 
X\ , %2, X3, %A, %5, %6, XT, X8, %9, 
xio,xn,a;i2,xi3,^i4,a;i5 > 0, 
δί,δϊ,δί,δ;>ο, 
St < 300, 
Jf < 300, 
St < 0.3, 
, <52- < 0.3. 
The solution can be computed by using LINGO which provides the 
following solutions: xx = 0.2855723, x2 = 0.2522141, x3 = 0.5054681, 
x4 = 0.5155977, x5 = 0.3880378, x6 = 0.5402304, x7 = 0.3964897^-01, 
x8 = 0.2517976, x9 = 0.4760572, xw = 0.5504814, xu 
= 0.4274446, 
xi2 = 0.2717116, xi3 = 0.2680179, xu 
= 1.284094, x15 = 0, <*f = 0, 
öt = 0 &Γ = 0, and St = 0. 
16.3 
SCENARIO-BASED GOAL PROGRAMMING 
Let Ω = {uii, u)2, · · ·, ω;} be a space of events with associated probabilities 
Pi,P2,■ ■ -,Ρι, ΣίΡί 
= 1· Consider / : Rm x Ω —> Rn to be a function such 
that /(x, ·) is a discrete random variable for each fixed x G Rm and /(·,ω) is 
continuous for WjSQ. Let D c Rm be a compact set and consider now the 
following scenario-based multi-criteria problem 
min/(x,Wi), 
(16.11) 
where ω, € Ω. Using the assumption we set before, we get that program 
(16.11) has at least a solution over D for all ω, e Ω. According to Refs. 
[9,10], we can introduce the following deterministic multi-criteria equivalent 
problems associated with program (16.11). 
Definition 14 A point x e D is an expected-value Pareto optimal solution 
of the scenario-based multi-criteria problem if it is a Pareto optimal solution 

16.3 SCENARIO-BASED GOAL PROGRAMMING 
403 
of the following problem: 
minE(/0r, ·)) := (Ε(Λ(χ, ·)), · · ·, E(/„(ar, ·))), 
(16.12) 
x€D 
where E(/j(x, ·)) is the expectation value of the random variable15 fi(x, ·) for 
each fixed x € D. 
Definition 15 A point x e D is a minimum-variance Pareto optimal solution 
of the scenario-based multi-criteria problem if it is a Pareto optimal solution 
of the following problem: 
mina2(f(x,-)) 
:= (σ2(/ι(χ, ·)),··■ ,σ 2(/„(ζ, ·))) , 
(16.13) 
x£L) 
where a2(fi(x, ·)) is the variance of the random variable fi(x, ·) for each fixed 
xeD. 
Definition 16 A point x € D is an expected-valued standard deviation Pareto 
optimal solution of the scenario-based multi-criteria problem if it is a Pareto 
optimal solution of the following program: 
min(E(/(z, -),a(f(x, 
·)) := (E(/i(x, ·)),···, E(fn(x, 
■), a(h (x, ■),..., a(fn(x, 
·)), 
x€D 
(16.14) 
where a(f(x, ·)) is the standard deviation of the random variable f(x, ·) for 
each fixed ω € Ω. 
Consider now the aspiration levels gi (i = 1.. .n), and suppose they are 
random variables gi : Ω —> R. Let E(c/,) and σ 2(^) be the expectation values 
and the variances of gi, respectively. Consider the following goal programming 
models associated with formulations (16.12), (16.13) and (16.14), respectively. 
G P Model 1: 
Π 
m i n ^ Ä t + Ä - ) , 
(16.15) 
i=l 
subject to 
f E(fi(x,-))+67-S+=E(gi), 
i = l,2,...n, 
i e f l , 
(16.16) 
1 δ+,δ~ > 0 
i = l , 2 , . . . n . 
16If Y : Ω —► Rn is a discrete random variable defined on the space Ω = {ω\,ω2,... 
,u>j} 
with associated probabilities pi,P2, ■ ■ ■ ,Ρι, Σ,Ρί 
= 1> the first moment is the expected 
value defined as E(Y) = J^ i Y(uji)pi, 
while the second moment is the variance defined as 
σ2(Υ) 
= Ε(Υ 
-E(Y))2. 

404 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
GP Model 2: 
n 
m i n $ > + + < j r ) 
(16.17) 
subject to 
σ2(/,(ζ, ■)) + δ~ - δ+ = a2{9i) 
i = 1,2,.. .n, 
xeD, 
(16.18) 
<5+,<5r>0, i = l . . . n . 
GP Model 3: 
n 
m i n ^ ( i + + δ- + 0+ + ϋτ), 
(16.19) 
i = l 
subject to 
E(/i(x, ·)) + δ~ - δ+ = E(ifc) i = 1,2,.. .n, 
a{fi(x, ·)) + 0," " ^ = σ(ο0 i = 1,2,.. .n, 
δϊ,δΓ,ΰί,ΰ+>0 
i = l,2,...n. 
(16.20) 
Suppose we take a sample of observations of the random vector f(x,ui), say, 
(f(x,u)i),f(x,u>2),---f{x,0Js)) 
£ Rsxm. 
If the observations are independent 
and identically distributed (i.i.d.) 
we can get an estimation of the mean 
and the variance of E(f(x, ·)), a2(f(x, ·)) and E(£)(·)) by using the classical 
statistical formulas 
E(/(z, ■)) « ^ = i / ( x , u ; f c ) , 
(16.21) 
^ , 0 ) „ EU(fM-WM))\ 
(1622) 
s — 1 
16.4 
APPLICATIONS 
In this section we present a set of applications—namely to finance, media man-
agement, public economics and software engineering—of the different Goal 
Programming formulations presented in the previous sections. 
16.4.1 
A Goal Programming Model for Portfolio Selection 
Portfolio managers have to acquire and interpret information related to the 
movements in security prices. Indeed, portfolio management concerns making 
decisions about investment mix and policy, balancing risk, liquidity and per-
formance of the chosen assets. The history of returns on different asset classes 
provides compelling evidence of a risk-return trade-off and the classical finan-

16.4 APPLICATIONS 
405 
Table 16.1 Return per unit in percentage/relative risk in percentage. 
Company/Year 
AT& T 
Walmart 
Exxon Mobil 
General Electric 
Bank of America 
Ford Motor Company 
Hewlett- Packard 
McKesson Corporation 
J. P. Morgan Chase 
Proctor & Gamble 
2007 
0.15/11.42 
0.01/3.49 
0.11/8.44 
0.02/3.58 
0.05/6.93 
0.01/9.36 
0.16/9.32 
-0.01/4.57 
0.08/6.58 
0.04/5.15 
cial theory demonstrated that portfolio diversification can reduce variability 
and investment risk because the assets prices do not move in exact lockstep. 
How do asset managers decide where and how to allocate their funds? 
As a numerical example, let us consider the following financial decision-
making situation based on real data coming from the NYSE (New York Stock 
Exchange). We selected the largest public and private companies by gross 
revenues in 2007. Data contains stock unit daily closing price and the per-
centage change in the price of a stock from the previous day's closing price. 
Table 16.1 represents price of expected return per unit and risk in percent-
age. We evaluate investment into different companies based on two objectives: 
maximizing return and minimizing risk. We consider two different GP formu-
lations, namely the weighted GP model and the GP model with satisfaction 
function. 
To simplify the equations we assign to each company a variable. 
The 
decision variables will be defined as follows: 
Xj = the amount of money invested in the security of company j 
(16.23) 
where j — 1 for AT & T, j = 2 for Walmart,..., j = 10 for Proctor & Gam-
ble. The Financial Decision Maker (FDM) prefers to invest by default into 
three different market sectors: at least 30,000.00$ to the financial sector, at 
least 20,000.00$ to the oil/gas sector and at least 10,000.00$ to the telecom-
munication sector. As said before, the multi-criteria problem for the year 
2007 consists of maximizing the return and minimizing the risk and can be 
formulated as follows: 
maxNΑχ 
:= 1.0015ΧΊ + 1.0001X2 + 1.0011X3+ 
I.OOO2X4 + 1.0005X5 + 1.0001X6 + I.OOI6X7+ 
(16.24) 
0.9999X8 + I.OOO8X9 + 1.0004Xio, 

406 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
mm NA2 := 1.1142Xi + 1.0349X2 + 1.0844X3+ 
1.0358X4 + 1.0693X5 + 1.0936X6 + 1.0932X7+ 
(16.25) 
1.0475X8 + 1.0658X9 + 1.0515XiO, 
subject to 
' X1 + X2 + X3 + X4 + X5 + Xe + X? + Xs + X9 + X10 = 100,000.00, 
X 5 + X 9 > 30,000.00, 
< X 3 > 20,000.00, 
Xi > 10,000.00, 
Xi,X2, ^3,-^4, ^5, ^6, ^7, ^8,-^9, ^10 > 0. 
(16.26) 
Let 51 = 100,125.00$ (return) and g2 = 106,200.00$ (risk) be the two 
aspiration levels for the objective functions NA\ and NA2. 
We propose a 
WGP model where each weight is a trade-off parameter between risk and 
return. We consider a different financial situation in which we assume w^ = 
w^ = 0.75 and w2 = w2 = 0.25. This characterizes a FDM with low risk 
aversion. The FDM solves the following WGP model: 
minZ = 0.75^ + 0.75if + 0.25.5^ + 0.255J, 
(16.27) 
subject to 
' 1.0015Χχ + I.OOOIX2 + I.OOHX3 + I.OOO2X4 + 1.0005X5+ 
1.0001X6 + I.OOI6X7 + 0.9999X8 + I.OOO8X9 + 1.0004Xi0 
-δ+ + δϊ = 100,125.00 
1.1142Χι + 1.0349X2 + 1.0844X3 + 1.0358X4 + 1.0693X5+ 
1.0936X6 + 1.0932X7 + 1.0475X8 -I- 1.0658X9 + 1.0515X10+ 
δ+ + <J" = 106,200.00 
Xi+X2 
+ X3+X4 
+ X5 + X6 + X7 + X8 + X9 + X10 = 100,000.00, 
X5+X9 > 30,000.00, 
X 3 > 20,000.00, 
Xi > 10,000.00, 
Χ ΐ , Χ 2 , Χ 3 , ^ 4 , Χ δ , ^ 6 , ^ 7 , ^ 8 , ^ 9 , Χ ΐ 0 > 0, 
k 
δ+,δϊ,δ+,δ2>0. 
(16.28) 
The results are presented in Table 16.2. 
Let us introduce the concept of satisfaction function. It will be utilized to 
integrate explicitly the FDM's preferences according to the deviations between 
the achievement and the aspiration levels of each objective. For satisfaction 
function, let us consider 
m) = TTW' 
(16-29) 

16.4 APPLICATIONS 
407 
where a is a parameter. This function exhibits the behavior to be considered a 
satisfaction function and it is trivial to verify that F(0) = 1, and F(+oo) = 0, 
F" ( ^ ) = 0 and that if 0 < Si < ± it holds 0 < F{6i) < 0.1, if δι > f it holds 
0 < F(Si) < 0.01. In other words, this function shows a level of satisfaction 
between 90 and 100 when 0 < 6i < ^ and a level of satisfaction between 0 
and 10 when Si > —. Natural candidates for the indifference threshold and the 
dissatisfaction threshold are, respectively, ξί = ^ and £d = f · Let us assume 
the veto threshold is ξυ = ^. In the following let us choose α = ^ , which 
implies that ξ, = ψ, ξ^ = 30 and ξυ = 60. The GP Model with satisfaction 
function and with weights wf = w^ = 0.75 and w^ = w^ = 0.25 is the 
following: 
maxZ = 0.75F(c5+) + 0.75F^) 
+ 0.25F(S+) + 0.25F{S^), 
(16.30) 
subject to 
' 1.0015Xi + 1.0001X2 + Ι.ΟΟΠΧ3 + I.OOO2X4 + 1.0005X5+ 
1.0001X6 + I.OOI6X7 + 0.9999X8 + I.OOO8X9 + 1.0004Xi0 
-δ+ + δϊ = 100,125.00 
1.1142Χι + 1.0349X2 + 1.0844X3 + 1.0358X4 + 1.0693X5+ 
1.0936X6 + 1.0932X7 + 1.0475X8 + 1.0658X9 + 1.0515X10+ 
δ+ + ί " = 106,200.00 
Xi + X2 + X3 + X4 + X5 + Xe + X7 + Xs + X9 + X10 = 100,000.00, 
X5 + X 9 > 30,000.00, 
X 3 > 20,000.00, 
Xi > 10,000.00, 
Xl,X2,X3,X4,X5,X6>X7,X8 5X9,Xl0 > 0, 
0<δ+,δ~ 
<60, t = 1,2. 
(16.31) 
We have solved the mathematical program (16.31) by using the software 
LINDO [19] and we have obtained the following solutions (Table 16.3). 
16.4.2 
A Goal Programming Model for Media Management and 
Planning 
Media markets are characterized by the presence of two distinct sides whose 
benefits from interacting through a common platform. The media firms sell 
the attention of viewers/readers/listeners to advertisers who need media firms 
to make their products known to potential consumers; more than the past ad-
vertisers face a typical multi-criteria problem and they have to make the best 
choice in terms of audience and costs by taking into account the audiences' 
preferences [2]. Moreover, in the last decade audience fragmentation and dig-
italization have changed the media scenario and media diet is getting more 
and more differentiated. Consequently, it is strategic to build a media plan 
able to reach the planned target group. A media planner has limited financial 

408 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
Table 16.2 
Results of the above WGP model 
Variable 
δΐ 
Si 
tf 
S* 
A T & T 
Walmart 
Exxon Mobil 
General Electric 
Bank of America 
Ford Motor Company 
Hewlett-Packard 
McKesson Corporation 
J. P. Morgan Chase 
Proctor & Gamble 
Value 
0.00 
60.00 
0.00 
0.00 
10,000.00 
40,000.00 
20,000.00 
0.00 
0.00 
0.00 
0.00 
0.00 
30,000.00 
0.00 
Table 16.3 
Results of the above GP model with satisfaction function. 
Variable 
st 
*r 
st 
<52" 
A T & T 
Walmart 
Exxon Mobil 
General Electric 
Bank of America 
Ford Motor Company 
Hewlett-Packard 
McKesson Corporation 
J. P. Morgan Chase 
Proctor & Gamble 
Value 
0.00 
59.99 
0.01 
0.00 
10,000.00 
39,983.77 
20,000.00 
16.23 
0.00 
0.00 
0.00 
0.00 
30,000.00 
0.00 

16.4 APPLICATIONS 
409 
resources and aims to get the best return on investment in terms of attention 
and engagement with potential customers, and at the same time to minimize 
total costs of advertising and communication. Several approaches and models 
have been developed in order to sustain the decision-making process in this 
area and create tools able to increase advertising productivity: each model has 
merits and drawbacks (see Ref. [2] and the references therein). Generally, the 
used objectives in the media selection and planning problem are conflicting 
and incommensurable such as the consumer exposures, consumer attention 
levels to a particular advertisement, attention and engagement of customers 
and the costs of advertising. Usually the available information related to these 
objectives is stochastic. Moreover, the Decision Maker appreciates differently 
the deviations between the achievement and the aspiration levels. Let us con-
sider an approach based on the GP with satisfaction function to integrate 
explicitly the DM's preferences for solving the media selection and planning 
problem. Our example is based on real data coming from the Italian media 
market. Table 16.4 shows the evolution of Italians' media diet [11]. 
Table 16.4 
The evolution of Italians' media consumption. 
Media vehicle 
Media consumption 
Tv 
94 % 
Radio 
67.8 % 
Newspaper 
43 % 
Table 16.5 shows an average of official prices' list for an advertising slot for 
different vehicles (TV, radio, newspaper, and internet). 
Let us choose g\ = 2,000 and 900,000 to be the goals. The integer decision 
variables X, are defined as follows: 
Xj = number of slots to be bought in the vehicle j , 
(16.32) 
The proposed model with satisfaction function is the following: 
maxZ = w+F(6+) + w~F(S^) + w%F(S£) + tujF(&f), 
(16.33) 
Table 16.5 
List of prices for an advertising slot. 
Media vehicles 
Prices (Euro) 
Tv 
70,000 
Radio 
10,000 
Newspaper 
60,000 

410 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
subject to 
I ( Ü I ) X I + I(v2)X2 + I(v3)X3 - δ+ + δ^ = 
gi, 
(16.34) 
c(vi)Xi + c(v2)X2 + c(v3)X3 - δ£ + δ2 = g2, 
XjED, 
j = 1,2,3, 
0<δ+,δ~<ξυ, 
i = l,2. 
where D is the set of integer numbers. The coefficients I(VJ ) associated with 
a vehicle Vj can be interpreted as an expected value that an individual will be 
exposed to an advertisement placed in media vehicle Vj, while the coefficient 
C(VJ) is the cost of a slot in the media vehicle Vj. The model is solved by 
LINDO and provides the following results: X\ = 6, X2 = 18, X3 = 5. 
16.4.3 
A Goal Programming Model for Site Selection 
Site location optimization usually involves the analysis of several conflicting 
criteria. In this context the DM faces the problem of determining the best 
site location by considering different objectives such as costs and budget, 
performance, maintenance, population density, and spatial coverage. 
In this illustrative example we utilize the site selection model presented 
by Brans et al. [8] and we extend it to a stochastic context by assuming 
that the underlying probability space consists of three different scenarios 
Ω = {ωι,ω2,ω3} 
with associated probabilities pi = | , p2 — | and p3 = | . 
Six criteria are considered by the DM in order to select one site among six 
potential locations to build a hydroelectric power-station. The set of poten-
tial criteria is as follows: X\ = Italy, X2 = Belgium, X3 = Germany, X4 
= Sweden, X5 = Austria, and XQ = France. These countries are evaluated 
through the following list of criteria: f\ = manpower, f2 = power (MW), f3 
= construction costs in dollar (109), f± = maintenance costs in dollar (106), 
/e — number of villages to evacuate, and fa = security level. The decision 
variables will be defined as follows: 
y _ j 1, 
if the country j is selected, 
, 
. 
J' 
\ 0, 
otherwise, 
^ ' ' 
where j = 1 for Italy, j = 2 for Belgium,..., j — 6 for France. We will consider 
three evaluations (scenarios) of each location according to each stochastic 
criterion as indicated in Tables 16.6 and 16.7. 
Table 16.8 describes the 
stochastic goals, Table 16.9 presents the deterministic equivalent formulation 
and the expected goals are provided in Table 16.10. 
The model we propose to be solved is the following: 
6 
min Z = Σ(τυ+δ+ 
+ w^Sr), 
(16.36) 

16.4 APPLICATIONS 
411 
Table 16.6 
Objective functions 
Objectives 
X\ 
X<i 
X3 
/i (min) 
/2 (max) 
f3 (min) 
/4 (min) 
/5 (min) 
/6 (max) 
(78,80,82) 
(84,90,92) 
(56,60,61) 
(5,5.4,5.8) 
(6,8,9) 
(1,5,7) 
(62,65,66) 
(50,58,60) 
(18,20,21) 
(9.5,9.7,9.8) 
(0.5,1,3) 
(0.3,1,1.7) 
(80,83,87) 
(54,60,66) 
(38,40,45) 
(6.8,7.2,7.6) 
(3,4,7) 
(3,7,10) 
Table 16.7 
Objective functions. 
Objectives 
X4 
X5 
XQ 
/1 (min) 
/2 (max) 
f3 (min) 
/4 (min) 
/5 (min) 
fe (max) 
(35,40,42) 
(70,80,90) 
(96,100,110) 
(7,7.5,7.7) 
(6,7,9) 
(8,10,13) 
(50,52,56) 
(70,72,73) 
(50,60,67) 
(1.5,2,2.6) 
(1,3,6) 
(6,8,9) 
(90,94,98) 
(90,96,99) 
(60,70,75) 
(3,3.6,4) 
(3,5,8) 
(5,6,9) 
Table 16.8 
Goals. 
Goals 
Samples 
ffi 
(38,40,44) 
g2 
(90,96,100) 
53 
(18,20,26) 
54 
(1.4,2,5) 
g5 
(0.5,1,4) 
56 
(7,10,14) 
subject to 
' 8OX1 + 6O.66X2 + 83.33X3 + 39X4 + 52.66X5 + 94X6 - 6? + δ7 = 40.66, 
88.66XJ + 56X2 + 6OX3 + 8OX4 + 71.66X5 + 95X6 - δ$ + δ7 = 95.33, 
59Χι + I9.66X2 + 41X3 + IO2X4 + 59X5 + 68.33X6 - δ£ + δ7 = 21.33, 
5.4ΛΊ + 9.66X2 + 7.2X3 + 7.4X4 + 2.03X5 + 3.53X6 - δ+ + 07 = 2.38, 
< 7.66Xi + I.5X2 + 4.66X3 + 7.33X4 + 3.33X5 + 5.33X6 - δ£ + 67 = 1.83, 
4.33Xi + X2 + 6.66X3 + 10.33X4 + 7.66X5 + 6.66X6 - δ£ + 67 = 10.33, 
Xi + X2 + X 3 + X4 + X5 + Xe = 1, 
-^1)X2)X35X4,X5,X6 S {0, 1}, 
k δ+,δ~>0, 
i = l,2,...,6. 
(16.37) 

412 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
Table 16.9 
Deterministic equivalent. 
Objectives 
E(/i) 
E(/a) 
E(/3) 
E(/4) 
E(/5) 
E(/e) 
Xl 
80 
88.66 
59 
5.4 
7.66 
4.33 
X2 
60.66 
56 
19.66 
9.66 
1.5 
1 
X3 
83.33 
60 
41 
7.2 
4.66 
6.66 
Xi 
39 
80 
102 
7.4 
7.33 
10.33 
X5 
52.66 
71.66 
59 
2.03 
3.33 
7.66 
Xe 
94 
95 
68.33 
3.53 
5.33 
6.66 
Table 16.10 
Expected goals. 
Goals 
Samples 
E(pi) 
40.66 
E(g2) 
95.33 
Efoa) 
21.33 
E(54) 
2.8 
E(55) 
1.83 
E(g6) 
10.33 
The solution of the deterministic equivalent, obtained by LINGO [19], is 
X2 (Belgium) and this means that the hydroelectric power-station will be 
built in Belgium. 
16.4.4 
A Goal Programming Model for the Next Release Problem 
In software engineering, the next release problem (NRP) consists in finding 
an ideal set of requirements to be developed in a next release by balancing the 
customers' priorities and the resource constraints of the developing company 
[6]. Several solutions have been proposed for this problem, e.g. of Bagnall 
et al. [6], Sagrado et al. [23] and Zhang et al. [27]. Here we propose a new 
approach based on a GP model for solving a stochastic extension of the multi-
objective next release problem (MONRP) proposed in Ref. [27]. 
The NRP assumes a set of independent requirements {ri, r^, · · ·, rn } which 
are candidates to be considered and then developed in the next release. Each 
requirement 7>, k = 1,2,... ,n, has an associated cost costk which is deter-
mined from the amount of resources and effort that each requirement needs 
in order to be implemented. The model also supposes that all requirements 
are suggested by different customers Cj, j = 1,2, ...,m, and the company 
assigns a different level of importance to each customer. This can be denoted 
by the following weight values {λι, Ä2,.. -, Xm} where λ^ is the weight associ-
ated with customer Cj. We denote by V(rk, Cj) the value of the requirement 

16.4 APPLICATIONS 
413 
rk for the customer Cj. Therefore, the overall score or importance of a given 
requirement rk to the company is calculated by 
m 
Sk=Y,XjV(rk,cj). 
(16.38) 
i=i 
The decision variables will be defined as follows: 
v 
f 1, 
if the requirement A; is selected for the next release, 
, 
, 
Xk 
= \ 0, 
otherwise. 
( 1 6' 3 9 ) 
Following Ref. [27], the multiobjective NRP considers two objectives, namely 
the overall customer satisfaction or score provided by Eq. (16.40) - to be 
maximized - and the overall cost for the next release given by Eq. (16.41) 
— to be minimized. The minimization of the cost is treated as an objective 
instead of a constraint. The objective functions considered in Ref. [27] are 
Y^SkXk 
(16.40) 
max 
k-1 
n 
mm Y^costkXk 
(16.41) 
fc=l 
We now consider a stochastic extension of the model (16.40)-(16.41) which 
suppose that the parameters rk, costk and λ^ are random variables defined 
on the probability space Ω. 
As a numerical example, let us suppose that Ω = {ωχ,ω^,ωζ} with prob-
abilities ρ(ωι) = ρ(ω2) — ρ(ω3) = | . In other words we suppose to have 
three different scenarios with uniform probability distribution. The following 
examples use the data presented in Tables 16.11 to 16.14 which have been 
simulated starting from the data presented by Sagrado et cd. [23]. Table 16.11 
presents the cost of each requirement (we drop the currency for simplicity). It 
is assumed that different scenarios can lead to different costs on the develop-
ment of each requirement. Table 16.12 presents the priority assigned by each 
customer to each requirement. In this case it is assumed that the priority 
is not affected by the different scenarios. Table 16.13 presents the different 
level of importance of each customer for the company and finally Table 16.14 
presents the score of each requirement. 
In order to solve the developed model, let us consider the deterministic 
equivalent formulation of the stochastic model and consider the following GP 
model with the following set of weights: wf =0.1, w^ =0.1, m^ = 0.4, w^ = 
0.4. 
minZ = 0.1(5f + 0.15Γ + 0.4(5^ + 0.4&Γ, 
(16.42) 

414 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
Table 16.11 
Requirements' development costs. 
Requirements 
ωι 
U>3 
Mean 
n 
1 
1 
5 
2.33 
r2 
3 
4 
5 
4 
T3 
2 
2 
6 
3.33 
V4 
2 
3 
4 
3 
Γ5 
1 
4 
6 
3.67 
re 
6 
7 
7 
6.67 
r7 
8 
10 
10 
9.33 
r» 
1 
2 
4 
2.33 
Γ9 
1 
1 
3 
1.67 
r i o 
2 
3 
6 
3.67 
Requirements 
U>1 
Mean 
Πι 
2 
2 
5 
3 
r i 2 
4 
5 
8 
5.67 
r i 3 
6 
8 
10 
8 
r i 4 
1 
2 
4 
2.33 
r i 5 
1 
1 
5 
2.33 
r i e 
4 
4 
4 
4 
r i 7 
8 
10 
10 
9.33 
r i 8 
1 
4 
6 
3.67 
r i g 
8 
8 
8 
8 
r20 
2 
4 
4 
3.33 
Table 16.12 
Priority levels assigned by each customer to each requirement. 
Priorities 
Cl 
C2 
C3 
C4 
C5 
Π 
4 
4 
5 
4 
5 
T-2 
2 
4 
3 
5 
4 
r 3 
1 
2 
3 
2 
2 
r4 
2 
2 
3 
3 
4 
r5 
5 
4 
4 
3 
5 
r6 
5 
5 
5 
4 
4 
r7 
2 
1 
2 
2 
2 
re 
4 
4 
4 
4 
4 
rg 
4 
4 
4 
2 
5 
r i o 
4 
5 
4 
3 
2 
Priorities 
Cl 
C2 
C3 
C4 
C5 
Til 
2 
2 
2 
5 
4 
r i 2 
3 
3 
4 
2 
5 
r i s 
4 
2 
1 
3 
3 
1 
r i 4 
2 
4 
5 
2 
4 
r i 5 
4 
4 
4 
4 
4 
r i e 
4 
2 
1 
3 
1 
r i 7 
4 
3 
2 
5 
1 
r i e 
1 
2 
3 
4 
2 
rig 
r2o 
3 
2 
3 
1 
3 
2 
3 
2 
4 
1 
Table 16.13 
Customer weights. 
Weights 
Wl 
a;2 
CLI3 
Cl 
5 
4 
1 
C2 
1 
4 
4 
C3 
1 
3 
2 
c4 
5 
5 
5 
C5 
3 
5 
4 

16.4 APPLICATIONS 
415 
Table 16.14 
Requirements' scores. 
Scores 
Wl 
U>2 
U>3 
Mean 
Scores 
Wl 
ω2 
U>3 
Mean 
r\ 
64 
92 
70 
75.33 
m 
51 
67 
55 
57.67 
f 2 
54 
78 
69 
67 
f l 2 
47 
71 
53 
57 
f 3 
26 
41 
33 
33.33 
ri3 
47 
57 
41 
48.33 
J-4 
42 
60 
47 
49.67 
Γ14 
41 
69 
54 
54.67 
V5 
63 
88 
64 
71.67 
ris 
60 
84 
64 
69.33 
re 
67 
95 
71 
77.67 
Γ16 
41 
47 
33 
40.33 
ri 
29 
38 
28 
31.67 
r\i 
53 
64 
49 
55.33 
7-8 
60 
84 
64 
69.33 
i"18 
36 
51 
43 
43.33 
Γ9 
53 
79 
58 
63.33 
ri9 
48 
68 
52 
56 
no 
50 
73 
55 
59.33 
Γ20 
26 
33 
24 
27.67 
subject to 
' 75.33Xi + 67X2 + 33.33X3 + 49.67X4 + 71.67X5 
+77.67X6 + 31.67X7 + 69.33X8 + 63.33X9 + 59.33Xi0 + 57.67Xn 
+57Xi2 + 48.33Xi3 + 54.67Xj4 + 69.33Xj5 
+40.33Xi6 + 55.33Xi7 + 43.33Xi8 + 56X19 + 27.67X2o + if ~ δΐ = 500> 
2.33Xi + AX2 + 3.3333^3 + 3X4 + 3.6667X5 + 6.67X6 + 9.33X7 
+2.33X8 + 1.67*9 + 3.67Xio + 3Xu 
+5.67Xi2 + 8X13 + 2.33Xi4 + 2.33Xi5 + 4Xi6 
+9.33X17 + 3.67Xi8 + 8X19 + 3.33X20 + δ2 - δ% = 25, 
Χ , € { 0 , 1 } , 
j = l,2,...20, 
t <5+,<5ΓΑ+Α->0. 
(16.43) 
The model is solved by LINGO [19] which provides the following values 
for the deviations: δ^ = 0, 5f = 12.67, 5% = 3.33, δ2 = 0. Furthermore, 
the chosen requirements are Τ·Ι,Γ2,Γ4,Γ5,Γ8,Γ9,ΓΙΟ,Ϊ*ΙΙ,ΓΙ4 and ris, the cost 
of this solution is 28.33$ while the customer satisfaction is 637.33. 
Following the approach by Aouni et al. [3], this second example introduces 
the concept of the satisfaction function. As above we are going to use the 
following definition of satisfaction function: F(6i) = ΤΤ^ΤΤΣ- The value chosen 
for a is a — 1 which implies & = | , £d = 3 and ξυ = 6. Using the same goals 
and weights of the previous example, the model is rewritten into the following: 
maxZ = 0.1F(5+) + O.lF(iJ-) + 0.4F(#) + 0.4F(£j), 
(16.44) 

416 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
subject to 
75.33Xi + 67X2 + 33.33X3 + 49.67X4 + 71.67X5 + 77.67X6 + 31.67X7 
+69.33X8 + 63.33X9 + 59.33Xi0 + 57.67Xn + 57Χχ2 
+48.33Xi3 + 54.67Xi4 + 69.33Xi5 + 40.33Xi6 + 55.33Xi7 + 43.33XX8 
+56Xi9 + 27.67X20 + <5f ~ <*ί~ = 500> 
2.33Xi + 4X2 + 3.3333X3 + 3X4 + 3.6667X5 + 6.67X6 + 9.33X7 + 2.33X8 
+1.67X9 + 3.67Xio + 3Xn + 5.67Xj2 + 8X13 + 2.33X14 + 2.33Xi5 + 4X16 
+9.33Xi7 + 3.67Xi8 + 8X19 + 3.33X20 + &Γ - δ+ = 25, 
JO € {0,1}, 
j = l,2,...20, 
δϊ,δϊ,δϊ,δ;>ο, 
0 < δ+ < 6, 
0 < δϊ < 6, 
0 < δ} < 6, 
0 < δο < 6. 
The solution provided by LINGO is the following: δ* = 4, <5j~ = 6, <5^~ = 6, 
δ^ = 0. The chosen requirements are Τ·Ι,Γ4,Γ5,Γ6,Γ8,Γ9,ΓΙΟ,ΓΙ 1,7-14 and ris, 
the cost of this solution is 31$ while the customer satisfaction is 648. 
EXERCISES 
This section presents some exercises to help the reader to become more 
familiar with the material above. 
16.1 
Solve the following GP model: 
minZ = 0.1<^ + 0.15f + ΟΛδ} + 0.4<5J, 
subject to 
xi + X2 + 3x3 + £j~ — δ^ = 500, 
2xi — 4x2 - 3x3 + δ2 — δ£ = 25, 
£1,2:2,3:3 > 0, 
_ 
δ+,δγ,δ+,δ^>0. 
16.2 
Solve the following GP model: 
minZ = ΟΛδ^ + 0.1 £f + ΟΛδ} + ΟΛδ^, 
subject to 
x\ + X2 + 3xs + δλ — δ^ = 500, 
2xi - 4^2 - 3x3 + 62 - δ£ = 1500, 
ΧΙ,ΧΊ,ΧΆ 
> 0, 
[ 
δ+,δϊ,δ+,δ2~>0. 
(16.45) 
(16.46) 
(16.47) 
(16.48) 
16.3 
Solve the model presented in Exercise 16.2 by including a different 
system of preferences through the satisfaction function F(öi) = . _ Q252S'2 

EXERCISES 
417 
(choose the indifference, the dissatisfaction and the veto thresholds being, 
respectively, equal to & = 40, £<* = 120 and ξν = 240): 
m a x Z = 0.1F(<5+) + 0.1F(5f) + 0.4F(5 +) + 0.4F((iJ), 
subject to 
( xi+x2 
+ 3x 3 + df - <5+ = 500, 
2xi - 4a;2 - 3a;3 + δ? - δ} = 25, 
Ζ ΐ , Ζ 2 , Χ 3 > 0, 
, <5+,<5rA+A->o. 
(16.49) 
(16.50) 
16.4 
Let Ω = {ω\ = 1,ω2 = 2,α>3 = 3} be the underlying space of events 
with associated probabilities pi = 0.1, P2 = 0.2 and P3 = 0.7. Let Y : Ω —> R 
be a random variable defined as Y(u>i) = w\. 
a) Calculate the expected value and the variance of Y. 
b) Consider the following scenario-based GP model: 
m i n Z = 0.15+ + O.lif + 0.45+ + ΟΛδ^ 
subject to 
Y{u)i)xi 
+x2 
+ 3x 3 + i f - <5+ = 500 
2xj - 4x 2 - y(wi)x 3 + (*2~ - &+ = 
2 5 
x i , x 2 , x 3 > 0 
, 
δ+,δϊ,δ+,δϊ>0 
Write the deterministic equivalent formulation of program 16.4 and solve 
it. 
REFERENCES 
1. Aouni, B., Linearisation des expressions quadratiques en programmation mathe-
matique: des bornes plus efficaces. 
Administrative Sciences Association of 
Canada, Management Science, 17, 38-46 (1996). 
2. Aouni, B., Colapinto, C , La Torre, D., Stochastic goal programming model and 
satisfaction functions for media selection and planning problem, 
International 
Journal of Multicriteria Decision Making, in press (2012). 
3. Aouni, B., Colapinto, C , and La Torre, D., Solving Stochastic Multi-Objective 
Programming in Multi-Attribute Portfolio Selection through the Goal Program-
ming Model, Journal of Financial Decision Making, 6, 17-30 (2010). 
4. Aouni, B. and La Torre, D., A generalized stochastic goal programming model, 
Applied Mathematics and Computation, 215, 4347-4357 (2010). 
5. Aouni, B. and Kettani, O., Goal programming model: a glorious history and a 
promising future, European Journal of Operational Research, 133(2), 1-7 (2001). 

418 
CHAPTER 16. THE GOAL PROGRAMMING MODEL 
6. Bagnall, A., Ray ward-Smith, V., and Whittley, I., The next release problem, 
Information and Software Technology, 43, 883-890 (2001). 
7. Ben Abdelaziz, F., Lang, P., and Nadeau, R., Dominance and efficiency in 
multicriteria decision under uncertainty, Theory and decisions, 47(3), 191-211 
(1999). 
8. Brans, J. P., Vincke, Ph., and Marechal, B., How to select and how to rank 
projects: the Promethee method, European Journal of Operations Research, 24, 
228-238 (1986). 
9. Caballero, R., Cerda E., Munoz M.M., Rey L., Stancu-Minasian I.M., Efficient 
solution concepts and their relations in stochastic multiobjective programming, 
Journal of Optimization Theory and Applications, 110(1), 53-74 (2001). 
10. Caballero, R., Cerda, E., Munoz, M. M., and Rey, L., Stochastic approach versus 
multiobjective approach for obtaining efficient solutions in stochastic multiob-
jective programming problems, European Journal of Operations Research, 158, 
633-648 (2004). 
11. Censis, Centro Studi Investimenti Sociali (2010), available at http://www.censis.it. 
12. Charnes, A. and Cooper, W. W., Chance constraints and normal deviates, Jour-
nal of the American Statistical Association, 57, 134-148 (1952). 
13. Charnes, A. and Cooper, W. W., Chance-constrained programming, Manage-
ment Science, 6, 73-80 (1959). 
14. Hannan, E., Non-dominance in goal programming, INFOR Information 
Systems 
and Operational Research 18, 300-309 (1980). 
15. Keeney, R. and Howard, R., Decisions with Multiple Objectives, Wiley, New 
York (1976). 
16. Larbani, M. and Aouni, B., A new approach for generating efficient solutions 
within the goal programming model, Journal of the Operational Research Soci-
ety, 62(1), 1-10 (2011). 
17. Lee, S. M., Goal programming for decision analysis of multiple objectives, Sloan 
Management Review, 14, 11-24 (1973). 
18. Lee, S. M. and Clayton, S.R., A goal programming model for academic resource 
allocation, Management Science, 18(8), B395-B408 (1972). 
19. LINGO. Release 13.0. UNDO Systems Inc. (2011). 
20. Martel, J.-M. and Aouni, B., Incorporating the Decision-Maker's preferences in 
the goal programming model, Journal of the Operational Research Society, 41, 
1121-1132 (1990). 
21. Martel, J.-M. and Aouni, B., Methode multicritere de choise d'un emplace-
ment: le cas d'un aeroport dans le Nouveau Quebec, Information 
System and 
Operations Research, 30(2), 97-117 (1992). 
22. Romero, C , Handbook of critical issues in goal programming, Pergamon Press, 
Oxford (1991). 
23. del Sagrado, J., del Aguila, I.M., and Orellana, F. J., Ant Colony Optimization 
for the Next Release Problem, 2nd International Symposium on Search Based 
Software Engineering, pp.47-56 (2010). 

EXERCISES 
419 
24. Sawaragi, Y., Nakayama, H., and Tanino, T., Theory of Multiobjective 
Opti-
mization, Academic Press, New York (1985). 
25. Stancu-Minasian, I. M., Stochastic programming with Multiple Objective Func-
tions, D. Reidel Publishing Company, Dordrecht (1984). 
26. White, D. J., Optimality and efficiency, Wiley, Chichester (1982). 
27. Zhang, Y., Harman, M., and Mansouri, S. A., The multiobjective next release 
problem, Proceedings of the 9th Annual Conference on Genetic and Evolutionary 
Computation GECCO '07 (2007). 

CHAPTER 17 
DECISION THEORY UNDER RISK AND 
APPLICATIONS IN SOCIAL SCIENCES: 
II. GAME THEORY 
E. V. PETRACOU1 AND A. N. YANNACOPOULOS2 
1 Department of Geography, University of the Aegean, Greece 
Department of Statistics, Athens University of Economics and Business, Greece 
Obviously, you are not a golfer—The Big Lebowski. 
17.1 
INTRODUCTION 
In this chapter we continue our investigation of decision theory and its use in 
the social sciences, by looking at the problem of decision making when there is 
more than one agent involved and furthermore, the actions of one agent may 
interfere with the gain (or loss) of the other. This is a more realistic situation 
and is clearly needed for a better understanding of social phenomena. 
This leads us to the theory of games. The theory of games was introduced 
in the 1940's by Von Neumann and Morgernstern as a model for economic 
behavior and has since become a dominant tool in the economic and social 
Mathematical Modeling with Multidisciplinary Applications.
 
421 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

422 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
sciences. The mathematical content of the theory is very rich, and brilliant 
mathematicians such as, e.g., Von Neumann and Nash have provided the 
mathematical framework. Our approach is inspired by that of Aubin [1]. 
17.2 
BEST REPLIES AND NASH EQUILIBRIA 
The simplest possible situation we may envisage is that of two agents A 
(Athanasios) and E (Electra). Each of the players has a strategy set SA = 
{s\, ■ ■ ■ , sn} and SE = {«i, · · · , sm}. Let us denote by PA(SA, 
SE) the payoff 
of agent A is he plays SA € SA while E plays SE € SE and by PE(SA, 
SE) the 
payoff of agent E is she plays SE € SE while A plays SA & SA- Since PA and 
PE are considered as payoffs (gains) it is natural to give the next definition. 
Definition 17 (Best replies) Define 
PA(SB) 
■= sup 
PA(SA,SE), 
the best payoff that agent A may obtain (over his strategy set) given that agent 
E plays strategy SE- The strategies sA such that 
PA(SA,SE)=P{(SE) 
are called the best replies of A to the strategy SE of E and we denote that as 
s*A € 
BR{sE). 
In a similar manner we define 
PE(SA) 
■= sup 
PE(SA,SE) 
and the strategies s*E such that 
PE(SA,SE)=PE(SA), 
the best replies of E to the strategy SA of A, denoted as sE € 
BR(SA)-
Note that equivalently, 
for given sE &SE, 
BR(sE) 
= arg max PA(SA,SE) 
C 
SA, 
SA£$A 
for given SA € SA, 
BR(SA) 
= arg max PE(SA,SE) 
C SE· 
SE^SE 
In general the sets of maximizers are not consisting of a single element. 
Then we have the following fundamental definition. 

17.2 BEST REPLIES AND NASH EQUILIBRIA 
423 
Definition 18 (Nash equilibrium) We call the strategy (s*A,s*E) a Nash 
equilibrium if 
sAeBR(sE), 
s*E€BR(sA), 
i.e. a Nash equilibrium is a pair of strategies that has the property of being a 
best reply for both agents. 
A Nash equilibrium has the property that none of the two agents wishes 
to leave it. Another way to define a Nash equilibrium is by 
PA(sE) = 
PA(sA,sE), 
The above definitions may be rewritten in terms of loss functions rather 
that payoff functions, where in this case the suprema are exchanged by infima. 
EXAMPLE 17.1 The Prisoner's Dilemma Game 
Two social groups considered as agents A and E, may choose to oppose 
or accepting the government's decision on some issue. The strategy sets 
are discrete SA = (sAti,sA^), 
where sA,i corresponds to A opposing 
the government's decision and SA,2 corresponds to A accepting the gov-
ernment's decision. Similarly with SE- For the sake of exposition let 
us assume that the government is trying to impose salary cuts to two 
different groups of employees (public sector A and private sector E) and 
the payoff is to be measured in terms of — x, where x is the monetary 
sum to be cut. 
The payoff PA is suchthat PA(SA,I,SE,I) 
= —a, PA(SA,I,SE,2) 
= —c, 
PA(SA,2,SE,I) 
= 0, PA(SA,2,SE,2) 
= —b, where a < b < c. As an 
illustrative example consider the case a = 1, = 3, c = 4. The payoff PE is 
such that PE(SA,I,SE,I) 
= -a, PE(SA,I,SE,2) 
— 0, PE(SA,2,SE,I) 
= -c, 
PE{SA,2,SE,2) 
= 
-b. 
For finite games we often display the payoff function in a single table 
A\E 
| 
sE,i 
SE,2 
SA,I 
SA,2 
(-a,-a) 
(-c,0) 
(0, -c) 
(-b, -b) 
We now easily calculate 
PA(sE,i) 
= 0, PA(sEi2) 
= -b 

424 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
(this is the maximum value of the first entry in the parentheses for the 
first column and the second column, respectively) and 
Pi(sA,i) 
= 0, P*E(SA,2) 
= -b 
(this is the maximum value of the second entry in the parentheses for 
the first row and the second row, respectively). Therefore the set of best 
replies are 
BR(sE,l) 
= SA,2, BR(SEfl) = SA,2 
(since if E plays SE,I then A by playing SA,2 obtains the maximum 
payoff which is 0 and if E plays SE,2 then A by playing SA,2 obtains 
the maximum payoff which is —b — we look at the first number in the 
parentheses) and 
BR(sA,l) 
= S£,2, BR(SA,2) = SE,2 
(since if A plays SA,I then E by playing SE,2 obtains the maximum 
payoff which is 0, since if A plays sA,2 then E by playing SE,2 obtains 
the maximum payoff which is — b — we look at the second number in 
the parentheses). The common element of the set of best replies is 
isA,2, SE,2): which is the Nash equilibrium. This can be seen since sA,2 € 
BR{SE,2) 
and SE,2 & BR(SA,2)- 
Observe that if both agents play this 
strategy they suffer a salary cut of b euros each. This is not the best 
solution since if they both played (SA,I,SE,I) 
they would both suffer a 
salary cut of a < b, so they would be better off. Observe that in this 
game both players would have mutually benefited if they had cooperated 
with each other, rather than played as individuals one against the other 
(for if they had communicated their intentions they would both choose 
strategy 1). This example furthermore shows that Nash equilibria maybe 
stable but not necessarily desirable, one should pretty much prefer to 
lock into (SA,I, SE,I), which Pareto dominates the other outcomes. 
■ EXAMPLE 17.2 
The Game of Chicken 
Consider two agents A and E (two countries) which are in a hostile 
situation. The first strategy is to retreat whereas the second strategy 
is to attack. If both agents attack then they have losses of c, if both 
retreat they have losses of a < c. If one attacks and the other retreats 
the one that attacks loses nothing whereas the one that retreats has a 
loss of b. As before a < b < c. 

17.2 BEST REPLIES AND NASH EQUILIBRIA 
425 
This game has the matrix 
A\E 
| 
sE,i 
SE,2 
SA,l 
SA,2 
(-a,-a) 
(-6,0) 
(0, -6) 
(-c, -c) 
The set of best replies are 
BR(sE,i) 
= sA,2, BR(sE,2) = SA,I, 
BR(SA,I) 
= sE,2, BR(sA,2) = «sa-
lt is seen that the pair (SA,I,SE,2) 
has the property that SA,I G 
BR{SE,-Z) 
and SE,2 € BR(SA,I)· 
Furthermore, the pair {SA,2,SE,I) 
also has the 
property that SA,2 € BR(SE,I) 
and SE,I & BR{SA,2)· 
Therefore, the 
Nash equilibria are now two (SA,I,SE,2) 
and (SA,2,SE,I): 
corresponding 
to one of the countries choosing to retreat while the other chooses to 
attack. These equilibria are Pareto ranked and there is a priori no way 
to pick one of the two, unless other mechanisms are included in the 
EXAMPLE 17.3 The Battle of the Sexes 
This is a game where the players have different preferences for what they 
wish to do (e.g., A prefers going to the ballet whereas E prefers going to 
see a football match) but at any rate they both prefer to be together. As 
Osborne and Rubinstein put it, this game "models a situation in which 
players wish to coordinate their behavior but have conflicting interests" 
[8]. 
This game has the payoff matrix 
A \ E \ 
SE,1 
SE,2 
SA,1 
SA,2 
(0, -a) 
(-6, -b) 
(-6,-6) 
(-«,0) 
The set of best replies are 
BR(sB,i) 
= sA,i, 
BR{sEfl) 
= sA,2, 
BR(SA,I) 
= sE,i, 
BR(sA,2) 
= sE,2-
It is seen that the pair (SA,I,SE,I) 
has the property that SA,I € 
BR(SE,I) 
and S E I € BR(SA,I)- 
Furthermore, the pair (SA,2,SE,2) 
also has the 

426 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
property that SA,2 € BR{SE,I) 
and SE,2 € BR{SA,2)- 
Therefore the 
Nash equilibria are two (SA,I,SE,I) 
and 
(SA,2,SE,2)· 
EXAMPLE 17.4 
Coordination Game 
This is a game in which again A and B wish to be together. This game 
has the payoff matrix 
A\E 
SEA 
SE,2 
SA,I 
SA,2 
The set of best replies are 
BR(sEil) 
= 
BR(sA,i) = 
(-b, -b) 
(0, -a) 
(-α,Ο) 
(-c,-c) 
SA,2, 
BR{sE,2) 
= SA,1, 
: SE,2, 
BR{SA,2) 
= 
SEA-
and the Nash equilibria are now two (SA,I,SE,2) 
a nd (SA,2,SE,I)- 
The 
Nash equilibria are Pareto ranked, one of the two being inferior of the 
other, however, the two players may as well lock into the inferior one 
(there is no a priori reason of which to choose unless other mechanisms 
are included in the game). One may argue that this simple observation 
is already a challenge to our assumptions of rationality. 
EXAMPLE 17.5 
A Model for International Agreements 
Assume that the two agents A and E represent countries that will either 
participate or not in an international agreement. The first strategy 
corresponds to participating, the second in not participating. If both do 
not participate they will face a loss of a units. The matrix of the game 
is as follows: 
A\E 
SEA 
SE,2 
SA,I 
SA,2 
(0,0) 
(-1,1) 
(1,-1) 
(-a,-a) 
The Nash equilibria depend on the value of a. If a € (0,1) then one 
can easily see that there is a unique Nash equilibrium (SA,2, 
SE,2) 
in 
which the two countries do not cooperate. Clearly, this is not the best 

17.2 BEST REPLIES AND NASH EQUILIBRIA 
427 
possible of all decisions since if the countries were playing 
(SA,I,SE,I) 
instead this would be beneficial for both (Pareto optimality). However, 
unless the two countries do not act in a selfish way (or if they do not 
communicate concerning their intentions beforehand) they will not get 
to this equilibrium. If a > 1 then the situation changes and there are 
two Nash equilibria (SA,I, 
SE,2) and {SA,2, 
SE,I)- 
There is no way before-
hand to know which of the two will be chosen, unless other criteria or 
supplementary mechanism selections are included in the game. 
In many cases of interest the strategy space may be continuous. The notions 
of best reply and Nash equilibria may be generalized in a natural way. We 
illustrate them with the following example: 
■ 
EXAMPLE 17.6 A M o d e l of Political Competition 
Assume a local society whose spatial location is the interval [0,1]. The 
members of the community must decide on the exact location s e [0,1] 
where a site that is used by the community is to be built. 
All the 
members of the community participate in voting for the exact location 
to be decided, and we assume that each voter wishes for the facility to 
be built as close as possible to her living site. We further assume that all 
agents ideal points are distributed in [0,1] with a distribution density / , 
for example, the uniform distribution. Two politicians propose for the 
location of the facility as part of their electoral campaign. The winner 
of the game is the politician whose proposal goes through and the payoff 
is 1. The other candidate gets —1, so the game is a zero-sum game. The 
voters simply vote for the closest candidate and we assume that their 
actions may not affect the politicians proposals. 
The strategy sets SA = SE = [0,1] are now uncountable sets contain-
ing an infinity of possible strategies. Suppose A chooses SA € [0,1] and 
E chooses SE & [0,1]. The payoff of each politician clearly depends on 
the median SM '■— SA~^SE ■ The payoff of politician A is 
(
1 
if 
SA < s ^ a n d s M > \ 
or SE < SA and SM < §, 
0 
if 
SA = sE and sM = f, 
— 1 if 
SA < s ^ a n d s M < ^ 
or SE < SA and SM > \, 
whereas PE{SA,SE) 
= —PA{SA,SE)- 
This payoff models the fact that 
if, e.g., SA > SE then all voters on the left of SM will vote for candidate 
E. 
Since the voters are uniformly distributed the fraction of voters 
on the left of SM is SM, this corresponds to the probability for E being 
preferred. Then A gets the rest of the voters which are 1 — SM- Similarly 
for the other cases. 

428 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
The best response correspondence for candidate A is 
{
(sE,l - sE) 
if sE < ψ 
sE 
if sE = 0. 
(1 - SE,SE) 
if 
SE > j -
Observe that the best reply is not a single-valued mapping, the image 
may be a whole interval and not a single number! This situation is quite 
common in optimization applications. The best response of candidate 
E is symmetric, 
{
(SA,1-SA) 
if 
sA < ψ 
sA 
if 
SA = I, 
(1-8A,SA) 
if 
sA>\-
The Nash equilibrium is the common point of these two correspondences, 
which is SA = SE = \. This is obvious since | = BRA{\) 
and | = 
BRE{\)- 
It can further be shown that this Nash equilibrium is unique. 
In this simple example it can be seen that the Nash equilibrium is 
for both candidates to adopt the same strategy and propose to build 
the facility in the middle. This of course reflects the symmetry of the 
distribution of the voters. An asymmetric distribution would lead to a 
different Nash equilibrium. This model has been proposed by Hotelling 
in 1927 (long before the introduction of game theory) as a model for 
location analysis and of course was treated in a different fashion than 
shown here. It was later taken up by Downs in 1957 as a model for 
electoral competition and has led to many variants and a lot of discussion 
(see, for example, Ref. [4]). 
17.3 
MIXED STRATEGIES AND MINIMAX 
Consider two agents A (Athanasios) and E (Electra) playing a zero sum 
game. Each of the players has a strategy set SA = { S A , I , · · · ,SA,U} 
and 
SE = {SE,1I · · · > SE,m} and may choose a mixed strategy which is represented 
by two probability vectors pA - {ΡΑ,Ι, · · · ,ΡΑ,Π}, 
PE = {ΡΕ,Ι, ■ · ■ ,PE,m} re-
spectively. A mixed strategy PA means that agent A will play strategy SA,I 
with probability ΡΑ,Ι, i = 1, · · · , n and similarly for agent E. The payoff of 
player A if he plays (pure) strategy i when E plays (pure) strategy j is Cy. 
Since it is a zero-sum game the payoff matrix has the property Cij = —Cji. 
The expected payoff for player A if he plays the mixed strategy PA while 
E plays the mixed strategy PE is 
n m 
PA(PA,PE) 
—^^PAjPEjCij, 
i=l j=l 

17.3 MIXED STRATEGIES AND MINIMAX 
429 
whereas the expected payoff for player E, in the same situation, is PE(J>A,PE) 
= 
—PA(PA,PE)- 
In contrast to what happens for pure strategies it can be 
shown that a Nash equilibrium always exists for mixed strategies. This result 
holds true for games which are not necessarily zero-sum games (i.e., when 
C{j ^ 
Cji)· 
■ EXAMPLE 17.7 Matching Pennies 
Consider the game with payoff matrix 
A\E 
\ SE,1 
SE,2 
SA,I 
(1,-1) 
(-1,1) 
sA,2 
(-1,1) 
(1,-1) 
This game presents a situation where according to Osborne and Rubin-
stein "the interests of the players are diametrically opposed" or "strictly 
competitive," [8] and has no pure strategy Nash equilibrium. 
If we consider mixed strategies then player A will pick strategy SA,I 
with probability ΡΑ,Ι = P and strategy SA,2 with probability PA,2 = 1 ~P 
whereas player E will pick strategy SE,I with probability ps,i = q and 
strategy SE,2 with probability ps,2 = 1 — 9- Then it can be seen that 
p = q = | is a (mixed strategy) Nash equilibrium. 
When working in terms of mixed strategies a game maybe rewritten as a linear 
programming problem. 
■ EXAMPLE 17.8 
Games and Linear Programming 
Let us consider the following game theoretic situation: 
Player A will choose the vector PA so as to win at least λ on average, 
i.e., it must hold 
n 
λ < ] P <kjPA,i, j = 1, · · · , m. 
His goal is to maximize this λ under the above constraints. This means 
that A will choose (ΡΑ,Ι, · · · :PA,n, λ) as the solution of the linear pro-

430 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
gramming problem 
max λ 
(ΡΑ,λ) 
subject to 
n 
λ - Σ 
cijPA,i < 0, j = 1, · · · , m, 
t = l 
n 
PA,i > 0, i = 1,··· ,n. 
Player £ will choose the mixed strategy PE — (ΡΕ,Ι, · · · ,Pß,m) so that 
she loses at most μ in the mean, that is μ > Y™=1 CijPEj for i = 1, · ■ ■ , n. 
Then she wishes to minimize this loss, so that she will choose PE and μ 
as the solution of the linear programming problem 
min μ 
(ΡΕ,μ) 
subject to 
m 
μ - ΣcijPEj 
^ °> i = !) · · ·. n> 
m 
U P E J = i. 
PB,j > 0 , j = 1,··· ,m. 
The students familiar with the theory of linear programming will soon 
notice that one problem is the dual of the other. Thus the optimal value 
of μ and the optimal value of λ are related. This observation is true in 
more general situations—see the minimax theorem. 
Mixed strategies can be defined equally well for the case of continuous strat-
egy spaces; in this case a mixed strategy is a probability distribution over the 
strategy space and the payoff is defined as the expectation over this distri-
bution. For instance, if the strategy spaces 5U and 5^ are continuous then 
a mixed strategy for A is a probability distribution GA on SA and a mixed 
strategy for E is a probability distribution GE on SE- Then the expected 
payoff is given by JSA JSE f(x, 
y)dGE(y)dGA(x). 
17.4 
NASH EQUILIBRIA AND CONSERVATIVE STRATEGIES 
Let us now consider more general strategy spaces, not necessarily discrete, 
so that the payoffs PA and PE of the two agents will be functions βΑ,ίε '■ 
SA x SE —> K. Let JA(X, y) by the gain of A and /B(X, y) be the gain of E 

17.4 NASH EQUILIBRIA AND CONSERVATIVE STRATEGIES 
431 
when they play strategies (x, y) G SA X SE- Then 
BRA(y) 
= arg max fA(x, y) 
X€SA 
is the set of best replies of A to the strategy y of E and 
BRE{x) 
= arg max fE(x, y) 
is the set of best replies of E to the strategy a; of A A Nash equilibrium is a 
strategy (x*,y*) such that 
x* G BRA(y*), 
y* G 
BRE(x*). 
Note that the set of best replies of one player to a strategy of another player 
may not consist of a single element (see, e.g., Example 17.6). Furthermore, 
note that a Nash equilibrium can be characterized as some sort of fixed point 
(for a multivalued map). 
We now consider a slightly different approach to the problem of charac-
terizing the best strategy to be followed by the two players. Suppose that 
each player chooses her or his moves so as to minimize the gain of the other. 
Then A knows that E will choose this strategy y that minimizes fA(x, y). So 
A has access to infyesE fA(x,y). 
Then he must try to do his best to max-
imize that and thus he will choose a strategy x so as to solve the problem 
suPxesA
 mfyesE fA{x,y)- 
Such a strategy x maximizes the "worst scenario" 
for the gains of A, i.e., the gains that he will have access to given that E is 
nasty, clever and lucky enough to mess A up as badly as she can. We will call 
this strategy for A, a conservative strategy and denote it by 
x G arg max ( inf fA(x, y)) . 
XGSA \yesE 
) 
Similarly for E, assuming that A does his best to mess her up we may 
define a similar strategy x which is the conservative strategy for E as 
y G arg max I inf fE(x,y)) 
■ 
y€<sE \xesA 
j 
The above discussion motivates the following: 
Definition 19 (Conservative strategies) A strategy (x, y) € SA x SE is 
called a conservative strategy if 
x G arg max I inf fA(x,y) 
I , 
Z € S A \y€SE 
) 
y G arg max ( inf fE{x, y) ) . 
y€SE 
\xeSA 
I 

432 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
The obvious question that arises is: Under which circumstances are these 
two strategies related? 
17.5 
ZERO-SUM GAMES AND THE MINIMAX THEOREM 
Consider the special class of games in which f(x,y) 
:= fA{x,y) = 
—fE{x,y), 
for all (x, y) G SAXSE- 
In such games the gain of A is the loss of E and vice 
versa. Such games are called zero-sum games. 
Suppose that (x*,y*) is a Nash equilibrium for such a game. Recall that 
for any function /, sup(—/) = — inf(/), inf(—/) = — sup(/). Then, 
BRA{y) = a,rg max fA(x,y) 
= arg max 
f{x,y) 
X£SA 
X(ZSA 
and 
BRE(x) 
= arg max fE(x, y) = arg min f(x, y), 
y€oE 
y€SE 
i.e., the best replies of A to a strategy y G SE are these strategies that 
maximize f(x,y) 
over x for a given y, whereas the best replies of E to a 
strategy x G SA are these strategies that minimize f(x, y) over y for a given 
x. 
Therefore, in a zero-sum game player A maximizes f(x, y) over x (for 
fixed y) whereas player E minimizes f(x,y) 
over y (for fixed x). If we have 
a matrix game then one player maximizes over rows whereas the other player 
minimizes over columns. Then by definition the Nash equilibrium is a point 
(x*,y*) such that 
f(x,y*) 
< f(x*,y*) 
< f{x\y), 
V (x,y) G SA X SE. 
This is a saddle point for the function /. Therefore, the Nash equilibrium for 
a zero sum game is characterized as a saddle point for the function / . 
■ EXAMPLE 17.9 
Consider SA X SE = [—1,1] x [—1,1] and f(x, y) = -x2 + y2. The Nash 
equilibrium is the strategy (0,0). 
Let us now consider the conservative strategies. From the definitions we obtain 
x G arg max ( inf fA(x, y) I = arg max ( inf f(x, y) I , 
x&SA \yeSE 
) 
xeSA \yeSE 
J 
and 
y G arg max ( inf fE(x,y)) 
= 
arg max I inf 
-f{x,y)) 
y€SE \X€SA 
J 
y€SE \x€SA 
J 
= arg min I sup f(x,y)) 
. 
y€SE \xeSA 
J 

17.5 ZERO-SUM GAMES AND THE MINIMAX THEOREM 
433 
y € arg min 
sup f(x,y) 
. 
yesE 
\xesA 
The above considerations lead to the following: 
Definition 20 A strategy (x, y) G SA X SE is a conservative strategy for a 
zero-sum game if 
x G arg max I inf f(x, y) 1 , 
xeSA \y€SE 
I 
The numbers 
VA ■— sup I inf f{x,y) 
I , andvs := inf ( sup 
f(x,y) 
x&sA \y^sE 
J 
yesE 
\xesA 
are called the conservative values of the game for A and E, respectively. 
In general VA φ VE* Let us first obtain an obvious inequality. For every 
y G SE, f(x,y) 
< suPxeSA fix^v) 
an<^ °f course this inequality holds for the 
infimum over y G SE SO that f(x,y) 
< miyesEsupx€SAf(x,y) 
= VE- Fur-
thermore, for every x e SA, mfyesE 
f{x, y) < f{x, y) and since this inequality 
holds for every x it holds also for the supremum of the quantity on the left-
hand side over all x, VA ■= supx6S/1 (infy6sE f{x,y)) 
< f{x,y). 
Therefore, 
VA < f(x,y) 
< VE, V(x,y) eSA 
x SE. 
The quantity VE — VA is called the duality gap. 
The important question that arises is when is this duality gap equal to 0? 
The second important question is whether there is any connection between 
Nash equilibria and conservative strategies. 
Theorem 15 A Nash equilibrium is also a conservative strategy for which 
VA = VE and the converse also holds. 
Proof: Let (x*,y*) be a Nash equilibrium for the game. We will then show 
that VA = VE and the (x*,y*) is also a cooperative equilibrium. Since VA < VE 
it is enough to show that VA > VE also holds. By the definition of a Nash 
equilibrium we have the saddle point property 
f(x,y*) 
< f{x*,y*) < f(x*,y), 
V(x,y) G SA x SE-
We start by the right-hand side of this inequality which since it holds for all 
y it holds also for the infimum over all y to yield /(#*, y*) < infyesE 
f(x*,y) 
and when the right-hand side of this inequality is considered as a function of 
x its value at x* is certainly less than the supremum of this quantity over all 

434 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
x G SA, therefore 
/(**,»·) < f(x*,v) 
< inf f(x*,y) 
< sup ( inf f(x,y)) 
=vA. 
(17.1) 
We then take the left-hand side of the saddle inequality, which since it holds for 
all x it also holds for the supremum over all x G SA to yield sup x e 5 A f(x, y*) < 
f{x*,y*) 
and when the left-hand side of the latter equality is considered as 
a function of y the value of this function at y* (which is the number on the 
left-hand side) is certainly larger or equal to the infimum of this function over 
all y G SE- The above reasoning gives 
vE = inf ( sup f(x,y)) 
< sup f{x,y*) 
< f(x\y*). 
(17.2) 
y&SE \X£SA 
J 
X€SA 
Combining (17.1) and (17.2) yields VE < VA SO that VE = VA-
By the saddle path property y* minimizes f(x*,y) 
and x* being a Nash 
equilibrium is chosen so as to maximize f(x,y). 
Therefore y* minimizes the 
maximum of f(x,y) 
over x, i.e., y* G arg πύη^ς^ (supxe<S/1 f(x,y)) 
and y* 
is also a conservative equilibrium for E. 
By the saddle path property x* 
maximizes f{x,y*) 
and since y* is a Nash equilibrium it is chosen so as to 
minimize f(x, y). Therefore x* maximizes the minimum of f(x, y) over y, i.e., 
x* e argmaxx6sA (infyesE f(x,y)) 
so that x* is also a conservative equilib-
rium. 
It remains to show the converse property. Suppose that vA = VE and that 
(x, y) is a conservative equilibrium. We will show that (x, y) is also a Nash 
equilibrium. Let v = VA = VE be the common value for the game. Since x 
maximizes the minimum of f(x, y) over y we have that 
inf f(x, y) = sup ( inf f(x, y)) = v. 
y£$E 
xesA 
\y^sE 
) 
Similarly since y minimizes the maximum of f(x, y) over x, we have that 
sup f(x, y) = inf ( sup f(x, y)) = v 
xesA 
V<=SE \xesA 
/ 
so that supx65A /(#, y) — infy€<sE f(x, y) = v. We now have the obvious17 
inequalities 
v = inf f(x,y) 
< f{x,y), 
and v = sup f(x,y) 
> f(x,y), 
Vx G SA, 
V^SE 
x£SA 
17The inf over y is smaller or equal than the value of the function at any point y, and we 
pick y = y. 

17.5 ZERO-SUM GAMES AND THE MINIMAX THEOREM 
435 
so that 
f{x,y) < f{x,y), Vx 6 5Λ. 
Similarly, we have that18 
v = sup f(x,y) 
> f(x,y), 
and v = inf f(x,y) 
< f{x,y), 
Vy € SB, 
xesA 
yeSE 
so that 
f(x,y)>f(x,y), 
Vj/e<SB. 
Therefore, the point (x, y) has the property 
f(x,y) < f(x,v) < f(x,y), 
v(x, y)eSAx 
sE 
and thus it is a saddle point, hence a Nash equilibrium. 
■ 
It remains to show that a Nash equilibrium exists. Since in the particular 
case of two players zero-sum games Nash equilibria can be characterized as 
saddle points of the payoff function, to do this we may use a general theorem 
for the existence of saddle points. This can be done using a class of important 
theorems called minimax theorems. The first such theorem was proved by 
John Von Neumann and bears his name. 
At this point we present and provide a proof of the famous Von Neumann 
minimax theorem. These are numerous proofs of this theorem as well as nu-
merous generalizations and extensions. Here we present one of the simplest 
versions of this theorem, and give a proof that was published by the math-
ematical economicist Nikaido in 1954 [5]. For an alternative proof one may 
see, e.g., Ref. [2]. 
Theorem 16 (Von Neumann minimax) Let SA and SE be compact con-
vex19 sets and let f : SA X SE —* K, continuous concave in x and convex in 
y. Then there exists a point (x, y) such that 
f(x,y)= 
sup f(x,y)= 
inf 
f(x,y). 
xesA 
y£sE 
1 8The sup over x is greater or equal than the value of the function at any point x and we 
pick x = x. 
19Recall the following fundamental definitions: A subset M of a metric space is called 
closed if it contains all its accumulation points. A subset M is open if for every x 6 M 
there exists an open ball of radius e > 0 centered at x, Bx(e) such that Bx(e) 
C M. 
A 
subset M is open if and only if its complement is closed and vice versa. A subset of a metric 
space is called compact if every open cover of this set has a finite subcover. Equivalently, a 
subset of a metric space is compact if every bounded sequence in this set has a convergent 
subsequence. A subset M of a metric space is called convex if it has the property that if 
x,y 6 M then \x + (1 — \)y € M for all λ e [0,1]. In finite-dimensional spaces compactness 
for a set is equivalent to this set being closed and bounded; however this is not true in 
infinite dimensions eventhough a compact set is always closed and bounded. A function 
/ : M -» R is convex if f(Xx + (1 - X)y) < Xf(x) + (1 - \)f{y) 
for all x, y 6 M, λ 6 [0,1]. 
A function is concave if —/ is convex. 

436 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
Proof: For any λ, μ € R define the sets 
Ax := {xeSA 
: f(x,y) 
> X, Vy G SE} C SA, 
Εμ ·.= {y eSE ■■ f(x,y) < μ, Vx e SA} c SE. 
By the properties of / these sets are closed convex sets. Next define 
λ* = sup{A : Ax φ 0} μ* = inf{μ : Εμ φ 0}, 
i.e., the smallest upper bound of the set of λ such that these exists an £ £ SA 
such that f(x, y) > X for all y G SE and the largest lower bound of the set of 
μ such that there exist a y e SE such that f(x,y) 
< μ for all x £ SA. 
By the compactness of SA and SE it follows that20 
Αχ. φ$, 
X* < oo, 
£μ· ^ 0, μ* > -oo. 
Since Α\· and Ε μ· are not empty let x* € AA« and y* e £^μ>. For the pair 
(x*,y*) it clearly holds that 
λ * < / ( ζ * , ! / * ) < μ · . 
If λ* = /x* then by the definition of A\* and Εμ> it follows that 
/(x*,y) > λ* - f{x\y") 
= μ*> f(x,y*), 
V(x,y) e SA x SE, 
therefore (x*,y*) is the saddle point we seek. It thus remain to show that 
λ* = μ*. 
To show that let e > 0. By the definitions of λ*, μ* if follows that A\*+<L = 0 
and Εμ*-ι = 0. By the definition of A\, we have that A\'+e 
= 0 implies that 
Vx€SA, 
3yeSE 
: f(x,y)<X*+e=:X1. 
(17.3) 
Similarly by the definition of Εμ, we have that Eß*-e = 0 implies that 
VyeSE, 
3xGSE 
: f(x,y) 
> μ·-e=: 
μι. 
(17.4) 
For a pair (x, y) € SA x SE define now 
SA,y := {xeSA 
: f(x,y) 
< Xi}, 
SE,X := {y G SE : f(x,y) 
> μι}, 
2 0 By Weierstrass' theorem a continuous function on a compact set has a minimum and a 
maximum. 

17.5 ZERO-SUM GAMES AND THE MINIMAX THEOREM 
437 
which by continuity of / are open sets. By (17.3) and (17.4) it follows that 
SA C [J 
SA,V, 
<SB C [J 
SE,X, 
yesE 
xesA 
so that we may use the open sets SA,y, 
<SEX for all possible x and y to 
construct open covers for SA and SE- But since SA and SE are compact sets, 
these open covers have finite subcovers. This means that there exist two finite 
sets {xi} G SA, i = 1, · · · , &i and {j/j} e SE, j = 1, · · · , (2 such that 
^A C [J SA,VJ , SE C (J 5Β)Χί 
j = l 
»=1 
therefore 
min/(ic,y.,·) < Ai, Va; € <SA, m a x / ^ j / ) > μι, Vy € «Sß. 
(17.5) 
Set 
0*(ϊ/) :=πΐ3χ(0,/(α;ί,?/)-/ii), ^(2;) :=max(0,Ai - 
f(x,yj), 
for i = 1, · · · , £1, j — 1, ■ ■ · , ^2, and observe that by (17.5) it follows that 
ii 
h 
t=l 
j = l 
Define the map 
which clearly is a continuous map # : <S^ x SE —► SA X SE- More importantly 
it is a continuous map of the set co({xi}) x co({yj}) to itself where by co we 
denote the convex hull (or convex closure). Brouwer's fixed point theorem21 
guarantees the existence of a point (a;*, 3/*) € co({xi}) x co({yj}) such that 
χ* Σ Φ*(ν*) = Σ Μν*)χί, 
*=1 
i=l 
2/*Σ^(^*) = 5Z^i(a;*)2/i· 
J = l 
j = l 
The Brouwer fixed point theorem states that any continuous function for a convex com-
pact subset of a Euclidean space to itself has a fixed point. 

438 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
For the i such that 0i(y*) > 0 we have that f(xi,y*) 
> μι- Taking convex 
combinations of these inequalities, recalling that x„ is in the convex hull of 
{xi} and using the concavity property of f(x,y) 
with respect to the first 
variable we see that 
f(x*,y*) 
>/xi-
Similarly, for the j such that ipj{x*) < 0 we have that f(x*, yj) < Xi- Follow-
ing the same approach as above but now using the convexity of f(x, y) with 
respect to the second variable we see that 
f(x*,y*) < λι. 
Combining these two inequalities μ\ < X\ therefore μ* < λ* + 2e for any e > 0 
so that μ* < X*. That combined with the fact λ* < μ* guarantees λ* = μ* 
and the proof is complete. 
■ 
One could argue that the concepts and techniques used in the proof are 
probably on the boundary of applied mathematics. At any rate we include 
it here and encourage the student to study it since applied mathematics may 
often have to resort to "pure" techniques and benefit considerably from them. 
As the eminent mathematician Henry Pollak once said, "There is no real 
distinction between pure mathematics and applied mathematics. There is 
only a difference between good mathematics and uninteresting mathematics." 
Furthermore, according to great geometer Nikolai Lobachevsky, "There is no 
branch of mathematics, however abstract, which may not someday be applied 
to the phenomena of the real world." 
An important consequence of the minimax theorem is the following: 
Theorem 17 A Nash equilibrium always exists in the space of mixed strate-
gies for finite games. 
Proof: 
The proof uses the von Neumann minimax theorem (see Theorem 
16) and the convexity properties of the space of mixed strategies. 
■ 
Remark 17.5.1 Theorem 17 can be generalized, upon conditions, for games 
with more complicated strategy spaces. 
17.6 
NASH EQUILIBRIA FOR MIXED STRATEGIES 
Now let us consider a more general game where there are more than 2 players. 
Assume that I = {1,2,··· ,7} is the set of players. We adopt the following 
notation: By Sj we denote the strategy of player i and by s-i the strategies 
of all the other players except i. Let Ui(si, s-i) be the payoff of player i if she 
plays strategy s* while the other players play strategy s_j. The best reply of 

17.6 NASH EQUILIBRIA FOR MIXED STRATEGIES 
439 
player i to the strategies of the other players is 
BRi(s-i) 
= arg max Ui(si,s_i). 
Si 
Clearly, this is not necessarily a single-valued mapping, in general it is a 
correspondence. 
Definition 21 A strategy s = (s\, ■ ■ ■ , Sj} is a Nash equilibrium for this game 
if Si € BRi(s-i) 
for all i £ l . 
In other words a Nash equilibrium is a best reply to itself. 
The existence of Nash equilibrium may be shown using a general theorem 
due to Kakutani. This is a fixed point theorem for non-single-valued mappings 
(correspondences). Clearly, a correspondence may be considered as a set 
valued mapping. If 5 is a set we will use the notation 2 s for the power set, 
i.e., the set consisting of all the possible subsets of S. 
Definition 22 A correspondence has closed graph if for all sequences {xn} 
and {yn} such that xn —► x and yn —> y we have that yn G f(xn) 
implies 
y e f(x). 
The closed graph property is some type of continuity assumption for the 
correspondence. 
Theorem 18 (Kakutani) Let S e i " be a nonempty, compact and convex 
set. Let f : S —> 2 s be a correspondence (set valued map), which has closed, 
nonempty and convex graph. Then f has a fixed point, i.e., there exists an 
x G / (not necessarily unique) such that x G f{x). 
The existence of the Nash equilibrium for mixed strategies may then be 
obtained by an application of the Kakutani fixed point theorem. 
Theorem 19 (Nash) There always exist a Nash equilibrium for the mixed 
strategies. 
Proof: Assume, without loss of generality, that each player has n pure strate-
gies. The mixed strategy space, for each player, is now the unit simplex Δ™-1 
which clearly is nonempty, convex and compact. The total strategy space is 
Δ η _ 1 x · · · x Δ η _ 1 where we take the Cartesian product of the unit simplex 
with itself / times. Clearly this is also a nonempty, convex and compact set. 
The payoff function for each agent is the expected payoff which is a continuous 
function. By Weierstrass theorem, since this continuous function is defined 
on a compact set it achieves its maximum, therefore the best replies corre-
spondences are nonempty. It can be seen that BRi(s-i) 
is convex. Indeed, 
let s, s G BRi(s-i). 
Then λ s + (1 - λ) s G BRi(s-i) 
for all λ G [0,1]. Finally, 
we need to show that the best reply correspondence has the closed graph 
property. This is not a very easy task, it is guaranteed again by a general 

440 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
theorem called the Berge maximum theorem (see, e.g., Ref. [2]). According 
to this theorem since the payoff function is continuous and compact the best 
reply correspondence is upper hemicontinuous and this leads to the required 
closed graph property. Thus an application of the Kakutani fixed point the-
orem leads to the existence of a fixed point for the best reply correspondence 
BR = (BRi, ■ ■ ■ , BRi) which is the Nash equilibrium. 
■ 
17.7 
COOPERATIVE GAMES 
In many situations in social sciences and economics agents do not play for 
themselves but rather cooperate with other agents. This will only happen if 
it is to their benefit to do so. Assume that utility is transferable. Therefore, 
before addressing such situations we need to describe first the utility of the 
various possible coalitions between players, how these change as a function 
of the various possible strategies and then define a rule on how the common 
utility of a coalition is divided among the individuals. The above questions 
lead us to the mathematical modeling of cooperative games. For a complete 
introduction see, e.g., Ref. [6]. 
We first need to define the set of all players 1 = {1, · · · , / } . We then 
need to define the set of all possible coalitions. A coalition is a subset of I , 
therefore the set containing all possible coalitions is the power set 21, the set 
of all possible subsets of Ί. For a discrete set / we will denote by card(I) its 
cardinality,22 i.e., the number of elements in this set. Since I is a discrete set, 
the powerset 2Z is also a discrete set of cardinality 21 where / = card(l) is 
the number of players. The set I is the largest possible coalition called the 
grand coalition and the empty set 0 is called the empty coalition. 
Definition 23 A characteristic function is a function υ : 2X —> M satisfying 
ν(Φ) = 0. 
The characteristic function is a set valued function which assigns a real 
number to every coalition, which is called the worth of the coalition. This de-
pending on the setup of the game will be considered either as loss or gain. The 
fact that the empty set is assigned the value 0 is just a convenient convention. 
Definition 24 The pair (J, v) is called a cooperative game in characteristic 
function form. 
The worth v(C) of a coalition C has to be divided among the players. A 
division rule a = (α,χ, ■ ■ ■ , aj) is called payoff. A special case of payoff is an 
imputation. 
Definition 25 An imputation is a payoff a = (oj, · · · ,ai) such that 
22 Alternative notation for the cardinality of a set is either |/| (which we avoid so as not to 
confuse the reader with absolute value) or ))/. 

17.7 COOPERATIVE GAMES 
441 
(i) ai > v({i}) for all i = 1, · · · , / and 
(ü) Έΐ=ιαί = ν(1)-
The first condition tells us that after joining the coalition each individual 
gets a share of the total earnings that is larger or equal to what she would 
get is she played on her own (this condition in called individual rationality), 
while the second is an efficiency or Pareto condition, stating that all the wealth 
obtained by the grand coalition is distributed to the individuals. 
Rationality of a payoff may go beyond the individual level. In particular, an 
allocation is called coalitionally rational if a(C) := ΣίΕθ ai — V(C) f°r every 
coalition C C 21, while it is called collectively rational if a(l) := Y2iecai 
= 
v(I) (this coincides with the Pareto efficiency condition). 
Definition 26 An imputation a = (ai,··· ,aj) (effectively) dominates over 
an imputation & = (&i, - · - , £>/) for the coalition C, denoted by a )~c b, if 
(i) ai > bi for all i € C and 
(ü) T,iecai 
<v(c)-
We will say that an imputation a (effectively) dominates over an imputation 
b if a)^c b for some coalition C. 
Clearly, if it was not for the second condition the above definition would 
not be possible. 
The behavior of the agents, i.e., whether they will join a particular coalition 
or not depends on the form of the characteristic function. 
The following 
definitions are used. 
Definition 27 A game (X,v) is called 
(i) superadditive if v{C\ U C2) > v(Ci) + v{C2) for every C\, C2 C 2 1 such 
that d Π C2 = 0, 
(ii) convex if'w(Ci) + v{C2) < υ((7χ U C2) + v{Ci Π C2) for all Cx, C2 C 21, 
(Hi) monotone if C\ C C2 C 2 1 implies v(C\) < v(C2) (or the opposite 
inequality). 
A game (I, v) is called subadditive if (J, —v) is superadditive, and concave if 
(Ι,—υ) is convex. 
Definition 28 A collection of coalitions {Cfc} is called balanced if there exist 
Xk € [0,1] such that for every i £ I, J2k.ieC 
Xk — 1 (the numbers {Xk} are 
called balancing weights). 
A game (I, v) is called balanced if for every balanced collection of coalitions 
{Ck} with balancing weights {Xk} it holds that 
ΣΧΜΟ^<υ{1). 
k 

442 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
A convex game is superadditive. Superadditivity may be interpreted as 
that the coalition C\ UC2 is worth more in terms of the characteristic function 
than the groups C\ and C2 on their own. Therefore, if v represents gain, it 
is to their mutual benefits for the two coalitions C±, C<i to unite to a larger 
coalition C\ U Ö2- The notion of subadditivity has a similar meaning if the 
characteristic function represents loss. 
Definition 29 Let 3(1, v) be the set of imputations for a game. The core of 
the game is defined as 
ί(Ι,ΐ)):={β€3(Ι,«) : ^ α ; > ^ ) V C c I } . 
iec 
The core is defined in such a way that no coalition can improve upon the 
allocation a to its members.23 Therefore, if we are in the core no member 
is willing to leave the core and join another coalition. An allocation is in 
the core if it is efficient and collectively (coalitionally) rational. It may also 
be seen that the core of a game €(1, v) is the set of all collectively rational 
payoffs. Alternatively, the core for a game is the set of imputations that are 
not dominated for any coalition. 
The core may be empty as the next example illustrates. 
■ EXAMPLE 17.10 
Simple Majority Game 
Assume the simple majority game with 3 players. A coalition is winning 
only if it contains at least two players. In terms of the characteristic 
function this gives v({i}) = 0 for alH € 3 = {1,2,3} and v(C) = 1 if 
card(C) > 2. For this game £(I, v) = 0 as there is no imputation for 
which J2iec ai ^ V(C) VC C J (unless v(I) > §). 
The non-emptyness of the core is guaranteed by the following theorem (see, 
e.g., Ref. [3] or [9]. 
Theorem 20 (Shapley-Bondareva) The core of a cooperative game (I, v) 
is non empty if and only if it is balanced. 
Other types of solutions, more general, and thus easier to exist, are possible. 
The following notion is due to Von Neumann. 
Definition 30 (Stable sets) A stable set 6 ( 1 , u) for a cooperative game 
(I, v) is the set of imputations, such that: 
(i) if a, b € 6 ( 1 , v) then neither a >~ b nor b >- a (internal stability); 
(ii) if c £ &(l,v) 
then there exists a £ &{Ι,υ) 
such that aye 
(external 
stability). 
If 12iec 
ai < "(C) f°r a coalition C then the members of C could improve their payoffs. 

17.7 COOPERATIVE GAMES 
443 
Remark 17.7.1 The following alternative interpretation of the core and the 
stable set are useful: For any X C 3(1, v) define 
D(X) :— {a e 3(1, v) : a >- b for someb G X}. 
A stable set is a set &(l,v) 
such that (i) 6(2", v) (Ί D(&(1, v)) = 0 and (ii) 
G(l,v) 
U D(&(1, v)) = 3(1, v) where these two conditions are the internal 
and external stability conditions, respectively. These two conditions can be 
expressed as one condition &(X,v) = 3(1, v) \ D(&(l,v)), 
which in fact is 
a fixed point condition for the set valued map f(X) = 3(1, v) \ D(X). 
On 
the other hand, the core for a game can be expressed as €(1, v) = 3(1, v) \ 
D(3(l,v)). 
The stable set may not be unique, but typically it is easier for a game to 
have a stable set than a core. It is clear that €(l,v) 
C &(l,v) 
C 
3(1,v). 
This means that the core is contained in every stable set. 
■ EXAMPLE 17.11 
The set &(l,v) 
= {(\, \,Q), (\,Q, \), (0, \, \)} is a stable set for the 
simple majority game with three persons. However, this is not the only 
stable set. For instance, the set {(x\, 1 — x\ — X3,xs)} for any xi,x$ G 
[0, | ) is also a stable set. 
Definition 31 The value of a cooperative game is an operator φ = (φ\ ,·■■ ,φι) : 
S - > R J assigning a payoff to each player in the game for a particular char-
acteristic function v. 
Definition 32 The Shapley value for a game is a mapping φ = (φ\, ■ ■ ■ , φι) : 
2τ -> R1 defined by 
, , , 
ν-^ 
card(C)\(I — card(C) — 1)! , ,_ 
,.,. 
._.. 
φί(υ)= 
Σ 
η 
— 
L(v(Cu{t})-v(C)). 
ceJ\{i} 
Remark 17.7.2 The factor ^d(cy.{i-card(C)-iy. 
hag fl probabiUstic 
inter. 
pretation. card(C)\ is the total number of ways that the set C can be formed 
prior to player's i addition to it. (I — card(C) — 1)! is the number of ways the 
remaining players can be added to C afterwards. I\ is the total number of all 
the orderings of the players. 
Remark 17.7.3 An equivalent definition of the Shapley value is as 
Μ υ ) = 
Σ 
(card(C) - 
1)1(1-card(C)y.{v{c)_v{cx{.})h 
C:i€C 
where now the summation is over all the coalitions containing player i. The 
prefactor \car 1 )~ H ~car ( ))■ / j a s a probabilistic interpretation. 
It is the 

444 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
probability that when i enters she will find the coalition C \ {i} already there. 
The numerator is the number of ways in which the card(C) — 1 members of 
C \ {i} come [i.e., the total number of ways that the coalition C \ {i} first 
forms (card(C) — 1)!/ and this is multiplied in the ways that player i and the 
remaining I — card(C) players enter [there are (I — card(C))\ ways for that]. 
The denominator is the total number of permutations of I players (P.). 
■ EXAMPLE 17.12 
Consider 3 players. Take player 1. All the coalitions not containing 1 are 
{2}, {3}, {2,3}. Assume that player 1 joins them with equal probability. 
The probability of when 1 joins she will find, e.g., {2} already there is 
' ~ Q ~ '' = | . This is because there are 2 coalitions of 1 player (not 
containing player 1) and in a total of 6 and she will join each one with 
equal probability which is | . The probability of 1 when joining finding, 
e.g., {2,3} already there is ( ~ '3j 
'' = g. This is because there is only 
1 coalition of 2 players not containing 1 and the probability of choosing 
that out of 6 possible coalitions is g. 
The Shapley value is a concept of value for a cooperative game that satisfies 
certain axioms which are considered as reasonable modelling assumptions. 
These axioms are (i) symmetry [i.e., symmetric players - players i and j with 
the same marginal contribution v(C U {i}) = v(C U {j}) for all C C I ) are 
assigned the same Shapley value), (ii) dummy players (i.e. players i such that 
v(C U {i}) = v(C) for all C C I] are assigned zero value, (iii) additivity and 
(iv) efficiency, ΣίςΐΦί(ν) 
= V(Z)- Shapley in a seminal paper published in 
1953 has proved that the Shapley value is the unique operator satisfying the 
above properties. 
Theorem 21 If (Χ,υ) is a convex game then φ(υ) G €(X, v). 
■ EXAMPLE 17.13 
Measurement of Voting Power 
Consider the simple majority game with characteristic function υ as 
defined in Example 17.10. To calculate the Shapley value for, e.g., agent 
1 we need to find all coalitions not including agent 1; these are {2}, {3} 
and {2,3}. Then, the Shapley value is obtained as a sum over these 3 
coalitions, 
-M{l,2})-t,({2})) 
-(«({l,3})-t,({3})) 
-(ι;({1,2,3})- ν({2,3}))=|. 
Φι{ν) 
1!(3 
+ 
+ 
1!(3-
2!(3-
3! 
- 1 -
3! 
- 2 -
3! 

17.7 COOPERATIVE GAMES 
445 
A similar calculation shows that φ?.(υ) = φ${ν) = | . That means that 
in this simple majority game every player has exactly the same power. 
This would not be true if for example one of the players had veto power. 
■ EXAMPLE 17.14 
Shapley Value for Dummy and Veto Players 
If a player i is a dummy player, i.e., a player that does influence any 
coalition by joining it will get φί — 0. If a player i is a veto player, i.e., a 
player that must be included in ay winning coalition then such a player 
will obtain a large Shapley value. 
■ EXAMPLE 17.15 
Cost Allocation Games 
Assume that the full cost of a common facility (common good) is to be 
shared between / countries (players). The set of countries is denoted 
by I = {1, · · · , / } . The countries may cooperate and form coalitions 
in order to secure the common good. Let v(C) be the benefit of the 
coalition of countries C. We may assume that this benefit can be ex-
pressed in terms of income and this total income will then be transferred 
to the members of the coalition as some sort of side payment. If Bi is 
the net benefit of country i from exploiting the common facility then 
the charge (participation cost) of i in the common project can be given 
as d — Bi — φί(ν) where φ is the Shapley value. This can be supported 
by the interpretation of the Shapley value as the average (expected) 
marginal benefit of a country i by participating in a coalition assuming 
that coalitions are chosen in random and with equal probability. In other 
words, the Shapley value assigns to a country the expected contribution 
she is to have to a coalition. 
The Shapley value has an interesting interpretation as an expected utility 
function as has been shown by Roth [7]. We need to introduce the following 
concepts first. A position in a game is a pair (i, v) where i is a player and v is 
a game. A player has preferences over mixtures of games (i.e., she may choose 
to play a game with a probability). In other words a player is choosing over 
lotteries in the space of games. The preference relation is assumed to satisfy 
4 axioms: 
(i) Let « b e a game in which i is a dummy player. Then (i,v) ~ (i,vo) 
(where ~ denotes indifference and vo is the null game assigning zero 
value to every coalition). Furthermore, (i,Vi) >- (i,Vo) where Vi is the 
game in which i is a dictator (v(C) = 1 if i g C and v(C) = 0 otherwise). 
(ii) For any game v and permutation π, {ί,ν) = (π(ί),π(ν)) 
(symmetry). 

446 
CHAPTER 17. DECISION THEORY AND GAME THEORY 
(iii) (i, (pw+(l—p)v)) 
~ \p(i, w); (1— p)(i,v)} where the second term denotes 
the lottery where (i, w) occurs with probability p and (i, v) occurs with 
probability 1 — 0. 
(iv) (I,VR) ~ (i, (l/r)vi) 
where VR is defined by VR(C) = 1 if C C R and 0 
otherwise24. 
We then have the following: 
Theorem 22 // u is an expected utility function over positions in games sat-
isfying the above 4 axioms and normalized so that u(i, Vi) = 1 and u(i, vo) = 0 
then u(i,v) = φί(ν) where φ is the Shapley value. 
17.8 
CONCLUSION 
In this short introduction we have tried to initiate the student to the funda-
mental notions of game theory and how it may be applied to understand and 
model phenomena in the social sciences. 
Our presentation provided a glimpse of the major aspects in the field, 
trying to balance mathematics with social science, and of course has had to 
omit many interesting and exiting aspects of game theory. However, it is our 
hope that this short introduction will provide an incentive to some of the 
students reading this book to study this field into more detail. 
Acknowledgments 
The authors wish to thank Professor Nicholas Yannacopoulos for his con-
structive comments and enjoyable conversations that maximized their utility 
(in the Benthamian use of the concept). Furthermore, they acknowledge the 
useful comments of the three referees that led to a considerable improvement 
of the chapter. Last (but not least!) they also wish to thank Dr. Yang 
for putting this effort together and offering them the tribune from which to 
present this first introduction to this exciting subject. 
EXERCISES 
17.1 
Work out the conservative strategies for the examples of the matrix 
games presented in this chapter and show that they coincide with the Nash 
equilibria. 
17.2 
Write down the characteristic function for a voting game with a veto 
player and work out the Shapley value for a simple example (3 or 4 voters). 
24Ufl can be interpreted as a unanimity game (recall that Vi is a game in which i is a 
dictator). 

EXERCISES 
447 
17.3 
Let I be a set of agents each one with utility itj. Suppose that utilities 
are transferable. Show that a possibility in defining a characteristic function 
for this game is by 
v(C) = m i n m a x y ^ U j ( s c , s i \ c ) · 
s^c sc l£ 
REFERENCES 
1. Aubin, J. P., Optima and Equilibria: An Introduction to Nonlinear 
Analysis, 
Springer, Berlin (1993). 
2. Berge, C , Topological Spaces: Including a Treatment of Multi-Valued 
Functions, 
Vector Spaces and Convexity, Dover (2010). 
3. Bondareva, O. N., Some applications of linear programming methods to the 
theory of cooperative games (In Russian). Problemy Kybernetiki, 10: 119-139 
(1963). 
4. McCarty, N. M. and Meirowitz, A., Political Game Theory: An 
Introduction, 
Cambridge University Press, Cambridge (2007). 
5. Nikaidö, H., On von Neumann's minimax theorem, Pacific J. Math., 4:65-72 
(1954). 
6. Peleg, B. and Sudhölter, P., Introduction to the Theory of Cooperative Games, 
2nd Ed., Springer, Heidelberg (2003). 
7. Roth, A. E., The Shapley value as a von Neumann-Morgenstern utility, Econo-
metrica, 45:657-664 (1977). 
8. Osborne, M. J. and Rubinstein, A., A Course in Game Theory, The MIT Press 
(1994). 
9. Shapley, L. S., On balanced sets and cores. Naval Research Logistics Quarterly, 
14:453-460 (1967). 

CHAPTER 18 
CONTROL PROBLEMS ON 
DIFFERENTIAL EQUATIONS 
CHUANG ZHENG 
School of Mathematical Science, Beijing Normal University, China 
18.1 
INTRODUCTION 
Control theory is an interdisciplinary branch of engineering and mathematics 
that deals with the behavior of dynamical systems. It is originated and has 
been strongly inspired by industrial applications such as airplanes, chemical 
plants, space vehicles and so on (see, for instance, [7], [19]). Control theory 
addresses a variety of different problems. The usual objective of control is to 
calculate solutions for the proper corrective action from the controller that 
results in system stability, that is, the system will hold the set point and 
not oscillate around it. One simple example is a car's cruise control, which 
is a device designed to maintain vehicle speed at a constant desired speed 
provided by the driver. However, not every system can be controlled. In 
addition to knowing the way to design controls, it is necessary to understand 
Mathematical Modeling with Multidisciplinary Applications.
 
449 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 

450 CHAPTER 18. CONTROL PROBLEMS ON DEs 
the inner property of the system. Hence, one natural and significant concept is 
that of controllability. It can be formulated, roughly, as follows. Consider an 
evolution system [either described in terms of Ordinary or Partial Differential 
Equations (ODE/PDE)]. We are allowed to act on the trajectories of the 
system by means of a suitable control (the right-hand side of the system, 
the boundary conditions, etc.). Then, for a given time interval t € (0, T) and 
initial and final states, we have to find a control such that the solution matches 
both the initial state at time t = 0 and the final one at time t = T. To do 
that, we need to know whether there exists such a control. If the control does 
exist, the system is controllable. There is a large literature on these topics. 
The foundations of finite-dimensional control theory were established by R. E. 
Kaiman [8,9] and since then, the theory has been greatly generalized, first to 
linear and nonlinear infinite dimensional systems and to stochastic systems, 
etc. (see Refs. [4,6,11-13,15,16] and the references therein). We refer, for 
instance, to the book by Lee and Marcus [10] for an introduction to those 
problems in the context of finite-dimensional systems. We also refer to the 
survey paper by Russell [15] and to the book of Lions [11] (also to his survey 
paper [12]) for an introduction to the controllability of PDEs, and to more 
recent works [14], [18], [17] and [20]. 
In 1988, Lions [12] introduced the so-called Hubert Uniqueness Method 
(shorted as HUM). Roughly speaking, it is based on the principle that, when-
ever a system is controllable, the control can be built by minimizing a suitable 
quadratic functional defined on the class of solutions of the adjoint system. 
Suitable variants of this functional allow building controls of minimal L2-
norm, bang-bang controls, approximate controls, etc. The details will be 
shown in Section 18.3.3. The main difficulty when minimizing these function-
als is to show that they are coercive. This turns out to be equivalent to the 
so-called observability property for the adjoint equation, which provides global 
estimates on the adjoint state everywhere in terms of partial measurements. 
There are many journal papers and books studying control problems of 
differential equations. Due to limited space, in this chapter we address only 
some basic topics related to the controllability of ODEs/PDEs. Section 18.2 
could be seen as an introduction to control problems in the context of finite 
dimensional systems (ODEs). We first establish an example of modeling an 
RLC series circuit with the electric current as the controller. Then we give 
a mathematical definition of controllability and show the Kaiman condition, 
which is a criteria for determining whether the system is controllable or not. 
In Section 18.3, we show another example of modeling a vibration system and 
show the corresponding control problem in the context of infinite dimensional 
systems (PDEs). We reestablish the controllability conceptions and show the 
equivalence between the controllability of the controlled system and the ob-
servability of its adjoint system. Hence, the controllability problem can be 
transferred to a problem whether the solutions of its adjoint system satisfy 
some kind of inequalities, which is easy to deal with in the mathematical point 
of view. Although the definitions are similar, we emphasize that finite dimen-

18.2 ORDINARY DIFFERENTIAL EQUATIONS 
451 
sional and infinite dimensional systems may have quite different properties 
from a control theoretical point of view. Interested readers can see the recent 
survey paper [19] and references therein for more details. 
18.2 
ORDINARY DIFFERENTIAL EQUATIONS 
In the latter 18th century, the steam engine led to the Industrial Revolution 
and at its core was the centrifugal governor, which was designed by James 
Watt in 1788. The centrifugal governor is an automatic control device to 
maintain the normal operation of the steam engine: As the speed of the prime 
mover increases/decreases, it drives some kind of mechanical device such that 
the speed of the prime mover decreases/increases by reducing/improving the 
rate of the working-fluid entering the steam engine. Hence, the centrifugal 
governor finishes the control of maintaining the speed of the steam engine. 
However, intuitive physical phenomena is not sufficient to study and ana-
lyze the control system and its dynamical characteristic. Mathematical mod-
eling is necessary to describe the control system quantitatively. In general, 
instead of considering the mathematical modeling as a part of the control 
theory, people prefer to it as a part of other scientific subjects. Therefore, 
most of the materials we contribute in this section can be found elsewhere. 
We emphasize that unlike the normal mathematical modeling process, the 
control device is designed by the designer. Hence, the corresponding mathe-
matical description of the control device can be designed even with the same 
physical model. This is the key point the readers have to keep in mind when 
reading this part: read every material from the control point of view. 
18.2.1 
Model Formulation 
We first show an example of a controller on RLC series circuit. The an RLC 
series circuit is an electrical circuit consisting of a resistor R, an inductor L, 
and a capacitor C, connected in series. In this circuit, the three components 
are all in series with the voltage source. The governing differential equation 
can be found by substituting into Kirchhoff's voltage law (KVL), the consti-
tutive equation for each of the three elements. From KVL, we have 
with 
±J 
i(T)dr = ec(t). 
(18.2) 
Now we consider this RLC circuit as a system with input function ej(f) and 

452 CHAPTER 18. CONTROL PROBLEMS ON DEs 
e.(t) 
-/\A/V 
' W -
R 
L 
ecft) 
Figure 18.1 RLC series circuit with controller ei(t). 
output ec{t). Setting 
u(t)=ei(t), 
y(t) = ec(t), 
xx(t) = l 
i(r)dr, 
x2{t)=i{t), 
J — OO 
system (18.1) and (18.2) corresponds to the following controlled system 
dx\(t) 
dt 
dX2(t) 
dt 
with the observer 
z 2(i), 
= ~Tc^(t) 
1 
-x2{t) + -u{t), 
y(t) = 
-Xl(t). 
(18.3) 
(18.4) 
We can determine the charge and the current x\{t) and x2{t) during the 
time variation, once we give the input voltage u(t), the charge and the current 
at io; i-e., xi(to) and £2(io)· We say xi(t) and X2{t) are states of the system 
(18.3). Moreover, Eq. (18.3) is the state equation of the RLC system. (18.4) is 
the corresponding observation equation, which shows the relationship between 
the input function and the state. 
We now rewrite system (18.3) and (18.4) by means of vectors. Denote by 
x(t) 
Xl(t) 
32 (t) 

18.2 ORDINARY DIFFERENTIAL EQUATIONS 
453 
System (18.3) and (18.4) can be written by 
dx(t) 
dt 
0 
1 
LC 
1 
R 
L 
x(i) 
0 
1 
I 
*(*). 
(18.5) 
y(t) 
c 
respectively. 
On the other hand, if we choose x\{t) = i(t),X2(t) — ec(t) as the states of 
the RLC series circuit, instead of J_ 
i(r)dr and i(t), the state equation of 
the system could be written by 
efoc(i) 
dt 
E 
L 
TT 
0 
x(i) 
1 1 
I 
0 
u(t), 
(18.6) 
with the observation equation 
y(t) = [0 
l]x. 
The example shows that the state equations can be different even though they 
describe the same dynamical system, due to the choices of the state variables. 
In other words, even though the state equation is not unique, the relationship 
between the control and the output is eternal for the same controlled system, 
no matter what kind of state variable is chosen. 
In general, suppose that the controlled system has m inputs u\, U2, ■ ■ ■ , um, 
I outputs 2/i,i/2; ·· · iVi a nd n variables x\,X2,· ·· ,xn- Denote by 
U : 
/ 
«1 
\ 
u2 
\ Um J 
ίνι \ 
2/2 
V» J 
/ * 1 
\ 
X2 
\ Xn 
) 
the system can be formulated as follows: 
dx(t) 
dt 
= f(x(t),t,u(t)), 
where each component of f could be a nonlinear function. The observation 
equation has the form 
y(t) = g(x(t),f,u(t)). 

454 CHAPTER 18. CONTROL PROBLEMS ON DEs 
In control theory, nowadays the most well developed controlled system has 
the form 
Γ *& 
= 
A(tMt)+B(t)u(t), 
dt 
(18.7) 
I y(t) 
= 
C(t)x(t)+£>(t)u(t), 
where A(t),B(t),C(t) 
and D(t) are n x n,n x m,l x n and / x m matrices, 
respectively. System (18.7) is the so-called linear system. 
From the above discussion we find out that if even most of the specific 
control systems are nonlinear, they can be described by linear systems (or 
linear constant-coefficient systems). In this chapter, we will introduce some 
basic tools of ordinary differential equations to develop the controllability 
property of the corresponding control systems. 
18.2.2 
Controllability 
As we mentioned before, the state equation of the system can be represented 
as first-order linear ordinary differential equations. In the simplified case when 
A and B are invariant matrices, the nonhomogeneous equation is given by 
d x ( i ) 
- 
,4x(t)+Bu(t),te(to,ti), 
Xo-
In (18.8), A is a real n x n matrix, B is a real n x m matrix and xo a 
vector in 1R™. The function x : [ίο,οο) —> R n represents the state and 
u : [to, oo) —> fftm represents the control. Both are vector functions of n and 
m components, respectively, depending exclusively on time t. Obviously, in 
practice m <n. The most desirable goal is, of course, controlling the system 
by means of a minimum number of m controls. 
To start with, we first give the definition of eAt, which is defined by the 
Series Expansion method: 
At 
r 
. 
AH2 
AH3 
Antn 
„ o r i , 
eAt = I + M+ —
+ — 
+ ... + —
+ 
. · . . 
(18.9) 
Here we omit the proof of the convergence of the right-hand side of (18.9) and 
assume that A is a constant nxn 
matrix. 
Most of the properties of eAt are the same as eat with a constant a. We will 
not enter in all of the details since they can be found in any classical textbook 
of ordinary differential equations (for instance, Ref. [1]). 
The algorithm of computing eAt is given as follows: 
1. Obviously, it is necessary to find the series A2, A3, · · ·. We apply the 
method to transform A to a Jordan normal form: 

18.2 ORDINARY DIFFERENTIAL EQUATIONS 
455 
Let P be a normal matrix. From the definition of eAt, the following 
equality holds (see Exercise 1): 
p-1eAtP 
= 
ep~lAPt. 
Applying the above property, we compute eAt as follows. 
Step 1 Choose an appropriate P such that A turns to be a Jordan 
normal form, i.e., 
/ Ji 
P~XAP = J = 
with 
Ji 
( \ 
1 
0 
Xi 
0 
0 
\ 0 
0 
0 
o \ 
0 
1 
Jq ) 
1,2,-
Step 2 The matrix Jt has the form 
Q2 
V 
0 
Qq ) 
with 
/ eXit 
teXit 
Qi = 
(ii-l>! 
„Ait \ 
»Ait 
t' i - 2
 
rA,t 
(ii-2)! e 
=Ait 
, i = 1,2, ··· ,q. 
I 
\ 
0 
0 
··· 
Step 3 Implement the matrix eAt with the formula eAt = 
PeJtP~1. 
Characterized by the variation of constants formula, the solution of system 
(18.8) has the form 
x(i) = e A ( t- t o )x 0 + / e(*-T)Aßu(r)dr, 
(18.10) 
•/to 

456 CHAPTER 18. CONTROL PROBLEMS ON DEs 
where eAt represents a matrix of an exponential function. The exact form of 
the solution and the way to compute it can be found in the exercises of this 
chapter. 
In this section, we are interested in the exact controllability of system 
(18.8), which is stated as follows: Let xo and xi be two given points in R" 
and ii > io, so is there a function u(x, t), such that the solution of system 
(18.8) satisfies x(to) = xo a nd x(^i) = xi ? If such a control u exists, we say 
that the system is exactly controllable from xo to xi at time t\ by the control 
u. 
In controlled system (18.8), A represents the inherent structure of the phys-
ical phenomena and B is designed by a human being. As we mentioned before, 
in applications it is desirable to make the number of controls m to be as small 
as possible. We hope it can be done by setting an appropriate control mech-
anism B. Later, we will show an example in which n components of the state 
can be controlled with one control only. However, in order to achieve this 
goal, B needs to be chosen in a strategic way depending on the matrix A. 
Let us look at two examples. The first one is the previous model we estab-
lished for the RLC circuit. Both components will be controlled by means of 
a scalar control. In the second one controllability does not hold since one of 
the components of the system is insensitive to the control. 
■ EXAMPLE 18.1 
In system (18.5), we set the parameters R = 0 and L = C = 1, and then 
it can be written as 
^ - = Ax(t) + Bu(t), 
(18.11) 
at 
where the matrices are now, respectively, 
A=[ 
° 
I V 
B 
' ° 
or, equivalently, 
- 1 0 / ' 
V I 
h 
= 
X2, 
j 
= 
—Xi + U. 
(18.12) 
Here we only have one control u for both components X\ and χ^. In other 
words, we hope to control the charge and the current during the time 
variation with the input voltage. On one hand, the input voltage u does 
not appear directly in the first equation of (18.12), which seems to be 
bad for controlling X\. On the other hand, both components are present 
in the second equation with the control, which is desirable. Therefore we 
cannot conclude immediately whether system (18.12) is controllable or 
not. Fortunately, the answer is positive. Indeed, given some arbitrary 

18.2 ORDINARY DIFFERENTIAL EQUATIONS 
457 
initial and final data, (χ^,χ^) and {x\,x\), 
respectively, it is easy to 
choose a cubic polynomial function z = z(t) such that 
j z{t0) =x°, 
z(h) = x\, 
{ z'(t0) = x°2, 
z'(h) = x\. 
We can then define u = z" + z as being the control. 
EXAMPLE 18.2 
In system (18.11), we now directly set 
(18.13) 
where a, b, c are constants. Obviously the solution has the form 
(18.14) 
( 
/"' 
Xl 
= 
β»(ί-*ο)χο + c 
e
a(t-s)w(s)(is, 
< 
Jta 
{ x2 = 
xleb^~s\ 
where x(to) = (χι,χ®) are the initial data at t = to-
The system is not controllable since the control u does not act on the 
second component x2 and it is completely determined by the initial data 
x\. Hence the system is not controllable. 
18.2.3 
Kalman's Rank Condition 
In this section, we will show the classical Kalman's rank condition, which 
completely solves the controllability problem of finite dimensional linear sys-
tems. The theorem shows a simple fact: the system is exactly controllable if 
and only if some kind of matrix deduced by the system (P here) is of full rank. 
In other words, the Kalman's rank condition gives us a criteria to determine 
whether the system is controllable or not. The proof is theoretical and tech-
nical, and readers who are not interested in this could skip this part and go 
to the theorem directly. Anyway, to understand the proof, readers only need 
linear algebra and a little patience. 
Theorem 23 (Kalman's rank condition) System (18.8) is exactly con-
trollable in some time t\ if and only if the rank of the matrix 
P = [B,AB,··- 
,An~lB] 

458 CHAPTER 18. CONTROL PROBLEMS ON DEs 
is n. Consequently, if system (18.8) is exactly controllable in some time t\, it 
is exactly controllable in any time. 
To prove the above theorem, we need the following lemma: 
Lemma 18.2.1 Suppose K(t),u(t) 
are n x r matrix and r-dimensional vec-
tor, respectively. Each element of them is a continuous function on the inter-
val [ti,t2]· Then for any n-dimensional vector a, the following two assertions 
are equivalent: 
There exists a u(i) such that I 
K(t)u(t)dt 
Jto 
a; 
• x = 0 is the only n-dimensional vector such that xTK(t) 
= 0,V t € 
[tiM-
Proof: 
We first state that xTK(t) 
= 0,V t 6 [£i,t2] is equivalent to that 
/•ti 
' / 
K{t)u(t)dt 
= 0 holds for all u(i). 
Jto 
In fact, if xTK(t) 
= 0, obviously 
x T / ' K(t)u{t)dt 
= I 
xTK(t)u(t)dt 
= 0. 
Λο 
Jto 
Conversely, if x T / 
K(t)u(t)dt 
= 0 holds for all u(i), we take u(f) = 
Jt0 
KT(t)x, 
then we have / 
||.ii(f)||2c£i = 0. Based on the property of the 
Jt0 
integration, we directly deduce xTK(t) 
= 0,Vi € [ii,t2]· 
Now we prove the lemma with the above statement. 
Suppose for any 
i-il 
n-dimensional vector a, there exists a u(f) such that / 
K(t)u(t)dt 
= a. 
Jt0 
Especially, by choosing a as 
ai 
/ 
1 \ 
0 
w 
a2 
/ 0 \ 
1 
\ o / 
• , ai = 
0 
V i / 
we obtain the corresponding u as ui(f), 112(f), · · · , u„(f), such that 
/ 
K(t)ui(t)dt 
= &i, 
Jt0 
i = 1,2, · · · ,n. 

18.2 ORDINARY DIFFERENTIAL EQUATIONS 
459 
If xTK{t) 
= 0, V £ € [ti, t2], then x T f£ K{t)u(t)dt 
= 0 holds for all u(i). By 
taking u as ui(£), 112(£),·· · , u„(i) into account we obtain 
Jt0 
x 
/ 
K(t)ui(t)dt 
— x &i = Xi = 0, 
i = l,2, •••,η, 
/to 
where Xi is the ith component of the vector x. Hence, x = 0. 
Now we suppose x = 0 is the only solution of xTK(t) 
= 0, V £ € [£1, £2]. We 
want to prove: for any n-dimensional vector a, there exists a u(£) such that 
/ 
K(t)u(t)dt 
= a. 
(18.15) 
•/to 
Let 
f*
1 
S = { I 
K(t)u(i)dt: 
u(t) is continuous on [£i,£2]}· 
•/to 
'to 
Obviously S is a linear space and the maximum of its dimension is n. 
It is sufficient to prove that S is a n-dimensional space. In fact, if dim5 = 
n, then a belongs to S and there exists a u(£) such that (18.15) holds. 
We assume that the dimension of S is less than n. There must exist a 
x φ 0 such that 
/•t 
I 
K{t)u(t)dt 
= 0 
Jtn 
X 
'to 
„T 
holds for all u(£). Consequently, x K(t) = 0,V £ € [£i,£2]· However, it is a 
contradiction that x = 0 is the only solution. 
Proof of Theorem 23. The solution of (18.8) is given by 
x(i) = βΛ<*-*ο)χο + f 
e{t-^AB\i{r)dT. 
•/to 
System (18.8) is exactly controllable if and only if there exists a u(·) such that 
eA( t l-t 0) X o + I 
e
{tl-T)ABvL{T)dT 
= 
Xl, 
Jto 
or, equivalently, 
ftl 
- a * + e-A{tl'to)
Xl 
= / 
e-{t-to)ABu(t)dt. 
Jto 
From Lemma 18.2.1, system (18.8) is exactly controllable if and only if x = 0 
is the only solution of xTe~AtB 
= 0, V£ € [0, £1 - £0]. 
Now we show that xTe~AtB 
= 0 is equivalent to xTAmB 
= 0 for all 
m = 0,1, · · · , n - 1. Indeed, let £ = 0 in x.Te~AtB 
= 0 we have x T B = 0. 

460 CHAPTER 18. CONTROL PROBLEMS ON DEs 
Since f(t) = -x.Te~AtB = 0 on the interval [0, ii -1 0]. Consequently f'(t) = 0 
at t = 0 which leads to xTAB 
= 0. Step by step we have xTAmB 
= 0 for all 
m = 0,1, · · · ,ra—l. Conversely, if xTAmB 
= 0 holds, by the Cayley-Hamilton 
Theorem it is true for any m e 1R. It means 
xTe-AtB 
= Y (-l)m—*TAmB 
= 0. 
m=0 
Finally, since x = 0 is the only solution of xTAmB 
= 0, it is equivalent to the 
rank of the matrix 
[Β,ΑΒ,··· 
,An~1B] 
is n. 
18.3 
PARTIAL DIFFERENTIAL EQUATIONS 
18.3.1 
Model Formulation 
In this section we will formulate a physical control model for a vibrating string. 
More precisely, consider a string staying on its position of equilibrium. Some 
small vibrations lead the displacements of some articles. The internal tension 
will cause the displacements of the neighborhoods of these articles and finally 
will lead to a wave movement of the whole string. We hope the string can 
move to any exact prespecified position by adding an external force on the 
string. 
We first make some reasonable assumptions: The string is thin and can 
be seen as a line with a constant linear mass. The string is soft and stretchy 
and the tension satisfies Hooke's law (strain is directly proportional to stress) 
while bending. The movement of the string proceeds on a flat surface and 
the displacement of each particle is perpendicular to the equilibrium position. 
Moreover, all displacements are small. 
Set the x-axis as the direction of the equilibrium position, and the j/-axis 
as the direction of the displacement of the articles (see Figure 18.3.1). The 
unknown function y = y(t, x) is the displacement of the particle at position x 
in time t. The external force density u(t, x) describes the force acting on each 
unit length of a;, p is the density of the string and is a constant. 
We apply the Micro-element analysis. Choose any small particle [a;, x + dx] 
where dx represents an infinitesimal variable. Obviously it has the quality 
pdx and obeys Newton's second law 
F = ma. 
The force of the particle has the tension on the left endpoint —T(£, a:), the 
tension on the right endpoint T(i, x+dx) and the external force on the particle 
perpendicular to x-axis G(t,x;dx). 
Let T(t,x) 
be differentiable with respect 

18.3 PARTIAL DIFFERENTIAL EQUATIONS 
461 
A i 
-T(t,x) 
A G(M;dx) 
T(t, x+dx) 
X 
O 
x+dx 
Figure 18.2 
Vibrating string. 
to x. The Newton's second law can be specifically represented as 
d2v 
pdx-^jy° 
= 
-T(t,x) 
+ T(t,x + dx) + 
G(t,x;dx) 
<9T 
= 
-7— dx + g(t, x)dxu°, 
ox 
where the higher-order infinitesimal is omitted in the second equality. Denote 
by (ΤΊ, Τ2) where 7\ and T<i are components on the x° and y° directions. The 
previous quality comes to be 
ÖT1 
0, 
dx 
d2y 
ÖT2 
PW = ^x- + 
u{t'x)-
(18.16) 
(18.17) 
Moreover, since the tension T acts on the tangential direction of the string, 
we have the third equation 
Τ2 = Ά 
dy_ 
dx 
Taking (18.18) into (18.16) and (18.17), it holds 
d2y 
. ,d2y 
pW 
= 
Tl{t)dx^+u{t>x)· 
(18.18) 
(18.19) 

462 
CHAPTER 18. CONTROL PROBLEMS ON DEs 
Under the assumption that the displacements are small, we have 
and the magnitude of the force equals 
dy 
dx 
« 1 , 
r=^i? + i? = r1^+(^y«r1. 
The length of the particle equals 
ds = y/dx2 + dy2 = dxJl + ί^λ 
2 
dx. 
Hence, during the dynamical process, the length of the particle remains con-
stant. Due to Hooke's law, the magnitude of the force T « ΤΊ remains con-
stant when time changes. Consequently (18.19) comes to be 
S
= e aSv
( t'
x )'
 
α=/Ι·
 
(18·
20) 
System (18.20) is the string's vibrating equation. The coefficient a describes 
the velocity of the wave depending on the string itself. The control u(t, x)/p 
is the force acting on the string. 
We now first establish the well-posedness of (18.20), i.e., the existence and 
uniqueness of the solution, under some suitable initial data and boundary 
conditions. 
Initial data For a physical process starting at time t = 0 and evolving 
over time interval t £ [0, T], the status at t = 0 will affect the movement when 
time evolves. In our case, two statuses of the string will be taken into account: 
dy 
Initial displacement y(0,x) = yo(x)', initial velocity — (t,x) |t=o = yi(x). 
Mathematically speaking, the initial conditions are the values of y(t, x) and 
its partial derivatives with respect to t at time t = to. In general, if m is the 
highest order of y(t, x) with respect to t, the initial data should be given as 
dy 
dm-ly 
y' dt 
dtm~x 
Boundary conditions In the string vibration problem, let the string lo-
cate in the interval [a,b\. There are several kinds of boundary conditions such 
as the Dirichlet boundary condition, Neumann boundary condition, mixed 
boundary condition, etc. Here we will consider the simplest Dirichlet case in 
which the movement of the boundary points satisfies 
y(t,x)\x=a = y(t,x)\x=b = o. 

18.3 PARTIAL DIFFERENTIAL EQUATIONS 
463 
Equation (18.20) is deduced from the vibration process and is called as 
the simplest one-dimensional wave equation. Its importance lies in the fact 
that not only does it arise in fields like acoustics, electromagnetics, and fluid 
dynamics but also because it is the basic hyperbolic partial differential equa-
tion for the description of waves—as they occur in physics—such as sound 
waves, light waves and water waves. In the sequel, we will introduce the 
well-posedness of (18.20) under suitable initial data and boundary conditions. 
Moreover, we will establish the controllability conception and describe some 
properties. As we shall see in the following section, the main properties of 
the hyperbolic equations such as time-reversibility and the lack of regularizing 
effects have some very important consequences in control problems too. 
18.3.2 
Controllability 
Let a; be a nonempty subset of the interval Ω = (0,1). 1ω is the characteristic 
function of ω. We consider the nonhomogeneous controlled wave equation: 
( d2v 
d2v 
~d"0 
= Ul"' 
(ί,χ)€(0,Τ)χΩ, 
y(t,0) = y(t, 1) = 0, 
t e ( 0 , T ) , 
(18.21) 
dy 
2/(0, a;) = 2/o, ^-(0, a;) = yi, 
x G Ω. 
In (18.21) y = y(t,x) 
is the state and u = u(t,x) the control. Since u is 
multiplied by 1ω the action of the control is restricted on the ω. Our aim is 
to change the dynamics of the system in the whole domain by means of the 
control u. 
Since system (18.21) is a system with a partial differential equation, some 
notations and basic properties are necessary. We put them here, and more 
details can be found in [5]. 
Denote by U = (0, T) x Ω. We have 
Definitions. Let u : U —> R, (t,x) £ U. 
... 3ti, 
. 
,. 
u(t + h, x) — u(t, x) 
. , , , . , . . 
Ill —(t,x) 
= hm 
- 
, provided this limit exists. 
at 
h-*o 
h 
,.., du, 
u(t,x + h) —u(t,x) 
. , , , . , . . 
[nj — (t, x) = hm 
, provided this limit exists. 
ox 
h—»o 
h 
[iii] Ck(Q) = {u : Ω —> R | u is fc-times continuously differentiable}. 
[iv] Χ>(Ω) = (7°°(Ω) = {u : Ω -» R | u is infinitely differentiable} = 

464 CHAPTER 18. CONTROL PROBLEMS ON DEs 
[v] L (U) = {u : U —> Ft is Lebesgue measurable and 
I M I ^ m < oo}, 
where 
1/2 
llullz,2(t/) = ( / 
M2dxdt 
[v] HQ(CI) = {u : Ω —* R is Lebesgue measurable and u e L 2(0),u x e 
L2(fi),u|x=o,i = 0}, where 
li/i(n)= ( / 
\u\2dx+ 
I 
\ux\2dx\ 
1/2 
The following theorem is a consequence of the classical results of existence 
and uniqueness of solutions of nonhomogeneous evolution equations. All the 
details may be found, for instance, in [3]. 
Theorem 24 For any u € L2((0,T) χ ω) and (y0,2/i) € Η&(Ω) χ L2(Q) 
equation (18.21) has a unique finite energy solution: 
yeC([0,T];Jff0
1(n))nC1([0,T];L2(Q)). 
For any initial data (yo, J/i) € HQ (Ω) χ £2(Ω), the set of reachable states 
R(T; (y0, yi)) = {(y(T), ^ ( T ) ) : y solution of (18.21) 
w i t h u e L 2 ( ( 0 , r ) χω)}. 
Remark that, for any (yo,yi) € Η$(Ω) χ ί/2(Ω), R(T; (yo,yi)) is an affine 
subspace of Η$(Ω) x L2(0) when the control u varies all over L2((0,T) 
x Ω). 
However the action of the control is localized in u>. Thus the controls may be 
viewed to belong to L2((0,T) 
χ ώ). 
The problem of controllability consists in describing the set of reachable 
states. There are different notions of controllability that need to be distin-
guished: 
(A) Approximate controllability. System (18.21) is said to be approximately 
controllable in time T if the set of reachable states is dense in ί?ο(Ω) χ 
L2(Q) for every (y0,2/i) e ^ ( Ω ) x Ζ,2(Ω). 
(B) Exact controllability. System (18.21) is said to be exactly controllable 
in time T if the set of reachable states equal to HQ (Ω) χ £2(Ω) for every 
(2/ο,2/ι)£ίί0
1(Ω)χ^2(Ω). 
(C) Null controllability. System (18.21) is said to be null controllable in time 
T if the set of (0,0) e R(T; (y0,yi)) for every (y0,2/i) G ί#(Ω) χ £2(Ω). 
Some remarks are in order. 

18.3 PARTIAL DIFFERENTIAL EQUATIONS 
465 
• The definition of the exact controllability is equal to the one in Section 
18.2.2. In fact, the above three definitions are all equivalent for the 
finite-dimensional system (18.8). 
• A very important property of the wave equation is the so-called finite 
speed of the propagation. Roughly speaking, the influence of the vibra-
tion from the left point x = 0 will require some time duration passing 
to the right side x = l(for instance, sound propagation from one point 
to another). Due to the finite speed of propagation of solutions of the 
wave equation, for any of these properties to hold, the control time T has 
to be sufficiently large, except for the trivial case in which the control 
subdomain ω coincides with the whole interval Ω. 
• The null and exact controllability are equivalent notions due to another 
crucial property, time reversibility. More precisely, if we expect to trans-
fer the state from A (yo,yi) at ί = 0 to the state B (y£,yf) 
at ί = Γ, 
we have the following methodology: we first solve system (18.21) back-
wards in time with the initial data given by (y(T),yt(T)) 
= 
(y£,yf) 
without control u. The corresponding solution at time t = 0 is denoted 
by C and is provided by the time reversible of the system. Moreover, 
since system (18.21) is linear, it obvious that transferring A to B is 
equivalent to transferring A—C to (0,0). 
• Null controllability is a commonly used notion since the state (0,0) is an 
equilibrium for system (18.21). Once the system reaches the equilibrium 
at time t = T by a control u, we can stop controlling and the system 
naturally stays in the equilibrium for all t > T. It also means, once the 
control exists, there are infinite ways to construct more controls. 
18.3.3 
Adjoint System and Observability 
In this section we transform the exact controllability property of system 
(18.21) to another equivalent condition which is the exact observable of its 
dual system. 
We denote by Η~1(Ω) the dual space to Η$(Ω). In other words, / belongs 
to H~1(Q) provided / is a bounded linear functional on Η$ (Ω). We write ( ,) 
to denote the pairing between H~1{Q) and HQ{Q). We define the norm 
U/Hjj-i(n) =sup{(/,u) |«€Αο(Ω)>ΝΙ»ΐ(η)<ι}· 
Assume / e H~1(Ci). Then there exist functions / ° , f1 in L2(0) such that 
(/»«) = / ( A + fvx)dx 
(v e Ht(tt)). 
(18.22) 

466 CHAPTER 18. CONTROL PROBLEMS ON DEs 
Furthermore, 
||/||„_ 1 ( Ω ) = inf { ( ^ ( l / ° l 2 + l / 1 ! 2 ) ^ ) 1 
I /satisfies (18.22) 1 
for / ° , Z1 e L2(fi). The existence of the functions can be found on p. 284 of 
Ref. [5] as the characterization of if - 1 . 
For (φ$, φ[) € L2(fl) x H~1(fi), 
consider the following backward homoge-
nous equation: 
f ^ - ^ = ° ' 
(*,*)€ (0,Τ)χΩ, 
φ(ί,0) = φ(ί,1) = 0, 
t e ( 0 , T ) , 
(18.23) 
T 
^Ψ ίτ· 
\ 
T 
ψ(Τ,χ)=φΙ
0, 
-^(Τ,χ)=φΙ, 
x€Ü. 
Let (φ, §f) e <7([0,Τ];£2(Ω) x H'1^)) 
be the solution of (18.23). We have 
the following lemma. 
Lemma 18.3.1 The following assertions are equivalent: 
• System (18.21) can be driven from (yo,yi) e ΗΓ)(Ω.) χ Ι?(Ώ) at t = 0 to 
the rest (0,0) at t = T. 
• For all (φξ, φ[) G £2(Ω) χ # _ 1(Ω), there exists u e L2((0, T) x ω) such 
that 
j 
J tpudxdt=(ijg{0),y0)_ii- 
J <p(0)vidx, 
(18.24) 
where φ(ί) is the corresponding solution of (18.23) with initial data 
Proof: We will first prove the assertions are equivalent under the assumption 
that all functions involved are smooth. Then by a density argument we finish 
the proof. 
We suppose that (2/0,2/1), {ψο,ψΐ) 
G Ρ(Ω) x £>(Ω), u e Ζ>((0,Τ) χ ω) and 
let 2/ and ψ be the solutions of (18.21) and (18.23), respectively. Multiply the 
equation of y by φ, integrate on (0, Γ), and we obtain 
Γϋ*(£-£)=Π-**
 
(18·
25> 

18.3 PARTIAL DIFFERENTIAL EQUATIONS 
467 
Integrating by parts the left hand-side of (18.25) equals 
LHS of U8,5> . I ( * | - £ , ) * |f + £1 ,(g - 
g)«, 
Hence, 
y y ^ M = y (W|!eo - ψΐυ^άχ - j (φ^ - ^(o)yoyx. 
(18.26) 
From a density argument we deduce, by passing to the limit in (18.26), it 
holds 
f 
ίφηάχάί= 
f 
<pS?g(T)dx-(<pf,y{T))-i,i 
Jo Λ, 
Ju 
<n 
( 1 8 2 7 ) 
+ ^(o)tfl<fa-(^(o)>W))_iii 
for any (y0,yi) 
G Η*{Ω) x £2(Ω) and (φξ,φ{) 
e £2(Ω) χ 
ff-^il). 
It follows directly from (18.27) that the two assertions are equivalent and 
the proof is complete. 
The second assertion in Lemma 18.3.1 may be seen as an optimality con-
dition for the critical points of the functional J : L2(Sl) x /ί - 1(Ω) —► R, 
J(<Po,<Pi) = \J 
y M2^di + (^(0),2/o)_ii-y^(0)yidx, (18.28) 
where φ is the solution of (18.23) with initial data (φζ, φ[) € £2(Ω) 
xH~1(fl). 
In fact, if we denote by (φ$ , φ[) the minimizer of J and φ the corresponding 
solution of (18.23) with initial data (φ'ο,ΦΪ), then it holds 
o 
= Hm UJMI, 
Φΐ) + ΚΨΙ, ΨΊ)) - σ{φΐ, ΦΙ)) 
h—>ο a 
= 
ψφάχάί- 
(■ΟΓ(°)>Ϊ/Ο)_ 
+ / 
ip(0)yidx, 
for any {φζ,ψχ) 
€ L2{Q) x /ί _ 1(Ω) where φ is the corresponding solution of 
(18.23). 
We now show that the sufficient condition ensuring the existence of a min-
imizer for J is the observability property of system (18.23), which is defined 
as follows: 

468 CHAPTER 18. CONTROL PROBLEMS ON DEs 
Definition 18.1 System (18.23) is observable in time T if there exists a 
positive constant C > 0 such that 
°\\(ψο,ΨΪ)\\1Ηη)ΧΗ-Η^) Ϊ f [ M ^ ' 
(18·29) 
JO 
J ω 
holds for any {ψζ,Ψι) S £2(Ω) x H~1(Q) where φ is the corresponding solu-
tion of (18.23) with initial data (φζ, φ{). 
Inequality (18.29) is called an observability inequality. It shows that the whole 
energy of the system (18.23) can be observed by the partial measurement on 
the subdomain ω. The following theorem holds: 
Theorem 25 Let (yo,yi) € HQ(CI) X L2(Q) and suppose that (18.23) is ob-
servable in time T. Then the functional J defined by (18.28) has a unique 
minimizer (φζ,φ^) 
€ £2(Ω) χ Η~1(Ω,). 
To prove Theorem 25, we need the following fundamental result in the 
Calculus of Variations: 
Theorem 26 Let H be a reflexive Banach space, K a closed convex subset 
of H and ψ : K —► R a convex, lower semicontinuous and coercive function. 
Then ψ attains its minimum in K, i.e. there exists XQ € K such that 
ψ(χο) = min^(x). 
x€A" 
The proof of Theorem 26 can be found in Ref. [2]. 
Proof of Theorem 25: It is easy to confirm that J is continuous and 
convex (see Exercise 18.3). To provide the existence of the minimizer of 
functional J, it is sufficient to verify that J coercive. More precisely, we 
need to prove that 
lim 
J(ip0,ipJ) 
= oo. 
Ι , 2 ( Ω ) χ / ί - 1 ( Ω ) " 
\\(ψο >¥>Dn .·> 
' ™-"j° 
Recalling the definition of J in (18.28) and the observability property (18.29), 
we have 
Jtä,tf) > \[ J 
T 
\<p\2dxdt 
o Ju 
IKwö.I/iJllff^njxL^njIKvo.V^ll^dDxH-^n) 
2 
1 
> 
y||(Vo>i')||L2(n)XH-i(n) 
*-' 11 / T 
T\ 
~2 ll(yo,2/i)|lHi(fj)xL2(n) 
\\(Ψο^Ψι)\\^{η)χΗ-ι(Ω) 

EXERCISES 
469 
Hence, it follows from Theorem 26 that J has a minimizer (φ^, φ[) S L2(Ci) x 
H~l (Ω). The uniqueness can be shown as a consequence of the strictly convex 
of J, which we also leave to an exercise (see Exercise 18.3). 
Combining Lemma 18.3.1 and Theorem 25, we guarantee that, under the 
hypothesis system (18.23) being observable at time T, system (18.3) is exactly 
controllable. Moreover, a control could be obtained as the solution of the 
homogenous system (18.23) with the initial data minimizing the functional 
J. Hence, the controllability problem is reduced to a minimization problem 
that may be solved by the Direct Method of the Calculus of Variations. 
Furthermore, the following corollary shows that the control obtained by 
this method is of minimal L2((0, T) x u;)-norm. 
Corollary 1 Let u = φ\ω be the control given by minimizing the functional 
J. 
If v e L2((0,T) x ω) is another control driving the solution of (18.3) to 
zero att = T with initial data (yo:Vi), then 
IMIL3((O,T)XC) ^ ΙΜΙ^((ο,τ)χω) ■ 
(18·30) 
Proof: We leave it as an exercise. 
EXERCISES 
18.1 
Deduce the formula (18.10) and compute the solution of (18.8) with 
this formula. 
18.2 
In fact, there are infinite ways to construct function z satisfying (18.13). 
Try to find one function z with a cubic polynomial function with initial 
data at to = 0, i.e., (x(0),x'(0)) 
= (1,0) and final data at t\ — 1, i.e., 
(x(l),x'(l)) = (0,0). Then write down the corresponding control for system 
(18.12). 
18.3 
Explain the functional J as (18.28) is continuous and strictly convex. 
18.4 
Prove Corollary (1). 
REFERENCES 
1. Arnold, V. I., Ordinary Differential Equations. Springer-Verlag, Berlin, (2006). 
Translated from the Russian by Roger Cooke, Second printing of the 1992 edi-
tion. 
2. Brezis, H., Functional Analysis, Sobolev Spaces and Partial Differential Equa-
tions. Springer, New York (2011). 
3. Cazenave, T. and Haraux, A., An Introduction to Semilinear Evolution Equa-
tions, Vol. 13 of Oxford Lecture Series in Mathematics and its Applications. The 
Clarendon Press Oxford University Press, New York (1998). 
4. Delfour, M. C. and Mitter, S. K., Controllability and Observability for Infinite-
Dimensional Systems. SI AM J. Control, 10:329-333 (1972). 

470 CHAPTER 18. CONTROL PROBLEMS ON DEs 
5. Evans, L. C , Partial Differential Equations, Vol. 19 of Graduate Studies in 
Mathematics. American Mathematical Society, Providence, RI (1998). 
6. Fattorini, H. O., Boundary 
Control Systems. 
SIAM J. Control, 6:349-385 
(1968). 
7. Fernändez-Cara, E. and Zuazua, E., On the history and perspectives of control 
theory. Matapli, (74):47-73 (2004). 
8. Kaiman, R. E., On the general theory of control systems. 
Proceedings of the 
First IFAC Congress on Automatic Control, 1:481-492 (1961). 
9. Kaiman, R. E., Ho, Y. C , and Narendra, K. S., Controllability of linear dynam-
ical systems. Contributions to Differential Equations, 1:189-213 (1963). 
10. Lee, E. B. and Markus, L., Foundations of Optimal Control Theory. Robert E. 
Krieger Publishing Co. Inc., Melbourne, FL, second edition (1986). 
11. Lions, J.-L., Controlabilite Exacte, Perturbations et Stabilisation de Systemes 
Distribues. 
Tome 1, Vol. 8 of Recherches en Mathematiques Appliquees [Re-
search in Applied Mathematics]. Masson, Paris, (1988). 
12. Lions, J.-L., Exact controllability, stabilization and perturbations for distributed 
systems. SIAM Rev., 30(l):l-68 (1988). 
13. Markus, L., Controllability of nonlinear processes. J. Soc. Indust. Appl. Math. 
Ser. A Control, 3:78-90 (1965). 
14. Micu, S. and Zuazua, E., An introduction to the controllability of partial dif-
ferential equations. In "Quelques Questions de Theorie du Controle", Sari, T., 
ed., pages 69-157. Collection Travaux en Cours Hermann (2004). 
15. Russell, D. L., Controllability and stabilizability theory for linear partial differ-
ential equations: recent progress and open questions. SIAM Rev., 20(4):639-739 
(1978). 
16. Sussmann, H. J., A general theorem on local controllability. 
SIAM J. Control 
Optim., 25(1):158-194 (1987). 
17. Zuazua, E., Controllability of partial differential equations and its semi-discrete 
approximations. Discrete Contin. Dyn. Syst., 8(2):469-513 (2002). 
18. Zuazua, E., Some problems and results on the controllability of partial differen-
tial equations. In European Congress of Mathematics, Vol. II (Budapest, 1996), 
volume 169 of Progr. Math., pp. 276-311. Birkhäuser, Basel (1998). 
19. Zuazua, E., Propagation, observation, and control of waves approximated by 
finite difference methods. SIAM Rev., 47(2): 197-243 (electronic) (2005). 
20. Zuazua E., Controllability and observability of partial differential 
equations: 
Some results and open problems. In Evolutionary Differential Equations, Vol. 8, 
pages 527-621. Elsevier Science (2006). 

CHAPTER 19 
MARKOV-JUMP STOCHASTIC MODELS 
FOR TROPICAL CONVECTION 
BOUALEM KHOUIDER 
Mathematics and Statistics, University of Victoria, Canada 
19.1 
INTRODUCTION 
Atmospheric convection is the process through which warm and moist air 
parcels rise from the surface, condense liquid water and form cumulus clouds. 
This results in precipitation and heavy storms. The process of condensation 
is accompanied by the release of latent heat, which is associated with the 
phase change of water from vapor to liquid and/or ice. In the tropics, moist 
convection constitutes a major source of energy for both local and large-scale 
circulations. Precipitation patterns in the tropics are organized into cloud 
clusters and superclusters on a wide range of scales; they range from the con-
vective cell (the cumulus cloud) of 1 to 10 km, to planetary scale waves with 
oscillation periods of 40 to 60 days. Due to the complex interactions between 
the local processes of convection and the large-scale waves, climate models fail 
Mathematical Modeling with Multidisciplinary Applications.
 
471 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley L· Sons, Inc. 

472 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
to properly capture tropical circulation patterns and their effect on the global 
circulation. In a climate model, the governing equations are discretized on a 
coarse mesh of roughly 100 km to 200 km and the effects of processes that are 
not resolved on such grids are represented by a parameterization also called a 
subgrid model. According to the last report of the United Nations' Intergov-
ernmental Panel on Climate Change (IPCC), the interactions of clouds and 
the climate system is one of the major challenges in climate research. 
The phenomenon of convection is in essence due to the very simple physi-
cal mechanism of buoyancy, which was discovered thousands of years ago by 
Archimedes. Buoyancy is the force that pushes light fluid to rise and heavy 
fluid to sink. When light fluid lies over heavy fluid as in normal atmospheric 
and oceanic conditions the situation is stable and if a fluid parcel is displaced 
mechanically in the vertical it will quickly sink or rise back toward its initial 
position and would normally undergo an oscillatory motion around its initial 
position. When the sun heats the surface (sea or land), the air parcels near 
the ground become quickly warm and moist, due to the evaporation of sea or 
land water. Because the warm and moist air near the surface is lighter than 
the dry and cold air above it, a turbulent motion begins and quickly mixes 
the air layer near the surface; because of the strong tropospheric stratification 
(the large discrepancy between the air density at the surface and at the top of 
the troposphere), the day is not long enough for this mixing process to pene-
trate very high before sun set. The cold surface-stable conditions are quickly 
restored at night as the ground loses its heat to space as long-wave radiation 
and the cycle continues. This process is called dry convection because it does 
not involve the phase change of water. It mainly serves to form what is known 
as the planetary boundary or mixed layer where the air density and poten-
tial temperature25 are relatively constant in the vertical. It leaves the upper 
troposphere unperturbed—happy and cool. When some "lucky" parcels are 
able to make it beyond the mixed layer they expand and cool down because of 
the pressure drop and potentially become saturated with water vapor. At this 
point the rising parcel starts to condense liquid water and releases latent heat, 
which in turn warms the parcel and partially compensates for the cooling by 
expansion. When this diabatic heating is large enough, the parcel becomes 
positively buoyant and will eventually rise high enough and entrain further 
convection and form a cloud. 
The level at which a rising parcel starts to condense water is called the 
lifted condensation level (LCL) while the level at which a parcel becomes pos-
itively buoyant because of condensational heating is called the level of free 
convection (LFC). The path of a hypothetical air parcel rising from the sur-
face is shown by the thick solid line in Figure 19.1. The thick dashed line is 
2 5The potential temperature is the temperature that an unsaturated air parcel would have 
if it is displaced adiabatically, i.e, without exchange of heat with the environment, to a 
reference pressure level, usually near the surface. 

19.1 INTRODUCTION 
473 
ILHdtM 
Planetary Boundary Layer 
Sr^ SURFACfi 
Figure 19.1 
Left: Path followed by a hypothetical parcel of air rising from the 
surface through the atmospheric column (solid line). The dashed line represents the 
environmental virtual temperature. The green area represents the convective available 
potential energy (CAPE) while the red area is the negative energy (CIN) that the rising 
parcel needs to overcome in order to reach its level of free convection and become freely 
buoyant. The dotted lines show the LCL and LFC levels. Right: A cartoon of a hot 
tower cumulus cloud formed by air parcels rising from the mixed boundary layer. 
the environmental virtual temperature,26 which yields a good approximation 
for the buoyancy that takes into account the water loading of the moist parcel. 
At any given point on its path, the parcel becomes positively buoyant, i.e., 
forced upward, if it finds itself virtually warmer than the environmental air 
around it and negatively buoyant if it is virtually colder. Given that potential 
energy associated with the convecting parcel is the vertical integral of the 
buoyancy force (which is proportional to the virtual temperature difference 
between the rising parcel and the environment), typically, the rising parcel 
needs to overcome a certain amount of negative energy before it reaches its 
LFC. The negative energy is known as convective inhibition (CIN) and is rep-
resented by the red area in Figure 19.1 while the positive (green) area above it 
is called convective available potential energy (CAPE). Observations showed 
that various mechanisms can contribute to provide the energy necessary for 
the rising parcel to overcome the CIN barrier. These include both local effects 
such as turbulent fluctuations in the boundary layer moisture and tempera-
ture, gust fronts, cold pools, and density currents and large scale effects such 
as organized convergence and propagating waves. Due to its complexity, the 
effect of CIN is still very poorly understood and as such it is not very well 
represented in climate models. The deterministic parameterization of CIN is 
at best unrealistic! 
26The virtual temperature is the temperature that a dry air parcel would have if it has the 
same pressure and density as the moist parcel. 

474 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Top of the troposphere 
Top of the boundary layer 
Figure 19.2 
A cartoon of the three cloud types showing congestus (c), deep 
convective (d), and a decaying deep convective tower with a lagging large stratiform 
anvil (s), with stratiform rain falling into a dry region below it where it eventually 
evaporates and cools the environment (hatched area). The arrows indicate convective 
motion within the cloud. 
Another conundrum of atmospheric convection, especially in the tropics, 
is its organization over a wide range of scales. Recent satellite and radar ob-
servations showed that organized convection involves three cloud types that 
interact with each other and help define a self-similar morphology for convec-
tively coupled waves of various sizes that are often embedded in each other 
like Russian dolls. It is suggested in some research papers that this can be 
possible only if the cloud-cloud interactions occur in some stochastic man-
ner so that when they are averaged locally or globally they would preserve 
their self-similar structure. This common structure consists of cumulus con-
gestus clouds that prevail in front of the wave followed by deep convective 
clouds that penetrate to the upper troposphere (near the tropopause) which 
in turn are lagged by icy stratiform anvils that prevail in the upper tropo-
sphere. Arguably a consensual explanation for the main physical mechanisms 
for this behavior is still an active research area but a more or less accepted 
explanation (which is somewhat biased toward the author's own research) is 
as follows. 1) Because of the entrainment of surrounding dry air, the rising 
parcels lose their buoyancy typically below the freezing level and form conges-
tus clouds. 2) As they form and dissipate in the middle of the troposphere, 
congestus clouds deposit and converge moisture in the horizontal and thus 
serve to precondition the environment for future parcels to penetrate higher 
and form deep convective clouds. 3) Stratiform clouds are believed to be a 
continuation of the deep penetrative clouds which start to dissipate from be-

19.2 RANDOM NUMBERS: THEORY AND SIMULATIONS 
475 
low and leave their icy anvil tops behind that continue to produce ice, thus 
heat. A cartoon of this three cloud-type paradigm is given in Figure 19.2. 
In this chapter, we present two stochastic models to represent, respectively, 
the random fluctuations of CIN and the random interactions of the three 
cloud types of organized convection using Markov jump processes. We start 
by presenting in section 19.2 a very basic introduction to random variables 
and the notion of Monte Carlo integration to familiarize the reader with the 
use of random numbers in computer simulations. In Section 19.3, we provide 
a crash-course introduction to the notion of Markov chains and birth-death 
processes. The stochastic model for CIN based on a simple birth-death process 
derived from an Ising-type model is then presented in Section 19.4 while the 
stochastic multicloud model is discussed in Section 19.5. A list of exercises 
is given at the end of the chapter to help improve the understanding of the 
theory in Sections 19.2 and 19.3. 
19.2 
INTRODUCTION TO RANDOM NUMBERS: THEORY AND 
SIMULATIONS 
19.2.1 
Random Variables 
A random variable X = Χ(ω) is by definition a function on a probability 
space Ω that takes values in a discrete set or a continuous interval of real 
numbers, according to a given probability distribution, P, defined of Ω. A 
random variable with values in a discrete set of real numbers is called a discrete 
random variable and a random variable that takes value in an interval is called 
a continuous random variable. 
Examples of discrete random variables: 
a) Perhaps the simplest example of a discrete random variable is that of tossing 
a fair coin, which results in heads or tails with a 50/50% chance. We can thus 
associate a random variable X that takes the value X = 0 if the outcome is 
heads and X = 1 if it is tails with the probability distribution 
P({X = 0}) = \,P({X 
= l}) = \. 
b) A similar example is that of throwing a die. The associated random 
variable takes its values in the discrete set {1,2,3,4,5,6} according to which 
face of the die appears. It's probability distribution is given by 
P({X = 1}) = Pl, P({X = 2}) = pa, · · ■ , P{{X = 6}) = P6, 
where 0 < pi,P2, ■ ■ · ,Ρβ < 1 satisfy p\ + P2 + · ■ · + Pe — 1· If the die is 
unloaded, then pi = p2 = ■ ■ ■ = ρβ = 1/6· 
c) If instead we consider throwing two dice at a time. Then the sum X 
of the two faces of the two dice is a random variable that takes values in 

476 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
{2,3, · · · , 12}. If we assume that the two dice are unbiased, then 
P{X = 2} = P{diel = l}P{die2 = 1} = -^ 
P{X = 3} = P{diel = l}P{die2 = 2} + P{diel = 2}P{die2 = 1} = ^-, 
P{X = 12} = P{diel = 6}P{die2 = 6} = -^. 
36 
Examples of continuous random variables: 
Concrete examples of continuous random variables are ubiquitous in nature 
and human life. Often a continuous random variable represents an idealized 
approximation of a discrete random variable taking values in a large discrete 
set. Common examples include that of the price of an asset in the stock 
market or the exact dimensions of a manufactured object—there is always 
some deviations from the aimed dimensions due to imperfections in the devices 
used for making the product, etc. 
The probability distribution of a continuous random variable is given in 
terms of the probability that X lies in a given interval [a, b]: P({a < X < b}). 
a) Uniform random variable on [0,1]: 
The uniform random variable is perhaps the simplest continuous random 
variable. It takes values in a specific interval [a, /?]. The distribution of 
the uniform random variable on [0,1] is as follows. If [a,b] C [0,1], then 
P({a < X < b}) = b - a, the length of the interval [a, b], 
If (a, 6) Π (0,1) = 0, then P{{a < X < b}) = 0. 
Note that accordingly, we have in general P({a < X < b}) = \(a, b)Π (0,1)| 
and P({0 < X < 1}) = 1. 
Very often, the probability distribution for a continuous random variable 
is given by an integral 
P{{a <X <b})= 
f 
f(x)dx, 
Ja 
where f(x) is a non-negative real valued function with the important property 
/ 
J — c 
f(x)dx = 1. 
f(x) is called the probability density function (pdf for short). For the example 
of a uniform random variable on [0,1] we have 
,, , 
ί 1 
if 0 < x < 1 
fix) = { 0, o " " 
otherwise. 

19.2 RANDOM NUMBERS: THEORY AND SIMULATIONS 
477 
The function 
F(x) = f 
f(x)dx, 
J — oo 
which is the probability that — oo < X < x is known as the cumulative distri-
bution function (CDF). For simplicity in exposition, the uniform distribution 
on an interval [α, β] is denoted below by U(a,ß). 
b) Gaussian or normal distributed random variable: 
A Gaussian random variable takes its values in (—00, +00) according to the 
Gaussian probability density function 
where μ, σ > 0 are two real parameters known as the mean and standard 
deviation of the Gaussian distribution. Note that 
is not known in closed form but it is easily evaluated using quadrature technique-
based algorithms that are already implemented in many of the available soft-
wares. For example in Matlab one can use the function normcdf which serves 
to evaluate the cumulative distribution function 
c) Exponentially distributed random variable: 
The pdf of an exponential random variable is given by 
f{x) = Xe~Xx for x > 0, 
where λ > 0 is a real parameter. The CDF takes the form 
F(x) = 1 - e'Xx, 
x>0. 
d) The Gamma distribution: 
Similarly to the exponential random variable a Gamma random variable takes 
its values on (0, +00). The pdf of a Gamma distribution with two parameters 
a, X is given by 
f{x) = -Ι—χΐ-ΐχθβ-** 
for 
x > 0. 
Γ(α) 
Here Γ(α) = J0°° xa~1e~xdx 
is a normalization constant with Γ(η) = (n — 
1)!, the function Γ is some sort of a generalization of the factorial opera-
tion to real numbers. Just like the normal distribution, the CDF of the 
Gamma distribution cannot be computed by hand. An approximate value 

478 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
however can be obtained numerically through the incomplete Gamma func-
tion: ? n in xa~1e~x 
dx which can be found in most of the available numer-
1 {a) JO 
ical libraries. In Matlab, for example, it is called gammainc. 
The exponential and Gamma distributions are commonly used to model 
the time of occurrence of rare events and highly skewed random variables. 
They are part of the family of fat tail distributions. 
19.2.2 
Mean, Variance, and Expectation 
Let X denote a continuous random variable with a probability distribution 
P(x) = P{X < x}. The mean or expectation of X is given by 
+oo) 
/
+OOJ 
xdP(x) 
-oo 
where the integral is in the sense of Stieltjes integration and dP(x) can be 
understood as the infinitesimal probability that x < X < x + dx. If X has a 
a PDF, say f(x), then 
/
+oo 
xf(x)dx. 
-oo 
Sometimes the mean is denoted by an overbar or angle brackets 
E[X] = X = (X). 
For any given real valued function g we can define the expectation of g(X) as 
/
+00 
/- + 00 
g(x)dP(x) = / 
g(x)f(x)dx. 
-oo 
J — oo 
The variance of X is given by Var\X) 
= E[{X - E\X\f\ 
= E[X2} 
-
E[X]2 and the standard deviation is given by σ = ^/Var[X]. 
Using simple 
integration rules, we can easily show that for 
• U(0,1), we have 
E\X\ = [ xdx = \ and Var[X] = [ x2dx - \ = -?-· 
Jo 
2 
J0 
4 
12 
• λί(μ,σ), 
Gaussian distribution with parameters μ,σ, we have 

19.2 RANDOM NUMBERS: THEORY AND SIMULATIONS 
479 
and Var[X] = -^=- 
f °° (x - μ)2 exp (- 
(X 
£ 
λ dx - μ2 = σ2. 
• the exponential distribution with a parameter λ > 0, we have 
f + OO 
1 
-, 
E[X} = \ 
xe~Xxdx= 
- and Var[X] = -=. 
Jo 
λ 
A 
19.2.3 
Conditional Probability 
Let X, Y be two random variables with their respective probability density 
functions fx and fy. The probability P({a < X <b,c <Y < d}) that both 
a < X < b and c < Y < d happen at the same time, is known as the joint 
probability distribution. The joint cumulative distribution function is the two 
variable function 
F(x,y)=P({X<x,Y<y}). 
The joint probability density function of X, Y is given by 
d2F(x,y) 
f{x>y) 
= 
-d^dy-> 
so that 
F(x,y)= [ 
[ f{t,s)dtds. 
J—CO J — OO 
We have the following compatibility conditions between the marginals and 
the joint distribution. 
/
X 
Λ + Ο Ο 
t>X 
fx(t)dt= 
/ 
f(t,s)dtds 
(19.1) 
-OO 
J— OO J— OO 
/
y 
I-+00 
r-y 
fY{s)ds= 
/ 
/ 
f(t,s)dsdt. 
■OO 
J— OO 
J—OO 
The two random variables X, Y are said to be independent if 
P({a <X <b,c<Y 
<d}) = P({a < X < b}) x P({c < Y < d}). 
If X, Y are independent then their joint probability density function satisfies 
f{x, y) = 
fx{x)fY(y)-
The probability that a < X < b given that c<Y 
< d denoted by P({a < 
X < b/c < Y < d} is known as the conditional probability of the random 
variable X given Y. We have 
P({a <X <b,c<Y 
<d}) = P({a < X <b/c<Y 
< d})x P({c < Y < d}). 

480 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
If X, Y are independent, then the conditional probability satisfies 
P{{a <X <b/c<Y 
<d})= 
P({a < X < b). 
The covariance of two random variables X, Y is given by Cov(X, Y) = 
E[(X - E[X])(Y - E[Y})] = E[XY] - E[X]E{Y\. 
It is easy to verify that 
Cov{X,X) 
= Var[X] and if X, Y are independent then Cov(X,Y) 
= 0. 
Note that Cov(X, Y) = 0 doesn't necessarily mean that X, Y are indepen-
dent. If Cov(X, Y) > 0, then X, Y are said to be positively correlated and if 
Cov(X, Y) < 0, they are said to be negatively correlated. Moreover, we have 
E[aX + bY] = aE[X]+bE[Y], 
Var[X + Y] = Var[X]+Var[Y] 
+ 
2Cov(X,Y), 
and Var[cX] = c2Var[X}. 
19.2.4 
Law of Large Numbers 
Let X\,X2, 
· · · , Xn,n 
> 2 be a sequence of independent and identically dis-
tributed (i.i.d) random variables, each having a mean μ and a standard de-
viation σ: E[Xj] = μ, Var[Xj] = σ2, Vj. We define the sample mean as the 
average random variable: 
1 
1 
n 
Xn = — {X\ + X2 + ■■■ Xn) = — > Xj-
Then the expected sample mean equals the population mean: 
Ε[Χη] = ^Υ/Ε[Χ^ 
= ^ημ = μ. 
The sample mean is said to be unbiased. Moreover, we have Cov(Xj,Xk) 
= 
0>J Φ k (because the r.v.'s are independent), implies 
ναΓ[Χη] = 
±ΣναΓ1ΧΑ 
σ2 
As a result the sample mean converges to the population mean μ in the 
probability or weak sense, i.e., 
lim 
P ■ 
n 
»-+00 
1 
n 
> e > = 0, for all e > 0 fixed. 

19.2 RANDOM NUMBERS: THEORY AND SIMULATIONS 
481 
This is known as the weak law of large numbers. 
It results directly from 
Chebyshev's inequality: 
Ve>0,P({|X„-M|>e})<^ä = 4 . 
ez 
rie-2 
We have also the strong law of large numbers which states 
P{ 
lim - V X,-,= μ \ = 1 
I n—>+oo n *-^ 
J 
I 
I 
i=1 
) 
but the proof of the latter result is much more involved. It can be found in 
any standard textbook on probability theory. 
19.2.5 
Monte Carlo Integration 
Consider the integral I = L g(x)dx. This integral can be thought of as the 
expectation E[g(U)] where U is a random variable uniformly distributed on 
[0,1] (U ~ U(0,1)). According to the law of large numbers above the expected 
value I = E[g(U)} can be estimated by a sample mean. Let Ui, U2, ■ ■ ■ ,Unbe 
a sequence of random numbers generated according to the uniform distribution 
W(0,1). Then, 
The strong law of large numbers guarantees that with probability one, 
lim /„ = /. 
n—>oo 
This is the basis for Monte-Carlo integration. We note that the sampling of 
genuinely random numbers is not possible on a digital computer. Instead, 
most programming languages and computing environments such as Matlab 
have one or more built in functions that can generate sequences of pseudo-
random numbers. The function rand() of Matlab for example can be used to 
generate sequences of pseudo-random numbers that are U{Q, 1) while randn 
samples the standard normal distribution Af(0,1) (Gaussian distribution of 
mean zero and variance one). Pseudo-random number generators are based 
on sequences of floating-point numbers that are drawn from some recurrent 
formula. Given that the number of floating-point numbers that are represented 
on any given computer is finite, all the pseudo-random numbers are periodic 
but their periods are usually very long. 
■ EXAMPLE 19.1 

482 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Consider 
/ = / 
exdx = e - 1 « 1.7183. 
Jo 
To use Monte Carlo integration, we view this integral as the expectation 
1 
n 
E[eu]^-^2eu', 
withW(0,l) 
nj=i 
and use the function rand() of Matlab to generate a sequence of U(0,1) 
pseudo-random numbers. Note that in Matlab rand(N,M) returns an 
N x M matrix of random numbers, all uniformly distributed in [0,1]. 
We consider the two cases with n — 10 and n = 1000 and produce two 
replicas in each case in order to highlight the random character of the 
computation. 
»rand('state' ,0) '/.this (re) initializes the function rand 
» I = mean(exp(rand(l,10)) 
ans= 
1.8318 
» I = mean(exp(rand(l,10)) 
ans= 
2.0358 
» I = mean(exp(rand(l, 1000000)) 
ans= 
1.7189 
» I = mean(exp(rand(l,1000000)) 
ans= 
1.7178 
Increasing the number of samples clearly improves the estimated in-
tegral. 
EXAMPLE 19.2 
Here we show how the Monte Carlo method can be used to compute an 
improper integral. We consider the integral 
r+oo 
We have 
/
-f-OO 
cos(x)e~x2/2dx. 
-oo 
/
"l~0° 
1 
\/27rcos(x)—i=e~x 
/2dx. 
Recognizing the normal probability density function f(x) = -75-e x /2, 
we view the given integral as the expectation E[cos(X)], where X is an 

19.2 RANDOM NUMBERS: THEORY AND SIMULATIONS 
483 
Af(0,1) random variable. Therefore 
1 ~ 
—Y,cos(xj)> 
where the Xj's are random numbers sampled (drawn) from the stan-
dard normal distribution. This can be easily accomplished in Matlab by 
using the randnQ function. The Matlab lines below show how this is 
implemented. To produce a benchmark value, we first use the determin-
istic quad function (i.e., the composite Simpson rule) on a finite interval 
[-A, A] with A = 10 and A = 100. 
» quad('cos(x).*exp(-x."2/2)',-10,+10) 
ans = 
1.5203 
» quad('cos(x).*exp(-x."2/2)',-100,+100) 
ans = 
1.5203 
» sqrt(2*pi)*mean(cos(randn(l,100))) 
ans = 
1.5682 
» sqrt(2*pi)*mean(cos(randn(l,100))) 
ans = 
1.4070 
» sqrt(2*pi)*mean(cos(randn(l,1000000))) 
ans = 
1.5212 
» sqrt(2*pi)*mean(cos(randn(l,1000000))) 
ans = 
1.5225 
The two examples above illustrated how to use (pseudo-) random numbers 
generated by the functions rand and randn to perform Monte Carlo integra-
tion based on the uniform and normal distributions, respectively. In practice, 
we may need to generate random numbers from an arbitrary probability dis-
tribution such as the exponential, the gamma, or the beta distribution. Many 
methods have been developed and made available in the literature to deal 
with such general cases as well as very particular ones. In the sequel, we 
assume that a uniform random number generator such as rand is given and 
present two standard techniques that can be used to generate pseudo-random 
numbers from an arbitrary distribution. 
19.2.6 
Inverse Transform Method 
The inverse transform method, for generating pseudo-random numbers, from 
an arbitrary distribution, is based on the following basic statement. 

484 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Given a random variable X and its probability density fx and cumulative 
distribution function, Fx(x), then the random variable 
U = FX(X)= [ 
fx(x)dx 
J—oo 
is uniformly distributed on (0,1). Conversely, if U ~ U(0,1), then we have 
P({X < x}) = PdF^iU) 
< x}) = P{{U < F(x)}) = F(x). 
This is represented schematically in Figure 19.3. If we are able to invert F 
easily, then the inverse transform method for fx can be implemented in two 
easy steps. 
1. Draw a uniform pseudo-random variate U ~ U(Q, 1). 
2. Set X = 
F~l(U). 
■ EXAMPLE 19.3 
We consider the standard exponential distribution X ~ exp(A). We have 
F(x) — 1 — e~Xx and for a given uniform variate, the inverse transform 
method yields 
X = F'^U) 
= -γ1η(1 - U). 
Λ 
Given that the probability for drawing U and 1 — U from the uniform 
distribution is the same, in practice exponential variates are usually 
generated by drawing uniform variates U € (0,1), then returning X = 
— 1η(£/)/λ. We now use the algorithm above to approximate the integral 
I = f0 
2xe~2xdx 
= | , which is the expectation of the exponential 
random variable X ~ exp(2). 
» u = randd, 1000000); 
» x = - log(u)/2; 
» mean(x) 
ans = 
0.4993 
» u = rand(l,1000000); 
» x - - log(u)/2; 
»mean(x) 
ans = 
0.5001 
» u = randd ,1000000); 
» x = - log(u)/2; 
»mean(x) 
ans -
0.5004 

19.2 RANDOM NUMBERS: THEORY AND SIMULATIONS 
485 
1 
0.9 
0.8 
0.7 
0.6 
0.5 
0.4 
0.3 
0.2 
0.1 
0 
~D 
u 
a 
I 
I 
I 
■_ 
/ 
/ 
/ 
/ 
x 
^ / F - 1 ( a ) 
F"1(b) 
Figure 19.3 
Schematic of the inverse method: P{{a < U < b}) = PÜF^ia) 
< 
X < F?(b)}). 
19.2.7 
Acceptance-Rejection Method 
As mentioned above, the inverse transform method is only feasible when the 
CDF F(x) can be easily inverted. Although one can always resort to numerical 
root-finding techniques such as Newton's method to invert F(x), it is not 
always a good idea because this can be very costly especially when we need to 
generate a large number of variates—to perform a Monte Carlo integration, 
for example. A better approach for the case when the inverse of F(x) is not 
known in closed form or is expensive to evaluate is the acceptance-rejection 
method discussed here. 
To simulate a random variable X obeying a given probability distribution 
with a pdf f(x), the acceptance-rejection method starts by finding a function 
t(x) such that f(x) < t(x),Vx G M. whose CDF is easy to invert. Once such a 
function t(x) is found, the acceptance-rejection method consists of the three 
main steps listed below. Let g(y) = t(y)/K 
where K — 
f_™t(y)dy. 
1. Use the inverse transform method to generate a pseudo-random number 
Y corresponding to g(y). 
2. Draw a uniform variate U from U(0,1), independent of Y. 

486 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
3. If U < f(Y)/t(Y), 
then return X = Y (accept), otherwise go to step 1 
(reject). 
Recall that for a given (fixed) Y, the probability for a uniformly distributed 
random number U to satisfy U < f{Y)/t(Y) 
is P({U < f(Y)/t(Y)}) 
= 
f(Y)/t(Y). 
Therefore, the more this ratio is close to one the better are the 
chances for the random number Y to be accepted and the above procedure to 
be terminated. The points Y where this ratio is close to 1 are very likely to be 
accepted while those with a small f(Y)/t(Y) 
are very unlikely to be accepted. 
To gain efficiency, it is thus important to choose a function t(x) which is as 
close as possible to f(x). 
Also, it can be shown that the average number of 
iterations (acceptance and rejection trails) to terminate the procedure with 
an accepted value X is given by K = J_ 
t(x)dx. 
If the support of f(x) is bounded, i.e., f(x) = 0 outside a bounded interval 
[a, β], then a natural choice for g(x) is simply the uniform distribution on [a, ß] 
and choose t(x) = constant = max[ajlg] f(x) for a < x < ß and t(x) = 0 
otherwise. 
■ EXAMPLE 19.4 
As an example we consider the beta-distribution on [0,1]. 
fW= 
nil 1 \ ' 
xe[0'1]' 
B(ai,a2) 
where 
B(aua2)= 
I 
x^-^l-xT^dx. 
Jo 
For αι = a2 = 3, we have f(x) = 30(x2 - 2x3 + x4), 
x e [0,1]. Note 
that its CDF is a fifth-order polynomial that is not easy to invert and 
thus the inverse transform method would be hard to apply here. 
Let t(x) = maxjo,!] /(#) = 30/16. Using the uniform distribution as 
the reference density g(x), we have the following algorithm: 
1. Draw two independent uniform random variates Ui,U2 from U(0,1). 
2. If U2 < 16(Uf - 2C/f + Uf) accept X = Ui\ otherwise, reject 
and go back to step 1. 
19.3 
MARKOV CHAINS AND BIRTH-DEATH PROCESSES 
In a general manner a stochastic process is a collection of random variables, 
Xt,t e S, where 5 is a discrete set or an interval of R. The Xt's can be either 

19.3 MARKOV CHAINS AND BIRTH-DEATH PROCESSES 487 
correlated or uncorrelated with each other. Markov chains lie somehow in 
between the fully correlated and fully uncorrelated extremes. In this section, 
we will review Markov chains in general and in particular the case of the birth 
and death process, which will be applied in Sections 1.3 and 1.4 below to model 
some features of tropical convection. In fact, birth and death processes are 
widely used in biology and computer science and many other disciplines. 
19.3.1 
Discrete-Time Markov Chains 
Consider a discrete stochastic process, Xt0,Xt1,Xt2i"'" 
where to < t\ < 
ti < ■ ■ ■ is an increasing sequence of discrete times and the X^ 's are discrete 
random variables defined on a common state space, xo,xi,X2,··· 
■ For sim-
plicity we will omit the subscript t and denote the discrete process simply as 
Χθ,Χ\,Χ2ι 
The stochastic process Xn, n > 0 is called a Markov chain if in addition it 
satisfies the Markov property 
P{Xn+l 
= Xj/Xn = Xi, Xn-1 = Xk, · " · , -^0 = xl} = P{Xn+l = Xj/Xn = Xi} ■ 
(19.2) 
The Markov chain is said to be stationary or homogeneous if P{Xn+\ = 
Xj/Xn = Xi] is independent of n. The conditional probabilities P^ = P{Xn+\ = 
Xj/Xn = Xi} are called the transition probabilities and the matrix P = 
[Pij]i,j>o is called the transition probability matrix. 
Two important properties of the matrix P are 1) all of its entries lie between 
0 and 1 and 2) all of its rows sum to one, namely, 0 < P,j < 1 and Σ ° ^ 0 Pij = 
1. These two properties result directly from the fact that for each fixed i, 
Pi,j,j = 0,1, · · · is a probability distribution on the state space XQ,XI,X2,··· 
. 
A matrix that satisfies these two properties is called a stochastic matrix. 
The Chapman-Kolmogorov equations 
Consider the n-step transition probabilities Pi · = P{Xn+k = Xj/xk = i} = 
P{Xn = Xj/Xo — Xi}- According to the definition of conditional probabili-
ties, we have for all i, j > 0 
p(n+m) 
Ξ p { X n + m 
= 
χ . / Χ ο = χ . } 
oo 
oo 
= Σ P{Xn+m = Xj/Xm = Xk}P{Xm = Xk/X0 = Xi} = ^ 
Ρ^Pkf' 
fc=0 fc=0 
Thus 
oo 
p(n+m) _ V-* p(n) p(m) ,· · _ n -i 9 
^ij 
— Z_^ ^ik 
rkj 
1 Z' J — U ' *> Z> ' " ' · 
k=0 
These identities are known as the Chapman-Kolmogorov equations. If we 
let P(") denote the n-step transition probability matrix, then it is easy to 
see, by the Chapman-Kolmogorov equations, that p("+1) = p(") x P and 
p(n) = ρ η = ρ χ ρ χ . . . χ ρ ( η times). 

488 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Limiting and stationary 
distribution 
A Markov chain Xn is said to have a limiting distribution if the limit 
limn 
>CJO Plj exists for all i,j, and is independent of i. 
The limit TTJ = 
limra 
>00 P,™ when it exists is called the limiting distribution of Xn. 
As a 
consequence of the Chapmann-Kolmogorov equations, the limiting distribu-
tion satisfies 
oo 
7Tj = 2_] KiPij or 7Γ = πΡ, 
(19.3) 
i=0 
i.e., π is a left eigenvector of the matrix P associated with the eigenvalue λ = 1. 
Any row vector nj,j = 0,1,2 · · · of real numbers which satisfies (19.3) and 
the two properties of a probability distribution: Y^l0irj 
= 1, 0 < π3, < 1 is 
called a stationary or invariant distribution of the Markov chain. The limiting 
distribution when it exists is an invariant distribution but the converse is not 
always true. Sufficient conditions for the existence of the limiting distribution 
and for the uniqueness of the stationary distribution are known but they 
are beyond the scope of this brief introduction. They involve the notion of 
ergodicity which intuitively amounts to saying that all the states of the chain 
are visited equally infinitely many times when the chain is run for an infinitely 
long time. The interested reader is referred to the books by S. M. Ross [12] 
and G. F. Lawler [2]. 
Time reversible chains and detailed balance 
Consider a stationary ergodic (i.e., that has a limiting and unique stationary 
distribution Ttj) Markov chain with transition probabilities Pij. Assume that 
the chain is run for a very long time and is in its equilibrium state, i.e., it 
satisfies P{Xn 
— Xj} = TTJ,J = 0,1,2,·-·. Consider the backward process 
Xn, Xn-i,Xn-2, 
■ ■ ■ when n goes to infinity. By some manipulations we can 
show that the time reversed process is also a Markov chain with the transition 
probabilities 
A Markov chain is said to be time reversible if Qij = Py for all i,j > 0. In 
other words, Xn is time reversible if 
KiPij = TtjPji, i, j = 0,1,2, · · · . 
(19.4) 
The equations in (19.4) are known as the detailed balance equations. They 
basically state that, in the long run, the rate of transition from state x, to ad-
equate the rate of transition from Xj to Xi. 
■ EXAMPLE 19.5 
A random walk on a finite set. Imagine a person who takes random 
steps between the positions 0,1,2, · · · , M. If at time n the person finds 

19.3 MARKOV CHAINS AND BIRTH-DEATH PROCESSES 
489 
herself in a state i, 0 < i < M, she will take a step randomly to the left 
or to the right according to the following transition probabilities: 
Pi,i+i = Oii, Pi,i-i = 1 - <Xi,i — 1,2, ·· · ,M - Ι,Ρο,ι = 1,-ΡΜ,Μ-Ι = 1· 
Here 0 < α» < 1 for i = 1, ■ · · , Μ — 1 to guarantee that the induced 
Markov chain is ergodic and time reversible. When the random walker 
hits 0 or M, with probability one, she will return to 1 or to M — 1, 
respectively, at the next step. This is a bounded random walk with re-
flecting boundaries. Bounded and unbounded random walks are widely 
used in the theory and applications of Markov chains and probability 
theory. While the Pij 's define the transition probability matrix of the 
discrete time Markov chain, we can easily write down the detailed bal-
ance equations: 
π0 = (1 - α ι ) π ι , π,αί = π ί + ι ( 1 - a i + i ) , i = 1,2, · · ·Μ - 2, 
T T M - l ^ M - l = 7ΓΜ-
Setting ao = 1 and CCM = 0, we can easily see that the solution to these 
equations is given by 
7ΙΌ 
- 1 
M 
j 
ati-i 
Ι + Σ Π Γ 
■
i
l
l
- 
a
i 
3 = 1 1=1 
and -Kj = π0 JJ 
ai 
For the particular case oij — 0.5, j = 1,2, · · · ,M — 1, we have πο = 
■KM = 1/2M and π^ = 1/M, for 1 < j < M - 1. 
19.3.2 
The Poisson Process 
The Poisson process, Nt, is a counting process, i.e., the process of counting 
the number of events that occur in sequence by time t, such that: 
i) N0 = 0. 
ii) Nt has independent and stationary increments. In other words, given 
ti < fa < ts < ti the number of events that occur between times ii 
and t2, Nt2 — Ntl, and the number of events that occur between £3 and 
*4> Nt4
 — -^t3, are independent random variables and the distribution of 
Nt+S — Nt, for s, t > 0, depends only on the length of the interval, s, 
and not on t. 

490 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
iii) Nt is Poisson distributed with mean λί where λ is a positive parameter 
called the rate of the process: 
P{Nt+s -Nt 
= k} = P{NS -N0 
= k} = P{NS = k} = 
e~Xs^j-. 
Using Taylor expansion and the moment generating function of the Poisson 
distribution, we can show that a counting process that satisfies i) and ii) above 
is a Poisson process with rate λ > 0 if and only if it also satisfies, for all small 
ft>0, 
P{Nt+h -Nt 
= l} = \h + o{h) and P{Nt+h - Nt > 2} = o(h), 
where o(h) is an arbitrary function of h that satisfies lim o(h)/h — 0. 
h—>0 
Inter-arrival times 
Consider a Poisson process Nt,t > 0 with a rate λ > 0. Let T\ be the time 
at which the first event of Nt occurs, T^ the time spent between the first 
and the second events, T3 the times between the second and third events, 
etc. Then T\,T2, ■ ■ ■ is a sequence of independent exponentially distributed 
random variables with a common rate λ > 0. This follows directly from the 
independence of increments property and the fact that Ρ{Τχ > t} = P{Nt = 
0} = e~xt. 
The waiting time Sn = 7\ + T2 H 
\-Tn until the nth event 
occurs is Gamma distributed with parameters n and λ. 
This intimate relationship between the Poisson process and the exponential 
random variables is due to the so-called memory less characterization-property 
of the exponential distribution, namely, T is an exponentially distributed 
random variable if and only if 
P{T >t + s} = P{X > t}P{X 
> s}. 
■ EXAMPLE 19.6 
Assume certain types of batteries are being used in a certain electronic 
device, one at a time. A battery in operation is replaced by a new one 
upon its failure. Assume that the lifetime of a battery in operation is 
an exponential random variable with rate λ > 0. Then the number of 
batteries being used by time t, Nt, is a Poisson process with rate λ > 0, 
namely, we have P{Nt = k} = 
e~xt(\t)k/k\. 
Assume that in a certain day, customers enter a store according to a Poisson 
process with rate λ, i.e., the number Nt of customers that enter the store by 
time t of the day is Poisson distributed with mean λί. Then the time spent 
between the arrivals of two successive customers is an exponential random 

19.3 MARKOV CHAINS AND BIRTH-DEATH PROCESSES 
491 
variable with mean l/λ, i.e., the average time spent between two successive 
arrivals is 1/λ (λ has units of one over time). Assume l/λ = 1 hour. Then, if 
we have waited 30 minutes after the nth customer arrived and nobody showed 
up, then the expected time for the (n + l)th customer is still 1 hour, because 
of the memoryless property of the exponential distribution. 
19.3.3 
Continuous-Time Markov Chains 
A stochastic process Xt where t is in (0, +oo) defined on a discrete state space 
XQ,XI,X2,··- 
is called a Markov chain if it satisfies the Markov property (in 
continuous form) 
P{Xt+s = Xj/Xs = Xi, Xu — Xu, 0 < U < s} = P{Xt+s = Xj/Xs = Xi}-
If P{Xt+s — Xj/Xs = Xi} is independent of s then Xt is said to be a stationary 
or homogeneous Markov chain. Similarly to the discrete case, the conditional 
probabilities Pij(t) = P{Xt+s = Xj/Xs = Xi} are called the transition prob-
abilities and the time-dependent matrix P(t) — [Pjj (£)] is called the transition 
probability matrix. 
The continuous version of the Chapman-Kolmogorov equations, which also 
follows from the elementary definition of conditional probabilities, reads 
oo 
Pij(t + s) = YiPik{s)Pkj(t), 
fc=0 
which results from the conditional probability formula P{Xt+s 
= Xj/Xo = 
xi} = Σ™=ορ{χϊ+<> — xj/xt 
= Xk}P{Xt 
= Xk/Xo = Xi}- Notice the 
analogy with the discrete case. 
Waiting time and transition rates 
An important property of continuous-time Markov chains is one that links 
them directly to the Poisson process. Assume that at time t the Markov chain 
Xt is in state Xi, i.e., Xt — a;,. For a stationary stochastic process, the Markov 
property is equivalent to the fact that the time T» the process stays in state 
Xi before it makes a transition (or jump) to another state Xj φ Xi, i.e., T» = 
inf{s > 0 such that Xt+S φ x% given that Xt = x%}, is an exponential random 
variable. Moreover, the times T^, it takes the chain to make a transition from 
Xi to Xj,j φ i are independent exponential random variables. By construction 
we have T» = min{Tij,j 
— 0,1,2 · ■ · , j φ i} and if qij,i φ j are the rates of 
the Ty's and Vi denote the rates of the waiting times Ti,i = 0,1,2,· ■·. Then 
according to the properties of exponential random variables, Vi = ^Zi^i^ij'· 
The matrix R whose diagonal Ru = — u» and non-diagonal entries are the q^s 
is called the infinitesimal generator of the chain. As we will see below, the 
matrix R completely determines the Markov chain. The entries qij are often 
called the transition rates of the chain. As an immediate consequence of this, 

492 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
we have, for sufficiently small h > 0, 
Pu(h) = P{Ti <h} = l-Vih 
+ o{h) and P^h) 
= Ρ{Τ^ > h} = qijh + o(h). 
Kolmogorov forward and backward equations 
By the Chapman-Kolmogorov equations, we have for h, t > 0 
oo 
p..(t + h) _ p..(t) = J2Pik(h)Pkj(t) - Ρφ) 
fe=0 
= Y^Pik{h)Pkj{t) - [1 - Ρα{Κ)]Ρφ). 
k^i 
Dividing both sides by h and letting h —► 0 and using the identities above 
yields the Kolmogorov backward equations 
ftPij(t) 
= YiQikPkj(t) 
- 
ViPjit). 
If instead we write Pij(t+h) = Σ™=0 Pik(t)Pkj (h), then similar manipulations 
yield the Kolmogorov forward equations 
JtPij(t) = J2qkjPik(t) - VjPijit). 
In matrix notation, the backward equations become P' = RP while the for-
ward equations read P' = PR. 
The backward and/or forward equations 
provide a system of linear ordinary differential equations for the transition 
probabilities. It is closed with the initial conditions Pij(0) = 6ij = 1 if i = j 
and 0 otherwise. Following the standard theory of differential equations, its 
solution is given by P(t) = exp(tR). 
However evaluating the matrix expo-
nential can be problematic in practice, especially, when the matrix R is very 
large, i.e., when the Markov chain has a large number of states. A lot of re-
search has been done in order to come up with practical solvers for this large 
ODE system. The interested reader is referred to work of Ref. [13]. 
Limiting distribution and detailed balance 
Similarly to the discrete case, the limiting distribution of Xt is given by Pj = 
lim Pij(t) when this limit exists and is independent of i. It satisfies the 
t—»oo 
steady state forward equations 
oo 
ΣQkjPk 
= VjPj, 0 < Pj-,< 1, Σ 
Pi = h 
k^j 
j=0 
A solution Pj ,j > 0 to these equations is called a stationary or an equilibrium 
distribution. Intuitively, these equations express the fact that, in the long 

19.3 MARKOV CHAINS AND BIRTH-DEATH PROCESSES 
493 
run, the rate of transition away from state j , VjPj, is balanced by the rate of 
transitions to state j , \ ^ qkjPk-
Let Pf, be the probability that the Markov chain makes a transition from 
Xi to Xj φ Xi the first time it leaves state i, i.e., Py = P{Tij = min(Tjfc, k φ 
i)}. 
According to the properties of exponential random variables, we have 
IPij = qij/vi, i φ j and P ^ = 0 . P is a stochastic matrix and the associated 
discrete Markov chain is called the embedded discrete chain of the original 
continuous-time Markov chain Xt. 
Let TTJ, j = 0,1, · · · , be the limiting distribution of the embedded chain. 
Then we have the following relationships between π^ and Pj: 
~--Si3L_ , = 0,1,.·.. 
3 
Ekvkpk 
We note that these equalities express simply the fact that (π,) oc (VJPJ) with 
the term in the denominator being the normalization constant. Therefore if 
we know π^ for the embedded discrete chain we can find Pj and vis versa. 
The continuous process Xt is said to be time reversible if the embedded 
discrete chain is time reversible, i.e., if 7TjPy = π^Ρ^, for all i, j , i.e., ViPiPij = 
VjPjFji for all i,j. But P ^ = q^/vi, therefore we have 
PiQij = PjQji, i,j = 0,1,2, · · - , 
(19.5) 
which are the detailed balance equations for the continuous chain Xt. 
Intu-
itively, these equations express the fact that the rate of transitions from state 
i to state j and from j to i are balanced in the long run. 
■ EXAMPLE 19.7 
Consider a certain machine that operates for an exponentially distributed 
random time before it breaks down at a rate μ > 0. Upon its failure the 
machine is sent to the repair shop where it takes an exponential time 
with rate λ > 0 before it is repaired and put back in service. Let Xt be 
the random variable that takes the value 1 if the machine is in service 
at time t and 0 otherwise. Then Xt is a continuous-time Markov chain 
with the state space reduced to 0 and 1, a two-state Markov chain. The 
infinitesimal generator is given by R 
equations are given by 
and the backward 
Poo = λ[Ριο - Poo], Pio = μ[Ροο ~ Pio], 
Ρόι = A[Pn - Poi], 
Pd = μ[Ροι - Pii]· 
We first note that this system splits into two two-by-two subsystems, 
one for PQO an<3 Pio and one for PQI and Pn. Combining the two first 

494 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
equations yields μΡ$0 + XP{Q = 0. i.e., Poo{t) + PLOW = c is constant 
and substitution in the second equation yields a single (linear) equation 
for Poo which can be easily solved by the method of integrating factors. 
With the initial conditions Pij (0) = Sij, we find 
Poo{t) = _ H _ + -ϊ-β-Ι**»» 
and P10 = -L·- 
- ^ _ β - ( λ + " ) « 
λ + μ 
Χ + μ 
Χ + μ 
λ + μ 
and using the identities Ρ^ + Pn = 1, i = 0,1 yields the other two 
probabilities without having to solve the remaining equations: 
PoiW = τ ^ - - j - ^ - e - ^ " ) * and Pn = - ± - + - g - e - ^ « . 
λ + μ 
λ + μ 
λ + μ 
λ + μ 
Letting t —► oo leads to the limiting distribution of the chain 
P - 
μ 
P - 
λ 
λ + μ 
λ + μ 
Notice that detailed balanced is evidently satisfied: λΡο = μΡχ. 
EXAMPLE 19.8 
The Birth and Death Process 
Assume that customers arrive in a shop according to a Poisson process 
with rate λ. The customers are served by m tellers. Upon arrival, 
a customer proceeds to the first available teller or waits in a queue 
until a teller is freed. Assume that the service time of each teller is 
an exponential random variable with rate μ >. Then, the number of 
customers, Xt, in the store at any given time, t > 0, is a continuous-
time Markov chain with transition rates 
Qn,n+i = λ, for n > 0, <?„,«-1 = ημ for 1 < n < m, 
Qn,n-i — 'τημ for n > m + 1. 
The rates of the waiting times between two transitions (i.e., before 
the next arrival or departure occurs) are given by VQ = λ, vn = X + 
ημ, for 1 < n < m, and vn — X + πιμ if n > m + 1. In queuing theory 
this is known as the M/M/m model. The infinitesimal generator of the 
chain is a tridiagonal matrix. Similar models are ubiquitous in practice. 
They are called birth and death processes. Xt = n is the regarded as the 
number of members in a population at time t. The rate at which arrivals 
occur, qn,n+i = λ η,η > 0, is called the birth rate and the rate at which 
departures occur, qn,n-i 
= μη,η > 1, is called the death rate. Notice 
that in the general case both arrival and departure rates are assumed 
dependent on n and that we implicitly assumed μο — 0. If in addition 

19.4 A BIRTH-DEATH PROCESS FOR CONVECTIVE INHIBITION 
495 
Xk = 0 for a certain integer k > 1 then the process becomes bounded to 
the states 0,1,2, · · · , k. If Xt = k, then new arrivals are not accepted. 
The steady state forward equations for the birth-death process are 
λο-Ρο = μι-Pi, 
(λη + μη)Ρη = Mn+i-Pn+i + λ„_ιΡ„_ι,η ψ 1. 
Substitution of the first equation into the second, the second into the 
third, and so on, yields 
ληΡη = ßn+\Pn+\i n ^ 0J 
which are nothing but the detailed balance equations (19.5) for the birth-
death process. With the constraint Y^JL0Pj = 1, the solution to this 
equations is 
- 1 
Λ„-ιΛπ-2···Λ0 
"n — 
Jro, JTQ — 
fJ-nfJ-n-lfJ-l 
Xn-lXn-2· · · AQ 
j=0 
ßnßn-lßl 
Therefore, a necessary condition for the birth-death process to admit 
a limiting distribution is X ^ l 0 ""* "—2"' ° < oo. This is guaranteed 
for the M/M/m process if the ratio λ/τημ < 1, i.e., the rate at which 
customers arrive is smaller than the rate at which they are being served. 
In the case of the finite state birth-death process this condition is always 
satisfied because the summation terminates at n = k; Xk = 0 . 
19.4 A BIRTH-DEATH PROCESS FOR CONVECTIVE INHIBITION 
19.4.1 
The Microscopic Stochastic Model for CIN: Ising Model 
Here a give a brief description of the microscopic stochastic model for CIN, 
which is used as a basis for the birth-death process for CIN. The interested 
reader is referred to Ref. [9] for more details. It is based on the Ising model 
for magnetization of statistical mechanics. As stated above, CIN is an energy 
barrier for spontaneous deep penetrative convection in the tropic and it is 
known to have important fluctuations in the horizontal on the order of 1 
km to 10 km. Hence, we consider sites that are uniformly distributed on a 
lattice (which can be though of as spanning one horizontal gridbox of the 
climate model) on which we define an order parameter aj on a finite lattice 
AC{0,1} Z. 
σχ(χ) = 1 at a site if convection is inhibited (a CIN site), 
(19.6) 
σι(χ) = 0 at a site if there is potential for deep convection (a PAC site). 

496 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
SigmaJ~i 
SijjniHj-0 
Sifmu _! - 1 
Figure 19.4 
A Cartoon of a deep penetrative hot-tower cloud represented at a PAC 
site. The order parameter takes values 0 or 1 on a given site according to whether it 
is a CIN site or there is potential for deep convection. 
A cartoonist picture of this representation is shown in Figure 19.4. On the 
coarse grid of mesh size Ax of a climate model, the value of CIN at a coarse 
mesh point, jAx, is given by the average 
χ 
f(j+l/2)Ax 
σ/Ο'Δχ) = — 
/ 
σι(χ)άχ. 
(19.7) 
AX 
J(j-i/2)&x 
Here we assume a simple ID domain for simplicity. The model's cumu-
lus parameterization then "decides" according to this average CIN value on 
whether to allow deep convection to occur at that grid point or not. As ex-
plained in the introduction section, factors to overcome CIN are very complex 
and can be both local or external. Instead of trying to follow the details of 
such interactions, the microscopic CIN sites are set to interact with each other 
and with the external large-scale values of the deterministic flow variables ac-
cording to the following probabilistic rules. 
A) If a CIN site is surrounded by mostly CIN sites, then it has higher 
probability to remain a CIN site. 
B) If a PAC site is surrounded by mostly CIN sites, then it has higher 
probability to switch to a CIN site. 
C) The external large-scale values, Uj, supply an external potential h(uj) 
that can modify the dynamics according whether external conditions 
favor CIN or PAC. 

19.4 A BIRTH-DEATH PROCESS FOR CONVECTIVE INHIBITION 
497 
Following the standard theory of the Ising model of statistical physics, the 
microscopic energy for CIN is given by the Hamiltonian 
tffcM = ~\ Σ 
Σ 
JMX 
- y))°i(x)*i(y) -h^ajix). 
(19.8) 
X 
Τ)φχ 
X 
Here Hh{&i) is the microscopic energy associated with a given configuration 
σ/ with J > 0 is the symmetric interaction potential and 7 defines the range 
of microscopic interactions 
with U{r) = U(-r),re 
R, U(r) = 0, \r\ > 1, for example, 
\ 
0 
otherwise. 
^ ' ' 
7 = jjri, where, in the ID setting, 2L is the number of interacting neighboring 
sites and N is the total number of sites. Note that, in the absence of the 
external factor, h = 0, the minimum energy level is achieved when σι(χ) = 
1 Vor, i.e., an all-CIN configuration, while the all-PAC configuration, σι{χ) = 
0, has the highest level—zero energy. 
If we regard the mixed boundary layer as a heat bath for CIN, then ac-
cording to the theory of statistical mechanics, the equilibrium distribution of 
the configurations aj for the Hamiltonian dynamics (that oscillate about the 
minimum energy level) is given by the Gibbs measure 
G(a/) = ±-e-ßH^<"\ 
(19.10) 
where β is a positive parameter that depends on the "temperature" of the 
microscopic system and Z\ is a normalization constant (which can be very 
large and hard to compute!). 
The external potential h modifies the CIN configuration according to whether 
the large scales are favorable to CIN or not. The Hamiltonian in (19.8) is a 
monotonic function of h, this is very helpfull when it comes to chosing the 
proper dependence on the large-scale variables. In practice, h, can be rep-
resented by either the large-scale subsidence of upper troposphere air, that 
cools and dries the boundary layer and thus increases the energy for CIN, or 
the large-scale fluctuations in the boundary layer temperature and moisture, 
that tends to destroy CIN energy or a certain combination of the two. Here, 
we omit the discussion about the actual coupling of the stochastic CIN to an 
actual climate model. The interested reader is referred to the research papers 
[6,9,10]. 

498 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Consistent with the Gibbs distribution, a simple dynamical model that 
systematically obeys the rules in A), B), and C), is given next. 
A configuration randomly flips at a site x, 
σηυ) = { 1 _ ? ί χ ) 
* V7 X' 
(i9.li) 
/v ' 
\ 
My) 
^νφχ, 
v 
; 
according a Markov jump process where the rate c(aj,x) 
is given by the so-
called Arrhenius adsorption and desorption rates 
( le-ßV(x) 
= 
i 
c(ax) = \ re 
, 
' 
σ' _l> 
(19.12) 
for which G(a) in (19.10) is the invariant measure. Here V(x) = H[afew(x 
= 
0)] - H[afd{x 
= 1)] = \ Σ,ζ^χ J(l(x 
~ ζ))σι(ζ) 
+ h i s t h e energy difference 
between the new configuration and the old configuration of σ/, when one 
single CIN site is destroyed, i.e., the energy that the rising parcel needs to 
provide in order for it to potentially penetrate deep in the troposphere. We 
note that a CIN site surrounded by CIN sites has a high energy to overcome 
in order to become a PAC site (rule A)) while a PAC site naturally decays 
into a CIN site and would remain so for a long time if it is surrounded by 
CIN sites (rule B)). Finally, the inclusion of the external potential h account 
for the effects for the effect of the large-scale dynamics, i.e., rule C). 
Here r is a parameter that represents the time scale of CIN which is typ-
ically on the order of a few minutes to a few hours. This in effect defines a 
two-state Markov chain at each site x of the lattice whose transition rates, 
<7io = e~^v^/r 
and ςοι = 1/r, depend on the state of the neighboring sites 
through the energy potential J. The construction of such Markov chains takes 
its roots from a more systematic procedure called Markov Chain Monte Carlo 
(or MCMC for short) that provides an efficient way to sample (draw random 
numbers) from a given distribution (here the Gibbs measure), especially, even 
when it is only known up to some normalization constant. It amounts to 
constructing an ergodic Markov chain whose equilibrium distribution is the 
probability distribution we wish to sample. It is easy to verify in our case that, 
at each site, our two-state Markov chain is in detailed balance with respect 
to the Gibbs measure: 
9ioG[a/(a: = 1)] = <?oiGMx = 0)]. 
In practice, the climate model gridbox is on the order of 100 to 200 km, 
which would require up to 40x40 microscopic CIN sites (in the full three-
dimensional setting) that are 2 to 5 km apart. For each grid box, we thus 
need to sample 1600 Gibbs measure at each time step of the climate model. 
This would induce astronomical computations in addition to the already high-
order complexity of the large-scale model that solves for the flow components. 
Below, we present a systematic coarse graining strategy that permits the 

19.4 A BIRTH-DEATH PROCESS FOR CONVECTIVE INHIBITION 
499 
derivation of a single birth-death process (that counts the number of active 
CIN sites) on each climate model grid box. 
19.4.2 
The Coarse-Grained Mesoscopic Stochastic Model: Birth-Death 
Process 
We now use a systematic coarse-graining strategy to reduce the complexity of 
the microscopic CIN model. This method is first developed in [3] and used for 
the CIN model in [6]. The coarse-grained procedure starts by the definition 
of a coarse-grained stochastic process that tracks the total number of CIN 
sites in a given mesoscopic region, the climate model grid box. We introduce 
a coarse lattice Ac. Let m, q be two integers. The fine and coarse lattices are 
given by 
Λ ΞΞ — Z Π [0,1] and Ac = — Z Π [0,11. 
mq 
m 
Each cell, Dk, k = 1,..., m, on the coarse lattice is divided onto q microscopic 
cells: 
£>k = -{l,2,...,<7},Vfc = l,...,m. 
We introduce the coarse-grained sequence of random variables (stochastic pro-
cess) 
Vt(k) = Σ 
σ'.*(ί/)· 
(19-13) 
yeDk 
Then, the sequence η = {r]t(k)}k,t in (19.13) is a birth-death Markov process 
defined on the configuration space 
wm,, = {o,i,...,g}Ac, 
such that »/f (fc) increases/decreases by one according to the transition proba-
bilities 
Prob{r/t+At(A;) = n + l\m(k) = n} = Ca(k, n)At + o(At), 
Prob{r/t+At(fc) = n - l|r?t(fc) = n} = Cd{k, n)At + o(At), 
(19.14) 
Prob{^+At(k) 
= η|%(fc) = n} = 1 - (C„(fc, n) + Cd(k, n))At + o(At), 
where the coarse-grained absorption and desorption rates are given, respec-
tively, by 
Ca(k,n) = 
-[q-V(k)} 
TI 
Cd{k, n) = —^k)e~ßY(k) 
(19.15) 
7/ 

500 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
where 
V(k) = J2 JikJWk) 
+ J(0,0)(V(k) 
-l)+h, 
(19.16) 
l€Ac 
ΙφΙί 
with J is the coarse-grained interaction potential. 
It is shown in Ref. [3] that J satisfies 
J{x -y) = J(k,I) + J^T[0(j^-j),x 
eDhyeDk,k^l, 
where 
J(k, l)=m2 
I I 
J{f{r - s))drds 
J 
JDixDk 
x£Dk 
y€D, 
x£Dk 
yeDl 
and 
and the coarse-grained Hamiltonian is given by 
Η(η) = - ^ Σ Σ J(k,l)v(k)V(l) - \j(0,0) Σ V(1){V(1) - l) - Λ Σ >?(0· 
!6AcfcEAc 
ieA c 
/ e A e 
ΗφΙ 
(19.19) 
Notice the presence of the term representing the interactions between rneso-
scopic (coarse-grained) cells in the definition of the coarse-grained Hamilto-
nian. 
The canonical Gibbs measure for the coarse-grained process is given by 
Gm,qAv) 
= 
-=^—e-^^Pm,q[dq) 
Am,q,ß 
where Pmiq(drf 
is the prior distribution. It is easily verified that this distri-
bution satisfies detailed balance with respect to the coarse grained adsorption 
desorption rates: 
Ca(k, i)Gm,q,ß{ti) = Cd{k, η + 5k)Gm,q,ß(v + ök) 
Cd(k, η)βηΛ,β{η) 
= Ca{k, η + 6k)Gm,q,0(V + Sk). 
(19.20) 

19.4 A BIRTH-DEATH PROCESS FOR CONVECTIVE INHIBITION 
501 
If the interactions between coarse-grained sites are ignored, which amounts 
to reducing the number of coarse cells to one that occupies the whole climate 
model grid box, the expressions for the coarse-grained potential, V, and the 
coarse-grained Hamiltonian, H, in (19.16) and (19.19), respectively, at an 
isolated coarse site k with a spin η{1ζ) simplify to 
Vh(V(k)) = Hh(v(k)) - Hh(V(k) + 1) = J(0,0)(i?(fc) - 1) + h, 
Hh(v(k)) = -ij(0,0)r/(fc)(7?(fc) - 1) - hV(k). 
(19.21) 
According to the definition of the internal potential U in (19.9) and the defi-
nition of J(0.0) in (19.18) we have in the the case where only nearest neighbor 
interactions (L = 1) are allowed between microscopic sites 
U(N\x - y\/L + 1 ) ^ 0 <^=> x = yoTX = y± — 
(with 1/iV being the actual mesh size on the microscopic lattice), hence 
J(oo)- 
2Uo 
= -g°-
J{f)'0)- 
2 ( 9 - l ) 
q - ϊ 
Transition Probability Matrix 
According to the theory of Markov chains in Section 19.3 the transition prob-
abilities, Pt(i,j), 0 < i, j < q, to go from a state ^(k) 
— i at time t = 0 to a 
state r7t (k) = j at time t > 0 satisfies the forward equations 
Kj(t) = Cd(j + l,k)PiJ+1(t) 
+ Ca(j - 
Ι,^ΡΜ-!® 
-{CaÜ, k) + Cd(j, k))Pij(t), 
j - 0, · · · , q 
(19.22) 
The solution of this linear ODE is easily computed through the standard 
exponential formula; the transition matrix is given by 
\ptUJ')}=etA, 
(19.23) 
where A is the tridiagonal-infinitesimal generator matrix; its upper and lower 
diagonals are formed by desorption and adsorption rates, Cd(j + 1, k), Cd(j — 
1, k), respectively, while the main diagonal is the negatives of the waiting time 
rates, -(Cd(j, 
k) + Cd(j, k)). 
However, in practice, there is no need to compute this exponential matrix 
when using this model for the purpose of climate simulations. The birth-death 
Markov process can be easily simulated without having to solve directly for 
the transition probabilities. Next, we present two algorithms to accomplish 
this. An approximate algorithm that uses the acceptance-rejection technique 
based on a fixed but small time step and an exact algorithm that uses the 
inverse method to advance with random time steps. The latter is known as 

502 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Gillespie's exact algorithm after the physicist and mathematical chemist who 
first used it to simulate chemical reactions. 
19.4.3 
Acceptance-Rejection Algorithm for the Birth-Death Markov 
Process 
Given a time interval [0, ΔΓ], which can be thought of as one time step of 
the global climate model simulation, and given the external potential h at 
time t = 0, the acceptance-rejection algorithm starts by dividing the time 
interval into K equal time steps of size St = AT/K. 
We assume that St is 
small enough so that the probability for having more than one transition, 
i.e., one birth or one death, is negligible. Approximately, at any given time 
step tn = nSt, n = 0,1, · · · , K — 1, we can have either one birth, one death, or 
none. Let 2\, T2 be the times until the next birth and next death, respectively. 
These are independent exponential random variables with rates λ = Οα(ηη) 
and μ = Cd(?yn), respectively, where ηη is the state of the birth-death process 
at time tn. The approximate algorithm consists on figuring out first whether a 
transition (a birth or a death) actually occurs in the time interval [tn, tn + St]. 
This is accomplished by sampling the random variable S = min(Ti, T2), which 
is an exponential random variable with rate λ + μ. If a transition occurs it 
is then further classified as a birth or a death according to the probabilities 
P{Ti < T2} = λ/(λ + μ) and P{T2 < Tx) = μ/(λ + μ). This algorithm is 
based on the acceptance-rejection method of Section 19.2. 
Acceptance-Rejection algorithm 
1) Given the state ηη of the process at time tn, compute the birth and 
death rates λ = Οα(ηη) and μ = Cd{r]n)-
3) Draw a uniform random number, r\, on the interval [0,1). 
4) First test: if r± < 1 — (μ + X)St then (no transition occurs in time St). 
Set r/(in + St) = ηη and tn = tn + St. 
If tn < AT then goto 1) 
else continue (exactly one transition occurs) 
5) Draw a second random number, r2, uniformly distributed on the interval 
[0,1). 
6) Second test: if r2 < λ/(μ + λ) then (a birth occurs) set 7?t„+,5t = ηη + 1 
else (a death occurs) set η^+δί = Vn — 1 
7) Set tn = tn + St. If tn < AT then goto 1. 

19.4 A BIRTH-DEATH PROCESS FOR CONVECTIVE INHIBITION 
503 
In the transition classification step we have divided the interval [0,1] into two 
subintervals of sizes λ/(λ + μ) and μ/(λ + μ), respectively. The probability for 
a birth to occur is equal to the probability that the uniform random number r2 
is in [0, λ/(λ+μ)] and that of a death is equivalent to r2 being in (λ/(λ+μ), 1]. 
19.4.4 
Gillespie's Exact Algorithm 
Instead of dividing the time interval into fixed small subintervals, we directly 
sample the exponential distribution S = min(Ti, T2) to compute the (random) 
time, s, at which the first transition occurs, by using the inverse-method 
presented in the previous section. If s < AT (where again AT is the large-
scale time step of the climate model), then we accept the transition and further 
classify it as a birth or a death as in the previous algorithm. This is repeated 
until the cumulative time reaches or exceeds AT. 
Gillespie's Exact-Inverse-Method Algorithm 
1) Given the state r/t of the process at time t, 0 < t < AT. 
2) Draw a uniform random number r\ from [0,1] and set s = —jrrr ln(ri). 
3) If s +1 > AT, then set t = AT and terminate the algorithm. 
Otherwise (the transition is accepted) we draw a second uniform random 
number r2 in [0,1]. 
4) If r2 < λ/(λ + μ), set 7?t+s = Vt + 1· 
otherwise set ^+s = rjt — 1. 
5) Set t = t + s. If t < AT goto 1. 
Notice that this algorithm does not assume that at most one transition occurs 
at each time step, instead, it finds the exact time when the first transition 
occurs. This is the reason why it is called the exact algorithm. When the time 
step 6t is chosen carefully so that the probability for more than one transition 
is very small, the two algorithms provide practically the same results. How-
ever, in addition to not having to worry whether St is sufficiently small, the 
exact algorithm has the advantage of not using unnecessary steps where no 
transitions occur—which is typical for the acceptance-rejection method, and 
it is thus more efficient. 
19.4.5 
Numerical Tests 
Here we implement and test the Monte Carlo algorithm above for the birth 
and death process with the adsorption and desorption rates in (19.15) in the 

504 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
absence of the external field: h = 0. We assume a single-uncoupled mesoscopic 
cell of size q. 
In Figures 19.5, 19.6 and 19.7 we plot the time evolution of ty/q for both 
a single realization (top of the figure) and the average over 100 realizations 
(bottom panel) for the values ßJQ = -4,0,2 and q = 5, q = 10 and q — 40, 
respectively. 
Independently on q, we observe that when ßUo is positive (attractive po-
tential) the process tends to equilibrate around the maximum level q (CIN 
site), when ßUo = 0 (no local interactions) it equilibrates around the middle 
point q/2, and when ßUo < 0 (repulsive potential) it tends to the low CIN 
level 0, i.e., a PAC state. This behavior can be explained as follows: 
• When ßUo > 0 the factor e~@J° is a small positive number and so the 
birth (adsorption) rate dominates the (death) desorption rate expect at 
the highest level q when it is zero. Thus, the process oscillates some-
where close to the state % = q-
• When ßUo = 0, the two rates are comparable; the desorption rate is 
higher for j > q/2 whereas the adsorption rate is higher when j < q/2, 
and they are equal at q/2. 
Hence, the process oscillates around the 
middle q/2 where the births and deaths are balanced. 
• When ßUo > 0, the adsorption rate dominates except near the state 
j = 0, where the death rate is effectively zero. Hence, the process will 
oscillate in the vicinity of the low CIN level (PAC state). 
19.5 
A BIRTH-DEATH PROCESS FOR CLOUD-CLOUD 
INTERACTIONS 
This section presents a multidimensional birth-death stochastic process to 
capture the random interactions between the three cloud types that charac-
terize organized tropical convection. This model has first appeared in [4] and 
it is somewhat in the refining stage in order to be implemented in an actual 
climate model. At this point, it is mainly used by the research group who 
created it and their collaborators in the context of idealized climate models 
used for pure research work. 
We aim to represent the unresolved variability of organized tropical convec-
tion in a typical large-scale climate simulation with a mesh size of 100 to 200 
km. We consider a horizontal grid box for the tropical troposphere, above the 
planetary boundary layer, of rectangular shape, divided onto a lattice of n x n 
lattice points or sites. The parameter n is a positive integer on the order 100 
or less so that the lattice sites are 1 to 5 kilometers apart, the typical scale 
for an individual cloud. We assume that each lattice site is either occupied 
by a certain cloud type (congestus, deep, or stratiform) or it is a clear sky 
site. A given site will switch from a given configuration to an other according 

19.5 A BIRTH-DEATH PROCESS FOR CLOUD-CLOUD INTERACTIONS 
505 
birth-death single realization: q=5, %t=3 hours, h s 0 
2 
4 
6 
8 
10 
12 
14 
16 
18 
20 
time (nondim units, T= 8 hours, 1E+6 iter.) 
birth-death average over 100 realizations: q=5,x.=3 hours, h = 0 
0.7 
?» 
Λ^^^Ψ^Φ^Φ^φ^ 
**ι*^^*Α^ΛΛ^Λ^Νι/ϊ^ν%Μ^*^^ν« 
8 
10 
12 
14 
16 
18 
time (nondim units, T= 8 hours,1 E+6 iter.) 
Figure 19.5 
Evolution in time of the random process »?t/<?· Top: single realization, 
bottom: average over 100 realizations, 77 = 3 hours, q = 5. 

506 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
birth-death single realization: q=10, τ.=3 hours, h = 0 
4 
6 
8 
10 
12 
14 
16 
time (nondim units, T= 8 hours, 1E+6 iter.) 
birth-death average over 100 realizations: q=10, τ.=3 hours, h = 0 
ßJo=2 
ß j = 0 
»wi/wV^Vw^^ 
0.2 
ßJo="4-
W*&Af*aW**toWv*i^^ 
4 
6 
8 
10 
12 
14 
16 
time (nondim units, T<= 8 hours, 1 E+6 iter.) 
Figure 19.6 Same as in Figure 19.5 but for q = 10. 

19.5 A BIRTH-DEATH PROCESS FOR CLOUD-CLOUD INTERACTIONS 
507 
,1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
0 
2 
4 
6 
8 
10 
12 
14 
16 
18 
20 
time (nondim units, T= 8 hours, 1 E+6 iter.) 
birth-death average over 100 realizations: q=40, τ =3 hours, h = 0 
0 2 
^f*^y^t*#<&^iK0+*^(»iM^&*****t'«i/v*wi+,»*^*^sy*+vfi·**·*,*!'* 
0.1 -
, l 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
0 
2 
4 
6 
8 
10 
12 
14 
16 
18 
20 
time (nondim units, T= 8 hours,1E+6 iter.) 
Figure 19.7 
Same as in Figure 19.5 but for q = 40. 

508 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
0 
2 
0 
1 
1 
3 
0 
1 
0 
2 
1 
0 
2 
0 
0 
3 
Figure 19.8 
Lattice cloud model. A given lattice site is either clear sky (0) or 
occupied by a congestus cloud (1), a deep convective cloud (2), or a stratiform anvil 
cloud (3). 
to some probability rules, which depend on the large-scale resolved variables. 
We thus construct a stochastic process at each lattice site taking the discrete 
values from 0 to 3 according to whether it is a clear sky site or it is occupied 
by a certain cloud type, as shown in Figure 19.8. 
Let X\ denote the state of site i of the lattice, i = 1, · · · , n x n, at time t: 
if site i is clear sky, 
if site i is occupied by a congestus cloud, 
, Q _ .. 
if site i is occupied by a deep convective cloud, 
if site i is occupied by a stratiform anvil. 
X\ is a Markov chain with the transition probabilities, 
P}k = Prob {Xt+At 
= k/X\ = l} = R\kAt + o(At), 
(19.25) 
for I, k = 0,1,2,3, and / φ k 
and 
3 
Ρί^ Prob {Xi+At=l/XI 
= 1} = 1- 
Σ 
Ρΐ"> 
(19·26) 
fc=0,fc^ 
where At > 0 is a small time increment and the -Rjfc's are prescribed transition 
rates. For simplicity, we ignore the direct-local interactions between sites and 
assume that the rates R\k depend solely on the large-scale resolved variables 
according to the following intuitive rules of switching back and forth between 
cloud type to cloud type and from cloudy and noncloudy sites. 
xi = 

19.5 A BIRTH-DEATH PROCESS FOR CLOUD-CLOUD INTERACTIONS 
509 
1. A clear site turns into a congestus site with high probability if CAPE is 
positive and the middle troposphere is dry. 
2. A congestus or clear sky site turns into a deep convective site with high 
probability if CAPE is positive and the middle troposphere is moist. 
3. A deep convective site turns into a stratiform site with high probability 
with a prescribed conversion rate, which may or may not depend on the 
state of the environment. 
4. A cloudy site turns back to a clear sky with a certain probability ac-
cording to a prescribed decay time scale for each cloud type. 
5. It is very unlikely, during the short period of time Δί, for a clear sky or 
a congestus site to turn into a stratiform site, for a deep convective or 
stratiform site to turn into a congestus site, or for a stratiform site to 
turn into a deep convective site. 
Notice that the assumption that the transition rates depend only on the large 
scale variables, which amounts to ignoring interactions between the lattice 
sites all together, implies that the stochastic processes associated with the 
different sites are independent and statistically identical. Therefore, unless 
otherwise stated, in the rest of the chapter, we drop the superscript i and 
consider only the generic process Xt with the transition probabilities Pik and 
transition rates Ra-. 
It follows immediately from Assumption 5 that 
Ro3 = Ais = R21 = R31 = -R32 = 0. 
(19.27) 
For fixed large-scale conditions, the stochastic process is a stationary Markov 
chain with the infinitesimal generator 
—Roi — R02 
R01 
R02 
0 
D _ 
-Rio 
—Rio — -R12 
-R12 
0 
R20 
0 
R20 — R23 
R23 
R30 
0 
0 
-Ä30 
Among all the physical quantities used to describe the state of the at-
mosphere, in a given large scale numerical model, two are considered to be 
important for both triggering and maintaining tropical convection, i.e., for 
the formation and decay of the three cloud types (congestus, deep, and strati-
form). These quantities are the convective available potential energy (CAPE) 
and the relative moisture content, i.e., moistness or rather dryness of the mid-
dle of the troposphere. In practice both CAPE and the atmospheric dryness 
are well-defined functions of the large-scale moist thermodynamic variables. 
Here, we assume that both CAPE and dryness are two external parameters, 
denoted here by the letters C and D, respectively, varying roughly between 0 
and 2. 
(19.28) 

510 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Let 
{ ' 
Then according to the assumptions 1,2,3,4 given above, we define 
r(x) = <! A e x 
if x > °' 
v ' 
' 
0 
otherwise. 
R01 = —T(C)T(D), 
Ro2 = — r ( C ) ( l - 
T(D)), 
T01 
T02 
Äio = —T(D), 
Aw = — r(C)(l - Γ(Ζ?)), 
(19.29) 
TlO 
7"12 
Ä20 = — ( 1 " r ( C ) ) , R23 = 1/T23, 
Ä30 = 1/750. 
T20 
Note for instance that RQI is zero when C < 0 or D < 0 and approaches T^J1 
when C and Z? are sufficiently large and positive, consistent with Assumption 
1 above. Here the η^'β are prescribed time scales of formation or decay of 
the corresponding cloud type or of conversion of cloud type I to cloud type 
k. There is no obvious way to chose their values. Based on physical intu-
ition gained from observations, numerical simulations, and theory of tropical 
convection, the rule of thumb is that the cloud lifetime is on the order of 
hours, that the rate of cloud formation is much faster than that of their de-
cay, and that stratiform clouds should decay much more slowly than either 
congestus or deep. Here we consider the two extreme cases depicted in table 
19.1, to highlight some interesting features of the stochastic multicloud model 
parameterization. 
In (19.29), we assumed for simplicity that the stratiform generation and 
decay rates, Λ23 and i?3o, are both independent of the large scale parameters 
C, D. However, there is no physical reason why this should be the case and 
obviously, the results would be sensitive to such dependence. To illustrate this 
point we also consider, in addition to (19.29), an example where R23 increases 
slowly with CAPE, using the time scales associated with Case 2 of Table 19.1, 
R23 = —T(VC). 
(19.30) 
T23 
19.5.1 
The Stationary Distribution, Cloud Area Fractions, and the 
Equilibrium Statistics of the Lattice Model 
The equilibrium distribution, Ve, of the multistate Markov chain Xt intro-
duced above, is given by the left eigenvalue of the infinitesimal generator. We 
have 
-p = 1 (1 
RQI 
I 
(Rno 
+ 
^12^01 "\ EZL 
1 
(pno 
+ 
R12R01 \ 
\ 
Z \ 
fiio+«i2' 
Λ20+Λ23 V ^ 2 
R10+R12) ' fl3o Η20+Λ23 ν Λ ° 2 ^ R10+R12J V 
(19.31) 
where Z is a normalization constant, so that the entries of Ve sum to one. 

19.5 A BIRTH-DEATH PROCESS FOR CLOUD-CLOUD INTERACTIONS 
Table 19.1 
Example of prescribed values of the time scale of formation or 
decay of each cloud type or of conversion of one cloud type to another. 
Time 
T01 
Tio 
T12 
T02 
T"23 
T20 
1"30 
Description 
formation of congestus 
decay of congestus 
conversion of congestus to deep 
formation of deep 
conversion of deep to stratiform 
decay of deep 
decay of stratiform 
Case 1 
1 hour 
5 hours 
1 hour 
2 hours 
3 hours 
5 hours 
5 hours 
Case 2 
3 hours 
2 hours 
2 hours 
5 hours 
0.5 hour 
5 hours 
24 hours 
Next, we define the area fractions <Jc,crd,<Js occupied by clouds of type 
congestus, deep, or stratiform at any given time t, as the number of lattice 
sites for which Xt = l,Xt 
= 2,Xt = 3, respectively, divided by the total 
number of sites N = n x n: 
1 
N 
1 
N 
1 
N 
i = l 
i=l 
where 
1 {*,'=*} = 
The clear sky area fraction is given by 
σΓ!ί = 1 
1 
if X\ = k, 
0 
otherwise. 
In effect, the area fraction vector (<xcs,crc,CT<2,as) is given by the probability 
distribution of the generic stochastic process Xt at time t. Therefore, the equi-
librium distribution Ve in (19.31) yields the long-time statistical equilibrium 
for the filling fractions ac, σ^, σ3. 
We now use Monte Carlo to simulate the sequence of Markov chain's XI, i = 
1,2, · · · N, associated with each one of the lattice sites. We use the acceptance-
rejection algorithm for a birth-death process discussed in the previous section 
where the transition times of the different sites are assumed to be independent 
exponential random variables. A maximum of two random numbers are thus 
generated at each iteration and for each lattice site, conditional on the states 
0,1,2,3. Recall that state 0 can change to state 1 or state 2, state 1 can go to 
either 0 or 2, and 2 can go to either 0 or 3, while state 3 can go only to 0. The 
first random number determines whether we make a change or not and the 
second random number determines if we got up or down, accordingly in the 
hierarchy of states. Only one random number is generated for state 3, since 
only one change (3 to 0) is permitted. 

512 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Figure 19.9 
An example of Monte Carlo simulation of stochastic multicloud model 
with n = 20, C = 0.25, D = 0.75, and the cloud time scales are as in Table 19.1, Case 
1. (A) A snapshot picture of one typical lattice configuration and (B) time series of the 
total coverages associated with each cloud type with the equilibrium values overlaid 
(dashed lines). 
As a test case, we let C = 0.25 and D = 0.75: a relatively moist mid-
dle troposphere with a moderate but positive CAPE value. Starting with a 
random initial lattice configuration, we integrate the stochastic lattice model 
for about 100 hours, with n = 20 and the typical time scales displayed in 
Table 19.1, Case 1. A snapshot (single realization at a fixed time) of the 
lattice state is shown in Figure 19.9(a) while the associated time series of the 
area fractions for each cloud type are shown in Figure 19.9(b), with the cor-
responding equilibrium values, from (19.31), are overlaid. Starting initially 
with a random lattice configuration, the cloud coverage fractions relax quickly 
to their corresponding equilibrium values and fluctuate around them with a 
significant variability of about 5% to 25% of the total area. 
19.5.2 
Coarse-Grained Birth-Death Stochastic Model and the 
Mean-Field Equations 
Clearly, for a large number of sites of up to 100 x 100, the full Monte Carlo 
simulation of evolving the 100 x 100 Markov chains all at once is impractical. 
However, since in practice we do not need to know the microscopic configura-
tion of the lattice but only large-scale macroscopic features such as the cloud 
fractions are needed. Here, we derive a multidimensional stochastic birth-
death process for the three cloud species using a coarse-graining methodology 
similar to the one used for the CIN model, though much simpler because local 
interactions are ignored. 
Let TV = n x n be the total number of lattice sites. Let TV* be the number 
of congestus sites, N^ the number of deep convective sites, and TV* the number 
of stratiform sites, inside the lattice, at any given time t > 0. The number of 

19.5 A BIRTH-DEATH PROCESS FOR CLOUD-CLOUD INTERACTIONS 
513 
clear sky sites is N*s = N — TV* - N% — ΛΓ|, by conservation of the total number 
of sites. Next, we compute the (transition) probabilities for the numbers 
(random variables) Ν*,Ν^,Νΐ 
to go up or down by one during the small 
interval of time (t,t + St]. 
We have 
N 
Prob{Nt
c
+6t > k + l/Nl = k} = ^ Ρ π Λ { Χ * = 0} i& + ο(Δί), 
t = l 
i.e., the probability that the number of congestus sites goes up by at least 
one is the sum of all the probabilities that a given clear sky site will turn 
into a congestus site. Given that all the sites are identical, i.e., the transition 
probability fjl
fc is independent of i. Moreover, as stated above, we have [see 
(19.32)] 
Prob{X* = 1} = ^ 
= o*c, Prob{X* = 2} = ^ 
= σ«, 
(19.33) 
Prob{X* = 3} = ^ 
= σ', 
Prob{X* = 0} = ^ 
= σ*β, Vi = 1,2, ■ · · , N. 
Using the fact that the sites are independent, and the fact that the min of 
m exponential random variables of equal rates λ is an exponential random 
variable with rate m\, we arrive at 
Prob{/Vc
i+At = k + l/Nl = k} = NCSP01 + o(At) = NaRotAt 
+ o(At). 
(19.34) 
Similarly, we have 
JV 
Prob{/Vc
<+At = k - l/Nl = k} = Σ Prob{Xi = 1} (i^ 0 + P?2) + o(At) 
t = l 
= NC{RW + Ri2)At 
+ o{At), 
N 
P r o b { ^ + A i = k + l/Nl = k) = £ 
Prob{X* = 0} P&+ 
i=l 
Prob{X* = 1}P[2 + o(At) = {NcsRo2 + NcR12)At 
+ o(At), 
(19.35) 

514 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
N 
Prob{/V<+At = k- 
1/iV* = k} = £ P r o b { * t = 2} (i*, + P&) + o(At) 
j = l 
Nd(R20 + R23)At + o(At), 
N 
Prob{iVs
t+At = k + l/Nl = k} = J2 PTob{Xl
t = 2} P& + o{At) 
i = l 
= NdR23At 
+ o(At), 
N 
Prob{/Vs
t+At = k - 1/Nt = k} = £ P r o b { X * = 3} P3
l
0 + ο(Δί) 
i = l 
= NsR30At 
+ o{At). 
(19.36) 
The stochastic process iV*, x = cs,c,d,s 
form a coupled system of birth-
death Markov processes whose transition probabilities are given by (19.34) to 
(19.36), which can be easily evolved in time using Gillespie's exact algorithm 
for which the cloud coverages are recovered according to (19.33), consistent 
with (19.32). In practice, we can also view this coupled birth-death system 
as a multistate/multivariable Markov chain undergoing one of the following 
seven transitions at a time: one congestus is formed from a clear sky, one 
deep is formed from a clear sky, one congestus is converted to deep, one deep 
is converted to stratiform, or one cloudy site of type 1,2, or 3 turns to a clear 
sky site. The associated transition probabilities are given by the the original 
rates in (19.29) multiplied by the total number of sites that are subject to 
the given transition in a way which is consistent with the formulas (19.34) 
to (19.36). For example the rate of transition from clear sky to congestus is 
NcsRoi and the rate of conversion of congestus to deep is NCR\2, etc. 
The vector (N*,Nd,Nl) 
is in effect a multidimensional birth-death process 
with immigration for the three cloud populations. The birth rates are given 
by the spontaneous formation of congestus and deep clouds from clear sky 
sites, NcsRoi and NcsRot2, and the death rates are given by the natural decay 
rates of the three cloud types, NcRio, NdR2,o, NSR3Q. 
The rates of conversion 
from congestus to deep and from deep to stratiform, NcRi^,NdR2,3, 
repre-
sent the rates of immigration from one population to another. We note that 
by construction of the multicloud model the birth rate of stratiform clouds 
and the immigration from deep to congestus, from congestus to stratiform, 
from stratiform to deep, and from stratiform to congestus are all set to zero. 
Accordingly, we can easily write down the multidimensional forward equations 
of this 3D birth-death process. 
Let €χ = (1,0,0), €2 = (0,1,0), 63 = (0,0,1) denote the three canonical 
unit vectors of R 3 and let Zt = (N^,Nd,Nl) 
denote our three-dimensional 
birth-death process. Let i = (i,j,k) 
be a generic element of the state space 
{0,1, · · · , TV}3 and P y denote the transition probability matrix of Zt. Then 

19.5 A BIRTH-DEATH PROCESS FOR CLOUD-CLOUD INTERACTIONS 
515 
the backward equations are given by 
-^rPij =NcsRoif>i+e1 
j + NcsRo2Pi+€2j 
+ NcR12Pi+e2-ei 
j 
+ iVdÜ23Pi+€3-€2,j + ATcRloPl-ei J + /Vdi?2oPi-£2,j + 
NsR30Pi-e3,i 
- [Ncs(Roi + R02) + NC(R10 
+ R12) + Nd(R23 
+ R20) + NSR30] 
P , j 
i,je{0,l,---iV} 3. 
(19.37) 
We note that (19.37) is a very large system of differential equations of dimen-
sion TV3. With a typical N = 40 x 40 sites this forms a « (4 x 109) x (4 x 109) 
dimensional system. Though the solution is known is closed form as the expo-
nential of the infinitesimal matrix, its actual computation is very difficult and 
even impossible using conventional methods. Sophisticated high performance 
computing technique are needed; although the infinitesimal generator is a very 
sparse matrix (only 8 entries are non-zero on each row), its exponential is a 
full matrix. 
Nonetheless, for the purpose of climate simulations, we do not actually 
need to compute the transition matrix P y but we need only to evolve the 
three-dimensional process Zt using a Monte Carlo algorithm involving only 
the seven non-zero transition rates at each time step. The Gillespie's exact 
algorithm version for simulating the 3D birth-death process, over one climate 
model time step [0, AT], can be formulated as follows. 
Multidimensional Gillespie's exact algorithm: 
0) Let A = /Vcs(i?oi + R02) + NC(RW + Ru) + Nd(R23 + R20) + 
NSR30. 
1) Let Zt = (Nc, Nd, Ns) be the state of the system at time t, 0 < t < AT. 
2) Generate a random number r\ uniformly from (0,1). Set s = — j ln(n). 
3) If t + s > AT, then no transition occurs. Set t = AT. Stop. 
4) If t + s < AT. Divide the interval into seven subintervals Ii, I2, ■ ■ ■ ,h 
of sizes 
/Vcs-Roi NcsRp2 
NCRW 
NCR12 
NdR23 
NdR20 
NSR30 
A 
' 
λ
'
λ
'
λ
'
λ
'
λ
'
λ
' 
respectively. 
5) Generate a random number r2. 
Select the subinterval Ik such that 
r2 & Ik- Then make the corresponding transition as follows. 
- If r2 e h, then NC = NC + 1. 
- If r2 € h, then Nd = Nd + 1. 
- If r2 e I3, then Nc = Nc - 1. 

516 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
- If ra € h, then Nc = Nc - 1, Nd = Nd + 1. 
- If r2 € h, then Nd = Nd - 1, iVs = JVS + 1. 
- If r 2 € l 6 ) theaNd = 
Nd-l. 
- Ifr2 e J7, then JV8 = JVe - 1. 
6) Set ί = f + s. If i < ΔΤ got to 1. 
As one would expect, the dynamics of the area fractions obtained by 
evolving the full microscopic lattice model, described in the previous section, 
through the detailed description of each one of the stochastic processes, X\ 
are statistically equivalent to those obtained by evolving the coarse-grained 
birth-death processes just described. However, it is important to note that the 
computations are orders of magnitude cheaper in the latter case: Compare 
generating two random numbers and testing them against seven transition 
rates versus simulating each one of the n x n sites. 
19.5.3 
The Deterministic Mean-Field Equations and Numerical 
Simulations 
As for all evolving physical quantities, one can easily use standard calculus to 
derive deterministic differential equations for the cloud coverages 
ac,ad,as. 
According to the discussion above, we have the following three-by-three sys-
tem of ODEs. In the jargon of stochastic modeling they are called mean-field 
equations and can be obtained rigorously as the continuous limit when the 
number of lattice sites goes to infinity: 
&c = (1 - ac — ad — as)Roi — ac(Ri0 + R12), 
&d=(l-ac-ad- 
as)Ro2 + ocR\2 - od(R2o + R23), 
(19.38) 
<7S =CTdR23 — iTsi?30. 
Note that the growth and decay rates of the mean-field variables in (19.38) 
are given respectively by the birth, death and immigration rates in (19.37) 
that are simply normalized by the total number of sites N. This is a non-
homogeneous linear system of ODEs with a unique equilibrium solution given 
by the stationary distribution in (19.31). 
The stability properties of the mean-field equations can be used to learn 
something about the behavior of the stochastic system. In Figure 19.10, we 
plot the contours of the real and imaginary parts of the eigenvalues of the 
matrix (of the ode system) in (19.38) as functions of the parameters C and 
D, using the time scales from Table 19.1, Case 1. Recall from the standard 
theory of differential equations that an equilibrium point is said to be an 
asymptotically stable node if all the associated eigenvalues are real negative. 
Small perturbations of the equilibrium decay and the equilibrium is recovered 
when t —► 00. If at least one eigenvalue is positive it is an unstable node 

19.6 FURTHER READING 
517 
and small perturbations grow without bound. If the matrix admit complex 
eigenvalues, then the equilibrium is called an asymptotically stable spiral if 
the real parts of all the eigenvalues are negative. It is an unstable spiral if 
one complex eigenvalue has a positive real part. In the case of an asymp-
totically stable spiral, small perturbations of the equilibrium spiral in toward 
the equilibrium position while in an unstable spiral they spiral out away from 
the equilibrium position; in the first case the solution exhibits decaying os-
cillations while in the second it is characterized by oscillations that grow in 
amplitude. An equilibrium with pure imaginary eigenvalues is called a center. 
In this case the solution is characterized by constant amplitude oscillations. 
As we see from Figure 19.10, the equilibrium of the mean-field equations 
(19.38) goes from an asymptotically stable node to a stable spiral as C is 
increased from 0 to 2. In other words this system bifurcates from an expo-
nentially damped regime to an oscillatory damped regime; for large values 
of C, we have one real negative eigenvalue and a pair of complex conjugate 
eigenvalues whose real part is negative while for small values of C, and only 
slightly depending on the values of D, we have three negative real eigenval-
ues. The imaginary part increases significantly with increasing values of C, 
especially for slightly moist conditions corresponding to D between 0.2 and 
0.3. The damping strength is also sensitive to changes in C and D. 
An important nondimensional number for the stochastic multicloud model 
is given by the ratio of the frequency to the damping rate, for the complex 
conjugate pair, plotted in Figure 19.11(E). In Figure 19.11, we display two 
time series of the area coverages obtained by evolving the stochastic model 
with D = 0.4 and the two different values of C = 0.1 and C = 1.5. Accord-
ing to Figure 19.11(E), the case C = 0.1 has a frequency to damping ratio 
near zero (below 0.1) while in the second case this ratio is above 0.6. As 
it is anticipated, the two time series are qualitatively different with the one 
corresponding to C = 1.5 having sharper peaks while the one corresponding 
to C = 0.1 has much longer excursions. This suggests that a large frequency 
to damping ratio, in a complex conjugate pair for the mean-field equations, 
would yield sharp and rapid oscillations, for the associated stochastic sys-
tem, while a small ratio would yield smoother oscillations with much longer 
excursions from equilibrium. 
19.6 
FURTHER READING 
To learn more about moist thermodynamics and moist convection in general, 
we refer to the excellent book of K. Emanuel [1]. More on organized convection 
and convectively coupled waves can be found in the review papers by G. 
Kiladis et cd. [7] and C. Zhang [15]. For the theory of Markov chains and 
birth death processes, we refer to the two pedagogical books of S. M. Ross 
[12] and G. F. Lawler [2]. A good text on statistical mechanics and the Ising 
model used in Section 19.4 is found in Ref. [14]. To learn more about the 

518 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
Real part 
0 
1 
2 
(abs of) Imaginary part 
Figure 19.10 
Equilibrium eigenvalues of the mean-field equations. Panels (A), (B), 
and (C) represent the contours of the real parts of the three eigenvalues, respectively, 
as CAPE C (horizontal axis) and dryness D (vertical axis) are varied from 0 to 2, 
Panel (D) shows the imaginary part of the complex conjugate pair, and Panel (E) 
displays the ratio of the frequency over the damping rate. 
y 
1 
1 
1 
* 
1 
o1 
' 
' 
' 
' 
' 
0 
20 
40 
60 
80 
100 
0 
20 
40 
60 
80 
100 
Time in hours 
Time in hours 
Figure 19.11 
Stochastic oscillations for both (a) when the frequency to damping 
ratio is small and (b) when it is large for the parameter values D = 0.4 and C = 0.1 
and C = 1.5, respectively, and the τ/fc's are as in Table 19.1. 

EXERCISES 
519 
practice and theory of Markov Chain Monte Carlo, we suggest the book by 
C. P. Robert and G. Casella [11] and the more practically oriented text of W. 
Stewart [13]. Finally, for more general (deterministic) mathematical models 
of the atmosphere and ocean we refer to the book by J. A. Majda [8] and a 
review on recent developments in mathematical modeling for climate science 
in the tropics is found in Ref. [5]. 
EXERCISES 
19.1 
Verify statistically that the average number of iterations to gener-
ate one random number using the acceptance rejection method for the beta-
distribution in Example 19.4 above is 30/16 « 1.875. Use Monte Carlo inte-
gration based on the acceptance-rejection method to estimate the expectation 
E[X}=tixf(x)dx. 
19.2 
In this exercise we test three different approaches to generate pseudo-
normal variates, with mean zero and variance one. One is based on the central 
limit theorem, one is the polar method discussed in the notes, and the third 
is the function randn of Matlab. 
1. Method based on the central limit theorem. 
Recall that according to the central limit theorem, if Xk, k= 1,2,··· , n 
are n random numbers from a distribution with mean μ and variance 
σ2 then as n increases 
τ; ^ Σ?=ι Xk ~ 
ημ 
approaches a normal distribution with mean zero and variance one. If 
the Xfc's are uniformly distributed on [0,1] then μ = 1/2 and σ2 = 1/12. 
If in addition, we choose n = 12 then we obtain a simple formula for y: 
12 
fc=l 
is approximately normally distributed with mean zero and variance one. 
Write a short Matlab code to generate normal variates according to this 
formula by generating 12 uniform variates using the function rand of 
Matlab, sum them together and substrate 6. E.g., 
» 
y = sum(rand(l, 12))- 6; 
will generate one pseudo-random num-
ber, which is approximately λί(0,1). 
Use this as a building block to 
write a Matlab code to generate sequences of normally distributed ran-
dom numbers of arbitrary size. 
2. The polar method. 
Let χχ, Χ2 be two independent uniformly distributed (pseudo-) random 

520 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
numbers on [0,1). Then, 
?/i = sin(27nri)-v/—2 log(x2) and ?/2 = οοβ^πζι)y/—2 l o g ^ ) 
are normally distributed with mean zero and variance one. Write a 
Matlab code to generate a sequence of normally distributed random 
numbers of an arbitrary size, according to this algorithm. 
3. Generate 1000 normally distributed jV(0,1) according to each one of 
the algorithms above and according to the Matlab function randn and 
save the three sequences as three different vectors, which you may call 
Ncentral, Npolar, Nrandn, respectively. Then use the Matlab function 
hist to bin each one of three random vectors in bins of size 1. Normalize 
the bin numbers by the total samples (1000). Use the bar command 
of Matlab to plot the histogram and plot the normal density f(x) 
= 
e~x /2/y/2n on top on each one of the histogram. 
Follow the following simple Matlab instructions for the function randn 
of Matlab, as a guideline example. 
» N =1000; 
»Nrandn = randn(N,l); 
» x=-3:l:3; 
» nh = hist (Nrandn,x) ; '/.counts number of random numbers 
'/.in each subinterval centered 
» nhnormalized = nh/N; '/, 
» figure 
» bar(x, nhnormalized) 
» hold on 
»ezplot('exp(-x~2/2)/sqrt(2*pi)',[-4,4]); 
Check the validity of each one of the methods above by comparing the numer-
ical values of unit-binned histograms (nhnomalized in the Matlab code above) 
to the exact normal distribution: 
fi+.5 e-x2/2 
hi= 
—j^dx, 
% = ■·■ ,-2,-1,0,1,2,· 
H-.b 
ν2π 
= · · · ,0.5977,6.0598,24.1730,38.2925,24.1730,6.0598,0.5977, ■ ■ ■%. 
19.3 
Use the Chapman-Kolmogorov equation for p("+1) to show that the 
limiting distribution of a Markov chain satisfies -Kj = Σ ° ^ 0 i^iPij for all j > 0. 
19.4 
A taxi driver conducts his business in three different towns 1, 2, and 
3. On any given day, when he is in town 1, the probability that the next 
passenger he picks up is going to a place in town 1 is 0.3, the probability that 
the passenger is going to town 2 is 0.2 and the probability that he is going to 

EXERCISES 
521 
town 3 is 0.5. When he is in town 2, the next passenger he picks up is going 
to a place in town 1 with probability 0.1, to town 2 with probability 0.8 and 
to town 3 with probability 0.1. When he is in town 3, these probabilities are 
0.4 to go to towns 1 and 2 and 0.2 to go to a place in town 3. 
1. Argue why the underlying process of tracking the location of the taxi 
driver after dropping a passenger is a Markov chain. Write down the 
associated transition probability matrix. 
2. Given that the taxi driver is currently in town 1 and is waiting to pick 
up his first customer for the day, what is the probability that he picks 
his third customer of the day in town 2? 
3. In the long run, which of towns 1,2, 3 does the taxi driver visit the most? 
Justify your answer. 
19.5 
Let Ti,T2 be two independent exponentially distributed random vari-
ables with rates λ > 0, μ > 0, respectively. 
(a) Show that S = min(Ti,T2) is an exponential random variable with rate 
λ + μ. 
(b) Show that Ρ{Τχ < T2} = 
j ^ . 
(c) Show that if μ = λ then ΤΊ +T2 is a Gamma random variable with param-
eters a = 2 and λ and in general if Τχ, T2, · · · , Tn are n independent and 
exponentially distributed random variables, with the same rate λ, then 
the sum Sn = 7\ + T2 + · · · Tn is Gamma distributed with parameters 
n and λ; fSn{x) 
= xn-1\ne-Xx/{n 
- 1)!. 
19.6 
Show that the product of two stochastic matrices is a stochastic ma-
trix. 
19.7 
A matrix P is said to be doubly stochastic if both all of its rows and all 
of its columns sum to 1. Show that the limiting distribution of Markov chain 
on a finite state space {xo,x\, ■ ■ ■ ,XM} with a doubly stochastic probability 
transition matrix is uniform, i.e., -Kj = 1/M + 1 for j = 0,1,2, · · · , M. 
19.8 
Let X be a non-negative random variable. Show that X is exponen-
tially distributed if and only if it satisfies the memoryless property 
P{X >s + t} = P{X > s}P{X 
> t}, 
for all s, t > 0. 
19.9 
Write down the forward and backward equations for a bounded birth 
death process with birth rates λ„ and death rates μη where μο = 0 and Afc = 0 
for k > 1. Give the infinitesimal generator matrix. 

522 
CHAPTER 19. MARKOV-JUMP STOCHASTIC MODELS 
19.10 
Find the transition probabilities for a birth only process, i.e., a birth 
only process for which λ„ > 0 and μη — 0 for all n. 
Start with the case 
λ„ = λ, i.e., the birth rate is independent of n. 
19.11 
Let Xt be a continuous-time Markov chain with state space 1,2,· · · 
and associated waiting rates vi,V2,··· 
and transition rates qij, i φ j . Consider 
the first passage time Tk into state k, given by 
Tfc = min{i > 0,Xt 
= k}. 
Let rriik be the expected first passage time from state i to state k: 
m ^ = 
E[Tk/X0 
= i]. 
1. Show that 
u» m»*, = 1 + j
. Qij 
mjk-
2. Find mu 
if Xt is a four state Markov chain with rates 
<Zi,2 = 2, <?i,3 = 2, q1A = 1, ς2,l - 3, q2,3 = 3, Q2,4 = 0, 
93,1 = 0, <?3,2 — 2, 93,4 = 2, Q4,i = 1, g4)2 = 0, Q-4,3 = 3. 
19.12 
Let Xt be a continuous-time Markov chain with state space {1, 2,3} 
and rates ς1>2 = 1,<ϊ2,ι = 4,52,3 = 1,93,2 = 4,ς 1 ι 3 = ρ3,ι = 0. Find the 
probability transition matrix P(t) 
of Xt and the limiting distribution if it 
exists. 
REFERENCES 
1. Emanuel, K., Atmospheric Convection, Oxford University Press, Oxford (1994). 
2. Lawler, G. F., Introduction to Stochastic Processes, 2nd Edition, Chapman and 
Hall/CRC (2006). 
3. Katsoulakis M. A., Majda A. J., and Vlachos D. G., "Coarse-grained stochastic 
processes and Monte Carlo simulations in lattice systems", Journal of Compu-
tational Physics, Vol 186(1), 250 - 278 (2003). 
4. Khouider, B., Biello, J., and Majda, A., " A stochastic multicloud model for 
tropical convection" in Commun. Math. Sei., Vol. 8 (1), 187-216 (2010). 
5. Khouider, B., Majda, A. J., and Stechmann, S., "Climate Science, Waves, and 
PDEs for the Tropics" to appear in Nonlinearity, (2012) 
6. Khouider, B., Majda, A. J., and Katsoulakis, M. A., "Coarse-grained stochas-
tic models for tropical convection and climate", Proc. Nat. Acad. Sei., Vol. 
100(21), pages 11941-11946 (2003). 
7. Kiladis, J. N., Wheeler, M. C , Haertel, P. T., Straub, K. H., and Roundy, P. 
E., "Convectively coupled equatorial waves", Rev. Geophys., Vol 47 RG2003, 
doi:10.1029/2008RG000266 (2009). 

EXERCISES 
523 
8. Majda, A. J., Introduction to PDEs and Waves for the Atmosphere and Ocean, 
American Mathematical Society (2003). 
9. Majda, A. J. and Khouider, B., "Stochastic and mesoscopic models for tropical 
convection", Proc. Nat. Acad. Sei. USA, Vol. 99, pages 1123-1128 (2002). 
10. Majda, A. J., Franzke, C , and Khouider, B., "An applied mathematics per-
spective on stochastic modelling for climate", Philos. Trans. Roy. Soc, Vol. 
366A, pages 2427-2453 (2008). 
11. Robert, C. P. and Casella, G., Monte Carlo Statistical Methods, Springer-Verlag, 
New York (1999). 
12. Ross, S. M., Introduction to Probability Models, 10th Edition, Academic Press 
(2010). 
13. Stewart, W. J-, An Introduction to the Numerical Solution of Markov Chains, 
Princeton University Press, New Jersey (1994). 
14. Thompson, C., Mathematical Statistical Mechanics, Princeton Univ. 
Press, 
Princeton (1972). 
15. Zhang, C , "Madden-Julian Oscillation", Reviews of Geophysics, Vol. 43, RG2003 
(2005). 

PROBLEM SOLUTIONS 
SOLUTIONS FOR CHAPTER l 
1.1 Let y be the axis perpendicular to the path of its movement towards the 
east. From Newton's second law, we know that 
y = a = 2ων, 
where v is the vertical velocity, and ω is the angular velocity of the Earth. 
Here we have assume that the horizontal velocity due to the Coriolis effect 
is small, and no air is present. From basic physics, we know that v = gt where 
g is the acceleration due to gravity. We have h = \gt2, or t = ^/2h/g. 
Now the governing equation becomes 
y = 2wgt. 
Mathematical 
Modeling with Multidisciplinary 
Applications. 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 
525 

526 
PROBLEM SOLUTIONS 
By integrating y once, we have 
y = ugt2. 
Integrating it again, we obtain 
ω o 
ω 
8h3 
y=39t 
= 3 \ / Τ · 
Since ω = 2π/(24 χ 3600) radian/s, g = 9.8 m/s 2, we have y « 7.7 mm for 
h = 50 m. 
1.2 The solution is y(a;) = A/x + Bx2 where A and B are arbitrary constants. 
1.3 Using a trial solution u ~ exp(ri), we have 
(r2+27?o;or + ^ ) e r i = 0, 
or 
r2 + 27yw0r + ω%. 
Its solutions are 
r = [-η ± y/η2 - 1]ω0· 
Clearly, Δ — jy2 — 1 = 0 defines a critical case. If η = 1, it is called critical 
damping, while η > 1 corresponds to overdamping and η < 1 corresponds to 
underdamping. When η = 0, the system becomes undamped simple harmonic 
motion, and ωο is its natural frequency. When η > 0, the amplitude of the 
system will decrease with time. 
1.4 In the polar coordinate system, the Laplace equation becomes 
1 d ( du\ 
1 d2u 
[r— I H 
= 0. 
r dr\ 
dr ) 
r2 ΘΘ2 
When converting from Cartesian coordinates, differentiation rules should be 
used. 
1.5 Verify this by substitution. For more information, please refer to more 
advanced literature. 
1.6 Verify the solutions by direct substitutions. For the later case, we have 
β = 
α2λ2+ω2. 
1.7 By direct substitution u(x, i) = exp(—vt/2)w(x,t), 
we have 
d2w 
od2w 
/, 
v2\ 
Polyanin A. D. and Zaitsev V., Handbook of Nonlinear 
Partial Differential 
Equations, 
Chapman & Hall/CRC, Boca Raton, (2004). 

PROBLEM SOLUTIONS 
527 
which is indeed the Klein-Gordon equation. 
1.8 Using the transformation u(x,t) 
= §gf 
a nd differentiation rules, the 
Burgers equation becomes -£ = ^f. 
SOLUTIONS FOR CHAPTER 2 
2.1 From the kinetic energy of a moving object Ek = \mv2 and the potential 
energy due to the Earth's gravity Ep = —GMfm, the total energy must be 
zero when an object is just able to escape the Earth, so we have 
Ek+Ep 
= -mv2 
— = 0, 
whose solution is v = J2G™E. 
As g — GMß/r2 
= 9.8 m/s2, we have 
v = \/2gr = 11.17 km/s, where we have used r — 6370 km. 
2.2 Raindrops vary in size from about 0.1 mm to 5.5 mm. Now the fluid is 
the air with density pa = 1.2 kg/m3, and viscosity μα — 1.8 x 10 - 5 Pa s. For 
a very small cloud drop or raindrop d — 0.15 mm = 1.5 x 10 - 4 m with a 
density of pw = 1000 kg/m3, we can estimate its terminal velocity as 
= (pw-Pa)9d2
 
= (1000 - 1.2) x 9.8 x (1.5 x IQ"4)2 ^ 
18μα 
18 x 1.8 x lO"5 
' 
' ' 
which is about the same value as observed by experiment. In this case, the 
Reynolds number is approximately Re = ^ 2 ^ « 6.8, which is bigger than 1. 
There will be some difference between estimated values and the real velocity. 
However, for larger raindrops, their falling velocities are high, and Stokes' 
law is no longer valid. 
2.3 For the waves in deep waters when the wavelength λ is much smaller than 
h (or λ < h), we have ^χ^οο, and e x p l - 2 ^ ] ) ^ Now we get 
tanh /2π/ι\ 
e ^ — e 
* 
e ^ - 0 
\ 
\ 
/ 
27rh 
2-Kh 
2π/ι 
\ λ / 
e λ + e 
λ 
e * + 0 
which leads to 
27rh 
e * 
— 
2ΤΓΛ 
e A 
— e 
+ e~ 
-
2~Ψ 
■*l·' 
1-rh 
V 2π 
V λ / 
V 2π 
A tsunami is a giant water wave whose wavelength and speed are constantly 
changing as it travels towards the shore. In deep ocean waters, the wave 
height is typically less than half a meter, but its wavelength is in the range of 
25 km to 50 km. Let us now estimate its speed in deep water using the typical 

528 
PROBLEM SOLUTIONS 
values of λ = 25 km to 50 km (or 2.5 x 104 to 5.0 x 104 meters), g = 9.8 m/s2. 
We have the phase speed 
9 . 8 x 2 . 5 x l 0 4
 
1ft_ 
. 
AAA 
. 
sa 197 m/s « 444 mph, 
27Γ 
for λ = 25 km. For longer wavelength λ = 50 km, its speed is about 630 
mph. This means that the first arrival of tsunami waves is always of long 
wavelength. As they travel shorewards, their wavelengths become typically 
in the range of 1.5 km to 5 km, but their wave heights can reach up to 30 
metres. Their speed can reduce to 230 down to 25 mph. 
2.4 We assume that the air pressure is hydrostatic. That is, the increase of 
the pressure dp is balanced by the increment of the weight —pgdz for a thin 
layer with a unit area. Here z is the altitude above the Earth's surface and 
the — sign indicates the fact that the z increases and pressure decreases in 
atmosphere. Therefore, we have dp = —pgdz or 
dp 
Tz = -p9· 
From p = pRT/M, we have p = pM/RT, 
and we now have 
dp 
pMg 
~d~z=~ RT ' 
or 
dp = 
Mg 
p 
RT 
Z' 
Integrating from z = 0 to z = h, we have 
/ dp — In p — In on — — / 
~^=dz ——-=—;h, 
JP0 
Jo RT 
RT 
where po is the pressure on the Earth's surface at z = 0. This means that 
l n - P = - Ä . 
Po 
RT 
Taking the logarithms, we have 
P = Poe Ί , 
7 = 
^ τ · 
We can see that the air pressure decreases exponentially as the height h in-
creases. We can define a characteristic height 
T 
- 
1 
- 
R
T 
~ ß~ 
Mg' 

PROBLEM SOLUTIONS 
529 
so that 
p = 
Poe-h'L. 
For the typical values of M = 0.0289 kg/mole, g = 9.8 m/s2, and T = 293 K 
(or 2O0C), we have 
8.31 x 393 
8597 m = 8.597 km, 
0.0289 x 9.8 
which corresponds to 7 « 0.00116 m l. This means that the air pressure at 
z = L will becomes 1/e « 36.8% of the pressure on the Earth's surface. 
SOLUTIONS FOR CHAPTER 3 
3.1 In the Runge-Kutta method, the steps can be reasonably large, compared 
with other methods. Fore example, one can use h = Ax = 0.5, then the 
Runge-Kutta steps will still give very accurate results. 
3.2 From dw/dt = aw — bw2, we have 
tun+i - wn = (awb - 
bwn)At, 
which can be written as 
wn+i = Xwn — ßw^, 
λ = 1 + οΔί, β — bAt. 
Rescaling wn as un = fwn, we have 
Un+l = Au n(l - 
Un), 
which is a well-known chaotic mapping. Try to vary λ from 1 to 4 and see 
how un behavior. You will see that when λ « 4, you will see chaos and the 
final un is very sensible to the small change in u\. In essence, you will observe 
the butterfly effect. Write a simple program and see what you can observe. 
3.3 Use an explicit scheme to solve this set of equations. Try to vary the time 
steps so as to produce smooth trajectories. 
3.4 The Crank-Nicolson scheme for the heat conduction gives 
-ru^Xl 
+ (1 + 2r)u]+1 - ru^+l = ru]+1 + (1 - 2r)u] + 
ru^, 
where r = XAt/2(Ax)2. 
This forms a tridiagonal matrix system. Its von 
Newmann stability condition is 
1 -4rsin2(fcAa;/2) 
_ l + 4rsin2(A;Aa;/2)' 

530 
PROBLEM SOLUTIONS 
Since \A\ < 1 for all values of k, this method is unconditionally stable. 
3.5 This equation is a nonlinear reaction-diffusion equation, it can generate 
stable patterns such as ribbons, rings and stripes under the right conditions. 
Write a simple program to show to demonstrate this. This pattern formation 
is an important characteristics of nonlinear reaction-diffusion systems. 
SOLUTIONS FOR CHAPTER 4 
4.1 What happen if you chose to start with numbers which are related to 
each other, such as f(x) = px for x = 1, 2, 3, 4? Try out 
2 4 8 16 
0 
2 4 8 
4.2 Obviously, there is no fixed answer for this open problem. 
4.3 A reasonable value for the CO is 3.70 liters/minute. 
4.4 No fixed answer. 
4.5 What we see here is that we have to reshape the results from Excel and 
realize that 1.125 = 9/8 and that 0.125 — 1/8. This insight can be seen as an 
important part of instrumental genesis. Of course, the expression (9a;2 — l)/8 
is purer and maybe more beautiful in the eyes of most viewers. 
4.6 Obviously, there is no fixed answer, but an exponential decreasing model 
is to be expected. 
SOLUTIONS FOR CHAPTER 5 
5.1 In conductors we obtain from Ohm's Law (5.7), 
E = I j . 
σ 
Using (5.4) this equation yields 
E = -curlH. 
σ 
www.mathworks.com/matlabcentral/fileexchange/29726-pattern-formation-and-kpp-equation 
See Lingefjärd, T. (2002). Mathematical modeling for preservice teachers: A problem from 
anesthesiology. The International 
Journal of Computers for Mathematical 
Learning 7(2), 
pp. 117-143. 

PROBLEM SOLUTIONS 
5 3 1 
Now we replace this expression for E in Faraday's Law (5.3). We deduce 
ίωΒ + curl i - c u r l H j = 0 . 
Finally, Eq.(5.8) is obtained by using the constitutive law (5.6). 
5.2 For a general vector field F = Frer + F$e$ + Fzez, by developing (5.9) 
we get 
ldFz 
dFe\ 
(dFr 
8FZ 
curlF = (tW -^7)er+{-d^- 
-fr) ee 
Then, for a field of the form (5.2) this formula yields 
„HA _ _ M ^ + i »(,*)«. 
oz 
r or 
Again we can obtain 
curlcurlA = - ^ 
+ ^
-
^
H 
) «*■ 
5.3 From (5.10) and the previous exercise, 
i T i 
dH<> 
^
l 
d 
( 
u\ 
curlH= -—— e r + 
-—(rHe)ez. 
oz 
ror\ 
/ 
Multiplying this equality by l/σ and then applying the curl operator we get 
curlficurlH^) = - 
(■?-(-
\σ 
) 
\oz 
σ 
ΟΗΘ. 
d.ld{rHe).. 
) ~ Έΐί— 
«„ 
) 
ee-
dz 
dr ar 
dr 
Finally, by replacing this expression in (5.8) we easily deduce (5.11). 
5.4 Let T = —. Let us recall that for any complex number a the real part of 
a is given by 
Re(a) = -(a + ä), 
where ä denotes the complex conjugate of a. 

532 
PROBLEM SOLUTIONS 
Then, 
rT 
^ [ A(x, t) · C(x, t)dt = ^ [ Re(eiwt A(x)) · Re(eia"C(x)) dt 
T Jo 
T J0 
= ~ 
[ (eiu"A(x) + e~iultÄ(x)) 
· (eiu,tC(x) + e-iuJtC{x)) 
dt 
4 T Jo 
(
rw-t 
rr-i 
»T-1 
A ( x ) - C ( x ) / 
e2iwt dt + A(x) · C(x) / 
dt + A(x) · C(x) / 
dt 
Jo 
Jo 
Jo 
+ Ä ( X T - C ( X T / 
e- 2 i w tdij = ^ ( A ( x ) - C Ö ö + Ä(x)-C(x)) 
= 1 (A(x)-C(x) + A(x)-C(x)) = ^Re (A(x) · C(x)) · 
5.5 According to the stirred tank model, the volume of a pit lake is calculated 
as 
dV(t) 
= ^ ς . ( ί ) _ ς ο ( ί ) ) 
dt 
where 
f 0, 
if the lake is flooding 
(V(t) < Vf), 
Qo{t) = < 
^N° q,-(i), 
if the lake is full 
(V(t) = V». 
Here Vf refers to the final volume of the lake. 
Focusing on the period V(t) < Vf, the lake volume does not remain con-
stant, therefore the mass rrii(t) = yi(t)V(t) 
[see Eq. (5.31)]. Taking the time 
derivative of m,(i), we get 
By writing 
y£< as a function of dmJ^t' and after replacing 
J£> by its ex-
pression in the above equations, we have 
dyi(t) 
1 drrii(t) 
1 
dt 
W)^^ 
~ W)yi{t)Uqj{t)· 
During the lake flooding {V(t) < V) =» ς0 = 0) ^ ^ is written as 
^ψ1 
= V(i)rf(i,y(i)) + Sart(t,y(t)) + Σ^Λ(^)) 
+ Σ°«(*)?ί(*)· 

PROBLEM SOLUTIONS 
533 
By replacing (19) into (19), we obtain the equation we are looking for 
= rf (*, y(i)) + yfi [Sarf(t, y(i)) + Σ ^ . ( t , y(t)) 
J'=l 
As it can be seen, it is exactly the same as (5.34). 
5.6 In order to solve this exercise, we will go back to the situation in which 
the chemical species of interest Ei, i = 1,...,N 
are involved in a set of J 
couples of reversible reactions. The generic notation of Eq.(5.35) is used for 
this reactions, with I = 1,..., 2 J, being characterized by the fact that the 
stoichiometric coefficients satisfy Eq. (5.41). 
In this situation, the evolution of the concentration of the ith chemical 
species is given by 
where 
\ 
»=1 
»=1 
/ 
Notice that we are following a kinetic approach to describe equilibrium condi-
tions. These conditions are attained when #■ = 0, j = 1,..., J, therefore the 
equilibrium constant associated with the jth equilibrium reaction is given by 
i=l 
On the other hand, the extension of Eq. (5.52) to J couples of reversible 
reactions is written as 
ni(t) = ni4nit 
+ Σ ^ -
1 - i ^ ' - 1 ) ^ * ) . 
J'=l 
Hence, as yi = nip, 
vm=PLinit+έ(λ·j_1 
- ^'
-1)&(ί)) · 
V 
7 = 1 
' 

534 
PROBLEM SOLUTIONS 
By replacing (19) into (19) we get 
Äj = pEil1(A?'-1-^-,)JJ 
Ί λ 
Μηίί + Σ ^ - 1 - ^ ' " 1 ) ^ 
2 ί - 1 
„ 2 3 - 1 
where K | and ^ are the equilibrium constant and reaction extent of the jth 
chemical reaction. Equation (19) constitutes a nonlinear system of algebraic 
equations that must be solved for ξj, j = 1,..., J in order to obtain the 
concentration at equilibrium. 
SOLUTIONS FOR CHAPTER 6 
6.1 Taking the derivative of FL{V) = e"7(1 + e") and employing the product 
and chain rules from calculus, we get 
ΛΜ = 
dFL{v) 
du 
ev 
l + ev 
(1+e") 2 
l + ev 
1 + e" 
F{u) [1 - F{y)\ 
as required. 
6.2 Working with expression (6.1) and letting ß = ßx — ßQ, we have 
Pr( y i = l|/J) 
= 
P{Un>Uio) 
= 
Ρτ(εΜ < en + χ'φ) 
/
OO 
FEv (ε%ι + x'iß) fEv(£%i)den 
-co 
/
OO 
exp (—e-('r"+a!i/3)) e"£il exp(-e-e")<feii 
-OO 
' 
= 
J 
exp (-e _ e i 1 - e - ( £ n + x ^ ) ) e~£il dea 
J — O O 
^ 
' 
= 
/" 
exp (-e" £ i l (l + e - 1 ^ ) ) e~eil de a. 

PROBLEM SOLUTIONS 
535 
Letting t = e εη, we have that dt = —e 6ilden. 
As en —> oo, t —> 0 and as 
Ei\ —> —oo, ί —> oo. Therefore, we can rewrite the integral as 
Pr(tfi = 1| 
£-„p(-t(i+«-^)) 
dt 
1 
OC 
t=0 
1 
1 + β-'ί"' 
7* ( 0 - 1 ) 
as required. A more general version of the proof for the case of multinomial 
outcomes is available in Ref. [25]. 
6.3 The full conditional distribution n(ß\y,z) 
is proportional to 
f(z\ß)w(ß) 
and its kernel can be written as 
*{ß\y, z) oc exp 
oc exp 
- \ {(z - Χβ)' (z - Χβ) + {β - ßo)' ßo"1 (ß - ß0)} 
_ I {-ζ'χβ - β'χ'ζ + β'χ'χβ + ß'ß^ß - ß'B^ßo - ßOBö'ß} 
where we have omitted terms that do not involve ß. Collecting terms and 
using the definitions of B and ß, we have that n(ß\y, z) is proportional to 
exp 
= exp 
- i {β' (X'X + Bö1) ß-ß' 
[X'z + B^ßo) 
- (z'X + ß'oBä1) ß} 
-1-{β'Β-ιβ-β'Β-ιβ-β'Β-ιβ) 
Adding and subtracting ß'B 
xß inside the curly braces, we can complete the 
square and write 
n(ß\y,z) 
ex exp - 1 | (ß - ß)' B'1 (ß - ß) - 
ß'B'lß\ 
oc exp - Ϊ { Μ ) ' * " Μ ) } 
where the last line follows by recognizing that ß'B 
xß does not involve β and 
can therefore be absorbed in the constant of proportionality. The result is the 

536 
PROBLEM SOLUTIONS 
kernel of the Gaussian density and hence we have shown that 
ß\y,z~N0,B), 
as required. 
SOLUTIONS FOR CHAPTER 7 
7.1 The definition of continuity of T requires that for any e > 0 there is a 
δ > 0 such that d(Tx, Ty) < e whenever d(x, y) < δ. For a contraction map 
T, we know that d(Tx,Ty) 
< cd(x,y), where c e [0,1). So, for any given 
e > 0 we choose δ = - if c φ 0 and δ =anything we wish if c = 0. Then we 
have 
d{Tx, Ty) < cd(x, y) < cö = e if c φ 0, 
and 
d(Tx, Ty) < cd(x, y) = 0 < e if c = 0, 
proving that T is continuous. 
7.2 We must prove that doc(x,y) 
= \\x — y\\oo = maxtej \x(t) — y(t)\ the three 
properties of a metric hold. 
1. doo(x, y) > 0 for all x, y € C(I), and άχ(χ, y) = 0 if and only if x = y. 
Because of the absolute value, doo(x,y) > 0 for all x,y € C(I). 
In 
addition, if maxte/ \x(t) — y(t)\ = 0, then \x(t) — y(t)\ — 0, sox(i) = y(t). 
And, of course, <ioo(^, x) = 0. 
2. doo(z,y) = doo(y,x) for all x,j/ € C(J); 
We see that 
doo{x,y) = ll^-j/Hoo =max\x(t)-y(t)\ 
= max\y(t) -x(t)\ 
=doo(y,x). 
3. cioo(a;, z) < d^x, 
y) + d^y, 
z) for all x,y,z 
£ C(I). 
We have 
άοο(χ,ζ) 
= 
max \x(t) - y{t)\ 
< 
max(\x(t)-y(t)\ 
+ 
\y(t)-z(t)\) 
(triangle inequality for absolute value) 
x\x(t)-y(t)\+n 
= 
doc(x,y) 
+ d00{y,z). 
< 
max|x(i) — y(t)\ + max|y(i) — z(t)\ 

PROBLEM SOLUTIONS 
537 
7.3 If x(t) is a solution to the the IVP (7.1) and (7.2), then by the steps that 
developed (7.3) in the main text, we know that (7.3) is satisfied. On the other 
hand, suppose that (7.3) holds: 
x(t)=x0 
+ 
f(x(s),s)ds. 
Differentiating with respect to t, we find that 
x'(t) = j(x0 
+ J 
f(x(s), s)ds) 
= 
f(x(t),t), 
using the Fundamental Theorem of Calculus. Furthermore, setting t = to in 
the integral equation, we find 
rto 
the definite integral above is zero. 
rto 
x(t0)=xo+ 
f(x(s),s)ds 
= x0, 
Jto 
7.4 The answers are as follows: 
(a) We can choose a and b in the definition of D as we wish. Since a;(0) = 1 
as opposed to x(0) = 0, we shift the inequality for x in the definition of 
D. Suppose we let D = {(x, t)\\x — 1| < 1, |i| < | } . Then we see that 
max |/(x)| = max \x\ = 2 < 3 = —, 
(x,t)€D 
(x,t)eD 
a 
so condition 1 in our set up is satisifed. Furthermore, we see that 
\f(x)-f(y)\ 
= 
\x-y\, 
so the Lipschitz condition 2 is satisfied with K = 1 and c = Ka = | < 1. 
(b) We calculate that x'(t) = ^e* = e* = x(t), so the ODE is satisfied. 
Since x(0) = e° = 1, the initial condition is also satisfied. We conclude 
the x(t) — e* is a solution of the IVP. 
(c) We define the Picard operator 
(Tx)(t) = x{0) + I f(x(s))ds 
= 1 + / 
x{s)ds 
Jo 
Jo 

538 
PROBLEM SOLUTIONS 
and construct the sequence of iterates xn+i = Txn as requested. Begin-
ning with xo = 1, we calculate that 
xi 
= 
TXQ = 1+1 
xods 
Jo 
= 
1+ 
Ids 
=l+t, 
Jo 
Χ2 = 
Tx\ = 1+1 
x\(s) ds 
Jo 
= 
1+ f (1 + s) ds = 1+ 
( s + y j 
= 
ΧΆ 
= 
= 
= 
X4 
= 
= 
t2 
i + t + y , 
Tx2 = 1+1 
X2(s)ds 
Jo 
1 + Γ (
1 + β + τ )
Λ = 1 + ('
+τ + τ)'0 
t2 
t3 
Tx3 = 1+1 
x3(s)ds 
Jo 
, 
/ · * / 
s2 
s3\ 
J 
( 
s2 
s3 
e 4 V 
t2 
t3 
t4 
=
 
1 + ί + τ + τ + 2ϊ-
The pattern makes it fairly clear that the sequence of iterates approaches 
the Taylor of e* = V —. 
„ n! 
n=0 
7.5 The answers are as follows: 
(a) We find that x'(t) = ft^rt 
= JJ^J 
= x2, so the ODE is sat-
isfied. Since a;(0) = γ^ 
= 1, the initial condition is also satisfied. 
This means that the x(t) = j ^ is a solution of the IVP. 
(b) We define the Picard operator 
(Tx)(t) = x{0) + I f(x(s))ds 
= l+ I 
x2{s)ds 
Jo 
Jo 

PROBLEM SOLUTIONS 
539 
and construct the sequence of iterates xn+\ = Txn for n— 1,2,3,4. 
Beginning with XQ = 1, we calculate that 
x\ 
= 
TXQ = 1+1 
(xo)2 ds 
Jo 
= 
1+ 
Ids 
=l+t, 
Jo 
x2 
= 
Τχχ = 1 + / (zi(s))2cZs 
./o 
= 
1+1 
(l + sf ds =1+ 
I (l + 2s + s2) ds 
Jo 
Jo 
= l + ( e + e» + f ^ = l + t + t» + £, 
x3 
= 
Tx2 = 1+ [ 
(x2(s))2ds 
= 
Tx2 = l + [ (x2(s))2 
Jo 
"
 1 + i ' (
1 + s + s i + j) dB 
-
 ι +ί(
ι + 2 ί + 3 8 24
34
44
5 +Η"
5 
' 
Ι + ί + ^ + ί ' + ^ 
+ ^ 
+ ^ 
+ ^ ' , 
x4 
= 
Γχ 3 = 1+1 
(x3(s))2 ds 
Jo 
£(} 
+ s + s2 + s* + ls* + lsS + ls° + 
^ ) 2 d s 
f (l + 2s + 3s2 + 4s3 + y s 4 + 4s5 + ™s6 
= 
1 
= 
1 
142 7 
86 o 
4 4 , 
, 
( 
2 
s 
4 
13 , 
2 
fi 29 7 
71 o 
86 
1 + ( S 
+ S 
+S 
+S 
+ ϊ Τ 
+ 3 S 
+ 6 3 S 
+ + 2 5 2 S 
+ 
- * 
315 
189 
126 
567 
3969 
59535 
/ o 
, 
1 + f + i* + i> + 1. + Hl5 + | (e + | t , + + J l l 8 + |L(» 
+ -??-*«> + - i - t l l + _Lf12 + J_ t13 + J_t14 
_L·^ 
315 
189 
126 
567 
3969 
59535 

540 
PROBLEM SOLUTIONS 
It is harder to see that the sequence approaches the Taylor series of the solution 
in part (a), namely 
1 
n=0 
But the early terms are certainly correct, and the number of correct terms 
increases as we progress through the sequence. 
7.6 Starting at (7.7), 
d2
2(Tx,Ty) < J 
j 
K\x{s) - y(s)\ ds 
di, 
we now suppose that t < 0. The Cauchy-Schwarz inequality gives 
/•0 
Γ /-O 
1 5 Γ 
fO 
f 
g(s)h(s)ds< 
J 
(g(s))2dsY 
\f 
(h(s))2ds 
. 
We apply the inequality with g(s) = 1 and h(s) = \x(s) — y(s)\. Then 
j 
1 · \x(s) - y(s)\ da<\j 
1 del' \j 
\x{s) - y(s)\2 ds ' 
<(-ί)4[^°|φ)-^)|2ώ]2. 
Plugging (19) into (7.7) gives 
d\{Tx,Ty) 
< 
K2 j 
(-i)i 
j 
\x(s) - y(s)\2 ds 
dt 
/■0 
/-O 
K2 j 
j (-t)\x(s) 
- y(s)\2 dsdt 
/•0 
fs 
= 
-K2 
f 
f 
t\x{s) - y{s)\2 dtds 
J —a Ja 
I tdt 
\x(s) - y(s)\2 ds 
Ja 
J —a 
= 
-K 
-K2 
'■ n2\ 
r° 
--YjJJx(s)-y(s)\2ds 

PROBLEM SOLUTIONS 
541 
< 
K2a 
2 „2 
r0 
/ 
\x(s) 
-y(s)\2ds, 
J — a 
and square rooting gives the result. 
7.7 For x, y € C(I), we calculate that 
d!(Tx,Ty) 
= 
f\f 
f(x(s),s)ds- 
[ 
f(y(s),s)ds 
Ji \Jo 
Jo 
= 
[\[\f(x(s),s)-f(y(s),s))ds 
Ji Uo 
< 
f\[ 
\f(x(s),s)-f(y(s),s)\ds 
Ji \Jo 
< 
[\f 
K\x(s)-y(s)\ds 
Ji \Jo 
dt 
dt 
dt 
We consider t > 0 first. Then 
di(Tx,Ty) 
< 
K \x(s) - y(s)\ dsdt 
/ t\x(s) — y{s)\ dsdt 
< 
K 
< 
Kadi(x,y). 
In the other hand, if t < 0 then 
di(Tx,Ty) 
< 
K \x(s) - y(s)\ dsdt 
< 
K j{-t) 
\x{s) - y{s)\ dsdt 
< 
Kadi(x,y). 
We conclude that the Picard operator T is contractive in the d\ metric with 
contractivity factor c = Ka < 1. 
SOLUTIONS FOR CHAPTER 8 
8.1 Denoting the two timing observations as y[l] and y[2], we have (from the 
calculations presented in the Example) 
x|(y[l]=y[l])~N(m[l],P[l]), 

542 
PROBLEM SOLUTIONS 
with ra[l] = 149.91 and P[l] = 147.97. The linearization of the observation 
equation about x = m[l] has 
H = ^/2gm[i] = 0.01844. 
The observation [5.45,5.60] = 5.525 ± 0.075 is interpreted as a realization 
y[2] — 5.525 of a observation y[2] having a variance of R[2] = ( χ ^ ) 2 = 
1.464 · 10~3. Finally, applying the updating formulas (8.14), we obtain the 
new posterior x|(y[l:2] = y[l:2]) ~ N(m[2],P[2]) with 
52.7, 
K[2] = P[1]H[2]T{R[2] + //[2]P[1]//[1]T)-1 
147.97 ■ 0.01844 
~ 1.464 · lO- 3 + 147.97 · (0.01844)2 
P[2] = P[l] - K[2]H[2]P[1] = 147.97 · (1 - 52.7 · 0.01844) = 4.185, 
m[2]=m[i\ 
+ 
K[2](y[2]-h(m[l])) 
2 ■ 14Q 91 
= 149.91 + 52.7 · (5.525 - \j 
*
) 
151.2. 
Frodo is now 95% certain that the chasm depth (in meters) is a number in 
the interval 151.2 ± 1.96^4.185 = [147, 155]. 
8.2 In general, the distance from a line x-i — mx\ + b and a point (x\, X2) is 
\mx\ + b — X2\/y/m2 + 1. 
The equation of the line for wall 1 is x-i — 0, and the distance is |0 · £1 + 0 — 
a^l/VO2 + 1 = I — 0Γ21 - For a point inside the room, x^ > 0 and the distance 
is yi = x2. 
The equation of the line for wall 2 is X2 — \/3(12 — xi), and the distance 
is I - VSxi + 1 2 ^ - z 2|/V3 + l = |6Λ/3 - ψχι 
- \x2\. 
For a point inside 
the room, the distance is y2 = 6\/3 — 2 X l — 
\χι· 
The equation of the line for wall 3 is x2 = V^xi, 
and the distance is 
|\/3χι —X2\/V3 + 1 = I 2 Xl ~ \xi\- 
For a point inside the room, the distance 
is y3 = ψχι 
- 
\x2. 
Thus y I (x = x) ~ N(Hx + b, R) with 
H 
0 
1 
V3 
_ 1 
•A 
_i 
2 
2 
0 
6Λ/3 
0 
R = σ2Ι, 
where σ is the standard deviation of a distance observation. 

PROBLEM SOLUTIONS 
543 
Using a flat prior, the position estimate is the posterior x|(y = y) ~ N(g, Q) 
with 
Q = {HTR-IH)-1 
= σ2 
q = QHTR-\y-b) 
= 
According to the Chebyshev inequality, the g-centered disk containing at least 
95% of the probability has radius 
"2/3 
0 
0 
2/3 
" 7.1547 ' 
1.4641 
0.05 
trace(P) 
/(4/3)(0.5)2σ2 
0.05 
= 2.58σ. 
The 95% ellipse is the set {x : (x - q)TP-1{x 
- q) < 5.99}. Here, P = ^f-7 
so the ellipse is a ς-centred circle with radius J5.99 ■ | · 0.52σ2 — σ. 
8.3 The observation function and its 2 x 2 Jacobian matrix are 
h{x) 
\s[l)-x\\ 
\s[2]-x\\ 
H = 
(X-S[1])T/\\X-8[1]\\ 
(x-a[2])T/\\x-a[2]\\ 
The cost function is 
Φ(Χ) = \(y - h(x))R-\y 
- h(x)) + 
\χτΡ~λχ, 
with R = 1027 and P = 302/. A contour plot of cost function values is shown 
below. 
20 
40 
Prom the plot it can be seen that φ has local minima near the two locations 
that satisfy the range observations exactly. If we only use the range obser-
vations, there would be ambiguity in the position solution, but because of 

544 
PROBLEM SOLUTIONS 
the prior, the cost function minimum near the origin is the unique global 
minimum. 
The Gauss-Newton method's steps can be computed using this Matlab/Octave 
script. 
m=[0;0]; P=30~2*eye(2); 
y=[108;46]; R=10"2*eye(2); 
h=0(x) [ norm(x—[100;0]); norm(x— [0;50])]; 
H=Q(x) diag(h(x))\([x-[100;0],x-[0;50]]'); 
x=m; '/, initial estimate is the prior mean 
nt=3; '/. number of GN steps 
for it=l:nt 
HH=H(x); 
S=HH*P*HH'+R; 
K=P*HH'/S; 
d=m-x-K*HH*(m-x)-K*(h(x)-y) 
x=x+d 
end 
The first three iterands of the Gauss-Newton method, starting from the 
" -7.2 ' 
3.6 
) ' -7.0700 ' 
4.1084 
ϊ ' -7.0696 " 
4.1121 
SOLUTIONS FOR CHAPTER 9 
9.1 Apply Itö's lemma to the function f(t,x) 
= exp(Xt + σχ) for a proper 
choice of λ and then set x = W(t). 
Alternatively, apply Itö's lemma to the 
function g(x) = ln(x) and then set x = S(t). 
9.2 First year calculus after you notice that (x — K)+ only contributes to the 
integral if x > K. But x is S(T) and this imposed restrictions on W(T). This 
is a random variable with known distribution (the normal distribution) and 
this leads to the stated results. 
9.3 Elementary. 
9.4 Since dS = μβ + aSdW 
taking expectations we see that cffi[5(i)] = 
ßE[S{t)]dt from which it follows that E[5(i)] = 5(0) εχρ(μί). For the second 
moment, apply Itö's lemma on f(x) = x2 calculated at x = S(t) and then 
take expectations. 
9.5 The solution of the static optimization problem is 
-=e~StVx, 

PROBLEM SOLUTIONS 
545 
-Vx 
μ-r 
Look for V in the form 
V(t,x) = e~sth{t) ln(x), 
and upon substitution into the HJB 
Mi)-
x 
(μ — r) ( 
1 
1 - -x \ -5 
1η(Λ(ί)) 
h(t) - Υ τ ψ + 1 = 0, 
\n(x) 
_\n{x) 
σ2 
V 
2 
with final condition h(T) = 0, which can be solved explicitly. 
SOLUTIONS FOR CHAPTER 10 
10.1 Let E^number of European cabinets produced each day, and C=number 
of Chinese cabinets produced each day. Then we have 
Maximize 
revenue 
= 
$Z0E + $26C 
subject to 
2.80E + 2.60C 
< 
330 (carpentry department), 
1Λ0Ε + 1.20C 
< 
220 (painting department), 
0.70E + 0.70C 
< 
130 (finishing department), 
E 
> 
58 (contract requirement), 
C 
> 
58 (contract requirement), 
E,C 
> 
0 (non-negativity). 
Using the Solver add-in in Excel we obtain that the optimal solution is to 
produce 64 units of European cabinets and 58 units of Chinese cabinets each 
day, which can lead to a total revenue of $3,428. 
10.2 Let Mi=number of Bl to make. M^ and M3 are defined similarly. Let 
i?i=number of B2 to buy. B2 and B$ are defined similarly. Then we have 
Minimize cost 
= 
$16.5Mi + $20.4ßi + $19M2 + $20.85B2 
+$22.5M3 + $24.76^3, 
subject to 
2.40Mi + 3.30M2 + 3.90M3 
< 
16,800 (Fabrication), 
0.26Mi + 0.32M2 + 0.48M3 
< 
1,800 (Inspection), 

546 
PROBLEM SOLUTIONS 
Μχ 
> 0.65(Mi + B-i) (Min make Bl), 
M2 
> 0.65(M2 + B2) (Min make B2), 
M3 
> 
0.65(M3 + B3) (Min make B3), 
Mi + Bi 
= 
2,100 (Bl Demand), 
M2 + B2 
= 
3,820 (B2 Demand), 
M3 + B3 
= 
1,820 (B3 Demand), 
Mi, M2, M 3,Bi,B 2,B3 
> 0 (non-negative integers). 
With the Excel solver, we obtain that the optimal solution is to make 1,663 
units of Bl, 2,483 units of B2, and 1,183 units of B3; buy 437 units of Bl, 
1,337 units of B2, and 637 units of B3, and the total cost is $153,797. 
10.3 Let A=number of tonnes of Cargo A loaded. B, C, D and E can be 
denned similarly. Then we obtain that 
Maximize value of shipment 
subject to 
A+B+C+D+E 
28A + 56B + 32C + 48£> + 38E 
< 
< 
$1,400A + $1,780B + $1,280C, 
+$920£>+$l,380£ 
2,450 (Weight limit), 
110,000 (Volume limit), 
0.22 * 980 < A 
< 
980 (Min and Max of Cargo A), 
0.22 * 880 < B 
< 
880 (Min and Max of Cargo B), 
0.22 * 1,980 < C 
< 
1,980 (Min and Max of Cargo C), 
0.22 * 2,300 < D 
< 
2,300 (Min and Max of Cargo D), 
0.22 * 3,680 < E 
< 
3,680 (Min and Max of Cargo E), 
A,B,C,D,E 
> 
0 (non-negativity). 
Using the spreadsheet, we find that the optimal solution is to load 215.6 tonnes 
of A, 483.2 t of B, 435.6 t of C, 506 t of D, and 809.6 t of E, which can achieve 
to the total value of $3,302,272. 

PROBLEM SOLUTIONS 
547 
10.4 Let J5i"i=number of workers starting at period i (with i = 1,2,3,4,5,6). 
Thus the model can be described as follows. 
Minimize 
staff size 
= 
Xi + X2 + X3 + X4, + X5 + Xe, 
subject to 
ΛΊ + X6 
> 4 (3AM-7AM needs), 
Xx + X2 
> 
12 (7AM-11AM needs), 
X2 + X3 
> 
17 (11AM-3PM needs), 
X3 + X1 
> 
10 (3PM-7PMm needs), 
X4 + X5 
> 
14 (7PM-11PM needs), 
X5 + Xe 
> 
5 (11PM-3AM needs), 
Xi, X2, Χ3, ΧΊ , Χ5, Xe 
> 0 (non-negativity). 
Using Excel and the Solver, we obtain that the optimal solution is to employ 
35 workers, 4 of whom start at 3 a.m., 16 start at 7 a.m., 1 start at 11 a.m., 
9 start at 3 p.m., and 5 start at 7 p.m. 
SOLUTIONS FOR CHAPTER 11 
11.1 Let v(t) = u(t)exp(at) 
and differentiate with respect to t to get 
v'(t) 
= 
av(t)+u'(t)eat 
= 
av(t) - av(t) + g(t)eat 
= 
g(t) exp(ai). 
Integrating both sides yields 
v(t) = v(0) + f g(s)eas 
ds. 
Jo 
This implies that 
u(t) = u0e-Qt + [ g(s)e-a{t-s) 
ds. 
Jo 
11.2 First, recall that the stochastic integral is a Gaussian random variable 
with mean zero and variance equal to 
Var ( j easdB{s)\ 
= ί e2asds = ^- (e2at - l ) . 

548 
PROBLEM SOLUTIONS 
But then the stochastic integral has the same probability distribution as the 
random variable 
- L ( e 2 a t - i ) 1 / 2 x y 
V2a 
where Y is a standard normal random variable, that is, Y has mean zero and 
variance equal to one and probability distribution 
P{Y<y) = 
^jyj-z2/2dz. 
We compute the expectation to be 
E iexp (ix ί eas dB(s)\ 
= E exp A - L (e2at - l ) 1 / 2 Y) 
Hence, we find the cumulant function of the stochastic integral to be 
11.3 Proceed like in Example 11.2, but now with the finite difference approx-
imations for u^(t),u 
(t) and u'{t). 
11.4 This is straightforward using the definition of an eigenvalue from linear 
algebra. 
SOLUTIONS FOR CHAPTER 12 
12.1 You win the sum 2" at the n + 1 play with probability (|) n + 1. The 
expected winning is a nonconverging sum. The expected logarithmic utility 
on the other hand is the sum Σ»=ι °ο(|)" + 1 ln(2n) which is a convergent sum. 
12.2 Assume without loss of generality that uo = 0. The first option provides 
utility «o(l)- The second option provides utility 6uo(p)- If the agent prefer 
the second it must be that SUQ{P) > uo(l) so that p = u^1 ( "°^ ' j . It is easy 
to show that since δ < 1 and UQ is strictly increasing that p > 1. 
SOLUTIONS FOR CHAPTER 15 
15.1 The resulting closed-loop transfer function Gc(s) becomes 
Y(s) 
12.46s+ 64.47 
Gc(s) 
W(s) 
39.69s1·25 + 12.46s + 65.068' 

PROBLEM SOLUTIONS 
549 
The analytical solution (impulse response) of the control system (19) is 
12.46 ^ 
(_i)fe /I2.46\ f c 
„ / 
65.068 , n r n n r 
,\ 
y(t) 
= 
> ^ — / - I 
x£fc(i, 
; 1.25,0.25 - k) 
yK '
 
3 9 ·
6 9 ^ 
fc! 
\39.69y 
*V ' 
39.69' 
' 
/ 
fc=0 
x 
' 
with zero initial conditions. 
15.2 The characteristic equation of this system is 
39.69s1'25 + 12.46s + 65.068 = 0 =s> 39.69s* + 12.46s* + 65.068 = 0. 
Using the notation w = s™, where LCM is m = 4, we obtain a polynomial of 
complex variable w in the form 
39.69u)5 + 12.46u>4 + 65.068 = 0. 
Solving the polynomial (19) we get the following roots and their arguments: 
wi — -1.17474, |arg(wi)| = π, 
w2,3 = -0.40540 ± 1.0426J, |arg(u;2,3)| = 1.9416, 
w4,5 = 0.83580 ± 0.64536J, |arg(w4,5)| = 0.6575. 
This first Riemann sheet is defined as a sector in w-plane within interval 
—π/4 < arg(u;) < π/4. Complex conjugate roots «^4,5 lie in this interval and 
satisfied the stability condition given as |arg(tt;)| > | , therefore the system is 
stable. The region where |arg(w)| > j is not physical. 
15.3 Characteristic equation of the system (15.91) with the parameters (15.94), 
orders qi = q2 = 0.98 = 98/100, q3 = 0.99 = 99/100, q4 = 0.97 = 97/100, 
with m — 100, for Jacobian (15.90) and slope a is 
Λ392 _ λ294 + 
0 1 λ293 _ 
m 1 9 6 
+ 
1 2 . 9 λ 1 9 5 _ 2 ? 2 λ 9 7 = 
0> 
and for Jacobian (15.90) and slope b it has form 
λ392 + 
4 λ294 + 
0 U 2 9 3 _ 7 λ196 + 
1 3 - 4 λ 1 9 5 + 3 g ^ 9 7 = 
Q 
Both above characteristic equations are polynomials of very high order and 
it is difficult to find the roots of such polynomials analytically. Because of 
this reason we can use a Matlab routine roots(). To remain system chaotic, 
there should be at least one root λ in unstable region, it means that |arg(A)| < 
7r/(2m) = π/200. This condition is satisfied for roots λι = 0 and \2 
~ 
1.0120565137 of slope a and λι = 0 and λ2,3 ~ 1.0107809162 ±0.0153011315j 

550 
PROBLEM SOLUTIONS 
of slope b. Such an equilibrium point is an unstable focus-node. These results 
confirm the results obtained via simulations and presented in Section 15.5.2. 
15.4 General numerical solution of the fractional-order Chen's system (15.72), 
obtained by method (15.14), has the following form: 
k 
x(tfc) 
= 
{a(y(tk-1)-x{tk-1)))h«-'£cj'l)x(ti<-j)> 
k 
y(ifc) 
= 
(di(ifc) - x(tfcMtjb-i) + cy(tfc-i)) h"2 - J ^ V * * - * ) , 
j=v 
k 
z(tk) 
= 
(x(tk)y(tk) 
- 6z(ifc-i)) h"3 
-^c^zitk-j), 
j=v 
where d — (c — a), TSim is the simulation time, k = 1, 2,3 ..., N, for TV = 
[Tsim/h], and (x(0), 2/(0), z(0)) is the start point (initial conditions). The 
binomial coefficients cf 
, Vi, are calculated according to relation (15.13). The 
parameters of the Chen system are: a = 35, b = 3, c = 28, d = —7, and orders: 
Qi = 0.8, q2 = 1.0, 
9 3 = 0.9. 
SOLUTIONS FOR CHAPTER 16 
16.1 LINGO provides the following solutions: x\ = 175, x2 = 0, and x% = 
108.3333. All deviations are equal to zero, which means that the achievement 
levels match exactly the goals. 
16.2 This model differs from the previous one because the second goal has 
been modified. In this case LINGO provides the following solutions: x\ = 
750.0000, Χ2 = 0, and x$ = 0. Furthermore, d^ = 250, which means that the 
achievement level of the first objective does not match its goal. 
16.3 LINGO provides the following solutions: x\ = 740, x2 = 0 and £3 = 0. 
The values of the deviations are, respectively, if = 0, δ^ = 240.0000, <5J = 20, 
and δ£ = 0. 
16.4 a) The random variable Y assigns the following values with associated 
probabilities: 
f 1 
Pi =0.1, 
Y = ) 4 
p2 = 0.2, 
[ 9 
P3 = 0.7. 
The expected value and the variance are equal to 7.2 and 14.304, re-
spectively. 

PROBLEM SOLUTIONS 
5 5 1 
b) The deterministic equivalent problem is the following: 
min 0.1(5+ + O.lJf + 0.4J+ + 0.4^, 
subject to 
7.2x1 +X2+ 3x3 + δϊ - 5+ = 500, 
2xi - 4x2 - 7.2x3 + &Γ - <5+ = 25. 
LINGO provides the following solutions: xi = 63.53734, X2 = 0, and 
X3 = 14.17704. All deviations are equal to zero. 
SOLUTIONS FOR CHAPTER 17 
17.1 Elementary. 
17.2 Let player 1 be the veto player without loss of generality. Then v(C) = 0 
if 1 i C and v{C) = 1 if 1 e C. 
17.3 This is the maximum sum of utilities the members of the coalition may 
guarantee against the worst possible attack on their profit by those outside 
the coalition. Transferable utility means we are allowed to add utilities so 
this suggestion makes sense. In terms of mixed strategies this is the Von 
Neumann-Morgernstern suggestion. 
SOLUTIONS FOR CHAPTER 18 
18.1 The solution of x'(i) = Ax(t) can be expressed as 
x(t) = eAtC, 
C = ( C i , · · · ,C„) T, CiGR, i = !,-■■ ,n. 
(19.39) 
We try to find the solution of (18.8) as the form of (19.39) with 
C(i) = (Ci(i),---,C„(i)) T. 
Substituting x(f) into (18.8). We have 
eAtC'(t) 
= Bu(t). 
Hence, 
C{t)= 
e-AsBu(s)ds 
+ C(t0). 
Moreover, taking the initial data χ(ίο) = χο into account, the solution of 
(18.8) could be the form we expected in the formula (18.10). 

552 
PROBLEM SOLUTIONS 
18.2 Suppose z(t) = a1x3+a2x2+a3x+ai. 
Since z(0) = 1, z'(0) = 0, z{\) = 0 
and z'(l) = 0, we have the following linear equations: 
a4 
= 
1, 
a3 
= 
0, 
ai + a-2 + a,3 + CLA = 
0, 
3ai + a2 + a3 
= 
0. 
Hence, 
z(t) = \x3 - \x2 + 1. 
Consequently, 
1 
3 
u(t) = z"(t) + z = -x3 - -x2 + 3x - 2 
is one of the controls driving (1,0) at t = 0 to the state (0,0) at t — 1. 
18.3 i7 is continuous if 
lim (J((ipo,Vi) 
+ Κψ0,ψ1)) 
- J(<p0,fi)) 
= 0 
h—>0 
for any (φο,φι), (ψο,Φι) £ L2(fl) x i7_1(ii). Indeed, it is true since 
J((<A), Ψ\) + ΗΦο, Ψι)) - J(<Po, ψ\) 
\ J 
f ((φ + Ιιψ)2-<p2)dxdt-h(^(0),y0)-ι,ι-h 
J 
i>(0)yidx 
= 
h ( ^ T / M - ^ 2 ) ώ * - <^(0),j/o)-M - jT ^(O)yidxJ . 
Now we show that J is strictly convex. Set t € (0,1). We compute 
J(% 0,¥>i) + (l-i)WO,^i)) 
= tJXvo, ¥>i) + (1 - t)J(i/H), Ψι) - 
~ 
J 
IΓ \ψ- 
M2dxdt. 
However, the observability inequality (18.29) tells us that 
C\\(vo-i>o^i-ipi)fL2{n)xH-i{n) 
^ / 
/ \<p-ii>\2dxdt. 
JO 
J ω 
Since {φο,ψι) φ (Φο,Φι), the left-hand side of (19) is strictly positive. Sub-
stituting (19) into (19), we arrive at 
J(t{fo, 
ψχ) + (1 - i)W>o,Φι)) > tJ(<po, <Pi) + (1 - t)J(il>o,il)i) 

PROBLEM SOLUTIONS 
553 
and J is strictly convex. 
18.4 Let (φο, φι) be the minimizer of J. Recalling (18.24) and let the control 
function be u = φ1ω. By taking (φο,φι) as the test function of (18.24), it 
holds 
rT 
ΜΙζ,2((0,Γ)χω) 
j j \φ\2άχάί = <^(0),yo)-i,i - J <p(0)yidx. 
Meanwhile, for the control v and test function (φο,Φι), (18.24) gives 
•^r(0),j/o)-i,i - / φ{ϋ)νιάχ= 
l 
l υφάχάί. 
at 
Jn 
Jo Ju, 
Substituting the above equation into the previous equation, we compute 
rT 
= 
υφάχάί 
< ||w||L2((0,r)xu;) \\<P\\i 
JO 
Jui 
^\Ιπ(0,Τ)Χω) 
= / 
/ νψ"*™- 
^ 
ΙΙνΙΙί,2((0,Γ)χα>) 
\\Ψ\\^((0,Τ)χω) 
/O 
Ju 
llL2((0,T)xw) I! UIIL 2((0,T)XUI) 
and Corollary 1 holds. 
SOLUTIONS FOR CHAPTER 19 
1 9 . 1 '/X/iaccept.reject.m 
mx/x/x/x/x/x/x/x/x/x/. 
function 
[Ex,ANT]=accept_reject(N) 
'/.'/.Ejc=erpectation, ASR=avergae success rate 
r a n d C s t a t e ' ,0) 
X=zeros(N,l); 
NT=X; 
for 1=1:N 
nr =1; 
nt=0; 
while(nr==l) 
nt=nt+l; 
Ul=rand(l);U2=rand(l); 
if(U2<=16*(U1"2-2*U1-3+Ü1"4)) 
X(I)=U1; 
nr=0; 
end, end 
NT(I)=nt; 
end 
ANT=mean(NT); 
Ex=mean(X); 
rar/x/x/x/x/x/x/x/x/. 
» [E,N]=accept_reject(100) 
E = 0.4998 N = 1.7100 
» [E,N]=accept_reject(1000) 
E = 
0.5022 N = 
1.9250 

554 
PROBLEM SOLUTIONS 
» 
[E,N]=accept_reject(10000) 
E = 
0.5007 N = 
1.8865 
» 
[E,N]=accept_reject(100000) 
E = 0.4999 
N = 
1.8746 
19.5 Consider two independent exponential random variables, Ti,T2, with 
rates, μ, λ. We can think of two alarm clocks and consider the times 7\, T2 at 
which each one of them goes off. 
(a) First, let us compute the probability that at least one of the two clocks 
goes off during the time interval [0,t]: 
Consider the random variable: 
T = min{T1,r2} 
Prob{T > t} = Prob{Ti > t, T2 > i) 
= Prob{T! > i}Prob{T2 > i} 
= / 
με~μτάτ 
/ 
\e~XTdT 
Jo 
Jo 
— e~ßte-Xt 
_ 
ε-(μ+λ)ί 
which is the probability that no one of the alarm clocks goes during the 
time interval [0, i], hence the probability that at least one of the alarm 
clocks goes off during that time interval is 
Prob{T < t} = 1 - e-^+V* 
which is the CDF of an exponential random variable with rate λ + μ. 
(b) The probability that clock ΤΊ goes off first: 
/»OO 
Prob{Ti <T2}= 
/ 
Prob{Ti < i}rfProb{T2 = t} 
Jo 
/»OO 
= / 
(1 - 
β-λ*)μβ-μ*άί 
Jo 
POO 
- 1 - / 
με-^+^άί 
Jo 
=1- 
μ 
= 
X 
λ + μ 
λ + μ' 

INDEX 
ID, 45 
Adams-Bashforth-Moulton method, 368 
adjoint system, 465 
algorithm, 454 
algorithms, 46 
applications, 385 
Chua's circuit, 387 
electrical heater, 385 
model of cell, 391 
arc furnaces, 85 
Banach's Fixed Point theorem, 154 
visualization, 156 
Bayesian inference, 178 
black body, 28 
booster method, 345 
boundary conditions, 91, 94, 332 
branch cut, 375, 376 
branch point, 375, 376 
Brownian motion, 39 
bubble, 31 
buoyancy, 30 
calculus of variations, 36 
cardiac output, 68 
Mathematical 
Modeling with 
Multidisciplinary 
Edited by Xin-She Yang 
Copyright © 2013 John Wiley & Sons, Inc. 
Cauchy-Schwarz inequality, 161 
central difference, 47 
champagne, 30 
chaos, 314 
chemical equilibrium, 106, 107 
chemical kinetics, 106 
chemical reactions, 104, 106, 107, 109, 
112 
chemical species, 104, 106, 107, 109, 113 
climate model, 504 
Collage theorem, 157 
visualization, 157 
concentration, 73 
condensation level, 472 
conservative strategies, 430 
continued fraction expansion, 364 
contraction map, 153 
visualization, 154 
control theory, 449 
controllability, 463 
convection, 471, 517 
convection-radiation, 94 
cooperative games, 440 
coordination game, 426 
cost allocation games, 445 
curriculum, 60 
Applications. 
555 

556 
INDEX 
Decision Making, 398 
decision model, 231 
decision theory, 285, 421 
differential equations, 32, 450 
diffusion equation, 32 
eddy current model, 89 
efficient solution, 398 
electromagnetic model, 89 
elliptic equation, 54 
ELSA electrode, 86 
ELSA numerical results, 98 
enthalpy, 93 
enthalpy formulation, 93 
equilibrium, 373 
equilibrium constant, 109 
error function, 40 
Euler implicit scheme, 115 
Euler scheme, 46 
expectation, 478 
financial derivatives, 191 
finite difference, 333 
finite difference method, 45 
finite element discretization, 96 
four number problem, 64 
fractal, 307 
dimension, 310 
fractional calculus, 357 
definition, 359 
Caputo, 361 
Grünwald-Letnikov, 360 
Riemann-Liouville, 360 
Laplace transform, 361 
numerical methods, 362 
properties, 362 
short memory principle, 363 
fractional differential equation, 371 
fractional-order control 
fractional-order controller, 373 
fractional-order controllers 
PIXDS 
controller, 374 
definition, 374 
properties, 374 
fractional-order system 
linear, 371, 372 
commensurate, 372 
incommensurate, 372 
nonlinear, 373 
stability, 375 
LTI system, 379 
nonlinear system, 382 
function 
Gamma, 359 
irrational, 366 
Mittag-LefHer, 359, 371 
multivalued, 375 
rational, 364 
game of chicken, 424 
game theory, 421 
Goal Programming, 399 
heat conduction, 12, 53 
hyperbolic equation 
first-order, 50 
second-order, 51 
image, 307 
industrial mathematics, 84 
infima, 423 
Initial Value Problem (IVP), 157 
equivalent integral equation, 158 
existence-uniqueness, 158, 160 
instability measure, 383 
inverse problem, 160, 169 
inverse transform method, 483 
irradiance, 28 
Ising model, 495 
iteration method, 55 
iterative algorithm, 97, 116 
Kalman's rank condition, 457 
labor planning, 248 
Lagrange multipliers, 112 
Laplace equation, 12 
lattice model, 510 
law of large numbers, 480 
leap-frog scheme, 47 
learning, 77 
limit model, 111, 113 
linear programming, 234, 429 
Lipschitz condition, 159 
Lotka-Volterra system, predator-prey sys-
tem, 165 
magma dyke, 34 
Markov chains, 486 
Markov-jump models, 471 
Markov-jump process, 475 
mass conservation, 105 
mathematical model, 26, 31 
mathematical modeling, 23, 28, 57, 229, 
519 
mathematics, 77 
curriculum, 74 
mean, 478 
mean-field equations, 516 

INDEX 
557 
medicine, 70 
memristor, 387 
metallurgical electrodes, 85 
metallurgy of silicon, 84 
metric, 152 
du 167 
d2, 161 
properties, 152 
metric space, 152 
complete, 153 
minimax, 428 
minimax theorem, 432, 438 
mixed strategies, 428 
model formulation, 25 
Monte Carlo integration, 481 
Multi-Criteria, 398 
Multi-Criteria Decision Making, 397 
Nash equilibrium, 422, 433 
Navier-Stokes equation, 14 
Neumann minimax, 435 
numerical integration, 40 
numerical methods, 41, 220, 329 
Nusselt number, 94 
observability, 467 
ODE, 4, 33 
optimization, 184 
options, 204 
parabolic equation, 52 
parameter estimation, 28 
Pareto cone, 398 
Pareto optimal, 398 
PDE, 11, 33, 49, 330 
Picard operator, 159 
contractive in doo, 160 
contractivity in di metric, 161 
preserves C(I), 159 
pit lake, 100 
Poiseuille flow, 9 
Poisson process, 489 
political competition, 427 
power series expansion, 363 
pricing, 257, 277 
prisoner's dilemma, 423 
probability, 475 
random variables, 475 
random walk, 37 
higher dimension, 39 
recursive approximation, 366 
Reynolds number, 30 
Riemann surface, 375, 376 
risk, 285, 421 
RLC circuit, 452 
Runge-Kutta method, 46, 48, 339 
scaled problem, 110 
scientific computing, 24 
shooting method, 343 
signal, 307 
similarity solution, 33 
singular perturbation, 329 
social sciences, 285, 421 
solubility equilibrium, 112 
sparkling water, 30 
SPP, 330 
stability condition, 47, 51 
stationary distribution, 510 
statistical model, 36 
Stefan-Boltzmann law, 28 
stirred tank model, 102, 114 
stochastic models, 475 
supply chain, 229, 236 
suprema, 423 
teacher education, 57 
theory of choice, 290 
thermal model, 92 
thermodynamics, 517 
thermoelectrical modeling, 88 
time discretization, 95, 115 
time-stepping, 53 
implicit, 47 
transition probability, 501 
upwind scheme, 50 
variance, 478 
viscosity 
dynamic, 30 
kinematic, 30 
Volterra equation, 370 
volume conservation, 104 
voting power, 444 
water quality, 100 
wave equation, 12, 13, 51, 463 
weak formulation, 96 
weather derivatives, 257 
Weighted Goal Programming, 400 
Wiener process, 195 
Yosida approximation, 97, 112, 114 
zero-sum games, 432, 435 

