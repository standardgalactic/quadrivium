
SETS FOR MATHEMATICS
Advanced undergraduate or beginning graduate students need a uniﬁed foundation
for their study of mathematics. For the ﬁrst time in a text, this book uses categorical
algebra to build such a foundation, starting from intuitive descriptions of mathemat-
ically and physically common phenomena and advancing to a precise speciﬁcation
of the nature of categories of sets.
Set theory as the algebra of mappings is introduced and developed as a unifying
basis for advanced mathematical subjects such as algebra, geometry, analysis, and
combinatorics. The formal study evolves from general axioms that express univer-
sal properties of sums, products, mapping sets, and natural number recursion. The
distinctive features of Cantorian abstract sets, as contrasted with the variable and
cohesive sets of geometry and analysis, are made explicit and taken as special ax-
ioms. Functor categories are introduced to model the variable sets used in geometry
and to illustrate the failure of the axiom of choice. An appendix provides an explicit
introduction to necessary concepts from logic, and an extensive glossary provides
a window to the mathematical landscape.


SETS FOR MATHEMATICS
F. WILLIAM LAWVERE
State University of New York at Buffalo
ROBERT ROSEBRUGH
Mount Allison University

  
Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo
Cambridge University Press
The Edinburgh Building, Cambridge  , United Kingdom
First published in print format 
-    ----
-    ----
-    ----
© F. William Lawvere, Robert Rosebrugh 2003
2003
Information on this title: www.cambridge.org/9780521804448
This book is in copyright. Subject to statutory exception and to the provision of
relevant collective licensing agreements, no reproduction of any part may take place
without the written permission of Cambridge University Press.
-    ---
-    ---
-    ---
Cambridge University Press has no responsibility for the persistence or accuracy of
s for external or third-party internet websites referred to in this book, and does not
guarantee that any content on such websites is, or will remain, accurate or appropriate.
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
hardback
paperback
paperback
eBook (NetLibrary)
eBook (NetLibrary)
hardback

Contents
Foreword 
page ix
Contributors to Sets for Mathematics
xiii
1
Abstract Sets and Mappings
1
1.1 Sets, Mappings, and Composition 
1
1.2
Listings, Properties, and Elements
4
1.3
Surjective and Injective Mappings
8
1.4 Associativity and Categories 
10
1.5
Separators and the Empty Set
11
1.6
Generalized Elements
15
1.7
Mappings as Properties
17
1.8
Additional Exercises
23
2
Sums, Monomorphisms, and Parts
26
2.1
Sum as a Universal Property
26
2.2
Monomorphisms and Parts
32
2.3
Inclusion and Membership
34
2.4
Characteristic Functions
38
2.5
Inverse Image of a Part
40
2.6
Additional Exercises
44
3
Finite Inverse Limits
48
3.1
Retractions
48
3.2
Isomorphism and Dedekind Finiteness
54
3.3
Cartesian Products and Graphs
58
3.4
Equalizers
66
3.5
Pullbacks
69
3.6
Inverse Limits
71
3.7
Additional Exercises
75
v

vi
Contents
4
Colimits, Epimorphisms, and the Axiom of Choice
78
4.1
Colimits are Dual to Limits
78
4.2
Epimorphisms and Split Surjections
80
4.3
The Axiom of Choice
84
4.4
Partitions and Equivalence Relations
85
4.5
Split Images
89
4.6
The Axiom of Choice as the Distinguishing Property
of Constant/Random Sets
92
4.7
Additional Exercises
94
5
Mapping Sets and Exponentials
96
5.1
Natural Bijection and Functoriality
96
5.2
Exponentiation
98
5.3 Functoriality of Function Spaces 
102
5.4
Additional Exercises
108
6 Summary of the Axioms and an Example of Variable Sets 
111
6.1
Axioms for Abstract Sets and Mappings
111
6.2
Truth Values for Two-Stage Variable Sets
114
6.3 Additional Exercises 
117
7
Consequences and Uses of Exponentials
120
7.1
Concrete Duality: The Behavior of Monics and Epics under
the Contravariant Functoriality of Exponentiation
120
7.2
The Distributive Law
126
7.3 Cantor’s Diagonal Argument 
129
7.4 Additional Exercises 
134
8
More on Power Sets
136
8.1
Images
136
8.2
The Covariant Power Set Functor
141
8.3
The Natural Map P X
 22X
145
8.4
Measuring, Averaging, and Winning with V -Valued Quantities
148
8.5
Additional Exercises
152
9
Introduction to Variable Sets
154
9.1
The Axiom of Inﬁnity: Number Theory
154
9.2
Recursion
157
9.3 Arithmetic of N 
160
9.4
Additional Exercises
165
10
Models of Additional Variation
167
10.1
Monoids, Posets, and Groupoids
167
10.2
Actions
171
10.3
Reversible Graphs
176
10.4
Chaotic Graphs
180

Contents
vii
10.5
Feedback and Control
186
10.6
To and from Idempotents
189
10.7
Additional Exercises
191
Appendixes
193
A Logic as the Algebra of Parts
193
A.0 Why Study Logic?
193
A.1 Basic Operators and Their Rules of Inference
195
A.2 Fields, Nilpotents, Idempotents
212
B The Axiom of Choice and Maximal Principles
220
C Deﬁnitions, Symbols, and the Greek Alphabet
231
C.1 Deﬁnitions of Some Mathematical and Logical Concepts
231
C.2 Mathematical Notations and Logical Symbols
251
C.3 The Greek Alphabet
252
Bibliography
253
Index
257


Foreword
Why Sets for Mathematics?
This book is for students who are beginning the study of advanced mathematical
subjects such as algebra, geometry, analysis, or combinatorics. A useful foundation
for these subjects will be achieved by openly bringing out and studying what they
have in common.
A signiﬁcant part of what is common to all these subjects was made explicit
100 years ago by Richard Dedekind and Georg Cantor, and another signiﬁcant part
50 years ago by Samuel Eilenberg and Saunders Mac Lane. The resulting idea of
categories of sets is the main content of this book. It is worth the effort to study this
idea because it provides a uniﬁed guide to approaching constructions and problems
in the science of space and quantity.
More speciﬁcally, it has become standard practice to represent an object of math-
ematical interest (for example a surface in three-dimensional space) as a “structure.”
This representation is possible by means of the following two steps:
(1) First we deplete the object of nearly all content. We could think of an idealized
computer memory bank that has been erased, leaving only the pure locations
(that could be ﬁlled with any new data that are relevant). The bag of pure points
resulting from this process was called by Cantor a Kardinalzahl, but we will
usually refer to it as an abstract set.
(2) Then, just as computers can be wired up in speciﬁc ways, suitable speciﬁc map-
pings between these structureless sets will constitute a structure that reﬂects
the complicated content of a mathematical object. For example, the midpoint
operation in Euclidean geometry is represented as a mapping whose “value” at
any pair of points is a special third point.
To explain the basis for these steps there is an important procedure known as the
axiomatic method: That is, from the ongoing investigation of the ideas of sets and
ix

x
Foreword
mappings, one can extract a few statements called axioms; experience has shown
that these axioms are sufﬁcient for deriving most other true statements by pure
logic when that is useful. The use of this axiomatic method makes naive set theory
rigorous and helps students to master the ideas without superstition. An analogous
procedure was applied by Eilenberg and Steenrod to the ongoing development of
algebraic topology in their 1952 book [ES52] on the foundations of that subject as
well as by other practitioners of mathematics at appropriate stages in its history.
Some of the foundational questions touched on here are treated in more detail in
the glossary (Appendix C) under headings such as Foundations, Set Theory, Topos,
or Algebraic Topology.
Organization
In Chapters 1–5 the emphasis is on the category of abstract sets and on some very
simple categorical generalities. The additional century of experience since Cantor
has shown the importance of emphasizing some issues such as:
(1) Each map needs both an explicit domain and an explicit codomain (not just a
domain, as in previous formulations of set theory, and not just a codomain, as
in type theory).
(2) Subsets are not mere sets with a special property but are explicit inclusion
maps. (This helps one to realize that many constructions involving subsets are
simpliﬁed and usefully generalized when applied appropriately to maps that
are not necessarily subsets.)
(3) The algebra of composition satisﬁes the familiar associative and identity rules;
other basic concepts, such as “belonging to” (e.g., membership in, and inclu-
sion among, subsets) and the dual “determined by” are easily expressible as
“division” relative to it. It turns out that this adherence to algebra (showing that
“foundation” does not need a language distinct from that of ordinary mathe-
matics) has broad applicability; it is particularly appropriate in smoothing the
transition between constant and variable sets.
(4) Becausefunctionalsplaysuchakeyroleinmathematics,thealgebraisexplicitly
strengthened to include the algebra of evaluation maps and induced maps.
All of these issues are elementary and quite relevant to the learning of basic
mathematics; we hope that mathematics teachers, striving to improve mathematics
education, will take them to heart and consider carefully the particular positive role
that explicit formulations of mathematical concepts can play.
Beginning in Chapter 6, examples of categories of cohesive and variable sets are
gradually introduced; some of these help to objectify features of the constant sets
such as recursion and coequalizers.

Foreword
xi
We illustrate the use of the maximal principle of Max Zorn in Appendix B, and
we include a proof of it in the form of exercises with hints. Several other results that
do not hold in most categories of variable or cohesive sets, such as the Schroeder–
Bernstein theorem and the total ordering of sizes, are treated in the same way.
Despite our axiomatic approach, we do not use the internal language that some
books on topos theory elaborate; it seemed excessively abstract and complicated
for our needs here.
Appendix A presents essentially a short course in “all that a student needs to
know about logic.” Appendix B, as mentioned, brieﬂy treats a few of the special
topics that a more advanced course would consider in detail. Appendix C provides
a glossary of deﬁnitions for reference. Some of the glossary entries go beyond bare
deﬁnition, attempting to provide a window into the background.
Some exercises are an essential part of the development and are placed in the
text, whereas others that are optional but recommended are for further clariﬁcation.
F. William Lawvere
Robert Rosebrugh
June 2002


Contributors to Sets for Mathematics
This book began as the transcript of a 1985 course at SUNY Buffalo and still
retains traces of that verbal record. Further courses in the 1990s at Buffalo and at
Mount Allison followed. We are grateful to the students in all those courses for
their interest, patience, and careful reading of the text, and in particular to the late
Ed Barry for his detailed set of notes and his bibliographical material.
John Myhill made the original course possible and also contributed some incisive
observations during the course itself. Max Zorn sent an encouraging postcard at
a critical juncture. Saunders Mac Lane strongly urged that the original transcript
be transformed into a book; we hope that, sixteen years later, the result of the
transformation will approach fulﬁllment of his expectations.
Several people contributed to making this work a reality, starting with Xiao-Qing
Meng, who was the original teaching assistant. By far the most creative and inspiring
contributor has been Fatima Fenaroli, who worked tirelessly behind the scenes from
the very beginning, and without whose constant collaboration the project would
never have come so far. Indispensable have been the advice and support of Steve
Schanuel; his mathematical insight, pedagogical sense, and unfailing ability to spot
errors have assisted through the many stages of revision.
Ellen Wilson typed the ﬁrst TEX version, which was the basis for further revi-
sions. Some of those revisions were made in response to constructive criticism by
Giuseppe Rosolini and Richard Wood, who gave courses (at Genoa and Dalhousie,
respectively) using the draft manuscript, and by the anonymous referees. Federico
Lastaria and Colin McLarty studied the manuscript and contributed several im-
provements. The drawings in xy-pic were created by Francisco Marmolejo. The
transformation into the current volume was made possible by our editor Roger
Astley and by Eleanor Umali, who managed the production process.
We are grateful to Rebecca Burke for her patient, understanding encouragement
that was crucial to the completion of this work, and for her hospitality, which made
our collaboration enjoyable.
All of these people have contributed toward the goal of concentrating the ex-
perience of the twentieth century in order to provide a foundation for twenty-ﬁrst
century education and research. Although our effort is only one of the ﬁrst steps in
that program, we sincerely hope that this work can serve as a springboard for those
who carry it further.
F. William Lawvere and Robert Rosebrugh
xiii


1
Abstract Sets and Mappings
1.1 Sets, Mappings, and Composition
Let us discuss the idea of abstract constant sets and the mappings between them
in order to have a picture of this, our central example, before formalizing a math-
ematical deﬁnition. An abstract set is supposed to have elements, each of which
has no structure, and is itself supposed to have no internal structure, except that the
elements can be distinguished as equal or unequal, and to have no external structure
except for the number of elements. In the category of abstract sets, there occur sets
of all possible sizes, including ﬁnite and inﬁnite sizes (to be deﬁned later). It has
been said that an abstract set is like a mental “bag of dots,” except of course that
the bag has no shape; thus,
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
may be a convenient way of picturing a certain abstract set for some considerations,
but what is apparently the same abstract set may be pictured as
•
•
•
•
•
•
• •
•
•
•
•
•
•
• •
•
•
•
•
•
•
•
for other considerations.
1

2
Abstract Sets and Mappings
What gives the category of sets its power is the concept of mapping. A mapping
f from an abstract set A to an abstract set B is often explained through the use of
the word value. (However, since the elements of B have no structure, it would be
misleading to always think of these values as quantities.) Each mapping f from A
to B satisﬁes
for each element x of A
there is exactly one element y of B
such that y is a value of f at x
This justiﬁes the phrase “the value”; the value of f at x is usually denoted by
f (x); it is an element of B. Thus, a mapping is single-valued and everywhere deﬁned
(everywhere onits domain)asinanalysis,butitalsohasadeﬁnitecodomain(usually
bigger than its set of actual values). Any f at all that satisﬁes this one property is
considered to be a mapping from A to B in the category of abstract constant sets; that
is why these mappings are referred to as “arbitrary”. An important and suggestive
notation is the following:
Notation 1.1: The arrow notation A
f  B just means the domain of f is A and
the codomain of f is B, and we write dom( f ) = A and cod( f ) = B. (We will
usually use capital letters for sets and lowercase letters for mappings.) For printing
convenience, in simple cases this is also written with a colon f : A
 B. We
can regard the notation f : A
 B as expressing the statement dom( f ) = A &
cod( f ) = B, where & is the logical symbol for and.
For small A and B, a mapping from A to B can be pictured using its cograph or
internal diagram by
A
B
•
•
•
•
•
•
•
•
•
f
where f (x) is the dot at the right end of the line that has x at its left end for each
of the three possible elements x.
Abstract sets and mappings are a category, which means above all that there is
a composition of mappings, i.e., given any pair f : A
 B and g : B
 C there
is a speciﬁed way of combining them to give a resulting mapping g ◦f : A
 C.
Note that the codomain set of the ﬁrst mapping f must be exactly the same set
as the domain set of the second mapping g. It is common to use the notation ◦
for composition and to read it as “following,” but we will also, and much more

1.1 Sets, Mappings, and Composition
3
often, denote the composite “g following f ” just by g f . A particular instance of
composition can be pictured by an external diagram or by an internal diagram as
below. First consider any three mappings f , g, and m with domains and codomains
as indicated:
A
B
C
•
•
•
•
•
•
•
•
•
•
••
A
B
C
f
g
m
External Diagram
Internal Diagram
f
m
g
The internalcograph diagrams expressthefullinformationaboutparticularmaps,
which is often more than we need; thus, we will use simple, external diagrams
wherever possible.
Since any mapping satisﬁes restrictions of the kind “for each . . . there is exactly
one . . . ,” in the diagram above, we observe that
r for each element a of A there is exactly one element b of B for which b is a value
of f at a (brieﬂy f (a) = b);
r for each element b of B there is exactly one element c of C for which c is a value
of g at b (brieﬂy g(b) = c);
r for each element a of A there is exactly one element c of C for which c is a value
of m at a (brieﬂy m(a) = c).
The external diagram above is said to be a “commutative diagram”, if and only if
m is actually the composite of g following f ; then, notationally, we write simply
m = g f .
More precisely, for the triangular diagram to be considered commutative, the
relation between f, g, m must have the following property:
For each element a of A we can ﬁnd the value of m(a) by proceeding in two
steps: ﬁrst ﬁnd f (a) and then ﬁnd g( f (a)); the latter is the same as m(a).
(Examining the internal diagram shows that m = g f in the ﬁgure above.)
A familiar example, when A = B = C is a set of numbers equipped with struc-
tural mappings providing addition and multiplication, involves f (x) = x2 and
g(x) = x + 2 so that (g ◦f )(x) = x2 + 2. The value of the composite mapping
at x is the result of taking the value of g at the value of f at x. In contexts such as

4
Abstract Sets and Mappings
this where both multiplication and composition are present, it is necessary to use
distinct notations for them.
Exercise 1.2
Express the mapping that associates to a number x the value
√
x2 + 2 as a composite
of three mappings.
♦
We need to be more precise about the concept of category. The ideas of set, map-
ping, and composition will guide our deﬁnition, but we need one more ingredient.
For each set A there is the identity mapping 1A : A
 A whose values are deter-
mined by 1A(x) = x. For any set A, this deﬁnition determines a particular mapping
among the (possibly many) mappings whose domain and codomain are both A.
On the basis of the preceding considerations we have part of the information
required to deﬁne the general notion of “category”. The ﬁrst two items listed corre-
spond to abstract sets and arbitrary mappings in the example of the category of sets.
A category C has the following data:
r Objects: denoted A, B, C, . . .
r Arrows: denoted f, g, h, . . . (arrows are also often called morphisms or maps)
r To each arrow f is assigned an object called its domain and an object called its
codomain (if f has domain A and codomain B, this is denoted f : A
 B)
r Composition: To each f : A
 B and g : B
 C there is assigned an arrow
g f : A
 C called “the composite of f and g” (or “g following f ”)
r Identities: To each object A is assigned an arrow 1A : A
 A called “the identity
on A”.
1.2 Listings, Properties, and Elements
We have not ﬁnished deﬁning category because the preceding data must be con-
strained by some general requirements. We ﬁrst continue with the discussion of
elements. Indeed, we can immediately simplify things a little: an idea of element
is not necessary as a separate idea because we may always identify the elements
themselves as special mappings. That will be an extreme case of the parameterizing
of elements of sets. Let us start with a more intermediate case, for example, the
set of mathematicians, together with the indication of two examples, say Sir Isaac
Newton and Gottfried Wilhelm Leibniz. Mathematically, the model will consist
not only of an abstract set A, (to stand for the set of all mathematicians) but also
of another abstract set of two elements 1 and 2 to act as labels and the speciﬁed
mapping with codomain A whose value at 1 is “Newton” and whose value at 2 is
“Leibniz”. The two-element set is the domain of the parameterization.
Such a speciﬁc parameterization of elements is one of two kinds of features of
a set ignored or held in abeyance when we form the abstract set. Essentially, all of

1.2 Listings, Properties, and Elements
5
the terms – parameterization, listing, family – have abstractly the same meaning:
simply looking at one mapping into a set A of interest, rather than just at the one
set A all by itself.
Whenever we need to insist upon the abstractness of the sets, such a preferred
listing is one of the two kinds of features we are abstracting away.
The other of the two aspects of the elements of an actual concrete aggregation
(which are to be ignored upon abstraction) involves the properties that the elements
might have. For example, consider the set of all the mathematicians and the property
“wasbornduringtheseventeenthcentury”thatsomeofthemathematicianshaveand
some do not. One might think that this is an important property of mathematicians
as such, but nonetheless one might momentarily just be interested in how many
mathematicians there are.
Certain properties are interpreted as particular mappings by using the two-
element set of “truth values” – true, false – from which we also arrive (by the
abstraction) at the abstract set of two elements within which “true” could be taken
as exemplary. If we consider a particular mapping such as
A
2
•
•
•
•
•
•
•
true
false
we see that all those elements of A that go to “true” will constitute one portion of A,
and so f determines a property “true” for some elements, and “not true,” or “false,”
for others. There are properties for which the codomain of f will need more than
two elements, for example, age of people: the codomain will need at least as many
elements as there are different ages.
As far as listing or parameterizing is concerned, an extreme case is to imagine that
all the elements have been listed by the given procedure. The opposite extreme case
is one in which no examples of elements are being offered even though the actual
set A under discussion has some arbitrary size. That is, in this extreme case the
index set is an empty set. Of course, the whole listing or parameterization in this
extreme case amounts really to nothing more than the one abstract set A itself.
Just short of the extreme of not listing any is listing just one element. We can do
this using a one-element set as parameter set.
domain
codomain
•
•
•
•
•
•

6
Abstract Sets and Mappings
To characterize mathematically what the one-element set is, we will consider it
in terms of the property that does not distinguish. The following is the ﬁrst axiom
we require of the category of sets and mappings.
AXIOM: TERMINAL SET
There is a set 1 such that for any set A there is exactly one mapping A
 1. This
unique mapping is given the same name A as the set that is its domain.
We call 1 a terminal object of the category of sets and mappings. There may
or may not be more than one terminal object; it will make no difference to the
mathematical content. In a given discussion the symbol 1 will denote a chosen
terminal object; as we will see, which terminal object is chosen will also have no
effect on the mathematical content.
Several axioms will be stated as we proceed. The axiom just stated is part of the
stronger requirement that the category of sets and mappings has ﬁnite inverse limits
(see Section 3.6). A typical cograph picture is
A
1
•
•
•
•
Only a one-element set V = 1 can have the extreme feature that one cannot detect
any distinctions between the elements of A by using only “properties” A
 V .
Having understood what a one-element set is in terms of mapping to it, we can now
use mappings from it to get more information about arbitrary A.
Deﬁnition 1.3: An element of a set A is any mapping whose codomain is A and
whose domain is 1 (or abbreviated . . . 1
a  A).
(Why does 1 itself have exactly one element according to this deﬁnition?)
The ﬁrst consequence of our deﬁnition is that
element is a special case of mapping.
A second expression of the role of 1 is that
evaluation is a special case of composition.
In other words, if we consider any mapping f from A to B and then consider any
element a of A, the codomain of a and the domain of f are the same; thus, we can

1.2 Listings, Properties, and Elements
7
form the composite f a,
which will be a mapping 1
 B. But since the domain is 1, this means that f a
is an element of B. Which element is it? It can only be, and clearly is, the value of
f at a:
A
f
1
a
fa
B
That is, if a is an element, f a = f (a).
Finally, a third important expression of the role of 1 is that
evaluation of a composite is a special case of the
Associative law
of composition (which will be one of the clauses in the deﬁnition of category). In
order to see this, suppose m = g f and consider
The formula (in which we introduce the symbols ∀to mean “for all” and ⇒to
mean “implies”)
m = g f =⇒[∀a[1
a  A ⇒m(a) = g( f a)]]
expresses our idea of evaluation of the composition of two mappings; i. e. if m is
the composite of f and g, then for any element a of the domain of f the value of
m at a is equal to the value of g at f (a). More brieﬂy, (g f )a = g( f a), which is a
case of the associative law.
The three points emphasized here mean that our internal pictures can be (when
necessary or useful) completely interpreted in terms of external pictures by also
using the set 1.
Notice that the axiom of the terminal set and the deﬁnition of element imply
immediately that the set 1 whose existence is guaranteed by the axiom has exactly

8
Abstract Sets and Mappings
one element, namely, the unique mapping from 1 to 1. There is always an identity
mapping from a set to itself, so this unique mapping from 1 to 1 must be the identity
mapping on 1.
We want to introduce two more logical symbols: the symbol ∃is read “there ex-
ists,” and ∃! is read “there exists exactly one”. Thus, we can repeat the characteristic
feature of every f : A
 B as follows:
∀a : 1
 A ∃! b : 1
 B[b is a value of f at a]
But this is a special case of the fact that composition in general is uniquely deﬁned.
1.3 Surjective and Injective Mappings
Recall the ﬁrst internal diagram (cograph) of a mapping that we considered:
A
B
•
•
•
•
•
•
•
•
•
•
f
Note that it is not the case for the f in our picture that
for each element b of B
there is an element x of A
for which b is the value of f at x. ( f(x) = b)
Deﬁnition 1.4: A mapping f : A
 B that has the existence property “for each
element b of B there is an element x of A for which b = f (x)” is called a surjective
mapping.
Neither is it the case that the f in our picture has the property
for each element b of B
there is at most one element x of A
for which f(x) = b
Deﬁnition 1.5: A mapping f : A
 B that has the uniqueness property “given
any element b of B there is at most one element x of A for which f (x) = b” is
called an injective mapping. In other words, if f is an injective mapping, then for
all elements x, x′ of A, if f (x) = f (x′), then x = x′.
Deﬁnition 1.6: A mapping that is both surjective and injective is called bijective.

1.3 Surjective and Injective Mappings
9
Thus, the f pictured above is neither surjective nor injective, but in the ﬁgure
below g : A
 B is an injective mapping from the same A and to the same B.
A
B
•
•
•
•
•
•
•
•
•
•
g
Exercise 1.7
Is the pictured g surjective?
♦
Exercise 1.8
Are there any surjective mappings A
 B for the pictured A, B?
♦
Exercise 1.9
How many mappings from the three-element set A to the seven-element set B are
there? Can we picture them all?
♦
Exercise 1.10
Same as 1.9, but for mappings B
 A from a seven-element to a three-element
set.
♦
Exercise 1.11
Are there any surjective B
 A? Are there any injective ones?
♦
Exercise 1.12
What deﬁnition of “ f1 ̸= f2” is presupposed by the idea “number of” mappings
we used in 1.9 and 1.10?
♦
Exercises 1.9 and 1.12 illustrate that the feature “external number/internal in-
equality of instances” characteristic of an abstract set is also associated with the
notion “mapping from A to B,” except that the elements (the mappings) are not
free of structure. But abstractness of the sets really means that the elements are for
the moment considered without internal structure. By considering the mappings
from A to B with their internal structure ignored, we obtain a new abstract set B A.
Conversely, we will see in Chapter 5 how any abstract set F of the right size can
act as mappings between given abstract sets. (For example, in computers variable
programs are just a particular kind of variable data.)

10
Abstract Sets and Mappings
1.4 Associativity and Categories
Recall that we saw in Section 1.2 that an “associative law” in a special case expresses
the evaluation of composition. Indeed, whenever we have
1
a  A
f  B
g  C
then we have the equation (g f )(a) = g( f a).
If we replace a by a general mapping u : T
 A whose domain is not necessarily
1, we obtain the Associative law
(g f )u = g( f u)
which actually turns out to be true for any three mappings that can be composed;
i.e., that from the commutativity of the two triangles below we can conclude that
moreover the outer two composite paths from T to C have equal composites (it is
said that the whole diagram is therefore “commutative”).
(gf)u = g(fu)
A
f
gf
C
T
u
fu
B
g
Since the 1 among abstract sets has the special feature (which we discuss in
Section 1.5) that it can separate mappings, in abstract sets the general associative
law follows from the special case in which T = 1.
An important property of identity mappings is that they not only “do nothing” to
an element but that they have this same property with respect to composition. Thus,
if 1A : A
 A and 1B : B
 B are identity mappings, then for any f : A
 B
we have the equations
f 1A = f = 1B f
With these ideas in hand we are ready to give the completed deﬁnition of category.
The beginning of our speciﬁcation repeats what we had before:
Deﬁnition 1.13: A category C has the following data:
r Objects: denoted A, B, C, . . .
r Arrows: denoted f, g, h, . . . (arrows are also often called morphisms or maps)
r To each arrow f is assigned an object called its domain and an object called its
codomain (if f has domain A and codomain B, this is denoted f : A
 B or
A
f  B)
r Composition: To each f : A
 B and g : B
 C, there is assigned an arrow
g f : A
 C called “the composite g following f ”
r Identities:
To each object A is assigned an arrow 1A : A
 A called
“the identity on A”.

1.5 Separators and the Empty Set
11
The data above satisfy the axioms
r Associativity: if A
f  B
g  C
h  D, then h(g f ) = (hg) f
r Identity: if f : A
 B, then f = f 1A and f = 1B f .
As we have been emphasizing,
AXIOM: S IS A CATEGORY
Abstract sets and mappings form a category (whose objects are called sets, and
whose arrows are called mappings).
This is the basic axiom implicit in our references to the “category of abstract sets
and mappings” above. There are many other examples of categories to be found in
mathematics, and a few of these are described in the exercises in Section 1.8 at the
end of the chapter.
1.5 Separators and the Empty Set
If a pair of mappings
A
f1

f2
 B
has the same domain and has the same codomain (i.e., they are two mappings that
could be equal), then we can discover whether they are really equal by testing with
elements
(∀x[1
x  A ⇒f1x = f2x]) =⇒f1 = f2
i.e., if the value of f1 equals the value of f2 at every element x of A, then f1 = f2.
This is one of the ways in which we can conclude that f1 = f2. The converse
implication of the statement is trivial because it is merely substitution of equals for
equals (a general idea of mathematics). But the indicated implication is a special,
particularly powerful feature of one-element abstract sets. In its contrapositive form
it states: If f1 ̸= f2, then there exists at least one element x at which the values of
f1 and f2 are different. (This is the answer to Exercise 1.12!) For a category C an
object with this property is called a separator.
Deﬁnition 1.14: An object S in a category C is a separator if and only if whenever
X
f1

f2
 Y
are arrows of C then
(∀x [S
x  X ⇒f1x = f2x]) =⇒f1 = f2

12
Abstract Sets and Mappings
As mentioned in 1.4 the property we have been describing is required of the
terminal object 1 as a further axiom in the category of abstract sets and arbitrary
mappings. It is a powerful axiom with many uses; it is special to the category S
of abstract sets and will not hold in categories of variable and cohesive sets where
more general elements than just the “points” considered here may be required for
the validity of statements even analogous to the following one (see Section 1.6):
AXIOM: THE TERMINAL OBJECT 1 SEPARATES MAPPINGS IN S
A one-element set 1 is a separator in S, i.e., if
X
f1

f2
 Y
then
(∀x [1
x  X ⇒f1x = f2x]) =⇒f1 = f2
Exercise 1.15
In the category of abstract sets S, any set A with at least one element 1
x  A is
also a separator. (When an exercise is a statement, prove the statement.)
♦
We return to the extreme case of listing or parameterization in which no elements
are listed. In this case there cannot be more than one listing map (we will use “map”
and “mapping” synonymously!) into A since the indexing set we are trying to use
is empty. On the other hand, there must be one since the statement deﬁning the
property of a mapping is a requirement on each element of the domain set (that
there is assigned to it a unique value element in the codomain). This property
is satisﬁed “vacuously” by a mapping from a set without elements since there is
simply no requirement. Thus, there exists a unique mapping from an empty set to
any given set. We require such a set as an axiom.
AXIOM: INITIAL SET
There is a set 0 such that for any set A there is exactly one mapping 0
 A.
We call 0 an initial object of the category of sets and mappings.
Note that the form of this axiom is the same as the form of the axiom of the
terminal set, i.e. we require the existence of a set and a unique mapping for every
set except that the unique mapping is now to the arbitrary set whereas formerly
it was from the arbitrary set. Like the axiom of the terminal set, the axiom of the
initial set will become part of a stronger axiom later. The initial set is often called
the empty set because, as we will later see, there are no maps 1
 0.

1.5 Separators and the Empty Set
13
Exercise 1.16
In the category of abstract sets S the initial set 0 is not a separator. (Assume that
two sets A and B exist with at least two maps A
 B.)
♦
ADDITIONAL EXAMPLES:
(1) If T is an index set of numbers, then
T
x  X
could be the listing of all the American presidents in chronological order. It
does turn out that the map is not injective – Cleveland was both the 22nd and
the 24th president.
If we want to ask who was the 16th president, the structure of the question
involves all three: the actual set, the actual listing, and a choice of index:
1
i
xi=xi
T
x
X
Lincoln derives by composing the index i = 16 and the list x of presidents.
(2) There are at least two uses of two-element sets:
Index sets and truth-value sets
Consider
1 •
2 •
τ
• 1
• 2
f
•
•
•
•
•
•
•
•
•
•
•
•
•
•
••
set of
all
tennis
players
1 = “best”,
2 = “second best”
The one that used to be the second-best tennis player could become the best;
encode that by noting that there is an endomapping (or self-mapping) τ that
interchanges the two denominations. The list f ′ that is correct today can be the
reverse of the list f that was true yesterday if an “upset” match occurred; i.e.
we could have f ′ = f τ.
A similar sort of thing happens also on the side of the possible properties of
the elements of X:
X
V
V
f
τ
•
•
•
•
•
•
•
•
•
true
false
•
•
true
false

14
Abstract Sets and Mappings
which results in
X
V
•
•
•
•
•
•
•
•
•
true
false
In this case we could also compose with the τ, but now it would instead be τ
following f (which is written τ f ). This is called logical negation since it transforms
f into not-f, i.e. (not-f)(x) = not-f(x). The composite property is the property of
not having the property f . Often in the same discussion both reparameterization of
lists and logical or arithmetic operations on properties occur, as suggested in the
following diagram:
T
x
 
V
T ′
X
f
V ′
If we have a list x of elements and a property f , then the composite f x can be
thought of in two equally good ways. Because V represents values, we can think of
this f x as just a property of elements of T ; for example, given the listing x of the
presidents, the property f of their being Democrats becomes a property of indices.
But f x could also be considered as a list (of truth values). The two concepts thus
reduce to the same in the special case T
 V , giving
LIST
TRUTH VALUES
PROPERTY
INDICES
or
of
or
=
or
of
or
FAMILY
QUANTITIES
MEASUREMENT
PARAMETERS
Of course, the words for T (indices/parameters) and the words for V (truthval-
ues/quantities) only refer to structure, which is “forgotten” when T, V are abstract
sets (but which we will soon “put back in” in a more conscious way); we mention
this fact mainly to emphasize its usefulness (via speciﬁc x and f ) even when the
structure forgotten on X itself was of neither of those kinds.
Exercise 1.17
Consider
S = Set of socks in a drawer in a dark room
V = {white, black}
f = color
How big must my “sampler” T be in order that for all injective x, f x is not
injective (i.e., at least two chosen socks will be “veriﬁed” to have the same color)?

1.6 Generalized Elements
15
T
V
S
objective
subjective
x
f=color
♦
1.6 Generalized Elements
Consider the following three related statements (from Sections 1.2 and 1.4):
(1) Element is a special case of mapping;
(2) Evaluation is a special case of composition;
(3) Evaluationofacompositeisaspecialcaseoftheassociativelawofcomposition.
Statement (2) in one picture is
1
a
b
A
f
B
(that is to say, f a = b) in which a, b are elements considered as a special case of
the commutativity of the following in which a, b are general mappings:
T
a
b
A
f
B
“Taking the value” is the special case of composition in which T is taken to be 1.
For statement (3), recall that the associative law applies to a situation in which
we have in general three mappings:
T
a
g(fa) = (gf)a
fa
C
A
f
gf
B
g
We can compute the triple composite in two ways: We can either form f a and
follow that by g, getting g( f a), or we can ﬁrst form g f (g following f ) and consider
a followed by that, obtaining what we call (g f )a; the associative law of composition
says that these are always equal for any three mappings a, f, g.

16
Abstract Sets and Mappings
In a special case, where T = 1, the description would be that the value of the
composite g f at an element a is by deﬁnition the element of C that we get by
successive evaluation of f and then of g, leading to the same picture
g(fa) = (gf)a
fa
f
g
but one that is special because it emanates from the one-element set.
In many cases we will actually want to reverse this specialization procedure; that
is, by the phrase
an element of A
we often actually mean a mapping to A from any T (not only T = 1). In case of
confusion we may refer to this as
a generalized element of A
A generalized element of A is actually nothing but an arbitrary mapping whose
codomain happens to be A. It has some domain, but we do not insist that that
domain be 1.
A more accurate description in terms of the content would be
variable element of A varying over T
This is a very ancient way of using the idea of element; for example, if we consider
the way people talk about temperature, they say the temperature, which seems to
be an element of the set of temperatures, and intend by it the actual temperature.
On the other hand, yesterday it was one value, and today it is another value. It is
varying, but it is still the. Just think of
T as the set of days
foreverydaythereisanelementintheconstantsense.Theactualtemperatureonthat
day is the value of a mapping; the mapping itself is the temperature the weatherman
is talking about. It is varying, but it is still considered as one entity, one “element”.
We speak this way about many other situations. “I am a different person today than
I was yesterday, yet I am still the same person.” To explain anything that involves
that sort of variation, one very common kind of model for it will involve somehow
(not as its only ingredient by any means but as one ingredient)
r an abstract set that plays the role of the “temporal” parameters,
r another one that plays the role of values, and
r a speciﬁc mapping that describes the result of the evolution process.

1.7 Mappings as Properties
17
The process itself has some cause that may also have to be mentioned, but the result
of that cause will be a succession of values; change is often described that way.
But we will always correctly persist in attaching the deﬁnite article “the” as in “the
temperature,” “the me” to express the underlying unity. An element of the set of
temperatures might very well be
(a) one single unchanging value of temperatures;
equally well it might be
(b) the temperature of Milan during one week,
in which case it is still one (generalized) element of the set of temperatures, but its
domain is T .
Variable sets also occur in real life; for example, the set of people inhabiting a
particular house may vary from year to year. To mathematically model such situ-
ations, categories of variable sets are useful. In this chapter we are emphasizing
the category in which the sets themselves are constant, but later we will explicitly
describe and construct examples of categories in which the sets are (even continu-
ously) variable.
1.7 Mappings as Properties
What about the mappings that have domain A? They certainly are not elements of
A in the usual sense; they could be called properties of (elements of) A.
To deal ﬁrst with some trivial cases, let us review the deﬁnition of 1 and 0. The
characterizing features of an empty set 0 is that
for each set A there is just one mapping 0
 A,
whereas the characterizing features of a terminal set 1 is
for each set A there is just one mapping A
 1.
The descriptions of 0 and 1 look rather similar except that the arrows are reversed,
but we will see that these objects are quite different when we start talking about
mappings from 1 and into 0 such as
1
 B
versus
A
 0
Whereas mappings from 1
 B exist for any B that is nonempty – and there will be
many of them (depending on the size of B) – by contrast A
 0 will exist only if
A is also empty, but even then there is only one map.
So the sets whose existence is required by the axioms of the terminal set and the
initial set should be very different! To allow 0 = 1 would result in all sets having

18
Abstract Sets and Mappings
only one (narrow sense) element. We must clearly avoid that. For sets A and B,
the notation A ∼= B, which is read “A is isomorphic to B,” means that there are
mappings f : A
 B and g : B
 A satisfying g f = 1A and f g = 1B. We will
have much more to say about this concept later (see Section 3.2), but for now we
use it (in a negative way) in the following:
AXIOM: NONDEGENERACY OF S
0 ̸∼= 1
Exercise 1.18
How many mappings are there from 0 to 1? from 0 to 0? from 1 to 0? (and so how
many elements does 0 have?)
Hint: To answer the third question requires more axioms than do the other two.
♦
Notice that we could have taken the apparently stronger statement “there is
no mapping from 1 to 0” instead of the axiom as stated. The stronger statement
certainly implies the axiom, but as shown by the exercise the axiom implies the
stronger statement too.
We are considering the question, If V is a ﬁxed set of values, then for any A,
what kind of properties A
 V can there be? (“Property” is being used in such a
general sense that it means just an arbitrary mapping but from the dual point of
view to that of generalized elements.)
If V is 0, we see that the answer to the preceding question is “none,” unless A is
itself empty, and in that case only one. If V = 1, there is exactly one mapping for any
A. We have to take a V that is somewhat larger if we want any interesting property
of (elements of) A at all. Thus, we will take a two-element set for V and see that
we in fact get enough properties to “discriminate” between the elements of any A.
The ability of “discriminating” elements by means of V -valued properties is fre-
quently expressed by the following:
Deﬁnition 1.19: An object V is a coseparator if for any A and for any parallel
pair
T
a0

a1
 A
(of “generalized elements”)
(∀ϕ[A
ϕ  V =⇒ϕa0 = ϕa1]) =⇒[a0 = a1]

1.7 Mappings as Properties
19
Notice that if V is a coseparator, then a0 ̸= a1 entails that there is A
ϕ  V with
ϕa0 ̸= ϕa1, i.e. V can discriminate elements. By what we have said here, neither
V = 0 nor V = 1 can coseparate.
Exercise 1.20
Use the fact that 1 is a separator in the category of abstract sets to show that (in
that category), if V can discriminate elements, then it can discriminate generalized
elements. Thus, in S the general T in Deﬁnition 1.19 could safely be replaced by
T = 1.
♦
Claim 1.21: If V is a set with exactly two elements, call it 2, then V is a coseparator
in the category of abstract sets.
Remark 1.22: We are assuming that there exists a set 2 with exactly two elements:
1
0

1
 2. We will make this existence more precise in Chapter 2. We also denote
by τ : 2
 2 the mapping completely deﬁned by τ(0) = 1 and τ(1) = 0.
Here is a provisional justiﬁcation of Claim 1.21 based on our naive conception
of V = 2; soon we will have enough axioms to formally prove it. Assume that A
is arbitrary but that there are maps 1
a0

a1
 A with a0 ̸= a1. We must “construct” a
A
ϕ  2 with ϕa0 ̸= ϕa1 showing that 2 coseparates (which follows by using the
result of Exercise 1.20). That this is possible is quite obvious from a picture, as
follows. If A is an arbitrary abstract set mapped into the two element set by ϕ
A
2
•a0
•a1
··
·
··
· ·
·
·
·
·
·
·
·
····
· ·
·
·
·
•
•
ϕ
then A is divided in 2 parts. Conversely, any mutually exclusive and jointly ex-
haustive division of A into two parts arises from a mapping to the two-element set.
(These are called either indicator functions or characteristic functions in probability
theory, combinatorics, and other subjects.)
The ϕ is the indicator or characteristic function of the whole partition in two parts
and would be determined by such a pattern. In our problem there is no speciﬁc
partition. We merely want to show that a partition can be chosen with the two
elements in different parts. This is a very weak condition on ϕ, so there are many

20
Abstract Sets and Mappings
such mappings; in the extreme we could imagine that only a0 goes to one value, or in
the opposite extreme that only a1 goes to the other value. Both are extreme concepts
of ϕ, and both would satisfy the requirement, namely, that the composites are still
different. We can make that more speciﬁc: We insist that one of the composites
comes out to be the element 0 and the other one the element 1, where we have
structured the abstract set 2 by considering both of its elements as being listed:
1
A
2
̸=
a0
a1
1
0
ϕ
We can simply insist that the indexing is preserved by ϕ. Among these maps there
is a sort of lowest possible choice for ϕ:
ϕ(a) =

1 if a = a1
0 if a ̸= a1

which is one possibility, and a highest possible choice for ϕ,
ϕ(a) =

1 if a ̸= a0
0 if a = a0

at the other extreme.
Both of these extreme cases of ϕ separate a0, a1. There will be many partitions
ϕ in between these two that will also separate a0, a1, but since there exists at least
one, we have convinced ourselves that 2 is a coseparator.
How many properties are there exactly?
Exercise 1.23
Consider a two-element set and a three-element set:
A
B
•
•
•
•
•
Name the elements of A by a0 and a1 and the elements of B by b0, b1, b2. Draw the
cographs of all mappings f : A
 B and all g : B
 A. How many mappings

1.7 Mappings as Properties
21
are there from A
 B? (We should ﬁnd that there are nine.) How many from
B
 A? (The answer is eight = 23.) Notice that if each cograph were reduced
to a dot we would obtain abstract sets of mappings with nine and eight elements;
these abstract sets can in turn be used to paramaterize the actual mappings (see
Chapters 5 and 7).
♦
Exercise 1.24
What about mappings from a ﬁve-element set into a two-element set? How many
mappings are there from
V
X
•
•
•
•
•
•
•
Answer: 25 = 32 mappings
♦
In general, we can say that the number of (two-valued) properties on a set with n
elements is 2n. One of the ideas of Cantor was to give meaning to this statement
even when n is not ﬁnite, as we shall see in more detail later.
The coseparating property of 2 is phrased in such a way that it is really just a dual
of the separating property that 1 has, i.e. there are enough elements to discriminate
properties just as there are enough properties to discriminate elements.
Considerthevariouselementsin,andthevarious2-valuedpropertiesontheset A:
1

... 
a’s
A

... 
ϕ’s
2
We test whether a0, a1 are different by using such properties as follows:
a0 ̸= a1 ⇒∃ϕ such that ϕa0 ̸= ϕa1
For each pair we ﬁnd a ϕ; for another pair we might need another ϕ. The dual
statement
ϕ1 ̸= ϕ2 ⇒∃a at which ϕ1a ̸= ϕ2a
that there are enough elements, distinguishing between properties with any kind
V of value specializes to a statement about two-valued properties: ϕ1 ̸= ϕ2 means
that two mappings are different, but for mappings to be different there must be
some element a at which their values are different. (Again we warn the reader that
in categories of less abstract sets, these separating and coseparating roles will be
taken by families of objects richer than 2 and 1.)

22
Abstract Sets and Mappings
Recall that the map A : A
 1 is unique. The statement “ f is constant” means
that there exists a single element of B such that f is the composite: the single
element following the unique map, i.e.
1
A
b
A
f=bA
B
Deﬁnition 1.25: An arrow A
f  B is constant if and only if it factors through 1;
i.e. there is an element b : 1
 B of B such that f = bA : A
 1
 B.
In particular, if we form the composites of the unique map to 1 with the two
elements of 2, we get two constant maps 2
 2:
2
1
2
•
•
•
•
•
2
1
2
•
•
•
•
•
2
0
2
1
We will ﬁnd various circumstances in which it is useful to look at the system of
self-maps of 2 in its own right, not just as part of the category of abstract sets but
as a scheme for picking out another, more interesting kind of set called reversible
graph (see Section 10.3). For this and other reasons it is important to know how
these four maps compose. We can write down the “multiplication table” for this
four-map system. The self-maps of any given object can always be composed, and
having names for them (four in this case), we can show, in the multiplication table,
what is the name of the composite of any two of them taken in a given order. Here
is the resulting table:
12
0
1
τ
0
0
0
0
1
1
1
1
τ
1
0
12
The composing of constants (which comes up in computing this table) works in
general as follows:
If f is constant with constant value b, then for any g, g f is constant but with
constant value gb

1.8 Additional Exercises
23
B
C
A
f
b
g
1
Similarly, if f is constant, then for any mapping a, f a is also constant with the
same constant value as f :
Exercise 1.26
Verify the composition table for endomappings of 2 by considering all four possi-
bilities for each of the two arrows in 2
 2
 2 and computing the composite.
♦
Exercise 1.27
Show how this four-element system acts as “logical operators” on the properties
A
 2 of (elements of) any A but also acts in another way on the lists 2
 A
(or ordered pairs) of elements of A.
Hint: Recall the discussion of tennis players in Section 1.5.
♦
1.8 Additional Exercises
Exercise 1.28
Uniqueness properties:
(a) Show that identity arrows in a category are unique, i.e. if 1A : A
 A and
1′
A : A
 A both satisfy the equations for identity arrows, then 1A = 1′
A.
(b) Show that the set 1 is unique “up to unique isomorphism,” (i.e. if 1′ also satisﬁes
the axiom of the terminal set then there are unique mappings f : 1
 1′ and
g : 1′
 1) and that g f = 11 and f g = 11′.
(c) Similarly, show that the empty set 0 is unique up to unique isomorphism.
Exercise 1.29
(a) Show that if f : A
 B and g : B
 C are injective mappings, then so is g f ,
i.e. “composites of injectives are injective”.
(b) Show that composites of surjectives are surjective.

24
Abstract Sets and Mappings
Exercise 1.30
Categories of structures:
(a) Show that (ﬁnite-dimensional) vector spaces as objects and linear transforma-
tions as arrows form a category with composition of arrows deﬁned by compo-
sition of mappings. Show that a one-dimensional space S is a separator; is it a
coseparator? Is the terminal object a separator?
(b) Show that groups as objects and group homomorphisms as arrows form a
category with composition of arrows deﬁned by composition of mappings.
Show that the additive group of integers is a separator. (Look up the deﬁnition
of “group” if necessary. We will discuss groups further in Section 10.1.)
(c) Show that partially ordered sets as objects and monotone (= order-preserving)
mappings as arrows form a category with composition of arrows deﬁned by
composition of mappings. Is the terminal object a separator in this category?
Is there a coseparator? (Look up the deﬁnition of “partially ordered set” if
necessary. We will discuss partially ordered sets further in Section 10.1.)
(d) A ﬁnite state machine with two inputs α and β is a ﬁnite set Q of “states” and
a pair of endomaps of Q corresponding to α and β that effect the elementary
state transitions of which the machine is capable. Given another such machine
with state set Q′, a homomorphism is a mapping ϕ : Q
 Q′ of state sets
preserving the transitions in the sense that
ϕα = α′ϕ and ϕβ = β′ϕ
where we have denoted by α′ and β′ the corresponding state transitions of
the second machine. Deﬁne composition of homomorphisms and show that a
category results.
Exercise 1.31
Categories as structures:
(a) Let V be a given vector space. Show that the following data deﬁne a cate-
gory V:
V has just one object called ∗;
the arrows of V from ∗to ∗are the vectors v in V ;
the identity arrow for ∗is the zero vector;
the composite of vectors v and v′ is their sum.
Hint: With the data given, verify the equations of Deﬁnition 1.13.
(b) Let X be a given partially ordered set (with partial order ≤). Show that the
following data deﬁne a category X:

1.8 Additional Exercises
25
the objects of X are the elements of X;
for elements x, x′ in X there is an arrow from x to x′ exactly when x ≤x′.
(It follows that there is at most one arrow from x to x′.)
Hint: Here we did not specify the composition or identity arrows, but there is
no choice about how to deﬁne them. Why?
Exercise 1.32
(a) (Dual categories) There are many methods of constructing new categories from
known categories. An important example is the dual or opposite category of a
category. Let C be a category. The dual category Cop has the same objects as C,
but for objects A and B the arrows from A to B in Cop are exactly the arrows
from B to A in C. Show how to deﬁne composition and identities for Cop to
make it a category.
(b) (Slice categories) Another important construction is the “slice category”. Let C
be a category and X an object of C. The slice category of C by X, denoted C/X,
has objects the arrows of C with codomain X. Let f : A
 X and g : B
 X
be objects of C/X. The arrows of C/X from f to g are arrows h of C such that
f = gh, i.e. they are the same thing as commutative triangles from f to g.
Composition and identities are inherited from C. Verify that C/X is a category.
(c) (Pointed sets) If we deﬁne objects to be pairs consisting of a set A and an
element 1
a  A of A, and arrows from A, a to B, b to be mappings A
f  B
such that f a = b, then we obtain a category denoted by 1/S. Verify that 1/S
is a category. Does 1/S have an initial object? Does it have a terminal object?
Does the terminal object separate mappings in 1/S? (This is a special case of
a dual notion to slice category: For C a category and X an object of C, describe
the category X/C.)

2
Sums, Monomorphisms, and Parts
2.1 Sum as a Universal Property
Our basic deﬁnitions of the fundamental operations
ADDITION
MULTIPLICATION
EXPONENTIATION
are all universal mapping properties; that is, we take as the deﬁning condition on
such a construction essentially “what it is good for”.
Let us consider sums. Our naive picture of the sum is that the sum of two sets
contains two parts, that the two parts are the same size as the given sets, that the
sum does not have anything in it except those two parts, and that the two parts do
not overlap. These ideas can be expressed more brieﬂy as follows:
The two parts are exhaustive and mutually exclusive.
•
•
•
•
•
•
•
•
•
•
The sum as deﬁned by the universal mapping property will, in particular, have two
mutually disjoint parts equivalent to two given sets and that together exhaust the
whole sum. However, it is not satisfactory to take these conditions as a deﬁnition
for at least two different reasons:
(1) There are categories other than abstract sets; for objects in these categories
there is also a notion of sum but one in which the two parts may interact. The
description in terms of nonoverlapping would be incorrect in such a case (see
Exercise 2.40). It is better to use the same form of the deﬁnition so that we see
the similarity more transparently.
(2) The second reason is related to the gap between the naive picture and the
formalized axiomatics. We always have some kind of naive picture for the
26

2.1 Sum as a Universal Property
27
things we are trying to describe by mathematical formalism. But the naive
picture usually does not match up perfectly with the precise formalism. There
is a gap between the two. We try to get them as close together as we can. That is
one of the struggles that moves mathematics forward. In particular, the words
“mutually exclusive and exhaustive pair of parts” describe formally much of
the naive picture of a sum. However, if we took that as the formalized axiom, it
would not formally imply the needed stronger conclusion that we can always
do certain things with the sum. We take those certain uses as the axiom.
First, let us consider the particular case of the sum of two copies of a one-element
set.
Any two-element set will have two arrows from 1 (elements in the narrow sense);
we could give them names 0 and 1.
1
0
2
1
1
That the set 2 has two parts which are disjoint and exhaustive means that these two
arrows are different and that there are no other arrows 1
 2. If we tried to take
that as our deﬁnition, we would meet a difﬁculty with other things we want to do
with 2: Namely, what is a mapping from 2 into another set B? It should just mean
to give a pair of elements of B because such a single mapping has to have a value
at one element and also a value at the other element.
Obviously if we had a mapping 2
f  B, we could compose it with the two
elements of 2, and we would obtain two elements of B.
Conversely, given two elements of B, say b0 and b1, then the naive picture of
2 and the “arbitrariness” of mappings suggest that there exists a unique mapping
f : 2
 B whose values are the given elements. We are led to deﬁne this particular
sum as follows:
Deﬁnition 2.1: The statement
2 = 1 + 1
means that
there are given mappings 1
0  2
1

1 such that
∀B, 1
b0  B, 1
b1  B ∃! f [ f (0) = b0 and f (1) = b1]
as in

28
Sums, Monomorphisms, and Parts
1
0
b0
2
f
B
1
1


b1
The uniqueness means that if we had two mappings f, g, both with the speciﬁed
values, then they would be equal. We already introduced the principle that there are
enough mappings from 1 to distinguish maps. From that the uniqueness part of the
condition on f would follow if there were only the two maps from 1 to 2; that is true
for the category of abstract sets (but not for all categories of interest). Concerning
the existence of f , the naive idea that arbitrary mappings exist is a guide, but we
want to prove all of the existence theorems from just a few; this is one of the few that
we assume. For any set B, to map 2 into B it sufﬁces to specify two elements; then
there will be one and only one f . The exhaustiveness and disjointness of elements
will follow (with the help of the other axioms). Knowing how a given object maps
to all objects B in its category determines indirectly how each object maps into it,
but some work will be required to realize that determination, even for the object 2.
Recall the contrast of listings versus properties (see Chapter 1). A sum of 1’s
(such as 2) is clearly well-adapted to a simple listing of elements of an arbitrary
object B. In the category S of abstract sets (and in a few others), 2 also serves well
as a codomain for properties.
It is really no more difﬁcult to describe the sum of any two sets; but the sum of
two sets is not merely a third set; rather, it is two maps as follows:
Deﬁnition 2.2: A sum of the two sets A0 and A1 is a set A together with given
mappings A0
i0  A
i1

A1 such that
∀B, A0
f0  B, A1
f1  B ∃! f [ f i0 = f0 and f i1 = f1]
as in the commutative diagram
A0
i0
f0
A
f
B
A1
i1
f1

2.1 Sum as a Universal Property
29
We denote the unique f deﬁned by the mappings f0 and f1 by
f =

f0
f1
We abbreviate by writing A = A0 + A1 with the mappings i0 and i1 understood.
Thus, given any two sets A0 and A1, to make A the sum of the two, we must give
i0 and i1 with the universal mapping property presented at the beginning of this
Section. For any B at all, if we have a map A
 B, then of course, by composing,
we get two maps A0
 B and A1
 B; but the sum injections i0 and i1 are
special so that conversely, given any f0 deﬁned on one part A0 and any f1 deﬁned
on the other part A1, there is exactly one f deﬁned on the whole that composes
with the i0, i1 to give the original f0, f1.
AXIOM: BINARY SUMS
Any two sets A0, A1 have a sum A0
i0  A
i1

A1.
Exercise 2.3
Given a set A0 with exactly two elements and a set A1 with exactly three elements,
specify a set A and two injection maps for which you can prove the universal
mapping property of a sum of A0 and A1. That is, given any f0 and f1, show how
to determine an appropriate f .
♦
EXAMPLE: COGRAPHS
We have already seen an important example of a mapping from a sum. The
cograph of a mapping, which we described with a picture in Section 1.1, is ac-
tually an instance. Indeed, suppose that f : A
 B is any mapping whatsoever.
We can deﬁne a mapping c : A + B
 B by c =

f
1B. That is, the following is a
commutative diagram:
The cograph of a mapping is illustrated by its internal diagram (which we have
already used informally many times!) by drawing the sets A and B disjointly and
showing a linking of an element a of A to an element b of B whenever f (a) = b;

30
Sums, Monomorphisms, and Parts
thus, two elements in A + B are linked in the internal diagram if and only if they
are merged by the cograph mapping c.
Exercise 2.4
Illustrate the example from Exercise 2.3 by an internal cograph picture.
♦
Coming back to Deﬁnition 2.2, for any element 1
a  A, we have
(∗) f a = f0a0
if i0a0 = a
for some element a0 of A0
f a = f1a1
if i1a1 = a
for some element a1 of A1
Naively, there could not be two different maps f that satisfy the condition (∗),
for A is exhausted by the two parts; if there were an element a that could not be
expressed in either of these two forms, then we could imagine that there could be
maps f for which the equations (∗) would be true and yet f could have various
values at such a. In other words the exhaustiveness of the two parts corresponds
naively to the uniqueness of the f . On the other hand, the disjointness has something
to do with the existence of the f . What would happen if we had an element a that
could be fed through both i0 and i1 (i.e., the two parts overlap, at least on that point)?
Then we could imagine that f0 and f1 take different values at a0 and a1; therefore,
there could not be any f at all because even f a would not be well-deﬁned. The
naive content of the disjointness and exhaustiveness corresponds to the existence
and uniqueness of such maps f .
We will write A0 + A1 = A as a kind of shorthand; it means that whenever we
need to apply the universal property we are given the i0 and the i1 required. The
universal mapping property has as a by-product that the “size” of A is determined
by the sizes of A0 and A1, but it has many more detailed uses than the mere “size”
statement.
How does the general sum relate to 2? If we are given a decomposition of any
set A as a sum of two other sets A0 and A1, we will automatically have a mapping
from A to 2, namely, the mapping that takes the two values on those two respective
parts. That follows from our deﬁnition, for we could apply the universal mapping
property by taking B = 2 and consider the two elements (one called 0 and the other

2.1 Sum as a Universal Property
31
called 1) of 2; each of those can be preceded by the unique map that always exists
from any set to the one-element set; i.e. we can take f0 and f1 to be, respectively,
A0’s unique map to 1 followed by the element 0 of 2
A1’s unique map to 1 followed by the other element 1 of 2
Now we have two maps, f0 and f1 going from A0 and A1 into the set 2, and so
there is a unique f whose domain is the sum, whose codomain is 2, and such that
these composites are equal to the respective constant mappings just constructed, as
in the following commutative diagram:
A0
i0
1
0
A0 + A1
f
2
A1
i1
1
1
On the part i0 of the sum, this mapping f constantly takes the value 0; the other
composite is constantly the other element 1 of 2.
Conversely, any mapping A
f  2 really is of the preceding sort because, if we
are given the f , then we can deﬁne two parts of which A is the sum. We can imagine
that each part is the one whose members are all the elements for which f has a
ﬁxed value. That is, we may construct mappings into 2 by other means and then
deduce the corresponding sum decomposition.
A
2
A0
A1
all this goes to 0:
all this goes to 1:
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
Anytime we have this situation, we may say A has been divided into two parts.
But what is a part and what is membership? We will discuss these concepts in the
next section.
Exercise 2.5
Deﬁne explicitly what should be meant by a sum of three given sets. If V is any
ﬁxed set with exactly three elements, show that any mapping A
 V comes from
a unique sum decomposition of A into three parts.
♦

32
Sums, Monomorphisms, and Parts
2.2 Monomorphisms and Parts
Monomapping, or monomorphism, is a stronger version of injective, which we will
have to use to deﬁne part in general categories of sets and for other purposes also:
Deﬁnition 2.6: An arrow S
i
 A is a monomapping or monomorphism if it has
the cancellation property with respect to composition on its right, i.e.,
∀T ∀s1, s2 : T
 S [is1 = is2 ⇒s1 = s2]
so whenever we have the conﬁguration
T
s1

s2
 S
i
 A
and is1 = is2, then s1 = s2.
Equivalently,
∀T ∀x [T
x  A ⇒∃at most one s [is = x]]
The expression above is called a cancellation property because, given an equation
involving composition with i on the left, we can cancel the i. Since s1 and s2
are generalized elements, the property says that i is injective even on generalized
elements.The differencebetweenmonomorphicandinjectiveisthat,forthe“mono”
property, we require the cancellation for all T . This does not matter in the case of
abstract sets, where cancellation with the general T or with just T = 1 means the
same thing (see Exercise 2.7). That “mono” implies injective is tautologous because
a general statement always implies any of its special cases. The converse statement
is not tautologous; it depends on the existence of sufﬁciently many elements.
Exercise 2.7
Using the axiom that 1 separates mappings, show that
injective ⇒monomapping
in the category of sets S.
♦
Exercise 2.8
Show that if i and j are composable monomorphisms, then ji is a monomorphism,
i.e. a composite of monomorphisms is a monomorphism. (Recall that injective
mappings also compose.)
♦

2.2 Monomorphisms and Parts
33
Exercise 2.9
Show that any mapping 1
a  A whose domain is 1 is necessarily a monomapping.
♦
Exercise 2.10
Show that if U has the property that the unique U
 1 is a monomapping, then
any mapping U
a  A with domain U is necessarily a monomapping.
♦
The origin of these words (including the term epimorphic, seen later to be related
to surjective) is in ancient Mediterranean languages as follows:
GREEK:
LATIN:
monomorphic
injective
epimorphic
surjective
We exploit the differences in the words to get slightly different meanings. The dif-
ference between injection and monomorphism is not too great in practice, whereas
the difference between surjection and epimorphism (the dual of monomorphism,
which we will deﬁne later) is greater. What we mean by monomapping or injective
mapping is one that does not identify (in the sense of “make equal”) any elements
that were previously distinct.
We are now ready to deﬁne part.
Deﬁnition 2.11: A part of set A is any mapping i for which
(1) the codomain of i is A, and
(2) i is a monomapping.
Any part of A has some domain, say S, but the property (2) means that the
part keeps the elements distinct: if we have is1 = is2, we can conclude s1 = s2. In
particular, if we return to the deﬁnition of sum, the injections into a sum have to be
monomappings.
Exercise 2.12
Prove on the basis of the axioms for S so far introduced that if A0
i0  A
i1

A1 is
a sum in S, then i0 is a monomapping.
♦
Here is an example of the notion of part: There is the set A of chairs in a room
and the set S of the students in the room. The mapping i assigns to every student
the chair in which she or he sits. That is an injective mapping. Why? Because we
have no situation of two students sitting in one seat. It is a monomorphism and

34
Sums, Monomorphisms, and Parts
therefore deﬁnes a part of the set of all seats. Students are not chairs – we have to
have a given mapping that speciﬁes the way in which we have a part. The account
of “part of” given in most books would make no sense for abstract sets: It is not that
every element of S is an element of A! In our concrete example, the latter would
mean that every student “is” a chair. But i is indeed a part in the sense that we
want to use the term in mathematics; it does deﬁne a condition on chairs – to be a
member of the part means to be an occupied chair.
2.3 Inclusion and Membership
To express the relationship between parts that arises when they can be compared,
we have
Deﬁnition 2.13: The part i is included in the part j (or there is an inclusion from
i to j) means that i and j are parts of the same A and that
We write i ⊆A j in this case and we sometimes omit the subscript A if the codomain
(“universe of discourse”) is obvious.
Exercise 2.14
Show that if i is a monomorphism and i = f k, then k is a monomorphism. Give
an example to show that f need not be injective.
♦
Thus, the k whose existence is required in the deﬁnition is always a monomap-
ping, and so k is a part of the domain V of j.
Deﬁnition 2.15: The (generalized) element a of A is a member of the part i of A,
denoted a ∈A i, means that i is a monomapping and that
Notice that we give the deﬁnition of membership for generalized elements. In
the special case T = 1 we are stating that an element a of A is a member of the part

2.3 Inclusion and Membership
35
i of A if there is an element a of the domain U of i that the part i interprets as a.
(Note that there can be at most one such a.)
Proposition 2.16: For any a, i and j (the “universe” A being understood),
a ∈i and i ⊆j ⇒a ∈j
Proof: The hypothesis gives us a and k for which a = ia and i = jk. To establish
the conclusion we would need
=a with a = j
=a. The only map at hand that even has
the right domain and codomain as such an
=a is ka; so deﬁne
=a = ka as in the diagram
T
a
 






=a

a

U
k

 
 
i
 






V
j


A
and see whether it satisﬁes the correct equation:
j
=a = j(ka)
= ( jk)a
= ia
= a
Hence, a = j
=a as required to prove that a ∈j.
■
Exercise 2.17
If a ∈i, then for all t, at ∈i.
♦
In order to follow the next construction it will be useful to make explicit the
logical rule of inference for implication–introduction.
If X, Y, Z are statements, then
(X & Y) ⇒Z holds
if and only if
Y ⇒(X ⇒Z) holds
(For more details about the symbols, see Appendix C.2 and Appendix A.)
For example, if one takes X to be the statement a ∈j, Y to be i ⊆j, and Z
to be a ∈j, the proposition we have just proved is the statement with & in the

36
Sums, Monomorphisms, and Parts
hypothesis. Thus, we could equally well say that we have proved the statement
with the ⇒inside the conclusion:
i ⊆j ⇒[a ∈i ⇒a ∈j]
Note that the variable a now appears in the conclusion but not in the hypothesis.
We also need to make explicit the
logical rule of inference for ∀-introduction.
If Y and W are statements in which W depends on a variable a but Y does not,
then
Y ⇒W holds
if and only if
Y ⇒∀a[W] holds
Thus, our proposition above is further equivalent to
i ⊆A j ⇒∀a[a ∈i ⇒a ∈j]
where the statement on the right has the universal quantiﬁer ∀a ranging over all
T
a  A for all sets T . The converse of (this form of) the proposition
∀a[a ∈i ⇒a ∈j] ⇒i ⊆A j
is also of interest. This converse is trivially true if the domain of a is arbitrary
since, for the special case a = i, a = 1U proves i ∈i; hence, if the hypothesis
∀a[ . . . ⇒. . . ] is true, we get
=a proving that i ∈j, but that is the same as a proof k
that i ⊆j. However, the converse becomes more interesting if we restrict the range
of the a’s for which we assume the hypothesis, for then it could be a nontrivial
property of our category that the conclusion i ⊆j nonetheless still followed from
this weaker hypothesis. Something of this sort will be true of categories of variable
sets, where it will be possible to restrict a to the indispensable domains of vari-
ation of the sets. In the case of abstract (= constant) sets there is no substantial
domain of variation, and so we can restrict the domain of a to be 1. That is, the cat-
egory of abstract sets satisﬁes the strengthened converse proposition (a weakened
hypothesis)
∀a[1
a  A ⇒(a ∈i ⇒a ∈j)] ⇒i ⊆j
Essentially, this follows from the idea of the arbitrariness of mappings: Note that
what is wanted in the conclusion is a single actual map k for which i = jk, yet the
hypothesis only says that
∀1
x  U [∃1
y  V
jy = ix]

2.3 Inclusion and Membership
37
(Here the a is the common value jy = a = ix). Since j is injective, the ∃y can be
strengthened to ∃!y.
Thus, from the hypothesis we get
∀x ∃!y [ jy = ix]
The idea that mappings are arbitrary means that, whenever ∀x∃!y[. . .] holds, then
there does exist a mapping k – in this case one for which
∀x[ j(kx) = ix]
Since there are “enough” 1
x  U, we conclude that jk = i, as required.
1
∀x
∃!y
U
k
i
V
j
A
We will soon be able to prove this strengthened converse on a more explicit basis
that does not depend on the vague “arbitrariness of mappings” principle.
Historically many mathematicians such as Dedekind and Banach used the same
symbol ⊆for both membership and inclusion, and indeed it is quite reasonable to
deﬁne x belongs to y for any two maps with codomain A and even to use the same
symbol for it
x ⊆y iff ∃z[x = yz]
where iff is the standard abbreviation for “if and only if”.
If y is not monomorphic, then such a z may not be unique; such z are often
called “liftings of x along y”. In the formalized set theory following Peano, the
membership symbol was given a completely different meaning, but mathematical
use of it has been as we deﬁned; thus, we feel justiﬁed in using the membership
symbol for this special case of the “belonging to” relation even though it is not
strictly needed. The notion obtained by reversing the arrows
may be called f is determined by h and is at least as important in mathematics
and its applications. Here the g, which shows a way of determining f values from
h values, is often called an “extension of f along h”; such a g is only guaranteed to

38
Sums, Monomorphisms, and Parts
be unique if h is “epimorphic” (the dual cancellation property). Epimorphic maps
with a given domain A are partitions (as opposed to parts) of A (see Section 4.4);
again the special case where both f and h are partitions rates special attention: in
that case the determining g is often called a “coarsening” of partitions (rather than
an including of parts).
Exercise 2.18
If f is determined by h, then any further ϕf is also determined by h.
General belonging and determining often reduce to the special cases of belonging
to parts (i.e., membership) and, respectively, of determining by partitions. This
happens because frequently a map y can be expressed as y = y0y1, where y0 is
“mono” and y1 is “epi”; then, if x belongs to y, it follows that x is a member of the
part y0 of A:
If z proves that x belongs to y, then y1z proves the stated membership; conversely,
if x ∈y0, then in a sense x “locally” belongs to y.
♦
Exercise 2.19
Formulate the dual construction, showing that if f is determined by h and if h has
a “mono/epi” factorization h = h0h1, then f is an invariant of the partition h1 of
the domain. (In suitable categories the converse will say that if f is an invariant
of h1, then some “expansion” of f is determined by h; the phrase “invariant of”
is frequently used in this context and is dual to “member of,” and we have used
the term “expansion” dually to a common use of the term “covering” to explain
“holding locally”.)
♦
2.4 Characteristic Functions
Given a chosen set V thought of as “truth values” and a chosen constant element
1
v1  V thought of as “true,” we can deﬁne a relationship as follows:
Deﬁnition 2.20: For any set A, mappingi with codomain A, and mapping A
ϕ  V ,
ϕ is an indicator or characteristic function of i if and only if
(1) i is monomorphic and
(2) for any T and any T
a  A
a ∈A i ⇐⇒ϕa = v1T

2.4 Characteristic Functions
39
(For any 1
c  C, cT denotes the constant map
T
T  1
c  C
with domain T and value c).
If we refer to the element v1 as “true,” then a is a member of i if and only if ϕa
is “true” since that is true for all a:
ϕi = v1U
where U = dom(i)
moreover for any a, if ϕa = v1T , then there is a for which a = ia:
Exercise 2.21
For example, if A = V and i = v1, then an indicator of v1 as required above is
ϕ = 1V .
♦
The exercise shows that (1) v1 is monomorphic, and (2) for any T and any
T
a  V
a ∈V v1 ⇐⇒1Va = v1T
The idea of the indicator, then, is that the general membership relation can be
represented by this particular case. An important fact about the category of abstract
sets is that for V = 2 and the chosen element 1
1  2 we have unique characteristic
functions for all parts of all sets. That is,
AXIOM: MEMBERSHIP REPRESENTATION VIA TRUTH VALUES
(1) Any A
ϕ  2 is the characteristic function of a part of A.
(2) Any part of A has a unique 2-valued characteristic function.
For categories of cohesive and variable sets there will still be a V ̸= 2 satisfying
properties (1) and (2), but that the set 2 has these two properties is special to the
category S and those special categories of variable sets called Boolean toposes.
The preceding principle will have a great many uses. It enables us, for example,
to count parts by counting 2-valued functions instead. Recall that counting requires
a clear notion for distinguishing the things being counted.

40
Sums, Monomorphisms, and Parts
Proposition 2.22: The following are equivalent for parts U
i
 A and V
j  A of
a set A:
(1) i ⊆A j & j ⊆A i,
(2) ∃h, k[ j = ih & i = jk & hk = 1U & kh = 1V ], and
(3) ϕ = ψ, where these are the characteristic functions of i and j, respectively.
Exercise 2.23
Prove the proposition, i.e. show that each of (1), (2), and (3) implies the others.
Hint: (2) obviously implies (1), but to see the converse remember that i and j are
parts.
♦
Deﬁnition 2.24: Parts i and j of a set A are equivalent, which we write i ≡A j if
and only if i ⊆A j & j ⊆A i.
Thus, characteristic functions do not distinguish equivalent parts, and parts are
distinguished for counting purposes only if they are not equivalent. Indeed, we will
sometimes abuse language by writing equivalent parts as equal. However, even if
two parts have the same number of elements in the sense we will describe soon in
Section 3.2, they need not be equivalent.
Exercise 2.25
If i and j are parts of A and their mere domains are isomorphic, meaning that
there are h, k satisfying hk = 1U & kh = 1V , then neither part need be included
in the other. However, if k also proves that i ⊆A j, then it follows that i ≡A j as
parts.
♦
2.5 Inverse Image of a Part
A frequent use of parts is in restriction of mappings.
Deﬁnition 2.26: If X
f  Y and if i is a part of X, then the composite f i
U
i
 X
f  Y
is called the restriction of f to the part i (often denoted f |i or f |i).
Exercise 2.27
Give an example of a surjective f and of a part of its domain such that the restriction
is not surjective. Give an example of f that is not injective but such that a restriction
of f is injective.
♦

2.5 Inverse Image of a Part
41
For example, if f describes the temporal variation of temperature throughout
a year and if j is the subzero part of the temperature values, then there can be a
certain week i in January such that f i ∈j.
Exercise 2.28
Monomaps are only left-cancellable and are not usually right-cancellable. Give an
example of distinct f, g with equal restrictions to the same part.
♦
An operation of fundamental importance in geometry, analysis, logic, and set
theory is that of forming the
INVERSE IMAGE OF A PART ALONG A MAP
which also goes under names like “substitution” or “pullback” in certain contexts.
Thus,ifwearegivenanarbitrarymap f from X toY andanarbitrarypart V  
i
 Y
of the codomain, then there is a part U  
i
 X of the domain such that
(0) for all T
x  X
x ∈i ⇐⇒f x ∈j
This is easily seen to imply that
(1) there is a commutative square
and that, moreover,
(2) any commutative square
can be expressed in terms of (1) by means of a common x:

42
Sums, Monomorphisms, and Parts
In other words, f restricted to the part i has its image in j, and i is the largest
part of X with that property.
(3) The x is unique (because we have assumed that i is a monomapping).
Exercise 2.29
(a) Show that (0) ⇒(1), (2), and (3).
(b) Show that (1), (2), (3), and j is mono ⇒i is mono.
(c) Show that (1), (2), and (3) ⇒(0).
(d) Show that for given f, j, if both i1, i2 satisfy (0), then i1 ≡X i2 as parts of X.
♦
The parti described above is called the inverse image of j along f . The operation
of inverse image has the following contravariant functoriality property:
Exercise 2.30
If j is the inverse image of k along g and if i is the inverse image of j along f ,
then i is the inverse image of k along g f .
♦
When there is a truth-value object V (such as the set 2 in the case of abstract sets),
i.e. an object “classifying” all parts by means of unique characteristic functions,
then inverse image is so intimately related to composing that the functoriality above
translates into a case of associativity (see Exercise 2.34).
Proposition 2.31: Y
ψ  V is the characteristic function of a part j if and only if
j is the inverse image along ψ of the one-element part 1
v1  V of V .

2.5 Inverse Image of a Part
43
Exercise 2.32
Prove the Proposition 2.31.
Hint: Apply the deﬁnition of indicator.
♦
Theorem 2.33: If ψ is the characteristic function of a part j, then for any f , ψ f
is the characteristic function of the inverse image of j along f .
Proof: Apply the functoriality of inverse image to the special case indicated.
■
Exercise 2.34
Interpret η(g f ) = (ηg) f in terms of the inverse images:
♦
An important special case of inverse image is intersection, which is what results
from inverse image along a map that is itself a part.
Exercise 2.35
The composite of monomaps is again such. Hence, if both f, j are monomaps and
i is the inverse image of j along f , then m = f i = j f is also a part, and for any y,
T
y
y ∈m ⇐⇒[y ∈j & y ∈f]
U
f
m

i
X 
f
V
j
Y
♦

44
Sums, Monomorphisms, and Parts
Deﬁnition 2.36: For parts i and j with the same codomain Y, a part m of Y is
called their intersection if and only if for all T, for all T
y  Y
y ∈m ⇐⇒[y ∈i & y ∈j]
The m so deﬁned is usually denoted m = i ∩j.
Remark 2.37: Exercise 2.35 proves that the inverse image of a part j along a
monomapping f is the intersection of the two parts j and f .
Exercise 2.38
Prove that we have j1 ∩j2 ≡j2 ∩j1.
♦
Inverseimagesalongarbitrarymapspreserveintersectionofpartsinthefollowing
sense:
Exercise 2.39
If X
f  Y and if j1, j2 are any two parts of Y, and if ik is the inverse image of jk
along f for k = 1, 2, then the inverse image of j1 ∩j2 along f is i1 ∩i2, where
the latter indicates intersection of parts of X. Brieﬂy, f −1( j1 ∩j2) ≡f −1( j1) ∩
f −1( j2), where we have exploited the essential uniqueness of the inverse image
operation to justify introducing a notation f −1( ) for it.
♦
2.6 Additional Exercises
Exercise 2.40
The category of vector spaces and linear transformations has sums, but they are
very different from the sums in S. Let V and V ′ be vector spaces.
(a) Show that the vector space V × V ′ of ordered pairs consisting of a vector from
V and one from V ′ (specify how this is a vector space!) is the sum.
Hint: The injection V
i0  V × V ′ sends v to (v, 0).
(b) Show that monomorphisms are injective linear transformations (i.e., those with
kernel 0). Thus, a subspace of a vector space determines a monomorphism to
the vector space (part of the space).
Recall that an object 1 that satisﬁes the axiom of the one-element set in a category
(i.e., for any object there is a unique map to 1) is called a terminal object of the
category. Dually, an object 0 that satisﬁes the axiom of the empty set in a category
(i.e., for any object there is a unique map from 0) is called an initial object of the
category.

2.6 Additional Exercises
45
(c) Show that the zero vector space is simultaneously a terminal object and an
initial object (such an object is called a zero object).
(d) Show that any part of a vector space has an inverse image along any linear
transformation. Remember to verify that the inverse image of the mapping is a
vector space.
Exercise 2.41
(a) Show that injective group homomorphisms are monomorphisms in the category
of groups and group homomorphisms.
(b) Show that the one-element group is a zero object.
The category of groups also has sums, but their construction is rather complicated –
they are sometimes called “free products”.
(c) Show that any part (= subgroup) of a group has an inverse image along any
group homomorphism.
Exercise 2.42
(a) Show that the category of partially ordered sets has sums.
Hint: The sum partial order is on the sum of the two sets involved. Elements
are related in the sum exactly if they are related in a component of the sum of
sets.
(b) Show that monomorphisms in the category of partially ordered sets are injective
monotone mappings.
(c) Show that the one-element set and the empty set with the only possible order
relations are the terminal and initial ordered sets.
Exercise 2.43
An important case of slice categories (see Exercise 1.30(e)) is the category of X-
indexed families of abstract sets S/X. Recall that in S/X objects are mappings
with codomain X and arrows are commutative triangles. The name “family” arises
as follows: For any object A
f  X of S/X and any element 1
x  X of X the
inverse image of x along f is a part of A denoted Ax and is called “the ﬁber of
A over x;” A is the “sum” of the family of all of its ﬁbers. This is a very simple
example of a variable set.
(a) Show that the category S/X has binary sums that are computed “ﬁberwise”.
(b) Show that monomorphisms in S/X are also “ﬁberwise” and have characteristic
morphisms taking values in the object 	 of S/X, which has each ﬁber equal
to 2.

46
Sums, Monomorphisms, and Parts
(c) Show that the terminal object in S/X is X
1X  X, and the initial object is the
unique 0
 X.
(d) Show that S/X has inverse images computed using the inverse images in S.
Exercise 2.44
(a) What are the parts of the terminal object in S/X (see the previous exercise)?
Show a one–one correspondence between them and elements of the object 	
above (i.e., arrows from the terminal object to 	).
(b) Show that the terminal object in S/X is not in general a separator. However,
show that for any parallel pair of different maps in S/X there is a map from a
part of the terminal object to the common domain that distinguishes the parallel
pair.
Exercise 2.45
A special case of the preceding examples occurs when X = 2. Here 2 has the
elements 0 and 1, and so each object of S/2 is just the sum of its two ﬁbers. A
related category is the “category of pairs of sets,” which we denote S × S. The
objects of this latter category are pairs written (A0, A1) of objects of S. An arrow
from (A0, A1) to (B0, B1) is a pair of mappings A0
f0  B0, A1
f1  B1.
(a) Show that S × S is a category.
(b) Show that any object (A0, A1) of S × S deﬁnes a unique object of S/2, and
conversely. Show that any arrow of S × S deﬁnes a unique arrow of S/2, and
conversely.
(c) Show that the correspondences in (b) respect identities and composition and
have the property that when their actions on objects are “composed” with each
other the resulting object is isomorphic to the starting object. In this situation,
we say that S × S and S/2 are equivalent as categories.
Exercise 2.46
(a) Show that the category of pointed sets 1/S (see Exercise 1.30(f)) has sums.
Hint: The sum of A, a and B, b is the set formed by taking the sum of the sets
A and B and then merging the elements a and b in A + B. Thus, the sum of a
two-element pointed set and three-element pointed set has how many elements?
(b) Describe monomorphisms in 1/S.
(c) Show that 1/S has inverse images.

2.6 Additional Exercises
47
Exercise 2.47
Let X be the category deﬁned by an ordered set X (see Exercise 1.31(b)).
(a) Show that objects x, x′ of X (elements of X!) have a sum exactly when they
have a least upper bound.
(b) Show that any arrow of X is a monomorphism.
(c) Show that a greatest element of X is a terminal object in X, whereas a smallest
element of X is an initial object.
(d) Show that a part of x (i.e., u ≤x) has an inverse image along an arrow to x
(i.e., x′ ≤x) if and only if u and x′ have a greatest lower bound.

3
Finite Inverse Limits
3.1 Retractions
We begin this chapter by observing an important condition which implies that a
mapping is a monomapping, namely, that it has a retraction.
Deﬁnition 3.1: For mappings r and i in any category, r is a retraction for i means
that ri is an identity mapping. In the same situation we say that i is a section for r.
To see more clearly what this says about domains and codomains, let X
i
 Y;
then, we see that r must have domain Y (in order that ri be deﬁned) and codomain
X (in order that ri could possibly be an identity mapping, necessarily that on X).
X
i
Y
r






ri = 1X
For a given mapping i, there may or may not be a retraction r for i, and there
might be many. (Similarly, a mapping r need not have any sections.) But to have
even one retraction is a strong condition:
Proposition 3.2: If i has at least one retraction r, then i is a monomapping (=
left-cancellable mapping, which we have seen is the same as injective mapping.)
Proof: We must show that for any x1, x2 as shown
T
x1

x2
 X
i
 Y
that ix1 = ix2 ⇒x1 = x2.
48

3.1 Retractions
49
So suppose ix1 = ix2. Then,
r(ix1) = r(ix2), so associativity of composition
(ri)x1 = (ri)x2, gives but ri being an identity
x1 = x2
map, this is as desired
■
(Note how closely this proof parallels the sort of calculation done in elementary
algebra: Suppose we know 7x1 = 7x2; then,
1
7(7x1) = 1
7(7x2)
( 1
77)x1 = ( 1
77)x2
1x1 = 1x2
x1 = x2
The construction in our proof is analogous to division by 7; i.e. to multiplication
by a multiplicative inverse for 7. The only new observation is that 1
7 does not really
need to be an inverse for 7, that is, to satisfy both 1
77 = 1 and 7 1
7 = 1; only the ﬁrst
of these equations was used – it is enough to have a left-inverse to be able to cancel
a factor on the left.)
Notice that this calculation gives more than merely knowing that i can be
cancelled;havingr providesaspeciﬁcreason,orproof,oftheleft-cancellabilityofi.
A mapping i that has a retraction is also called a split injection or split mono-
mapping. Thus,
Deﬁnition 3.3: The arrow i : X
 Y is a split injection if and only if
∃r : Y
 X [ri = 1X]
Such a mappingr is also sometimes called a “splitting for i” instead of “retraction
for i” or “left-inverse for i”. Here is a picture with internal diagrams (since this is
a monomapping, it is already a part of Y):
X
Y
•
•
•
•
•
•
•
•

50
Finite Inverse Limits
Now for r to be a retraction from Y back to X along i, ri = 1X, we see that for
any element x
r(ix) = (ri)x = x
so any element y of Y that came from an x must be sent by r back to where it
came from, and that is all the equation ri = 1X says. It says nothing about the other
elements of Y, if there are any; but of course, to be a mapping Y
 X, r must be
deﬁned for all those other elements of Y as well, and r must send them somewhere
in X (it does not matter where we send them, and so there will usually be many
possibilities for the mapping r).
X
Y
•
•
•
•
•
•
•
•
?
?
r?
One possibility is
X
Y
•
•
•
•
•
•
•
•
r
For example, with S the set of students, C the set of chairs, and
S
i
 C
assigning to each student the chair in which that student is sitting, r must assign
a student to every chair, and the equation says that to each occupied chair must
be assigned the student who is occupying it. But for the other chairs we can make
any deﬁnite decision we want; for instance, r could assign all the unoccupied chairs
to one particular student, or any other rule could be adopted for the unoccupied
chairs and would nonetheless complete the deﬁnition of yet another retraction r for
our given i.
We hope this example will show that, in the category of abstract sets, almost every
monomapping has at least one retraction: just pick any element of the domain to be

3.1 Retractions
51
the recipient of all the extra elements of the codomain. The only difﬁculty arises
when the domain is empty and the codomain is not: the (unique) map
0
 Y
is a monomapping but is not split if Y ̸= 0.
Claim 3.4: In the category of abstract sets and mappings, if X  
i
 Y is a
monomapping with domain X not empty, then i has a retraction.
To prove the claim we will use two properties of the category of abstract sets and
arbitrary mappings whose precise relation to our axioms will be established later
in Section 6.1:
(1) If X ̸= 0, then X has an element 1
x0  X;
(2) every part X  
i
 Y has a complement X′  
i′
 Y, i.e.
X
i
 Y
i′

X′
is a sum diagram.
Now,weproceedwithclaim3.4; X isnotempty,solet1
x0  X beanelementand
X′
i′  Y a complement of i. The deﬁning property of sum says that to deﬁne any
mapping Y
 X (in particular the r we are looking for) is equivalent to specifying
mappings from the two parts whose sum is Y. We use the mappings we have,
X
1X
 
i
Y
X
X′
 
 
i′
X′
1
x0
where the bottom arrow is the only mapping X′
 1. Now the universal mapping
property of sum tells us that there will be a mapping Y
r  X, making the diagram
commute as follows:
X
1X
 
i
Y
r
X
r =
 1X
x0X′
X′
 
 
i′

52
Finite Inverse Limits
Of course, we do not really need the commutativity of the bottom triangle, for the
top triangle says ri = 1X, which is all we wanted.
■
A proposition of this type is deﬁnitely not true in other categories with more geo-
metrical content. Examples of such categories are in the next exercise. We discuss
additional examples below in Exercise 8.11.
Exercise 3.5
The category C has as objects those parts of Rn, for various n, which are open. The
arrows of C are mappings between the objects that are continuous. (For deﬁnitions
of open and continuous see any advanced calculus text.) Show that C is a category,
that is, deﬁne composition and identities and check the axioms. A subcategory D
of C is deﬁned when we restrict to mappings that have a derivative. What rule of
elementary calculus shows that D has composition? A subcategory of D is obtained
by restricting to the smooth mappings – those that have all derivatives.
♦
In the category C, even though the sphere is a retract of punctured space (the
open part of Rn obtained by removing a single point), it is not a retract of the whole
(unpunctured) space. It is important to look at examples like this to get a better idea
aboutwhatpartofourreasoningcanbeusedinthesemoregeneralsituationswithout
change (for instance ri = 1X always implies i is a monomapping) and what part
is special to the category of abstract sets S (for instance i is a monomapping with
nonempty domain implies ∃r[ri = 1]). Let us describe the example more precisely:
In n-dimensional space (e.g., n = 2, the plane) we have the (n −1)-dimensional
sphere (i.e., the circle, if n = 2).
Claim 3.6: There does not exist any continuous retraction for the inclusion:
(n −1)-dimensional unit sphere  
i
 n-dimensional space, centered at the origin.
X
Y
X
Y
n = 2
i
This claim is proved in analysis but is reasonable on the basis of the intuition of
continuity. On the other hand, if we change the situation only slightly and replace
the codomain Y by the “punctured plane” with the origin removed, then there is a

3.1 Retractions
53
fairly obvious continuous retraction: just send each point in the punctured plane to
the unique point on the circle that lies on the same ray from the origin, i.e.,
If our circle has radius 1, the formula for r is
r(y1, y2) = ( y1
|y|, y2
|y|)
where |y| def
=

y2
1 + y2
2 is the distance from the point y = (y1, y2) in the plane to
the origin.
We could also have considered as codomain a unit ball rather than the whole
Euclidean space with the same result: that the unpunctured version is completely
different from the punctured version with respect to the question of continuously
retracting onto the sphere.
Exercise 3.7
Suppose S
i
 B
j  E are maps in any category. Then i has a retraction if ji
does.
♦
That our proof of the ubiquity of retractions for abstract sets does not work for
continuous sets can be understood more exactly if we recall that it was based on
the concept of sum and still more exactly on the concept of complementary part.
Although sums exist generally in the continuous category, it is emphatically not the
case that to every part X0  
 Y there is another part X1  
 Y together with
which it sums to Y. Indeed, we might take X1 as the “rest of” Y after removing X0,
but the deﬁning property of sum, (that any pair of maps f0, f1
X0
f0

 
i0



Z
X1
i1
f1

54
Finite Inverse Limits
can be combined via deﬁnition by cases to give a single map Y
 Z) will fail in
the continuous category C: even if f0, f1 were both continuous, their combination
on Y would not be unless a further condition were veriﬁed. For example, if X0 is the
circle included by i0 as the boundary of a disc Y and if i1 is the “rest” (i.e., the open
disk included by i1 as everything in Y except the boundary), then for continuity of
the “sum” map

f0
f1 one needs not only continuity of f0, f1 separately but also that
lim
n→∞f1(yn) = f0(x)
whenever yn is a sequence in the open interior i0, which tends to x on the boundary.
These matters are discussed more fully in courses in analysis and geometry.
3.2 Isomorphism and Dedekind Finiteness
“Equations” between sets, such as the statement that a set is the sum of two others
or that it is the inverse image of a part along a map (and many others that we will
meet soon such as the commutative law for products, the laws of exponents, the
distributive law, etc.) are not really equations but rather statements that certain sets
havethesamenumberofelements.Moreprecisely,theintendedstatementsoftensay
more:aspeciﬁcdemonstrationoftheequinumerosityisstatedtobeavailable.Sucha
demonstration is a given isomorphism in the category of abstract sets and mappings.
Deﬁnition 3.8: X
f  Y is an isomorphism (or is invertible) if and only if there
exists a Y
g  X for which both equations g f = 1X and f g = 1Y are true. Such
a g is called a (two-sided) inverse for f .
We obviously have the implications
f isomorphism
A ⇓
f has a retraction and f has a section
B ⇓
f is injective and f is surjective
Def ⇕
f is bijective
But we claim that implication A is reversible in any category and that implication
B is reversible in the category of abstract sets and arbitrary maps; thus, in this
category the isomorphisms are the same as the bijections (another name for which
is one-to-one correspondences).
The reversal of implication A above means that, even though retractions (= left
inverses) are not unique, and neither are sections (= right inverses), nonetheless if
both exist for the same f , then they are all equal:

3.2 Isomorphism and Dedekind Finiteness
55
Proposition 3.9: In any category,
X
f
 Y
r





	
s






if
then
A∗:
r f = 1X and f s = 1Y =⇒r = s
C :
∃r[r f = 1X] =⇒∀s1s2[ f s1 = 1Y and f s2 = 1Y =⇒s1 = s2]
Proof: On the assumption of the hypothesis of A∗,
r = r1Y = r( f s) = (r f )s = 1Xs = s
proving the conclusion of A∗. It should be clear that A∗implies the converse of A.
Because A∗is known, the proof of C requires us only to notice that C is equivalent
to
∀s1, s2∀r[r f = 1X and f s1 = 1Y and f s2 = 1Y =⇒s1 = s2]
which follows from two applications of A∗together with the remark that
r = s1 and r = s2 =⇒s1 = s2
■
Stated in words, C says that any two sections of f are equal provided that f has
at least one retraction; the proviso is certainly needed since most maps that have
sections have more than one.
The reversibility of implication B above, namely that any bijection has a two-
sided inverse, does not hold in some categories (such as that of continuous maps),
but it does hold in case the inverse is allowed to be an “arbitrary” map. One way to
prove it would be to assume that every surjective f has at least one section s (this
is the axiom of choice; see Section 4.3) and then use the following generally valid
proposition.
Proposition 3.10: If f s = 1Y and if f is a monomorphism, then s is the two-sided
inverse of f .
Proof: We are supposed to prove that s f = 1X, but as in other cases when we can
hope to use a cancellation property, we ﬁrst prove something a little longer,
f (s f ) = ( f s) f = 1Y f = f = f 1X
from which the conclusion follows by left-cancellation of f .
■

56
Finite Inverse Limits
However, that bijection implies isomorphism does not really depend on a power-
ful principle such as the axiom of choice; the latter is usually only required when
the map g to be constructed is not unique and hence must be chosen arbitrarily. But
the bijectivity of f says exactly that
∀y ∃!x [fx = y]
1
x
y
 
X
f
Y
the existence of x coming from the surjectivity of f and the uniqueness from
the injectivity of f . Hence, by the concept of “arbitrary map” there should be a
well-deﬁned map g such that
gy = the x for which [ f x = y]
for all y; then of course g f x = x for all x and f gy = y for all y so that g is the
two-sided inverse of f because 1 is a separator.
Notation: If g f = 1X and f g = 1Y, we write f −1 = g.
Proposition 3.11: If X
f  Y is an isomorphism, then Y
f −1  X is also an
isomorphism.
Proof: Writing the two equations g f = 1Y, f g = 1X in the opposite order, we see
that f = g−1, i.e. the f −1 has f as a two-sided inverse.
■
Proposition 3.12: If each of f1, f2 is an isomorphism and if f2 f1 makes sense,
then f2 f1 is also an isomorphism.
Proof: Let g1, g2 be two-sided inverses
The only obvious candidate for the inverse of the composite f = f2 f1 is the com-
posite in opposite order g = g1g2 of the inverses. Indeed
g f = (g1g2)( f2 f1) = g1(g2 f2) f1 = g11Y f1 = g1 f1 = 1X
f g = ( f2 f1)(g1g2) = f2( f1g1)g2 = f21Y g2 = f2g2 = 1Z

3.2 Isomorphism and Dedekind Finiteness
57
In other words,
( f2 f1)−1 = f −1
1
f −1
2
is the required two-sided inverse.
■
Notation: f : X
∼ Y means that f is an isomorphism. We say X is isomorphic
with Y, written X ∼= Y if there exists at least one f from X to Y, which is an
isomorphism, i.e.
∃f [ f : X
∼ Y]
As discussed previously this deﬁnition is used in every category, but in the case
of the category of abstract sets and arbitrary maps it is often referred to as being
equinumerous or having the same cardinality with isomorphic being reserved for
other categories in which naturally some further structure (such as group structure
or topological structure) will be the “same” between isomorphic X, Y. However,
abstract sets should be considered as the case of “zero structure,” and because
we have learned to treat the number zero on an (almost) equal footing with other
numbers, we should simplify terminology and our thinking by treating the cate-
gory of sets on an (almost) equal footing with other categories such as are met in
more structured parts of mathematics. That isomorphism of abstract sets gives us
a way to study equinumerosity without counting (hence also for inﬁnite sets) was
exploited systematically by Cantor. (He was anticipated to some extent by Galileo
and Steiner.)
Exercise 3.13
[Galileo Galilei, 1638] The set of all nonnegative whole numbers is isomorphic
with the set of all square whole numbers because the map f (x) = x2 has (with the
stated domain and codomain) a two-sided inverse g. What is the usual symbol for
this g?
♦
Of course counting will be one of the methods for investigating size (all methods
are consequences of the deﬁnition). Namely, if X is thought of as a “standard” set
(like {1, 2, 3, 4, 5}), then a speciﬁc counting process that counts a set Y is of course
a speciﬁc invertible map f : X
∼ Y. (Note that the same Y can be counted in
different “orders” by the same X, which would involve different maps.) If Z can
also be counted by the same X, we can then conclude that Y and Z are (objectively)
the same size (which is true independently of our subjectively chosen standard X
and of our choices of counting order):

58
Finite Inverse Limits
Corollary 3.14:
X
f ∼
g
∼
=⇒
∼
Y = Z
Y
Z
Proof: By Propositions 3.11 and 3.12, h def
= g f −1 shows the required existence.
■
The observation of Galileo that an inﬁnite set can be isomorphic to a proper part
of itself was turned into a deﬁnition by Dedekind:
Deﬁnition 3.15: A set X is said to be Dedekind-ﬁnite if and only if
∀f [X
f  X and f monic =⇒f isomorphism]
and correspondingly X is said to be Dedekind-inﬁnite if and only if
∃f [X
f  X and f monic and f not surjective]
Exercise 3.16
Show that X = [0, 1], the unit interval of calculus, is Dedekind-inﬁnite.
♦
Exercise 3.17
If X is Dedekind-ﬁnite, A  
i
 X is a part of X and A is equinumerous with X
(i.e., A ∼= X), then the part is the whole in the sense that i itself is invertible.
♦
3.3 Cartesian Products and Graphs
There is a common theme involving several different interrelated constructions that
we will now explore:
FINITE INVERSE LIMITS
Cartesian operations































Terminal object
Inverse image (of a part along a map)
Intersection (of parts)
Equalizers
Cartesian products
Pullbacks (= ﬁbered products)
and numerous subsidiary notions like
Graphs, diagonal, projections

3.3 Cartesian Products and Graphs
59
The French philosopher Ren´e Descartes is said to have introduced the idea that
dealing with more than one quantity can be done by introducing higher-dimensional
space. Along with that goes the idea of describing parts of higher-dimensional space
by means of equations. For example, consider the portion (circle) of the plane
where a certain equation is true. The operation of passing from the coordinatized
plane to the portion where the equation x2 + y2 = 1 is true will be an example of
the equalizer process. We can also intersect ﬁgures in higher-dimensional space,
raising questions such as: If two ﬁgures are described by equations, then is their
intersection also described by equation(s)? and so on. There is a rich interplay of
all these Cartesian operations, which are also called ﬁnite inverse limits.
We will ﬁnd that Cartesian products and equalizers will be sufﬁcient to construct
inverse limits, and so it turns out that inverse images can be deﬁned in terms of
equalizers and Cartesian product. Alternatively, equalizers can be deﬁned in terms
of inverse images, and thus we will have to understand not only what each of these
operations is but also how some of them can be deﬁned in terms of others because
these relationships are part of the lore of how the operations are used.
Let us consider ﬁrst a very simple but important example, namely the product
2 × 2, where 2 is a two-element set whose elements we can call 0,1 for convenience.
It will then turn out that the product 2 × 2 has four elements, which can be labeled
⟨0, 1⟩
⟨1, 1⟩
⟨0, 0⟩
⟨1, 0⟩
by “ordered pairs” of elements of 2. The universal mapping property, which we
will require of products in general, amounts in this case to the following: Suppose
X is any set and suppose that
X
ϕ  2,
X
ψ  2
are any two given maps with the same domain X and whose codomains are the
factors of the product 2 × 2 under consideration; then, there is a uniquely deﬁned
single map
X
⟨ϕ,ψ⟩ 2 × 2
whose domain is still X but whose codomain is the product and whose value at any
element x is the element of 2 × 2 labeled by the ordered pair of values determined
by the given ϕ, ψ:
⟨ϕ, ψ⟩x = ⟨ϕx, ψx⟩
The mapping ⟨ϕ, ψ⟩can be understood in terms of the parts of X for which ϕ, ψ
are the characteristic functions with 1 interpreted as true and 0 as false. If x belongs

60
Finite Inverse Limits
to the part characterized by ϕ but does not belong to the part characterized by ψ,
then, at such an x, ⟨ϕ, ψ⟩has the value
⟨ϕ, ψ⟩x = ⟨1, 0⟩
and similarly for the other three kinds of element x deﬁnable in terms of ϕ, ψ. Now
the mappings
2 × 2
 2
are usually called propositional operations or truth tables. For example, the map &
described by the table 2 × 2
&  2
u
v
u & v
0
0
0
0
1
0
1
0
0
1
1
1
is usually called “conjunction” and read “and”. Now a composite
with a propositional operator such as & yields a new property ϕ&ψ of (elements
of) X constructed out of the two given properties ϕ, ψ. A propositional operation
corresponds, via characteristic functions, to an operation on parts of any given X.
Proposition 3.18: If ϕ is the characteristic function of the part i of X and ψ is the
characteristic function of the part j of X, then
ϕ & ψ is the characteristic function of i ∩j
or, equivalently, if we denote by {X | ϕ} the part of X with characteristic function
ϕ, we have
{X | ϕ & ψ} ≡{X | ϕ} ∩{X | ψ}
Exercise 3.19
Prove the proposition.
♦
The product of any two sets A, B should be thought of as a “bag of dots” P
that has “the right number of elements” and is moreover equipped with a pair of

3.3 Cartesian Products and Graphs
61
“projection” maps πA, πB that “arrange P in rectangular fashion” as follows:
B
P
πB
πA
A
These features will follow from the deﬁnition below for products that directly
express the most basic act we constantly do in actual use of products. In the category
of abstract sets and mappings we will use the same deﬁnition of product that we
use in any category.
Deﬁnition 3.20: In any category, a product of two objects A and B is a pair of
given mappings
A
πA

P
πB  B
such that
∀X, f : X
 A, g : X
 B ∃!h : X
 P [ f = πAh and g = πBh]
as in the following commutative diagram:
A
X
f

h






g
		
P
πA


πB
 
B
AXIOM: BINARY PRODUCTS
Any two sets A, B have a product, A
πA

P
πB  B.
Usually we write P = A × B, h = ⟨f, g⟩so that the diagram in the axiom is
A
X
f

⟨f,g⟩






g

A ×
πA

πB
B

62
Finite Inverse Limits
Exercise 3.21
Show directly from the axiom that there is a map
B × A
τA,B
 A × B
for which
π A,B
A
τA,B = π B,A
A
π A,B
B
τA,B = π B,A
B
Using the uniqueness of the induced map as required in the axiom, show that
τA,BτB,A = 1A×B
the identity mapping. Caution: In dealing with more than one product, it is often
necessary to use a more precise notation for the projections as we have done in the
description of τ.
♦
Exercise 3.22
Show that for any A, 1 × A ∼= A.
Hint: To show one of the equations requires using the uniqueness clause in the
deﬁnition of product.
♦
The uniqueness of the induced maps into a product enables one to calculate their
values at (generalized) elements: If X
f  A, X
g  B, and if T
x  X, consider
the diagram
A
T
fx

x

gx

X
f

⟨f,g⟩

g

A × B
πA
πB
B
We see that ⟨f, g⟩x has the projections
πA(⟨f, g⟩x) = (πA⟨f, g⟩)x = f x
πB(⟨f, g⟩x) = (πB⟨f, g⟩)x = gx
Hence, by uniqueness of maps with speciﬁed projections, we obtain
⟨f, g⟩x = ⟨f x, gx⟩
An example apparently less abstract than that of 2 × 2 can be obtained by con-
sidering the description f of the ﬂight of a ﬂy trapped in a tin can C (during a time
interval T ). If A denotes the points on the base of the can, and if B denotes the

3.3 Cartesian Products and Graphs
63
points on the side seam, then there is a map C
πA  A that assigns to each point of
the space in the can its “shadow” in A, and there is also C
πB  B assigning to each
point in C the point on the seam at the same height. Then by composition we obtain
fA = πAf
fB = πBf
C
A
B
f
T
C
B
A
πAf
•
•
•
f
fA
fB
But conversely, if we were given a mapping T
f A  A from times to A (for example
by a movie ﬁlm that had been shot with the camera looking up from below through
a glass bottom), and if we were similarly given a temporal record T
fB  B of
the heights, we could uniquely reconstruct the actual ﬂight T
f  C as the only
mapping satisfying the two composition equations.
Deﬁnition 3.23: If A
f  B is any mapping, then (relative to a given object conﬁg-
ured as a product of A and B) by the graph of f is meant the mapping A
γ f  A × B
whose projections are the identity map 1A and f respectively as in the commutative
diagram:
A
A
1A

γf 
f

A × B
πA

πB

γf = ⟨1A, f⟩
B
For example, for any element x of A the value of γ f is γ f (x) = ⟨x, f x⟩in the
product:
Proposition 3.24: The graph of f is a part of A × B. The elements of A × B,
which are members of the part γ f , are precisely all those whose form ⟨x, y⟩has
the property that y = f x.

64
Finite Inverse Limits
Proof: Since πAγ f = 1A, we have that πA is a retraction for γ f and hence γ f is
monic and therefore a part of its codomain A × B. If T
p  A × B is any element
of A × B, it is necessarily of the form
p = ⟨x, y⟩
where x = πA p, y = πB p. If y = f x, then γ f (x) = ⟨x, f x⟩= ⟨x, y⟩= p so that
Conversely, if p is a member of γ f there must be an x that “proves” this membership
so that p = ⟨x, f x⟩.
■
Using the picture of a product as a rectangular arrangement with pairs labeling
its elements, we get a very graphical internal picture of a map that is at least as
important as the cographical internal picture of f .
•
⟨x, fx⟩
γfx = ⟨x, fx⟩
•x
B
A
A × B
When we need to calculate explicitly using this idea that the graph is also a map,
we recover the original f just by composing
f = πBγ f
Proposition 3.25: Any section of the projection A × B
πA  A is the graph of a
unique map A
 B.
Proof: Recall that a section of a mapping π is a mapping s for which πs = 1A. If
π = πA is the projection from a product we can compose a given section s with the
other projection, obtaining
f def
= πBs

3.3 Cartesian Products and Graphs
65
But then s must be the graph of the f so deﬁned because
γ f = ⟨1A, f ⟩
is the unique map for which the projections are 1A and f , and by construction s
has those two projections.
■
Proposition 3.25 suggests considering that for any map
E
π  A
(not necessarily a projection from a product), any section s of π could be regarded
as a “generalized map” with domain A but with a variable codomain, that is, the
value of such a “map” at 1
x  A lies in the ﬁber Ex of π over x, and these ﬁbers
may vary. This point of view is very important in mathematics when, for example,
considering vector functions, ﬁber bundles, and so forth.
Exercise 3.26
Show that the ﬁber (= inverse image of x along π) of π at x “is” B if π =
πA : A × B
 A.
♦
In the case of a product with two (or more) factors repeated, we may use a slightly
different way of abbreviating the notation for the projections:
A × A = A2
π0

π1
 A
π0⟨a0, a1⟩= a0
π1⟨a0, a1⟩= a1
Moreover, among the many possible graphs in this case, there is an especially
simple one that nonetheless sometimes needs to be mentioned explicitly, the graph
of the identity map on A, which is often called the diagonal map δA = ⟨1A, 1A⟩, so
A
δA  A × A
π0

π1
 A
satisﬁes
πkδA = 1A for k = 0, 1
A given map
A2
θ  A
is often called a “binary algebraic operation on A” since, for any two elements
a0, a1 of A, θ will produce a single element as a result:

66
Finite Inverse Limits
(A frequently used notation is to write the symbol for the operation between the
symbols for the two elements of A, which are the components of the element of A2 to
which the operation is being applied). Thus, for example & is a binary operation on
A = 2 (the set of truth values), and multiplication IR2
·  IR is a binary operation
on the set A = IR of real numbers.
Exercise 3.27
What is the composite map
usually called?
♦
Exercise 3.28
A binary operation θ is said to satisfy the “idempotent law” if the composite
A
δA 
1A

A2
θ
 A
is the identity. Does multiplication of real numbers satisfy the idempotent law?
What about conjunction 2 × 2
 2 of truth values?
♦
3.4 Equalizers
Deﬁnition 3.29: Given A
f

g
 B, an equalizer for f with g is any map E
i
 A
such that
(1) f i = gi
(2) ∀T ∀x [ f x = gx =⇒∃! x [x = ix]]
as in the following commutative diagram:
T
x
x
 
E
i
A
f
g
B
Exercise 3.30
Any equalizer i (as in the deﬁnition) is a part of A. If i is an equalizer, then for
any x
x ∈i ⇐⇒f x = gx
♦

3.4 Equalizers
67
Exercise 3.31
Suppose that E
i
 A and E′
i′  A are equalizers of the parallel pair A
f

g
 B.
Show that E ∼= E′ by an isomorphism compatible with i, i′; we say that i and i′
themselves are isomorphic.
Hint: Use the universal mapping property of equalizers to ﬁnd candidate inverse
isomorphisms.
♦
Notice that the same proof would also show that any two products of X and Y
are isomorphic. This justiﬁes a common abuse of language that allows us to speak
of the equalizer of f and g or the product of X and Y. That is, any two equalizers
(or products) are “equal” up to isomorphism, and this provides further examples of
the “equations” among sets that we mentioned at the beginning of Section 3.2. The
proof that the inverse image of a part along a map is unique up to isomorphism is
the same as those given above. The proof that the sum is unique up to isomorphism
is dual, i.e., it is the same proof with the arrows reversed.
Because of their great importance in mathematics, we might want to assume as
an axiom that equalizers always exist for any parallel pair f, g of maps. However,
having assumed the existence of products and inverse images, it turns out that we
can prove the existence of equalizers – indeed by two different constructions.
Exercise 3.32
The equalizer of the projection maps B2
π0

π1
 B is the diagonal B
δB  B2. Given
any A
f

g
 B, we can form the single map ⟨f, g⟩: A
 B2 along which we can
take the inverse image of the part δB.
Prove that if i is assumed to have the universal mapping property appropriate to the
particular inverse image, it follows that i also has the universal mapping property
required of the equalizer of f with g.
♦
The other construction of the equalizer will only use that special case of inverse
image known as intersection. Given A
f

g
 B, then each of them has a graph,

68
Finite Inverse Limits
which is a part of A × B:
•
•
•
•
•
•
A
A × B
f
g
γf
γg
If we intersect these two parts of A × B, we clearly get a part of A × B that “sits
over” the desired part of A. To establish this fact rigorously, note that both of the
graphs actually have the same domain A, thus, their intersection E
j  A × B,
being included (⊆) in both, participates in a commutative diagram
where i f and ig are the “proofs” of the respective inclusions. But i f , ig are both
maps from E to A, and the unusually special construction actually leads to the
following:
Proposition 3.33: i f = ig.
Proof: Since γ f i f = γgig,
πAγ f i f = πAγgig
But by half of the deﬁnition of graph,
πAγ f = 1A = πAγg
hence, i f = ig.
■
Exercise 3.34
Deﬁne i = i f = ig as in Proposition 3.33. Show that f i = gi and that indeed i is the
equalizer of f with g. Hence, the equalizer of two maps can always be constructed
whenever we can form their graphs and intersect them.
♦

3.5 Pullbacks
69
3.5 Pullbacks
The constructions of terminal object, cartesian product, inverse image, intersection,
and equalizer are all special cases of one general construction called “limit”. In
practice there are several other instances that often occur, a frequent one being
“pullback” or “ﬁbered product”. We will show in Section 3.6 that the existence of
equalizers and ﬁnite products sufﬁces to guarantee the existence of all ﬁnite limits
and also that the existence of pullbacks and the terminal object sufﬁces for the
existence of all ﬁnite limits.
Deﬁnition 3.35: Given any two maps with common codomain A0
f0  B
f1

A1 a
pullback (or ﬁbered product) of them means a pair of maps π0, π1 with common
domain P that
(1) form a commutative square f0π0 = f1π1
and, moreover,
(2) are universal among such squares in that,
for any T, a0, a1
f0a0 = f1a1 ⇒∃!a [a0 = π0a and a1 = π1a]
We point out that like products, equalizers, inverse images, and sums, pullbacks
are unique up to unique isomorphism. The proof is once again that of Exercise 3.31,
and we will speak of P as the pullback of f0 and f1 without explicitly mentioning
π0 and π1.
The uniqueness of the induced maps into a pullback enables one to calculate
their values at (generalized) elements: Suppose X
a0  A0, X
a1  A1 satisfy

70
Finite Inverse Limits
f0a0 = f1a1, and so they deﬁne an arrow to the pullback denoted X
⟨a0,a1⟩ P. If
T
x  X is any generalized element of X, then the value ⟨a0, a1⟩x has the projec-
tions
π0(⟨a0, a1⟩x) = (π0⟨a0, a1⟩)x = a0x
π1(⟨a0, a1⟩x) = (π1⟨a0, a1⟩)x = a1x
Hence, by uniqueness of maps with speciﬁed projections, we obtain
⟨a0, a1⟩x = ⟨a0x, a1x⟩
and hence the latter pair is the generalized element of P, which is the required
value.
Proposition 3.36: If products of two objects and equalizers exist, then pullbacks
exist.
Proof: Given data f0, f1 as above, ﬁrst form the product A0 × A1 with projections
now denoted pi for i = 0, 1. The square
is usually not commutative, but we can form the equalizer P  
i
 A0 × A1 of the
two composites f0 p0, f1 p1, that is the part of the product on which the diagram
becomes commutative. If we then deﬁne
π0 = p0i
π1 = p1i
we will have f0π0 = f1π1. If the (generalized) element ⟨a0, a1⟩of A0 × A1 satisﬁes
f0a0 = f1a1, then it will actually be a member of i, with a unique “proof” a; but
⟨a0, a1⟩= ia ⇒
a0 = p0⟨a0, a1⟩= p0ia = π0a
a1 = p1⟨a0, a1⟩= p1ia = π1a
as required of a pullback.
■
Proposition 3.37: The existence of pullbacks and terminal object implies the exis-
tence of binary products, inverse images, intersections, and equalizers.

3.6 Inverse Limits
71
Proof: If B = 1, then there is only one possibility for f0, f1, and moreover any
square ending in B is commutative. Hence, the diagram
shows that product is literally a special case of pullback provided we have a terminal
object 1 (of course in the category of sets we have a terminal object, namely a one-
element set). We have previously seen that equalizers can be constructed using
products and intersections (of graphs) or using products and inverse images (of
diagonal parts). Further, we saw that intersection may be considered as a special
case of inverse image. The proposition will be proved if we can show that inverse
image is a special case of pullback; the interesting aspect, which requires proof, is
considered in the following exercise.
Exercise 3.38
Suppose that
is a pullback square and also that j is a monomorphism. Then it follows that j is a
monomorphism.
■
3.6 Inverse Limits
Now we want to describe the more general concept of limit. The data for a limit
construction involve a family Ai of objects and a family f j of arrows between them.
Actually, we should specify a data type
J
d

c
 I

72
Finite Inverse Limits
(or “directed graph”), where J is a set of indices for the arrows f j in speciﬁc data
of this type and I is the set of indices for the objects A j. In data of the given type,
the domains and codomains are required to be given by the maps d, c:
Ad( j)
f j  Ac( j)
for all
1
j  J
(We call the data type ﬁnite if I and J are ﬁnite. We do not require that the Ai’s
be ﬁnite.)
Deﬁnition 3.39: The limit (also called inverse limit) of given data Ai, f j as above
is given by a single object L together with a universal cone; here by a cone with
vertex L and with base the given data is meant a family
L
πi  Ai
for
1
i
 I
of maps satisfying
That the above cone is universal means that for any object T and any cone with
vertex T and with the given data as base, i.e. for any family
T
ai  Ai
for
1
i
 I
for which
f jad( j) = ac( j)
for all
1
j  J
there is a unique
T
a  L
that preserves the cone structure such that
ai = πia
for all
1
i
 I
For example, products of I factors are easily seen to be limits according to the
data type
0
 I

3.6 Inverse Limits
73
forinthecaseofproductstherearenogiven“bondingmaps” f j andcorrespondingly
no equations presupposed in the universal property. On the other hand, equalizers
are limits according to the data type
2
d

c
 2
where d, c are the two distinct constant maps, because any equalizer data
A
f

g
 B
involves two given arrows between two given objects according to the scheme that
both arrows have the same domain A (hence constancy of d) but also the same
codomain B (hence constancy of c).
Exercise 3.40
Specify a pair of mappings 2
 3 so that limits according to this data type are
pullbacks.
♦
Once again we note that limits are unique up to isomorphism.
AXIOM: FINITE INVERSE LIMITS
S has all ﬁnite limits.
This means that there is a limit for any data for any ﬁnite data type whatsoever.
Luckily the general property can be deduced from simpler information.
Theorem 3.41: In any category, if products and equalizers exist, then limits ac-
cording to any data type can be constructed.
To help in understanding the following proof notice that Proposition 3.36 is a
special case of this theorem and that the construction used in the proof of that
proposition is generalized here.
Proof: Given the data type
J
d

c
 I
and also given Ai, f j such that
Ai
f j  Ai′
whenever
d( j) = i
c( j) = i′

74
Finite Inverse Limits
consider the products 
1
i→I
Ai and also 
1
j→J
Ac( j).
Thus, for example, if the data type is
4
 5
expressing the graph
A0
f0








A2
f1

f2








A4
f3

A1
A3
then the ﬁrst product has ﬁve factors, namely all the Ai’s, but the second product
has four factors that (since c has only two values, etc.) are really just A1 taken twice
and A3 taken twice.
Now between the two products we can construct two maps:
	
1
i→I
Ai
p

f

	
1
j→J
Ac( j)
where for all j
which determines f by determining all of its J coordinates as being (essentially)
all the given bonding maps f j. The other map p is simpler for it does not depend
on the given bonding maps at all.
Now if we are given any family of maps
T
ai  Ai
for
1
i
 I

3.7 Additional Exercises
75
it can be considered as a single map T
⟨ai⟩I  I Ai. Consider the diagram
T
⟨ai⟩I  I Ai
p

f
 J Ac( j)
By construction of p and f , ⟨ai⟩I will satisfy the equation
p⟨ai⟩I = f ⟨ai⟩I
if and only if the given family satisﬁes the family of compatibility equations
ai′ = f jai
whenever
d( j) = i
c( j) = i′
Hence, if we let
L
e  Ai
be an equalizer of p, f
then precisely such “ f j compatible” families will factor across the monic e. That
is, if we deﬁne
πi = pie
for
1
i
 I
then πi will have the universal mapping property required of the limit.
■
Corollary 3.42: If pullbacks and a terminal object exist in a category, then all
ﬁnite limits exist.
Proof: Proposition 3.37.
■
Exercise 3.43
A terminal object is an inverse limit.
Hint: The data type for the limit has both I and J empty.
♦
Exercise 3.44
For any given single map X
f  Y, the pullback of f along itself is often called
“the equivalence relation associated to f ”. This pullback involves a pair of maps
K
 X and hence a single map e to X × X. For any parallel pair T
x1

x2
 X,
f x1 = f x2 iff ⟨x1, x2⟩belongs to e. (See also Proposition 4.8 and Exercises 4.22
and 4.23.)
♦
3.7 Additional Exercises
Exercise 3.45
Show that the category of ﬁnite-dimensional vector spaces has all ﬁnite limits.
Hint: They are computed using the ﬁnite limits in S.

76
Finite Inverse Limits
Exercise 3.46
(a) Show that in the category of ﬁnite-dimensional vector spaces the sum and the
product of two vector spaces V, V ′ are the same vector space that we usually
denote V ⊕V ′. It has both projections and injections.
This means that if V is a vector space there is both a diagonal linear transformation
V
δV  V ⊕V and a codiagonal linear transformation V ⊕V
γV  V . Therefore
we can deﬁne a binary operation on linear transformations T, T ′ : V
 V ′, whose
result is the threefold composite
T + T ′ = V
δV  V ⊕V
 V ′ ⊕V ′ γV ′  V ′
The middle arrow is called T ⊕T ′.
(b) Show how to deﬁne T ⊕T ′, that + coincides with the sum of linear transfor-
mations met in linear algebra, and that + makes the linear transformations from
V to V ′ into a group.
Exercise 3.47
Show that the category of groups has all ﬁnite limits.
Exercise 3.48
(a) Show that the categories S/X have all ﬁnite limits.
Hint: They are computed “ﬁberwise”.
More generally,
(b) for any category C that has all ﬁnite limits, show that C/X has all ﬁnite limits
for any X in C.
Exercise 3.49
Show that the category of pointed sets 1/S has all ﬁnite limits.
Exercise 3.50
Sets with action: Given a set A (frequently referred to as an “alphabet”), by an
“action” of A on a set S is meant any mapping S × A
δ  S.
(a) Show that sets equipped with given A-actions form a category if we take
as arrows from (S, δ) to (S′, δ′) those mappings S
ϕ  S′ such that ϕδ =
δ′(ϕ × 1A). (A special case where A has two elements was considered in Exer-
cise 1.30 (d).)
When δ is given, it is convenient to abbreviate δ(s, a) simply by sa and call
it the action of a on s.
(b) Show that the category of A-sets has sums and ﬁnite limits.

3.7 Additional Exercises
77
Exercise 3.51
M-sets:Amonoidisaset M withanassociativebinaryoperation(thatism(m′m′′) =
(mm′)m′′ for any three elements) and an element 1 which is an identity (that is
1m = m = m1 for any m). If M is a monoid and X is a set, a (right) action of M
on X is a mapping X × M
δ  X such that x1 = x and (xm)m′ = x(mm′) (where
we are writing xm for δ(x, m)). A set X equipped with an action of M is called
an M-set. A morphism of M-sets from X to X′ is a mapping X
ϕ  X′ that is
equivariant, (i.e., it satisﬁes an equation like that above for A-sets.)
(a) Show that M-sets form a category.
(b) Show that the category of M-sets has sums and ﬁnite limits.
Actually the category of A-sets is a special example of a category of M-sets,
where M is the special free monoid
M = A∗= 1 + A + A × A + A × A × A + . . .
What should the inﬁnite “sum” mean?
Exercise 3.52
If X is the category formed from a partially ordered set X, show that a product of
two objects is exactly the same thing as a greatest lower bound.

4
Colimits, Epimorphisms, and the Axiom of Choice
4.1 Colimits are Dual to Limits
Each notion of limit has a corresponding “dual” notion of colimit whose universal
mapping property is obtained by reversing all arrows. Thus, for example, the termi-
nal object 1 has the limit property that every object X maps uniquely to 1, whereas
the coterminal (or initial) object 0 has the dual property that every object Y has a
unique map from 0. The limit concept of product, i.e. a span (= pair of arrows
with common domain) A
πA

A × B
πB  B such that spans A
f

X
g  B as
below uniquely determine the ⟨f, g⟩in
A
X
f

⟨f,g⟩






g

A × B

B
(which expresses the universal mapping property of projections), dualizes to the
concept of coproduct, i.e. a cospan of injections A
i A  A + B
iB

B such that
cospans A
f  Y
g

B as below uniquely determine the

f
g in
Theuniversalmappingpropertyforinjectionstothecoproductshouldberecognized
immediately as that for the injections to the sum. Similarly, the concept of equalizer
78

4.1 Colimits are Dual to Limits
79
for f, g, namely a (necessarily mono!) arrow E
i
 A for which arrows X
x  A
“equalizing” f and g ( f x = gx) uniquely determine the X
x  E, as in
dualizes to the concept of coequalizer for f, g, namely an arrow B
q  Q for which
arrows B
y  Y “coequalizing” f and g (i.e., y f = yg) uniquely determine the
Q
y  Y in
which we will study in more detail later.
Exercise 4.1
Formulate the notion of “pushout,” the colimit concept dual to pullback.
♦
Exercise 4.2
Formulate the general notion of the colimit of a data type
J
 I
♦
Exercise 4.3
Prove that the existence of pushouts and an initial object implies the existence of
coproducts.
Hint: Use the dual of Proposition 3.37.
♦
Exercise 4.4
Find sufﬁcient conditions to guarantee the existence of all ﬁnite colimits. Prove that
the conditions are (necessary and) sufﬁcient.
Hint: Use the dual of Proposition 3.41.
♦

80
Colimits, Epimorphisms, and the Axiom of Choice
We require the axiom that the category of abstract sets and mappings has all ﬁnite
colimits:
AXIOM: FINITE COLIMITS IN S
S has all ﬁnite colimits.
This axiom is dual to the axiom of ﬁnite limits. It includes the axiom of the empty
set and guarantees that ﬁnite sums, coequalizers, and pushouts all exist in S.
4.2 Epimorphisms and Split Surjections
Although seemingly not a limit notion, the concept of monomorphism also has its
dual, that of epimorphism:
Deﬁnition 4.5: An epimorphism f is a map that has the right-cancellation prop-
erty ∀φ, ψ[φf = ψ f ⇒φ = ψ].
We will use the term epimapping (or epimap) interchangeably with the term
epimorphism for mappings in S and also use the term epic as an adjective.
Exercise 4.6
Any coequalizer is an epimorphism.
Hint: Recall the dual proof!
♦
Exercise 4.7
Recall the deﬁnition of cograph from Section 2.1. Show that the cograph is an
epimorphism. Show that any retraction of the injection B
i1  A + B is the cograph
of a unique mapping from A to B. (These results are dual to Propositions 3.24 and
3.25.)
♦
We will study below the relationship between epic and “surjective” (which in
form is not dual to “injective,” although it does turn out to be equivalent to the dual
in very particular categories such as S).
There is actually an important link between cancellation properties and limits.
Proposition 4.8: A map i is a monomorphism if and only if when we form the
pullback of i with itself the two projections are equal.
Proof: Suppose the square below is a pullback and moreover π0 = π1 = π.

4.2 Epimorphisms and Split Surjections
81
If ix0 = ix1, then by the universal property of pullbacks, there is a unique T
x  P
forwhichboth x0 = π0x, x1 = π1x.Butsincewehaveassumedπ0 = π1,thisyields
x0 = x1; i.e. i has left-cancellation.
Conversely, assume i has cancellation and that π0, π1 form a pullback of i with i.
Then in particular iπ0 = iπ1, hence by cancellation π0 = π1.
■
Exercise 4.9
Without considering the internal picture, show that a map is epimorphic iff two
normally different maps in the pushout of the map with itself are equal.
♦
Using simple properties of the sets 1 and 2, one can show that in the category of
abstract sets and mappings:
Proposition 4.10: A mapping X
p  Y is an epimapping iff it is surjective.
Proof: Assume p is epic, that is, it satisﬁes the right-cancellation law
ψ0 p = ψ1 p ⇒ψ0 = ψ1
X
p  Y
ψ1

ψ2
 V
for all V . We want to show that p is surjective, that is
∀y∃x[px ?= y]
1
x
y
?
X
p
where y is any element of Y with domain 1. To arrive at a proof by contradiction,
suppose that contrary to the desired conclusion there is at least one y0 for which
there is no corresponding x, i.e. px ̸= y0 for all x. Take V = 2 and let ψ1 be the
characteristic function of (the one-element part) y0, but let ψ0 be the “constantly

82
Colimits, Epimorphisms, and the Axiom of Choice
false” map Y
 2. Then for all elements x : 1
 X of X
(ψ1 p)(x) = ψ1(px)
= false sincepx ̸= y0 and ψ1(y) = true iff y = y0
= ψ0(px)
= (ψ0 p)x
hence, ψ1 p = ψ0 p since 1 is a separator. But then ψ1 = ψ0 since we assumed p
epic. However, by the way we deﬁned ψ0 and ψ1, ψ1y0 ̸= ψ0y0, and so we reach
a contradiction, showing that there is no such y0 (i.e., p is surjective).
For the converse part of the proposition, assume that p is surjective and try to
show the right-cancellation property; thus, suppose ψ1 p = ψ0 p, where V is now
arbitrary, as are ψ0, ψ1. We will use the fact that 1 is a separator. Let y be an arbitrary
element of Y. By surjectivity of p there is an element x : 1
 X such that y = px,
and so ψ0y = ψ0(px) = (ψ0 p)x = (ψ1 p)x = ψ1(px) = ψ1y.
1
x
y
X
p
Y
ψ0
ψ1
Hence, ψ0 = ψ1 since 1 separates. Because this cancellation holds for all V , we
have proved that p satisﬁes right-cancellation, i.e. it is epic.
■
If we strengthen the notion of surjectivity to demand the extreme case of existence
of prevalues for all generalized elements, not only elements with domain 1, we
obtain the strong condition of split surjectivity:
Deﬁnition 4.11: An arrow X
p  Y is split surjective if and only if
∀T∀y∃x[px = y]
T
x


   
y
 






X
p

One often expresses this property of p by saying that every y has a lift x. To see
why, redraw the triangle with p vertical as is often done for continuous mappings
in topology.
Proposition 4.12: An arrow X
p  Y is split surjective iff there exists a section
for p.
Proof: If p is split surjective, let T = Y and y = 1Y, the identity mapping of Y.
Then, as a very special case of the split surjectivity, there exists x = s such that

4.2 Epimorphisms and Split Surjections
83
Y
s
   
1Y







ps = 1
X
p
 Y
In other words, p has a section s (usually there will be many).
Conversely,suppose p hasasections;thenwearetoshowthat p issplitsurjective.
So consider any T and any T
y  Y. There is an obvious way to attempt to construct
the x we need: try x def
= sy
T
y
 






X
p


s

We then have to show that the x so constructed really maps back to y under p, as
required for split surjectivity:
px = p(sy)
by deﬁnition of x
= (ps)y
by associativity
= 1Y y
since s was a section of p
= y
Thus p is split surjective if it has a section, and hence the proof of the proposition
is complete.
■
Since split surjectivity trivially implies surjectivity (just take the special case
T = 1), we have, by means of the logical equivalences in the last two propositions,
actually already proved the following proposition. However, we will also give a
direct proof in the hope of further clarifying the relationship between the concepts.
Note that the proof that follows is valid in any category.
Proposition 4.13: Any mapping p that has a section is an epimorphism.
Proof: Let s be a section for p. We must show that p has the right-cancellation
property; thus, assume
ψ0 p = ψ1 p
X
p  Y
ψ2

ψ1
 V
where V is arbitrary. But then
(ψ0 p)s = (ψ1 p)s
ψ0(ps) = ψ1(ps)
ψ0 = ψ1
since ps = 1Y
as was to be shown.
■

84
Colimits, Epimorphisms, and the Axiom of Choice
4.3 The Axiom of Choice
The converse of the last proposition, namely that there are no epimappings except
for those that actually have sections s, is not at all obvious. Once we have a section in
hand, cancellation becomes the result of a concrete process of calculation, as in the
preceding proof, unlike the abstract leap involved in just “doing the cancellation”.
On the other hand, where the section comes from may also be mysterious. The
usual point of view is that the converse is true for constant abstract sets (and is in
fact a strong testimony to the “arbitrariness” of the maps in that category), whereas
it is obviously false for sets that are less abstract, less constant, or both (as we will
soon see). The name of the converse is
AXIOM: THE AXIOM OF CHOICE
Every surjective mapping is split surjective (i.e., every epimap has a section).
Much ink has been spilled over this axiom.
Proposition 4.14: Any section s for a map p is a single procedure that
simultaneously chooses an element from each ﬁber of p
where the important notion of ﬁber is given by
Deﬁnition 4.15: For each X
p  Y and 1
y  Y, the ﬁber of p over y is the
domain of inverse image of the singleton (= one element) part y along p
Proof: (of Proposition 4.14.) Since ps = 1Y, p(sy) = y, i.e. sy ∈p−1[y]; in other
words sy is a member of the ﬁber of p over y, but this is so for all y.
■
Now (as further axioms of higher set theory reinforce) any reasonable family of
sets parameterized by a set Y can be realized as the family of ﬁbers of some single
map p with codomain Y. The sets in the family are all nonempty if and only if p is
surjective (see Exercise 4.16). Hence, the axiom of choice, “Every surjective map

4.4 Partitions and Equivalence Relations
85
is split surjective,” says that any family of nonempty sets has at least one choice
map that chooses an element from each set in the family.
Exercise 4.16
Show that the mapping p is surjective iff each of its ﬁbers has at least one element.
♦
Exercise 4.17
Show that the mapping p is injective iff each of its ﬁbers has at most one element.
♦
Thus, a mapping is bijective if and only if each of its ﬁbers has exactly one
element.
Exercise 4.18
Show that the mapping from real numbers to real numbers deﬁned by the formula
f (x) = x2(x −1)
is surjective and hence has sections in the category of abstract sets and arbitrary
mappings. Show, however, that none of these sections are in the continuous category
(see Exercise 3.5) because each one must have a “jump”.
♦
As we will see in Appendix B, an equivalent form of the axiom of choice, often
used in proofs in analysis and algebra, is
The Maximal Principle of Zorn
4.4 Partitions and Equivalence Relations
The dual notion (obtained by reversing the arrows) of “part” is the notion of
partition.
Deﬁnition 4.19: A partition of A is any surjective mapping p with domain A. The
ﬁbers of p are called the cells of the partition.
Proposition 4.20: Let A
p   I be surjective, and for each 1
i
 I let Ai be the
cell of p over i. Then all the Ai are nonempty parts of A; every element of A is in
exactly one of the Ai.
By way of explanation, note that every (not necessarily surjective) mapping with
domain A gives rise to a partition of A, as described in the proposition, by restricting

86
Colimits, Epimorphisms, and the Axiom of Choice
consideration to those elements of the codomain at which the ﬁber is nonempty. In
other words, a general mapping speciﬁes more information than just the partition
of its domain in that it speciﬁes also the size of the part of the codomain where the
ﬁbers are empty. By restricting to the case where the latter part is empty (i.e., to the
case of surjective mappings), we are in the case of mappings that specify no more
(and no less) than a partition of the domain. This “justiﬁes” Deﬁnition 4.19.
(A similar discussion could have been given for the dual concept “part of B”. That
is, any mapping with codomain B gives rise to a part of B, namely the part whose
members are just those elements of B that actually are values of the given mapping.
However, a general (not-necessarily-injective) mapping speciﬁes much more infor-
mation than just this “image” part since the members of the image will have some
“multiplicity,” i.e. will be values of the map at more than one element of the domain
(multiplicity = size of ﬁber). Injective mappings (where all nonempty ﬁbers have
multiplicity exactly one) are just parts, without any additional information.
Here is a typical cograph picture of a partition of a set A into three parts:
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
• • •
•
•
•
•
•
•
•
•
•
•
•
•
In terms of partitions, the axiom of choice can be rephrased by saying that for any
partition p of any set, there exists at least one choice function s that chooses an
element from each cell of the partition
The axiom of choice seems quite plausible because we are allowing “arbitrary”
mappings s. In categories in which only geometrically “reasonable” mappings are
allowed, the axiom of choice is usually not true; but this only points out that such
categories are distinct from the category of constant sets and arbitrary maps, which
itself exists as an especially simple extreme case with which to contrast the others
(Cantor’s abstraction). Some of the opposition to the axiom of choice stems from

4.4 Partitions and Equivalence Relations
87
its consequence, the Banach–Tarski Paradox, which states that a solid ball can
be shattered into ﬁve parts of such an unreasonable “arbitrary” nature that they
can be reassembled into two solid balls of the same size as the original. The ab-
stractness of the sets, correlated with the arbitrary nature of the mappings, makes
such paradoxes possible, but of course such paradoxes are not possible in the real
world where things have variation and cohesion and mappings are not arbitrary.
Nonetheless, since Cantor mathematicians have found the constant noncohesive
sets useful as an extreme case with which continuously variable sets can be con-
trasted.
Closely related to the notion of partition is the concept of equivalence relation.
Deﬁnition 4.21: A relation R from X to Y is a part R  ⟨p0,p1⟩ X × Y of the product
of X and Y. If X = Y, we speak of a relation on X. The opposite of a binary relation
R is the binary relation from Y to X with projections p1 and p0. It is denoted Rop.
Notice that there is an abuse of language in omitting the projections involved in
deﬁning the binary relation R – and as a mapping Rop has the same domain as R!
Exercise 4.22
Rop actually is a part of Y × X.
Hint: Use the “twist” map τX,Y
♦
Suppose that A
p   I is a partition, and let the following diagram be a pullback:
Exercise 4.23
The resulting arrow Rp
⟨p0,p1⟩ A × A is a monomorphism.
♦
Thus, Rp is a relation on A. It has some special properties we are about to explore,
but notice that the proof that ⟨p0, p1⟩is monic does not depend on the fact that p is
epi. We will need that only when we come to the proof of Proposition 4.32 below.
With A as test object and the identity mappings to the vertices of the pullback above
we obtain a mapping r : A
 Rp:

88
Colimits, Epimorphisms, and the Axiom of Choice
The mapping r satisﬁes p0r = 1A = p1r. In general,
Deﬁnition 4.24: A relation R  ⟨p0,p1⟩ X × X on X is called reﬂexive iff there is a
mapping r : X
 R such that p0r = 1X = p1r.
Exercise 4.25
Recall the diagonal map X
δX  X × X. A relation R is reﬂexive if and only if it
contains the diagonal part, or if and only if for any (generalized) element x of X
we have ⟨x, x⟩is a member of R.
♦
Combining the fact that ⟨p0, p1⟩is monic with uniqueness of mappings to prod-
ucts, we see that for a reﬂexive relation,r is unique. Thus, a relation either is or is not
reﬂexive. In Section 10.4 we will study reﬂexive graphs determined by two sets E
and V and three mappings: s, t : E
 V and r : V
 E such that sr = 1V = tr.
In that case r is part of the reﬂexive graph structure and need not be unique because
⟨s, t⟩need not be mono.
The relation Rp has two additional important properties we now deﬁne.
Deﬁnition 4.26: A relation R  ⟨p0,p1⟩ X × X on X is called symmetric iff
Rop ⊆X×X R.
Exercise 4.27
A relation R is symmetric if and only if for any (generalized) element ⟨x, y⟩of
X × X we have
⟨x, y⟩∈R =⇒⟨y, x⟩∈R
if and only if the restriction of the twist mapping τX,X to R is contained in R.
♦
Exercise 4.28
The relation Rp is symmetric.
♦

4.5 Split Images
89
A third important property of Rp is the following:
Deﬁnition 4.29: A relation R is called transitive if and only if for any (generalized)
elements ⟨x, y⟩and ⟨y, z⟩of X × X we have
⟨x, y⟩∈R & ⟨y, z⟩∈R =⇒⟨x, z⟩∈R
Exercise 4.30
The relation Rp associated to a map A
p  I is transitive.
♦
Combining these properties of Rp, we make the following deﬁnition:
Deﬁnition 4.31: A relation R on X is called an equivalence relation iff it is
reﬂexive, symmetric, and transitive.
Now if we start with an equivalence relation R on X, we may form the coequalizer
of R
p0

p1
 X, which we denote by X
pR  PR. This is a partition of X. (We obtain a
partition of X by forming the coequalizer of any two mappings with codomain
X – it is the special properties of equivalence relations that allow the next result.)
Taking the equivalence relation of a partition of X and taking the partition from an
equivalence relation on X are inverse processes:
Proposition 4.32: If p is a partition of X, then p = pRp. If R is an equivalence
relation on X then R = RpR.
Exercise 4.33
Prove Proposition 4.32.
♦
4.5 Split Images
There is a version of the choice axiom that does not assume the given map is
surjective and correspondingly produces another map that is in general somewhat
less than a section.
If X
f  Y is any mapping, provided X is nonempty, there
exists Y
g  X for which f g f = f .
Exercise 4.34
Show that the principle just enunciated is equivalent to the axiom of choice. (What
do you need to assume about the category to prove this equivalence?)
♦
Proposition 4.35: If f g f = f and f is epimorphic, then f g = 1Y (i.e., g is a section
for f ).

90
Colimits, Epimorphisms, and the Axiom of Choice
Proof: f g f = 1Y f and f is right-cancellable.
■
Proposition 4.36: If f g f = f and f is monomorphic, then g f = 1X (i.e., g is a
retraction for f ).
Proof: Exercise.
■
It will be recalled that we proved earlier that if X
f  Y is monic and X ̸= 0, then
f has a retraction using only the existence of complements for all parts and that
any nonempty set has an element; thus, this monic case of the f g f = f principle
does not involve “choice” functions. The f g f = f principle can be used to derive
the main properties of the image factorization of a mapping f (which we illustrate
with external and internal diagrams)
f = ip
i injective
p surjective
X
Y
I
f
p
i
for any f by strengthening it to a split image (meaning p has a splitting or section
s):
X
f
p
  
Y
f = ip
i injective
ps = 1I
I
 
i
s




Exercise 4.37
If the factorization f = ip is a split image for f , then i is the part of y whose
members are exactly all those elements of Y that are values of f ; i.e.,
∀T
y  Y[y ∈i ⇐⇒∃x[y = f x]]
♦
The section s in the split-image concept is not determined by f (even though the
imagefactorization f = ip isessentiallydetermined),butontheotherhanditmakes
some calculations somewhat easier. The next few exercises are concerned with

4.5 Split Images
91
showing how split images can be derived from the pseudosections g for arbitrary
nonempty X.
Exercise 4.38
If f g f = f , we can explicitly deﬁne (by composition) another “better” g for which
both
fgf = f
and
gfg = g
X
f
g
g
The improvement process goes no further: g = g; i.e. if g already satisﬁes both
equations, the process (−) will not change it.
♦
Exercise 4.39
If f = ip, where p has a section s and i has a retraction r, and if we deﬁne g def
= sr,
then the resulting g will already satisfy both f g f = f and g f g = g.
♦
Exercise 4.40
Suppose f g f = f and let i be an equalizer of f g with 1Y, where Y is the codomain
of f . Show, using the universal mapping property of equalizers, that a unique
map p exists for which f = ip. Show that pgi = 1E and hence that if we deﬁne
s def
= gi,r def
= pg we get that ps = 1I andri = 1E. Moreover ir = f g and sp = g f .
How must g be related to f in order to have further that g = sr?
♦
Although most categories do not have split images, often they do have image
factorization f = ip in the sense that i is the smallest part of the codomain through
which f factors and p is the proof that f belongs to i. (It then follows that p is an
epimap.)
With images available we can deﬁne a composition of relations and give another
characterization of transitive relations.
If R
⟨p0,p1⟩ X × Y is a relation from X to Y and S
⟨q0,q1⟩ Y × Z is a relation
from Y to Z, we denote by S ×Y R the pullback of p1 and q0; thus, we have
S ×Y R
p2
R
p0
p1



q
 
X
Y
Z
1

92
Colimits, Epimorphisms, and the Axiom of Choice
Deﬁnition 4.41: The relational composite of R and S is the image
S ◦R = I⟨p0 p2, q1q2⟩of the mapping ⟨p0 p2, q1q2⟩: S ×Y R
 X × Z.
Note that the graph γ f of a mapping X
f  Y is a relation from X to Y.
Exercise 4.42
If X
f  Y and Y
g  Z then γg f = γg ◦γ f .
♦
Exercise 4.43
A relation R


⟨p0,p1⟩ X × X on X is transitive iff R ◦R ⊆X×X R.
♦
4.6 The Axiom of Choice as the Distinguishing Property
of Constant/Random Sets
Much of mathematics revolves around determining whether speciﬁc maps f have
sections s or not. In a general way this is because the sets of mathematical interest
have some variation/cohesion within them and the maps (such as s) in the corre-
sponding categories are accordingly not “arbitrary”. However, for the category S
of constant sets and arbitrary maps, the axiom of choice is usually assumed to hold.
Thename“choice”comesfromthefollowingobservation:Amap X
f  Y canbe
viewed as a family of sets
X y = {x| f x = y}
parameterized by the elements y of Y. Then a section s for f is a single rule that
chooses one element from each set in the family:
f s = 1Y =⇒f (sy) = y =⇒s(y) ∈X y for each y
The notion of part (including membership in a part and part deﬁned by a condition)
as just used in the explanation of the word “choice,” can itself be entirely explained
in terms of composition of mappings (without assuming rigid membership chains
or imposing an a priori model for every part).
The axiom of choice implies two other properties (which will not both be true of
genuinely variable sets), both of which can be stated in terms of parts. The Boolean
property states that for any part i0 : A0  
 X of any set X there is another part
i1 : A1  
 X of X (the complement of A0) such that X is the coproduct of A0 and
A1; i.e. for all Y, for any pair of arrows f0 : A
 Y, f1 : A1
 Y with codomain
Y there exists a unique f : X
 Y, making the diagram below commutative:

4.6 The Axiom of Choice: Distinguishing Constant/Random Sets
93
A0
f0
i0
X
f
A1
f1
i1
It can be proved that the Boolean property follows from the axiom of choice.
Now we only point out the randomness implied by the Boolean property: The maps
f0, f1 can be speciﬁed independently (no compatibility required on any “boundary”
between A0, A1) and still be part of a single map (on the whole X) that the Boolean
category allows; moreover, the uniqueness of the extended map f shows that A0, A1
together exhaust X (for if there were any additional part, f could be varied on it
without disturbing the condition that f restricts to the given f0, f1).
There are many important categories of variable sets that satisfy the Boolean
property without satisfying the axiom of choice. The most important such examples
are determined by groups, and in Chapter 10 we will study enough group theory to
understand in a general way how these examples operate.
The other very restrictive consequence of the axiom of choice is sometimes
called the localic property or the property that “parts of 1 separate”. Recall from
Exercise 2.44 that in S/X the terminal object has many parts in general, and indeed
they separate maps in that category. In all of our categories there turn out to be
suitable objects B such that “parts of B separate,” meaning that there are enough
elements whose domains are (domains of) parts of B to distinguish maps between
any X, Y:
A category of sets is called localic if this holds for B = 1.
It can be shown that the localic property follows from the axiom of choice. Al-
though most of the examples of categories of variable sets are not localic, there are
a great many that are localic even without satisfying the axiom of choice. The most
important localic examples correspond to topological spaces. In Exercise 10.27 we
will learn enough about topological spaces to comprehend how sets varying over
a topological parameter space “restrict” from one open region to a smaller one.

94
Colimits, Epimorphisms, and the Axiom of Choice
There are a great many groups and a great many topological spaces, and each
one of each gives an example of a category of variable sets. But examples that are
both localic and Boolean and yet do not satisfy the axiom of choice are harder to
come by and indeed have only been known since Cohen’s 1963 discoveries. The
study of such “independence proofs” is a part of the multifaceted lore of variable
sets.
4.7 Additional Exercises
Exercise 4.44
Prove Proposition 4.20.
Exercise 4.45
(a) Show that the category of ﬁnite-dimensional vector spaces has ﬁnite colimits.
(b) Show that in the category of ﬁnite-dimensional vector spaces epimorphisms
are surjective linear transformations and, moreover, any epimorphism has a
section.
Exercise 4.46
(a) Show that in a slice category S/X a morphism h from f : A
 X to
g : B
 X is an epimorphism iff h is a surjective mapping in S.
(b) Show that the slice categories S/X have ﬁnite colimits.
Hint: They are computed using colimits in S.
Exercise 4.47
(a) Show that epimorphisms in the category of M-sets are equivariant mappings
that are surjective.
(b) Show that these categories have ﬁnite colimits.
Hint: They are computed using colimits in S.
Exercise 4.48
(a) Show that the category of partially ordered sets has ﬁnite colimits.
(b) Show that epimorphisms in the category of partially ordered sets are surjective
(order-preserving) mappings.

4.7 Additional Exercises
95
Exercise 4.49
Describe equivalence relations in the categories S/X.
Exercise 4.50
Describe equivalence relations in the categories of M-sets.
Exercise 4.51
(a) Describe equivalence relations in the category of groups. In the category of
groups equivalence relations are called congruences. The congruences on a
group correspond bijectively to the normal subgroups.
(b) Show that the analogue of Proposition 4.20 holds in the category of groups
(where it is usually called the First Isomorphism theorem.)
Exercise 4.52
Show that the axiom of choice holds in the categories S/X.
Exercise 4.53
Show that the axiom of choice does not hold in the category of groups.
Exercise 4.54
Show that the axiom of choice does not hold in general in the category of M-sets.
Hint: There is a very small counterexample using the action of a one-letter alphabet
on sets with at most two elements. In fact, it can be shown that the axiom of choice
fails in M-sets unless M is the monoid with only one element (in which case M-sets
are equivalent to S).
Exercise 4.55
On the other hand, if a monoid has an inverse for every element (i.e., is a group G),
then as mentioned in Section 4.6 the Boolean property holds for G-sets.
Hint: Consider the nature of monomorphisms in G-sets; they are rather special.

5
Mapping Sets and Exponentials
5.1 Natural Bijection and Functoriality
The essential properties of the product operation can be summed up by the ﬁgure
P
X
 Y0 × Y1
X
 Y0, X
 Y1
↓↑
where the horizontal bar will be interpreted in such contexts to mean there is a
natural process that, to every arrow of the type indicated above the bar, assigns one
of the type indicated below the bar, and there is also a natural process from below
to above, and these two natural processes are inverse to each other in the sense that
following one process by the other gives nothing new. Of course, in the example of
products the two processes in question are supposed to be
(1) taking the components of a map whose codomain is a product, and
(2) “pairing.”
Just from the idea that there should be such a couple of inverse processes, we can
(by a “bootstrap” procedure) discover more speciﬁcally how the processes must
work. Namely, from the presumption that P should function for all X, Y0, Y1, and
for all maps as indicated, we can deduce two special cases: Let Y0, Y1 be arbitrary
but suppose X = Y0 × Y1; then, we make the very special choice “above the bar” of
1Y0×Y1 which will correspond to something speciﬁc, namely, the projections below
the bar
Y0 × Y1
1  Y0 × Y1
Y0 × Y1
p0  Y0, Y0 × Y1
p1  Y1
Returning to the general X, the same projections are the means by which, through
96

5.1 Natural Bijection and Functoriality
97
composition, the general top-to-bottom process is effected as follows:
X
f  Y0 × Y1
X
p0 f  Y0, X
p1 f  Y1
↓
Of course the bottom-to-top process is usually just indicated by pairing (the result
of which is often denoted by brackets),
X
⟨f0, f1⟩ Y0 × Y1
X
f0  Y0, X
f1  Y1
↑
but this can also be analyzed further: First consider the special case in which X is
arbitrary but both Y0 = X and Y1 = X; then, we have the possibility of considering
the very special pair of maps below the bar, which by the pairing process will lead
to a speciﬁc map
X
δX  X × X
X
1X  X, X
1X  X
known as the diagonal δX = ⟨1X, 1X⟩. The diagonal helps via composition to effect
the general case of the pairing process provided one ﬁrst develops the “functoriality”
of product (which can also be regarded as deduced from the basic P ):
If X0
f0  Y0, X1
f1  Y1 are any two mappings, there is an induced map
X0 × X1
f0× f1 Y0 × Y1
called the (Cartesian) product of the two maps that is characterized by the equations
or, in terms of values, by
( f0 × f1)⟨x0, x1⟩= ⟨f0x0, f1x1⟩

98
Mapping Sets and Exponentials
Exercise 5.1
(“Functoriality of product”) If Y0
g0  Z0, Y1
g1  Z1 are further maps, then
(g0 × g1)( f0 × f1) = (g0 f0) × (g1 f1)
♦
Now the analysis of the pairing in terms of the product of maps and composition
with δX is just this:
If X0 = X, X1 = X and if X
f0  Y0, X
f1  Y1 then
⟨f0, f1⟩= ( f0 × f1)δX
as is easily checked by following both sides of the equation with the projections.
This two-level method, applied here to summarize the transformations possible
with the product construction, will be applied to many different constructions later,
so let us restate the levels: The crude idea that there should be a natural invertible
process ↓↑between maps of two kinds is reﬁned to a precise suggestion of how
the process can be carried out, namely, to apply a functorial construction and com-
pose with a speciﬁc map; a relationship between the two levels is essentially that
the crude idea of the invertible process, applied to a very special case and to the very
special identity map, yields that speciﬁc map, which can be used in composition to
help effect the process.
5.2 Exponentiation
We will now discuss another important construction, that of exponentiation or
mapping set, whose description involves a strictly analogous two-tier process for
objects X, Y and B:
X
 Y B
X × B
 Y ↓↑
Immediately we can derive from this crude idea what the elements of Y B must be
by considering the special case X = 1: The process
1
 Y B
B
 Y ↓
must be an invertible process (recall from Exercise 3.22 that 1 × B ∼= B), i.e. there
must be just as many elements of Y B as there are actual maps B
 Y.
Now if we are given any map
X × B
f  Y

5.2 Exponentiation
99
whose domain is equipped with a product structure (frequently one refers to such
f as a function of two variables), then for each element 1
x  X of X we can
consider (with x the constant composite: B
 1
x  X)
X
Y
× B
f
B
⟨x,1B ⟩
fx
In other words fx is the map B
 Y whose value at any element b is
fx(b) = f (x, b)
That is, such a single map f on a product X × B gives rise to a family, parameterized
by X, of maps B
 Y. Depending on the size of X and on the nature of f , one
may have (but usually will not have) the following two properties:
(1) Every map B
 Y occurs as fx for at least one 1
x  X (i.e., every B
 Y
has at least one “name” provided by the scheme X, f ).
(2) fx1 = fx2 only when x1 = x2, (i.e., “nameable” maps B
 Y have only one
“name”.)
In case both properties are true, one often writes Y B in place of X and calls the map
Y B × B
 Y evaluation (rather than calling it f ). For any B
f  Y let 1
⌜f ⌝ Y B
be the unique element of Y B guaranteed by the properties (1) and (2); then we have
for all f, b
Such a universal map-parameterizing scheme (one which does enjoy both properties
(1) and (2)) will have a unique relationship to any map-parameterizing scheme X, f
(in which X × B
f  Y and any 1
x  X names B
fx  X), as expressed by the
natural invertible process
X
⌜f ⌝ Y B
X × B
f  Y
↓↑
namely,
⌜f ⌝x = ⌜fx⌝
Thus, this extended naming process is related to the evaluation map by
eval(⌜f ⌝x, b) = f (x, b)

100
Mapping Sets and Exponentials
or
eval(⌜f ⌝× 1B) = f
For any f, ⌜f ⌝is the only map for which the latter equation is true, and thus we
can say brieﬂy that any f is uniquely derivable from the evaluation map.
As an example imagine that the elements of B represent particles of a continuous
body of matter (such as a cloud); also imagine that a set E represents the points of
ordinary space and a set T represents the instants of time within a certain interval.
Then,
E B = placements of B
is a set, each element of which determines an entire map B
 E telling where in
E each particle of B is (i.e., a placement of B in E). Thus, a motion of B during
the time interval T could be considered as a mapping
T ⌜m⌝ E B
whose value at any instant is a placement.
By the fundamental transformation law for mapping sets, ⌜m⌝corresponds to a
unique
T × B
m  E
which represents the same motion in a different mathematical aspect: for each
instant t and particle b, the value m(t, b) is the point in space at which the particle
b ﬁnds itself at instant t during the motion. But there is still a third way to describe
the same motion. Because of the natural twist map B × T
τ  T × B, we have
B × T
mτ  E, and hence by a different instance of the fundamental transformation
we ﬁnd
B ⌜mτ⌝ E T
which seems to describe the motion equally well. Here
E T = paths in E
is a set, each element of which determines a whole map T
 E from instants
of time to points of space (i.e., a “path”). The given motion determines, for each
particle b, the whole path that b follows during T . The expressions
B
 E T
B × T
 E
T
 E B

5.2 Exponentiation
101
are thus the three descriptions of the same motion of the cloud. The ﬁrst and last
involve the inﬁnite-dimensional function spaces E T and E B, whereas the middle
one involves only the ﬁnite dimensional B × T
∼ T × B.
Although maps whose codomain is a function space (= mapping set or expo-
nential) can always be “transformed down” in the indicated manner, nothing of the
sort is true in general for mappings whose domain is a function space. Mappings
whose domain is a function space are often called
Operators or Functionals
and include such things as differentiation and integration. An example of an inte-
gration functional arises when we consider the mass distribution on the body B and
the resulting map
E B
 E
whose value at any placement is the center of mass (which is a point of E) of that
placement. Thus, the description of a motion by means of
T
 E B
is necessary if we want to compute by composition
EB
T
E
the map whose typical value is the instantaneous position of the center of mass. On
the other hand, a typical differentiation operator is the “velocity”
E T
 V T
whose value at any path of points is the corresponding path of velocity vectors. If
we are to calculate the velocity ﬁeld resulting from a particular motion m of an
extended body B, the appropriate description of the motion will be
B
 E T
for then we can just calculate by composition
ET
diﬀerentiate
B
motion
v
V T

102
Mapping Sets and Exponentials
and then apply once again the fundamental transformation to get ⌜vτ⌝
T
 V B
whose value at any instant is the velocity ﬁeld over the body.
5.3 Functoriality of Function Spaces
We will take as an axiom the following:
AXIOM: EXPONENTIATION AXIOM
For any two sets B, Y there exists a set Y B and an evaluation Y B × B
eval  Y having
the universal property that for each X and for each X × B
f  Y there is a unique
X
⌜f ⌝ Y B for which eval (⌜f ⌝× 1B) = f . Brieﬂy,
X
⌜f ⌝ Y B
X × B
f  Y
with the evaluation map arising as the unique f for which ⌜f ⌝= 1Y B.
Proposition 5.2: If Y1
ϕ  Y2 then there is a unique Y B
1
ϕB  Y B
2 for which
ϕB⌜g⌝= ⌜ϕg⌝
B
g  Y1
ϕ  Y2
for all g.
Proof: The axiom says that to construct a map whose codomain is a function space
Y B
2 it sufﬁces to construct the corresponding map whose domain is a product, in
our case Y B
1 × B. But this is easily done as the following composition:
Y B
1 × B
eval1  Y1
ϕ  Y2
Y B
1
ϕB  Y B
2
Notice that this means that ϕB = ⌜ϕ eval1⌝by the axiom, and thus
eval2(ϕB × 1B) = ϕ eval1
Furthermore (ϕB × 1B)(⌜g⌝× 1B) = ϕB⌜g⌝× 1B. Thus,
eval2(ϕB⌜g⌝× 1B) = eval2(ϕB × 1B)(⌜g⌝× 1B)
= ϕ eval1(⌜g⌝× 1B) = ϕg
= eval2(⌜ϕg⌝× 1B)
That is, both ϕB⌜g⌝and ⌜ϕg⌝give the same result when crossed with 1B and then
composed with eval2. Since the axiom states the uniqueness of maps yielding a

5.3 Functoriality of Function Spaces
103
given result under this two-step transformation, we conclude that they are equal, as
Proposition 5.2 called for.
■
Remark: Note that the argument works just as well if ⌜g⌝is a generalized element
of Y B
1 , that is, for X × B
g  Y1.
Exercise 5.3
If Y1
ϕ  Y2
ψ  Y3, then
(ψϕ)B = ψ BϕB
♦
The preceding exercise establishes the “covariant functoriality of induced maps
on function spaces” with given domain B. But if we ﬁx the codomain space Y and
instead let the domain space B vary along maps, we ﬁnd that there are again induced
maps on the function spaces, but of a contravariant nature, in the following sense:
Proposition 5.4: If B2
β  B1 then there is a unique
Y B1
Y β  Y B2
for which
Y β⌜g⌝= ⌜gβ⌝
for all g.
Proof: Again we construct by composition the map Y B1 × B2
 Y that uniquely
corresponds by the fundamental transformation of the axiom to the Y β desired:
Y B1 × B2
1×β  Y B1 ×B1 eval1 Y
This can be done along the lines of the proof of Proposition 5.2.
■
Proposition 5.5: If B3
α  B2
β  B1, then
Y βα = Y αY β
Proof: The proof of the proposition is simply a “higher” expression of the associa-
tivity of composition in
g

104
Mapping Sets and Exponentials
One way Y β⌜g⌝= ⌜gβ⌝; hence,
Y αY β⌜g⌝= Y α⌜gβ⌝= ⌜(gβ)α⌝
but the other way
Y βα⌜g⌝= ⌜g(βα)⌝
hence the two are equal for each g, which accounts for the conclusion.
■
In case B2
β  B1 is injective, then Y B1
Y β  Y B2 is often called the operator of
restriction (of maps, restriction to the smaller domain along the part of their origi-
nal domain).
The next proposition shows that the operation on mappings that we take as most
fundamental, namely composition, can itself be expressed via an actual mapping –
at least when the three sets involved are ﬁxed.
Proposition 5.6: There is a map Y Y1
2 × Y B
1
⌜c⌝ Y B
2 such that
⌜c⌝(⌜ϕ⌝, ⌜g⌝) = ⌜ϕg⌝
for all
B
g  Y1
ϕ  Y2
Proof: Deﬁne c by:
Y Y1
2
× Y B
1 × B
c

1×eval
Y2
Y Y1
2
× Y1
eval










■
Note that ⌜c⌝can be further transposed by another instance of the axiom to give
Y Y1
2
 (Y B
2 )(Y B
1 )
whose value at any ⌜ϕ⌝is the name ⌜ϕB⌝of the (covariantly) induced map on the
function spaces with domain (= exponent) B. That is, the inducing operation is
itself represented by a mapping. In a similar fashion (taking a differently labeled
instance of c) the third way (as in our example of motion) yields
B B2
1
 (Y B2)(Y B1)
representing the contravariant-inducing process by an actual map.

5.3 Functoriality of Function Spaces
105
Recalling that the set 2 represents, via the notion of characteristic function, the
arbitrary parts of an arbitrary set B,
B
 2
?  
 B
we can combine this bijection with the function-space axiom to get
1
 2B
?  
 B
so that the elements of the set 2B serve as effective names for the arbitrary parts
of B and, in particular, the “number” of parts can be deﬁned to be the number of
elements of 2B. Moreover, the meaning of the evaluation map in this case is just
“membership”:
eval(⌜ϕ⌝, b) = ϕb
thus, if ϕ is the characteristic function of a part i, we could deﬁne
[b ∈i] = eval(⌜ϕ⌝, b)
as the truth value of the statement that b is a member of i.
Exercise 5.7
If B2
β  B1, then
2B1
2β  2B2
represents by a map the operation of taking the inverse image along β of arbitrary
parts of B1.
♦
To justify the use of the exponential notation for function spaces, we will show
that for ﬁnite sets the number of maps from B to Y is the numerical exponential –
number of elements of Y to the power number of elements of B.
Proposition 5.8:
Y 0
∼ 1
Y A+B
∼ Y A × Y B
Proof: To construct 1
 Y 0 is equivalent to constructing 1 × 0
 Y, but since
0 × 1
∼ 1 × 0, that is equivalent to constructing 0
 Y 1, which is unique;

106
Mapping Sets and Exponentials
the composite 1
 Y 0
 1 is the identity because maps to 1 are unique, and
the composite Y 0
 1
 Y 0 must be the identity since it corresponds to a map
0
 (Y)(Y 0) of which there is only one. For the second statement from the propo-
sition consider the injections i A, iB into the sum A + B; by the functoriality of Y ( )
these induce “restriction” maps Y A+B
 Y A, Y A+B
 Y B, which can be paired
to yield
Y A+B
⟨Yi A ,YiB ⟩
 Y A × Y B
the map mentioned in the statement, which we want to show is invertible. To
construct an inverse we must construct ﬁrst a candidate
Y A × Y B
 Y A+B
which is equivalent to constructing
A + B
 Y (Y A×Y B)
which must necessarily be the “copair” of two maps
A
 Y (Y A×Y B)
B
 Y (Y A×Y B)
But such a couple of maps is equivalent to
Y A × Y B
 Y A
Y A × Y B
 Y B
for which the obvious choices are the projections; tracing back through the equiv-
alences, we then have our map
Y A × Y B
 Y A+B
whichwe mustshowis theinverse.Themapistheonewhosevalueatapairofnames
is the name of the copair,
⟨⌜f A⌝, ⌜fB⌝⟩
goes to
⌜ f A
fB
⌝
which is indeed clearly inverse to the previous one whose value at ⌜f ⌝is
⟨⌜f i A⌝, ⌜f iB⌝⟩.
■
Notice that the effect of Proposition 5.8 is to represent the invertible process
characteristic of sum
A + B
 Y
A
 Y, B
 Y ↓↑

5.3 Functoriality of Function Spaces
107
as an actual invertible map. In a similar way the processes characteristic of product,
and even the processes characteristic of exponentiation itself (!), can be represented
by actual invertible maps by allowing the exponential sets to intervene, as will be
shown in the following two propositions.
Proposition 5.9:
1B
∼ 1
(Y0 × Y1)B
∼ Y B
0 × Y B
1
Proof: Since the assertions of the proposition are that certain speciﬁc maps are
invertible, we must ﬁnd these inverses. The inverse of the unique 1B
 1 is the
“name” 1
 1B of the unique B
 1. The map ⟨π B
0 , π B
1 ⟩has an inverse,
Y B
0 × Y B
1
 (Y0 × Y1)B
which is constructed as the map corresponding to
Y B
0 × Y B
1 × B
ϵ  Y0 × Y1
where
ϵ⟨⌜g0⌝, ⌜g1⌝, b⟩= ⟨g0b, g1b⟩
■
Thus Proposition 5.9 internalizes or objectiﬁes the deﬁning property of the ter-
minal object and the deﬁning process of the product concept.
Proposition 5.10:
Y
∼ Y 1
Y X×B
∼ (Y B)X
Proof: The diagrams:
Y
Y 1
Y × 1
pr
Y
Y 1
⟨1Y1,Y  ⟩
Y 1 × 1
eval
1

108
Mapping Sets and Exponentials
deﬁne the two maps inverse to each other for the ﬁrst “equation”. For the second,
we have
Schematically, the ﬁrst map is ⌜f ⌝→⌜x →f (x, −)⌝, and its inverse is ⌜ϕ⌝→
⌜⟨x, b⟩→(ϕx)(b)⌝. (Do Exercise 5.16.) Thus, the invertible map of the proposition
internalizes the process
X × B
 Y
X
 Y B
which is the deﬁning property of exponentiation itself.
■
More surprising is that the existence of exponentiation implies a fundamental
“equation” that does not mention exponentiation but is only concerned with the
lower-order operations of sum and product. We refer to the distributive law, which
is discussed in Section 7.2.
5.4 Additional Exercises
Exercise 5.11
In Exercise 3.46 we saw that the linear transformations between ﬁnite-dimensional
vector spaces V and V ′ have a natural commutative group operation. In fact they
even form a vector space, often denoted L(V, V ′). This is easily seen by remem-
bering that the linear transformations may be represented by matrices (though this
representation depends on choosing bases for V and V ′).
Show, however, that L(V, V ′) does not satisfy the exponential axiom.
Hint: There is a simple dimension argument to show this.
Exercise 5.12
The categories S/X have mapping sets. To see how these are constructed, let
A
α  X and B
β  X be objects. We can write these as families of ﬁbers: ⟨Ax⟩x∈X
and ⟨Bx⟩x∈X. The mapping set αβ has, as ﬁber over the element x, the mapping set
in S denoted ABx
x .
Show that αβ has the correct universal property.

5.4 Additional Exercises
109
Exercise 5.13
For any monoid M the category of M-sets (see Exercise 3.51) has mapping sets.
Construct these from the equivariant mappings and show that the universal property
holds.
Hint: The construction is a little more subtle than might be supposed. However, if
M happens to be a group, your general description of the M-set Y X for M-sets X
and Y can be shown to be equivalent to the following simpler description: Consider
the set of all arbitrary mappings from the underlying set of X to the underlying set
of Y and deﬁne on it an appropriate action of M.
(Caution: If your deﬁnition of this appropriate action does not explicitly involve
the inverse operation of the group, you will not be able to prove the universal
property.)
Exercise 5.14
The category of partially ordered sets has exponentials. If X and Y are partially
ordered sets, the mappings from X to Y, which are order-preserving, have a natural
order inherited from the order on Y.
Show that this ordered set has the universal property of the exponential.
Exercise 5.15
Complete the proof of Proposition 5.9 by showing that the maps deﬁned are inverse
to each other as claimed.
Exercise 5.16
Complete the proof of Proposition 5.10 by showing that the maps deﬁned are inverse
to each other as claimed.
Exercise 5.17
Let A and B be categories. The concept of functor F from A to B is deﬁned in
Appendix C.1, as well as in 10.18.
(a) Show that the assignments (X) = (X, X) for any set X and ( f ) = ( f, f )
for any mapping f deﬁne a functor  : S
 S × S;  is called the diagonal
functor.
(b) Show that the assignments (−× B)(X) = X × B for any set X
and
(−× B)( f ) = f × 1B for any mapping f deﬁne a functor (−× B) : S
 S.
(c) Show that the assignments (−)B(X) = X B for any set X and (−)B( f ) = f B
for any mapping f deﬁne a functor (−)B : S
 S.

110
Mapping Sets and Exponentials
(d) Show that the assignments −× −(X, Y) = X × Y for any pair of sets (X, Y)
and −× −( f, g) = f × g for any pair of mappings ( f, g) deﬁne a functor
−× −: S × S
 S.
(e) If V and W are vector spaces considered as categories (Exercise 1.31) show
that any linear transformation between them is a functor.
(f) If X and Y are partially ordered sets considered as categories (Exercise 1.31),
show that a functor between them is the same thing as a monotone mapping.

6
Summary of the Axioms and an Example
of Variable Sets
6.1 Axioms for Abstract Sets and Mappings
We have now seen most of the axioms we will require of the category S of abstract
sets and mappings. As we progressed, some of the earlier axioms were included
in later axioms. For example, the existence of the one-element set is part of the
axiom that S has ﬁnite limits. Although we did not insist on it earlier, it is also the
case that some of the axioms are more special than others. By this we mean that
even though they hold in S they will not generally hold in categories of variable
or cohesive sets. Thus, we are going to review the axioms here so that they can be
considered all at once and grouped according to their generality.
The very ﬁrst axiom, of course, is
AXIOM: S IS A CATEGORY
We have been emphasizing all along that the fundamental operation in a category,
composition, is the basic tool for both describing and understanding all of the other
properties of S.
The next group of three axioms is satisﬁed by any category of sets, variable or
constant. In fact a category satisfying them is called a topos (in the elementary
sense), and these categories have been studied intensively since 1969.
AXIOM: FINITE LIMITS AND COLIMITS
S has all ﬁnite limits and colimits.
AXIOM: EXPONENTIATION
There is a mapping set Y X for any objects X and Y in S.
AXIOM: REPRESENTATION OF TRUTH VALUES
There is a truth value object 1
t
 , i.e. there is a one–one correspondence be-
tween parts (up to equivalence) of an object X and arrows X
  mediated by
pullback along t.
111

112
Summary of the Axioms and an Example of Variable Sets
Some of the consequences of these axioms have been studied already. Note that
the truth value object  is not required to be 1 + 1. Indeed, in the next section we
will see a ﬁrst example of variable sets, and it will be immediately obvious when we
compute the truth value object there that it is not 1 + 1. Thus, we now need to sepa-
rate two properties that were merged in stating the truth-values axiom in Section 2.4.
Since  is a truth value object, the monomapping 0  
  has a character-
istic mapping called ¬ : 
 . Precomposing with 1
t
  deﬁnes another
element of  called f for false.
AXIOM: S IS BOOLEAN
 is the following sum:

t
f : 1 + 1
∼  where the injections are t and f .
The special toposes which (like S) satisfy this last axiom are called Boolean
toposes; they allow the use of classical logic (see Appendix A).
The next axiom has not been explicitly stated until now. We explain why below,
but it should be pointed out that there are Boolean toposes that do not satisfy it. For
example, the category S/X is always a Boolean topos, but if X has more than one
element, then the category does not satisfy this axiom.
AXIOM: S IS TWO-VALUED
 has exactly two elements.
The two elements of  must then be t and f . The axiom is equivalent to the re-
quirement that 1 has exactly two parts.
Exercise 6.1
Prove that S/2 is not two-valued.
♦
AXIOM: THE AXIOM OF CHOICE
Any epimorphism has a section.
Thus, as we have already pointed out, there is a representation of the cells of a
partition by a choice of elements of the domain of the partition. This axiom has
a very different character from the others. For one thing it can be shown that it
implies the Boolean axiom (see McLarty [M92], Theorem 17.9).
The axiom of choice also implies, as a special case, that for any set X the
epimorphic part of the unique mapping X
 1 is a split epimorphism. Since this
image is called the support of X, this special property is sometimes referred to by
saying that supports split.

6.1 Axioms for Abstract Sets and Mappings
113
Theprinciplethatnonemptysetshaveelementsisfalseinmosttoposesofvariable
or cohesive sets; moreover, there are several different precise meanings to the term
“nonempty” relative to which the principle may be true in various special cases.
Rather than just X not equal to 0, the requirement that the terminal map X
 1
be an epimorphism is sometimes a more reasonable expression of the idea that X
is not empty.
Recall that we assumed in Chapter 1 that S satisﬁes two other important pro-
perties:
(i) 1 is a separator, and
(ii) in S we have 0 ̸= 1.
A topos that satisﬁes (i) and (ii) is called a well-pointed topos. It is a theorem
[MM92] that a topos is well-pointed if and only if it is Boolean, two-valued, and
supports split. As a result, the two properties we required for S in Chapter 1, namely
(i) and (ii), that is that S is well-pointed, are actually consequences of the axioms we
have already stated. Conversely, our assumption in Chapter 1 that S is well-pointed
implies that S is Boolean and two-valued. It also implies the special case of the
axiom of choice called “supports split”.
There is one more axiom we will require of S. The axioms so far say nothing
about the possibility of mathematical induction. When a starting element of a set
and a process for forming new elements of the set (an endo-mapping) are given, a
unique sequence determined by the starting element and the process should result.
Mathematical practice usually makes the idealization that all such sequences are
parameterizations by a single object N; such an N must be “inﬁnite”. However, the
axioms we have so far do not guarantee the existence of such an object; we will
consider it in Section 9.1. In fact, within any category of sets that has an inﬁnite
object it is possible to ﬁnd a Boolean topos that does not have such an object.
In summary then, we can say precisely what we mean by a category of abstract
sets and arbitrary mappings. It is a topos that is two-valued with an inﬁnite
object and the axiom of choice (and hence is also Boolean). Experience shows that
mathematical structures of all kinds can be modeled as diagrams in such a topos.
We conclude this section by fulﬁlling the promises made within Claim 3.4. The
ﬁrst of these is the following:
if X ̸= 0, then X has an element 1
 X.
We will show that X ̸= 0 ⇒X
  1, and then the axiom of choice provides the
elementweneed.Nowthe(split)imagefactorizationof X
 1as X
  I  
 1
determines a subobject of 1. Since S is two-valued and Boolean, there are only two
mappings 1
 1 + 1 ∼= . These classify the only two subobjects of 1, which thus
must be 1 and 0. Hence, I is either 1 or 0. So we will have completed the proof if
we know that X
 0 implies X ∼= 0.

114
Summary of the Axioms and an Example of Variable Sets
Exercise 6.2
Show that X × 0
p1  0 is an isomorphism.
Hint: Recall that Y 0 ∼= 1. Use this to show that any arrow X
 0 has an inverse.
♦
The second promise was that every part X  
i
 Y has a complement
X′  
i′
 Y. One way to see this follows from the next exercise:
Exercise 6.3
Let A0
i0  A0 + A1
i1

A1 be a sum and B
g  A0 + A1. In the diagram follow-
ing with both squares deﬁned to be pullbacks we have that the top row is a sum.
♦
Now, to fulﬁll the second promise, we may take the sum diagram for  (since S
is Boolean!) as the bottom row and use the characteristic map Y
ϕ   for X as g.
We conclude that Y is the sum of X and X′ since X′ is by deﬁnition the pullback
of ϕ along the false map f .
6.2 Truth Values for Two-Stage Variable Sets
Perhaps the simplest kind of variable set (beyond the constant kind whose category
S has been studied up to now) is the category S2op of two-stage sets with only
one connection between the stages. Here we will use the symbols 2 = U
 1
to suggest a (previous) stage U, which, together with a present stage constitutes a
total movement 1. A set X in the category S2op of all sets undergoing this movement
will be analyzed in terms of constant sets in S as
Here X1 in S is the set of elements of X that persist throughout both stages, XU in
S is the set of elements of X that persisted through the previous stage, and ξX is
the map describing the internal structure of X by specifying for each element x of
X1 the element (of XU) that x “was” during the previous stage U; the result of this

6.2 Truth Values for Two-Stage Variable Sets
115
speciﬁcation is denoted by ξX(x). A map X
f  Y in S2op is analyzed as a pair f1,
fU of maps in S for which ξY f1 = fUξX, that is the square below commutes:
Exercise 6.4
If ξY f1 = fUξX and ξZg1 = gUξY, then
ξZ(g1 f1) = (gU fU)ξX
♦
By the exercise, we get a well-deﬁned operation of composition of maps in S2op:
(g f )1 = g1 f1
(g f )U = gU fU
The terminal set 1 of S2op is (in its S-analysis)
since, for any X, there is a unique commutative square
in S. To what extent do the maps
1
x  X
in S2op represent the elements of X? The equation required of any map in this
category reduces to

116
Summary of the Axioms and an Example of Variable Sets
in this case; thus, x is entirely determined by x1, and conversely any element x1
of X1 in S (no condition) determines, using ξX, a unique xU making the square
commutative, i.e. determines a unique 1
x  X in S2op. Thus, we may brieﬂy say
that the maps 1
x  X “are” the elements of X that live through both stages.
How can we represent the elements of X in their aspect of existence only through
the previous stage U? To that end consider the variable set
U =
0

1
which has no elements that persist through both the present and previous stages but
has one element throughout the previous stage. This U then is a nonzero variable
set with no element in the narrow sense. The property that nonzero abstract sets do
have elements, as discussed in the previous section, is seen to be already violated
with this simple variation. Now for any X, the maps U
x  X in S2op may be
analyzed in S as
but x1 is unique, and the square commutes no matter what element xU of XU is
chosen. Thus, we may say the maps U
x  X “are” the elements of X that existed at
the previous stage.
Exercise 6.5
There is exactly one map U
ξ  1 in S2op. Moreover, given any 1
x  X, the com-
position U
ξ  1
x  X in S2op represents the xU that the ξX speciﬁes as the element
that x “was” throughout U.
(Draw the appropriate diagram to verify the statement.)
♦
Exercise 6.6
A map A
i
 X in S2op is a part of X if and only if the following three conditions
are all satisﬁed.
A1 is a part of X1 in S
AU is a part of XU in S
ξXi1 = iUξA
♦

6.3 Additional Exercises
117
Moreover, ξA is uniquely determined (if it exists) by X, i1, iU; the condition that
ξA exists is
∀x ∈X1[x ∈A1 =⇒ξXx ∈AU]
Now we will calculate the truth-value variable set P(1) = P2(1) in S2op that
precisely represents all parts in that category through characteristic functions
X
 P(1)
?  
 X ↓↑
An arbitrary part A
i A  X may involve elements of X that are not now in A but
were previously in A. Yet the characteristic function ϕ of A must be deﬁned for all
elements of X, and of course ϕ must be a map in S2op. By taking X = 1 and X = U
above, this forces
P(1) =
0 U 1
0
1
to have three truth values globally, but only two truth values in the previous stage.
For any A  
 X, one can deﬁne ϕ at the “present” stage by
ϕ1x =





0 if x ̸∈A, ξX(x) ̸∈A
U if x ̸∈A, ξX(x) ∈A
1 if x ∈A
Exercise 6.7
Deﬁne also ϕU and show that ϕUξX = ξP(1)ϕ1. For each of the two types of elements
of X,
x ∈A ⇐⇒ϕx = 1
♦
6.3 Additional Exercises
Exercise 6.8
The categories S/X satisfy most of the axioms in Section 6.1, as we have seen in
Exercises 3.48, 4.46, 4.52, 5.12. Show that S/X has a truth-value object, namely,

118
Summary of the Axioms and an Example of Variable Sets
the projection 2 × X
 X. Thus, S/X fails to be a category of abstract sets and
mappings only in that it is not two-valued.
Exercise 6.9
(a) Show that there is a (diagonal) functor (see Appendix C.1) denoted X from S
to S/X whose value at a set A is the object of S/X given by the projection map-
ping A × X
 X.(SodeﬁneX alsoonmappingsandshowthatitsatisﬁesthe
equations.)
(b) Show that there is a functor 	X (for sum, why?) from S/X to S that sends an
object Y
 X of S/X to the set Y.
These two functors have the following important relationship:
(c) Show that for any set A in S and object Y
ϕ  X in S/X there is a one–one
correspondence between mappings in S from 	X(ϕ) to A and mappings in
S/X from ϕ to X(A). (	X is left adjoint – see Appendix C.1 – to X.)
Exercise 6.10
Show that S2op has all ﬁnite limits and colimits.
Hint: They are computed “pointwise”.
Exercise 6.11
The previous exercise and the description in Section 6.2 of P(1) show that S2op is
not Boolean. Show that it is not two-valued either.
Exercise 6.12
(a) Show that epimorphisms in S2op are pointwise. By “pointwise” here we mean
a property holding at both 1 and U. Thus, epimorphisms are pointwise means
that X
f  Y is epi in S2op iff f1 and fU are epi in S.
(b) Show that supports split in S2op, but
(c) Show that the axiom of choice fails in S2op.
Hint: There is a nonsplit epimorphism between objects with no more than two
elements at each vertex.
Exercise 6.13
Show how to construct mapping sets in S2op.
Hint: (Y X)U = Y XU
U
and (Y X)1 is a certain set of pairs of mappings.

6.3 Additional Exercises
119
Exercise 6.14
(a) Show that there is a (diagonal) functor (see Appendix C.1) denoted  from S
to S2op whose value at a set A is the object of S2op given by the identity mapping
A
 A. (So deﬁne  also on mappings and show it satisﬁes the equations.)
(b) Show that there is a functor dom from S2op to S that sends an object X =
X1
ξX  XU of S2op to the set X1.
(c) Show that there is a functor cod from S2op to S that sends an object X =
X1
ξX  XU of S2op to the set XU.
These three functors have the following important relationships. Show that
for any set A in S and object X = X1
ξX  XU of S2op there are one–one
correspondences
(i) between mappings in S from cod(X) to A and mappings in S2op from X to
(A) (cod is left adjoint – see Appendix C.1 – to ) and
(ii) between mappings in S2op from (A) to X and mappings in S from A to
dom(X) (dom is right adjoint to ).
Exercise 6.15
If M is a monoid, the category of M-sets has ﬁnite limits and colimits as well as
mapping sets (Exercises 3.51, 4.47, 5.13), but does not satisfy the axiom of choice
(4.54). It does have a truth-value object. First, note that a subobject of an M-set X
is simply a part A  
 X of X that is closed under the right action of M. For its
characteristic function ϕA we send x ∈X to the set I of i ∈M such that xi ∈A.
This I is a part of M closed under right multiplication by all of M (called a “right
ideal”). The set of right ideals of M, denoted M, has a right action by M given by
Im = { j ∈M | mj ∈I}, and so it is an M-set. It is the object we seek; M itself is
an element of M that plays the role of “true”.
Show that, with the characteristic mappings just outlined M is indeed the truth-
value object.
Thus, the category of M-sets is a topos.

7
Consequences and Uses of Exponentials
7.1 Concrete Duality: The Behavior of Monics and Epics under
the Contravariant Functoriality of Exponentiation
Any conceivable cancellation law states in effect that some algebraic process or
other is injective. This is most evident in the deﬁnition of the concept of monomor-
phism, whereby the “injectivity” of the algebraic process of composing with f on
the left turns out to be equivalent to injectivity of f itself as a map. In terms of
function spaces we can express the equivalence
f injective ⇐⇒f monomorphic
simply by
X
f

injective Y ⇐⇒∀T

X T
f T

injective Y T 
since we see that to say that f T is injective in its action on elements 1
 X T
deﬁned on 1 is equivalent to saying that for all x1, x2
T
x1 
x2
X
f  Y,
f x1 = f x2 =⇒x1 = x2
if we only recall that the action of f T is
f T ⌜x⌝= ⌜f x⌝for all T
x  X
But what if f is epimorphic? Since the statement
ϕ1 f = ϕ2 f =⇒ϕ1 = ϕ2
is also a cancellation property, it also expresses that some process is injective, and
if we look a little more closely, we see that the process in question is the one
120

7.1 Concrete Duality
121
represented by the contravariant functoriality of mapping sets. For later use it is
preferable to state this fact as property relative to a given object V .
Proposition 7.1: For a given X
f  Y and a given V ,
V Y
V f  V X
is injective (on elements) exactly when
ϕ1 f = ϕ2 f =⇒ϕ1 = ϕ2
holds for any Y
ϕ1

ϕ2
 V .
Proof:
V f ⌜ϕ⌝= ⌜ϕf ⌝
■
Corollary 7.2: X
f  Y is epimorphic if and only if
V Y
V f  V X
is injective for all V .
It will be recalled that the deﬁnition of (for example) “epimorphism” is the formal
dual of the deﬁnition of “monomorphism” in the sense that one simply reverses all
arrows in the relevant diagrams; of course if the original diagrams had been given
speciﬁc interpretation in terms of speciﬁc sets and mappings, such interpretation
is lost when we pass to this formal dual in that the formal dualization process
in itself does not determine speciﬁc sets and speciﬁc mappings that interpret the
dualized statement. On the other hand, for any given V , we do have the process of
contravariant functoriality that for any speciﬁc diagram, say
X
Y
produces a speciﬁc diagram (with “bigger” sets!) in which all arrows have been
reversed
V X
V Y
and that satisﬁes (at least) all the commutativities (= statements about equality of
compositions) satisﬁed by the original diagram except, of course, that the order of

122
Consequences and Uses of Exponentials
the composition has been reversed. This is often referred to as “concrete duality
with respect to V ” or “dualizing into V ”. Not every statement will be taken into its
formal dual by the process of dualizing with respect to V , and indeed a large part
of the study of mathematics
s p a c e
vs.
q u a n t i t y
and of logic
t h e o r y
vs.
e x a m p l e
may be considered as the detailed study of the extent to which formal duality and
concrete duality into a favorite V correspond or fail to correspond.
In the context of constant sets, the choice V = 2 is the starting point of many
such duality theories.
Theorem 7.3: X
f  Y is epimorphic if and only if 2Y 2 f  2X is monomorphic.
Proof: The “only if” direction is a special case of (the internalization of) the deﬁ-
nition of “epic”.
Conversely, if 2Y 2 f  2X is monomorphic, then f satisﬁes the (restricted to 2)
right-cancellation property
X
f  Y
ϕ1

ϕ2
 2,
ϕ1 f = ϕ2 f =⇒ϕ1 = ϕ2
But we can take
ϕ1 = characteristic function of the image of f
ϕ2 = identically true,
which will surely satisfy ϕ1 f = ϕ2 f ; if we apply the assumed cancellation property,
we see that f is epimorphic (hence intuitively that the image of f ﬁlls up the whole
of Y).
■
Because the dualization functor is not reversible without modiﬁcation, the fol-
lowing further duality property does not follow from the previous theorems.
Theorem 7.4: X
f  Y is a monomorphism if and only if 2Y 2 f  2X is
epimorphic.

7.1 Concrete Duality
123
Proof: If T
x1 
x2
X
f  Y have equal composites, then by functoriality so do
2Y
 2X
 2T
and thus if 2 f is epimorphic, then 2x1 = 2x2, from which we will conclude shortly
that x1 = x2, so that f is monomorphic.
Conversely, if f is assumed monomorphic, we need to conclude that
2Y 2 f  2X
is epimorphic, for which it sufﬁces to show that 2 f is surjective. So assume ⌜ϕ⌝
is any element of 2X; we must show that there is at least one ⌜ψ⌝for which
2 f ⌜ψ⌝= ⌜ϕ⌝, i.e. for which

But ϕ is the characteristic function of a part i of X, and by assumption f is a part of
Y; thus, the composite f i is a part of Y; we naturally guess that taking ψ to be the
characteristic function of this composite part will satisfy our requirement, which
we can prove as follows:
ϕx = true ⇐⇒x ∈i
ψy = true ⇐⇒y ∈f i
Calculate, for any x
(ψ f )x = true
⇕
ψ( f x) = true
⇕
f x ∈f i
⇕
x ∈i
⇕
ϕx = true
Hence, ψ f = ϕ as required.

124
Consequences and Uses of Exponentials
We return to showing that
2x1 = 2x2 ⇒x1 = x2
A useful tool is the singleton map { } deﬁned as the exponential transpose of the
characteristic function of the diagonal
X  
δX
 X × X
X × X
 2
X
{ }  2X
In other words if {x} = ⌜ϕ⌝and i is the part of X with characteristic function ϕ,
then for any x′
x′ ∈i ⇐⇒x′ = x
Now if we assume that T
x1 
x2
X are such that in 2X
 2T we have
2x1 = 2x2, then composing with X
{ }  2X we get equal maps X
 2T and hence
equal maps T × X
 2 and therefore equal parts of T × X. But it is easily seen
that the parts of T × X arising in this way are actually the graphs of the corres-
ponding maps T
 X; if the graphs are equal, then the corresponding maps
are equal, as was to be shown.
■
Theorem 7.4 about 2 in the category of constant sets becomes a deﬁnition of a
special kind of object V in more general categories.
Deﬁnition 7.5: An object V is an injective object if for every monomorphism
X  
f
 Y and every X
ϕ  V there exists Y
ϕ  V such that
ϕf = ϕ
X


f

ϕ
Y
ϕ
V
In case the category has exponentiation, V is injective if and only if for every
monomorphism X
f  Y, V Y
V f  V X is surjective (on elements 1
 V X). It is
not surprising that most of the concrete dualities in mathematics and logic that work
well involve dualizing into an injective object V .

7.1 Concrete Duality
125
Another twist on the same underlying problem is the following: Let V be any
given object and deﬁne X
f  Y to be co-surjective relative to V to mean
∀ϕ ∃ϕ[ϕf = ϕ]
X
f

∀ϕ
Y
ϕ
V
By abstract duality plus justiﬁable prejudice we might expect co-surjectivity to be
similar to injectivity for a map. To make this precise, consider one more deﬁnition:
For T
x1 
x2
X, say that x1 ≡V x2 if and only if
∀X
ϕ  V [ϕx1 = ϕx2]
This ≡V may be read as “congruent modulo V ” or more simply as “equal insofar
as V -valued properties can distinguish”.
Proposition 7.6: If f is co-surjective relative to V , then f is “monic modulo V ,”
i.e.,
f x1 ≡V f x2 =⇒x1 ≡V x2
Proof: The hypothesis of the implication refers of course to testing relative to all
Y
 V . We must show ϕx1 = ϕx2 for any given X
ϕ  V . But by co-surjectivity
ϕ can be extended to a ϕ
T
x1
x0
X
f
ϕ
Y
ϕ
V
ϕx1 = (ϕ f )x1
= ϕ( f x1)
= ϕ( f x2) by the hypothesis f x1 ≡V f x2
= (ϕ f )x2
= ϕx2
■
Without yet going into detail concerning the modiﬁcations necessary to reverse
the concrete duality, we note that double dualization V (V X) depends only on the

126
Consequences and Uses of Exponentials
dual V X and is a covariant functor in that X
f  Y induces
V V X
 V V Y
in the same direction. Moreover, there is for each X a map
X
ˆ( )  V V X
deﬁned by
x −→⌜ϕ −→ϕx⌝
and often written (ignoring the distinction between a map and the corresponding
element of a mapping set) as ˆx(ϕ) = ϕ(x). The map ˆ( ), sometimes called the
Fourier transform or the Dirac delta, is natural in the sense that for any map
X
f  Y the diagram
is commutative. In case V is a coseparator, the map ˆ( ) is monic and thus X is
(the domain of) a part of the double dual of X. The fact that this double dual
is much larger than X can often be overcome, and X can actually be recovered
from the knowledge of its dual A = V X by noting that the “variable quantities”
A and the “constant quantities” V have some algebraic structure in common and
consideringonlythepart A∗= Hom (A, V )  
 V A whosememberscorrespond
to those maps A
 V that preserve this algebraic structure; the thus-tempered
X
ˆ( )  (V X)
∗has a better chance of being invertible, as we shall see in Section 8.4.
7.2 The Distributive Law
The distributive law states that a natural map
A × X1 + A × X2
 A × (X1 + X2)
is actually invertible. Here the × and + denote product and coproduct (= sum
in the case of sets), and the natural map exists whenever product and coproduct
exist. In fact the natural map in question comes from a special case of the fol-
lowing observation: to deﬁne a map ?
 A × S whose codomain is a product is
equivalent to deﬁning maps from ? to each of the factors, whereas to deﬁne a map
P1 + P2
 ?? whose domain is a coproduct is equivalent to deﬁning maps from
each of the summands to ??; hence, in case we have both that the codomain is known

7.2 The Distributive Law
127
to be a product and that the domain is known to be a coproduct, then deﬁning a map
is equivalent to deﬁning a “matrix” of (smaller) maps specifying each component
of the value of the big map for each kind (summand) of input. For example, any map
P1 + P2
 A × S
(between the indicated combinations of any four given sets) is speciﬁed by a
2 × 2 matrix whose entries would be the four possible threefold composites with
projections and injections.
In the case at hand, where S = X1 + X2, Pk = A × Xk, we have enough structure
to actually specify such a matrix, where
P1
 A is A × X1
proj  A
P2
 A is A × X2
proj  A
P1
 S is A × X1
proj  X1
inj  X1 + X2
P2
 S is A × X2
proj  X2
inj  X1 + X2
Of course, the natural map just described in detail is the one corresponding to
the intuitive picture of a product as a rectangular arrangement and of a coproduct
of sets as a disjoint union:
A × X1
A × X2
X1
X2
X1 + X2
A
A
However, although the “rectangular arrangement” picture of the elements of a
product is justiﬁed by the deﬁning property of products, the “disjoint sum” picture
of the elements of a coproduct is NOT justiﬁed by the deﬁning property in itself
of coproducts. This is because the deﬁning property of a coproduct X1 + X2 = S
refers to co-elements of S,
S
 V

128
Consequences and Uses of Exponentials
and says nothing in itself about how to determine the elements
T
 S
that S might have. Indeed, in other important categories the coproduct may be quite
unlike a disjoint sum; for example, in the basic category of linear algebra namely,
the category of vector spaces and linear transformations (also called linear spaces
and linear maps) the coproduct is the same space as the product (see Exercise 3.46),
and hence neither the distributive law nor “disjointness” could hold. Thus, the in-
vertibility of the natural map A × X1 + A × X2
 A × (X1 + X2) in the context
of nonlinear spaces and nonlinear maps (in particular for abstract sets and arbitrary
maps) must be due (like the disjointness of +) to some further feature of these
categories beyond the mere existence of product and coproduct in themselves. The
existence of exponentiation turns out to supply this feature. For to show that the
natural map has an inverse we must construct a candidate
A × (X1 + X2)
 A × X1 + A × X2
and then verify that the candidate really is inverse; the construction is the step that
requires some additional ingredient. But note that the required candidate should
be a map whose domain is a product and that since the crucial feature of the
exponentiation axiom is an invertible process, we could just as well view that
axiom as a prescription for constructing lower-order maps A × S
 Y by instead
constructing higher-order maps S
 Y A. This apparently perverse interpretation
of the exponentiation axiom turns out to be exactly what is needed in this case (and
in many other cases) since it enables us to gain access to certain special structures
that S has. That is, the proof of the distributive law can be achieved by constructing
an inverse map
A × (X1 + X2)
?  A × X1 + A × X2
as we have seen. But by the exponentiation axiom, we can equivalently construct
X1 + X2
?  (A × X1 + A × X2)A
which (by the special coproduct structure of S = X1 + X2) is equivalent to the
problem of constructing two maps (for k = 1, 2)
Xk
?  (A × X1 + A × X2)A
By applying exponentiation again, but in the opposite direction, this is equivalent
to constructing two maps
A × Xk
 A × X1 + A × X2

7.3 Cantor’s Diagonal Argument
129
Butsuchmaps arestaringusin theface–thetwoinjections!Hence,wecanconstruct
the required candidate map
A × (X1 + X2)
 A × X1 + A × X2
which can be shown to behave as expected,
⟨a, ikx⟩→ik⟨a, x⟩
on elements (when 1
x  Xk).
Exercise 7.7
Verify that the candidate map just constructed really is the two-sided inverse of the
natural map
A × X1 + A × X2
 A × (X1 + X2)
♦
Exercise 7.8
Prove (using exponentiation) that
0
∼ A × 0
♦
Exercise 7.9
Prove (using exponentiation) that if X
f  Y is an epimorphic map, then
A × X
1A× f A × Y
is also epimorphic.
♦
7.3 Cantor’s Diagonal Argument
Over a century ago Georg Cantor proved an important theorem that includes the
result
X < 2X
for all sets X (see Def. 7.15 below). This result, well-known for ﬁnite sets X, was
quite new for inﬁnite sets since it showed that some inﬁnities are deﬁnitely bigger
than others (even though many constructions on inﬁnite sets X tend to give sets of
the same cardinality, that is,
2 × X ∼= X,
X2 ∼= X

130
Consequences and Uses of Exponentials
hold for inﬁnite abstract sets). Indeed, this speciﬁc and fundamental construction
leads to a potentially inﬁnite sequence of larger and larger inﬁnities
X < 2X < 22X
< 222X
< . . .
An even more fundamental consequence of Cantor’s theorem is the obvious con-
clusion that there cannot exist a “universal set” V for which every set X appears
as the domain of a part of V
X  
 V
because if there were such a V , we could take X = 2V to reach a contradiction since
(see Theorem 7.4) the restriction map
2V
  2X
is surjective, but Cantor showed that no map X
 2X is surjective.
Cantor’s method for proving this theorem is often called the “diagonal argument”
even though the diagonal map δX is only one of two equally necessary pillars on
which the argument stands, the second being a ﬁxed-point-free self-map τ (such as
logical negation in the case of the set 2). This diagonal argument has been traced (by
philosophers) back to ancient philosophers who used something like it to mystify
people with the Liar’s paradox. Cantor, however, used his method to prove positive
results, namely inequalities between cardinalities. The philosopher Bertrand
Russell, who was familiar with Cantor’s theorem, applied it to demonstrate the
inconsistency of a system of logic proposed by the philosopher Frege; since then
philosophers have referred to Cantor’s theorem as Russell’s paradox and have even
used their relapse into the ancient paradox habit as a reason for their otherwise
unfounded rumor that Cantor’s set theory might be inconsistent. (Combatting this
rumor became one of the main preoccupations of the developers of the axiomatized
set theories of Zermelo, Fraenkel, von Neumann, and Bernays [Sup72]. This pre-
occupation assumed such an importance that the use of such axiom systems for
clarifying the role of abstract sets as a guide to mathematical subjects such as
geometry, analysis, combinatorial topology, etc., fell into neglect for many years.)
Around 1930 both G¨odel and Tarski again used exactly the same diagonal argu-
ment of Cantor, except in categories of a more linguistic nature than the category
of sets, to obtain their famous results to the effect that (G¨odel) for any proposed
axiom system for number theory there will always be further truths about the num-
ber system that do not follow as theorems in that axiom system, and (Tarski) even
though it is easy to construe mathematical statements ϕ as mathematical entities
⌜ϕ⌝, there can be no deﬁnition of a single “truth predicate” T such that, for any

7.3 Cantor’s Diagonal Argument
131
statement ϕ and every speciﬁc mathematical entity x,
⌜ϕ⌝T x ⇐⇒ϕ(x)
is a mathematical theorem.
We will ﬁrst prove the theorem in a still more positive form as a ﬁxed point
theorem, of which Cantor’s theorem will be the contrapositive. Cantor himself
proved cardinality inequalities not only for the set 2X of subsets but also for the
set RX of real-valued functions, and correspondingly our ﬁxed-point theorem will
deal with objects Y more general than Y = 2.
Deﬁnition 7.10: A self-map Y
τ  Y of an object Y is said to have 1
y  Y as a
ﬁxed point if and only if τy = y. Thus, τ is said to be ﬁxed-point-free if and only if
∀1
y  Y[τy ̸= y]. At the other extreme, an object Y is said to have the ﬁxed-point
property if and only if every self-map τ has at least one ﬁxed-point y.
Remark 7.11: Although the ﬁxed-point-property is so rare as to be uninteresting
forthecategoryofabstractconstantsetsandarbitrarymaps,itismuchmorefrequent
and useful in the category of continuous spaces and maps, where Brouwer proved
that the n-dimensional ball has the ﬁxed point property; for n = 1, this fact implies
existential statements such as Rolle’s theorem, which involves continuous maps of
the interval [−1, 1] into itself.
Theorem 7.12: Suppose there is an X and a map ϕ
X × X
ϕ  Y
such that for every X
f  Y there is at least one 1
a  X such that
f = ϕ(a, −)
Then Y has the ﬁxed-point property.
Proof: Consider any Y
τ  Y. We must show that τ has a ﬁxed point. Deﬁne an f
by the triple composite
In other words, for all x
f x = τϕ(x, x)

132
Consequences and Uses of Exponentials
Now by the assumed property of ϕ, this f must be “ϕ-represented” by some a:
f x = ϕ(a, x)
for all x. Hence,
τϕ(x, x) = ϕ(a, x)
for all x. In particular, if we take x = a,
τϕ(a, a) = ϕ(a, a)
which means that if we deﬁne y in terms of a by commutativity of
then y is a ﬁxed point of τ
τy = y
■
Corollary 7.13: (Cantor) If Y has at least one self-map τ with no ﬁxed points, then
for every X and for every
X
	  Y X
	 is not surjective.
Proof: Surjectivity of 	 expressed by the diagram
is exactly the property assumed in the theorem for the corresponding ϕ for which
	 = ⌜ϕ⌝. The corollary is the contrapositive of the theorem, and any statement
implies its contrapositive.
■
Corollary 7.14: There is no surjective map
X
 2X

7.3 Cantor’s Diagonal Argument
133
nor is there any surjective map
X
 RX
where R is the set of real numbers.
Proof: Logical negation 2
τ  2 is ﬁxed-point-free. Indeed, τ(false) ̸= false, and
τ(true) ̸= (true). For the second statement, all we need to know about R is that it
has a self-map τ such as
τ(x) = x + 1
for which τ(x) ̸= x for all 1
x  R.
■
Deﬁnition 7.15: For sets X and Y we write X ≤Y when there exists at least one
monomapping from X to Y. We write X < Y to mean X ≤Y and that moreover no
surjective maps X
 Y exist.
Corollary 7.16:
X < 2X for all X
Indeed
X < Y X for any Y with 2 ≤Y
■
Another frequently cited application of Cantor’s argument shows that there are
strictly more real numbers than rational numbers. This can be established in three
steps as follows:
Q ∼= N < {0, 1, 2, 3, 4, 5, 6, 7, 8}N  
 R
That is, we separately establish (by a snakelike counting of fractions) that the set of
rational numbers is isomorphic as an abstract set with the set of natural numbers,
and we note that among the reals there are those (nonnegative ones) whose decimal
expansion involves no 9’s. The latter set is equivalent to the function space Y X
indicated with a sequence N
a  {0, 1, . . . , 8} mapping to the real with decimal

134
Consequences and Uses of Exponentials
expansion
a0 · a1a2a3 . . . =
∞

n=0
an10−n
Thus, we can apply our argument above with X = N, Y = {0, . . . , 8}, noting that
the ﬁnite set Y does indeed have endomaps that move every element.
7.4 Additional Exercises
Exercise 7.17
Show that the truth-value object 
 is an injective object in any topos. More generally
show that the mapping set 
X is an injective object for any object X.
Exercise 7.18
Find all of the injective objects in the categories S/X.
Hint: Start with the case X = 1 (i.e., the category of abstracts sets and mappings).
Exercise 7.19
Find all of the injective objects in the category S2op.
Exercise 7.20
The distributive law holds in any topos. Verify this explicitly for S2op.
Exercise 7.21
Categories with ﬁnite sums and products (including 0 and 1!) in which the dis-
tributive law holds are extremely important in theoretical computer science. For
example (see Walters [Wal91]), let f, g : A
 B and suppose ϕ : A
 2 is a
“test function”. Show that the triple composite
A
⟨1,ϕ⟩ A × 2
∼
 A + A

f
g
 B
can be interpreted as “if ϕ then f else g”. Indeed, if we call the composite
h : A
 B, then
h(a) =
 f (a)
if ϕ(a) = true
g(a)
otherwise

7.4 Additional Exercises
135
Exercise 7.22
The concept of natural transformation τ from a functor F to a functor G is deﬁned
in Appendix C.1.
(a) Show that there is a natural transformation α from the functor dom : S2op
 S
to the functor cod : S2op
 S (see Exercise 6.14) whose component for an
object X of S2op is the mapping X1
ξX  XU.
(b) Show that for any set B there is a natural transformation β from the functor
−× B : S
 S (see Exercise 5.17) to the identity functor 1S : S
 S.
Hint: The components are projections.
(c) Functors can be composed. For example, the composite of the functors
 : S
 S × S and −× −: S × S
 S (see Exercise 5.17) is the functor
(−× −) : S
 S whose value at a set X is X × X. Show that the product
projections provide the components of two natural transformations from the
functor (−× −) to the identity functor 1S : S
 S.

8
More on Power Sets
8.1 Images
We have been introduced to the contravariant functoriality of 2X, which should be
understood both as
(1) a special case of the composition-induced contravariant functoriality (X
 Y
induces V Y
 V X) of V -valued function spaces (5.5), and
(2) the operation of inverse image on parts
internalized using the special property that V = 2 has of encoding parts via char-
acteristic functions (2.30, 2.34).
The covariant functor 22X (obtained by composing the contravariant 2( ) with
itself) can be interpreted to consist of all “classes” of parts of X, since a map
2X
α  2 is the characteristic function of a deﬁnite part (or class) of the set 2X of
parts of X.
But we now want to consider an important way of making the smaller 2X a
covariant functor of X.
First let us agree to use a somewhat more convenient notation for parts. A part
of X consists of two components:
(1) the underlying set |A| of the part, which is the domain of the other component,
and
(2) i A, which is the monomorphic given inclusion of A into X.
136

8.1 Images
137
To say that A and B are equivalent parts of X means that there is
with h invertible and with the equation
iBh = i A
satisﬁed (which is denoted A ≡X B, see Deﬁnition 2.24). By contrast |A| ∼= |B|
means merely that |A|, |B| have the same number of elements but not necessarily
in a way that respects the inclusions. We commonly say that “A is a three-element
part of X” to mean that A is a part of X such that |A| has three elements; two
given three-element parts of X could have no elements in common, could overlap
nontrivially, or even could have the same elements of X as members, but only in
the last case would they be isomorphic as parts of X. Once this much is clearly
understood, one then usually follows the “abuse of notation,” which drops the | |
sign and just uses the same symbol A to stand both for the part (which involves a
given i A as understood) or for the domain of the part; one then sees from the context
whether morphisms of parts (i.e., inclusion relation) or maps of the underlying sets
are being discussed. Recall that our notion of membership is
For any X
f  Y we will construct an induced map
This operation arises so frequently that it has at least four other notations
P f = f! = f [ ] = ∃f = im f
where the f [ ] suggests that it is a generalization to parts of the evaluation of f at
elements, the ∃f suggests its intimate connection with the “there exists” operation
of logic, and the last im f indicates that it is the internalization of the “geometric”
operation of taking the direct image of a part of X. The latter operation, for given

138
More on Power Sets
X
f  Y, is as follows: Given any part A of X, factorize the composite f i A into
surjective and injective; the resulting part of Y is called f [A]. (See the picture
following Exercise 8.3.)
The following exercise implies in particular that any two such factorizations will
give equivalent parts of Y.
Exercise 8.1
(“diagonal ﬁll-in”)
If j2 is injective, p1 surjective, and j2 p2 = j1 p1, then there exists an h (necessarily
unique) for which both
p2 = hp1
j1 = j2h
♦
Sinceequivalentpartscorrespondtoequalcharacteristicfunctions,wehaveamap
2X
im f
 2Y
at least if we rely on the principle that any well-deﬁned process determines a map.
Such reliance can be avoided by a method (similar to that used before) to deduce
the existence of im f as a map from a few previously assumed speciﬁc axioms, as
follows:
Exercise 8.2
Let EX denote the part of X × 2X whose characteristic function is the evaluation
map X × 2X
∈X  2. Show that the image I f of EX along the map f × 12X

8.1 Images
139
is a part of Y × 2X, whose characteristic function Y × 2X
 2 has the desired
2X
im f  2Y
as its exponential transpose; i.e.
im f ⌜A⌝= ⌜f [A]⌝
where the further “abuse” of notation
⌜A⌝= ⌜characteristic function of A⌝
has been used.
♦
The connection of direct image with existential quantiﬁcation is laid bare by the
following exercise:
Exercise 8.3
If in
p is surjective; A, B are parts of X, Y, respectively; and f i A = iB p, then for
any y
X
Y
A
fA
•
•
•
•
•
•
•
•
f
y
y
♦
What is called in deductive logic the “rule of inference for existential quantiﬁer
introductionandelimination”correspondspreciselytoageometricpropertyrelating

140
More on Power Sets
inverse image and direct image. You can prove this rule in Exercise 8.5 below, but
ﬁrst note that
2 f ⌜B⌝= ⌜f −1B⌝= B f
(The notation B f is especially apt if one thinks of B here as the characteristic
function manifestation of the part.) If A is any part of X and B is any part of Y,
there may or may not exist a map h for which
(it would be unique since iB is monic); if such a map does exist, we might write as
a further deﬁnition
A ⊆f B
Exercise 8.4
A ⊆f B ⇐⇒∀x[x ∈A =⇒f x ∈B].
♦
Exercise 8.5
Show that
f [A] ⊆Y B
⇕
A ⊆X B f
by demonstrating that both are equivalent to A ⊆f B, that is,
if for any x, A(x) implies B( f x)
then for any y, ∃x[ f x = y and A(x)] implies B(y)
and conversely. (Here A(x) means x ∈A; i.e., we are using the same symbol A to
denote both a part and its characteristic function, which is an abuse of notation that
should cause no confusion since we now understand the difference.)
♦
Exercise 8.6
Interpret the foregoing exercise in the case X = Y × T , f = projection to Y.
♦

8.2 The Covariant Power Set Functor
141
8.2 The Covariant Power Set Functor
The covariant power set functor P is by deﬁnition
P X = 2X
P f = im f
The functoriality as usual refers to an equation:
Exercise 8.7
For X
f  Y
g  Z one has
P(g f ) = (Pg)(P f )
as maps P X = 2X
 2Z = P Z. In other words
(g f )[A] = g[ f [A]]
for any part A of X.
Hint: Usethediagonalﬁll-inexercise(andthefactthatthecompositesofsurjectives
are surjective) to conclude that the composite on top in the following picture is the
other half of the image factorization of (g f )i A:
Alternatively, (introducing properties, elements, and existential quantiﬁers) show
that for any z and for any property . . . ,
∃x[(g f )x = z and . . .] ⇐⇒∃y[gy = z and ∃x[ f x = y and . . .]]
♦
The claim that P f ,
A −→f [A]
is one generalization of the basic evaluation
x −→f (x)
on elements becomes more clear if we ﬁrst internalize the idea that parts are gen-
eralized elements in a deﬁnite manner
X
{ }  P X

142
More on Power Sets
known as the singleton map, which assigns to every element x the name of the
characteristic function of x considered as a part of X. This map can be constructed
in basic steps as follows: The diagonal map
X
δX  X × X
is a part of X × X (since it is split by the projections) and hence has a characteristic
map
X × X
⃝
=X  2
where (writing aϕb for the typical value ϕ⟨a, b⟩of a map A × B
ϕ  C)
x1⃝
=Xx2 = true ⇐⇒x1 = x2
But like any map whose domain is a product, ⃝
=X has an exponential transpose
X
 2X
Exercise 8.8
If A × B
f  C has the two exponential transposes A
f1  C B and B
f2  C A, and
if A = B, then
f1 = f2 ⇐⇒f (a, b) = f (b, a) for all ⟨a, b⟩∈A × A
♦
The latter condition is satisﬁed for ⃝
=X. Hence, the diagonal map gives rise by
the procedure above to (not two, but) one map
X
{ }  2X = P X
such that
x′ ∈{x} ⇐⇒x′ = x
Now the statement that P f generalizes evaluation at elements becomes the fol-
lowing naturality (see “natural transformation” in Appendix C.1):
Exercise 8.9
For any X
f  Y, the square below commutes
♦

8.2 The Covariant Power Set Functor
143
In case f is itself a monomorphism (hence makes X the underlying set of part
of Y), P f can be calculated without any real use of existential quantiﬁcation since
f i A is already injective (hence does not need to be further factored):
Proposition 8.10: If f is a monomorphism, then 2 f is a split epimorphism; in fact
P f is a section for 2 f .
Proof: For any f one has
f [A] ⊆B if and only if A ⊆B f = 2 f (B)
so in particular
f [A] ⊆f [A] if and only if A ⊆2 f ( f [A]) = (2 f ◦P f )(A)
i.e.,
A ⊆(2 f P f )(A)
for all parts A of X. But if f is monic, then i(P f )A = f i A, whose inverse image
2 f (
) is reduced to A. In other words, the square
is almost trivially seen itself to satisfy the universal mapping property of an inverse
image square, that is,
A = 2 f ((P f )(A)) for all A in P X = 2X
We conclude that 2Y
2 f  2X is surjective, split by P f .
■
Thecontravariantpowersetfunctor2( ) andthecovariantpowersetfunctorP both
come up in geometry and analysis in many ways, for example in connection with
the condition that a map be continuous or that it be locally bounded. A continuous
space (topological space) X is often considered to consist of an underlying abstract
set |X| of points, together with a set F X of “closed parts” and a structural map

144
More on Power Sets
|X| × F X
∈X  2 indicating when any given point is a member of any given closed
part. The transpose of ∈X, F X
 2|X| = P|X| interprets each closed part of X
as a part of the set |X|. Usually, special conditions are assumed on F X, ∈X, but
we will not need these here (however see Exercise 8.11 for a class of examples.)
On the other hand, a local boundedness space (= bornological set) X involves an
underlying set |X| of points, a set BX of “bounded parts,” and a membership map
|X| × BX
∈X  2; this is apparently exactly the same sort of thing BX
 2X as a
continuous space, except for the different words. The special axiomatic conditions
usually imposed on a system of bounded parts are, of course, quite different from
those usually imposed on a system of closed parts (for example, an arbitrary subpart
of a bounded part should again be bounded, whereas no such thing is true for closed
sets; the whole part 1X is always considered closed, but 1X is bounded only for trivial
boundedness systems). However, the striking contrast between closed and bounded
is seen in the concepts of continuous versus bornological mapping. Namely, if
X and Y are continuous spaces, a continuous map X
f  Y is a map |X|
| f |  |Y|
of points together with a proof that the inverse image of closed parts is closed:
By contrast, if X and Y are local boundedness spaces, a bornological map X
f  Y
is a map|X|
| f |  |Y|of pointstogether withaproofthatthedirectimagesofbounded
parts are bounded:
Exercise 8.11
A metric space X involves a set |X| of points and a distance function
|X| × |X|
dX  R∞
≥0
where R∞
≥0 = {r|0 ≤r ≤∞} is the set of (nonnegative, extended) real numbers
and dX is required to satisfy
dX(x, x) = 0
dX(x, y) + dX(y, z) ≥dX(x, z)

8.3 The Natural Map P X
 22
X
145
for any ⟨x, y, z⟩∈|X|3. This inequality can be pictured as
x
y
z
✟✟✟✟✟
A map X
f  Y of metric spaces is (often required to be) distance-decreasing in
the weak sense that
dY( f x1, f x2) ≤dX(x1, x2)
for any ⟨x1, x2⟩∈|X|2. Each metric space has a natural notion of bounded part:
A part B of |X| is bounded if and only if it is contained in some ball with some
center and some ﬁnite radius, i.e.,
B ∈BX
def
⇐⇒∃x0∃r[r < ∞and ∀x[x ∈B ⇒dX(x, x0) ≤r]]
But each metric space also has a natural notion of closed part, namely, any part
containing each point that can be approximated by points known to be in the part:
A ∈F X
def
⇐⇒∀x[∀r[r > 0 ⇒∃a[a ∈A and dX(x, a) ≤r]] ⇒x ∈A]
Show that any map f of metric spaces (which is distance-decreasing in the weak
sense) is both continuous (in the sense that 2 f carries the natural closed parts of
the codomain back to natural closed parts of the domain) as well as bornological
(in the sense that P f carries the natural bounded parts of the domain to the natural
bounded parts of the codomain).
♦
8.3 The Natural Map P X
 22
X
Both the functor P and the (larger) twice-contravariant 22( ) are covariant; we will
describe a direct natural comparison
P X

X  22X
between them (which will turn out to be injective). Given any part A of X,

X( )A
will be a map
2X
 2

146
More on Power Sets
namely, the one whose value at any X
ϕ  2 is the truth value (in 2 = {0, 1})

x∈X ϕ(x)A(dx)
calculated as follows: if there is any x in A at which ϕ takes the value 1, then the
answer is 1, whereas if ϕ restricted to A is constantly 0 (ϕ might take value 1 outside
of A; that does not matter), then the answer is 0. Of course, the ϕ’s are “really”
(characteristic functions of) parts also, so the description of

X could equally well
be stated: for any given part A in P X, consider any part ϕ in 2X and ask if ϕ
intersects A. If so the answer is 1, otherwise 0. For example,
Thus,
2X

X( )A  2
determines an element of 22X , but this can be done for any part A in P X, and hence
there should be a map P X
 22X . The reason the domain is not being called 2X
will be seen in Exercise 8.13 below.
Exercise 8.12
The existence of the map

X can be deduced from previous concrete constructions
and its nature clariﬁed for later use. Note that 2 = P1 and that there is a canonical
“union” map
that acts as follows:
For each of the four parts of 2,
µ1({0, 1}) = µ1({1}) = 1
µ1({0}) = µ10 = 0

8.3 The Natural Map P X
 22
X
147
Moreover, the covariant functoriality of P (discussed in the previous sections) may
be considered (further internalized) as a canonical map
Y X × P X
 PY
f, A −→f [A]
Hence, in particular, taking Y = 2 = P1, we have
2X × PX
PP1
P1 = 2
and therefore by taking the exponential transpose of the composite we have
P X
 22X
which is the same as our

X.
♦
Exercise 8.13
For any X
f  Y, the square
2
2
2
is commutative.
♦
Exercise 8.14
Let X
δ  22X be the evaluation map δ(x)(ϕ) = ϕ(x). Then the triangle
X
{ }

δ








PX

X
 22X
is commutative.
♦
Now only some of the elements of 22X come from elements of P X by our

X
process:
Exercise 8.15
If 2X
α  2 is such that there is an A for which
α(ϕ) =

x∈X ϕ(x)A(dx)

148
More on Power Sets
for all X
ϕ  2, then α has the following properties:
α(0X) = 0
where 0X : X
 1
0  2 is the constantly-0 function, and
α(ϕ1 ∪ϕ2) = αϕ1 ∨αϕ2
for any X
ϕ1

ϕ2
 2, where
(ϕ1 ∪ϕ2)(x)
def= ϕ1(x) ∨ϕ2(x)
for all x, where ∨is deﬁned by v1 ∨v2 = 1 if and only if v1 = 1 or v2 = 1 for v1, v2
in 2. Give examples of maps 2X
α  2 that do not have the two linearity properties
here shown to hold for

X( )A.
♦
Comment: Such linear α’s are sometimes called “grills”; they may be considered
as generalized parts in that every part A determines a grill, and the union of two
grills can be deﬁned in a way extending the union operation on parts. But there are
many grills that are not parts. For example, in the plane X, we can deﬁne an α by
α(ϕ) = 1 if and only if ϕ is a part of the plane with positive area.
Remark: All the general constructions in Sections 8.1–8.3 (such as singleton,
the map from the covariant power set to the doubly contravariant one, etc.) are
applicable in any topos with 2 replaced by .
8.4 Measuring, Averaging, and Winning with V-Valued Quantities
Several natural restrictions can be placed on elements of V V X to yield a covariant
subfunctor
Hom ?(V X, V )  
 V V X
of mathematical interest. When V is equipped with some structure, as for example
with V = 2 above, conditions similar to linearity may be imposed. But let us brieﬂy
consider two conditions that might reasonably be deﬁned using only the knowledge
that V is a given set. We want that at least the evaluation functionals V X
ˆx  V
(given by ˆx(ϕ) = ϕ(x) for all ϕ (i.e., ˆx = δ(x)) be included, and this will be true of
both our conditions.
Suppose that every month the same set X of people are to be asked which of a
set V of three brands of a product they prefer, giving a result X
ϕ  V each month.
We want to devise a single procedure α that will give α(ϕ) an element of V so that
we can reasonably say that the people prefer v = α(ϕ) this month. One obvious
condition that α will need to satisfy is that it should be an averaging functional to

8.4 Measuring, Averaging, and Winning with V -Valued Quantities
149
the extent that if it should happen that all people choose at ϕ the same brand v, that
same v should surely be the result α(ϕ).
Deﬁnition 8.16: V X
α  V is weakly averaging if for each v, if ϕv(x)
def= v for all
x, then
α(ϕv) = v
Thisisobviouslyanextremelyweakconditionandmaybesatisﬁedbyfunctionals
that nobody would want to consider as averaging. (When V has additional structure,
it makes sense to require that α also be linear, in which case there are often theo-
rems saying that a linear averaging procedure is an expectation with respect to a
probability distribution on X.)
Proposition 8.17: For any x in X, V X
ˆx  V is weakly averaging. That is, if HomV
denotes the constant-preserving functionals, one has
Proof: Obvious.
■
Thus, a trivial way of deﬁning a weakly averaging V X
 V is to choose some
single individual x in X and then evaluate every survey ϕ by merely noting how x
answered and presenting his or her answer as the “digested result of the survey”.
This offends our sense of fairness to the extent that we are led to formulate a
different sort of condition (which we will not study here) that could be imposed on
an averaging functional:
Deﬁnition 8.18: The arrow V X
α  V is said to be symmetric if for every invert-
ible self-map (also called automorphism or permutation) of X, X
∼
σ
X
α(ϕσ) = α(ϕ)
for all X
ϕ  V .
We will emphasize instead a certain kind of highly skewed weakly averaging
functionals. The idea is that one might hope to recover X from  = V X by putting
strong enough conditions on maps 
 V to characterize the values ˆx of δ in
case  = V X. Such considerations are basic to almost all situations in algebraic
geometry, particle physics, functional analysis, and so on, wherein one wants to

150
More on Power Sets
locate or recapture points of space or states of motion X by comparing (in quantita-
tive ways) observable variable quantities in V X with (relatively) constant quantities
in V .
Deﬁnition 8.19: A V -generalized point of X is a functional V X
α  V such that
for each V
λ  V,
α(λϕ) = λ(α(ϕ))
for all X
ϕ  V , where λϕ denotes the composition and λ(v) denotes usual evalu-
ation. That is
should commute.
This condition is quite strong. For example, if V denotes the real numbers and
α is an expectation, and if we consider as an example of λ the operation of multi-
plying by a constant (e.g., doubling), then
α(λϕ) = λ(α(ϕ))
follows from linearity. But instead take λ to be squaring: just the case
α(ϕ2) = α(ϕ)2
of our condition forces (the distribution underlying) α to be so concentrated that
the standard deviation (relative to α) of all random variables ϕ is zero!
Proposition 8.20: Each point is a generalized point.
Proof: If α = ˆx, then for any X
ϕ  V
λ  V
α(λϕ) = (λϕ)x = λ(ϕx) = λ(α(ϕ))
■
Exercise 8.21
Any generalized point is weakly averaging.
Hint: Each element of V determines a constant self-map of V , V  
 V V , and
this can be used to show that
X  
 HomV V (V X, V )  
 HomV (V X, V )  
 V V X

8.4 Measuring, Averaging, and Winning with V -Valued Quantities
151
where HomV V denotes the generalized points, that is, the functionals α that are
homogeneous with respect to all λ in V V .
♦
To what extent all generalized points are really just the original elements has
long been of interest. Isbell showed in 1960 [Is60] that if V is a given inﬁnite set,
then
X
∼ HomV V (V X, V )
for all sets X that arise in ordinary geometry and analysis even though by Cantor’s
theorem most of these X’s are larger than V . However, many set-theorists study
the possibility of the existence of sets X so large that they cannot be “measured”
by any ﬁxed V in this way (paradoxically, these hypothetical extremely large sets
are usually called “measurable cardinals”).
For a small V , like V = 2, it is easy to ﬁnd examples of generalized points that
are not points but are interesting in view of some applications: V V has four elements
λ, of which the identity 1V contributes no restriction on generalized points. Thus,
Proposition 8.22: A functional 2X
α  2 commutes with all λ in 22 if and only if
α(⌜X⌝) = 1,
α(0) = 0
α(ϕ) = 1 ⇐⇒α(¬ϕ) = 0
(where ¬ : 2
 2 is deﬁned by ¬0 = 1, ¬1 = 0).
■
Such generalized points α are sometimes considered to arise from a context in
which the elements of X can “choose sides” in various ways to produce an alignment
ϕ that will either “win” α(ϕ) = 1 or “lose” α(ϕ) = 0. (The following is a further
restriction on α sometimes considered: if ϕ ⊆ϕ′ and α(ϕ) = 1 then α(ϕ′) = 1.
However, it is not true in all situations α that a team ϕ′ bigger than a winning team
ϕ would also win (consider what may happen if too many CIA and MI5 individuals
inﬁltrate our team)). We want to see that there are situations α that are generalized
points of X in the sense that they preserve the action of all λ ∈22 but are not points
ˆx0; in other words, the situation α is more complex than one in which there is such
a towering star player x0 that for any ϕ, ϕ is a winning team if and only if x0 is on
ϕ. If X is too small, such complexity will not be possible.
Exercise 8.23
If X = V , then X
∼ HomV V (V X, V ). Take the example ϕ = 1X but note that in
this case a condition λ in V V may be considered also as an arbitrary input for a
functional.
♦

152
More on Power Sets
Thus, for V = 2, we need to take X with at least three elements to ﬁnd generalized
points α which do not come from points.
Exercise 8.24
If X has n elements, show that the number of maps 2X
α  2 that commute with
the action of all four λ in 22 is
22n−1 −1
For the case n = 3, X = {a, b, c}, determine explicitly all eight α’s by displaying,
for each α all the teams ϕ that win α.
(Such ϕ can conveniently be displayed as subsets of {a, b, c}.)
♦
Exercise 8.25
Let V = 3. Show that the 27 conditions a generalized point must satisfy all follow
from a much smaller number among them. Show that any generalized point of any
ﬁnite set X is in fact a point of X itself.
♦
Remark 8.26: The recovery of X from measurement, i.e.,
X
∼ HomV V (V X, V )
is also valid when X is “any” metrizable continuous space, V = R (the space of
real numbers), and all maps are continuous.
♦
8.5 Additional Exercises
Exercise 8.27
To deﬁne the covariant power set functor we used only the elementary (topos)
properties of S. Describe im f for an arrow X
f  Y in S/X. Note that to do this it
is ﬁrst necessary to describe the objects P X (recall Exercises 5.12, 6.8).
Exercise 8.28
Describe im f for an arrow X
f  Y in S2op.
Recall Section 6.2 and Exercise 6.13.
Exercise 8.29
Describe im f for an arrow X
f  Y in M-sets.
Recall Exercises 5.13, 6.15.

8.5 Additional Exercises
153
Exercise 8.30
Similarly, to deﬁne the singleton arrow, X
{ }  P X, we again used only the ele-
mentary (topos) properties of S. Describe X
{ }  P X for an object X in each of
S/A, S2op and M-sets. Keep in mind that 2 in the construction of Section 8.2 must
be replaced by the appropriate truth-value object.
Exercise 8.31
Showthatthediagonalarrow X
X  X × X providescomponentsofanaturaltrans-
formation (see Appendix C.1) from the identity functor to the composite functor
(−× −)(see Exercise 5.17). Find a natural transformation from the composite
functor (−× −) to the identity functor on S × S.

9
Introduction to Variable Sets
9.1 The Axiom of Inﬁnity: Number Theory
Recall that we denote by S the category of (abstract, discrete, constant) sets and
arbitrary maps between them that we have studied till now. In the various branches
of mathematics (such as mechanics, geometry, analysis, number theory, logic)
there arise many different categories X of (not necessarily discrete, variable) sets
and respectful maps between them. The relation between S and the X’s is (at least)
threefold:
(0) S is “case zero” of an X in that in general the sets in X have some sort of
structure such as glue, motion and so on, but in S this structure is reduced to
nothing. However, the general X often has a functor X
| |  S determining the
mere number (Cantor) |X| of each such emergent aggregate X.
(1) A great many of the mathematical properties of such a category X of variable
sets are the same or similar to properties of the category S of constant sets.
Thus, a thorough knowledge of the properties of S, together with some cate-
gorical wisdom, can be indispensable in dealing with problems of analysis,
combinatorics, and so forth. The main common properties include the concepts
of function spaces X T and of power sets P(X).
(2) Many examples of categories of variable sets X are reconstructible from S as
X = STop, where T is a datum (which can also be described in S) whose role is
to specify the general nature of the glue, motion, and so on, in which all sets in
X participate, and X is considered to consist of all possible examples having
that particular general nature. (Sometimes such a datum T is called a theory;
we will explicitly consider a few such theories, some of which can actually be
extracted in a fairly simple way from X itself.)
The connection between X and STop often comes about in the following way:
among the variable sets in X there are a few special ones T  
 X such that
knowledge of the |X T | for T in T and their interactions as constant sets (in S)
154

9.1 The Axiom of Inﬁnity: Number Theory
155
sufﬁces to reconstruct any variable set X. (T =↑was considered in Chapter 6.) A
basic example of a mode of variability of sets is T = ·
. That is, we consider a
category S·
of variable sets X in which X has not only elements but also an in-
ternal “dynamic” of the sort that any given element uniquely determines a “next”
element, and the maps between sets respect this internal dynamic. The category
S·
can be regarded as constructed from S as follows:
A set X of S·
“is” (i.e., determines and is determined by) a set of S together
with an endomap as structure
X
ξX in S
A map of S·
“is” two sets X
ξX, Y 
ξY and a mapping f in S satisfying the equa-
tion in S,
f ξX = ξY f
so the following diagram commutes:
Composition in S·
of two maps X
ξX
f  Y 
ξY
g  Z
ξZ is only deﬁned in
case the codomain of f and the domain of g (not only have the same underlying
abstract set of elements but also) have the same internal dynamic ξY. In that case the
composite is formed by forming the g f as in S and forgetting ξY while retaining ξX
and ξZ. Note that we will sometimes abuse notation and not mention the dynamic
ξX of X
ξX.
Exercise 9.1
If f ξX = ξY f and if gξY = ξZg, then (g f )ξX = ξZ(g f ). That is, the composite de-
ﬁned above really does give a result that is again a map in S·
.
♦
Exercise 9.2
Let 1 denote a one-element set equipped with the only possible dynamic (endomap).
For any X in S·
, there is a unique S·
-map X
 1. Show also that S·
has
an initial object.
♦
Exercise 9.3
A map 1
x  X in S·
is always the same thing as a ﬁxed point of the dynamic of
X, that is, an element x of the underlying abstract set of X for which
ξXx = x
♦

156
Introduction to Variable Sets
Thus, the maps from T = 1, although an extremely important aspect of the sets X
in S·
, fall far short of detecting all the elements of the underlying set of X; another
object T = N is necessary for that purpose, and that will force the existence in S
itselfof inﬁnite sets.Inmoredetail,theunderlyingabstractsetof N (alsodenoted N)
must be equipped with an S-endomap N
σ (usually called “successor”) of the
underlying set (in order to be a set of S·
at all), and we want there to be a natural
invertible correspondence
N
x  X in S·
1
x0  X in S
↑↓
Taking the case X = N, x = 1N, we deduce that there must be a distinguished
element
1
x0 = 0  N
of the underlying abstract set of N. Since just to say N
x  X in S·
is to say that
xσ = ξXx in S, we are led to the following statement characterizing the system
1
0  N
σ
of maps in S·
in terms of S only:
AXIOM: DEDEKIND–PEANO
There exist 1
0  N
σ  N in S such that for any diagram
1
x0  X
ξ
in S there exists a unique sequence x for which both x0 = x0 and xσ = ξx
Here “sequence” is the standard name for maps in S with domain N. The equation
expressed by the commutativity of the square is the condition that x be a respectful
map in variable sets, and the triangular equation expresses that the element x0
is being represented by x. Notice also that the axiom is a statement about S. It
is precisely the axiom of inﬁnity we promised in Chapter 6. With this axiom we
have completed our listing of axioms for S. In any category, an object N (or more
precisely, the diagram 1
0  N
σ  N) satisfying the Dedekind–Peano axiom is
called a natural number object.

9.2 Recursion
157
Now the claim that N is not ﬁnite can be justiﬁed by examples of X. For example,
one variable set in S·
is
0
1
2
3
4
i.e. ξ(x) = x + 1
x < 4;
ξ(4) = 4
X5 :
Hence, there must exist a map N
x  X5 in S·
with this ﬁve-element codomain,
that is, a map in S for which
x0 = 0
xσ0 = x0 + 1 = 1
xσσ0 = xσ0 + 1 = 1 + 1 = 2
xσσσ0 = xσσ0 + 1 = 2 + 1 = 3
xσσσσ0 = xσσσ0 + 1 = 3 + 1 = 4
xσσσσσ0 = ξ(4) = 4
Hence, 0, σ0, σσ0, σσσ0, σσσσ0 must be distinct elements of N since they have
distinct values under at least one map x. Of course under this x all the elements
σ 50, σ 60, . . . get the same value in X5. But the single set N is supposed to work for
all X, so one could take X = X6 to see that there is at least one x that distinguishes
σ 50 from σ 60, and so on. Thus, in N all elements obtained from 0 by successive
application of the successor map σ are distinct. If N had other elements than those so
obtained, an X could be constructed for which two mappings N
 X represent
the same element of X, contradicting the uniqueness part of the universal mapping
property of N. Thus, we are led to the following intuitive idea:
N = {0, 1, 2, 3, . . .}
σn = n + 1
9.2 Recursion
The universal property of the successor σ says (using the usual notation xn = xn
for the values of a sequence) that for any given “next step” rule X
ξ on any set X
and any given starting value 1
x0  X, there is a unique sequence x in X such that
x0 = the given starting value
xn+1 = ξ(xn) for all n
The sequence x is said to be deﬁned by simple recursion from x0, ξ. We will prove
in Lemma 9.5 the existence of sequences deﬁned by somewhat more general kinds

158
Introduction to Variable Sets
of recursions as well. First note that we can formally prove one of the characteristic
properties of inﬁnite sets.
Theorem 9.4: 1 + N
∼ N. The successor map is injective but not surjective,
therefore N is Dedekind inﬁnite.
Proof: By the universal mapping property of coproduct there is a unique f for
which
1
i∗
0

1 + N
f
 N
N
iN
σ

We want to deﬁne an inverse N
g  1 + N = X for f by recursion. But the
“recursion” satisﬁed by g is
g0 = i∗
g(n + 1) = iN(n)
in which the right-hand side is not simply some function ξ of the “previous value”
g(n) but instead is some function of n and does not mention g(n). Even dependence
on both n and g(n) still permits recursive deﬁnition:
Lemma 9.5: (Recursion Lemma) If N × A
h  A is any given map and if 1
a0  A
is any given element, then there exists a unique sequence N
g  A for which
g(0) = a0
g(n + 1) = h(n, g(n))
Proof: (The discrete version of a standard method for dealing with nonautonomous
differential equations: augment the state space to include also the time coordinate).
Deﬁne
X = N × A,
ξX(n, a) = ⟨n + 1, h(n, a)⟩,
x0 = ⟨0, a0⟩
Then by simple recursion there is a unique x for which
x(0) = x0 = ⟨0, a0⟩
x(n + 1) = ξx(n)

9.2 Recursion
159
But if we deﬁne u and g by
so that xn = ⟨un, gn⟩for all n, then we have
⟨u0, g0⟩= ⟨0, a0⟩
⟨u(n + 1), g(n + 1)⟩= ξ⟨u(n), g(n)⟩
= ⟨u(n) + 1, h(n, gn)⟩
by deﬁnition of ξ. Hence, by taking projections
u(0) = 0
u(n + 1) = u(n) + 1
that is, u = 1N by uniqueness, and
g(0) = a0
g(n + 1) = h(n, gn)
as required; g is uniquely determined since x is.
■
Corollary 9.6: There is a unique map N
p  N called the predecessor map for
which
p(0) = 0
pσ = 1N
In other words p(n + 1) = n forall n.(Hence σ isinjective since it hasaretraction.)
Proof: Take the ﬁrst projection from N × N for h in the lemma. This is the opposite
extreme (from the original axiom) of the lemma, namely the rule N × A
 A
(with N = A) for computing the next value depends only on N rather than
on A.
■
Now we can complete the proof of the theorem 1 + N
∼
f
N because the inverse
g can be deﬁned by
g(0) = i∗
g(n + 1) = iN(n)

160
Introduction to Variable Sets
(similar to, but not identical with, the predecessor function). Then
f g(0) = 0
( f g)(n + 1) = f iN(n)
= σ(n) = n + 1
so that f g = 1N by uniqueness of functions deﬁned by recursion. Also
g f i∗= g(0) = i∗
g f iN = gσ = iN
so that g f = 11+N by the uniqueness of maps from coproduct sets. Hence,
1 + N
∼ N.
■
9.3 Arithmetic of N
We also want to show that N × N ∼= N, but we need ﬁrst to develop some of the
arithmetic of N to be able to deﬁne the comparison maps.
Much of the arithmetic of N is implicit in the internalization of the recursion
process itself. First note that
Proposition 9.7: Given any map A
α  A there is a sequence N
α( )  AA such
that
α0 = 1A
αn+1 = ααn
(composition)
(note the abuse of notation which ignores ⌜⌝).
Proof: Apply the Dedekind–Peano axiom to the case where X = AA, x0 = ⌜1A⌝,
and where the “next stage” endomap
AA
ξ  AA
is the one that composes any map β with α: ξ(β) = αβ for all 1
β  AA.
■
Internalizing the proposition, we get
Theorem 9.8: For any set A there is a map
AA
iterA  (AA)N
that assigns to any α the (name of the) sequence of iterates of α.

9.3 Arithmetic of N
161
Exercise 9.9
Show directly that iterA exists.
♦
For example, if A = N we have a procedure
N N
iterN
 (N N)N ∼= N N×N
which assigns, to each map N
α  N, a binary operation α on N satisfying
α(0, m) = m for all m
α(n + 1, m) = α(α(n, m)) for all n, m
For example, if we take α = σ, the basic successor operation itself, then the
iteratively derived binary operation satisﬁes
σ(0, m) = m
σ(n + 1, m) = σ(σ(n, m)) = σ(n, m) + 1
This proves the existence (as a map) of the operation of addition of natural
numbers
σ(n, m) = n + m
in which notation the above recursion rules for generating σ become the familiar
0 + m = m
(n + 1) + m = (n + m) + 1
Diagonalizing the addition map
N
δ  N × N
+  N
we get the map N
 N, which is usually denoted by 2 · ( ), “multiplication by
2”. The iteration process can be applied to the latter to yield the binary operation α
for which
α(0, m) = m
α(n + 1, m) = 2 · α(n, m)
Exercise 9.10
Determine the operation α satisfying the preceding recursion relations.
♦
Exercise 9.11
Use the maps 2 · ( ) and 2 · ( ) + 1 to set up an explicit invertible map
N + N
∼ N.
♦

162
Introduction to Variable Sets
To obtain the existence of multiplication as a map, note that it should satisfy the
recursion
0 · m = 0
(n + 1) · m = n · m + m
More generally, given any set A equipped with an “addition” (assumed associative)
A × A
+  A and a “zero” 1
0  A, we can simply apply the iterator to the trans-
pose of + and follow the result by evaluation at 0
A
⌜+⌝ AA
iter  (AA)N
evN
0  AN
obtaining a map whose transpose is the map
N × A
·  A
which is usually called multiplication.
The idea for proving N × N
∼ N is based on the observation that the ﬁbers of
the map N × N
+  N are ﬁnite (in fact the nth ﬁber has length n + 1), and so it
should be possible to deﬁne a map N
 N × N that runs through each ﬁber one
after another, thus eventually running through all of N × N (without repetitions):
0, 0
0, 1
0, 2
1, 0 2 0 3 0
N × N
+
N
0
1
2
The inverse N × N
f  N of the desired enumeration N
 N × N will indicate
the number of steps that have been traversed in the enumerated path in reaching a
given point ⟨x, y⟩. The ﬁber of + in which ⟨x, y⟩lies is determined by x + y = n,

9.3 Arithmetic of N
163
and at the top (beginning) of the nth ﬁber the path has taken

k<n
(k + 1) = n(n + 1)
2
= (x + y)(x + y + 1)
2
steps. Thus, at the point ⟨x, y⟩itself, where x additional (downward to the right)
steps have been taken, we get
f (x, y) = (x + y)(x + y + 1)
2
+ x
This quadratic expression is actually injective and surjective when considered with
only natural numbers in its domain and codomain, N × N
f  N. The best proof
of that is to recursively deﬁne the inverse map N
⟨x,y⟩ N × N whose components
are often called “pairing functions”.
Exercise 9.12
Show that for any set A equipped with a commutative and associative operation
A × A
+  A, with zero 1
0  A, there is a map
AN

 AN
that assigns to any sequence a its sequence of partial sums
(

a)n =
n−1

k=0
ak
(note that ( a)0 = 0 independent of a).
♦
The veriﬁcation that, for example, the composition of two sequences deﬁned
by recursion is equal to another given sequence deﬁned by recursion can often
be done just by verifying that the effective recursion data are the same. But more
generally, such equality statements are usually proved by the method known as
induction. Note that the equalizer of two sequences is a part of N, therefore the
usual statement of induction involves parts of N rather than equations.
Theorem 9.13: (also known as Peano’s Postulate). If A is any part of N, one can
conclude that A is actually the whole of N, A
∼
i A
N, provided one can show that
both
0 ∈A
and
∀n [n ∈A ⇒n + 1 ∈A]
Proof: We need to recursively deﬁne an inverse x : N
 A for the inclusion i A
of A in N. By the second part of the hypothesis there is a map A
σA  A for which

164
Introduction to Variable Sets
i AσA = σi A. Since, moreover, 0 ∈A, there is by recursion a unique N
x  A for
which
x0 = 0
xσ = σAx
Then,
i Ax0 = 0
i Axσ = i AσAx
= σi Ax
= σ(i Ax)
Therefore,
i Ax = 1N
as the unique solution of the recursion problem whose solution is 1N. Furthermore,
we have i A(xi A) = (i Ax)i A = 1Ni A = i A1A, and so xi A = 1A since i A is monic.
Combining these shows that i A : A
∼ N, as claimed.
■
Now the equation
means that A
σA is a part of N
σ in the sense of the category S·
(see Exercise
9.18). The induction theorem says that if such a part contains the element 0 in its
underlying abstract set, then it can only be the whole N. But how many parts of N
(in the sense of S·
) are there altogether? There is of course the empty part. But,
moreover, given any element of N, for example 5, the representing map
N 5+( ) N
is a part of N (also in S·
) whose members are 5, 6, 7, 8 . . . . It should be clear
that there are no other parts of N in S·
(even though in S there is a huge number
2N of parts of N). This knowledge of the structure of parts of N will be essential
in understanding the nature of a different remarkable variable set P N(1), the set of
truth values for S·
.
Exercise 9.14
Determine the classiﬁer P N(1) for sub dynamical systems.

9.4 Additional Exercises
165
Hint: Let 0 stand for “true” (“already true”) and ∞for “false” (i.e., “will never
become true”) and remember that the indicator map X
 P N(1) of any part A
of any X must be a map in S·
, whereas the internal dynamic of P N(1) must be
given once and for all independently of X. Show that every map N
 P N(1) has
ﬁnite image.
♦
9.4 Additional Exercises
Exercise 9.15
Why does the statement 1 + N ∼= N imply that successor is not surjective?
Exercise 9.16
Show that the addition mapping N × N
+  N satisﬁes
(n + m) + p =n + (m + p)
n + m =m + n
n + p = m + p ⇒n = m
Exercise 9.17
Show that the multiplication mapping N × N
·  N satisﬁes
(n · m) · p =n · (m · p)
n · m =m · n
n · p = m · p ⇒n = m or p = 0
Exercise 9.18
Identify the monomorphisms in S·
.
Exercise 9.19
Show that S·
has products and equalizers (and hence all ﬁnite limits). Show that
S·
has all ﬁnite colimits.
Exercise 9.20
Show that S·
has exponential objects. Notice that this exercise combined with
the preceding exercise and Exercise 9.14 implies that S·
is a topos.
Exercise 9.21
Show that there is an object in S/X that has an element 0 and an endomorphism σ
(both in the sense of S/X) that satisﬁes the Dedekind–Peano axiom.
Hint: The object is constant as a family, that is, as a mapping to X it is a projection.

166
Introduction to Variable Sets
Exercise 9.22
Show that S2op has a natural number object.
Hint: The object has an identity as its transition arrow.
Exercise 9.23
Show that the category of M-sets has a natural number object.
Hint: The object has trivial action by M.
Exercise 9.24
Show that S·
(!) has a natural number object.
Hint: The object has an identity as its structural endomorphism.
Exercise 9.25
(a) Show that there is a (diagonal) functor (Appendix C.1) denoted  from S to
S·
whose value at a set A is the object of S·
given by A with the identity
endomorphism. (Deﬁne  also on mappings and show it satisﬁes the equations.)
(b) Show that there is a functor Fix from S·
to S that sends an object X of S·
to its set of ﬁxed points (see Exercise 9.3).
These two functors have the following important relationship:
(c) Show that for any set A in S and object X in S·
there is a one–one correspon-
dence between mappings in S·
from (A) to X and mappings in S from A
to Fix(X). ( is left adjoint – see Appendix C.1 – to Fix.)

10
Models of Additional Variation
10.1 Monoids, Posets, and Groupoids
The section title names three very special classes of categories that arise frequently.
Knowledge of these categories is helpful in analyzing less special situations.
Deﬁnition 10.1: A monoid is a category with exactly one object.
Hence any two maps in a monoid A can be composed; this composition is
associative and has a two-sided neutral element usually called 1. A monoid A is
often said to arise concretely if we are given some large category E (of structures
or spaces), if we choose an object A of E, and if we deﬁne A to consist of all
E-endomaps of A.
A
A
E
Thus, for example, all linear endomaps of the particular linear space A = IR3,
i.e. all 3 × 3 real matrices, constitute a monoid A, where composition is matrix
multiplication. Here E could be the concrete category of all IR-linear spaces and
maps; hence, A can be considered to arise concretely in the preceding sense. We
will study in more detail in Section 10.3 another example, the concrete monoid
of all endomaps (in the sense of the concrete category E = S of abstract sets and
167

168
Models of Additional Variation
arbitrary maps) of the particular two-element set A = 2; the resulting monoid A
has exactly four maps in it, one of which is a non-identity involution (ττ = 1) and
two of which are constant (cx = c for all x in A); moreover,
τc0 = c1, τc1 = c0
where c0, c1 are the two constants.
Deﬁnition 10.2: In a category (not necessarily a monoid), the notion of constant
map A
c  B can be deﬁned as follows: for every object T there is a map T
cT  B
such that for all T
x  A, cx = cT .
Note that in any category with a terminal object, a constant in the sense of
Deﬁnition 1.25 satisﬁes this deﬁnition also.
Exercise 10.3
Show that 2
c1  2 is constant in the sense of this deﬁnition even when we consider
it within the whole category S.
♦
On the other hand, monoids often arise non-concretely:
Exercise 10.4
With each real number s associate “abstractly” a map Ts and deﬁne
1 = T0
TsTt = Ts+t
Show that a monoid (i.e., a one-object category) is thus obtained. Can this monoid
be realized concretely, as the full subcategory of all endomaps of a suitable object
A in the category of all structured spaces of some kind?
♦
Exercise 10.5
For pairs ⟨a, b⟩of real numbers, deﬁne
⟨a2, b2⟩· ⟨a1, b1⟩= ⟨a2a1, a2b1 + b2⟩
Prove that this is a one-object category. Which pair ⟨a0, b0⟩is the identity map 1 of
this category? Can it be concretely realized?
♦
A second special class of categories is described by

10.1 Monoids, Posets, and Groupoids
169
Deﬁnition 10.6: A category A is a poset (short for partially ordered set) if and
only if there is at most one map from any object to any other object:
A′
f

g
 A =⇒f = g
We often write A′ ≤A (or A′ ⊆A or A′ ⊢A) to mean
∃f [A′
 A]
Sometimes it is important (though usually not) to distinguish between posets in
general and “strict” posets in particular, the latter being those for which the further
condition
A′ ≤A and A ≤A′ =⇒A′ = A
holds.
A poset A is often said to arise concretely if we are given a large category E of
structured spaces, choose an object X in E, and deﬁne A to be a category of parts
of X (in the sense of E) with inclusions as maps.
Exercise 10.7
In a poset all maps are monomaps. If A is a category that has a terminal object and in
which all maps are monomaps, then A is a poset. Give an example of a category in
which all maps are monomaps but which is not a poset.
♦
Exercise 10.8
In any category B, we could deﬁne B′ ≤B to mean ∃B′
 B. Explain how this
idea associates to every category B a poset B po and deﬁne a functor (see Deﬁni-
tion 10.18) B
 B po. When is this functor invertible?
♦
Exercise 10.9
Consider triples ⟨x, y,r⟩, where x, y are arbitrary real numbers but r is real with
r > 0. Deﬁne ⟨x, y,r⟩
f  ⟨x, y,r⟩to mean that r ≤r as real numbers and f is
a nonnegative real number f ≥0 for which
(x −x)2 + (y −y)2 = (r −r + f )2
Deﬁne composition so as to make this a category. Is it a poset? Can it be concretely
realized?
♦

170
Models of Additional Variation
Exercise 10.10
There is only one category that is both a monoid and a poset, and it is a “groupoid”
in the following sense:
♦
Deﬁnition 10.11: A category is said to be a groupoid if and only if every arrow in
it has a two-sided inverse in the same category:
∀A′, A∀A′
f  A∃A
g  A′[ f g = 1A and g f = 1A′]
Usually the name group is reserved for those groupoids that are moreover
monoids, but frequently in applications groupoids arise that are not monoids; fortu-
nately, almost all the profound theorems proved in the past 200 years for one-object
groups extend rather effortlessly to groups with many objects. Certainly for our
purposes, the property of having all maps invertible will be more signiﬁcant as an
indicator of a qualitative particularity of variation/motion; the accident of being
described in terms of a single object will mainly serve the subjective purpose of
making some problems seem simpler. One sometimes says that a groupoid A arises
concretely if we are given a category E of structured spaces and we deﬁne A to be
the category of all isomorphisms in E
A = Iso(E)
that is, the objects of A are the same as those of E, but the maps of A are only those
maps of E that have 2-sided inverses in E.
Exercise 10.12
1A is invertible for all A. If f1, f2 are invertible and composable in E, then f2 f1 is
invertible in E. Hence, Iso(E) is a category.
♦
Exercise 10.13
If g is the two-sided inverse for f , then g itself has a two-sided inverse. Hence
Iso(E) is a groupoid.
♦
Exercise 10.14
If we intersect the groupoid Iso(E) with the endomorphism monoid EndoE(A) of
an object, we get
AutE(A) = Iso(E) ∩EndoE(A)
a one-object groupoid (called the automorphism group of A in E).
♦

10.2 Actions
171
Exercise 10.15
If A is a ﬁnite set in the category E = S of abstract sets and arbitrary maps, then
AutS(A) = A! (factorial)
♦
Exercise 10.16
Show that there is a group with only three maps
1, w, w2, w3 = 1
Can it be realized concretely?
♦
10.2 Actions
10.2.1 Actions as a Typical Model of Additional Variation and
the Failure of the Axiom of Choice as Typical
The notion of “action” is deﬁned for any (even abstractly given) category A, but
then the actions of A are the objects of a category
ˆA of structured spaces from
which we can extract concrete subcategories A′, which in turn (in their abstract
guise) have actions. This dialectic is quite essential in all parts of mathematics
since even if we start with the “self-action” of concrete A, other actions of the same
A immediately arise by mathematical constructions such as taking the spaces of
open subsets, of compact subsets, of continuous functions, or of measures, on the
original spaces. Actually, there are left actions and right actions of A. Let us ﬁrst
consider the situation in which A is a given subcategory of a category E. For any
object X of E we can consider the algebra A(X) of A-valued functions on X (in
the sense of E) as follows:
(0) For each object A of A there is a set
A(X)(A) def
= E(X, A)
deﬁned in this case as the set of all E-maps X
 A.
(1) For each element f of the set A(X)(A) and for each map A
α  A′ of A
there is an associated element αf of the set A(X)(A′), deﬁned in this case as
composition.
(2) 1A f = f .
(3) (αα) f = α(αf ) in A(X)(A′′) whenever A
α  A′
α  A′′ in A and whenever
f is an element of the set A(X)(A).
Any system of sets associated to the objects of a category A together with any
system of operations between these sets associated to the maps of A in such a
way as to satisfy conditions (2) and (3) is called a left A-action, or simply a left

172
Models of Additional Variation
A-set, regardless of whether it is given by composition in terms of some enveloping
category E and some object X in it.
Exercise 10.17
The preceding description of the action of maps in A as operations on the function
algebra of X is not limited to unary operations because not only is A not necessarily
a monoid, but it even may contain Cartesian products for some of its objects. For
example, if E is the category of smooth (C∞) manifolds X (e.g., open balls and
their bounding spheres, tori, IRn, etc.) and smooth (C∞) maps between them, we
could take as A the subcategory of E determined by the two objects IR and IR2;
then if f1, f2 are any two elements of A(X)(IR) and if IR2
θ  IR is addition or
multiplication, then there is a uniquely determined element f of A(X)(IR2) for
which f1θ f2 = θ f in A(X)(IR).
♦
The totality of left A-sets becomes a category SA by deﬁning the appropriate con-
cept of map between them; in this case maps ϕ are often called A-homomorphisms
or A-natural maps (or even A-homogeneous maps). The crucial formula express-
ing compatibility with the action is
(αg)ϕ = α(gϕ)
for all elements g of the domain of ϕ and all A-maps α acting on both domain and
codomain of ϕ; since each of the domain and codomain is really a family of sets,
one for each object A of A, correspondingly ϕ is really a family of set maps ϕA,
and the preceding formula is often expressed as the commutativity of the naturality
diagram
(Since left A-sets are often “algebras” – as opposed to the “geometries” we will
usually deal with – it would not be inappropriate here to use I. N. Herstein’s con-
vention that in algebra evaluation and composition are written in the opposite order:
thus, (g)ϕ would mean the value of the homomorphism ϕ at the element g, and ϕψ
would mean ﬁrst ϕ then ψ; we will not be using that notation in most contexts.)
We can sum up the discussion with the following deﬁnitions.
Deﬁnition 10.18: If A and B are categories, a functor 
 from A to B is an
assignment of
r an object 
(A) in B for every object A in A
r an arrow 
( f ) : 
(A)
 
(A′) in B for every arrow A
 A′ in A

10.2 Actions
173
subject to the following equations:
r 
(1A) = 1
(A)
r 
(g f ) = 
(g)
( f ) whenever A
f  A′
g  A′′
Deﬁnition 10.19: The category of left A-sets SA has as objects the functors 
 :
A
 S. A morphism ϕ in SA from 
 to 
′ is a natural transformation, where a
natural transformation or homomorphism ϕ : 
 
′ is a family of morphisms
ϕA : 
(A)
 
′(A) satisfying

′(α)ϕA = ϕA′
(α)
whenever
A
α  A′
Exercise 10.20
If A ⊂E is a full subcategory and if X
ϕ  Y is any map in E, then there is a
natural homomorphism of left A-sets
A(Y)
 A(X)
between the associated function algebras deﬁned by
g →gϕ
♦
Instead of trying to maintain two conventions on the order of composition (one
for algebra and one for geometry) most authors write something like
A(Y)
ϕ∗ A(X)
to denote the operation of “pulling back along ϕ” the A-valued functions g on Y to
A-valued functions on X, i.e. ϕ∗g = gϕ. One can prove the functoriality formula
(ψϕ)∗= ϕ∗ψ∗
very easily in this context. (The functor is objectively contravariant as X varies no
matter how we subjectively write it.)
Some basic examples of right A-actions also arise from some realization of A
as a concrete category and the choice of an object X in an enveloping category
E ⊃A. We will use (for the moment) GA(X) to denote the resulting right A-set:
(0) For each object A of A there is a set
GA(X)(A) def
= E(A, X)
(1) For each element x of GA(X)(A) and for each map A′
α  A of A there is an
associated element xα of GA(X)(A′).
(2)
x1A = x
(3)
x(αα′) = (xα)α′ in GA(X)(A′′)
whenever A′′
α′  A′
α  A in A and x is an element of GA(X)(A).

174
Models of Additional Variation
Just as we called the concrete example A(X) of a left A-set a “function algebra”
with the action of A called “algebraic operations” on the functions, and natural
homogeneous maps “homomorphisms,” so we could call GA(X) the “geometry
of ﬁgures” in X with the action of A expressing “incidence relations” among the
ﬁgures x, x′; the natural homogeneous maps could be called “A-smooth”. Note that
if x is a part of X and if x′ is a given ﬁgure in X, then there is at most one α such that
x′ = xα, in which case we could just write x′
 x or x′ ∈x or x′ ⊆x to describe
the incidence situation. However, in general the description of an incidence situation
will involve speciﬁcally naming elements α of the set GA(X)(x′, x) of maps in A
for which x′ = xα. This is because in general it is necessary to consider “singular”
ﬁgures x (i.e., those that are not parts) to do justice to the geometry GA(X) of X, as
seen from A in E. For example, A itself may be shaped as a closed interval [0, 1],
X may be a plane, and “A-smooth” may mean exactly “continuous”. The ﬁgures in
GA(X)(A) are continuous curves in the plane, including many that are parts of the
plane but also many loops x for which x(0) = x(1) and hence x is “singular”! This
latter is actually an incidence relation, for we can include in our little category A also
the space A′ consisting of one point. A ﬁgure of type A′ in X is then just a speciﬁed
point x′ of the plane. There are two maps A′
α0

α1
 A of particular interest here.
Exercise 10.21
Deﬁne α0, α1 so that the incidence relations in GA(X)
xα0 = x′
xα1 = x′
are equivalent to saying that the curve x is a loop at the point x′.
♦
Exercise 10.22
If A ⊂E and X
ϕ  Y is an arrow of E show that there is an induced A-smooth
map of right A-sets:
GA(X)
ϕ  GA(Y)
♦
Exercise 10.23
Let Aop be the opposite category for A, i.e., the category with the same objects as
A, but with Aop(A, A′) = A(A′, A) and composition derived from A’s. Show that
a right A-set is the same thing as a left Aop-set and further that the category of right
A-sets and all A-smooth maps is exactly SAop.
♦
Brieﬂy for right A-sets the action of A is contravariant, whereas the basic induced
A-natural maps are covariant, (opposite to the situation for left A-sets).

10.2 Actions
175
Of both left and right A-sets there is a supply of especially fundamental examples
whose construction does not require imagining a concrete enveloping category E,
namely, we can consider A(X) and GA(X), where X is an object of A itself. These
examples are usually referred to by names like “representable functors,” “regular
representation,” or “self-actions by translation”. Of course, if A is a monoid this
supply of examples is limited to one, even though the categories of left A-sets and
right A-sets are still quite vast and varied. But the representables are very useful
probes in studying the general actions.
Exercise 10.24
(Yoneda’s lemma) For any category A, let C be an object of A and let 
 be any
right A-set, i.e. a family of sets parameterized by objects of A and a family of
set-maps between these contravariantly parameterized by the maps of A, satisfying
the associative and unit laws
x1 = x
x(αα′) = (xα)α′
Then any A-smooth map
GA(C)
ϕ  
is actually
ϕ = ˆx
forauniquelydeterminedelement x of
(C)(ﬁgurein
oftypeC).Here ˆx(c) def
= xc
for any A
c  C. Further, the action in 
 can be seen as composition of A-smooth
maps: xα = ˆx ˆα for C′
α  C.
♦
Exercise 10.25
(Cayley) Every abstract monoid A can be realized concretely.
Hint: Take E = SAop, and take for A the (essentially unique) representable right
A-set; apply Yoneda’s lemma with 
 = C = A.
♦
Exercise 10.26
(Dedekind, Hausdorff) Every abstract poset A can be realized concretely as
inclusions.
Hint: Take E = SAop and consider the particular object 1 such that
1(A) = a one-element set for all A in A.

176
Models of Additional Variation
Then there is a unique part
GA(C)  
 1
in E for each C in A, and by Yoneda

GA(B) ⊆GA(C)
as parts of 1
in E

⇐⇒

B
 C
in A

If 
 is an arbitrary right A-set, then the action of B
 C on an element x of 
 at
C is represented as composition (in E = SAop) with the inclusion
GA(C)
x
GA(B)
⊆
x|B
Φ
(composition of x with an inclusion is in general often called “restriction” of x
from the larger part to the smaller).
♦
Exercise 10.27
The action by restriction along an inclusion is not necessarily either surjective or
injective.
Hint: Consider the category A = [U
 C] consisting of only two objects and
only one nonidentity map. It is a poset. Let 
(U) = the set of all continuous real-
valued functions on the open interval (0, 1), but 
(C) = the set of all real functions
continuous on the closed interval [−1, 1]. Show that the single restriction process

(C)
 
(U) is neither injective nor surjective.
♦
Exercise 10.28
If A is just a set of objects (no nonidentity maps), then
SAop ∼= S/A.
♦
10.3 Reversible Graphs
Let A be the concrete four-element monoid obtained as endomaps of the two-
element set in the category of sets. The concrete action of A on 2 is a left action,
and indeed the discussion of “winning teams” in Proposition 8.22 and Exercise 8.24
concerns function algebras and homomorphisms relative to this category. However,

10.3 Reversible Graphs
177
we want here to describe instead some examples of right actions of this same
A. In this case we can visualize the right A-sets as (reversible) “graphs” in the
following way. Suppose X is a set equipped with a right action of A = {1, τ, c0, c1}.
Since
cic j = ci
holds in A, one can show that there is a part X0 of the underlying set of X that can
be described in several equivalent ways:
Exercise 10.29
Each of the following four conditions on an element x of X implies the others
xc0 = x,
xc1 = x
∃x′[x′c0 = x],
∃x′[x′c1 = x]
♦
Let X0
i
 X be the part of X whose members are all these special elements;
then we have
τ ∗i = i
where τ ∗is the map deﬁned by the action
τ ∗x = xτ
Moreover, there exists a unique pair of maps d0, d1 as in
X0
i  X
τ ∗
d0

d1

such that id0 = c0∗, id1 = c1∗, where ck∗x = xck as with τ. Then
d0τ ∗= d1,
d1τ ∗= d0
The elements of X0 are often called “nodes” or “vertices”.
Deﬁnition 10.30: For A = {1, τ, c0, c1}, an element x of a right A-set is called a
loop if and only if
xc0 = xc1
An element x is called a one-lane loop if and only if
xτ = x

178
Models of Additional Variation
Exercise 10.31
If x is a loop, then xτ is also a loop. Any one-lane loop is a loop (but not conversely),
and any member of X0 is a one-lane loop (but not conversely).
♦
The preceding calculations suggest a good way to picture an A-set X:
Deﬁnition 10.32: Say that a
x  b in X if and only if
xc0 = a and xc1 = b
(Caution: X is not usually a category since we are not given any composition rule,
and hence x is not in itself a map since we cannot apply it to anything – on the other
hand, we will sometimes consider various ways of enlarging X to get a category.)
Thus, we can picture any right A-set as a reversible graph. The general elements
of X are pictured as arrows that connect deﬁnite nodes as speciﬁed by the action of
c0, c1. For a node a it is convenient to picture the one-lane loop ia as an arrow that
is collapsed to a point, whereas all other arrows (including other loops and even
other one-lane loops) retain length. Since
a x  b ⇐⇒b xτ  a
it is convenient to draw x, xτ next to one another like the two lanes of a two-lane
highway. Thus,
out
in
leave
enter
foray
is a very important example of a ﬁve-element right A-set that has no two-lane loops.
[The representable right A-set, the self-action, gets instead the following picture
c0
c1
1
τ
since
τc1 = c0
τc0 = c1
The ﬁve-element example will be seen to consist of the “truth values” for the
whole category SAop.
Exercise 10.33
There is a unique A-smooth (i.e., natural homogeneous) map ϕ from the repre-
sentable right A-set into the truth-value graph for which
ϕ(1) = enter

10.3 Reversible Graphs
179
There is another one ψ uniquely determined by
ψ(1) = foray
ϕ is injective and hence a part in SAop but ψ is not injective on either nodes or
arrows.
♦
Exercise 10.34
Deﬁne (by a table) an action of A on a set of the right size so that the resulting
A-set can be pictured as the graph
•
and do the same for
•
♦
Exercise 10.35
Deﬁne a surjective A-smooth map p between the two A-sets above
•
•
p
s
Determine all A-smooth maps s in the opposite direction and show that
ps ̸= id
for all of them.
♦
Exercise 10.36
Deﬁne a surjective A-smooth map p “from the interval to the loop”
•
c0
•c1
•
p
s
1
τ
Determine all A-smooth s in the opposite direction and show that ps ̸= id for all
such s.
♦

180
Models of Additional Variation
The last two exercises illustrate that the failure of the axiom of choice is typical
for variable or cohesive sets.
10.4 Chaotic Graphs
Several different kinds of structures are loosely referred to as “graphs”; for exam-
ple, we have already brieﬂy introduced “reversible” graphs. In this section (and fre-
quently later) we will call “graphs” the reﬂexive, not necessarily reversible graphs,
which are just the right actions of the three-element monoid
1 = {1, δ0, δ1}
δiδ j = δi
i, j = 0, 1
Exercise 10.37
This monoid can be realized concretely as the order-preserving self-maps of the
nontrivial two element poset.
♦
If X is such a graph, then for each element x, xδ0 is the beginning point of the
arrow x, and xδ1 is the endpoint. The points themselves are considered degenerate
arrows, which are special loops.
Deﬁnition 10.38: The arrow x is a loop if and only if xδ0 = xδ1 and is degenerate
if and only if
xδ0 = x = xδ1
Exercise 10.39
If xδ0 = x, then x is a degenerate loop (use the multiplication table for 1 and the
associativity of the action).
♦
Exercise 10.40
Write the action table for the seven-element right 1-set pictured here
c
w

a
x
 b
y

z







♦
A basic example of a graph is the right action of 1 on itself, which is pictured
as
0
u  1

10.4 Chaotic Graphs
181
with the correspondences
u ∼1, 0 ∼δ0, 1 ∼δ1 in 1
Exercise 10.41
If X is any graph and x in X, then there is a unique map of graphs (= 1-smooth
map)
for which x(u) = x.
♦
We now want to discuss left-1 actions. There is a huge difference between
the left and right categories. The graphs have the capacity to encode arbitrarily
complicated information, and thus the complete classiﬁcation of graphs is probably
not possible. On the other hand the left-actions can be completely classiﬁed almost
immediately. Their interest is that they will give rise to a class of right actions,
the chaotic graphs, which will include the recipients for many graph quantities of
interest.
In general, if T is a set with a given left action of a monoid A, and if V is any
set, then the set
T ⇒V
of all maps from T to V has a natural right action of A:
( f α)(t) = f (αt) for all t in T
which deﬁnes f α as a new element of T ⇒V for any given element f of T ⇒V .
The argument αt (at which f is evaluated to get the value at t of f α) is given by
the presupposed left action on T of α in A.
Exercise 10.42
For an iterated action f (α1α2) = ( f α1)α2 since both sides have the same value at
each t in T .
♦
Now in particular a left action on T of the three-element monoid 1 means
δiδ jt = δit
for i, j = 0, 1
Exercise 10.43
If δ0t = δ0s, then δ1t = δ1s and conversely.
♦

182
Models of Additional Variation
Hence, the orbits of a left action are just determined by either of the two equations
in the exercise, and each of δ0, δ1 is constant on each orbit. In other words, a left
action with just one orbit is speciﬁed by an arbitrary set and a chosen pair t0, t1 of
elements, with
δ0t = t0
δ1t = t1
for all t in the orbit.
(Recall that the basic example of a left 1 action involved two constant maps,
but the equations cannot force that to be taking place only on a two-element set.)
The most general left 1-set is just a disjoint sum (no interaction between the
summands) of summands, each of which is a left 1 set in its own right but with
the special property of having a single orbit. Since
(

k
Tk) ⇒V ∼=

k
(Tk ⇒V )
is a general result, for our present purpose it will sufﬁce to consider the case of a
single orbit. However,
Exercise 10.44
If π0(T ) denotes the set of orbits (components) of a left 1-set T , then the action
of δ0, δ1 gives rise to two sections of the canonical surjection T
  π0(T ):
•
•
•
•
•
π0T
T
♦
The orbits are the ﬁbers; each of these contains two labeled points t0, t1, but in
some ﬁbers the labeled points may coincide. An arbitrary left 1-set is described
up to isomorphism by giving the set I of components (I = π0(T ) above) for each
i in I, giving the number Ni of elements in that ﬁber, and specifying the part I1 of
the components in which t0 = t1 (rather than t0 ̸= t1) is to hold; these are restricted
only by I1 ≤I and
Ni ≥1 for all i in I
Ni ≥2 for all i not in I1
(I itself can be 0.)

10.4 Chaotic Graphs
183
Returning to the construction of the chaotic graph T ⇒V with a given set V of
“values” and a given left 1-set T with one component: the arrows are arbitrary
functions f from T to V , and
( f δ0)(t) = f (δ0t) = f (t0)
( f δ1)(t) = f (δ1t) = f (t1)
deﬁne f δ0 and f δ1 as constant functions.
Exercise 10.45
The points of T ⇒V are all the constant functions. Identifying these points with
the elements of V , the starting and ending points of any f are identiﬁed with the
values at t0 and t1 of f , respectively.
♦
The intuitive reason for calling T ⇒V “chaotic” is that, for given points v0, v1,
any function T
f  V for which f (t0) = v0 and f (t1) = v1 is considered admis-
sible as an arrow from v0 to v1. One way of relating these very special graphs to
more general, more highly structured ones, is indicated as follows:
Exercise 10.46
If X is any graph and if R is the chaotic graph R = T ⇒V derived from the value
set V and the left 1-set of one component given by 1
t0

t1
 T , then a graph map
X
f  R is determined by specifying a value f (x) in V for each point of V and a
function fx : T
 V for each arrow x of X subject to these conditions:
(1) if a
x  b in X then
t = t0 ⇒fx(t) = f (a)
t = t1 ⇒fx(t) = f (b)
(2) If x = xδ0 = xδ1 = a is a degenerate arrow of X, then fx is the constant func-
tion fx(t) = f (a) for all t in T .
♦
Among the chaotic graphs T ⇒V are the codiscrete ones determined by an
arbitrary set V and by the extremely special two-element left 1-set T in which
t0 ̸= t1. In other words the codiscrete graph on V points has as its arrows all ordered
pairs of elements of V with
⟨v0, v1⟩δi = ⟨vi, vi⟩
for i = 0, 1
That is, the projection and diagonal structure on the cartesian product V × V de-
termines the codiscrete graph structure. The universal mapping property becomes
simply the following:

184
Models of Additional Variation
Proposition 10.47: If V is the codiscrete graph with V points and if X is any
graph, then any graph map
X
 V
is entirely determined by a map X0
 V of sets, where X0 is the set of points of
X. That is, the restriction

X ⇒op
1 V

 (X0 ⇒1 V )
is an isomorphism of abstract sets.
Proof: No matter how many arrows a
x  b there are in X, f (x) can only be the
arrow ⟨f (a), f (b)⟩in V , independently of x.
■
Corollary 10.48: There is a graph 2 such that for any graph X, the graph maps
X
 2 are in one-to-one correspondence with the arbitrary subsets of the set of
points (vertices) of X.
Proof: The set 2 of two elements is the truth-value object for the category of abstract
sets. So consider the codiscrete graph 2 with four arrows and two points, and apply
Proposition 10.47.
■
One can similarly “classify” sets of arrows (not just of vertices).
There is a completely different two-element left 1-set T , namely, the one in
which δ0t = δ1t for all t; in other words t0 = t1, but there is one other element t
that is not a value of either δ0 or δ1.
Exercise 10.49
For the left 1-set T just described, the graph T ⇒V , for any given set V , satisﬁes
T ⇒V ∼= V × ˙V
the sum of V noninteracting copies of a graph ˙V that has one point and V loops.
(Under the isomorphism the “name” of the degenerate loop depends on the sum-
mand.)
♦
Note that a “pointed set” can be viewed as either a graph or a left 1-set. This
can be explained as follows:

10.4 Chaotic Graphs
185
Exercise 10.50
If A is a commutative monoid, there exists an isomorphism of categories
left A-sets
 right A-sets
Note: An isomorphism of categories is a functor that has an inverse, which means
a functor in the opposite direction so that both composites of the two functors are
identity functors.
♦
Exercise 10.51
There is a commutative monoid {1, ϵ} with two elements in which ϵ2 = ϵ and a
surjective homomorphism (= functor) of monoids
1
 {1, ϵ}
Hence, any left (respectively right) {1, ϵ}-set has (via the homomorphism) a natural
left (respectively right) 1 action.
♦
Exercise 10.52
In the notation of the preceding exercise, any {1, ϵ}-set is uniquely a disjoint sum
of pointed sets.
♦
Exercise 10.53
A left 1-set arises by the process above from a pointed set if and only if it has a
single orbit (of arbitrary size T ), and in that orbit the two distinguished points are
equal: t0 = t1.
♦
Exercise 10.54
A right 1-set arises by the procedure above from a pointed set if and only if it is a
graph with precisely one point (= vertex), i.e. if and only if it is connected and all
arrows are loops.
♦
Exercise 10.55
A graph is of the form T ⇒V , where T is a left 1-set arising from a pointed set
(as above) if and only if it is a graph consisting entirely of loops and in which every
vertex is the site of the same number of loops, which number is moreover a power
of the total number of vertices. More exactly, if T = E + {t0 = t1}, then one can
construct an isomorphism of graphs
V ×
˙
(V E)
∼ T ⇒˙V
♦

186
Models of Additional Variation
10.5 Feedback and Control
Can a graph ⟨1A, ϕ⟩of a map A
ϕ  B be part of a graph structure in the sense
of a right 1-set? One way of making this question deﬁnite is as follows: A right
1-set P can equivalently be described as a pair of sets and three maps
A
γ
 P
π

ψ

for which πγ = 1A = ψγ ; that is, the “reﬂexivity” γ is a common section for the
“source” map π and for the “target” map ψ so that it chooses for each “state” a
in A a particular “arrow” γ a in P, which is actually a loop, i.e. an arrow from
a to a itself. The right 1-set structure on such a P is deﬁned by p · δ0 = γ πp,
p · δ1 = γ ψp.
Exercise 10.56
Verify that these equations deﬁne a right 1-set. Conversely, show that any right
1-set P gives rise to such a diagram by deﬁning the state set A to consist of the
trivial arrows, i.e. those p for which p · δ0 = p = p · δ1. Remember that not all
loops are trivial.
♦
Exercise 10.57
If A
ϕ  B and γ = ⟨1A, ϕ⟩is its graph, then on the set P = A × B we have part
of a graph structure
A
γ
 A × B
π

ψ






where π = projection to A since πγ = 1A. (The map ϕ is recovered from its graph
γ by following instead with the projection to B.) Show that a map A × B
ψ  A
completes the structure of a right 1-set on A × B iff ψ(a, ϕa) = a for all a.
♦
Given any A × B
ψ  A to be considered as “target,” pairing it with the projec-
tion π to A considered as “source,” we get a “graph” (not reﬂexive) in which the
arrows are labeled by the elements of B with the property that given any b and any
state a there is exactly one arrow in the graph with label b and source a; the target of
that arrow is a′ = ψ(a, b). The elements of B act via ψ on the states, and the graph
pictures the possible operation of the system; imagine that if b is activated when
the system is in state a, the system will move somehow to state a′. The element b
may be said to maintain a state a iff a = ψ(a, b), i.e. if b labels a loop at a. The
problem of completing the information ψ with a map ϕ whose graph γ = ⟨1, ϕ⟩

10.5 Feedback and Control
187
makes this graph reﬂexive may be a nontrivial one if the maps are to be in a highly
structured category such as a category from linear algebra.
Exercise 10.58
Let A and B be vector spaces and let B
α  A be a linear map.We will consider
some action graphs in which α is one of the ingredients. A simple example is
essentially just the vector subtraction in A
ψ(a, b) = α(b) −a
Show that, with this action graph, b maintains a iff
α(b) = 2a
♦
Exercise 10.59
Using a “feedback” map A
β  B to “observe” the states permits one to adjust
the acting element b before applying α, leading to an action called feedback
control
ψ(a, b) = α(b −β(a))
Show that b maintains a with feedback control iff
α(b) = (1 + αβ)a
♦
Exercise 10.60
Given two opposed linear maps, the graph deﬁned by feedback control ψ as above
may sometimes admit a completion to a right 1 action on A × B; this requires
another linear map A
ϕ  B whose graph would supply the reﬂexivity; in other
words, ϕ would supply, for every state a, a chosen b that would succeed in main-
taining a. Show that a map ϕ works that way iff
αϕ = 1 + αβ
Show that if solutions ϕ to the latter equation exist, then α is surjective (and one
can take ϕ = σ + β, where σ is any chosen section of α). But note that in most
practical examples, dimA > dimB, so that no surjective α can exist.
♦
The preceding exercise raises the question of calculating the possible reﬂexivity
structures on subgraphs of a given nonreﬂexive graph A
P
π

ψ

. Thus, we consider

188
Models of Additional Variation
homomorphisms
where σρ = 1V = τρ,
πh P = h Aσ,
ψh P = h Aτ.
Exercise 10.61
Show how to consider the diagram above as q∗(Y)
h  X, where X is the given
A
P
π

ψ

and where q is the inclusion functor between ﬁnite categories
where 1 is a category with seven maps all told, the bottom object is in two
ways a retract of the top object, and the endomorphisms of the top are isomorphic
to 1.
♦
Exercise 10.62
For every X as above there is a well-deﬁned reﬂexive graph (right 1-set) q∗(X)
such that for every Y there is a bijection
q∗Y
 X
Y
 q∗X
between (nonreﬂexive) graph maps above the bar and 1-maps (i.e., graph maps
preserving given reﬂexivities) below the bar. In particular, each way of choosing
a reﬂexivity structure Y on a part of X can be indicated by factoring across the
canonical q∗q∗X
 X.
♦
Returning to the linear construction discussed in Exercises 10.51 through 10.59,
we point out that it also is a functor. That is, we can consider diagrams
A
β
 B
A′
β′  B′
of linear maps as concrete structures of a certain abstract kind (see Exercise 10.63).

10.6 To and from Idempotents
189
Exercise 10.63
Deﬁne morphisms between such structures in order to obtain a reasonable cate-
gory D of feedback-command data.
Hint: A morphism should consist of a pair of linear maps satisfying two commu-
tativity equations.
♦
Exercise 10.64
Show that there is a functor F from D to the category Aff↓↓of nonreﬂexive afﬁne
graphs such that
F(A
β
 B)
α

= A
A × B
ψ

πA

with ψ(a, b) = α(b) −a as before.
♦
Exercise 10.65
Given any diagram X of shape A
β
 B
α

in any category, consider the diagram
B(X) of the same shape
B
1B
 B
βα

Show that there is a natural map X
=
β  B(X) of such diagrams (one leg of which
is 1B). In the linear case, determine the graph F(B(X)) and explain why the func-
torially induced F(
=
β) “labels” the arrows in the graph F(X).
♦
Exercise 10.66
Linearize and functorize Exercises 10.61 and 10.62.
♦
10.6 To and from Idempotents
Some constructions starting from an arbitrary given map may produce diagrams
involving idempotent maps e = e · e = e2. In most categories idempotents can be
split, giving structures of the abstract shape
E =
•
e


p
 
•
i
	
wherein pi = 1, e = ip. Note that the category 2 = ·
 · has the property that
functors 2
 A to any category A correspond exactly to morphisms in A.

190
Models of Additional Variation
Exercise 10.67
Consider the three functors
2
p

i

e
 E
corresponding to the morphisms of the same names in E. Given any σ in S with
σ 2 = σ, each of p∗(σ), i∗(σ), e∗(σ) = σ is a map in S considered as a left 2-set.
Given any X
f  Y in S considered as a left 2-set M, there are thus six sets
equipped with idempotents that are universal with respect to maps to or from M.
Show that these adjoints give speciﬁcally
p!M = cograph of f
p∗M = kernel pair (equivalence relation) of f
i!M = cokernel pair of f, gluing two copies of Y along X
i∗M = graph of f
all equipped with a natural idempotent, whereas
e!M = cograph of f but with different adjunction map than p!M
e∗M = graph of f but with different adjunction map than i∗M.
Determine also the other two associated canonical adjunction maps.
♦
Exercise 10.68
Splitting the idempotents in a left action of 1 yields a diagram of the form of a
left action of 1,
T
s0

s1
 X
p

with the two s0, s1 having a common retraction p. It is sometimes said that p
“unites the two identical opposites” since the two subobjects s0, s1 united in the
one X are identical (with T ) as mere objects (i.e., upon neglecting the inclusions)
but are often “opposite” in one sense or another. Because the two are subobjects
of the same object, we can intersect them, obtaining the subobject s0 ∩s1 of X.
Since they also have a common domain, we can consider their equalizer k. However,
the presence of p implies that these two constructions give the same result. That is,
the natural map f , which proves inclusion in one direction,

10.7 Additional Exercises
191
exists because s0t = s1t = x implies that x ∈s0 and x ∈s1, but using p we can
also show that for any x in X, if
t0 proves x ∈s0 and t1 proves x ∈s1
then in fact t0 = t1 so that actually x ∈j, thus deﬁning an inverse for f .
♦
10.7 Additional Exercises
Exercise 10.69
In a poset A show that A ≤A′ and A′ ≤A implies A ∼= A′.
Exercise 10.70
From a poset A may be constructed a strict poset As as follows. There is an
equivalence relation R on objects of A deﬁned by ARA′ iff A ≤A′ and A′ ≤A.
As has objects given by the codomain As of the associated partition A
pR  As.
There is an arrow B ≤B′ in As iff there are A ≤A′ in A such that pR(A) = B and
pR(A′) = B′.
(a) Show that As is a strict poset and that pR is a functor (order-preserving).
(b) Show that As satisﬁes a universal property: If A
F  B is a functor to a strict
poset B, then there is a unique functor As
F′  B such that F′ pR = F.
Exercise 10.71
Show that S/X is the same as the category of left X-sets, where X is viewed as a
category with no nonidentity arrows. Compare Exercise 10.28.
Exercise 10.72
Show that the category SA has ﬁnite limits and colimits. These are all computed
“pointwise”. For example, if 
 and  are left A-sets, then their product in SA is a
left A-set 
 ×  with (
 × )(A) = 
(A) × (A).
Exercise 10.73
Show that the category SA has a natural number object.
Hint: All of the A-actions in that object are identity.
Exercise 10.74
Show that the category SA has a truth value object . This is a generalization of
Exercise 6.15.

192
Models of Additional Variation
Hint: As a functor  : A
 S, the value of  at X in A is given by the set of
“subfunctors” of the representable functor GA(X).
Exercise 10.75
Show that the category SA has mapping sets.
Hint: If 
 and  are left A-sets, then the functor 
 : A
 S has value at X
given by the set of natural transformations from 
 × GA(X) to . Write the precise
formula for the A-action on the latter sets.

Appendix A
Logic as the Algebra of Parts
A.0 Why Study Logic?
The term “logic” has always had two meanings – a broader one and a narrower one:
(1) All the general laws about the movement of human thinking should ultimately
be made explicit so that thinking can be a reliable instrument, but
(2) already Aristotle realized that one must start on that vast program with a more
sharply deﬁned subcase.
The achievements of this subprogram include the recognition of the necessity of
making explicit
(a) a limited universe of discourse, as well as
(b) the correspondence assigning, to each adjective that is meaningful over a whole
universe, the part of that universe where the adjective applies. This correspon-
dence necessarily involves
(c) an attendant homomorphic relation between connectives (like and and or) that
apply to the adjectives and corresponding operations (like intersection and
union) that apply to the parts “named” by the adjectives.
When thinking is temporarily limited to only one universe, the universe as such
need not be mentioned; however, thinking actually involves relationships between
several universes. For example, the three universes (1) of differential equations,
(2) of functions of time, and (3) of formal power series are all distinct with differ-
ent classes of adjectives meaningful over each one. But there are key relationships
between these three universes that are the everyday preoccupation of users of many
mathematical sciences: a function might satisfy a differential equation, a power
series might approximate a function or might formally satisfy a differential equa-
tion, whereas we might seek to solve a differential equation or expand a function,
and so on. Each suitable passage from one universe of discourse to another induces
193

194
Logic as the Algebra of Parts
(0) an operation of substitution in the inverse direction, applying to the adjectives
meaningful over the second universe and yielding new adjectives meaningful
over the ﬁrst universe.
The same passage also induces two operations in the forward direction:
(1) one operation corresponds to the idea of the direct image of a part but is called
“existential quantiﬁcation” as it applies to the adjectives that name the parts;
(2) the other forward operation is called “universal quantiﬁcation” on the adjectives
and corresponds to a different geometrical operation on the parts of the ﬁrst
universe.
It is the study of the resulting algebra of parts of a universe of discourse and
of these three transformations of parts between universes that we sometimes call
“logic in the narrow sense”. Presentations of algebraic structures for the purpose
of calculation are always needed, but it is a serious mistake to confuse the arbitrary
formulations of such presentations with the objective structure itself or to arbitrarily
enshrineonechoiceofpresentationasthenotionoflogicaltheory,therebyobscuring
even the existence of the invariant mathematical content. In the long run it is best
to try to bring the form of the subjective presentation paradigm as much as possible
into harmony with the objective content of the objects to be presented; with the
help of the categorical method we will be able to approach that goal.
How much logic is actually relevant to the practice of a mathematical science is
a question we can only scientiﬁcally answer after learning a signiﬁcant fragment
of this logic. Some use of logic is essential in clarifying the successive states of
our calculations in the everyday algebra of ordinary variable quantities. In this
appendix we will become familiar with some instructive examples of such use after
making explicit the main features of this logical algebra, both objectively in terms
of parts of universes of discourse as well as subjectively in terms of the syntax and
symbolism commonly used to present the logical algebra that organizes the naming
of these parts. As is customary, we begin with the propositional logic of a single
universe of discourse and then proceed to the predicate logic where that universe
is varied; the variation of universes introduces new features even in those cases in
which it only involves passing from a given universe to a universe of ordered pairs
or ordered triples.
Note: In the foregoing preliminary remarks we have used the term “adjective,”
whereas in the remaining text of this appendix we refer usually to “statements”; the
link between the two is expressed by the traditional term “predicate” as follows:
Over a given universe of discourse (such as functions) an adjective (or more gener-
ally an adjectival phrase) such as “positive” corresponds to a predicate or statement
form such as “is positive,” which can in turn become many particular statements

A.1 Basic Operators and Their Rules of Inference
195
such as
1 + x2 is positive
ex is positive
and so on; each thing or family of things (in the universe of discourse) for which
the resulting statement is true belongs to the part of the universe (e.g., the positive
functions) the adjective speciﬁes.
Historical Note
It is sometimes objected that logic is allegedly not algebra since – for example –
nobody thinks in cylindric algebra. That is an unfortunate misunderstanding: cylin-
dric algebras (and polyadic algebras) were an important initial attempt in the 1950s
to make explicit the objective algebra brieﬂy described above; however, they were
excessively inﬂuenced by the styles of subjective presentation (of logical content)
that had become traditional since the 1930s under the name of “ﬁrst order predicate
calculus” or the like. Those styles of presentation involved various arbitrary choices
(such as the speciﬁcation of a single inﬁnite list of variables) that proved to be quite
bizarre when confronted with ordinary mathematical practice; surely the logic of
mathematics is not cylindric algebra. For about a hundred years now, mathemat-
ical scientists have indeed had an intuitive distrust of attempts by some logicians
to interfere with mathematics. However, some explicit recognition of the role of
logical algebra is helpful and even necessary for the smooth and correct learning,
development, and use of mathematics, including even the high school algebra of
ordinary quantities.
A.1 Basic Operators and Their Rules of Inference
Although the basic statements of mathematics are equations, many of the state-
ments of interest have a somewhat more complicated structure; often this more
complicated structure is expressed in the words that surround the equations, but
in order to bring this structure into sharper relief it is useful to introduce a few
“logical” symbols beyond just = (equals). These are
∃, ∧, ∨, true, false (positive)
∀, ⇒
(negative)
used as operations to build up more complicated statements from simpler ones
(usually starting from equations as the “simplest,” although of course equations
themselves can be complicated) and the symbol ⊢, which expresses that one state-
ment follows from another. (The reason for distinguishing the negative or higher

196
Logic as the Algebra of Parts
operators from the positive ones is mentioned in Exercise A.16.) Thus if A, B are
statements, then
A ∧B
is the statement whose truth would mean that A is true and B is true, whereas
A ∨B
is the statement whose truth would mean roughly that at least one of A or B is true;
thus, ∧, ∨are read simply “and,” “or”. If we express by
C ⊢D
the relation that “D follows from C” (often called “C entails D”), then the essential
rules of inference that govern the use of ∧are as follows:
If C ⊢D1 and if C ⊢D2, then
C ⊢D1 ∧D2
and conversely, if C ⊢D1 ∧D2, then both
C ⊢D1
and
C ⊢D2
This can be expressed more brieﬂy as
C ⊢D1 ∧D2
iff
C ⊢D1, C ⊢D2
or still more brieﬂy as
C ⊢D1 ∧D2
C ⊢D1,
C ⊢D2
where the horizontal bar means “iff” in this context, i.e. if we know of three state-
ments C, D1, D2 that they satisfy the deducibility (or “following from”) relation
above the line, then we can conclude that they satisfy the deducibility relations
below the line, and conversely. Since
C ⊢C
holds for any statement, we can conclude, taking the special case where C is
D1 ∧D2, that
D1 ∧D2 ⊢D1
D1 ∧D2 ⊢D2
for any two statements D1, D2, and that in turn implies the “top to bottom” half of
the basic rule of inference above for ∧if we use the fact that “following from” is
transitive:
Whenever C ⊢E, E ⊢D, then also C ⊢D.

A.1 Basic Operators and Their Rules of Inference
197
To analyze the “bottom to top” half of the basic two-way rule of inference for ∧
similarly, note that
(a) (when we take the case in which D1, D2 are both C),
C ⊢C ∧C
for any C, and also that
(b) (exercise!) whenever C1 ⊢D1, C2 ⊢D2 it follows that
C1 ∧C2 ⊢D1 ∧D2
Taking the case of (b), where C1, C2 are both C, and applying the transitivity
of ⊢to that together with (a), we obtain that
whenever
C ⊢D1, C ⊢D2,
then also
C ⊢D1 ∧D2
Since we already understood what ∧means, the detailed analysis above of its
characterization in terms of ⊢may seem pedantic; however, it is necessary to grasp
every detail of it because we will apply exactly the same pattern of analysis to many
other concepts that will not be quite so obvious.
The statement “true” is roughly like the quantity 1. It is characterized by the fact
that
C ⊢true
holds for any statement C.
Exercise A.1
The statements
C ⊢C ∧true
C ∧true ⊢C
hold for any C.
♦
We often write C ≡C ∧true. Here A ≡B (read “A is equivalent” to B) means,
as in this case, that entailment ⊢holds in both directions.
To say that a statement D is true means that it follows from true:
true ⊢D
Exercise A.2
Whenever
true ⊢D1
true ⊢D2
then
true ⊢D1 ∧D2
♦

198
Logic as the Algebra of Parts
The relation of “false” to ⊢is essentially opposed to that of “true”. That is,
false ⊢D
holds for any statement D, and
C ⊢false
means that C is false; for example 0 = 1 ⊢false holds in any nondegenerate ring.
The basic rule of inference for ∨is opposite to that for ∧:
C1 ∨C2 ⊢D
C1 ⊢D,
C2 ⊢D
Note that the comma below the line still means “and” in the metalanguage even
though what we are describing is “or”.
Exercise A.3
Verify that the above rule of inference is intuitively reasonable; derive from it that
Ci ⊢C1 ∨C2
i = 1, 2
D ∨D ⊢D
holds for any C1, C2, D and also that whenever C1 ⊢D1, C2 ⊢D2,
C1 ∨C2 ⊢D1 ∨D2
then use transitivity and the identity inference to rederive the two-way rule from
these special consequences, i.e. analyze the ∨rule in the “same pattern” by which
we analyzed the ∧rule.
♦
Exercise A.4
(false ∨C) ≡C, for all C
♦
The operation ⇒applied to a pair of statements B, D gives another statement
B ⇒D, which is usually read “B implies D” or “if B then D”. (It is to be disting-
uished from B ⊢D, which is a statement about statements usually written down
only when we mean to assert that D in fact follows from B, whereas B ⇒D is a
statement which, like other statements, may be important to consider even when it
is only partly true.) The rule of inference characterizing ⇒is not only in terms of
⊢, but also involves ∧:
C ⊢(B ⇒D)
C ∧B ⊢D
(This is sometimes called “modus ponens and the deduction theorem” by logicians.)
That is, if we know that D follows from C ∧B, then we can conclude that B ⇒D

A.1 Basic Operators and Their Rules of Inference
199
follows from C alone (and also that C ⇒D follows from B alone since C ∧B ≡
B ∧C); conversely, if we know that B ⇒D follows from C, then we can conclude
that D alone follows from the composite hypothesis C ∧B. In particular, since
(true ∧B) ≡B,
true ⊢B ⇒D
B ⊢D
holds for any two statements B, D; this motivates the frequent abuse of notation
whereby we often write ⇒when we mean ⊢. This is an abuse that causes no major
problems when no more than one implication is involved, but (for example) when
we assert
(B ⇒D) ⊢E
we are not asserting that E is necessarily true but only that it follows whenever
B ⇒D is true, which in turn means . . . . But in particular the preceding discussion
indicates the basic strategy for proving the truth of statements of the form B ⇒D,
namely, we temporarily assume that B is true and then try to show that D follows;
if we succeed, then we have proven the truth of B ⇒D with no assumptions, for
that is what B ⇒D means.
The ⇒operator has many properties:
Exercise A.5
true
⊢
(B ⇒B)
for all B
B ∧(B ⇒D)
⊢
D
for all B, D
(A ⇒B) ∧(B ⇒C)
⊢
(A ⇒C)
for all A, B, C
if B1 ⊢B2 then (A ⇒B1) ⊢(A ⇒B2)
for all A
if A2 ⊢A1 then (A1 ⇒B) ⊢(A2 ⇒B)
for all B
((C ∧B) ⇒D) ≡(C ⇒(B ⇒D))
for all C, B, D
B ⇒(D1 ∧D2) ≡(B ⇒D1) ∧(B ⇒D2)
for all B, D1, D2
(B1 ∨B2) ⇒D ≡(B1 ⇒D) ∧(B2 ⇒D)
for all B1, B2, D
( true ⇒D) ≡
D
( false ⇒D) ≡true
(D ⇒true ) ≡true
♦
The expressions above are all to be proved using the basic rules of inference
for ⇒. The presence of the operator ⇒satisfying its rule of inference enables us to
prove an important “distributivity” between “and” and “or” that does not explicitly
mention ⇒but which cannot be proved without it:
A ∧(B1 ∨B2) ≡(A ∧B1) ∨(A ∧B2)

200
Logic as the Algebra of Parts
Recall that the equivalence “≡” is a metastatement (statement about statements)
whose assertion means that in fact ⊢holds in both directions; using ⇒we can
deﬁne an analog among statements themselves:
B ⇐⇒D
is an abbreviation that stands for the compound statement
(B ⇒D) ∧(D ⇒B)
Often B ⇐⇒D is read “B iff D,” and the strategy for proving its truth has two parts:
ﬁrst temporarily assume B and deduce D; then forget that, temporarily assume
D, and try to prove B (this second part is called “proving the converse” since,
independently of their truth, D ⇒B is called the converse of B ⇒D); only if we
succeed in proving both of these do we have a right to assert the ⇐⇒statement,
i.e. only then have we proved B ⇐⇒D to be true.
The reader may have noted the absence, in the exercise listing various properties
of ⇒, of any simple equivalence for statements of the form (B ⇒false). That is
because the abbreviation
¬B ≡(B ⇒false)
deﬁnes another important logical operation read “not B” roughly speaking because
the statement denying B is essentially the statement that assuming B would lead
to a contradiction. From the basic rules of inference we can prove the following
properties of ¬:
Exercise A.6
(B ∧¬B) ≡
false
if (B ∧C) ≡false then C ⊢¬B
¬(B1 ∨B2) ≡(¬B1) ∧(¬B2)
(B ⇒¬D) ≡¬(B ∧D)
B
⊢
¬¬B
false
≡¬ true
true
≡¬ false
♦
Exercise A.7
If we suppose (B ∨¬B) ≡true for all B (this “law of the excluded middle” is not
valid in all systems of statements of interest in mathematical analysis), then we
further have
¬¬B ⊢B
¬(B1 ∧B2) ≡(¬B1) ∨(¬B2) (de Morgan’s law)

A.1 Basic Operators and Their Rules of Inference
201
Of course, if B is an equation x = y, then we usually write
¬B ≡x ̸= y
♦
Remark A.8: It is often useful to introduce another logical operation B\A called
“logical subtraction” and read “B but not A” characterized by a rule of inference
dual to that for implication
B\A ⊢C
B ⊢A ∨C
Exercise A.9
Logical subtraction satisﬁes a whole list of properties roughly opposite to those
satisﬁed by ⇒. In case the law of excluded middle holds, we could deﬁne logical
subtraction as (B\A) ≡B ∧(A ⇒false). However, in general \ may exist when ⇒
is impossible and in other cases ⇒may exist but \ is impossible. In terms of \ we
can deﬁne a different negation operator A′ = (true \A), but even when both oper-
ations ( )′, ¬( ) are present A′ may be different from ¬A. (Example: the A’s, B’s,
etc., denote real numbers between 0, 1, and ⊢denotes ≤of real numbers.)
♦
Exercise A.10
If we deﬁne
∂A ≡A ∧A′
(read“boundaryof A”)inasystemwhere\ispresent,thenfromtheruleofinference
follows
∂(A ∧B) ≡((∂A) ∧B) ∨(A ∧∂B)
a boundary formula of topology that is important for the boundary-value problems
of analysis and physics (note the similarity with the Leibniz rule for differentiation
of quantities).
♦
To specify the role of the existential quantiﬁer ∃and the universal quantiﬁer ∀it
is necessary to be more speciﬁc about the kinds of statements we are considering.
Consider two universes X, Y of things (points, bodies, quantities, etc.) being talked
about and a mapping f between them:
X
f  Y
Assume that there are two systems of statements both having some or all of the
logical operations previously discussed; one system refers to the things in X, the
other to the things in Y. Thus,
A ⊢X C

202
Logic as the Algebra of Parts
means that both A, C refer to the things in X and that whenever A is true of
something in X, then C is also true of the same thing; this is frequently symbolized
by the use of a variable x to denote the things in X, and A(x) signiﬁes that x satisﬁes
the statement A. Then
A(x) ⊢x C(x)
means the same as
A ⊢X C
i.e., any x in X that satisﬁes A also satisﬁes C. Similarly,
B ⊢Y D
means the same sort of relation between statements about the things in Y. Now the
role of the given mapping f is this: it associates to every thing x in X a speciﬁc thing
f x in Y. Hence, to any statement B about the things in Y there is a corresponding
statement B f about things in X
(B f )(x) = B( f (x))
by deﬁnition. This process is often called “substitution” or “inverse image” along f .
For example, if f (x) = x2 and B(y) ≡(y −1 = 10), then (B f )(x) ≡(x2 −1 =
10), whereas if D(y) ≡(y + 1 = 0), then (Df )(x) ≡(x2 + 1 = 0). It is easy to
see that
if B ⊢Y D
then B f ⊢X Df
for any statements B, D about things in Y. Thus, the process of substitution of f into
statements goes “backwards” relative to f , i.e., it takes statements on the codomain
Y of f back to statements on the domain X of f , and moreover it “preserves
entailment ⊢,” i.e. maps statements in fact related by ⊢Y to statements related
by ⊢X.
Both operations ∀f and ∃f by contrast are “covariant,” meaning that they go in
the same direction as f . Thus, in many situations, for any admissible statement A
on X, the statement ∃f A will be an admissible statement on Y, where ∃f is related
to substitution along f by the following rule of inference
∃f A ⊢Y B
A ⊢X B f
for any admissible statement B on Y, or using the “variable” notation,
(∃f A)(y) ⊢B(y)
for any y in Y
iff
A(x) ⊢B( f (x))
for any x in X

A.1 Basic Operators and Their Rules of Inference
203
This rule of inference is precisely the rule for carrying out calculations on the basis
of the meaning of ∃f A, which is
(∃f A)(y) ≡





“there exists something x in X
that satisﬁes A(x) and
goes to y under f : f (x) = y”
and is clearly a statement about y’s rather than x’s. For (going from below the line
to above) if A, B are related by A(x) ⊢X B( f (x)) for all x, then to infer B(y) for
a given y, it sufﬁces to know that we can ﬁnd some x for which y = f (x) and for
which A(x) holds; (going down) if conversely the existential statement entails B
on Y for all y, then the entailment below the line must hold for all x.
The expression ∃f A names the image of A along f , denoted f (A).
Exercise A.11
If A1 ⊢X A2 then ∃f A1 ⊢Y ∃f A2
∃f falseX ≡Y
falseY
∃f (A1 ∨A2) ≡Y (∃f A1) ∨(∃f A2)
A ⊢X (∃f A) f
∃f (B f ) ⊢Y B
♦
Similarly, the universal quantiﬁcation ∀f along f is characterized by its relation to
substitution along f , which is the rule of inference
B ⊢Y ∀f A
B f ⊢X A
for all statements A on X and B on Y. This rule governs the calculations appropriate
to the meaning
(∀f A)(y) ≡“for all things x in X for which f x = y, A(x) holds”
Exercise A.12
Formulate and prove the basic properties of ∀f that are dual to those stated in
Exercise A.11 for ∃f .
♦
We now give three basic examples of mappings f along which quantiﬁcation is
often performed. First, suppose Y = 1 is a universe with only one thing but X is
arbitrary. Then only one mapping f
X
 1

204
Logic as the Algebra of Parts
is possible. In the category of abstract, constant sets (which one usually refers to
as “the” category of sets), 1 has only two subsets, so that up to equivalence there
are only two statements on 1, “true” and “false”. Their inverse images under the
unique f are trueX and falseX, but on X there are in general many more statements
A(x) possible (except if X is the empty universe, in which case trueX = falseX). A
general A really depends on x in the sense that A(x0) may hold for one thing x0 in
X, and A(x1) may not hold for another thing x1 in X. But ∃f A no longer depends
on anything; it is either absolutely true (in case A(x) holds for at least one x) or
absolutely false (in case A(x) fails for all x); in other words
∃f A ≡1 true1, A ̸≡falseX
∃f A ≡1 false1, A ≡falseX
Foramoregeneralandtypicalexample,supposeY isanarbitraryset(or“universe
of things”) but that we have another set T and deﬁne X to be the cartesian product
T × Y. Then, a simple choice of f is the projection map
where we recall that everything x in X is uniquely expressible in the form x = ⟨t, y⟩,
where t is in T and y is in Y. Now if we consider any admissible statement B on
Y, we have
(B f )(t, y) ≡B(y)
i.e. B f is the “same” statement as B but is now considered to depend (vacuously)
on the additional variable t. On the other hand, a typical statement A on X really de-
pends on both t and y (and for that reason is often called a “relation” between T and
Y), but its existential quantiﬁcation along the projection f no longer depends on t:
(∃f A)(y) ⊢Y B(y)
A(t, y) ⊢T ×Y B(y)
Usually, a notation for f is chosen emphasizing what it forgets (namely t) rather
than the rest of x (namely y) that it retains; this is because, when given y, the
existence of an x that maps to it by the projection is equivalent to the existence of
a t such that the pair ⟨t, y⟩has the required property, since x for which f (x) = y

A.1 Basic Operators and Their Rules of Inference
205
is uniquely of that form x = ⟨t, y⟩for a t uniquely determined by x (of course t is
not uniquely determined by y, except for special A). Thus, traditionally one writes
∃t A ≡∃f A
for f the projection on a cartesian product that leaves out t, and A a statement on
that product, or (slightly confusingly) with all variables displayed
∃t A(t, y) ≡Y (∃f A)(y)
where f (t, y) = y. The left-hand side depends on y but not on t; one says that the
operator ∃t “binds” the variable t just as a deﬁnite integral
 1
0 f (t)dt is merely a
number, not a function of t. Similarly
∀t A(t, y) ≡Y (∀f A)(y)
where f is the projection f (t, y) = y and A is a statement on the entire cartesian
product X = T × Y since to say that all x for which f x = y have property A
(y being given) is in this special case the same as to say that all t, when paired with
y, satisfy the relation A(t, y) owing to the nature of f .
Our ﬁrst example is a special case of this second one, since if Y = 1 then
X = T × Y = T . A further important subcase of this second example is as fol-
lows: suppose Y = T 2 = T × T ; then X = T × Y = T × T 2 = T 3, and the same
projection f is now
f (t1, t2, t3) = ⟨t1, t2⟩
The statements B on Y are binary relations on T , whereas the statements A on X
are ternary relations on T . Quantifying along this f (either ∀or ∃) a ternary relation
gives a binary relation. As an example of how this is used in expressing properties
of particular binary relations B on T (i.e., statements on T 2), let us consider a
particular one we will denote by ≤:
t1 ≤t2 ≡T ×T B(t1, t2)
The notation suggests that we might want to consider whether B is “transitive”, a
condition usually written as
t1 ≤t2 ∧t2 ≤t3 ⇒t1 ≤t3
As mentioned before, we do not really need the complication of the ⇒operator
to assert something as simple as this; the ⊢relation on statements is good enough,
but which ⊢? Clearly, it must be the ⊢3 between statements on X = T 3 since
the left-hand side of the implication involves three variables, but then what is the

206
Logic as the Algebra of Parts
meaning of the two sides when all we were given concretely to speak about was the
binary relation B, that is, a certain statement on Y = T 2? There are three different
tautological f ’s that enter essentially into the construction even if we do not always
explicitly mention them,
X = T 3
 T 2 = Y
namely, we deﬁne
π3(t1, t2, t3) = ⟨t1, t2⟩
π1(t1, t2, t3) = ⟨t2, t3⟩
π2(t1, t2, t3) = ⟨t1, t3⟩
following the custom to name the projection for what it leaves out.Then with B
denoting the given ≤relation on T 2,
(Bπ3)(t1, t2, t3) ≡t1 ≤t2
(Bπ1)(t1, t2, t3) ≡t2 ≤t3
are both statements on X = T 3 so that the ∧operator for such statements can be
applied by forming
(Bπ3 ∧Bπ1)(t1, t2, t3) ≡(t1 ≤t2) ∧(t2 ≤t3)
and the result compared with the other Bπ2. The expression
Bπ3 ∧Bπ1 ⊢3 Bπ2
is then the entailment relation signifying that B on T 2 is transitive. But now noting
that Bπ2 is actually independent of the middle variable t2, we can (by the rule of
inference for ∃) existentially quantify to get an entailment on T 2,
∃π2(Bπ3 ∧Bπ1) ⊢2 B
which equally well expresses the same property of B; or in variable notation,
∃r[t ≤r ∧r ≤s] ⊢2 t ≤s
That is, to prove t ≤s by use of transitivity is independent of any speciﬁc r between
them, it is sufﬁcient to know that “there exists” one.

A.1 Basic Operators and Their Rules of Inference
207
Bothofthe precedingforms of thetransitivityconditionon B areusedineveryday
reasoning; it is essential to know that they are equivalent. However, one could say
crudely (and a similar comment can be made about each of the logical operators):
although the determining rule of inference says that the operator is “not needed”
when it occurs on one side of the ⊢, once the operator is determined it can also occur
on the other side of the ⊢; there it usually is essential and cannot be eliminated. For
example, we could express C ⊢D1 ∧D2 without ∧just by listing C ⊢D1, C ⊢D2,
but A ∧B ⊢C expresses (except in trivial cases) that A, B must be jointly assumed
to deduce C; of course in that situation we can “eliminate” the ∧in favor of
the ⇒, A ⊢(B ⇒C), but we can in general go further: i.e. having introduced ⇒,
we have to admit the possibility of conditions like (B ⇒C) ⊢D, but there is no way
in general to eliminate this occurrence of ⇒. Similarly C1 ∨C2 ⊢D is equivalent
to listing Ci ⊢D, but a condition like C ⊢D1 ∨D2 cannot be expressed in general
in terms of simpler operators. For example, the condition that a transitive binary
relation ≤be a linear order
trueT 2 ⊢T 2 [t1 ≤t2 ∨t2 ≤t1]
which is just
true ⊢2 B ∨Bσ
σ(t1, t2) = ⟨t2, t1⟩
in the notation used above, cannot be expressed in terms of equations or simple
logical operations such as ∧but requires the use of ∨. Now a similar remark
involving ∃concerns the statement that a transitive relation be “dense”. If we
consider a transitive binary relation
t < s ≡D(t, s)
(using different symbols to distinguish from B) it is said to be dense if (in variables)
t < s ⊢∃r[t < r ∧r < s]
i.e., (roughly speaking) if more things can always be found between given things
(relative to D). Without variables, this says
D ⊢2 ∃π2[Dπ3 ∧Dπ1]
For example, this property holds in the universe of real numbers but not in the
universe of whole numbers with the usual interpretation of D. So long as we
consider only the “structure” T, D by itself, and hence only statements that can be
built up logically from D, there is no way to eliminate the ∃(since it occurs on
the right hand side of ⊢). The example of real numbers shows, however, that if we
have at our disposal additional structure, in particular if we can make statements of

208
Logic as the Algebra of Parts
the type
F(r, t, s) ≡r = t + s
2
we can (using equational axioms, etc., about F) prove outright that if t < s, then
t < t + s
2
∧t + s
2
< s
from which the ∃r . . . could be deduced since we already have something more
explicit.
As a third example, we will consider the case in which X
f  Y is the “diagonal”
mapping
X
  X × X
deﬁned by
(x) = ⟨x, x⟩
Then, for any binary relation B on X (statement on X2)
(B)(x) ≡B(x, x)
deﬁnes a unary relation (statement on X). Special interest attaches to
E ≡∃( trueX)
the binary relation on X obtained by existentially quantifying the trivially true unary
relation along the diagonal map. By the rule of inference for ∃,
E ⊢2 B
trueX ⊢1 B
or in terms of variables,
E(x1, x2) ⊢B(x1, x2)
holds if and only if B is a binary relation whose diagonalization is outright true,
that is,
trueX ⊢B(x, x)
To obtain a class of B with that property, consider any (unary) statement A on X
and consider
B(x1, x2) def
= (A(x1) ⇒A(x2))
i.e. B ≡(Ap1 ⇒Ap2), where pi(x1, x2) = xi
i = 1, 2 ;
then
(B)(x) ≡(A(x) ⇒A(x))

A.1 Basic Operators and Their Rules of Inference
209
which is identically true since any statement truly implies itself. Hence, by the
preceding fragment of the rule of inference for ∃,
E ⊢B
proving
E(x1, x2) ⊢(A(x1) ⇒A(x2))
for any A
which is the usual rule of inference for equality E,
x1 = x2
def
≡E(x1, x2)
the rule being often called the rule of substitution for equality. Using equality E,
we can make explicit the usual distinction between our B and D by
E ⊢2 B
E ∧D ⊢2 falseT 2
which express that B is reﬂexive whereas D is antireﬂexive (stronger than merely
being nonreﬂexive). Although antireﬂexivity is thus expressed using only ∧and
false, we could introduce the somewhat more complicated operator ⇒if we wished
by quoting its rule of inference, yielding
D ⊢(E ⇒false)
By the deﬁnition of “not,” we see that (when we can use the operator ⇒) antire-
ﬂexivity of D is equivalent to
D ⊢¬E
or with variables
t1 < t2 ⊢t1 ̸= t2
or if one prefers (since we used ⇒anyway)
true ⊢t1 < t2 ⇒t1 ̸= t2
Finally, since one usually treats the “true ⊢” as understood when asserting
something,
t1 < t2 ⇒t1 ̸= t2
An extremely important use of the equality relation E is in the deﬁnition of the
unique existential quantiﬁer that establishes a link between the general relations
expressed by “statements,” as discussed above on the one hand and the well-deﬁned
“operations”ofalgebraandanalysisontheotherhand.First,weconsideruniqueness
(without commitment about existence). If A is any statement on T , we want to ex-
press the idea that at most one thing in T satisﬁes A. This would mean that whenever

210
Logic as the Algebra of Parts
t1, t2 both have the property expressed by A, then in fact t1, t2 denote the same thing
(the traditional example is A(t) ≡“t is the king of France at a given time”); in other
words,
A(t1) ∧A(t2) ⊢t1 = t2
where the entailment ⊢is obviously supposed to be on T × T . It is important to
allow additional variables, so we generalize this to
A(t1, y) ∧A(t2, y) ⊢T 2×Y t1 = t2
where the right-hand side must mean Eπ, when the map T 2 × Y
π  Y is the
obvious projection, and the left-hand side is Aπ1 ∧Aπ2 where the maps
T 2 × Y
π1

π2
 T × Y
are again obvious once we recognize that there are two of them. Finally, it is very
important to be able to consider this uniqueness property of A independently of
whether we know it is true, so we use ⇒instead of ⊢to deﬁne a new statement,
“uniqueness in T of A,”
UnT A ≡∀π[Aπ2 ∧Aπ1 ⇒Eπ]
which is a statement on Y whenever A is a statement on T × Y. With variables,
(UnT A)(y) ≡∀t1, t2[A(t1, y) ∧A(t2, y) ⇒t1 = t2]
For example A(t, y) might have the meaning “t is a solution of a certain differential
equation with initial value y”. Then, to prove UnT A for y would mean that any
two solutions of the equation having initial value y are equal (as functions); this is
a separate issue from that of whether there are any solutions starting from y, and
both are independent (unless we know more about the differential equation) from
the issue of whether existence or uniqueness holds for some other y.
Exercise A.13
Let T = IR = Y, i.e. both universes are the set of all real numbers. Consider the
relation
A(t, y) ≡[y = t(t −1)]
Then
⊢(UnT A)(y) ⇐⇒y ≤−1
4
For example,
(UnT A)(0) ⊢false
(Draw graph.)
♦

A.1 Basic Operators and Their Rules of Inference
211
We have already discussed
(∃T A)(y) ≡∃t A(t, y)
and so we can deﬁne
∃!T A ≡∃T A ∧UnT A
a statement on Y, for any statement A on T × Y, written in variables
∃!t A(t, y) ≡∃t[A(t, y)] ∧∀t1, t2[A(t1) ∧A(t2) ⇒t1 = t2]
and read “there exists a unique t for which A(t, y)”.
Exercise A.14
With the notation of the previous exercise,
⊢(∃T A)(y) ⇐⇒y ≥−1
4
and
⊢(∃!T A)(y) ⇐⇒y = −1
4
(Refer to the graph of the function deﬁned in the previous exercise.)
♦
Now if Y
g  T is any given mapping, we can deﬁne a statement G on T × Y
(often called the “graph” of g) by
G(t, y) ≡[t = g(y)]
Then it will be true (as a statement on 1) that
∀y∃!tG(t, y)
Conversely, (by the very meaning of “arbitrary” mapping) if we have any statement
G on T × Y for which the above ∀∃! statement on 1 is true, there will be a mapping
Y
g  T whose graph is G. What will be its value at any given thing y in Y? It
will be “the” t (justiﬁed by the ! clause) for which G(t, y) (which exists by the ∃
clause in the ∃!).

212
Logic as the Algebra of Parts
Exercise A.15
If G is a statement on T × Y and H is a statement on X × T , then their composition
is deﬁned to be the statement X × Y expressed by
∃t[H(x, t) ∧G(t, y)]
This is actually ∃π[Hπ ∧Gπ], where each of the three π’s are different mappings
with domain X × T × Y. A binary relation on T is transitive if and only if it follows
from its composition with itself. If G, H are graphs of mappings Y
 T, T
 X,
then their composition is the graph of a mapping Y
 X.
♦
Exercise A.16
The condition that G be the graph of a mapping can be expressed without
using ∀, ⇒by using instead ∃, ∧. In fact, we can use ∃, ∧in the simple com-
bination known as composition; namely, consider the transpose relation G∗of G
deﬁned by
G∗(y, t) ≡G(t, y)
and consider ET , EY the equality relations on T and Y, respectively; then
G is the graph of a mapping only if the two entailments
EY ⊢Y 2 G∗◦G
G ◦G∗⊢T 2 ET
hold
where the small circle denotes composition. (In fact if for a given G there is any
relation G∗that satisﬁes these two entailments, then G∗must be the transpose of
G, as deﬁned above, and hence G is the graph of a mapping.) This reformula-
tion is important since ∃, ∧(which go into the deﬁnition of ◦) are stable under
many more geometrical transformations used in analysis than are ∀, ⇒(which
go into the deﬁnition of !). Moreover this latter kind of relation (expressed in the
box) between “relations” and “mappings” will persist in situations in which the
values of G(t, y) are much richer mathematical objects than just “yes” and “no”
answers.
♦
A.2 Fields, Nilpotents, Idempotents
Examples of Logical Operators in Algebra
The proofs of many of the exercises in this section will be clearer if explicit rules
of inference from the previous section are cited at the appropriate points.

A.2 Fields, Nilpotents, Idempotents
213
The most basic properties of algebraic structures such as rings, linear spaces,
and categories are expressed by equations; for example, the distributive property,
nilpotence, associativity, or the property of being a solution. However, in working
with these equations we must frequently use stronger logical operators, both in
stating stronger axioms on the ground ring in linear algebra and in summarizing
the meaning of our complicated calculations. (It should be remarked, however, that
most of this logic again becomes equational when we pass to a higher realm.) For
example, using the logical symbol ⊢, which can be read “entails,” the additional
axioms stating that a given ring R is a ﬁeld are that R is nondegenerate,
0 = 1 ⊢false
(usually expressed by introducing “not” and saying
true ⊢0 ̸= 1)
and that every nonzero quantity in R has a reciprocal,
x ̸= 0 ⊢∃y[xy = 1]
When the law of excluded middle is valid, the latter is equivalent to the (in general
stronger) condition, involving the logical symbol for “or,”
x = 0 ∨∃y[xy = 1]
being trueR (which has the virtue of being invariant under more geometrical trans-
formations but the drawback, in those cases like continuous functions where the law
of excluded middle is false, of being less likely to be true). Usually, one expresses
this ﬁeld axiom using ∀⇒as
true ⊢∀x[x ̸= 0 ⇒∃y[xy = 1]]
with the understanding that the universe over which both x, y vary is R. Thus
Z = {. . . −3, −2, −1, 0, 1, 2, 3 . . .} is a ring R that is not a ﬁeld since, for example,
5 ̸= 0, but there is no y in Z for which 5y = 1. In any ring we can deduce purely
equationally from the hypotheses
xy1 = 1
xy2 = 1
that y1 = y2 (here is the deduction, using only [commutative] ring axioms and the
hypotheses:
y1 = y11 = y1(xy2) = (y1x)y2 = (xy1)y2 = 1y2 = y2)
Therefore, we can conclude that in any ring, reciprocals are unique, and hence in
any ﬁeld that (using the exclamation point to signify this uniqueness)
∀x[x ̸= 0 ⇒∃!y[xy = 1]]

214
Logic as the Algebra of Parts
Further (since R is nondegenerate if it is a ﬁeld), “the” (just justiﬁed) reciprocal of
x cannot be zero either.
Exercise A.17
If y is a reciprocal of x, then x is a reciprocal of y; if, in any given ring R, 0 has a
reciprocal, then R is degenerate. In case R is a ﬁeld, if we restrict the universe to
the set G of all nonzero elements of R (G is no longer a ring) the slightly simpler
statement
∀x∃!y[xy = 1]
is true over G. Since this is the criterion for the existence of a mapping, there is a
mapping
G ( )−1  G
called the reciprocal mapping whose graph is deﬁned by
x · y = 1
that is, y = x−1 if and only if x · y = 1.
♦
Exercise A.18
A much better way of understanding the last construction is as follows: Let R be
any commutative ring (not necessarily a ﬁeld, maybe even degenerate). Deﬁne G
to be the subset of R consisting of all elements x of R satisfying
∃y[xy = 1]
in R. Then there is a reciprocal mapping G
 G, 1 is in G, and G is closed
under multiplication; i.e., if x1, x2 are in G, then x1x2 is in G since 1−1 = 1, and
(x1x2)−1 = x−1
2 x−1
1 . This means that G is a (commutative) group called “the multi-
plicative group of R”. If 0 is in G, then R is degenerate. For any x in G, −x is also
in G. But x1, x2 in G does not imply x1 + x2 in G. If R = IR, the real numbers,
then 1 + x2 is always in G for any x, and the same is true if R = C(S) = the ring
of all continuous real-valued functions on any continuous domain (“topological
space”) S.
♦
Now the condition that a ring R be a ﬁeld is just that R be the disjoint union of
{0} and G, namely that (reading the ∨form of the deﬁnition backwards and using
the symbol for “not”)
∃!x[¬G(x)]

A.2 Fields, Nilpotents, Idempotents
215
Since any ring R has a special element 1 and since R has an addition operation,
there are elements in R that may as well be denoted
2 = 1 + 1
3 = 1 + 1 + 1
...
(not all of these need be distinct). Even if R is a ﬁeld, not all of these need have
reciprocals; for example, there is an important ﬁeld with only three elements in
all in which 3 = 0. However, a great many rings, even those that are not ﬁelds, do
involve IR in such a way that all of the above do have reciprocals, which can be
denoted as usual by 1
2, 1
3, . . . Thus, 1
2 is in G, 1
3 is in G . . . , where G denotes the
multiplicative group of any such ring R.
Exercise A.19
In any ring having 1
2,
true ⊢∀x∃y[y + y = x]
♦
By a subring of a given ring R is meant a subset S of the elements of R that
contains 0, 1 and is closed under the addition, the subtraction, and the multiplication
of R. Thus, if p is any polynomial with coefﬁcients in Z in several, say three,
variables, and if x, y, z are in S, then p(x, y, z) is also in S.
Exercise A.20
If R is a ring having 1
2 and if S is a subset containing 0, 1 closed under addition and
closed under the unary operations of multiplication by 1
2 and by −1, then S is a
subring if and only if S is closed under the unary operation of squaring. (The answer
is a frequently used formula.)
♦
Now a subring is not necessarily closed under division, even to the extent to
which division is deﬁned in R. Thus, Z ⊂IR is a subring, but Z is not a ﬁeld even
though IR is a ﬁeld. But any subring of any ﬁeld does have a special property not
shared by all rings of interest, namely
xy = 0 ⊢[x = 0 ∨y = 0]
Exercise A.21
Prove the statement just made in any subring of a ﬁeld.
♦

216
Logic as the Algebra of Parts
A nondegenerate ring S having this property for all x, y in S is called an integral
domain. This is intimately related to the cancellation property
∀x1, x2[ax1 = ax2 ⇒x1 = x2]
for an element a, which (using subtraction) is easily proved equivalent to the “non-
zerodivisor” property of a
∀x[ax = 0 ⇒x = 0]
where all universal quantiﬁers range over all x, x1, x2 in the ring in which we are
considering a. We might call a “monomorphic” in that ring. Note that this property
uses the logical operators in an essential way since, when we want to prove
a is monomorphic ⊢something else about a
we cannot always eliminate the ∀, ⇒implicit on the left-hand side. Of course,
if the “something else” is just another instance of the cancellation property, such
proof may present no problem. Now clearly a = 0 can not be monomorphic in a
nondegenerate ring since
ax = 0 · x = 0
for any x, yet we could take x = 1; hence, it would not follow that x = 0. Now the
idea of an integral domain is that (if the law of excluded middle is assumed) the
only a that is not monomorphic in R is a = 0. That is, the validity for all a in R of
any one of
a ̸= 0 ⇒∀x[ax = 0 ⇒x = 0]
∃x[ax = 0 ∧x ̸= 0] ⇒a = 0
∀x[ax = 0 ⇒[a = 0 ∨x = 0]]
is equivalent (using the law of the excluded middle) to the condition that R is
an integral domain. The last form with ∨is the one familiar from high school as
a crucial step in the method of solving polynomial equations by factoring. This
method is used in proving
Theorem A.22: In any integral domain, the equation
x2 = x
has precisely two solutions.
Proof: If x2 = x then x2 −x = 0, and hence x(x −1) = 0 (since x(x −1) = x2 −x
in any ring). Now use the integral domain property to get x = 0 ∨x −1 = 0, i.e.
x = 0 ∨x = 1. We say “precisely two” because the ring is nondegenerate.
■

A.2 Fields, Nilpotents, Idempotents
217
Exercise A.23
In any commutative ring, an element satisfying x2 = x is called idempotent. If x
is an idempotent, then so is its “complement” 1 −x. The product of any two idem-
potents is an idempotent. If x and y are idempotents and if xy = 0 (one says x, y
are “disjoint” or “orthogonal”) then x + y is also an idempotent. One says a ring
“has connected spectrum” if it has precisely two idempotents. In general, the idem-
potents describe chunks of the “spectrum,” for example, of a linear transformation
(which gives rise to a ring).
♦
Very important in engineering calculus [B99], in analyzing linear transfor-
mations, and so on, are the nilpotent elements in commutative rings, where x is
nilpotent if and only if
∃n[xn+1 = 0]
Here the ∃n does not range over the ring we are talking about but rather over the set
0, 1, 2, 3 . . . of natural numbers, which act as exponents on elements of any ring
(or indeed of any system wherein at least multiplication is deﬁned). In more detail,
we could say that x is nilpotent of order 1 if
x2 = 0
while x ̸= 0, that x is nilpotent of order 2 if
x3 = 0
while x2 ̸= 0, and so on. Of course 0 is nilpotent of order zero. In a nondegenerate
ring x = 1 is not nilpotent of any order. Using commutativity, we ﬁnd that the
product of a nilpotent with any element is again nilpotent. Again using commuta-
tivity, we discover that the sum of any two nilpotent elements is nilpotent; however,
the order may increase. For example, if x2 = 0 and y2 = 0, we can calculate that
(x + y)3 = 0; as for (x + y)2, it might be 0, but only in case xy = 0, which is not
always true. Analysis of the calculation leads to the idea that, to be sure of the
nilpotency of a sum, we have to add the orders of nilpotency of the summands:
Theorem A.24: If xn+1 = 0, ym+1 = 0 in a commutative ring, then always
(x + y)n+m+1 = 0
Proof: In any commutative ring the distributive law implies the binomial expansion
(x + y)p =

i+ j=p
Ci jxi y j
for any x, y in the ring and any p in N (note that N ⊂Z and that Z can be used as

218
Logic as the Algebra of Parts
coefﬁcients in any ring – indeed in any system in which addition and subtraction
are deﬁned. In fact
Ci j = (i + j)!
i! j!
is in N despite the denominators, where ! denotes “factorial,” by Pascal). Thus, the
proof of the theorem reduces to the following fact about the elementary arithmetic
of N:
■
Lemma A.25: i + j = n + m + 1
⊢
[i ≥n + 1] ∨[ j ≥m + 1].
Exercise A.26
Prove Lemma A.25.
♦
In any case, since
xn+1 = xn · x
is a product, it is immediately clear that
Theorem A.27: In an integral domain, the only nilpotent element is 0.
An extremely important property (for analysis, linear algebra, computer science,
etc.) is the following, showing that, although the existence of nilpotent elements has
the“negative”consequencesthatsomeelements(theones“near”zero)aredeﬁnitely
not invertible, it also has the “positive” consequence that some other elements
(those “near” 1) deﬁnitely are invertible, and there is even a speciﬁc formula for the
reciprocals.
Theorem A.28: If h is any nilpotent element in a ring, then 1 −h has a reciprocal
in the same ring. In fact if hn+1 = 0, then
1
1 −h =
n

k=0
hk
Proof: Calculate that the right-hand side, multiplied by 1 −h, gives 1.
■
Remark A.29: In a ring furnished with a notion of convergence, Theorem A.28
can often be generalized to some h for which hn merely converges to 0 as n tends
to ∞, i.e. to small h’s not necessarily so small as to be “nilpotent”. But the formula
of the theorem is surprisingly often useful even just for the nilpotent case.

A.2 Fields, Nilpotents, Idempotents
219
Exercise A.30
If u has a reciprocal and h is nilpotent then u ± h has a reciprocal. (A formula, only
slightly more complicated than that of the theorem, can either be deduced from the
theorem as a corollary or calculated and proved directly.)
♦
Exercise A.31
If u1 = 1 −h1, u2 = 1 −h2 are invertible elements of a (commutative) ring of
the form indicated with h1, h2 nilpotent (with orders of nilpotency n1, n2 say),
the product u1u2 is of course invertible; is it again of the special form, namely
“inﬁnitesimally near 1” in the sense that
u1u2 = 1 −h
for some nilpotent h of some order? Start with the special case h2
1 = 0 = h2
2,
h1h2 = 0. What if hi = tiϵ, where ϵ2 = 0? What if multiplication were non-
commutative?
♦
Remark A.32: (An Embedding) Any given integral domain R can be realized as a
subring of a ﬁeld F by constructing F to consist of equivalence classes of fractions
x
s , where x is in R, s is in R, and s ̸= 0.
The condition that a ring R has “no” (i.e., no nonzero) nilpotent elements is often
referred to in geometry and analysis by saying the R is “reduced”. It is more general
than the cancellation (i.e., integral domain) property since, for example, R = IR2
with coordinatewise multiplication is reduced (i.e., has no nilpotent element) but is
not an integral domain since it has nontrivial idempotent elements ⟨0, 1⟩, ⟨1, 0⟩. In
logical notation with variables, R is reduced if and only if
∃n[xn+1 = 0] ⊢x = 0
holds for all x in R. Since the ∃occurs on the left, this is one of its eliminable cases.
But more profoundly (i.e., using something of the quantitative content of the theory
of rings and not merely logical form):
Exercise A.33
If a ring satisﬁes
⊢∀x[x2 = 0 ⇒x = 0]
then it is reduced.
Hint: Show that if xn+1 = 0, then x2n = 0; hence, using our main assumption, then
also xn = 0. By induction, the n can be decreased until eventually n = 1.
♦

Appendix B
The Axiom of Choice and Maximal Principles
The axiom of choice was ﬁrst formulated by Zermelo in 1904 and used to prove
his Well-Ordering theorem. The axiom was considered controversial because it
introduced a highly nonconstructive aspect that differed from other axioms of
set theory. For some time it was mainly used in the form of the Well-Ordering
theorem (which is actually equivalent to the choice axiom). In this formulation,
the axiom permits arguments by the so-called transﬁnite induction. For about the
last 50 years it has usually been used in the form of the Maximal Principle
of Zorn (published in the 1930s, though a version by Hausdorff was published
earlier.)
If nontrivial variation with respect to some category S of abstract sets and ar-
bitrary mappings is allowed in a category of variable sets, the axiom of choice
tends not to hold as we have seen in Exercises 4.54, 6.12, and Section 10.3. In
fact, the axiom is valid in certain very special toposes of variable sets determined
relative to a category of abstract sets and arbitrary mappings, as was mentioned in
Section 4.6.
Here we will demonstrate that Zorn’s Maximal Principle is equivalent to the
axiom of choice. We will show this for forms of the Maximal Principle that use
both chains and directed (or ﬁltered) posets. The latter form is more suitable for
arguments made in mathematical practice, whereas it is the former that we will
see as a direct consequence of the axiom of choice. In addition we will consider
Hausdorff’s Maximal Principle and some other consequences of the choice axiom.
Our proofs of the maximal principles will follow directly from the famous Fixed-
Point theorem of Bourbaki (B.15 below).
To state the results we need a few deﬁnitions. First recall the deﬁnition of poset,
Deﬁnition 10.6, that is a category with at most one arrow between any two objects.
Any set of objects of a poset E determines a full subcategory, which is also a poset,
called a subposet of E.
220

The Axiom of Choice and Maximal Principles
221
Deﬁnition B.1: Let S be a set of objects of a poset E. An object u in E is an upper
bound for S if for any s in S, s ≤u.
Deﬁnition B.2: Let S be a set of objects of a poset E. The object u is a least upper
bound (abbreviated lub) or supremum (abbreviated sup) for S if it is an upper
bound for S, and moreover for any upper bound u′ for S we have u ≤u′.
Dually we have deﬁnitions of lower bound and greatest lower bound (abbre-
viated glb) or inﬁmum (abbreviated inf) for a set S of objects of E.
Deﬁnition B.3: Let D be a set of objects of a poset E. We say D is directed
if it is nonempty and every two-element part of D has an upper bound in D, or
equivalently
∀x, y ∈D ∃u ∈D x ≤u & y ≤u
Exercise B.4
Show that the power set P X of any set X is a poset with arrows given by the
inclusion relation ⊆. Note that P X is directed as a part of itself. Indeed, any part
of P X has a sup.
♦
The next concept is important in the sequel.
Deﬁnition B.5: An object m of a poset E is maximal if
∀x m ≤x =⇒m ∼= x
A minimal object is deﬁned dually.
An important special case is
Deﬁnition B.6: An object m of a poset E is a maximum if m is an upper bound
for all of E. A minimum object is deﬁned dually.
Exercise B.7
Show that a maximum is maximal. Show that a maximum object of a subposet S
of E is a sup of S.
♦
We can now state (the directed version) of
The Maximal Principle of Zorn

222
The Axiom of Choice and Maximal Principles
If every directed part of a poset E has an upper bound, then E has a maximal object.
We can immediately prove that Zorn’s Maximal Principle implies the axiom of
choice. This proof is a very typical example of the use of this principle in modern
mathematics.
Theorem B.8: The Maximal Principle of Zorn implies the axiom of choice.
Proof: We need to begin with an epimorphism e : A
  B in S and ﬁnd a section
for it. This section should be a maximal object in some suitable poset, for this is
what Zorn’s principle provides. The objects of our poset E will be pairs ⟨i, s⟩, where
i : Bi  
 B is a part of B and s : Bi
 A satisﬁes ∀b ∈i, es(b) = b. Note that
it is immediate that such s must be mono. We call the pairs ⟨i, s⟩partial sections
of e. Partial sections of e form a poset E when ≤is deﬁned by
⟨i, s⟩≤⟨i′, s′⟩iff i ⊆i′ & the restriction of s′ to Bi is s
We will obtain a maximal object of E by showing that E has least upper bounds
for directed parts and applying the Maximal Principle. It will turn out that such a
maximal object provides a section. So let D be a directed part of E. Deﬁne a part
iD : BD  
 B of B by
∀b b ∈iD
iff
∃⟨i, s⟩in D & b ∈i
Deﬁne sD : BD
 A by
sD(b) = s(b) whenever b ∈i and ⟨i, s⟩in D
It is necessary to verify that sD is well-deﬁned by showing that if b ∈i and b ∈i′,
then s(b) = s′(b). This is where we use that D is directed: there is an upper bound
⟨i′′, s′′⟩in D for ⟨i, s⟩, ⟨i′, s′⟩. Thus, i ⊆i′′ and i′ ⊆i′′, and s(b) = s′′(b) = s′(b).
It is also obvious that ⟨iD, sD⟩is an upper bound for D since
∀⟨i, s⟩in D
b ∈i =⇒b ∈iD
and so i ⊆iD.
Thus, E has a maximal object ⟨im, sm⟩. We claim that sm is the required section
of e, that is, Bm ∼= B. If not, there is b0 : 1
 B such that b0 is not in im, and so
i1 =

im
b0 : Bm + 1  
 B
is a part of B. Since e is epi there is a : 1
 A such that e(a) = b0. Let
s1 =

sm
b0 : Bm + 1
 A
and then ⟨i1, s1⟩is a partial section of s. However, im ⊆im + 1, but

im
b0 is not

The Axiom of Choice and Maximal Principles
223
included in im (since b0 is not in im), and this contradicts the maximality of im.
Thus, sm has domain B.
■
There are many other uses of the Maximal Principle of Zorn. For example, it
implies that any proper ideal in a commutative ring is contained in a maximal ideal
(see Exercise B.34) and that any vector space has a basis.
Deﬁnition B.9: A poset E is called a total order (or chain) if for objects x, y in
E either x ≤y or y ≤x. A subposet C of E, which is itself a chain is called a
chain in E.
Exercise B.10
Show that a totally ordered poset E is directed.
♦
With the deﬁnition we can state
The Maximal Principle of Zorn (chain version)
If E is a poset such that every chain in E has an upper bound, then E has a maximal
object.
Exercise B.11
Show that the Maximal Principle of Zorn (chain version) implies the Maximal
Principle of Zorn.
♦
Notice that a proof very similar to that of Theorem B.8 will show directly that
the axiom of choice is implied by the chain version of the Maximal Principle.
Deﬁnition B.12: For any set X, ∀X denotes the characteristic function X
 
of the one-element part of X whose element is the composite X
 1 true  
called trueX for short. Thus
is a pullback.
Given any I
F  X, corresponding to an I-parameterized family of parts of X,
consider its transpose τ F; then, the composite ∀I[τ F] is the characteristic function
of the part of X called the intersection of the family F.

224
The Axiom of Choice and Maximal Principles
We will use the higher dual distributive law of logic
∀a(La or Ra) entails ∃a(La) or ∀a(Ra)
We will discuss below in Exercise B.26 the question of when this law is valid
(it is certainly valid for any category S of abstract sets or any topos in which the
axiom of choice is true).
For simplicity we will assume that posets are strict in the sense that x = y follows
from x ≤y and y ≤x; then, sups are unique if they exist.
Deﬁnition B.13: If f is an endomap of a set X, then a ﬁxed point for f is an
element x of X such that f x = x.
Deﬁnition B.14: If f is an endomap of the set of objects of a poset E, then an
f -chain is any chain C in E such that x ∈C implies f x ∈C. We denote the part
of the power set of the objects of E consisting of all f -chains by ch f (E).
Theorem B.15: (Bourbaki Fixed Point theorem 1950). Let E be a poset, and let
f be an inﬂationary endomap of the set of objects of E, that is, for all x in E,
x ≤f (x). Then f has at least one ﬁxed point provided that any chain in E has a
sup in E.
Proof: Deﬁne a subsystem to be any part (of the objects of E) closed with respect
to sups of f -chains and to f itself. Let A be the intersection of all subsystems of
E. Thus
·
·
are commutative diagrams and A is the smallest part with those properties. Since
we have allowed the part 0 in ch f (E), it follows that A is nonempty and indeed
has a smallest element 0. Because of the ﬁrst diagram, any ﬁxed point of A is also
a ﬁxed point of E. Thus, for the remainder of the proof we work in A.
We need to establish that any subsystem (such as A) whose only subsystem is
itself has the following two
Elementary Properties of Irreducible Subsystems
(P)
t ≤a entails t = a or f (t) ≤a
(B)
it is true that t ≤a or f (a) ≤t

The Axiom of Choice and Maximal Principles
225
These properties will sufﬁce because they clearly imply the “ f -trichotomy”
property for A,
t = a
or
f (a) ≤t
or
f (t) ≤a
which in turn easily implies that the whole of A is an f -chain. (As often in inductive
proofs, to reach the latter goal we needed to prove something stronger.) But A being
an f -chain entails that sup A ∈A since we have assumed that A is closed under
such sups. Then sup A is a ﬁxed point of f since sup A ≤f (sup A), yet x ≤sup A
for all x ∈A and f (sup A) ∈A.
In order to establish the two properties above, deﬁne a part of A:
P = {a ∈A | ∀t ∈A[t ≤a ⇒[t = a or f (t) ≤a]]}
Then, more precisely, what we will show is that P = A.
It will sufﬁce to show that P is a subsystem, for then A ⊆P by deﬁnition of A.
To show that P is a subsystem, we ﬁrst will need to show that for any given a ∈P
each of the following is a subsystem:
Ba = {b ∈A | b ≤a or f (a) ≤b}
Exercise B.16
Because a ∈P, Ba is closed under f .
♦
Exercise B.17
The subset Ba is closed under any sups that exist in A.
Thus Ba = A, i.e. any a ∈P is a “bridge point” for A.
Hint: Use the higher dual distributive law.
♦
Both of the clauses needed to show that P is a subsystem will depend on the
bridge-point property.
Exercise B.18
Assume a ∈P. Use the fact that a is a bridge point to conclude that f a ∈P.
♦
Exercise B.19
Applying a different case of the higher dual distributive law to the fact that each
element of P is a bridge point, conclude that P is closed under sups of f -chains.
Hint: Suppose C is any f -chain in P and t is any element of A for which t ≤sup C;
then it must be shown that t = sup C or f (t) ≤sup C. But all elements of C are
bridge points; hence, t satisﬁes
∀a ∈C[t ≤a or f (a) ≤t]

226
The Axiom of Choice and Maximal Principles
The higher dual distributive law can be applied by taking Lt(a) to be “t ≤a” and
Rt(a) to be “ f (a) ≤t,” leading to two possibilities:
(1) If ∀a ∈C[ f (a) ≤t], then ∀a ∈C[a ≤t], and hence sup C ≤t, i.e. t = sup C.
(2) If t ≤a for some a ∈C, then since a ∈P, one has t = a or f (a) ≤t:
(a) if t = a, then f (t) = f (a), yet f (a) ∈C since C is an f -chain, and so
f (t) ≤sup C;
(b) if f (a) ≤t, together with t ≤a ≤f (a), we have t = f (a) ∈C, and so
f (t) ≤sup C.
Thus, in all these cases t = sup C or f (t) ≤sup C; since this is true for all t ≤
sup C, it follows that sup C ∈P.
♦
Since the foregoing holds for all f -chains C, we have completed the proof that
P is a subsystem. Therefore, P = A, and so, as shown above under “Elementary
Properties of Irreducible Systems,” f has a ﬁxed point. Thus, the exercise completes
the proof of the Bourbaki Fixed-Point theorem.
■
Exercise B.20
(Hausdorff 1914) The axiom of choice implies that any poset X contains a maximal
chain (the Hausdorff Maximal Principle). Indeed, if not, let ϕ be a section for the
ﬁrst projection in
[Proper inclusions of pairs of chains in X]
 chains (X)
and let f be ϕ followed by the second projection. The sup of a chain of chains
always exists and is again a chain.
Note: This proof of the Hausdorff Maximal Principle evidently uses Boolean logic
(which is actually a consequence of the axiom of choice, see [D75] or [Joh77]).
♦
Exercise B.21
(Zorn 1935) Any poset in which every chain has an upper bound has itself a maximal
element.
Hint: An upper bound of a maximal chain is a maximal element; indeed, if C is a
chain, and if m is any upper bound for C and x is any element with m ≤x, then
C ∪{x} is a chain; thus, if C is maximal, x ∈C and hence x = m.
♦
Combining this exercise with Theorem B.8 and Exercise B.11, we have
Theorem B.22: The axiom of choice is equivalent to the Maximal Principle of Zorn
(either version!).

The Axiom of Choice and Maximal Principles
227
As mentioned at the beginning of this appendix, Zermelo used the axiom of
choice to prove his Well-Ordering theorem.
Deﬁnition B.23: A poset E is called well-ordered if whenever S is a nonempty
part of the objects of E then S has a minimum object.
Exercise B.24
Show that a well-ordered poset E is a total order.
Hint: Consider the minimum object of a two-object set.
♦
Exercise B.25
(Zermelo 1908) Every set X can be well-ordered.
Hint: Consider the set of all well-orderings of parts of X and order it by “initial
segment”; in this case a maximal well-ordering must have the whole X as set of
objects.
♦
A given surjective map has a section provided that certain associated sets are well-
orderable therefore the Well-Ordering theorem is actually equivalent to the axiom
of choice. In fact, there are literally dozens of useful mathematical principles in
topology and algebra that have also been shown equivalent to the choice axiom
over the past 75 years.
The higher dual distributive law of logic used in the above proof of the Theorem
B.15 is true in many toposes but not in most. This law is dual to the usual inﬁnite
distributive law
u ≤ua for all a entails u

wa ≤

uawa
which is true in any topos because of the existence of implication as an operation
on subobjects. In a Boolean topos like S, the power sets are self-dual, and hence
the higher dual law holds as well.
Exercise B.26
Does the higher dual distributive law imply the Boolean property? Does it hold in
the topos SCop of all actions of C on abstract sets, in case C is discrete, or a group,
or a poset?
♦
Here are some additional exercises:
Exercise B.27
An irreducible f -system is not only closed with respect to sups of f -chains, but in
fact has sups of all chains.
Hint: Use a third instance of the higher dual distributive law.
♦

228
The Axiom of Choice and Maximal Principles
Exercise B.28
Any irreducible f -system, such as P = A in Exercise B.19 has two further prop-
erties: The endomap f is order-preserving, and every part has a sup.
♦
Note: The latter two properties are of importance even when f is not inﬂationary
and the system is not irreducible: Tarski’s ﬁxed-point theorem states that every
order-preserving endomap of a poset having all sups has a ﬁxed point. The reader
shouldbeabletoproveit;itiseasierthantheBourbakitheoremwhoseconsequences
we are discussing in this appendix.
Exercise B.29
Use Tarski’s ﬁxed-point theorem to show that if there are parts B
α  A and
A
β  B, then there exists an isomorphism A ∼= B. This result depends on the
further assumption that all parts have Boolean complements; it is not true for most
categories of variable or cohesive sets.
Hint: Construct an order-preserving endomap of 2A by using complementation in
both A and B and also applying both α and β; on a ﬁxed “point” of that endomap,
use β, and on the complement use a retraction for α. The construction actually can
be applied to any pair of maps; what conclusion can then be drawn?
♦
Exercise B.30
Using Zorn’s Maximal Principle (and Boolean logic) show that any family E
 I
of sets makes I a chain with respect to the ordering: i ≤j iff there exists an injective
Ei
 E j.
Hint: If there is no injective E1
 E2, then any maximal partial injection from
part of E2 into E1
X
E2
E1
will actually have its domain total, that is X = E2.
♦
General Remark: Inductive arguments rely on special cases of the principle that
within any given set E as universe, if too many conﬂicting higher-order operations
are considered, they will be constrained to have some relation. The simplest sort of
such relation is a ﬁxed point. For example, arbitrary sups and an order-preserving

The Axiom of Choice and Maximal Principles
229
endomap are sufﬁciently conﬂicting, according to the Tarski theorem, as are sups
of chains and an inﬂationary endomap, according to the Bourbaki theorem. Some
systems of operations, even higher-order ones, are sufﬁciently harmonious to permit
“freedom” from such unexpected relations, as the following example shows:
Exercise B.31
Free sups exist. More precisely, given any set X, there is a poset P X that has sups
of all parts and a map X
η  P X such that, given any map X
ϕ  E, where E
is any poset having sups of all parts (no relations are assumed in E beyond the
deﬁnition of sups), there is a unique map P X
ϕ′  E that preserves all sups and
satisﬁes ϕ′η = ϕ.
♦
Of course systems of ﬁnitary operations that are free of any unexpected relations
do tend to exist because of the assumption that a natural number system exists on
some set. There are many variants of that theme, for example:
Exercise B.32
Consider systems E involving a nullary operation 1
∞ E and a unary operation
E
f  E subject to the condition that f (∞) = ∞; a category is obtained by consid-
ering that a homomorphism between any two such systems is a map of the carrying
sets that preserves both these operations. Show that there is a free such system N ′
generated by the one-point set, i.e. there is 1
0  N ′ such that for any such system
E and for any given point 1
x  E there is a unique homomorphism N ′
x′  E for
which x′(0) = x. Does N ′ have any f -ﬁxed points other than ∞? (In the category
of abstract sets, N ′ has an ordering for which all parts have sups, but in categories
of variable or cohesive sets this N ′ fails to have all sups.)
♦
Thus, it is the combining of higher-order operations with very distinct (even
ﬁnitary) ones that may be impossible to do in a “free” way within any ﬁxed set.
Example: (Gaifman [G64]) Any inﬁnite poset with arbitrary sups and an endomap
f of the underlying set for which f f = identity must satisfy some additional
relation. (Actually, Gaifman showed that there are no “free” [in a sense analogous
to those of Exercise B.31 and B.32] complete Boolean algebras except ﬁnite ones,
which implies our statement.)
♦
The irreducible subsystems (such as A in our proof of the Bourbaki theorem)
that help to reveal these relations seem to have the property that every element
is somehow “reached” from below by applying the operations. It has been found
useful (by Cantor and since) to make this reaching idea appear more precise by

230
The Axiom of Choice and Maximal Principles
introducing well-orderings along which the operations can be “inﬁnitely iterated”.
In the case of our irreducible systems A = P with sups of chains and an inﬂationary
f , this is already achieved:
Exercise B.33
Consider a chain C having sups of any part as well as an order-preserving endomap
f such that x ≤f x for all x. (Then there is a smallest element 0 and a largest
element ∞, and moreover f (∞) = ∞.) If C has no parts closed under f and sups
(other than C itself), then
f (x) = x ⇒x = ∞
Can you show that C is well-ordered?
♦
Returning to ﬁnitary algebra, the following is a typical application of Zorn’s
Maximal Principle:
Exercise B.34
If A is any commutative ring in which it is false that 0 = 1, then there exists a
ﬁeld F and a surjective ring homomorphism A
 F (such a homomorphism is a
“closed point” of the space specA, which plays a key role in algebraic geometry and
functional analysis. Since typically A has a great many surjective homomorphisms
to other rings A
 B, where also 0 ̸= 1 in B [such homomorphisms correspond to
nonemptyclosedsubspacesofspecA],byapplyingtheexerciseto B andcomposing,
we see that specA typically has many closed points).
Hint: Surjective homomorphisms with domain A are determined by their kernels,
which are A-linear subgroups of A; the codomain of such a homomorphism is a
ﬁeld iff the corresponding A-linear subgroup is maximal among those that do not
contain 1. The A-linear subgroups have been known since Dedekind as ideals.
♦

Appendix C
Deﬁnitions, Symbols, and the Greek Alphabet
C.1 Deﬁnitions of Some Mathematical and
Logical Concepts
Included here are some of the main deﬁnitions from the text. Several entries go
beyond bare deﬁnition, in an attempt to provide a window into the historical and
foundational background.
Adjoint Functors:
Let X and A be categories and F : X
 A and G : A
 X be functors. We say
that F is left adjoint to G (or equivalently G is right adjoint to F, and write this
F ⊣G) if for any objects X in X and A in A there is a given bijection ϕ(X, A)
between arrows from F X to A and arrows from X to G A,
F X
 A
X
 G A
which is moreover natural in X and A. This means that the following holds. Suppose
that X′
x  X in X and F X
f  A, then
ϕ(X, A)( f ) ◦x = ϕ(X′, A)( f ◦Fx)
and the similar condition holds for arrows A
a  A′:
ϕ(X, A′)(a ◦f ) = a ◦ϕ(X, A)( f )
There are many examples of this concept in the text and exercises. For exam-
ple, consider the the diagonal functor  : S
 S × S, which sends a set X to
the pair (X, X) (and a mapping f to ( f, f )). The sum functor + : S × S
 S,
which sends (A, B) to A + B is left adjoint to , whereas the product functor
is right adjoint to . Another key example is the exponential or mapping-space
functor (−)B whose properties follow from its deﬁnition as the right adjoint of
(−× B).
231

232
Deﬁnitions, Symbols, and the Greek Alphabet
In case F1 and F2 are both left adjoint to G, there is a natural isomorphism
F1 ∼= F2, and, similarly, any two right adjoints to F are naturally isomorphic.
Algebraic Topology:
The cohesive spaces of various categories (continuous, smooth, analytic, com-
binatorial) serve as domains for cohesively variable quantities and as arenas for
uninterrupted motion. But in particular, a space also has qualitative attributes that
collectively might be called its “shape,” the best-known such attribute being mea-
sured by the Euler characteristic and the Betti numbers that count the number
of k-dimensional “holes” in the space. (The qualitative attributes of a cohesive
space can make a crucial difference when dealing with the differential and inte-
gral calculus of quantities that vary over such a space as domain; such quantities
arise in electromagnetism and statistical mechanics, and the precise effect of the
shape on their behavior is expressed by theorems of de Rham and of Stokes.)
Not only Betti and Volterra, but also Vietoris and Noether, as well as Hurewicz
and Steenrod, and many others, devised algebraic and combinatorial construc-
tions for getting at these qualitative attributes. Those constructions were varied
and sometimes complex so questions naturally arose: Do they always give the
“same answer,” and can they be adequately conceived in a more direct manner? In
1952 Eilenberg and Steenrod showed how to answer those questions by unifying
the subject in a way that also made possible the ensuing 50 years of remarkable
advance. Their use of the axiomatic method resulted from participating in the on-
going development, extracting the essential features, and making these features
explicit in order that they could serve as a basis and guide for further work in the
ﬁeld.
The analogy between set theory and algebraic topology goes even further.
Namely, in both subjects the examples ﬁrst considered satisfy a special axiom
concerning the one-point space 1: In the abstract-set categories there are enough
maps from 1 to separate maps between any two sets, and in singular cohomology,
the cohomology of 1 vanishes in higher dimensions. But later important uses of both
axiom systems have involved mathematically rich situations in which those special
axioms do not hold. When it was ﬁrst realized that these special axioms were too
restrictive, one spoke of “generalized elements”, “generalized cohomology theo-
ries,” respectively but as the central role of these situations became established, the
word “generalized” was gradually dropped, and now we speak just of “elements”
(i.e., ﬁgures of various basic shapes, not just punctiform) and of “cohomology the-
ories” (which do not necessarily vanish in higher dimensions even for the one-point
space). In the case of set theory we approach these more general situations through
our investigations of variable sets.

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
233
Category Theory:
Category Theory was made explicit by Eilenberg and Mac Lane. In 1945 [EM45]
they concentrated some of the essential general features of the developments up
to then in algebraic topology and in functional analysis, which are still-developing
branches of the science that ﬁnds and uses the relation between quality and quantity
in the study of space and number. A further development of category theory came in
1958 [Kan58] when Kan made explicit the notion of adjoint functors, which were
then rapidly seen to be ubiquitous (even if implicit) in mathematics. In the 1960s
and 1970s it was established in detail that the mathematically useful portions of
set theory and of logic in the narrow sense can be seen as part of category theory
[La69b], [KR77], [FS79].
Characteristic Functions (2.20):
Suppose we have ﬁxed an element 1
v1  V of a set V . (In the case of abstract sets
we will often take V to be a two-element set and call the distinguished element
“true”.) Then a part i of a set A is said to have a map A
ϕ  V as characteristic
function iff the elements of A, which are members of i, are precisely those to which
ϕ gives the value true. In symbols,
∀T
a  A [a ∈i ⇐⇒ϕa = v1T ]
(here v1T denotes the composite map T
 1
v1  V , which is constantly true).
That is, i = ϕ−1[v1] is the inverse image of the one-element part “true” of V along
ϕ. In the category of sets, every part i has a unique characteristic function ϕ (to
V = 2), and for any map f the two ways of substituting f agree:
ϕ f −1[ j] = ϕ j f
Composition:
Value of the Composite Mapping / Associative Law
∀x[(g f )x = g( f x)]
1
x

fx
(gf)x = g(fx)
A
f
gf
B
g
C
T = 1
elements/values

234
Deﬁnitions, Symbols, and the Greek Alphabet
T
x
fx
(gf)x = g(fx)
A
f
gf
B
g
C
T = arbitrary set : the associative law
Contrapositive:
The contrapositive of a statement “P implies Q” is the statement that
“not Q implies not P” or in symbols: (¬Q ⇒¬P)
If the original implication is true, then the contrapositive is always true also, and
in classical logic if the contrapositive is true, we can conclude that the original
statement was true (the latter procedure being often referred to as proof by con-
tradiction). For example: The statement that “1 is a separator in the category of
sets” in its contrapositive guise assumes the following form (which is sometimes
understood as the deﬁnition of equality for mappings):
[∀1
x  X [ f1x = f2x]] ⇒f1 = f2
Of course, to recognize the expression above as the contrapositive of the sepa-
rator condition involves one more ingredient beyond the notion of contrapositive
itself, namely, the recognition that existentially quantiﬁed statements are negated
as follows:
¬∃x P ≡∀x¬P
Converse of an Implication:
The converse of a statement of the form
P implies Q (or in symbols: P ⇒Q)
is the statement
Q implies P (or in symbols: Q ⇒P)
Even when the original statement is true, the converse statement may or may not
be true, depending on the case.

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
235
Element (1.3):
r (in the narrow sense) An element of a set A is any mapping whose domain is
1 and whose codomain is A. This mapping is also sometimes referred to as the
indication of an element, but we will not distinguish between elements and their
indication.
r (in the generalized sense) An element of A is just another word for any mapping
with codomain A; such a generalized element may also be referred to as a
variable element or as a parameterization or listing of elements.
Epimorphism / Right Cancellation (4.5):
This concept is strictly “dual” to that of monomorphism. We say f is an epimor-
phism iff it satisﬁes the right-cancellation property
∀ϕ1, ϕ2 [ϕ1 f = ϕ2 f ⇒ϕ1 = ϕ2]
Foundation:
A foundation makes explicit the essential general features, ingredients, and oper-
ations of a science as well as its origins and general laws of development. The
purpose of making these explicit is to provide a guide to the learning, use, and
further development of the science. A “pure” foundation that forgets this purpose
and pursues a speculative “foundation” for its own sake is clearly a nonfoundation.
Foundation, Category of Categories as:
Among the general features of mathematics a foundation should make explicit are
(1) the nature and workings of the logical and algebraic theories within which we
reason and calculate;
(2) the nature and workings of the set-universes, whether abstract and constant,
or cohesive and variable, that we imagine as an objective or geometrical back-
ground;
(3) the nature and workings of the interpretations, known as structures or models,
of theories into set-universes.
These requirements have forced mathematics toward the foundational view we
havetriedtoconveyinthisglossaryandinthisbook;thiscanbeseeninthefollowing
way: The “category” of models of a given theory in a given set-universe must form
something like a mathematical category since these structures are different realiza-
tionsoftheonesinglesystemoffeaturesrequiredbythetheory,andhencetheremust
be ways of comparing different ones by “morphisms” or maps that “preserve” those

236
Deﬁnitions, Symbols, and the Greek Alphabet
features. Something of that sort applies roughly to concepts generally, but in math-
ematics it is quite deﬁnite. For example, consider a theory A of addition and multi-
plication, which in an appropriate background universe U has many models such as
Q(1) = a system of constant quantities;
Q(S) = a system of quantities varying over a region S of space; and
Q(T ) = a system of quantities varying over an interval T of time.
Then a speciﬁed motion m : T
 S will yield a morphism that we name m∗:
Q(S)
 Q(T ), and a speciﬁed instant t : 1
 T of time will yield a morphism
t∗: Q(T )
 Q(1), such morphisms being structure-preserving maps for the
theory A. The background universe U must also be a category since morphisms
of spaces (or sets) are the ingredients in the morphisms like t∗, m∗of structures.
A key discovery around 1962 (foreshadowed by the algebraic logic of the 1950s)
was that a theory A is also a category! That is because the most basic operation
of calculation and reasoning (which as it turned out uniquely determines the other
operations) is substitution, and substitution correctly objectiﬁed is composition.
(The symbolic schemes often called “theories” are a necessary but not uniquely
determined apparatus for presenting theories [in the usual algebraic sense of
presentation].) It seems that two things (like A and U) cannot be concretely related
unless they can be construed as objects of the same category; fortunately, in this
case we have that both A and U are categories, and so a relation like Q : A
 U
is a functor in a category of categories. Moreover, the morphisms between different
models are just natural transformations between functors. These considerations
put a mathematical focus on some questions that a foundation needs to address.
Function:
Although the word “function” is sometimes used in a way synonymous with “map-
ping,” more frequently it is used to describe maps (in some category) whose
codomains are some special objects V deemed to have a “quantitative” charac-
ter (for example V = 2 or V = ), and so one speaks of, for example, “the algebra
of smooth complex-valued functions” on any smooth space. The V -valued func-
tions on any object will always form an “algebra” (in a general sense) because the
maps V
 V , V × V
 V , and so on, will act as operations on them.
Functor (10.18):
Let A and B be categories. A (covariant) functor F, denoted F : A
 B from
A to B is an assignment of
r an object F(A) in B for every object A in A
r an arrow F( f ) : F(A)
 F(A′) in B for every arrow A
 A′ in A

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
237
subject to the following equations:
r F(1A) = 1F(A)
r F(g f ) = F(g)F( f ) whenever A
f  A′
g  A′′
A contravariant functor F : A
 B assigns objects to objects, and an arrow
F( f ) : F(A′)
 F(A) (note direction!) in B for every arrow A
 A′ in A. It
satisﬁes the equation F(g f ) = F( f )F(g) instead of the second equation above.
Inclusion (2.13):
The notation
i′ ⊆A i
means both i, i′ are parts of a set A and
∃k [i′ = ik]
which is equivalent to saying
∀a[a ∈i′ ⇒a ∈i]
When the set A is understood, we write simply i′ ⊆i.
Intersection (2.36):
If i1, i2 are parts of A, then their intersection denoted
i1 ∩i2
is also a part j of A characterized up to equivalence by having as members precisely
those elements of A common to i1 and i2
(∀T
a  A[a ∈j ⇐⇒a ∈i1 & a ∈i2]) ⇐⇒j ≡i1 ∩i2
Among the many ways that intersection can be characterized is as the “inverse
image” along i1 of i2.
Inverse Image (2.5):
If A
f  B is any mapping and j is any part of B, the condition “ f ∈j” is typically
not outright true but does have a “solution set”: the part of A for which f ∈j holds,
more exactly the part i of A whose members are precisely all those elements a of

238
Deﬁnitions, Symbols, and the Greek Alphabet
A for which f a ∈j. In symbols:
∀T
a  A [a ∈i ⇐⇒f a ∈j]
⇐⇒i ≡f −1[ j]
We call f −1[ j] the inverse image of j along f .
Injective / Monomap / Left-Cancellation / Part:
All four of these terms mean essentially the same thing but with different gram-
matical shadings as in “A huge person is a giant.”
Injective (1.5):
Given an object I, we may say that f is I-injective iff f has the left-cancellation
property for all test pairs with domain I:
∀a1, a2 [I
a1

a2
 A & f a1 = f a2 ⇒a1 = a2]
Since the deﬁnition of “monomorphism” contains the phrase “∀T ,” it is obvious that
any monomorphism is always I-injective. The converse proposition, namely that
I-injective ⇒monomorphism, holds if I is a separator, as is easy to prove. In the
case of the category of abstract sets, we usually take I = 1 and refer to 1-injective
mappings simply as injective. Thus injective mappings f are usually considered
“by deﬁnition” to satisfy
f a1 = f a2 ⇒a1 = a2
where a1, a2 are elements (in the narrow sense) of the domain of f ; however, since
1 is a separator, injective mappings in fact satisfy the full left-cancellation property.
In contrapositive form,
∀a1, a2[a1 ̸= a2 ⇒f a1 ̸= f a2]
describes injective/monic f , thus to show that a certain f is not injective, it sufﬁces
to exhibit that
∃a1, a2 [ f a1 = f a2 & a1 ̸= a2]
Left-Cancellation / Monomapping (2.6):
The statement f has the left-cancellation property means that for any a1 and a2
for which f a1 = f a2 we can conclude a1 = a2, or in symbols
∀T ∀a1 ∀a2 [ f a1 = f a2 ⇒a1 = a2]

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
239
as in the diagram
If f has the left-cancellation property in a certain category, we say that f is a
monomorphism in that category. Since the morphisms in the category of sets
are called mappings, the monomorphisms in that category may also be called
monomappings.
Logic:
Thescienceoflogicintheancientphilosophicalsensemeansthestudyofthegeneral
laws of the development of thinking. Thinking (1) reﬂects reality (i.e., has a content)
but also (2) is itself part of reality and so has some motions that are oblivious to
content. Therefore the science of logic ﬁnds two aspects of thought’s motion: (1) the
struggle to form a conceptual image of reality that is ever more reﬁned, whose laws
we may call objective logic, and (2) the motion of thought in itself (for example the
inference of statements from statements), whose laws we may call subjective logic.
Although grammar and some aspects of algebra might be considered as subjective
logic, we will limit ourselves to the part we will sometimes refer to as logic in the
narrow sense – that which is related to the inference of statements from statements
by means dependent on their form rather than on their content. (Logic in the narrow
sense is explained in more detail in Appendix A.)
Logic in the narrow sense is useful (at least in mathematics) if it is made explicit,
and the work of Boole and Grassmann in the 1840s, Schr¨oder in the late 1800s,
Skolem in the early 1900s, Heyting in the 1930s (and of many others) has led to a
highdevelopment,mostaspectsof whichwererevealedtobespecialcasesofadjoint
functors by 1970 [La69b]. The use of adjoint functors assists in reincorporating the
subjective into its rightful place as a part of the objective so that it can organically
reﬂect the objective and in general facilitate the mutual transformation of these two
aspects of logic.
Logic, Objective:
The long chains of correct reasonings and calculations of which subjective logic is
justly proud are only possible within a precisely deﬁned universe of discourse, as
has long been recognized. Since there are many such universes of discourse, think-
ing necessarily involves many transformations between universes of discourse as

240
Deﬁnitions, Symbols, and the Greek Alphabet
well as transformations of one universe of discourse into another. The results of
applying logic in the narrow sense to the laws of these objective transformations are
necessarily inadequate; for example, such attempts have led to the use of phrases
such as “let X be a set in which there exists a group structure,” which are essentially
meaningless. Rather than using “there exists” in such contexts, one needs instead a
logic of “given.” Before category theory, at least one systematic discussion of the
laws of these objective transformations was given by Bourbaki, who discussed how
one structure could be deduced from another. The concepts of categories, func-
tors, homomorphisms, adjoint functors, and so on, provide a rich beginning to the
project of making objective logic explicit, but there is probably much more to be
discovered.
Logic, Intuitionistic:
A. Heyting, in the 1930s, developed a logical algebra that happens to be applicable
in any topos. This logic is weaker than the Boolean one because it allows for
the possibility of motion or internal variation in the sets or universes to which it
is being applied, and thus the typical Boolean inference (or subobject inclusion)
“not(not A) entails A” is usually not correct. Because Heyting’s work was intended
to model the “constructivist” philosophy of the intuitionist Brouwer, Heyting’s
logic is sometimes incorrectly referred to as intuitionistic logic, and for that reason
topos theory is sometimes referred to as constructive set theory; neither of these
does justice to the true generality of Heyting’s discovery or to Grothendieck’s
theory. There are a few toposes that have been speciﬁcally constructed in an attempt
to understand the constructivist philosophy, but most toposes have little to do
with it.
Mapping (1.1):
In the category of abstract sets, f is a mapping with domain A and codomain B
if for every element x of A there is exactly one element y of B such that y is the
value of f at x. In symbols,
∀1
x  A ∃!1
y  B[y = f x]
and as a diagram
1
∃!y

∀x
A
f
B

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
241
Membership (2.15):
The notation a ∈A i means i is a part of a set A and ∃a [a = ia] as in the diagram
When, as is usually the case, the set A is understood, we write simply a ∈i.
Natural Transformation (10.19):
Let F, G : A
 B be functors. A natural transformation τ from F to G is the
assignment of an arrow τA : FA
 G A in B for each object A of A subject to the
requirement that for each arrow A1
α  A2 in A the following square commutes:
The arrows τA are called the components of the natural transformation. In case
each τA is an isomorphism in B, then τ is called a natural isomorphism; in that
case there is an inverse natural transformation.
There are many examples in the text and exercises – notably the natural map
treated in Section 8.3, the singleton (see Exercise 8.9), and the arrows in the cate-
gories of A-sets in Section 10.2.
One-Element Set (Section 1.2):
The set 1 is characterized by the fact that for any set A there is exactly one mapping
with domain A and codomain 1. In symbols,
∀A ∃! [A
 1]
that is, the statements below are both true:
∀A

EXISTENCE (∃)
∃f [A
f  1]
AT MOST ONE (!) ∀f, g [A
f

g
 1 ⇒f = g]

242
Deﬁnitions, Symbols, and the Greek Alphabet
Part (2.11):
By a part of a set A is meant any monomapping i whose codomain is A. Nota-
tion: U  
i
 A. Parts of A are called equivalent if they are isomorphic as objects
of the slice category S/A.
Separator (1.14):
A set T is a separator if there are enough mappings with it as domain to separate
pairs of mappings with arbitrary domains; i.e. when A is an arbitrary set and if f1
and f2 are any two mappings with domain A and some common codomain B, if f1
is distinct from f2 there should exist a mapping x with domain T and codomain A
such that f1x is distinct from f2x. An important property of the category of abstract
sets is that the terminal set 1 is a separator. In symbols,
∀A ∀B ∀f1, f2[[A
f1

f2
 B & f1 ̸= f2] ⇒∃1
x  A[ f1x ̸= f2x]]
as in the diagram:
1
x
A
f1
f2
B
Set Theory:
Set theory was started in the late 1800s when Cantor made explicit an abstraction
process (arising from his own work on Fourier analysis) and applied the idea of
isomorphism(whichhehadlearnedfromtheworkofSteineronalgebraicgeometry)
to the results of this abstraction process. Some of Cantor’s followers did not fully
appreciate this abstraction process (in editing Cantor’s works for publication they
issued judgments of it such as “kein gl¨ucklicher Versuch” and “um keinen Schritt
weitergekommen,” p. 35, edition of 1932 [C66]). For this and other reasons, too
much of the technical development of set theory has been rather detached from its
origins in the speciﬁc requirements of functional analysis and algebraic geometry.
Thus, the great functional analyst and algebraic geometer of the 1950s and 1960s,
Grothendieck, made only peripheral reference to set theory as known at the time
when he devised topos theory, an explicit theory of the categories of cohesive and
variable sets as they actually occur in geometry and analysis [AGV72]. In 1970 the
essential part of Grothendieck’s theory was drastically simpliﬁed in response to the
needs of continuum mechanics and algebraic topology [La71], [T72] (see [Joh77],

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
243
[BW85], [MM92]). These developments made the bridging of the previous gap
between axiomatic set theory and naive set theory possible.
Set Theory, Axiomatic:
The use of the axiomatic method, to make explicit the basic general features of
the application of set theory to the study of mathematical subjects was delayed for
much of the twentieth century by the attempt to popularize a certain philosophical
view; according to that view the intersection of any two unrelated sets should have
a well-deﬁned meaning. That contrasts with the phenomenon noted in practice
that inclusions, and more generally, relations between sets, are effected by speciﬁc
mappings. The description of this “cumulative hierarchy” came to be considered
by some as the only possible sort of formalized set theory.
Set Theory, Naive:
A certain body of set-theoretical methods and results is required for the learning
and development of analysis, geometry, and algebra. Because of the insufﬁciently
analyzed belief that this body could not be made logically precise without the
cumulative hierarchy and global inclusion, it became customary to describe it in a
“nonformalized” manner known as “naive set theory” [H60]. One of the purposes
of this book is to overcome this division between naive and axiomatic aspects by
giving formal axioms sufﬁcient to describe the applicable aspects of the set theory
that has been developed by Dedekind, Hausdorff and their many successors. For an
earlier version, see [La64].
Set Theory, Parameterization:
Many of the applications of naive set theory could be described as based on “para-
meterization”: a set is used to parameterize some things, some mappings on the set
are deemed to express relations among the things, calculation and reasoning are
applied to these maps, and the result is used to guide our dealing with the original
things. Since in particular set theory should be partly applicable to itself, several of
the axioms can be motivated by the observation that they simply assert that there are
enough sets to parameterize some basic set-theoretic “things,” as in the following
three cases.
A set T can parameterize
(1) elements of a set A, by means of a map T
 A; a bijective parameterization
can be achieved by taking T = A and 1A as the map;
(2) pairs of elements of A, B by means of a pair of maps T
 A, T
 B; here
a bijective parameterization has T = A × B and the projections as the maps;

244
Deﬁnitions, Symbols, and the Greek Alphabet
(3) maps A
 B by means of a map T × A
 B; a bijective parameterization
is possible if we can take T = B A and evaluation as the map.
Such parameterizations are the subject of the related ideas of universal mapping
property, representable functors, and adjoint functors developed by Grothendieck,
Kan, and Yoneda in the late 1950s.
(Sets [or spaces] themselves are T-parameterized in geometry by using a map
E
 T withtheﬁbers Et beingthesetsparameterized;Cantor’sdiagonalargument
showed that no single T can parameterize all sets.)
Surjective (1.4):
Thisconceptisnotlogicallydualtoinjectivesinceitisanexistentialconditionrather
than one of cancellation. Hence, the theorem that for some categories “surjective”
and “epimorphic” coincide will tell us something special about those categories.
The exact notion of “surjective” is related to a chosen object I (such as I = 1 in
the case of abstract sets). We say f is I-surjective iff
∀y∃x[fx = y]
I
∃x
∀y
A
f
B
where x, y are both supposed to have domain I but respective codomains A, B.
That is, every I-element of the codomain is required to be a value of f (for at least
one x).
To show that epimorphism ⇒1-surjective in the case of abstract sets, suppose
that f has the right-cancellation property but that (aiming toward a proof by con-
tradiction) there is a y that does not appear as a value of f . But then if we take
as ϕ1 the characteristic function of y and as ϕ2 the constantly “false”: B
 2, it
follows that ϕ1 f = ϕ2 f but ϕ1 ̸= ϕ2, contradicting that f has right cancellation.
Hence, there is no such y, that is, f is surjective.
Topos:
Since 1970 [La71], the geometrical constructions of Grothendieck in SGA 4
[AGV72] were uniﬁed with the constructions of the set theorists Cohen, Scott and
Solovay [B77] by the observation that both are largely concerned with categories
X that
(1) have ﬁnite products and in which, moreover, there exist
(2) for each object A, a right adjoint ( )A to the functor A × ( ), and

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
245
(3) a map 1
true  , which is a universal part in the sense that for any part
α : A  
 X of any object in X, there is a unique 1
ϕ
  such that
is a pullback; i.e. for any T
x
 X
x belongs to α iff ϕx = true T
This is sometimes called the “elementary” theory of toposes since the three axioms
are ﬁnitary and internal to X.
Topos and the Cantorian Contrast:
The cohesive and variable sets (“spaces”) are persistent ideas collectively developed
as part of our coping with the world of matter in motion of which we are an
interacting part. Cantor and subsequent mathematicians have found it useful to
apply something like the ancient Greek ideas of arithmos and chaos by analyzing
this variation and cohesion through contrasting it with constancy and noncohesion
Y, wherein objects are distinct and ﬁxed enough to have a property like number
but nearly devoid of any other property. (Cantor further conjectured, in effect, that
if “nearly devoid” could be idealized to “totally devoid” for a topos Y of abstract
sets, then Y would satisfy some strong special properties such as the continuum
hypothesis – a conjecture apparently proved in the 1930s by G¨odel, although that
interpretation is still not widely accepted.) Mathematical practice made clear that
cohesion and variation occur in many diverse but related categories X. Construing
some of those categories as toposes makes it possible to study the contrast arising
in Cantor’s abstraction process as a geometric morphism X

  Y. This process

∗of extraction of pure points unites two opposite inclusions of Y into X: the
subcategory 
∗of discrete spaces with zero cohesion and zero motion and the
subcategory 
! of codiscrete spaces with total (but banal) cohesion and motion.
These opposite but identical subcategories provide a zeroeth approximation to the
reconstruction of any space X by placing it canonically in an interval

∗
∗X
 X
 
!
∗X
(In fact closer approximations to X involving narrower intervals are often obtainable
bygeometricmorphismsinvolvingalessabstracttoposY′,butwedonotdiscussthat
here.) There are no nonconstant X-maps from a codiscrete space to a discrete space;

246
Deﬁnitions, Symbols, and the Greek Alphabet
this sharply separates the two aspects (of a Y-object) that the elements are totally
distinguished and yet have total lack of distinguishing properties; these aspects are
thus revealed to form not a conceptual inconsistency but a productive dialectical
contradiction.
Topos, Geometric Morphism:
A pair of adjoint functors
X

∗
 Y

∗

with 
∗left adjoint to 
∗is called a geometric morphism X

 Y in case 
∗
preserves ﬁnite limits. The latter “exactness” property will automatically be true
in case there is a further left adjoint 
! to 
∗. (Note that this string 
! ⊣
∗⊣
∗
is in objective analogy with the string ∃⊣substitution ⊣∀of logic in the narrow
sense.) When 
! exists, the morphism 
 is often called “essential”. Grothendieck’s
compact notation is: asterisks for functors that are present for every 
, exclamation
points for functors that are present only for notably special 
, whereas the lower
position (for either) denotes functors deemed to have the same direction as 
 and
the upper position denotes functors having the opposite direction to 
. In case a
further right adjoint 
! to 
∗exists, a special geometric morphism  results in
the opposite direction with ∗= 
∗and ∗= 
!; such a  may be called “ﬂat”
because the left adjoint !(= 
∗) not only exists but preserves ﬁnite limits.
All four functors exist in the case X = Yop
1 , the category of reﬂexive graphs in a
topos Y (see Section 10.3), where X

 Y is determined by 
∗= the inclusion
of trivial graphs.
Topos of Abstract Sets:
For a topos U the conditions that
(1) epimorphisms have sections (axiom of choice), and
(2) there are (up to isomorphism) exactly two parts of 1,
are generally sufﬁcient to exclude most traces of cohesion or variation, as Cantor
proposed. (It follows that 2 =  and that 1 separates.)
Occasionally the (provably stronger) Generalized Continuum Hypothesis of
Cantor may be further imposed:
(GCH) Whenever monomorphisms A
 X
 2A exist, then an isomorphism
A ∼= X or X ∼= 2A also exists.
Usually a topos of abstract sets is assumed to satisfy (1) and (2) and also
Dedekind’s axiom concerning the existence of a set of natural numbers:

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
247
(3) The forgetful functor U′
 U has a left adjoint, where U′ is the category
whose objects are the objects of U equipped with an action by an arbitrary
endomap.
Topos, Grothendieck:
For the development of number theory, algebraic geometry, complex analysis, and
of the cohomology theories relevant thereto, it was found necessary in 1963 to
introduce explicitly certain categories that Grothendieck and Giraud called “U-
toposes.” (“Topos” is a Greek term intended to describe the objects studied by
“analysis situs,” the Latin term previously established by Poincar´e to signify the
science of place [or situation]; in keeping with those ideas, a U-topos was shown
to have presentations in various “sites”.)
In modern terms a U-topos is a topos X equipped with a geometric morphism 
to a topos U of abstract sets satisfying the condition that X is boundedly generated
over U in the sense that some single map B
 
∗I generates X. In the cases
where one can choose I = 1, the generation condition means that the map
X(B, X) · B
 X
is an epimorphism for all X, where by deﬁnition
X(B, X) = 
∗(X B)
U · B = (
∗U) × B
The functor 
∗= X(1, −) is sometimes called the “global sections” functor to
remind us that the objects of X may be spatially more variable than those of U, or
the “ﬁxed points” functor to remind us that the objects of X may be dynamically
more active, or the “underlying discrete set” functor to remind us that they may be
more cohesive than those of U.
As an application of Grothendieck’s powerful method of relativization, it is very
useful to consider U-topos also in the more general case where U itself is an arbitrary
topos not necessarily consisting of purely abstract sets.
Union:
The hierarchical philosophy led to the identiﬁcation of the notions of set and of sub-
set (part). This in turn led to a confusion between sums (of sets) and unions (of parts
of a given set); for example, the editors of Cantor’s collected works [C66] com-
plained that he had deﬁned the sum only in the case of disjoint sets. If Ai  
 X
is a given family of parts (for example a family consisting of only two parts), then

248
Deﬁnitions, Symbols, and the Greek Alphabet
the union of the family is a part of X obtained by (epi–mono) image factorization
of the induced map from the sum
Ai
inj
A = ΣiAi

i Ai
X
In toposes, any epimorphism is a coequalizer of the induced equivalence relation
given by the self-pullback A ×X A
 A. In turn this relation can be expressed
as
i, j Ai ×X A j
 Ai
(where each summand Ai ×X A j is an intersection of parts and so is again a part of
X). By the universal mapping property of coequalizers, any part B
 X to which
each of the given parts belongs will also contain the union; i.e. in the category of
parts of X
 Ai ⊆B
Ai ⊆B, for all i
are equivalent; the objective form of the rules of inference for disjunction (= re-
peated “or”). However, the universal mapping property of the union is stronger than
that since even if B is an arbitrary object (not necessarily the domain of a part of
X), any given family Ai
βi  B of maps (not necessarily monos) will be derivable
from a unique single map 
i Ai
 B provided only that the equations
expressing agreement on the overlap are satisﬁed by the given family βi.
Yoneda Embedding:
A functor Q : A
 S is called representable if there is an object A in A and
an element q of the set Q(A) so that for all B in A, the map A(A, B)
 Q(B),
which takes any A
b  B into Q(b)(q), is an isomorphism of sets. Equivalently,
there exists a natural isomorphism of functors A(A, −) ∼= Q, where A(A, −) is the
very special functor A A(A,−) S whose values “are” (i.e., perfectly parameterize) the
maps with domain A provided by the category A. It is a consequence of Yoneda’s

C.1 Deﬁnitions of Some Mathematical and Logical Concepts
249
lemma that any two representing objects for the same functor Q are isomorphic, and
indeed there is a unique isomorphism a between them such that the induced Q(a)
takes the “universal element” q given with one representation into the universal
element given with the other. For any map a (not necessarily an isomorphism) from
A1 to A2 in a category A, the composition of maps induces a corresponding natural
transformation a∗: A(A2, −)
 A(A1, −) (see Exercise 10.22) in the opposite
direction between the corresponding representable functors. Thus, there is a functor
Aop
Y  SA
called the Yoneda embedding, deﬁned by Y(A) = A(A, −).
The very same construction applied to the opposite category yields the notion of
contravariant representable functor Aop
X  S as one for which X(B) ∼= A(B, A)
naturally for all B but for a ﬁxed A that is said to represent X. Because the resulting
Yoneda embedding
A
Y  SAop
is full and faithful (see Yoneda’s lemma), one often suppresses any symbol for it and
considers A to be simply a special subcategory of SAop; and conversely, subcate-
gories C of SAop that contain this A often embody very useful generalizations of the
concept that A itself embodied. The special cases in which A is a monoid or a poset
were already studied and used over a century ago: Cayley observed that a canonical
example of a left action of A is the action of A itself on the right, and Schr¨oder,
Dedekind, Cantor, and others made much use of the canonical representation of
a poset as inclusions between certain subsets (actually right ideals) of a given set
(namely of its own set of objects). Note that the category 2 with one nonidentity
arrow (see Section 6.2) embeds in S as the sets 0 and 1 and that the Yoneda
embedding of a given category A actually belongs to the induced subcategory
if and only if A is a poset.
Yoneda’s Lemma:
For any contravariant functor Aop
X  S to sets and for any given object A, the
value X(A) is isomorphic as a set to the (a priori “big”) set of natural transforma-
tions A(A, −)
 X (see Exercise 10.24). When we introduce some still larger

250
Deﬁnitions, Symbols, and the Greek Alphabet
categories via exponentiation in the category of categories, wherein S is an object,
this says more fully that the functor “evaluate at A”
SAop
 S
is one of the representable functors on SAop, indeed it is representable by the repre-
sentable functor on Aop. Corollaries of Yoneda’s lemma include the fullness of the
Yoneda embedding, the uniqueness of representing objects, and the fact that “any”
set-valued functor is canonically a colimit of representable ones. In case A itself is
small relative to S (which means that the objects of A can be parameterized by an
object of S and that A has small hom-sets), then the latter is equivalent to the fact
that any X has a presentation as a coequalizer of two maps between two inﬁnite
sums of representable functors.
Yoneda and Totality:
For any category A such that the arrows between any two objects of A can be
parameterized by an object of S, we say that A has small hom-sets.
A category A with small hom-sets is totally cocomplete if its Yoneda embedding
Y∗= Y has a left adjoint Y ∗: SAop
 A. For example, the category of groups or
the category A = SCop of C-sets are totally cocomplete; Y ∗too may have a left
adjoint Y!. For example, C-sets, but not groups, have such an “opposite” embedding
Y! into the same functor category. One and only one category A has both a further
adjoint to Y! and also a still further left adjoint to that, i.e., an adjoint string of
length 5
U ⊣V ⊣Y! ⊣Y ∗⊣Y∗
starting with Y∗= Y on the right, relating A to SAop, namely A ∼= S, the base cate-
gory of sets itself [RW94]. There are several subcategories of the functor category
SSop that still unite the opposites Y! and Y∗; for example, the category of simplicial
complexes that are important in combinatorial topology. Another subcategory of
SSop containing Y∗as the codiscrete objects is the category of bornological sets,
important in functional analysis, where X : Sop
 S is considered as a structure
in which X(S) ∼= Bor(S, X) acts as the set of “bounded” S-parameterized parts
of X.

C.2 Mathematical Notations and Logical Symbols
251
C.2 Mathematical Notations and Logical Symbols

denoting a map (also called transformation or function)
from a domain A to a codomain B, A
 B
⇒
A ⇒B (A implies B) or (A only if B) or (if A then B)
⇐
A ⇐B (A is implied by B) or (A if B) or (if B then A)
⇔
A ⇔B also written “iff” (A if and only if B)
A ⇒B & B ⇒A (A implies B and B implies A)
−→
value at
∼
a map that has an inverse (called isomorphism)
 

representing the domain as a part of the codomain
=
equals
≡
equivalence of parts
∀
for all
∃
there exists
(existential statement)
∈
membership
(a member of)
>
greater than
∞
inﬁnity
⊢
entails
∧
and, also &
f g
composite of two maps
(read “ f following g”)
\
but not
̸=
not equal
⊆
inclusion
(of a part in another part)
!
unique
(= exactly one)
¬
not
∩
intersection
(of parts)
<
smaller than

sum

integral sign
∨
or
⟨⟩
notation for ordered pairs
or triples or n-tuples
∂
boundary of

252
Deﬁnitions, Symbols, and the Greek Alphabet
C.3 The Greek Alphabet
Since the Latin letters a, b, x, y, and so forth, are sometimes not enough to express all
the different mathematical entities that may arise in a given discussion, Greek letters
are also used in all ﬁelds where mathematics is applied. Usually their meaning is
speciﬁed at the beginning of each discussion just as is done for the meaning of the
Latin letters. The Greek letters themselves are pronounced as follows:
α
alpha
ν
nu
β
beta
ξ
xi
γ
gamma
o
omicron
δ
delta
π
pi
ϵ
epsilon
ρ
rho
ζ
zeta
σ
sigma
η
eta
τ
tau
θ
theta
υ
upsilon
ι
iota
ϕ
phi
κ
kappa
χ
chi
λ
lambda
ψ
psi
µ
mu
ω
omega
This list contains the lowercase Greek letters. The uppercase sigma and pi are
often used to denote sum and product and are written  and $. Other frequently
occurring uppercase Greek letters are  (omega),  (delta), 
 (gamma), % (psi),
 (phi), and X (chi).

Bibliography
[AGV72]
M. Artin, A. Grothendieck, and J. L. Verdier. Th´eorie des topos et
cohomologie ´etale des sch´emas, (SGA4). Volume 269 and 270 of
Lecture Notes in Math., Springer-Verlag, 1972.
[BW85]
M. Barr and C. Wells. Toposes, Triples and Theories. Grundlehren
Math. Wiss. 278, Springer-Verlag, 1985.
[BW95]
M. Barr and C. Wells. Category Theory for Computing Science,
second edition. Prentice-Hall, 1995.
[B77]
J. L. Bell. Boolean-valued models and independence proofs in set
theory. Clarendon Press, 1977.
[B97]
J. L. Bell. Zorn’s lemma and complete Boolean algebras in intu-
itionistic type theories. Journal of Symbolic Logic, 62:1265–1279,
1997.
[B99]
J. L. Bell. A Primer of Inﬁnitesimal Analysis. Cambridge University
Press, 1998.
[C66]
G. Cantor. Abhandlungen mathematischen und philosophischen In-
halts. Ed: Ernst Zermelo. Georg Olms, 1966. (Reprograﬁscher Nach-
druck der Ausgabe Berlin 1932.)
[D75]
R. Diaconescu. Axiom of choice and complementation. Proceedings
of the American Mathematical Society, 51:176–178, 1975.
[EM45]
S. Eilenberg and S. Mac Lane. General theory of natural equiva-
lences. Transactions of the American Mathematical Society, 58:231–
294, 1945.
[ES52]
S. Eilenberg and N. Steenrod. Foundations of Algebraic Topology.
Princeton University Press, 1952.
[FS79]
M. Fourman and D. S. Scott. Sheaves and logic. In Proceedings of the
Durham Symposium, 1977. Lecture Notes in Mathematics No. 753,
Springer-Verlag, 1979.
253

254
Bibliography
[G64]
H. Gaifman. Inﬁnite boolean polynomials I. Fund. Math. 54: 229–
250, 1964.
[H60]
P. Halmos. Naive Set Theory. Van Nostrand, 1960.
[Is60]
J. Isbell. Adequate subcategories. Illinois J. Math 4: 541–552, 1960.
[Joh77]
P. T. Johnstone. Topos Theory. Academic Press, 1977.
[JM95]
A. Joyal and I. Moerdijk. Algebraic Set Theory. Cambridge Univer-
sity Press, London Math Soc. Lecture Note Series 220, 1995.
[Kan58]
D. Kan. Adjoint functors. Transactions of the American Mathemati-
cal Society, 87:294–329, 1958.
[KR77]
A. Kock and G. Reyes. Doctrines in categorical logic. Handbook of
Mathematical Logic, North-Holland, 1977.
[La64]
F. W. Lawvere. Elementary Theory of the Category of Sets. Proceed-
ings of the National Academy of Sciences 52:1506–1511, 1964.
[La69a]
F. W. Lawvere. Diagonal arguments and cartesian closed categories.
Lecture Notes in Math, 92:134–145, Springer-Verlag, 1969.
[La69b]
F. W. Lawvere. Adjointness in foundations. Dialectica, 23:281–296,
1969.
[La71]
F. W. Lawvere. Quantiﬁers and sheaves. In Actes du congr`es inter-
national des math´ematiciens, 329–334, Gauthier-Villars, 1971.
[La73]
F. W. Lawvere. Metric spaces, generalized logic and closed cate-
gories. Rendiconti del Seminario Matematico e Fisico di Milano,
43:135–166, 1973.
[LaS97]
F. W. Lawvere and S. H. Schanuel. Conceptual Mathematics. A ﬁrst
introduction to categories. Cambridge University Press, 1997.
[MM92]
S. Mac Lane and I. Moerdijk. Sheaves in Geometry and Logic.
Springer-Verlag, 1992.
[M92]
C. McLarty. Elementary Categories, Elementary Toposes. Oxford
University Press, 1992.
[M87]
E. Mendelson. Introduction to Mathematical Logic. Third edition.
Wadsworth and Brooks/Cole, 1987.
[RW94]
R. Rosebrugh and R. J. Wood. An adjoint characterization of the
category of sets. Proceedings of the American Mathematical Society,
122:409–413, 1994.
[Sup72]
P. Suppes. Axiomatic Set Theory. Dover, 1972.
[T72]
M. Tierney. Sheaf theory and the continuum hypothesis. Lecture
Notes in Math, 274:13–42, Springer-Verlag, 1972.
[Wal91]
R. F. C. Walters. Categories and Computer Science. Cambridge Uni-
versity Press, 1991.

Bibliography
255
Additional References
G. Boole (1815–1864). Collected Logical Works (2 volumes). Chicago: Open Court
Publ. Co., 1916 and 1940.
G. Cantor (1845–1918). Contributions to the Founding of the Theory of Transﬁnite
Numbers. La Salle, Ill.: Open Court Publ. Co., 1952.
R. Dedekind (1831–1916). Gesammelte mathematische Werke. Braunschweig,
1930.
G. Galilei (1564–1642). Discorsi e dimostrazioni matematiche intorno a due nuove
scienze attinenti alla meccanica e i movimenti locali. Leiden: 1638. (“Dis-
courses on Two New Sciences”)
K. G¨odel (1906–1978). The Consistency of the Axiom of Choice and of the Gener-
alized Continuum-Hypothesis with the Axioms of Set-Theory. Annals of Math-
ematics Studies No. 2. Princeton, N.J.: Princeton University Press, 1940.
H. G. Grassmann (1809–1877). Die Ausdehnungslehre, ein neuer Zweig der Math-
ematik. Gesammelte Werke, Ersten Bandes erster Theil (Leipzig: B. G.
Teubner 1894) (Reprint Bronx, N.Y.: Chelsea, 1969).
A. Grothendieck (born 1928). Techniques des constructions en g´eom´etrie analy-
tique. S´eminaire Henri Cartan, 11:1–28, 1960–61.
F. Hausdorff (1869–1942). Das Chaos in kosmischer Auslese, ein erkenntniskritis-
cher Versuch von Paul Mongr´e (pseud.). Leipzig: C. G. Naumann, 1898.
F. Hausdorff. Grundz¨uge der Mengenlehre. Leipzig: Von Veit, 1914.
A. Heyting (1898–1980). Mathematische Grundlagenforschung: Intuitionismus,
Beweistheorie.ErgebnissederMathematikundihrerGrenzgebiete3–4.Berlin:
Springer, 1934.
E. Schr¨oder (1841–1902). Vorlesungen ¨uber die Algebra der Logik (exakte Logik).
Abriss der Algebra der Logik, Bronx, N.Y.: Chelsea Publ. Co., 1966.
T. Skolem (1887–1963). Selected Works in Logic. Edited by Jens Erik Fenstad.
Scandinavian University Books, Oslo: Universitetsforlaget, 1970.
J. Steiner (1796–1863). Gesammelte Werke. Herausgegeben von K. Weierstrass
auf Veranlassung der k¨oniglich-preussischen Akademie der Wissenschaften,
Berlin: G. Reimer, 1881–82.
E. F. Zermelo (1871–1953). Untersuchungen ¨uber die Grundlagen der Mengen-
lehre: I. Math. Annalen 65:261–281, 1908.
M. Zorn (1906–1993). A remark on method in transﬁnite algebra. Bull. Amer. Math.
Soc. 41:667–670, 1935.


Index
Deﬁnitions appear in bold type.
action, 76, 171ff
left A-action, 171
right A-action, 173
addition, 161
adjoint functors, 190, 231, 246
algebraic topology, 232
arithmetic, 160ff
Aristotle, 193
arrow, 10
associative law, 7, 10, 233
automorphism group, 170
averaging, 148ff
axiom for sets:
S is a category, 11, 111
1 separates mappings, 12
binary products, 61
binary sums, 29
Booleanness, 112
choice, 84, 112, 220ff
Dedekind–Peano, 156
exponentiation, 102, 111
ﬁnite colimits, 80, 111
ﬁnite inverse limits, 73, 111
initial set, 12
nondegeneracy of S, 18
terminal set, 6
truth values represent parts, 111
two-valuedness, 112
axiomatic method, ix
Banach–Tarski paradox, 87
belongs to, 37
Bernays, 130
bijective mapping, 8
binary product, 61
Boole, 239
Boolean property, 92
bornological set, 144
bounded part, 144f
Bourbaki
Fixed-Point Theorem, 224
Brouwer, 131, 240
cancellation property, 120
Cantor, v, 129, 242, 245, 247
cardinality, 57
category, 10f
of abstract sets and arbitrary
mappings, 113
of categories, 235, 250
category theory, 233
Cayley, 175, 249
cell of partition, 85
chain, 223
characteristic function,
19, 38, 233
choice, axiom of, 84, 220ff
closed part, 143ff
codomain, 2
257

258
Index
coequalizer, 79
cograph, 2, 8, 29
colimit, 78
colimit axiom, 80
commutative ring, 213, 230
complement, 51, 92
component
of a natural transformation,
241
composite relation, 92, 212
composition, 2, 10, 233
cone, universal, 72
congruence, 95
constant arrow, 22
constant map, 168
continuous category, 52
continuous space, 143
continuum hypothesis, 245, 246
contrapositive statement, 234
contravariant, 103
converse statement, 234
coproduct, 78
coseparator, 18
cospan, 78
co-surjective, 125
coterminal object, 78
covariant functoriality, 103
data type, 71
Dedekind, v, 175, 243, 249
Dedekind-ﬁnite, 58
Dedekind-inﬁnite, 58
Dedekind–Peano axiom, 156
de Morgan’s law, 200
determined by, 37
diagonal
map, 65
functor, 109
argument, Cantor’s, 129ff
Dirac delta, 126
directed poset, 221
distance-decreasing, 145
distributive law, 126ff
in computer science, 134
domain, 2
dual
category, 25
proof, 67
property, 21
duality, concrete, 120ff
dynamical system, 155
Eilenberg, v, 233
element, 6, 235
generalized, 16, 235
elementary topos, 111
empty set, 12
endomapping, 13
entails, 196
versus implies, 198
epimorphism, 80, 235
equality,
rule of inference for, 209
equalizer, 66
equinumerous, 57
equivalence relation, 89
equivalent parts, 40, 138
equivalent categories, 46
equivariant, 77
evaluation, 6, 99
excluded middle, 200
existential quantiﬁer, 201ff
unique, 209
expectation, 149
exponentiation, 98
external diagram, 3
f-chain, 224
family, 5
feedback, 186ff
control, 187
ﬁber, 84
ﬁbered product, 69
ﬁberwise, 45
ﬁeld, 213, 230
ﬁnite state machines,
category of, 24
ﬁnite, Dedekind, 58
ﬁxed point, 131, 224
ﬁxed-point-free, 131

Index
259
ﬁxed-point property, 131
for all, 36, 203
foundation, v, 235
category of categories as, 235
Fourier transform, 126
Fraenkel, 130
free monoid, 77
Frege, 130
function, 236
functionals, 101
functor, 109, 172, 236
representable, 248
functoriality
of products, 98
of function spaces, 102ff
Gaifman, 229
Galileo, 57
generalized
element, 16, 235
point, 150
continuum hypothesis, 246
Giraud, 247
G¨odel, 130
graph, 63, 212
chaotic, 180ff
of a mapping, 63, 211ff
reversible, 176
Grassmann, 239
Grothendieck, 242
topos, 247
groupoid, 170
groups, category of, 24
Hausdorff, 175, 220, 243
Maximal Principle, 226
Heyting, 240
homomorphism, 172
ideal, 230
idempotent, 189, 217
identity
arrow, 10
law, 11
mapping, 4
image, 90, 136
existential quantiﬁcation and,
137, 139, 194, 203ff
implication, 35, 198
inclusion, 34, 237
indexed families, 45
indicator, 38
inference rules, 35, 195ff
inﬁnite, Dedekind, 58
inﬂationary, 224, 228ff
initial object, 12
injective mapping, 8, 238
injective object, 124, 238
integral domain, 216
internal diagram, 2
intersection, 43, 44, 237
of a family, 223
inverse image, 41, 237
inverse limit, 71ff
involution, 168
Isbell, 151
isomorphic, 18
isomorphism, 54
of categories, 185
iteration, 160ff
Kan, 233
left
A action (set), 171
A-set, 171
adjoint, 118
adjoint functor, 231
cancellation, 238
Leibniz rule, 201
lift, 82
limit, 58, 72
Lincoln, 13
linear transformation, 24
listing, 5
localic, 93
logic, 193ff, 239
intuitionistic, 240
objective, 239
positive, 195

260
Index
loop
degenerate, 180
in reﬂexive graph, 180
in reversible graph, 176f
one-lane, 177
lower bound, 221
greatest, 77, 221
M-sets, category of, 77
Mac Lane, v, 233
mapping, 2, 240
mapping set, 98
matrix, 127
maximal object, 221
Maximal Principle
of Hausdorff, 226
of Zorn, 85, 220ff
chain version, 226
directed version, 222
maximum object, 221
measurable cardinals, 151
membership, 34, 241
metric space, 144
monoid, 77, 167
monomapping, 238
monomorphism, 32, 238
morphism, 10
motion, 100
multiplication, 162
natural, 126
isomorphism, 232, 241
map, 172
number object, 156
transformation, 135,
173, 241
negation, 200
nilpotent, 217
number theory, 154ff
object, 10
one element set, 241
one-to-one correspondence, 54
operators, 101
opposite category, 25, 174
order of nilpotency, 217
pairs of sets, category of, 46
parameterization, 5
part, 33, 242
bounded, 144
closed, 143ff
partially ordered sets, category
of, 24
partition, 85
Peano’s postulate, 163
pointed sets, category of, 25, 46
pointwise, 118
posets, 169
arise concretely, 169
strict, 224
power set functor
covariant, 141ff
contravariant, 122ff
predicate, 194
product, 61
property, 5, 17
pullback, 69
pushout, 79
reciprocal, 213
recursion, 157ff
reﬂexive, 88
relation, 87
representable functor, 248
representation of membership, 39
restriction, 40
retraction, 48
right
A action (set), 173
adjoint functor, 231
cancellation, 80, 235
ring, 213
Russell, 130
Schr¨oder, 239, 249
section, 48
self-mapping, 13
separator, 11, 242
set theory, 242
axiomatic, 243
naive, 243
parameterization, 243

Index
261
singleton map, 124, 142
Skolem, 239
slice category, 25
small hom-sets, 250
space, topological, 143
span, 78
sphere, 52
split
image, 89ff
injection, 49
monomapping, 49
surjective, 82
Steenrod, vi, 232
Steiner, 242
sub dynamical system, 164
subposet, 220
subring, 215
substitution, rule of, 209
subtraction, logical, 201
sum, 28
support, 112
splits, 112
supremum, 221
surjective mapping, 8, 244
symmetric, 88
arrow, 149
Tarski, 130, 228
terminal object, 6
set axiom, 6
theory, 154
topological space, 143
topology, algebraic, 232
topos, 244
of abstract sets, 246
and Cantorian contrast, 245
elementary, 111
geometric morphism of, 246
Grothendieck, 247
total order, 223
totally cocomplete, 250
transitive, 89
truth values, 39
represent membership,
39, 111
represent parts, 111
two, 27
union, 247
unique existential quantiﬁer, 211
universal
mapping property, 26, 29
quantiﬁer, 203
upper bound, 221
least, 221
variable
element, 16
sets, 17, 154
two-stage, 114ff
vector spaces, category of, 24
von Neumann, 130
Walters, 134
weakly averaging, 149
well ordered, 227
Well-Ordering
Theorem of Zermelo, 227
well-pointed topos, 113
Yoneda, 175
and totality, 250
embedding, 249
Yoneda’s Lemma, 249
Zermelo, 130, 220
zero object, 45
Zorn, vi, 220ff

