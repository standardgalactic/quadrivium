
GRAPHS: THEORY AND 
ALGORITHMS 


GRAPHS: THEORY AND 
ALGORITHMS 
K. T H U L A S I R A M A N 
Μ. N. S. SWAMY 
Concordia University 
Montreal, Canada 
A Wiley-lnterscience Publication 
JOHN WILEY & SONS, INC. 
New York / 
Chichester / 
Brisbane / Toronto / 
Singapore 

In recognition of the importance of preserving what has been 
written, it is a policy of John Wiley & Sons, Inc., to have books 
of enduring value published in the United States printed on 
acid-free paper, and we exert our best efforts to that end. 
Copyright © 1992 by John Wiley & Sons, Inc. 
All rights reserved. Published simultaneously in Canada. 
Reproduction or translation of any part of this work 
beyond that permitted by Section 107 or 108 of the 
1976 United States Copyright Act without the permission 
of the copyright owner is unlawful. Requests for 
permission or further information should be addressed to 
the Permissions Department, John Wiley & Sons, Inc. 
Library of Congress Cataloging in Publication Data: 
Thulasiraman, K. 
Graphs: theory and algorithms / K. Thulasiraman and M.N.S. Swamy. 
p. 
cm. 
"A Wiley-Interscience publication." 
Includes bibliographical references and index. 
ISBN 0-471-51356-3 
1. Graph theory. 2. Electric networks. 3. Algorithms. 
I. Swamy, Μ. N. S. II. Title. 
QA166.T58 
511'.5-dc20 
1992 
91-34930 
CIP 
10 9 8 7 6 5 4 3 2 1 

Dedicated to Our Parents 
and Teachers 
^ g ^ f t f e i Star ^ 
U 
from Vishwasara Tantra 
Salutations to the Guru who with the collyrium stick of knowledge 
has opened the eyes of one blinded by the disease of ignorance. 


CONTENTS 
PREFACE 
xiii 
1 
BASIC CONCEPTS 
1 
1.1 
Some Basic Definitions / 1 
1.2 
Subgraphs and Complements / 4 
1.3 
Walks, Trails, Paths, and Circuits / 7 
1.4 
Connectedness and Components of a Graph / 9 
1.5 
Operations on Graphs / l l 
1.6 
Special Graphs / 16 
1.7 
Cut-Vertices and Separable Graphs / 19 
1.8 
Isomorphism and 2-Isomorphism / 22 
1.9 
Further Reading / 25 
1.10 
Exercises / 26 
1.11 
References / 29 
2.1 
Trees, Spanning Trees, and Cospanning Trees / 31 
2.2 
Λ-Trees, Spanning Λ-Trees, and Forests / 38 
2.3 
Rank and Nullity / 41 
2.4 
Fundamental Circuits / 41 
2.5 
Cutsets / 42 
2.6 
Cuts / 43 
2 
TREES, CUTSETS, AND CIRCUITS 
31 
vli 

Vlii 
CONTENTS 
2.7 
Fundamental Cutsets / 46 
2.8 
Spanning Trees, Circuits, and Cutsets / 48 
2.9 
Further Reading / 51 
2.10 
Exercises / 51 
2.11 
References / 54 
3 
EULERIAN AND HAMILTONIAN GRAPHS 
3.1 
Eulerian Graphs / 57 
3.2 
Hamiltonian Graphs / 62 
3.3 
Further Reading / 67 
3.4 
Exercises / 68 
3.5 
References / 70 
4 
GRAPHS AND VECTOR SPACES 
4.1 Groups and Fields / 72 
4.2 
Vector Spaces / 74 
4.3 Vector Space of a Graph / 80 
4.4 
Dimensions of Circuit and Cutset Subspaces / 86 
4.5 
Relationship between Circuit and Cutset Subspaces / 
4.6 
Orthogonality of Circuit and Cutset Subspaces / 90 
4.7 
Further Reading / 93 
4.8 Exercises / 94 
4.9 
References / 96 
5 
DIRECTED GRAPHS 
5.1 
Basic Definitions and Concepts / 97 
5.2 
Graphs and Relations / 104 
5.3 
Directed Trees or Arborescences / 105 
5.4 
Directed Eulerian Graphs / 110 
5.5 
Directed Spanning Trees and Directed Euler Trails / 
5.6 
Directed Hamiltonian Graphs / 115 
5.7 
Acyclic Directed Graphs / 118 
5.8 
Tournaments / 119 
5.9 
Further Reading / 121 
5.10 
Exercises / 121 
5.11 
References / 124 

CONTENTS 
iX 
6 
MATRICES OF A GRAPH 
126 
6.1 
Incidence Matrix / 126 
6.2 
Cut Matrix / 130 
6.3 
Circuit Matrix / 133 
6.4 
Orthogonality Relation / 136 
6.5 
Submatrices of Cut, Incidence, and Circuit Matrices / 139 
6.6 
Unimodular Matrices / 145 
6.7 
The Number of Spanning Trees / 147 
6.8 
The Number of Spanning 2-Trees / 151 
6.9 
The Number of Directed Spanning Trees in a Directed 
Graph / 155 
6.10 
Adjacency Matrix / 159 
6.11 
The Coates and Mason Graphs / 163 
6.12 
Further Reading / 172 
6.13 
Exercises / 173 
6.14 
References / 176 
7 
PLANARITY AND DUALITY 
179 
7.1 
Planar Graphs / 179 
7.2 
Euler's Formula / 182 
7.3 
Kuratowski's Theorem and Other Characterizations of 
Planarity / 186 
7.4 
Dual Graphs / 188 
7.5 
Planarity and Duality / 193 
7.6 
Further Reading / 196 
7.7 
Exercises / 196 
7.8 
References / 198 
8 
CONNECTIVITY AND MATCHING 
200 
8.1 
Connectivity or Vertex Connectivity / 200 
8.2 
Edge Connectivity / 207 
8.3 
Graphs with Prescribed Degrees / 209 
8.4 
Menger's Theorem / 213 
8.5 
Matchings / 215 
8.6 
Matchings in Bipartite Graphs / 217 
8.7 
Matchings in General Graphs / 224 
8.8 
Further Reading / 230 
8.9 
Exercises / 231 
8.10 
References / 234 

X 
CONTENTS 
9 
COVERING AND COLORING 
236 
9.1 
Independent Sets and Vertex Covers / 236 
9.2 
Edge Covers / 243 
9.3 
Edge Coloring and Chromatic Index / 245 
9.4 
Vertex Coloring and Chromatic Number / 251 
9.5 
Chromatic Polynomials / 253 
9.6 The Four-Color Problem / 257 
9.7 
Further Reading / 258 
9.8 
Exercises / 259 
9.9 
References / 262 
10 
MATROIDS 
265 
10.1 
Basic Definitions / 266 
10.2 
Fundamental Properties / 268 
10.3 
Equivalent Axiom Systems / 272 
10.4 
Matroid Duality and Graphoids / 276 
10.5 
Restriction, Contraction, and Minors of a Matroid / 282 
10.6 
Representability of a Matroid / 285 
10.7 
Binary Matroids / 287 
10.8 
Orientable Matroids / 292 
10.9 
Matroids and the Greedy Algorithm / 294 
10.10 Further Reading / 298 
10.11 Exercises / 299 
10.12 
References / 303 
11 
GRAPH ALGORITHMS 
306 
11.1 
Transitive Closure / 307 
11.2 
Shortest Paths / 314 
11.3 
Minimum Weight Spanning Tree / 324 
11.4 
Optimum Branchings / 327 
11.5 
Perfect Matching, Optimal Assignment, and Timetable 
Scheduling / 332 
11.6 
The Chinese Postman Problem / 342 
11.7 
Depth-First Search / 346 
11.8 
Biconnectivity and Strong Connectivity / 354 
11.9 
Reducibility of a Program Graph / 361 
11.10 si-Numbering of a Graph / 370 
11.11 Planarity Testing / 373 

CONTENTS 
Xi 
11.12 
Further Reading / 379 
11.13 
Exercises / 380 
11.14 
References / 382 
12 
FLOWS IN NETWORKS 
390 
12.1 
12.2 
12.3 
12.4 
12.5 
12.6 
12.7 
12.8 
12.9 
12.10 
12.11 
12.12 
12.13 
12.14 
The Maximum Flow Problem / 391 
Maximum Flow Minimum Cut Theorem / 392 
Ford-Fulkerson Labeling Algorithm / 396 
Edmonds and Karp Modification of the Labeling 
Algorithm / 400 
Dinic Maximum Flow Algorithm / 404 
Maximal Flow in a Layered Network: The MPM 
Algorithm / 408 
Preflow Push Algorithm: Goldberg and Tarjan / 411 
Maximum Flow in 0-1 Networks / 422 
Maximum Matching in Bipartite Graphs / 426 
Menger's Theorems and Connectivities / 427 
NP-Completeness / 433 
Further Reading / 436 
Exercises / 437 
References / 439 
AUTHOR INDEX 
445 
SUBJECT INDEX 
451 


PREFACE 
In the past two decades graph theory has come to stay as a powerful 
analytical tool in the understanding and solution of large complex problems 
that arise in the study of engineering, computer, and communication 
systems. While its origin is traced to Euler's solution in 1735 of the 
Konigsberg bridge problem, its first application to a problem in physical 
science did not occur until 1847, when Kirchhoff developed the theory of 
trees for its application in the study of electrical networks. The elegance 
with which the graph of an electrical network captures the structural 
relationships between the voltage and current variables of the network has 
led to equally elegant contributions to electrical network theory. One such 
condition is Tellegen's theorem, the application of which in the computation 
of network sensitivities is now well recognized. The theory of network flows 
developed by Ford and Fulkerson in 1956 was the first major application of 
graph theory to operations research. This theory provides the main link 
between graph theory and operations research and continues to be a 
fascinating topic of further research. Computer and communication systems 
are among the recent additions to the growing list of application areas of 
graph theory. Motivated by applications in the design of interconnection 
networks for these systems, in recent years there has been a great deal of 
interest in the design of graphs having specified topological properties such 
as distance, connectivity, and regularity. Fascinated by the challenges 
encountered in the design of efficient algorithms for graph problems, 
theoretical computer scientists have developed in the past two decades a 
large number of interesting and deep graph algorithms adding to the 
richness of graph theory. Theoretical computer scientists have also identified 
the class of graph problems for which "efficient" algorithms are not likely to 
xiii 

XiV 
PREFACE 
exist, giving birth to the theory of NP-Completeness. This is indeed a 
significant contribution of computer science to graph theory. 
Every time a new area of application of graph theory emerged, the need 
arose for the introduction and study of new concepts or a further study of 
several known concepts. This continuous interaction has immensely con-
tributed to the recent explosion of graph theory, which was fairly dormant 
for more than a century after its origin. Thus graph theory is now a vast 
subject with several fascinating branches of its own: enumerative graph 
theory, extremal graph theory, random graph theory, algorithmic graph 
theory, and so on. 
As its name implies, this book is on graph theory and graph algorithms. It 
is addressed to students in engineering, computer science, and mathematics. 
Our choice of topics has been motivated by their relevance to applications. 
Thus we attempt to provide a unified and an in-depth treatment of those 
topics in graph theory and graph algorithms that we believe to be fundamen-
tal in nature and that occur in most applications. Broadly speaking, the 
book may be considered as consisting of two parts dealing with graph theory 
and graph algorithms in that order. 
In the first ten chapters we discuss the theory of graphs. The topics 
discussed include trees, circuits, cutsets, Hamiltonian and Eulerian graphs, 
directed graphs, matrices of a graph, planarity, connectivity, matching, and 
coloring. We have also included an introduction to matroid theory. Among 
the matroid topics presented are Minty's self-dual axiom system, which 
makes obvious the duality between circuits and cutsets of a graph, the arc 
coloring lemma, the greedy algorithm, and its intimate relationship with 
matroids. 
The last two chapters of the book deal with graph algorithms. In Chapter 
11 we discuss several algorithms which are basic in the sense that they serve 
as building blocks in designing more complex algorithms. In most cases the 
algorithms of Chapter 11 are based on results and concepts presented in 
earlier chapters. In certain cases we also introduce and discuss new concepts 
such as branching and graph reducibility. In Chapter 12 we develop the 
theory of network flows. We start with the maximum flow minimum cut 
theorem of Ford and Fulkerson and then proceed to develop several 
algorithms for the maximum flow problem, culminating with the recent work 
of Goldberg and Tarjan. In this chapter we also show how the network flow 
technique can be used to develop connectivity and matching algorithms as 
well as prove Menger's theorems on connectivities. We conclude Chapter 12 
with a brief introduction to the theory of NP-Completeness. While develop-
ing the algorithms of Chapters 11 and 12 we pay particular attention to the 
proof of correctness and complexity analysis of the algorithms. 
The book can be used to organize different courses to suit the needs of 
different groups of students. The first ten chapters contain adequate materi-
al for a one-semester course on graph theory at the senior or beginning 
graduate level. The authors have taught for several years a course on graph 

PREFACE 
XV 
theory with system applications based on the first seven chapters and a 
selection of topics from the remaining chapters. The last two chapters and 
appropriate background material selected from the other chapters can serve 
as the core of a course on algorithmic graph theory. These two chapters can 
also serve as supplemental material for a general course on design and 
analysis of algorithms. 
Several colleagues and students have assisted us in the writing of this 
book. Raghu Prasad Chalasani, Concordia University; Joseph Cheriyan, 
Cornell University; Anindya Das, University of Montreal; 
Andrew 
Goldberg, Stanford University; R. Jayakumar, Concordia University; V. 
Krishnamoorthy, Anna University, Madras (India); and N. Srinivasan, 
University of Madras deserve special thanks. We are greatful to Anindya 
Das, Joseph Cheriyan, and Andrew Goldberg for their careful reading of 
the last chapter of the book and drawing our attention to recent develop-
ments on the maximum flow problem. 
It is a pleasure to thank the following organizations for their support to 
our research leading to the preparation of the book: Natural Sciences and 
Engineering Research Council of Canada; Fonds pour la Formation de 
Chercheurs et Γ Aide a la Recherche (FCAR), Quebec; Bell Northern 
Research Laboratory, Ottawa; Centre de Recherche Informatique de Mon-
treal, Montreal; German National Science Foundation; and the Japan 
Society for Promotion of Science. 
Finally we thank our wives—Santha Thulasiraman and Leela Swamy— 
and our children for their patience and understanding during the entire 
period of our efforts. 
K. THULASIRAMAN 
Μ. N. S. SWAMY 

It is probably fair to say, and has been said before by many others, that 
graph theory began with Euler's solution in 1735 of the class of problems 
suggested to him by the Konigsberg bridge puzzle. But had it not started 
with Euler, it would have started with Kirchhoff in 1847, who was motivated 
by the study of electrical networks; had it not started with Kirchhoff, it 
would have started with Cayley in 1857, who was motivated by certain 
applications to organic chemistry, or perhaps it would have started earlier 
with the four-color map problem, which was posed to De Morgan by 
Guthrie around 1850. And had it not started with any of the individuals 
named above, it would almost surely have started with someone else, at 
some other time. For one has only to look around to see "real-world 
graphs" in abundance, either in nature (trees, for example) or in the works 
of man (transportation networks, for example). Surely someone at some 
time would have passed from some real-world object, situation, or problem 
to the abstraction we call graphs, and graph theory would have been born. 
D. R. Fulkerson 
(From Preface to Studies in Graph Theory, Part II, 
The Mathematical Association of America, 1975) 

CHAPTER 1 
BASIC CONCEPTS 
We begin our study with an introduction in this chapter to several basic 
concepts in the theory of graphs. A few results involving these concepts will 
be established. These results, while illustrating the concepts, will also serve 
to introduce the reader to certain techniques commonly used in proving 
theorems in graph theory. 
1.1 
SOME BASIC DEFINITIONS 
A graph G = (V, E) consists of two sets: a finite set V of elements called 
vertices and a finite set Ε of elements called edges. Each edge is identified 
with a pair of vertices. If the edges of a graph G are identified with ordered 
pairs of vertices, then G is called a directed or an oriented graph. Otherwise 
G is called an undirected or a nonoriented graph. Our discussions in the first 
four chapters of this book are concerned with undirected graphs. 
We use the symbols vl,v2,v3,... 
to represent the vertices and the 
symbols e,, e2, e 3 , . . . to represent the edges of a graph. The vertices v, and 
vt associated with an edge e, are called the end vertices of et. The edge e, is 
then denoted as e, = (υ,, υ,). Note that while the elements of Ε are distinct, 
more than one edge in Ε may have the same pair of end vertices. All edges 
having the same pair of end vertices are called parallel edges. Further, the 
end vertices of an edge need not be distinct. If e, = (ν,,ν,), 
then the edge e, 
is called a self-loop at vertex v,. A graph is called a simple graph if it has no 
parallel edges or self-loops. A graph G is of order η if its vertex set has η 
elements. 
1 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

2 
BASIC CONCEPTS 
A graph with no edges is called an empty graph. A graph with no vertices 
(and hence no edges) is called a null graph. 
Pictorially a graph can be represented by a diagram in which a vertex is 
represented by a dot or a circle and an edge is represented by a line segment 
connecting the dots or the circles, which represent the end vertices of the 
edge. For example, if 
V={v1,v2,v3,v4,v5,v6} 
and 
Ε — {e^, e*2, e3, e^, c 5} , 
such that 
*\ = 
(νχ,ν2), 
e3 = (v5, 
υ6), 
e 4
 
= (^i, 
v2), 
then the graph G = (Κ, E) is represented as in Fig. 1.1. In this graph ex and 
e 4 are parallel edges and e5 is a self-loop. 
An edge is said to be incident on its end vertices. Two vertices are 
adjacent if they are the end vertices of some edge. If two edges have a 
common end vertex, then these edges are said to be adjacent. 
For example, in the graph of Fig. 1.1, edge e, is incident on vertices u, 
and v2; w, and i>4 are two adjacent vertices, while e, and e2 are two adjacent 
edges. 
The number of edges incident on a vertex y, is called the degree of the 
vertex, and it is denoted by d(u,). Sometimes the degree of a vertex is also 
Figure 1.1. Graph G = (V,E). 
V= {vu v2, v„ v4, vs, υ6}; Ε = {*„ e2, e3, e„ e5}. 

SOME BASIC DEFINITIONS 
3 
referred to as its valency. A vertex of degree 1 is called a pendant 
vertex. 
The only edge incident on a pendant vertex is called a pendant edge. A 
vertex of degree 0 is called an isolated vertex. By definition, a self-loop at a 
vertex v, contributes 2 to the degree of υ,. 5(G) and A(G) denote, 
respectively, the minimum and maximum degrees in G. 
In the graph G of Fig. 1.1 
d(v,) = 3 , 
d(v2) = 2 , 
d(v3) = 0, 
d(v4) = 1, 
d(v5) = 3 , 
d(v6) = 1 . 
Note that u 3 is an isolated vertex, u 4 and v6 are pendant vertices, and e2 is a 
pendant edge. For G it can be verified that the sum of the degrees of the 
vertices is equal to 10, whereas the number of edges is equal to 5. Thus the 
sum of the degrees of the vertices of G is equal to twice the number of edges 
of G and hence an even number. It may be further verified that in G the 
number of vertices of odd degree is also even. These interesting results are 
not peculiar to the graph of Fig. 1.1. In fact, they are true for all graphs as 
the following theorems show. 
Theorem 1.1. The sum of the degrees of the vertices of a graph G is equal 
to 2m, where m is the number of edges of G. 
Proof. Since each edge is incident on two vertices, it contributes 2 to the 
sum of the degrees of the graph G. Hence all the edges together contribute 
2m to the sum of the degrees of G. 
• 
Theorem 1.2. The number of vertices of odd degree in any graph is even. 
Proof. Let the number of vertices in a graph G be equal to n. Let, without 
any loss of generality, the degrees of the first r vertices υ,, v2,..., 
vr be 
even and those of the remaining η - r vertices be odd. Then 
Σ <*(!>,) = Σ <*(«,)+ Σ d(Vl). 
(i.i) 
1=1 
ι - l 
i = r + l 
By Theorem 1.1, the sum on the left-hand side of (1.1) is even. The first 
sum on the right-hand side is also even because each term in this sum is 
even. Hence the second sum on the right-hand side should be even. Since 

4 
BASIC CONCEPTS 
each term in this sum is odd, it is necessary that there be an even number of 
terms in this sum. In other words, η - r, the number of vertices of odd 
degree, should be even. 
• 
1.2 
SUBGRAPHS AND COMPLEMENTS 
Consider a graph G = (V, E). G' = (V, E') is a subgraph of G if V and E' 
are, respectively, subsets of V and Ε such that an edge (υ,, υ) is an E' only 
if v, and vl are in V. G' will be called a proper subgraph of G if either E' is 
a proper subset of Ε or V is a proper subset of V. If all the vertices of a 
graph G are present in a subgraph G' of G, then G' is called a spanning 
subgraph of G. 
For example, consider the graph G shown in Fig. 1.2a. The graph G' 
shown in Fig. 1.2ft is a subgraph of G. Its vertex set is {u,, v2, v4, v5). In 
fact, it is a proper subgraph of G. The graph G" of Fig. 1.2c is a spanning 
subgraph of G. 
Some of the vertices in a subgraph may be isolated vertices. For example, 
the graph G'" shown in Fig. 1.2d is a subgraph of G with an isolated vertex. 
Figure 1.2. A graph and some of its subgraphs, (a) Graph G. (Z>) Subgraph G'. (c) 
Subgraph G". (d) Subgraph G'". 

SUBGRAPHS AND COMPLEMENTS 
5 
If a subgraph G' = (V, Ε') of a graph G has no isolated vertices, then it 
can be seen from the definition of a subgraph that every vertex in V is the 
end vertex of some edge in Ε'. Thus in such a case, E' uniquely specifies V 
and hence the subgraph G'. The subgraph G' is then called the induced 
subgraph of G on the edge set E' (or simply edge-induced subgraph of G) 
and is denoted as 
(Ε'). 
Note that the vertex set V of (Ε') is the smallest subset of V containing 
all the end vertices of the edges in Ε'. The subgraphs G' and G" of Fig. 1.2ft 
and c are edge-induced subgraphs of the graph G of Fig. 1.2a, whereas G'" 
shown in Fig. \.2d is not an edge-induced subgraph. 
Next we define a vertex-induced subgraph. 
Let V be a subset of the vertex set V of a graph G = (V, E). Then the 
subgraph G' = (V, Ε') is the induced subgraph of G on the vertex set V (or 
simply vertex-induced subgraph of G) if E' is a subset of Ε such that edge 
(υ,, Vj) is in E' if and only if v, and u; are in V. In other words, if v, and v, 
are in V, then every edge in Ε having υ, and υ as its end vertices should be 
in Ε'. Note that, in this case, V 
completely specifies E' and thus the 
subgraph G'. Hence the vertex-induced subgraph G' = (V, Ε') is denoted 
simply as (V). 
As an example, the graph shown in Fig. 1.3 is a vertex-
induced subgraph of the graph G of Fig. 1.2a. 
Note that the edge set E' of the vertex-induced subgraph on the vertex 
set V is the largest subset of Ε such that the end vertices of all of its edges 
are in V. 
Unless otherwise stated, an induced subgraph will refer to a vertex-
induced subgraph. 
A subgraph G' of a graph G is said to be a maximal subgraph of G with 
respect to some property Ρ if G' has the property Ρ and G' is not a proper 
subgraph of any other subgraph of G having the property P. 
A subgraph G' of a graph G is said to be a minimal subgraph of G with 
respect to some property PUG' 
has the property Ρ and no subgraph of G 
having the property Ρ is a proper subgraph of G'. 
Maximal and minimal subsets of a set with respect to a property are 
defined in a similar manner. 
For example, the vertex set V of an edge-induced subgraph (Ε') 
of a 
graph G = (V, E) is a minimal subset of V containing the end vertices of all 
»5 of the graph G of Fig. 1.2a. 
Figure 1.3. A vertex-induced subgraph 

6 
BASIC CONCEPTS 
the edges of E'. On the other hand, the edge set E' of a vertex-induced 
subgraph ( V ) is the maximal subset of Ε such that the end vertices of all of 
its edges are in V. 
Later we shall see that a "component" (Section 1.4) of a graph G is a 
maximal "connected" subgraph of G, and a "spanning tree" (Chapter 2) of 
a connected graph G is a minimal "connected" spanning subgraph of G. 
Next we_ define the complement of a graph. 
Graph G = (V, E') is called the complement of a simple graph G = (V, E) 
if the edge (vt, vt) is in E' if and_only if it is not in E. In other words two 
vertices u, and vf are adjacent in G if and only if they are not adjacent in G. 
A graph and its complement are shown in Fig. 1.4. As another example, 
consider the graph G shown in Fig. 1.5e. In this graphjthere is an edge 
between every pair of vertices. Hence in the complement G of G there will 
Figure 1.4. A graph and its comple-
ment, (a) Graph G. (b) Graph G, com-
plement of G. 
» * 0 
0 » 5 
(61 
Figure 1.5. A graph and its comple-
ment, (a) Graph G. (b) Graph G, com-
plement of G. 

WALKS, TRAILS, PATHS, AND CIRCUITS 
7 
be no edge between any pair of vertices; that is, G will contain only isolated 
vertices. This is shown in Fig. 1.5ft. 
Let G' = (V, Ε') be a subgraph of a graph G = (V, E). The subgraph 
G" = (V, Ε - Ε') of G is called the complement of G' in G. For example, in 
Fig. 1.2, subgraph G" is the complement of G' in the graph G. 
The following example illustrates some of the ideas presented thus far. 
Suppose we want to prove the following: 
At any party with six people there are three mutual acquaintances or 
three mutual nonacquaintances. 
Representing people by the vertices of a graph and acquaintance relation-
ship among the people by edges connecting the corresponding vertices, we 
can see that the above assertion can also be stated as follows: 
In any simple graph G with six vertices there are three mutually adjacent 
vertices or three mutually nonadjacent vertices. 
In view of the definition of the complement of a graph, we see that the 
above statement is equivalent to the following: 
_ 
For any simple graph G with six vertices, G or G contains three mutually 
adjacent vertices. 
To prove this, we may proceed as follows: 
Consider any vertex ν of a simple graph G with six vertices. Note that if υ 
is not adjacent to three vertices in G, then it will be adjacent to three 
vertices in G. So, without any loss of generality, we may assume that, in G, 
υ is adjacent to some three vertices vt, v2, and u 3. If any two of these 
vertices, say vi and v2, are adjacent in G, then the vertices ν, υι, and υ2 are 
mutually adjacent in G, and the assertion is proved. 
If no two of the three vertices vlt 
v2, and v3 are adjacent in G, then it 
means that u,, v2, and v3 are mutually nonadjacent in G. Hence, by the 
definition of a complement, the vertices vt, v2, and v3 are mutually adjacent 
in G, and the assertion is again proved. 
1.3 
WALKS, TRAILS, PATHS, AND CIRCUITS 
A walk in a graph G = (V, E) is a finite alternating sequence of vertices and 
edges v0, eu vu e2,..., 
vk_l, 
ek, vk beginning and ending with vertices such 
that v,_x and vt are the end vertices of the edge en l ^ i ^ k. Alternately, a 
walk can be considered as a finite sequence of vertices v0, v,, 
v2,...,vk, 
such that (y,_i, ι>,), 1 ^ ι 
k, is an edge in the graph G. This walk is usually 
called a v0-vk 
walk with υ0 and vk referred to as the end or terminal vertices 
of this walk. All other vertices are internal vertices of this walk. Note that in 
a walk, edges and vertices can appear more than once. 
A walk is open if its end vertices are distinct; otherwise it is closed. 
In the graph G of Fig. 1.6, the sequence i>,, e1, v2, e2, u 3, es, v6, e9, 
vs, 
e7,v3,eu,v6 
is an open walk, whereas the sequence 
v1,el,v2,e3,v5,e7,v3, 
e2, v2, e,, u, is a closed walk. 

8 
BASIC CONCEPTS 
Ίο 
»7 
Figure 1.6. Graph G. 
A walk is a trail if all its edges are distinct. A trail is open if its end 
vertices are distinct; otherwise, it is closed. In Fig. 1.6, u,, ex, v2, e2, v3, 
es, 
v6, e u , v3 is an open trail, whereas υ,, e,, v2, e2, v3, e7, v5, e3, v2, e4, u 4, e5, 
y, is a closed trail. 
An open trail is a path if all its vertices are distinct. 
A closed trail is a circuit if all its vertices except the end vertices are 
distinct. 
For example, in Fig. 1.6 the sequence u,, e,, v2, e2, v3 is a path, whereas 
the sequence v,, e,, v2, e3, v5, e6, v4, e5, υ, is a circuit. 
An edge of a graph G is said to be a circuit edge of G if there exists a 
circuit in G containing the edge. Otherwise the edge is called a noncircuit 
edge. In Fig. 1.6, all edges except en are circuit edges. 
The number of edges in a path is called the length of the path. Similarly 
the length of a circuit is defined. 
A path is even if it is of even length; otherwise it is odd. Similarly even 
and odd circuits are defined. 
The distance between two vertices u and ν in G, denoted by d(u, υ), is 
the length of the shortest u-υ path in G. If no such path exists, then we 
define d(u, v) to be infinite. The diameter of G, denoted by diam(G), is the 
maximum distance between any two vertices of G. 
The following properties of paths and circuits should be noted: 
1. In a path the degree of each vertex that is not an end vertex is equal to 
2; the end vertices have degrees equal to 1. 
2. In a circuit every vertex is of degree 2, and so of even degree. The 
converse of this statement, namely, the edges of a subgraph in which 

CONNECTEDNESS AND COMPONENTS OF A GRAPH 
9 
every vertex is of even degree form a circuit, is not true. A more 
general question is discussed in Chapter 3. 
3. In a path the number of vertices is one more than the number of 
edges, whereas in a circuit the number of edges is equal to the number 
of vertices. 
1.4 
CONNECTEDNESS AND COMPONENTS OF A GRAPH 
An important concept in graph theory is that of connectedness. 
Two vertices v, and vt are said to be connected in a graph G if there exists 
a v-vJ 
path in G. A vertex is connected to itself. 
A graph G is connected if there exists a path between every pair of 
vertices in G. 
For example, the graph of Fig. 1.6 is connected. 
Consider a graph G = (V, E) which is not connected. Then the vertex set 
V of G can be partitioned
t into subsets V , , V 2 , . . . , V 
such that the 
vertex-induced subgraphs (V,), i = 1,2,..., p, are connected and no vertex 
in subset V, is connected to any vertex in subset Vf, / # i. The subgraphs 
(Vt), 
i = 1, 2 , . . . , p, are called the components of G. It may be seen that a 
component of a graph G is a maximal connected subgraph of G; that is, a 
component of G is not a proper subgraph of any other connected subgraph 
of G. 
For example, the graph G of Fig. 1.7 is not connected. Its four compo-
nents Gl, G2, G3, and G 4 have vertex sets {vt, υ2, ν3}, (ι>4, υ5}, {v6, 
υΊ, 
u g}, and {υ9}, respectively. 
Note that an isolated vertex by itself should be treated as a component 
since, by definition, a vertex is connected to itself. Further, note that if a 
graph G is connected, it has only one component that is the same as G itself. 
We next consider some properties of connected graphs. 
Figure 1.7. Graph G with components G,, G 2, G 3, and G 4. 
Ά set V is said to be partitioned into subsets V,, V2,..., Vp if V, U V2 U · · · U Vp = V and 
V, Π V, = 0 for all i and /, iV /'. {V,, V 2,..., V,,} is then called a partition of V. 

10 
BASIC CONCEPTS 
Theorem 1.3. In a connected graph, any two longest paths have a common 
vertex. 
Proof. Consider any two longest paths P, and P2 in a connected graph G. 
Let P, be denoted by the vertex sequence υ0,υί,υ2,... 
,vk and P2 by the 
sequence v'Q, v\, 
v'2,...,v'k. 
Assume that P, and P2 have no common vertex. Since the graph G is 
connected, then for some i,0<i<k 
and some j,0<j<k 
there exists a 
υ,-v'j path Pa such that all the vertices of Pa other than vt and υ'} are different 
from those of Pl and P2. The paths P,, P2, and Pa may be as shown in Fig. 
1.8. Let 
/, = length of v0-v, path P u , 
t2 = length of v-vk 
path 
Pl2, 
/[ = length of ι>ό-ι>'; path P 2 1 , 
t'2 = length of v'-v'k path 
P22, 
ta = length of path P f l. 
The paths P n , P 1 2, P 2 1 , and P 2 2 are also shown in Fig. 1.8. Note that 
f, + t2 = t[ + t'2 = length of a longest path in G 
and 
ta>0. 
Path P, 
•'it 
i" 21 
* ^ 
' i J 
Path P2 
Figure 1.8. Paths P,, P 2 and P„. 

OPERATIONS ON GRAPHS 
11 
Without any loss of generality, let 
and 
t' > t' 
so that 
Ί + ' ! 2= i, + t 2 = t\ 
+t2. 
Now it may be verified that the paths Pn, Pa, and P2i together constitute 
a v0-v'0 path with its length equal to /, + t[ + ta > i, + t2 because /„ > 0. This 
contradicts that r, + t2 is the length of a longest path in G. 
• 
The following theorem is a very useful one; it is used often in the 
discussions of the next chapter. In this theorem as well as in the rest of the 
book, we abbreviate {x} to χ whenever it is clear that we are referring to a 
set rather than an element. 
Theorem 1.4. If a graph G = (V, E) is connected, then the graph G' = 
(V, Ε — e) that results after removing a circuit edge e is also connected. 
• 
We leave the proof of this theorem as an exercise. 
1.5 
OPERATIONS ON GRAPHS 
In this section we introduce a few operations involving graphs. The first 
three operations are binary operations involving two graphs, and the last 
four are unary operations, that is, operations defined with respect to a single 
graph. 
Consider two graphs, G, = (V,, Ej) and G 2 = (V 2, E2). The union of G, 
and G 2, denoted as G, U G 2, is the graph G 3 = (V, U V2, El U E2)\ that is, 
the vertex set of G 3 is the union of Vl and V2, and the edge set of G 3 is the 
union of £, and E2. 
For example, two graphs G, and G 2 and their union are shown in Fig. 
1.9a, b and c. 
The intersection of G, and G2, 
denoted as G, Π G2, 
is the graph 
G 3 = (V, Π V2, Ε, Π E2). That is, the vertex set of G 3 consists of only those 
vertices present in both Gl and G 2, and the edge set of G 3 consists of only 
those edges present in both G, and G 2. 
The intersection of the graphs G, and G 2 of Fig. 1.9a and 1.96 is shown 
in Fig. l.9d. 

12 
BASIC CONCEPTS 
(6) 
"1 
o-
(c) 
" t o 
Figure 1.9. Union, intersection, and ring sum operations on graphs, (a) Graph G,. 
(b) Graph G2. (c) G, U G2. (<*) G, Π G2. (e) G, Θ G2. 

OPERATIONS ON GRAPHS 
13 
"5 
(e) 
Figure 1.9. (Continued) 
The ring sum of two graphs G, and G 2, denoted as G , © G 2 , is the 
induced graph G 3 on the edge set £, Θ E2. 
In other words G 3 has no 
isolated vertices and consists of only those edges present either in G, or in 
G 2, but not in both. The ring sum of the graphs of Fig. 1.9a and 1.96 is 
shown in Fig. 1.9e. 
It may be easily verified that the three operations defined are commuta-
tive, that is, 
G, U G 2 = G 2 U G, , 
GxnG2= 
G2DGl 
, 
Gj Φ G 2 = G 2 φ G, . 
Also note that these operations are binary, that is, they are defined with 
respect to two graphs. Of course, the definitions of these operations can be 
extended in an obvious way to include more than two graphs. 
Next we discuss four unary operations on a graph. 
Vertex Removal 
If v, is a vertex of a graph G = (V, E), then G — υ, is the 
induced subgraph of G on the vertex set V—υ,; that is, G - v, is the 
graph obtained after removing from G the vertex υ, and all the edges 
incident on vr 
Edge Removal 
If e, is an edge of a graph G = (V, E), then G - e, is the 
' Note that £, θ £ 2 = (£, - E2) U (£ 2 - £,). 

14 
BASIC CONCEPTS 
subgraph of G that results after removing from G the edge e,. Note that 
the end vertices of e, are not removed from G. 
The removal of a set of vertices or edges from a graph is defined as the 
removal of single vertices or edges in succession. 
If G, = (V, Ε') is a subgraph of the graph G = (V, E), then by G - G, 
(c) 
Figure 1.10. Vertex and edge removal operations on a graph, (a) G. (b) G - u , . 
(c) 
G-{e7,es). 

OPERATIONS ON GRAPHS 
15 
we refer to the graph G' = (V, Ε - Ε'). Thus G — G, is the complement in 
G of the subgraph G,. 
The vertex removal and edge removal operations are illustrated in Fig. 
1.10. 
The short-circuiting or identifying operation to be considered next is a 
familiar one for electrical engineers. 
Short-Circuiting or Identifying A pair of vertices v, and v] in a graph G are 
said to be short-circuited (or identified) if the two vertices are replaced by 
a new vertex such that all the edges in G incident on v, and i»; are now 
incident on the new vertex. For example, short-circuiting v3 and v4 in the 
graph of Fig. 1.11a results in the graph shown in Fig. 1.11ft. 
Contraction By contraction of an edge e we refer to the operation of 
removing e and identifying its end vertices. A graph G is contractible to a 
graph Η ύ Η can be obtained from G by a sequence of contractions. For 
example, the graph shown in Fig. 1.11c is obtained by contracting the 
edges e, and e 5 of the graph G in Fig. 1.11a. 
«61 
Figure 1.11. Short-circuiting and contracting in a graph, (a) Graph G. (ft) Graph G 
after short-circuiting i>3 and v4. (c) Graph G after contracting e, and e5. 

16 
BASIC CONCEPTS 
1.6 
SPECIAL GRAPHS 
Certain special classes of graphs that occur frequently in the theory of 
graphs are introduced next. 
A complete graph G is a simple graph in which every pair of vertices is 
adjacent. If a complete graph G has η vertices, then it will be denoted by 
Kn. It may be seen that K„ has n(n - l)/2 edges. As an example, the graph 
K5 is shown in Fig. 1.12. 
A graph G is regular if all the vertices of G are of equal degree. If G is 
regular with d(v,) = r for all vertices υ, in G, then G is called r-regular. A 
4-regular graph is shown in Fig. 1.13. It may be noted that Kn is an 
(n - l)-regular graph. 
A graph G = (V, E) is bipartite if its vertex set V can be partitioned into 
two subsets K, and V2 such that each edge of Ε has one end vertex in Vl and 
another in V2; (V,, V2) is referred to as a bipartition of G. If in a simple 
bipartite graph G, with bipartition ( V , , ^ ) , there is an edge (υ,-,υ,) for 
every vertex υ, in V, and every vertex u; in V2, then G is called a complete 
bipartite graph and will be denoted by Kmn if Vi has m vertices and V2 has η 
vertices. 
A bipartite graph and the complete bipartite graph K3 4 are shown in Fig. 
1.14. 
A graph G = (V, E) is k-partite if it is possible to partition V into k 
subsets V,, V2,..., Vk such that each edge of G has one end vertex in some 
Vl and the other in some Vt, ΪΦ j . A complete k-partite graph G is a simple 
fc-partite graph with vertex set partition {V,, V2,..., Vk) and with the 
additional property that for every vertex u, in Vr and every vertex υ ; in Vs, 
r¥=s, l < r , 5 < / c , (vt, uy) is an edge in G. A complete 3-partite graph is 
shown in Fig. 1.15. 
Figure 1.12. Graph Ks. 
Figure 1.13. A 4-regular graph. 

SPECIAL GRAPHS 
17 
(/>) 
Figure 1.14. (a) A bipartite graph, (b) The complete bipartite graph 
K34. 
We conclude this section with a useful characterization of bipartite 
graphs. 
Theorem 1.5. A graph with η =: 2 vertices is bipartite if and only if it 
contains no circuits of odd length. 
Proof 
Necessity 
Let G = (V, E) be a bipartite graph with bipartition (X, Y). 
Consider any circuit C of G. Suppose that we traverse C starting from a 
vertex, say v0, of G. Without loss of generality, let v0 be in X. Since the 
circuit terminates in X, it follows that every time we traverse an edge (u f, vt) 
with υ, in X and vf in Y, then there will be an untraversed edge 
vk) of C 
with vk in Χ Thus at the end of the traversal we shall have traversed an 
even number of edges and so C is of even length. 

18 
BASIC CONCEPTS 
Figure 1.15. A complete 3-partite graph. 
Sufficiency 
Let G = (V, E) be a graph with η > 2 vertices and with no 
circuits of odd length. Without loss of generality, assume that G is con-
nected. Pick any vertex uolG 
and define a partition (X, Y) of V as follows: 
X = {x\d(u, x) is even}, 
y = {y\d(u, y) is odd} . 
Clearly χ is in X. We now show that (X, Y) is a bipartition of G. Consider 
any two vertices ν and w in X. We need to show that υ and w are not 
adjacent in G. Assume the contrary and let e = (υ, w) denote an edge 
connecting υ and w in G. Let P, be a shortest u-υ path and P 2 be a shortest 
u-w path. Since both υ and w are in X, these paths are, by definition, of 
even lengths. As we traverse P, and P 2 starting from u, let Λ: be the last 
vertex common to P, and P 2. Since Px and P 2 are shortest paths, the u-x 
sections of these paths are of the same length. Thus the x-v section of P, 
and the x-w section of P 2 are both even or are both odd. Therefore, if we 
concatenate them, then we would get an even path connecting υ and w. This 

CUT-VERTICES AND SEPARABLE GRAPHS 
19 
path and the edge e = (v, w) would then produce a circuit of odd length in 
G. This is contrary to the hypothesis that G has no odd circuits. Therefore 
no two vertices of X are adjacent in G. 
In a similar manner we can show that no two vertices of Y are adjacent. 
Thus G is a bipartite graph with bipartition (X, Y). 
• 
1.7 
CUT-VERTICES AND SEPARABLE GRAPHS 
A vertex u, of a graph G is a cut-vertex of G if the graph G - v, consists of a 
greater number of components than G. If G is connected, then G - vt will 
contain at least two components, that is, G - v, will not be connected. 
According to this definition, an isolated vertex is not a cut-vertex. 
We call a graph trivial if it has only one vertex. Thus a trivial graph has 
no cut-vertex. 
A nonseparable graph is a connected graph with no cut-vertices. All other 
graphs are separable. (Note that a graph that is not connected is separable.) 
The graph G shown in Fig. 1.16a is separable. It has three cut-vertices u t, 
v2, and u 3. 
A block of a separable graph G is a maximal nonseparable subgraph of 
G. The blocks of the separable graph G of Fig. 1.16a are shown in Fig. 
1.166. 
The following theorem presents an equivalent definition of a cut-vertex. 
Theorem 1.6. A vertex ν is a cut-vertex of a connected graph G if and only 
if there exist two vertices u and w distinct from υ such that υ is on every u-w 
path. 
Proof 
Necessity 
Since υ is a cut-vertex of G, G - υ is, by definition, not 
connected. Let G, be one of the components of G - v. Let 
be the vertex 
set of G, and V2 the complement of V, in V- v. 
Let u and w be two vertices such that u is in Vx and w is in V2. Consider 
any u-w path in G. If the cut-vertex υ does not lie on this path, then this 
path is also in G - u; that is, the vertices u and w are connected in G - v. 
However, this is a contradiction since u and w are in different components 
of G - v. Hence the vertex ν lies on every u-w path. 
Sufficiency 
If υ is on every u-w path, then the vertices u and w are not 
connected in G - v. Thus the graph G - υ is not connected. Hence, by 
definition, υ is a cut-vertex. 
• 
An equivalent definition of a separable graph follows from Theorem 1.6: 
A connected graph G is separable if and only if there exists a vertex ν in 
G such that it is the only vertex common to two proper nontrivial subgraphs 
G, and G 2 whose union is equal to G. 

20 
BASIC CONCEPTS 
δ » . 
(b) 
Figure 1.16. A separable graph and its blocks, (a) A separable graph G. (ϋ>) Blocks 
of G. 
Suppose a graph G is separable. Is it possible that all the vertices of G are 
cut-vertices? The answer is "no" as we prove in the next theorem. 
Theorem 1.7. Every nontrivial connected graph contains at least two ver-
tices that are not cut-vertices. 
Proof. Consider a nontrivial connected graph G. Let u and υ be two 
vertices of G such that d(u, v) = diam(G). We claim that neither u nor υ is a 

CUT-VERTICES AND SEPARABLE GRAPHS 
21 
cut-vertex of G. Suppose, on the contrary, that one of u and v, say v, is a 
cut-vertex of G. Then let w be a vertex belonging to a component of G — υ 
not containing u. Since very u-w path contains v, it follows that 
d{u, w) > d(u, v) = diam(G). 
A contradiction, since diam(G) is the maximum distance between any two 
vertices in G. Hence υ is not a cut-vertex. Similarly, u is also not a 
cut-vertex. Thus the desired result follows. 
• 
A family of u-v paths in a graph G is said to be internally disjoint if no 
vertex of G is an internal vertex of more than one of these paths. In the 
following theorem due to Whitney [1.1], we present an important characteri-
zation of a block. 
Theorem 1.8 (Whitney). A graph G with η > 3 vertices is a block if and only 
if any two vertices of G are connected by at least two internally disjoint 
paths. 
Proof 
Necessity 
Let G be a block. Consider any two vertices u and ν with 
distance d(u, υ). We prove that there are at least two internally disjoint u-v 
paths. Proof is by induction on d(u, v). 
Consider, first, the case d(u, v) = l. Clearly in this case u and ν are 
adjacent. Let e = (u, v). Since G is a block, it has no cut-vertices. In 
particular, neither u nor υ is a cut-vertex. So the graph G - e is connected 
and there is a u - υ path in G not containing the edge e. In other words G 
has two internally disjoint u-v paths whenever d(u, v) = 1. 
Assume that for any two vertices at distance less than k, there are at least 
two internally disjoint paths between these two vertices. Let d(u, v) = k 2:2. 
Consider a u-v path of length k and let w be the last vertex that precedes ν 
on this path. Then d(u, w) = k - 1, and so by the induction hypothesis there 
are two internally disjoint u-w paths Ρ and Q in G. If one of these paths 
contains v, then clearly G has two internally disjoint u-v paths. 
Suppose that neither Ρ nor Q contains v. Since G is a block, G - w is 
connected. So, in G there is a u - ν path P* that does not contain w. Let χ 
be the last vertex of P* that is also in one of the two paths Ρ and Q. Since u 
is present in all these three paths such a vertex χ exists. Without loss of 
generality, assume that χ is in P. Then, G has two internally disjoint u-v 
paths; one of them is a concatenation of the u-x section of Ρ and the x-v 
section of P* and the other is obtained by adding the edge (w, v) to Q. 
Sufficiency 
If any two vertices of G are connected by at least two 
internally disjoint paths, then clearly G is connected and also, by Theorem 
1.6, G has no cut-vertex. Hence G is a block. 
• 

22 
BASIC CONCEPTS 
Several equivalent characterisations of a block are given in Exercise 1.24. 
A block G is also called 2-connected or biconnected because at least two 
vertices have to be removed from G to disconnect it. The concepts of vertex 
and edge connectivities and generalized versions of Theorem 1.8, called 
Menger's theorems, will be discussed in Chapter 8. 
1.8 
ISOMORPHISM AND 2-ISOMORPHISM 
The two graphs shown in Fig. 1.17 are "seemingly" different. However, one 
can be redrawn to look exactly like the other. Thus these two graphs are 
Figure 1.17. Isomorphic graphs, (a) 
G,. (b) G 2. 

ISOMORPHISM AND 2-ISOMORPHISM 
23 
"equivalent" in some sense. This equivalence is stated more precisely as 
follows: 
Two graphs G, and G 2 are said to be isomorphic if there exists a 
one-to-one correspondence between their vertex sets and a one-to-one 
correspondence between their edge sets so that the corresponding edges of 
G, and G 2 are incident on the corresponding vertices of Gt and G 2. In other 
words, if vertices v1 and v2 in G, correspond respectively to vertices v\ and 
v'2 in G 2, then an edge in G, with end vertices u, and v2 should correspond 
to an edge in G 2 with v\ and v2 as end vertices and vice versa. 
According to this definition, the two graphs shown in Fig. 1.17 are 
isomorphic. The correspondences between their vertex sets and edge sets 
are as follows: 
Vertex correspondence 
u, «-»i>2, 
υ 4 ** Κ > 
Edge correspondence 
ei*-*e\ , 
« 4 * * 
« 6 > 
Consider next the two separable graphs G, and G 2 shown in Fig. 1.18a and 
1.186. These two graphs are not isomorphic. Suppose we "split" the 
cut-vertex u, in G, into two vertices so as to get the two edge-disjoint 
graphs
+ shown in Fig. 1.18c. If we perform a similar "splitting" operation on 
the cut-vertex v\ in G 2, we get the two edge-disjoint graphs shown in Fig. 
1.18d. It may be seen that the graphs of Fig. 1.18c and 1.18d are 
isomorphic. Thus the two graphs G, and G 2 become isomorphic after 
splitting the cut-vertices. Such graphs are said to be 
l-isomorphic. 
2-isomorphism to be defined next is a more general type of isomorphism. 
Two graphs G, and G 2 are 2-isomorphic if they become isomorphic after 
one or more applications of either or both of the following operations: 
1. Splitting a cut-vertex in G, and/or G 2 into two vertices to get two 
edge-disjoint graphs. 
2. If one of the graphs, say G,, has two subgraphs G[ and G" that have 
exactly two common vertices u, and v2, the interchange of the names 
* Two graphs are edge-disjoint if they have no edge in common, and vertex-disjoint if they have 
no vertex in common. 
V2 
*~*
 V'i 
>
 
y 3 *"*
 
V ' \ 
Vs «-» v'5 . 
e2 
e\, 
e3+*e2, 
t 
^ 
t 

24 
BASIC CONCEPTS 
(c) 
(d) 
Figure 1.18. 1-isomorphic graphs, (a) G,. (b) G2. (c) Graph after splitting u, in G,. 
(d") Graph after splitting v\ in G 2. 
of these vertices in one of the subgraphs. (Geometrically this oper-
ation is equivalent to turning around one of the subgraphs G\ and G" 
at the common vertices vl and v2.) 
Consider the graphs Gx and G 2 shown in Fig. 1.19a and 1.196. After 
performing in Gx a splitting operation on vertex v2 and a turning around 
operation at vertices υχ and v2, we get the graph G[ shown in Fig. 1.19c. A 
splitting operation on vertex v'2 in G 2 results in the graph G 2 shown in Fig. 
1.19d. These two graphs Gj and G'2 are isomorphic. Hence G, and G 2 are 
2-isomorphic. 
The next theorem presents an important result on 2-isomorphic graphs. 

FURTHER READING 
25 
(c) 
(d) 
Figure 1.19. Illustration of 2-isomorphism. (a) Gv (b) G2. (c) G\. (d) G'2. 
Theorem 1.9. Two graphs G, and G 2 are 2-isomorphic if and only if there 
exists a one-to-one correspondence between their edge sets such that the 
circuits in one graph correspond to the circuits in the other. 
• 
The fact that circuits in Gj will correspond to circuits in G 2, when G, and 
G 2 are 2-isomorphic, is fairly obvious. However, the proof of the converse 
of this result is too lengthy to be discussed here. Whitney's original paper 
[1.2] on 2-isomorphic graphs discusses this. 
1.9 
FURTHER READING 
Harary [1.3], Berge [1.4], Bondy and Murty [1.5], Lovasz [1.6], Chartrand 
and Lesniak [1.7], and Bollobas [1.8] are excellent references for several of 

26 
BASIC CONCEPTS 
the topics covered in this book. Berge [1.4] also discusses hypergraphs and 
matroids. Bondy and Murty [1.5] include a collection of a number of 
unsolved problems in graph theory. Lovasz [1.6] discusses graph theory 
through a number of problems and solutions. Among other things, Bollobas 
[1.8] gives an introduction to extremal graph theory and random graphs. See 
Swamy and Thulasiraman [1.9] for a detailed discussion of graph algorithms 
and electrical network applications of graph theory. For an elegant intro-
duction to topics in graph theory including matroids see Wilson [1.10]. 
Other textbooks on graph theory include Liu [1.11] and Deo [1.12]. Several 
books and monographs devoted exclusively to special topics such as extrem-
al graph theory, random graphs, and so forth are also available. These will 
be referred to in the appropriate chapters of this book. 
1.10 
EXERCISES 
1.1 
Let G be a graph with η vertices and m edges such that the vertices 
have degree k or k + 1. Prove that if G has nk vertices of degree k and 
nk+i vertices of degree k + 1, then nk = (k + \)n - 2m. 
1.2 
Prove or disprove: 
(a) The union of any two distinct closed walks joining two vertices 
contains a circuit. 
(b) The union of any two distinct paths joining two vertices contains a 
circuit. 
1.3 
If in a graph G there is a path between any two vertices a and b, and 
a path between any two vertices b and c, then prove that there is a 
path between a and c. 
1.4 
Let P, and P 2 be two distinct paths between any two vertices of a 
graph. Prove that Ρ, Θ P 2 is a circuit or the union of some edge-
disjoint circuits of the graph. 
1.5 
Prove that a closed trail with all its vertices of degree 2 is a circuit. 
1.6 
Show that if two distinct circuits of a graph G contain an edge e, then 
in G there exists a circuit that does not contain e. 
1.7 
Show that in a simple graph G with S(G) ^ k there is a path of length 
at least k. Also show that G has a circuit of length at least k + 1, if 
ik>2. 
1.8 
Prove that a graph G = (V, E) is connected if and only if, for every 
partition (Vx, V2) of V with Vx and V2 nonempty, there is an edge of G 
joining a vertex in Vx to a vertex in V2. 
1.9 
Prove that a simple graph G with η vertices and k components can 

EXERCISES 
27 
have at most (n - k)(n - k + l)/2 edges. Deduce from this result that 
G must be connected if it has more than (n - l)(n - 2)12 edges. 
1.10 Prove that if a graph G (connected or disconnected) has exactly two 
vertices of odd degree, then there must be a path joining these two 
vertices. 
1.11 Prove that if a simple graph G is not connected, then its complement 
G is. 
1.12 If G is a graph with η vertices and m edges such that m < η - 1, then 
prove that G is not connected. 
1.13 If, for a graph G with η vertices and m edges, m^n, 
then prove that 
G contains a circuit edge. 
1.14 Prove that a simple η-vertex graph G is connected if 5(G) ^ (η - 1)/ 
2. 
1.15 Show that a simple graph G with at least two vertices contains two 
vertices of the same degree. 
1.16 Show that if a graph G = (V, E) is simple and connected but not 
complete, then G has three vertices u, v, and w such that the edges 
(w, υ) and (υ, w) are in Ε and the edge (u, w) is not in E. 
1.17 
Show that if a simple graph G has diameter greater than 3, then G has 
diameter less than 3. 
1.18 The girth of a graph G is the length of a shortest circuit in G. If G has 
no circuits, we define the girth of G to be infinite. Show that a 
^-regular graph of girth 4 has at least 2k vertices. 
1.19 A simple grapji G is self-complementary 
if it is isomorphic to its 
complement G. Prove that the number of vertices of a self-
complementary graph must be of the form 4k or 4k + 1 where k is an 
integer. 
1.20 Prove that an «-vertex simple graph is not bipartite if it has more than 
n
2/4 edges. 
1.21 Let G be a simple graph with maximum degree Δ. Show that there 
exists a Δ-regular graph containing G as an induced subgraph. 
1.22 Construct a simple cubic graph with 2n(n s 3) vertices having no 
triangles. 
(Note: A graph is cubic if it is 3-regular. A triangle is a circuit of 
length 3.) 
1.23 Prove that if 
is a cut-vertex of a simple graph G, then υ is not a 
cut-vertex of G. 

28 
BASIC CONCEPTS 
Figure 1.20 
1.24 
Prove that the following properties of a graph G with η ^ 3 vertices 
are equivalent: 
(a) G is nonseparable. 
(b) Every two vertices of G lie on a common circuit. 
(c) For any vertex υ and any edge e of G there exists a circuit 
containing both. 
(d) Every two edges of G lie on a common circuit. 
(e) Given two vertices and one edge of G, there is a path joining the 
vertices that contains the edge. 
(f) For every three distinct vertices of G there is a path joining any 
two of them that contains the third. 
(g) For every three distinct vertices of G there is a path joining any 
two of them that does not contain the third. 
1.25 
Show that if a graph G has no circuits of even length, then each block 
of G is either Kt or K2 or a circuit of odd length. 
1.26 
Show that a connected graph that is not a block has two blocks that 
have a common vertex. Let b(v) denote the number of blocks of a 
graph G = (V, E) containing vertex v. Show that the number of 
blocks of G is equal to ρ + Σ 
ip(v) - 1), where ρ is the number of 
components of G. 
1.27 
Let c(B) denote the number of cut-vertices of a connected graph G 
that are vertices of the block B. Then the number c(G) of cut-vertices 
of G is given by 
c ( G ) - l = 
Σ 
[c(B)-l]. 
all blocks 
1.28 
A bridge of a graph G is an edge e such that G - e has more 
components than G. Prove the following: 

REFERENCES 
29 
Figure 1.21 
(a) An edge e of a connected graph G is a bridge if and only if there 
exist vertices u and w such that e is on every u-w path of G. 
(b) An edge of a graph G is a bridge of G if and only if it is on no 
circuit of G. 
1.29 Are the graphs shown in Fig. 1.20 isomorphic? Why? 
1.30 Show that the two graphs of Fig. 1.21 are not isomorphic. 
1.31 Determine all nonisomorphic simple graphs of order 3 and those of 
order 4. 
(Note: There are exactly four nonisomorphic graphs on three vertices, 
and 11 on four vertices.) 
1.32 Prove that any two simple connected graphs with η vertices, all of 
degree 2, are isomorphic. 
1.11 
REFERENCES 
1.1 
H. Whitney, "Nonseparable and Planar Graphs," Trans. Amer. Math. Soc, 
Vol. 34, 339-362 (1932). 
1.2 
H. Whitney, "2-Isomorphic Graphs," Am. J. Math., Vol. 55, 245-254 (1933). 
1.3 
F. Harary, Graph Theory, Addison-Wesley, Reading, Mass., 1969. 
1.4 
C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
1.5 
J. A. Bondy and U. S. R. Murty, Graph Theory with Applications, Macmillan, 
London, 1976. 
1.6 
L. Lovasz, Combinatorial Problems and Exercises, North-Holland, Am-
sterdam, 1979. 
1.7 
G. Chartrand and L. Lesniak, Graphs and Digraphs, Wadsworth and Brooks/ 
Coles, Pacific Grove, Calif. 1986. 
1.8 
B. Bollobas, Graph Theory: An Introductory Course, Springer-Verlag, New 
York, 1979. 

30 
BASIC CONCEPTS 
1.9 
Μ. Ν. S. Swamy and K. Thulasiraman, Graphs, Networks and Algorithms, 
Wiley-Interscience, New York, 1981. 
1.10 R. J. Wilson, Introduction to Graph Theory, Oliver and Boyd, Edinburgh, 
1972. 
1.11 C. L. Liu, Introduction to Combinatorial Mathematics, McGraw-Hill, New 
York, 1968. 
1.12 N. Deo, Graph Theory with Applications to Engineering and Computer 
Science, Prentice-Hall, Englewood Cliffs, N.J., 1974. 

CHAPTER 2 
TREES, CUTSETS, AND CIRCUITS 
The graphs that are encountered in most of the applications are connected. 
Among connected graphs trees have the simplest structure and are perhaps 
the most important ones. If connected graphs are important, then the set of 
edges disconnecting a connected graph should be of equal importance. This 
leads us to the concept of a cutset. In this chapter we study trees and cutsets 
and several results associated with them. We also bring out the relationship 
between trees, cutsets, and circuits. 
2.1 
TREES, SPANNING TREES, AND COSPANNING TREES 
A graph is said to be acyclic if it has no circuits. A tree is a connected acyclic 
graph. A tree of a graph G is a connected acyclic subgraph of G. A spanning 
tree of a graph G is a tree of G having all the vertices of G. A connected 
subgraph of a tree Τ is called a subtree of T. 
Consider, for example, the graph G shown in Fig. 2.1a. The graphs G, 
and G 2 of Fig. 2.16 are two trees of G. The graphs G 3 and G 4 of Fig. 2.1c 
are two of the spanning trees of G. 
The cospanning tree T* of a spanning tree Γ of a graph G is the subgraph 
of G having all the vertices of G and exactly those edges of G that are not in 
T. Note that a cospanning tree may not be connected. The cospanning trees 
G* and G* of the spanning trees G 3 and G 4 of Fig. 2.1c are shown in Fig. 
2.1d. 
The edges of a spanning tree Τ are called the branches of T, and those of 
the corresponding cospanning tree T* are called links or chords. 
31 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

3 2 
TREES, CUTSETS, AND CIRCUITS 
Id 
Figure 2.1. Trees, spanning trees, and cospanning trees, (a) Graph G. (b) Trees G, 
and G2 of G. (c) Spanning trees G3 and G4 of G. (d) Cospanning trees GJ and GJ of 
G. 

TREES, SPANNING TREES, AND COSPANNING TREES 
33 
" 4 0 
" 3 0 
C * 3
 
C * 4 
id) 
Figure 2.1. (Continued) 
A spanning tree Τ uniquely determines its cospanning tree T*. As such, 
we refer to the edges of Τ * as the chords or links of T. 
We now proceed to discuss several properties of a tree. 
While the definition of a tree as a connected acyclic graph is conceptually 
simple, there exist several other equivalent ways of characterizing a tree. 
These are discussed in the following theorem. 
Theorem 2.1. The following statements are equivalent for a graph G with η 
vertices and m edges: 
1. G is a tree. 
2. There exists exactly one path between any two vertices of G. 
3. G is connected and m = η - 1. 
4. G is acyclic and m = η - 1. 
5. G is acyclic, and, if any two nonadjacent vertices of G are connected 
by an edge, then the resulting graph has exactly one circuit. 
Proof 
1=P2 
See Exercise 1.2b. 
2Φ3 
We first note that G is connected because there exists a path 
between any two vertices of G. 
We prove that m = η - 1 by induction on the number of vertices of G. 
This is obvious for connected graphs with one or two vertices. Assume that 
this is true for connected graphs with fewer than η vertices. 
Consider any edge em G. The edge e constitutes the only path between 
the end vertices of e. Hence in G — e there is no path between these 

34 
TREES, CUTSETS, AND CIRCUITS 
vertices. Thus G - e is not connected. Further, it should contain exactly two 
components, for otherwise the graph G will not be connected. 
Let G, and G 2 be the two components of G - e. Let ηλ and m, be, 
respectively, the numbers of vertices and edges in Gv Similarly, let n2 and 
m2 be denned for G 2. Then we have 
n = ml + n2 
and 
m = m, + m2 + 1. 
Note that G{ and G 2 satisfy the hypothesis of statement 2, namely, there 
exists exactly one path between any two vertices in G, and G 2. Since η, < η 
and n2<n, 
we have by the induction hypothesis 
m, = «, - 1 
and 
m 2 = n2 - 1. 
Hence 
m = / j , - l + n
2 - l + l = n - l . 
3 ^ 4 
Let the graph G be renamed as G 0; that is, G0= G. 
Suppose that G 0 has some circuits. Then let G, be the graph that results 
after removing from G 0 a circuit edge, say e{; that is, Gx = G0 - ex. Since G„ 
is connected, it follows from Theorem 1.4 that G, is also connected and has 
all the η vertices of G 0. Further, the number of edges in G, is equal to 
m-l. 
If G, is not acyclic, let e2 be a circuit edge of G,. Again the graph 
G 2 = G, - e2 = G 0 - e, - e 2 should be connected and should have all the η 
vertices of G,. Also, G 2 has m - 2 edges. If G 2 is not acyclic, repeat this 
process until we get a connected graph Gp that is acyclic. Note that Gp has η 
vertices and m— ρ edges. 
Since Gp is connected and acyclic, it must be a tree. Hence it follows from 
the previous statement of the theorem that 
m — ρ = η — 1. 
Since by hypothesis m = η - 1, we get ρ = 0. Thus the graph G = G 0 is 
acyclic. 

TREES, SPANNING TREES, AND COSPANNING TREES 
35 
4φ5 
Let G,, G 2 , . . . , Gp be the ρ components of G with n, and m, 
denoting, respectively, the numbers of vertices and edges in the component 
G,. Then 
m = m, + m 2 + · • · + mp 
and 
η = η, + « 2 + · · · + np . 
Each component G, is connected, and it is also acyclic because G is. 
Hence G, is a tree. Then, by statement 3 of the theorem, 
m, = n, = 1 for all 1 s ι < ρ . 
Hence we get 
ρ 
ρ 
m - Σ m, = Σ (η, - 1) = η - ρ . 
/ = 1 
ι = 1 
However, by hypothesis 
m = η - 1 . 
Hence we get 
p = l. 
Thus G consists of exactly one component. Hence it is connected. Since it 
is also acyclic, it is a tree. Then, by statement 2 of the theorem, there exists 
exactly one path between any two distinct vertices of G. Hence if we add an 
edge e = (υ,, υ 2) to G, then this edge together with the unique path between 
i>, and υ2 will form exactly one circuit in the resulting graph. 
5φ1 
Suppose that G is not connected. Consider any two vertices va 
and vb that are in different components of G. Then va and vb are not 
connected in G. 
Addition of an edge (va, vb) to G does not produce a circuit since in G 
there is no path between va and vb. This, however, contradicts the hypoth-
esis. Hence the assumption that G is not connected is false. Thus G is 
connected. 
Since G is also acyclic, it must be a tree, by definition. 
• 
It should be clear that each of statements 1 through 5 of Theorem 2.1 
represents a set of necessary and sufficient conditions for a graph G to be a 
tree. An immediate consequence of this theorem is the following. 

36 
TREES, CUTSETS, AND CIRCUITS 
Corollary 2.1.1. Consider a subgraph G' of an w-vertex graph G. Let G' 
have η vertices and m' edges. Then the following statements are equivalent: 
1. G' is a spanning tree of G. 
2. There exists exactly one path between any two vertices of G'. 
3. G' is connected and m' = η - 1. 
4. G' is acyclic and m' - η - 1. 
5. G' is acyclic, and, if any two nonadjacent vertices of G' are connected 
by an edge, then the resulting graph has exactly one circuit. 
• 
A condition that is not covered by Corollary 2.1.1 but can be proved 
easily is stated next. 
Corollary 2.1.2. A subgraph G' of an η-vertex graph G is a spanning tree of 
G if and only if G' is acyclic, connected, and has η - 1 edges. 
• 
It should now be obvious that a subgraph of an π-vertex graph G having 
any three of the following properties should be a spanning tree of G: 
1. It has η vertices. 
2. It is connected. 
3. It has η - 1 edges. 
4. It is acyclic. 
The question then arises whether any two of these four properties will be 
sufficient to define a spanning tree. 
This question is answered next. (See also Exercise 2.3.) 
Theorem 2.2. A subgraph G' of an η-vertex graph G is a spanning tree of G 
if and only if G' is acyclic and has η - 1 edges. 
Proof. Necessity follows from Theorem 2.1, statement 4. 
To show the sufficiency, we have to prove that G' is connected and has 
all the η vertices of G. 
Let G' consist of ρ components G,, G 2 , . . . , Gp, with «, denoting the 
number of vertices in component G,. Let n' be the number of vertices in G'. 
Then 
ρ 
n' = Σ η,. 
ι= 1 
Each G, is connected. It is also acyclic because G is. Thus each G, is a tree 

TREES, SPANNING TREES, AND COSPANNING TREES 
37 
and hence has η, - 1 edges. Thus the total number of edges in G' is equal to 
Ρ 
Σ ( η , - 1 ) = " ' - / > · 
But by hypothesis 
n' - ρ = η - 1 . 
Since n' < n and ρ ^ 1, it is clear that the above equation is true if and only 
if n' - η and ρ = 1. Thus G' is connected and has η vertices. Since it is also 
acyclic, it is, by definition, a spanning tree of G. 
• 
Suppose a graph G has a spanning tree T. Then G should be connected 
because the subgraph Τ of G is connected and has all the vertices of G. 
Next, we would like to prove the converse of this result, namely, that a 
connected graph has at least one spanning tree. 
If a connected graph G is acyclic, then it is its own spanning tree. If not, 
let e, be some circuit edge of G. Then, by Theorem 1.4, the graph 
G, = G - e, is connected and has all the vertices of G. If G, is not acyclic, 
repeat the process until we get a connected acyclic graph Gp that has all the 
vertices of G. This graph Gp will then be a spanning tree of G. 
The results of this discussion are summarized in the next theorem. 
Theorem 2.3. A graph G is connected if and only if it has a spanning 
tree. 
• 
Since a spanning tree Γ of a graph G is acyclic, every subgraph of Τ is an 
acyclic subgraph of G. Is it then true that every acyclic subgraph of G is a 
subgraph of some spanning tree of G? The answer is "yes" as proved in the 
next theorem. 
Theorem 2.4. A subgraph G' of a connected graph G is a subgraph of some 
spanning tree of G if and only if G' is acyclic. 
Proof. Necessity is obvious. 
To prove the sufficiency, let Γ be a spanning tree of a graph G. Consider 
the graph G, = TU G'. It is obvious that G' is a subgraph of G,. G, is 
connected and has all the vertices of G because Γ is a subgraph of G,. If G, 
is acyclic, then it is a spanning tree of which G' is a subgraph, and the 
theorem is proved. (Note that if G, is acyclic, G, = Γ and G' is then a 
subgraph of T.) 
Suppose G, has a circuit Cx. Since G' is acyclic, it follows that not all the 
edges of C, are in G'. Thus C, must have at least one edge, say e,, which is 

38 
TREES, CUTSETS, AND CIRCUITS 
not in G'. Removal of this circuit edge e, from G, results in the graph 
G 2 = G, - e,, which is also connected and has all the vertices of G,. Note 
that G' is a subgraph of G 2. If G 2 is acyclic, then it is a required spanning 
tree. If not, repeat the process until a spanning tree of which G' is a 
subgraph is obtained. 
• 
Next we prove an interesting theorem on the minimum number of 
pendant vertices, that is, vertices of degree 1, in a tree. 
Theorem 2.5. In a nontrivial tree there are at least two pendant vertices. 
Proof. Suppose a tree Τ has η vertices. Then, by Theorem 2.1, it has η - 1 
edges. We also have, by Theorem 1.1, that 
η 
Σ d{v,) = 2 x number of edges in Τ . 
Thus 
+ d(v2) + ·•• + d(v„) = 
2n-2. 
This equation will be true only if at least two of the terms on its left-hand 
side are equal to 1, that is, Τ has at least two pendant vertices. 
• 
2.2 
/(-TREES, SPANNING /(-TREES, AND FORESTS 
A k-tree* is an acyclic graph consisting of k components. Obviously, each 
component of a k-tree is a tree by itself. Note that a 1-tree is the same as a 
tree. 
If a k-tree is a spanning subgraph of a graph G, then it is called a 
spanning k-tree of G. 
The cospanning k-tree T* of a spanning &-tree Τ of G is the spanning 
subgraph of G containing exactly those edges of G that are not in T. 
For example, the graph of Fig. 2.2ft is a 2-tree of the graph G shown in 
Fig. 2.2a. A spanning 3-tree Τ of G and the corresponding cospanning 
3-tree T* are shown in Fig. 2.2c and 2.2a". 
Let the k components of a spanning A>tree of an η-vertex graph G be 
denoted by T,, T2,..., Tk. If n, is the number of vertices in Γ,, then 
η = «, + n2 + · · · + nk . 
' This definition of &-tree has been used extensively in the electrical network literature. In 
current graph theory literature this term has a different meaning. See Rose [2.1]. 

fc-TREES, SPANNING fc-TREES, AND FORESTS 
39 
(0 
id) 
Figure 2.2. Illustrations of the definitions of a A:-tree, a spanning &-tree, and a 
cospanning fc-tree. (a) Graph G. (b) A 2-tree of G. (c) A spanning 3-tree Τ of G. 
(d) Cospanning 3-tree T*. 
Since each Ti is a tree, we have, by Theorem 2.1, 
m, = n, - 1 , 
where m, is the number of edges in T,. 
Thus the total number of edges in the spanning Λ-tree Γ is equal to 
* 
k 
Σ tn{ι = Σ (w, - 1) = η - k . 
1=1 
1=1 
If m is the number of edges in G, then the cospanning A>tree T* will have 
m - n + k edges. 

40 
TREES, CUTSETS, AND CIRCUITS 
A. forest of a graph G is a spanning fc-tree of G, where k is the number of 
components in G. 
If a graph G has ρ components, then for any spanning fc-tree of G, k 2: p. 
Since a forest Τ of G is a spanning Λ-tree of G with k= p, it is necessary 
that each component of Τ be a spanning tree of one of the components of 
G. Thus a forest Γ of a graph G with ρ components G,, G 2 , . . . , Gp consists 
of ρ components TX,T2,... 
,Tp such that T, is a spanning tree of G ( , l s i ' < 
P-
The co-forest T* of a forest Γ of a graph G is the spanning subgraph of G 
containing exactly those edges of G that are not in T. 
" 9 
" 2 
" 3 
" β 
" 7 
»11 
(C) 
Figure 2.3. Forest and co-forest, (a) Graph G. (6) A forest Τ of G. (c) Co-forest 
Γ*. 

FUNDAMENTAL CIRCUITS 
41 
Note that forest and spanning tree are synonymous in the case of a 
connected graph. 
A forest Τ and the corresponding co-forest T* of a graph are shown in 
Fig. 2.3. 
2.3 
RANK AND NULLITY 
Consider a graph G with m edges, η vertices, and k components. The rank 
of G, denoted by p(G), is defined equal to n- k, and the nullity of G, 
denoted by p-(G), is defined equal to m - η + k. Note that 
p(G) + ,*(G) = m . 
It follows from the definition of a forest and a co-forest that the rank 
p(G) of a graph G is equal to the number of edges in a forest of G, and the 
nullity p-(G) of G is equal to the number of edges in a co-forest of G. 
The numbers p(G) and /x.(G) are among the most important ones 
associated with a graph. As we shall see in Chapter 4, they define the 
dimensions of the cutset and circuit subspaces of a graph. 
2.4 
FUNDAMENTAL CIRCUITS 
Consider a spanning tree 7 of a connected graph G. Let the branches of Τ 
be denoted by bx, b2,..., 
bn_x, 
and let the chords of Τ be denoted by 
c,, c 2 , . . . , c m _ n + 1 , where m is the number of edges in G, and η is the 
number of vertices in G. 
While Τ is acyclic, by Theorem 2.1 the graph Τ U c, contains exactly one 
circuit C,. This circuit consists of the chord c, and those branches of Τ that 
lie in the unique path in Τ between the end vertices of c,. The circuit C, is 
called the fundamental 
circuit of G with respect to the chord c, of the 
spanning tree T. 
The set of all the m - η + 1 fundamental circuits C,, C 2 , . . . , C m _ n + 1 of G 
with respect to the chords of the spanning tree Τ of G is known as the 
fundamental set of circuits of G with respect to T. 
An important feature of the fundamental circuit C, is that it contains 
exactly one chord, namely, chord c,. Further, chord c, is not present in any 
other fundamental circuit with respect to T. Because of these properties, the 
edge set of no fundamental circuit can be expressed as the ring sum of the 
edge sets of some or all of the remaining fundamental circuits. We also show 
in Chapter 4 that every circuit of a graph G can be expressed as the ring sum 
of some fundamental circuits of G with respect to a spanning tree of G. It is 
for these reasons that the "fundamental" circuits are called so. 
A graph G and a set of fundamental circuits of G are shown in Fig. 2.4. 

42 
TREES, CUTSETS, AND CIRCUITS 
10 
Ic) 
Figure 2.4. A set of fundamental circuits of a graph G. (a) Graph G. (b) A spanning 
tree Γ of G. (c) Set of five fundamental circuits of G with respect to T. (Chords are 
indicated by dashed lines.) 
2.5 
CUTSETS 
A cutset 5 of a connected graph G is a minimal set of edges of G such that 
its removal from G disconnects G, that is, the graph G - S is disconnected. 
For example, consider the subset 5, = {e,, e 3, e 7, e, 0} of edges of the 
graph G in Fig. 2.5a. The removal of S, from G results in the graph 
G, = G - S, of Fig. 2.5i>. G, is disconnected. Furthermore, the removal of 
any proper subset of S, cannot disconnect G. Thus S, is a cutset of G. 

CUTS 
43 
Figure 2.5. Illustration of the definition of a cutset, (a) Graph G. (b) G, = G - S,, 
5, = {«?,, <?3, <?7, e, 0}. (c) G 2 = G - S 2, 5 2 = {e,, e 2, e 5, e 7, e Q}. (a") G 3 = G - S 2, 
•52' = {e,, e2, e5, eg). 
Consider next the set S2 = {e,, e2, es, e7, e9}. The graph G2 = G - S2 
shown in Fig. 2.5c is disconnected. However, the set S'2 = {e1, e2, e5, 
eg}, 
which is a proper subset of S2, also disconnects G. The graph G 3 = G - S'2 is 
shown in Fig. 2.5d. Thus 5 2 is not a cutset of G. 
Note that, by the definition of a cutset given above, if S is a cutset of a 
graph G, then the ranks of G and G-S 
differ by at least 1; that is, 
p ( G ) - p ( G - 5 ) > l . 
Seshu and Reed [2.2] define a cutset as follows: 
A cutset 5 of a connected graph G is a minimal set of edges of G such 
that removal of 5 connects G into exactly two components; that is, p(G) -
p ( G - 5 ) = l. 
The question now arises whether these two definitions of a cutset are 
equivalent. The answer is "yes" and its proof is left as an exercise (Exercise 
2.15). 
2.6 
CUTS 
We now define the concept of a cut, which is closely to that of a cutset. 

44 
TREES, CUTSETS, AND CIRCUITS 
Consider a connected graph G with vertex set V. Let V, and V2 be two 
mutually disjoint subsets of V such that V=V1UV2; 
that is, V, and V2 have 
no common vertices and together contain all the vertices of V. Then the set 
S of all those edges of G having one end vertex in V, and the other in V2 is 
called a cut of G. This is usually denoted by (VUV2). 
Reed [2.3] refers to a 
cut as a seg (the set of edges of segregating the vertex set V). 
For example, for the graph G shown in Fig. 2.6, if V, = {u,, v2, u 3, vA) 
and V2 - {v5, υ6, υΊ}, then the cut (V,, V2) of G is equal to the set {e6, e 7, 
e 8} of edges. 
Note that the cut (V,, V2) of G is the minimal set of edges of G whose 
removal disconnects G into two graphs G, and G 2, which are induced 
subgraphs of G on the vertex sets V, and V2. Gx and G 2 may not be 
connected. If both these graphs are connected, then (ν^,^) is also the 
minimal set of edges disconnecting G into exactly two components. Then, 
by definition, (V,, V2) is a cutset of G. 
Suppose that for a cutset 5 of G, V, and V2 are, respectively, the vertex 
sets of the two components Gt and G 2 of G - 5. Then S is the cut 
(Vl,V2). 
Thus we have the following theorem. 
Figure 2.6. Definition of a cut. (a) Graph G. (b) Cut <K,, V2> of G. 

CUTS 
45 
Theorem 2.6 
1. A cut (V,, V 2) of a connected graph G is a cutset of G if the induced 
subgraphs of G on vertex sets Vt and V2 are connected. 
2. If S is a cutset of a connected graph G, and V, and V2 are the vertex 
sets of the two components of G - S, then S = (V,, V 2). 
• 
Any cut (V,, V 2) in a connected graph G contains a cutset of G, since the 
removal of {Vj, V2) from G disconnects G. In fact, we can prove that a cut 
in a graph G is the union of some edge-disjoint cutsets of G. Formally, we 
state this in the following theorem. 
Theorem 2.7. A cut in a connected graph G is a cutset or union of 
edge-disjoint cutsets of G. 
• 
The proof of this theorem is not difficult, and it is left as an exercise 
(Exercise 2.19). 
Consider next a vertex v1 in a connected graph. The set of edges incident 
on u, forms the cut (vu 
V— u,). The removal of these edges disconnects G 
into two subgraphs. One of these subgraphs containing only the vertex υ, is, 
by definition, connected. The other subgraph is the induced subgraph G' of 
" 2 O 
Ο « 2 
».o-
-o»« 
Figure 2.7. Illustration of Theorem 2.8. (a) Graph G. (b) Induced subgraph of G on 
the vertex set {v2, v3, ι>4, i>5, v6, v7, t>„}. 

46 
TREES, CUTSETS, AND CIRCUITS 
G on the vertex set V- vv Thus the cut (vl,V—vi) 
is a cutset if and only 
if G' is connected. However, G' is connected if and only if vx is not a 
cut-vertex (Section 1.7). Thus we have the following theorem. 
Theorem 2.8. The set of edges incident on a vertex υ in a connected graph 
G is a cutset of G if and only if υ is not a cut-vertex of G. 
• 
For example, consider the separable graph G shown in Fig. 2.7a in which 
i>, is a cut-vertex. The induced subgraph of G on the vertex set V—vl = 
{v2, v3, v4, vs, v6, i>7, vg) is shown in Fig. 2.7b. This subgraph consists of three 
components and is not connected. Thus the edges incident on the cut-vertex 
UJ do not form a cutset of G. 
2.7 
FUNDAMENTAL CUTSETS 
It was shown in Section 2.4 that a spanning tree of a connected graph can be 
used to obtain a set of fundamental circuits of the graph. We show in this 
section how a spanning tree can also be used to define a set of fundamental 
cutsets. 
Consider a spanning tree Γ of a connected graph G. Let b be a branch of 
7. Now, removal of the branch b disconnects Γ into exactly two components 
Tj and 7 2. Note that 7, and T2 are trees of G. Let Vi and V2, respectively, 
denote the vertex sets of 7, and T2. Vx and V2 together contain all the 
vertices of G. 
Let G, and G 2 be, respectively, the induced subgraphs of G on the vertex 
sets V, and V2. It can be seen that 7, and T2 are, respectively, spanning trees 
of G, and G 2. Hence, by Theorem 2.3, G, and G 2 are connected. This, in 
turn, proves (Theorem 2.6) that the cut (V,, V2) is a cutset of G. This cutset 
is known as the fundamental cutset of G with respect to the branch b of the 
spanning tree 7 of G. The set of all the η -1 
fundamental cutsets with 
respect to the η - 1 branches of a spanning tree Γ of a connected graph G is 
known as the fundamental set of cutsets of G with respect to the spanning 
tree 7. 
Note that the cutset (Vj, V 2) contains exactly one branch, namely, the 
branch b of 7. All the other edges of (VX,V2) 
are links of 7. This follows 
from the fact that (Vx, V2) does not contain any edge of 7, or 7 2. Further, 
branch b is not present in any other fundamental cutset with respect to 7. 
Because of these properties, the edge set of no fundamental cutset can be 
expressed as the ring sum of the edge sets of some or all of the remaining 
fundamental cutsets. We show in Chapter 4 that every cutset of a graph G 
can be expressed as the ring sum of the fundamental cutsets of G with 
respect to a spanning tree 7 of G. 
A graph G and a set of fundamental cutsets of G are shown in Fig. 2.8. 

FUNDAMENTAL CUTSETS 
47 
ie) 
(0 
Figure 2.8. A set of fundamental cutsets of a graph, (a) Graph G. (b) Spanning tree 
Τ of G. (c) Fundamental cutset with respect to branch e,. (d) Fundamental cutset 
with respect to branch e2. (e) Fundamental cutset with respect to branch e6. 
(/) 
Fundamental cutset with respect to branch es. 

48 
TREES, CUTSETS, AND CIRCUITS 
2.8 
SPANNING TREES, CIRCUITS, AND CUTSETS 
In this section we discuss some interesting results that relate cutsets and 
circuits to spanning trees and cospanning trees, respectively. These results 
will bring out the "dual" nature of circuits and cutsets. They will also lead to 
alternate characterizations of cutsets and circuits in terms of spanning trees 
and cospanning trees, respectively. 
It is obvious that removal of a cutset S from a connected graph G 
destroys all the spanning trees of G. A little thought will indicate that a 
cutset is a minimal set of edges whose removal from G destroys all the 
spanning trees of G. However, the converse of this results is not so obvious. 
The first few theorems of this section discuss these questions and similar 
ones relating to circuits. 
Theorem 2.9. A cutset of a connected graph G contains at least one branch 
of every spanning tree of G. 
Proof. Suppose that a cutset S of G contains no branch of a spanning tree Γ 
of G. Then the graph G - S will contain the spanning tree Τ and hence, by 
Theorem 2.3, G - S is connected. This, however, contradicts that 5 is a 
cutset of G. 
• 
Theorem 2.10. A circuit of a connected graph G contains at least one edge 
of every cospanning tree of G. 
Proof. Suppose that a circuit C of G contains no edge of the cospanning 
tree T* of a spanning tree Τ of G. Then the graph G - T* will contain the 
circuit C. Since G - T* is the same as the spanning tree T, this means that 
the spanning tree Τ contains a circuit. However, this is contrary to the 
definition of a spanning tree. 
• 
Theorem 2.11. A set 5 of edges of a connected graph G is a cutset of G if 
and only if 5 is a minimal set of edges containing at least one branch of 
every spanning tree of G. 
Proof. 
Necessity 
If the set 5 of edges of G is a cutset of G, then, by Theorem 
2.9, it contains at least one branch of every spanning tree of G. If it is not a 
minimal such set, then a proper subset S' of S will contain at least one 
branch of every spanning tree of G. Then G - S' will contain no spanning 
tree of G and it will be disconnected. Thus removal of a proper subset S' of 
the cutset S of G will disconnect G. This, however, would contradict the 
definition of a cutset. Hence the necessity. 
Sufficiency 
If S is a minimal set of edges containing at least one branch 
of every spanning tree of G, then the graph G - S will contain no spanning 

SPANNING TREES, CIRCUITS, AND CUTSETS 
49 
tree, and hence it will be disconnected. Suppose S is not a cutset. Then a 
proper subset S' of S will be a cutset. Then, by the necessity part of the 
theorem, S' will be a minimal set of edges containing at least one branch of 
every spanning tree of G. This, however, will contradict that 5 is a minimal 
such set. Hence the sufficiency. 
• 
Theorem 2.11 gives a characterization of a cutset in terms of spanning 
trees. We would like to establish next a similar characterization for a circuit 
in terms of cospanning trees. 
Consider a set C of edges constituting a circuit in a graph G. By theorem 
2.10, C contains at least one edge of every cospanning tree of G. We now 
show that no proper subset C of C has this property. 
It is obvious that C does not contain a circuit. Hence, by Theorem 2.4, 
we can construct a spanning tree Τ containing C. The cospanning tree T* 
corresponding to Τ has no common edge with C . Hence for every proper 
subset C of C, there exists at least one cospanning tree T* that has no 
common edge with C . In fact, this statement is true for every acyclic 
subgraph of a graph. Thus we have the following theorem. 
Theorem 2.12. A circuit of a connected graph G is a minimal set of edges of 
G containing at least one edge of every cospanning tree of G. 
• 
The converse of Theorem 2.12 follows next. 
Theorem 2.13. The set C of edges of a connected graph G is a circuit of G if 
it is a minimal set containing at least one edge of every cospanning tree of 
G. 
Proof. As shown earlier, the set C cannot be acyclic since there exists, for 
every acyclic subgraph G' of G, a cospanning tree not having in common 
any edge with G'. Thus C has at least one circuit C . Suppose that C is a 
proper subset of C. Then, by Theorem 2.12, C is a minimal set of edges 
containing at least one edge of every cospanning tree of G. This, however, 
contradicts the hypothesis that C is a minimal such set. Hence no proper 
subset of C is a circuit. Since C is not acyclic, C must be a circuit. 
• 
Theorems 2.12 and 2.13 establish that a set C of edges of a connected 
graph G is a circuit if and only if it is a minimal set of edges containing at 
least one edge of every cospanning tree of G. 
The new characterizations of a cutset and a circuit as given by Theorems 
2.11, 2.12, and 2.13, clearly bring out the dual nature of the concepts of 
circuits and cutsets. This duality is explored further in Chapter 10, where we 
discuss the theory of matroids. 
The next theorem relates circuits and cutsets without involving trees. 

50 
TREES, CUTSETS, AND CIRCUITS 
Theorem 2.14. A circuit and a cutset of a connected graph have an even 
number of common edges. 
Proof. Let C be a circuit and S a cutset of a connected graph G. Let V, and 
V2 be the vertex sets of the two connected subgraphs G, and G 2 of G - S. 
If C is a subgraph of G, or of G 2, then obviously the number of edges 
common to C and S is equal to zero, an even number. 
Suppose that C and S have some common edges. Let us traverse the 
circuit C starting from a vertex, say vx, in the set Vx. Since the traversing 
should end at υ,, it is necessary that every time we meet with an edge of S 
leading us from a vertex in Vx to a vertex in V2, there must be an edge of S 
leading us from a vertex in V2 back to a vertex in Vx. This is possible only if 
C and S have an even number of common edges. 
• 
Theorem 2.14 is a very important one. It forms the basis of the 
orthogonality relationship between cutsets and circuits. This relationship is 
discussed in Chapter 4. 
We would like to point out that the converse of Theorem 2.14 is not quite 
true. However, we show in Chapter 4 that a set S of edges of a graph G is a 
cutset (circuit) or the union of some edge-disjoint cutsets (circuits) if and 
only if 5 has an even number of edges in common with every circuit (cutset). 
Fundamental circuits and fundamental cutsets of a connected graph have 
been denned with respect to a spanning tree of a graph. It is, therefore, not 
surprising that fundamental circuits and cutsets are themselves related as 
proved next. 
Theorem 2.15 
1. The fundamental circuit with respect to a chord of a spanning tree Γ of 
a connected graph consists of exactly those branches of Τ whose 
fundamental cutsets contain the chord. 
2. The fundamental cutset with respect to a branch of a spanning tree Τ 
of a connected graph consists of exactly those chords of Τ whose 
fundamental circuits contain the branch. 
Proof 
1. Let C be the fundamental circuit of a connected graph G with respect 
to chord c, of a spanning tree Τ of G. Let C contain, in addition to the 
chord c,, the branches bx,b2,... 
,bk of T. 
Suppose S,, 1 ^ / ^ k, is the fundamental cutset of G with respect to 
the branch b,,i£i^k, 
of T. The branch bt is the only branch 
common to both Cand S,. The chord c, is the only chord in C. Since C 
and 5, must have an even number of common edges, it is necessary 

EXERCISES 
51 
that the fundamental cutset 5, contain c,. Next we show that no other 
fundamental cutset of Τ contains c,. 
Suppose the fundamental cutset Sk+i 
with respect to branch bk+l 
of 
Τ contains c,. Then c, will be the only common edge between C and 
Sk+X. 
This will contradict Theorem 2.14. Thus the chord c, is present 
only in those cutsets denned by the branches bx, b2,..., 
bk. 
2. Proof of this part is similar to that of part 1. 
• 
2.9 
FURTHER READING 
The concept of a tree is central in the development of several results relating 
circuits and cutsets of a graph. It so happens that the spanning trees, 
circuits, and cutsets of a connected graph are, respectively, the bases, 
circuits, and cocircuits of a matroid defined on the edge set of a graph. So 
the results of this chapter will be of help in understanding our development 
of matroid theory in Chapter 10. 
Electrical network theory is one of the earliest areas of applications of 
graph theory. The results of this chapter and those of Chapters 4 and 6 form 
the foundation of the graph-theoretic study of electrical networks. The 
pioneering work of Seshu and Reed [2.2] and textbooks by Kim and Chien 
[2.4], Chen [2.5], Mayeda [2.6] and Swamy and Thulasiraman [2.7] are 
highly recommended for further reading on this topic. 
Several questions relating to trees have been extensively studied in the 
literature. Some of these are discussed in the subsequent chapters of the 
book. 
2.10 
EXERCISES 
2.1 
Show that there are exactly 6 nonisomorphic trees on 6 vertices, and 
11 on 7 vertices. Draw all of them. 
2.2 
Show that a tree is a bipartite graph. 
2.3 
Consider a subgraph Gs of a connected graph G having η vertices. 
Show that except for the pair (b) and (d), no other pair of the 
following conditions implies that Gs is a spanning tree of G: 
(a) Gs contains η vertices. 
(b) Gs contains η — 1 edges. 
(c) Gs is connected. 
(d) Gs contains no circuits. 
2.4 
Prove that each pendant edge (the edge incident on a pendant vertex) 
in a connected graph G is contained in every spanning tree of G. 

52 
TREES, CUTSETS, AND CIRCUITS 
2.5 
Prove that each edge of a connected graph G is a branch of some 
spanning tree of G. 
2.6 
Prove that in a tree every vertex of degree greater than 1 is a 
cut-vertex. 
2.7 
Prove that each edge of a nonseparable graph G can be made a chord 
of some cospanning tree of G. 
2.8 
Prove or disprove: Any two edges of a nonseparable graph can be 
contained in some fundamental circuit. 
2.9 
Let dx, d2,... ,dn denote the degrees of the vertices of a nontrivial 
tree T. Prove that the number of pendant vertices of Τ equals 
2+ Σ ( 4 - 2 ) 
2.10 
Prove that a nonseparable graph has nullity equal to 1 if and only if it 
is a circuit. 
2.11 Show that the nullity of a graph is nonnegative. Give an example of a 
graph with nullity equal to 0. 
2.12 
Consider the following two operations on a graph G: 
(a) If only two edges, ex = (υ,, v„) and e2 = {υ2, υα), are incident on 
vertex va, then replace ex and e2 by a single edge connecting u, 
and v2. 
(b) Replace any edge (vx,v2) 
by two edges (υι,υβ) 
and (v2, 
va) 
where va is a new vertex not in G. 
Prove that the nullity of G is invariant under these operations. 
2.13 A connected graph G is minimally connected if for every edge e of G 
the graph G - e is not connected. Prove that a connected graph is a 
tree if and only if it is minimally connected. 
2.14 
Prove that a subgraph Gs of a connected graph G is a spanning tree of 
G if and only if it is a maximal subgraph of G containing no circuits. 
2.15 
Show that a cutset of a connected graph G is a minimal set S of edges 
of G such that removal of S disconnects G into exactly two compo-
nents; that is, p(G) - p(G - 5) = 1. 
2.16 
Prove that every connected graph contains a cutset. 
2.17 
Prove that a subgraph of a connected graph G can be included in a 
cospanning tree of G if and only if it contains no cutsets of G. 
2.18 Prove that a subset S of edges of a connected graph G forms a 
cospanning tree of G if and only if it is a maximal subset of edges 
containing no cutsets of G. 

EXERCISES 
53 
2.19 
Prove that a cut in a connected graph G is a cutset or union of 
edge-disjoint cutsets of G. 
2.20 Prove that every cutset of a nonseparable graph with more than two 
vertices contains at least two edges. 
2.21 Prove that a graph G is nonseparable if and only if every two edges of 
G lie on a common cutset. 
2.22 
Let C be a circuit in a graph G. Let a and b be any two edges in C. 
Prove that there exists a cutset 5 such that S Π C = {a, b}. 
2.23 
Let Γ, and T2 be spanning trees of a connected graph G. Show that if 
e is any edge of Tx, then there exists an edge/of T2 with the property 
that (7", - e) Uf (the graph obtained from Γ, by replacing e by / ) is 
also a spanning tree of G. Show also that 7", can be "transformed" 
into T2 by replacing the edges of Tx one at a time by the edges of T2 
in such a way that at each stage we obtain a spanning tree of G. 
2.24 
(a) Let C, and C2 be two circuits in a graph G. Let ex be an edge that 
is in both C, and C2, and let e2 be an edge that is in C, but not in 
C 2. Prove that there exists a circuit C 3 such that C 3 C ( C , U 
C 2) - ex and e 2 is in C 3. 
(b) Repeat part (a) when the term "circuit" is replaced by a "cutset." 
(Note: This result is one of the postulates used by Whitney [2.8] to 
define "circuits" of a matroid (Chapter 10).) 
2.25 
Let Τ be an arbitrary tree on k + 1 vertices. Show that if G is simple, 
connected and 5(G) ^ k, then G has a subgraph isomorphic to T. 
2.26 
Show that a graph G contains A: edge-disjoint spanning trees if and 
only if for each partition (Vx, V2,..., Vt) of V the number of edges 
that have their end vertices in different parts of the partition is at least 
k(l- 
1) (Nash-Williams [2.9] and Tutte [2.10]). 
2.27 A center of a graph G = (V, E) is a vertex u such that max„ e v, 
{d(u, v)} is as small as possible, where d(u, v) is the distance between 
u and v. Show that a tree has exactly one center or two adjacent 
centers. 
2.28 The tree graph of an η-vertex connected graph G is the graph whose 
vertices are the spanning trees Γ,, T2,..., 
Tr of G, with 7", and Tf 
adjacent if and only if they have exactly n—2 edges in common. 
Show that the tree graph of any connected graph is connected 
(Cummins [2.11]). 
(Hint: See Exercise 2.23.) 

54 
TREES, CUTSETS, AND CIRCUITS 
2.11 
REFERENCES 
2.1 
D. J. Rose, "On Simple Characterizations of fc-trees," Discrete Maths., Vol. 7, 
317-322 (1974). 
2.2 
S. Seshu and M.B. Reed, Linear Graphs and Electrical Networks, Addison-
Wesley, Reading, Mass., 1961. 
2.3 
Μ. B. Reed, "The Seg: A New Class of subgraphs," IRE Trans. Circuit 
Theory, Vol. CT-8, 17-22 (1961). 
2.4 
W. H. Kim and R. T. Chien, Topological Analysis and Synthesis of Communi-
cation Networks, Columbia University Press, New York, 1962. 
2.5 
W. K. Chen, Applied Graph Theory: Graphs and Electrical Networks, North-
Holland, Amsterdam, 1971. 
2.6 
W. Mayeda, Graph Theory, Wiley-Interscience, New York, 1972. 
2.7 
Μ. N. S. Swamy and K. Thulasiraman, Graphs, Networks and Algorithms, 
Wiley-Interscience, New York, 1981. 
2.8 
H. Whitney, "On the Abstract Properties of Linear Dependence," Am. J. 
Math., Vol. 57, 509-533 (1935). 
2.9 
C. St. J. A. Nash-Williams, "Edge-Disjoint Spanning Trees of Finite Graphs," 
/. London Math. Soc, Vol. 36, 445-450 (1961). 
2.10 W. T. Tutte, "On the Problem of Decomposing a Graph into η Connected 
Factors," /. London Math. Soc, Vol. 36, 221-230 (1961). 
2.11 R. L. Cummins, "Hamilton Circuits in Tree Graphs," IEEE Trans. Circuit 
Theory, Vol. CT-13, 82-90 (1966). 

CHAPTER 3 
EULERIAN AND HAMILTONIAN 
GRAPHS 
Many discoveries in graph theory can be traced to attempts to solve 
"practical" problems—puzzles, games, and so on. One of these problems 
was the celebrated Konigsberg bridge problem. This problem may be stated 
as follows: 
There are two islands in the Pregel river in Konigsberg, Germany. These 
islands were connected to each other and to the banks of the river by seven 
bridges as shown in Fig. 3.1a. The problem was to start at any one of the 
four land areas (marked as A, B, C, and D in Fig. 3.1a), walk through each 
bridge exactly once, and then return to the starting point, that is, to 
establish a closed walk across all the seven bridges without recrossing any of 
them. 
Many were convinced that there was no solution to this problem. Indeed, 
Euler, the great Swiss mathematician, proved so in 1736 and laid the 
foundation of the theory of graphs. Euler first showed that the problem was 
equivalent to establishing a closed trail along the edges of the graph of Fig. 
3.16, where the vertices A, B, C, and D represent the land areas, and the 
edges represent the bridges connecting the land areas. He then generalized 
the problem and established a characterization of graphs in which such a 
closed trail exists. These graphs have come to be known as Eulerian graphs. 
The discussion of Section 3.1 concern these graphs. 
In 1859 Sir William Hamilton, another great mathematician, invented a 
game. The game challenges the player to establish a closed route along the 
edges of a dodecahedron that passes through each vertex exactly once. 
Hamilton's game, in graphical terms, is equivalent to determining whether 
in the graph of the dodecahedron shown in Fig. 3.2 there exists a spanning 
55 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

56 
EULERIAN AND HAMILTONIAN GRAPHS 
(a) 
(b) 
Figure 3.1. (a) Königsberg bridge problem, (b) Graph of the Königsberg bridge 
problem. 
18 
17 
Figure 3.2. Graph of Hamilton's game. 

EULERIAN GRAPHS 
57 
circuit, that is, a circuit containing all the 20 vertices. It may be verified that 
the sequence of vertices, 1,2,... ,20, 1 constitutes one such circuit in the 
graph. All graphs in which a spanning circuit exists have come to be known 
as Hamiltonian graphs. The discussions of Section 3.2 concern these graphs. 
3.1 
EULERIAN GRAPHS 
An Euler trail in a graph G is a closed trail containing all the edges of G. An 
open Euler trail is an open trail containing all the edges of G. A graph 
possessing an Euler trail is an Eulerian graph. 
Consider the graph G, shown in Fig. 3.3a. The sequence of edges e,, e2, 
e3, e4, e5, e6, e7, es, e9, el0, e n , and e12 constitutes an Euler trail in G,. 
Hence G, is Eulerian. 
In the graph G 2 of Fig. 3.36, the sequence of edges ex, e2, e3, e 4, e5, 
e6, 
e7, es, e9, e, 0, e u , eX2, and el3 constitutes an open Euler trail. However, 
there is no Euler trail in G 2. Hence G 2 is not Eulerian. 
A non-Eulerian graph G 3 with no open Euler trail is shown in Fig. 3.3c. 
The following theorem gives simple and useful characterizations of 
Eulerian graphs. 
Figure 3.3. (a) G,, an Eulerian graph, (b) G 2, a non-Eulerian graph having an open 
Euler trail, (c) G 3, a non-Eulerian graph with no open Euler trail. 

58 
EULERIAN AND HAMILTONIAN GRAPHS 
Figure 3.3. (Continued) 
Theorem 3.1. The following statements are equivalent for a connected 
graph G: 
1. G is Eulerian. 
2. The degree of every vertex in G is even. 
3. G is the union of edge-disjoint circuits. 

EULERIAN GRAPHS 
59 
Proof 
ΙΦ2 
Let Τ be an Euler trail in G. Suppose we traverse Τ starting from 
any vertex, say vx, in G. Let Τ be 
f I
 
— 
·*1 ) €\> 
%2> ^2> * 3 > · · · ' 
» - ^ Λ ' ^r> -*r+l
 
— 
where, of course, all the edges are distinct; the vertices x2,...,xr 
may not 
all be distinct and some of these vertices may be vx. Then it is clear that the 
pair of successive edges e, and e
l
+ , , l s i < r - l , contributes 2 to the degree 
of the vertex xl+l. 
In addition, vertex i>, gets a contribution of 2 to its degree 
from the initial and the final edges e, and er. Thus all the vertices are of 
even degree. 
2φ3 
Since G is connected and every vertex in G has even degree, it 
follows that the degree of each vertex in G is greater than 1. Thus G has no 
pendant vertices. Hence G is not a tree by Theorem 2.5. This means that G 
has at last one circuit, say C,. 
Consider the graph Gx = G - Cx. Since every vertex in C, is also of even 
degree, it follows that every vertex in Gx must have even degree. However, 
G, may be disconnected. 
If G, is totally disconnected, that is, G, contains only isolated vertices, 
then G = Cx and statement 3 is proved. Otherwise G, has at least one circuit 
C 2. 
Consider next the graph G 2 = G, - C2 = G - C, — C2. Again every ver-
tex in G 2 has even degree. If G 2 is totally disconnected, then G 2 = C, U C 2. 
Otherwise repeat the procedure until we obtain a totally disconnected graph 
G„ = G - C, - C 2 — · · · - Cn, where C,, C 2 , . . . , C„ are circuits of G, no 
two of which have common edges. Then 
G = C, U C 2 U · · · U C„ 
and statement 3 is proved. 
3φ1 
Let G be the union of the edge-disjoint circuits C,, C 2 , . . . , Cn. 
Consider any of these circuits, say C,. Since G is connected, there must be 
at least one circuit, say C2, which has a common vertex vx with Cx. Let TX2 
be a closed trail beginning at u, and traversing C, and C 2 in succession. This 
trail obviously contains all the edges of C, and C2. 
Again, since G is connected, Tl2 must have a common vertex v2 with at 
least one circuit, say C3, different from C, and C 2. The closed trail Γ, 2 3 
beginning at i»2 and traversing Tx2 and C 3 in succession will contain all the 
edges of C,, C 2, and C 3. 
Repeat this procedure until the closed trail Tx2i...n containing all the 
edges of C,, C 2 , . . . , C„ is obtained. This closed trail is an Euler trail in G. 
Hence G is Eulerian. 
• 

60 
EULERIAN AND HAMILTONIAN GRAPHS 
By this theorem, the graph G, of Fig. 3.3a is Eulerian because every 
vertex in Gx is of even degree, whereas the graphs G 2 and G 3 of Fig. 3.3ft 
and 3.3c are not Eulerian since they contain some vertices of odd degree. It 
may also be verified that the Eulerian graph G, is the union of the 
edge-disjoint circuits whose edge sets are 
{e 3, e 7, e g } , 
{e 2, e 9, e 1 0} , 
{
ei>
 
e\\i
 
e \ i i 
• 
The following result is a consequence of statement 3 of Theorem 3.1. 
Corollary 3.1.1. Every vertex of an Eulerian graph is contained in some 
circuit. 
• 
Though an Euler trail does not exist in a graph that contains some 
vertices of odd degree, it is possible to construct in such a graph a set of 
edge-disjoint open trails that together contain all the edges of the graph. 
This is proved in the next theorem. 
Theorem 3.2. Let G = (V, E) be a connected graph with 2k odd degree 
vertices, k^ 1. Then Ε can be partitioned into subsets El,E2,...,Ek 
such 
that each Ei constitutes an open trail in G. 
Proof. Let r, and st, 1 £ i 
k, be the 2k odd degree vertices of G. Now to 
G add k new vertices iv,, w2,... 
,wk together with 2k edges (r,, w,) and 
(s,, w,), 1 < ι < &. In the resulting graph G' every vertex is of even degree, 
and hence G' is Eulerian. 
It may be noted that in any Euler trail of G\ the edges (r,, iv,) and 
(s f, w,) for any 1 s i < k appear consecutively. Removal of these 2k edges 
will then result in k edge-disjoint open trails of G such that each edge of G 
is present in precisely one of these trails. These open trails give the required 
partition of E. 
• 
Corollary 3.2.1. Let G be a connected graph with exactly two odd degree 
vertices. Then G has an open trail (which begins at one of the odd degree 
vertices and ends at the other) containing all the edges of G. 
• 
For example, the graph G 2 of Fig. 3.3ft has exactly two odd degree 
vertices v6 and v3, and the open trail {e,, e2, e3, e 4, e 5, e 6, e 7, c g, e 9, e 1 0, e u , 
e u >
 
e \ i ) contains all the edges of G 2. This trail begins at v6 and ends at u 3. 
The graph G 3 of Fig. 3.3c has four odd degree vertices. This graph has 
two edge-disjoint open trails constituted by the following sets of edges: 

EULERIAN GRAPHS 
61 
»4 
Figure 3.4. A graph randomly Eulerian from two vertices. 
{
e i 
ι
 
e2i
 
e i i
 
E 4 > ^ 5 } 
{
e6'
 
e T
 
C 8 '
 
e9i
 
eW
 
e\\i
 
e n } 
· 
A graph G is said to be randomly Eulerian from a vertex υ if, whenever 
we start from υ and traverse along the edges of G in an arbitrary way, we 
eventually obtain an Euler trail. 
It should be noted that if a graph G is randomly Eulerian from a vertex v, 
then it should be possible to extend every closed v-v trail not containing all 
the edges to an Euler trail of G. In other words, if an Eulerian graph G is 
not randomly Eulerian from a vertex 1», then there must be a closed v-v trail 
containing all the edges incident on ν but not containing all the edges of G. 
For example, consider the Eulerian graph of Fig. 3.4. This graph is 
randomly Eulerian from vertices vx and v2. It is not randomly Eulerian from 
the other vertices. It may be verified that for each vertex u, different from vx 
and v2 there exists a closed vrv, 
trail containing all the edges incident on v, 
but not containing all the edges of G. For example, the closed v3-v3 
trail 
consisting of the edges e 4, ex, e2, and e3 has this property. 
The next theorem gives a characterization of a graph that is randomly 
Eulerian from a vertex v. 
Theorem 3.3. An Eulerian graph G is randomly Eulerian from a vertex ν if 
and only if every circuit of G contains v. 
Proof 
Necessity 
Suppose graph G is randomly Eulerian from a vertex v. 
Assume that there exists a circuit C in G that does not contain v. Consider 
the graph G' = G - C. Every vertex in G' is of even degree. G' may not be 
connected. However, G", the component of G' containing v, is Eulerian, 
and it contains all the edges incident on v. Thus in G", there exists an Euler 

62 
EULERIAN AND HAMILTON IAN GRAPHS 
trail Τ starting and ending at vertex v. This trail necessarily contains all the 
edges incident on v. Therefore it cannot be extended to include the edges of 
C. This contradicts the fact that G is randomly Eulerian from v. 
Sufficiency 
Let vertex υ in an Eulerian graph G be present in every 
circuit of G. Assume that G is not randomly Eulerian from v. Then there 
exists a closed v-v trail Τ containing all the edges incident on ν but not 
containing all the edges of G. Further, there exists a vertex u Φ ν such that it 
is the end vertex of an edge not in T. 
On removing from G the edges of T, a graph G' in which υ is an isolated 
vertex results. In G' every vertex is of even degree. So the component of G' 
containing u is an Eulerian graph. By Corollary 3.1.1 there is a circuit 
containing w. This circuit obviously does not contain vertex v. This con-
tradicts the hypothesis that ν is in every circuit of G. 
• 
It may be verified that in the graph G of Fig. 3.4, vertices vx and v2 are 
present in every circuit of G. Thus G is randomly Eulerian from both these 
vertices. On the other hand, for each one of the other vertices there exists a 
circuit not containing it. 
A graph is randomly Eulerian if it is randomly Eulerian from each of its 
vertices. It then follows from Theorem 3.3 that all the vertices of a randomly 
Eulerian graph G are in exactly one circuit C of G and there is no other 
circuit in G. In other words, G is randomly Eulerian if and only if it is a 
circuit. 
The characterizations of Eulerian graphs given in Theorem 3.1 are not 
constructive in nature. An efficient algorithm to construct an Euler trail in 
an Eulerian graph will be presented in Chapter 11 (Section 11.6) where we 
shall also discuss, among other things, the well-known Chinese postman 
problem, an important application of Eulerian graphs. 
3.2 
HAMILTONIAN GRAPHS 
A Hamilton circuit in a graph G is a circuit containing all the vertices of G. 
A Hamilton path in G is a path containing all the vertices of G. 
A graph G is defined to be Hamiltonian if it has a Hamilton circuit. 
The graph G, shown in Fig. 3.5a is Hamiltonian because the sequence of 
edges e,, e2, e 3, e 4, e5, e6 constitutes a Hamilton circuit in G,. The graph of 
Fig. 3.56 has a Hamilton path formed by the edges e,, e 2, e*3, e4, but it has 
no Hamilton circuit. 
Whereas an Euler trail is a closed walk passing through each edge exactly 
once, a Hamilton circuit is a closed walk passing through each vertex exactly 
once. Thus there is a striking similarity between an Eulerian graph and a 
Hamiltonian graph. This may lead one to expect that there exists a simple, 
useful, and elegant characterization of a Hamiltonian graph, as in the case 

HAMILTONIAN GRAPHS 
63 
(«) 
101 
Figure 3.5. (a) A Hamiltonian graph. 
(b) A non-Hamiltonian graph having a 
Hamilton path. 
of Eulerian graphs. Such is not the case; in fact, development of such a 
characterization is a major unsolved problem in graph theory. However, 
several sufficient conditions have been established for a simple graph to be 
Hamiltonian. (Recall that a graph is simple if it has neither parallel edges 
nor self-loops.) We consider some of these conditions in this section. 
A sequence d, s d 2 s • · · < d„ is said to be graphic if there is a graph G 
with η vertices vx, v2 
v„ such that the degree d(v,) of u, equals d, for 
each i. (d,, d 2 , . . . , d„) is then called the degree sequence of G. 
If 
and 
d, < d, < · · · s d 
1 
2 
π 
S*: 
d , * < d 2 * < - < d ^ 
are graphic sequences such that d* > d, for 1 < / < n, then S* is said to 
majorize S. 
The following result is due to Chvatal [3.1]. 
Theorem 3.4. A simple graph G = (V, E) of order n, with degree sequence 
• · s d„, is Hamiltonian if 
d , < d 2 
(3.1) 
Proof. First note that if dk s A:, then the number of vertices with degrees 

64 
EULERIAN AND HAMILTONIAN GRAPHS 
not exceeding k is at least k. Similarly if dn_k s η - k, then the number of 
vertices whose degrees are not exceeded by η - k is at least k + 1. Further, 
if a graphic sequence satisfies (3.1), then so does every graphic sequence 
that majorizes it. 
We now prove the theorem by contradiction. 
Let there be a simple non-Hamiltonian graph whose degree sequence 
satisfies (3.1). Then this graph is a spanning subgraph of a simple maximal 
non-Hamiltonian graph G = (V, E) whose degree sequence d, < d 2 < · · • < 
d„ also satisfies (3.1). 
Let u and υ be two nonadjacent vertices in G such that d(w) + d(v) is as 
large as possible and d(u) s d(v). Since G is maximal non-Hamiltonian, it 
follows that addition of an edge joining u and υ will result in a Hamiltonian 
graph. Thus in G there is a Hamilton path « = ux, w2, u 3 , . . . , un = υ with u 
and ν as the end vertices (Fig. 3.6). Let 
5 = {i|(u,, « , + , ) £ £ } , 
T={i\(u„un)EE}. 
Now there is n o / e S Π Τ. For if jε S Π Τ, then the edges («,, w J + 1) and 
(u , u„) would be in G, 
and so the cyclic sequence of vertices 
Uj, u 
i,..., 
u,, u!+1, 
u/+2, 
. . · , « „ , w, would form a Hamilton circuit in G. 
Since the vertex M„ = υ is neither in S nor in 7\ it follows that S U 7 C 
{ 1 , 2 , . . . , η - 1}. Therefore, 
d(«) + d(u) = |5| + | T | < n 
and 
<*(")< 3 « . 
where |A"| denotes the number of elements in set X. 
Since S Π Τ = 0 , no wy with / £ 5 is adjacent to v. The choice of d(u) and 
d(i>) then implies that for jES, 
d(w ;)<d(«). Thus there are at least 
\S\ = d(u) vertices whose degrees do not exceed d(u). So if we set k = d(«), 
then we get d t ^ Λ < 5 « , and therefore by (3.1) dn_k^n- 
k. This means 
that there are at least k + 1 vertices whose degrees are not exceeded by 
η - k. The vertex u can be adjacent to at most k of these k + 1 vertices 
because d(u) = 
Thus there is a vertex w with d(w) > π - k, which is not 
adjacent to u. But then d(u) + d[w)szn>d(u) 
+ d(v) contradicting the 
choice of d(u) and d(v). 
• 
Figure 3.6 

HAMILTONIAN GRAPHS 
65 
We establish, in the following corollary, the sufficient conditions de-
veloped by Dirac [3.2], Ore [3.3], Posa [3.4], and Bondy [3.5] for a graph to 
be Hamiltonian. 
Corollary 3.4.1. A simple graph G = (V,E) 
of order n > 3 with degree 
sequence d, < d 2 < · · · < d n is Hamiltonian if one of the following conditions 
is satisfied: 
1. (Dirac) 
l < J t < n ^ d
t > | n . 
2. (Ore) 
(κ, v)0Εφ 
d(u) + d(v)> n. 
3. (Posa) 
1<A:< 
\n^dk>k. 
4. (Bondy) j < k, d ; < j , dk< k - 1 Φ dt + dk> 
n. 
Proof. We prove by showing that all these conditions imply (3.1). 
1Φ2 
Clearly any degree sequence that satisfies condition 1 also satis-
fies condition 2. 
2Φ3 
If this is not true, then there exists a t such that 1 =£ t< \n and 
Now suppose there exists an / with l< t and (v„ v,)0E. Then 
d, + d, <2d, < 2 · \n = n, 
contradicting condition 2. Therefore the induced subgraph of G on the 
vertices i>,, v2,..., 
v, is a complete graph. 
Since d, ^ t, every vertex υ,, 1 ^ ι' ^ f, is adjacent to at most one vertex 
vt, r + l < ; ' < / i . Further, t<\n 
implies that n-t>t. 
So there exists a 
vertex vr 
f + l < / < n , which is not adjacent to any v,, l ^ i ^ t . Thus 
dt < π - t - 1. But then 
d, + d ; < r + n - f- l 
Thus were have (v„ vf)0E and d, + dy. < η contradicting condition 2. 
If this is not true, then there exists a j<k 
such that d ; 
;', 
d* := A: - 1 and df + dk< n. Then d ; < 
If we now set t = d ; < 
we get 
Therefore we have / < 5/1 and d, s t contradicting condition 3. 
4φ(3.1) 
If this is not true, then there exists a t such that d, 
t < \n 
and d„_, < η — t - 1. But then 

66 
EULERIAN AND HAMILTONIAN GRAPHS 
d, + dn_,<t+ 
n - 
t - \ 
= 
n - l , 
contradicting condition 4. 
• 
It is easy to see that if a graphic sequence satisfies any one of the 
conditions stated in Theorem 3.4 and Corollary 3.4.1, so does every graphic 
sequence that majorizes it. Chvatal's condition, the weakest of these five 
conditions, has the interesting property that it is the best condition of this 
kind. That is, if a graphic sequence fails to satisfy Chvatal's condition, then 
it is majorized by the degree sequence of a non-Hamiltonian graph [3.1]. 
Though, in general, it is difficult to establish the non-Hamiltonian nature 
of a graph, in certain cases it may be possible to do so by the use of some 
shrewd arguments. This is illustrated in Liu [3.6] through the following 
example. 
Consider the graph G shown in Fig. 3.7. We show that there is no 
Hamilton path in G. 
Among all the edges incident on any vertex at most two can be included 
in any Hamilton path. In the graph G, vertex i>8 is of degree 5, and hence at 
least three of the edges incident on u 8 cannot be included in any Hamilton 
path. The same is true of the vertices vl0 and v12. Since the degrees of 
v2,v4, 
v6, and u 1 6 are equal to 3, at least one of the three edges incident on each of 
»4 
Figure 3.7. A non-Hamiltonian graph. 

FURTHER READING 
67 
these vertices cannot be included in a Hamilton path. Thus at least 13 of the 
27 edges of G cannot be included in any Hamilton path. Hence there are not 
enough edges to form a Hamilton path on the 16 vertices of G. Thus G has 
no Hamilton path. 
A graph is randomly Hamiltonian from a vertex υ if any path starting 
from υ can be extended to be a Hamilton v-v circuit. A graph is randomly 
Hamiltonian if it is randomly Hamiltonian from each of its vertices. 
The following theorem completely characterizes randomly Hamiltonian 
graphs. Proof of this theorem may be found in Behzad and Chartrand [3.7]. 
Theorem 3.5. A simple graph of order η is randomly Hamiltonian if and 
only if it is a circuit or a complete graph or the complete bipartite graph 
Knl2nl2, 
the last one being possible only when η is even. 
• 
We conclude this section with a reference to the traveling salesman 
problem. The problem is as follows: 
A salesman is required to visit a number of cities. What is the route he 
should take, if he has to start at his home city, visit each city exactly once, 
and then return home traveling the shortest distance? 
Suppose we represent cities by the vertices of a graph and roads by edges 
connecting the vertices. The length of a road may be represented as a weight 
associated with the corresponding edge. If between every pair of vertices 
there is a road connecting them, then it may be seen that the traveling 
salesman problem is equivalent to finding a shortest Hamilton circuit in a 
complete graph in which each edge is associated with a weight/ 
In a complete graph of order η there exist (n - l)!/2 Hamilton circuits. 
One "brute-force" approach to solving the traveling salesman problem is to 
generate all the (n - l)!/2 Hamilton circuits and then pick the shortest one. 
The labor in this approach is too great (even for a computer), even for 
values of η as small as 50. For arbitrary values of n, no efficient algorithm 
for solving this problem exists. 
More discussions on the traveling salesman problem and related al-
gorithms may be found in Lin and Kernighan [3.8], Belmore and 
Nemhauser [3.9], Held and Karp [3.10] and [3.11], Rosenkrantz, Stearns, 
and Lewis [3.12], and Lawler, Lenstra, Kan, and Shmoys [3.13]. 
3.3 
FURTHER READING 
Berge [3.14] proves, in a unified manner, several sufficient conditions for a 
graph to be Hamiltonian. This book also discusses the question of partition-
ing the edge set of a graph into paths, circuits, and so on. See also Bondy 
f The weight of a circuit is the sum of the weights of the edges in the circuit. 

68 
EULERIAN AND HAMILTONIAN GRAPHS 
and Murty [3.15], Chartrand and Lesniak [3.16], Bollobas [3.17], Nash-
Williams [3.18], and Lesniak-Foster [3.19]. 
We mentioned in Section 3.2 that if the degree sequence of a graph does 
not satisfy Chvatal's condition (3.1), then it is majorized by the degree 
sequence of a non-Hamiltonian graph. Further there are graphic sequences 
that do not satisfy (3.1), but that are necessarily degree sequences of 
Hamiltonian graphs. See Nash-Williams [3.20]. 
Motivated by Ore's sufficient condition (see Corollary 3.4.1), Bondy and 
Chvatal introduced in [3.21] the concept of the closure of a graph and 
obtained a sufficient condition for a graph to be Hamiltonian. They also 
showed how this result can be used to deduce Theorem 3.4 and Corollary 
3.4.1. Generalizations of these ideas may be found in [3.17]. Also see [3.13], 
[3.15], and [3.16] and Exercises 3.14 and 3.16. 
3.4 
EXERCISES 
3.1 
Let G = (V, E) be a connected graph with 2k odd degree vertices, 
k 2: 1. Then Ε can be partitioned into subsets 
E2,..., 
Ek so that 
for each i, E, is a trail connecting odd degree vertices and such that at 
most one of these trails has odd length (Chartrand, Polimeni, and 
Stewart [3.22]). 
3.2 
Prove that a nontrivial connected graph G is Eulerian if and only if 
every edge of G lies on an odd number of circuits (Toida [3.23]). 
3.3 
Prove that if a graph G is randomly Eulerian from a vertex v, then ν 
is the only cut-vertex or G has no cut-vertices. 
3.4 
Let G be an Eulerian graph with η ^ 3 vertices. Prove that G is 
randomly Eulerian from none, one, two, or all of its vertices. 
3.5 
If a graph G is randomly Eulerian from a vertex v, then prove that 
A(G) = d(v), where A(G) is the maximum degree in G. 
3.6 
Let G be a randomly Eulerian graph from a vertex v. If d(u) = d(v), 
UJ^V, 
then prove that G is randomly Eulerian from u. 
3.7 
Do there exist graphs in which an Euler trail is also a Hamilton 
circuit? Characterize such graphs. 
3.8 
Show that the graph of Fig. 3.8 does not have a Hamilton path. 
3.9 
Let G be a connected simple graph with η > 25(G) vertices. Prove 
that the length of a longest path of G should be greater than or equal 
to 25(G), where 5(G) is the minimum degree in G (Dirac [3.2]). 
3.10 Let G be a simple connected graph with η & 3 vertices such that for 
any two nonadjacent vertices u and υ in G 

EXERCISES 
69 
Figure 3.8 
d(u) + d(v) > A:. 
Show that if k = n, G is Hamiltonian and if k < n, G contains a path 
of length k and a circuit of length (k + 2)12. 
3.11 Let d, s d2 s · • · < dn be the degrees of a simple graph with η ^ 2 
vertices. If 
d ^ s f c - l s ^ n - ΐ φ dn+l_k 
^ η - k , 
then prove that G has a Hamilton path (Chvatal [3.1]). 
3.12 
Let G be a simple graph with η vertices and m edges such that n ^ 3 
and m > ( n
2 - 3 n + 6)/2. Prove that G is Hamiltonian (Ore [3.3]). 
3.13 
Let G be a simple graph with η vertices, and u and ν be nonadjacent 
vertices in G such that 
d(u) + d(u) > η . 
Denote by G' the graph obtained by adding edge («, v) to G. Show 
that G is Hamiltonian if and only if G' is Hamiltonian. 
3.14 The closure of a simple graph G with η vertices is the graph obtained 
from G by recursively joining pairs of nonadjacent vertices whose 
degree sum is at least η until no such pair remains. Show that the 
closure of a graph is well-defined. 
(Note: An easy consequence of Exercise 3.13 is that a graph is 
Hamiltonian if and only if its closure is Hamiltonian. So G is 
Hamiltonian if its closure is complete. For an algorithm to determine 

70 
EULERIAN AND HAMILTONIAN GRAPHS 
3.5 
REFERENCES 
3.1 
V. Chvatal, "On Hamilton's Ideals," /. Combinatorial Theory B, Vol. 12, 
163-168 (1972). 
3.2 
G. A. Dirac, "Some Theorems on Abstract Graphs," Proc. London Math. 
Soc, Vol. 2, 69-81 (1952). 
3.3 
O. Ore, "Arc Coverings of Graphs," Ann. Mat. Pura Appl., Vol. 55, 315-321 
(1961). 
3.4 
L. Posa, "A Theorem Concerning Hamilton Lines," Magyar Tud. Akad. Mat. 
Kutato Int. Kozl., Vol. 7, 225-226 (1962). 
3.5 
J. A. Bondy, "Properties of Graphs with Constraints on Degrees," Studia Sci. 
Math. Hungar., Vol. 4, 473-475 (1969). 
3.6 
C. L. Liu, Introduction to Combinatorial Mathematics, McGraw-Hill, New 
York, 1968. 
3.7 
M. Behzad and G. Chartrand, Introduction to the Theory of Graphs, Allyn 
and Bacon, Boston, 1971. 
3.8 
S. Lin and B. W. Kernighan, "An Effective Heuristic Algorithm for the 
Traveling Salesman Problem," Oper. Res., Vol. 21, 498-516 (1973). 
3.9 
M. Belmore and G. L. Nemhauser, "The Traveling Salesman Problem: A 
Survey," Oper. Res., Vol. 16, 538-558 (1968). 
3.10 M. Held and R. M. Karp, "The Traveling Salesman Problem and Minimum 
Spanning Trees," Oper. Res., Vol. 18, 1138-1162 (1970). 
a Hamilton circuit of G given a Hamilton circuit of the closure of G, 
see [3.21] and [3.13].) 
3.15 
Prove that the maximum number of pairwise edge-disjoint Hamilton 
circuits in the complete graph Kn is [(n - l)/2j. 
(Note: [x\ means the greatest integer less than or equal to x.) 
3.16 
A simple graph G is Hamilton connected if for every pair of distinct 
vertices u and ν of G there exists a Hamilton u-υ path. If a simple 
graph G is of order n, then the (n + \)-closure of G is the graph 
obtained from G by recursively joining pairs of nonadjacent vertices 
whose degree sum is at least η + 1 until no such pair remains. Show 
that if the (n + l)-closure of a simple graph G is complete, then G is 
Hamilton connected. 
(Note: An easy corollary of this result is that a simple graph G is 
Hamilton connected if d(u) + d(v) s η + 1, for all distinct nonadja-
cent vertices u and ν of G. In fact, it is this result that suggested the 
definition of the (n + l)-closure of a graph. See Ore [3.24] and Erdos 
and Gallai [3.25].) 
3.17 
Show that the tree graph (defined in Exercise 2.28) of a connected 
graph is Hamiltonian (Cummins [3.26], Shank [3.27]). 

REFERENCES 
71 
3.11 Μ. Held and R. M. Karp, "The Traveling Salesman Problem and Minimum 
Spanning Trees: Part II," Math. Programming, Vol. 1, 6-25 (1971). 
3.12 D. J. Rosenkrantz, R. E. Stearns, and P. M. Lewis, "An Analysis of Several 
Heuristics for the Travelling Salesman Problem," SI AM J. Comput., Vol. 6, 
563-581 (1977). 
3.13 E. L. Lawler, J. K. Lenstra, A. H. G. Rinnooy Kan, and D. B. Shmoys, Eds.; 
The Travelling Salesman Problem, Wiley-Interscience, New York, 1985. 
3.14 C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
3.15 J. A. Bondy and U. S. R. Murty, Graph Theory with Applications, Macmillan, 
London, 1976. 
3.16 G. Chartrand and L. Lesniak, Graphs and Digraphs, Wadsworth and Brooks/ 
Coles, Pacific Grove, Calif., 1986. 
3.17 B. Bollobas, Graph Theory: An Introductory Course, Springer-Verlag, New 
York, 1979. 
3.18 C. St. J. A. Nash-Williams, "Hamiltonian Circuits," in Studies in Graph 
Theory, Part II, MAA Press, Washington, D.C., 1975, pp. 301-360. 
3.19 L. Lesniak-Foster, "Some Recent Results in Hamiltonian Graphs," J. Graph. 
Theory, Vol. 1, 27-36 (1977). 
3.20 C. St. J. A. Nash-Williams, "Hamilton Arcs and Circuits," in Recent Trends in 
Graph Theory, Springer, Berlin, 1971, pp. 197-210. 
3.21 J. A. Bondy and V. Chvatal, "A Method in Graph Theory," Discrete Math., 
Vol. 15, 111-135 (1976). 
3.22 G. Chartrand, A. D. Polimeni, and M. J. Stewart, "The Existence of 
1-Factors in Line Graphs, Squares, and Total Graphs," Indag. Math., Vol. 35, 
228-232 (1973). 
3.23 S. Toida, "Properties of an Euler Graph," J. Franklin Institute, Vol. 295, 
343-345 (1973). 
3.24 O. Ore, "Hamilton Connected Graphs," J. Math. Pures. Appl., Vol. 42, 
21-27 (1963). 
3.25 P. Erdos and T. Gallai, "On Maximal Paths and Circuits of Graphs," Acta 
Math. Acad. Sci. Hung., Vol. 10, 337-356 (1959). 
3.26 R. L. Cummins, "Hamilton Circuits in Tree Graphs," IEEE Trans. Circuit 
Theory, Vol. CT-13, 82-90 (1966). 
3.27 H. Shank, "A Note on Hamilton Circuits in Tree Graphs," IEEE Trans. 
Circuit Theory, Vol. CT-15, 86 (1968). 

CHAPTER 4 
GRAPHS AND VECTOR SPACES 
Modern algebra has proved to be a very valuable tool for engineers and 
scientists in the study of their problems. Identifying the algebraic structure 
associated with a set of objects has been found to be very useful since the 
powerful and elegant results relating to the algebraic structure can then be 
brought to bear upon the study of such a set. Systems theory, electrical 
network theory, coding theory, switching circuits (sequential and combina-
tional), and computer science are some examples of areas that have 
benefited by taking such an approach. 
In this chapter we show that a vector space can be associated with a 
graph, and we study in detail the properties of two important subspaces of 
this vector space, namely, the cutset and circuit spaces. 
In the first two sections of this chapter, we provide an introduction to 
some elementary algebraic concepts and results that will be used in the 
discussions of the subsequent sections. For more detailed discussions of 
these concepts and related results in linear algebra MacLane and Birkhoff 
[4.1], Halmos [4.2], and Hohn [4.3] may be consulted. 
4.1 
GROUPS AND FIELDS 
Consider a finite set S = {a, ft, c,...}. 
Let + denote a binary operation 
defined on S. This operation assigns to every pair of elements a and b of 5 a 
unique element denoted by α + ft. The set S is said to be closed under + if 
the element a + ft belongs to S whenever a and ft are in 5. 
The operation + is said to be associative if 
72 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

GROUPS AND FIELDS 
73 
a + (b + c) = (a + b) + c 
for all a, b, and c in 5 . 
Further, it is said to be commutative if 
a + b = b + a 
for all α and binS 
. 
We are now in a position to define a group. 
A set S with a binary operation + , called addition, is a group if the 
following postulates hold: 
1. 5 is closed under +. 
2. + is associative. 
3. There exists a unique element e in S such that a + e = e + a = a for all 
a in 5. The element e is called the identity of the group. 
4. For each element a in S there exists a unique element b such that 
b + a = a + b = e. The element 6 is called the inverse of a and vice 
versa. Clearly the identity element e is its own inverse. 
A group is said to abelian if the operation + is commutative. 
A common example of a group is the set S = {..., - 2 , - 1 , 0 , 1 , 2 , . . . } of 
all integers, with + defined as the usual addition operation. In this group, 0 
is the identity element and —a is the inverse of a for all a in S. Note that this 
group is abelian. 
Is the set 5 of all integers with the multiplication operation a group? (No. 
Why?) 
An important example of a group is the set Zp = { 0 , 1 , 2 , . . . , ρ - 1} of 
integers with modulo
+ ρ addition operation. In this group, 0 is the identity 
element. Further the integer ρ - a is the inverse of the integer a, for all a 
not equal to 0. Of course, 0 is its own inverse. This group is also abelian. As 
an example, the addition table for Z 5 is as follows: 
-Ι-
0 
1 
2 
3 
4 
Ο 
0 
1 
2 
3 
4 
1 
1 
2 
3 
4 
0 
2 
2 
3 
4 
0 
1 
3 
3 
4 
0 
1 
2 
4 
4 
0 
1 
2 
3 
Next we define a field. 
A set F with two operations + and ·, called, respectively, addition and 
multiplication, is a field if the following postulates are satisfied: 
fIf a = mp + q, 0 s q < ρ - 1, then in modulo arithmetic a = ^(modulo p). 

74 
GRAPHS AND VECTOR SPACES 
1. F is an abelian group under +, with the identity element denoted as e. 
2. The set F-{e) 
is an abelian group under ·, the multiplication 
operation. 
3. The multiplication operation is distributive with respect to addition; 
that is, 
a • (b + c) = (a · b) + (a • c) 
for all a, b, and c in F . 
As an example, consider again the set Z = { 0 , l , 2 , . . . , p - 1 } with addi-
tion (modulo p) and multiplication (modulo p) as the two operations. As 
shown earlier, Zp is an abelian group under modulo ρ addition, with 0 as the 
identity element. It can be shown that the set Zp - {0} = { 1 , 2 , . . . , 
ρ - 1} is a group under modulo ρ multiplication if and only if ρ is prime. 
This group is also abelian. The fact that modulo ρ multiplication is distribu-
tive with respect to modulo ρ addition may be easily verified. Thus the set 
Zp is a field if and only if ρ is prime. 
The field Zp is usually denoted as G¥(p) and is called a Galois field. The 
following multiplication table for GF(5) is given as an illustration: 
0 
1 
2 
3 
4 
0 
0 
0 
0 
0 
0 
1 
0 
1 
2 
3 
4 
2 
0 
2 
4 
1 
3 
3 
0 
3 
1 
4 
2 
4 
η 
4 
3 
2 
1 
A field that is of special interest to us is GF(2), the set of integers modulo 2. 
In this field 
0 + 0 = 0 
0-0 = 0 
1 + 0 = 0 + 1 = 1 
1-0 = 0 - 1 = 0 
1 + 1 = 0 
1-1 = 1. 
4.2 
VECTOR SPACES 
Consider a set S with a binary operation B . Let F be a field with + and · 
denoting, respectively, the addition and multiplication operations. A multi-
plication operation, denoted by *, is also defined between elements in F and 
those in S. This operation assigns to each ordered pair (a, s), where a is in F 
and s in S, a unique element denoted by a * s of 5. The set 5 is a vector 
space over F if the following postulates hold: 

VECTOR SPACES 
75 
1. 5 is an abelian group under Ξ. 
2. For any elements a and β in F, and any elements s, and s2 in S, 
a *(s, E)s 2) = (a * j , ) E ( a *s 2) 
and 
( α + β ) * ί 1 = ( « * ϊ 1 ) Ξ ( / 8 * ϊ Ι ) . 
3. For any elements α and /3 in F and any element s in 5, 
(a · /3)*s = a *(/3 *s). 
4. For any element s in S, 1 * s = s, where 1 is the multiplicative identity 
in F. 
Next we give an important example of a vector space. 
Consider the set W of all n-vectors
+ over a field F. (Note that the 
elements of the η-vectors are chosen from F.) The symbols + and • will, 
respectively, denote the addition and multiplication operations in F, and the 
symbols 0 and 1 will denote the additive and multiplicative identities in F. 
Let Ξ , an addition operation on W, and *, a multiplication operation 
between the elements of F and those of W, be defined as follows: 
1. If ω, = (α,, α 2 , . . . , αη) and ω 2 = (>31, β2,..., 
βη) are elements of W, 
then 
ω, • ω 2 = (α, + β,, α 2 + / 3 2 , . . . , α„ + β„). 
2. If α is in F, then 
a * ω, = (α · α,, α · α 2 , . . . , α · α π ) . 
With Ξ defined as above, we can easily establish that W is an abelian group 
under • , with the /i-vector ( 0 , 0 , 0 , . . . ,0) as the identity element. Thus W 
satisfies the first postulate in the definition of a vector space. We can easily 
show that the elements of IV and F also satisfy the other three requirements 
of a vector space. 
For example, the set W of the following eight 3-vectors is a vector space 
over GF(2): 
'An η-vector over F is a row vector with η elements from the field F. 

76 
GRAPHS AND VECTOR SPACES 
ω 0 = (000), 
ω, = ( 0 0 1 ) , 
ω 2 = (0 1 0 ) , 
ω 3 = (011), 
ω4 = (100), 
ω 5 = (101), 
ω 6 = (110), 
ω 7 = (111) . 
This vector space is used in all illustrations in this section. 
A few important definitions and results (without proof) relating to a 
vector space are stated next. 
Consider a vector space S over a field F. 
Vectors and Scalars Elements of 5 are called vectors and those of F are 
called scalars. 
Linear Combination If an element s in 5 is expressible as 
s = (a, * s,) Ξ (a 2 * s 2) Ξ · • · Ξ (a, * s ;), 
where s,'s are vectors and a,'s are scalars, then s is said to be a linear 
combination of s,, s2,..., 
Sj. 
Linear Independence Vectors sl,s2,... 
,sJ are said to be linearly in-
dependent if no vector in this set is expressible as a linear combination of 
the remaining vectors in the set. 
Basis Vectors Vectors sx, s2,... 
,sn form a basis in the vector space 5 if 
they are linearly independent and every vector in 5 is expressible as a 
linear combination of these vectors. The vectors s,, s2,... 
,sn are called 
basis vectors. 
It can be shown that the representation of a vector as a linear 
combination of basis vectors is unique for a given basis. A vector space 
may have more than one basis. However, it can be proved that all the 
bases have the same number of vectors. 
Dimension The dimension of the vector space 5, denoted as dim(S), is the 
number of vectors in a basis of 5. 
Subspace If 5' is a subset of the vector space S over F, then 5' is a 
subspace of 5 if 5' is also a vector space over F. 
Direct Sum The direct sum 5, • S2 of two subspaces 5, and S2 of S is the 
set of all vectors of the form s , S i , , where s, is in 5, and s ; is in S2. 
It can be shown that S, ED 5 2 is also a subspace, and that its dimension is 
given by 
dim(5, • 5 2) = dim(5,) + dim(S 2) - d i m ^ Π 5 2 ) . 
Note that S t Π S2 is also a subspace whenever Sj and 5 2 are subspaces. 
Let us illustrate these definitions using the vector space W of 3-vectors 
over GF(2). The vectors ω 0, ωχ,..., 
ω 7 of W are as defined earlier. 

VECTOR SPACES 
77 
1. ω, is a linear combination of ω 6 and ω 7 since 
ω, = ( 1 * ω 6 ) Ξ ( 1 * ω 7 ) . 
2. Vectors ω 3 and ω 4 are linearly independent since neither of these two 
can be expressed in terms of the other. Note that ω 0 and ω, are not 
linearly independent, for any i. 
3. Vectors ω,, ω 2, and ω 4 form a basis in W since they are linearly 
independent, and the remaining vectors can be expressed as linear 
combinations of these: 
ω0 = ( 0 * ω , ) Ξ ( 0 * ω 2 ) Ξ ( 0 * ω 4 ) , 
ω3 = ( 1 * ω , ) Ξ ( 1 * ω 2 ) , 
ω5 = ( 1 * ω , ) Ξ ( 1 * ω 4 ) , 
ω6 = ( 1 * ω 2 ) Ξ ( 1 * ω 4 ) , 
ω7 = (1 * ω,) Β (1 * ω 2) Ξ (1 * ω 4) . 
It may be verified that the vectors ω,, ω 3 and ω 7 also form a basis. 
4. Dimension of W is equal to 3 since there are three vectors in a basis of 
W. 
5. The sets 
W = {ω 0, ω,, ω 2, ω3} 
and 
W"= {ω0, ω,, ω 6, ω 7} 
are subspaces of W. It may be verified that {ω,, ω 2} is a basis for W, 
and {ω,, ω 6} is a basis for W". Thus 
dim(W) = 2 
and 
dim(W") = 2. 
6. If W and W" are as defined above, then 
W Ξ W" = {ω 0, ω,, ω 2, ω 3, ω 4, ω 5, ω 6, ω 7} . 
7. The dimension of W El W is given by 

78 
GRAPHS AND VECTOR SPACES 
dim( W Ξ W") = dim(lV') + dim(W") - dim( W η W") 
= 4-dim(W'n W"). 
Since 
w'nw" 
= {u>0,a>x}, 
we have 
dim( W Π W") = 1. 
Thus 
dim(W'0W") = 4 - l = 3 . 
This can also be obtained by noting that in this case W ' 0 W " = W. 
Next we define isomorphism between two vector spaces defined over the 
same field. 
Let S and 5' be two η-dimensional vector spaces over a field F. Then S 
and 5' are said to be isomorphic if there exists a one-to-one correspondence 
between S and 5' such that the following hold true: 
1. If vectors s, and s2 of 5 correspond to the vectors s[ and s'2 of S, 
respectively, then the vector s, Ξ s2 corresponds to the vector s[ Δ s'2, 
where Ξ and Δ are corresponding operations in S and S'. 
2. For any a in F, the vector a*s corresponds to the vector a As' 
if s 
corresponds to s', where * and Δ are corresponding operations in S 
and S'. 
Consider an /i-dimensional vector space S over a field F and the n-
dimensional vector space W of Λ-vectors over F. Let the vectors 
sl,s2,. 
• • ,s„ form a basis in 5. Suppose we define that a vector s in S 
corresponds to the vector ω = (α,, a2,..., 
αηγ 
of W if and only if 
s = (a, * s,) • (a 2 * s2) EE] · · · Ξ (a„ * sn). Then it is not difficult to show that 
this one-to-one correspondence defines an isomorphism between 5 and W. 
Thus we have the following important result. 
Theorem 4.1. Every η-dimensional vector space over a field F is isomorphic 
to the vector space W of η-vectors over F. 
• 
*a, 
a„ are called the coordinates of s relative to the basis { j , , s2 
s„}. 

VECTOR SPACES 
79 
Theorem 4.1 provides the main link connecting vector spaces and mat-
rices. It implies that an η-dimensional vector space over a field F can be 
studied in terms of the η-dimensional vector space W of all η-vectors over F. 
We conclude this section with the definition of two more important 
concepts—dot product (or inner product) and orthogonality. 
Let 
ω, = (α, α 2 · · · α„) 
and 
ω 2 = (/3, 
β2--β„) 
be two vectors in the vector space W of η-vectors over F. The dot product of 
ω, and ω 2, denoted by (ω,, ω 2), is a scalar defined as 
<ω,, ω 2) = α, · 0, + α 2 · β2 + • • • + αη • β„ . 
For example, if 
ω, = (0 
1 0 0 
1) 
and 
ω 2 = (1 0 
1 1 
1), 
then 
( ω, ω 2) = 0 · 1 + 1 · 0 + 0 · 1 + 0 · 1 + 1 · 1 
= 0 + 0 + 0 + 0 + 1 
= 1 . 
Vectors ω, and ω, are orthogonal to each other if (ω,, ω ) = 0, where 0 is 
the additive identity in F. For example, the vectors 
ω, = (1 
1 0 
1 1) 
and 
ω 2 = (1 
1 1 0 
0) 
are orthogonal over GF(2) since 

80 
GRAPHS AND VECTOR SPACES 
4.3 
VECTOR SPACE OF A GRAPH 
In this section we show how we can associate a vector space with a graph, 
and we also identify two important subspaces of this vector space. 
Consider a graph G = (V, E). Let WG denote the collection of all subsets 
of E, including the empty set 0 . First we show that Wc is an abelian group 
under Θ, the ring sum operation between sets. After suitably defining 
multiplication between the elements of the field GF(2) and those of WG, we 
show that Wo is a vector space over GF(2). 
The following are easy to verify: 
1. Wc is closed under Θ. 
2. θ is associative. 
3. φ is commutative. 
Further, for any element E, in WG, 
Είθ0=Ει 
and 
£ , © £ , = 0 . 
Thus for the operation Θ, 0 is the identity element, and each E, is its 
own inverse. Hence WG is an abelian group under Φ, thereby satisfying the 
first requirement in the definition of a vector space. 
<«,, ω2> = 1-1 + 1-1 + 0-1 + 1-0+ 1-0 
= 1 + 1 + 0 + 0 + 0 
= 0. 
Two subspaces W and W" of W are orthogonal subspaces of W if each 
vector in one subspace is orthogonal to every vector in the other subspace. 
Two subspaces W and W" of W are orthogonal complements if they are 
orthogonal to each other and their direct sum W Ξ W" is equal to the 
vector space W. 
For example, consider again the three-dimensional vector space W of 
3-vectors 
over 
GF(2). 
In 
this 
vector space 
the 
subspaces 
W = 
{ω 0, ω,, ω 2, ω 3) and W" = {ω 0, ω 4} are orthogonal to each other. It may be 
verified that the direct sum of W and W" is equal to W. Hence they are 
orthogonal complements. 

VECTOR SPACE OF A GRAPH 
81 
Let *, a multiplication operation between the elements of GF(2) and 
those of WG, be defined as follows: 
For any £,· in WG, 
l*E, = E, 
and 
0*E, = 0 . 
With this definition of * we can easily verify that the elements of Wc 
satisfy the following other requirements for a vector space: 
For any elements α and β in GF(2) = {0,1}, and any elements £, and £ ; 
in 
Wc, 
1. (a + β)*Ει 
= 
(α*Ε,)®(β*Εί). 
2. α*(Ε,ΦΕι) 
= 
(α*Ε,)Φ(α*Ε)). 
3. (α·β)·Ε, 
= 
α*(β*Ε,). 
4. 1 *£, = £ , . 
Note that 1 is the multiplicative identity in GF(2). 
Thus WG is a vector space over GF(2). 
If Ε - {e,, e2,..., 
em}, 
then it is easy to see that the subsets {«,}, 
{e2}, • • •, {em} will constitute a basis for WG. Hence the dimension of WG is 
equal to m, the number of edges in G. 
Since each edge-induced subgraph of G corresponds to a unique subset of 
E, and by definition (see Chapter 1), the ring sum of any two edge-induced 
subgraphs corresponds to the ring sum of their corresponding edge sets, it is 
clear that the set of all edge-induced subgraphs of G is also a vector space 
over GF(2) if we define the multiplication operation * as follows: 
For any edge-induced subgraph G, of G, 
1 * G, = G, 
and 
O*G, = 0 , 
the null graph having no vertices and no edges. 
This vector space will also be referred to by the symbol WG. Note that 
WG will include 0 , the null graph. 
We summarize the results of this discussion in the following theorem. 
Theorem 4.2. For a graph G having m edges WG is an m-dimensional vector 
space over GF(2). 
• 

82 
GRAPHS AND VECTOR SPACES 
Since, in this chapter, we are concerned only with edge-induced sub-
graphs, we refer to them simply as subgraphs without the adjective "edge-
induced." However, we may still use this adjective in some places to 
emphasize the edge-induced nature of the concerned subgraph. 
Next we show that the following subsets of WG are subspaces: 
1. Wc, the set of all circuits (including the null graph 0 ) and unions of 
edge-disjoint circuits of G. 
2. Ws, the set of all cutsets (including the null graph 0 ) and unions of 
edge-disjoint cutsets of G. 
This result will follow once we show that Wc and Ws are closed under Θ, the 
ring sum operation. 
Theorem 4.3. Wc, the set of all circuits and unions of edge-disjoint circuits 
of a graph G, is a subspace of the vector space WG of G. 
Proof. By Theorem 3.1, a graph can be expressed as the union of edge-
disjoint circuits if and only if every vertex in the graph is of even degree. 
Hence we may regard Wc as the set of all edge-induced subgraphs of G, in 
which all vertices are of even degree. 
Consider any two distinct members C, and C 2 of Wc: Cx and C 2 are 
edge-induced subgraphs with the degrees of all their vertices even. Let C 3 
denote the ring sum of C t and C 2. To prove the theorem, we need only to 
show that C 3 belongs to Wc. In other words we should show that in C 3 every 
vertex is of even degree. 
Consider any vertex υ in C 3. Obviously, this vertex should be present in 
at least one of the subgraphs C, and C 2. Let AT,, i = 1,2,3, denote the set of 
edges incident on ν in C,. Let \Xt\ denote the number of edges in Xt. Thus 
\Xt\ is the degree of the vertex υ in C,. Note that \XX \ and |A"2| are even and 
one of them may be zero. Further \X3\ is nonzero. 
Since C 3 = C, Θ C 2, we get 
X3 ' Χχ φ X2 · 
Hence 
1 ^ 1 = 1 ^ 1 + 
1 ^ 1 - 2 1 ^ 0 ^ 1 . 
It is now clear from this equation that \X3\ is even, because |ΑΊ| and \X2\ 
are both even. In other words the degree of vertex υ in C 3 is even. Since this 
should be true for all vertices in C 3, it follows that C 3 belongs to Wc, and 
the theorem is proved. 
• 
Wc will be referred to as the circuit subspace of the graph G. 

VECTOR SPACE OF A GRAPH 
83 
As an example to illustrate the result of Theorem 4.3, consider the graph 
G shown in Fig. 4.1a. The subgraphs C, and C2 shown in Fig. 4.1b and 4.1c 
are unions of edge-disjoint circuits of G, since the degree of each vertex in 
these subgraphs is even. Thus they belong to the subspace Wc of Wc. The 
ring sum C 3 of C, and C 2 is shown in Fig. 4.Id. It may be seen that all the 
vertices in C 3 are of even degree. Hence C 3 also belongs to Wc. 
Figure 4.1. (a) Graph G. (b) Subgraph C, of G. (c) Subgraph C2 of G. (d) Subgraph 
C, θ C 2 of G. 

84 
GRAPHS AND VECTOR SPACES 
Next we show that Ws, the set of all cutsets and unions of edge-disjoint 
cutsets of G, is a subspace of WG. 
By Theorem 2.7, a cut is a cutset or union of some edge-disjoint cutsets. 
Thus every cut of G belongs to Ws. We now prove that every element of Ws 
is a cut. While doing so we also prove that Ws is a subspace of WG. 
Theorem 4.4. The ring sum of any two cuts in a graph G is also a cut in G. 
Proof. Consider any two cuts S, = (V,, V2) and S2 = (V3, V4) in a graph 
G = (V, E). Note that 
ν^υν2 = ν3υν4 = ν 
and 
ν,ην2 = ν3ην4 = 0 . 
Let 
A = V, Π V3, 
c= v2nv3, 
d = v2 η v4. 
It is easy to see that the sets A, B, C, and D are mutually disjoint. Then 
St = (AUB, 
CUD) 
= (A, C) U (A, D) U (B, C) U (B, D) 
and 
5 2 = < A U C , f l U D ) 
= <i4,fl>U(i4,D>U(C,B>U<C,D> . 
Hence, we get 
S
i e S
2 = (A,C)U(B, 
D)U(A,B)L)(C,D) 
. 
Since 
( / 4 U D , f l U C ) = ( / l , C ) U ( f l ( D ) U ( A , 5 ) U ( C 1 D ) , 
we can write 

VECTOR SPACE OF A GRAPH 
8 5 
S1®S2 = (AUD,BUC) 
. 
Because ADD and B U C are mutually disjoint and together include all the 
vertices in V, S, Θ S2 is a cut in G. Hence the theorem. 
■ 
Since the ring sum of two disjoint sets is the same as their union, we get 
the following corollary of Theorem 4.4. 
Corollary 4.4.1. The union of any two edge-disjoint cuts in a graph G is also 
a cut in G. 
■ 
Since a cutset is also a cut, it is now clear from Corollary 4.4.1 that Ws is 
the set of all cuts in G. 
Further, by Theorem 4.4, Ws is closed under the ring sum operation. 
Thus we get the following theorem. 
Theorem 4.5. Ws, the set of all cutsets and unions of edge-disjoint cutsets in 
a graph G, is a subspace of the vector space WG of G. 
■ 
Ws will be referred to as the cutset subspace of the graph G. 
As an example illustrating the result of Theorem 4.5, consider the 
following cuts 5, and S2 in the graph G of Fig. 4.2: 
•jj 
\^ι> e y, e 4, e$, e^, e-j) 
= 
<VltV2), 
02~ 
l e i > e2' 
e4> 
e5> 
eSI 
= (v3,vA), 
where 
»e 
Figure 4.2 

86 
GRAPHS AND VECTOR SPACES 
Vl = {Vi, 
V2, 
V4) 
, 
V2 = {v3,v5,v6) 
, 
V3 = {vl,v4,v5) 
, 
V4={v2,v3,v6}. 
Then 
S, φ S2 — {e2, e3, e6, e7, es) . 
If 
D 
A 
Β 
C 
V,nV 3 = 
{ i ;
1 , i ;
4 } , 
vlnv4 = {υ2}, 
v2nv3 = {v 5), 
v2nv4 = 
{v3,v6), 
then it is verified that the set 5, Φ 5 2 = {e2, e3, e6, e 7, es} can be written (as 
in the proof of Theorem 4.4) as 
5, Φ 5 2 = (A U D, Β U C) = ({vu 
v4, v3, v6), {v2, v5)) . 
4.4 
DIMENSIONS OF CIRCUIT AND CUTSET SUBSPACES 
In this section we show that the dimensions of the circuit and cutset 
subspaces of a graph are equal to the nullity and the rank of the graph, 
respectively. We do this by proving that the set of fundamental circuits and 
the set of fundamental cutsets with respect to some spanning tree of a 
connected graph are bases for the circuit and cutset subspaces of the graph, 
respectively. 
Let Γ be a spanning tree of a connected graph G with η vertices and m 
edges. The branches of Τ will be denoted by ft,, b2,..., 
bn_, and the chords 
by c,, c 2 , . . . , cm_n+l. 
Let C, and S, refer to the fundamental circuit and the 
fundamental cutset with respect to c, and b„ respectively. 
By definition, each fundamental circuit contains exactly one chord, and 
this chord is not present in any other fundamental circuit. Thus no fun-
damental circuit can be expressed as the ring sum of the other fundamental 
circuits. Hence the fundamental circuits C,, C 2 , . . . , C m _ n + 1 are indepen-
dent. Similarly, the fundamental cutsets St, 
S2,...,S„_i 
are also in-
dependent since each of these contains exactly one branch that is not 
present in the others. 

DIMENSIONS OF CIRCUIT AND CUTSET SUBSPACES 
87 
To prove that C,, C 2 , . . . , CM_N 
+ I (S,, S 2 , . . . , S„_,) constitute a basis for 
the circuit (cutset) subspace of G, we need only to prove that every 
subgraph in the circuit (cutset) subspace of G can be expressed as a ring sum 
of C,'s (S,'s). 
Consider any subgraph C in the circuit subspace of G. Let C contain the 
chords c , c ( , . . . , c . Let C denote the ring sum of the fundamental 
circuits C(-, C, 2,..., C . Obviously, the chords c , c, 2,..., c, are present in 
C , and C contains no other chords of T. Since C also contains these chords 
and no others, C ' 0 C contains no chords. 
We now claim that C ' 9 C is empty. If this is not true, then by the 
preceding arguments, C ' ® C contains only branches and hence has no 
circuits. On the other hand, being a ring sum of circuits, C θ C is, by 
Theorem 4.3, a circuit or the union of some edge-disjoint circuits. Thus the 
assumption that C φ C is not empty leads to a contradiction. Hence C φ C 
is empty. This implies that C = C = C ( ]® C, 2© · · · φ C,. In other words, 
every subgraph in the circuit subspace of G can be expressed as a ring sum 
of C,'s. 
In an exactly similar manner we can prove that every subgraph in the 
cutset subspace of G can be expressed as a ring sum of 5,'s. 
Thus we have the following theorem. 
Theorem 4.6. Let a connected graph G have m edges and η vertices. Then: 
1. The fundamental circuits with respect to a spanning tree of G consti-
tute a basis for the circuit subspace of G, and hence the dimension of 
the circuit subspace of G is equal to m - η + 1, the nullity of G. 
2. The fundamental cutsets with respect to a spanning tree of G consti-
tute a basis for the cutset subspace of G, and hence the dimension of 
the cutset subspace of G is equal to η - 1, the rank of G. 
• 
It is now easy to see that in the case of a graph G that is not connected, 
the set of all the fundamental circuits with respect to the chords of a forest 
of G, and the set of all the fundamental cutsets with respect to the branches 
of a forest of G are, respectively, bases for the circuit and cutset subspaces 
of G. Thus we get the following corollary of the previous theorem. 
Corollary 4.6.1. If a graph G has m edges, η vertices, and ρ components, 
then: 
1. The dimension of the circuit subspace of G is equal to m - η + ρ, the 
nullity of G. 
2. The dimension of the cutset subspace of G is equal to η — ρ, the rank 
of G. m 

88 
GRAPHS AND VECTOR SPACES 
Figure 4.3 
As an example, consider the graph G shown in Fig. 4.3. The edges 
marked as bx, b2, b3, b4 constitute a spanning tree of G. The chords of T are 
marked as cx, c2, c3, c4, and c5. The fundamental circuits C,, C2, C3, C4, 
and C5 with respect to the chords cx, c2, c3,c4, and c5, and the fundamental 
cutsets 5,, S2, S3, and S4 with respect to the branches bx, b2, b3, and b4 are 
obtained as 
C2 = (c2,bx,b2,b3} 
, 
C3 = {c3,ft3,64}, 
Q = {c4, ft2>ft4} > 
C5 = {c5, ft2, 63} . 
•S, = {bx,cx,c2} 
, 
o2 = {b2, cx, c2, c4, c5), 
Λ3 = {o3, c2, c3, c5) , 
54 = { f t4. C3» C4} · 
Consider first the subgraph C consisting of the edges bx, b2, ò3, c2, c3, c4, 
and c5. It may be verified that in C every vertex is of even degree, and hence 
C belongs to the circuit subspace of G. Since C contains the chords c2,c3,c4, 
and c5, it follows from the arguments preceding Theorem 4.6 that C should 
be equal to the ring sum of the fundamental circuits C2, C3,C4, and C5. This 
can be verified to be true as follows: 
C2S>C3G>C4®CS = {c2, bx, b2, b3)Θ{c3, b3, b4}Φ{c4, b2, b4) 
®{cs,b2,b3) 
— \bx, o2, o3, c2, c3, c4, c5) 
= C. 

RELATIONSHIP BETWEEN CIRCUIT AND CUTSET SUBSPACES 
89 
Consider next the cut S consisting of the edges bx, b3, c t , c 3, c 5. Again, 
since S contains the branches ft, and b3, it should be equal to the ring sum of 
the cutsets 5, and S3. This also can be verified to be true as follows: 
St φ Sj
 = {ftp C j , c 2} φ {ft3, c 2, C j , c 5} 
= 5 . 
In the preceding discussions we have shown that, starting from a spanning 
tree, we can construct bases for the circuit and cutset subspaces of a graph. 
The bases so constructed are commonly used in the study of electrical 
networks. 
4.5 
RELATIONSHIP BETWEEN CIRCUIT AND CUTSET SUBSPACES 
We establish in this section a characterization for the subgraphs in the circuit 
subspace of a graph G in terms of those in the cutset subspace of G. 
We proved in Section 2.8 (Theorem 2.14) that a circuit and a cutset have 
an even number of common edges. Since every subgraph in the circuit 
subspace of a graph is a circuit or the union of edge-disjoint circuits, and 
every subgraph in the cutset subspace is a cutset or the union of edge-
disjoint cutsets, we get the following as an immediate consequence of 
Theorem 2.14. 
Theorem 4.7. Every subgraph in the circuit subspace of a graph G has an 
even number of common edges with every subgraph in the cutset subspace 
of G. m 
In the next theorem we prove the converse of Theorem 4.7. 
Theorem 4.8 
1. A subgraph of a graph G belongs to the circuit subspace of G if it has 
an even number of common edges with every subgraph in the cutset 
subspace of G. 
2. A subgraph of a graph G belongs to the cutset subspace of G if it has 
an even number of common edges with every subgraph in the circuit 
subspace of G. 
Proof 
1. We may assume, without any loss of generality, that G is connected. 
The proof when G is not connected will follow in an exactly similar 
manner. 

90 
GRAPHS AND VECTOR SPACES 
Let Γ be a spanning tree of G. Let bx, b2,... 
denote the branches 
of Γ and c t, c 2 , . . . denote its chords. Consider any subgraph C of G 
that has an even number of common edges with every subgraph in the 
cutset subspace of G. Without any loss of generality, assume that C 
contains the chords c,, c 2 , . . . , cr. Let C denote the ring sum of the 
fundamental circuits C,, C 2 , . . . , C r with respect to the chords c,, 
c 2 , . . . , cr. 
Obviously, C" consists of the chords c,, c2,...,cr 
and no other 
chords. Hence C © C consists of no chords. 
C, being the ring sum of some circuits of G, has an even number of 
common edges with every subgraph in the cutset subspace of G. Since 
C also has this property, so does C φ C. 
We now claim that C ' ® C is empty. If not, C ' ® C contains only 
branches. Let bt be any branch in C Φ C. Then bt is the only edge 
common between C Θ C and the fundamental cutset with respect to 
bt. This is not possible since C'®C 
must have an even number of 
common edges with every cutset. Thus C Φ C should be empty. In 
other words, C = C = C, Φ C2 Φ · · · Θ Cr, and hence C belongs to the 
circuit subspace of G. 
2. The proof of this part follows in an exactly similar manner. 
• 
4.6 
ORTHOGONALITY OF CIRCUIT AND CUTSET SUBSPACES 
By Theorem 4.1, every η-dimensional vector space over a field F is 
isomorphic to the vector space of all η-vectors over the same field. Hence 
WG, the vector space of a graph G, is isomorphic to the vector space of all 
m-vectors over GF(2), where m is the number of edges in G. 
Let ex, e2,...,em 
denote the m edges of G. Suppose we associate each 
edge-induced subgraph G, of G with an m-vector w, such that the ;'th entry 
of w, is equal to 1 if and only if the edge et is in G,. Then the ring sum 
G, Φ G ; of two subgraphs G, and G ; will correspond to the m-vector w, + wy, 
the modulo 2 sum of wt and wt. It can now be seen that the association just 
described indeed defines an isomorphism between Wc and the vector space 
of all m-vectors over GF(2). In fact, if we choose { e j , {e2},..., 
{em} as 
the basis vectors for WG, then the entries of w, are the coordinates of G, 
relative to this basis. 
In view of this isomorphism we again use the symbol Wa to denote the 
vector space of all the m-vectors associated with the subgraphs of the graph 
G. Also, Wc will denote the subspace of m-vectors representing the 
subgraphs in the circuit subspace of G and similarly Ws will denote the 
subspace of those representing the subgraphs in the cutset subspace of G. 
Consider any two vectors w, and n>j such that w, is in Wc and wf is in Ws. 
Because every subgraph in Wc has an even number of common edges with 

ORTHOGONALITY OF CIRCUIT AND CUTSET SUBSPACES 
91 
those in Ws, it follows that the dot product (wlt w ;) of wt and w is equal to 
the modulo 2 sum of an even number of l's. This means (wt, Wj) = 0. In 
other words, the m-vectors in Wc are orthogonal to those in Ws. Thus we 
have the following theorem. 
Theorem 4.9. The cutset and circuit subspaces of a graph are orthogonal to 
each other. 
• 
Consider next the direct sum WC\BWS. 
We know that 
dim(W c Θ Ws) = dim(W c) + dim(W s) - dim(W c Π Ws). 
Since dim(lV c) + dim(Ws) = m, we get 
d i m ( W c 0 f f s ) = ( n - d i m ( W c Π 
Ws). 
Now the orthogonal subspaces Wc and Ws will also be orthogonal comple-
ments of WG if and only if dim(W c • Ws) = m. In other words Wc and Ws 
will be orthogonal complements if and only if dimiWcD Ws) = 0, that is, 
Wc Π Ws is the zero vector whose elements are all equal to zero. Thus we 
get the following theorem. 
Theorem 4.10. Wc and Ws, the circuit and cutset subspaces of a graph are 
orthogonal complements if and only if Wc Π Ws is the zero vector. 
• 
Suppose Wc and Ws are orthogonal complements. Then it means that 
every vector in WG can be expressed as wt + wjy where tv, is in Wc and w) is 
in Ws. In other words every subgraph of G can be expressed as the ring sum 
of two subgraphs, one belonging to the circuit subspace and the other 
belonging to the cutset subspace. In particular, the graph G itself can be 
expressed as above. 
Suppose Wc and Ws are not orthogonal complements. Then, clearly, 
there exists a subgraph that cannot be expressed as the ring sum of 
subgraphs in Wc and Ws. The question then arises whether, in this case too, 
it is possible to express G as the ring sum of subgraphs from Wc and Ws. 
The answer is in the affirmative as stated in the next theorem. 
Theorem 4.11. Every graph G can be expressed as the ring sum of two 
subgraphs one of which is in the circuit subspace and the other is in the 
cutset subspace of G. 
• 
See Chen [4.4] and Williams and Maxwell [4.5] for a proof of this 
theorem. 
We conclude this section with an example. 

92 
GRAPHS AND VECTOR SPACES 
<*> 
(6) 
Figure 4.4. (a) Graph G„. (b) Graph G„. 
Consider the graph Ga shown in Fig. 4.4a. It may be verified that no 
nonempty subgraph of this graph belongs to the intersection of the cutset 
and circuit subspaces. Hence these subspaces of Ga are orthogonal comple-
ments. Then the set of fundamental circuits and fundamental cutsets with 
respect to some spanning tree of Ga constitutes a basis for the vector space 
of Ga. One such set with respect to the spanning tree formed by the edges 
«?,, e 2, e3, and e 4 follows: 
Fundamental cutset vectors 
S, = (l 
5 2 = (0 
5 3 = (0 
5 4 = (0 
Fundamental circuit vectors 
C, = (l 
1 1 0 1 0 0) 
C 2 = (l 
1 0 0 0 1 0) 
C 3 = (0 0 
1 1 0 0 
1) 
We can now verify that every vector can be expressed as the ring sum of a 
circuit 
vector 
and 
a 
cutset 
vector. 
In 
particular, 
the 
vector 
(1 
1 1 1 1 1 1) representing Ga itself can be expressed as: 
0 0 0 
1 1 0) 
1 0 0 
1 1 0) 
0 1 0 
1 0 
1) 
0 0 
1 0 0 1) 

FURTHER READING 
93 
( 1 1 1 1 1 1 
i) = 5,e52©s4ec1ec2 
= 
( 1 1 0 1 0 0 1 ) 
Θ(0 
0 
1 0 
1 1 0 ) 
where ( 1 1 0 
1 0 
0 
1) represents a cut and (0 0 
1 0 
1 1 0) 
represents a circuit in Ga. 
Consider next the graph Gb in Fig. 4.4b. In this graph the edges ex, 
e2, 
e 3, and e 4 constitute a cut as well as a circuit. Hence the circuit and cutset 
subspaces of this graph are not orthogonal complements. This means that 
there exists some subgraphs in Gb that cannot be expressed as the ring sum 
of subgraphs from the cutset and circuit subspaces of Gb. 
However, 
according to Theorem 4.11, such a decomposition should be possible for Gb. 
This is true since 
Gb = 
{ex,e2,es}®{ei,e4,e6}, 
where {ex, e2, e5} is a cut and {e 3, e4, e6} is a circuit in Gb. 
4.7 
FURTHER READING 
An early paper on vector spaces associated with a graph is by Gould [4.6], 
where the question of constructing a graph having a specified set of circuits 
is also discussed. Chen [4.4] and Williams and Maxwell [4.5] are also 
recommended for further reading on this topic. 
We conclude with a brief introduction to the concept of principal 
partition of a graph. Though motivated by an application in electrical 
network analysis, this concept is quite profound as we shall see below. 
Consider a connected graph G = (V, E). The distance d(Tx, T2) between 
any two spanning trees Tx and T2 of G is defined as 
ά(τχ,τ2) 
= \τχ-τ2\ 
= 
\τ2-τχ\. 
In other words d(Tx, T2) is equal to the number of edges of TX(T2), 
that 
are not present in T2(TX). 
Two trees Tx and T2 are maximally distant if 
d(Tx, T2)> d(Tn 
Tf) for every pair of spanning trees T, and 
of G. Let dm 
denote the maximum distance between any two spanning trees of G. 
Given a pair of maximally distant spanning trees Tx and T2. Suppose c is 
a common chord of Tx and T2. The A:-subgraph Gc of G with respect to c is 
constructed as follows: 
1. Let L, be the set of all the edges in the fundamental circuit with 
respect to Γ, defined by c. 

94 
GRAPHS AND VECTOR SPACES 
2. Let L 2 be the union of all the fundamental circuits with respect to T2 
denned by every edge in L,. 
3. Repeating the above, we can obtain a sequence of sets of edges 
L j , L 2 , . - - until we arrive at a set Lk+X 
= Lk. 
Then the induced 
subgraph on the edge set Lk is called the fc-subgraph Gc with respect to 
c. 
Replacing circuit by cutset, in the above construction, we can define in an 
exactly dual manner the ^-subgraph Gb with respect to a common branch b. 
The principal subgraph G, with respect to common chords is the union of 
the ^-subgraphs with respect to all the common chords. The principal 
subgraph G 2 with respect to the common branches is the union of the 
fc-subgraphs with respect to all the common branches. 
Kishi and Kajitani [4.7] have shown that G, and G 2 have no common 
edges. Let E, and E2 denote the edge sets of G, and G 2, respectively, and 
let £ 0 = £ - (£,U E2). Then the partition (£ 0, £,, E2) is called the princi-
pal partition of G. This partition is unique and is independent of the 
maximally distant spanning trees used to construct the partition. 
Let Ea and Eb be a partition of the edge set £ of a graph. Let Ga be the 
subgraph on the edge set Ea and let Gb 
be the graph obtained by 
contracting all the edges in Ga. Ohtsuki, Ishizaki, and Watanabe [4.8] have 
shown that 
It can be shown that the quantity p(G a) + p-(G£) achieves the value dm 
when Ea = £, and Eb = £ 0 U £ 2. This result is the basis of an optimum 
choice of variables in an approach for electrical network analysis. See [4.8] 
and [4.9]. For this reason in electrical network theory dm is referred to as the 
topological degrees of freedom. 
Lin [4.10] discusses an algorithm for computing the principal partition of 
a graph. Bruno and Weinberg [4.11] extend the concept of principal 
partition to matroids. 
4.8 
EXERCISES 
4.1 Show that the circuits formed by the following sets of edges constitute 
a basis for the circuit subspace of the graph shown in Fig. 4.5: 
{e,, e3, e4, e6} ; 
{e2, e3, e5, e7} ; 
{eJte2,eg}. 
4.2 An incidence set at a vertex is the set of edges incident on the vertex. 
Show that any η — 1 incidence sets in an η-vertex connected graph 
form a basis of the cutset subspace of the graph. 

EXERCISES 
95 
«ι 
Figure 4.5 
4.3 
If ρ is the rank and μ is the nullity of a graph G, show that 
(a) The number of distinct bases possible for the cutset subspace of G 
is equal to 
^ (2
P - 2°)(2
P - 2')(2
P - 2
2) · · · (2
P - 2
P _ 1 ) . 
(b) The number of distinct bases possible for the circuit subspace of G 
is equal to 
(2" - 2°)(2
μ - 2')(2" - 2
2) · · • (2
μ - 2 "
- 1 ) . 
4.4 
For the graph G shown in Fig. 4.6, obtain the following: 
(a) A set of basis vectors for the circuit subspace, which are not 
fundamental circuit vectors with respect to any spanning tree of G. 
(b) A set of basis vectors for the cutset subspace, which are neither 
incidence sets nor fundamental cutsets with respect to any spanning 
tree of G. 
4.5 
(a) Test whether the cutset and circuit subspaces of the graph G of 
Fig. 4.6 are orthogonal complements of the vector space of G. 
(b) Express G as the ring sum of two subgraphs, one from the circuit 
subspace and the other from the cutset subspace. 
4.6 
Show that every subset of the edge set of a tree is a cut of the tree. 
4.7 
Show that a subgraph of a graph has an even number of edges if it 
belongs to both the cutset and the circuits subspaces of the graph. 
4.8 A subset E' of edges of a graph is said to be independent if E' contains 
no circuits. Prove the following: 
(a) Every subset of an independent set is independent. 

9β 
GRAPHS AND VECTOR SPACES 
Figure 4.6 
(b) If / and / are independent sets containing k and k + 1 edges, 
respectively, then there exists an edge e that is in J but not in I, 
such that / U (e) is an independent set. 
4.9 
Repeat Exercise 4.8 replacing "circuit" by "cutset." 
4.9 
REFERENCES 
4.1 
S. MacLane and G. Birkhoff, Algebra, Macmillan, New York, 1967. 
4.2 
P. R. Halmos, Finite-Dimensional Vector Spaces, Van Nostrand Reinhold, 
New York, 1958. 
4.3 
F. E. Hohn, Elementary Matrix Algebra, MacMillan, New York, 1958. 
4.4 
W. K. Chen, "On Vector Spaces Associated with a Graph," SIAM J. Appl. 
Math., Vol. 20, 526-529 (1971). 
4.5 
T. W. Williams and L. M. Maxwell, "The Decomposition of a Graph and the 
Introduction of a New Class of Subgraphs," SIAM J. Appl. Math., Vol. 20, 
385-389 (1971). 
4.6 
R. Gould, "Graphs and Vectors Spaces," J. Math. Phys., Vol. 37, 193-214 
(1958). 
4.7 
G. Kishi and Y. Kajitani, "Maximally Distant Trees and Principal Partition of 
a Linear Graph," IEEE Trans. Circuit Theory, Vol. CT-16, 323-330 (1969). 
4.8 
T. Ohtsuki, Y. Ishizaki, and H. Watanabe, "Topological Degrees of Freedom 
and Mixed Analysis of Electrical Networks," IEEE Trans. Circuit Theory, 
Vol. CT-17, 491-499 (1970). 
4.9 
Μ. N. S. Swamy and K. Thulasiraman, Graphs, Networks and Algorithms, 
Wiley-Interscience, New York, 1981. 
4.10 P. M. Lin, "An Improved Algorithm for Principal Partition of Graphs," Proc. 
IEEE Intl. Symp. Circuits and Systems, Munich, Germany, 145-148 (1976). 
4.11 J. Bruno and L. Weinberg, "The Principal Minors of a Matroid," Linear 
Algebra Its Appl., Vol. 4, 17-54, (1971). 

CHAPTER 5 
DIRECTED GRAPHS 
In the last four chapters we developed several basic results in the theory of 
undirected graphs. Undirected graphs are not adequate for representing 
several situations. For example, in the graph representation of a traffic 
network where an edge may represent a street, we have to assign directions 
to the edges to indicate the permissible direction of traffic flow. As another 
example, a computer program can be modeled by a graph in which an edge 
represents the flow of control from one set of instructions to another. In 
such a representation of a program, directions have to be assigned to the 
edges to indicate the directions of the flow of control. An electrical network 
is yet another example of a physical system whose representation requires a 
directed graph. 
In this chapter we develop several basic results in the theory of directed 
graphs. We discuss questions relating to the existence of directed Euler 
circuits and Hamilton trails. We also discuss directed trees and their 
relationship with directed Euler trails. 
5.1 
BASIC DEFINITIONS AND CONCEPTS 
We begin with the introduction of a few basic definitions and concepts 
relevant to directed graphs. 
A directed graph G = (V, E) consists of two sets: a finite set V of 
elements called vertices and a finite set £ of elements called edges. Each 
edge is associated with an ordered pair of vertices. 
We use the symbols vx,v2,... 
to represent the vertices and the symbols 
ex, e2,... 
to represent the edges of a directed graph. If e, = (v„ vf), then υ, 
97 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

98 
DIRECTED GRAPHS 
and Vj are called the end vertices of the edge e,, v, being called the initial 
vertex and y; the terminal vertex of e,. All edges having the same pair of 
initial and terminal vertices are called parallel edges. An edge is called a 
self-loop at vertex υ,, if v, is the initial as well as the terminal vertex of the 
edge. 
In the pictorial representation of a directed graph, a vertex is represented 
by a dot or a circle and an edge is represented by a line segment connecting 
the dots or the circles that represent the end vertices of the edge. In 
addition, each edge is assigned an orientation indicated by an arrow that is 
drawn from the initial to the terminal vertex. 
For example, if 
V= 
{Όι,υ2,υ3,υ4,υ5,υ6,υΊ} 
and 
Ε — {β,, e2, e3, eA, e5, e6, e 7, eR} 
such that 
ei = 
( v
x , v
2 ) , 
e 2 = 
(Vi,v2), 
« 3 = 
( " 1 . 0 3 ) » 
^ = ( ^ 3 . ^ 1 ) . 
«5 = ("2. " 4 ) . 
^ 
= 
( « 3 . ^ 4 ) , 
e7 
= (v4, 
v4) 
, 
*e = (*>5. 
v6), 
then the directed graph G = (V, E) will be represented as in Fig. 5.1. In this 
graph e, and e2 are parallel edges, and e 7 is a self-loop. 
An edge is said to be incident on its end vertices. Two vertices are 
adjacent if they are the end vertices of some edge. If two edges have a 
common end vertex, then these edges are said to be adjacent. 
An edge is said to be incident out of its initial vertex and incident into its 
terminal vertex. A vertex is called an isolated vertex if no edge is incident on 
it. 
The degree d(Vj) of a vertex Vj is the number of edges incident on vr The 
in-degree d~{vt) 
of Vj is the number of edges incident into 
and the 
out-degree ά
+(υ;) 
is the number of edges incident out of vr And δ
 + and δ ~ 
will denote the minimum out-degree and the minimum in-degree in a 

BASIC DEFINITIONS AND CONCEPTS 
99 
Figure 5.1. A directed graph. 
directed graph. Similarly Δ
+ and Δ" will denote the maximum out-degree 
and the maximum in-degree, respectively. 
For any vertex υ the sets Γ
+(ι>) and Γ~(υ) are defined as follows: 
r
+(v) 
= 
{w\(v,w)(EE}, 
Γ » = {νν|(Η>, 
v)EE). 
For example, in the graph of Fig. 5.1 Γ
+(υ,) = {υ2, i>3} and Γ~(υ 4) = 
{v2, v3, 
v4}. 
Note that a self-loop at a vertex contributes to the in-degree as well as to 
the out-degree of the vertex. The following result is a consequence of the 
fact that every edge contributes 1 to the sum of the in-degrees as well as to 
the sum of the out-degrees of a directed graph. 
Theorem 5.1. In a directed graph, sum of the in-degrees = sum of the 
out-degrees = m, where m is the number of edges of the graph. 
• 
Subgraphs and induced subgraphs of a directed graph are defined as in 
the case of undirected graphs (Section 1.2). 
The graph that results after ignoring the orientations of a directed graph 
G is called the underlying undirected graph of G. This undirected graph will 
be denoted by Gu. 
A directed walk in a directed graph G = (V, E) is a finite sequence of 
vertices v0, i>,,..., vk, such that (u,_,, υ,), 1 s i < k, is an edge in G. This 
directed walk is usually called a v0-vk 
directed walk. v0 is called the initial 
vertex, vk is called the terminal vertex of this walk, and all other vertices are 
called internal vertices. The initial and terminal vertices of a directed walk 
are called its end vertices. Note that in a directed walk, edges and hence 
vertices can appear more than once. 
A directed walk is open if its end vertices are distinct; otherwise it is 
closed. 

100 
DIRECTED GRAPHS 
A directed walk is a directed trail if all its edges are distinct. A directed 
trail is open if its end vertices are distinct; otherwise it is closed. 
An open directed trail is a directed path if all its vertices are distinct. 
A closed directed trail is a directed circuit if all its vertices except the end 
vertices are distinct. 
A directed graph is said to be acyclic if it has no directed circuits. For 
example, the directed graph in Fig. 5.2 is acyclic. 
A sequence of vertices in a directed graph G is a walk in G if it is a walk 
in the underlying undirected graph Gu. For example, the sequence υ,, υ2, 
υ3, υ4, υ2, ν3 in the graph of Fig. 5.2 is a walk; but it is not a directed walk. 
Trail path and circuit in a directed graph are defined in a similar manner. 
A directed graph is connected if the underlying undirected graph is 
connected. 
A subgraph of a directed graph G is a component of G if it is a 
component of G„. 
In a directed graph G a vertex v, is strongly connected to a vertex vt if in 
G there exists a directed path from v, to v, and a directed path from v to v,. 
If v, is strongly connected to vr then, obviously, vJ is strongly connected to 
υ,. Every vertex is strongly connected to itself. 
If v, is strongly connected to vr and vt is strongly connected to vk, then it 
is easy to see that v, is strongly connected to vk. Therefore, in such a case, 
we simply state that the vertices υ,, vr and vk are strongly connected. 
A directed graph is strongly connected if all its vertices are strongly 
connected. For example, the graph in Fig. 5.3 is strongly connected. 
A maximal strongly connected subgraph of a directed graph G is called a 
strongly connected component of G. If a directed graph is strongly con-
nected, then it has only one strongly connected component, namely, itself. 
Consider a directed graph G = (V, E). It is easy to see that each vertex of 
G is present in exactly one strongly connected component of G. Thus the 
vertex sets of the strongly connected components constitute a partition of 
the vertex set V of G. 
Figure 5.2. An acyclic directed graph. 
Figure 5.3. A strongly connected directed 
graph. 

BASIC DEFINITIONS AND CONCEPTS 
101 
For example, the directed graph of Fig. 5.4a has three strongly connected 
components with {v2, v3, u 4, v5}, {vt}, and {v6} as their vertex sets, which 
form a partition of the vertex set {«,, v2, v3, v4, v5, v6} of the directed 
graph. 
It is interesting to note that there may be some edges in a directed graph 
that do not belong to any strongly connected component of the graph. For 
example, in the graph of Fig. 5.4a, the edges e,, e6, e7, eg, and exo are not 
present in any strongly connected component. 
Thus while the "strongly connected" property induces a partition of the 
vertex set of a graph, it may not induce a partition of the edge set. 
Union, intersection, ring sum, and other operations involving directed 
graphs are defined in exactly the same way as in the case of undirected 
graphs (see Section 1.5). 
The graph that results after contracting all the edges in each strongly 
connected component of a directed graph G is called the condensed graph 
Gc of G. For example, the condensed graph of the graph of Fig. 5.4a is 
shown in Fig. 5.4b. 
The vertex in Gc, which corresponds to a strongly connected component, 
is called the condensed image of the component. 
ib) 
Figure 5.4. A graph and its condensed graph. 

102 
DIRECTED GRAPHS 
The rank and nullity of a directed graph are the same as those of the 
corresponding undirected graph. Thus if a directed graph G has m edges, η 
vertices, and ρ components, then the rank ρ and the nullity μ of G are given 
by 
ρ = 
η-ρ 
and 
μ = m — η + ρ . 
Next we define a minimally connected directed graph and study some 
properties of such graphs. 
A directed graph G is minimally connected if G is strongly connected, and 
the removal of any edge from G destroys its "strongly connected" property. 
For example, the graph of Fig. 5.5 is minimally connected. 
Obviously, a minimally connected directed graph can have neither paral-
lel edges nor self-loops. 
We know that an undirected graph is minimally connected if and only if it 
is a tree (Exercise 2.13). By Theorem 2.5, a tree has at least two vertices of 
degree 1. Thus in a minimally connected undirected graph there are at least 
two vertices of degree 1. 
We now establish an analogous result for the case of directed graphs. In a 
strongly connected directed graph the degree of every vertex should be at 
least 2, since at each vertex there should be one edge incident out of the 
vertex and one edge incident into the vertex. In the following theorem we 
prove that a minimally connected directed graph has at least two vertices of 
degree 2. 
Theorem 5.2. If a minimally connected directed graph G has more than one 
vertex, then G has at least two vertices of degree 2. 
Proof. Since G is strongly connected and has more than one vertex, it must 
have at least one directed circuit. Thus for G, the nullity μ > 1. 
We shall prove the theorem by induction on μ. 
Figure 5.5. A minimally connected di-
rected graph. 

BASIC DEFINITIONS AND CONCEPTS 
103 
If μ = 1, then G must be a directed circuit, and hence the theorem is true 
for this case. 
Let the theorem be true for all minimally connected directed graphs for 
which the nullity μ < k, with k > 2. Now consider a minimally connected 
graph G with μ = k. We shall show that the theorem is true for G. 
Two cases now arise. 
Case 1 
Every directed circuit in G is of length 2. 
In this case any two adjacent vertices of G are joined by exactly two edges 
oriented in different directions. Let G' be a simple undirected graph that 
has the same vertex set as G and in which two vertices are adjacent if and 
only if they are adjacent in G. Since G is connected, G' is also connected. 
Further, G' has no circuits because G has no directed circuit of length 
greater than 2. Thus G' is a tree. Hence, by Theorem 2.5, it has at least two 
pendant vertices. These two vertices have degree 2 in G, and the theorem is 
therefore true for this case. 
Case 2 
G has a directed circuit C of length / > 3. 
Since G is minimally connected, there is only one edge in G between any 
two adjacent vertices of C, and further, there is no edge in G between any 
two vertices that are not adjacent in C. 
Suppose G' is the graph that results after contracting the edges of C. 
Then G' has m -I 
edges and η -I +1 vertices, where m and η are, 
respectively, the number of edges and the number of vertices in G. 
Therefore the nullity of G' is equal to 
(m - / ) - ( « - / + 1 ) + 1 = k- 
1. 
Since G' is also minimally connected, it follows from the induction hypoth-
esis that G' has at least two vertices vx and v2 of degree 2. If one of these 
vertices, say vx, is the condensed image of C, then C has at least one vertex, 
say v3, which is of degree 2. In such a case v2 and v3 are two vertices of 
degree 2 in G. 
On the other hand, if neither vx nor v2 is the condensed image of C, then 
vx and v2 are two vertices of degree 2 in G. 
Hence the theorem. 
• 
We conclude this section with the definition of the "quasi-strongly 
connected" property. 
A graph is said to be quasi-strongly connected if for every pair of vertices 
vx and v2 there is a vertex v3 from which there is a directed path to vx and a 
directed path to v2. Note that v3 need not be distinct from i>, or v2. 
For example, the graph of Fig. 5.6 is quasi-strongly connected. 

104 
DIRECTED GRAPHS 
"β 
Figure 5.6. A quasi-strongly connected graph. 
5.2 
GRAPHS AND RELATIONS 
A binary relation on a set X = {*,, x2,...} 
is a collection of ordered pairs of 
elements of X. For example, if the set X is composed of men and R is the 
relation "is son of," then the ordered pair (*,, xt) means that x, is the son of 
Xj. This is also denoted as x, R xf. 
A most convenient way of representing a binary relation Λ on a set X is 
by a directed graph, the vertices of which stand for the elements of X and 
the edges stand for the ordered pairs of elements of X defining the relation 
R. 
For example, the relation "is a factor o f on the set X= {2, 3, 4, 6, 9} is 
shown in Fig. 5.7. 
Consider a set X = {*,, x2,...} 
and a relation R on X. 
1. Λ is reflexive if every element x, is in relation R to itself; that is, for 
every 
x, R xr 
2. R is symmetric if 
R xt implies xs R x,. 
3. R is transitive if x, R Xj and x) R xk imply xt R xk. 
4. R is an equivalence relation if it is reflexive, symmetric, and transitive. 
If R is an equivalence relation denned on a set 5, then we can uniquely 
partition S into subsets 5,, S2,...,Sk 
such that two elements χ and y 
of S belong to 5, if and only if χ R y. The subsets 5,, S2,..., 
Sk are all 
called the equivalence classes induced by the relation R on the set S. 
Suppose the set X is composed of positive integers. Then: 
1. The relation "is a factor o f is reflexive and transitive. 

DIRECTED TREES OR ARBORESCENCES 
105 
Figure 5.7. A directed graph representing the relation "is a factor of." 
2. The relation "is equal to" is reflexive, symmetric, and transitive and is 
therefore an equivalence relation. 
The directed graph representing a reflexive relation is called a reflexive 
directed graph. In a similar way symmetric and transitive directed graphs are 
defined. We can now make the following observations about these graphs: 
1. In a reflexive directed graph, there is a self-loop at each vertex. 
2. In a symmetric directed graph, there are two oppositely oriented edges 
between any two adjacent vertices. Therefore an undirected graph can 
be considered as representing a symmetric relation if we associate with 
each edge two oppositely oriented edges. 
3. The edge (vl,v2) 
is present in a transitive graph G if there is a 
directed path in G from u, to v2. 
5.3 
DIRECTED TREES OR ARBORESCENCES 
A vertex υ in a directed graph G is a root of G if there are directed paths 
from ν to all the remaining vertices of G. 
For example, in the graph G of Fig. 5.6, the vertex i>, is a root. It is clear 
that if a graph has a root, it is quasi-strongly connected. In the following 
theorem we prove that the quasi-strongly connected property implies the 
existence of a root. 
Theorem 5.3. A directed graph G has a root if and only if it is quasi-strongly 
connected. 

106 
DIRECTED GRAPHS 
Proof 
Necessity 
Obvious. 
Sufficiency 
Consider the vertices xx, x2,...,xn 
of G. Since G is quasi-
strongly connected, there exists a vertex y 2 from which there is a directed 
path to xx and a directed path to x2. For the same reason there is a vertex y3 
from which there is a directed path to y2 and a directed path to x3. Clearly, 
y3 is also connected to xx and x2 by directed paths through y2. Proceeding in 
this manner, we see that there is a vertex yn from which there is a directed 
path to yn_x 
and xn. Obviously yn is a root since it is also connected to 
xx,... 
,x„_x through y n_,. 
• 
A directed graph G is a tree if the underlying undirected graph is a tree. 
A directed graph G is a directed tree or arborescence if G is a tree and has 
a root. A vertex ν in G is called a leaf if d
+(i>) = 0. 
For example, the graph of Fig. 5.8 is a directed tree. In this graph the 
vertex υ, is a root and it is the only root. 
We present in the next theorem a number of equivalent characterizations 
of a directed tree. 
Theorem 5.4. Let G be a directed graph with η > 1 vertices. Then the 
following statements are equivalent: 
1. G is a directed tree. 
2. There exists a vertex r in G such that there is exactly one directed path 
from r to every other vertex of G. 
3. G is quasi-strongly connected and loses this property if any edge is 
removed from it. 
4. G is quasi-strongly connected and has a vertex r such that 
<T(r) = 0 
»7
 
P S 
» 4 
Figure 5.8. A directed tree. 

DIRECTED TREES OR ARBORESCENCES 
107 
and 
ίΓ(υ) = 1, 
υΦτ. 
5. G has no circuits (not necessarily directed circuits) and has a vertex r 
such that 
rf» 
= 0 
and 
d~(p) = \ , 
υΦτ. 
6. G is quasi-strongly connected without circuits. 
Proof 
1Φ2 
The root r in G has the desired property. 
2φ3 
Obviously G is quasi-strongly connected. Suppose this property is 
not destroyed when an edge (u, v) is removed from G. Then there is a 
vertex ζ such that there are two directed paths from z, one to u and the 
other to v, which do not use the edge (u, v). Thus in G, there are two 
directed paths from ζ to υ and hence two directed paths from r to v. This 
contradicts statement 2. 
3φ> 4 
Since G is quasi-strongly connected, it has a root r. So, for every 
vertex υ Φ r, 
d~[v)>\ 
. 
Suppose, for some vertex v, that 
d~(v)>l. 
Then there are two edges, say (*, v) and (y, v), incident into v. Thus there 
are two distinct paths from r to v, one through (x, v) and the other through 
(y, v). So even if we remove one of these two edges, the resulting graph still 
has r as a root and hence remains quasi-strongly connected. This contradicts 
statement 3 and so, 
d~(v) = l, 
υΦτ. 
Finally, no edge can be incident into r, for otherwise the graph that 
results after removing this edge from G will still have r as its root and hence 
will be quasi-strongly connected. This will again contradict statement 3. 
Therefore 
d'(r) = 0. 

108 
DIRECTED GRAPHS 
4φ5 
The sum of in-degrees in G is equal to n — l. Therefore by 
Theorem 5.1, G has η - 1 edges. Since G is also connected, by Theorem 
2.1, statement 3, it is a tree and hence is circuitless. 
5=£> 6 
G has η - 1 edges because the sum of in-degrees in G is equal to 
n — l. Since it is also circuitless, it follows from Theorem 2.2 that it is a tree. 
Therefore, there exists a unique path in G from vertex r to every other 
vertex. Such a path should be a directed path, for otherwise at least one of 
the vertices in this path will have its in-degree greater than 1, contradicting 
statement 5. Thus vertex r is a root of G. Therefore, by Theorem 5.3, G is 
quasi-strongly connected. 
6^>1 
Since G is quasi-strongly connected, it has a root, by Theorem 
5.3. Further, it is a tree because it is connected and has no circuits. 
• 
A subgraph of a directed graph G is a directed spanning tree of G if the 
subgraph is a directed tree and contains all the vertices of G. For example, 
the subgraph consisting of the edges ex, e2, e}, e 4, and es is a directed 
spanning tree of the graph of Fig. 5.6. 
We know that a graph G has a spanning tree if and only if G is 
connected. The corresponding theorem in the case of directed graphs 
follows. 
Theorem 5.5. A directed graph G has a directed spanning tree if and only if 
G is quasi-strongly connected. 
Proof 
Necessity 
If G has a directed spanning tree, then obviously the root of 
the directed tree is also a root of G. Therefore, by Theorem 5.3, G is 
quasi-strongly connected. 
Sufficiency 
Suppose G is quasi-strongly connected and it is not a 
directed tree. Then, by Theorem 5.4, statement 3, there are edges whose 
removal from G will not destroy the quasi-strongly connected property of G. 
Therefore, if we remove successively all these edges from G, then the 
resulting graph is a directed spanning tree of G. 
• 
A binary tree is a directed tree in which the out-degree of every vertex is 
at most 2. For example, the graph of Fig. 5.9 is a binary tree. In the study of 
certain aspects of computer science, for example, analysis of algorithms, 
search techniques, and so on, binary trees are found to be very useful. One 
problem in this context is the following: 
Given η weights wx, w2,..., 
wn and η lengths 
/ 2 , . . . , /„, construct a 
binary tree with η leaves vx, v2,...,v„ 
such that: 
1. wt, 1 s j < η, is the weight of vertex υ,. 

DIRECTED TREES OR ARBORESCENCES 
109 
000 
001 010 
011 
110 
111 
Figure 5.9. A binary tree. 
2. / (, 1 < ϊ < «, is the length of the path from the root to υ,. 
3. Σ" = 1 w,l,, called the weighted path length, is minimum. 
A situation where a more general problem arises is now described. 
The set of words such that no word is the beginning of another is called a 
prefix code. Clearly, if a sequence of letters is formed by concatenating the 
words of a prefix code, the sequence can be decomposed into individual 
words of the prefix code by reading the sequence from left to right. For 
example {000, 001, 01, 10, 11} is a prefix code and the sequence 1011001000 
formed by concatenating the words of this code is easily decomposed into 
the words 10, 11, 001, and 000. 
Suppose S = {0, 1, 2 , . . . , m - 1} is an alphabet of m letters. Let Γ be a 
directed tree such that: 
1. The out-degree of each vertex is at most m. 
2. Each out-going edge at a vertex is associated with a letter of the 
alphabet 5 such that no two such edges are associated with the same 
letter. 
Then each leaf ν can be associated with a word that is formed by concatenat-
ing all the letters in the order in which they appear on the edges along the 
path from the root to v. If may be verified that the words so associated with 
the leaves form a prefix code. For example, the prefix code corresponding to 
the directed tree of Fig. 5.9 is the following: 
{000,001,010,011,10, 110,111} . 
Now the problem is: Given m and the lengths /,, l2,... ,/„, construct a 
prefix code using the letters of the alphabet 5 = {0, 1, 2 , . . . ,m - 1} with /,, 
/ 2 , . . . , /„ as the lengths of the code words. 
A discussion of this and certain related problems may be found in Swamy 
and Thulasiraman [5.1]. 

110 
DIRECTED GRAPHS 
5.4 
DIRECTED EULERIAN GRAPHS 
A directed Euler trail in a directed graph G is a closed directed trail that 
contains all the edges of G. An open directed Euler trail is an open directed 
trail containing all the edges of G. A directed graph possessing a directed 
Euler trail is called a directed Eulerian graph. 
The graph G of Fig. 5.10 is a directed Eulerian graph since the sequence 
of edges ex, e2, e 3, e4, e5, e6 constitutes a directed Euler trail in G. 
The following theorem gives simple and useful characterizations of 
directed Eulerian graphs. The proof of this theorem follows along the same 
lines as that for Theorem 3.1. 
Theorem 5.6. The following statements are equivalent for a connected 
directed graph G: 
1. G is a directed Eulerian graph. 
2. For every vertex υ of G, d~(v) = d
+(v). 
3. G is the union of some edge-disjoint directed circuits. 
• 
Consider, for example, the directed Eulerian graph G of Fig. 5.10. It is 
easy to verify that it satisfies property 2 of Theorem 5.6. Further it is the 
union of the edge-disjoint circuits {e2, e 3} and {ex, e 4, es, e6}. 
Another theorem that can be easily proved is the following one. 
Theorem 5.7. A directed connected graph possesses an open directed Euler 
trail if and only if the following conditions are satisfied: 
1. In G there are two vertices vx and v2 such that 
and 
d~(v
2
) = d
+(v
2
) 
+ l. 
e 3 
Figure 5.10. A directed Eulerian graph. 
Figure 5.11. A graph with an open di-
rected Euler trail. 

DIRECTED EULERIAN GRAPHS 
111 
2. For every vertex v, different from vx and v2, 
d » 
= d » . 
• 
For example, the graph G of Fig. 5.11 satisfies the conditions of Theorem 
5.7. The sequence of edges ex, e2, e3, e4, e5, e6 is an open directed Euler 
trail in G. 
An interesting application of Theorem 5.6 is discussed next. 
Let S = { 0 , 1 , . . . , s - 1} be an alphabet of s letters. Obviously we can 
construct s" different words of length η using the letters of the alphabet S. A 
de Bruijn sequence is a circular sequence a0, a,, a2,...,aL_x 
of length 
L = s" such that for every word ω of length n, there is a unique ι such that 
i i 
+ 1 
**/ +n - 1 ' 
where the computation of the indices is modulo L. de Bruijn sequences find 
application in the study of coding theory and communication circuits. 
Reference [5.2] may be consulted for more information on these sequences. 
We now wish to consider the following problem: 
For every s a 2 and every integer n, does there exist a de Bruijn sequence 
over the alphabet S = {0, 1, 2 , . . . , s - 1}? The answer is in the affirmative, 
as we shall see now. 
We show that for every s a 2 and every η there exists a directed Eulerian 
graph Gs „ such that each directed Euler trail in this graph corresponds to a 
de Bruijn sequence of length s" over the alphabet S = { 0 , 1 , 2 , . . . , s - 1}. 
The graph Gsn = (V, E) is constructed as follows: 
1. V consists of all the s"'
1 
words of length η -1 over the alphabet S. 
2. £ is the set of all the s" words of length η over S. 
3. The edge blb2--bn 
has blb2- 
· · bn_x 
as its initial vertex and 
^ 2 ^ 3 · · · ft„ as its terminal vertex. Note that at each vertex there are s 
incoming edges and s outgoing edges. Thus for each vertex v, d~(v) = 
d » . 
For example, the graphs G 2 4 and G2 
3 are as shown in Fig. 5.12a and 5.12ft. 
Suppose there exists a directed Euler trail C in Gsn. 
If we concatenate the 
first letters of the words, represented by the edges of Gsn, 
in the order in 
which they appear in C, Then we get a sequence of length s" such that every 
subsequence of η consecutive letters in this sequence will correspond to a 
unique word and no two different subsequences will correspond to the same 
word. Thus the sequence constructed will be a de Bruijn sequence. For 
example, the sequence of edges 000, 001, 011, 111, 110, 101, 010, 100 is a 
directed Euler trail in G2 
3. Concatenating the first letters of these words we 
get the de Bruijn sequence 00011101. 

0000 
1111 
(a) 
000 
111 
(b) 
Figure 5.12. (e) Graph G2A. (b) Graph G2 3. 
112 

DIRECTED SPANNING TREES AND DIRECTED EULER TRAILS 
113 
Thus to show that there exists a de Bruijn sequence for every $ s 2 and 
every n, we have to prove that Gs „ is a directed Eulerian graph. This we do 
in the following theorem. 
Theorem 5.8. Gsn is a directed Eulerian graph. 
Proof. Gs „ is connected since for any two vertices i>, = bxb2 · · · fr„_, and 
υ 2 ~
 
C i
c z " '
 
c n - i > there is a directed path from i>, to v 2 consisting of the 
following edges: 
b i
b 2 • · ·
 b „ - i
c i > b2b3 • • • b
n _
x c
x c
2 , 6
n _ , c , c
2 · · · c„_, . 
Since, as we have seen before, the in-degree of every vertex in Gs „ is equal 
to its out-degree, it follows from Theorem 5.6 that Gs n is a directed 
Eulerian graph. 
• 
Corollary 5.8.1. For every i > 2 and every η there exists a de Bruijn 
sequence. 
• 
5.5 
DIRECTED SPANNING TREES AND DIRECTED EULER TRAILS 
Let G be a directed Eulerian graph without self-loops. In this section we 
relate the number of directed Euler trails in G to the number of directed 
spanning trees of G. 
Let vt,v2,... 
,v„ denote the vertices of G. Consider a directed Euler 
trail C in G. Let eH be any edge of G incident into u,. For every 
ρ = 2, 3 , . . . , η, let e ; denote the first edge on C to enter vertex υ after 
traversing ev . For example, in the directed Eulerian graph shown in Fig. 
5.10, the sequence of edges e,, e2, e3, e 4, e5, e6 is a directed Euler trail. If 
we choose e ; ) = e5, then eJ2 = ex, e ; j = e6, and eu = e 4. 
Let Η denote the subgraph of G on the edge set [eJ2, e^,..., 
e^. 
Lemma 5.1. Let C be a directed Euler trail of a directed Eulerian graph G. 
The subgraph H, as defined earlier, is a directed spanning tree of G with 
root υ j . 
Proof. Clearly in H, d~(vl) = 0, and d'{vp) 
= \ for all ρ = 
2,3,...,η. 
Suppose Η has a circuit C. Then v1 is not in C , for otherwise either 
d 
(
u i )
 > 0 or </~(ι>)> 1 for some other vertex υ on C . For the same reason 
C is a directed circuit. Since d~(v) = 1 for every vertex ν on C , no edge not 
in C enters any vertex in C. This means that the edge e, which is the first 
edge of C to enter a vertex of C after traversing 
, does not belong to H, 
contradicting the definition of H. Thus Η has no circuits. 
Now it follows from Theorem 5.4, statement 5, that Η is a directed 
spanning tree of G. 
• 

114 
DIRECTED GRAPHS 
Given a directed spanning tree Η of an η-vertex directed Eulerian graph 
G without self-loops, let υ, be the root of Η and eh an edge incident into u, 
in G. Let ey for ρ = 2, 3 , . . . , η be the edge entering vp in H. We now 
describe a method for constructing a directed Euler trail in G. 
1. Start from vertex υ, and traverse backward on any edge entering υ, 
other than eh if such an edge exists, or on eh if there is no other 
alternative. 
2. In general on arrival at a vertex vp, leave it by traversing backward on 
an edge entering vp that has not yet been traversed and, if possible, 
other than e^. Stop if no untraversed edges entering vp exist. 
In this procedure every time we reach vertex vp¥=Vi, 
there will be an 
untraversed edge entering vp because the in-degree of every vertex in G is 
equal to its out-degree. Thus this procedure terminates only at the vertex υ λ 
after traversing all the edges incident into i>,. 
Suppose there exists in G an untraversed edge («, υ) when the procedure 
terminates at υ,. Since the in-degree of u is equal to its out-degree, there 
exists at least one untraversed edge incident into u. If there is more than one 
such untraversed edge, then one of these will be the edge y entering u in H. 
This follows from step 2 of the procedure. This untraversed edge y will lead 
to another untraversed edge that is also in H. Finally we shall arrive at vt 
and shall find an untraversed edge incident into υ,. This is not possible since 
all the edges incident into u, will have been traversed when the procedure 
terminates at i>,. 
Thus all the edges of G will be traversed during the procedure we 
described above, and indeed a directed Euler trail is constructed. 
Since at each vertex vp there are (d~(vp) - 1)! different orders for picking 
the incoming edges (with et at the end), it follows that the number of 
distinct directed Euler trails
Pthat we can construct from a given directed 
spanning tree Η and eh is 
Π (£/>,)-!)!. 
p = l 
Further, each different choice of Η will yield a different e for some 
p = 2 , 3 , . . . , « , which will in turn result in a different entry to vp after 
traversing et in the resulting directed Euler trail. 
Finally, since the procedure of constructing a directed Euler trail is the 
reversal of the procedure for constructing a directed spanning tree, it follows 
that every directed Euler trail can be constructed from some directed 
spanning tree. 
Thus we have proved the following theorem due to Van Aardenne-
Ehrenfest and de Bruijn [5.3]. 

DIRECTED HAMILTONIAN GRAPHS 
115 
Theorem 5.9. The number of directed Euler trails of a directed Eulerian 
graph G without self-loops is 
rd(G) Π (</>„)-1)! 
p = l 
where rd(G) 
is the number of directed spanning trees of G with vt as 
root. 
• 
Since the number of directed Euler trails is independent of the choice of 
the root, we get the following. 
Corollary 5.9.1. The number of directed spanning trees of a directed 
Eulerian graph is the same for every choice of root. 
• 
We establish in Section 6.9 a formula for evaluating 
Td(G). 
5.6 
DIRECTED HAMILTONIAN GRAPHS 
A directed circuit in a directed graph G is a directed Hamilton circuit of G if 
it contains all the vertices of G. 
A directed path in G is a directed Hamilton path of G if it contains all the 
vertices of G. 
A graph is a directed Hamiltonian graph if it has a directed Hamilton 
circuit. 
For example, the sequence of edges ex, e2, e3, e4, e5, e6 is a directed 
Hamilton circuit in the graph of Fig. 5.13a. In Fig. 5.136, the sequence of 
edges e,, e2, e3, e4, e5 is a directed Hamilton path. Note that this latter 
graph has no directed Hamilton circuit. 
Characterizing a directed Hamiltonian graph is as difficult as characteriz-
ing an undirected Hamiltonian graph. However, there are several sufficient 
conditions that guarantee the existence of directed Hamilton circuits and 
paths. We now discuss a few of these conditions. 
A directed graph G is complete if its underlying undirected graph is 
complete. 
The following theorem is due to Moon [5.4]. 
Theorem 5.10. Let u be any vertex of a strongly connected complete 
directed graph with « s 3 vertices. For each k, 3 s f c < « , there is a directed 
circuit of length k containing u. 
Proof. Let G - (V, E) be a strongly connected complete directed graph 
with n > 3 vertices. Consider any vertex u of G. Let 5 = T
+(u) and 
T = F~(u). Since G is strongly connected, neither S nor Γ is empty. For the 

116 
DIRECTED GRAPHS 
Figure 5.13. (a) A directed Hamiltonian 
graph, (b) A directed graph with a 
Hamilton path but with no Hamilton 
circuits. 
e i 
V 
'if 
'7 
ei ' · 
\f3 
(6) 
same reason there is a directed edge from a vertex v E S to a vertex wET. 
Thus « is in a directed circuit of length 3 (see Fig. 5.14). 
We prove the theorem by induction on k. Assume that u is in directed 
circuits of all lengths between 3 and p, where p<n. We now show that u is 
in a directed circuit of length p + 1. 
Let C: u = v0, u,, v2,..., vp = u be a directed circuit of length p. Two 
cases need to be considered. 
Suppose for some vertex v not in C there exist two directed edges (x, v) 
and (u, y) with x and y on C. Then there exist two adjacent vertices v, and 
Figure 5.14 

DIRECTED HAMILTONIAN GRAPHS 
117 
Figure 5.15 
on C such that the directed edges (v„ v) and (v, vl+i) 
are in G. Thus in 
this case u is in the directed circuit u = v0, i>,, v2,..., 
υ,, v, 
..., υ = u 
of length ρ + 1. 
Otherwise, let S be the set of all those vertices not in C, which are the 
terminal vertices of edges directed away from the vertices of C, and let Τ be 
the set of all those vertices not in C, which are the initial vertices of edges 
directed toward vertices in C. Again, since G is strongly connected, neither 
S nor Τ is empty. Further, there exists an edge directed from a vertex υ £ S 
to a vertex wET. 
Thus u is in the directed circuit u = υ0, υ, w, v2,..., 
vp = 
u of length ρ + 1 (see Fig. 5.15). 
• 
Corollary 
5.10.1. A 
strongly connected 
complete 
directed 
graph 
is 
Hamiltonian. 
• 
Next we state without proof a very powerful theorem due to Ghouila-
Houri. The proof of this theorem may be found in [5.5] (pp. 196-199). 
Theorem 5.11. Let G be a strongly connected η-vertex graph without 
parallel edges and self-loops. If for every vertex ν in G 
then G has a directed Hamilton circuit. 
• 
The following result generalizes Dirac's result (Corollary 3.4.1) for 
undirected graphs, and it can be proved using Theorem 5.11 and Exercise 
5.6. 
Corollary 5.11.1. Let G be a directed η-vertex graph without parallel edges 
or self-loops. If min(S~, δ
 + ) ^ 5 Π > 1 , then G contains a directed Hamilton 
circuit. 
• 

118 
DIRECTED GRAPHS 
We conclude this section with a result on the existence of a directed 
Hamilton path. 
Theorem 5.12. If a directed graph G = (V, E) is complete, then it has a 
directed Hamilton path. 
Proof. Consider a directed path P: ax, a2,..., 
ap of maximum length in G. 
Suppose b is a vertex not lying on P. Then the edge (b,at)0E, 
for 
otherwise the path b, a,, a2,...ap 
will be longer than P. Therefore, 
(aub)EE. 
Now (b,a2)0E, 
for otherwise a,, b, a2,a3,... 
,ap will be a path longer 
than P. Thus (a2, 
b)E.E. 
Repeating this argument we find that (ap, b) G E. But this is a contradic-
tion, for αλ,α2,.... 
,ap, b will be a path longer than P. Thus there is no 
vertex outside P, and hence Ρ is a directed Hamilton path in G. 
• 
For more general conditions for the existence of Hamilton circuits and 
paths, see Exercises 5.14 to 5.16. 
5.7 
ACYCLIC DIRECTED GRAPHS 
In this section we study some properties of an important class of directed 
graphs, namely, the acyclic directed graphs. As we know, a directed graph is 
acyclic if it has no directed circuits. Obviously the simplest example of an 
acyclic directed graph is a directed tree. 
The main result of this section is that we can label the vertices of an 
η-vertex acyclic directed graph G with integers from the set { 1 , 2 , . . . , n) 
such that the presence of the edge (/, j) in G implies that i* < j . Note that the 
edge (t, /) is directed from vertex / to vertex j . Ordering the vertices in this 
manner is called topological sorting. For example, the vertices of the acyclic 
directed graph of Fig. 5.16 are topologically sorted. The proof of the main 
result of this section depends on the following theorem. 
Theorem 5.13. In an acyclic directed graph G there exists at least one vertex 
with zero in-degree and at least one vertex with zero out-degree. 
Proof. Let P: vx, v2,..., 
vp be a maximal directed path in G. We claim that 
the in-degree of rj, and the out-degree of vp are both equal to zero. 
If the in-degree of υ, is not equal to zero, then there exists a vertex w 
such that the edge (w, υ,) is in G. We now examine two cases. 
Case 1 
Suppose w Φ υ,, for any i, 1 < / < p . Then there is a directed path 
P': w, D, , D 2, . . . , vp that contains all the edges of P. This contradicts that 
Ρ is a maximal directed path. 

TOURNAMENTS 
119 
2 
1 
Figure 5.16. An acyclic directed graph. 
Case 2 
Suppose w = v, for some i. Then in G there is a directed circuit C: 
vx, v2,..., 
y,, o,. This is again a contradiction since G has no directed 
circuits. 
Thus there is no vertex w such that the edge (w, 
is in G. In other words 
the in-degree of υ, is zero. 
Following a similar reasoning we can show that the out-degree of vp is 
zero. 
• 
To topologically sort the vertices of an η-vertex acyclic directed graph G, 
we proceed as follows. 
Select any vertex with zero out-degree. Since G is acyclic, by Theorem 
5.13, there is at least one such vertex in G. Label this vertex with the integer 
n. Now remove from G this vertex and the edges incident on it. Let G' be 
the resulting graph. Since G' is also acyclic, we can now select a vertex 
whose out-degree in G' is zero. Label this with the integer η - 1. Repeat 
this procedure until all the vertices are labeled. It is now easy to verify that 
this procedure results in a topological sorting of the vertices of G. 
For example, the labeling of the vertices of the graph of Fig. 5.16 has 
been done according to this procedure. 
5.8 
TOURNAMENTS 
A tournament is a complete directed graph. It derives its name from its 
application in the representation of structures of round-robin tournaments. 
In a round-robin tournament several teams play a game that cannot end in a 
tie, and each team plays every other team exactly once. In the directed 
graph representation of the round-robin tournament, vertices represent 
teams and an edge 
u 2) is present in the graph if the team represented by 
the vertex vt defeats the team represented by the vertex v2. Clearly, such a 

120 
DIRECTED GRAPHS 
Figure 5.17. A tournament. 
directed graph has no parallel edges and self-loops, and there is exactly one 
edge between any two vertices. Thus it is a complete directed graph and 
hence a tournament. A tournament is shown in Fig. 5.17. 
The teams participating in a tournament can be ranked according to their 
scores. The score of a team is the number of teams it has defeated. This 
motivates the definition of the score sequence of a tournament. 
The score sequence 
of an π-vertex tournament is the sequence 
(s,, s2,... 
,sn) 
such that each s, is the out-degree of a vertex of the 
tournament. An interesting characterization of a tournament in terms of the 
score sequence is given in the following theorem. 
Theorem 5.14. A sequence of nonnegative integers s,, s 2 , . . . , s„ is the score 
sequence of a tournament G if and only if 
ι. Σ * , - ^ . 
2. Σ s, >
 
k^
k~ 
^ 
for all k < n. 
1=1 
^ 
Proof 
Necessity 
Note that the sum Σ" =, s, is equal to the number of edges in 
the tournament G (Theorem 5.1). Since a tournament is a complete graph, 
it has n(n -1)12 
edges, where η is the number of vertices. Thus 
1 = 1 
To prove condition 2, consider the subtournament on any k vertices 
i>,, v2,..., 
vk. This subtournament has k(k - l)/2 edges. Therefore in the 
entire tournament 
k(k-\) 
2 
i-l 

EXERCISES 
121 
since there may be edges directed from the vertices in the subtournament to 
those outside the subtournament. 
Sufficiency 
See [5.5] (pp. 107-109). 
• 
Suppose we can order the teams in a round-robin tournament such that 
each team precedes the one it has defeated. Then we can assign the integers 
1,2,..., η to the teams to indicate their ranks in this order. Such a ranking 
is always possible since in a tournament there exists a directed Hamilton 
path (Theorem 5.12), and it is called ranking by a Hamilton path. 
Note that ranking by a Hamilton path may not be the same as ranking by 
the score. Further, a tournament may have more than one directed Hamil-
ton path. In such a case there will be more than one Hamilton path ranking. 
However, there exists exactly one directed Hamilton path in a transitive 
tournament. This is stated in the following theorem, which is easy to prove. 
Theorem 5.15. In a transitive tournament there exists exactly one directed 
Hamilton path. 
• 
For other ranking procedures see Bondy and Murty [5.6], Kendall [5.7], 
and Moon and Pullman [5.8]. 
5.9 
FURTHER READING 
Berge [5.5], Harary [5.9], and Chartrand and Lesniak [5.10] are good 
references for a number of results on directed graphs. Moon [5.11] is a 
monograph exclusively devoted to the study of tournaments. See also 
Nash-Williams [5.12]. 
Directed trees are used in the computer representation of combinatorial 
objects. For an extensive discussion of this topic Knuth [5.13] and [5.14], 
Alio, Hopcroft, and Ullman [5.15], and Reingold, Nievergelt, and Deo 
[5.16] may be referred. 
Directed trees also arise in several other applications such as the to-
pological study of electrical networks. In this study one is interested in 
computing the number of directed trees of a directed graph. This question is 
discussed in Chapter 6. 
Harary, Norman, and Cartwright [5.17] and Robert [5.18] discuss several 
applications of directed graphs. 
5.10 
EXERCISES 
5.1 
Let G be a directed graph without self-loops and parallel edges. Let 
max{5 ~,δ
 + } = k. Prove the following: 

122 
DIRECTED GRAPHS 
(a) G has a directed path of length at least k, 
(b) G has a directed circuit of length at least k + 1, if k >0. 
5.2 
Show that the edges of an undirected graph G = (V, E) can be 
oriented so that in the resulting directed graph 
\d
+(v) - d'(v)\ < 1 for all υ E V . 
5.3 
A directed cut in a directed graph is a cut (S, S) whose edges are all 
oriented away from 5 or all oriented toward S. Show that an edge of a 
directed graph belongs either to a directed circuit or to a directed 
cutset, but no edge belongs to both. (This is a special case of a more 
general result known as the "arc coloring lemma," which we prove in 
Chapter 10. See Theorem 10.31.) 
5.4 
For a directed graph G with at least one edge, prove that the 
following are equivalent: 
(a) G has no directed circuits. 
(b) Each edge of G is in a directed cutset. 
5.5 
For a connected directed graph G with at least one edge, prove that 
the following are equivalent: 
(a) G is strongly connected. 
(b) Every edge of G lies on a directed circuit. 
(c) G has no directed cutsets. 
5.6 
Show that an η-vertex directed graph without parallel edges or 
self-loops is strongly connected if 
min{S~, δ
 + } > 
. 
5.7 
Show that a strongly connected graph that contains a circuit of odd 
length also contains a directed circuit of odd length. 
5.8 
Let G = (V, E) be a directed graph such that 
(a) d\x) 
- d~(x) = I = d~(y) - d\y) 
and 
(b) d " » = d'(v) 
for υ Ε V- {x, y). 
Show that there are / edge-disjoint directed x-y paths in G. 
5.9 
Show that a strongly connected graph has a spanning directed walk. 
5.10 What is the longest circular sequence formed out of three symbols x, 
y, and ζ such that no subsequence of four symbols is repeated? Give 
one such sequence. 
5.11 Find a circular sequence of seven 0's and seven l's such that all 
four-digit binary sequences except 0000 and 1111 appear as sub-
sequences of the sequence. 

EXERCISES 
123 
5.12 Prove that a directed Hamilton circuit of Gsn 
corresponds to a 
directed Euler trail of Gsn_l. 
Is it true that Gs „ always has a directed 
Hamilton circuit? 
5.13 Show that the number of directed Euler trails in a directed graph, 
having η vertices and m>2n 
edges, is even. 
5.14 
(a) Let G be a strongly connected nontrivial η-vertex directed graph 
with no parallel edges or self-loops. Prove that G has a directed 
Hamilton circuit if, for every pair u, ν of distinct nonadjacent 
vertices, 
d(u) + d(v) > In - 1 
(Meyniel [5.19]). 
(b) Let G be a nontrivial π-vertex directed graph G = (V, E) with no 
parallel edges or self-loops. Prove that G has a directed Hamilton 
circuit if, whenever u and i; are distinct vertices with (M, 
v)f£E, 
d
+(u) + d~(v)>n 
(Woodall [5.20]). 
5.15 Let G = (V, E) be an η-vertex directed graph without parallel edges 
or self-loops such that for every pair of distinct nonadjacent vertices u 
and ν 
d(u) + d{v) > In - 3 . 
Prove that G contains a directed Hamilton path. 
Note: This result can be proved using Exercise 5.14. One corollary 
of this that can be proved independently is: An Λ-vertex directed 
graph G = (V, E) without parallel edges or self-loops contains a 
directed Hamilton path if, for every vertex ν G V, 
d
+{v) + 
d-(v)^n-\. 
5.16 
A directed graph G = (V, E) is Hamilton connected if G contains a 
directed Hamilton u-υ path for every distinct vertices u and ν of G. 
Let G be a nontrivial η-vertex directed graph without parallel edges 
or self-loops such that for every pair u, ν of distinct vertices with 
(u,v)0E, 
d
+(u) + d~(v)>n 
+ l . 
Prove that G is Hamilton connected (Overbeck-Larisch [5.21]). 
5.17 Show that every tournament is strongly connected or can be trans-
formed into a strongly connected tournament by reversing the orien-
tation of just one edge. 

124 
DIRECTED GRAPHS 
5.11 
REFERENCES 
5.1 
Μ. N. S. Swamy and K. Thulasiraman, Graphs, Networks and Algorithms, 
Wiley-Interscience, New York, 1981. 
5.2 
S. W. Golomb, Shift Register Sequences, Holden-Day, San Francisco, 1967. 
5.3 
T. Van Aardenne-Ehrenfest and N. G. de Bruijn, "Circuits and Trees in 
Oriented Linear Graphs," Simon Stevin, Vol. 28, 203-217 (1951). 
5.4 
J. W. Moon, "On Subtournaments of a Tournament," Canad. Math. Bull., 
Vol. 9, 297-301 (1966). 
5.5 
C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
5.6 
J. A. Bondy and U. S. R. Murty, Graph Theory with Applications, Macmillan, 
London, 1976. 
5.7 
M. G. Kendall, "Further Contributions to the Theory of Paired 
Comparisons," Biometrics, Vol. 11, 43-62 (1955). 
5.8 
J. W. Moon and N. J. Pullman, "On Generalized Tournament Matrices," 
SI AM Rev., Vol. 12, 384-399 (1970). 
5.9 
F. Harary, Graph Theory, Addison-Wesley, Reading, Mass., 1969. 
5.10 G. Chartrand and L. Lesniak, Graphs and Directed Graphs, Wadsworth and 
Brooks/Cole, Pacific Grove, Calif., 1986. 
5.11 J. W. Moon, Topics on Tournaments, Holt, Rinehart and Winston, New York, 
1968. 
5.12 C. St. J. A. Nash-Williams, "Hamiltonian Circuits," in Studies in Graph 
Theory, Part II, MAA Press, 1975, Washington, D.C., pp. 301-360. 
5.13 D. E. Knuth, The Art of Computer Programming, Vol. 1: Fundamental 
Algorithms, Addison-Wesley, Reading, Mass., 1968. 
5.14 D. E. Knuth, The Art of Computer Programming, Vol. 3: Sorting and 
Searching, Addison-Wesley, Reading, Mass.,1973. 
5.15 Α. V. Aho, J. E. Hopcroft, and J. D. Ullman, The Design and Analysis of 
Computer Algorithms, Addison-Wesley, Reading, Mass., 1974. 
5.18 
A subset 5 C V is an independent set of a graph G = (V, E) if no two 
of the vertices in S are adjacent. Prove that a directed graph G 
without self-loops has an independent set 5 such that each vertex υ of 
G not in S can be reached from a vertex in S by a directed path of 
length at most 2 (Chvatal and Lovasz [5.22]). 
An interesting corollary of this result is the following: A tournament 
contains a vertex from which every vertex can be reached by a 
directed path of length at most 2. 
5.19 
Show that the scores s, of an η-vertex tournament satisfy 
Σι,
2 = Σ ( π - ι - ο
2 . 
1=1 
1=1 

REFERENCES 
125 
5.16 Ε. Μ. Reingold, J. Nievergelt, and N. Deo, Combinatorial Algorithms: 
Theory and Practice, Prentice-Hall, Englewood Cliffs, N.J., 1977. 
5.17 F. Harary, R. Z. Norman, and D. Cartwright, Structural Models: An Intro-
duction to the Theory of Directed Graphs, Wiley, New York, 1965. 
5.18 F. S. Robert, Discrete Mathematical Models with Applications to Social, 
Biological and Environmental Problems, Prentice-Hall, Englewood Cliffs, 
N.J., 1976. 
5.19 M. Meyniel, "Une Condition Suffisante d'Existence d'un Circuit Hamiltonian 
dans un Graph Oriente," J. Combinatorial Theory, Vol. 14B, 137-147, 
(1973). 
5.20 D. R. Woodall, "Sufficient Conditions for Circuits in Graphs," Proc. London, 
Math. Society, Vol. 24, 739-755, (1972). 
5.21 M. Overbeck-Larisch, "Hamiltonian Paths in Oriented Graphs," J. Combina-
torial Theory, Vol. 21B, 76-80 (1976). 
5.22 V. Chvatal and L. Lovasz, "Every Directed Graph Has a Semi-Kernel," in 
Hypergraph Seminar, C. Berge and D. K. Ray-Chaudhuri, Eds., Springer, 
New York, 1974, p. 175. 

CHAPTER 6 
MATRICES OF A GRAPH 
In this chapter we introduce the incidence, circuit, cut, and adjacency 
matrices of a graph and establish several properties of these matrices that 
help to reveal the structure of a graph. The incidence, circuit, and cut 
matrices arise in the study of electrical networks because these matrices are 
the coefficient matrices of Kirchhoff s equations that describe a network. 
Thus the properties of these matrices and other related results to be 
established in this chapter form the basis of graph-theoretic study of 
electrical networks and systems. The properties of the adjacency matrix to 
be discussed here form the basis of the signal flow graph approach, which is 
a very powerful tool in the study of linear systems. Signal flow graph theory 
is developed in Section 6.11. 
Our discussions of incidence, circuit, and cut matrices are mainly with 
respect to directed graphs. However, these discussions become valid for 
undirected graphs too if addition and multiplication are in GF(2), the field 
of integers modulo 2. 
6.1 
INCIDENCE MATRIX 
Consider a graph G with η vertices and m edges and having no self-loops. 
The all-vertex incidence matrix Ac = [a,7] of G has η rows, one for each 
vertex, and m columns, one for each edge. The element ait of Ac is defined 
as follows: 
126 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

INCIDENCE MATRIX 
127 
G is directed 
1, 
if the y'th edge is incident on the i'th vertex and 
oriented away from it; 
- 1 , 
if the y'th edge is incident on the i'th vertex and 
oriented toward it; 
0, 
if the y'th edge is not incident on the i'th vertex . 
G is undirected 
_ r i , 
if 
fl'/-\0, 
ot 
the y'th edge is incident on the i'th vertex; 
otherwise. 
A row of Ac will be referred to as an incidence vector of G. Two graphs 
and their all-vertex incidence matrices are shown in Fig. 6.1a and 6.1b. 
1 
1 
0 
0 
0 
0 
0 
- 1 
0
-
1 
ι 
o
o
o 
0
-
1
1
0
1
1
0 
ο 
ο 
0
-
1
-
1 
o - i 
is) 
- 1 
1 
Figure 6.1 (a) A directed graph G and its all-vertex incidence matrix, (b) An 
undirected graph G and its all-vertex incidence matrix. 

128 
MATRICES OF A GRAPH 
" 4 
V 5 
"i
 
ee 
Ί 
0 
0 
0 
0 
0 
0 
1 
1 
0 
1 
0 
1 
0 
1 
1 
(i>> 
Figure 6.1. (Continued) 
It should be clear from the preceding definition that each column of Ac 
contains exactly two nonzero entries, one +1 and one - 1 . Therefore we can 
obtain any row of Ac from the remaining η - 1 rows. Thus any η - 1 rows of 
Ac contain all the information about Ac. In other words the rows of Ac are 
linearly dependent. 
An (n - l)-rowed submatrix A of Ac will be referred to as an incidence 
matrix of G. The vertex that corresponds to the row of Ac that is not in A 
will be called the reference vertex of A. Note that 
rank(.4) = r a n k ( / l c ) < n - l . 
(6.1) 
Now we show that in the case of a connected graph, rank of Ac is in fact 
equal to η - 1. This result is based on the following theorem. 
Theorem 6.1. The determinant of any incidence matrix of a tree is equal to 
±1. 
1
1
0
0 
1 
1 
1 
1 
0
0
0
1 
0
0
0
0 

INCIDENCE MATRIX 
129 
Proof. Proof is by induction on the number η of vertices in a tree. 
Any incidence matrix of a tree on two vertices is just a 1 x 1 matrix with 
its only entry being equal to ±1. Thus the theorem is true for η = 2. Note 
that the theorem does not arise for η = 1. 
Let the theorem be true for 2 s « < t . Consider a tree Τ with k + 1 
vertices. Let A denote an incidence matrix of T. By Theorem 2.5, Γ has at 
least two pendant vertices. Let the i'th vertex of Γ be a pendant vertex, and 
let this not be the reference vertex of A. If the only edge incident on this 
vertex is the /th one, then in A 
a,, = ± l 
and 
a,; = 0, 
]ΦΙ. 
If we now expand the determinant of A by the /"th row, then 
det(A) = ± ( - l ) '
+ ' d e t ( A ' ) 
(6.2) 
where A' is obtained by removing the i'th row and the /th column from A. 
Suppose Τ is the graph that results after removing the i'th vertex and the 
/th edge from T. Clearly 7" is a tree because the /'th vertex is a pendant 
vertex and the /th edge is a pendant edge in T. Further it is easy to verify 
that A' is an incidence matrix of T'. Since T is a tree on η - 1 vertices, we 
have by the induction hypothesis that 
detA' = ± l . 
(6.3) 
This result in conjunction with (6.2) proves the theorem for η = k + 1. 
• 
Since a connected graph has at least one spanning tree, it follows from 
Theorem 6.1 that in any incidence matrix A of a connected graph with η 
vertices there exists a nonsingular submatrix of order η - 1 . Thus for a 
connected graph, 
rank(A) = η - 1. 
(6.4) 
Since rank(A c) = rank(A), we get the following theorem. 
Theorem 6.2. The rank of the all-vertex incidence matrix of an n-vertex 
connected graph G is equal to η - 1, the rank of G. 
• 
An immediate consequence of Theorem 6.2 is the following. 
Corollary 6.2.1. If an π-vertex graph has ρ components, then the rank of its 
all-vertex incidence matrix is equal to η - ρ, the rank of G. 
• 

130 
MATRICES OF A GRAPH 
6.2 
CUT MATRIX 
To define the cut matrix of a directed graph we need to assign an orientation 
to each cut of the graph. 
Consider a directed graph G = (V, E). If Va is a nonempty subset of V, 
then we may recall ^Chapter 2) that the set of edges connecting the vertices 
in Va to those in Va is a cut, and this cut is denoted as (ν,,,ν,,). The 
orientation of {Va, Va) may be assumed to be either from Va to_ Va or from 
Va to Va. Suppose we assume that the orientation is from Va to Va. Then the 
orientation of an edge in (Va,Va) 
is said to agree with the orientation of the 
cut (Va,Va) 
if the edge is oriented from a vertex in Va to a vertex in Va. 
The cut matrix Qc = [qtj] of a graph G with m edges has m columns and 
as many rows as the number of cuts in G. The entry qtj is defined as follows: 
G is directed 
1, 
if the /th edge is in the ith cut and its orientation agrees with 
the cut orientation; 
I - 1 , 
if the /th edge is in the ith cut and its orientation does not 
agree with the cut orientation; 
0 , if the /th edge is not in the ith cut. 
G is undirected 
_ ί 1, 
if the /th edge is in the /th cut; 
Q'i ~ \ 0, 
otherwise . 
A row of Qc will be referred to as a cut vector. 
Three cuts of the directed graph of Fig. 6.1a are shown in Fig. 6.2. In 
each case the cut orientation is shown in dashed lines. The submatrix of Qc 
corresponding to these cuts is 
e i 
e2 
e 3 
« 6 
« 7 
Cutl ' 1 
0 
1 
0 
1 
1 0" 
Cut 2 1 
1 0 
0 
0 
- 1 
1 
Cut 3 0 
- 1 
1 
0 
1 
1 0 
The corresponding submatrix in the undirected case can be obtained by 
replacing the - l ' s in the matrix by +l's. 
Consider next any vertex v. The nonzero entries in the corresponding 
incidence vector represent the edges incident on v. These edges form the cut 
(ν, V- v). If we assume that the orientation of this cut is from υ to V- 
v, 
then we can see from the definitions of cut and incidence matrices that the 
row in Qc corresponding to the cut (ν, V- v) is the same as the row in Ac 
corresponding to the vertex v. Thus Ac is a submatrix of Qc. 

CUT MATRIX 
131 
Figure 6.2. Some cuts of the graph of 
Cut 3 
Fig. 6.1a. 
Now we proceed to show that the rank of Qc is equal to that of Ac. To do 
so we need the following theorem. 
Theorem 6.3. Each row in the cut matrix Qc can be expressed, in two ways, 
as a linear combination of the rows of the matrix Ac. In each case the 
nonzero coefficients in the linear combination are all +1 or all - 1 . 
Proof. Let (Va, Va) be the i'th cut in a graph G with η vertices and m edges, 
and let 
be the corresponding cut vector. Let Va = {y,, v2>.. •, vr) and 
Va = {vr+l, 
vr+1,... 
,v„}. For 1 < i < n, let a, denote the incidence vector 
corresponding to the vertex v,. 

132 
MATRICES OF A GRAPH 
We_ assume, without_ any loss of generality, that the orientation of 
{Va, Va) is from Va to Va, and prove the theorem by establishing that 
q, = «i + a2 + · · · + ar = - ( a r + 1 + ar+2 + · · • + a„). 
(6.5) 
Let vp and vq be the end vertices of the kth edge, 1 < A; ^ m. Let this edge 
be oriented from vp to vq so that 
°pk =
1 -
aqk = - l , 
(6.6) 
Now four cases arise. 
Case 1 
vpEV0 
and vq Ε Va, that is, ρ s r and q 2: r + 1, so that 
= 1. 
Case 2 
vpEVa 
and vq Ε Va, that is, ρ > r + 1 and q < r, so that <?,λ = 
- 1 . 
Caie 3 
vp,vqEVa, 
that is p, q ^ r, so that q,k = 0. 
Case 4 
vp, vq Ε Va, that is, p, q > r + 1, so that 
= 0. 
It is easy to verify, using (6.6), that the following is true in each of these 
four cases. 
<tik = ( « u + « 2 * + · · · + « r * ) 
= -(«,+!.* + <>r+2.k + ·•· + ank). 
(6.7) 
Now (6.5) follows since (6.7) is valid for all 1 < A: < m. Hence the 
theorem. 
• 
To illustrate Theorem 6.3, consider the cut 1 j n Fig. 6.2. This cut 
separates the vertices in Va = {υ,, i>3} from those in Va. The cut orientation 
is from Va to Va. So the corresponding cut vector can be expressed as 
follows: 
[1 0 1 0 
1 1 0] = α, + α 3 
= -a2 
-a4-a5 
where a,, a2,..., 
a5 are the rows of the matrix A in Fig. 6.1a. 
An important consequence of Theorem 6.3 is that rank (Qc) s rank(A c). 
However, rank(Q c) ^ rank(y4c) because Ac is a submatrix of Qc. Therefore, 
we get 
rank((2 c) = rank(/l c). 
Thus Theorem 6.2 and Corollary 6.2.1, respectively, lead to the following. 

CIRCUIT MATRIX 
133 
Theorem 6.4. The rank of the cut matrix Qc of an η-vertex connected graph 
G is equal to « - 1, the rank of G. 
• 
Corollary 6.4.1. The rank of the cut matrix Qc of an η-vertex graph G with ρ 
components is equal to η - ρ, the rank of G. 
• 
As the above discussions show, the all-vertex incidence matrix A c is an 
important submatrix of the cut matrix Qc. Next we identify another im-
portant submatrix of Qc. 
We know that a spanning tree Τ of an η-vertex connected graph G defines 
a set of η - 1 fundamental cutsets—one fundamental cutset for each branch 
of T. The submatrix of Qc corresponding to these η - 1 fundamental cutsets 
is known as the fundamental cutset matrix QfoiG 
with respect to T. 
Let bt, b2,..., 
b„_i denote the branches of T. Suppose we arrange the 
columns and the rows of Qf so that 
1. For 1 < i < η - 1, the ith column corresponds to the branch bt. 
2. The ith row corresponds to the fundamental cutset defined by br 
If, in addition, we assume that the orientation of a fundamental cutset is so 
chosen as to agree with that of the defining branch, then the matrix 
Qfcan 
be displayed in a convenient form as follows: 
Qf = [U\Qfc} 
(6-8) 
where U is the unit matrix of order η - 1 and its columns correspond to the 
branches of T. 
For example, the fundamental cutset matrix Qfot the connected graph of 
Fig. 6.1a with respect to the spanning tree T= {e,, e2, e6, e7} is 
Qf 
e2 
e6 
e 7 
e 3 
« 4 
ex 
1 
0 
0 
0 
1 - 1 
0 
e2 
0 
1 
0 
0 
- 1 
1 0 
0 
0 
1 
0 
0 
1 1 
e 7 
0 
0 
0 
1 
0 
1 1 
(6.9) 
It is clear from (6.8) that the rank of Qf is equal to η - 1, the rank of Qc. 
Thus every cut vector (which may be a cutset vector) can be expressed as a 
linear combination of the fundamental cutset vectors. 
6.3 
CIRCUIT MATRIX 
A circuit can be traversed in one of two directions, clockwise or anticlock-
wise. The direction we choose for traversing a circuit defines its orientation. 

134 
MATRICES OF A GRAPH 
Figure 6.3 
The orientation of a circuit can be pictorially shown by an arrow as in Fig. 
6.3. 
Consider an edge e that has υ, and υ ; as its end vertices. Suppose that this 
edge is oriented from u, to υ] and that it is present in circuit C. Then we say 
that the orientation of e agrees with the orientation of the circuit if u, 
appears before u; when we traverse C in the direction specified by its 
orientation. For example, in Fig. 6.3, the orientation of e, agrees with the 
circuit orientation whereas that of eA does not. 
The circuit matrix Bc = [btj\ of a graph G with m edges has m columns 
and as many rows as the number of circuits in G. The entry 6 ( / is defined as 
follows: 
G is directed 
if the /th edge is in the ith circuit and its orientation 
agrees with the circuit orientation; 
if the /'th edge is in the ith circuit and its orientation 
does not agree with the circuit orientation; 
if the /th edge is not in the ith circuit. 
G is undirected 
if the /th edge is in the ith circuit; 
otherwise . 
A row of Bc will be referred to as a circuit vector of G. 
As an example, consider again the graph of Fig. 6.1a. Three circuits of 
this graph with their orientations are shown in Fig. 6.4. The submatrix of Bc 
corresponding to these three circuits is 
Circuit 1 
Circuit 2 
Circuit 3 
1 
- 1 
0 
- 1 
1 1 
1 
- 1 
0 
e4 
e5 
e6 
e7 
1 - 1 0 
0 
0 
0 
0 
0 
1 
0 - 1 - 1 

CIRCUIT MATRIX 
135 
Circuit 3 
Figure 6.4. Some circuits of the graph of Fig. 6.1a. 
The corresponding submatrix for the undirected graph of Fig. 6.1ft can be 
obtained by replacing the - l ' s by +l's. 
Next we identify an important submatrix of Bc. 
Consider any spanning tree Γ of a connected graph G having η vertices 
and m edges. Let c,, c 2 , . . . , c m _ „ + 1 be the chords of T. We know that these 
m - η + 1 chords define a set of m - η + 1 fundamental circuits. The 
submatrix of Bc corresponding to these fundamental circuits is known as the 
fundamental 
circuit matrix Bf of G with respect to the spanning tree T. 
Suppose we arrange the columns and rows of Bf so that 
1. For l < i < f f i - B + l, the ith column corresponds to the chord c,. 
2. The ith row corresponds to the fundamental circuit defined by c, 
If, in addition, we choose the orientation of a fundamental circuit to agree 
with that of the defining chord, then the matrix Bf can be written as 
BF = [U\BFT] 
(6.10) 
where U is the unit matrix of order m - η + 1 and its columns correspond to 
the chords of T. 

136 
MATRICES OF A GRAPH 
For example, the fundamental circuit matrix of the graph of Fig. 6.1a 
with respect to the spanning tree T= {eu e2, e6, e7} is 
e3 
e 5 
«1 
e 2 
e 6 
1 
0 
0 
- 1 
1 
0 
0 
e 4 
0 
1 
0 
1 - 1 
- 1 
- 1 
e5 
0 
0 
1 
0 
0 
- 1 
- 1 
It is obvious from (6.10) that the rank of Bf is equal t o m - n + 1. Since 
Bf is a submatrix of Bc, we get 
r a n k ( B c ) > m - n + l . 
(6.12) 
We show in the next section that the rank of Bc in the case of a connected 
graph is equal to m - η + 1. 
Now note that the approach used in the previous section to establish the 
rank of Qc cannot be used in the case of Bc. (Why?) Does this mean that 
the "duality" we observed (Chapter 4) between circuits and cutsets is 
merely accidental? No, we shall see that the arguments of the next section 
would further confirm this "duality." 
6.4 
ORTHOGONALITY RELATION 
We showed in Section 4.6 that in the case of an undirected graph every 
circuit vector is orthogonal to every cut vector. Now we prove that this 
result is true in the case of directed graphs too. Our proof is based on the 
following theorem. 
Theorem 6.5. If a cut and a circuit in a directed graph have 2k edges in 
common, then k of these edges have the same relative orientations in the cut 
and in the circuit, and the remaining k edges have one orientation in the cut 
and the opposite orientation in the circuit. 
Proof. Consider a cut (Va,Va) 
and a circuit C in a directed graph. Suppose 
we traverse C starting from a vertex jn Va. Then, for every edge ex that leads 
us from a vertex in Va to a vertex in Va, there is an edge e2 that leads us from 
a vertex in V„ to a vertex in Va. The proof of the theorem will follow if we 
note that if e,(e 2) has the same relative orientation in the cut and in the 
circuit, then e2(ex) 
has one orientation in the cut and the opposite orienta-
tion in the circuit (see Fig. 6.5). 
• 
Now we prove the main result of this section. 

ORTHOGONALITY RELATION 
137 
Figure 6.5 
Theorem 6.6 (Orthogonality Relation). If the columns of the circuit matrix 
Bc and the cut matrix Qc are arranged in the same edge order, then 
Proof. Consider a circuit and a cut that have 2k edges in common. The 
inner product of the corresponding circuit and cut vectors is equal to zero, 
since, by Theorem 6.5, it is the sum of k l's and k - l ' s . The proof of the 
theorem now follows because each entry of the matrix BCQ'C is the inner 
product of a circuit vector and a cut vector. 
• 
The orthogonality relation is a very profound result with interesting 
applications in graph theory and in network theory. Now we use this 
relation to establish the rank of the circuit matrix Bc. 
Consider a connected graph G with η vertices and m edges. Let Bf and Qf 
be the fundamental circuit and cutset matrices of G with respect to a 
spanning tree T. If the columns of Bf and Qf are arranged in the same edge 
order, then we can write Bf and Q, as 
BcQ'c = o. 
Bf = [Bfl 
U] 
and 
Qf = [u 
By the orthogonality relation 
0, 
that is, 
that is, 
Bfl = 
-Q'fc. 
(6.13) 

138 
MATRICES OF A GRAPH 
Let β = [/3,, ft,..., β„\βρ+ί,. 
. ., ft,], where ρ is the rank of G, be a 
circuit vector with its columns arranged in the same edge order as Bf and 
Qf. Then, again by the orthogonality relation, 
fiQ'r = [A, 
ft,..., 
ftlft+„ 
· . . , A J [ = ο. 
Therefore 
[ft, ft,..., ft] = -[ft + 1, ft+2,..., ft,]G'/e = [βρ+ι, 
βρ+2,..., 
ftjft,. 
Using the above equation we can write [ft, ft,..., ft,] as 
[ f t , 
ft,..., 
ft,] 
= [ f t + 
1 , 
ft+2,..., 
ft,][ft, 
U] = [ f t
+
1 , 
ft+2,..., 
ftjft 
. 
(6.14) 
Thus any circuit vector can be expressed as a linear combination of the 
fundamental circuit vectors. So 
rank(ft) s rank(B r) = m - η + 1. 
Combining the above inequality with (6.12) establishes the following 
theorem and its corollary. 
Theorem 6.7. The rank of the circuit matrix Bc of a connected graph G with 
η vertices and m edges is equal to m - η + 1, the nullity of G. 
• 
Corollary 6.7.1. The rank of the circuit matrix Bc of a graph G with η 
vertices, m edges, and ρ components is equal to m - η + ρ, the nullity of 
G. m 
Suppose a = [a,, a 2 , . . . , a p, a p + 1 , . . . , a m ] is a cut vector such that its 
columns are arranged in the same edge order as Bf and Q f, then we can 
start from the relation 
aB'f = 0 
and prove that 
ο = [α,, α 2 ) . . . ,ap]Qf 
, 
(6.15) 
by following a procedure similar to that used in establishing (6.14). Thus 
every cut vector can be expressed as a linear combination of the fundamen-
tal cutset vectors. Since T&nk.(Qf) = η - 1, we get 

SUBMATRICES OF CUT, INCIDENCE, AND CIRCUIT MATRICES 
139 
6.5 
SUBMATRICES OF CUT, INCIDENCE, AND CIRCUIT MATRICES 
In this section we characterize those submatrices of Qc, Ac, 
and Bc that 
correspond to circuits, cutsets, spanning trees, and cospanning trees and 
discuss some properties of these submatrices. 
Theorem 6.8 
1. There exists a linear relationship among the columns of the cut matrix Qc 
that correspond to the edges of a circuit. 
2. There exists a linear relationship among the columns of the circuit matrix 
Bc that correspond to the edges of a cutset. 
Proof 
1. Let us partition Qc into columns so that 
Qc = 
[Q
{l\Q'
2\...,Q
im)]. 
Let β = [β,, β2,..., 
β„] be a circuit vector. Then by the orthogonali-
ty relation, we have 
<2J3' = 0 
or 
A(2
( l > + /32<2
(2) + · · · + /3 m<2
( m ) = 0 . 
(6.16) 
If we assume, without loss of generality, that the first r elements of β 
are nonzero and the remaining ones are zero, then we have from 
(6.16) 
^ β
(
1
> + / 8 2 ρ
( 2 ) + · · · + / 3 Γ β
( Γ ) = 0 . 
rank(G c) = r a n k ( G / ) = 
, i - l . 
This is thus an alternative proof of Theorem 6.4. 
Note that the ring sum of two subgraphs corresponds to modulo 2 
addition of the corresponding vectors. Therefore in the case of undirected 
graphs, (6.14) and (6.15) are merely restatements of what we have already 
proved in the course of our arguments leading to Theorem 4.6, namely, a 
circuit (cut) can be expressed as a ring sum of fundamental circuits (fun-
damental cutsets). 

140 
MATRICES OF A GRAPH 
Q = [Qu 
Qn), 
Thus there exists a linear relationship among the columns 
Q
(l\ 
β
< Ζ ). · · ·. Q
(r) of Qc
 
t n a t correspond to the edges of a circuit. 
2. The proof in this case follows along the same lines as that for part 
1. 
• 
Corollary 6.8.1. There exists a linear relationship among the columns of the 
incidence matrix that correspond to the edges of a circuit. 
Proof. The result follows from Theorem 6.8, part 1, because the incidence 
matrix is a submatrix of Qc. 
• 
Theorem 6.9. A square submatrix of order η - 1 of any incidence matrix A 
of an η-vertex connected graph G is nonsingular if and only if the edges that 
correspond to the columns of the submatrix form a spanning tree of G. 
Proof 
Necessity 
Consider the η - 1 columns of a nonsingular submatrix of A. 
Since these columns are linearly independent, by Corollary 6.8.1, there is no 
circuit in the corresponding subgraph of G. Since this circuitless subgraph 
has η - 1 edges, it follows from Theorem 2.2 that it is a spanning tree of G. 
Sufficiency 
This follows from Theorem 6.1. 
• 
Thus the spanning trees of a connected graph are in one-to-one corre-
spondence with the nonsingular submatrices of the matrix A. This result is in 
fact the basis of a formula for counting spanning trees that we discuss in 
Section 6.7. 
Theorem 6.10. Consider a connected graph G with η vertices and m edges. 
Let Q be a submatrix of Qc with η - 1 rows and of rank η - 1. A square 
submatrix of Q of order η - 1 is nonsingular if and only if the edges 
corresponding to the columns of this submatrix form a spanning tree of G. 
Proof 
Necessity 
Let the columns of the matrix Q be rearranged so that 
Q = [Qn 
Qn] 
with Qn nonsingular. Since the columns of Qu are linearly independent, by 
Theorem 6.8, part 1, there is no circuit in the corresponding subgraph of G. 
This circuitless subgraph has η — 1 edges and is therefore, by Theorem 2.2, a 
spanning tree of G. 
Sufficiency 
Suppose we rearrange the columns of Q so that 

SUBMATRICES OF CUT, INCIDENCE, AND CIRCUIT MATRICES 
141 
and the columns of β π correspond to the edges of a spanning tree T. Then 
the fundamental cutset matrix Qf with respect to Τ is 
Qf = [u 
Qfc\. 
Since the rows of Q can be expressed as linear combinations of the rows of 
Qf, we can write Q as 
Q = [Qu 
Qn] = t>Qf 
= D[U 
Qfc]. 
Thus 
Qn = DU = D . 
Now D is nonsingular because both Q and Qf are of maximum rank n — l. 
So Qn 
is nonsingular, and the sufficiency of the theorem follows. 
• 
A dual theorem is presented next. 
Theorem 6.11. Consider a connected graph G with η vertices and m edges. 
Let β be a submatrix of the circuit matrix Bc of G with m - η + 1 rows and 
of rank m - η + 1. A square submatrix of Β of order m - η + 1 is nonsingu-
lar if and only if the columns of this submatrix correspond to the edges of a 
cospanning tree. 
Proof 
Necessity 
Let the columns of the matrix Β be rearranged so that 
B = [BU 
Bl2] 
with Bu nonsingular. Since the columns of Bu are linearly independent, by 
Theorem 6.8, part 2, the corresponding subgraph contains no cutsets of G. 
Further this subgraph has m - η +1 edges. Thus it is a maximal (why?) 
subgraph of G containing no cutsets and is therefore a cospanning tree of G 
(see Exercise 2.18). 
Sufficiency 
Suppose we rearrange the columns of Β so that 
B = [BU 
Bl2] 
and the columns of Bu correspond to the edges of a cospanning tree of G. 
Then the fundamental circuit matrix Bf with respect to this cospanning tree 
is 
B, = [U 
Bf,). 

142 
MATRICES OF A GRAPH 
and 
"1 
1 0 0 
0 
- 1 
0 0 
0 
0 
1 0 
.0 
0 
1 1 
" 1 0 
0' 
- 1 
1 
1 
. 
0 0 
1. 
It may be verified that the determinants of these matrices are nonzero, and 
thus these matrices are nonsingular. 
We conclude this section with the study of an interesting property of the 
inverse of a nonsingular submatrix of the incidence matrix. 
Theorem 6.12. Let An 
be a nonsingular submatrix of order η-I 
of an 
incidence matrix A of an η-vertex connected graph G. Then the nonzero 
elements in each row of Axl
l 
are either all 1 or all - 1 . 
Proof. Let A be the incidence matrix with vr as the reference vertex. 
Assume that 
A = [Au 
Al2], 
where Au 
is nonsingular. We know from Theorem 6.9 that the edges 
corresponding to the columns of Au 
constitute a spanning tree ToiG. 
Then 
Qf, the fundamental cutset matrix with respect to T, will be 
Qf = [U 
Qfc] 
Since the rows of Β can be expressed as linear combinations of the rows of 
Bf, we can write Β as 
Β = [Bu 
Bn] = DBf 
= D[U 
Bfl] 
so that BU = DU = D. 
Now D is nonsingular because both Β and Bf are of maximum rank 
m — n + 1. Thus Bu 
is nonsingular and the sufficiency of the theorem 
follows. 
• 
To illustrate Theorems 6.10 and 6.11, consider the graph G of Fig. 6.1a 
and the matrices Qf and Bf in (6.9) and (6.11). The fourth-order square 
submatrix of Qf corresponding to the spanning tree {e,, e 3, e5, e 7} and the 
third-order submatrix of Bf corresponding to the cospanning tree {e2, e 4, e6) 
are, respectively, 

SUBMATRICES OF CUT, INCIDENCE, AND CIRCUIT MATRICES 
143 
By Theorem 6.3, each cut vector can be expressed as a linear combina-
tion of the rows of the incidence matrix. So we can write Qf as 
Qf = [V 
Qfc) = D[Au 
Au\. 
Thus 
D = 
Al-l
l. 
Consider now the /th row qt of Qf. Let the corresponding cutset be 
(va,v„). 
Let 
V„ = 
{Oi,V2,...fVk} 
and 
K = {v
k+l, v
k+2
,...,v
n
} 
. 
Suppose that the orientation of the cutset (Va, Va) is from Va to Va. Then 
we get from (6.5) that 
q, = al + a2 + --- + ak 
(6.17) 
= -(«*+.+ «* + 2 + · · · + «„), 
(6-18) 
where a, is the ith row of Ac. 
Note that row ar corresponding to vr will not be present in A. So if 
vrE. Va, then to represent q, as a linear combination of the rows of A we 
have to write q, as in (6.18). If vr G Va, then we have to write qt as in (6.17). 
In both cases the nonzero coefficients in the linear combination are either all 
1 or all - 1 . 
Thus the nonzero elements in each row of D = A„ are either all 1 or all 
- 1 . 
• 
The proof used in Theorem 6.12 suggests the following simple procedure 
for evaluating ΑΪ*. 
1. From Au 
construct the tree Τ for which An 
is the incidence matrix 
with vertex v„ as the reference vertex. 
2. Label the edges of Τ as e,, e2,..., 
e„_, so that e, corresponds to the 
ith column of Au. 
Similarly label the vertices of Τ as υ,, v2,..., 
i>„_, 
so that v( corresponds to the ith row of 
Au. 
3. Let the ith column of 
correspond to υ,. For each i, l s / < n - l , 
do the following: Remove c, from Τ and let 7\ and T2 be the two 

144 
MATRICES OF A GRAPH 
components of_the resulting disconnected graph. Let Va be the vertex 
set of 7\ and Va the vertex_set of T2, and let e, be oriented from a 
vertex in Va to a vertex in Va. If vnEVa, 
then the ithjow of Ajl has 
- 1 in all columns that correspond to the vertices in V„; all the other 
elements of the ith row will be zero. If vnEVa, 
then the ith row has 1 
in all the columns that correspond to the vertices in Va; all the other 
elements in the ith row will be zero. 
As an illustration, let 
« 1 
e2 
e 3 
0 
- 1 
0 
0 
1 
1 1 
0 
- 1 
0 0 
1 
0 
0 0 
- 1 
The tree Τ for which A u is an incidence matrix is shown in Fig. 6.6a. The 
reference vertex is i>5. 
To obtain the first row of Λ η ' , we first remove e, from Τ and get the two 
components 7\ and T2 shown in Fig. 6.6b. Thus 
Figure 6.6. (β) Tree T. (b) Subtrees Γ, and T2. 

UNIMODULAR MATRICES 
145 
Va = {vlt 
V2, 
V5) 
K = 
{v3,v4}. 
Since the reference vertex is in Va, the first row of A,
-,
1 will have - 1 in the 
columns corresponding to the vertices v3 and v4 of Va, and it is 
[0 0 
- 1 
- 1 ] . 
In a similar way we get all the other rows of A\~{, and A,",
1 is 
0 
0 - 1 
- Γ 
- 1 0 
0 
0 
1 1 
1 
1 · 
0 
0 
0 - 1 . 
6.6 
UNIMODULAR MATRICES 
A matrix is unimodular if the determinant of each of its square submatrices 
is 1, - 1 , or 0. 
We show in this section that the matrices Ac, 
Qf, 
and Bf are all 
unimodular. 
Theorem 6.13. The incidence matrix Ac of a directed graph is unimodular. 
Proof. We prove the theorem by induction on the order of a square 
submatrix of 
Ac. 
Obviously the determinant of every square submatrix of A c of order 1 is 
1, - 1 , or 0. Assume, as the induction hypothesis, that the determinant of 
every square submatrix of order less than k is equal to 1, - 1 , or 0. 
Consider any nonsingular square submatrix of Ac of order k. Every 
column in this matrix contains at most two nonzero entries, one +1 and /or 
one - 1 . Since the submatrix is nonsingular, not every column can have both 
+ 1 and - 1 . For the same reason in this submatrix there can be no column 
consisting of only zeros. Thus there is at least one column that contains 
exactly one nonzero entry. Expanding the determinant of the submatrix by 
this column and using the induction hypothesis, we find that the desired 
determinant is ±1. 
• 
Let Qf be the fundamental cutset matrix of an η-vertex connected graph 
G with respect to some spanning tree T. Let the branches of Γ be ft,, 
b2,.. 
·,&„_,. 
Let G' be the graph that is obtained from G by identifying or short-
circuiting the end vertices of one of the branches, say, branch ft,. Then 
T- {ft,} is a spanning tree of G'. Let us now delete from Qf the row 

146 
MATRICES OF A GRAPH 
It can be verified that this matrix is the fundamental cutset matrix of the 
graph shown in Fig. 6.7 with respect to the spanning tree {el,e6}. 
This 
graph is obtained from the graph of Fig. 6.1a by identifying the end vertices 
of e 2 as well as the end vertices of e 7. 
Theorem 6.14. Any fundamental cutset matrix Qfof a connected graph G is 
unimodular. 
Proof. Let Qf be the fundamental cutset matrix of G with respect to a 
spanning tree T. Then 
Qf = [v 
QfA-
Figure 6.7 
corresponding to branch />, and denote the resulting matrix as Q'f. Then it is 
not difficult to show that Q'f is the fundamental cutset matrix of G' with 
respect to the spanning tree T- {ft,}. Thus the matrix that results after 
deleting any row from Qf is a fundamental cutset matrix of some connected 
graph. Generalizing this, we can state that each matrix formed by some rows 
of Qf is a fundamental cutset matrix of some connected graph. 
For example, consider the graph G of Fig. 6.1a and the fundamental 
cutset matrix Qf given in (6.9). The submatrix consisting of the two rows of 
Qf corresponding to the branches e, and e6 is 

THE NUMBER OF SPANNING TREES 
147 
Let an incidence matrix A of G be partitioned as A = [Au 
Al2] where the 
columns of Au 
correspond to the branches of T. We know from Theorem 
6.9 that A
u is nonsingular. Now we can write Qf as 
Qf = [U 
Qfc] = An
l[Au 
Al2). 
If C is any square submatrix of Qf of order n — l, where η is the number 
of vertices of G, and D is the corresponding submatrix of A, then C = 
A\~{D. Since det D = ±1 or 0 and det A^ = ±1, we get 
d e t C = ± l o r O . 
(6.19) 
Consider next any square submatrix Η of Qf of order less than n — l. 
From the arguments preceding this theorem we know that Η is a submatrix 
of a fundamental cutset matrix of some connected graph. Therefore, 
det Η = ±1 or 0, the proof of which follows along the same lines as that 
used to prove (6.19). 
Thus the determinant of every square submatrix of Qf is ±1 or 0 and 
hence Qf is unimodular. 
• 
Next we show that Bf is unimodular. 
Theorem 6.15. Any fundamental circuit matrix Z^of a connected graph G is 
unimodular. 
Proof. Let Bf and Qf be the fundamental circuit and cutset matrices of G 
with respect to a spanning tree T. If Qf = [U Qfc], then we know from 
(6.13) that 
Bf = [-Q'fc 
U]-
Since Qfc is unimodular, Q'fc is also unimodular. It is now a simple exercise 
to show that [-Q'fc 
U] is also unimodular. 
• 
6.7 
THE NUMBER OF SPANNING TREES 
In this section we derive a formula for counting the number of spanning 
trees in a connected graph. This formula is based on Theorem 6.9 and a 
result in matrix theory, known as the Binet-Cauchy theorem. 
A major determinant or briefly a major of a matrix is a determinant of 
maximum order in the matrix. Let Ρ be a matrix of order ρ x q and Q be a 
matrix of order q x ρ with p^q. 
The majors of Ρ and Q are of order p. If a 
major of Ρ consists of the columns i i , i 2 , . . . , ip of P, then the corresponding 
major of Q is formed by the rows ix, i2,...,ip 
of Q. For example, if 

148 
MATRICES OF A GRAPH 
Μί 
~\ 
λ 
\] 
- 
β " 
1 
2 
- 3 
. 1 
2" 
- 1 
1 
2. 
then for the major 
of P, 
-1 
2 
2 
-3 
is the corresponding major of Q. 
Theorem 6.16 (Binet-Cauchy). If Ρ is a ρ χ ο matrix and β is a ο x ρ 
matrix, with p^q, 
then 
det(Pg) = Σ (product of the corresponding majors of Ρ and Q). 
• 
Proof of this theorem may be found in Hohn [6.1]. 
As an illustration, if the matrices Ρ and Q are given as earlier, then 
applying the Binet-Cauchy theorem we get 
det(PG) = 
+ 
1 
- 1 
1 
2 
I 
1 
3 
1 2 
I 
1 3 
1 
2 
2 
2 
2 
- 1 
Τ 
2 
- 1 
- 3 
1 
Τ 
2 2 
1 
2 
-1 
3 
2 
- 1 
3 
3 
-1 2 
2 
- 3 
- 3 
1 
1 2 
+ 
-1 3 
2 2 
167. 
Theorem 6.17. Let G be a connected undirected graph and A an incidence 
matrix of a directed graph that is obtained by assigning arbitrary orienta-
tions to the edges of G. Then 
t ( G ) = det(AA') , 
where t ( G ) is the number of spanning trees of G. 
Proof. By the Binet-Cauchy theorem 
det(AA') = E( 
Product of the 
\ 
ν corresponding majors of A and A I 
(6.20) 

THE NUMBER OF SPANNING TREES 
149 
Note that the corresponding majors of A and A' both have the same value 
equal to 1, - 1 , or 0 (Theorem 6.13). Therefore each nonzero term in the 
sum on the right-hand side of (6.20) has the value 1. Furthermore, a major 
of A is nonzero if and only if the edges corresponding to the columns of the 
major form a spanning tree. 
Thus there is a one-to-one correspondence between the nonzero terms in 
the sum of the right-hand side of (6.20) and the spanning trees of G. Hence 
the theorem. 
• 
As an example, consider the graph G shown in Fig. 6.8a. A directed 
graph obtained by assigning arbitrary orientations to the edges of G is 
shown in Fig. 6.86. The incidence matrix of this directed graph with vertex 
i>4 as the reference is given by 
»4 
(a) 
Figure 6.8 

150 
MATRICES OF A GRAPH 
So 
' 
2 
AA'= 
- 1 
1 
0 
3 
- 1 
01 
0 
- 1 
2 
and 
det(AA') = 8 . 
The eight spanning trees of G are 
{ e , , e 4 , e 5 } , 
{e,, <?3, e 4} , 
{e,, e 3, <?5} , 
{eue2,e3}, 
{eue2,e5}, 
{e3,e4,e5}, 
{e2,e3,e4}, 
{e2,eA,e5}. 
Let υ,, υ2,...,υ„ 
denote the vertices of an undirected graph G without 
self-loops. The degree matrix Κ = [ktj] of G is an η x η matrix defined as 
follows: 
We can easily see that K= ACA'C and is independent of our choice of edge 
orientations for arriving at the all-vertex incidence matrix Ac. If vr is the 
reference vertex of A, then A A' is obtained by removing the rth row and the 
rth column of K. Thus the matrix A A' used in Theorem 6.17 can be 
obtained by an inspection of the graph G. 
It is clear from the definition of the degree matrix that the sum of all the 
elements in each row of Κ equals zero. Similarly the sum of all the elements 
in each column of Κ equals zero. A square matrix with these properties is 
called an equi-cofactor matrix. As its name implies, all the cofactors of an 
equi-cofactor matrix are equal [6.2]. Thus from Theorem 6.17 we get the 
following result, originally due to Kirchhoff [6.3]. 
Theorem 6.18. All the cofactors of the degree matrix of a connected 
undirected graph has the same value equal to the number of spanning trees 
of G. m 
Next we derive a formula for counting the number of distinct spanning 
trees that can be constructed on η labeled vertices. Clearly this number is 
the same as the number of spanning trees of Kn, the complete graph on η 
labeled vertices. 
Theorem 6.19 (Cayley). There are n"~
2 labeled trees on η &2 vertices. 
if / Φ j and there are ρ parallel edges 
connecting v, and vt ; 

THE NUMBER OF SPANNING 2-TREES 
151 
Proof. In the case of Kn, the matrix A A' is of the form 
Γ η - 1 
- 1 
· · • 
- 1 ] 
- 1 
n - 1 
··· 
- 1 
L - 1 
- 1 
· · · 
n
-
l
j 
By Theorem 6.17, the determinant of this matrix gives the number of 
spanning trees of K„, which is the same as the number of labeled trees on η 
vertices. 
To compute det(AA'), 
subtract the first column of AA' from all the other 
columns of AA'. Then we get 
η — 1 — η 
-η 
• • · 
-η 
- 1 
η 
0 
••· 
0 
- 1 0 
η 
· · · 
0 
L 
- 1 
0 
0 
· · · 
nj 
Now adding to the first row of the above matrix every one of the other rows, 
we get 
" 
1 0 
0 
·•· 
0 " 
- 1 
η 0 
·•· 
0 
- 1 
0 
η 
•·· 
0 
. 
L - l 
0 
0 ··· 
n j 
The determinant of this matrix is n"~
2. The theorem now follows since 
addition of any two rows or any two columns of a matrix does not change 
the value of the determinant of the matrix. 
• 
Several proofs of Cayley's theorem [6.4] are available in the literature. 
See Moon [6.5] and Priifer [6.6]. 
6.8 
THE NUMBER OF SPANNING 2-TREES 
In this section we relate the cofactors of the matrix AA' oi a graph G to the 
number of spanning 2-trees of the appropriate type. For this purpose we 
need symbols to denote 2-trees in which certain specified vertices are 
required to be in different components. We use the symbol Tljk 
rsl 
to 

152 
MATRICES OF A GRAPH 
denote spanning 2-trees in which the vertices v„ vjt vk,... 
are required to 
be in one component and the vertices vr,vs,v,... 
are required to be in the 
other component of the 2-tree. The number of these spanning 2-trees in the 
graph G will be denoted by rl]k 
„, . For example, in the graph of Fig. 
6.8a, the edges e, and e3 form a spanning 2-tree of the type TU23, 
and 
T 1 4 , 2 3
 
= 
1· 
In the following we denote by A an incidence matrix of the directed 
graph that is obtained by assigning arbitrary orientations to the edges of the 
graph G. However, we shall refer to A as an incidence matrix of G. We shall 
assume, without any loss of generality, that v„ is the reference vertex for A, 
and the ith row of A corresponds to vertex ν,. Δ,; will denote the (i, j) 
cofactor of AA'. 
Let A 
denote the matrix obtained by removing from A its ith row. If G' 
is the graph obtained by short-circuiting the vertices υ, and vn in G, then we 
can easily verify the following: 
1. A_, is the incidence matrix of G' with v„ as the reference vertex. 
2. A set of edges forms a spanning tree of G' if and only if these edges 
form a spanning 2-tree Tin of G. 
Thus there exists a one-to-one correspondence between the nonzero majors 
of A_, and the spanning 2-trees of the type T, „. 
Theorem 6.20. For a connected graph G, 
Δ . = τ- . 
Proof. Clearly Δ„ = det(A_,A'_,). Proof is immediate since the nonzero 
majors of A_, correspond to the spanning 2-trees Tin 
of G and vice 
versa. 
• 
Consider next the (i, /) cofactor Δ ( ; of AA', which is given by 
Ai; = (-l)'
+'det(A_,A'_ ;). 
(6.21) 
By the Binet-Cauchy theorem, 
det(A_,A' ) = Σ( 
Productofthe 
\ 
' 
\ corresponding majors of A _,· and A_t l 
Each nonzero major of A _, corresponds to a spanning 2-tree of the type 
T, „, and each nonzero major of A 
corresponds to a spanning 2-tree of the 
type Tin. 
Therefore the nonzero terms in the sum on the right-hand side of 
(6.22) correspond to the spanning 2-trees of the type Ttl „. Each one of 
these nonzero terms is equal to a determinant of the type det(F_,F'_ ;), 
where F is the incidence matrix of a 2-tree of the type Γ 
. 

THE NUMBER OF SPANNING 2-TREES 
153 
Theorem 6.21. Let F denote the incidence matrix of a 2-tree Τηη 
with v„ as 
the reference vertex. If the i'th row of F corresponds to vertex vt, then 
det(F_,F'_,) = ( - l ) '
+ \ 
Proof. Let Γ, and T2 denote the two components of Γ 
. Assume that v„ is 
in T2. By interchanging some of its rows and the corresponding columns, we 
can write the matrix FF' as 
5 
= [O4D]' 
where 
1. C is the degree matrix of Γ,, and 
2. D can be obtained by removing from the degree matrix of T2 the row 
and the column corresponding to vn. 
Let row k' of S correspond to vertex vk. 
Interchanging some rows and the corresponding columns of a matrix does 
not alter the values of the cofactors of the matrix. So 
(/', ;') cofactor of S = (/, ;') cofactor of (FF') 
= (-l)'
+'det(F_,F'_ /). 
(6.23) 
By Theorem 6.18 all the cofactors of C have the same value equal to the 
number of spanning trees of 7,. So we have 
(Γ, /') cofactor of c = 1. 
Furthermore, 
det D = 1 . 
So 
(f, j') cofactor of S = [(Γ, /') cofactor of C][det D] 
= 1 . 
(6.24) 
Now, from (6.23) and (6.24) we get 
det(F_,F'_,) = ( - l )
, + ' . 
• 
Proof of Theorem 6.21 is by Sankara Rao, Bapeswara Rao, and Murti 
[6.7]. 
The following result is due to Mayeda. 

154 
MATRICES OF A GRAPH 
Δ = τ · 
ι/ 
Ι." 
Proof. Since each nonzero term in the sum on the right-hand side of (6.22) 
is equal to a determinant of the type given in Theorem 6.21, we get 
So 
detM_IA'_;) = (-l)
, +V l / i ( I. 
AfJ = (-l)
,+'det(i4_X_,) 
To illustrate Theorems 6.20 and 6.22 consider again the graph of Fig. 6.8a. 
If vertex υ 4 is the references vertex for A, then 
and 
So 
Γ1 0 
0 
1 0 ] 
-
2 
Lo ο -ι ο - u 
Γ1 
0 0 
1 01 
A
i 
Lo -ι 
ι -ι 
o r 
τ 2 4 = det(A 
_2A'_2) 
= d e t([o 2]) 
= 4 
T 2 X 4 = 
(-l)
2+3det{A_2A'_,) 
-Mil:!]) 
= 2. 
In this graph the spanning 2-trees of the type T24 
are 
{ e 4 , e 5 } , 
{ e 3 , e 4 } . 
{eue3}, 
{ e , , e 5 } , 
and the spanning 2-trees of the type T23 
4 are 
{
ei>
 
e i ) 
< 
{
e3> 
^ 4 ) 
· 
and 
Theorem 6.22. For a connected graph G, 

THE NUMBER OF DIRECTED SPANNING TREES IN A DIRECTED GRAPH 
155 
6.9 
THE NUMBER OF DIRECTED SPANNING TREES IN A 
DIRECTED GRAPH 
In this section we discuss a method due to Tutte [6.8] for computing the 
number of directed spanning trees in a given directed graph having a 
specified vertex as root. This method is in fact a generalization of the 
method given in Theorem 6.17 to compute the number of spanning trees of 
a graph, and it is given in terms of the in-degree matrix. 
The in-degree matrix Κ = [kpq] of a directed graph G = (V, E) without 
self-loops and with V= {υ,, v2,..., 
vn} 
is an η χ η matrix denned as 
follows: 
' - ω , 
if ρ Φ q and there are ω parallel edges directed 
from vp to vq ; 
d~{vp), 
np = q. 
Let Kt) denote the matrix obtained by removing row i and column / from 
K. 
Tutte's method is based on the following theorem. 
Theorem 6.23. A directed graph G = (V, E) with no self-loops and with 
V= {u,, v2,..., 
v„) is a directed tree with vr as the root if and only if its 
in-degree matrix Κ has the following properties: 
fO, 
ifp = r ; 
[ 1 , 
\ip*r. 
2. d e t ( / U = 1 . 
Proof 
Necessity 
Suppose the given directed graph G is a directed tree with vr 
as the root. Clearly G is acyclic. So (see Section 5.7) we can label the 
vertices of G with the numbers 1,2,... ,n in such a way that (/, /) is a 
directed edge of G only if i < j . Then in such a numbering, the root vertex 
would receive the number 1. If the ith row and the i'th column of the new 
in-degree matrix K' of G correspond to the vertex assigned the number i, 
then we can easily see that K' has the following properties: 
k'„ = l, 
ίογρΦί, 
k'pq=0, 
\fp>q. 
Therefore 
det(*;,) = l 

156 
MATRICES OF A GRAPH 
The matrix K' can be obtained by interchanging some rows and the 
corresponding columns of K. Such an interchange does not change the value 
of the determinant of any submatrix of K. So 
det(/^ r r) = det(/c; i) = l . 
Sufficiency 
Suppose the in-degree matrix Κ of the graph G satisfies the 
two properties given in the theorem. If G is not a directed tree, then by 
property 1 and Theorem 5.4, statement 5, it contains a circuit C. The root 
vertex vr cannot be in C, for this would imply that d~(vr)>0 
or that 
d~(v)>l 
for some other vertex υ in C, contradicting property 1. In a similar 
way, we can show that 
1. C must be a directed circuit. 
2. No edge not in C is incident into any vertex in C. 
Consider now the submatrix K, of Κ consisting of the columns corre-
sponding to the vertices in C. Because of the above properties, each row of 
Ks corresponding to a vertex in C has exactly one +1 and one - 1 . All the 
other rows contain only zero elements. Thus the sum of the columns of 
is 
zero. In other words the sum of the columns of Κ that correspond to the 
vertices in C is zero. Since vr is not in C, this is true in the case of the matrix 
Krr too, contradicting property 2. Hence the sufficiency. 
• 
We now develop Tutte's method for computing the number τα of the 
directed spanning trees of a directed graph G having vertex vr as the root. 
Assume that G has no self-loops. 
For any graph g let K(g) denote its in-degree matrix, and let K' be the 
matrix obtained from Κ by replacing its rth column by a column of zeros. 
Denote by 5 the collection of all the subgraphs of G in each of which 
d~(vr) = 0 and d~(vp) = 1 for ρ Φ r. Clearly 
\S\=f\d-(vp). 
#>=· 
Further, for any subgraph g £ S, the corresponding in-degree matrix satisfies 
property 1 given in Theorem 6.23. 
It is well known in matrix theory that the determinant of a square matrix 
is a linear function of its columns. For example, if 
^ = [ P i . P 2 , . . . , p ' / + p " , . . . , p ( 1 ] 
is a square matrix with the columns />,, p2,..., 
p, + p",..., 
p„, then 
det Ρ = det[p,, p2,..., 
p'„ ..., p„] + det[p,, p2,..., 
p",..., 
p„]. 

THE NUMBER OF DIRECTED SPANNING TREES IN A DIRECTED GRAPH 
157 
Using the linearity of the determinant function and the fact that the sum 
of all the entries in each column of the matrix K'(G) is equal to zero, we 
can write det K'{G) as the sum of \S\ determinants, each of which satisfies 
property 1 given in Theorem 6.23. It can be seen that there is a one-to-one 
correspondence between these determinants and the in-degree matrices of 
the subgraphs in 5. Thus 
det K\G)= 
Σ det 
K'(g). 
So 
det Κ'„(β)=Σ 
det K'„(g). 
Since 
det K'rr(G) = det 
K„(G), 
and 
d e t / C ( g ) = det/s: r r(g) 
for all g(E 5 , 
we get 
detK„(G)= Σ det 
K'„(g). 
From Theorem 6.23 it follows that each determinant in the sum on the 
right-hand side of the above equation is nonzero and equal to 1 if and only if 
the corresponding subgraph in 5 is a directed spanning tree. Thus we have 
proved the following theorem. 
Theorem 6.24. Let Κ be the in-degree matrix of a directed graph G without 
self-loops. Let the ith row of Κ correspond to vertex u, of G. Then the 
number rd of the directed spanning trees of G having vr as its root is given 
by 
Td 
= det K„, 
where Krr is the matrix obtained by removing from Κ its rth row and its rth 
column. 
• 
We now illustrate Theorem 6.24 and the arguments leading to its proof. 
Consider the directed graph G shown in Fig. 6.9. Let us compute the 
number of directed spanning trees with vertex υ, as the root. 

158 
MATRICES OF A GRAPH 
Figure 6.9 
The in-degree matrix Κ of G is 
and 
We can write det K' as 
K = 
1 
- 1 
-1 
2 
0 
- 1 
0 
- 1 
- 2 
0 
2 - 1 
0 
- 1 
3J 
det K' 
0 
- 1 
0 
2 
0 
- 1 
0 
- 1 
0 
1 
0 
0 
0 
0 
0 
-
- 2 
- 1 
3 
- 1 
0 
1 
0 
- 1 
1 
0 
1 
1 
+ 
0 
- 1 
0 
0 
0 
0 
0 
+ 
+ 
+ 
1 
- 1 
0 
3 
- 1 
- 1 
1 
0 
0 
1 
0 
0 - 1 
0 
1 
0 
0 
- 1 
1 
0 
1 
-1 
0 
- 1 
0 
0 
1 
- 1 
0 
1 
0 
0 
0 
0 
1 
- 1 
0 
- 1 
1 
The six determinants on the right-hand side correspond to the subgraphs on 
the following sets of edges: 
{ « 4 , « s } , 
{ e 4 . e 6 } . 
{e„e3}. 
Removing the first row and the first column from the above determinants, 
we get 
det K'n = 
2 
- 1 
1 
0 
I 
1 0 
I 
1 
- 1 
- 1 
3 
0 1 Τ 
0 1 
0 
1 
+ 
1 0 
1 
1 0 + 
1 - 1 
- 1 
1 Τ 
- 1 
1 + - 1 
1 
= 5 . 

ADJACENCY MATRIX 
1 5 9 
The five directed spanning trees with u, as root are 
{«„«5}- 
{e^e6}, 
{e,,e 3}, 
{e4,es}, 
{e4, e6} . 
6.10 ADJACENCY MATRIX 
Let G = (V, E) be a directed graph with no parallel edges. Let V = 
{u,, v2,..., 
v„}. The adjacency matrix M = [m,y] of G is an n x n matrix 
with m„ defined as follows: 
m„ 
( 1 , 
if(Vi,Vl)EE. 
0, 
otherwise. 
For example, the graph of Fig. 6.10 has the following adjacency matrix: 
M = v2 
Vx 
V2 
l>3 
V4 
1 0 
1 0 -
1 0 
0 
0 
0 
1 0 
1 
0 
1 0 
1 
In the case of an undirected graph, m/y = 1 and only if there is an edge 
connecting i>, and Vj. 
We now study some results involving the adjacency matrix. 
Theorem 6.25. The (1, /) entry m^ of Mr is equal to the number of directed 
walks of length r from v, to vr 
Proof. Proof is by induction on r. Obviously, the result is true for r= 1. 
As the inductive hypothesis we shall assume that the theorem is true for 
MT~\ Then 
Figure 6.10 

160 
MATRICES OF A GRAPH 
M
3 = 
2 2 
1 2 
1 1 1 1 
2 
1 1 1 
2 
1 1 1 
The entry (1,4) in this matrix gives the number of directed walks of length 3 
from y, to v4. These walks are 
(
e 6 -
e i '
e 4 )
 
a
n
d 
(.eue4,e7). 
We next study an important theorem due to Harary [6.9] that forms the 
foundation of the signal flow approach for the solution of linear algebraic 
equations. To introduce the theorem, we need some terminology. 
A 1 -factor of a directed graph G is a spanning subgraph of G in which the 
in-degree and the out-degree of every vertex are both equal to 1. Obviously, 
such a subgraph is a collection of vertex-disjoint directed circuits including 
self-loops of G. For example, the two 1-factors of the graph of Fig. 6.10 are 
shown in Fig. 6.11a and 6.11ft. 
Consider now a permutation;Ί, y 2, · · ·, /„ of the integers 1,2,..., n. This 
permutation is even if an even number of interchanges are required to 
rearrange it as 1, 2, 3 , . . . , n. An odd permutation is defined in a similar 
way. For example, consider the permutation 1 3 4 2. The following sequence 
of two interchanges will rearrange this permutation as 1 2 3 4: 
1. Interchange 3 and 2. 
2. Interchange 3 and 4. 
Thus this permutation is an even permutation. 
Theorem 6.26. Let H,, i' = l , 2 , . . . , p, be the 1-factors of an n-vertex 
directed graph G. Let L, denote the number of directed circuits in //, and let 
_ γ 
/ number of directed walks of \ 
t
= i \ length r - 1 from υ, to vk 
I
 
m*>" 
For each k the corresponding term in the sum in the above equation gives 
the number of directed walks of length r from u, to υ. whose last edge is from 
vk to Vj. The theorem follows for M\ if we note that the number of directed 
walks of length r from v, to vt = Σ£ = 1 (number of directed walks of length r 
from v, to υ j whose last edge is from vk to u ;). 
• 
For example, consider the third power of the matrix Μ of the graph of 
Fig. 6.10: 

ADJACENCY MATRIX 
1 6 1 
4 
< 
6 
Figure 6 . 1 1 . The two 1-factors of the graph of Fig. 6.10. 
Μ be the adjacency matrix of G. Then 
P 
det 
Af 
= 
( - 1 ) " 
Σ 
( ~ 1 )
L ' 
· 
1 = 1 
Proof. From the definition of a determinant 
det Μ = Σ e
h
h 
. . , , , » ! „ , 
· " J
2 ,
2 m
n
)
n , 
( 6 . 2 5 ) 
where 
1 - 0 ) = ΟΊ> 72»· · ·> /«)
 i s 
a permutation of 1 , 2 , . . . , n. 
2. €hj 
, y „
 = 1 if ( / ) '
s 
a
n 
e
v
e
n permutation; otherwise it is equal to 
- 1 . 
3 . The sum E
(
y
) is taken over all permutations of 
1 , 2 , . . 
. , n. 
A nonzero term mlh - m2h 
mnj 
corresponds to the set of edges (υ,, 
vjt), (v2, v/2),..., 
(vn, vt ) . Each vk appears exactly twice in this set, once as 
a first element and once as a second element of some ordered pairs. This 
means that in the subgraph consisting of the edges (ι>,, 
), ( u
2 , v/2), 
..., 
(υη, υ ) the in-degree and the out-degree of each vertex are both equal to 1 . 
Thus each nonzero term in the sum in ( 6 . 2 5 ) corresponds to a 1-factor of G. 
Conversely, each 1-factor corresponds to a nonzero term mXj · m2j 

162 
MATRICES OF A GRAPH 
For example, the 1-factor in Fig. 6.116 corresponds to the term m 1 3-
m32 · m 2 1 · m 4 4. 
We now have to fix the sign of 
h 
^ . Let C be a directed circuit in the 
1-factor corresponding to /,, j
2 , . . ·, /„• Let C consist of the ω edges 
(υ,,, υ, 2), (u,2, υ,),..., 
(υ,ω, 
vit). 
The initial vertices of these edges form the array 
Ί> 
' 2 » • · · » ' < » > 
and their terminal vertices form the array 
i2, i 3 , . . . , ij . 
It is easy to show that ω - 1 interchanges are sufficient to rearrange the 
array i 2, i 3 , . . . ,i, as i,, i 2 , . . . , i a. 
Let there be L directed circuits in the 1-factor corresponding to 
in 
Ji> · • •' in- L
e t 
t
n
e lengths of these directed circuits be ω,, ω 2 , . . . , ω^. 
Then we need 
( ω , - 1 ) + (α> 2-1) + ··· + Κ - 1 ) = ΐ ν 
interchanges to rearrange 
j
2 , . . . , 
as 1,2,..., n. So, 
;„ = ( - i r = ( - l )
n 
+ 
t -
Thus summarizing: 
1. Each nonzero term mXh 
mn)^ corresponds to a 1-factor //, of G 
(note that the value of this term is 1). 
2. e 
, = (-l)
n+L' 
where L, is the number of directed circuits in H,. 
Ι\·)2·- 
·>η
 
V 
' 
' 
'
 
1 
Thus (6.25) reduces to 
ρ 
d e t M ^ - l ) " Σ (-I)
1 , 1 · 
• 
<-ι 
For example, consider the 1-factors of Fig. 6.11. The corresponding L,'s 
are 

THE COATES AND MASON GRAPHS 
163 
Thus the determinant of the adjacency matrix of the graph of Fig. 6.10 is 
( - 1 ) ' + ( - l )
2 = 0 . 
This may be verified by direct expansion of the determinant. 
Suppose in a directed graph G, each edge (i, j) is assigned a weight wir 
Then we may define the adjacency matrix Μ = [m ] of G as follows: 
_ Γ wtj , if there is an edge directed from vertex i to vertex / ; 
m
, i ~ {0 , 
otherwise . 
Let us define the weight product w(H) of a subgraph Η of G as the product 
of the weights of all the edges of H. If Η has no edges, that is, Η is empty, 
we define w(H) = 1. Then we can obtain the following as an easy extension 
of Theorem 6.26. 
Theorem 6.27. The determinant of the adjacency matrix Μ of an n-vertex 
weighted directed graph G is given by 
det Μ = (-1)" Σ 
(-l)
L"w(H) 
Η 
where Η is a 1-factor of G, and LH is the number of directed circuits in 
H. 
• 
6.11 
THE COATES AND MASON GRAPHS 
In this section we develop a graph-theoretic approach for the solution of 
linear algebraic equations. Two closely related methods due to Coates [6.10] 
and Mason [6.11] and [6.12] are discussed. 
6.11.1 
Coates' Method 
Consider a linear system described by the set of equations 
ΑΧ=ΒχΛ+1, 
(6.26) 
where A = [a,J is an η x η nonsingular matrix, A!" is a column vector of 
unknown variables xt,x2,... 
,x„, 
Β is a column vector of elements 
fc,, b2,..., 
bn, and xn+l 
is the input variable. We can solve for xk as 
Σ & A , 
x t ,
 
= 
iZdei~A~ 
· 
<
6'
27> 
where Δ,Α is the (i, k) cofactor of A. 

164 
MATRICES OF A GRAPH 
Let A' denote the matrix obtained from A by adding - β to the right of A 
and then adding a row of zeros at the bottom of the resulting matrix. Let us 
now associate with A' a weighted directed graph GC(A') as follows. 
GC(A') has η + 1 vertices x,, x 2 , . . . ,x„+l. 
If a / ( ^ 0 , then in GC(A') there 
is an edge directed from x, to xy with weight ajr Clearly A' is the transpose 
of the adjacency matrix of GC(A'). 
And GC(A') is called the Coates flow 
graph or simply the Coates graph associated with A'. We shall also refer to it 
as the Coates graph associated with the system of equations (6.26). 
As an example consider the set of equations: 
2 
1 
1 
1 
- 1 
- 2 
2 
1 
2 
The matrix A' in this case is 
A' = 
"1 •*R 
" 1" 
x 2 
— 
0 
-
.
x i . 
. - 1 . 
1 
1 - f 
- 1 
--2 
0 
1 
2 
1 
0 
0 
0. 
(6.28) 
2 
1 
2 
0 
The Coates graph GC(A') 
associated with the set of equations (6.28) is 
shown in Fig. 6.12a. 
Note that we may regard each vertex x,, 1 < i < n, of GC(A') as repre-
senting an equation in (6.26). For example, the ith equation in (6.26) can be 
obtained by equating to zero the sum of the products of weights of the edges 
directed into x, and the variables corresponding to the vertices from which 
these variables originate. Furthermore, the Coates graph GC(A) associated 
with A can be obtained by removing from GC(A') the vertex x n + 1 . The 
graph GC(A) in the case of (6.28) is shown in Fig. 6.126. 
Since A is the transpose of the adjacency matrix of GC(A) and since a 
matrix and its transpose have the same value of determinant, we get from 
Theorem 6.27 
det A = 
(-l)^(-l)
L"w(H), 
(6.29) 
where Η is a 1-factor in GC(A), w(H) is the weight product of H, and LH is 
the number of directed circuits in H. Thus we can evaluate the denominator 
of (6.27) in terms of the weight products of the 1-factors of GC(A). 
To 
derive a similar expression for the numerator of (6.27), we need to evaluate 
Δ„· 
A 1-factorial connection Ηη from x, to xt in GC(A) is a spanning subgraph 
of GC(A) that contains (a) a directed path Ρ from x, to x ; and (b) a set of 
vertex-disjoint directed circuits that include all the vertices of GC(A) except 
those contained in P. As an example, a 1-factorial connection from x 4 to x 2 
of the graph GC(A') of Fig. 6.12a is shown in Fig. 6.12c. 

THE COATES AND MASON GRAPHS 
165 
Figure 6.12. (a) The Coates graph 
GC(A')- W The graph GC(A)- (<0 A 
1-factorial connection HA2 
of the 
graph GC(A'). 

166 
MATRICES OF A GRAPH 
Theorem 6.28. Let GC(A) be the Coates graph associated with an η x η 
matrix A. Then: 
2. Δ , , ^ - ΐ Γ ^ ί - ι ^ Μ / / , , ) , 
ivy. 
where 
Η is a 1-factor in the graph obtained by removing vertex x, from 
GC(A), 
Ht) is a 1-factorial connection in GC(A) from vertex xf to vertex x y, and 
LH and 
are the numbers of directed circuits in Η and H,r respectively. 
Proof 
1. Follows from Theorem 6.27. 
2. Note that Δ,· is the determinant of the matrix obtained from A by 
replacing the y'th column of A by a column of zeros except for the 
element of the ith row, which is 1. Let the resulting matrix be denoted 
by Aa. 
Then the Coates graph Gc(Aa) 
is obtained from GC(A) by 
removing all the edges incident out of x ; (including self-loops at x y) 
and then adding an edge directed from x ; to x, with weight 1. Now 
from Theorem 6.27 we get 
A„ = det Aa 
= ( - 1 ) " Σ ( - 1 ) Ν ν ( # α ) , 
(6.30) 
"a 
where Ha is a 1-factor in Gc(Aa) 
and La is the number of directed 
circtuis in Ha. 
Each 1-factor Ha must necessarily contain the added edge with 
weight 1. Removing this edge from Ha we get a 1-factorial connection 
Ηη of GC(A). 
Furthermore, w(Ha) = w(Htl). 
We can also see that 
there is a one-to-one correspondence between Ha in Gc(Aa) 
and Hh in 
GC(A) such that w(Ha) = w(// i ;). Since the number of directed circuits 
in Hit is one less than that in Ha, we have L'H = La -1. So we get 
from (6.30) 
Δ ( ; = (-ΐ)"-'Σ(-ΐ)
ιΜ^)· 
• 
Consider now the term Σ",, 6,Δ ι λ, the numerator of (6.27). This term is 
equal to the determinant of the matrix obtained from A by replacing the /th 
column by B. We can easily relate this to detA'n+l 
k (where A'n + i
k is the 
matrix obtained by removing from A' the (n + l)th row and the kth column) 
as follows: 

THE COATES AND MASON GRAPHS 
167 
Σ ί - ι ^ Μ " ) 
Η 
for k = 1,2,..., n, where 
1. Hn+lk 
is a 1-factorial connection of GC(A') from vertex *„ + 1 to vertex 
xk, 
2. Η is a 1-factor of G c(/4), and 
3. 
and L H are the numbers of directed circuits in H„+lk 
and H, 
respectively. 
• 
Equation (6.34) is called Coates' gain formula. 
We now illustrate an 
application of this formula by solving (6.28) for 
x2lxA. 
The 1-factors of the graph GC(A) (Fig. 6.126) associated with the matrix 
A of (6.28) are given below along with their weight products. The different 
directed circuits in a 1-factor are distinguished by enclosing the vertices in 
each directed circuit within parentheses. 
1-Factor 
Weight Product 
( * i ) ( *
2 ) ( * 3 ) 
- 4 
(Xt)(x2,X3) 
- 4 
( * ; , ) ( * , , X 3 ) 
- 2 
(x3)(xux2) 
2 
( * 1 . * 3 > * 2 ) 
~
4 
Σ b A ,
k = ( - i y
n
+
i
) -
k - \ - l ) d c t ( A '
n
+
u
k ) . 
(6.31) 
1 = 1 
From part 2 of Theorem 6.28 we get 
( - l ) "
+ , + * d e t ( i C l i 4 ) = ( - l ) " 
Σ 
(-D
L"w(Hn 
+ u
k ) , 
(6.32) 
where L'H is the number of directed circuits in the 1-factorial connection 
Hn 
+ i.k of GC(A'). 
Combining (6.31) and (6.32), 
Σ & Α 4 = (-1)" 
Σ 
( - l )
L M / /
n 
+ 1 , J . 
(6.33) 
From (6.29) and (6.33) we get the following theorem. 
Theorem 6.29. If the coefficient matrix A is nonsingular, then the solution 
of (6.26) is given by 
Σ 
( - i )
l M W „
+ , , ) 
= ^ I L I 
( 6.34) 

168 
MATRICES OF A GRAPH 
From this we get the denominator in (6.34) as 
Σ (-l)
L"*(H) 
= (-l)
3(-4) + (-l)
2(-4) + (-l)
2(-2) 
+ (-l)
2(2) + (-l)(l) + (-l)(-4) 
= 4 - 4 - 2 + 2 - 1 + 4 
= 3 . 
The 1-factorial connections from x4 to x2 of GC(A') (Fig. 6.12«) are given 
below. The vertices that lie in a directed path are also now included within 
parentheses. 
1-Factorial Connection 
Weight Product 
(x4,xi,x2)(x}) 
- 2 
( * 4 >
 
x \ > * 3 > ^ 2 ) 
^ 
(x 4,* 3, x2)(xx) 
- 4 
( * 4 > * 3 > X\ > ^ 2 ) 
1 
From this we get the numerator of (6.34) as 
Σ 
(-l)
Li,w(Hn+i.k) 
= ( - 1 X - 2 ) + 4 + ( - 1 K - 4 ) + 1 
1
1 η + 1 ,lc 
= 2 + 4 + 4 + 1 
= 11 . 
Thus we get 
i2 = 11 
x4 
3 
6.11.2 
Mason's Method 
To develop Mason's method, first we rewrite (6.26) as 
η 
X i
 
= Κ
 
+ 
ι )
χ ί
 
= Σ α,*** - b,xn + i , 
j = 1,2,..., η 
k - 1 
We may write this in matrix form as follows: 
(A'+ Un+1)X'= 
X', 
where A' is the (n + 1) x (n + 1) matrix defined earlier, Un+l is the unit 
matrix of order n + 1, and X' is the column vector of variables 

THE COATES AND MASON GRAPHS 
169 
The Coates graph GC(A' + Un + l) is called Mason's signal flow graph or 
simply the Mason graph associated with the matrix A' and it is denoted by 
Gm(A'). 
For example, the Mason graphs Gm(A') 
and Gm(A) 
associated 
with the system of equations (6.28) are shown in Fig. 6.13. 
We may regard each vertex in Gm(A') 
as representing a variable. If there 
is a directed edge from vertex JC, to xjt then we may consider the variable x, 
as making a contribution of (a,,*,) to the variable xr So xt is equal to the 
sum of the products of the weights of the edges incident into vertex xj and 
the variables corresponding to the vertices from which these edges emanate. 
Thus the Mason graph is a convenient pictorial display of the flow of 
variables in a system. 
*1 
2 
(i>) 
Figure 6.13. (a) The Mason graph G
m ( A ' ) . 
(b) The graph 
G
m ( A ) . 

170 
MATRICES OF A GRAPH 
Note that to obtain the Coates graph from a given Mason graph, we 
simply subtract one from the weight of each self-loop, and for each vertex of 
a Mason graph without a self-loop we add one with weight - 1 . This is 
equivalent to saying that the Coates graph Gc can be obtained from a Mason 
graph Gm simply by adding a self-loop of weight - 1 at each vertex. The set 
of such self-loops of weight - 1 added to construct Gc will be denoted by 5. 
Note that the graph Gc so constructed will have at most two and at least one 
self-loop at each of its vertices. 
Consider now the Mason graph Gm(A) 
associated with a matrix A, and 
let Gc be the corresponding Coates graph. Let Η be a 1-factor of G c having / 
self-loops from the set S. Let LQ + / be the total number of directed circuits 
in H. On removing from Η the j added self-loops of the set S, we get a 
unique subgraph Q of Gm that is a collection of LQ vertex-disjoint directed 
circuits. Further, for / < n, 
w(H) = (-iyW(Q). 
(6.35) 
Note that if / = n, then Q is an empty subgraph of Gm which, by definition 
has weight w(Q) = 1. So, in such a case, 
w(//) = ( - i y . 
(6.36) 
We can also see that for each subgraph Q of Gm, which is a collection of LQ 
vertex-disjoint directed circuits, there corresponds a unique 1-factor of Gc 
that is obtained by adding self-loops (from the set 5) of weight - 1 to the 
vertices not in Q. 
From Theorem 6.27 we have 
detA = ( - l )
n E ( - l ) ' '
c + V ( / / ) 
Η 
= ( - l ) " [ l + Σ ( - 1 ) ^ ( 6 ) 1 · 
(6-37) 
Q
 
J 
The last step follows from (6.35) and (6.36). 
We may also rewrite (6.37) as 
det A = (-1)" [ l - Σ <2„ + Σ Ql2 ~ Σ Q,3 + • • ] 
(6.38) 
where Qjk 
is the weight product of the /th subgraph of Gm, which is a 
collection of k vertex-disjoint directed circuits. 
Thus we have expressed the denominator of (6.27) in terms of the weight 
products of appropriate subgraphs of the Mason graph. 
Let us refer to (-1)" det A as the determinant of the graph Gm(A) 
and 
denote it by Δ. Then using (6.33) and a reasoning exactly similar to that 

THE COATES AND MASON GRAPHS 
171 
1=1 
where P'„+Uk is the /'th directed path from x
n
+
l to xk in Gm(A), 
and Δ, is 
determinant of the subgraph of Gm(A'), 
which is vertex-disjoint from the /'th 
directed path P'„+ltk. 
Thus we get the following. 
Theorem 6.30. If the coefficient matrix A in (6.26) is nonsingular, then 
Σνν(Ρ; + Μ)Δ, 
T*- 
= -
i 
, 
k = l,2,...,n, 
(6.39) 
where P'„+1<k is the /'th directed path from x
n
+
} to x
k in Gm(A'), 
Δ ; is the 
determinant of the subgraph of Gm(A'), 
which is vertex-disjoint from the /'th 
directed path P'„+lk, 
and Δ is the determinant of the graph Gm(A). 
• 
Equation (6.39) is known as Mason's gain formula. In systems theory 
literature P'n+lk 
is referred to as a forward path from vertex x
n
+
l to vertex 
x k . Furthermore the directed circuits of Gm(A') 
are called the feedback 
loops. 
We now illustrate application of (6.39) by solving (6.28) for 
x2/x4. 
The different collections of vertex-disjoint directed circuits of Gm(A) 
(Fig. 6.136) and their weight products are 
Directed Circuit 
Weight Product 
CO 
3 
(x3) 
3 
(χλ,χ2) 
1 
(x2,x3) 
- 2 
(JC,,JC 3) 
2 
(x,,x 2, JC3) 
1 
C*l> * 3 > * 2 ) 
~4 
(*i)(* 3) 
9 
(Xi)(x2,X3) 
- 6 
( *
3 ) ( * 1 ' * 2 ) 
3 
From this we get the denominator in (6.39) as 
Δ = 1 - ( 3 + 3 + 1 - 2 + 2 + 1 - 4 ) + ( 9 - 6 + 3 ) 
= 3 . 
The different directed paths of Gm(A') 
(Fig. 6.13a) from x
A to x
2 along 
employed to derive (6.38), we can express the numerator of (6.27) as 
π 
E M „ = (-irE»v(p: + 1,jA ;, 

172 
MATRICES OF A GRAPH 
Δ, = 1 - 3 = - 2 , 
Δ 3 = 1 - 3 = - 2 . 
There are no directed circuits that are vertex-disjoint from P\2 and 
P\2. 
So 
Δ 2 = 1, 
Δ 4 = 1· 
Thus the numerator in (6.39) is 
< 2 Δ , + P\^2 
+ Ρΐ,2Δ3 
+ Ρΐ,2Δ< = 2 + 4 + 4 + 1 = 11 
So 
fa 
= 11 
XA 
3 
6.12 
FURTHER READING 
Seshu and Reed [6.13], Chen [6.2], Mayeda [6.14], and Deo [6.15] are other 
references for the topics covered in this chapter. Chen also gives historical 
details regarding the results presented here. 
The textbook by Harary and Palmer [6.16] is devoted exclusively to the 
study of enumeration problems in graph theory, in particular, to those 
related to unlabeled graphs. See also Biggs [6.17]. 
The problem of counting spanning trees has received considerable atten-
tion in electrical network theory literature. Recurrence relations for count-
ing spanning trees in special classes of graphs are available. For example, 
see Myers [6.18] and [6.19], Bedrosian [6.20], Bose, Feick, and Sun [6.21], 
and Swamy and Thulasiraman [6.22]. Berge [6.23] contains formulas for the 
with their weight products are 
j 
P'4a 
Weight Product 
1 
(xA,xl,x2) 
- 1 
2 
(x4, 
X j , x3, 
x2) 
4 
3 
(x4, 
x3, 
x2)
 
— 2 
4 
(x4, 
x$, 
X], 
x2j 
1 
The directed circuits, which are vertex-disjoint from P
l
42 
and P
3
4 2, are (x 3) 
and (JC,), respectively. So 

EXERCISES 
173 
number of spanning trees having certain specified properties. For algorithms 
to generate all the spanning trees of a connected graph see Gabow and 
Myers [6.24] and Jayakumar, Thulasiraman, and Swamy [6.25] and [6.26]. 
Chen [6.2] gives an extensive discussion of several aspects concerning the 
signal flow graph approach. See Robichaud, Boisvert, and Robert [6.27] for 
several applications of signal flow graphs. Balabanian and Bickart [6.28] 
may be consulted for the application of signal flow graphs in the study of 
electrical networks. 
An algorithm due to Rao [6.29] to construct graphs having specified 
circuit and cutset matrices is discussed in [6.30]. See also Cederbaum [6.31], 
Boesch and Youla [6.32], and Kim and Chien [6.33]. 
Swamy and Thulasiraman [6.30] give a detailed discussion of applications 
of graphs in electrical network theory. 
6.13 
EXERCISES 
6.1 
Let Qf - [qtJ] be a fundamental cutset matrix and Bf = [btl] be a 
fundamental circuit matrix of a connected directed graph. Prove the 
following: 
(a) If the products (q,jqk)) 
and (qirqkr) 
are both nonzero, then they 
are equal. 
(b) Repeat (a) for Bf. 
6.2 
Let β be a matrix formed by any μ(β) 
independent rows of the 
circuit matrix of a connected directed graph G having m edges. Show 
that if F is any matrix of order p(G) x m and of rank p(G), having 
entries 1 , - 1 , and 0 and satisfying BF' = 0, then each row of F is a 
row of the cut matrix of G. 
6.3 
Let β be a matrix formed by any p(G) independent rows of the cut 
matrix of a connected directed graph G having m edges. Show that if 
F is any matrix of order p.(G) x m and of rank μ ( ΰ ) , having entries 
1 , - 1 , and 0 and satisfying QF' = 0, then each row of F corresponds 
to a circuit or an edge-disjoint union of circuits of G. 
6.4 
Let Q(x, y) be the submatrix of the cut matrix Qc of a connected 
nonseparable directed graph G containing only those rows of Qc that 
correspond to cuts separating vertices χ and y. Show that Q(x, y) 
contains a fundamental cutset matrix of G. (See Kajitani and Ueno 
[6.34] for a more general result.) 
6.5 
Let β be a submatrix of the circuit matrix Bc of a planar graph G 
containing only those rows of Bc that correspond to the meshes of G. 
Show that Β is unimodular. (See Chapter 7 for the definition of a 
planar graph.) 

174 
MATRICES OF A GRAPH 
is nonsingular. 
6.10 Prove that the circuit and cutset subspaces Wc and Ws over GF(2) of 
a connected undirected graph G are orthogonal complements of the 
vector space WG if and only if the number of spanning trees of G is 
odd. 
6.11 For any edge e of a graph G, let G · e denote the graph obtained from 
G by contracting the edge e. If G is connected, show that 
T ( G ) = T ( G - e) + T ( G · e). 
6.12 Use the recursion formula in Exercise 6.11 to find the number of 
spanning trees in a wheel on η vertices. (See Section 8.4 for the 
definition of a wheel.) 
6.13 Show that if e is an edge of K„, then 
r(Kn-e) 
= (n-2)n"-
3 
. 
6.14 (a) Let Η be an Η-vertex graph in which there are k parallel edges 
between every pair of adjacent vertices and let G be the underly-
ing simple graph of H. Show that 
T(H) = r~V(G). 
(b) Let Η be the graph obtained from an π-vertex connected graph G 
6.6 
Let β be a matrix formed by any /i(G) independent rows of the 
circuit matrix of a connected directed graph G. Show that the 
determinants of all the major nonsingular submatrices of Β have the 
same magnitude. 
6.7 
Prove Theorem 4.11. 
6.8 
Prove that for a connected directed graph G 
T(G) = det(B /B' /) = d e t ( g / G ' / ) , 
where Bf is a fundamental circuit matrix and Qf is a fundamental 
cutset matrix of G. 
6.9 
Let β be a matrix formed by any p(G) independent rows of the cut 
matrix of a connected directed graph G, and let β be a matrix formed 
by any p(G) independent rows of the circuit matrix of G. Show that 

EXERCISES 
175 
when each edge of G is replaced by a path of length k. Show that 
τ(Η) = k! 
. m - n + l 
T ( G ) , 
where m is the number of edges in G. 
6.15 
Establish Theorem 6.17 as a special case of Theorem 6.24. 
6.16 
A graph G with weights associated with its edges is called a weighted 
graph. Recall that the weight product of a subgraph of G is equal to 
the product of the weights of the edges of the subgraph and that if the 
subgraph has only isolated vertices, then its weight product is defined 
to be 1. 
Let A be the incidence matrix of a connected directed graph G, 
with vertex v„ as reference. Assume that the ith row of A corresponds 
to vertex υ,·. Let W be the diagonal matrix representing the weights of 
G and assume that the columns of A and W are arranged in the same 
edge order. Prove that 
(a) det(AWA') 
= sum of the weight products of all the spanning trees 
of G. 
(b) Δ ι ; = sum of the weight products of all the spanning 2-trees Ttj 
n 
of G, where Δ ί ; is the (/, j) cofactor of AWA'. 
6.17 The out-degree matrix Κ = [ktj\ 
of a directed graph G with no 
self-loops is defined as follows: 
Also define an in-going directed tree as a directed graph that has a 
vertex vr to which there is a directed path from every other vertex, 
and its underlying undirected graph is a tree. Show that the number 
of in-going spanning directed trees of a graph G can be computed in a 
way similar to Theorem 6.24. 
6.18 The out-degree matrix Κ = [Α;(;] of a weighted directed graph G 
without self-loops is defined as follows: 
(a) ktj = -(sum of the weights of the edges directed from υ, to Vj), 
(b) A:,, = sum of the weights of the edges incident out of υ,. 
Prove that det(AT„) is the sum of the weight products of all the 
in-going spanning directed trees of G having v, as root. 
(Note: Here by a root we mean a vertex v, such that there is a 
directed path to u, from every other vertex.) 
if i Φ j and there are ρ parallel edges directed 
from υ, to vt ; 

176 
MATRICES OF A GRAPH 
6.19 
Solve the following system of equations: 
" 3 - 2 
1" "*Γ " 3" 
- 1 
2 0 
x2 
= 
1 
. 3 - 2 
2. 
*3. 
. - 2 . 
6.20 Let G m be the Mason graph associated with a system of linear 
equations. Prove the following: 
(a) We can remove the self-loop of weight akk Φ 1 at vertex xk simply 
by multiplying the weight of every edge incident into xk by the 
factor 1/(1 - 
akk). 
(b) We can remove a vertex xp with no self-loop by doing the 
following: For all ϊΦρ and k^p, 
add (apiakp) 
to the weight of 
the edge (xt, 
xk). 
6.21 Using the method in Exercise 6.20, reduce the Mason graph associ-
ated with (6.40) to a graph containing only the vertices xA and x2 and 
solve for 
x2/xA. 
6.14 
REFERENCES 
6.1 
F. E. Hohn, Elementary Matrix Algebra, Macmillan, New York, 1958. 
6.2 
W. K. Chen, Applied Graph Theory, North-Holland, Amsterdam, 1971. 
6.3 
G. Kirchhoff, "Uber die Auftosung der Gleichungen, auf welche man bei der 
Untersuchung der linearen Verteilung galvanischer Strome gefiihrt wird," 
Ann. Phys. Chem., Vol. 72, 497-508 (1847). 
6.4 
A. Cayley, "A Theorem on Trees," Quart. J. Math., Vol. 23, 376-378 (1889). 
6.5 
J. W. Moon, "Various Proofs of Cayley's Formula for Counting Trees," in A 
Seminar on Graph Theory, F. Harary and L. W. Beinke, Eds., Holt, Rinehart 
and Winston, New York, 1967, pp. 70-78. 
6.6 
H. Priifer, "Neuer Beweis eines Satzes uber Permutationen," Arch. Math. 
Phys., Vol. 27, 742-744 (1918). 
6.7 
K. Sankara Rao, V. V. Bapeswara Rao, and V. G. K. Murti, "Two-Tree 
Admittance Products," Electron. Lett., Vol. 6, 834-835 (1970). 
6.8 
W. T. Tutte, "The Dissection of Equilateral Triangles into Equilateral Tri-
angles," Proc. Cambridge Phil. Soc, Vol. 44, 203-217 (1948). 
6.9 
F. Harary, "The Determinant of the Adjacency Matrix of a Graph," SIAM 
Rev., Vol. 4, 202-210 (1962). 
6.10 C. L. Coates, "Flow-Graph Solutions of Linear Algebraic Equations," IRE 
Trans. Circuit Theory, Vol. CT-6, 170-187 (1959). 
6.11 S. J. Mason, "Feedback Theory: Some Properties of Signal Flow Graphs," 
Proc. IRE., Vol. 41, 1144-1156 (1953). 

REFERENCES 
177 
6.12 S. J. Mason, "Feedback Theory: Further Properties of Signal Flow Graphs," 
Proc. IRE., Vol. 44, 920-926 (1956). 
6.13 S. Seshu and Μ. B. Reed, Linear Graphs and Electrical Networks, Addison-
Wesley, Reading, Mass., 1961. 
6.14 W. Mayeda, Graph Theory, Wiley-Interscience, New York, 1972. 
6.15 N. Deo, Graph Theory with Applications to Engineering and Computer 
Science, Prentice-Hall, Englewood Cliffs, N.J., 1974. 
6.16 F. Harary and Ε. M. Palmer, Graphical Enumeration, Academic Press, New 
York, 1973. 
6.17 N. Biggs, Algebraic Graph Theory, Cambridge University Press, Cambridge, 
England, 1974. 
6.18 B. R. Myers, "Number of Trees in a Cascade of 2-Port Networks," IEEE 
Trans. Circuit Theory, Vol. CT-14, 284-290 (1967). 
6.19 B. R. Myers, "Number of Spanning Trees in a Wheel," IEEE Trans. Circuit 
Theory, Vol. CT-18, 280-282 (1971). 
6.20 S. D. Bedrosian, "Number of Spanning Trees in Multigraph Wheels," IEEE 
Trans. Circuit Theory, Vol. CT-19, 77-78 (1972). 
6.21 Ν. K. Bose, R. Feick, and F. K. Sun, "General Solution to the Spanning Tree 
Enumeration Problem in Multigraph Wheels," IEEE Trans. Circuit Theory, 
Vol. CT-20, 69-70 (1973). 
6.22 Μ. N. S. Swamy and K. Thulasiraman, "A Theorem in the Theory of 
Determinants and the Number of Spanning Trees of a Graph," Proc. IEEE 
Int. Symp. on Circuits and Systems, 153-156 (1976). 
6.23 C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
6.24 Η. N. Gabow and E. W. Myers, "Finding all Spanning Trees of Directed and 
Undirected Graphs," SI AM J. Comp., Vol. 7, 280-287 (1978). 
6.25 R. Jayakumar, K. Thulasiraman, and Μ. N. S. Swamy, "Complexity of 
Computation of a Spanning Tree Enumeration Algorithm," IEEE Trans. 
Circuits and Systems, Vol. CAS-31, 853-860 (1984). 
6.26 R. Jayakumar, K. Thulasiraman, and Μ. N. S. Swamy, "MOD-CHAR: An 
Implementation of Char's Spanning Tree Enumeration Algorithm and Its 
Complexity Analysis," IEEE Trans. Circuits and Systems, Vol. CAS-36, 
219-228 (1989). 
6.27 L. P. A. Robichaud, M. Boisvert, and J. Robert, Signal Flow Graphs and 
Applications, Prentice-Hall, Englewood Cliffs, N.J., 1962. 
6.28 N. Balabanian and T. A. Bickart, Electrical Network Theory, Wiley, New 
York, 1969. 
6.29 V. V. Bapeswara Rao, "The Tree-Path Matrix of a Network and Its Applica-
tions," Ph.D. Thesis, Dept. of Electrical Engineering, Indian Institute of 
Technology, Madras, India, 1970. 
6.30 Μ. N. S. Swamy and K. Thulasiraman, Graphs, Networks and Algorithms, 
Wiley-Interscience, 1981. 
6.31 I. Cederbaum, "Applications of Matrix Algebra to Network Theory," IRE 
Trans. Circuit Theory, (Special supplement), Vol. CT-6, 127-137 (1959). 

178 
MATRICES OF A GRAPH 
6.32 F. T. Boesch and D. C. Youla, "Synthesis of (n + l)-Node Resistor n-Ports," 
IEEE Trans. Circuit Theory, Vol. CT-12, 515-520 (1965). 
6.33 W. H. Kim and R. T. Chien, Topological Analysis and Synthesis of Communi-
cation Nets, Columbia University Press, New York, 1962. 
6.34 Y. Kajitani and S. Ueno, "On the Rank of Certain Classes of Cutsets and 
Tie-Sets of a Graph," IEEE Trans. Circuits and Sys., Vol. CAS-26, 666-668 
(1979). 

CHAPTER 7 
PLANARITY AND DUALITY 
In this chapter we discuss two important concepts in graph theory, namely, 
planarity and duality. First we consider planar graphs and derive some 
properties of these graphs. Characterizations of planar graphs due to 
Kuratowski, Wagner, Harary and Tutte and MacLane are also discussed. 
We then discuss Whitney's definition of duality of graphs, which is given in 
terms of circuits and cutsets, and relate this concept to the seemingly 
unrelated concept of planarity. 
Duality has been of considerable interest to electrical network theorists. 
This interest is due to the fact that the voltages and currents in an electrical 
network are dual variables. Duality of these variables arises as a result of 
Kirchhoff s laws. Kirchhoff s voltage law is in terms of circuits and Kirch-
hoff s current law is in terms of cutsets. Duality between circuits and cutsets 
was observed in Chapters 2 and 4. This duality will become obvious in 
Chapter 10, where we show that the set of circuits and the set of cutsets of a 
graph have the same algebraic structure. 
7.1 
PLANAR GRAPHS 
A graph G is said to be embeddable on a surface 5 if it can be drawn on S so 
that its edges intersect only at their end vertices. A graph is said to be planar 
if it can be embedded on a plane. Such a drawing of a planar graph G is 
called a planar embedding of G. 
Two planar embeddings of a graph are shown in Fig. 7.1. In one of these 
(Fig. 7.1e) all the edges are drawn as straight-line segments, while in the 
other (Fig. l.\b) 
one of the edges is drawn as a curved line. Note that the 
179 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

Figure 7.1. Two planar embeddings of a graph. 
(M 
edge connecting vertices a and d in Fig. 7.16 cannot be drawn as a straight 
line if all the remaining edges are drawn as shown. 
Obviously, if a graph has self-loops or parallel edges, then in none of its 
planar embeddings all the edges can be drawn as straight-line segments. This 
naturally raises the question whether for every simple planar graph G there 
exists a planar embedding in which all the edges of G can be drawn as 
straight-line segments. The answer to this question is in the affirmative, as 
stated in the following theorem. 
Theorem 7.1. For every simple planar graph there exists a planar embed-
ding in which all the edges of the graph can be drawn as straight-line 
segments. 
• 
 
PLANARITY AND DUALITY 

PLANAR GRAPHS 
181 
This result was proved independently by Wagner [7.1], Fary [7.2], and 
Stein [7.3]. 
If a graph is not embeddable on a plane, then it may be embeddable on 
some other surface. However, we now show that embeddability on a plane 
and embeddability on a sphere are equivalent; that is, if a graph is 
embeddable on a plane, then it is also embeddable on a sphere and vice 
versa. The proof of this result uses what is called the stereographic projec-
tion of a sphere onto a plane, which is described below. 
Suppose that we place a sphere on a plane (Fig. 7.2) and call the point of 
contact the south pole and the diametrically opposite point on the sphere 
the north pole N. Let Ρ be any point on the sphere. Then the point P' at 
which the straight line joining Ν and P, when extended, meets the plane, is 
called the stereographic projection of Ρ onto the plane. It is clear that there 
is a one-to-one correspondence between the points on a sphere and their 
stereographic projections on the plane. 
Theorem 7.2. A graph G is embeddable on a plane if and only if G is 
embeddable on a sphere. 
Proof. Let G' be an embedding of G on a sphere. Place the sphere on the 
plane so that the north pole is neither a vertex of G' nor a point on an edge 
of G'. 
/v 
Figure 7.2. Stereographic projection. 

182 
PLANARITY AND DUALITY 
(<) 
Figure 7.3. Basic nonplanar graphs, (a) K} 
(b) K S J. 
Then the image of G' under the stereographic projection is an embedding 
of G on the plane because edges of G' intersect only at their end vertices 
and there is a one-to-one correspondence between points on the sphere and 
their images under stereographic projection. 
The converse is proved similarly. 
• 
Two basic nonplanar graphs called Kuratowski's graphs are shown in Fig. 
7.3. One of these is K5, the complete graph on five vertices, and the other is 
AT33. We call these graphs basic nonplanar graphs because they play a 
fundamental role in an important characterization of planarity due to 
Kuratowski (Section 7.3). The nonplanarity of these two graphs is estab-
lished in the next section. 
Before we conclude this section, we would like to point out that Whitney 
[7.4] has proved that a separable graph is planar if and only if its blocks are 
planar. So while considering questions relating to the embedding on a plane, 
it is enough if we concern ourselves with only nonseparable graphs. 
7.2 
EULER'S FORMULA 
An embedding of a planar graph on a plane divides the plane into regions. 
A region is finite if the area it encloses is finite; otherwise it is infinite. 
For example, in the planar graph shown in Fig. 7.4, the hatched region f5 
is the infinite region; /,, / 2, / 3, and f4 are the finite regions. 
Clearly, the edges on the boundary of a region contain exactly one 
circuit, and this circuit is said to enclose the region. For example, the edges 

EULER'S FORMULA 
183 
Figure 7.4 
ex, e8, e9, e 1 0, and e u form the region /, in the graph of Fig. 7.4, and they 
contain the circuit {e,, e g, eg, 
e10). 
Note that in any spherical embedding of a planar graph, every region is 
finite. 
Suppose we embed a planar graph on a sphere and place the sphere on a 
plane so that the north pole is inside any chosen region, say, region /. Then 
under the stereographic projection the image of/will be the infinite region. 
Thus a planar graph can always be embedded on a plane so that any chosen 
region becomes the infinite region. 
Let /ι» Λ» · · •' fr
 D e 
t
n
e regions of a planar graph with fr as the infinite 
region. We denote by C,, 1 ^ i: :£ r, the circuit on the boundary of region/,. 
The circuits C,, C 2 , . . . , C r_,, corresponding to the finite regions, are 
called meshes. 
It is easy to verify that the ring sum of any k^2 
meshes, say, C,, 
C2,...,Ck, 
is a circuit or union of edge-disjoint circuits enclosing the 
regions /,, / 2 , . . . , fk. Since each mesh encloses only one region, it follows 
that no mesh can be obtained as the ring sum of some of the remaining 
meshes. Thus the meshes C,, C 2 , . . . , Cr_l are linearly independent. 
Suppose that any element C of the circuit subspace of G encloses the 
finite regions /,, / 2 , . . . , fk. Then it can be verified that 
C — 
φ C 2 φ ' ' * Φ Ck. 

184 
PLANARITY AND DUALITY 
For example, in the graph of Fig. 7.4, the set C = {e,, e2, e3, e4, e5, e6, 
e 7, es) encloses the regions /,, f2, /3, f4. Therefore, 
C
 = Cj Φ C 2 Φ C3 Φ C4. 
Thus every element of the circuit subspace of G can be expressed as the 
ring sum of some or all of the meshes of G. Since the meshes are themselves 
independent, we get the following theorem. 
Theorem 7.3. The meshes of a planar graph G form a basis of the circuit 
subspace of G. 
• 
Following is an immediate consequence of this theorem. 
Corollary 7.3.1 (Euler's Formula). If a connected planar graph G has m 
edges, η vertices, and r regions, then 
η - m + r = 2 . 
Proof. The proof follows if we note that by Theorem 7.3, the nullity μ of G 
is equal to r - 1. 
• 
In general it is difficult to test whether a graph is planar or not. We now 
use Euler's formula to derive some properties of planar graphs. These 
properties can be of help in detecting nonplanarity in certain cases, as we 
shall see soon. 
Corollary 7.3.2. If a connected simple planar graph G has m edges and 
> 3 
vertices, then 
m < 3n - 6 . 
Proof. Let F= {f, f2,..., 
fr} denote the set of regions of G. 
Let the degree d(f) 
of region f denote the number of edges on the 
boundary of 
bridges
1 being counted twice. (For example, in the graph of 
Fig. 7.4, the degree of region /, is 6.) Noting the similarity between the 
definitions of the degree of a vertex and the degree of a region, we get from 
Theorem 1.1, 
Σ <*(/,) = 2m. 
Since G has neither parallel edges nor self-loops and η s: 3, it follows that 
'For the definition of bridge, see Exercise 1.28. 

EULER'S FORMULA 
185 
d ( / , ) > 3 , for all i. Hence 
Σ «/(/,) &3r. 
Thus 2m > 3r, that is, 
r < | m . 
Using this inequality in Euler's formula, we get 
η - m + \m > 2 
or 
m < 3n - 6 . 
• 
Corollary 7.3.3. Ks is nonplanar. 
Proof. For K5, n = 5 and m = 10. If it were planar, then by Corollary 7.3.2, 
m = 1 0 < 3 n - 6 = 9; 
a contradiction. Thus K5 must be nonplanar. 
• 
Corollary 7.3.4. K33 is nonplanar. 
Proof. For K3 3, m = 9 and η = 6. If it were planar, then by Euler's formula 
it has r = 9 - 6 + 2 = 5 regions. 
In K3 3 there is no circuit of length less than 4. Hence the degree of every 
region is at least 4. Thus, 
r 
2m = Σ 
d(f,)si4r 
ι = 1 
or 
2m 
r s — 
4 ' 
that is, r < 4 ; a contradiction. Hence K33 is nonplanar. 
• 
Corollary 7.3.5. In a simple planar graph G there is at least one vertex of 
degree less than or equal to 5. 
Proof. Let G have m edges and η vertices. If every vertex of G has degree 

186 
PLANARITY AND DUALITY 
greater than 5, then by Theorem 1.1, 
2 m > 6 n 
or 
w > 3« . 
But by Corollary 7.3.2, 
m s 3 n - 6 . 
These two inequalities contradict one another. Hence the result. 
• 
7.3 
KURATOWSKI'S THEOREM AND OTHER 
CHARACTERIZATIONS OF PLANARITY 
Characterizations of planarity given by Kuratowski, Wagner, Harary and 
Tutte and MacLane are presented in this section. 
To explain Kuratowski's characterization, we need the definition of the 
concept of homeomorphism between graphs. 
The two edges incident on a vertex of degree 2 are called series edges. 
Let ex = (u, v) and e2 = (v, w) be the series edges incident on a vertex v. 
Removal of vertex ν and replacing ex and e2 by a simple edge («, w) is called 
series merger (Fig. 7.5a). 
Adding a new vertex υ on an edge (u, w), thereby creating the edges 
(u, υ) and (v, w), is called series insertion (Fig. 7.5b). 
Two graphs are said to be homeomorphic if they are isomorphic or can be 
made isomorphic by repeated series insertions and/or mergers. 
It is clear that if a graph G is planar, then any graph homeomorphic to G 
is also planar, that is, planarity of a graph is not affected by series insertions 
or mergers. 
We proved in the previous section that K5 and K33 
are nonplanar. 
Therefore, a planar graph does not contain a subgraph homeomorphic to K5 
or KJ3. 
It is remarkable that Kuratowski [7.5] could prove that the converse 
of this result is also true. In the following theorem, we state this celebrated 
characterization of planarity. Proof of this may also be found in Harary 
[7.6]. 
Theorem 7.4 (Kuratowski). A graph is planar if and only if it does not 
contain a subgraph homeomorphic to K5 or K3 3. 
• 
See also Tutte [7.7] for a constructive proof of this theorem. 
As an illustration of Kuratowski's theorem, consider the graph G shown 

KURATOWSKI'S THEOREM AND OTHER CHARACTERIZATIONS OF PLANARITY 
1 8 7 
6u> 
(a) 
Figure 7.5. (a) Series merger, (ft) Series 
Figure 7.6. (a) Graph G. (b) Subgraph 
insertion. 
of G homeomorphic to K3 3. 
in Fig. 7.6a. It contains a subgraph (Fig. 7.6ft) that is homeomorphic to 
K3 3. Therefore G is nonplanar. 
We now present another characterization of planarity independently 
proved by Wagner [7.8] and by Harary and Tutte [7.9]. 
Theorem 7.5. A graph is planar if and only if it does not contain a subgraph 
contractible to K5 or Ki3. 
■ 
Consider now the graph (known as the Petersen graph) shown in Fig. 7.7. 
This graph does not contain any subgraph isomorphic to K5 oi Ki3, but it is 
known to be nonplanar. So if we wish to use Kuratowski's criterion to 

188 
PLANARITY AND DUALITY 
Figure 7.7. The Petersen graph. 
establish the nonplanar character of the Petersen graph, then we need to 
locate a subgraph homeomorphic to K5 or K33. 
However, the nonplanarity 
of the graph follows easily from Theorem 7.5 because the graph reduces to 
K5 after contracting the edges et, e2, e3, e 4, and e5. 
MacLane's characterization of planar graphs is stated next. 
Theorem 7.6. A graph G is planar if and only if there exists in G a set of 
basis circuits such that no edge appears in more than two of these 
circuits. 
• 
We know that the meshes of a planar graph form a basis of the circuit 
subspace of the graph, and that no edge of the graph appears in more than 
two of the meshes. This proves the necessity of Theorem 7.6. The proof of 
the sufficiency may be found in MacLane [7.10]. 
Another important characterization of planar graphs in terms of the 
existence of dual graphs is discussed in Section 7.5. 
7.4 
DUAL GRAPHS 
A graph G 2 is a dual of a graph G, if there is a one-to-one correspondence 
between the edges of G2 and those of G, such that a set of edges in G 2 is a 
circuit vector of G 2 if and only if the corresponding set of edges in G, is a 
cutset vector of G r Duals were first defined by Whitney [7.11], though his 
original definition was given in a different form. 
Clearly, to prove that G 2 is a dual of G, it is enough if we show that the 
vectors forming a basis of the circuit subspace of G 2 correspond to the 
vectors forming a basis of the cutset subspace of G,. 
For example, consider the graphs G, and G2 shown in Fig. 7.8. The edge 
e, of G, corresponds to the edge e* of G 2. It may be verified that the circuits 
{e,, e2, e3}, {e3, eA, e5, e6), and {e 6, e 7, e 8} form a basis of the circuit 

DUAL GRAPHS 
189 
subspace of G,, and the corresponding sets of edges {e*, e*, e*}, {e*, e*, 
e*, el}, and {e*, e*, el} form a basis of the cutset subspace of G 2. Thus G 2 
is a dual of G,. 
We now study some properties of the duals of a graph. 
Theorem 7.7. Let G 2 be a dual of a graph G,. Then a circuit in G 2 
corresponds to a cutset in G, and vice versa. 
Proof. Let C* be a circuit in G 2 and C be the corresponding set of edges in 
G,. 
Suppose that C is not a cutset. Then it follows from the definition of a 
dual that C must be the union of disjoint cutsets C,, C 2 , . . . , Ck, k s 2 . 
Let C*, C * , . . . , Ck be the sets of edges in G 2 that correspond to the 
cutsets Cj, C 2 , . . . , Ck. Again from the definition of a dual it follows that 
Cj*, C * , . . . , C* are circuits or unions of disjoint circuits. 
Since C* is the union of Cj*, C*,..., 
C*, k ^ 2, it is clear that C* must 
contain more than one circuit. However, this is not possible since C* is a 
circuit, and no proper subset of a circuit is a circuit. Thus k = 1, or in other 
words, C is a cutset of G,. 
In a similar way we can show that each cutset in G, corresponds to a 
circuit in G 2. 
• 
Theorem 7.8. If G 2 is a dual of G,, then G, is a dual of G 2. 
Proof. To prove the theorem we need to show that each circuit vector of G, 
corresponds to a cutset vector of G 2 and vice versa. 
Let C be a circuit vector in Gj, with C* denoting the corresponding set of 
edges in G 2. 
By Theorem 4.7, C has an even number of common edges with every 
cutset vector of G,. Since G 2 is a dual of G,, C* has an even number of 
common edges with every circuit vector of G 2. Therefore, by Theorem 4.8, 
C* is a cutset vector of G 2. 
In a similar way we can show that each cutset vector of G 2 corresponds to 
a circuit vector of G,. Hence the theorem. 
• 
In view of Theorem 7.8, we refer to graphs Gx and G 2 as simply duals if 
one of them is dual of the other. 
The following result is a consequence of Theorem 7.8 and the definition 
of a dual. 
Theorem 7.9. If G t and G 2 are dual graphs, then the rank of one is equal to 
the nullity of the other; that is, 
p(G,) = / 1(G 2) 

190 
PLANARITY AND DUALITY 
Corollary 7.10.2. If a graph G has a dual, then every graph homeomorphic 
to G also has a dual. 
• 
and 
p(G 2) = M ( G I ) . 
• 
Suppose a graph G has a dual. Then the question arises whether every 
subgraph of G has a dual. To answer this question we need the following 
result. 
Theorem 7.10. Consider two dual graphs G, and G 2. Let e = (i>,, v2) be an 
edge in G,, and e* = (ν*, u*) be the corresponding edge in G 2. Let G\ be 
the graph obtained by removing the edge e from G,; let G'2 be the graph 
obtained by contracting e* in G 2. Then Gj and G 2 are duals, the one-to-one 
correspondence between their edges being the same as in G, and G 2. 
Proof. Let C and C* denote corresponding sets of edges in G, and G 2, 
respectively. 
Suppose C is a circuit in G J. Since it does not contain e, it is also a circuit 
in G P Hence C* is a cutset, say (V*,Vb), 
in G 2. Since C* does not 
contain e*, the vertices v* and u* are both in V* or in Vb. Therefore C* is 
also a cutset in G 2. Thus every circuit in Gj corresponds to a cutset in G'2. 
Suppose C* is a cutset in G 2. Since C* does not contain e*, it is also a 
cutset in G 2. Hence C is a circuit in Gp Since it does not contain e, it is also 
a circuit in G[. Thus every cutset in G'2 corresponds to a circuit in G\. 
• 
In view of this theorem, we may say, using the language of electrical 
network theory, that "open-circuiting" an edge in a graph G corresponds to 
"short-circuiting" the corresponding edge in a dual of G. 
A useful corollary of Theorem 7.10 now follows. 
Corollary 7.10.1. If a graph G has a dual, then every edge-induced subgraph 
of G also has a dual. 
Proof. The result follows from Theorem 7.10, if we note that every 
edge-induced subgraph Η of G can be obtained by removing from G the 
edges not in H. 
• 
To illustrate Corollary 7.10.1, consider the two dual graphs Gx and G 2 of 
Fig. 7.8. The graph Gj shown in Fig. 7.9a is obtained by removing from G, 
the edges e3 and e6. The graph G'2 of Fig. 7.9b is obtained by contracting the 
edges e* and e* of G 2. It may be verified that Gj and G'2 are duals. 
Observing that series edges in a graph G correspond to parallel edges in a 
dual of G, we get the following corollary of Theorem 7.10. 

DUAL GRAPHS 
191 
Figure 7.8. Dual graphs, (a) Graph G,. 
Figure 7.9. Dual graphs, (a) Graph G[. 
(b) Graph G2. 
(b) Graph G'2. 
We now proceed to develop an equivalent characterization of a dual. 
Let G be an η-vertex graph. We may assume without loss of generality 
that it is connected. Let K* be a subgraph of G, and let G' be the graph 
obtained by contracting the edges of K*. Note that G' is also connected. 
If K* has n* vertices and ρ connected components, then G' will have 
η - (η* - ρ) vertices. Therefore, the rank of G' is given by 
p(G') = « - ( « * - / , ) - ! 
= 
p(G)-p(K*). 
(7.1) 

192 
PLANARITY AND DUALITY 
p(H) = 
p(,G2)-p(K*) 
Theorem 7.11. Let G, and G 2 be two graphs with a one-to-one correspond-
ence between their edges. Let Η be any subgraph of G, and H* the 
corresponding subgraph in G 2. Let K* be the complement of H* in G 2. 
Then G, and G 2 are dual graphs if and only if 
μ(Η) = ρ(β2)-ρ(Κ·). 
(7.2) 
Proof 
Necessity 
Let G, and G 2 be dual graphs. Let G 2 be the graph obtained 
from G 2 by contracting the edges of K*. Then by Theorem 7.10, Η and G 2 
are dual graphs. Therefore, by Theorem 7.9, 
M ( J / ) = P ( G ; ) . 
But by (7.1), 
p(G'2) = 
p(G2)-p(K*). 
Hence 
p(H) = 
p(G2)-p(K*). 
Sufficiency 
Assume that (7.2) is satisfied for every subgraph Η of 
Gv 
We now show that each circuit in G T corresponds to a cutset in G 2 and vice 
versa. 
Let Η be a circuit in G,. Then μ(Η) = 1. Therefore by (7.2), 
p(K*) = p ( G
2 ) - l . 
Since Η is a minimal subgraph of G with nullity equal to 1, and AT* is the 
complement of H* in G 2, it is clear that K* is a maximal subgraph of G 2 
with rank equal to p(G2) - 1. It now follows from the definition of a cutset 
that H* is a cutset in G2. 
In a similar way we can show that a cutset in G 2 corresponds to a circuit 
in G,. 
Thus G, and G 2 are dual graphs. 
• 
Whitney's [7.11] original definition of duality was stated as in Theorem 
7.11. 
To illustrate this definition, consider the dual graphs G, and G 2 of Fig. 
7.8. A subgraph Η of G, and the complement K* of the corresponding 
subgraph in G 2 are shown in Fig. 7.10. We may now verify that 

PLANARITY AND DUALITY 
193 
Figure 7.10. Illustration of Whitney's definition 
of duality, (a) Graph Η, μ(Η) = \. (b) Graph 
K*, p(K*) = 2. 
7.5 
PLANARITY AND DUALITY 
In this section we characterize the class of graphs that have duals. While 
doing so, we relate the two seemingly unrelated concepts, planarity and 
duality. 
First we prove that every planar graph has a dual. The proof is based on a 
procedure for constructing a dual of a given planar graph. 
Consider a planar graph and let G be a planar embedding of this graph. 
Let / j , f2,---,fr 
be the regions of G. Construct a graph G* defined as 
follows: 
1. G* has r vertices υ*, v*,... 
,v*, vertex ν*, 1 s / < r, corresponding 
to region /,. 
2. G* has as many edges as G has. 
3. If an edge e of G is common to the regions f{ and / y (not necessarily 
distinct), then the corresponding edge e* in G* connects vertices v* 
and v*. (Note that each edge e of G is common to at most two 
regions, and it is possible that an edge may be in exactly one region.) 

194 
PLANARITY AND DUALITY 
A simple way to construct G* is to first place the vertices ν*, ν*,. •., ν*, 
one in each region of G. Then, for each edge e common to regions / and/ y, 
draw a line connecting v* and υ* so that it crosses the edge e. This line 
represents the edge e*. 
The procedure for constructing G* is illustrated in Fig. 7.11. The 
continuous lines represent the edges of the given planar graph G and the 
dashed lines represent those of G*. 
We now prove that G* is a dual of G. 
Let Cu 
C 2 , . . . , C r _ , denote the meshes of G, and C*, C*,...,C*_, 
denote the corresponding sets of edges in G*. It is clear from the procedure 
used to construct G* that the edges in C* are incident on the vertex v* and 
form a cut whose removal will separate v* from the remaining vertices of 
G*. 
By Theorem 7.3, C\, C 2 , . . . , C r_, form a basis of the circuit subspace of 
G, and we know that the incidence vectors C*, C*,..., 
C*_j form a basis 
of the cutset subspace of G*. Since there is a one-to-one correspondence 
between C,'s and C*'s, G and G* are dual graphs. Thus we have the 
following theorem. 
Theorem 7.12. Every planar graph has a dual. 
• 
The question that immediately arises now is whether a nonplanar graph 
has a dual. The answer is "no," and it is based on the next two lemmas. 
Lemma 7.1. K3 
3 has no dual. 
Figure 7.11. Construction of a dual. 

PLANARITY AND DUALITY 
195 
Proof. First observe that 
1. K3 3 has no cutsets of two edges. 
2. K3 3 has circuits of length 4 or 6 only. 
3. K3 3 has nine edges. 
Suppose K3 3 has a dual G. Then these observations would, respectively, 
imply the following for G: 
1. G has no circuits of two edges; that is, G has no parallel edges. 
2. G has no cutsets with less than four edges. Thus every vertex in G is of 
degree at least 4. 
3. G has nine edges. 
The first two imply that G has at least five vertices, each of degree at least 4. 
Thus G must have at least \ x 5 x 4 = 10 edges. However, this contradicts 
observation 3. Hence K3,3 has no dual. 
• 
Lemma 7.2. Ks has no dual. 
Proof. First observe that 
1. K5 has no circuits of length 1 or 2. 
2. K5 has cutsets with 4 or 6 edges only. 
3. K5 has 10 edges. 
Suppose K5 has a dual G. Then by observation 2, G has circuits of lengths 4 
and 6 only. In other words all circuits of G are of even length. So G is 
bipartite. 
Since a bipartite graph with six or fewer vertices cannot have more than 
nine edges, it is necessary that G has seven vertices. But by observation 1 
the degree of every vertex of G is at least 3. Hence G must have at least 
\ x 7 x 3 > 1 0 edges. This, however, contradicts observation 3. Hence K5 
has no dual. 
• 
The main result of this section now follows. 
Theorem 7.13. A graph has a dual if and only if it is planar. 
Proof. The sufficiency part of the theorem is the same as Theorem 7.12. 
We can prove the necessity by showing that a nonplanar graph G has no 
dual. By Kuratowski's theorem, G has a subgraph Η homeomorphic to K33 
or Ks. If G has a dual, then by Corollary 7.10.1, Η has a dual. But then, by 
Corollary 7.10.2, K33 
or K5 should have a dual. This, however, will 

196 
PLANARITY AND DUALITY 
contradict the fact that neither of these graphs has a dual. Hence G has no 
dual. 
• 
Theorem 7.13 gives a characterization of planar graphs in terms of the 
existence of dual graphs and was originally proved by Whitney. The proof 
given here is due to Parsons [7.12]. Whitney's original proof, which does not 
make use of Kuratowski's theorem, may be found in [7.13]. 
From the procedure given earlier in this section it is clear that different 
(though isomorphic) planar embeddings of a planar graph may lead to 
nonisomorphic duals (Exercise 7.7). The following theorem presents a 
property of the duals of a graph. 
Theorem 7.14. All duals of a graph G are 2-isomorphic; every graph 
2-isomorphic to a dual of G is also a dual of G. 
• 
The proof of this theorem follows in a straightforward manner from the 
definition of a dual and Theorem 1.9. 
7.6 
FURTHER READING 
Whitney [7.4], [7.11], and [7.14] and books by Seshu and Reed [7.13], Ore 
[7.15], Harary [7.6], Bondy and Murty [7.16], and Chartrand and Lesniak 
[7.17] are recommended for further reading. 
Two properties of a nonplanar graph G that are of interest follow: 
1. The minimum number of planar subgraphs whose union is G; this is 
called the thickness of G. 
2. The minimum number of crossings (or intersections) in order to draw a 
graph on a plane; this is called the crossing number of G. 
For several results on the thickness and the crossing numbers of a 
nonplanar graph, see Harary [7.6]. See also Bose and Prabhu [7.18]. 
An algorithm to test the planarity of a graph will be discussed in Section 
11.11 where references relating to the planar embedding problem and 
applications may also be found. 
7.7 
EXERCISES 
7.1 
Show that if G is a connected planar graph with m edges, η vertices, 
and with girth* &>3, then m == k(n - 2)l{k - 2). Using this result 
deduce that the Petersen graph is nonplanar. 
'For the definition of girth, see Exercise 1.18. 

EXERCISES 
197 
7.2 
Let d,, d 2, • • • ,d„ be the degrees of the vertices of a simple planar 
graph. Prove that if η s 4 , then 
η 
Σ d,
2<2(n + 3 )
2 - 6 2 . 
ι = 1 
7.3 
Prove that a simple planar graph with η > 4 vertices has at least four 
vertices with degree 5 or less. 
7.4 
Prove or disprove: Every connected simple nonplanar graph is con-
tractible to K5 or K3 
3 . 
7.5 
Let G be a simple graph with at least 11 vertices. Show that G and its 
complement G cannot both be planar. (In fact, a similar result can be 
proved with 11 replaced by 9. See Tutte [7.19].) Give an^xample of a 
graph G on 8 vertices with the property that both G and G are planar. 
7.6 
Using Kuratowski's theorem prove that the Petersen graph is non-
planar. 
7.7 
Find two nonisomorphic duals of the graph in Fig. 7.12. 
Figure 7.12 
7.8 
A planar graph is a maximal planar graph if, for every pair of 
nonadjacent vertices u and v, the graph G U {e}, where e = (u, υ), is 
nonplanar. 
Let G be a simple maximal planar graph with « ^ 4 vertices. If p, 
denotes the number of vertices of degree i in G for / = 3 , 4 , . . . , k = 
A(G), then show that 
3p 3 + 2pA + p5 = P
l + 2p 8 + . . . + (n - 6)6p, + 12 . 
7.9 
Prove that a planar graph without self-loops is nonseparable if and 
only if its dual is nonseparable. 
7.10 Show that the dual of a nonseparable planar graph is Eulerian if and 
only if the graph is bipartite. 

198 
PLANARITY AND DUALITY 
7.11 A planar graph is self-dual if it is isomorphic to its dual. Show that if a 
graph G with η vertices and m edges is self-dual, then m = 2n - 2. 
7.12 A one-terminal-pair graph is a graph with two vertices specially 
designated as the terminals of the graph. A planar one-terminal-pair 
graph is a one-terminal-pair graph that is planar and remains planar 
when an edge joining the two terminals is added to it. 
A series-parallel graph is a one-terminal-pair graph denned recursive-
ly as follows: 
(a) A single edge is a series-parallel graph. 
If G' and G" are series-parallel, then: 
(b) The series combination of G' and G" is a series-parallel graph. 
By the series combination of G' and G" we mean the joining of 
one of the terminals of G' with one of the terminals of G". (Fig. 
7.13a). 
Figure 7.13. (a) Series combina-
tion of G' and G". (b) Parallel 
combination of G' and G". 
(c) The parallel combination of G' and G" is a series-parallel graph. 
By the parallel combination of G' and G" we mean the joining of 
the two terminals of G' with the two terminals of G". (Fig. 
7.136). 
Show that a dual of a graph G is a series-parallel graph if and only if 
G is series-parallel. 
7.8 
REFERENCES 
7.1 
K. Wagner, "Bemerkungen zum Vierfarbenproblem," Uber. Deutsch. Math. 
Verein, Vol. 46, 26-32 (1936). 
7.2 
I. Fary, "On Straight Line Representation of Planar Graphs," Acta Sci. Math. 
Szeged, Vol. 11, 229-233 (1948). 
7.3 
S. K. Stein, "Convex Maps," Proc. Am. Math. Soc, Vol. 2, 464-466 (1951). 

REFERENCES 
199 
7.4 
Η. Whitney, "Non-Separable and Planar Graphs," Trans. Am. Math. Soc, 
Vol. 34, 339-362 (1932). 
7.5 
C. Kuratowski, "Sur le Probleme des courbes gauches en topologie," Fund. 
Math., Vol. 15, 271-283 (1930). 
7.6 
F. Harary, Graph Theory, Addison-Wesley, Reading, Mass., 1969. 
7.7 
W. T. Tutte, "How to Draw a Graph," Proc. London Math. Soc, Vol. 13, 
743-767 (1963). 
7.8 
K. Wagner, "Uber eine Eigenschaft der ebenen Komplexe," Math. Ann., Vol. 
114, 570-590 (1937). 
7.9 
F. Harary and W. T. Tutte, "A Dual Form of Kuratowski's Theorem," 
Canad. Math. Bull., Vol. 8, 17-20 (1965). 
7.10 S. MacLane, "A Structural Characterization of Planar Combinatorial 
Graphs," Duke Math. J., Vol. 3, 340-372 (1937). 
7.11 H. Whitney, "Planar Graphs," Fund. Math., Vol. 21, 73-84 (1933). 
7.12 T. D. Parsons, "On Planar Graphs," Am. Math. Monthly, Vol. 78, 176-178 
(1971). 
7.13 S. Seshu and Μ. B. Reed, Linear Graphs and Electrical Networks, Addison-
Wesley, Reading, Mass., 1961. 
7.14 H. Whitney, "A Set of Topological Invariants for Graphs," Am. J. Math., 
Vol. 55, 231-235 (1933). 
7.15 O. Ore, The Four Colour Problem, Academic Press, New York, 1967. 
7.16 J. A. Bondy and U. S. R. Murty, Graph Theory with Applications, Macmillan, 
London, 1976. 
7.17 G. Chartrand and L. Lesniak, Graphs and Digraphs, Wadsworth and Brooks/ 
Cole, Pacific Grove, Calif., 1986. 
7.18 Ν. K. Bose and K. A. Prabhu, "Thickness of Graphs with Degree Con-
strained Vertices," IEEE Trans. Circuits and Sys., Vol. CAS-24, 184-190 
(1975). 
7.19 W. T. Tutte, "On the Nonbiplanar Character of the Complete 9-Graph," 
Canad. Math. Bull., Vol. 6, 319-330 (1963). 

CHAPTER 8 
CONNECTIVITY AND MATCHING 
In Chapter 1 we denned a graph to be connected if there exists a path 
between any two vertices of the graph. Suppose a graph G is connected. 
Then we may be interested in finding how "well-connected" G is. In other 
words we may like to know the minimum number of vertices or edges whose 
removal will disconnect G. This leads us to the concepts of vertex and edge 
connectivities of a graph. In this chapter we first develop several results 
relating to vertex and edge connectivities of a graph. We also discuss a 
classical result in graph theory, namely, Menger's theorem, which relates 
connectivities to the number of vertex-disjoint and edge-disjoint paths. 
A matching in a graph is a set of edges no two of which have common 
vertices. In the latter part of this chapter we develop the theory of 
matchings, starting our development with Hall's marriage theorem. 
Connectivity and matching are two extensively studied topics in graph 
theory. Many deep results in graph theory belong to these two areas. 
8.1 
CONNECTIVITY OR VERTEX CONNECTIVITY 
The connectivity k ( G ) of a graph G is the minimum number of vertices 
whose removal from G results in a disconnected graph or a trivial graph/ 
K ( G ) is also called vertex connectivity to distinguish it from edge connectivi-
ty, which is introduced in the next section. 
For example, the connectivity of the graph of Fig. 8.1 is 2 since the 
removal of vertices vx and v2 from this graph results in a disconnected graph, 
whereas the removal of no single vertex will disconnect the graph. 
'Recall (Section 1.7) that a trivial graph is a graph with just a single vertex. 
200 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

CONNECTIVITY OR VERTEX CONNECTIVITY 
201 
Figure 8.1 
Obviously, the connectivity of a disconnected graph is 0. 
Consider a graph G on n vertices. It is clear that K(G) = n — 1 if G is 
complete. If G is not complete, it will have at least two nonadjacent vertices 
vx and v2. The removal of the remaining n-2 
vertices from G will then 
result in a graph in which υ, and v2 are not connected. Thus if G is not 
complete, we have 
K ( G ) < H - 2 . 
A disconnecting set in a graph G is a set of vertices whose removal from 
G results in a disconnected graph or a trivial graph. 
A graph G is said to be k-connected if K(G) a k. So, a A:-connected graph 
has no disconnecting set S with \S\ :£ k - 1. 
If a graph is connected, its connectivity is greater than or equal to 1. So 
connected graphs are 1-connected. 
If a connected graph has no cut-vertices, then its connectivity is greater 
than 1. So, connected graphs with no cut-vertices are 2-connected. 
In the following theorem we present a simple upper bound on the 
connectivity of a graph. 
Theorem 8.1. For a simple connected graph G, K(G) < S(G), where 8(G) is 
the minimum degree in G. 
Proof. Consider any vertex y in a simple connected graph G = (V, E). Let 
Γ(υ) denote the set of vertices adjacent to u. It is clear that Γ(ν) is a 
disconnecting set since the removal of the vertices in Γ(υ) results in a trivial 
graph or a disconnected graph in which υ is not connected to any of the 
remaining vertices. Thus 
K(G) = S | I » | 
forallüGV. 
Since G is simple, 
\m\ = d(v), 

202 
CONNECTIVITY AND MATCHING 
and hence 
K(G)*mm{d(v)} 
= «(G). 
• 
If a graph G has m edges and η vertices vuv2,... 
,vn, 
then we know 
from Theorem 1.1, 
d(u,) + d(v2) + ••• + d(v„) = 2m . 
So, 
« - 5 ( G ) < 2 m 
and 
2m 
KG)-
L η 
(8.1) 
where |*J denotes the largest integer less than or equal to x. 
Combining (8.1) with the result of Theorem 8.1, we get the following. 
Theorem 8.2. For a simple connected graph G having m edges and η 
vertices, 
Let f(k, n) denote the least number of edges that a -connected graph on 
η vertices must have. Of course, we assume that k< n. From Theorem 8.2 it 
is clear that 
/ ( * , « ) > [ y j , 
(8.2) 
where fjc"j denotes the smallest integer greater than or equal to x. 
Harary [8.1] has proved that equality holds in (8.2) by giving a procedure 
for constructing a /c-connected graph Hkn 
which has exactly \kn/2] edges. 
This procedure is as follows. 
Case 1 
k even. 
Let k = 2r. Then H2rn 
has vertices v0, vt, v2,..., 
u n_, and two vertices v, 
and vf are adjacent if / - r s / s f + r, where addition is modulo n. 
H6S is shown in Fig. 8.2a. 

CONNECTIVITY OR VERTEX CONNECTIVITY 
2 0 3 
is) 
»o 
Figure 8.2. (a) Η6Λ. (b) //5,8. (c) tf7,9 

204 
CONNECTIVITY AND MATCHING 
Case 2 k odd, η even. 
Let k = 2r + 1. H2r+ln 
is constructed by first constructing H2r„ and then 
adding edges joining vertex v, to vertex v} for i = 1, 2 , . . . , n/2 and / = ι + 
n/2 (mod n). 
// 5 8 is shown in Fig. 8.26. 
Case 3 & odd, η odd. 
Let 
= 2r + 1. H2r+1 
n is constructed by first constructing H2rn 
and then 
adding edges joining i>, and uy for i = 0, 1, 2 , . . . ,(n - l)/2 and 
; = i + (n + l)/2 (modn). 
f/7 9 is shown in Fig. 8.2c 
It is easy to verify that the graph Hkn constructed as described here has 
exactly \kn/2] edges. We now prove that Hkn is ^-connected. 
Theorem 8.3. Graph Hkn is ^-connected. 
Proof 
Case 1 k = 2r. 
From the symmetry of H2rn 
it is sufficient to show that the vertices v0 and 
υ β , α = 1 , 2 , . . . , η - 1 cannot be disconnected by removal of fewer than 2r 
vertices. Suppose that v0 and va can be disconnected by removal of 2r - 1 
vertices υ,, u, 2,..., vt 
. One of the two intervals [0, a], [a, n] contains at 
most r - 1 of these indices. Suppose it is interval [0, a]. Then two consecu-
tive vertices of the sequence obtained by removing υ , ν,,..., 
ν, 
from 
the sequence υ0, υ,, υ2,...,να 
are connected by an edge (because the 
difference between their indices is s r ) . Hence there is a path from v0 to va, 
a contradiction. 
Case 2 k = 2r + 1, η even. 
Suppose the vertices v0 and va are disconnected by the removal of 2r 
vertices vti, υ, ,..., u,2r. If one of the two intervals [0, a], [a, n] does not 
contain a consecutive r number of these indices, then a path from v0 to va 
can be constructed as shown under case 1. Therefore, suppose that v0 and va 
are disconnected by the removal of v„ vl+1,..., 
vi+r_lt 
where 1 =£ i =£ a - r, 
and va+j, 
v
a
+
l
+
1 , . . . , O
a
+
J
+
r .
l
t where 1 < / < η - r - a. 
Let 

CONNECTIVITY OR VERTEX CONNECTIVITY 
205 
Then 
β G [a + j + r, η + i - 1], 
β' £ [i + r, a + j - 1]. 
There is a path from vertex v0 to vertex 
and from vertex vp. to vertex 
va. Hence there is a path from vertex υ0 to vertex va since in H2r+1 
„ there is 
an edge connecting νβ and υβ,. 
Case 3 
k = 2r + 1, η odd 
Proof follows as in case 2. 
• 
In the next theorem we present a sufficient condition for a graph to be 
A>connected. This result is due to Bondy [8.2]. 
Theorem 8.4. Let G be a simple graph of order n. Suppose we order the 
vertices of G so that 
d(Vl)^d(v2)<---^d(vn). 
Then G is λ-connected if 
d(vr) > r + k - 1 iorl<r<n-l 
- 
d(v„_k+l) 
Proof. Suppose a simple graph G satisfies the conditions of the theorem. If 
it is not Λ-connected, then there exists a disconnecting set S such that 
|S| = s < * . 
Consider now the graph G - S that is not connected. Let Η be a 
component of G - S of minimum order h. Then it is clear that the degree in 
Η of each vertex of Η is at most h - 1. Therefore, in G, the degree of each 
vertex of Η is at most h + s - 1. Thus 
d(vh)<h 
+s-\<h 
+k-\. 
(8.3) 
Therefore, by the conditions of the theorem, 
h>n-l-d(vn_k+1). 
(8.4) 
Since G — S has η - s vertices and Η is a component of G — S of 
minimum order, we have 
h ^ η — s — h 
or 
h + s < / i - h . 

206 
CONNECTIVITY AND MATCHING 
Therefore, 
d(v) s A + j - l s n - A - 1 , 
ve 
V(H), 
(8.5) 
where V(H) is the vertex set of H. Since every vertex u e V(G) - V(H) - S 
is adjacent to at most η - h - 1 vertices, we have 
d(u) =Ξ η - h - 1, 
u e V(G) - V(H) - S . 
(8.6) 
From (8.5) and (8.6) we conclude that all the vertices of degrees exceeding 
η - h - 1 are in S. Thus there are at most s vertices of degrees exceeding 
η - h - 1. Therefore 
Using (8.4) in (8.7), we get 
d(vn-s)<d(v„_k+i). 
Therefore 
n—s<n-k+1 
(8.7) 
or 
a contradiction. 
For example, the degrees of the graph in Fig. 8.3 satisfy the conditions of 
Theorem 8.4 for k = 3. Hence it is 3-connected. 
Figure 8.3. A 3-connected graph that satisfies the 
conditions of Theorem 8.4 for k = 3. 

EDGE CONNECTIVITY 
207 
8.2 
EDGE CONNECTIVITY 
Edge connectivity 
κ ' ( G ) of a graph G is the minimum number of edges 
whose removal from G results in a disconnected graph or a trivial graph. In 
other words κ ' ( G ) is the number of edges in a cut having the minimum 
number of edges. For example, for the graph of Fig. 8.4 the edge connectivi-
ty is equal to 2, since the removal of the two edges ex and e2 disconnects the 
graph, and removal of no single edge results in a disconnected graph. 
A graph G is said to be k-edge connected if K'(G)^k. 
Thus at least k 
edges have to be removed to disconnect a Λ-edge-connected graph. 
Since the edges incident on any vertex υ of G form a cut of G , it follows 
that 
K ' ( G ) < 5 ( G ) . 
In the following theorem we relate # c ( G ) , κ ' ( G ) , and 6 ( G ) . 
Theorem 8.5. For a simple graph G , 
Proof. We have already proved the second inequality. The first inequality 
can be proved as follows. 
If G is not connected, then K ( G ) = K ' ( G ) = 0. Thus in such a case the 
condition K ( G ) = £ K ' ( G ) is satisfied. 
If G is connected and κ ' ( G ) = 1, then G has a bridge e. In this case, if we 
remove one of the vertices on which e is incident, then a disconnected graph 
or the trivial graph results. Thus K ( G ) ^ κ ' ( G ) in this case too. 
Suppose κ ' ( G ) ^ 2. Then G has κ ' ( G ) edges whose removal disconnects 
it. Removal of any κ ' ( G ) - 1 of these edges results in a graph with a bridge 
e = (vx, v2). For each of these κ ' ( G ) - 1 edges select an end vertex different 
from vx and v2. Removal of these vertices will remove from G the κ ' ( G ) - 1 
edges and possibly some more. Suppose the resulting graph is disconnected. 
Figure 8.4. A 2-edge-connected graph. 

208 
CONNECTIVITY AND MATCHING 
Then k ( G ) S Κ'(G) - 1. Otherwise this graph will have e as a bridge, and so 
removal of u, or v2 will result in a disconnected graph or the trivial graph. In 
such a case k ( G ) =S Κ'(G). 
Thus in all cases 
Next we present a sufficient condition for κ ' ( G ) to be equal to 3 ( G ) . This 
result is due to Chartrand [8.3]. 
Theorem 8.6. Let G be an η-vertex simple graph. If 8(G) a L"/2j then 
k'(G) 
= 
8(G). 
Proof. It can be shown that G is connected (see Exercise 1.14). Therefore 
k'(G)>0. 
Since κ ' ( G ) < 8(G), the proof will follow if we show that k\G) S 8(G). 
Suppose k'(G)<8(G). 
Then there exists a cut S = (V,, V,) such that 
K ' ( G ) = |S| < ^ ( G ) . Let the edges of S be incident with g vertices in V, and 
ρ vertices in V,. 
Suppose |Vj = q. Then each vertex of V, is an end vertex of at least one 
edge in 5. If we denote by GX the induced subgraph of G on the vertex set 
V,, then G , has at least 
since 8(G) > κ'(G) s q. This is a contradiction since in a simple graph there 
cannot be more than q(q-\)l2 
edges connecting q vertices. Therefore 
|V,| > q. In a similar way we can prove that \VX \ > p. 
_ 
If 
> q and |V,| > p, then there are vertices in both V, and Vx that are 
adjacent to only vertices in V, and Κ,, respectively. Thus each of Vj and V, 
contains at least 8(G) +1 vertices. Therefore G has at least 28(G) + 2 
vertices. But 
k(G)<k'(G). 
• 
m
i = 
\(q8(G)-K'(G)) 
edges. Since k'(G)<8(G), 
we get 
mi>\(q8(G)-8(G)) 
= 
l8(G)(q-l) 
> k ( ? - i ) . 
>n , 
leading to a contradiction. Therefore there is no cut S with \S\ < 8(G). 
• 

GRAPHS WITH PRESCRIBED DEGREES 
209 
m^dk 
, 
\idk<k 
8.3 
GRAPHS WITH PRESCRIBED DEGREES 
Recall that a sequence (d,, d 2 , . . . , d„) of nonnegative integers is graphic if 
there exists an η-vertex graph with vertices ι>,, v2,..., 
vn such that vertex u, 
has degree d,. 
In this section we first describe an algorithm to construct a simple graph, 
if one exists, having a prescribed degree sequence. We then use this 
algorithm to establish Edmonds' theorem on the existence of it-edge-
connected simple graphs having prescribed degree sequences. 
Consider a graphic sequence (d,, d 2 , . . . , dn) with d, > d 2 > · · • > d„. Let 
d, be the degree of vertex v,. "To lay off dk" means to connect the 
corresponding vertex vk to the vertices 
y , , v2,..., 
vdk, 
\idk<k 
or to the vertices 
vl,v2,...,vk_l,vk+x,...,vdk+l 
, if dk>k 
. 
The sequence 
(d, - 1,. .. ,ddk- 
1, d d k + u . . .,dK_L,0, 
dk + l , . . . ,d„), 
\ldk<k 
or 
(d, - 1 , . . . , dk.l - 1,0, dk+x - 1 , . . . , d d t + 1 - 1, ddk+2,..., 
d j , if dk > A: 
is called the residual sequence after laying off dk or simply the residual 
sequence. 
Hakimi [8.4] and Havel [8.5] have given an algorithm for constructing a 
simple graph, if one exists, having a prescribed degree sequence. This 
algorithm is based on a result that is a special case (where k = 1) of the 
following theorem due to Wang and Kleitman [8.6]. 
Theorem 8.7. If a sequence (d,, d 2 , . . . , d„) with d, s d 2 s · · · > d„ is the 
degree sequence of a simple graph, then so is the residual sequence after 
laying off dk. 
Proof. To prove the theorem we have to show that a graph having 
(d,, d 2 , . . . , d„) as its degree sequence exists such that vertex vk is adjacent 
to the first dk vertices other than itself. If otherwise, select from among the 
graphs with the degree sequence (d,, d 2 , . . . , d„) a simple graph G in which 
vk is adjacent to the maximum number of vertices among the first dk vertices 
other than itself. Let vm be a vertex not adjacent to vk in G such that 

210 
CONNECTIVITY AND MATCHING 
or 
m < dk + 1, 
if k < dk. 
In other words vm is among the first dk vertices other than vk. So vk is 
adjacent in G to some vertex vq that is not among these first dk vertices. 
Then dm > dq (if equality, the order of q and m can be interchanged), and 
hence vm is adjacent to some vertex ν,, ίΦ q, ίΦ m, such that v, and vq are 
not adjacent in G. If we now remove the edges (vm, υ,) and (vk, vq) and 
replace them by (vm, vk) and (υ,, vq), we obtain a graph G' with one more 
vertex adjacent to vk among the first dk vertices other than itself violating 
the definition of G. 
• 
From Theorem 8.7 we get the following algorithm which is a generaliza-
tion of Hakimi's algorithm for realizing a sequence D = (a
1,, d2,..., 
dn) 
with dx > d2 > · · · s d„ by a simple graph. 
Choose any dk Φ 0. "Lay off" dk by connecting vk to the first dk vertices 
other than itself. Compute the residual degree sequence. Reorder the 
vertices so that the residual degrees in the resulting sequence are in 
nonincreasing order. Repeat this process until one of the following occurs: 
1. All the residual degrees are zero. In this case the resulting graph has D 
as its degree sequence. 
2. One of the residual degrees is negative. This means that the sequence 
D is not graphic. 
To illustrate the preceding algorithm, consider the sequence 
V \
 
V2
 
V3
 
V4
 
V5 
Z> = (4 
3 
© 
2 
2). 
After laying off d3 (which is circled), we get the sequence 
V i
 
V2
 
V3
 
V4
 
VS 
D' = (3 
2 
0 
1 
2), 
which, after reordering of the residual degrees, becomes 
V \
 
V2
 
VS
 
V4
 
V3 
D, = (3 
2 
φ 
1 
0). 
We next lay off the degree corresponding to u5 and get 
u, v2 
vs 
υ4 
υ3 
D[ = (2 
1 
0 
1 
0) 

GRAPHS WITH PRESCRIBED DEGREES 
211 
Reordering the residual degrees in D[ we get 
Vl
 
V2
 
V4
 
V5
 
V3 
D 2 = ( © 
ι 
ι 
o 
0 ) . 
Now laying off the degree corresponding to y,, we get 
l/| 
v
2 
v
4 
1/3 
D'2 = (0 
0 
0 
0 
0 ) . 
The algorithm terminates here. Since all the residual degrees are equal to 
zero, the sequence (4, 3, 3, 2, 2) is graphic. The required graph (Fig. 8.5) is 
obtained by the following sequence of steps, which corresponds to the order 
in which the degrees were laid off: 
1. Connect i>3 to u,, v2, and v4. 
2. Connect v5 to υ, and v2. 
3. Connect υ, to v2 and v4. 
Erdos and Gallai [8.7] have given a necessary and sufficient condition (not 
of an algorithmic type) for a sequence to be graphic. See also Harary [8.8]. 
Suppose that in the algorithm we lay off at each step the smallest nonzero 
residual degree. Then using induction we can easily show that the resulting 
graph is connected if 
d, > 1 
for all i 
(8.8) 
and 
η 
Σ ^ 2 ( « - 1 ) . 
(8.9) 
ι = 1 
Note that (8.8) and (8.9) are necessary for the graph to be connected. In 
fact we prove in the following theorem a much stronger result. This result is 
due to Edmonds [8.9]. The proof given here is due to Wang and Kleitman 
[8.10]. 
Figure 8.5. A graph with degree sequence (4, 3, 3, 
2, 2). 

212 
CONNECTIVITY AND MATCHING 
Theorem 8.8 (Edmonds). A necessary and sufficient condition for a graphic 
sequence (d,, d 2 , . . . , d„) to be the degree sequence of a simple /c-edge-
connected graph, for k > 2, is that each degree d, > k. 
Proof. Necessity is obvious. 
We prove the sufficiency by showing that the algorithm we have just 
described results in a Λ-edge-connected graph when all the degrees in the 
given graphic sequence are greater than or equal to k. Note that at each step 
of the algorithm, we should lay off the smallest nonzero residual degree. 
Proof is by induction. Assume that the algorithm is valid for all sequences 
in which each degree d, s: ρ with ρ ^ k - 1. 
To prove the theorem we have to show that in the graph constructed by 
the algorithm every cutset (A, A) has at least_fe edges. Proof is trivial if 
|A| = 1 or |A| = 1. So assume that |A| a 2 and |A| > 2 . 
We claim that in the connection procedure of the algorithm, one of the 
following three cases will eventually occur at some step, say, step r. (Step r 
means the step when the rth vertex is fully connected.) 
Case 1 All the nonzero residual degrees are at least k. 
Case 2 
All the nonzero residual degrees are at least k - 1, and there is 
at least one edge constructed by steps 1 , . . . , r that lies in 
(A, 
A). 
Case 3 
All the nonzero residual degrees are at least k -2, and there are 
at least two edges constructed by steps 1,2, . . . , r that lie in 
(A, 
A). 
All these three cases imply that the cutset (A, A) has at least k edges by 
induction. 
We prove this claim as follows: 
Let v, be the vertex that is connected at step i. Without loss of generality 
we may assume that υλ is in A. We now show that at some step in the 
connection procedure case 3 must occur if cases 1 and 2 never occur. 
At step 1, y, is fully connected. Then: 
a. The smallest nonzero residual degrees are k-l, 
because case 1 has 
not occurred. 
b. The degrees of none of the vertices in A are decreased by 1 when υ, is 
connected, because case 2 has not occurred. 
Hence v2, the vertex to be connected at step 2, must be in A. (All vertices in 
A must have degree at least k.) Now if v2 is connected and case 1 does not 
occur and no edge connects A with A, then we shall still have (a) and (b) as 
before. Hence the next vertex to be connected will still be in A. 
Since the residual degrees are decreased at each step of the connection 
procedure, sooner or later there must exist an rwith υ, in A, such that when 
i>, is connected, an edge will connect A with A. If case 2 does not occur, 

MENGER'S THEOREM 
213 
then one of the nonzero residual degrees among the vertices of A not yet 
fully connected becomes k - 2. This means, by our connection procedure, 
that vr must connect to every vertex in A, because vertices in A all have 
residual degree equal to k, and_since we connect vr to the vertices of the 
largest residual degree. Since | / l | s 2 , at this step case 3 occurs. 
• 
Wang and Kleitman [8.6] have also established necessary and sufficient 
conditions for a graphic sequence to be the degree sequence of a simple 
A;-vertex-connected graph. 
8.4 
MENGER'S THEOREM 
We present in this section a classical result in graph theory, namely, 
Menger's theorem [8.11]. This theorem helps to relate the connectivity of a 
graph to the number of vertex-disjoint paths between any two distinct 
vertices in the graph. 
Theorem 8.9 (Menger). The minimum number of vertices whose removal 
from a graph disconnects two nonadjacent vertices s and t is equal to the 
maximum number of vertex-disjoint s-t paths in the graph. 
• 
Proof of this theorem is given in Section 12.10. 
Theorem 8.10. A necessary and sufficient condition that a simple graph 
G = (V, E), with |V|sA: + l, be Λ-connected is that there are k vertex-
disjoint s-t paths between any two vertices s and t of G. 
Proof. Obviously, the theorem is true for k = 1. So we need to prove the 
theorem for k > 2. 
Necessity 
If s and t are not adjacent, then the necessity of the theorem 
follows from Theorem 8.9. 
Suppose that s and t are adjacent and that there are at most k - 1 
vertex-disjoint s-t paths in G. Let e = (s, t). Consider now the graph 
G' = G - e. Since there are at most k - 1 vertex-disjoint s-t paths in G, 
there cannot be more than k-2 
vertex-disjoint s-t paths in G'. Thus there 
exists a set ACV— {s, t} of vertices, with \A\^ k - 2 , whose removal 
disconnects s and t in G'. Then 
\V- A\ = \ V\ - \A\ > k + 1 - (k - 2) = 3 , 
and therefore, there is a vertex u in V- A different from s and t. 
Now we show that there exists an s-u path in G' that does not contain 
any vertex of A. Clearly, this is true if s and u are adjacent. If s and u are 
not adjacent, then there are k vertex-disjoint s-u paths in G, and hence 

214 
CONNECTIVITY AND MATCHING 
there are k - 1 vertex-disjoint s-u paths in G'. Since | A\ < k - 2, at least 
one of these k - 1 paths will not contain any vertex of A. 
In a similar way we can show that in G' there exists au - t path that does 
not contain any vertex of A. 
Thus there exists in G' an s-t path that does not contain any vertex of A. 
This, however, contradicts that A is an s-t disconnecting set in G'. 
Hence the necessity. 
Sufficiency 
G is connected because there are k vertex-disjoint paths 
between any two distinct vertices of G. Further, not more than one of these 
paths can be of length 1, since there are no parallel edges in G. The union of 
the remaining k - 1 paths must contain at least k - 1 distinct vertices other 
than s and t. Hence 
\V\>(k-\) 
+ 2> k. 
Suppose in G there is a disconnecting set A with \A\ < k. Then consider 
the subgraph G' of G on the vertex set V- A. This graph contains at least 
two distinct components. If we select two vertices s and t from any two 
different components of G', then there are at most \A \ < k vertex-disjoint 
s - ί paths in G. This contradicts that any two vertices are connected by k 
vertex-disjoint paths in G. 
Hence the sufficiency. 
• 
This result is due to Whitney [8.12]. Since it is only a variation of 
Theorem 8.9, we shall refer to this also as Menger's theorem. 
Consider next two special classes of ^-connected graphs, namely, the 
2-connected graphs and the 3-connected graphs. There are several equiva-
lent characterizations of 2-connected graphs. Some of them we have already 
listed as exercises in Chapter 1. 
Tutte has given a characterization of 3-connected graphs. This characteri-
zation is given in terms of a special class of graphs called wheels. 
Consider a circuit C of length n. If we add a new vertex and connect it to 
all the vertices of C, then we get the (n + l)-wheel Wn + l . For example, W7 is 
shown in Fig. 8.6. 
Tutte's [8.13] characterization of 3-connected graphs is stated in the next 
theorem. 
Figure 8.6. Wheel W7. 

MATCHINGS 
215 
Theorem 8.11. A simple graph G is 3-connected if and only if G is a wheel 
or can be obtained from a wheel by a sequence of operations of the 
following types: 
1. The addition of a new edge. 
2. The replacement of a vertex ν of degree ^4 by two adjacent vertices 
v' and υ" of degrees s 3 such that each vertex formerly adjacent to υ is 
now adjacent to exactly one of v' and v". 
• 
We conclude this section with a characterization of A>edge-connected 
graphs. This characterization is analogous to Theorem 8.9 and is also known 
as Menger's theorem, though it was independently discovered by Ford and 
Fulkerson [8.14] and by Elias, Feinstein, and Shannon [8.15]. 
Theorem 8.12. The minimum number of edges whose removal from a 
connected graph G disconnects two distinct vertices s and t is equal to the 
maximum number of edge-disjoint s-t paths in G. 
• 
Proof of Theorem 8.12 is also given in Section 12.10. 
8.5 
MATCHINGS 
The discussions of this and the remaining sections of this chapter concern 
the following problem, known as the marriage problem, and related ones. 
We have a finite set of boys, each of whom has several girlfriends. Under 
what conditions can we marry off the boys in such a way that each boy 
marries one of his girlfriends? (No girl should marry more than one boy!) 
This problem can be posed in graph-theoretical terminology as follows: 
Construct a bipartite graph G in which the vertices xJyx2,... 
,xn repre-
sent the boys and the vertices >>,, y2,..., 
ym represent the girls. An edge 
(χ,, yt) is present in G if and only if yt is a girlfriend of x,. The marriage 
problem is then equivalent to finding in G a set of edges such that no two of 
them have a common vertex and each x, is an end vertex of one of these 
edges. 
For example, suppose there are four boys bx, b2, b3, and 6 4 and four girls 
£i> # 2 ' # 3 '
 
a
n
o
< 
#4>
 
w i
t
n their relationships as follows: 
*.-»{*.}. 
b2-*{g2) 
, 
b3-^{g1, 
g2) , 
b*->{gi, 
gA) • 

2 1 6 
CONNECTIVITY AND MATCHING 
*,o 
-^>«, 
b2o 
y* 
!^°*2 
* 3 
Figure 8.7 
t4o*— 
og4 
The bipartite graph representing this situation is shown in Fig. 8.7. It is easy 
to verify that it is not possible to marry off all the four boys such that each 
one marries one of his girlfriends. However, we can marry off as many as 
three boys without violating the requirement of the marriage problem. For 
example, two sets of such appropriate pairing are 
1. (&„g,), (P2,g2), 
(*4.ft)· 
2. (fc„g,), (&3.&)> (&4>&)· 
These discussions motivate the definition of a matching in a graph. 
Two edges in a graph are said to be independent if they do not have any 
common vertex. Edges e,, e 2,... are said to be independent if no two of 
them have a common vertex. 
A matching in a graph is a set of independent edges. For example, in the 
graph of Fig. 8.8 {e,, e4} is a matching. 
Obviously, a maximal matching is a maximal set of independent edges. 
Thus in the graph of Fig. 8.8 {e1,e^} is a maximal matching, whereas 
{es, e6) is not. 
A matching with the largest number of edges is called a maximum 
matching. The set {el,es,e6} 
is a maximum matching in the graph of Fig. 
8.8. The number of edges in a maximum matching of G will be called the 
matching number of G and will be denoted by a^G). 
A vertex is said to be saturated in a matching M if it is an end vertex of an 
edge in M. For example, the vertex v is saturated in the matching 
{e,, e5. e6} in the graph of Fig. 8.8. 
In the following a bipartite graph G = (V, E) with bipartition (X, Y) will 
be denoted by the triplet (X, Y, E). 
We say that the set X can be matched into Y in the bipartite graph 
(X, Y, E) if there is a matching M such that every vertex of X is saturated in 
M. The matching M will then be called a complete matching of X into Y. 
With this new terminology the marriage problem becomes equivalent to 
finding necessary and sufficient conditions for the existence of a complete 
matching of X into Y, in a bipartite graph (X, Y, E). In the next section we 
present several results concerning matchings in bipartite graphs, in addition 
to providing an answer to the marriage problem. 

MATCHINGS IN BIPARTITE GRAPHS 
217 
Figure 8.8 
8.6 
MATCHINGS IN BIPARTITE GRAPHS 
Consider a bipartite graph G = (Χ, Υ, E). Let S be any subset of X and let 
Γ(5) denote the set of vertices adjacent to the vertices in S. Suppose 
| 5 | > |r(S)|. Then it is clear that there is no complete matching of S into 
T(S), and any matching Μ in G will saturate at most |Γ(5)| of the vertices of 
S. So 
| M | < W - ( | 5 | - | r ( 5 ) | ) . 
(8.10) 
Since (8.10) is valid for any subset 5 of X, we can conclude that for any 
matching M, 
| M | < | * | - m a x ( | S | - | r ( S ) | ) . 
(8.11) 
We now define the deficiency σ(5) of any subset 5 of X and the deficiency 
&(G) of G as follows: 
σ(5) = | 5 | - | Γ ( 5 ) | 
(8.12) 
and 
a(G) = m a x ( | S | - | r ( S ) | ) . 
(8.13) 
Now using (8.13), we can rewrite (8.11) as 
\M\x\X\-oiG). 
(8.14) 
The main result of this section is that in a bipartite graph G = (X,Y, 
E) 
there exists a matching with \X\- 
a(G) edges. In other words we show that 

218 
CONNECTIVITY AND MATCHING 
the number of edges in a maximum matching of G is equal to \X\ - 
a(G). 
The result will be proved in two parts. We consider the case a(G) = 0 first, 
and the case cr(G) > 0 later. (Note that a(G) a 0, since for the empty set 0 , 
σ(0) = 0.) 
Note that the case a(G) = 0 occurs if for every subset S of X 
|S|s|r(S)|, 
and the case a(G) > 0 occurs when for some subset 5 of AT 
|5|>|Γ(5)|. 
The following result is due to Hall [8.16]. Our proof is based on Halmos 
and Vaughan [8.17]. 
Theorem 8.13 (Hall). In a bipartite graph G = (Χ, Υ, E) there exists a 
complete matching of X into Y if and only if, for any 5 C X, 
|5|<|Γ(5)|. 
Proof 
Necessity 
From (8.14) it is clear that complete matching of X into Y 
requires that a(G) = 0 or, in other words, 
|5|<|Γ(5)|, 
SCX. 
Sufficiency 
Proof is by induction on \X\, the number of vertices in X. 
If |Al = 1, then obviously there is a complete matching of X into Y since 
the only vertex in X should be adjacent to at least one vertex in Y. 
Assume as the induction hypothesis that the sufficiency is true for any 
bipartite graph with \X\<m-\. 
Consider then a bipartite graph G = 
(Χ, Υ, E) with \X\ = m. Let for every subset S of X, \S\ < |Γ(5)|. We now 
show that there is a complete matching of X into Y by examining the 
following cases. 
Case 1 
For every nonempty proper subset S of X, \S\ < |Γ(5)|. 
Select any edge (x0, y0), x0EX 
and y 0 Ε Y. Let G' be the graph obtained 
from G by removing x0 and y 0 and the edges incident on them. Since the 
vertices of every subset S of X - {xQ} are adjacent to more than |5| vertices 
in y, they are adjacent to |S| or more vertices in Y - {y 0}. Therefore by the 
induction hypothesis, there exists a complete matching of X — {x0} 
into 
Υ~{)>ο}· This matching together with the edge (x0, y 0) is a complete 
matching of X into Y. 

MATCHINGS IN BIPARTITE GRAPHS 
219 
Case 2 
There is a nonempty property subset 5 0 of X such that \S0\ = 
|Γ(5„)|· 
Let G' be the subgraph of G containing the vertices in the sets SQ and Γ(5 0) 
and the edges connecting these vertices. 
Let G" be the subgraph of G containing the vertices in the sets X - S0 
and Y - T(S 0) and the edges connecting these vertices. 
We show that in G' there is a complete matching of 5 0 into Γ(5 0), and in 
G" there is a complete matching of X — S0 into y - r ( 5
0 ) . These two 
matchings together will form a complete matching of X into Y. 
Consider first the graph G'. Let, for any subset S of S 0, Γ'(5) denote the 
set of vertices in Γ(5„) adjacent to those in S. It is then clear that 
r(S) 
= r(S), 
ScS0. 
Since, for every subset S of 5 0, 
| 5 | < | r ( 5 ) | = | r ' ( S ) | , 
it follows from the induction hypothesis that there is a complete matching of 
S 0 into IYA). 
Consider next the graph G". Let, for any subset of X - S0, Γ"(5) denote 
the set of vertices in Υ - Γ(5 0) adjacent to those in S. Now for S C X - 
S0, 
| 5 U S 0 | = |5| + |S 0| 
< | r ( 5 U S 0 ) | 
= | P ( S ) | + |Γ(5 0)| . 
Since |5 0| = |Γ(5 0)|, we get from the above 
|5|<|Γ"(5)|, 
SCX-S0. 
Thus again by the induction hypothesis there is a complete matching of 
X-S0 
into Υ - Γ ( 5 0 ) . 
This completes the proof of sufficiency. 
• 
As we observed before, Theorem 8.13 provides an answer to the mar-
riage problem, and it is stated next. 
Theorem 8.14 (Hall). A necessary and sufficient condition for a solution of 
the marriage problem is that every set of k boys collectively have at least k 
girlfriends, 1 =s k s m, where m is the number of boys. 
• 
Theorem 8.13 is simply a translation into graph-theoretical terminology 
of Theorem 8.14. 

220 
CONNECTIVITY AND MATCHING 
Next we prove that when a(G) > 0, the number of edges in a maximum 
matching is equal to \X\ - cr(G). To do so, we need the following two 
lemmas. 
Lemma 8.1. Let S, and S2 be any two subsets of X. Then 
o-(S, U S2) + a(Sl Π S2) > σ(5,) + 
a(S2). 
Proof. It is a simple exercise to verify that 
|5, U S2\ + |S, Π 5 2| = |5,| + \S2\. 
(8.15) 
Since 
\r(SlUS2)\ 
= 
\r(Sl)UT(S2)\ 
and 
i n s . n s ^ l s i n s j n r ^ ) ! , 
we get 
|Γ(5, U 5 2)| + |r(S, Π S 2)| ^ |Γ(5,) U Γ(5 2)| + |Γ(5,) ΠΓ(5 2)| 
= |Γ(5,)| + |Γ(5 2)|. 
(8.16) 
Now subtracting (8.16) from (8.15) we get 
σ(5, U S2) + σ(5, Π S2) > |5,| + |5 2| - |Γ(5,)| - |Γ(5 2)| 
= σ(5,) + σ(5 2). 
• 
Lemma 8.2. Let 5, and S2 be two subsets of X such that σ(5,) = σ(5 2) = 
σ(ϋ). Then 
σ(5, U 5 2) = σ(5, Π 5 2) = tf(G). 
Proof. From Lemma 8.1, 
σ(5, U 5 2) + σ(5, Π 5 2) ^ σ(ί,) + σ(Ξ2) = 2a(G). 
Since neither <r(S, U 5 2) nor σ·(5, Π 5 2) is greater than a(G), we get 
<7(5, U 5 2) = σ(5, Π 5 2) = <r(G). 
• 
Theorem 8.15. In a bipartite graph G = (Χ, Υ, E) with a ( G ) > 0 , the 
number of edges in maximum matching is equal to 
- o-(G). 

MATCHINGS IN BIPARTITE GRAPHS 
221 
Proof. Let 5 , , S2,..., 
Sk be all the subsets of X with their deficiencies equal 
to o - ( G ) . 
Let 
s0 = 5 , η s
2 η · · · η s
k . 
By Lemma 8 . 2 , 
a ( S
0 ) = 
a ( G ) > 0 . 
Thus S0 is nonempty. We may now note that every subset of X having its 
deficiency equal to a(G) contains SQ. 
Consider any vertex x0 in S0. Let G ' be the graph that is obtained by 
removing from G the vertex x0 and all the edges incident on it. It is clear 
that 
CT-(G') 
< a(G), since no subset of the set X - {x0} contains S 0. We now 
show that e r ( G ' ) = a(G) - 1. 
Consider the set S^ = S0- 
{x0}. We have 
a(S') 
= 
\Si\-\r(S'0)\ 
= | 5 0 | - 1 - | Γ ( 5 ί ) | . 
Since a(S'0)< 
CT(G), 
we obtain 
| 5
0 | - ι - | γ ( 5 ; ) | < | 5
0 | - | γ ( 5
0 ) | , 
that is, 
| Γ ( 5 ; ) | > | Γ ( 5
0 ) | . 
( 8 . 1 7 ) 
On the other hand, since SQ is a subset of 5 0 , 
| Γ ( 5 ί ) | ^ | Γ ( 5 0 ) | . 
( 8 . 1 8 ) 
Combining ( 8 . 1 7 ) and ( 8 . 1 8 ) , we get 
TO)| = |r(5 0)|. 
Therefore 
σ(5;) = | 5 0 | - 1 - | Γ ( 5 0 ) | = σ ( Ο ) - 1 . 
Since t r ( G ' ) < a(G), we can conclude that 
CT(G') 
= a(G) - 1 . 
If we repeat this argument until an appropriate set of e r ( G ) vertices is 
removed from X along with the edges incident on these vertices, we get a 
subgraph of G with deficiency equal to zero. By Theorem 8 . 1 3 , there is a 
complete matching in this subgraph. This will be a matching for G contain-

222 
CONNECTIVITY AND MATCHING 
ing X— a(G) edges. It is clear from (8.14) that such a matching will be a 
maximum matching of G. 
• 
We can combine Theorems 8.13 and 8.15 into one, and because of its 
importance, we present it here. See Konig [8.18] and Ore [8.19]. 
Theorem 8.16 (Konig). The number of edges in a maximum matching of a 
bipartite graph G = (X, Y,E) 
is equal to |ΑΊ - σ(β), where a(G) is the 
deficiency of G. 
• 
Corollary 8.16.1. In a nonempty bipartite graph G = (Χ, Υ, E) there is a 
complete matching of X into Y if 
min {d(x)\ srmax {d(y)} . 
xex 
yeY 
min {d(x)} = d, 
Proof. Let 
and 
max{d(y)} = d 2 . 
yeY 
Consider any subset A of X. Let Ex be the set of edges incident on the 
vertices in A, and E2 the set of edges incident on the vertices in Γ(Α). Then 
we have 
| £ , 1 > μ κ 
and 
\E2\x\T(A)\d2. 
Since £, C E2, we have 
\Y{A)\d2>\E2\>\Ex\>\A\dx 
. 
So 
|r(i4)|aH, 
ACX. 
Thus by Hall's theorem there is a complete matching of X into Y. 
• 
Next we consider two results that are related to Hall's theorem. 

MATCHINGS IN BIPARTITE GRAPHS 
223 
Our first result is from transversal theory. 
Let Μ be a nonempty finite set and S = {£,, S 2 , . . . , S r} be a family of 
(not necessarily distinct) nonempty subsets of M. Then a transversal (or 
system of distinct representatives) of S is a set of r distinct elements of M, one 
from each set Sr 
For example, if Μ = {1, 2, 3, 4, 5, 6} and S, = {1, 3, 4}, S 2 = {1, 3, 4}, 
5 3 = {1, 2, 5}, and 5 4 = {5, 6}, then {1, 3, 2, 6} is a transversal of the family 
5 = {5,, S2, S 3. 5 4}. On the other hand, if S, = S2 = {1, 3}, 5 3 = {3, 4), and 
5 4 = {1, 4}, then there is no transversal for the family {5,, S2, S 3, 5 4}. 
The following question now arises: 
What are the necessary and sufficient conditions for a family of subsets of 
a set to have a transversal? 
Suppose we construct a bipartite graph G = (Χ, Υ, E) such that: 
1. The vertex x, of X corresponds to the set 5, in S. 
2. The vertex y, of Y corresponds to element i of M. 
3. Edge (*,, yt) Ε £ if and only if / £ 5,. 
We can now see that the question becomes equivalent to finding a complete 
matching of X into Y in the bipartite graph G constructed as above. Thus we 
get the following theorem, which is simply a restatement of Hall's theorem 
in the language of transversal theory. 
Theorem 8.17. Let Μ be a nonempty set and 5 = {5,, 5 2 , . . . , 5 r} a family 
of subsets of M. Then 5 has a transversal if and only if the union of any k, 
1 < k s r, of the subsets 5, contain at least k elements of M. 
• 
A purely combinatorial proof of Theorem 8.17 without using concepts 
from graph theory was given by Rado. The proof is very elegant and may be 
found in Rado [8.20]. 
The next result relates to matrices whose elements are 0's and l's. Such 
matrices are called (0,1) matrices. In the following, a line of a matrix refers 
to a row or a column of the matrix. 
Theorem 8.18 (Konig and Egervary). The minimum number of lines that 
contain all the l's in a (0,1) matrix is equal to the maximum number of l's 
no two of which are in the same line of M. 
• 
Given a (0,1) matrix Μ of order mx n. Suppose we construct a bipartite 
graph G = (Χ, Υ, E) such that: 
1. The vertices xt, x2,... 
,xm of X correspond to the m rows of M. 
2. The vertices y,, y2,..., 
y„ of Y correspond to the η columns of M. 
3. The edge (x„ yf) ε £ if the (i, j) entry of Μ is equal to 1. 

224 
CONNECTIVITY AND MATCHING 
If we now consider a vertex as covering all the edges incident on the vertex, 
then the Konig-Egervary theorem can be restated as follows: 
In a bipartite graph the minimum number of vertices that cover all the 
edges is equal to the number of edges in any maximum matching of the 
graph. 
In Chapter 9 (Theorem 9.2) we prove this form of the Konig-Egervary 
theorem. 
8.7 
MATCHINGS IN GENERAL GRAPHS 
In this section we establish some results relating to matchings in a general 
graph. 
Consider a graph G = (V, E) and a matching Μ in G. An alternating 
chain in G is a trail whose edges are alternately in Μ and Ε — M. For 
example, the sequence of edges e,, e2, e3, e 4, e 7, e 6 is an alternating chain 
relative to the matching Μ = {e2, eA, e6} in the graph of Fig. 8.9. The edges 
in the alternating chain that belong to Μ are called dark edges and those 
that belong to Ε - Μ are called light edges. Thus e,, e3, e7 are light edges, 
whereas e2, e4, e6 are dark edges in the alternating chain considered above. 
Theorem 8.19. Let M, and M2 be two matchings in a simple graph G = 
(V, E). Let G' = (V, E') be the induced subgraph of G on the edge set 
M, ®M2 = (Af, - M2) U (M2 - M,) . 
Then each component of G' is of one of the following types: 
1. A circuit of even length whose edges are alternately in Μλ and M2. 
2. A path whose edges are alternately in M, and M2 and whose end 
vertices are unsaturated in one of the two matchings. 
Figure 8.9 

MATCHINGS IN GENERAL GRAPHS 
225 
Proof. Consider any vertex ν Ε V. 
Case 1 
ν Ε V(A/, - A/2) and v0V(M2 
- A/,), where V(M, - M}) de-
notes the set of vertices of the edges in A/, - A/;. 
In this case υ is the end vertex of an edge in A/, - A/ 2. Since Mx is a 
matching, no other edge of Mx - M2 is incident on v. Further, no edge of 
M2- 
Af, is incident on ν because υ0V(M2 
- A/,). Thus in this case the 
degree of ν in G' is equal to 1. 
Case 1 
υ Ε V(Ai, - Αί 2) and ι; Ε V(M2 - M,). 
In this case a unique edge of Af, - A/2 is incident on υ and a unique edge of 
Af2 - A/, is incident on v. Thus the degree of ν is equal to 2. 
Since the two cases considered are exhaustive, it follows that the max-
imum degree in G' is 2. Therefore the connected components will be of one 
of the two types described in the theorem. 
• 
For example, consider the two matchings Af, = {e 5, e 7, e9) and M2 = 
{e,, e 1 0, e,,} of the graph G of Fig. 8.9. Then 
Af, Φ Μ2 = {e,, e 5, e7, e9, e 1 0, e n ) , 
and the graph G' will be as in Fig. 8.10. It may be seen that the components 
of G' are of the two types described in Theorem 8.19. 
In the following theorem we establish Berge's [8.21] characterization of a 
maximum matching in terms of an alternating chain. 
Theorem 8.20 (Berge). A matching Af is maximum if and only if there exists 
no alternating chain between any two unsaturated vertices. 
Proof 
Necessity 
Suppose there is an alternating chain Ρ between two unsatu-
rated vertices. Then replacing the dark edges in the chain by the light edges 
v 7 
Figure 8.10 

226 
CONNECTIVITY AND MATCHING 
will give a matching M, with 
|M,| = |M| + 1. 
Note that Μ, = (Μ - P) U (Ρ - M). 
For example, in the graph of Fig. 8.9, consider the matching Μ = 
{e2, e 4}. There is an alternating chain es, e 4, e n , e2, and e 1 2 between the 
unsaturated vertices v3 and v7. If we replace in Μ the dark edges eA and e2 
by the light edges e5, e u , and e 1 2, we get the matching {e5, eu, e 1 2}, which 
has one more edge than M. 
Sufficiency 
Suppose Μ satisfies the conditions of the theorem. Let M' 
be a maximum matching. Then it follows from the necessity part of the 
theorem that Μ' also satisfies the conditions of the theorem, namely, there 
is no alternating chain between any vertices that are not saturated in Μ'. We 
now show that |M| = \M'\, thereby proving the sufficiency. 
Since Μ = (Μ Π Μ') U (Μ - Μ') and Μ' = (Μ Π Μ') U (Μ' - Μ), it is 
clear that |M| = |M'| if and only if |M - M'| = \M' - M\. 
Let G' be the graph on the edge set Μ Θ Μ' = (Μ - Μ') U (Μ' - Λί). 
Consider first a circuit in G'. By Theorem 8.19 such a circuit is of even 
length, and the edges in this circuit are alternately in Μ - Μ' and M' - Μ. 
Therefore each circuit in G' has the same number of edges from both 
M-M' 
and M' - M. 
Consider next a component of G' that is a path. Again, by Theorem 8.19, 
the edges in this path are alternately in M-M' 
and M' - M. Further the 
end vertices of this path are unsaturated in Μ or Μ'. Suppose the path is of 
odd length, then the end vertices of the path will be both unsaturated in the 
same matching. This would mean that with respect to one of these two 
matchings there is an alternating chain between two unsaturated vertices. 
But this is a contradiction because both Μ and Μ' satisfy the condition of 
the theorem. So each component of G' that is a path has an even number of 
edges, and hence it has the same number of edges from M-M' 
and 
M'-M. 
Thus each component of G' has an equal number of edges from 
M-M' 
and M'-M. 
Since the edges of G' constitute the set (Μ - Μ') U 
(Μ' - Μ), we get 
\M-M'\ 
= \M'-M\ 
, 
and so, |M| = |M'|. 
• 
Given a matching Μ in a graph G, let Ρ be an alternating chain between 
any two vertices that are not saturated in M. Then as we have seen before, 
Μ θ Ρ is a matching with one more edge than M. For this reason the path Ρ 
is called an augmenting path relative to M. 

MATCHINGS IN GENERAL GRAPHS 
227 
Next we prove two interesting results on bipartite graphs using the theory 
of alternating chains. 
Consider a bipartite graph G = (Χ, Υ, E) with maximum degree Δ. Let 
Xx denote the set of all the vertices in X of degree Δ. If G' is the bipartite 
graph (Xx, Γ(Α",), Ε'), where E' is the set of edges connecting Xx and 
Γ(λ",), then it can be seen from Corollary 8.16.1 that there exists in C a 
complete matching of Xx into Γ(ΧΧ). 
Such a matching clearly saturates all 
the vertices in Xx. Thus there exists a matching in G that saturates all the 
vertices in X of degree Δ. Similarly, there exists a matching in G that 
saturates all the vertices in Y of degree Δ. The question that now arises is 
whether in a bipartite graph there exists a matching that saturates all the 
maximum degree vertices in both X and Y. To answer this question, we 
need the following result due to Mendelsohn and Dulmage [8.22]. 
Theorem 8.21 (Mendelsohn and Dulmage). Let G = (Χ, Υ, E) be a bipartite 
graph, and let Λ/, be a matching that matches X,CX with Y, C Y (/ = 1,2). 
Then there exists a matching M' C Mx U M2 that saturates Xx and Y2. 
Proof. Consider the bipartite graph G' = (XlL)X2, 
Yx U Y2, M , U M 2 ) . 
Each vertex of this graph has degree 1 or 2; hence each component of this 
graph is either a path or a circuit whose edges are alternatively in M, and 
M2. (See proof of Theorem 8.19.) 
Each vertex yE.Y2-Yx 
has degree 1 in G'. So it is in a connected 
component that is a path Py from y to a vertex χ E X2 - Xx or to a vertex 
ζ G y, - Y2. In the former case the last edge of Py is in M2 and so Μ, Θ Py 
matches Xx U {x) with Yx U {y}. In the latter case the last edge of Py is in 
Mx and so Μ, Θ Py matches Xx with (y, - z) U {y}. In either case Μ, Θ Py 
saturates ΥΧΓ\Υ2. 
Thus Mx ΦPy saturates y E.Y2- 
Yx, and all the vertices 
in Xx and YXC\Y2. 
If we let 
P= 
U 
Py, 
y e Y
2 - Y , 
then we can see that Mx Θ Ρ is a matching that saturates A", and Y2. This is a 
required matching M' C MXU M2. 
• 
Theorem 8.22. In a bipartite graph there exists a matching that saturates all 
the maximum degree vertices. 
Proof. Consider a bipartite graph G = (Χ, Υ, E). Let X' CX and 
Y'CY 
contain all the vertices of maximum degree in G. As we have seen before, 
there exists a matching M, that saturates all the vertices in X' and a 
matching M2 that saturates all the vertices in Y'. So by Theorem 8.21, there 
exists a matching M' C Mx U M2 that saturates all the vertices in X' and Y'. 

228 
CONNECTIVITY AND MATCHING 
p 0(S) = |S|(mod2). 
(8.20) 
This is a required matching saturating all the maximum degree vertices in 
G. 
U 
Corollary 8.22.1. The set of edges of a bipartite graph with maximum degree 
Δ can be partitioned into Δ matchings. 
Proof. Consider a bipartite graph G = (X, Υ, E) with maximum degree Δ. 
By Theorem 8.22 there exists a matching A/, that saturates all the vertices of 
degree Δ. Then the bipartite graph G' = (Χ, Υ, Ε - A/,) has maximum 
degree Δ - 1. This graph contains a matching M2 that saturates every vertex 
of degree Δ - 1. By repeating this process we can construct a sequence of 
disjoint matchings A/,, A/ 2,..., ΑίΔ that form a partition of E. 
• 
An application of Theorems 8.21 and 8.22 and Corollary 8.22.1 is 
considered in Section 11.5. 
Now we return to our discussion of matchings in general graphs. 
A matching saturating all the vertices of a graph G is called a perfect 
matching of G. 
We conclude this section with a theorem due to Tutte [8.23] on the 
conditions for the existence of a perfect matching in a graph. Our proof here 
is due to Anderson [8.24]. 
A component of a graph is odd if it has an odd number of vertices; 
otherwise it is even. If S is a subset of vertices of a graph G, then we shall 
denote by p0(S) the number of odd components of G - S. 
Theorem 8.23 (Tutte). A graph G = (V, E) has a perfect matching if and 
only if 
p 0 ( 5 ) < | 5 | 
forallSCK. 
(8.19) 
Proof 
Necessity 
Suppose that G has a perfect matching M. For some S C V, let 
G,, G 2 , . . . ,Gk 
be the odd components of G - S. Since each G, is odd, 
some vertex u, of G, must be matched under A/ with some vertex v) of 5. 
Thus S has at least k vertices, and hence 
p 0 ( S ) < | 5 | . 
Sufficiency 
First note that if a graph G satisfies (8.19), then choosing 
5 = 0 we get po(0) 
^ 0. So in such a case there will be no odd components 
in G. In other words G will have an even number of vertices. 
Proof of sufficiency is by induction on /, where 2/= |V|. We use Hall's 
theorem (Theorem 8.13) and the simple fact that 

MATCHINGS IN GENERAL GRAPHS 
229 
The case / = 1 is trivial. Assume that the result is true for all graphs with 
less than 21 vertices. Consider then a graph G with 21 vertices and that 
satisfies (8.19). Now we have two cases. 
Case 1 
Suppose that p0(S) <\S\ for all 5, 2 < |5| < 21. 
Consider any edge e = (a, b) in G. Let A = [a, b) and GA = G — A. For 
any subset Τ of vertices of GA, let p'0(T) 
denote the number of odd 
components in GA - T. Thenp' 0(T) s |T\, for if p'0(T) >\T\, then we would 
get p0(T U A) = p'0(T) > I T\ = IΤ U A\ - 2, contradicting (8.19). Therefore, 
by induction, GA, and hence G, has a perfect matching 
Case 2 Let there be a set S such that p0(S) = \S\ s 2. Assume that 5 is a 
First observe that there are no even components in G - S. For if there were 
any, we could remove a vertex ν from one and add it to 5. This would 
necessarily give us at least one more odd component. So p0(S U v) s 
p0(S) 
+ 1 = \S\ + 1. Condition (8.19) requires that p0(S U v) <\S\ + 1. So 
p0(S U v) = \S\ + 1. But this would contradict the maximality of 5. Hence 
there are no even components in G - S. 
Let | 5 | = s, and let G,, G 2 , . . . , Gs be the s odd components of G - 5. 
We now show that we can take a vertex from each one of these odd 
components and match it with a vertex in S. If this is not possible, then by 
Hall's theorem, there are k odd components that are connected in G to only 
h < k vertices of 5. But if Τ denotes such a set of h vertices, we would then 
have 
contradicting (8.19). Thus we can take a vertex u, from each G,, 1 < / < J , 
and match it with a vertex in S. 
Now each G\ = G, — v, has an even number of vertices. The proof will be 
completed if we show that each G[ has a perfect matching. 
If G\ contains a set R of vertices such that p"0(R)> \R\, where p"0(R) is 
the number of odd components in G' - R, then by (8.20), p"0(R) a \R\ + 2, 
so that 
maximal such set. 
p0(T)>k>h 
= \T\ 
p0(RUSU{v,}) 
= p"0(R) + 
p0(S)-i 
>|/?| + |S| + 1 
= 
\RUSU{v,}\-
(8.21) 
But condition (8.19) requires that 
p0(RUSU{ 
u , } ) s | / l u 5 U { « , } ! . 

230 
CONNECTIVITY AND MATCHING 
8.8 
FURTHER READING 
Berge [8.26], Harary [8.8], Chartrand and Lesniak [8.27], and Bollobas 
[8.28] are general references recommended for further reading on connec-
tivity and matching. Berge also presents a detailed discussion on the 
realizability of degree sequences for the cases of both directed and undi-
rected graphs. Harary gives a historical account of Menger's theorem and its 
several variations. 
A communication network can be modeled by a graph. The concept of 
vulnerability arises in the study of such models. By vulnerability we mean 
the susceptibility of the network to attack. A network may be considered 
"destroyed" if after removal of some vertices or edges the resulting graph is 
not connected. Thus vulnerability of a network is related to the vertex and 
edge connectivities of the network. For example, a network TV, may be 
considered more vulnerable than a network N2 if the vertex connectivity of 
/V, is less than that of N2. 
Boesch [8.29] has several papers on the design of graphs having specified 
connectivity and reliability properties. Some of the early papers that deal 
with this topic include Hakimi [8.30], Boesch and Thomas [8.31], and Amin 
and Hakimi [8.32]. Frank and Frisch [8.33] is recommended for further 
reading on this topic. For some of the more recent works, see Krishnamoor-
thy, Thulasiraman, and Swamy [8.34] and [8.35], Bermond, Homobono, 
and Peyrat [8.36], Opatrny, Srinivasan, and Alagar [8.37], and Chung and 
Garey [8.38]. For a detailed review of combinatorial and algorithmic aspects 
of reliability, see Colbourn [8.39]. 
The problem of testing the connectivity of a graph and the problem of 
finding a maximum matching are closely related to that of finding a 
maximum flow in a transport network. This will be discussed in Chapter 12. 
The papers by Mirsky and Perfect [8.40], Brualdi [8.41], and the book by 
Mirsky [8.42] are highly recommended for further reading on matchings and 
transversal theory. Applications involving the theory of matchings (in 
particular, the optimal assignment problem and a time-tabling problem) and 
related algorithms are discussed in Chapter 11. 
So 
p 0 ( * U S U { u ( } ) = | * U S U { u , } | 
contradicting the maximality of S. Thus by induction, G\ has a perfect 
matching. 
• 
Lovasz [8.25] gives an alternative proof of Theorem 8.23 using Theorem 
8.20. 

EXERCISES 
231 
8.9 
EXERCISES 
8.1 
Let ί ί , < ( 1 2 < · · · < ^ denote the degrees of a simple graph G. Show 
that G is &-connected, k<n, 
if 
(a) d(vr) > r + k - 1, r < 
; and 
(b) d ( u n - * + , ) ^ 
. 
8.2 
Show that a simple η-vertex graph G is Α-connected if 
6
(
G
)
a
u
±
!
^
. 
8.3 
Let 
G = (Κ, E) 
be 
a 
simple 
^-connected 
graph. 
Let 
Β = 
[bx, b2,..., 
bk} be a set of vertices with \B\ - k. If a Ε V- Β, show 
that there exist k vertex-disjoint a-bt paths from a to B. 
8.4 
Let G be a simple A:-connected graph with k a: 2. Show that there 
exists a circuit that passes through an arbitrary set of two edges e, and 
e2 and k - 2 vertices. 
8.5 
Let G be a /c-connected graph with k > 2. Then prove that every A 
vertices of G lie on a circuit of G. 
8.6 
Prove that a simple graph G with n s 2 vertices is A-edge-connected if 
and only if for every two distinct vertices u and ν of G, there exist at 
least A: edge-disjoint u-v paths in G. 
(Note: This is the edge analog of Theorem 8.10.) 
8.7 
Show that K(Hkn) 
= K'(Hkn) 
= k. 
8.8 
Find a 5-connected graph with 7 vertices and 18 edges. 
8.9 
Show that the edges of a simple graph G can be oriented to form a 
strongly connected graph if and only if G is 2-edge-connected. 
8.10 The associated directed graph D(G) of an undirected graph G is the 
graph obtained by replacing each edge e of G by two oppositely 
oriented edges having the same end vertices as e. Show that: 
(a) There is a one-to-one correspondence between paths in G and 
directed paths in D(G). 
(b) D(G) is A:-edge-connected if and only if G is fc-edge-connected. 
(Note: A directed graph G is k-edge-connected if and only if at 
least k edges have to be removed to destroy all directed s-t paths for 
any two vertices s and t of G.) 
8.11 Find a simple graph having the degree sequence (5, 4, 4, 4, 3, 3, 3, 3, 
3) and with the largest possible edge connectivity. 

232 
CONNECTIVITY AND MATCHING 
8.12 Show that a sequence (d,, d 2 , . . . , d„) of nonnegative integers is the 
degree sequence of a tree if and only if 
d, > 1 for all i, 
and 
π 
Σ d, = 2(n - 1). 
1 = 1 
8.13 Show that a sequence (d,, d 2 , . . . , d„) of nonnegative integers is the 
degree sequence of a graph if and only if Σ" = 1 d, is even (Hakimi 
[8.4]). 
8.14 Show that a sequence (d,, d 2 , . . . , d„) of nonnegative integers is the 
degree sequence of a simple graph if and only if 
(a) Σ d, is even; and 
1=1 
* 
π 
(b) Σ d,,== k(k - 1) + Σ 
min{fc, d,} 
f o r l < A : < w - l . 
i=l 
i = * + l 
(Erdos and Gallai [8.7]). 
8.15 Show that a sequence (d,, d 2 , . . . , d„) (realizable by a simple graph) 
is the degree sequence of a simple Λ-connected graph if and only if 
(a) d, > k for 1 < i < Λ , 
(b) m - 2J d, +
 1 
^
 
1 
>n-k, 
where m is the number of edges of G. (Wang and Kleitman [8.6]). 
8.16 Prove or disprove: For every matching Μ there exists a maximum 
matching M' such that Μ C Μ'. 
8.17 Prove that every 3-regular graph without bridges has a perfect 
matching. 
8.18 Prove that if G is a Ar-regular bipartite graph with k > 0, then G has a 
perfect matching. 
8.19 A nonnegative real square matrix Ρ is doubly stochastic if the sum of 
the entries in each row of Ρ is 1 and the sum of the entries in each 
column of Ρ is 1. A permutation matrix is a (0,1) matrix that has 
exactly one 1 in each row and each column. Show that a doubly 
stochastic matrix Ρ can be expressed as 

EXERCISES 
233 
P = c,P, + c2P2 + ·•• + ckPk , 
where each P, is a permutation matrix, each c, is a nonnegative real 
number, and Ef=1 c, = 1. 
8.20 Let G be a bipartite graph with bipartition (X, Y). If G has a 
complete matching of X into Y, show that there exists an x0 G X, such 
that for each y G Γ(χ 0) at least one maximum matching uses the edge 
(*<» y)-
8.21 A k-factor of a graph G is a Ac-regular spanning subgraph of G. 
Clearly a 1-factor is a perfect matching. G is k-factorable if G is the 
union of some edge-disjoint Α-factors. Show that Knn 
and K2n are 
1-factorable. 
8.22 
(a) Show that K2n+1 
can be expressed as the union of η connected 
2-factors ( n ^ l ) . 
(Note: A connected 2-factor is a Hamilton circuit.) 
(b) Show that K2n is the union of a 1-factor and (η -1) 
connected 
2-factors. 
8.23 
Show that a connected graph G is 2-factorable if and only if it is 
regular with even degree. 
8.24 
Let Μ and Ν be two edge-disjoint matchings of a graph G with 
|Λί|>|Ν|. Show that there are disjoint matchings M' and N' with 
|M'| = | M | - 1 and |ΛΤ| = |JV| + 1, and M'l)N' 
= MlSN. 
8.25 
If G = (V, E) is a bipartite graph and A a Δ, then show that there 
exist A disjoint matchings Mx, M2,..., 
Mk of G such that 
where m is the number of edges of G. 
8.26 Show that a tree Τ has a perfect matching if and only if p0(v) = 1 for 
all vertices υ in Γ, where p0(v) is the number of odd components of 
8.27 Derive Hall's theorem from Tutte's theorem. 
8.28 
Derive Hall's theorem from Menger's theorem (see Wilson [8.43], 
Theorem 28d). 
£ = M
1 U M
2 U " - U M
t 
and for 1 < / < A, 
T-v. 

234 
CONNECTIVITY AND MATCHING 
8.10 REFERENCES 
8.1 
F. Harary, "The Maximum Connectivity of a Graph." Proc. Nat. Acad. Sci., 
U.S., Vol. 48, 1142-1146 (1962). 
8.2 
J. A. Bondy, "Properties of Graphs with Constraints on Degrees," Studia Sci. 
Math. Hung., Vol. 4, 473-475 (1969). 
8.3 
G. Chartrand, "A Graph Theoretic Approach to a Communication Problem," 
SI A Μ J. Appl. Math., Vol. 14, 778-781 (1966). 
8.4 
S. L. Hakimi, "On the Realizability of a Set of Integers as Degrees of the 
Vertices of a Graph," SIAMJ. Appl. Math., Vol. 10, 496-506 (1962). 
8.5 
V. Havel, "A Remark on the Existence of Finite Graphs" (in Hungarian), 
Casopois Pest. Math., Vol. 80, 477-480 (1955). 
8.6 
D. L. Wang and D. J. Kleitman, "On the Existence of η-Connected Graphs 
with Prescribed Degrees («2=2)," Networks, Vol. 3, 225-239 (1973). 
8.7 
P. Erdos and T. Gallai, "Graphs with Prescribed Degrees of Vertices" (in 
Hungarian), Mat. Lapok, Vol. 11, 264-274 (1960). 
8.8 
F. Harary, Graph Theory, Addison-Wesley, Reading, Mass., 1969. 
8.9 
J. Edmonds, "Existence of λ-Edge-Connected Ordinary Graphs with Pre-
scribed Degrees," /. Res. Nat. Bur. Stand. B., Vol. 68, 73-74 (1964). 
8.10 D. L. Wang and D. J. Kleitman, "A Note on κ-Edge Connectivity," SI AM J. 
Appl. Math., Vol. 26, 313-314 (1974). 
8.11 K. Menger, "Zur allgemeinen Kurventheorie," Fund. Math., Vol. 10, 96-115 
(1927). 
8.12 H. Whitney, "Congruent Graphs and the Connectivity of Graphs," Am. J. 
Math., Vol. 54, 150-168 (1932). 
8.13 W. T. Tutte, "A Theory of 3-Connected Graphs," Indag. Math., Vol. 23, 
441-455 (1961). 
8.14 L. R. Ford and D. R. Fulkerson, "Maximal Flow Through a Network," 
Canad. J. Math., Vol. 8, 399-404 (1956). 
8.15 P. Elias, A. Feinstein, and C. E. Shannon, "A Note on the Maximum Flow 
Through a Network," IRE Trans. Inform. Theory, IT-2, 117-119 (1956). 
8.16 P. Hall, "On Representatives of Subsets," J. London Math. Soc, Vol. 10, 
26-30 (1935). 
8.17 P. R. Halmos and Η. E. Vaughan, "The Marriage Problem," Am. J. Math., 
Vol. 72, 214-215 (1950). 
8.18 D. Konig, "Graphs and Matrices" (in Hungarian), Mat. Fiz. Lapok, Vol. 38, 
116-119 (1931). 
8.19 O. Ore, "Graphs and Matching Theorems," Duke Math. J., Vol. 22, 625-639 
(1955). 
8.20 R. Rado, "Note on the Transflnite Case of Hall's Theorem on Representa-
tives," J. London Math. Soc, Vol. 42, 321-324 (1967). 
8.21 C. Berge, "Two Theorems in Graph Theory," Proc. Nat. Acad. Sci. U.S., 
Vol. 43, 842-844 (1957). 
8.22 N. S. Mendelsohn and A. L. Dulmage, "Some Generalizations of the Problem 
of Distinct Representatives," Canad. J. Math., Vol. 10, 230-241 (1958). 

REFERENCES 
235 
8.23 W. Τ. Tutte, "The Factorization of Linear Graphs," J. London Math. Soc, 
Vol. 22, 107-111 (1947). 
8.24 I. Anderson, "Perfect Matchings of a Graph," J. Combinatorial Theory B, 
Vol. 10, 183-186 (1971). 
8.25 L. Lovasz, "Three Short Proofs in Graph Theory," /. Combinatorial Theory 
B, Vol. 19, 111-113 (1975). 
8.26 C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
8.27 G. Chartrand and L. Lesniak, Graphs and Digraphs, Wadsworth and Brooks/ 
Cole, Pacific Grove, Calif., 1986. 
8.28 B. Bollobas, Graph Theory: An Introductory Course,'Springer-Verlag, New 
York, 1979. 
8.29 F. T. Boesch, Ed., Large-Scale Networks: Theory and Design, IEEE Press, 
New York, 1976. 
8.30 S. L. Hakimi, "An Algorithm for Construction of Least Vulnerable Communi-
cation Networks or the Graph with the Maximum Connectivity," IEEE Trans. 
Circuit Theory, Vol. CT-16, 229-230 (1969). 
8.31 F. T. Boesch and R. E. Thomas, "On Graphs of Invulnerable Communication 
Nets," IEEE Trans. Circuit Theory, Vol. CT-17, 183-192 (1970). 
8.32 A. T. Amin and S. L. Hakimi, "Graphs with Given Connectivity and 
Independence Number or Networks with Given Measures of Vulnerability and 
Survivability," IEEE Trans. Circuit Theory, Vol. CT-20, 2-10 (1973). 
8.33 H. Frank and I. T. Frisch, Communication, Transmission, and Transportation 
Networks, Addison-Wesley, Reading, Mass. 1971. 
8.34 V. Krishnamoorthy, K. Thulasiraman, and Μ. N. S. Swamy, "Minimum-
Order Graphs with Prescribed Diameter, Connectivity and Regularity," Net-
works, Vol. 19, 25-46 (1989). 
8.35 V. Krishnamoorthy, K. Thulasiraman, and Μ. N. S. Swamy, "Incremental 
Distance and Diameter Sequences of a Graph: New Measures of Network 
Performance," IEEE Trans. Computer, Vol. 39, 230-237 (1990). 
8.36 J. C. Bermond, N. Homobono, and C. Peyrat, "Large Fault-Tolerant Inter-
connection Networks," Graphs and Combinatorics, Vol. 5, 107-123 (1989). 
8.37 J. Opatrny, N. Srinivasan, and V. S. Alagar, "Highly Fault-Tolerant Com-
munication Network Models," IEEE Trans. Circuits and Systems, Vol. 30, 
23-30 (1989). 
8.38 F. R. K. Chung and M. R. Garey, "Diameter Bounds for Altered Graphs," J. 
Graph Theory, Vol. 8, 511-534 (1984). 
8.39 C. J. Colbourn, The Combinatorics of Network Reliability, Oxford University 
Press, Oxford, 1987. 
8.40 L. Mirsky and H. Perfect, "Systems of Representatives," J. Math. Anal. 
Applic, Vol. 15, 520-568 (1966). 
8.41 R. A. Brualdi, "Transversal Theory and Graphs," in Studies in Graph Theory, 
Part II, MAA Press, 1975, Washington, D.C., pp. 23-88. 
8.42 L. Mirsky, Transversal Theory, Academic Press, New York, 1971. 
8.43 R. J. Wilson, Introduction to Graph Theory, Oliver and Boyd, Edinburgh, 
1972. 

CHAPTER 9 
COVERING AND COLORING 
In the previous chapters we defined several useful parameters associated 
with a graph, namely, rank, nullity, connectivity, matching number, and so 
on. As we mentioned earlier, rank and nullity arise in the study of electrical 
networks. Connectivity arises in the study of communication nets. In this 
chapter we study several other useful parameters of a graph—vertex in-
dependence number, vertex and edge covering numbers, chromatic index, 
and chromatic number. We begin with a discussion of the vertex independ-
ence number and the vertex and edge covering numbers. We relate these 
numbers to the matching number defined in the previous chapter and 
develop equivalent formulations of Hall's theorem. Then we study the 
chromatic index and the chromatic number, which relate to the vertex and 
edge colorability properties of a graph. 
The parameters to be discussed in this chapter arise in the study of 
several practical problems such as timetable scheduling and communication 
net design. 
9.1 
INDEPENDENT SETS AND VERTEX COVERS 
Consider a graph G = (V, E). A subset S of V is an independent set of G if 
no two vertices of 5 are adjacent in G. An independent set is also called a 
stable set. 
An independent set S of G is maximum if G has no independent set 5' 
with |S"| > 
The number of vertices in a maximum independent set of G 
is called the independence number (stability number) of G and is denoted by 
«o(G). 
236 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

INDEPENDENT SETS AND VERTEX COVERS 
237 
b 
e 
Figure 9.1 
For example, in the graph of Fig. 9.1, the sets {b, d), {b, /}, {a, c), and 
{b, d, / } are independent sets. Of these, [b, d) and {b, / } are not maximal 
independent sets; {a, c) is maximal but it is not maximum; {b, d, / } is 
maximum. 
A subset Κ of V is a vertex cover of G if every edge of G has at least one 
end vertex in K. If we consider a vertex as covering all the edges incident on 
it, then a vertex cover of G is a subset of V that covers all the edges of G. 
A vertex cover Κ of G is minimum if G has no vertex cover K' with 
\K'\ < \ K\. The number of vertices in a minimum vertex cover of G is called 
the vertex covering number of G and is denoted by 
β0(ΰ). 
For example, in the graph of Fig. 9.1, the sets (a, c, e, /}, [a, c, d, e), 
{b,d,e,f}, 
and {a, c, e) are vertex covers. Of these, {a,c,e,f} 
and 
{a, c, d, e) are not minimal; {b, d, e, / } is minimal but not minimum; 
{a,c,e} 
is minimum. 
aQ(G) 
and fi0(G) will be denoted simply as a0 and β0, respectively, 
whenever the graph G under consideration is clear from the context. Recall 
that a,(G) is the number of edges in a maximum matching of G. 
Independent sets and vertex covers are closely related concepts, as we 
show in the following theorem. 
Theorem 9.1. Consider a graph G = (V, E). A subset_S of V is an in-
dependent set of G if and only if the complement 5 of S in V (i.e., 
S = V- S) is a vertex cover of G. 
Proof. By definition 5 is an independent set of G if and only if no edge of G 
has both its end vertices in S. In other words S is anjndependent set if and 
only if every edge of G has at least one end vertex in 5, the complement of S 
in V. The theorem now follows from the definition of a vertex cover. 
• 
Corollary 9.1.1. For a simple η-vertex graph, aQ + β0 = η. 

238 
COVERING AND COLORING 
Proof. Consider a maximum independent set 5* and a minimum vertex 
cover Κ * of a graph G = (V, E). Then 
\S*\ = «o 
and 
1*1 = A,. 
By Theorem 9.1, 5* = V-S* 
is a vertex cover and Έ* = V- K* is an 
independent set. Therefore, 
|5*| = | V - 5 * | = n - a 0 > / 3 0 
and 
\Κ*\ = \ν-Κ*\ 
= 
η-β0^α0. 
Combining these inequalities, we get 
«ο + A) = η . 
* 
Consider any maximum matching M* and any minimum vertex cover K* 
in a graph G. Since at least \M*\ vertices are required to cover the edges of 
Λί*, the vertex cover K* must contain at least \M*\ vertices. Therefore, 
\M*\<\K*\. 
(9.1) 
In general, equality does not hold in (9.1). However, we show in the 
following theorem that \M*\ = \K*\ if G is a bipartite graph. 
Theorem 9.2. For a bipartite graph the number of edges in a maximum 
matching equals the number of vertices in a minimum vertex cover, that is, 
«, = A,-
Proof. Let M* be a maximum matching and K* a minimum vertex cover in 
a bipartite graph G = (X, 
Y,E). 
Consider any subset A of X. Each edge e of G is incident on either a 
vertex in A or a vertex in X - A. Further, any edge incident on a vertex in 
A is also incident on a vertex in Γ(Α), the set of vertices adjacent to those in 
A. Thus the set (X - A) U Γ(Α) is a vertex cover of G, and hence 
\{Χ-Α)\ 
+ 
\Γ(Α)\*\Κ·\ 

INDEPENDENT SETS AND VERTEX COVERS 
239 
But from Hall's theorem (Theorem 8.13), 
|M*| = min {\X-A\ 
+ \T(A)\} *\K*\. 
(9.2) 
Now combining (9.1) and (9.2), we get 
\M*\ 
= \K*\. m 
Theorem 9.2 is due to Konig [9.1]. 
We established in Theorem 8.20 a characterization of a maximum match-
ing using the concept of an alternating chain. Since an independent set is the 
vertex analog of a matching, a similar characterization may be expected to 
exist in the case of a maximum independent set too. This is indeed true, and 
in the following we develop such a characterization. We follow the treat-
ment given in Berge [9.2]. 
Let us first define an alternating sequence, the vertex analog of an 
alternating chain. 
Let Y be an independent set of a graph G = (V, E). An alternating 
sequence relative to Y is a sequence 
<r={Xu 
yx,x2> 
3
, 2 - · · · } 
of distinct vertices alternately belonging to X = Υ = V- Y and Y such that 
the following conditions are satisfied: 
1. 
J C , G X , y , E Y . 
2. y, is adjacent to at least one vertex in the set [xl,x2,... 
,x,}. 
3. 
JC, + 1 is not adjacent to any vertex in {*,, x2,..., 
J C , } . 
4. 
is adjacent to at least one vertex in {y t, y2,..., 
y,}. 
An alternating sequence is maximal if no more vertices can be added to it 
without violating these conditions. 
For example, in the graph of Fig. 9.1, the sequence {/, a, b, c) is a 
maximal alternating sequence relative to the independent set {a, c}. 
Consider a tree T. Recall (Exercise 2.2) that Τ is bipartite, that is, its 
vertex V set can be partitioned into two subsets X and Y such that: 
1. V= XL) Y. 
2. χ η y = 0 . 
3. X and Y are both independent sets in the tree. 
We shall refer to (X, Y) as a bipartition of the vertex set of T, and the 
vertices of X and Y as X- and Y-vertices, respectively. 

240 
COVERING AND COLORING 
As a first step toward the development of a characterization of a 
maximum independent set in terms of an alternating sequence, we now 
show that if \X\ > | Y\ in a tree, then there is an alternating sequence relative 
to Y using all the vertices of Y. To do so we need the following lemma. 
Lemma 9.1. Let (X, Y) be a bipartition of the vertex set of a tree T. If 
\X\ = \Y\ + ρ, ρ > 0 , then X contains at least ρ + 1 pendant vertices of T. 
Proof. Proof is by induction on the number η of vertices of T. Clearly, the 
lemma is true for η = 2, 3, 4. Let the result be valid for all trees having 
fewer than η vertices, η > 5. 
Consider an η-vertex tree Τ with | A"| = | Y\ + p. Let υ be a pendant vertex 
of Τ and let 
T' = T-{v} 
. 
Note that 7" is a tree with η- I vertices. 
Suppose υ is an AT-vertex. If ρ = 0, then υ is the required Z-vertex of T. 
Otherwise, by the induction hypothesis, at least ρ pendant vertices of T' are 
A'-vertices. These ρ vertices are also pendant in Τ and hence they, along 
with υ, are the required A'-vertices for T. 
Proof is immediate if υ is a Y-vertex. 
• 
Lemma 9.2. Let (Χ, Y) be a bipartition of the vertex set of a tree T. 
1. If |A"| = |y| or |A"| = |y| + l, then there is an alternating sequence 
i
x\> )>i>
 x2< y2' · • •}
 t n a t uses each vertex of Τ exactly once. 
2. If |A"| > I Y| + 1, then there is a maximal alternating sequence of odd 
length {*,, yx,...,} 
that uses each vertex of Y exactly once. 
Proof 
1. The result is true for a tree with 2 vertices. Assume the result to be 
true for any tree with 2k vertices. Consider then a tree Γ with 2k + 1 
vertices and |Al = | Y| + 1. Then, by the previous lemma, there exists 
in Τ a pendant vertex xk 
+ iE.X. Let 7" = Τ - {xk 
+ , } . By the induction 
hypothesis, there is in T' an alternating sequence {*,, y
x , . . . , 
yk) 
that 
uses 
all the 
vertices 
of 
7". Therefore 
the 
sequence 
{*,, y
x , . . . , y k , xk+l) 
is a required sequence for T. (Note that this 
sequence is of odd length.) 
Next assume the result to be valid for any tree with 2k + 1 vertices. 
Consider a tree Τ with 2k+ 2 vertices and |A"| = |Y|. Then by the 
previous lemma, there exists in Γ a pendant vertex yk+lE. 
Y. Let 
T' = Τ - {yk+l}. 
Now, by the induction hypothesis, there is an alter-
nating sequence {xx, y x , • • • ,xk+i) 
that uses all the vertices of T'. 

INDEPENDENT SETS AND VERTEX COVERS 
241 
Therefore the sequence {*,, y,, ... ,xk+1, 
yk+l} 
is a required se-
quence for T. 
2. If | A | > | Y | + 1, remove from Γ as many pendant X-vertices 
as 
necessary until we get a tree Τ in which the number of A"-vertices is 
one more than the number of Y-vertices. By the previous lemma, this 
is always possible. 
Now, by the result of part 1 of the lemma, there exists a maximal 
alternating sequence of odd length that uses all the vertices of T' and 
hence all the Y-vertices of T. 
• 
For example, in the tree of Τ of Fig. 9.2, {xl,yl, 
x2, y2, x3, y 3, * 4, y4, xs> 
ys> *6> ^ 6 ' ^ 7 } '
s alternating sequence that uses all the Y-vertices of T. 
We now state and prove a characterization of a maximum independent 
set in terms of an alternating sequence. 
Theorem 9.3. An independent set Y in a graph G is maximum if and only if 
in G there exists no maximal alternating sequence of odd length relative to 
Y. 
Proof 
Necessity 
Consider a graph G = (V, E). 
Let Y be a maximum in-
dependent set in G and X=V- 
Y. 
Suppose there exists a maximal alternating sequence σ of odd length 
relative to Y, and let 
σ = CTJ U σ2, 
*8 
*, o-
Figure 9.2 

242 
COVERING AND COLORING 
where 
tr2 = σ Π Υ 
and 
σχ = σ Π Χ . 
Note that since σ is of odd length, |σ,| > \σ2\, and the last vertex of σ is 
an A"-vertex. Furthermore, since σ is maximal, no vertex yt ε Υ - σ2 can be 
added to σ without violating condition 2 in the definition of an alternating 
sequence. 
Thus no vertex y £ Υ - σ2 is adjacent to any vertex χ, Ε σ,. Since σχ and 
(Υ - σ 2) are themselves independent sets, it follows that (Υ - σ2) U σχ is an 
independent set. So, 
| ( y - a
2 ) u
f
f
l | > | ( y - ^ ) | + |a 2| = | y | , 
contradicting that Y is a maximum independent set. 
Sufficiency 
Let A" be a maximum independent set and Y an independent 
set with | y | < |A*|. We now show that there exists an alternating sequence of 
odd length relative to Y. Let 
y 0 = y - ( A - n y ) , 
χ0 = 
χ-(χηγ), 
and let G 0 be the induced subgraph of G on the vertex set (AO U Y0). If G0 
is not connected, then let Gx, G2,..., 
Gk be the connected components of 
G 0 with (X, U y,) as the vertex set of G,. Note that 
υ 
χ, = 
1 = 1 
and 
ύ Υ, = y 0 · 
1 = 1 
Since |AT| > \ Y \ , \X0\ >\Y0\. Therefore for some i, \X,\>\Y,\. 
Let, without 
loss of generality, / = 1. 
Now let Γ be a spanning tree of Gx. Clearly, (A^, Yx) is a bipartition of 
the vertex set of T. Since \XX\ > \YX\, by the previous lemma there exists in 
G, a maximal alternating sequence σ (relative to Yx) of odd length that uses 
all the vertices of Yx. Clearly σ is an alternating sequence of odd length 
relative to Y for G also. We now show that σ is a maximal such sequence in 
G. 

EDGE COVERS 
243 
Note that the A'-vertices and y-vertices of σ belong to X0 and 
Y0, 
respectively. 
Consider any Y-vertex y, that is not in σ. Two cases now arise. 
Case 1 
y^YHX. 
In this case yt is not adjacent to A'-vertices. In particular yt is not adjacent to 
any A"-vertex of σ. 
Case 2 
yt Ε Y0. 
In this case yf is not in G, because σ contains all the y-vertices of G,. Hence 
yt is not adjacent to any of the vertices of G,. In particular _y; is not adjacent 
to any A'-vertex of σ. 
Thus in both the cases, y] cannot be used to extend σ. Therefore, for G, σ 
is a maximal alternating sequence of odd length relative to Y. 
• 
For example, consider the independent set Y = {a, c} in the graph of Fig. 
9.1. This is not maximum, and it may be verified that {d, c, b, a, / } is a 
maximal alternating sequence of odd length relative to Y. 
9.2 
EDGE COVERS 
Consider a graph G = (V, E). A subset Ρ of Ε is an edge cover of G if every 
vertex of G is an end vertex of at least one of the edges of P. If we consider 
an edge as covering its end vertices, then an edge cover is a subset of edges 
covering all the vertices of G. 
An edge cover Ρ of G is minimum 
if G has no edge cover P' with 
\P' \ < \ P\. The number of edges in a minimum edge cover of G is called the 
edge covering number of G and is denoted by S^G). 
For example, in the graph of Fig. 9.1, the set {ex, e 3, e5} is a minimum 
edge cover. 
Note that the vertex covering number and the edge covering number are 
denoted by β0 and /3,, respectively; similarly the independence number and 
matching number are denoted by a0 and a,, respectively. 
In the following we use the same symbol to denote an edge cover as well 
as the induced subgraph on the edges of the cover. 
Suppose that an edge cover Ρ is minimal. Then it is easy to verify that Ρ 
has neither circuits nor paths of length greater than 2. This means that each 
component of Ρ is a tree in which all the edges are incident on a common 
vertex. 
In the next theorem, which is the edge analog of Corollary 9.1.1, we 
relate a t and βχ. This result is due to Gallai [9.3]. 

244 
COVERING AND COLORING 
Theorem 9.4. For a simple η-vertex graph G without isolated vertices, 
α, + β, = η . 
Proof. Let M* be a maximum matching and P* a minimum edge cover of 
G. Let N(M*) denote the set of vertices that are not saturated in M*. Then 
|/V(M*)| = η - 2α,. Now, for each vertex υ in N(M*), select an edge that is 
incident on υ and adjacent to an edge in M*. Let Pa be the set of (η - 2a,) 
edges so selected. Then it is clear that the set Ρ = Μ* U Pa is an edge cover 
and 
\P\ = α, + η — 2a, = η - a, . 
Thus 
fl, = | P * | < | F | = n - a , , 
so that 
a, + fl, < η . 
(9.3) 
Now let P* have r connected components so that 
β
ί = | ρ · | = „ - 
r . 
Select one edge from each one of the r components of P. Let Μ be the set of 
r edges so chosen. It is clear that Μ is a matching, and so 
a, = |M*|>|M| = r = n - / 3 , . 
Thus 
a, + β, > η . 
(9.4) 
Combining (9.3) and (9.4), we get 
α, + β, = η . 
• 
Consider a maximum independent set 5* and a minimum edge cover P* 
in a graph G with no isolated vertices. Since 
edges are required to cover 
the vertices of S*, any edge cover must contain at least |S*| edges. Thus 
|S*|<|P*|. 
(9.5) 
In general, equality does not hold in (9.5). However, when a graph G is 

EDGE COLORING AND CHROMATIC INDEX 
245 
bipartite, |S*| = |P*|, and this we prove in the next theorem, which is 
analogous to Theorem 9.2. 
Theorem 9.5. In a bipartite graph G, without isolated vertices, the number 
of vertices in a maximum independent set is equal to the number of edges in 
a minimum edge cover, that is, 
« o = 
0 i 
· 
Proof. Let G have η vertices. Then by Corollary 9.1.1, aQ = η — β0, and by 
Theorem 9.4, β, = η - α,. But by Theorem 9.2, αχ - β0. So we get a0 -
βν 
• 
Theorems 9.2 and 9.5 are both equivalent formulations of Hall's theorem 
(Exercises 9.5 and 9.6). 
9.3 
EDGE COLORING AND CHROMATIC INDEX 
A k-edge coloring of a graph is the assignment of k distinct colors to the 
edges of the graph. An edge coloring is proper if in the coloring no two 
adjacent edges receive the same color. A 3-edge coloring and a proper 
4-edge coloring of a graph are shown in Fig. 9.3. A graph is k-edge colorable 
if it has a proper k-edge coloring. 
We shall assume, without any loss of generality, that the graphs to be 
considered in this section have no self-loops. 
The chromatic index or the edge chromatic number x'(G) of a graph G is 
the minimum k for which G has a proper A:-edge coloring. Graph G is k-edge 
chromatic if x'{G) = k. It may verified that the chromatic index of the graph 
of Fig. 9.3a is 4. 
It may be seen that a k-edge coloring of a graph G = (V, E) induces the 
partition (£,, E2,..., 
Ek) of E, where E, denotes the subset of edges that 
are assigned the color i in the coloring. Similarly every partition of Ε into A: 
subsets corresponds to a A:-edge coloring of G. So we shall often denote an 
edge coloring by the partition of G it induces. 
If a coloring % = (£,, E2,..., 
Ek) is proper, then each £, is a matching. 
Therefore x'(G) may be regarded as the smallest number of matchings into 
which the edge set of G can be partitioned. This interpretation of x'(G) will 
be helpful in the proof of certain useful results. 
Since in any proper coloring the edges incident on a vertex should receive 
different colors, it follows that 
X'(G)*A, 
(9.6) 
where Δ is the maximum degree in G. 

246 
COVERING AND COLORING 
a 
Figure 9.3. Edge coloring (numbers indicate col-
ors), (a) A proper 4-edge coloring, (b) A 3-edge 
coloring. 
In general x'(G) τ^Δ. However, in the case of a bipartite graph χ' = Δ. 
Theorem 9.6. For a bipartite graph χ' = Δ. 
Proof. By Corollary 8.22.1, the edge set of a bipartite graph G can be 
partitioned into Δ matchings. Thus 
x'(G) — ^ · 
Combining this with (9.6) proves the theorem. 
• 
Though Δ colors are not, in general, sufficient to properly color the edges 
of a graph. Vizing [9.4] has shown that for any simple graph Δ + 1 colors are 
sufficient. To prove Vizing's theorem we need to establish a few basic 
results. 

EDGE COLORING AND CHROMATIC INDEX 
247 
We shall say that, in a coloring, color i is represented at vertex υ if in the 
coloring at least one of the edges incident on υ is assigned the color i. The 
number of distinct colors represented at vertex ν will be denoted by c(u). 
For example, in the coloring shown in Fig. 9.36, 
c(/) = 2. 
We now consider the question of existence of 2-edge colorings of a graph 
in which c(v) = 2 for every vertex υ in the graph. 
Lemma 9.3. Let G be a connected graph that is not a circuit of odd length. 
Then G has a 2-edge coloring in which both colors are represented at each 
vertex of degree at least 2. 
Proof 
Case 1 
G is Eulerian. 
If G is a circuit, then by the hypothesis of the theorem it must be of even 
length. In such a case it is easy to verify that G has a 2-edge coloring having 
the required property. 
If G is not a circuit, then it must have a vertex i>0 of degree at least 4. Let 
ϋ 0 >
 
e\>
 
V l >
 e2'
 
V2>
 
e3> 
• • • '
em>
 
V 0 
be an Euler trail and let 
£, = {e,|i odd} 
and 
E2 = {e\i even} . 
(9.7) 
Then (£,, E2) is a 2-edge coloring in which at every vertex both colors are 
represented because in the Euler trail considered every vertex including v0 
appears as an internal vertex. 
Case 2 
G is not Eulerian. 
In this case G must have an even number of odd vertices. Now construct an 
Eulerian graph G' by adding a new vertex v0 and connecting it to every 
vertex of odd degree in G. Let v0, e,, u,,..., em, v0 be an Euler trail in G'. 
If £, and E2 are defined as in (9.7), then (£,, E2) is a 2-edge coloring of G' 
in which both colors are represented at each vertex of G. It may now be 
verified that (£, Π Ε, E2 Π Ε) is a 2-edge coloring of G in which both colors 
are represented at each vertex of degree at least 2. 
• 
A k-edge coloring £ of a graph G = (V, E) is optimum if there is no other 
A>edge coloring %' of G such that 

248 
COVERING AND COLORING 
Σ Φ ) < Σ C(t>) , 
u e v 
u e v 
where φ ) and c'(v) are the number of distinct colors represented at vertex 
υ in the colorings % and %', respectively. 
Clearly, in any coloring Έ, φ ) s d(v) for every vertex v. Further, for 
every υ, φ ) = d(v) if and only if % is a proper coloring. 
A useful result on the nature of an optimum coloring is presented next. 
Lemma 9.4. Let Έ = (£,, E2,..., 
Ek) be an optimum A;-edge coloring of a 
graph G = (V, E). Suppose that there is a vertex u in G and there are two 
colors i and j such that i is not represented at u and j is represented twice at 
u. Let G' be the induced subgraph of G on the edge set Et U Er Then the 
component Η of G' containing the vertex u is a circuit of odd length. 
Proof. If Η is not a circuit of odd length, then, by Lemma 9.3, there is a 
2-edge coloring of Η in which both colors ι and / are represented at each 
vertex of degree at least 2 in H. 
If we use this 2-edge coloring to recolor the edges of Η and leave the 
colors of the other edges of G unaltered as they are in %, then we get a new 
A-edge coloring %' in which both colors i a n d a r e represented at vertex u. 
Hence, 
c'(u) = c(«) + 1 , 
where c'(u) is the number of distinct colors represented at vertex u in the 
coloring Έ'. Further, for every vertex υ Φ u, 
c'(v) > φ ) . 
Hence 
Σ c(v) > Σ Φ ) , 
vev 
vev 
contradicting that % is an optimum edge coloring. Thus it follows that Η is a 
circuit of odd length. 
• 
A Α-edge coloring %' is an improvement on the Α-edge coloring % if 
Σ c'(v) > Σ Φ ) · 
u e v 
u e v 
We now prove Vizing's theorem [9.4]. Our proof is due to Fournier [9.5]. 
We follow the treatment given in Bondy and Murty [9.6]. 
Theorem 9.7 (Vizing). If G = (V, E) is a simple graph, then either x'(G) = 
Δ or x'(G) = A+ 1. 

EDGE COLORING AND CHROMATIC INDEX 
249 
Proof. Since x'{G) s= Δ, it is enough if we prove that x'(G) < Δ + 1 . 
Let Έ = {£,, E2,..., 
E&+1} 
be an optimal (Δ + l)-edge coloring of G. 
Assume that x'(G) > Δ + 1, that is, % is not a proper (Δ + l)-edge coloring. 
Then there exists a vertex u in G such that c(u)<d(u). 
This implies that 
there exist colors i 0 and /, such that i 0 is not represented at u and i, is 
represented twice at u. Let edge (u, v}) have color i, (Fig. 9.4a). 
Since the maximum degree in G is Δ, it follows that in the coloring %, not 
all the Δ + 1 colors are represented at i>,. 
Figure 9.4 

250 
COVERING AND COLORING 
(c) 
Figure 9.4. (Continued) 
Let color i2 be not represented at vertex vv Then i2 must be represented 
at vertex u, for otherwise we can recolor edge (u, u,) with color i2 and 
obtain a new coloring of G that is an improvement on %. Let edge (u, v2) 
have color i2. Again not all the colors are represented at v2. 
Suppose that color i3 is not represented at v2. Then it must be repre-
sented at u, for otherwise we can recolor edge (u, vt) with i2 and edge 
(u,v2) 
with i3, thereby obtaining an improvement on %. Let edge (u, v3) 
have color i3. 
Repeating these arguments, we can construct a sequence υ1,υ2,... 
of 
vertices and a sequence /,, i2,... 
of colors such that: 
1. (u, vf) has color i r 
2. i)+i 
is not represented at vr 
We can now easily see that there exists a smallest integer / such that, for 
some k < I, 
'/+ι=«'* 
(Fig. 9.4a). 
To establish a contradiction, we next recolor, in two different ways, some 
of the edges incident on u and obtain two new optimal (A+l)-edge 
colorings Έ' and %". 
= {E[, E'2,..., 
£^ + 1} is obtained by recoloring (u, vt) with color 
l s / < t - l . Each one of the remaining edges of G receives in 
the same 
color as it does in % (Fig. 9.46). 
%" = {£", E"2,..., El+l) 
is obtained by recoloring (u, u;) with color 

VERTEX COLORING AND CHROMATIC NUMBER 
251 
1 < ; ' < / - 1, and (u, u() with color ik. Each one of the remaining edges of G 
receives in Έ" the same color as it does in % (Fig. 9.4c). 
Let G' be the subgraph of G on the edge set (E'lg U E') with H' denoting 
its component containing u. Similarly, G" is the subgraph of G on the edge 
set (£,"O U E"k) with H" denoting its component containing u. 
In both Έ' and 
color i 0 is not represented at u and color ik is 
represented twice at this vertex. Therefore it follows from Lemma 9.4 that 
H' and H" are both circuits. 
Now (w, vk) is the only edge of H' that is not in H". Therefore u and vk 
are connected in G" too. Thus they lie in the same component of G", 
namely, the component H". The degree of vk in H" is then 1, for otherwise 
its degree in H' will be greater than 2. This contradicts that H" is also a 
circuit. Thus % is a proper (Δ + l)-edge coloring. 
• 
For a more general result than Theorem 9.7 see Exercise 9.8. 
9.4 
VERTEX COLORING AND CHROMATIC NUMBER 
A k-vertex coloring of a graph is the assignment of k distinct colors to the 
vertices of the graph. A vertex coloring is proper if in the coloring no two 
adjacent vertices receive the same color. A proper 3-vertex coloring is 
shown in Fig. 9.5. A graph is k-vertex colorable if it has a proper A:-vertex 
coloring. 
We may assume, without any loss of generality, that the graphs to be 
considered in this section are simple. 
The chromatic number x(G) of a graph G is the minimum number A: for 
which G is Ac-vertex colorable. G is k-chromatic if x(G) = A:. For example, 
the chromatic number of the graph in Fig. 9.5 is 3. 
We shall hereafter refer to a "proper A:-vertex coloring" as simply a 
"A:-coloring." Similarly, "Ar-vertex colorable" will be abbreviated to "A:-
colorable." 
1 
Figure 9.5. A proper 3-vertex coloring. 

252 
COVERING AND COLORING 
Note that a k coloring of a graph G = (V, E) induces a partition 
(V,, V 2,..., Vk) of V, where each Vj is the subset of vertices assigned the 
color / and therefore is an independent set. Similarly each partition of V into 
k independent sets corresponds to a A-coloring of G. 
We proved in the previous section (Theorem 9.7) that at most Δ + 1 
colors are required to properly color the edges of a simple graph. We now 
prove an analogous result for vertex coloring. 
Theorem 9.8. If a graph G is simple, then it is Δ + 1 colorable. 
Proof. Given Δ + 1 distinct colors, we can obtain a Δ + 1 coloring of G as 
follows. 
Pick any vertex vQ and assign it to any one of the Δ + 1 colors. Then select 
an uncolored vertex, say υ,. Assign to υ, a color that has not been assigned 
to the vertices adjacent to it. This is always possible because d(vx) ^ Δ, and 
hence at most Δ colors will have been assigned to the vertices adjacent to i;,. 
Repeat this process until all the vertices are colored. The resulting coloring 
is clearly a proper (Δ + l)-coloring. 
• 
Clearly, χ = Δ + 1 for complete graphs and for circuits of odd length. A 
very interesting result is that for all other graphs χ ^ Δ. This result due to 
Brooks [9.7] is proved next. Our proof here is due to Melnikov and Vizing 
[9.8]. For an alternate proof see Lovasz [9.9]. 
Theorem 9.9 (Brooks). Let G be a connected simple graph. If G is neither a 
circuit of odd length nor a complete graph, then x(G) ^ Δ. 
Proof. Clearly the theorem is valid for Δ = 0,1,2. 
To prove the theorem for Δ a 3, assume the contrary, that is, there exist 
graphs that are not complete and for which Δ 2:3 and χ = Δ + 1. Then select 
such a graph G = (V, E) with the minimum number of vertices. 
Let v0 ε V, and G' be the graph that results after removing v0 from G. It 
follows from the choice of G that G' is Δ-colorable. This implies that 
d(v0) = Δ, for otherwise one of the Δ colors used to color G' can be used to 
color v0, contradicting that x(G) = Δ + 1. Another important implication is 
the following. 
Property 1 In any Δ-coloring of G' the vertices adjacent to v0 are 
colored differently. 
Let «,, M 2, . . . , Μ δ be the vertices adjacent to v0. Let u l t u 2 , . . . , κ Δ receive 
the colors 1,2,... ,Δ, respectively, in a coloring of G'. Let G(i, ;') denote 
the induced subgraph of G' on the vertices that are assigned colors i and /. 
Then: 

CHROMATIC POLYNOMIALS 
253 
Property 2 Vertices u, and u ; are in the same connected component of 
G(i, j). 
For otherwise, by interchanging the colors ι and / in the component 
containing u,, we can get a new Δ-coloring of G' in which u, and uj are 
assigned the same color, contradicting Property 1. 
Let C,j be the component of G(i, j) containing u, and ur Then: 
Property 3 
C,t is a path from u, to u ;. 
Suppose that the degree of u, in Ctl is greater than 1. Then u, is adjacent to 
at least two vertices of color /. Since in G', d(u,) ^ Δ - 1, we can recolor u, 
with a color k Φ i, j so that in the resulting new coloring w, and uk receive 
the same color, contradicting Property 1. 
Similarly, the degree of uy in C,; is 1. 
The degree in C of all other vertices is 2. For otherwise, let w be the first 
vertex of degree (in C / y) greater than 2 as we move on a path from u, to u-. 
If u is colored with color i, then it is adjacent to at least three vertices of 
color /. Since d(u) < Δ , we can then recolor u with a color k Φ i, j so that in 
the new coloring u, and M; will be in different components, contradicting 
Property 2. 
Thus C,y is a path from u, to ur 
Property 4 
C. and Cik have no common vertex except u,. 
Let u Φ Uj be common to C,; and Cik. Then u is colored with color i, and it is 
adjacent to at least two vertices of color / and two vertices of color k. Since 
d(u) 
Δ, there exists a color / Φ i, j , k with which we can recolor u. But this 
would disconnect u, and up contradicting Property 2. 
Now we proceed to establish a contradiction of Property 4. 
Since G is not a (Δ+ l)-vertex complete graph, there exist two vertices, 
say U] and u2, which are not adjacent. Then the path C 1 2 contains a vertex 
uΦu2 
adjacent to ut. Suppose that we interchange colors 1 and 3 in the 
path C 1 3 (which exists because Δ ^ 3 ) , so that in the new coloring C , ux 
receives color 3 and w3 receives color 1. But then the new components C[2 
and C'23 contain the common vertex uΦu2, 
contradicting Property 4. 
This completes the proof of the theorem. 
• 
9.5 
CHROMATIC POLYNOMIALS 
In this section we discuss the question of counting the number of distinct 
proper λ-colorings of a graph. 
If a graph is λ-colorable, then it may be possible to color it with A colors 

254 
COVERING AND COLORING 
o-
-o 
b 
Figure 9.6 
c 
in more than one way. Two colorings of a graph are considered distinct if at 
least one vertex of the graph is assigned different colors in the two colorings. 
The chromatic polynomial 
P(G, A) expresses for each integer λ the 
number of distinct λ-colorings possible for a graph G. 
For example, consider the graph shown in Fig. 9.6. Given λ colors, we 
can select any one of them to color vertex a. Vertex b can then be colored 
with any one of the remaining λ - 1 colors. For each coloring of vertex b, 
there are λ - 1 different ways of coloring vertex c. Thus the graph of Fig. 
9.6 can be colored in λ(λ - l )
2 different ways. In other words the chromatic 
polynomial of the graph is λ(λ - l)
2. In fact, we can repeat these arguments 
to show that the chromatic polynomial of a path on η vertices is equal to 
As another example, consider next K„, the complete graph on η vertices 
vi,v2,..., 
vn. Given λ colors, the vertex u, can be colored with any one of 
the λ colors, vertex v2 with any one of the remaining λ - 1 colors, vertex v3 
with any one of the remaining A - 2 colors, and so on. Thus 
Next we present a formula for determining the chromatic polynomial of a 
graph G. 
Theorem 9.10. Let u and ν be two nonadjacent vertices in a simple graph G. 
Let e = (u, v). If G · e denotes the simple graph obtained from G by 
short-circuiting the vertices u and υ and replacing the resulting sets of 
parallel edges with single edges, and if G + e denotes the graph obtained by 
adding the edge e to G, then 
Proof. Each λ-coloring of G in which the vertices u and ν are assigned 
different colors corresponds to a λ-coloring of G + e and vice versa. 
Similarly, each λ-coloring of G in which u and υ are assigned the same color 
corresponds to a λ-coloring of G • e and vice versa. Hence 
A ( A - l ) ' 
. Π — 
λ) = λ ( λ - 1 ) · · ( λ - * + 
P(G, λ) = P(G + e, λ) + P(G • e, λ). 
P(G, A) = P(G + e, A) + P(G · e, A). 
• 
This result can be stated in a different form as follows. 
Corollary 9.10.1. If e = (u, υ) is an edge of a simple graph G, then 

CHROMATIC POLYNOMIALS 
255 
P(G, A) = P(G - e, A) - P(G • e, λ), 
where G — e is obtained by removing e from G and G · e is as defined in 
Theorem 9.10. 
• 
If we repeatedly apply the formula given in Theorem 9.10 on a graph G, 
then the process will terminate in complete graphs, say, Hx, H2,..., 
Hk, so 
that 
P(G, A) = P(HX, A) + P(H2, A) + · · · + P(Hk, 
A) . 
On the other hand, if we use the formula given in Corollary 9.10.1, the 
process will terminate in empty graphs (i.e., graphs that have no edges) so 
that the chromatic polynomial is a linear combination of the chromatic 
polynomials of empty graphs. 
Both these procedures are illustrated in Fig. 9.7. 
Theorem 9.11. The chromatic polynomial P(G, A) of an η-vertex graph G is 
of degree n, with leading term A" and constant term zero. Furthermore, the 
coefficients are all integers and alternate in sign. 
Proof. The proof is by induction on the number m of edges. Clearly the 
theorem is valid for m = 0, since the chromatic polynomial of an n-vertex 
empty graph is A". 
Assume that the theorem holds for all graphs with fewer than m edges. 
Consider now an η-vertex graph G with m edges. Let e be an edge of G. 
Then G - e is an η-vertex graph with m - 1 edges and G · e is an (η — 1)-
vertex graph with m - 1 or less edges. 
By the induction hypothesis it now follows that there are nonnegative 
integer coefficients a,, a2,...,a„_, 
and bx, b2,..., 
b„_2, such that 
P(G - e, λ) = λ" - α ^ , λ " -
1 + a^k"'
2 
-••• 
+ ( - ^ " « α , λ 
and 
P(G · e, A) = A""
1 - b„_2\"-
2 
+ b^.X"^ 
+ ( - l ) " " ^ . 
By Corollary 9.10.1, 
P(G, A) = P(G - e, A) - P(G · e, A) 
=A- - κ., + I)A— + Σ (-i)K-, + ν,μ-'. 
i = 2 
Thus G too satisfies the theorem. 
• 

256 
COVERING AND COLORING 
Ob 
*>d 
O a. d 
b 
Ο 
λ
3 
i ) ( V 
i ) ( 
ο ) 
(**') 
(b) 
Figure 9.7. Calculation of the chromatic polynomial of a graph G. (a) Using 
Theorem 9.10. P(G, λ) = λ(λ - 1)(A - 2)(A - 3) + 2A(A — 1)(A — 2) + λ(λ — 1). (b) 
Using Corollary 9.10.1. P(G, λ) = λ
3 — 2A
2 + A. 

THE FOUR-COLOR PROBLEM 
257 
9.6 
THE FOUR-COLOR PROBLEM 
Figure 9.8 
In map making, to distinguish the different regions, one is interested in 
coloring the regions so that no two adjacent regions receive the same color. 
This problem of properly coloring the regions of a planar graph is the same 
as that of properly coloring the vertices of the dual of the graph. It is easy to 
construct an example to show that three colors are, in general, not sufficient 
to properly color a planar graph. In the following theorem, known as the 
five-color theorem, we show that five colors are sufficient. 
Theorem 9.12. Every planar graph is 5-colorable. 
Proof. We shall assume that the theorem is true for all planar graphs of 
order less than η and then show that it is also true for a planar graph 
G = (V, E) of order n. 
By Corollary 7.3.5, there exists in G a vertex v0 of degree ^ 5 . Let G' be 
the induced subgraph of G on V— {v0}. 
Color G' with the five colors ax, a2,...,as. 
(This is possible by the 
induction hypothesis.) Clearly, one of these colors can be assigned to v0 in a 
proper 5-coloring of G, unless d(vQ) = 5, and all the 5 vertices vx, v2,..., 
v5 
adjacent to v0 are assigned different colors. 
Assume that u,, l < / < 5 , is assigned the color ar 
Further, let 
vx, 
v2,... 
,v5 be arranged in clockwise order as shown in Fig. 9.8. 
Let G(a,, a ;) be the subgraph of G on the vertices, which have been 
assigned the color a, or a ;. 
In G ( a , , a 3 ) , the component that contains i>, should contain v3; for 
otherwise the colors a, and a3 could be interchanged in this component and 
v0 could be colored with a,. 

258 
COVERING AND COLORING 
Similarly, in G(a,,a 4) the component that contains i>, should also 
contain v4. (See Fig. 9.8.) 
Then in G(a2, as), v2 and vs will not be connected. If now colors a2 and 
as are interchanged in the component of G(a2, a5) that contains v2, then v0 
can be colored with a2. Thus G is 5-colorable. 
• 
The preceding result is due to Heawood [9.10]. 
The question now arises as to whether the five-color theorem is the best 
possible. It was conjectured that every planar graph is 4-colorable. This was 
known as the four-color conjecture. This conjecture remained unsolved for 
more than 100 years and was the subject of extensive research. In 1976, 
Appel and Haken [9.11] proved this conjecture true. This is stated in the 
following theorem. 
Theorem 9.13 (Four-Color Theorem). Every planar graph is 4-colorable. 
• 
There is a vast literature on the four-color problem. See Ore [9.12], Saaty 
[9.13], and Saaty and Kainen [9.14] for an extensive survey of the problem 
with historical details. See also Whitney and Tutte [9.15]. 
9.7 
FURTHER READING 
Berge [9.2], Bondy and Murty [9.6], Harary [9.16], and Chartrand and 
Lesniak [9.17] are general references for the topics covered in this chapter. 
A classical result in graph theory due to Turan [9.18] determines the 
minimum number of edges than an η-vertex graph with independence 
number 
must have (Exercise 9.2). See Erdos [9.19]. This result is the 
starting point for a branch of graph theory known as extremal graph theory. 
The book by Bollobas [9.20] is devoted exclusively to the study of extremal 
graph problems. Extremal results form the basis of the design of communi-
cation nets having specified vulnerability and reliability properties. See 
Frank and Frisch [9.21], Boesch [9.22], and Karivaratharajan 
and 
Thulasiraman [9.23], [9.24]. See also Section 8.8. 
See Berge [9.2] (Chapter 16), Liu [9.25] (Chapter 9), and Lovasz [9.26] 
for an application of the independence number in information theory. 
Read [9.27] gives an excellent survey of results on chromatic polynomials. 
See also Birkhoff [9.28] and Tutte [9.29] and [9.30]. Liu [9.25] (pp. 
245-246) discusses an application of coloring in the decomposition of a 
graph into planar subgraphs. This problem arises in the design of printed 
circuits. See Wood [9.31] for an application of coloring in time-tabling 
problems, and Christofides [9.32] for coloring algorithms. 
A set of vertices D in a graph G is a dominating set in G if every vertex 
not in D is adjacent to a vertex in D. For a review of results concerning 

EXERCISES 
259 
dominating sets, see Cockayne and Hedetniemi [9.33]. An extremal result 
concerning dominating sets is given in Cockayne and Hedetniemi [9.34]. 
Consider a simple graph G. Let <o(G) denote the maximum order among 
all the complete subgraphs of G. The graph G is a perfect graph if 
χ(Η) = ω(Η) 
for every induced subgraph Η of G. This concept was 
introduced by_Berge [9.2] who conjectured that a simple graph G is perfect 
if and only if G is perfect. This conjecture, referred to as the perfect graph 
conjecture, was proved by Lovasz in [9.35]. 
Berge also conjectured that a simple graph G is perfect if and only if no 
induced subgraph of G or G is a circuit of odd length greater than 3. This 
conjecture known as the strong perfect graph conjecture remains unproved 
though it has been shown to be true for certain special classes of graphs. See 
Tucker [9.36] and Parthasarathy and Ravindra [9.37]. See Golumbic [9.38] 
for perfect graph algorithms. 
9.8 
EXERCISES 
9.1 
Prove or disprove: Every vertex cover of a graph contains a minimum 
vertex cover. 
9.2 
Given any two integers η and k with η ^ k > 0. Let q = [nlk\ and let 
r be an integer such that 
Let Gn 
k be the simple graph that consists of k disjoint complete 
graphs, of which r have q + 1 vertices and k — r have q vertices. Then 
show that every graph G with η vertices and a 0(G) ^ k that has the 
minimum possible number of edges is isomorphic to G„ k (Turan 
[9.18]). An easy corollary of this result is: 
If G is a simple graph with η vertices and m edges and with 
a 0(G) = A;, then 
9.3 
If G is a simple graph with η vertices and m edges, then show that 
η = kq + r , 
0<r<k. 
2 
« 0 ( G ) > 
η 
2m + η ' 
9.4 
Show that the maximum number of edges that an w-vertex simple 
graph G with no triangles can have is [n /4J. Construct a graph with 
this property. 

260 
COVERING AND COLORING 
9.5 
Derive Hall's theorem, Theorem 8.13, from Theorem 9.2. 
9.6 
Derive Hall's theorem, Theorem 8.13, from Theorem 9.5. 
9.7 
Show that 
X K
Kn) 
| „ 
> 
jf n is odd . 
9.8 
Show that if G is a graph without self-loops, then 
x'(G)*a 
+ k, 
where k is the maximum number of parallel edges between any two 
vertices of G (Vizing [9.4]). 
9.9 
Let G be a graph without self-loops. If A(G) = 3, then show that 
*'(G) = 3or 4. 
9.10 Show that, for a regular nonempty simple graph with odd number of 
vertices, 
*'(G) = A + 1. 
9.11 Show that for any arbitrary orientation of the edges of a simple graph 
G, there exists a directed path of length x(G) - 1. 
9.12 Show that if any two circuits of odd length of a graph G have a vertex 
in common, then 
* ( G ) < 5 . 
9.13 Using Corollary 7.3.5, show that every planar graph is 6-colorable. 
9.14 Show that if a simple graph has degree sequence (d,, d 2 , . . . , d„) then 
x(G) ^ max min {d, + 1, i) 
(Welsh and Powell [9.39]). 
(Note: This result can be proved by showing that the following 
greedy coloring algorithm uses at most max min {d, + 1, /'} colors: 
Color u, with color 1, then color v2 with color 1 if u, and v2 are not 
adjacent and with color 2 otherwise, and so on. In other words color 
each vertex with the smallest color it can have at that stage.) 
9.15 Show that for a simple graph G 
X(G) < 1 + max δ(Η) 

EXERCISES 
261 
Figure 9.9 
where the maximum is taken over all induced subgraphs Η of G 
(Szekeres and Wilf [9.40]). 
9.16 Show that for a simple graph G 
* ( G ) < 1 + /(G) 
where /(G) denotes the length of a longest path in G. 
9.17 
Show that for an η-vertex simple graph G, 
(a) 
x(G)a0(G)>n; 
(b) *(G) + a 0 ( G ) < n + l; 
(c) x(G) + X(G)^n 
+ l. 
9.18 
Let G be a simple w-vertex regular graph of degree k. Show that 
9.19 
Let G be a planar graph in which each region is bounded by exactly 
three edges. Show that G is 3-colorable if and only if G is Eulerian. 
9.20 
Show that a simple graph is nonplanar if it has seven vertices and the 
degrees of its vertices are all equal to 4 (Liu [9.25]). 
9.21 (a) Show that a graph is 2-colorable if and only if all its circuits are of 
even length. 
(b) Show that the regions of a planar graph G can be properly 
colored with two colors if and only if G is Eulerian. 
9.22 Find the chromatic polynomial of the graph shown in Fig. 9.9. 
9.23 
(a) Show that an η-vertex graph G is a tree if and only if 
P(G, λ) = λ ( λ - 1 )
π "
1 . 
<? 
<? 

262 
COVERING AND COLORING 
(b) Show that if an η-vertex graph G is connected, then 
P(G, λ ) < λ ( λ - 1 ) ' 
, π - 1 
9.24 
Show that if G is a circuit of length n, then 
P(G, λ) = ( λ - 1 ) " + ( - 1 )
η ( λ - 1 ) . 
9.25 
Show that if G is a wheel on η + 1 vertices, then 
P(G, A) = A(A-2)" + (-l)"A(A-2). 
9.26 
Show that if a simple graph G has η vertices, m edges, and A: 
components, then 
(a) The coefficient of A"
- 1 in P(G, λ) is - m . 
(b) The smallest exponent of λ in P(G, λ) with a nonzero coefficient 
9.27 
A clique of a graph G = (V, E) is a set S C V such that the induced 
subgraph of G on S is a complete graph. Let Ρ = {Ρ,, P 2 , . . . , Pk} be 
a partition of V into cliques. Let 
Thus 0(G) is the smallest possible number of cliques into which Κ can 
be partitioned. 
Show that, for a simple graph G, a 0(G) =£ 0(G). Further, if S is an 
independent set and Ρ is a partition of V into cliques such that 
|5| = |P|, then show that 5 is a maximum independent set and Ρ is a 
minimum partition of V into cliques. 
9.9 
REFERENCES 
9.1 
D. Konig, "Graphs and Matrices," (in Hungarian), Mat. Fiz. Lapok, Vol. 38, 
116-119 (1931). 
9.2 
C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
9.3 
T. Gallai, "Uber extreme Punkt und Kantenmengen," Ann. Univ. Sci. 
Budapest, Eotvos Sect. Math., Vol. 2, 133-138 (1959). 
9.4 
V. G. Vizing, "On an Estimate of the Chromatic Class of a p-Graph," (in 
Russian), Diskret. Analiz., Vol. 3, 25-30 (1964). 
9.5 
J. C. Fournier, "Colorations des aretes d'un graphe," Cahiers du CERO, Vol. 
15, 311-314 (1973). 
9.6 
J. A. Bondy and U. S. R. Murty, Graph Theory with Applications, Macmillan, 
London, 1976. 
is k. 
0(G) = min {|P|}. 

REFERENCES 
263 
9.7 
R. L. Brooks, "On Colouring the Nodes of a Network," Proc. Cambridge 
Phil. Soc, Vol. 37, 194-197 (1941). 
9.8 
L. S. Melnikov and V. G. Vizing, "New Proof of Brooks' Theorem," J. 
Combinatorial Theory, Vol. 7, 289-290 (1969). 
9.9 
L. Lovasz, "Three Short Proofs in Graph Theory," J. Combinatorial Theory 
B, Vol. 19, 111-113 (1975). 
9.10 P. J. Heawood, "Map Colour Theorems," Quart. J. Math., Vol. 24, 332-338 
(1890). 
9.11 Κ. I. Appel and W. Haken, "Every Planar Map is Four-Colorable," Bull. Am. 
Math. Soc, Vol. 82, 711-712 (1976). 
9.12 O. Ore, The Four-Color Problem, Academic Press, New York, 1967. 
9.13 T. L. Saaty, "Thirteen Colorful Variations on Guthrie's Four-Color Conjec-
ture," Am. Math. Monthly, Vol. 79, 2-43 (1972). 
9.14 T. L. Saaty and P. C. Kainen, The Four-Color Problem: Assaults and 
Conquests, McGraw-Hill, New York, 1977. 
9.15 H. Whitney and W. T. Tutte, "Kempe Chains and the Four Colour Problem," 
in Studies in Graph Theory, Part II, MAA Press, Washington, D.C., 1975, pp. 
378-413. 
9.16 F. Harary, Graph Theory, Addison-Wesley, Reading, Mass., 1969. 
9.17 G. Chartrand and L. Lesniak, Graphs and Digraphs, Wadsworth and Brooks/ 
Cole, Pacific Grove, Calif., 1986. 
9.18 P. Turan, "An Extremal Problem in Graph Theory," (in Hungarian), Mat. 
Fiz. Lapok, Vol. 48, 436-452 (1941). 
9.19 P. Erdos, "On the Graph Theorem of Turan," (in Hungarian), Mat. Lapok, 
Vol. 21, 249-251 (1970). 
9.20 B. Bollobas, Extremal Graph Theory, Academic Press, New York, 1978. 
9.21 H. Frank and I. T. Frisch, Communication, Transmission, and Transportation 
Networks, Addison-Wesley, Reading, Mass., 1971. 
9.22 F. T. Boesch, Ed., Large-Scale Networks: Theory and Design, IEEE Press, 
New York, 1976. 
9.23 P. Karivaratharajan and K. Thulasiraman, "AT-Sets of a Graph and Vul-
nerability of Communication Nets," Matrix and Tensor Quart., Vol. 25, 
63-66, (1974), 77-86 (1975). 
9.24 P. Karivaratharajan and K. Thulasiraman, "An Extremal Problem in Graph 
Theory and Its Applications," Proc. IEEE Intl. Symp. on Circuits and 
Systems, Tokyo, Japan, 1979. 
9.25 C. L. Liu, Introduction to Combinatorial Mathematics, McGraw-Hill, New 
York, 1968. 
9.26 L. Lovasz, "On the Shannon Capacity of a Graph," IEEE Trans. Inform. 
Theory, Vol. IT-25, 1-7 (1979). 
9.27 R. C. Read, "An Introduction to Chromatic Polynomials," /. Combinatorial 
Theory, Vol. 4, 52-71 (1968). 
9.28 G. D. Birkhoff, "A Determinant Formula for the Number of Ways of 
Coloring a Map," Ann. Math., Vol. 14, 42-46 (1912). 

264 
COVERING AND COLORING 
9.29 W. T. Tutte, "On Chromatic Polynomials and the Golden Ratio," /. Com-
binatorial Theory, Vol. 9, 289-296 (1970). 
9.30 W. T. Tutte, "Chromials," in Studies in Graph Theory, Part II, MAA Press, 
Washington, D.C., 1975, pp. 361-377. 
9.31 D. C. Wood, "A Technique for Coloring a Graph Applicable to Large-Scale 
Timetabling Problems," Computer J., Vol. 12, 317 (1969). 
9.32 N. Christofides, Graph Theory: An Algorithmic Approach, Academic Press, 
New York, 1975. 
9.33 E. J. Cockayne and S. T. Hedetniemi, "Towards a Theory of Domination in 
Graphs," Networks, Vol. 7, 247-267 (1977). 
9.34 E. J. Cockayne and S. T. Hedetniemi, "Optimal Domination in Graphs," 
IEEE Trans. Circuits and Sys., Vol. CAS-2, 41-44 (1975). 
9.35 L. Lovasz, "Normal Hypergraphs and the Perfect Graph Conjecture," Dis-
crete Math., Vol. 2, 253-267 (1972). 
9.36 A. Tucker, "The Strong Perfect Graph Conjecture for Planar Graphs," 
Canad. J. Math., Vol. 25, 103-114 (1973). 
9.37 K. R. Parthasarathy and G. Ravindra, "The Strong Perfect Graph Conjecture 
is True for Kt 3-free Graphs," J. Comb. Theory, Vol. 22B, 212-223 (1976). 
9.38 M. C. Golumbic, Algorithmic Graph Theory and Perfect Graphs, Academic 
Press, New York, 1980. 
9.39 D. J. A. Welsh and Μ. B. Powell, "An Upper Bound for the Chromatic 
Number of a Graph and Its Application to Timetabling Problems," Computer 
J., Vol. 10, 85-87 (1967). 
9.40 G. Szekeres and H. S. Wilf, "An Inequality for the Chromatic Number of a 
Graph," J. Comb. Theory, Vol. 4, 1-3 (1968). 

CHAPTER 10 
MATROIDS 
Consider a finite set S of vectors over an arbitrary field. The collection of 
the independent sets of vectors of S possesses several interesting properties. 
For example, 
1. Any subset of an independent set is independent. 
2. If Ip and Ip+l 
are any two independent sets with | / p + 1 | = \lp\ + 1, then 
Ip together with some element of Ip + l forms an independent set of 
elements. 
It is interesting to note that there are several algebraic systems that possess 
these two properties. For instance, the collection of subsets of edges of a 
graph that do not contain any circuit possesses these properties. It was while 
studying the properties of such systems that Whitney [10.1] introduced the 
concept of a matroid. 
In this chapter we give an introduction to the theory of matroids. We 
discuss several fundamental properties of a matroid. Of special interest to us 
is the result that the "duality" that we observed between the circuits and the 
cutsets of a graph is not accidental. As we shall see, this duality is a 
consequence of the fact that the collection of subgraphs that have no circuits 
and the collection of subgraphs that have no cutsets both have the matroid 
structure. We also study the "painting" theorem and the arc coloring 
lemma, which find an application in network analysis. We conclude the 
chapter with a discussion of the "greedy" algorithm, which is a generaliza-
tion of a well-known algorithm due to Kruskal for finding a minimum cost 
spanning tree of a weighted connected graph. 
265 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

266 
MATROIDS 
10.1 
BASIC DEFINITIONS 
There are several equivalent axiom systems for characterizing a matroid. We 
begin our discussion with what are known as the independence axioms. In 
Section 10.3 we derive some of the equivalent axiom systems. 
A matroid Μ is a finite set S and a collection 3 of subsets of S such that 
the following axioms, called independence axioms, are satisfied: 
1-1. 0E 
3. 
1-2. If XE 3 and YCX, 
then YE 3. 
1-3. If X and Y are members of 3 with |A"| = |Y| + 1, there exists 
xEX-Y 
such that Y U χ Ε 3. 
The elements of 5 are called the elements of the matroid M. Members of 3 
are called the independent sets of M. A maximal independent set of Μ is 
called a base of M. The collection of the bases of Μ is denoted by S9(M) or 
simply 38. 
A subset of S not belonging to 3 is called dependent. A minimal 
dependent subset of 5 is called a circuit of M. An element x of S is a loop of 
Μ if {x} is dependent. The collection of circuits of Μ is denoted by "#(M) or 
simply %. 
The rank function ρ of Μ associates to each subset A of 5 a nonnegative 
integer p(A) defined by 
p(A) = max{\X\:XCA,XE3} 
. 
p(A) is called the rank of A. The rank of the matroid Μ denoted by p(M) is 
the rank of the set S. 
We now consider some examples. 
Let 5 be a finite subset of a vector space. As we observed earlier, the 
family of all the subsets of linearly independent vectors in 5 satisfy the 
independence axioms 1-1 through 1-3. Hence these subsets of S form the 
collection of independent sets of a matroid on 5. In this matroid the rank of 
a subset X of S is equal to the dimension of the vector space generated by 
X. 
Let G be an undirected graph with edge set E. We can define two 
matroids on E. 
First consider the collection 3 of all the subsets of Ε that do not contain 
any circuits. Clearly 3 satisfies 1-1 and 1-2. We can easily show that 
(Exercise 4.8) that 3 satisfies 1-3. Thus 3 is the collection of independent 
sets of a matroid Μ on E. Each base of Μ is a spanning forest of G. In this 
matroid the rank of any subset X of Ε is equal to the rank of the subgraph 
of G induced by X. Furthermore, each circuit of Μ is a circuit of G. For this 
reason Μ is called the circuit matroid of G. 

BASIC DEFINITIONS 
267 
Consider next the family 3 * of all the subsets of Ε that do not contain 
any cutset of G. We can show (Exercise 4.9) that 3* satisfies axioms 1-1 
through 1-3, and hence it is the family of independent sets of a matroid M* 
on E. Each base of M* is a cospanning forest of G. In this matroid the rank 
of any subset X oi Ε is equal to the nullity of the subgraph of G induced by 
X. Furthermore, each circuit of Μ * is a cutset of G. The matroid M* is 
called the cutset matroid or the bond matroid of G. 
The two matroids Μ and M* defined above possess the interesting 
property that the bases of one are the complements in Ε of the bases of the 
other. This result is true for any matroid on any finite S (not necessarily the 
edge set of a graph). In other words for any matroid Μ on a set 5 there 
exists a matroid M* on 5 with the bases of Μ * being the complements of the 
bases of M. We discuss this result in Section 10.4. 
Another example of a matroid is the matching matroid defined on the 
vertex set of a graph. 
Theorem 10.1. Let G be an undirected graph with vertex set V. Let 3 be the 
collection of all the subsets ICV such that the elements of / are saturated in 
some matching of G. Then 3 is the collection of independent sets of a 
matroid on V. 
Proof. Clearly 3· satisfies axioms 1-1 and 1-2. 
To show that 3 satisfies axiom 1-3, consider any two members Ip and Ip+l 
of 3 containing ρ and ρ + 1 vertices, respectively, and let Xp and Xp+l 
be 
any two matchings saturating the elements of Ip and Ip + X, respectively. Now 
two cases arise. 
Case 1 
Suppose that some element χ Ε Ip+i 
— lp is saturated in Xp. 
Then Xp saturates IpU χ and the axiom 1-3 is satisfied. 
Case 2 
Suppose that no element of / 
+ 1 - Ip is saturated in Xp. Then 
consider the subgraph G' on the edge set Xp(&Xp 
+ x 
=(Xp-
Xp+l)U 
(Xp+l 
- Xp). By Theorem 8.19 each component of G' 
is either 
1. a circuit whose edges are alternately in Xp and Xp+X 
or 
2. a path whose edges are alternately in Xp and Xp+X and whose 
end vertices are not saturated in one of the two matchings. 
Since \Ip+x - lp\> \Ip - Ip+l\, 
there is a path Ρ in G' from a 
vertex υ Ε Ip + l - Ip to a vertex not in Ip - Ip+X. 
Then 
ΧρΦΡ 
will be a matching saturating ν and all the elements of Ip. Thus 
Ip U ν is a member of 3, and axiom 1-3 is satisfied. 
• 
As an example, consider the graph G shown in Fig. 10.1a. The sets 
/ 4 = {u,, v2, v3, v4} and / 6 = {υ 1 ; v2, υ3, v4, υ5, v6} are saturated in the 
matchings X4 = {e,, e2} and X6 = {e2, e3, e4), respectively. The subgraph on 

268 
MATROIDS 
Figure 10.1. (a) A graph G with the match-
ings X4 and X6 indicated, (b) Subgraph of G 
on the edge set X4®Xb. 
the edge set XA(BX6 = {e,, e3, eA} is shown in Fig. 10.1ft. There is a path P 
from the vertex v5El6-IA 
to the vertex vb0IA-I6. 
The matching 
XA Φ P = {e2, e3, e4} saturates the set IAUvs. 
Two matroids Ml and Af2 on the sets S, and 52, respectively, are 
isomorphic if there is a one-to-one correspondence between the elements of 
5, and 52, which preserves independence. 
A matroid M on 5 is called graphic if it is isomorphic to the circuit 
matroid of a graph G. M is called cographic if it is isomorphic to the cutset 
matroid of a graph G. 
10.2 FUNDAMENTAL PROPERTIES 
We establish in this section several fundamental properties of a matroid. All 
these properties are familiar in graph theory. 
We first consider the independent sets and the bases of a matroid M. 

FUNDAMENTAL PROPERTIES 
269 
Theorem 10.2 (Augmentation Theorem). Let X and 
Y be any two 
in-
dependent subsets in a matroid M. If |A"| < | Y\, then there exists ZC.Y- 
X 
such that |A"U Z| = | Y\ and XI) Ζ is independent in M. 
Proof. Let Z 0 be a set such that: 
1. 
Z0CY-X. 
2. X U Z 0 is independent in M. 
3. If A' U Ζ is independent in Μ for any Z C V - I , then 
\Xl)Z0\> 
\xuz\. 
Suppose that l A ' U Z o l ^ y l . Then there exists a set Y0CY 
with \Y0\ = 
\X\J Z 0 | + 1. Since y o is independent in M, by axiom 1-3 there exists an 
element y ε Y0 - (A' U Z 0) such that A" U Z 0 U >> is independent in Μ. The 
set Z0Uy 
contradicts the choice of Z 0. Hence lA' U Z 0| s |y|, and the proof 
now follows. 
• 
Corollary 10.2.1. All the bases of a matroid Μ on a set 5 have the same 
cardinality equal to the rank of M. 
Proof. If not, let Bx, B2 be bases with \BX \ < \ B2\. Then by the augmenta-
tion theorem there exists Ζ C B2 - B, such that Bx U Ζ is independent. 
This, however, contradicts the maximality of Βλ in A 
• 
The following generalization of this result can also be proved using the 
augmentation theorem. 
Corollary 10.2.2. Let Μ be a matroid on a set S and ACS. 
Then all the 
maximal independent subsets of A have the same cardinality. 
• 
Another corollary of Theorem 10.2 is stated next without proof. 
Corollary 10.2.3. If Bx and B2 are the bases of a matroid Μ and χ ε S, - 5 2 , 
then there exists y Ε B 2 - B, such that (β, U )>) - χ is a base of M. 
• 
We next obtain some properties of the rank function of a matroid. 
Theorem 10.3. The rank function ρ of a matroid Μ on a set S satisfies the 
following properties, where A, Β C S and 
xE.S. 
1. 
OsP(A)^\A\. 
2. MAC 
B, then p(A) < p(B). 
3. p(A)<p(AVx)^p(A) 
+ l. 
4. The submodular inequality 
p(A) + p(B) > p(A UB) + p(A η Β) . 

270 
MATROIDS 
5. If p(A U y) = p(A U JC) = p(A), then p(A U χ U y) = p(A). 
Proof. The first three properties follow easily from the definition of the rank 
function. 
To establish property 4, let X be a maximal independent subset of Α Π Β. 
By the augmentation theorem, there exists a maximal independent subset Y 
of AU Β containing X. Let Y= XliVUW, 
where VCA-B 
and WC 
B-A. 
Since X\JV 
is an independent subset of A, and X\JW 
is an 
independent subset of B, we get 
p(A)*\XUV\ 
and 
p(B)>\XUW\. 
Hence 
p(A) + p(B) >\XUV\ 
+ \XL>W\ 
= 2\X\ + \V\ + \W\ 
= | * | + (|*| + |V| + |W|) 
= ρ(ΑΓ\ B) + p(AU 
B). 
Property 5 is an easy consequence of property 4. 
• 
We next consider the circuits of a matroid. Some properties, which follow 
directly from the definition of a circuit, are 
1. Every proper subset of a circuit is independent. So, if C, and C2 are 
distinct circuits, then 
CxgC2. 
2. If C is a circuit, then p(C) = |C| - 1. 
3. A matroid Μ on a set 5 has no circuits if and only if all the subsets of S 
are independent. Thus S is the only base of such a matroid M. 
Theorem 10.4. If C, and C 2 are distinct circuits of a matroid Μ and 
χ Ε C, Π C 2, then there exists a circuit C 3 such that C 3 C (C, U C 2) - x. 
Proof. Let C = (Cj U C 2) - JC. We prove the theorem by showing that C is 
dependent, that is, 
p(C')<\C'\. 
Since C\ and C 2 are distinct circuits, Cl Π C 2 is a proper subset of both Cj 
and C 2. Hence C, Π C2 is independent. Thus 
p(cxr\c2) 
= 
\c,r\c2\ 

FUNDAMENTAL PROPERTIES 
271 
Furthermore, 
and 
p(C2)=\C2\-l. 
Now, using the above and the submodularity of the rank function (Theorem 
10.3), we get 
p(C, U C2) < p(C.) + p(C 2) - p(C, Π C 2) 
= 1^1-1 + 1 ^ 1 - 1 - 1 ^ 0 ^ 1 
= | C , U C 2 | - 2 
< | C ' | . 
(10.1) 
Since C ' C Q U Q , we also have 
/ K H s p i Q U C j ) . 
(10.2) 
Combining (10.1) and (10.2), we get 
p(C')<\C'\. 
• 
Corollary 10.4.1. If /I is an independent set in a matroid M on a set S, then 
for any χ G S , A U J : contains at most one circuit. 
Proof. Let, for some χ £ 5, there exist two distinct circuits C, and C 2 such 
that j r £ C , n C
2 , 
C{QALIx, 
and C2QA\Jx. 
Then by the previous 
theorem there exists a circuit C C (C, U C 2) - x . Hence (C, U C 2) - χ is 
dependent. But (C, U C2) - χ C A, contradicting the independence of 
Α. m 
Corollary 10.4.2. If Β is a base of a matroid Λί on a set S and xGS - B, 
then there exists a unique circuit C = C(*, 5 ) such that χ E. C C Β U x. 
Proof. Since β is a maximal independent set, Β Li χ contains a circuit. By 
the previous corollary, such a circuit is unique. 
• 
The circuit C(x, B) denned in the above corollary is called the fundamen-
tal circuit of χ with respect to base B. 
We next prove a much stronger result than Theorem 10.4. 

272 
MATROIDS 
Theorem 10.5. If C, and C 2 are distinct circuits of a matroid and χ Ε C, Π 
C 2, then for any element yECt-C2 
there exists a circuit C such that 
y e C C ( Q U C 2) - χ . 
Proof. Suppose that C,, C 2, JC, y are such that the theorem is false and that 
| C , U C 2 | is minimum among all pairs of distinct circuits violating the 
theorem. 
By Theorem 10.4 there exists a circuit C 3 C (C, U C 2) - x. From our 
choice of χ and y is it clear that y0C3. Furthermore, C 3 Π (C 2 - C,) Φ 0 , 
for otherwise C 3 C C,, contradicting the fact that C, is a minimal dependent 
set. Let then zEC3C\(C2- 
C\). 
Now, for the circuits C 2 and C 3 we have the following: 
1. 
zEC2HC3. 
2. xEC2- 
C3. 
3. C2 U C 3 is a proper subset of C, U C 2 because y0C2L>C3. 
From our choice of C, and C 2 it follows that there exists a circuit C 4 such 
that 
i e c 4 c ( c 2 u c 3 ) - z . 
Consider next the circuits C, and C 4 for which we have the following: 
1. x e c , n c 4 . 
2. y e C, - C 4, because y e'Cz U C 3. 
3. C, U C 4 is a proper subset of C, U C 2, because ζ &CX U C 4. 
Again from our choice of C, and C 2 it follows that there exists a circuit C 5 
such that y Ε C 5 C (C, U C 4) - JC. 
Since C, U C 4 is a proper subset of C, U C2, we have found a circuit C 5 
such that y e C 5 C (Cj U C 2) - jt, contradicting our choice of C, and C 2. 
• 
10.3 
EQUIVALENT AXIOM SYSTEMS 
In this section we establish some alternative axiom systems for defining a 
matroid. Such equivalent characterizations would help us in gaining more 
insight into the structure of matroids. 
We begin with an equivalent set of independence axioms. 
Theorem 10.6 (Independence Axioms). A collection J of subsets of a set S is 
the set of independent sets of a matroid on 5 if and only if 3
s satisfies axioms 

EQUIVALENT AXIOM SYSTEMS 
273 
1-1, 1-2, and 
1-3'. If A is any subset of S, then all the maximal subsets Y of A, with 
Y G 3, have the same cardinality. 
Proof. The proof is left as an exercise. See Corollary 10.2.2. 
• 
Theorem 10.7 (Base Axioms). Let 38 be the set of bases of a matroid. Then 
B-l. 38 ¥=0, and no set in 38 contains another properly. 
B-2. If β,, B2 e 38 and χ e β,, then there exists y £ f l 2 such that 
(β, - JC) U y G 38. 
Conversely, if 38 is a collection of subsets of a set S satisfying B-l and B-2, 
then 
3 = {I\I C B, for some Β G 38} 
is the collection of independent sets of a matroid on S. 
Proof. We have already proved that the bases of a matroid satisfy B-l and 
B-2. (Recall the definition of a base and see Corollary 10.2.3.) 
Given 38 satisfying B-l and B-2, we now show that 3 as defined in the 
theorem is the collection of independent sets of a matroid on 5. 
First note that B-l and B-2 imply that for * G β, - B2 there exists 
y G B2 - B, such that (β, - χ) U y is a member of 38. 
Clearly, 3 satisfies axioms 1-1 and 1-2. To prove axiom 1-3, first we show 
that all the members of 38 have the same cardinality. 
Suppose there exists fl„ fi2G38 with | β , | > | β 2 | . Then by repeated 
application of β-2 we can remove β 2 - β, from β 2 and replace it it by a set 
ACBi-B2 
with |^4| = | β
2 - β , | and such that β 3 = ( β 2 Π β,) U A is a 
member of 38. But β 3 C β,, contradicting B-l. Thus all the members of 38 
have the same cardinality. 
Consider next any two distinct members X and Y of 3 with | Y| = |AT| + 1. 
Let XC β,, YC β 2 , and β,, β 2 6 38. Let 
X — {xx, x2,... 
,xk} , 
&i ~ i
xi>
 
x2> 
· · • 
° i , b2,..., 
bq) , 
B2 = {yi> y2>- • • - y*. y * + i . c , , c 2 , . . . 
,cq_,}. 
Now consider B1-bq. 
By B-2 there exists zE.B2 
such that B' = 
(β, - Z>?) U ζ is a member of 38. If ζ G Y, then ( ^ U z ) C B ' , and hence it is 
a member of 3. So 1-3 is satisfied in this case. 

274 
MATROIDS 
liz^Y, 
then consider B"= B' - bq„v 
Again by B-2 there exists z'Ε 
B2 
such that B" = (B' - bq_l)L)z' 
is a member of 38. If z' Ε Y, then 
XLiz'C 
B". Hence (XL) z')E3, 
and axiom 1-3 is satisfied. 
If z ' 0 Y , remove bq_2 from B", and so on. Since |{6,, b2,..., 
bq}\> 
|{c,, c 2 , . . . , c 
,}|, after at most q steps we arrive at a situation where we 
replace some b, by an element of Y, thereby satisfying axiom 1-3. 
• 
Theorem 10.8 (Rank Axioms). The rank function ρ of a matroid Μ on a set 
5 satisfies the following: 
R-l. 0 < p ( A ) < | A | , for all A C S . 
R-2. If A C Β C S, then p(A) < p(B). 
R-3. For any A, 
BCS, 
p(A) + p(B) > p(A U Β) + p(A Π Β). 
Conversely, if an integer-valued function ρ defined on a finite set S satisfies 
R-l, R-2, and R-3, then the set 
3 = {I\P(I) 
= 
\I\,ICS} 
is the collection of independent sets of a matroid on 5. 
Proof. We have already proved in Theorem 10.3 that the rank function of a 
matroid satisfies R-l, R-2, and R-3. 
To prove the converse, suppose that ρ satisfies R-l, R-2, and R-3. It 
follows from R-l that p(0) = 0. So 0 E # , and axiom 1-1 is satisfied. 
Let BE3 
and ACB. 
Then by R-3, we get 
p(A) + p(B - A) > p(A U (Β - A)) + p(A η (Β - A)) 
= p(B) + p(0) 
= | β | . 
(10.3) 
If p(A)<|A|, then by R-l, 
p(A) + p(B - A)<\A\ 
+ \B - A\ 
"1*1, 
contradicting (10.3). Hence p(A) = \A\, and thus A is also a member of J, 
thereby satisfying axiom 1-2. 
To prove 1-3, first note that R-2 and R-3 imply the following: 
R-3'. If p(A U^) = p(A Uy) = p(A), then p(A U χ U y ) = p(A). 

EQUIVALENT AXIOM SYSTEMS 
275 
Now let X and Y be two distinct members of $ with \X\ = k and | Y| = k + 1. 
Suppose that, for every y Ε Υ - X, p(X Uy) = k. Then by repeated applica-
tion of R-3' we get 
p(XD(Y-X)) 
= p(XU Y) = k, 
contradicting that p(Y) = k + 1. So there exists an element yEY-X 
with 
the property p(XL) y) = k + 1, and thus axiom 1-3 is satisfied. 
• 
Theorem 10.9 (Circuit Axioms). Let <β be the set of circuits of a matroid on 
a set S. Then: 
C-l. 0 ^ ^ and no set in 
contains another properly. 
C-2. If Cj, C 2G 
C, Φ C 2, and χG C, Π C 2, then there exists 
CJE
<€ 
such that C 3 C (C, U C 2) -
Conversely, if 
is a collection of subsets of a set 5 satisfying C-l and C-2, 
then the set 3 = {l\C$Zl, 
for all CG
 c€) is the collection of independent 
sets of a matroid on 5. 
Proof. We have proved earlier that the circuits of a matroid satisfy C-l and 
C-2 (see Theorem 10.4.) 
Given 
satisfying C-l and C-2, we now show that the set $ denned as in 
the theorem is the collection of independent sets of a matroid on S. We do 
so by showing that 3> satisfies axioms 1-1, 1-2, and 1-3' (see Theorem 10.6.) 
First note that $ is the collection of all the subsets of 5 that do not 
contain any member belonging to %. Therefore it satisfies axioms 1-1 and 
1-2. 
To prove that $ satisfies axiom 1-3', consider any subset A of 5. Let 5, 
and 5 2 be distinct maximal subsets of A that belong to 
Assuming that 
|5 2| > |S,|, we establish a contradiction. 
Since Sj and S 2 are distinct, 5, - Ξ2Φ0 
and S2 - S, Φ 0. Let χ G S2 - 5,. 
Then clearly S^x^^. 
Hence there exists C £ « with 
xECCSxUx. 
Further, C Π (5, - S2) Φ 0, as otherwise C C 5 2, contradicting that 5 2 £ $>. 
Let then x' G C Π (S, - 5 2) and 5 3 = (5, - x') U x. Note that | 5 3 | = |5,|. 
We first prove: 
1. 5 3GJf. 
Clearly S, - x' G 3. If S 3 £ Ά then there exists C'E<€ with χ Ε C C 
S3ESx\Jx. 
Further C Φ C as x'gC. 
Thus C and C are distinct 
members of % such that 
(a) 
xECnC. 
(b) C C S , U x and C ' C J . U x . 

276 
MATROIDS 
Then it follows from C-2 that there exists C"E <€ with C"C(CU C ) 
- χ C Sj Ε 3. This contradicts that no member of 3 contains a 
member of 
Therefore, S 3 G 3. 
We next prove the following: 
2. S3E3 
is a maximal subset of A. 
If not, let 5' G 3 be a maximal subset of A with S3 C 5'. Now x' 
0S', 
as otherwise S, C S \ contradicting the maximality of 5, in A. Then 
S ' U J C ' ^ J * . Hence there exists C"'G<£ with JC' G C"'C 5' U J C ' . Fur-
ther, C " n ( 5 ' - S 1 ) ^ 0 , as otherwise C"'CS,. Let JC"G C " ' n ( S ' -
5,). Then we can show (as in the proof of 1) that (5' - JC") U Χ' Ε 3. 
But S, C (5' - JC") U Χ' Ε 3, contradicting the maximality of 5, in A. 
Thus S 3 is a maximal subset of A. 
Note that S3 is constructed from S, by replacing an element JC' G 5, - 5 2 by 
an element JC G 5 2 - 5,. Since |5 2| > l i j , we can repeat this construction a 
finite number of times to obtain a maximal subset Sn of A with Sn Ε 3 and 
S„ C S2, a contradiction. 
• 
10.4 
MATROID DUALITY AND GRAPHOIDS 
In this section we first introduce the concept of matroid duality and discuss 
some results relating a matroid and its dual. We then establish the 
"painting" theorem, which would lead to the definition of a graphoid. We 
conclude with the development of Minty's self-dual axiom system for 
matroids, which is based on graphoids. 
We begin with a theorem due to Whitney [10.1], which defines the dual of 
a matroid. 
Theorem 10.10. Let 38 be the set of bases of a matroid Μ on a set S. Then 
3 8 * = {S - B\B G 3 8 } is the set of bases of a matroid M* on S. 
Proof. Clearly, 3 8 * satisfies axiom B-l. To show that axiom B-2 is also 
satisfied, consider any two members B* and B\ of 9 8 * with B* = S - B1 
and B* = S - B2. Let xE Β* — B*. Then χ Ε B2 — B1. By Exercise 10.4 
there exists yEBx-B2 
such that B3 = (B, - y) U JC is a base of Μ. Now 
yG Β* - B* and 
(B*-x)Uy 
= 
S-((B,-y)Ux) 
= 5 - β
3 = β * . 
Thus axiom B-2 is satisfied and hence 38 * is the set of bases of a matroid M* 
on 5. 
• 

MATROID DUALITY AND GRAPHOIDS 
277 
The matroid M* denned in Theorem 10.10 is called the dual matroid or 
simply the dual of M. It is easy to see that Μ is the dual of Μ *. So we shall 
refer to Μ and M* as dual matroids. 
The circuit matroid and the cutset matroid of a graph defined in Section 
10.1 may now be seen to be dual matroids. 
A base of M* is called a cobase of Μ. Similarly a circuit of M* is a 
cocircuit of M, a loop of Μ * is a coloop of M, the rank function of M* is the 
corank function of M, and so on. The rank function of Μ * is denoted by p*. 
If Β is a base of M, then the cobase S - Β is denoted by B*. The collection 
of cobases of Μ is denoted by 38*(Λί) and the collection of cocircuits is 
denoted by <£*(M). 
Now we establish some results relating a matroid and its dual. Many of 
these results are well known in graph theory (see Chapter 2). 
It is clear from the definition of a dual that 
The following theorem generalizes this relationship between ρ and p*. 
Theorem 10.11. If Μ and M* are dual matroids on a set S, then for all 
ACS 
Proof. Consider ACS 
and let β* be a base of M* such that |J3* Π 
is 
maximum. Then β is a base of Μ with \B Π (5 - A)\ maximum. It follows 
from the definition of a rank function that 
p*(Af)=|S|-p(Af). 
(10.4) 
p*(A) = \A\ + 
p(S-A)-p(M). 
(10.5) 
p*(A) = 
\B*DA\ 
(10.6) 
and 
p(S - A) 
\BD(S-A)\. 
(10.7) 
Now 
\B*nA\ 
\A\-\BHA\ 
and 
BH(S- 
Α)\ = 
\Β\-\ΒΠΑ\ 
= ρ(Μ)-\ΒΠΑ\ 
. 

278 
MATROIDS 
So we get from (10.6) and (10.7) 
p*(A) = \A\ + p(S-A)-p(M). 
Μ 
Note that for each statement involving the circuits, bases, and so on, of a 
matroid there is a dual statement involving the cocircuits, cobases, and so 
on, of the matroid. This is because the cocircuits, cobases, and so on, are 
themselves are circuits, bases, and so on, of a matroid. 
In all the lemmas and theorems of this section we include the dual 
statements wherever applicable. The proofs of these dual statements follow 
in the obvious manner. 
Lemma 10.1 Let Μ be a matroid on a set S. If A C S is independent in M, 
then 5 - A contains a cobase of M. Dually, if A* C S is independent in M*, 
then S - A* contains a base of M. 
Proof. There exists a base Β of Μ with A C B. So S - A contains the 
corresponding cobase B*. 
• 
Theorem 10.12. Let Μ be a matroid on a set S. If A and A* are subsets of S 
with AD A* = 0, A independent in M and A* independent in Λί*, then 
there exists a base β of Μ with AC Β and A* CB*. 
Proof. By the previous lemma S- A* contains a base of M. Since AC 
S - A* is independent in M, there exists, by Theorem 10.2, a base Β of Μ 
with AC BC S -A*, 
and hence A* C B*. 
• 
Lemma 10.2. Let Μ be a matroid on a set S. Then each base Β of Μ has 
nonnull intersection with every cocircuit of M. 
Dually, each cobase of Μ has nonnull intersection with every circuit of 
M. 
Proof. If, for any cocircuit C* of M, C* Π Β = 0 , then Β* = S - Β would 
contain C*, contradicting the independence of B* in M*. 
• 
Let β* be any cobase of a matroid on a set S. By the dual of Corollary 
10.4.2, for any χ Ε Β, Β* U χ contains exactly one cocircuit. This cocircuit is 
called the fundamental 
cocircuit of χ with respect to B. Note that this 
cocircuit contains exactly one element from B, namely, the element x. 
Lemma 10.3. Let Μ be a matroid. For any independent set A of Μ there 
exists a cocircuit having exactly one element from A. Further, if \A\< 
p(M), then there exists a cocircuit having null intersection with A. 
Dually, for any independent set A* of M* there exists a circuit having 
exactly one element from A*. Further, if \ A*\< p*(M*), then there exists a 
circuit having null intersection with A*. 

MATROID DUALITY AND GRAPHOIDS 
279 
Proof. Let β be a base of Μ with A C B, and let C* be the fundamental 
cocircuit of an element χ Ε Β with respect to B. Then C* Π A = {x} if 
χ Ε A, and C* Π A = 0 if jr G β - Λ. Thus follows the proof. 
• 
Theorem 10.13. Let Μ be a matroid on a set 5. A subset A"of 5 is a base of 
Μ if and only if A" is a minimal subset having nonnull intersection with every 
cocircuit of M. 
Dually, a subset X* of 5 is a cobase of Μ if and only if it is a minimal 
subset having nonnull intersection with every circuit of M. 
Proof. Necessity follows easily from Lemmas 10.2 and 10.3. 
To prove the sufficiency, let A' be a minimal subset of 5 having nonnull 
intersection with every cocircuit of Μ. Then S — X is a maximal subset 
having no cocircuit of Μ. So, by definition, 5 - X is a cobase of M, and 
hence A
r is a base of Μ. 
• 
Next we obtain some new characterizations of circuits and cocircuits. 
Theorem 10.14. Let Μ be a matroid on a set S. A subset AOf S is a circuit 
of Μ if and only if it is a minimal subset having nonnull intersection with 
every cobase of M. 
Dually, a subset X* of 5 is a cocircuit of Μ if and only if it is a minimal 
subset having nonnull intersection with every base of M. 
Proof. See proof of Theorem 2.13. 
• 
Let C* be a cocircuit of a matroid Μ on 5. By the previous theorem, C* 
is a minimal subset having nonnull intersection with every base of M. So 
5 — C* is a maximal subset containing no base of M. Thus we have the 
following. 
Lemma 10.4. If C* is a cocircuit of a matroid Μ on a set 5, then for any 
χ G C*, (S — C*) U χ contains a base Β of M. 
Dually, if C is a circuit of a matroid Μ on a set S, then for any χ EC, 
(S - C)Lix 
contains a cobase of M. 
• 
Theorem 10.15. Let Μ be a matroid on a set S. A subset AOf 5 is a circuit 
of Μ if and only if it is a minimal subset with l A T l C l ^ l for every 
cocircuit C* of M. 
Dually, a subset A'* of 5 is a cocircuit of Μ if and only if it is a minimal 
subset with \X* Π C| Φ 1 for every circuit C of M. 
Proof 
Necessity 
Proof is by contradiction. For any proper subset C of a circuit 
C, there exists, by Lemma 10.3, a cocircuit C* such that |C* Π C'\ = 1. 
Suppose that |C Π C*| = 1 for some circuit C and some cocircuit C*, and 

280 
MATROIDS 
let C Π C* = {*}. Consider now 5' = 5 - C* and C = C - x. Clearly, C C 
5'. By Lemma 10.4, S' U χ contains a base. Let then Β C 5' U χ be a base 
with C C β. Note that xEB. 
So the circuit C = C U χ is contained in B, a 
contradiction. 
Sufficiency 
If A is a subset of S with |ΑΠ C*| ^ 1 for every cocircuit 
C*, then A should contain a circuit, for otherwise X would be independent 
in M, and so by Lemma 10.3 there would exist a cocircuit having exactly one 
element from X. 
Let then C be a circuit contained in A". It is clear from the necessity part 
of the theorem that |C Π C*| ^ 1 for every cocircuit C*. Therefore A = C, 
for otherwise the minimality of A would be contradicted. 
• 
We now introduce the notion of a painting of a finite set 5 and establish 
the "painting" theorem. 
A painting of a set S is a partitioning of S into three subsets R, G, and β 
such that \G\ = 1. For easy visualization we regard the elements in R as 
being "painted red," the element in G as being "painted green," and the 
elements in Β as being "painted blue." 
Theorem 10.16 (Painting Theorem). Let Af be a matroid on a set S. For any 
painting of S, there is either 
1. a circuit C of Μ consisting of the green element and no blue elements 
or 
2. a cocircuit C* of Μ consisting of the green element and no red 
elements. 
Proof. We shall assume that the green element is in some circuit, for 
otherwise it will be a coloop (why?), and the theorem will follow trivially. 
Suppose, for some painting of S, statement 1 is not true. Then consider 
the subset S' = RU G. Clearly, any circuit contained in S' consists of only 
red elements. Let R' be a minimal subset of red elements such that the set 
S" = S' - R' contains no circuit, and let β be a base with S"CB. 
Then we 
can easily see that the fundamental circuit of any element yER' 
with 
respect to Β consists of only red elements. 
Now, let C* be the fundamental cocircuit of the green element with 
respect to B. Suppose C* contains a red element x. Then xER' 
and 
|C* Π Cx\ = 1, where Cx is the fundamental circuit of χ with respect to B. 
This contradicts Theorem 10.15, and hence C* is a cocircuit containing the 
green element and no red elements. Thus statement 2 is true. 
• 
Theorems 10.15 and 10.16 lead us to the definition of a graphoid 
introduced by Minty [10.2]. 
A graphoid is a structure (5, ^,3)) 
consisting of a finite set S and two 

MATROID DUALITY AND GRAPHOIDS 
281 
collections 
and 3 of nonempty subsets of S satisfying the following 
conditions: 
G-l. If C e ^ a n d DE3, 
then | C n D | * l . 
G-2. For any painting of 5, there is either 
a. a member of % consisting of the green element and no blue 
elements or 
b. a member of 3 consisting of the green element and no red 
elements. 
G-3. No member of 
contains another member of 
properly; 
no member of 3 contains another member of 3 properly. 
Theorem 10.17. Let Μ be a matroid on a set 5. Then (5, <€(Μ), <€*(M)) is 
a graphoid. 
Proof. Follows from Theorems 10.15 and 10.16. 
• 
We now proceed to establish the converse of Theorem 10.17. 
Theorem 10.18. Let ( 5 , ^ , 2 ) ) be a graphoid. Then BCS 
is a maximal 
subset containing no member of % if and only if Β contains no member of % 
and S - Β contains no member of 9). 
Proof 
Necessity 
Let β be a maximal subset of 5 containing no member of <€. 
Suppose S - Β contains a member D of 3. Let χ Ε D. Then Β U χ contains 
a member C of 
and χ EC. So CC\D = {x}, contradicting G-l. Thus 
S - Β contains no member of 3). 
Sufficiency 
Let Β C 5 contain no member of ^ and S - Β contain no 
member of 3). We now show that, for any xES- 
Β, Β Ux contains a 
member of <€. 
Consider a painting of 5 in which all the elements of Β are red, χ is green, 
and all the remaining elements of S - Β are blue. Clearly, there is no 
member of 3 containing only green and blue elements. Thus by G-2, BU χ 
contains a member of '4. 
• 
Theorem 10.19. Let (5, 
3) be a graphoid. If β is a maximal subset of 5 
containing no member of 
then 5 - Β is a maximal subset of S containing 
no member of 3. 
Proof. Follows from Theorem 10.18 and its dual. 
• 
Theorem 10.20. Let (5, <β, 3) be a graphoid. Then % is the collection of 
circuits of a matroid Μ on 5 and 3 is the collection of cocircuits of M. 

282 
MATROIDS 
Figure 10.2 
Proof. We first show that <<? is the set of circuits of a matroid M, on 5. 
Clearly, axiom C-l is satisfied. 
To show that C-2 is also satisfied, let C, and C 2 be any two distinct 
members of 
with χ E C, Π C 2 and y E C, - C 2, and consider a painting of 
5 in which y is green, JC is blue, the rest of C, U C 2 are red, and the rest of S 
are blue (see Fig. 10.2). 
Now there exists no member D of 3 consisting of the green element and 
no red elements. For if such a member D of 3 exists, then we can easily 
show that either | Q Π D\ = 1 or |C 2 Π D\ = 1, thereby contradicting G-l. So 
by G-2 there exists a member C 3 of 
consisting of the green element and no 
blue elements. By G-3, {y} is not a member of <£. So it follows that 
y Ε C 3 E (C, U C 2) - JC. Thus axiom C-2 is satisfied, and hence 
is the 
collection of circuits of a matroid M, on 5. 
In a similar way we can show that 3 is the collection of circuits of a 
matroid M2 on S. 
By Theorem 10.19 the bases of Mx are the complements of the bases of 
M 2. So Λ/, and M2 are dual matroids. 
• 
The equivalence of the graphoid axiom system and the circuit axiom 
system follows from Theorems 10.17 and 10.20. This result is due to Minty 
[10.2] who has given an elegant exposition of the theory of matroids based 
on graphoids. 
10.5 
RESTRICTION, CONTRACTION, AND MINORS OF A MATROID 
Consider a graph G with edge set E. Relative to any subset Τ of E, we can 
define two graphs denoted by G\T and G- T. The graph G|T, called the 
restriction of G to T, is obtained from G by deleting (open-circuiting) the 
edges belonging to Ε - Τ and then removing the resulting isolated vertices. 
In fact G\T is the induced subgraph of G on T. The graph G · T, called the 
contraction of G to T, is obtained by contracting the edges belonging to 

RESTRICTION, CONTRACTION, AND MINORS OF A MATROID 
283 
W 
Figure 10.3. (a) Graph G. (b) G\T, restriction of G to T; T= {ex, e6, e7, eg}. (c) 
G · T, contraction of G to T. 
Ε — T. Figure 10.3 shows a graph G and the graphs G\ Τ and G · Τ for 
Τ — {ex, e6, 
e7, 
Now it is easy to verify the following: 
1. A subset X of edges is an acyclic subgraph of G\ Τ if and only if it is an 
acyclic subgraph of G. 
2. A subset X of edges is an acyclic subgraph of G · Τ if and only if there 
exists a subset Y of Ε - Τ such that Y is a spanning forest of 
G\(E — T) and XU Y is an acyclic subgraph of G. 
These ideas motivate the introduction of two submatroids induced on a 
matroid by a subset of the elements of the matroid. 
If J(M) is the set of independent sets of a matroid Μ on S and Τ C S, let 
f(M\T) 
= {X\X QT,XE 
J(M)} 
. 
We can easily show that J(M\ T) is the set of independent sets of a matroid 

284 
MATROIDS 
on Τ. This matroid is denoted by Μ \ Τ and is called the restriction of Μ to T. 
The following observations are obvious: 
1. A C Τ is independent in M\T if and only if X is independent in M. 
2. A C Γ is a circuit of M\T if and only if it is a circuit of M. 
3. If λ is the rank function of M\T, then for any A C T , 
A(A) = p(A). 
(10.8) 
4. If M(G) is the circuit matroid of a graph G with edge set E, then for 
any ΤC E, M(G)\T = 
M(G\T). 
Next we define the submatroid Μ · Τ. Let 3(M · T) be the collection of all 
those subsets X of Τ such that there exists a maximal independent subset Y 
of 5 - Γ with A U y e i ( M ) . 
Theorem 10.21. J(M · T) is the collection of independent sets of a matroid 
on T. 
Proof. Let A, and A 2 be two members of $(Μ·Τ) 
such that |A 2| = 
I A, I + 1. Then there exist maximal independent subsets 7, and Y2 of S - Τ 
with A' = A, U y, and A" = A 2 U Y2 independent in Μ. Now |A"| = |A'| + 
1. So there exists, by axiom 1-3, an element χ EX"- 
X' such that A' U χ is 
independent in M. Note that A" - A' = (A 2 - A,) U (Y2 - Yx). 
Further, 
χ e' y 2 - y, because y, is a maximal independent subset of S - T. So χ ε 
A 2 - A, and (A, U JC) C Τ is a member of J?(M · T). Thus ^(Λί · Γ) satisfies 
axiom 1-3. It is easy to see that axioms 1-1 and 1-2 are also satisfied. 
• 
The matroid defined in Theorem 10.21 is called the contraction of Μ to Τ 
and is denoted by Μ · Τ. Note that if M(G) is the circuit matroid of a graph 
G with edge set Ε then, for any Τ C E, M(G · T) = M(G) • T. 
Let ρ
 T be the rank function of Μ • Τ. Then from the definition of Μ · Τ 
we get, for any 
ACT, 
p
T(A) = p(AU(S-T))-p(S-T). 
(10.9) 
We observed in Chapter 7 that open-circuiting or removing of an edge 
and the contracting of an edge of a graph are dual operations. In particular, 
if G and G' are dual graphs and Τ and T' are the corresponding subsets of 
edges of G and G', respectively, then G\T is the dual of G'-T' 
(see 
Theorem 7.10). The following theorem is the matroid analog of this 
relationship. 
Theorem 10.22. If Μ is a matroid on S and TCS, 
then: 

REPRESENTABILITY OF A MATROID 
285 
1. (M\T)* = M* • T. 
2. (M-T)* 
= M*\T. 
Proof 
1. Let A be the rank function of M\T and A* be the rank function of 
(M\T)*. 
Then from (10.5) we have, for any XC.T, 
X*(X) = \X\ -
X(T) + 
p(T-X). 
Let ρ be the rank function of Μ · Τ and (p*)
T be the rank function 
of Μ * · Τ. Then from (10.9) and (10.5) we get 
(p*)
T(X) 
= p*(X U (5 - T)) + p*(S - T) 
= 
p*(S-(T-X))-p*(S-T) 
= \S\-\T\ 
+ \X\-p(S) 
+ 
p(T-X) 
-(\S\-\T\-p(S) 
+ p(T)) 
= \X\-p(T) 
+ 
p(T-X) 
= |A'|-A(7') + A(7
,-A'), 
by (10.8) 
= λ*(Α-). 
Since (Λ/| Τ)* and Μ* · Τ have the same rank function, we get 
(M\T)* = Μ* · Τ . 
2. Putting Μ for M* in 1 and taking the duals, we get 2. 
• 
If Μ is a matroid on 5 and Τ C 5, a matroid Ν on Τ is called a minor of Μ if 
Ν is obtained by a succession of restrictions and/or contractions of M. This 
topic has been extensively developed by Tutte [10.3]. 
Using the terminology developed thus far, we can state in matroid 
terminology many of the results relating to planar graphs and dual graphs. 
For example, Theorem 7.5 can be stated as follows: 
A graph is planar if and only if the circuit matroid M(G) of the graph 
does not contain either of the matroids M(K5) or M(K33) 
as a minor. 
10.6 
REPRESENTABILITY OF A MATROID 
Let Μ be a matroid on a set 5. Let Β = {6,, b2,..., 
br) be a base of Μ and 
let B* = S - Β = {e,, e2,..., 
eq) be the corresponding cobase of M. Recall 
that Β* Π C(e y) = er j = 1 , . . . , q, where C(e ;) is the fundamental circuit of 

286 
MATROIDS 
er Similarly Β Π C*{bt) = b}, j = 1 , . . . , r, where C*(/>;) is the fundamental 
cocircuit of bf. As in the case of undirected graphs (Chapter 6), we may now 
define the fundamental cocircuit matrix Df and the fundamental circuit matrix 
where U is a unit matrix whose columns correspond to the elements of B. A 
matrix of this form is called a standard representation of Μ with respect to 
the base B. 
Now consider a graph G. Suppose we arbitrarily assign orientations to the 
edges of G and let G' be the resulting directed graph. Then by Theorem 6.9 
the incidence matrix of G' is a representation of the circuit matroid M(G) 
over any field F. We can also see (Theorem 6.10) that any fundamental 
cutset matrix of G' is a standard representation of M(G) over any field F. 
Further by Theorem 6.11 any fundamental circuit matrix of G' is a standard 
representation of the cutset matroid M*(G) of G over any field F. Thus we 
have the following. 
Theorem 10.23. The circuit matroid and the cutset matroid of a graph G are 
both representable over any field F. • 
We now prove the following main theorem of this section. 
Theorem 10.24. If a matroid Μ on 5 is representable over a field F, then the 
dual matroid M* on S is also representable over F. 
Proof. Suppose Μ is of rank r and has η elements. Let the r x η matrix A 
be a representation of Μ over F. 
Let X be the set of all those column vectors χ such that Ax = 0; AT is 
called the null space of A. It is well known in linear algebra that the 
dimension of X is equal to η - r. Now select from X a set of η - r linearly 
independent column vectors, and with these vectors as columns form an 
η x (η - r) matrix B. Note that AB = 0. 
We now show that B' is a representation over F of the dual matroid M*. 
We do so by proving that any r columns of A are linearly dependent if and 
only if the complementary set of η - r columns of B' are linearly dependent. 
For this purpose we shall choose the first r columns of A. Clearly, this 
involves no loss of generality. 
The first r columns of A are linearly dependent if and only if there exists 
a nonzero column vector χ = [ J C , , x2,...,xr, 
0, 0 , . . . ,0]' belonging to X. 
Such a vector xGX exists if and only if there exists a column vector y Φ0 
D* of Μ with respect to the base Β 
the form 
L L / ^ a i i u l i l t j unuurnctuui 
t t r t u t i 
ΙΠΜΙΙΛ 
Clearly, these two matrices will be of 
D], 

BINARY MATROIDS 
287 
with η - r entries and such that 
x= By . 
Now writing Β as 
β] 
where β, is r x ( « - r) and B2 is (n - r) x (n - r), we can see from the 
above equation that B2y = 0. Since y Φ 0, it follows that B2 is singular. Thus 
the rows of B2, and hence the last η - r columns of B' are dependent, and 
the theorem is proved. 
• 
An easy corollary of Theorem 10.24 is the following result. 
Corollary 10.24.1. Let Μ be a matroid of rank r on a set 5 = 
{sl, s2,... 
,sn}. 
If Μ has the standard representation 
S l
 
S2 
' ' '
 Sr
 
Sr+1 
' ' '
 
Sn 
[ 
Ur 
I 
Λ 
], 
then M* has the standard representation 
Sl
 
S 2 ' ' '
 Sr
 
Sr+l ' ' '
 Sn 
[ 
-A' 
I 
un-A 
where Uk is the kx k identity matrix. 
• 
The relationship (6.13) between the fundamental circuit matrix and the 
fundamental cutset matrix of a connected graph follows easily from the 
corollary. 
For further discussions on the matroid representability problem see 
Welsh [10.4]. 
10.7 
BINARY MATROIDS 
A matroid is binary if it is representable over GF(2), the field of integers 
modulo 2. 
Clearly, the circuit matroid M(G) and the cutset matroid M*(G) of a 
graph G are binary. We have proved in Theorem 4.6 that each circuit of 
M(G) can be expressed as a ring sum of some of the fundamental circuits of 

288 
MATROIDS 
G. A similar result is true in the case of the cutsets of G. This property of 
circuits and cutsets (cocircuits) holds true in the case of any binary matroid. 
However, it is not, in general, true in the case of arbitrary matroids. As an 
example, let S = {1,2,3,4} and let M have as its circuits all subsets of three 
elements of S. Then the ring sum of the circuits {1,2,3} and {1,2,4} is 
{3,4}, which is an independent set of M. 
In this section we establish several properties of a binary matroid, which 
would lead us to the development of alternative characterizations of such a 
matroid. 
Let M be a matroid on a set S. Let B = {/>,, b2,..., 
br) be a base of M 
and let B* = S - B = {ex, e2,..., eq} be the corresponding cobase of M. 
Recall that B* Π C(et) = ey, /' = 1,..., q, where C{ej) is the fundamental 
circuit of er Similarly B Π C*(fty) = ft;, / = 1, 
, r, where C*(fty) is the 
fundamental cocircuit of br As in the case of undirected graphs (Chapter 6), 
we may now define the fundamental cocircuit matrix Df and the fundamental 
circuit matrix D* of M with respect to the base B. Clearly, these two 
matrices will be of the form 
b1b2--br 
ele2---eq 
Df = [ 
Ur 
| 
F 
] , 
D}=[ 
G 
I 
I/, 
]. 
Note that Df = [d,t] and D* = [d,*] are both (0,1) matrices. 
Suppose the matrix M is binary. Then it has a standard representation 
over GF(2) of the form 
bxb2---br 
exe2---eq 
[ 
U, 
| 
A 
]. 
(10.10) 
Let the fundamental circuit C(ey) be {e;, bx, b2,...,bk). 
Then the 
modulo 2 sum of the columns of the matrix in (10.10) corresponding to the 
elements of C(e;) is zero. Since the modulo 2 sum of vectors corresponds to 
the ring sum of the corresponding sets, we can see that 
_ f l , 
if ft, e CÎ*,). 
α»-[θ, 
ìib&Qe,). 
In other words 
A = G'. 
(10.11) 
Thus the matrix [Ur G'] is a standard representation over GF(2) of M with 
respect to the base B. 
Starting from a standard representation for the dual matroid M *, we can 

BINARY MATROIDS 
289 
show in a similar manner that [F' 
Uq] is a standard representation over 
GF(2) of M*. 
Since a matroid has a unique standard representation with respect to a 
given base, it follows from Corollary 10.24.1 that 
F=G'. 
(10.12) 
Thus we have proved the following theorem. 
Theorem 10.25. Let Μ be a binary matroid on a set S. 
1. The fundamental cocircuit matrix of Μ with respect to any base is a 
standard representation of M. 
2. The fundamental circuit matrix of Μ with respect to any base is a 
standard representation of M*. 
• 
From (10.12) we also get the following important result. 
Theorem 10.26. Let Μ be a binary matroid. Let Df and D* be the 
fundamental cocircuit matrix and the fundamental circuit matrix of Μ with 
respect to a common base. Then 
Df(D*y 
= o. 
m 
(io.i3) 
Given a circuit C of a matroid M, we can associate with C a (0,1) row 
vector, each entry of which corresponds to an element of M, and an entry in 
this vector is 1 if the corresponding element is in C. For example, the rows 
of D* are the vectors that correspond to the fundamental circuits. The 
matrix of all the circuits vectors of Μ is called the circuit matrix of Μ and is 
denoted by D*(M). 
In a similar way the cocircuit matrix D(M) of Μ is 
defined. 
Suppose χ is the vector corresponding to a circuit C of a binary matroid 
M. Since Df is a standard representation of M, the ring sum of the columns 
of Df corresponding to the elements of C is zero. In other words 
Dfx' = 0. 
(10.14) 
Similarly if χ is a cocircuit vector, we have 
D*fx' = 0. 
(10.15) 
Note that we have assumed that the columns of D *, Df, and χ are arranged 
in the same element order. 
Theorem 10.27. Let Μ be a binary matroid on S. For any base Β and circuit 

290 
MATROIDS 
C of M, if C - Β = { J C , , x2,..., 
xk} and if C(JC,) is the fundamental circuit of 
JC, with respect to B, then 
Proof. Proof is based on (10.12) and (10.14). See proof of Theorem 
6.7. 
• 
To prove the converse of Theorem 10.27, we need the following. 
Theorem 10.28. Let Μ be a matroid. For any base Β and circuit C of M, let 
C = C ( J C , ) Φ C ( J C
2 ) Φ · • · Φ C ( J C J , where {JC,, J C 2 , . . . , JC*} = C - Β and C ( J C , ) 
is the fundamental circuit of JC, in B. Then the ring sum C , φ C
2 of any two 
distinct circuits of Μ contains a circuit of M. 
Proof. Suppose C , φ C
2 does not contain a circuit and let C , Π C2 = {JC, , 
x2,...,xp}. 
Then C , ® C
2 = ( C , U C2)- 
{ J C , , . .. ,jc p} is independent in M. 
So there 
exists a base β D C , φ C
2 . But then Cx- B = C2- B = 
{ J C , , . . . , jc p}, so that by the hypothesis of the theorem, 
contradicting the fact that C\ ¥= C2. 
• 
Theorem 10.29. Let Μ be a matroid. For any base Β and circuit C of M, let 
C = 
C ( J C , ) © C ( J C 2 ) ® - - - ® C ( x k ) , where {JC,, J C 2 , . . . ,xk} = C
- Band 
C ( J C , ) 
is the fundamental circuit of JC, in β. Then Μ is binary. 
Proof. Let Β = {6,, b2,..., 
br) 
be any base of Μ and let S-B 
= 
{e,, e 2 , . . . , e }. The fundamental circuit matrix D*(M) of Λί with respect 
to B is of the form 
C = C ( J C , ) Φ C ( J C 2 ) Φ · · · Φ C ( J C J . 
C , = C ( J C , ) © C ( J C 2 ) Φ · · · Φ C ( J C P ) = C 2 ' 
bxb2--bf 
{ 
Λ 
We prove the theorem by showing that the matrix 
b, b <2---br 
ele2---eq 
Ur 
I 
A' 
} . 
(10.16) 
is a standard representation of Μ over GF(2). 
Let C be a circuit of M. If C-B 
= {eH, e 
,...,e,k 
hypothesis of the theorem 
e, }, then by the 

BINARY MATROIDS 
291 
c=c(eI.)ec(e,2)®---ec(el4). 
It now follows from the definition of A that the modulo 2 sum of the 
columns of the matrix in (10.16) corresponding to the members of C is zero. 
Thus these columns are linearly dependent over GF(2). 
Suppose W= {ft,,..., b„ e , , . . . , e p } is a circuit of the matroid M' 
induced on S by the linear dependence of the corresponding column vectors 
of the matrix in (10.16). Then 
W= C(e,)© C(e2)θ· 
· · θ C(ep) . 
By Theorem 10.28, W contains a circuit C" of Μ. But C cannot be a proper 
subset of W, for then it would contradict that W is a circuit of Μ'. Thus 
W= 
C. 
Hence the matrix in (10.16) is a representation of Μ over GF(2). 
• 
Further characterizations of a binary matroid are given in the following 
theorem. 
Theorem 10.30. For a matroid Μ the following statements are equivalent: 
1. For any circuit C and any cocircuit C* of M, \CD C*\ is even. 
2. The ring sum of any collection of distinct circuits of Μ is the union of 
disjoint circuits of Μ. 
3. For any base Β and circuit C οί M, if C - Β = {e,, e2,..., 
e ] and 
C(e,) is the fundamental 
circuit of e, in the base B, 
then 
C= 
C(ei)®C(e2)®---®C(eq). 
4. Μ is binary. 
Proof 
1φ2 
Let C,, C2,...,Ck 
be distinct circuits of M, and let A = 
Cl®C2®---®Ck. 
We may assume without loss of generality that A 
contains no loops. 
Since for any cocircuit C*,\C* Π C,\ is even for 1 ^ i
1 ^ k, it follows easily 
that 
Π C*| is also even. Suppose that A is not dependent. Then a 
contradiction results because by Lemma 10.3 there exists a cocircuit having 
exactly one element from A. Thus A is dependent and contains a circuit C. 
If A = C, the theorem is proved. If not, let Ax = A ® C. Note that for 
any cocircuit C*, \ C* Π Αλ\ is even. So we may now repeat the argument on 
A,. Since A, is finite and A, = A - C, this process will eventually termi-
nate, yielding a finite collection of disjoint circuits whose union is A. 
2φ3 
See proof of Theorem 4.6 
3=p4 
Same as Theorem 10.29. 

292 
MATROIDS 
10.8 
ORIENTABLE MATROIDS 
A matroid Μ is orientable if it is possible to assign negative signs to some of 
the nonzero entries in the circuit matrix D* = D*(M) and in the cocircuit 
matrix D = D(M) in such a way that the inner product of any row of the 
signed circuit matrix with any row of the signed cocircuit matrix is zero over 
the ring of integers. 
Clearly, the circuit matroid and the cutset matroid of a graph are both 
orientable. 
A painting of an orientable matroid Μ is a partitioning of the elements of 
Μ into three sets R, G, and Β and the distinguishing of one element of the 
set G. We can visualize this as coloring of the elements of Μ with three 
colors, each element being painted red, green, or blue, and exactly one 
green element being colored dark green. Note that the dark green element 
is also to be treated as a green element. 
The main result of this section is the "arc coloring lemma" due to Minty 
[10.2]. 
Theorem 10.31 (Arc Coloring Lemma). Let Μ be an orientable matroid. For 
any painting of the elements of M, exactly one of the following is true: 
1. There exists a circuit containing the dark green element but no blue 
elements, in which all the green elements are similarly oriented (i.e., 
all have the same sign in the signed circuit matrix). 
2. There exists a cocircuit containing the dark green element but no red 
elements, in which all the green elements are similarly oriented. 
Proof. Proof is by induction on the number of green elements. 
If there is only one green element, the result follows by axiom G-2. 
Suppose the result is true when the number of green elements is m. 
Consider then a painting in which there are m + 1 green elements. Choose a 
green element χ other than the dark green element (see Fig. 10.4). 
4φ1 
By Theory 10.27 each circuit C can be expressed in terms of 
fundamental circuits as 
C = C{xx)Θ C(x2)Θ · · · Θ 
C(xk). 
By (10.15), |C* Π C(x,)\ is even for all 1 < i < k. So it now readily follows 
that |C* Π C| is even. 
• 
Obviously, alternative characterizations of a binary matroid in terms of 
cocircuits can be obtained by replacing circuits by cocircuits in Theorem 
10.30. 

ORIENTABLE MATROIDS 
293 
Figure 10.4 
Color the element Λ: red. In the resulting painting there are m green 
elements. If now there is a cocircuit of type 2, the theorem is proved. 
Suppose we color χ blue. If in the resulting painting there is a circuit of 
type 1, the theorem is proved. 
Suppose neither of the two occurs. Then by the induction hypothesis we 
have the following: 
a. There is a cocircuit of type 2 when χ is colored blue. 
b. There is a circuit of type 1 when χ is colored red. 
Now let the corresponding rows of the signed circuit and cocircuit matrices 
be as shown: 
dg 
R 
Β 
G 
χ 
Cocircuit 
+1 
0 0 - - - 0 
0 
1 - 1 · ·-01 
1 1 - 1 0 
? 
Circuit 
+1 
- 1 1 - 0 - 1 
0 
0 - 0 0 
0 1 - - 1 0 
? 
Here we have assumed without loss of generality that +1 appears in the 
dark green position of both vectors. 
By definition, the inner product of these two vectors is zero. The 
contribution to this inner product from the dark green element is 1; from all 
the red and blue elements, zero; from the green elements, a nonnegative 
integer p; and from x, an unknown integer q, which must be 0, 1, or —1. 
Thus we have 1 + ρ + q = 0. This equation is satisfied only for ρ = 0 and 
q = - 1 . Therefore in one of the two vectors the question mark is +1 and in 
the other it is - 1 . Choosing the vector in which the question mark is 1, we 
get the desired circuit or cocircuit. 
Thus either statement 1 or statement 2 occurs. Both cannot occur 
simultaneously, for then the inner product of the corresponding circuit and 
cocircuit vectors will not be zero. 
• 
The arc coloring lemma in the special case of graphs ([10.5] and [10.6]), 
is obvious. 

294 
MATROIDS 
10.9 
MATROIDS AND THE GREEDY ALGORITHM 
Consider a set S whose elements s, have been assigned nonnegative weights 
w(s,). The weight of a subset of S is defined as equal to the sum of the 
weights of all the elements in the subset. Let J be a collection of subsets of 
S. Many problems in combinatorial optimization reduce to the following 
problem: 
Determine a maximum weight member of 
For example, finding a maximum weight spanning tree of a weighted 
connected graph G reduces to the above problem, where J is the collection 
of all spanning trees of G. 
The following algorithm, called the greedy algorithm, naturally suggests 
itself to solve such a combinatorial optimization problem. 
Algorithm 10.1 The Greedy Algorithm 
51. Choose an element i , such that { i , } G $> and such that H>(i,) > w(s) 
for all s with {s} G J. If no such J, exists, stop. 
52. Choose an element s 2 such that {J, , i 2} G $ and such that w(s2) a 
w(s) for all s Φ sx with {s,, s) G 
If no such element s2 exists, stop. 
Sk. Choose an element sk distinct from sx, s2,... 
,sk_x 
such that {i,, 
s 2 , . . . , sk_l, 
sk) G $ and such that w(sk) is a maximum over all such 
s. If no such sk exists, stop. 
• 
Clearly, when the greedy algorithm terminates, it will have picked a 
maximal member of 3>. But this member may not be of maximum weight in 
For example, if 
S = {a, b,c, d) , 
tv(a) = 4 , 
w(b) = 3, 
w(c) = 2, 
w(d) = 2, 
and 
J = {{a},{a, 
c),{b, 
c, d),{b, 
d}}, 
then the algorithm will pick {a,c}. 
But {b, c, d) is a maximum weight 
member of S. However, suppose we modify the weights so that 
w(a) = 6, 
w(b) = 3, 
w(c) = 2, 
w(d) = 2. 
The algorithm will again pick {a,c}, 
which is now a maximum weight 
member of J. 
Next we investigate the relationship between the greedy algorithm and 
the structure of J. 

MATROIDS AND THE GREEDY ALGORITHM 
295 
Consider a matroid Μ on a set S. Let $ be the collection of independent 
sets of M. Let 
Λ = {<*!' « 2 . · • • . « « } 
and 
/2 = {ft,,ft2,...,ft„} 
be two independent sets whose elements are arranged in the order of 
nonincreasing weights. Thus w(ax) s: w(a2) > · · · > w(am) 
and w(ft,) > 
w(b2) > · · · > »v(i»n). Then /, is lexicographically greater than / 2 if there is 
some k such that w(a,) = vf(ft,) for 1 £ i s k - 1 and 
> w(bk) or else 
νν(α,) = w(ft,) for 1 < i < η and m > n. A set that is not lexicographically less 
than any other set is said to be lexicographically maximum. 
From this 
definition it should be clear that a lexicographically maximum independent 
set must be a base. 
A set Β Ε J
1 is Gale optimal in 3> if for every / ε 3> there exists a 
one-to-one correspondence between / and Β such that, for all a El, 
w(a)< w(ft), where b is the element of Β that corresponds to a. Clearly, 
only bases can be Gale optimal. Also if a base is Gale optimal, then it must 
have maximum weight. 
In the following we assume that the elements of each set are arranged in 
the order of nonincreasing weights. 
Theorem 10.32. Let β be the collection of independent sets of a matroid on 
S and Β a base of M. For any nonnegative weighting of the elements of S, 
the following are equivalent: 
1. β is lexicographically maximum in J. 
2. Β is Gale optimal in β. 
3. β is a maximum weight member of β. 
Proof 
1=£>2 
Let β = {ft,, b2,..., 
br) be a lexicographically maximum base of 
M. Suppose β is not Gale optimal. Then there exists an independent set 
/ = {a,, a2,...,ak) 
such that νν(α,) = iv(ft,) for 1 < / < A: - 1, and 
w(ak)> 
w(bk). 
Consider then the independent sets Bk_x = {ft,, b2,... 
,bk_l) 
and 
/ = {a,, a2,..., 
ak). By axiom 1-3 there exists α;. ε / such that 
/' = 
{bl,b2,...,bk_l,aJ} 
is an independent set. But then / ' is lexicographically greater than Β 
because νν(α,)2= w(ak)> 
w(bk), which contradicts that Β is lexicographically 
maximum in $. 

296 
matroids 
As B' is a maximum weight base, it follows that w(b,) = tv(6,). Hence B' is 
also lexicographically maximum. 
• 
It is easy to show (as in the proof of 1 Φ 2 in Theorem 10.32) that the 
greedy algorithm will pick a lexicographically maximum base that, by 
Theorem 10.32, has maximum weight. Thus we have the following. 
Theorem 10.33. Let $ be the collection of independent sets of a matroid on 
5 whose elements have been assigned nonnegative weights. The greedy 
algorithm when applied on $ will pick a maximum weight member of S. 
• 
In view of Theorem 10.33 it is clear that a maximum weight base will be 
selected if we choose the elements of the matroid in the order of nonincreas-
ing weights, rejecting an element only if its selection would destroy the 
independence of the set of chosen elements. The greedy algorithm to pick a 
minimum weight base is obvious. 
As an example, consider the weighted graph G in Fig. 10.5. The weights 
of the edges are as shown in the figure. The greedy algorithm to select a 
maximum weight spanning tree of G will first arrange the edges in the order 
of nonincreasing weight. Thus the edges will be ordered as 
The algorithm will pick the first three edges a, b, and e because they do not 
w{b,) > w{b[) 
for all 1 < i < r . 
a, b, e, f, d, c,g,h 
. 
a 
Figure 10.5. A weighted graph. 
6 
2=>3 
Obvious. 
3=pl 
Let B = {b1, b2,...,br) 
be a lexicographically maximum base 
and B' = [b[, b'2,..., 
b'r) be a base of maximum weight. Since 1 Φ 2 , it 
follows that 

MATROIDS AND THE GREEDY ALGORITHM 
297 
contain any circuit. The edge / will be rejected because the set {a, b, e) U 
{/} contains a circuit. The edge d will then be picked, c will be rejected 
because it forms a circuit with e and d, which have already been picked. For 
the same reason g and h will also be rejected. Thus the greedy algorithm 
picks {a, b, e, d}, which is a maximum weight spanning tree of G. 
We now prove the converse of Theorem 10.33. 
Theorem 10.34. Let 3> be the collection of subsets of a set S with the 
property that A G J and Β C A implies that BE.3>. Then for all nonnegative 
weightings of the elements of S, the greedy algorithm when applied on $• 
picks a maximum weight number of $ only if 3> is the collection of 
independent sets of a matroid on 5. 
Proof. It is clear from the independence axioms that we have only to show 
that if A = {a,, a 2 , . . . ,ak) £ $ and Β = {bx, b2,..., 
bk+l} 
£ 3>, then there 
exists a b,0 A such that A U bt £ J
1. 
For this purpose let us define a weighting of the elements of S as follows: 
w(o,) = l , 
l s / < f c , 
w(b,) = x, 
b,(EB-A, 
w(e) = 0, 
eES-(AU 
Β) , 
where 0 < J C < 1 . Then the greedy algorithm first selects the elements 
a,, a2,..., 
ak. If no b, exists with {b„ a , , . . . , ak) £ β, the algorithm will 
thereafter select from members of S - (A U B). So when it terminates, it 
will have picked a set whose weight is equal to the weight of A. 
If \BC\A\ = t, then 
w(A) = A: 
and 
w(B) = t + (k + \-t)x 
. 
Clearly, we can select 0 < χ < 1 such that w(A) < w(B). But then the greedy 
algorithm will not have selected a maximum weight member of $. This is a 
contradiction. 
• 
The greedy algorithm for the problem of finding a maximum weight 
spanning tree was first discovered by Kruskal [10.7]. The extension of this 
algorithm to matroids was independently discovered by Rado [10.8], Ed-
monds [10.9], Gale [10.10], and Welsh [10.11]. For further discussions of the 
maximum weight spanning tree problem see Section 11.3. 

298 
MATROIDS 
10.10 
FURTHER READING 
Welsh [10.4], Randow [10.12], and Recski [10.13] are excellent texts that 
contain a wealth of information on matroid theory. Berge [10.14] has a 
chapter on matroids. Wilson [10.15] gives an elegant introduction to mat-
roids. He brings out clearly the power of the generality of a matroid by 
including simple proofs of two theorems on edge-disjoint spanning trees in a 
graph. In addition to Whitney's original paper [10.1], we highly recommend 
for further reading the papers by Rado [10.16], Lehman [10.17], Tutte 
[10.18] through [10.21], Mirsky [10.22], Harary and Welsh [10.23], Wilson 
[10.24], Edmonds [10.25], and Edmonds and Fulkerson [10.26], as well as 
the books by Mirsky [10.27], Lawler [10.28], Papadimitriou and Steiglitz 
[10.29], and Graver and Watkins [10.30]. 
Tutte [10.3], [10.18], and [10.19] develops the theory of chain groups and 
matroids. He defines a matroid as regular if it is isomorphic to the matroid 
of a regular chain group. It can be shown that a matroid is regular if and 
only if it is representable over every field. Another characterization is that a 
matroid is regular if and only if it is orientable [10.2]. Tutte also develops 
necessary and sufficient conditions for a matroid to be graphic. A binary 
matroid is graphic if and only if it does not contain as minor the Fano 
matroid or its dual or M*(KS) 
or Μ*(K3 
3). For more discussions on this 
question see [10.20] and [10.4]. (See Exercise 10.22 for a definition of the 
Fano matroid.) 
For a theory of connectivity in matroids see Tutte [10.21]. For a theory of 
orientability that is applicable to general matroids, see Bland and Las 
Vergnas [10.31] and Folkman and Lawrence [10.32]. 
Lehman [10.17] gives a solution of the Shannon switching game using 
matroid concepts. See Edmonds [10.33], Bruno and Weinberg [10.34], and 
Welsh [10.4]. 
A beauty of matroid theory is its unifying nature, which has yielded 
simple proofs of several results in transversal theory and graph theory. See 
Edmonds [10.25] and [10.33] and Wilson [10.15]. 
For matroid algorithms see Lawler [10.28], Papadimitriou and Steiglitz 
[10.29], and Recski [10.13]. See also Knuth [10.35], Edmonds [10.36], and 
Welsh [10.4]. 
Matroid theory is now being increasingly used in the study of electrical 
network problems. Recski [10.13] gives a detailed treatment of applications 
of matroids in electrical network theory. See also Duffin [10.37], Duffin and 
Morley [10.38], Narayanan [10.39], Bruno and Weinberg [10.40], [10.41] 
and [10.42], Iri and Tomizawa [10.43], Recski [10.44] and [10.45], and 
Peterson [10.46]. Bruno and Weinberg [10.40] also give a good introduction 
to matroid theory. For network-theoretic applications of the arc coloring 
lemma see Vandewalle and Chua [10.47], Chua and Greene [10.48], and 
Wolaver [10.49]. 

EXERCISES 
299 
10.11 
EXERCISES 
10.1 
Let Μ be a matroid on 5 with ACS. 
Define J
1' to be the collection 
of subsets AOf 5 such that X is independent in Μ and Χ Π A = 0 . 
Prove that 3' is the collection of independent sets of a matroid on S. 
10.2 
Let S be a set having η elements. Show that the collection J of all 
subsets of S having k or fewer elements is the set of independent sets 
of a matroid. This matroid is called the uniform matroid of rank k 
and is denoted by Uk „. 
10.3 
Let Μ be a matroid on S, and let Bu 
B2 be distinct bases of M. 
Prove that there exists a one-to-one correspondence between β, and 
B2 such that for all eEBu 
(B2- 
e')U e is a base of M, where 
e' Ε Β2 corresponds to e. 
10.4 
If β,, B2 are bases of a matroid Μ and A'1 C β,, prove that there 
exists X2 C B2 such that (β, - Χλ) U X2 and ( β 2 - X2) U AT, are both 
bases of Μ (Greene [10.50]). (See also [10.12], Chap. V.) 
10.5 
Let 3 be a collection of nonnull subsets of S such that for any two 
distinct members Χ, Y of 3 with Λ Γ Ε Α Ί Ί Κ , yEX- 
Y there exists 
Ζ Ε 3 such that y Ε Ζ C (Α' U Y) - x. Then prove that the collection 
3' of minimal members of 3) is the set of circuits of a matroid (Tutte 
[10.3]). 
10.6 
If C is a circuit of a matroid Μ and a EC, prove that there exists a 
base β such that C = C(a, B). 
10.7 
Prove that if β is a base of a matroid Μ and xE B, there is exactly 
one cocircuit C* of Μ such that C* Π (β - χ) = 0 . 
10.8 
If C is a circuit of a matroid Λ/ and x, y are distinct elements of C, 
prove that there exists a cocircuit C* containing χ and .y but no other 
element of C (Minty [10.2]). 
10.9 
Let Μ be a matroid on S and let x, y, ζ be distinct elements of 5. If 
there is a circuit C, containing χ and y and a circuit C 2 containing y 
and z, then prove that there exists a circuit C 3 containing χ and z. 
10.10 
A set A C S is closed in a matroid Μ on 5 if for all J C E 5 - A, 
p(A U x) = p(A) + 1. Show that the intersection of two closed sets is 
a closed set. 
10.11. 
Let Μ be a matroid on a set S. The closure σ(Α) of a subset A of 5 
is the set of all elements χ of S with the property that p(A Ux) = 
p(A). Prove the following: 
(a) If 
Λ: is contained in a(AL)y) 
but not in σ(Α), 
then y is 
contained in σ(Α U x). 

300 
MATROIDS 
(b) An element JC belongs to σ(Α) if and only if JC £ A or there 
exists a circuit C of Μ for which C - A = { J C } . 
10.12 A hyperplane of a matroid Μ on S is a maximal proper closed subset 
of S. Show that Η is a hyperplane of the matroid Μ if and only if 
S - Η is a cocircuit of Μ (see Welsh [10.4] for a matroid axiom 
system in terms of hyperplanes). 
10.13 Show that if Μ is a matroid on 5 and ACS, 
then the contraction 
Μ · Τ of Μ to Γ is the matroid whose cocircuits are precisely those 
cocircuits of Μ which are contained in A. 
10.14 If Μ is a matroid on S and TCXCS, 
prove the following: 
(a) 
M\T=(M\X)\T. 
(b) Μ· Τ=(Μ· 
Χ)· Τ. 
(c) (M\X)-T 
= 
(M-(S-(X-T)))\T. 
(d) (M · Jf)l Γ = (M\S -(X- 
T)) • T. 
10.15 A matroid Μ on S is connected or nonseparable if for every pair of 
distinct elements JC and y of S there is a circuit of Μ containing χ and 
y. Otherwise it is disconnected or separable. Show that a matroid Μ 
is connected if and only if its dual Μ * is connected. 
(Note: If G is a graph, then M(G) is connected if and only if G is 
2-connected.) 
10.16 Show that a matroid Μ on 5 is not connected if and only if there 
exists a proper subset A of 5 such that 
p(A) + p(S-A) 
= p(S) 
(Whitney [10.1]). 
10.17 Prove or disprove: Graph G is contractible to Η if and only if M(G) 
contains M(H) as a contraction minor. 
10.18 Prove that the uniform matroid U2 4 is representable over every field 
except GF(2). 
10.19 Prove that a matroid is binary if and only if for any circuit C and 
cocircuit C*, \CΠ C * | ^ 3 . 
10.20 Let 9 be a family of finite nonempty subsets of a set S. A transversal 
of a subfamily of 
is called a partial transversal of S*. Show that if 9* 
is a collection of finite nonempty subsets of a set S, then the 
collection of partial transversals of 9
s is the set of independent sets of 
a matroid on 5. (See Section 8.6 for the definition of a transversal.) 
Find the rank function of this matroid. A matroid Μ on 5 is called a 
transversal matroid if there exists some family 9
s of subsets of S such 

EXERCISES 
301 
that S(M) 
is the family of partial transversals of 5*. Find the rank 
function of a transversal matroid (see Theorem 8.15). 
10.21 Show that every fc-uniform matroid is a transversal matroid. 
10.22 The Fano matroid F is the matroid defined on the set 5 = {1, 2, 3, 4, 
5, 6, 7} whose bases are all those subsets of S containing three 
elements except {1, 2, 3}, {1, 4, 5}, {1, 6, 7}, {2, 4, 7}, {2, 5, 6}, 
{3, 4, 6}, and {3, 5, 7}. Show that F is 
(a) binary, 
(b) nontransversal, 
(c) nongraphic, and 
(d) noncographic. 
10.23 
Show that the circuit matroid of KA is not a transversal matroid. 
10.24 A matroid Μ on S is Eulerian if S can be expressed as the union of 
disjoint circuits. A matroid is bipartite if every circuit of Μ contains 
an even number of elements. Prove that a matroid is bipartite if and 
only if M* is Eulerian. 
10.25 
Let D be a directed graph without self-loops and let X and Y be two 
disjoint sets of vertices of D. A subset A of X is called independent 
if there exist \A\ vertex-disjoint chains from A to Y. Show that these 
independent sets form the independent sets of a matroid on X. (Such 
a matroid is called a gammoid.) (See Mason [10.51].) 
10.26 
A matroid Μ on S is base orderable if for any two bases β,, B2 of Μ 
there exists a one-to-one correspondence between B, and B2 such 
that for each xE.Bx, 
both (Bx - x) U x ' and (B2 - x')Ux 
are bases 
of Μ where x' is the element of B2 that corresponds to x. Show the 
following: 
(a) M(KA) is not base orderable. 
(b) If Μ is base orderable on S and TC.S, 
then M\T is base 
orderable. 
(c) If Μ is base orderable, then any minor of Μ is base orderable. 
10.27 
Let Mx and M2 be two matroids on a set S. 
(a) Show that the set of all unions / U / of an independent set / of 
M, and an independent set J of Μ2 form the independent sets of 
a new matroid. (This matroid is called the union of Mx and M2 
and is denoted by Mt U M2.) 
(b) If p, and p 2 denote the rank functions of matroids Μ, and M2 on 
a set 5, show that 
p(A) = mm {Pl(X) 
+ p2(X) + \A- 
X\} 

302 
MATROIDS 
min max w(e) — max min 
w(e). 
Best 
( E B 
C'et'eec 
where ACS 
and ρ is the rank function of A/, U M2 (Wilson 
[10.15], pp. 154-158). 
10.28 Let Af be a matroid on S. Prove the following: 
(a) Ai contains k disjoint bases if and only if, for any / I C S , 
p(A) + 
\S-A\>kp(.S). 
(b) S can be expressed as the union of not more than k independent 
sets if and only if for any 
ACS, 
kp(A)>\A\. 
[Hint: Consider the union of k copies of A/ and use the result of 
Exercise 10.27 (Wilson [10.15], pp. 154-158).] 
10.29 Show that when the greedy algorithm has chosen A: elements, these k 
elements are of maximum weight with respect to all independent sets 
of k or fewer elements. 
10.30 A number of jobs are to be processed by a single machine. All jobs 
require the same processing time. Each job has assigned to it a 
deadline. 
(a) Show that the collection of all subsets of jobs that can be 
completed on time forms the independent sets of a matroid. 
(b) Suppose each job has a penalty that must be paid if it is not 
completed by its deadline. In what order should these jobs be 
processed so that the total penalty is minimum? 
10.31 Let A/ be a matroid whose elements have been assigned nonnegative 
weights. Prove the following: 
(a) No element of a maximum weight base is the smallest element of 
any circuit of M. 
(b) Each element of a maximum weight base is the largest element 
of at least one cocircuit of M. 
Using (b), design a procedure for constructing a maximum weight 
base of a matroid. (Prim [10.52] describes such a procedure for 
constructing a minimum weight spanning tree of a connected graph.) 
10.32 Let Μ be a matroid on S with nonnegative weights assigned to the 
elements of S. Let S3 be the collection of bases of Μ and %* the 
collection of cocircuits of A/. Prove 

REFERENCES 
303 
10.12 
REFERENCES 
10.1 
Η. Whitney, "On the Abstract Properties of Linear Dependence," Am. J. 
Math., Vol. 57, 509-533 (1935). 
10.2 
G. J. Minty, "On the Axiomatic Foundations of the Theories of Directed 
Linear Graphs, Electrical Networks and Network Programming," /. Math, 
and Mech., Vol. 15, 485-520 (1966). 
10.3 
W. T. Tutte, Introduction to the Theory of Matroids, American Elsevier, New 
York, 1971. 
10.4 
D. J. A. Welsh, Matroid Theory, Academic Press, New York, 1976. 
10.5 
G. J. Minty, "Monotone Networks," Proc. Roy. Soc, A, Vol. 257, 194-212 
(1960). 
10.6 
G. J. Minty, "Solving Steady-State Non-Linear Networks of 'Monotone' 
Elements," IRE Trans, Circuit Theory, Vol. CT-8, 99-104 (1961). 
10.7 
J. B. Kruskal, "On the Shortest Spanning Subgraph of a Graph and the 
Travelling Salesman Problem," Proc. Am. Math. Soc, Vol. 7, 48-49 (1956). 
10.8 
R. Rado, "Note on Independence Functions," Proc. London Math. Soc, 
Vol. 7, 300-320 (1957). 
10.9 
J. Edmonds, "Matroids and the Greedy Algorithm," Math. Programming, 
Vol. 1, 127-136 (1971). 
10.10 D. Gale, "Optimal Assignments in an Ordered Set: An Application of 
Matroid Theory," J. Combinatorial Theory, Vol. 4, 176-180 (1968). 
10.11 D. J. A. Welsh, "Kruskal's Theorem for Matroids," Proc. Cambridge Phil. 
Soc, Vol. 64, 3-4 (1968). 
10.12 Rabe von Randow, Introduction to the Theory of Matroids, Springer Lecture 
Notes in Mathematical Economics, Vol. 109, Springer-Verlag, Berlin, 
1975. 
10.13 A. Recski, Matroid Theory and Its Applications in Electric Network Theory 
and Statics, Springer-Verlag, Berlin, 1989. 
10.14 C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
10.15 R. J. Wilson, Introduction to Graph Theory, Oliver and Boyd, Edinburgh, 
1972. 
10.16 R. Rado, "A Theorem on Independence Relations," Quart, J. Math (Ox-
ford), Vol. 13, 83-89 (1942). 
10.17 A. Lehman, "A Solution of the Shannon Switching Game," SIAM J. Appl. 
Math., Vol. 12, 687-725 (1964). 
10.18 W. T. Tutte, "A Homotopy Theorem for Matroids-I and II," Trans. Am. 
Math. Soc, Vol. 88, 144-174 (1958). 
10.19 W. T. Tutte, "Lectures on Matroids," J. Res. Nat. Bur. Stand., Vol. 69B, 
1-48 (1965). 
10.20 W. T. Tutte, "Matroids and Graphs," Trans. Am. Math. Soc, Vol. 90, 
527-552 (1959). 
10.21 W. T. Tutte, "Connectivity in Matroids," Canad. J. Math., Vol. 18, 1301-
1324 (1966). 

304 
MATROIDS 
10.22 L. Mirsky, "Application of the Notion of Independence to Combinatorial 
Analysis," J. Combinatorial Theory, Vol. 2, 327-357 (1967). 
10.23 F. Harary and D. J. A. Welsh, "Matroids versus Graphs," in The Many 
Facets of Graph Theory, Springer Lecture Notes, Vol. 110, Springer-Verlag, 
Berlin, 1969, pp. 155-170. 
10.24 R. J. Wilson, "An Introduction to Matroid Theory, Am. Math. Monthly, 
Vol. 80, 500-525 (1973). 
10.25 J. Edmonds, "Minimum Partition of a Matroid into Independent Subsets," /. 
Res. Nat. Bur. Stand., Vol. 69B, 67-72 (1965). 
10.26 J. Edmonds and D. R. Fulkerson, "Transversals and Matroids Partition," /. 
Res. Nat. Bur. Stand., Vol. 69B, 147-153 (1965). 
10.27 L. Mirsky, Transversal Theory, Academic Press, London, 1971. 
10.28 E. L. Lawler, Combinatorial Optimization: Networks and Matroids, Holt, 
Rinehart and Winston, New York, 1976. 
10.29 C. H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Al-
gorithms and Complexity, Prentice-Hall, Englewood Cliffs, N.J., 1982. 
10.30 J. E. Graver and M. Watkins, Combinatorics with Emphasis on the Theory of 
Graphs, Springer-Verlag, New York, 1977. 
10.31 R. G. Bland and M. Las Vergnas, "Orientability of Matroids," /. Combina-
torial Theory B, Vol. 24, 94-123 (1978). 
10.32 J. Folkman and J. Lawrence, "Oriented Matroids," J. Combinatorial Theory 
B, Vol. 25, 199-236 (1978). 
10.33 J. Edmonds, "Lehman's Switching Game and a Theorem of Tutte and 
Nash-Williams," J. Res. Nat. Bur. Stand., Vol. 69B, 73-77 (1965). 
10.34 J. Bruno and L. Weinberg, "A Constructive Graph-Theoretic Solution of the 
Shannon Switching Game," IEEE Trans. Circuit Theory, Vol. CT-17, 74-81 
(1970). 
10.35 D. E. Knuth, "Matroid Partitioning," Stanford University Rep. STAN-CS-
73-342, 1-12 (1973). 
10.36 J. Edmonds, "Matroid Partition," in Lectures in Appl. Math., Vol. 11: 
Mathematics of Decision Sciences, 1967, pp. 335-346. 
10.37 R. J. Duffin, "Topology of Series-Parallel Networks," J. Math. Anal. Appl., 
Vol. 10, 303-318 (1965). 
10.38 R. J. Duffin and T. D. Morley, "Wang Algebra and Matroids," IEEE Trans. 
Circuits and Syst., Vol. CAS-25, 755-762 (1978). 
10.39 H. Narayanan, "Theory of Matroids and Network Analysis," Ph.D. Thesis, 
Indian Institute of Technology, Bombay, India, 1974. 
10.40 J. Bruno and L. Weinberg, "Generalized Networks: Networks Embedded on 
a Matroid, Part 1," Networks, Vol. 6, 53-94 (1976). 
10.41 J. Bruno and L. Weinberg, "Generalized Networks: Networks Embedded on 
a Matroid, Part 2," Networks, Vol. 6, 231-272 (1976). 
10.42 L. Weinberg, "Matroids, Generalized Networks and Electric Network Syn-
thesis," J. Combinatorial Theory B, Vol. 23, 106-126 (1977). 
10.43 M. Iri and N. Tomizawa, "A Unifying Approach to Fundamental Problems 

REFERENCES 
305 
in Network Theory by Means of Matroids," Electron. Commun. in Japan, 
Vol. 58-A, 28-35 (1975). 
10.44 A. Recski, "On Partitional Matroids with Applications," in Coll, Math. Soc. 
J. Bolyai, Vol. 10: Infinite and Finite Sets, North-Holland-American 
Elsevier, Amsterdam, 1974, pp. 1169-1179. 
10.45 A. Recski, "Matroids and Independent State Variables," Proc. 2nd Euro-
pean Conf. Circuit Theory and Design, Genova, 1976. 
10.46 B. Petersen, 'Investigating Solvability and Complexity of Linear Active 
Networks by Means of Matroids," IEEE Trans. Circuits and Syst., Vol. 
CAS-26, 330-342 (1979). 
10.47 J. Vandewalle and L. O. Chua, "The Colored Branching Theorem and Its 
Applications in Circuit Theory," IEEE Trans. Circuits and Systems, Vol. 
CAS-27, 816-825 (1980). 
10.48 L. O. Chua and D. M. Greene, "Graph-Theoretic Properties of Dynamic 
Nonlinear Networks," IEEE Trans. Circuits and Systems, Vol. CAS-23, 
292-312 (1976). 
10.49 D. A. Wolaver, "Proof in Graph Theory of the No Gain Property of Resistor 
Networks." IEEE Trans. Circuits and Systems, Vol. CAS-17, 436-437 
(1970). 
10.50 C. Greene, "A Multiple Exchange Property for Bases," Proc. Am. Math. 
Soc, Vol. 39, 45-50 (1973). 
10.51 J. H. Mason, "On a Class of Matroids Arising from Paths in Graphs," Proc. 
London Math. Soc, Vol. 25, 55-74 (1972). 
10.52 R. C. Prim, "Shortest Connection Networks and Some Generalizations," 
Bell Sys. Tech. J., Vol. 36, 1389-1402 (1957). 

CHAPTER 11 
GRAPH ALGORITHMS 
Graphs arise in the study of several practical problems. The first step in such 
studies is to discover graph-theoretic properties of the problem under 
consideration that would help us in the formulation of a method of solution 
to the problem. Usually solving a problem involves analysis of a graph or 
testing a graph for some specified property. Graphs that arise in the study of 
real-life problems are very large and complicated. Analysis of such graphs in 
an efficient manner, therefore, involves the design of efficient computer 
algorithms. 
In this and the following chapter of the book we discuss several graph 
algorithms. We consider these algorithms to be basic in the sense that they 
serve as building blocks in the design of more complex algorithms. These 
algorithms will also help us provide the reader with further insight on some 
of the topics discussed in the previous chapters as well as introduce new 
concepts. While our main concern is to develop the theoretical foundation 
on which the design of the algorithms is based, we also develop results 
concerning the computational complexity of these algorithms (in particular, 
in Chapter 12). In certain cases the computational complexity depends 
crucially on the computational complexity of certain basic operations such as 
finding union of disjoint sets. In such cases we provide adequate references 
for the interested reader to pursue further. 
The computational complexity of an algorithm is a measure of the 
running time of the algorithm. Thus it is a function of the size of the input. 
In the case of graph algorithms, complexity results will be in terms of the 
number of vertices and the number of edges in the graph. In the following a 
function g(n) is said to be 0( /(n)) if and only if there exist constants c and 
306 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

TRANSITIVE CLOSURE 
307 
n0 such that \g(n)\ ^ c\f(n)\ for all η > n0. Furthermore, all our complexity 
results will be with respect to the worst-case analysis. 
There are different methods of representing a graph on a computer. Two 
of the most common methods use the adjacency matrix (Section 6.10) and 
the adjacency list. Adjacency matrix representation is not a very efficient 
one in the case of sparse graphs. In the adjacency list representation, we 
associate with each vertex a list that contains all the edges incident on it. A 
detailed discussion of data structures for representing a graph may be found 
in some of the references listed at the end of this chapter. 
11.1 
TRANSITIVE CLOSURE 
We may recall (Section 5.2) that a binary relation on a set is a collection of 
ordered pairs of the elements of the set. The transitive closure of a binary 
relation R is a relation R* defined as follows: χ R* y if and only if there 
exists a sequence 
x0 — x, xx, x2,..., 
xk — y 
such that k>0 
and x0 R xx, x, R x2,... 
, x t _ , R xk. 
Clearly, if χ R y, then χ R* y. Hence R C R*. Further, it can be easily 
shown that R* is transitive. In fact, it is the smallest transitive relation 
containing R. So if R is transitive, then R* = R. 
As we have already pointed out in Section 5.2, a binary relation can be 
represented by a directed graph. Suppose that G is the directed graph 
representing a relation R. The directed graph G* representing the transitive 
closure R* of R is called the transitive closure of G. It follows from the 
definition of R* that the edge (x, y), χ Φ y, is in G* if and only if there exists 
in G a directed path from the vertex χ to the vertex y. Similarly the self-loop 
(x, x) at vertex χ is in G* if and only if there exists in G a directed circuit 
containing x. For example, the graph shown in Fig. 11.1ft is the transitive 
closure of the graph of Fig. 11.1a. 
Suppose that we define the reachability matrix of an η -vertex directed 
graph G as an η x η (0,1) matrix in which the (i, ;) entry is equal to 1 if and 
only if there exists a directed path from vertex i to vertex j when i Φ j , or a 
directed circuit containing vertex i" when ι = /. In other words the (i, /) entry 
of the reachability matrix is equal to 1 if and only if vertex / is reachable 
from vertex i through a sequence of directed edges. It is now easy to see that 
the adjacency matrix of G* is the same as the reachability matrix of G. 
The problem of constructing the transitive closure of a directed graph 
arises in several applications. For examples, see Gries [11.1]. In this section 
we discuss an elegant and computationally efficient algorithm due to War-
shall [11.2] for computing the transitive closure. We also discuss a variation 
of WarshalFs algorithm given by Warren [11.3]. 

308 
GRAPH ALGORITHMS 
la) 
Figure 11.1. (a) Graph G. (b) G*, transitive closure 
of G. 
Let G be an η-vertex directed graph with its vertices denoted by the 
integers 1 , 2 , . . . , n. Let G° = G. Warshall's algorithm constructs a sequence 
of graphs so that G ' C G '
+
1 , 0 S ( < n - l , and G" is the transitive closure of 
G. The graph G', i a 1 , is obtained from G '
- 1 by processing vertex i in G'~\ 
Processing vertex i in G'~
l 
involves addition of new edges to G'~
l 
as 
described now. 
Let, in G'~
l, the edges (i, k), (i, /), (/, m),... 
be incident out of vertex i. 
Then for each edge (;', i) incident into vertex i, add to G
, _ 1 the edges (/, k), 
(/, 0 , (/»»»),... if these edges are not already present in G
l _ 1. The graph 
that results after vertex i is processed is denoted as G'. 
Warshall's algorithm is illustrated in Fig. 1 1 . 2 . It is clear that G' C 
G
i+\ 
1 ^ 0 , To show that G" is the transitive closure of G we need to prove the 
following result. 
Theorem 11.1 
1 . Suppose that, for any two vertices s and t, there exists in G a directed 
path Ρ from vertex ί to vertex / such that all its vertices other than s 
and r are from the set { 1 , 2 , . . . , / } . Then G' contains the edge (s, t). 
2 . Suppose that, for any vertex *, there exists in G a directed circuit C 
containing s such that all its vertices other than s are from the set 
{ 1 , 2 , . . . , i}. Then G' contains the self-loop (s, s). 
<j 
» 
ο 

TRANSITIVE CLOSURE 
309 
(s) 
0 4 
(M 
(e) 
Figure 11.2. Illustration of Warshall's algorithm. 
(a) G", (b) G' = G2. (c) G3 = G4. 
Proof 
1. Proof is by induction on i. 
Clearly the result is true for G1 since Warshall's construction, while 
processing vertex 1, introduces the edge (s, t) if G° (=G) contains the 
edges (s, 1) and (1, t). 
Let the result be true for all Gk, k< i. 
Suppose that / is not an internal vertex of P. Then it follows from the 
induction hypothesis that G'_1 contains the edge (s, t). Hence G' also 
contains (s, t) because G'-1 C.G'. 
Suppose that 1 is an internal vertex of P. Then again from the 
induction hypothesis it follows that G,_1 contains the edges (s, i) and 
(i, t). Therefore, while processing vertex i in G'~\ the edge (s, r) is 
added to G'. 
2. Proof follows along the same lines. 
■ 

310 
GRAPH ALGORITHMS 
As an immediate consequence of this theorem we get the following. 
Corollary 11.1.1. G" is the transitive closure of G. 
• 
We next give a formal description of Warshall's algorithm. In this descrip-
tion the graph G is represented by its adjacency matrix Μ and the symbol ν 
stands for Boolean addition. 
Algorithm 11.1. Transitive Closure (Warshall) 
51. (Initialization)Μ is the adjacency matrix of G. 
52. Do S3 for i = 1,2,... ,n. 
53. Do S4 for j = 1,2,..., n. 
54. If M(j, i) = 1, do S5 for A: = 1,2,..., n. 
55. M(j, k) = M(j, k) ν M(i, k). 
56. HALT. (Ai is the adjacency matrix of G*.) 
• 
Note that the matrix Μ (when the algorithm begins to execute S3 with ί = ρ) 
is the adjacency matrix of G
p~\ 
Further, processing a diagonal entry does 
not result in adding new nonzero entries. 
A few observations are now in order: 
1. Warshall's algorithm transforms the adjacency matrix Μ of a graph G 
to the adjacency matrix of the transitive closure of G by suitably 
overwriting on M. It is for this reason that the algorithm is said to 
work "in place." 
2. The algorithm processes all the edges incident into a vertex before it 
begins to process the next vertex. In other words it processes the 
matrix Μ columnwise. Hence we describe Warshall's algorithm as 
column-oriented. 
3. While processing a vertex no new edge (i.e., an edge that is not 
present when the processing of that vertex begins) incident into the 
vertex is added to the graph. This means that while processing a vertex 
we can choose the edges incident into the vertex in any arbitrary 
order. 
4. Suppose that the edge (;', i) incident into the vertex i is not present 
while vertex / is processed, but that it is added subsequently while 
processing some vertex k, k> i. Clearly this edge is not processed 
while processing vertex i. Neither will it be processed later since no 
vertex is processed more than once. In fact, such an edge will not 
result in adding any new edges. 
5. Warshall's algorithm is said to work in one pass since each vertex is 
processed exactly once. 

TRANSITIVE CLOSURE 
311 
Suppose that we wish to modify Warshall's algorithm so that it becomes 
row-oriented. In a row-oriented algorithm, while processing a vertex, all the 
edges incident out of the vertex are to be processed. The processing of the 
edge (/', ;') introduces the edges (i, k) for every edge (/, k) incident out of 
vertex 
Therefore new edges incident out of a vertex may be added while 
processing a vertex "rowwise". Some of these newly added edges may not 
be processed before the processing of the vertex under consideration is 
completed. If the processing of these edges is necessary for the computation 
of the transitive closure, then such a processing can be done only in a second 
pass. Thus, in general, a row-oriented algorithm may require more than one 
pass to compute the transitive closure. 
For example, consider the graph G of Fig. 11.3a. After processing 
rowwise the vertices of G we obtain the graph G' shown in Fig. 11.36. 
Clearly, G' is not the transitive closure of G since the edge (1,2) is yet to be 
added. It may be noted that the edge (1,3) is not processed in this pass 
ο 
> 
ο 
» 
ο 
•———ο 
1
4 
3 
2 
la I 
(c) 
Figure 11.3. An example of row-oriented transitive closure algorithm, (a) G. (b) G'. 
(c) G*. 

312 
GRAPH ALGORITHMS 
because it is added only while processing the edge (1,4). The same is the 
case with the edge (4,2). 
Suppose we next process the vertex of G'. In this second pass the edge 
(1,2) is added while processing vertex 1 and we get the transitive closure G* 
shown in Fig. 11.3c. Thus in the case of the graph of Fig. 11.3a two passes 
of the row-oriented algorithm are required. 
Now the question arises whether two passes always suffice. The answer is 
in the affirmative, and Warren [11.3] has demonstrated this by devising a 
clever two-pass row-oriented algorithm. In this algorithm, while processing a 
vertex, say vertex /', in the first pass only edges connected to vertices less 
than i are processed, and in the second pass only edges connected to vertices 
greater than i are processed. In other words the algorithm transforms the 
adjacency matrix Μ of the graph G to the adjacency matrix of G* by 
processing in the first pass only entries below the main diagonal of Μ and in 
the second pass only entries above the main diagonal. Thus during each pass 
at most n(n - l)/2 edges are processed. A description of Warren's modifica-
tion of Warshall's algorithm now follows. 
Algorithm 11.2. Transitive Closure (Warren) 
51. Μ is the adjacency matrix of G. 
52. Do S3 for i = 2 , 3 , . . . , n. 
53. Do S4 for ; = 1,2,..., i - 1. 
54. If M(i, j) = 1, then do S5 for k = 1 , . . . , n. 
55. M(i, k) = M(i, k) ν M(j, k). 
56. Do S7 for ι = 1,2,..., η - 1 . 
57. Do S8 for / = ί + 1, ι + 2 , . . . , n. 
58. If M(i, j) = 1, then do S9 for k = 1,2,..., n. 
59. M(i, k) = M{i, k) ν M(j, k). 
S10. HALT. (M is the adjacency matrix of G*.) 
• 
Note that in this algorithm steps S2 through S5 correspond to the first pass 
and steps S6 through S9 correspond to the second pass. 
As an example, consider again the graph shown in Fig. 11.3a. At the end 
of the first pass of Warren's algorithm we obtain the graph shown in Fig. 
11.4a, and at the end of the second pass we get the transitive closure G* 
shown in Fig. 11.46. 
The proof of correctness of Warren's algorithm is based on the following 
lemma. 
Lemma 11.1. Suppose that, for any two vertices s and t, there exists in G a 
directed path Ρ from s to t. Then the graph that results after processing 
vertex s in the first pass (steps S2 through S5) of Warren's algorithm 
contains an edge (s, r), where r is a successor of s on Ρ and either r > s or 
r = t. 

TRANSITIVE CLOSURE 
313 
1
4 
3 
2 
(b) 
Figure 11.4. Illustration of Warren's algorithm. 
Proof. Proof is by induction on s. 
If 5 = 1, then the lemma is clearly true because all the successors of 1 on 
Ρ are greater than 1. Assume that the lemma is true for all s < k and let 
s = k. Suppose (s, *',) is the first edge on P. If i, > s, then clearly the lemma 
is true. 
If i, < s, then by the induction hypothesis the graph that results after 
processing vertex i, in the first pass contains an edge (/,, i 2), where i2 is a 
successor of i, on Ρ and either i2 > i, or i2 = t. 
If i2 Φ t and i2 < s, then again by the induction hypothesis the graph that 
results after processing vertex i2 in the first pass contains an edge (i 2, i3) 
where i3 is a successor of i2 on P, and either i3 > i2 or i3 = t. 
If i 3 5^ r and i3 < s, we repeat the arguments on i3 until we locate an im 
such that either im > s or i m = i. Thus the graph that we have before the 
processing 
of 
vertex 
s 
begins 
contains 
the 
edges 
CM]), 
(i,, i 2 ) , . . . ,(i m_!, / m ) such that the following conditions are satisfied: 
1. ip is a successor of ip_l on Ρ, ρ 2 2. 
2. 'm-i > 
'
m - 2 > 'm-3 > "'' > «Ί. and ik < s for k Φ m. 
3. im = r or i m > s. 
We now begin to process vertex s. Processing of (s, /,) introduces the edge 
(s, i2) because of the presence of (/',, i 2). Since i 2 > i',, the edge (s, i2) is 
subsequently processed. Processing of this edge introduces (s, i 3) because of 
the presence of (i 2, i3), 
and so on. Thus when the processing of s is 
completed, the required edge (s, im) is present in the resulting graph. 
• 
Theorem 11.2. Warren's algorithm computes the transitive closure of a 
graph G. 

314 
GRAPH ALGORITHMS 
Proof. We need to consider two cases: 
Case 1 For any two distinct vertices s and t there exists in G a directed 
path Ρ from s to t. 
Let (i, /) be the first edge on Ρ (as we proceed from s to t) such that i > j . 
Then it follows from the previous lemma that the graph that we have, before 
the second pass of Warren's algorithm begins, contains an edge (/', k), where 
A; is a successor of i on Ρ and either k = t or k > i. Thus after the first pass is 
completed there exists a path P': s, /,, i2,...,im, 
t such that 
s<ii<i2 
< · · • < im and each iJ+i is a successor of i ; on P. 
When in the second pass we process vertex s, the edge CM,) is first 
encountered. The processing of this edge introduces the edge (s, i2) because 
of the presence of the edge (/,, i2). Since i2 > /,, the edge (s, i 2) is processed 
subsequently. This, in turn, introduces the edge (s, t 3), and so on. Thus 
when the processing of s is completed, we have the edge (s, t) in the 
resulting graph. 
Case 2 
There exists in G a directed circuit containing a vertex s. 
In this case we can prove along the same lines as before that when the 
processing of vertex s is completed in the second pass, the resulting graph 
contains the self-loop (s, s). 
• 
Clearly both Warshalls and Warren's algorithms have the worst-case 
complexity 0(n
3). 
Warren [11.3] refers to other row-oriented algorithms. 
For some of the other transitive closure algorithms, see [11.4] through 
[11.12]. Syslo and Dzikiewicz [11.13] discuss computational experiences with 
several of the transitive closure algorithms. Melhorn [11.14] discusses the 
transitive closure problem in the context of general path problems in graphs. 
Several additional references on this topic can also be found in [11.14]. 
11.2 
SHORTEST PATHS 
Let G be a connected directed graph in which each directed edge is 
associated with a real number called the length of the edge. The length 
of an edge directed from a vertex i to a vertex 
is denoted by w(i, j). 
If there is no edge directed from vertex i to vertex /', then w(i, j) = oo. The 
length of a directed path in G is the sum of the lengths of the edges in the 
path. A minimum length directed s-t path is called a shortest path from s to 
t. The length of a shortest directed s-t path, if it exists, is called the distance 
from s to t, and it is denoted as d(s, t). 
In this section we consider the following two problems: 

SHORTEST PATHS 
315 
1. Find the shortest paths from a specified vertex s to all other vertices in 
G. 
2. Find the shortest paths between all the ordered pairs of vertices in G. 
These two problems arise in several optimization problems. For example, 
finding a minimum cost flow in a transport network involves finding a 
shortest path from the source to the sink in the network [11.15]. 
11.2.1 Shortest Paths from a Specified Vertex s to All Other 
Vertices in a Graph 
We first develop an algorithm due to Dijkstra [11.16], which finds shortest 
paths from a specified vertex s to all the other vertices in an n-vertex 
connected directed graph G. We assume that all the lengths are nonnega-
tive. The following ideas form the basis of Dijkstra's algorithm. 
Let V denote the vertex set of G, and let S be a subset of V such that 
J G S . Let 5 denote the complement of S in V. Thus 5 = V- S. 
Among all the directed paths from s to the vertices in S, let Ρ be a path 
with minimum length. The length of Ρ is then called the distance d(s, S) 
from s to S. Let P: s,...,u, 
v. Then clearly νG S and « G S . Further, the 
s-u section of Ρ must be a shortest s-u path with all its vertices in S. 
Therefore, 
d(s, S) = d(s, u) + w(u, v). 
From this we can see that the distance d(s, S) can be computed using the 
formula 
d(s, S) = min {d(s, u) + w(u, v)} . 
(11.1) 
u e s 
ves 
Now, if ν is the vertex in 5 such that d(s, S) = d(s, u) + w(u, υ) for some 
u G S, then clearly 
d(s, v) = d(s, S). 
(11.2) 
Dijkstra's algorithm constructs a sequence S0 = {s}, S,, 5 2 , . . . of subsets of 
V such that the following conditions are satisfied: 
1. If s = u0, 
M 2 , . . . , u n_! are the vertices of V such that d(s, «,) s 
d(s, u2) < d(s, u 3) < · · · < d(s, «„_,), then S, = {s, u „ u 2 , . . . , u,} for 
;>o. 
2. When the set S, has been determined, the shortest paths from s to u,, 
M 2 , . . . , ut will be known. 

316 
GRAPH ALGORITHMS 
If the sets 5, are defined as stated, then by (11.2) we have 
d(S,ui+l) 
= d(s,S,). 
(11.3) 
Thus determining Si+l from 5, involves computing d(s, S (). 
The subsets S,, S2,...,Sn_} 
can be constructed as follows: By (11.1), 
d(s, S0) = min {d(s, u) + w(u, v)} = min {w(s, v)} . 
"
e f o 
ves0 
vel0 
Hence by (11.3), M, is a vertex with the property 
d(s, w,) = min {w(s, v)}. 
(11-4) 
ves0 
If P, denotes a shortest path from s to the vertex u,, then clearly P,: s, ux. 
Suppose that the subsets S0, Slt... 
,S, and the paths P,, P 2,..._, P, have 
been determined. Now to determine _S 1 + 1, we first compute d(i,S,) using 
(11.1). By (11.3), u i + 1 is a vertex in 5, with the property 
d(s, ul+i) 
= 
d(s,Sl). 
By (11.1), there is a vertex y G 5, such that 
Φ . 
= d(s, uf) + w(uj, «, + 
1). 
Therefore we can obtain P
m by adjoining the edge (u ;, «,+,) to the path P ;. 
If we are interested only in a shortest path from a specified vertex s to 
another specified vertex t, then we can terminate the procedure after we 
have determined the first set 5, which contains t. 
It is clear that in this procedure we need to compute the minimum in 
(11.1]) at each stage. If this minimum were to be computed from scratch at 
each stage, then determining S, from 5,_, would require (i - 1) x (n - i) 
additions and {i(n - i) - 1} comparisons. The total number of operations 
for the entire algorithm would then be 
Σ {(2/-l)(n-i)-l> 
resulting in an overall complexity of Oi[n
3). However, many of these 
additions and comparisons would be repeated unnecessarily. 
Dijkstra, in his algorithm, avoids such repeated additions and com-
parisons by storing computational information from one stage to the next. 
This is achieved by a labeling procedure that, as we shall see, improves the 
complexity of the algorithm to 0(n
2). 
The following ideas lead to Dijkstra's 

SHORTEST PATHS 
317 
labeling procedure. Suppose we do the labeling so that for ί = 0 , 1 , 2 , . . . the 
label /,(u) for vertex ν satisfies the following: 
1. l0(s) = 0 and /0(i>) = °° for all υ Φ s. 
2. For i > l , 
l,(v) = d(s, v) 
for all υ Ε S,_, , 
l.(v) = min {d(s, u) + w(w, U)} for all ν Ε 5 , . 
Clearly, then, u, is a vertex with the property 
d(s, «,) = φ , 
= min { / » } . 
Now we can compute 
from /,(υ) as follows: 
1. For υ Ε 5,., 
= /,(«) = φ , υ). 
2. For υ Ε 5,, 
+ 
= min {d(s, u) + w(u, υ)} 
= min {/,.(u), d(s, «,) + w(u„ v)} 
= min { / » , / , ( « , ) +w{u„ v)}. 
(11.5) 
Then 
is to be chosen such that 
d(s, ι ι ι + Ι ) = φ , 5 , ) 
= min{/ I + 1(i;)}. 
(11.6) 
ves. 
Note that the label of ut does not change after the set S, has been 
determined. 
Thus Dijkstra's algorithm begins with the label /„(s) = 0 and l0(v) = » for 
all υ Φ s. As the algorithm progresses, the labels are modified according to 
(11.5). The labels /„_,(u) would give the distance from s to v. 
_ 
It is clear that determining M i + 1 involves computing / 1 + 1(i>) for all ν GS, 
and then finding the minimum of these labels. For i > 1 the former computa-
tions (11.5) require ( n - i - 1 ) 
additions and ( n - i - 1 ) 
comparisons, 
whereas the latter computations (11.6) require {{n-i)-2\ 
comparisons. 
Thus, clearly, the complexity of Dijkstra's algorithm is 0(n ) . 
A description of Dijkstra's algorithm is presented next. In this description 
LABEL is an array in which the current labels of the vertices are stored. A 
vertex becomes permanently labeled when it is set equal to u, for some i. We 
use an array PERM to indicate which of the vertices are permanently 

318 
GRAPH ALGORITHMS 
labeled. If P E R M ( U ) = 1, then ν is a permanently labeled vertex. Note that 
in such a case the label of ν is equal to d(s, v). We start with P E R M ( s ) = 1 
and 
P E R M ( u ) = 0 for all υ Φ s. 
PRED is an array that keeps a record of the vertices from which the 
vertices get permanently labeled. If a vertex υ is permanently labeled, then 
u, PRED(u), PRED(PRED(v)), 
...,s 
are the vertices in a shortest directed s-v path. 
Algorithm 11.3. Shortest Paths (Dijkstra) 
50. G is the given directed graph with lengths associated with its edges. 
Shortest paths from vertex s to all other vertices in G are required. 
51. (Initialize.) Set L A B E L ( J ) = 0, PERM(s) = 1, and PRED(s) = s. For 
all ν ¥• s, set L A B E L ( U ) = oo, PERM(u) = 0, and PRED(i;) = v. 
52. Set i = 0 and u = s. (w is the latest vertex permanently labeled. Now 
it is s.) 
53. 
[Compute L A B E L ( U ) and update the entries of the PRED array.] 
Set ι = / + l. Do the following for each vertex ν that is not yet 
labelled permanently: 
1. Set Μ = min{LABEL(u), LABEL(u) + w(u, v)}. 
2. If Λί <LABEL(i>), then set LABEL(u) = Μ and P R E D ( U ) = H. 
54. 
(Identify vertex «,). Find among all vertices, which are not yet 
permanently labeled, a vertex w with the smallest label. (In case of a 
tie the choice can be made arbitrarily.) Set PERM(w) = 1 and u = w. 
(u, = w, and it is the latest vertex labeled permanently.) 
55. If i < η - 1, then go to S3. Otherwise HALT. [All the shortest paths 
are found. The vertex labels give the lengths of the shortest paths. 
Now v, PRED(i;), PRED(PRED(u)),... ,s are the vertices in a 
shortest directed s-υ path.] 
• 
Note that in a computer program °° is represented by as high a number as 
necessary. Further, if the final label of a vertex υ is equal to oo, then it means 
that there is no directed path from s to υ. 
To illustrate Dijkstra's algorithm, consider the graph G in Fig. 11.5 in 
which the length of an edge is shown next to the edge. In Fig. 11.6 we have 
shown the entries of the LABEL and PRED arrays. 
For any i the circled entries in the LABEL array correspond to the 
permanently labeled vertices, namely, the vertices in 5,. The entry with the 
mark * is the label of the latest vertex permanently labeled, namely, the 
vertex «,. The shortest paths from s and the corresponding distances are 
obtained from the final values of the entries in the PRED and LABEL 
arrays. 

SHORTEST PATHS 
319 
14 
ΊΧ 
S 
8 
6
\ 
'2 
D ^ - ^ ' 
*5 
< 
8 
< 
6 " 
E 
12' 
\ Λ 1 9 
7 
N. 
X* 
10 
Figure 11.5 
H 
i 
0 
1 
2 
3 
4 
5 
6 
7 
Vertices 
Λ 
©* 
© 
© 
© 
© 
© 
© 
© 
B 
00 
7 
CD* 
CD 
CD 
CD 
CD 
CD 
c 
00 
» 
00 
00 
« 
00 
« 
©* 
D 
00 
8 
8 
®* 
® 
® 
® 
® 
E 
00 
00 
00 
00 
©· 
© 
® 
(g) 
F 
00 
00 
00 
00 
00 
00 
@ · 
@ 
<7 
0 0 
©· 
© 
© 
© 
© 
© 
© 
H 
0 0 
0 0 
0 0 
0 0 
21 
©* 
© 
© 
(«) 
PRED(/l)«/4 
PRED(Ä)-/< 
PRED(C)-C 
PREEK D)~A 
From 
Λ 
Λ 
A 
A 
A 
A 
A 
To 
B 
C 
D 
E 
F 
G 
H 
PRED(£)«2) 
P R E D ( F ) - # 
PRED(G)-/1 
PREEK # ) - / > 
Shortest Path 
A, B 
No path 
A,D 
A,D,E 
A,D,H,F 
A,G 
A,D,H 
(b) 
ure 11.6. Illustration of Dijkstra's algorithm. The LABEL array is shown in (a). 

320 
GRAPH ALGORITHMS 
In our discussions thus far we have assumed that all the lengths are 
nonnegative. Dijkstra's algorithm is not valid if some of the lengths are 
negative. (Why?) 
We next present a shortest path algorithm due to Ford [11.17] that allows 
the presence of edges with negative lengths but does not allow directed 
circuits of negative length. This algorithm is also attributed to Bellman 
[11.18] and Moore [11.19]. Note that for convenience in subsequent discus-
sions of the algorithm, we have chosen to use λ(ι>) instead of LABEL(u) to 
denote the label of a vertex. 
Algorithm 11.4. Shortest Paths in Graphs with Negative Length Edges 
(Bellman-Ford-Moore) 
50. G is the given directed graph with lengths associated with its edges. 
Shortest paths from vertex s to all other vertices in G are required. 
51. (Initialize.) Set A(s) = 0 and PRED(s) = s. For all ν Φ s, set λ(υ) = °° 
and PRED(u) = v. 
52. If there exists no edge β = («,•, vt) for which λ ^ ) > λ(υ,) + w(e), 
then HALT. (The current vertex label values represent the lengths of 
the shortest paths.) 
53. Select an edge e = (v,,vl) 
for which λ(ι>;) > λ(υ,) + w(e) and set 
A(u y) = λ(υ,) + w(e) and PRED(u ;) = υ,. Go to S2. 
• 
For our purposes in the above algorithm oo is not greater than oo + k, even 
if k is negative. Also, the algorithm will not terminate if there is a directed 
path from s to a vertex on a directed circuit of negative length because in 
such a case going around this circuit will decrease label values, and the 
process can be repeated indefinitely. We now prove that in all other cases 
the algorithm will terminate in a finite number of steps and at termination, 
for every vertex υ, λ(ν) will give the length of a shortest directed path from J 
to v. 
Lemma. 11.2. If the graph G has no directed circuits of negative lengths, 
then, if at any stage of Algorithm 11.4 λ(υ) is finite, there is a directed path 
from J to w whose length is λ(υ). 
Proof. We prove the result by displaying a directed path from s to v. The 
construction is backward from v. 
Let u denote the vertex that gave υ its present label λ(υ). If A ' ( M ) 
represents the label of u at the time it gave ν the label λ(ι>), then 
X(v) = A ' ( M ) + w(e), where e = (Μ, V). Now, continue from u to the vertex 
that gave it the label A ' ( « ) , and so on. In this process no vertex will be 
encountered more than once because each step in the process refers to an 
earlier time in the execution of the algorithm, and a vertex can decrease its 
own label only by going through a directed circuit of negative length. Thus 

SHORTEST PATHS 
321 
there is a directed path from s to ν such that the label A(i/) is the sum of the 
lengths of the edges on this path, and the required result follows. 
• 
Recall that d(s, υ), the distance from s to u, denotes the length of a 
shortest directed path from s to v. 
Theorem 11.3. For a directed graph G with no directed circuits of negative 
length, the Bellman-Ford-Moore Algorithm (Algorithm 11.4) terminates in 
a finite number of steps, and upon termination, A(u) = d(s, v) for all v. 
Proof. Consider any vertex ν in G. By Lemma 11.2, at any stage of the 
Bellman-Ford-Moore algorithm, A(u) represents the length of a directed 
path from s to v. Since there are only a finite number of such paths, it 
follows that the number of possible values for A(i>) is also finite. 
Clearly, upon termination of the algorithm, A(u) 2 d(s, v). If A(u)> 
d(s, υ), then let P: s = v0, vx,..., 
vk = ν be a shortest directed path from s 
to υ and let e, denote the edge (υ,·_ι> i>,) on this path. For every i = 0, 1, 
2 , . . . , k, we have 
d(s, υ,) = Σ w(e,) • 
Let v, be the first vertex on this path for which, upon termination of the 
algorithm, λ(υ,) > d(s, vt). 
Since λ(υ,_,) = d(s, υ,.,) we have d(s, vt) = 
A(y,_j) + w(e:) and so upon termination A(u () > A(u,_,) + w(el). This is a 
contradiction because when the algorithm terminates there is no edge 
e = (M, W) with A ( H » ) > A(w) + w(e). Thus, for every vertex υ, on Ρ, λ(ι>,) = 
d(s, v,). In particular, X(vk) = A(i>) = d(s, v) and the theorem follows. 
• 
Note that the number of directed paths from J to a vertex could be 
exponential in the number of vertices of the graph. So, if in the implementa-
tion of Algorithm 11.4 edges are selected in an arbitrary manner, it is 
possible that the algorithm may perform an exponential number of oper-
ations before terminating. We can show that the following implementation 
of the algorithm will achieve a complexity of 0(mri) where m and η are, 
respectively, the number of edges and the number of vertices of G. 
Order the edges as e,, e2,...,em. 
Perform S3, examining edges in this 
order and updating the vertex labels whenever required. After one such 
scan or sweep of all the edges, perform additional sweeps until an entire 
sweep produces no changes in the vertex labels. If the number of edges in a 
shortest directed path from s to υ is k, then it can be shown by induction 
that by the end of the kth sweep, ν will have its final label. Since k 
η - 1 
and each sweep requires 0(m) 
operations, this implementation of the 
Bellman-Ford-Moore algorithm requires 0(mn) 
time. 
Sometimes we may be interested in getting the second, third, or higher 

322 
GRAPH ALGORITHMS 
shortest paths. These and related problems are discussed in Dreyfus [11.20], 
Hu [11.21], Frank and Frisch [11.21], Christofides [11.23], Lawler [11.24], 
Gordon and Minoux [11.25], Minieka [11.26], and Spira and Pan [11.27]. 
For algorithms designed for sparse networks see Johnson [11.28] and 
Wagner [11.29]. See also Johnson [11.30], Edmonds and Karp [11.31], and 
Fredman [11.32]. For a shortest path problem that arises in solving a special 
system of linear inequalities and its applications see Comeau and 
Thulasiraman [11.33], Liao and Wong [1.34], and Lengauer [11.35]. 
11.2.2 Shortest Paths between All Pairs of Vertices 
Suppose that we are interested in finding the shortest paths between all the 
n{n - 1) ordered pairs of vertices in an η-vertex directed graph. A straight-
forward approach to get these paths would be to use Dijkstra's algorithm η 
times. However, there are algorithms that are computationally more effi-
cient than this. These algorithms are applicable even when the lengths are 
negative, but there are no negative-length directed circuits. Now we discuss 
one of these algorithms. This algorithm, due to Floyd [11.36], is based on 
Warshall's procedure (Algorithm 11.1) for computing transitive closure. 
Consider an η-vertex directed graph G with lengths associated with its 
edges. Let the vertices of G be denoted as 1, 2 , . . . , n. Assume that there 
are no negative-length directed circuits in G. Let W = [ H ' i / ] be the η x η 
matrix of direct lengths in G, that is, wtl is the length of the directed edge 
(/, ;') in G. We set w(j = °° if there is no edge (i,;') directed from ι to /. We 
also set w„ = 0 for all i. 
Starting with the matrix W
( 0 ) = W, Floyd's algorithm constructs a se-
quence 
W
(
2 \ W
(
n
) of η x η matrices so that the entry 
in W
M 
would give the distance from i to ; in G. The matrix 
= [w]^] is 
constructed from the matrix 
= [w|*
_ I )] according to the following 
rule: 
<
) 
= m i n { < - " , w r
,
) + < - '
) } . 
(H.7) 
Let Pf^ denote a path of minimum length among all the directed i-j paths, 
which use as internal vertices only those from the set {1,2,..., /c}. The 
following theorem proves the correctness of Floyd's algorithm. 
Theorem 11.4. For 0 < k < n, 
is equal to the length of P$\ 
Proof. Proof follows along the same lines as that for Theorem 11.1. 
• 
Usually, in addition to the shortest lengths, we are also interested in 
obtaining the paths that have these lengths. Recall that in Dijkstra's 
algorithm we use the PRED array to keep a record of the vertices that occur 
in the shortest paths. This is achieved in Floyd's algorithm as described 
next. 

SHORTEST PATHS 
323 
z
( 0 ) = 
Given Z
(*
 
0 = [z,
(* ° ] , Z
(*' = [z,^] is obtained according to the following 
rule: Let 
M = m i n { < - " , w , r
i ) + 
<-
1)} 
Then 
iz**"
0, 
i f M = H ' < * -
1 ) 
^· - U - « . 
« * < • * - » .
 
(
η ·
9
) 
This rule is similar to the one given in S3 of Algorithm 11.3 for updating the 
PRED array. The justification for this rule is as follows. If 
then 
Length of />{*> = length of 
. 
Therefore zj*' is the same as z**"
1'. 
On the other hand, if Μ < w^'
x), 
then P ^ is the concatenation of the 
paths Pfk'
x) 
and Pk
k~
x) 
in that order. So 
_<*) = 
7 ( * - D 
It should be clear that the shortest i-j path is given by the sequence /', ι,, 
h< • • • > ' p ' J °f vertices, where 
= 
ϊ , - z g , 
/ = 
(11.10) 
Note that in (11.7) 
= 
if w<*
 
υ or wj£
 
0 is equal to °°. This 
simple observation is made use of in the following description of Floyd's 
algorithm. We have also incorporated in this algorithm a test to detect the 
presence of a negative-length directed circuit. 
Algorithm 11.5. Shortest Paths between All Pairs of Vertices (Floyd) 
SI. W= [w,j] is the η x η matrix of direct lengths in the given directed 
graph G. Here wlt = 0 for all i = 1, 2 , . . . , η. Ζ = [z i y] is an η x η 
As we construct the sequence W
( 0 ), W
(1\..., 
W
l"\ 
we also construct 
another sequence Z
( 0 ) , Z
( 1 ) , . . . , Z
< n ) of matrices such that the entry z'*' of 
Z
( t ) gives the vertex that immediately follows vertex i in P{*\ Clearly, then 
j , 
if ννη Φ οο ; 
0, 
ifw„ = o o . 
ί
1 1 -
8 ) 

324 
GRAPH ALGORITHMS 
matrix in which 
S2. Set k = 0. 
V 
0, 
if w y = o o . 
53. Set k = k + 1. For all ι ^ k such that w r t # oo, and all / Φ k such that 
wkj Φ oo, do the following: 
1. Set Μ — min{n'Iy, wlk + wk)). 
2. If Μ < wt], then set ztj = zik and wtj = M. 
54. 1. If any w„<0, 
then vertex i is in some negative-length directed 
circuit, and so HALT. 
2. If every wu sO and k = n, then [ w j gives the lengths of all the 
shortest paths, and zit gives the first vertex after vertex i in a 
shortest directed i-j path. HALT. 
3. If all w„ > 0 but k < n, then go to S3. 
• 
It is easy to see that Floyd's algorithm is of complexity 0(n
3). This 
algorithm is also valid for finding shortest paths in a network with negative 
lengths provided the network does not have a directed circuit of negative 
length. Dantzig [11.37] proposed a variant of Floyd's algorithm that is also 
of complexity 0(n
3). 
For some of the other shortest path algorithms see Tabourier [11.38], 
Yen [11.39], and Williams and White [11.40]. Pierce [11.41] and Deo and 
Pang [11.42] give exhaustive bibliographies of algorithms for the shortest 
path and related problems. A discussion of complexity results for shortest 
path problems can be found in Melhorn [11.14] and Tarjan [11.43]. Discus-
sions of shortest path problems in a more general setting can be found in 
[11.14] and [11.25], Carre [11.44], and Tarjan [11.45]. For some recent 
developments see Frederickson [11.46] and Moffat and Takoka [11.47]. 
11.3 
MINIMUM WEIGHT SPANNING TREE 
Consider a weighted connected undirected graph G with a nonnegative real 
weight w(e) associated with each edge e of G. The weight of a subgraph of 
G will refer to the sum of the weights of the edges of the subgraph. In this 
section we discuss the problem of constructing a minimum weight spanning 
tree of G. Recall that this problem was discussed earlier in Section 10.9 in 
the general setting of a matroid, namely, determining a maximum or 
minimum weight independent set of a matroid. As noted earlier, the greedy 
algorithm presented in that section was first proposed by Kruskal in [11.48] 
in the context of the minimum weight spanning tree problem. Our interest 
in this section is to present a unified treatment of two algorithms for this 

MINIMUM WEIGHT SPANNING TREE 
325 
problem, namely, Kruskal's algorithm and the one due to Prim [11.49]. The 
next two theorems provide the basis of these algorithms. 
Theorem 11.5. Consider a vertex υ in a weighted connected graph G. 
Among all the edges incident on v, let e be one of minimum weight. Then, 
G has a minimum weight spanning tree that contains e. 
Proof. Let Tmm be a minimum weight spanning tree of G. If Tmm does not 
contain e, then consider the fundamental circuit C of T^,, with respect to e. 
Let e' be the edge of C that is adjacent to e. Clearly e' £ T m i n. Also 
7" = Tmin - e' + e is a spanning tree of G. Since e and e' are both incident 
on v, we get w(e)^w(e'). 
But w(e)>w(e') because w(T') = 
w(Tmtn) 
- w(e') + w(e) > w(Tmia). 
So, w(e) = w(e') and w(T') = w(Tmin). 
Thus Γ 
is a minimum weight spanning tree. The theorem follows since T' contains 
e. 
U 
Theorem 11.6. Let Γ be an acyclic subgraph of a weighted connected graph 
G such that there exists a minimum weight spanning tree containing T. If G' 
denotes the graph obtained by contracting the edges of T, and T^ i n is a 
minimum weight spanning tree of G', then T'min U Τ is a minimum weight 
spanning tree of G. 
Proof. Let r m i n be a minimum weight spanning tree of G containing T. If 
T m i n = Τ U T', then clearly T' is a spanning tree of G'. Therefore 
w(T')>w(T'mJ. 
(11.11) 
It is easy to see that T'mm U Τ is also a spanning tree of G. So 
w ( T ; i n u r ) > w ( T m i n ) 
= νν(Γ) + νν(Γ'). 
(11.12) 
From this we get 
H>(r;, n)>.v(r). 
(11-13) 
Combining (11.11) and (11.13) we get w(T'mia) 
= w(T'), 
and so w(T'min U 
T) = w{T' U T) = w(Tmin). 
Thus T'min U Τ is a minimum spanning tree of 
G. 
• 
We now present Kruskal's algorithm. 
Algorithm 11.6. Minimum Weight Spanning Tree (Kruskal) 
SO. G is the given nontrivial η-vertex weighted connected graph. 

326 
GRAPH ALGORITHMS 
51. Set i = 1 and E0 = 0. 
52. Select an edge e, of minimum weight such that e,&E,_l 
and the 
edge-induced subgraph (E,_iU{e,}) is acyclic, and then define 
T, = (£,_, U {e,}) and £, = 
U {e,}. If no such edge exists, then 
let T m i n = Γ,., and HALT. 
53. Set i = i + 1 and go to S2. 
• 
Kruskal's algorithm essentially proceeds as follows. Edges are first sorted 
in the order of nondecreasing weights and then examined, one at a time, for 
inclusion in a minimum weight spanning tree. An edge is included if it does 
not form a circuit with the edges already selected. 
For an illustration of Kruskal's algorithm see Section 10.9. 
Next we prove the correctness of Kruskal's algorithm. 
Theorem 11.7. Kruskal's algorithm constructs a minimum weight spanning 
tree of a weighted connected graph. 
Proof. Let G be the given nontrivial weighted connected graph. Clearly, 
when Kruskal's algorithm terminates, the edges selected will form a span-
ning tree of G. Thus the algorithm terminates with i = n, and T„_t is a 
spanning tree of G. 
We next establish that Γ„_, is indeed a minimum weight spanning tree of 
G by proving that every 7", constructed in the course of Kruskal's algorithm 
is contained in a minimum weight spanning tree of G. Our proof is by 
induction on /'. 
Clearly by Theorem 11.5 G contains a minimum weight spanning tree 
that contains the edge ev In other words Tx is contained in a minimum 
weight spanning tree of G. As inductive hypothesis assume that T„ i s 1 is 
contained in a minimum weight spanning tree of G. Let G' be the graph 
obtained by contracting the edges of Tr Again, by Theorem 11.5, the edge 
ei+l 
is contained in a minimum weight spanning tree T'min of G'. By 
Theorem 11.6, T, U T'mm is a minimum weight spanning tree of G. More 
specifically Ti+l = Tt U {ei+1} 
is contained in a minimum weight spanning 
tree of G and the correctness of Kruskal's algorithm follows. 
• 
We next present another algorithm due to Prim [11.49] to construct a 
minimum-weight spanning tree of a weighted connected graph. As we shall 
see soon, this algorithm is also based on Theorems 11.5 and 11.6 and can be 
viewed as a variant of Kruskal's algorithm. 
Algorithm 11.7. Minimum Weight Spanning Tree (Prim) 
50. G is the given nontrivial η-vertex weighted connected graph. 
51. Set i = 1 and E0 = 0. Select any vertex, say v, of G and set Vx = {v}. 
52. Select an edge e, = (p, q) of minimum weight such that e, has exactly 

OPTIMUM BRANCHINGS 
327 
one end vertex, say p, in Vr Define ViJI_x = Vi\J {q}, Ei, = 
U 
{e,}, and Γ, = (£,_, U e,). 
S3. If i < η - 1, set i = / + 1 and return to S2. Otherwise, let T m i n = Tn_1 
and HALT. 
• 
As in Kruskal's algorithm, Prim's algorithm also constructs a sequence of 
acyclic subgraphs 
7* 2,..., and terminates with Tn_1, 
a minimum weight 
spanning tree of G. The subgraph Tl + 1 is constructed from T, by adding an 
edge of minimum weight with exactly one end vertex in Tt. This construc-
tion ensures that all T,'s are connected. If G' denotes the graph obtained by 
contracting the edges of T,, and v' denotes the vertex of G', which 
corresponds to the vertex set of 7",·, then e, + 1 is in fact a minimum weight 
edge incident on v' in G'. This observation and Theorems 11.5 and 11.6 can 
be used (as in the proof of Theorem 11.7) to prove that each T, is contained 
in a minimum weight spanning tree of G. This would then establish that the 
spanning tree produced by Prim's algorithm is a minimum weight spanning 
tree of G. 
For complexity results relating to the minimum weight spanning tree 
enumeration problem see Kerschenbaum and Van Slyke [11.50], Yao 
[11.51], and Cheriton and Tarjan [11.52]. For sensitivity analysis of mini-
mum weight spanning trees and shortest path trees see Tarjan [11.53]. See 
Papadimitriou and Yannakakis [11.54] for a discussion of the complexity of 
restricted minimum weight spanning tree problems. For a history of the 
minimum weight spanning tree problem see Graham and Hall [11.55]. 
11.4 
OPTIMUM BRANCHINGS 
Consider a weighted directed graph G = (V, E). Let w(e) be the weight of 
edge e. Recall that the weight of a subgraph of G is defined to be equal to 
the sum of the weights of all the edges in the subgraph. 
A subgraph Gs of G is a branching in G if Gs has no directed circuits and 
the in-degree of each vertex of G, is at most 1. Clearly each component of 
Gs is a directed tree. A branching of maximum weight is called an optimum 
branching. 
In this section we discuss an algorithm due to Edmonds [11.56] for 
computing an optimum branching of G. Our discussion here is based on 
Karp [11.57]. 
An edge e = (i, ;') directed from vertex i to vertex ;' is critical if 
1. w(e)>0. 
2. w(e) > w(e') for every edge e' = (k, j) incident into j . 
A spanning subgraph Η of G is a critical subgraph of G if 

328 
GRAPH ALGORITHMS 
1. Every edge of Η is critical. 
2. The in-degree of every vertex of Η is at most 1. 
A directed graph G and a critical subgraph Η of G are shown in Fig. 11.7. 
It is easy to see that 
1. Each component of a critical subgraph contains at most one circuit, 
and such a circuit will be a directed circuit. 
2. A critical subgraph with no circuits is an optimum branching of G. 
Consider a branching B. Let e = (/, /) be an edge not in B, and let e' be the 
edge of Β incident into vertex j . Then e is eligible relative to Β if 
B' = 
(BUe)-e' 
is a branching. 
For example, the edges {e,, e2, e3, e4, e 7, e g} form a branching Β of the 
graph of Fig. 11.7. The edge e 6, not in B, is eligible relative to Β since 
(B U e 6) - e7 
is a branching of this graph. 
The following two lemmas are easy to prove, and they lead to Theorem 
11.8, which forms the basis of Karp's proof of the correctness of Edmonds' 
algorithm. In the following the edge set of a subgraph Η will also be 
denoted by H. 
Lemma 11.3. Let Β be a branching, and let e = (i, j) be an edge not in B. 
Then e is eligible relative to Β if and only if in Β there is no directed path 
from / to i. 
• 
Lemma 11.4. Let β be a branching and let C be a directed circuit such that 
no edge of C - Β is eligible relative to B. Then |C - B\ = 1. 
• 
Theorem 11.8. Let Η be a critical subgraph. Then there exists an optimum 
branching Β such that, for every directed circuit C in H, \C- B\ - 1. 
Proof. Let Β be an optimum branching that, among all optimum branch-
ings, contains a maximum number of edges of the critical subgraph. 
Consider any edge eEH- 
B. Let e be incident into vertex /, and let e' 
be the edge of Β incident into /. If e were eligible, then 
(B U e) - e' 
would also be an optimum branching, containing a larger number of edges 

OPTIMUM BRANCHINGS 
329 
Figure 11.7. (a) A directed graph G. (6) A 
critical subgraph of G. 

330 
GRAPH ALGORITHMS 
of Η than Β does; a contradiction. Thus no edge of Η - Β is eligible relative 
to B. So, by Lemma 11.4, for each circuit C in H, \C - B\ = 1. 
• 
Let C,, C 2 , . . . , Ck be the directed circuits in H. Note that no two circuits 
of Η can have a common edge. In other words these circuits are edge-
disjoint. For each C (, let e° be an edge of minimum weight in C,. 
Corollary 11.8.1. There exists an optimum branching Β such that: 
1. \C,-B\ 
= 1, i = l , 2 , . . . , A . 
2 . If no edge of Β - C, is incident into a vertex in C,, / = 1 , 2 , . . . , k, then 
Cl~B 
= e
a
l. 
(11.14) 
Proof. Let, among all optimum branchings satisfying item 1, β be a 
branching 
containing a minimum 
number 
of edges from 
the 
set 
{e\, e 2, •. •, e°k}. We now show that Β satisfies item 2 . 
If not, suppose, for some i, e" ε Β, but no edge of Β - C, is incident into 
a vertex in C,. Let e= C,- B. Then (B - ef) U e is clearly an optimum 
branching that satisfies item 1 but has fewer edges than Β from the set 
{e\, e\,..., 
e°k). This is a contradiction. 
• 
This result is very crucial in the development of Edmonds' algorithm. It 
suggests that we can restrict our search for optimum branchings to those that 
satisfy (11.14). 
Now we construct, from the given graph G, a simpler graph G'. We also 
show how to construct from an optimum branching of G' an optimum 
branching of G that satisfies (11.14). 
As before, let Η be the critical subgraph of G and let C,, C 2 , . . . , Ck be 
the directed circuits in H. The graph G' is constructed by contracting all the 
edges in each C„ i = l, 2,...,k. 
In G', vertices of each circuit C, are 
represented by a single vertex a,, called a pseudo-vertex. The weights of the 
edges of G' are the same as those of G, except for the weights of the edges 
incident into the pseudo-vertices. These weights are modified as follows. 
Let e = (j, /') be an edge of G such that / is a vertex of some circuit Cr and 
ι is not in Cr. Then in G', e is incident into the pseudo-vertex ar. Define e as 
the unique edge in Cr that is incident into vertex 
Then in G' the weight of 
e, denoted by w'(e), is given by 
w\e) = w(e) - w(e) + w(e°r) . 
(11.15) 
For example, consider the edge ex incident into the directed circuit 
{e2, e3, e4, es) of the critical subgraph of the graph G of Fig. 11.7. Then 
e, = e5, and the weight of ex in G' is given by 

OPTIMUM BRANCHINGS 
331 
w'(ex) = w(ex) - w(e5) + w(e4) 
= 5 - 6 + 5 
= 4 . 
Note that e 4 is a minimum weight edge in the circuit {e2, e 3, e 4, es). 
Let Ε and Ε', respectively, denote the edge sets of G and G'. We now 
show how to construct from a branching fl' of G' a branching Β of G that 
satisfies (11.14) and vice versa. 
For any branching Β of G that satisfies (11.14) it is easy to see that 
Β' = ΒΠΕ' 
(11.16) 
is a branching of G'. Further B' as defined is unique for a given B. 
Next consider a branching B' of G'. For each C,, let us define C[ as 
follows: 
1. If the in-degree in B' of a pseudo-vertex a, is zero, then 
c; = c , - c ° . 
2. If the in-degree in Β' of α, is nonzero, and e is the edge of B' incident 
into at, then 
c; = c , - e . 
Then it is easy to see that 
B = B ' \ J C ; . 
(11.17) 
is a branching of G that satisfies (11.14). Further Β as defined is unique for a 
given B'. 
Thus we conclude that there is a one-to-one correspondence between the 
set of branchings of G that satisfy (11.14) and the set of branchings of G'. 
Furthermore, the weights of the corresponding branchings Β and B' 
satisfy 
k 
k 
w(B) - w(B') = Σ w(C,) - Σ w(e^) . 
(11.18) 
1 = 1 
1 = 1 
This property of Β and B' implies that if Β is an optimum branching of G 
that satisfies (11.14), then B' is an optimum branching of G' and vice versa. 
Thus we have proved the following theorem. 
Theorem 11.9. There exists a one-to-one correspondence between the set of 

332 
GRAPH ALGORITHMS 
all optimum branchings in G that satisfy (11.14) and the set of all optimum 
branchings in G'. 
• 
Edmonds' algorithm for constructing an optimum branching is based on 
Theorem 11.9 and is as follows: 
Algorithm 11.8. Optimum Branching (Edmonds) 
51. From the given graph G = G0 construct a sequence of graphs G0, G,, 
G 2 , . . . , Gk, where 
1. Gk is the first graph in the sequence whose critical subgraph is 
acyclic and 
2. Gn 1 :£ i =£ k, is obtained from G,_, by contracting the circuits in 
the critical subgraph //,_, of G,_, and altering the weights as in 
(11.15). 
52. Since Hk is acyclic, it is an optimum branching in Gk. Let Bk = Hk. 
Construct the sequence Bk_1, 
Bk_2,..., 
B0, where 
1. Β,, 0 ^ i s k - 1, is an optimum branching of G, and 
2. Bt, for i s O , is constructed by expanding, as in (11.17), pseudo-
vertices in Bl+l. 
• 
As an example let G 0 be the graph in Fig. 11.7a, and let H0 be the graph in 
Fig. 11.76. H0 is the critical subgraph of G„. After contracting the edges of 
the circuits in H0 and modifying the weights, we obtain the graph G, shown 
in Fig. 11.8a. The critical subgraph Hl of G, is shown in Fig. 11.86. //, is 
acyclic. So it is an optimum branching of G,. An optimum branching of G 0 
is obtained from Hl by expanding the pseudo-vertices a, and a2 (which 
correspond to the two directed circuits in H0), and it is shown in Fig. 11.8c. 
Tarjan [11.58] gives an 0(m 
log n) implementation of Edmonds' al-
gorithm, where m is the number of edges and η is the number of vertices. 
See also Camerini, Fratta, and Maffioli [11.59]. Chu and Liu [11.60] and 
Bock [11.61] have also independently discovered Edmonds' algorithm. 
11.5 
PERFECT MATCHING, OPTIMAL ASSIGNMENT, AND 
TIMETABLE SCHEDULING 
The optimal assignment and the timetable scheduling problems, the study of 
which involves the theory of matching, are discussed in this section. 
Obtaining an optimal assignment requires as a first step the construction of a 
perfect matching in an appropriate bipartite graph. With this in view, we 
first discuss an algorithm for constructing a perfect matching in a bipartite 
graph. 

PERFECT MATCHING, OPTIMAL ASSIGNMENT, AND TIMETABLE SCHEDULING 
333 
Figure 11.8. (a) Graph G1. (b) Hlt a critical subgraph of G,. (c) An optimum 
branching of graph G of Fig. 11.7a. 

334 
GRAPH ALGORITHMS 
11.5.1 Perfect Matching 
Consider the following personnel assignment problem in which η available 
workers are qualified for one or more of η available jobs, and we are 
interested to know whether we can assign jobs to all the workers, one job 
per worker, for which they are qualified. If we represent the workers by one 
set X={xt, 
x2,...,xn} 
of vertices and the jobs by the other set Y = 
{yx, y2, • • •, y„) of vertices of a bipartite graph G, in which x, is joined to yt 
if and only if the worker x, is qualified for the job _y;, then it is clear that the 
personnel assignment problem is to find whether the graph G has a perfect 
matching or not. 
One method of finding a solution for this problem would be to apply an 
algorithm to find a maximum matching. Such an algorithm will be discussed 
in Chapter 12. If the maximum matching consists of η edges, then it shows 
that the graph has a perfect matching, and the maximum matching is a 
perfect matching. 
The main drawback of this method is that if the graph does not have a 
perfect matching, then we will know this only at the end of the procedure. 
Now we discuss an algorithm that either finds a perfect matching of G or 
stops when it finds a subset S of X such that |Γ(5)| < |S|, where Γ(5) is the 
set of vertices adjacent to those in 5. Clearly, by Hall's theorem (Theorem 
8.13) there exists no perfect matching in the latter case. 
The basic idea behind the algorithm is very simple. We start with an 
initial matching M. If Μ saturates all the vertices in X, then it is the one for 
which we are looking. Otherwise, we choose an unsaturated vertex u in X 
and systematically search for an augmenting path Ρ starting from u. This 
search would result in a tree called a Hungarian tree of the graph. 
At any stage, if we find an augmenting path, we perform the augmenta-
tion and get the new matching, which saturates one more vertex in X, and 
proceed as before. If such a path does not exist, then we would have 
obtained a set S C X, violating the necessary and sufficient condition for the 
existence of a perfect matching. The details of this search procedure are 
discussed below. 
Let Μ be a matching in G, and let u be an unsaturated vertex in X. A 
tree Η in G is called an M-alternating tree rooted at u if: 
1. u belongs to the vertex set of H. 
2. For every vertex ν of H, the unique path from u to i; in Η is an 
Λί-alternating path (i.e., an alternating path relative to M). 
Let us denote by S the subset of vertices of X and by Τ the subset of vertices 
of Y that occur in H. 
The alternating tree is grown as follows. Initially, Η consists of only the 
vertex u. It is then grown in such a way that at any stage, there are two 
possibilities. 

PERFECT MATCHING, OPTIMAL ASSIGNMENT, AND TIMETABLE SCHEDULING 
335 
Μ 
(6) 
Figure 11.9. Examples of alternating trees. 
1. All vertices of Η except u are saturated (e.g., see Fig. 11.9a). 
2. Η contains an unsaturated vertex different from u (e.g., see Fig. 
11.96), in which case we have an augmenting path and hence we get a 
new matching. 
In the first case either Γ(5) = Τ or Τ C Γ(5). 
la. Γ ( 5 ) = Γ . Since |5| = |Γ| + 1 in the tree H, we get in this case 
|T(S)| = |S| - 1, and so the set S does not satisfy the necessary and 
sufficient condition required by Hall's theorem. Hence we conclude 
that there exists no perfect matching in G. 
lb. Τ C Γ(5). So there exists a vertex y in Y that does not occur in Τ but 
that occurs in Γ(5). Let this vertex y be adjacent to vertex χ in S. If y 
is saturated with the vertex ζ as its mate, then we grow Η by adding 
the vertices y and ζ and the edges (x, y) and (y, z). We are then 
back to the first case. If y is unsaturated, we grow Η by adding the 
vertex y and the edge (*, y), resulting in the second case. The path 
from u to y in Η is an augmenting path relative to M. 
This method is presented in the following algorithm. 
Algorithm 11.9. Perfect Matching 
SI. Let G be a bipartite graph with bipartition (X, Y) and 1*1 = \Y\. Let 
M0 be the null matching, that is, M0 = 0 . Set /' = 0. 

336 
GRAPH ALGORITHMS 
52. If all the vertices in X are saturated in the matching M, then HALT. 
(Λί, is a perfect matching in G.) Otherwise pick an unsaturated vertex 
Μ in A' and set S = {u} and Τ = 0 . 
53. If Γ(5)= T, then HALT. (Now |Γ(5)|<|5|, and hence there is no 
perfect matching in G.) Otherwise select a vertex y from Γ(5) - T. 
54. If y is not saturated in M„ go to S5. Otherwise set ζ = mate of 
y , 
S = 5U {z} and T= TU{y}, 
and then go to S3. 
55. (An augmenting path Ρ is found.) Set Ml+1 
= Μ, Θ Ρ and i = i + 1. 
Go to S2. 
• 
As an example, consider the bipartite graph G shown in Fig. 11.10a. In this 
graph the edges of an initial matching Μ are shown in dashed lines. The 
vertex x, is not saturated in M. The M-alternating tree rooted at x, is now 
developed. We terminate the growth of this tree as shown in Fig. 11.106 
when we locate the augmenting path x,, y
x , x2, y
3 . We then augment Μ and 
obtain the new matching shown in Fig. 11.10c. 
Vertex x 4 is not saturated in this new matching. So we proceed to develop 
the alternating tree rooted at x 4, with respect to the new matching. This tree 
terminates as shown in Fig. ll.lOd. Further growth of this tree is not 
possible since at this stage Γ(5) = Τ, where 5 = {χ,, x 2, x 3, x 4} and Τ = 
{>Ί' y-ii y i ) - Hence the graph in Fig. 11.10a has no perfect matching. 
Sometimes we may be interested in finding perfect matchings having a 
specific property. Itai, Rodeh, and Tanimoto [11.62] discuss an algorithm 
applicable for a class of such problems. 
11.5.2 Optimal Assignment 
Consider an assignment problem in which each worker is qualified for all the 
jobs. Here it is obvious that every worker can be assigned a job (of course, 
we assume, as before, that there are η workers and η jobs). In fact, any 
maximum matching performs this, and we have got n\ such matchings. A 
problem of interest in this case is to take into account the effectiveness of 
the workers in their various jobs, and then to make that assignment, which 
maximizes the total effectiveness of the workers. The problem of finding 
such an assignment is known as the optimal assignment problem. 
The bipartite graph for this problem is a complete one; that is, if X = 
{x,, x 2 , . . . ,x„) represents the workers and Y = { y
u 
y
2 , . . . , 
y
n } represents 
the jobs, then for all i and /', x, is adjacent to y
r Also, we assign a weight 
Wjj = w(x,, yj) to every edge (x (, y
t ) , which represents the effectiveness of 
worker x, in job y ; (measured in some unit). Then the optimal assignment 
problem corresponds to finding a maximum weight perfect matching in this 
weighed graph. Such a matching is referred to as an optimal matching. 
We now discuss an 0(n
3) 
algorithm due to Kuhn [11.63], and Munkres 
[11.64], for the optimal assignment problem. We follow the treatment given 
in Bondy and Murty [11.65]. 

PERFECT MATCHING, OPTIMAL ASSIGNMENT, AND TIMETABLE SCHEDULING 
337 
Figure 11.10 

338 
G R A P H A L G O R I T H M S 
A feasible vertex labeling is a real-valued function / on the set X U Y such 
that 
f(x) + /(y) ^ W(JC, y) for all χ £ X and y e Y. 
f(x) is then called the label of the vertex x. 
For example, the following labeling is a feasible vertex labeling: 
/(JC) = max{ tv(jc, y)} , if JC £ X ; 
/(y) = 0, 
i f y £ y . 
From this it should be clear that there always exists a feasible vertex labeling 
irrespective of what the weights are. 
For a given feasible vertex labeling /, let Ef denote the set of all those 
edges (JC, y) of G such that /(JC) + /(y) = H>(JC, y). The spanning subgraph of 
G with the edge set Ef is called the equality subgraph corresponding to /. We 
denote this subgraph by Gf. 
The following theorem relating equality subgraphs and optimal matchings 
forms the basis of the Kuhn-Munkres algorithm. 
Theorem 11.10. Let / b e a feasible vertex labeling of a graph G = (V, E). If 
Gf contains a perfect matching Λί*, then Λί* is an optimal matching in G. 
Proof. Suppose that Gf contains a perfect matching Λί*. Since Gf is a 
spanning subgraph of G, Λί* is also a perfect matching in G. Let w(M*) 
denote the weight of Λί*, that is, 
νν(Λί*) = Σ 
w(e). 
Since each edge e £ Λί* belongs to the equality subgraph and the vertices 
of the edges of Λί* cover each vertex of G exactly once, we get 
w(M*)= Σ 
w(e) 
= Σ Μ . 
(11.19) 
On the other hand, if Λί is any perfect matching in G, then 
w(M)= Σ w(e) 
( E M 
= Ξ Σ / ( Ι > ) . 
(11.20) 
u e v 

PERFECT MATCHING, OPTIMAL ASSIGNMENT, AND TIMETABLE SCHEDULING 
339 
Now combining (11.19) and (11.20), we see that 
w(M*)>w(M). 
Thus M* is an optimal matching in G. 
• 
In the Kuhn-Munkres algorithm, we first start with an arbitrary feasible 
vertex labeling / and find the corresponding Gf. We will choose an initial 
matching Μ in Gf and apply Algorithm 11.9. If a perfect matching is 
obtained in Gf, then, by Theorem 11.10, this matching is optimal. Otherwise 
Algorithm 11.9 terminates with a matching M' that is not perfect, giving an 
Μ'-alternating tree Η that contains no Μ'-augmenting path and that cannot 
be grown further in Gf. We then modify / to a feasible vertex labeling / ' 
with the property that both M' and Η are contained in Gf., and Η can be 
extended in Gf,. We make such a modification in the feasible vertex labeling 
whenever necessary, until a perfect matching is found in some equality 
subgraph. Details of the Kuhn-Munkres algorithm are presented next. 
Algorithm 11.10. Optimal Assignment (Kuhn and Munkres) 
51. G is the given complete bipartite graph with bipartition (AT, Y) and 
\X\ = \ Y\. W= [w i y] is the given weight matrix. Set i = 0. 
52. Start with an arbitrary feasible vertex labeling / in G. Find the 
equality subgraph Gf and then select an initial matching Λί,· in Gf. 
53. If all the vertices in X are saturated in Λί,, then Λί, is a perfect 
matching, and hence by Theorem 11.10, it is an optimal matching. So 
HALT. Otherwise let u be an unsaturated vertex in X. Set S = {«} 
and T = 0. 
54. Let Tf(S) be the set of vertices that are adjacent in Gf to the vertices 
in S. If Tf(S)DT, 
then go to S5. Otherwise (i.e., if 
Vf(S)=T) 
compute 
d, = min { /(*) + f(y)~ 
w(x, y)} 
(11.21) 
and get a new feasible vertex labeling / ' given by 
\f(v)-df, 
if i ; E S ; 
f'(v) 
= \f(v) + df, 
if vET; 
(11.22) 
[/(f), 
otherwise. 
(Note that df > 0 and Tf(S) = T.) 
Replace / by / ' and Gf by Gf.. 
55. Select a vertex y from Tf(S) - T. If y is not saturated in M,, go to S6. 

340 
GRAPH ALGORITHMS 
To illustrate the Kuhn-Munkres algorithm consider a complete bipartite 
graph G having the following weight matrix W= [wtJ]: 
W = 
4 4 
1 3 
3 2 2 1 
5 4 4 3 
1 
1 2 2J 
An initial feasible vertex labeling / of G may be chosen as follows: 
f(Xl) 
= 4, 
f(x2) = 3, 
f(x3) = 5, 
f(x4) = 2; 
The equality subgraph G^-is shown in Fig. 11.lie. Applying Algorithm 11.9, 
we find that Gf has no perfect matching because for the set S = {JC, , x2, 
x3), 
T = r(5) = { y 1 ; y 2 } . 
Using (11.21) we compute 
df = l. 
Figure 11.11 
Otherwise set ζ = mate of y in M,,, S - S U {2} and Γ = Τ U {y}, and 
then go to S4. 
S6. (An augmenting path Ρ is found.) Set Mi+l = Μ , Φ Ρ and / = i + 1. 
Go to S3. 
• 

PERFECT MATCHING, OPTIMAL ASSIGNMENT, AND TIMETABLE SCHEDULING 
341 
The following new labeling/' is then obtained using (11.22): 
/'(*,) = 3 , 
f'(x2) 
= 2, 
/'(*,) = 4 , 
/'(x 4) = 2 ; 
f'(yl) 
= u 
/ ' ( >
2 ) = i . 
/ ' ( > ' 3 ) = o , 
/ ' ( y 4 ) = o . 
The equality subgraph Gf. is shown in Fig. 11.116. Using Algorithm 11.9 on 
Gf., 
we obtain the perfect matching Μ consisting of the edges (xl, 
y2), 
(x2, yx), 
( J C 3 , y3), and (x 4, y 4). This matching is an optimal matching. 
Megiddo and Tamir [11.66] discuss an 0(n log n) algorithm for a class of 
weighted matching problems that arise in certain applications relating to 
scheduling and optimal assignments. More recent results on the perfect 
matching and the optimal assignment problems can be found in Karp 
[11.67], Derigs [11.68], Avis [11.69], Avis and Lai [11.70], and Grigoriadis 
and Kalantari [11.71]. 
More discussions of matching algorithms and related references can be 
found in Chapter 12. 
11.5.3 Timetable Scheduling 
In a school there are ρ teachers xx, x2,... 
,xp and q classes yx, y2,..., 
yq. 
Given that teacher x, is required to teach class yl for ρη periods, we would 
like to schedule a timetable having the minimum possible number of 
periods. This is a special case of what is known as the timetable scheduling 
problem. 
Suppose that we construct a bipartite graph G = (X, Y) in which the 
vertices in X represent the teachers and those in Y represent classes, and 
vertex x, G X is connected to vertex ys G Y by ptj parallel edges. Since in any 
one period each teacher can teach at most one class and each class can be 
taught by at most one teacher, it follows that a teaching schedule for one 
period corresponds to a matching in G, and conversely each matching 
corresponds to a possible assignment of teachers to classes for one period. 
Thus the timetable scheduling problem is to partition the edges of G into as 
few matchings as possible. 
By Corollary 8.22.1, the minimum number of matchings in any partition 
of the edge set of a bipartite graph G is equal to the maximum degree in G. 
The proof of this theorem also suggests the following procedure for de-
termining a partition having the smallest number of matchings: 
Step 1. Let G be the given bipartite graph. Set i = 0 and G0 = G. 
Step 2. Construct a matching Mt of G, that saturates all the maximum 
degree vertices in G,. 
Step 3. Remove M, from G,. Let G 1 + 1 denote the resulting graph. If G ( + 1 
has no edges, then M0, A/,,... ,M, is a required partition of the 
edge set of G. Otherwise set i = i + 1 and go to step 1. 

342 
GRAPH ALGORITHMS 
Clearly, the complexity of this procedure depends on the complexity of 
implementing step 2, which requires finding a matching that saturates all the 
maximum degree vertices in a bipartite graph G = (X, Y). Such a matching 
may be found as follows. (See proof of Theorem 8.21.) 
Let Xa denote the set of maximum degree vertices in X, and let Yb denote 
the set of maximum degree vertices in Y. Let Ga denote the subgraph of G 
formed by the edges incident on the vertices in Xa. Similarly Gb is the 
subgraph on the edges incident on the vertices in Yb. 
By Theorem 8.22 there is a matching Ma that saturates all the vertices in 
X„. The matching Ma is a maximum matching in G„. Similarly in Gb there is 
a maximum matching Mb that saturates all the vertices in Yb. Following the 
procedure used in the proof of Theorem 8.21, we can find from Ma and Mb a 
matching Λί that saturates the vertices in Xa and Yb. Then Λί is a required 
matching saturating all the maximum degree vertices in G. 
The complexity of finding Λίβ and Mb is the same as the complexity of 
finding a maximum matching that, as we shall see in Chapter 12, is 0(n
 
5), 
where η is the number of vertices in the bipartite graph. It is easy to see that 
the complexity of constructing Μ from Ma and Λί,, is 0(n
2). 
Thus the overall 
complexity of implementing step 2 is 0(n
2 5 ) . This bound can be improved 
since all that we need in step 2 is a matching that saturates all the maximum 
degree vertices. Cole and Hopcroft [11.72] present such an algorithm of 
complexity 0(m log n), where m is the number of edges in the bipartite 
graph. An earlier algorithm for this problem due to Gabow and Kariv 
[11.73] had complexity 0(min {n
2log n, m log
2«}). 
Since step 2 will be repeated Δ times where Δ is the maximum degree in 
G and Δ == n, it follows that the complexity of constructing the required 
timetable is 0(mn log n). 
A more general problem follows. Let us assume that only a limited 
number of classrooms are available. The question is: How many periods are 
now needed to schedule a complete timetable? 
Suppose that / lessons are to be given and that they have to be scheduled 
in a p-period timetable. This timetable would require an average of \l/p] 
lessons to be given per period. So it is clear that at least \l/p] rooms will be 
needed in some one period. Interestingly one can always arrange / lessons in 
a p-period timetable so that at most \l/p] rooms are occupied in any one 
period. See Exercises 8.24 and 8.25. 
A discussion of the general form of the timetable scheduling problem and 
references related to this may be found in Even, Itai, and Shamir [11.74]. 
11.6 
THE CHINESE POSTMAN PROBLEM 
A postman picks up mail at the post office, delivers it along a set of streets, 
and returns to the post office. Of course, he must cover every street at least 
once, in either direction. The question is: What route would enable the 

THE CHINESE POSTMAN PROBLEM 
343 
postman to walk the shortest distance possible? This problem known as the 
Chinese postman problem was first proposed by the Chinese mathematician 
Kwan [11.75]. 
If G denotes the weighted connected graph representing the streets and 
their lengths, then the Chinese postman problem is simply that of finding a 
minimum weight closed walk that traverses every edge of G at least once. 
We shall refer to such a minimum weight closed walk as an optimal Chinese 
postman tour. Any closed walk traversing every edge at least once will be 
referred to as a postman 
tour. 
If G is Eulerian, then clearly any Euler trail of G is an optimal postman 
tour. 
Suppose that G is not Eulerian. Then we can easily see that every 
postman tour of G corresponds to an Euler trail in the (Eulerian) graph G* 
that has the same vertex set as G and that has as many copies of an edge 
(i, /) as the number of times it appears in the walk. Conversely, if G* is an 
Eulerian graph constructed by adding to G appropriate numbers of addition-
al copies of edges, then each Euler trail of G* will correspond to a postman 
tour of G. We can consider G* as consisting of two types of edges: the 
original edges (the edges of G) and the pseudo-edges (the parallel edges 
asked to G to make it Eulerian). Our objective, therefore, is to obtain a G* 
such that the sum of the weights of its pseudo-edges is as small as possible. 
Note here that the weight of a pseudo-edge is the same as that of the 
corresponding edge. 
In order to gain an insight into the structure of G*, consider a vertex υ 
whose degree in G is odd. Clearly in G* an odd number of pseudo-edges 
must be incident on v. Let (u, v) be one such pseudo-edge. If u is of even 
degree in G, then there must be a pseudo-edge (w, u) incident on w, for 
otherwise the degree of u in G* will be odd. Continuing this argument, we 
can see that in G* there is a path of pseudo-edges that starts at υ and ends at 
a vertex whose degree in G is odd. Thus, if G has 2k, k^l 
odd degree 
vertices, then we can group these vertices into k distinct pairs 
(vl,v2). 
(υ3,νΑ),... 
, ( i > 2 * - i >
 
v2k)
 
s
u
c
n 
t
n
a
t in G* there is a path of pseudo-edges 
between the vertices of each pair. These observations suggest the following 
procedure to construct G* from G. 
Pick any two vertices, say u and υ, whose degrees in G are odd. Find an 
u-v path in G and add to G pseudo-edges along this path. Clearly, in the 
resulting graph G' both u and υ will have even degrees. Repeat this 
procedure, picking any two odd degree vertices in G'. This procedure will 
terminate when we have obtained an Eulerian graph G* in which all vertices 
have even degrees. 
It should be easy to see that the sum W* of the weights of pseudo-edges 
of the graph G* (constructed as above) is equal to the sum of the weights of 
the paths chosen to add the pseudo-edges. So, in order to minimize W* it is 
necessary that the paths selected must be the shortest ones. Also, our choice 
of pairs of odd-degree vertices influences the value of W*. In other words to 

344 
GRAPH ALGORITHMS 
minimize W* we should group the odd-degree vertices into k pairs (w l t v2), 
(l> 3 ) VA), 
. . . ,(v2k-U
 
V2k)
 
s
u
c
h 
t
h
a
t 
k 
i= 1 
is as small as possible. Recall that d(vit vt) denotes the distance between u, 
and v, in G. 
We can easily verify that the minimum value of W* and the correspond-
ing shortest paths can be obtained by solving a maximum weight perfect 
matching problem in a complete bipartite graph as described in S3 and S4 of 
the following algorithm due to Edmonds [11.76] and Edmonds and Johnson 
[11.77]! 
Algorithm 11.11 Optimal Chinese Postman Tour (Edmonds and Johnson) 
50. Given a weighted connected graph G, an optimal Chinese postman 
tour is required. 
51. Identify all the odd-degree vertices of G. Let these be u,, i> 2,..., u2k, 
k a 1. If there are no odd-degree vertices in G, set G* = G and go to 
S5. 
52. Compute the shortest paths between all pairs of odd-degree vertices. 
Let d(vt, vt) denote the distance between u, and vr 
53. Construct a complete bipartite graph G' with bipartition as follows: 
X
 = {jCj, x2, • • · , X2k} ' 
Y={yi,y2,---,y2k), 
>0
 = o. 
w(xn yf) = Μ - d(v„ v,) 
for i V ; , 
where Μ is a large number. 
54. Find a maximum weight perfect matching in G'. For each (x,, yt) in 
this perfect matching, add pseudo-edges to G along a shortest 
v-v, 
path. Let G* denote the resulting Eulerian graph. 
55. Construct an Euler trail of G*. This trail defines an optimal Chinese 
postman tour. HALT. 
• 
It is easy to show that no edge can appear in more than one of the 
shortest paths identified in S4 in Algorithm 11.11. This means that no edge 
will be traversed more than twice in the optimal Chinese postman tour. 
Note that S2 can be carried out by Algorithm 11.5 for the all pairs 
shortest path problem. Step S4 can be carried out by Algorithm 11.10 for 
the optimal assignment problem. To carry out S5 we need an efficient 
algorithm to construct an Euler trail in an Eulerian graph. An algorithm due 
to Fleury [11.78], which achieves this, is described below. 

THE CHINESE POSTMAN PROBLEM 
345 
Algorithm 11.12. Eulerian Trail (Fleury) 
50. Given an Eulerian graph G = (V, E), an Euler trail of G is required. 
51. Let i = 0 and select an arbitrary vertex v0 of G and define T0: v0. 
52. Given that the trail Γ,: v0, ex, u,, e2,..., 
e„ υ, has been constructed, 
select an edge el+i 
from 
Ε — {ex, e2,..., 
e,} 
subject to the following conditions: 
(
a)
 
e i + i '
s incident on υ,. 
(b) Unless there is no other choice, el+l 
is not a bridge of the graph 
G, = G - { e , , e 2 , . . . , e , } . 
If no such edge el+1 
exists, then HALT. 
53. Define 7", + 1: v0, ex, i>,, e2,.. 
.,el 
+ l , vl + l , where el + 1 =(υ,, 
υι+ι). 
54. Set I = I + 1 and go to S2. 
• 
Theorem 11.11. If G is Eulerian, then Fleury's algorithm constructs an 
Eulerian trail of G. 
Proof. Let G = (V, E) be an Eulerian graph. Suppose that Fleury's al-
gorithm starts with vertex υ 0 of G and terminates with the trail 
Tp:v0,ei,v1,e2,v2,...,ep,vp. 
Note that whereas the vertices u,'s of Tp may not all be distinct, the edges 
e,'s are. We need to show that Tp is an Eulerian trail of G. For i = 
1, 2,...,p, 
let 
Gj = G - {e^e^.. 
.,e,} . 
First we show that vp = v0. Since the algorithm terminates in vp, the 
degree of υ in Gp is zero. If υρΦυ0, 
then the degrees of vp and v0 in Tp will 
be odd because they are the terminal vertices of Tp. This would then imply 
that the degree of vp in G is odd since the degree of a vertex in G is equal to 
the sum of its degrees in Gp and Tp. A contradiction because G is Eulerian 
and every vertex in G has even degree. Hence vp = v0 and Tp is a closed 
trail. Furthermore, this means that every vertex v, has even degree in Tp and 
so every vertex of Gp must also have even degree. 
We next show that Tp contains every edge of G. Suppose that this is not 
true. Let S denote the set of vertices of positive degree in Gp. Clearly S is 
nonempty and vp e 5, where 5 = V — S. Let vk be the last vertex of Τ that 

346 
GRAPH ALGORITHMS 
belongs to S. Since Tp terminates in υρ Ε S, it follows that the edge 
ek+i ~ (
vk>
 vk+i) *
s t r i e 
o n ' y edge of the cut (S,S) 
in Gk. In other words 
ek+1 
is a bridge of Gk. 
For / = k, k + 1 , . . . , p, let G\ denote the subgraph of G, induced by the 
vertex set S. Since none of the edges ek+l, 
e k + r , . . . , ep have both their end 
vertices in 5, it follows that G'k = G'k+l = · · • = G'p. Also note that every 
vertex in G'p has even degree because it is the subgraph of Gp induced by 
vertices of positive degree. Thus by Theorem 3.1, G'p is Eulerian. Now 
consider any edge e Φ ek+x 
of Gk incident on vk. It follows from S2 of the 
algorithm that e is also a bridge of Gk, for otherwise ek+l 
would not have 
been picked at this step. Thus e is a bridge of G'k and also of G'. But G'p 
has no bridges because, as we have seen, it is Eulerian and every edge of an 
Eulerian graph lies in a circuit of the graph (Corollary 3.1.1). 
Thus Tp is a closed trail and contains every edge of G. In other words 
Fleury's algorithm constructs an Eulerian trail of G. 
• 
For a variant of the Chinese postman problem (namely, the rural Chinese 
postman problem) and its application in communication network protocol 
testing see Aho, Dahbura, Lee and Uyar [11.79]. For some generalizations 
of this problem and related algorithms see Orloff [11.80], Papadimitriou 
[11.81], Lenstra and Rinooy-Kan [11.82], Frederickson [11.83], and Dror, 
Stern, and Trudeau [11.84]. 
11.7 DEPTH-FIRST SEARCH 
In this section we describe a systematic method for exploring a graph. This 
method known as depth-first search, in short, DFS, has proved very useful 
in the design of several efficient algorithms. Some of these algorithms are 
discussed in the remaining sections of this chapter. Our discussion here is 
based on [11.85]. 
11.7.1 DFS of an Undirected Graph 
We first describe DFS of an undirected graph. To start with, we assume that 
the graph under consideration is connected. If the graph is not connected, 
then DFS would be performed separately on each component of the graph. 
We also assume that there are no self-loops in the graph. 
DFS of an undirected graph G proceeds as follows: 
We choose any vertex, say v, in G and begin the search from v. The start 
vertex υ, called the root of the DFS, is now said to be visited. 
We then select an edge (v, w) incident on υ and traverse this edge to visit 
w. We also orient this edge from ν to w. The edge (v, w) is now said to be 
examined and is called a tree edge. The vertex ν is called the father of w, 
denoted as FATHER(w). 
In general, while we are at some vertex x, two possibilities arise: 

DEPTH-FIRST SEARCH 
347 
1. If all the edges incident on χ have already been examined, then we 
return to the father of χ and continue the search from FATHER(x). 
The vertex χ is now said to be completely scanned. 
2. If there exist some unexamined edges incident on x, then we select one 
such edge (JC, y) and orient it from χ to y. The edge (x, y) is now said 
to be examined. Two cases need to be considered now: 
Case 1 
If y has not been previously visited, then we traverse the 
edge (x, y), visit y, and continue the search from y. In this 
case (x, y) is a tree edge and JC = FATHER(.y). 
Case 2 
If y has been previously visited, then we proceed to select 
another unexamined edge incident on x. In this case the edge 
(x, y) is called a back edge. 
During the DFS, whenever a vertex χ is visited for the first time, it is 
assigned a distinct integer D F N ( J C ) such that D F N ( x ) = i, if χ is the ith 
vertex to be visited during the search. D N F ( J C ) is called the depth-first 
number of jt. Clearly, depth-first numbers indicate the order in which the 
vertices are visited during DFS. 
DFS terminates when the search returns to the root and all the vertices 
have been visited. 
As we can see from the preceding description, DFS partitions the edges 
of G into tree edges and back edges. It is easy to show that the tree edges 
form a spanning tree of G. DFS also imposes directions on the edges of G. 
The resulting directed graph will be denoted by G. The tree edges with their 
directions imposed by the DFS will form a directed spanning tree of G. This 
directed spanning tree will be called the DFS tree. 
Note that DFS of a graph is not unique since the edges incident on a 
vertex may be chosen for examination in any arbitrary order. 
As an example, we have shown in Fig. 11.12 DFS of an undirected graph. 
In this figure tree edges are shown as continuous lines, and back edges are 
shown as dashed lines. Next to each vertex we have shown its depth-first 
number. We have also shown in the figure the list of edges incident on each 
vertex v. This list for a vertex ν is called the adjacency list of v, and it gives 
the order in which the edges incident on ν are chosen for examination. 
We now present a formal description of the DFS algorithm. In this 
description the graph under consideration is not assumed to be connected. 
The array MARK used in the algorithm has one entry for each vertex. To 
begin with we set MARK(u) = 0 for every vertex υ in the graph, thereby 
indicating that no vertex has yet been visited. Whenever a vertex is visited, 
we set the corresponding entry in the MARK array equal to 1. The arrays 
D F N and FATHER are as defined before. TREE and BACK are two sets 
storing, respectively, the tree edges and the back edges as they are gen-
erated. 

348 
GRAPH ALGORITHMS 
1 
6 
Vertex 
Adjacency List 
1 
(1,2), (1,3), (1,4) 
2 
(2,1), (2,3), (2,8), (2,9), (2,10), (2,11) 
3 
(3,1), (3,2), (3,4), (3,5), (3,6), (3,7) 
4 
(4,1), (4,3), (4,5), (4,6) 
5 
(5,3), (5,4) 
6 
(6,3), (6,4) 
7 
(7.3), (7,8) 
8 
(8,2), (8,7) 
9 
(9,2), (9,10), (9,11) 
10 
(10,2), (10,9) 
11 
(11,2), (11,9) 
Figure 11.12. DFS of an undirected graph. 
Algorithm 11.13. DFS of an Undirected Graph 
51. G is the given graph. Set TREE = 0 , BACK = 0 , and i = l. For 
every vertex υ in G, set FATHER(i>) = 0 and MARK(u) = 0. 
52. (DFS of a component of G begins.) Select any vertex, say vertex r, 
with MARK(r) = 0. Set DFN(r) = i, MARK(r) = 1, and υ = r. (The 
vertex r is called the root of the component under consideration.) 
53. If all the edges incident on υ have already been labeled "examined," 
then go to SS. (v is now completely scanned.) Otherwise select an 
edge (v, w) that is not yet labeled "examined" and go to S4. 
54. Orient the edge (υ, w) from ν to w and label it "examined." Do the 
following and then go to S3. 

DEPTH-FIRST SEARCH 
349 
1. If M A R K ( H - ) = 0, 
set 
I = I + 1, 
D F N ( M > ) = i, 
TREE = TREE U {(v, w)}, 
MARK(w) = 1, 
FATHER(w) = v, 
ν — w. 
2. If MARK(w) = l, set 
BACK = BACK U {(v, w)}. 
55. If FATHER(u) Φ0 (i.e., ν is not the root of the component under 
consideration), then set υ = FATHER(u) and go to S3. Otherwise go 
to S6. 
56. If, for every vertex x, MARK(x) = 1, then go to S7; otherwise set 
i = / + l and go to S2. 
57. (DFS is completed.) HALT. 
• 
Let Γ be a DFS tree of a connected undirected graph. As we mentioned 
before, Γ is a directed spanning tree of G. For further discussions, we need 
to introduce some terminology. 
If there is a directed path in Τ from a vertex υ to a vertex w, then υ is 
called an ancestor of w, and w is called a descendant of v. Furthermore, if 
υ Φ w, υ is called a proper ancestor of w, and w is called a proper descendant 
of v. If (v, w) is a directed edge in T, then ν is called the father of w, and w 
is called a son of v. Note that a vertex may have more than one son. A 
vertex ν and all its descendants form a subtree of Τ with vertex ν as the root 
of this subtree. 
Two vertices ν and w are related if one of them is a descendant of the 
other. Otherwise υ and w are unrelated. If υ and w are unrelated and 
DFN(i;)<DFN(w), then υ is said to be to the left of w; otherwise, ν is to 
the right of w. Edges of G connecting unrelated vertices are called cross 
edges. 
We now show that there are no cross edges in G. 
Let υ, and v2 be any two unrelated vertices in T. Clearly then there are 
two distinct vertices s, and s2 such that (1) FATHER(s,) = FATHER(s 2) 
and (2) i>, and v2 are descendants of sx and s2, respectively (see Fig. 11.13). 
Let Γ, and T2 denote the subtrees of Τ rooted at s, and s2, respectively. 
Assume without loss of generality that DFN(ij)<DFN(j 2). It is then clear 
from the DFS algorithm that vertices in 7Λ, are visited only after the vertex s, 
is completely scanned. Further, scanning of s, is completed only after all the 
vertices in Γ, are scanned completely. So there cannot exist an edge 
connecting u, and v2. For if such an edge existed, it would have been visited 
before the scanning of Sj is completed. 
Thus we have the following. 

350 
GRAPH ALGORITHMS 
Figure 11.13 
», 
Theorem 11.12. If (v, w) is an edge in a connected undirected graph G, then 
in any DFS tree of G either ν is a descendant of w or vice versa. 
• 
The absence of cross edges in an undirected graph is an important 
property that forms the basis of an algorithm to be discussed in the next 
section for determining the biconnected components of a graph. 
11.7.2 DFS of a Directed Graph 
DFS of a directed graph is essentially similar to that of an undirected graph. 
The main difference is that in the case of a directed graph an edge is 
traversed only along its orientation. As a result of this constraint, edges in a 
directed graph G are partitioned into four categories (and not two as in the 
undirected case) by a DFS of G. An unexamined edge (v, w) encountered 
while at the vertex υ would be classified as follows. 
Case 1 
w has not yet been visited. 
In this case (v, w) is a tree edge. 
Case 2 
w has already been visited. 
a. If w is a descendant of ν in the DFS forest (i.e., the subgraph of tree 
edges), then (v, w) is called a forward edge. 

D E P T H - F I R S T S E A R C H 
351 
b. If w is an ancestor of υ in the DFS forest, then (v, w) is called a back 
edge. 
c. If ν and w are not related in the DFS forest and D F N ( H ' ) <DFN(i/), 
then (v, w) is a cross edge. Note that there are no cross edges of the 
type (v, w) with DFN(w) > DFN(u). The proof for this is along the 
same lines as that for Theorem 11.12. 
A few useful observations are now in order: 
1. An edge (v, w), with DFN(w) > DFN(u), is either a tree edge or a 
forward edge. During the DFS it is easy to distinguish between a tree 
edge and a forward edge because a tree edge always leads to a new 
vertex. 
2. An edge (v, w) with DFN(tv) < DFN(u) is either a back edge or a 
cross edge. Such an edge (v, w) is a back edge if and only if w is not 
completely scanned when the edge is encountered while examining the 
edges incident out of v. 
3. DFS forest, the subgraph of tree edges, may not be connected even if 
the directed graph under consideration is connected. The first vertex 
to be visited in each component of the DFS forest will be called the 
root of the corresponding component. 
A description of the DFS algorithm for a directed graph is presented next. 
In this algorithm we use a new array SCAN that has one entry for each 
vertex in the graph. To begin with we set SCAN(u) = 0 for every vertex υ, 
thereby indicating that none of the vertices is completely scanned. When-
ever a vertex is completely scanned, the corresponding entry in the SCAN 
array is set to 1. As we pointed out earlier, when we encounter an edge 
(v,w) 
with 
D F N ( H > ) <DFN(i>), we shall classify it as a back edge if 
SCAN(»v) = 0; otherwise (v,w) 
is a cross edge. We also use two arrays, 
FORWARD and CROSS, that store respectively, forward and cross edges. 
Algorithm 11.14. DFS of a Directed Graph 
51. 
G is the given directed graph with no self-loops. Set TREE = 0 , 
FORWARD = 0 , BACK = 0 , CROSS = 0 , and i = l. For every 
vertex υ in G, set MARK(u) = 0, FATHER(u) = 0, and SCAN(u) = 
0. 
52. 
(DFS with a new root begins.) Select any vertex, say vertex r, with 
MARK(r) = 0. Set DFN(r) = t, MARK(r) = 1, and υ = r. 
53. 
If all the edges incident out of ν have already been labeled "ex-
amined," set SCAN(i>) = 1, and then go to S5. (v is now completely 
scanned.) Otherwise select an edge (v, w) that is not yet labeled 
"examined' and go to S4. 

352 
GRAPH ALGORITHMS 
54. Label the edge (v, w) "examined," do the following, and then go to 
S3. 
1. If MARK(vv) = 0, then set 
j = i + 1, 
D F N ( H - ) = i, 
TREE = TREE U {(i>, w)}, 
MARK(w) = 1, 
FATHER(w) = v, 
υ = w. 
2. Otherwise set 
FORWARD = FORWARD U {(υ, w)} if DFN(tv) > DFN(u), 
BACK = BACK U {(i>, w)} if DFN(w) < DFN(u), and 
S C A N ( M > ) = 0; 
CROSS = CROSS U {(v, w)}, otherwise. 
55. If FATHER(u) Φ0 (i.e., ν is not a root), then set ν = FATHER(u) 
and go to S3. Otherwise go to S6. 
56. If for every vertex x, MARK(x) = 1, then go to S7; otherwise set 
/ = ι + 1 and go to S2. 
57. (DFS is completed.) HALT. 
• 
As an example, DFS of a directed graph is shown in Fig. 11.14a. Next to 
each vertex we have shown its depth-first number. The tree edges are shown 
as continuous lines, and the other edges are shown as dashed lines. The DFS 
forest is shown separately in Fig. 11.14ft. 
We pointed out earlier that the DFS forest of a directed graph may not be 
connected, even if the graph is connected. This can also be seen from Fig. 
11.14b. This leads us to the problem of discovering sufficient conditions for 
a DFS forest to be connected. In the following we prove that the DFS forest 
of a strongly connected graph is connected. In fact, we shall be establishing 
a more general result. 
Let Τ denote a DFS forest of a directed graph G = (V, E). Let G, = 
(Vf, Ej), with |Vj| 2:2, be a strongly connected component of G. Consider 
any two vertices υ and ic in 6,. Assume without loss of generality that 
D F N ( U ) < D F N ( M ' ) . Since Gj is strongly connected, there exists a directed 
path Ρ in G, from ν to w. Let χ be the vertex on Ρ with the lowest depth-first 
number and let Tx be the subtree of Γ rooted at x. Note that cross edges and 
back edges are the only edges that lead out of the subtree Tx. Since these 
edges lead to vertices having lower depth-first numbers than D F N ( J C ) , it 
follows that once path Ρ reaches a vertex in Tx, then all the subsequent 
vertices on Ρ will also be in Tx. In particular, w also lies in Tx. So it is a 
descendant of x. Since D F N ( * ) ^ D F N ( u ) < D F N ( w ) , it follows from the 
DFS algorithm that υ is also in Tx. Thus any two vertices ν and w in G, have 
a common ancestor that is also in G,. 

DEPTH-FIRST SEARCH 
353 
8 
Figure 11.14. (a) DFS of a directed graph, (b) DFS forest of graph in (a). 
We may conclude from this that all the vertices of G, have a common 
ancestor r, that is also in G,. It may now be seen that among all the common 
ancestors in Τ of vertices in G,, vertex r, has the highest depth-first number. 
Further, it is easy to show that if υ is a vertex in G„ then any vertex on the 
tree path from r, to υ will also be in G (. So the subgraph of Γ induced by Vt 
is connected. Thus we have the following. 
Theorem 11.13. Let G, = (V), Et) be a strongly connected component of a 
directed graph G = (V, E). If Γ is a DFS forest of G, then the subgraph of Τ 
induced by V, is connected. 
• 

354 
GRAPH ALGORITHMS 
Following is an immediate corollary of Theorem 11.13. 
Corollary 11.13.1. The DFS forest of a strongly connected graph is 
connected. 
• 
It is easy to show that the DFS algorithms 11.13 and 11.14 are both of 
complexity 0(n + m), where η is the number of vertices and m is the 
number of edges in a graph. 
11.8 BICONNECTIVITY AND STRONG CONNECTIVITY 
In this section we discuss algorithms due to Tarjan [11.85] and Hopcroft and 
Tarjan [11.86] for determining the biconnected components and the strongly 
connected components of a graph. These algorithms are based on DFS. We 
begin our discussion with the biconnectivity algorithm. 
11.8.1 
Biconnectivity 
We may recall (Chapter 8) that a biconnected graph is a connected graph 
with no cut-vertices. A maximal biconnected subgraph of a graph is called a 
biconnected component of the graph.
+ 
A crucial step in the development of the biconnectivity algorithm is the 
determination of a simple criterion that can be used to identify cut-vertices 
as we perform a DFS. Such a criterion is given in the following two lemmas. 
Let G = (V, E) be a connected undirected graph. Let Τ be a DFS tree of 
G with vertex r as the root. Then we have the following. 
Lemma 11.5. Vertex υ Φ r is a cut-vertex of G if and only if for some son s 
of ν there is no back edge between any descendant in Τ of s (including itself) 
and a proper ancestor of v. 
Proof. Let G' be the graph that results after removing vertex ν from G. By 
definition, υ is a cut-vertex of G if and only if G' is not connected. 
Let s,, s2,..., 
sk be the sons of ν in T. For each i, 1 < i s Jfc, let V, denote 
the set of descendants of s, (including itself), and let G ( be the subgraph of 
G' induced on V). Further let V" -V 
- U * = 1 V „ where V = V- {v}, and let 
G" be the subgraph induced on V". Note that all the proper ancestors of υ 
are in V". 
Clearly, Gx, G2,...,Gk 
and G" are all subgraphs of G, which together 
contain all the vertices of G'. We can easily show that all these subgraphs 
are connected. Further, by Theorem 11.12 there are no edges connecting 
vertices belonging to different G,'s. So it follows that G' will be connected if 
'Note that a biconnected component is the same as a block defined in Section 1.7. 

BICONNECTIVITY AND STRONG CONNECTIVITY 
355 
and only if for every i, 1 < ι < A:, there exists an edge (a, b) between a 
vertex a £ V, and a vertex b £ V". Such an edge (a,b) will necessarily be a 
back edge, and b will be a proper ancestor of v. We may therefore conclude 
that G' will be connected if and only if for every son s, of ν there exists a 
back edge between some descendant of s, (including itself) and a proper 
ancestor of v. The proof of the lemma is now immediate. 
• 
Lemma 11.6. The root vertex r is a cut-vertex of G if and only if it has more 
than one son. 
Proof. Proof in this case follows along the same line as that for Lemma 
11.5. 
• 
In the following we refer to the vertices of G by their depth-first 
numbers. To embed into the DFS procedure the criterion given in Lemmas 
11.5 and 11.6, we now define, for each vertex υ of G, 
L O W ( D ) = min({u} U {*v| there exists a back edge (x, w) such that JC is a 
descendant of υ, and w is a proper ancestor of ν in 
T}). 
(11.23) 
Using the LOW values defined, we can restate the criterion given in Lemma 
11.5 as in the following theorem. 
Theorem 11.14. Vertex ν Φ r is a cut-vertex of G if and only if υ has a son * 
such that LOW(s) > v. 
• 
Noting that LOW(u) is equal to the lowest numbered vertex that can be 
reached from ν by a directed path containing at most one back edge, we can 
rewrite (11.23) as 
Low(u) = min({i>} U {LOW(i)|i is a son of v} 
U {vv|(u, w) is a back edge}). 
This equivalent definition of LOW(u) suggests the following steps for 
computing LOW(y): 
1. When ν is visited for the first time during DFS, set LOW(u) equal to 
the depth-first number of v. 
2. When a back edge (u, w) incident on υ is examined, set LOW(u) to the 
minimum of its current value and the depth-first number of w. 
3. When the DFS returns to ν after completely scanning a son s of υ, set 
LOW(u) equal to the minimum of its current value and LOW(s). 

356 
GRAPH ALGORITHMS 
Figure 11.15. G,, G 2, G3, G 4, G5—bicon-
nected components of a graph. 
Note that for any vertex v, computation of LOW(u) ends when the scanning 
of υ is completed. 
We next consider the question of identifying the edges belonging to a 
biconnected component. For this purpose we use an array STACK. To 
begin with STACK is empty. As edges are examined, they are added to the 
top of STACK. 
Suppose DFS returns to a vertex υ after completely scanning a son s of v. 
At this point computation of LOW(s) will have been completed. Suppose it 
is now found that LOW(s)s v. Then, by Theorem 11.14, ν is a cut-vertex. 
Further, if s is the first vertex with this property, then we can easily see that 
the edge (v, s) along with the edges incident on s, and its descendants will 
form a biconnected component. These edges are exactly those that lie on 
top of STACK up to and including (u, s). They are now removed from 
STACK. From this point on the algorithm behaves in exactly the same way 
as it would on the graph G', which is obtained by removing from G the 
edges of the biconnected component that has just been identified. 
For example, a DFS tree of a connected graph may be as in Fig. 11.15, 
where G,, G2,..., 
G 5 are the biconnected components in the order in which 
they are identified. 
A description of the biconnectivity algorithm now follows. This algorithm 
is essentially the same as Algorithm 11.13, with the inclusion of appropriate 
steps for computing LOW(y) and identifying the cut-vertices and the edges 
belonging to the different biconnected components. Note that in this 
algorithm the root vertex r is treated as a cut-vertex, even if it is not one, for 
the purpose of identifying the biconnected component containing r. 
Algorithm 11.15. Biconnectivity 
51. G is the given connected graph. For every vertex ν in G, set 
FATHER(t>) = 0 and MARK(u) = 0. Set ι = 1 and STACK = 0 . 
52. Select any vertex, say vertex r, with MARK(r) = 0. Set 
DFN(r) = 0, 
LOW(r) = i, 
MARK(r) = 1, 
ν = r. 

BICONNECTIVITY AND STRONG CONNECTIVITY 
357 
53. If all the edges incident on υ have already been labeled "examined," 
then go to S5. Otherwise select an edge (v, w) that is not yet labeled 
"examined." Label this edge "examined," add it to the top of 
STACK, and go to S4. 
54. Do the following and then go to S3: 
1. If MARK(tv) = 0, set 
i = i + 1, 
DFN(w) = /', 
LOW(w) = i, 
FATHER(w) = v, 
MARK(vv) = 1. 
2. 
If 
M A R K ( H O = 1, 
set 
LOW(i>) = min{LOW(u), D F N ( H > ) } . 
55. If FATHER(u) Φ 0, go to S6; otherwise go to S8. 
56. If LOW(u)>DFN(FATHER(i;)), then remove all the edges from 
the top of STACK up to and including the edge (FATHER(u), υ). 
(A biconnected component has been found.) 
57. Set 
LOW(FATHER(u)) = min{LOW(i;), LOW(FATHER(y))}, 
υ = FATHER(u) 
and go to S3. 
58. (All biconnected components have been found.) HALT. 
• 
See Fig. 11.16 for an illustration of this algorithm. 
ν — w. 
Figure 11.16. Illustration of Algorithm 
11.15. LOW values are shown in 
parentheses. Biconnected components 
are {e 2, e3, e4, es, e6}, {e,}, and {e 7, 
4 (2) 
5 (2) 

358 
GRAPH ALGORITHMS 
11.8.2 Strong Connectivity 
Recall that a graph is strongly connected if for every two vertices ν and w 
there exists in G a directed path from υ to w and a directed path from w to 
v; further a maximal strongly connected subgraph of a graph G is called a 
strongly connected component of the graph. 
Consider a directed graph G = (V, E). Let GX=(VX, Ex), 
G 2 = 
(V2, E 2 ) , . . . , Gk = (V*, £*) be the strongly connected components of G. 
Let Γ be a DFS forest of G and 7Ί, T2,...,Tk 
be the induced subgraphs of 
Τ on the vertex sets Vx, V2,...,Vk, 
respectively. We know from Theorem 
11.13 that Tx, T2,...,Tk 
are connected. 
Let r,, l < / < & , be the root of T,. Assume that if i<j, then DFS 
terminates at vertex r, earlier than at r y. Then we can see that for each i < ;', 
either r, is to the left of r ; or r, is a descendant of rj in T. Further G„ 
1 < i < £, would consist of those vertices that are descendants of r, but are in 
none of G,, G 2 , . . . , G,_,. 
The first step in the development of the strong connectivity algorithm is 
the determination of a simple criterion that can be used to identify the roots 
as we perform a DFS. The following observations will be useful in deriving 
such a criterion. These observations are all direct consequences of the fact 
that there exist no directed circuits in the graph obtained by contracting all 
the edges in each one of the sets Ex, E2,...,Ek 
(see Section 5.1). 
1. There is no back edge of the type (υ, w) with υ Ε V, and w E Vjy i Φ j . 
In other words all the back edges that leave vertices in Vt also end on 
vertices in Vj. 
2. There is no cross edge of the type (v, w) with υ E Vt, w Ε V, ί Φ], and 
rj is an ancestor of r,. Thus for each cross edge (v, w) one of the 
following two is true: 
a. υ Ε V, and wE V) for some i and / with i Φ j and rj to the left of r (. 
b. For some i, vEVl and wEVr 
Assuming that the vertices of G are named by their DFS numbers, we define 
for each ν in G, 
LOWLINK(y) = min({u} U {w\ there is a cross edge or a back edge 
from a descendant of ν to w, and w is in the same 
strongly connected component as v}). 
Suppose vEVr 
Then it follows from the above definition that LOW-
LINK(u) is the lowest numbered vertex in V, that can be reached from υ by 
a directed path that contains at most one back edge or one cross edge. From 
the observations that we have just made it follows that all the edges of such 
a directed path will necessarily be in G,. As an immediate consequence we 
get 

BICONNECTIVITY AND STRONG CONNECTIVITY 
359 
LOWLINK(r,) = r, 
for all 1 < ι < k . 
(11.24) 
Suppose υ £ Vt and ν ¥= r,. Then there exists a directed path Ρ in G, from 
υ to r,. Such a directed path Ρ should necessarily contain a back edge or a 
cross edge because r, < y, and only cross edges and back edges lead to lower 
numbered vertices. In other words Ρ contains a vertex w < v. So for ν Φ r,, 
we get 
Combining (11.24) and (11.25) we get the following theorem, which 
characterizes the roots of the strongly connected components of a directed 
graph. 
Theorem 11.15. A vertex ν is the root of a strongly connected component of 
a directed graph G if and only if LOWLINK(t;) = v. 
• 
The following steps can be used to compute LOWLINK(u) as we perform 
1. On visiting υ for the first time, set LOWLINK(u) equal to the DFS 
number of v. 
2. If a back edge (u, w) is examined, then set LOWLINK(u) equal to the 
minimum of its current value and the DFS number of w. 
3. If a cross edge (u, w) with w in the same strongly connected compo-
nent as υ is explored, set LOWLINK(u) equal to the minimum of its 
current value and the DFS number of w. 
4. When the search returns to υ after completely scanning a son s of v, 
set LOWLINK(u) to the minimum of its current value and LOW-
LINK(s). 
To implement step 3 we need a test to check whether w is in the same 
strongly connected component as v. For this purpose we use an array 
STACK1 to which vertices of G are added in the order in which they are 
visited during the DFS. STACK1 is also used to determine the vertices 
belonging to a strongly connected component. 
Let ν be the first vertex during DFS for which it is found that LOW-
LINK(u) = v. Then by Theorem 11.15, υ is a root and in fact it is rt. At this 
point the vertices on top of STACK1 up to and including υ are precisely 
those that belong to Gj. Thus G, can easily be identified. These vertices are 
now removed from STACK1. From this point on the algorithm behaves in 
exactly the same way as it would on the graph G', which is obtained by 
removing from G the vertices of G,. 
As regards the implementation of step 3 in LOWLINK computation, let 
υ £ Vt, and let (υ, w) be a cross edge encountered while examining the edges 
LOWLINK(u) < υ . 
(11.25) 
a DFS. 

360 
G R A P H A L G O R I T H M S 
incident on v. Suppose w is not in the same strongly connected component 
as v. Then it would belong to a strongly connected component Gy whose 
root r ; is to the left of r, (observation 2a p. 358). The vertices of such a 
component would already have been identified, and so they would no longer 
be on STACK1. Thus w will be in the same strongly connected component 
as υ if and only w is on STACK1. 
A description of the strong connectivity algorithm now follows. This is 
the same as Algorithm 11.14 with the inclusion of appropriate steps for 
computing LOWLINK values and for identifying the vertices of the different 
strongly connected components. We use in this algorithm an array POINT. 
To begin with POINT(u) = 0 for every vertex v. This indicates that no 
vertex is on the array STACK1. ΡΟΙΝΤ(υ) is set to 1 when υ is added to 
STACK1, and it is set to zero when ν is removed from STACK1. 
Algorithm 11.16. Strong Connectivity 
51. G is the given directed graph. For every vertex υ in G, set 
MARK(u) = 0, FATHER(u) = 0, and POINT(u) = 0. Set i = 1 and 
STACK1 = 0 . 
52. Select any vertex, say vertex r, with MARK(r) = 0. Set 
DFN(r) = i, 
LOWLINK(r) = i, 
MARK(r) = 1. 
Add r to STACK1, set POINT(r) = 1 and υ = r. 
53. If all the edges incident on υ have already been labeled "examined," 
then go to S5. Otherwise select an edge (υ, w) that is not yet labeled 
"examined." Label it "examined" and go to S4. 
54. Do the following and then go to S3: 
1. If MARK(w) = 0, set 
i = i + 1, 
D F N ( H O = i, 
L O W L I N K ( H - ) = i, 
F A T H E R ( H - ) = υ, 
M A R K ( M > ) = 1. 
Add w to STACK1, and set P O I N T ( H O = 1 and ν = w. 
2. If MARK(w) = l, DFN(w)<DFN(u), and POINT(»v) = l, then 
set 
LOWLINK(u) = min{LOWLINK(y), DFN(w)}. 
55. If LOWLINK(u) = DFN(u), then remove all the vertices from the 
top of STACK1 up to and including v. (These vertices form a 
strongly connected component.) Then set P O I N T ( J C ) = 0 for all such 
vertices χ removed from STACK1. 

REDUCTIBILITY OF A PROGRAM GRAPH 
361 
1 I D 
9 (7) 
1 0 ( 9 ) 
Figure 11.17. Illustration of Algorithm 11.16. LOWLINK values are shown in 
parentheses. Strongly connected components are {3, 4, 5}, {6, 7, 8, 9, 10}, {2}, and 
{1, 11, 12, 13}. 
56. If FATHER(u) = 0, go to S7; otherwise set 
1. LOWLINK(FATHER(u)) 
= min {LOWLINK( FATHER( v)), LOWLINK(i;)}, 
2. υ = FATHER^), 
and then go to S3. 
57. If for every vertex x, MARK(x) = 1, then go to S8; otherwise set 
i = i + 1 and go to S2. 
58. (All 
strongly 
connected 
components 
have 
been 
identified.) 
HALT. 
• 
See Fig. 11.17 for an illustration of this algorithm. 
11.9 
REDUCIBILITY OF A PROGRAM GRAPH 
A program graph is a directed graph G with a distinguished vertex s such 
that there is a directed path from s to every other vertex of G. In other 
words every vertex in G is reachable from s. The vertex s is called the start 
vertex of G. We assume that there are no parallel edges in a program graph. 
This assumption will involve no loss of generality as far as our discussions in 
this section are concerned. 
The flow of control in a computer program can be modeled by a program 
graph in which each vertex represents a block of instructions that can be 
executed sequentially. Such a representation of computer programs has 

362 
GRAPH ALGORITHMS 
proved very useful in the study of several questions relating to what is 
known as the code optimization problem. 
For many of the code optimization methods to work, the program graph 
must have a special property called reducibility. See [11.87] through [11.95]. 
Reducibility of a program graph G is defined in terms of the following 
two transformations on G: 
5,: 
Delete self-loops (u, υ) in G. 
S2: 
If (v, w) is the only edge incident into w, and w Φ s, delete vertex w. 
For every edge (w, x) in G add a new edge (v, x) if (v, x) is not 
already in G. (This transformation is called collapsing vertex w into 
vertex v.) 
For example collapsing vertex 5 into vertex 4 in the program graph of 
Fig. 11.18a results in the graph shown in Fig. 11.186. 
A program graph is reducible if it can be transformed into a graph 
consisting only of vertex s by repeated applications of the transformations S, 
and S2. 
For example, the graph in Fig. 11.18a is reducible. It can be verified that 
this graph can be reduced by collapsing the vertices in the order 5, 8, 4, 3, 
10, 9, 7, 6, 2. 
Cocke [11.88] and Allen [11.93] were the original formulators of the 
notion of reducibility, and their definition is in terms of a technique called 
interval analysis. The definition given above is due to Hecht and Ullman 
[11.96], and it is equivalent to that of Cocke and Allen. 
If a graph G is reducible, then it can be shown [11.96] that any graph G' 
obtained from G by one or more applications of the transformations 5, and 
S2 is also reducible. Thus the order of applying transformations does not 
matter in a test for reducibility. Further, some interesting classes of pro-
grams such as "go-to-less" programs give rise to graphs that are necessarily 
reducible [11.96], and most programs may be modeled by a reducible graph 
using a process of "node splitting" [11.97]. 
Suppose we wish to test the reducibility of a graph G. This may be done 
by first deleting self-loops using transformation 5, and then counting the 
number of edges incident into each vertex. Next we may find a vertex w with 
only one edge (v, w) incident into it and apply transformation S2, collapsing 
w into v. We may then repeat this process until.we reduce the graph entirely 
or discover that it is not reducible. Clearly each application of S2 requires 
0(n) time, where η is the number of vertices in G and reduces the number 
of vertices by 1. Thus the complexity of this algorithm is 0(n
2). 
Hopcroft 
and Ullman [11.98] have improved this to 0(m log m), where m is the 
number of edges in G. Tarjan [11.99] and [11.100] has subsequently given 
an algorithm that compares favorably with that of Hopcroft and Ullman. 
Hecht and Ullman [11.96] and [11.101] have given several useful structur-

REDUCIBIUTY OF A PROGRAM GRAPH 
363 
6 
7 
9 
1 0 
(/>) 
Figure 11.18. (a) A reducible program graph G. HIGHPT1 values are given in 
parentheses, (b) Graph obtained after collapsing in G vertex 5 into vertex 4. 
al characterizations of program graphs. One of these is given in the 
following Theorem. 
Theorem 11.16. Let G be a program graph with start vertex s. G is 
reducible if and only if there do not exist distinct vertices ν Φ s and w Φ s, 

364 
GRAPH ALGORITHMS 
OS 
Figure 11.19. A basic nonreducible graph. 
directed paths 
from s to ν and P 2 from s to w, and a directed circuit C 
containing υ and w, such that C has no edges and only one vertex in 
common with each of P, and P 2 (see Fig. 11.19). 
• 
Proof of Theorem 11.16 may be found in [11.96] and [11.102]. 
We now proceed to discuss Tarjan's algorithm for testing the reducibility 
of a program graph. This algorithm uses DFS and is based on a characteriza-
tion of reducible program graphs that we shall prove using Theorem 11.16. 
Our discussion here is based on [11.99]. 
Let G be a program graph with start vertex s. Let Γ be a DFS tree of G 
with s as the root. Henceforth we refer to vertices by their depth-first 
numbers. 
Theorem 11.17. G is reducible if and only if G contains no directed path Ρ 
from s to some vertex ν such that υ is a proper ancestor in Τ of some other 
vertex on P. 
Proof. Suppose G is not reducible. Then there exist vertices υ and w, 
directed paths P, and P 2, and circuit C that satisfy the condition in Theorem 
11.16. Assume that ν < w. Let C, be the part of C from υ to w. Then C, 
contains some common ancestor « of υ and w. The directed path consisting 
of P 2 followed by the part of C from w to u satisfies the condition in the 
theorem. 
Conversely, suppose there exists a directed path Ρ that satisfies the 
condition in the theorem. Let then υ be the first vertex on P, which is a 
proper ancestor of some earlier vertex on P. Suppose w is the first vertex on 
P, which is a descendant of v. Let P, be the part of Τ from s to v, and let P 2 
be the part of Ρ from s to w. Also let C be the directed circuit consisting of 
the part of Ρ from w to ν followed by the path of tree edges from υ to w. 
Then we can see that υ, w, Pt, P 2, and C satisfy the condition in Theorem 
11.16. So G is not reducible. 
• 

REDUCTIBILITY OF A PROGRAM GRAPH 
365 
For any vertex v, let HIGHPTl(u) be the highest numbered proper 
ancestor of ν such that there is a directed path Ρ from ν to HIGHPTl(i>) 
and Ρ includes no proper ancestors of υ except HIGHPTi(u). We define 
HIGHPTl(u) = 0 if there is no directed path from υ to a proper ancestor of 
υ. As an example, in Fig. 11.18a we have indicated in parentheses the 
HIGHPT1 values of the corresponding vertices. 
Note that in HIGHPTl(u) calculation we may ignore forward edges since 
if Ρ is a directed path from ν to w and Ρ contains no ancestors of ν except ν 
and w, we may substitute for each forward edge in Ρ a path of tree edges or 
a part of it and still have a directed path from υ to w that contains no 
ancestors of υ except ν and w. 
Tarjan's algorithm is based on the following characterization of program 
graphs. 
Theorem 11.18. G is reducible if and only if there is no vertex υ with an 
edge (M, V) incident into υ such that w<HIGHPTl(u), where w is the 
highest numbered common ancestor of w and v. 
Proof. Suppose G is not reducible. Then by Theorem 11.17 there is a 
directed path Ρ from s to υ with υ a proper ancestor of some other vertex on 
P. Choose Ρ as short as possible. Let »v be the first vertex on Ρ that is a 
descendant of v. Then all the vertices except υ that follow w on Ρ are 
descendants of υ in T. In other words the part of Ρ from w to υ includes no 
proper 
ancestors 
of 
w except 
v. 
So HIGHPTl(>v) 5: v. 
Thus 
w, 
H I G H P T I ( H ' ) , and the edge of Ρ incident into w satisfy the condition in the 
theorem. 
Conversely, suppose the condition in the theorem holds. Then the edge 
(u, v) is not a back edge because in such a case the highest numbered 
common ancestor w of u and υ is equal to v, and so w = υ > HIGHPTl(u). 
Thus («, v) is either a forward edge or a cross edge. Let P, be a directed 
path from υ to HIGHPTl(u), which passes through no proper ancestors of ν 
except HIGHPTl(u). Then the directed path consisting of the tree edges 
from s to u followed by the edge (u, v) followed by P, satisfies the condition 
in Theorem 11.17. So G is not reducible. 
• 
Now it should be clear that testing reducibility of a graph G using 
Theorem 11.18 involves the following main steps: 
1. Perform a DFS of G with s as the root. 
2. Calculate HIGHPTl(u) for each vertex υ in G. 
3. For cross edges check the condition in Theorem 11.18 during the 
HIGHPT1 calculation. 
4. For forward edges check the condition in Theorem 11.18 after the 
HIGHPT1 calculation. 

366 
GRAPH ALGORITHMS 
ν 
ZOO 
< 
'6 2 
Figure 11.20 
u 
Note that, as we observed earlier, forward edges may be ignored during the 
HIGHPT1 calculation. Further as we observed in the proof of Theorem 
11.18, back edges need not be tested for the condition in Theorem 11.18. 
To calculate HIGHPT1 values, we first order the back edges (u, v) by the 
number of v. Then we process the back edges in order, from highest to 
lowest v. Initially all vertices are unlabeled. To process the back edge (u, v), 
we proceed up the tree path from u to v, labeling each currently unlabeled 
vertex with v. (We do not label υ itself.) If a vertex w gets labeled, we 
examine all cross edges incident into w. If (z, w) is such a cross edge (see 
Fig. 11.20), we proceed up the tree path from ζ to v, labeling each 
unlabeled vertex with v. If ζ is not a descendant of v, then G is not reducible 
by Theorem 11.18, and the calculation stops. We continue labeling until we 
run out of cross edges incident into just labeled vertices; then we process the 
next back edge. When all the back edges are processed, the labels give the 
HIGHPT1 values of the vertices. Each unlabeled vertex has HIGHPT1 
equal to zero. 
We now describe Tarjan's algorithm for testing reducibility. In this 
algorithm we use η queues, called buckets, one for each vertex. The bucket 
BUCKET(w) corresponding to vertex w contains the list of back edges 
(w, w) incident into vertex w. While processing back edge (w, w), we need to 
keep track of certain vertices from which u can be reached by directed 
paths. The set CHECK is used for this purpose. 
Algorithm 11.17. Program Graph Reducibility (Tarjan) 
SI. 
Perform a DFS of the given η-vertex program graph G. Denote 
vertices by their DFS numbers. Order the back edges (M, V) of G by 
the number of v. 

REDUCIBILITY OF A PROGRAM GRAPH 
367 
52. 
For i = l, 2 , . . . , , i set 
HIGHPTl(i) = 0, 
BUCKET(i) = the empty list. 
53. 
Add each back edge (u, w) to 
B U C K E T ( H > ) . 
54. 
Set w = η - 1. 
55. 
Test if BUCKET(w) is empty. If yes, go to S6; otherwise go to S7. 
56. 
Set w = w - 1. If w < 1, go to S16; otherwise go to S5. 
57. 
(Processing of a new back edge begins.) Delete a back edge (x, w) 
from BUCKET(w) and set CHECK = {x}. 
58. 
Test if CHECK is empty. If yes (processing of a back edge is over), 
go to S5; otherwise go to S9. 
59. 
Delete u from CHECK. 
510. Test if Μ is a descendant of w. If yes, go to Sll; otherwise go to S17. 
511. Test if u = w. If yes, go to S8; otherwise go to S12. 
512. Test if HIGHPTl(u) = 0. If yes, go to S13; otherwise go to S15. 
513. Set HIGHPTl(u) = w. 
514. For each cross edge (u, w) add ν to CHECK. 
515. Set w = F A T H E R ( w ) . 
G O to Sll. 
516. If Μ £ HIGHPTl(u) for each forward edge (u, v) (the graph is 
reducible), then HALT. Otherwise go to S17. 
517. HALT. The graph is not reducible. 
• 
Note that S10 in Algorithm 11.17 requires that we be able to determine 
whether a vertex w is a descendant of another vertex u. Let ND(u) be the 
number of descendants of vertex u in T. Then we can show that w is a 
descendant of u if and only if u s w < u + ND(w). (See Exercise 11.8). We 
can calculate ND(u) during the DFS in a straightforward fashion. 
The efficiency of Algorithm 11.17 depends crucially on the efficiency of 
the HIGHPT1 calculation. To make the HIGHPT1 calculation efficient, in 
Algorithm 11.17 we need to avoid examining vertices that have already been 
labeled. Tarjan suggests a procedure to achieve this. The following observa-
tion forms the basis of this procedure: 
Suppose at S12 we are examining a vertex u for labeling. At this stage let 
u' be the highest unlabeled proper ancestor of u. This means that all the 
proper ancestors of u except Μ', which lie between u' and u in T, have 
already been labeled. Thus u' is the next vertex to be examined. Further-
more when u is labeled, then all the vertices for which u is the highest 
unlabeled proper ancestor will have u' as their highest unlabeled proper 
ancestor. 
To implement the method that follows from this observation, we shall use 
sets numbered 1 to n. A vertex w Φ1 will be in the set numbered v, that is, 
SET(y), if υ is the highest numbered unlabeled proper ancestor of w. Since 

368 
GRAPH ALGORITHMS 
vertex 1 never gets labeled, each vertex is always in a set. Initially a vertex is 
in the set whose number is its father in T. Thus initially add i to 
SET(FATHER(/)) for i = 2, 3 , . . . , n. 
To carry out S15, we find the number u' of the set containing u and let 
that be the new u. Further when u becomes labeled, we shall combine the 
sets numbered u and u' to form a new set numbered «'. Thus u' becomes 
the highest numbered unlabeled proper ancestor of all the vertices in the old 
SET(u). 
It can now be seen that replacing S12 through S15 in Algorithm 11.17 by 
the following sequence of steps will implement the method described. Of 
course, SETs are initialized as explained earlier. 
S12'. Set u' = the number of the set containing u. 
S13'. Test if HIGHPTl(u) = 0. If yes, go to S14'; otherwise go to S16'. 
S14\ Set 
1. HIGHPTl(u) = w; and 
2. SET(u') = SET(u)USET(u'). 
SIS'. For each cross edge (v, u) add ν to CHECK. 
S16'. Set u = u'. Go to Sll. 
It can be verified that the modified HIGHPT1 calculations require 0(n) set 
unions, 0(m + n) executions of step S12', and 0{m + n) time exclusive of 
set operations. If we use the algorithm described in Fischer [11.103] and 
Hopcroft and Ullman [11.104] for performing disjoint set unions and for 
performing S12', then it follows from the analysis given in Tarjan [11.105] 
that the reducibility algorithm has complexity 0(ma(m, 
n)), where a(m, n) 
is a very slowly growing function that is related to a functional inverse of 
Ackermann's function A(p, q), and it is defined as follows: 
a(m, n) - min{z s l| A(z, 4[m/n]) > log 2 n). 
The definition of Ackermann's function is 
A(p, q) = 
2q, 
0, 
w, 
{A(p-\,A{p,q 
1)), 
p = 0; 
o = 0and p ^ l 
ρ > 1 and q = 1 : 
ρ > 1 and q ^ 2 , 
(11.26) 
Note that Ackermann's function is a very rapidly growing function. It is easy 
to see that A(3,4) is a very large number, and it can be shown that 
a(m, η) ^ 3 if m Φ 0 and log 2 η < A(3,4). The algorithm for set operations 
mentioned is also described in Aho, Hopcroft, and Ullman [11.106] and 
Horowitz and Sahni [11.107]. 
Algorithm 11.17 is nonconstructive, that is, it does not give us the order 

REDUCIBILITY OF A PROGRAM GRAPH 
369 
in which vertices have to be collapsed to reduce a reducible graph. How-
ever, as we shall see now, this information can be easily obtained as this 
algorithm progresses. 
During DFS let us assign to the vertices numbers called SNUMBERs 
from η to 1 in the order in which scanning at a vertex is completed. In fact 
this is the same as the order in which the corresponding entries of the array 
SCAN in Algorithm 11.14 are set to 1. The following can be easily verified: 
1. If (v, 
w) is a tree edge, then 
S N U M B E R ( U ) < S N U M B E R ( H < ) . 
2. If ( v , w) is a cross edge, then SNUMBER(u) < SNUMBERt». 
3. If ( v , w) is a back edge, then SNUMBER(iv) > SNUMBER(iv). 
4. If ( v , w) is a forward edge, then SNUMBER(tv) < S N U M B E R i » . 
As an example, in Fig. 11.21 we have shown in parentheses the SNUM-
BERs of the corresponding vertices of the graph in Fig. 11.18a. 
Suppose we apply the reducibility algorithm, and each time we label a 
vertex υ let us associate with it a pair (HIGHPTl(u), SNUMBER(tv)). 
When the algorithm is finished, let us order the vertices so that a vertex 
labeled (xu yx) appears before a vertex labeled (x2, y2) if and only if 
xx> 
x2 or xx = x2 and yx<y2. 
This order of vertices is called 
reduction 
order. 
Note that an unlabeled vertex ν is associated with the pair (0, 
SNUMBER(i>)). 
Figure 11.21. Graph of Fig. 11.18a 
with SNUMBER values in paren-
(10)6 
7 ( 9 ) 
9 ( 7 ) 
10 (β) 
theses. 

370 
GRAPH ALGORITHMS 
Suppose va, vb, vc,... 
is a reduction order for a reducible program graph 
G. Let Γ be a DFS tree of G with vertex s as the root. Using Theorem 11.18 
and the properties of SNUMBERs outlined earlier, it is easy to show that 
the tree edge (M, va) is the only edge incident into va. Suppose we collapse 
va into u and let G' be the resulting reducible graph. Also let 7" be the tree 
obtained from Τ by contracting the edge (u, va). Then clearly 7" is a DFS 
tree of G'. Further: 
1. A cross edge of G corresponds to nothing or to a cross edge or to a 
forward edge of G'. 
2. A forward edge of G corresponds either to nothing or to a forward 
edge of G'. 
3. A back edge of G corresponds either to nothing or to a back edge of 
G'. 
It can now be verified that the relative HIGHPT1 values of the vertices in 
G' will be the same as those in G. This is also true for the SNUMBERs. 
Thus vb, vc,... 
will be a reduction order for G'. Repeating these arguments, 
we get the following theorem. 
Theorem 11.19. If a program graph G is reducible, then we may collapse 
the vertices of G in the reduction order using the transformation S 2 
(interspersed with applications of 5,). 
• 
For example, it can be verified from HIGHPT1 values given in Fig. 11.18a 
and the SNUMBER values given in Fig. 11.21 that the sequence 4, 5, 3, 8, 
10, 9, 7, 6, 2 is a reduction order for the graph in Fig. 11.18a. 
Closely related to the problem of testing reducibility, is the problem of 
testing whether a graph is series-parallel (see Exercise 7.12 for the defini-
tion of series-parallel graphs). For a characterization of series-parallel 
graphs using DFS and a recognition algorithm for series-parallel graphs see 
Shinoda, Chen, Yasuda, Kajitani, and Mayeda [11.108], and Valdes, Tarjan, 
and Lawler [11.109]. 
11.10 
Sf-NUMBERING OF A GRAPH 
In this section we present yet another application of DFS—computing an 
sf-numbering of a graph. This numbering is necessary for the planarity 
testing algorithm to be discussed in the following section. 
Given an η-vertex biconnected graph G = (V, E) and an edge (s, t) of G, 
a numbering of the vertices of G is called an si-numbering of G if the 
following conditions are satisfied, where g(v) denotes the corresponding 
st-number of vertex v: 

sf-NUMBERING OF A GRAPH 
371 
1. For all υ 6 V, 1 < g(v) =£ n, and for u Φ v, g(u) Φ g(v). 
2. g{s) = l. 
3. *(*) = «· 
4. For υ £ V— {s, t} there are adjacent vertices u and w such that 
g(u)<g(v)<g(w). 
A graph G and an si-numbering of G are shown in fig. 11.22. Lempel, 
Even, and Cederbaum [11.110] have shown that for every biconnected 
graph and every edge (s, t) there exists an sr-numbering. The if-numbering 
algorithm to be discussed next is due to Even and Tarjan [11.111]. 
Given a biconnected graph G and an edge (s, i)» the sf-numbering 
algorithm of Even and Tarjan first performs a DFS of G with r as the start 
(root) vertex and (f, s) as the first edge. In other words DFN(r) = 1, and 
DFN(s) = 2. Recall that DFN(u) denotes the DFS number of vertex v. 
During the DFS, the algorithm also computes, for each vertex υ, its 
depth-first number, FATHER(u) in the DFS tree, the low point LOW(u), 
and identifies the tree edges and back edges. Next the vertices s and t and 
the edge (s, t) are marked "old." All the other vertices and edges are 
marked "new." An algorithm, called the path finding algorithm, is then 
invoked repeatedly (in an order to be described later) until all the vertices 
and edges are marked "old." 
The path finding algorithm when applied from an "old" vertex υ finds a 
directed path into υ or from υ and proceeds as follows. 
Figure 11.22. sr-graph G. 

372 
GRAPH ALGORITHMS 
Path Finding Algorithm (Applied from Vertex v) 
51. Pick a "new" edge incident on v. 
i. If (v, w) is a back edge ( D F N ( w ) < D F N ( u ) ) , then mark e "old" 
and HALT. 
Note: The path consists of the single edge e. 
ii. If (v, w) is a tree edge ( D F N ( w ) > D F N ( i ; ) ) , then do the fol-
lowing: 
Starting from υ traverse the directed path that defined L O W ^ ) 
and mark all edges and vertices on this path "old." HALT. 
Note: The path here starts with the tree edge (v, t) and ends in 
the vertex u such that D F N ( M ) = LOW(»v). This path has exactly 
one back edge. 
iii. If (w, v) is a back edge ( D F N ( w ) > DFN(u)) do the following: 
Starting from ν traverse the edge (w, v) backward and continue 
backward along tree edges until an "old" vertex is encountered. 
Mark all the edges and vertices on this path "old" and HALT. 
Note: The path in this case is directed into v. 
52. If all the edges incident on υ are "old" HALT. 
Note: The path produced is empty. 
The following facts hold true after each application of the path finding 
algorithm. Note that the algorithm is always applied from an "old" vertex. 
1. All ancestors of an "old" vertex are old too. This is true before the 
first application of the algorithm since t is the only ancestor of s and it 
is "old." This property remains true after any one of the applicable 
steps of the algorithm. 
2. When the algorithm is applied from an "old" vertex v, it either 
produces an empty path or it produces a path that starts at v, passes 
through "new" vertices and edges and ends at another "old" vertex. 
This is obvious when (v, w) or (w, v) is a back edge [cases (i) and (iii) 
of Sl]. This is also true when (υ, w) is a tree edge because in the 
biconnected graph G the vertex u defining LOW(w) is an ancestor of υ 
and therefore u is "old." 
Even and Tarjan's fi-numbering algorithm presented next uses a stack 
STACK that initially contains only t and s with s on top of t. In this 
description we do not explicitly include the details of DFS. We also assume 
that to start with t, s and the edge (r, s) are "old." 
Algorithm 11.18. sr-Numbering (Even and Tarjan) 
Sl. Set i = 1. 

PLANARITY TESTING 
373 
52. Let ν be the top vertex on STACK. Remove ν from STACK. If 
υ = r, then set g(v) = i and HALT. 
53. (υΦ t). Apply the path finding algorithm from v. If the path is 
empty, then set g(v) = i, i = / + 1 and go to S2. 
54. (The path is not empty.) Let the path be P: v, 
u2,..., 
uk, 
w. 
Place uk, u
k
u
,
, 
υ on STACK in this order (note that υ comes 
on top of STACK) and go to S2. 
• 
Theorem 11.20. Algorithm 11.18 computes an sr-numbering for every bicon-
nected graph G = (V, E). 
Proof. The following facts about the algorithm are easy to verify: 
1. No vertex appears in more than one place on STACK at any time. 
2. Once a vertex ν is placed on STACK, no vertex under ν receives a 
number until υ does. 
3. A vertex is permanently removed from STACK only after all edges 
incident on υ become "old." 
We now show that each vertex υ is placed on STACK before / is 
removed. Clearly this is true for υ = s because initially t and s are placed on 
STACK with s on top of t. 
Consider any vertex ν Φ s, t. Since G is biconnected, there exists a 
directed path Ρ of tree edges from s to v. Let P: s, ux, u2,... 
,uk = v. Let m 
be the first index such that um is not placed on STACK. Since um_x is placed 
on STACK, t can be removed only after « m_, is removed (fact 2), and 
um_l 
is removed only after all edges incident on « m_, are "old" (fact 3). So um 
must be placed on STACK before t is removed. 
We need to show that the numbers assigned to the vertices are indeed 
si-numbers. Since each vertex is placed on STACK and eventually removed, 
every vertex ν gets a number g(v). 
Clearly all numbers assigned are distinct. Also g(s) = 1 and g(r) = η 
because s is the first vertex and t is the last vertex to be removed. Every time 
a vertex ν Φ s, t is placed on STACK, there is an adjacent vertex placed 
above ν and an adjacent vertex placed below v. By fact 2 the one above gets 
a lower number and the one below gets a higher number. 
• 
See Erbert [11.112] for another si-numbering algorithm. 
11.11 
PLANARITY TESTING 
In this section we discuss the problem of testing the planarity of a graph. In 
recent years this and related problems on planar graphs have assumed great 

374 
GRAPH ALGORITHMS 
importance in view of their practical applications. See, for example, Wimer, 
Koren, and Cederbaum [11.113]. 
The most successful approach so far for testing the planarity of a graph 
has been attempts to construct a representation of a planar embedding of 
the graph. If such a representation can be obtained, then the graph is 
planar; if not, the graph is nonplanar. All the planarity testing algorithms 
based on this idea can be grouped into two categories: path addition 
algorithms and vertex addition algorithms. 
Path addition algorithms first find a cycle in the graph. When this cycle is 
removed, the remaining edges of the graph would form several connected 
components. Each of these components is then embedded in the plane along 
with the original cycle and the embeddings of the component are combined, 
if possible, to give an embedding of the entire graph. 
In [11.114] Hopcroft and Tarjan proposed a linear time algorithm for 
testing planarity of a graph. This algorithm finds a cycle in the graph using 
depth-first search. This cycle is then embedded in the plane, thereby 
dividing the plane into two regions—one inside the cycle and the other 
outside the cycle. The connected components of the graph, obtained after 
removing the cycle, are then successively embedded either in the inside 
region or in the outside region. During the embedding of any component, if 
necessary, all the components that are already embedded in the inside 
region may be moved to the outside region, and all those already embedded 
in the outside region may be moved to the inside region. All these 
rearrangements are done in an efficient manner without actually drawing the 
embedding, so that the algorithm has 0{n) time bound. Expositions of 
Hopcroft and Tarjan's algorithm may be found in Melhorn [11.14], Rein-
gold, Nievergelt, and Deo [11.115], and Even [11.116]. Earlier, De-
moucron, Malgrange, and Pertuiset [11.117] had given an algorithm similar 
to Hopcroft and Tarjan's that avoids the rearrangement of already embed-
ded components by choosing the components, for embedding at each stage, 
in an appropriate manner. Rubin [11.118] developed an 0(n
2) 
space and 
0(n
2) 
time implementation of this algorithm and showed that, for all 
practical purposes, his implementation behaves as an O(n) algorithm. 
Vertex addition algorithms use an alternate approach to embed a graph in 
the plane. These algorithms start with a single embedded vertex and add all 
the edges incident on that vertex. The other end vertices of these edges are 
not embedded. They then embed an unembedded vertex and add all edges 
incident on it in the same way. This process of embedding is continued until 
the entire graph is constructed. For these algorithms to work correctly, the 
vertices must be embedded in a special order. 
In [11.110] Lempel, Even, and Cederbaum proposed a vertex addition 
algorithm. In this algorithm, at any time during the embedding process, the 
subgraph embedded up to that time is represented by certain formulas that 
are then manipulated, by applying certain transformations, to check whether 
the next vertex can be embedded. The best implementation of Lempel, 
Even, and Cederbaum's algorithm was reported by Booth and Lueker 

PLANARITY TESTING 
375 
[11.119]. They developed a data structure called a Ρβ-tree to represent the 
permutations of a set in which elements of certain subsets of the given set 
are required to occur consecutively, and presented efficient algorithms to 
manipulate the Ρβ-tree. Using PQ-trees, Booth and Lueker developed an 
0(n) time implementation of Lempel, Even, and Cederbaum's algorithm. 
We now proceed to discuss the essential features of Lempel, Even, and 
Cederbaum's algorithm to test the planarity of a graph. Hereafter we refer 
to this algorithm as the LEC algorithm. 
Let G = (V, E) be a simple biconnected graph with η = |V| vertices and 
m = | £ | edges. The LEC algorithm first renumbers the vertices of G as 1, 
2 , . . . , η using an si-numbering. The vertices of G are thereafter referred to 
by their si-numbers, and they are processed in that order for embedding. 
The si-numbering is essential for the algorithm to work correctly. The graph 
G, with its vertices labeled according to an si-numbering, is called an 
st-graph. Clearly the edges (1,2), (η - 1, n), and (1, n) are present in any 
si-graph G. Furthermore, if each edge is oriented from its lower numbered 
vertex to its higher numbered vertex, then G may be viewed as a directed 
graph. The following observations follow easily from the definition of 
si-numbering. 
Observation 1. In G the in-degree of vertex 1 is zero, the out-degree of 
vertex η is zero, and for every other vertex D , 2 s p < N - 1 , the in-degree 
and out-degree are nonzero. 
Observation 2. For any vertex v, 2 S D < « , there exists a path in G from 
vertex 1 to υ such that all the internal vertices on the path are less than v. 
These observations may be verified for the si-graph G shown in Fig. 
11.22. 
For any si-graph G, let Gk, 1 ^ k s n, denote the subgraph of G induced 
by the vertex set Vk = { 1 , 2 , . . . , k}. Thus Gk consists of all those edges of G 
whose end vertices are both in Vk. Now we define the graph Bk as follows: 
Gk is a subgraph of Bk. In addition to Gk, Bk contains all the edges of G that 
emanate from vertices of Vk and enter, in G, vertices of V- Vk. These edges 
are called virtual edges and the vertices they enter in V- Vk are called virtual 
vertices. These vertices are labeled as their counterparts in G but are kept 
separate. Thus, in Bk there may be several virtual vertices with the same 
label, each with exactly one entering edge. For example, Fig. 11.23 shows 
the graph B9 of the si-graph shown in Fig. 11.22. 
If the si-graph G is planar, then there exists a planar embedding G of G. 
Note that G contains a planar embedding Gk of Gk, 
l < A : < n . Using 
observation 1, the following lemma can be proved. 
Lemma 11.7. If Gk is a planar embedding of Gk contained in a planar 
embedding G of an si-graph G, then all the edges and vertices of G - Gk are 
drawn on one region of Gk. 
• 

376 
GRAPH ALGORITHMS 
Figure 11.23. Graph B9. 
Thus we can assume, without loss of generality, that if G is a planar 
graph, then there exists a planar embedding of Bk in which all the virtual 
edges are drawn in the outside region. Since the edge (1, n) is a virtual edge 
in every Bk, I s k^n- 
1, it follows that vertex 1 is on the outside region of 
every Gk. Thus we can draw the graph Bk in the following form. Vertex 1 is 
drawn at the bottom level. All the virtual vertices appear at the highest level 
on the horizontal line. The remaining vertices of Gk are drawn in such a way 
that vertices with higher labels are drawn higher. Such a realization of Bk is 
called a bush form of Bk. For example, a bush form of the graph B9 is shown 
in Fig. 11.24. Since Bk and its bush form are isomorphic, hereafter we shall 
refer to the bush form of Bk also by Bk. 
Note that in the bush form Bk, the virtual vertices are labeled k + 1 or 
higher, and the si-numbering ensures that there exists at least one virtual 
vertex labeled k + 1. Lempel, Even, and Cederbaum proved that if G is 
planar, then there exists a bush form of Bk in which all the virtual vertices 
with labels k + 1 appear next to each other on the horizontal line. Let B'k be 
such a bush form isomorphic to Bk. For example, the bush form B'9 
corresponding to B9 is shown in Fig. 11.25. If for a given Bk a corresponding 
B'k exists, then the bush form Bk+1 can be constructed from B'k as follows. 
Merge all the virtual vertices labeled k + 1 into one vertex and pull it down 
from the horizontal line. Add all the edges of G that emanate from vertex 
k + 1 as virtual edges. Now vertex A: + 1 is considered embedded. Thus, if 
for each Bk, 1 < λ < η - 2 , the corresponding B'k exists, then we can 
construct the bush forms B2, Bi,...,Bn_l 
starting with Bx. Note that 

PLANARITY TESTING 
377 
© © © © © © © 
Figure 11.24. Bush form B9 
Figure 11.25. Bush form B9. 

378 
GRAPH ALGORITHMS 
B'n_l = B n_, and applying this procedure to B„_l will give a planar embed-
ding of G. 
Algorithm 11.19. Planarity Testing (Lempel, Even and Cederbaum) 
50. Given a graph G, test if G is planar. 
51. Find an sf-numbering of G; renumber the vertices according to the 
s/-numbering and obtain the si-graph (bush form B, consists of the 
vertex 1 and all the edges in G incident out of vertex 1 as virtual 
edges). 
52. Set k = l. 
53. (B'k is a bush form isomorphic to bush form Bk in which all the virtual 
vertices labeled k + 1 appear consecutively.) If B'k does not exist, 
HALT (G is not planar). 
54. Construct Bk+l 
from B'k (Bk+i 
is constructed from B'k by merging all 
the virtual vertices labeled k + 1 into a single vertex k + 1 and adding 
all the edges in G incident out of vertex k + 1 as virtual edges). 
55. If k = η - 1, HALT. (The graph is planar.) Otherwise set k = k + 1 
and go to S3. 
• 
The crucial step in the LEC algorithm is the construction of B'k from Bk 
for every l < t < n - 2 . Such bush forms would exist if the given graph G is 
planar. We now state two lemmas that form the basis of an algorithm for 
constructing B'k from Bk. The term subbush used in the following discussions 
is defined first. 
Let υ be a cut vertex of a bush form Bk. If V denotes the vertex set of a 
component of Bk- 
v, then the subgraph of Bk induced by the vertex set 
V U {v} is called a subbush of Bk relative to v. 
Lemma 11.8. Let υ be a cut vertex of Bk. If υ > 1, then exactly one subbush 
of Bk, relative to υ, contains vertices lower than v. 
• 
Lemma 11.9. Let Η be a maximal biconnected component of Bk and 
>Ί > >2> · · · ' yq be the vertices of Η that are also end vertices of the edges of 
Bk - H. In every bush form isomorphic to Bk, ylf 
y2,..., 
y, are on the 
outside window (the circuit forming the boundary of the infinite region) of 
Η and in the same order, except that the orientation may be reversed. 
• 
The proof of the lemmas use observation 2 and Lemma 11.7, and may be 
found in [11.116]. 
From Lemma 11.9 it follows that a bush form isomorphic to Bk can be 
obtained by flipping a subbush. Lemma 11.8 implies that a cut vertex υ of Bk 
is the lowest vertex in each of the subbushes, except the one that contains 
vertex 1. These subbushes have the same structure as a bush form, except 

FURTHER READING 
379 
that their lowest vertex is υ rather than 1. If there are ρ such subbushes of Bk 
relative to v, then these subbushes can be permuted around ν in any of the 
ρ! permutations to obtain a bush form isomorphic to Bk. Also each of these 
subbushes can be flipped over. These transformations, namely, permutation 
and flipping, maintain the bush form. In fact Lempel, Even, and Cederbaum 
proved the following (See Even [11.116]). 
Theorem 11.21. If ΒI and B
2
k are bush forms of the same Bk, then there 
exists a sequence of permutations and flippings that transform B
l
k into B\ 
such that in B
2
k and B
3
k the virtual vertices appear in the same order. 
• 
The above theorem implies that each bush form Bk can be transformed 
into a bush form B'k in which all the virtual vertices labeled k + 1 appear 
next to each other. For example, the bush form Bg shown in Fig. 11.25 is 
obtained from the bush form B9 of Fig. 11.24 by flipping the subbush 
containing the set of vertices {1, 3, 4, 9} and permuting the subbushes 
around the cut-vertex 1. Now the problem is to find, from among all 
possible permutations and flippings, an appropriate sequence that will 
transform Bk into B'k. Moreover, one would like to do these transformations 
efficiently, without drawing the actual bush forms. As we stated earlier, 
Booth and Lueker showed that these transformations can be implemented 
efficiently using Ρβ-trees. PQ-trees can be used to represent the informa-
tion pertaining to bush forms as well as to obtain the bush form Bk+X 
from 
For more recent results on planar graphs and the planarity testing 
problem see Nishizeki and Chiba [11.120] and de Fraysseix and Rosenstiehl 
[11.121]. The planar layout problem and some related results are discussed 
in Otten and Van Wijk [11.122], Rosenstiehl and Tarjan [11.123], Chiba, 
Nishizeki, Abe and Ozawa [11.124], and Jayakumar, Thulasiraman, and 
Swamy [11.125]. For algorithms for the maximal planarization problem see 
Chiba, Nishioka, and Shirakawa [11.126], Ozawa and Takahashi [11.127], 
Jayakumar, Thulasiraman, and Swamy [11.128], and Marek-Sadowska 
[11.129]. Eades and Tamassia [11.130] have given an extensive annotated 
bibliography of algorithms for planar drawings with various properties and 
related applications. 
11.12 
FURTHER READING 
In the past two decades a large number of graph algorithms have been 
reported in the literature and certain new research areas (motivated by 
recent technological developments) have emerged. References to some of 
these may be found in Section 12.12 of this book. See Lengauer [11.131] for 
an extensive coverage of applications of combinatorial algorithms in integ-
rated circuit layout design. 

380 
GRAPH ALGORITHMS 
11.13 
EXERCISES 
11.1 
A transitive reduction of a directed graph G = (V, E) is defined to be 
any graph G' = (V, £') with as few edges as possible such that the 
transitive closure of G' is equal to the transitive closure of G. Design 
an algorithm to find a transitive reduction of a directed graph. How 
is this algorithm related to the transitive closure algorithm? (Aho, 
Garey, and Ullman [11.132].) 
11.2 
Prove the validity of the following modification of Dijkstra's al-
gorithm for finding the shortest paths between a specified vertex s 
and all other vertices in a weighted directed graph G, which has no 
directed circuits of negative lengths. In the following, Ε denotes the 
edge set of G, and w(u, v) denotes the length of the directed edge 
(", v). 
51. Set σ(ί) = 0, and set σ{μ) = °° for u Φ s. 
52. Set S = {s}. 
53. If 5 = Φ, HALT; otherwise select u* such that u* Ε S and 
°-(w*) = min {σ(κ)} . 
54. For each ν such that (u*, υ) Ε Ε, set σ(υ) = ππη{σ(ι>), a(u*) + 
w(u*, υ)}. If this process decreases σ(ν), set 5 = S U {v}. 
55. Set S = 5 - {u*}, and go to S3. 
(Edmonds and Karp [11.31].) 
11.3 
Prove the validity of the following algorithm due to Dantzig [11.37] 
for finding the shortest paths between all pairs of vertices in a 
weighted graph that has no directed circuits of negative length. Here 
W
k(i, j) is the distance from i to / where 1 s j , j < k and no vertices 
higher than k are used on the path. w(i, ;') = W\i, j) is the length of 
the edge (/, ;') and w(i, j) = <» if no such edge exists. Also w(i, i) = 0 
for all i. 
51. Set k = 2. 
52. For 1 < j < k do 
W
k(i, k) = min Mi, k), W
k~\i, j) + w(j, k)} 
W
k(k, i) = min {w(k, i), w(k j) + W
k'\j, 
i)} . 
53. For 1 <i, j<k do 
W\i, j) = min {W
k~\i, j), W
k(i, k) + W
k(k, j)} 

EXERCISES 
381 
S4. If k = n, STOP; otherwise set k = k + 1 and go to S2. 
Also show how negative-length circuits can be detected while 
carrying out this algorithm. 
11.4 
Using topological sorting, design an algorithm to find the shortest 
path from a vertex s to all the other vertices in an acyclic weighted 
directed graph. 
11.5 
Suppose the shortest path from ι to j is not unique. Which path is 
chosen by Floyd's algorithm (Algorithm 11.5)? 
11.6 
An optimum branching may not be an optimum spanning directed 
tree. Show how Edmonds' algorithm can be modified to find an 
optimum spanning directed tree. 
11.7 
Using DFS, design algorithms for the following problems: 
(a) Topological sorting of the vertices of a graph. 
(b) Finding bridges of a graph. 
(c) Finding a spanning forest. 
(d) Finding a set of fundamental circuits and a set of fundamental 
cutsets. 
(e) Testing whether a graph is bipartite. 
(f) Testing whether a subset of edges is a cut of a graph. 
11.8 
Consider a graph G and let Γ be a DFS spanning forest of G. Let 
ND(y) be the number of descendants of υ (including itself). Prove 
that a vertex w is a descendant of υ if and only if 
DFN(u) < DFN(w) < DFN(u) + ND(u). 
11.9 
Modify the DFS algorithm to include computation of ND(tv). 
11.10 
Let Γ be a DFS tree of a connected graph G. Let Gs be a complete 
subgraph of G. Show that all the vertices of Gs lie on one directed 
path in T. 
11.11 
Let Γ be a DFS tree of a directed graph G. If C is a directed circuit 
in G and υ is the vertex on C with minimum depth-first number, 
show that ν is an ancestor in Τ of every vertex on C. 
11.12 
Breadth-first search (BFS) explores a connected graph G as follows: 
51. To begin with no vertices of G are labeled. 
52. Select vertex s and label it with 0. 
53. Set i = 0. 
54. Let S be the set of all unlabeled vertices adjacent to at least one 
vertex labeled i. 
55. If S is empty HALT. Otherwise label all the vertices in S with 
i + l. 

382 
GRAPH ALGORITHMS 
11.14 
REFERENCES 
11.1 
D. Gries, Compiler Construction for Digital Computers, Wiley, New York, 
1971. 
11.2 
S. Warshall, "A Theorem on Boolean Matrices," J. ACM, Vol. 9, 11-12 
(1962). 
11.3 
H. S. Warren, "A Modification of Warshall's Algorithm for the Transitive 
Closure of Binary Relations," Comm. ACM, Vol. 18, 218-220 (1975). 
11.4 
V. L. Arlazarov, E. A. Dinic, M. A. Kronrod, and I. A. Faradzev, "On 
Economical Construction of the Transitive Closure of a Directed Graph," 
Soviet Math. Dokl., Vol. 11, 1209-1210 (1970). 
11.5 
V. Strassen, "Gaussian Elimination is Not Optimal," Numerische Math., 
Vol. 13, 354-356 (1969). 
11.6 
M. J. Fischer and A. R. Meyer, "Boolean Matrix Multiplication and 
Transitive Closure," Conf. Record, IEEE 12th Annual Symp. on Switching 
and Automata Theory, 1971, pp. 129-131. 
11.7 
Μ. E. Furman, "Application of a Method of Fast Multiplication of Matrices 
S6. Set i = i + l and go to S4. 
Show that the edges traversed while labeling the vertices form a 
spanning tree of G. 
11.13 Show how the BFS algorithm can be used to compute the distance 
from a vertex s to all the vertices in a connected graph G. (By 
distance between vertices u and υ here we mean the length of a u-v 
path having the smallest number of edges.) 
11.14 Show that the set of back edges of a reducible program graph is 
unique, that is, all DFS spanning forests have the same set of back 
edges (Hecht and Ullman [11.101]). 
11.15 
Given a biconnected graph G, design a DFS-based algorithm to 
extract a minimal biconnected subgraph of G. 
11.16 Prove the following theorem known as the planar separator theorem 
([11.133], [11.134] and [11.135]). Let G = (V, E) be a planar graph 
with a nonnegative real number w(v), called weight of v, associated 
with each vertex v. Let W= Συεν 
w(v) be the total weight of G. 
Then there is a partition A, S, Β of V such that 
1) W(A) = Zu&Aw(v)^2l
/iW, 
W(fl)<2/3W. 
2) | 5 | < 4 Vn 
3) S separates A from B, that is, Ε Π (A x Β) = Φ. 
4) Partition A, S, Β can be constructed in time 0(n). 
(Note: See also [11.14] for a proof of this and several related 
results.) 

REFERENCES 
383 
in the Problem of Finding the Transitive Closure of a Graph," Soviet Math. 
Dokl., Vol. 11, 1252 (1970). 
11.8 
I. Munro, "Efficient Determination of the Transitive Closure of a Directed 
Graph," Information Processing Lett., Vol. 1, 56-58 (1971). 
11.9 
P. E. O'Neil and E. J. O'Neil, "A Fast Expected Time Algorithm for 
Boolean Matrix Multiplication and Transitive Closure," Inform, and Con-
trol, Vol. 22, 132-138 (1973). 
11.10 
J. Eve and R. Kurki-Suonio, "On Computing the Transitive Closure of a 
Relation," Acta Informatica, Vol. 8, 303-314 (1977). 
11.11 
P. Purdom, "A Transitive Closure Algorithm," BIT, Vol. 10, 76-94 (1970). 
11.12 
C P . Schnorr, "An Algorithm for Transitive Closure with Linear Expected 
Time," SIAMJ. Computing, Vol. 7, 127-133 (1978). 
11.13 
Μ. M. Syslo and J. Dzikiewicz, "Computational Experience with Some 
Transitive Closure Algorithms," Computing, Vol. 15, 33-39 (1975). 
11.14 
K. Melhorn, Graph Algorithms and NP-Completeness, Springer-Verlag, 
Berlin, 1984. 
11.15 
L. R. Ford and D. R. Fulkerson, Flows in Networks, Princeton University 
Press, Princeton, N.J., 1962. 
11.16 
E. W. Dijkstra, "A Note on Two Problems in Connexion with Graphs," 
Numerische Math., Vol. 1, 269-271 (1959). 
11.17 
L. R. Ford, Jr., "Network Flow Theory," Paper P-923, RAND Corp., 
Santa Monica, Calif., 1956. 
11.18 
R. E. Bellman, "On a Routing Problem," Quart. Appl. Math., Vol. 16, 
87-90 (1958). 
11.19 
E. F. Moore, "The Shortest Path Through a Maze," Proc. Intl. Symp. 
Theory of Switching, Part II, University Press, Cambridge, Mass., 1957, pp. 
285-292. 
11.20 
S. E. Dreyfus, "An Appraisal of Some Shortest-Path Algorithms," Oper-
ations Research, Vol. 17, 395-412 (1969). 
11.21 
T. C. Hu, "A Decomposition Algorithm for Shortest Paths in a Network," 
Operations Research, Vol. 16, 91-102 (1968). 
11.22 
H. Frank and I. T. Frisch, Communication, Transmission and Transporta-
tion Networks, Addison-Wesley, Reading, Mass., 1971. 
11.23 
N. Christofides, Graph Theory: An Algorithmic Approach, Academic Press, 
New York, 1975. 
11.24 
E. L. Lawler, Combinatorial Optimization: Networks and Matroids Holt, 
Rinehart and Winston, New York, 1976. 
11.25 
M. Gordon and M. Minoux, Graphs and Algorithms, (trans, by S. Vajda), 
Wiley, New York, 1984. 
11.26 
E. Minieka, Optimization Algorithms for Networks and Graphs, Marcel 
Dekker, New York, 1978. 
11.27 
P. M. Spira and A. Pan, "On Finding and Updating Spanning Trees and 
Shortest Paths," SIAM J. Comput., Vol. 4, 375-380 (1975). 
11.28 
D. B. Johnson, "Efficient Algorithms for Shortest Paths in Sparse Net-
works," J. ACM, Vol. 24, 1-13 (1977). 

384 
GRAPH ALGORITHMS 
11.29 
R. A. Wagner, "A Shortest Path Algorithm for Edge-Sparse Graphs," /. 
ACM, Vol. 23, 50-57 (1976). 
11.30 
D. B. Johnson, "A Note on Dijkstra's Shortest Path Algorithm," /. ACM, 
Vol. 20, 385-388 (1973). 
11.31 
J. Edmonds and R. M. Karp, "Theoretical Improvements in Algorithmic 
Efficiency for Network Flow Problems," J. ACM, Vol. 19, 248-264 (1972). 
11.32 
M. L. Fredman, "New Bounds on the Complexity of the Shortest Path 
Problem," SI AM J. Comp., Vol. 5, 83-89 (1976). 
11.33 
M. A. Comeau and K. Thulasiraman, "Structure of the Submarking Reach-
ability Problem and Network Programing," IEEE Trans. Circuits and 
Systems, Vol. 35, 89-100 (1988). 
11.34 
Y. Liao and C. K. Wong, "An Algorithm to Compact VLSI Symbolic 
Layout with Mixed Constraints," IEEE Trans. CAD. Circuits and Systems, 
Vol. 2, 62-69 (1983). 
11.35 
T. Lengauer, "On the Solution of Inequality Systems Relevant to IC 
Layout," J. Algorithms, Vol. 5, 408-421 (1984). 
11.36 
R. W. Floyd, "Algorithm 97: Shortest Path," Comm. ACM, Vol. 5, 345 
(1962). 
11.37 
G. B. Dantzig, "All Shortest Routes in a Graph," in Theory of Graphs, 
Gordon and Breach, New York, 1967, pp. 91-92. 
11.38 
Y. Tabourier, "AH Shortest Distances in a Graph: An Improvement to 
Dantzig's Inductive Algorithm," Discrete Math., Vol. 4, 83-87 (1973). 
11.39 
J. Y. Yen, "Finding the Lengths of All Shortest Paths in N-Node, Non-
Negative Distance Complete Networks Using N
3/2 Additions and Ν
3 
Comparisons," J. ACM, Vol. 19, 423-424 (1972). 
11.40 
T. A. Williams and G. P. White, "A Note on Yen's Algorithm for Finding 
the Length of All Shortest Paths in N-Node Non-Negative Distance Net-
works," /. ACM, Vol. 20, 389-390 (1973). 
11.41 
A. R. Pierce, "Bibliography on Algorithms for Shortest Path, Shortest 
Spanning Tree and Related Circuit Routing Problems (1956-1974)," Net-
works, Vol. 5, 129-149 (1975). 
11.42 
N. Deo and C. Y. Pang, "Shortest Path Algorithms-Taxonomy and 
Annotation," Networks, Vol. 14, 275-323 (1984). 
11.43 
R. E. Tarjan, "Data Structures and Network Algorithms," CBMS-NSF 
Regional Conference Series in Applied Mathematics, Vol. 44, Society for 
Industrial Applied Mathematics, Philadelphia, 1983. 
11.44 
B. Carre, Graphs and Networks, Clarendon Press, Oxford, 1979. 
11.45 
R. E. Tarjan, "A Unified Approach to Path Problems," /. ACM., Vol. 28, 
577-593 (1981). 
11.46 
G. N. Frederickson, "Fast Algorithms for Shortest Paths in Planar Graphs 
with Applications," SI AM J. Comp., Vol. 16, 1004-1022 (1987). 
11.47 
A. Moffat and T. Takoka, "An All-Pairs Shortest Path Algorithm with 
Expected Time 0(n
2 log n)," SIAMJ. Comp., Vol. 16, 1023-1031 (1987). 
11.48 
J. B. Kruskal, Jr., "On the Shortest Spanning Subtree of a Graph and the 
Travelling Salesman Problem," Proc. Am. Math. Soc, Vol. 7, 48-50 
(1956). 

REFERENCES 
385 
11.49 
R. C. Prim, "Shortest Connection Networks and Some Generalizations," 
Bell Sys. Tech. J., Vol. 36, 1389-1401 (1957). 
11.50 
A. Kerschenbaum and R. Van Slyke, "Computing Minimum Spanning 
Trees Efficiently," Proc. 25th Ann. Conf. of the ACM, 1972, pp. 518-527. 
11.51 
A. C. Yao, "An 0(\E\ log log |V|) Algorithm for Finding Minimum 
Spanning Trees," Information Processing Lett., Vol. 4, 21-23 (1975). 
11.52 
D. Cheriton and R. E. Tarjan, "Finding Minimum Spanning Trees," SIAM 
J. Comput., Vol. 5, 724-742 (1976). 
11.53 
R. E. Tarjan, "Sensitivity Analysis of Minimum Spanning Trees and 
Shortest Path Trees," Information Processing Lett., Vol. 14, 30-33 (1982). 
11.54 
C. H. Papadimitriou and M. Yannakakis, "The Complexity of Restricted 
Minimum Spanning Tree Problems," J. ACM, Vol. 29, 285-309 (1982). 
11.55 
R. L. Graham and P. Hall, "On the History of the Minimum Spanning Tree 
Problem," Mimeographed, Bell Laboratories, Murray Hill, N.J., 1982. 
11.56 
J. Edmonds, "Optimum Branchings," J. Res. Nat. Bur. Std., Vol. 71B, 
233-240 (1967). 
11.57 
R. M. Karp, "A Simple Derivation of Edmonds' Algorithm for Optimum 
Branchings," Networks, Vol. 1, 265-272 (1972). 
11.58 
R. E. Tarjan, "Finding Optimum Branchings," Networks, Vol. 7, 25-35 
(1977). 
11.59 
P. M. Camerini, L. Fratta, and F. Maffioli, "A Note on Finding Optimum 
Branchings," Networks, Vol. 9, 309-312 (1979). 
11.60 
Y. Chu and T. Liu, "On the Shortest Arborescence of a Directed Graph," 
Scientia Sinica [Peking], Vol. 4, 1396-1400, (1965); Math. Rev., Vol. 33, 
#1245 (D. W. Walkup). 
11.61 
F. C. Bock, "An Algorithm to Construct a Minimum Directed Spanning 
Tree in a Directed Network," in Developments in Operations Research, B. 
Avi-Itzak, Ed., Gordon and Breach, New York, 1971, pp. 29-44. 
11.62 
A. Itai, M. Rodeh, and S. L. Tanimoto, "Some Matching Problems for 
Bipartite Graphs," J. ACM, Vol. 25, 517-525 (1978). 
11.63 
H. W. Kuhn, "The Hungarian Method for the Assignment Problem," Naval 
Res. Legist. Quart., Vol. 2, 83-97 (1955). 
11.64 
J. Munkres, "Algorithms for the Assignment and Transportation 
Problems," J. SIAM, Vol. 5, 32-38 (1957). 
11.65 
J. A. Bondy and U. S. R. Murty, Graph Theory with Applications, 
Macmillan, London, 1976. 
11.66 
N. Megiddo and A. Tamir, "An 0(N log N) Algorithm for a Class of 
Matching Problems," SIAM J. Comput., Vol. 7, 154-157 (1978). 
11.67 
R. M. Karp, "An Algorithm to Solve the m x η Assignment Problem in 
Expected Time (mn log «)," Networks, Vol. 10, 143-152 (1980). 
11.68 
V. Derigs, "A Shortest Augmenting Path Method for Solving Minimal 
Perfect Matching Problems," Networks, Vol. 11, 379-390 (1981). 
11.69 
D. Avis, "A Survey of Heuristics for the Weighted Matching Problem," 
Networks, Vol. 13, 475-493 (1983). 
11.70 
D. Avis and C. W. Lai, "The Probabilistic Analysis of a Heuristic for the 
Assignment Problem," SIAM J. Comp., Vol. 17, 732-741 (1988). 

386 
GRAPH ALGORITHMS 
11.71 
Μ. D. Grigoriadis and B. Kalantri, "A New Class of Heuristic Algorithms 
for Weighted Perfect Matching," J. ACM, Vol. 35 , 769-776 (1988). 
11.72 
R. Cole and J. Hopcroft, "On Edge Coloring Bipartite Graphs," SIAMJ. 
Comp., Vol. 11, 540-546 (1982). 
11.73 
Η. N. Gabow and O. Kariv, "Algorithm for Edge Coloring Bipartite 
Graphs and Multigraphs," SIAMJ. Comp., Vol. 11, 117-129 (1982). 
11.74 
S. Even, A. Itai, and A. Shamir, "On the Complexity of Time-Table and 
Multicommodity Flow Problems," SI AM J. Comput., Vol. 5, 691-703 
(1976). 
11.75 
Meo-Ko Kwan, "Graphic Programming Using Odd and Even Points," 
Chinese Math., Vol. 1, 273-277 (1962). 
11.76 
J. Edmonds, "The Chinese Postman Problem," Operations Research, Vol. 
13, Suppl. 1, 373 (1965). 
11.77 
J. Edmonds and E. L. Johnson, "Matching, Euler Tours and the Chinese 
Postman," Math. Programming, Vol. 5, 88-124 (1973). 
11.78 
R. J. Wilson, Introduction to Graph Theory, Oliver and Boyd, Edinburgh, 
1972. 
11.79 
Α. V. Aho, A. T. Dahbura, D. Lee, and M. U. Uyar, "An Optimization 
Technique for Protocol Conformance Test Generation Based on UIO 
Sequences and Rural Chinese Postman Tours," in Protocol Specification, 
Testing, and Verification, VIII, S. Aggarwal and Κ. K. Sabnani, Eds., 
Elsevier North-Holland, New York, 1988, pp. 75-86. 
11.80 
C. S. Orloff, "A Fundamental Problem in Vehicle Routing," Networks, Vol. 
4, 35-64 (1974). 
11.81 
C. H. Papadimitriou, "On the Complexity of Edge Traversing," J. ACM, 
Vol. 23, 544-554 (1976). 
11.82 
J. Lenstra and A. Rinooy-Kan, "On General Routing Problems," Net-
works, Vol. 6, 273-280 (1976). 
11.83 
G. N. Frederickson, "Approximation Algorithms for Some Postman Prob-
lems," J. ACM, Vol. 26, 538-554 (1979). 
11.84 
M. Dror, H. Stern, and P. Trudeau, "Postman Tour on a Graph with 
Precedence Relation on Arcs," Networks, Vol. 17, 283-294 (1987). 
11.85 
R. E. Tarjan, "Depth-First Search and Linear Graph Algorithms," SIAM J. 
Comput., Vol. 1, 146-160 (1972). 
11.86 
J. Hopcroft and R. Tarjan, "Efficient Algorithms for Graph Manipulation," 
Comm. ACM, Vol. 16, 372-378 (1973). 
11.87 
Α. V. Aho, J. E. Hopcroft, and J. D. Ullman, "On Finding the Least 
Common Ancestors in Trees," SIAM J. Comput., Vol. 5, 115-132 (1976). 
11.88 
J. Cocke, "Global Common Subexpression Elimination," SIGPLAN 
Notices, Vol. 5, 20-24 (1970). 
11.89 
J. D. Ullman, "Fast Algorithms for the Elimination of Common Subexpres-
sions," Acta Informatica, Vol. 2, 191-213 (1973). 
11.90 
K. Kennedy, "A Global Flow Analysis Algorithm," Int. J. Computer Math., 
Vol. 3, 5-16 (1971). 
11.91 
M. Schaefer, A Mathematical Theory of Global Program Optimization, 
Prentice-Hall, Englewood Cliffs, N.J., 1973. 

REFERENCES 
387 
11.92 
Α. V. Aho and J. D. Ullman, The Theory of Parsing, Translation and 
Compiling, Vol. II, Compiling, Prentice-Hall, Englewood Cliffs, N.J., 1973. 
11.93 
F. E. Allen, "Control Flow Analysis," SIGPLAN Notices, Vol. 5, 1-19 
(1970). 
11.94 
F. E. Allen, Program Optimization, Annual Review in Automatic Program-
ming, Vol. 5, Pergamon, New York, 1969. 
11.95 
M. S. Hecht, Flow Analysis of Computer Programs, Elsevier, New York, 
1977. 
11.96 
M. S. Hecht and J. D. Ullman, "Flow Graph Reducibility," SIAM J. 
Comput., Vol. 1, 188-202 (1972). 
11.97 
J. Cocke and R. E. Miller, "Some Analysis Techniques for Optimizing 
Computer Programs," Proc. 2nd Int. Conf. on System Sciences, Honolulu, 
Hawaii, 1969. 
11.98 
J. E. Hopcroft and J. D. Ullman, "An η log η Algorithm for Detecting 
Reducible Graphs," Proc. 6th Annual Princeton Conf. on Information 
Sciences and Systems, Princeton, N.J., 1972, pp. 119-122. 
11.99 
R. E. Tarjan, "Testing Flow Graph Reducibility," Proc. 5th Annual ACM 
Symp. on Theory of Computing, 1973, pp. 96-107. 
11.100 R. E. Tarjan, "Testing Flow Graph Reducibility," /. Comput. Sys. Sci., 
Vol. 9, 355-365 (1974). 
11.101 M. S. Hecht and J. D. Ullman, "Characterizations of Reducible Flow 
Graphs," J. ACM, Vol. 21, 367-375 (1974). 
11.102 J. M. Adams, J. M. Phelan, and R. H. Stark, "A Note on the Hecht-
Ullman Characterization of Non-Reducible Flow Graphs," SIAM J. Corn-
put., Vol. 3, 222-223 (1974). 
11.103 M. Fischer, "Efficiency of Equivalence Algorithms," in Complexity of 
Computer Computations, R. E. Miller and J. W. Thatcher, Eds., Plenum 
Press, New York, 1972, pp. 153-168. 
11.104 J. E. Hopcroft and J. D. Ullman, "Set Merging Algorithms," SIAM J. 
Comput., Vol. 2, 294-303 (1973). 
11.105 R. E. Tarjan, "On the Efficiency of a Good but Not Linear Set Union 
Algorithm," /. ACM, Vol. 22, 215-225 (1975). 
11.106 Α. V. Aho, J. E. Hopcroft, and J. D. Ullman, The Design and Analysis of 
Computer Algorithms, Addison-Wesley, Reading, Mass., 1974. 
11.107 E. Horowitz and S. Sahni, Fundamentals of Data Structures, Computer 
Science Press, Potomac, Md., 1976. 
11.108 S. Shinoda, W-K. Chen, T. Yasuda, Y. Kajitani, and W. Mayeda, "A 
Necessary and Sufficient Condition for any Tree of a Connected Graph to 
be a DFS-Tree of One of Its 2-Isomorphic Graphs," IEEE ISCAS, New 
Orleans, 2841-2844 (1990). 
11.109 J. Valdes, R. E. Tarjan, and E. L. Lawler, "The Recognition of Series 
Parallel Digraphs," SIAM J. Comp., Vol. 11, 298-313 (1982). 
11.110 A. Lempel, S. Even, and I. Cederbaum, "An Algorithm for Planarity 
Testing of Graphs," Theory of Graphs, International Symp., Rome, July 
1966, P. Rosenstiehl, Ed., Gordon and Breach, New York, 1967, pp. 
215-232. 

388 
GRAPH ALGORITHMS 
11.111 S. Even and R. E. Tarjan, "Computing an si-Numbering," Th. Comp. Sci., 
Vol. 2, 339-344 (1976). 
11.112 J. Erbert, "sf-Ordering the Vertices of Biconnected Graphs," Computing, 
Vol. 30, 19-33 (1983). 
11.113 S. Wimer, J. Koren, and I, Cederbaum, "Floor Plans, Planar Graphs and 
Layouts," IEEE Trans. Circuits and Systems, Vol. CAS-35, 267-278 (1988). 
11.114 J. Hopcroft and R. E. Tarjan, "Efficient Planarity Testing," /. ACM, Vol. 
21, 549-568 (1974). 
11.115 Ε. M. Reingold, J. Nievergelt, and N. Deo, Combinatorial Algorithms: 
Theory and Practice, Prentice-Hall, Englewood Cliffs, N.J., 1977. 
11.116 S. Even, Graph Algorithms, Computer Science Press, Potomac, Md., 1979. 
11.117 G. Demoucron, Y. Malgrange, and R. Pertuiset, "Graphes Planaires: 
Reconnaissance 
et 
Construction 
de 
Representation 
Planaires 
Topologiques," Rev. Francaise de Rech. Operationelle, Vol. 8, 33-47 
(1984). 
11.118 F. Rubin, "An Improved Algorithm For Testing the Planarity of a Graph," 
IEEE Trans. Computers, Vol. C-24, 113-121 (1975). 
11.119 K. S. Booth and G. S. Lueker, "Testing for the Consecutive Ones Property, 
Interval Graphs and Graph Planarity Testing Using PQ-tree Algorithms," J. 
Comp. and Sys. Sciences, Vol. 13, 335-379 (1976). 
11.120 T. Nishizeki and N. Chiba, "Planar Graphs: Theory and Algorithms," 
Annals of Discrete Mathematics, Vol. 32, North-Holland, Amsterdam, 1988. 
11.121 H. de Fraysseix and P. Rosenstiehl, "A Depth-First Search Characterization 
of Planarity," Annals of Discrete Mathematics, Vol. 13, 75-80 (1982). 
11.122 R. H. J. M. Otten and J. G. Van Wijk, "Graph Representation in 
Interactive Layout Design," Proc. IEEE Intl. Symp. Circuits and Systems, 
1978, pp. 914-918. 
11.123 P. Rosenstiehl and R. E. Tarjan, "A Unified Approach to Visibility 
Representation of Planar Graphs," Discrete and Computational Geometry, 
Vol. 1, Springer-Verlag, Berlin, 1986, pp. 343-353. 
11.124 N. Chiba, T. Nishizeki, S. Abe, and T. Ozawa, "A Linear Algorithm for 
Embedding Planar Graphs Using PQ-trees," J. Comp. and Syst. Sciences, 
Vol. 30, 54-76 (1985). 
11.125 R. Jayakumar, K. Thulasiraman, and Μ. N. S. Swamy, "Planar Embed-
ding: Linear Time Algorithms for Vertex Placement and Edge Ordering," 
IEEE Trans. Circuits and Systems, Vol. 35, 334-344 (1988). 
11.126 N. Chiba, I. Nishioka, and I. Shirakawa, "An Algorithm of Maximal 
Planarisation of Graphs," Proc. IEEE Intl. Symp. Circuits and Systems, 
1979, pp. 649-652. 
11.127 T. Ozawa and H. Takahashi, "A Graph-Planarization Algorithm and Its 
Applications," Graph Theory and Algorithms, Lecture Notes in Computer 
Science, Vol. 108, 95-107 (1981). 
11.128 R. Jayakumar, K. Thulasiraman, and Μ. N. S. Swamy, "0(n
2) Algorithms 
for Graph Planarisation," IEEE Trans. CAD. Integrated Circuits and 
Systems, Vol. 8, 257-267 (1988). 

REFERENCES 
389 
11.129 Μ. Marek-Sadowska, "Planarisation Algorithms for Integrated Circuits 
Engineering," Proc. IEEE Intl. Symp. on Circuits and Systems, New York, 
1978, pp. 919-923. 
11.130 P. Eades and R. Tamassia, "Algorithms for Drawing Graphs," An Anno-
tated Bibliography, Technical Report No. CS-89-09, Dept. Comp. Science, 
Brown University, 1989. 
11.131 T. Lengauer, Combinatorial Algorithms for Integrated Circuit Layout, 
Wiley, New York, 1990. 
11.132 Α. V. Aho, M. R. Garey, and J. D. Ullman, "The Transitive Reduction of a 
Directed Graph," SIAM J. Computing, Vol. 1, 131-137 (1972). 
11.133 R. Lipton and R. E. Tarjan, "A Separtor Theorem for Planar Graphs," 
Proc. of the Conf. on Theoretical Computer Science, Waterloo, Canada, 
1-10 (1977). 
11.134 R. Lipton and R. E. Tarjan, "Applications of a Planar Separator 
Theorem," Proc. 18th Annual Symp. Foundations of Computer Science 
Conf., 1977, pp. 162-170. 
11.135 J. D. Ullman, Computational Aspects of VLSI, Computer Science Press, 
Rockville, Md., 1984. 

CHAPTER 12 
FLOWS IN NETWORKS 
Network optimization, a branch of operations research, refers to the class of 
optimization problems defined on graphs or networks. These problems 
include the minimum cost flow problem, the maximum flow problem, 
covering problems, and such problems as the optimal assignment problems 
and the Chinese postman problem considered in the previous chapter. While 
important by themselves, they also arise as subproblems while studying 
larger and more complex problems. For instance, as we have seen in the 
previous chapter, shortest path and matching algorithms serve as building 
blocks in the algorithm for the Chinese postman problem. 
In this chapter we study, in sufficient detail, the maximum flow problem. 
While the theoretical richness of this problem has an unsurpassing beauty, it 
is also practically very important. It provides the main link between graph 
theory and operations research. The celebrated max-flow min-cut theorem 
of Ford and Fulkerson is equivalent to some of the celebrated graph 
theorems such as Hall's marriage theorem and Menger's theorems on 
connectivities. This equivalence has helped develop efficient matching and 
connectivity algorithms. 
The chapter is organized as follows. After stating the maximum flow 
problem in Section 12.1, we develop in Section 12.2 the maximum flow 
minimum cut theorem. We then proceed to develop two fundamentally 
different approaches to the maximum flow problem. In Sections 12.3 to 
12.6, Ford and Fulkerson's labeling algorithm and several refinements of 
this algorithm are discussed. In Section 12.7 we develop the recent work of 
Goldberg and Tarjan, which represents a significant departure from earlier 
works based on Ford and Fulkerson's algorithm. In Section 12.8 we study 
the complexity of the maximum flow problem in the case of a special class of 
390 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

THE MAXIMUM FLOW PROBLEM 
391 
networks called 0-1 networks. The next two sections show how network 
flow techniques can be used to develop algorithms for matching and 
connectivity problems. We conclude with a brief introduction to the theory 
of NP-completeness. 
12.1 THE MAXIMUM FLOW PROBLEM 
A transport network TV is a connected directed graph that has no self-loops 
and that satisfies the following conditions: 
1. There is only one vertex with zero in-degree; this vertex is called the 
source and is denoted by s. 
2. There is only one vertex with zero out-degree; this vertex is called the 
sink and is denoted by t. 
3. Each directed edge e = (/, /) in Ν is associated with a nonnegative real 
number called the capacity of the edge; it is denoted by c(e) or c(i, ;'). 
If there is no edge e directed from ι to ;', then we define c(e) = 0. 
A transport network represents a model for the transportation of a com-
modity from its production center to its market through communication 
routes. The capacity of an edge may then be considered as representing the 
maximum rate at which a commodity can be transported along the edge. 
A flow f in a transport network Ν is an assignment of a nonnegative real 
number f(e) = f(i, j) to each edge e = (i, j) such that the following condi-
tions are satisfied: 
1. /(j, / ) < c(i, /) for every edge (i, j) in TV. 
(12.1) 
2. Σ.„, /(/, /) = Σ β Ι Ι j / ( / , ι) for all i Φ s, t. 
(12.2) 
The value f(e) of the flow in edge e may be considered as the rate at which 
material is transported along e under the flow/. Condition (12.1), called the 
capacity constraint, requires that the rate of flow along an edge cannot 
exceed the capacity of the edge. Condition (12.2), called the conservation 
condition, requires that for each vertex i, except the source and the sink, the 
rate at which material is transported into i is equal to the rate at which it is 
transported out of i. 
As an example, a transport network TV with a flow/is shown in Fig. 12.1. 
In this figure next to each edge e we have shown the capacity c(e) and the 
flow /(e) in that order. 
The value of a flow /, denoted by val(/), is defined as 
val(/)= Σ/(*,/)· 
(12.3) 
all i 

392 
FLOWS IN NETWORKS 
4,4 
2, 1 
.3,2 
2. 1 
/ 
N. 
1 
Λ 
/ \ 
5,2, 
' 
2 , 2 \ 
3,2 
\ 
6,4 
10,2 
c 
' 3 
d 
Figure 12.1. A transport network. 
Soon we prove using the conservation condition that 
val(/)= Σ/(*,/)= Σ/(/,')· 
all ι 
all / 
(12.4) 
This would only confirm the intuitively obvious fact that, because of the 
conservation condition, the total amount of material transported out of the 
source is equal to the total amount transported into the sink. 
A flow /* in a transport network Ν is said to be maximum if there is no 
flow fin Ν such that val(/) > val(/*). 
12.2 MAXIMUM FLOW MINIMUM CUT THEOREM 
A cut (S, S) in a transport network Ν is said to separate the source s and 
the sink / if s Ε S and t Ε S. Such a cut will be referred to as an s-t cut. The 
capacity c(K) = c(5, 5) of a cut Κ = {S, S) is denned as 
c(K) = Σ Φ, j). 
(12.5) 
ies 
,es 
Note that the capacities of the edges directed from S to Sjdo not contribute 
to the capacity of the cut Κ = (S, S)._We denote by f(S, S) the sum of the 
flows in the edges directed from 5 to 5. The quantity f(S, S) is defined in a 
similar way. 
_ 
For example, consider the cut Κ = (S, S) in the transport network shown 
in Fig. 12.1, where 
S = {a, b, c,s) 
and 
S={d, t) . 
The edges directed from 5 to S are e 3, e 4, and e g. Hence 

MAXIMUM FLOW MINIMUM CUT THEOREM 
393 
c(S, S) = c(e 3) + c(e 4) + c(e 8) = 11, 
/ ( S , S ) = / ( e 3 ) + /(e 4) + / ( e 8 ) = 8 , 
f(S, 5) = /(e 9) = 2 . 
Theorem 12.1. For any flow/and any s-t cut (S, S) in a transport network 
N, 
val(/) = / ( S , S ) - / ( S , S ) . 
(12.6) 
Proof. From the definitions of a flow and the value of a flow, we have 
V 
a - 
-\ 
V 
λ · · 
· \ 
i
v
a
l ( / ) > 
if* 
= 
·*; 
Z / 0 , / ) - Z / ( ; , i ) = (o, 
i f i e s - { s } . 
all / 
all ; 
>• 
'
 
1 
' 
Summing these equations over all the vertices in S, we get 
Σ Σ /(Λ /) - Σ Σ /(/, 0 = val(/). 
(12.7) 
i 6 S all ι 
i e i all y 
In this equation both /(/, j) and - / ( / , /), for i £ S and / £ 5, appear exactly 
once on the left-hand side and get canceled out. So (12.7) simplifies to 
Σ Σ/('·,/)-Σ Σ/κ/,ο = ν Η ΐ ( / ) . 
Thus 
/ ( S , 5 ) - / ( 5 , S ) = val(/). 
• 
Note that (12.3) is a special case of (12.6). 
Corollary 12.1.1. For any flow / a n d any s-t cut Κ = (S, S) in a transport 
network N, 
v a l ( / ) < c ( 5 , S ) . 
(12.8) 
Proof. Since every /(i, ;') is nonnegative, we get from (12.6) 
val(/) = / ( S , S ) - / ( S , S) 
< / ( 5 , 5 ) 
< c(5, 5 ) . 
• 
An edge (i, /) is said to be f-saturated if /(/, /) = c(i, ;') and f-unsaturated 
otherwise; it is f-positive if /(/, /) > 0, and f-zero if /(i, /) = 0. 

394 
FLOWS IN NETWORKS 
Note that equality in (12.8) holds if and only if f(S, S) = 0 and f(S, S) = 
c(S, 5). Injrther words val(/) = c(S, 5) if and only if_all the edges directed 
from S to S are /-saturated and those directed from S to S are /-zero. 
An s-t cut Κ in a transport network Ν is a minimum cut if there is no s-t 
cut K' in Ν such that c(/C) < c(K). 
Corollary 12.1.2. Let / be a flow and Κ be an s-t cut such that val(/) = 
c(K). Then / is a maximum flow and Κ is a minimum s-f cut. 
Proof. Let /* be a maximum flow and K* be a minimum s-t cut. By 
Corollary 12.1.1, 
val(/*)<c(K*). 
So we get 
val(/) < val(/*) < c(tf*) < c(K). 
Since, by hypothesis, val(/) = c(K), 
it follows that val(/) = val(/*) 
c(K*) = c(K). Thus / is a maximum flow and Κ is a minimum s-f cut. I 
We now proceed to show that the value of a maximum flow is in fact 
equal to the capacity of a minimum cut. 
Consider a transport network Ν with a flow /. Let 
e, 
e2 
e, 
ek 
Ρ: 
Ο 
Ο 
Ο · · · Ο 
Ο · · · Ο 
Ο 
S = U0 
Μ, 
U2 
«,_, 
II, 
Uk = V 
be a path in Ν from the source to some vertex v. Note that Ρ need not be a 
directed path. 
Edge e, of Ρ is called a forward edge of Ρ if it is oriented from u,_, to u,. 
Otherwise it will be called a backward edge of P. For each edge e, in P, let 
/(«,.), 
if e, is a forward edge ; 
if e, is a backward edge . 
\ 
· ) 
With the path Ρ we associate a nonnegative number e(P) defined by 
e(P) = min{ C,(P)}. 
(12.10) 
Note that e(P) > 0. 
We call a path f-unsaturated if all the forward edges of the path are 
/-unsaturated and all the backward edges of the path are /-positive. 
An s-t path Ρ is called an f-augmenting path if Ρ is /-unsaturated. From 

MAXIMUM FLOW MINIMUM CUT THEOREM 
3 9 5 
'3 
d 
Figure 12.2 
(12.9) and (12.10) it follows that for an s-t path P, e(P) > 0 if and only if P 
is /-augmenting. Given an s-t path P in the network N, we can define a new 
flow / as follows: 
I
f(e) + e(P), 
if e is a forward edge of P ; 
f(e) - e(P), if e is a backward edge of P ; 
/(e), 
otherwise . 
We can easily see that 
val(/) = val(/) + e(P). 
Thus val(/) > val(/) if and only if P is /-augmenting. In other words a flow/ 
is not maximum if there exists an /-augmenting path. 
As an example, consider the network N of Fig. 12.1. Let flow / be as 
shown in this figure. In the path P consisting of e2, es. e-,, and e8, the edges 
e2, eg, and e-, are forward edges, and e5 is the only backward edge. With 
respect to the flow /, e2(P) = 1, e5(P) = 1, e7(P) = 1, and e8(P) = 2. Hence 
e(P) = min{e2(P), e5(P), e,(P), e8(P)} = 1. 
Since e(P) > 0, P is/-augmenting. The revised flow /based on the path P 
is as shown in Fig. 12.2. Note that/is obtained by increasing the flows in all 
the forward edges of P by e(P) and decreasing the flows in the backward 
edges of P by e(P). The flows in the remaining edges remain unaltered. 
Theorem 12.2. A flow / in a transport network N is maximum if and only if 
there is no /-augmenting path. 
Proof. 
Necessity If there is an /-augmenting path P in N, then clearly / is not a 
maximum flow because the revised flow / based on P has a larger value than 
/· 

396 
FLOWS IN NETWORKS 
Sufficiency 
Suppose that Ν contains no/-augmenting path. Let S denote 
the set of all vertices in Ν that can be reached from the source by 
/-unsaturated paths. Clearly, sES. 
Further, tES 
because there is no 
/-augmenting path in N. 
_ 
Now we show that val(/) = c(S, S), Jhereby proving (by Corollary 
12.1.2) that / i s a maximum flow and (S, S) is a minimum cut. 
Consider a directed edge (i>, w) with υ Ε S and wES. 
Since vES, 
there 
is an /-unsaturated s-υ path Q. The edge (υ, w) must be /-saturated, for 
otherwise Q can be extended to yield an /-unsaturated s-w path, and this is 
not possible since w Ε S. Similarly we can show that every edge_(u, w) 
directed from S to 5 should be /-zero. Thus /(S, 5) = c(S, S) and f(S, S) = 
0. Hence 
val( / ) = /(S, S) - / ( S , S) = c(S, 5 ) . 
It now follows from Corollary 12.1.2 that/is a maximum flow and (S,S) 
is 
a minimum cut. 
• 
In the course of the proof of Theorem 12.2 we have also established the 
following well-known result due to Ford and Fulkerson [12.1] and Elias, 
Feinstein and Shannon [12.2]. 
Theorem 12.3 (Max-Flow Min-Cut Theorem). In a transport network the 
value of a maximum flow is equal to the capacity of a minimum cut. 
• 
The max-flow min-cut theorem can be used to prove several results of 
combinatorial significance. We discuss two of these results in Sections 12.9 
and 12.10. For others, Ford and Fulkerson [12.3] and Berge [12.4] may be 
consulted. 
12.3 
FORD-FULKERSON LABELING ALGORITHM 
We now discuss an algorithm also due to Ford and Fulkerson [12.1] for 
determining a maximum flow in a transport network. This algorithm, based 
on Theorem 12.2, consists of two phases. 
Given a flow /. In the first phase we use a labeling procedure to check 
whether an /-augmenting path exists. If such a path does not exist, then by 
Theorem 12.2 the present flow/is maximum. Otherwise we proceed to the 
second phase in which, using the labels generated in the first phase, we 
determine an /-augmenting path Ρ and obtain the revised flow / based on P. 
We then repeat phase 1 with the new flow /. Note that val(/)>val(/). 
In the first phase a label of the form (dv, Δ„) is assigned to a vertex v. 
The first symbol dv in the label indicates the vertex from which υ receives its 
label. It would also indicate the direction of labeling—forward or backward. 

FORD-FULKERSON LABELING ALGORITHM 
397 
Soon it will become clear that when a vertex υ gets labeled, it means that 
there exists an /-unsaturated s-υ path Ρ and that for this path P, e(P) = Δ„. 
The first phase begins by labeling the source s as ( - , °°); here the value of 
ds is irrelevant. The labeling of the vertices then proceeds according to the 
following rules: 
Suppose a vertex u is labeled and a vertex υ is unlabeled. Let e be an 
edge connecting u and v. 
Forward Labeling 
If e = («, v), then forward labeling of υ from « along e is 
possible if c(e)>/(e). If such a labeling is done, then ν gets the label 
( M
+ , Δ„), where 
A„ = min{A„,c(e)-/(e)}. 
Backward Labeling 
If e = (v, u), then backward labeling of υ from u along 
e is possible if /(e) > 0. If such a labeling is done, then ν gets the label 
(ιΓ, Δ„), where 
Δ„ = min{A u, /(e)} . 
In the first phase a vertex gets labeled at most once. This phase 
terminates when either (1) the vertex ί receives a label or (2) with t 
unlabeled, no more vertices can be labeled. 
If t receives a label in the first phase, then it follows from the rules for 
labeling that there exists an /-augmenting path Ρ and that e(P) = Δ,. In the 
second phase the path Ρ is traced back using the dv symbols, and the revised 
flow / based on Ρ is also determined. Phase 1 is then repeated using the new 
flow /. If phase 1 terminates without labeling t, then it means that there is no 
/-augmenting path, and hence the present flow / is maximum. 
A description of the Ford-Fulkerson's algorithm is now presented. 
Algorithm 12.1. Maximum Flow in a Transport Network (Ford and 
Fulkerson) 
51. Select any flow / in the given transport network. We may select 
/(e) = 0 for every edge e in N. 
52. (Phase 1 begins.) Label s as ( - ,
0 0 ) . 
53. If there exists an unlabeled vertex that can be labeled through either 
forward labeling or backward labeling, then select one such vertex v, 
label it, and then go to S4. Otherwise go to S7. 
54. If υ = t, then go to S5. (Phase 1 ends.) Otherwise go to S3. 
55. (Phase 2 begins.) Let the label of υ be (</„,Δ„). Now do the 
following: 
1. If dv = u
+, then set /(«, υ) = /(«, υ) + Δ,. 
2. If du = Μ", then set f(v, u) =f(v, u) - Δ,. 

398 
FLOWS IN NETWORKS 
56. If u = s, erase all the labels (phase 2 ends) and go to S2. Otherwise 
set v = u and go to S5. 
57. (The present flow / is maximum.) HALT. 
■ 
We now illustrate this algorithm. 
Consider the transport network N shown in Fig. 12.3. In this figure, next 
to each edge e we have shown c(e) and /(e) in this order. We take as an 
initial flow /(e) = 0 for all the edges in N. Starting with the label (-, °°) for 
the source s, we label (S3 of Algorithm 12.1) the vertices a, b, c, d, and t in 
this order. The resulting labels are 
a: (s+, 3), 
b: (a+,3), 
c: (a+, 3), 
d: (c+,2), 
t: 
(b\2). 
Phase 1 now terminates because vertex / has just been labeled. In phase 2 
we determine an augmenting path P and the revised flow /, as follows (S5 
and S6). 
The first symbol in the label of t is b+. This means that in the path P 
vertex b precedes /. The first symbol in the label of b indicates that a 
precedes b in P. Similarly we see that Ä precedes a in P. Thus 
All the edges in P are forward edges. So to obtain the revised flow /, we 
<«
+.3> 
(Λ2Ι 
Figure 12.3. Network for illustrating Ford-Fulkerson's labeling algorithm. 

F O R D - F U L K E R S O N L A B E L I N G A L G O R I T H M 
399 
increase the flows in all the edges of Ρ by Δ, = 2. The flow /, has a value 
equal to 2, and it is shown in Fig. 12.4a. 
We now erase the labels of all the vertices. Starting with /, we then obtain 
a new set of labels as shown in Fig. 12.4a. An augmenting path with respect 
to /, consists of the vertices s, c, d, t in this order. All the edges in this path 
Ρ are forward edges. The flows in these edges are increased by 2. The 
resulting flow f2 is shown in Fig. 12.4i>. 
3,2 
4,0 
5, 0 
2,0 
c 
d 
4) 
(c
+. 
(a) 
3, 0 
<<Λ 
2) 
6,0 
3,2 
K°°) 
4,2 
4,2 
1.C\ 
'5,0 
S 
\ l , 0 
2,2 
3,0 
2,2 
3,2 
4,3 
, 1) 
a 
4, 1 
i 
1, 1 
5,0 
S 
V '
 
1 
2,2 
3,0 
. 2, 2 
6,3 
(c) 
Figure 12.4. Illustration of Ford-Fulkerson's labeling algorithm. 

400 
FLOWS IN NETWORKS 
A new set of labels based on f2 is shown in Fig. 12.46. An augmenting 
path with respect to f2 consists of the vertices s, c, b, a, d, t. The edge 
connecting a and 6 is a backward edge in this path. All the other edges of 
this path are forward edges. We now increase the flows in the forward edges 
by 1 and decrease the flow in the backward edge by 1. The resulting flow / 3 
is shown in Fig. 12.4c. 
Starting with / 3 we then proceed to label the vertices. This process 
terminates as in Fig. 12.4c without labeling vertex t. Thus there is no 
augmenting path relative to the flow / 3. So / 3 is a maximum flow. 
Let 5 denote the set of labeled vertices in Fig. 12.4c. Thus S = {s, a, 6, 
c}. Then it is clear from the proof of Theorem 12.2 that the cut (S, S) is a 
minimum cut and val(/ 3) = capacity of (S, S). 
12.4 
EDMONDS AND KARP MODIFICATION OF THE LABELING 
ALGORITHM 
In the Ford-Fulkerson algorithm, which we described in the previous 
subsection, vertices can be labeled in any order. In other words selection of 
an augmenting path (when it exists) can be made in any arbitrary manner. 
We now illustrate, with an example, a problem to which this arbitrariness 
might lead. 
Consider the transport network TV shown in Fig. 12.5. Suppose we start 
the labeling algorithm with the zero flow and alternately use the paths P,: s, 
a, 6, t and P 2: s, 6, a, t as augmenting paths. At each step the flow value 
increases by exactly 1, and the maximum flow of 2M is achieved after 2M 
augmentation steps. Thus the number of computational steps used in this 
case is not bounded by a function of the number of vertices and the number 
of edges in N. This number is in fact a function of the capacity M, which can 
be arbitrarily large. 
b 
a 
Figure 12.5 

EDMONDS AND KARP MODIFICATION OF THE LABELING ALGORITHM 
401 
Furthermore, Ford and Fulkerson [12.3] showed that their algorithm may 
fail if the capacities are irrational numbers. They gave an example where the 
flow converges in infinitely many steps to one fourth of the value of a 
maximum flow. 
To avoid this problem, Edmonds and Karp [12.5] have suggested a 
refinement to the labeling algorithm: At each step augment the flow along a 
shortest path. Here by a shortest path we refer to a path having the smallest 
number of edges. It can be easily seen that a shortest augmenting path will 
be selected if in the labeling procedure we scan on a "first-labeled first-
scanned" basis; that is, if vertex υ has been labeled before vertex u, then 
scan υ before u. Here to scan a labeled vertex υ means to label (whenever 
possible) all the unlabeled vertices adjacent to v. 
Edmonds and Karp have also shown that this refinement will guarantee 
that the number of computational steps required to implement the labeling 
algorithm will be independent of the capacities. We now proceed to develop 
this result. 
Consider a flow / in a transport network N. Let 
Ρ: 
Ο 
Ο 
Ο · · · 
Ο 
Ο · · · 
Ο 
Ο 
S = Μ
0 
Μ , 
«
2 
Μ , - Ι
 
u k - \
 
Uk
 
= 
t 
be an augmenting path. Recall that 
_ f c(e,) - f(e,), 
if e, is a forward edge ; 
€'
 _ I f(
ei). 
'f
 e , is
 a backward edge . 
Further 
e(/») = min 
{e,(P)}. 
Thus e(F) = e,(P), for some i. The corresponding e, is then called a 
bottleneck. 
Assume that the labeling algorithm starts with an initial flow /„ and 
constructs a sequence of flows /,, f2, /3,... 
. 
Note that when an edge e is a bottleneck in the forward direction in an 
augmenting path, then during the augmentation it gets saturated. Also, if e 
is a bottleneck in the backward direction, then during the augmentation the 
flow through e is reduced to zero. This observation leads to the following 
result. 
Lemma 12.1. If k < ρ and e is a bottleneck in the forward (backward) 
direction both in the augmenting path that changes fk to fk+i 
and in the 
augmenting path that changes fp to fp+l, 
then there exists an /, 
k<l<p, 
such that e is used as a backward (forward) edge in the augmenting path, 
which changes /, to fl+1. 
• 

402 
FLOWS IN NETWORKS 
Let λ'(«, V) denote the length of a shortest /-unsaturated path from u to 
v. Here, of course, the path need not be directed. Further note that an edge 
e is used as a forward edge in the path only if it is not saturated, that is, 
fi(e)<c(e), 
and e is used as a backward edge only if/(e)>0. 
Lemma 12.2. For every vertex υ and every k = 0, 1 , 2 . . . , 
X
k(s,v)<X
k+\s,v), 
(12.11) 
X
k(v,t)<X
k+\v,t). 
(12.12) 
Proof. We shall prove (12.11), and the proof of (12.12) will follow in a 
similar manner. 
Suppose there is no fk+l-unsaturated 
path from s to v. Then λ*
 + 1(ί, ν) is 
assumed to be infinite and (12.11) follows trivially. So assume that 
e, 
e2 
e3 
ep 
Ρ: 
Ο 
Ο 
Ο 
Ο ··· 
Ο 
Ο 
S = U 0 
Μ, 
U 2 
Μ 3
 
Up-\ 
" ρ
 = 
υ 
is a shortest fk + i-unsaturated 
path from s to v. 
Suppose that e, is used as a forward edge in P. Then 
fk+^ei)<c(el). 
Therefore, (1) either fk(el)<c(el) 
or (2) fk{et) 
= c(e,), and so e, has been 
used as a backward edge in the augmenting path, which changes fk tofk 
+ l . 
In the former case 
X
k(s,u,)sX
k{s, 
«,_,) + 1, 
(12.13) 
because a shortest fk-unsaturated 
path from s to u,_, followed by e, in the 
forward direction is an fk-unsaturated 
path from s to «,. Clearly, in the latter 
case 
Α*(ί,Μ ι_ Ι) = Α*(ϊ,ΐί 1) + 1. 
(12.14) 
In either case (12.13) holds. 
Similarly we can show that (12.13) holds when e, is used as a backward 
edge in the path P. 
Now summing (12.13) for i = 1, 2 , . . . , ρ and noting that X
k(s, u 0) = 0, 
we get 
A*(s, up)<p 
= 
X
k+\s,v). 
Thus (12.11) follows. 
• 
Lemma 12.3. If the "first-labeled first-scanned" principle is used and if k < I 

EDMONDS AND KARP MODIFICATION OF THE LABELING ALGORITHM 
403 
and e is used as a forward (backward) edge in the augmenting path that 
changes fk to fk+] 
and as a backward (forward) edge in the augmenting path 
that changes /, to 
then 
X'(s, ή s A*(s, i) + 2 . 
Proof. Assume that e is directed from u to v. Then 
A*(i, v) = \
k(s, u) + 1 , 
(12.15) 
because e is used as a forward edge while augmenting fk. Further, 
A'(s, t) = \'(s, v) + l + \'(u, t), 
(12.16) 
because e is used as a backward edge while augmenting 
But 
A'(s, υ) a A*(j, υ) 
and 
A ' ( M , t)>\
k(u, 
ή . 
(12.17) 
Now we get from (12.15), (12.16), and (12.17) 
λ'(ί, t) a A * ( J , u) + \
k(u, 0 + 2 
= A*(i, f) + 2. 
• 
Theorem 12.4 (Edmonds and Karp). If, in Ford-Fulkerson's labeling al-
gorithm, each flow augmentation is done along a shortest augmenting path, 
then a maximum flow can be obtained after no more than m(n + 2)/2 
augmentations, where m is the number of edges and n is the number of 
vertices in the transport network. 
Proof. Consider any edge e directed from « t o u . Consider the sequence of 
flows / * , / * , . . . , where Λ, < k2 < ..., such that e is used as a forward edge 
while augmenting fk and is a bottleneck. By Lemma 12.1 there exists a 
sequence lx, l2,..., 
such that 
*,</,< 
k2 < l2 < Jfc3 < · · • , 
and e is used as a backward edge while augmenting /,. 
By Lemma 12.3 
λ*·(Μ) + 2^λ''(ί, 0 

404 
FLOWS IN NETWORKS 
and 
A''(s,0 + 2^A*'
+ 1(s, ί)· 
So 
λ*·0, r) + 4(/-l)<A*>(i, t). 
Since 
\
k'(s, 
r) < η - 1 
and 
A * ' ( * , 0
2 1 . 
we get 
1 + 4 ( / - 1 ) < / I - 1 
or 
n + 2 
>* — 
· 
Thus e can be used as a bottleneck in the forward direction at most 
(n +2)14 times. Similarly it can be used as a bottleneck in the backward 
direction at most (n + 2)14 times. Thus each edge can serve as a bottleneck 
at most (n + 2)/2 times. Therefore the total number of augmentations is at 
most m(n + 2)12. 
• 
In the proof of Theorem 12.4 no assumption has been made about the 
nature of the capacities, except that they are nonnegative. Thus it is clear 
from this theorem that if the "first-labeled first-scanned" principle is used, 
then Algorithm 12.1 will terminate after a finite number of augmentations 
for any real nonnegative capacities. Since an augmenting path can be found 
in O(m) steps, it follows from Theorem 12.4 that Algorithm 12.1 is of 
complexity 
O(m
2n). 
Zadeh [12.6] has characterized a class of networks for which 
0(n
3) 
augmentations are necessary when each augmentation is done along a 
shortest augmenting path. Thus the upper bound in Theorem 12.4 cannot be 
improved upon except for a linear scale factor. 
12.5 
DINIC MAXIMUM FLOW ALGORITHM 
In this section we discuss an algorithm, due to Dinic [12.7], for the 
maximum flow problem. This algorithm, like Edmonds and Karp's, also 

DINIC MAXIMUM FLOW ALGORITHM 
4 0 5 
performs augmentations along shortest paths, but achieves a complexity of 
0(mn2) by finding in one application of the labeling procedure all possible 
shortest augmentations. An outline of Dinic's algorithm is as follows. 
The algorithm starts with the zero flow (/(e) = 0 for every edge e). At 
this point let lx be the length of a shortest augmenting path from s to t. The 
algorithm identifies all shortest augmenting paths of length /, and using these 
paths constructs a new flow /,. Let /2 denote the length of a shortest 
augmenting path in the network when the flow is /,. The algorithm would 
then identify all shortest augmenting paths of length l2, perform augmenta-
tions using these paths, and construct a new flow/2 with val(/2)>val(/i). 
This procedure is repeated, constructing flows /3, / 4,..., until we reach a 
flow fk for which no augmenting path is available (lk+1 = °°). At this point 
the algorithm would terminate with fk as a maximum flow. 
As we can see from the preceding, Dinic's algorithm involves repeated 
applications of two procedures: 
1. Identifying shortest augmenting paths relative to each flow/,. 
2. Performing augmentations. 
The first objective is achieved by constructing what is called a layered 
network relative to flow / . The second is achieved by finding what is called a 
maximal flow in this layered network. These concepts are discussed next. 
Given a transport network N = (V, E) with a flow/. The residual network 
Nf = (V, Ef) relative to / is defined as follows. Nf has the same vertex set V 
as N. For each edge e = {u, v) in N, Nf has the following: 
1. An edge e' = (u, v), if /(e) < c(e), with capacity cf(e') = c(e) - /(e). 
(Note: In this case e E £ is a candidate for use as a forward edge in an 
augmenting path relative to flow /. So such an edge e'E Ef is called a 
forward edge of ΝΛ. 
Figure 12.6 

406 
FLOWS IN NETWORKS 
2. An edge e' = (v, u), if /(e)>0, with capacity cf(e') = /(e). (Note: In 
this case e £ Ε is a candidate for use as a backward edge in an 
augmenting path relative to flow /. So such an edge e' £ Ef is called a 
backward edge of ty.) 
Note that if 0 </(e) < c(e), the edge (u, υ) as well as the edge (υ, u) will 
be present in Nf. Also note that the undirected path corresponding to each 
directed s-t path in 
is an /-augmenting path in N. 
As an example, for the transport network and the flow shown in Fig. 
12.1, the corresponding residual network is shown in Fig. 12.6. 
The layered network with respect to flow / is defined by the following 
algorithm: 
Algorithm 12.2. Layered Network 
51. Set V0 = {s} and ι = 0. 
52. Set T= [υ\υΦ Vt for 
and (u, v)EEf 
for some uE Vt). 
53. If T = 0, the present flow / is maximum. HALT. 
54. If t Ε Τ, then set / = i + 1, V, = {/} and E, = {(u, ν) Ε Ef\u £ Vt and 
vEVl+i). 
Include all the edges in E, in the layered network. HALT. 
55. Set V 1 +, = T. Set E, = {(«, υ) Ε Ef\u Ε V( and ν Ε V1 + 1} and include 
the edges in E, in the layered network. 
56. Set i = / + l and go to S2. 
The sets Vj's defined in Algorithm 12.2 are called layers of the network 
and / is referred to as the length of the layered network. The capacity of an 
edge e in the layered network is the same as its capacity cf(e) in Nf. 
The algorithm described for constructing the layered network is essential-
ly a breadth-first search (see Exercise 11.12 for a definition of breadth-first 
search) of Nf with the source s as the start vertex. Also the set Vj contains 
exactly those vertices that are at distance i (in Nf) from s (see Exercise 
11.13). Note that here distance from s to ν refers to the length of an s-v 
path that has the smallest number of edges. Since / £ VJ, the sink is at 
distance / from s. Thus each directed s-t path in the layered network 
corresponds to a shortest /-augmenting path. Also, every shortest /-
augmenting path corresponds to a directed s-t path in the layered network. 
Thus the layered network serves the important role of identifying all 
shortest /-augmenting paths. 
Though we have used the residual network Nf to describe construction of 
the layered network, in practice, this is done directly from Ν and the flow/. 
Since \Ef \ ^ 2|£|, and breadth-first search of a directed graph examines each 
edge exactly once, it follows that the complexity of constructing a layered 
network is 0(m), where m is the number of edges in TV. 
We next draw attention to the following important properties of a layered 
network: 

DINIC MAXIMUM FLOW ALGORITHM 
407 
1. There is no edge («, v) with u G V), vEVj and j> i + 1. 
2. There is no edge (u, v) with w G V„ vEVj and / ^ i. 
3. AH edges in £, are directed from V, to V,_,. 
4. The layered network is an acyclic directed network. 
A flow g in a layered network is a maximal flow if for each directed s-t 
path P: s = v0, u , , . . . , v, = t in the layered network there exists at least one 
edge e,. = (vi_l, υ,) on this path such that g(e () = c^e,). Note that a maximal 
flow may not be a maximum flow. However, we can see that once a maximal 
flow has been constructed, no unsaturated s-t path of length / will be 
available for further flow augmentation. For this reason a maximal flow is 
also called a blocking flow. 
Given a blocking flow g, a new flow / ' of value val(/')>val(/) can 
easily be constructed as follows: 
1. If (u, v), with u Ε K,_, and ν Ε Vn is a forward edge, then /'(«, υ) = 
f(u, v) + g(u, v). 
2. If (u, v), with u G Vj., and υ Ε V, is a backward edge, then /'(u, M ) = 
f(v, u)-g(u, 
v). 
3. For all other edges (u, v) of N, /'(u, i>) =/(u, u). 
In the following, by phase we refer to that part of Dinic's algorithm that 
starts with a flow /, constructs the layered network relative to /, finds a 
maximal flow g in it and augments the flow in the original network to a flow 
/'. Dinic's algorithm may consist of several phases. We now show that the 
number of these phases is bounded by n, the number of vertices in TV. 
Let LN(j) denote the layered network constructed in phase i and /, 
denote the length of LN(i'). 
Lemma 12.4. Consider a directed s-t path P: s = v0, y , , . . . , υ, 
= / in 
LN(/ + 1). Let V, denote the ith layer of LN(i). If every vertex of Ρ appears 
in LN(i), then for all a = 0, 1,2,..., 
υα Ε Vb implies a > b. 
Proof. The result is clearly true for a = 0. Suppose that it is true for v0, 
υ , , . . . , va, and suppose that va+lEVc. 
We need to show that a + 1 s: c. If 
not, then c > a + l. Since by induction va was in layer Vb with a s b, it 
follows that the edge e* = (va, va+i) 
was not in LN(i) since edges in a 
layered network connect vertices in consecutive layers. Hence the flow / in 
e* would not have been altered by the augmenting procedure of phase i. But 
e* is in LN(i + 1). Since at the beginning of phase i + 1, e* was available for 
augmentation, and the flow in e* was not affected by phase i, e* must have 
been available for inclusion in phase i. This is a contradiction and the lemma 
follows. 
• 

408 
FLOWS IN NETWORKS 
Theorem 12.5. li+x 
>/,. 
Proof. Consider a directed s-t path P: s = v0, vx,..., 
υ, 
= t in LN(i + 1). 
Case 1 
Suppose that every vertex of Ρ appears in LN(i). 
Since sink l = D , t i 6 V l , we have, by the previous lemma, ll+x>lr 
If 
Ί+ι
 = h the entire path Ρ is in LN(i) as well as in LN(i + 1), and so none of 
the edges of Ρ were saturated before as well as after the construction of a 
maximal flow in LN(i). This is not possible since a maximal flow in LN(i) 
saturates at least one edge in every s-t path. So 
> /,. 
Case 2 
Suppose that not all of the vertices of Ρ appear in LN(/). 
Let e* = (υα, υα+χ) 
be the first edge of Ρ such that for some b, va G Vb but 
va+x 
is not in LN(i). Thus flow in e* was not affected by augmentations 
during phase i. Since e* was available for inclusion in LN(i +1) at the 
beginning of phase (i + 1), it must have been available for inclusion in 
LN(i'), but it was not included. The only possibility is that va+x 
entered 
LN(i') in the layer υ,, which contains the sink, but this is a special layer and 
contains only t. (Note: υα+χ 
Φ t because va+x is not in LN(/).) So b + 1 = /,. 
By the previous lemma a2b. 
Thus / ι + 1 > β + 1 > 6 + 1 = /„ completing the 
proof for this case. 
• 
Theorem 12.5 means that the length of the layered network increases 
from phase to phase. Since the length of a path is bounded by n, it follows 
that the number of phases in Dinic's algorithm is also bounded by n. 
Using a backtracking algorithm, Dinic has shown that a maximal flow can 
be obtained in 0(mn) time. Since a layered network can be constructed in 
0(m) time, it follows that the complexity of a phase is 0(mn). Since there 
are at most η phases, we have the following. 
Theorem 12.6. Dinic's algorithm is of complexity 0(mn
2). 
• 
12.6 
MAXIMAL FLOW IN A LAYERED NETWORK: 
THE MPM ALGORITHM 
In this section we present yet one more refinement of the maximum flow 
algorithm. This comes from a very simple, elegant, and ingenious algorithm 
of Malhotra, Pramodh-Kumar, and Maheswari [12.8] (MPM) to construct in 
0(n
2) 
time a maximal flow in a layered network. 
Consider a layered network with cf(e) denoting the capacity of edge e in 
the network. The in-potential of a vertex υ is the sum of the capacities of all 
the edges directed into v. The out-potential of ν is the sum of the capacities 

MAXIMAL FLOW IN A LAYERED NETWORK: THE MPM ALGORITHM 
409 
of all the edges directed out of v. The potential of ν is the smallest of these 
two. A vertex with minimum potential is called a reference. 
In the following algorithm a pass refers to the sequence of steps in which 
a reference vertex in the current network is identified, a flow of value equal 
to the potential of the reference vertex r is pushed form ί to ί through the 
current network and a new layered network is constructed (S2 to S4 in the 
algorithm.) 
Algorithm 12.3. Maximal Flow in a Layered Network (Malhotra, 
Pramodh-Kumar, and Maheswari) 
50. Given a layered network, a maximal flow g is required. 
51. Set g(e) = 0 for every edge e in the network. Compute the potential 
of every vertex. Pick a vertex of the smallest potential, say P*. Let 
this vertex be denoted by r. 
52. (Beginning of a pass. Push out P* units of flow from the reference r 
to the sink t.) Let r be in layer /. Push P* units of flow through the 
outgoing edges at r, saturating them one at a time so that at most one 
outgoing edge has flow added to it but remains unsaturated. (Note: 
For pushing the flow the outgoing edges may be selected in any 
arbitrary order.) Every time the flow in an edge is increased, 
decrease its capacity by the same amount. (The edge flows and the 
capacities after each push reflect the latest augmentation of flow in 
the layered network.) 
For each vertex υ' in layer (i +1) do the following. Let h(v') be 
the total flow pushed into υ' from the previous layer in the current 
pass. Now push h(v') units of flow through the outgoing edges at υ', 
saturating them one at a time so that at most one outgoing edge has 
flow added to it but remains unsaturated. Every time the flow in an 
edge is increased, decrease the edge capacity by the same amount. 
Repeat the above for every vertex in the layers i + 2, i + 3 , . . . , 
until the sink t is reached. (Note: The layers should be chosen in the 
increasing order of their numbers. We would never find a vertex of 
insufficient capacity to handle the flow pushed into it because the 
reference r is a vertex of smallest potential). 
53. (Push backward P* units of flow from the reference r to the source s.) 
Push backward P* units of flow through the incoming edges at r, 
saturating them one at a time so that at most one incoming edge has 
flow added to it but remains unsaturated. Every time the flow in an 
edge is increased, decrease the edge capacity by the same amount. 
For each vertex u' in layer i - 1 do the following: Let fc(u') denote 
the total flow pushed out of u' to vertices in the next layer in the 
current pass. Now push backward k(u') units of flow through the 
incoming edges at u', saturating them one at a time so that at most 
one incoming edge has flow added to it but remains unsaturated. 

410 
FLOWS IN NETWORKS 
Every time the flow in an edge is increased, decrease the edge 
capacity by the same amount. 
Repeat the above for every vertex in the layers i - 2, i - 3 , . . . , 
until the source s is reached. 
54. (Prune.) Remove from the layered network all edges with zero 
capacities. Remove every vertex that has had all of its incoming 
edges or all of its outgoing edges removed. (Note: Vertex r will be 
deleted at this point.) Continue this pruning process until only 
vertices that have nonzero potentials remain. (End of the current 
pass.) If no such vertex is present. HALT. (A maximal flow has been 
found.) 
55. Select a vertex of smallest potential in the pruned network. With r 
denoting this vertex and P* denoting its potential, go to S2 (in fact 
repeat S2 to S4). 
• 
Since at least one vertex is removed at each pruning stage, the MPM 
algorithm will terminate. Since at termination every s-t path in the layered 
network has at least one edge e with g(e) = cf(e) the algorithm terminates 
with a maximal flow. 
If pushing flow along an edge saturates the edge, then the push is called a 
saturating push; otherwise it is a nonsaturating push. 
Clearly, the MPM algorithm performs at most m saturating pushes 
because once an edge gets saturated, no more flow is pushed through that 
edge. During each execution of S2 to S4, at most η nonsaturating pushes 
(one per vertex) are performed. Since these steps are repeated at most η 
times, the algorithm performs at most n
2 nonsaturating pushes. Thus at most 
(m + n
2) push operations are performed. Since all other operations can be 
implemented in 0(m) time, it follows that the MPM algorithm has complex-
ity 
0(n
2). 
Thus we have the following complexity result for Dinic's algorithm when 
the MPM algorithm is used to find a maximal flow. 
Theorem 12.7. The complexity of the Dinic-MPM algorithm for the maxi-
mal flow problem is 0(n ) where η is the number of vertices in the transport 
network. 
• 
Prior to the MPM algorithm, Karzanov [12.9] and Cherkasky [12.10] had 
presented algorithms of complexities 0(n
3) 
and 0(n
2m
V2), 
respectively. 
The other algorithms based on Dinic's method include Galil [12.11], Gaul 
and Naamad [12.12], Shiloach [12.13], Sleator [12.14], Sleator and Tarjan 
[12.15], Shiloach and Vishkin [12.16], Gabow [12.17], and Tarjan [12.18]. 
Some of these algorithms are fast on sparse graphs, while the others are fast 
on dense graphs. Algorithms due to Shiloach and Vishkin [12.16] and 
Tarjan [12.18] have both complexity Q(n
3). 
Galil's algorithm [12.11] has 

PREFLOW PUSH ALGORITHM: GOLDBERG AND TARJAN 
411 
12.7 
PREFLOW PUSH ALGORITHM: GOLDBERG AND TARJAN 
Given a transport network Ν = (V, Ε) with η vertices and m edges, it is 
clear from our discussions thus far that an assignment / of nonnegative real 
numbers to the edges of Ν is a maximum flow if and only if / satisfies the 
following: 
1. f(e)s 
c(e), for every e £ £ . 
2. Σ„ /(u, υ) - Συ f(v, u) = 0, for all u<EV. 
3. There is no s-t /-augmenting path. 
All the algorithms (Sections 12.3 to 12.6) based on Ford-Fulkerson's 
work start with an assignment /that satisfies (1) and (2) and terminate with 
an / satisfying (3), always maintaining (1) and (2) at each step of the 
algorithm. In contrast, we develop in this section, an algorithm that starts 
with an assignment / that satisfies (1) and (3) and terminates with an/that 
satisfies (2) always maintaining (1) and (3) at each step in the algorithm. This 
algorithm, due to Goldberg [12.19] and Goldberg and Tarjan [12.20], uses 
the idea of a preflow originally introduced by Karzanov. 
Given a transport network N = (V, E) with η vertices and m edges, a 
pseudo-flow f is an assignment of nonnegative real numbers to the edges of 
TV such that 
f(i,j)^c(i,j) 
for ( / , / ) £ Ε . 
A pseudo-flow / is a preflow if 
e(y)
 = Σ f(u, υ) - Σ f{v, « ) ^ 0 
for every ν Φ s, t. 
U 
u 
And e(v) is refined to as excess at vertex v. Clearly a preflow / is a flow if 
e(v) = 0 for every νΦχ, 
t. 
Given a preflow /, let Nf = (V, Ef) denote the residual network with 
respect to /. Recall that each edge (u, υ)Ε Ε induces an edge (u, υ) ε Ef, if 
/(u, v) < C(M, V), and an edge (v, u) ε Ef if /(u, υ) > 0. Edges of Nf are all 
called residual edges. In the former case (Μ, ν) ε Ef is called a forward edge 
complexity 0(n
5l3m
2li). 
Algorithms due to Galil and Naamad [12.12] and 
Sleator and Tarjan [12.15] have complexities 0(mn(log n)
2) and 0(mn log «), 
respectively. Gabow's algorithm [12.17], based on scaling, is of complexity 
0(mn log U), where U is the maximum of edge capacities assumed to be 
integers. Among the algorithms based on Dinic's method, the only parallel 
algorithm is that of Shiloach and Vishkin, which has a parallel running time 
of 0(/i
2log n) (improved later to 
0(n
2)). 

412 
FLOWS IN NETWORKS 
and in the latter case (v, u)E Ef is a backward edge. As in Section 12.5, 
cf(e) will denote the capacity of the residual edge e: 
A valid labeling d of TV is an assignment of nonnegative integers to the 
vertices of Ν such that d(s) = n, d(t) = 0 and for every residual edge (v, w), 
d(v) £ d(w) + 1. It can be shown that if d(v) < n, then d(v) is a lower bound 
on the distance from ν to t in Nf, and if d(v) a n, then d{y) - η is a lower 
bound on the distance from υ to s in Nf. 
A vertex υ is active \i v^s, 
t, and e(i>) > 0. 
The maximum flow algorithm due to Goldberg [12.19] and Goldberg and 
Tarjan [12.20] starts with the preflow / that is equal to the capacity c(e) on 
every edge e directed away from s, and zero on all other edges, and with 
some initial valid labeling. The simplest choice of a valid initial labeling is 
d(s) = n, and d(v) = 0 for all υ Φ s. The algorithm then repetitively performs 
two basic operations, push and relabel, as described in the following: 
Push (v, w) 
Applicability, 
ν is active, (v, w) Ε Ef and d(v) = d{w) + 1. 
Action. Set δ = min{e(u), cf{v, w)} and do the following: 
1. Increase f{v, w) by δ if (v, w) is a forward edge; otherwise decrease 
f(w, υ) by δ. 
2. Decrease e{v) by δ and increase 8{w) by δ. 
(Note: δ > 0 because both e(v) and cf(v, w) are positive.) 
• 
Relabel (v) 
Applicability, 
ν is active, and for every (v, w) Ε Ef, d(v) s d(w). 
Action. Set d{v) = min ( 0 i M, ) e £ {d(w) + 1}. 
• 
A push from ν to w is a saturating push if cf(v, w) = 0 after the push; 
otherwise it is a nonsaturating push. Note that relabeling of υ sets the label 
of ν to the largest value allowed by the valid labeling constraints. Also, 
immediately after relabeling, a push operation will be applicable along at 
least one edge (v,w)E 
Ef. 
Lemma 12.5. Given a preflow / and a valid labeling d, the following hold 
true: 
1. If ν is any active vertex, then either a push or a relabel operation is 
applicable to v. 
2. The labeling d remains valid after each basic operation (push or 
relabel). 
3. / remains a preflow after each basic operation. 
c(e) - /(e), 
if e is a forward edge ; 
/(e), 
if e is a backward edge . 

PREFLOW PUSH ALGORITHM: GOLDBERG AND TARJAN 
413 
Algorithm 12.4. Generic Maximum Flow Algorithm (Goldberg 
and Tarjan) 
50. Given a transport network N = (V, E), a maximum flow in Ν is 
required. 
51. (Initialize preflow / and valid labeling d) Set 
(i) 
f(s, u) = c(s, u), for every (s, u) e E. 
(ii) f(v, w) = 0, for every (u, w)EE 
with υ Φ s. 
(iii) d(s) = n, and d{v) = 0 for all υ Φ s. 
52. If there is no active vertex, HALT, ( / i s a maximum flow.) 
53. Select an active vertex and apply a basic operation. Go to S2. 
• 
Note that in Algorithm 12.4 the basic operations can be applied in any 
order. Lemma 12.5 guarantees that the algorithm maintains the invariants 
that d is a valid labeling and / is a preflow. Thus this lemma also guarantees 
that S3 of the Algorithm 12.4 will be executed as long as there is an active 
vertex. So, at termination the preflow / i s a flow. Now we need to prove that 
the algorithm terminates in finite time, and that at termination, the flow is 
indeed a maximum flow. First we take up the question of finiteness of the 
algorithm. 
Proof 
1. By definition d(v) < d(w) + 1 for every (i>, w) e Ef. If the push oper-
ation is not applicable to υ, then d(v) < d(w) + 1 for every residual 
edge (v, w). (Note that at least one residual edge (υ, w) will be there 
because υ is active.) Since the labels are integers, d(v) ^ d(w) for all 
these residual edges, and so a relabel operation is applicable to v. 
2. As we pointed out before, a valid labeling d remains valid after a 
relabel operation. Consider then a push operation along an edge 
(u, w)E Ef. This may add edge (w, v) to Nf and may delete (υ, w) 
from Nf. Since d{w) = d(v) - 1, we have d{w) ^ d(v), and so addition 
of (w, v) to Nf does not affect the valid labeling constraint. Deletion of 
(i>, w) from Nf removes the corresponding constraint and so leaves the 
labeling valid. 
3. A relabel operation does not modify the preflow /. Consider then a 
push operation along the residual edge (u, w). This decreases e(v) by δ 
and increases e(w) by the same amount. But 0 < δ < e(v). So both e(v) 
and e(w) remain nonnegative after the push operation and the result 
follows. 
• 
Next we present the following generic maximum flow algorithm due to 
Goldberg and Tarjan. 

414 
FLOWS IN NETWORKS 
Lemma 12.6. If / is a preflow and υ is an active vertex, then, in Nf, the 
source s is reachable from v. 
Proof. Let S denote the set of vertices reachable from ν by directed paths in 
Nf. Suppose that s0S. 
It is clear that there is no edge ( / , e Ef with i £_S 
and / G 5. This means that for every (/,;') ε Ε with i ε S and / ε S, 
f(i, j) = c(i, /), and that for everyji, /) ε Ε with i ε S and ; ε S, f(i, j) = 0. 
In other words f(S, S) > 0 and f(S, S) = 0. So 
2e(i)=f(S, 
5 ) - / ( S , 5 ) < 0 
Since / is a preflow, 
2e(i)>0. 
So E, e se(i) = 0. Since vCS and 
> 0 , it follows that e(J)<0 for some 
i ε 5, contradicting that / is a preflow. 
• 
It is easy to see that the relabel operation applied to a vertex υ increases 
d(v). So for any vertex v, the label d(v) never decreases. In fact we show in 
the following lemma that the labels stay finite during an execution of the 
algorithm. 
Lemma 12.7. At any time during the execution of the generic maximum 
flow algorithm, d(v)s2n 
- 1 for all vEV. 
Proof. Clearly the lemma is trivial for s and t. Since the algorithm changes 
the labels of active vertices only, the result will follow if we show that for 
any active vertex υ, d(v)^2n 
-1. By Lemma 12.6, there exists in Tv^ a 
directed path Ρ from υ to s. Let Ρ: ν = υ0, υχ, υ2,..., 
ν, = s. Since each 
edge (ν,, vi+x) 
on this path is a residual edge and the labeling is a valid one, 
it follows that d(v,)^d(vl+x) 
+ 1 . Therefore, we have d(u) = d(i>0) — 
d(vl) + l<d(s) + n-l 
= 2n-l. 
• 
Since the relabel operation applies only to vertices v¥=s, t and for all 
ν ε V, d(v) never decreases and remains nonnegative during an execution of 
the algorithm, we have the following bound on the total number of relabel 
operations performed by the generic maximum flow algorithm. 
Lemma 12.8. The number of relabel operations performed by the generic 
maximum flow algorithm is at most 2n - 1 per vertex and at most (2n - 1) 
(n - 2) < 2n
2 overall. 
• 
In the following two lemmas we derive bounds on the total numbers of 
saturating and nonsaturating push operations performed by the generic 
maximum flow algorithm. 

P R E F L O W P U S H A L G O R I T H M : G O L D B E R G A N D T A R J A N 
415 
Lemma 12.9. The total number of saturating push operations performed by 
the generic maximum flow algorithm is at most 2mn. 
Proof. Consider an edge (i>, w) Ε Ε. Suppose a saturating push occurs along 
the edge (v, w) Ε Ef. In order for another push to occur along this edge, the 
algorithm must first push flow along the edge (w, υ) E Ef. This cannot 
happen until d(w) increases by at least 2. Thus between any two saturating 
pushes along the edge (v, w)E Ef, d(w) must increase by at least 2. 
Similarly d(v) must increase by at least 2 between any two saturating pushes 
along (w, ν) E Ef. Since, d(v) + d(w) > 1 when the first push occurs, and by 
Lemma 12.8, d(v) + d{w) < An - 3 when the last push occurs, it follows that 
the total number of saturating pushes corresponding to each (v, w) Ε Ε is at 
most 2n - 1 so that the total number of such pushes over all edges in TV is at 
most (2n - l)m < 2nm. 
• 
Lemma 12.10. The total number of nonsaturating push operations per-
formed by the generic maximum flow algorithm is at most 4mn
2. 
Proof. Let 
Φ = Σ d(v). 
^active 
First note that Φ is zero immediately after initialization; Φ is always 
nonnegative, and Φ is zero at termination. So the total decrease in Φ is 
equal to the total increase in Φ. 
Now we have the following important observations: 
1. A saturating push operation may initiate a relabel operation and so 
may cause Φ to increase by at most 2n - 1. So, by Lemma 12.9, the 
total increase in Φ due to saturating push operations is at most 2mn 
( 2 n - l ) . 
2. By Lemma 12.8, the total increase in Φ due to all the relabel 
operations is at most (2M - 1) (n - 2). 
3. A nonsaturating push operation along (v, w) E Ef causes Φ to decrease 
by at least one because this makes ν inactive, and d(w) = d(v) - 1. 
(Note: When υ becomes inactive, w may become active because of the 
push. So in such a case the decrease may be just equal to 1). 
Thus from observations 1 and 2 the total increase in Φ is at most (2n - 1) 
(n - 2) + 2mn (2n - 1) s 4mn
2. So the total decrease in Φ is at most 4mn
2. 
The lemma follows, since by observation 3 the total number of nonsaturat-
ing push operations is no more than the total decrease in Φ. 
• 
Thus we have proved the following. 

416 
FLOWS IN NETWORKS 
Theorem 12.8. The generic maximum flow algorithm terminates after 
0(mn
2) 
basic operations. 
• 
Having proved that the algorithm terminates in finite time, we next prove 
that at termination the preflow is a maximum flow. We do this by showing 
that at no time during the execution of the algorithm, Nf contains a directed 
s-t path. 
Lemma 12.11. Given a preflow / and a valid labeling d, in Nf there is no 
directed s-t path. 
Proof. Assume the contrary and let P: s = v0, υ , , . . . , υ, = t be a directed 
s-t path in Nf. Since the labeling d is a valid one and each edge (v„ vi+x) on 
Ρ is a residual edge, it follows that 
^ d(vl+i) 
+ 1, for all O s f < / . So 
we have d(s) = d(v0)^d(t) 
+l<n 
because d(t) = 0 and / < « . This con-
tradicts that d(s) = n. 
• 
Theorem 12.9. The generic maximum flow algorithm terminates with a 
maximum flow. 
Proof. At termination, e(v) = 0 for all v¥=s, t. So the algorithm terminates 
with a flow /. But Nf has no directed s-t path. In other words there is no 
/-augmenting path in N. So, by Theorem 12.2, / is a maximum flow. • 
The running time of the generic maximum flow algorithm depends on the 
order in which the active vertices are selected for performing the basic 
operations. In any case it is clear that a polynomial time implementation of 
this algorithm is possible. We now proceed to study refined implementations 
of this algorithm and study their time complexities. 
In these implementations we associate with each vertex ν a list L(y) of all 
the edges incident on ν—the edges directed into as well as those directed 
out of v. Thus the edge (v, w) will appear in both the lists L(v) and L{w). 
To begin with, the first edge in L(v) is called the current edge of v. Every 
time we select a vertex ν for a push operation the current edge is the one 
that will be chosen for consideration. Note that the edge (v, w) Ε Ε induces 
a residual edge (υ, w)EEf 
if f(v, w)< c(v, w), and an edge (w, υ) Ε Ε 
induces a residual edge (v, w)EEf 
if f{w, v)>0. 
Also recall that the 
applicability of a push operation at vertex ν is checked with respect to the 
residual edges directed out of v. 
To describe our first refined algorithm we need to describe a new 
operation push/relabel (v). This operation combines the basic operations— 
push and relabel—using the lists L(u)'s. When applied to an active vertex v, 
push/relabel (v) selects the current edge of υ and checks if the correspond-
ing residual edge (υ, w)—called the current residual edge—would permit a 
push operation along (v, w). If the push operation is applicable, then the 

PREFLOW PUSH ALGORITHM: GOLDBERG AND TARJAN 
417 
push/relabel (v) operation is applied to push the excess out of υ along the 
current residual edge. If the push operation is not applicable, then push/ 
relabel (v) advances the current edge to the next edge in L(v). If the current 
edge is the last edge in L(v), no advancing will be possible. In such a case 
the first edge in L(v) will be made the current edge and the relabel 
operation will be applied to v. 
Now we have a formal description of push/relabel (v). 
Push /relabel (u) 
Applicability, 
υ is active. 
Action. Let e = (v, w) be the current edge of v. 
51. If the push operation is applicable along the current edge, 
then apply push(i>, w) and HALT. 
52. If the push operation is not applicable along the current edge 
and if the current edge is not the last edge in L(v), then 
make the next edge in L(v) the current edge and HALT. 
53. If the push operation is not applicable along the current edge 
and if the current edge is the last edge in L(v), then make 
the first edge in L(v) the current edge of v, apply relabel(u) 
and HALT. 
• 
The following lemma shows that the push/relabel operation uses the 
relabel operation correctly. 
Lemma 12.12. The push /relabel operation does a relabeling only when the 
relabeling operation is applicable. 
Proof. Clearly, the push/relabel operation applies the relabeling operation 
at a vertex υ only when υ is active. Consider now a residual edge (υ, w) just 
before relabeling. Let e be the corresponding edge in L(v). Assume that e is 
directed from υ to w. That is, e = (v, w). 
Case 1 
Suppose that when e was the current edge, a push operation was 
not applicable along (u, w). Thus at that time one of the following was true. 
(i) (v, w) was a residual edge and d(v) < d(w) + 1. 
(ii) (υ, w) was not a residual edge (Note: (v, w)0Ef). 
If (i) is true, then at that time d(v) ^ d(w), and this inequality remains true 
at the time of relabeling because d(w) never decreases, and d(v) has not 
changed since e was the current edge. If (ii) is true, then a push operation 
along (w, v) must have been performed to make cf(v, w)>0 
(i.e., to make 
(v, w) a residual edge). This would not be possible until d{w)> d(v). Thus 
in either case d[v) ^ d(w) at the time relabeling is done. 
Case 2 
Suppose that when e was the current edge, a push operation was 
applicable along (υ, w). This means that at that time (v, w) was a residual 

418 
FLOWS IN NETWORKS 
edge and d{v) = d(w) + 1. Now note that when push/relabel (u) chose the 
edge next to e in L(u), one of the following two would have occurred in an 
earlier step: 
(i) d(w) increased and a push along (v, w) was no longer applicable. 
(ii) The residual edge (υ, w) got saturated and it was no longer a residual 
edge. 
If (i) is true, at that time d(v) s d(w), and the inequality remains true at 
the time of relabel because d(v) has not changed during the scan of L(v) and 
d(w) never decreases. If (ii) is true, then a later push along edge (w, v) must 
have occurred making (v, w) a residual edge just before relabeling. When 
such a push occurred d(w) = d(v) + l, and so d(v)^d(w). 
Again this 
inequality remains true at the time of relabel. 
Thus just before the push/relabel (υ) does a relabeling, d(v)^d(w) 
for 
every residual edge (v, w) and so a relabeling is applicable to v. 
The proof in the case e is directed from w to υ follows in a similar 
manner. 
• 
Suppose we define S3' as follows: 
S3'. Select an active vertex υ and push/relabel (u). 
Then replacing, in Algorithm 12.4, S3 by S3', we get a refined algorithm 
whose complexity is derived next. 
Theorem 12.10. The refined algorithm runs in 0(mn) time plus 0(1) time 
per nonsaturating push, for a total of 0(mn
2) 
time. 
Proof. Consider a vertex v^s, 
t. Recall that deg(u) denotes the degree of ν 
(number of edges incident on v). By Lemma 12.7, each vertex will be 
labeled at most 2n - 1 times. Before a relabeling is done by the push/relabel 
(u) operation, one full scan of the edges in the list is required. Relabeling 
itself requires another full scan of the list L(v). Also, one full scan of L(v) 
will be done after the last relabeling of v. Thus at most 4n - 1 scans of L(v) 
will be performed by the algorithm. But each scan of L(v) has complexity 
0(deg(i>)). Thus the total time spent by push/relabel operations selecting υ 
is 0{n deg(u)) plus 0(1) per push. Summing over all the vertices and using 
Lemmas 12.9 and 12.10 we get the desired result (Note: Συ deg(u) = m). 
• 
A further refinement of the basic operations is possible. This involves 
repeated applications of the push/relabel operation to an active vertex until 
e(v) = 0 or d(v) increases. This operation is called the discharge operation. 
Suppose we maintain the active vertices in a list Q such that vertices are 
added at one end and removed from the other end. This will ensure that the 
active vertices added to Q are processed on a "first-in-first-out" (FIFO) 
basis. For this reason Q is called a FIFO queue. 

PREFLOW PUSH ALGORITHM: GOLDBERG AND TARJAN 
419 
Maintaining the active vertices in a FIFO queue and applying the 
discharge operations until Q is empty, we get what is called the FIFO 
algorithm. A formal description of this algorithm follows. 
Algorithm 12.5. FIFO Maximum Flow Algorithm (Goldberg and Tarjan) 
50. Given a transport network TV with source s and sink t, a maximum 
flow in Ν is required. 
51. (Initialize the preflow/, valid labeling d, and the FIFO queue Q). Set 
Add to Q every vertex υ adjacent to s. 
52. If Q = 0 , HALT (a maximum flow has been found). 
53. Remove vertex υ from the front of Q. 
54. Apply push/relabel (v). If a vertex w becomes active during this 
push/relabel, add w to the rear of Q. 
55. If e{v) > 0 and d(v) has not increased, go to S4. 
56. If e{v) > 0 and d(v) has increased, add υ to the rear of Q. 
57. Go to S2. 
• 
Note that the discharge operation consists of repeated applications of S4 
and S5. Also, note that in Algorithm 12.5, once an active vertex is chosen, 
one could go on applying push/relabel until e(v) = 0, instead of putting ν in 
the Q (step S6) if it is still active and is relabeled. However, this will not 
change the complexity. 
To analyze the FIFO algorithm, we need the concept of a pass. The first 
pass consists of applying the discharge operations on the vertices added to Q 
during initialization. Pass (/ + 1), ι s 1 consists of applying discharge oper-
ations on vertices that are added to the queue during pass i. 
Lemma 12.13. The FIFO maximum flow algorithm makes at most 4n
2 
passes. 
Proof. Let d m a x = {d(v)\v is active}. Consider a pass and let ν denote an 
active vertex with d(v) = d m a x at the beginning of the pass. We now have the 
following observations: 
1. Suppose that no label changes during the pass. This means that every 
active vertex considered during the pass successfully pushed out its 
excess. Some of these vertices may become active during later pushes 
c(u. υ), 
if u = s ; 
0, 
otherwise. 

420 
FLOWS IN NETWORKS 
into them during the same pass. But no further push into ν is possible 
during this pass because it has the highest label. So this vertex remains 
inactive even at the end of the pass. Thus dmax decreases during the 
pass. 
2. d m a x does not change during the pass. This means that vertex υ 
becomes inactive during the pass and some other vertex changes its 
label by at least one to restore the value of d m a x. 
3. d m a x increases. Clearly some vertex must increase its label by at least 
as much as d m a x increases. 
From observations (2) and (3) and Lemma 12.8 it follows that the 
number of passes during which d m a x stays the same or increases is at most 
2n
2. Since dmax = 0 at the start of the algorithm and d m a x =Ϊ 0 throughout the 
algorithm, it follows that the number of passes during which d m a x decreases 
is also at most 2n
2. So the total number of passes made by the FIFO 
algorithm is at most An
2. 
• 
Theorem 12.11. The FIFO maximum flow algorithm is of complexity 0(n
3). 
Proof. It is clear that during a pass each vertex v^s, t makes at most one 
nonsaturating push per each vertex. So by the previous lemma the total 
number of nonsaturating pushes during the entire algorithm is 0(n
3). This 
combined with Theorem 12.10 gives the desired complexity result. 
• 
Besides the FIFO strategy for maintaining and selecting active vertices 
for processing, a few other strategies have also been considered. 
The highest label preflow push algorithm selects an active vertex that is 
farthest from the sink. In other words a vertex υ with d(v) = d m a x is selected. 
The LIFO (last-in-first-out) push algorithm maintains all active vertices 
in a stack and selects according to the last-in-first-out rule. 
We next analyze the highest label preflow push algorithm and establish 
that its complexity is 0(n
2Vm). 
We follow Cheriyan and Maheswari [12.21]. 
A push along residual edge (v, w) is a nonzeroing push if this is the first 
push along (υ, w) after a relabel of v. A phase consists of all pushes that 
occur between two consecutive relabel steps. The length /, is the difference 
between d m a x at the start of the phase and d m a x at the end of the phase. Thus 
Σ, /, is the total change in dmax over the entire algorithm. As in the proof of 
Lemma 12.13, it can be shown that Σ, /, = 
0(n
2). 
In order to determine the number of nonsaturating pushes performed by 
the highest label preflow push algorithm, the computation is divided into 
phases. Clearly at any vertex there is at most one nonsaturating push per 
phase. Since there are 0(n
2) phases, the complexity of this algorithm is 
0(n
3). But we can do better than this. 
During a phase, each nonsaturating push leaves behind a current residual 
edge. We can partition these (nonsaturating pushes) edges into what are 

PREFLOW PUSH ALGORITHM: GOLDBERG AND TARJAN 
421 
called trajectories. A trajectory from χ to y is a directed path of current 
residual edges such that (i) no edge on this path corresponds to a saturating 
push or a nonzeroing push and that (ii) the most recent push into χ is either 
a saturating or nonzeroing push. This means that we can associate each 
trajectory with a unique nonzeroing or saturating push. Also it is important 
to note that all the nonsaturating pushes performed by the highest label 
preflow push algorithm are contained in the trajectories. Though the 
partition of nonsaturating pushes into trajectories can be done as the 
algorithm progresses, the partition may not be unique. Furthermore, a 
trajectory may span several phases, that is, it may contain nonsaturating 
pushes from different phases. 
Let us now consider the current residual edges left behind by the 
nonsaturating pushes performed during a phase. These edges constitute a 
directed forest Τ since each vertex has exactly one out-going current residual 
edge. To compute the total number of nonsaturating pushes we now 
proceed as follows. 
A trajectory is short if its length is less than n/Vm; otherwise it is long. A 
push is a short trajectory push if it is contained in a short trajectory; 
otherwise it is a long trajectory push. 
Clearly, over the entire algorithm there are 0(n
2Vrh) 
short trajectory 
pushes, since each trajectory is associated with a unique nonzeroing or 
saturating push, and over the entire algorithm the total number of saturating 
pushes and nonzeroing pushes is 0{mn). 
The long trajectory pushes can be accounted as follows. Consider now 
the forest Τ of current residual edges left behind during a phase, say phase i. 
Since the trajectories that intersect with the edges of Τ (i.e., those trajec-
tories that contain pushes performed during phase i) are edge-disjoint, there 
are at most v m such long trajectories. Thus the contribution of phase i to 
the number of long trajectory pushes is vm/,. Summing this over i and 
recalling that Σ, /, = 0(n
2), 
we see that there are at most nVm 
long 
trajectory pushes performed over the entire algorithm. 
Summarizing, the nonsaturating pushes performed by the highest label 
preflow push algorithm is 
0(n
2Vm). 
Maintaining all active vertices in a list-based bucket data structure, a 
highest label vertex can be picked in constant time. Thus we have the 
following result due to Cheriyan and Maheswari [12.21]. 
Theorem 12.12. The highest label preflow push algorithm has complexity 
0(n
2Vm). 
Μ 
Cheriyan and Maheswari [12.21] have also shown that the LIFO al-
gorithm has complexity 0(mn
2). 
They have defined what is called a maximal 
excess preflow push algorithm and established its complexity as 
0(mn
2). 
They have also demonstrated that the time bounds obtained for all these 
algorithms—the FIFO, the highest label, the LIFO, and the maximal excess 

422 
FLOWS IN NETWORKS 
algorithms—are tight. Using the dynamic tree structure [12.15], Goldberg 
[12.19] and Goldberg and Tarjan [12.20] improved the time bound of the 
preflow push algorithm to 0(mn log n
2/m). Subsequently, Ahuja, Orlin, and 
Tarjan [12.22] obtained an 0(mn log(n/m(log U)
u2 
+ 2)) algorithm using 
scaling and the dynamic tree data structure. (Recall that U refers to the 
maximum of edge capacities assumed to be integers.) This algorithm, which 
is an improved version of an earlier algorithm by Ahuja and Orlin [12.23], 
modifies the push(v, w) procedure (see page 412) so that δ can take on any 
value between 0 and D where D = min{e(u), cf(v, w)}. 
In [12.24] Tuncel provides an alternate proof of the complexity of the 
highest label preflow push algorithm (Theorem 12.12). Interestingly, he 
shows that this complexity result would hold even if the algorithm were to 
send flow over arbitrary admissible edges, not just the current edge. 
In [12.25] Cheriyan and Hagerup have presented a randomized algorithm 
with expected time complexity of 0(min{mn log n, mn + n
2(log n)
2}). 
as 
improved later by Tarjan. In [12.26] Alon gives a derandomization of this 
algorithm, which results in an algorithm of complexity 0(min{mn log n, 
mn + n
8 / 3log n}). Cheriyan, Hagerup, and Melhorn present in [12.27] an 
"incremental" algorithm that runs in 0(/j
3/log n) time. What is significant is 
that they show that the generic algorithm (Algorithm 12.4) can be made to 
work "incrementally," that is, it starts with just the edges leaving the source 
s and as the execution progresses more edges are added gradually to the 
execution subnetwork. 
Goldberg [12.19], Goldberg and Tarjan [12.20], and Cheriyan and 
Maheswari [12.21] also discuss parallel as well as distributed implementa-
tions of the preflow push algorithm. Note that the FIFO algorithm lends 
itself to natural distributed and parallel implementations. 
12.8 
MAXIMUM FLOW IN 0-1 NETWORKS 
A transport network is a 0-1 network if the capacity c(e) = 1 for every edge 
e in the network. A 0-1 network is of type 1 if it has no parallel edges, and 
is of type 2 if, for every vertex υ in the network, either dm(v) = 1 or 
dout(v) 
= 1. These networks arise when network flow techniques are used to 
solve combinatorial problems. (See Sections 12.9 and 12.10.) In view of 
these applications, we study, in this section, the complexity of constructing a 
maximum flow in a 0-1 network. Naturally, one would expect in these cases 
better complexity results than in the case of general networks. This is indeed 
true, as we shall see soon. 
Our discussion here follows the work of Even and Tarjan [12.28]. Thus 
we analyze Dinic's algorithm for its behavior when applied on 0-1 networks. 
It is easy to see that any residual network derived from a 0-1 network is 
also a 0-1 network. Also, a maximal flow in a 0-1 layered network can be 
found in 0(m) time, where m is the number of edges in the network. This is 

MAXIMUM FLOW IN 0-1 NETWORKS 
423 
because all the pushes involved in the application of the MPM algorithm are 
of the saturating type. Thus, Dinic's algorithm is of complexity 0(mri) in the 
case of 0-1 networks. However, we can get better results by improving the 
bound on the number of phases (or layered networks) needed. 
Consider now a 0-1 network Ν = (V, Ε) with η vertices and m edges. For 
a flow / in TV, let Nf = (V, Ef) denote the corresponding residual network. 
Recall that cf(e) denotes the capacity of the edge e in Nf. Also, each edge 
e = (u, v) in TV with /(e) = 0 corresponds to a unique edge e' = (u, v), in Nf 
with cf(e') = 1. If /(e) = 1, then e corresponds to the edge e' = (v, u) with 
cf(e') = 1. In the following we shall denote by Fm the value of a maximum 
flow in Ν and by F'm the value of a maximum flow in Nf. Also, F will denote 
the value of flow /. 
The following two lemmas are crucial for the development of the results 
of this section. 
Lemma 12.14. F'm = Fm- 
F. 
Proof. Consider a set S whh s £ i and tgS. 
Let c((S, S)) denote the 
capacity of thes-r cut (5, 5) in N, and cf((S, S)) denote the capacity of 
the s-t cut (S, S) in Nf. 
Consider an edge e = (u, ύ) in TV with « e S and υ GS. The contribution 
of e to cf((S,lS)) 
is one_ if /(e) = 0, and zero if /(e) = 1. Thus, the 
contribution of e to cf((S, S)) can be expressed as (1 -/(e)). Similarly the 
contribution from an edge e = (u, v) with uES 
and υG5 to cf({S, S) can 
be written as simply /(e). So, we have 
^ « 5 , 5 » = 
Σ 
( 1 - / W ) + 
Σ 
Re) 
e£(S.S) 
ee(S.S) 
= c({S,S))-f(S,'S) 
+ f(S,S) 
= 
c((S,S))-F. 
This implies that a minimum cut in Nf corresponds to a minimum cut in 
N. By the maximum flow minimum cut theorem (Theorem 12.3), the 
capacities of these cuts are, respectively, F'm and Fm. Thus F'm = Fm- 
F. 
• 
Lemma 12.15. Given a transport network N = (V, E) with zero flow on 
every edge, let / denote the length of the corresponding layered network. 
Then 
(i) 
/ < mlFm , 
if Ν is a 0-1 network . 
(ii) 
/ < ( 2 n / F ^
/ 2 ) , 
if TV is a 0-1 network of type 1. 
(iii) 
/ < ( n -2IFm) 
+ 1, 
if Ν is a 0-1 network of type 2 . 
(Note: Fm denotes the value of a maximum flow in N.) 

424 
FLOWS IN NETWORKS 
Proof. Recall that V, denotes the set of vertices in the i'th layer of the 
layered network, and E, denotes the set of edges in Nf directed from the 
vertices in Vf to those in Vi+l. Since/(e) = 0 for every_e e E, it follows that 
£, = ( 5 , 5 ) , where 5 = V0 U V, • · · U V,. So c((5, 5)) = \E,\. Then, by 
Corollary 12.1.1, we have 
Fm*\E,\ 
(12.18) 
With these preliminaries we can now prove the results of the lemma. 
(i) Summing up (12.18) for every i = 1,2,..., /, we get Fm · I < \E\ = m 
and the result follows. 
(ii) Since in a 0-1 network of type 1, there are no parallel edges, each E, 
satisfies 
\E,\^\V,\\Vi+i\. 
(12.19) 
From (12.19) we get, for 1 < / < /, 
F
m*\V,\\V,+x\-
So either |V,| ^ F^
2 or |V; + 1| > F
1^
2. Thus at least L(/ + l)/2j of the 
K/s satisfy | ν ] . | > £ ^
2 . But 
i\V,\ = n. 
So we get 
and the result follows. 
(iii) In case of a 0-1 network of type 2 a maximum flow can be expressed 
as the sum of flows along Fm internally disjoint s-t paths. Since s and 
t are the only two common vertices in these Fm paths we have 
F
m ( A - l ) s « - 2 where λ is the length of a shortest of these paths. 
So λ < (η - 2)/Fm + 1. But / =£ A. Thus, the result follows. 
• 
We are now ready to establish the complexity of Dinic's maximum flow 
algorithm for the different types of 0-1 networks considered in Lemma 
12.15. 
Theorem 12.13. Given a transport network N, the complexity of Dinic's 
maximum flow algorithm is as follows. 

MAXIMUM FLOW IN 0-1 NETWORKS 
425 
(i) 
0(m
312), 
if TV is a 0-1 network . 
(ii) 
0(n
2,3m), 
(iii) 
0(n
ll2m), 
if Ν is a 0-1 network of type 1 . 
if TV is a 0-1 network of type 2 . 
Proof. Consider a transport network TV with flow / of value F. Let Nf denote 
the corresponding residual network. Then, the layered network for TV with 
the flow / is identical to the layered network for Nf with zero flow 
everywhere. Thus, while computing (using Lemma 12.15) the bound for the 
length of the layered network of Ν with flow /, we can use F'm = Fm - F in 
place of Fm. 
This observation plays a key role in the proofs that now follows. We 
prove the results by obtaining an appropriate bound on the number of 
phases Dinic's algorithm would require. 
(i) If Fm < m
1 / 2, the number of phases is bounded by m
1/2 
because by 
Lemma 12.15 the length of any layered network in such a case is at 
most m
1 / 2. Thus the required complexity result follows. 
Suppose Fm>m
112. 
Then consider the phase during which the 
flow reaches Fm- 
m
112. 
If F is the value of the total flow when the 
112 
layered network for this phase is constructed, then F <Fm- 
m 
Also, by Lemma 12.14, for this layered network F'm = 
Fm-F> 
m
1'
2. 
As pointed out at the start of our proof of this theorem, the 
length of this layered network therefore satisfies 
Thus the number of phases up to this point in Dinic's algorithm is at 
most m
1 / 2 - l . The number of additional phases to terminate the 
algorithm is also at most m
1'
2 because the value of a maximum flow 
in subsequent networks is at most m"
2. Thus the total number of 
phases is at most 2m
1 1 2 and the result follows. 
(ii) If Fm s n
2'
3, the result follows from Lemma 12.15 since the number 
of phases required is bounded by n
213. Otherwise, consider the phase 
during which the flow reaches Fm- 
n
213. 
Then the value F of the 
flow when the layered network for this phase is constructed satisfies 
F < Fm — n
213. 
Also, F'm for the corresponding residual network 
satisfies F'm = Fm - F > n
213. 
As observed before, the layered net-
work at this point is identical to the layered network constructed for 
Nf with zero flow everywhere. But Nf may not be a type 1 network. 
It may have parallel edges: if e, = (u, v) and e2 = (i>, u) are two 
edges with /(e,) = 0 and f(e2) = 1, then the corresponding residual 

426 
FLOWS IN NETWORKS 
edges in Nf will be in parallel. But between any two vertices in Nf, 
there will be at most two edges in parallel. So as in the proof of the 
result (ii) of Lemma 12.15, we get 
Thus either |V,| > (F'J2)
1'
2 
or |V,_,| > (F'J2)
U2. 
So, at least [1+1/ 
2J Vj.'s satisfy |V,| 2= (F'J2)
V2. 
Since Σ',=0\V,\< 
η we get 
Since F'm ^ n
2n, 
we get / = 0(n
2n). 
Thus, the number of phases up 
to this point is 0(n
21 
) . Also, the additional phases to completion of 
Dinic's algorithm is at most n
2 / 3 since the value of a maximum flow 
in subsequent networks is at most n
2 / 3. So, the total number of the 
phases required is 0 ( n
2 / 3 ) and the result follows, 
(iii) Given a 0-1 network of type 2 with flow /, we first claim that the 
corresponding residual network is also of type 2. If there is no flow 
through a vertex υ, then all the edges incident on ν in TV will also be 
present in Nf. On the other hand, suppose that the flow through ν is 
1, and this flow enters υ via an edge e, and leaves via an edge e2, 
then the corresponding edges in Nf will have directions opposite to ex 
and e2, respectively. Thus the numbers of incoming edges and 
outgoing edges at ν remain the same in both Ν and Nf. Since Ν is of 
type 2, so is Nf. 
If Fm^n
v2, 
the required result follows from Lemma 12.15 be-
cause the number of phases is bounded by n
112. Otherwise proceed-
ing along the same lines as in the proof of the result (i) of this 
theorem and using the result (iii) of Lemma 12.15 we can show that 
the total number of phases required is 0(n
112). 
The result in this 
case would then follow. 
• 
12.9 
MAXIMUM MATCHING IN BIPARTITE GRAPHS 
In this section we present an application of the maximum flow algorithm in 
solving a combinatorial problem. We show how this algorithm can be used 
to obtain a maximum matching in a bipartite graph. 
Given a bipartite graph G = (V, E) with bipartition (X, Y), let us con-
struct a transport network N = (V*,E*) 
as follows: TV has vertex set 
^Ζΐν,,,ΙΙν,Ι 
for ! = = / < / . 
and so 

MENGERS THEOREMS AND CONNECTIVITIES 
427 
V* = V U {s, r). And TV has a directed edge (s, x) for each χ EX, a directed 
edge (y, t) for each y E Y, and a directed edge (JC, y) for each undirected 
edge (JC, y), χ Ε X, y Ε Y of G. Also c(x, y) = l for every edge in TV. And ί 
and t are, respectively, the source and the sink of N. Clearly TV is a 0-1 
network of type 2. 
Consider now a matching Μ in G. Let us now define a flow / as follows. 
For each (JC, y) Ε Μ, let /(JC, y) = l,f(s, 
x) = l and/(y, t) = 1. Then we can 
see that val(/) = |M|. In other words each matching Μ in G defines a flow 
of value \M\. 
Let / be a flow in Ν of value F. Then there are exactly F edges of the 
form (s, JC) for which /(*, JC) = 1. For each such edge (s, x) there is exactly 
one vertex y Ε Y such that /(JC, y) = 1. Since c(y, r) = 1 and (y, i) is the only 
outgoing edge at y, it follows that /(y, i) = 1 and so there is no JC' Φ χ such 
that /(JC', y) = 1. In other words the edges (JC, y) with /(JC, y) = 1 define a 
matching Μ of cardinality F. 
Summarizing, there is a one-to-one correspondence between the set of 
matchings in G and the set of flows in TV. Thus a maximum matching in G 
corresponds to a maximum flow in N. Since Ν is a 0-1 network of type 2, we 
get the following result from Theorem 12.13. 
Theorem 12.14. A maximum matching in a bipartite graph G = (V, E) with 
η vertices and m edges can be constructed in 0{mn
l 
2) time. 
• 
The above result was also proved in [12.29] by Hopcroft and Karp. Their 
algorithm can also be viewed as one of constructing a maximum flow in a 
0-1 network of type 2 using Dinic's algorithm. A discussion of the theoreti-
cal basis of Hopcroft and Karp's approach may also be found in Swamy and 
Thulasiraman [12.30]. See also Exercise 12.10. 
Generalizing Hopcroft and Karp's approach, Even and Kariv [12.31] 
have developed an 0(n
25) 
algorithm for determining a maximum matching 
in a general graph. Later Micali and Vazirani [12.32], using the same ideas, 
obtained a simplified algorithm of complexity 0(mVn). 
See also Kameda 
and Munro [12.33]. 
For a basic approach to the maximum matching problem see Edmonds 
[12.34]. Gabow [12.35] has given an 0(n
3) 
implementation of Edmonds' 
algorithm. A discussion of this algorithm may also be found in Swamy and 
Thulasiraman [12.30]. For algorithms for the maximum weighted matching 
problem see Edmonds [12.36], Lawler [12.37], Papadimitriou and Steiglitz 
[12.38], Gabow [12.39], and Galil, Micali, and Gabow [12.40]. See also 
Tarjan [12.41] and Melhorn [12.42]. 
12.10 
MENGERS THEOREMS AND CONNECTIVITIES 
In this section we prove Menger's theorems for both directed and undirected 
graphs (Theorems 12.16 through 12.19) using the max-flow min-cut 

428 
FLOWS IN NETWORKS 
1. Let /* be a maximum flow in TV and let N* be the directed graph 
obtained by removing from TV all its /*-zero edges. Since the capacity 
of every edge is unity, it is clear that/*(e) = 1 for every edge e in TV*. 
Thus: 
a. dM - dN.(s) = val(/*) = d-.(t) - 
d;.(t). 
b. d„.(v) = dN.(v) 
for all υ Φ s, t. 
Here άχ.(χ) and d„.(x) denote, respectively, the out-degree and the 
in-degree in the graph TV* of the vertex x. 
Therefore (Exercise 5.8) there are val(/*) edge-disjoint directed s-t 
paths in N* and hence also in N. Thus 
Now let { P u P2,..., 
Pr) be a collection of r edge-disjoint directed s-t 
paths in TV. Define a flow / such that 
Proof 
v a l ( / * ) < r . 
(12.20) 
f(e) = 
1, 
if e is in some P, ; 
0, 
otherwise. 
Clearly, 
val(/) = r. 
Since /* is a maximum flow, we have 
val(/*)>r . 
(12.21) 
Combining (12.20) and (12.21), we get 
val(/*) = r . 
theorem. We may recall that we had stated earlier Menger's theorems, 
without proofs, for undirected graphs (see Theorems 8.9 and 8.12). In the 
following discussions, for the sake of generality, we shall permit the source 
to have nonzero in-degree and the sink to have nonzero out-degree. 
Our proof of Menger's theorems is based on the following result. 
Theorem 12.15. Let Ν be a transport network with source s and sink t and 
in which each edge has unit capacity. Then: 
1. The value of a maximum flow in Ν is equal to the maximum number r 
of edge-disjoint directed s-t paths in N. 
2. The capacity of a minimum cut in Ν is equal to the minimum number 
q of edges whose removal destroys all directed s-t paths in N. 

MENGERS THEOREMS AND CONNECTIVITIES 
429 
2. Let K* = (5, 5) be a minimum s-t cut in N. Suppose we remove from 
Ν the set of edges (S, S). Then in the resulting directed graph there 
will be no directed s-t paths. So 
cap(A:*) = |(S,S)|>c7. 
(12.22) 
Now let Ζ denote a set of q edges whose removal destroys all directed 
s-t paths in N, and let S denote the set of all vertices reachable from s 
by a directed path containing_no edge from Z. Clearly, K= (S,S) 
is 
an s-t cut in N. Further, (S, S) C Z. So, 
cap(A:*)<cap(/Q = \(S, S)\<\Z\ 
= q. 
(12.23) 
Combining (12.22) and (12.23), we get 
cap(K*) = q . U 
Theorem 12.16. Let s and t be two vertices in a directed graph G. Then the 
maximum number of edge-disjoint directed s-t paths in G is equal to the 
minimum number of edges whose removal destroys all directed s-t paths in 
G. 
Proof. From G construct a transport network Ν with s as the source and t as 
the sink by assigning unit capacity to each edge of G. The theorem then 
follows from Theorem 12.15 and the max-flow-min-cut theorem. 
• 
For an undirected graph G, let D(G) denote the directed graph obtained 
by replacing each edge e of G by a pair of oppositely oriented edges having 
the same end vertices as e. It can be easily shown that 
1. There exists a one-to-one correspondence between the paths in G and 
the directed paths in D(G). 
2. For any two vertices s and t, the minimum number of edges whose 
removal destroys all s-t paths in G is equal to the minimum number of 
edges whose removal destroys all directed s-t paths in D(G). 
The undirected version of Theorem 12.16 now follows from the above 
observations. 
Theorem 12.17. Let s and t be two vertices of an undirected graph G. The 
maximum number of edge-disjoint s-t paths in G is equal to the minimum 
number of edges whose removal destroys all s-t paths in G. 
• 
Vertex analogs of Theorems 12.16 and 12.17 are proved next. 
Let s and t be any two nonadjacent vertices in a directed graph G = 
(V, E). From G construct a directed graph G' as follows: 

430 
FLOWS IN NETWORKS 
1. Split vertex vEV- 
{s, t} into two new vertices v' and v" and connect 
them by a directed edge (υ', υ"). 
2. Replace each edge of G having υ £ V - {s, t) as terminal vertex by a 
new edge having υ' as terminal vertex. 
3. Replace each edge of G having υ £ V- {s, t) as initial vertex by a new 
edge having v" as initial vertex. 
A graph G and the corresponding graph G' are shown in Fig. 12.7. It is not 
difficult to prove the following: 
1. Each directed s-t path in G' corresponds to a directed s-t path in G 
that is obtained by contracting all edges of the type (υ', ν"); converse-
ly, each directed s-t path in G corresponds to a directed s-t path in G' 
obtained by splitting all the vertices other than s and t of the path. 
2. Two directed s-t paths in G' are edge-disjoint if and only if the 
corresponding paths in G are vertex-disjoint. 
3. The maximum number of edge-disjoint directed s-t paths in G' is 
equal to the maximum number of vertex-disjoint directed s-t paths in 
G. 
w' 
to" 
z 
ζ" 
Figure 12.7. (a) Graph G. (b) Graph G'. 

MENGERS THEOREMS AND CONNECTIVITIES 
431 
4. The minimum number of edges whose removal destroys all directed 
s-t paths in G' is equal to the minimum number of vertices whose 
removal destroys all directed s-t paths in G. 
From these observations we get the following vertex analog of Theorem 
12.16. 
Theorem 12.18. Let s and t be two nonadjacent vertices in a directed graph 
G. Then the maximum number of vertex-disjoint directed s-t paths in G is 
equal to the minimum number of vertices whose removal destroys all 
directed s-t paths in G. 
• 
The vertex analog of Theorem 12.17 now follows. 
Theorem 12.19. Let s and / be two nonadjacent vertices in an undirected 
graph G. Then the maximum number of vertex-disjoint s-t paths in G is 
equal to the minimum number of vertices whose removal destroys all s-t 
paths in G. 
Proof. Apply Theorem 12.18 to the graph D(G). 
• 
Given an undirected graph G and two nonadjacent vertices s and t, let 
k(S, r) denote the minimum number of vertices whose removal disconnects s 
and t. The observations leading to Theorem 12.19 suggest the following 
algorithm for computing k(S, t). 
First construct the directed graph D(G) as described before. Then 
construct the graph D'(G) (see Fig. 12.7). Assign unit capacity to all the 
edges in D'(G), 
and in the resulting transport network Ν compute the 
maximum flow from s to t. k(S, t) is then equal to the value of this maximum 
flow. 
Since the network Ν is a 0-1 network of type 2 it follows from Theorem 
12.13 that k(S, t) can be computed in 0(mn
v 
). Note that the network has 
at most 2/i vertices and has at most (2m + n) edges, where m and η are, 
respectively, the numbers of vertices and edges of G. 
Recall that the connectivity of an η-vertex complete graph is equal to 
n — l. We now state and prove the correctness of a procedure to compute κ, 
the connectivity of a simple η-vertex undirected graph G = (V, E), which is 
not completely connected. We follow Even [12.43]. The procedure is as 
follows. 
Order the vertices as vx, v2,..., 
vn such that (u,, υ , ) ^ £ for some i Φ 1. 
Compute κ(υχ, ι>;) for every vertex v, such that (vx, 0^0E. 
Let γ be the 
minimum of these values. Repeat this computation with v2, u 3 , . . . , (each 
time updating the value of y) and terminate with vk, once k exceeds the 
current value of γ. 
We now prove that this procedure terminates with y = κ. 

432 
FLOWS IN NETWORKS 
Clearly, after the first computation of κ ( υ π υ,.) for some (υ,, v , ) 0 E , γ 
satisfies 
κ < γ < « - 2 . 
(12.24) 
From this point on, γ can only decrease. 
By definition κ is the minimum number of vertices whose removal 
disconnects two vertices. Let R denote such a set of vertices. Since \R\ = κ, 
at least one of the vertices u,, v2,...,vk 
is not in R. Let u, be one such 
vertex. Then removing from G the vertices in R will separate the remaining 
vertices into at least two sets, such that each path from a vertex of one set to 
a vertex of another passes through at least one vertex of R. Thus there exists 
a vertex υ such that K ( U ( , V) =£\R\ = κ. Therefore γ ^ κ. Thus γ = κ. 
Since each step of this procedure requires at most η maximum flow 
computations, each of complexity 0(n
1/2m), 
and at most κ + 1 steps will be 
performed, it follows that the complexity of this procedure is 
0(κη
3ητή). 
But by Theorem 8.2, κ ^ 2mln. Thus we have the following. 
Theorem 12.20. The complexity of computing the vertex connectivity of an 
undirected graph G is 0(n
ll2m
2), 
where m and η are, respectively, the 
numbers of edges and vertices of G. 
• 
A discussion of implementations that improve on this complexity result 
may be found in Galil [12.44]. For early algorithms to test whether the 
connectivity of an undirected graph is at least k, see Kleitman [12.45], Even 
[12.46], and Galil [12.44]. Recently Cheriyan and Thurimella [12.47] and 
[12.48] and Nagamochi and Ibaraki [12.49] and [12.50] have improved upon 
the complexity of the Λ-vertex connectivity problem. The complexity of their 
algorithms is 0{k
2n
2) 
for k< Vn and 0(k
3n
l 
5 ) , otherwise. Cheriyan and 
Thurimella also present distributed as well as parallel algorithms. 
Recall that in Section 11.8 we discussed an algorithm (based on DFS) to 
test whether a given undirected graph is 2-connected. For an O(n) algorithm 
to test the 3-connectivity of an η-vertex graph, see Hopcroft and Tarjan 
[12.51]. 
As can be seen from the result of Theorem 12.19 edge connectivities of 
an undirected graph G can also be computed using the network flow 
techniques. The corresponding directed graph D{G) will be of type 1. In 
fact, it can be easily shown that edge connectivity computation would 
require at most η - 1 network flow computations. Thus, from Theorem 
12.13, we can show that the complexity of computing the edge connectivity 
of an undirected graph is 0(min{m
3 / 2n, 
n
5/3m}). 
Matula [12.52] has given an 0{mn) edge connectivity algorithm. He has 
also developed (private communication) an 0(n) algorithm that determines 
an edge-cut of cardinality at most 2 + ε times the cardinality of a minimum 
edge-cut. However, these algorithms are not based on network flow tech-
niques. 

NP-COMPLETENESS 
433 
For algorithms for computing connectivities of directed graphs see Even 
[12.43] and Galil [12.44]. Recently Gabow [12.53] has given an algorithm of 
complexity 0(km \og(n
2/m)) 
to test fc-edge connectivity of directed graphs. 
This algorithm obviously extends to undirected graphs too. 
12.11 
NP-COMPLETENESS 
Following Edmonds [12.34], we consider an algorithm for a problem efficient 
if there exists a polynomial p(k) such that an instance of the problem whose 
input length (length of the data describing the instance) is k takes at most 
p(k) 
elementary computational steps to solve. That is, we accept an 
algorithm as efficient only if it is of polynomial-time complexity. Thus all the 
graph algorithms discussed in this book are efficient because they have 
complexities polynomial in m and n, namely, the parameters that reflect the 
length of the data representing the input graph. However, there exists a 
large family of problems that defy polynomial-time algorithms in spite of 
massive efforts to solve them efficiently. This family includes several im-
portant problems such as the travelling salesman problem, the graph 
coloring problem, the problem of simplifying Boolean functions, scheduling 
problems, and certain covering problems. Interestingly, these problems, 
called the NP-complete problems, are tied by a strong structural relation-
ship. // one can find a polynomial-time 
algorithm for an 
NP-complete 
problem, 
then polynomial-time 
algorithms can be found for all the NP-
complete problems. Though the mathematical machinery required to de-
velop the theory of NP-completeness is beyond the scope of this book, we 
attempt in this section a brief introduction to this theory. Our presentation 
follows the elegant and easy-to-read and yet rigorous discussions given by 
Even [12.43] and Wilf [12.54]. 
A decision problem is one that asks only for a yes or no answer. For 
example, the question "Can this graph be 5-colored?" is a decision problem. 
Similarly, the question "Is there a tour of this graph of length less than 20 
miles?" is also a decision problem. Many of the important optimization 
problems can be phrased as decision problems. Usually, if we find a fast 
algorithm for a decision problem, then we will be able to solve the 
corresponding original problem also efficiently. For instance, if we have a 
fast algorithm to solve the decision problem for graph coloring, then by 
repeated applications (in fact, η log η applications) of this algorithm, we can 
find the chromatic number of an η-vertex graph. 
A decision problem belongs to the class Ρ if there is a polynomial-time 
algorithm to solve the problem. A decision problem belongs to the class Ν Ρ 
(nondeterministic polynomial) if there exists a polynomial-time algorithm to 
check the correctness of a claimed answer. The reason for calling such a 
"computation" nondeterministic is that we do not claim to have a (de-
terministic) method to guess the correct answer. We merely say that one 
exists. For example, for the problem "Is it true that TV is not prime?" the 

434 
F L O W S IN N E T W O R K S 
guess is simply a specification of a factor F. We can easily divide TV by F and 
check that the remainder is zero. Thus this problem is in NP. Similarly, the 
decision problems "Can this graph be 
-colored?" and "Is there a tour of 
this graph of length less than 20 miles?" are in NP. 
Summarizing, in Ρ are problems for which it is easy to find a solution, 
and in NP are problems for which it is easy to check a solution that may 
have been very tedious to find. We should emphasize that there are 
problems that are not even known to belong to NP, let alone to P. 
Given two decision problems Q and Q', Q' is quickly reducible to Q if 
whenever we are given an instance /' of the problem Q' we can convert it, 
with only a polynomial amount of work, into an instance / of Q, in such a 
way that /' and I both have the same answer (Yes or No). 
A decision problem is NP-hard if every problem in NP is quickly 
reducible to it. An NP-hard problem Q is NP-complete if Q is in NP. Thus a 
decision problem is NP-complete if it belongs to NP and every problem in 
NP is quickly reducible to it. Thus a fast algorithm for some NP-complete 
problem implies a fast algorithm for every problem in NP. 
The question now is: Is there any NP-complete problem at all? In other 
words, is there a single computational problem with the property that every 
one of the diverse problems in NP is quickly reducible to it? 
In 1971 Stephen Cook [12.55] proved that there is an NP-complete 
problem. The problem is called the satisfiability problem. Cook's work is 
based on the theory of Turing machines. A Turing machine is an extremely 
simple finite-state computer, and when it performs a computation, a unit of 
computational work can be very clearly and unambiguously described. What 
is important is the thesis (called Church's thesis) that a problem can be 
solved by an algorithm if and only if it can be solved by some Turing 
machine that halts for every input. See standard tests such as Minsky [12.56] 
and Hopcroft and Ullman [12.57] for a discussion of Turing machines and 
Church's thesis. 
The satisfiability problem is defined next. Given a finite set X= ( J C , , 
J C 2 , . . . , JC„} °f Boolean variables. A literal is either a variable JC, or its 
complement x,. Thus the set of literals is L = { J C , , J C 2 , . . . , JC„, 3c,, 
xl,..., 
x„). A clause C is a subset of L . The satisfiability problem (SAT) is: 
Given a set of clauses, does there exist a set of truth values (Tor F), one for 
each variable, such that every clause contains at least one literal whose value 
is T. 
Cook's proof that SAT is NP-complete opened the way to demonstrate 
the NP-completeness of a vast number of problems. To prove the NP-
completeness of some problem X that is in NP, it is sufficient to show that 
SAT reduces to X. If that is true, then every problem in NP can be reduced 
to the problem X by first reducing it to an instance of SAT and then to an 
instance of X. 
The second problem to be proved NP-complete is 3-SAT the 3-satis-
fiability problem, which is the special case of SAT in that only three literals 
are permitted in each clause. 

NP-COMPLETENESS 
435 
The list of NP-complete problems has grown very rapidly since Cook's 
work. Karp [12.58] and [12.59] demonstrated the NP-completeness of a 
number of combinatorial problems. Garey and Johnson [12.60] is the most 
complete reference on NP-completeness and is highly recommended. Other 
good textbooks recommended for this study include Horowitz and Sahni 
[12.61], Melhorn [12.42], Aho, Hopcroft, and Ullman [12.62], and Rein-
gold, Nievergelt, and Deo [12.63]. For updates on NP-completeness see the 
articles titled "NP-Completeness: An Ongoing Guide" in the Journal of 
Algorithms. 
Since the concept of reducibility plays a dominant role in establishing the 
NP-completeness of a problem, we shall illustrate this with an example. 
Consider the graph G = (V, E) in Fig 12.8 and the decision problem 
"Can the vertices of G be 3-colored?" We now reduce this problem to an 
instance of SAT. 
We define 12 Boolean variables x
t
; (i = 1, 2, 3, 4; / = 1, 2,3) where the 
variable xt, corresponds to the assertion that "vertex i has been assigned 
color /." The clauses are defined as follows: 
C(i) = {xlA,x,t2,xlt3} 
, 
l s i < 4 ; 
Γ(ί) = {*,,,, * , , 2 } , 
l s / < 4 ; 
tf(0 = {*,.i, * . , 3 > \ 
l s / < 4 ; 
V(i) = {x,,2,x,,3}, 
1 ^ 4 ; 
D(e, j) = {xu y, xuJ, 
for every e = (u, υ) e Ε, 1 =s / < 3 . 
Whereas C(i) asserts that each vertex i has been assigned at least one color, 
the clauses T(i), U(i), and V(i) together assert that no vertex has been 
assigned more than one color. The clauses D(e, ;')'s guarantee that the 
coloring is proper (adjacent vertices have been assigned distinct colors). 
Thus, the graph of Fig. 12.8 is 3-colorable if and only if there exists an 
assignment of truth values Τ and F to the 12 Boolean variables 
JC, 2 , . . . , J C 4 3 such that the each of the clauses contains at least one literal 
whose value is T. 
Figure 12.8 

436 
FLOWS IN NETWORKS 
Now, we are ready to conclude with the following quote from Lawler 
[12.37, page 13] attributed to Vilenkin [12.64, page 11]: 
A mathematician asked a physicist: "Suppose you were given an empty 
teakettle and an unlit gas plate. How would you bring water to boil?" 
"I'd fill the teakettle with water, light the gas, and set the teakettle on 
the plate." "Right," said the mathematician, "and now please solve 
another problem. Suppose the gas were lit and the teakettle were full. 
How would you bring the water to a boil?" "That's even simpler. I'd 
set the teakettle on the plate." "Wrong," exclaimed the mathemati-
cian. "The thing to do is to put out the flame and empty the teakettle. 
This would reduce our problem to the previous problem!" 
That is why, whenever one reduces a new problem to problems already 
solved, one says in jest that one is applying the "teakettle principle." 
12.12 
FURTHER READING 
Standard references on network optimization include Ford and Fulkerson 
[12.3], Lawler [12.37], Papadimitriou and Steiglitz [12.38], Chvatal [12.65], 
and Rockefeller [12.66], For a guided tour of combinatorial optimization 
(through the travelling salesman problem) including approximation al-
gorithms and the theory of NP-completeness, see Lawler, Lenstra, Rinnooy 
Kan, and Shmoys [12.67]. 
For recent work on minimum-cost circulation algorithms, see Goldberg 
[12.19] and Goldberg, Plotkin, and Tardos [12.68]. Goldberg, Tardos, and 
Tarjan [12.69] and Ahuja, Magnanti, and Orlin [12.70] are excellent surveys 
of algorithmic developments on the network flow problem. They also 
contain exhaustive lists of references related to this problem. 
The recent review by Goldberg and Gusfield [12.71] of a Russian book, 
Flow Algorithms by Adel'son-Vel'ski, Dinic, and Karzanov deserves special 
mention. This book published in 1975 has not yet been translated into 
English. Quoting from the review, "this book describes many major results 
obtained in the Soviet Union (and originally published in papers by 1976) 
that were independently discovered later (and in some cases much later) in 
the West." Of special interest to us in the context of discussions in this 
chapter is the fact that Podderyugin published in 1973 an 0(mn) 
edge 
connectivity algorithm. However, Matula's work [12.52] has a stronger 
result. Also, Karzanov, independently of Hopcroft and Karp [12.29], pub-
lished in 1971 the 0(mn
xn) 
bipartite matching algorithm. 
Network flow techniques have been extensively used in formulating and 
solving several important problems. A recent application to systems level 
diagnosis may be found in Sullivan [12.72], 

EXERCISES 
437 
In the past decade considerable progress has been made in parallel and 
distributed computing. Akl [12.73], Quinn [12.74], and Lakshmivarahan and 
Dhall [12.75] are very good references on parallel computing principles. 
They also treat some graph problems. Bertsekas and Tsitsiklis [12.76] give a 
detailed coverage of distributed algorithms for several network optimization 
problems. 
Random graphs play a dominant role in average-case and probabilistic 
analysis of graph algorithms. Two excellent sources of information on 
random graphs are Palmer [12.77] and Bollobas [12.78]. See also Bollobas 
[12.79]. 
12.13 
EXERCISES 
12.1 
Show that if there exists no directed s-t path in a transport network 
N, then the value of a maximum flow and the capacity of a minimum 
cut are both zero. 
12.2 
If (5, 5) and (Τ, T) are minimum cuts in a transport network TV, 
show that (SU T, SL> T) and ( 5 Π Τ, 5 Π Τ) are also minimum 
cuts in N. 
12.3 
Show that in any transport network with integer capacities, there is a 
maximum flow / such that f(e) is an integer for every edge e in N. 
12.4 
Consider a transport network Ν in which each vertex ν Φ s, t is 
associated with a nonnegative integer m(v). Show how a maximum 
flow in which the flow into each vertex υ Φ s, t is not greater than 
m{v) can be found by applying the maximum flow algorithm to a 
modified network. (See the construction used in establishing 
Theorem 12.18.) 
12.5 
Consider a transport network TV in which a lower bound is also 
specified for flow in each edge. 
(a) Find a necessary and sufficient condition for the existence of a 
flow in N. 
(b) Modify the maximum flow algorithm to find a maximum flow in 
N. 
12.6 
Prove that in a transport network with a lower bound for flow in 
each edge, there exists a flow if and only if every edge e is in a 
directed circuit or is in a directed path from s to t or is in a directed 
path from t to s. 
12.7 
Describe a method for locating in a transport network Ν an edge e 
that has the property that increasing its capacity increases the 
maximum flow in N. 

438 
FLOWS IN NETWORKS 
12.8 
Let G = (V, E) be an acyclic digraph. We wish to find a minimum 
number of directed vertex-disjoint paths that cover all the vertices; 
that is, every vertex is on exactly one path. The paths may start 
anywhere and end anywhere, and their lengths are not restricted in 
any way. A path may be of zero length; that is, consist of one vertex. 
(a) Describe an algorithm for achieving this goal and make it as 
efficient as possible. 
(b) Is the condition that G is acyclic essential for the validity of your 
algorithm? Explain. 
(c) Give the best upper bound you can on the time complexity of 
your algorithm 
(Note: This exercise is from Even [12.43].) 
12.9 
This problem is similar to 12.8 except that the paths are not required 
to be vertex (or edge) disjoint. 
(a) Describe an algorithm for finding a minimum number of cover-
ing paths. 
(b) Is the condition that G is acyclic essential for the validity of your 
algorithm? Explain. 
(c) Give the best upper bound you can on the time complexity of 
your algorithm. 
(Hint: 0(\V\-\E\) 
is achievable.) 
(d) Two vertices u and ν are called concurrent if no directed path 
exists from Μ to υ or from υ to u. A set of concurrent vertices is 
such that every two in the set are concurrent. Prove that the 
minimum number of paths that cover the vertices of G is equal 
to the maximum number of concurrent vertices. 
(Note: This exercise is from Even [12.43].) 
12.10 Prove the following results which lead to the complexity 0(n
25) 
of 
Hopcroft and Karp's [12.29] maximum matching algorithm for a 
bipartite graph. 
1. Let Μ and TV be two matchings in a graph G. If \M\ = s and 
\N\ = r with r>s, 
then ΜΦΝ 
contains at least r-s vertex-
disjoint augmenting paths relative to M. 
2. Let Μ be a matching. Let \M\ = r and suppose that the cardinali-
ty of a maximum matching is s. Then there exists an augmenting 
path relative to Μ of length at most 
3. Let Μ be a matching, Ρ a shortest augmenting path relative to M, 
and P' an augmenting path relative to Μ Φ P. Then | P ' | 2 : 
|P| + | P n P ' | . 

REFERENCES 
439 
4. Suppose that we compute, starting with a matching M 0 = 0 , a 
sequence of matchings A/,, M2,..., 
Λί,,..., where M, + 1 = 
Μ, Θ Ρ, and Ρ, is a shortest augmenting path relative to M,. Then 
| Ρ , · Ι ^ Ι Λ
+
1 Ι · 
5. For all i and / such that |P,| = | P j , P, andP, are vertex disjoint. 
6 . Let s be the cardinality of a maximum matching. The number of 
disjoint integers in the sequence |P 0|, | P j , . . . , | P , | , . . . is less 
than or equal to 
2 [ V J J + 2 . (See Swamy and Thulasiraman 
[ 1 2 . 3 0 ] ) 
12.14 
REFERENCES 
12.1 
L. R. Ford and D. R. Fulkerson, "Maximal Flow through a Network," 
Canad. J. Math., Vol. 8, 399-404 (1956). 
12.2 
P. Elias, A. Feinstein, and C. E. Shannon, "A Note on the Maximum Flow 
through a Network," IRE Trans. Information Theory, Vol. IT-2, 117-119 
(1956). 
12.3 
L. R. Ford and D. R. Fulkerson, Flows in Networks, Princeton University 
Press, Princeton, N.J., 1962. 
12.4 
C. Berge, Graphs and Hypergraphs, North-Holland, Amsterdam, 1973. 
12.5 
J. Edmonds and R. M. Karp, "Theoretical Improvements in Algorithmic 
Efficiency for Network Flow Problems," J. ACM, Vol. 19, 248-264 (1972). 
12.6 
N. Zadeh, "Theoretical Efficiency of the Edmonds-Karp Algorithm for 
Computing Maximal Flows," J. ACM, Vol. 19, 184-192 (1972). 
12.7 
E. A. Dinic, "Algorithm for the Solution of a Problem of Maximum Flow in 
a Network with Power Estimation," Soviet Math. Dokl., Vol. 11, 1277-1280 
(1970). 
12.8 
V. M. Malhotra, M. Pramodh-Kumar, and S. N. Maheswari, "An 
0(V
3) 
Algorithm for Maximum Flows in Networks," Information Processing Lett., 
Vol. 7, 277-278 (1978). 
12.9 
Α. V. Karzanov, "Determining the Maximal Flow in a Network by the 
Method of Preflows," Soviet Math. Dokl., Vol. 15, 434-437 (1974). 
12.10 R. V. Cherkasky, "Algorithm of Construction of Maximal Flow in Networks 
with Complexity of 0(V
2VE) 
Operations," Mathematical Methods of Solu-
tion of Economical Problems, Vol. 7, 112-125 (1977) (in Russian). 
12.11 Z. Galil, "An 0(V
5,3E
2'
3) 
Algorithm for the Maximal How Problem," Acta 
Informatica, Vol. 14, 221-242 (1980). 
12.12 Z. Galil and A. Naamad, "An 0(EV
5'
3 
\og
2V) Algorithm for the Maximal 
How Problem," J. Comput. System Sci., Vol. 21, 203-217 (1980). 
12.13 Y. Shiloach, An Ofnllog
2!) Maximum-Flow Algorithm, Technical Report 
STAN-CS-78-802, Computer Science Department, Stanford University, Stan-
ford, Calif., 1978. 
12.14 D. D. Sleator, An Ofnm logn) Algorithm for Maximum Network Flow, 

440 
FLOWS IN NETWORKS 
Technical Report STAN-CS-80-831, Computer Science Department, Stan-
ford University, Stanford, Calif., 1980. 
12.15 D. D. Sleator and R. E. Tarjan, "A Data Structure for Dynamic Trees," J. 
Comput. System Sci., Vol. 26, 362-391 (1983). 
12.16 Y. Shiloach and U. Vishkin, "An 0(n
2 log n) Parallel Max-How Algorithm," 
Journal of Algorithms, Vol. 3, 128-146 (1982). 
12.17 Η. N. Gabow, "Scaling Algorithms for Network Problems," J. of Comput. 
and Sys. Sci., Vol. 31, 148-168 (1985). 
12.18 R. E. Tarjan, "A Simple Version of Karzanov's Blocking Flow Algorithm," 
Operations Research Letters, Vol. 2, 265-268 (1984). 
12.19 Α. V. Goldberg, "Efficient Graph Algorithms for Sequential and Parallel 
Complexity," Ph.D. Thesis, Laboratory for Computer Science, M.I.T., 
Cambridge, Mass., 1987. Also available as Technical Report MIT/LCS/TR-
374. 
12.20 Α. V. Goldberg and R. E. Tarjan, "A New Approach to the Maximum Flow 
Problem," Λ ACM, Vol. 35, 921-940 (1988). 
12.21 J. Cheriyan and S. N. Maheshwari, "Analysis of Preflow Push Algorithms for 
Maximum Network Flows," SIAMJ. Computing, Vol. 18,1057-1086 (1989). 
12.22 R. K. Ahuja, J. B. Orlin, and R. E. Tarjan, "Improved Time Bounds for the 
Maximum Flow Problem," SIAM. J. Computing, Vol. 18, 939-954 (1989). 
12.23 R. K. Ahuja and J. B. Orlin, "A Fast and Simple Algorithm for the 
Maximum Flow Problem," Working Paper, Sloan School of Management, 
M.I.T., Cambridge, Mass. Available as Sloan W.P. No. 1905-87 (revised), 
Oct. 1988 (to appear in Operations Research). 
12.24 L. Tuncel, "On the Complexity of Preflow Push Algorithms for Maximum 
Flow Problems," Technical Report No. 901, School of Operations Research 
and Industrial Engineering, Cornell University, Ithaca, New York, April 1990. 
12.25 J. Cheriyan and T. Hagerup, "A Randomized Maximum Flow Algorithm," 
Proc. 30th Annual IEEE Symp. on Foundations of Computer Science, 1989, 
pp. 118-123. 
12.26 N. Alon, "Generating Pseudo-Random Permutations and Maximum Flow 
Algorithms," Information Processing Letters, 1990. 
12.27 J. Cheriyan, T. Hagerup, and K. Melhorn, "Can a Maximum Flow Be 
Computed in 0(mn) time?," Proc. 17th International Colloquium on Au-
tomata, Languages and Programming, Warwick University, England, July 
1990. (See Springer-Verlag Lecture Notes in Computer Science, No. 443, 
235-248.) 
12.28 S. Even and R. E. Tarjan, "Network Flow and Testing Graph Connectivity," 
SIAM. J. Computing, Vol. 4, 507-518 (1975). 
12.29 J. E. Hopcroft and R. M. Karp, "An n
sn Algorithm for Maximum Matching 
in Bipartite Graphs," SIAM J. Computing, Vol. 2, 225-231 (1973). 
12.30 Μ. N. S. Swamy and K. Thulasiraman, Graphs, Networks and Algorithms, 
Wiley-Interscience, New York, 1981. 
12.31 S. Even and O. Kariv, "An 0(n"
2) 
Algorithm for Maximum Matching in 
General Graphs," Proc. 16th Annual IEEE Symp. on Foundations ofComp. 
Science, 1975, pp. 100-112. 

REFERENCES 
441 
12.32 S. Micali and V. V. Vazirani, "An 0(yf\V\-\E\) 
Algorithm for Finding 
Maximum Matching in General Graphs," Proc. 16th Annual IEEE Symp. on 
Foundations of Comp. Science, 1980, pp. 17-27. 
12.33 T. Kameda and I. Munro, "A 0(\V\ · \E\) Algorithm for Maximum Matching 
of Graphs," Computing, Vol. 12, 91-98 (1974). 
12.34 J. Edmonds, "Paths, Trees and Flowers," Canad. J. Math., Vol. 17, 449-467 
(1965). 
12.35 Η. N. Gabow, "An Efficient Implementation of Edmonds' Algorithm for 
Maximum Matching on Graphs," /. ACM, Vol. 23, 221-234 (1976). 
12.36 J. Edmonds, "Maximum Matching and a Polyhedron with 0, 1 Vertices, "/. 
Res. Nat. Bur. Std., Vol. 69B, 125-130 (1965). 
12.37 E. L. Lawler, Combinatorial Optimization: Networks and Matroids, Holt, 
Rinehart and Winston, New York, 1976. 
12.38 C. H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Al-
gorithms and Complexity, Prentice-Hall, Englewood Cliffs, N.J., 1982. 
12.39 Η. N. Gabow, "Implementation of Algorithms for Maximum Matching on 
Nonbipartite Graphs," Ph.D. Thesis, Dept. of Electrical Engineering, Stan-
ford University, Stanford, Calif., 1973. 
12.40 Z. Galil, S. Micali, and H. Gabow, "Maximal Weighted Matching on 
General Graphs," Proc. 23rd Annual IEEE Symp. on Foundations of 
Computer Science, 1982, pp. 255-261. 
12.41 R. E. Tarjan, Data Structures and Network Algorithms, Society for Industrial 
and Applied Mathematics, Philadelphia, 1983. 
12.42 K. Melhorn, Graph Algorithms and NP-Completeness, Springer-Verlag, New 
York, 1984. 
12.43 S. Even, Graph Algorithms, Computer Science Press, Potomac, Md., 1979. 
12.44 Z. Galil, "Finding the Vertex Connectivity of Graphs," SIAM J. Computing, 
Vol. 9, 197-199 (1980). 
12.45 D. J. Kleitman, "Methods for Investigating Connectivity of Large Graphs," 
IEEE Trans. Circuit theory, CT-16, 232-233 (1969). 
12.46 S. Even, "Algorithm for Determining Whether the Connectivity of a Graph 
Is at Least k," SIAM J. Computing, Vol. 4, 393-396 (1977). 
12.47 J. Cheriyan and R. Thurimella, "Algorithms for Parallel Λ-Vertex Connec-
tivity and Sparse Certificates," Proc. 24th ACM Symp. on Theory of 
Computing (1991). 
12.48 J. Cheriyan and R. Thurimella, "On Determining Vertex Connectivity," 
Technical Report UMIACS-TR-90-79 CS-TR-2485, University of Maryland, 
College Park, Md, June 1990. 
12.49 H. Nagamochi and T. Ibaraki, "Linear Time Algorithms for Finding a Sparse 
Ac-Connected Spanning Subgraph of a Ac-Connected Graph," to appear. 
12.50 H. Nagamochi and T. Ibaraki, "Computing Edge-Connectivity in Multiple 
and Capacitated Graphs," Proc. SIGAL Conference, Lecture Notes in Com-
puter Science, Springer-Verlag, Berlin, August 1990. 
12.51. J. E. Hopcroft and R. E. Tarjan, "Dividing a Graph into Triconnected 
Components," SIAM J. Computing, Vol. 2, 135-158 (1973). 

442 
FLOWS IN NETWORKS 
12.52 D. Matula, "Edge Connectivity in 0(mn) Time," Proc. 28th IEEE Annual 
Symp. on Foundations of Computer Science, Los Angeles, 1987, pp. 249-251. 
12.53 Η. N. Gabow, "A Matroid Approach to Finding Edge Connectivity and 
Packing Arobrescences," Preprint, University of Colorado, Boulder, Co, 
Oct. 1990, Proc. 24th ACM Symp. on Theory of Computing, 1991. 
12.54 H. S. Wilf, Algorithms and Complexity, Prentice-Hall, Englewood Cliffs, 
N.J., 1986. 
12.55 S. A. Cook, "The Complexity of Theorem Proving Procedures," Proc. 3rd 
ACM Symp. on Theory of Computing, 1971, pp. 151-158. 
12.56 M. Minsky, Computation: Finite and Infinite Machines, Prentice-Hall, En-
glewood Cliffs, N.J., 1967. 
12.57 J. E. Hopcroft and J. D. Ullman, Formal Languages and Their Relation to 
Automata, Addison-Wesley, Reading, Mas., 1969. 
12.58 R. M. Karp, "Reducibility among Combinatorial Problems," Complexity of 
Computer Communications, R. E. Miller and J. W. Thatcher, Eds., Plenum 
Press, New York, 1972, pp. 85-104. 
12.59 R. M. Karp, "On the Computational Complexity of Combinatorial Prob-
lems," Networks, Vol. 5, 45-68 (1975). 
12.60 M. R. Garey and D. S. Johnson, Computers and Intractability, A Guide to 
the Theory of NP-Completeness, Freeman, San Francisco, Calif., 1979. 
12.61 E. Horowitz and S. Sahni, Fundamentals of Computer Algorithms, Computer 
Science Press, Potomac, Md., 1978. 
12.62 Α. V. Aho, J. E. Hopcroft, and J. D. Ullman, The Design and Analysis of 
Computer Algorithms, Addison-Wesley, Reading, Mass., 1974. 
12.63 Ε. M. Reingold, J. Nievergelt, and N. Deo, Combinatorial Algorithms: 
Theory and Practice, Prentice-Hall, Englewood Cliffs, N.J. 1977. 
12.64 N. Ya. Vilenkin, Combinatorics (Trans, from Russian by A. Schenitzer and 
S. Schenitzer), Academic Press, New York, 1971. 
12.65 V. Chvatal, Linear Programming, Freeman Press, San Francisco, 1983. 
12.66 R. T. Rockafellar, Network Flows and Monotropic Optimization, Wiley-
Interscience, New York, 1984. 
12.67 E. L. Lawler, J. K. Lenstra, A. H. G. Rinnooy Kan, and D. B. Shmoys, 
Eds., The Travelling Salesman Problem, Wiley-Interscience, New York, 
1985. 
12.68 Α. V. Goldberg, S. A. Plotkin, and E. Tardos, Combinatorial Algorithms for 
the Generalized Circulation Problem, Research Report, Lab. for Computer 
Science, M.I.T., Cambridge, Mass., 1988. 
12.69 Α. V. Goldberg, E. Tardos, and R. E. Tarjan, "Network Flow Algorithms," 
Technical Report #860, School of Operations Research and Industrial 
Engineering, Cornell University, Itaca, N.Y., Sept. 1989. 
12.70 R. K. Ahuja, T. L. Magnanti, and J. B. Orlin, "Network Flows," Working 
Paper, Sloan School of Management, M.I.T., Cambridge, Mass. Available as 
Sloan W.P. No. 2059-88, 1989. 
12.71 Α. V. Goldberg and D. Gusfield, "Book Review: Flow Algorithms by G. M. 
Aderson-VePski, E. A. Dinic and Α. V. Karzanov," Technical Report No. 

R E F E R E N C E S 
443 
STAN-CS-90-1313, Dept. of Computer Science, Stanford University, Stan-
ford, Calif., 1990. 
12.72 G. F. Sullivan, "A Polynomial-Time Algorithm for Fault Diagnosability," 
Proc. 16th Annual IEEE Symp. on Foundations of Comp. Science, 1984, pp. 
148-150. 
12.73 S. G. Akl, The Design and Analysis of Parallel Algorithms, Prentice-Hall, 
Englewood Cliffs, N.J., 1989. 
12.74 M. J. Quinn, Designing Efficient Algorithms for Parallel Computers, 
McGraw-Hill, New York, 1987. 
12.75 S. Lakshmivarahan and S. K. Dhall, Analysis and Design of Parallel Al-
gorithms, McGraw-Hill, New York, 1990. 
12.76 D. P. Bertsekas and J. N. Tsitsiklis, Parallel and Distributed Computation: 
Numerical Methods, Prentice-Hall, Englewood Cliffs, N.J., 1989. 
12.77 E. Palmer, Graphical Evolution: An Introduction to Theory of Random 
Graphs, Wiley-Interscience, New York, 1985. 
12.78 B. Bollobas, Random Graphs, Academy Press, London, 1985. 
12.79 B. Bollobas, Graph Theory: An Introductory Course, Springer-Verlag, New 
York, 1979. 


AUTHOR INDEX 
Aardenne-Ehrenfest, T. van, 144 
Abe, S., 379 
Adams, J. M., 387 
Aho, Α. V., 121, 346, 368, 380, 386-387, 435 
Ahuja, R. K., 422, 436 
Akl, S., 437 
Alagar, V. S., 230 
Allen, F. E., 362, 387 
Alon, N., 422 
Amin, A. T., 230 
Anderson, I., 228 
Appel, Κ. I., 258 
Arlazorov, V. L., 382 
Avis, D., 341 
Balabanian, N., 173 
Bedrosian, S. D., 172 
Behzad, M., 67 
Bellman, R. E., 320 
Belmore, M., 67 
Berge, C, 25-26, 67, 121, 172, 225, 230, 239, 
258-259, 298, 396 
Bermond, J. C, 230 
Bertsekas, D. P., 437 
Bickart, R. Α., 173 
Biggs, N., 172 
Birkhoff, G., 72 
Birkhoff, G. D., 258 
Bland, R. G., 298 
Bock, F. C, 332 
Boesch, F. T., 173, 230, 258 
Boisvert, M., 173 
Bollobas, B., 25-26, 68, 230, 258, 437 
Bondy, J. Α., 25-26, 65, 67-68, 121, 196, 205, 
248, 258, 336 
Booth, K. S., 374 
Bose, Ν. K., 172, 196 
Brooks, R. L., 252 
Brualdi, R. Α., 230 
Bruijn, N. G. de, 114 
Bruno, J., 94, 298 
Camerini, P. M, 332 
Carre, B., 324 
Cartwright, D., 121 
Cayley, Α., 151 
Cederbaum, I., 173, 371, 374, 379 
Chartrand, G., 25, 67-68, 121, 196, 208, 230, 
258 
Chen, W. K., 51, 91, 93, 150, 172-173, 370 
Cheriton, D., 327 
Cheriyan, J., 420-422, 432 
Cherkasky, R. V., 410 
Chiba, N., 379 
Chien, R. T., 51, 173 
Christofides, N., 258, 322 
Chu, Y., 332 
Chua, L. O., 298 
Chung, F. R. K., 230 
Chvatal, V., 63, 68-69, 124, 436 
Coates, C. L., 163 
Cockayne, E. J., 259 
445 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

446 
AUTHOR INDEX 
Cocke, J., 362, 386-387 
Colbourn, C. J., 230 
Cole, R., 342 
Comeau, Μ Α., 322 
Cook, S. Α., 434, 484 
Cummins, R. L., 53, 70 
Dahbura, A. T., 346 
Dantzig, G. B., 324, 380 
Demoucron, G., 374 
Deo, N., 26, 121, 172, 324, 374, 435 
Derigs, V., 341 
Dhall, S. K., 437 
Dijkstra, E. W., 315 
Dinic, Ε. Α., 382, 404 
Dirac, G. Α., 65, 68 
Dreyfus, S. E., 322 
Dror, M., 346 
Duffin, R. J., 298 
Dulmage, A. L., 227 
Dzikiewicz, J., 314 
Eades, P., 379 
Edmonds, J., 211, 297-298, 322, 327, 344, 380, 
401, 427, 433 
Elias, P., 215, 396 
Erbert, J., 373 
Erdos, P., 70, 211, 232, 258 
Eve, J., 383 
Even, S., 342, 371, 374, 379, 388, 422, 427, 
431-433, 438 
Faradzev, I. Α., 382 
Fary, I., 181 
Feick, R., 172 
Feinstein, Α., 215, 396 
Fischer, M. J., 368, 382 
Fleury, 344 
Floyd, R. W., 322 
Folkman, J., 298 
Ford, L. R., 215, 320, 383, 396, 401, 436 
Fournier, J. C, 248 
Frank, H., 230, 258, 322 
Fratta, L., 332 
Fraysseix, H. de, 379 
Frederickson, G. N., 324, 346 
Fredman, M. L., 322 
Frisch, I. T., 230, 258, 322 
Fulkerson, D. R., 215, 298, 383, 396, 401, 436 
Furman, Μ. E., 382 
Gabow, Η. N., 173, 342, 410-411, 427, 433 
Gale, D., 297 
Galil, Z., 410-411, 427, 432-433 
Gallai, T., 70, 211, 232, 243 
Garey, M. R., 230, 380, 435 
Ghouila-Houri, Α., 117 
Goldberg, Α. V., 411-412, 422, 436 
Golomb, S. W., 124 
Golumbic, M. G, 259 
Gordon, M., 322, 383 
Gould, R., 93 
Graham, R. L., 327 
Graver, J. E., 298 
Greene, C, 299 
Greene, D. M, 298 
Gries, D., 307 
Grigoriadis, M. D„ 341 
Gusfield, D., 436 
Hagerup, T., 422 
Haken, W., 258 
Hakimi, S. L., 209, 230, 232 
Hall, P., 218, 327 
Halmos, P. R., 72, 218 
Harary, F., 25, 121, 160, 172, 186-187, 196, 
202, 211, 230, 258, 298 
Havel, V., 209 
Heawood, P. J., 258 
Hecht, M. S., 362, 382, 387 
Hedetniemi, S. T., 259 
Held, M, 67 
Hohn, F. E., 72, 148 
Homobono, N., 230 
Hopcroft, J. E., 121, 342, 354, 362, 368, 374, 
386, 427, 432, 434-436, 438 
Horowitz, E., 368, 435 
Hu, T. C, 322 
Ibaraki, T., 432 
Iri, M, 298 
Ishizaki, Y., 94 
Itai, Α., 336, 342 
Jayakumar, R., 173, 379 
Johnson, D. J3., 322 
Johnson, D. S., 435 
Johnson, E. L., 344 
Kainen, P. C, 258 
Kajitani, Y., 94, 173, 370 
Kalantari, B., 341 
Kameda, T., 427 
Kariv, O., 342, 427 
Karivaratharajan, P., 258 
Karp, R. N., 67, 322, 327, 341, 380, 401, 427, 
435-436, 438 
Karzanov, Α. V., 410, 436 

AUTHOR INDEX 
447 
Kendall, M. G., 121 
Kennedy, K., 386 
Kernighan, B. W., 67 
Kerschenbaum, Α., 327 
Kim, W. H., 51, 173 
Kirchhoff, G., 150 
Kishi, G., 94 
Kleitman, D. J., 209, 211, 213, 232, 432 
Knuth, D. E., 121, 298 
Konig, D., 222, 239 
Koren, I., 374 
Krishnamoorthy, V., 230 
Kronrod, Μ. Α., 382 
Kruskal, J. B., 297, 324 
Kuhn, H. W., 336 
Kuratowski, C, 186 
Kurki-Suonio, R„ 383 
Kwan, M.K., 343 
Lai, C. W., 341 
Lakshmivarahan, S., 437 
Las Vergnas, M., 298 
Lawler, E. L., 67, 298, 322, 370, 427, 436 
Lawrence, J., 298 
Lee, D., 346 
Lehman, Α., 298 
Lempel, Α., 371, 374, 379 
Lengauer, T., 322, 379 
Lenstra, J. K., 67, 346, 436 
Lesniak, L., 25, 68, 121, 196, 230, 258 
Lewis, P. M, 67 
Liao, Y., 322 
Lin, P. M., 94 
Lin, S., 67 
Lipton, R., 389 
Liu, C. L., 26, 66, 258, 261 
Liu, T„ 332 
Lovasz, L., 25-26, 124, 230, 252, 258-259 
Lueker, G. S., 374 
MacLane, S., 72, 188 
Maffioli, F., 332 
Magnanti, T. L., 436 
Maheswari, S. N., 408, 420-422 
Malgrange, Y., 374 
Malhotra, V. M., 408 
Marek-Sadowska, M., 379 
Mason, J. H., 301 
Mason, S. J., 163 
Matula, D., 432, 436 
Maxwell, L. M., 91, 93 
Mayeda, W., 51, 153, 172, 370 
Megiddo, N., 341 
Melhorn, K., 314, 324, 374, 422, 427, 435 
Melnikov, L. S., 252 
Mendelsohn, N. S., 227 
Menger, K., 213 
Meyer, A. R., 382 
Meyniel, M., 123 
Micali, S., 427 
Miller, R. E., 387 
Minieka, E., 322 
Minoux, M., 322, 383 
Minsky, M., 434 
Minty, G. J., 280, 282, 292-293, 299, 303 
Mirsky, L., 230, 298 
Moffat, Α., 324 
Moon, J. W., 115, 121, 151 
Moore, E. F., 320 
Morley, T. D., 298 
Munkres, J., 336 
Munro, I., 383, 427 
Murti, V. G. K., 153 
Murty, U. S. R., 25-26, 68, 121, 196, 248, 258, 
336 
Myers, B. R., 172-173 
Myers, E. W., 173 
Naamad, Α., 410-411 
Nagamochi, H., 432 
Narayanan, H., 298 
Nash-Williams, C. St. J. Α., 53, 68, 121 
Nemhauser, G. L., 67 
Nievergelt, J., 121, 374, 435 
Nishioka, 1., 379 
Nishizeki, T., 379 
Norman, R. Z., 121 
Ohtsuki, T., 94 
O'Neil, E. J., 383 
O'Neil, P. E., 383 
Opatrny, J., 230 
Ore, O., 65, 69-70, 196, 222, 258 
Orlin, J. B., 422, 436 
Orloff, C. S., 346 
Otten, R. H. J. M., 379 
Overbeck-Larisch, M., 123 
Ozawa, T., 379 
Palmer, Ε. M., 172, 437 
Pan, Α., 322 
Pang, C. Y., 324 
Papadimitriou, C. H., 298, 327, 346, 427, 436 
Parsons, T. D., 196 
Parthasarathy, K. R., 259 
Perfect, H., 230 
Pertuiset, R., 374 
Petersen, B., 298 

448 
AUTHOR INDEX 
Peyrat, C, 230 
Phelan, J. M., 387 
Pierce, A. R., 324 
Plotkin, S. Α., 436 
Polimeni, A. D., 68 
Posa, L., 65 
Powell, Μ. B., 260 
Prabhu, Κ. Α., 196 
Pramodh Kumar, M., 408 
Prim, R. C, 302, 325-326 
Priifer, H., 151 
Pullman, N. J., 121 
Purdom, P., 383 
Quinn, M., 437 
Rado, R., 223, 297-298 
Randow, Rabe von, 298 
Rao, K. S., 153 
Rao, V. V. B., 153, 173 
Ravindra, G., 259 
Read, R. C, 258 
Recski, Α., 298 
Reed, Μ. B., 43-44, 51, 172, 196 
Reingold, Ε. M., 121, 374, 435 
Rinnooy-Kan, A. H. G., 67, 346, 436 
Robert, F. S., 173 
Robert, J., 121 
Robichaud, L. P. Α., 173 
Rockefeller, R. T., 436 
Rodeh, M., 336 
Rose, D. J., 38 
Rosenkrantz, D. J., 67 
Rosenstiehl, P., 379 
Rubin, F., 374 
Saaty, T. L., 258 
Sahni, S., 368, 435 
Schaefer, M, 386 
Schnorr, C. P., 383 
Seshu, S., 43, 51, 172, 196 
Shamir, Α., 342 
Shank, H., 70 
Shannon, C. E., 215, 396 
Shiloach, Y., 410 
Shinoda, S., 370 
Shirakawa, 1., 379 
Shmoys, D. B., 67, 436 
Sleator, D. D., 410-411, 440 
Spira, P. M, 322 
Srinivasan, N., 230 
Stark, R. H., 387 
Stearns, R. E., 67 
Steiglitz, K., 298, 427, 436 
Stein, S. K, 181 
Stern, H., 346 
Stewart, M. J., 68 
Strassen, V., 382 
Sullivan, G. F., 436 
Sun, F. K., 172 
Swamy, Μ. N. S., 26, 51, 96, 109, 172-173, 
230, 379, 427, 439 
Syslo, Μ. M., 314 
Szekeres, G., 261 
Tabourier, Y., 324 
Takahashi, H., 379 
Takoka, T., 324 
Tamassia, R., 379 
Tamir, Α., 341 
Tanimoto, S. L., 336 
Tardos, E., 436 
Tarjan, R. E., 324, 327, 332, 354, 362, 368, 
370-371, 374, 379, 386, 389, 410-412, 422, 
427, 432, 436 
Thomas, R. E., 230 
Thulasiraman, K„ 26, 51, 96, 109, 172-173, 
230, 258, 322, 379, 427, 439 
Thurimella, R., 432 
Toida, S., 68 
Tomizawa, N., 298 
Trudeau, P., 346 
Tsitsiklis, J. N., 437 
Tucker, Α., 259 
Tuncel, L., 422 
Turan, P., 258, 259 
Tutte, W. T„ 53, 155, 186-187, 197, 214, 228, 
258, 285, 298-299, 389 
Ueno, S., 173 
Ullman, J. D., 121,362,368, 380, 382,386-387, 
389, 434-435 
Uyar, M. U., 346 
Valdes, J., 370 
Vandewalle, J., 298 
van Slyke, R., 327 
Vaughan, Η. E., 218 
Vazirani, V. V., 427 
Vilenkin, Ν. Y., 436 
Vishkin, U., 410 
Vizing, V. G., 246, 248, 252, 260 
Wagner, K., 181, 187 
Wagner, R. Α., 322 
Wang, D. L., 209, 211, 213, 232 
Warren, H. S., 307, 312, 314 
Warshall, S., 307 

Watanabe, Η., 94 
Watkins, Μ., 298 
Weinberg, L., 94, 298 
Welsh, D. J. Α., 260, 287, 297-298, 300 
White, G. P., 324 
Whitney, H., 21, 25, 53, 182, 188, 192, 196, 
214, 258, 265, 276, 298, 300 
Wijk, J. C. van, 379 
Wilf, H. S„ 261, 433 
Williams, Τ. Α., 324 
Williams, T. W., 91, 93 
Wilson, R. J., 26, 233, 298, 302, 344 
Wimer, S., 374 
AUTHOR INDEX 
449 
Wolaver, D. H., 298 
Wong, C. K., 322 
Wood, D. C, 258 
Woodall, D. R., 123 
Yannakakis, M., 327 
Yao, A. C, 327 
Yasuda, T., 370 
Yen, J. Y., 324 
Youla, D. G, 173 
Zadeh, N., 404 


SUBJECT INDEX 
Abelian group, 73 
Ackermann's function, 368 
Acyclic graph, 31 
directed, 100 
Adjacency list, 347 
Adjacency matrix: 
of directed graph, 159 
of weighted directed graph, 163 
Adjacent edges, 2, 98 
Adjacent vertices, 2, 98 
Algorithm(s): 
biconnectivity, 356 
breadth-first search, 381 
Chinese postman tour, 344 
connectivity, 427-433 
depth-first search of directed graph, 351 
depth-first search of undirected graph, 348 
Dinic's maximum flow, 404-408 
Dinic-MPM maximum flow algorithm, 
404-410 
Edmonds and Karp's modification of 
labeling algorithm, 400-404 
Euler trail, 345 
FIFO maximum flow, 419 
generic maximum flow (Goldberg and 
Tarjan), 413 
graphs with prescribed degrees, 209-213 
greedy, 294 
greedy coloring, 260 
highest label preflow push, 420-421 
layered network, 406 
LIFO preflow push, 420 
maximal excess preflow push, 421 
maximal flow in a layered network, 409-410 
maximum bipartite matching, 426-427 
maximum flow in transport network (labeling 
algorithm), 397 
maximum flow in 0-1 networks, 422-426 
minimum weight spanning tree, 325-326 
optimal assignment, 339 
optimum branching, 332 
path finding, 372 
perfect matching, 335 
planarity testing, 378 
program graph reducibility, 366 
shortest paths between all pairs of vertices, 
323 
shortest paths from a specified vertex to all 
vertices, 318-320 
i/-numbering, 372 
strong connectivity, 360 
timetable scheduling, 341-342 
transitive closure, 310-312 
All-vertex incidence matrix: 
of directed graph, 126 
of undirected graph, 126 
Alternating chain (with respect to a matching), 
224 
Alternating sequence (relative to an 
independent set), 239 
maximal, 239 
Λί-AIternating tree, 334 
451 
Graphs: Theory and Algorithms 
by K. Thulasiraman and M. N. S. Swamy 
Copyright © 1992 John Wüey & Sons, Inc. 

452 
SUBJECT INDEX 
Ancestor (of a vertex), 349 
proper, 349 
Arborescence, 106 
Arc coloring lemma, 122, 292 
Associated directed graph, 231 
Associative property, 72 
Augmentation theorem, 269 
Augmenting path (relative to a matching), 226 
/-Augmenting path, 394 
Back edge, 347, 351 
Backward edge, 394 
Backward labeling, 397 
Base axioms for matroid, 273 
Base in matroid, 266 
Base orderable matroid, 301 
Basis of vector space, 76 
Basis vectors, 76 
Bellman-Ford-Moore algorithm, 320 
Berge's (alternating chain) theorem, 225 
Biconnected component, 354 
Biconnectivity algorithm, 356 
Binary: 
matroid, 287 
relation, 104 
Binary tree, 108 
Binet-Cauchy theorem, 148 
Bipartite graph, 16 
Bipartite matroid, 301 
Bipartition, 16, 239 
Block of graph, 19 
Bond matroid, 267 
Bottleneck, 401 
Branch, 31 
Branching, 327 
algorithm, 332 
optimum, 327 
Breadth-first search algorithm, 381 
Bridge, 28 
Brooks' theorem, 252 
Bush form, 376 
Capacity: 
of cut, 392 
of edge, 391 
Capacity constraint, 391 
Cayley's theorem, 150 
Center, 53 
Cheriyan and Maheswari's maximum flow 
algorithm, 420-421 
long trajectory push in, 421 
phase in, 420 
short trajectory push in, 421 
Chinese postman tour: 
algorithm, 344 
problem, 343 
rural, 346 
Chord, 31 
jfc-Chromatic graph, 251 
Chromatic index, 245 
Chromatic number, 251 
Chromatic polynomial, 254 
Circuit(s): 
axioms for matroid, 275 
directed, 100 
in directed graph, 100 
directed Hamilton, 115 
edge, 8 
even,8 
fundamental, 41 
fundamental set of, 41 
in graph, 8 
Hamilton, 62 
length of, 8 
matroid, 266 
in matroid, 266 
odd, 8 
subspace, 82 
vector, 134 
weight of, 67 
Circuit matrix, 134 
of directed graph, 134 
fundamental, 135 
of matroid, 289 
of undirected graph, 134 
Class NP, 433 
Class P, 433 
Clique, 262 
Closed set: 
in matroid, 299 
relative to binary relation, 72 
(n + l)-CIosure, 70 
Closure of graph, 69 
Coates' flow graph, 164 
Coates' gain formula, 167 
Coates' graph, 164 
Coates' method, 163 
Cobase in matroid, 277 
Cocircuit, 277 
fundamental, 278 
matrix, 286 
Code-optimization problem, 362 
Co-forest, 40 
Cographic matroid, 268 
Collapsing a vertex, 362 
Coloop in matroid, 277 

SUBJECT INDEX 
453 
Column-oriented, 310 
Commutative property, 73 
Complement: 
of simple graph, 6 
of subgraph, 7 
Complete bipartite graph, 16 
Complete directed graph, 115 
Complete graph, 16 
Complete matching (in bipartite graph), 216 
Complete λ-partite graph, 16 
Completely scanned, 347 
Component(s): 
biconnected, 354 
of directed graph, 100 
even, 228 
of graph, 9 
odd, 228 
Condensed graph, 101 
Condensed image, 101 
Connected directed graph, 100 
Connected graph, 9 
Λ-Connected graph, 201 
Connected matroid, 300 
Connected vertices, 9 
Connectivity, 200 
algorithms, 427-433 
edge, 207 
vertex, 200 
Conservation condition, 391 
Contractible, 15 
Contraction: 
of edge, 15 
of graph, 282 
of matroid, 284 
Coordinates of vector, 78 
Corank function of matroid, 277 
Cospanning tree, 31 
Cospanning k-tree, 38 
Critical edge, 327 
Critical subgraph, 327 
Cross edge, 349, 351 
Crossing number, 196 
Cubic graph, 27 
Cut, 44 
capacity of, 392 
directed, 122 
matrix, 130 
minimum, 394 
vector, 130 
Cut matrix, 130 
of directed graph, 130 
of undirected graph, 130 
Cutset(s), 42 
fundamental, 46 
fundamental set of, 46 
matroid, 267 
subspace, 85 
Cut-vertex, 19 
splitting, 23 
Dantzig's algorithm, 380 
Dark edge, 224 
de Bruijn sequence, 111 
Decision problem, 433 
Class NP, 433 
Class P, 433 
Deficiency, 217 
Degree: 
of region, 184 
of vertex, 2, 98 
Degree matrix, 150 
Degree sequence, 63 
Dependent set in matroid, 266 
Depth-first number, 347 
Depth-first search algorithms, 348, 351 
for directed graph, 351 
for undirected graph, 348 
Descendant (of vertex), 349 
proper, 349 
DFS tree, 347 
Diameter, 8 
Dijkstra's algorithm, 318 
Dimension of vector space, 76 
Dinic's maximum flow algorithm, 404-408 
phase in, 407 
Dinic-MPM maximum flow algorithm, 404-410 
Directed circuit, 100 
Directed cut, 122 
Directed Eulerian graph, 110 
Directed Euler trail, 110 
open, 110 
Directed graph, 1, 97 
Directed Hamilton circuit, 115 
Directed Hamilton path, 115 
Directed Hamiltonian graph, 115 
Directed path, 100 
Directed spanning tree, 108 
Directed trail, 100 
closed, 100 
open, 100 
Directed tree, 106 
Directed walk, 99 
closed, 99 
open, 99 
Direct sum of subspaces, 76 
Discharge operation, 418 

454 
SUBJECT INDEX 
Disconnected matroid, 300 
Disconnecting set, 201 
Distance: 
between spanning trees, 93 
between vertices, 8 
Dominating set, 258 
Dot product of vectors, 79 
Doubly stochastic matrix, 232 
Dual matroid(s), 277 
Dual of graph, 188 
Edge(s), 1, 97 
adjacent, 2, 98 
back, 347, 351 
backward, 394 
circuit, 8 
critical, 327 
cross, 349, 351 
current, 416 
current residual, 416 
eligible, 328 
forward, 350, 394 
independent, 216 
noncircuit, 8 
parallel, 1, 98 
pendant, 3 
residual, 411 
tree, 347, 351 
virtual, 375 
fc-Edge chromatic graph, 245 
Edge chromatic number, 245 
Λ-Edge colorable graph, 245 
yt-Edge coloring, 245 
optimum, 247 
proper, 245 
λ-Edge connected: 
directed graph, 231 
graph, 207 
Edge connectivity, 207 
Edge cover, 243 
minimum, 243 
Edge covering number, 243 
Edge-disjoint graphs, 23 
Edge-induced subgraph, 5 
Edge-removal, 13 
Edmonds and Johnson's Chinese postman tour 
algorithm, 344 
Edmonds and Karp's modification of labeling 
algorithm, 400-404 
Edmonds and Karp's theorem on labeling 
algorithm, 403 
Edmonds' optimum branching algorithm, 332 
Edmonds' theorem on A-edge connectivity, 212 
Eligible edge, 328 
Embeddable, 179 
Empty graph, 2 
End vertex: 
of directed walk, 99 
of edge, 1, 98 
of walk, 7 
Equality subgraph, 338 
Equi-cofactor matrix, 150 
Equivalence: 
classes, 104 
relation, 104 
Euler trail, 57 
directed, 110 
open, 57 
open directed, 110 
Euler trail algorithm, 345 
Eulerian graph, 57 
directed, 110 
randomly, 61, 62 
Eulerian matroid, 301 
Euler's formula, 184 
Even and Tarjan's analysis of maximum flow 
algorithms, 422-426 
Even and Tarjan's s/-numbering algorithm, 372 
Examine (an edge in a DFS), 346 
Extremal graph theory, 258 
A:-Factor, 233 
Ar-Factorable graph, 233 
1-Factorial connection in directed graph, 164 
1-Factor in directed graph, 160 
Father (of vertex), 346, 349 
Feasible vertex labeling, 338 
Feedback loop, 171 
Feedback path, 171 
Field, 73 
Five-color theorem, 257 
Fleury's algorithm, 345 
Flow, 391 
blocking, 407 
maximal, 407 
maximum, 392 
maximum algorithms, 390-426 
pre-, 411 
pseudo-, 411 
Floyd's algorithm, 323 
Ford-Fulkerson's maximum flow algorithm, 
397 
Forest, 40 
Forward edge: 
relative to DFS, 350 
relative to directed path, 394 
Forward labeling, 397 
Forward path, 171 

SUBJECT INDEX 
455 
Four-color conjecture, 258 
Four-color problem, 257 
Four-color theorem, 258 
Fundamental circuit, 41 
matrix, 135 
matrix of matroid, 288 
in matroid, 271 
Fundamental cocircuit, 278 
matrix, 288 
Fundamental cutset, 46 
matrix, 133 
Fundamental set of circuits, 41 
Fundamental set of cutsets, 46 
Gale optimal, 295 
Galois field, 74 
Gammoid, 301 
Girth, 27 
Goldberg and Tarjan's maximum flow 
algorithm, 411-420 
Graph(s), 1 
acyclic, 31 
associated directed, 231 
bi-connected, 22 
bipartite, 16 
A-chromatic, 251 
Coates, 164 
complete, 16 
complete bipartite, 16 
complete directed, 115 
complete fc-partite, 16 
connected, 9 
2-connected, 22 
A;-connected, 201 
connected directed, 100 
cubic, 27 
directed, 1, 97 
directed acyclic, 100 
directed Eulerian, 110 
directed Hamilton connected, 123 
directed Hamiltonian, 115 
λ-edge chromatic, 245 
k-edge colorable, 245 
A-edge-connected, 207 
Λ-edge-connected directed, 231 
edge-disjoint, 23 
empty, 2 
Eulerian, 57 
^-factorable, 233 
Hamilton connected, 70 
Hamiltonian, 62 
homeomorphic, 186 
isomorphic, 23 
1-isomorphic, 23 
2-isomorphic, 23 
Kuratowski's, 182 
Mason, 169 
maximal planar, 197 
minimally connected, 52 
minimally connected directed, 102 
nonoriented, 1 
nonseparable, 19 
null, 2 
one-terminal-pair, 198 
oriented, 1 
parallel combination of, 98 
A-partite, 16 
perfect, 259 
Peterson, 187 
planar, 179 
planar one-terminal-pair, 198 
program, 361 
quasi-strongly connected, 103 
randomly Eulerian, 61, 62 
randomly Hamiltonian, 67 
reducible program, 362 
reflexive directed, 105 
regular, 16 
r-regular, 16 
self-complementary, 27 
self-dual, 198 
separable, 19 
series combination of, 198 
series-parallel, 198 
simple, 1 
i/-numbering of a, 370 
strongly connected, 100 
symmetric directed, 105 
transitive directed, 105 
trivial, 19 
underlying undirected, 99 
undirected, 1 
A-vertex colorable, 251 
vertex-disjoint, 23 
weighted, 175 
Graphic matroid, 268 
Graphic sequence, 63 
Graphoid, 280 
Greedy algorithm, 294 
Greedy coloring algorithm, 260 
Group, 73 
Hall's theorems, 218-219 
Hamilton circuit, 62 
directed, 115 
Hamilton connected: 
directed graph, 123 
graph, 70 

456 
SUBJECT INDEX 
Hamiltonian graph, 62 
directed, 115 
randomly, 67 
Hamilton path, 62 
directed, 115 
HIGHPTdO, 365 
Homeomorphic graphs, 186 
Hopcraft and Tarjan's algorithms, 354, 388 
Hungarian tree, 334 
Hyperplane, 300 
Identifying vertices, 15 
Identity of group, 73 
Improvement on edge coloring, 248 
Incidence matrix, 128 
Incidence set, 94 
Incidence vector, 127 
Incident into, 98 
Incident on, 2, 98 
Incident out of, 98 
In-degree, 98 
matrix, 155 
Independence axioms for matroid, 266, 272 
Independence number, 236 
Independent edges, 216 
Independent set(s): 
of graph, 124, 236 
of matroid, 266 
maximum, 236 
Induced subgraph, 5, 99 
In-going directed tree, 175 
root of, 175 
Initial vertex: 
of directed walk, 99 
of walk, 7 
Inner product, 79 
Internal vertex, 7, 99 
Intersection of graphs, 11 
Interval analysis, 362 
Inverse of element in group, 73 
Isolated vertex, 3, 98 
Isomorphic: 
graphs, 23 
matroids, 268 
vector spaces, 78 
1-Isomorphic graphs, 23 
2-Isomorphic graphs, 23 
Konig-Egervary theorem, 223 
Konigsberg bridge problem, 55 
Konig's theorem, 222 
Kruskal's algorithm, 325 
Kuhn-Munkres algorithm, 339 
Kuratowski's graphs, 182 
Kuratowski's theorem, 186 
Label of vertex, 338 
Labeled trees, 150 
Labeling algorithm, 39 
Layered network, 406 
algorithm, 406 
blocking flow in a, 407 
layers of, 406 
length of, 406 
maximal flow in a, 407 
maximal flow in a, algorithm, 409-410 
Leaf, 106 
Left (of vertex), 349 
Lempel, Even and Cederbaum's planarity 
testing algorithm, 378 
Length: 
of circuit, 8 
of edge, 314 
of path, 8 
Lexicographically greater, 295 
Lexicographically maximum, 295 
Light edge, 224 
Linear combination, 76 
Linearly independent vectors, 76 
Link, 31 
Loop in matroid, 266 
LOWXf), 355 
LOWLINK(y), 358 
Major, 147 
Major determinant, 147 
Majorise, 63 
Malhotra, Pramodh Kumar and Mahaswari's 
algorithm, 409-410 
Marriage problem, 215 
Mason graph, 169 
Mason's gain formula, 171 
Mason's method, 168 
Mason's signal flow graph, 169 
Matched into, 216 
Matching, 216 
bipartite, algorithm, 426-427 
complete, 216 
matroid, 267 
maximum, 216 
number, 216 
optimal, 336 
perfect, 228 
(0,1) Matrix, 223 
Matroid(s), 266 
base axioms for, 273 
base in, 266 

SUBJECT INDEX 
457 
base orderable, 301 
binary, 287 
bipartite, 301 
bond, 267 
circuit, 266 
circuit axioms for, 275 
circuit in, 266 
circuit matrix of, 289 
closed set in, 299 
closure in a, 299 
cobase in, 277 
cocircuit in, 277 
cocircuit matrix of, 289 
cographic, 268 
coloop in, 277 
connected, 300 
contraction of, 284 
corank function of, 277 
cutset, 267 
dependent set in, 266 
disconnected, 300 
dual of, 277 
elements of, 266 
Eulerian, 301 
Fano, 301 
fundamental circuit in, 271 
fundamental circuit matrix of, 286, 288 
fundamental cocircuit in, 278 
fundamental cocircuit matrix of, 286, 288 
graphic, 268 
hyperplane in, 300 
independence axioms for, 266, 272 
independent sets of, 266 
isomorphic, 268 
loop in, 266 
matching, 267 
minor of, 285 
nonseparable, 300 
orientable, 292 
rank axioms for, 274 
rank function of, 266 
rank in, 266 
rank of, 266 
regular, 298 
representable, 286 
restriction of, 284 
separable, 300 
standard representation of, 286 
transversal, 300 
uniform, 299 
union of, 301 
Max-flow min-cut theorem, 396 
Maximal planar graph, 197 
Maximal subgraph, 5 
Maximal subset, 5 
Maximally distant spanning trees, 93 
Mendelsohn and Dulmage's theorem, 227 
Menger's theorems, 213-215 
proof of, 427-431 
Mesh, 183 
Minimal subgraph, 5 
Minimal subset, 5 
Minimally connected: 
directed graph, 102 
graph, 52 
Minimum weight spanning tree algorithms, 
325, 326 
Minor of matroid, 285 
Minty's painting theorem, 280 
Network: 
layered, 406 
residual, 405 
0-1, 422 
0-1 Network, 422 
of type 1, 422 
of type 2, 422 
Network optimization, 436 
Noncircuit edge, 8 
Nonoriented graph, 1 
Nonseparable graph, 19 
Nonseparable matroid, 300 
NP, 433 
NP-complete, 434 
NP-hard, 434 
Null graph, 2 
Nullity: 
of directed graph, 102 
of graph, 41 
Null space, 286 
One-terminal-pair graph, 198 
planar, 198 
Operations on graphs, 11-15 
Optimal assignment algorithm, 339 
Optimal assignment problem, 336 
Optimum i-edge coloring, 247 
Order of graph, 1 
Orientable matroid, 292 
Orientation of edge, 98 
Oriented graph, 1 
Orthogonal complements, 80 
Orthogonality: 
of circuit and cutset subspaces, 90 
relation, 137 
Orthogonal subspaces, 80 
Orthogonal vectors, 79 

458 
SUBJECT INDEX 
Out-degree, 98 
matrix, 175 
Painting: 
of orientable matroid, 292 
of set, 280 
Painting theorem, 280 
Parallel edges, 1, 98 
Λ-Partite graph, 16 
complete, 16 
Partition, 9 
principal, 94 
Partitioned, 9 
Path: 
augmenting, 226 
/-augmenting, 394 
directed, 100 
in directed graph, 100 
directed Hamilton, 115 
even, 8 
in graph, 8 
Hamilton, 62 
internally disjoint, 21 
length of, 8 
odd, 8 
Pendant: 
edge, 3 
vertex, 3 
Perfect graph conjecture, 259 
strong, 259 
Perfect matching, 228 
algorithm, 335 
Permutation, 160 
even, 160 
matrix, 232 
odd, 160 
Petersen graph, 187 
Planar embedding, 179 
Planar graph, 179 
region of, 184 
Planar one-terminal-pair graph, 198 
Planar separator theorem, 382 
Planarity testing algorithm, 378 
/-Positive edge, 393 
Postman tour, 343 
Prefix code, 109 
Prim's algorithm, 326 
Principal partition, 94 
Principal subgraphs, 94 
Program graph, 361 
Program graph reducibility algorithm, 366 
Proper subgraph, 4 
Pseudo edges, 343 
Pseudo vertex, 330 
Push, 410 
nonsaturating, 410, 412 
nonzeroing, 420 
saturating, 410, 412 
Push (v,w) operation, 412 
Push/relabel operation, 412 
Quasi-strongly connected graph, 103 
Quickly reducible, 434 
Rank axioms for matroid, 274 
Rank function of matroid, 266 
Rank in matroid, 266 
Rank of directed graph, 102 
Rank of graph, 41 
Rank of matroid, 266 
Ranking, 121 
Reachability matrix, 307 
Reducible program graph, 362 
Reducibility of program graph, 362 
algorithm, 366 
Reduction order, 369 
Reference vertex, 128 
Reflexive directed graph, 105 
Reflexive relation, 104 
Region of planar graph, 182 
Regular graph, 16 
r-Regular graph, 16 
Relabel operation, 412 
Related vertices, 349 
Representable matroid, 286 
standard, 286 
Residual network, 405 
Residual sequence, 209 
Restriction: 
of graph, 282 
of matroid, 284 
Right (of vertex), 349 
Ring sum of graphs, 13 
Root: 
of component (in DFS), 348, 351 
of DFS, 346 
in directed graph, 105 
of in-going directed tree, 175 
Row-oriented, 311 
Satisfiability problem, 434 
3-Satisfiability problem, 434 
/-Saturated edge, 393 
Saturated vertex (in matching), 216 
Scalar, 76 
Score, 120 
Score sequence, 120 
Seg, 44 

SUBJECT INDEX 
459 
Self-complementary graph, 27 
Self-dual graph, 198 
Self-loop, 1, 98 
Separable graph, 19 
Separable matroid, 300 
Series edges, 186 
Series insertion, 186 
Series merger, 186 
Series-parallel graph(s), 198 
parallel combination of, 198 
series combination of, 198 
Short-circuiting vertices, 15 
Shortest path, 314 
algorithms, 318, 320, 323, 380 
Simple graph, 1 
Sink, 391 
SNUMBER(t)), 369 
Son (of vertex), 349 
Source, 391 
Spanning subgraph, 4 
Spanning tree(s), 31 
directed, 108 
distance between, 93 
maximally distant, 93 
maximum weight, 294 
minimum weight, 324 
minimum weight, algorithm, 325-326 
Spanning fc-tree, 38 
Splitting cut vertex, 23 
Splitting vertex, 430 
Stability number, 236 
Stable set, 236 
Start vertex (in program graph), 361 
Stereographic projection, 181 
i/-graph, 375 
ir numbering, 370 
algorithm, 372 
rf-number of a vertex, 370 
Strong connectivity algorithm, 360 
Strongly connected component, 100 
Strongly connected graph, 100 
Strongly connected vertices, 100 
Subbush, 378 
SubgrapMs), 4, 99 
complement of, 7 
critical, 327 
edge-induced, 5 
induced, 5, 99 
maximal, 5 
minimal, 5 
principal, 94 
proper, 4 
spanning, 4 
vertex-induced, 5 
weight of a, 324 
/c-Subgraphs, 94 
Subspace, 76 
circuit, 82 
cutset, 85 
Subtree, 31 
Susceptibility, 230 
Symmetric directed graph, 105 
Symmetric relation, 104 
System of distinct representatives, 223 
Tarjan's algorithms, 348, 351, 356, 360, 366 
Terminal vertex: 
of directed walk, 99 
of edge, 98 
of walk, 7 
Thickness, 196 
Timetable scheduling algorithm, 341-342 
Topological degrees of freedom, 94 
Topological sorting, 118 
Tournament, 119 
Trail, 8, 100 
closed, 8 
closed directed, 100 
directed, 100 
directed Euler, 110 
Euler, 57 
open, 8 
open directed, 100 
open directed Euler, 110 
Trajectory, 421 
long, 421 
short, 421 
Transitive closure: 
algorithms, 310, 312 
of binary relation, 307 
of graph, 307 
Transitive directed graph, 105 
Transitive reduction, 380 
Transitive relation, 104 
Transport network, 391 
Transversal, 223 
partial, 300 
Transversal matroid, 300 
Travelling salesman problem, 67 
Tree, 31 
binary, 108 
cospanning, 38 
DFS, 346 
directed, 106 
in directed graph, 106 
directed spanning, 108 
in graph, 31 
Hungarian, 334 

460 
SUBJECT INDEX 
Tree (Continued) 
spanning, 31 
A-Tree, 38 
cospanning, 38 
spanning, 38 
Tree edge, 346, 350 
Tree graph, 53 
Triangle, 27 
Trivial graph, 19 
Turan's theorem, 259 
Turning around, 24 
Tutte's perfect matching theorem, 228 
Underlying undirected graph, 99 
Undirected graph, 1 
Uniform matroid, 299 
Unimodular matrix, 145 
Union: 
of graphs, 11 
of matroids, 301 
Unrelated vertices, 349 
/-Unsaturated edge, 393 
/-Unsaturated path, 394 
Valency, 3 
Valid labeling, 412 
Vector, 76 
η-Vector, 75 
Vector space, 74 
Vertex, 1, 97 
active, 412 
adjacent, 2, 98 
ancestor of, 349 
concurrent, 438 
cut-, 19 
descendant of, 349 
end, 1, 7, 98-99 
excess of a, 411 
father of, 346, 349 
initial, 98-99 
in potential of a, 408 
internal, 7, 99 
isolated, 3, 98 
out potential of a, 408 
pendant, 3 
potential of a, 409 
reference, 128, 409 
son of, 349 
i/-number of a, 370 
terminal, 7, 98-99 
virtual, 375 
^-Vertex colorable graph, 251 
Λ-Vertex coloring, 251 
proper, 251 
Vertex connectivity, 200 
Vertex cover, 237 
minimum, 237 
Vertex covering number, 237 
Vertex-disjoint graphs, 23 
Vertex-induced subgraph, 5 
Vertex removal, 13 
Visit (vertex in DFS), 346 
Vizing's theorem, 248 
Vulnerability, 230 
Walk, 7, 100 
closed, 7 
closed directed, 99 
directed, 99 
open, 7 
open directed, 99 
Warren's algorithm, 312 
Washall's algorithm, 310 
Weighted graph, 175 
Weighted path length, 109 
Weight product of subgraph, 163 
Wheel, 214 
Whitney's theorems, 21, 213 
/-Zero edge, 393 

