
Normal Curve Areas 
I 
L 
Source: Abridged from Table I of A. Hald, Statistrcal Tables and Formulas (New York: Wiley), 1952. Reproduced by 
permission of A. Hald. 

Critical Values of t 
Source: 
6.314 
2.920 
2.353 
2.132 
2.015 
1.943 
1.895 
1.860 
1.833 
1.812 
1.796 
1.782 
1.771 
1.761 
1.753 
1.746 
1.740 
1.734 
1.729 
1.725 
1.721 
1.717 
1.714 
1.711 
1.708 
1.706 
1.703 
1.701 
1.699 
1.697 
1.684 
1.671 
1.658 
1.645 
,ed with the 
~d permission of the 'Itustees of Biometril 
- 
from E. S. Pearson and 
. 
IUC 
H. 0. 
Hartley (eds), The B~ometnka Tables for Stat~st~crans, 
Vol. 1,3d ed , Biometrika, 1966. 

A FIRST COURSE IN BUSINESS 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . . . . . . . - 
Eighth Edition 
JAMES T. M c C L A V E  
Info Tech, Inc. 
University of Florida 
i 
I 
P. GEORGE BENSON 
I 
Terry College of Business 
I 
University of Georgia 
I 
TERRY S l N C l C H  
University of South Florida 
I 
I 
PRENTICE HALL 
Upper Saddle River, NJ 07458 

"W 
PROBABILITY 
11 7 
3.1 
Events, Sample Spaces, and Probability 118 
3.2 
Unions and Intersections 130 
3.3 
Complementary Events 134 
3.4 
The Additive Rule and Mutually Exclusive Events 135 
3.5 
Conditional Probability 140 
3.6 
The Multiplicative Rule and Independent Events 144 
3.7 
Random Sampling 154 
Statistics in Action: 
Lottery Buster 
158 
Quick Review 158 
*"ss""ms,"ms%"- 
W".""""" 
* 
" .bb " "* "" .
"
m
.
*
P
 
RIABLES AND PROBABILITY 
DISTRIBUTIONS 
167 
4.1 
Two Types of Random Variables 168 
I 
4.2 
Probability Distributions for Discrete Random Variables 171 
4.3 
The Binomial Distribution 181 
4.4 
The Poisson Distribution (Optional) 194 
4.5 
Probability Distributions for Continuous Random 
I 
Variables 201 
4.6 
The Uniform Distribution (Optional) 202 
4.7 
The Normal Distribution 206 
4.8 
Descriptive Methods for Assessing Normality 219 
4.9 
Approximating a Binomial Distribution with a Normal 
Distribution (Optional) 225 
4.10 
The Exponential Distribution (Optional) 231 
4.11 
Sampling Distributions 236 
4.12 
The Central Limit Theorem 242 
Statistics in Action: 
IQ, Economic Mobility, and the Bell Curve 
251 
Quick Review 252 
Real-World Case: 
The Furniture Fire Case (A Case Covering Chapters 3-4) 
257 

CONTENTS 
vii 
sms-*w 
" 
"bums 
INFERENCES BASED ON A SINGLE SAMPLE: 
ESTIMATION WITH CONFIDENCE INTERVALS 
259 
5.1 
Large-Sample Confidence Interval for a Population 
Mean 260 
5.2 
Small-Sample Confidence Interval for a Population Mean 268 
I 
I 
5.3 
Large-Sample Confidence Interval for a Population 
Proportion 279 
I 
5.4 
Determining the Sample Size 286 
I 
Statistics in Action: 
Scallops, Sampling, and the Law 
292 
Quick Review 293 
I 
ma"-mum""-"% 
" m-" 
us m"-w--t-""m 
m ""a","- 
""rn *""m%*"-" 
I 
ASED ON A SINGLE 
I +  
TESTS OF HYPOTHESIS 
299 
I 
i 
6.1 
The Elements of a Test of Hypothesis 300 
f 
a 
6.2 
Large-Sample Test of Hypothesis About a Population 
Mean 306 
6.3 
Observed Significance Levels: p-Values 313 
6.4 
Small-Sample Test of Hypothesis About a Population 
Mean 319 
6.5 
Large-Sample Test of Hypothesis About a Population 
I 
I 
Proportion 326 
6.6 
A Nonparametric Test About a Population Median 
(Optional) 332 
i 
Statistics in Action: 
March Madness-Handicapping 
the NCAA Basketball Tourney 
338 
Quick Review 338 
"s,,,m*x- 
-"a" 
I 
COMPARING POPULATION MEANS 
345 
7.1 
Comparing Two Population Means: Independent 
Sampling 346 
7.2 
Comparing Two Population Means: Paired Difference 
Experiments 362 
I 
7.3 
Determining the Sample Size 374 

viii 
CONTENTS 
7.4 
Testing the Assumption of Equal Population Variances 
(Optional) 377 
7.5 
A Nonparametric Test for Comparing Two Populations: 
Independent Sampling (Optional) 384 
7.6 
A Nonparametric Test for Comparing Two Populations: 
Paired Difference Experiment (Optional) 393 
7.7 
Comparing Three or More Population Means: Analysis of 
Variance (Optional) 400 
Statistics in Action: 
On the Trail of the Cockroach 
41 6 
Quick Review 418 
Real-World Case: The Kentucky Milk Case-Part 
I I  (A Case Covering Chapters 5-7) 
426 
8.1 
Comparing Two Population Proportions: Independent 
Sampling 428 
8.2 
Determining the Sample Size 435 
8.3 
Comparing Population Proportions: Multinomial 
Experiment 437 
8.4 
Contingency Table Analysis 445 
Statistics in Action: 
Ethics in Computer Technology and Use 
458 
Quick Review 461 
Real-World Case: Discrimination in the Workplace (A Case Covering Chapter 8) 468 
9.1 
Probabilistic Models 472 
9.2 
Fitting the Model: The Least Squares Approach 476 
- 
9.3 
Model Assumptions 489 
9.4 
An Estimator of a2 490 
- 
9.5 
Assessing the Utility of the Model: Making Inferences About 
the Slope PI 494 
9.6 
The Coefficient of Correlation 505 
- 
9.7 
The Coefficient of Determination 509 

9.8 
Using the Model for Estimation and Prediction 516 
9.9 
Simple Linear Regression: A Complete Example 529 
9.10 
A Nonparametric Test for Correlation (Optional) 532 
Statistics in Action: 
Can "Dowsers" Really Detect Water? 
540 
Quick Review 544 
INTRODUCTION TO MULTIPLE REGRESSION 
557 
10.1 
Multiple Regression Models 558 
i 
/ 
10.2 
The First-Order Model: Estimating and Interpreting the 
p Parameters 559 
10.3 
Model Assumptions 565 
10.4 
Inferences About the P Parameters 568 
10.5 
Checking the Overall Utility of a Model 580 
10.6 
Using the Model for Estimation and Prediction 593 
10.7 
Residual Analysis: Checking the Regression Assumptions 598 
10.8 
Some Pitfalls: Estimability, Multicollinearity, and 
Extrapolation 614 
Statistics in Action: 
"Wringing" The Bell Curve 
624 
Quick Review 626 
Real-World Case: 
The Condo Sales Case (A Case Covering Chapters 9-1 0) 634 
11.1 
Quality, Processes, and Systems 638 
11.2 
Statistical Control 642 
11.3 
The Logic of Control Charts 651 
11.4 
A Control Chart for Monitoring the Mean of a Process: 
The T-Chart 655 
11.5 
A Control Chart for Monitoring the Variation of a Process: 
The R-Chart 672 
11.6 
A Control Chart for Monitoring the Proportion of Defectives 
Generated by a Process: The p-Chart 683 

Statistics in Action: 
Deming's 14 Points 692 
Quick Review 694 
Real-World Case: 
The Casket Manufacturing Case (A Case Covering Chapter 11) 699 
APPENDIXB 
Tables 707 
AP P E N D l  X C 
Calculation Formulas for Analysis 
of Variance: Independent Sampling 739 
ANSWERS TO SELECTED EXERCISES 
741 
References 747 
Index 753 

",: 
r 
This eighth edition of A First Course in Business Statistics is an introductory 
business text emphasizing inference, with extensive coverage of data collection 
and analysis as needed to evaluate the reported results of statistical studies and to 
make good decisions. As in earlier editions, the text stresses the development of 
statistical thinking, the assessment of credibility and value of the inferences made 
from data, both by those who consume and those who produce them. It assumes a 
mathematical background of basic algebra. 
A more comprehensive version of the book, Statistics for Business and Eco- 
nomics (8/e), is available for two-term courses or those that include more exten- 
sive coverage of special topics. 
NEW IN THE EIGHTH EDITION 
Major Content Changes 
Chapter 2 includes two new optional sections: methods for detecting outliers 
(Section 2.8) and graphing bivariate relationships (Section 2.9). 
Chapter 4 now covers descriptive methods for assessing whether a data set is ap- 
proximately normally distributed (Section 4.8) and normal approximation to 
the binomial distribution (Section 4.9). 
Exploring Data with Statistical Computer Software and the Graphing Calculator- 
Throughout the text, computer printouts from five popular Windows-based 
statistical software packages (SAS, SPSS, MINITAB, STATISTIX and 
EXCEL) are displayed and used to make decisions about the data. New to 
this edition, we have included instruction boxes and output for the TI-83 graph- 
ing calculator. 
Statistics in Action-One 
feature per chapter examines current real-life, high- 
profile issues. Data from the study is presented for analysis. Questions prompt 
the students to form their own conclusions and to think through the statistical 
issues involved. 
Real-World Business Cases-Six 
extensive business problem-solving cases, with 
real data and assignments. Each case serves as a good capstone and review of 
the material that has preceded it. 
Real-Data Exercises-Almost 
all the exercises in the text employ the use of cur- 
rent real data taken from a wide variety of publications (e.g., newspapers, 
magazines, and journals). 
Quick Review-Each chapter ends with a list of key terms and formulas, with ref- 
erence to the page number where they first appear. 
Language Lab-Following 
the Quick Review is a pronunciation guide for Greek 
letters and other special terms. Usage notes are also provided. 

xii 
TRADITIONAL STRENGTHS 
We have maintained the features of A First Course in Business Statistics that we 
believe make it unique among business statistics texts. These features, which assist 
the student in achieving an overview of statistics and an understanding of its rel- 
evance in the business world and in everyday life, are as follows: 
The Use of Examples as a Teaching Device 
Almost all new ideas are introduced and illustrated by real data-based applica- 
tions and examples. We believe that students better understand definitions, gen- 
eralizations, and abstractions after seeing an application. 
Many Exercises-Labeled 
by Type 
The text includes more than 1,000 exercises illustrated by applications in almost 
all areas of research. Because many students have trouble learning the mechanics 
of statistical techniques when problems are couched in terms of realistic applica- 
tions, all exercise sections are divided into two parts: 
Learning the Mechanics. Designed as straightforward applications of new 
concepts, these exercises allow students to test their ability to comprehend a 
concept or a definition. 
Applying the Concepts. Based on applications taken from a wide variety of jour- 
nals, newspapers, and other sources, these exercises develop the student's skills to 
comprehend real-world problems and describe situations to which the tech- 
niques may be applied. 
A Choice in Level of Coverage of Probability (Chapter 3) 
One of the most troublesome aspects of an introductory statistics course is the study 
of probability. Probability poses a challenge for instructors because they must decide 
on the level of presentation, and students find it a difficult subject to comprehend. We 
believe that one cause for these problems is the mixture of probability and counting 
rules that occurs in most introductory texts. We have included the counting rules and 
worked examples in a separate appendix (Appendix A) at the end of the text. Thus, 
the instructor can control the level of coverage of probability. 
Nonparametric Topics Integrated 
In a one-term course it is often difficult to find time to cover nonparametric tech- 
niques when they are relegated to a separate chapter at the end of the book. Conse- 
quently, we have integrated the most commonly used techniques in optional sections 
as appropriate. 
Coverage of Multiple Regression Analysis (Chapter 10) 
This topic represents one of the most useful statistical tools for the solution of ap- 
plied problems. Although an entire text could be devoted to regression modeling, 
we believe we have presented coverage that is understandable, usable, and much 
more comprehensive than the presentations in other introductory statistics texts. 

Footnotes 
, . 
Although the text is designed for students with a non-calculus background, foot- 
notes explain the role of calculus in various derivations. Footnotes are also used to 
inform the student about some of the theory underlying certain results. The foot- 
notes allow additional flexibility in the mathematical and theoretical level at 
which the material is presented. 
SUPPLEMENTS FOR THE INSTRUCTOR 
The supplements for the eighth edition have been completely revised to reflect 
the revisions of the text. To ensure adherence to the approaches presented in the 
main text, each element in the package has been accuracy checked for clarity and 
freedom from computational, typographical, and statistical errors. 
Annotated Instructor's Edition (AIE) (ISBN 0-1 3-027985-4) 
Marginal notes placed next to discussions of essential teaching concepts include: 
Instructor's Notes by Mark Dummeldinger (ISBN 0-1 3-027410-0) 
1 
Teaching Tips-suggest 
alternative presentations or point out common stu- 
This printed resource contains suggestions for using the questions at the end of 
the Statistics in Action boxes as the basis for class discussion on statistical 
ethics and other current issues, solutions to the Real-World Cases, a complete 
short answer book with letter of permission to duplicate for student usc, and 
many of the exercises and solutions that were removed from previous editions 
of this text. 
I 
Instructor's Solutions Manual by Nancy S. Boudreau 
(ISBN 0-1 3-027421 -6) 
dent errors 
Exercises-reference 
specific section and chapter exercises that reinforce the 
concept 
H-disk 
icon identifies data sets and file names of material found on the 
data CD-ROM in the back of the book. 
Solutions to all of the even-numbered exercises are given in this manual. Careful 
attention has been paid to ensure that all methods of solution and notation are 
consistent with those used in the core text. Solutions to the odd-numbered exer- 
cises are found in the Student's Solutions Manual. 
Short Answers-section 
and chapter exercise answers are provided next to 
the selected exercises 
Test Bank by Mark Dummeldinger (ISBN 0-1 3-027419-4) 
Entirely rewritten, the Test Bank now includes more than 1,000 problems that cor- 
relate to problems presented in the text. 

xiv 
PREFACE 
Test Cen-EQ (ISBN 0-1 3-027367-8) 
Menu-driven random test system 
Networkable for administering tests and capturing grades online 
Edit and add your own questions-or 
use the new "Function Plotter" to create 
a nearly unlimited number of tests and drill worksheets 
PowerPoint Presentation Disk by Mark Dummeldinger 
(ISBN 0-1 3-027365-1) 
This versatile Windows-based tool may be used by professors in a number of 
different ways: 
Slide show in an electronic classroom 
'. 
" 
" 
Printed and used as transparency masters 
Printed copies may be distributed to students as a convenient note-taking device 
Included on the software disk are learning objectives, thinking challenges, concept pre- 
sentation slides, and examples with worked-out solutions. The PowerPoint Presenta- 
tion Disk may be downloaded from the FTP site found at the McClave Web site. 
( 
I
,
 
Data CD-ROM-available free with every text purchased from 
Prentice Hall (ISBN 0-1 3-027293-0) 
The data sets for all exercises and cases are available in ASCII format on a CD- 
ROM in the back of the book. When a given data set is referenced, a disk symbol 
and the file name will appear in the text near the exercise. 
McClave Internet Site (http://www.prenhall.com/mcclave) 
This site will be updated throughout the year as new information, tools, and 
applications become available. The site contains information about the book 
and its supplements as well as FTP sites for downloading the PowerPoint Pre- 
sentation Disk and the Data Files. Teaching tips and student help are provided 
as well as links to useful sources of data and information such as the Chance 
Database, the STEPS project (interactive tutorials developed by the Univer- 
sity of Glasgow), and a site designed to help faculty establish and manage 
course home pages. 
SUPPLEMENTS AVAILABLE FOR STUDENTS 
Student's Solutions Manual by Nancy S .  Boudreau 
' I  - 
(ISBN 0-1 3-027422-4) 
Fully worked-out solutions to all of the odd-numbered exercises are provided in 
this manual. Careful attention has been paid to ensure that all methods of solution 
and notation are consistent with those used in the core text. 

- 
Companion Microsoft Excel Manual by Mark Dummeldinger 
(ISBN 0-1 3-029347-4) 
Each companion manual works hand-in-glove with the text. Step-by-step keystroke 
level instructions, with screen captures, provide detailed help for using the technol- 
ogy to work pertinent examples and all of the technology projects in the text. A 
cross-reference chart indicates which text examples are included and the exact page 
reference in both the text and technology manual. Output with brief instruction is 
provided for selected odd-numbered exercises to reinforce the examples. A Student 
Lab section is included at the end of each chapter. 
The Excel Manual includes PHstat, a statistics add-in for Microsoft Excel 
(CD-ROM) featuring a custom menu of choices that lead to dialog boxes to 
help perform statistical analyses more quickly and easily than off-the-shelf Excel 
permits. 
Student Version of SPSS 
Student versions of SPSS, the award-winning and market-leading commercial and 
data analysis package, and MINITAB are available for student purchase. Details 
on all current products are available from Prentice Hall or via the SPSS Web site 
at http://www.spss.com. 
Learning Business Statistics with ~icrosoft' Excel 
by John L. Neufeld (ISBN 0-13-234097-6) 
The use of Excel as a data analysis and computational package for statistics is ex- 
plained in clear, easy-to-follow steps in this self-contained paperback text. 
A MINITAB Guide to Statistics by Ruth Meyer and David Krueger 
(ISBN 0-1 3-784232-5) 
This manual assumes no prior knowledge of MINITAB. Organized to correspond 
to the table of contents of most statistics texts, this manual provides step-by-step 
instruction to using MINITAB for statistical analysis. 
ConStatS by Tufts University (ISBN 0-1 3-502600-8) 
ConStatS is a set of Microsoft Windows-based programs designed to help col- 
lege students understand concepts taught in a first-semester course on proba- 
bility and statistics. ConStatS helps improve students' conceptual understanding 
of statistics by engaging them in an active, experimental style of learning. A 
companion ConStatS workbook (ISBN 0-13-522848-4) that guides students 
through the labs and ensures they gain the maximum benefit is also available. 
ACKNOWLEDGMENTS 
This book reflects the efforts of a great many people over a number of years. First we 
would like to thank the following professors whose reviews and feedback on orga- 
nization and coverage contributed to the eighth and previous editions of the book. 

xvi 
PREFACE 
Reviewers Involved with the Eighth Edition 
Mary C. Christman, University of Maryland; James Czachor, Fordham-Lincoln 
Center, AT&T; William Duckworth 11, Iowa State University; Ann Hussein, Ph.D., 
Philadelphia University; Lawrence D. Ries, University of Missouri-Columbia. 
Reviewers of Previous Editions 
Atul Agarwal, GMI Engineering and Management Institute; Mohamed Albohali, 
Indiana University of Pennsylvania; Gordon J. Alexander, University of Min- 
nesota; Richard W. Andrews, University of Michigan; Larry M. Austin, Texas Tech 
University; Golam Azam, North Carolina Agricultural & Technical University; 
Donald W. Bartlett, University of Minnesota; Clarence Bayne, Concordia Uni- 
versity; Carl Bedell, Philadelphia College of Textiles and Science; David M. 
Bergman, University of Minnesota; William H. Beyer, University of Akron; Atul 
Bhatia, University of Minnesota; Jim Branscome, University of Texas at Arlington; 
Francis J. Brewerton, Middle Tennessee State University; Daniel G. Brick, Uni- 
versity of St. Thomas; Robert W. Brobst, University of Texas at Arlington; Michael 
Broida, Miami University of Ohio; Glenn J. Browne, University of Maryland, Bal- 
timore; Edward Carlstein, University of North Carolina at Chapel Hill; John M. 
Charnes, University of Miami; Chih-Hsu Cheng, Ohio State University; Larry 
Claypool, Oklahoma State University; Edward R. Clayton, Virginia Polytechnic 
Institute and State University; Ronald L. Coccari, Cleveland State University; 
Ken Constantine, University of New Hampshire; Lewis Coopersmith, Rider Uni- 
versity; Robert Curley, University of Central Oklahoma; Joyce Curley-Daly, Cal- 
ifornia Polytechnic State University; Jim Daly, California Polytechnic State 
University; Jim Davis, Golden Gate University; Dileep Dhavale, University of 
Northern Iowa; Bernard Dickman, Hofstra University; Mark Eakin, University of 
Texas at Arlington; Rick L. Edgeman, Colorado State University; Carol Eger, 
Stanford University; Robert Elrod, Georgia State University; Douglas A. Elvers, 
University of North Carolina at Chapel Hill; Iris Fetta, Clemson University; Susan 
Flach, General Mills, Inc.; Alan E. Gelfand, University of Connecticut; Joseph 
Glaz, University of Connecticut; Edit Gombay, University of Alberta; Jose Luis 
Guerrero-Cusumano, Georgetown University; Paul W. Guy, California State Uni- 
versity, Chico; Judd Hammack, California State University-Los Angeles; Michael 
E. Hanna, University of Texas at Arlington; Don Holbert, East Carolina Univer- 
sity; James Holstein, University of Missouri, Columbia; Warren M. Holt, South- 
eastern Massachusetts University; Steve Hora, University of Hawaii, Hilo; Petros 
Ioannatos, GMI Engineering & Management Institute; Marius Janson, University 
of Missouri, St. Louis; Ross H. Johnson, Madison College; I? Kasliwal, California 
State University-Los Ange1es;Timothy J. Killeen, University of Connecticut;Tim 
Krehbiel, Miami University of Ohio; David D. Krueger, St. Cloud State Universi- 
ty; Richard W. Kulp, Wright-Patterson AFB, Air Force Institute of Technology; 
Mabel T. Kung, California State University-Fullerton; Martin Labbe, State Uni- 
versity of New York College at New Paltz; James Lackritz, California State Uni- 
versity at San Diego; Lei Lei, Rutgers University; Leigh Lawton, University of St. 
Thomas; Peter Lenk, University of Michigan; Benjamin Lev, University of Michi- 
gan-Dearborn; Philip Levine, William Patterson College; Eddie M. Lewis, Uni- 
versity of Southern Mississippi; Fred Leysieffer, Florida State University; Xuan Li, 
Rutgers University; Pi-Erh Lin, Florida State University; Robert Ling, Clemson 
University; Benny Lo; Karen Lundquist, University of Minnesota; G. E. Martin, 

Clarkson University; Brenda Masters, Oklahoma State University; William Q. 
Meeker, Iowa State University; Ruth K. Meyer, St. Cloud State University; Ed- 
ward Minieka, University of Illinois at Chicago; Rebecca Moore, Oklahoma State 
University; June Morita, University of Washington; Behnam Nakhai, Millersville 
University; Paul I. Nelson, Kansas State University; Paula M. Oas, General Office 
Products; Dilek Onkal, Bilkent University,Turkey;Vijay Pisharody, University of 
Minnesota; Rose Prave, University of Scranton; P. V. Rao, University of Florida; 
Don Robinson, Illinois State University; Beth Rose, University of Southern Cali- 
fornia; Jan Saraph, St. Cloud State University; Lawrence A. Sherr, University of 
Kansas; Craig W. Slinkman, University of Texas at Arlingon; Robert K. Smidt, Cal- 
ifornia Polytechnic State University; Toni M. Somers, Wayne State University; 
Donald N. Steinnes, University of Minnesota at Du1uth;Virgil F. Stone,Texas A & 
M University; Katheryn Szabet, La Salle University; Alireza Tahai, Mississippi 
State University; Kim Tamura, University of Washington; Zina Taran, Rutgers 
University; Chipei Tseng, Northern Illinois University; Pankaj Vaish, Arthur An- 
dersen & Company; Robert W. Van Cleave, University of Minnesota; Charles E 
Warnock, Colorado State University; Michael P. Wegmann, Keller Graduate 
School of Management; William J. Weida, United States Air Force Academy; T. J. 
Wharton, Oakland University; Kathleen M. Whitcomb, University of South Car- 
olina; Edna White, Florida Atlantic University; Steve Wickstrom, University of 
Minnesota; James Willis, Louisiana State University; Douglas A. Wolfe, Ohio State 
University; Gary Yoshimoto, St. Cloud State University; Doug Zahn, Florida State 
University; Fike Zahroom, Moorhead State University; Christopher J. Zappe, 
Bucknell University. 
Special thanks are due to our ancillary authors, Nancy Shafer Boudreau and 
Mark Dummeldinger, and to typist Kelly Barber, who have worked with us for 
many years. Laurel Technical Services has done an excellent job of accuracy 
checking the eighth edition and has helped us to ensure a highly accurate, clean 
text. Wendy Metzger and Stephen M. Kelly should be acknowledged for their 
help with the TI-83 boxes. The Prentice Hall staff of Kathy Boothby Sestak, 
Joanne Wendelken, Gina Huck, Angela Battle, Linda Behrens, and Alan Fischer, 
and Elm Street Publishing Services' Martha Beyerlein helped greatly with all 
phases of the text development, production, and marketing effort. We acknowl- 
edge University of Georgia Terry College of Business MBA students Brian F. 
Adams, Derek Sean Rolle, and Misty Rumbley for helping us to research and ac- 
quire new exerciselcase material. Our thanks to Jane Benson for managing the 
exercise development process. Finally, we owe special thanks to Faith Sincich, 
whose efforts in preparing the manuscript for production and proofreading all 
stages of the book deserve special recognition. 
For additional information about texts and other materials available from 
Prentice Hall, visit us on-line at http://www.prenhall.com. 
James T. McClave 
P. George Benson 
Terry Sincich 

TO THE STUDENT 
The following four pages will demonstrate how to use this text effectively to make 
studying easier and to understand the connection between statistics and your world. 
Chapter Openers Provide 
a Roadmap 
Where We've Been quickly 
reviews how information learned 
previously applies to the chapter 
at hand. 
Where We're Going highlights 
S I M P L E  L I N E A R  R E G R E S S I O N  
C
O
N
T
E
N
T
S
 
9 1 
P m h a h ~ l i \ t i c  Model\ 
9.2 
R r l m g  l h c  M o d c l . T h c  Least SquaresApproach 
9.3 
M o d e l  A \ u m p l ~ i m s  
9.4 
An E \ t m s t o r  of oZ 
9.5 
Asscssm~ the U t i l i t y  of the M<,dcl M a k m g  Inferences A b o u t  the Slope 8, 
9 6 
T h c  C o c t l ~ c r o l  
or ('wrclatwn 
Y 7 
n t ~  
(.OC~I~CIC~II 
,>I I l c l e r r n m r n o n  
9.8 
I l m g  l l l c  M o d e l  h r  I 
\ I ~ m i ! l ~ c m  
and Prcdmion 
9.9 
S m p l e  Lmuar Ilegreww A Complctc Example 
9.lU 
A NonparametncTcrt tor Currelallan (Optional) 
how the chapter topics fit into 
your growing understanding 
of statistical inference. 
S
T
A
T
I
S
T
I
C
S
 
I
N
 
A
C
T
I
O
N
 
.,.. 
. 
. . . . . . . . ..... .. . ..... ........ .......... . . . . . . 
Can "Dowscn"Real1y Detect Water? 
huuw 11 wc measure ~CIUBTL. foolape ;and .ige .dl the 
rmm cilmc as assescd value. we can c\t.hhrh Ihr rr- 
l a t t o n \ h ~ p  hcl%ccn ~ h c \ c  v a n a h k - - o n e  that lets us 
u\c l h c \ r  v a r l s h b  klr p r e d s t m n  Tht, chapter cov- 
e n  I h c  \implc\l vlualmn-relatmp 
t w o  varmhlrs. 
The m o l e  complex p r o h l c m  ot rclatmg m o r e  than 
t w o  v a r ~ h l e \  
8, the l o p r  oi Chaplcr I 0  
SECTION 4.12 
T h e  C e n t r a l  L i m i t  T h e o r e m  
251 
S T A T I S T I C S  I N  A B L ~ B ~ J . ~  
IQ, Econorn~c Mobility, and the Bell Curve \ 
I n  thc8r cunrrovcn#al hook l i a ,  I I d  Orrvr (Free Prcsr. 
able having a normal dl.tnhut,on wllh mean p = I M  nlld 
(tandad davlallonl. - I5 msd,slnb"tlon,or h r l i a l n r  8, 
shown In Flgurc449 
In lhclr h o d  ilcrrn\lr#n and Murray relsr lolnccoml 
nvc cl.wc\ ol pioplc dillncd hv pmccnl~lc~ 
of the oorm.il 
dlrfnhul,,,n c1.nr I ('rcrv hnlht')c,,n*,*sol 
lllore ~ 8 t h  
lQ\ 
sh,K ,hi ',W ,pir<rnlllc Cl.,,, 
11 ( Ihnell, 1 .,,c ,1,,nc 
~ 8 t h  
lo* ~ C ! U C L ~  
CIIC 75ll1 .md lJS1li ~WCLIIIIICI 
Cl.i\) I l l  ('nor 
mnl') mcudi\ 101 hcluccn l l ~  
X l h  .md 71111 pi#tcnl~les: 
CI~,\ IV ('dull') .arc ~ h m i  
ul11, 10, hctwcin (hc rll> and 
251h pi.lccmllo .id Cl.M\' ( ' v i r i  dull") .lrc 10, below the 
5th pc#ccnt,lr lbwccl.i~~c5.~8c.41~~ 
~lla*lralcd~n 
i i w c 4 4 9  
\ "Statistics in Action" Boxes. 
Explore High-Interest Issues 
encer drawn l a m  (hem (Scc 10 crmlplr "Mllnplni. lIr< 
R"li<,,,L* 
Acnull,,n',n lnlcah<lul thc rilillll>lldlllli.imonp 
rrce, gcnc*, and 10. <hame Summer 1995 ) In C h . w r  
l l X S t ~ t # , l ~ o  
mAct#on,wc r x p l o r e ~  
l i u  11, thsw pn,hli.m< 
One ol fhc man! i o s l r o v u \ ~ r \  5prrkcd lh) I h i  hmk 8, 
the author\'tcnct ,ha< lcvel of ~nrclllgsncc (or l a d  thi.rcul1 
F o c u s  
Highlight controversial, contemporary 
issues that involve statistics. 
a tvfhcr whmc cnrn,ng ;,,c In Ihc 1>o,,c,m i,ru pcr<cn, of 
thc [#ncomrl dluuhutam hd, wmclhlng lbkuims ~h.ince 8n 
fwcnty (or lesi) of nvng lo the top fdlh ,it Iha rnoimc dl\- 
trlhulloll and n,m,n, ,I lif,v-l,f,, 
'h.3"~~ 01 \r;n,ns 8" 
the 
h c,,,,, 
m llhb 11c ha\ Ic*, 1h.i" <oni 'h.,"'e 
I,, In", o l  m,ng 
*hove ercn t1,c mcil,,,,, ,na,mc 
M,,,, 
peliplc .It p,c\cnt 
are stuck ncn, u1,err ,1,c,, p.mn,, wcrc on ihc 1nr<,me dls 
tr#huf#,m ~n p.trl 1hcc.1~~ 
Ilntcll~r~nccl.ahah hr\hccnmea 
Work through the "Focus" questions 
to help you evaluate the findings. 
Integration of Real-World Data helps 
students see relevance to their daily lives. 
xviii 

Shaded Boxes Highlight 
Important Information 
Definitions, Strategies, Key 
Formulas, Rules, and other 
important information is 
highlighted in easy-to-read boxes. 
Prepare for quizzes and tests by 
reviewing the highlighted 
information. 
/ 
Interesting Examples / 
with Solutions 
Examples, witfi complete 
step-by-step solutions and 
explanations, illustrate every 
concept and are numbered 
for easy reference. 
* Solutions are carefully explained to . 
prepare for the section exercise set. 
The end of the solution is clearly 
marked by a 
symbol. 
Assigning probabilities to sample points is easy for some experiments. For 
example, if thc cxpcrment is to toss a fair coin and observe the face. we would 
probably all agrcc to assign a probability of 
to the two sample pomts. Ohserve 
a bead and Obscrvc a tail. Howrver,many experlmenls have sample points whose 
probabilities arc more dlfflcult to assign. 
of each tvoc 01 PC to stock. An imuortant factor affectme the solut~on 1s the 
proportion of curturners who purchase each type of PC. Show how t h ~ s  
problem 
mieht be tonnulated in the framework of an experiment w ~ t h  sample uolnts 
. . 
and a sample space. Indicate how prohahillties m~ght he awgncd to the sample 
points. 
5 o I u t i o n If we use the term customer to refer to a uerson who uurchases one of the two 
typcs of PCs. the experment can be defined as the entrance of a customer and the 
obqervation ot whlch tvve of PC 1s ~urchaqed.Therc arc two sample points In the 
. . 
sample space corresponding to thls experiment: 
I): (The customer purchase? a standard desktop unit) 
L: (lhe customer purchases a laptop unit) 
The difference between this and the coln-toss experiment becomes apparent 
when wc attcmpt to assign probahilit~es lo the two sample pointy. What prohah~li- 
ty ~hould 
wc asign to the sample point I)? If you answer 5. you are awummg that 
the evcnts D and L should occur with equal I~kel~hood.~ust 
l~kc thc ~ a m ~ l c  
uolnts 
Then we use* 
Fl'uar 2 19 
SAS printout of numerical 
dercrlptlve measurer for 50 
RhD percentages 
N 
Hean 
Std DBY 
Skewness 
"9s 
CV 
T:*Ban.O 
S9n RanL 
Num '- 
0 
5 o I u t i o n The SAS prmtout drbcnhlng lhc RdiU percentage dala 1s dkplaycd m Hgurr 2.19. 
The vnrrancc and sldnda~d dcwatcon, hlghhghlcd on thc pl~nloul, are: 
ri = 3,922792 and r = 1.980604 
1004 ldax 
75% 93 
50% Hed 
25% Q1 
0% Mi" 
, 
mmenrs 
50 Sun Wgts 
50 
8.492 
Sun 
424.6 
1.980604 Variance 
3.922792 
0.854601 
Kurtosis 
0.419288 
3797.92 
CSS 
192.2168 
23.32317 
std man 
0.2801 
30.31778 
Prob, T 
0.0001 
637.5 
Prob>lSl 
0.0001 
so 
Quantiles(Def-51 
13.5 
99% 
13.5 
9.6 
95% 
13.2 
8.05 
90% 
11.2 
7.1 
10% 
6.5 
5.2 
5% 
5.9 
1% 
5 . 1  
8.3 
2.5 
, 
Computer Output 
Integrated Throughout 
Statistical software packages such 
as SPSS, MINITAB, SAS, and EXCEL 
crunch data quickly so you can 
spend time analyzing the results. 
Learning how to interpret statistical 
output will prove helpful in future 
classes or on the job. 
When computer output appears 
in examples, the solution explains 
how to read and interpret 
the output. 
xix 

p v ~ o t s  
of Exercises for Practice 
Learning the Mechanics 
2.311 (Mculalr the modc. mean, and median of the following 
data: 
18 10 
15 
13 
17 
15 
12 
15 18 16 
11 
2.31 Calculate the mean and median of the following grade 
point averages 
1.2 
2 5 
2 1 
3.7 
2.8 
2.0 
2.32 Calculate the mean for samples where 
a. n = 10.Z.t = XS 
b. n = 16.21 = 4W 
c. n = 45. Zx = 35 
(1. n = 1 8 . 2 ~  
= 242 
2.33 Calculate the mean, medlan, and mode for each of the 
2.34 Drscr~hr how lhc mran compares to the median for a 
d~strthutlon as follows: 
a. Skewed to the left 
b. Skewed to the right 
c. Symmetric 
Applying the Concepts 
2.35 The total number of passengers handled m 1998 by 
exht cruse h p \  based ~n Port Canaveral (Florida) are 
l&d 
m the table below Find and interpret the mean 
and median ot the data set 
tmn of these 50 womm. Numencal descnpttve statlrtics 
for the data are ?how" ~n the MINITAB pnntout below. 
a. Find the mran, rnedlan. and modal agc of the d~strl- 
bution, Interpret the% values. 
b. What do thc mran and the median mdicate about 
the skewnes of the age dlstrlbutlon? 
e. What percentage of these women are in their for- 
ties? Theu flfttrs"Thelr sixtles? 
Cruise Line (Ship) 
Number of Passengers 
........................... .. 
............................. 
Canaveral (Dolphin) 
152,240 
Carnival (Fantaw) 
480,924 
Dmey ( M a w )  
71,504 
Premier (Ocranlc) 
270.361 
Royal Caribbean (Nordic Empress) 
lll%l6l 
Sun CTUZ Casinos 
453.806 
Strrlmg Cmses (New Yorker) 
15,782 
T m a r  Int'l Shmmne (Topaz) 
28,280 
. . . .  
-- 
source llorrdu ~ r e n d  Val 41. No 9, Jan 1939 
\ 
MINITAB Output for Exercise 2.36 
~escriptive Statistics 
Variable 
N 
Mean 
Median 
Tr Mean 
StDev 
SE Mean 
A g e  
50 
48.160 
47.000 
47.795 
6.015 
0.851 \ 
Variable 
Min 
Max 
01 
Q3 
AW 
36.000 
68.000 
45.000 
51.aso 
Every section in the book is 
followed by an Exercise Set divided 
into two parts: 
Learning the Mechanics has 
straightforward applications 
of new concepts. Test your 
mastery of definitions, 
concepts, and basic 
computation. Make sure 
you can answer all of these - 
questions before moving on. 
Applying the Concepts 
tests your understanding of 
concepts and requires you to 
apply statistical techniques in 
solving real-world problems. 
\ 
I ' ~ e a l  Data 
. \Computer Output 
Most of the exercises contain 
data or information taken 
Computer output screens appear 
from newspaper articles, 
in the exercise sets to give you 
magazines, and journals. 
practice in interpretation. 
Statistics are all around you. 

End of Chapter Review 
1 
Each chapter ends with information 
K e y  Terms 
designed to help you check your 
Language Lab helps you learn 
the language of statistics through 
pronunciation guides, descriptions 
of symbols, names, etc. 
Note Sianrd 1.) 
item, arc from rhr upnu,d wrronh In ths chapter 
Analysls ofvalrancr (ANOVA) 400 
Pared dlifir~ncc expertmen1 365 
Sum of squares for error. 402 
- 
Symbol 
Pronuncmtlon 
(P, - pz) 
mu 1 mmu, mu 2 
D~tference between populatmn mean* 
(T, - i,) 
x bar I mlnua .r bar 2 
Dlfl~rincr between sample means 
0,: 
slgmn ofx har I mmu%x bar 2 
Standard dcvmmn of the ramplmg d~str~butmn 
of ( i ,  - 5,) 
Supplementary Exercises review 
all of the important topics covered 
in the chapter and provide 
(A Case Covering Chapters 1 and 2) 
I 
understanding of the material, 
Blockmq 165 
P<xkd \ r m p l ~  ~\lun.$t~ 
olvanance 351 
Standard error 347 
F dnlnhul~m* 377 
Randonw~d lhlock ~ x p i n m t n t  165 
Trtatrntm' 
4M 
study for tests, and expand 
F test* 
1x1 
Rank Sum' 
185 
Wlluxon lank rum test' 
384 
mcan squ u c  lor enor' 
402 
Rohuu M~lhod* 410 
Wdcoxon ugnid rank trxt' 
393 
mi.," y u a r i  for trrafmmts* 4M 
your knowledge of statistics. 
Quick Review provides a list of key 
terms and formulas with page 
number references. 
I 
1 
additional practice learning statistical 
computations. 
Data sets for use with the 
problems are available on a CD-ROM 
A r 
I IRR
any products and services are purchased by gov- 
ernments.citis& s t a t e w d  businesses on Be basis 
M 
of \edcd h~ds, and contracts arc awarded to the 
.......................... I 
Starred (*) exerclrrr refer to the optronol secnons m lhrr 
C ~ W ,  
sample 1 
sample 2 
1, = 135 
n, = 148 
L e a r n m g  the M e c h a n i c s  
~ , = 1 2 2  ~
=
8
1
 
7 89 Independent random samples were selected trom tw, 
$ = 2 1  
s : = 3 0  
normally dl\tnhutid p<qwlatmns wlth means p ,  and 
p2 respe~t~vely 
I
~
L
 
\ d m p ~ ~  
(IZ~, means and van 
c What ~ a m p l r  
s m s  would be requred ~f you wtrh to 
anccs art shown m the tollow~ng tahle 
estmate (p, - p,) to wlthm 2 wlth 90% confl 
dence) Assume that n = n, 
- 
Real-World Cases 
luwcrl hddcri Thi\ prim* work, cntrrmcly well in com- 
Vadablt 
Column(r, 
Typo 
Dtrrrlptlon .............................. 
petttwc miukcl\, hut 11 has the polcnl~al to mcrcaae the coat 
. -. . 
of purcha\mg tt the markc15 arc noncomprt~l~ve 
or tf collu- 
YEAR 
1-4 
Oh 
Ycdr ln whlch milk contraet 
w e  practices are pment An mvratigalmn that began with 
rwardcd 
a statlatical analysts of hlds tn the Flortda school mdk mar- 
MARKET 
QL 
Nort"ern 
Market 
kc1 in 1986 led lo lhc rcowery of more lhiln 833,(Kl(l.WO 
(TRI-COUNTY 
in the back of the book. The disk icon 
indicates when to use the CD. 
$100.000.000 for school mdk hvheeine in twenlv other 1 
I 
Six real-business cases put you 
in the position of the business 
decision maker or consultant. 
Use the data provided and the 
information you have learned 
in preceding chapters to reach 
' 
a decision and support your 
arguments about the questions 
being asked. 
Finding One-Variable Descriptive Statistics 
USING THE T I - 8 3  G R A P H I N G  CALCULATOR 
Step 1 Enter the data 
Press STAT 1 for STAT Edit 
Enter the data mto one of the lhsts 
Step 2 Calculule dew-iptrve rtulr~frcs 
Press STAT 
Pras the right arrow key to highhght CALC 
Press ENTER for 1-VarStats 
Enter the namc of the list containing your data. 
Press 2nd 1 tor L1 (or 2nd 2 for LZ etc.) 
Press ENTER 
- Using the TI-83 
Graphing Calculator 
Provides you with step-by-step 
instruction on using the TI-83 
in a variety of applications. 
xxi 

S T A T I S T I C S ,  D A T A ,  
A N D  S T A T I S T I C A L  T H I N K I N G  
C O N T E N T S  
. . . . . , . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1.1 
The Science of Statistics 
1.2 
Types of Statistical Applications in Business 
1.3 
Fundamental Elements of Statistics 
1.4 
Processes (Optional) 
1.5 
Types of Data 
1.6 
Collecting Data 
1.7 
The Role of Statistics in Managerial Decision-Making 
S T A T I S T I C S  
I
N
 A
C
T
I
O
N
 . 
A 20/20 View of Survey Results: Fact or Fiction? 
W h e r e  W e ' r e  G o i n g  
I 
S 
tatistics? Is it a field of study, a group of numbers 
that summarizes the statc of our national ccono- 
my, the performance of a stock, or the business con- 
ditions in a particular locale? Or, as one popular 
book (Tanur et al., 1989) suggests, is it "a guide to 
the unknown"? We'll see in Chapter 1 that each of 
these descriptions is applicable in understanding 
what statistics is. We'll see that there are two areas of 
statistics: descriptive statistics, which focuses on de- 
veloping graphical and numerical summaries that de- 
scribe some business phenomenon, and inferential 
statistics, which uses these numerical summaries to 
assist in making business decisions. The primary 
theme of this text is inferential statistics. Thus, we'll 
concentrate on showing how you can use statistics 
to interpret data and use them to make decisions. 
Many jobs in industry, government, medicine, and 
other fields require you to make data-driven deci- 
sions, so understanding these methods offers you im- 
portant practical benefits. 

2 
CHAPTER 1 
S t a t i s t i c s ,  D a t a ,  a n d  S t a t i s t i c a l  T h i n k i n g  
THE SCIENCE OF STATISTICS 
What does statistics mean to you? Does it bring to mind batting averages, Gallup 
polls, unemployment figures, or numerical distortions of facts (lying with statistics!)? 
Or is it simply a college requirement you have to complete? We hope to persuade 
you that statistics is a meaningful, useful science whose broad scope of applications to 
business, government, and the physical and social sciences is almost limitless. We 
also want to show that statistics can lie only when they are misapplied. Finally, we 
wish to demonstrate the key role statistics play in critical thinking-whether 
in the 
classroom, on the job, or in everyday life. Our objective is to leave you with the im- 
pression that the time you spend studying this subject will repay you in many ways. 
The Random House College Dictionary defines statistics as "the science that 
deals with the collection, classification, analysis, and interpretation of information 
or data." Thus, a statistician isn't just someone who calculates batting averages at 
baseball games or tabulates the results of a Gallup poll. Professional statisticians 
are trained in statistical science. That is, they are trained in collecting numerical in- 
formation in the form of data, evaluating it, and drawing conclusions from it. Fur- 
thermore, statisticians determine what information is relevant in a given problem 
and whether the conclusions drawn from a study are to be trusted. 
Statistics is the science of data. It involves collecting, classifying, summarizing, 
organizing, analyzing, and interpreting numerical information. 
In the next section, you'll see several real-life examples of statistical appli- 
cations in business and government that involve making decisions and drawing 
conclusions. 
TYPES OF STATISTICAL APPLICATIONS IN BUSINESS 
Statistics means "numerical descriptions" to most people. Monthly unemployment 
figures, the failure rate of a new business, and the proportion of female executives 
in a particular industry all represent statistical descriptions of large sets of data col- 
lected on some phenomenon. Often the data are selected from some larger set of 
data whose characteristics we wish to estimate. We call this selection process sam- 
pling. For example, you might collect the ages of a sample of customers at a video 
store to estimate the average age of all customers of the store.Then you could use 
your estimate to target the store's advertisements to the appropriate age group. 
Notice that statistics involves two different processes: (1) describing sets of data 
and (2) drawing conclusions (making estimates, decisions, predictions, etc.) about 
the sets of data based on sampling. So, the applications of statistics can be divided 
into two broad areas: descriptive statistics and inferential statistics. 
DEFINITION 1.2 
Descriptive statistics utilizes numerical and graphical methods to look for 
patterns in a data set, to summarize the information revealed in a data set, 
and to present the information in a convenient form. 

SECTION 1.2 
Types o f  Statistical Applications in Business 
3 
,- 
DEFINITION 1.3 
Inferential statistics utilizes sample data to make estimates, decisions, 
predictions, or other generalizations about a larger set of data. 
Although we'll discuss both descriptive and inferential statistics in the fol- 
lowing chapters, the primary theme of the text is inference. 
Let's begin by examining some business studies that illustrate applications of 
statistics. 
Study 1 
"U.S. Market Share for Credit Cards" ( The Nilson Report, Oct. 8,1998) 
The Nilson Report collected data on all credit or debit card purchases in the Unit- 
ed States during the first six months of 1998. The amount of each purchase was 
recorded and classified according to type of card used. The results are shown in 
the Associated Press graphic, Figure 1.1. From the graph, you can clearly see that 
half of the purchases were made with a VISA card and one-fourth with a Master- 
Card. Since Figure 1.1 describes the type of card used in all credit card purchases 
for the first half of 1998, the graphic is an example of descriptive statistics. 
FIGURE 1.1 
U.S. Credit Card Market 
Shares 
Source: The Nilson Report, Oct. 8, 
1998. 
Diners Club 1% 
Study 2 
"The Executive Compensation Scoreboard" (Business Week, Apr. 19, 
1999) 
How much are the top corporate executives in the United States being paid and 
are they worth it? To answer these questions, Business Week magazine compiles its 
"Executive ~om~ensat'ion 
Scoreboard" each year based on a survey of executives 
at the highest-ranking companies listed in the Business Week 1000. The average* 
total pay of chief executive officers (CEOs) at 365 companies sampled in the 
1998 scoreboard was $10.6 million-an 
increase of 36% over the previous year. 
*Although we will not formally define the term average until Chapter 2, typical or middle can be 
substituted here without confusion. 

- 
4 
CHAPTER 1 
S t a t i s t i c s ,  D a t a ,  a n d  S t a t i s t i c a l  T h i n k i n g  
TABLE 
1.1 Average 
Return-to-Pay Ratios of 
CEOs, by lndustry 
Average 
Industry 
Ratio 
............................................................ ,.. 
Industrial high-tech 
Services 
Telecommunications 
Utilities 
Financial 
Consumer products 
Resources 
Industrial low-tech 
Transportation 
Source: Analysis of data in 
"Executive Compensation 
Scoreboard," Business Week, 
Apr~l 19,1999. 
To determine which executives are worth their pay, Business Week also 
records the ratio of total shareholder return (measured by the dollar value of a 
$100 investment in the company made 3 years earlier) to the total pay of the 
CEO (in thousand dollars) over the same 3-year period. For example, a $100 in- 
vestment in Walt Disney corporation in 1995 was worth $156 at the end of 1998. 
When this shareholder return ($156) is divided by CEO Michael Eisner's total 
1996-1998 pay of $594.9 million, the result is a return-to-pay ratio of only .0003, 
one of the lowest among all other chief executives in the survey. 
An analysis of the sample data set reveals that CEOs in the industrial high- 
technology industry have one of the highest average return-to-pay ratios (.046) 
while the CEOs in the transportation industry have one of the lowest average ratios 
(.015). (See Table 1.1.) Armed with this sample information Business Week might 
infer that, from the shareholders' perspective, typical chief executives in trans- 
portation are overpaid relative to industrial high-tech CEOs. Thus, this study is an 
example of inferential statistics. 
Study 3 
"The Consumer Price Index" (US. Department of Labor) 
A data set of interest to virtually all Americans is the set of prices charged for 
goods and services in the U.S. economy. The general upward movement in this set 
of prices is referred to as inflation; the general downward movement is referred to 
as deflation. In order to estimate the change in prices over time, the Bureau of 
Labor Statistics (BLS) of the U.S. Department of Labor developed the Consumer 
Price Index (CPI). Each month, the BLS collects price data about a specific col- 
lection of goods and services (called a market bu~ket) from 85 urban areas around 
the country. Statistical procedures are used to compute the CPI from this sample 
price data and other information about consumers' spending habits. By comparing 
the level of the CPI at different points in time, it is possible to e> ;mate (make an 
inference about) the rate of inflation over particular time intends and to com- 
pare the purchasing power of a dollar at different points in time. 
One major use of the CPI as an index of inflation is as an indicator of the suc- 
cess or failure of government economic policies. A second use of the CPI is to esca- 
late income payments. Millions of workers have escalator clauses in their collective 
bargaining contracts; these clauses call for increases in wage rates based on increas- 
es in the CPI. In addition, the incomes of Social Security beneficiaries and retired 
military and federal civil service employees are tied to the CPI. It has been estimat- 
ed that a 1% increase in the CPI can trigger an increase of over $1 billion in income 
payments.Thus, it can be said that the very livelihoods of millions of Americans de- 
pend on the behavior of a statistical estimator, the CPI. 
Like Study 2, this study is an example of inferential statistics. Market basket 
price data from a sample of urban areas (used to compute the CPI) are used to 
make inferences about the rate of inflation and wage rate increases. 
These studies provide three real-life examples of the uses of statistics in 
business, economics, and government. Notice that each involves an analysis of 
data, either for the purpose of describing the data set (Study 1) or for making in- 
ferences about a data set (Studies 2 and 3). 
FUNDAMENTAL ELEMENTS OF STATISTICS 
Statistical methods are particularly useful for studying, analyzing, and learning 
about populations. 

SECTION 
1.3 
Fundamental Elements o f  Statistics 
5 
c 
FINITION 1.4 
A population is a set of units (usually people, objects, transactions, or events) 
that we are interested in studying. 
For example, populations may include (1) all employed workers in the 
United States, (2) all registered voters in California, (3) everyone who has pur- 
chased a particular brand of cellular telephone, (4) all the cars produced last 
year by a particular assembly line, ( 5 )  the entire stock of spare parts at United 
Airlines' maintenance facility, (6) all sales made at the drive-through window of 
a McDonald's restaurant during a given year, and (7) the set of all accidents oc- 
curring on a particular stretch of interstate highway during a holiday period. 
Notice that the first three population examples (1-3) are sets (groups) of people, 
the next two (4-5) are sets of objects, the next (6) is a set of transactions, and the 
last (7) is a set of events. Also notice that each set includes all the units in the 
population of interest. 
In studying a population, we focus on one or more characteristics or prop- 
erties of the units in the population. We call such characteristics variables. For 
example, we may be interested in the variables age, gender, income, and/or the 
number of years of education of the people currently unemployed in the United 
States. 
DEFINITION 1.5 
A variable is a characteristic or property of an individual population unit. 
\ The name "variable" is derived from the fact that any particular character- 
istic may vary among the units in a population. 
In studying a particular variable it is helpful to be able to obtain a numerical 
representation for it. Often, however, numerical representations are not readily 
available, so the process of measurement plays an important supporting role in 
statistical studies. Measurement is the process we use to assign numbers to vari- 
ables of individual population units. We might, for instance, measure the prefer- 
ence for a food product by asking a consumer to rate the product's taste on a scale 
from 1 to 10. Or we might measure workforce age by simply asking each worker 
how old she is. In other cases, measurement involves the use of instruments such 
as stopwatches, scales, and calipers. 
If the population we wish to study is small, it is possible to measure a vari- 
able for every unit in the population. For example, if you are measuring the start- 
ing salary for all University of Michigan MBA graduates last year, it is at least 
feasible to obtain every salary. When we measure a variable for every unit of a 
population, the result is called a census of the population. Typically, however, the 
, I 
populations of interest in most applications are much larger, involving perhaps 
many thousands or even an infinite number of units. Examples of large popula- 
tions include those following Definition 1.4, as well as all invoices produced in the 
last year by a Fortune 500 company, all potential buyers of a new fax machine, and 
all stockholders of a firm listed on the New York Stock Exchange. For such popu- 
lations, conducting a census would be prohibitively time-consuming and/or costly. 

6 
CHAPTER 1 
S t a t i s t i c s ,  Data, and Statistical Thinking 
A reasonable alternative would be to select and study a subset (or portion) of the 
units in the population. 
A sample is a subset of the units of a population. 
For example, suppose a company is being audited for invoice errors. Instead 
of examining all 15,472 invoices produced by the company during a given year, an 
auditor may select and examine a sample of just 100 invoices (see Figure 1.2). If he 
is interested in the variable "invoice error status," he would record (measure) the 
status (error or no error) of each sampled invoice. 
F I G U R E  1.2 
A sample of all 
company invoices 
Population 
Sample 
1st invoice selected 
-7 
2nd invoice selected 
-7 
15,472 invoices 
r-7 - 
100th invoice selected 
After the variable(s) of interest for every unit in the sample (or popula- 
tion) is measured, the data are analyzed, either by descriptive or inferential sta- 
tistical methods. The auditor, for example, may be interested only in describing 
the error rate in the sample of 100 invoices. More likely, however, he will want to 
use the information in the sample to make inferences about the population of all 
15,472 invoices. 

L 
SECTION 1.3 
Fundamental Elements o f  Statistics 
7 
DEFINITION 1.7 
A statistical inference is an estimate or prediction or some other generaliza- 
tion about a population based on information contained in a sample. 
That is, we use the information contained in the sample to learn about the 
larger population." Thus, from the sample of 100 invoices, the auditor may esti- 
mate the total number of invoices containing errors in the population of 15,472 in- 
voices. The auditor's inference about the quality of the firm's invoices can be used 
in deciding whether to modify the firm's billing operations. 
underfilled paint cans. As a result, the retailer has begun inspecting incoming 
shipments of paint from suppliers. Shipments with underfill prob1;ms 
will be 
returned to the supplier. A recent shipment contained 2,440 gallon-size cans. The 
retailer sampled 50 cans and weighed each on a scale capable of measuring weight 
to four decimal places. Properly filled cans weigh 10 pounds. 
a. Describe the population. 
b. Describe the variable of interest. 
c. Describe the sample. 
, .' 
d. Describe the inference. 
S o I u t i o n 
a. The population is the set of units of interest to the retailer, which is the 
shipment of 2,440 cans of paint. 
I 
b. The weight of the paint cans is the variable the retailer wishes to evaluate. 
c. The sample is a subset of the population. In this case, it is the 50 cans of paint 
selected by the retailer. 
d. The inference of interest involves the generalization of the information con- 
tained in the weights of the sample of paint cans to the population of paint 
cans. In particular, the retailer wants to learn about the extent of the under- 
fill problem (if any) in the population. This might be accomplished by find- 
ing the average weight of the cans in the sample and using it to estimate the 
average weight of the cans in the population. 
s 
..%""a 
wa"""-"mmm"" " m  S" """ """*"rn 
""msss"w"~mm"w 
m-"la%,-"t"- 
m""wn*-m""am"*"m-"a"" 
"" 
"Cola wars" is the popular term for the intense competition between Coca-Cola 
and Pepsi displayed in their marketing campaigns. Their campaigns have featured 
movie and television stars, rock videos, athletic endorsements, and claims of 
consumer preference based on taste tests. Suppose, as part of a Pepsi marketing 
campaign, 1,000 cola consumers are given a blind taste test (i.e., a taste test in 
which the two brand names are disguised). Each consumer is asked to state a 
preference for brand A or brand B. 
a. Describe the population. 
b. Describe the variable of interest. 
*The termspopulation and sample are often used to refer to the sets of measurements themselves, 
as well as to the units on wh~ch the measurements are made. When a single variable of interest 1s 
being measured, this usage causes little confusion But when the terminology is ambiguous, we'll 
refer to the measurements as populutmn dutu sets and sample dutu wtr, respectively 

CHAPTER 
1 
S t a t i s t i c s ,  Data, a n d  Statistical Thinking 
c. Describe the sample. 
d. Describe the inference. 
S o I u t i o n 
a. The population of interest is the collection or set of all cola consumers. 
b. 
The characteristic that Pepsi wants to measure is the consumer's cola pref- 
erence as revealed under the conditions of a blind taste test, so cola prefer- 
ence is the variable of interest. 
c. The sample is the 1,000 cola consumers selected from the population of all 
cola consumers. 
d. The inference of interest is the generalization of the cola preferences of the 
1,000 sampled consumers to the population of all cola consumers. In partic- 
ular, the preferences of the consumers in the sample can be used to estimate 
the percentage of all cola consumers who prefer each brand. 
The preceding definitions and examples identify four of the five elements of 
an inferential statistical problem: a population, one or more variables of interest, 
a sample, and an inference. But making the inference is only part of the story. We 
also need to know its reliability-that 
is, how good the inference is.The only way 
we can be certain that an inference about a population is correct is to include the 
entire population in our sample. However, because of resource constraints (i.e., in- 
sufficient time and/or money), we usually can't work with whole populations, so 
we base our inferences on just a portion of the population (a sample). Conse- 
quently, whenever possible, it is important to determine and report the reliability 
of each inference made. Reliability, then, is the fifth element of inferential statis- 
tical problems. 
The measure of reliability that accompanies an inference separates the sci- 
ence of statistics from the art of fortune-telling. A palm reader, like a statistician, 
may examine a sample (your hand) and make inferences about the population 
(your life). However, unlike statistical inferences, the palm reader's inferences 
include no measure of reliability. 
Suppose, as in Example 1.1, we are interested in estimating the average 
weight of a population of paint cans from the average weight of a sample of cans. 
Using statistical methods, we can determine a bound o n  the estimation error. This 
bound is simply a number that our estimation error (the difference between the 
average weight of the sample and the average weight of the population of cans) is 
not likely to exceed. We'll see in later chapters that this bound is a measure of the 
uncertainty of our inference. The reliability of statistical inferences is discussed 
throughout this text. For now, we simply want you to realize that an inference is 
incomplete without a measure of its reliability. 
DEFINITION 1.8 
A measure of reliability is a statement (usually quantified) about the degree 
of uncertainty associated with a statistical inference. 
Let's conclude this section with a summary of the elements of both descrip- 
tive and inferential statistical problems and an example to illustrate a measure of 
reliability. 

i ,. 
SECTION 1.4 
Processes ( O p t i o n a l )  
9 
scriptive Statistical Proble 
1. The population or sample of interest 
2. One or more variables (characteristics of the population or sampl 
units) that are to be investigated 
3. Tables, graphs, or numerical summary tools 
4. Conclusions about the data based on the patterns revealed 
2. One or more variables (characteristics of the population units) that are 
to be investigated 
3. The sample of population units 
4. The inference about the population based on information contained in 
the sample 
- u s " s , - ~ w ~ ~ m a , ,  
sumers were 
indicated in a taste test. Describe how the reliability of an inference concerning. - 
the preferences of all cola consumers in the Pepsi bottler's marketing region 
could be measured. 
S o I u t i o n When the preferences of 1,000 consumers are used to estimate the preferences of 
all consumers in the region, the estimate will not exactly mirror the preferences of 
the population. For example, if the taste test shows that 56% of the 1,000 consumers 
chose Pepsi, it does not follow (nor is it likely) that exactly 56% of all cola 
drinkers in the region prefer Pepsi. Nevertheless, we can use sound statistical 
reasoning (which is presented later in the text) to ensure that our sampling 
procedure will generate estimates that are almost certainly within a specified 
limit of the true percentage of all consumers who prefer Pepsi. For example, such 
reasoning might assure us that the estimate of the preference for Pepsi from the 
sample is almost certainly within 5% of the actual population preference. The 
implication is that the actual preference for Pepsi is between 51% [i.e., 
(56 - 5)%] and 61% [i.e., (56 + 5)%]-that 
is, (56 ? 5)%. This interval 
represents a measure of reliability for the inference. 
* 
PROCESSES (OPTIONAL) 
Sections 1.2 and 1.3 focused on the use of statistical methods to analyze and learn 
about populations, which are sets of existing units. Statistical methods are equally 
useful for analyzing and making inferences about processes. 
DEF 
A process is a series of actions or operations that transforms inputs to 
outputs. A process produces or generates output over time. 

10 
CHAPTER 
1 
Statistics, Data, a n d  Statistical Thinking 
FIGURE 1.3 
Graphical depiction of a 
manufacturing process 
The most obvious processes that are of interest to businesses are production 
or manufacturing processes. A manufacturing process uses a series of operations 
performed by people and machines to convert inputs, such as raw materials and 
parts, to finished products (the outputs). Examples include the process used to 
produce the paper on which these words are printed, automobile assembly lines, 
and oil refineries. 
Figure 1.3 presents a general description of a process and its inputs and out- 
puts. In the context of manufacturing, the process in the figure (i.e., the transfor- 
mation process) could be a depiction of the overall production process or it could 
be a depiction of one of the many processes (sometimes called subprocesses) that 
exist within an overall production process. Thus, the output shown could be fin- 
ished goods that will be shipped to an external customer or merely the output of 
one of the steps or subprocesses of the overall process. In the latter case, the out- 
put becomes input for the next subprocess. For example, Figure 1.3 could repre- 
sent the overall automobile assembly process, with its output being fully 
assembled cars ready for shipment to dealers. Or, it could depict the windshield 
assembly subprocess, with its output of partially assembled cars with windshields 
ready for "shipment" to the next subprocess in the assembly line. 
INPUTS 
OUTPUTS 
TRANSFORMATION PROCESS 
Information 
Methods 
,- I 
Materials 
Machines 
Implemented by people 
People --- 
and/or mach~nes 
I 
Besides physical products and services, businesses and other organizations 
generate streams of numerical data over time that are used to evaluate the per- 
formance of the organization. Examples include weekly sales figures, quarterly 
earnings, and yearly profits. The U.S. economy (a complex organization) can be 
thought of as generating streams of data that include the Gross Domestic Product 
(GDP), stock prices, and the Consumer Price Index (see Section 1.2). Statisti- 
cians and other analysts conceptualize these data streams as being generated by 
processes. Typically, however, the series of operations or actions that cause partic- 
ular data to be realized are either unknown or so complex (or both) that the 
processes are treated as bluck boxes. 
A process whose operations or actions are unknown or unspecified is called a 
black box. 
Frequently, when a process is treated as a black box, its inputs are not spec- 
ified either. The entire focus is on the output of the process. A black box process is 
illustrated in Figure 1.4. 

SECTION 1.4 
Processes ( O p t i o n a l )  
11 
FIGURE 1.4 
A black box process with 
numerical output 
TRANSFORMATION PROCESS 
F 
INPUTS -I 
In studying a process, we generally focus on one or more characteristics, or 
properties, of the output. For example, we may be interested in the weight or the 
length of the units produced or even the time it takes to produce each unit. As 
with characteristics of population units, we call these characteristics variables. In 
studying processes whose output is already in numerical form (i.e., a stream of 
numbers), the characteristic, or property, represented by the numbers (e.g., sales, 
GDP, or stock prices) is typically the variable of interest. If the output is not nu- 
meric, we use measurement processes to assign numerical values to variables." 
For example. if in the automobile assembly process the weight of the fully assem- 
bled automobile is the variable of interest, a measurement process involving a 
large scale will be used to assign a numerical value to each automobile. 
As with populations, we use sample data to analyze and make inferences (es- 
timates, predictions, or other generalizations) about processes. But the concept of 
a sample is defined differently when dealing with processes. Recall that a popula- 
tion is a set of existing units and that a sample is a subset of those units. In the case 
of processes, however, the concept of a set of existing units is not relevant or ap- 
propriate. Processes generate or create their output over time-one 
unit after an- 
other. For example, a particular automobile assembly line produces a completed 
vehicle every four minutes. We define a sample from a process in the box. 
Any set of output (objects or numbers) produced by a process is called a 
sample. 
Thus, the next 10 cars turned out by the assembly line constitute a sample 
from the process, as do the next 100 cars or every fifth car produced today. 
considering offering a 50% discount to customers who wait more than a specified 
, number of minutes to receive their order. To help determine what the time limit 
should be, the company decided to estimate the average waiting time at a 
particular drive-through window in Dallas,Texas. For seven consecutive days, the 
worker taking customers' orders recorded the time that every order was placed. 
The worker who handed the order to the customer recorded the time of delivery. 
In both cases, workers used synchronized digital clocks that reported the time to 
the nearest second. At the end of the 7-day period, 2,109 orders had been timed. 
*A process whose output is already in numerical form necessarily includes a measurement 
process as one of its subprocesses. 

12 
CHAPTER 
1 
S t a t i s t i c s ,  D a t a ,  a n d  S t a t i s t i c a l  T h i n k i n g  
a. Describe the process of interest at the Dallas restaurant. 
- 
b. Describe the variable of interest. 
c. Describe the sample. 
d. Describe the inference of interest. 
- 
e. Describe how the reliability of the inference could be measured. 
S o I u t i o n 
a. The process of interest is the drive-through window at a particular fast-food 
restaurant in Dallas, Texas. It is a process because it "produces," or "gener- 
ates," meals over time. That is, it services customers over time. 
The variable the company monitored is customer waiting time, the length 
of time a customer waits to receive a meal after placing an order. Since the 
study is focusing only on the output of the process (the time to produce 
the output) and not the internal operations of the process (the tasks re- 
quired to produce a meal for a customer), the process is being treated as a 
black box. 
The sampling plan was to monitor every order over a particular 7-day pe- 
riod. The sample is the 2,109 orders that were processed during the 7-day 
period. 
The company's immediate interest is in learning about the drive-through 
window in Dallas. They plan to do this by using the waiting times from the 
sample to make a statistical inference about the drive-through process. In 
particular, they might use the average waiting time for the sample to esti- 
mate the average waiting time at the Dallas facility. 
As for inferences about populations, measures of reliability can be de- 
veloped for inferences about processes. The reliability of the estimate of 
the average waiting time for the Dallas restaurant could be measured by 
a bound on the error of estimation. That is, we might find that the aver- 
age waiting time is 4.2 minutes, with a bound on the error of estimation 
of .5 minute. The implication would be that we could be reasonably cer- 
tain that the true average waiting time for the Dallas process is between 
3.7 and 4.7 minutes. 
Notice that there is also a population described in this example: the compa- 
ny's 6,289 existing outlets with drive-through facilities. In the final analysis, 
the company will use what it learns about the process in Dallas and, perhaps, 
similar studies at other locations to make an inference about the waiting 
times in its populations of outlets. 
I 
Note that olltput already generated by a process can be viewed as a popula- 
tion. Suppose a soft-drink canning process produced 2,000 twelve-packs yesterday, 
all of which were stored in a warehouse. If we were interested in learning some- 
thing about those 2,000 packages-such 
as the percentage with defective card- 
board packaging-we 
could treat the 2,000 packages as a population. We might 
draw a sample from the population in the warehouse, measure the variable of in- 
terest, and use the sample data to make a statistical inference about the 2,000 
.. 
packages, as described in Sections 1.2 and 1.3. 
In this optional section we have presented a brief introduction to processes 
and the use of statistical methods to analyze and learn about processes. In Chap- 
- 
ter 11 we present an in-depth treatment of these subjects. 

SECTION 1.5 
T y p e s  of Data 
13 
TYPES OF DATA 
You have learned that statistics is the science of data and that data are obtained 
by measuring the values of one or more variables on the units in the sample (or 
population). All data (and hence the variables we measure) can be classified as 
one of two general types: quantitative data and qualitative data. 
Quantitative data are data that are measured on a naturally occurring nu- 
merical scale." The following are examples of quantitative data: 
1. The temperature (in degrees Celsius) at which each unit in a sample of 20 
pieces of heat-resistant plastic begins to melt 
2. The current unemployment rate (measured as a percentage) for each of the 
50 states 
3. The scores of a sample of 150 MBA applicants on the GMAT, a standardized 
business graduate school entrance exam administered nationwide 
4. The number of female executives employed in each of a sample of 75 man- 
ufacturing companies 
DEFINITION 1.12 
Quantitative data are measurements that are recorded on a naturally occur- 
ring numerical scale. 
In contrast, qualitative data cannot be measured on a natural numerical 
scale; they can only be classified into categoriest Examples of qualitative data are: 
1. The political party affiliation (Democrat, Republican, or Independent) in a 
sample of 50 chief executive officers 
2. The defective status (defective or not) of each of 100 computer chips manu- 
factured by Intel 
3. The size of a car (subcompact, compact, mid-size, or full-size) rented by 
each of a sample of 30 business travelers 
4. A taste tester's ranking (best, worst, etc.) of four brands of barbecue sauce 
for a panel of 10 testers 
Often, we assign arbitrary numerical values to qualitative data for ease of 
computer entry and analysis. But these assigned numerical values are simply 
codes: They cannot be meaningfully added, subtracted, multiplied, or divided. For 
example, we might code Democrat = 1, Republican = 2, and Independent = 3. 
Similarly, a taste tester might rank the barbecue sauces from 1 (best) to 4 (worst). 
These are simply arbitrarily selected numerical codes for the categories and have 
no utility beyond that. 
*Quantitative data can be subclassified as either interval data or ratio data. For ratio data. the 
origin (i.e., the value 0) is a meaningful number. But the origin has no meaning with interval data. 
Consequently, we can add and subtract interval data, but we can't multiply and divide them. Of 
the four quantitative data sets listed, (1) and (3) are interval data, while (2) and (4) are ratio data. 
'Qualitative data can be subclassified as either nominal data or ordinal data. The categories of 
an ordinal data set can be ranked or meaningfully ordered. but the categories of a nominal data 
set can't be ordered. Of the four qualitative data sets listed above, (1) and (2) are nominal and 
(3) and (4) are ordinal. 

14 
CHAPTER 
1 
S t a t i s t i c s ,  Data, a n d  Statistical Thinking 
DEFINITION 1.1 3 
Qualitative data are measurements that cannot be measured on a natural nu- 
merical scale; they can only be classified into one of a group of categories. 
Chemical and manufacturing plants sometimes discharge toxic-waste materials 
such as DDT into nearby rivers and streams. These toxins can adversely affect the 
plants and animals inhabiting the river and the river bank. The U.S. Army Corps of 
Engineers conducted a study of fish in the Tennessee River (in Alabama) and its 
three tributary creeks: Flint Creek, Limestone Creek, and Spring Creek. A total 
of 144 fish were captured and the following variables measured for each: 
S o l u t i o n  
1. Riverlcreek where fish was captured 
2. Species (channel catfish, largemouth bass, or smallmouth buffalofish) 
3. Length (centimeters) 
4. Weight (grams) 
5. DDT concentration (parts per million) 
Classify each of the five variables measured as quantitative or qualitative. 
The variables length, weight, and DDT are quantitative because each is measured 
on a numerical scale: length in centimeters, weight in grams, and DDT in parts per 
million. In contrast, riverlcreek and species cannot be measured quantitatively: 
They can only be classified into categories (e.g., channel catfish, largemouth bass, 
and smallmouth buffalofish for species). Consequently, data on riverlcreek and 
species are qualitative. 
i "  
As you would expect, the statistical methods for describing, reporting, and 
analyzing data depend on the type (quantitative or qualitative) of data measured. 
We demonstrate many useful methods in the remaining chapters of the text. But 
first we discuss some important ideas on data collection. 
COLLECTING DATA 
Once you decide on the type of data-quantitative 
or qualitative-appropriate 
for the problem at hand, you'll need to collect the data. Generally, you can obtain 
the data in four different ways: 
1. Data from apublished source 
2. Data from a designed experiment 
3. Data from a survey 
4. Data collected observationally 
Sometimes, the data set of interest has already been collected for you and is 
available in a published source, such as a book, journal, or newspaper. For example, 
you may want to examine and summarize the unemployment rates (i.e., percentages 
of eligible workers who are unemployed) in the 50 states of the United States. You 
can find this data set (as well as numerous other data sets) at your library in the Sta- 
tistical Abstract of the United States, published annually by the US. government. Sim- 
ilarly, someone who is interested in monthly mortgage applications for new home 

SECTION 1.6 
C o l l e c t i n g  D a t a  
15 
construction would find this data set in the Survey of Current Business, another gov- 
ernment publication. Other examples of published data sources include The Wall 
Street Journal (financial data) and The Sporting News (sports information)." 
A second method of collecting data involves conducting a designed experi- 
ment, in which the researcher exerts strict control over the units (people, objects, 
or events) in the study. For example, a recent medical study investigated the po- 
tential of aspirin in preventing heart attacks. Volunteer physicians were divided 
into two groups-the 
treatment group and the control group. In the treatment 
group, each physician took one aspirin tablet a day for one year, while each physi- 
cian in the control group took an aspirin-free placebo (no drug) made to look like 
an aspirin tablet. The researchers, not the physicians under study, controlled who 
received the aspirin (the treatment) and who received the placebo. A properly de- 
signed experiment allows you to extract more information from the data than is 
possible with an uncontrolled study. 
Surveys are a third source of data. With a survey, the researcher samples a 
group of people, asks one or more questions, and records the responses. Probably 
the most familiar type of survey is the political polls conducted by any one of a 
number of organizations (e.g., Harris, Gallup, Roper, and CNN) and designed to 
predict the outcome of a political election. Another familiar survey is the Nielsen 
survey, which provides the major television networks with information on the 
most watched TV programs. Surveys can be conducted through the mail, with 
telephone interviews, or with in-person interviews. Although in-person interviews 
are more expensive than mail or telephone surveys, they may be necessary when 
complex information must be collected. 
Finally, observational studies can be employed to collect data. In an obser- 
vational study, the researcher observes the experimental units in their natural set- 
ting and records the variable(s) of interest. For example, a company psychologist 
might observe and record the level of "Type A" behavior of a sample of assembly 
line workers. Similarly, a finance researcher may observe and record the closing 
stock prices of companies that are acquired by other firms on the day prior to the 
buyout and compare them to the closing prices on the day the acquisition is an- 
nounced. Unlike a designed experiment, an observational study is one in which the 
researcher makes no attempt to control any aspect of the experimental units. 
Regardless of the data collection method employed, it is likely that the data 
will be a sample from some population. And if we wish to apply inferential statis- 
tics, we must obtain a representative sample. 
DEFINITION 1.14 
A representative sample exhibits characteristics typical of those possessed 
by the population of interest. 
For example, consider a political poll conducted during a presidential elec- 
tion year. Assume the pollster wants to estimate the percentage of all 120,000,000 
registered voters in the United States who favor the incumbent president. The 
pollster would be unwise to base the estimate on survey data collected for a sam- 
ple of voters from the incumbent's own state. Such an estimate would almost cer- 
tainly be biased high. 
*With published data, we often make a distinction between the primary source and secondary 
source. If the publisher is the original collector of the data, the source is primary. Otherwise, the 
data are secondary source data. 

16 
CHAPTER 
1 
S t a t i s t i c s ,  D a t a ,  a n d  S t a t i s t i c a l  T h i n k i n g  
The most common way to satisfy the representative sample requirement is 
to select a random sample. A random sample ensures that every subset of fixed 
size in the population has the same chance of being included in the sample. If the 
pollster samples 1,500 of the 120,000,000 voters in the population so that every 
subset of 1,500 voters has an equal chance of being selected, he has devised a ran- 
dom sample. The procedure for selecting a random sample is discussed in Chap- 
ter 3. Here, however, let's look at two examples involving actual sampling studies. 
psychologist designed a series of 10 questions based on a widely used set of 
criteria for gambling addiction and distributed them through the Web site, 
S o l u t i o n  
ABCNews.com.(A sample question: "Do you use the Internet to escape 
problems?") A total of 17,251 Web users responded to the questionnaire. If 
participants answered "yes" to at least half of the questions, they were viewed as 
addicted. The findings, released at the 1999 annual meeting of the American 
Psychological Association, revealed that 990 respondents, or 5.7%, are addicted to 
the Internet (Tampa Tribune, Aug. 23,1999). 
Identify the data collection method. 
Identify the target population. 
Are the sample data representative of the population? 
The data collection method is a survey: 17,251 Internet users responded to 
the questions posed at the ABCNews.com Web site. 
Since the Web site can be accessed by anyone surfing the Internet, presum- 
ably the target population is all Internet users. 
Because the 17,251 respondents clearly make up a subset of the target pop- 
ulation, they do form a sample. Whether or not the sample is representative 
is unclear, since we are given no information on the 17,251 respondents. 
However, a survey like this one in which the respondents are self-selected 
(i.e., each Internet user who saw the survey chose whether or not to re- 
spond to it) often suffers from nonresponse bim. It is possible that many In- 
ternet users who chose not to respond (or who never saw the survey) would 
have answered the questions differently, leading to a higher ( or lower) per- 
centage of affirmative answers. 
+. 
conducted a study to determine how such a positive effect influences the risk 
preference of decision-makers (Organizational Behavior and Humun Decision 
Processes, Vol. 39, 1987). Each in a random sample of 24 undergraduate business 
students at the university was assigned to one of two groups. Each student assigned 
to the "positive affect" group was given a bag of candies as a token of appreciation 
for participating in the study; students assigned to the "control" group did not receive 
the gift. All students were then given 10 gambling chips (worth $10) to bet in the 
casino game of roulette.The researchers measured the win probability (is., chance of 
winning) associated with the riskiest bet each student was willing to make. The win 
probabilities of the bets made by two groups of students were compared. 
a. Identify the data collection method. 
b. Are the sample data representative of the target population? 

SECTION 
1.7 
T h e  Role of S t a t i s t i c s  in M a n a g e r i a l  D e c i s i o n - M a k i n g  
17 
S o I u t i o n 
a. The researchers controlled which group-"positive 
affect" or "control"-- 
the students were assigned to. Consequently, a designed experiment was 
used to collect the data. 
b. The sample of 24 students was randomly selected from all business students 
at the Ohio State University. If the target population is all Ohio State Uni- 
versity busines~ students, it is likely that the sample is representative. How- 
ever, the researchers warn that the sample data should not be used to make 
inferences about other, more general, populations. 
THE ROLE OF STATISTICS I N  MANAGERIAL 
DECISION-MAKING 
According to H. G. Wells, author of such science fiction classics as The War of the 
Worlds and The Time Machine, "Statistical thinking will one day be as necessary 
for efficient citizenship as the ability to read and write." Written more than a 
hundred years ago, Wells' prediction is proving true today. 
The growth in data collection associated with scientific phenomena, business 
operations, and government activities (quality control, statistical auditing, fore- 
casting, etc.) has been remarkable in the past several decades. Every day the 
media present us with the published results of political, economic, and social sur- 
veys. In increasing government emphasis on drug and product testing, for exam- 
ple, we see vivid evidence of the need to be able to evaluate data sets intelligently. 
Consequently, each of us has to develop a discerning sense-an 
ability to use ra- 
tional thought to interpret and understand the meaning of data. This ability can 
help you make intelligent decisions, inferences, and generalizations; that is, it helps 
you think critically using statistics. 
DEFINITION 1 .I5 
Statistical thinking involves applying rational thought and the science of sta- 
tistics to critically assess data and inferences. Fundamental to the thought 
process is that variation exists in populations and process data. 
To gain some insight into the role statistics plays in critical thinking, let's 
look at a study evaluated by a group of 27 mathematics and statistics teachers at- 
tending an American Statistical Association course called "Chance." Consider 
the following excerpt from an article describing the problem. 
There are few issues in the news that are not in some way statistical. Take 
one. Should motorcyclists be required by law to wear helmets.?. . . In "The 
Case for N o  Helmets" (New York Times, June 17,1995), Dick Teresi, editor 
of a magazine for Harley-Davidson hikers, argued that helmet.\ may actually 
kill, since in collisions at speeds greater than 15 miles an hour the heavy 
helmet may protect the head hut snap the spine. [Teresi] citing a "study," said 
"nine states without helmet laws had a lower fatality rate (3.05 deaths per 
10,000 motorcycles) than those that mandated helmets (3.38)," and "in a 
survey of 2,500 [at a rally], 98% of the respondents opposed such laws." 
[The course instructors] asked:After reading this [New York Times] piece, 
do you think it is safer to ride a motorcycle without a helmet? Do you think 
98% might he a valid estimate o f  bikers who oppose helmet laws? What 

18 
CHAPTER 
1 
S t a t i s t i c s ,  D a t a ,  a n d  S t a t i s t i c a l  T h i n k i n g  
S T A T I S T I C S  I N  
A 20/20 View of Survey Resul 
Did you ever notice that, no matter where you 
stand on popular issues of the day, you can 
always filad stafistics or surveys to back up your 
point of view-whether 
to take vitamins, 
whether day care harms kids, or what foods can 
hurt you or save you? There is an endless flow 
of information to help you make decisions, but 
is this information accurate, unbiased? John 
Stossel decided to check that out, and you may 
be surprised to learn if the picture you're getting 
doesn't seem quite right, maybe it isn't. 
Barbara Walters gave this introduction to a March 31, 
1995, segment of the popular prime-time ABC television pro- 
gram 20/20. The story is titled "Facts or Fiction?-ExposCs of 
So-called Surveys." One of the surveys investigated by ABC 
correspondent John Stossel compared the discipline prob- 
lems experienced by teachers in the 1940s and those experi- 
enced today.The results: In the 1940s, teachers worried most 
about students talking in class, chewing gum, and running in 
the halls.Today, they worry most about being assaulted! This 
information was highly publicized in the print media-in 
daily 
newspapers, weekly magazines, Ann Landers' column, the 
Congressional Quarterly, and The Wall Street Journal, among 
others-and 
referenced in speeches by a variety of public fig- 
ures, including former first lady Barbara Bush and former 
Education secretary William Bennett. 
"Hearing this made me yearn for the old days when life 
was so much simpler and gentler, but was life that simple 
then?" asks Stossel. "Wasn't there juvenile delinquency [in 
the 1940s]? Is the survey true?" With the help of a Yale 
School of Management professor, Stossel found the original 
source of the teacher survey-Texas 
oilman T. Colin 
Davis-and 
discovered it wasn't a survey at all! Davis had 
simply identified certain disciplinary problems encountered 
by teachers in a conservative newsletter-a 
list he admitted 
was not obtained from a statistical survey, but from Davis' 
personal knowledge of the problems in the 1940s ("I was in 
school then") and his understanding of the problems today 
("I read the papers"). 
Stossel's critical thinking about the teacher "survey" led 
to the discovery of research that is misleading at best and 
unethical at worst. Several more misleading (and possibly 
unethical) surveys were presented on the ABC program. 
Listed here, most of these were conducted by businesses or 
special interest groups with specific objectives in mind. 
The 20/20 segment ended with an interview of Cynthia 
Crossen, author of Tainted Truth, an expos6 of misleading 
and biased surveys. Crossen warns: "If everybody is misus- 
ing numbers and scaring us with numbers to get us to do 
something, however good [that something] is, we've lost the 
power of numbers. Now, we know certain things from re- 
search. For example, we know that smoking cigarettes is 
hard on your lungs and heart, and because we know that, 
many people's lives have been extended or saved. We don't 
further statistical information would you like? [From Cohn, I/: "Chance in 
college curriculum," AmStat News, Aug -Sept. 1995, No. 223, p. 2.1 
You can use "statistical thinking" to help you critically evaluate the study. 
For example, before you can evaluate the validity of the 98% estimate, you would 
want to know how the data were collected for the study cited by the editor of the 
biker magazine. If a survey was conducted, it's possible that the 2,500 bikers in the 
sample were not selected at random from the target population of all bikers, but 
rather were "self-selected." (Remember, they were all attending a rally-a 
rally 
likely for bikers who oppose the law.) If the respondents were likely to have 
strong opinions regarding the helmet law (e.g., strongly oppose the law), the re- 
" sulting estimate is probably biased high. Also, if the biased sample was intention- 
al, with the sole purpose to mislead the public, the researchers would be guilty of 
unethical statistical practice. 
You'd also want more information about the study comparing the motorcycle 
fatality rate of the nine states without a helmet law to those states that mandate hel- 

SECTION 1.7 
T h e  Role of S t a t i s t i c s  i n  M a n a g e r i a l  D e c i s i o n - M a k i n g  
19 
want to lose the power of information to help us make de- 
cisions, and that's what I worry about." 
F
o
c
u
s
 
a. Consider the false March of Dimes report on domestic 
violence and birth defects. Discuss the type of data re- 
quired to investigate the impact of domestic violence on 
birth defects. What data collection method would you 
recommend? 
b. Refer to the American Association of University 
Women (AAUW) study of self-esteem of high school 
girls. Explain why the results of the AAUW study are 
likely to be misleading. What data might be appropriate 
for assessing the self-esteem of high school girls? 
c. Refer to the Food Research and Action Center study of 
hunger in America. Explain why the results of the study 
are likely to be misleading. What data would provide in- 
sight into the proportion of hungry American children? 
Reported Information (Source) 
Actual Study Information 
. , , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .-. . . . . . . . . . . . 
Eating oat bran is a cheap and easy way to reduce your 
Diet must consist of nothing but oat bran to achieve a 
cholesterol count. (Quaker Oats) 
slightly lower cholesterol count. 
150,000 women a year die from anorexia. (Feminist group) 
Approximately 1,000 women a year die from problems that 
were likely caused by anorexia. 
Domestic violence causes more birth defects than all 
No study-false 
report. 
medical issues combined. (March of Dimes) 
Only 29% of high school girls are happy with themselves, 
Of 3,000 high school girls 29% responded "Always true" to 
compared to 66% of elementary school girls. (American 
the statement, "I am happy the way I am." Most answered, 
Association of University Women) 
"Sort of true" and "Sometimes true." 
One in four American children under age 12 is hungry or at 
Based on responses to the questions: "Do you ever cut the 
risk of hunger. (Food Research and Action Center) 
size of meals?" "Do you ever eat less than you feel you 
should?" "Did you ever rely on limited numbers of foods 
to feed your children because you were running out of 
money to buy food for a meal?" 
mets. Were the data obtained from a published source? Were all 50 states included in 
the study? That is, are you seeing sample data or population data? Furthermore, do 
the helmet laws vary among states? If so, can you really compare the fatality rates? 
These questions led the Chance group to the discovery of two scientific and 
statistically sound studies on helmets. The first, a UCLA study of nonfatal in- 
juries, disputed the charge that helmets shift injuries to the spine. The second 
study reported a dramatic decline in motorcycle crash deaths after California 
passed its helmet law. 
Successful managers rely heavily on statistical thinking to help them make 
decisions. The role statistics can play in managerial decision-making is displayed in 
the flow diagram in Figure 1.5. Every managerial decision-making problem begins 
with a real-world problem. This problem is then formulated in managerial terms 
and framed as a managerial question. The next sequence of steps (proceeding 
counterclockwise around the flow diagram) identifies the role that statistics can 
play in this process.The managerial question is translated into a statistical question, 

20 
CHAPTER 
1 
S t a t i s t i c s ,  D a t a ,  a n d  S t a t i s t i c a l  T h i n k i n g  
F I G U R E  1.5 
Flow diagram showing the role 
of statistics in managerial 
decis~on-making 
Source Chervany, Benson, and lyer 
(1 980) 
Managerial formulation 
Manager~al question 
Answer to 
relatmg to problem 
managerial question 
t 
t 
Statistical formulation 
of questlon 
STATISTICAL 
the sample data are collected and analyzed, and the statistical question is an- 
swered. The next step in the process is using the answer to the statistical question to 
reach an answer to the managerial question. The answer to the managerial ques- 
tion may suggest a reformulation of the original managerial problem, suggest a new 
managerial question, or lead to the solution of the managerial problem. 
One of the most difficult steps in the decision-making process-one 
that re- 
quires a cooperative effort among managers and statisticians-is the translation of 
the managerial question into statistical terms (for example, into a question about 
a population). This statistical question must be formulated so that, when an- 
swered, it will provide the key to the answer to the managerial question. Thus, as 
in the game of chess, you must formulate the statistical question with the end re- 
sult, the solution to the managerial question, in mind. 
In the remaining chapters of the text, you'll become familiar with the tools 
essential for building a firm foundation in statistics and statistical thinking. 
Key Terms 
Note: Starred (*) terms are from the 
optional section in this chapter: 
Black box* 10 
Census 5 
n 
Data 2 
Descriptive statistics 2 
Designed experiment 16 
Inference 3 
Inferential statistics 3 
Measure of reliability 8 
Measurement 5 
Observational study 15 
Population 5 
Process* 9 
Published source 14 
Qualitative data 14 
Quantitative data 13 
Random sample 16 
Reliability 8 
Representative sample 15 
Sample 6,11 
Statistical inference 7 
Statistical thinking 17 
Statistics 2 
Survey 15 
Unethical statistical practice 18 
Variable 5 

E x e r c i s e s  
21 
Note: Swred (*) exercises are frorn the optional section in 
this chapter. 
Learning the Mechanics 
1.1 
What is statistics? 
Explain the difference between descriptive and infer- 
ential statistics. 
List and define the four elements of a descriptive sta- 
tistics problem. 
List and define the five elements of an inferential sta- 
tistical analysis. 
List the four major methods of collecting data and 
explain their differences. 
Explain the difference between quantitative and qual- 
itative data. 
Explain how populations and variables differ. 
Explain how populations and samples differ. 
What is a representative sample'? What is its value? 
1.10 Why would a statistician consider an inference incom- 
plete without an accompanying measure of its reliability? 
*1.11 Explain the difference between a population and a 
process. 
1.12 Define statistical thinking. 
1.13 Suppose you're given a data set that classifies each 
sample unit into one of four categories: A, B, C, or D. 
You plan to create a computer database consisting of 
these data, and you decidc to code the data as A = 1, 
B = 2, C = 3, and D = 4. Are the data consisting of 
the classifications A, B, C, and D qualitative or quan- 
titative? After the data are input as 1, 2, 3, or 4, are 
they qualitative or quantitative? Explain your 
answcrs. 
Applying the Concepts 
1.14 The Cutter Consortium recently surveyed 154 U.S. 
companies to determine the extent of their involve- 
ment In e-commerce.They found that "a stunning 65% 
of companies. . .do not have an overall e-commerce 
strategy." Four of the questions they asked are listed 
bclow. For each question, determine the variable of 
interest and classify it as quantitative or qualitative. 
(Internet Week, Sept. 6,1999, www.internetwk.corn) 
a. Do you have an overall e-commerce strategy? 
b. If you don't already have an e-commerce plan, 
when will you implement one: never, later than 
2000, by the second half of 2000, by the first half of 
2000, by the end of 1999? 
c. Are you delivering products over the Internet? 
d. What was your company's total revenue in the last 
fiscal year? 
1.15 Pollsters regularly conduct opinion polls to determine 
the popularity rating of the current president. Suppose a 
poll is to be conducted tomorrow in which 2,000 indi- 
viduals will be asked whether the president is doing a 
good or bad job. The 2,000 individuals will be selected 
by random-digit telephone dialing and asked the ques- 
tion over the phone. 
a. What is the relevant population? 
b. What is the variable of interest'? Is it quantitative or 
qualitative? 
c. What is the sample? 
d. What is the inference of interest to the pollster? 
e. What method of data collection is employed? 
f. How likely is the sample to be representative? 
1.16 Colleges and universities are requiring an increasing 
amount of information about applicants before making 
acceptance and financial aid decisions. Classify each of 
the following types of data required on a college appli- 
cation as quantitative or qualitative. 
a. High school GPA 
b. High school class rank 
c. Applicant's score on the SAT or ACT 
d. Gender of applicant 
e. Parents' income 
f. Age of applicant 
1.17 As the 1990s came to a close, the U.S. economy was boom- 
ing. One of the consequences was an ultra-tight labor 
market in which companies struggled to find, attract, and 
retain good employees. To help employers better under- 
stand what employees value, Fort Lauderdale-based 
Interim Services, Inc. surveyed a random sample of 
1,000 employees in the U.S. One question they asked 
was, "If your employer provides you with mentoring 
opportunities are you likely to remain in your job for 
the next five years'?" They found that 620 members of 
the sample said "yes." (HRMagazine, Sept. 1999) 
a. Identify the population of interest to Interim Ser- 
vices, Inc. 
b. Based on the question posed by Interim Services, 
Inc., what is the variable of interest? 
c. Is the variable quantitative or qualitative? Explain. 
d. Describe the sample. 
e. What inference can be made from the results of the 
survey? 
1.18 For the past 15 years, global competition has spurred 
U.S. companies to downsize, streamline, and cut costs 
through outsourcing and the use of temporary employ- 
ees. In fact, the number of temporary employees has 
increased by more than 250% during the 1990s. The 
Institute of Managcmcnt and Office Angels-the 
United 
Kingdom's secretarial recruitment agency--conducted 
a survey to study the temporary employment market. 
They mailed a questionnaire to a random sample of 

22 
CHAPTER 1 
S t a t i s t i c s ,  D a t a ,  a n d  S t a t i s t i c a l  T h i n k i n g  
4,000 Institute of Management members and received 
684 replies. One question asked: "Do you expect an 
increase, no change, or decrease in the number of tem- 
porary employees in your organization by 2002?" 43% 
indicated the number of temporary employees would 
increase. (Management Services, Sept. 1999) 
a. Identify the data collection method used by the re- 
searchers. 
b. Identify the population sampled by the researchers. 
c. Based on the question posed by the researchers, 
what is the variable of interest? 
d. Is the variable quantitative or qualitative? Explain. 
e. What inference can be made from the results of the 
study? 
1.19 All highway bridges in the United States are inspected 
periodically for structural deficiency by the Federal 
Highway Administration (FHWA). Data from the 
FHWA inspections are compiled into the National 
Bridge Inventory (NBI). Several of the nearly 100 vari- 
ables maintained by the NBI are listed below. Classify 
each variable as quantitative or qualitative. 
a. Length of maximum span (feet) 
b. Number of vehicle lanes 
c. Toll bridge (yes or no) 
d. Average daily traffic 
e. Condition of deck (good, fair, or poor) 
f. Bypass or detour length (miles) 
g. Route type (interstate, U.S., state, county, or city) 
1.20 Refer to Exercise 1.19. The most recent NBI data were 
analyzed and the results published in the Journal of 
Infrastructure Systems (June 1995). Using the FHWA 
inspection ratings, each of the 470,515 highway bridges 
in the United States was categorized as structurally defi- 
cient, functionally obsolete, or safe. About 26% of the 
bridges were found to be structurally deficient, while 
19% were functionally obsolete. 
a. What is the variable of interest to the 
researchers? 
b. Is the variable of part a quantitative or quali- 
tative? 
c. Is the data set analyzed a population or a sample? 
Explain. 
d. How did the researchers obtain the data for their 
study? 
1.21 The Journal of Retailing (Spring 1988) published a study 
of the relationship between job satisfaction and the 
degree ol Machiavellian orientation. Briefly, the 
Machiavellian orientation is one in which the executive 
exerts very strong control, even to the point of decep- 
tion and cruelty, over the employees he or she supervis- 
es. The authors administered a questionnaire to each in 
a sample of 218 department store executives and 
obtained both a job satisfaction score and a 
Machiavellian rating. They concluded that those with 
higher job satisfaction scores are likely to have a lower 
"Mach" rating. 
C, 
a. What is the population from which the sample was 
selected? 
b. What variables were measured by the authors? 
c. Identify the sample. 
d. Identify the data collection method used. 
e. What inference was made by the authors? 
1.22 Media reports suggest that disgruntled shareholders 
are becoming more willing to put pressure on corpo- 
rate management. Is this an impression caused by a 
few recent high-profile cases involving a few large 
invcstors, or is shareholder activism widespread? To 
answer this question the Wirthlin Group, an opinion 
research organization in McLean, Virginia, sampled 
and questioned 240 large invcstors (money man- 
agers, mutual fund managers, institutional investors, 
etc.) in the United States. One question they asked 
was: Have you written or called a corporate director 
to express your views? They found that a surprising- 
ly large 40% of the sample had (New York Times, 
Oct. 31,1995). 
a. Identify the population of interest to the Wirthlin 
Group. 
b. Based on the question the Wirthlin Group asked, 
what is the variable of interest? 
c. Describe the sample. 
d. What inference can be made from the results of the 
survey? 
1.23 Corporate merger is a means through which one firm 
(the bidder) acquires control of the assets of another 
firm (the target). During 1995 there was a frenzy of 
bank mergers in the United States, as the banking 
industry consolidated into more efficient and more 
competitive units. The number of banks in the United 
States has fallen from a high of 14,496 in 1984 to just 
under 10,000 at the end of 1995 (Fortune, Oct. 2,1995). 
a. Construct a brief questionnaire (two or three ques- 
tions) that could be used to query a sample of bank 
presidents concerning their &inions of why the in- 
dustry is consolidating and whether it will consoli- 
date further. 
b. Describe the population about which inferences 
could be mad;from the results of the survey. 
c. Discuss the pros and cons of sending the question- 
naire to all bank presidents versus a sample of 200. 
"1.24 Coca-Cola and Schweppes Beverages Limited 
(CCSB), which was formed in 1987, is 49% owned by 
the Coca-Cola Company. According to Industrial 
Management and Data Systems (Vol. 92,1992) CCSB's 
Wakefield plant can produce 4,000 cans of soft drink 
per minute. The automated process consists of mea- 
suring and dispensing the raw ingredients into storage 
vessels to create the syrup, and then injecting the 
syrup, along with carbon dioxide. into the beverage 
cans. In order to monitor the subprocess that adds 
carbon dioxide to the cans, five filled cans are pulled 
off the line every 15 minutes and the amount of carbon 

E x e r c i s e s  
23 
dioxide in each of these five is measured to deter- 
mine whether the amounts are within prescribed 
limits. 
a. Describe the process studied. 
b. Describe the variable of interest. 
c. Describe the sample. 
d. Describe the inference of interest. 
e. Brix is a unit for measuring sugar concentration. If a 
technician is assigned the task of estimating the av- 
erage brix level of all 240,000 cans of beverage stored 
in a warehouse near Wakefield, will the technician be 
examining a process or a population? Explain. 
1.25 Job-sharing is an innovative employment alternative that 
originated in Sweden and is becoming very popular in the 
United States. Firms that offer job-sharing plans allow two 
or more persons to work part-time, sharing one full-time 
job. For example, two job-sharers might alternate work 
weeks, with one working while the other is off. Job-sharers 
never work at the same time and may not even know each 
other. Job-sharing is particularly attractive to working 
mothers and to people who frequently lose their jobs due 
to fluctuations in the economy. In a survey of 1,035 major 
US. firms, approximately 22% offer job-sharing to their 
employees (Entrepreneur, Mar. 1995). 
a. Identify the population from which the sample was 
selected. 
b. Identify the variable measured. 
c. Identify the sample selected. 
d. What type of inference is of interest to the govern- 
ment agency? 
1.26 The People's Republic of China with its 1.2 billion 
people is emerging as the world's biggest cigarette 
market. In fact, China's cigarette industry is the central 
government's largest source of tax revenue. To better 
understand Chinese smokers and the potential public 
health disaster they represent, door-to-door interviews 
of 3,423 men and 3,593 women were conducted in the 
Minhang District, a suburb of 500,000 people near 
Shanghai. The study concluded that "people in China, 
despite their modest incomes, are willing to spend an 
average of 60 percent of personal income and 17 per- 
cent of household income to buy cigarettes" (Newark 
Star-Ledger, Oct. 19,1995). 
a. Identify the population that was sampled. 
b. How large was the sample size? 
c. The study made inferences about what population? 
d. Explain why different answers to parts a and c might 
affect the reliability of the study's conclusions. 
1.27 To assess how extensively accounting firms in New York 
State use sampling methods in auditing their clients, the 
New York Society of CPAs mailed a questionnaire to 
800 New York accounting firms employing two or more 
professionals.Thcy received responses from 179 firms of 
which four responses were unusable and 12 reported 
they had no audit practice. The questionnaire asked 
firms whether they use audit sampling methods and, if 
so, whether or not they use random sampling (CPA 
Journal, July 1995). 
a. Identify the population, the variables, the sample, 
and the inferences of interest to the New York Soci- 
ety of CPAs. 
b. Speculate as to what could have made four of the 
responses unusable. 
c. In Chapters 6-9 you will learn that the reliability of 
an inference is related to the size of the sample used. 
In addition to sample size, what factors might affect 
the reliability of the inferences drawn in the mail sur- 
vey described above? 
1.28 The employment status (employed or unemployed) of 
each individual in the US. workforce is a set of data 
that is of interest to economists, businesspeople, and 
sociologists. These data provide information on the 
social and economic health of our society. To obtain 
information about the employment status of the work- 
force, the U.S. Bureau of the Census conducts what is 
known as the Current Population Survey. Each month 
approximately 1,500 interviewers visit about 59,000 of 
the 92 million households in the United States and 
question the occupants over 14 years of age about their 
~mployment status. Their responses enable the Bureau 
of the Census to estimate thc percentage of people in 
the labor force who are unemployed (the unernploy- 
rnerzt rate). 
a. Define the population of interest to the Census 
Bureau. 
b. What variable is being measured? Is it quantitative 
or qualitative? 
c. Is the problem of interest to the Census Bureau de- 
scriptive or inferential? 
d. In order to monitor the rate of unemployment, it is 
essential to have a definition of "uneiployed." Dif- 
ferent economists and even different countries de- 
fine it in various ways. Develop your own definition 
of an "unemployed person." Your definition should 
answer such questions as: Arc students on summer 
vacation unemployed? Are college professors who 
do not teach summer school unemployed? At what 
age are people considered to be eligible for the 
workforce? Are people who are out of work but not 
actively seeking a job unemployed? 

M E T H O D S  F O R  D E S C R I B I N G  
S E T S  O F  D A T A  
C O N T E N T S  
................................ 
... 
2.1 
Describing Qualitative Data 
2.2 
Graphical Methods for Describing Quantitative Data 
2.3 
Summation Notation 
2.4 
Numerical Measures of Central Tendency 
2.5 
Numerical Measures of Variability 
2.6 
Interpreting the Standard Deviation 
2.7 
Numerical Measures of Relative Standing 
2.8 
Methods for Detecting Outliers (Optional) 
2.9 
Graphing Bivariate Relationships (Optional) 
2.10 
The Time Series Plot (Optional) 
2.11 
Distorting the Truth with Descriptive Techniques 
..................................................................................................................................................... 
I 
S T A T I S T I C ' S  
I
N
 A
C
T
I
O
N
 
Car 6; Driver's "Road Test Digest" 
P 
W h e r e  W e ' v e  B e e n  
I 
n Chapter 1 we looked at some typical examples 
of the use of statistics and we discussed the role 
that statistical thinking plays in supporting manager- 
ial decision-making. We examined the difference be- 
tween descriptive and inferential statistics and 
described the five elements of inferential statistics: a 
population, one or more variables, a sample, an in- 
ference, and a measure of reliability for the infer- 
ence. We also learned that data can be of two 
types-quantitative and qualitative. 
W h e r e  W e ' r e  G o i n g  
B 
efore we make an inference, we must be able to 
describe a data set. We can do this by using 
graphical and/or numerical methods, which we dis- 
cuss in this chapter. As we'll see in Chapter 5, we use 
sample numerical descriptive measures to estimate 
the values of corresponding population descriptive 
measures. Therefore, our efforts in this chapter will 
ultimately lead us to statistical inference. 

26 
CHAPTER 
2 M e t h o d s  for Describing Sets of D a t a  
Suppose you wish to evaluate the managerial capabilities of a class of 400 MBA 
students based on theii Graduate Management Aptitude Test (GMAT) scores. 
How would you describe these 400 measurements? Characteristics of the data set 
include the typical or most frequent GMAT score, the variability in the scores, the 
highest and lowest scores, the "shape" of the data, and whether or not the data set 
contains any unusual scores. Extracting this information by "eye-balling" the data 
isn't easy. The 400 scores may provide too many bits of information for our minds 
to comprehend. Clearly we need some formal methods for summarizing and char- 
acterizing the information in such a data set. Methods for describing data sets are 
also essential for statistical inference. Most populations are large data sets. Con- 
sequently, we need methods for describing a sample data set that let us make de- 
scriptive statements (inferences) about the population from which the sample 
was drawn. 
Two methods for describing data are presented in this chapter, one graphical 
and the other numerical. Both play an important role in statistics. Section 2.1 pre- 
sents both graphical and numerical methods for describing qualitative data. 
Graphical methods for describing quantitative data are presented in Section 2.2 
and optional Sections 2.8,2.9, and 2.10; numerical descriptive methods for quan- 
titative data are presented in Sections 2.3-2.7. We end this chapter with a section 
on the misuse of descriptive techniques. 
DESCRIBING QUALITATIVE DATA 
Recall the "Executive Compensation Scoreboard" tabulated annually by Business 
Week (see Study 2 in Section 1.2). Forbes magazine also conducts a salary survey 
of chief executive officers each year. In addition to salary information, Forbes 
collects and reports personal data on the CEOs, including level of education. Do 
most CEOs have advanced degrees, such as masters degrees or doctorates? To an- 
swer this question,Table 2.1 gives the highest college degree obtained (bachelors, 
- 
masters, doctorate, or none) for each of the 25 best-paid CEOs in 1998. 
For this study, the variable of interest, highest college degree obtained, is 
qualitative in nature. Qualitative data are nonnumerical in nature; thus, the 
value of a qualitative variable can only be classified into categories called class- 
es. The possible degree types-bachelors, masters, doctorate, and none-repre- 
sent the classes for this qualitative variable. We can summarize such data 
numerically in two ways: ( I )  by computing the class frequency-the 
number of 
observations in the data set that fall into each class; or (2) by computing the 
class relative frequency-the 
proportion of the total number of observations 
falling into each class. 
DEFINITION 2.1 
A class is one of the categories into which qualitative data can be classified. 
The class frequency is the number of observations in the data set falling into 
a particular class. 

SECTION 
2.1 
Describing Qualitive Data 
27 
TABLE 
2.1 
Data on 25 Best-Paid Executives 
CEO 
Company 
Degree 
................................................................................................................................................................... 
-1. Michael D. Eisner 
Walt Disney 
2. Me1 Karmazin 
CBS 
3. Stephen M. Case 
America Online 
4. Stephen C. Hilbert 
Conseco 
5. Craig R. Barrett 
Intel 
- 6. Millard Drexler 
Gap 
-- 
7. John F. Welch. Jr. 
General Electric 
8. Thomas G. Stemberg 
9. Henry R. Silverman 
10. Reuben Mark 
11. Philip J. Purcell 
12. Scott G. McNealy 
13. Margaret C. Whitman 
14. Louis V. Gerstner, Jr. 
15. John F. Gifford 
16. Robert L. Waltrip 
17. M. Douglas Ivester 
18. Gordon M. Binder 
19. Charles R. Schwab 
20. William R. Steere, Jr. 
21. Nolan D. Archibald 
22. Charles A. Heimbold, Jr. 
23. William L. Larson 
24. Maurice R. Greenberg 
25. Richard Jay Kogan 
Staples 
Cendant 
Colgate-Palmolive 
Morgan Stanley Dean Witter 
Sun Microsystems 
eBay 
IBM 
Maxim Integrated Products 
Service Corp. International 
Coca-Cola 
Amgcn 
Charles Schwab 
Pfizer 
Black & Decker 
Bristol-Myers Squibb 
Network Association 
American International Group 
Schering-Plough 
Bachelors .- 
Bachelors 
Bachelors 
None 
- 
Doctorate 
Masters .. 
Doctorate 
Masters 
JD(law) 
Masters 
Masters 
Masters 
Masters 
Masters 
Bachelors 
Bachelors 
Bachelors 
Masters 
Masters 
Bachelors 
Masters 
LLB (law) 
JD (law) 
LLB (law) 
Masters 
Source: Forbes, May 17,1999 
DEFINITION 2.3 
The class relative frequency is the class frequency divided by the total numbe 
of observations in the data set. 
Examining Table 2.1, we observe that 1 of the 25 best-paid CEOs did not 
obtain a college degree, 7 obtained bachelors degrees, 11 masters degrees, and 
6 doctorates or law degrees. These numbers-1, 
7, 11, and 6-represent 
the 
class frequencies for the four classes and are shown in the summary table, 
Table 2.2. 
TABLE 
2.2 
~umrnaty Table for Data on 25 Best-Paid CEOs 
Class 
Frequency 
Relative Frequency 
....................................................................................................................................... 
Highest Degree Obtained 
Number of CEOs 
Proportion 
.............................................................................................................................................................. 
None 
1 
.04 
Bachelors 
7 
.28 
Masters 
11 
.44 
DoctorateILaw 
6 
.24 
Totals 
25 
1 .OOO 

28 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of D a t a  
Table 2.2 also gives the relative frequency of each of the four degree classes. 
From Definition 2.3, we know that we calculate the relative frequency by dividing the 
class frequency by the total number of observations in the data set.Thus, the relative 
frequencies for the four degree types are 
1 
None: - 
= .04 
25 
C 
\ 
FIGURE 2.1 
EXCEL graph for data on 25 
CEOs 
None 4% 
FIGURE 2.2 
EXCEL pie chart for data on 
25 CEOs 
I 
Bachelors: - 
= .28 
25 
11 
Masters: - 
= .44 
25 
6 
Doctorate: - 
= .24 
25 
From these relative frequencies we observe that nearly half (44%) of the 25 
best-paid CEOs obtained their masters degree. 
Although the summary table of Table 2.2 adequately describes the data of 
Table 2.1, we often want a graphical presentation as well. Figures 2.1 and 2.2 show 
two of the most widely used graphical methods for describing qualitative data- 
bar graphs and pie charts. Figure 2.1 shows the frequencies of "highest degree ob- 
tained" in a bar g r q h  created using the EXCEL software package. Note that the 
height of the rectangle, or "bar," over each class is equal to the class frequency. 
(Optionally, the bar heights can be proportional to class relative frequencies.) In 
contrast, Figure 2.2 (also created using EXCEL) shows the relative frequencies of 
the four degree types in a pie chart. Note that the pie is a circle (spanning 360") 
and the size (angle) of the "pie slice" assigned to each class is proportional to the 
class relative frequency. For example, the slice assigned to masters degree is 44% 
DEGREE 
I 
I 
( 7
(
 
Bachelors 
N o n e  
n I 
Lors 
I\ 
DOC t 
/ L a w  
Masters 
Doctor/Law 
11 
1 
I 
6 1 
I 
I 
I 
I 
I 
I 

SECTION 2.1 
Describing Qualitive Data 
29 
Let's look at two practical examples that require interpretation of the graphical 
results. 
~
~
m
m
~
r
n
~
~
~
*
s
~
m
n
~
-
~
r
n
-
m
~
-
s
~
~
"
"
 
" -%"m*mm+"s- 
ardiac physicians in southwest Florida have been studying a new drug 
designed to reduce blood loss in coronary artery bypass operations. Blood loss data 
for 114 coronary artery bypass patients (some who received a dosage of the drug and 
others who did not) were collected and are made available for analysis." Although 
the drug shows promise in reducing blood loss, the physicians are concerned about 
possible side effects and complications. So their data set includes not only the 
qualitative variable, DRUG, which indicates whether or not the patient received the 
drug, but also the qualitative variable, COMP, which specifies the type (if any) of 
complication experienced by the patient. The four values of COMP recorded by the 
physicians are: (1) redo surgery, (2) post-op infection, (3) both, or (4) none. 
a. Figure 2.3, generated using SAS computer software, shows summary tables 
for the two qualitative variables, DRUG and COMP. Interpret the results. 
b. Interpret the SAS graph and summary tables shown in Figure 2.4. 
FIGURE 2.3 
SAS summary 
and COMP 
tables for DRUG 
Cumulative Cumulative 
DRUG 
Frequency 
Percent 
Frequency 
Percent 
........................................................ 
NO 
YES 
Cumulative Cumulative 
COMP 
Frequency 
Percent 
Frequency 
Percent 
........................................................ 
1 : REDO 
12 
10.5 
12 
10.5 
2 : INFECT 
12 
10.5 
2 4 
21.0 
3 :BOTH 
4 
3.5 
2 8 
24.5 
4 : NONE 
8 6 
75.5 
114 
100.0 
S o I u t i o n 
a. The top table in Figure 2.3 is a summary frequency table for DRUG. Note 
that exactly half (57) of the 114 coronary artery bypass patients received the 
drug and half did not. The bottom table in Figure 2.4 is a summary frequen- 
cy table for COMP. The class relative frequencies are given in the Percent 
column. We see that 75.5% of the 114 patients had no complications, leaving 
24.5% who experienced either a redo surgery, a post-op infection, or both. 
b. At the top of Figure 2.4 is a side-by-side bar graph for the data. The first four 
bars represent the frequencies of COMP for the 57 patients who did not 
receive the drug; the next four bars represent the frequencies of COMP for 
the 57 patients who did receive a dosage of the drug. The graph clearly 
shows that patients who got the drug suffered more complications.The exact 
percentages are displayed in the summary tables of Figure 2.4. About 30% 
of the patients who got the drug had complications, compared to about 17% 
for the patients who got no drug. 
Although these results show that the drug may be effective in reducing 
blood loss, they also imply that patients on the drug may have a higher risk of 
*The data for this study are real. For confidentiality reasons, the drug name and physician group 
are omitted. 

30 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  Data 
complications. But before using this information to make a decision about the 
drug, the physicians will need to provide a measure of reliability for the inference. 
That is, the physicians will want to know whether the difference between the per- 
centages of patients with complications observed in this sample of 114 patients is 
N SUM 
SUM OF N BY COMP GROUPED BY DRUG 
Cumulative 
Cumulative 
COMP 
Frequency 
Percent 
Frequency 
Percent 
1 :REDO 
5 
8.8 
5 
8.8 
2 : INFECT 
4 
7.0 
9 
15.8 
3 : BOTH 
1 
1.8 
10 
17.5 
4 : NONE 
47 
82.5 
5 7 
100.0 
Cumulative 
Cumulative 
COMP 
Frequency 
Percent 
Frequency 
Percent 
..................................................................... 
1 : REDO 
7 
12.3 
7 
12.3 
2 : INFECT 
7 
12.3 
14 
24.6 
3 : BOTH 
3 
5.3 
17 
29.8 
4 : NONE 
4 0 
70.2 
57 
100.0 
FIGURE 2.4 
SAS bar graph and summary tables for COMP by DRUG 

I 
SECTION 
2.1 
Describing Qualitive Data 
31 
generalizable to the population of all coronary artery bypass patients. Measures of 
reliability will be discussed in Chapters 5-8. 
80% of the wealth of a country lies with approximately 20% of the people. This 
discovery of "the vital few and the trivial many," called the Pareto principle, holds 
I 
true even today. In his book Defect Prevention (1989), V. E. Kane reports the 
following: 80% of sales are attributable to 20% of the customers; 80% of 
customer complaints result from 20% of the components of a product; 80% of 
defective items produced by a process result from 20% of the types of errors that 
are made in production. In industry a Pareto analysis involves the categorization 
1 
of items and the determination of which categories contain the most 
observations, i.e., which are the "vital few" categories. The primary tool of Pareto 
analysis is the Pareto diagram. The Pareto diagram is simply a bar graph with the 
bars arranged in descending order of height from left to right across the 
I 
horizontal axis. This arrangement locates the most important categories-those 
with the largest frequencies-at 
the left of the graph. 
a. Table 2.3a contains summary data from the automobile industry (adapted 
from Kane, 1989). All cars produced on a particular day were inspected for 
general defects. Each of the 125 defects discovered were categorized by 
type: accessory, body, electrical, engine, and transmission. The table gives 
the number of defects of each type. Construct a Pareto diagram for the data. 
Identify the categories that produced the most defects. 
TABLE 
2.3 Summary of Car Defects 
a. General Defect 
Number 
b. Body Defect 
Number 
I 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . - 
Accessory 
50 
Chrome 
2 
Body 
70 
Dents 
25 
Electrical 
12 
Paint 
30 
Engine 
8 
Upholstery 
10 
Transmission 
5 
Windshield 
3 
Total 
125 
Total 
70 
I 
b. All 70 body defects were further classified as to whether they were chrome, 
dent, paint, upholstery, of windshield defects. Table 2.3b gives the number of 
each type. Construct a Pareto diagram for the body type defects. Interpret 
the results. 
S o I u t i o n 
a. The Pareto diagram for the 125 car defects is a frequency bar graph, with the 
bars arranged in order of height. The diagram is displayed in Figure 2.5a. 
Clearly, body and accessory defects (the two categories at the far left of the 
graph) are the most frequently observed types of car defects. Management 
should focus their problem-solving efforts in these two areas. 
b. A Pareto diagram for the 70 body part defects is shown in Figure 2.5b. You 
can see that paint and dent defects (again, the two categories at the far left 
of the graph) are the most frequently observed types of body defects. These 
defects should be targeted for special attention by managers, engineers, and 
assembly-line workers. [Note: When one or more Pareto diagrams are used 
to decompose the original Pareto diagram in Figure 2Sa, the resulting graph 
(Figure 2.5b) is called exploding the Pareto diagram.] 

32 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of D a t a  
FIGURE 2.5 
a. Car defects 
Pareto diagrams 
for Example 2.2 
70 
60 
$ 50 
40 
r 
2 30 
20 
10 
T v ~ e  
of defect 
b. Car body defects 
Learning the Mechanics 
a. Compute the frequency for each of the three classes. 
b. Compute the relative frequency for each of the three 
2.1 Complete the following table. 
...................... 
____ ............................................................... . ............................ 
classes. 
Grade on Business 
c. Display the results, part a, in a frequency bar graph. 
Statistics Exam 
Frequency 
Relative Frequency 
d. Dkplay the results, part b, in a pie chart. 
A: 90-1 00 
- 
.08 
B: 80-89 
36 
- 
C: 65-79 
90 
- 
D: 50-64 
30 
- 
F: Below 50 
28 
- 
Total 
200 
1 .OO 
- 
2.2 A qualitative variable with three classes (X,Y, and Z) is 
measured for each of 20 units randomly sampled from a 
target population. The data (observed class for each 
unit) are listed below. 
Y
X
X
Z
X
Y
Y
Y
X
X
Z
X
 
Y
Y
X
Z
Y
Y
Y
X
 
Applying the Concepts 
2.3 Until their profitability was threatened by competition 
from Japan and Europe in the 1970s, most U.S. firms paid 
relatively little attention to customer satisfaction. Today, 
customer satisfaction and loyalty are valued and moni- 
tored by all world-class organizations. But are satisfied 
customers necessarily loyal customers? Harte-Hanks 
Market Research surveyed customers of department 
stores and banks and published the results (shown on 
p. 33) in American Demographics (Aug. 1999). 
a. Construct a relative frequency bar chart for each of 
the data sets. 

SECTION 2.1 
D e s c r i b i n g  Q u a l i t i v e  D a t a  
33 
Department 
Banks 
Stores 
Totally satisfied and very loyal 
27 % 
4% 
Totally satisfied and not very loyal 
18% 
25 % 
Not totally satisfied and very loyal 
13% 
2% 
Not totally satisfied and not very loyal - 
42% 
- 
69 % 
100% 
100% 
Source: American Demogruphics, Aug. 1999 
b. Could these data have been described using pie 
charts? Explain. 
c. Do the data indicate that customers who are totally 
satisfied are very loyal? Explain. 
2.4 Port Canaveral (Florida) handled over 1.5 million cruise 
passengers in 1998. The number of passengers handled 
by each of the cruise ships that sail out of Port 
Canaveral is listed in the table. 
Cruise Line (Ship) 
Number of Passengers 
Canaveral (Dolphin) 
Carnival (Fantasy) 
Disney (Magic) 
Premier (Oceanic) 
Royal Caribbean (Nordic Empress) 
Sun Cruz Casinos 
Sterling Cruises (New Yorker) 
Topaz Int'l. Shipping (Topaz) 
Other 
Total 
1,591,560 
Source: Florida Trend, Vol. 41, No. 9, Jan. 1999. 
a. Find the relative frequency of the number of passen- 
gers for each cruise ship. 
b. Identify the cruise ship with the highest relative fre- 
quency. Interpret this number. 
c. Construct a bar graph to describe the popularity of 
cruise ships that sailed from Port Canaveral in 1998. 
2.5 Disgruntled shareholders who put pressure on corpo- 
rate management to make certain financial decisions 
are referred to as shareholder activists. In Exercise 1.22 
we described a survey of 240 large investors designed to 
determine how widespread shareholder activism actu- 
ally is. One of several questions asked was: If the chief 
executive officer and the board of directors differed on 
company strategy, what action would you, as a large 
Response 
Number of Investors 
..................................................................................................................... 
Seek formal explanation 
154 
Seek CEO performance review 
49 
Dismiss CEO 
20 
Seek no action 
17 
Total 
240 
investor of the firm, take? (New York Times, Oct. 31, 
1995) The responses are summarized in the table. 
a. Construct a relative frequency table for the data. 
b. Display the relative frequencies in a graph. 
c. Discuss the findings. 
2.6 
According to Topaz Enterprises, a Portland, Oregon- 
based airfare accounting firm, "more than 80% of all 
tickets purchased for domestic flights are discounted" 
(Travel Weekly, May 15, 1995). The results of the 
accounting firm's survey of domestic airline tickets are 
summarized in the table. 
...................................................................................... 
Domestic Airline Ticket Type 
Proportion 
Full coach 
Discounted coach 
Negotiated coach 
First class 
Business class 
Business class negotiated 
- 
Advance purchase 
Capacity controlled discount 
Nonrefundable 
Total 
1 .000 
a. Give your opinion on whether the data described in 
the table are from a population or a sample. Explain 
your reasoning. 
b. Display the data with a bar graph. Arrange the bars 
in order of height to form a Pareto diagram. Inter- 
pret the resulting graph. 
c. Do the data support the conclusion reached by 
Topaz Enterprises regarding the percentage of tick- 
ets purchased that are discounted? 
[Note: Advance purchase and negotiated tickets are 
considered discounted.] 
"Reader-response cards" are used by marketers to 
advcrt~se their product and obtain sales leads. These 
cards are placed in magazines and trade publications. 
Readers detach and mail in the cards to indicate their 
interest in the product, expecting literature or a phone 
call In return. How effective are these cards (called 
"blngo cards" in the industry) as a marketing tool? 
Performark, a Minneapolis business that helps compa- 
nies close on sales leads, attempted to answer th~s 
ques- 
tion by rcsponding to 17,000 card-advertisements 
placed by industrial marketers in a wide variety of trade 
Advertiser's Response Time 
Percentage 
Never responded 
21 
13-59 days 
33 
60-120 days 
34 
More than 120 days 
12 
Total 
100 

publications over a 6-year period. Performark kept 
track of how long it took for each advertiser to respond. 
A summary of the response times, reported in Inc. mag- 
azine (July 1995), is given in the table on p. 33. 
a. Describe the variable measured by Performark. 
b. Inc. displayed the results in the form of a pie chart. 
Reconstruct the pie chart from the information given 
in the table. 
c. How many of the 17,000 advertisers never responded 
to the sales lead? 
d. Advertisers typically spend at least a million dollars 
on a reader-response card marketing campaign. 
Many industrial marketers feel these "bingo cards" 
are not worth their expense. Does the information in 
the pie chart, part b, support this contention? Ex- 
plain why or why not. If not, what information can be 
gleaned from the pie chart to help potential "bingo 
card" campaigns? 
2.8 Many librarians rely on book reviews to determine which 
new books to purchase for their library. A random 
sample of 375 book reviews in American history, geogra- 
phy, and area studies was selected and the "overall opin- 
ion" of the book stated in each review was ascertained 
(Library Acquisitions: Practice and Theory, Vol. 19,1995). 
Overall opinion was coded as follows: 1 = would not rec- 
ommend, 2 = cautious or very little recommendation, 
3 = little or no preference, 4 = favorable/recommended, 
5 = outstanding/significant contribution. A summary of 
the data is provided in the bar graph. 
1 
2 
> 
5 
Poorest 
Highest 
Source: Reprinted from Library Acquisitions: Practice and Theory, 
Vol. 19, No. 2, P.W. Carlo and A. Natowitx, "Choice Book Reviews 
in American History, Geography, and Area Studies: An Analysis for 
1988-1993," p. 159. Copyright 1995, with kind permission from 
Elsevier Science Ltd,The Boulevard, Langford Lane, Kidlington 
OX5 IGB, UK. 
a. Interpret the bar graph. 
b. Comment on the following statement extracted from 
the study: "A majority (more than 75%) of books re- 
viewed are evaluated favorably and recommended 
for purchase." 
2.9 The Internet and its World Wide Web provide computer 
users with a medium for both communication and 
34 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
entertainment. However, many businesses are recogniz- 
ing the potential of using the Internet for advertising 
and selling their products. Inc. Technology (Sept. 12, 
1995) conducted a survey of 2,016 small businesses 
(fewer than 100 employees) regarding their weekly 
Internet usage. The survey found 1,855 small businesses 
that do not use the Internet, 121 that use the Internet 
from one to five hours per week, and 40 that use the 
Internet six or more hours per week. 
a. Identify the variable measured in the survey. 
b. Summarize the survey results with a graph. 
c. What portion of the 2,016 small businesses use the 
Internet on a weekly basis? 
2.10 Owing to several major ocean oil spills by tank vessels, 
Congress passed the 1990 Oil Pollution Act, which 
requires all tankers to be designed with thicker hulls. 
Further improvements in the structural design of a tank 
vessel have been implemented since then, each with the 
objective of reducing the likelihood of an oil spill and 
decreasing the amount of outflow in the event of hull 
puncture. To aid in this development, J. C. Daidola 
reported on the spillage amount and cause of puncture 
for 50 recent major oil spills from tankers and carriers. 
The data are reproduced in the table on p. 35 (Marine 
Technology, Jan. 1995). 
a. Use a graphical method to describe the cause of oil 
spillage for the 50 tankers. 
b. Does the graph, part a, suggest that any one cause is 
more likely to occur than any other? How is this in- 
formation of value to the design engineers? 
2.11 Since opening its doors to Western investors in 1979, 
the People's Republic of China has been steadily 
moving toward a market economy. However, because of 
the considerable political and economic uncertainties 
in China, Western investors remain uneasy about their 
investments in China. In 1995 an agency of the Chinese 
government surveyed 402 foreign investors to assess 
their concerns with the investment environment. Each 
was asked to indicate their most serious concern. The 
results appear below. 
Investor's Concern 
.............................................................. 
Communication infrastructure 
Environmental protection 
Financial services 
Government efficiency 
Inflation rate 
Labor supply 
Personal safety 
Real estate prices 
Security of personal property 
Water supply 
Frequency 
Source: Adapted from China Marketing News, No. 26, 
November 1995. 

SECTION 2.1 
D e s c r i b i n g  Q u a l i t i v e  D a t a  
35 
0ILSPILL.DAT 
........................................................................................................................................................................................................... 
Cause of Spillage 
Spillage 
(metric tons, 
Fire/ 
Hull 
Tanker 
thousands) 
Collision 
Grounding 
Explosion 
Failure 
Unknown 
........................................................................................................................................................................................................... 
Atlantic Empress 
Castillo De Bellver 
Amoco Cadiz 
Odyssey 
Torrey Canyon 
Sea Star 
Hawaiian Patriot 
Independento 
Urqu~ola 
Irenes Serenade 
Khark 5 
Nova 
Wafra 
Epic Co/ocotronis 
Sinclair Petrolore 
Yuyo Maru No 10 
Assimi 
Andros Patria 
World Glory 
Brzt~sh Ambassador 
Metula 
Pericles G. C. 
Mandoil II 
Jacob Maersk 
Burmah Agate 
J. Antonio Lavalleja 
Napier 
Exxon Valdez 
Corznthos 
Trader 
St. Peter 
Gino 
Golden Drake 
Ionnis Angelicoussis 
Chryssi 
Irenes Challenge 
Argo Merchant 
Heimvard 
Pegasus 
Pacocean 
Texaco Oklahoma 
Scorpio 
Ellen Conway 
Caribbean Sea 
Cretan Star 
Grand Zenith 
Atheman Venture 
Venoil 
Aragon 
Ocean Eagle 
Source: Daidola, J. C. "Tanker structure behavior during collision and grounding." Marine Technology, Vol. 32, No. 1, Jan. 
1995, p. 22 (Table 1). Reprinted with permission of The Society of Naval Architects and Marine Engineers (SNAME), 601 
Pavonia Ave., Jersey City, NJ 07306, USA, (201) 798-4800. Material appearing in The Society of Naval Architect and Marine 
Engineers (SNAME) publications cannot be reprinted without obtaining written permission. 

36 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  Data 
a. Construct a Pareto diagram for the 10 categories. 
c. In this case, are 80% of the investors concerned with 
b. According to your Pareto diagram, which environ- 
20% of the environmental factors as the Pareto prin- 
mental factors most concern investors'? 
ciple would suggest? Justify your answer. 
GRAPHICAL METHODS FOR DESCRIBING 
QUANTITATIVE DATA 
Recall from Section 1.5 that quantitative data sets consist of data that are record- 
ed on a meaningful numerical scale. For describing, summarizing, and detecting 
patterns in such data, we can use three graphical methods: dot plots, stem-and-leaf 
displays, and histograms. 
For example, suppose a financial analyst is interested in the amount of re- 
sources spent by computer hardware and software companies on research and de- 
velopment (R&D). She samples 50 of these high-technology firms and calculates 
the amount each spent last year on R&D as a percentage of their total revenues. 
The results are given in Table 2.4. As numerical measurements made on the sam- 
ple of 50 units (the firms), these percentages represent quantitative data. The an- 
alyst's initial objective is to summarize and describe these data in order to extract 
relevant information. 
TABLE 
2.4 
Percentage of Revenues Spent on Research and Development 
Company 
Percentage 
Company 
Percentage 
Company 
Percentage 
Company 
Percentage 
A visual inspection of the data indicates some obvious facts. For example, 
the smallest R&D percentage is 5.2% and the largest is 13.5%. But it is difficult 
to provide much additional information on the 50 R&D percentages without re- 
sorting to some method of summarizing the data. One such method is a dot 
plot. 
Dot Plots 
A dot plot for the 50 R&D percentages, produced using MTNTTAB software, is 
shown in Figure 2.6.The horizontal axis of Figure 2.6 is a scale for the quantitative 
variable, percent. The numerical value of each measurement in the data set is lo- 
cated on the horizontal scale by a dot. When data values repeat, the dots are 
placed above one another, forming a pile at that particular numerical location. As 
you can see, this dot plot shows that almost all of the R&D percentages are be- 
tween 6% and 12%, with most falling between 7% and 9%. 

SECTION 2.2 
Graphical M e t h o d s  f o r  Describing Q u a n t i t a t i v e  Data 
37 
FIGURE 2.6 
A MINITAB dot plot for 
the 50 R&D percentages 
FIGURE 2.7 
A STATlSTlX stem-and-leaf 
display for the 50 R&D 
percentages 
Stem-and-Leaf Display 
We used STATTSTTX software to generate another graphical representation of 
these same data, a stem-and-leaf display, in Figure 2.7. In this display the stem is 
the portion of the measurement (percentage) to the left of the decimal point, 
while the remaining portion to the right of the decimal point is the lea8 
The stems for the data set are listed in a column from the smallest (5) to the 
largest (13). Then the leaf for each observation is recorded in the row of the dis- 
play corresponding to the observation's stem. For example, the leaf 5 of the first 
observation (13.5) in Table 2.3 is placed in the row corresponding to the stem 13. 
Similarly, the leaf 4 for the second observation (8.4) in Table 2.3 is recorded in the 
row corresponding to the stem 8, while the leaf 5 for the third observation (10.5) 
is recorded in the row corresponding to the stem 10. (The leaves for these first 
three observations are shaded in Figure 2.7.) Typically, the leaves in each row are 
ordered as shown in Figure 2.7. 
STEM AND LEAF PLOT OF RDPCT 
MINIMUM 
5.2000 
MEDIAM 
8.0500 
MAXIMUM 
13.500 
LEAF DIGIT UNIT = 0.1 
5 2 REPRESENTS 5.2 
STEM 
3 
5 
12 
6 
23 
7 
(9) 
8 
18 
9 
10 
10 
6 
11 
3 
12 
3 
13 
LEAVES 
269 
055568999 
11224557789 
001222458 
02455679 
1556 
137 
50 CASES INCLUDED 
0 MISSING CASES 
The stem-and-leaf display presents another compact picture of the data set. 
You can see at a glance that most of the sampled computer companies (37 of 50) 
spent between 6.0% and 9.9% of their revenues on R&D, and 11 of them spent 
between 7.0% and 7.9%. Relative to the rest of the sampled companies, three 
spent a high percentage of revenues on R&D-in 
excess of 13% 
Most statistical software packages allow you to modify the definitions of the 
stem and leaf to alter the graphical description. For example, suppose we had de- 
fined the stem as the tens digit for the R&D percentage data, rather than the ones 
and tens digits. With this definition, the stems and leaves corresponding to the 
measurements 13.5 and 8.4 would be as follows: 

38 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
Note that the decimal portion of the numbers has been dropped. Generally, 
only one digit is displayed in the leaf. 
If you look at the data, you'll see why we didn't define the stem this way. All 
the R&D measurements fall below 13.5, so all the leaves would fall into just two 
stem rows-1 
and 0-in 
this display. The resulting picture would not be nearly as 
informative as Figure 2.7. 
Histograms 
3 
A relative frequency histogram for these 50 R&D percentages is shown in Figure 
2.8. The horizontal axis of Figure 2.8, which gives the percentage spent on R&D 
for each company, is divided into intervals commencing with the interval from 
(5.15-6.25) and proceeding in intervals of equal size to (12.85-13.95) percent. 
(The procedure for creating the class intervals will become clear in Example 2.3.) 
The vertical axis gives the proportion (or relative frequency) of the 50 percentages 
that fall in each interval. Thus, you can see that nearly a third of the companies 
spent between 7.35% and 8.45% of their revenues on research and development. 
This interval contains the highest relative frequency, and the intervals tend to 
contain a smaller fraction of the measurements as R&D percentage gets smaller 
or larger. 
FIGURE 2.8 
Histogram for the 50 
computer companies' 
x .30 
R&D percentages 
5 
& .20 
9 
.- * 
d 
2 .lo 
.OO 
5.15 6.25 
7.35 8.45 9.55 10.65 11.75 12.85 13.95 
R&D percentage 
By summing the relative frequencies in the intervals 6.25-7.35, 7.35-8.45, 
8.45-9.55,9.55-10.65, you can see that 80% of the R&D percentages are between 
6.25 and 10.65. Similarly, only 6% of the computer companies spent over 12.85 
percent of their revenues on R&D. Many other summary statements can be made 
by further study of the histogram. 
Dot plots, stem-and-leaf displays, and histograms all provide useful graphic 
descriptions of quantitative data. Since most statistical software packages can be 
used to construct these displays, we will focus on their interpretation rather than 
their construction. 
Histograms can be used to display either the frequency or relative frequen- 
cy of the measurements falling into specified intervals known as measurement 
classes. The measurement classes, frequencies, and relative frequencies for the 
R&D percentage data are shown in Table 2.5. 

SECTION 
2.2 
Graphical M e t h o d s  f o r  Describing Q u a n t i t a t i v e  Data 
39 
TABLE 
2.5 
Measurement Classes, Frequencies, and Relative 
Frequencies for the R&D Percentage Data 
FIGURE 2.9 
Effect of the size of a data set 
on the outline of a histogram 
Class 
Measurement Class 
Class Frequency 
Class Relative Frequency 
Totals 
50 
1.00 
By looking at a histogram (say, the relative frequency histogram in Figure 2.8), 
you can see two important facts. First, note the total area under the histogram and 
then note the proportion of the total area that falls over a particular interval of the 
horizontal axis. You'll see that the proportion of the total area above an interval is 
equal to the relative frequency of measurements falling in the interval. For example, 
the relative frequency for the class interval 7.35-8.45 is .28. Consequently, the rec- 
tangle above the interval contains .28 of the total area under the histogram. 
Second, you can imagine the appearance of the relative frequency histogram 
for a very large set of data (say, a population). As the number of measurements in 
a data set is increased, you can obtain a better description of the data by decreas- 
ing the width of the class intervals. When the class intervals become small enough, 
a relative frequency histogram will (for all practical purposes) appear as a smooth 
curve (see Figure 2.9). 
Measurement classes 
Measurement classes 
Measurement classes 
a. Small data set 
b. Larger data set 
c. Very large data set 
While histograms provide good visual descriptions of data sets-particularly 
very large ones-they 
do not let us identify individual measurements. In contrast, 
each of the original measurements is visible to some extent in a dot plot and clear- 
ly visible in a stem-and-leaf display. The stem-and-leaf display arranges the data in 
ascending order, so it's easy to locate the individual measurements. For example, in 
Figure 2.7 we can easily see that three of the R&D measurements are equal to 8.2, 
but we can't see that fact by inspecting the histogram in Figure 2.8. However, 
stem-and-leaf displays can become unwieldy for very large data sets. A very large 
number of stems and leaves causes the vertical and horizontal dimensions of the 
display to become cumbersome, diminishing the usefulness of the visual display. 

40 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets of D a t a  
< 
< 
lost because of the long time the firm takes to develop price quotes for 
potential customers. To investigate this possibility, 50 requests for price quotes 
were randomly selected from the set of all quotes made last year, and the 
processing time was determined for each quote. The processing times are 
displayed in Table 2.6, and each quote was classified according to whether the 
order was "lost" or not (i.e., whether or not the customer placed an order after 
receiving a price quote). 
TABLE 
2.6 
Price Quote Processing Time (Days) 
Request Number 
Processing Time 
Lost? 
Request Number 
Processing Time 
Lost? 
N o  
N o  
N o  
Yes 
N o  
N o  
N o  
N o  
N o  
N o  
Yes 
N o  
N o  
N o  
N o  
N o  
Yes 
N o  
N o  
Yes 
N o  
N o  
Yes 
N o  
N o  
N o  
N o  
N o  
Yes 
N o  
N o  
N o  
Yes 
N o  
N o  
Yes 
N o  
N o  
N o  
N o  
N o  
N o  
N o  
Yes 
N o  
N o  
Yes 
N o  
Yes 
N o  
a. Use a statistical software package to create a frequency histogram for these 
data. Then shade the area under the histogram that corresponds to lost 
orders. 
i 
b. Use a statistical software package to create a stem-and-leaf display for 
a 
these data. Then shade each leaf of the display that corresponds to a lost 
order. 
c. Compare and interpret the two graphical displays of these data. 
S o I u t i o n 
a. We used SAS to generate the frequency histogram in Figure 2.10. SAS, like 
most statistical software, offers the user the choice of accepting default 
class intervals and interval widths, or the user can make his or her own 
selections. After some experimenting with various numbers of class inter- 
vals and interval widths, we used 10 intervals. SAS then created intervals of 
width 2 days, beginning at 1 day, just below the smallest measurement of 

G r a p h i c a l  M e t h o d s  f o r  D e s c r i b i n g  Q u a n t i t a t i v e  Data 
41 
FIGURE 2.10 
Frequency 
SAS frequency histogram for 
14 
the quote processing time data 
13 
4 
6 
8 
10 12 
11 
16 
18 
20 
Processing time (days) 
1.25 days, and ending with 21 days, just above the largest measurement of 
20.2 days. Note that SAS labels the midpoint of each bar, rather than its 
endpoints. Thus, the bar labeled "2" represents measurements from 1.00 to 
2.99, the bar labeled "4" represents measurements from 3.00 to 4.99, etc. 
This histogram clearly shows the clustering of the measurements in the 
lower end of the distribution (between approximately 1 and 7 days), and 
the relatively few measurements in the upper end of the distribution 
(greater than 12 days). The shading of the area of the frequency histogram 
corresponding to lost orders clearly indicates that they lie in the upper tail 
of the distribution. 
We used SPSS to generate the stem-and-leaf display in Figure 2.11. Note 
that the stem consists of the number of whole days (units and tens digits), 
and the leaf is the tenths digit (first digit after the decimal) of each mea- 
surement." The hundredths digit has been dropped to make the display 
more visually effective. SPSS also includes a column titled Frequency show- 
ing the number of measurements corresponding to each stem. Note, too, 
that instead of extending the stems all the way to 20 days to show the largest 
measurement, SPSS truncates the display after the stem corresponding to 13 
days, labels the largest four measurements (shaded) as Extremes, and simply 
lists them horizontally in the last row of the display. Extreme observations 
that are detached from the remainder of the data are called outliers, and 
they usually receive special attention in statistical analyses. Although out- 
liers may represent legitimate measurements, they are frequently mistakes: 
incorrectly recorded, miscoded during data entry, or taken from a popula- 
tion different from the one from which the rest of the sample was selected. 
Stem-and-leaf displays are useful for identifying outliers. Note that like the 
histogram, the stem-and-leaf display shows the shaded "lost" orders in the 
upper-tail of the distribution. 
*In the examples in this section, the stem was formed from the digits to the left of the decimal. 
This is not always the case. For example, in the following data set the stems could be the tenths 
digit and the leaves the hundredths digit: .12, .15, .22, .25, .28, .33. 

42 
CHAPTER 
2 
M e t h o d s  f o r  Describing Sets of Data 
F I G U R E  2.1 1 
SPSS stem-and-leaf display for 
the quote processing time data 
Frequency 
Stem & Leaf 
5.00 
1 . 24789 
5.00 
2 . 03569 
8.00 
3 . 23344699 
6.00 
4 . 034469 
6.00 
5 . 114579 
5.00 
6 . 01467 
5.00 
7 . 24557 
1.00 
8 .  2 
3.00 
9 . 049 
1.00 
10 . 0 
.oo 
11 . 
.oo 
12 . 
1.00 
13 . 4 
4.00 Extremes 
(14.1), (14.31, (16.31, (20.2) 
Stem width: 
1.00 
Each leqf: 
1 case(s) 
c. As is usually the case for data sets that are not too large (say, fewer than 
100 measurements), the stem-and-leaf display provides more detail than the 
histogram without being unwieldy. For instance, the stem-and-leaf display in 
Figure 2.11 clearly indicates not only that the lost orders are associated 
with high processing times (as does the histogram in Figure 2.10), but also 
exactly which of the times correspond to lost orders. Histograms are most 
useful for displaying very large data sets, when the overall shape of the 
distribution of measurements is more important than the identification of 
individual measurements. Nevertheless, the message of both graphical dis- 
plays is clear: establishing processing time limits may well result in fewer 
lost orders. 
Most statistical software packages can be used to generate histograms, stem- 
and-leaf displays, and dot plots. All three are useful tools for graphically describ- 
ing data sets. We recommend that you generate and compare the displays 
whenever you can. You'll find that histograms are generally more useful for very 
large data sets, while stem-and-leaf displays and dot plots provide useful detail for 
smaller data sets. 
I U S I N G  THE T I - 8 3  G R A P H I N G  CALCULATOR 
Making a Histogram on the TI-83 
Step 1 Enter the data 
Press STAT 1 for STAT edit 
Use the arrow and ENTER keys to enter the data set into L1. 
Step 2. Set up the histogram plot 
Press 2nd Y = for STAT PLOT 
Press 1 
for Plot 1 
(continued) 

SECTION 2.2 
G r a p h i c a l  M e t h o d s  f o r  D e s c r i b i n g  Q u a n t i t a t i v e  Data 
43 
Use the arrow and ENTER keys to set up the screen as shown below. 
Note: Press 2nd 1 for L1 
Step 3 Select your window settings 
Press WINDOW and adjust the settings as follows: 
Xmin = lowest class boundary 
Xmax = highest class boundary 
Xscl = class width 
Ymin = 0 
Ymax = greatest class frequency 
Yscl = approximately YmaxIlO 
Xres = 1 
Step 4 View the graph 
Press GRAPH 
0 p t i o n a l Read class frequencies and class boundaries 
Step 
You can press TRACE to read the class frequencies and class boundaries. 
Use the arrow keys to move between bars. 
Example The figures below show TI-83 window settings and histogram for the fol- 
lowing sample data: 
86,70,62,98,73,56,53,92,86,37,62,83,78,49,78,37,67,79,57 
WINDOW 
Xmin= -. 
5 
Xmax=100.5 
Xscl=10 
Ymin=0 
Ymax=5 
Yscl=l 
Xres=l 
Making a Histogram From a Frequency Table 
Step 1 Enrer the data 
Enter a value from the middle of each class in L1 
Enter the class frequencies or relative frequencies in L2 
Step 2 Set up the histogram plot 
Press 2nd Y = for STAT PLOT 
Press 1 
for Blot 1 
(continued) 

44 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  o f  D a t a  
Use the arrow and ENTER keys to set up the screen as shown below. 
Steps 3-4 
Follow steps 3-4 given above. 
Learning the Mechanics 
2.12 Graph the relative frequency histogram for the 500 
meawrements summari~ed in the accompanying rela- 
tive frequency table. 
Y 
................................................................................. 
Measurement Class 
Relative Frequency 
.............................................................................. 
S 2 . 5  
.10 
2.5-4.5 
.15 
4.5-6.5 
.25 
6.5-8.5 
.20 
8.5-10.5 
.05 
10.5-12.5 
.10 
12.5-14.5 
.10 
14.5-16.5 
.05 
2.13 Refer to Exercise 2.12. Calculate the number of the 
500 measurements falling into each o l  the measure- 
ment clahses. Then graph a frequency histogram for 
these data. 
2.14 SAS was used to generate the stem-and-leaf display 
shown here. Note that SAS arranges the slems in 
descending order. 
a. How many observations were in the original data set? 
b. In the bottoni row of the stern-and-leaf display, iden- 
tify the $tern, the leaves, and the nurntxrs in the 
orignal data set represented by this stem and its 
leaves. 
c Re-create all the numbers in the data set and con- 
struct a dot plot. 
2.15 MINITAB was used to generate the following histogram: 
a. Is this a frequency histogram or a relative frequency 
histogram? Explain. 
b. How many measurement classes were used in the 
construction of this histogram'? 
c. How many measurements are there in the data set 
described by this histogram? 
MINITAB output for Exercise 2.1 5 
- 
MIDDLE OF 
INTERVAL 
2 0 
2 2 
2 4 
2 6 
2 8 
3 0 
3 2 
3 4 
3 6 
3 8 
4 0 
42 
4 4 
4 6 
NUMBER OF 
OBSERVATIONS 
1 
* 
3 
*** 
2 
** 
3 
*** 
q 
**** 
7 
******* 
11 
*********** 
6 
****** 
2 
** 
3 
*** 
3 
*** 
2 
** 
1 
* 
1 
* 
2.16 The graph on p. 45 summarizes the scores obtained by 
100 students on a questionnaire designed to measure 
managerial ability. (Scores are integer values that range 
from 0 to 20.A high score indicates a high level of ability.) 
a. Which measurement class contains the highest pro- 
portion of test scores? 
b. What proportion of the scores lie between 3.5 and 5.5? 
c. What proportion of the scores are higher than 11.5? 
d. How many students scored less than 5.5:' 

SECTION 2.2 
G r a p h i c a l  M e t h o d s  f o r  D e s c r i b i n g  Q u a n t i t a t i v e  D a t a  
45 
1.5 
3.5 
5.5 
7.5 
9.5 
11.5 
13.5 
15.5 17.5 
Managerial ability 
Applying the Concepts 
2.17 The table (p..46) reports the one-year percentage 
change in stock price for all technology companies and 
all industrial companies on Fortune (Sept. 6,1999) mag- 
azine's ranking of the "One Hundred Fastest-Growing 
- 
Companies." 
a. Use a statistical software package to construct a 
stem-and-leaf display for the stock price changes of 
technology companies. Do the same for industrial 
companies. 
b. Use the results of part a to compare and contrast the 
stock price changes of the techrialogy and industrial 
companies. 
c. What percentage of the technology companies in the 
data set had stock prices that more than doubled? 
2.18 Mark McGwire of the St. Louis Cardinals and Sammy 
Sosa of the Chicago Cubs hit 70 and 66 home runs, 
respectively, during the 1998 Major League Baseball 
season, breaking the record held by Roger Maris (61 
home runs) since 1961. J.S. Simonoff of New York 
University collected data on the number of runs scored 
STLRUNS.DAT 
............................................................... 
St. Louis Cardinals 
by their respective teams in games in which McGwire 
and Sosa hit home runs (Journal of Statistics Education, 
Vol. 6, 1998). The data are reproduced in the table 
below. (An asterisk indicates a game in which McGwire 
or Sosa hit multiple home runs.) 
a. Construct a stem-and-leaf display for the number of 
runs scored by St. Louis during games when McGwire 
hit a home run. 
b. Repeat part a for Chicago and Sosa. 
c. Compare and contrast the two distributions. 
d. On the stem-and-leaf display, circle the games in 
which McGwire or Sosa hit multiple home runs. Do 
you detect any patterns? 
2.19 Bonds can be issued by the federal government, state 
and local governments, and US corporations. A mort- 
gage bond is a promissory note in which the issuing 
company pledges certain real assets as security in 
exchange for a specified amount of money. A debenture 
is an unsecured promissory note, backed only by the 
general credit ol the issuer. The bond price of either a 
mortgage bond or debenture is negotiated between the 
asked price (the lowest price anyone will accept) and 
the bid price (the highest price anyone wants to pay) 
(Alexander, Sharpe, and Bailey, Fundamentals of 
Investments, 1993). The table on page 47 contains the 
bid prices for a sample of 30 publicly traded bonds 
issued by utility con~panies. 
a. A frequency histogram (p. 47) was generated using 
SPSS. Note that SPSS labels the midpoint of each 
measurement class rather than the two endpoints. 
Interpret thc histogram. 
b. Use the histogram to determine the number of 
bonds in the sample that had a bid price greater than 
$96.50. What proportion of the total number of 
bonds is this group? 
c. Shade the area under the histogram that corresponds 
to the proportion in part b. 
CUBSRUNS.DAT 
... 
............................. 
chicago Cubs 
................................................................ 
3 
6* 
8* 
6 
7* 
4 
5 
2 
7 
2 
1 
8* 
6 
13 
1 
9* 
6 
8 
4 
2 
3* 
10 
3 
6 
9 
6* 
5 
4 
10 
5 
5 
4 
4 
9 
2 
9 
5 
7 
5* 
5 
4 
8 
5* 
6 
5 
15 
lo* 
9 
8 
l l *  
5 
3 
11 
6 

CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets of Data 
- 
FORT100.DAT 
.................. _....__. 
. ............................................................................................................................................................ 
Technology Companies 
% Change 
Industrial Companies 
% Change 
....................................................................................................................................................................................... 
- 
SIEBEL SYSTEMS 
THQ 
NETWORK APPLIANCE 
CITRIX SYSTEMS 
r 
VERITAS SOFTWARE 
VITESSE SEMICONDUCTOR 
DELL COMPUTER 
CREE RESEARCH 
QUALCOMM 
ARGUSS HOLDINGS 
TEKELEC 
LEGATO SYSTEMS 
ASPECT DEVELOPMENT 
COMPUWARE 
HAUPPAUGE DIGITAL 
ZOMAX 
AVT 
MERCURY INTERACTIVE 
WHITTMAN-HART 
AAVID THERMAL TECH. 
i2 TECHNOLOGIES 
INSIGHT ENTERPRISES 
ANALYTICAL SURVEYS 
HNC SOFTWARE 
CIBER 
TSR 
TECH DATA 
POMEROY COMPUTERS RES. 
MERITAGE 
SALTON 
CONSOLIDATED GRAPHICS 
KELLSTROM INDUSTRIES 
ARMOR HOLDINGS 
MONACO COACH 
SUMMA INDUSTRIES 
TOWER AUTOMOTIVE 
CADE INDUSTRIES 
DYCOM INDUSTRIES 
MODTECH HOLDINGS 
MORRISON KNUDSEN 
SCHULER HOMES 
Source: Fortune, Sept. 6,1999. 
2.20 Production processes may be classified as make-to-stock 
processes or make-to-order processes. Make-to-stock 
processes are designed to produce a standardized prod- 
uct that can be sold to customers from the firm's inven- 
tory. Make-to-order processes are designed to produce 
products according to customer specifications 
(Schroeder, Operations Management, 1993). In general, 
performance of make-to-order processes is measured by 
delivery time-the 
time from receipt of an order until 
the product is delivered to the customer. The following 
data set is a sample of delivery times (in days) for a par- 
ticular make-to-order firm last year. The delivery times 
marked by an asterisk are associated with customers 
who subsequently placed additional orders with the firm. 
The MINITAB stem-and-leaf display of these data is 
shown at the bottom of page 47. 
a. Circle the individual leaves that are associated with 
customers who did not place a subsequent order. 
b. Concerned that they are losing potential repeat cus- 
tomers because of long delivery times, the manage- 
ment would like to establish a guideline for the 
maximum tolerable delivery time. Using the stem- 


48 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of D a t a  
- 
Q CLEANAIR.DAT 
............................................................................................................................................................................................................................... 
Company 
Company 
Identification Number 
Penalty 
Law* 
Identification Number 
Penalty 
Law* 
............................................................................................................................................................................................................................... 
01 
$ 930,000 
CERCLA 
16 
90,000 
RCRA 
02 
10,000 
CWA 
17 
20,000 
CWA 
03 
90,600 
CAA 
18 
40,000 
CWA 
04 
123,549 
CWA 
19 
20,000 
CWA 
05 
37,500 
CWA 
20 
40,000 
CWA 
06 
137,500 
CWA 
21 
850,000 
CWA 
07 
2,500 
SDWA 
22 
35,000 
CWA 
08 
1,000,000 
CWA 
23 
4,000 
CAA 
09 
25,000 
CAA 
24 
25,000 
CWA 
09 
25,000 
CAA 
25 
40,000 
CWA 
10 
25,000 
CWA 
26 
30,000 
CAA 
10 
25,000 
RCRA 
27 
15,000 
CWA 
11 
19,100 
CAA 
28 
15,000 
CAA 
12 
100,000 
CWA 
29 
105,000 
CAA 
12 
30,000 
CWA 
30 
20,000 
CWA 
13 
35,000 
CAA 
31 
400,000 
CWA 
13 
43,000 
CWA 
32 
85,000 
CWA 
A 
14 
190,000 
CWA 
33 
300,000 
CWNRCRAICERCLA 
15 
15,000 
CWA 
34 
30,000 
CWA 
*CAA: Clean Air Act; CERCLA: Comprehensive Environmental Response, Compensation, and Liability Act; CWA: Clean Water Act; 
RCRA: Resource Conservation and Recovery Act; SDWA: Safe Drinking Water Acl. 
Source: Tabor, R. H., and Stanwick, S. D. "Arkansas: An environmental perspective." Arkansas Business and Economic Review, Vol. 28, NO. 2, 
Summer 1995, pp. 22-32 (Table 4). 
(Note: Some companies were involved in more than one 
Air Act violations relative to the other types of vio- 
civil action.) 
lations reported in the table? Explain. 
a. Construct a stem-and-leaf display for all 38 penalties. 
2-22 in a manufacturing plant a work center is a specific pro- 
( 
b. Circle the individual leaves that are associated with 
duction facility that consists of one or more people 
penalties imposed for violations of the Clean Air Act. 
andlor machines and is treated as one unit for the pur- 
c. What does the pattern of circles in part b suggest 
poses of capacity requirements planning and job sched- 
about the severity of the penalties imposed for Clean 
uling. If jobs arrive at a particular work center at a 
l 
W0RKCTR.DAT 
..................................................................................................................................................................................... 
Number of ltems Arriving at Work Center per Hour 
..................................................................................................................................................................................... 
155 
115 
156 
150 
159 
163 
172 
143 
159 
166 
148 
175 
151 
161 
138 
148 
129 
135 
140 
152 
139 
Number of ltems Departing Work Center per Hour 
MINITAB Output for Exercise 2.22 
. . 
......... . . 
. . . .  
-----+---------+---------+---------+-----------+----------- 
+ - ARRIVE 
... 
.
.
.
 
. . . . . . . . .  
-----+---------+---------+-----------+---------+--------- 
+-DEPART 
105 
12 0 
135 
150 
165 
180 
i 

SECTION 2.2 
G r a p h i c a l  M e t h o d s  f o r  D e s c r i b i n g  Q u a n t i t a t i v e  D a t a  
49 
faster rate than they depart, the work center impedes 
the overall production process and is referred to as a 
bottleneck (Fogarty, Blackstone, and Hoffmann, 
Production and Inventory Management, 1991). The data 
in the table (bottom of p. 48) were collected by an oper- 
ations manager for use in invcstigating a potential bot- 
tleneck work center. MINITAB dot plots for the two 
sets of data are also shown on p. 48. D o  the dot plots 
suggest that the work center may be a bottleneck? 
Explain. 
2.23 In order to estimate how long it will take to produce a 
particular product, a manufacturer will study the rela- 
tionship between production time per unit and the 
number of units that have been produced. The line or 
curve characterizing this relationship is called a learn- 
ing curve (Adler and Clark, Management Science, 
Mar. 1991). Twenty-five employees, all of whom were 
performing the same production task for the tenth 
time, were observed. Each person's task completion 
_, 
time (in minutes) was recorded. The same 25 employ- 
ees were observed again the 30th time they performed 
the same task and the 50th time they performed the 
task.The resulting completion timcs are shown in the 
table below. 
a. Use a statistical software package to construct a fre- 
quency histogram for each of the three data sets. 
Performance 
Employee 
10th 
b. Compare the histograms. Does it appear that the re- 
lationship between task completion time and the 
number of times the task is perforrncd is in agree- 
ment with the observations noted above about pro- 
duction processes in general? Explain. 
2.24 Financially distressed firms can gain protection from 
their creditors while they restructure by filing for pro- 
tection under US Bankruptcy Codes. In a prepack- 
aged bankruptcy, a firm negotiates a reorganization 
plan with its creditors prior to filing for bankruptcy. 
This can result in a much quicker exit from bankrupt- 
cy than traditional bankruptcy filings. Brian Betker 
conducted a study of 49 prepackaged bankruptcies 
that were filed between 1986 and 1993 and rcported 
the results in Financial Management (Spring 1995). The 
table on page 50 lists the time in bankruptcy (in 
months) for these 49 companies.The table also lists the 
results of a vote by each company's board of dircctors 
concerning their preferred reorganization plan. (Note: 
"Joint" = joint exchange offer with prepackaged bank- 
ruptcy solicitation; "Prepack" = prepackaged bank- 
ruptcy solicitation only; "None" = no pre-filing vote 
held.) 
a. Construct a stem-and-leaf display for the length of 
time in bankruptcy for all 49 companies. 
b. Summarize the information reflected in the stem- 
and-leaf display, part a. Make a general statement 
about the length of time in bankruptcy for firms 
using "prepacks." 
c. Select a graphical technique that will permit a com- 
parison of the time-in-bankruptcy distributions for 
the three types of "prepack" firms: those who held 
no pre-filing vote; those who voted their preference 
for a joint solution; and those who voted their pref- 
erence for a prepack. 
Histogram for Exercise 2.25 
20 r 
" 
0.2 
0.3 
0.4 
0.5 
0.0 
0.7 
1
.
 0.9 
1 
1.1 
Sufficient norm constraint level 
Source: Hoffman, M.W., and Buckley, K.M. "Robust time- 
domain processing of broadband microphone array data." 
IEEE Trunsuctions on Speech and Audio Proce~sing, Vol. 3, 
No. 3, May 1995, p. 199 (Figure 4). 01995 IEEE. 

50 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  
d. The companies that were reorganized through a lever- 
aged buyout are identified by an asterisk (*) in the 
table. Identify these firms on the stem-and-leaf display, 
part a, by circling their bankruptcy times. Do you ob- 
serve any pattern in the graph? Explain. 
2.25 It's not uncommon for hearing aids to malfunction and 
cancel the desired signal. IEEE Transactions on Speech 
and Audio Processing (May 1995) reported on a new 
audio processing system designed to limit the amount of 
signal cancellation that may occur. The system utilizes a 
BANKRUPT.DAT 
............................................................................................................. 
&a 
Pre-filing 
Time in Bankruptcy 
m p a n y  
Votes 
(months) 
AM International 
Anglo Energy 
Arizona Biltmore* 
,, 
Astrex 
Barry's Jewelers 
Calton 
Cencor 
Charter Medical* 
Cherokee* 
Circle Express 
Cook Inlet Comm. 
Crystal Oil 
Divi Hotels 
Edgell Comm.* 
Endevco 
Gaylord Container 
Great Amer. Comm.* 
Hadson 
In-Store Advertising 
JPS Textiles* 
Kendall* 
Kinder-Care 
Kroy* 
Ladish* 
LaSalle Energy* 
None 
Prepack 
Prepack 
None 
None 
Prepack 
Joint 
Prepack 
Joint 
Prepack 
Prepack 
None 
None 
Prepack 
Prepack 
Joint 
Prepack 
Prepack 
Prepack 
Prepack 
Prepack 
None 
Prepack 
Joint 
Prepack 
Sets of Data 
mathematical equation that involves a variable, 
called 
a sufficient norm constraint. A histogram for realizations 
of I! produced using simulation, is shown on page 49. 
a. Estimale the percentage of realizations of V with 
values ranging from .425 to .675. 
b. Cancellation of the desired signal is limited by se- 
lecting a norm constraint I.: Find the value of V for a 
company that wants to market the new hearing aid 
so that only 10% of the realizations have values 
below the selected level. 
................................................................................................................. 
Pre-filing 
Time in Bankruptcy 
Company 
Votes 
(months) 
................................................................................................................. 
LIVE Entertainment 
Joint 
1.4 
Mayflower Group* 
Prepack 
1.4 
Memorex Telex* 
Prepack 
1.1 
Munsingwear 
None 
2.9 
Nat'l Environmental 
Joint 
5.2 
Petrolane Gas 
Prepack 
1.2 
Price Communications 
None 
2.4 
Republic Health* 
Joint 
4.5 
Resorts Int'l* 
None 
7.8 
Restaurant Enterprises* 
Prepack 
1.5 
Rymer Foods 
Joint 
2.1 
SCI TV* 
Prepack 
2.1 
Southland* 
Joint 
3.9 
Specialty Equipment* 
None 
2.6 
SPI Holdings* 
Joint 
1.4 
Sprouse-Reitz 
Prepack 
1.4 
Sunshine Metals 
Joint 
5.4 
TI EiCommunications 
None 
2.4 
Trump Plaza 
Prepack 
1.7 
Trump Taj Mahal 
Prepack 
1.4 
Trump's Castle 
Prepack 
2.7 
USG 
Prepack 
1.2 
Vyquest 
Prepack 
4.1 
West Point Acq.* 
Prepack 
2.9 
*Leveraged buyout. 
Source: Betker, B.L. "An empirical examination of prepackaged bankruptcy." Financial Management, Vol. 24, No. 1, Spring 1995, p. 6 (Table 2). 
1 
SUMMATION NOTATION 
Now that we've examined some graphical techniques for summarizing and de- 
scribing quantitative data sets, we turn to numerical methods for accomplishing 
this objective. Before giving the formulas for calculating numerical descriptive 
measures, let's look at some shorthand notation that will simplify our calcula- 
tion instructions. Remember that such notation is used for one reason only-to 
avoid repeating the same verbal descriptions over and over. If you mentally 
substitute the verbal definition of a symbol each time you read it, you'll soon 
get used to it. 
We denote the measurements of a quantitative data set as follows: 
XI, x2, x3,. ... X, where xl is the first measurement in the data set, x2 is the second 
measurement in the data set, x3 is the third measurement in the data set,. .., and 

e 
SECTION 2.3 
S u m m a t i o n  N o t a t i o n  
51 
x, is the nth (and last) measurement in the data set. Thus, if we have five mea- 
surements in a set of data, we will write x,, x2, x3, x,, xs to represent the mea- 
surements. If the actual numbers are 5, 3, 8, 5, and 4, we have xl = 5, x2 = 3, 
x, = 8, x, = 5, and X, = 4. 
I 
, 
Most of the formulas we use require a summation of numbers. For example, one 
I 
sum we'll need to obtain is the sum of all the measurements in the data set, or 
I 
xl + x2 + x3 + . . a  + x,. TO shorten the notation, we use the symbol 2 for the 
n 
summation. That is, xl + x2 + x3 + ... + x, = 
x,. Verbally translate 2 x, as 
r = l  
r = l  
follows: "The sum of the measurements, whose typical member is x,, beginning 
with the member xl and ending with the member x,." 
Suppose, as in our earlier example, x, = 5, x2 = 3, x, = 8, x, = 5, and x, = 4. 
5 
Then the sum of the five measurements, denoted 
x,, is obtained as follows: 
r=l 
I 
Another important calculation requires that we square each measurement 
I 
n 
and then sum the squares. The notation for this sum is 2 x:. For the five mea- 
r=l 
surements above, we have 
5 
= 5' + 32 + S2 + 52 + 42 
= 25 + 9 + 64 + 25 + 16 = 139 
In general, the symbol following the summation sign 2 represents the vari- 
able (or function of the variable) that is to be summed. 
e Meaning of Summation Notatio 
Sum the measurements on the 
the right of the sum- 
mation symbol, beginning with 
d ending with the nth 
measurement. 
I 
Learning the Mechanics 
n 
Note: In all exercises, x represents 
. 
,=I 
2.27 Suppose a data set contains the obsenations 3,8,4,5,3, 
2.26 A data set contains the observations 5 , 1 , 3 , 2 , 1 .  Find: 
4,6. Find: 
a. Cx b. 2 x 2  c. C ( X  - 1 )  
a. C x  b. E x 2  C. C ( X  - 5)2 
d. C ( x  - 1)' 
e. (EX)' 
d. E ( x  - 2)2 e. (EX)' 

52 
CHAPTER 
2 , M e t h o d s  f o r  D e s c r i b i n g  S e t s  of D a t a  
2.28 Refer to Exercise 2.26. Find: 
2.29 A data set contains the observations 6,0, -2, -1,3. Find: 
Numerical descriptive 
measures 
NUMERICAL MEASURES OF CENTRAL TENDENCY 
When we speak of a data set, we refer to either a sample or a population. If sta- 
tistical inference is our goal, we'll wish ultimately to use sample numerical de- 
scriptive measures to make inferences about the corresponding measures for a 
population. 
As you'll see, a large number of numerical methods are available to de- 
scribe quantitative data sets. Most of these methods measure one of two data 
characteristics: 
1. The central tendency of the set of measurements-that 
is, the tendency of the 
data to cluster, or center, about certain numerical values (see Figure 2.12a). 
2. The variability of the set of measurements-that 
is, the spread of the data 
(see Figure 2.12b). 
In this section we concentrate on measures of central tendency. Tn the next 
section, we discuss measures of variability. 
The most popular and best-understood measure of central tendency for a 
quantitative data set is the arithmetic mean (or simply the mean) of a data set. 
The mean of a set of quantitative data is the sum of the measurements divid- 
ed by the number of measurements contained in the data set. 
In everyday terms, the mean is the average value of the data set and is often 
used to represent a "typical" value. We denote the mean of a sample of measure- 
ments by T (read "x-bar"), and represent the formula for its calculation as shown 
in the box. 
t 
I- 
Spread -4 
Center 
a. 
b. 

C 
53 * 
SECTION 2.4 
N u m e r i c a l  M e a s u r e s  o f  C e n t r a l  T e n d e n c y  
Calculate the mean of thc following five samplc mcasurcmcnts: 5 , 3 , 8 , 5 , 6 .  
S o I u t i o n Using the definition of sample mean and the summation notation, we find 
Thus, the mean of this sample is 5.4.* 
* 
r the R&D expenditure percen 
S o I u t i o n The mean R&D percentage for the 50 companies is denoted 
Rather than compute F by hand (or calculator), we entered the data of 
Table 2.4 into a computer and employed SPSS statistical software to compute 
the mean. The SPSS printout is shown in Figure 2.13. The sample mean, high- 
lighted on the 
is i = 8.492. 
- 
- 
RDEXP 
Valid cases: 
50.0 
Missing cases: 
.O 
Percent missing: 
.O 
Mean 
8.4920 
Std Err 
.2801 Min 
5.2000 
Skewness 
.8546 
Median 
8.0500 
Variance 
3.9228 Max 
13.5000 
S E Skew 
.3366 
5% Trim 
8.3833 
Std Dev 
1.9806 Range 
8.3000 Kurtosis 
.4193 
IQR 
2.5750 S E Kurt 
.6619 
FIGURE 2.1 3 
SPSS printout of numerical descriptive measures for 50 R&D percentages 
Given this information, you can visualize a distribution of R&D percent- 
ages centered in the vicinity of T = 8.492. An examination of the relative fre- 
quency histogram (Figure 2.8) confirms that i does in fact fall near the center of 
thc distribution. 
The sample mean i will play an important role in accomplishing our objec- 
tive of making inferences about populations based on sample information. For this 
reason we need to use a different symbol for the mean of a population-the 
mean 
*In the examples given here, x is sometimes rounded to the nearest tenth, sometimes the nearest 
hundredth, sometimes the nearest thousandth, and so on.There is no specific rule for rounding 
when calculating T because i is specifically defined to be the sum of all measurements divided by 
n; that is, it is a specific fraction. When x is used for descriptive purposes, it is often convenient to 
round the calculated value of i to the number of significant figures used for the original 
measurements. When i is to be used in other calculations, however, it may be necessary to retain 
more significant figures. 

C 
CHAPTER 
2 
M e t h o d s  f o r  Describing Sets of Data 
of the set of measurements on every unit in the population. We use the Greek let- 
ter p (mu) for the population mean. 
FIGURE 2.14 
Location of the median 
ek letters to represent 
mean are: 
We'll often use the sample mean, i, 
to estimate (make an inference about) the 
population mean, p. For example, the percentages of revenues spent on R&D by the 
population consisting of all US companies has a mean equal to some value, p. Our 
sample of 50 companies yielded percentages with a mean of 2 = 8.492. If, as is usu- 
ally the case, we don't have access to the measurements for the entire population, 
we could use 2 as an estimator or approximator for p. Then we'd need to know 
something about the reliability of our inference. That is, we'd need to know how ac- 
curately we might expect 2 to estimate p. In Chapter 5, we'll find that this accuracy 
depends on two factors: 
1. The size of the sample. The larger the sample, the more accurate the estimate 
will tend to be. 
2. The variability, or spread, of the data. All other factors remaining constant, 
the more variable the data, the less accurate the estimate. 
Another important measure of central tendency is the median. 
The median of a quantitative data set is the middle number when the mea- 
surements are arranged in ascending (or descending) order. 
The median is of most value in describing large data sets. If the data set is 
characterized by a relative frequency histogram (Figure 2.14), the median is the 
point on the x-axis such that half the area under the histogram lies above the me- 
dian and half lies below. [Note: In Section 2.2 we observed that the relative fre- 
quency associated with a particular interval on the horizontal axis is proportional 
Median 

SECTION 2.4 
Numerical Measures o f  Central Tendency 
55 - 
to the amount of area under the histogram that lies above the interval.] We denote 
the median of a sample by m. 
8 -  
Consider the following sample of n = 7 measurements: 5,7,4,5,20,6,2. 
a. Calculate the median m of this sample. 
b. Eliminate the last measurement (the 2) and calculate the median of the 
remaining n = 6 measurements. 
S o I u t i o n 
a. The seven measurements in the sample are ranked in ascending order: 2,4, 
5,5,6,7,20 
Because the number of measurements is odd, the median is the middle mea- 
surement. Thus, the median of this sample is m = 5 (the second 5 listed in 
the sequence). 
b. After removing the 2 from the set of measurements (the second 5 listed in 
the sequence), we rank the sample measurements in ascending order as 
follows: 4,5,5,6,7,20 
Now the number of measurements is even, so we average the middle two 
measurements.The median ism = (5 + 6)/2 = 5.5. 
+ 
In certain situations, the median may be a better measure of central ten- 
dency than the mean. In particular, the median is less sensitive than the mean to 
extremely large or small measurements. Note, for instance, that all but one of the 
measurements in part a of Example 2.6 center about x = 5. The single relatively 
large measurement, x = 20, does not affect the value of the median, 5, but it caus- 
es the mean,? = 7, to lie to the right of most of the measurements. 
As another example of data from which the central tendency is better de- 
scribed by the median than the mean, consider the salaries of professional athletes 
(e.g., National Basketball Association players). The presence of just a few athletes 
(e.g., Shaquille O'Neal) with very high salaries will affect the mean more than the 
median. Thus, the median will provide a more accurate picture of the typical salary 
for the professional league. The mean could exceed the vast majority of the sample 
measurements (salaries), making it a misleading measure of central tendency. 
S 0 I U t i 0 n For this large data set, we again resort to a computer analysis. The SPSS printout 
is reproduced in Figure 2.15, with the median highlighted. You can see that the 
median is 8.05.This value implies that half of the 50 R&D percentages in the data 
set fall below 8.05 and half lie above 8.05. 

56 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of D a t a  
RDEXP 
Valid cases: 
50.0 
Missing cases: 
.O 
Percent missing: 
.O 
Mean 
8.4920 
Std Err 
.2801 Min 
5.2000 Skewness 
.8546 
Median 
8.0500 
Variance 
3.9228 Max 
13.5000 S E Skew 
.3366 
5% Trim 
8.3833 
Std Dev 
1.9806 Range 
8.3000 Kurtosis 
.4193 
I QR 
2.5750 S E Kurt 
.6619 
FIGURE 2.15 
SPSS printout of numerical descriptive measures for 50 R&D percentages. 
Note that the mean (8.492) for these data is larger than the median. This fact 
indicates that the data are skewed to the right-that 
is, there are more extreme 
measurements in the right tail of the distribution than in the left tail (recall the 
histogram, Figure 2.8). 
In general, extreme values (large or small) affect the mean more than the 
median since these values are used explicitly in the calculation of the mean. On 
the other hand, the median is not affected directly by extreme measurements, 
since only the middle measurement (or two middle measurements) is explicitly 
used to calculate the median. Consequently, if measurements are pulled toward 
one end of the distribution (as with the R&D percentages), the mean will shift to- 
ward that tail more than the median. 
6 
i
A comparison of the mean and median gives us a general method for de- 
tecting skewness in data sets, as shown in the next box. 
4 
1

SECTION 2.4 
N u m e r i c a l  M e a s u r e s  o f  C e n t r a l  T e n d e n c y  
57 
the data set is skewed to 
e mean is less than (to the left of) th 
A third measure of central tendency is the mode of a set of measurements. 
DEFINITION 2.6 
The mode is the measurement that occurs most frequently in the data set. 
~
~
m
~
-
s
~
~
~
~
~
w
Each of 10 taste testers rated a new brand of barbecue sauce on a 10 point scale, 
where 1 = awful and 10 = excellent. Find the mode for the 10 ratings shown 
below. 
8
7
9
6
8
1
0
9
9
5
7
 
S o I u t i o n 
Since 9 occurs most often, the mode of the 10 taste ratings is 9. 
* 
Note that the data in Example 2.8 are actually qualitative in nature (e.g., 
"awful," "excellent"). The mode is particularly useful for describing qualitative 
data. The modal category is simply the category (or class) that occurs most often. 
Because it emphasizes data concentration, the mode is also used with quantitative 
data sets to locate the region in which much of the data is concentrated. A retail- 
er of men's clothing would be interested in the modal neck size and sleeve length 
of potential customers. The modal income class of the laborers in the United 
States is of interest to the Labor Departnlent. 
For some quantitative data sets, the mode may not be very meaningful. For 
example, consider the percentages of revenues spent on research and develop- 
ment (R&D) by 50 companies,Table 2.4. A reexamination of the data reveals that 
three of the measurements are repeated three times: 6.5%,6.9%, and 8.2%. Thus, 
there are three modes in the sample and none is particularly useful as a measure 
of central tendency. 
A more meaningful measure can be obtained from a relative frequency 
histogram for quantitative data. Thc measurement class containing the largest 
relative frequency is called the modal class. Several definitions exist for locat- 
ing the position of the mode within a modal class, but the simplest is to define 
the mode as the midpoint of the modal class. For example, examine the relative 
frequency histogram for the R&D expenditure percentages, reproduced below 
in Figure 2.16. You can see that the modal class is the interval 7.35-8.45. 
The 
mode (the midpoint) is 7.90. This modal class (and the mode itself) identifies 
-.. 
the area in which the data are most concentrated, and in that sense it is a mea- 
sure of central tendency. However, for most applications involving quantitative 

58 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of D a t a  
F I G U R E  2.16 
Relative frequency 
histoqram for the 
1 
computer companies' 
9 .30 
R&D percentages: The 
modal class 
3 
.2o 
$ .- * - 
2 .lo 
.oo 
5.15 6.25 7.35 8.45 9.55 10.65 11.75 12.85 13.95 
R&D percentage 
data, the mean and median provide more descriptive information than the 
mode. 
:inding One-Variable Descriptive Statistics 
J S l N G  THE T I - 8 3  GRAPHING CALCULATOR 
it ep 1 Enter the data 
, 
Press STAT 1 for STAT Edit 
Enter the data into one of the lists. 
Step 2 Calculate descriptive statistics 
Press STAT 
Press the right arrow key to highlight CALC 
Press ENTER for 1-Var Stats 
Enter the name of the list containing your data. 
Press 2nd 1 for L1 (or 2nd 2 for L2 etc.) 
Press ENTER 
You should see the statistics on your screen. Some of the statistics are off the bottom 
of the screen. Use the down arrow to scroll through to see the remaining statistics. Use 
the up arrow to scroll back up. 
Example The descriptive statistics for the sample data set 
86,70,62,98,73,56,53,92,86,37,62,83,78,49,78,37,67,79,.57 
are shown below, as calculated by the TI-83. 
(continued, 
--.c 

r 
SECTION 
2.4 
N u m e r i c a l  M e a s u r e s  o f  C e n t r a l  T e n d e n c y  
59 - 
Sorting The descriptive statistics do not include the mode. To find the mode, sort 
Data 
your data as follows: 
Press STAT 
Press 2 for SORTA( 
Enter the name of the list your data is in. If your data is in L1, press 2nd 1 
Press ENTER 
The Tcreen will say: DONE 
To see the sorted data, press STAT 1 for STAT Edit 
Learning the Mechanics 
Applying the Concepts 
2.30 Calculate the mode, mean, and median of the following 
2.35 The total number of passengers handled in 1998 by 
data: 
eight cruise shlps based in Port Canaveral (Florida) are 
18 10 
15 13 17 
15 )2 
4.5 18 16 11 
listed in the table below. Find and interpret the mean 
2.31 Calculate the mean and median of tde following grade 
and median of the data set. 
polnt averages: 
< 3 , 
-
?
l
 
' 
* 
? 
Fortune (Oct. 25,1999) magazine's second annual ranking 
3.2 
2.5 
2.1 
"3.7 
2.8 
2.0 
o\ the 50 moTt powerful women in America is provided in 
the table on page 60. In addition to salary, position, and 
2.32 Calculate the mean for samples where 
profile, Fortune based these rankings on the woman's 
a. n = 10, Ex = 85 
b. n = 16, Ex = 40 
influence within her company and her company's effect 
c. n = 45, Ex = 35 
d. n = 18, Ex = 242 
on culture in society. Cons~der the age (in years) distribu- 
2.33 Calculate the mean, median, and mode for each of th8- 
tion of these 50 women. Numerical descriptive statistics 
followmg samples: 
for the data are shown in the MINITAB printout below. 
a.7,-2,3,3,0,4 
b. 2,3,5,3,2,3,4,3,5,1,2,3,4 
a. Find the mean, median, and modal age of the distri- 
c. 51,50,47,50,48,41,59,68,45,37 
bution. Interpret these values. 
2.34 Descr~be how the mean compares to the median for a 
b. What do the mean and the median indicate about 
distribution as follows: 
the skewness of the age distribution? 
a. Skewed to the left 
b. Skewed to the right 
c. What percentage of these women are in their for- 
c. Symmetric 
ties? Their fifties? Their sixt~es? 
CRUISE.DAT 
....................................................................................................................... 
Cruise Line (Ship) 
Number of Passengers 
....................................................................................................................... 
Canaveral (Dolphin) 
152,240 
Carnival (Fantasy) 
480,924 
Disney (Magic) 
73,504 
Premier (Oceanic) 
270,361 
Royal Caribbean (Nordic Empress) 
106,161 
Sun Cruz Casinos 
453,806 
Sterling Cruises (New Yorker) 
15,782 
Topaz Int'l. Shipping (Topaz) 
28,280 
Source Florida Trend, Vol 41, No. 9, Jan. 1999. 
MINITAB Output for Exercise 2.36 
Descriptive Statistics 
Variable 
N 
Mean 
Median 
Tr Mean 
StDev 
SE Mean 
50 
48.160 
47.000 
47.795 
6.015 
0.851 
Variable 
Min 
Max 
Q 1 
Q3 
Age 
36.000 
68.000 
45.000 
51.250 

60 
- 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
,
q
 
WOMENPOW.DAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Rank 
Name 
Age 
Company 
Title 
Carly Fiorma 
Heidi Miller 
Mary Meeker 
Shclly Lazarus 
Meg Whitman 
Debby Hopkins 
Marjorie Scardino 
Martha Stewart 
Nancy Peretsman 
Pat RUSSO 
Patricia Dunn 
Abby Joseph Cohen 
Ann Livermore 
Andrea Jung 
Sherry Lansing 
Karen Katen 
Marilyn Carlson Nelson 
Judy McGrath 
Lois Juliber 
Gerry Laybourne 
Jud~th Estrin 
Cathleen Black 
Linda Sandford 
Ann Moore 
Jill Barad 
Oprah Winfrey 
Judy Lewent 
Joy Covey 
Rebecca Mark 
Deborah Willingham 
Dina Dubion 
Patricia Woertz 
Lawton Fitt 
Ann Fudge 
Carolyn Ticknor 
Dawn Lepore 
Jeannine Rivet 
Jamie Gorelick 
Jan Brandt 
Bridget Macaskill 
Jeanne Jackson 
Cynthia Trudell 
Nina DiSesa 
Linda Wachner 
Darla Moore 
Marion Sandler 
Michelle Anthony 
Orit Gadlesh 
Charlotte Beers 
Abigail Johnson 
Hewlett-Packard 
CI tigroup 
Morgan Stanley 
Ogilvy & Mather 
eBay 
Boeing 
Pearson 
Martha Stewart Living 
Allen & Co. 
Lucent Technologies 
Barclays Global Investors 
Goldman Sachs 
Hewlett-Packard 
Avon Products 
Paramount P~ctures 
Pfizer 
Carlson Cos. 
MTV & M2 
Colgate-Palmolive 
Oxygen Med~a 
Cisco Systems 
Hcarst Magazines 
IBM 
Time Inc. 
Matte1 
Harpo Entertainment 
Mcrck 
Amazon.com 
Azurix 
Microsoft 
Chase Manhattan 
Chevron 
Goldman Sachs 
Kraft Foods 
Hcwlett-Packard 
Charles Schwab 
UnitedHealthcare 
Fannie Mae 
America Online 
OppenheimerFunds 
Banana Republic 
General Motors 
McCann-Erickson 
Warnaco 
Rainwater Inc. 
Golden West 
Sony M u w  
Bain & Co. 
J. Walter Thompson 
Fidelity Investments 
CEO 
CFO 
Managing Director 
CEO 
CEO 
CFO 
CEO 
CEO 
Ex. V.P. 
Ex. V.P. 
Chairman 
Managing Director 
CEO 
COO 
Chairman 
Ex. V.P. 
CEO 
Presidcnt 
COO 
CEO 
Sr. V.P. 
President 
General Manager 
President 
CEO 
Chairman 
Sr. V.P. 
COO 
CEO 
v. P. 
Ex. V.P. 
President 
Managing Director 
Ex. V.P. 
CEO 
CIO 
CEO 
Vice Chairman 
Mar. President 
CEO 
CEO 
v. P, 
Chairman 
Chairman 
President 
Co-CEO 
Ex. V.P. 
Chairman 
Chairman 
v. P. 
Source: Fortune, October 25,1999. 
d. Use a statistical software package to construct a rel- 
2.37 The Superfund Act was passed by Congress to encour- 
ative frequency histogram. What is thc modal age 
age state participation in the implementation of laws 
class? Compare this to the modal age found in part a. 
relating to the release and cleanup of hazardous sub- 
e. Locate the mean and median on the histogram, part d. 
stances. Hazardous waste sites financed by the Superfund 

SECTION 2.4 
N u m e r i c a l  M e a s u r e s  o f  C e n t r a l  T e n d e n c y  
61 - 
Act are called Superfund sites. A total of 395 Superfund 
sites are operated by waste management companies in 
Arkansas (Tabor and Stanwick, Arkansas Bl~siness and 
Economic Review, Summer 1995). The number of these 
Superfund sites in each of Arkansas' 75 counties is 
shown in the table. Numerical descriptive measures for 
the data set are provided in the EXCEL printout. 
Source: Tabor, R.H.. and Stanwick. S.D. "Arkansas: An environmental 
perspective. "Arkansas Business and Economic Krvirw, Vol. 28, No. 2, 
Summer 1995, pp. 22-32 (Table 1). 
EXCEL Output for Exercise 2.37 
SITES 
Range 
48 1 
Mean 
Standard Error 
Median 
Mode 
Standard Deviation 
Sample Variance 
Kurtosis 
Skewness 
5.24 
0.836517879 
3 
2 
7.244457341 
52.48216216 
16 .dl176573 
3.468289878 
Minimum 
Maximum 
Sum 
a. Locate the measures of central tendency on the 
printout and interpret their values. 
b. Note that the data set contains at least one county 
with an unusually large number of Superfund sites. 
Find the largest of these measurements, called an 
outlier. 
c. Delete the outlier, part b, from the data set and re- 
calculate the measures of central tendency. Which 
measure is most affected by the elimination of the 
outlier? 
2-38 Platelet-activating factor (PAF) is a potent chemical 
that occurs in patients suffering from shock, inflamma- 
tion, hypotension. and allergic responses as well as res- 
piratory and cardiovascular disorders. Consequently, 
0 
48 
393 
Count 
drugs that effectively inhibit PAF, keeping it from bind- 
ing to human cells, may be successful in treating these 
disorders. A bioassay was undertaken to investigate the 
potential of 17 traditional Chinese herbal drugs in PAF 
inhibition (H. Guiqui, Progress in Natural Science, June 
1995). The prevention of the PAF binding process, mea- 
sured as a percentage, for each drug is provided in the 
accompanying table. 
75 
DRUGP*E.D*T .......................................................... 
Drug 
PAF Inhibition (%) 
Hai-feng-teng (Fuji) 
Hai-feng-teng (Japan) 
Shan-ju 
Zhang-yiz-hu-jiao 
Shi-nan-teng 
Huang-hua-hu-jiao 
Hua-nan-hu-jiao 
Xiao-yie-pa-ai-xiang 
Mao-ju 
Jia-,ju 
Xie-yie-ju 
Da-yie-ju 
Bian-yie-hu-jiao 
Bi-bo 
Duo-mai-hu-jiao 
Yan-sen 
Jiao-guo-hu-jiao 
Confidence Leve1(95.000%) 
Source: Guiqui, H. "PAF receptor antagonistic 
principles from Chinese traditional drugs." Progress in 
Natural Science, Vol. 5, No. 3, June 1995, p. 301 (Table 1). 
1.639542488 
a. Construct a stem-and-leaf display for the data. 
b. Compute the median inhibition percentage for the 
17 herbal drugs. Interpret the result. 
c. Compute the mean inhibition percentage for the 17 
herbal drugs. Interpret the result. 
d. Compute the mode of the 17 inhibition percentages. 
Interpret the result. 
e. Locate the median, mean, and mode on the stem- 
and-leaf display, part a. Do these measures of central 
tendency appear to locate the center of the data? 
2.39 The salaries of superstar professional athletes receive 
much attcntion in the media. The multimillion-dollar 
long-term contract is now commonplace among this 
elite group. Nevertheless, rarely does a season pass 
without negotiations between one or more of the 
players' associations and team owners for additional 
salary and fringe benefits for all players in their par- 
ticular sports. 
a. If a players' association wanted to support its argu- 
ment for higher "average" salaries, which measure 
of central tendency do you think it should use? 
Why? 

62 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  
b. To refute the argument, which measure of central 
C 
tendency should the owners apply to the players' 
salaries? Why? 
2.40 Major conventions and conferences attract thousands 
of people and pump millions of dollars into the local 
economy of the host city. The decision as to where to 
hold such conferences hinges to a large extent on the 
availability of hotel rooms. The table, extracted from 
The Wall Street Journal (Nov. 17,1995), lists the top ten 
U.S. cities ranked by the number of hotel rooms. 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
City 
No. of Rooms 
No. of Hotels 
Las Vegas 
Orlando 
Los Angeles-Long 
Beach 
Chicago 
Washington, D.C. 
New York City 
Atlanta 
San Diego 
Anaheim-Santa 
Ana 
San Francisco 
Source: Smith Travel Research. September 1995. 
SPSS Output for Exercise 2.41 
Sets o f  D a t a  
- 
a. Find and interpret the median for each of the data sets. 
b. For each city, calculate the ratio of the number of 
rooms to the number of hotels. Then find the average 
number of rooms per hotel in each city. 
c. Re-rank the cities based on your answer to part b. 
2.41 Refer to the Financial Management (Spring 1995) study 
of prepackaged bankruptcy filings, Exercise 2.24 (p. 49). 
Recall that each of 49 firms that negotiated a reorgani- 
zation plan with its creditors prior to filing for bank- 
ruptcy was classified in one of three categories: joint 
exchange offer with prepack, prepack solicitation only. 
and no pre-filing vote held. An SPSS printout of 
descriptive statistics for the length of time in bankrupt- 
cy (months), by category, is shown below. 
a. Locate the measures of central tendency on the 
printout and interpret their values. 
b. Is it reasonable to use a single number (e.g., mean or 
median) to describe the center of the time-in-bank- 
ruptcy distributions? Or should three "centers" be 
calculated, one for each of the three categories of 
prepack firms? Explain. 
2.42 The U.S. Energy Information Association tracks the 
prices of regular unleaded gasoline in the United States 
each year. The table (p. 63) lists the average 1998 prices 
(in cents) in each of a sample of 20 states. 
TIME 
By CATEGORY Joint 
Valid cases: 
11.0 
Missing cases: 
.O 
Percent missing: 
.O 
Mean 
2.6545 
Std Err 
.5185 Min 
1.2000 Skewness 
.7600 
Median 
1.5000 Variance 
2.9567 Max 
5.4000 S E Skew 
.6607 
5% Trim 
2.5828 
Std Dev 
1.7195 Range 
4.2000 Kurtosis 
-1.4183 
IQR 
3.1000 
S E Kurt 
1.2794 
Valid cases: 
11.0 
Missing cases: 
.O 
Percent missing: 
- 0  
Mean 
4.2364 
Std Err 
.7448 Min 
2.4000 
Skewness 
1.8215 
Median 
3.2000 Variance 
6.1025 Max 
10.1000 S E Skew 
.6607 
5% Trim 
4.0126 
Std Dev 
2.4703 Range 
7.7000 Kurtosis 
2.6270 
1 QR 
1.6000 S E Kurt 
1.2794 
.............................................................................. 
TIME 
By CATEGORY Prepack 
Valid cases: 
27.0 
Missing cases: 
.O 
Percent missing: 
.O 
Mean 
1.8185 Std Err 
.I847 Min 
1.0000 Skewness 
1.4539 
Median 
1 .4000 Variance 
.9216 Max 
4.1000 S E Skew 
.4479 
5% Trim 
1.7372 Std Dev 
.9600 Range 
3.1000 Kurtosis 
.9867 
1 QR 
.9000 S E Kurt 
.8721 

a. Calculate the mean, median, and mode of this data set. 
b. Eliminate the highest price from the data set and re- 
peat part a. What effect does dropping this mcasure- 
- 
- 
ment have on the measures of central tendency 
calculated in part a? 
c. Arrange the 20 prices in order from lowest to highest. 
Next, eliminate ihe lowest two prices and the highest 
two prices from the data set and calculate the mean of 
the remaining prices. The result is called a 10% 
trimmed meun, since it is calculated after dropping the 
highest 10% and the lowest 10% of the values in the 
data set. An advantage of the trimmed mean is that it is 
not as sensitive as the arithmetic mean to extreme ob- 
servations in the data set. 
Numerical M e a s u r e s  o f  Variability 
63 - 
GASPRICE.DAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
State 
Price 
Arkansas 
85.2 
Connecticut 
112.2 
Delaware 
94.6 
Hawaii 
117.9 
Louisiana 
85.7 
Maine 
90.1 
Massachusetts 
95.6 
Michigan 
84.4 
Missouri 
85.9 
Nevada 
102.1 
New Hampshire 
96.6 
New Jersey 
81.7 
New York 
96.4 
North Dakota 
90.4 
Oklahoma 
81.4 
Oregon 
100.2 
Pennsylvania 
91.1 
Texas 
83.8 
Wisconsin 
95.6 
Wyoming 
84.4 
Source: Statistical Abstract of the 
United States: 1998. U.S. Energy 
Information Administration, 
Petroleum Marketing Monthly. 
NUMERICAL MEASURES OF VARIABILITY 
Measures of central tendency provide only a partial description of a quantitative 
data set. The description is incomplete without a measure of the variability, or 
spread, of the data set. Knowledge of the data's variability along with its center 
can help us visualize the shape of a data set as well as its extreme values. 
For example, suppose we are comparing the profit margin per construction 
job (as a percentage of the total bid price) for 100 construction jobs for each of 
two cost estimators working for a large construction company.The histograms for 
the two sets of 100 profit margin measurements are shown in Figure 2.17. If you 
examine the two histograms, you will notice that both data sets are symmetric with 
equal modes, medians, and means. However, cost estimator A (Figure 2.17a) has 
profit margins spread with almost equal relative frequency over the measure- 
ment classes, while cost estimator B (Figure 2.17b) has profit margins clustered 
about the center of the distribution. Thus, estimator B's profit margins are less 
variable than estimator A's. Consequently, you can see that we need a measure of 
variability as well as a measure of central tendency to describe a data set. 
Perhaps the simplest measure of the variability of a quantitative data set is 
its range. 
EFI 
The range of a quantitative data set is equal to the largest measuremen 
minus the smallest measurement. 
The range is easy to compute and easy to understand, but it is a rather in- 
sensitive measure of data variation when the data sets are large. This is because 

64 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of Data 
c FIGURE 2.17 
4 
t 
Profit margin histograms for 
two cost estimators 
60 
60 
9" 
0" 
0- 45 
* 
3 45 
0 
8 
C 
9 
13 
g 30 
5 30 
z 
z 
15 
15 
-10 
0 
10 
20 
30 
40 
-10 
0 
10 
20 
30 
40 
Profit (%) 
Profit (%) 
a. Cost estimator A 
b. Cost estimator B 
two data sets can have the same range and be vastly different with respect to data 
variation. This phenomenon is demonstrated in Figure 2.17. Although the ranges 
are equal and all central tendency measures are the same for these two symmet- 
ric data sets, there is an obvious difference between the two sets of measure- 
ments. The difference is that estimator B's profit margins tend to be more 
stable-that 
is, to pile up or to cluster about the center of the data set. In contrast, 
estimator A's profit margins are more spread out over the range, indicating a 
higher incidence of some high profit margins, but also a greater risk of losses. 
Thus, even though the ranges are equal, the profit margin record of estimator A is 
more variable than that of estimator B, indicating a distinct difference in their cost 
estimating characteristics. 
Let's see if we can find a measure of data variation that is more sensitive 
than the range. Consider the two samples in Table 2.7: Each has five measure- 
ments. (We have ordered the numbers for convenience.) 
TABLE 
2.7 
Two Hypothetical Data Sets 
Sample 1 
Sample 2 
Measurements 
1,2,3,4,5 
2,3,3,3,4 
- 1 + 2 + 3 + 4 + 5  
15 
- 
- - 
= 3  
- 2 + 3 + 3 + 3 + 4  
15 
Mean 
x = 
x = 
- 
- - 
= 3  
5 
5 
5 
5 
Deviations of measure- 
(1 - 3), (2 - 3), (3 - 3), (4 - 3), 
(2 - 3), (3 - 3), (3 - 3), (3 - 3), 
ment values from i 
(5 - 3), or -2, -I,(), 1,2 
(4 - 3), or -1,0,0,0,1 
Note that both samples have a mean of 3 and that we have also calculated 
the distance and direction, or deviation, between each measurement and the 
mean. What information do these deviations contain? If they tend to be large in 
magnitude, as in sample 1, the data are spread out, or highly variable. If the de- 
viations are mostly small, as in sample 2, the data are clustered around the mean, 
- 
x, and therefore do not exhibit much variability. You can see that these devia- 
tions, displayed graphically in Figure 2.18, provide information about the vari- 
ability of the sample measurements. 

- 
SECTION 2.5 
N u m e r i c a l  Measures o f  V a r i a b i l i t y  
65 
FIGURE 2.18 
- 
x . 
Dot plots for two data 
x - 
. 
sets 
. . . . . 
. . .  
I 
I 
I 
I 
I 
I
*
X
 
I 
I 
I 
I 
I 
I
*
X
 
0
1
2
3
4
5
 
0
1
2
3
4
5
 
a. Sample 1 
b. Sample 2
 
The next step is to condense the information in these deviations into a single 
4 
numerical measure of variability. Averaging the deviations from i won't help be- 
cause the negative and positive deviations cancel; that is, the sum of the deviations 
(and thus the average deviation) is always equal to zero. 
Two methods come to mind for dealing with the fact that positive and nega- 
tive deviations from the mean cancel. The first is to treat all the deviations as 
- though they were positive, ignoring the sign of the negative deviations. We won't 
pursue this line of thought because the resulting measure of variability (the mean 
of the absolute values of the deviations) presents analytical difficulties beyond the 
scope of this text. A second method of eliminating the minus signs associated 
with the deviations is to square them. The quantity we can calculate from the 
squared deviations will provide a meaningful description of the variability of a 
data set and presents fewer analytical difficulties in inference-making. 
To use the squared deviations calculated from a data set, we first calculate 
the sample variance. 
DEFINITION 2.8 
I
The sample variance for a sample of n measurements is equal to the sum of 
the squared deviations from the mean divided by (n - 1). In symbols, using s2 
to represent the sample variance, 
5 
(x, - 
2 - i=l 
S - 
n - 1  
Note: A shortcut formula for calculating s2 is 
n - l  
Referring to the two samples in Table 2.7, you can calculate the variance for 
sample 1 as follows: 
The second step in finding a meaningful measure of data variability is to cal- 
culate the standard deviation of the data set. 

66 
CHAPTER 2 
M e t h o d s  for Describing Sets of Data 
The sample standard deviation, s, is defined as the positive square root of the 
sample variance, s2. Thus, s = G. 
The population variance, denoted by the symbol a2 (sigma squared), is the 
average of the squared distances of the measurements on all units in the popula- 
tion from the mean, p, and a (sigma) is the square root of this quantity. Since we 
never really compute a2 or a from the population (the object of sampling is to 
7 
avoid this costly procedure), we simply denote these two quantities by their re- 
spective symbols. 
Notice that, unlike the variance, the standard deviation is expressed in the 
original units of measurement. For example, if the original measurements are in 
dollars, the variance is expressed in the peculiar units "dollar squared," but the 
standard deviation is expressed in dollars. 
You may wonder why we use the divisor (n - 1) instead of n when calculat- 
ing the sample variance. Wouldn't using n be more logical, so that the sample 
variance would be the average squared deviation from the mean? The trouble is, 
. 
using n tends to produce an underestimate of the population variance, a2. So we 
use (n - 1) in the denominator to provide the appropriate correction for this ten- 
dency.* Since sample statistics like s2 are primarily used to estimate population 
parameters like a2, (n - 1 )  is preferred to n when defining the sample variance. 
Calculate the variance and standard deviation of the following sample: 2,3,3,3,4. 
S o l u t i o n  As the number of measurements increases, calculating s2 and s becomes very 
tedious. Fortunately, as we show in Example 2.10, we can use a statistical software 
package (or calculator) to find these values. If you must calculate these quantities 
by hand, it is advantageous to use the shortcut formula provided in Definition 2.8. 
To do this, we need two summations: Ex and Ex2. These can easily be obtained 
from the following type of tabulation: 
*"Appropriaten here means that s2 with the divisor of (n - 1) is an unbiased estimator of 0'. We 
define and discuss "unbiasedness" of estimators in Chapter 4. 
-. 

SECTION 2.5 
N u m e r i c a l  Measures o f  V a r i a b i l i t y  
67 - 
Then we use* 
Use the computer to find the sample variance s2 and the sample standard 
deviation s for the 50 companies' percentages of revenues spent on R&D. 
S o l u t i o n  
FIGURE 2.19 
SAS printout of numerical 
descriptive measures for 50 
R&D percentages 
The SAS printout describing the R&D percentage data is displayed in Figure 2.19. 
The variance and standard deviation, highlighted on the printout, are: 
s2 = 3.922792 and s = 1.980604. 
* 
UNIVARIATE PROCEDURE 
Moments 
N 
50 Sum Wgts 
50 
Mean 
.492 Sum 
Std 
0604 Varia 
Skewness 
0.854601 Kurto 
USS 
3797.92 CSS 
192.2168 
CV 
23.32317 Std Mean 
0.2801 
T:Mean=O 
30.31778 Prob> T 
0.0001 
Sgn Rank 
637.5 Prob> I S 1 
0.0001 
Num "= 0 
5 0 
Quantiles(Def=5) 
100% Max 
13.5 
99% 
13.5 
75% Q3 
9.6 
9 5% 
13.2 
50% Med 
8.05 
9 0% 
11.2 
25% Q1 
7.1 
10% 
6.5 
0% Min 
5.2 
5% 
5.9 
1% 
5.2 
Range 
8.3 
Q3-Ql 
2.5 
Mode 
6.5 
You now know that the standard deviation measures the variability of a set 
of data and how to calculate it. But how can we interpret and use the standard de- 
viation? This is the topic of Section 2.6. 
*When calculating sZ, how many decimal places should you carry? Although there are no rules for 
the rounding procedure, it's reasonable to retain twice as many decimal places in s2 as you 
ultimately wish to have ins. If you wish to calculates to the nearest hundredth (two decimal 
places), for example, you should calculate s2 to the nearest ten-thousandth (four decimal places). 

68 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
Learning the Mechanics 
2.43 Answer the following questions about variability of 
data sets: 
a. What is the primary disadvantage of using the range 
to compare the variability of data sets? 
b. Describe the sample variance using words rather 
than a formula. Do the same with the population 
variance. 
c. Can the variance of a data set ever be negative? Ex- 
plain. Can the variance ever be smaller than the stan- 
dard deviation? Explain. 
2.44 Calculate the variance and standard deviation for sam- 
ples where 
a. n = 10, Ex2 = 84, Ex = 20 
I 
b. n = 40, Ex2 = 380, Ex = 100 
c. n = 20, Ex2 = 18, Zx = 17 
2.45 Calculate the range, variance, and standard deviation 
for the following samples: 
a. 4,2,1,0,1 
b. 1,6,2,2,3,0,3 
C. 8,-2,1,3,5,4,4,1,3,3 
d.0,2,0,0,-1,1,-2,1,0,-1,L,-L,0,-3,-2,-1, 
0 , l  
, 
2.46 Calculate the range, variance, and standard deviation 
for the following samples: 
a. 39,42,40,37,41 
b. 100,4,7,96,80,3,1,10,2 
c. 100,4,7,30,80,30,42,2 
2.47 Compute T, s2, and s for each of the following data sets. 
I f  appropriate, specify the units in which your answer is 
expressed. 
a. 3,1,10,10,4 b. 8 feet, 10 feet, 32 feet, 5 feet 
c. -1, -4, -3,1, -4, -4 
d. 1/5 ounce, '/5 ounce, 'h ounce, % ounce, % ounce, % 
ounce 
2.48 Consider the following sample of five measurements: 2, 
1,L 0,3 
a. Calculate the range, s2, and s. 
b. Add 3 to each measurement and repeat part a. 
c. Subtract 4 from each measurement and repeat part a 
Buick 
Price 
............................................................. 
Century Custom 
$19,335 
Century Limited 
20,705 
Regal LS 
22,255 
Regal GS 
24,955 
LeSabre Custom 
23,340 
LeSabre Limited 
26,605 
Park Avenue 
3 1,800 
Park Avenue Ultra 
36,695 
Riviera 
34,490 
d. Considering your answers to parts a, b, and c, what 
seems to be the effect on the variability of a data set 
by adding the same number to or subtracting the 
same number from each measurement? 
Applying the Concepts 
2.49 The lable at the bottom of the page lists the 1999 base 
prices for automobiles manufactured by Buick and 
Cadillac. 
a. Calculate the range of the Buick prices and the range 
of the Cadillac prices. 
b. The lowest and highest priced Chevrolet cars are 
$9,373 (Metro) and $45,575 (Corvette), respectively. 
Calculate Chevrolet's range. 
c. Using only the three ranges you computed in parts a 
and b and no other information, is it possible to de- 
termine which manufacturer produces only luxury 
cars? Explain. 
2.50 Refer to Exercise 2.35 (p. 59). The total number of 
passengcrs handled in 1998 by eight Port Canaveral 
(Florida) cruise ships are reproduced in the next 
table. 
a. Find the range of the data. 
b. Find the variance of the data. 
Cruise Line (Ship) 
Number of Passengers 
..................................................................................................................... 
Canaveral (Dolphin) 
152,240 
Carnival (Fantasy) 
480,924 
Disncy (Magic) 
73,504 
Premier (Oceanic) 
270,361 
Royal Caribbean (Nordic Empress) 
106,161 
Sun Cruz Casinos 
453,806 
Sterling Cruises (New Yorker) 
15,782 
Topaz Int'l. shipping (Topaz) 
28,280 
Source: Florida Trend, Vol. 41, No. 9, Jan. 1999. 
Cadillac 
Price 
Catera 
DeVille 
DeVille D'Elegance 
DeVille Concours 
Eldorado 
Eldorado Touring 
Seville SLS 
Seville STS 
Source: Automotive News, Nov. 30,1998. 

c. Find the standard deviation of the data. 
d. Suppose the standard deviation of the number of 
passengers handled by cruise ships in another Flori- 
da city is 209,000. For which of the two cities is the 
cruise ship passenger data more variable? 
2.51 The Consumer Price Index (CPI) measures the price 
change of a constant market basket of goods and ser- 
vices.The Bureau of Labor Statistics publishes a nation- 
al CPI (called the US. City Average Index) as well as 
separate indexes for each of 32 different cities in the 
United States. The CPI is used in cost-of-living escalator 
clauses of many labor contracts to adjust wages for 
inflation (Bureau of Labor Statistics Handbook of 
Methods, 1992). The table below lists the published 
values of the U.S. City Average Index and the Chicago 
Index during 1994 and 1995. 
CITYCPI.DAT 
..................................................................................................................... 
Month 
US. City Average Index 
Chicago 
..................................................................................................................... 
January 1994 
146.2 
146.5 
February 
146.7 
146.8 
March 
147.2 
147.6 
April 
' 
147.4 
147.9 
May 
147.5 
147.6 
June 
148.0 
148.1 
July 
148.4 
148.3 
August 
149.0 
149.8 
September 
149.4 
150.2 
October 
149.5 
149.4 
November 
149.7 
150.4 
December 
149.7 
150.5 
January 1995 
150.3 
151.8 
February 
150.9 
152.3 
March 
151.4 
152.6 
April 
151.9 
153.1 
May 
152.2 
153.0 
June 
152.5 
153.5 
July 
152.5 
153.6 
August 
152.9 
153.8 
September 
153.2 
154.0 
October 
153.7 
154.3 
November 
153.6 
154.0 
Deccmber 
153.5 
153.8 
Source CPI Detailed Report, Bureau of Labor Statistics, 
Jan 1994-Dec 1995 
a. Calculate the mean values for the U.S. City Average 
Index and the Chicago Index. 
b. Find the ranges of the U.S. City Average Index and 
the Chicago Index. 
c. Calculate the standard deviation for both the U.S. 
City Average Index and the Chicago Index over the 
time period described in the table. 
d. Which index displays greater variation about its 
mean over the time period in question? Justify your 
response. 
N u m e r i c a l  Measures o f  V a r i a b i l i t y  
69 
2.52 A widely used technique for estimating the length of 
time it takes workers lo produce a product is the time 
study. In a time study, the task to be studied is divided 
into measurable parts and each is timed with a stop- 
watch or filmed for later analysis. For each worker, this 
process is repeated many times for each subtask. Then 
the average and standard deviation of the time required 
to complete each subtask are computed for each 
worker. A worker's overall time to complete the task 
under study is then determined by adding his or her 
subtask-time averages (Gaither, Production and 
Operations Management, 1996). The data (in minutes) 
given in the table are the result of a time study of a pro- 
duction operation involving two subtasks. 
a. Find the overall time it took each worker to com- 
plete the manufacturing operation under study. 
b. For each worker, find the standard deviation of the 
seven times for subtask 1. 
c. In the context of this problem, what are the standard 
deviations you computed in part b measuring? 
d. Repeat part b for subtask 2. 
e. If you could choose workers similar to A or workers 
similar to B to perform subtasks 1 and 2, which type 
would you assign to each subtask? Explain your de- 
cisions on the basis of your answers to parts a-d. 
2.53 The table lists the 1995 profits (in millions of dollars) 
for a sample of seven airlines. 
Worker A 
Repetition 
Subtask 1 
Subtask 2 
AIRLINES.DAT 
................................................ 
Airline 
Profit 
................................................ 
Southwest 
182.6 
Continental 
226.0 
Northwest 
342.1 
Delta 
510.0 
US. Air 
119.3 
United 
378.0 
America West 
54.8 
Worker B 
...................................................................................... 
Subtask 1 
Subtask 2 
Source: "Business Week 
1000." Business Week, March 
25,1996, p. 90. 
a. Calculate the range, variance, and standard devia- 
tion of the data set. 

70 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
b. Specify the units in which each of your answers to 
set increase or decrease? Why? Would the standard 
part a is expressed. 
deviation of the data set increase or decrease? Why? 
c. Suppose America West had a loss of $50 instead of a 
profit of $54.8 million. Would the range of the data 
INTERPRETING THE STANDARD DEVIATION 
We've seen that if we are comparing the variability of two samples selected from 
a population, the sample with the larger standard deviation is the more variable of 
the two. Thus, we know how to interpret the standard deviation on a relative or 
comparative basis, but we haven't explained how it provides a measure of vari- 
ability for a single sample. 
To understand how the standard deviation provides a measure of variability 
of a data set, consider a specific data set and answer the following questions: How 
many measurements are within 1 standard deviation of the mean? How many 
measurements are within 2 standard deviations? For a specific data set, we can an- 
swer these questions by counting the number of measurements in each of the in- 
tervals. However, if we are interested in obtaining a general answer to these 
questions, the problem is more difficult. 
Tables 2.8 and 2.9 give two sets of answers to the questions of how many 
measurements fall within 1,2, and 3 standard deviations of the mean. The first, 
which applies to any set of data, is derived from a theorem proved by the Russian 
mathematician F! L. Chebyshev (1821-1894). The second, which applies to mound- 
shaped, symmetric distributions of data (where the mean, median, and mode are 
all about the same), is based upon empirical evidence that has accumulated over 
the years. However, the percentages given for the intervals in Table 2.9 provide re- 
markably good approximations even when the distribution of the data is slightly 
skewed or asymmetric. Note that both rules apply to either population data sets or 
sample data sets. 
TABLE 
2.8 
Interpreting the Standard Deviation: Chebyshev's Rule 
a. No useful infor 
ction of measurements 
of the mean, i.e., within the interval (2 - 3s, ? -!- 3s) for samples a 
(T, - 3a, p t- 3a) for populations. 
d. Generally, for any number k greater than 1, at least (1 - 1/k2) of t 
measurements will fall within k standard deviations of the mean, 
within the interval (? - ks, 2 + ks) for samples and (p - k q  T, + 

SECTION 2.6 
I n t e r p r e t i n g  t h e  S t a n d a r d  Deviation 
71 - 
TABLE 
2.9 
lnterpreting the Standard Deviation: The Empirical Rule 
1 fall within 2 standar 
deviations of the mean, i.e., within the interval (i - 2s, i + 2s) f 
samples and (p - 2a, p + 2a) for populations. 
c. Approximately 99.7% (essentially all) of the measurements will 
within 3 standard deviations of the mean, i.e., within the inter 
(X - 3s, X + 3s 
- 3a, p + f a )  for population 
The 50 companies' percentages of revenues spent on R&D are repeated in Tablc 2.10. 
TABLE 
2.10 
R&D Percentages for 50 Companies 
13.5 
9.5 
8.2 
6.5 
8.4 
8.1 
6.9 
7.5 
10.5 
13.5 
7.2 
7.1 
9.0 
9.9 
8.2 
13.2 
9.2 
6.9 
9.6 
7.7 
9.7 
7.5 
7.2 
5.9 
6.6 
11.1 
8.8 
5.2 
10.6 
8.2 
11.3 
5.6 
10.1 
8.0 
8.5 
11.7 
7.1 
7.7 
9.4 
6.0 
8.0 
7.4 
10.5 
7.8 
7.9 
6.5 
6.9 
6.5 
6.8 
9.5 
We have previously shown (see Figure 2.13, p. 53) that the mean and stan- 
dard deviation of these data (rounded) are 8.49 and 1.98, respectively. Calculate 
the fraction of these measurements that lie within the intervals x & s, x rt 2s, 
and i & 3s, and compare the results with those predicted in Tables 2.8 and 2.9. 
S o I u t i o n We first form the interval 
A check of the measurements reveals that 34 of the 50 measurements, or 68%, are 
within 1 standard deviation of the mean. 
The next interval of interest 
contains 47 of the 50 measurements, or 94%. 
Finally, the 3-standard-deviation interval around T, 
contains all, or 100%, of the measurements. 

72 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of Data 
In spite of the fact that the distribution of these data is skewed to the right 
(see Figure 2.8, page 38), the percentages within 1,2, and 3 standard deviations 
(68%, 94%, and 100%) agree very well with the approximations of 68%, 95 %, and 
99.7% given by the Empirical Rule (Table 2.9). You will find that unless the dis- 
tribution is extremely skewed, the mound-shaped approximations will be reason- 
ably accurate. Of course, no matter what the shape of the distribution, 
Chebyshev's Rule (Table 2.8) assures that at least 75% and at least 89% (%) of 
the measurements will lie within 2 and 3 standard deviations of the mean, 
respectively. 
"-- 
, , 
*,....-, 
Chehyshev'~ Rule and the Empirical Rule are useful as a check on the calculation 
of the standard deviation. For example, suppose we calculated the standard 
deviation for the R&D percentages (Table 2.10) to be 3.92.Are there any "clues" 
in the data that enable us to judge whether this number is reasonable? 
S o l u t i o n  
FIGURE 2.20 
The relation between the range 
and the standard deviation 
The range of the R&D percentages in Table 2.10 is 13.5 - 5.2 = 8.3. From 
Chebyshev's Rule and the Empirical Rule we know that most of the 
measurements (approximately 95% if the distribution is mound-shaped) will be 
within 2 standard deviations of the mean. And, regardless of the shape of the 
distribution and the number of measurements, almost all of them will fall within 3 
standard deviations of the mean. Consequently, we would expect the range of 
the measurements to be between 4 (i.e., rt 2s) and 6 (i.e., f 3s) standard 
deviations in length (see Figure 2.20). 
For the R&D data, this means that s should fall between 
Range 
8.3 
- 
Range 
8.3 
- 
6 
6 
4 
4 
=1.38 
and 
- 2.08 
In particular, the standard deviation should not be much larger than '/4 of 
the range, particularly for the data set with 50 measurements. Thus, we have rea- 
son to believe that the calculation of 3.92 is too 1arge.A check of our work reveals 
that 3.92 is the variance s2, not the standard deviation s (see Example 2.10). We 
"forgot" to take the square root (a common error); the correct value is s = 1.98. 
Note that this value is between '1, and 7, of the range. 
In examples and exercises we'll sometimes use s = range14 to obtain a 
crude, and usually conservatively large, approximation for s. However, we stress 
that this is no substitute for calculating the exact value of s when possible. 
Finally, and most importantly, we will use the concepts in Chebyshev's Rule 
and the Empirical Rule to build the foundation for statistical inference-making. 
The method is illustrated in Example 2.13. 
its grade A battery is 60 months. However, the guarantee on this brand is for just 
36 months. Suppose the standard deviation of the life length is known to be 
10 months, and the frequency distribution of the life-length data is known to be 
mound-shaped. 
a. Approximately what percentage of the manufacturer's grade A batteries 
will last more than 50 months, assuming the manufacturer's claim is true? 

SECTION 
2.6 
I n t e r p r e t i n g  t h e  S t a n d a r d  D e v i a t i o n  
73 - 
b. Approximately what percentage of the manufacturer's batteries will last 
less than 40 months, assuming the manufacturer's claim is true? 
c. 
Suppose your battery lasts 37 months. What could you infer about the man- 
ufacturer's claim? 
S 0 I u t i o n If the distribution of life length is assumed to be mound-shaped with a mean of 
60 months and a standard deviation of 10 months, it would appear as shown in 
Figure 2.21. Note that we can take advantage of the fact that mound-shaped 
distributions are (approximately) symmetric about the mean, so that the 
percentages given by the Empirical Rule can be split equally between the halves of 
the distribution on each side of the mean.The approximations given in Figure 2.21 
are more dependent on the assumption of a mound-shaped distribution than those 
given by the Empirical Rule (Tablc 2.9), because the approximations in Figure 2.21 
depend on the (approximate) symmetry of the mound-shaped distribution. We 
saw in Example 2.11 that the Empirical Rule can yield good approximations even 
for skewed distributions. This will not be true of the approximations in Figure 2.21; 
the distribution must be mound-shaped and approximately symmetric. 
FIGURE 2.21 
Battery life-length 
distribution: 
Manufacturer's claim 
assumed true 
p - 2 0  
-
0
 
p 
0 
p + 2 0  
40 
50 
60 
70 
80 
Life length (months) 
For example, since approximately 68% of the measurements will fall within 
1 standard deviation of the mean, the distribution's symmetry implies that ap- 
proximately {,(68%) = 34% of the measurements will fall between the mean 
and 1 standard deviation on each side. This concept is illustrated in Figure 2.21. 
The figure also shows that 2.5% of the measurements lie beyond 2 standard devi- 
ations in each direction from the mean. This result follows from the fact that if ap- 
proximately 95% of the measurements fall within 2 standard deviations of the 
mean, then about 5% fall outside 2 standard deviations; if the distribution is ap- 
proximately symmetric, then about 2.5% of the measurements fall beyond 2 stan- 
dard deviations on each side of the mean. 
a. It is easy to see in Figure 2.21 that the percentage of batteries lasting more 
than 50 months is approximately 34% (between 50 and 60 months) plus 
50% (greater than 60 months). Thus, approximately 84% of the batteries 
should have life length exceeding 50 months. 
b. The percentage of batteries that last less than 40 months can also be easily 
determined from Figure 2.21. Approximately 2.5% of the batteries should 
fail prior to 40 months, assuming the manufacturer's claim is true. 
c. If you are so unfortunate that your grade A battery fails at 37 months, you 
can make one of two inferences: either your battery was one of the approx- 
imately 2.5% that fail prior to 40 months, or something about the manufac- 
turer's claim is not true. Because thc chances are so small that a battery fails 

74 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  o f  D a t a  
- 
before 40 months, you would have good reason to have serious doubts about 
the manufacturer's claim. A mean smaller than 60 months andlor a standard 
deviation longer than 10 months would both increase the likelihood of fail- 
ure prior to 40 months." 
r)r 
Example 2.13 is our initial demonstration of the statistical inference-making 
process. At this point you should realize that we'll use sample information (in Ex- 
ample 2.13, your battery's failure at 37 months) to make inferences about the 
population (in Example 2.13, the manufacturer's claim about the life length for 
the population of all batteries). We'll build on this foundation as we proceed. 
*The assumption that the distribution is mound-5haped and symmetric may also be incorrect. 
However, ~f the distr~but~on 
were skewed to thc nght, as hte-length d~stributions often tend to be, 
the percentage of meawrements more than 2 standard deviations below the mean would be even 
- 
less than 2.5%. 
Learning the Mechanics 
2.54 For any set of data, what can be said about the percent- 
age of the measurements contained in each of the fol- 
lowing intervals? 
a. T - s t o T + s  
b. Z - 2 s t o % + Z s  
c. x - 3s to x: f 3s 
255 For a set of data with a mound-shaped relative frequen- 
cy distribution, what can be said about the percentage 
of the measurements contained in each of' the intervals 
specified in Exercise 2.54? 
2.56 Given a data set with a largest value of 760 and a small- 
est value of 135, what would you estimate the standard 
deviation to be? Explain the logic behind the procedure 
you used to estimate the standard deviation. Suppose 
the standard deviation is reported to be 25. Is this feasi- 
ble? Explain. 
2.57 The following is a sample of 25 measurements: 
a. Compute T, s2, and s for this sample. 
b. Count the number of measurements in the intervals 
- 
x & s,T f 2s, T & 3s. Express each count as a per- 
centage of the total number of measurements. 
MINITAB Output for Exercise 2.58 
c. Compare the percentages found in part b to the per- 
centages given by the Empirical Rule and Cheby- 
shev's Rule. 
d. Calculatc lhe range and use it to obtain a rough ap- 
proximation for s. Does the result compare favor- 
ably with the actual value for s found in part a? 
Applying the Concepts 
2.58 To minimize the potential for gastrointestinal disease 
outbreaks, all passenger cruise ships arriving at U.S. 
ports are subject to unannounced sanitation inspec- 
tions. Ships are rated on a 100-point scale by the 
Centers for Disease Control. A score of 86 or higher 
indicates that the ship is providing an accepted stan- 
dard of sanitation. The January 1999 sanitation scores 
for 121 cruise ships are listed in the table on p. 75. A 
MINITAB printout of descriptive statistics for the data 
is shown below. 
a. Locate the mean and standard deviation on the 
MINITAB printout. 
b. Calculate the intervals T f s, 2 f 2s, and 2 f 3s. 
c. Find the percentage of mcasurements in the data set 
that fall within each of the intervals, part b. Do these i 
percentages agree with either Chebyshev's Rule or the 
Empirical Rule'? 
2.59 In the spring of 1998, the New Jersey State Chamber of 
Commcrce and Rutgers Business School-with 
spon- 
sorship by Arthur Andersen-conducted 
a survey to 
Descriptive Statistics 
1 
Variable 
N 
Mean 
Median 
Tr Mean 
StDev 
SE Mean 
Sanlevel 
121 
90.339 
92.000 
91.138 
6.947 
0.632 
Variable 
Min 
Max 
Q 1 
Q3 
Sanlevel 
36.000 
99.000 
88.000 
94.000 

SECTION 2.6 
I n t e r p r e t i n g  t h e  S t a n d a r d  D e v i a t i o n  
Ship 
Score 
Americana 
Arcadia 
Arkona 
Astor 
Asuka 
Blackwatch 
C. Columbus 
Carnival Dectmy 
Celebration 
Century 
Clipper Adventurer 
Club Med I 
Contessa I 
Costa Rornantica 
Costa Victoria 
Crown Princess 
Crystal Harmony 
Crystal Symphony 
Dawn Princess 
Delphin 
Destiny 
Discovery Sun 
Disney Magic 
Dolphin 1V 
Dreamward 
Ecstasy 
Edinburgh Castle 
Elation 
Emerald 
Enchanted Capri 
Enchanted Isle 
Enchantment of the Seas 
Europa 
Fantasy 
Fascination 
Flamenco 
Galaxy 
Grand Princess 
Grande Caribe 
Grande Mariner 
Grandeur of the Seas 
Ship 
............................................ 
Hanseatic 
Holiday 
Horizon 
Imagination 
Inspiration 
Island Adventure 
Island Dawn 
Island Princess 
Islandbreeze 
Jubilee 
Leeward 
Legacy 
Legend of the Seas 
Maasdam 
Majesty of the Seas 
Maxim Gorky 
Mayan Prince 
Melody 
Mercury 
Monarch of the Seas 
Nantucket Clipper 
Nieuw Amsterdam 
Nippon Maru 
Noordam 
Nordic Princess 
Norway 
Norwegian Crown 
Norwegian Dynasty 
Norwegian Majesty 
Norwegian Sea 
Norwegian Star 
Norwegian Wind 
Oceanbreeze 
Oriana 
Palm Beach Princess 
Paradise 
Paul Gauguin 
Queen Elizabeth 2 
Radisson Diamond 
Regal Empress 
Regal Princess 
........... 
Score 
........... 
93 
93 
94 
91 
91 
95 
86 
88 
94 
93 
92 
86 
99 
96 
93 
81 
94 
91 
97 
96 
89 
86 
36 
93 
93 
88 
90 
95 
91 
91 
78 
95 
87 
98 
88 
95 
86 
87 
90 
95 
95 
Ship 
Score 
............................................................... 
Regal Voyager 
Rembrandt 
Rhapsody of the Seas 
Rotterdam VI 
Royal Princess 
Royal Viking Sun 
Ryndam 
Sea Bird 
Sea Goddess I 
Sea Goddess I1 
Sea Lion 
Seabourn Legend 
Seabourn Pride 
Seabreeze I 
Sensation 
Silver Cloud 
Sky Princess 
Song of America 
Sovereign of the Seas 
Spirit of Columbia 
Splendour of the Seas 
Starship Oceanic 
Statendam 
Stella Solaris 
Sun Princess 
Superstar Capricorn 
Topaz 
Tropicale 
Universe Explorer 
Veendam 
Victoria 
Viking Serenade 
Vision of the Seas 
Vistafjord 
Westerdam 
Wind Spirit I1 
World Discoverer 
Yorktown Clipper 
Zenith 
Source. Center for Environmental Health and Injury Control; Tampa Tribune, Feb. 7,1999. 
investigate Generation Xers' expectations of the future 
s = 10.64 
workplace and their careers.Telephone interviews were 
conducted with 662 randomly selected New Jerseyans 
min = 2.0 
between the ages of 21 and 28. One question asked: 
max = 50 
"What is the maximum number of vears vou exvect to 
spend with any one employer over the course of your 
Sources: N.J. State Chamber of Commerce,press release, June 18, 
career?"The 590 useable responses to this question are 
1998 and personal communication from P. George Benson. 
summarlzed as follows: 
a. What evidence exists to suggest that the distribution 
of years is not mound-shaped? 
n = 590 
- 
x = 18.2 years 
median = 15 years 
b. suppose you did not know the sample standard de- 
viation, s. Use the range of the data set to estimate s. 
Compare your estimate to the actual sample stan- 
dard deviation. 
-. 

76 
C H A P T E R  2 M e t h o d s  f o r  D e s c r i b i n g  S e t s  o f  D a t a  
c. In the last decade, workers moved between compa- 
nies much more frequently than in the 1980s. Conse- 
quently, the researchers were surprised by the 
expectations of longevity expressed by the Genera- 
tion Xers. What can you say about the percentage of 
Generation Xers in the sample whose response was 
40 years or more? 8 years or more? 
2.60 As a result of government and consumer pressure, auto- 
mobile manufacturers in the United States are deeply 
involved in research to improve their products' gaso- 
line mileage. One manufacturer, hoping to achieve 
40 miles per gallon on one of its compact models, mea- 
sured the mileage obtained by 36 test versions of the 
model with the following results (rounded to the near- 
est mile for convenience): 
b. Descriptive statistics for the 50 spillage amounts 
are provided in the SPSS printout. Use this infor- 
mation to form an interval that can be used to pre- 
dict the spillage amount for the next major oil spill. 
2.62 Refer to the Arkunsas Business and Economic Review 
(Summer 1995) study of the number of Superfund 
hazardous waste sites in Arkansas counties, 
Excrcisc 2.37 (p. 60). The EXCEL numerical descrip- 
tive statistics printout is reproduced here and the data 
are listed on page 78. Calculate the percentage of mea- 
surements in the intervals F f s, T i 2s, and i f 3s. 
Check the agreement of thesc percentages with both 
Chebyshev's Rule and the Empirical Rule. 
EXCEL Output for Exercise 2.62 
The mean and standard deviation of these data are 
shown in the SAS printout below. 
a. Find the mean and standard deviation on the print- 
out and give the units in which they are expressed. 
b. If the manufacturer would be satisfied with a (popu- 
lation) mean of 40 miles per gallon, how would it 
react to the above test data'? 
c. Use the information in Tables 2.8-2.9 to check the 
reasonableness of the calculated standard deviation 
s = 2.2. 
d. Construct a relative frequency histogram of the data 
set. Is thc data set mound-shaped? 
e. What percentage of the measurements would you 
expect to find within the intervals i f s, T f 2s, 
x i 
3s? 
f. Count the number of measurements that actually fall 
within the intervals of part e. Express each interval 
count as a percentage o f  the total number of niea- 
surements. Compare thesc results with your answers 
to part e. 
2.61 Refer to the Marine Technology (Jan. 1995) data on 
spillage amounts (in thousands of metric tons) for 50 
major oil spills, Exercise 2.10 (p. 34). An SPSS histogram 
for the 50 spillage amounts is shown on p. 77. 
a. Interpret the histogram. 
SAS Output for Exercise 2.60 
SITES 
I 
I 
1 Mean 
1 
5.24 1 
Standard Error 
0.836517879 
Median 
Standard Deviation 
7.244457341 
Sample Variance 
52.48216216 
Kurtosis 
16.41176573 
Skewness 
3.468289878 
I Ranse 
I 
48 1 
Minimum 
0 
Maximum 
48 
Sum 
393 
Count 
75 
Confidence Leve1(95.000%)1 
1.639542488 
2.63 Refer t o  the Financial Management (Spring 1995) 
study of 49 firms filing for prepackaged bankruptcy, 
Exercise 2.24 (p. 49). Recall that the variable of interest 
was length of time (months) in bankruptcy for each firm. 
a. A MINITAB histogram for the 49 bankruptcy times 
is displayed on p. 77. Comment on whether the Em- 
pirical Rule is applicable for describing the bank- 
ruptcy time distribution for firms filing for 
prepackaged bankruptcy. 
b. Numerical descriptive statistics for the data set are 
also shown in the MINITAB printout at the bottom 
of p. 77. Usc this information to construct an interval 
that captures at least 75% of the bankruptcy times 
foi "prepack" firms. 
Analysis Variable : MPG 
1 

A 
SECTION 2.6 
I n t e r p r e t i n g  t h e  S t a n d a r d  D e v i a t i o n  
77 
SPSS Output for Exercise 2.61 
SPILLAGE 
Count Mid~oint 
1 
223 
1 
237 1: 
1 
251 1 
I....+....I....+....I....+....I....+....I....+....I 
0 
4 
8 
12 
16 
2 0 
Histogram frequency 
Variable SPILLAGE 
Mean 
Std Dev 
Kurtosis 
Skewness 
Range 
Maximum 
S.E. Mean 
7.546 
Variance 
2847.457 
S.E. Kurt 
.662 
S.E. Skew 
.337 
Minimum 
21.00 
Sum 
2991.000 
Valid Observations - 
50 
Missing Observations - 
0 
MlNlTAB Output for Exercise 2.63 
Descriptive Statistics 
Variable 
N 
Mean 
Median 
Tr Mean 
StDev 
SE Mean 
Time 
49 
2.549 
1.700 
2.333 
1.828 
0.261 
I 
Variable 
Min 
Max 
Q 1 
Q3 
Time 
1.000 
10.100 
1.350 
3.500 
MlNlTAB Histogram for Exercise 2.63 
20 I 
1
2
3
4
5
6
7
8
9
1
0
 
Time 
c. Refer to the data listed in Exercise 2.24. Count the 
number of the 49 bankruptcy times that fall within 
the interval, part b, and convert the result to a per- 
centage. Does the result agree with Chebyshev's 
Rule? The Empirical Rule? 
d. A firm is considering filing a prepackaged bankrupt- 
cy plan. Estimate the length of time the firm will be 
in bankruptcy. 
2.64 The American Rifleman (June 1993) reported on the 
velocity of ammunition fired from the FEG P9R pistol, a 
9mm gun manufactured in Hungary. Field tests revealed 
that Winchester bullets fired from the pistol had a mean 
velocity (at 15 feet) of 936 feet per second and a stan- 
dard deviation of 10 feet per second. Tests were also con- 
ducted with Uzi and Black Hills ammunition. 

78 
CHAPTER 
2 M e t h o d s  f o r  D e s c r i b i n g  S e t s  o f  D a t a  
a. Describe the velocity distribution of Winchester 
bullets fired from the FEG P9R pistol. 
b. A bullet, brand unknown, is fired from the FEG 
P9R pistol. Suppose the velocity (at 15 feet) of the 
bullet is 1,000 feet per second. Is the bullet likely to 
be manufactured by Winchester? Explain. 
2.65 A buyer for a lumber company must decide whether to 
buy a piece of land containing 5,000 pine trees. If 1,000 
of the trees are at least 40 feet tall, the buyer will pur- 
chase the land; otherwise, he won't. The owner of the 
land reports that the height of the trees has a mean of 
30 feet and a standard deviation of 3 feet. Based on this 
information, what is the buyer's decision? 
2.66 A chemical company produces a substance composed 
of 98% cracked corn particles and 2% zinc phosphide 
for use in controlling rat populations in sugarcane liclds. 
Production must be carefully controlled to maintain the 
2% zinc phosphide because too much zinc phosphide 
will cause damage to the sugarcane and too little will be 
ineffective in controlling the rat population. Records 
from past production indicate that the distribution of 
the actual percentage of zinc phosphide present in the 
substance is approximately mound-shaped, with a mean 
of 2.0% and a standard deviation of .08%. 
a. If the production line is operating correctly, ap- 
proximately what proportion of batches from a 
day's production will contain less than 1.84% of 
zinc phosphide? 
b. Suppose one batch chosen randomly actually con- 
tains 1.80% zinc phosphide. Does this indicate that 
there is too little zinc phosphide in today's produc- 
tion? Explain your reasoning. 
2.67 When it is working properly, a machine that fills 25- 
pound bags of flour dispenses an average of 25 pounds 
per fill; the standard deviation of the amount of fill is 
.1 pound. To monitor the performance of the machine. 
an inspector weighs the contents of a bag coming off 
the machine's conveyor belt every half-hour during the 
day. If the contents of two consecutive bags fall more 
than 2 standard deviations from the mean (using the 
mean and standard deviation given above), the filling 
process is said to be out of control and the machine is 
shut down briefly for adjustments. The data given in 
the table below are the weights measured by the 
inspector yesterday. Assume the machine is never shut 
down for more than 15 minutes at a time. At what 
times yesterday was the process shut down for adjust- 
ment? Justify your answer. 
Time 
Weight 
(pounds) 
Time 
Weight 
(pounds) 
8:00 A.M. 
8:30 
9:OO 
9:30 
1o:oo 
10:30 
11:oo 
11:30 
12:oo 
12:30 P.M. 
1:oo 
1:30 
2:oo 
2:30 
3:OO 
3:30 
4:OO 
4:30 
5:OO 
ARKFUND.DAT 
...................................................................................................................................................................................................................... 
3
3
2
1
2
0
5
3
 5
2
1
8
2
1
2
3
5
 3 
1
3
 
0
8
0
9
6
8
6
2
1
6
0
6
0
5
 5
0
1
2
5
 0
0
 
0 
6 
2 1 0 1 2  
3 1 0  
3 
17 
2 
4 
2 
1
2
1
 4 
2 
1 1 1  5 
2
2
7
2
3
1
8
2
 0
0
0
2
3
1
0
2
3
4
8
2
1
 
Source Tabor, R. H., and Stanwick, S. D. "Arkansas: An environmental perspective." Arkansas Business und Econornlc Revlew, 
Vol. 28, No. 2, Summer 1995, pp 22-32 (Table 1). 
NUMERICAL MEASURES OF RELATIVE STANDING 
We've seen that numerical measures of central tendency and variability describe 
the general nature of a quantitative data set (either a sample or a population). In 
addition, we may be interested in describing the relative quantitative location of a 
particular measurement within a data set. Descriptive measures of the relationship 
of a measurement to the rest of the data are called measures of relative standing. 
One measure of the relative standing of a measurement is its percentile 
ranking. For example, if oil company A reports that its yearly sales are in the 90th 
percentile of all companies in the industry, the implication is that 90% of all oil 
companies have yearly sales less than company A's, and only 10% have yearly 


80 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  . 
FIGURE 2.23 
SAS Descriptive Statistics for 50 
R&D Percentages 
UNIVARIATE PROCEDURE 
Variable=RDPCT 
Moments 
N 
50 Sum Wgts 
50 
Mean 
8.492 Sum 
424.6 
Std Dev 
1.980604 Variance 
3.922792 
Skewness 
0.854601 Kurtosis 
0.419288 
USS 
3797.92 CSS 
192.2168 
CV 
23.32317 Std Mean 
0.2801 
T:Mean=O 
30.31778 
0.0001 
Sgn Rank 
50 
Prob'lTl 
0.0001 
637.5 
Prob> S 
Num "=O 
100% Max 
75% 43 
50% Med 
25% Q1 
0% Min 
Range 
43-Q1 
Mode 
~ x t  
remes 
Lowest 
Obs 
Highest 
Obs 
5.2( 
45) 
11.3( 
34) 
5.6( 
46) 
11.7( 
47) 
5.9( 
44) 
13.2( 
42) 
6 ( 
48) 
13.5( 
1) 
6.5( 
50) 
13.5( 
16) 
DEFINITION 2.1 1 
The sample 2-score for a measurement x is 
The population z-score for a measurement x is 
S o I u t i o n Joe Smith's annual income lies below the mean income of the 200 steelworkers 
(see Figure 2.24). We compute 

FIGURE 2.24 
Annual income of steel workers 
FIGURE 2.25 
Population z-scores for a 
mound-shaped distribution 
Y 
SECTION 2.7 
N u m e r i c a l  Measu'res of Relative S t a n d i n g  
81 
which tells us that Joe Smith's annual income is 1.0 standard deviation below the 
sample mean, or, in short, his sample z-score is -1.0. 
1 
I 
$18,000 
$22,000 
$24,000 
$30,000 
X- 3s 
Joe Smlth's 
P 
K +  3s 
income 
The numerical value of the z-score reflects the relative standing of the 
measurement. A large positive z-score implies that the measurement is larger 
than almost all other measurements, whereas a large negative z-score indicates 
that the measurement is smaller than almost every other measurement. If a z- 
score is 0 or near 0, the measurement is located at or near the mean of the sam- 
ple or population. 
We can be more specific if we know that the frequency distribution of the 
measurements is mound-shaped. In this case, the following interpretation of the z- 
score can be given. 
tions of 
Approximately 68% of the measurements will have a z-score between 
2. Approximately 95% of the measurements will have a z-score between 
3. Approximately 99.7% (almost all) of the measurements will have a 
z-score between -3 and 3. 
Note that this interpretation of z-scores is identical to that given by the Em- 
pirical Rule for mound-shaped distributions (Table 2.9). The statement that a 
measurement falls in the interval ( p  - a) to ( p  + a )  is equivalent to the state- 
ment that a measurement has a population z-score between -1 and 1, since all 
measurements between (p - a) and (p + a )  are within 1 standard deviation of 
p. These z-scores are displayed in Figure 2.25. 
p-30 
p - 2 0  
1-0 
b 
p + 0  
p + 2 0  
p + 3 0  
Measurement scale 
-3 
-2 
- 1 
0 
1 
2 
3 
z-scale 

82 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  o f  D a t a  
Learning the Mechanics 
2.68 Compute the z-score corresponding to each of the fol- 
lowing values of x: 
a. x = 40, s = 5, i = 30 
b. x = 90, p = 89, u = 2 
c. p = 50, a = 5, x = 50 
d. s = 4, x = 20, T = 30 
e. In parts a-d, state whether the z-score locates x with- 
in a sample or a population. 
f. In parts a-d, state whether each value of x lies above 
or below the mean and by how many standard 
deviations. 
2.69 Give the percentage of measurements in a data set that 
are above and below each of the following percentiles: 
a. 75th percentile 
b. 50th percentile 
c. 20th percentile 
d. 84th percentile 
2.70 What is the 50th percentile of a quantitative data set 
called? 
2.71 Compare the z-scores to decide which of the following x 
values lie the greatest distance above the mean and the 
greatest distance below the mean. 
a. x = 100, p = 50, u = 25 
b. x =  1 , p  = 4 , u  = 1 
c. x = 0, p = 200,u = 100 
d. x =  1 0 , p =  5 , u = 3  
2.72 Suppose that 40 and 90 are two elements of a population 
data set and that their z-scores are -2 and 3, respectively. 
Using only this information, is it possible to determine 
the population's mean and standard deviation? If so, find 
them. If not, explain why it's not possible. 
Applying the Concepts 
2.73 The U.S. Environmental Protection Agency (EPA) sets 
a limit on the amount of lead permitted in drinking 
water.The EPA Action Level for lead is ,015 milligrams 
per liter (mg/L) of water. Under EPA guidelines, if 90% 
of a water system's study samples have a lead concen- 
tration less than .015 mg/L, the water is considered safe 
for drinking. I (co-author Sincich) received a recent 
report on a study of lead levels in the drinking water of 
homes in my subdivision. The 90th percentile of the 
study sample had a lead concentration of ,00372 mg/L. 
Are water customers in my subdivision at risk of drink- 
ing water with unhealthy lead levels? Explain. 
MINITAB Output for Exercise 2.74 
2.74 Refer to the January 1999 sanitation levels of cruise 
ships, Exercise 2.58 (p. 74). The MINITAB descriptive 
statistics printout is reproduced below. 
a. Give a measure of relative standing for the Dawn 
Princess' score of 79. Interpret the result. 
b. Give a measure of relative standing for the Topaz's 
score of 92. Interpret the result. 
c. Find the 75th percentile of the sanitation level scores 
and interpret its value. [Note: The 75th percentile is 
denoted Q3 on the MINITAB printout.] 
2.75 In 1997 the United States imported merchandise valued 
at $871 billion and exported merchandise worth $689 
billion. The difference between these two quantities 
(exports minus imports) is referred to as the merchan- 
dise trade balance. Since more goods were imported 
than exported in 1997, the merchandise trade balance 
was a negative $182 billion. The accompanying table lists 
the U.S. exports to and imports from a sample of 10 
countries in 1997 (in millions of dollars). 
a. Calculate the U.S. merchandise trade balance with 
each of the ten countries. Express your answers in 
billions of dollars. 
b. Use a z-score to identify the relative position of the 
U.S. trade balance with Japan within the data set you 
developed in part a. Do the same for the trade balance 
with Egypt. Write a sentence or two that describes the 
relative positions of these two trade balances 
Country 
............................ 
Brazil 
China 
Egypt 
France 
Italy 
Japan 
Mexico 
Panama 
Sweden 
Singapore 
Exports 
......................... 
15,914.7 
12,862.3 
3,835.4 
15,964.9 
8,994.7 
65,548.5 
71,388.4 
1,536.1 
3,314.1 
17,696.2 
Imports 
................... 
9,625.5 
62,557.6 
657.5 
20,636.4 
19,407.5 
121,663.2 
85,937.5 
367.2 
7,298.9 
20,074.6 
Source: Statistical Abstract of the United 
States: 1998, pp. 801-804. 
2.76 In 1998, the food, drink, and tobacco sector of the U.S. 
economy did not fare well. Forbes (Jan. 11,1999) reports 
Descriptive Statistics 
I 
Variable 
N 
Mean 
Median 
Tr Mean 
StDev 
SE Mean 
Sanlevel 
121 
90.339 
92.000 
91.138 
6.947 
0.632 
Variable 
Min 
Max 
Q 1 
Q3 
Sanlevel 
36.000 
99.000 
88.000 
94.000 
- 

4 
SECTION 
2.7 
N u m e r i c a l  M e a s u r e s  o f  R e l a t i v e  S t a n d i n g  
83 
the sales growth of a sample of 12 companies from that 
sector. 
Company 
1998 Sales Growth 
Anheuser-Busch 
.9% 
Campbell Soup 
-.l 
Coca-Cola 
2.4 
Dole Food 
7.9 
Flowers Industries 
120.5 
General Mills 
6.6 
H.J. Heinz 
-1.9 
Hershey Foods 
4.5 
Philip Morris 
2.3 
Smithfield Foods 
-5.0 
Universal 
-4.0 
Wm Wrigley Jr. 
4.7 
Source: Forbes, Jan. 11,1999, p. 175. 
a. Find the mean and standard deviation of the sales 
growth data. 
b. Find the z-scores for Coca-Cola, Flowers Industries, 
and Smithfield Foods. 
c. Using the z-scores from part b, describe the location 
of each of the three companies within the sample of 
sales growths. 
2.77 Refer to the Arkansas Business and Economic Review 
(Summer 1995) study of hazardous waste sites in 
Arkansas counties, Exercise 2.37 (p. 61). An SAS descrip- 
tive statistics printout for the number of Superfund 
waste sites in each of the 75 counties is displayed here. 
a. Find the 10th percentile of the data set on the print- 
out. Interpret the result. 
b. Find the 95th percentile of the data set on the print- 
out. Interpret the result. 
c. Use the information on the SAS printout to calculate 
the z-score for an Arkansas county with 48 Super- 
fund sites. 
d. Based on your answer to part c, would you classify 
48 as an extreme number of Superfund sites? 
2.78 At one university, the students are given z-scores at the 
end of each semester rather than the traditional GPAs. 
SAS Output for Exercise 2.77 
UNIVARIATE PROCEDURE 
Variable=NUMSITES 
Moments 
Mean 
Std Dev 
Skewness 
USS 
cv 
T : Mean=O 
Sgn Rank 
Num "=O 
Sum Wgt s 
Sum 
Variance 
Kurtosis 
CSS 
Std Mean 
100% 
Max 
75% 
43 
50% 
Med 
25% 
Q 1  
0% 
Min 
Range 
Q3-Q1 
Mode 
Extremes 
Lowest 
Obs 
Highest 
Obs 
0 ( 
6 8 )  
17 ( 
47) 
0  ( 
6 7 )  
21 ( 
52) 
0  ( 
6 6 )  
21 ( 
7 5 )  
0  ( 
39) 
25 ( 
36) 
0 ( 
38) 
48 ( 
7 4 )  

84 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  o f  D a t a  
~ 
- 
The mean and standard deviation of all students' cumu- 
C. The president of the university wishes to graduate 
lative GPAs, on which the z-scores are based, are 2.7 
the top 16% of the students with cum laude honors 
and .5, respectively. 
and thc top 2.5% with summa cum laude honors. 
a. Translate each of the following z-scores to corre- 
Where (approximately) should the limits be set in 
sponding GPA: z = 2 . 0 , ~  = -1.0, z = .5, z = -2.5. 
terms of z-scores? In terms of GPAs? What assump- 
b. Students with z-scores below -1.6 are put on proba- 
tion, if any, did you make about the distribution of 
What is the corresponding probationary GPA? 
the GPAs at the university? 
METHODS FOR DETECTING OUTLIERS (OPTIONAL) 
Sometimes it is important to identify inconsistent or unusual measurements in a 
data set.An observation that is unusually large or small relative to the data values 
we want to describe is called an outlier. 
Outliers are often attributable to one of several causes. First, the measure- 
ment associated with the outlier may be invalid. For example, the experimental 
procedure used to generate the measurement may have malfunctioned, the ex- 
perimenter may have misrecorded the measurement, or the data might have been 
coded incorrectly in the computer. Second, the outlier may be the result of a mis- 
classified measurement. That is, the measurement belongs to a population differ- 
ent from that from which the rest of the sample was drawn. Finally, the 
measurement associated with the outlier may be recorded correctly and from the 
same population as the rest of the sample, but represents a rare (chance) event. 
Such outliers occur most often when the relative frequency distribution of the 
sample data is extremely skewed, because such a distribution has a tendency to in- 
clude extremely large or small observations relative to the others in the data set. 
An observation (or measurement) that is unusually large or small relative to 
the other values in a data set is called an outlier. Outliers typically are attrib- 
utable to one of the following causes: 
1. The measurement is observed, recorded, or entered into the computer 
incorrectly. 
2. The measurement comes from a different population. 
3. The measurement is correct, but represents a rare (chance) event. 
Two useful methods for detecting outliers, one graphical and one numerical, 
are box plots and z-scores. The box plot is based on the quartiles of a data set. 
Quartiles are values that partition the data set into four groups, each containing 
25% of the measurements.The lower quartile QL is the 25th percentile, the middle 
quartile is the median m (the 50th percentile), and the upper quartile Q, is the 
75th percentile (see Figure 2.26). 
The quartiles for a data set 

SECTION 
2.8 
M e t h o d s  for D e t e c t i n g  Outliers ( O p t i o n a l )  
85 * 
DEFINITION 2.13 
The lower quartile QI, 
is the 25th percentile of a data set.The middle quartile 
m is the median. The upper quartile Q ,  is the 75th percentile. 
A box plot is based on the interquartile range (IQR), the distance between 
the lower and upper quartiles: 
IQR = Q" - Q, 
The interquartile range (IQR) is the distance between the lower and upper 
quartiles: 
A vertical MINITAB box plot for the 50 companies' percentages of rev- 
enues spent on R&D (Table 2.4) is shown in Figure 2.27". Note that a rectangle 
(the box) is drawn, with the top and bottom sides of the rectangle (the hinges) 
drawn at the quartiles QL and Q,. By definition, then, the "middle" 50% of the 
observations-those between QL and Q,-fall 
inside the box. For the R&D data, 
these quartiles appear to be at (approximately) 7.0 and 9.5. Thus, 
IQR = 9.5 - 7.0 = 2.5 (approximately) 
FIGURE 2.27 
14 - 
MINITAB box plot for 
* 
R&D percentages 
13 - 
12 - 
11 - 
* i 
10 - 
n 
2 9 -  
8 - 
7 - 
The median is shown at about 8.0 by a horizontal line within the box. 
To guide the construction of the "tails" of the box plot, two sets of limits, 
called inner fences and outer fences, are used. Neither set of fences actually ap- 
pears on the box plot. Inner fences are located at a distance of l.S(IQR) from the 
hinges. Emanating from the hinges of the box are vertical lines called the whiskers. 
The two whiskers extend to the most extreme observation inside the inner fences. 
For example, the inner fence on the lower side (bottom) of the R&D percentage 
box plot is (approximately) 
*Although box plots can be generated by hand, the amount of detail required makes them 
particularly well suited for computer generation. We use computer software to generate the box 
plots in this sectlon. 

86 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of Data 
Lower inner fence = Lower hinge - 1 .5(IQR) 
.r 7.0 - lS(2.5) 
= 7.0 - 3.75 = 3.25 
The smallest measurement in the data set is 5.2, which is well inside this inner 
fence. Thus, the lower whisker extends to 5.2. Similarly, the upper whisker ex- 
tends to about (9.5 + 3.75) = 13.25. The largest measurement inside this fence is 
the third largest measurement, 13.2. Note that the longer upper whisker reveals 
the rightward skewness of the R&D distribution. 
Values that are beyond the inner fences are deemedpotential outliers because 
they are extreme values that represent relatively rare occurrences. In fact, for mound- 
shaped distributions, fewer than 1 % of the observations are expected to fall outside 
the inner fences.Two of the 50 R&D measurements, both at 13.5, fall outside the upper 
inner fence. Each of these potential outliers is represented by the asterisk (*) at 13.5. 
The other two imaginary fences, the outer fences, are defined at a distance 
3(1QR) from each end of the box. Measurements that fall beyond the outer fences 
are represented by 0s (zeros) and are very extreme measurements that require spe- 
cial analysis. Since less than one-hundrcdth of 1% (.01% or .0001) of the measure- 
ments from mound-shaped distributions are expected to fall beyond the outer fences, 
these measurements are considered to be outliers. No measurement in the R&D per- 
centage box plot (Figure 2.27) is represented by a 0; thus there are no outliers. 
Recall that outliers are extreme measurements that stand out from the rest 
of the sample and may be faulty: They may be incorrectly recorded observations, 
members of a population different from the rest of the sample, or, at the least, very 
unusual measurements from the same population. For example, the two R&D 
measurements at 13.5 (identified by an asterisk) may be considered outliers. When 
we analyze these measurements, we find that they are correctly recorded. How- 
ever, it turns out that both represent R&D expenditures of relatively young and 
fast-growing companies. Thus, the outlier analysis may have revealed important 
factors that relate to the R&D expenditures of high-tech companies: their age and 
rate of growth. Outlier analysis often reveals useful information of this kind and 
therefore plays an important role in the statistical inference-making process. 
In addition to detecting outliers, box plots provide useful information on the 
variation in a data set.The elements (and nomenclature) of box plots are summa- 
rized in the next box. Some aids to the interpretation of box plots are also given. 
ox Plot 
(the box) is drawn 
hinges) drawn at the 
ower and upper quartiles (QL a 
n of the data is shown 
in the box, usually by a line or a symbol (such as " + "). 
. The points at distances lS(1QR) from each hinge define the inner fences 
of the data set. Lines (the whiskers) are drawn from each hinge to the 
most extreme measurement inside the inner fence. 
3. A second pair of fences, the outer fences, are defined at a distance of 3 
interquartile ranges, 3(IQR), from the hinges. One symbol (usually "*") 
is used to represent measurements falling between the inner and outer 
fences, and another (usually "0") is used to represent measurements be- 
yond the outer fences. 
4. The symbols used to represent the median and the extreme data points 
(those beyond the fences) will vary depending on the software you use 
(continued) 

SECTION 2.8 
M e t h o d s  f o r  D e t e c t i n g  O u t l i e r s  ( O p t i o n a l )  
87 " 
to 
CO 
umentation to determine exactly which symbols are used. 
Aids to the Inter 
1. Examine the length of the box. The IQR is a measure of the sample's 
variability and is e 
for the comparison of two samples 
(see Example 2.17) 
2. Visually compare the lengths of the whiskers. If one is clearly longer, the 
distribution of the 
skewed in the direction of the longer 
3. Analyze any meas 
lie beyond the fences. Fewer than 5% 
should fall beyond 
es, even for very skewed distributions. 
Measurements beyond the outer fences are probably outliers, with one 
of the following explanations: 
a. The measurement is incorrect. It may have been observed, recorded, 
or entered into the computer incorrectly. 
b. The measurement belongs to a population different from the popula- 
tion that the rest of the sample was drawn from (see Example 2.17). 
The measurement is correct and from the same population as the rest. 
enerally, we accept this explanation only after carefully ruling out all 
-* 
.., 
d 
- 
In Example 2.3 we analyzed 50 processing times for the development of price 
quotes by the manufacturer of industrial wheels. The intent was to determine 
whether the success or failure in obtaining the order was related to the amount of 
time to process the price quotes. Each quote that corresponds to "lost" business 
was so classified. The data are repeated in Table 2.11 (p. 88). Use a statistical 
software package to draw a box plot for these data. 
S o l u t i o n  
FIGURE 2.28 
SAS box plot for processing 
time data 
The SAS box plot printout for these data is shown in Figure 2.28. SAS uses a 
horizontal dashed line in the box to represent the median, and a plus sign (+) to 

88 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of Data 
TABLE 
2.1 1 
Price Quote Processing Time (Days) 
Request Number 
Processing Time 
Lost? 
Request Number 
Processing Time 
Lost? 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1 
2.36 
No 
26 
3.34 
No 
2 
5.73 
No 
27 
6.00 
No 
3 
6.60 
No 
28 
5.92 
No 
4 
10.05 
Yes 
29 
7.28 
Yes 
5 
5.13 
No 
30 
1.25 
No 
6 
1.88 
No 
31 
4.01 
No 
7 
2.52 
No 
32 
7.59 
No 
8 
2.00 
No 
33 
13.42 
Yes 
9 
4.69 
No 
34 
3.24 
No 
10 
1.91 
No 
35 
3.37 
No 
11 
6.75 
Yes 
36 
14.06 
Yes 
12 
3.92 
No 
37 
5.10 
No 
13 
3.46 
No 
38 
6.44 
No 
14 
2.64 
No 
39 
7.76 
No 
15 
3.63 
No 
40 
4.40 
No 
16 
3.44 
No 
41 
5.48 
No 
17 
9.49 
Yes 
42 
7.51 
No 
18 
4.90 
No 
43 
6.18 
No 
19 
7.45 
No 
44 
8.22 
Yes 
20 
20.23 
Yes 
45 
4.37 
No 
21 
3.91 
No 
46 
2.93 
No 
22 
1.70 
No 
47 
9.95 
Yes 
23 
16.29 
Yes 
48 
4.46 
No 
24 
5.52 
No 
49 
14.32 
Yes 
25 
1.44 
No 
50 
9.01 
No 
1 I 
represent the mean. (SAS shows the mean in box plots, unlike many other 
statistical programs.) Also, SAS uses the symbol "0" to represent measurements 
between the inner and outer fences and "*" to represent observations beyond the 
outer fences (the opposite of MINITAB). 
Note that the upper whisker is longer than the lower whisker and that the 
mean lies above the median; these characteristics reveal the rightward skewness of 
the data. However, the most important feature of the data is made very obvious 
by the box plot: There are at least two measurements between the inner and outer 
fences (in fact, there are three, but two are almost equal and are represented by 
1 
the same "0") and at least one beyond the outer fence, all on the upper end of the 
distribution. Thus, the distribution is extremely skewed to the right, and several 
measurements need special attention in our analysis. We offer an explanation 
the outliers in the following example. 
m * ~ , ~ ~ m s b L , \ * , . , * , ~ , , * ~ % * . s " m h ~ % ~  
The box plot for the 50 processing times (Figure 2.28) does not explicitly reveal 
the differences, if any, between the set of times corresponding to the success and 
the set of times corresponding to the failure to obtain the business. Box plots 
corresponding to the 39 "won" and 11 "lost" bids were generated using SAS, and 
are shown in Figure 2.29. Interpret them. 
S o I u t i o n 
The division of the data set into two parts, corresponding to won and lost bids, 
eliminates any observations that are beyond inner or outer fences. Furthermore, 
[ 
the skewness in the distributions has been reduced, as evidenced by the facts that 
the upper whiskers are only slightly longer than the lower, and that the means are 
closer to the medians than for the combined sample. The box plots also reveal that 
the processing times corresponding to the lost bids tend to exceed those of the 
- 

SECTION 
2.8 
M e t h o d s  f o r  D e t e c t i n g  O u t l i e r s  ( O p t i o n a l )  
89 - 
BUSINESS 
Lost 
Won 
FIGURE 2.29 
SAS box plots of processing 
time data: Won and lost bids 
won bids. A plausible explanation for the outliers in the combined box plot 
(Figure 2.29) is that they are from a different population than the bulk of the 
times. In other words, there are two populations represented by the sample of 
processing times-one 
corresponding to lost bids, and the other to won bids. 
The box plots lend support to the conclusion that the price quote processing 
time and the success of acquiring the business are related. However, whether the 
visual differences between the box plots generalize to inferences about the popu- 
lations corresponding to these two samples is a matter for inferential statistics, not 
graphical descriptions. We'll discuss how to use samples to compare two popula- 
tions using inferential statistics in Chapters 7 and 8. 
Variable=TIME 
The following example illustrates how z-scores can be used to detect outliers 
and make inferences. 
"-1 
b
~
~
~
~
~
~
~
-
>
S
r
n
n
~
Suppose a female bank employee believes that her salary is low as a result of sex 
discrimination.To substantiate her belief, she collects information on the salaries 
of her male counterparts in the banking business. She finds that their salaries 
have a mean of $34,000 and a standard deviation of $2,000. Her salary is $27,000. 
Does this information support her claim of sex discrimination? 
S o I u t i o n 
The analysis might proceed as follows: First, we calculate the z-score for the 
woman's salary with respect to those of her male counterparts. Thus, 
The implication is that the woman's salary is 3.5 standard deviations below 
the mean of the male salary distribution. Furthermore, if a check of the male 
salary data shows that the frequency distribution is mound-shaped, we can infer 
that very few salaries in this distribution should have a z-score less than -3, as 
shown in Figure 2.30. Clearly, a z-score of -3.5 represents an outlier-a 
mea- 
surement from a distribution different from the male salary distribution or a very 
unusual (highly improbable) measurement for the male salary distribution. 

90 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of Data 
F I G U R E  2.30 
Male salary distribution 
27,000 
34,000 
Salary ($) 
Which of the two situations do you think prevails? D o  you think the 
woman's salary is simply unusually low in the distribution of salaries, or do you 
think her claim of sex discrimination is justified? Most people would probably 
conclude that her salary does not come from the male salary distribution. How- 
ever, the careful investigator should require more information before inferring sex 
discrimination as the cause. We would want to know more about the data collec- 
tion technique the woman used and more about her competence at her job. Also, 
perhaps other factors such as length of employment should be considered in the 
analysis. 
Examples 2.17 and 2.18 exemplify an approach to statistical inference that 
might be called the rare-event approach. An experimenter hypothesizes a specif- 
ic frequency distribution to describe a population of measurements. Then a sample 
of measurements is drawn from the population. If the experimenter finds it un- 
likely that the sample came from the hypothesized distribution, the hypothesis is 
concluded to be false. Thus, in Example 2.18 the woman believes her salary re- 
flects discrimination. She hypothesizes that her salary should be just another mea- 
surement in the distribution of her male counterparts' salaries if no discrimination 
exists. However, it is so unlikely that the sample (in this case, her salary) came 
from the male frequency distribution that she rejects that hypothesis, concluding 
that the distribution from which her salary was drawn is different from the distri- 
bution for the men. 
This rare-event approach to inference-making is discussed further in later 
chapters. Proper application of the approach requires a knowledge of probability, 
the subject of our next chapter. 
We conclude this section with some rules of thumb for detecting outliers. 
inner and outer fences are 
deemed highly suspect outliers. 
z-scores: Observations with z-scores greater than 3 in absolute value 
z-scores greater than 1 in absolute v 
*The z-score and box plot methods both establish rule-of-thumb limits outslde of which a 
measurement is deemed to be an outher Usually, the two methods produce slmilar results. 
However, the presence of one or more outliers in a data set can inflate the computed value of s 
Con~equently, it will be less hkely that an errant observation would have a z-score larger than 3 in 
absolute value In contrast, the values of the quartiles used to calculate the intervals for a box plot 
are not affected by the presence of outl~ers 

SECTION 2.8 
M e t h o d s  f o r  D e t e c t i n g  O u t l i e r s  ( O p t i o n a l )  
91 4 
Making a Box Plot on the TI-83 
Step 1 Enter the data 
Press STAT 1 for STAT Edit 
Enter the data set into L1. 
Step 2. Set up the box plot 
Press 2nd Y= for STAT PLOT 
Press 1 
for Plot 1 
Use the arrow and ENTER keys to set up the screen as shown below. 
Step 3 Select your window settings 
Press WINDOW and adjust the settings as follows: 
Xmin = smallest data value (or smaller) 
Xmax = largest data value (or larger) 
Xscl 
= approximately (xmax - xmin)/lO 
' 
Ymin = O 
Ymax = 10 
Yscl = 1 
Step 4 Viewthegraph 
Press GRAPH 
0 p t iona l Read the five number summary 
Press TRACE 
Step 
Use the left and right arrow keys to move between minx, Q1, 
Med, Q3, and maxX. 
Ex ample Make a bpx plot for the given data, 
The window settings and horizontal box plot are shown below. 

92 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets of Data 
Learning the Mechanics 
e. What percentage of the measurements in the data 
2.79 A sample data set has a mean of 57 and a standard devi- 
ation of 11. Determine whether each of the following 
sample measurements are outliers. 
a. 65 
b. 21 
c. 72 
d. 98 
2.80 Define the 25th, 50th, and 75th percentiles of a data set. 
Explain how they provide a description of the data. 
2.81 Suppose a data set consisting of exam scores has a lower 
quartile QL = 60, a median rn = 75, and an upper quar- 
tile Q,, = 85. The scores on the exam range Srom 18 to 
100. Without having the actual scores available to you, 
construct as much of the box plot as possible. 
2.82 MINITAB was used to generate the box plot shown here. 
set lie to the right of the median? To the left of the 
upper quartile? 
f. Identify any outliers in the data. 
2.83 Consider the following two sample data sets: 
Sample A 
......................................... 
121 
171 
158 
173 
184 
163 
157 
85 
145 
165 
172 
196 
170 
159 
172 
161 
187 
100 
142 
166 
171 
Sample B 
a. Use a statistical software package to construct a box 
plot for each data set. 
b. Using information reflected in your box plots, describe 
the similarities and differences in the two data sets. 
Applying the Concepts 
2.84 The table contains the top salary offer (in thousands of 
dollars) received by each member of a sample of 50 
MBA students who recently graduated from the 
Graduate School of Management at Rutgers, the state 
university of New Jersey. 
- 
Source: Career Services Office, Graduate 
School of Management, Rutgers University. 
a. The mean and standard deviation are 52.33 and 9.22, 
respectively. Find and interpret the z-score associated 
with the highest salary offer, the lowest salary offer, 
and the mean salary offer. Would you consider the 
highest offer to be unusually high? Why or why not? 
b. Use a statistical software package to construct a box 
plot for this data set. Which salary offers (if any) are 
potentially faulty observations? Explain. 
a. What is the median of the data set (approximately)? 
b. What are the upper and lower quartiles of the data 
set (approximately)? 
c. What is the interquartile range of the data set (ap- 
proximately)? 
2.85 Refer to the Financial Management (Spring 1995) study 
d. Is the data set skewed to the left, skewed to the right, 
of 49 firms filing for prepackaged bankruptcies, 
or symmetric? 
Exercise 2.24 (p. 49). Recall that three types ot 

SECTION 2.8 
M e t h o d s  f o r  D e t e c t i n g  O u t l i e r s  ( O p t i o n a l )  
93 
"prepack" firms exist: (1) those who hold no pre-filing 
vote; (2) those who vote their preference for a joint 
solution; and (3) those who vote their preference for a 
prepack. Box plots, constructed using MINITAB, for 
the time in bankruptcy (months) for each type of firm 
are shown below. 
Prepack 
None 
Joint 
Category 
a. How do the median bankruptcy times compare for 
the three types? [Hint: Recall that MINITAB uses a 
horizontal line through the box to represent the 
median.] 
b. How do the variabilities of the bankruptcy times 
compare for the three types? 
e. The standard deviations of the bankruptcy times are 
2.47 for "none," 1.72 for "joint," and 0.96 for 
"prepack." Do the standard deviations agree with 
the interquartile ranges (part b) with regard to the 
comparison of the variabilities of the bankruptcy 
times? 
d. Is there evidence of outliers in any of the three dis- 
tributions? 
2.86 Refer to the Fortune (Oct. 25, 1999) ranking of the 50 
most powerful women in America, Exercise 2.36 (p. 59). 
A box plot for the ages of the 50 women, produced 
using STATISTIX, is shown above right. 
a. Use the box plot to estimate the lower quartile, me- 
dian, and upper quartile of these data. (Compare 
your estimates to the actual values shown on the 
MINITAB printout, p. 59.) 
b. Does the age distribution appear to be skewed? 
Explain. 
e. Are there any outliers in these data? If so, identify 
them. 
2.87 A manufacturer of minicomputer systems is interested 
in improving its customer support services. As a first 
step, its marketing department has been charged with 
the responsibility of summarizing the extent of cus- 
tomer problems in terms of system down time. The 40 
most recent customers were surveyed to determine the 
amount of down time (in hours) they had experienced 
STATISTIX Output for Exercise 2.86 
50 Cases 
during the previous month. These data are listed in the 
table. 
DOWNTIME.DAT 
..................................................................................................................... 
Customer 
Down 
Customer 
Down 
Customer 
Down 
Number 
Time 
Number 
Time 
Number 
Time 
......................................................................................................... 
230 
12 
244 
2 
258 
28 
23 1 
16 
245 
11 
259 
19 
232 
5 
246 
22 
260 
34 
233 
16 
247 
17 
261 
26 
234 
21 
248 
31 
262 
17 
235 
29 
249 
10 
263 
11 
236 
38 
250 
4 
264 
64 
237 
14 
25 1 
10 
265 
19 
238 
47 
252 
15 
266 
18 
239 
0 
253 
7 
267 
24 
240 
24 
254 
20 
268 
49 
241 
15 
255 
9 
269 
50 
242 
13 
256 
22 
243 
8 
257 
18 
a. Use a statistical software package to construct a box 
plot for these data. Use the information reflected in 
the box plot to describe the frequency distribution of 
the data set. Your description should address central 
tendency, variation, and skewness. 
b. Use your box plot to determine which customers are 
having unusually lengthy down times. 
c. Find and interpret the z-scores associated with the 
customers you identified in part b. 
2.88 According to Forbes (Jan. 11,1999), retailing was one of 
the U.S. economy's best-performing sectors in 1998. The 
Internet and its associated on-line sales played a signif- 
icant role in the performance. The table on p. 94 lists the 
1998 sales and net income (in millions of dollars) for 24 
major retailers. 

94 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
RETAIL 98.DAT 
a. Use a 
package 
construct a box 
Q ................................................................................................ 
plot for each of the two variables, sales and net income. 
Net 
b. Which companies (if any) show up as outliers with 
Company 
Sales 
Income 
respect to sales? With respect to net income? 
................................................................................................ 
c. Use the box plots to estimate the upper quartiles of 
Ames Dept Stores 
2,500 
42 
the two data sets and internret their values. Wh~ch 
AutoZone 
3,243 
228 
companies fall above the upper quartiles'? 
Bed Bath & Beyond 
Best Buy 
BJ's wholesale Club 
3,497 
77 
CDW Computer Centers 
1,607 
61 
Costco Cos 
24,270 
460 
Dollar General 
3,089 
169 
Family Dollar Stores 
2,362 
103 
Gap 
8,190 
726 
Global DirectMail 
1,401 
43 
Goody's Family 
1,062 
37 
Home Depot 
28,692 
1,503 
Kohl's 
3,470 
171 
Lowe's Cos 
11,727 
449 
Office Depot 
8,425 
21 1 
Pier 1 Imports 
1,120 
76 
Ross Stores 
2,125 
129 
Staples 
6,596 
178 
Starbucks 
1,309 
68 
Tiffany 
1,094 
79 
Wal-Mart Stores 
132,235 
4,158 
Walgreen 
15,307 
537 
Williams-Sonoma 
1,033 
45 
Source: Forbes, January 11,1999, p. 196. 
GRAPHING BlVARlATE RELATIONSHIPS (OPTIONAL) 
The claim is often made that the crime rate and the unemployment rate are "high- 
ly correlated." Another popular belief is that the Gross Domestic Product (GDP) 
and the rate of inflation are "related." Some people even believe that the Dow 
Jones Industrial Average and the lengths of fashionable skirts are "associated." 
The words "correlated," "related," and "associated" imply a relationship between 
two variables-in 
the examples above, two quantitative variables. 
One way to describe the relationship between two quantitative variables- 
called a bivariate relationship-is 
to plot the data in a scattergram (or scatterplot). 
A scattergram is a two-dimensional plot, with one variable's values plotted along 
the vertical axis and the other along the horizontal axis. For example, Figure 2.31 
is a scattergram relating (1) the cost of mechanical work (heating, ventilating, 
and plumbing) to (2) the floor area of the building for a sample of 26 factory and 
warehouse buildings. Note that the scattergram suggests a general tendency for 
mechanical cost to increase as building floor area increases. 
When an increase in one variable is generally associated with an increase in 
the second variable, we say that the two variables are "positively related" or "pos- 
itively correlated."" Figure 2.31 implies that mechanical cost and floor area are 
positively correlated. Alternatively, if one variable has a tendency to decrease as 
the other increases, we say the variables are "negatively correlated." Figure 2.32 
shows several hypothetical scattergrams that portray a positive bivariate rela- 
*A formal definition of correlation is given in Chapter 9. We will learn that correlation measures 
the strength of the linear (or straight-line) relationship between two variables. 

SECTION 2.9 
G r a p h i n g  Bivariate Relationships ( O p t i o n a l )  
95 - 
FIGURE 2 . 3 1  
Y 
.-. .,. 
* r e  
Scattergram of cost vs. floor 
"0 800 
FIGURE 2.32 
Hypothetical bivariate 
relationship 
i 
area 
Variable #2 
a. Positive relationship 
0
1
2
3
4
5
6
7
 
Floor area (thousand square meters) 
Variable #2 
Variable #2 
b. Negative relationship 
c. No relationship 
tionship (Figure 2.32a), a negative bivariate relationship (Figure 2.32b), and a sit- 
uation where the two variables are unrelated (Figure 2.32~). 
*-- 
D*" 
1
1
1
1
1
a
-
-
 
A medical item used to administer to a hospital patient is called a factor. For 
example, factors can be intravenous (IV) tubing, IV fluid, needles, shave kits, 
bedpans, diapers, dressings, medications, and even code carts. The coronary care 
unit at Bayonet Point Hospital (St. Petersburg, Florida) recently investigated the 
relationship between the number of factors administered per patient and the 
patient's length of stay (in days). Data on these two variables for a sample of 50 
coronary care patients are given in Table 2.12. Use a scattergram to describe the 
relationship between the two variables of interest, number of factors and length 
of stay. 
S o I u t i o n Rather than construct the plot by hand, we resort to a statistical software package. 
The SPSS plot of the data in Table 2.12, with length of stay (LOS) on the vertical axis 
and number of factors (FACTORS) on the horizontal axis, is shown in Figure 2.33. 
As plotting symbols, SPSS uses numbers. Each symbol represents the num- 
ber of sample points (e.g., patients) plotted at that particular coordinate. Although 
the plotted points exhibit a fair amount of variation, the scattergram clearly shows 

96 
CHAPTER 
2 
M e t h o d s  f o r  Describing Sets o f  Data 
TABLE 
2.12 
Data on Patient's Factors and Length of Stay 
- 
Number of Factors 
Length of Stay (days) 
Number of Factors 
Length of Stay (days) 
................................................................................................. ................................................................................................ 
231 
9 
354 
11 
323 
7 
142 
7 
113 
8 
286 
9 
208 
5 
341 
10 
162 
4 
201 
5 
117 
4 
158 
11 
159 
6 
243 
6 
169 
9 
156 
6 
55 
6 
184 
7 
77 
3 
115 
4 
103 
4 
202 
6 
147 
6 
206 
5 
230 
6 
360 
6 
78 
3 
84 
3 
525 
9 
331 
121 
9 
7 
302 
7 
248 
5 
60 
2 
233 
8 
110 
2 
260 
4 
131 
5 
224 
7 
364 
4 
472 
12 
180 
7 
220 
8 
134 
383 
6 
6 
401 
15 
301 
9 
155 
4 
262 
7 
338 
8 
Source: Bayonet Point Hospital, Coronary Care Unit. 
FIGURE 2.33 
SPSS scatterplot of data in 
Table 2.12 
PLOT OF LOS WITH FACTORS 
I 
I 
I 
I 
I 
I 
I 
I 
525 
1 
FACTORS 
an increasing trend. It appears that a patient's length of stay is positively corre- 
lated with the number of factors administered to the patient. Hospital adminis- 
trators may use this information to improve their forecasts of lengths of stay for 
future patients. 
1 

SECTION 2.10 
T h e  T i m e  S e r i e s  P l o t  ( O p t i o n a l )  
97 - 
U S I N G  THE T I - 8 3  GRAPHING CALCULATOR 
Making Scatterplots 
To make a scatterplot for paired data, 
Step 1 Enter the data 
Press STAT 1 for STAT Edit 
. Enter your x-data in L1 and your y-data in L2. 
Step 2 Set up the scatterplot 
Press 2ndY= for STAT PLOT 
Press 1 
for Plot1 
Use the arrow and ENTER keys to set up the screen as shown below. 
Step 3 
Examp 
View the scatterplot 
Press ZOOM 9 for ZoomStat 
le The figures below show a table of data entered on the TI-83 and the 
scattcrplot of the data obtained using the steps given above. 
The scattergram is a simple but powerful tool for describing a bivariate re- 
lationship. However, keep in mind that it is only a graph. No measure of reliabili- 
ty can be attached to inferences made about bivariate populations based on 
scattergrams of sample data. The statistical tools that enable us to make inferences 
about bivariate relationships are presented in Chapter 9. 
THE TIME SERIES PLOT (OPTIONAL) 
Each of the previous sections has been concerned with describing the information 
contained in a sample or population of data. Often these data are viewed as hav- 
ing been produced at essentially the same point in time.Thus, time has not been a 
factor in any of the graphical methods described so far. 

98 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets of D a t a  
Data of interest to managers are often produced and monitored over time. 
Examples include the daily closing price of their company's common stock, the 
company's weekly sales volume and quarterly profits, and characteristics-such as 
weight and length--of products produced by the company. 
FIGURE 2.34 
Time series plot of company 
sales 
DEFINITION 2.15 
Data that are produced and monitored over time are called time series data. 
Recall from Section 1.4 that a process is a series of actions or operations that 
generates output over time. Accordingly, measurements taken of a sequence of 
units produced by a process-such 
as a production process-are 
time series data. 
In general, any sequence of numbers produced over time can be thought of as 
being generated by a process. 
When measurements are made over time, it is important to record both the 
numerical value and the time or the time period associated with each measure- 
ment. With this information a time series plot-sometimes 
called a run chart-can 
be constructed to describe the time series data and to learn about the process that 
generated the data. A time series plot is simply a scatterplot with the measure- 
ments on the vertical axis and time or the order in which the measurements were 
made on the horizontal axis.The plotted points are usually connected by straight 
lines to make it easier to see the changes and movement in the measurements 
over time. For example, Figure 2.34 is a time series plot of a particular company's 
monthly sales (number of units sold per month). And Figure 2.35 is a time series 
plot of the weights of 30 one-gallon paint cans that were consecutively filled by 
the same filling head. Notice that the weights are plotted against the order in 
which the cans were filled rather than some unit of time. When monitoring pro- 
duction processes, it is often more convenient to record the order rather than the 
exact time at which each measurement was made. 
Jan 
Mar 
May July Sept Nov 
Jan 
Mar May 
July 
Sep 
Nov 
Year 1 
Year 2 

FIGURE 2.35 
Time series plot of 
paint can weights 
10.04 
SECTION 2.10 
T h e  T i m e  S e r i e s  P l o t  ( O p t i o n a l )  
99 
I
I
!
 I
I
I
I
 I 
I
I
I
I
 I
I
 I 
I 
I 
I 
I 
I 
I
I
I
I
I
,
,
,
,
 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 
Order of production 
Time series plots reveal the movement (trend) and changes (variation) in 
the variable being monitored. Notice how sales trend upward in the summer and 
how the variation in the weights of the paint cans increases over time. This kind of 
information would not be revealed by stem-and-leaf displays or histograms, as the 
following example illustrates. 
FIGURE 2.36 
Deming's time series 
plot and histogram 
W. Edwards Deming was one of America's most famous statisticians. He was best 
known for the role he played after World War I1 in teaching the Japanese how to 
improve the quality of their products by monitoring and continually improving 
their production processes. In his book Out of the Crisis (1986), Deming warned 
against the knee-jerk (i.e., automatic) use of histograms to display and extract 
information from data. As evidence he offered the following example. 
Fifty camera springs were tested in the order in which they were produced. 
The elongation of each spring was measured under the pull of 20 grams. Both a 
time series plot and a histogram were constructed from the measurements. They 
are shown in Figure 2.36, which has been reproduced from Deming's book. If 
you had to predict the elongation measurement of the next spring to be produced 
(i.e., spring 51) and could use only one of the two plots to guide your prediction, 
which would you use? Why? 
Order of manufacture 

100 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  o f  D a t a  
S o I u t i o n 
Only the time series plot describes the behavior over time of the process that 
produces the springs. The fact that the elongation measurements are decreasing 
over time can only be gleaned from the time series plot. Because the histogram 
does not reflect the order in which the springs were produced, it in effect 
represents all observations as having been produced simultaneously. Using the 
histogram to predict the elongation of the 51st spring would very likely lead to an 
overestimate. 
T 
The lesson from Deming's example is this: For displaying and analyzing 
data that have been generated over time by a process, the primary graphical tool 
is the time series plot, not the histogram. 
DISTORTING THE TRUTH WITH DESCRIPTIVE 
TECHNIQUES 
A picture may be "worth a thousand words," but pictures can also color mes- 
sages or distort them. In fact, the pictures in statistics (e.g., histograms, bar charts, 
time series plots, etc.) are susceptible to distortion, whether unintentional or as a 
result of unethical statistical practices. In this section, we will mention a few of the 
pitfalls to watch for when interpreting a chart, graph, or numerical descriptive 
measure. 
One common way to change the impression conveyed by a graph is to 
change the scale on the vertical axis, the horizontal axis, or both. For example, Fig- 
ure 2.37 is a bar graph that shows the market share of sales for a company for 
each of the years 1995 to 2000. If you want to show that the change in firm A's 
market share over time is moderate, you should pack in a large number of units 
per inch on the vertical axis-that 
is, make the distance between successive units 
on the vertical scale small, as shown in Figure 2.37. You can see that a change in 
the firm's market share over time is barely apparent. 
FIGURE 2.37 
Firm A's market share from 
1995 to 2000-packed 
1 
Year 
If you want to use the same data to make the changes in firm A's market 
share appear large, you should increase the distance between successive units on 
the vertical axis. That is, stretch the vertical axis by graphing only a few units per 
inch as in Figure 2.38. A telltale sign of stretching is a long vertical axis, but this is 
often hidden by starting the vertical axis at some point above 0, as shown in the 

! 
4 
SECTION 2.11 
D i s t o r t i n g  t h e  T r u t h  w i t h  D e s c r i p t i v e  T e c h n i q u e s  
101 
FIGURE 2.38 
Firm A's market share from 1995 to 
2000-stretched 
vertical axis 
FIGURE 2.39 
Changes in money supply from 
January to June 
5: 370 
2 368 
3 366 
364 
362 
Jan. Feb. Mar. Apr. May June 
Month 
a. Vertical axis started at a point greater 
than zero 
" 
1995 1996 1997 1998 1999 2000 
Year 
0 'hX
Jan. Feb. Mar. Apr. May June 
Month 
b. Gap in vertical axis 
time series plot, Figure 2.39a. The same effect can be achieved by using a broken 
line-called 
a scale break-for 
the vertical axis, as shown in Figure 2.39b. 
Stretching the horizontal axis (increasing the distance between successive 
units) may also lead you to incorrect conclusions. With bar graphs, a visual distor- 
tion can be achieved by making the width of the bars proportional to the height. 
For example, look at the bar chart in Figure 2.40a, which depicts the percentage of 
FIGURE 2.40 
Relative share of the 
.30 
.30 
automobile market for each of 
5 
four major manufacturers 
G 
5' 
G- 
s 
c- 
. -.- ., 
3 .15 
4 .IS 
e, 
. - 
C-l 
P 
.- 
u 
- 
- 
2 
2 
" 
" 
A
B
C
D
 
A 
B 
C 
D 
Manufacturer 
Manufacturer 
a. Bar chart 
b. Width of bars grows with height 

102 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  S e t s  of D a t a  
- 
a year's total automobile sales attributable to each of the four major manufactur- 
ers. Now suppose we make both the width and the height grow as the market 
share grows. This change is shown in Figure 2.40b. The reader may tend to equate 
the area of the bars with the relative market share of each manufacturer. But in 
fact, the true relative market share is proportional only to the height of the bars. 
Sometimes we do not need to manipulate the graph to distort the impres- 
sion it creates. Modifying the verbal description that accompanies the graph can 
change the interpretation that will be made by the viewer. Figure 2.41 provides a 
good illustration of this ploy. 
F I G U R E  2.41 
Production continues to 
For our production, we need not even 
change the chart, so we can't be 
accused of fudging the data. Here 
we'll vmply change the title so that 
for the Senate subcomm~ttee, we'll 
indicate that we're not dolug as well 
as in the past ... 
2000: 2nd best year for production 
whereas for the general public, we'll 
tell them that we're still in the prime 
years. 
Source: Adapted from Selazny, G. "Grappling with Graphics," Management 
Review, Oct. 1975, p. 7. 
Although we've discussed only a few of the ways that graphs can be used to 
' 
convey misleading pictures of phenomena, the lesson is clear. Look at all graphi- 
cal descriptions of data with a critical eye. Particularly, check the axes and the size 
of the units on each axis. Ignore the visual changes and concentrate on the actual 
i 
numerical changes indicated by the graph or chart. 
The information in a data set can also be distorted by using numerical de- 
scriptive measures, as Example 2.21 indicates. 
I 
-
*
=
P
m
=
r
n
 
"a"%" " 
a 
a" % -1 
S" " *"a"n"m-s 
-
"
-
-
 
Suppose you're considering working for a s 
ne that currently has 
a senior member and three junior members. You inquire about the salary you 
could expect to earn if you join the firm. unfortunately, you receive two answers: 
AnswerA: The senior member tells you that an "average employee" 
earns $67,500. 

4 
SECTION 2 . 1 1 q ~ i s t o r t i n g  t h e  Truth with Descriptive Techniques 
103 
Answer B: 
One of the junior members later tells you that an "average 
employee" earns $55,000. 
Which answer can you believe? 
S o I u t i o n The confusion exists because the phrase "average employee" has not been clearly 
defined. Suppose the four salaries paid are $55,000 for each of the three junior 
members and $1 05,000 for the senior member. Thus, 
3($55,000) + $105,000 
$270,000 
- 
Mean = 
- 
4 
= $67,500 
4 
Median = $55,000 
You can now see how the two answers were obtained. The senior member re- 
ported the mean of the four salaries, and the junior member reported the median. 
The information you received was distorted because neither person stated which 
measure of central tendency was being used. 
Another distortion of information in a sample occurs when only a measure 
of central tendency is reported. Both a measure of central tendency and a measure 
of variability are needed to obtain an accurate mental image of a data set. 
Suppose you want to buy a new car and are trying to decide which of two mod- 
els to purchase. Since energy and economy are both important issues, you decide to 
purchase model A because its EPA mileage rating is 32 miles per gallon in the city, 
whereas the mileage rating for model B is only 30 miles per gallon in the city. 
However, you may have acted too quickly. How much variability is associ- 
ated with the ratings? As an extreme example, suppose that further investigation 
reveals that the standard deviation for model A mileages is 5 miles per gallon, 
whereas that for model B is only 1 mile per gallon. If the mileages form a mound- 
shaped distribution, they might appear as shown in Figure 2.42. Note that the 
larger amount of variability associated with model A implies that more risk is in- 
volved in purchasing model A. That is, the particular car you purchase is more 
likely to have a mileage rating that will greatly differ from the EPA rating of 
32 miles per gallon if you purchase model A, while a model B car is not likely to 
vary from the 30-miles-per-gallon rating by more than 2 miles per gallon. 
Mileage distributions for 
two car models 
Mileage distribution 
ileage distribution 
PB PA 
We conclude this section with another example on distorting the truth with 
numerical descriptive measures. 

104 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
, 3 .+ 
- 
S T A T I S T I C S  I N  L h ? ? h ~  
Car & Driver's "Road Test Diges 
P 
eriodically, Car & Driver magazine conducts compre- 
hemive road tests on all new car models. The results of 
the tests are reported in Car & Driver's "Road Test Digest." 
The "Road Test Digest" includes the following variables for 
each new car tested: 
1. Model 
2. List price ($) 
3. Elapsed time from 0 to 60 mph (seconds) 
4. Elapsed time for mile at full throttle (seconds) 
5. Maximum speed (mph) 
6. Braking distance from 70 to 0 mph (feet) 
F o c u s  
The "Road Test Digest" data from the July 1998 issue of 
Car & Driver is available on the data disk that accompanies 
this text. The name of the file containing the data is 
CAR.DAT. Your assignment is to completely describe the 
data for Car & Driver magazine. Are there any trends in the 
data? What are typical values of these variables that a new 
car buyer can expect? Are there any new car models that 
have exceptional values of these variables? Are there any 
relationships among the variables? Your summary results 
will be reported in a future issue of the magazine. 
7. EPA-estimated city fuel economy (mpg) 
8. Road-holding (grip) during cornering (gravitational 
force, in g's) 
organization. Consider the following three reported results of the CDF survey. 
Reported result 1: 25 percent of the 16- and 17-year-olds in the Portland, 
Maine, Bayside East Housing Project were out of school. Fact: Only eight 
children were .\urveyed; two were found to he out of school. 
Reported result 2: Of all the secondary school students who had been sus- 
pended more than once in census tract 22 in Columbia, South Carolina, 33% 
had been suspended two times and 67% had been suspended three or more 
times. Fact: CDF found only three children in that entire census tract who had 
been suspended; one child was suspended twice and the other two children, 
three or more times. 
Reported result 3: In the Portland Bayside East Housing Project, 50% of all 
the secondary school children who had been suspended more than once 
had been suspended three or more times. Fact: The survey found two sec- 
ondury school children had been suspended in that area; one of them had 
been suspended three or more times. 
Identify the potential distortions in the results reported by the CDF. 
e. " 
S o I u t i o n In each of these examples the reporting of percentages (i.e., relative frequencies) 
instead of the numbers themselves is misleading. No inference we might draw 
from the cited examples would be reliable. (We'll see how to measure the 
reliability of estimated percentages in Chapter 5.) In short, either the report 
should state the numbers alone instead of percentages, or, better yet, it should 
state that the numbers were too small to report by region. If several regions were 
combined, the numbers (and percentages) would be more meaningful. 
'I 

(I 
L a n g u a g e  L a b  
105 
Key Terms 
Note Starred (*) items are from the 
oprmnal sectLon5 In this chapter 
Bar graph 28 
B~variate relationship* 94 
Box plots* 84 
Central tendency 52 
Chebyshev's Rule 70 
Cld55 26 
Cla~s frequency 26 
Clas relatwe frequency 27 
Dot plot 36 
Empmcal Rule 71 
H~nges* 85 
H~stogram 38 
Inner fencesx 85 
Interquartde range* 85 
Lower quart~le* 85 
Mean 52 
Mcasurement classes 38 
Measures of central tendency 52 
Measures of relative standing 78 
Measures of variability or spread 52 
Median 54 
Middlc quartile* 85 
Modal class 57 
Mode 57 
Mound-shaped distribution 70 
Numerical descriptive measures 52 
Outer fences* 85 
Outliers* 84 
Pareto diagram 31 
Percentile 79 
Pie chart 28 
Quartiles* 84 
Range 63 
Rare-event approach* 90 
Relative frequency histogram 38 
Scattergram* 94 
Scatterplot* 94 
Skewness 56 
Standard deviation 66 
Stem-and-leaf display 37 
Symmetric distribution 56 
Time series data* 98 
Time series plot* 98 
Upper quartile* 85 
Variance 65 
Whiskers* 85 
z-score 80 
.................................................................................................................................................................................................................................................
Key Formulas 
(Class frequency) 
Class relative frequency 27 
II 
Sample mean 52 
Sample standard deviation 66 
Sample z-score 80 
x - P 
z =- 
Population z-score 80 
u 
IQR = Qu - QL 
Interquartile range 85 
Symbol 
Pronunciation 
Description 
....................................................................................................................................................................................................................................
n 
... 
2 
sum of 
Summation notation; 
x, represents the sum of the measurements XI, x2, 
, X, 
r=l 
P 
mu 
Population mean 
- 
x 
x-bar 
Sample mean 
u2 
sigma squared 
Population variance 
u 
sigma 
Population standard deviation 
S! 
Sample variance 
s 
Sample standard deviation 
z-score for a measurement 
nl 
Median (middle quartile) of a sample data set 

106 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets of D a t a  
QL 
Lower quartile (25th percentile) 
Qu 
Upper quartile (75th percentile) 
IQR 
Interquartile range 
Starred (*) exercises are from the optional sections in th~s 
chapter. 
Learning the Mechanics 
2.89 
Construct a relative frequency histogram for the data 
summarized in the accompanying table. 
Measurement 
Class 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.OO-.75 
.75-1.50 
1.50-2.25 
2.25-3.00 
3.00-3.75 
3.75-4.50 
4.50-5.25 
Relative 
Frequency 
. . . . . . . . . . . . . . . . . . . . 
.02 
.01 
.03 
.05 
.10 
.14 
.19 
Measurement 
Class 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
5.25-6.00 
6.00-6.75 
6.75-7.50 
7.50-8.25 
8.25-9.00 
9.00-9.75 
Relative 
Frequency 
. . . . . . . . . . . . . . . . . . . . . 
.15 
.12 
.09 
.05 
.04 
.01 
2.90 Discuss the conditions under which the median is pre- 
ferred to the mean as a measure of central tendency. 
2.91 Consider the following three measurements: 50, 70, 
80. Find the z-score for each measurement if they are 
from a population with a mean and standard devia- 
tion equal to 
a. p = 60, u = 10 b. p = 50, u = 5 
c. p = 40, u = 10 d. p = 40, u = 100 
2.92 If the range of a set of data is 20, find a rough approx- 
imation to the standard deviatmn ot the data sct. 
2.93 For each of the following data sets, compute i, 
s2, and s: 
a. 13,1,10,3,3 
b. 13,6,6,0 
c. 1,0,1,10,11,11,15 d. 3,3,3,3 
2.94 For each of the following data sets, compute i, 
s2, and 
s. If appropriate, specify the un~ts in which your 
answers are expressed. 
a. 4,6,6,5,6,7 b. -$I, $4, -$3, $0, -$3, -$6 
c. %%,%%,2/5%, 
1/5%, Xh%, 
d. Calculate the range of each data set in parts a-c. 
2.97 
2.95 Explain why we generally prefer the standard devia- 
tion to the range as a measure of variability for quan- 
titative data. 
Applying the Concepts 
2.96 U.S. manufacturing executives frequently complain 
about the high cost of labor in this country. While it 
may be high relative to many Pacific Rim and South 
Hourly Manufacturing Labor Rates 
Country 
(in German marks) 
Germany 
43.97 
Switzerland 
41.47 
Belgium 
37.35 
Japan 
36.01 
Austria 
35.19 
Netherlands 
34.87 
Sweden 
31.00 
France 
28.92 
United States 
27.97 
Italy 
27.21 
Ireland 
22.17 
Britain 
22.06 
Spain 
20.25 
Portugal 
9.10 
Source. The New York Times, October 15,1995, p. 10. 
a. What percentage of countries listed in the table 
have a higher wage rate than the United States? A 
lower wage rate than the United States? 
b. As of July 5,1996, one German mark was worth .65 
U.S. dollars (The Wall Street Journal, July 8,1996). 
Convert the data set to U.S. dollars and use the data 
set to answer the remaining parts of this exercise. 
c. What is the mean hourly wage for the 13 Western 
countries listed in the table? For all 14 countries? 
d. Find s2 and s for all 14 countries. 
e. According to Chebyshev's Rule, what percentage 
of the measurements in the table would you expect 
to find in the intervals 2 f .75s, 2 f 2.5s, Y i 
4s? 
f. What percentage of measurements actually fall in 
the intervals of part e? Compare your results with 
those of part e. 
Beanie Babies are toy stuffed animals that have , 
become valuable collector's items since the introduc- 
tion of Ally the Alligator in 1994. Beanie World 
Magazine provided the information (page 107) on 50 
1 
Beanie Babies. 
a. Summarize the retiredlcurrent status of the 50 
Beanie Babies with an appropriate graph. Interpret 
the graph. 
b. Summarize the values of the 50 Beanie Babies with 
an appropriate graph. Interpret the graph. 
American countries, the table indicates that among 
*c. Use a graph to portray the relationship between a 
Western countries, US. labor costs are relatively low. 
Beanie Baby's value and its age. Do you detect a trend? . 

S u p p l e m e n t a r y  E x e r c i s e s  
BEANIE.DAT 
........................................................................................................................................................................ 
Age (Months) 
Retired (R) 
Name 
as of Sept. 1998 
Current (C) 
Value ($) 
........................................................................................................................................................................ 
1. Ally the Alligator 
2. Batty the Bat 
3. Bongo thc Brown Monkey 
4. Blackie the Bear 
5. Bucky thc Beaver 
6. Bumble the Bee 
7. Crunch the Shark 
8. Congo the Gorilla 
9. Derby the Coarse Mained Horse 
10. Digger the Red Crab 
11. Echo the Dolphin 
12. Fetch the Golden Retriever 
13. Early the Robin 
14. Fhp the Wh~tc Cat 
15. Gdrc~a the Teddy 
16. Happy the Hippo 
17. Grunt the Razorback 
18. Gigi the Poodle 
19. Goldie the Goldfish 
20. Iggy the Iguana 
21. Inch the Inchworm 
22. Jake the Mallard Duck 
23. Kiwi the Toucan 
24. Kuku the Cockatoo 
25. M~stic the Unicorn 
26. Me1 the Koala Bear 
27. Nanook the Husky 
28. Nuts the Squirrel 
29. Peace the Tie Died Teddy 
30. Patty the Platypus 
31. Quacker the Duck 
32. Puffer the Penguin 
33. Princess the Bear 
34. Scottie the Scottie 
35. Rover the Dog 
36. Rex the Tyrannosaurus 
37. Sly the Fox 
38. Shther the Snake 
39. Sk~p 
the Siamese Cat 
40. Splash the Orca Whale 
41. Spooky the Ghost 
42. Snowball the Snowman 
43. Stmger the Scorpion 
44. Spot the Dog 
45. Tank the Armadillo 
46. Stripes the Tiger (GoldIBlack) 
47. Teddy the 1997 Holiday Bear 
48. Tuffy the Terrier 
49. Tracker the Basset Hound 
50. Zip the Black Cat 
So~lrce: Beanie World Magazine, Sept. 1998. 
2.98 Consumer Reports, published by Consumers Union, is 
of 46 brands of toothpaste (Consumer Reports, Sept. 
a magazine that contains ratings and reports for con- 
1992). Each was rated on: package design, flavor, 
sumers on goods, services, health, and personal 
cleaning ability, fluoride content, and cost per month 
finances. Consumers Union reported on the testing 
(a cost estimate based on brushing with half-inch of 

108 
CHAPTER 
2 
M e t h o d s  f o r  D e s c r i b i n g  Sets of D a t a  
- 
toothpaste twice daily). The data shown below are 
costs per month for the 46 brands. Costs marked by 
an asterisk represent those brands that carry the 
American Dental Association (ADA) seal verifying 
effective decay prevention. 
a. Use a statistical software package to construct a 
stem-and-leaf display for the data. 
b. Circle the individual leaves that represent those 
brands that carry the ADA seal. 
c. What does the pattern of circles suggest about the 
costs of those brands approved by the ADA? 
2.99 A manufacturer of industrial wheels is losing many 
profitable orders because of the long time it takes the 
firm's marketing, engineering, and accounting depart- 
ments to develop price quotes for potential customers. 
To remedy this problem the firm's management 
would like to set guidelines for the length of time each 
department should spend developing price quotes.To 
help develop these guidelines, 50 requests for pri~e 
quotes were randomly selected from the set of all 
price quotes made last year; the processing time (in 
days) was determined for each price quote for each 
department. These times are displayed in the table 
below. The price quotes are also classified by whether 
they were "lost" (i.e., whether or not the customer 
placed an order after receiving the price quote). 
a. MINITAB stem-and-leaf displays for each of the 
departments and for the total processing time are 
givcn on pg. 109. Note that the units of the leaves 
for accounting and total processing times are units 
(1.0), while the leaf units for marketing and engi- 
neering processing times are tenths (.I). Shade the 
leavcs that correspond to "lost" orders in each of 
the displays, and interpret each of the displays. 
b. Using your results from part a, develop "maximum 
processing time" guidelines for each department 
that, if followed, will help the firm reduce the num- 
ber of lost orders. 
Request 
Number 
Marketing 
Engineering 
Accounting 
Lost? 
Request 
Number 
Marketing 
Engineering 
Accounting 
Lost? 
.1 
No 
.1 
No 
.6 
No 
.8 
Yes 
.5 
No 
.1 
No 
.1 
No 
3.8 
No 
.5 
No 
.8 
No 
.1 
No 
1 .o 
No 
.8 
No 
1.0 
No 
3.7 
No 
.1 
No 
.2 
Yes 
.3 
No 
.4 
No 
22.0 
No 
1.7 
No 
.1 
No 
30.0 
Yes 
.1 
No 
2.3 
No 
.5 
No 
.2 
No 
.5 
No 
2.2 
Yes 
.1 
No 
3.3 
No 
2.0 
No 
10.5 
Yes 
8.4 
No 
.4 
No 
18.2 
Yes 
.3 
No 
.4 
No 
7.0 
Yes 
14.4 
No 
5.8 
No 
.3 
No 
.1 
No 
9.9 
Yes 
3.2 
No 
6.2 
No 
13.5 
Yes 
.1 
No 
1.9 
Yes 
2.0 
No 

MINITAB Output for Exercise 2.99 
Stem-and-leaf of MKT 
N = 50 
Leaf Unit = 0.10 
6 
0 112446 
7 
1 3  
14 
2 0024699 
16 
3 25 
22 
4 001577 
(10) 
5 0344556889 
18 
6 0002224799 
8 
7 0038 
4 
8 07 
2 
9 
2 
10 0 
1 
11 0 
Stem-and-leaf of ENG 
N = 50 
Leaf Unit = 0.10 
& 
S u p p l e m e n t a r y  E x e r c i s e s  
109 
Stem-and-leaf of ACC 
N = 50 
Leaf Unit = 1.0 
Stem-and-leaf of TOTAL 
N = 50 
Leaf Unit = 1.0 
2.100 Refer to Exercise 2.99. Summary statistics for the pro- 
b. Calculate the maximum processing time corre- 
cessing times are given in the MINITAB printout below. 
sponding to a z-score of 3 for each of the depart- 
a. Calculate the z-score corresponding to the maxi- 
ments. What percentage of the orders exceed these 
mum processing time guideline you developed in 
guidelines? How does this agree with Chebyshev's 
Exercise 2.99 for each department, and for the 
Rule and the Empirical Rule? 
total processing time. 
c. Repeat part b using a z-score of 2. 
MINITAB Output for Exercise 2.100 
N 
MKT 
50 
ENG 
50 
ACC 
5 0 
TOTAL 
5 0 
MIN 
MKT 
0.100 
ENG 
0.400 
ACC 
0.100 
TOTAL 
1.800 
MEAN 
4.766 
5.044 
3.652 
13.462 
MAX 
11.000 
14.400 
30.000 
36.200 
MEDIAN 
5.400 
4.500 
0.800 
13.750 
Q 1 
2.825 
1.775 
0.200 
8.075 
TRMEAN 
STDEV 
SEMEAN 
4.732 
2.584 
0.365 
4.798 
3.835 
0.542 
2.548 
6.256 
0.885 
13.043 
6.820 
0.965 

110 
CHAPTER 
2 M e t h o d s  f o r  D e s c r i b i n g  
d. Compare the percentage of "lost" quotes with 
corresponding times that exceed at least one of 
the guidelines in part b to the same percentage 
using the guidelines in part c. Which set of guide- 
lines would you recommend be adopted? Why? 
*2.101 A time series plot similar to the one shown here 
appeared in a recent advertisement for a well- 
known golf magazine. One person might interpret 
the plot's message as the longer you subscribe to the 
magazine, the better golfer you should become. 
Another person might interpret it as indicating that 
if you subscribe for 3 years, your game should 
improve dramatically. 
1 
2 
3 
Length of subscription 
(years) 
a. Explain why the plot can be interpreted in more 
than one way. 
b. How could the plot be altered to rectify the cur- 
rent distortion? 
2.102 A company has roughly the same number of people 
in each of fivc departments: Production, Sales, R&D, 
Maintenance, and Administration. The following 
table lists the number and type of major injuries that 
occurred in each departmcnt last year. 
IN.JURY.DAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Type of Injury 
Department 
Number of Injuries 
Burn 
Production 
3 
Maintenance 
6 
Back strain 
Production 
2 
Sales 
1 
R&D 
1 
Maintenance 
5 
Administration 
2 
Eye damage 
Production 
1 
Maintenance 
2 
Administration 
1 
Deafness 
Production 
1 
Cuts 
Production 
4 
Sales 
1 
R&D 
1 
Maintenance 
10 
Broken arm 
Production 
2 
Maintenance 
2 
Broken leg 
Sales 
1 
Maintenance 
1 
Broken finger 
Administration 
1 
Concussion 
Maintenance 
3 
Administration 
1 
Hearing loss 
Maintenance 
2 
S e t s  o f  D a t a  
a. Construct a Pareto diagram to identify which depart- 
ment or departments have the worst safety record. 
b. Explodc the Pareto diagram of part a to identify 
the most prevalent type of injury in the depart- 
ment with the worst safety record. 
2.103 In some locations, radiation levels in homes are mea- 
sured at well above normal background levels in the 
environment. As a result, many architects and 
builders are making design changes to ensure ade- 
quate air exchange so that radiation will not be 
"trapped" in homes. In one such location, 50 homes' 
levels were measured. and the mean level was 
10 parts per billion (ppb), the median was 8 ppb, and 
the standard deviation was 3 ppb. Background levels 
in this location are at about 4 ppb. 
a. Based on these results, is the distribution of the 50 
homes' radiation levels symmetric, skewed to the 
left, or skewed to the right'? Why? 
b. Use both Chebyshev's Rule and the Empirical 
Rule to describe the distribution of radiation lev- 
els. Which do you think is most appropriate in this 
case? Why? 
c. Use the results from part b to approximate the 
number of homes in this sample that have radia- 
tion levels above the background level. 
d. Suppose another home is measured at a location 
10 miles from the one sampled, and has a level of 
20 ppb. What is the z-score for this measurement 
relative to the 50 homes sampled in the other loca- 
tion? Is it likely that this new measurement comes 
from the same distribution of radiation levels as 
the other 50? Why'? How would you go about con- 
firming your conclusion? 
2.104 The accompanying table lists the unemployment rate 
in 1997 tor a sample of nine countries. 
I 
Country 
Percent Unemployed 
Australia 
Canada 
France 
Germany 
Great Britain 
Italy 
Japan 
Sweden 
United States 
Source: Statistical Abstract of the United 
States: 1998, p. 842. 
a. Find the mean and median unemployment rate in 
the sample. Interpret these values. 
b. Find the standard deviation of the unemployment 
rate in the sample. 
c. Calculate the z-scores of the unemployment rates 
of the United States and France. 

d. Describe the information conveyed by the sign 
(positive or negative) of the z-scores you calcu- 
lated in part c. 
2.105 Forbes magazine (Jan. 11,1999) reported the finan- 
cial standings of each team in the National 
Football League (NFL). The next table lists cur- 
rent team value (without deduction for debt, 
except stadium debt) and operating income for 
each team in 1998. 
a. Use a statistical software package to construct a 
stem-and-leaf plot for an NFL team's current value. 
h. Does the distribution of current values appear to 
be skewed? Explain. 
c. Use the stem-and-leaf plot of part a to find the 
median of the current values. 
d. Calculate the z-scores for the Denver Broncos cur- 
rent value and operating income. 
c. Interpret the two z-scores of part d. 
f. Which other NFL teams have positive current 
value z-scores and negative operating income 
z-scores? 
". Identify any outliers in the current value data set. 
*h. Construct a graph to investigate a possible trend 
between an NFL team's current value and its op- 
erating income. What do you observe? 
*2.106 If not examined carefully, the graphical description 
of U.S. peanut production shown at the bottom of 
the page can be misleading. 
a. Explain why the graph may mislead some readers. 
h. Construct an undistorted graph of U.S. peanut 
production for the given years. 
2.107 A study by the U.S. Public Research Interest Group 
found that in Massachusetts bank customers were 
charged lower fees than the national average for reg- 
ular checking accounts, NOW accounts, and savings 
accounts. For regular checking accounts the 
Massachusetts mean was $190.06 per year, while the 
national mean was $201.94 (Boston Globe, Aug. 9, 
1995). The referenced article did not explain how 
these averages were determined other than to say the 
e 
S u p p l e m e n t a r y  E x e r c i s e s  
111 
NFLVALUE.DAT 
........................................................................................................ 
Current 
Operating 
Team 
Value 
Income 
(9 millions) 
($ millions) 
........................................................................................................... 
Dallas Cowboys 
663 
56.7 
Washington Redskins 
607 
48.8 
Tampa Bay Buccaneers 
502 
41.2 
Carolina Panthers 
488 
18.8 
New England Patriots 
460 
13.5 
Miami Dolphins 
446 
32.9 
Denver Broncos 
427 
5.0 
Jacksonville Jaguars 
419 
29.3 
Baltimore Ravens 
408 
33.2 
Seattle Seahawks 
399 
6.4 
Pittsburgh Steelers 
397 
15.5 
Cincinnati Bengals 
394 
3.4 
St. LOUIS 
Rams 
390 
33.2 
New York Giants 
376 
25.2 
San Francisco 49ers 
371 
12.7 
Tennessee Titans 
369 
4.1 
New York Jets 
363 
12.1 
Kansas City Chiefs 
353 
31.0 
Buffalo Bills 
326 
10.7 
San Diego Chargers 
323 
8.2 
Green Bay Packers 
320 
16.4 
Philadelphia Eagles 
318 
19.1 
New Orleans Saints 
315 
11.3 
Chicago Bears 
313 
19.7 
Minnesota Vikings 
309 
5.1 
Atlanta Falcons 
306 
16.8 
Indianapolis Colts 
305 
15.8 
Arizona Cardmals 
301 
10.6 
Oakland Raiders 
299 
17.3 
Detroit Lions 
293 
16.4 
Source: Forbes, Jan. 11,1999 
national average was estimated from a sample of 271 
banks in 25 states. Prepare a report that explains in 
detail how Massachusetts' mean could have been esti- 
mated. There are 245 banks in Massachusetts. Your 
answer should include a sampling plan, a measure- 
ment plan, and a calculation formula. 
US. Peanut ProductLon* 
(in bill~on\ of pounds) 
4.1 

112 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets of D a t a  
2.108 The U.S. Federal Trade Commission has recently 
begun assessing fines and other penalties against 
weight-loss clinics that make unsupported or mis- 
leading claims about the effectiveness of their pro- 
grams. Brochures from two weight-loss clinics both 
advertise "statistical evidence" about the effective- 
ness of their programs. Clinic A claims that the mean 
weight loss during the first month is 15 pounds; Clinic 
B claims a median weight loss of 10 pounds. 
a. Assuming the statistics are accurately calculated, 
which clinic would you recommend if you had no 
other information? Why? 
b. Upon further research, the median and standard 
deviation for Clinic A are found to be 10 pounds 
and 20 pounds, respectively, while the mean and 
standard deviation for Clinic B are found to be 10 
and 5 pounds, respectively. Both are based on sam- 
ples of more than 100 clients. Describe the two 
clinics' weight-loss distributions as completely as 
possible given this additional information. What 
would you recommend to a prospective client 
now? Why? 
c. Note that nothing has been said about how the 
sample of clients upon which the statistics are 
based was selected. What additional information 
would be important regarding the sampling tech- 
niques employed by the clinics? 
2.109 The Baltimore Orioles had the highest player payroll 
in Major League Baseball (MLB) in 1998 while the 
Tampa Bay Devil Rays (an expansion team) had one 
of the lowest payrolls. The 1998 salaries for the ros- 
tered players on these two MLB teams were analyzed 
using SPSS. The SPSS histograms for each data set 
are displayed in the right column. 
a. Compare the two histograms. Do you detect any dif- 
ferences in the shapes of the distributions? Skew- 
ness? 
b. Interpret the descriptive statistics shown on the 
SPSS printouts. 
2.110 The Age Discrimination in Employment Act mandates 
that workers 40 years of age or older be treated without 
regard to age in all phases of employment (hiring, pro- 
motions, firing, etc.). Age discrimination cases are of 
two types: disparate treatment and disparate impact. In 
the former, the issue is whether workers have been 
intentionally discriminated against. In the latter, the 
issue is whether employment practices adversely affect 
the protected class (i.e., workers 40 and over) even 
though no such effect was intended by the employer 
(Zabel, 1989). A small computer manufacturer laid off 
10 of its 20 software engineers. The ages of all engineers 
at the time of the layoff are listed in the next table. 
Analyze the data to determine whether the company 
may be vulnerable to a disparate impact claim. 
LAYOFEDAT 
Notlaid off: 34 55 42 38 42 32 40 40 46 
29 
Laidoff: 
52 35 40 41 40 39 40 64 47 44 
SPSS Histogram of the BALTIMORE Salaries, Ex. 2.109 
I 
1 
Std. Dev. = 2222.79 
Mean = 2685.2 
N = 28.00 
0.0 
2000.0 
4000.0 
6000.0 
1000.0 
3000.0 
5000.0 
7000.0 
SAL1000 
Salary (thousands) 
SPSS Histogram of the TAMPA BAY Salaries, Ex. 2.109 
Std. Dev. = 1349.45 
Mean = 830.7 
N = 33 .OO 
5 0 0  
1 5 0 0 . 0  
2500.0 
3500.0 
4500.0 5500.0 
SALlOOO 
Salary (thousands) . 
*2.111 A national chain of automobile oil-change franchis- 
es claims that "your hood will be open for less than 
12 minutes when we service your car." To check 
their claim, an undercover consumer reporter from 
a local television station monitored the "hood time" 
of 25 consecutive customers at one of the chain's 
franchises. The resulting data are shown on p. 113. 
Construct a time series plot for these data and 
describe in words what it reveals. 
The automobile sales in the United States (in thou- 
sands of cars) for the "Big Three" U.S. manufactur- 
ers (Ford, General Motors, and Chrysler), European 
manufacturers, and Japanese manufacturers for 
1995 are reported in the table on p.113. 

S u p p l e m e n t a r y  Exercises 
113 * 
HOODTIME.DAT 
................................................ 
Customer 
Hood Open 
Number 
(Minutes) 
Customer 
Hood Open 
Number 
(Minutes) 
a. Construct a relative frequency bar graph for these 
data. 
b. Stacking is the combining of all bars in a bar graph 
into a single bar. by drawing one on top of the other 
and distinguishing one from another by the use of 
colors or patterns. Stack the relative frequencies of 
the five car manufacturers' sales. 
c. What information about the U.S. automobile mar- 
ket is reflected in your graph of part a? 
CARSALES.DAT 
la ................................................... 
Manufacturer 
Sales 
General Motors 
229.7 
Ford 
131.2 
Chrysler 
58.3 
Japanese 
192.6 
European 
37.0 
Total 
648.8 
So~~rce: 
Wall Street Journal, 
December 6,1995, p. BS. 
d. What share of the US. automobile market has 
been captured by US. manufacturers'? 
2.113 Computer anxiety is defined as "the mixture of fear, 
apprehension, and hope that people feel when plan- 
ning to interact, or when interacting with a comput- 
er." Researchers have found computer anxiety in 
people at all levels of society, including students, doc- 
tors, lawyers, secretaries, managers, and college pro- 
fessors. One profession for which little is known 
about the level and impact of computer anxiety is sec- 
ondary technical education (STE).The extent of com- 
puter anxiety among STE teachers was investigated 
in the Journal of Studies in Technical Careers (Vol. 15, 
1995). A sample of 116 teachers were administered 
the Computer Anxiety Scale (COMPAS) designed to 
measure level of computer anxiety. Scores, ranging 
from 10 to 50, were categorized as follows: very anx- 
ious (37-50); anxiousltense (33-36); some mild anxi- 
ety (27-32); generally relaxed/comfortable (20-26); 
very relaxedlconfident (10-19). A summary of the 
COMPAS anxiety levels for the sample is provided in 
the table at the bottom of the page. 
a. Graph and interpret the results. 
b. One of the objectives of the research is to com- 
pare the computer anxiety levels of male and fe- 
male STE teachers. Use the summary information 
in the table below to make the comparison. 
Male Teachers 
Female Teachers 
All Teachers 
Source: Gordon, H .  R. D. "Analysis of the computer anxiety levels 
of secondary technical education teachers in West Virginia." 
.lournu1 0fStudic.s in Technical Careers, Vol. 15, No. 2,1995, 
pp. 26-27 (Table 2). 
Score 
Relative 
Category 
Range 
Frequency 
Frequency 
........................................................................................................................................................ 
Verv anxious 
37-50 
22 
.19 
Anxiousltense 
33-36 
8 
.07 
Some m~ld anxiety 
27-32 
23 
.20 
Generally relaxed1 comfortable 
20-26 
24 
.21 
Very relaxedlconhdent 
10-19 
39 
.33 
Totals 
116 
1.00 
Source Gordon, H. R. D. "Analysis of the computer anxiety levels of secondary technical 
educat~on teachers In West V~rgma." Journal of Stur1lc.s In Technical Careers, Vol. 15, No. 2, 
1995, pp. 26-27 (Table 1). 

114 
CHAPTER 2 
M e t h o d s  f o r  D e s c r i b i n g  Sets o f  D a t a  
eal-World Case The Kentucky Milk Case-Part 1 
(A Case Covering Chapters 1 and 2) 
M 
any products and services are purchased by gov- 
ernments, cities, states, and businesses on the basis 
of sealed bids, and contracts are awarded to the 
lowest bidders. This process works extremely well in com- 
petitive markets, but it has the potential to increase the cost 
of purchasing if the markets are noncompetitive or if collu- 
sive practices are present. An investigation that began with 
a statistical analysis of bids in the Florida school milk mar- 
ket in 1986 led to the recovery of more than $33,000,000 
from dairies who had conspired to rig the bids there in the 
1980s. The investigation spread quickly to other states, and 
to date settlements and fines from dairies exceed 
$100,000,000 for school milk bidrigging in twenty other 
states. This case concerns a school milk bidrigging investi- 
gation in Kentucky. 
Each year, the Commonwealth of Kentucky invites bids 
from dairies to supply half-pint containers of fluid milk 
products for its school districts. The products include whole 
white milk, low-fat white milk, and low-fat chocolate milk. 
In 13 school districts in northern Kentucky, the suppliers 
(dairies) were accused of "price-fixing," that is, conspiring 
to allocate the districts, so that the "winner" was predeter- 
mined. Since these districts are located in Boone, Camp- 
bell, and Kenton counties, the geographic market they 
represent is designated as the "tri-county" market. Between 
1983 and 1991, two dairies-Meyer 
Dairy and Trauth 
Dairy-were 
the only bidders on the milk contracts in the 
school districts in the tri-county market. Consequently, 
these two companies were awarded all the milk contracts in 
the market. (In contrast, a large number of different dairies 
won the milk contracts for the school districts in the re- 
mainder of the northern Kentucky market-called 
the 
"surrounding" market.) The Commonwealth of Kentucky 
alleged that Meyer and Trauth conspired to allocate the dis- 
tricts in the tri-county market. To date, one of the dairies 
(Mcyer) has admitted guilt, while the other (Trauth) stead- 
fastly maintains its innocence. 
The Commonwealth of Kentucky maintains a database 
on all bids received from the dairies competing for the milk 
contracts. Some of these data have been made available to 
you to analyze to determine whether there is empirical ev- 
idence of bid collusion in the tri-county market. The data, 
available in ASCII format on a 3.5" diskette, is described in 
detail below. Some background information on the data 
and important economic theory regarding bid collusion is 
also provided. Use this information to guide your analysis. 
Prepare a professional documcnt which presents the results 
of your analysis and gives your opinion regarding collusion. 
DATA. ASCII file name: MILK.DAT 
Number of observations: 392 
................................................................................................ 
...... 
Variable 
Column(s) Type 
Description 
.......................................................................................................... 
YEAR 
1-4 
MARKET 
6-15 
WINNER 
17-30 
WWBID 
32-38 
WWQTY 
4046 
LFWBID 
48-53 
LFWQTY 
55-62 
LFCBID 
64-69 
LFCQTY 
71-78 
DISTRICT 
80-82 
KYFMO 
84-89 
MILESM 
91-93 
MILEST 
95-97 
LETDATE 
99-106 
Year in which milk contract 
awarded 
Northern Kentucky Market 
(TRI-COUNTY 
or SURROUND) 
Name of winning dairy 
Winning bid price of whole 
white milk (dollars per 
half-pint) 
Quantity of whole white 
milk purchased (number of 
half-pints) 
Winning bid price of low-fat 
white milk (dollars per 
half-pint) 
Quantity of low-fat white 
milk purchased (number of 
half-pints) 
Winning bid price of low-fat 
chocolate milk (dollars per 
half-pint) 
Quantity of low-fat 
chocolate milk purchased 
(number of half-pints) 
School district number 
FMO minimum raw cost of 
milk (dollars per 
half-pint) 
Distance (miles) from 
Meyer processing plant to 
school district 
Distance (miles) from 
Trauth processing plant to 
school district 
Date on which bidding on 
milk contract began 
(monthldaylyear) 
BACKGROUND INFORMATION 
Collusive Market Environment. 
Certain economic features of a market create an envi- 
ronment in which collusion may be found. These basic fea- 
tures include: 
1. Few sellers and high concentration. Only a few dairies con- 
trol all or nearly all of the milk business in the market. 

& 
R e a l - W o r l d  C a s e  
115 
2. Homogeneous products. The products sold are essential- 
ly the same from the standpoint of the buyer (i.e., the 
school district). 
3. Inelastic demand. Demand is relatively insensitive to 
price. (Note: The quantity of milk required by a school 
district is primarily determined by school enrollment, 
not price.) 
5. Similar costs. The dairies bidding for the milk contracts 
face similar cost conditions. (Note: Approximately 60% 
of a dairy's production cost is raw milk, which is federal- 
ly regulated. Meyer and Trauth are dairies of similar size 
and both bought their raw milk from the same supplier.) 
Although these market structure characteristics create 
an environment which makes collusive behavior easier, they 
do not necessarily indicate the existence of collusion. An 
analysis of the actual bid prices may provide additional in- 
formation about the degree of competition in the market. 
Collusive Bidding Patterns. The analyses of patterns in 
sealed bids reveal much about the level of competition, or 
lack thereof, among the vendors serving the market. Con- 
sider the following bid analyses: 
1. Market shares. A market share for a dairy is the number 
of milk half-pints supplied by the dairy over a given 
school year, divided by the total number of half-pints 
supplied to the entire market. One sign of potential col- 
lus~ve behavior is stable, nearly equal market shares 
over time for the dairies under investigation. 
2. Incumbency rates. Market allocation is a common form 
of collusive behavior in bidrigging conspiracies. Typical- 
ly, the same dairy controls the same school districts ycar 
after year.The incumbency rate for a market in a given 
school year is defined as the percentage of school dis- 
tricts that are won by the same vendor who won the pre- 
vious year. An incumbency rate that exceeds 70% has 
been considered a sign of collusive behavior. 
3. Bid levels and dispersion. In competitive sealed bid mar- 
kets vendors do not share information about their bids. 
Consequently, more dispersion or variability among the 
bids is observed than in collusive markets, where ven- 
dors communicate about their bids and have a tendency 
to submit bids in close proximity to one another in an at- 
tempt to make the bidding appear competitive. Further- 
more, in competitive markets the bid dispersion tends to 
be directly proportional to the level of the bid: When 
bids are submitted at relatively high levels, there is more 
variability among the bids than when they are submitted 
at or near marginal cost, which will be approximately 
the same among dairies in the same geographic market. 
4. Price versus cost/distance. In competitive markets, bid 
prices are expected to track costs over time. Thus, if the 
market is competitive, the bid price of milk should be 
highly correlated with the raw milk cost. Lack of such a 
relationship is another sign of collusion. Similarly, bid 
price should be correlated to the distance the product 
must travel from the processing plant to the school (due 
to delivery costs) in a competitive market. 
5. Bid sequence. School milk bids are submitted over the 
spring and summer months, generally at the end of one 
school year and before the beginning of the next. When 
the bids are examined in sequence in competitive mar- 
kets, the level of bidding is expected to fall as the bid- 
ding season progresses. (This phenomenon is 
attributable to the learning process that occurs during 
the season, with bids adjusted accordingly. Dairies may 
submit relatively high bids early in the season to "test 
the market," confident that volume can be picked up 
later if the early high bids lose. But, dairies who do not 
win much business early in the season are likely to be- 
come more aggressive in their bidding as the season pro- 
gresses, driving price levels down.) Constant or slightly 
increasing price patterns of sequential bids in a market 
where a single dairy wins year after year is considered 
another indication of collusive behavior. 
6. Comparison of average winning bid prices. Consider two 
similar markets, one in which bids are possibly rigged 
and the other in which bids are competitively deter- 
mined. In theory, the mean winning price in the "rigged" 
market will be significantly higher than the mean price 
in the competitive market for each year in which collu- 
sion occurs. 

3.2 
Unions and Intersection 
3.3 
Complementary Events 
3.4 
The Additive Rule and Mutually Exc 
3.5 
Conditional Probability 
.6 
The Multiplicative Rule and Independe 
3.7 
Random Sampling 
eTATIeTlb3 IIh &&TION 
3.1 
Game Show Strategy: To Switch or Not to Switch 
3.2 
Lottery Buster 
.+--q{\ 
Where We've Been - 
We've identified inference, from a sample to a popu- 
lation, as the goal of statistics. And we've seen that to 
reach this goal, we must be able to describe a set of 
measurements. Thus, we explored the use of graphi- 
cal and numerical methods for describing both quan- 
titative and qualitative data sets. 
' 
Where We're Going 
We now turn to the problem of making an inference. 
What is it that permits us to make the inferential 
jump from sample to population and then to give a 
measure of reliability for the inference? As you'll 
see, the answer is probability. This chapter is devoted 
to a study of probability-what it is and some of the 
basic concepts of the theory behind it. 

I I 2  CHAPTER 3 
Probability 
Recall that one branch of statistics is concerned with decisions about a population 
based on sample information. You can see how this is accomplished more easily if 
you understand the relationship between population and sample-a relationship 
that becomes clearer if we reverse the statistical procedure of making inferences 
from sample to population. In this chapter then, we assume that the population is 
known and calculate the chances of obtaining various samples from the popula- 
tion. Thus, we show that probability is the reverse of statistics: In probability, we 
use the population information to infer the probable nature of the sample. 
Probability plays an important role in inference-making. Suppose, for example, 
you have an opportunity to invest in an oil exploration company. Past records 
show that out of 10 previous oil drillings (a sample of the company's experiences), 
all 10 came up dry. What do you conclude? Do you think the chances are better 
than 50:50 that the company will hit a gusher? Should you invest in this company? 
Chances are, your answer to these questions will be an emphatic No. If the corn- 
pany's exploratory prowess is sufficient to hit a producing well 50% of the time, a 
record of 10 dry wells out of 10 drilled is an event that is just too improbable. 
Or suppose you're playing poker with what your opponents assure you is a 
well-shuffled deck of cards. In three consecutive five-card hands, the person on 
your right is dealt four aces. Based on this sample of three deals, do you think the 
cards are being adequately shuffled? Again, your answer is likely to be No 
because dealing three hands of four aces is just too improbable if the cards were 
properly shuffled. 
Note that the decisions concerning the potential success of the oil drilling com- 
pany and the adequacy of card shuffling both involve knowing the chance-or 
probability-of a certain sample result. Both situations were contrived so that you 
could easily conclude that the probabilities of the sample results were small. 
Unfortunately. the probabilities of many observed sample results aren't so easy to 
evaluate intuitively. For these cases we will need the assistance of a theory of 
probability. 
Let's begin our treatment of probability with simple examples that are easily 
described. With the aid of simple examples, we can introduce important defini- 
tions that will help us develop the notion of probability more easily. 
1 
Suppose a coin-is tossed once and the up face is recorded. The result we see and 
record-is called an observdon, or meusuremmt, and the process of making an 
observation is called an experiment. Notice that our definition of experiment is 
broader than the one used in the physical sciences, where you would picture test 
tubes, microscopes, and other laboratory equipment. Among other things, statisti- 
cal experiments may includc recording a customer's preference for one of two 
comp;ter operatingsystems (DOS or Macintosh), recording a change in the Dow 
 ones ~nduitrial ~ " e r a ~ e  
from one day to the next, rccording the weekly sales of 
a business firm, and counting the number of errors on a page of an accountant's 
ledger.The point is that a statistical experiment can be almost any act of observa- 
tion as long as the outcome is uncertain. 
An experiment is an act or process of observation that leads to a single outcome that 
cannot be predicted with certainty. 

SECTION 3.1 
Events, Sample Spaces, and Probability 
1 1 3 
+ 
Consider another simple experiment consisting of tossing a die and observing 
the number on the up face.The six basic possible outcomes to this experiment are: 
1. Observe a 1 
2. Observe a 2 
3. Observe a 3 
4. Observe a 4 
5. Observe a 5 
6. Observe a 6 
Note that if this experiment is conducted once, you can observe one and only 
one of these si.x basic outcomes, and the outconie cannot be predicted with certain- 
ty. Also, these possibilities cannot be decomposed into more basic outcomes. 
Because observing the outcome of an experiment is similar to selecting a sample 
from a population, the basic possible outcomes to an experiment are called sample 
points.' 
Two coins are tossed, and their up faces are recorded. List all the sample points for 
this experiment. 
bULUTlUN 
Even for a seemingly trivial experiment, we must be careful when listing the 
sample points. At first glance, we might expect three basic outcomes: Observe 
two hcads, Observe two tails. or Observe onc head and onc tail. However, further 
reflection reveals that the last of these, Observe one head and one tail, can be 
decomposed into two outcomes: Head on coin 1, Tail on coin 2; and Tail on coin 1, 
Head on coin 2.t Thus, we have four sample points: 
1. Observe HH 
2. Observe HT 
3. Observe TH 
4. Observe TT 
where H in the first position means "Head on coin 1," H in the second position 
means "Head on coin 2," and so on. 
C 
We often wish to refer to - 
the c o l l e c t i ~ a i t h e  
. . . . . . . . . . 
- sample points of an experi- 
m 2 t .  This collection is called the sample space of the experiment. For example, 
there are six sample points in the sample space associated with the die-toss exper- 
iment. The sample spaces for the experiments discussed thus far are shown in 
Table 3.1. 
*Alternatively, the term "simple event" can be used. 
tEven if the coins are identical in appearance, there are, in fact, two distinct coins.Thus, the designation 
of one coin as coin 1 and the other coin as coin 2 is legitimate in any case. 

1 14 CHAPTER 3 
Probability 
TABLE 3.1 
Experiments and Their Sample Spaces 
Experiment: Observe the up face on a coin. 
Sample space 1. Observe a head 
2. Obaerve a tail 
- 
Th~s sample space can be represented In set notation as a set containing two sample points: 
s W, TI 
where H represents the sample pomt Observe a head and T represents the sample point Observe a tad. 
a. Experiment: Observe 
the up face on a coin 
S 
b. Experiment: Observe thc 
up face on a die 
S 
c. Experiment: Observe the 
up faces on two coins 
FIGURE 3. I 
Venn diagrams for the 
three experiments 
from Table 3.1 
Experiment: Observe the up face on a die. 
Sample space: 1. Observe a 1 
2. Observe a 2 
3. Observe a 3 
4. Observe a 4 
5. Observe a 5 
6. Observe a 6 
This sample space can be represented in set notation as a set of six sample points: 
Experiment: Observe the up faces on two coins. 
Sample space: I .  Observe H H  
2. Observe H T  
3. Observe TH 
4. Observe TT 
This sample space can be represented in set notation as a set of four sample points: 
S: (HH, H1; TH, T T ]  
The sample space of an experiment is the collection of all its sample points. 
Just as graphs are useful in describing sets of data, a pictorial method for pre- 
senting the sample space will often be useful. Figure 3.1 shows such a representa- 
tion for each of the experiments in Table 3.1. In each case, the sample space is 
shown as a closed figure, labeled S, containing all possible sample points. Each 
sample point is represented by a solid dot (i.e., a "point") and labeled according- 
ly. Such graphical representations are called Venn diagrams. 
Now that we know that an experiment will result in only one basic outcome- 
called a sample point-and that the sample space is the collection of all possible 
sample points, we're ready to discuss the probabilities of the sample points. You've 
undoubtedly used the term probability and have some intuitive idea about its 
meaning. Probability is generally used synonymously with " c m e , "  "odds," and 
similar concepts. For example, if a fair coin is tossed, we might reason that both the 
sample points, Observe a head and Observe a tail, have the same chance of occur- 
ring. Thus, we might state that "the probability of observing a head is 50%" or "the 
odds of seeing a head are 5050." Both of these statements are based on an infor- 
mal knowledge of probability. We'll begin our treatment of probability by using 
such informal concepts and then solidify what we mean later. 
0 and 1 that measures the 
iment -
s
 
the occurrence of a sample 

FIGURE 3.2 
PROPORTION 
The proportion of 
0.63 r 
heads in N tosses 
of a coin 
Events, Sample Spaces, and Probability 
1 1 5 
I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I l 1 1 1 1 1 1 1 1 1 l I l I I I I I I I l I I I I l  
100 200 300 
400 500 
hW 700 800 9'00 1000 1100 1200 1300 1400 1500 
SAMPLE SIZE (N) 
point in a very long series of repetitions of an experiment.* For example, if we are 
assigning probabilities to the two sample points in the coin-toss experiment 
(Observe a head and Observc a tail), we might reason that if we toss a balanced 
coin a very large number of times, the samplc points Observe a head and Observe 
a tail will occur with the same relative frequency of .5. 
Our reasoning is supported by Figure 3.2. The figure plots the relative fre- 
quency of the number of times that a head occurs when simulating (by computer) 
the toss of a coin N times, where N ranges from as few as 25 tosses to as many as 
1,500 tosses of the coin. You can see that when N is large (i.e., N = 1,500), the rel- 
ative frequency is converging to .5. Thus, the probability of each sample point in 
the coin-tossing experiment is .5. 
For some experiments, we may have little or no information on the relative fre- 
quency of occurrence of the sample points; consequently, we must assign proba- 
bilities to thc samplc points based on general information about the experiment. 
For example, if the experiment is to invest in a business venture and to observe 
whether it succeeds or fails, the sample space would appear as in Figure 3.3. We 
are unlikely to be able to assign probabilities to the sample points of this experi- 
I 
ment based on a long series of repetitions since unique factors govern each pcr- 
formance of this kind of experiment. Instead, we may consider factors such as the 
personnel managing the venture, the general state of the economy at the time, the 
FI 
rate of success of similar ventures, and any other pertinent information. If we 
finally decide that the venture has an 80% chance of succeeding, we assign a 
probability of .8 to the sample point Success. This probability can be interpreted as 
a measure of our degree of belief in the outcome of the business venture; that is, it 
is a subjective probability. Notice, however, that such probabilities should be based 
on expert information that is carefully assessed. If not, we may be misled on any 
FIGURE 3.3 
Experiment: Invest in a 
*The result derives from an axiom in probability theory called the Law of Large Numbers. Phrased 
business venture and 
informally, this law states that the relative frequency of the number of times that an outcome occurs 
observe whether it 
when an experiment is replicated over and over again (i.e., a large number of times) approaches the 
succeeds ( S )  or fails (F) 
theoretical probability of the outcome. 

I I6 
CHAPTER 3 
Probability 
decisions based on these probabilities or based on any calculations in which they 
appear. [Note: For a text that deals in detail with the subjective evaluation of 
probabilities, see Winkler (1972) or Lindley (1985).] 
No matter how you assign the probabilities to sample points, the probabilities 
assigned must obey two rules: 
3. 
All ~arnplc pomt probabilities tnust lie between 0 
. 
. 
.. . . - . . 
2. ?he proh;~hilities ol' all the .;ample points within a sample space itiusr sum to I .  
Assigning probabilities to sample points is easy for some experiments. For 
example, if the experiment is to toss a fair coin and observe the face, we would 
probably all agree to assign a probability of '/2 to the two sample points, Observe 
a head and Observe a tail. However, many experiments have sample points whose 
probabilities are more difficult to assign. 
@g+~("t,,& 
5.2 A retail computer store sells two basic types of personal computers (PCs): stan- 
dard desktop units and laptop units. Thus the owner must decide how many of 
each type of PC to stock. An important factor affecting the solution is the pro- 
portion of customers who purchase each type of PC. Show how this problem 
might be formulated in the framework of an experiment with sample points and a 
sample space. Indicate how probabilities might be assigned to the sample points. 
~OLUTlOh, 
If we use the term customer to refer to a person who purchases one of the two 
types of PCs, the experiment can be defined as the entrance of a customer and the 
observation of which type of PC is purchased. There are two sample points in the 
sample space corresponding to this experiment: 
D: {The customer purchases a standard desktop unit} 
L: (The customer purchases a laptop unit) 
The difference between this and the coin-toss experiment becomes apparent 
when we attempt to assign probabilities to the two sample points. What probabil- 
ity should we assign to the sample point D? If you answer .5, you are assuming 
that the events D and L should occur with equal likelihood, just like the sample 
points Heads and Tails in the coin-toss experiment. But assignment of sample 
point probabilities for the PC purchase experiment is not so easy. Suppose a check 
of the store's records indicates that 80% of its customers purchase desktop units. 
Then it might be reasonable to approximate the probability of the sample point D 
as .8 and that of the sample point L as .2. Here we scc that sample points are not 
always equally likely. so assigning probabilities to them can be complicated-par- 
titularly for experiments that represent real applications (as opposed to coin- 
and die-toss experiments). 
Although the probabilities of sample points are often of interest in their own 
right, it is usually probabilities of collections of sample points that are important. 
Example 3.3 demonstrates this point. 

SECTION 3.1 
Events, Sample Spaces, and Probability 
1 1 7 
FIGURE 3.4 
Die-toss experiment 
with event A: Observe 
an even number 
A fair die is tossed, and the up face is observed. If the face is even, you win $1. 
Otherwise, you lose $1. What is the probability that you win? 
4OLUTION 
Recall that the sample space for this experiment contains six sample points: 
Since the die is balanced, we assign a probability of 1/6 to each of the sample 
points in this sample space. An even number will occur if one of the sample points, 
Observe a 2, Observe a 4. or Observe a 6, occurs. A collection of sample points 
such as this is called an event, which we denote by the letter A. Since the event A 
contains three sample points-each with probability %-and 
since no sample 
points can occur simultaneously, we reason that the probability of A is the sum of 
the probabilities of the sample points in A. Thus, the probability of A is '/6 + 1/6 + 
1/6 = 1/2.This implies that, in the long run, you will win $1 half the time and lose $1 
half the time. 
C 
Figure 3.4 is a Venn diagram depicting the sample space associated with a die- 
toss experiment and the event A, Observe an even number. The event A is repre- 
sented by the closed figure inside the sample space S. This closed figure A contains 
all the sample points that comprise it. 
To decide which sample points belong to the set associated with an event A, test 
each sample point in the sample space S. If event A occurs, then that sample point 
is in the event A. For example, the event A, Observe an even number, in the die- 
toss experiment will occur if the sample point Observe a 2 occurs. By the same 
reasoning, the sample points Observe a 4 and Observe a 6 are also in event A. 
To summarize, we have demonstrated that an event can be defined in words or 
it can be defined as a specific set of sample points. This leads us to the following 
general definition of an event: 
DEFINITION 3.4 
An event is a specific collection of sample points 
Consider the experiment of tossing two coins. Suppose the coins are not balanced 
and the correct probabilities associated with the sample points are given in the 
table. [Note: The necessary properties for assigning probabilities to sample points 
are satisfied.] 
Consider the events 
A: {Observe exactly one head] 
B: {Observe at least one head} 
Calculate the probability of A and the probability of B. 
Sample Point 
Probability 

1 I8 CHAPTER 3 
Probability 
&OLUTlON 
Event A contains the sample points HT and TH. Since two or more sample points 
cannot occur at the same time, we can easily calculate the probability of event A 
by summing the probabilities of the two sample points. Thus, the probability of 
observing exactly one head (event A), denoted by the symbol P(A), 
is 
P(A) = P(0bserve H T )  + P(0bserve T H )  = 2/9 + y9 = % 
Similarly, since B contains the sample points HH, H7: and TH, 
P(B) = % + 2/9 + 2/9 = 8/9 
b. 
The preceding example leads us to a general procedure for finding the proba- 
bility of an event A: 
Thus, we can summarize the steps for calculating the probability of any event, 
as indicated in the next box. 
4 
in the event of interest. 
e)CAmp~@ 
3.9 
Diversity training of employees is the latest trend in U.S. business. USA Today 
(Aug. 15,1995) reported on the primary reasons businesses give for making diver- 
sity training part of their strategic planning process. The reasons are summarized 
in Table 3.2. Assume that one business is selected at random from all U.S. busi- 
nesses that use diversity training and the primary reason is determined. 
a. Define the experiment that generated the data in Table 3.2, and list the 
sample points. 
TABLE 3.2 
Primary Reasons for Diversity Training 
Reason 
Percentage 
Comply wlth personnel policies (CPP) 
7 
Increase productwity (IP) 
47 
Stay competlt~vc (SC) 
38 
Soc~al respons~bil~ty 
(SR) 
4 
Other ( 0 )  
4 
Total 
100% 
Source: USA Today, August 15,1995 

. 
CPP 
SR 
0 0 
FIGURE 3.5 
Venn diagram for 
diversity training survey 
TABLE 3.3 
Sample 
Point Probabilities 
for Diversity 
Training Survey 
Sample Point 
Probability 
CPP 
.07 
1P 
.47 
SC 
.38 
SR 
.04 
0 
.04 
SECTION 3.1 
Events, Sample Spaces, and Probability 
1 19 
b. Assign probabilities to the sample points. 
c. What is the probability that the primary reason for diversity training is busi- 
ness related; that is, related to competition or productivity? 
d. What is the probability that social responsibility is not a primary reason for 
diversity training? 
IsaLu-rlaN 
a. The experiment is the act of determining the primary reason for diversity 
training of employees at a US. business. The sample points, the simplest 
outcomes of the experiment, are the five response categories listed in Table 
3.2.These sample points are shown in the Venn diagram in Figure 3.5. 
b. If. as in Example 3.1, we were to assign equal probabilities in this case, each of 
the response categories would have a probability of one-fifth ('/s), or .20. 
But, by examining Table 3.2 you can see that equal probabilities are not rea- 
sonable here because the response percentages were not even approximate- 
ly the same in the five classifications. It is more reasonable to assign a proba- 
bility equal to the response percentage in each class, as shown in Table 3.3.* 
c. Let the symbol B represent the event that the primary reason for diversity 
training is business related. B is not a sample point because it consists of 
more than one of the response classifications (the sample points). In fact, as 
shown in Figure 3.5, B consists of two sample points, IP and SC. The proba- 
bility of B is defined to be the sum of the probabilities of the sample points 
in B: 
d. Let NSR represent the event that social responsibility is not a primary reason 
for diversity training. Then NSR consists of all sample points except SR, and 
the probability is the sum of the corresponding sample point probabilities: 
You have the capital to invest in two of four ventures, each of which requires 
approximately the same amount of investment capital. Unknown to you, two of 
the investments will eventually fail and two will be successful. You research the 
four ventures because you think that your research will increase your probability 
of a successful choice over a purely random selection, and you eventually decide 
on two. What is the lower limit of your probability of selecting the two best out of 
four'? That is, if you used none of the information generated by your research, and 
selected two ventures at random, what is the probability that you would select the 
two successful ventures? At least one? 
47OLUTION 
Denote the two successful enterprises as S, and S, and the two failing enterprises 
as F, and F,. The experiment involves a random selection of two out of the four 
ventures, and each possible pair of ventures represents a sample point. The six 
sample points that make up the sample space are 
*The response percentages were based on a sample of U.S. husinesses; consequently, these assigned 
probabilities are estimates of tlic true population-response percentages. You'll learn how to measure 
the rcliahility of probability estimates in Chapter 7. 

120 CHAPTER 3 
Probability 
The next step is to assign probabilities to the sample points. If we assume 
that the choice of any one pair is as likely as any other, then the probability of 
each sample point is y6. Now check to see which sample points result in the 
choice of two successful ventures. Only one such sample point exists-namely, 
(S,, S,). Therefore, the probability of choosing two successful ventures out of 
the four is 
P(s,, s2) = 1/6 
The event of selecting at least one of the two successful ventures includes all 
- 
the sample points except (F,, F2). 
P(Sc1cct at least one success) = P(S,, S,) + P(S,, F,) + P(Sl, F,) + P(S,. Fl) 
+ P(S2, FJ 
= y6 + ?/6 + y6 + y6 + ?6 = y6 
Therefore, the worst that you could do in selecting two ventures out of four 
may not be too bad. With a random selection, the probability of selecting two suc- 
cessful ventures will be l/h and the probability of selecting at least one successful 
venture out of two is Y6. 
C 
The preceding examples have one thing in common: The number of sample 
points in each of the sample spaces was small; hence, the sample points were easy 
to identity and list. How can we managc this when thc sample points run into the 
thousands or millions? For example. suppose you wish to select five business ven- 
tures from a group of 1,000. Then each different group of five ventures would rep- 
resent a sample point. How can you determine the number of sample points asso- 
ciated with this experiment? 
One method of determining the number of sample points for a complex exper- 
iment is to develop a counting system. Start by examining a simple version of the 
experiment. For example, see if you can develop a system for counting the number 
of ways to select two ventures from a total of four (this is exactly what was done in 
Example 3.6). If the ventures are represented by the symbols V,, V2, V3, and V,, 
'
the sample points could be listed in the following pattern: 
(V,, V2) 
(V2, V J  
v 3 ,  V'J 
(V,, V,) 
(V2, V4) 
(V,. V',) 
Note the pattern and now try a more complex situation-say, sampling three ven- 
I 
tures out of five. List the sample points and observe the pattern. Finally, see if you 
can deduce the pattern for the general case. Perhaps you can program a comput- 
er to produce the matching and counting for the number of samples of 5 selected 
from a total of 1,000. 

SECTION 3.1 
Events, Sample Spaces, and Probability 
I 2 I 
A second method of determining the number of sample points for an experi- 
ment is to use combinatorial mathematics. This branch of mathematics is con- 
cerned with developing counting rules for given situations. For example, there is a 
simple rule for finding the number of different samples of five ventures selected 
from 1,000. This rule, called the combinations 
-.em 
rule, is given by the formula 
where N is the number of elements in the population; n is the number of elements 
i;the 
sample; and the factorial symbol (!) means that, say, 
Thus, 5! = 5.4.3.2.1. (The quantity O! is defined to be equal to 1.) 
Refer to Example 3.6 in which we selected two ventures from four in which to 
invest. Use the combinatorial counting rule to determine how many different 
selections can be made. 
~JOLUTION 
For this example, N = 4, n = 2, and 
You can see that this agrees with the number of sample points obtained in 
Example 3.6. 
C 
Suppose you plan to invest equal amounts of money in each of five business ven- 
tures. If you have 20 ventures from which to make the selection, how many dif- 
ferent samples of five ventures can be selected from the 20? 
IsoLu-rlar\, 
For this example, N = 20 and n = 5. Then the number of different samples of 5 
that can be selected from the 20 ventures is 
The symbol c). 
meaning the number of combinations ofN elements taken n 
at a time, is just one of a large number of counting rules that have been developed 
by combinatorial mathematicians.This counting rule applies to situations in which 
the experiment calls for selecting n elements from a total of N elements, without 
replacing each element before the next is selected. If you are interested in learn- 
ing other methods for counting sample points for various types of experiments, 
you will find a few of the basic counting rules in Appendix A. Others can be 
found in the chapter references. 
k 

- 
I22 CHAPTER 3 
Probability 
Marilyn vos Savant, who is 
listed in Gurnness Book ot 
World Records Hall of 
Fame for "Highest IQ," writes a monthly column in the 
Sunday newspaper supplement, Parade Magazine. Her 
column, "Ask Marilyn." is devoted to games of skill, 
puzzles, and mind-bending riddles. In one issue, vos 
Savant posed the following question: 
Suppose you're on a game show, and you're given a 
choice of three doors. Behind one door is a car; behind 
the others, goats. You pick a door-say, #1-and the 
host, who knows what's behind the doors, opens anoth- 
er door-say #3-which has a goat. He then says to 
you, "Do you want to pick door #2?" Is it to your 
advantage to switch your choice? 
Vos Savant's answer: "Yes, you should switch. The 
first door has a 1/3 chance of winning [the car], but 
the second has a 2/3 chance [of winning the car]." 
Predictably, vos Savant's surprising answer elicited 
thousands of critical letters, many of them from Ph.D. 
mathematicians, who disagreed with her. Some of the 
more interesting and critical letters, which were printed 
in her next column (Parade Magazine, Feb. 24,1991) 
are condensed below: 
"May I suggest you obtain and refer to a standard 
textbook on probability before you try to answer a 
question of this type again?" (University of Florida) 
"Your logic is in error, and I am sure you will 
receive many letters on this topic from high school 
and college students. Perhaps you should keep a few 
addresses for help with future columns." (Georgia 
State University) 
"You are utterly incorrect about the game-show 
question, and I hope this controversy will call some 
public attention to the serious national cr~sis in 
mathematical education. If you can admit your 
error you will have contributed constl.uctively 
toward the solution of a deplorable situation. How 
many irate mathematicians are needed to get you to 
change your mind?" (Georgetown University) 
"I am in shock that after being corrected by at least 
three mathematicians, you still do not see your mis- 
take." (Dickinson State University) 
"You are the goat!" (Western State Unive~sity) 
"You're wrong, but look on the positive side. If all 
the Ph.D.3 were wrong, the country would be in 
serious trouble." (U.S. Army Research Institute) 
The logic employed by those who disagree with vos 
Savant is as follows: Once the host shows you door #3 
(a goat), only two doors remain.The probability of the 
car being behind door #1 (your door) is '/2: similarly, 
the probability is '/2 for door #2.Therefore, in the long 
run (i.e., over a long series of trials) it doesn't matter 
whether you switch to door #2 or keep door #l. 
Approximately 50% of the time you'll win a car, and 
50% of thc time you'll get a goat. 
Who is correct, the Ph.D.s or vos Savant? By 
answering the following series of questions, you'll 
arrive at the correct solution. 
Focus 
a. Before the show is taped, the host randomly 
decides the door behind which to put the car; then 
the goats go behind the remaining two doors. List 
the sample points for this experiment. 
b. Suppose you choose at random door #l. Now, for 
each sample point in part a, circle door #1 and put 
an X through one of the remaining two doors that 
hides a goat. (This is the door that the host shows- 
always a goat.) 
c. Refer to the altered sample points in part b. 
Assume your strategy is to keep door #I. Count the 
number of sample points for which this is a "win- 
ning" strategy (i.e., you win the car). Assuming 
equally likely sample points, what is the probability 
that you win the car? 
d. Repeat part c, but assume your strategy is to always 
switch doors. 
e. Based on the probabilities of parts c and d, is it to 
your advantage to switch your choice? 

SECTION 3.1 
Events, Sample Spaces, and Probability 
1 23 
Learning the Mechanics 
3.1 
An experiment results in one of the followmg 
sample points: E,, E,, E,, E,, or E,. 
a. Find P(EJ ~f P(E,) = .I, P(E,) = .2, P(E,) = .I, 
and P(E5) = .l. 
p i -  - 
5 
b. Find P(E,) ~f P ( E , )  = P(E,), P(E ) - .l, 
= :  
P(E,) = .2, and P(E,) = .l. 
t L I) C- i, 
c. Find P(E,) if P(E,) = P(E,) = P(E,) = P(E5) 
= .1. 
r ' ? \ =  
, 
_ 
3.2 
The accompanymg diagram describes the sample 
space of a particular experiment and events A 
and B. 
a. What is this type of diagram called? 
b. Suppose the sample points are equally likely. 
Find P(A) and P(B). 
c. Suppose P(l) = P(2) = P(3) = P(4) = P(5) = 
L/2o and P(6) = P(7) = P(8) = P(9) = P(10) = 
3/20. ~ i n d  
P(A) and P(B). 
3.3 
The sample space for an experiment contains five 
sample points with probabilities as shown in the 
table. Find the probability of each of the follow- 
ing events: 
Sample Points 
Probabilities 
1, 
.05 
2 
.20 
3 
.30, 
4 
.30 
5 
.15 
0 -  6 
A: (Either 1,2, or 3 occurs] 
P (A) 
.sQ 
B: [Either 1.3, or 5 occurs) 
7 
C: 14 does not occur] 
3.4 
Compute each of the following: 
3.5 
Two marbles are drawn at random and without 
replacement from a box containing two blue mar- 
bles and three red marbles. Determinc the proba- 
bility of observing each of the following cvcnts: 
A: {Two blue marbles are drawn] 
B: (A red and a blue marble are drawn] 
C: (Two red marbles are drawn] ,, , , 
, 
u 1 1 J -  
3.6 
Simulate the experiment descr~bed in Exercise 3.5 
using any five identically shaped objects, two of 
which are one color and three, another. Mix the 
objects, draw two, record the results, and then 
replace the objects. Repeat the experiment a large 
number of times (at least 100). Calculate the pro- 
portion of time events A, B, and C occur. How do 
these proportions compare with the probabilities 
you calculated in Exercise 3.5? Should these pro- 
portions equal the probabilities? Explain. 
Applying the Concepts 
3.7 
Total Quality Management ( T Q M )  has been 
defined as responsive customer service through 
continuously improved and redesigned work 
processes (Quality Progress, July 1995). However, 
as its usage has grown it has been called differ- 
ent names by different organizations. At the 
University of North Carolina in Charlotte 
(UNCC), where TQM implementation began in 
1992, it is called Continuous Quality Improvcrnent 
(CQI). In evaluating perceptions of CQI, UNCC 
professors K. Buch and J. W. Shelnutt asked 159 
employees to indicate how strongly they agreed or 
disagreed with a series of statements including: "I 
believe that management is committed to CQI." 
The following responses were received: 
Strongly 
Neither agree 
Strongly 
agree 
Agree 
nor disagree 
Disagree 
disaeree 
30 
64 
41 
18 
6 
Source: Buch, K., and Shelnut, J. W. "UNC Charlotte measures the effects 
of its quality initiative." Quality Progress, July 1995. p. 75 (Table 2). 
a. Define the experiment and list the sample 
points. 
b. Assign probabilities to the sample points. 
c. What is the probability that an employee agrees 
or strongly agrees with the above statement? 

124 CHAPTER 3 
Probability 
d. What is the probability that an employee does 
not strongly agree with the above statement? 
3.8 
Communications products (telephones, fax 
machines, etc.) can be designed to operate on 
either an analog or a digital system. Because of 
improved accuracy, a digital signal will soon 
replace the current analog signal used in tele- 
phone lines. The rcsult will be a flood of new digi- 
tal products for cons'umers to choose from 
(Newsweek, Nov. 16, 1992). Suppose a particular 
firm plans to produce a new fax machinc in both 
analog and digital forms. Concerned with whether 
the products will succeed or fail in the market- 
place, a market analysis is conducted that results 
in the sample points and associated probabilities 
of occurrence listed in the table (S,: analog suc- 
ceeds, Fa: analog fails, etc.). Find the probability 
of each of the following events: 
A: (Both new products are successful] 
B: (The analog design is successful} 
C: {The digital design is successful} 
D: (At least one of the two products is successful] 
Sample Points 
Probabilities 
Of six cars produced at a particular factory 
between 8 and 10 A.M. last Monday morning, test 
runs revealed three of them to be "lemons." 
Nevertheless, three of the six cars were shipped 
to dealer A and the other three to dealer B. 
Dealer A received all three lemons. What is the 
probability of this event occurring if, in fact, the 
three cars shipped to dealer A were selected at 
random from the six produced? 
Carbon monoxide (CO) is an odorless, colorless, 
highly toxic gas which is produced by fires as well 
as by motor vehicles and appliances that use 
carbon-based fuels. The Anterican Journal of 
Public Health (July 1995) published a study on 
unintentional CO poisoning of Colorado residents 
for the yeala 19x6-1991. A total of 981 cases of 
CO poisoning were reported during the six-year 
period. Each case was classified as fatal or nonfa- 
tal and by source of exposure. The number of 
cases occurring in each of the catcgories is shown 
in the accompanying table. Assume that one of 
the 981 cases of unintentional CO poisoning is 
randomly selected. 
a. List all sample points for this experiment. 
Source of Exposure 
Fatal 
Nonfatal 
Total 
Fire 
63 
53 
116 
Auto exhaust 
60 
178 
238 
Furnace 
18 
345 
363 
Kerosene or spaceheater 
9 
18 
27 
Appliance 
9 
63 
72 
Other gas-powered motor 
3 
73 
76 
Fireplace 
0 
16 
16 
Other 
3 
19 
22 
Unknown 
9 
42 
51 
Total 
174 
807 
981 
Source: Cook, M. C., Simon, P. A,, and Hoffman, R. E. "Unintentional 
carbon monoxide poisoning in Colorado, 1986 through 1991." American 
JonrnnlofPublic Healrh, Vol. 85. No. 7. July 1995. p. 989 (Table 1). 
American Public Health Association. 
b. What is the set of all sample points called? 
c. Let A be the event that the CO poisoning is 
caused by fire. Find P(A). 
d. Let B be the event that the CO poisoning is 
fatal. Find P(B). 
e. Let C be the event that the CO poisoning is 
caused by auto exhaust. Find P(C). 
f. Let D be the event that the CO poisoning is 
caused by auto exhaust and is fatal. Find P(D). 
g. Let E be the event that the CO poisoning is 
caused by fire but is nonfatal. Find P(E). 
3.11 
The credit card industry depends heavily on mail 
solicitation to attract new customers. In 1994, the 
industry sent out 2.4 billion pieces of mail and 
incurred postage costs of ncarly $500 million 
(Forbes, Sept. 11,1995). The table on page 125 lists 
the number of credit card accounts outstanding 
on June 30,1995. for the top 15 credit card com- 
panies. One of these 177.5 million accounts is to 
be selected at random and the credit card compa- 
ny holding the account is to be identified. 
a. List or describe the sample points in this 
experiment. 
b. Find the probability of each sample point. 
c. What is the probability that the account select- 
ed belongs to a nontraditional bank? A tradi- 
tional bank? 
3.12 
Consumer Reports magazine annually asks read- 
ers to evaluate their experiences in buying a new 
car during the previous year. More than 120.000 
questionnaires were completed for the 1994 sales 
year. Analysis of the questionnaires revealed that 
readers' were most satisfied with the following 
three dealers (in no particular order): Infiniti, 
Saturn, and Saab (Consumer Reports, Apr. 1995). 
a. List all possible sets of rankings for these top 
three dealers. 
b. Assuming that each set of rankings in part a is 
equally likely, what is the probability that 

SECTION 3.1 
Events, Sample Spaces, and Probability 
Numher of Accounts (in millions) 
Cltlbank 
D~scoverINovus* 
MBNA* 
Fmt USA* 
First Chlcago 
ATSrT Universal* 
Hou\chold International* 
Chase Manhattan 
Chemical Bdnk 
Capltdl Ow+ 
Bank of America 
Bank One 
Advantah 
Bank of New York 
Opt~ma (Amencan Express)* 
Total 
*Not a traditional bank 
Sourc~: RAM Research Corp.1Capital One Financial Corp. 
Sucondary Source: Novack. .I."'& 
data edge." Forbes September 11. 1995, p. 148. 
readers ranked Saturn first? That readers 
ranked Saturn third? That readers ranked 
Saturn first and Infiniti second (which is, in 
fact, what they did)? 
3.13 
Often, probabilities are expresscd in terms of 
odds. especially in gambling settings. For exam- 
ple, handicappers for greyhound races express 
their belief about the probabilities that each grey- 
hound will win a race in terms of odds. If the prob- 
ability of evcnt E is P(E), then the odds in favor 
of E are P(E) to 1 - P(E). Thus, if a handicapper 
assesses a probability of .25 that Oxford Shoes 
will win its next race, the odds in favor of Oxford 
Shoes are '5/1nn to 7-5/100, or 1 to 3. It follows that 
the odds against E are 1 - P(E) to P(E), or 3 to 1 
against a win by Oxford Shoes. In general, if the 
odds in favor of event EJ are n to b, thcn P(E) = 
a/(u + 0). 
a. A second handicapper assesses the probability 
of a win by Oxford Shoes to be y3. According 
to the second handicapper, what are the odds 
in favor of Oxford Shoes winning? 
b. A third handicapper assesses the odds in favor 
of Oxford Shoes to be 1 to 1. According to the 
third handicapper, what is the probability of 
OxCord Shoes winning? 
c. A fourth handicapper assesses the odds against 
Oxford Shoes winning to be 3 to 2. Find this 
handicapper's assessment of the probability 
that Oxford Shoes will win. 
3.14 
The Value Line Survey, a service for common 
stock investors, provides its subscribers with up- 
to-date evaluations of the prospects and risks 
associated with the purchase of a large number of 
common stocks. Each stock is ranked 1 (highest) 
to 5 (lowest) according to Value Line's estimate of 
the stock's potential for price appreciation during 
the next 12 months. Suppose you plan to purchase 
stock in three electrical utility companies from 
among seven that possess rankings of 2 for price 
appreciation. Unknown to you, two of the compa- 
nies will experience serious difficulties with their 
nuclear facilities during the coming year. If you 
randomly select the three companies from among 
the seven, what is the probability that you select: 
a. None of the companies with prospective 
nuclear difficulties? 
b. One of the companies with prospective nuclear 
difficulties? 
c Both of the companies with prospective 
nuclear difficulties? 
3.15 
Sustainable development or sustainable farming 
means "finding ways to live and work the Earth 
without jeopardizing the future" (Schmickle, 
Minneapolis Star Tribune, June 20, 1992). Studies 
were conducted in five midwestern states to 
develop a profile of a sustainable farmer. The 
results revealed that farmers can be classified 
along a sustalnab~llty scale, dependmg on whether 
they arc likcly or unhkely to engage In the follow- 
Ing practices. (1) Raise a broad mlx of crops. (2) 
Raise I~vestock; (3) Use chen~icals sparmgly. (4) 
Use techniques for regeneratmg the sod, such as 
crop rotation. 
a. List the different sets of classificat~ons that are 
possible. 
, 
b. Suppose you are planning to mtervlew farmers 
acrow the country to determme the frequency 

I26 CHAPTER 3 
Probability 
with which they fall into the classification sets 
fied as unlikely on all four criteria (i.e.. classi- 
you listed for part a. Since no information is 
fied as a nonsustainable farmer)? 
yet available, assume initially that there is an 
c. Using the same assumption as in part b, what is 
equal chance of a farmer falling into any single 
the probability that a farmer will be classified 
classification set. Using that assumption, what 
as likely on at least three of the criteria (i.e., 
is the probability that a farmer will be classi- 
classified as a near-sustainable farmer)? 
UNIONS AND INTERSECTIONS 
An event can often be wewed as a composition of two or more other events. 
Such events, which are called compound events. can be formed (composed) in two 
ways, as defined and illustrated here. 
nion of two events A and B is the event that occurs if either A or B or both 
on a single performance of the experiment. We denote the union of events A 
by the symbol AUB. AUB consists of all the sample points that belong to A 
r B or both. (See Figure 3.6a.) 
DEFINITION 3.6 
The intersection of two events A and B is the event that occurs if both A and B occur 
on a single performance of the experiment. We write AnB for the intersection of A and 
B. A n B  consists of all the sample points belonging to both A and B (See Figure 3.6b.) 
@)C&MPL@ 
3.9 Consider the die-toss experiment. Define the following events: 
A: {Toss an even number] 
B: {Toss a number less than or equal to 3) 
a. Describe AUB for this experimcnt. 
b. Describe A n  B for this experiment. 
c. Calculate P(AUB) and P(AnB) assuming the die is fair. 
eOUTION 
Draw the Venn diagram as shown in Figure 3.7 
a. The union of A and B is the event that occurs if we observe either an even 
number, a number less than or equal to 3, or both on a single throw of the 
die. Consequently, the sample points in the event AUB are those for which 
A occurs, B occurs, or both A and B occur. Checking the sample points in the 
FIGURE 3.6 
Venn diagrams for 
union and intersection 
Entire shaded area is 
A U B .  
S 
a. Union 
Shaded area is 
A n B .  
1 
S 
b. Intersection 

1 
SECTION 3.2 
Unions and Intersections 127 
FIGURE 3.7 
Venn diagram for die toss 
entire sample space, we find that the collection of sample points in the union 
of A and B is 
A U B  = [1,2,3,4,6} 
b. The intersection of A and B is the event that occurs if we observe both an 
even number and a number less than or equal to 3 on a single throw of the 
die. Checking the sample points to see which imply the occurrence of both 
events A and B, we see that the intersection contains only one sample point: 
In other words, the intersection of A and B is the sample point Observe a 2. 
, c. Recalling that the probability of an event is the sum of the probabilities of 
the sample points of which the event is composed, we have 
P(AUB) = P(l) + P(2) + P(3) + P(4) + P(6) 
= y6 + v 6  + p6 + y6 + Y6 = v6 
and 
Many firms undertake direct marketing campaigns to promote their products. 
The campaigns typically involve mailing information to millions of households. 
The response rates are carefully monitored to determine the demographic char- 
acteristics of respondents. By studying tendencies to respond, the firms can better 
target future mailings to those segments of the population most likely to pur- 
chase their products. 
Suppose a distributor of mail-order tools is analyzing the results of a recent 
mailing. The probability of response is believed to be related to income and age. 
The percentages of the total number of respondents to the mailing are given by 
income and age classificalion in Table 3.4. 
Define the following events: 
A: {A respondent's income is more than $50,000) 
B: {A respondent's age is 30 or more) 
a. Find P(A) and P(B). 
b. Find P(A U B). 
C. Find P(AnB). 
eOLUl7ON 
Following the steps for calculating probabilities of events, we first note that the 
objective is to characterize the income and age distribution of respondents to the 
mailing. To accomplish this, we define the experiment to consist of selecting a 
TABLE 3.4 
Percentage of Respondents in Age-Income Classes 
INCOME 
Age 
<$25,000 
$25,0lM-$50,000 
>$50,OOU 
< 30 yrs 
5 % 
12% 
, 10% 
30-50 yrs 
14% 
22 % 
16% 
> 50 yrs 
8 % 
10% 
3 % 

128 CHAPTER 3 
Probability 
respondent from the collection of all respondents and observing which income 
and age class he or she occupies. The sample points are the nine different age- 
income classifications: 
E,: (<30 yrs, <$25,000] 
E,: (30-50 yrs, <$25.000] 
E,: {>SO yrs, >$50,000] 
Next, we assign probabilities to the sample points. If we blindly select one of 
the respondents. the probability that he or she will occupy a particular age- 
income classification is just the proportion, or relative frequency, of respon- 
dents in the classification. These proportions are given (as percentages) in Table 
3.4. Thus, 
P(EJ = Relative frequency of respondents in age-income class 
{<30 yrs, <$25,000} = .05 
and so forth. You may verify that the sample points probabilities add to 1. 
a. To find P(A), we first determine the collection of sample points contained in 
event A. Since A is defined as (>$50,000}, we see from Table 3.4 that A 
contains the three sample points represented by the last column of the table. 
In words. the event A consists of thc inconic classification {>$50,000) in all 
three age classifications.The probability of A is the sum of the probabilities 
of the sample points in A: 
Similarly. B consists of the six sample points in the second and third rows of 
Table 3.4: 
P(B) = .14 + .22 + .16 + .08 + .10 + .03 = .73 
b. The union of events A and B, AUB, consists of all the sample points in 
either A or B or both. That is, the union of A and R consists of all respon- 
dents whose income exceeds $50,000 or whosc age is 30 or more. In Table 3.4 
this is any sample point found in the third column or the last two rows.Thus, 
P(AUB) = .10 + .14 + .22 + .16 + .08 + .I0 + .03 = .83 
c. The intersection of events A and B, A n B ,  consists of all sample points in 
both A and B. That is, the intersection of A and B consists of all respon- 
dents whose income exceeds $50.000 atzd whose age is 30 or more. In Table 
3.4 this is any sample point found in the third column and the last two 
rows. Thus, 
P(AnB) = .16 +-.03 = .19 
b. 
A very useful concept in the calculation of event probabilities is the notion of 
complementary events: 

FIGURE 3.8 
Venn diagram of 
complementary events 
FIGURE 3.9 
Complementary events 
in the toss of two coins 
SECTION 3.4 
The Additive Rule and Mutually Exclusive Events 
1 29 
t that A does not occur-that is, the event 
consistmg of all sample points that are not in event A. We denote the complement of 
A by A'. 
An event A is a collection of sample points. and the sample points included in 
Ac are those not in A. Figure 3.8 demonstrates this idea. Note from the figure that 
all sample points in S are included in eitherA or A
C and that no sample point is in 
both A and AC.This leads us to conclude that the probabilities of an event and its 
complement must sum to 1: 
-1 
2 W ~ ~ * + r ' ~ - X  
Ibe wni of thc probabil~ties of complementary events equal< I :  w., P(A) - P(Ac) = I .  
In many probability problems, calculating the probability of the complement of 
the event of interest is easier than calculating the event itself.Then, because 
we can calculate P(A) by using the relationship 
P(A) = 1 - P(A
C). 
Consider the experiment of tossing two fair coins. Use the complementary rela- 
tionship to calculate the probability of event A: {Observing at least one head]. 
+OLUTION 
We know that the event A: {Observing at least one head} consists of the sample 
points 
A: {HH, H7; TH] 
The complement of A is defined as the event that occurs when A does not occur. 
Therefore, 
A
C: (Observe no heads} = {TT] 
This complementary relationship is shown in Figure 3.9. Assuming the coins are 
balanced, 
and 
P(A) = 1 - P(Ac) = 1 - -4 = 3/4. 
b. 
5 THE ADDITIVE RULE AND MUTUALLY 
EXCLUSIVE EVENTS 
In Section 3.2 we saw how to determine which sample points are contained in a 
union and how to calculate the probability of the union by adding the probabili- 
ties of the samplc points in the union. It is also possible to obtain the probability 
of the union of two events by using the additive rule of probability. 
The union of two events will often contain many sample points, since the union 
occurs if either one or both of the events occur. By studying the Venn diagram in 

Probability 
Entirc shaded arcn is 
I 
A U B .  
FIGURE 3.10 
Venn diagram of union 
E.@&4PLS 3.12 
FIGURE 3.1 1 
Venn diagram of 
mutually exclusive events 
Figure 3.10, you can see that the probability of the union of two events, A and B, 
can be obtained by summing P(A) and P(B) and subtracting the probability cor- 
responding to AnB. ?%erefore, the formula for calculating the probability of the 
union of two events is given in the next box. 
Hospital records show that 12% of all patients are admitted for surgical treat- 
ment, 16% are admitted for obstetrics, and 2% receive both obstetrics and surgi- 
cal treatment. If a new patient is admitted to the hospital, what is the probability 
that the patient will be admitted either for surgery, obstetrics, or both? Use the 
additivc rule of probability to arrive at the answer. 
~ X ~ L U I X ~ N  
Consider the following events: 
A: {A patient admitted to the hospital receives surgical treatment] 
B: {A patient admitted to the hospital receives obstetrics treatment) 
Then, from the given information, 
P(A) = .12 
and the probability of the event that a patient receives both obstetrics and surgi- 
cal treatment is 
P(A f l  B )  = .02 
The event that a patient admitted to the hospital receives either surgical treat- 
ment, obstetrics treatment, or both is the union AUB. The probability of AUB is 
given by the additive rule of probability: 
P(AUB) = P(A) + P ( R )  - P(AnB) = .12 + .16 - .02 = .26 
Thus, 26% of all patients admitted to the hospital receive either surgical treat- 
ment, obstetrics treatment, or both. 
k 
A very special relationship exists between events A and B when A n B  contains 
no sample points. In this case we call the events A and B mutually exclusive events, 
Events A and B are mutually exclusive if AnB contains no sample points, that is, if A 
and B have no samplc points in common. 
Figure 3.11 shows a Venn diagram of two mutually exclusive events. The 
events A and B have no sample points in common, that is, A-and B cannot 
.-. 
occur 
simultaneously, a
n
d
,
 
Thus, we have the importan<~elationship g ~ v e n
in the box. 

SECTION 3.4 
The Additive Rule and Mutually Exclusive Events 
13 1 
FIGURE 3. I 2  
Venn diagram for 
coin-toss experiment 
the union of A and 
P(A) + P(W 
Caution:The formula shown above is ,false if the events are not mutually exclu- 
sive. In this case (i.e., two nonmutually exclusive events), you must apply the gen- 
eral additive rule of probability. 
Consider the experiment of tossing two balanced coins. Find the probability of 
observing at least one head. 
~OLUTION 
Define the events 
A: {Observe at least one head} 
B: (Observe exactly one head] 
C: {Observe exactly two heads] 
Note that 
A = BUC 
and that BnC contains no sample points (see Figure 3.12). Thus, B and C are 
mutually exclusive, so that 
Although Example 3.13 is very simple, it shows us that writing events with 
verbal descriptions that include the phrases "at least" or "at most" as unions of 
mutually exclusive events is very useful. This practice enables us to find the prob- 
ability of the event by adding the probabilities of the mutually exclusive events. 
Learning the Mechanics 
3.16 
A fair coin is tossed three times and the events A 
V 
and B are defined as follows: 
A: (At least onc hcad is observed] 
B: (The number of heads observed is odd] 
a. Identify the sample points in the events A, B, 
AUB,Ac,and AflB. 
b. Find P(A). P(B), P(A U B). P(AC), and P(A n B) 
by summing the probabilities of the appropri- 
ate sample points. 
c. Find P(AUB) using the additive rule. 
Compare your answer to the one you obtained 
in part b. 
d. Are the events A and B mutually exclusive? 
3.17 
What are 
3.18 
A pair of fair dice is tossed. Define the following 
events: 
A: {You will roll a 7) (i.e., the sum of the dots on the up 
faces of the two dice is cqual to 7) 
B: {At least one of the two dice shows a 4) 
a. Identifv the sample points in the events A, B, 
AnB,AUB,and A'. 
b. Find P(A), P(B), P(A fl B), P(A U B), and P(Ac) 
by summing the probabilities of the appropri- 
ate sample points. 
c. Find P(AUB) using the additive rule. Compare 
your answer to that for the same event in part b. 
d. Are A and B mutually exclusive? Why? 
3.19 
Consider the accompanying Venn diagram, whcrc 
P(E,) = P(E,) = P(E,) = %. P(E,) = P(E,) = 
%o, P(E,) = %o, and P(E,) = 1/5. Find each of the 
following probabilities: 

132 CHAPTER 3 
Probability 
3.20 
Consider the accompanying Venn diagram. where 
P(E,) = .10. P(E,) = .05. P(E,) = P(E,) = .2, 
P(EJ = .06, P(E,) = .3, P(E,) = .06, and P(E,) = 
.03. Find the following probabilities: 
a. P(AC) b. P(B') c. P(A"B) 
d. P(AUB) 
e. P(AnB) f. P(AcUBc) 
g. Are events A and B mutually exclusive? Why? 
3.21 
The following table describes the adult popula- 
tion of a small suburb of a large southern city. A 
marketing research firm plans to randomly select 
onc adult from the suburb to evaluate a new food 
product. For this experiment the nine age-income 
categories are the sample points. Consider the fol- 
lowing events: 
A: (Person is under 25) 
B: (Person is between 25 and 45) 
C: (Person is over 45) 
D: (Person has income under $20,000) 
E: (Person has income of $20,000-$50,000) 
F: (Person has income over $50,000) 
Convert the frequencies in the table to relative 
frequencies and use them to calculate the follow- 
ing probabilities: 
INCOME 
a. P(B) b. P(F) c. P(CnF) d. P(BUC) 
e. P(AC) f. P(ACnF) 
g. Consider each pair of events (A and B, A and 
C, etc.) and list the pairs of events that are 
mutually exclusive. Justify your choices. 
3.22 
Refer to Exercise 3.21. Use the same event defi- 
nitions to do the following exercises. 
a. Write the event that the person selected is 
under 25 with an income over $50.000 as an 
intersection of two events. 
b. Write the event that the person selected is age 
25 or older as the union of two mutually exclu- 
sive events and as the complement of an event. 
Applying the Concepts 
3.23 
A state energy agency mailed questionnaires on 
energy conservation to 1.000 homeowners in the 
state capital. Five hundred questionnaires were 
returned. Suppose an esperiment consists of ran- 
domly selecting and reviewing one of the returned 
questionnaires. Consider the events: 
A: {The home is constructed of brick) 
B: (The home is more than 30 years old) 
C: {The home is heated with oil] 
Describe each of the following events in terms of 
unions, intersections, and complements (i.e., A U B, 
AnB, A", etc.): 
a. The home is more than 30 years old and is 
heated with oil. 
b. The home is not constructed of brick. 
c. The home is heated with oil or is more than 30 
years old. 
d. The home is constructed of brick and is not 
heated with oil. 
3.24 
Corporate downsizing in the United States has 
caused a significant increase in the demand for 
temporary and part-time workers. In Japan a sinl- 
ilar increase in demand has been fueled by the 
need for less costlv labor and protection against 
variation in labor demand. The distribution (in 
percent) of nonregular workers in Japan in 1992 
(by age) is provided in the table on page 133 
(adapted from Monthly Labor Review, Oct. 1995). 
Column headings are defined below the table. 
Suppose a nonregular worker is to be chosen at 
random from this population. Define the follow- 
ing events: 
A: {The worker is 40 or over) 
B: {The worker is a teenager and part-time] 
C:{The worker is under 40 and either arubaito or 
dispatched) 
D: [The worker is part-time] 
a. Find the probability of each of the above events. 
b. Find P(AnD) and P(AUD). 

SECTION 3.4 
The Additive Rule and Mutually Exclusive Events 
133 
Age 
Part-Time 
Arubaito 
Temporary and Day 
Dispatched 
Totals 
15-19 
.3 
3.7 
2.3 
.2 
6.5 
20-29 
3.4 
7.8 
6.1 
4.7 
22.0 
30-39 
8.4 
1.6 
4.5 
2.7 
17.2 
4049 
15.6 
1.6 
7.3 
1.4 
25.9 
50-59 
9.4 
1.1 
5.8 
.6 
16.9 
60 and over 
4.3 
1.8 
4.8 
.6 
11.5 
Totals 
41.4 
17.6 
30.8 
10.2 
100.0 
. 
-- 
Part-time: Work fewer hours per day or days per week than regular workers; arubaito; someone 
with a "side" job who is in school or has regular employment elsewhere: temporary: employed on 
a contract lasting more than one month hut less than one year; day: employed on a contract of 
less than one month's duration: dispat~&d: hired from a temporary-help agency. 
Source: Houseman. S.. and Osawa, M. "Part-time and temporary employment in Japan." Monthly 
Labor Revrrw, October 1995. pp. 12-13 (Tables 1 and 2). 
C. Describe in words the following events: A
C, B
C, 
and D
C. 
d. Find the probability of each of the events you 
described in part c. 
3.25 
A buyer for a large metropolitan department 
store must choose two firms from the four avail- 
able to supply the store's fall line of men's slacks. 
The buyer has not dealt with any of the four firms 
before and considers their products equally attrac- 
tive. Unknown to the buyer, two of the four firms 
are having serious financial problems that may 
result in their not being able to deliver the fall 
line of slacks as soon as promised. The four firms 
are identified as G, and G, (firms in good financial 
condition) and P, and P, (firms in poor financial 
condition). Sample points identify the pairs of 
firms selected. If the probability of the buyer's 
selecting a particular firm from among the four is 
the same for each firm, the sample points and 
their probabilities for this buying experiment are 
those listed in the following table. 
Sample Points 
Probability 
GIG: 
96 
G,P, 
76 
G,P2 
96 
G2p1 
96 
GzP2 
96 
P,pz 
1/6 
We define the following events: 
A:(At least one of the selected firms' is in good 
financial condition] 
B: (Firm P, is selected] 
a. Define the event A n B  as a specific collection 
of sample points. 
b. Define the event AUB as a specific collection 
of sample points. 
C. Define the event A
C as a specific collection of 
sample points. 
d. Find P(A), P(B), P(AnB). P(AUB), and P(Ac) 
by summing the probabilities of the appropri- 
ate sample points. 
e. Find P(AUB) using the additive rule. Are 
events A and B mutually exclusive? Why? 
3.26 
Roulette is a very popular game in many Amer- 
ican casinos. In roulette, a ball spins on a circular 
wheel that is divided into 38 arcs of equal length, 
bearing the numbers 00, 0, 1, 2, ..., 35, 36. The 
number of the arc on which the ball stops is the 
outcome of one play of the game. The numbers 
are also colored in the following manner: 
Red: 1,3,5,7,9,12,14,16,18,19,21.23,25,27,30,32.34,36 
Black: 2.4,6,8,10,11,13,15,17,20,22,24.26,28,29,31,33,35 
Greerz: 00,O 
Players may place bets on the table in a variety of 
ways, including bets on odd, even, red, black, high, 
low, etc. Define the following events: 
A: (Outcome is an odd number (00 and 0 are consid- 
ered neither odd nor even)] 
B: (Outcome is a black number] 
C: {Outcome is a low number (1-18)) 
a. Define the event A n B  as a specific set of 
sample points. 
b. Define the event AUB as a specific set of 
sample points. 
C. Find P(A). P(B), P(AnB), P(AUB), and P(C) 
by summing the probabilitics of the appropri- 
ate sample points. 
d. Define the event AflBnC as a specific set of 
sample points. 
e. Find P(AUB) using the additive rule. Are 
events A and B mutually exclusive? Why? 
f. Find P(AnBnC) by summing the probabili- 
ties of thc sample points given in part d. 
g. Define the event (AUBUC) as a specific set 
of sample points. 

134 CHAPTER 3 
Probability 
h. Find P(AUBUC) by summing the probabili- 
ties of the sample points given in part g. 
3.27 
After completing an inventory of three warehous- 
es, a manufacturer of golf club shafts described its 
stock of 20,125 shafts with the percentages given 
in the table. Suppose a shaft is selected at random 
from the 20,125 currently in stock and the ware- 
house number and type of shaft are observed. 
TYPE OF SHAFT 
Regular 
Stiff 
Extra Stiff 
1 
41 % 
6 % 
0% 
Warehouse 
2 
10% 
15% 
4% 
3 
11% 
7% 
6% 
a. List all the sample points for this experiment. 
b. What is the set of all sample points called? 
C. Let C be the event that thc shaft selected is 
from warehouse 3. Find P(C) by summing the 
probabilities of the sample points in C. 
d. Let F be the event that the shaft chosen is an 
extra-stiff type. Find P(F). 
e. Let A be the event that the shaft selected is 
from warehouse 1. Find P(A). 
f. Let D be the event that the shaft selected is a 
regular type. Find P(D). 
g. Let E be the event that the shaft selected is a 
stiff type. Find P(E). 
Refer to Exercise 3.27. Define the characteristics 
of a golf club shaft portrayed by the following 
events, and then find the probability of each. For 
each union, use the additive rule to find the prob- 
ability. Also, determine whether the events are 
mutually exclusive. 
a. A n F  b. CUE c. C n D  
d. A U F  e. A U D  
The types of occupations of the 123,060,000 
employed workers (age 16 years and older) in the 
United States in 1994 are described in the table, 
and their relative frequencies are listed. A worker 
is to be selected at random from this population 
and his or her occupation is to be determined. 
(Assume that each worker in the population has 
only one occupation.) 
a. What is the probability that the worker will be 
a male service worker? 
b. What is the probability that the worker will be 
a manager or a professional? 
c. What is the probability that the worker will be 
a female professional or a fanale operatorlfab- 
ricatorllaborer? 
d. What is the probability that the worker will 
not be in a technical/sales administrative 
occupation? 
Occupation 
Relative Fkequency 
Male Worker 
Manageriallprofessional 
Technical/sales/administrative 
Service 
Proasion production, craft, and repair 
Operatorslfahricatorsllahorers 
Farming, forestry. and fishing 
Female Worker 
Manageriallprofessional 
Technicallsalesladministrative 
Service 
Precision production, craft, and repair 
Operatorslfabricators/laborers 
Farming, forestry, and fishing 
Source: Statistical Ahsrracl of the Unired Srales: 1995, p. 411 
3.30 
The long& 
success of a business depends on its 
ability to market products with superior charac- 
teristics that maximize consumer satisfaction and 
that give the firm a competitive advantage 
(Kotler, Marketing Management, 1994). Ten new 
products have been developed by a food-products 
firm. Market research has mdicated that the 10 
products have the characteristics describtd by the 
Venn diagram shown here. 
Superior 
Consumer 
Product 
Satisfaction 
Characteristics 
Competitive 
Advantage 
I 
a Write the event that a product possesses all the 
desired characteristics as an intersection of the 
events defined in the Venn d~agram. Which 
products are contained in th~s 
intersection? 
b. If one of the 10 products were selected at 
random to be marketed, what is the probabil- 
ity that it would possess all the desired char- 
acteristics? 
c. 
Write the event that the randomly selected 
product would give the firm a competitive 
advantage or would satisfy consumers as a 
union of the events defined in the Venn dia- 
gram. Find the probability of this union. 

d. Write the event that the randomly selected 
product would possess superior product char- 
acteristics and satisfy consumers. Find the 
probability of this intersection. 
3.31 
Identifying managerial prospects who are both 
talented and motivated is difficult. A human- 
resources director constructed the following two- 
way table to define nine combinations of talent- 
motivation levels. The number in a cell is the 
director's estimate of the probability that a man- 
agerial prospect will fall in that category. Suppose 
the director has dccided to hire a new manager. 
Define the following events: 
A: (Prospect places in high-motivation category] 
B: (Prospect places in high-talent category} 
C: {Prospect is medium or better in both categories) 
D: (Prospect places low in at least one category) 
E: (Prospect places highest in both categories] 
FIGURE 3.13 
Reduced sample space 
for the die-toss 
experiment given that 
event B has occurred 
SECTION 3.5 Conditional Probability 
135 
TALENT 
Motivatinn 
High 
Medium 
Low 
High 
.05 
.16 
.05 
Medium 
.19 
.32 
.05 
Low 
.ll 
.05 
.02 
a. Does the sum of the cell probabilities equal I? 
b. List the sample points in each of the events 
described above and find their probabilities. 
C. Find P(AUB), P(AnB), and P(A U C). 
d. Find P(Ac) and explain what this means from a 
practical point of view. 
e. Considcr each pair of events ( A  and B, A and C, 
etc.). Which of the pairs are mutually exclu- 
sive? Why'? 
The event probabilities we've been discussing give the relative frequencies of the 
occurrences of the events when the experiment is repeated a very large number of 
times. Such probabilities are often called unconditional probabilities because no 
special conditions are assumed, other than those that define the experiment. 
Often, however, we have additional knowledge that might affect the outcome 
of an experiment, so we need to alter the probability of an event of interest. A 
probab~lity that reflects such additional knowledge is called the conditional prob- 
ability of the event. For example, we've seen that the probability of observing an 
even number (event A) on a toss of a fair die is ?4. But suppose we're given the - 
information that on a particular throw of the die the result was a number less than 
or equal to 3 (event B). Would the probability of observing an even number on 
that throw of the die still be equal to h? 
It can't be, because making the assump- 
tion that B has occurred reduces the sample space from six sample points to three 
sample points (namely, those contained in event B). This reduced sample space is 
as shown in Figure 3.13. Because the sample points for the die-toss experiment are 
equally likely, each of the three sample points in the reduced sample space is 
of Y3. Since the only even number of the 
he number 2 and the die is fair, we con- 
- 
- 
clude that the orobabilitv that A occurs aiven that B occurs is '/3. We use the 
" 
symbol P(A~B-~ 
the p
r
o
b
a
h
~
~
e
v
e
n
t
 
B occurs. 
s
e
 
die-toss example P(A~B) = h. 
To get the probability of event A given that event B occurs. we proceed as fol- 
lows. We divide the probability of the part of A that falls within the reduced 
sample space B, namely P(AnB), by the total probability of the reduced sample 
space, namely, P(B). Thus. for the die-toss example with event A: {Observe an 
even number) and event 6: {Observe a number less than or equal to 31, we find 

1 36 
CHAPTER 3 
Probability 
I e B n F '  
B ' ~ F '  I The formula for P(A(B) is true in general: 
- 
S 
FIGURE 3.14 
Sample space for contact- 
ing a sales product 
This formula adjusts the probability of AnB from its original value in the com- 
plete sample space S to a conditional probability in the reduced sample space B. If 
the sample points in the complete sample space are equally likely, then the for- 
mula will assign equal probabilities to the sample points in the reduced sample 
space, as in the die-toss experiment. If, on the other hand. the sample points have 
unequal probabilities, the formula will assign conditional probabilities propor- 
tional to the probabilities in the complete sample space.This is illustrated by the 
following examples. 
~KAMPL.~;. 
3.14. 
Suppose you are interested in the probability of the sale of a large piece of earth- 
moving equipment. A single prospect is contacted. Let F be the event that the 
bu-jer has sufficient money (or credit) to buy the product and let Fc denote the 
complement of F (the event that the prospect does not have the financial capa- 
bility to buy the product). Similarly. let B be the event that the buyer wishes to buy 
the product and let B
C be the complement of that event. Then the four sample 
points associated with the experiment are shown in Figure 3.14, and their proba- 
bilities are given in Table 3.5. 
Find the probability that a single prospect will buy, given that the prospect is 
able to finance the purchase. 
Suppose you consider the large collection of prospects for the sale of your product 
and randomly select one person from this collection. What is the probability that 
the person selected will buy the product? In order to buy the product, the cus- 
tomer must be financially able A d  have the desire to buy, so this probability 
would correspond to the entry in Table 3.5 below (To buy, B} and next to (Yes, F), 
or P ( B n F )  = .2. This is called the ponditional probability of the event BnF. 
In contrast, suppose you know that the prospect selected has the financial 
capability for purchasing the product. Now you are seeking the probability that 
the customer will buy given (the condition) that the customer has the financial 
ability to pay. This pobability, the conditional probability of B give: 
that F has 
occurred and denoted by the symbol P(BIF), would be d G m m e d  by considerin; 
- 
TABLE 
3.5 
Probabilities of Customer Desire to 
Buy and Ability to Finance 
DESIRE 
To Buy, B 
Not to Buy, Bc 
.2 
.1 
Ahle to Finance 
Yes, 
I 
No, FC 
.4 
.3 
4 
i 

S 
FIGURE 3.15 
Subspace (shaded) 
containing sample points 
irnplyng a financially 
able prospect 
SECTION 3.5 
Conditional Probability 
I37 
only the sample points in the reduced sample space containing the sample points 
B n F  and B'nF-i.e., 
sample points that imply the prospect is financially able to 
buy. (This subspace is shaded in Figure 3.15.) From our definition of conditional 
probability, 
IC 
where P(F) is the sum of the probabilities of the two sample points corresponding 
to B n F  and B'n F (given in Table 3.5). Then 
and the conditional probability that a prospect buys, given that the prospect is 
financially able, is 
As we would expect, the probability that the prospect will buy, given that he or 
she is financially able, is higher than the unconditional probability of selecting a 
prospect who will buy. 
L 
Note in Example 3.14, that the conditional probability formula assigns a prob- 
ability to the event (Bfl F) in the reduced sample space that is proportional to the 
probability of the event in the complete sample space.To see this, note that the two 
sample points in the reduced sample space, (Bn F) and (BCnF), have probabilities 
of .2 and .I, respectively, in the complete sample space S. The formula assigns 
conditional probabilities 2/3 and %1 (use the formula to check the second one) to 
these sample points in the reduced sample space 8 so that the conditional proba- 
bilities retain the 2 to 1 proportionality of the original sample point probabilities. 
The investigation of consumer product complaints by the Federal Trade 
Commission (FTC) has generated much interest by manufacturers in the quality 
of their products. A manufacturer of an electromechanical kitchen utensil con- 
ducted an analysis of a large number of consumer complaints and found that they 
fell into the six categories shown in Table 3.6. If a consumer complaint is received, 
what is the probability that the cause of the complaint was product appearance 
given that the complaint originated during the guarantee period? 
~v~LUTION 
Let A represent the event that the cause of a particular complaint is product 
appearance, and let B represent the event that the complaint occurred during the 
guarantee period. Checking Table 3.6, you can see that (18 + 13 + 32)% = 63% 
of the complaints occur during the guarantee period. Hence, P(B) = .63. The 
TABLE 3.6 
Distribution of Product Complaints 
REASON FOR COMPLAINT 
-- 
Electrical 
Mechanical 
Appearance 
Totals 
During Guarantee Period 
18% 
13% 
32% 
63 % 
After Guarantee Period 
12% 
22 % 
3 % 
37% 
Totals 
30% 
35 % 
35% 
100% 

138 CHAPTER 3 
Probability 
percentage of complaints that were caused by the appearance and occurred 
during the guarantee period (the event A n B) is 32%. Therefore. P(A n B) = .32. 
Using these probability values, we can calculate the conditional probability 
P(A(B) 
that the cause of a complaint is appearance given that the complaint 
occurred during the guarantee time: 
Consequently, we can see that slightly more than half the complaints that occurred 
during the guarantee period were due to scratches dents, or other imperfections in 
the surface of the kitchen devices. 
b, 
You will see in later chapters that conditional probability plays a key role in 
manv applications of statistics. For example. we may be interested in the proba- 
bility that a particular stock gains 10% during the next year. We may asses this 
probability using information such as the past performance of the stock or the 
general state of the economy at present. However. our probability may change 
drastically if we assume that the Gross Domestic Product (GDP) will increase by 
10% in the next year. We would then be assessing the conditional probability 
that our stock gains 10% in the next year given that the GDP gains 10% in the 
same year. Thus, the probability of any event that is calculated or assessed based 
on an assumpti 
event occurs c
o
n
c
u
r
r
e
n
v
 
p-y. 
- 
- 
- 
THE MULTIPLICATIVE RULE A N D  
INDEPENDENT EVENTS 
The probability of an intersection of two events can be calculated using the mul- 
tiplicative rule, which employs the conditional probabilities we defined in the 
previous section. Actually, we have already developed the formula in another 
context. You will recall that the forn~ula for calculating the conditional probabili- 
ty of B given A is 
If we multiply both sides of this equation by P(A), we get a formula for the prob- 
ability of the intersection of events A and B: 
. 
. 
.. . 2 
. .!. , ,$,.*..*&,".,r."* 
' ...s ?-.,.:..< .*. 7' . ..*: .:, .. 
. 
I
'
 
. . 
. ,  
, 
I 
Multiplicative Rule of Probability 
ns) = P ( B ) P ( A ~ B )  
The second expression in the box is obtained by multiplying both sides of the 1 
equation P ( A ~ B )  
= P(A nB)/P(B) by P(B). 
5)LAMPLE- 3.16 
An investor in wheat futures is concerned with the following events: 
B: (US. production of wheat will be profitable next year] 
A: {A serious drought will occur next year] 
Based on available information, the investor believes that the probability is .O1 
that production of wheat will be profitable assuming a serious drought will occur 
, 

Venn diagram for 
finding P(A) 
SECTION 3.6 
The Multiplicative Rule and Independent Events 139 
in the same year and that the probability is .05 that a serious drought will occur. 
That is, 
P(B(A) = .O1 and P(A) = .05 
Based on the information provided, what is the probability that a serious drought 
will occur and that a profit will be made? That is, find P(AnB), the probability of 
the intersection of events A and B. 
&JOLUTION 
We want to calculate P(AnB). Using the formula for the multiplicative rule, we 
obtain: 
P(AnB) = P(A)P(B~A) = (.05)(.01) = .0005 
The probability that a serious drought occurs nncl the production of wheat is 
profitable is only .0005. As we might expect, this intersection is a very rare 
event. 
h. 
Intersections often contain only a few sample points. In this case, the probabil- 
ity of an intersection is easy to calculate by summing the appropriate sample 
point probabilities. However, the formula for calculating intersection probabilities 
is invaluable when the intersection contains numerous sample points, as the next 
example illustrates. 
A county welfare agency employs ten welfare workers who interview prospective 
food stamp recipients. Periodically the supervisor selects, at random, the forms 
completed by two workers to audit for illegal deductions. Unknown to the super- 
visor, three of the workers have regularly been giving illegal deductions to appli- 
cants. What is the probability that both of the two workers chosen have been 
giving illegal deductions? 
eat--u-rlor\, 
Define the following two events: 
A: {First worker selected gives illegal deductions] 
B: {Second worker selected gives illegal deductions) 
We want to find the probability of the event that both selected workers have been 
giving illegal deductions. This event can be restated as: (First worker gives illegal 
deductions and second worker gives illegal deductions).Thus. we want to find the 
probability of the intersection, AflB.Applying the multiplicative rule, we have 
To find P(A) it is helpful to consider the experiment as selecting one worker 
from the ten. Then the sample space for the cxperiment contains ten sample 
points (representing the ten welfare workers), wherc the three workers giving 
illegal deductions are denoted by the symbol I (I,. I,, I,). and the seven workers 
not giving illegal deductions are denoted by the symbol N (Nl, . . . , N,). The result- 
ing Venn diagram is illustrated in Figure 3.16. Since the first worker is selected at 
random from the ten, it is reasonable to assign equal probabilities to the 10 sample 
points. Thus, each sample point has a probability of '/lo. The sample points in 
event A are {I,, I,, I,}-the three workers who are giving illegal deductions.Thus, 

1 40 CHAPTER 3 
Probability 
To find the conditional probability, P(B~A), we need to altcr the sample space 
S. Since we know A has occurred, i.e., the first worker selected is giving illegal 
deductions, only two of the nine remaining workers in the sample space are giving 
illegal deductions. The Venn diagram for this new sample space is shown in Figure 
3.17. Each of these 9 sample points are equally likely, so each is assigned a proba- 
bility of v9. Since the event (BIA) contains the sample points {I,, I,], we have 
Venn diagram for 
finding P(A(A) 
Substituting P(A) = '/lo and P(B~A) = 7 9  into the formula for the multiplicative 
rule, we find 
Thus, there is a 1 in 15 chance that both workers chosen by the supervisor have 
been giving illegal deductions to food stamp recipients. 
h 
The sample space approach is only one way to solve the problem posed in 
Example 3.17. An alternative method employs the concept of a tree diagram. 
Tree diagrams are helpful for calculating the probability of an intersection. 
To illustrate, a tree diagram for Example 3.17 is displayed in Figure 3.18 The 
tree begins at the far left with two branches. These branches represent the two 
possible outcomes N (no illegal deductions) and I (illegal deductions) for the first 
worker selected. The unconditional probability of each outcome is given (in 
parentheses) on the appropriate branch. That is, for the first worker selected, 
P(N) = 7/10 and P(1) = 3/10. (These can be obtained by summing sample point 
probabilities as in Example 3.17.) 
The next level of the tree diagram (moving to the right) represents the out- 
comes for the second worker selected. The probabilities shown here are condi- 
tional probabilities since the outcome for the first worker is assumed to be known. 
For example, if the first worker is giving illegal deductions (I), the probability that 
the second worker is also giving illegal deductions (I) is 7 9  since of the nine work- 
ers left to be selected, only two remain who are giving illegal deductions. This 
FIGURE 3.18 
select 1st 
Tree diagram for 
worker 
Example 3.17 
I 
Select 2nd 
I Outcome 
' Probability 
worker 
j 
! 

SECTION 3.6 
The Multiplicative Rule and lndependent Events 
14 1 
conditional probability, 99, is shown in parentheses on the bottom branch of 
Figure 3.18. 
Finally, the four possible outcomes of the experiment are shown at the end of 
each of the four tree branches. These events are intersections of two events (out- 
come of first worker r r r d  outcome of second worker). Consequently, the multi- 
plicative rule is applied to calculate each probability, as shown in Figure 3.18.You 
can see that the intersection ( I n I ] ,  i.e., the event that both workers selected are 
giving illegal deductions, has probability 6/90 = '/IS-the 
same value obtained in 
Example 3.17. 
In Section 3.5 we showed that the probability of an event A may be substan- 
tially altered by the knowledge that an event B has occurred. However, this will 
not always be the case. In some instances, the assumption that event B has 
occurred will not alter the probability of event A at all. When this is true, we call 
events A and B independent. 
Evcnts A and B ale independent events if the occurrence 01 B does not alter the prob- 
ability that A has occurred; that is, cvents A and B are independent if 
P(AIB) = P(A) 
When events A and B are lndependent, it is also true that 
P(B(A) = P(B) 
Events that are not independent are said to be dependent. 
3. k &  
Consider the experiment of tossing a fair die and let 
I - 
J 
S 
FIGURE 3.1 9 
Venn diagram for die- 
toss experiment 
A: {Observe an even number] 
B: (Observe a number less than or equal to 4) 
Are events A and B independent? 
I 
~OLUTIOM 
I 
The Venn diagram for this experiment is shown in Figure 3.19. We first calculate 
P(A) = P(2) + P(4) + P(6) = 7 2  
P(B) = P(1) + P(2) + P(3) + P(4) = 2/3 
4 I 
Now assuming B has occurred, the conditional probability of A given B is 
J 
Thus, assuming that event B does not alter' the probability of observing an even 
number, it remains %.Therefore, the events A and B are independent. Note that if 
we calculate the conditional probability of B given A, our conclusion is the same: 

142 CHAPTER 3 
Probability 
pp 
-- 
S 
FIGURE 3.20 
Mutually exclusive events 
are dependent events 
Refer to the consumer product complaint study in Example 3.15. The percentages 
of complaints of various types during and after the guarantee period are shown in 
Table 3.6. Define the following events: 
A: [Cause of complaint is product appearance) 
B: (Complaint occurred during the guarantee term} 
Are A and B independent events? 
SULUTIUN 
Events A and B are independent if P(A\B) = P(A). We calculated P(A(B) in 
Examvle 3.15 to be .51. and from Table 3.6 we see that 
Therefore, P(A~B) is not equal to P(A), and A and B are dependent events. 
h 
To gain an intuitive understanding of independence, think of situations in 
which ;he occurrence of one event dies not alkr the probability that a second 
event will occur. For example, suppose two small companies are being monitored 
by a financier for possible investment. If the businesses are in different industries 
and they are otherwise unrelated, then the success or failure of one company 
may be independent of the success or failure of the other. That is, the event that 
company A fails may not alter the probability that company B will fail. 
As a second example, consider an election poll in which 1,000 registered voters 
are asked their preference between two candidates. Pollsters try to use proce- 
dures for selecting a sample of voters so that the responses are independent. That 
is, the objective of the pollster is to select the sample so the event that one polled 
voter prefers candidate A does not alter the probability that a second polled 
voter prefers candidate A. 
We will make three final points about independence.The first is that the prop- 
.-?--- 
like the mutually exclusive property, cannot be shown 0% 
, 
d i a m i s  m e a n s v t  trust your intuition.7;;- 
- 
g w r a l ,  the only w a m n d e p e n d e n c e  is by performing the calculations 
of the urobabilities in the definition. 
Q e  second point concerns the relationship between the mutually exclusive 
and independencGoperties. Suppose that events A and B are n~utually exclusive. 
as shown in Figure 3.20, and both events have nonzero probabilities. Are these 
events independent or dependent? That is, does the assumption that B occurs 
1 
alter the probability of the occurrence of A? It certainly does, because if we 
assume that B has occurred, it is impossible for A to have occurred simultaneously. 
Thus, rnutual~xclusive events a-endent 
events since - 
the probability of the intersection o 
is very easy to c
a
l
c
u
v
a
 
lor calcuTar 
an intersection, we find 
- 
Thus, since P(B~A) = P(B) when A and B are independent, we have the following 
useful rule: 

SECTION 3.6 
The Multiplicative Rule and Independent Events 
143 
Ifevents A and B are independent, the probability of the intersect~on o f  A and 3 equal 
the product of the probabilities of A and 8; that is, 
P(AnB) = P(A)P(B) 
true: If P(AnB) = P(A)P(B), then events A and 3 are ~ndependen 
In the die-toss experiment, we showed in Example 3.18 that the events A: 
{Observe an even number} and B: {Observe a number less than or equal to 4) are 
independent if the die is fair. Thus, 
P(AnB) = P(A)P(B) = (%)(%) = 1/3 
This agrees with the result that we obtained in the example: 
P(AnB) = P(2) + P(4) = 7 6  = 1/3 
&)C.&-S 
3.243 
Almost every retail business has the problem of determining how much invento- 
ry to purchase. Insufficient inventory may result in lost business, and excess inven- 
tory may have a detrimental effect on profits. Suppose a retail computer store 
owner is planning to place an order for personal computers (PCs). She is trying to 
decide how many IBM PCs and how many IBM compatibles to order. 
The owner's records indicate that 80% of the previous PC customers pur- 
chased IBM PCs and 20% purchased compatibles. 
a. What is the probability that the next two customers will purchase compat- 
ibles? 
b. What is the probability that the next ten customers will purchase compatibles? 
soLu-rlotd 
a. Let C, represent the event that customer 1 will purchase a compatible and 
C, represent the event that customer 2 will purchase a compatible.The event 
that both customers purchase compatibles is the intersection of the two 
events, C, nC,. From the records the store owner could reasonably conclude 
that P(C,) = .2 (based on the fact that 20% of past customers have pur- 
chased compatibles), and the same reasoning would apply to C,. However, in 
order to compute the probability of C,nC,, we need more information. 
Either the records must be examined for the occurrence of consecutive pur- 
chases of compatibles, or some assumption must be made to allow the cal- 
culation of P(C,nC2) from the multiplicative rule. It seems reasonable to 
make the assumption that the two events are independent, since the decision 
of the first customer is not likely to affect the decision of the second cus- 
tomer. Assuming independence, we have 
b. To see how to compute the probability that ten consecutive purchases will 
be compatibles. first consider the event that three consecutive customers 
purchase compatibles. If C, represents the event that the third customer 
purchases a compatible, then we want to compute the probability of the 
intersection C,n C2 with C3. Again assuming independence of the purchasing 
decisions, we have 

SECTION 3.6 
The Multiplicative Rule and Independent Events 
143 
If evenrc A und B arc intfependenr, the probability of the intersectioti of A and B equal 
the product of the probabilities of A and B; that is, 
P(AnB) = P(A)P(B) 
true: If P(An B )  = P(A)P(B), then events A and B are ~ndepcnden 
In the die-toss experiment, we showed in Example 3.18 that the events A: 
{Observe an even number} and B: {Observe a number less than or equal to 4) are 
independent if the die is fair. Thus, 
This agrees with the result that we obtained in the example: 
P ( A n B )  = P(2) + P(4) = 96 = 1/3 
6)CAW.ttZ. 3.24% Almost every retail business has the problem of determining how much invento- 
ry to purchase. Insufficient inventory may result in lost business, and excess inven- 
tory may have a detrimental effect on profits. Suppose a retail computer store 
owner is planning to place an order for personal computers (PCs). She is trying to 
decide how many IBM PCs and how many IBM compatibles to order. 
The owner's records indicate that 80% of the prevlous PC customers pur- 
chased IBM PCs and 20% purchased compatibles. 
a. What is the probability that the next two customers will purchase compat- 
ibles? 
b. What is the probability that the next ten customers will purchase compatibles? 
eoLu-naN 
a. Let C, represent the event that customer 1 will purchase a compatible and 
C, represent the event that customer 2 will purchase a compatible. The event 
that both customers purchase compatibles is the intersection of the two 
events, C,nC,. From the records the store owner could reasonably conclude 
that P(C,) = .2 (based on the fact that 20% of past customers have pur- 
chased compatibles), and the same reasoning would apply to C2. However, in 
order to compute the probability of C,nC,, we need more information. 
Either the records must be examined for the occurrence of consecutive pur- 
chases of con~patibles. or some assumption must be made to allow the cal- 
culation of P(C,nCJ from the multiplicative rule. It seems reasonable to 
make the assumption that the two events are independent, since the decision 
of the first customer is not likely to affect the decision of the second cus- 
tomer. Assuming independence, we have 
b. To see how to compute the probability that ten consecutive purchases will 
be compatibles, first consider the event that three consecutive customers 
purchase compatibles. If C, represents the event that the third customer 
purchases a compatible, then we want to compute the probability of the 
intersection C, n C, with C,. Again assuming independence of the purchasing 
decisions, we have 

144 CHAPTER 3 
Probability 
Similar reasoning leads to the conclusion that the intersection of ten such 
events can be calculated as follows: 
P(c,nc,n...nc,,) = P(C, )P(c,) ... P(c,,,) = (.2)1•‹ = .0000001024 
Thus, the probability that ten consecutive customers purchase IBM compat- 
ibles is about 1 in 10 million, assuming the probability of each customer's pur- 
chase of a compatible is .2 and the purchase decisions are independent. 
Learning the Mechanics 
3.32 
An experiment results in one of three mutually 
exclusive events. A, B, or C. It is known that P(A) = 
.30, P(B) = .55, and P(C) = .15. Find each of the 
following probabilities: 
a. P ( A u  B) b. P(A n C )  
I 
c. P ( A ~ B )  d. P(BUC) 
e. Are B and C independent events? Explain. 
3.33 
Consider the experiment depicted by the Venn 
diagram, with the sample space S containing five 
sample points. The sample points are assigned the 
following probabilities: P(E,) = .20, P(E,) = .30, 
P(E,) = .30, P(EJ - .lo, P(E,) = .lo. 
a. Calculatc P(A), P(B), and P(AnB). 
b. Suppose we know that event A has occurred, 
so that the reduced sample space consists of the 
three sample points in A-namely. El, E2, and 
E,. Use the formula for conditional probability 
to adjust the probabilities of these three sample 
points for the knowledge that A has occurred 
[i.e., P ( E , J A ) ] . v ~ ~ ~ ~ ~  
that the conditional proba- 
bilities are in the same proportion to one anoth- 
er as the original sample point probabilities. 
c. Calculate thc conditional probabilily I'(B~A) 
in two ways: ( 1 )  Add the adjusted (conditional) 
probabilities of the sample points in the inter- 
section AnB, since these represent the event 
that B occurs given that A has occurred; (2) 
Use the formula for conditional probability: 
Verify that the two methods yield the same 
result. 
d. Are events A and B independent? Why or 
why not? 
3.34 
Three fair coins are tossed and the following 
events are defined: 
A: (Observe at least one head] 
B: (Observe exactly two heads) 
C: {Observe exactly two tails] 
D: {Observe at most one head} 
a. Sum the p~ohabilities of the appropriate sample 
points to find: P(A), P(B), P(C), P(D), Q A n B ) ,  
P(AnD), P(BnC), and P(BflD). 
b. Use your answers to part a to calculate P(B~A), 
P(A I D), and P ( C I  
B). 
c. Which pairs of events, if any, are independent? 
Why? 
3.35 
An experiment results in one of five sample points 
with the following probabilities: P(E,) = .22, P(EJ 
= 31, P(E,) = .15, P(EJ = .22, and P(E,) = .1. 
The following events have been defined: 
A: {El, EJ 
B: (E,, E3,EJ 
C: {El, &I 
Find each of the following probabilities: 
a. P(A) b. P(B) c. P ( A n B )  
d. P(A[B) e. P(BnC) f. P(CIB) 
g. Consider each pair of events: A and B, A and 
C, and B and C. Are any of the pairs of events 
independent? Why? 
3.36 
Two fair dice are tossed, and the following events 
are defined: 
A: (Sum of the numbers showing is odd) 
B; {Sum of the numbers showing is 9,1l, or 12) 
Are events A and B independent? Why? 
3.37 
A sample space contains six sample points and 
events A, B, and C as shown in the Venn dia- 
gram. The probabilities of the sample points are 

SECTION 3.6 
The Multiplicative Rule and Independent Events 
145 
a. Which pairs of events, if any, are mutually 
exclusive? Why? 
b. Which pairs of events,if any, are independent? 
Why? 
c. Find P(AUB) by adding the probabilities of 
the sample points and then by using the addi- 
tive rule. Verify that the answers agree. Repeat 
for P(A U C). 
Defend or refute each of the following statements: 
a. Dependent events are always mutually exclu- 
sive. 
b. Mutually exclusive events are always depen- 
dent. 
c. Independent events are always mutually 
exclusive. 
For two events, A and B, P(A) = .4 and P(B) = .2. 
a. Il' A and B are independent, find P(AnR), 
P(A I B). and P(A U B). 
b. If A and B are dependent, with P(AJB) = .6, 
find P(AnB) and P(BA). 
Applying the Concepts 
3.40 
"Go" is one of the oldest and most popular strate- 
gic board games in the world, especially in Japan 
and Korea. This two-player gamc is played on a 
flat surface marked with 19 vertical and 19 hori- 
zontal lines.The objective is to control territory by 
placing pieces called "stones" on vacant points on 
the board. Players alternate placing their stones. 
The player using black stones goes first, followed 
by the player using white stones. [Note: The 
University of Virginia requires MBA students to 
learn Go to understand how the Japanese conduct 
business.] Chance (Summer 1995) published an 
article that investigated the advantage of playing 
first (i.e., using the black stones) in Go.The results 
of 577 games recently played by professional Go 
players were analyzed. 
a. In the 577 games, the player with the black 
stones won 319 times and the player with the 
white stones won 258 times. Use this informa- 
tion to assess the probability of winning when 
you play first in Go. 
b. Profcwondl Go players are classified by level. 
Group C includes the top-level players fol- 
lowed by Group B (middle-level) and Group 
A (low-level) players.Thc table below describes 
the number of games won by the player with 
the black stones, categorized by level of the 
black player and level of the opponent. Assess 
the probability of winning when you play first 
in Go for each combination of player and 
opponent level. 
c. If the player with the black stones is ranked 
higher than the player with the white stones, 
what is the probability that black wins? 
d. Given the players are of the same level, what is 
thc probability that the player with the black 
stones wins? 
3.41 . Businesses that offer credit to their customers are 
inevitably faced with the task of collecting unpaid 
bills. A study of collection remedies used by cred- 
itors was published in the Journal of Financial 
Research (Spring 1986).As part of the study,cred- 
itors in four states were asked about how they 
deal with past-due bills. Their responses are tal- 
lied in the table on page 146. "Tough actions" 
Black Player Level 
Opponent Level 
Number of Wins 
Number of Games 
C 
A 
34 
34 
C 
B 
69 
79 
C 
C 
66 
1 18 
B 
A 
40 
54 
B 
B 
52 
95 
B 
C 
27 
79 
A 
A 
15 
28 
A 
B 
11 
51 
A 
C 
5 
39 
Totals 
319 
577 
Source J Kim, and H. J. K~rn 'The advantage of playmg h a t  In Go" Chance, Vol 8, No 3, 
Summer 1995, p 26 (Table 3) 

146 CHAPTER 3 
Probability 
Wisconsin 
Illinois 
Arkansas 
Louisiana 
Take tough action early 
0 
Take tough action later 
37 
Never take tough action 
9 
included filing a legal action, turning the debt over 
to a third party such as an attorney or collection 
agency, garnishing wages, and repossessing 
secured property. Suppose one of the creditors 
questioned is selected at random. 
a. What is the probability that the creditor is 
from Wisconsin or Louisiana? 
b. What is the probability that the creditor is not 
from Wisconsin or Louisiana? 
c What is the probability that the creditor never 
takes tough action? 
d. What is the probability that the creditor is 
from Arkansas and never takes tough action? 
e. What is the probability that the creditor never 
takes tough action, given that the creditor is 
from Arkansas? 
f. If the creditor takes tough action early, what 
is the probability that the creditor is from 
Arkansas or Louisiana? 
g. What is the probability that a creditor from 
Arkansas never takes tough action? 
3.42 
In the last decade, increasingly more employees 
have been offered a variety of health care plans to 
choose from. This is a direct result of the growing 
prevalence of preferred provider organizations 
(PPOs) and health maintenance organizations 
(HMOs). PPOs permit employees to choose their 
health care provider. but offer financial incentives 
when designated doctors and hospitals are chosen. 
HMOs offer prepaid health care from a particular 
set of providers (Monthly Labor Review, Oct. 
1995). A survey of 100 large. 100 medium, and 100 
small companies that offer their employees HMOs, 
PPOs, and fee-for-service plans was conducted; 
each firm provided information on the plans 
chosen by their employees. These companies had a 
total employment of 833,303 people. A breakdown 
of the number of employees in each category by 
firm size and plan is provided in the table. 
Fee-for- 
Company Size 
Service 
PPO 
HMO 
Totals 
Small 
1.808 
1,757 
1,456 
5,021 
Medium 
8,953 
6,491 
6,983 
22,382 
Large 
330,419 
241,770 
233,711 
805,900 
Totals 
341,180 
250,018 
242.105 
833,303 
Source: Adapted from Bucci, M., and Grant, R. "Employer-sponsored 
health insurance: What's offered: what's chosen?" Monthly Labor 
Revien: October 1995, pp. 38-43. 
One employee from the 833,303 total employees 
is to be chosen at random for further analysis. 
Define the events A and B as follows: 
A: (Observe an employee that chose fee-for-service) 
B: (Obscrve an employee from a small company} 
a. Find P(B). b. Find P(A fl B). 
c. Find P(AUB). d. Find P(A~B). 
e. Are A and B independent? Justify your answer. 
3.43 
Refer to the American Journal of Public Health 
study of unintentional carhon monoxide (CO) 
poisonings in Colorado, Exercise 3.10. The 981 
cases were classified in a table, which is repro- 
duced below. A case of unintentional CO poison- 
ing is chosen at random from the 981 cases. 
Source of Exposure 
Fatal 
Nonfatal 
Total 
Fire 
Auto exhaust 
Furnace 
Kerosene or spaceheater 
Appl~ance 
Other gas-powered motor 
Fireplace 
Other 
Unknown 
Total 
174 
807 
98 1 
Source: Cook, M. C., Simon, P.A., and Hoffman, R. E."Unintentional 
carbon monoxide poisoning in Colorado. 1986 through 1991." American 
Journal ofpublic H~cilrh, Val. 85, No. 7. July 1995. p. 989 (Table 1). 
American Public Health Association. 
a. Given that the source of the poisoning is fire, 
what is the probability that the case is fatal? 
b. Given that the case is nonfatal. what is the 
probability that it is caused by auto exhaust? 
c. If the case is fatal, what is the probability that 
the source is unknown? 
d. If the case is nonfatal, what is the probability 
that the source is not fire or a fireplace? 
3.44 
Physicians and pharmacists sometimes fail to 
inform patients adequately about the proper 
application of prescription drugs and about the 
precautions to take in order to avoid potential 
side effects. This failure is an ongoing problem 
in the United States. One method of increas- 
ing patients' awareness of the problem is for 
physicians to provide Patient Medication 
Instruction (PMI) sheets. The American Medical 
Association, however. has found that only 20% of 

SECTION 3.6 
The Multiplicative Rule and Independent Events 
147 
the doctors who prescribe drugs frequently dis- 
tribute PMI sheets to their patients. Assume that 
20% of all patients receive the PMI sheet with 
their prescriptions and that 12% receive the PMI 
sheet and are hospitalized because of a drug- 
related problem. What is the probability that a 
person will be hospitalized for a drug-related 
problem given that the person has received the 
PMI sheet? 
3.45 
A soft-drink bottler has two quality control inspec- 
tors independently check each case of soft dunks 
lor chipped or cracked bottles before the cases 
leave the bottling plant. Having observed the work 
of the two trusted inspectors over several years, 
the bottler has determined that the probability of 
a defective case getting by the first inspector is .05 
and the probability of a defective case getting by 
the second inspector is .lo. What is the probability 
that a defective case gets by both inspectors'? 
3.46 
The table describes the 63.1 million U.S. long- 
form federal tax returns filed with the Internal 
Revenue Service (IRS) in 1992 and the percent- 
age of those returns that were audited by the IRS. 
b. Find the probability that a randomly selected 
U.S. secondary school subscribes to CCN and 
uses the broadcasts more than five times per 
week. 
- 
3.48 
In October 1994. a flaw was discovered in the 
Pentium chip installed in many new personal com- 
puters.The chip produced an incorrect result when 
dividing two numbers. Intel, the manufacturer of 
the Pentium chip, initially announced that such an 
error would occur only once in 9 billion divides, or 
"once in every 27,000 years" for a typical user; 
consequently, it did not immediately rcplace the 
chip. Assume the probability of a divide error with 
the Pentium chip is, in fact, ~~.ooo.ooo.ooo. 
a. For a division performed using the flawed 
Pentium chip, what is the probability that no 
error will occur'? 
b. Consider two successive divisions performed 
using the flawed chip. What is the probability 
that neither result will be in error'? (Assume 
that any one division has no impact on the result 
of any other division performed by the chip.) 
c. Depending on the procedure, statistical soft- 
Number of Tax Filers 
Income 
(millions) 
Percentage Audited 
Under $25,000 
18.7 
.6 
$25,000-$49.999 
27.5 
.6 
S50.000-$99,999 
13.7 
1.0 
$100,000 or more 
3.2 
4.9 
S O U ~ L E  Stnosncal Abstract of the Unrred States. 1995. p. 344. 
a. If a tax filer is randomly selected from this 
population of tax filers (i.e., each tax filer has 
an cqual probability of being selected), what is 
the probability that the tax filer was audited? 
b. If a tax filer is randomly selected from this 
population of tax filers, what is the probabili- 
ty that the tax filer had an income of $25,000- 
$49,999 in 1992 and was audited? What is the 
probability that the tax filer had an income of 
$50,000 or more in 1992 or was not audited? 
3.47 
"Channel One" is an education television network 
that is available to all secondary schools in the 
United States. Participating schools are equipped 
with TV sets in every classroom in order to 
receive the Channel One broadcasts. According 
to Educationril Technology (May-June 1995). 40% 
of all US. secondary schools subscribe to the 
Channel One Communications Network (CCN). 
Of these subscribers, only 5% never use the CCN 
broadcasts, while 20% use CCN more than five 
times per week. 
a. Find the probability that a randomly selected 
U.S. secondary school subscribes to CCN but 
never uses the CCN broadcasts. 
ware packages may perform an extremely 
large number of divisions to produce the 
required output. For heavy users of the soft- 
ware, 1 billion divisions over a short time frame 
is not unusual. Calculate the probability that 1 
billion divisions performed using the flawed 
Pentium chip will result in no errors. 
d. Use the result, part c, to compute the probabil- 
ity of at least one error in the 1 billion divi- 
sions. [Nort.:Two months after the flaw was dis- 
covered, Intel agreed to replace all Pentium 
chips free of charge.] 
3.49 
The genet~c origin and properties of maize 
(modern-day corn), a domest~c plant developed 
8.000 years ago in Mexico, wai mvestigated in 
Econornlc Botany (Jan.-Mar. 1995). Seeds from 
maize ears carry either single spikelets or paired 
spikelets, but not both. Progeny testy on approxi- 
mately 600 malzc cars revealed the following 
information. Forty percent of all seeds carry single 
spikelets, whde 60% carry pared spikelets. A seed 
with single spikelets wdl produce maize ears with 
single spikelets 29% of the time and paired 
spikelets 71% of the time. A seed with paired 
spikelets will produce maize ears with single 
spikelets 26% of the time and paired spikelets 
74% of the time. 
a. Find the probability that a randomly selected 
maize ear seed carries a single spikclet and 
produces ears with single spikelets. 
b. Find the probability that a randomly selected 
maize ear seed produces ears with paired 
spikelets. 

148 CHAPTER 3 
Probability 
3.50 
A particular automatic sprinkler system for high- 
rise apartment buildings, office buildings. and 
hotels has two different types of activation devices 
for each sprinkler head. One type has a reliability 
of .91 (i.e., the probability that it will activate the 
sprinkler when it should is .91). The other type, 
which operates independently of the first type, has 
a reliability of 237. Suppose a serious fire starts 
near a particular sprinkler head. 
a. What is the probability that the sprinkler head 
will be activated? 
b. What is the probab~lity that the sprinkler head 
a. 
will not be activated? 
c. What is the probability that both activation 
devices will work properly'? 
b. 
d. What is the probability that only the device 
with reliability .9 1 will work properly? 
3.51 
One definition of Total Quality Munugemrnt 
c. 
(TQM) was given in Exercise 3.7. Another defini- 
ment of workers, improved communication with 
customers, evaluation of work processes, and sta- 
tistical analysis of processes and their output 
(Benson, Mitznesota Matmgement Review. Fall 
1992). One hundred U.S. companies were sur- 
veyed and it was found that 30 had implcmcntcd 
TQM. Among the 100 companies surveyed, 60 
reported an increase in sales last year. Of those 
60,20 had implemented TQM. Suppose one of the 
100 surveyed companies is to be selected at 
random for additional analysis. 
tion is a "management philosophy and a system of 
management techniques to improve product and 
service quality and worker productivity." TQM 
involves such techniques as teamwork, empower- 
What is the probabdity that a firm that imple- 
mented TQM is selected? That a firm whose 
sales increased is selected? 
Are the two events (TQM implemented] and 
(Sales increased] independent or dependent? 
Explain. 
Suppose that instead of 20TQM implcmcnters 
among the 60 firms reporting sales increases, 
there were 18. Now are the events {TQM 
implemented) and {Sales increased} indepen- 
dent or dependent? Explain. 
How a sample is selected from a population is of vital importance in statistical 
inference because the probability of an observed sample will be used to infer the 
characteristics of the sampled population. To illustrate, suppose you deal yourself 
four cards from a deck of 52 cards and all four cards are aces. D o  you conclude 
that your deck is an ordinary bridge deck, containing only four aces, or do you 
conclude that the deck is stacked with more than four aces? It depends on how 
the cards were drawn. If the four aces were always placed at the top of a standard 
bridge deck, drawing four aces is not unusual-it is certain. O n  the other hand. if 
the cards are thoroughly mixed, drawing four aces in a sample of four cards is 
highly improbable.The point, of course, is that in order to use the observed sample 
of four cards to draw inferences about the population (the deck of 52 cards), you 
need t o  know how the sample was selected from the deck. 
One of the simplest and most frequently employed sampling procedures is 
implied in many of the previous examples and exercises. It is called random sam- 
pling and produces what is known as a random sample. 
If n elements are selected from a population in such a way that every set of n elements 
in the population has an equal probability of being selected, the n elements are said to 
be a random sample.* 
1 
If a population is not too large and the elements can be numbered on slips of 
paper, poker chips, etc., you can physically mix the slips of paper or chips and 
remove n elements from the total. The numbers that appear on the chips selected 
would indicate the population elements to be included in the sample. Since it is 
*Strictly speaking, this is a simple random sample.There are many different types of random samples. 
The simple random sample IS the most common. 
i 

SECTION 3.7 
Random Sampling 
149 
often difficult to achieve a thorough mix, such a procedure only provides an 
approximation to random sampling. Most researchers rely on random number 
generators to automatically generate the random sample. Random number gen- 
erators are available in table form and they are built into most statistical software 
packages. 
@
&
 
I 
Suppose you wish to randomly sample five households from a population of 
100,000 households to participate in a study. 
a. How many different samples can be selected? 
b. Use a random number generator to select a random sample. 
e o u r r a M  
a. To determine the number of samples, we'll apply the combinatorial rule of 
Section 3.1. In this case, N = 100,000 and n = S.Then, 
Thus, there are 83.3 billion trillion different samples of five households that 
can be selected from 100.000. 
b. To ensure that each of the possible samples has an equal chance of being 
selected, as required for random sampling, we can employ a random number 
table, as provided in Table I of Appendix B. Random number tables are 
constructed in such a way that every number occurs with (approximately) 
equal probability. Furthermore, the occurrence of any one number in a posi- 
tion is independent of any of the other numbers that appear in the table. To 
use a table of random numbers, number the N elements in the population 
from 1 to A! Then turn to Table I and select a starting number in the table. 
Proceeding from this number either across the row or down the column, 
remove and record 12 numbers from the table. 
To illustrate, first we number the households in the population from 1 to 
100,000. Then, we turn to a page of Table I, say the first page. (A partial repro- 
duction of the first page of Table I is shown in Table 3.7.) Now, we arbitrarily select 
a starting number, say the random number appearing in the third row, second 
column. This number is 48,360. Then we proceed down the second column to 
obtain the remaining four random numbers. In this case we have selected five 
random numbers, which are shaded in Table 3.7. Using the first five digits to rep- 
resent households from 1 to 99,999 and the number 00000 to represent household 
100,000, we can see that the households numbered 
48,360 
93,093 
39,975 
6,907 
72,905 
should be included in our sample. Note: Use only the necessary number of digits in 
each random number to identify the element to be included in the sample. If, in 

I SO 
CHAPTER 3 
Probability 
TABLE 3.7 
Partial Reproduction of Table I in Appendix B 
1 
2 
3 
4 
5 
6 
the course of recording the n numbers from the table, you select a number that 
has already been selccted, simply discard the duplicate and select a replacement at 
the end of the sequence. Thus, you may have to record more than n numbers 
from the table to obtain a sample of n unique numbers. 
Can we be perfectly sure that all 83.3 billion trillion samples have an equal 
chance of being selected? That fact is, we can't; but to the extent that the random 
number table contains truly random sequences of digits, the sample should be 
very close to random. 
b. 
Table I in Appendix B is just one example of a random number generator. For 
most scientific studies that require a large random sample, computers are used to 
generate the random sample. The SAS and MINITAB statistical software pack- 
ages both have easy-to-use random number gcnerators. 
For example, suppose we required a random sample of n = 50 households 
from the population of 100,000 households in Example 3.21. Here, we might 
employ the SAS random number generator. Figure 3.21 shows a SAS printout list- 
ing 50 random numbers (from a population of 100.000). The households with 
these identification numbers would be included in the random sample. 
I 
- 
random sample of 
1 
50 households 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 

SECTION 3.7 
Random Sampling 
15 1 
3 . 2  L OT T ERY B U ST E R 
"Welcome to the Wonder- 
ful World of Lottery 
Bu$ters." So begins the pre- 
micr issue of Lottery B L L T ~ ~ I ;  
a monthly publication for players of the state lottery 
games. Lottery Buster provides interesting facts and fig- 
ures on the nearly 40 state lotteries currently operating 
in the United States and purported "tips" on how to 
increase a player's odds of winning the lottery. 
New Hampshire, in 1963, was the first state in 
modern times to authorize a state lottery as an altcr- 
native to increasing taxes. (Prior to this time, begin- 
ning in 1895, lotteries were banned in America for fear 
of corruption.) Since then, lotteries have become 
immensely popular for two reasons. First, they lure you 
with the opportunity to win millions of dollars with a 
$1 investment; second, when you lose, at least you 
know your money is going to a good cause. 
The popularity of the state lottery has brought with 
it an avalanche of self-proclaimed "experts" and 
"mathematical wizards" (such as the editors of Lortery 
Br~stw) who provide advice on how to win the lot- 
tery-for a fee, of course! These experts-the legiti- 
mate ones, anyway-base their "systems" of winning 
on their knowledge of probability and statistics. 
For example, more experts would agree that the 
"golden rule" or "first rule" in winning lotteries is game 
selection. State lotteries generally offer three types of 
games: Instant (scratch-off) tickets, Daily Numbers 
(Pick-3 and Pick-4), and the weekly Pick-6 Lotto game. 
C 
The Instant game involves scratchmg off the thin, 
opaque covering on a ticket to determine whether you 
have won or lost. The cost of a ticket is 5 0 ~ .  
and the 
amount to be won ranges from $1 to $200,000 in most 
states, while it reaches $1 million in others. Lottery 
Buster advises against playing the Instant game 
because it is "a pure chance play, and you can win only 
by dumb luck. No skill can be applied to this game." 
The Daily Numbers game permits you to choose 
either a three-digit (Pick-3) or four-digit (Pick-4) 
number at a cost of $1 per ticket. Each night, the win- 
ning number is drawn. If your number matches thc 
winning number, you win a large sum of money, usual- 
ly $100,000. You do have some control over the Daily 
Numbers game (since you pick the numbers that you 
play) and, consequently, there are strategies available 
to increase your chances of winning. Howevcr, the 
Daily Numbers game, like the Instant game, is not 
available for out-of-state play. For this reason. and 
because the payoffs are relatively small, lottery experts 
prefcr the weekly Pick-6 Lotto game. 
To play Pick-6 Lotto, you select six numbers of 
your choice from a field of numbers ranging from 1 to 
N, where N depends on which state's game you are 
playing. For example, Florida's Lotto game involves 
picking six numbers ranging from 1 to 49 (denoted 
6/49) as shown on the Florida Lotto ticket, Figure 3.22. 
Delaware's Lotto is a 6/30 game, and Pennsylvania's is 
a 6/40 game.The cost of a ticket is $1 and the payoff, if 
your six numbers match the winning numbers drawn 
at the end of each week, is $6 million or more, depend- 
ing on the number of tickets purchased. (To date, 
Pennsylvania has had the largest weekly payoff of $97 
million.) In addition to the grand prize, you can win 
second-, third-, and fourth-prize payoffs by matching 
five, four, and three of the six numbers drawn, respec- 
tively. And you don't have to be a resident of the state 
to play the state's Lotto game. Anyone can play by 
calling a toll-free "hotline" number. 
Focus 
a. Consider Florida's 6149 Lotto game. Calculate the 
number of possible ways in which you can choose 
the six numbers from the 49 available. If you pur- 
chase a single $1 ticket, what is the probability that 
you win the grand prize (i.e.,match all six numbers)? 
b. Repeat part a for Delaware's 6/30 game. 
c. Repeat part a for Pennsylvania's 6/40 game. 
d. Since you can play any state's Lotto game, which of 
the three, Florida, Delaware, or Pennsylvania, 
would you choose to play? Why? 
e. One strategy used to increase your odds of winning 
a Lotto is to employ a wheeling system. In a com- 
plete wheeling system. you select more than six 
numbers, say, seven, and play every combination of 
six of those seven numbers. Suppose you choose to 
"wheel" the following seven numbers in a 6/40 
game: 2, 7, 18, 23, 30, 32, 39. How many tickets 
would you need to purchase to have every possible 
combination of the seven numbers? List the six 
numbers on each of these tickets. 
continued 

152 CHAPTER 3 
Probability 
f. Refer to part e. What is the probability of winning 
ets had at least one neighboring pair. Thus, some 
the 6/40 Lotto when you wheel seven numbers? 
"experts" feel that you have a better chance of win- 
Does the strategy, in fact, increase your odds of 
ning if you include at least one neighbormg pair in 
winning'? 
your number aelect~on. Calculate the probability of 
g. Consider the strategy of playing neighboring pairs. 
w~nning the 6/40 Lotto with the six numbers: 2,15, 
Neighbormg pairs are two consecutive numbers 
19, 20. 27, 37. [Note: 19. 20 is a neighboring pair.] 
that come up together on the winning ticket. In one 
Compare this probability to the one in part c. 
state lottery, for example, 79% ot the wmning tick- 
Comment on the ne~ghbormg pairs strategy. 
FIGURE 3.22 
Reproduction of 
Florida's 6/49 Lotto 
ticket (Statistics in 
Action 3.2) 
Learning the Mechanics 
3.52 
Suppose you wish to sample n = 2 elements from 
a total of N = 10 elements. 
a. Count the number of different samples that 
can be drawn, first by listing them, and then 
by using combinatorial mathematics. (See 
Section 3.1 .) 
b. If random sampling is to be employed, what is 
the probability that any particular sample will 
be selected'? 
c. Show how to use the random number table, 
Table I in Appendix B, to select a random 
sample of 2 elements from a population of 10 
elements. Perform the sampling procedure 20 
times. Do any two of the samples contain the 
same 2 elements'? Given your answer to part b, 
did you cxpect repeated samples? 
3.53 
Suppose you wish to sample n = 3 elements from 
a total of N = 600 elements. 
a. Count the number of different samples by using 
combinatorial mathematics (see Section 3.1). 
b. If random sampling is to be employed, what is 
thc probability that any particular sample will 
be selected? 
c. Show how to use the random number table, 
Table I In Append~x B, to select a random 
sample of 3 elements from a population of 600 
elements. Perform the sampling procedure 20 
times. Do any two of the sarnplcs contain the 
same three elements? Given your answer to 
part b, did you expect repeated samples'? 
d. Use a computer to generate a random sample 
of 3 from the population of 600 elements. 
3.54 
Suppose that a population contains N = 200,000 
elements. Use a computer or Table I of Appendix B 
to select a random sample of n = 10 elements 
from the population. Explain how you selected 
your sample. 
Applying the Concepts 
3.55 
In auditing a firm's financial statements, an auditor 
will (I) assess the capability of the firm's account- 
ing system to accumulate, measure, and synthesize 
transactional data properly, and (2) assess the 
operational effectiveness of the accounting 
system. In performing the second assessment, the 
auditor frequently relies on a random sample of 
actual transactions (Stickney and Weil, Financial 
AccounringAn Introdz~ction to Concrpts, Methods, 
and Uses, 1994). A particular firm has 5,382 cus- 
tomer accounts that are numbered from 0001 to 

a. One account is to be selected at random for 
audit. What is the probability that account 
number 3,241 is selected? 
b. Draw a random sample of ten accounts and 
explain in detail the procedure you used. 
c. Refer to part b.The following are two possible 
random samplcs of size ten. Is one more likely 
to be selected than the other? Explain. 
Sample Number 1 
Sample Number 2 
3.56 
To ascertain the effectiveness of their advertising 
campaigns, firms frequently conduct telephone 
interviews with consumers.They may use random 
samples of telephone numbers that are arbitrarily 
or systematically selected from telephone direc- 
tories, or they may employ an innovation called 
random-digit dialing. In this approach, a random 
number generator mechanically creates the 
sample of phone numbers to be called. An advan- 
tage of randorn-digit dialing is that it can obtain a 
representative sample from the population of all 
households with telephones, whereas telephone- 
directory sampling obtains a sample only from 
the population of households with listed tele- 
phone numbers. 
a. Explain how the random number table (Table 
I of Appendix B, or a computer) could be 
used to generate a sample of 7-digit tele- 
phone numbers. 
b. Use the procedure you described in part a to 
gcncrate a sample of ten 7-digit telephone 
numbers. 
QUICK REVIEW 
1 53 
c. Use the procedure you described in part a to 
generate five 7-digit telephone numbers whose 
first three digits are 373. 
When a company sells shares of stock to investors, 
the transaction is said to take place in the prinzary 
nznrket. To enable investors to rescll the stock 
when they wish, secondary markets called stock 
exchanges were created. Stock exchange transac- 
tions involve buyers and sellers exchanging cash 
for shares of stock, with none of the proceeds going 
to thc companies that issued the shares (Radcliffe, 
Investment: Concepts, Anrilysis, Strategy, 1994). The 
results of the previous business day's transactions 
for stocks traded on the New York Stock Exchange 
(NYSE) and five regional exchanges- the 
Midwest, Pacific, Philadelphia, Boston, and 
Cincinnati stock exchanges-are summarized each 
business day in the NYSE-Composite Transactions 
table in The Wall Street Journal. 
a. Exanline the NYSE-Composite Transactions 
table in a recent issue of The Wall Street 
Journal and explain how to draw a random 
sample of stocks from the table. 
b. Use the procedure you described in part a to 
draw a random sample of 20 stocks from a 
recent NYSE-Composite Transactions table. 
For each stock in the sample, list its name (i.e., 
the abbreviation given in the table), its sales 
volume, and its closing price. 
In addition to its decennial enumeration of the 
population, the US. Bureau of the Census regu- 
larly samples the population to estimate level of 
and changes in a number of other attributes, such 
as income, family size, employment. and marital 
status. Suppose the bureau plans to sample 1,000 
households in a city that has a total of 534.322 
households. Show how the bureau could use the 
random number table in Appendix B or a com- 
puter to gencrate the sample. Select the first 10 
households to be included in the sample. 
Key Terms 
Additive rule of probability 130 
Experiment 112 
Random number generator 149 
Combinations rule 121 
Independent events 141 
Random sample 148 
Cornbinatorial mathematics 121 
Intersection 126 
Sample point 113 
Complementary events 128 
Multiplicative rule 138 
Sample space 114 
Compound event 126 
Multiplicative rule of probability 138 
Tree diagram 140 
Conditional probability 135 
Mulually exclusive events 130 
Union 126 
Event 117 
Probability rules 116 
Venn diagram 114 

154 CHAPTER 3 
Probability 
Key Formulas 
P(A) + P(A
C) = 1 
P(AUB) = P(A) + P(B) - P ( A n B )  
P(A n B )  = 0 
P(AUR) = P(A) + P(B) 
P(AnB) = P(A)P(B~A) 
= P(B)P(A~B) 
P(A(B) = P(A) 
P(AnB) = P(A)P(B) 
N ! 
(9 
= Z ( N ~  
n)! 
where N! = N(N - 1)(N - 2)...(2)(1) 
Complementary events 129 
Additive rule 130 
Mutually exclusive events 130 
Additive rule for mutually exclusive events 131 
Conditional probability 136 
Multiplicative rule 138 
Independent events 141 
Multiplicative rule for independent events 143 
Combinatorial rule 121 
Symbol 
Pronunciation 
Description 
Probability of A 
A union B 
A intersect B 
A complement 
Probability of A given B 
N chose n 
N factorial 
Sample space 
Set of sample points, 1.2,3,4,5, in sample space 
Set of sample pants, 1,2, In event A 
Prohab~l~ty 
that event A occur\ 
Union of events A and B (e~ther 
A or B or both occur) 
Intersect~on of events A and B (hoth A and B occur) 
Complement of event A (the event that A does not occur) 
Cond~t~onal 
probab~lity that event A occurs glven that event B occurs 
Number of combmat~ons of N elements taken n at a time 
Multiply N(N - l)(N - 2)...(2)(1) 
Learning the Mechanics 
3.59 
What are the two rules that probabilities assigned 
to sample points must obey? 
3.60 
Are mutually exclusive events also dependent 
events? Explain. 
3.61 
Given that P(AnB) = .4 and P(AJB) = .8. find 
P(B). - 5 
3.62 
Which of the following pairs of events are mutu- 
ally exclus~ve? Justify your response. 
a. {The Dow Jones Industrial Average increases 
on Monday). (A large New York bank decreas- 
es its prime interest rate on Monday] 
b. {The next sale by a PC retaller is an IBM com- 
I 
patible microcomputer], (The next sale by a PC 
retaller is an Apple microcomputer] 
c. (You reinvest all your d~vldend lncome for 
1997 in a limited partne~ship], 
{You reinvest all 
your dividend income for 1997 in a money 
I 
market fund] 
3.63 
The accompanying Venn diagram illustrates a 
sample space containing six sample points and 
three events. A. B, and C. The orobabilities of the 
.
.
.
 
sample points are: P ( l )  = .3, P(2) = .2, P(3) = .1 
P(4) = .l. P(5) = .I, and P(6) = .2. 
a. Find P(AnB), P(BnC),P(AUC),P(AUBUC), 
P(BC), P ( A " ~ B ) ,  
P(B~C), 
and P(B\A). 
b. Are A and B independent? Mutually exclu- 
sive? Why? 

c. Are R and C independent? Mutually exclu- 
sive? Why? 
3.64 
Two events, A and B, are independent, with P(A) 
= .3 and P(B) = .l. 
a. Are A and B mutually exclusive? Why? 
b. Find P(AI B) and P ( B ~ A ) .  
c. Find P(A U B). 
3.65 
Find the numerical value of: 
3.66 
A random sample of five graduate students is to 
be selected from 50 MBA majors for participation 
in a case competition. 
a. In how many different ways can the sample be 
drawn? 
b. Show how the random number table.Table I of 
Appendix B, can be used to select the sample 
of students. 
Applying the Concepts 
3.67 
A research and development company survcycd 
all 200 of its employees over the age of 60 and 
obtained the information given in the table below. 
One of these 200 employees is selected at random. 
What is the 
that the person select- 
ed is on the technical staff? 
If the person selected has over 20 years of ser- 
vice with the company, what is the probability 
that the person plans to retire at age 68? 
If the person selected is on the technical staff, 
what is the probability that the person has 
been with the company less than 20 years? 
What is the probability that the person selected 
has over 20 years with the company, is on the 
nontechnical staff, and plans to retire at age 65? 
Consider the events A: {Plan to retire at age 
681 and B: (On the technical staff]. Are events 
A and H independent? Explain. 
Consider the event D: {Plan to retire at age 68 
and on the technical staff]. Describe the com- 
plement of event D. 
Consider the event E: {On the nontechnical 
staff]. Are events B and E mutually exclusive? 
Explain. 
3.68 
Many US. manufacturers are adopting the IS0 
9000 series of standards for setting up and docu- 
menting quality systems, processes. and proce- 
dures. However, it is not generally known how 
managers who have led or participated in the 
implementation of the standards view them or 
how the standards were achieved. A sample of 40 
IS0 9000-registered companies in Colorado was 
selected and the manager most responsible for 
I S 0  9000 implementation was interviewed 
(Qlurlify Progress, 1995). The following are some 
of the data obtained by the study: 
Level of Top Management lnvolvenient 
in the I S 0  9000 Registration Process 
Frequency 
Very ~nvolved 
9 
Moderate involvement 
16 
Min~mal involvement 
12 
Not involved 
3 
Length of Time to Achieve 
IS0 9000 Registration- 
Requency 
Less than 1 year 
1-1.5 years 
1.6-2 years 
2.1-2.5 years 
More than 2.5 years 
Source: Weston, F. C., "What do managers really think of the 
I S 0  9000 registration process'?" Quality Progress, October 
1995, p. 6849 (Tables 3 and 4). 
Suppose one of the 40 managers who were inter- 
viewed is to be randomly selected for additional 
questioning. Consider the events defined below: 
A: {The manager was involved in the IS0 9000 regis- 
tration] 
B: {The length of time to achieve IS0 9000 registra- 
tion was more than 2 years] 
a. Find P(A). 
b. Find P(B). 
c. Explain why the above data are not sufficient 
to determine whether events A and B are inde- 
pendent. 
3.69 
The table on page 156 lists the overall percentage 
of domestic flights of major U.S. airlines that 
arrived on time during June 1995. 
a. One of these ten airlines is to be selected at 
random. What is the probability that Southwest 
is selected? That Continental is selected? 
b. If one of Continental's domestic flights during 
June 1995 were randomly selected, what is the 
UNDER 20 YEARS WITH COMPANY 
OVER 20 YEARS WITH COMPANY 
Technical Staff 
Nontechnical Staff 
Technical Staff 
Nontechnical Staff 
Plan to Retire at Age 65 
3 1 
5 
45 
12 
Plan to Retire at Age 68 
59 
25 
15 
8 

1 56 
CHAPTER 
3 
Probability 
p~ 
Carrier 
Percent Arriving on Xme 
Southwest 
82.9 
Amencan 
78.5 
Northwest 
78.4 
USAir 
77.0 
America West 
75.8 
Un~tcd 
75.4 
Delta 
74.3 
TWA 
72.9 
Alaska 
70.0 
Continental 
64.1 
Source~Avrutron Daily, August 7.1995. 
probability that the flight arrived on time? 
Was late? 
c. These data are reported each month by the air- 
lines to the U.S. Department of Transportation. 
Consequently, some experts question their 
accuracy. With this in mind, would you recom- 
mend that these percentages be treated as 
upper or lower boinds for the actual on-time 
percentages? Explain. 
3.70 
The state legislature has appropriated $1 million 
to be distributed in the form of grants to individu- 
als and organi7ations engaged in the research and 
development of alternative energy sourccs. You 
have been hired by the state's energy agency to 
assemble a panel of five energy experts whose 
task it will be to determine which individuals and 
organizations should receive the grant money. You 
have identified 11 equally qualified individuals 
who are willing to serve on the panel. How many 
different panels of five expcrts could be formed 
from these 1 I individuals'? 
3.71 
A manufacturer of electronic digital watches 
claims that the probability of its watch running 
more than 1 minute slow or I minute fast after 1 
year of use is ,051. A consumer protection agency 
has purchased four of the manufacturer's watches 
with the intention of testing the claim. 
a. Assuming that the manufacturer's claim is cor- 
rect, what is the probability that none of the 
watches are as accurate as claimed? 
b. Assuming that the manufacturer's claim is cor- 
rect. what is the probability that exactly two of 
the four watches are as accurate as claimcd? 
c. Suppose that only one of the four tested watch- 
es is as accurate as claimed. What inference can 
be made about the manufacturer's claim? 
Explain. 
d. Suppose that none of the watches tested are as 
accurate as claimed. Is it necessarily true that 
the manufacturer's claim is false? Explain. 
3.72 
'Ihe corporations in the highly competitive razor 
blade industry do a tremendous amount of adver- 
tising each year. Corporation G gave a supply of 
three top name brands, G, S, and W, to a consumer 
and asked her to use them and rank them in order 
of preference. The corporation was, of course, 
hoping the consumer would prefer its brand and 
rank it first, thereby giving them some material for 
a consumer interview advertising campaign. If the 
consumer did not prefer one blade over any other, 
but was still required to rank the blades, what is 
the probability that: 
a. The consumer ranked brand G first? 
b. The consumer ranked brand G last? 
c. The consumer ranked brand G last and brand 
W second? 
d. The consumer ranked brand W first, brand G 
second. and brand S third? 
3.73 
Two marketing research companies, Richard 
Saunders International and Marketing Intelli- 
gence Service. joined forces to create a consumer 
preference poll called Acupoll. Acupoll is used 
to predict whether newly developed products 
will succeed if they are brought to market. The 
reliability of the Acupoll has been described as 
follows: The probability that Acupoll predicts 
the success of a particular product, given that 
later the product actually is successful. is .89 
(Minneapolis Star Tribune. Dec. 16,1992). A com- 
pany is considering the introduction of a new 
product and assesses the product's probability of 
success to be .90. If this company were to have its 
product evaluated through Acupoll, what is the 
probability that Acupoll predicts success for the 
product and the product actually turns out to be 
successful? 
3.74 
Use your intuitive understanding of indepen- 
dence to form an opinion about whether each of 
the followins scenarios represents an indepen- 
dent event. 
a. The results of consecutive tosses of a coin 
b. The opinions of randomly selected individuals 
in a preelection poll 
c. A major league baseball player's results in two 
consecutive at-bats 
d. The amount of gain or loss associated with 
investments in different stocks if these stocks 
are bought on the same day and sold on the 
same day one month later 
e. The amount of gain or loss associated with 
investments in differcnt stocks that are 
bought and sold in different time periods, five 
years apart 
f. The prices bid by two different development 
firms in response to a building construction 
proposal 
3.75 
A local country club has a membership of 600 and 
operates facilities that include an 18-hole champi- 
onship golf course and 12 tennis courts. Before 
deciding whether to accept new members, the club 
president would like to know how many members 

regularly use each facility. A survey of the mem- 
bership indicates that 70% regularly use the golf 
course, 50% regularly use the tennis courts, and 
5% use neither of these facilities regularly. 
a. Construct a Venn diagram to describe the 
results of the survey. 
b. If one club member is chosen at random, what 
is the probability that the member uses either 
the golf course or the tennis courts or both? 
c. If one member is chosen at random, what is 
the probability that the member uses both the 
golf and the tennis lacilities? 
d. A member is chosen at random from among 
those known to use the tennis courts regularly. 
What is the probability that the member also 
uses the golf course regularly? 
3.76 
Insurance companies use rnorrality tables to help 
them determmc how large a premium to charge a 
particular individual for a particular life insurance 
policy. The accompanying table shows the proba- 
bility of survival to age 65 for persons of the spec- 
ified ages. 
Probability of Survival 
Age 
to Age 65 
~ - 
0 
.72 
10 
.74 
20 
.74 
30 
.75 
35 
.76 
40 
.77 
45 
.79 
50 
.81 
55 
.85 
60 
.90 
a. For a person 20 years old, what is the probabil- 
ity that he or she will die before age 65? 
b. Describe in words the trend indicated by the 
increasing probabilities in the second and 
fourth columns. 
3.77 
"What are the characteristics of families with 
young children (under age 6)?" This was one of 
several questions posed by a University of 
Michigan researcher in Children and Youth 
Services Review (Vol. 17. 1995). Using data 
obtained from the National Child Care Survey, 
the income distribution and employment status of 
these families are summarized in the table below: 
a. Find the probability that a randomly selected 
family with young children has an income 
above the poverty line, but less than $25,000. 
b. Find the probability that a randomly selected 
family with young children has unemployed 
parents or no parents. 
c. Find the probability that a randomly selected 
family with young children has an income 
below the poverty line. 
All-terrain vehicles (ATVs) came under fire in the 
1980s owing to the high number of injuries and 
deaths attributed to these machines. In response, 
manufacturers agreed to provide extensive safety 
warnings to owners, to develop a media safety- 
awareness program, and to implement a nation- 
wide training program. The Journal of Risk and 
Uncertainty (May 1992) published an article inves- 
tigating the relationship of injury rate to a variety 
of factors. One of the more interesting factors 
studied. age of thc drivcr, was found to havc a 
strong relationship to injury rate. The article 
reports that prior to the safety-awareness pro- 
gram, 14% of the ATV drivcrs were under age 12; 
another 13% were 12-15. and 48% were under 
age 25. Suppose an ATV driver is selected at 
random prior to the installation of the safety- 
awareness program. 
a. Find the probability that the ATV driver is 15 
years old or younger. 
b. Find the probability that the ATV driver is 25 
years old or older. 
c. Given that the ATV driver is under age 25, what 
is the probability the driver is under age 12? 
d. Are the events Under age 25 and Under age 12 
mutually exclusive? Why or why not? 
e. Are the events Under age 25 and Under age 12 
independent'? Why or why not? 
The probability that an Avon salesperson sells 
beauty products to a prospective customer on the 
first visit to the customer is .4. If the salesperson 
fails to make the sale on the first visit, the proba- 
bility that the sale will be made on the second visit 
is .65. The salesperson never visits a prospective 
customer more than twice. What is the probability 
Income Characferistic 
Percentage 
No parent 
1 
Below poverty line; not employed 
7 
Below poverty line; employed 
7 
Above poverty Ime, but less than $25,000, not employed 
2 
Above poverty h e ,  but less than $25,000; employed 
22 
$25,000 or more 
61 
i 
Total 
100 

158 CHAPTER 
3 
Probability 
t 
A Syqtem Comprised of Three Componcnts ~n Series 
Input 
Output 
i 
I 
that the salesperson will make a sale to a particu- 
lar customcr? 
3.80 
The perfol-mance of quality inspectors affects 
both the quality of outgoing products and the cost 
of the products. A product that passes inspection 
is assumed to meet quality standards; a product 
that fails inspection may be reworked, scrapped, 
or reinspected. Quality engineers at Westinghouse 
Electric Corporation evaluated performances of 
inspectors in judging the quality of solder joints by 
comparing each inspector's classifications of a set 
of 153 joints with the consensus evaluation of a 
panel of experts. The results for a particular 
inspector are shown in the accompanying table. 
INSPECTOR'S JUDGMENT 
Committee's Judgment 
Joint Acceptable 
Joint Rejectable 
Joint acceptable 
Joint rejectable 
Source: Meagher, J. J., and Scazzero. J. A. "Measuring inspector variability." 
39th Annunl Quality Congrevs Trunsnctions, May 1985, pp. 75-81, American 
Society for Quality Control. 
One of the 153 solder joints is to be selected at 
random. 
a. What is the probability that the inspector 
judges the joint to be acceptable? That the 
committee judges the joint to be acceptable? 
b. What is the probability that both the inspector 
and the committee judge the joint~to be 
acceptable? That neither judge the joint to be 
acceptable? 
c. What is the probability that the inspector and 
the committee disagree? Agree? 
3.81 
The figure shown above is a schematic represen- 
tation of a system comprised of three components. 
The system operates properly only if all three 
components operate properly. The three compo- 
nents are said to operate in series. The compo- 
nents could be mechanical or electrical; they could 
be work stations in an assembly process; or they 
could represent the functions of three different 
deparlrnents in an organization. The probability 
or Failure for each component is listed in the table. 
Assume the components operate independently 
of each other. 
Component 
Probability of Failure 
a. Find the probability that thc system operates 
properly. 
b. What isthe probability that at least one of the 
components will fail and therefore that the 
system will fail? 
3.82 
The figure below is a representation of a system 
comprised of two subsystems that are said to 
operate in parallel. Each subsystem has two com- 
ponents that operate in series (refer to Exercise 
3.81).The system will operate properly as long as 
at least one of the subsystems functions properly. 
The probability of failure for each component in 
the system is .l. Assume the components operate 
independently of each other. 
a. Find the probability that the system operates 
properly. 
b. Find the probability that exactly one subsys- 
tem fails. 
C. Find the probability that the system fails to 
operate properly. 
d. How many parallel subsystems like the two 
shown here would be required to guarantee 
that the system would opcrate properly at least 
99% of the time? 
3.83 
Consider the population of new savings accounts 
opened in one business day at a bank, as shown in 
the table. Suppose you wish to draw a random 
sample of two accounts from this population. 
Account Number 
0001 
0002 
0003 
0004 
0005 
Account Balance 
$1,000 
$12,500 
$850 
$1,000 
$3.450 
A System Comprised of Two Parallel Subsystems 
Subsystem A 
Input -----, 
>---output 
Subsystem B 
& 

a. List all possible different pairs of accounts that 
could be obtained. 
b. What is thc probability of selecting accounts 
0001 and 0004? 
c. What is the probability of selecting two 
accounts that each have a balance of $1,000? 
That each have a balance other than $1.000? 
3.84 
Two hundred shoppcrs at a large suburban mall 
were asked two questions: (1) Did you see a tele- 
vision ad for the sale at department store X 
during the past two weeks? (2) Did you shop at 
department store X during the past two weeks? 
The responses to these quections are summarized 
in the table. One of the 200 shoppers qucstioned is 
to be chosen at random. 
Shopped at X 
Did Not Shop at X 
Saw ad 
100 
25 
Did not see ad 
25 
50 
a. What is the probability that the person select- 
ed saw the ad? 
b. What is the probability that the person select- 
ed saw the ad and shopped at store X? 
c. Find the conditional probability that the 
person shopped at store X given that the 
person saw the ad. 
d. What is the probability that the person select- 
ed shopped at store X? 
e. Use your answers to parts a, b, and d to check 
the independence of the events {Saw ad} and 
{Shopped at XI. 
f. Are the two events (Did not see ad] and {Did 
not shop at X] mutually exclusive? Explain. 
3.85 
The National Resident Matching Program 
(NRMP) is a service provided by the Association 
of American Medical Colleges to match graduat- 
ing medical students with residency appointments 
at hospitals. After students and hospitals have 
evaluated each other, they submit rank-order lists 
of their preferences to the NRMP. Using a match- 
ing algorithm. the NRMP then generates final, 
nonnegotiable assignments of students to the res- 
idency programs of hospitals (Acorlemic Medicine. 
June 1995). Assume that three graduating med- 
ical students (#I, #2, and #3) have applied for posi- 
tions at three diffcrcnt hospitals (A, B, and C), 
where each hospital has one and only one resi- 
dent opening. 
a. How many different assignments of medical 
students to hospitals are possible? List them. 
b. Suppose student #1 prefers hospital B. If the 
NRMP algorithm is entirely random, what is 
the probabil~ty that the student is assigned to 
hospital B? 
A small brewery has two bottling machines. 
Machine A produces 75% of the bottles and 
machine B produces 25%. One out of every 20 
bottles filled by A is rejected for some reason, 
while one out of every 30 bottles from B is 
rejected. What proportion of bottles is rejected? 
What is the probability that a randomly selected 
bottle comes from machine A, given that it is 
accepted? 
Suppose there are 500 applicants for five equiva- 
lent positions at a factory and the company is able 
to narrow the field to 30 equally qualified appli- 
cants. Seven of the finalists are minority candi- 
dates. Assume that the five who are chosen are 
selected at random from this final group of 30. 
a. In how many different ways can the selection 
be made? 
b. What is the probability that none of the minor- 
ity candidates is hired? 
c. What is the probability that no more than one 
minority candidate is hired? 
A fair coin is flipped 20 times and 20 heads are 
observed. In such cases it is often said that a tail is 
due on the next flip. Is this statement true or 
false? Explain. 

R A N D O M  V A R I A B L E S  A N D  
P R O B A B I L I T Y  D I S T R I B U T I O N S  
C O N T E N  
................................. 
4.1. 
4.2 
4.3 
4.4 
4.5 
4.6 
4.7 
4.8 
T
S
"
 
............ 
Two Types of Random Variables 
Probability Distributions for Discrete Random Variables 
The Binomial Distribution 
The Poisson Distribution (Optional) 
Probability Distributions for Continuous Randoh Variables 
The Uniform Distribution (Optional) 
The Normal Distribution 
Descriptive Methods for Assessing Normality 
4.9 
Approximating a Binomial Distribution with a Normal Distribution (Optional) 
4.10 
The Exponential Distribution (Optional) 
4.11 
Sampling Distributions 
4.12 
The Central Limit Theorem 
S T A T I S T I C S  
I
N
 A
C
T
I
O
N
 
...................................................................................................................................................... 
IQ, Economic Mobility, and the Bell Curve 
n, ,,,. 
,., 
Where W e ' v e  B e e n  
W 
e saw by illustration in Chapter 3 how proba- 
bility would be used to make an inference 
about a population from data contained in an ob- 
served sample. We also noted that probability would 
be used to measure the reliability of the inference. 
, 
W h e r e  W e ' r e  G o i n g  
*r 
M 
ost of the experimental events we encountered 
in Chapter 3 were events described in words 
and denoted by capital letters. In real life, most sam- 
ple observations are numerical-in other words, they 
are numerical data. In this chapter, we learn that data 
are observed values of random variables. We study 
several important random variables and learn how to 
find the probabilities of specific numerical outcomes. 

168 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
- 
FIGURE 4.1 
Venn diagram for coin- 
tossing experiment 
You may have noticed that many of the examples of experiments in Chapter 3 
generated quantitative (numerical) observations. The Consumer Price Index, the 
unemployment rate, the number of sales made in a week, and the yearly profit of 
a company are all examples of numerical measurements of some phenomenon. 
Thus, most experiments have sample points that correspond to values of some nu- 
merical variable. 
To illustrate, consider the coin-tossing experiment of Chapter 3. Figure 4.1 is 
a Venn diagram showing the sample points when two coins are tossed and the up 
faces (heads or tails) of the coins are observed. One possible numerical outcome 
is the total number of heads observed. These values (0, 1, or 2) are shown in 
parentheses on the Venn diagram, one numerical value associated with each sam- 
ple point. In the jargon of probability, the variable "total number of heads ob- 
served when two coins are tossed" is called a random variable. 
DEFINITION 4.1 
A random variable is a variable that assumes numerical values associated 
with the random outcomes of an experiment, where one (and only one) nu- 
merical value is assigned to each sample point. 
The term random variable is more meaningful than the term variable because 
the adjective random indicates that the coin-tossing experiment may result in one 
of the several possible values of the variable-0,1, 
and 2-according to the ran- 
dom outcome of the experiment, HH, HT, TH, and TT. Similarly, if the experiment 
is to count the number of customers who use the drive-up window of a bank each 
day, the random variable (the number of customers) will vary from day to day, part- 
ly because of the random phenomena that influence whether customers use the 
drive-up window. Thus, the possible values of this random variable range from 0 to 
the maximum number of customers the window could possibly serve in a day. 
We define two different types of random variables, discrete and continuous, 
in Section 4.1. Then we spend the remainder of this chapter discussing specific 
types of random variables and the aspects that make them important in business 
applications. 
T W O  TYPES OF RANDOM VARIABLES 
Recall that the sample point probabilities corresponding to an experiment must 
sum to 1. Dividing one unit of probability among the sample points in a sample 
space and consequently assigning probabilities to the values of a random variable 
is not always as easy as the examples in Chapter 3 might lead you to believe. If the 
number of sample points can be completely listed, the job is straightforward. But 
if the experiment results in an infinite number of numerical sample points that are 
impossible to list, the task of assigning probabilities to the sample points is im- 
possible without the aid of a probability model. The next three examples demon- 
strate the need for different probability models depending on the number of 
values that a random variable can assume. 
- - - - - - " P - - - a - * * "  
" 
ional publication) is asked to 
or 3. A score is then obtained 
by adding together the ratings of the 10 experts. How many values can this 
random variable assume? 

; 
) 
1 
;e 
Le 
2- 
nt 
:h 
t- 
ie 
to 
H ,  
Fi c 
'SS 
1st 
~ l e  
~ l e  
he 
iut 
ire 
m- 
In- 
of 
I to 
led 
his 
& 
SECTION 4.1 
T W O  T y p e s  o f  R a n d o m  V a r i a b l e s  
169 
S o I u t i o n 
A sample point is a sequence of 10 numbers associated with the rating of each 
expert. For example, one sample point is 
{ L O ,  0,L LO, 0,3,1,01 
The random variable assigns a score to each one of these sample points by adding 
the 10 numbers together. Thus, the smallest score is 0 (if all 10 ratings are 0) and 
the largest score is 30 (if all 10 ratings are 3). Since every integer between 0 and 
30 is a possible score, the random variable denoted by the symbol x can assume 
31 values. Note that the value of the random variable for the sample point above 
is x = 8 .* 
This is an example of a discrete random variable, since there is a finite num- 
ber of distinct possible values. Whenever all the possible values a random variable 
can assume can be listed (or counted), the random variable is discrete. 
" .
1
_
1
*
1
n
P
n
m
m
 
Suppose the Environmental Protection Agency (EPA) takes readings once a 
month on the amount of pesticide in the discharge water of a chemical company. 
If the amount of pesticide exceeds the maximum level set by the EPA, the 
company is forced to take corrective action and may be subject to penalty. 
Consider the following random variable: 
Number, x, of months before the company's discharge 
exceeds the EPA's maximum level 
What values can x assume? 
S o I u t i o n The company's discharge of pesticide may exceed the maximum allowable level 
on the first month of testing, the second month of testing, etc. It is possible that the 
company's discharge will never exceed the maximum level. Thus, the set of 
possible values for the number of months until the level is first exceeded is the set 
of all positive integers 
1,2,3,4 ,... 
If we can list the values of a random variable x, even though the list is never- 
ending, we call the list countable and the corresponding random variable discrete. 
Thus, the number of months until the company's discharge first exceeds the limit 
is a discrete random variuble. 
3 
""A" 
Refer to Example 4.2. A second random variable of interest is the amount x of 
pesticide (in milligrams per liter) found in the monthly sample of discharge waters 
from the chemical company. What values can this random variable assume? 
*The standard mathematical convention is to use a capital letter (e.g., X) to denote the theoretical 
random variable.The possible values (or realizations) of the random variable are typically denoted 
with a lowercase letter (e.g.,x).Thus, in Example 4.1, the random variable X can take on the values 
x = 0,1,2,. . . ,30. Since this notation can be confusing for introductory statistics students, we 
simplify the notation by using the lowercase x to represent the random variable throughout. 

CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
- 
S o I u t i o n 
Unlike the number of months before the company's discharge exceeds the EPA's 
maximum level, the set of all possible values for the amount of discharge cannot 
be listed-i.e., 
is not countable. The possible values for the amounts of pesticide 
would correspond to the points on the interval between 0 and the largest possible 
value the amount of the discharge could attain, the maximum number of 
milligrams that could occupy 1 liter of volume. (Practically, the interval would be 
much smaller, say, between 0 and 500 milligrams per liter.) When the values of a 
random variable are not countable but instead correspond to the points on some 
interval, we call it a continuous random variable. Thus, the amount of pesticide in 
the chemical plant's discharge waters is a continuous random variable. * 
Random variables that can assume a countable number of values are called 
discrete. 
Random variables that can assume values corresponding to any of the points 
contained in one or more intervals are called continuous. 
Several more examples of discrete random variables follow: 
1. The number of sales made by a salesperson in a given week: x = 0,1,2,. .. 
2. The number of consumers in a sample of 500 who favor a particular product 
over all competitors: x = 0,1,2,. . . ,500 
3. The number of bids received in a bond offering: x = 0,1,2,. . . 
4. The number of errors on a page of an accountant's ledger: x = 0,1,2,. . . 
5. The number of customers waiting to be served in a restaurant at a particular 
time: x = 0, 1,2,. . . 
Note that each of the examples of discrete random variables begins with the 
words "The number of.. ." This wording is very common, since the discrete ran- 
dom variables most frequently observed are counts. 
We conclude this section with some more examples of continuous random 
variables: 
1. The length of time between arrivals at a hospital clinic: 0 5 x < a (infinity) 
2. For a new apartment complex, the length of time from completion until a 
specified number of apartments are rented: 0 5 x < a 
3. The amount of carbonated beverage loaded into a 12-ounce can in a can- 
filling operation: 0 5 x 5 12 
4. The depth at which a successful oil drilling venture first strikes oil: 
0 5 x 5 c, where c is the maximum depth obtainable 
5. The weight of a food item bought in a supermarket: 0 5 x 5 500 [Note: 
Theoretically, there is no upper limit on x, but it is unlikely that it would 
exceed 500 pounds.] 
Discrete random variables and their probability distributions are discussed 
in Sections 4.2-4.4. Continuous random variables and their probability distribu- 
tions are the topic of Sections 4.5-4.12. 

Z 
t 
f 
m 
a 
e 
n 
c 
. . 
.lct 
Jar 
the 
an- 
om 
ity) 
ti1 a 
:an- 
oil: 
lote: 
auld 
ssed 
:ibu- 
U 
SECTION 4.2 
P r o b a b i l i t y  D i s t r i b u t i o n s  f o r  D i s c r e t e  R a n d o m  V a r i a b l e s  
171 
Applying the Concepts 
4.1 What is a random variable? 
4.2 How do discrete and continuous random variables differ? 
4.3 Security analysts are professionals who devote full-time 
efforts to evaluating the investment worth of a narrow 
list of stocks. For example, one security analyst might 
specialize in bank stocks while another specializes in 
evaluating firms in the computer or pharmaceutical 
industries. The following variables are of interest to 
security analysts (Radcliffe, Investments: Concepts, 
Analysis and Strategy, 1994). Which are discrete and 
which are continuous random variables? 
a. The closing price of a particular stock on the New 
York Stock Exchange 
b. The number of shares of a particular stock that are 
traded each business day 
c. The quarterly earnings of a particular firm 
d. The percentage change in yearly earnings between 
1999 and 2000 for a particular firm 
e. The number of new products introduced per year by 
a firm 
f. The time until a pharmaceutical company gains ap- 
proval from the U.S. Food and Drug Administration 
to market a new drug 
4.4 Which of the following describe continuous random 
variables, and which describe discrete random variables? 
a. The number of newspapers sold by the New York 
Times each month 
b. The amount of ink used in printing a Sunday edition 
of the New York Times 
c. The actual number of ounces in a one-gallon bottle 
of laundry detergent 
d. The number of defective parts in a shipment of nuts 
and bolts 
e. The number of people collecting unemployment in- 
surance each month 
4.5 
Give two examples of a business-oriented discrete 
random variable. Do the same for a continuous random 
variable. 
4.6 Give an example of a discrete random variable that 
would be of interest to a banker. 
4.7 
Give an example of a continuous random variable that 
would be of interest to an economist. 
4.8 
Give an example of a discrete random variable that 
would be of interest to the manager of a hotel. 
4.9 
Give two examples of discrete random variables that 
would be of interest to the manager of a clothing store. 
4.10 Give an example of a continuous random variable that 
would be of interest to a stockbroker. 
PROBABILITY DISTRIBUTIONS FOR DISCRETE 
RANDOM VARIABLES 
A complete description of a discrete random variable requires that we specify the 
possible values the random variable can assume and the probability associated 
with each value. To illustrate, consider Example 4.4. 
~
-
~
~
~
"
s
"
~
~
"
"
b
"
>
"
*
-
~
*
~
m
-
-
~
~
-
~
~
 
- w h , % ~ % ~ ~ " ~ " ~ s " s , ~ ~ * ~ > " ~ >  
~ m ~ L , % v * m " . ~ - u s ~ s m ~ ~ ~ ~ ~ n m  
call the experiment of tossing two coins (Section 4.1), and let x  be the number 
of heads observed. Find the probability associated with each value of the random 
variable x, assuming the two coins are fair. 
S o I u t i o n 
The sample space and sample points for this experiment are reproduced in 
Figure 4.2. Note that the random variable x  can assume values 0,1,2. Recall (from 
Chapter 3) that the probability associated with each of the four sample points is 
'/,. Then, identifying the probabilities of the sample points associated with each of 
these values of x, we have 
P(x = 0) = P(TT) = i 
P(x = 1) = P ( T H )  + P ( H T )  = a + = $ 
P(x = 2) = P ( H H )  = a 

172 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
. 
- 
FIGURE 4.2 
Venn diagram for the two-coin- 
toss experiment 
FIGURE 4.3 
P ( 4  
Probability distribution for 
coin-toss experiment: 
1 
Graphical form 
1 
TABLE 4.1 
Probability Distribution for Coin- 
Toss Experiment: Tabular Form 
a. Point representation of p(x) 
b. Histogram representation of p(x) 
Thus, we now know the values the random variable can assume (O,l, 2) and 
how the probability is distributed over these values (x, 1/2, 'I4). 
This completely de- 
scribes the random variable and is referred to as the probability distribution, de- 
noted by the symbol p(x).* The probability distribution for the coin-toss example 
is shown in tabular form in Table 4.1 and in graphical form in Figure 4.3. Since the 
probability distribution for a discrete random variable is concentrated at specific 
points (values of x), the graph in Figure 4.3a represents the probabilities as the 
heights of vertical lines over the corresponding values of x. Although the repre- 
sentation of the probability distribution as a histogram, as in Figure 4.3b, is less 
precise (since the probability is spread over a unit interval), the histogram repre- 
sentation will prove useful when we approximate probabilities of certain discrete 
random variables in Section 4.4. 
We could also present the probability distribution for x as a formula, but this 
would unnecessarily complicate a very simple example. We give the formulas for 
the probability distributions of some common discrete random variables later in 
this chapter. 
DEFINITION 4.4 
The probability distribution of a discrete random variable is a graph, table, or 
formula that specifies the probability associated with each possible value the 
random variable can assume. 
Two requirements must be satisfied by all probability distributions for dis- 
crete random variables. 
*In standard mathematical notat~on, the probahilit that a random varlahle X takes on a value x 
is denoted P(x = r) = p(r).Thus, P(X = 0) = p(Of, P(X = 1) = p(l). etc. In th~s 
introductory 
text, we ddopt the slmpler p(x) notatmn. 
- 

1 
e 
e 
1C 
e 
1- 
5s 
=- 
te 
lis 
or 
i: 
lis- 
SECTION 4.2 
Probability Distributions f o r  Discrete Random Variables 
173 
equirements for the Probability Distribution of a Discrete 
  and om Variable, x 
1 
2 
I 
4 
I 
I 
2 
the toss of two fair coins) in Figure 4.4. Try to locate the mean of the distribution 
intuitively. We may reason that the mean p of this distribution is equal to 1 as fol- 
Example 4.4 illustrates how the probability distribution for a discrete ran- 
dom variable can be derived, but for many practical situations the task is much 
more difficult. Fortunately, many experiments and associated discrete random 
variables observed in business possess identical characteristics. Thus, you might 
observe a random variable in a marketing experiment that would possess the 
same characteristics as a random variable observed in accounting, economics, or 
management. We classify random variables according to type of experiment, de- 
rive the probability distribution for each of the different types, and then use the 
appropriate probability distribution when a particular type of random variable is 
observed in a practical situation. The probability distributions for most common- 
ly occurring discrete random variables have already been derived. (We describe 
two of these in Sections 4.3 and 4.4.) This fact simplifies the problem of finding the 
appropriate probability distributions for the business analyst. 
Since probability distributions are analogous to the relative frequency dis- 
tributions of Chapter 2, it should be no surprise that the mean and standard devi- 
ation are useful descriptive measures. For example, if a discrete random variable x 
were observed a very large number of times and the data generated were 
arranged in a relative frequency distribution, the relative frequency distribution 
would be indistinguishable from the probability distribution for the random vari- 
able.Thus, the probability distribution for a random variable is a theoretical model 
for the relative frequency distribution of a population. To the extent that the two 
distributions are equivalent (and we will assume they are), the probability distri- 
bution for x possesses a mean p and a variance a2 
that are identical to the corre- 
sponding descriptive measures for the population. This section explains how you 
can find the mean value for a random variable. We illustrate the procedure with an 
example. 
Examine the probability distribution for x (the number of heads observed in 
FI GURE 4.4 
lows: In a large number of experiments, l/, should result in x = 0, '/, in x = 1 , and 
Probability distribution for a 
l/, in x = 2 heads. Therefore, the average number of heads is 
two-coin toss 
E*. = o(;) + l($) + 2(9 = 0 + $ +; = 1 
Note that to get the population mean of the random variable x, we multiply 
each possible value of x by its probability p(x), and then sum this product over all 
possible values of x. The mean of x is also referred to as the expected value of x, 
denoted E(x). 
*Unless otherwise indicated, summations will always be over all possible values of x. 

174 
CHAPTER 4 
Random Variables and Probability Distributions 
- 
DEFINITION 4.5 
The mean, or expected value, of a discrete random variable x is 
The term expected is a mathematical term and should not be interpreted as it 
is typically used. Specifically, a random variable might never be equal to its "ex- 
pected value." Rather, the expected value is the mean of the probability distribu- 
tion or a measure of its central tendency.You can think of p as the mean value of x 
in a very large (actually, infinite) number of repetitions of the experiment. 
*mmsq*" I * ,a"YIYStS - 
I * a"n"mnm-m"sm"*"s~* 
1* IY*IU .
m
m
P
m
"
*
 
pose you work for an insurance company, and you sell a $10,000 one-year term 
insurance policy at an annual premium of $290. Actuarial tables show that the 
probability of death during the next year for a person of your customer's age, sex, 
health, etc., is .001. What is the expected gain (amount of money made by the 
company) for a policy of this type? 
S o I u t i o n 
The experiment is to observe whether the customer survives the upcoming year. 
The probabilities associated with the two sample points, Live and Die, are .999 and 
.OO1,~respectively. 
The random variable you are interested in is the gain x, which 
can assume the values shown in the following table. 
Gain, x 
Sample Point 
Probability 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
$290 
Customer lives 
.999 
-$9,710 
Customer dies 
.001 
If the customer lives, the company gains the $290 premium as profit. If the 
customer dies, the gain is negative because the company must pay $10,000, for a 
net "gain" of $(290 - 10,000) = -$9,710. The expected gain is therefore 
In other words, if the company were to sell a very large number of one-year 
$10,000 policies to customers possessing the characteristics described above, it 
would (on the average) net $280 per sale in the next year. 
Example 4.5 illustrates that the expected value of a random variable x need 
not equal a possible value of x. That is, the expected value is $280, but x will equal 
either $290 or -$9,710 each time the experiment is performed (a policy is sold 
and a year elapses).The expected value is a measure of central tendency-and in 
this case represents the average over a very large number of one-year policies- 
but is not a possible value of x. 
We learned in Chapter 2 that the mean and other measures of central ten- 
dency tell only part of the story about a set of data. The same is true about prob- P 
ability distributions. We need to measure variability as well. Since a probability 

1 
7 
1. 
d 
h 
he 
: a 
ear 
:, it 
eed 
pal 
;old 
d in 
:s- 
ten- 
rob- 
dity 
S ECTION 4.2 
Probability Distributions for Discrete Random Variables 
175 
distribution can be viewed as a representation of a population, we will use the 
population variance to measure its variability. 
The population variance a2 is defined as the average of the squared distance 
of x from the population mean p. Since x is a random variable, the squared distance, 
(x - 
is also a random variable. Using the same logic used to find the mean 
value of x, we find the mean value of (x - p)' by multiplying all possible values of 
(x - p)2 byp(x) and then summing over all possible x values." This quantity, 
is also called the expected value of the squared distance from the mean; that is, 
a2 = E[(x - p)']. The standard deviation of x is defined as the square root of the 
variance a2. 
DEFINITION 4.6 
The variance of a discrete random variable x is 
DEFINITION 4.7 
The standard deviation of a discrete random variable is equal to the square 
root of the variance, i.e., a = G. 
Knowing the mean p and standard deviation a of the probability distribu- 
tion of x, in conjunction with Chebyshev's Rule (Table 2.8) and the Empirical 
Rule (Table 2.9), we can make statements about the likelihood that values of x 
will fall within the intervals p k a, p & 2a, and p & 3a. These probabilities are 
given in the box. 
.. . 
. 
. 
Chebyshev's Rule and Empirical Rule for a Discrete 
Random Variable 
*It can be shown that E[(x - /.L)'] = E(x') - p2 where E(x2) = 
xZp(x). Note the similarity 
between this expression and the shortcut formula 
Chapter 2. 

176 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
FIGURE 4.5 
Shapes of two probability 
distributions for a discrete 
random variable x 
a. Skewed d~str~but~on 
b. Mound-shaped, symmetric 
-. 
SS 
ventures. Assume you know that 70% of such ventures are successful, the 
outcomes of the ventures are independent of one another, and the probability 
distribution for the  number,^, of successful ventures out of five is: 
a. Find p = E(x). Interpret the result. 
b. Find rr = d ~ [ ( x  
- p)2]. Interpret the result. 
c. Graph p(x). Locate p and the interval p f 2a on the graph. Use either 
Chebyshev's Rule or the Empirical Rule to approximate the probability 
1 
I 
that x falls in this interval. Compare this result with the actual probability. 
I 
d. Would you expect to observe fewer than two successful ventures out of five? j 
i 
S o I u t i o n 
a. Applying the formula, 
I 
p = E(x) = 
xp(x) = 0(.002) + 1(.029) + 2(.132) + 3(.309) 
+ 4(.360) + 5(.168) = 3.50 
On average, the number of successful ventures out of five will equal 3.5. Re- 
member that this expected value only has meaning when the experiment- ! 
investing in five Internet business ventures-is repeated a large number of 
times. 
b. 
Now we calculate the variance of x: 
+ (3 - 3.5)2(.309) + (4 - 3.5)2(.360) + (5 - 3.5)2(.168) 
= 1.05 
Thus, the standard deviation is 
(+= *= 
m = 1 . 0 2  - 

- 
S ECTION 4.2 
P r o b a b i l i t y  D i s t r i b u t i o n s  f o r  D i s c r e t e  Random Variables 
177 
This value measures the spread of the probability distribution of x, the num- 
ber of successful ventures out of five. A more useful interpretation is ob- 
tained by answering parts c and d. 
c. The graph of p(x) is shown in Figure 4.6 with the mean p and the inter- 
val p & 2 a  = 3.50 & 2(1.02) = 3.50 & 2.04 = (1.46,5.54) shown on the 
graph. Note particularly that p = 3.5 locates the center of the probability 
distribution. Since this distribution is a theoretical relative frequency dis- 
tribution that is moderately mound-shaped (see Figure 4.6), we expect 
(from Chebyshev's Rule) at least 75% and, more likely (from the Empiri- 
cal Rule), approximately 95% of observed x values to fall in the interval 
p f 2a-that 
is, between 1.46 and 5.54. You can see from Figure 4.6 that 
the actual probability that x falls in the interval p f 2 a  includes the sum 
of p(x) for the values x = 2, x = 3, x = 4, and x = 5 .This probability is 
p(2) + p(3) + p(4) + p(5) = .I32 + .309 + .360 + .I68 = .969. Therefore, 
96.9% of the probability distribution lies within 2 standard deviations of 
the mean. This percentage is consistent with both Chebvshev's Rule and 
the Empirical Rule. 
- 
F IG U R E  4.6 
Graph of p(x) for Example 4.6 
Fewer than two successful ventures out of five implies that x = 0 or x = 1. 
Since both these values of x lie outside the interval p & 2a, we know from 
the Empirical Rule that such a result is unlikely (approximate probability 
of .05).The exact probability, P(x 5 l), is p(0) + JI(~) = ,002 + ,029 = .031. 
Consequently, in a single experiment where we invest in five Internet busi- 
ness ventures, we would not expect to observe fewer than two successful 
ones. 
Learning the Mechanics 
4.11 A dl~crete random variable x can assume five possible 
I 
values: 2, 3, 5, 8, and 10. Its probability distribution is 
p(x) 
.15 
.10 - .25 
.25 
shown here: 

178 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
a. What is p(5)? 
b. What is the probability that x equals 2 or lo? 
c. What is P(x 5 8)? 
4.12 Explain why each of the following is or is not a valid 
probability distribution for a discrete random variable x: 
a. 
x 
0
1
2
3
 
4.13 The random variable x has the following discrete prob- 
ability distribution: 
a. Find p = E(x). 
b. Find u2 = E [ ( x  - p)']. 
c. Find u. 
d. Interpret the value you obtained for p. 
e. In this case, can the random variable x ever assume 
the value p? Explain. 
f. In general, can a random variable ever assume a 
value equal to its expected value? Explain. 
4.15 Consider the probability distribution for the random 
variable x shown at the top of the next column. 
X 
p(x) 
a. Find p, u2, and a. 
b. Graphp(x). 
c. Locate p and the interval p f 2u on your graph. 
What is the probability that x will fall within the in- 
terval p f 2u? 
1 
3 
5 
7 
9 
.1 
.2 
.4 
.2 
.1 
Applying the Concepts 
4.16 The age distribution as of July 1, 1999 for the 55 
employees of a highly successful two-year old "dot- 
com" company headquartered in Atlanta is shown at 
the bottom of the page. An employee is to be random- 
ly selected from this population. 
a. Can the relative frequency distribution in the table 
be interpreted as a probability distribution? Explain. 
b. Graph the probability distribution. 
c. What is the probability that the randomly selected 
employee is over 30 years of age? Over 40 years of 
t 
a. Find P(x 5 3). 
b. Find P(x < 3). 
c. Find P(x = 7). 
d. Find P(x 2 5). 
e. Find P(x > 2). 
f. Find P(3 % x 5 9). 
4.14 Consider the probability distribution shown here. 
age? Under 30 years of age? 
d. What is the probability that the randomly selected 
employee will be 25 or 26 years old? 
x 
p(x) 
4.17 Nitrous oxide, more commonly known as "laughing gas," 
1
2
4
1
0
 
.2 
.4 
.2 
.2 
is used extensively in dental procedures. According to 
the American Dental Association, 60% of all dentists 
use nitrous oxide in their practice (New York Times, June 
20,1995). Suppose x equals the number of dentists in a 
random sample of five dentists who use laughing gas in 
practice. If p = .60 is the probability of any one dentist 
using laughing gas (and the dentists operate indepen- 
Find the probability that the number of dentists using 
laughing gas in the sample of five is 
a. 4 
b. less than 2 
c. greater than or equal to 3 
dently), then the probability distribution of x (we show 
how to calculate these probabilities in Section 4.3) is: 
4.18 A team of consultants studied the service operation at 
the Wendy's Restaurant in the Woodbridge Mall in 
Woodbridge, New Jersey. They measured the time 
between customer arrivals to the restaurant over the 
course of a day and used those data to develop a prob- 
ability distribution to characterize x, the number of 
X 
- 
Source: Personal communication from P. George Benson. 
- 
0 
1 
2 
3 
4 
5 

t 
e 
1. 
d , 
f 
:d 
. ,3 
to 
its 
ne 
L a 
in 
ist 
:n- 
3W 
5 -- 
778 - 
ing 
n at 
1 in 
ime 
the 
rob- 
r of - 
33 - 
12.73 - 
SECTION 4.2 
P r o b a b i l i t y  D i s t r i b u t i o n s  f o r  D i s c r e t e  Random Variables 
179 - 
Probability Distribution for Exercise 4.18 
Source: Ford, R., Roberts, D., and Saxton, P. Queuing Models. Graduate School of Management, Rutgers 
Univers~ty. 1992. 
customer arrivals per 15-minute period. The distribu- 
tion is shown in thk table at the top of this page. 
a. Does this distribution meet the two requirements for 
the probability distribution of a discrete random 
variable? Justify your answer. 
h. What is the probability that exactly 16 customers 
enter the restaurant in the next 15 minutes? 
c. Find p(x 5 10). 
d. Find p(5 5 x 5 15). 
4.19 In a study of tax write-offs by the affluent, Peter 
Dreier of Occidental College (Los Angeles) compiled 
the relative frequency distribution shown on the right. 
The distribution describes the incomes of all house- 
holds in the United States that filed tax returns in 
1995. A household is to be randomly sampled from 
this population. 
a. Explain why the percentages in the table can be in- 
terpreted as probabilities. For example, the proba- 
bility of selecting a household with income under 
$10,000 is ,185. 
h. Find the probability that the selected household has 
income over $200,000; over $100,000; less than 
$100.000; between $30,000 and $49,999. 
. 
c. Together, the income categories (1,2,3,. .) and the 
percentages form a discrete probability distribution. 
Graph this distribution. 
d. What is the probability that the randomly selected 
household will fall in income category 6? In income 
category 1 or 9? 
......................................................................................................... .+,.. ....... 
Income 
Percentage of 
Category 
Household Income 
Households 
..................................................................................................................... 
1 
Under $10,000 
18.5 
2 
$10,000 to $19,999 
19.0 
3 
$20,000 to $29,999 
15.9 
4 
$30,000 to $39,999 
12.8 
5 
$40,000 to $49,999 
9.1 
6 
$50,000 to $74,999 
13.8 
7 
$75,000 to $99,999 
5.7 
8 
$1 00,000 to $199,999 
4.1 
9 
$200,000 and over 
1.1 
Source: Johnston, D.C. "The Divine Write-off." New York Times, 
January 12,1996, p.D1. 
4.20 Many real-world systems (e.g., electric power transmis- 
sion, transportation, telecommunications, and manufac- 
turing systems) can be regarded as capacitated-flow 
networks, whose arcs have independent but random 
capacities. A team of Chinese university professors 
' 
investigated the reliability of several flow networks in 
the journal Networks (May 1995). One network exam- 
ined in the article, and illustrated below, is a bridge net- 
work with arcs a,, a,, a3, a,, a,, and a,. The probability 
distribution of the capacity x for each of the six arcs is 
provided in the table on p. 180. 
a. Verify that the properties of discrete probability 
distributions are satisfied for each arc capacity 
distribution. 
Source * - 
0 
as 
4 
- 
Sink 
node 
node 
a, 
a6 

180 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
b. Find the probability that the capacity for arc a, will 
exceed 1. 
c. Repcat part b for each of the remaining five arcs. 
d. One path from the source node to the sink node is 
through arcs a,and a,. Find the probability that the 
system maintains a capacity of more than 1 through 
the a,-a, path. (Recall that the arc capacities are 
independent.) 
Probability Distribution for Exercise 4.20 
................................................................................................................. 
Arc 
Capacity ( x )  
p(x) 
Arc 
Capacity ( x )  
p(x) 
................................................ 
................................................ 
a1 
3 
.60 
a4 
1 
.90 
2 
.25 
0 
.10 
1 
.10 
0 
.05 
................................................ 
................................................ 
a2 
2 
.60 
a5 
1 
.90 
1 
.30 
0 
.10 
0 
.10 
................................................ 
................................................ 
a3 
1 
.90 
a6 
2 
.70 
0 
.10 
1 
.25 
0 
.05 
Source: Lin. J., et al. "On reliability evaluation of capacitated-flow 
network in terms of minimal pathsets." Network\. Vol. 25, No. 3, May 
1995, p. 135 (Table l), 1905, John Wiley and Sons. 
Firm A 
Firm B 
....................................................................................................... 
Loss next year 
Probability 
Loss next year 
Probability 
........................................................................................................... 
$
0
 
.01 
$
0
 
.OO 
500 
.01 
200 
.01 
1,000 
.01 
700 
.02 
1,500 
.02 
1,200 
.02 
2,000 
.35 
1,700 
.I5 
2,500 
.30 
2,200 
.30 
3,000 
.25 
2,70tr 
.30 
3,500 
.02 
3,200 
.15 
4.000 
.01 
3,700 
.02 
4.500 
.01 
4,200 
.02 
5,000 
.01 
4,700 
.01 
4.23 A team of consultants working for a large national 
supermarket chain based in the New York metropolitan 
area developed a statistical model for predicting the 
annual sales of potential new store locations. Part of 
their analysis involved identifying variables that influ- 
ence store sales, such as the size of the store (in square 
feet), the size of the surrounding population, and the 
number of checkout lanes. They surveyed 52 supermar- 
kets in a particular region of the country and construct- 
ed the relative frequency distribution shown at the 
bottom of the page to describe the number of checkout 
lanes ner store. x. 
4.21 Refer to Exercise 4.20. Compute the mean capacity of 
a. Why do the relative frequencies in the table repre- 
each of the six arcs. Interpret the results. 
sent the approximate probabilities of a randomly se- 
4.22 The risk of a portfolio of financial assets is sometimes 
lected supermarket having x number of checkout 
callcd investment risk (Radcliffe, 1994). In general, 
lanes? 
invcstrnent risk is typically measured by computing the 
b. Find E(x) and interpret its value in the context of 
variance or standard deviation of the probability distri- 
the problem. 
bution that describes the decision-maker's potential 
c. Find the standard deviation of x. 
outcomes (gains or losses). The greater the variation in 
. 
d. According to Chebyshcv's Rule (Chapter 2), what 
potential outcomes, the greater the uncertainty faced 
percentage of supermarkets would be expected to 
by the decision-maker; the smaller the variation in 
fall within p EL a ?  Within p f 2a? 
I
i 
potential outcomes, the more predictable the decision- 
e. What is the actual number of supermarkets that fall 
maker's gains or losses.The two discrete probability dis- 
within p f a ?  p f 2u? Compare your answers to 
tributions givcn in the table (upper right) were 
those of part d. Are the answers consistent? 
i 
i 
developed from historical data. They describe the 
4.24 Most states offer weekly lotteries to generate revenue 
potential total physical damagc losses next year to the 
for the state. Despite the long odds of winning, resi- 
fleets of delivery trucks of two different firms. 
dents continue to gamble on the lottery each week 
a. Verify that both firms have the same expected total 
(see Chaptcr 3's Statistics in Action). The chance of 
physical damage loss. 
winning Florida's Pick-6 Lotto game is 1 in approxi- 
b. Compute the standard deviation of each probabili- 
mately 23 million. Suppose you buy a $1 Lotto ticket 
ty distribution, and determine which firm faces the 
in anticipation of winning the $7 million grand prize. 
greatcr risk of physical damagc to its fleet next 
Calculate your expected net winnings. Interpret the 
year. 
result. 
x 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
Relative Frequency 
.01 
.04 
.04 
.08 
.lo 
.15 
.25 
.20 
.08 
.05 
Source: Adapted from Chow, W., et. 01. "A model for predicting a supermarket's annual sales per square foot." 
Graduate School of Management. Rutgers University, 1994. 

SECTION 4.3 
T h e  B i n o m i a l  D i s t r i b u t i o n  
181 
THE BINOMIAL DISTRIBUTION 
Many experiments result in dichotomous responses-i.e., responses for which there 
exist two possible alternatives, such as Yes-No, Pass-Fail, Defective-Nondefective, 
or Male-Female. A simple example of such an experiment is the coin-toss experi- 
ment. A coin is tossed a number of times, say 10. Each toss results in one of two 
outcomes, Head or Tail. Ultimately, we are interested in the probability distribu- 
tion of x, the number of heads observed. Many other experiments are equivalent 
to tossing a coin (either balanced or unbalanced) a fixed number n of times and 
observing the number x of times that one of the two possible outcomes occurs. 
Random variables that possess these characteristics are called binomial random 
variables. 
Public opinion and consumer preference polls (e.g., the CNN, Gallup, and 
Harris polls) frequently yield observations on binomial random varrables. For ex- 
ample, suppose a sample of 100 current customers is selected from a firm's data 
base and each person is asked whether he or she prefers the firm's product (a 
Head) or prefers a competitor's product (a Tail). Suppose we are interested in x, 
the number of customers in the sample who prefer the firm's product. Sampling 
100 customers is analogous to tossing the coin 100 times. Thus, you can see that 
consumer preference polls like the one described here are real-life equivalents of 
coin-toss experiments. We have been describing a binomial experiment; it is iden- 
tified by the following characteristics. 
a. You randomly select three bonds out of a possible 10 for an investment 
portfolio. Unknown to you, eight of the 10 will maintain their present value, 
and the other two will lose value due to a change in their ratings. Let x be 
the number of the three bonds you select that lose value. 
t 
f 
lt 
0 
11 
0 
b. Before marketing a new product on a large scale, many companies will conduct 
a consumer preference survey to determine whether the product is likely to be 
successful. Suppose a company develops a new diet soda and then conducts a 
taste preference survey in which 100 randomly chosen consumers state their 
preferences among the new soda and the two leading sellers. Let x be the num- 
ber of the 100 who choose the new brand over the two others. 
t 
4. The trials are independent. 
5. The binomial random variable x is the number of S's in n trials. 
c. Some surveys are conducted by using a method of sampling other than 
simple random sampling (defined in Chapter 3). For example, suppose a 

182 
CHAPTER 4 
Random Variables and Probability Distributions 
television cable company plans to conduct a survey to determine the frac- 
tion of households in the city that would use the cable television service.The 
sampling method is to choose a city block at random and then survey every 
household on that block. This sampling technique is called cluster sampling. 
Suppose 10 blocks are so sampled, producing a total of 124 household 
responses. Let x be the number of the 124 households that would use the 
television cable service. 
S o I u t i 0 n 
a. In checking the binomial characteristics in the box, a problem arises with 
both characteristic 3 (probabilities remaining the same from trial to trial) 
and characteristic 4 (independence). The probability that the first bond you 
1 
pick loses value is clearly 2/1@ Now suppose the first bond you picked was 
one of the two that will lose value. This reduces the cl.,ance that the second 
bond you pick will lose value to '/,, since now only one of the nine remaining 
1 
bonds are in that category. Thus, the choices you make are dependent, and 
therefore x, the number of three bonds you select that lose value, is not a 
binomial random variable. 
b. Surveys that produce dichotomous responses and use random sampling 
techniques are classic examples of binomial experiments. In our example, 
1 
each randomly selected consumer either states a preference for the new 
diet soda or does not. The sample of 100 consumers is a very small propor- 
tion of the totality of potential consumers, so the response of one would be, 
I 
for all practical purposes, independent of another." Thus, x is a binomial 
random variable. 
I 
c. This example is a survey with dichotomous responses (Yes or No to the 
1 
J 
cable service), but the sampling method is not simple random sampling. i 
Again, the binomial characteristic of independent trials would probably not 
be satisfied.The responses of households within a particular block would be 
dependent, since the households within a block tend to be similar with re- 
spect to income, level of education, and general interests. Thus, the binomial 
' 
model would not be satisfactory for x if the cluster sampling technique were 
employed. 
20% are laptops. 
a. Use the steps given in Chapter 3 (box on page 124) to find the probabilitj 
that all of the next four on-line PC purchases are laptops. 
b. Find the probability that three of the next four on-line PC purchases are 
laptops. 
1 
c. Let x represent the number of the next four on-line PC purchases that are 
laptops. Explain why x is a binomial random variable. 
I 
d. Use the answers to parts a and b to derive a formula for p(x), the probab~l- 
ity distribution of the binomial random variable x. 
*In most real-life applications of the binomial distribution, the population of interest has a finite 
number of elements (trials), denoted N. When N is large and the sample slze n 1s small relative to 
N, say n/N 5 ,051, the sampling procedure, for all practical purposes, satisfies the conditions of a 
binomial experiment. 
e. 

:- 
e 
Y 
5 
d 
le 
th 
1) 
)U 
as 
ld 
22 
ld 
' a 
ng 
le, 
:w 
)r- 
=, 
ial 
he 
ng. 
lot 
be 
re- 
rial 
ere 
q " 
on- 
md 
lity 
are 
are 
~bil- 
0 
SECTION 4.3 
T h e  Binomial Distribution 
183 " 
S 0 I u t i 0 n 
a. 1. The first step is to define the experiment. Here we are interested in ob- 
serving the type of PC purchased on-line by each of the next four (buy- 
ing) customers: desktop (D) or laptop (L). 
2. Next, we list the sample points associated with the experiment. Each 
sample point consists of the purchase decisions made by the four on-line 
customers. For example, DDDD represents the sample point that all 
four purchase desktop PCs, while LDDD represents the sample point 
that customer 1 purchases a laptop, while customers 2,3, and 4 purchase 
desktops. The 16 sample points are listed in Table 4.2. 
TABLE 4.2 
Sample Points for PC Experiment of Example 4.8 
DDDD 
LDDD 
LLDD 
DLLL 
LLLL 
DLDD 
r 
* 
LDLD 
LDLL 
DDLD 
LDDL 
LLDL 
DDDL 
DLLD 
LLLD 
DLDL 
DDLL 
3. We now assign probabilities to the sample points. Note that each sample 
point can be viewed as the intersection of four customers' decisions and, 
assuming the decisions are made independently, the probability of each 
sample point can be obtained using the multiplicative rule, as follows: 
P(DDDD) = P[(customer 1 chooses desktop) n (customer 2 chooses desktop) 
rl (customer 3 chooses desktop) n (customer 4 chooses desktop)] 
= P(customer 1 chooses desktop) X P(customer 2 chooses 
desktop) X P(customer 3 chooses desktop) 
X P(customer 4 chooses desktop) 
All other sample point probabilities are calculated using similar reason- 
ing. For example, 
You can check that this reasoning results in sample point probabilities 
that add to 1 over the 16 points in the sample space. 
4. Finally, we add the appropriate sample point probabilities to obtain the 
desired event probability. The event of interest is that all four on-line 
customers purchase laptops. In Table 4.2 we find only one sample point, 
LLLL, contained in this event. All other sample points imply that at 
least one desktop is purchased. Thus, 
P(A11 four purchase laptops) = P(LLLL) = (.2)4 = .0016 
That is, the probability is only 16 in 10,000 that all four customers pur- 
chase laptop PCs. 

184 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
b. The event that three of the next four on-line buyers purchase laptops con- 
sists of the four sample points in the fourth column of Table 4.2: 
D L L  L, LDLL, L L D L , . ~ ~ ~  
LLLD. To obtain the event probability we add 
the sample point probabilities: 
P(3 of next 4 customers purchase laptops) 
= P(DLLL) + P(LDLL) + P(LLDL) + P(LLLD) 
= (.2)3(.8) + (.2)3(.8) + (.2)3(.8) + (.2)".8) 
= 4(.2)3(.8) = .0256 
Note that each of the four sample point probabilities is the same, because 
each sample point consists of three L's and one D; the order does not affect 
the probability because the customers' decisions are (assumed) 
independent. 
We can characterize the experiment as consisting of four identical trials- 
the four customers' purchase decisions. There are two possible outcomes to i 
each trial, D or L, and the probability of L ,  p = .2, is the same for each trial. 
we are assuming that each customer's purchase decision is indepen- 
dent of all others, so that the four trials are independent.Then it follows that 
x, the number of the next four purchases that are laptops, is a binomial ran- 
dom variable. 
The event probabilities in parts a and b provide insight into the formula for 
the probability distribution p(x). First, consider the event that three pur- 
chases are laptops (part b). We found that 
I 
P(x = 3 )  = (Number of sample points for which x = 3 )  X 
(.2)Number of laptop5 purchased x 
Number of desktops purchased 
(.8) 
= 4(.2)".8)' 
In general, we can use combinatorial mathematics to count the number of 
sample points. For example, 
Number of sample points for which (x = 3) 
= Number of different ways of selecting 3 of the 4 trials for L purchases 
The formula that works for any value of x can be deduced as follows. Since 
P(x = 3 )  = (:)(.2)'(.8)', the p(x) = 
(.2)7.8)4-x 
(3 
The component 
counts the number of sample points with x laptops and 
(9 
the component (.2)x(.8)4-x is the probability associated with each sample 
point having x laptops. 

S ECT ION 4.3 
T h e  Binomial D i s t r i b u t i o n  
185 
d 
t 
1 
- 
0 
11. 
1- 
at 
n- 
or 
Lr - 
- of 
ises 
Lnce 
s and 
mple 
For the general binomial experiment, with n  trials and probability of Suc- 
cess p  on each trial, the probability of x Successes is 
No. of simple 
Probability of x S's 
events w~th 
and (n - x) F's m 
x S's 
any s~mple event 
" * 
In theory, you could always resort to the principles developed in Example 4.8 
to calculate binomial probabilities; list the sample points and sum their probabili- 
ties. However, as the number of trials (rt) increases, the number of sample points 
grows very rapidly (the number of sample points is 2").Thus, we prefer the formu- 
la for calculating binomial probabilities, since its use avoids listing sample points. 
The binomial distribution is summarized in the box. 
F 
The Binomial Probability Distribution 
where 
p  = Probability of a success on a single trial 
q = l - p  
n = Number of trials 
x = Number of successes in n trials 
As noted in Chapter 3, the symbol 5! means 5 -4.3 ~ 2 . 1  
= 120. Similarly, 
n! = n(n - l ) ( n  - 2) - - -3.2-1; remember, O! = 1. 
The mean, variance, and standard deviation for the binomial random vari- 
able x are shown in the box. 
'.i.% 
fid. 
. *.b. 
rim 
Mean, Variance, and Standard Deviation for a Binomial 
~andom 
variable 
Mean: p = np 
Variance: a2 = npq 
Standard deviation: a = 6 
As we demonstrated in Chapter 2, the mean and standard deviation provide 
measures of the central tendency and variability, respectively, of a distribution. Thus, 
we can use p and cr to obtain a rough visualization of the probability distribution for 

186 
C HAPTER 4 
Random Variables and Probability Distributions 
x when the calculation of the probabilities is too tedious.To illustrate the use of the 
binomial probability distribution, consider Examples 4.9 and 4.10. 
A machine that produces stampings for automobile engines is malfunctioning 
and producing 10% defectives. The defective and nondefective stampings proceed 
from the machine in a random manner. If the next five stampings are tested, find 
the probability that three of them are defective. 
S 0 I u t i 0 n 
Let x equal the number of defectives in n = 5 trials.Then x is a binomial random 
variable withp, the probability that a single stamping will be defective, equal to .I, 
and q = 1 - p = 1 - .1 = .9. The probability distribution for x is given by the 
expression 
- 
- 
5! 
x!(5 - x)! (.1)x(.9)5-x 
To find the probability of observing x = 3 defectives in a sample of n = 5. 
substitute x = 3 into the formula for p(x) to obtain 
Note that the binomial formula tells us that there are 10 sample points having 3 
defectives (check this by listing them), each with probability (.1)3(.9)2. 
" 
%
-
-
 
p(x). Calculate the mean p and standard deviation a. Locate p and the interval 
p - 2a to p + 2a on the graph. If the experiment were to be repeated many 
times, what proportion of the x observations would fall within the interval p - 2u 
to p + 2a? 
S o I u t i o n 
Again, n = 5, p = .I, and q = .9. Then, substituting into the formula for p(x): 

SECTION 4.3 
T h e  Binomial Distribution 
187 
The graph of p(x) is shown as a probability histogram in Figure 4.7. b(3) is 
taken from Example 4.9 to be .0081.] 
FIGURE 4.7 
The binomial distribution: n = 5, p = .I 
To calculate the values of p and a, substitute n = 5 and p = .1 into the fol- 
lowing formulas: 
To find the interval p - 2 u  to p + 2u, we calculate 
If the experiment were to be repeated a large number of times, what pro- 
portion of the x observations would fall within the interval p - 2u to p + 2a? 
You can see from Figure 4.7 that all observations equal to 0 or 1 will fall within the 
interval. The probabilities corresponding to these values are S905 and .3280, re- 
spectively. Consequently, you would expect .5905 + .3280 = .9185, or approxi- 
mately 91.9%, of the observations to fall within the interval p - 2u to p + 2a. 
This again emphasizes that for most probability distributions, observations rarely 
fall more than 2 standard deviations from p. 
Using Binomial Tables 
Calculating binomial probabilities becomes tedious when n is large. For some 
values of n and p the binomial probabilities have been tabulated in Table I1 of Ap- 
pendix B. Part of Table I1 is shown in Table 4.3; a graph of the binomial probabil- 
ity distribution for n = 10 and p = .10 is shown in Figure 4.8. Table I1 actually 
contains a total of nine tables, labeled (a) through (i), one each corresponding to 
n = 5,6,7,8,9,10,15,20, and 25. In each of these tables the columns correspond 
to values of p, and the rows correspond to values (k) of the random variable x. 
The entries in the table represent cumulative binomial probabilities, P(x 5 k). 

188 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
TABLE 4.3 
Reproduction of Part of Table I I  of Appendix B: Binomial Probabilities for n = 10 
FIGURE 4.8 
P(X> 
Binomial probability distribution for n = 10 
and p = .lo; P ( x  5 2) shaded 
.4 
a 
.3 
.2 
.1 
0 
r 
4 
0 1 2 3 4 5 6 7 8 9 1 0  
corresponding to k = 2 is .930 (shaded), and its interpretation is 
! 
Thus, for example, the entry in the column corresponding to p = .I0 and the row 
P(x 5 2) = P ( x  = 0) + P ( x  = 1) + P(x = 2) = .930 
This probability is also shaded in the graphical representation of the binomial dis- 
: 
tribution with n = 10 and p = .10 in Figure 4.8. 
You can also use Table I1 to find the probability that x  equals a specific value. 
For example, suppose you want to find the probability that x  = 2 in the binomial 
distribution with n = 10 and p = .lo. This is found by subtraction as follows: 
I 
P ( x  = 2) = [ P ( x  = 0) + P ( x  = 1) + P(x = 2)] - [ P ( x  = 0) + P(x = I)] 
The probability that a binomial random variable exceeds a specified value 
can be found using Table I1 and the notion of complementary events. For example, 
to find the probability that x  exceeds 2 when n = 10 and p = .lo, we use 
Note that this probability is represented by the unshaded portion of the graph in 
Figure 4.8. 
All probabilities in Table I1 are rounded to three decimal places. Thus, al- 
though none of the binomial probabilities in the table is exactly zero, some are 
small enough (less than .0005) to round to .000. For example, using the formula to 
find ~ ( x  
= 0) when n = 10 and p = .6, we obtain 

X 
N 
S- 
e. 
a1 
ue 
lle, 
, in 
al- 
are 
1 to 
S ECT ION 4.3 
T h e  Binomial Distribution 
189 
but this is rounded to .000 in Table I1 of Appendix B (see Table 4.3). 
Similarly, none of the table entries is exactly 1.0, but when the cumulative 
probabilities exceed .9995, they are rounded to 1.000. The row corresponding to 
the largest possible value for x, x = n, is omitted, because all the cumulative 
probabilities in that row are equal to 1.0 (exactly). For example, in Table 4.3 with 
n = 10, P(x 5 10) = 1 .O, no matter what the value of p. 
The following example further illustrates the use of Table 11. 
t 
S o l u t i o n  
Suppose a poll of 20 employees is taken in a large company. The purpose is to 
determine x, the number who favor unionization. Suppose that 60% of all the 
company's employees favor unionization. 
a. Find the mean and standard deviation of x. 
b. Use Table I1 of Appendix B to find the probability that x 5 10. 
c. Use Table I1 to find the probability that x > 12. 
d. Use Table I1 to find the probability that x = 11. 
e. Graph the probability distribution of x and locate the interval p & 2a on 
the graph. 
a. The number of employees polled is presumably small compared with the 
total number of employees in this company. Thus, we may treat x, the 
number of the 20 who favor unionization, as a binomial random variable. 
The value of p is the fraction of the total employees who favor unionization; 
i.e., p = .6. Therefore, we calculate the mean and variance: 
p = np = 20(.6) = 12 
a2 = npq = 20(.6)(.4) = 4.8 
b. Looking in the k = 10 row and the p = .6 column of Table I1 (Appendix B) 
for n = 20, we find the value of .245. Thus, 
c. To find the probability 
we use the fact that for all probability distributions, 
p(x) = 1. Therefore, 
All x 
Consulting Table 11, we find the entry in row k = 12, column p = .6 to be 
3 4 .  Thus, 

190 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
I 
d. To find the probability that exactly 11 employees favor unionization, recall 
that the entries in Table I1 are cumulative probabilities and use the relationship 
P(x = 11) = [p(O) + p(1) + . . . + p ( l l ) ]  - [p(O) + p(1) + . . + p(lO)] 
= P(x 5 11) - P(x 5 10) 
Then 
P ( x  = 11) = .404 - .245 = .I59 
I 
I 
e. The probability distribution for x in this example is shown in Figure 4.9. 
aC 
Note that 
The interval (7.6, 16.4) is also shown on Figure 4.9. The probability that x 
falls in this interval is P(x = 8,9,10, ... , 16) = P(x 5 16) - P(x 5 7 )  = 
.984 - .021 = .963. This probability is very close to the .95 given by the 
Empirical Rule. Thus, we expect the number of employees in the sample of 
20 who favor unionization to be between 8 and 16. 
The binomial probability 
distribution for x in 
.20 
Example 4.1 1 : n = 20, 
p = .6 
.15 
I Binomial Probabilities 
Binomial Probabilities on the TI-83 
To compute P ( x  = k), the probability of k successes in n trials, where the p is proba- 
bility of success for each trial, use the binompdf( command. Binompdf stands for "bi- 
(continued) 

ba- 
bi- 
ed) 
S ECT ION 4.3 
T h e  B i n o m i a l  D i s t r i b u t i o n  
191 " 
sity function." This command is undef'the DISTRibution menu 
and has the format binompdf(n,p, k). 
EXAMPLE: 
Compute the probability of 5 successes in 8 trials where the probability of success for 
a single trial is 40% 
In this example, n = 8, p = .4, and k = 5 
Press 
2nd 
VARS 
for 
DISTR 
Press the down arrow key until 
0:binompdf 
is highlighted 
Press 
ENTER 
After 
binompdf(, type 
8, .4,5) 
Press 
ENTER 
You should see 
Thus, P(X = 5.) is about 12.4%. 
P(x 5 k )  
To compute P(x 5 k), the probability of k or fewer successes in n trials, where thep is 
probability of success for each trial, use the binomcdf( command. Binomcdf stands for 
"binomial cumulative probability density function." This command is under the DIS- 
TRibution mcnu and has the format binonicdf(n, p, k). 
EXAMPLE: 
Compute the probability of less than 5 successes in 8 trials where the probability of 
success for a single tr~al is 40%. 
In this example, n 7 8, p = .4, and k = 5 .  
Press 
2nd 
VARS 
for 
DISTR 
Press down the arrow key until 
A:binomcdf 
is highlighted 
Press ENTER 
After binomcdf(, type 8, .4,5) 
Press 
ENTER 
You should see. 
Ibinmcdf (87.4, 51 
1 

CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Thus, P(x < 5)is about 95%. 
P(x < k), P(x > k), P(x 2 k )  
To find the probability of less than k successes P(x < k ) ,  more than k successes 
P(x > k ) ,  or at least k successes P(x 2 k), variations of the binomcdf( command 
must be used as  show^ below. 
P(x < k )  use 
binomcdf(n, p, k - 1) 
P(x > k )  use 
1-binomcdf(n, p, k) 
P(x 2 k ) .  use 
1-binomcdf(n, p, k - 1) 
where n = number of trials and p = probability of success in each trial. 
Learning the Mechanics 
4.25 Compute the following: 
4.26 Consider the following probability distribution: 
a. Is x a discrete or a continuous random variable? 
b. What is the name of this probability distribution? 
c. Graph the probability distribution. 
d. Find the mean and standard deviation of x. 
e. Show the mean and the 2-standard-deviation interval 
on each side of the mean on the graph you drew in 
part c. 
4.27 If x is a binomial random variable, compute p(x) for 
each of the following cases: 
a. n =  S , x =  1 , p =  .2 
b. n = 4 , x = 2 , q =  .4 
c. n = 3 , x =  O,p= .7 
d. n = 5 , x = 3 , p = . 1  
e. n = 4 , x  = 2,q = .6 
f. n =  3 , x =  1 , p =  .9 
4.28 If x is a binomial random variable, use Table I1 in 
Appendix B to find the following probabilities: 
a. P(X = 2) for n = 10, p = .4 
b. P(x I 
5) for n = 15, p = .6 
c. P x > 1)for n = 5, p = .1 
d. P x  i < 10)forn = 25, p = .7 
e. P(x 2 10) for n = 15, p = .9 
f. P(X = 2) for n = 20, p = .2 
4.29 If x is a binomial random variable, calculate p, a', and a 
for each of the following: 
a. n = 25, p = .5 
b. n = 80, p = .2 
c. n = 100,p = .6 
d. n = 70,p = .9 
e. n = 60,p = .8 
f. n = 1,000,p = .04 
Applying the Concepts 
4.30 Periodically, the Federal Trade Commission (FTC) 
monitors the pricing accuracy of electronic checkout 
scanners at stores to ensure consumers are charged the 
correct price at checkout. A 1998 study of over 100,000 
items found that one of every 30 items is priced incor- 
rectly by the scanners (Price Check !I: A Follow-Up 
Report on the Accuracy of Checkout Scanner Prices, 
Dec. 16,1998). Suppose the FTC randomly selects five 
items at a retail store and checks the accuracy of the 
scanner pricc of each. Let x represent the number of 
the five items that is priced incorrectly. 
a. Show that x is (approximately) a binomial random 
variable. 
b. Use the information in the FTC study to estimate p 
for the binomial experiment. 
c. What is the probability that exactly one of the five 
items is priced incorrectly by the scanner? 
d. What is the probability that at least one of the five 
items is priced incorrectly by the scanner? 
4.31 According to the Internal Revenue Service (IRS), the 
chances of your tax return being audited are about 15 in 
1,000 if your income is less than $100,000 and 30 in 
1.000 if your income is $100,000 or more (Statistical 
Abstract of the United States: 1998). 
a. What is the probability that a taxpayer with income 
less than $100,000 will be audited by the IRS? With 
income $100,000 or more? 
b. If five taxpayers with incomes under $100,000 are 
randomly selected. what is the probability that ex- 
actly one will be audited? That more than one will be 
audited? 
c. Repeat part b assuming that five taxpayers with in- 
comes of $100,000 or more are randomly selected. 

SECTION 4.3 
T h e  B i n o m i a l  D i s t r i b u t i o n  
193 
3m 
e P 
we 
Five 
the 
5 in 
1 in 
ical 
)me 
Yith 
are 
ex- 
I1 be 
n in- 
:d. 
d. If two taxpayers with incomes under $100,000 are 
randomly selected and two with incomes more than 
$100,000 are randomly selected, what is the proba- 
bility that none of these taxpayers will be audited by 
the IRS? 
e. What assumptions did you have to make in order to 
answer these questions using the methodology pre- 
sented in this section? 
4.32 As the baby boom generation ages, the number of 
employees injured on the job will continue to increase. A 
recent poll by the Gallup Organization sponsored by 
Philadelphia-based CIGNA Integrated Care found that 
about 40% of employees have missed work due to a mus- 
culoskeletal (back) injury of some kind (National 
Underwriter, Apr. 5,1999). Let x be the number of sam- 
pled workers who have missed work due to a back injury. 
a. Explain why x is approximately a binomial random 
variable. 
b. Use the Gallup poll data to estimate p for the bino- 
mial random variable of part a. 
c. A random sample of 10 workers is to be drawn from 
a particular manufacturing plant. Use the p from 
part b to find the mean and standard deviation of x, 
the number of workers that missed work due to 
back injuries. 
d. For the sample in part c, find the probability that ex- 
actly one worker missed work due to a back injury. 
That more than one worker misscd work due to a 
back injury. 
4.33 "Do you believe your children will have a higher stan- 
dard of living than you have?"This question was asked of 
a national sample of American adults with children in a 
TirneKNN poll (Jan. 29, 1996). Sixty-three percent 
answered in the affirmative, with a margin of error of plus 
or minus 3%. Assume that the true percentage of all 
American adults who believe their children will have a 
higher standard of living is .60. Let x represent the 
number in a random sample of five American adults who 
believe their children will have a higher standard of living. 
a. Demonstrate that x is (approximately) a binomial 
random variable. 
b. What is the value of p for the binomial experiment? 
C. Find P(X = 3). 
d. Find ~
(
x
 
5 2). 
4.34 According to Catalyst, a New York-based women's 
advocacy and research group, 12% of all corporate offi- 
cers at the 500 largest U.S. corporations in 1999 were 
women, compared to 8% in 1995. (Atlanta Journal 
Constitution, Nov. 12, 1999). 
a. According to Catalyst's data, in a sample of 1,000 
corporate officers at the 500 largest U.S. firms, how 
many would you expect to be women? 
b. If eight corporate officers were randomly selected 
from the 500 largest U.S. firms, what is the probabili- 
ty that none would be women? That half would be 
women? 
c. What assumptions did you have to make in order to 
answer part b using the binomial distribution? 
4.35 On January 28,1986, the space shuttle Challenger was 
totally enveloped in an explosive burn that destroyed 
the shuttle and resulted in the deaths of all seven astro- 
nauts aboard. A presidential commission assigned to 
investigate the accident concluded that the explosion 
was caused by the failure of the O-ring seal in the joint 
between the two lower segments of the right solid-fuel 
rocket booster. In a report madc one year prior to the 
catastrophe, the National Aeronautics and Space 
Administration (NASA) claimed that the probability 
of such a failure was about '/ji,,,,,,,,), 
or about once in 
every 60,000 flights. But a risk assessment study con- 
ducted for the Air Force at about the same time 
assessed the probability of shuttle catastrophe due to 
booster rocket "burn-through" to be '/,,, or about once 
in every 35 missions. 
a. The catastrophe occurred on the twenty-fifth shuttle 
mission. Assuming NASA's failure-rate estimate was 
accurate, compute the probability that no disasters 
would have occurred during 25 shuttle missions. 
b. Repeat part a, but use the Air Force's failure-rate 
estimate. 
C. What conditions must exist for the probabilities, 
parts a and b, to be valid? 
d. Given the events of January 28, 1986, which risk 
assessment-NASA's or the Air Force's-appears to 
be more appropriate? [Hint: Consider the comple- 
ment of the events, parts a and b.] 
e. After making improvcments in the shuttle's systems 
over the late 1980s and early 1990s, NASA issued a 
report in 1993 in which the risk of catastrophic fail- 
ure of the shuttle's main engine was assessed for 
each mission at 1 in 120. ("Laying Odds on Shuttle 
Disaster," Chance, Fall 1993.) Use this risk assess- 
ment and the binomial probability distribution to 
find the probability of at least one catastrophic fail- 
ure in the next 10 missions. 
4.36 The number of bank mergers in the 1990s far exceeded 
any previous 10-year period in US. history. As mergers 
created larger and larger banks, many customers 
charged the mega-banks with becoming more and more 
impersonal in dealing with customers. A recent poll by 
the Gallup Organization found 20% of retail customers 
switched banks after their banks merged with another 
(Bank Marketing, Feb. 1999). One year after the acqui- 
sition of First Fidelity by First Union, a random sample 
of 25 retail customers who had banked with First 
Fidelity were questioned. Let x be the number of those 
customers who switched their business from First Union 
to a different bank. 
a. What assumptions must hold in order for x to be a bi- 
nomial random variable? In the remainder of this ex- 
ercise, use the data from the Gallop Poll to estimatep. 
b. What is the probability that x 5 lo? 

194 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
c. Find E(x) and the standard deviation of x. 
4.38 A study conducted in New Jersey by the Governor's 
d. Calculate the interval p =t 2v. 
Council for a Drug Free Workplace concluded that 
e. If samples of size 25 were drawn repeatedly a large 
70% of New Jersey's businesses have employees 
number of times and x determined for each sample, 
whose performance is affected by drugs andlor alco- 
what proportion of the x values would fall within the 
hol. In those businesses, it was estimated that 8.5% of 
interval you calculated in part d? 
their workforces have alcohol problems and 5.2% 
4.37 Every quarter the Food and Drug Administration 
have drug problems. These last two numbers are 
(FDA) produces a report called the Total Diet Study. 
slightly lower than the national statistics of 10% and 
The FDA's report covers more than 200 food items, 
7%, respectively (Report: The Governor's Council for 
each of which is analyzed for potentially harmful chem- 
a Drug Free Workplace, SpringISummer 1995). 
ical compounds. A recent Total Dzet Study reported that 
a. In a New Jersey company that acknowledges it has 
no pesticides at all were found in 65% of the domesti- 
performance problems caused by substance abuse, out 
cally produced Eocd samples (Consumer's Research, 
of every 1,000 employees, approximately how many 
June 1995). Cons~der a random sample of 800 food 
have drug problems? 
items analyzed for the presence of pesticides. 
b. In the company referred to in part a, if 10 employees 
a. Compute p and u for the random variable x, the 
are randomly selected to form a committee to address 
number of food items found that showed no trace of 
alcohol abuse problems, what is the probability that at 
pesticide. 
least one member of the committee 1s an alcohol 
b. Based on a sample of 800 food items, is it likely you 
abuser? That exactly two are alcohol abusers? 
would observe less than half without any traces of 
c. What assumptions did you have to make in order to 
pesticide? Explain. 
ancwer part b using the methodology of this section? 
'm 
THE POISSON DISTRIBUTION (OPTIONAL) 
A type of probability distribution that is often useful in describing the number of 
events that will occur in a specific period of time or in a specific area or volume is 
the Poisson distribution (named after the 18th-century physicist and mathemati- 
cian, SimCon Poisson). Typical examples of random variables for which the Pois- 
son probability distribution provides a good model are 
1. The number of industrial accidents per month at a manufacturing plant 
2. The number of noticeable surface defects (scratches, dents, etc.) found by 
quality inspectors on a new automobile 
3. The parts per million of some toxin found in the water or air emission from 
a manufacturing plant 
E 
4. The number of customer arrivals per unit of time at a supermarket checkout 
, 
counter 
5. The number of death claims received per day by an insurance company 
6. The number of errors per 100 invoices in the accounting records of a 
company 
1. The experiment consists of counting the number of times a certain event 
occurs during a given unit of time or in a given area or volume (or 
weight, distance, or any other unit of measurement). 
2. The probability that an event occurs in a given unit of time, area, or vol- 
ume is the same for all the units. 
3. The number of events that occur in one unit of time, area, or volume is 
I 
independent of the number that occur in other units. 
i 
4. The mean (or expected) number of events in each unit is denoted by the 
Greek letter lambda, A. 

5 
t 
S 
f 
b 
e 
d 
tr 
i s  
ut 
lY 
es 
:ss 
at 
101 
to 
I? 
of 
: 
is 
 ti- 
>is- 
I by 
-om 
;out 
of a 
:nt 
:or 
ol- 
e is 
the 
L 
S o l u t i o n  
SECTION 4.4 
T h e  Poisson Distribution ( O p t i o n a l )  
195 
The characteristics of the Poisson random variable are usually difficult to 
verify for practical examples. The examples given satisfy them well enough that 
the Poisson distribution provides a good model in many instances. As with all 
probability models, the real test of the adequacy of the Poisson model is in 
whether it provides a reasonable approximation to reality-that is, whether em- 
pirical data support it. 
The probability distribution, mean, and variance for a Poisson random vari- 
able are shown in the next box. 
, and Variance for a Poisson 
(x = 
here 
A = Mean number of events during given unit of time, area, volume, etc. 
e = 2.71828 . . . 
The calculation of Poisson probabilities is made easier by the use of Table I11 
in Appendix B, which gives the cumulative probabilities P ( x  5 k) for various val- 
ues of A. The use of Table 111 is illustrated in Example 4.12. 
Suppose the number, x, of a company's employees who are absent on Mondays 
has (approximately) a Poisson probability distribution. Furthermore, assume that 
the average number of Monday absentees is 2.6. 
a. Find the mean and standard deviation of x, the number of employees absent 
on Monday. 
b. Use Table IT1 to find the probability that fewer than two employees are ab- 
sent on a given Monday. 
c. Use Table I11 to find the probability that more than five employees are ab- 
sent on a given Monday. 
d. Use Table I11 to find the probability that exactly five employees are absent 
on a given Monday. 
a. The mean and variance of a Poisson random variable are both equal to A. 
Thus, for this example, 
*The Poisson probability distribution also provides a good approximation to a binomial 
distribution with mean h = np when n is large andp is small (say, np 5 7). 

196 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
- 
Then the standard deviation of x is 
Remember that the mean measures the central tendency of the distribution 
and does not necessarily equal a possible value of x. In this example, the 
mean is 2.6 absences, and although there cannot be 2.6 absences on a given 
Monday, the average number of Monday absences is 2.6. Similarly, the stan- 
dard deviation of 1.61 measures the variability of the number of absences 
per week. Perhaps a more helpful measure is the interval p f 2u, which in 
this case stretches from -.62 to 5.82. We expect the number of absences to 
fall in this interval most of the time-with at least 75% relative frequency 
(according to Chebyshev's Rule) and probably with approximately 95% 
relative frequency (the Empirical Rule). The mean and the 2-standard- 
deviation interval around it are shown in Figure 4.10. 
FIGURE 4.10 
P(X) 
Probability distribution for number of 
Monday absences 
b. A partial reproduction of Table I11 is shown in Table 4.4. The rows of the 
table correspond to different values of A, and the columns correspond to dif- 
ferent values (k) of the Poisson random variable x. The cntries in the table 
TABLE 4.4 
Reproduction of Part of Table I l l  in Appendix B 
A 
............ 
2.2 
2.4 
2.6 
2.8 
3.0 
3.2 
3.4 
3.6 
3.8 
4.0 
4.2 
4.4 
4.6 
4.8 
5.0 
5.2 
5.4 
5.6 
5.8 
6.0 
0 
1 
1 
2 
3 
4 
5 
6 
7 
8 
................ . .... . ..... . ........................................................................................................................... 
9 
i 
.I11 
.355 
.623 
319 
,928 
.975 
.993 
.998 
1.000 
1.000 
,091 
.308 
.570 
.779 
.904 
.964 
.988 
.997 
,999 
1.000 
.074 
.267 
.518 
.736 
.877 
.951 
.983 
.995 
,999 
1.000 
.061 
.231 
.469 
.692 
.848 
.935 
.976 
.992 
,998 
,999 
.050 
,199 
423 
.647 
315 
.916 
966 
.988 
996 
.999 
1 
.041 
.I71 
.380 
.603 
.781 
395 
,955 
.983 
.994 
,998 
,033 
.I47 
.340 
.558 
.744 
,871 
.942 
.977 
.992 
.997 
,027 
.I26 
.303 
.515 
,706 
344 
.927 
.969 
.988 
.996 
.022 
.lo7 
.269 
.473 
.668 
.8l6 
.909 
.960 
.984 
.994 
.018 
.092 
.238 
.433 
.629 
.785 
289 
.949 
.979 
.992 
,015 
.078 
.210 
,395 
.590 
,753 
.867 
,936 
,972 
0 1  0 6  
I85 
3.59 
5 1  
720 
4 4  
9 2  
6 4  : I
.010 
,056 
.I63 
.326 
,513 
.686 
,818 
.905 
.955 
.980 
.008 
.048 
.I43 
.294 
.476 
,651 
.791 
387 
,944 
.975 
.007 
.040 
.I25 
.265 
.440 
.616 
.762 
367 
.932 
.968 
,006 
.034 
.lo9 
.238 
406 
.581 
.732 
245 
.918 
960 1 
.005 
.029 
,095 
.213 
,373 
.546 
,702 
.822 
.903 
.951 
.004 
.024 
,082 
.I91 
.342 
S12 
,670 
.797 
286 
.941 
s 
.003 
,021 
.072 
,170 
.313 
,478 
.638 
.771 
,867 
.929 . 
.002 
.017 
.062 
.I51 
.285 
.446 
.606 
.744 
347 
.916 

he 
if- 
)le 
SECTION 4.4 
T h e  Poisson Distribution ( O p t i o n a l )  
197- 
(like the binomial probabilities in Table 11) give the cumulative probability 
P(x s k). To find the probability that fewer than two employees are absent 
on Monday, we first note that 
This probability is a cumulative probability and therefore is the entry in 
Table I11 in the row corresponding to h = 2.6 and the column corresponding 
to k = 1. The entry is .267, shown shaded in Table 4.4. This probability cor- 
responds to the shaded area in Figure 4.10 and may be interpreted as mean- 
ing that there is a 26.7% chance that fewer than two employees will be 
absent on a given Monday. 
To find the probability that more than five employees are absent on a given 
Monday, we consider the complementary event 
where .951 is the entry in Table I11 corresponding to h = 2.6 and k = 5 (see 
Table 4.4). Note from Figure 4.10 that this is the area in the interval p f ~ C T ,  
or 
- .62 to 5.82. Then the number of absences should exceed 5-or, equivalently, 
should be more than 2 standard deviations from the mean-during only about 
4.9% of all Mondays. Note that this percentage agrees remarkably well with 
that given by the Empirical Rule for mound-shaped distributions, which tells us 
to expect approximately 5% of the measurements (values of the random 
variable) to lie farther than 2 standard deviations from the mean. 
To use Table I11 to find the probability that exactly five employees are ab- 
sent on a Monday, we must write the probability as the difference between 
two cumulative probabilities: 
Note that the probabilities in Table I11 are all rounded to three decimal 
places. Thus, although in theory a Poisson random variable can assume infinitely 
large values, the values of k in Table I11 are extended only until the cumulative 
probability is 1.000. This does not mean that x cannot assume larger values, but 
only that the likelihood is less than .001 (in fact, less than .0005) that it will do so. 
Finally, you may need to calculate Poisson probabilities for values of h not 
found in Table 111. You may be able to obtain an adequate approximation by in- 
terpolation, but if not, consult more extensive tables for the Poisson distribution. 
Learning the Mechanics 
4.39 Consider the probability distribution shown here: 
c. Graph the probability distribution. 
d. Find the mean and standard deviation of x. 
e. Find the mean and standard deviation of the proba- 
bility distribution. 
a. Is x a discrete or continuous random variable? 
4.40 Given that x is a random variable for which a Poisson 
Explain. 
probability distribution provides a good approximation, 
b. What is the name of this probability distribution? 
use Table I11 to compute the following: 

198 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Poisson Probabilities 
\y 
USI NG T H E  TI -83 CRAPHIN'G C A L C U L A T O R  
Poisson Probabilities on the TI-83 
P(x = k) 
To compute ~ ( x  
= k), the probability of exactly k successes in a specified interval 
where A is the mean number of successes in the interval, use the poissonpdf( com- 
mand. Poissonpdf stands for "Poisson probability density function." This command is 
under the DTSTR~bution menu and has the format poissonpdf(A. k). 
EXAMPLE: 
Suppose that the number, x, of reported sightmgs per week of blue whales is recorded. 
Assume that x has approximately a Poisson probability distribution, and that the av- 
erage number of weekly sightings is 2.6. 
Compute the probability that exactly five sightings are made during a given week. 
In this example, A = 2.6 and k = 5 
Press 2nd 
VARS 
for 
DISTR 
Press thc down arrow key until 
B:poissonpdf 
is highlighted 
Press ENTER 
After poissonpdf(, type 2.6,s) 
Press ENTER 
You should see 
Thus, the P(x = 5) is about 7.4%. 
To computeP(x 5 k), the probability of k or fewer successes in a specified interval, 
where A is the mean number of successes in the interval, use the poissoncdf( com- 
mand. Poissoncdf stands for "Poisson cumulative probability density function." This 
command is under the DISTRibution menu and has the format poissoncdf( A, k). 
EXAMPLE: 
In the example given above, compute the probability that five or fewer sightings are 
made during a given week. 
(continued) 

SECTION 4.4 
T h e  Poisson D i s t r i b u t i o n  ( O p t i o n a l )  
199 
In this example, A = 2.6 and k = 5 
Press 2nd 
VARS 
for 
DISTR 
Press the down arrow key until 
C:poissoncdf 
is highlighted 
Press ENTER 
After poissoncdf(, type 2.6,s) 
Press 
ENTER 
You should see: ' 
Thus, the P(x 5 5 )  is about 95.1%. 
P(x < k), P(x > k), P(x 2 k) 
To find the probability ot less than k successes P(x < k), more than k successes 
P(x > k), or at least k successes P(x 2 k),variations of poissoncdf( command must 
be used as shown below. 
P(x < k )  
use 
poissoncdf(A, k - 1) 
P(x > k )  
use 
1 - poissoncdf(A, k) 
P(x s: k )  
use 
1 - poissoncdf(A, k - 1) 
where A is the mean number of successes in the specified interval. 
a. P(x 5 2) when A = 1 
b. P(x 5 2) when A = 2 
C. P(x 5 2) when A = 3 
d. What happens to the probability of the event 
{x 5 2) as A increases from 1 to 3? Is this intuitively 
reasonable? 
4.41 Assume that x is a random variable having a Poisson 
probability distribution with a mean of 1.5. Use Table 
I11 to find the following probabilities: 
a. P(x 5 3) h. P(x 2 3) c. P(x = 3) 
d. P(x = 0) 
c. P(x > 0 )  f. P(x > 6 )  
4.42 Suppose x is a random variable for which a Poisson 
probability distribution with h = 5 provides a good 
characterization. 
a. Graphp(x) for x = 0, 1,2, ... ,IS. 
b. Find p and a for x, and locate p and the interval 
p k 2a on the graph. 
c. What is the probability that x will fall within the in- 
terval p f 2u? 
Applying the Concepts 
4.43 The Federal Deposit Insurance Corporation (FDIC), 
insures deposits of up to $100,000 in banks that are 
members of the Federal Reserve System against losses 
due to bank failure or theft. Over the last 5 years, the 
average number of bank failures per year among 
insured banks was 4.4 (FDIC, Nov. 1999). Assume that 
x, the number of bank failures per year among mured 
banks, can be adequately characterized by a Poisson 
probability distribution with mean 4. 
a. Find the expected value and standard deviation of x. 
b. In 1997, only one insured bank failed. How far (in stan- 
dard deviations) does x = 1 lie below the mean of the 
Poisson distribution? That is, find the z-score for x = 1. 

200 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
c. In 1999, six insured banks failed. Find P(x 5 6). 
d. Discuss conditions that would make the Poisson as- 
sumption plausible. 
4.44 As part of a project targeted at improving the services 
of a local bakery, a management consultant (L. Lei of 
Rutgers University) monitored customer arrivals for 
several Saturdays and Sundays. Using the arrival data, 
she estimated the average number of customer arrivals 
per 10-minute period on Saturdays to be 6.2. She 
assumed that arrivals per 10-minute interval followed 
the Poisson distribution (some of whose values are miss- 
ing) shown at the bottom of the page. 
a. Compute the missing probabilities. 
b. Plot the distribution. 
c. Find p and u and plot the intervals p + a ,  p + 2u, 
and p f 3 u  on your plot of part b. 
d. The owner of the bakery claims that more than 75 cus- 
tomers per hour enter the store on Saturdays. Based 
on the consultant's data, is this likely'? Explain. 
4.45 The Environmental Protection Agency (EPA) issues 
pollution standards that vitally affect the safety of con- 
sumers and the operations of industry (The United States 
Government Manuul1998-1999). For example, the EPA 
states that manufacturers of vinyl chloride and similar 
compounds must limit the amount of these chemicals in 
plant air emissions to no more than 10 parts per million. 
Suppose the mean emission of vinyl chloride for a par- 
ticular plant is 4 parts per million. Assume that the 
number of parts per million of vinyl chloride in air sam- 
ples, x, follows a Poisson probability distribution. 
a. What is the standard deviation of x for the plant? 
b. Is it likely that a sample of air from the plant would 
yield a value of x that would exceed the EPA limit? 
Explain. 
c. Discuss conditions that would make the Poisson as- 
sumption plausible. 
4.46 US. airlines fly approximately 48 billion passenger-miles 
per month and average about 2.63 fatalities per month 
(Statistical Abstract of the United States: 1998). Assume 
the probability distribution for x, the number of fatalities 
per month, can bc approximated by a Poisson probability 
distribution. 
a. What is the probability that no fatalities will occur 
during any given month? [Hint: Either use Table I11 
of Appendix B and interpolate to approximate the 
probability, or use a calculator or computer to calcu- 
late the probability exactly.] 
b. Find E(x) and the standard deviation of x. 
c. Use your answers to part b to describe the probabil- 
ity that as many as 10 fatalities will occur in any 
given month. 
d. Discuss conditions that would make the Poisson as- 
sumption plausible. 
4.47 University of New Mexico economists Kishore 
Gawande and Timothy Wheeler studied the effective- 
ness of the Maritime Safety Program of the US. Coast 
Guard by examining the records of 951 deep-draft US. 
Flag vessels. They modeled the number of casualties 
experienced by a vessel over a three-year period as a 
Poisson random variable, x. Casualties were defined as 
the number of deaths or missing persons in a three-year 
interval. Using the data on the 951 vessels, they cstimat- 
ed E(x) to be .03 (Management Science, January 1999). 
a. Find the variance x. 
b. Discuss the conditions that would make the re- 
searchers' Poisson assumption plausible. 
c. What is the probability that a deep-draft U.S. flag ves- 
sel will have exactly one casualty in a three-year time 
period? No casualties in a three-year period? 
4.48 The number x of people who arrive at a cashier's 
counter in a bank during a specified period of time 
often exhibits (approximately) a Poisson probability 
distribution. If we know the mean arrival rate A, the 
Poisson probability distribution can be used to aid in 
the design of the customer service facility. Suppose 
you estimate that the mean number of arrivals per 
minute for cashier service at a bank is one person per 
minute. 
i 
a. What is the probability that in a given minute the 
i 
number of arrivals will equal three or more? 
b. Can you tell the bank manager that the number of 
i 
arrivals will rarely exceed two per minute? 
4.49 In studying the product life cycle in the commercial 
mainframe computer market over the period 1968 to 
1982, Shane Greenstein (Northwestern University) and 
James Wade (University of Illinois) found that the 
number of new product introductions per year per firm, 1 
E 
x, could be approximated by a Poisson random variable 
with mean equal to .37 (Rand Journal of Economics, 
Winter 1998). 
a. Find the standard deviation of x. 
b. Plot p(x), the probability distribution for x. 
c. Is it likely that the mainframe manufacturer would 
introduce more than two new products per year? I 
Less than one new product per year? Justify your 
j 
answers. 
Probability Distribution for Exercise 4.44 
x 
P ( X )  
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
.002 
.013 
- 
.081 
,125 
.I55 - 
.I42 
.I10 
.076 - 
.026 
.014 
,007 
Source. Lei, L. Dorsl's Bakery: Modeling Serv~ce Operations. Graduate School of Management, Rutgers University, 1993. 

t 
5 
P 
S 
r 
.. 
S- 
Le 
's 
ie 
t Y 
ne 
in 
se 
her 
ler 
.he 
of 
:ial 
8 to 
ind 
the 
rm, 
lble 
tics, 
juld 
:ar? 
{our 
SECTION 4.5 
Probability Distributions For C o n t i n u o u s  Random Variables 
201 - 
PROBABILITY DISTRIBUTIONS FOR CONTINUOUS 
RANDOM VARIABLES 
Recall that a continuous random variable is one that can assume any value with- 
in some interval or intervals. For example, the length of time between a cus- 
tomer's purchase of new automobiles, the thickness of sheets of steel produced in 
a rolling mill, and the yield of wheat per acre of farmland are all continuous ran- 
dom variables. 
The graphical form of the probability distribution for a continuous random 
variable x is a smooth curve that might appear as shown in Figure 4.1 1. This curve, 
a function of x, is denoted by the symbol f(x) and is variously called a probability 
density function (pdf), a frequency function, or a probability distribution. 
The areas under a probability distribution correspond to probabilities for x. 
For example, the area A beneath the curve between the two points a and b, as 
shown in Figure 4.11, is the probability that x assumes a value between a and b 
(a < x < b). Because there is no area over a point, say x = a, it follows that (ac- 
cording to our model) the probability associated with a particular value of x is 
equal to 0; that is, P(X = a) = 0 and hence ~ ( a  
< x < b) = P(a 5 x 5 b). In 
other words, the probability is the same whether or not you include the end- 
points of the interval. Also, because areas over intervals represent probabilities, it 
follows that the total area under a probability distribution, the probability as- 
signed to all values of x, should equal 1. Note that probability distributions for 
continuous random variables possess different shapes depending on the relative 
frequency distributions of real data that the probability distributions are sup- 
posed to model. 
A probability distribution f (x) for a continuous 
random variable x 
I 
The areas under most probability distributions are obtained by using calcu- 
lus or numerical methods.* Because these methods often involve difficult proce- 
dures, we will give the areas for some of the most common probability 
distributions in tabular form in Appendix B. Then, to find the area between two 
values of x, say x = a and x = b, you simply have to consult the appropriate 
table. 
For each of the continuous random variables presented in this chapter, we 
will give the formula for the probability distribution along with its mean p and 
standard deviation a. These two numbers will enable you to make some approxi- 
mate probability statements about a random variable even when you do not have 
access to a table of areas under the probability distribution. 
*Students with knowledge of calculus should note that the probability that x assumes a value in 
the interval a < x < b is P(a < x < b) = 
f ( x )  dx, assuming the integral exists. Similar to the 
h" 
requirement for a discrete probability distribution, we require f ( x )  2 0 and 

202 
CHAPTER 4 
Random Variables a n d  Probability Distributions 
THE UNIFORM DISTRIBUTION (OPTIONAL) 
All the probability problems discussed in Chapter 3 had sample spaces that con- 
. 
tained a finite number of sample points. In many of these problems, the sample 
points were assigned equal probabilities-for example, the die toss or the coin 
toss. For continuous random variables, there is an infinite number of values in the 
sample space, but in some cases the values may appear to be equally likely. For ex- 
ample, if a short exists in a 5-meter stretch of electrical wire, it may have an equal 
probability of being in any particular 1-centimeter segment along the line. Or if a 
safety inspector plans to choose a time at random during the four afternoon work 
hours to pay a surprise visit to a certain area of a plant, then each 1-minute time 
interval in this 4-work-hour period will have an equally likely chance of being se- 
lected for the visit. 
Continuous random variables that appear to have equally likely outcomes 
over their range of possible values possess a uniform probability distribution, 
perhaps the simplest of all continuous probability distributions. Suppose the ran- 
dom variable x can assume values only in an interval c 5 x 5 d. Then the uniform 
frequency function has a rectangular shape, as shown in Figure 4.12. Note that the 
possible values of x consist of ail points in the interval between point c and point 
d. The height of f (x) is constant in that interval and equals 1 /(d - c). Therefore, 
the total area under f (x) is given by 
Total area of rectangle = (Base)(Height) = (d - 
FI GURE 4.1 2 
The uniform probability distribution 
1 - 
d - c  
X 
c 
a
h
 
d 
D 
The uniform probability distribution provides a model for continuous ran- 
dom variables that are evenly distributed over a certain interval. That is, a uniform 
random variable is one that is just as likely to assume a value in one interval as it 
is to assume a value in any other interval of equal size. There is no clustering of 
values around any value; instead, there is an even spread over the entire region of 
possible values. 
The uniform distribution is sometimes referred to as the randomness distn- 
bution, since one way of generating a uniform random variable is to perform an 
experiment in which a point is randomly selected on the horizontal axis between 
the points c and d. If we were to repeat this experiment infinitely often, we would 
create a uniform probability distribution like that shown in Figure 4.12. The 
random selection of points in an interval can also be used to generate random 
numbers such as those in Table I of Appendix B. Recall that random numbers 
are selected in such a way that every number would have an equal probability of 
II 

In- 
~ l e  
)in 
he 
ZX- 
ual 
if a 
)rk 
me 
se- 
nes 
Ion, 
.an- 
x m  
the 
oint 
ore, 
-+ X 
; ran- 
iform 
1 as it 
n g  of 
ion of 
distri- 
rm an 
tween 
would 
2. The 
ndom 
mbers 
ility of 
SECTION 4.6 
T h e  Uniform D i s t r i b u t i o n  ( O p t i o n a l )  
203 
selection. Therefore, random numbers are realizations of a uniform random vari- 
able. (Random numbers were used to draw random samples in Section 3.7.) The 
formulas for the uniform probability distribution, its mean, and standard deviation 
are shown in the box. 
c + d 
d -
c  
Suppose the interval n < x < b lies within the domain of x; that is, it falls 
within the larger interval c 5 x 5 d. Then the probability that x assumes a value 
within the interval a < x < b is equal to the area of the rectangle over the inter- 
val, namely, (b - a)/(d - c). * (See the shaded area in Figure 4.12). 
Suppose the research department of a steel manufacturer believes that one of the 
company's rolling machines is producing sheets of steel of varying thickness. The 
thickness is a uniform random variable with values between 150 and 200 milli- 
meters. Any sheets less than 160 millimeters must be scrapped because they are 
unacceptable to buyers. 
a. Calculate and interpret the mean and standard deviation of x, the thickness 
of the sheets produced by this machine. 
b. Graph the probability distribution of x, and show the mean on the horizon- 
tal axis. Also show 1- and 2-standard-deviation intervals around the mean. 
c. Calculate the fraction of steel sheets produced by this machine that have to 
be scrapped. 
S o I u t i 0 n 
a. To calculate the mean and standard deviation for x, we substitute 150 and 
200 millimeters for c and d, respectively, in the formulas for uniform random 
variables. Thus, 
c + d 
150 + 200 
- 
CL=-- 
2 
2 
= 175 millimeters 
and 
d - c 
200 - 150 
50 
g=-- 
--- 
- 
6 
- fi 
3.464 
- 14.43 millimeters 
*The student with knowledge of calculus should note that 
P(a < x < b) = b ( x ) d ( r )  = [Ll(d - c)dx = (6 - u)/(d - c )  

204 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Our interpretations follow: 
The average thickness of all manufactured steel sheets is p = 175 millimeters. 
From Chebyshev's Theorem (Table 2.8, p. 70), we know that at least 75% of 
the thickness values,~, 
in the distribution will fall in the interval 
p f 2 a  = 175 & 2(14.43) 
= 175 f 28.86 
or, between 146.14 and 203.86 millimeters. (This demonstrates, once again, 
the conservativeness of Chebyshev's Theorem since we know that all values 
of x fall between 150 and 200 millimeters.) 
b. The uniform probability distribution is 
FIGURE 4.1 3 
Distribution for x 
in Example 4.1 3 
FIGURE 4.14 
Probability that sheet thickness, 
x, is between 150 and 160 
millimeters 
The graph of this function is shown in Figure 4.13. The mean and 1- and 2- 
standard-deviation intervals around the mean are shown on the horizontal axis. 
c. To find the fraction of steel sheets produced by the machine that have to be 
scrapped, we must find the probability that x, the thickness, is less than 160 mil- 
limeters. As indicated in Figure 4.14, we need to calculate the area under the 
frequency function f(x) between the points x = 150 and x = 160. This is the 
area of a rectangle with base 160 - 150 = 10 and height '/,,,. The fraction 
that has to be scrapped is then 
That is, 20% of all the sheets made by this machine must be scrapped. * 

rs. 
of 
in, 
Les 
1 2- 
~xis. 
o be 
I mil- 
r the 
s the 
ction 
SECTION 4.6 
T h e  U n i f o r m  D i s t r i b u t i o n  ( O p t i o n a l )  
205& 
Learning the Mechanics 
4.50 Suppose x is a random variable best described by a uni- 
form probability distribution with c = 20 and d = 45. 
Find the followmg probabilities: 
a. ~ ( 2 0  
5 x 5 30) b. ~ ( 2 0  < x 5 30) 
c. P(X 2 30) d. ~ ( x  
3 45) e. P(X 5 40) 
t ~ ( x  
< 40) g. ~ ( 1 5  I 
x i 
35) 
h. ~(21.5 5 x 5 31.5) 
Suppose x is a random variable best described by a uni- 
form probability distribution with c = 3 and d = 7. 
a. Find f(x). 
b. Find the mean and standard deviation of x. 
c. Find P ( ~  
- cr 5 x 5 p + c). 
4.52 Refer to Exercise 4.51. Find the value of a that makes 
each of the following probability statements true. 
a. P(X 2 a) = .6 b. P(X % a) = .25 
c. P(X I 
a) = 1 d. ~ ( 4  
5 x 5 a) = .5 
4.53 The random variable x is best described by a uniform 
probability distribution with c = 100 and d = 200. Find 
the probability that x assumes a value 
a. More than 2 standard deviations from p. 
b. Less than 3 standard deviations from p. 
r. Within 2 standard deviations of p. 
4.54 The random variable x is best described by a uniform 
probability distribution with mean 10 and standard 
deviation 1. Find c, d, and f(x). Graph the probability 
distribution. 
Applying the Concepts 
4.55 The frequency distribution shown in the next table 
depicts the property and marine losses incurred by a 
large oil company over the last two years. This distri- 
bution can be used by the company to predict future 
losses and to help determine an appropriate level of 
insurance coverage. In analyzing the losses within an 
interval of the distribution, for simplification, analysts 
may treat the interval as a uniform probability distribu- 
tion (Research Review, Summer 1998). In the insurance 
business, intervals like these are often called layers. 
a, Use a uniform distribution to model the loss amount 
in layer 2. Graph the distribution. Calculate and in- 
terpret its mean and variance. 
b. Repeat part a for layer 6. 
C. If a loss occurs in layer 2, what is the probability that 
it exceeds $10,000? That it is under $25,000? 
d, If a layer-6 loss occurs, what is the probability that it 
is between $750,000 and $1,000,000? That it exceeds 
$900,000? That it is exactly $900,000? 
4.56 Researchers at the University of California-Berkeley 
have designed, built, and tested a switched-capacitor 
circuit for generating random signals (International 
....................................................................................... 
Property and Marine 
Layer 
Losses (millions of $) 
Frequency 
................................................................................. 
1 
0.00-0.01 
668 
2 
0.01-0.05 
38 
3 
0.05-0.1 0 
7 
4 
0.1 0-0.25 
4 
'" 
5 
0.25-0.50 
2 
6 
0.50-1.00 
1 
7 
1 .OO-2.50 
0 
Source: Cozzolino, John M., and Perter J. Mikola, 
"Applications of the Piecewise Constant Pareto 
Distribution," Reseclrch Renew, Summer 1998. 
Journal of Circuit Theory and Applications, May-June 
1990). The circuit's trajectory was shown to be uni- 
formly distributed on the interval (0,l). 
a. Give the mean and variance of the circuit's trajectory. 
b. Compute the probability that the trajectory falls be- 
tween .2 and .4. 
c. Would you expect to observe a trajectory that ex- 
ceeds .995? Explain. 
4.57 The data set listed in the table was created using the 
MINITAB random number generator. Construct a rela- 
tive frequency histogram for the data. Except for the 
expected variation in relative frequencies among the 
class intervals, docs your histogram suggest that the data 
are observation4 on a uniform random variable with 
c = 0 and d = 1001 Explain. 
4.58 During the recession of the late 1980s and early 1990s, 
many companies began tightening their reimbursement 
expense policies. For example, a survey of 550 compa- 
nies by the Dartnell Corporation found that in 1992 
about half reimbursed their salespeople for home fax 
machines, but by 1994 only one-fourth continued to do 
so (Inc., Sept. 1995). One company found that monthly 
reimbursements to their employees, x, could be ade- 
quately modeled by a uniform distribution over the 
interval $10,000 5 x 5 $15,000. 

206 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
a. Find E(x) and interpret it in the context of the exercise. 
b. What is the probability of employee reimbursements 
exceeding $12,000 next month? 
c. For budgeting purposes, the company needs to esti- 
mate next month's employee reimbursement expenses. 
How much should the company budget for employee 
reimbursements if they want the probability of ex- 
ceeding the budgeted amount to be only .20? 
4.59 The manager of a local soft-drink bottling company 
believes that when a new beverage-d~rpensing machine 
is set to dispense 7 ounces, it in fact dispenses an amount 
x at random anywhere between 6.5 and 7.5 ounces inclu- 
sive. Suppose x has a uniform probability distribution. 
a. Is the amount dispensed by the beveragc machine a 
discrete or a continuous random variable? Explain. 
b. Graph the frequency function for x, the amount of 
beverage the manager believes is dispensed by the 
new machine when it is set to dispense 7 ounces. 
c. Find the mean and standard deviation for the distri- 
bution graphed in part b, and locate the mean and 
the interval p ? 2 u  on the graph. 
d. Find P(X 2 7). 
e. Find ~ ( x  
< 6). 
f. Find ~ ( 6 . 5  
5 x 5 7.25). 
g. What 1s the probability that each of the next six bot- 
tles filled by the new machine will contain more than 
7.25 ounces of beverage? Assume that the amount of 
beverage dispensed in one bottle is independent of 
the amount dispensed in another bottle. 
4.60 The reliability of a piece of equipment is frequently 
defined to be the probability,p, that the equipment per- 
forms its intended function successfully for a given 
period of time under specific conditions (Render and 
Heizer, Principles of Operations Management, 1995). 
Because p varies from one point in time to another. 
some reliability analysts treat p as if it were a random 
variable. Suppose an analyst characterizes the uncer- 
tainty about the reliability of a particular robotic device 
used in an automobile assembly line using the following 
distribution: 
1 
0 5 P ' l  
f(p) = { 0 
otherwise 
a. Graph the analyst's probability distribution forp. 
b. Find the mean and variance of p. 
c. According to the analyst's probability distribution 
for p, what is the probability that p is greater than 
.95? Less than .95? 
d. Suppose the analyst receives the additional informa- 
tion that p is definitely between .90 and .95, but that 
there is complete uncertainty about where it lies bc- 
tween these values. Describe the probability distn- 
bution the analyst should now use to describep. 
THE NORMAL DISTRIBUTION 
One of the most commonly observed continuous random variables has a bell-shaped 
probability distribution (or bell curve) as shown in Figure 4.15. It is known as a nor. 
mal random variable and its probability distribution is called a normal distribution. 
A normal probability 
distribution 
The normal distribution plays a very important role in the science of sta- 
tistical inference. Moreover, many business phenomena generate random vari- 
ables with probability distributions that are very well approximated by a normal 
distribution. For example, the monthly rate of return for a particular stock is ap- 
proximately a normal random variable, and the probability distribution for the 
weekly sales of a corporation might be approximated by a normal probabilit! 
distribution. The normal distribution might also provide an accurate model for 
the distribution of scores on an employment aptitude test. You can determine 
the adequacy of the normal approximation to an existing population by com- 
paring the relative frequency distribution of a large sample of the data to the 

f 
Y 
n 
d 
). 
r, 
m 
r- 
:e 
lg 
on 
Lan 
na- 
hat 
be- 
,tri- 
pe" 
nor- 
Ion. 
- 
X 
f sta- 
vari- 
xmal 
is ap- 
)r the 
bility 
el for 
rmine 
com- 
to the 
SECTION 4.7 
The Normal D i s t r i b u t i o n  
207 
normal probability distribution. Methods to detect disagreement between a set 
of data and the assumption of normality are presented in Section 4.8. 
The normal distribution is perfectly symmetric about its mean p, as can be 
seen in the examples in Figure 4.16. Its spread is determined by the value of its 
standard deviation a. 
F IG U R E  4.16 
f 
Several normal distributions with different 
means and standard deviations 
The formula for the normal probability distribution is shown in the box. 
When plotted, this formula yields a curve like that shown in Figure 4.15. 
ean of the normal random variable x 
tandard deviation 
Note that the mean p and standard deviation a appear in this formula, so 
that no separate formulas for p and a are necessary. To graph the normal curve we 
have to know the numerical values of p and a. 
Computing the area over intervals under the normal probability distribution 
is a difficult task.* Consequently, we will use the computed areas listed in Table IV 
of Appendix B. Although there are an infir'tely large number of normal curves- 
one for each pair of values for p and a- have formed a single table that will 
apply to any normal curve. 
Table 1V is based on a normal distribution with mean p = 0 and standard 
deviation a = 1, called a standard normal distribution. A random variable with a 
standard normal distribution is typically denoted by the symbol z.The formula for 
the probability distribution of z is given by 
*The student with knowledge of calculus should note that there is not a closed-form expression 
for P(u < x < h) = /hf(x) d r  for the normal probability distribution.The value of this definite 
Ja 
integral can be obtained to any desired degree of accuracy by numerical approximation 
procedures. For this reason, it is tabulated for the user. 

208 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Figure 4.17 shows the graph of a standard normal distribution. 
DEFINITION 4.8 
I 
The standard normal distribution is a normal distribution with ,u = 0 and 
cr = 1. A random variable with a standard normal distribution, denoted by 
the symbol z, is called a standard normal random variable. 
Since we will ultimately convert all normal random variables to standard nor- 
mal in order to use Table IV to find probabilities, it is important that you learn to 
use Table IV well. A partial reproduction of Table IV is shown in Table 4.5. Note 
that the values of the standard normal random variable z are listed in the left- 
hand column. The entries in the body of the table give the area (probability) be- 
tween 0 and z. Examples 4.14-4.17 illustrate the use of the table. 
TABLE 4.5 
Reproduction of Part of Table IV in Appendix B 

r- 
to 
te 
Et- 
be- 
- 
19 ,...... " 
159 
'53 
~ 4 1  
517 
379 
224 
549 
852 
133 
389 
621 
,830 
1015 
11 77 
i319 
$44 1 - 
S ECTION 4.7 
T h e  Normal D i s t r i b u t i o n  
209 
-c 
-m-w--m 
-1.33 and +1.33. 
S o I u t i o n 
The standard normal distribution is shown again in Figure 4.18. Since all 
probabilities associated with standard normal random variables can be depicted as 
areas under the standard normal curve, you should always draw the curve and 
then equate the desired probability to an area. 
In this example we want to find the probability that z falls between -1.33 and 
+1.33, which is equivalent to the area between -1.33 and +1.33, shown shaded in 
Figure 4.18. Table IV provides the area between z = 0 and any value of z, so that if 
we look up z = 1.33, we find that the area between z = 0 and z = 1.33 is .4082. This 
is the area labeled A ,  in Figure 4.18.To find the area A, located between z = 0 and 
z = -1.33, we note that the symmetry of the normal distribution implies that the 
area between z = 0 and any point to the left is equal to the area between z = 0 and 
the point equidistant to the right.Thus, in this example the area between z = 0 and 
z = -1.33 is equal to the area between z = 0 and z = t-1.33. That is, 
F I G U R E  4.1 8 
Areas under the standard normal curve for 
Example 4.1 4 
z 
The probability that z falls between -1.33 and +1.33 is the sum of the areas of A, 
and A2. We summarize in probabilistic notation: 
Remember that "<" and "5" are equivalent in events involving z, because the in- 
clusion (or exclusion) of a single point does not alter the probability of an event 
involving a continuous random variable. 
m"","""P
"" "" 
""* 
probability that a standard normal random variable exceeds 1.64; that is, 
> 1.64). 
S 0 I u t i o n The area under'the standard normal distribution to the right of 1.64 is the shaded 
area labeled A ,  in Figure 4.19. This area represents the desired probability that z 
exceeds 1.64. However, when we look up z = 1.64 in Table IV, we must remember 
that the probability given in the table corresponds to the area between z = O and 
z = 1.64 (the arca labeled A, in Figure 4.19). From Table IV we find that 
A, = .4495. To find the area A, to the right of 1.64, we make use of two facts: 
1. The standard normal distribution is symmetric about its mean, z = 0. 
2. The total area under the standard normal probability distribution equals 1. 

210 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Taken together, these two facts imply that the areas on either side of the mean z = 0 
equal .5; thus, the area to the right of z = 0 in Figure 4.19 is A, + A, = .5. Then 
P(z > 1.64) = Al = .5 - A, = .5 - .4495 = .0505 
FI GURE 4.19 
Areas under the standard normal curve for 
Example 4.1 5 
-&=A~ 
z 
1.64 
To attach some practical significance to this probability, note that the implication is 
that the chance of a st~pdard normal random variable exceeding 1.64 is approxi- 
mately .05. 
Find the probability that a standard normal random variable lies to the left of .67. 
S o I u t i o n 
The event is shown as the highlighted area in Figure 4.20. We want to find 
P(Z < .67). We divide the highlighted area into two parts: the area A, between 
z = 0 and z = .67, and the area A, to the left of z = 0. We must always make such 
a division when the desired area lies on both sides of the mean (z = 0) because 
Table IV contains areas between z = 0 and the point you look up. We look up 
I 
z = .67 in Table IV to find that Al = .2486. The symmetry of the standard normal 
distribution also implies that half the distribution lies on each side of the mean,so 
the area A, to the left of z = 0 is .S. Then, 
1 
I 
Note that this probability is approximately .75. Thus, about 75% of the time the 
j 
standard normal random variable z will fall below .67. This implies that z = .67 
represents the approximate 75th percentile for the distribution. 
S o I u t i o n 
We want to find 
P(lz1 > 1.96) = P(z < -1.96 or z > 1.96) 
This probability is the shaded area in Figure 4.21. Note that the total shaded 
area is the sum of two areas, Al and A,-areas that are equal because of the 
symmetry of the normal distribution. 
- 

4 
S ECTION 4.7 
T h e  Normal D i s t r i b u t i o n  
211 
1s 
i- 
c 
ms- 
7. 
ld 
zn 
ch 
Lse 
UP 
nal 
, so 
L z 
: 
the 
= .67 
s)r 
96 in 
haded 
of the 
We look up z = 1.96 and find the area between z = 0 and z = 1.96 to be 
.4750.Then the area to the right of 1.96, A,, is .5 - .4750 = .0250, so that 
FI GURE 4.21 
Areas under the standard normal curve for 
Example 4.1 7 
z 
-1.96 
0 
1.96 
To apply Table IV to a normal random variable x with any mean p and any 
standard deviation a, we must first convert the value of x to a z-score. The popu- 
lation z-score for a measurement was defined (in Section 2.6) as the distance be- 
tween the measurement and the population mean, divided by the population 
standard deviation. Thus, the z-score gives the distance between a measurement 
and the mean in units equal to the standard deviation. In symbolic form, the z-score 
for the measurement x is 
Note that when x = p, we obtain z = 0. 
An important property of the normal distribution is that if x is normally dis- 
tributed with any mean and any standard deviation, z is alwuys normally distrib- 
uted with mean 0 and standard deviation 1 .That is, z is a standard normal random 
variable. 
Recall from Example 4.17 that ~
(
1
 
zl > 1.96) = .O5. This probability coupled 
with our interpretation of z implies that any normal random variable lies more 
than 1.96 standard deviations from its mean only 5% of the time. Compare this to 
the Empirical Rule (Chapter 2) which tells us that about 5% of the measurements 
in mound-shaped distributions will lie beyond 2 standard deviations from the 
mean. The normal distribution actually provides the model on which the Empirical 
Rule is based, along with much "empirical" experience with real data that often ap- 
proximately obey the rule, whether drawn from a normal distribution or not. 
distributed with a mean of 10 hours and a standard deviation of 
1.5 hours. Find the probability that the cell phone will last between 8 and 12 hours 
between charges. 

212 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
S o I u t i 0 n 
The normal distribution with mean p = 10 and a = 1.5 is shown in Figure 4.22. 
The desired probability that the charge lasts between 8 and 12 hours is shaded. In 
order to find the probability, we must first convert the distribution to standard 
normal, which we do by calculating the z-score: 
Areas under the normal curve for Example 4.1 8 U L  
The z-scores corresponding to the important values of x are shown beneath the x 
values on the horizontal axis in Figure 4.22. Note that z = 0 corresponds to the 
mean of p = 10 hours, whereas the x values 8 and 12 yield z-scores of - 1.33 and 
+ 1.33, respectively. Thus, the event that the cell phone charge lasts between 8 and 
12 hours is equivalent to the event that a standard normal random variable lies 
between -1.33 and +1.33. We found this probability in Example 4.14 (see Fig- 
ure 4.18) by doubling the area corresponding to z = 1.33 in Table IV. That is, 
The steps to follow when calculating a probability corresponding to a nor- 
mal random variable are shown in the box. 
. Convert the boundaries of the shaded area from x values to standard 
normal random variable z values using the formula 
x - P 
z = -  u 
Show the z values under the correspon 
. Use Table IV in Appendix B to find 
rresponding to the 
z values. If necessary, use the symmetry of the normal distribution to find 
areas corresponding to negative z values and the fact that the total area 
on each side of the mean equals .5 to convert the areas from Table IV to 
the probabilities of the event you have shade 

SECTION 4.7 
T h e  N o r m a l  D i s t r i b u t i o n  
213 
Normal Probabilities 
U S I N G  THE T I - 8 3  GRAPHING CALCULATOR 
How to Graph the Area under the Standard Normal 
Start from the home screen. 
Step 1 Set the viewing window. (Recall Standard Normal uses z-values, no1 the 
actual data.) 
tep 2 Access the Distributions 
Press 
WINDOW 
Menu. 
Set 
Xn~in = -5 
Xmax = 5
\
 
Xscl = 1 
Ymin = 0 
Re1 
Ymax = .5 
is tl 
Yscl = 0 
blu 
Xres = 1 
:all, the negative sign 
he gray key not the 
e key 
J Step 3 View graph. 
Press 
2ndVARS 
The graph will be displayed 
Arrow right to DRAW 
along with the area, lower 
Press ENTER 
limit, and upper limit. 
, 
Enter your lower limit 
Press comma 
Enter your upper limit 
Press ) Press ENTER 
Example What is the probability that z is less than 1.5 under the Standard Normal 
curve? 
Step 1 Set your window. (See screen below.) 
Step 2 Enter your values (see lower left screen). Press ENTER. 
Step 3 You will see display (see lower right screen) 
Step 4 Clear the screen for the next problem. Return to the home streen. 
Press 2"* PRGM ENTER CLEAR CLEAR. 

214 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
1 
advertised mean in-city mileage of 27 miles per gallon. Although such 
. 
- 
- 
advertisements seldom report any measure of variability, suppose you write the 
manufacturer for the details of the tests, and you find that the standard deviation 
is 3 miles per gallon. This information leads you to formulate a probability model 
for the random variable x, the in-city mileage for this car model. You believe that 
the probability distribution of x can be approximated by a normal distribution 
with a mean of 27 and a standard deviation of 3. 
a. If you were to buy this model of automobile, what is the probability that you 
would purchase one that averages less than 20 miles per gallon for in-city 
' 
driving? In other words, find ~
(
x
 
< 20). 
b. Suppose you purchase one of these new models and it does get less than 
20 miles per gallon for in-city driving. Should you conclude that your 
probability model is incorrect? 
S o I u t i 0 n 
a. The probability model proposed for x, the in-city mileage, is shown in 
Figure 4.23. 
FIGURE 4.23 
Areas under the normal curve for Example 4.1 9 
20 
27 
-2.33 
0 
Z 
We are interested in finding the area A to the left of 20 since this area cor- 
responds to the probability that a measurement chosen from this distribu- 
1 
tion falls below 20. In other words, if this model is correct, the area A 
1 
represents the fraction of cars that can be expected to get less than 20 miles 
per gallon for in-city driving. To find A, we first calculate the z value corre- 
sponding to x = 20. That is, 
Then 
P(x < 20) = P(z < -2.33) 
as indicated by the shaded area in Figure 4.23. Since Table IV gives only 
areas to the right of the mean (and because the normal distribution is sym- 
metric about its mean), we look up 2.33 in Table IV and find that the corre- 
sponding area is .4901. This is equal to the area between z = 0 and 
; 
z = -2.331, so we find 
i 
According to this probability model, you should have only about a 1% 
chance of purchasing a car of this make with an in-city mileage under I 
20 miles per gallon. 
- 
t 

S ECT ION 4.7 
The Normal Distribution 
215 " 
re- 
nd 
1% 
der 
b. Now you are asked to make an inference based on a sample-the car you pur- 
chased. You are getting less than 20 miles per gallon for in-city driving. What 
do you infer? We think you will agree that one of two possibilities is true: 
i
1. The probability model is correct. You simply were unfortunate to have 
purchased one of the cars in the 1 % that get less than 20 miles per gallon 
in the city. 
2. The probability model is incorrect. Perhaps the assumption of a normal 
distribution is unwarranted or the mean of 27 is an overestimate, or the 
standard deviation of 3 is an underestimate, or some combination of 
these errors was made. At any rate, the form of the actual probability 
model certainly merits further investigation. 
You have no way of knowing with certainty which possibility is correct, but 
the evidence points to the second one. We are again relying on the rare-event ap- 
proach to statistical inference that we introduced earlier. The sample (one mea- 
surement in this case) was so unlikely to have been drawn from the proposed 
probability model that it casts serious doubt on the model. We would be inclined 
to believe that the model is somehow in error. 
t 
Occasionally you will be given a probability and will want to find the val- 
ues of the normal random variable that correspond to the probability. For ex- 
ample, suppose the scores on a college entrance examination are known to be 
normally distributed, and a certain prestigious university will consider for ad- 
mission only those applicants whose scores exceed the 90th percentile of the test 
score distribution. To determine the minimum score for admission considera- 
tion, you will need to be able to use Table IV in reverse, as demonstrated in the 
following example. 
S o I u t i 0 n 
In this case we are given a probability, or an area, and asked to find the value of 
the standard normal random variable that corresponds to the area. Specifically, we 
want to find the value z, such that only 10% of the standard normal distribution 
exceeds z, (see Figure 4.24). 
FI GURE 4.24 
Area under the standard normal 
curve for Example 4.20 
z 
0 
zo 
We know that the total area to the right of the mean z = 0 is .5, which im- 
plies that 2, must lie to the right of (above) 0. To pinpoint the value, we use the 
fact that the area to the right of z, is .lo, which implies that the area between 
z = 0 and zo is .5 - .1 = .4. But areas between z = 0 and some other z value are 
exactly the types given in Table IV. Therefore, we look up the area .4000 in the 
body of Table IV and find that the corresponding z value is (to the closest ap- 
proximation) z, = 1.28. The implication is that the point 1.28 standard deviations 
above the mean is the 90th percentile of a normal distribution. 
@ 

216 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
- zo and + zo, i.e., P(- zo 5 z 5 zo) = .95. 
S o I  u t i o n  Here we wish to move an equal distance zo in the positive and negative directions 
from the mean z = 0 until 95% of the standard normal distribution is enclosed. 
This means that the area on each side of the mean will be equal to '/,(.95) = .475, 
as shown in Figure 4.25. Since the area between z = 0 and zo is .475, we look up 
.475 in the body of Table IV to find the value z, = 1.96. Thus, as we found in the 
reverse order in Example 4.17,95% of a normal distribution lies between +1.96 
and - 1.96 standard deviations of the mean. 
FIGURE 4.25 
Areas under the standard 
normal curve for 
Example 4.21 
Now that you have learned to use Table IV to find a standard normal z value 
that corresponds to a specified probability, we demonstrate a practical application 
in Example 4.22. 
am"sm*m"u#"*m* *"."U 
""* -*s*s# Y % I I 1  
"1" -1 "*"""-a"" .* ""1 s* 1 *1" 1" ** 1"" *. 
1 
I*"m"-mm-" 
I 
"YSI ** 
"NY. I *""+""-*" 
* . n I I 
T 
lll n 
Suppose a paint manufacturer has a daily  production,^, that is normally distributed 
with a mean of 100,000 gallons and a standard deviation of 10,000 gallons. 
Management wants to create an incentive bonus for the production crew when the 
daily production exceeds the 90th percentile of the distribution, in hopes that the 
crew will, in turn, become more productive. At what level of production should 
management pay the incentive bonus? 
S o l u t i o n  In this example, we want to find a production level, x,, such that 9Ooh of the daily 
levels (x values) in the distribution fall below xu and only 10% tall above x,. That is, 
Converting x to a standard normal random variable, where p = 100,000 and 
a = 10,000, we have 
In Example 4.20 (see Figure 4.24) we found the 90th percentile of the standard 
normal distribution to be z, = 1.28. That is, we found P(z 5 1.28) = .90. Conse- 
quently, we know the production level xo at which the incentive bonus is paid cor- 
responds to a z-score of 1.28; that is, 

1 
;. 
e 
e 
d 
ly 
is, 
~d 
ard 
Lse- 
:or- 
S ECTION 4.7 
T h e  N o r m a l  D i s t r i b u t i o n  
217 
If we solve this equation for x,, we find 
This x value is shown in Figure 4.26.Thus, the 90th percentile of the produc- 
tion distribution is 112,800 gallons. Management should pay an incentive bonus 
when a day's production exceeds this level if its objective is to pay only when pro- 
duction is in the top 10% of the current daily production distribution. 
>Sr 
FI GURE 4.26 
Area under the normal curve 
for Example 4.22 
* 
100,000 
xo = 1 12.800 
x 
I 
Learning the Mechanics 
4.61 Find the area under the standard normal probability 
distribution between the following pairs of z-scores: 
a. z = 0 and z = 2.00 b. z = 0 and z = 3 
c. z = 0 and z = 1.5 d. z = 0 and z = 3 0  
4.62 Find the following probabilities for the standard normal 
random variable z: 
a . ~ ( - l < z ~ l )  
b. P ( - 2 ~ ~ 5 2 )  
c. P(-2.16 5 z 5 .55) d. P(-.42 < z < 1.96) 
e. P(Z 2 -2.33) f. P(Z < 2.33) 
4.63 Find a value of the standard normal random variable z, 
call ~t zo, such that 
a. P(z 5 z,,) = ,2090 
b. P(z 5 zo) = .7090 
C. P(-zo 5 z < zo) = .8472 
d. P(-z,, 5 z 5 z,,) = .I664 
e. P(z,, 5 z 5 0 )  = ,4798 
f. P(-1 < z < z,) = S328 
4.64 The random variable x has a normal distribution with 
p = 1,000andcr = 10. 
a. Find the probability that x assumes a valuc more 
than 2 standard deviations from its mean. More than 
3 standard deviations from p. 
h. Find the probability that x assumes a value within 
1 standard deviation of its mean. Within 2 standard 
deviations of p. 
c. Find the value of x that represents the 80th per- 
centile of this distribution.The 10th percentile. 
4.65 Suppose x is a normally distributed random variable 
with p = 11 and a = 2. Find each of the following: 
a. ~ ( 1 0 5  
x 5 12) b. ~ ( 6  
5 x 5 10) 
4.66 Suppose x is a normally distributed random variable 
with p = 50 and a = 3. Find a value of the random 
variable, call it x,,, such that 
a. P(x 5 x,,) = 3413 b. P(x > x,) = .025 
c. P(x > x,,) = .95 
d. P(41 5 x < x,,) = A630 
e. 10% of the values of x are less than x,,. 
f. 1% of the values of x are greater than xo. 
Applying t h e  Concepts 
4.67 The crop yield for a particular farm in a particular year is 
typically measured as the amount of the crop produced 
per acre. For example, cotton is measured in pounds per 
acre. It has bccn demonstrated that the normal distribu- 
tion can be used to characterize crop yields over time 
(Americun Journal ofAgricultura1 Economics, May 1999). 
Historical data indicate that next summer's cotton yield 
for a particular Georgia farmer can be characterized by a 
normal distribution with mean 1,500 pounds per acre and 
standard deviation 250.The farm in question will be prof- 
itable if it produces at least 1,600 pounds per acre. 
a. What is the probability that the farm will lose money 
next summer? 
b. Assume the same normal distribution is appropriate 
for describing cotton yield in each of the next two 
summers. Also assume that the two yields are statis- 
tically independent. What is the probability that the 
farm will lose money for two straight ycars? 
c. What is the probability that the cotton yield falls 
within 2 standard deviations of 1,500 pounds per acre 
next summer? 

218 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
4.68 The characteristics of an industrial filling process in 
which an expensive liquid is injected into a container 
was investigated in Journal of Quality Technology (July 
1999). The quantity injected per container is approxi- 
mately normally distributed with mean 10 units and 
standard deviation .2 units. Each unit of fill costs $20 per 
unit. If a container contains less than 10 units (i.e., is 
underfilled) it must be reprocessed at a cost of $10. A 
properly filled container sells for $230. 
a. Find the probability that a container is underfilled. 
Not underfilled. 
b. A container is initially underfilled and must be re- 
processed. Upon refilling it contains 10.60 units. How 
much profit will the company make on this container? 
c. The operations manager adjusts the mean of the fill- 
ing process upward to 10.10 units in order to make 
the probability of underfilling approximately zero. 
Under these conditions, what is the expected profit 
per container? 
4.69 The problem of matching aircraft to passenger demand 
on each flight leg is called the flight assigvlment 
in the airline industry. Spill is defined as the number of 
passengers not carried because the aircraft's capacity is 
insufficient. A solution to the flight assignment problem 
at Delta Airlines was published in Interfaces (Jan.-Feb. 
1994). The authors-four Delta Airlines researchers and 
a Georgia Tech professor (Roy Marsten)-demonstrated 
their approach with an example in which passenger 
demand for a particular flight leg is normally distributed 
with a mean of 125 passengers and a standard deviation 
of 45. Consider a Boeing 727 with a capacity of 148 pas- 
sengers and a Boeing 757 with a capacity of 182. 
,, 
a. What is the probability that passenger demand will ex- 
ceed the capacity of the Boeing 727? The Boeing 757? 
b. If the 727 is assigned to the flight leg. what is the 
probability that the flight will depart with one or 
more empty seats? Answer the same question for 
the Boeing 757. 
c. If the 727 is assigned to the flight, what is the proba- 
bility that the spill will be more than 100 passengers? 
4.70 Government data indicate that the mean hourly wage 
for manufacturing workers in the United States is $14 
(Statistical Abstract of the United States: 1999). Suppose 
the distribution of manufacturing wage rates nation- 
wide can be approximated by a normal distribution with 
standard deviation $1.25 per hour. The first manufac- 
turing firm contacted by a particular worker seeking a 
new job pays $15.30 per hour. 
a. If the worker were to undertake a nationwide job 
search, approximately what proportion of the wage 
rates would be greater than $15.30 per hour? 
b. If the worker were to randomly select a U.S. manu- 
facturing firm, what is the probability the firm would 
pay more than $15.30 per hour? 
c. The population median, call it 7, 
of a continuous 
random variable x is the value such that 
P(X 2 17) = P(X 5 7) 
= 5 T h a t  is, the median is the 
value 7 such that half the area under the probability 
distribution lies above 7 and half lies below it. Find 
the median of the random variable corresponding to 
the wage rate and compare it to the mean wage rate. 
4.71 In studying the dynamics of fish populations, knowing 
the length of a species at different ages is critical, espe- 
cially for commercial fishermen. Fisheries Science (Feb. 
1995) published a study of the length distributions of sar- 
dines inhabiting Japanese waters. At two years of age. 
fish have a length distribution that is approximatelj 
normal with p = 20.20 centimeters (cm) and o = .65 cm. 
a. Find the probability that a two-year-old sardine inhab- 
iting Japanese waters is between 20 and 21 cm long. 
b. A sardine captured in Japanese waters has a length 
of 19.84 cm. Is this sardine likely to be two years old? 
c. Repeat part b for a sardine with a length of 22.01 cm. 
4.72 Personnel tests are designed to test a job applicant's cog- 
nitive andlor physical abilities. An IQ test is an example 
of the former; a speed test involving the arrangement of 
pegs on a peg board is an example of the latter (Cowling 
and James, The Essence of Personnel Management and 
Industrial Relations, 1994). A particular dexterity test is 
administered nationwide by a private testing service. It is 
known that for all tests administered last year the distri- 
bution of scores was approximately normal with mean 
75 and standard deviation 7.5. 
a. A particular employer requires job candidates to 
score at least 80 on the dexterity test. Approximately 
what percentage of the test scores during the past 
year exceeded 80? 
b. The testing service reported to a particular employer 
that one of its job candidate's scores fell at the 98th 
percentile of the distribution (i.e., approximately 98% 
of the scores were lower than the candidate's, and only 
2% were higher). What was the candidate's score? 
4.73 In baseball, a "no-hitter" is a regulation 9-inning game 
in which the pitcher yields no hits to the opposing bat- 
ters. Chance (Summer 1994) reported on a study of no- 
hitters in Major League Baseball (MLB). The initial 
analysis focused on the total number of hits yielded per 
game per team for all 9-inning MLB games played 
between 1989 and 1993. The distribution of hits19- 
innings is approximately normal with mean 8.72 and 
standard deviation 1.10. 
a. What percentage of 9-inning MLB games result in 
fewer than 6 hits? 
b. Demonstrate, statistically, why a no-hitter is consid- 
ered an extremely rare occurrence in MLB. 
4.74 Before negotiating a long-term construction contract, 
building contractors must carefully estimate the total 
cost of completing the project. The process is compli- 
cated by the fact that total cost cannot be known with 
certainty ahead of time. Benzion Barlev of New York 
University proposed a model for total cost of a long- 
term contract based on the normal distribution (Journal 
of Business Finance and Accounting, July 1995). For one 

SECTION 4.8 
D e s c r i p t i v e  M e t h o d s  f o r  Assessing N o r m a l i t y  
219 
1 
I 
> 
1 
5 
5 
1 
3 
Y 
It 
r 
h 
6 
Y 
le 
t- 
>- 
a1 
:r 
:d 
9- 
I d 
in 
d- 
ct , 
tal 
lli- 
,th 
rk 
kg- 
zal 
ne 
particular construction contract, Barlev assumed total 
cost, x, to be normally distributed with mean $850,000 
and standard deviation $170,000. The revenue, R, 
promised to the contractor is $1,000,000. 
a. The contract will be profitable if revenue exceeds 
total cost. What is the probability that the contract 
will be profitable for the contractor? 
b. What is the probability that the project will result in a 
loss for the contractor? 
c. Suppose the contractor has the opportunity to rene- 
gotiate the contract. What value of R should the con- 
tractor strive for in order to have a .99 probability of 
making a profit? 
4.75 A machine used to regulate the amount of dye dispensed 
for mixing shades of paint can be set so that it discharges 
an average of p milliliters (mL) of dye per can of paint. 
The amount of dye discharged is known to have a normal 
distribution with a standard dcviation of .4 mL. If more 
than 6 mL of dye are discharged when making a certain 
shade of blue paint, the shade is unacceptable. Determine 
the setting for p SO that only 1% of the cans of paint will 
be unacceptable. 
DESCRIPTIVE METHODS FOR ASSESSING NORMALITY 
In the chapters that follow, we learn how to make inferences about the population 
based on information in the sample. Several of these techniques are based on the 
assumption that the population is approximately normally distributed. Conse- 
quently, it will be important to determine whether the sample data come from a 
normal population before we can properly apply these techniques. 
Several descriptive methods can be used to check for normality. In this sec- 
tion, we consider the four methods summarized in the box. 
The first two methods come directly from the properties of a normal dis- 
tribution established in Section 4.7. Method 3 is based on the fact that for nor- 
mal distributions, the z values corresponding to the 25th and 75th percentiles 
are -.67 and .67, respectively (see Example 4.16). Since a = 1 for a standard 
normal distribution, 
The final descriptive method for checking normality is based on a normal 
probability plot. In such a plot, the observations in a data set are ordered from 
smallest to largest and then plotted against the expected z-scores of observations 
calculated under the assumption that the data come from a normal distribution. 
When the data are, in fact, normally distributed, a linear (straight-line) trend will 
result. A nonlinear trend in the plot suggest that the data are nonnormal. 
Determininq Whether the Data Are From an Approximately 
. - 
rmal ~istribution 
. Construct either a histogram or stem-and-leaf display for the data and 
note the shape of the graph. If the data are approximately normal, the 
shape of the histogram or stem-and-leaf display will be similar to the nor- 
mal curve, Figure 4.15 (i.e., mound-shaped and symmetric about the mean). 
2. 
Compute the intervals 2 f 
s, ? f 2s, and 2 f 
3s, and determine the 
percentage of measurements falling in each. If the data are approxi- 
mately normal, the percentages will 
roximately equal to 68%, 
95 %, and loo%, respectively. 
3. Find the interquartile range, IQR, and 
tion, s, for the sam- 
ple, then calculate the ratio IQRIs. If the 
approximately normal, 
then IQRIs = 1.3. 
(continued) 

220 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
DEFINITION 4.9 
A normal probability plot for a data set is a scatterplot with the ranked data val- 
ues on one axis and their corresponding expected z-scores from a standard 
normal distribution on the other axis. [Note: Computation of the expected stan- 
dard normal z-scores are beyond the scope of this text. Therefore, we will rely 
on available statistical software packages to generate a normal probability plot.] 
The Environmental Protection Agency (EPA) performs extensive tests on all new 
car models to determine their mileage ratings. The results of 100 EPA tests on a 
certain new car model are displayed in Table 4.6. Numerical and graphical 
descriptive measures for the data are shown on the MINITAB and SPSS 
printouts, Figures 4.27a-c. Determine whether the EPA mileage ratings are from 
an approximate normal distribution. 
TABLE 4.6 
EPA Gas Mileage Ratings for 100 Cars (miles per gallon) 
S o l u t i o n  As a first check, we examine the MINITAB histogram of the data shown in Fig- 
ure 4 . 2 7 ~  
Clearly, the mileages fall in an approximately mound-shaped, symmetric 
distribution centered around the mean of approximately 37 mpg. Note that a 
normal curve is superimposed on the figure. Therefore, using check #1 in the box, 
the data appear to be approximately normal. 
FIGURE 4.27a 
MINITAB histogram for 
mileage data 
2 0 
3 0 
3 5 
4 0 
45 
MPG 

SECTION 4.8 
Descriptive M e t h o d s  for Assessing Normality 
221 
To apply check #2, we obtain x = 37 and s = 2.4 from the MINITAB print- 
out, Figure 4.27b.The intervals T f s, i f 2s, and i zt 3s, are shown in Table 4.7, 
as well as the percentage of mileage ratings that fall in each interval. These per- 
centages agree almost exactly with those from a normal distribution. 
FIGURE 4.27b 
MINITAB descriptive 
statistics for mileage data 
Descriptive Statistics 
Variable 
N 
Mean 
Median 
Tr Mean 
StDev 
Se Mean 
I 
MPG 
100 
36.994 
37.000 
36.992 
2.418 
0.242 
Variable 
Min 
Max 
Q 1 
Q3 
MPG 
30.000 
44.900 
35.625 
38.375 
TABLE 4.7 
Describing the 100 EPA Mileage Ratings 
Interval 
Percentage in Interval 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
- 
x f 
s = (34.6,39.4) 
- 
68 
x f 
2s = (32.2,41.8) 
- 
96 
x f 
3s = (29.8,44.2) 
99 
Check #3 in the box requires that we find the ratio IQRIs. From Figure 4.27b, 
the 25th percentile (called Q, by MINITAB) is QL = 35.625 and the 75th per- 
centile (labeled Q3 by MINITAB) is Q, = 38.375. Then, IQR = Q, - QL = 2.75 
and the ratio is 
IRQ 
2.75 
- 
= 1.15 
s 
2.4 
Since this value is approximately equal to 1.3, we have further confirmation that 
the data are approximately normal. 
A fourth descriptive method is to interpret a normal probability plot. An 
SPSS normal probability plot for the mileage data is shown in Figure 4.27~. Notice 
that the (standardized) ordered mileage values (shown on the horizontal axis) fall 
- 
reasonably close to a straight line when plotted against the expected z-scores 
from a normal distribution. Thus, check #4 also suggests that the EPA mileage 
data are likely to be approximately normally distributed. 
* 
FI GURE 4 . 2 7 ~  
SPSS normal probability plot 
for mileage data 
Standardized Observed Value 

222 
C HAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
The checks for normality given in the box are simple, yet powerful, tech- 
niques to apply, but they are only descriptive in nature. It is possible (although un- 
likely) that the data are nonnormal even when the checks are reasonably satisfied. 
Thus, we should be careful not to claim that the 100 EPA mileage ratings of Ex- 
ample 4.23 are, in fact, normally distributed. We can only state that it is reasonable 
to believe that the data are from a normal distribution.* 
As we will learn in the next chapter, several inferential methods of analysis 
require the data to be approximately normal. If the data are clearly nonnormal, in- 
ferences derived from the method may be invalid. Therefore, it is advisable to 
check the normality of the data prior td conducting the analysis. 
Normal Probability Plot 
USING THE T I - 8 3  GRAPHING CALCULATOR 
How to Graph a Normal Probability Plot 
Start from the home screen 
Step 1 Enter your data into List 1 (Recall the List are accessed by pressing STAT 
ENTER. Always begin from a "clear" List). 
Step 2. Access the "Stat Plot" menu. 
Press 
2""NTER 
Press 
ENTER 
Press 
ENTER 
Arrow down and right to 
last graph. 
Press 
ENTER 
Set 
Data List: L1 
Data Axis: X 
Step 3 Press ZOOM 9 
Your data will be displayed against the residuals. If you see a "generally" lin- 
ear relationship your data are near normal. 
Example Using a Normal Probability Plot, test whether or not the data are nor- 
mally distributed. 
(continued) 
*Statistical tests of normality that provide a measure of reliability for the inference are available 
However, these tests tend to be very senq~t~ve 
to slight departures from normality, i e , they tend 
to reject the hypothesis of normal~ty for any distribution that is not perfectly symmetr~cal and 
mound-shaped Consult the references (see Ramsey & Ramsey, 1990) if you want to learn more 
about these ~ L S ~ S .  

SECTION 4.8 
D e s c r i p t i v e  M e t h o d s  f o r  Assessing N o r m a l i t y  
223 
Step 1 Enter Data into List1 (see screen above). 
Step 2 Access the STAT PLOT Menn. Press 2"d Y = ENTER ENTER. 
(You will see the screen below after you change your setting to match.) 
lotZ 
Plot3 
'f LEdlh 
a+.. w lm 
List: LI 
Axis:B V 
- 
-- 
Step 3 View Display. Press ZOOM 9 (see screen above right). 
There is a noticeable curvc.The data are not Normally Distributed. 
Step 4 Clear the screen for the next problem. Return to the home screen. 
Press 2nd Y = ENTER. Arrow right. Press ENTER CLEAR. 
Learning the Mechanics 
a. Calculate IQR. 
4.76 If a population data set is normally distributed, what is 
b. Calculate IQRls. 
the proportion of measurements you would expect to 
c. Is the value of IQRIs approximately equal to 1.3? 
fall within the following intervals? 
What does this imply? 
a . p * u  
4.78 Normal probability plots for three data sets are shown 
b. k d~ 2u 
below. Which plot indicates that the data are approxi- 
c. p % 3u 
mately normally distributed? 
4.77 Consider a sample data set with the following summary 
statistics: s = 95, Q, = 72, Q, = 195. 

224 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
4.79 Examine the sample data below. 
a. Construct a stem-and-leaf plot to assess whether the 
data are from an approximately normal distribution. 
b. Compute s for the sample data. 
c. Find the values of QL and Q, and the value of s from 
part b to assess whether the data come from an ap- 
proximately normal distribution. 
d. Generate a normal probability plot for the data and 
use it to assess whether the data are approximately 
normal. 
Applying the Concepts 
4.80 In Exercise 2.18 (p. 45) you read about a Journal of 
Statistics Education study of team performance on 
games in which Mark McGwire (of the St. Louis 
Cardinals) and Sammy Sosa (of the Chicago Cubs) hit 
home runs during their record-breaking 1998 Major 
League Baseball season. The data on number of runs 
scored by their respective teams in these games are 
reproduced in the table on the right. 
a. Determine whether the data on number of runs 
scored by the St. Louis Cardinals are approximately 
normal. 
b. Repeat part a for the Chicago Cubs. 
4.81 The data on January 1999 sanitation scores for 121 
cruise ships, first presented in Exercise 2.58 (p. 74), are 
reproduced on page 225. Assess whether the sanitation 
scores are approximately normally distributed. 
4.82 Refer to Exercise 2.36 (p. 59) and the ages of the 50 
most powerful women in corporate America as deter- 
mined by Fortune (Oct. 25,1999). A MINITAB printout 
MINITAB Output for Exercise 4.82 
St. Louis Cardinals 
Chicago Cubs 
with summary statistics for the age distribution is 
reproduced below. 
a. Use the relevant statistics on the printout to deter- 
mine whether the age distribution is approximately 
normal. 
b. In Exercise 2.36d you constructed a relative fre- 
quency histogram for the age data. Use this graph 
to support your conclusion in part a. 
4.83 Refer to the New Jersey Chamber of Commerce1 
Rutgers Business SchoolIArthur Andersen 1998 study 
of Generation Xers' expectations of their future 
careers, Exercise 2.59 (p. 75). Recall that a total of 590 
GenXers responded to the question: "What is the max- 
imum number of years you expect to spend with any 
one employer?" The mean response was 18.2 years 
with a standard deviation of 10.64 years. Demonstrate 
why the distribution of years for all GenXers who 
respond is unlikely to be normally distributed. 
Descriptive Statistics 
Variable 
N 
Mean 
Median 
Tr Mean 
StDev 
SE Mean 
~ g e  
50 
48.160 
47.000 
47.795 
6.015 
0.851 
Variable 
Min 
Max 
Q1 
Q3 
Age 
36.000 
68.000 
45.000 
51.250 

A 
SECTION 4.9 
Approximating a Binomial Distribution with a Normal Distribution 
225 
Americana 
Arcadia 
Arkona 
Astor 
Asuka 
Black Watch 
C. Columbus 
Carnival Destiny 
Celebration 
Century 
Clipper Adventurer 
Club Med I 
Conte~sa I 
Costa Romantica 
Costa Victoria 
Crown Princess 
Crystal Harmony 
Crystal Symphony 
Dawn Princcss 
Delphin 
Destiny 
Discovery Sun 
Disney Magic 
Dolphin IV 
Dreamward 
Ecstasy 
Edinburgh Castle 
Elation 
Emerald 
Enchanted Capri 
Enchanted Isle 
Enchantment of the Seas 
Europa 
Fantasy 
Fascination 
Flamenco 
Galaxy 
Grand Princess 
Grande Caribe 
Grande Mariner 
Grandeur of the Seas 
SANIT.DAT (Data for Exercis 
........................................................................ 
Ship 
Score 
........................................................................ 
4.81) 
................................................................ 
Ship 
Score 
Hanseatic 
Holiday 
Horizon 
Imagination 
Inspiration 
Island Adventure 
Island Dawn 
Island Princess 
Islandbreeze 
Jubilee 
Leeward 
Legacy 
Legend of the Seas 
Maasdam 
Majesty of the Seas 
Maxim Gorky 
Mayan Prince 
Melody 
Mercury 
Monarch of the Seas 
Nantucket Clipper 
Nicuw Amsterdam 
Nippon Maru 
Noordam 
Nordic Princess 
Norway 
Norwegian Crown 
Norwegian Dynasty 
Norwegian Majesty 
Norwegian Sea 
Norwegian Star 
Norwegian Wind 
Oceanbreeze 
Oriana 
Palm Beach Princess 
Paradise 
Paul Gauguin 
Queen Elizabeth 2 
Radisson Diamond 
Regal Empress 
Regal Princess 
Ship 
Score 
Regal Voyager 
Rembrandt 
Rhapsody of the Seas 
Rotterdam VI 
Royal Princess 
Royal Viking Sun 
Ryndam 
Sea Bird 
Sea Goddess I 
Sea Goddess I1 
Sea Lion 
Seabourn Legend 
Seabourn Pride 
Seabreeze I 
Sensation 
Silver Cloud 
Sky Princess 
Song of America 
Sovereign of the Seas 
Spirit of Columbia 
Splendour of the Seas 
Starship Oceanic 
Statendam 
Stella Solaris 
Sun Princess 
Superstar Capricorn 
Topaz 
Tropicale 
Universe Explorer 
Veendam 
Victoria 
Viking Serenade 
Vision of the Seas 
Vistafjord 
Westerdam 
Wind Spirit I1 
World Discoverer 
Yorktown Clipper 
Zenith 
Source: Center for Environmental Health and Injury Control; Turnpa Tribune, Feb. 7,1999. 
APPROXIMATING A BINOMIAL DISTRIBUTION 
WITH A NORMAL DISTRIBUTION (OPTIONAL) 
When the discrete binomial random variable (Section 4.3) can assume a large 
number of values, the calculation of its probabilities may become very tedious. 
To contend with this problem, we provide tables in Appendix B to give the 
probabilities for some values of n and p, but these tables are by necessity in- 
complete. Recall that the binomial probability table (Table 11) can be used only 
for n = 5,6,7,8,9,10, 15,20, or 25. To deal with this limitation, we seek ap- 
proximation procedures for calculating the probabilities associated with a bino- 
mial probability distribution. 

C HAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
When n is large, a normal probability distribution may be used to provide a 
good approximation to the probability distribution of a binomial random variable. 
To show how this approximation works, we refer to Example 4.1 1, in which we 
used the binomial distribution to model the number x of 20 employees who favor 
unionization. We assumed that 60% of all the company's employees favored 
unionization. The mean and standard deviation of x were found to be p = 12 and 
o = 2.2. The binomial distribution for n = 20 and p = .6 is shown in Figure 4.28, and 
the approximating normal distribution with mean p = 12 and standard deviation 
cr = 2.2 is superimposed. 
As part of Example 4.11, we used Table I1 to find the probability that 
x 5 10. This probability, which is equal to the sum of the areas contained in the 
rectangles (shown in Figure 4.28) that correspond to p(O),p(l),p(2), . . . ,p(10), was 
found to equal .245.The portion of the approximating normal curve that would be 
used to approximate the area p(0) + p(l) + p(2) + . . . + p(lO) is shaded in 
Figure 4.28. Note that this shaded area lies to the left of 10.5 (not lo), so we may 
include all of the probability in the rectangle corresponding top(10). Because we 
are approximating a discrete distribution (the binomial) with a continuous distri- 
bution (the normal), we call the use of 10.5 (instead of 10 or 11) a correction for 
continuity. That is, we are correcting the discrete distribution so that it can be ap- 
proximated by the continuous one. The use of the correction for continuity leads 
to the calculation of the following standard normal z value: 
F IG U R E  4.28 
P 
Binomial distribution for 
n = 20, p = .6 and 
.20 
normal distribution with 
p = 12, G- = 2.2 
.15 
Using Table TV, we find the area between z = 0 and z = .68 to be .2517.Then the 
probability that x is less than or equal to 10 is approximated by the area under the 
normal distribution to the left of 10.5, shown shaded in Figure 4.28. That is, 
The approximation differs only slightly from the exact binomial probability, .245. 
Of course, when tables of exact binomial probabilities are available, we will use 
the exact value rather than a normal approximation. 

i 
3 
1 
Y 
e 
L- 
Ir 
)- 
1s 
- X 
the 
the 
B 
245. 
I use 
SECTION 4.9 
Approximating a Binomial Distribution with a Normal Distribution 
227 
Use of the normal distribution will not always provide a good approxima- 
tion for binomial probabilities. The following is a useful rule of thumb to deter- 
mine when n is large enough for the approximation to be effective: The interval 
p k 3u should lie within the range of the binomial random variable x (i.e., 0 to n) 
in order for the normal approximation to be adequate. The rule works well because 
almost all of the normal distribution falls within 3 standard deviations of the 
mean, so if this interval is contained within the range of x values, there is "room" 
for the normal approximation to work. 
As shown in Figure 4.29a for the preceding example with n = 20 and p = .6, 
the interval p f 
3 a  = 12 * 3(2.19) = (5.43, 18.57) lies within the range 0 to 20. 
However, if we were to try to use the normal approximation with n = 10 and 
p = .l, the interval p f 3 a  is 1 + 3(.95), or (- l.85,3.8~). 
As shown in Figure 4.29b, 
this interval is not contained within the range of x since x = 0 is the lower bound 
for a binomial random variable. Note in Figure 4.29b that the normal distribution 
will not "fit" in the range of x, and therefore it will not provide a good approxi- 
mation to the binomial probabilities. 
Rule of thumb for normal 
approximation to binomial 
.20 
probabilities 
a. n = 20, p = .6: Normal approximation is good 
* X 
0
1
2
3
4
5
6
7
8
9
1
0
 
-3o-k--3o- 
n = 10 
b. n = 10, p = .l: Normal approximation is poor 
"
1
_
_
1
_
.
1
1
.
_
-
"
-
x
s
w
 
One problem with any product (e.g., a graphing calculator) that is mass-produced 
is quality control. The process must somehow be monitored or audited to be sure 
the output of the 
conforms to requirements. One method of dealing with 
this problem is lot acceptance sampling, in which items being produced are 
sampled at various stages of the production process and are carefully inspected. 
The lot of items from which the sample is drawn is then accepted or rejected, 

228 
C HAPTER 4 
Random Variables and Probability Distributions 
based on the number of defectives in the sample. Lots that are accepted may be 
sent forward for further processing or may be shipped to customers; lots that are 
rejected may be reworked or scrapped. 
For example, suppose a manufacturer of calculators chooses 200 stamped 
circuits from the day's production and determines x, the number of defective cir- 
cuits in the sample. Suppose that up to a 6% rate of defectives is considered ac- 
ceptable for the process. 
a. Find the mean and standard deviation of x, assuming the defective rate is 6%. 
b. Use the normal approximation to determine the probability that 20 or more 
defectives are observed in the sample of 200 circuits (i.e., find the approxi- 
mate probability that x 2 20). 
S o I u t i o n 
a. The random variable x is binomial with n = 200 and the fraction defective 
p = .06. Thus, 
We first note that 
lies completely within the range from 0 to 200. Therefore, a normal proba- 
bility distribution should provide an adequate approximation to this bino- 
mial distribution. 
b. Use the rule of complements, P(x r 20) = 1 - P(x 5 19). To find the ap- 
proximating area corresponding to x 5 19, refer to Figure 4.30. Note that we 
want to include all the binomial probability histogram from 0 to 19, inclu- 
sive. Since the event is of the form x 5 a, the proper correction for continu- 
ity is a + .5 = 19 + .5 = 19.5. Thus, the z value of interest is 
Referring to Table IV in Appendix B, we find that the area to the right of the 
mean 0 corresponding to z = 2.23 (see Figure 4.31) is .4871. So the area 
A = P(Z 5 2.23) is: 

SECTION 4.9 
Approximating a Binomial Distribution with a Normal Distribution 
229 
Standard normal distribution 
Thus, the normal approximation to the binomial probability we seek is 
In other words, the probability is extremely small that 20 or more defectives 
will be observed in a sample of 200 circuits-if in fact the true fraction of 
defectives is .06. If the manufacturer observes x 2 20, the likely reason is 
that the process is producing more than the acceptable 6% defectives. The 
lot acceptance sampling procedure is another example of using the rare- 
event approach to make inferences. 
+ 
The steps for approximating a binomial probability by a normal probability 
are given in the accompanying box. 
ial 
. After you have 
ed n and p for the binomial distribution, cal 
late the interval 
If the interval lies in 
e 0 to n, the normal distribution will 
vide a reasonable approximation to the probabilities of most binom 
events. 
2. Express the binomial probability to be approximated in the form 
P(X 5 a) or P(X 5 b) - P(X 5 a). For example, 
For each value o 
the correspondine, standard normal z value is 
Sketch the approximating normal distribution and shade the area corr 
sponding to the probability of the event of interest, as in Figure 4.3 
Verify that the rectangles you have included in the shaded area c 
spond to the event probability you wish to approximate. Using 
and the z value(s) you calculated in step 3, find the shaded ar 
. , -  
the ap 
ility 
(continue 

230 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
binomial probabilities by 
Learning the Mechanics 
4.84 Assume that x is a binomial random variable with n and 
p as specified in parts a-f. For which cases would it be 
appropriate to use a normal distribution to approximate 
the bmomial distribution'? 
a. n = 100, p = .O1 
b. n = 20, p = .6 
c. n = 10, p = .4 
d. n = 1,000, p = .05 
e. n =  100,p=.8 
I 
f. n = 3 5 , p = . 7  
I 
4.85 Assume that x is a binomiz 11 random variable wil 
n = 25 and p = .5. Use Table I1 of Appendix B and the 
normal approximation to find the exact and approxi- 
mate values, respectively, for the following probabilities: 
a. P(X 5 11) 
I 
b. P(X 2 16) 
c. ~
(
8
~
~
~
1
6
)
 
I 
4.86 Assume that x is a binomial random variable with 
n = 100 and p = .40. Use a normal approximation to 
find the following: 
I 
a. P(X 5 35) 
I 
b. ~ ( 4 0  
5 x 5 50) 
c. ~
(
x
 
2 38) 
Applying the Concepts 
4.87 Refer to the FTC study of the pricing accuracy of super- 
market electronic scanners, Exercise 4.30 (p. 192). 
Recall that the probability that a scanned item is priced 
incorrectly is y3,, = .033. 
1 
a. Suppose 10,000 supermarket items are scanned. 
What is the approximate probability that you ob- 
serve at least 100 items with incorrect prices? 
b. Suppose 100 items are scanned and you are interested 
in the probability that fewer than five are incorrectly 
priced. Explain why the approximate method of part a 
may not yield an accurate estimate of the probability. 
Certain semiconductor wafers are exposed to an envi- 
ronment that generates up to 100 possible defects per 
wafer. The number of defects per wafer, x, was found to 
follow a binomial distribution if the manufacturing 
process is stable and generates defects that are random- 
ly distributed on the wafers (IEEE Transactions on 
Semiconductor Manufacturing, May 1995). Let p repre- 
sent the probability that a defect occurs at any one of 
the 100 points of the wafer. For each of the following 
cases, dctermine whether the normal approximation can 
be used to characterize x. 
a. p = .O1 
b. p = .SO 
c. p = .90 
4.89 In 1999, nearly 500,000 Americans underwent laser 
surgcry to correct their vision. While the majority of 
patients were pleased with the results, it is estimated 
that 1% of patients of corneal specialists and 5% of 
patients of less experienced ophthalmologists have seri- 
ous post-laser vision problems (Time, Oct. 11,1999). 
a. If all 500,000 patients were operated on by corneal 
specialists, what is the expected number of patients 
who will experience serious post-laser vision prob- 
lems? Answer the same question assuming all patients 
are operated on by ophthalmologists. 
b. If 400 employees of a particular company choose to 
undergo laser surgery with ophthalmologists, what is 
the approximate probability that 20 or more of these 
employees will suffer serious vision problems? Justi- 
fy the methodology you used to answer the question. 
c. Refer to part b. Can the same methodology be used to 
answer the same question assuming all 400 employ- 
ees had chosen a corneal specialist'? Explain. 
4.90 In recent years, American consumers have come to 
regard credit cards as commodities. As a result, the credil 
card industry has become increasingly competitive. The 
table on p. 231 reports the industry's market share data 
for mid-1999.A random sample of 100 credit card users is 
to be questioned regarding their satisfaction with their 
credit card company. For simplification, assume that each 
4.88 The computer chips in today's notebook and laptop 
computers are produced from semiconductor wafers. 
I 
-
-

SECTION 4.10 
T h e  E x p o n e n t i a l  D i s t r i b u t i o n  ( O p t i o n a l )  
231 
r 
I 
1 
r , f 
d , 
f 
i- 
a1 
ts 
b- 
Its 
to 
is 
:se 
;ti- 
In. 
to 
IY- 
to 
:dit 
fie 
ata 
-s is 
leir 
ach 
credit card user carries just one credit card and that the 
market share percentages are the percentages of all 
credit card customers that carry each brand. 
Credit Card 
Market Share % 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Visa 
47.0 
Mastercard 
25.5 
American Express 
20.2 
Discover 
6.0 
Diners Club 
1.3 
Source: Newsweek, Oct. 4,1999, p. 55. 
a. Propose a procedure for randomly selecting the 
100 credit card users. 
b. For random samples of 100 credit card users, what is 
the expected number of customers who carry Visa? 
Discover? 
c. What is the probability that half or more of the sample 
of credit card users carry Visa? American Express? 
d. Justify the use of the normal approximation to the 
binomial in answering the question in part c. 
4.91 Refer to Exercise 4.35 (p. 193). where the number of 
shuttle catastrophes caused by booster failure in n mis- 
sions was treated as a binomial random variable. Using 
the binomial distribution and the probability of cata- 
strophe determined by the Air Force's risk assessment 
study ('I3,), 
you determined the probability of at least 
one shuttle catastro~he in 25 missions to be S1.55. 
a. Based on the guidelines presented in this section, 
would it have been advisable to approximate this 
probability using the normal approximation to the 
binomial distribution? Explain. 
b. Regardless of your answer to part a, use the normal 
distribution to approximate the binomial probability. 
Comment on the difference between the exact and 
approximate probabilities. 
C. Refer to part a. Would the normal approximation be 
advisable if n = 100? If n = 500? If n = 1,000? 
d. Approximate the probability that more than 25 cata- 
strophes occur in 1,000 flights, assuming that the 
probability of a catastrophe in any given flight re- 
mains %,. 
4.92 The Chronicle of Higher Education Almanac (Aug. 
27,1999) reports that the percentage of undergraduates 
in the United States receiving federal financial aid is 
45% at public four-year institutions and 52% at private 
four-year institutions.The U.S. Department of Education 
is interested in questioning a random sample of 100 U.S. 
undergraduate students to assess their satisfaction with 
federal financial aid procedures and policies. 
a. Explain the difficulties of obtaining the desired ran- 
dom sample. 
b. Assume the appropriate percentage above applies 
to your institution. If a random sample of 100 stu- 
dents from your institution were contacted, what is 
the approximate probability that 50 or more receive 
financial aid? Less than 25? 
c. What assumptions must be made in order to answer 
part b using the normal approximation to the 
binomial? 
4.93 According to New Jersey Business (Feb. 1996), Newark 
International Airport's new terminal handles an aver- 
age of 3,000 international passengers an hour, but is 
capable of handling twice that number. Also, 80% of 
arriving international passengers pass through without 
their luggage being inspected and the remainder are 
detained for inspection. The inspection facility can 
handle 600 
an hour without unreasonable 
delays for the travelers. 
a. When international passengers arrive at the rate of 
1,500 per hour, what is the expected number of pas- 
sengers who will be detained for luggage inspection? 
b. In the future, it is expected that as many as 4,000 in- 
ternational passengers will arrive per hour. When that 
occurs, what is the expected number of passengers 
who will be detained for luggage inspection? 
c. Refer to part b. Find the approximate probability 
that more than 600 international passengers will be 
detained for luggage inspection. (This is also the 
probability that travelers will experience unreason- 
able luggage inspection delays.) 
THE EXPONENTIAL DISTRIBUTION (OPTIONAL) 
The length of time between arrivals at a fast-food drive-through restaurant, the 
length of time between breakdowns of manufacturing equipment, and the length of 
time between filings of claims in a small insurance office are all business phenom- 
ena that we might want to describe probabilistically. The amount of time between 
occurrences of random events like these can often be described by the exponential 
probability distribution. For this reason, the exponential distribution is sometimes 
called the waiting time distribution. The formula for the exponential probability 
distribution is shown in the box along with its mean and standard deviation. 

232 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Unlike the normal distribution which has a shape and location determined 
by the values of the two quantities p and a, the shape of the exponential distri- 
bution is governed by a single quantity, A. Further, it is a probability distribution 
with the property that its mean equals its standard deviation. Exponential distri- 
butions corresponding to h = .5,1, and 2 are shown in Figure 4.33. 
FIGURE 4.33 
f (4 
Exponential distributions 
t 
To calculate probabilities for exponential random variables, we need to be 
able to find areas under the exponential probability distribution. Suppose we 
want to find the area A to the right of some number a, as shown in Figure 4.34. 
This area can be calculated by using the formula in the box. 
Findinq the Area A to the Riqht of a Number a for an 
FIGURE 4.34 
f ( x )  
The area A to the riaht of a number a for an 
t 
exponential distribution 
*For students with a knowledge of calculus, the shaded area in Figure 4.34 corresponds to the integral 

i 
S ECTION 4.10 
T h e  E x p o n e n t i a l  D i s t r i b u t i o n  ( O p t i o n a l )  
233 
Use Table V in Appendix B or a pocket calculator with an exponential func- 
tion to find the value of epA" after substituting the appropriate numerical values 
for A and a. 
I 
P
-
n
m
-
m
-
1
.
1
1
1
 
Suppose the length of time (in days) between sales for an automobile salesperson 
is modeled as an exponential distribution with A = .5. What is the probabilitv the 
salesperson goes mbre than 5 days without a sale? 
S o I u t i o n The probability we want is the area A to the right of a = 5 in Figure 4.35. To find 
this probability, use the formula given for area: 
FIGURE 4.35 
f (x) 
Area to the right of a = 5 for Example 4.25 
.6 
Referring to Table V, we find 
Our exponential model indicates that the probability of going more than 5 days 
without a sale is about .08 for this automobile salesperson. 
oven. Preliminary testing has shown that the length of life (in years), x, of a 
magnetron tube has an exponential probability distribution with A = .16. 
a. Find the mean and standard deviation of x. 
b. Suppose a warranty period of 5 years is attached to the magnetron tube. 
What fraction of tubes must the manufacturer plan to replace, assuming 
that the exponential model with A = .16 is correct? 
c. Find the probability that the length of life of a magnetron tube will fall 
within the interval p - 2a to p + 2a. 
S o I u t i o n 
a. For this exponential random variable, p = llh = Yl6 = 6.25 years. Also, 
since p = (T, (T = 6.25 years. 
b. To find the fraction of tubes that will have to be replaced before the 5-year 
warranty period expires, we need to find the area between 0 and 5 under the 
distribution. This area, A, is shown in Figure 4.36. 
- X 
ral 

234 
CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
FI GURE 4.36 
f (4 
Area to the left of a = 5 for Example 4.26 
A 
0 
5 
10 
15 
To find the required probability, we recall the formula 
(see Table V). To find the area A, we use the complementary relationship: 
I 
So approximately 55% of the magnetron tubes will have to be replaced dur- 
ing the 5-year warranty period. 
1 
c. We would expect the probability that the life of a magnetron tube, x, falls 
within the interval p - 2 a  to p + 2 a  to be quite large. A graph of the ex- 
ponential distribution showing the interval p - 2a to p + 2a is given in Fig- 
~ 
ure 4.37. Since the point p - 2a lies below x = 0, we need to find only the 
area between x = 0 and x = p + 2 a  = 6.25 + 2(6.25) = 18.75. 
This area, P, which is shaded in Figure 4.37, is 
t 

Ils 
X- 
g- 
ne 
SECTION 4.10 
T h e  E x p o n e n t i a l  D i s t r i b u t i o n  ( O p t i o n a l )  
235 
You can see that this probability agrees very well with the Empirical Rule 
(Table 2.9, p. 71) even though this probability distribution is not mound- 
shaped. (It is strongly skewed to the right.) 
Learning the Mechanics 
4.94 The random variables x and y have exponential distri- 
butions with A = 3 and A = .75, respectively. Using 
Table V in Appendix B, carefully plot both distributions 
on the same set of axes. 
4.95 Use Table V in Appendix B to determine the value of 
e-"'for each of the following cases. 
a. h = l , a = l  b. A =  1 , a = 2 . 5  
c. A = 2.5, a = 3 d. A = 5, a = .3 
4.96 Suppose x has an exponential distribution with A = 3. 
Find the following probabilities: 
a. P(X > 2) b. P(X > 1.5) c. P(X > 3) 
d. ~ ( x  
> .45) 
4.97 Suppose x has an exponential distribution with A = 2.5. 
Find the following probabilities: 
a. ~ ( x  
5 3) b. P(X 5 4) c. P(X 5 1.6) 
d. ~ ( x  
5 .4) 
4.98 Suppose the random variable x has an exponential 
probability distribution with A = 2. Find the mean and 
standard deviation of x. Find the probability that x will 
assume a value within the interval f 2a. 
Applying the Concepts 
4.99 University of Michigan researchers B. Wilkinson, N. 
Diedrich and E. Rothman, and C. Drummond of 
Indiana-Purdue University in Fort Wayne studied the 
duration between goals scored by the University of 
Michigan hockey team during its 40-game, 1996 
national championship season. They found that the 
time-between-scores could be characterized with an 
exponential distribution with a mean of 10.54 minutes 
(Geological Society of America Bulletin, August 1998). 
a. Find the value of A for this exponential distribution. 
h. Find the mean and standard deviation for this dis- 
tribution and interpret each in the context of the 
problem. 
c. Graph this exponential distribution. Locate the 
mean on the graph. 
d. If Michigan scores with exactly two minutes left in 
the game, what is the probability they will score 
again before time runs out? 
4.100 Lack of port facilities or shallow water may require 
cargo on a large ship to be transferred to a pier using 
smaller craft. This process may require the smaller craft 
to cycle back and forth from ship to shore many times. 
Researchers G. Horne (Center for Naval Analysis) and 
T. Irony (George Washington University) developed 
models of this transfer process that provide estimates 
of ship-to-shore transfer times (Naval Research 
Logistics, Vol. 41, 1994). They modeled the time 
between arrivals of the smaller craft at the pier using 
an exponential distribution. 
a. Assume the mean time between arrivals at the pier 
is 17 minutes. Give the value of A for this exponen- 
tial distribution. Graph the distribution. 
b. Suppose there is only one unloading zone at the 
pier available for the small craft to use. If the first 
craft docks at 10:OO A.M. and doesn't finish unload- 
ing until 10:15 A.M., what is the probability that the 
second craft will arrive at the unloading zone and 
have to wait before docking? 
4.101 Product reliability has been defined as the probability 
that a product will perform its intended function satis- 
factorily for its intended life when operating under 
specified conditions. The reliability function, R(x). for a 
product indicates the probability of the product's life 
exceeding x time periods. When the time until failure 
of a product can be adequately modeled by an expo- 
nential distribution, the product's reliability function is 
R(x) = e-" 
(Ross, Stochastic Processes, 1996). 
Suppose that the time to failure (in years) of a particu- 
lar product is modeled by an exponential distribution 
with A = .5. 
a. What is the product's reliability function? 
b. What is the probability that the product will per- 
form satisfactorily for at least four years? 
c. What is the probability that a particular product will 
survive longer than the mean life of the product? 
d. If A changes, will the probability that you calculated 
in part c change? Explain. 
e. If 10,000 units of the product are sold, approxi- 
mately how many will perform satisfactorily for 
more than five years? About how many will fail 
within one year? 
f. How long should the length of the warranty period 
be for the product if the manufacturer wants to re- 
place no more than 5% of the units sold while 
under warranty? 
4.102 A part processed in a flexible manufacturing system 
(FMS) is routed through a set of operations, some of 
which are sequential and some of which are parallel. In 
addition, an FMS operation can be processed by alter- 
native machines. An article in IEEE Transactions (Mar. 
1990) gave an example of an FMS with four machines 
operating independently. The repair rates for the 

236 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
machines (i.e., the time, in hours, it takes to repair a 
failed machine) are exponentially distributed with means 
p, = 1, p2 = 2, p, = .5, and p, = .5, respectively. 
a. Find the probability that the repair time for machine 
1 exceeds one hour. 
b. Repeat part a for machine 2. 
c. Repeat part a for machines 3 and 4. 
d. If all four machines fail simultaneously, find the 
probability that the repair time for the entire system 
exceeds one hour. 
4.103 The importance of modeling machine downtime cor- 
rectly in simulation studies was discussed in Industrial 
Engineering (Aug. 1990).The paper presented simula- 
tion results for a single-machine-tool system with the 
following properties: 
The interarrival times of jobs are exponentially dis- 
tributed with a mean of 1.25 minutes 
The amount of time the machine operates before 
breaking down is exponentially distributed with a 
mean of 540 minutes 
a. Find the probability that two jobs arrive.for pro- 
cessing at most one minute apart. 
b. Find the probability that the machine operates for 
at least 720 minutes (12 hours) before breaking 
down. 
4.104 In an article published in the European Journal of 
Operutiontrl Research (Vol. 21, 1985) the vehicle-dis- 
patching decisions of an airport-based taxi service 
were investigated. In modeling the system, the authors 
assumed travel times of successive trips to be inde- 
pendent exponential random variables. Assume 
A = ,051. 
a. What is the mean trip time for the taxi service'? 
b. What is the probability that a particular trip will take 
more than 30 minutes'? 
c. Two taxis have just been dispatched. What is the 
probability that both will be gone for more than 
30 mjnutes? That at lcast one of the taxis will return 
within 30 minutes? 
SAMPLING DISTRIBUTIONS 
In previous sections we assumed that we knew the probability distribution of a random 
variable, and using this knowledge we were able to compute the mean, variance, and 
probabilities associated with the random variable. However, in most practical applica- 
tions, the true mean and standard deviation are unknown quantities that would have to 
be estimated. Numerical quantities that describe probability distributions are calledpa- 
rameters. Thus,p, the probability of a success in a binomial experiment, and p and a,the 
mean and standard deviation of a normal distribution, are examples of parameters 
A parameter is a numerical descriptive measure of a population. Because it is 
based on the observations in the population, its value is almost always unknown. 
We have also discussed the sample mean x, sample variance s2, sample stan- 
dard deviation s, etc., which are numerical descriptive measures calculated from 
the sample. We will often use the information contained in these sample statistics 
to make inferences about the parameters of a population. 
DEFINITION 4.1 1 
A sample statistic is a numerical descriptive measure of a sample. It is calcu- 
ted lrom the observations in the sample. 
Note that the term statistic refers to a sample quantity and the term para- 
meter refers to a population quantity. 
In order to use sample statistics to make inferences about population parame- 
ters, we need to be able to evaluate their properties. Does one sample statistic contam 
more information than another about a population parameter? On what basis should 
we choose the "best" statistic for making inferences about a parameter? If we want 

I 
1 
n 
ld 
a- 
to 
a- 
he 
5 
an- 
om 
tics 
U- 
ara- 
m e -  
ntain 
~ould 
want 
SECTION 4.11 
S a m p l i n g  D i s t r i b u t i o n s  
237 
to estimate, for example, the population mean p, we could use a number of sample 
statistics for our estimate. Two possibilities are the sample mean i and the sample 
median m. Which of these do you think will provide a better estimate of p? 
Before answering this question, consider the following example: Toss a fair 
die, and let x equal the number of dots showing on the up face. Suppose the die is 
tossed three times, producing the sample measurements 2,2,6. The sample mean 
is T = 3.33 and the sample median is m = 2. Since the population mean of x is 
y = 3.5, you can see that for this sample of three measurements, the sample mean 
- 
x provides an estimate that falls closer to p than does the sample median (see Fig- 
ure 4.38a). Now suppose we toss the die three more times and obtain the sample 
measurements 3, 4, 6. The mean and median of this sample are T = 4.33 and 
m = 4, respectively. This time rn is closer to p (see Figure 4.38b). 
FIGURE 4.38 
0 
0 
0 
0 
Comparing the sample mean 
A 
1 
I 
I 
i 'It4 
5
6
0
1
 
3 t 4 t 5  
6 
(X) and sample median (m) as 
estimators of the population 
m 
3 
t f  
F m 
mean (I*.) 
a. Sample 1: f is closer than rn to p 
b. Sample 2: m is closer than .E to p 
This simple example illustrates an important point: Neither the sample mean 
nor the sample median will alwuys fall closer to the population mean. Conse- 
quently, we cannot compare these two sample statistics, or, in general, any two 
sample statistics, on the basis of their performance for a single sample. Instead, we 
need to recognize that sample statistics are themselves random variables, because 
different samples can lead to different values for the sample statistics. As random 
variables, sample statistics must be judged and compared on the basis of their 
probability distributions, i.e., the collection of values and associated probabilities 
of each statistic that would be obtained if the sampling experiment were repeated 
a very large number of times. We will illustrate this concept with another example. 
Suppose it is known that the connector module manufactured for a certain 
brand of pacemaker has a mean length of p = .3 inch and a standard deviation of 
.005 inch. Consider an experiment consisting of randomly selecting 25 recently 
manufactured connector modules, measuring the length of each, and calculating 
the sample mean length i. If this experiment were repeated a very large number 
of times, the value of i would vary from sample to sample. For example, the first 
sample of 25 length measurements might have a mean 2 = .301, the second sam- 
ple a mean i = .298, the third sample a mean 5 = .303, etc. If the sampling ex- 
periment were repeated a very large number of times, the resulting histogram of 
sample means would be approximately the probability distribution of i. 
If i is a 
good estimator of p, we would expect the values of i to cluster around p as 
shown in Figure 4.39. This probability distribution is called a sampling distribu- 
tion because it is generated by repeating a sampling experiment a very large 
number of times. 
FI GURE 4.39 
Sampling distribution for T based on 
a sample of n = 25 length 
measurements T
,297 
,298 ,299 
.3 F 
.301 ,302 
.303 
- 

238 
CHAPTER 4 
Random Variables and Probability Distributions 
DEFINITION 4.12 
The sampling distribution of a sample statistic calculated from a sample of 
n measurements is the probability distribution of the statistic. 
In actual practice, the sampling distribution of a statistic is obtained mathe- 
matically or (at least approximately) by simulating the sample on a computer 
using a procedure similar to that just described. 
If i has been calculated from a sample of n = 25 measurements selected 
from a population with mean p = .3 and standard deviation a = ,005, the sam- 
pling distribution (Figure 4.39) provides information about the behavior of i in 
repeated sampling. For example, the probability that you will draw a sample of 
25 length measurements and obtain a value of i in the interval .299 5 i 5 . 3  
will be the area under the sampling distribution over that interval. 
Since the properties of a statistic are typified by its sampling distribution, it fol- 
lows that to compare two sample statistics you compare their sampling distributions. 
For example, if you have two statistics, A and B, for estimating the same parameter 
(for purposes of illustration, suppose the parameter is the population variance u2) 
and 
if their sampling distributions are as shown in Figure 4.40, you would choose statistic 
A in preference to statistic B. You would make this choice because the sampling dis- 
tribution for statistic A centers over a2 and has less spread (variation) than the sam- 
pling distribution for statistic B. When you draw a single sample in a practical 
sampling situation, the probability is higher that statistic A will fall nearer u2. 
F IG U R E  4.40 
Sampling 
Two sampling distributions for estimating the 
distribut~on 
population variance, a2 
Remember that in practice we will not know the numerical value of the un- 
known parameter a2, so we will not know whether statistic A or statistic B is 
closer to a2 for a sample. We have to rely on our knowledge of the theoretical 
sampling distributions to choose the best sample statistic and then use it sample 
after sample. The procedure for finding the sampling distribution for a statistic is 
demonstrated in Example 4.27. 
s *  " - 
0,3, and 12 and described 
by the probability distribution shown here. A random sample of n = 3 
measurements is selected from the population. 
a. Find the sampling distribution of the sample mean Y. 
b. Find the sampling distribution of the sample median m. 

r 
1 
n , f 
3 
d- 
1s. 
er 
ld 
tic 
is- 
n- 
:a1 
3n 
ic A 
3
m
 
un- 
B is 
tical 
nple 
tic is 
m 
ibed 
= 3 
/ 
SECTION 4.11 
S a m p l i n g  D i s t r i b u t i o n s  
239 
TABLE 4.8 
All Possible Samples of n = 3 Measurements, Example 4.27 
Possible Samples 
i 
m 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . . 
Probability 
S 0 I u t i o n 
Every possible sample of n = 3 measurements is listed in Table 4.8 along with the 
sample mean and median. Also, because any one sample is as likely to be selected 
as any other (random sampling), the probability of observing any particular 
sample is x7. The probability is also listed in Table 4.8. 
a. From Table 4.8 you can see that i can assume the values 0,1,2,3,4,5,6,8,9, 
and 12. Because T = 0 occurs in only one sample, P(i = 0) = 1/,,. Similarly, 
- 
x = 1 occurs in three samples: (0, 0, 3), (0, 3, O), and (3, 0, 0). Therefore, 
P(i = 1) = 3, 
= '/g. Calculating the probabilities of the remaining values 
of i and arranging them in a table, we obtain the probability distribution 
shown here. 
This is the sampling distribution for F because it specifies the probability as- 
sociated with each possible value of ?. 

240 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
b. In Table 4.8 you can see that the median m can assume one of the three val- 
ues 0,3, or 12. The value m = 0 occurs in seven different samples. Therefore, 
P(m = 0) = 7/,,. Similarly, m = 3 occurs in 13 samples and m = 12 occurs in 
seven samples. Therefore, the probability distribution (i.e., the sampling dis- 
tribution) for the median m is as shown below. 
8 
Example 4.27 demonstrates the procedure for finding the exact sampling 
distribution of a statistic when the number of different samples that could be se- 
lected from the population is relatively small. In the real world, populations often 
consist of a large number of different values, making samples difficult (or impos- 
sible) to enumerate. When this situation occurs, we may choose to obtain the ap- 
proximate sampling distribution for a statistic by simulating the sampling over and 
' 
over again and recording the proportion of times different values of the statistic 
occur. Example 4.28 illustrates this procedure. 
1 
" " % *  
Suppose we perform the following experiment over and over again: Take a sample 
of 11 measurements from the uniform distribution shown in Figure 4.41. T h ~ s  
distribution, known as the uniform distribution, was discussed in opti&al Section 4.6. 
Calculate the two sample statistics 
- 
C X  
x = Sample mean = - 
11 
m = Median = Sixth sample measurement when the 11 measurements 
are arranged in ascending order 
f 
Obtain approximations to the sampling distributions of T and m. 
I 
I 
S o I u t i o n We use a computer to generate 1,000 samples, each with n = 11 observations. 
- 
Then we compute 2 and m for each sample. Our goal is to obtain approximations 
to the sampling distributions of i and m to find out which sample statistic ( i  or m) 
contains more information about p. [Note: In this particular example, we knmc 
the population mean is p = 5 .  (See optional Section 4.6)] The first 10 of the 
1,000 samples generated are presented in Table 4.9. For instance, the first 
computer-generated sample from the uniform distribution (arranged In 
ascending order) contained the following measurements: .125, .138, .139, .217. 
f (x) 
.419, S06, S16, .757, .771, .786, and .919. The sample mean i and median m 
- t. 
computed for this sample are 
- .I25 + .I38 + . + .919 
X = 
11 
= .481 
m = Sixth ordered measurement = SO6 
1 
The relative frequency histograms for i and m for the 1,000 samples of size 
0 
n = 11 are shown in Figure 4.42. 
FIGURE 4.41 
You can see that the values of 2 tend to cluster around p to a greater extent 
Uniform distribution from 0 to 1 
than do the values of m. Thus,on the basis of the observed sampling distributions,w 
I 
- 

~ns. 
3ns 
m) 
LOW 
the 
irst 
1 in 
217, 
n rn 
' size 
xtent 
as, we 
SECTION 4.11 
S a m p l i n g  D i s t r i b u t i o n s  
241 
TABLE 4.9 
First 10 Samples of n = 11 Measurements 
from a Uniform Distribution 
Sample I 
Measurements 
.12 .18 .24 .30 36 .42 .48 .54 .60 .66 .72 .78 .84 .90 
.12 .18 .24 .30 .36 .42 .48 .54 .60 .66 .72 .78 .84 .90 
a. Sampling distribution for ,Y (based on 1,000 samples of 
b. Sampling distribution for rn (based on 1,000 samples of 
n = 11 measurements) 
n = 11 measurements) 
FIGURE 4.42 
Relative frequency histograms for i and m, Example 4.28 
conclude that i contains more information about p than rn does-at least for sam- 
ples of n = 11 measurements from the uniform distribution. 
As noted earlier, many sampling distributions can be derived mathemati- 
cally, but the theory necessary to do this is beyond the scope of this text. Conse- 
quently, when we need to know the properties of a statistic, we will present its 
sampling distribution and simply describe its properties. An important sampling 
distribution, the sampling distribution of i, 
is described in the next section. 
Learning the Mechanics 
4.105 The probab~lity distribution shown here describes a 
population of measurements that can assume values 
of 0,2.4. and 6, each of which occur5 w~th the same rel- 
atlve frequency: 
a. List all the different samples of n = 2 measure- 
b. Calculate the mean of each different sample listed in 
ments that can bc selected from this population. 
part a. 

I 
242 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
I 
c If a sample of n = 2 measurements is randomly se- 
I 
/I I 
lected from the population, what is the probability 
that a specific sample will be selected? 
d. Assume that a random sample of n = 2 measure- 
ments is selected from the population. List the dif- 
ferent values of T found in part b, and find the 
probability of each. Then give the sampling distri- 
bution ol the sample mean i in tabular form. 
e. Construct a probability histogram for the sampling 
distribution of 2. 
4.106 Simulate sampling from the population described in 
Exercise 4.105 by marking the values of x, one on each 
of four identical coins (or poker chips, etc.). Place the 
coins (marked 0,2,4, and 6) into a bag, randomly select 
one, and observe its value. Replace this coin, draw a 
second coin, and observe its value. Finally, calculate the 
mean i for this sample of n = 2 observations randomly 
selected from the population (Exercise 4.105, part b). 
Replace the coins, mix, and using the same procedure, 
select a sample of n = 2 abservations from the popula- 
tion. Record the numbers and calculate 7 for this 
sample. Repeat this sampling process until you acquire 
100 values of T. Construet a relative frequency distribu- 
tion for these 100 sample means Compare this distribu- 
tion to the exact sampling distribution of i found in part 
e of Exercise 4.105. [Note: the distribution obtained in 
this exercise is an approximation to the exact sampling 
distribution. But, if you were to repeat the sampling pro- 
cedure, drawing two coins not 100 times but 10,000 
times, the relative frequency distribution for the 10,000 
sample means would be almost identical to the sam- 
pling distribution of i found in Exercise 4.105, part e.] 
4.107 Consider the population described by the probability 
distribution shown below. 
The random variable x is observed twice. If these obser- 
vations are independent, verify that the different sam- 
ples of size 2 and their probabilities are as shown at the 
top of the next column. 
a. Find the sampling distribution of the sample mean x. 
Sample 
Probability 1 
Sample 
Probability 
b. Construct a probability histogram for the sampling 
distribution of T. 
c. What is the probability that 7 is 4.5 or larger? 
d. Would you expect to observe a value of i equal to 
4.5 or larger? Explain. 
4.108 Refer to Exercise 4.107 and find E ( x )  = p. Then 
use the sampling distribution of i found in Exer- 
cise 4.107 to find the expected value of i. 
Note that 
E ( 7 )  = I*.. 
4.109 Refer to Exercise 4.107. Assume that a random sample 
of n = 2 measurements is randomly selected from the 
population. 
a. List the different values that the sample median rn 
may assume and find the probability of each. Then 
give the sampling distribution of the sample median. 
b. Construct a probability histogram for the sampling 
distribution of the sample median and compare it 
with the probability histogram for the sample mean 
(Exercise 4.107, part b). 
4.110 Consider a population that contains values of x equal 
to 00,01,02, 03,. . . ,96, 97,98,99. Assume that these 
values of x occur with equal probability. Use the com- 
puter to generate 500 samples, each containing n = 25 
measurements, from this population. Calculate the 
sample mean i and sample variance s2 for each of the 
500 samples. 
a. To approximate the sampling distribution of 2, con- 
struct a relative frequency histogram for the 500 val- 
ues of i. 
b. Repeat part a for the 500 values of s2. 
THE CENTRAL LIMIT THEOREM 
Estimating the mean useful life of automobiles, the mean monthly sales for all 
computer dealers in a large city, and the mean breaking strength of new plastic are 
practical problems with something in common. In each case we are interested m 
making an inference about the mean ,z of some population. As we mentioned III 
Chapter 2, the sample mean T is, in general, a good estimator of p. We now devel- 
op pertinent,information about the sampling distribution for this useful statist~c 

- 
c3 
to 
:n 
:r- 
at 
de 
he 
m 
Len 
an. 
ing 
: 
it 
:an 
Pal 
lese 
3m- 
: 25 
the 
the 
;on- 
val- 
~r all 
are 
:d in 
:d in 
evel- 
istic. 
S ECTION 4.12 
T h e  C e n t r a l  Limit T h e o r e m  
243 
The mean and standard deviation of this probabihty distribution are u. = .5 and 
a = .29. (See optional Section 4.6 for the formulas for p and u.) Now suppose a 
sample of 11 measurements is selected from this population. Describe the sampling 
distribution of the sample mean T based on the 1,000 sampling experiments 
discussed in Example 4.28. 
FIGURE 4.43 
J 
Sampled uniform population 
S o I u t i o n 
You will recall that in Example 4.28 we- generated 1,000 sahples of n = 11 
measurements each. The relative frequency histogram for the 1,000 sample means 
is shown in Figure 4.44 with a normal probability distribution superimposed. You 
can see that this normal probability distribution approximates the computer- 
generated sampling distribution very well. 
FIGURE 4.44 
Relative frequency 
histogram for i in 1,000 
,120 
samples of n = 11 
measurements with normal 
distribution superimposed 
2' 
5 .090 
To fully describe a normal probability distribution, it is necessary to know 
its mean and standard deviation. Inspection of Figure 4.44 indicates that the 
mean of the distribution of i, 
px, 
appears to be very close to .5, the mean of the 
sampled uniform population. Furthermore, for a mound-shaped distribution such 
as that shown in Figure 4.44, almost all the measurements should fall within 3 
standard deviations of the mean. Since the number of values of i is very large 
(1,000), the range of the observed x's divided by 6 (rather than 4) should give a 

244 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
reasonable approximation to the standard deviation of the sample mean, IT,. The 
values of i range from about .2 to .8, so we calculate 
Range of x's 
.8 - .2 
cry = 
-- 
- 
6 
6 
= .I 
To summarize our findings based on 1,000 samples, each consisting of 11 measure- 
ments from a uniform population, the sampling distribution of T appears to be ap- 
proximately normal with a mean of about .5 and a standard deviation of about .l. 
The sampling distribution of T has the properties given in the next box, as- 
suming only that a random sample of n observations has been selected from any 
population. 
1. Mean of sampling distribution equals mean of sampled population.That 
is,p~~, 
= E(X) = p.* 
2. Standard deviation of sampling distribution equals 
Standard deviation of sampled population 
Square root of sample size 
standard error of the 
You can see that our approximation to py in Example 4.29 was precise, 
since property 1 assures us that the mean is the same as that of the sampled pop 
ulation: .5. Property 2 tells us how to calculate the standard deviation of the 
sampling distribution of T. Substituting a = .29, the standard deviation of the 
sampled uniform distribution, and the sample size n = 11 into the formula f o ~  
a,, we find 
Thus, the approximation we obtained in Example 4.29, a, = .l, is very close to the 
exact value, a, = .09. 
What can be said about the shape of the sampling distribution of i? 
Two im- 
portant theorems provide this information. 
*When a sample statistic has a mean equal to the parameter estimated, the statistic is said to be an 
unbiased estimate of the parameter. From property 1. you can see that T is an unbiased estimate of k. 
'If the sample size, n, is large relative to the number, N, of elements in the population, (e.g., 5% or 
more), v/fi must be multiplied by a finite population correction factor. V(N 
- n ) / ( N  - 1). 
For most sampling situations, this correction factor will be close to 1 and can he ignored. 
'+The variance of T is the smallcst among all unbiased estimators of p.Thus T is dccmed the 
MVUE (i.e., minimum variance, unbiased estimator) for p. 

SECTION 4.12 
T h e  C e n t r a l  Limit T h e o r e m  
245 " 
of n observations is selected from a population with a nor- 
. 
- 
heorem 4.2 (Central Limit Theor 
nsider a random sample of n observations selected from a population 
ny population) with mean p and standard deviation cr. Then, when n is 
fficiently large, the sampling distribution of F will be approximately a 
rmal distribution with mean p, = p and standard deviation u, = a/&. 
e larger the sample size, the better will be the normal approximation to 
sampling distribution of T.* 
Thus, for sufficiently large samples the sampling distribution of T is approx- 
imately normal. How large must the sample size n be so that the normal distribu- 
tion provides a good approximation for the sampling distribution of i? The 
answer depends on the shape of the distribution of the sampled population, as 
shown by Figure 4.45. Generally speaking, the greater the skewness of the sam- 
pled population distribution, the larger the sample size must be before the normal 
distribution is an adequate approximation for the sampling distribution of i. For 
most sampled populations, sample sizes of n 2 25 will suffice for the normal ap- 
proximation to be reasonable. We will use the normal approximation for the sam- 
pling distribution of i when the sample size is at least 25. 
population with mean equal to 80 and standard deviation equal to 5. It is known 
that the population is not extremely skewed. 
a. Sketch the relative frequency distributions for the population and for the 
sampling distribution of the sample mean, i. 
b. Find the probability that i will be larger than 82. 
S o I u t i 0 n 
a. We do not know the exact shape of the population relative frequency distri- 
bution, but we do know that it should be centered about p = 80, its spread 
should be measured by u = 5, and it is not highly skewed. One possibility is 
shown in Figure 4.46a. From the Central Limit Theorem, we know that the 
sampling distribution of i will be approximately normal since the sampled 
population distribution is not extremely skewed. We also know that the 
sampling distribution will have mean and standard deviation 
u 
p, = p = 80 
and 
a, = - 
- 5 
&-x=' 
The sampling distribution of 2 is shown in Figure 4.46b. 
*Moreover, because of the Central Limit Theorem, the sum of a random sample of n 
observations, Ex, will possess a sampling distribution that is approximately normal for large 
samples. This distribution will have a mean equal to np and a variance equal to na2. Proof of 
the Central Limit Theorem is beyond the scope of this book, but it can be found in many 
mathematical statistics texts. 

CHAPTER 4 
Random Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
FI GURE 4.45 
Sampling distributions of 2 for 
different populations and 
different sample sizes 
Sampling 
Sampling 
Sampling 
Original 
distribution of 
distribution of 
distribution of 
population 
i f o r n = 2  
i for n = 5 
i for n = 30 
70 
75 
p = 80 
85 
90 
77 
pi = 80 83 
a. Population relative frequency distribution 
b. Sampling distribution of 2 
A population relative frequency distribution and the sampling distribution for F 
b. The probability that T will exceed 82 is equal to the darker shaded area in 
Figure 4.47. To find this area, we need to find the z value corresponding to 
- 
x = 82. Recall that the standard normal random variable z is the difference 
between any normally distributed random variable and its mean, expressed 

- 
- 
X 
. - 
X 
lrea in 
ling to 
erence 
Iressed 
&
S ECT ION 4.12 
The Central Limit Theorem 
247" 
in units of its standard deviation. Since 5 is approximately a normally dis- 
tributed random variable with mean pi = p and cry = a / G ,  it follows that 
the standard normal z value corresponding to the sample mean, Y, is 
- 
(Normal random variable) - (Mean) 
x - px 
z = 
-- 
- 
Standard deviation 
Ux 
FIGURE 4.47 
The sampling distribution of i 
P(R > 82) 
Therefore, for i = 82, we have 
The area A in Figure 4.47 corresponding to z = 2 is given in the table of 
areas under the normal curve (see Table IV of Appendix B) as .4772. 
Therefore, the tail area corresponding to the probability that i exceeds 82 is 
~ - ~ ~ ~ " , w ~ , ~ ~ ~ " ~ > , , " > ~ ~ " s " m > ~ . ~  
w - - m - " " m - - , m - = s P P - - u b , " , " , , , . , %  
.,-= 
A manufa 
t the distribution of the lengths of 
life of its best battery has a mean of 54 months and a standard deviation of 6 months. 
Suppose a consumer group decides to check the claim by purchasing a sample of 50 
of these batteries and subjecting them to tests that determine battery life. 
a. Assuming that the manufacturer's claim is true, describe the sampling dis- 
tribution of the mean lifetime of a sample of 50 batteries. 
b. Assuming that the manufacturer's claim is true, what is the probability the 
consumer group's sample has a mean life of 52 or fewer months? 
S o 1 u t i o n 
a. Even though we have no information about the shape of the probability 
distribution of the lives of the batteries, we can use the Central Limit 
Theorem to deduce that the sampling distribution for a sample mean life- 
time of 50 batteries is approximately normally distributed. Furthermore, the 
mean of this sampling distribution is the same as the mean of the sampled 
population, which is p = 54 months according to the manufacturer's claim. 
Finally, the standard deviation of the sampling distribution is given by 
u 
6 - .85 month 
"=/;;=%- 
FIGURE 4.48 
Sampling distribution of F in Example 4.31 for 
n = 50 
F 

248 
CHAPTER 4 
R a n d o m  Variables a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Note that we used the claimed standard deviation of the sampled population, 
cr = 6 months. Thus, if we assume that the claim is true, the sampling distrib- 
ution for the mean life of the 50 batteries sampled is as shown in Figure 4.48. 
b. If the manufacturer's claim is true, the probability that the consumer 
group observes a mean battery life of 52 or fewer months for their sample 
of 50 batteries, P ( i  5 52), is equivalent to the darker shaded area in Fig- 
ure 4.48. Since the sampling distribution is approximately normal, we can 
find this area by computing the standard normal z value: 
where px, the mean of the sampling distribution of E, is equal to p, the mean 
of the lives of the sampled population, and a, is the standard deviation of the 
sampling distribution of i. 
Note that z is the familiar standardized distance 
(z-score) of Section 2.7 and, since 2 is approximately normally distributed,it 
will possess (approximately) the standard normal distribution of Section 5.3. 
The area A shown in Figure 4.48 between i = 52 and i = 54 (correspond- 
ing to z = -2.35 ) is found in Table IV of Appendix B to be .4906. There- 
fore, the area to the left of F = 52 is 
Thus, the probability the consumer group will observe a sample mean of 52 
or less is only .0094 if the manufacturer's claim is true. If the 50 tested bat- 
teries do exhibit a mean of 52 or fewer months, the consumer group will 
have strong evidence that the manufacturer's claim is untrue, because such 
an event is very unlikely to occur if the claim is true. (This is still another 
application of the rare-event approach to statistical inference.) 
We conclude this section with two final comments on the sampling distribu- 
tion of i. 
First, from the formula a, = a / f i ,  we see that the standard deviation 
of the sampling distribution of i gets smaller as the sample size n gets larger. For 
example, we computed cr, = .85 when n = 50 in Example 4.31. However, for 
n = 100 we obtain a, = a/& = 6/* 
= .60. This relationship will hold true 
for most of the sample statistics encountered in this text.That is:The standard devia- 
tion of the sampling distribution decreases as the sample size increases. Consequently, 
the larger the sample size, the more accurate the sample statistic (e.g., i) 
is in esti- 
mating a population parameter (e.g., p). We will use this result in Chapter 5 to help 
us determine the sample size needed to obtain a specified accuracy of estimation. 
Our second comment concerns the Central Limit Theorem. In addition to 
providing a very useful approximation for the sampling distribution of a sample 
mean, the Central Limit Theorem offers an explanation for the fact that many rel- 
ative frequency distributions of data possess mound-shaped distributions. Many of 
the measurements we take in business are really means or sums of a large number 
of small phenomena. For example, a company's sales for one year are the total of 
the many individual sales the company made during the year. Similarly, we can 
view the length of time a construction company takes to build a house as the 
total of the times taken to complete a multitude of distinct jobs, and we can regard 
the monthly demand for blood at a hospital as the total of the many individual pa- 
tients' needs. Whether or not the observations entering into these sums satisfy the 
assumptions basic to the Central Limit Theorem is open to question. However,it 
is a fact that many distributions of data in nature are mound-shaped and possess 
the appearance of normal distributions. 

t 
2 
t- 
11 
:h 
F 
u- 
In 
or 
or 
ue 
ia- 
tly, 
$ti- 
elp 
on. 
1 to 
pie 
rel- 
Y of 
ber 
11 of 
can 
the 
;ard 
I pa- 
r the 
er, it 
jSeSS 
S ECT ION 4.12 
T h e  C e n t r a l  L i m i t  T h e o r e m  
249 - 
Learning the Mechanics 
4.111 Suppose a random sample of n measurements is select- 
ed from a population with mean p = 100 and variance 
n2 = 100. For each of the following values of n, give 
the mean and standard deviation of the sampling dis- 
tribution of the sample mean i. 
a. n = 4 b. n = 25 c. n = 100 
d. n = 50 e. n = 500 f. n = 1,000 
4.112 Suppose a random sample of n = 25 measurements is 
selected from a population with mean p and standard 
deviation u. For each of the following values of p and 
u, 
give the values of pi and a,. 
a. p = 10, u = 3 b. p = 100, u = 25 
c. p = 20, n = 40 d. p = 10, u = 100 
4.113 Consider the probability distribution shown here. 
a. Find p, n2, and a. 
b. Find the sampling distribution of T for random sam- 
ples of n = 2 measurements from this distribution 
by listing all possible values of T, and find the prob- 
ability associated with cach. 
c. Use the results of part b to calculate p, and a,. Con- 
firm that p, = p and u, = u/& 
= u
/
~
.
 
4.114 A random sample of n = 64 observations is drawn 
from a population with a mean equal to 20 and stan- 
dard deviation equal to 16. 
a. Give the mean and standard deviation of the (re- 
peated) sampling distribution of 2. 
b. Describe the shape of the sampling distribution of 
- 
x. Does your answer depend on the sample size? 
c. Calculate the standard normal z-score correspond- 
ing to a value of i = 15.5. 
d. Calculate the standard normal z-score correspond- 
ing to i = 23. 
4.115 Refer to Exercise 4.114. Find the probability that 
a. i is less than 16 b. i is greater than 23 
c. i is greater than 25 
d. i 
falls between 16 and 22 e. i is less than 14 
Applying the Concepts 
4.116 The Amer~can Automobile Association (AAA) is a 
not-for-profit federation of 90 clubs that provides it 
yf2 
members with travel, financial, insurance, and auto- 
related services. In May 1999, A A A  advised its mem- 
bers that the average daily meal and lodging costs for a 
fam~ly of tour was $213 (Travel News, May 11, 1999). 
Assume the standard dev~ation of such cwts was $15 
and that the average daily cost reported by AAA is the 
population mean. Suppose 49 families of four were 
sclectcd and their travel expenses during June 1999 
werc monitored. 
a. Describe the sampling distr~bution of i ,  the average 
daily meal and lodging costs for the sample of fam- 
ilies. In particular, how is i distributed and what are 
the mean and variance of i'? 
Justify your answers. 
b. What is the probability that the average daily ex- 
penses for the sample of families was greater than 
$213'1 Greater than $217? Between $209 and $217? 
4.117 At the end of the twentieth century, workers were 
much less likely to remain with one employer for many 
years than their parents a generation before. (Georgia 
Trend, December 1999) D o  today's college students 
understand that the workplace they are about to enter 
is vastly different than the one their parents entered? 
To help answer this question, researchers at the Terry 
College of Business at the University of Georgia sam- 
pled 344 business students and asked them this ques- 
tion: Over the course of your lifetime, what is the 
maximum number of years you expect to work for any 
one employer'? The resulting sample had i = 19.1 
years and s = 6 years. Assume the sample of students 
was randomly selected from the 5,800 undergraduate 
students in the Tcrry College. 
a. Describe the sampling distribution of i. 
b. If the population mean were 18.5 years, what is 
P ( i  2 19.1 years)? 
c. If the population mean were 19.5 years, what is 
P ( i  2 19.1 years)? 
d. If P ( i  2 19.1) = .5, what is the population mean? 
e. If P ( i  2 19.1) = .2, is the population mean greater 
or less than 19.1 years? Justify your answer. 
4.118 The College Student Journal (Dec. 1992) investigated 
differences in traditional and nontraditional students, 
where nontraditional students are generally defined as 
those 25 years or older and who are working full or 
part-time. Based on the study results, we can assume 
that thc population mean and standard deviation for 
thc GPA of all nontraditional students is p = 3.5 and 
u = .5. Suppose that a random sample of n = 100 
nontraditional students is selected from the popula- 
tion of all nontraditional students. and the GPA of 
each student is determined. Thcn i ,  the sample mean, 
will be approximately normally distributed (because 
of the Central Limit Theorem). 
a. Calculate p, and ul. 
b. What is thc approximate probability that the non- 
traditional student sample has a mean GPA be- 
tween 3.40 and 3.60? 
c. What is the approximate probability that the sam- 
ple of 100 nontraditional students has a mean GPA 
that exceeds 3.62? 

250 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
d. How would the sampling distribution of T change if 
thc sample size n were doublcd from 100 to 200? 
How do your answers to parts b and c change when 
the sample size is doubled? 
4.119 University of Louisville researchers J. Usher, S. Alex- 
ander, and D. Duggins examined the process of fill- 
ing plastic pouches of dry blended biscuit mix 
(Quality Engineering, Vol. 91,1996). The current fill 
mean of the process is set at p = 406 grams and the 
process fill standard deviation is u = 10.1 grams. 
(According to the researchers, "The high level of 
variation is due to the fact that the product has poor 
flow properties and is, therefore, dil'ficult to fiil con- 
sistently from pouch to pouch.") Operators monitor 
the process by randomly sampling 36 pouches each 
day and measuring the amount of biscuit mix in 
each. Consider F, the main fill amount of the sample 
of 36 products. 
a. Describe the sampling distributidn of i. 
(Give the 
values of p, and u,, and the shape of the probabili- 
ty distriljution.) 
b. Find P(2 5 400.8). 
c. Suppose that on one particular day, the operators 
observe i = 400.8. One of the operators believes 
that this indicates that the true process fill mean p 
for that day is less than 406 grams. Another operator 
argues that p = 406 and the small value of i ob- 
served is due to random variation in the fill process. 
Which operator do you agree with? Why? 
4.120 The ocean quahog is a type of clam found in the 
coastal waters of New England and the mid-Atlantic 
states. Extensive beds of ocean quahogs along the New 
Jersey shore gave rise to the development of the 
largest U.S. shellfish harvesting program. A federal 
survey of offshore ocean quahog harvesting in New 
Jersey, conducted from 1980 to 1992, revealed an aver- 
age catch per unit effort (CPUE) of 89.34 clams. The 
CPUE standard deviation was 7.74 (Journal of 
Shellfish Research, June 1995). Let i represent the 
mean CPUE for a sample of 35 attempts to catch 
ocean quahogs off the New Jersey shore. 
a. Compute pi and u,. Intcrpret their values. 
b. Sketch the sampling distribution of F. 
c. Find P ( i  > 88). d. Find P ( i  < 87). 
4.121 Neuroscientists at the Massachusetts Institute of 
Technology (MIT) have been experimenting with 
melatonin-a hormone secreted by the pineal gland 
in the brain-as a sleep-inducing hormone. Since the 
hormone is naturally produced, it is nonaddictive. 
(Proceedings of the National Academy qf Sciences, 
Mar. 1994.) In the MIT study, young male volunteers 
were given various doses of melatonin or a placebo (a 
dummy medication containing no melatonin). Then 
they were placed in a dark room at midday and told to 
close their eyes for 30 minutes.The variable of interest 
was the time x (in minutes) elapsed before each vol- 
unteer fell asleep. 
a. With the placebo (i.e., no hormone) the researchers 
found that the mean time to fall asleep was 15 mln- 
utes. Assume that with the placebo treatment 
p = 15 and u = 5. Now, consider a random sample 
of 40 young males, each of whom is given a dosage 
of the sleep-inducing hormone, melaton~n. Find 
P(T < 6) if melatonin is not effective against in- 
somnia. 
b. The times (in minutes) to fall asleep for theae 
40 males are listed in the tablc* below. Use the data 
to make an inference about the true value of ~r. 
for 
those taking the melatonin. Does melatonin appear 
to be an effective drug against insomnia? 
I 
*These are simulated sleep times based on summary 
information prov~ded in the MIT study. 
I 
4.122 National Car Rental Systems, Inc., comm~ss~oned 
the 
United States Automobile Club (USAC) to conduct 
a survey of the general condition of the cars rented 
to the public by Hertz, Avis, National, and Budget 
Rent-a-Car.' USAC off~cials evaluate each compa- 
ny's cars using a demerit point system. Each car 
starts with a perfect score of 0 points and incurs 
demerit points for cach discrepancy noted by the 
inspectors. One measure of the overall cond~tion of a 
i 
company's cars is the mean of all scores received by 
the company, I.e., the company'sfleet mean score To 
I 
estimate the fleet mean score of each rental car com- 
pany, 10 major airports were randomly selected, and 
, 
10 cars from each company were randomly rented 
r 
for inspection from each airport by USAC offic~als; 
i.e., a sample of size n = 100 cars from each compa- 
ny's fleet was drawn and inspected. 
a. Describe the sampling distribution of i, the mean 
score of a sample of n = 100 rental cars. 
b. Interpret the mean of i in the context of this problem. 
c. Assume p = 30 and u = 60 for one rental car com- 
pany. For this company, find P(T 2 45). 
d. Refer to part c. The company claims that their true 
fleet mean score "couldn't possibly be as high as 
30." The sample mean score tabulated by USAC 
for this company was F = 45. Does this result tend 
to support or refute the claim? Explain. 
+Information by personal communication with Rajiv Tandon. 
Corporate Vice President and General Manager of thc Car 
Rental Division, National Car Rental Systems, Inc., Minneapolis. 
Minnesota. 

:he 
uct 
ted 
get 
pa- 
car 
urs 
the 
> f a  
3m- 
and 
~ t e d  
ials; 
Lean 
lem. 
:om- 
true 
;h as 
SAC 
tend 
lis, 
SECTION 4.12 
T h e  C e n t r a l  L i m i t  T h e o r e m  
251 - 
S T A T I S T I C S  I N 
IQ, Economic Mobility, and the Be 
I 
n their controversial book The Bell Curve (Free Press, 
1994), Professors Richard J. Herrnstein (a Harvard psy- 
chologist who died while the book was in production) and 
Charles Murray (a political scientist at MIT) explore, as the 
subtitle states, "intelligence and class structure in American 
life." The Bell Curve heavily employs statistical analyses in 
an attempt to support the authors' positions. Since the 
book's publication, many expert statisticians have raised 
doubts about the authors' statistical methods and the infer- 
ences drawn from them. (See, for example, "Wringing The 
Bell Curve: A cautionary tale about the relationships among 
race, genes, and IQ," Chance, Summer 1995.) In Chapter 
10's Statistics in Action, we explore a few of these problems. 
One of the many controversies sparked by the book is 
the authors' tenet that level of intelligence (or lack thereof) 
is a cause of a wide range of intractable social problems, in- 
cluding constrained economic mobility. "America has taken 
great pride in the mobility of generations," state Herrnstein 
and Murray, "but this mobility has its limits . . . .The son of 
a father whose earnings are in the bottom five percent of 
the [income] distribution has something like one chance in 
twenty (or less) of rising to the top fifth ol the income dis- 
tribution and almost a fifty-fifty chance of staying in the 
bottom fifth. He has less than one chance in four of rising 
above even the median income . . . . Most people at present 
are stuck near where their parents were on the income dis- 
tribution in part because [intelligence], which has become a 
major predictor of income, passes on sufficiently from one 
generation to the next to constrain economic mobility." 
The measure of intelligence chosen by the authors is the 
well known Intelligent Quotient (IQ). Numerous tests have 
been developed to measurc IQ; Herrnstein and Murray use 
the Armed Forces Qualification Test (AFQT), originally 
designed to measure the cognitive ability of military re- 
cruits. Psychologists traditionally treat IQ as a random vari- 
FI GURE 4.49 
The distribution of I Q  
able having a normal distribution with mean p = 100 and 
standard deviation u = 15. This distribution, or bell curve, is 
shown in Figure 4.49. 
In their book, Herrnstein and Murray refer to five cogni- 
tive classes of people defined by percentiles of the normal 
distribution. Class I ("very bright") consists of those with IQs 
abovc the 95th percentile; Class 11 ("bright") are those with 
IQs between the 75th and 95th percentiles; Class 111 ("nor- 
mal") includes IQs between the 25th and 75th percentiles; 
Class IV ("dull") are those with IQs between the 5th and 
25th percentiles; and Class V ("very dull") are IQs below the 
5th percentile. Tnese classes are also illustrated in Figure 4.49. 
F o c u s  
a. Assuming that the distribution of fb is accurately rep- 
resented by the bell curve in Figure 4.49, determine the 
proportion of people with IQs in each of the five cogni- 
tive classes defined by Herrnstein and Murray. 
b. Although the cognitive classes above are defined in 
terms of percentiles, the authors stress that IQ scores 
should be compared with z-scores, not percentiles. In 
other words, it is more informative to give the differ- 
ence in z-scores for two TQ scores than it is to give the 
difference in percentiles. To demonstrate this point, cal- 
culate the difference in z-scores for IQs at the 50th and 
55th percentiles. Do the same for IQs at the 94th and 
99th percentiles. What do you observe? 
c. Researchers have found that scores on many intelli- 
gence tests are decidedly nonnormal. Some distributions 
are skewed toward higher scores, others toward lower 
scores. How would the proportions in the five cognitive 
classes differ for an IQ distribution that is skewed right? 
Skewed left? 

252 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Key Terms 
Note: Starred (*) terms refer to the optional sections in this chapter. 
Bell curve 206 
Bell-shaped distribution 206 
Binomial experiment 181 
Binomial random variable 181 
Central Limit Theorem 245 
Continuous probability 
distribution 201 
Continuous random variable 170 
Countable 169 
Correction for continuity* 226 
Cumulative binomial probabilities 
Discrete random variable 170 
Expected value 174 
Exponential distribution* 231 
Frequency function 
201 
Normal distribution 206 
Normal probability plot 220 
Normal random variable 206 
Parameter 236 
Poisson random variable* 194 
187 
Probability density function 201 
Probability distribution 172 
Random variable 168 
Sample statistic 236 
Sampling distribution 238 
Standard error of the mean 244 
Standard normal distribution 208 
Uniform distribution* 202 
Waiting time dktribution* 231 
...........................................................................................................................................................................................................................................
Key Formulas 
Note: Starred (*)formulas refer to the optional sections in th~s 
chapter. 
Probability Distribution 
Random Variable 
or Density Function 
Mean 
Standard Deviation 
- 
.................................................................................................................................................................................................................................. 
General discrete, x 
P ( X )  
c XPW 
J c ( x  - P ) ~ P ( X )  
174.175 
all r 
Binomial, x 
( :) PxU n-x 
nP 
V'GG 
185 
Poisson, * x 
Axe-' 
- 
x! 
h 
fi 
195 
Uniform, * x 
1 
c + d  
d - c  
- 
( c s x s d )  
d - c' 
- 
2 
- 
fi 
203 
Normal, x 
1 
-e-(l/2)[(x-~)/(~12 
U V ' G  
P 
u 
207 
Standard Normal, z = - 1 
-(l/2)z2 
\/?;;e 
0 
1 
208 
Exponential, * x 
he-"Jx > 0 )  
1 - 
1 - 
h 
A 
232 
Sample Mean, 2 
Normal (for large n )  
P 
u/ V'i 
245 
................................................................................................................................................................................................................................................... 
(a + .5) - p 
Normal Approximation to Binomial* 
P(x % a) = P 
u 
] 
229 
Symbol 
Pronunciation 
Description 
....................................................................................................................................................................................................................... 
P ( X )  
Probability distribution of the random variable x 
S 
The outcome of a binomial trial denoted a "success" 
F 
The outcome of a binomial trial denoted a "failure" 
P 
The probability of success (S) in a binomial trial 
4 
The probability of failure (F) in a binomial trial, where q = 1 - p 
A 
lambda 
The mean (or expected) number of events for a Poisson random variable; 
parameter for an exponentla1 random variable 

S u p p l e m e n t a r y  Exercises 
253 
f (4 
fofx 
Probability density function for a continuous random variable x 
0 
theta 
Population parameter (general) 
P i  
mu of x-bar 
True mean of sampling distribution of x 
gx 
sigma of x-bar 
True standard deviation of sampling distribution of i 
Note: Starred (*) exercises refer to the optional sections in 
this chapter. 
Learning the Mechanics 
4.123 Which of the following describe discrete random vari- 
ables, and which describe continuous random variables? 
a. The number of damaged inventory items 
b. The average monthly sales revenue generated by a 
salesperson over the past year 
c. The number of square feet of warehouse space a 
company rents 
d. The length of time a firm must wait before its 
copying machine is fixed 
4.124 For each of the following examples, decide whether x is 
a binomial random variable and explain your decision: 
a. A manufacturer of computer chips randomly selects 
100 chips from each hour's production in order to 
estimate the proportion defective. Let x represent 
the number of defectives in the 100 sampled chips. 
b. Of five applicants for a job, two will be selected. Al- 
though all applicants appear to be equally qualified, 
only three have the ability to fulfill the expectations 
of the company. Suppose that the two selections are 
made at random from the five applicants, and let x 
be the number of qualified applicants selected. 
c. A software developer establishes a support hotline 
for customers to call in with questions regarding use 
of the software. Let x represent the number of calls 
received on the support hotline during a specified 
workday. 
d. Florida is one of a minority of states with no state 
income tax. A poll of 1,000 registered voters is con- 
ducted to detcrmine how many would favor a state 
income tax in light of the state's current fiscal con- 
dition. Let x be the number in the sample who 
would favor the tax. 
4.U5 Given that x is a binomial random variable, compute 
p(x) for each of the following cases: 
a. n = 7 , x =  3,p = .5 
b 9 n = 4 , x = 3 , p = . 8  
c. n = 15, x = 1, p = .l 
4.l26 Consider the discrete probability distribution shown 
here. 
a. Calculate p, u2, and u. 
b. What is P(X < 15)? 
c. Calculate p f 2u. 
d. What is the probability that x is in the interval 
p * 2u? 
4.127 Suppose x is a binomial random variable with n = 20 
and p = .7. 
a. Find P x = 14). 
b. Find P i x 5 12). 
c. Find P x > 12). 
d. Find P 9 5 x 5 18). 
e. Find P 1 8 < x < 18). 
f. Find p, u2, and a. 
g. What is the probability that x is in the interval 
p f 20 
*4.128 Suppose x is a Poisson random variable. Compute p(x) 
for each of the following cases: 
a. A  = 2,x = 3 
b. A =  1,x = 4 
c. A  = .5, x = 2 
"4.129 Assume that x is a random variable best described 
by a uniform distribution with c = 10 and d = 90. 
a. Find f(x). 
b. Find the mean and standard deviation of x. 
c. Graph the probability distribution for x and locate 
its mean and the interval p f 2u on the graph. 
d. Find P(x 5 60). e. Find P(x r 90). 
f. Find P(x 5 80). 
g. Find P(p - u 5 x 5 p + u). 
h. Find P(x > 75). 
4.130 The random variable x has a normal distribution with 
p = 75 and a = 10. Find the following probabilities: 
a. P(X 5 80) b. P(X 2 85) 
c. ~ ( 7 0  
5 x 5 75) d. P(X > 80) 
e. P(X = 78) f. P(X 5 110) 
"4.131 Assume that x is a binomial random variable with 
n = 100 and p = .5. Use the normal probability dis- 
tribution to approximate the following probabilities: 
a. P(X 5 48) b. ~ ( 5 0  
5 x 5 65) 
c. P(X 2 70) d. ~ ( 5 5  
5 x 5 58) 
e. P(X = 62) f. P(X 5 49 or x 2 72) 
4.132 The random variable x has a normal distribution with 
p = 40 and a2 = 36. Find a value of x, call it x,, such 
that 
a. P(x 2 x,) = .10 
b. P(p 5 x < x,) = .40 

254 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
c. P(X < x,) = .05 
d. P(x r x,) = .40 
e. P(x,, 5 x < p )  = .45 
"4.133 Assume that x has an exponential distribution with 
A = 3.0. Find 
a. P x 5 2) b. ~
(
x
 
> 3) c. P(X = 1) 
d. P i x 5 7) e. ~ ( 4  
5 x 5 12) 
4.134 A random sample of n = 68 observations is selected 
from a population with p  = 19.6 and a = 3.2. 
Approximate each of the following probabilities. 
a. P ( i  5 19.6) b. P ( i  5 19) 
c. P(T 2 20.1) d. P(19.2 5 T 5 20.6) 
4.135 A random sample of size n is to be drawn from a 
large population with mean 100 and standard devia- 
tion 10, and the sample mean T is to be calculated.To 
see the effect of different sample sizes on the stan- 
dard deviation of the sampling distribution of T, 
plot 
u / 6  against n for n = 1,5,10,20,30,40, and 50. 
- .  
Applying the Concepts 
4.136 A national study conducted by Geoffrey Alpert 
(University of South Carolina) found that 40% of all 
high-speed police chases end in accidents. As a result, 
many police departments have moved to restrict high- 
speed chases. One exception is the Tampa Police 
Department. After restricting chases for three years, 
management changed their policy and eased the restric- 
tions. Although overall crime dropped by 25%, high- 
speed chases increased from 10 in thc previom 5 months 
to 85 in the succeeding 5 months, w~th 29 of those result- 
ing in accidents (New York Times, Dec. 17, 1995). 
Consider a random sample of five hlgh-speed chases. 
a. Demonstrate that x, the number of chases result- 
ing in an accident, is an approximate binomial ran- 
dom variable. 
b. Using the Alpert statistics, what is the probability 
that the five h~gh-speed chases result in at least 
one accident? 
c. Use the Tampa data to estimate the probability of 
part b. 
d. Which probability, part b or part c, best describes 
high-speed chases in your state? Explain. 
*4.137 Millions of suburban commuters are finding railroads 
to be a convenient, time-saving, less stressful alterna- 
tive to the automobile. While generally perceived as a 
safe mode of transportation, the average number of 
deaths per week due to railroad accidents is a sur- 
prisingly high 20 (U.S. National Center for Health 
Statistics, Vltal Statistics of the United States, 1998). 
a. Construct arguments both for and against the use 
of the Poisson distribution to characterize the num- 
ber of deaths per week due to railroad accidents. 
b. For the remainder of this exercise, assume the 
Poisson distribution is an adequate approxima- 
tion for x, the number of deaths per week due to 
railroad accidents. Find E(x) and the standard 
deviation of x. 
c. Based strictly on your answers to part b, is it likely 
that only four or fewer deaths occur next week? 
Explain. 
d. Find P(x 5 4). Is this probability consistent with 
your answer to part c? Explain. 
4.138 A large number of preventable errors (e.g., overdos- 
es, botched operations, misdiagnoses) are being made 
by doctors and nurses in U.S. hospitals (New York 
Times, July 18,1995).A study of a major metropolitan 
hospital revealed that of every 100 medications pre- 
scribed or dispensed, one was in error; but, only one 
in 500 resulted in an error that caused significant 
problems for the patient. It is known that thc hospital 
prescribes and dispenses 60,000 medications per year. 
a. What is the expected number of errors per year at 
this hospital? The expected number of significant 
errors per year? 
b. Within what limits would you expect the number 
of significant errors per year to fall? 
c. What assumptions did you need to make in order 
to answer these questions? 
4.139 The tolerance l i m i ~  
for a particular quality characteristic 
(e.g., length, weight, or strength) of a product are the 
minimum and/or maximum values at which the product 
will operate properly. Tolerance limits are set by the 
engineering design function of the manufacturing oper- 
ation (Moss, Applying TQM to Product Design and 
Development, 1996). The tensile strength of a particular 
metal part can be characterized as being normally dis- 
tributed with a mean of 25 pounds and a standard devi- 
ation of 2 poundsThe upper and lower tolerance limits 
for the part are 30 pounds and 21 pounds respective1y.A 
part that falls within the tolerance limits results in a 
profit of $10.A part that falls below the lower tolerance 
limit costs the company $2; a part that falls above the 
upper tolerance limit costs the company $1. Find the 
company's expected profit per metal part produced. 
4.140 The distribution of the demand (in number of units 
per unit time) for a product can often be approximat- 
ed by a normal probability distribution. For example, 
a bakery has determined that the number of loaves of 
its white bread demanded daily has a normal distri- 
bution with mean 7,200 loaves and standard devia- 
tion 300 loaves. Based on cost considerations, the 
company has decided that its best strategy is to pro- 
duce a sufficient number of loaves so that it will fully 
supply demand on 94% of all days. 
a. How many loaves of bread should the company 
produce? 
b. Based on the production in part a, on what per- 
centage of days will the company be left with more 
than 500 loaves of unsold bread? 
4.141 The metropolitan airport commission is considering the 
establishment of limitations on noise pollution around 
a local airport. At the present time, the noise level per 
jet takeoff in one neighborhood near the airport is 

t 
d 
r 
i- 
i- 
:s 
4 
a 
Z 
ke 
ke 
ts 
~ t -  
le, 
of 
ri- 
la- 
he 
'0- 
1 1 ~  
nY 
er- 
)re 
the 
ind 
Per 
t is 
& 
approximately normally distributed with a mean of 
100 decibels and a standard deviation of 6 decibels. 
a. What is the probability that a randomly selected 
jet will generate a noise level greater than 108 deci- 
bels in this neighborhood? 
h. What is the probability that a randomly selected jet 
will generate a noise level of exactly 100 decibels? 
c. Suppose a regulation is passed that requires jet 
noise in this neighborhood to be lower than 
105 decibels 95% of the time. Assuming the stan- 
dard deviation of the noise distribution remains the 
same, how much will the mean level of noise have 
to be lowered to comply with the regulation? 
4.142 A tool-and-die machine shop produces extremely 
high-tolerance spindles. The spindles are 18-inch slen- 
der rods used in a variety of military equipment. A 
piece of equipment used in the manufacture of the 
spindles malfunctions on occasion and places a single 
gouge somewhere on the spindle. However, if the 
spindle can be cut so that it has 14 consecutive inches 
without a gouge, then the spindle can be salvaged for 
other purposes. Assuming that the location of the 
gouge along the spindle is random, what is the proba- 
bility that a defective spindle can be salvaged'? 
,1143 The length of time between arrivals at a hospital 
clinic and the length of clinical service time are two 
random variables that play important roles in design- 
ing a clinic and deciding how many physicians and 
nurses are needed for its operation. The probability 
distributions of both the length of time between 
arrivals and the length of service time are often 
approximately exponential. Suppose the mean time 
between arrivals for patients at a clinic is 4 minutes. 
a. What is the probability that a particular interar- 
rival time (the time between the arrival of two pa- 
tients) is less than 1 minute? 
b. What is the probability that the next four interar- 
rival times are all less than 1 minute? 
c. What is the probability that an interarrival time 
will exceed 10 minutes? 
$4.144 The net weight per package of a certain brand of corn 
chips is listed as 10 ounces. The weight actually deliv- 
ered to each package by an automated machine is a 
normal random variable with mean 10.5 ounces and 
standard deviation .2 ounce. Suppose 1,500 packages 
are chosen at random and the nct weights are ascer- 
tained. Let x be the number of the 1,500 selected pack- 
ages that contain at least 10 ounces of corn chips.Then 
x is a binomial random variable with n = 1,500 and 
p = probability that a randomly selected package 
contains at least 10 ounces. What is the approximate 
probability that they all contain at least 10 ounces of 
corn chips? What is the approximate probability that at 
least 90% of the packages contain 10 ounces or more? 
4.145 Refer to the Financial Management (Spring 1995) study 
of 49 companies that filed for a prepackaged bankrupt- 
S u p p l e m e n t a r y  E x e r c i s e s  
255 
cy, Exercise 2.24 (p. 49). The time in bankruptcy (mea- 
sured in months) for each company is repeated in the 
table on page 256. Determine whether the bankruptcy 
times are approximately normally distributed. 
4.146 In Lee County, Georgia, the distribution of weekly 
wages for workers in the construction industry in 
1997 was skewed to the right with mean equal to $473 
(Georgia Department of Labor, Labor Market 
Information, 1999). Assume the standard deviation 
of the distribution was $25. An economist plans to 
randomly sample 40 workers in Lee County and 
question them regarding their weekly wages, their 
age, and the length of their employment. 
a. Describe what is known about the distribution of 
x, the weekly wages of workers in the construction 
industry. 
b. Describe what is known about the distribution of 
y, the age of the construction workers. 
c. Describe the distributions of i and 7. 
d. Find P(T 2 $465). 
e. What additional information is needed to be able 
to calculate P(y 2 30)? 
4.147 One measure of elevator performance is cycle time. 
Elevator cycle time is the time between successive ele- 
vator starts, which includes the time when the car is 
moving and the time when it is standing at a floor. 
Researchers have found that simulation is necessary to 
determine the average cycle timc of a system of eleva- 
tors in complex traffic situations. Simulation (Oct. 1993) 
published a study on the use of a microcomputer-based 
simulator for elevators. The simulator produced an 
average cycle time p of 26 seconds when traffic intensi- 
ty was set at 50 persons every five minutes. Consider a 
sample of 200 simulated elevator runs and let i repre- 
sent the mean cycle time of this sample. 
a. What do you know about the distribution of x, the 
time between successive elevator starts? (Give the 
value of the mean and standard deviation of x and 
the shape of the distribution, if possible.) 
b. What do you know about the distribution of i ?  
(Give the value of the mean and standard deviation 
of 2 and the shape of the distribution, if possible.) 
c Assume u, 
the standard deviation of cycle time x, is 20 
seconds Use this information to calculate P ( i  > 26.8). 
d. Repeat part c but assume u = 10. 
4.148 Refer to the Simulation (Oct. 1993) study of elevator 
cycle times, Exercise 4.147. Cycle time is related to the 
distance (measured by number of floors) the elevator 
covers on a particular run, called running distance. The 
simulated distribution of running distance, x, during a 
down-peak period in elevator traffic intensity is shown 
in the figure on p. 256. The distribution has mean 
p = 5.5 floors and standard deviation u = 7 floors. 
Consider a random sample of 80 simulated elevator 
runs during a down-peak in traffic intensity. Of interest 
is the sample mean running distance, i. 

256 
CHAPTER 4 
R a n d o m  V a r i a b l e s  a n d  P r o b a b i l i t y  D i s t r i b u t i o n s  
Company 
Pre-Filing 
Votes 
.............................. 
Time in 
Bankruptcy 
(months) 
. 
AM International 
Anglo Energy 
Arizona Biltmore* 
Astrex 
Barry's Jewelers 
Calton 
Cencor 
Charter Medical* 
Cherokee* 
Circle Express 
Cook Inlet Comm. 
Crystal Oil 
Divi Hotels 
Edgell Comm.* 
Endevco 
Gaylord Container 
Great Amer. Comm.* 
Hadson 
In-Store Advertising 
JPS Textiles* 
Kendall* 
Kinder-Care 
Kroy* 
Ladish* 
LaSalle Energy* 
None 
Prepack 
Prepack 
None 
None 
None 
Joint 
Prepack 
Joint 
Prepack 
Prepack 
None 
None 
Prepack 
Prepack 
Joint 
Prepack 
Prepack 
Prepack 
Prepack 
Prepack 
None 
Prepack 
Joint 
Prepack 
....................................................................................................................... 
Time in 
Pre-Filing 
Bankruptcy 
Company 
Votes 
(months) 
.............................................................................................................. 
LIVE Entertainment 
Joint 
1.4 
Mayflower Group* 
Prepack 
1.4 
Memorex Telex* 
Prepack 
1.1 
Munsingwear 
None 
2.9 
Nat'l Environmental 
Joint 
5.2 
Petrolane Gas 
Prepack 
1.2 
Price Communications 
None 
2.4 
Republic Health* 
Joint 
4.5 
Resorts Int'l* 
None 
7.8 
Restaurant Enterprises* 
Prepack 
1.5 
Rymer Foods 
Joint 
2.1 
SCI TV* 
Prepack 
2.1 
Southland* 
Joint 
3.9 
Specialty Equipment* 
None 
2.6 
SPI Holdings* 
Joint 
1.4 
Sprouse-Reitz 
Prepack 
1.4 
Sunshine Metals 
Joint 
5.4 
TIE/Communications 
None 
2.4 
Trump Plaza 
Prepack 
1.7 
Trump Taj Mahal 
Prepack 
1.4 
Trump's Castle 
Prepack 
2.7 
USG 
Prepack 
1.2 
Vyquest 
Prepack 
4.1 
West Point Acq.* 
Prepack 
2.9 
Source: Betker, Brian L. "An empirical examination of prepackaged bankruptcy." Ftnanclal Management, Vol. 24, No. 1, Spring 1995, p. 6 (Table 2). 
*Leveraged buyout. 
a. Find py and a,. 
c. During a down-peak in traffic intensity, is it likely to 
b. Is the shape of the distribution of x similar to the 
observe a sample mean running distance of i = 5.3 
figure? If not, sketch the distribution. 
floors? Explain. 
Numbe~ 
of runs 
RUNNING DISTANCE DISTRIBUTION 
0 
5 
10 
15 
20 
25 
30 
35 
40 
Running distance (Number of floors) 
Source: Siikonen, M. L. "Elevator traffic simulation." Simulation, Vol. 61, No. 4, Oct. 1993, p. 266 
(Figure 8). Copyright O 1993 by Simulation Councils, Inc. Reprinted by permission. 

T h e  F u r n i t u r e  Fire C a s e  
257 - 
Real-World Case The Furniture Fire Case 
(A Case Covering Chapters 3-4) 
A 
wholesale furniture retailer stores in-stock items at a 
large warehouse located in Tampa, Florida. In early 
1992, a fire destroyed the warehouse and all the fur- 
nlture In it. After determ~nmg the fire was an accident, the 
retaller sought to recover costs by submitting a claim to its 
Insurance company. 
As is typical in a fire insurance policy of this type, the 
furniture retailer must provide the insurance company with 
an est~mate of "lost" prof~t for the de~troyed items. Retall- 
ers calculate profit margin in percentage form using the 
Gross Profit Factor (GPF). By definition, the GPF for a 
single sold Item is the ratio of the prot~t to the item's selling 
prlce measured as a percentage, i.e., 
Item GPF = (ProfitISales price) X 100% 
Of interest to both the retailer and the insurance company 
is the average GPF for all of the items in the warehouse. 
Since these furniture pieces were all destroyed, their even- 
tual selling prices and profit values are obviously unknown. 
Consequently, the average GPF for all the warehouse items 
is unknown. 
One way to estimate the mean GPF of the destroyed 
items is to use the mean GPF of similar, recently sold items. 
The retailer sold 3,005 furniture items in 1991 (the year prior 
to the fire) and kept paper invoices on all sales. Rather than 
calculate the mean GPF for all 3,005 items (the data were 
not computerized), the retailer sampled a total of 253 of the 
invoices and computed the mean CPF for these items. 
The 253 items were obtained by first selecting a sample of 
134 items and then augmenting this sample with a second 
' sample of 119 items. The mean GPFs for the two subsamples 
were calculated to be 50.6% and 51.0%, respectively, yielding 
an overall average GPF of 50.8%. This average GPF can be 
applied to the costs of the furniture items destroyed in the fire 
to obtain an estimate of the "lost" profit. 
According to experienced claims adjusters at the insur- 
ance company, the GPF for sale items of thc type destroyed 
in the fire rarely exceeds 48%. Consequently, the estimate 
of 50.8% appeared to be unusually high. (A 1 % increase in 
GPF for items of this type equates to, approximately, an 
I additional $16,000 in profit.) When the insurance company 
questioned the retailer on this issue, the retailer respond- 
ed."Our estimate was based on selecting two independent, 
random samples from the population of 3,005 invoices in 
1991. Since the samdes were selected randomlv and the 
total sample size is large, the mean GPF estimate of 50.8% 
is valid." 
A dispute arose between the furniture retailer and the 
insurance company, and a lawsuit was filed. In one portion 
of the suit, the insurance company accused the retailer of 
fraudulently representing their sampling methodology. 
Rather than selecting the samples randomly, the retailer 
was accused of selecting an unusual number of "high profit" 
items from the population in order to increase the avcrage 
GPF of the overall sample. 
To support their claim of fraud, the insurance company 
hired a CPA firm to independently assess the retailer's 1991 
Gross Profit Factor. Through the discovery process, the 
CPA firm legally obtained the paper invoices for the entire 
population of 3,005 items sold and input the information 
into a computer.The selling price, profit, profit margin, and 
month sold for these 3,005 furniture items are available on 
the data disk that accompanies this text, as described below. 
Your objective in this case is to use these data to deter- 
mine the likelihood of fraud. Is it likely that a random sam- 
ple of 253 items selected from the population of 3,005 items 
would yield a mean GPF of at least 50.8%? Or, is it likely 
that two independent. random samples of size 134 and 119 
will yield mean GPFs of at least 50.6% and 51.0%, respec- 
tively? (These were the questions posed to a statistician re- 
tained by the CPA firm.) Use the ideas of probability and 
sampling distributions to guide your analysis. 
Prepare a professional document that presents the re- 
sults of your analysis and gives your opinion regarding 
rraud. Be sure to describe the assumptions and methodolo- 
gy used to arrive at your findings. 
Variable 
Column(s) 
Type 
Description 
MONTH 
17-19 
QL 
Month in which item was 
sold in 1991 
INVOICE 
25-29 
QN 
Invoice number 
SALES 
35-42 
QN 
Sales price of item 
in dollars 
PROFIT 
47-54 
QN 
Profit amount of item 
in dollars 
MARGIN 
59-64 
QN 
Profit margin of item = 
(ProfitISales) X 100% 

I N F E R E N C E S  B A S E D  O N  A 
S I N G L E  S A M P L E :  
E s t i m a t i o n  w i t h  C o n f i d e n c e  I n t e r v a l s  
C O N T E N T S  
............................................................... 
5.1 
Large-Sample Confidence Interval for a Population Mean 
5.2 
Small-Sample Confidence Interval for a Population Mean 
5.3 
Large-Sample Confidence Interval for a Population Proportion 
5.4 
Determining the Sample Size 
S T A T I S T I . C S  
I
N
 A ' C T I O N  
................................................................................................................................................. 
Scallops, Sampling, and the Law 
I 
, 
W h e r e  W e ' v e  B e e n  
1 
W 
e've learned that populations are character- 
ized by numerical descriptive measures (called 
parameters) and that decisions about their values are 
based on sample statistics computed from sample 
data. Since statistics vary in a random manner from 
sample to sample, inferences based on them will be 
subject to uncertainty. This property is reflected in 
the sampling (probability) distribution of a statistic. 
U 
W h e r e  W e ' r e  G o i n g  
I 
n this chapter, we'll put all the preceding material 
into practice; that is, we'll estimate population 
means and proportions based on a single sample se- 
lected from the population of interest. Most impor- 
tantly, we use the sampling distribution of a sample 
statistic to assess the reliability of an estimate. 

260 
CHAPTER 
5 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
The estimation of the mean gas mileage for a new car model, the estimation of the 
expected life of a computer monitor, and the estimation of the mean yearly sales 
for companies in the steel industry are problems with a common element. In each 
case, we're interested in estimating the mean of a population of quantitative mea- 
surements. This important problem constitutes the primary topic of this chapter. 
You'll see that different techniques are used for estimating a mean, depend- 
ing on whether a sample contains a large or small number of measurements. Nev- 
ertheless, our objectives remain the same: We want to use the sample information 
to estimate the mean and to assess the reliability of the estimate. 
First, we consider a method of estimating a population mean using a large 
random sample (Section 5.1) and a small random sample (Section 5.2). Then, we 
consider estimation of population proportions (Section 5.3). Finally, we see how to 
determine the sample sizes necessary for reliable estimates based on random 
sampling (Section 5.4). 
LARGE-SAMPLE CONFIDENCE INTERVAL 
FOR A POPULATION MEAN 
We illustrate the large-sample method of estimating a population mean with an ex- 
ample. Suppose a large bank wants to estimate the average amount of money 
owed by its delinquent debtors-i.e., 
debtors who are more than two months be- 
hind in payment. To accomplish this objective, the bank plans to randomly sample 
100 of its delinquent accounts and to use the sample mean, x, of the amounts 
overdue to estimate p, the mean for all delinquent accounts. The sample mean i 
represents apoint estimator of the population mean p. How can we assess the ac- 
curacy of this point estimator? 
A point estimator of a population parameter is a rule or formula that 
tells us how to use the sample data to calculate a single number that can be 
used as an estimate of the population parameter. 
According to the Central Limit Theorem, the sampling distribution of the 
sample mean is approximately normal for large samples, as shown in Figure 5.1. 
Let us calculate the interval 
Sampling distribution of i 
That is, we form an interval 4 standard deviations wide-from 
2 standard devia- 
tions below the sample mean to 2 standard deviations above the mean. Prior to 
drawing the sumple, what are the chances that this interval will enclose p, the 

260 
CHAPTER 
5 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
I 
The estimation of the mean gas mileage for a new car model, the estimation of the 
expected life of a computer monitor, and the estimation of the mean yearly sales 
for companies in the steel industry are problems with a common element. In each 
case, we're interested in estimating the mean of a population of quantitative mea- 
surements. This important problem constitutes the primary topic of this chapter. 
You'll see that different techniques are used for estimating a mean, depend- 
ing on whether a sample contains a large or small number of measurements. Nev- 
ertheless, our objectives remain the same: We want to use the sample information 
to estimate the mean and to assess the reliability of the estimate. 
First, we consider a method of estimating a population mean using a large 
random sample (Section 5.1) and a small random sample (Section 5.2). Then, we 
consider estimation of population proportions (Section 5.3). Finally, we see how to 
determine the sample sizes necessary for reliable estimates based on random 
sampling (Section 5.4). 
LARGE-SAMPLE CONFIDENCE INTERVAL 
FOR A POPULATION MEAN 
We illustrate the large-sample method of estimating a population mean with an ex- 
ample. Suppose a large bank wants to estimate the average amount of money 
owed by its delinquent debtors-i.e., 
debtors who are more than two months be- 
hind in payment. To accomplish this objective, the bank plans to randomly sample 
100 of its delinquent accounts and to use the sample mean, 2, of the amounts 
overdue to estimate p, the mean for all delinquent accounts. The sample mean i 
represents a point estimutor of the population mean p. How can we assess the ac- 
curacy of this point estimator? 
DEFINITION 5.1. 
A point estimator of a population parameter is a rule or formula that 
tells us how to use the sample data to calculate a single number that can be 
used as an estimate of the population parameter. 
According to the Central Limit Theorem, the sampling distribution of the 
sample mean is approximately normal for large samples, as shown in Figure 5.1. 
Let us calculate the interval 
FIGURE 5.1 
Sampling distribution of T 
i 
Approximately Y i  
That is, we form an interval 4 standard deviations wide-from 
2 standard devia- I 
tions below the sample mean to 2 standard deviations above the mean. Prior to 
drawing the sample, what are the chances that this interval will enclose p, the 

SECTION 5.1 
Large-Sample C o n f i d e n c e  Interval f o r  a Population Mean 
261 
I 
population mean? 
To answer this question, refer to Figure 5.1. If the 100 measurements yield a 
value of i that falls between the two lines on either side of p-i.e., 
within 2 stan- 
dard deviations of p-then 
the interval i + 2a, will contain p; if F falls outside 
these boundaries, the interval ? f 2u, will not contain p. Since the area under the 
normal curve (the sampling distribution of ?) between these boundaries is about 
.95 (more precisely, from Table IV in Appendix B the area is .9544), we know that 
the interval T * 2cr, will contain p with a probability approximately equal to .95. 
For instance, consider the overdue amounts for 100 delinquent accounts 
shown in Table 5.1. A SAS printout of summary statistics for the sample of 100 over- 
due amounts is shown in Figure 5.2. From the printout, we find ? = $233.28 and 
s = $90.34. To achieve our objective, we must construct the interval 
TABLE 
5.1 
Overdue Amounts (in Dollars) for 100 Delinquent Accounts 
I Analysis Variable : AMOUNT 
I 
N O b s  
N 
Minimum 
Maximum 
Mean 
Std Dev I 
FIGURE 5.2 
SAS summary statistics for the overdue amounts of 100 delinquent accounts 
But now we face a problem.You can see that without knowing the standard devi- 
ation cr of the original population-that 
is, the standard deviation of the overdue 
amounts of all delinquent accounts-we 
cannot calculate this interval. However, 
since we have a large sample (n = 100 measurements), we can approximate the 
interval by using the sample standard deviation s to approximate a. Thus, 
That is, we estimate the mean amount of delinquency for all accounts to fall with- 
in the interval $215.21 to $251.35. 
Can we be sure that p, the true mean, is in the interval (215.21,251.35)? We 
cannot be certain, but we can be reasonably confident that it is. This confidence is 
derived from the knowledge that if we were to draw repeated random samples of 
100 measurements from this population and form the interval F & 2a2 each time, 
approximately 95% of the intervals would contain p. We have no way of knowing 

v 
262 
CHAPTER 
5 
I n f e r e n c e s  Based on a S i n g l e  S a m p l e  
Interval 
1 
2 
3 
5 
6 
7 
8 
9 
10 
FIGURE 5.3 
Confidence intervals for p: 10 
samples 
(without looking at all the delinquent accounts) whether our sample interval is one 
of the 95% that contains p or one of the 5% that does not, but the odds certainly 
1 
favor its containing p. Consequently, the interval $215.21 to $251.35 provides a re- 
liable estimate of the mean delinquency per account. 
The formula that tells us how to calculate an interval estimate based on 
sample data is called an interval estimator, or confidence interval. The probability. 
.95, that measures the confidence we can place in the interval estimate is called a 
confidence coefficient. The percentage, 95%, is called the confidence level for the 
interval estimate. It is not usually possible to assess precisely the reliability of 
point estimators because they are single points rather than intervals. So, because 
we prefer to use estimators for which a measure of reliability can be calculated, we 
will generally use interval estimators. 
DEFINITION 5.2 
I 
An interval estimator (or confidence interval) is a formula that tells us how to 
use sample data to calculate an interval that estimates a population parameter. 
? 
I 
DEFINITION 5.3 
The confidence coefficient is the probability that a randomly selected confi- 
dence interval encloses the population parameter-that 
is, the relative fre- 
quency with which similarly constructed intervals enclose the population 
parameter when the estimator is used repeatedly a very large number of times. 
The confidence level is the confidence coefficient expressed as a percentage. 
Now we have seen how an interval can be used to estimate a population 
mean. When we use an interval estimator, we can usually calculate the probabilit~ 
that the estimationprocess will result in an interval that contains the true value of 
the population mean. That is, the probability that the interval contains the param- 
eter in repeated usage is usually known. Figure 5.3 shows what happens when 10 
different samples are drawn from a population, and a confidence interval for pis 
calculated from each. The location of p is indicated by the vertical line in the figure. 
Ten confidence intervals, each based on one of 10 samples, are shown as horizontal 
line segments. Note that the confidence intervals move from sample to sample- 
sometimes containing p and other times missing p. If our confidence level r~ 95% 
then in the long run, 95% of our confidence intervals will contain p and 5% will not. 
1 
Suppose you wish to choose a confidence coefficient other than .95. Notice 
in Figure 5.1 that the confidence coefficient .95 is equal to the total area under the 
sampling distribution, less .05 of the area, which is divided equally between the 
two tails. Using this idea, we can construct a confidence interval with any desired 
confidence coefficient by increasing or decreasing the area (call it a) assigned to 
the tails of the sampling distribution (see Figure 5.4 ). For example, if we place 
area a/2 in each tail and if z,,~ is the z value such that the area a/2 lies to its right, 
then the confidence interval with confidence coefficient (1 - a )  is 
FIGURE 5.4 
Locating z,,, on the standard normal 
curve 
z 
-z d 2  
0 
Z d 2  
C- 

SECTION 5.1 
L a r g e - S a m p l e  C o n f i d e n c e  I n t e r v a l  f o r  a P o p u l a t i o n  M e a n  
263 
To illustrate, for a confidence coefficient of .90 we have (1 - a) = .90, 
a = .lo, and a/2 = .05; z , ~ ,  is the z value that locates area .05 in the upper tail of 
the sampling distribution. Recall that Table IV in Appendix B gives the areas be- 
tween the mean and a specified z value. Since the total area to the right of the 
mean is .5, we find that z,, 
will be the z value corresponding to an area of 
.5 - .05 = .45 to the right of the mean (see Figure 5.5).This z value is z , ~ ,  = 1.645. 
FIGURE 5.5 
The z value (zo5) corresponding to an area equal to 
.05 in the upper tail of the z-distribution A 
z 
I 
z.05 =1.645 
Confidence coefficients used in practice usually range from .90 to .99. The 
most commonly used confidence coefficients with corresponding values of a and 
za12 are shown in Table 5.2. 
TABLE 
5.2 
Commonly Used Values of z,,, 
Confidence Level 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
lOO(1 - a) 
a 
4 2  
zm/z 
ight (see Figure 5.4) an 
ion of the sampled po 
nd n is the sample size. 
most always the case) and n is large (s 
pproximately equal to 
the sample standard deviation. 
Assumptions: None, since the Central Limit Theorem guarantees that the 
- 
nofxis 
al. 

264 
CHAPTER 5 
I n f e r e n c e s  Based o n  a S i n g l e  Sample 
year. To accomplish this, the records of 225 flights are randomly selected, andthe 
number of unoccupied seats is noted for each of the sampled flights. The sample 
mean and standard deviation are 
- 
x = 11.6 seats 
s = 4.1 seats 
Estimate p, the mean number of unoccupied seats per flight during the past year, 
using a 90% confidence interval. 
S o I u t i o n The general form of the 90% confidence interval for a population mean is 
For the 225 records sampled, we have 
Since we do not know the value of a (the standard deviation of the number of un- 
occupied seats per flight for all flights of the year), we use our best approximation- 
the sample standard deviation s. Then the 90% confidence interval is, 
approximately, 
or from 11.15 to 12.05.That is, at the 90% confidence level, we estimate the mean 
number of unoccupied seats per flight to be between 11.15 and 12.05 during the 
sampled year. This result is verified on the MINITAB printout of the analysis 
shown in Figure 5.6. 
FIGURE 5.6 
MINITAB printout for the 
confidence intervals in 
Example 5.1 
N 
MEAN STDEV SE MEAN 
90.0 PERCENT C.I. 
NoSeats 
225 
11.6 
4.1 
0.273 
( 
11.15, 
12.05) 
We stress that the confidence level for this example, 9096, refers to the pro- 
j 
cedure used. If we were to apply this procedure repeatedly to different samples. 
approximately 90% of the intervals would contain p. We do not know whether 
this particular interval (1 1.15,12.05) is one of the 90% that contain p or one of the 
I 
10% that do not-but 
the odds are that it does. 
I 
The interpretation of confidence intervals for a population mean is summa- 
rized in the box on page 265. 
Sometimes, the estimation procedure yields a confidence interval that is too 
wide for our purposes. In this case, we will want to reduce the width of the interval 
to obtain a more precise estimate of p. One way to accomplish this is to decrease the 
confidence coefficient, 1 - a. For example, reconsider the problem of estimating 
the mean amount owed, p, for all delinquent accounts. Recall that for a sample of 
100 accounts, T = $233.28 and s = $90.34. A 90% confidence interval for p.-is 
C- 

SECTION 5.1 
L a r g e - S a m p l e  C o n f i d e n c e  I n t e r v a l  f o r  a P o p u l a t i o n  M e a n  
265 " 
Interpretation of a Confidence Interval for a Population Mean 
hen we form a 100(1 - a)% confidence interval for p, we usually express 
ur confidence in the interval with a statement such as, "We can be 
00(1 - a)% confident that p lies between the lower and upper bounds of 
confidence interval," where for a particular application, we substitute the 
ropriate numerical values for the confidence and for the lower and upper 
ounds. The statement reflects our confidence in the estimation process rather 
in the particular interval that is calculated from the sample data. We know 
repeated application of the same procedure will result in different lower 
upper bounds on the interval. Furthermore, we know that 100(1 - a)% 
he resulting intervals will contain p. There is (usually) no way to deter- 
ine whether any particular interval is one of those that contain p, or one 
at does not. However, unlike point estimators, confidence intervals have 
me measure of reliability, the confidence coefficient, associated with them. 
that reason they are generally preferred to point estimators. 
or ($21 8.42, $248.14). You can see that this interval is narrower than the previously 
calculated 95% confidence interval, ($215.21, $251.35). Unfortunately, we also 
have "less confidence" in the 90% confidence interval. An alternative method 
used to decrease the width of an interval without sacrificing "confidence" is to in- 
crease the sample size n. We demonstrate this method in Section 5.4. 
Learning the Mechanics 
5.1 Find z,,~ for each of the following: 
a . a = . l O  b. a =  .Ol 
c. a  = .05 d. a = .20 
52 What is the confidence level of each of the following 
confidence intervals for p? 
5.3 A random sample of n measurements was selected from 
a population with unknown mean p and standard devi- 
atlon u. Calculate a 95% confidence interval for p for 
each ot the following situations: 
a. n = 75.i = 28, s2 = 12 
b. n = 200, i = 102, s2 = 22 
c. n = 100,i = 15, s = .3 
d. n = 100, T = 4.05, s = .83 
e. Is the assumption that the underlying population of 
measurements is normally distributed necessary to 
ensure the validity of the confidence intervals in 
parts a-d? Explain. 
5.4 A random sample of 90 observations produced a mean 
- 
x = 25.9 and a standard deviation s = 2.7. 
a. Find a 95% confidence interval for the population 
mean p. 
b. Find a 90% confidence interval for p. 
c. Find a 99% confidence interval for p. 
d. What happens to the width of a confidence interval 
as the value of the confidence coefficient is increased 
while thc sample size is held fixed? 
e. Would your confidence intervals of parts a-c be valid 
if the distribution of the original population was not 
normal? Explain. 
5.5 The mean and standard deviation of a random sample of 
n measurements are equal to 33.9 and 3.3, respectively. 
a. Find a 95% confidence interval for p if n = 100. 
b. Find a 95% confidence interval for p if n = 400. 

v 
P
I 
266 
CHAPTER 
5 
I n f e r e n c e s  B a s e d  o n  a  S i n g l e  S a m p l e  
c. Find the widths of the confidence intervals found in 
parts a and b. What is the effect on the width of a 
confidence interval of quadrupling the sample size 
while holding the confidence coefficient fixeds? 
Applying the Concepts 
5.6 The U.S. has 1.4 million tax-exempt organizations. These 
include most schools and universities, foundations, and 
social services organizations such as the Red Cross, the 
Salvation Army, the YMCA, and the American Cancer 
Society. Donations to these organizations not only go to 
the stated charitable purpose, but are used to cover 
fundraising expenses and overhead. For a sample of 
30 charities, the table below lists their charitable com- 
mitment, the percentage of their expenses that go 
toward the stated charitable purpose. 
a. Give a point estimate for the mean charitable com- 
mitment of tax-exempt organi~ations. 
b. Construct a 98% confidence interval for the true 
mean charitable commitment of tax-exempt organi- 
zations. Interpret the result. 
c. Why is the confidence interval of part b a better esti- 
mator of the mean charitable commitment than the 
point estimator of part a? Explain. 
5.7 The Journal o f  the American Medical Association 
(Apr. 21, 1993) reported on the results of a National 
Health Interview Survey designed to determine the 
prevalence of smoking among U.S. adults. More than 
40,000 adults responded to questions such as "Have you 
smoked at least 100 cigarettes in your lifetime?" and 
"Do you smoke cigarettes now?" Current smokers 
(more than 11,000 adults in the survey) were also asked: 
"On the average, how many cigarettes do you now 
smoke a day?" The results yielded a mean of 20.0 ciga- 
rettes per day with an associated 95% confidence inter- 
val of (1 9.7,20.3). 
a. Carefully describe the population from which the 
sample was drawn. 
b. Interpret the 95% confidence interval. 
c. State any assumptions about the target populatio~i ol 
current cigarette smokers that must be satisfied for 
- 
inferences derived from the interval to be valid. 
I 
d. A tobacco industry researcher claims that the mean 
; 
number of cigarettes smoked per day by regular ciga- 
rette smokers is less than 15. Comment on this claim. 
5.8 Research indicates that bicycle helmets save lives. A 
study reported in Public Health Reports (May-June 
, 
1992) was intended to identify ways of encouraging i 
CHARITY.DAT 
.................... 
................................................................................................ - 
Organization 
Charitable Commitment 
......................................................................................................................................... 
American Cancer Society 
62 % 
American National Red Cross 
91 
Big Brothers Big Sisters of America 
77 
Boy Scouts of America National Council 
81 
Boys & Girls Clubs of America 
81 
CARE 
91 
Covenant House 
15 
Disabled American Veterans 
65 
pucks Unlimited 
78 
Feed the Children 
90 
Girl Scouts of the USA 
83 
Goodwill Industries International 
89 
Habitat for Humanity International 
81 
Mayo Foundation 
26 
Mothers Against Drunk Drivers 
71 
Multiple Sclerosis Association of America 
56 
Museum of Modern Art 
79 
Nature Conservancy 
77 
Paralyzed Veterans of America 
50 
Planned Parenthood Federation 
81 
Salvation Army 
84 
Shriners Hospital for Children 
95 
Smithsonian Institution 
87 
Special Olympics 
72 
Trust for Public Land 
88 
United Jewish AppeallFederation-NY 
75 
United States Olympic Committee 
78 
United Way of New York City 
85 
WGBH Educational Foundation 
81 
YMCA of the USA 
80 
Source: "Look Before You Give," Forhe,, Dec. 27,1999, pp 206-216. 

SECTION 5.1 
L a r g e - S a m p l e  C o n f i d e n c e  I n t e r v a l  f o r  a P o p u l a t i o n  M e a n  
267 
helmet use in children. One of the variables measured 
was the children's perception of the risk involved in 
bicycling. A four-point scale was used, with scores rang- 
ing from 1 (no risk) to 4 (very high risk). A sample of 
797 children in grades 4-6 yielded the following results 
on the perception of risk variable: T = 3.39, s = 30. 
a. Calculate a 90% confidence interval for the average 
perception of risk for all students in grades 4-6. 
What assumptions did you make to ensure the valid- 
ity of the confidence interval? 
b. If the population mean perception of risk exceeds 
2.50, the researchers will conclude that students in 
these grades exhibit an awareness of the risk in- 
volved with bicycling. Interpret the confidence inter- 
val constructed in part a in this context. 
5.9 The relationship between an employee's participation in 
the performance appraisal process and subsequent subor- 
dinate reactions toward the appraisal was investigated in 
the Journal ofApplied Psychology (Aug. 1998). In Chapter 
9 we will discuss a quantitative measure of the relationship 
between two variables, called the coefficient of correla- 
tion r. The researchers obtained r for a sample of 34 stud- 
ies that examined the relationship between appraisal 
participation and a subordinate's satisfaction with the 
appraisaLThese correlations are listed in the table. (Values 
of r near + 1 reflect a strong positive relationship between 
the variables.) A MINITAB printout showing a 95% con- 
fidence interval for the mean of the data is provided 
below. Locate the 95% confidence interval on the printout 
and interpret it in the words of the problem. 
0 CORRM.DAT 
S O  .58 .71 .46 
.63 .66 .31 .35 .51 .06 .35 .19 
.40 .63 .43 .16 -.08 
.51 .59 .43 .30 .69 .25 .20 
.39 .20 .51 .68 
.74 .65 .34 .45 .31 .27 
Source: Cawley, B. D., Keeping, L. M., and Levy, P. E. "Participation in 
the performance appraisal process and employee reactions: A meta- 
analytic review of field investigations." Journal ofApplied Psychology, 
Vol. 83, No. 4, Aug. 1998, pp. 632-633 (Appendix). 
5.10 Named for the section of the 1978 Internal Revenue 
Code that authorized them, 401(k) plans permit 
employees to shift part of their before-tax salaries into 
investments such as mutual funds. Employers typically 
match 50% of the employee's contribution up to about 
6% of salary (Fortune, Dcc. 28, 1992). One company, 
concerned with what it believed was a low employee 
participation rate in its 401(k) plan, sampled 30 other 
companies with similar plans and asked for their 401(k) 
participation rates. The following rates (in percentages) 
were obtained: 
Descriptive statistics for the data are given in the SPSS 
printout at the bottom of the page. 
a. Use the information on the SPSS printout to con- 
struct a 95% confidence interval for the mean par- 
ticipation rate for all companies that have 401(k) 
plans. 
b. Interpret the interval in the context of this problem. 
c. What assumption is necessary to ensure the validity 
of this confidence interval? 
d. If the company that conducted the sample has a 71% 
participation rate, can it safely conclude that its rate 
is below the population mean rate for all companies 
with 401 (k) plans? Explain. 
e. If in the data set the 60% had been 80%, how would 
the center and width of the confidence interval you 
constructed in part a be affected? 
5.11 The 1967 Age Discrimination in Employment Act 
(ADEA) made it illegal to discriminate against work- 
ers 40 years of age and older. Opponents of the law 
argue that there are sound economic reasons why em- 
ployers would not want to hire and train workers who 
are very close to retirement. They also argue that peo- 
ple's abilities tend to deteriorate with age. In fact, 
Forbes (Dec. 13,1999) reported that 25-year-olds did 
significantly better than 60-year-olds on the Wechsler 
Adult Intelligence Scale, the most popular IQ test. 
The data on p. 268 are raw test scores (i.e., not the fa- 
miliar normalized IQ scores) for a sample of 36 25- 
year-olds and 36 60-year-olds. 
MINITAB Output for Exercise 5.9 
Variable 
N 
Mean 
StDev 
SE Mean 
95.0 % CI 
corr 
34 
0.4224 
0.1998 
0.0343 
( 0.3526, 0.4921) 
SPSS Output for Exercise 5.1 0 
Number of Valid Observations (Listwise) = 
30.00 
Variable 
Mean 
Std Dev 
Minimum 
Maximum 
N Label 
PARTRATE 
79.73 
5.96 
60.00 
90.00 
30 

268 
CHAPTERS I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
I 
STATISTIX Output for Exercise 5.1 1 
/ DESCRIPTIVE STATISTICS 
I 
VARIABLE 
N 
L O 9 5 % C I  
MEAN 
UP 95% CI 
SD 
RAWIQ60 
3 6 
41.009 
45.306 
49.602 
12.698 
a. Estimate the mean raw test score for all 25-year-olds 
using a 95% confidence interval. Give a practical in- 
terpretation of the confidence interval. 
b. What assumption(s) must hold for the method of es- 
timation used in part a to bc appropriate'? 
c. The STATISTIX printout above provides an analysis 
of the saniplc raw test scores ol 60-year-olds. Find a 
95% confidence interval for the mean raw score of 
all 60-year-olds and interpret your result. [Note: In 
Chaptcr 9 we will present a method for directly com- 
paring the means ol 25-year-olds and 60-year-olds.] 
IQ25.DAT 
, 
IQ60 DAT 
I 
................................................... . B 
........... : 
.............................. 
; 
25-Year-Olds 
60-Year-01ds 
..................................................... 
..................................................... 
54 
61 
80 
92 
41 
63 
42 
54 
38 22 
58 
37 
59 
68 
66 
76 
82 
80 
60 
49 
51 60 
45 
42 
82 
47 
81 77 
88 
94 
73 
28 
65 
65 
60 
34 
49 
86 
55 
82 45 
51 
34 
33 
40 
28 
36 
60 
70 
72 
63 
50 
52 
67 
45 
61 47 
30 
45 45 
75 
60 
58 49 
63 
68 
45 
37 
27 
40 
37 
58 
Source: Adapted from "The Case for Age Discrimination," Forbes, 
Dec. 13.1999, p. 13. 
SMALL-SAMPLE CONFIDENCE INTERVAL FOR A 
POPULATION MEAN 
Federal legislation requires pharmaceutical companies to perform extensive tests 
on new drugs before they can be marketed. Initially, a new drug is tested on ani- 
mals. If the drug is deemed safe after this first phase of testing, the pharmaceut~cal 
company is then permitted to begin human testing on a limited basis. During this 
second phase, inferences must be made about the safety of the drug based on in- 
f 
formation in very small samples. 
Suppose a pharmaceutical company must estimate the average increase in 
blood pressure of patients who take a certain new drug. Assume that only six pa- 
tients (randomly selected from the population of all patients) can be used in the 
initial phase of human testing. The use of a small sample in making an inference 
about p presents two immediate problems when we attempt to use the standard 
normal z as a test statistic. 
Problem 1. The shape of the sampling distribution of the sample mean Y (and 
the z statistic) now dcpends on the shape of the population that is sampled. We 
can no longer assume that the sampling distribution of i is approximately normal. 
becavse the Central Limit Theorem ensures normality only for samples that are 
sufficiently large. 
Solution to Problem 1. According to Theorem 4.1, the sampling distribution 
of i (and z )  is exactly normal even for relatively small samples if the sampled pop- 
ulation is normal. It is approximately normal if the sampled population is approx- 
imately normal. 
Problem 2. The population standard deviation a is almost always unknown. I 
Although it is still true that a, = cr/Vk, the sample standard deviation s may pro- 
vide a poor approximation for a when the sample size is small. 
Solution to Problem 2. Instead of usiug the standard normal statistic 

In 
P- 
IX- 
m. 
ro- 
4 
SECTION 5.2 
S m a l l - S a m p l e  C o n f i d e n c e  Interval f o r  a P o p u l a t i o n  Mean 
269 
which requires knowledge of or a good approximation to u, 
we define and use the 
i*UI 
statistic 
in which the sample standard deviation, s, replaces the population standard devi- 
ation, F. 
The distribution of the t statistic in repeated sampling was discovered by 
W. S. Gosset, a chemist in the Guinness brewery in Ireland, who published his 
discovery in 1908 under the pen name of Student. The main result of Gosset's 
work is that if we are sampling from a normal distribution, the t statistic has a 
sampling distribution very much like that of the z statistic: mound-shaped, sym- 
metric, with mean 0. The primary difference between the sampling distributions 
of t and z is that the t statistic is more variable than the z, which follows intu- 
itively when you realize that t contains two random quantities (i 
and s), whereas 
z contains only one (x). 
The actual amount of variability in the sampling distribution of t depends on 
the sample size n. A convenient way of expressing this dependence is to say that 
the t statistic has (n - 1) degrees of freedom (do. Recall that the quantity (n - 1) 
is the divisor that appears in the formula for s2. This number plays a key role in 
the sampling distribution of s2 and appears in discussions of other statistics in later 
chapters. In particular, the smaller the number of degrees of freedom associated 
with the t statistic, the more variable will be its sampling distribution. 
In Figure 5.7 we show both the sampling distribution of z and the sampling 
distribution of a t statistic with 4 df. You can see that the increased variability of 
the t statistic means that the t value, t,, that locates an area a in the upper tail of 
the t-distribution is larger than the corresponding value z,. For any given value of 
a, the t value t, increases as the number of degrees of freedom (df) decreases. Val- 
ues of t that will be used in forming small-sample confidence intervals of p are 
given in Table VI of Appendix B. A partial reproduction of this table is shown in 
Table 5.3. 
FIGURE 5.7 
Normal z-distribution 
Standard normal (z) 
distribution and t-distribution 
with 4 df 
0 
Note that t, values are listed for degrees of freedom from 1 to 29, where a 
refers to the tail area under the t-distribution to the right oft,. For example, if we 
want the t value with an area of .025 to its right and 4 df, we look in the table 
under the column t,,,, for the entry in the row corresponding to 4 df. This entry is 
t.,, 
= 2.776, as shown in Figure 5.8. The corresponding standard normal z-score is 
z,~,, = 1.96. 

5 
Inferences Based on a Single Sample 
TABLE 
5.3 Reproduction of Part of Table VI in Appendix B 
i 
i 
Degrees of Freedom 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
14 
1.345 
1.761 
2.145 
2.624 
2.977 
3.787 
4.140 
15 
1.341 
1.753 
2.131 
2.602 
2.947 
3.733 
4.073 
m 
1.282 
1.645 
1.960 
2.326 
2.576 
3.090 
3.291 
ormal z-distribution 
The t,,,, value in a t-distribution 
with 4 df and the 
corresponding zo,, value 
Note that the last row of Table VI, where df = ca (infinity), contains the stan- 
1 
dard normal z values.This follows from the fact that as the sample size n grows very 
large, s becomes closer to cr and thus t becomes closer in distribution to z. In fact, 
1 
when df = 29, there is little difference between corresponding tabulated values of 
1 
z and t. Thus, researchers often choose the arbitrary cutoff of n = 30 (df = 29) to 
f 
distinguish between the large-sample and small-sample inferential techniques. 
/ 
Returning to the example of testing a new drug, suppose that the six test pa- 
tients have blood pressure increases of l.7,3.O, 8.3.4.2.7. and 2.1 points. How can we j 
use this information to construct a 95% confidence interval for p, the mean increase 
in blood pressure associated with the new drug for all patients in the population? 
First, we know that we are dealing with a sample too small to assume thal 1 
the sample mean T is approximately normally distributed by the Central Lim~t 
Theorem. That is, we do not get the normal distribution of i "automatically" from 1 
6 
the Central Limit Theorem when the sample size is small. Instead, the measured 
variable, in this case the increase in blood pressure, must be normally distributed 
in order for the distribution of T to be normal. 

". 
SECTION 5.2 
Small-Sample C o n f i d e n c e  Interval for a Population Mean 
271 
Second, unless we are fortunate enough to know the population standard 
deviation a, which in this case represents the standard deviation of all the pa- 
tients' increases in blood pressure when they take the new drug, we cannot use the 
standard normal z statistic to form our confidence interval for p. Instead, we 
must use the t-distribution, with (n - 1) degrees of freedom. 
In this case, n - 1 = 5 df, and the t value is found in Table 5.3 to be 
t,,,, = 2.571 with 5 df. Recall that the large-sample confidence interval would 
have been of the form 
where 95% is the desired confidence level. To form the interval for a small sample 
from a normal distribution, we simply substitute t for z and s for a in the preceding 
formula: 
A MINITAB printout showing descriptive statistics for the six blood pres- 
sure increases is displayed in Figure 5.9. Note that F = 2.283 and s = .950. Sub- 
stituting these numerical values into the confidence interval formula, we get 
or 1.286 to 3.280 points. Note that this interval agrees (except for rounding) with 
the confidence interval generated by MINITAB in Figure 5.9. 
We interpret the interval as follows: We can be 95% confident that the mean 
increase in blood pressure associated with taking this new drug is between 1.286 
and 3.28 points. As with our large-sample interval estimates, our confidence is in 
the process, not in this particular interval. We know that if we were to repeatedly 
use this estimation procedure, 95% of the confidence intervals produced would 
contain the true mean p, assuming that the probability distribution of changes in 
blood pressure from which our sample was selected is normal. The latter assump- 
tion is necessary for the small-sample interval to be valid. 
What price did we pay for having to utilize a small sample to make the infer- 
ence? First, we had to assume the underlying population is normally distributed, and 
if the assumption is invalid, our interval might also be invalid." Second, we had to 
form the interval using a t value of 2.571 rather than a z value of 1.96, resulting in a 
wider interval to achieve the same 95% level of confidence. If the interval from 
1.286 to 3.28 is too wide to be of use, then we know how to remedy the situation: in- 
crease the number of patients sampled to decrease the interval width (on average). 
The procedure for forming a small-sample confidence interval is summa- 
rized in the next box. 
F I G U R E  5.9 
MINITABanalysisofsixblood 
pressure increases 
*By invahd, we mean that the probability that the procedure will yield an interval that contains y 
is not equal to (1 - a) Generally, if the underlying population is approximately normal, then the 
conf~dence coefficient will approximate the probabdity that a randomly selected interval contains p. 
-C- 
N  
MEAN 
STDEV 
SEMEAN 
9 5 . 0 P E R C E N T C . I .  
B P I n c r  
6 
2.283 
0 . 9 5 0  
0.388 
( 
1.287, 
3.280) 

272 
CHAPTERS I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
where tu,2 is based on ( n - 1 ) degrees of freedom 
Assumptions: A random sample is selected fr 
ulation with a relative 
I 
determine whether the item is defective destroys the item) in order to measure 
some particular characteristic of the product. The cost of destructive sampling 
often dictates small samples. For example, suppose a manufacturer of printers for 
personal computers wishes to estimate the mean number of characters printed 
before the printhead fails. Suppose the printer manufacturer tests n = 15 
& .  
randomly selected printheads and records the number of characters printed until 
failure for each. These 15 measurements (in millions of characters) are listed in 
1 
Table 5.4, followed by an EXCEL summary statistics printout in Figure 5.10. 
j 
TABLE 
5.4 
Number of Characters (in Millions) 
1 
for n = 15 Printhead Tests 
1 
a. Form a 99% confidence interval for the mean number of characters printed 
before the printhead fails. Interpret the result. 
b. What assumption is required for the interval, part a, to be valid? Is it rea- 
sonably satisfied? 
FIGURE 5.10 
I Mode 
I 
#N/A 1 
Number 
Standard Error 
0.049875 
I Ranue 
1 
0.7 1 
f 
Median 
1.25 1 
Standard Deviation 
Sample Variance 
Kurtosis 
Skewness 
EXCEL summary statistics 
printout for data in Table 5.4 
0.193164 
0 .O373l2 
0.063636 
-0.49126 
Minimum 
Maximum 
Sum 
'The procedure given in the box assumes that the population standard deviation a is unknown, 
which is almost always the case. If a is known, we can form the small-sample confidence interval 
just as we would a large-sample confidence interval using a standard normal z value instead oft. 
However, we must still assume that the underlying population is approximately normal. 
Mean 
0.85 
1.55 
18.58 
Count 
1.238667 
15 
Confidence Leve1(95.000%) I 
0.097753 

# 
SECTION 5.2 
S m a l l - S a m p l e  C o n f i d e n c e  I n t e r v a l  f o r  a P o p u l a t i o n  M e a n  
273 
S 0 I u t i o n 
a. For this small sample (n = 15), we use the t statistic to form the confidence 
interval. We use a confidence coefficient of .99 and n - 1 = 14 degrees of 
freedom to find t,,, in Table VI: 
ta/2 = 
= 2.977 
[Note: The small <ample forces us to extend the interval almost 3 standard 
deviations (of 2) on each side of the sample mean in order to form the 99% 
confidence interval.] From the EXCEL printout, Figure 5.10, we find 
- 
x = 1.239 and s = ,193. Substituting these values into the confidence inter- 
val formula, we obtain: 
Thus, the manufacturer can be 99% confident that the printhead has a mean 
life of between 1.091 and 1.387 million characters. If the manufacturer were 
to advertise that the mean life of its printheads is (at least) 1 million charac- 
ters, the interval would support such a claim. Our confidence is derived 
from the fact that 99% of the intervals formed in repeated applications of 
this procedure would contain p. 
b. Since n is small, we must assume that the number of characters printed 
before printhead failure is a random variable from a normal distribution. 
That is, we assume that the population from which the sample of 15 mea- 
surements is selected is distributed normally. One way to check this assump- 
tion is to graph the distribution of data in Table 5.4. If the sample data are 
approximately normal, then the population from which the sample is select- 
ed is very likely to be normal. A MINITAB stem-and-leaf plot for the 
sample data is displayed in Figure 5.1 1. The distribution is mound-shaped 
and nearly symmetric. Therefore, the assumption of normality appears to be 
reasonably satisfied. 
FIGURE 5.11 
MINITAB stem-and-leaf display of 
data in Table 5.4 
Stem-and-leaf of NUMBER 
N = 15 
Leaf Unit = 0.010 
We have emphasized throughout this section that an assumption that the 
population is approximately normally distributed is necessary for making small- 
sample inferences about p when using the t statistic. Although many phenome- 
na do have approximately normal distributions, it is also true that many random 

CHAPTER 
5 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
phenomena have distributions that are not normal or even mound-shaped. Em- 
pirical evidence acquired over the years has shown that the t-distribution is 
rather insensitive to moderate departures from normality. That is, use of the t 
statistic when sampling from mound-shaped populations generally produces 
credible results; however, for cases in which the distribution is distinctly non- 
normal, we must either take a large sample or use a nonparametric method. (A 
nonparametric method for making inferences from a single sample is presented 
in optional Section 6.6.) 
Confidence Interval for a Population Mean 
U S I N G  THE T I - 8 3  GRAPHIN'G C A L C U L A T O R  
Start from the home screen. 
Step '1 Enter the data into the list 
Press STAT 
Press ENTER 
Enter each piece of data (remember to presv "ENTER after each entry) 
Step 2. Access the Statistical Tests Menu 
Press STAT 
Arrow sight to "TESTS" . 
Arrow down to ''8 : TInterval . . ." 
Press ENTER 
Step 3 Choose "Data" or "StW' 
"Stats" 1s when you are enterlng the 
Press ENTER 
mean, std. dev., sample size yourself. 
Set 
List :L1 
"Llst" 1s where you put your data "Freq" 
C-Level : 1 - a 
1s how many tmes you entered each 
A~~~~ down to -calculate" 
p~ece of data ( ~ t  
can be a hst) "C-Level" 
w~ll be given In the problem 
Press ENTER 
Freq 1
Step 4 View Display 
The confidence interval will be displayed as well as the mean, std. dev., and 
the sample size. 
Example Consider example 5.2 (p. 272): "Printhead Test." 
Compute a 99% confidence interval for the .mean using the' 15 pieces of 
data given: 
Step 1 Enter the data into List1 
Press STAT 
' 
Press ENTER 
Enter each plcce of data. 
Step 2 Press 
STAT 
Arrow right to "TESTS" 
Arrow down to "8 : TInterval . . ." 
(you should be looking at this screen) 

SECTION 5.2 
S m a l l - S a m p l e  C o n f i d e n c e  I n t e r v a l  f o r  a P o p u l a t i o n  M e a n  
275 
Step 3 
Press ENTER 
Highlight "Data" then press ENTER (you will see this screen) 
tats 
Match the settings on this screen then arrow down, highlight "~alculate," 
and press ENTER (you will see this screen) 
I 
Step 4 As you can see from the screen our 99% confidence interval is (1.0902, 
1.3871). You will also notice it giQes the mean, std. dev., and the sample me. 
Step 5 Return to the home screen 
Press CLEAR ENTER 
Learning the Mechanics 
5.12 Suppose you have selected a random sample of n = 5 
measurements from a normal distribution. Compare the 
standard normal z values with the corresponding t 
values if you were forming the following confidence 
intervals. 
a. 80% confidence interval 
b. 90% confidence interval 
c. 95% confidence interval 
d. 98% confidence interval 
e. 99% confidence interval 
f. Use the table values you obtained in parts a-e to 
sketch the 2- and t-distributions. What are the simi- 
larities and differences? 
5.13 Let t,, be a particular value of t. Use Table VI of 
Appendix B to find t,, values such that the following 
statements are true. 
a. P(-t,, < t < to) = .95 where df = 10 
b. P(t 5 -to or t 2 t,) = .05 where df = 10 
c. P(t 5 to) = .05 where df = 10 
d. P(t 5 -t,, or t 2 t,) = .10 where df = 20 
e. P(t 5 -to or t 2 t,,) = .O1 where df = 5 
5.14 The following random sample was selected from a 
normal distribution: 4,6,3,5,9,3. 
a. Construct a 90% confidence interval for the popula- 
tion mean p. 
b. Construct a 95% confidence interval for the popula- 
tion mean y. 

276 
CHAPTER 
5 
I n f e r e n c e s  Based o n  a Single Sample 
+ 
c. Construct a 99% confidence interval for the popula- 
tion mean p. 
d. Assume that the sample mean 2 and sample standard 
deviation s remain exactly the same as those you just 
calculated but that they are based on a sample of 
n = 25 observations rather than n = 6 observations. 
Repeat parts a-c. What is the cffect of increasing the 
sample size on the width of the confidence intervals? 
5.15 The following sample of 16 measurements was select- 
ed from a population that is approximately normally 
distributed: 
a. Construct an 80% confidence interval for the popu- 
lation mean. 
b. Construct a 95% confidence interval for the popula- 
tion mean and compare the width of this interval 
with that of part a. 
c. Carefully interpret each of the confidence inter- 
vals and explain why the 80% confidence interval 
is narrower. 
Applying the Concepts 
5.16 Health insurcrs and the federal government are both 
putting pressure on hospitals to shorten the average 
length of stay (LOS) of t k i r  patients. In 1996, the aver- 
age LOS for men in the United Statcs was 5.7 days and 
the average for women was 4.6 days (St~~tisticalAh.stmct 
of the United States: 1998). A random sample of 20 hos- 
pitals in one state had a mean LOS for women in 2000 
of 3.8 days and a standard deviation of 1.2 days. 
a. Use a 90% confidence interval to estimate the popu- 
lation mean LOS for women for the state's hospitals 
in 2000. 
b. Interpret the interval in terms of this application. 
c. What is meant by the phrase "90% confidence 
interval"? 
5.17 Periodically, the Hillsborough County (Florida) Water 
Department tests the drinking water of homeowners 
for contaminants such as lead and copper.The lead and 
copper levels in water specimens collected in 1998 for a 
sample of 10 residents of the Crystal Lakes Manors sub- 
division are shown in the next colun~n. 
a. Construct a 99% confidence interval for the mean 
lead level in water specimens from Crystal Lake 
Manors. 
b. Construct a 99% confidence interval for the mean 
copper level in water specimens from Crystal Lake 
Manors. 
c. Interpret the intervals, parts a and b, in the words of 
the problem. 
d. Discuss the meaning of the phrase, "99% confident." 
Lead ( pg/L) 
Copper (mg/L) 
Source: Hillsborough County Water 
Department Environmental 
Laboratory,Tampa, Florida. 
5.18 Deloitte & Touche rank the 500 fastest growing tech- 
nology companics in the United States based on per- 
centage growth over a five-year period. Their rankings 
are called the Technology Fast 500. A random sample of 
12 companies from the 1999 Technology Fast 500 and 
their growth rates are shown in the table (page 277) 
followed by a MINITAB analysis of the data. 
a. Find a 95% confidence interval for the true mean 
five-year revenue growth rate for the 1999 Technolo- 
gy Fast 500. Interpret the result. 
b. In order to cstimatc the mean described in part a with 
a small-sample confidence interval, what characteristic 
must the population possess? 
c. Explain why the required population characteristics 
may not hold in this case. 
5.19 Accidental spillage and misguided disposal of petrole- 
um wastes have resulted in extensive contamination of 
soils across the country. A common hazardous com- 
pound found in the contaminated soil is benzo(a)pyrene 
[B(a)p]. An experiment was conducted to determine 
the effectiveness of a method designed to remove B(a)p 
from soil (Journal o f  Hazardous Materials, Junc 1995). 
Three soil specimens contaminated with a known 
amount of B(a)p were treated with a toxin that inhibits 
microbial growth. After 95 days of incubation, the per- 
centage of B(a)p removed from each soil specimen was 
measured.The experiment produced the following sum- 
mary statistics:i = 49.3 and s = 1.5. 
a. Use a 99% confidence interval to estimate the mean 
percentage of B(a)p removed from a soil specimen 
in which the toxin was used. 
b. Interpret the interval in terms of this application. 
c. What assumption is necessary to ensure the validity 
of this confidence interval? 
5.20 It is customary practice in the United States to base 
roadway design on the 30th highest hourly volume in a 
year.Thus, all roadway facilities are expected to operatc 

SECTION 5.2 
S m a l l - S a m p l e  C o n f i d e n c e  I n t e r v a l  f o r  a P o p u l a t i o n  M e a n  
277 
^ 
Rank 
Company 
1994-1 999 Revenue Growth Rate 
Netscape Communications 
Primary Network 
WebTrends 
CTX 
ARIS 
Iomega 
Medarex 
World Access 
Force 3 
Theragenics 
Ascent Solutions 
3 Com 
Source: Forbes ASAF: Nov. 29,1999, pp. 97-111. 
MINITAB Output for Exercise 5.1 8 
Variable 
N 
Mean 
StDev 
SE Mean 
95.0% CI 
grwthrate 
12 
7298 
18157 
5241 
( 
-4238, 
18834) 
Stem-and-leaf of grwthrat N = 
12 
Leaf Unit = 1000 
at acceptable levels of service for all but 29 hours of the 
year. The Florida Department of Transportation 
(DOT), however, has shifted from the 30th highest hour 
to the 100th highest hour as the basis for level-of-service 
determinators. Florida Atlantic University researcher 
Reid Ewing investigated whether this shift was war- 
ranted in the Journal ofSTAR Research (July 1994).The 
table on page 276 gives the traffic counts at the 30th 
highest hour and the 100th highest hour of a recent year 
for 20 randomly selected DOT permanent count sta- 
tions. MINITAB stem-and-leaf plots for the two vari- 
ables are provided on p. 278 as well as summary statistics 
and 95% ~onfidence interval printouts. 
a. Describe the population from which the sample data 
is selected. 
h. Does the sample appear to be representative of the 
population'? Explain. 
c. Locate and interpret the 95% confidence interval for 
the mean traffic count at the 30th highest hour. 
d. What assumption is necessary for the confidence in- 
terval to be valid? Does it appear to be satisfied? 
Explain. 
e. Repeat parts c and d for the 100th highest hour. 
5.21 Private and public colleges and universities rely on 
money contributed by individuals, corporations, and 
foundations for both salaries and operating expenses. 
Much of this money is put into a fund called an endow- 
ment, and the college spends only the interest earned by 
the fund. A random sample of eight college endowments 
drawn from the list of endowments in the Chronicle of 
Higher Education Almanac (Sept. 2, 1996) yielded the 
following endowments (in millions of dollars). 
Estimate the mean endowment for this population of 
colleges and universities using a 95% confidence inter- 
val. List any assumptions you make. 
5.22 In the late 1990s, the hot market for IPOs-initial public 
offerings of stock-created 
billions of dollars of new 
wealth for owners, managers, and employees of compa- 
nies that were previously privately owned. Nevertheless, 

278 
CHAPTER 5 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
Station 
Type of Route 
30th Highest Hour 
100th Highest Hour 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . , . . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
small city 
recreational 
small city 
rural 
urban 
urban 
rural 
rural 
urban 
rural 
rural 
urban 
rural 
small city 
small city 
urban 
rural 
small city 
recreational 
recreational 
Source: Ewing, R. "Roadway levels of service in an era of growth 
management." Journal of STAR Research, Vol. 3, July 1994, p. 103 (Table 2). 
Stem-and-leaf of Hour30 
N = 20 
Leaf Unit = 100 
1 
0 2  
3 
0 58 
6 
1 044 
9 
1 899 
(6) 
2 011122 
5 
'2 
5 
3 344 
2 
3 
2 
4 
2 
4 59 
Stem-and-leaf of HourlOO N = 20 
Leaf Unit = 100 
1 
0 2  
4 
0 589 
6 
1 33 
10 
1 7779 
10 
2 00001 
5 
2 
5 
3 134 
2 
3 
2 
4 4  
1 
4 8  
N 
MEAN 
STDEV 
Hour30 
20 2205.95 
1223.81 
Hour100 
20 2095.60 
1203.12 
SE MEAN 
95.0 PERCENT C.I. 
273.65 
( 1633.05, 2778.85) 
269.02 
( 1532.39, 2658.81) 

SECTION 5.3 
L a r g e - S a m p l e  C o n f i d e n c e  I n t e r v a l  for a P o p u l a t i o n  P r o p o r t i o n  
279 " 
hundreds of large and thousands of small companies 
remain privately owned. The operating incomes (earn- 
ings before interest, taxes, and depreciation) of a 
random sample of 15 firms from Forbes 500 Biggest 
Private Companies list is given in the table to the right. 
a. Describe the population from which the random 
sample was drawn. 
b. Use a 98% confidence interval to estimate the mean 
operating income of the population of companies in 
question. 
c. Interpret your confidence interval in the context of 
the problem. 
d. What characteristic must the population possess to 
ensure the appropriateness of the estimation proce- 
dure used in part b? 
5.23 The table at the lower right lists the number of full- 
time employees at each of 22 office furniture dealers 
serving Tampa, Florida, and its surrounding communi- 
ties. Summary statistics for the data are provided in the 
SAS printout below. 
a. Construct a 99% confidence interval for the true 
mean number of full-time employees at office furni- 
ture dealers in Tampa. 
b. Interpret the interval, part a. 
c. Comment on the assumption required for the inter- 
val to be valid. 
d. The 22 dealers in the sample were the top-ranked 
furniture dealers in Tampa based on sales volume in 
1995. How does this fact impact the validity of the 
confidence interval? Explain. 
SAS Output for Exercise 5.23 
BIGCOM.DAT 
................................................................................................................ 
Operating Income 
Company 
(in millions) 
Pacific Coast Building Products 
$52 
Chef Amenca 
72 
Brookshire Grocery 
i 
45 
Penske Truck Leasing 
700 
E & J Gallo Winery 
175 
LDI 
28 
Asplundh Tree Expert 
165 
TY 
750 
American Foods Group 
11 
Hobby Lobby Creative Centers 
73 
Weitz 
14 
Science Applications International 
487 
Findlay Industries 
37 
Carlson Companies 
250 
Quality Stores 
55 
Source: "Staying Private," Forbes, Dec. 13,1999, pp. 182-240. 
Source: Tampa Bay Business Journal, June 21-27,1996, p. 27. 
Analysis Variable : NUMEMPLY 
LARGE-SAMPLE CONFIDENCE INTERVAL FOR A 
POPULATION PROPORTION 
The number of public opinion polls has grown at an astounding rate in recent 
years. Almost daily, the news media report the results of some poll. Pollsters regu- 
larly determine the percentage of people who approve of the president's on-the-job 
performance, the fraction of voters in favor of a certain candidate, the fraction of 
customers who prefer a particular product, and the proportion of households that 
watch a particular TV program. In each case, we are interested in estimating the 
percentage (or proportion) of some group with a certain characteristic. In this sec- 
tion we consider methods for making inferences about population proportions 
when the sample is large. 

280 
CHAPTER 
5 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
A food-products company conducted a market study by randomly sampling and 
interviewing 1,000 consumers to determine which brand of breakfast cereal they 
prefer. Suppose 313 consumers were found to prefer the company's brand. How 
would you estimate the true fraction of all consumers who prefer the company's 
cereal brand? 
S o l u t i o n  What we have really asked is how you would estimate the probabilityp of success 
in a binomial experiment, where p is the probability that a chosen consumer 
prefers the company's brand. One logical method of estimating p for the 
population is to use the proportion of successes in the sample. That is, we can 
estimate p  by calculating 
Number of consumers sampled who prefer the company's brand 
jj = 
Number of consumers sampled 
where a is read "p hat."Thus, in this case, 
To determine the reliability of the estimator j3, we need to know its sampling dis- 
tribution. That is, if we were to draw samples of 1,000 consumers over and over 
again, each time calculating a new estimate jj, what would be the frequency dis- 
tribution of all the 6 
values? The answer lies in viewing ji as the average, or mean, 
number of successes per trial over the n trials. If each success is assigned a value 
equal to 1 and a failure is assigned a value of 0, then the sum of all n sample ob- 
servations is x, the total number of successes, and jj = x/n is the average, or mean, 
number of successes per trial in the n  trials. The Central Limit Theorem tells us 
that the relative frequency distribution of the sample mean for any population is 
approximately normal for sufficiently large samples. 
* 
The repeated sampling distribution of jj has the characteristics listed in the 
next box and shown in Figure 5.12. 
Sampling Distribution of 
1. 
'lhe mean of thc sampling distribution of 
isp; that is, jj is an unbiased 
estimator of p. 
2. The standard deviation of the 
f @ is a; 
that 
- 
is, 
= d p q / n ,  where q = 1 - p. 
. For large samples, the sampling distribution of 6 is approximately nor- 
mal. A sample size is considered large if the interval j3 f 3ui; does 
not include 0 or 1. [Note: This requirement is almost equivalent to that 
given in optional Section 4.9 for approximating a binomial distribution 
with a normal one. The difference is that we assumed p to be known in 
optional Section 4.9; now we are trying to make inferences about an 

SECTION 5.3 
Large-Sample C o n f i d e n c e  Interval f o r  a P o p u l a t i o n  P r o p o r t i o n  
281 
The fact that jj is a "sample mean number of successes per trial" allows us to 
form confidence intervals about p in a manner that is completely analogous to 
that used for large-sample estimation of p. 
rge-Sampl 
ence 
P 
X 
where? = -and? = 1 - ji 
n 
Note: When n is large, j3 can approximate the value of p in the formula for a;. 
Thus, if 313 of 1,000 consumers prefer the company's cereal brand, a 95% 
confidence interval for the proportion of all consumers who prefer the company's 
brand is 
where q = 1 - p. Just as we needed an approximation for u in calculating a 
large-sample confidence interval for p, we now need an approximation for p. As 
Table 5.5 shows, the approximation for p does not have to be especially accurate, 
T~~~ 5.5 values of pq 
because the value of 
needed for the confidence interval is relatively insensi- 
tive to changes in p. Therefore, we can use ji to approximate p. Keeping in mind that 
for Several 
ij = 1 - F, we substitute these values into the formula for the confidence interval: 
Different 
Values of p 
P 
P9 
6 
p * 1.9hdx 1,000 = j, * 1.96dx 
, , . . . , , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1'000 
The company can be 95% confident that the interval from 28.4% to 34.2% contains 
the true percentage of all consumers who prefer its brand.That is, in repeated con- 
struction of confidence intervals, approximately 95% of all samples would pro- 
duce confidence intervals that enclosep. Note that the guidelines for interpreting a 
confidence interval about p also apply to interpreting a confidence interval for p 
because p is the "population fraction of successes" in a binomial experiment. 

282 
CHAPTER 5 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
- ,.. ,,. 
' ,  
-<,..-- 
Many public polling agencies conduct survey\ to determine the current con\umer 
sentiment concerning the state of the economy. For example, the Bureau of 
Economic and Business Research (BEBR) at the University of Florida conducts 
quarterly surveys to gauge consumer sentiment in the Sunshine State. Suppose 
that BEBR randomly samples 484 consumers and finds that 257 are optimistic 
about the state of the economy. Use a 90% confidence interval to estimate the 
proportion of all consumers in Florida who are optimistic about the state of the 
economy. Based on the confidence interval, can BEBR infer that the majority of 
Florida consumers are optimistic about the economy? 
S o l u t i o n  The number, x, of the 484 sampled consumers who are optimistic about the 
Florida economy is a binomial random variable if we can assume that the sample 
was randomly selected from the population of Florida consumers and that the poll 
was conducted identically for each sampled consumer. 
The point estimate of the proportion of Florida consumers who are opti- 
mistic about the economy is 
We first check to be sure that the sample size is sufficiently large that the 
normal distribution provides a reasonable approximation for the sampling distri- 
bution of 13. We check the 3-standard-deviation interval around @: 
Since this interval is wholly contained in the interval (0, I), we may conclude that 
the normal approximation is reasonable. 
We now proceed to form the 90% confidence interval for p, the true pro- 
portion of Florida consumers who are optimistic about the state of the economy: 
I 
Thus, we can be 90% confident that the proportion of all Florida consumers who 
1 
are confident about the economy is between .494 and S68. As always, our confi- I 
dence stems from the fact that 90% of all similarly formed intervals will contain 1 
the true proportion p and not from any knowledge about whether this particular 
interval does. 
Can we conclude that the majority of Florida consumers are optimistic about 
the economy based on this interval? If we wished to use this interval to infer that a 
majority is optimistic, the interval would have to support the inference that p ex- 
ceeds .5-that 
is, that more than 50% of the Florida consumers are optimistic 

at 
0- 
1y: 
/h0 
nfi- 
.ain 
dar 
,out 
at a 
ex- 
istic 
SECTION 5.3 
Large-Sample C o n f i d e n c e  Interval f o r  a Population Proportion 
283 - 
about the economy. Note that the interval contains some values below .5 (as low as 
.494) as well as some above .5 (as high as .568). Therefore, we cannot conclude that 
the true value of p exceeds .5 based on this 90% conficlence interval. 
3~ 
Caution: Unless n is extremely large, the large-sample procedure presented in 
this section performs poorly when p is near 0 or 1. For example, suppose you 
want to estimate the proportion of executives who die from a work-related injury. 
This proportion is likely to be near 0 (say, p = .001 ). Confidence intervals for p 
based on a sample of size n = 50 will probably be misleading. 
To overcome this potential problem, an extremely large sample size is re- 
quired. Since the value of n required to satisfy "extremely large7' is difficult to de- 
termine, statisticians (see Agresti & Coull, 1998) have proposed an alternative 
method, based on the Wilson (1927) point estimator of p. The procedure is out- 
lined in the box. Researchers have shown that this confidence interval works well 
for any p even when the sample size n is very small. 
characteristic of interest, x is the number of successes in the sample, and n is 
the sample size. 
;andom sample of 200 Americans, 3 were victims of a violent crirne.~stimate the 
true proportion of Americans who were victims of a violent crime using a 95% 
confidence interval. 
S o I u t i o n Let p represent the true proportion of Americans who were victims of a violent 
crime. Since p is near 0, an "extremely large" sample is required to estimate its 
value using the usual large-sample method. Since we are unsure whether the 
sample size of 200 is large enough, we will apply the adjustment outlined in the box. 
The number of "successes" (i.e., number of violent crime victims) in the 
sample is x = 3. Therefore, the adjusted sample proportion is 
Note that this adjusted sample proportion is obtained by adding a total of four 
observations-two 
"successes" and two "failuresn-to the sample data. Substitut- 
ing p = .025 into the equation for a 95% confidence interval, we obtain 

284 
CHAPTER 
5 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
or (.004, .046). Consequently, we are 95% confident that the true proportion of 
Americans who are victims of a violent crime falls between .004 and .046. + 
Confidence Interval for a Population 
U S I N G  THE T I - 8 3  GRAPHING C A L C U L A T O R  
Confidence Intervals for Proportions on the TI-83 
You can find confidence intervals for proportions using the 1-PropZInt command in 
the STAT TESTS Menu. 
Step 1. Select the appropriate type of confidence interval 
Press STAT and h~ghlight TESTS 
. 
* 
. 
Use the arrow keys to highlight kl-PropZInt 
Press ENTER 
Step 2 Determine your values tor x, n and confidence level 
Enter these values for x, n and C-Level 
where x = number of successes 
n = sample size 
C-Level = level of confidence 
Step 3 Calculate the confidence interval 
a Highlight Calculate 
Press ENTER 
Example Suppose that 1,100 US. citizens are randomly chosen and 532 answer 
that they favor a flat income tax rate. Use a 95% confidence interval to 
estimate the true proportion of citizens who favor a flat income tax rate. 
In this example, x = 532, n = 1,100 and C-Level = .95 
. 
The TI-83 screens for this example are showh below. 
I 
I 
I 
I 
Thus, We can be 95% confident that the interval from 45.4% to 51.3% con- 
tains the true percentage of all U.S. citizens who favor a flat income tax rate. 
Learning the Mechanics 
C. What assumption is necessary to ensure the valid~r\ 
5.24 A random sample of size n = 121 yielded 
= .88. 
of this confidence interval? 
a. Is the sample size large enough to use the methods 
5.25 For the binomial sample information summarized ~n 
of this section to construct a confidence interval for 
each part, indicate whether the sample size is large 
p? Explain. 
enough to usc the methods of this chapter to construct a 
b. Construct a 90% confidence interval for p. 
confidence interval for p. 

- 
dity 
d in 
lrge 
~ c t  
a 
SECTION 5.3 
L a r g e - S a m p l e  C o n f i d e n c e  I n t e r v a l  f o r  a P o p u l a t i o n  P r o p o r t i o n  
285 
5.26 A random sample of 50 consumers taste tested a new 
snack food. Their responses were coded (0: do not like; 
1: like; 2: indifferent) and recorded as follows: 
a. Use an 80% confidence interval to estimate the pro- 
portion of consumers who like the snack food. 
b. Provide a statistical interpretation for the confidence 
interval you constructed in part a. 
5.27 A random sample of size n = 225 yielded a = .46. 
a. Is the sample size large enough to use the methods 
of this section to construct a confidence interval for 
p? Explain. 
b. Construct a 95% confidence interval for p. 
c. Interpret the 95% confidence interval. 
d. Explain what is meant by the phrase "95% confi- 
dence interval." 
Applying the Concepts 
5.28 The Gallup Organization surveyed 1,252 debit card- 
holders in the United States and found that 180 had 
used the debit card to purchase a product or service 
on the Internet (Card Fax, November 12,1999). 
a. Describe the population of interest to the Gallup 
Organization. 
b. If you personally were charged with drawing a ran- 
dom sample from this population, what difficulties 
would you encounter? Assume in the remainder of 
the exercise that the 1,252 debit cardholders were 
randomly selected. 
c. Is the sample size large enough to construct a valid 
confidence interval for the proportion of debit card- 
holders who have used their card in making pur- 
chases over the Internet? Justify your answer. 
d. Estimate the proportion referred to in part c using a 
98% confidence interval. Interpret your result in the 
context of the problem. 
e. If you had constructed a 90% confidence interval in- 
stead, would it be wider or narrower? 
529 As Internet usage proliferates, so do questions of securi- 
ty and confidentiality of personal information, including 
such things as social security and credit card numbers. 
NCR Corporation surveyed 1,000 U.S. adults and asked 
them under what circumstances they would give person- 
al information to a company. Twenty-nine percent said 
they would never give personal data to a company, while 
51% said they would if the company had strict privacy 
guidelines in place (Precision Marketing, Oct. 4,1999). 
a. Verify that the sample size is large enough to con- 
struct a valid confidence interval for p, the propor- 
tion of all US. adults who would never give personal 
information to a company. 
b. Construct a 95% confidence interval for p and in- 
terpret your result in the context of the problem. 
c. Other than the size of the sample, what assumption 
must be made about the sample in order for the esti- 
mation procedure of part b to be valid? 
5.30 By law, all new cars must be equipped with both driver- 
side and passenger-side safety air bags. There is con- 
cern, however, over whether air bags pose a danger for 
children sitting on the passenger side. In a National 
Highway Traffic Safety Administration (NHTSA) study 
of 55 people killed by the cxploslve force of air bags, 35 
were children seated on the front-passenger side (Wall 
Street Journal, Jan. 22, 1997). This study led some car 
owners with children to disconnect the passenger-side 
air bag. Consider all fatal automobile accidents in which 
it is determined that air bags were the cause of death. 
Let p represent the true proportion of these accidents 
involving children seated on the front-passenger side. 
a. Use the data from the NHTSA study to estimate p. 
b. Construct a 99% confidence interval for p. 
c. Interpret the interval, part b, in the words of the 
problem. 
d. NHTSA investigators determined that 24 of 35 chil- 
dren killed by the air bags were not wearing seat 
belts or were improperly restrained. How does this 
information impact your assessment of the risk of an 
air bag fatality? 
5.31 Refer to the Marine Technology (Jan. 1995) study of the 
causes of fifty recent major oil spills from tankers and 
carriers, Exercise 2.10 (p. 34). Recall that 12 of the spills 
were caused by hull failure. 
a. Give a pomt estimate for the proportion of major 
oil spill4 that are caused by hull failure. 
b. Form a 95% confidence interval for the estimate, 
part a. Interpret the result. 
5.32 Refer to the Federal Trade Commission (FTC) 1998 
"Price Check" study of electronic checkout scanners, 
Exercise 4.30 (p. 192). The FTC inspected 1,669 scanners 
at retail stores and supermarkets by scanning a sample of 
items at each store and determining if the scanned price 
was accurate. The l T C  gives a store a "passing" grade if 
98% or more of the items are priced accurately. Of the 
1,669 stores in the study, 1,185 passed inspection. 
a. Find a 90% confidence interval for the true propor- 
tion of retail stores and supermarkets with electron- 
ic scanners that pass the FTC price-check test. 
Interpret the result. 
b. In 1996, the FTC found that 45% of the stores passed 
inspection. Use the interval from part a to determine 
whether the proportion of stores that pass inspec- 
tion in 1998 exceeds .45. 

286 
CHAPTER 5 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
5.33 The accounting firm of Price Waterhouse annually moni- 
tors the U.S. Postal Service's performance. One parameter 
of interest is the percentage of mail delivered on time. In a 
sample of 332,000 items mailed between Dec. 10 and 
Mar. 3-the 
most difficult delivery season due to bad 
weather and holidays-Price 
Waterhouse determined that 
282,200 items were delivered on time (Tampa Tribune, 
Mar. 26,1995). Use this information to estimate with 99% 
confidence the true percentage of items delivered on time 
by the US. Postal Service. Interpret the result. 
5.34 Family-owned companies are notorious for having diffi- 
culties in transferring control from one generation to 
the next. Part of this problem can be traced to lack of a 
well-documented strategic business plan. In a survey of 
3,900 privately held family firms with revenues exceed- 
ing $1,000,000 a year, Arthur Andersen, the interna- 
tional accounting and consulting firm, found that 1,911 
had no strategic business plan (Minneapolis Star 
Tribune, Sept. 4,1995). 
a. Describe the population studied by Arthur Andersen. 
b. Assume the 3,900 firms were randomly sampled 
from the population. Use a 90% confidence interval 
to estimate the proportion of family-owned compa- 
nies without strategic business plans. 
c. How wide is the 90% confidence interval you con- 
structed in part b? Would an 80% confidence inter- 
val be wider or narrower? Justify your answer. 
DETERMINING THE SAMPLE SIZE 
Recall (Section 1.5) that one way to collect the relevant data for a study used to 
make inferences about the population is to implement a designed (planned) ex- 
periment. Perhaps the most important design decision faced by the analyst is to 
determine the size of the sample. We show in this section that the appropriate 
sample size for making an inference about a population mean or proportion de- 
pends on the desired reliability. 
Estimating a Population Mean 
Consider the example from Section 5.1 in which we estimated the mean overdue 
amount for all delinquent accounts in a large credit corporation. A sample of 
100 delinquent accounts produced the 95% confidence interval: 
- 
x f 2a, = 233.28 * 18.07. Consequently, our estimate ?r was within $18.07 of 
the true mean amount due, p, for all the delinquent accounts at the 95% confi- 
dence level. That is, the 95% confidence interval for p was 2(18.07) = $36.14 wide 
when 100 accounts were sampled. This is illustrated in Figure 5.13a. 
F I G U R E  5.13 
Relationship between sample size and width of confidence interval: Delinquent debtors example 

SECTION 5.4 
D e t e r m i n i n g  t h e  Sample Size 
2874 
Now suppose we want to estimate p to within $5 with 95% confidence. That 
is, we want to narrow the width of the confidence interval from $36.14 to $5, as 
shown in Figure 5.13b. How much will the sample size have to be increased to ac- 
complish this? If we want the estimator T to be within $5 of p, we must have 
2cx = 5 
or, equivalently, 
2 - 
= 5 
(3 
The necessary sample size is obtained by solving this equation for n. To do this we 
need an approximation for a. We have an approximation from the initial sample 
of 100 accounts-namely, the sample standard deviation, s = 90.34. Thus, 
Approximately 1,306 accounts will have to be randomly sampled to estimate the 
mean overdue amount p to within $5 with (approximately) 95% confidence. The 
confidence interval resulting from a sample of this size will be approximately $10 
wide (see Figure 5.13b). 
In general, we express the reliability associated with a confidence interval 
for the population mean p by specifying the bound, B, within which we want to 
estimate p with 100(1 - a)% confidence. The bound B then is equal to the half- 
width of the confidence interval, as shown in Figure 5.14. 
FIGURE 5.14 
Specifying the bound B 
as the half-width of a 
conf~dence interval 
P 
7a12Oi 
P 
P + Zan% 
+B-B+ 
The procedure for finding the sample size necessary to estimate p to within 
a given bound B is given in the box. 
Sam~le Size Determination for 100(1 - a)% Confidence 
t e k a ~  
for 
order to estimat 
- a )  % confidence, the 
quired sample size is found as follows: 
(continued) 

288 
CHAPTER 5 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
I 
y the standard devi- 
any case, you should round the value of n obtained upward to ensure that the 
l 
to a pressure of 13.5 pounds. When the machine is properly calibrated, the mean 
inflation pressure is 13.5 pounds, but uncontrollable factors cause the pressures of 
individual footballs to vary randomly from about 13.3 to 13.7 pounds. For quality 
control purposes, the manufacturer wishes to estimate the mean inflation pressure 
to within .025 pound of its true value with a 99% confidence interval. What 
sample size should be used? 
f 
S 0 I U t i 0 n We desire a 99% confidence interval that estimates p to within B = .025 pound of 
its true value. For a 99% confidence interval, we have z,,, 
= z,oos = 2.575. To 
estimate a, we note that the range of observations is R = 13.7 - 13.3 = .4 and use 
(+ = Rl4 = .I. Now we use the formula derived in the box to find the sample size n: 
We round this up to n = 107. Realizing that a was approximated by R/4, we 
i 
might even advise that the sample size be specified as n = 110 to be more certain 
of attaining the objective of a 99% confidence interval with bound B = .025 
pound or less. 
> 
Sometimes the formula will yield a small sample size ( n < 25 ). Unfortu- 
. +
*
 
nately, this solution is invalid because the procedures and assumptions for small 
samples differ from those for large samples, as we discovered in Section 5.2. 
Therefore, if the formulas yield a small sample size, one simple strategy is to select 
a sample size n = 30. 
I 
Estimating a Population Proportion 
I 
i 
The method outlined above is easily applied to a population proportion p. For ex- 
I 
ample, in Section 5.3 a company used a sample of 1,000 consumers to calculate a 
95% confidence interval for the proportion of consumers who preferred its cereal 
brand, obtaining the interval .313 f .029. Suppose the company wishes to estimate 
its market share more precisely, say to within .015 with a 95 % confidence interval. 
The company wants a confidence interval with a bound B on the estimate of 
p of B = .015. The sample size required to generate such an interval is found by 
solving the following equation for n: 
z a p ;  = B 
or 
z , , E  = .015 
(see Figure 5.15) 

SECTION 
5.4 
D e t e r m i n i n g  t h e  S a m p l e  Size 
289 
A 
FIGURE 5.15 
Specifying the bound B 
of a confidence interval 
for a population 
proportion p 
*P^ 
P - Z,12~p^ 
P 
P + z a 1 z q  
k-----~-B---d 
Since a 95% confidence interval is desired, the appropriate z value is 
z ~ , ~  
= zOz5 = 1.96 = 2. We must approximate the value of the product pq before 
we can solve the equation for n. As shown in Table 5.5, the closer the values of p 
and q to .5, the larger the product pq. Thus, to find a conservatively large sample 
size that will generate a confidence interval with the specified reliability, we gen- 
erally choose an approximation of p close to .5. In the case of the food-products 
company, however, we have an initial sample estimate of ji = .313. A conserva- 
tively large estimate of pq can therefore be obtained by using, say, p = .35. We 
now substitute into the equation and solve for n: 
The company must sample about 4,045 consumers to estimate the percentage 
who prefer its brand to within .015 with a 95% confidence interval. 
The procedure for finding the sample size necessary to estimate a popula- 
tion proportion p to within a given bound B is given in the box. 
Sample Size Determination for 100 (1 - a)O/o Confidence 
nterval for p 
In order to estim 
binomial probabilit 
ithin a bound B with 
100(1 - CY) % confidence, the required sample size is found by solving the fol- 
lowing equation for n: 
- 
pq is unknown, it can be estimated by using the 
sample fraction of successes, p, from a prior sample. Remember (Table 5.5) 
that the value of pq is at its maximum when p equals .5, so that you can obtain 
conservatively large values of n by approximating p by .5 or values close to .5. 
In any case, you should round the value of n obtained upward to ensure that 
the sample size will be sufficient to achieve the specified reliability. 

290 
CHAPTER 5 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
s""mmas- 
-
-
#
 
A cellular telephone manufacturer that entered the postregulation market too 
quickly has an initial problem with excessive customer complaints and consequent 
returns of the cell phones for repair or replacement. The manufacturer wants to 
determine the magnitude of the problem in order to estimate its warranty liability. 
How many cellular telephones should the company randomly sample from its 
warehouse and check in order to estimate the fraction defective, p, to within .O1 
with 90% confidence? 
S o I u t i o n 
In order to estimate p to within a bound of .01, we set the half-width of the 
confidence interval equal to B = .Ol, as shown in Figure 5.16. 
The equation for the sample size n requires an estimate of the product pq. 
We could most conservatively estimate pq = .25 (i.e., use p = .5 ),but this may be 
overly conservative when estimating a fraction defective. A value of .l, corre- 
sponding to 10% defective, will probably be conservatively large for this applica- 
tion. The solution is therefore 
FIGURE 5.16 
Specified reliability for estimate of 
fraction defective in Example 5.7 
a = .05 
o! = .05 0
p - 1.6450; 
K B  = .01-+B p 
= p . 0 l + i  
+ 1.6450; 
Thus, the manufacturer should sample 2,436 cellular telephones in order to esti- 
mate the fraction  defective,^, to within .O1 with 90% confidence. Remember that 
this answer depends on our approximation forpq, where we used .09. If the frac- 
' 
tion defective is closer to .05 than .lo, we can use a sample of 1,286 cell phones 
(check this) to estimate p to within .O1 with 90% confidence. 
The cost of sampling will also play an important role in the final determina- 
tion of the sample size to be selected to estimate either p or p. Although more 
complex formulas can be derived to balance the reliability and cost considera- 
tions, we will solve for the necessary sample size and note that the sampling bud- 
get may be a limiting factor. Consult the references for a more complete 
treatment of this problem. 
Learning the Mechanics 
5.36 If nothing is known about p, .5 can be substituted forp 
5.35 If you wish to estimate a population mean to within a 
in the sample-size formula for a population proport~on I 
bound B = .3 using a 95% confidence interval and you 
But when this IS done, the rerulting sample size ma) br 
know from prior sampling that a2 is approximately 
larger than needed. Under what circumstances will ' 
equal to 7.2, how many observations would have to be 
using p = .5 in the sample-size formula yield a samplt. 
included in your sample? 
size larger than needed to construct a conf~dencz 

SECTION 5.4 
D e t e r m i n i n g  t h e  S a m p l e  S i z e  
291 
interval for p with a specified bound and a specified 
confidence level? 
5.37 Suppose you wish to estimate a population mean cor- 
rect to within a bound B = .20 with probability equal to 
.90.You do not know a', but you know that the obser- 
vations will range in value between 30 and 34. 
a. Find the approximate sample size that will produce 
the desired accuracy of the estimate. You wish to be 
conservative to ensure that the sample size will be 
ample to achieve the desired accuracy of the esti- 
mate. [Hint: Using your knowledge of data variation 
from Section 2.6, assume that the range of the obser- 
vations will equal 4a.I 
b. Calculate the approximate sample size making the 
less conservative assumption that the range of the 
observations is equal to 6u. 
5.38 In each case, find the approximate sample size required 
to construct a 95% confidence interval for p that has 
bound B = .08. 
a. Assume p is near .2. 
b. Assume you have no prior knowledge about p, but 
you wish to be certain that your sample is large enough 
to achieve the specified accuracy for the estimate. 
5.39 'Ihe following is a 90% confidence interval for p: (.26, 
S4). How large was the sample used to construct this 
interval? 
5.40 Suppose you wish to estimate the mean of a normal 
population using a 95% confidence interval, and you 
know from prior information that a2 .-. 1. 
a. To see the effect of the sample size on the width of 
the confidence interval, calculate the width of the 
confidence interval for n = 16,25,49,100, and 400. 
h. Plot the width as a function of sample size n on 
graph paper. Connect the points by a smooth curve 
and note how the width decreases as n increases. 
Applying the Concepts 
5.41 Do you pay for certain Web services? Georgia Institute 
of Technology's Graphics Visualization and Usability 
Center surveyed 13,000 Internet users and asked them 
about their willingness to pay fees for access to Web 
sites. Of these, 2,938 were definitely not willing to pay 
such fees (Inc. Technology, No. 3,1995). 
a. Assume the 13,000 users were randomly selected. 
Construct a 95% confidence interval for the propor- 
tlon definitely unwilling to pay fees. 
b. What is the w~dth of the interval you constructed in 
" 
part a? For most applicat~ons, this width 1s unneces- 
x 
sarlly narrow. What does that suggest about the sur- 
irl 
vey's sample size? 
C. How large a sample size is necessary to estimate 
i i  
the proportion of interest to withln 2% with 95% 
"confidence? 
Z& 
SA2 'Ihe EPA wants to test a randomly selected sample of n 
water specimens and estimate the mean daily rate of pol- 
lution produced by a mining operation. If the EPA wants 
a 95% confidence interval estimate with a bound on the 
error of 1 milligram per liter (mg/L), how many water 
specimens are required in the sample? Assume prior 
knowledge indicates that pollution readings in water sam- 
ples taken during a day are approximately normally dis- 
tributed with a standard deviation equal to 5 mgIL. 
5.43 A gigantic warehouse located in Tampa, Florida, stores 
approximately 60 million empty aluminum beer and 
soda cans. Recently, a fire occurred at the warehouse. 
The smoke from the fire contaminated many of the cans 
with blackspot, rendering them unusable. A University 
of South Florida statistician was hired by the insurance 
company to estimate the true proportion of cans in the 
warehouse that were ccntaminated by the fire. How 
many aluminum cans should be randomly sampled to 
estimate the true proportion to within .02 with 90% 
confidence? 
5.44 In a survey conducted for Money magazine by the ICR 
Survey Research Group, 26% of parents with college- 
bound high school children reported not having saved 
any money for college. The poll had a ". . . margin of 
error of plus or minus 4 percentage points" (Newark 
Star-Ledger, Aug. 16,1996). 
a. Assume that random sampling was used in conduct- 
ing the survey and that the researchers wanted to 
have 95% confidence in their results. Estimate the 
sample size used in the survey. 
b. Repeat part a, but this time assume the researchers 
wanted to be 99% confident. 
5.45 A large food-products company receives about 
100,000 phone calls a year from consumers on its toll-free 
number. A computer monitors and records how many 
rings it takes for an operator to answer, how much time 
each caller spends "on hold," and other data. However, 
the reliability of the monitoring system has been called 
into question by the operators and their labor union. As a 
check on the computer system, approximately how many 
calls should be manually monitored during the next year 
to estimate the true mean time that callers spend on hold 
to within 3 seconds with 95% confidence? Answer this 
question for the following values of the standard devia- 
tion of waiting times (in seconds): 10,20, and 30. 
5.46 The United States Golf Association (USGA) tests all new 
brands of golf balls to ensure that they meet USGA spec- 
ifications. One test conducted is intended to measure the 
average distance traveled when the ball is hit by a 
machine called "Iron Byron," a name inspired by the 
swing of the famous golfer Byron Nelson. Suppose the 
USGA wishes to estimate the mean distance for a new 
brand to within 1 yard with 90% confidence. Assume that 
past tests have indicated that the standard deviation of the 
distances Iron Byron hits golf balls is approximately 10 
yards. How many golf balls should be hit by Iron Byron to 
achieve the desired accuracy in estimating the mean? 

292 
CHAPTER 
5 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
A 
rnold Bennett, a Sloan School of Management pro- 
fessor at the Massachusetts Institute of Technology 
(MIT), describes a recent legal case in which he served as a 
statistical "expert" in Interfaces (Mar.-Apr. 1995). The case 
involved a ship that fishes for scallops off the coast of New 
England. In order to protect baby scallops from being har- 
vested, the U.S. Fisheries and Wildlife Service requires that 
"the average meat per scallop weigh at least l/ii, of a 
pound." The ship was accused of violating this weight stan- 
dard. Bennett lays out the scenario: 
The vessel arrived at a Massachusetts port with 
11,000 bags of scallops, from which the harbormaster 
randomly selected 18 bags for weighing. From each 
such bag, his agents took a large scoopful of scallops; 
then, to estimate the bag's average meat per scallop, they 
divided the total weight of meat in the scoopful by the 
number of scallops it contained. Based on the 18 [num- 
bers] thus generated, the harbormaster estimated that 
each of the ship's scallops possessed an average y39 of 
a pound of meat (that is, they were about seven percent 
lighter than the minimum requirement). Viewing this 
outcome as conclusive evidence that the weight stan- 
dard had been violated, federal authorities at once con- 
fiscated 95 percent of the catch (which they then sold at 
auction). The fishing voyage was thus transformed into 
a financial catastrophe for its participants. 
Bennett provided the actual scallop weight measurements 
for each of the 18 sampled bags in the articlc.The data are list- 
ed in Table 5.6. For ease of exposition, Bennett expressed each 
number as a multiple of 1/,, of a pound, the minimum permis- 
sible average weight per scallop. Consequently, numbers below 
one indicate individual bags that do not meet the standard. 
TABLE 
5.6 
Scallop Weight Measurements for 18 
Bags Sampled 
Source: Bennett, A. "Misapplications review: Jail terms." 
Interfirces Vol. 25, No. 2, March-April 1995, p. 20. 
The ship's owner filed a lawsuit against the federal gov- 
ernment, declaring that his vessel had fully complied with 
the weight standard. A Boston law firm was hired to repre- 
sent the owncr in legal proceedings and Bennett was re- 
tained by thc firm to provide statistical litigation support 
and, if necessary, expert witness testimony. 
F
o
c
u
s
 
a. Recall that the harbormaster sampled only 18 of the 
ship's 11,000 bags of scallops. One of the questions the 
lawyers asked Bennett was: "Can a reliable estimate of 
the mean weight of all the scallops be obtained from a 
sample ol size IS?" Give your opinion on this issue. 
b. As stated in the article, the government's decision rule is 
to confiscate a scallop catch if the sample mean weight 
of the scallops is less than '/;, 
of a pound. Do you see 
any flaws in this rule? 
c. Develop your own procedure for determining whether a 
ship is in violation of the minimum weight restriction. 
Apply your rule to the data in Table 5.6. Draw a conclu- 
sion about the ship in question. 
5.47 Does the caffeine in coffee, tea, and cola induce an addic- 
draw conclusions (Los Angeles Times, Oct. 5. 1994). Is 
tion similar to that induced by alcohol, tobacco, heroine, 
the sample largc enough to estimate the true proportion 
and cocaine? In an attempt to answer this question, 
of caffeine drinkers who are caffeine dependent to within 
researchers at Johns Hopkins University examined 27 
.05 of the true value with 99% confidence? Explain. 
caffeine drinkers and found 25 who displayed some type 
of withdrawal symptoms whcn abstaining from caffeine. 
[Note: The 27 caffeine drinkers volunteered for the 
study.] Furthermore, of 11 caffeine drinkers who were 
diagnosed as caffeine dependent, 8 displayed dramatic 
withdrawal symptoms (including impairment in normal 
functioning) when they consumed a caffeine-free diet in 
a controlled setting. The National Coffee Association 
claimed, however, that the study group was too small to 
5.48 It costs more to produce defective items-since 
they 
must be scrapped or reworked-than 
it does to produce 
nondefective items. This simple fact suggests that manu- 
facturers should ensure the quality of their products by 
perfecting their production processes rather than through 
inspection of finished products (Deming, 1986). In order 
to better understand a particular metal-stamping process. 
a manufacturer wishes to estimate the mean length of 
items produced by the process during the past 24 hours 
e 

a. How many parts shbuld be sampled in order to esti- 
mate the population mean to within .1 millimeter 
(mm) with 90% confidence? Previous studies of this 
machine have indicated that the standard deviation 
of lengths produced by the stamping operation is 
about 2 mm. 
b. Time permits the use of a sample size no larger than 
100. If a 90% confidence interval for p is constructed 
1 
using n = 100, will it be wider or narrower than 
would have been obtained using the sample size de- 
termined in part a? Explain. 
c. If management requires that p be estimated to with- 
in .1 mm and that a sample size of no more than 100 
be used, what is (approximately) the maximum con- 
fidence level that could be attained for a confidence 
interval that meets management's specifications? 
- 
Key Terms 
Bound on the error of estimation 287 
Confidence level 262 
Point estimator 260 
Conf~dence coefficient 262 
Degrees of freedom 269 
t statistic 269 
Confidence interval 262 
Interval estimator 262 
). Is 
tion 
thin 
.hey 
luce 
anu- 
s by 
3ugh 
nder 
xess, 
th of 
mrs. 
Key Formulas 
A 
8 f (za/z)uil 
Large-sample confidence interval for population parameter 9 
where and ug are obtained from the table below 
Parameter 0 
Estimator 
Standard Error crg 
........................................................................................... 
- 
u 
Mean, p 
x 
- 
6 
263 
Proportion, p 
Small-sample confidence interval for population mean p 
272 
x t 2  
P=- 
Adjusted estimator of p 
283 
n t 4  
( ~ , , 2 ) ~ ( 7 ~  
,, = - 
Determining the sample size n for estimating p 
288 
B2 
Determining the sample size n for estimating p 
289 
Symbol 
Pronunciation 
Description 
......................................................................................................................................................................................................................................
fl 
theta 
General population parameter 
!J 
mu 
Population mean 
P 
Population proportion 
B 
Bound on error of estimation 
a 
alpha 
(1 - a) represents the confidence coefficient 
b 2  
z of alpha over 2 
z value used in a 100(1 - a )  % large-sample confidence interval 
to 1 
t of alpha over 2 
t value used in a 100(1 - a)% small-sample confidence interval 
- 
x 
x-bar 
Sample mean; point estimate of p 
? 
p-hat 
Samplc proportion; point estimate of p 
P 
p-curl 
Adjusted sample proportion 

294 
CHAPTER 
5 
I n f e r e n c e s  Based o n  a  Single Sample 
Symbol 
Pronunciation 
Description 
u 
sigma 
S 
UT 
sigma of 2 
l 
sigma of? 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . 
Population standard deviation 
Sample standard deviation; point estimate of u 
Standard deviation of sampling distribution of 2 
Standard deviation of sampling distribution of 9 
Note: L ~ s t  the assumptions necessary for the valld 
irnplementat~on of the stat~stlcalprocedures you use m 
solvmg all thae exercises. 
Learning the Mechanics 
5.49 Let t, represent a particular value of t from Table VI of 
Appendix B. Find the table values such that the follow- 
11 
ing statements arc true. 
a. P(t 5 t,) = .05 where df = 20 
b. P(t 2 to) = .005 where df = 9 
c. P(t 5 -t, or t 2 t,) = .10 where df = 8 
d. P(t 5 -to or t r to) = .O1 where df = 17 
5.50 In each of the following instances, determine whether 
you would use a z or t statistic (or neither) to form a 
95% confidence interval, and then look up the appro- 
priate z or t value. 
a. Random sample of size n = 23 from a normal distri- 
bution with unknown mean p and standard deviation u 
b. Random sample of size n = 135 from a normal dis- 
tribution with unknown mean p and standard devia- 
tion a 
c. Random sample of size n = 10 from a normal distri- 
bution with unknown mean p and standard devia- 
tion u = 5 
d. Random sample of size n = 73 from a distribution 
about which nothing is known 
e. Random sample of size n = 12 from a distribution 
about which nothing is known 
5.51 A random sample of 225 measurements is selected 
from a population, and the sample mean and standard 
deviation are 5 = 32.5 and s = 30.0, respectively. 
a. Use a 99% confidence interval to estimate the mean 
of the population, p. 
b. How large a sample would be needed to estimate p 
to within .5 with 99% confidence? 
c. What is meant by the phrase "99% confidence" as it 
is used in this exercise? 
5.52 In a random sample of 400 measurements, 227 of the 
measurements possess the characteristic of interest,A. 
a. Use a 95% confidence interval to estimate the true 
proportion p of measurements in the population 
with characteristic A. 
_ b. How large a sample would be needed to estimatep 
to within .02 with 95% confidence? 
Applying the Concepts 
5.53 As part of a study of residential property values in 
Cedar Grove, New Jersey, the county tax assessor 
sampled 20 single-family homes that sold during 1996 
and recorded their sales prices (in thousands of dol- 
lars; see table below). A stem-and-leaf display and 
descriptive statistics for these data are shown in the 
MINITAB printout on p. 295. 
a. On the MINITAB printout, locate a 95% confi- 
dence interval for the mean sale price of all single- 
family homes in Cedar Grove, New Jersey. 
b. Give a practical interpretation of the interval, part a. 
c. What is meant by the phrase "95% confidence" as it 
is used in this exercise? 
d. Comment on the validity of any assumptions re- 
quired to properly apply the estimation procedure. 
5.54 The Centers for Disease Control and Prevention 
(CDCP) in Atlanta, Georgia, conducts an annual survey 
of the general health of the US. population as part of its 
Behavioral Risk Factor Surveillance System (New York 
Times, Mar. 29, 1995). Using random-digit dialing, the 
CDCP telephones US. citizens over 18 years of age and 
asks them the following four questions: 
(1) Is your health generally excellent, very good, good, 
fair, or poor? 
(2) How many days during the previous 30 days was 
your physical health not good because of injury or 
illness? 
189.9 
235.0 
159.0 
190.9 
239.0 
559.0 
875.0 
635.0 
265.0 
330.0 
669.0 
935.0 
210.0 
179.9 
334.9 
219.0 
1,190.0 
739.0 
424.7 
229.0 
Source: Multiple Listing Service of Suburban Essex County, New Jersey. 

S u p p l e m e n t a r y  Exercises 
295 
" 
MINITAB Output for Exercise 5.53 
Stem-and-leaf of SalePric N = 20 
Leaf Unit = 10 
4 
1 5789 
10 
2 112336 
10 
3 33 
8 
4 2  
7 
5 5  
6 
6 36 
4 
7 3  
3 
8 7  
2 
9 3  
1 
10 
1 
11 9 
- 
N 
MEAN 
STDEV SE MEAN 
95.0 PERCENT C.I. 
SalePric 
20 
440.4 
303.0 
67.8 
( 
298.6, 
582.3) 
(3) How many days during the previous 30 days was 
your mental health not good because of stress, de- 
pression, or emotional problems? 
(4) How many days during the previous 30 days did your 
physical or mental health prevent you from per- 
forming your usual activities? 
Identify the parameter of interest for each question. 
5-55 Refer to Exercise 5.54. According to the CDCP, 89,582 
of 102,263 adults interviewed stated their health was 
good, very good, or excellent. 
a. Use a 99% confidence interval to estimate the true 
proportion of US. adults who believe their health to 
be good to excellent. Interpret the interval. 
b. Why might the estimate, part a, be overly optimistic 
(i.e., biased high)? 
j.j6 Substance abuse problems are widespread at New 
Jersey businesses, according to the Governor's Council 
for a Drug Free Workplace Report (SpringISummer 
1995). A questionnaire on the issue was mailed to all 
New Jersey businesses that were members of the 
Governor's Council. Of the 72 companies that respond- 
ed to the survey, 50 admitted that they had employees 
whose performance was affected by drugs or alcohol. 
a. Use a 95% confidence interval to estimate the pro- 
portion of all New Jersey companies with substance 
abuse problems. 
b. What assumptions are necessary to ensure the valid- 
ity of the confidence interval? 
c. Interpret the interval in the context of the problem. 
d. In interpreting the confidence interval, what does it 
mean to say you are "95% confident"? 
e. Would you use the interval of part a to estimate the 
proportion of all U.S. companies with substance 
abuse problems? Why or why not? 
5.57 Research reported in the Professional Geographer 
(May 1992) investigates the hypothesis that the dispro- 
portionate housework responsibility of women in two- 
income households is a major factor in determining the 
proximity of a woman's place of employment. The 
researcher studied the distance (in miles) to work for 
both men and women in two-income households. 
Random samples of men and women yielded the fol- 
lowing results: 
Central City 
Suburban 
Residence 
Residence 
...................................................................... 
Men 
Women 
Men 
Women 
............................................................................................................ 
Sample Size 
159 
119 
138 
93 
Mean 
7.4 
4.5 
9.3 
6.6 
Std. Deviation 
6.3 
4.2 
7.1 
5.6 
- 
a. For central city residences, calculate a 95% confi- 
dence interval for the average distance to work for 
men and women in two-income households. Inter- 
pret the intervals. 
b. Repeat part a for suburban residences. 
[Note: We will show how to use statistical techniques to 
compare two population means in Chapter 7.1 
5.58 Refer to the Journal of the American Medical 
Association (Apr. 21,1993) report on the prevalence of 
cigarette smoking among U.S. adults, Exercise 5.7 
(p. 266). Of the 43,732 survey respondents, 11,239 indi- 
cated that they were current smokers and 10,539 indi- 
cated they were former smokers. 
a. Construct and interpret a 90% confidence interval 
for the percentage of U.S. adults who currently 
smoke cigarettes. 


S u p p l e m e n t a r y  E x e r c i s e s  
297 " 
as 
ne 
:t. 
x- 
of 0 
six 
im 
di- 
m 
the 
six 
nal 
the 
estimator of the binomial probability? Justify your 
response. 
c. Construct a 95% confidence interval for the true 
proportion of the market who still refuse to purchase 
ice cream bars six months after the event. 
d. Interpret both the point estimate and confidence in- 
terval in terms of this application. 
e. Suppose it is now one year after the outbreak of 
food poisoning was traced to ice cream bars. The 
manufacturer wishes to estimate the proportion who 
still will not purchase bars to within .02 using a 95% 
confidence interval. How many consumers should be 
sampled? 
5.65 Refer to the National Highway Traffic Safety 
Administration (NHTSA) study of fatal auto accidents 
caused by air bags, Exercise 5.30 (p. 285). Recall that 
the NHTSA wants to estimate the proportion of such 
accidents in which children seated on the front pas- 
senger side were killed. How many fatal accidents 
should the NHTSA sample in order to estimate the 
proportion to within .1 of its true value using a 99% 
confidence interval? 

I N F E R E N C E S  B A S E D  
O N  A S I N G L E  S A M P L E :  
Tests o f  H y p o t h e s i s  
C O N T E N  
... ..'. .................. 
6.1 
6.2 
6.3 
6.4 
6.5 
6.6 
T  S 
............. 
The Elements of a Test of Hypothesis 
Large-Sample Test of Hypothesis About a Population Mean 
Observed Significance Levels: p-Values 
Small-Sample Test of Hypothesis About a Population Mean 
Large-Sample.Test of Hypothesis About a Population Proportion 
A Nonparametric Test About a Population Median (Optional) 
S T A T I S T I C S  
I N  
A
C
T
I
O
N
 
.................................................................................................................................... 
March Madness: Handicapping the NCAA Basketball Tourney 
r 
Where W e ' v e  B e e n  
r e  W e ' r e  G o i n g  
W 
e saw how to use sample information to esti- 
mate population parameters in Chapter 5. The 
sampling distribution of a statistic is used to assess 
the reliability of an estimate, which we express in 
terms of a confidence interval. 
W 
e'll see how to utilize sample information to 
test what the value of a population parameter 
may be. This type of inference is called a test of hy- 
pothesis. We'll also see how to conduct a test of hy- 
pothesis about a population mean p and a 
population proportion p. And, just as with estima- 
tion, we'll stress the measurement of the reliability of 
the inference. An inference without a measure of re- 
liability is little more than a guess. 

300 
 CHAPTER^ 
I n f e r e n c e s  Based o n  a S i n g l e  Sample 
1 
Suppose you wanted to determine whether the mean waiting time in the drive- 
* 
through line of a fast-food restaurant is less than five minutes, or whether the ma- 
jority of consumers are optimistic about the economy. In both cases you are 
interested in making an inference about how the value of a parameter relates to a 
specific numerical value. Is it less than, equal to, or greater than the specified num- 
ber? This type of inference, called a test of hypothesis, is the subject of this chapter. 
We introduce the elements of a test of hypothesis in Section 6.1. We then 
show how to conduct a large-sample test of hypothesis about a population mean 
in Sections 6.2 and 6.3. In Section 6.4 we utilize small samples to conduct tests 
about means, and in optional Section 6.6 we consider an alternative nonpara- 
metric test. Large-sample tests about binomial probabilities are the subject of 
Section 6.5. 
THE ELEMENTS OF A TEST OF HYPOTHESIS 
Suppose building specifications in a certain city require that the average breaking 
strength of residential sewer pipe be more than 2,400 pounds per foot of length 
(i.e., per linear foot). Each manufacturer who wants to sell pipe in this city must 
demonstrate that its product meets the specification. Note that we are again in- 
terested in making an inference about the mean p of a population. However, in 
this example we are less interested in estimating the value of p than we are in test- 
ing a hypothesis about its value. That is, we want to decide whether the mean break- 
ing strength o f  the pipe exceeds 2,400 pounds per linear foot. 
The method used to reach a decision is based on the rare-event concept 
explained in earlier chapters. We define two hypotheses: (1) The null hypothesis 
is that which represents the status quo to the party performing the sampling 
experiment-the 
hypothesis that will be accepted unless the data provide con- 
vincing evidence that it is false. (2) The alternative, or research, hypothesis is 
I 
that which will be accepted only if the data provide convincing evidence of its 
truth. From the point of view of the city conducting the tests, the null hypothesis 
is that the manufacturer's pipe does not meet specifications unless the tests pro- 
vide convincing evidence otherwise. The null and alternative hypotheses are 
therefore 
Null hypothesis (H,): p 5 2,400 
(i.e., the manufacturer's pipe does not meet specifications) 
Alternative (research) hypothesis (H,): p > 2,400 
(i.e., the manufacturer's pipe meets specifications) 
How can the city decide when enough evidence exists to conclude that the 
manufacturer's pipe meets specifications? Since the hypotheses concern the value 
of the population mean p, it is reasonable to use the sample mean i to make the 
inference, just as we did when forming confidence intervals for p in Sections 5.1 
and 5.2. The city will conclude that the pipe meets specifications only when the 
sample mean i convincingly indicates that the population mean exceeds 2,400 
pounds per linear foot. 
"Convincing" evidence in favor of the alternative hypothesis will exist when 
the value of i exceeds 2,400 by an amount that cannot be readily attributed to 
sampling variability. To decide, we compute a test statistic, which is the z value that 
I 
measures the distance between the value of x and the value of p specified in the 
null hypothesis. When the null hypothesis contains more than one value of p, as In 
this case (H,: p 5 2,400), we use the value of p closest to the values specified In 
the alternative hypothesis. The idea is that if thc hypothesis that p equals 2,400car 

SECTION 6.1 
T h e  E l e m e n t s  o f  a Test o f  H y p o t h e s i s  
301 
be rejected in favor of p > 2,400, then p less than or equal to 2,400 can certainly 
be rejected. Thus, the test statistic is 
Note that a value of z = 1 means that 2 is 1 standard deviation above p = 2,400; a 
value of z = 1.5 means that F is 1.5 standard deviations above p = 2,400, etc. How 
large must z be before the city can be convinced that the null hypothesis can be re- 
jected in favor of the alternative and conclude that the pipe meets specifications? 
If you examine Figure 6.1, you will note that the chance of observing i more 
than 1.645 standard deviations above 2,400 is only .05-if 
in fact the true mean p is 
2,400. Thus, if the sample mean is more than 1.645 standard deviations above 
2,400, either Ho is true and a relatively rare event has occurred (.05 probability) or 
Ha is true and the population mean exceeds 2,400. Since we would most likely re- 
ject the notion that a rare event has occurred, we would reject the null hypothesis 
(p 9 2,400) and conclude that the alternative hypothesis (p > 2,400) is true. 
What is the probability that this procedure will lead us to an incorrect decision? 
FIGURE 6.1 
The sampling 
distribution of 2, 
assuming p = 2,400 
- 
X 
Such an incorrect decision-deciding that the null hypothesis is false when 
in fact it is true-is 
called a Type I error. As indicated in Figure 6.1, the risk of 
making a Type I error is denoted by the symbol a. That is, 
a = P(Type I error) 
= P(Rejecting the null hypothesis when in fact the null hypothesis is true) 
In our example 
a = P(z > 1.645 when in fact p = 2,400) = .05 
We now summarize the elements of the test: 
Ho: p 5 2,400 
Ha: p > 2,400 
- 
x - 2,400 
Test statistic: z = 
Rejection region: z > 1.645, which corresponds to a = .05 

302 
 CHAPTER^ 
Inferences Based on a Single Sample 
4 - 
Note that the rejection region refers to the values of the test statistic for which we 
will reject the null hypothesis. 
To illustrate the use of the test, suppose we test 50 sections of sewer pipe and 
find the mean and standard deviation for these 50 measurements to be 
- 
x = 2,460 pounds per linear foot 
s = 200 pounds per linear foot 
As in the case of estimation, we can use s to approximate (T when s is calculated 
from a large set of sample measurements. 
The test statistic is 
Substituting 2 = 2,460, n = 50, and s = 200, we have 
Therefore, the sample mean lies 2.12~7, above the hypothesized value of p, 2,400. 
as shown in Figure 6.2. Since this value of z exceeds 1.645, it falls in the rejection 
region. That is, we reject the null hypothesis that p = 2,400 and conclude thal 
p > 2,400. Thus, it appears that the company's pipe has a mean strength that ex- 
ceeds 2,400 pounds per linear foot. 
F I G U R E  6.2 
Location of the test 
statistic for a test of the 
hypothesis 
H,: p = 2,400 
How much faith can be placed in this conclusion? What is the probability 
that our statistical test could lead us to reject the null hypothesis (and conclude 
that the company's pipe meets the city's specifications) when in fact the null hj- 
pothesis is true? The answer is a = .05. That is, we selected the level of risk, a, of 
making a Type I error when we constructed the test. Thus, the chance is only 1 in 
20 that our test would lead us to conclude the manufacturer's pipe satisfies the 
city's specifications when in fact the pipe does not meet specifications. 
Now, suppose the sample mean breaking strength for the 50 sections of 
sewer pipe turned out to be 2 = 2,430 pounds per linear foot. Assuming that the 
sample standard deviation is still s = 200, the test statistic is 

SECTION 6.1 
The Elements o f  a Test o f  Hypothesis 
303 
Therefore, the sample mean i = 2,430 is only 1.06 standard deviations above the 
null hypothesized value of p = 2,400. As shown in Figure 6.3, this value does not 
fall into the rejection region (z > 1.645). Therefore, we know that we cannot reject 
H, using a = .05. Even though the sample mean exceeds the city's specification of 
2,400 by 30 pounds per linear foot, it does not exceed the specification by enough 
to provide convincing evidence that the population mean exceeds 2,400. 
FIGURE 6.3 
Location of test 
statistic when 
- 
x = 2.430 
Should we accept the null hypothesis H,: p 5 2,400 and conclude that the 
manufacturer's pipe does not meet specifications? To do so would be to risk a 
Type I1 error-that 
of concluding that the null hypothesis is true (the pipe does 
not meet specifications) when in fact it is false (the pipe does meet specifica- 
tions). We denote the probability of committing a Type I1 error by P. Unfortu- 
nately, P is often difficult to determine precisely. Rather than make a decision 
(accept H,) for which the probability of error (P) is unknown, we avoid the po- 
tential Type I1 error by avoiding the conclusion that the null hypothesis is true. In- 
stead, we will simply state that the sample evidence is insufficient to reject H, at 
a = .05. Since the null hypothesis is the "status-quo" hypothesis, the effect of not 
rejecting H, is to maintain the status quo. In our pipe-testing example, the effect of 
having insufficient evidence to reject the null hypothesis that the pipe does not 
meet specifications is probably to prohibit the utilization of the manufacturer's 
pipe unless and until there is sufficient evidence that the pipe does meet specifi- 
cations. That is, until the data indicate convincingly that the null hypothesis is 
false, we usually maintain the status quo implied by its truth. 
Table 6.1 summarizes the four possible outcomes of a test of hypothesis. The 
"true state of nature" columns in Table 6.1 refer to the fact that either the null hy- 
pothesis H, is true or the alternative hypothesis Ha is true. Note that the true state 
of nature is unknown to the researcher conducting the test. The "decision" rows in 
Table 6.1 refer to the action of the researcher, assuming that he or she will either 
conclude that Ho is true or that H ,  is true, based on the results of the sampling ex- 
periment. Note that a Type I error can be made only when the null hypothesis is 
rejected in favor of the alternative hypothesis, and a Type I1 error can be made 
only when the null hypothesis is accepted. Our policy will be to make a decision 
only when we know the probability of making the error that corresponds to that 
decision. Since a is usually specified by the analyst, we will generally be able to re- 
ject H, (accept Ha) when the sample evidence supports that decision. However, 
since p is usually not specified, we will generally avoid the decision to accept H,, 
preferring instead to state that the sample evidence is insufficient to reject H, when 
the test statistic is not in the rejection region. 

304 
CHAPTER 
6 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
TABLE 
6.1 
Conclusions and Consequences for a Test of Hypothesis 
True State of Nature 
The elements of a test of hypothesis are summarized in the following box. 
Note that the first four elements are all specified before the sampling experiment 
is performed. In no case will the results of the sample be used to determine the 
hypotheses-the 
data are collected to test the predetermined hypotheses, not to 
formulate them. 
Conclusion 
...... .......................................................... 
Accept H,, (Assume Hn True) 
Reject H,, (Assume Ha True) 
,. - 
a. ** s. , 
2 
Elements of a Test of Hypothesis 
Null hypothesis (H,,): A theory about the values of one or more popula- 
tion parameters. The theory generally represents the status quo, which 
we adopt until it is proven false. 
Alternative (research) hypothesis ( 
hypothesis. The theory generally 
only when sufficient evidence exi 
Test statistic: A sample statistic us 
hypothesis. 
Rejection region: The numerical values of the test statistic for which the 
null hypothesis will be rejected. The rejection region is chosen so that the 
probability is a that it will contain the test statistic when the null hy- 
pothesis is true, thereby leading to a Type 1 error. The value of a is usu- 
ally chosen to be small (e.g., .O 
0), and is referred to as the level 
of significance of the test. 
Assunlptions: Clear statement 
y assumptions made about the 
population(s) being sampled. 
Experiment and calculation of test statistic: Performance of the sampling 
experiment and determination of the numerical value of the test statistic. 
Conclusion: 
a. If the numerical value of the test statistic falls in the rejection region, we 
reject the null hypothesis and conclude that the alternative hypothesis is 
true. We know that the hypothesis-testing process will lead to this conclu- 
sion incorrectly (Type I error) only lOOa% of the time when H,, is true. 
b. If the test statistic does not fall in the rejection region, we do not re- 
ject Ho. Thus, we reserve judgment about which hypothesis is true. We 
do not conclude that the null hypothesis is true because we do not (in 
general) know the probability /3 that our test procedure will lead to 
Hn True 
................................... 
. ..... . .................... 
Correct decision 
Type I error (probability a) 
*In many practical business applications of hypothesis testing, nonrejection leads management to 
behave as if the null hypothesis were accepted. Accordingly, the distinction between acceptance 
and nonrejection is frequently blurred in practice. 
Ha True 
.............................................................. . 
Type I1 error (probability P) 
Correct decision 

SECTION 6.1 
T h e  E l e m e n t s  o f  a T e s t  o f  H y p o t h e s i s  
305 
Learning the Mechanics 
6.1 Which hypothesis, the null or the alternative, is the 
status-quo hypothesis? Which is the research hypothesis? 
6.2 Which element of a test of hypothesis is used to decide 
whcther to reject the null hypothesis in Savor of the 
alternative hypothesis? 
6.3 What is the level of significance of a test of hypothesis? 
6.4 What is the difference between Type I and Type TI 
errors in hypothesis testing? How do a and /3 relate to 
Type I and Type I1 errors? 
65 List the four possible results of the combinations of deci- 
sions and true states of nature for a test of hypothesis. 
6.6 We (generally) reject the null hypothesis when the test 
statistic falls in the rejection region, but we do not 
accept the null hypothesis when the test statistic does 
not fall in the rejection region. Why? 
6.7 If you test a hypothesis and reject the null hypothesis in 
favor of the alternative hypothesis, does your test prove 
that the alternative hypothesis is correct? Explain. 
Applying the Concepts 
6.8 The interest rate at which London banks lend money to 
one another is called the London interbank offered mte, 
or Libor. According to The Wall Street Journal (Nov. 11, 
1998). the British Bankers Association regularly surveys 
international banks for the Libor ratc. One recent rcport 
had the average Libor rate at .39 percent for 3-month 
loans-a 
value considered high by many Western banks. 
Set up the null and alternative hypothesis for testing the 
reportcd value. 
6.9 The national student loan default rate has dropped 
steadily over the last decade. USF Magazine (Spring 
1999) reported the default rate (i.e., the proportion of 
college students who default on their loans) at .10 in 
fiscal year 1996. Set up the null and alternative hypothe- 
ses if you want to determine if the student loan default 
rate in 2000 is less than .lo. 
6.10 According to the Journal of Psychology and Aging 
(May 1992), older workers (i.e., workers 45 years old 
or older) have a mean job satisfaction rating of 4.3 on 
a 5-point scale. (Higher scores indicate higher levels 
of satisfaction.) 
a. Set up H,, and Ha to test the journal's claim. 
b. Describe aType I error for this test. 
c. Describe a Type I1 error for this test. 
6.11 Sometimes, the outcome of a jury trial defies the "com- 
monsense" expectations of the general public (e.g., the 
0. J. Simpson verdict in the "Trial of the Century"). Such 
a verdict is more acceptable if we understand that the 
jury trial of an accused murderer is analogous to the 
statistical hypothesis-testing process. The null hypothesis 
in a jury trial is that the accused is innocent. (The status- 
quo hypothesis in the U.S. system of justice is innocence, 
which is assumed to be true until proven beyond a rea- 
sonable doubt.) The alternative hypothesis is guilt, 
which is accepted only when sufficient evidence exists to 
establish its truth. If the vote of the jury is unanimous in 
favor of guilt. the null hypothesis of innocence is reject- 
ed and the court concludes that the accused murderer is 
guilty. Any vote other than a unanimous one for guilt 
results in a "not guilty" verdict.The court never accepts 
the null hypothesis; that is, the court never declares the 
accused "innocent." A "not guilty" verdict (as in the 0. J. 
Simpson case) implies that the court could not find the 
defendant guilty beyond a reasonable douhi. 
a. Define Type I and Type I1 errors in a murder trial. 
b. Which of the two errors is the more serious? Explain. 
c. The court docs not, in general, know the values of a 
and p; but ideally, both should be small. One of these 
probabilities is assumed to be smaller than the other 
in a jury trial. Which one, and why'? 
d. The court system relies on the belief that the value of 
a is madc very small by requiring a unanimous vote 
before guilt is concluded. Explain why this is so. 
e. For a jury prejudiced against a guilty verdict as the 
trial begins, will the value of a increase or decrease? 
Explain. 
f. For a jury prejudiced against a guilty verdict as the 
trial begins, will the value of /3 increase or decrease'? 
Explain. 
6.12 A group of physicians subjected the polygraph (or lie 
detector) to the same careful testing given to medical 
diagnostic tests. They found that if 1,000 people were 
subjected to the polygraph and 500 told the truth and 
500 licd, the polygraph would indicate that approxi- 
mately 185 of the truth-tellers were liars and that 
approximately 120 of the liars were truth-tellers 
(Discover, 1986). 
a. In the application of a polygraph test, an individual is 
presumed to be a truth-teller (H,)) until "proven" a 
liar (H,). In this context, what is a Type I error? A 
Type I1 error'? 
b. According to the study, what is the probability (ap- 
proximately) that a polygraph test will result in a 
Type I error? A Type I1 error? 
6.13 According to Chemical Marketing Reporter (Feb. 20, 
1995), pharmaceutical companies spend $15 billion per 
year on research and development of new drugs. The 
pharmaceutical company must subject each new drug to 
lengthy and involved testing before receiving the neces- 
sary permission from the Food and Drug Administration 
(FDA) to market the drug.The FDA's policy is that the 
pharmaceutical company must provide substantial evi- 
dence that a new drug is safe prior to receiving FDA 

306 
CHAPTER 6 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
l 
ap roval, so that the FDA can confidently certify the 
f 
unique body characteristics. For example, a system 
sa ety of the drug to potential consumers. 
developed by Palmguard, Inc. tests the hypothesis 
I 
a. If the new drug testing were to be placed in a test of 
hypothesis framework, would the null hypothesis be 
H,: The proposed user is authorized 
that the drug is safe or unsafe? The alternative 
versus 
1 
hypothesis? 
b. Given the choice of null and alternative hypotheses 
in part a, describe Type I and Type I1 errors in terms 
of this application. Define a and P in terms of this 
application. 
c. If the FDA wants to be very confident that the drug 
is safe before permitting it to be marketed, is it more 
important that a or p be small? Explain. 
6.14 One of the most pressing problems in high-technology 
industries is computer security. Computer security is 
typically achieved by use of a password-a 
collection 
Ha: The proposed user is unauthorized 
I 
by checking characteristics of the proposed user's palm 
against those stored in the authorized users' data bank 
(Omni, 
1984). 
a. Define a Type I error and Type I1 error for this test. 
Which is the more serious error? Why? 
b. Palmguard reports that the Type I error rate for its 
, 
system is less than 1%, whereas the Type I1 error 
rate is .00025%. Interpret these error rates. 
c. Another successful security system, the EyeDentify- 
dfsymbok (usually letters and numbers) that must be 
er, "spots authorized computer users by reading the 
supplied by the user before the computer permits access 
one-of-a-kind patterns formed by the network of 
to the account. The problem is that persistent hackers 
minute blood vessels across the retina at the back of 
can create programs that enter millions of combinations 
the eye." The EyeDentifyer reports Type I and IS 
of symbols into a target system until the correct pass- 
error rates of .01% (1 in 10,000) and .005% (5 in 
word is found. The newest systems solve this problem 
100,000), respectively. Interpret these rates. 
by requiring authorized users to identify themselves by 
LARGE-SAMPLE TEST OF HYPOTHESIS ABOUT A 
POPULATION MEAN 
In Section 6.1 we learned that the null and alternative hypotheses form the basis 
for a test of hypothesis inference. The null and alternative hypotheses may take 
, 
one of several forms. In the sewer pipe example we tested the null hypothesis that 
the population mean strength of the pipe is less than or equal to 2,400 pounds per 
linear foot against the alternative hypothesis that the mean strength exceeds 
2,400. That is, we tested 
This is a one-tailed (or one-sided) statistical test because the alternative hypothe- 
- - 
sis specifies that the population parameter (the population mean p, in this exam- 
ple) is strictly greater than a specified value (2,400, in this example). If the null 
hypothesis had been H,): p 2 2,400 and the alternative hypothesis had been 
Ha: p < 2,400, the test would still be one-sided, because the parameter is still 
specified to be on "one side" of the null hypothesis value. Some statistical investi- 
gations seek to show that the population parameter is either larger or smaller 
than some specified value. Such an alternative hypothesis is called a two-tailed (or 
two-sided) hypothesis. 
While alternative hypotheses are always specified as strict inequalities, such 
as p < 2,400, p > 2,400, or p f 2,400, null hypotheses are usually specified as 
equalities, such as p = 2,400. Even when the null hypothesis is an inequality, such 
as p 9 2,400, we specify Ho: p = 2,400, reasoning that if sufficient evidence exists 
to show that Ha: p > 2,400 is true when tested against Ho: p = 2,400, then surely 
sufficient evidence exists to reject p < 2,400 as well. Therefore, the null hypothesis , 
is specified as the value of p closest to a one-sided alternative hypothesis and as the 

SECTION 6.2 
Large-Sample Test of Hypothesis About a Population Mean 
307 
FIGURE 6.4 
Rejection regions 
corresponding to one- and 
two-tailed tests 
only value not specified in a two-tailed alternative hypothesis.The steps for select- 
ing the null and alternative hypotheses are summarized in the accompanying box. 
ps for Selecting 
ve Hypotheses 
. Select the alternativ 
thesis as that which the sampling experiment 
lish. The alternative hypothesis will assume one of 
Example: Ha: ,u > 2,400 
b. One-tailed, lower-tailed 
Example: Ha: p < 2,400 
c. Two-tailed 
Example: Ha: p # 2,400 
2. Select the null hyporhe~is as the status quo, that which will be presumed 
true unless the sampling experiment conclusively establishes the alter- 
native hypothesis. The null hypothesis will be specified as that parameter 
value closest to the alternative in one-tailed tests, and as the comple- 
mentary (or only unspecified) value in two-tailed tests. 
The rejection region for a two-tailed test differs from that for a one-tailed 
test. When we are trying to detect departure from the null hypothesis in either di- 
rection, we must establish a rejection region in both tails of the sampling distrib- 
ution of the test statistic. Figures 6.4a and 6.4b show the one-tailed rejection 
regions for lower- and upper-tailed tests, respectively. The two-tailed rejection re- 
gion is illustrated in Figure 6.4~. 
Note that a rejection region is established in 
each tail of the sampling distribution for a two-tailed test. 
0 
a. Form of Ha: < 
0 
b. Form of Ha: > 
0 
c. Form of Ha: + 
The rejection regions corresponding to typical values selected for a are 
shown in Table 6.2 for one- and two-tailed tests. Note that the smaller a you select, 
the more evidence (the larger z )  you will need before you can reject H,. 
TABLE 
6.2 Rejection Regions for Common Values of a 
Alternative Hypotheses 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Lower-Tailed 
Upper-Tailed 
Two-Tailed 
A manufacturer of cereal wants to test the performance of one of its filling 
machines. The machine is designed to discharge a mean amount of p = 12 ounces 
per box, and the manufacturer wants to detect any departure from this setting. 

308 
 CHAPTER^ 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
(L 
This quality study calls for randomly sampling 100 boxes from today's production 
run and determining whether the mean fill for the run is 12 ounces per box. Set up 
a test of hypothesis for this study, using a = .01. (In Chapter 11, we describe how 
this problem can be addresed using control charts.) 
S 0 I U t i 0 n 
Since the manufacturer wishes to detect a departure from the setting of p = 12 in 
either direction, p < 12 or p > 12, we conduct a two-tailed statistical test. 
Following the procedure for selecting the null and alternative hypotheses, we 
specify as the alternative hypothesis that the mean differs from 12 ounces, since 
detecting the machine's departure from specifications is the purpose of the quality 
control study. The null hypothesis is the presumption that the fill machine is 
operating properly unless the sample data indicate otherwise. Thus, 
The test statistic measures the number of standard deviations between the 
observed value of T and the null hypothesized value p = 12: 
- 
x - 12 
Test statistic: - 
u, 
The rejection region must be designated to detect a departure from p = 12 
in either direction, so we will reject H,, for values of z that are either too small 
(negative) or too large (positive). To determine the precise values of z that com- 
prise the rejection region, we first select a, the probability that the test will lead to 
incorrect rejection of the null hypothesis. Then we divide a equally between the 
lower and upper tail of the distribution of z, as shown in Figure 6.5. In this exam- 
ple, a = 0.1, so a12 = .005 is placed in each tail. The areas in the tails correspond 
to z = -2.575 and z = 2.575, respectively (from Table 6.2): 
Rejection region: z < -2.575 or z > 2.575, (see Figure 6.5) 
FIGURE 6.5 
Two-tailed rejection region: a = .O1 
z = - 2k75 
z = 2.575 
I 
Computed z = - 3.0 
Axsumptions: Since the sample size of the experiment is large enough (n > 30). 
the Central Limit Theorem will apply, and no assumptions need be made about 
the population of fill measurements. The sampling distribution of the sample 
mean fill of 100 boxes will be approximately normal regardless of the distribution 
of the individual boxes' fills. 
Note that the test in Example 6.1 is set up before the sampling experiment is 
conducted.The data are not used to develop the test. Evidently, the manufacturer 
does not want to disrupt the filling process to adjust the machine unless the sam- 

SECTION 6.2 
L a r g e - S a m p l e  Test of H y p o t h e s i s  A b o u t  a P o p u l a t i o n  Mean 
309 
ple data provide very convincing evidence that it is not meeting specifications, be- 
cause the value of a has been set quite low at .01. If the sample evidence results in 
the rejection of H,, the manufacturer can be 99% confident that the machine 
needs adjustment. 
Once the test is set up, the manufacturer is ready to perform the sampling 
experiment and conduct the test. The test is performed in Example 6.2. 
---.--*a"-.e-- 
-.. 
Refer to the quality control test set up in Example 6.1. Supposc the samplc yields 
the following results: 
- 
n = 100 observations 
x = 11.85 ounces 
s = .5 ounce 
Use these data to conduct the test of hypothesis. 
S o l u t i o n  Since the test is completely specified in Example 6.1, we simply substitute the 
sample statistics into the test statistic: 
The implication is that the sample mean, 11.85, is (approximately) 3 standard de- 
viations below the null hypothesized value of 12.0 in the sampling distribution of 
- 
x. You can see in Figure 6.5 that this value of z is in the lower-tail rejection region, 
which consists of all values of z < -2.575. These sample data provide sufficient 
evidence to reject H,, and conclude, at the a = .O1 level of significance, that the 
mean fill differs from the specification of p = 12 ounces. It appears that the ma- 
chine is, on average, underfilling the boxes. 
* 
Two final points about the test of hypothesis in Example 6.2 apply to all sta- 
tistical tests: 
Since z is less than -2.575, it is tempting to state our conclusion at a sig- 
nificance level lower than a = .01. We resist the temptation because the 
level of a is determined before the sampling experiment is performed. If 
we decide that we are willing to tolerate a 1 % Type I error rate, the result 
of the sampling experiment should have no effect on that decision. In 
general, the same data should not be used both to set up and to conduct the 
test. 
When we state our conclusion at the .O1 level of significance, we are refer- 
ring to the failure rate of the procedure, not the result of this particular test. 
We know that the test procedure will lead to the rejection of the null 
hypothesis only 1% of the time when in fact p = 12. Therefore, when the test 
statistic falls in the rejection region, we infer that the alternative p .f 12 is 
true and express our confidence in the procedure by quoting the a level of sig- 
nificance, or the 100(1 - a) % confidence level. 
The setup of a large-sample test of hypothesis about a population mean is 
summarized in the following box. Both the one- and two-tailed tests are shown. 

310 
 CHAPTER^ 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  Sample 
ne-Tailed Test 
ptions need to be 
bil~ty d~stribution of 
he population because the Central Limit Theorem assures us that, for large samples, 
statistic will be approximately normally distributed regardless of the shape of 
rlying probability distribution of the population. 
Note: po is the symbol for the numerical value assigncd to p undcr the null 
hypothcsis. 
Once the test has been set up, the sampling experiment is performed and the 
test statistic calculated.The next box contains possible conclusions for a test of hy- 
pothesis, depending on the result of the sampling experiment. 
egion, reject H,) and 
conclude that the alternative hypothesis H, is true. State that you are 
rejecting H, at the a level of significance. Remember that the confi- 
dence is in the testingprocess, not the particular result of a single test. 
2. If the test statistic does not fall in the rejection region, conclude that the 
Learning the Mechanics 
6.15 For each of the following rejection regions, sketch the 
sampling distribution for z and ind~cate the location of 
the rejection region. 
a. z > 1.96 
b. z > 1.645 c. z > 2.575 
d. z < -1.28 
e. z < -1.645orz > 1.645 
f. z < -2.575 or z > 2.575 
g. For each of the rejection regions specified in parts a-f, 
what is the probability that aType I error will be made? 
6.16 Suppose you are interested in conducting the statistical 
test of H,,: p = 255 against Ha: p > 255, and you have 
decided to use the following decision rule: Reject H, if 
the sample mean of a random sample of 81 items is 
more than 270. Assume that the standard deviation of 
the population is 63. 
a. Express the decision rule in terms of z. 
b. Find a, the probability of making a Type I error. hy 
using this decision rule. 

SECTION 6.2 
L a r g e - S a m p l e  T e s t  of H y p o t h e s i s  A b o u t  a P o p u l a t i o n  M e a n  
311 
6.17 A random sample of 100 observations from a population 
with stardard deviation 60 yielded a sample mean of 110. 
a. Test the null hypothesis that p = 100 against the al- 
ternative hypothesis that p > 100 using n = .05. In- 
terpret the results of the test. 
b. Test the null hypothesis that p = 100 against the al- 
ternative hypothesis that p # 100 using u = .05. In- 
terpret the results of the test. 
c. Compare the results of the two tests you conducted. 
Explain why the results differ. 
6.18 A random sample of 64 observations produced the fol- 
lowing summary statistics: i = .323 and s2 = .034. 
a. Test the null hypothesis that p = .36 against the al- 
ternative hypothesis that p < .36 using a = .lo. 
b. Test the null hypothesis that p = .36 against the al- 
ternative hypothesis that p # .36 using u = .lo. In- 
terpret the result. 
Applying the Concepts 
6.19 During the National Football League (NFL) season, Las 
Vegas oddsmakers establish a point spread on each game 
for betting purposes. For example, the St. Louis Rams 
were established as 7-point favorites over the Tennessee 
Titans in the 2000 Super Bowl. The final scores of NFL 
games were compared against the final point spreads 
established by the oddsmakers in Chance (Fall 1998).The 
difference between the game outcome and point spread 
(called a point-spread error) was calculated for 240 NFL 
games. The mean and standard deviation of the point- 
spread errors are y = -1.6 and s = 13.3. Use this infor- 
mation to test the hypothesis that the true mean 
point-spread error for all NFL games is 0. Conduct the 
test at a! = .O1 and interpret the result. 
6.20 According to the National Funeral Directors 
Association, the nation's 22,000 funeral homes collected 
an average $5,020 per full-service funeral in 1998, up 
from $4,780 in 1996 (Wall Street Journal Interactive 
Edition, Jan. 7,2000). In early 2000, a random sample of 
36 funeral homes reported revenue data for 1999. 
Among other measures, each reported its average fee 
for a full-service funeral during 1999. These data (in 
thousands of dollars) are shown in the table below, 
rounded to the nearest hundred. 
6.1 
8.1 
4.0 
7.1 
6.2 
5.2 
4.9 
7.0 
5.4 
10.3 
5.0 
4.6 
5.4 
4.5 
3.9 
5.1 
4.7 
6.1 
5.9 
5.3 
5.0 
4.0 
5.3 
4.3 
7.1 
5.9 
6.1 
4.5 
5.0 
4.8 
5.7 
5.9 
4.8 
4.1 
6.1 
5.3 
a. What are the appropriate null and alternative hy- 
potheses to test whethcr the average full-service fee 
of U. S. funeral homes in 1999 exceeds $5,020? 
b. Conduct the test at n = .05 using a statistical soft- 
ware package. Do the sample data provide sufficient 
evidence to conclude that the average fee in 1999 
was higher than in 1998? 
c. In conducting the test, was it necessary to assume 
that population of average full-service fees was nor- 
mally distributed? Justify your answer. 
6.21 Most major corporations have psychologists available 
to help employees who suffer from stress. One problem 
that is difficult to diagnose is post-traumatic stress dis- 
order (PTSD). Researchers studying PTSD often use 
as subjects former prisoners of war (POWs). 
Psychological Assessment (Mar. 1995) published the 
results of a study of World War I1 aviators who were 
captured by German forces after they were shot down. 
Having located a total of 239 World War I1 aviator 
POW survivors, the researchers asked each veteran to 
participate in the study; 33 responded to the letter of 
invitation. Each of the 33 POW survivors was adminis- 
tered the Minnesota Multiphasic Personality Inventory, 
one component of which measures level of PTSD. 
[Note: The higher the score, the higher the level of 
PTSD.] The aviators produced a mean PTSD score of 
- 
x = 9.00 and a standard deviation of s = 9.32. 
a. Set up the null and alternative hypotheses for deter- 
mining whether the true mean PTSD score of all 
World War I1 aviator POWs is less than 16. [Note: 
The value, 16, represents the mean PTSD score es- 
tablished for Vietnam POWs.] 
b. Conduct the test, part a, using a = .lo. What are the 
practical implications of thc test? 
c. Discuss the representativeness of the sample used in 
the study and its ramifications. 
6.22 A study reported in the Journal of Occupational and 
Organizational Psychology (Dec. 1992) investigated the 
relationship of employment status to mental health. A 
sample of 49 unemployed men was given a mental 
health examination using the General Health 
Questionnaire (GHQ).The GHQ is a widely recognized 
measure of present mental health, with lower values 
indicating better mental health. The mean and standard 
deviation of the GHQ scores were i = 10.94 and 
s = 5.10, respectively. 
a. Specify the appropriate null and alternative hy- 
potheses if we wish to test the research hypothesis 
that the mean GHQ score for all unemployed men 
exceeds 10. Is the test one-tailed or two-tailed? Why? 
b. If we specify a = .05, what is the appropriate rejec- 
tion region for this test? 
c. Conduct the test, and state your conclusion clearly in 
the language of this exercise. 
6.23 In quality control applications of hypothesis testing, 
the null and alternative hypotheses are frequently 
specified as 
H,: The production process is performing satisfactorily 

312 
 CHAPTER^ 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
Ha: The process is performing in an unsatisfactory manner 
SAS Output for Exercise 6.23 
Accordingly, a is sometimes referred to as the pro- 
ducer's risk, while p is called the consumer's risk 
(Stevenson, Production/Operations Management, 1996). 
An injection molder produces plastic golf tees. The 
process is designed to produce tees with a mcan weight 
of ,250 ounce. To investigate whether the injection 
molder is operating satisfactorily, 40 tees were random- 
ly samplcd from thc last hour's production. Their 
weights (in ounces) are listed in the table above. 
Summary statistics for the data are shown in the SAS 
printout at the top of this page. 
a. Do the data provide sufficient evidence to conclude 
that the process is not operating satisfactorily? Test 
using a = .O1 
b. In the context of this problem, explain why it makes 
sense to call a the producer's risk and P the con- 
sumer's risk. 
6.24 What factors inhibit the learning process in the class- 
room? To answer this question, researchers at Murray 
State University surveyed 40 students from a senior-level 
marketing class (Marketing Education Review, Fall 1994). 
Each student was given a list of factors and asked to rate 
the extent to which each factor inhibited the learning 
process in courses offered in their department. A 7-point 
rating scale was used, where I = "not at all" and 7 = 
"to a great extent."The factor with the highest rating was 
instructor-related: "Professors who place too much 
emphasis on a single right answer rather than overall 
thinking and creative ideas." Summary statistics for the 
student ratings of this factor are: i = 4.70, s = 1.62. 
a. Conduct a test to determine if the true mean rating 
for this instructor-related factor exceeds 4. Use 
a = .05. Interpret the test results. 
m 
SPSS Output for Exercise 6.25 
Analysis Variable : WEIGHT 
I 
b. Because the variable of interest, rating, is measured 
on a 7-point scale, it is unlikely that the population of 
ratings will be normally distributed. Consequently, 
some analysts may perceive the test, part a, to be in- 
valid and scarch for alternative methods of analysis. 
Defend or refute this argument. 
Current technology uses X-rays and lasers for inspec- 
tion of solder-joint defects on printed circuit boards 
(PCBs) (Quality Congress Transactions, 1986). A par- 
ticular manufacturer of laser-based inspection equip- 
ment claims that its product can inspect on average at 
least 10 solder joints per second when the joints are 
spaced .1 inch apart. The equipment was tested by a 
potential buyer on 48 different PCBs. In each case, the 
equipment was operated for exactly 1 second. The 
number of solder joints inspected on each run follows: 
a. The potential buyer wants to know whether the sam- 
ple data refute the manufacturer's claim. Specify the 
null and alternative hypotheses that the buyer should 
test. 
b. In the context of this exercise, what is aType I error? 
A Type I1 error? 
c. Conduct the hypothesis test you described in part a, 
and mterpret the test's results in the context of this 
exercise. Use a = .05 and the SPSS descriptive sta- 
tistics printout at the bottom of the page. 
6.26 A company has devised a new ink-jet cartridge for its 
plain-paper fax machine that it believes has a longer 
lifetime (on average) than the one currently being pro- 
duced. To investigate its length of life, 225 of the new 
cartridges were tested by counting the number of high- 
quality printed pages each was able to produce. The 
sample mean and standard deviation were determined 
to be 1,511.4 pages and 35.7 pages, respectively.The his- 
I 
Variable 
Mean 
Std Dev 
Minimum 
Maximum 
N Label 
NUMBER 
9.29 
2.10 
.00 
13.00 
48 
1 

SECTION 6.3 
O b s e r v e d  S i g n i f i c a n c e  Levels: p-Values 
313 
torical average lifetime for cartridges produced by the 
current Pocess is 1,502.5 pages; the historical standard 
deviation is 97.3 pages. 
a. What are the appropriate null and alternative hy- 
potheses to test whether the mean lifetime of the 
new cartridges exceeds that of the old cartridges? 
b. Use cu = .005 to conduct the test in part a. Do the 
new cartridges have an average lifetime that is statis- 
tically significantly longer than thc cartridges cur- 
rently in production? 
c. Does the difference in average lifetimes appear to be 
of practical significance from the perspective of the 
consumer'? Explain. 
d. Should the apparent decrease in the standard devia- 
tion in lifetimes associated with the new cartridges 
be viewed as an improvement over the old car- 
tridges? Explain. 
6.27 Nutritionists stress that weight control generally 
requires significant reduct~ons in the intake of fat. A 
random sample of 64 middle-aged men on weight con- 
trol programs is selected to determine whether their 
mean intake of fat excccds the recommended 30 grams 
per day. The sample mean and standard dev~ation are 
- 
x = 37 and s = 32, respectively. 
a. Considering the sample mean and standard devia- 
tion, would you expcct the distribut~on for fat intake 
per day to be symmetric or skewed? Explain. 
b. Do the sample results indicate that the mean intake 
for middle-aged men on weight control programs ex- 
ceeds 30 grams'? Test using a = .10. 
C. Would you reach the same conclusion as in part b 
using a = .05? Using a = .01? Why can the conclu- 
sion of a test change when the value of a is 
changed? 
OBSERVED SIGNIFICANCE LEVELS: p-VALUES 
According to the statistical test procedure described in Section 6.2, the rejection re- 
gion and, correspondingly, the value of a are selected prior to conducting the test, and 
the conclusions are stated in terms of rejecting or not rejecting the null hypothesis.A 
second method of presenting the results of a statistical test is one that reports the ex- 
tent to which the test statistic disagrees with the null hypothesis and leaves to the 
reader the task of deciding whether to reject the null hypothcsis.This measure of dis- 
agreement is called the observed significance level (or p-value) for the test. 
DEFINITION 6.1 
The observed significance level, or p-value, for a specific statistical test is the 
probability (assuming H, is true) of observing a value of the test statistic that 
is at least as contradictory to the null hypothesis, and supportive of the alter- 
native hypothesis, as the actual one computed from the sample data. 
For example, the value of the test statistic computed for the sample of n = 50 
sections of sewer pipe was z = 2.12. Since the test is one-tailed-i.e., 
the alternative 
(research) hypothesis of interest is Ha: p, > 2,400-values 
of the test statistic even 
more contradictory to H,, than the one observed would be values larger than 
z = 2.12. Therefore, the observed significance level (p-value) for this test is 
p-value = P(z > 2.12) 
or, equivalently, the area under the standard normal curve to the right of z = 2.12 
(see Figure 6.6). 
FIGURE 6.6 
Finding the p-value for an upper-tailed 
test when z = 2.1 2 
z 
2.12 

314 
 CHAPTER^ 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
FIGURE 6.7 
Finding the p-value for a one- 
tailed test 
FIGURE 6.8 
Finding the p-value for a two- 
tailed test: p-value = 2(p/2) 
The area A in Figure 6.6 is given in Table TV in Appendix B as .4830. There- 
fore, the upper-tail area corresponding to z = 2.12 is 
p-value = .5 - .4830 = .0170 
Consequently, we say that these test results are "very significant"; i.e., they dis- 
agree rather strongly with the null hypothesis, H,): p = 2,400, and favor Ha: 
p > 2,400. The probability of observing a z value as large as 2.12 is only .0170, if 
in fact the true value of p is 2,400. 
If you are inclined to select a = .05 for this test, then you would reject the 
null hypothesis because the p-value for the test, .0170, is less than .05. In contrast, 
if you choose a = .Ol, you would not reject the null hypothesis because the p-value 
for the test is larger than .01. Thus, the use of the observed significance level is 
identical to the test procedure described in the preceding sections except that 
the choice of a is left to you. 
The steps for calculating the p-value corresponding to a test statistic for a 
population mean are given in the next box. 
s t  of Hypothesis 
. Determine the value of the test statistic z corresponding to the result of 
the sampling experiment. 
a. If the test is one-tailed, the p-value is equal to the tail area beyond z 
in the same direction as the alternative hypothesis. Thus, if the alter- 
native hypothesis is of the form > , the p-value is the area to the 
right of, or above, the observed z value. Conversely, if the alternative 
is of the form < , the p-value is the area to the left of, or below, the 
observed z value. (See Figure 6.7.) 
b. If the test is two-tailed, the p-value is equal to twice the tail area beyond 
the observed z value in the direction of the sign of z. That is, if z is 
positive, the p-value is twice the area to the right of, or above, the ob- 
ved z value. Conversely, if z is negative, the p-value is twice the 
to the left of, or below, the observed z value. (See Figure 6.8.) 
Tesi statistic 
Test statistic 
z 
a. Lower-tailed test, Ha: 1 < lo 
b. Upper-tailed test, Ha: > ko 
Test statistic 
Test statistic 
z 
Z 
a. Test statistic z negative 
b. Test statistic z positive 

SECTION 6.3 
O b s e r v e d  S i g n i f i c a n c e  L e v e l s :  p - V a l u e s  
315 
--- 
Find the obscrvcd significance level for thc test of the mean filling weight in 
Examples 6.1 and 6.2. 
S 0 I U t i 0 n Example 6.1 presented a two-tailed test of the hypothesis 
H,: p = 12 ounces 
against the alternative hypothesis 
Ha: p Z 12 ounces 
The observed value of the test statistic in Example 6.2 was z = -3.0, and any 
value of z less than -3.0 or greater than +3.0 (because this is a two-tailed test) 
would be even more contradictory to H,. Therefore, the observed significance 
level for the test is 
p-value = P(z < -3.0 or z > +3.0) = P((z1 > 3.0) 
Thus, we calculate the area below the observed z value, z = -3.0, and dou- 
ble it. Consulting Table IV in Appendix B, we find that P(Z < -3.0) = 
.5 - ,4987 = .0013. Therefore, the p-value for this two-tailed test is 
We can interpret this p-value as a strong indication that the machine is not 
filling the boxes according to specifications, since we would observe a test statistic 
this extreme or more extreme only 26 in 10,000 times if the machine were meeting 
specifications (p = 12). The extent to which the mean differs from 12 could be 
better determined by calculating a confidence interval for p. 
When publishing the results of a statistical test of hypothesis in journals, case 
studies, reports, etc., many researchers make use of p-values. Instead of selecting a 
beforehand and then conducting a test, as outlined in this chapter, the researcher 
computes (usually with the aid of a statistical software package) and reports the 
value of the appropriate test statistic and its associated p-value. It is left to the 
reader of the report to judge the significance of the result-i.e., 
the reader must 
determine whether to reject the null hypothesis in favor of the alternative hy- 
pothesis, based on the reported p-value. Usually, the null hypothesis is rejected if 
the observed significance level is less than the fixed significance level, a, chosen by 
the reader. The inherent advantage of reporting test results in this manner are 
twofold: (1) Readers are permitted to select the maximum value of a that they 
would be willing to tolerate if they actually carried out a standard test of hypoth- 
esis in the manner outlined in this chapter, and (2) a measure of the degree of sig- 
nificance of the result (i.e., the p-value) is provided. 
2. If the observed significance level (p-value) of the test is less than the 
chosen value of a, reject the null hypothesis. Otherwise, do not reject the 
null hypothesis. 

316 
 CHAPTER^ 
I n f e r e n c e s  Based on a S i n g l e  S a m p l e  
FIGURE 6.9 
MINITAB printout for the 
lower-tailed test in Example 6.4 
S o l u t i o n  
Knowledge of the amount of time a patient occupies a hospital bed-called 
length 
of stay (L0S)-is 
important for allocating resources. At one hospital. the mean 
length of stay was determined to be 5 days. A hospital administrator believes that 
the mean LOS may now be less than 5 days due to a newly adopted managed care 
system. To check this, the LOSS (in days) for 100 randomly selected hospital 
patients were recorded; these are listed in Table 6.3. Test the hypothesis that the 
true mean LOS at the hospital is less than 5 days, i.e., 
Ho: p = 5 
Ha: p < 5 
Use the data in the table to conduct the test at a = .05. 
TABLE 
6.3 
Lengths of Stay for 100 Hospital Patients 
2
3
8
6
4
4
6
4
2
5
 
8
1
0
 
4
 4
 4
 2
 1
3
2
1
0
 
1
3
2
3
4
3
5
2
4
1
 
2
9
1
7
1
7
9
9
9
4
4
 
1
1
1
3
1
6
3
3
2
5
 
TEST OF MU = 5.000 VS MU L.T. 5.000 
THE ASSUMED SIGMA = 3.68 
N 
MEAN 
STDEV 
SE MEAN 
Z 
P VALUE 
LOS 
100 
4.530 
3.678 
0.368 
-1.28 
0.10 
Instead of performing the computations by hand, we will use a statistical software 
package.The data were entered into a computer and MINITAB was used to conduct 
the analysis.The MINITAB printout for the lower-tailed test is displayed in Figure 6.9. 
Both the test statistic, z = - 1.28, and p-value of the test, p = .lo, are highlighted on 
the MINITAB printout. Since thep-value exceeds our selected a value, a = .05, we 
cannot reject the null hypothesis. Hence, there is insufficient evidence (at a = .05 
conclude that the true mean LOS at the hospital is less than 5 days. 
Note: Some statistical software packages (e.g., SAS and SPSS) will conduct 
only two-tailed tests of hypothesis. For these packages, you obtain the p-value for 
a one-tailed test as shown in the box: 
H, is of form > and z is positive 
Ha is of form < and z is negative 
Ha is of form > and z is negative 
Ha is of form < and z is positive 

SECTION 6.3 
O b s e r v e d  S i g n i f i c a n c e  L e v e l s :  p - V a l u e s  
317 
Hypothesis Testing 
U S I N G  THE T I - 8 3  GRAPHING CALCULATOR 
Computing the p-value for a I-Test. 
Start from the honie screen. 
Step 1 Access the "Statistical Test" Menu. 
Press 
STAT 
Note I: p, is the as- 
Arrow right to TESTS 
sumed population 
Press 
ENTER 
mean, a is the popula- 
Arrow right to STATS 
tion standard deviation, 
Press 
ENTER 
x is the sample mean, 
Set 
po: See Note I J - 
and n is the sample size. 
m: 
I r r l  
- 
X :  
IIII 
: 
11 11 
p: See Note I1 
Note 11: Recall: yov 
Press 
ENTER 
always test Ha! 
Arrow down to 
Arrow to highlight the 
Press 
ENTER 
appropriate test. 
Sten 2 View Dis~lav 
L
,
 
The chosen test will be displayed as well as the z-test statistic, the 
p-value, the sample mean, and the sample size. 
Example: A manufacturer claims themerage life expectancy of this partic- 
ular model light bulb is 10,000 hours with a = 1,000 hours. A 
simple random sample of 40 light bulbs shows x = 9,755 hours. 
Using a = .05 test the manufacturer's claim. 
For this problem the hypotheses will be: H,: p > =10,000 
Ha: p < 10,000 
Step 1 Access the Statistical Test Menu. Enter your setting for this problem 
(see the screen below left). ' 
>v. 0 
Draw 
Arrow down to Calculate and press ENTER (screen above right 
will be displayed). 
Step 2 View Display. As you can see the p-value is 0.061. RecaM, we reject 
H, only if p < ,a. Therefore do'not reject H,. 
Step 3 Clear the screen for the next problem. Return to the home screen. 
Press CLEAR. 

318 
 CHAPTER^ 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
Learning the Mechanics 
6.28 It a hypothesis test were conducted using a = .05, for 
which of the following p-values would the null hypoth- 
esis be rejected? 
a..06 
b..10 
c..01 d. ,001 e..251 
f..042 
6.29 For each a and observed significance level (p-value) 
pair, indicate whether the null hypothesis would be 
rejected. 
a. a = .05, p-value = .lo 
b. a = .lo, p-value = .05 
c. a = .01, p-value = .001 
d. a = .025,p-value = .05 
e. a = .lo, p-value = .45 
6.30 An analyst tested the null hypothesis p 2 20 against the 
alternative hypothesis that p < 20. The analyst report- 
ed a p-value of .06. What is the smallest value of a for 
which the null hypothesis would be rejected? 
6.31 In a test of H,: p = 100 against Ha: p > 100, the sample 
data yielded the test statistic z = 2.17. Find thep-value 
for the test. 
6.32 In a test of the hypothesis Ho: p = 10 versus 
Ha: p Z 10, a sample of n = 50 observations possessed 
mean i = 10.7 and standard deviation s = 3.1. Find and 
interpret the p-value for this test. 
6.33 Consider a test of H,,: p = 75 performed using the com- 
puter. SAS reports a two-tailed p-value of .1032. Make 
the appropriate conclusion for each of the following 
situations: 
a. Ha: p < 75, z = -1.63, a = .05 
b. Ha: p < 75, z = 1.63, a = .10 
C. Ha: p > 75, z = 1.63, a = .I0 
Applying the Concepts 
6.34 According to USA Today (Dec. 30,1999), the average 
age of viewers of MSNBC cable television news pro- 
gramming is 50 years. A random sample of 50 U. S. 
households that receive cable television programming 
yielded the following additional information about the 
ages of MSNBC news viewers: 
5 = 51.3 years 
and 
s = 7.1 years 
Do the sample data provide sufficient evidence to con- 
clude that the average age of MSNBC's viewers is 
greater than 50 years? 
a. Conduct the appropriate hypothesis test. 
b. Calculate the observed significance level of the test 
and interpret its value in the context of the problem. 
c. Would the p-value have been larger or smaller if 7 
had been larger? Explain. 
Research published in Nature (Aug. 27,1998) revealed 
that people are, in fact, more attracted to "feminized" 
faces, regardless of gender. In one experiment, 50 human 
subjects viewed both a Japanese female and a 
Caucasian male face on a computer. Using special 
computer graphics, each subject could morph the 
faces (by making them more feminine or more mas- 
culine) until they attained the "most attractive" face. 
The level of feminization x (measured as a percent- 
age) was measured. 
a. For the Japanese female face, i = 10.2% and 
s = 31 3%. The researchers used this sample infor- 
mation to test the null hypothesis of a mean level of 
feminization equal to O%.Verify that the test statistic 
is equal to 2.3. 
b. Refer to part a. The researchers reported the p-value 
of the test as p = ,027. Verify and interpret this result. 
c. For the Caucasian male face, 7 = 15.0% and 
s = 25.1%. The researchers reported the test statistic 
(for the test of the null hypothesis stated in part a) as 
4.23 with an associated p-value of approximately 0. 
Verify and interpret these results. 
6.36 Refer to the Wall Street JournaliNational Funeral 
Directors Association study of the average-fee charged 
for a full-service funeral during 1999, Exercise 6.20 
(p. 311). Recall that a test was conducted to determine 
if the true mean fee charged exceeds $5,020. The data 
(recorded in thousands of dollars) for the sample of 
36 funeral homes were analyzed using STATISTIX. 
The resulting printout of the test of hypothesis is 
shown here. 
STATlSTlX Output for Exercise 6.36 
ONE-SAMPLE T TEST FOR REVENUE 
NULL HYPOTHESIS: MU = 5.02 
ALTERNATIVE HYP: MU > 5.02 
MEAN 
STD ERROR 
MEAN - HO 
LO 95% CI 
UP 95% CI 
T 
DF 
P 
I CASES INCLUDED 36 
MISSING CASES 0 I 
6.35 Television commercials most often employ females, 
a. Locate the p-value for this upper-tailed test of 
or "feminized" males, to pitch a company's product. 
hypothesis. 

SECTION 6.4 
S m a l l - S a m p l e  Test o f  H y p o t h e s i s  A b o u t  a P o p u l a t i o n  M e a n  
319 
b. Use the p-value to make a decision regarding the 
null hypothesis tested. Does the decision agree with 
your decision in Exercise 6.20? 
6.37 In Exercise 5.8 (p. 266) we examined research about 
bicycle helmets reported in Public Health Reports 
(May-June 1992). One of the variables measured was 
the children's perception of the risk involved in bicy- 
cling. A random sample of 797 children in grades 4-6 
were asked to rate their perception of bicycle risk with- 
out wearing a helmet, ranging from 1 (no risk) to 4 
(very high risk). The mean and standard deviation of 
the sample were i = 3.39, s = 80, respectively. 
a. Assume that a mean score, p, of 2.5 is indicative of 
indifference to risk, and values of p exceeding 2.5 
indicate a perception that a risk exists. What are the 
appropriate null and alternative hypotheses for tcst- 
ing the research hypothesis that children in this age 
group perceive a risk associated with failure to wear 
helmets? 
b. Calculate the p-value for the data collected in this 
study. 
c. Interpret the p-value in the context of this research. 
638 Refer to Exercise 6.22 (p. 311), in which a random 
sample of 49 unemployed men were administered the 
General Health Questionnaire (GHQ). The sample 
mean and standard deviation wcrc 10.94 and 5.10, 
respectively. Denoting the population mean GHQ for 
unemployed workers by p, we wish to test the null 
hypothesis H,: p = 10 versus the one-tailed alternative 
Ha: p > 10. 
a. When the data are run through MINITAB, the re- 
sults (in part) are as shown in the printout below. 
Check the program's results for accuracy. 
b. What conclusion would you reach about the test 
based on the computer analysis? 
6.39 An article published in the Journal of the American 
MedicalAssociation (Oct. 16,1995) calls smoking in China 
"a public health emergency." The researchers found that 
smokers in China smoke an average of 16.5 cigarettes a 
day.The high smoking rate is one reason why the tobacco 
industry is the central government's largest source of tax 
revenue. Has the average number of cigarettes smoked 
per day by Chinese smokers increased over the past two 
years? Consider that in a random sample of 200 Chinese 
smokers in 1997, the number of cigarettes smoked per 
day had a mean of 17.05 and a standard deviation of 5.21. 
a. Set up the null and alternative hypotheses for testing 
whether Chinese smokers smoke, on average, more 
cigarettes a day in 1997 than in 1995. (Assume that 
the population mean for 1995 is p = 16.5.) 
b. Compute and interpret the observed significance 
level of the test. 
c. Why is a two-tailed test inappropriate for this 
problem? 
6.40 In Exercise 6.23 (p. 311) you tested H,: p = ,250 versus 
Ha: p f .250, where p is the population mean weight 
of plastic golf tees. A SAS printout for the hypothesis 
test is shown below. Locate the p-value on the printout 
and interpret its value. 
MINITAB Output for Exercise 6.38 
TEST OF MU = 10.00 VS MU G.T. 10.00 
THE ASSUMED SIGMA = 5.10 
N 
MEAN STDEV SE MEAN 
Z P VALUE 
GHQ 
49 10.94 
5.10 
0.73 
1.29 
.0985 
SAS Output for Exercise 6.40 
I Analysis Variable : WT-250 (Test Mean Weight=.250) 
SMALL-SAMPLE TEST OF HYPOTHESIS ABOUT A 
POPULATION MEAN 
A manufacturing operation consists of a single-machine-tool system that pro- 
duces an average of 15.5 transformer parts every hour. After undergoing a com- 
plete overhaul, the system was monitored by observing the number of parts 

320 
CHAPTER 
6 
Inferences Based on a Single Sample 
produced in each of seventeen randomly selected one-hour periods. The mean and 
standard deviation for the 17 production runs are: 
Does this sample provide sufficient evidence to conclude that the true mean num- 
ber of parts produced every hour by the overhauled system differs from 15.5? 
This inference can be placed in a test of hypothesis framework. We establish 
the preoverhaul mean as the null hypothesized value and utilize a two-tailed al- 
ternative that the true mean of the overhauled system differs from the preover- 
haul mean: 
H,: p = 15.5 
Ha: p + 15.5 
Recall from Section 5.3 that when we are faced with making inferences about 
a population mean using the information in a small sample, two problems emerge: 
1. The normality of the sampling distribution for i does not follow from the 
Central Limit Theorem when the sample size is small. We must assume that 
the distribution of measurements from which the sample was selected is 
approximately normally distributed in order to ensure the approximate nor- 
mality of the sampling distribution of i. 
2. If the population standard deviation a is unknown, as is usually the case, then 
we cannot assume that s  will provide a good approximation for (T when the 
sample size is small. Instead, we must use the t-distribution rather than the stan- 
dard normal z-distribution to make inferences about the population mean p. 
Therefore, as the test statistic of a small-sample test of a population mean, we use 
the t statistic: 
- 
- 
x - po 
x - 15.5 
- 
Test statistic: t = ----- - 
s / f i  
s / G  
where pO is the null hypothesized value of the population mean, p. In our exam- 
ple, po = 15.5. 
To find the rejection region, we must specify the value of a, the probability 
that the test will lead to rejection of the null hypothesis when it is true, and then 
consult the t-table (Table VI of Appendix B). Using a = .05, the two-tailed rejec- 
tion region is 
Rejection region: t+ = t,025 = 2.120 with n - 1 = 16 degrees of freedom 
Reject H, if t < -2.120 or t > 2.120 
The rejection region is shown in Figure 6.10. 
FIGURE 6.10 
Two-tailed rejection region for 
small-sample t -test 
Observed 
t = -2.06 

SECTION 6.4 
S m a l l - S a m p l e  Test of H y p o t h e s i s  A b o u t  a P o p u l a t i o n  Mean 
321 
We are now prepared to calculate the test statistic and reach a conclusion: 
Since the calculated value of t does not fall in the rejection region (Figure 6.10), 
we cannot reject H,, at the a = .05 level of significance. Based on the sample evi- 
dence, we should not conclude that the mean number of parts produced per hour 
by the overhauled system differs from 15.5. 
It is interesting to note that the calculated t value, -2.06, is less than the .05 
level z value, - 1.96. The implication is that if we had incorrectly used a z statistic 
for this test, we would have rejected the null hypothesis at the .05 level, conclud- 
ing that the mean production per hour of the overhauled system differs from 15.5 
parts. The important point is that the statistical procedure to be used must always 
be closely scrutinized and all the assumptions understood. Many statistical dis- 
tortions are the result of misapplications of otherwise valid procedures. 
The technique for conducting a small-sample test of hypothesis about a 
population mean is summarized in the following box. 
One-Tailed Test 
Two-Tailed Test 
- 
x - Po 
Test statistic: t = - 
Test statistic: t = 
s / G  
Rejection region: t < -t,, 
Rejection region: It / > to,, 
(or t > t, when Ha: > I.Ll,) 
................................................................................................................................................................... " 
where t, and t,,p are based on ( n - 1 ) degrees of freedom 
Assumption: A random sample is selected from a population with a relative frequen- 
meets new air pollution standards. The mean emission p of all engines of this 
type must be less than 20 parts per million of carbon. Ten engines are 
manufactured for testing purposes, and the emission level of each is determined. 
The data (in parts per million) are listed below: 
Do the data supply sufficient evidence to allow the manufacturer to con- 
clude that this type of engine meets the pollution standard? Assume that the pro- 
duction process is stable and the manufacturer is willing to risk a Type I error with 
probability a = .01. 
S o 1 U t i o n 
The manufacturer wants to support the research hypothesis that the mean 
emission level p for all engines of this type is less than 20 parts per million. The 
elements of this small-sample one-tailed test are 

322 
 CHAPTER^ 
Inferences Based on a s i n g l e  Sample 
I 
- 
x - 20 
Test statistic: t = - 
s/ 6 
Assumption: The relative frequency distribution of the population of emis- 
sion levels for all engines of this type is approximately normal. 
Rejection region: For a = .O1 and df = n - 1 = 9, the one-tailed rejection 
region (see Figure 6.1 1) is t < - t 
= -2.821. 
FIGURE 6.1 1 
A t-distribution with 9 df 
and the rejection region 
for Example 6.5 
- 
t 
-3.00 
i 
To calculate the test statistic, we entered the data into a computer and ana- 
lyzed it using SAS.The SAS descriptive statistics printout is shown in Figure 6.12. 
From the printout, we obtain i = 17.17, s = 2.98. Substituting these values into 
the test statistic formula, we get 
Since the calculated t falls in the rejection region (see Figure 6.11), the manufac- 
turer concludes that p < 20 parts per million and the new engine type meets the 
pollution standard. Are you satisfied with the reliability associated with this in- 
ference? The probability is only a = .O1 that the test would support the research 
hypothesis if in fact it were false. 
FIGURE 6.12 
SAS descriptive statistics 
for 10 emission levels 
5
I 
Find the observed significance level for the test described in Example 6.5. 
Analysis Variable : EMIT 
N ~ b s  N 
Minimum 
Maximum 
Mean 
Std Dev 
Interpret the result. 
S o I u t i 0 n 
The test of Example 6.5 was a lower-tailed test: H,: p = 20 versus Ha: p < 20. 
Since the value of t computed from the sample data was t = -3.00, the observed 
significance ievel (or p-value) for the test is equal to the probability that t would 
assume a value less than or equal to -3.00 if in fact No were true. This is equal to 
the area in the lower tail of the t-distribution (shaded in Figure 6.13). 
I 

SECTION 6.4 
Small-Sample Test of Hypothesis About a Population Mean 
323 
FIGURE 6.1 3 
with 9 df 
The observed significance level for the 
test of Example 6.5 
1 
h 
One way to find this area-i.e., 
the p-value for the test-is 
to consult the 
t-table (Table VI in Appendix B). Unlike the table of areas under the normal 
curve, Table VI gives only the t values corresponding to the areas .loo, .050, .025, 
.010, .005, .001, and .0005. Therefore, we can only approximate the p-value for the 
test. Since the observed t value was based on 9 degrees of freedom, we use the 
df = 9 row in Table VI and move across the row until we reach the t values that 
are closest to the observed t = -3.00. [Note: We ignore the minus sign.] The t val- 
ues corresponding to p-values of .010 and .005 are 2.821 and 3.250, respectively. 
Since the observed t value falls between to,, and to,,, the p-value for the test lies 
between .005 and .010. In other words, .005 < p-value < .O1. Thus, we would re- 
ject the null hypothesis, H,: p = 20 parts per million, for any value of a larger than 
.O1 (the upper bound of the p-value). 
A second, more accurate, way to obtain the p-value is to use a statistical soft- 
ware package to conduct the test of hypothesis. The SAS printout for the test of 
H,: p = 20 is displayed in Figure 6.14. Both the test statistic ( -3.00 ) and p-value 
(.0149) are highlighted in Figure 6.14. Recall (from Section 6.3) that SAS con- 
ducts, by default, a two-tailed test. That is, SAS tests the alternative Ha: p f 20. 
Thus, the p-value reported on the printout must be adjusted to obtain the appro- 
priate p-value for our lower-tailed test. Since the value of the test statistic is neg- 
ative and Ha is of the form < (i.e., the value of t agrees with the direction 
specified in Ha), the p-value is obtained by dividing the printout value in half: 
p-value 
Reported p-value 
?, 
F I G U R E  6.14 
SAS test of Hop = 20 for 
Example 6.1 6 
Analysis Variable : EMIT-20 
You can see that the actual p-value of the test falls within the bounds obtained 
from Table VI. Thus, the two methods agree; we will reject H,: p = 20 in favor of 
Ha: p < 20 for any a level larger than .01. 
Small-sample inferences typically require more assumptions and provide 
less information about the population parameter than do large-sample inferences. 
Nevertheless, the t-test is a method of testing a hypothesis about a population 
mean of a normal distribution when only a small number of observations are 
available. What can be done if you know that the population relative frequency 
distribution is decidedly nonnormal, say highly skewed? A nonparametric statis- 
tical method is described in optional Section 6.6. 

324 
CHAPTER 
6 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
Learning the Mechanics 
6.41 For each of the following rejection regions, sketch the 
sampling distribution of t, and indicate the location of 
the rejection region on your sketch: 
a. t > 1.440 where df = 6 
b. t < -1.782 where df = 12 
c. t < -2.060 or t > 2.060 where df = 25 
6.42 For each of the rejection regions defined in Exercise 6.41, 
what is the probability that a Type I error will be made? 
6.43 A random sample of n observations is selected from a 
normal population to test the null hypotheyis that 
p = 10. Specify the rejection region for each of the fol- 
lowing combinations of H,,, a, and n: 
a. Ha: p 1.2 10; a = .05; n = 14 
b. Ha: p > 10; a = .01; n = 24 
c. Ha:p > 10;a = .10;n = 9 
d. Ha: p < 10; a = .01; n = 12 
e. Ha:p # 10; a = .10;n = 20 
f. Ha: p < 10; a = .05: n = 4 
6.44 A sample of five measurements, randomly selected 
from a normally distributed population, resulted in the 
following summary statistics: i = 4.8, s = 1.3. 
a. Test the null hypothesis that the mean of the popula- 
tion is 6 against the alternative hypothesis, p < 6. 
Use a = .05. 
b. Test the null hypothesis that the mean of the popula- 
tion is 6 against the alternative hypothesis, p 1. 6. 
Use a = .05. 
c. Find the observed significance level for each test. 
6.45 MINITAB is used to conduct a t-test for the null 
hypothesis H,,: p = 1,000 versus the alternative hypoth- 
esis Ha: p > 1,000 based on a sample of 17 observa- 
tions. The software's output is shown below. 
a. What assumptions are necessary for the validity of 
this procedure? 
b. Interpret the results of the test. 
c. Suppose the alternative hypothesis had been the 
two-tailed Ha: p # 1,000. If the t statistic were un- 
changed, then what would the p-value be for this 
test'? Interpret the p-value for the two-tailed test. 
Applying the Concepts 
6.46 Information Resources Inc., a Chicago-based research 
organization, tracks supermarket sales in 28 metropoli- 
tan markets in the United States. They convert their 
data for specific products to an index that measures 
product usage relative to the national average usage. 
For example, Green Bay, Wisconsin's ketchup index is 
143, the highest in the nation. This means that Green 
Bay residents consume 43% more ketchup, on average, 
than the mean national consumption rate. The table lists 
the salad dressings index for each in a sample of seven 
Southeastern cities. 
SALAD.DAT 
............................................................................... 
Salad Dressings Index (U. S. mean = 100) 
............................................................................... 
Charlotte, N. C. 
124 
B~rm~ngham. 
Al. 
99 
Raleigh, N. C. 
124 
Knoxville, Tenn. 
99 
Memphis, Tenn. 
90 
Atlanta, Ga. 
111 
Nashville, Tenn. 
89 
Source: Wdl Street Journal Interactwe Edztlon, 
Jan 5.2000. 
a. Specify the appropriate null and alternative hy- 
potheses for testing whether the true mean con- 
sumpt~on rate of salad dressings In the Southeastern 
Un~ted States is d~ffcrent than the mean nat~onal 
conwmption rate of 100. 
b. What assumptions about the sample and population 
must hold in order lor it to be appropriate to use a 
t statistic in conducting the hypothesis test? 
c. Conduct the hypothesis test using a = .05. 
d. Is the observcd significance level of the test greater 
or less than .05? Justify your answer. 
6.47 A study was conducted to evaluate the effectiveness of 
a new mosquito repellent designed by the U.S. Army to 
be apphed a? camouflage face paint (Journal of [he 
Mosquzto Control Awoc~nt~on, 
June 1995). The repel- 
lent was applied to the forearms of five volunteers and 
then the arms were exposed to fifteen active mosqul- 
toes tor a 10-hour period. Based on the number and 
location of the mosquito bites, the percentage of the 
1 
forearm wrface area protected from bites (called per 
cent repellency) was calculated for each of the five vol 
unteers. For one color of paint (loam), the follow~np 
summary statistics were obtained: 
MINITAB Output for Exercise 6.45 
TEST OF MU = 1,000 VS MU G.T. 1,000 
N 
MEAN 
STDEV 
SE MEAN 
T 
P VALUE 
X 
1 7  
1020 
43.54 
10.56 
1.894 
.0382 
4 

SECTION 6.4 
S m a l l - S a m p l e  T e s t  of H y p o t h e s i s  A b o u t  a P o p u l a t i o n  M e a n  
325 
a. The new repellent is considered effective if it pro- 
vides a percent repellency of at least 95. Conduct a 
test to determine whether the mean repellency per- 
centage of the new mosquito repellent is less than 
95.Test using a = .10 
b. What assumptions are required for the hypothesis 
test in part a to be valid? 
6.48 The Cleveland Casting Plant is a large, highly automated 
producer of gray and nodular iron automotive castings 
for Ford Motor Company (Quality Engineering, Vol. 7, 
1995). One process variable of interest to Cleveland 
Casting is the pouring temperature of the molten iron. 
The pouring temperatures (in degrees Fahrenheit) for a 
sample of 10 crankshafts are listed in the table. The target 
setting for the pouring temperature is set at 2,550 degrees. 
Assuming the process is stable, conduct a test to deter- 
mine whether the true mean pouring temperature differs 
from the target setting.Test using a = .01. 
2,543 2,541 
2,544 
2,620 
2,560 
2,559 
2,562 
2,553 2,552 
2,553 
Source Pr~ce. B . and Barth, B. "A structural model relating 
process Inputs and final product characteristics." Quahty 
Engmeenng, Vol 7, No. 4,1995, p. 696 (Table 2) 
6.49 By law, the levels of toxic organic compounds in fish 
are constantly monitored. A technique, called matrix 
solid-phase dispersion (MSPD), has been developed for 
chemically extracting trace organic compounds from 
fish specimens (Chrornatographia, Mar. 1995). The 
MSPD method was tested as follows. Uncontaminated 
fish fillets were injected with a known amount of toxin. 
The MSPD method was then used to extract the conta- 
mmant and the percentage of the toxic compound 
recovered was measured. The recovery percentages for 
n = 5 fish fillets are listed below: 
, 
Do the data provide sufficient evidence to indicate that 
the mean recovery percentage of the toxic compound 
exceeds 85% using the new MSPD method? Test using 
a = .05. 
650 To instdl customer loyalty, airlines, hotels, rental car com- 
pames, and cred~t card companies (among others) have 
lnit~atedfrequency rnarketingprograrns that reward their 
regular customers. In the United States alone, 30 million 
people are members of the frequent flier programs of the 
a~rline mdustry (Fortune, Feb. 22,1993). A large fast-food 
restaurant chain wished to explore the profitability of 
such a program.They randomly selected 12 of their 1,200 
restaurants nationwide and instituted a frequency pro- 
gram that rewarded customers with a $5.00 gift certificate 
after every 10 meals purchased at full price. They ran the 
trial program for three months.The restaurants not in the 
sample had an average increase in profits of $1,047.34 
over the previous three months, whereas the restaurants 
in the sample had the following changes in profit: 
Note that the last number is negative, representing a 
decrease in profits. Summary statistics and graphs for 
the data are given in the SPSS printout on page 326. 
a. Specify the appropriate null and alternative hy- 
potheses for determining whether the mean profit 
change for restaurants with frequency programs is 
significantly greater (in a statistical sense) than 
$1,047.34. 
b. Conduct the test of part b using a = .05. Does it ap- 
pear that the frequency program would be profitable 
for the company if adopted nationwide? 
6.51 The Occupational Safety and Health Act (OSHA) 
allows issuance of engineering standards to ensure safe 
workplaces for all Americans. The maximum allowable 
mean level of arsenic in smelters, herbicide production 
facilities, and other places where arsenic is used is 
.004 milligram per cubic meter of air. Suppose smelters 
at two plants are being investigated to determine 
whether they are meeting OSHA standards. Two analy- 
ses of the air are made at each plant, and the results (in 
milligrams per cubic meter of air) are shown in the table. 
Plant 1 
Plant 2 
.............................................................................................................. 
Observation 
Arsenic Level 
Observation 
Arsenic Level 
.............................................................................................................. 
1 
.01 
1 
.05 
2 
.005 
2 
.09 
a. What are the appropriate null and alternative hy- 
potheses if we wish to test whether the plants meet 
the current OSHA standard? 
b. These data are analyzed by MINITAB, with the re- 
sults as shown on p. 326. Check the calculations of 
the t statistics and p-values. 
c. Interpret the results of the two tests. 
6.52 Periodic assessment of stress in paved highways is 
important to maintaining safe roads. The Mississippi 
Department of Transportation recently collected data 
on number of cracks (called crack intensity) in an 

326 
CHAPTER 
6 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
. 
. 
SPSS Output for Exercise 6.50 
I 
PROFIT 
Valid cases: 
12.0 
Missing cases: 
.O 
Percent missing: 
.O 
Mean 
2509.431 
Std Err 
620.4388 Min 
-2191.00 
Skewness 
-.3616 
Median 
2493.450 Variance 
4619332 Max 
6552.700 
S E Skew 
.6373 
5% Trim 
2545.940 
Std Dev 
2149.263 
Range 
8743.700 
Kurtosis 
1.8750 
1 QR 
1780.025 
S E Kurt 
1.2322 
.............................................................................. 
Frequency 
Stem & 
Leaf 
1.00 Extremes 
(-2191) 
1.00 
0
.
5
 
2.00 
1 . 58 
4.00 
2 . 2369 
2.00 
3 . 34 
1.00 
4
.
7
 
1.00 Extremes 
(6553) 
Stemwidth: 
1000.00 
Each leaf: 
1 case(s) 
.............................................................................. 
MINITAB Output for Exercise 6.51 
I 
I TEST OF MU = 0.00400 VS MU G.T. 0.00400 
I 
N 
MEAN 
STDEV 
SE MEAN 
T 
P VALUE 
Plant1 
2 
0.00750 
0.00354 
0.00250 
1.40 
0.20 1 
Plant2 
2 
0.07000 
0.02828 
0.02000 
3.30 
0.094 
undivided two-lane highway using van-mounted state- 
and Transportation Officials (AASHTO) recommends 
of-the-art video technology (Journal o f  Infrastructure 
a maximum mean crack intensity of .I00 for safet, 
{ 
Systems, Mar. 1995). The mean number of cracks 
purposes. Test the hypothesis that the true mean crack 
found in a sample of eight 50-meter sections of the 
intensity of the Mississippi highway exceeds the 
highway was F = .210, with a variance of s2 = .011. 
AASHTO recommended maximum. Use a = .01. 
Suppose the American Association of State Highway 
LARGE-SAMPLE TEST OF HYPOTHESIS ABOUT A 
POPULATION PROPORTION 
Inferences about population proportions (or percentages) are often made in the 
context of the probability, p, of "success" for a binomial distribution. We saw how 
to use large samples from binomial distributions to form confidence intervals for 
p in Section 5.3. We now consider tests of hypotheses about p. 
For example, consider the problem of insider trading in the stock market. In- 
sider trading is the buying and selling of stock by an individual privy to inside in- 
formation in a company, usually a high-level executive in the firm. The securities 
and Exchange Commission (SEC) imposes strict guidelines about insider trading 
so that all investors can have equal access to information that may affect the stock's 
price. An investor wishing to test the effectiveness of the SEC guidelines monitors 
the market for a period of a year and records the number of times a stock price in- 
creases the day following a significant purchase of stock by an insider. For a total of 
576 such transactions, the stock increased the following day 327 times. Does this 
sample provide evidence that the stock price may be affected by insider trading? 

Large-Sample Test of Hypothesis About a Population Proportion 
327 
We first view this as a binomial experiment, with the 576 transactions as the tri- 
als, and success representing an increase in the stock's price the following day. Let p 
represent the probability that the stock price will increase following a large insider 
purchase. If the insider purchase has no effect on the stock price (that is, if the infor- 
mation available to the insider is identical to that available to the general market), 
then the investor expects the probability of a stock increase to be the same as that of 
a decrease, or p = .5. On the other hand, if insider trading affects the stock price (in- 
dicating that the market has not fully accounted for the information known to the 
insiders), then the investor expects the stock either to decrease or to increase more 
than half the time following significant insider transactions; that is, p # .5. 
We can now place the problem in the context of a test of hypothesis: 
H,: p = .5 
Ha: p f .5 
Recall that the sample proportion, p, is really just the sample mean of the out- 
comes of the individual binomial trials and, as such, is approximately normally dis- 
tributed (for large samples) according to the Central Limit Theorem. Thus, for 
large samples we can use the standard normal z as the test statistic: 
Sample proportion - Null hypothesized proportion 
Test statistic: z = 
Standard deviation of sample proportion 
where we use the symbol p, to represent the null hypothesized value of p. 
Rejection region: We use the standard normal distribution to find the 
appropriate rejection region for the specified value of a. Using a = .05, 
the two-tailed rejection region is 
See Figure 6.15. 
FIGURE 6.1 5 
Rejection region for insider trading example 
g= 
z = 3.24 
We are now prepared to calculate the value of the test statistic. Before doing so, 
we want to be sure that the sample size is large enough to ensure that the normal 
approximation for the sampling distribution of j? is reasonable. To check this, we 
calculate a 3-standard-deviation interval around the null hypothesized value, p,, 
which is assumed to be the true value of p until our test procedure indicates other- 
wise. Recall that a,- = - 
and that we need an estimate of the product pq in 
order to calculate a numerical value of the test statistic z. Since the null hypothesized 
value is generally the accepted-until-proven-otherwise value, we use the value of poqo 
(where q, = 1 - p,) to estimate pq in the calculation of z. Thus, 

328 
CHAPTER 
6 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
I 
and the 3-standard-deviation interval around p, is 
As long as this interval does not contain 0 or 1 (i.e., is completely contained in the 
interval 0 to I), as is the case here, the normal distribution will provide a reason- 
able approximation for the sampling distribution of @. 
Returning to the hypothesis test at hand, the proportion of the sampled 
transactions that resulted in a stock increase is 
Finally, we calculate the number of standard deviations (the z value) between the 
sampled and hypothesized value of the binomial proportion: 
The implication is that the observed sample proportion is (approximately) 
3.24 standard deviations above the null hypothesized proportion .5 (Figure 6.15). 
Therefore, we reject the null hypothesis, concluding at the .05 level of significance 
that the true probability of an increase or decrease in a stock's price differs from 
.5 the day following insider purchase of the stock. It appears that an insider pur- 
chase significantly increases the probability that the stock price will increase the 
following day. (To estimate the magnitude of the probability of an increase, a 
confidence interval can be constructed.) 
The test of hypothesis about a population proportionp is summarized in the 
next box. Note that the procedure is entirely analogous to that used for conduct- 
ing large-sample tests about a population mean. 
ne-Tailed Test 

SECTION 6.5 
Large-Sample Test o f  H y p o t h e s i s  A b o u t  a  P o p u l a t i o n  P r o p o r t i o n  
329 
S o l u t i o n  
shipments of manufactured items that contain a large percentage of defectives. 
For example, a manufacturer of alkaline batteries may want to be reasonably 
certain that fewer than 5% of its batteries are defective. Suppose 300 batteries 
are randomly selected from a very large shipment; each is tested and 10 defective 
batteries are found. Does this provide sufficient evidence for the manufacturer to 
conclude that the fraction defective in the entire shipment is less than .05? 
Use a = .01. 
Before conducting the test of hypothesis, we check to determine whether the 
sample size is large enough to use the normal approximation for the sampling 
distribution of p. The criterion is tested by the interval 
Since the interval lies within the interval (0, I), the normal approximation will be 
I 
adequate. 
The objective of the sampling is to determine whether there is sufficient ev- 
idence to indicate that the fraction defective, p, is less than .05. Consequently, we 
will test the null hypothesis that p = .05 against the alternative hypothesis that 
( 
p < .05. The elements of the test are 
F - Po 
Test statistic: z = - 
a,- 
Rejection region: z < -zol = -2.33 
(see Figure 6.16) 
We now calculate the test statistic: 
I 
Notice that we use po to calculate a,; because, in contrast to calculating a,- for a 
confidence interval, the test statistic is computed on the assumption that the null 
hypothesis is true-that 
is, p = po. Therefore, substituting the values for 13 and p, 
into the z statistic, we obtain 
FIGURE 6.16 
Rejection region for Example 6.7 
z 
Computed z = -1.35 

330 
 CHAPTER^ 
I n f e r e n c e s  B a s e d  p n  a S i n g l e  S a m p l e  
As shown in Figure 6.16, the calculated z value does not fall in the rejection re- 
gion. Therefore, there is insufficient evidence at the .01 level of significance to in- 
dicate that the shipment contains fewer than 5% defective batteries. 
'. 
-,&.-,- 
In Exarn~le 6.7 wc found that wc did not have sufficient evidence. at the a = .O1 
level of significance, to indicate that the fraction defective p of alkaline batteries was 
less than p = .05. How strong was the weight of evidence favoring the alternative 
hypothesis (Ha: p < .05 )? Find the observed significance level for the test. 
S o l u t i o n  
p-value = ,0885 
AIL7 
F I G U R E  6.1 7 
The observed significance level 
for Example 6.8 
The computed value of the test statistic z was z = - 1.35. Therefore, for this lower- 
tailed test, the observed significance level is 
Observed significance level = P(z 5 -1.35) 
This lower-tail area is shown in Figure 6.17.The area between z = 0 and z = 1.35 
is given in Table IV in Appendix B as .4115. Therefore, the observed significance 
level is .5 - .4115 = .0885. Note that this probability is quite small. Although we 
did not reject H,,: p = .05 at a = .01, the probability of observing a z value as 
small as or smaller than -1.35 is only .0885 if in fact H, is true. Therefore, we 
would reject H, if we choose a = .10 (since the observed significance level is less 
than .lo), and we would not reject H, (the conclusion of Example 6.7) if we 
choose a = .05 or a = .01. 
4 
Small-sample test procedures are also available for p, although most surveys 
use samples that are large enough to employ the large-sample tests presented in 
this section. A test of proportions that can be applied to small samples is dis- 
cussed in Section 8.3. 
Learning the Mechanics 
6.53 For the binomial sample sizes and null hypothesized 
values of p in each part, determine whether the sample 
size is large enough to use the normal approximation 
methodology presented in this section to conduct a test 
of the null hypothesis H,: p = p,. 
a. n = 900, p, = 975 b. n = 125, p, = .O1 
c. n = 40, p, = .75 d. n = 15, p,, = .75 
e. n = 12, p, = .62 
6.54 Suppose a random sample of 100 observations from a 
binomial population gives a value of a = .63 and you 
wish to test the null hypothesis that the popillation 
parameter p is equal to .70 against the alternative 
hypothesis that p is less than .70. 
a. Noting that 
= .63, what does your intuition tell 
you? Does the value of a appear to contradict the 
null hypothesis? 
b. Use the large-sample z-test to test H,: p = .70 
against the alternative hypothesis, Ha: p < .70. Use 
a = .05. How do the test results compare with your 
intuitive decision from part a? 
c. Find and interpret the observed significance level of 
the test you conducted in part b. 
6.55 Refer to Exercise 5.26 (p. 285), in which 50 consumer\ 
taste tested a new snack food. Their responses (where 
0 = do not like; 1 = like; 2 = indifferent) are repro- 
duced below. 
a. Test H,: p = .5 against Ha: p > .5, where p is the 
proportion of customers who do not like the snack 
food. Use a = 10. 
b. Find the observed significance level of your test. 

SECTION 6.5 
L a r g e - S a m p l e  Test o f  H y p o t h e s i s  A b o u t  a  P o p u l a t i o n  P r o p o r t i o n  
331 
SPSS Output for Exercise 6.56 
- - - - - -  Binomial Test 
Cases 
Test Prop. = 
.5000 
220 
= 1 
Obs. Prop. = 
.4400 
280 
= 0 
- - 
Z Approximation 
500 
Total 
2-Tailed P = 
0.3300 
6.56 A statistics student used a computer program to test the 
null hypothesis H,: p = .5 against the one-tailed alter- 
native, Ha: p > .5. A sample of 500 observations are 
input into SPSS, which returns the output shown above. 
a. The student concludes, based on thep-value, that there 
is a 33% chance that the alternative hypothesis is true. 
Do you agree? If not, correct the interpretation. 
b. How would thep-value change if the alternative hy- 
pothesis were two-tailed, Ha: p # .5? Interpret this 
p-value. 
Applying the Concepts 
6.57 Pond's Age-Defying Complex, a cream with alpha- 
hydroxy acid, advertises that it can reduce wrinkles and 
improve the skin. In a study published in Archives of 
Dermatology (June 1996), 33 women over age 40 used a 
cream with alpha-hydroxy acid for twenty-two weeks. 
At the end of the study period, 23 of the women exhib- 
ited skin improvement (as judged by a dermatologist). 
a. Is this evidence that the cream will improve the skin 
of more than 60% of women over age 40? Test using 
a = .05. 
b. Find and interpret the p-value of the test. 
6.58 Shoplifting in the U. S. costs retailers about $15 billion a 
year. Those losses translate into higher prices for con- 
sumers. Despite the seriousness of the problem, 
Shoplifters Alternative of Jericho, N. Y., claims that only 
50% of all shoplifters are turned over to police (Athens 
Daily News, Dec. 12,1999). A random sample of 40 U. S. 
retailers were questioned concerning the disposition of 
the most recent shoplifter they apprehended. Only 24 
were turned over to police. Do these data provide suffi- 
cient evidence to contradict Shoplifters Alternative? 
a. Is the sample size large enough to use thc inferential 
procedure presented in this section to answer the 
question? Explain. 
b. Conduct a hypothesis test to answer the question of 
interest. Use a = .05. 
c. Find the observed significance level of the hypothesis 
test in part b. 
d. For what values of a would the observed significance 
level be sufficient to reject the null hypothesis of the 
test you conducted in part b? 
659 The placebo effect describes the phenomenon of 
improvement in the condition of a patient taking a 
placebo-a 
pill that looks and tastes real but contains 
no medically active chemicals. Physicians at a clinic in 
La Jolla, California, gave what they thought were drugs 
to 7,000 asthma, ulcer, and herpes patients. Although 
the doctors later learned that the drugs were really 
placebos, 70% of the patients reported an improved 
condition (Forbes, May 22,1995). Use this information 
to test (at a = .05) the placebo effect at the clinic. 
Assume that if the placebo is ineffective, the probability 
of a patient's condition improving is .5. 
6.60 Refer to the Nature (Aug. 27, 1998) study of facial 
characteristics that are deemed attractive, Exercise 6.35 
(p. 318). In another experiment, 67 human subjects 
viewed side-by-side an image of a Caucasian male 
face and the same image 50% masculinized. Each sub- 
ject was asked to select the facial image that they 
deemed more attractive. Fifty-eight of the 67 subjects 
felt that masculinization of face shape decreased 
attractiveness of the male face. The researchers used 
this sample information to test whether the subjects 
showed preference for either the unaltered or mor- 
phed male face. 
a. Set up the null and alternative hypotheses for this test. 
b. Compute the test statistic. 
c. The researchers reported p-value .= 0 for the test. 
Do you agree? 
d. Make the appropriate conclusion in the words of the 
problem. Use a = .01. 
6.61 Creative Good, a New York consulting firm, claimed 
that 39% of shoppers fail in their attempts to purchase 
merchandise on-line because Web sites are too com- 
plex. They estimated that this would translate into a 
loss of more than $6 billion for on-line merchants 
during the 1999 holiday season (Forbes, Dec. 13,1999). 
Another consulting firm asked a random sample of 60 
on-line shoppers to each test a different randomly 
selected e-commerce Web site. Only 15 reported suffi- 
cient frustration with their sites to deter making a 
purchase. 
a. Do these data provide sufficient evidence to reject 
the claim made by Creative Good? Test using 
a = .01. 
b. Find the observed significance level of the test and 
interpret it in the context of the problem. 
6.62 In 1895, druggist Asa Candler began distributing hand- 
written tickets to his customers for free glasses of 
Coca-Cola at his soda fountain.That was the genesis of 

332 
CHAPTER 
6 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
the discount coupon. In 1975 it was estimated that 69% 
tive decay prevention.The data for the 46 brands (coded 
of U.S. consumers regularly used discount coupons 
1 = ADA seal, 0 = no ADA seal) are listed here. 
when shopping. In a 1995 consumer survey, 71% said 
- -  - 
they regularly redeem coupons (Newark Star-Ledger, 
Oct. 9, 1995). Assume the 1995 survey consisted of a 
random samplc of 1,000 shoppers. 
a. Does the 1995 survey provide sufficient evidence 
that the percentage of shoppers using cents-off 
coupons exceeds 69%? Test using a = .05. 
b. Is the sample size large enough to use the inferential 
procedures presented in this section? Explain. 
c. Find the observed significance level for the test you 
conducted in part a, and interpret its value. 
6.63 Consumer Reports (Sept. 1992) evaluated and rated 46 
brands of toothpaste. One attribute examined in the study 
was whether or not a toothpaste brand carries an 
a. Give the null and alternative hypotheses for testing 
whether the true proportion of toothpaste brands 
with the ADA seal verifying effective decay preven- 
tion is less than .5. 
b. The data were analyzed in SPSS; the results of the 
test are shown in the SPSS printout below. Interpret 
American Dental Association (ADA) seal verifying effec- 
the results. 
SPSS Output for Exercise 6.63 
- - - - - - Binomial Test 
ADASEAL 
Cases 
Test Prop. = 
.5000 
20 
~ 1 . 0 0  
Obs. Prop. = 
. 4 3 4 8  
26 
= 
.OO 
- - 
Z Approximation 
46 
Total 
2-Tailed P = 
.4610 
, 
A NONPARAMETRIC TEST ABOUT A POPULATION 
M E D I A N  (OPTIONAL) 
In Sections 6.2-6.4 we utilized the z and t statistics for testing hypotheses about a 
population mean. The z statist~c is appropriate for large random samples selected 
from "general" populations-that 
is, with few limitations on the probability d~s- 
tribution of the underlying population. The t statistic was developed for small- 
sample tests in which the sample is selected at random from a normal distribution. 
The question is: How can we conduct a test of hypothesis when we have a small 
sample from a nonnormal distribution? The answer is: Use a procedure that re- 
quires fewer or less stringent assumptions about the underlying population, called 
a nonparametric method. 
The sign test is a relatively simple nonparametric procedure for testing hy- 
potheses about the central tendency of a nonnormal probability distribution. Note 
that we used the phrase centrul tendency rather than population mean. This is be- 
cause the sign test, like many nonparametric procedures, provides inferences 
about the population median rather than the population mean p. Denoting the 
population median by the Greek letter, 7, we know (Chapter 2) that 7 is the 50th 
percentile of the distribution (Figure 6.18) and as such is less affected by the 
skewness of the distribution and the presence of outliers (extreme observations). 
Since the nonparametric test must be suitable for all distributions, not just the nor- 
mal, it is reasonable for nonparametric tests to focus on the more robust (less sen- 
sitive to extreme values) measure of central tendency, the median. 
r-, 

SECTION 6.6 
A N o n p a r a m e t r i c  Test A b o u t  a P o p u l a t i o n  M e d i a n  ( O p t i o n a l )  
333 
FIGURE 6.18 
Location of the population median, 7 
11 
Median 
For example, increasing numbers of both private and public agencies are re- 
quiring their employees to submit to tests for substance abuse. One laboratory 
that conducts such testing has developed a system with a normalized measure- 
ment scale, in which values less than 1.00 indicate "normal" ranges and values 
equal to or greater than 1.00 are indicative of potential substance abuse. The lab 
reports a normal result as long as the median level for an individual is less than 
1.00. Eight independent measurements of each individual's sample are made. 
Suppose, then, that one individual's results were as follows: 
If the objective is to determine whether the population median (that is, the 
true median level if an indefinitely large number of measurements were made on 
the same individual sample) is less than 1.00, we establish that as our alternative 
hypothesis and test 
H,: ,q = 1.00 
Ha: r] < 1.00 
The one-tailed sign test is conducted by counting the number of sample mea- 
surements that "favor" the alternative hypothesis-in 
this case, the number that 
are less than 1.00. If the null hypothesis is true, we expect approximately half of 
the measurements to fall on each side of the hypothesized median and if the al- 
ternative is true, we expect significantly more than half to favor the alternative- 
that is, to be less than 1.00. Thus, 
Test statistic: S = Number of measurements less than 1.00, 
the null hypothesized median 
If we wish to conduct the test at the a = .05 level of significance, the rejection region 
can be expressed in terms of the observed significance level, or p-value of the test: 
Rejection region: p-value 5 .05 
In this example, S = 7 of the 8 measurements are less than 1.00. To deter- 
mine the observed significance level associated with this outcome, we note that 
the number of measurements less than 1.00 is a binomial random variable (check 
the binomial characteristics presented in Section 4.3), and i f  H, is true, the bino- 
mial probability p that a measurement lies below (or above) the median 1.00 is 
equal to .5 (Figure 6.18). What is the probability that a result is as contrary to or 
more contrary to H, than the one observed if H,, is true? That is, what is the prob- 
ability that 7 or more of 8 binomial measurements will result in Success (be less 
than 1.00) if the probability of Success is .5? Binomial Table I1 in Appendix B 
(using n = 8 and p = .5) indicates that 
P(x 2 7) = 1 - P(x 5 6) = 1 - .965 = .035 
Thus, the probability that at least 7 of 8 measurements would be less than 1.00 if 
the true median were 1.00 is only .035. The p-value of the test is therefore .035. 

334 
CHAPTER 
6 
I n f e r e n c e s  Based o n  a S i n g l e  S a m p l e  
I 
N 
BELOW 
EQUAL 
ABOVE 
P-VALUE 
READING 
8 
7 
0 
1 
0.0352 
0.8350 I 
F I G U R E  6.19 
MINITAB printout of sign test 
This p-value can also be obtained using a statistical software package. The 
MINITAB printout of the analysis is shown in Figure 6.19, with the p-value 
highlighted on the printout. Since p = .035 is less than a = .05, we conclude that 
this sample provides sufficient evidence to reject the null hypothesis. The impli- 
cation of this rejection is that the laboratory can conclude at the a = .05 level of 
significance that the true median level for the tested individual is less than 1.00. 
However, we note that one of the measurements greatly exceeds the others. 
with a value of 3.79, and deserves special attention. Note that this large mea- 
surement is an outlier that would make the use of a t-test and its concomitant as- 
sumption of normality dubious. The only assumption necessary to ensure the 
validity of the sign test is that the probability distribution of measurements is 
continuous. 
The use of the sign test for testing hypotheses about population medians is 
summarized in the box. 
S I G N  TEST OF MEDIAN = 1.000 VERSUS 
L.T. 
1.000 
of measurements less then 77, 
d S, is the number of measurements 
ater than n, 
. . 
. 
... . 
1" 
ble 11, Ap- 
uous probability distri- 
ape of the probability 
tribu 
Recall that the normal probability distribution provides a good approxima- 
tion for the binomial distribution when the sample size is large. For tests about the 
median of a distribution, the null hypothesis implies that p = .5, and the normal 
distribution provides a good approximation if n r 10. (Samples with n 2 10 sat- 
isfy the condition that np * 3- 
is contained in the interval 0 to n.) n u s ,  we 
can use the standard normal z-distribution to conduct the sign test for large sam- 
ples. The large-sample sign test is summarized in the next box. 

SECTION 6.6 
A Nonparametric Test About a Population Median (Optional) 
335 
(S - 5) - .5n 
Test statistic: z = 
.5 fi 
Note: S is calculated as shown in the previous box. We subtract .5 from S as the "cor- 
on for continuity." The null hypothesized mean value is np = Sn, and the stan- 
deviation is 
*= 
*= 
. 5 f i  
s on the normal approximation to the binomial distribution.] 
Rejection region: z > z,,~ 
ound in Table IV of Appendix B. 
time to failure for its players is 5,250 hours of utilization. A sample of 20 CDs from 
a competitor is obtained, and they are continuously tested until each fails. The 20 
failure times range from five hours (a "defective" player) to 6,575 hours, and 14 of 
the 20 exceed 5,250 hours. Is there evidence that the median failure time of the 
competitor differs from 5,250 hours? Use a = .lo. 
S o I u t i o n The null and alternative hypotheses of interest are 
H,: 77 = 5,250 hours 
Ha: r] # 5,250 hours 
Test statistic: Since n 2 10, we use the standard normal z statistic: 
where S is the maximum of S1, the number of measurements greater than 5,250, 
and S,, the number of measurements less than 5,250. 
Rejection region: z > 1.645 
where 
zai2 = z,~, = 1.645 
Assumptions: The distribution of the failure times is continuous (time is a 
continuous variable), but nothing is assumed about the shape of its proba- 
bility distribution. 
Since the number of measurements exceeding 5,250 is S2 = 14 and thus the num- 
ber of measurements less than 5,250 is S, = 6, then S = 14, the greater of S, and 
S,. The calculated z statistic is therefore 
The value of z is not in the rejection region, so we cannot reject the null hypothe- 
sis at the a = .10 level of significance. Thus, the CD manufacturer should not 

336 
 CHAPTER^ 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
+ 
conclude, on the basis of this sample, that its competitor's CDs have a median fail- 
ure time that differs from 5,250 hours. 
The one-sample nonparametric sign test for a median provides an alterna- 
tive to the t-test for small samples from nonnormal distributions. However, if the 
distribution is approximately normal, the t-test provides a more p~werful test 
about the central tendency of the distribution. 
Learning the Mechanics 
6.64 What is the probability that a randomly selected obser- 
vation exceeds the 
a. Mean of a normal distribution? 
b. Median of a normal distribution? 
c. Mean of a nonnormal distribution? 
d. Median of a nonnormal distribution? 
6.65 Use Table I1 of Appendix B to calculate the following 
binomial probabilities: 
a. P(x 2 7) when n = 8 and p = .5 
b. P(x 2 5) when n = 8 and p = .5 
c. P(x 2 8) when n = 8 and p = .5 
d. P(x 2 10) when n = 15 and p = .5. Also use the nor- 
mal approximation to calculate this probability, then 
compare the approximation with the exact value. 
e. P(x 2 15) when n = 25 and p = .5. Also use the nor- 
mal approximation to calculate this probability, then 
compare the approximation with the exact value. 
6.66 Consider the following sample of 10 measurements: 
Use these data to conduct each of the following sign 
tests using the binomial tables (Tablc 11, Appendix B) 
and a = .05: 
a. H,,: 7 = 9 versus Ha: 7 > 9 
b. H,,: 7 = 9 versus Ha: 7 # 9 
c. H,,: 7 = 20 versus Ha: 7 < 20 
d. H,,: 7 = 20 versus H,: q # 20 
e. Repeat each of the preceding tests using the normal 
approximation to the binomial probabilities. Com- 
pare the results. 
f. What assumptions are necessary to ensure the valid- 
ity of each of the preceding tests? 
6.67 Suppose you wish to conduct a test of the research 
hypothesis that the median of a population is greater 
than 75. You randomly sample 25 measurements from 
the population and detcrmine that 17 of them exceed 75. 
Set up and conduct the appropriate test of hypothesis at 
the .I0 level of significance. Be sure to specify all neces- 
sary assumptions. 
Applying the Concepts 
6.68 One way to assess the benefits of an MBA degree is to 
investigate the salaries received by MBA students sev- 
eral years after graduation. In 1998, the Graduate 
Management Admission Council estimated that the 
median earnings for graduates of full-time, highly- 
ranked MBA programs four years after graduating was 
$96,000 (Selections, Winter 1999). A random sample of 
50 graduates from the class of 1996 of a particular 
highly ranked MBA program were mailed a question- 
naire and asked to report their earnings for 2000 
Fifteen useable responses were received; 9 indicated 
earnings greater than $96,000 and 6 indicated earnings 
below $96,000. 
a. Specify the null and alternative hypotheses that 
should be used in testing whether the median income 
of graduates of the MBA program was more than 
$96,000 in 2000. 
b. Conduct the test of part a using a = .05 and draw 
your conclusion in the context of the problem. 
c. What assumptions must hold to ensure the validity 
of your hypothesis lest? 
6.69 The biting rate of a particular species of fly was investi- 
gated in a study reported in the Journal of the American 
Mosquito Control Association (Mar. 1995). Biting rate was 
defined as the number of flies biting a volunteer during 
15 minutes of exposure. This species of fly is known to 
have a median biting rate of 5 bites per 15 minutes on 
Stanbury Island, Utah. However, it is theorized that the 
median biting rate is higher in bright, sunny weather. 
(This information is of interest to marketers of pesticides) 
To test this theory, 122 volunteers were exposed to the 
flies during a sunny day on Stanbury Island. Of these vol- 
unteers, 95 experienced biting rates greater than 5. 
a. Set up the null and alternative hypotheses for the test. 
b. Calculate the approximate p-value of the test. [Hint: 
Use the normal approximation for a binomial 
probability.] 
c. Make the appropriate conclusion at a = .01. 
6.70 Reducing the size of a company's workforce in order to 
reduce costs is referred to as corporate downsizing or 
reductions in force (RIF) by the business community 
and media (Business Week, Feb. 24, 1997). Following 
RIFs, companies are often sued by former employees 

1 
j 
7 
3 
n 
e 
1. 
-) 
Le 
11- 
st. 
1 t: 
al 
to 
or 
ity 
ing 
ees 
SECTION 6.6 
A N o n p a r a r n e t r i c  Test A b o u t  a P o p u l a t i o n  M e d i a n  ( O p t i o n a l )  
337 
MINITAB Output for Exercise 6.70 
SIGN TEST OF MEDIAN = 37.00 VERSUS G.T. 
37.00 
N BELOW EQUAL ABOVE 
P-VALUE 
MEDIAN 
AGE 
15 
4 
0 
11 
0.0592 
43.00 
who allege that the RIFs were discriminatory with 
regard to age. Fedcral law protects employees over 
40 years of age against such discrimination. Suppose 
one large company's employees have a median age of 
37. Its RIF plan is to fire 15 employees with ages listed 
in the table below. 
a. Calculate the median age of the employees who are 
being terminated. 
b. What are the appropriate null and alternative hy- 
potheses to test whether the population from 
which the terminated employees were selected has 
a median age that exceeds the entire company's 
median age? 
c. The test of part b was conducted using MINITAB. 
Find the significance level of the test on the MINITAB 
printout shown above and interpret its value. 
d. Assuming that courts generally require statistical 
evidence at the .10 level of significance beforc rul- 
ing that age discrimination laws were violated, what 
do you advise the company about its planned RIF? 
Explain. 
6.71 The Federal Aviation Administration (FAA) increased 
the frequency and thoroughness of its review of aircraft 
maintenance procedures in response to the admission by 
ValuJet Airlines that it had not met some maintenance 
requirements. Suppose that the FAA samples the records 
of six aircraft currently utilized by one airline and deter- 
mines the number of flights between the last two com- 
plete engine maintenances for cach, with the results 
shown in the table. The FAA requires that this mainte- 
nance be performed at least every 30 flights. Although it is 
obvious that not all aircraft are meeting the requirement, 
the FAA wishes to test whether the airline is meeting this 
particular maintenance requirement "on average." 
a. Would you suggest the t-test or sign test to conduct 
the test? Why? 
b. Set up the nil1 and alternative hypotheses such that 
the burden of proof is on the airline to show it is 
meeting the "on-average" requirement. 
c. What are thc test statistic and rejection region for this 
test if the level of significance is a = .01? Why would 
the level of significance be set at such a low value? 
d. Conduct the test, and state the conclusion in terms of 
this application. 
6.72 In Exercise 5.18 (p. 276), the average 5-year revenue 
growth for the 500 fastest growing technology compa- 
nies in 1999 (i.e., Forbes' Technology Fast 500) was 
investigated. The data are reproduced in the table 
below. 
1994-1999 Revenue 
Rank 
Company 
Growth Rate (%) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
4 
Netscape Communication 
64,240 
22 
Primary Network 
10,789 
89 
WebTrends 
3,378 
160 
CTX 
1,864 
193 
ARIS 
1,543 
268 
lomega 
1,098 
274 
Medarex 
1,075 
322 
World Access 
895 
359 
Force 3 
808 
396 
Theragenics 
704 
441 
Ascent Solutions 
630 
485 
3 Com 
555 
Source: Forha ASAE: Nov. 29,1999, pp. 97-111. 
a. Recall that in Exercise 5.18a, the t-distribution was 
employed to make an inference about the true 
mean 5-year revenue growth rate for the 1999 Tech- 
nology Fast 500. Explan why the resulting infer- 
ence may be invalid. 
b. Give the null and alternative hypotheses for a 
nonparametric test d e ~ ~ g n e d  
to determine if the 
"average" 5-year revenue growth rate is less than 
5,000 percent. 
c. Conduct the test of part b using a = .05. Interpret 
your result in the context of the problem. 

C 
Y
I 
338 
CHAPTER 
6 
I n f e r e n c e s  Based o n  a S i n g l e  Sample 
~ ~ * ~ m a m m w w m n  
March Madness: 
Handicapping the NCAA Basketball Tourney 
- 
F 
or three weeks each March, the National Collegiate Ath- 
letic Association (NCAA) holds its annual men's basket- 
ball championship tournament. The 64 best college basketball 
teams in the nation play a single-elimination tournament-a 
total of 63 games-to 
determine the NCAA champion. Due 
to its extreme popularity (all 63 games are televised by CBS), 
the media refers to the tournament as "March Madness." 
The NCAA groups the 64 teams into four regions (East, 
South, Midwest, and West) of 16 teams each. The teams in 
each region are ranked (seeded) from 1 to 16 based on their 
performance during the regular season. The NCAA con- 
siders such factors as overall record, strength of schedule, 
average margin of victory, wins on the road, and confer- 
ence affiliation to determine a team's seeding. In the first 
round, the number one seed plays the number 16 seed, the 
second seed plays the fifteenth seed, the third seed plays 
the fourteenth seed, etc. (See Figure 6.20.) Winners contin- 
ue playing until the champion is determined. 
Tournament followers, from hardcore gamblers to the 
casual fan who enters the office betting pool, have a strong 
FIGURE 6.20 
The design of a 16-team NCAA 
regional tournament 
6 
Key Terms 
Note: Starred (*) items are from the 
*Nonparametric Method 332 
Test statistic 300 
optional section in this chapter. 
Null hypothesis 300 
Wo-tailed test 306 
Alternative (research) hypothesis 300 
Observed significance level (p-value) 313 
Type I error 301 
Conclusion 304 
One-tailed test 306 
Type I1 error 303 
Level of significance 304 
Rejection region 302 
Upper-tailed test 307 
Lower-tailed test 307 
*Sign Test 332 

interest in handicapping the games. Obviously, predicting 
the eventual champion is a prime interest. However, know- 
ing who will win each game and the margin of victory may 
be just as important. To provide insight into this phenome- 
non, statisticians Hal Stern and Barbara Mock analyzed 
data from the past 13 NCAA tournaments and published 
their results in Chance (Winter 1998). The results of first- 
round games are summarized in Table 6.4. 
F o c u s  
a. A common perception among fans, media, and gamblers 
is that the higher seeded team has a better than 50-50 
chance of winning a first-round game. Is there evidence 
to support this perception'? Conduct the appropriate test 
for each matchup. What trends do you observe? 
b. Is there evidence to support the claim that a I-, 2-, 3-, or 4- 
seeded team will win by an average of more than 10 points 
in first-round games? Conduct the appropriate test for 
each matchup. 
c. Is there evidence to support the claim that a 5-, 6-, 7-, or 
8-seeded team will win by an average of less than five 
points in first-round games? Conduct the appropriate 
test for each matchup. 
d. The researchers also calculated the difference between 
the game outcome (victory margin, in points) and point 
spread estabhshed by Las Vegas oddsmakers for a Sam- 
ple of 360 recent NCAA tournament games. The mean 
difference is .7 and the standard deviation of the differ- 
ence is 11.3. If the true mean difference is 0, then the 
point spread can be considered a good predictor of 
the game outcome. Use this sample information to 
test the hypothesis that the point spread, on average, is a 
good predictor of the victory margin in NCAA tourna- 
ment games. 
TABLE 
6.4 
Summary of First-Round NCAA Tournament Cames, 1985-1 997 
Number Won 
Margin of Victory (Points) 
................................................................. 
Matchup 
Number 
by Favorite 
(Seeds) 
of Games 
(Higher Seed) 
Mean 
Standard Deviation 
................................................................................................................................................................................ 
1 vs 16 
52 
62 
22.9 
12.4 
2vs 15 
52 
49 
17.2 
11.4 
3 vs 14 
52 
41 
10.6 
12.0 
4 vs 13 
52 
42 
10.0 
12.5 
5 vs 12 
52 
37 
5.3 
10.4 
6vs11 
52 
36 
4.3 
10.7 
7 vs 10 
52 
35 
3.2 
10.5 
8vs 9 
52 
22 
-2.1 
11.0 
Source: Stern, H. S., and Mock, B. "College basketball upsets: Will a 16-seed ever beat a 1-seed?" 
Chance, Vol. 11, No. 1, Winter 1998, p. 29 (Table 3). 
................................................................................................................................................................................................................................................... 
Key Formulas 
A 
0 - 60 
For testing H,,: 0 = O,, the large-sample test statistic is z = - 
where G, O,,, and q are obtained from the table below: 
" 8  
Parameter, 
Hypothesized Parameter Value, 
Estimator, 
Standard Error of Estimator, 
........................................................................................................................................................................................................................ 
- 

340 
 CHAPTER^ 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
For testing H,: p = p,, the small-sample test statistic is 
- 
t = -  - 
321 
s/ di 
*For testing Ho: 71 = 70, the nonparametric test statistic is: 
S = the number of the sample measurements greater than (or less than) 71, 
(S - .5) - .5n 
z 
= 
.5 VL 
(small samples) 
334 
(large samples) 
335 
Symbol 
Pronunciation 
Description 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Ho 
H-oh 
Null hypothesis 
HZ! 
H-a 
a 
alpha 
P 
beta 
, 
eta 
Alternative hypothesis 
Probability of Type 1 error 
Probability of Type I1 error 
Test statistic for slgn test 
Populat~on median 
Note: Starred (*) exercises refer to the optional section in 
this chapter. 
Learning the Mechanics 
6.73 Complete the following statement: The smaller the p-value 
associated with a test of hypothesis, the stronger the sup- 
port for the 
hypothesis. Explain your answer. 
6.74 Which of the elements of a test of hypothesis can and 
should be specified prior to analyzing the data that are 
to be utilized to conduct the test? 
b. Test H,,: p = 8.4 against Ha: p # 8.4 Use a = .05. 
6.78 A t-test is conducted for the null hypothesis HI,: = 10 
versus the alternative Ha: p > 10 for a random sample 
of n = 17 observations. The data are analyzed usmg 
MINITAB, with the results shown below. 
a. Interpret the p-value. 
b. What assumptions are necessary for the validity of 
this test? 
c. Calculate and interpret thep-value assuming the al- 
ternative hypothesis was instead Ha: p + 10. 
6.75 A random sample of 20 observations selected from a 
normal population produced i = 72.6 and s2 = 19.4 
Applying the Concepts 
a. Test H,: p = 80 against Ha: p < 80. Use a = .05. 
6.79 "Take the Pepsi Challenge" was a marketing campaign 
b. Test H,: p = 80 against Ha: p # 80. Use a = .01. 
used recently by the Pepsi-Cola Company. Coca-Cola 
6.76 A random sample of n = 200 observations from a 
drinkers participated in a blind taste test where they 
binomial population yields 
= .29. 
were asked to taste unmarked cups of Pepsi and Coke 
a. Test HI,: p = .35 against H:,: p < .35. Use a = .05. 
and were asked to select their favorite. In one Pepsi 
b. Test HI,: p = .35 against Ha: p # .35. Use a = .05. 
television commercial, an announcer states that "in 
TEST OF MU = 10.000 VS MU G.T. 10.000 
N 
MEAN 
STDEV 
SE MEAN 
T 
P VALUE 
X 
17 
12.50 
8.78 
2.13 
1.174 
.I288 
6.77 A random sample of 175 measurements possessed a 
reccnt blind taste tests, more than half the D ~ e t  Coke 
mean i = 82 and a standard deviation s = .79. 
drinkers surveyed said they preferred the ta5te of Diet 
a. Test HI,: p = 8.3 against Ha: p # 8.3 Use a = .05. 
Pepsi" (Consumer's Research, May 1993). Suppose 100 
MINITAB Output for Exercise 6.78 

Diet Coke drinkers took the Pepsi Challenge and 56 
preferred the taste of Diet Pepsi. Test the hypothesis 
that more than half of all Diet Coke drinkers will select 
Diet Pepsi in the blind taste test. Use a = .05. What 
are the consequences of the test results from Coca- 
Cola's perspective? 
6.80 Medical tests have been developed to detect many 
serious diseases. A medical test is designed to mini- 
mize the probability that it will produce a "false pos- 
itive" or a "false negative." A false positive refers to 
a positive test result for an individual who does not 
have the disease, whereas a false negative is a nega- 
tive test result for an individual who does have the 
disease. 
a. If we treat a medical test for a disease as a statistical 
test of hypothesis, what are the null and alternative 
hypotheses for the medical test? 
b. What are the Type I and Type I1 errors for the 
test? Relate each to false positives and false nega- 
tives. 
c Which of the errors has graver consequences? Con- 
sidering this error, is it more important to minimize 
a or /3? Explain. 
6.81 The trade publication Potentials in Marketing 
(Nov./Dec. 1995) surveyed its readers concerning 
their opinions of electronic marketing (i.e., market- 
ing via the Internet, e-mail, CD-ROMs, etc.). A ques- 
tionnaire was faxed to 1 .500 randomly selected U.S. 
readers in August and September 1995. Of the 195 
questionnaires that were returned, 37 reported that 
their company already has a World Wide Web site 
and 59 indicated that their company had plans to 
create one. 
a. Do these data provide sufficient evidence to reject 
the claim by a producer of a well-known Web 
browser that "more than 25% of all U.S. businesses 
will have Web sites by the middle of 1995"? 
b. Discuss potential problems associated with the sam- 
pling methodology and the appropriateness of the 
sample for making generalizations about all U.S. 
businesses. 
6.82 The Lincoln Tunnel (under the Hudson River) con- 
nects suburban New Jersey to midtown Manhattan. 
On Mondays at 8:30 A.M., the mean number of cars 
waiting in line to pay the Lincoln Tunnel toll is 1,220. 
Because of the substantial wait during rush hour, the 
Port Authority of New York and New Jersey is consid- 
ering raising the amount of the toll between 7:30 and 
8:30 A.M. to encourage more drivers to use the tunnel 
MINITAB Output for Exercise 6.83 
S u p p l e m e n t a r y  E x e r c i s e s  
341 
at an earlier or later time (Newark Star-Ledger, Aug. 
27,1995). Suppose the Port Authority experiments 
with peak-hour pricing for six months, increasing the 
toll from $4 to $7 during the rush hour peak. On 10 dif- 
ferent workdays at 8:30 A.M. aerial photographs of the 
tunnel queues are taken and the number of vehicles 
counted. The results follow: 
Analyze the data for the purpose of determining 
whether peak-hour pricing succeeded in reduclng the 
average number of vehicles attempting to use the 
Lincoln Tunnel during the peak rush hour. Utilize 
the information in the accompanying EXCEL printout. 
EXCEL Output for Exercise 6.82 
Count 
I Standard Error 
1 
50.81006025 1 
Mean 
989.8 
Standard Deviation 
160.6755184 
Ranae 
Median 
I Minimum 
I 
735 1 
970.5 
Mode 
Maximum 
6.83 In order to be effective, the mean length of life of a 
certain mechanical component used in a spacecraft 
must be larger than 1,100 hours. Owing to the pro- 
hibitive cost of this component, only three can be 
tested under simulated space conditions. The life- 
times (hours) of the components were recorded and 
the following statistics were computed: i = 1,173.6 
and s = 36.3. These data were analyzed using 
MINITAB, with the results shown in the printout 
below. 
#N/A 
1260 
Count 
TEST OF MU = 1100 VS MU G.T. 1100 
N 
MEAN 
STDEV 
SE MEAN 
T 
P VALUE 
COMP 
3 
1,173.6 
36.3 
20.96 
3.512 
.0362 
Sum 
I 
9898 
10 
Confidence Leve1(95.000%) 
1 
99.58574067 

\ 
342 
CHAPTER 
6 
I n f e r e n c e s  B a s e d  o n  a S i n g l e  S a m p l e  
a. Verify that the software has correctly calculated the 
t statistic and determine whether the p-value is in 
the appropriate range. 
b. Interpret the p-value. 
c. Which type of error, I or 11, is of greater concern for 
this test? Explain. 
d. Would you recommend that this component be 
passed as meeting specifications? 
6.84 In Exercise 6.25 (p. 312) you tested H,: p 2 10 versus 
Ha: p < 10, where p is the average number of solder 
joints inspected per second when the joints are spaced 
.1 inch apart. An SPSS printout of the hypothesis test is 
shown below. 
a. Locate the two-tailed p-value of the test shown on 
the printout. 
b. Adjust the p-value for the one-tailed test (if neces- 
sary) and interpret its value. 
6.85 Sales promotions that are used by manufacturers to 
entice retailers to carry, feature, or push the manufac- 
turer's products are called trade promotions. A survey 
of 250 manufacturers conducted by Cannondale 
Associates, a sales and marketing consulting firm, 
found that 91% of the manufacturers believe their 
spending for trade promotions is inefficient (Potentials 
in Marketing, June 1995). Is this sufficient evidence to 
reject a previous claim by the American Marketing 
Association that no more than half of all manufacturers 
are dissatisfied with their trade promotion spending? 
a. Conduct the appropriate hypothesis test at a = .02. 
Begin your analysis by determining whether the 
sample size is large enough to apply the testing 
methodology presented in this chapter. 
b. Report the observed significance level of the test and 
interpret its meaning in the context of the problem. 
6.86 A consumer protection group is concerned that a 
ketchup manufacturer is filling its 20-ounce family-size 
containers with less than 20 ounces of ketchup. The 
group purchases 10 family-size bottles of this ketchup, 
weighs the contents of each, and finds that the mean 
weight is equal to 19.86 ounces, and the standard devi- 
ation is equal to .22 ounce. 
a. Do the data provide sufficient evidence for the con- 
sumer group to conclude that the mean fill per fam- 
ily-size bottle is less than 20 ounces? Test using 
a = .05 
b. If the test in part a were conducted on a periodic 
basis by the company's quality control department. 
is the consumer group more concerned about the 
company's making a Type I error or a Type I1 error? 
(The probability of making this type of error is 
called the consumer's risk.) 
c. The ketchup company is also interested in the mean 
amount of ketchup per bottle. It does not wish to 
overfill them. For the test conducted in part a, 
which type of error is more serious from the com- 
pany's point of view-a 
Type I error or a Type I1 
error? (The probability of making this type of error 
is called the producer's risk.) 
6.87 The EPA sets an airborne limit of 5 parts per million 
(ppm) on vinyl chloride, a colorless gas used to make 
plastics, adhesives, and other chemicals. It is both a 
carcinogen and a mutagen (New Jersey Department 
of Health, Hazardous Substance Fact Sheet, Dec. 
1994). A major plastics manufacturer, attempting to 
control the amount of vinyl chloride its workers are 
exposed to, has given instructions to halt production 
if the mean amount of vinyl chloride in the air 
exceeds 3.0 ppm. A random sample of 50 air speci- 
mens produced the following statistics: 2 = 3.1 ppm. 
s = .5 ppm. 
a. Do these statistics provide sufficient evidence to 
halt the production process? Use a = .01. 
b. If you were the plant manager, would you want to 
use a large or a small value for a for the test in part a? 
Explain. 
c. Find the p-value for the test and interpret its value. 
One way of evaluating a measuring instrument is to 
repeatedly measure the same item and compare the 
average of these measurements to the item's known 
measured value. The difference is used to assess the 
instrument's accuracy (Quality Progress, Jan. 1993).To 
evaluate a particular Metlar scale, an item whose 
weight is known to be 16.01 ounces is weighed five 
times by the same operator. The measurements, in 
ounces, are as follows: 
SPSS Output for Exercise 6.84 
Variable 
Number 
Standard 
Standard 
of Cases 
Mean 
Deviation 
Error 
(Difference) Standard Standard 
t 
Degrees of 
2-Tail 
Mean 
Deviation 
Error 
Value 
Freedom 
Prob . 

a. In a statistical sense, does the average measure- 
ment differ from 16.01? Conduct the appropriate 
hypothesis test. What does your analysis suggest 
about the accuracy of the instrument? 
b. List any assumptions you make in conducting the 
hypothesis test. 
*c. Conduct the appropriate nonparametric test of the 
data. Interpret the results. 
6.89 According to the National Restaurant Association, 
hamburgers are the number one selling fast-food item 
in the United States (Newark Star-Ledger, Mar. 17, 
1997). An economist studying the fast-food buying 
habits of Americans paid graduate students to stand 
outside two suburban McDonald's restaurants near 
Boston and ask departing customers whether they 
spent more or less than $2.25 on hamburger products 
for their lunch. Twenty answered "less than"; 50 said 
"more than"; and 10 refused to answer the question. 
a. Is there sufficient evidence to conclude that the me- 
dian amount spent for hamburgers at lunch at Mc- 
Donald's is less than $2.25? 
b. Does your conclusion apply to all Americans who 
eat lunch at McDonald's? Justify your answer. 
c. What assumptions must hold to ensure the validity 
of your test in part a? 
6.90 One study (Journal of Political Economy, Feb. 1988) 
of gambling newsletters that purport to improve a 
bettor's odds of winning bets on NFL football games 
indicates that the newsletters' betting schemes were 
not profitable. Suppose a random sample of 50 games 
is selected to test one gambling newsletter. Following 
the newsletter's recommendations, 30 of the 50 games 
produced winning wagers. 
a. Test whether the newsletter can be said to signifi- 
cantly increase the odds of winning over what one 
could expect by selecting the winner at random. 
Use a = .05 
b. Calculate and interpret the p-value for the test. 
6.91 The "beta coefficient" of a stock is a measure of the 
stock's volatility (or risk) relative to the market as a 
whole. Stocks with beta coefficients greater than 1 
generally bear greater risk (more volatility) than the 
market, whereas stocks with beta coefficients less than 
1 are less risky (less volatile) than the overall market 
(Alexander, Sharpe, and Bailey, Fundamentals of 
Investments, 1993). A random sample of 15 high- 
technology stocks was selected at the end of 1996, and 
the mean and standard deviation of the beta coeffi- 
cients were calculated: T = 1.23, s = .37 
a. Set up the appropriate null and alternative hy- 
potheses to test whether the average high- 
S u p p l e m e n t a r y  E x e r c i s e s  
343 
technology stock is riskier than the market as a 
whole. 
b. Establish the appropriate test statistic and rejec- 
tion region for the test. Use a = .lo. 
c. What assumptions are necessary to ensure the va- 
lidity of the test? 
d. Calculate the test statistic and state your conclu- 
sion. 
e. Interpret the p-value on the SAS computer output 
shown here. (Prob > IT on the SAS printout cor- 
responds to a two-tailed test of the null hypothesis 
p = 1.) 
f. If the alternative hypothesis of interest is p > 1, 
what is the appropriate p-value of the test? 
SAS Output for Exercise 6.91 
Analysis Variable : BETA-1 
6.92 The manufacturer of an over-the-counter analgesic 
claims that its product brings pain relief to headache 
sufferers in less than 3.5 minutes, on average. In order 
to be able to make this claim in its television adver- 
tisements, the manufacturer was required by a partic- 
ular television network to present statistical evidence 
in support of the claim. The manufacturer reported 
that for a random sample of 50 headache sufferers, 
the mean time to relief was 3.3 minutes and the stan- 
dard deviation was 1.1 minutes. 
a. Do these data support the manufacturer's claim? 
Test using a = .05. 
b. Report the p-value of the test. 
c. In general, do large p-values or small p-values sup- 
port the manufacturer's claim? Explain. 
6.93 According to the U. S. Department of Commerce, the 
average price for a new home topped $200.000 for 
the first time in 1999. In November 1999, the average 
new-home price was $209.700 (Wall Street Journal 
Interactive Edition, Jan. 7, 2000). The prices of a 
random sample of 32 new homes sold in November 
2000 yielded T = $216,981 and s = $19,805. 
a. What are the appropriate null and alternative hy- 
potheses to test whether the mean price of a new 
home in November 2000 exceeds $209,700? 
b. Compute and interpret the p-value of the test. Do 
the data provide sufficient evidence to conclude 
that the mean new-home price in November 2000 
exceeded the reported mean price of November 
1999? 

C O M P A R I N G  P O P U L A T I O N  M E A N S  
Comparing Two Population Means: Independent Sampling 
Comparing Two Population Means: Paired Difference Experiments 
Determining the Sample Size 
Testing the Assumption of Equal Population Variances (Optional) 
A Nonparametric Test for Comparing Two Populations: Independent Sampling 
(Optional) 
A Nonparametric Test for Comparing Two Populations: Paired Difference 
. 
Experiments (Optional) 
Comparing Three or More Population Means: ANOVA (Optional) 
S T A T I S T I C S  
I N  A
C
T
I
O
N
 
On the Trail of the Cockroach 
( W h e r e  W e ' v e  B e e n  
I 
W 
e explored two methods for making statistical 
inferences, confidence intervals and tests of 
hypotheses, in Chapters 5 and 6. In particular, we 
studied confidence intervals and tests of hypotheses 
concerning a single population mean p and a single 
population proportion p. We also learned how to se- 
lect the sample size necessary to obtain a specified 
amount of information concerning a parameter. 
r e  W e ' r e  G o i n g  
N 
ow that we've learned to make inferences about 
a single population, we'll learn how to compare 
two populations. For example, we may wish to com- 
pare the mean gas mileages for two models of auto- 
mobiles. In this chapter we'll see how to decide 
whether differences exist and how to estimate the dif- 
ferences between population means. We will learn 
how to compare population proportions in Chapter 8. 

346 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Many experiments involve a comparison of two population means. For in- 
stance, a consumer group may want to test whether two major brands of food 
freezers differ in the mean amount of electricity they use. A golf ball supplier may 
wish to compare the average distance that two competing brands of golf balls trav- 
el when struck with the same club. In this chapter we consider techniques for 
using two (or more) samples to compare the populations from which they were 
selected. 
'QI COMPARING T W O  POPULATION MEANS: 
INDEPENDENT SAMPLING 
Many of the same procedures that are used to estimate and test hypotheses about 
a single parameter can be modified to make inferences about two parameters. 
Both the z and t statistics may be adapted to make inferences about the difference 
between two population means. 
In this section we develop both large-sample and small-sample methodologies 
for comparing two population means. In the large-sample case we use the z statistic. 
while in the small-sample case we use the t statistic. 
Large Samples 
regarding restrictions on trade between the two countries. One of the claims made 
repeatedly by U.S. officials is that many Japanese manufacturers price their goods 
higher in Japan than in the United States, in effect subsidizing low prices in the 
United States by extremely high prices in Japan. According to the U.S. argument, 
Japan accomplishes this by keeping competitive U.S. goods from reaching the 
Japanese marketplace. 
An economist decided to test the hypothesis that higher retail prices are 
being charged for Japanese automobiles in Japan than in the United States. She 
obtained random samples of 50 retail sales in the United States and 30 retail sales 
in Japan over the same time period and for the same model of automobile, con- 
verted the Japanese sales prices from yen to dollars using current conversion 
rates, and obtained the summary information shown in Table 7.1. Form a 95% con- 
fidence interval for the difference between the population mean retail prices of 
this automobile model for the two countries. Interpret the result. 
TABLE 
7.1 
Summary Statistics for Automobile Retail Price Study 
U.S. Sales 
Japan Sales 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Sample size 
50 
30 
Sample mean 
$16,545 
$17,243 
Sample standard deviation 
$ 1,989 
$ 1,843 
S o 1 u t i o n 
Recall that the general form of a large-sample confidence interval for a single 
mean p is 5;; f z,/,ap That is, we add and subtract z,/, standard deviations of the 
sample estimate, i, 
to the value of the estimate. We employ a similar procedure 
to form the confidence interval for the difference between two population 
means. 

SECTION 7.1 
C o m p a r i n g  Two Population Means: I n d e p e n d e n t  Sampling 
347 
Let p1 represent the mean of the population of retail sales prices for this car 
model sold in the United States. Let p2 be similarly defined for retail sales in 
Japan. We wish to form a confidence interval for ( p ,  - p2). An intuitively ap- 
pealing estimator for ( p ,  - p2j is the difference between the sample means, 
(Fl - T 2 )  Thus, we will form the confidence interval of interest by 
Assuming the two samples are independent, the standard deviation of the differ- 
ence between the sample means is 
Using the sample data and noting that a = .05 and 2 . 0 ~ ~  
= 1.96, we find that the 
95% confidence interval is, approximately, 
or (-1,558,162). Using this estimation procedure over and over again for differ- 
ent samples, we know that approximately 95% of the confidence intervals formed 
in this manner will enclose the difference in population means ( p l  - p2). There- 
fore, we are highly confident that the difference in mean retail prices in the Unit- 
ed States and Japan is between -$1,558 and $162. Since 0 falls in this interval, the 
economist cannot conclude that a significant difference exists between the mean 
retail prices in the two countries. 
* 
The justification for the procedure used in Example 7.1 to estimate 
( p ,  - p2) relies on the properties of the sampling distribution of (TI - G). The 
performance of the estimator in repeated sampling is pictured in Figure 7.1, and 
its properties are summarized in the box. 
, 
* 
b V  
' ,  . 
- 
Properties of the Sampling Distribution of (x, - x,) 
- 
The mean of the sampling distribution (Y1 - x2) is (pI - p2). 
If the two samples are independent, the standard deviation of the Sam 
pling distribution is 
V(y,-y2) 
= dz 
where a: and a$ are the variances of the two populations being sample 
and n, and n2 are the respective sample sizes. We also refer to VP,-X~) 
a 
- 
the standard error of the statistic (xl - x2). 
- 
The sampling distribution of (TI - x2) is approximately normal for larg 
samples by the Central Limit Theorem. 

348 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
In Example 7.1, we noted the similarity in the procedures for forming a 
large-sample confidence interval for one population mean and a large-sample 
confidence interval for the difference between two population means. When we 
are testing hypotheses, the procedures are again very similar. The general large- 
sample procedures for forming confidence intervals and testing hypotheses about 
(p, - p2) are summarized in the next two boxes. 
Assumptions: The two samples are randomly selected in an independent 
manner from the two populations. The sample sizes, n, and n,, are large 
enough so that 7, and & both have approximately normal sampling distribu- 
1 
tions and so that s: and s; provide good approximations to a: and a:. This will 
, 
be true if n, r 30 and n2 2 30. 
I 
pothesis for (p, - p2) 
i j I 
One-Tailed Test 
Two-Tailed Test 
i 
Ho: (PI - P 2 )  = Do 
Ho: (PI - F 2 )  = DO 
Ha: (PI - ~
2
)
 
< DO 
Ha: (PI - ~ * 2 )  + DO 
[or Ha: (PI - F2) > Do1 
where Do = Hypothesized difference between the means (this difference is 
often hypothesized to be equal to 0) 
Test statistic: 
Rejection region: / z /  > z a , ~  
tions: Same as for the large-sample confidence interval. 

SECTION 7.1 
C o m p a r i n g  Two Population Means: I n d e p e n d e n t  Sampling 
349 
S o l u t i o n  
Japan, Example 7.1. Another way to compare the mean retail prices for the two 
countries is to conduct a test of hypothesis. Use the summary data in Table 7.1 to 
conduct the test. Use a = .05. 
Again, we let p, and p2 represent the population mean retail sales prices in the 
United States and Japan, respectively. If the claim made by the U.S. government is 
true, then the mean retail price in Japan will exceed the mean in the U.S., i.e., 
p1 < p2 or (p, - p2) < 0. Thus, the elements of the test are as follows: 
H,: (pl - p2) = 0 (i.e., pl = pZ; note that Do = 0 for this hypothesis test) 
Ha: (pt - ~
2
)
 
< 0 (i.e.9 PI < ~
2
)
 - 
- 
(XI - &) - DO XI - X' - 0 
Test statistic: z = 
- 
- 
U(i1-X2) 
U(X, X , )  
Rejection region: z < - Z , ~ S  = -1.645 
(see Figure 7.2) 
Substituting the summary statistics given in Table 7.1 into the test statistic, we obtain 
As you can see in Figure 7.2, the calculated z value does not fall in the rejection 
region. Therefore, the samples do not provide sufficient evidence, at a = .05, for 
the economist to conclude that the mean retail price in Japan exceeds that in the 
United States. 
FIGURE 7.2 
Rejection region for Example 7.2 
a = .05 
Note that this conclusion agrees with the inference drawn from the 95% confi- 
dence interval in Example 7.1. 
* 
, 
& 
" -< 
" 
,-,-,- 
- . , 
Find the obwrvcd significance Ic\ el for the tcst in Ewnplc 7.2. Interpret the result. 
S o  I  u t i  o  n The alternative hypothesis in Example 7.2, Ha: 
- k )  < 0, required a lower 
one-tailed test using 

350 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  Means 
as a test statistic. Since the value z calculated from the sample data was -1.59, the 
observed significance level (p-value) for the lower-tailed test is the probability of 
observing a value of z more contradictory to the null hypothesis as z = -1.59; 
\ 
that is. 
p-value = P(z < -1.59) 
This probability is computed assuming H, is true and is equal to the shaded area 
shown in Figure 7.3. 
FIGURE 7.3 
p-value = ,0559 
The observed significance level 
for Example 7.2 Y
-1.59 
0 
The tabulated area corresponding to z = 1.59 in Table IV of Appendix B is 
.4441. Therefore, the observed significance level of the test is 
p-value = .5 - .4441 = .0559 
Since our selected a value, .05, is less than this p-value, we have insufficient evi- 
dence to reject H,: (P, - p2) = 0 in favor of Ha: (p, - p2) < 0. 
The p-value of the test is more easily obtained from a statistical software 
package. A MINITAB printout for the hypothesis test is displayed in Figure 7.4. 
The one-tailedp-value, highlighted on the printout, is .056. [Note that MINITAB 
also gives a 95% confidence interval for (p, - 4. 
This interval agrees with the 
interval calculated in Example 7.1.1 
pa 
FIGURE 7.4 
MINITAB printout 
hypothesis test of 
for the 
Example 7.2 
TWO sample T for US VS JAPAN 
N 
Mean 
StDev 
SE Mean 
US 
5 0 
16545 
1989 
281.29 
JAPAN 30 
17243 
1843 
336.48 
95% CI for mu US - mu JAPAN: (-1558, 162) 
T-Test mu US = mu JAPAN (vs < ) :  T= -1.59 P=0.056 DF= 78 
tailed and two-tailed tests. However, SAS and SPSS conduct only two-tailed 
hypothesis tests. For these packages, obtain the p-value for a one-tailed test 
as follows: 
Reported p-value 
P = 
3 
if form of H, (e.g. 
agrees with sign of test sta- 
& 
tistic (e.g., negative) 
p = l -  
.g., < ) disagrees with sign of 

SECTION 7.1 
C o m p a r i n g  T w o  P o p u l a t i o n  Means: I n d e p e n d e n t  S a m p l i n g  
351 
Small Samples 
When comparing two population means with small samples (say, n, < 30 and 
n, < 30), the methodology of the previous three examples is invalid.The reason? 
When the sample sizes are small, estimates of a: and cr; are unreliable and the 
Central Limit Theorem (which guarantees that the z statistic is normal) can no 
longer be applied. But as in the case of a single mean (Section 6.4), we use the fa- 
miliar Student's t-distribution described in Chapter 5. 
To use the t-distribution, both sampled populations must be approximately 
normally distributed with equal population variances, and the random samples 
must be selected independently qf each other. The normality and equal variances 
assumptions imply relative frequency distributions for the populations that would 
appear as shown in Figure 7.5. 
FIGURE 7.5 
Assumptions for the two-sample t: (1) normal 
populations, (2) equal variances 
P2 
P1 - 
(PI - P2 > 0) 
Since we assume the two populations have equal variances (a: = a: = a2), 
it is reasonable to use the information contained in both samples to construct a 
pooled sample estimator of u2 for use in confidence intervals and test statistics. 
Thus, if s: and si are the two sample variances (both estimating the variance u2 
common to both populations), the pooled estimator of a2, denoted as si, is 
(n1 - 1)s: + (n, - 1)s; 
(nl - 1)s: + (n, - 1)s; 
s; = 
- 
- 
(nl - 1) + (n2 - 1) 
n, + n, - 2 
From sample 1 From sample 2 
- - 
where xl represents a measurement from sample 1 and x2 represents a measurement 
from sample 2. Recall that the term degrees of freedom was defined in Section 5.2 as 
1 less than the sample size. Thus, in this case, we have (n, - 1) degrees of free- 
dom for sample 1 and (n2 - 1) degrees of freedom for sample 2. Since we are 
pooling the information on a2 obtained from both samples, the degrees of free- 
dom associated with the pooled variance s; is equal to the sum of the degrees 
of freedom for the two samples, namely, the denominator of s:; 
that is, 
(nl - 1) + (n2 - 1 )  = n, + n2 - 2. 
Note that the second formula given for si shows that the pooled variance is 
simply a weighted average of the two sample variances, s: and 5;. The weight given 
each variance is proportional to its degrees of freedom. If the two variances have 
the same number of degrees of freedom (i.e., if the sample sizes are equal), then the 
pooled variance is a simple average of the two sample variances. The result is an av- 
erage or "pooled" variance that is a better estimate of a2 than either s: or s; alone. 

352 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Both the confidence interval and the test of hypothesis procedures for com- 
paring two population means with small samples are summarized in the accom- 
panying boxes. 
/ 
(nl - 1)s: + (nZ - 1)s; 
nl f nZ - 2 
is based on (al + n2 - 2) degrees of freedom. 
, ' 
umptions: 1. Both sampled populations have relative frequency distrib- 
utions that are approximately normal. 
2. The population variances are equal. 
3. The samples are randomly and independently selected 
from the population. 
+ n, - 2) degrees of freedom. 
ssumptions: Same 
he small-sample confidence interval for 
n the previous box 
a"" """"-"m"--m-m-Mm---*m-*--*msP*- 
ers have developed an index designed to measure manager 
a1 success. The index (measured on a 100-point scale) is based on the manager's 
length of time in the organization and his or her level within the firm; the higher 
the index, the more successful the manager. Suppose a researcher wants to com- 
pare the average success index for two groups of managers at a large manufac- 
turing plant. Managers in group 1 engage in a high volume of interactions with 
people outside the manager's work unit. (Such interactions include phone and 
face-to-face meetings with customers and suppliers, outside meetings, and public 
relations work.) Managers in group 2 rarely interact with people outside their 
work unit. Independent random samples of 12 and 15 managers are selected from 

SECTION 7.1 
C o m p a r i n g  T w o  P o p u l a t i o n  M e a n s :  I n d e p e n d e n t  S a m p l i n g  
353 
groups 1 and 2, respectively, and the success index of each recorded. The results of 
the study are given in Table 7.2. 
S o l u t i o n  
TABLE 
7.2 
Managerial Success Indexes for Two Croups of Managers 
FIGURE 7.6 
SAS printout for Example 7.4 
Croup 1 
.................................................................................................................................................. 
Interaction with Outsiders 
.............................................................................................................................................................. 
65 
58 
78 
60 
68 
69 
66 
70 
53 
71 
63 
63 
a. Use the data in the table to estimate the true mean difference between the 
success indexes of managers in the two groups. Use a 95% confidence inter- 
val, and interpret the interval. 
b. What assumptions must be made in order that the estimate be valid? Are 
they reasonably satisfied? 
Croup 2 
Few Interactions 
62 
53 
36 
34 
56 
50 
42 
57 
46 
68 
48 
42 
52 
53 
43 
a. For this experiment, let p1 and p2 represent the mean success index of group 
1 and group 2 managers, respectively.Then, the objective is to obtain a 95% 
confidence interval for ( p ,  - p2). 
The first step in constructing the confidence interval is to obtain summary 
statistics (e.g.,i and s) on the success index for each group of managers.The 
data of Table 7.2 were entered into a computer, and SAS was used to obtain 
these descriptive statistics. The SAS printout appears in Figure 7.6. Note 
that i, = 65.33, s, = 6.61, i2 
= 49.47, and s2 = 9.33. 
Analysis Variable : SUCCESS 
N Obs 
N 
Minimum 
Maximum 
Mean 
Std Dev 
......................................................... 
N Obs 
N 
Minimum 
Maximum 
Mean 
StdDev 
Next, we calculate the pooled estimate of variance: 
where s i  is based on (n, + n2 - 2) = (12 + 15 - 2) = 25 degrees of free- 
dom. Also, we find 
= t,025 = 2.06 (based on 25 degrees of freedom) from 
Table VI of Appendix B. 

354 
CHAPTER 
7 
C o m p a r i n g  Population Means 
I 
F I G U R E  7.7 
SPSS normal probability plots 
for Example 7.4 
Finally, the 95% confidence interval for (pl - p2), the difference between 
mean managerial success indexes for the two groups, is 
or (9.28, 22.44). Note that the interval includes only positive differences. 
Consequently, we are 95% confident that (pl - p2) exceeds 0. In fact, we 
estimate the mean success index, p,, for managers with a high volume of 
Normal Q-Q Plot of SUCCESS 
For GROUP = 1.00 
50 
60 
Observed Value 
Normal Q-Q Plot of SUCCESS 
For GROUP = 2.00 
30 
40 
Observed Value 

C o m p a r i n g  Two Population Means: I n d e p e n d e n t  Sampling 
355 
outsider interaction (group 1) to be anywhere between 9.28 and 22.44 points 
higher than the mean success index, p2, of managers with few interactions 
(group 2). 
b. To properly use the small-sample confidence interval, the following assump- 
tions must be satisfied: 
1. The samples of managers are randomly and independently selected from 
the populations of group 1 and group 2 managers. 
2. The success indexes are normally distributed for both groups of managers. 
3. The variance of the success indexes are the same for the two popula- 
tions, i.e., cr: = a:. 
The first assumption is satisfied, based on the information provided about 
the sampling procedure in the problem description. To check the plausibility 
of the remaining two assumptions, we resort to graphical methods. Figure 7.7 
is a portion of an SPSS printout that displays normal probability plots 
(called Q-Q plots) for the success indexes of the two samples of managers. 
The near straight-line trends on both plots indicate that the success index 
distributions are approximately mound-shaped and symmetric. 
Consequently, each sample data set appears to come from a population that 
is approximately normal. 
One way to check assumption #3 is to test the null hypothesis H,: u; = a$ 
This test is covered in optional Section 7.4. Another approach is to exam- 
ine box plots for the sample data. Figure 7.8 is an SPSS printout that shows 
side-by-side vertical box plots for the success indexes in the two samples. 
Recall, from Section 2.9, that the box plot represents the "spread" of a data 
set. The two box plots appear to have about the same spread; thus, the 
samples appear to come from populations with approximately the same 
variance. 
SPSS box plots for 
Example 7.4 
80 
Group 
All three assumptions, then, appear to be reasonably satisfied for this appli- 
cation of the small-sample confidence interval. 
TI 

356 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
The two-sample t statistic is a powerful tool for comparing population means 
when the assumptions are satisfied. It has also been shown to retain its usefulness 
when the sampled populations are only approximately normally distributed. And 
when the sample sizes are equal, the assumption of equal population variances 
can be relaxed. That is, if nl = n2, then a: and (T; can be quite different and the 
test statistic will still possess, approximately, a Student's t-distribution. When the 
assumptions are not satisfied, you can select larger samples from the populations 
or you can use other available statistical tests (nonparametric statistical tests). A 
nonparametric test for independent samples is presented in optional Section 7.5. 
Learning the Mechanics 
7.1 In order to compare the means of two populations, inde- 
pendent random samples of 400 observations are select- 
ed from each population, with the following results: 
Sample 1 
Sample 2 
a. Use a 95% confidence interval to estimate the dif- 
ference between the population means (pl - p,). 
Interpret the confidence interval. 
b. Test the null hypothesis H,: (pl - p2) = 0 versus the 
alternative hypothesis Ha: (p, - p,) # 0. Give the 
significance level of the test, and interpret the result. 
c. Suppose the test in part b was conducted with the al- 
ternative hypothesis Ha: (p, - p,) > 0. HOW would 
your answer to part b change? 
d. Test the null hypothesis H,: (pl - p,) = 25 versus 
Ha: (pl - p,) # 25. Give the significance level, and 
interpret the result. Compare your answer to the test 
conducted in part b. 
e. What assumptions are necessary to ensure the validi- 
ty of the inferential procedures applied in parts a-d? 
7.2 
To use the t statistic to test for a difference between 
the means of two populations, what assumption\ must 
be made about the two populations? About the two 
samples? 
7.3 
Two populations are described in each of the following 
cases. In which cases would it be appropriate to apply 
the small-sample t-test to investigate the difference 
between the population means? 
a. Population 1: Normal distribution with variance a:. 
Population 2: Skewed to the right with variance 
a; = a:. 
b. Population 1: Normal distribution with variance a:. 
Population 2: Normal distribution with variance 
a; # u:. 
c. Population 1: Skewed to the left with variance a:. 
Population 2: Skewed to the left with variance 
a; = a:. 
d. Population 1: Normal distribution with variance a:. 
Population 2: Normal distribution with variance 
u: = u:. 
e. Population 1: Uniform distribution with variance cry. 
Population 2: Uniform distribution with variance 
u; = a:. 
7.4 
Assume that a: = a; = u2. Calculate the pooled esti- 
mator of a2 for each of the following cases: 
a. s: = 120, s; = 100, n, = n2 = 25 
b. s: = 12, s; = 20, n1 = 20, n, = 10 
c. s: = .15, s; = .20, n, = 6, n, = 10 
d. s: = 3,000, s; = 2,500, n, = 16, n2 = 17 
e. Note that the pooled estimate is a weighted average 
of the sample variances. To which of the variances 
does the pooled estimate fall nearer in each of the 
above cases? 
7.5 
Independent random samples from normal populations 
produced the results shown here. 
Sample 1 
Sample 2 
3.1 
2.7 
1.7 
3.6 
2.8 
3.9 
3.0 
a. Calculate the pooled estimate of a2. 
b. Do the data provide suffic~ent evidence to indicate 
that p, > p,? Test using a = .lo. 
c. Find a 90% confidence interval for (p, - pZ). 
d. Which of the two inferential procedures, the test ot h!- 
pothesis in part b or the confidence interval in part c, 
provides more information about (p, - p,)? 
7.6 
Two independent random samples have been selected. 
100 observations from population 1 and 100 from pop- 
ulation 2. Sample means T, = 15.5 and ?, = 26.6 were 
obtained. From previous experience with these popula- 
tions, it is known that the variances are cr? = 9 and 
a; = 16. 
i 

SECTION 7.1 
C o m p a r i n g  T w o  P o p u l a t i o n  M e a n s :  I n d e p e n d e n t  S a m p l i n g  
357 
a. Find u(,,-,). 
b. Sketch the approximate sampling distribution for 
(TI - &) assuming (pl - p2) = 10. 
c. Locate the observed value of ( i l  - &) on the graph 
you drew in part b. Does it appear that this value 
contradicts the null hypothesis H,,: (P, - P ~ )  
= 10? 
d. Use the z-table on the inside of the front cover to de- 
termine the rejection region for the test of H,: 
(p, - p,) = 10 against H,: (p, - p,) i 
10. Use 
a = .05. 
e. Conduct the hypothesis test of part d and interpret 
your result. 
f. Construct a 95% confidence interval for (pl - 4. 
Interpret the interval. 
g. Which inference provides more information about 
the value of (p, - p2)-the test of hypothesis in part 
e or the confidence interval in part f? 
7.7 Independent random samples are selected from two 
populations and used to test the hypothesis 
H,,: (p, - p2) = 0 
against 
the 
alternative 
H,: (p, - pZ) f 0. A total of 233 observations from 
population 1 and 312 from population 2 are analyzed by 
using MINITAB, with the results shown in the printout. 
a. lnterpret the results of the computer analysis. 
h. I f  the alternative hypothesis had been Ha: 
- p2) < 0, how would the p-value change? In- 
terpret the p-value for this one-tailed test. 
7.8 Independent random samples from approximately 
normal populations produced the results shown below: 
LM7-8.DAT 
, , , , , , , . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Sample 1 
I 
Sample 2 
MINITAB Output for Exercise 7.7 
a. Do the data provide sufficient evidence to conclude 
that (p2 - p,) > lo? Test using a = .01. 
b. Construct a 98% confidence interval for (p, - pl). 
Interpret your result. 
7.9 Independent random samples selected from two normal 
populations produced the sample means and standard 
deviations shown below: 
Sample 1 
Sample 2 
a. The test H,,: (p, - p2) = 0 against Ha: (p, - p2) f 0 
was conducted using SAS, with the results shown in 
the printout at the bottom of the page. Check and in- 
terpret the results. 
b. Estimate (p, - p2) using a 95% confidence interval. 
Applying the Concepts 
7.10 Many psychologists believe that knowledge of a college 
student's relationships with his or her parents can be 
useful in predicting the student's future interpersonal rela- 
tionships both on the job and in private life. Researchers 
at the University of South Alabama compared the atti- 
tudes of male and female students toward their fathers 
(Journal of Genetic Psychology, Mar. 1998). Using a 
five-point Likert-type scale, they asked each group to 
complete the following statement: My relationship with 
my father can best be described as (1) Awful! (2) Poor, 
(3) Average, (4) Good, or (5) Great! The data (adapted 
from the article) are listed in the table on page 358, 
accompanied by a STATISTIX printout of the analysis. 
a. Do male college students tend to have better rela- 
tionships, on average, with their fathers than female 
students? Conduct the appropriate hypothesis test 
using a = .01. 
Two sample Z for X1 v s  X2 
N 
Mean 
StDev 
SEMean 
X1 
233 
473 
8 4 
15.26 
X2 
3 12 
485 
9 3 
17.66 
Z-Test mu XI = mu X2 (vs n.e.): T= -1.576 P=0.1150 
SAS Output for Exercise 7.9 
Variable: X 
I s ~ P L E  N 
Mean 
8td Dev 
Std Error I 
........................................... 

358 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
STATlSTlX Output for Exercise 7.1 0 
TWO-SAMPLE T TESTS FOR FATHRATE BY GENDER 
NULL HYPOTHESIS: DIFFERENCE = 
0 
ALTERNATIVE HYP: DIFFERENCE <> 0 
ASSUMPTION 
T 
DF 
P 
95% CI FOR DIFFERENCE 
F 
NUM DF 
DEN DF 
P 
TESTS FOR EQUALITY 
------- 
------ 
------ 
------ 
OF VARIANCES 
1.99 
89 
43 
0.0068 
FATHER.DAT 
............................................................................................................ 
Father Ratings for Females 
............................................................................................................ 
5
2
5
5
3
3
2
5
2
1
5
4
2
5
3
 
5
4
2
5
5
2
3
4
3
5
4
4
4
2
1
 
5
3
5
4
4
5
5
5
3
5
5
4
5
4
5
 
1
5
4
4
5
4
4
4
2
1
1
4
2
3
4
 
2
4
2
3
5
2
4
5
5
5
5
5
5
1
2
 
2
5
4
1
2
5
4
3
5
5
3
5
5
5
2
 
............................................................................................................ 
Father Ratings for Males 
Data adapted from: Vitulli, William F.. and Richardson, Deanna 
K., "College Student's Attitudes toward Relationships with 
Parents: A Five-Year Comparative Analysis," Journal of Genetic 
Psychology, Vol. 159, No. 1, Mar. 1998, pp. 45-52. 
b. Find the p-value of the test you conducted in part a. 
c. What assumptions, if any, about the samples did you 
have to make to ensure the validity of the hypothesis 
test you conducted? 
d. Refer to part c. If you made assumptions, check to 
see if they are reasonably satisfied. If no assumptions 
were necessary, explain why. 
7.11 Ingratiation is defined as a class of strategic behav- 
iors designed to make others believe in the attractive- 
ness of one's personal qualities. In organizational 
settings, individuals use such behaviors to influence 
superiors in order to attain personal goals. An index 
that measures ingratiatory behavior, called the 
Measure of Tnrrratiatorv Behaviors in Organizational 
u 
" 
Settings (MIBOS) Index, was applied independently to 
a sample of managers employed by four manufacturing 
companies in the southeastern United States and to 
clerical personnel from a large university in the north- 
western United States (Journal of Applied Psychology, 
Dec. 1998). Scores are reported on a five-point scale 
with higher scores indicating more extensive ingratiato- 
ry behavior. Summary statistics are show in the table. 
Managers 
Clerical Personnel 
....................................................................................... 
n1 = 288 
- 
n, = 110 
- 
xl = 2.41 
x2 = 1.90 
Sl = .74 
s, = .59 
Source: Harrison, Allison W., Hochwarter, Wayne 
A., Perrewe, Pamela L, and Ralston, David A., "The 
Ingratiation Construct: An Assessment of the 
Validity of the Measure of Ingratiatory Behaviors in 
Organization Settings (MIBOS).".lournal ofApplied 
Psychology, Vol. 86, No. 6, Dec. 1998, pp. 932-943. 
a. Specify the null and alternative hypotheses you 
would use to test for a difference in ingratiatory be- 
havior between managers and clerical personnel. 
b. Conduct the test of part a using a = .05. Interpret 
the results of the test in the context of the problem. 
c. Construct a 95% confidence interval for ( p ,  - p'J 
and interpret the result. Your conclusion should 
agree with your answer in part b. 
7.12 Some college professors make bound lecture notes avail- 
able to their classes in an effort to improve teachinp 
effectiveness. Marketing Educational Review (Fall 1994) 

SECTION 7.1 
C o m p a r i n g  T w o  P o p u l a t i o n  Means: I n d e p e n d e n t  S a m p l i n g  
359 
published a study of business students' opinions of lec- 
ture notes. Two groups of students were surveyed- 
86 students enrolled in a promotional strategy class that 
required the purchase of lecture notes, and 35 students 
enrolled in a saleslretailing elective that did not offer 
lecture notes. At the end of the semester, the students 
were asked to respond to the statement: "Having a 
copy of the lecture notes was [would be] helpful in 
understanding the material." Responses were mea- 
sured on a nine-point semantic difference scale, where 
1 = "strongly disagree" and 9 = "strongly agree." A 
summary of the results are reported in the table. 
................................................................................ 
Classes Buying 
Classes Not Buying 
Lecture Notes 
Lecture Notes 
................................................................................ 
n, = 86 
n, = 35 
- 
- 
x, = 8.48 
x2 = 7.80 
s: = 0.94 
s; = 2.99 
Source: Gray, J. I., and Abernathy, A. M. "Pros 
and cons of lecture notes and handout packages: 
Faculty and student opinions," Murketing 
Erlucution Review, Vol. 4, No. 3, Fall 1984, p. 25 
(Table 4). American Marketing Association. 
a. Describe the two populations involved in the com- 
parison. 
b. Do the samples provide sufficient evidence to con- 
clude that there is a difference in the mean respons- 
es of the two groups of students? Test using a = .01. 
c. Construct a 99% confidence interval for (p, - p2). 
Interpret the result. 
d. Would a 95% confidence interval for (P, - p,) be 
narrower or wider than the one you found in part c? 
Why? 
7.13 Marketing strategists would like to predict consumer 
response to new products and their accompanying pro- 
motional schemes. Consequently, studies that examine 
the differences between buyers and nonbuyers of a 
product are of interest. One classic study conducted by 
Shuchman and Riesz (Journal of Marketing Research, 
Feb. 1975) was aimed at characterizing the purchasers 
SAS Output for Exercise 7.1 3 
and nonpurchasers of Crest toothpaste. The researchers 
demonstrated that both the mean household size 
(number of persons) and mean household income were 
significantly larger for purchasers than for nonpurchasers. 
A similar study utilized independent random samples of 
size 20 and yielded the data shown in the table on the 
age of the householder primarily responsible for buying 
toothpaste. An analysis of the data is provided in the 
SAS printout at the bottom of the page. 
Purchasers 
I 
Nonpurchasers 
a. Do the data present sufficient evidence to conclude 
there is a difference in the mean age of purchasers 
and nonpurchasers? Use a = .lo. 
b. What assumptions are necessary in order to answer 
part a? 
c. Find the observed significance level for the test on 
the printout, and interpret its value. 
d. Calculate and interpret a 90% confidence interval 
for the difference between the mean ages of pur- 
chasers and nonpurchasers. 
7.14 Valparaiso University professors D. L. Schroeder and 
K. E. Reichardt conducted a salary survey of members 
of the Institute of Management Accountants (IMA) 
and reported the results in Management Accounting 
(June 1995). A salary questionnaire was mailed to a 
random sample of 4,800 IMA members; 2,287 were 
returned and form the database for the study. The 
researchers compared average salaries by management 
level, education, and gcnder. Some of the results for 
entry level managers are shown in the table on p. 360. 
a. Suppose you want to make an inference about the 
difference between salaries of male and female 
TTEST PROCEDURE 
Variable : AGE 
BUYER 
N 
Mean 
Std Dev 
Std Error 
....................................................................... 
NONPURCH 
2 0 
47.20000000 
13.62119092 
3.04579088 
PURCHASE 
2 0 
39.80000000 
10.03992032 
2.24499443 
Variances 
T 
DF 
Prob> IT1 
....................................... 
Unequal 
1.9557 
34.9 
0.0585 
Equal 
1.9557 
38.0 
0.0579 
For HO: Variances are equal, F' = 1.84 
DF = 
(l9,lg) Prob>F1 = 0.1927 

CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Baccalaureate Degree 
CPA Degree 
No CPA 
................................................................................ 
Men 
Women 
Men 
Women 
Mean Salary 
$40,084 
$35,377 
$39,268 
$33,159 
Number of Respondents 
48 
39 
205 
177 
Source: Schroeder, D. L., and Reichardt, K. E. "Salaries 1994." Management Accounting, 
Vol. 76, No. 12, June 1995, p. 34 (Table 12). 
entry-level managers who earned a CPA degree, at a 
95% level of confidence. Why is this impossible to do 
using the information in the table? 
Make the inference, part a, assuming the salary stan- 
dard deviation for male and female entry-level man- 
agers with CPAs are $4,000 and $3,000, respectively. 
Repeat part b, but assume the male and female 
salary standard deviations are $16,000 and $12,000, 
respectively. 
Compare the two inferences, parts b and c. 
Suppose you want to compare the mean salaries of 
male entry-level managers with a CPA to the mean 
salary of male entry-level managers w~thout a CPA 
degree. Give sample standard deviatmn values that 
will yield a significant difference between the two 
means, at a = .05. 
In your opinion, are the sample standard deviations, 
part e, reasonable values for the salary data? Explain. 
As a country's standard of living increases, so does its 
production of solid waste. The attendant environmental 
threat makes solid-waste management an important 
national problem in many countries of the world. The 
International Journal of Environmental Health Research 
(Vol. 4, 1994) reported on the solid-waste generation 
rates (in kilograms per capita per day) for samples of 
cities from industrialized and middle-income countries. 
The data are provided in the next table. 
a. Based on only a visual inspection of the data, does it 
appear that the mean waste generation rates of cities 
in industrialized and middle-income countries differ? 
b. Conduct a test of hypothesis (at a = .05) to support 
your observation in part a. Use the EXCEL printout 
below to make your conclusion. 
7.16 A recent rash of retirements from the U.S. Senate 
@ SOLWASTE.DAT 
prompted Middlebury College researchers J. E.Trickett 
and P. M. Sommers to study the ages and lengths of ser- 
vice of members of Congress (Chance, Spring 1996) 
One question of interest to the researchers is: "Did the 
13 senators who decided to retire in 1995-1996 begm 
their careers at a younger average age than did the rest 
of their colleagues in the Senate?" 
a. The average age at which the 13 retiring senators 
began their service is 45.783 years; the correspondins 
................................................................................................................. 
Industrialized Countries 
................................................................................................................. 
New York (USA) 
2.27 
Phoenix (USA) 
2.31 
London (UK) 
2.24 
Hamburg (Germany) 
2.18 
Rome (Italy) 
2.15 
EXCEL Output for Exercise 7.1 5 
I 
I 
Middle-Income Countries 
Singapore 
0.87 
Hong Kong 
0.85 
Medellin (Colombia) 
0.54 
Kano (Nigeria) 
0.46 
Manila (Philippines) 
0.50 
Cairo (Egypt) 
0.50 
Tunis (Tunisia) 
0.56 
I 
t-Test: Two-Sample Assuming Equal Variances 
1 
I 

SECTION 7.1 
C o m p a r i n g  T w o  P o p u l a t i o n  Means: I n d e p e n d e n t  S a m p l i n g  
361 
average for all other senators is 47.201 years. Is this 
sufficient information to answer the researchers' 
question? Explain. 
b. The researchers conducted a two-sample t-test on 
the difference between the two means. Specify the 
null and alternative hypotheses for this tcst. Clearly 
define the parameter of interest. 
c. The observed significance level for the test, part b, 
was reported as p = .55. Interpret this result. 
7.17 Many American industries have adopted a participative 
management style utilizing self-managed work teams 
(SMWTs). SMWTs require that employees be trained in 
interpersonal skills such as listening, decision-making, and 
conflict resolution (Quulity Munagement Journul, Summer 
1995). Survey data were collected from 114 AT&T 
employees who work in one of fifteen SMWTs at an 
AT&T technical division. Thc workers wcre divided into 
two groups: (1) those who reported positive spillover of 
work skills to family life and (2) those who did not report 
positive work spillover.The two groups were compared on 
a variety of job and demographic characteristics, several of 
which are shown in the table below. (All but the demo- 
graphic characteristics were measured on a 7-point scale, 
ranging from 1 = "strongly disagrce" to 7 = "strongly 
agree"; thus, the larger the number, the more of the job 
characteristic indicated.) Fully interpret the result for each 
characteristic. Which job-related characteristics are most 
highly associated with positive work spillover? 
7.18 In the United States, high job turnover rates are 
common in many industries and are associated with high 
Results for Exercise 7.1 7 
product defect rates. High turnover rates mean more 
inexperienced workers who are unfamiliar with the com- 
pany's product lines (Stevenson, Prodi~ction/Operutions 
Management, 1996). In a recent study, five Japanese and 
five U.S. plants that manufacture air conditioners were 
randomly sampled; their turnover rates are listed in the 
accompanying table; a MINITAB descriptive statistics 
printout is provided at the bottom of the page. 
U.S. Plants 
Japanese Plants 
.......................................................... 
7.11% 
3.52% 
6.06 
2.02 
8.00 
4.91 
6.87 
3.22 
4.77 
1.92 
a. Do the data provide sufficient evidence to indicate that 
the mean annual percentage turnover for US. plants 
exceeds the corresponding mean percentage for Japan- 
ese plants'? Test using a = .05. 
b. Report and interpret the observed significance level 
of the test you conducted in part a. 
c. List any assumptions you made in conducting the 
hypothesis test of part a. Comment on their validity 
for this application. 
7.19 Helping smokers kick the habit is a big business in 
today's no-smoking environment. One of the more 
commonly used treatments according to an article in 
Characteristic 
................................................................................... 
Use of creative ideas (7-pt. scale) 
Communication (7-pt. scale) 
Utilization of information (7-pt. scale) 
Participation in decisions (7-pt. scale) 
Good use of skills (7-pt. scale) 
Age (years) 
Education (years) 
Means 
................................................................................. 
(1) No Positive Work 
(2) Positive Work 
Spillover (n = 67) 
Spillover (n = 47) 
Source: Stanley-Stevens, L.,Yeatts, D. E., and Seward, R. R. "Positive effects of work on family-life: A case for self-managed 
work teams." Quulity Munagement Journal, Summer 1995, p. 38 (Table 1). 
dlNITAB Output for Exercise 7.1 8 
TWOSAMPLE T FOR US VS JAPAN 
N 
MEAN 
STDEV 
SE MEAN 
US 
5 
6.56 
1.22 
0.54 
JAPAN 5 
3.12 
1.23 
0.55 
95 PCT CI FOR MU US - MU JAPAN: (1.62, 5 
TTEST MU US = MU JAPAN (VS NE): T= 4.46 

362 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
the Journal of Imagination, Cognition and Personality 
(Vol. 12,1992193) is Spiegel's three-point message: 
1. For your body, smoking is a poison. 
2. You need your body to live. 
3. You owe your body this respect and protection. 
To determine the effectiveness of this treatment, the au- 
thors conducted a study consisting of a sample of 52 
smokers placed in two groups, a Spiegel treatment 
group or a control group (no treatment). Each partici- 
pant was asked to record the number of cigarettes he or 
she smoked each week. The results for the study are 
shown here for the beginning period and four follow-up 
time periods. 
Number of Cigarettes 
Smoked In Week 
Beginning 
Treatment 
Control 
First follow-up (2 wks) 
Treatment 
Control 
Second follow-up (4 wks) 
Treatment 
Control 
Third follow-up (8 wks) 
Treatment 
Control 
Fourth lollow-up (12 wks) 
Treatment 
Control 
SPSS Output for Exercise 7.20 
a. Create 95% confidence intervals for the difference in 
the average number of cigarettes smoked per week 
for the two groups for the beginning and each fol- 
low-up period. Interpret the results. 
b. What assumptions are necessary for the validity of 
these confidence intervals? 
7.20 Suppose you manage a plant that purifies its liquid 
waste and discharges the water into a local river. An 
EPA inspector has collected water specimens of the dis- 
charge of your plant and also water specimens in the 
river upstream from your plant. Each water specimen is 
divided into five parts, the bacteria count is read on 
each, and the median count for each specimen is report- 
ed. The bacteria counts for each of six specimens are 
reported in the following table for the two locations. 
a. Why might the bacteria counts shown here tend to 
be approximately normally distributed? 
b. What are the appropriate null and alternative hy- 
potheses to test whether the mean bacteria count for 
the plant discharge exceeds that for the upstream lo- 
cation? Be sure to define any symbols you use. 
c. The data are submitted to SPSS, and part of the out- 
put is shown below. Carefully interpret this output. 
d. What assumptions are necessary to ensure the valid- 
Plant Discharge 
............................................................................................ 
30.1 
36.2 
33.4 
28.2 
29.8 
34.9 
ity of this test? 
Upstream 
29.7 
30.3 
26.4 
27.3 
31.7 
32.3 
Independent samples of LOCATION 
Group 1: LOCATION EQ 
1.00 
Group 2: 
LOCATION EQ 
2.00 
t-test for: BACOUNT 
Number 
Standard 
Standard 
of Cases 
Mean 
Deviation 
Error 
Group 1 
6 
32.1000 
3.189 
1.302 
Group 2 
6 
29.6167 
2.355 
.961 
COMPARING TWO POPULATION MEANS: 
PAIRED DIFFERENCE EXPERIMENTS 
F 
2-Tail 
Value Prob. 
1.83 
.522 
Suppose you want to compare the mean daily sales of two restaurants located in 
the same city. If you were to record the restaurants' total sales for each of 12 ran- 
domly selected days during a six-month period, the results might appear as shown 
Pooled Variance Estimate 
t 
Degrees of 2-Tail 
Value 
Freedom 
Prob. 
1.53 
10 
.I56 
Separate Variance Estimate 
t 
Degreesof 2-Tail 
Value 
Freedom 
Prob. 
1.53 
9.20 
.I59 

SECTION 7.2 
C o m p a r i n g  T w o  P o p u l a t i o n  M e a n s :  P a i r e d  D i f f e r e n c e  E x p e r i m e n t s  
363 
in Table 7.3. An SPSS printout of descriptive statistics for the data is displayed in 
Figure 7.9. Do these data provide evidence of a difference between the mean 
daily sales of the two restaurants? 
TABLE 
7.3 
Daily Sales for Two Restaurants 
Day 
Restaurant 1 
Restaurant 2 
1 (Wednesday) 
$1,005 
$ 918 
2 (Saturday) 
2,073 
1,971 
3 (Tuesday) 
873 
825 
4 (Wednesday) 
1,074 
999 
5 (Friday) 
1,932 
1,827 
6 (Thursday) 
1,338 
1,281 
7 (Thursday) 
1,444 
1,302 
8 (Monday) 
759 
678 
9 (Friday) 
1,905 
1,782 
10 (Monday) 
693 
639 
11 (Saturday) 
2,106 
2,049 
12 (Tuesday) 
981 
933 
We want to test the null hypothesis that the mean daily sales, pl and p2, for 
the two restaurants are equal against the alternative hypothesis that they differ, i.e., 
FIGURE 7.9 
SPSS descriptive statistics for 
daily restaurant sales 
If we employ the t statistic for independent samples (Section 7.1) we first calculate 
s: using the values of sl and s2 highlighted on the SPSS printout: 
Number of Valid Observations (Listwise) = 
12.00 
Variable 
Mean 
Std Dev 
Minimum 
Maximum 
N Label 
REST1 
1349.00 
530.07 
693.00 
2106.00 
12 
REST2 
1267.00 
516.04 
639.00 
2049.00 
12 
Then we substitute the values of X1 and K, 
also highlighted on the printout, to 
form the test statistic: 
This small t value will not lead to rejection of H, when compared to the t-distribution 
with nl + n2 - 2 = 22 df, even if a were chosen as large as .20 (t,,, = t,,,, = 1.321). 
Thus, from this analysis we might conclude that insufficient evidence exists to infer 
that there is a difference in mean daily sales for the two restaurants. 
However, if you examine the data in Table 7.3 more closely, you will find this 
conclusion difficult to accept.The sales of restaurant 1 exceed those of restaurant 
2 for every one of the randomly selected 12 days. This, in itself, is strong evidence to 

364 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
i 
indicate that pl differs from pz, and we will subsequently confirm this fact. Why, 
then, was the t-test unable to detect this difference? The answer is: The indepen- 
dent samples t-test is not a valid procedure to use with this set of data. 
The t-test is inappropriate because the assumption of independent samples 
, 
is invalid. We have randomly chosen days, and thus, once we have chosen the 
sample of days for restaurant 1, we have not independently chosen the sample of 
days for restaurant 2. The dependence between observations within days can be 
seen by examining the pairs of daily sales, which tend to rise and fall together as 
we go from day to day. This pattern provides strong visual evidence of a violation 
of the assumption of independence required for the two-sample t-test of Section 7.1. 
In this situation, you will note the large variation within s~lmples (reflected by the 
large value of s:) in comparison to the relatively small difference between the 
sample means. Because s; is so large, the t-test of Section 7.1 is unable to detect a 
possible difference between p, and p,. 
We now consider a valid method of analyzing the data of Table 7.3. In Table 7.4 
we add the column of differences between the daily sales of the two restaurants. 
We can regard these daily differences in sales as a random sample of all daily d~f- 
ferences, past and present. Then we can use this sample to make inferences about 
the mean of the population of differences, p,, which is equal to the difference 
(p, - p2). That is, the mean of the population (and sample) of differences equals 
the difference between the population (and sample) means. Thus, our test becomes 
H,,: pD = 0 [i.e., (pl-p2) = 0] 
H,: PO f 0 [i.e., (p,-pz) f 01 
I 
The test statistic is a one-sample t (Section 6.4), since we are now analyzing a sin- 1 
gle sample of differences for small n: 
- 
x, - 0 
Test statistic: t = 
sD/ 6 
where ED = Sample mean difference 
s,, 
= Sample standard deviation of differences 
n, = Number of differences = Number of pairs 
Assumptions: The population of differences in daily sales is approximately 
normally distributed. The sample differences are randomly selected from the 
TABLE 
7.4 
Daily Sales and Differences for Two Restaurants 
Difference 
Day 
Restaurant 1 
Restaurant 2 
(Restaurant 1 - Restaurant 2) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . , , , , . . . . . . . . . . . . . . . 
1 (Wednesday) 
$1,005 
$ 918 
$ 87 
2 (Saturday) 
2,073 
1,971 
102 
3 (Tuesday) 
873 
825 
48 
4 (Wednesday) 
1,074 
999 
75 
5 (Friday) 
1,932 
1,827 
105 
6 (Thursday) 
1,338 
1,281 
57 
7 (Thursday) 
1,449 
1,302 
147 
8 (Monday) 
759 
678 
81 
4 (Friday) 
1,905 
1,782 
123 
10 (Monday) 
693 
639 
54 
I 
11 (Saturday) 
2,106 
2,049 
57 
12 (Tuesday) 
98 1 
933 
48 

SECTION 7.2 
C o m p a r i n g  Two P o p u l a t i o n  Means: Paired D i f f e r e n c e  Experiments 
365 
population differences. [Note: We do not need to make the assumption that 
a: = c;.] 
Rejection region: At significance level a = .05, we will reject Ho if It1 > t,os, 
where t.05 is based on (n, - 1) degrees of freedom. 
Referring to Table IV in Appendix B, we find the t value corresponding to 
a = .025 and n~ - 1 = 12 - 1 = 11 df to be t,ozs = 2.201. Then we will reject the 
null hypothesis if ltl > 2.201 (see Figure 7.10). Note that the number of degrees 
of freedom has decreased from n, + n2 - 2 = 22 to 11 when we use the paired 
difference experiment rather than the two independent random samples design. 
F I G U R E  7.10 
t-distribution with 11 df 
Rejection region for restaurant sales 
example 
a - .025 
z 
Summary statistics for the n = 12 differences are shown on the MINITAB 
printout, Figure 7.11. Note that iD 
= 82.0 and s, 
= 32.0 (rounded). Substituting 
these values into the formula for the test statistic, we have 
FIGURE 7.1 1 
MINITAB analysis of 
TEST OF MU = 
0.000 VS MU N.E. 
0.000 
Because this value oft falls in the rejection region, we conclude (at a = .05) that 
the difference in population mean daily sales for the two restaurants differs from 0. 
We can reach the same conclusion by noting that the p-value of the test, high- 
- 
lighted in Figure 7.11, is approximately 0. The fact that (2, - x,) = iD 
= $82.00 
strongly suggests that the mean daily sales for restaurant 1 exceeds the mean 
daily sales for restaurant 2. 
This kind of experiment, in which observations are paired and the differ- 
ences are analyzed, is called a paired difference experiment. In many cases, a 
paired difference experiment can provide more information about the difference 
between population means than an independent samples experiment. The idea is 
to compare population means by comparing the differences between pairs of ex- 
perimental units (objects, people, etc.) that were very similar prior to the experi- 
ment. The differencing removes sources of variation that tend to inflate a'. For 
instance, in the restaurant example, the day-to-day variability in daily sales is re- 
moved by analyzing the differences between the restaurants' daily sales. Making 
comparisons within groups of similar experimental units is called blocking, and 
the paired difference experiment is an example of a randomized block experi- 
ment. In our example, the days represent the blocks. 
differences in  able 7.4 
N 
MEAN 
STDEV 
SE MEAN 
T 
P VALUE 
DIFF 
12 
82.000 
31.989 
9.234 
8.88 
0.0000 

366 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Some other examples for which the paired difference experiment might be 
i 
appropriate are the following: 
1 
1. Suppose you want to estimate the difference (pl - p2) in mean price per 
I 
gallon between two major brands of premium gasoline. If you choose two 
' 
independent random samples of stations for each brand, the variability in 
price due to geographic location may be large. To eliminate this source of 
I 
I 
variability you could choose pairs of stations of similar size, one station for 
I 
each brand, in close geographic proximity and use the sample of differences 
between the prices of the brands to make an inference about (p, - p2). 
2. A college placement center wants to estimate the difference (p, - p,) in 
mean starting salaries for men and women graduates who seek jobs through 
the center. If it independently samples men and women, the starting salaries 
may vary because of their different college majors and differences in grade 
point averages. To eliminate these sources of variability, the placement cen- 
ter could match male and female job seekers according to their majors and 
grade point averages. Then the differences between the starting salaries of 
each pair in the sample could be used to make an inference about (p, - k). 
3. To compare the performance of two automobile salespeople, we might test a 
hypothesis about the difference (P, - p2) in their respective mean monthly 
sales. If we randomly choose n, months of salesperson 1's sales and indepen- 
dently choose n2 months of salesperson 2's sales, the month-to-month vari- 
ability caused by the seasonal nature of new car sales might inflate s i  and 
prevent the two-sample t statistic from detecting a difference between p, and 
p2, if such a difference actually exists. However, by taking the difference in 
monthly sales for the two salespeople for each of n months, we eliminate the 
month-to-month variability (seasonal variation) in sales, and the probabd~ty 
of detecting a difference between p1 and p,, if a difference exists, is increased. 
The hypothesis-testing procedures and the method of forming confidence 
intervals for the difference between two means using a paired difference experi- 
ment are summarized in the boxes for both large and small n. 
e popula- 
i 
sed on (n, - 1) degrees of free 
1 
of the population of 
i 
mly selected from the 
I 

SECTION 7.2 
C o m p a r i n g  T w o  P o p u l a t i o n  M e a n s :  Paired D i f f e r e n c e  E x p e r i m e n t i  
367 
Large Sample 
Test statistic: z 
Small Sample - 
tistic: t = x~ - 
ection region: t < -t 
Rejection region: It 1 > t4 
r t  > t,wh 
ere t,, and telz are based on (nD - 1) degrees of freedom 
mptions: 1. The relative frequency distribution of the population of 
differences is normal. 
2. The differences are randomly selected from the popula- 
tion of differences. 
ting salaries of male and female 
by choosing a male and a female 
with the same major and similar grade point averages (GPAs). Suppose a random 
sample of 10 pairs is formed in this manner and the starting annual salary of each 
person is recorded. The results are shown in Table 7.5. Compare the mean starting 
salary, PI, for males to the mean starting salary, p,, for females using a 95% 
confidence interval. Interpret the results 
TABLE 
7.5 
Data on Annual Salaries for Matched Pairs of College Graduates 
Difference 
Pair 
Male 
Female 
(Male - Female) 
. . . . . . , , . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1 
$29,300 
$28,800 
$ 500 
2 
31,500 
3 1,600 
- 100 
3 
30,400 
29,800 
600 
4 
28,500 
28,500 
0 
5 
33,500 
32,600 
900 
Difference 
Pair 
Male 
Female 
(Male - Female) 
5 o I u t i o n 
Since the data on annual salary are collected in pairs of males and females 
matched on GPA and major, a paired difference experiment is performed. To 

368 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
conduct the analysis, we first compute the differences between the salaries, as 
shown in Table 7.5. Summary statistics for these n = 10 differences are displayed 
in the MINITAB printout, Figure 7.12. 
The 95% confidence interval for p, = (pl - p2) for this small sample is 
FIGURE 7.12 
MINITAB analysis of 
differences in Table 7.5 
where ta,2 = t,025 = 2.262 (obtained from Table VI, Appendix B) is based on 
n - 2 = 8 degrees of freedom. Substituting the values of x, and sD shown on the 
printout, we obtain 
N 
MEAN 
STDEV 
SE MEAN 
95.0 PERCENT C.I. 
DIFF 
10 
400.000 
434.613 
137.437 
( 
89.013, 710.987) 
[Note: This interval is also shown on the MINITAB printout, Figure 7.12.1 Our in- 
terpretation is that the true mean difference between the starting salaries of males 
and females falls between $89 and $71 1, with 95% confidence. Since the interval 
falls above 0, we infer that p1 - p2 > 0, that is, that the mean salary for males ex- 
ceeds the mean salary for females. 
* 
To measure the amount of information about (pl - p2) gained by using a 
paired difference experiment in Example 7.5 rather than an independent sam- 
ples experiment, we can compare the relative widths of the confidence intervals 
obtained by the two methods. A 95% confidence interval for (p, - p,) using the 
paired difference experiment is, from Example 7.5, ($89, $711). If we analyzed 
the same data as though this were an independent samples experiment,* we 
would first obtain the descriptive statistics shown in the MINITAB printout, 
Figure 7.13. 
Then we substitute the sample means and standard deviations shown on 
the printout into the formula for a 95% confidence interval for (pl - p2) using in- 
dependent samples: 
*This is done only to provide a measure of the increase in the amount of information obtained by 
a paired deslgn In comparlson to an unpa~red des~gn. Actually, ~f an experiment is des~gned uwg 
paning, an unpalred analysis would be invalid because the assumption of mdependent samples 
would not be satlafled. 

SECTION 7.2 
C o m p a r i n g  T w o  P o p u l a t i o n  M e a n s :  P a i r e d  D i f f e r e n c e  E x p e r i m e n t s  
369 
FIGURE 7.1 3 
MINITAB analysis of data in 
Table 7.5, assuming 
independent samples 
TWOSAMPLE T FOR C 1  VS C2 
N 
MEAN 
STDEV 
SE MEAN 
C 1  1 0  
29930 
1735 
549 
C2 
1 0  
29530 
1527 
483 
95 PCT C I  FOR MU C 1  - MU C 2 :  (-1136, 1936) 
TTEST MU C 1  = MU C 2 ( V S  N E ) :  T= 0.55 
P ~ 0 . 5 9  DF= 
18 
POOLED STDEV = 
1634 
where 
MINITAB performed these calculations and obtained the interval (-$1,136, 
$1,936). This interval is highlighted on Figure 7.13. 
Notice that the independent samples interval includes 0. Consequently, if we 
were to use this interval to make an inference about (pl - p,), we would incor- 
rectly conclude that the mean starting salaries of males and females do not differ! 
You can see that the confidence interval for the independent sampling experiment 
is about five times wider than for the corresponding paired difference confidence 
interval. Blocking out the variability due to differences in majors and grade point 
averages significantly increases the information about the difference in male and 
female mean starting salaries by providing a much more accurate (smaller confi- 
dence interval for the same confidence coefficient) estimate of (p, - pZ). 
You may wonder whether conducting a paired difference experiment is al- 
ways superior to an independent samples experiment. The answer is: Most of the 
time, but not always. We sacrifice half the degrees of freedom in the t statistic 
when a paired difference design is used instead of an independent samples design. 
This is a loss of information, and unless this loss is more than compensated for by 
the reduction in variability obtained by blocking (pairing), the paired difference 
experiment will result in a net loss of information about 
- p 2 )  Thus, we 
should be convinced that the pairing will significantly reduce variability before 
performing the paired difference experiment. Most of the time this will happen. 
One final note: Thc pairing of the observations is determined before the ex- 
periment is performed (that is, by the design of the experiment). A paired differ- 
ence experiment is never obtained by pairing the sample observations after the 
measurements have been acquired. 
Learning the Mechanics 
7.21 A pared difference experiment yielded n~ pairs of 
7.22 The data for a random sample of six paired obsewa- 
observations. In each case, what is the rejection region 
tions are shown in the table on page 370. 
for testing H,,: p,, > 2? 
a. Calculate the difference between each pair of obser- 
a.n,= 
12,a = .05 
b. n~ = 24,a = .I0 
vations by subtracting observation 2 from observa- 
c. n, = 4, a = .025 
d. n~ = 8, a = .O1 
tion 1. Use the differences to calculate i, and sh. 

370 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  Means 
Sample from Population 1 
Sample from Population 2 
Pair 
(Observation 1) 
(Observation 2) 
b. If pI and p, are the means of populations 1 and 2, re- 
spectively, express p, in terms of p, and p> 
c. Form a 95% confidence interval for pD. 
d. Test the null hypothesis H,,: p, = 0 against the al- 
ternative hypothesis Ha: p, # 0. Use a = .05. 
7.23 The data for a random sample of 10 paired observa- 
tions are shown in the accompanying table. 
Pair 
Sample from Population 1 
Sample from Population 2 
a. If you wish to test whether these data are sufficient 
to indicate that the mean for population 2 is larger 
than that for population 1, what are the appropriate 
null and alternative hypotheses? Define any symbols 
you use. 
b. The data are analyzed using MINITAB, with the re- 
sults shown below. Interprct these results. 
c. The output of MINITAB also included a confidence 
interval. Interpret this output. 
d. What assumptions are necessary to ensure the valid- 
ity of this analysis? 
MINITAB Output for Exercise 7.23 
7.24 A paired difference experiment produced the follow- 
ing data: 
n, = 18 il = 92 x2 = 95.5 i, = -3.5 
sk = 21 
a. Determine the values oft for which the null hypoth- 
esis, pl - p2 = 0, would be rejected in favor of the 
alternative hypothesis, pl - p2 < 0. Use cu = .lo. 
b. Conduct the paired difference test described in part a. 
Draw the appropriate conclusions. 
c. What assumptions are necessary so that the paired 
difference test will be valid? 
d. Find a 90% confidence interval for the mean differ- 
ence pD. 
e. Which of the two inferential procedures, the confi- 
dence interval of part d or the test of hypothesis of 
part b, provides more information about the differ- 
ences between the population means? 
7.25 A paired difference experiment yielded the data shown 
in the next table. 
a. Test H,,: p~ = 10 against Ha: p, # 10, where 
,uD = (pI - pZ). Use a = .05. 
b. Report the p-value for the test you conducted in part 
a. Interpret the p-value. 
LM7-25.DAT 
Applying the Concepts 
...................................................................................................... 
Pair 
Obs.1 
Obs. 2 
...................................................................................................... 
1 
55 
44 
2 
68 
55 
3 
40 
25 
4 
55 
56 
7.26 When searching for an item (e.g., a roadside traffic sign. 
a misplaced file, or a tumor in a mammogram), common 
sense dictates that you will not re-examine items previ- 
ously rejected. However, researchers at Harvard 
Medical School found that a visual search has no 
memory (Nature, Aug. 6, 1998). In their experiment. 
nine subjects searched for the letter "T" mixed among 
several letters "L." Each subject conducted the search 
under two conditions: random and static. In the random 
condition, the location of the letters were changed every 
111 milliseconds; in the static condition, the location of 
Pair 
0bs.l 
Obs. 2 
5 
75 
62 
6 
52 
38 
7 
49 
31 
TEST OF MU = 0.000 VS MU L.T. 0.000 
N 
MEAN 
STDEV SE MEAN 
T 
P VALUE I 
N 
MEAN 
STDEV SE MEAN 
95.0 PERCENT C.I. 
DIFF 
10 
-3.700 
2.214 
0.700 
( 
-5.284, 
-2.116) 

the letters remained unchanged. In each trial, the reac- 
tion time (i.e., the amount of time it took the subject to 
locate the target letter) was recorded in milliseconds. 
a. One goal of the research is to compare the mean re- 
action times of subjects in the two experimental con- 
ditions. Explain why the data should be analyzed as a 
paired-difference experiment. 
b. If a visual search had no memory, then the main reac- 
tion times in the two conditions will not differ. Speci- 
fy H,, and Ha for testing the "no memory" theory. 
c. The test statistic was calculated as t = 1.52 with 
p-value = .15. Make the appropriate conclusion. 
7.27 Lack of sleep costs companies about $1 8 billion a year 
in lost productivity, according to the National Sleep 
Foundation. Companies are waking up to the problem, 
however. Some even have quiet rooms available for 
study or sleep. "Power naps" are in vogue (Athens 
Daily News, Jan. 9, 2000). A major airline recently 
began encouraging reservation agents to nap during 
their breaks. The table lists the number of complaints 
received about each of a sample of 10 reservation 
agents during the six months before naps were encour- 
aged and during the six months after the policy change. 
0 POWERNAP.DAT 
..................................................................................................................... 
Agent 
1999 No. of Complaints 
2000 No. of Complaints 
a. Do the data present sufficient evidence to conclude 
that the new napping policy reduced the mean num- 
ber of customer complaints about reservation 
agents? Test using a = .05. 
b. What assumptions must hold to ensure the validity 
of the test? 
7.28 Refer to the Journal of Genetic Psychology (Mar. 1998) 
comparison of male and female college students' atti- 
tudes toward their fathers, Exercise 7.10 (p. 357). In this 
exercise, data adapted from the same study are used to 
compare male students' attitudes toward their fathers 
with their attitudes toward their mothers. Each of a 
sample of 13 males from the original sample of 44 males 
was asked to complete the following statement about 
each of his parents: My relationship with my father 
(mother) can best be described as (1) Awful! (2) Poor, 
(3) Average, (4) Good, or (5) Great! The data obtained 
are shown in the table: 
Student 
Attitude toward Father 
Attitude toward Mother 
..................................................................................................................... 
1 
2 
3 
2 
5 
5 
3 
4 
3 
4 
4 
5 
5 
3 
4 
6 
5 
4 
7 
4 
5 
8 
2 
4 
9 
4 
5 
10 
5 
4 
11 
4 
5 
12 
5 
4 
13 
3 
3 
Source: Adapted from Vitulli, William F., and Richardson, Deanna K., 
"College Student's Attitudes toward Relationships with ParentsA 
Five-Year Comparative Analysis," Journal of Genetic Psychology, Vol. 
159, No. 1, Mar. 1998, pp. 45-52. 
STATISTIX Output for Exercise 7.28 
I PAIRED T TEST FOR FATHERATT - MOTHERATT I 
NULL HYPOTHESIS: DIFFERENCE = 
0 
ALTERNATIVE HYP: DIFFERENCE <> 0 
SECTION 7.2 
C o m p a r i n g  T w o  P o p u l a t i o n  M e a n s :  P a i r e d  D i f f e r e n c e  E x p e r i m e n t s  
371 
&- 
MEAN 
-0.3077 
STDERROR 
0.2861 
LO 95% CI 
-0.9311 
UP 95% CI 
0.3157 
T 
-1.08 
DF 
12 
P 
0.3033 
a. Specify the appropriate hypotheses for testing 
whether male students' attitudes toward their fathers 
differ from their attitudes toward their mothers, on 
average. 
b. Use the accompanying STATISTIX printout to con- 
duct the test of part a (at a = .05). Interpret the re- 
sults in the context of the problem. 
c. What assumptions about the sample and its popula- 
tion did you have to make in order to ensure the va- 
lidity of the hypothesis test? 
d. Are you satisfied that your assumption about the 
population is correct? Justify your answer. 
7.29 Twice a year The Wall Street Journal asks a panel of 
economists to forecast interest rates, inflation rates, 
growth in Gross Domestic Product, and other econom- 
ic variables. The table (p. 372) reports the inflation fore- 
casts (in percent) made in June 1999 and in January 
2000 by nine randomly selected members of the panel. 
a. On average, were the economists more optimistic 
about the prospects for low inflation in late 1999 

372 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
INFLATE.DAT 
.............................................................................................................................. 
" 
June 1999 Forecast 
January 2000 Forecast 
for 11/99 
for 5/00 
.................................................................................................................................. 
Bruce Steinberg 
1.8 
2.2 
Wayne Angel1 
2.3 
2.3 
David Blitzer 
2.3 
2.3 
M~chael Cosgrove 
2.5 
3.0 
Gad Fosler 
2.3 
2.4 
John Lonski 
2.5 
3.0 
Donald Ratajczak 
2.5 
2.5 
Thomas Synott 
2.3 
2.6 
Sund Won Sohn 
2.5 
2.6 
Source Wall Street Journal, January 3,2000. 
than they were for Spring 2000? Specify the hy- 
potheses to bc tested. 
b. Conduct the hypothesis test using a = .05 and an- 
swer the question posed in part a. 
7.30 Facility layout and material flowpath design are major 
factors in the productivity analysis of automated manu- 
facturing systems. Facility layout is concerned with the 
location arrangement of machines and buffers for work- 
in-process. Flowpath design is concerned with the direc- 
tion of manufacturing material flows (e.g., unidirectional 
or bidirectional) (Lee, Lei, and Pinedo, Annals of 
Operations Research, 1997). A manufacturer of printed 
circuit boards (PCBs) is interested in evaluating two 
alternative existing layout and flowpath designs. The 
output of each design was monitored for eight consecu- 
tive working days. 
Working Days 
Design 1 
.............................. 
1,220 units 
1,092 units 
1,136 units 
1,205 units 
1,086 units 
1,274 units 
1,145 units 
1,281 units 
Design 2 
1,273 units 
1,363 units 
1,342 units 
1,471 units 
1,299 units 
1,457 units 
1,263 units 
1,368 units 
a. Construct a 95% confidence interval for the differ- 
ence in mean daily output of the two designs. 
b. What assumptions must hold to ensure the validity 
of the confidence interval? 
c. Design 2 appears to be superior to Design 1. Is this 
confirmed by the confidence interval? Explain. 
7.31 A pupillometer is a device used to observe changes in 
pupil dilations as the eye is exposed to different visual 
stimuli. Since there is a direct correlation between the 
amount an individual's pupil dilates and his or her inter- 
est in the stimuli, marketing organizations sometimes 
use pupillometers to help them evaluate potential con- 
sumer interest in new products, alternative package 
designs, and other factors (Optical Engineering, Mar. 
1995). The Design and Market Research Laboratories 
of the Container Corporation of America used a pupil- 
lometer to evaluate consumer reaction to different sil- 
vcrware patterns for a client. Suppose 15 consumers 
were chosen at random, and each was shown two silver- 
ware patterns. Their pupillometer readings (in millime- 
ters) are shown in the table on page 373. 
a. What are the appropriate null and alternative hy- 
potheses to test whether the mean amount of pupil 
dilation differs for the two patterns? Define any 
symbols you use. 
b. The data were analyzed using MINITAB, with the 
results shown in the printout (p. 373). Interpret 
these results. 
c. Is the paired difference design used for this study 
preferable to an independent samples design? For in- 
dependent samples we could select 30 consumers, di- 
vide them into two groups of 15, and show each group 
a differcnt pattern. Explain your preference. 
7.32 A study reported in the Journal o,f Psychology (Mar. 
1991) measures the change in female students' self- 
concepts as they move from high school to co1lege.A 
sample of 133 Boston College first-year female students 
wasselected for the study. Each was asked to evaluate 
several aspects of her life at two points in time: at the 
end of her senior year of high school, and during her 
sophomore year of college. Each student was asked to 
ev&uate where she believed she stood on a scale that 
ranged from top 10% of class (1) to lowest 10% of class 
(5). The results for three of the traits evaluated are 
reported in the second table on p. 373. 
a. What null and alternative hypotheses would you test 
to determine whether the mean self-concept of fe- 
males decreases between the senior year of high school 
and the sophomore year of college as measured by 
each o f  these thrce traits? 
b. Are these traits more appropriately analyzed using 
an independent samples test or a paired difference 
test? Explain. 

SECTION 7.2 
C o m p a r i n g  T w o  P o p u l a t i o n  M e a n s :  P a i r e d  D i f f e r e n c e  E x p e r i m e n t s  
373 
Consumer 
Pattern 1 
Pattern 2 
MlNlTAB Output for Exercise 7.31 
Consumer 
Pattern 1 
Pattern 2 
- - 
TEST OF MU = 0.000 VS MU N.E. 
0.000 
,:, 
STDEV 
S E  MEAN 
T 
P VALUE 
.I61 
.0415 
5.76 
0.0000 
N 
MEAN 
STDEV 
S E  MEAN 
95.0 PERCENT C I  
I DTFF 
15 
.239 
.I61 
.0415 
(.150, .328) 
Results for Exercise 7.31 
Trait 
Senior Year of 
Sophomore Year of 
. . . . . . . . . . . . . . . . . . 
. . . . . . . . .iS" . . . . . . . . . . . . . . . . . . . . 
~ g h  
School 
ollege 
Leadership 
133 
2.09 
2.33 
Popularity 
133 
2.48 
2.69 
Intellectual self-confidence 
133 
2.29 
2.55 
c. Noting the size of the sample, what assumptions are 
between the mean number of swims required by male 
necessary to ensure the validity of the tests? 
and female pups? Use the MINITAB printout below to 
d. The article reports that the leadership test results in 
conduct the test (at a = .lo). Comment on the assump- 
ap-value greater than .05, while the tests for popu- 
tions required for the test to be valid. 
larity and intellectual self-confidence result in 
p-values less than .05. Interpret these results. 
7.33 Merck Research Labs conducted an experiment to evalu- 
ate the effect of a new drug using the single-T swim maze. 
Nineteen impregnated dam rats were allocated a dosage 
of 12.5 milligrams of the drug. One male and one female 
rat pup were randomly selected from each resulting litter 
to perform in the swim maze. Each pup was placed in the 
water at one end of the maze and allowed to swim until it 
escaped at the opposite end. If the pup failed to escape 
after a certain period of time, it was placed at the begin- 
ning of the maze and given another chance. The experi- 
ment was repeated until each pup accomplished three 
successful escapes. The next table reports the number of 
Litter 
Male 
Female 
Litter 
Male 
Female 
swims required by each pup to perform three successful 
I 
Source: Thomas E. Bradstreet, Merck Research Labs, BL 3-2, West 
escapes. Is there sufficient evidence of a difference 
Point, PA 19486. 
MlNlTAB Output for Exercise 7.33 
TEST OF MU = 0.000 VS MU N.E. 
0.000 
N 
MEAN 
STDEV 
S E  MEAN 
T 
P VALUE 
SwimDiff 
19 
r 
0.368 
3.515 
0.806 
0.46 
0.65 

374 
CHAPTER 7 
C o m p a r i n g  Population Means 
DETERMINING THE SAMPLE SIZE 
You can find the appropriate sample size to estimate the difference between a 
pair of population means with a specified degree of reliability by using the method 
described in Section 5.4. That is, to estimate the difference between a pair of 
means correct to within B units with probability (1 - a), let z,,, standard devia- 
tions of the sampling distribution of the estimator equal B. Then solve for the sarn- 
ple size. To do this, you have to solve the problem for a specific ratio between n, 
and n,. Most often, you will want to have equal sample sizes, that is, n, = n, = n. 
We will illustrate the procedure with two examples. 
"d->-m m>-- 
,. 
crop yields. Suppose we want to compare the mean yield pl of wheat when a new 
fertilizer is used to the mean yield p2 with a fertilizer in common use. The estimate 
of the difference in mean yield per acre is to be correct to within .25 bushel with a 
confidence coefficient of .95. If the sample sizes are to be equal, find n, = n, = 11. 
the number of one-acre plots of wheat assigned to each fertilizer. 
S o I U t i 0 n To solve the problem, you need to know something about the variation in the 
bushels of yield per acre. Suppose from past records you know the yields of wheat 
possess a range of approximately 10 bushels per acre. You could then approximate 
o, 
= a2 = a by letting the range equal 4a. Thus, 
4a = 10 bushels 
a = 2.5 bushels 
The next step is to solve the equation 
for n, where n = n, = n,. Since we want the estimate to lie within B = .25 of 
- ,a,) with confidence coefficient equal to .95, we have za12 = zozs = 1.96. 
Then, letting a, = u2 = 2.5 and solving for n, we have 
i 
n = 768.32 = 769 (rounding up) 
Consequently, you will have to sample 769 acres of wheat for each fertilizer 
to estimate the difference in mean yield per acre to within .25 bushel. Since this 
i 
would necessitate extensive and costly experimentation, you might decide to allow 
a larger bound (say, B = S O  or B = 1) in order to reduce the sample size, or you 
might decrease the confidence coefficient. The point is that we can obtain an idea 
of the experimental effort necessary to achieve a specified precision in our final 

SECTION 
7.3 
D e t e r m i n i n g  t h e  Sample Size 
375 
estimate by determining the approximate sample size before the experiment is 
begun. 
I 
two instruments,A and B, designed to measure the potency (in parts per million) 
of an antibiotic. To conduct the experiment, the manager plans to select n, 
specimens of the antibiotic from a vat and to measure each specimen with both 
instruments. The difference (pA - pB) will be estimated based on the n, paired 
differences (x, - x,) obtained in the experiment. If preliminary measurements 
suggest that the differences will range between plus or minus 10 parts per million, 
how many differences will be needed to estimate (p, - pB) correct to within 1 part 
per million with confidence equal to .99? 
S o I u t i o n The estimator for (p, - pB), based on a paired difference experiment, is 
- 
x, = (XA - is) 
and 
Thus, the number n, of pairs of measurements needed to estimate 
- pB) to 
within 1 part per million can be obtained by solving for nD in the equation 
where zO05 = 2.58 and B = 1. To solve this equation for n,, we need to have an 
approximate value for a,. 
We are given the information that the differences are expected to range 
from -10 to 10 parts per million. Letting the range equal 4aD, we find 
Range = 20 = 4aD 
Substituting a, = 5, B = 1, and z 
005 = 2.58 into the equation and solving for n,, 
we obtain 
Therefore, it will require n~ = 167 pairs of measurements to estimate (p, - 
correct to within 1 part per million using the paired difference experiment. 
The box summarizes the procedures for determining the sample sizes nec- 
essary for estimating (p, - p2) for the case n, = n, = 2 and for estimating p,. 

376 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
u will need to substitute estimates for the values of a? and a; before solv- 
for the sample size. These estimates might be sample variances sf and$ 
prior sampling (e.g., a pilot sample), or from an educated (and conserv- 
ly large) guess based on the range-that 
is, 
ired Difference Experiment 
estimate p, to within a given bound B wit 
bility (1 - a), use the 
owing formula to solv 
ore solving for the sample 
.This estimate 
from prior sampling (e.g., 
(and conservatively large) guess based on 
Learning the Mechanics 
7.34 Find the appropriate values of n, and n2 (assume 
n, = n2) needed to estimate (p, - p,) with: 
a. A bound on the error of estimation equal to 3.2 with 
95% confidence. From prior experience it is known 
that a ,  = 15 and a, = 17. 
b. A bound on the error of estimation equal to 8 with 
99% confidence. The range of each population is 60. 
c. A 90% confidence interval of width 1.0. Assume that 
a: = 5.8 and a; = 7.5. 
7.35 Suppose you want to use a paired difference experi- 
ment to estimate the difference between two popula- 
tion means correct to within 1.8 with a 95% 
confidence interval. If prior information suggests that 
the population variances of the diffcrcnces is approx- 
imately equal to a; = 28. how many pairs should be 
selected? 
7.36 Enough money has been budgeted to collect indepen- 
dent random samples of size n, = n, = 100 from popu- 
lations 1 and 2 in ordcr to estimate (pl - p2). Prior 
information indicates that a, = a, = 10. Have suffi- 
cient funds been allocated to construct a 90% confi- 
dence interval for (pl - p2) of width 5 or less? Justify 
your answer. 
Applying the Concepts 
7.37 Refer to the EPA study of average bacteria counts in 
water specimens at two river locations, Exercise 7.20 
(p. 362). How many water specimens need to be sam- 
pled at each location in order for a 95% confidence 
interval for the true mean difference in bacteria counts 
to yield an estimate that lies within 1.5 bacteria of the 
true difference? Assume equal sample sizes will be col- 
lected at each location. 
7.38 Is housework hazardous to your health? A study in the 
Public Health Reports (July-Aug. 1992) compares the life 
expectancies of 25-year-old white women in the labor 
force to those who are housewives. How large a sample 
would have to be taken from each group in order to be 
95% confident that the estimate of difference in aver- 
age life expectancies for the two groups is within one 
year of the true difference in average life expectancies? 

SECTION 7.4 
Testing t h e  Assumption of Equal Population Variances ( O p t i o n a l )  
377 
Assume that equal sample sizes will be selected from 
ference to within 1 mile with 99% confidence. Assume an 
thc two groups, and that the standard deviation for both 
equal number of men and women will be sampled and 
groups is approximately 15 years. 
7.39 Rcfer to the Merck Research Labs experiment 
designed to evaluate the effect of a new drug using rats 
in a single-T swim maze, Exercise 7.33 (p. 373). How 
many matched pairs of male and female rat pups need 
to be included in the experiment in order to estimate 
the difference between the mean number of swim 
attempts required to escape to within 1.5 attempts with 
95% confidence? Use the value of s, found in Exercise 
7.33 in your calculations. 
7.40 The Professional Geographei. (May 1992) published a 
u, = a, = 6 miles. 
7.41 Even though Japan is an economic superpower, 
Japanese workers are in many ways worse off than their 
U.S. and European counterparts. For example, a few 
years ago the estimated average housing space per 
person (in square feet) was 665.2 in the United States, 
and only 269 in Japan (Minneapolis Star-Tribune, Jan. 31, 
1993). Suppose a team of economists and sociologists 
from the United Nations plans to reestimate the differ- 
ence in the mean housing space per person for U.S. and 
Japanese workers. Assume that equal sample sizes will 
study of the proximity of a woman's place of employment 
be used for each country and that the standard devia- 
in two-income households. One inference involved esti- 
tion is 35 square feet for Japan and 80 for the United 
mating the difference between the average distances to 
States. How many people should be sampled in each 
work for men and women living in suburban residences. 
country to estimate the difference to within 10 square 
Determine the sample sizes required to estimate this dif- 
feet with 95% confidence? 
TESTING THE ASSUMPTION OF EQUAL 
POPULATION VARIANCES (OPTIONAL) 
Consider the problem of comparing two population means with small (independent) 
samples. Recall, from Section 7.1, that the statistical method employed requires 
that the variances of the two populations be equal. Before we compare the means 
we should check to be sure that this assumption is reasonably satisfied. Otherwise, 
any inferences derived from the t-test for comparing means may be invalid. 
To solve problems like these we need to develop a statistical procedure to 
compare population variances. The common statistical procedure for comparing 
population variances, a: and a:, makes an inference about the ratio a:/af. In this 
section, we will show how to test the null hypothesis that the ratio cr:/ai equals 1 (the 
variances are equal) against the alternative hypothesis that the ratio differs from 1 
(the variances differ): 
To make an inference about the ratio a:/a:, 
it seems reasonable to collect 
., 
- 
sample data and use the ratio of the sample variances, s:/si. We will use the test 
statistic 
To establish a rejection region for the test statistic, we need to know the 
sampling distribution of $1~;. As you will subsequently see, the sampling distri- 
bution of s:/sz is based on two of the assumptions already required for the t-test: 
"I: 
1. The two sampled populations are normally distributed. 
2. The samples are randomly and independently selected from their respective 
populations. 
When these assumptions are satisfied and when the null hypothesis is true (that is, 
a: = a:), the sampling distribution of F = s:/s$ is the F-distribution with (n, - 1) 

378 
CHAPTER 
7 
C o m p a r i n g  Population Means 
numerator degrees of freedom and (n, - 1) denominator degrees of freedom, 
respectively. The shape of the F-distribution depends on the degrees of freedom 
associated with s: and & - t h a t  is, on (n, - 1) and (n, - 1). An F-distribution 
with 7 and 9 df is shown in Figure 7.14. As you can see, the distribution is skewed 
to the right, since s:/s; cannot be less than 0 but can increase without bound. 
We need to be able to find F values corresponding to the tail areas of this 
distribution in order to establish the rejection region for our test of hypothesis be- 
cause we expect the ratio F of the sample variances to be eithcr very large or very 
small when the population variances are unequal. The upper-tail F values for 
a = .10, .05, .025, and .O1 can be found in Tables VIII, IX, X, and XI of Appendix B. 
Table IX is partially reproduced in Table 7.6. It gives F values that correspond to 
a = .05 upper-tail areas for different degrees of freedom v, for the numerator 
sample variance, s:, whereas the rows correspond to the degrees of freedom v, for 
TABLE 
7.6 
Reproduction of Part of Table IX in Appendix B: Percentage Points of 
the F-Distribution, cu = .05 
f(F) 
A 
............................................................................................................................................................................................... 
Numerator Degrees of Freedom 

SECTION 7.4 
Testing t h e  Assumption of Equal Population Variances ( O p t i o n a l )  
379 
the denominator sample variance, s;. Thus, if the numerator degrees of freedom is 
I 
v l  = 7 and the denominator degrees of freedom is v, = 9, we look in the seventh 
I 
column and ninth row to find F,,, = 3.29. As shown in Figure 7.14, a = .05 is the 
, 
tail area to the right of 3.29 in the F-distribution with 7 and 9 df. That is, if a: = a;, 
then the probability that the F statistic will exceed 3.29 is a = .05. 
! 
convenience followed by a SAS printout of the analysis in Figure 7.15.The use of 
the t statistic was based on the assumption that the populat& variances of the 
managerial success indexes were equal for the two groups. Check this assumption 
at a = .lo. 
TABLE 
7.7 
Managerial Success Indexes for T w o  C r o u p s  o f  Managers 
Croup 1 
Croup 2 
...................................... ... ................................... .............................. ... ... . . . ... . . . .... ............................ " 
Interaction with Outsiders 
I 
Few Interactions 
TTEST PROCEDURE 
Variable: SUCCESS 
GROUP 
N 
Mean 
Std D e v  
Std Error 
Minimum 
Maximum 
.............................................................................. 
1 
12 65.33333333 
6.61036835 
1.90824897 
53.00000000 
78.00000000 
2 
15 49.46666667 
9.33401358 
2.41003194 
34.00000000 
68.00000000 
Variances 
T 
DF 
Prob> IT1 
....................................... 
Unequal 
5.1615 
24.7 
0.0001 
Equal 
4.9675 
25.0 
0.0000 
For HO: Variances are equal, F' = 1.99 
DF = (14,ll) 
FIGURE 7.15 
SAS F-test for the data in Table 7.7 
S o l u t i o n  Let 
a: = Population variance of success indexes for Group 1 managers 
crz = Population variance of success indexes for Group 2 managers 
The hypotheses of interest then are 
The nature of the F-tables given in Appendix B affects the form of the test statis- 
tic. To form the rejection region for a two-tailed F-test, we want to make certain 

380 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
that the upper tail is used, because only the upper-tail values of Fare shown inTa- 
bles VIII, IX, X, and XI. To accomplish this, we will always place the larger sample 
variance in the numerator of the F-test statistic. This has the effect of doubling the 
tabulated value for a, since we double the probability that the F-ratio will fall in 
the upper tail by always placing the larger sample variance in the numerator. 
That is, we establish a one-tailed rejection region by putting the larger variance in 
the numerator rather than establishing rejection regions in both tails. 
From the SAS printout in Figure 7.15, we find that s, = 6.610 and 
s2 = 9.334. Therefore, the test statistic is: 
I 
I 
Larger sample variance - s; - (9.334)2 
F =  
- -- 
- - 
- 1.99 
Smaller sample variance 
s; 
(6.61 0)' 
For numerator df v, = n2 - 1 = 14 and denominator df v2 = nl - 1 = 11, we 
i 
will reject H,: a; = a; at a = .10 when the calculated value of F exceeds the tab- 
ulated value: 
Fd2 = Fo, = 2.74 
(see Figure 7.16) 
Note that F = 1.99 does not fall into the rejection region shown in Figure 7.16. 
Therefore, the data provide insufficient evidence to reject the null hypothesis 
of equal population variances. 
This F-test is also shown on the SAS printout, Figure 7.15. Both the test sta- 
tistic, F = 1.99, and two-tailedp-value, .2554, are highlighted on the printout. Since 
a = .10 is less than the p-value, our conclusion is confirmed: we do not reject the 
null hypothesis that the population variances of the success indexes are equal. 
Although we must be careful not to accept H,, (since the probability of a 
Type 11 error, P, is unknown), this result leads us to behave as if the assumption of 
equal population variances is reasonably satisfied. Consequently, the inference 
drawn from the t-test in Example 7.4 appears to be valid. 
We conclude this section with a summary of the F-test for equal population 
variances." 
*Although a test of a hypothesis of equality of variances is the most common application of the 
F-test, it can also be used to test a hypothesis that the ratio between the population variances is 
equal to some specified value, H,,: a:/"; = k. The test is conducted in exactly the same way as 
specified in the box, except that we use the test statistic 

SECTION 7.4 
Testing t h e  Assumption of E q u a l  Population Variances ( O p t i o n a l )  
381 
Smaller sample variance 
2 
S1 
= - when st > st 
(or $ when s; > s: 
Rejection region: 
F > F42 
e Fa and FaI2 are based on vl = numerator degrees of freedom and v2 = 
minator degrees of freedom; vl and v2 are the degrees of freedom for the 
erator and denominator sample variances, respectively. 
Assumptions: 1. Both sampled populations are normally distributed." 
2. The samples are random and independent. 
Note: Rejecting the null hypothesis Hi,: u: = u; implies that the assumption 
of equal population variances is violated. Consequently, the small-sample proce- 
dure for comparing population means in Section 7.1 may lead to invalid infer- 
ences. In this situation, apply the nonparametric procedure for comparing two 
populations discussed in optional Section 7.5, or consult the chapter references for 
methods that utilize an adjusted t-statistic. 
Learning the Mechanics 
7.42 Use Tables VIII, IX, X, and XI of Appendix B to find 
each of the following F values: 
a. F,, where vl = 9 and v2 = 6 
b. Fnl where v, = 18 and v2 = 14 
c. F,,,, where v, = 11 and v2 = 4 
d. Fln where v, = 20 and v2 = 5 
7.43 For each of the following cases, identify the rejection 
region that should be used to test H,,: a: = ui against 
Ha: a: f u:. Assume v, = 10 and v2 = 12. 
a . a =  .20 b. a =  .lo c. a = .05 
d. a = .02 
7.44 Specify the appropriate rejection region for testing 
H . u 2 -  
2. 
,. , - a2 in each of the following situations: 
.~k a. H;a: > u$;a = .05,nl = 25,n2 = 20 
d l -  
7.45 Independent random samples were selected from each 
of two normally distributed populations, n1 = 12 from 
population 1 and n, = 27 from population 2.The means 
and variances for the two samples are shown in the table. 
Sample 1 
Sample 2 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
nl = 12 
- 
n2 = 27 
- 
x, = 31.7 
x2 = 37.4 
s: = 3.87 
s; = 8.75 
*The F-test is much less robust (i.e., much more sensitive) to departures from normality than the 
t-test for comparing the population means. If you have doubts about the normality of the 
population frequency distributions, use a nonparametric method for comparing the two variances. 
A method can be found in the nonparamctric statistics texts listed in the chapter references. 

382 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  Means 
jPSS Output for Exercise 7.46 
Summaries of 
X 
By levels of 
SAMPLE 
Variable 
Value Label 
Mean 
Std Dev 
Cases 
For Entire Population 
3.3000 
2.3656 
11 
SAMPLE 
1.00 
2.4167 
1.4359 
6 
SAMPLE 
2.00 
4.3600 
2.9729 
5 
Total Cases = 
11 
a. Test the null hypothesis H,,: u: = a; against the al- 
ternative hypothesis Ha: u: f a;. Use a = .lo. 
b. Find the approximate p-value of the test. 
7.46 Independent random samples were selected from each 
of two normally distributed populations, n, = 6 from 
population 1 and n, = 5 from population 2. The data 
are shown in the table below, and an SPSS descriptive 
statistics printout is provided abovc. 
a. Test H,: a: = 
against Ha: a: < u:. Use a = .01. 
b. Find the approximate p-value of the test. 
Sample 1 
Sample 2 
Applying the Concepts 
7.47 In addition to evaluating the performance of individ- 
ual companies, securities analysts also evaluate and 
compare industry sectors. One of the variables used in 
this analysis is the percentage growth in net incomes 
for the previous year. The table, extracted from Forbes 
(Jan. 10, 2000), lists the percentage growth in net 
income for samples of firms from the banking and 
energy sectors of the U.S. economy. 
a. Suppose you want to compare the mean growth in 
net incomes for the banking and energy sectors. What 
assumption about the variability in growth rates must 
be true for the inference about the means to be valid? 
b. What are the appropriate null and alternative hy- 
potheses to use in comparing the variability of net in- 
come growth rates of the banking and energy sectors? 
c. Conduct the test of part b using a = .05. Interpret 
your results in the context of the problem. 
d. What assumptions must hold to ensure the validity 
of the test? 
7.48 A study in the Journal of Occupational and 
Organizational Psychology (Dec. 1992) investigated the 
relationship of employment status and mental health. A 
sample of working and unemployed people was selected, 
and each person was given a mental hcalth examination 
using the General Health Questionnaire (GHQ), a widely 
recognized measure of mental health. Although the article 
focused on comparing the mean GHQ levels, a compari- 
son of the variability of GHQ scores for employed and 
unemployed men and women is of interest as well. 
a. In general terms, what does the amount of variability 
in GHQ scores tell us about the group? 
b. What are the appropriate null and alternative hy- 
potheses to compare the variability of the mental 
health scores of the employed and unemployed 
groups'? Define any symbols you use. 
c. The standard deviation for a sample of 142 employed 
men was 3.26, while the standard deviation for 49 
unemployed men was 5.10. Conduct the test you set 
up in part b using a = .05. Interpret the results. 
d. What assumptions are necessary to ensure the valid- 
ity of the test? 
7.49 Tests of product quality using human inspectors can lead 
to serious inspection error problems (Journal of Quality 
Technology, Apr. 1986). To evaluate the performance of 
inspectors in a new company, a quality manager had a 
sample of 12 novice inspectors evaluate 200 finished prod- 
ucts.The same 200 items were evaluated by 12 experienced 
inspectors. The quality of each item-whether 
defective 
or nondefective-was 
known to the manager. The table 
(p. 383) lists the number of inspection errors (classifying a 
defective item as nondefective or vice versa) made by each 
inspector. A SAS printout with descriptive statistics for 
the two types of inspectors is provided on the next pa8e. 
Banking 
Bank of NY 
46.5% 
Compass 
9.7 
First Union 
35.1 
PNCBank 
13.6 
Regions 
30.2 
State Street 
13.2 
Summit 
-2.4 
Synovus 
20.3 
Energy 
.......................................................................................................... 
Ashland 
42.9% 
Coastal 
22.8 
Duke 
3.2 
Exxon Mobil 
-29.7 
MidAmerican 
231.7 
Nicor 
-6.5 
OGE 
-11.0 
Royal Dutch 
-56.6 
UGE 
38.2 
Source: Forbes, Jan. 10,2000, pp. 84-167. 

SECTION 7.4 
Testing t h e  A s s u m p t i o n  of E q u a l  P o p u l a t i o n  V a r i a n c e s  ( O p t i o n a l )  
SAS Output for Exercise 7.49 
Analysis Variable : ERRORS 
.......................... 
INSPECT=EXPER-------------------------- 
N Obs 
N 
Minimum 
Maximum 
Mean 
Std Dev 
................................................................. 
12 12 
10.0000000 
31.0000000 
20.5833333 
5.7439032 
................................................................. 
......................... 
INSPECT=NOVICE-------------------------- 
N Obs 
N 
Minimum 
Maximum 
Mean 
Std Dev 
................................................................. 
12 12 
20.0000000 
48.0000000 
32.8333333 
8.6427409 
................................................................. 
1NSPECT.DAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Novice Inspectors 
] "' Experienced Inspectors 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Industrialized Countries 1"'~iddle-Income Countries 
a. Prior to conducting this experiment, the manager be- 
lieved the variance in inspection errors was lower for 
experienced inspectors than for novice inspectors. Do 
the sample data support her belief? Test using a = .05. 
b. What is the appropriate p-value of the test you con- 
ducted in part a? 
7.50 Refer to the International Journal of Environmental 
Health Research (Vol. 4, 1994) study, Exercise 7.15 
(p. 360) in which the mean solid-waste generation rates 
for middle-income and industrialized countries were 
compared. The data are reproduced in the table at right. 
a. In order to conduct the two-sample t-test in Exercise 
7.15,it was necessary to assume that the two population 
variances were equal.Test this assumption at a = .05. 
Use the SAS printout below to conduct the test. 
b. What does your test indicate about the appropriate- 
ness of applying a two-sample f-test? 
7.51 Following the Persian Gulf War, the Pentagon changed 
its logistics processes to be more corporate-like. The 
extravagant "just-in-case" mentality was replaced with 
SAS Output for Exercise 7.50 
New York (USA) 
2.27 
Singapore 
Phoenix (USA) 
2.31 
Hong Kong 
London (UK) 
2.24 
Medellin (Colombia) 
Hamburg (Germany) 
2.18 
Kano (Nigeria) 
Rome (Italy) 
2.15 
Manila (Philippines) 
Cairo (Egypt) 
Tunis (Tbnisia) 
"just-in-time7' systems. Emulating Federal Express and 
United Parcel Service, deliveries from factories to fox- 
holes are now expedited using bar codes, laser cards, 
radio tags, and databases to track supplies. The table 
on the next page contains order-to-delivery times (in 
days) for a sample of shipments from the United States 
to the Persian Gulf in 1991 and a sample of shipments 
to Bosnia in 1995. 
a. Use the SPSS printout on p. 384 to test whether the 
variances in order-to-delivery times for Persian Gulf 
and Bosnia shipments are equal. Use a = .05. 
b. Given your answer to part a, is it appropriate to con- 
struct a confidence interval for the difference be- 
tween the mean order-to-delivery times? Explain. 
7.52 The American Educational Research Journal (Fall, 1998) 
published a study to compare the mathematics achieve- 
ment test scores of male and female students. 
TTEST PROCEDURE 
Variable: WASTE 
COUNTRY 
N 
Mean 
Std Dev 
Std Error 
......................................................................... 
INDUS 
5 
2.23000000 
0.06519202 
0.02915476 
MIDDLE 
7 
0.61142857 
0.17286108 
0.06533535 
Variances 
T 
DF 
Prob> IT1 
..................................... 
Unequal 
22.6231 
8.1 
0.0001 
Equal 
19.7302 
10.0 
0.0000 
For HO: Variances are equal, F' = 7.03 
DF = (6,4) 
Prob>F1 = 0.0800 

384 
CHAPTER 
7 C o m p a r i n g  P o p u l a t i o n  M e a n s  
SPSS Output for Exercise 7.51 
Independent samples of 
LOCATION 
Group 1: 
LOCATION 
EQ 
1.00 
Group 2: 
LOCATION 
EQ 
2.00 
t-test for: TIME 
Number 
Standard 
Standard 
of Cases 
Mean 
Deviation 
Error 
Group 1 
9 
25.2444 
10.520 
3.507 
Group 2 
9 
7.3778 
3.654 
1.218 
Persian Gulf 
Bosnia 
F 
2-Tail 
Value Prob. 
8.29 
.007 
Source: Adapted from Crock, S. 
"The Pentagon goes to B- 
school." Business Week, 
December 11,1995, p. 98. 
a. The researchers hypothesized that the distribution 
of test scores for males is more variable than the 
corresponding distribution for females. Use the 
summary information in the table below to test this 
claim at a = .01. 
b. Does the result, part a, prevent you from conducting 
a test to compare the mean scores of males and fe- 
males? Explain. 
Pooled Variance Estimate 
t 
Degrees of 2-Tail 
Value 
Freedom 
Prob. 
4.81 
16 
.OOO 
Males 
Females 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Sample size 
1,764 
1,739 
Mean 
48.9 
48.4 
Standard deviation 
12.96 
11.85 
Separate Variance Estimate 
t 
Degrees of 2-Tail 
Value 
Freedom 
Prob. 
4.81 
9.90 
.001 
Source: Bielinski, J., and Davison, M. L. "Gender 
differences by item difficulty interactions in multiple- 
choice mathematics items." Americun Educutionul 
Research Journul, Vol. 35, No. 3, Fall 1998, p. 464 (Table 1). 
A NONPARAMETRIC TEST FOR COMPARING TWO 
POPULATIONS: INDEPENDENT SAMPLING (OPTIONAL) 
Suppose two independent random samples are to be used to compare the popu- 
lations and the t-test of Section 7.1 is inappropriate for making the comparison. 
We may be unwilling to make assumptions about the form of the underlying pop- 
ulation probability distributions or we may be unable to obtain exact values of the 
sample measurements. If the data can be ranked in order of magnitude for either 
of these situations, the Wilcoxon rank sum test (developed by Frank Wilcoxon) 
can be used to test the hypothesis that the probability distributions associated with 
the two populations are equivalent. 
For example, suppose six economists who work for the federal government 
and seven university economists are randomly selected, and each is asked to pre- 
dict next year's percentage change in cost of living as compared with this y&+ 
figure. The objective of the study is to compare the government economists' pre- 
dictions to those of the university economists. The data are shown in Table 7.8. 
Experience has shown that the populations of predicted percentage changes 
often possess probability distributions that are skewed, as shown in Figure 7.17. 
Consequently, a t-test should not be used to compare the mean predictions of the 
two groups of economists because the normality assumption that is required for 
the t-test may not be valid. 

s ~ c ~ l 0 ~ 7 . 5  
A Nonparametric Test for Comparing T w o  Populations (Optional) 
385 
TABLE 
7.8 
Percentage Cost of Living Change, as Predicted 
by Covernment and University Economists 
Covernment Economist (1) 
University Economist (2) 
.......................................................................................................................... 
Prediction 
Rank 
Prediction 
Rank 
.......................................................................................................................... 
3.1 
4 
4.4 
6 
4.8 
7 
5.8 
9 
2.3 
2 
3.9 
5 
5.6 
8 
8.7 
11 
0.0 
1 
6.3 
10 
2.9 
3 
10.5 
12 
10.8 
13 
Tv~ical ~robabilitv distribution of ~redicted 
I 
Percentage Change 
The two populations of predictions are those that would be obtained from 
all government and all university economists if they could all be questioned. To 
compare their probability distributions using a nonparametric test, we first rank 
the sample observations as though they were all drawn from the same population. 
That is, we pool the measurements from both samples and then rank the mea- 
surements from the smallest (a rank of l) to the largest (a rank of 13). The ranks 
of the 13 economists' predictions are indicated in Table 7.8. 
The test statistic for the Wilcoxon test is based on the totals of the ranks for 
each of the two samples-that 
is, on the rank sums. If the two rank sums are 
nearly equal, the implication is that there is no evidence that the probability dis- 
tributions from which the samples were drawn are different. On the other hand, if 
the two rank sums are very different, the implication is that the two samples may 
, 
have come from different populations. 
For the economists' predictions, we arbitrarily denote the rank sum for gov- 
ernment economists by TI and that for university economists by T,. Then 
The sum of T, and T, will always equal n(n + 1)/2, where n = nl + n,. So, for this 
example, nl = 6, n2 = 7, and 

386 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Since TI + T2 is fixed, a small value for T, implies a large value for T2 (and vice 
versa) and a large difference between TI and T2. Therefore, the smaller the value 
of one of the rank sums, the greater the evidence to indicate that the samples were 
selected from different populations. 
The test statistic for this test is the rank sum for the smaller sample; or, in the 
case where n, = n,, either rank sum can be used. Values that locate the rejection 
region for this rank sum are given in Table XI1 of Appendix B. A partial repro- 
duction of this table is shown in Table 7.9. The columns of the table represent n,, 
the first sample size, and the rows represent n2, the second sample size. The TL and 
Tu entries in the table are the boundaries of the lower and upper regions, r~spective- 
ly, for the rank sum associated with the sample that has fewer measurements. If the 
sample sizes nl and n, are the same, either rank sum may be used as the test sta- 
tistic.To illustrate, suppose n, = 8 and n2 = 10. For a two-tailed test with a = .05, 
we consult part a of the table and find that the null hypothesis will be rejected if 
the rank sum of sample 1 (the sample with fewer measurements), 7J is less than or 
equal to TL = 54 or greater than or equal to Tu = 98. (These values are highlight- 
ed in Table 7.9.) The Wilcoxon rank sum test is summarized in the box on p. 387. 
TABLE 
7.9 
Reproduction of Part of Table XI1 in Appendix B: Critical Values for the Wilcoxon Rank Sum Test 
a = .025 one-tailed; a = .05 two-tailed 
Note that the assumptions necessary for the validity of the Wilcoxon rank 
sum test do not specify the shape or type of probability distribution. However, the 
distributions are assumed to be continuous so that the probability of tied mea- 
surements is 0 (see Chapter 4), and each measurement can be assigned a unique 
rank. In practice, however, rounding of continuous measurements will sometimes 
produce ties. As long as the number of ties is small relative to the sample sizes the 
Wilcoxon test procedure will still have an approximate significance level of a. The 
test is not recommended to compare discrete distributions for which many ties are 
expected. 
ar's 
percentage change in cost of living tend to be lower than the university 
economists'. That is, test to determine if the probability distribution of 
government economists' predictions is shifted to the left of the probabilit! 
distribution of university economists' predictions. Conduct the test using the 
data in Table 7.8 and a = .05. 

A Nonparametric Test for Comparing Two Populations (Optional) 
387 
Wilcoxon Rank Sum Test: Independent Samples* 
can be used if n, = 4.) 
his rank sum as 7: 
from which the samples are drawn 
verage of the ranks they would receive if they 
ive order. For example, if the third-ranked and 
S o l u t i o n  
H,,: The probability distributions corresponding to the government and 
university economists' predictions of inflation rate are identical 
Ha: The probability distribution for the government economists' predic- 
tions lies below (to the left of) the probability distribution for the uni- 
versity economists' predictionst 
Test statistic: Since fewer government economists (n, = 6) than university 
economists (n2 = 7) were sampled, the test statistic is T,, the rank sum of 
the government economists' predictions. 
Rejection region: Since the test is one-sided, we consult part b of Table XI1 
for the rejection region corresponding to a = .05. We reject H, only for 
TI 5 TL, the lower value from Table XII, since we are specifically testing 
that the distribution of government economists' predictions lies below the 
distribution of university economists' predictions, as shown in Figure 7.18. 
Thus, we reject H,, if TI 5 30. 
*Another statistic used for comparing two populations based on independent random samples is 
the Mann- Whitney U statistic. The U statistic is a simple function of the rank sums. It can be 
shown that the Wilcoxon rank sum test and the Mann-Whitney U-test are equivalent. 
+The alternative hypotheses in this chapter will be stated in terms of a difference in the location of 
thc distributions. However, since the shapes of the distributions may also differ under Ha, some of 
the figures (e.g., Figure 7.18) depicting the alternative hypothesis will show probability 
distributions with different shapes. 

388 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  Means 
FIGURE 7.18 
Probability distribution for 
Probability distribution for 
Alternative hypothesis and 
government economists' predictions 
university economists' predictions 
rejection region for Example 7.9 
* 
Since T,, the rank sum of the government economists' predictions in 
Table 7.8, is 25, it is in the rejection region (see Figure 7.18). Therefore, we can 
conclude that the university economists' predictions tend, in general, to exceed 
the government economists' predictions. This same conclusion can be reached 
using a statistical software package. The SAS printout of the analysis is shown in 
Figure 7.19. Both the test statistic (T, = 25) and two-tailed p-value ( p  = .0184) 
are highlighted on the printout. The one-tailed p-value, p = .0184/2 = .0092, is 
less than a = .05, leading us to reject H,. 
* 
FIGURE 7.19 
SAS printout for Example 7.9 
N P A R l W A Y  P R O C E D U R E  
Wilcoxon Scores (Rank Sums) for Variable PCTCHNG 
Classified by Variable ECONOMST 
Sum of 
Expected 
Std Dev 
Mean 
ECONOMST 
N 
Scores 
Under HO 
Under HO 
Score 
GOVERN 
6 
25.0 
42.0 
7.0 
4.16666667 
UNIV 
7 
66.0 
49.0 
7.0 
9.42857143 
Wilcoxon 2-Sample Test (Normal Approximation) 
(with Continuity Correction of .5) 
S= 25.0000 
Z= -2.35714 
Prob > IZI = 0.0184 
T-Test approx. Significance = 
0.0362 
Kruskal-Wallis Test (Chi-square Approximation) 
CHISQ= 5.8980 
DF= 1 
Prob > CHISQ= 
0.0152 
Table XI1 in Appendix B gives values of TL and Tu for values of n, and 
less than or equal to 10. When both sample sizes n, and n, are 10 or larger, the 
sampling distribution of T, can be approximated by a normal distribution with 
mean and variance 

S~crlo~7.5 
A N o n p a r a m e t r i c  T e s t  f o r  C o m p a r i n g  T w o  P o p u l a t i o n s  ( O p t i o n a l )  
389 
Therefore, for n, r 10 and n, 2 10 we can conduct the Wilcoxon rank sum test 
using the familiar 2-test of Section 7.1.The test is summarized in the next box. 
e Wilc 
for 
d n, 2 
Let Dl and R, represent the probability distributions for populations 1 and 2, respectively. 
shifted to the right of 
He: Dl is shifted either to the right or to 
Learning the Mechanics 
7.53 Specify the test statistic and the rejection region for 
the Wilcoxon rank sum test for independent samples in 
each of the following situations: 
a. n, = 10, n, = 6, a = .10 
H,: Two probability distributions, 1 and 2, are 
identical 
Ha: Probability distribution for population 1 is shift- 
ed to the right or left of the probability distribution 
, ,  
for population 2 
-t; 
b. n, = 5, n, = 7, a = .05 
H,,: Two probability distributions, 1 and 2, are 
identical 
Ha: Probability distribution for population 1 is shift- 
ed to the right of the probability distribution for 
population 2 
c n, = 9, n, = 8, a = .025 
H,:Two probability distributions, 1 and 2, are identical 
Ha: Probability distribution for population 1 is shift- 
ed to the left of the probability distribution for pop- 
ulation 2 
d. n, = 15, n, = 15, a = .05 
Ho:Two probability distributions, 1 and 2, are identical 
Ha: Probability distribution for population 1 is shift- 
ed to the right or left of the probability distribution 
for population 2 
754 Suppose you want to compare two treatments, A and 
B. In particular, you wish to determine whether the 
distribution for population B is shifted to the right of 
the distribution for population A. You plan to use the 
Wilcoxon rank sum test. 
a. Specify the null and alternative hypotheses you 
would test. 
b. Suppose you obtained the following independent 
random samples of observations on experimental 
units subjected to the two treatments. Conduct a 
test of the hypotheses described in part 
a. Test using a = .05. 
kd 
LM7-54.DAT 
........................................................................................ 
Sample A: 37,40,33,29,42,33, 35, 28, 34 
Sample B: 65,35,47,52 
7.55 Explain the difference between the one-tailed and 
two-tailed versions of the Wilcoxon rank sum test for 
independent random samples. 
7.56 
Independent random samples are selected from two 
populations. The data are shown in the table. 
............................................................... 
Sample 1 
Sample 2 
..................... 
............................... 
15 
16 
5
9
 5 
10 
13 
12 
8 
10 
12 
8 
9 
4 

390 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
a. Use the Wilcoxon rank sum test to determine 
whether the data provide sufficient evidence to indi- 
cate a shift in the locations of the probability distribu- 
tions of the sampled populations.Test using a = .05. 
b. Do the data provide sufficient evidence to indicate 
that the probability distribution for population 1 is 
shifted to the right of the probability distribution 
for population 2? Use the Wilcoxon rank sum test 
with a = .05. 
Applying the Concepts 
7.57 University of Queensland researchers J. Hann and 
R. Weber sampled private sector and public sector orga- 
nizations in Australia to study the planning undertaken 
by their information systems departments (Management 
Science, July 1996). As part of that process they asked 
each sample organization how much it had spent on 
information systems and technology in the previous 
fiscal year as a percentage of the organization's total 
revenues. The results are reported in the table. 
Private Sector 
Public Sector 
............................................................ 
2.58% 
5.40% 
5.05 
2.55 
.05 
9.00 
2.10 
10.55 
4.30 
1.02 
2.25 
5.11 
2.50 
12.42 
1.94 
1.67 
2.33 
3.33 
Source: Adapted from Hann, J., and 
Weber, R. "Information systems 
plannlng A model and empirical 
tests." Murzugement Sctence, Vol 42, 
No. 2, July, 1996, pp. 1043-1064. 
a. Do the two sampled populations have identical prob- 
ability distributions or is the distribution for public 
sector organizations in Australia located to the right 
of Australia's private sector firms? Test using a = .05. 
b. Is the p-value for the test less than or greater than 
.05? Justify your answer. 
c. What assumptions must be met to ensure the valid- 
ity of the test you conducted in part a? 
7.58 In Exercise 7.15 (p. 360) the solid waste generation 
rates for cities in industrialized countries and cities in 
middle-income countries were investigated. In this exer- 
cise, the focus is on middle-income countries versus low- 
income countries. The next table, extracted from the 
International Journal of Environmentul Health 
Research (1994), reports waste generation values (kg per 
capita per day) for two independent samples. Do the 
rates differ for the two categories of countries? 
a. Which nonparametric hypothesis-testing proce- 
dures could bc uscd to answer the question? 
SOLWASTZDAT 
.................................................. 
Cities of 
Low-Income Countries 
.................................................. 
Jakarta 
.60 
Surabaya 
.52 
Bandung 
.55 
Lahore 
.60 
Karachi 
.SO 
Calcutta 
.51 
Kanpur 
.50 
................................................. 
Cities of 
Middle-Income Countries 
................................................. 
Singapore 
37 
Hong Kong 
.85 
Medellin 
.54 
Kano 
.46 
Manila 
SO 
Cairo 
.SO 
Xnis 
.56 
Source: Al-Momani,A. H. "Solid-waste management: 
Sampling, analysis and assessment of household waste in 
the city of Amman." International Journal of' 
Environmental Health Research, Vol. 4.1994, pp. 208-222. 
b. Specify the null and alternative hypotheses of the test. 
c. Conduct the test using a = .01. Interpret the results 
in the context of the problem. 
7.59 
Purchasing organizations such as the National 
Association of Purchasing Management advocate ethi- 
cal purchasing practices for purchasing managers 
including the avoidance of situations that might influ- 
ence or appear to influence purchasing decisions. In 
Mexico, the U.S.'s third largest trading partner, purchas- 
ing has not fully evolved into a profession with its own 
standards of ethical behavior. Researchers at Xavier 
University investigated the question: Do American and 
Mexican purchasing managers perceive ethical situa- 
tions differently (Industrial Marketing Management, 
July 1999)? As part of their study, 15 Mexican purchas- 
ing managers and 15 American purchasing managers 
were asked to consider different ethical situations and 
respond on a 100-point scale with end points "strongly 
disagree" (1) and "strongly agree" (100). For the situa- 
tion "accepting free trips from salespeople is okay." the 
responses shown in the table on p. 391 were obtained. 
a. Consider a Wilcoxon rank sum test to determine 
whether American and Mexican purchasing man- 
agers perceive the given ethical situation differently. 
A STATISTIX printout of the analysis is also 
shown on p. 391.Verify the rank sums shown on the 
printout are accurate. 
b. Conduct the test of a = .05. Use the p-value shown 
on the printout to make your conclusion. (Note: 
STATISTIX cmploys the equivalent Mann-Whitney 
U-test to analyze the data. The p-values of the two 
tests are identical.) 
c. Under what circumstances could the two-sample 
t-test of Section 7.1 be uscd to analyze the data? 
Check to see whether the t-test is appropriate in 
this situation. 
7.60 The data in the second table on p. 391, extracted from 
Technometrics (Feb. 1986), represent daily accumulat- 
ed stream flow and precipitation (in inches) for two 
US. Geological Survey stations in Colorado. Conduct a 
test to determine whether the distributions of daily 

S~cno~7.5 A N o n p a r a m e t r i c  Test f o r  C o m p a r i n g  Two Populations ( O p t i o n a l )  
American Purchasing Managers 
Mexican Purchasing Managers 
...................................................................................................................... 
50 
15 
19 
10 
15 
5 
10 
8 
11 
90 
60 
55 
35 
40 
5 
65 
80 
40 
30 
80 
25 
50 
85 
45 
20 
75 
30 
20 
35 
95 
Source: Adapted from Tadepalli, R., Moreno, A,, and Trevino, S., "Do 
American and Mexican Purchasing Managers Perceive Ethical Situations 
Differently? An Empirical Investigation," Industrial Murketing 
Manrrgement, Vol. 28. No. 4, July 1999, pp. 369-380. 
STATlSTlX Output for Exercise 7.59 
............................................................................................................................... 
Station 1 
Station 2 
RANK SUM TWO-SAMPLE (MANN-WHITNEY) TEST FOR FREETRIP BY COUNTRY 
SAMPLE 
COUNTRY 
RANK SUM 
SIZE 
U STAT 
MEAN RANK 
---------- 
--------- 
------ 
--------- 
- - - - - - - - - 
MEX 
279.00 
15 
159.00 
18.6 
US 
186.00 
15 
66.000 
12.4 
TOTAL 
465.00 
3 0 
NORMAL APPROXIMATION WITH CONTINUITY CORRECTION 
1.908 
TWO-TAILED P-VALUE FOR NORMAL APPROXIMATION 
0.0564 
TOTAL NUMBER OF VALUES THAT WERE TIED 
18 
MAXIMUM DIFFERENCE ALLOWED BETWEEN TIES 0.00001 
CASES INCLUDED 30 
MISSING CASES 0 
Source: Gastwirth, J. L., and Mahmoud, H. "An efficient robust 
nonparametric test for scale change for data from a gamma distribution." 
Technometrics, Vol. 28, No. 1, Feb. 1986, p. 83 (Table 2). 
accumulated stream flow and precipitation for the two 
statlons differ in location. Use a = .lo. Why is a non- 
parametric test appropriate for this data? 
7.61 Recall that the variance of a binomial sample propor- 
tion, F, depends on the value of the population param- 
eter,~. As a consequence, the variance of a sample 
percentage, (loop)%, also depends on p. Thus if you 
conduct an unpaired t-test (Section 7.1) to compare 
the means of two populations of percentages, you may 
be vlolatlng the assumption that a: = a;, upon which 
the t-test IS based. If the disparity in the variances is 
large, you w1l1 obtain more reliable test results u m g  
the Wilcoxon rank sum test for independent samples. 
In Exercise 7.18 (p. 361), we used a Student's t-test to 
compare the mean annual percentages of labor 
turnover between U.S. and Japanese manufacturers of 
air conditioners. The annual percentage turnover rates 
for five U.S. and five Japanese plants are shown in the 
table (p. 392). Do the data provide sufficient evidence 
to indicate that the mean annual percentage turnover 
for American plants exceeds the corresponding mean 
for Japanese plants? Test using the Wilcoxon rank sum 
test with a = .05. Do your test conclusions agree with 
those of the t-test in Exercise 7.182 

392 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  Means 
TURNOVERDAT 
.......................................................... 
U.S. Plants 
Japanese Plants 
.............................................. 
7.11% 
3.52% 
6.06 
2.02 
8.00 
4.91 
6.87 
3.22 
4.77 
1.92 
7.62 A major razor blade manufacturer advertises that its 
twin-blade disposable razor "gets you lots more 
shaves" than any single-blade disposable razor on the 
market. A rival company that has been very successful 
in selling single-blade razors plans to test this claim. 
Independent random samples of eight single-blade 
users and eight twin-blade users are taken, and the 
number of shaves that each gets before indicating a 
preference to change blades is recorded. The results 
are shown in the table. 
RAZOR.DAT 
.................................................... 
Twin Blades 
Single Blades 
.............................................. 
8 
15 
10 
13 
17 
10 
6 
14 
9 
6 
3 
5 
7.63 A management information system (MIS) is a comput- 
er-based information-processing system designed to 
support the operations, management, and decision 
functions of an organization. The development of an 
MIS involves three stages: definition, physical design, 
and implementation of the system (Munuging 
Information, 1993). Thirty firms that recently imple- 
mented an MIS were surveyed: 16 were satisfied with 
the implementation results, 14 were not. Each firm was 
asked to rate the quality of the planning and negotia- 
tion stages of the development process, using a scale of 
0 to 100, with higher numbers indicating better quality. 
(A scorc ol 100 indicates that all the problems that 
occurred in the planning and negotiation stages were 
successfully resolved, while 0 indicates that none were 
resolved.) The results are shown in the table below. 
Firms with a Good MIS 
Firms with a Poor MIS 
11 
12 
7 
7 
a. The Wilcoxon rank sum test was used to compare 
the quality of the development processes of suc- 
a. Do the data support the twin-blade manufacturer's 
cessfully and unsuccessfully implemented MISs.The 
claim? Use a = .05. 
results are shown in the SAS printout provided. De- 
b. Do you think this experiment was designed in the 
termine whether the distribution of quality scores 
best possible way? If not, what design might have 
for successfully implemented systems lies above the 
been better? 
distribution of scores for unsuccessfully implement- 
c. What assumptions are necessary for the validity of 
ed systems.Test using a = .05. 
the test you performed in part a? Do the assump- 
b. Under what circumstances could you use the two- 
tions seem reasonable for this application? 
sample t-test of Section 7.1 to conduct the same test? 
SAS Output for Exercise 7.63 
N P A R l W A Y  P R O C E D U R E  
Wilcoxon Scores (Rank Sums) for Variable QUALITY 
Classified by Variable FIRM 
Sum of 
Expected 
Std Dev 
Mean 
FIRM 
N 
Scores 
Under HO 
Under HO 
Score 
GOOD 
16 
290.500000 
248.0 
23.9858196 
18.1562500 
POOR 
14 
174.500000 
217.0 
23.9858196 
12.4642857 
Average Scores were used for Ties 
Wilcoxon 2-Sample Test (Normal Approximation) 
(with Continuity Correction of .5) 
S= 174.500 
Z= -1.75103 
Prob > I Z I  = 0.0799 
T-Test approx. Significance = 
0.0905 
Kruskal-Wallis Test (Chi-square Approximation) 
CHISQ= 3.1396 
DF= 1 
Prob > CHISQ= 
0.0764 

S ~ c ~ l 0 ~ 7 . 6  
A Nonparametric Test for Comparing Two Populations (Optional) 
393 
A NONPARAMETRIC TEST FOR COMPARING TWO 
POPULATIONS: PAIRED DIFFERENCE 
EXPERIMENTS (OPTIONAL) 
Nonparametric techniques can also be employed to compare two probability dis- 
tributions when a paired difference design is used. For example, consumer pref- 
erences for two competing products are often compared by having each of a 
sample of consumers rate both products. Thus, the ratings have been paired on 
each consumer. Here is an example of this type of experiment. 
For some paper products, softness is an important consideration in deter- 
mining consumer acceptance. One method of determining softness is to have 
judges give a sample of the products a softness rating. Suppose each of 10 judges 
is given a sample of two products that a company wants to compare. Each judge 
rates the softness of each product on a scale from 1 to 10, with higher ratings im- 
plying a softer product. The results of the experiment are shown in Table 7.10. 
TABLE 
7.10 Softness Ratings of Paper 
Product 
Difference 
.......................................................................................................................................................................................................................................... 
Judge 
A 
B 
(A - B) 
Absolute Value of Difference 
Rank of Absolute Value 
.......................................................................................................................................................................................................................................... 
1 
6 
4 
2 
2 
5 
2 
8 
5 
3 
3 
7.5 
3 
4 
5 
- 1 
1 
2 
4 
9 
8 
1 
1 
2 
5 
4 
1 
3 
3 
7.5 
6 
7 
9 
-2 
2 
5 
7 
6 
2 
4 
4 
9 
8 
5 
3 
2 
2 
5 
9 
6 
7 
-1 
1 
2 
10 
8 
2 
6 
6 
10 
T+ = Sum of positive ranks = 46 
T- = Sum of negative ranks = 9 
Since this is a paired difference experiment, we analyze the differences be- 
tween the measurements (see Section 7.2). However, the nonparametric ap- 
proach-called 
the Wilcoxon signed rank test-requires 
that we calculate the 
ranks of the absolute values of the differences between the measurements, that is, 
the ranks of the differences after removing any minus signs. Note that tied absolute 
dijrerences are assigned the average of the ranks they would receive if they were un- 
equal but successive measurements. After the absolute differences are ranked, the 
sum of the ranks of the positive differences of the original measurements, T+, 
and the sum of the ranks of the negative differences of the original measure- 
ments, T_, are computed. 
We are now prepared to test the nonparametric hypotheses: 
H,: The probability distributions of the ratings for products A and B are 
iden tical 
Ha: The probability distributions of the ratings differ (in location) for the 
two products (Note that this is a two-sided alternative and that it im- 
plies a two-tailed test.) 
Test statistic: T = Smaller of the positive and negative rank sums T+ and T- 

394 
CHAPTER 
7 
C o m p a r i n g  Population Means 
The smaller the value of 7: the greater the evidence to indicate that the two 
probability distributions differ in location. The rejection region for T can be de- 
termined by consulting Table XI11 in Appendix B (part of the table is shown in 
Table 7.11). 
This table gives a value To for both one-tailed and two-tailed tests for 
each value of n, the number of matched pairs. For a two-tailed test with 
a = .05, we will reject H, if T 5 To. You can see in Table 7.1 1 that the value of 
To that locates the boundary of the rejection region for the judges' ratings for 
a = .05 and n = 10 pairs of observations is 8. Thus, the rejection region for the 
test (see Figure 7.20) is 
Rejection region: T 5 8 for a = .05 
TABLE 
7.1 1 
Reproduction of Part of Table Xlll of Appendix B: Critical Values for the 
Wilcoxon Paired Difference Signed Rank Test 
One-Tailed 
Two-Tailed I n = 5 
n = 6 
n = 7 
n = 8 
n = 9 
n = 10 
....................................................................................................................................................................... 
FIGURE 7.20 
Rejection region for 
paired difference 
experiment 
Since the smaller rank sum for the paper data, T- = 9, does not fall within the re- 
jection region, the experiment has not provided sufficient evidence to indicate 
that the two paper products differ with respect to their softness ratings at the 
a = .05 level. 
Note that if a significance level of a = .10 had been used, the rejection re- 
gion would have been T 5 11 and we would have rejected H,. In other words, the 
samples do provide evidence that the probability distributions of the softness rat- 
ings differ at the a = .10 significance level. 

 SECTION^.^ 
A Nonpararnetric Test for C o m p a r i n g  Two P o p u l a t i o n s  ( O p t i o n a l )  
395 
The Wilcoxon signed rank test is summarized in the box. Note that the dif- 
ference measurements are assumed to have a continuous probability distribution 
so that the absolute differences will have unique ranks. Although tied (absolute) 
differences can be assigned ranks by averaging, the number of ties should be small 
relative to the number of observations to ensure the validity of the test. 
iasmwwd m, 
Wilcoxon Signed Rank Test for a Paired ~ifference'kx~erirnent 
, and D2 represent the probability distributions for populations 1 and2, respec 
Two-Tailed Test 
............ ' ........... ' .............. * ................................... 
and D2 
are identical 
H": D, and D, are identical 
is shifted to the right of D, 
Ha: D, is shifted either to the 
[or Ha: D, is shifted to the left of D,] 
left or to the right of D, 
Calculate the difference within each of the n matched pairs of observations.Then r 
absolute value of the n d~ftcrences from the smallest (rank 1) to the highest (r 
calculate the rank sum T- of the negative ddferences and the rank sum T+ 
s~tive differences. [Note: Differences equal to 0 are eliminated, and the number 
rences is reduced accordmgly.] 
Test statisttc: 
T, the smaller of r+ or T- 
positive differences] 
Rejection region: 
T 5 T,, 
is given in Table XI11 in Appendix B. 
ns: 
1. The sample of differences 1s randomly selccted from the populati 
of differences. 
2. The probability distribution from which the sample of paired diffe 
ences is drawn is continuous 
"a -- 
m-stmt 
m
s
P
m
"
s
 
l m-m--m"&",s,"" 
m-*x*h%wnb-m-a 
ll " --- 
Suppose the U.S. Consumer Product Safety Commission (CPSC) wants to test the 
hypothesis that New York City electrical contractors are more likely to install 
-
A
 
unsafe electrical outlets in urban homes than in suburban homes. A pair of homes, 
one urban and one suburban and both serviced by the same electrical contractor, 
is chosen for each of ten randomly selected electrical contractors. A CPSC 
inspector assigns each of the 20 homes a safety rating between 1 and 10, with 
higher numbers implying safer electrical conditions. The results are shown in 
Table 7.12. Use the Wilcoxon signed rank test to determine whether the CPSC 
hypothesis is supported at the a = .05 level. 
S o I u t i o n The null and alternative hypotheses are 
H,,: The probability distributions of home electrical ratings are identical for 
urban and suburban homes 

396 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
TABLE 
7.12 
Electrical Safety Ratings for 10 Pairs of New York City Homes 
Location 
Difference 
......................................................................................... 
Contractor 
Urban A 
Suburban B 
(A - B) 
Rank of Absolute Difference 
................................................................................................................................................................................................... 
1 
7 
9 
-2 
4.5 
2 
4 
5 
- 1 
2 
3 
8 
8 
0 
(Eliminated) 
4 
9 
8 
1 
2 
5 
3 
6 
-3 
6 
6 
6 
10 
- 4 
7.5 
7 
8 
9 
- 1 
2 
8 
10 
8 
2 
4.5 
9 
9 
4 
5 
9 
10 
5 
9 
- 4 
7.5 
................................................................................................................................................................................................... 
Positive rank sum = T+ = 15.5 
Ha: The electrical ratings for suburban homes tend to exceed the electrical 
ratings for urban homes 
Since a paired difference design was used (the homes were selected in urban-sub- 
urban pairs so that the electrical contractor was the same for both), we first cal- 
culate the difference between the ratings for each pair of homes, and then rank 
the absolute values of the differences (see Table 7.12). Note that one pair of rat- 
ings was the same (both 8), and the resulting 0 difference contributes to neither 
the positive nor the negative rank sum. Thus, we eliminate this pair from the cal- 
culation of the test statistic. 
Test statistic: T+, the positive rank sum 
In Table 7.12, we compute the urban minus suburban rating differences, and 
if the alternative hypothesis is true, we would expect most of these differences to 
be negative. Or, in other words, we would expect the positive rank sum T+ to be 
small if the alternative hypothesis is true (see Figure 7.21). 
Rejection region: For a = .05, from Table XI11 of Appendix B, we use 
n = 9 (remember, one pair of observations was eliminated) to find the 
rejection region for this one-tailed test: T+ r 8 
FIGURE 7.21 
The alternative hypothesis for 
Example 7.1 0: We expect T, to 
be small 
Probability distribution for 
Probability distribution for 
Electrical rating 
Since the computed value T+ = 15.5 exceeds the critical value of 8, we conclude 
that this sample provides insufficient evidence at a = .05 to support the alterna- 
tive hypothesis. We cannot conclude on the basis of this sample information that 

S ~ ~ r l 0 ~ 7 . 5  
A N o n p a r a m e t r i c  T e s t  f o r  C o m p a r i n g  T w o  P o p u l a t i o n s  ( O p t i o n a l )  
397 
suburban homes have safer electrical outlets than urban homes. A MINTTAB 
printout of the analysis, shown in Figure 7.22, confirms this conclusion. The p-value 
of the test (highlighted) is .221, which exceeds a = .05. 
4 
FIGURE 7.22 
MINITAB printout for 
Example 7.1 0 
TEST OF MEDIAN = 0.000000 VERSUS MEDIAN L.T. 0.000000 
N FOR 
WILCOXON 
ESTIMATED 
N 
TEST STATISTIC P-VALUE 
MEDIAN 
AminusB 
10 
9 
15.5 
0.221 
-1.000 
As is the case for the rank sum test for independent samples, the sampling 
distribution of the signed rank statistic can be approximated by a normal distri- 
bution when the number n of paired observations is large (say, n 2 25). The large- 
sample z-test is summarized in the box below. 
One-Tailed Test 
Two-Tailed Test 
...... * .............,.. . ....... . .... .. .... .... ................................................. . ................... . ................................ . ..... . .......... 
H,: 4 and D2 are identical 
H,,: D, and 
are identical 
H,: Dl is shifted to the right of 4 
Ha: 4 is shifted either to the left 
[or H,: D, is shifted to the left of 41 
or to the right of 
T+ - [n(n + 1)/4] 
Test statistic: z = 
d [ n ( n  + 1)(2n + l ) ] / 2 4  
Rejection region: 
Rejection reglon: 
z > z ,  
[orz< 
Izl > za/2 
ssumpttons: The sample size n is greater than or equal to 25. Differences equal to 0 
Learning the Mechanics 
7.64 Specify the test statistic and the rejection region for 
the Wilcoxon signed rank test for the paired difference 
design in each of the following situations: 
a. n = 30, a = .10 
H,:Two probability distributions, 1 and 2, are 
identical 
Ha: Probability distribution for population 1 is 
shifted to the right or left of probability distrib- 
ution for population 2 
b. n = 20, a = .05 
H,: Two probability distributions, 1 and 2, are 
identical 
Ha: Probability distribution for population 1 is shift- 
ed to the right of the probability distribution for 
population 2 
c. n = 8,a = .005 
H,: Two probability distributions, 1 and 2, are 
identical 
Ha: Probability distribution for population 1 is shift- 
ed to the left of the probability distribution for 
population 2 

398 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  Means 
7.65 Suppose you want to test a hypothesis that two treat- 
ments,A and B, are equivalent against the alternative 
hypothesis that the responses for A tend to be larger 
than those for B. You plan to use a paired difference 
experiment and to analyze the resulting data (shown 
below) using the Wilcoxon signed rank test. 
LM7-65.DAT 
Treatment 
Pair 
A 
B 
Treatment 
Pair 
A 
B 
a. Specify the null and alternative hypotheses you 
would test. 
b. Suppose the paired difference experiment yielded 
the data in the table. Conduct the test of part a. Test 
using a = .025. 
7.66 Explain the difference between the one- and two- 
tailed versions of the Wilcoxon signed rank test for the 
paired difference experiment. 
7.67 In order to conduct the Wilcoxon signed rank test, why 
do we need to assume the probability distribution of 
differences is continuous? 
7.68 Suppose you wish to test a hypothesis that two treat- 
ments, A and B, are equivalent against the alternative 
that the responses for A tend to be larger than those 
for B. 
a. If the number of pairs equals 25, give the rejection 
region for the large-sample Wilcoxon signed rank 
test for a = .05. 
b. Suppose that T+ = 273. State your test conclusions. 
c. Find the p-value for the test and interpret it. 
7.69 A paired difference experiment with n = 30 pairs 
yielded T+ = 354. 
a. Specify the null and alternative hypotheses that 
should be used in conducting a hypothesis test to 
determine whether the probability distribution for 
population 1 is located to the right of that for popu- 
lation 2. 
b. Conduct the test of part a using a = .05. 
c What is the approximatep-value of the test of part b? 
d. What assumptions are necessary to ensure the va- 
lidity of the test you performed in part b? 
Applying the C o n c e p t s  
7.70 An atlas is a compendium of geographic, economic, 
and social information that describes one or more 
ATLAS.DAT 
Rankings 
Theme 
High School Teachers 
Geography Alumni 
Tourism 
Physical 
Transportation 
People 
H~\tory 
Chmate 
Forestry 
Agriculture 
Fishing 
Energy 
Mining 
Manufacturing 
Source: Keller. C. P., et al. "Planning the next generation of regional 
atlases: Input from educators." Journal of Geography, Vol. 94, No. 3. 
MayIJune 1995, p. 413 (Table 1). 
geographic regions. Atlases are used by the sales and 
marketing functions of businesses, local chambers of 
commerce, and educators. One of the most critical 
aspects of a new atlas design is its thematic content. 
In a survey of atlas users (Journal of Geography, 
MayIJune 1995), a large sample of high school teach- 
ers in British Columbia ranked 12 thematic atlas 
topics for usefulness. The consensus rankings of the 
teachers (based on the percentage of teachers who 
responded they "would definitely use" the topic) are 
given in the table above. These teacher rankings 
were compared to the rankings of a group of univer- 
sity geography alumni made three years earlier. 
Compare the distributions of theme rankings for the 
two groups with an appropriate nonparametric test. 
Use a = .05. Interpret the results practically. 
7.71 According to the National Sleep Foundation, com- 
panies are encouraging their workers to take 
"power naps" (Athens Daily News, Jan. 9,2000). In 
1999 Number 
2000 Number 
Agent 
of Complaints 
of Complaints 

S~crl0~7.5 
A N o n p a r a m e t r i c  T e s t  f o r  C o m p a r i n g  T w o  P o p u l a t i o n s  ( O p t i o n a l )  
399 
Exercise 7.27 (p. 371), you analyzed data collected 
by a major airline that recently began encouraging 
reservation agents to nap during their breaks. The 
number of complaints received about each of a 
sample of 10 reservation agents during the six 
months before naps were encouraged and during 
the six months after the policy change are repro- 
duced on p. 398. Compare the distributions of 
number of complaints for the two time periods using 
the Wilcoxon signcd rank test. Use a = .05 to make 
the appropriate inference. 
7.72 In Exercise 7.29 (p. 371), the inflation forecasts of 
nine economists that were made in June 1999 and 
January 2000 were reported. These forecasts, 
obtained from the Wall Street Journal, are repro- 
duced below. To determine whether the economists 
were more optimistic about the prospects for low 
inflation in latc 1999 than in mid 2000, apply the 
Wilcoxon signed rank test. 
June 1999 
Forecast 
for 1 1  199 
January 2000 
Forecast 
for 5/00 
Bruce Steinberg 
Wayne Angel1 
David Blitzer 
Michael Cosgrove 
Gail Fosler 
John Lonski 
Donald Ratajczak 
Thomas Synott 
Sung Won Sohn 
Source: Wall Street Journal, January 3,2000. 
a FLEXTIME.DAT 
.................................................... 
.................................................... 
Employee 
Before After 
Employee 
Before After 
.................................................... 
.................................................... 
1 
54 
68 
6 
82 
88 
2 
25 
42 
7 
94 
90 
3 
80 
80 
8 
72 
81 
4 
76 
91 
9 
33 
39 
5 
63 
70 
10 
90 
93 
toward their jobs were again measured. The resulting 
attitude scores are displayed in the table above. The 
higher the score, the more favorable the employee's 
attitude toward his or her work. Use a nonparametric 
test procedure to evaluate the success of the pilot flex- 
time program. Test using a = .05. 
7.74 
The Standard and Poor's 500 Index is a benchmark 
against which investors compare the performance of indi- 
vidual stocks. A sample of eight of the manufacturing 
companies included in the index were evaluated for prof- 
itability in 1998 and 1999 with the results shown in the 
table below. The profitability measure used was net 
margin-defined 
as net income from continuing opera- 
tions before extraordinary items as a percentage of sales. 
Firm 
1999 
1998 
Net Margin ( O h )  
Net Margin (96) 
Applied Materials 
Caterpillar 
Ingersoll-Rand 
Johnson Controls 
3M 
Black & Decker 
Newel1 Rubbermaid 
Corning 
a. Specify the null and alternative hypotheses you 
11.0 
9.3 
would employ. 
Source: Business Week, March 27,2000, pp. 182-183. 
. . 
b. Conduct the test using a = .05. Interpret your results 
in the context of the problem. 
c. Explain the difference between a Type I and a Type 
I1 error in the context of the problem. 
7.73 A job-scheduling innovation that has helped man- 
agers overcome motivation and absenteeism problems 
associated with a fixed 8-hour workday is a concept 
called flextime. This flexible working hours program 
permits employees to design their own 40-hour work 
week to meet their personal needs (New York Times, 
Mar. 31,1996). The management of a large manufac- 
turing firm may adopt a flextime program depending 
on the success or failure of a pilot program. Ten 
employees were randomly selected and given a ques- 
tionnaire designed to measure their attitude toward 
their job. Each was then permitted to design and 
follow a flextime workday. After six months, attitudes 
a. Is there sufficient evidence to conclude that U.S. 
manufacturing f~rms were more profitable in 1999 
than 1998? Test using a = .05. 
b. What assumptions must be met to ensure the valid- 
ity of the test in part a? 
7.75 It has been known for a number of years that the tail- 
ings (waste) of gypsum and phosphate mines in 
Florida contain radioactive radon 222. The radiation 
levels in waste gypsum and phosphate mounds in Polk 
County, Florida, are regularly monitored by the 
Eastern Environmental Radiation Facility (EERF) 
and by the Polk County Health Department (PCHD), 
Winter Haven, Florida. The table (p. 400) shows mea- 
surements of the exhalation rate (a measure of radia- 
tion) for 15 soil samples obtained from waste mounds 
in Polk County, Florida. The exhalation rate was 

r 
400 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
SPSS Output for Exercise 7.75 
- - - - - Wilcoxon Matched-pairs Signed-ranks Test 
PCHD 
w i t h  EERF 
Mean Rank 
Cases 
8.40 
10 - Ranks (EERF Lt PCHD) 
7.20 
5 + Ranks (EERF Gt PCHD) 
0 
Ties 
(EERF Eq PCHD) 
- - 
15 Total 
Z = -1.3631 
2-tailed P = .I728 
measured for each soil sample by both the PCHD 
and the EERF. Do the data provide sufficient evidence 
EXRATES.DAT 
......................................................................................... 
(at a = .05) to indicate that one of the measuring facili- 
Charcoal Canister No. 
PCHD 
EERF 
.......................................................................... 
tles, PCHD or EERF, tends to read h~gher or lower than 
the other? Use the SPSS Wilcoxon signed rank prmtout 
71 
1,709.79 
1,479.0 
58 
357.17 
257.8 
above to make your conclusions. 
Source Horton,T R "Prehmmary radiolog~cal 
assessment of radon exhalat~on from phosphate 
gypsum p~les and Inactwe uranlum m~ll t a h g s  pdes" 
EPA-52015-79-004. Washmgton, D C Envlronmental 
Protection Agency, 1970. 
COMPARING THREE OR MORE POPULATION 
MEANS: ANALYSIS OF VARIANCE (OPTIONAL) 
Suppose we are interested in comparing the means of three or more populations 
For example, we may want to compare the mean SAT scores of seniors at three 
different high schools. Or, we could compare the mean income per household of 
residents in four census districts. Since the methods of Sections 7.1-7.6 apply to 
two populations only, we require an alternative technique. In this optional section, 
we discuss a method for comparing two or more populations based on indepen- 
dent random samples, called an analysis of variance (ANOVA). 
In the Jargon of ANOVA, treatments represent the groups or populations of 
interest. Thus, the primary objective of an analysis of variance is to compare the 
treatment (or population) means. If we denote the true means of thep treatments 
as p,, p2, .... p,,, then we will test the null hypothesis that the treatment means 
are all equal against the alternative that at least two of the treatment mean5 d~ffer 

FIGURE 7.23 
Dot plot of SAT scores: 
Difference between means 
dominated by sampling 
variability 
FIGURE 7.24 
Dot plot of SAT scores: 
Difference between means 
large relative to sampling 
variability 
C o m p a r i n g  T h r e e  o r  More P o p u l a t i o n  M e a n s  ( O p t i o n a l )  
401 
Ha: At least two of the p treatment means differ 
The p's might represent the means of all female and male high school seniors' 
SAT scores or the means of all households' income in each of four census regions. 
To conduct a statistical test of these hypotheses, we will use the means of the 
independent random samples selected from the treatment populations using the 
completely randomized design. That is, we compare the p sample means, 
- - 
- 
XI, x2, . . . > xp. 
To illustrate the method in a two-sample case, suppose you select indepen- 
dent random samples of five female and five male high school seniors and obtain 
sample mean SAT scores of 550 and 590, rcspectively. Can we conclude that males 
score 40 points higher, on average, than females? To answer this question, we 
must consider the amount of sampling variability among the experimental units 
(students). If the scores are as depicted in the dot plot shown in Figure 7.23, then 
the difference between the means is small relative to the sampling variability of 
the scores within the treatments, Female and Male. We would be inclined not to 
reject the null hypothesis of equal population means in this case. 
Female mean 
Male mean 
SAT score 
Female score 
0 Male score 
In contrast, if the data are as depicted in the dot plot of Figure 7.24, then the 
sampling variability is small relative to the difference between the two means. We 
would be inclined to favor the alternative hypothesis that the population means 
differ in this case. 
Female mean 
Male mean 
I 
I 
+ 
4 
* * * * *  
0 0 0 0 0  
I 
4 
450 
475 
500 
525 
550 
575 
600 
625 
650 
SAT score 
Female score 
0 Male score 
You can see that the key is to compare the difference between the treatment 
means to the amount of sampling variability.To conduct a formal statistical test of 
the hypotheses requires numerical measures of the difference between the treat- 
ment means and the sampling variability within each treatment. The variation 
between the treatment means is measured by the Sum of Squares for Treatments 
(SST), which is calculated by squaring the distance between each treatment mean 
and the overall mean of d l  sample measurements, multiplying each squared dis- 
tance by the number of sample measurements for the treatment, and adding the 
results over all treatments: 
P 
- 
SST = 2 n,(T, - x)* = 5(550 - 570)2 + 5(590 - 570)~ = 4,000 
r=l 

402 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  Means 
where we use 2 to represent the overall mean response of all sample measurements, 
that is, the mean of the combined samples. The symbol n, is used to denote the san- 
ple size for the ith treatment. You can see that the value of SST is 4,000 for the two 
samples of five female and five male SAT scores depicted in Figures 7.23 and 7.24. 
Next, we must measure the sampling variability within the treatments. We 
I 
call this the Sum of Squares for Error (SSE) because it measures the variability 
around the treatment means that is attributed to sampling error. Suppose the 10 
measurements in the first dot plot (Figure 7.23) are 490,520,550,580, and 610 for 
females, and 530,560,590,620, and 650 for males. Then the value of SSE is com- 
puted by summing the squared distance between each response measurement 
and the corresponding treatment mean, and then adding the squared differences 
over all measurements in the entire sample: 
1 
- 
SSE = 2 (x,, - 
+ 2 (x, - x2)' + . . + 
(x,, - id2 
j=l 
j=l 
j=1 
where the symbol X I ,  is the jth measurement in sample 1, x2, is the jth measure- 
ment in sample 2, and so on. This rather complex-looking formula can be simpli- 
fied by recalling the formula for the sample variance, s2, given in Chapte~ 2: 
(x, - q2 
s2= C 
,=, n - 1 
Note that each sum in SSE is simply the numerator of s2 for that particular 
treatment. Consequently, we can rewrite SSE as 
SSE = (nl - 1)s: + (n2 - 1)s; + . + (n, - 1)s; 
where s:, s;, . . . , st are the sample variances for the p treatments. For our samples 
of SAT scores, we find s: = 2,250 (for females) and s; = 2,250 (for males); then 
we have 
SSE = (5 - 1)(2,250) + (5 - 1)(2,250) = 18,000 
To make the two measurements of variability comparable, we divide each by 
1 
the degrees of freedom to convert the sums of squares to mean squares. First, the 
Mean Square for Treatments (MST), which measures the variability among the 
treatment means, is equal to 
SST - 4,000 
MST = - 
- 
= 4,000 
p - 1  
2 - 1  
where the number of degrees of freedom for the p treatments is ( p  - 1). Next, the 
Mean Square for Error (MSE), which measures the sampling variability within the I 
treatments, is 
SSE 
18,000 
- 
MSE = - 
- - 
= 2,250 
n - p  
1 0 - 2  
Finally, we calculate the ratio of MST to MSE-an F statistic: 
MST 
4,000 
F = - - -  
- 
= 1.78 
MSE 
2,250 

- 
SECTION 7.7 
C o m p a r i n g  Three or More Population Means ( O p t i o n a l )  
403 
Values of the F statistic near 1 indicate that the two sources of variation, between 
treatment means and within treatments, are approximately equal. In this case, the 
difference between the treatment means may well be attributable to sampling 
error, which provides little support for the alternative hypothesis that the popula- 
tion treatment means differ. Values of F well in excess of 1 indicate that the varia- 
tion among treatment means well exceeds that within means and therzfore support 
the alternative hypothesis that the population treatment means differ. 
When does F exceed 1 by enough to reject the null hypothesis that the 
means are equal? This depends on the degrees of freedom for treatments and for 
error, and on the value of a selected for the test. We compare the calculated F 
value to a table F value (Tables VIII-XI of Appendix B) with v, = ( p  - 1) de- 
grees of freedom in the numerator and v, = ( n  - p) degrees of freedom in the 
denominator and corresponding to a Type I error probability of a. For the SAT 
score example, the F statistic has v ,  = ( 2  - 1 )  = 1 numerator degree of freedom 
and v, = (10 - 2 )  = 8 denominator degrees of freedom. Thus, for a = .05 we 
find (Table IX of Appendix B) 
The implication is that MST would have to be 5.32 times greater than MSE before 
we could conclude at the .05 level of significance that the two population treat- 
ment means differ. Since the data yielded F = 1.78, our initial impressions for the 
dot plot in Figure 7.23 are confirmed-there 
is insufficient information to con- 
clude that the mean SAT scores differ for the populations of female and male 
high school seniors. The rejection region and the calculated F value are shown in 
Figure 7.25. 
Reiection reqion and calculated 
1 
I 
I 
- 
1.78 (Fig. 7.23) 
5.32 
64.00 (Fig. 7.24) 
Tabled value 
In contrast, consider the dot plot in Figure 7.24. Since the means are the 
same as in the first example, 550 and 590, respectively, the variation between the 
means is the same, MST = 4,000. But the variation within the two treatments ap- 
pears to be considerably smaller. The observed SAT scores are 540,545,550,555, 
and 560 for females, and 580,585,590,595, and 600 for males. These values yield 
s: = 62.5 and sz = 62.5. Thus, the variation within the treatments is measured by 
SSE = (5 - 1)(62.5) + (5 - 1)(62.5) 
SSE 
500 
MSE = - 
- 
- -- = 62.5 
n - p  
8 

404 
CHAPTER f 
C o m p a r i n g  P o p u l a t i o n  Means 
Then the F-ratio is 
MST 
4,000 
F = -- = --- 
MSE 
62.5 = 64.0 
Again, our visual analysis of the dot plot is confirmed statistically: F = 64.0 well 
exceeds the tabled F value, 5.32, corresponding to the .05 level of significance. We 
would therefore reject the null hypothesis at that level and conclude that the 
SAT mean score of males differs from that of females. 
Recall that we performed a hypothesis test for the difference between two 
means in Section 7.1, using a two-sample t statistic for two independent samples. 
When two independent samples are being compared, the t- and F-tests are equiv- 
alent. To see this, recall the formula 
where we used the fact that sz = MSE, which you can verify by comparing the for- 
mulas. Note that the calculated F for these samples ( F  = 64) equals the square of 
the calculated r for the same samples (t = 8). Likewise, the tabled F value (5.32) 
equals the square of the tabled t value at the two-sided .05 level of significance 
(t,,,,, = 2.306 with 8 df). Since both the rejection region and the calculated values 
are related in the same way, the tests are equivalent. Moreover, the assumptions 
that must be met to ensure the validity of the t- and F-tests are the same: 
1. The probability distributions of the populations of responses associated with 
each treatment must all be normal. 
2. The probability distributions of the populations of responses associated with 
each treatment must have equal variances. 
3. The samples of experimental units selected for the treatments must be 
random and independent. 
In fact, the only real difference between the tests is that the F-test can be used to 
compare more thun two treatment means, whereas the t-test is applicable to two 
samples only. The F-test is summarized in the accompanying box. 
Ha: At least two treatment means differ 
MST 
Test statistic: F = - 
MSE 
Assumptions: 
1. Samples are selected randomly and independently from 
the respective populations. 
2. Allp population probability distributions are normal. 
3. The p population variances are equal. 
region: F > Fa, where F, is based on (p - 1) numerator degrees of 
dom (associated with MST) and (n - p) denominator degrees of freedom 
associated with MSE). 

SECTION 7.7 
C o m p a r i n g  T h r e e  or More P o p u l a t i o n  M e a n s  ( O p t i o n a l )  
405 
Computational formulas for MST and MSE are given in Appendix C. We 
will rely on some of the many statistical software packages available to compute 
the F statistic, concentrating on the interpretation of the results rather than their 
calculations. 
~
~
*
"
a
,
~
r
n
~
-
wants to compare the mean distances associated with four 
different brands of golf balls when struck with a driver. An independent sampling 
design is employed, with Iron Byron, the USGA's robotic golfer, using a driver to 
hit a random sample of 10 balls of each brand in a random sequence. The distance 
is recorded for each hit, and the results are shown in Table 7.13, organized by brand. 
TABLE 
7.13 
Results of Independent Sampling Design: 
Iron Byron Driver 
Brand A 
Brand B 
Brand C 
Brand D 
Sample Means 
250.8 
261.1 
270.0 
249.3 
a. Set up the test to compare the mean distances for the four brands. Use a = .lo. 
b. Use the SAS Analysis of Variance program to obtain the test statistic and p- 
value. Interpret the results. 
S o l u t i o n 
a. To compare the mean distances of the four brands, we first specify the 
hypotheses to be tested. Denoting the population mean of the ith brand by p,, 
we test 
H,: P1 = P2 = P3 = P4 
H,: The mean distances differ for at least two of the brands 
The test statistic compares the variation among the four treatment (Brand) 
means to the sampling variability within each of the treatments. 
MST 
Test statistic: F = - 
MSE 
Rejection region: F > Fa = Flo 
with v, = (p - 1) = 3 df and v2 = (n - p) = 36 df 
From Table VIII of Appendix B, we find F,, .= 2.25 for 3 and 36 df. Thus, we 
will reject H, if F > 2.25. (See Figure 7.26.) 
The assumptions necessary to ensure the validity of the test are as follows: 
1. The samples of 10 golf balls for each brand are selected randomly and 
independently. 

406 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
F-test for golf ball experiment 
t 
0 
1 
21 
L 
Observed F: 
2. The probability distributions of the distances for each brand are normal. 
3. The variances of the distance probability distributions for each brand are 
equal. 
b. The SAS printout for the analysis of the data in Table 7.13 is given in Fig- 
ure 7.27. The Total Sum of Squares is designated the Corrected Total, and 
it is partitioned into the Model (representing treatments) and Error Sumc 
of Squares. The bottom part of the printout also gives the treatment 
(Brand) sum of squares under the column headed Anova SS. 
Analysis of Variance Procedure 
Dependent Variable: DISTANCE 
Sum of 
Mean 
source 
DF 
Squares 
Square F Value 
Pr > F 
Model 
3 
2794.388750 
931.462917 
43.99 
0.0001 
Error 
36 
762.301000 
21.175028 
Corrected Total 
39 
3556.689750 
R-Square 
C.V. 
Root MSE 
DISTANCE Mean 
0.785671 
1.785118 
4.601633 
257.777500 
Source 
DF 
Anova SS Mean Square F Value 
Pr > F 
BRAND 
3 
2794.388750 
931.462917 
43.99 
0.0001 
FIGURE 7.27 
SAS analysis of variance printout for golf ball distance data 
The values of the mean squares, MST and MSE (highlighted on the printout), 
are 931.46 and 21.18, respectively. The F-ratio, 43.99, also highlighted on the 
printout, exceeds the tabled value of 2.25. We therefore reject the null hy- 
pothesis at the .10 level of significance, concluding that at least two of the 
brands differ with respect to mean distance traveled when struck by the driver. 
The observed significance level of the F-test is also highlighted on the print- 
out: .0001.This is the area to the right of the calculated F value and it implies 
that we would reject the null hypothesis that the means are equal at any 
CY level greater than .0001. 
The results of an analysis of variance (ANOVA) can be summarized in a 
simple tabular format similar to that obtained from the SAS program In 
Example 7.11. The general form of the table is shown in Table 7.14, where the 
symbols df, SS, and MS stand for degrees of freedom, Sum of Squares, and Mean 
Square, respectively. Note that the two sources of variation, Treatments and Error, 

SECTION 7.7 
C o m p a r i n g  T h r e e  o r  More P o p u l a t i o n  M e a n s  ( O p t i o n a l )  
407 
add to the Total Sum of Squares, %(Total). The ANOVA summary table for Ex- 
ample 7.11 is given in Table 7.15. 
TABLE 
7.14 
General ANOVA Summary Table for a Completely 
Randomized Design 
Source 
d f 
SS 
MS 
F 
................................................................................................................................................... 
Treatments 
p - 1 
SST 
SST 
MST = - MST 
- 
P - 1  
MSE 
Error 
SSE 
SSE 
n -  P 
MSE = -- 
n - P  
Total 
n  - 1 
SS(Tota1) 
TABLE 
7.15 
ANOVA Summary Table for Example 7.1 1 
Source 
df 
S S 
MS 
F 
p-Value 
........................................................................................................................................... 
Brands 
3 
2,794.39 
931.46 
43.99 
.0001 
Error 
36 
762.30 
21.18 
Total 
39 
3,556.69 
Suppose the F-test results in a rejection of the null hypothesis that the treat- 
ment means are equal. Is the analysis complete? Usually, the conclusion that at 
least two of the treatment means differ leads to other questions. Which of the 
means differ, and by how much? For example, the F-test in Example 7.11 leads to 
the conclusion that at least two of the brands of golf balls have different mean dis- 
tances traveled when struck with a driver. Now the question is, which of the 
brands differ? How are the brands ranked with respect to mean distance? 
One way to obtain this information is to construct a confidence interval for 
the difference between the means of any pair of treatments using the method of 
Section 7.1. For example, if a 95% confidence interval for 
- pc in Example 7.1 1 
is found to be (-24, -13), we are confident that the mean distance for Brand C 
exceeds the mean for Brand A (since all differences in the interval are negative). 
Constructing these confidence intervals for all possible brand pairs will allow you 
to rank the brand means. A method for conducting these multiple comparisons- 
one that controls for Type I errors-is 
beyond the scope of this introductory text. 
Consult the chapter references to learn more about this methodology. 
Using the TI-83 Graphing Calculator 
ONE-WAY ANOVA O N  THE T I - 8 3  
Start from the home screen. 
Step '1 Enter each data set into its own list (i.e., sample 1 into Listl, sample 2 into 
List2, sample 3 into List3, etc.). 
(continued) 

408 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Step 2 Acccss the Statistical Test Menu. 
Press STAT 
Arrow right to TEST 
Arrow UTJ to F : ANOVA( 
Step 
s 
E 
Press ENTER 
3 Enter each list, separated by 
analysis (e.g., L1, L2, L3, L4). 
Press ENTER 
cpmmas, for which you want to perform the 
tep 4 View Display. 
The calculator will display the F-test statistic, as well as the p-value, the 
Factor degrees of freedom, sum of squares, mean square, and by arrowing 
down the Error degrees of freedom, sum of squares, mean square, and the 
pooled standard deviation. 
ixample Below are four different samples. At the a = 0.05 level of significance 
test whether the four population means are equal. The null hypothegs 
will be ffo: p, = p2.= p3 = p4 The alternative hypothesis is Ha: At least 
one mean is different. 
Step 1 Enter the data into the lists. 
Step 2 Access the Statistical Test Menu. 
Step 3 Enter each list for which you wish to perform the analysis (see screen belou 
left). 
Step 4 Press ENTER and view scieen (see screen above right.) As you ca 
see from the screen, the p-value is 0.1598 which is not less than 0.05 therc 
fore we should not reject Ho: p1 = p2 = p3 = p4. The d~fterences are nc 
significant. ' 
Step 5 Clcar the screen for the next problem. Return to ,the home screen. Pre 
CLEAR. 
S o I u t i o n The assumptions for the test are repeated below. 
1. The samples of golf balls for each brand are selected randomly and inde- 
pendently. 
2. The probability distributions of the distances for each brand are normal. 

SECTION 7.7 
C o m p a r i n g  Three o r  M o r e  P o p u l a t i o n  Means ( O p t i o n a l )  
409 
3. The variances of the distance probability distributions for each brand are 
equal. 
Since the sample consisted of 10 randomly selected balls of each brand and 
the robotic golfer Iron Byron was used to drive all the balls, the first assumption of 
independent random samples is satisfied. To check the next two assumptions, we 
will employ two graphical methods presented in Chapter 2: stem-and-leaf dis- 
plays and dot plots. A MINITAB stem-and-leaf display for the sample distances of 
each brand of golf ball is shown in Figure 7.28, followed by a MINITAB dot plot 
in Figure 7.29. 
FIGURE 7.28 
MINITAB stem-and-leaf displays for 
golf ball distance data 
- 
Stem-and-leaf of BrandA N = 10 
Leaf Unit = 1.0 
2 
24 45 
2 
24 
4 
24 88 
(3) 25 011 
3 
25 3 
2 
25 4 
1 
25 
1 
25 
1 
26 0 
Stem-and-leaf of BrandB N = 10 
Leaf Unit = 1.0 
2 
25 45 
3 
25 7 
3 
25 
4 
26 0 
(3) 26 223 
3 
26 445 
Stem-and-leaf of BrandC N = 10 
Leaf Unit = 1.0 
Stem-and-leaf of BrandD N = 10 
Leaf Unit = 1.0 

410 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
FIGURE 7.29 
MINITAB dot plots 
for golf ball distance 
data 
The normality assumption can be checked by examining the stem-and-leaf 
displays in Figure 7.28. With only 10 sample measurements for each brand, how- 
ever, the displays are not very informative. More data would need to be collect- 
ed for each brand before we could assess whether the distances come from 
normal distributions. Fortunately, analysis of variance has been shown to be a 
very robust method when the assumption of normality is not satisfied exactly: 
That is, moderate departures from normality do not have much effect on the 
significance level of the ANOVA F-test or on confidence coefficients. Rather 
than spend the time, energy, or money to collect additional data for this experi- 
ment in order to verify the normality assumption, we will rely on the robustness 
of the ANOVA methodology. 
Dot plots are a convenient way to obtain a rough check on the assumption 
of equal variances. With the exception of a possible outlier for Brand D, the dot 
plots in Figure 7.29 show that the spread of the distance measurements is about 
the same for each brand. Since the sample variances appear to be the same, the as- 
sumption of equal population variances for the brands is probably satisfied. Al- 
though robust with respect to the normality assumption, ANOVA is not robust 
with respect to the equal variances assumption. Departures from the assumption 
of equal population variances can affect the associated measures of reliability 
(e.g., p-values and confidence levels). Fortunately, the effect is slight when the 
sample sizes are equal, as in this experiment. 
Although graphs can be used to check the ANOVA assumptions, as in Ex- 
ample 7.12, no measures of reliability can be attached to these graphs. When you 
have a plot that is unclear as to whether or not an assumption is satisfied, you can 
use formal statistical tests, which are beyond the scope of this text. (Consult the 
chapter references for information on these tests.) When the validity of the 
ANOVA assumptions is in doubt, nonparametric statistical methods are useful. 
Learning the Mechanics 
7.76 A partially completed ANOVA table for an indepen- 
....................................................................................... 
dent sampling design is shown at right. 
Source 
df 
SS 
MS 
f 
....................................................................................... 
a. Complete the ANOVA table. 
b. How many treatments are involved in the experiment? 
Treatments 
6 
17.5 - - 
c. Do the data provide sufficient evidence to indicate 
Error 
- - - 
a difference among the population means? Test 
Total 
41 
46.5 
using a = .lo. 

SECTION 7.7 
C o m p a r i n g  T h r e e  o r  M o r e  P o p u l a t i o n  M e a n s  ( O p t i o n a l )  
411 
Dot Plots for Exercise 7.77 . 
Sample 1 
Sample 2 
d. Find the approximate observed significance level 
for the test in part c, and interpret it. 
e. Suppose that x, = 3.7 and & = 4.1. Do the data 
provide sufficient evidence to indicate a difference 
between p1 and p,? Assume that there are six ob- 
servations for each treatment.Test using a = .lo. 
f. Refer to part e. Find a 90% confidence interval for 
(PI - ~ 2 ) .  
g. Refer to part e. Fmd a 90% confidence interval for pl. 
Consider dot plots a and b shown above. In which plot 
is the difference between the sample means small rela- 
tive to the variability within the sample observations? 
Justify your answer. 
Refer to Exercise 7.77. Assume that the two samples 
represent independent, random samples corresponding 
to two treatments. 
a. Calculate the treatment means, i.e., the means of 
samples 1 and 2, for both dot plots. 
h. Use the means to calculate the Sum of Squares for 
Treatments (SST) for each dot plot. 
c. Calculatc the sample variance for each sample and 
use these values to obtain the Sum of Squares for 
Error (SSE) for each dot plot. 
d. Calculate the Total Sum of Squares [SS(Total)] for 
the two dot plots by adding thc Sums of Squares 
for Treatments and Error. What percentage of 
SS(Tota1) is accounted for by the treatments-that 
is, what percentage of the Total Sum of Squares is 
the Sum of Squares for Treatments-in 
each case? 
e. Convert the Sum of Squares for Treatments and 
Error to mean squares by dividing each by the ap- 
propriate number of degrees of freedom. Calculate 
the F-ratio of the Mean Square for Treatments 
(MST) to the Mean Square for Error (MSE) for 
each dot plot. 
f. Use the F-ratios to test the null hypothesis that the 
two samples are drawn lrom populations with equal 
means. Use a = .05. 
g. What assumptions must be made about the proba- 
bility distributions corresponding to the responses 
for each treatment in order to ensure the validity of 
the F-tests conducted in part f? 
7.79 Refer to Exercises 7.77 and 7.78. Conduct a two- 
sample t-test (Section 7.1) of the null hypothesis that 
the two treatment means are equal for each dot plot. 
Use a = .05 and two-tailed tests. In the course of the 
test, compare each of the following with the F-tests in 
Exercise 7.78: 
a. The pooled variances and the MSEs 
b. The t- and F-test statistics 
c. The tabled values of t and F that determine the re- 
jection regions 
d. The conclusions of the t- and F-tests 
e. The assumptions that must be made in order to en- 
sure the validity of the t- and F-tests 
7.80 Refer to Exercises 7.77 and 7.78. Complete the follow- 
ing ANOVA table for each of the two dot plots: 
Source 
df 
SS 
MS 
F 
............................................................................ 
Treatments 
Error 
Total 
7.81 A MINITAB printout for an experiment utilizing inde- 
pendent random samples is shown below. 
a. How many treatments are involved in the experi- 
ment? What is the total sample size? 
MINITAB Output for Exercise 7.81 
SOURCE 
FACTOR 
57258 
19086 
14.80 
0.002 
ERROR 
3 4 
43836 
1289 

412 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
b. Conduct a test of the null hypothesis that the treat- 
ment means are equal. Usc a = .lo. 
C. What additional information is needed in order to be 
able to compare specific pairs of treatment means? 
Applying the Concepts 
7.82 In forming real estate portfolios, investors typically 
diversify the geographic locations of their holdings. 
While some choose to own properties in a variety of 
different metropolitan areas, others diversify across 
submarkets within the same metropolitan region. J. 
Rabianski and P. Cheng of Georgia State University 
investigated the appropriateness of the latter approach 
as it applics to investing in office properties (Jo~irnul of 
Real Estate Portfolio Management, Vol. 3,1997). Using 
the office vacancy rate of a submarket as a proxy for 
total rate of return lor the ollice submarket, the 
Submarket 
Mean Vacancy Rate (%) 
................................................................................... 
Buckhead 
16.85 
Downtown 
20.73 
Midtown 
19.75 
North Central 
16.73 
Northeast 
16.95 
Northwest 
16.81 
North Lake 
20.38 
i 
South 
28.26 
Source. Adapted from Rab~ansk~, 
J. S , and Cheng, 
P.,"Intrametropol~tan Spatla1 Dlvers~ficat~on," 
Journal of Real E~trire PortfoLo Management, 
Vol 3, No 2,1997, pp 117-128. 
researchers compared submarkets within several U.S. 
metropolitan areas. The table at left presents the mean 
vacancy rates of the eight office submarkets of Atlanta, 
Georgia, for a period of nine years. Quarterly vacancy 
rates were used in calculating the means. 
a. Specify the null and alternative hypotheses to usein 
comparing the mean vacancy rates of the eight of- 
fice-property submarkets of Atlanta. 
b. The researchers reported an ANOVA F statistic of 
F = 17.54 for the Atlanta data. Conduct the hy- 
pothesis test you specified in part a. Draw the ap- 
propriate conclusions in the context of the problem. 
c. Givc the approximate p-value for the test you con- 
ducted in part b. 
d. What assumptions must be met to ensure the valid- 
ity of the inference you made in part b? Which of 
these assumptions do you consider the most ques- 
tionable in this application? Why? 
7.83 
Refer to Fortune (Oct. 25,1999) magazine's study of the 
50 most powerful women in America. Exercise 2.36 
(p. 59). The data table, reproduced below, gives the aye 
(in years) and title of each of these 50 women. Suppose 
you want to compare the average ages of powerful 
women in three groups based on their position (title) 
within the firm: Group 1 (CEO, CFO, CIO, or COO); 
Group 2 (Chairman, President, or Director); and Group 
3 (Vice President,Vice Chairman, or General Manager). 
A MINITAB analysis of variance is conducted on the 
data, with the results shown in the printouts on 
p. 413-415. Fully interpret the results. Give the null and 
altcrnative hypotheses tested. Also, determine whether 
the ANOVA assumptions are reasonably satisfied. 
Rank 
Name 
Age 
Company 
............................... - 
Title 
Carly Fiorina 
Heidi Miller 
Mary Meeker 
Shelly Lazarus 
Meg Whitman 
Dcbby Hopkins 
Marjorie Scardino 
Martha Stewart 
Nancy Peretsman 
Pat Russo 
Patricia Dunn 
Abby Jo~eph Cohen 
Ann Livermore 
Andrea Jung 
Sherry Lansing 
Karen Katen 
Marilyn Carlson Nelson 
Judy McGrath 
Lois Juliber 
Gerry Laybourne 
Hewlett-Packard 
Citigroup 
Morgan Stanley 
Ogilvy & Mather 
eBay 
Boelng 
Pearson 
Martha Stewart Living 
Allen & Co. 
Lucent Technologies 
Barclays Global Investors 
Goldman Sachs 
Hewlett-Packard 
Avon Products 
Paramount P~ctures 
Pfizer 
Carlson Cos. 
MTV & M2 
Colgate-Palmolive 
Oxygen Med~a 
CEO 
CFO 
Managing Director 
CEO 
CEO 
CFO 
CEO 
CEO 
Ex. V.P. 
Ex. V.P. 
Chairman 
Managing Director 
CEO 
COO 
Chairman 
Ex. V.P 
CEO 
President 
COO 
CEO 
(continued) 

SECTION 7.7 
C o m p a r i n g  T h r e e  o r  M o r e  P o p u l a t i o n  Means ( O p t i o n a l )  
Rank 
Name 
Age 
Company 
Title 
Judith Estrin 
Cathleen Black 
Linda Sandford 
Ann Moore 
Jill Barad 
Oprah Winfrey 
Judy Lewent 
Joy Covey 
Rebecca Mark 
Deborah Willingham 
Dina Dubion 
Patricia Woertz 
Lawton Fitt 
Ann Fudge 
Carolyn Ticknor 
Dawn Lepore 
Jeannine Rivet 
Jamie Gorelick 
Jan Brandt 
Bridget Macaskill 
Jeanne Jackson 
Cynthia Trudell 
Nina DiSesa 
Linda Wachner 
Darla Moore 
Marion Sandler 
Michelle Anthony 
Orit Gadlesh 
Charlotte Beers 
Abigail Johnson 
Cisco Systems 
Hearst Magazines 
IBM 
Time Inc. 
Matte1 
Harpo Entertainment 
Merck 
Amazon.com 
Azurix 
Microsoft 
Chase Manhattan 
Chevron 
Goldman Sachs 
Kraft Foods 
Hewlett-Packard 
Charles Schwab 
UnitedHealthcare 
Fannie Mae 
America Online 
OppenheimerFunds 
Banana Republic 
General Motors 
McCann-Erickson 
Warnaco 
Rainwater Inc. 
Golden West 
Sony Music 
Bain & Co. 
J. Walter Thompson 
F~dcl~ty 
Investments 
Sr. V.P. 
President 
General Manager 
President 
CEO 
Chairman 
Sr. V. P. 
COO 
CEO 
v. P. 
Ex. V.P. 
President 
Man. Dir. 
Ex. V.P. 
CEO 
CIO 
CEO 
Vice Chairman 
Mar. President 
CEO 
CEO 
v. P. 
Chairman 
Chairman 
President 
Co-CEO 
Ex. V.P. 
Chairman 
Chairman 
V.P. 
Source: Fortune, October 25,1999. 
MINITAB Output for Exercise 7.83 
Analysis of Variance for Age 
Source 
DF 
SS 
MS 
F 
P 
Group 
2 
114.3 
57.1 
1.62 
0.209 
Error 
47 
1658.5 
35.3 
Total 
49 
1772.7 
Individual 95% CIS For Mean 
Based on Pooled StDev 
Leve 1 
N 
Mean 
StDev 
- - - - - - - - - + - - - - - - - - - + - - - - - - - - - + - - - - - - -  
1 
21 
48.952 
7.159 
(--------*-------- 
) 
2 
16 
49.188 
5.648 
(---------*--------- 
) 
3 
13 
45.615 
3.595 
(----------*---------- 
) 
---------+---------+---------+------- 
Pooled StDev 
5.940 
45.0 
48.0 
51.0 
7.84 Researchers at Pennsylvania State University and 
were asked about the safety of nuclear power plants. 
Iowa State University jointly studied the attitudes of 
Responses were made on a seven-point scale, where 
three groups of professionals that influence US. policy 
1 = very unsafe and 7 = very safe. The mean safety 
governing new technologies: scientists, journalists, and 
scores for the groups are scientists, 4.1; journalists, 3.7; 
federal government policymakers (American Journal 
government officials, 4.2. 
of Political Science, Jan. 1998). Random samples of 100 
a. How many treatments are included in this study? 
scientists, 100 journalists, and 100 government officials 
Describe them. 

414 
CHAPTER 7 C o m p a r i n g  P o p u l a t i o n  M e a n s  
MINITAB Output for Exercise 7.83 (Cont'd.) 
Stem-and-leaf of Age 
Group = 1 
N = 21 
Leaf Unit = 1.0 
1 
3 6  
1
3
 
3 
4 11 
4 
4 3  
8 
4 4555 
9 
4 6  
(2) 4 88 
10 
5 011 
7 
5 2222 
3 
5 
3 
5 
3 
5 8  
2 
6 0  
1
6
 
1
6
 
1
6
 
1
6
8
 
Stem-and-leaf of Age 
Group = 2 N = 16 
Leaf Unit E 1.0 
1
4
0
 
1
4
 
3 
4 55 
8 
4 66677 
8 
4 899 
5 
5 
5 
5 33 
3 
5 55 
1
5
 
1
5
 
1 
6 
-p- - 9  '" ,"-- 
"*-- 
1
6
 
1
6
4
 
Stem-and-leaf of Age 
Group = 3 N = 13 
Leaf Unit = 1.0 
1 
3 7  
1
3
 
1
4
 
3 
4 23 
5 
4 45 
(4) 4 6667 
4 
4 89 
2 
5 00 
d. If the MST = 11.280, what is the approximate 
p-value of the test of part a? 
7.85 The Minnesota Multiphasic Personality Inventory 
(MMPI) is a questionnaire used to gauge personality 
type. Several scales are built into the MMPI to assess 
response distortion; these include the Infrequency (I), 
Obvious (0), Subtle (S), Obvious-subtle (0-S), and 
Dissimulation (D) scales. Psychological Assessnlent 
(Mar. 1995) published a study that investigated the 
effcctiveness of these MMPI scales in detecting delib- 
erately distorted responses. An independent sampling 
design with four treatments was employed. The treat- 
ments consisted of independent random samples of 
females in the following four groups: nonforensic psy- 
chiatric patients ( n ,  = 65), forensic psychiatric 
patients (n, = 28), college students who were request- 
ed to respond honestly (n, = 140), and college stu- 
dents who were instructed to provide "fake bad" 
responses (n, = 45). All 278 participants were given 
the MMPI and the I, 0 ,  S, 0-S, and D scores were 
recorded for each. Each scale was treated as a 
response variable and an analysis of variance conduct- 
ed. The ANOVA F values are reported in the table. 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Response Variable 
ANOVA F Value 
Infrequency (I) 
155.8 
Obvious (0) 
49.7 
Subtle (S) 
10.3 
Obvious-subtle (0-S) 
45.4 
Dissimulation (D) 
39.1 
a. For each response variable, determine whether the 
mean scores of the four groups completing the 
MMPI differ significantly. Use a = .05 for each test. 
b. If the MMPI is effective in detecting distorted re- 
sponses, then the mean score for the "fake bad 
treatment group will be largest. Based on the ~nfor- 
mation provided, can the researchers make an in- 
ference about the effectiveness of the MMPI? 
Explain. 
7.86 The Journal of Hazardous Materials (July 1995) pub- 
lished the results of a study of the chemical properties 
of three different types of hazardous organic solvents 
used to clean metal parts: aromatics, chloroalkancs. 
and esters. One variable studied was sorption rate. 
measured as mole percentage. Independent samples 
of solvents from each type were tested and their sorp- 
b. Specify the null and alternative hypotheses that 
tion rates were recorded, as shown in the table on p. 415. 
should be used to investigate whether there are dif- 
An SPSS analysis of variance of the data is shown in 
ferences in the attitudes of scientists, journalists, and 
the printout above the table. 
government officials regarding the safety of nuclear 
a. Is there evidence of differences among the mean 
power plants. 
sorption rates of the three organic solvent types'? 
c. The MSE for the sample data is 2.355. At least how 
Test using a = .lo. 
large must MST be in order to reject the null hypoth- 
b. List the assumptions required for the analysis, part 
esis of the test of part a using a = .05? 
a, to be valid. 

SECTION 7.7 
C o m p a r i n g  T h r e e  o r  M o r e  P o p u l a t i o n  M e a n s  ( O p t i o n a l )  
MINITAB Output for Exercise 7.83 (Cont'd.) 
Group 
SPSS Output for Exercise 7.86 
I SORPRATE 
I 
Sum of 
Squares 
df 
Between Groups / 
3.305 1 
Within Groups 
1.955 
Total 
5.261 
HAZARDS.DAT 
......................................................................................................... 
Aromatics 
Chloroalkanes 
Esters 
......................................................................................... 
1.06 
.95 
1.58 
1.12 
.29 
.43 
.06 
.79 
,651 
1.45 
.91 
.06 
.51 
.09 
.82 
1.15 
.57 
.83 
.44 
.10 
.17 
39 
1.12 
1.16 
.43 
.61 
.34 
.60 
1.05 
5 5  
.53 
.17 
Source: Reprinted from Journal of Hazardous Materials, Vol. 
42, No. 2, J. D. Ortego et al., "A review of polymeric 
geosynthetics used in hazardous waste facilities," p. 142 (Table 9), 
July 1995, Elsevier Science-NL, Sara Burgerhartstraat 25,1055 
KV Amsterdam, The Netherlands. 
encourages the buyer to buy now before some future 
event occurs that makes the terms of the sale less 
favorable for the buyer. Sales scenarios were present- 
ed to a sample of 238 purchasing executives. Each sub- 
ject received one of the five closing techniques or a 
scenario in which no close was achieved. After reading 
the sales scenario, each executive was asked to rate 
their level of trust in the salesperson on a 7-point 
scale. The table reports the six treatments employed in 
the study and the number of subjects receiving each 
treatment. 
............................................................................................ 
Treatments: Closing Techniques 
Sample Size 
c. Check the assumptions, part b. Do they appear to 
be reasonably satisfied? 
7.87 Industrial sales professionals have long debated the 
effectiveness of various sales closing techniques. 
University of Akron rcsearchers S. Hawes, J. Strong, 
and B. Winick investigated the impact of five different 
closing techniques and a no-close condition on the 
level of a sales prospect's trust in the salesperson 
(Industrial Marketing Management, Sept. 1996). Two 
of the five closing techniques were the assumed close 
and the impending event technique. In the former, the 
salesperson simply writes up the order or behaves as if 
the sale has been made. In the latter, the salesperson 
1. No close 
38 
2. Impending event 
36 
3. Social validation 
29 
4. If-then 
42 
5. Assumed close 
36 
6. Either-or 
56 
a. The investigator's hypotheses were 
Ho: The salesperson's level of prospect trust is not 
influenced by the choice of closing method 
Ha: The salesperson's level of prospect trust is 
influenced by the choice of closing method 

S T A T I S T I C S  I N 
On the Trail of the Cockroac 
E 
ntomologists have long established that insects such as 
ants, bees, caterpillars, and termites use chemical or 
"odor" trails for navigation. These trails are used as high- 
ways between sources of food and the insect nest. Until re- 
cently, however, "bug" researchers believed that that 
navigational behavior of cockroaches scavenging for food 
was random and not linked to a chemical trail. 
One of the first researchers to challenge the "random- 
walk" theory for cockroaches was professor and entomolo- 
gist Dini Miller of Virginia Tech University. According to 
Miller, "the idea that roaches forage randomly means that 
they would have to come out of their hiding places every 
night and bump into food and water by accident. But 
roaches never seem to go hungry." Since cockroaches had 
never before been evaluated for trail-following behavior, 
Miller designed an experiment to test a cockroach's ability 
to follow a trail to their fecal material (Explore, Research at 
the University of Florida, Fall 1998). 
First, Dr. Miller developed a methanol extract from 
roach feces-called 
a pheromone. Shc theorized that 
"pheromones are communication devices between cock- 
roaches. If you have an infestation and have a lot of fecal 
material around, it advertises, 'Hey, this is a good cockroach 
place."'Then, she created a chemical trail with the 
pheromone on a strip of white chromatography paper and 
placed the paper at the bottom of a plastic, V-shaped con- 
tainer, 122 square centimeters in size. German cockroaches 
were released into the container at the beginning of the 
trail, one at a time, and a video surveillance camera was 
used to monitor the roach's movements. 
In addition to the trail containing the fecal extract (the 
treatment), a trail using methanol only was created.This sec- 
ond trail served as a "control" to compare back against the 
treated trail. Since Dr. Miller also wanted to determine if 
trail-following ability differed among cockroaches of differ- 
ent age, sex, and reproductive stage, four roach groups were 
utilized in the experiment: adult males, adult females, gravid 
(pregnant) females, and nymphs (immatures).Twenty roach- 
es of each type were randomly assigned to the treatment 
trail and 10 of each type were randomly assigned to the con- 
trol trail. Thus, a total of 120 roaches were used in the ex- 
periment. A layout of the design is illustrated in Figure 7.30. 
The movement pattern of each cockroach tested was 
translated into xy coordinates every one-tenth of a second 
by the Dynamic Animal Movement Analyzer (DAMA) 
program. Miller measured the perpendicular distance of 
each xy coordinate from the trail and then averaged these 
distances, or deviations, for each cockroach. The average 
trail deviations (measured in pixels*) for 120 cockroaches 
in the study are listed in Table 7.16 and saved in the file 
ROACH.DAT. 
F o c u s  
Conduct the appropriate analysis of the data. Use the re- 
sults to answer the following research questions (not nec- 
essarily in the order presented): 
(1) Is there evidence that cockroaches within a group ex- 
hibit the ability to follow fecal extract trails? 
(2) Does trail-following ability differ among cockroaches 
of different age, sex, and reproductive status? 
Write up the results of your analysis in a report and pre- 
sent it to your class. 
*1 pixel = 2 centimeters 
FIG u R E  7.3 0 
Layout of Experimental Design for Cockroach Study 
Roach Type 
.................................................................................................................................. 
Adult Male 
Adult Female 
Gravid Female 
Nymph 
............................................................................................................................................................................. 
Extract 
n = 20 
n = 20 
n = 20 
n = 20 
control 
n = 10 
n = 10 
n = 10 
n = 10 

 
SECTION 7.7 
C o m p a r i n g  T h r e e  o r  M o r e  P o p u l a t i o n  M e a n s  ( O p t i o n a l )  
417 
I 
I 
i 
ROACH.DAT 
TABLE 
7.16 
Average Trail Deviations for 120 Cockroaches 
Adult Males 
Adult Females 
Gravid Females 
Nymphs 
........................................................................ 
................. 
.............................................. 
Extract 
Control 
Extract 
Control 
Extract 
Control 
Extract 
Control 
.................................................................................................................... 
........................................ 
3.1 
42.0 
7.2 
70.2 
78.7 
54.6 
7.7 
132.9 
6.2 
22.7 
17.3 
49.0 
70.3 
54.3 
27.7 
19.7 
34.0 
93.1 
9.1 
40.5 
79.9 
63.5 
18.4 
32.1 
2.1 
17.5 
13.2 
13.3 
51.0 
52.6 
47.6 
66.4 
2.4 
78.1 
101.2 
31.8 
13.6 
95.1 
22.4 
126.0 
4.4 
74.1 
4.6 
116.0 
20.4 
117.9 
8.3 
131.1 
2.4 
50.3 
18.1 
164.0 
51.2 
53.3 
13.5 
50.7 
I 
I 
7.6 
8.9 
73.0 
30.2 
27.5 
84.0 
45.6 
93.8 
5.5 
11.3 
4.8 
44.3 
63.1 
103.5 
8.4 
59.4 
1 
6.9 
82.0 
20.5 
72.6 
4.8 
53.0 
3.3 
25.6 
25.4 
51.6 
23.4 
51.2 
2.2 
5.8 
48.2 
10.4 
2.5 
27.8 
13.3 
32.0 
4.9 
2.8 
57.4 
6.9 
18.5 
4.4 
65.4 
32.6 
4.6 
3.2 
10.5 
23.8 
7.7 
3.6 
59.9 
5.1 
3.2 
1.7 
38.4 
3.8 
2.4 
29.8 
27.0 
3.1 
1.5 
21.7 
76.6 
2.8 
I 
Sourtr. Dr. Dini Miller, Department of Entomolgy, Vlrgma Polytechnic Institute and State University. 
i 
d 
a- 

418 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Rewrite these hypotheses in the form required for 
an analysis of variance. 
b. The researchers reported the ANOVA F statistic as 
F = 2.21. Is there sufficient evidence to reject H,, at 
a = .05? 
c. What assumptions must be met in order for the test 
of part a to be valid? 
d. Would you classify this experiment as observational 
or designed? Explain. 
7.88 
On average, over a million new businesses are started 
in the United States every year. An article in the 
Journal of Business Venturing (Vol. 11,1996) reported 
on the activities of entrepreneurs during the organiza- 
tion creation process. Among the questions investigat- 
ed were what activities and how many activities do 
entrepreneurs initiate in attempting to establish a new 
business? A total of 71 entrepreneurs were inter- 
viewed and divided into three groups: those that were 
successful in founding a new firm (34), those still 
actively trying to establish a firm (21), and those who 
tried to start a new firm, but eventually gave up (16). 
The total number of activities undertaken (i.e., dcvel- 
oped a business plan, sought funding, looked for facil- 
ities, etc.) by each group over a specified time period 
during organization creation was measured and the 
following incomplete ANOVA table produced: 
....................................................................................... 
Source 
df 
SS 
MS 
F 
....................................................................................... 
Groups 
2 
128.70 
- - 
Error 
68 
27,124.52 - 
Source: Carter, N., Garner, W., and Reynolds, I? 
"Exploring start-up event sequences." Journal of 
Business Venturing, Vol. 11,1996, p. 159. 
a. Complete the ANOVA table. 
h. Do the data provide sufficient evidence to indicate 
that the total number of activities undertaken dif- 
fered among the three groups of entrepreneurs? 
Test using a = .05. 
c. What is the p-value of the test you conducted in 
part b? 
d. One of the conclusions of the study was that the 
behaviors of entrepreneurs who have successfully 
started a new company can be differentiated from 
the behaviors of entrepreneurs that failed. Do you 
agree? Justify your answer. 
Key Terms 
Note: Starred (*) items are from the optional sections in this chapter. 
Analysis of Vairance (ANOVA) 400 
Paired difference experiment 365 
Sum of squares for error* 402 
Blocking 365 
Pooled sample estimate of variance 351 
Standard error 347 
F-distribution* 377 
Randomized block experiment 365 
Treatments* 400 
F-test* 381 
Rank Sum* 385 
Wilcoxon rank sum test* 384 
Mean square for error* 402 
Robust Method* 410 
Wilcoxon signed rank text* 393 
Mean square for treatments* 402 
................................................................................................................................................................................................................................................. 
Key Formulas 
Note: Starred (*) formulas are from the optional sections in this chapter. 
(1 - a)100% confidence interval fore: (see table below) 
For testing H,,: 0 = Do: (see table below) 
6 - Do 
Large samples: + z,j2aa 
Large samples: z = --- 
0 8  
,. 
0 - Do 
Small samples: f t4us 
Small samples: t = ---- 
F 8  
Standard Error 
Parameter, 0 
Estimator, 6 
of Estimator, ( ~ 8  
Estimated Standard Error 
........................................................................................................................................................................................................................................... 
(cdl - cd2) 
(21 - 2 2 )  
J? + p 
(independent samples) 
Large n: Jz 
p~ (paired sample) 

larger s2 
d 
if Ha: 7 
f 1 
('2 
u: 
- if Ha: 7 
> 1 
('2 
ndn, + n2 + 1) 
Tl - 
*z = 
2 
n(n + 1) 
T+ - - 
Xz = 
4 
MST 
* F  = - 
MSE 
L a n g u a g e  Lab 
Pooled sample variance 
Determining the sample size for estimating (p, - p2) 
a? 
Test statistic for testing H,: - 
d 
Wilcoxon rank sum test (large samples) 
Wilcoxon signed ranks test (large samples) 
ANOVA F-test 
Symbol 
Pronunciation 
Description 
. . . . . . . . . . . . . . . . . . . . . . .. . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Note: Starred (*) symbols are from the optional sections in this chapter. 
( - ) 
mu-1 minus mu-2 
(i, 
- G) 
x-bar-1 minus x-bar-2 
sigma of x-bar-1 minus x-bar-2 
s-p squared 
D naught 
mu D 
x-bar D 
S-D 
n-D 
F-alpha 
sigma-1 squared over sigma-2 squared 
Difference between population means 
Difference between sample means 
Standard deviation of the sampling distribution of (i, - G) 
Pooled sample variance 
Hypothesized value of difference 
Difference between population means, paired data 
Mean of sample differences 
Standard deviation of sample differences 
Number of differences in sample 
Critical value of F associated with tail area a 
Numerator degrees of freedom for F statistic 
Denominator degrees of freedom for F statistic 
Ratio of two population variances 
Sum of ranks of observations in sample 1 
Sum of ranks of observations in sample 2 
Critical lower Wilcoxon rank sum value 
Critical upper Wilcoxon rank sum value 
Sum of ranks of positive differences of paired observations 
Sum of ranks of negative differences of paired observations 
Critical value of Wilcoxon signed rank test 

420 
CHAPTER 
7 
C o m p a r i n g  P o p u l a t i o n  Means 
ANOVA* 
Analysis of Variance 
SST* 
Sum of Squares for Treatments (i.e., the variation among 
treatment means) 
SSE* 
Sum of Squares for Error (i.e., the variability around the 
treatment means due to sampling error) 
MST* 
Mean Square for Treatments 
MSE* 
Mean Square for Error (an estimate of u2) 
Starred (*) exercises refer to the optional sections in this 
chapter. 
Learning the Mechanics 
7.89 Independent random samples were selected from two 
I 
normally distributed populations with means p, and 
p2, respectively. The sample sizes, means, and vari- 
I 
ances are shown in the followmg table. 
I 
.............................................. 
Sample 1 
Sample 2 
......................................... 
n1 = 12 
- 
n2 = 14 
- 
x1 = 17.8 
x, = 15.3 
sf = 74.2 
s; = 60.5 
a. Test H,: (pl - p2) = 0 against Ha: ( p ,  - p2) > 0. 
Use a = .05. 
b. Form a 99% confidence interval for ( p ,  - p2). 
c. How large must n, and n2 be if you wish to esti- 
mate (pl - p2) to within 2 units with 99% confi- 
dence? Assume that n1 = n2. 
+7.90 Two independent random samples were selected from 
normally distributed populations with means and vari- 
ances (pl, uf) and (p,, u;), respectively. The sample 
sizes, means, and variances are shown in the table 
below. 
Sample 1 
Sample 2 
............................................... 
n, = 20 
n2 = 15 
- 
x1 = 123 
& = 116 
sf = 31.3 
sz = 120.1 
a. Test H,: a: = a$ against Ha: a: # a$. Use a = .05. 
b. Would you be willing to use a t-test to test the null 
hypothesis H,: (p, - p2) = 0 against the alterna- 
tive hypothesis Ha: ( p ,  - p2) # O? Why? 
7.91 Two independent random samples are taken from two 
populations. The results of these samples are summa- 
rized in the next table. 
a. Form a 90% confidence interval for ( p ,  - p2). 
b. Test H,: ( p I  - p2) = 0 against Ha: (pl - p2) # 0. 
Use a = .01. 
Sample 1 
Sample 2 
............................................. 
n1 = 135 
n, = 148 
- 
- 
X I  = 12.2 
x2 = 8.3 
sf = 2.1 
s; = 3.0 
c. What sample sizes would be required if you wish to 
estimate (p1 - p2) to within .2 with 90% confi- 
dence? Assume that n, = n2. 
7.92 List the assumptions necessary for each of the follow- 
ing inferential techniques: 
a. Large-sample inferences about the difference 
( p ,  - p2) bctween population means using a two- 
sample z statistic 
b. Small-sample inferences about ( p ,  - p2) using an in- 
dependent samples design and a two-sample t statistic 
c. Small-sample inferences about ( p ,  - p,) using a 
paired difference design and a single-sample t sta- 
tistic to analyze the differences 
*d. Inferences about the ratio a:/u; of two population 
variances using an F-test. 
7.93 A random sample of five pairs of observations were 
selected, one of each pair from a population with 
mean p,, the other from a population with mean pp 
The data are shown in the accompanying table. 
Value from 
Value from 
Pair 
Population 1 
Population 2 
a. Test the null hypothesis H,: p, = 0 against 
Ha: p, # 0, where p,, 
= pl - p 2  Use a = .05. 
b. Form a 95% confidence interval for p,. 
c. When are the procedures you used in parts a and b 
valid? 
"7.94 Two independent random samples produced the mea- 
surements listed in the table on page 421. Do the data 
provide sufficient evidence to conclude that there is a 

S u p p l e m e n t a r y  E x e r c i s e s  
421 
difference between the locations of the probability distri- 
butions for the sampled populations? Test using a = .05. 
Sample from Population 1 
Sample from Population 2 
................................................. 
................................................. 
1.2 
1 .O 
1.5 
1.9 
1.9 
1.8 
1.3 
2.7 
.7 
1.1 
2.9 
3.5 
2.5 
'7.95 A random sample of nine pairs of observations are 
recorded on two variables, x and y. The data are shown 
in the following table. 
Pair 
x 
y 
Pair 
x 
y 
................................... 
................................... 
1 
19 
12 
6 
29 
10 
2 
27 
19 
7 
16 
16 
3 
15 
7 
8 
22 
10 
4 
35 
25 
9 
16 
18 
5 
13 
11 
Do the data provide sufficient evidence to indicate 
that the probability distribution for x is shifted to the 
right of that for y? Test using a = .05. 
7.96 Independent random samples are utilized to compare 
four treatment means.The data are shown in the table 
below. 
Treatment 1 
Treatment 2 
Treatment 3 
Treatment 4 
.................................................................................................................... 
8 
6 
9 
12 
10 
9 
10 
13 
9 
8 
8 
10 
10 
8 
11 
11 
11 
7 
12 
11 
a. Given that SST = 36.95 and SS(Tota1) = 62.55, 
complete an ANOVA table for this experiment. 
b. Is there evidence that the treatment means differ? 
Use a = .lo. 
c. Place a 90% confidence interval on the mean re- 
sponse for treatment 4. 
Applying the Concepts 
,797 The Journal of Testing and Evaluation (July 1992) pub- 
lished an investigation of the mean compression 
strength of corrugated fiberboard shipping containers. 
Comparisons were made for boxes of five different 
sizes: A, B, C, D, and E.Twenty identical boxes of each 
size were independently selected and tested, and the 
peak compression strength (pounds) recorded for each 
box. Thc figure below shows the sample means for the 
five box types as well as the variation around each 
sample mean. 
a. Explain why the data is collected as an independent 
samples design. 
b. Refer to box types B and D. Based on the graph, 
does it appear that the mean compressive strengths 
of thesc two box types are significantly different? 
Explain. 
c. Based on the graph, does it appear that the mean 
compressive strengths of all five box types are sig- 
nificantly different? Explain. 
A 
B 
C 
D 
E 
Box type 
Source: Singh, S. F! , et al. "Compression of single-wall 
corrugated shipping containers using fixed and floating test 
platens." Journal of Testing and Evaluation, Vol. 20, No. 4, July 
1092, p. 319 (Figure 3). Copyright American Society for 
Testing and Materials. Reprinted with permission. 
7.98 Refer to the Marine Technology (Jan. 1995) study of 
major oil spills from tankers and carriers, Exercise 2.10 
(p. 34).The data for the 50 recent spills are saved in the 
file 0ILSPILL.DAT. 
a. Construct a 90% confidence interval for the differ- 
ence between the mean spillage amount of acci- 
dents caused by collision and the mean spillage 
amount of accidents caused by firelexplosion. In- 
terpret the result. 
b. Conduct a test of hypothesis to compare the mean 
spillage amount of accidents caused by grounding to 
the corresponding mean of accidents caused by hull 
failure. Usc a = .05. 
c. Refer to parts a and b. State any assumptions re- 
quired for the inferences derived from the analyses to 
be valid. Are these assumptions reasonably satisfied? 

422 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
*d. Conduct a test of hypothesis to compare the variation 
in spillage amounts for accidents caused by collision 
and accidents caused by grounding. Use a = .02. 
7.99 A manufacturer of automobile shock absorbers was 
interested in comparing the durability of its shocks 
with that of the shocks produced by its biggest com- 
petitor. To makc the comparison, one of the manu- 
facturer's and one of the competitor's shocks were 
randomly selected and installed on the rear wheels 
of each of six cars. Alter the cars had been driven 
20,000 miles, the strength of each test shock was 
measured, coded, and recorded. Results of the exam- 
ination are shown in the table. 
Manufacturer's 
competitor's 
Car Number 
Shock 
Shock 
An EXCEL printout of an analysis of the data is pro- 
vided below. 
a. Do the data present sufficient evidence to conclude 
that there is a difference in the mean strength of 
the two types of shocks after 20,000 miles of use? 
Use a = .05. 
b. Find the approximate observed significance level 
for the test, and interpret its value. 
c. What assumptions are necessary to apply a paired 
difference analysis to the data? 
d. Construct a 95% confidence interval for (p, - p,). 
Interpret the confidence interval. 
EXCEL Output for Exercise 7.99 
*e. Analyze the data using a nonparametric test. Inter- 
pret the results. 
7.100 Suppose the data in Exercise 7.99 are based on inde- 
pendent random samples. 
a. Do the data provide sufficient evidence to indicate 
a difference between the mean strengths for the two 
types of shocks? Use a = .05. 
b. Construct a 95% confidence interval for (p, - p2). 
Interpret your result. 
c. Compare the confidence intervals you obtained in 
Exercise 7.99 and in part b of this exercise. Which is 
wider? To what do you attribute the difference in 
width? Assuming in each case that the appropriate 
assumptions are satisfied, which interval provides you 
with more information about (p, - p2)? Explain. 
d. Are the results of an unpaired analysis valid if the 
data come from a paired experiment? 
7.101 Nontraditional university students, generally defined 
as those at least 25 years old, comprise an increasingly 
large proportion of undergraduate student bodies at 
most universities. A study reported in the College 
Student Journal (Dec. 1992) compared traditional and 
nontraditional students on a number of factors, includ- 
ing grade point average (GPA). The table below sum- 
marizes the information from the sample. 
G PA 
Traditional Students 
Nontraditional Students 
a. What are the appropriate null and alternative hy- 
potheses if we want to test whether the mean GPAs 
of traditional and nontraditional students differ'? 
b. Conduct the test using a = .01, and interpret the 
result. 
t-Test: Paired Two Sample for Means 
t stat 
P(T<=t) one-tail 
t Critical one-tail 
P(T<=~)~wo-tail 
t Critical two-tail 
ComShock 
10.3 
3.304 
6 
Mean 
Variance 
Observations 
Pearson Correlation 
Hypothesized Mean Difference 
df 
7.67868896 
0.000298532 
2.015049176 
0.000597064 
2.570577635 
Mf gShock 
10.71666667 
3.069666667 
6 
0.997902853 
0 
5 

c What assumptions are necessary to ensure the va- 
lidity of the test'? 
.:7.102 An accounting firm that specializes in auditing the 
financial records of large corporations is interested 
in evaluating the appropriateness of the fees it 
charges for its services. As part of its evaluation, it 
wants to compare the costs it incurs in auditing cor- 
porations of different sizes. The accounting firm 
decided to measure the size of its client corporations 
in terms of their yearly sales.Accordingly, its popula- 
tion of client corporations was divided into three 
subpopulations: 
A: Those with sales over $250 million 
B: Those with sales between $100 million and 
$250 million 
C: Those with sales under $100 million 
The firm chose random samples of 10 corporations 
from cach of the subpopulations and determined the 
costs (in thousands of dollars), given in the accompa- 
nying table, from its records. 
a. ~&struct a dot plot for the sample data, using 
different types of dots for each of the three sam- 
ples. Indicate the location of each of the sample 
means. Based on the information reflected in 
your dot plot, do you believe that a significant 
difference exists among the subpopulation 
means? Explain. 
b. SAS was used to conduct the analysis of variance 
calculations, resulting in the printout shown below. 
Conduct a test to determine whether the three 
classes of firms have different mean costs incurred 
in audits. Use a = .05. 
c. What is the observed significance level for the test 
in part b? Interpret it. 
d. What assumptions must be met in order to ensure 
the validity of the inferences you made in parts b 
and c? 
SAS Output for Exercise 7.1 02 
S u p p l e m e n t a r y  Exercises 
7.103 One theory regarding the mobility of college and uni- 
versity faculty members is that those who publish the 
most scholarly articles are also the most mobile. The 
logic behind this theory is that good researchers who 
publish frequently receive more job offers and are 
therefore more likely to move from one university to 
another. The Academy of Management Journal (Vol. 
25, 1982) examined this relationship for persons 
employed in industry. Using the personnel records of a 
large national oil company, the researchers obtained 
thc early career performance records for 529 of the 
company's employees. Of these, 174 were classified as 
stuyers, those who stayed with the company; the other 
355, who left the company at varying points during a 
15-year period, were classified as leavers. Summary sta- 
tistics on three variables-initial performance, rate of 
career advancement (number of promotions per year), 
and final performance appraisals-for 
both stayers 
and leavers are shown in the table on p. 424. For each 
variable, compare the means of stayers and leavers 
using an appropriate statistical method. Interpret the 
results. 
7.104 A study in the Journal of Psychology and Marketing 
(Jan. 1992) investigates the degree to which American 
General Linear Models Procedure 
Dependent Variable: COST 
Source 
Sum of 
Mean 
DF 
Squares 
Square 
F Value 
Pr > F 
Model 
2 318861.667 
159430.833 
8.44 
0.0014 
Error 
27 510163.000 
18894.926 
Corrected Total 
29 829024.667 
R-Square 
C.V. 
RootMSE 
COST Mean 
0.384623 
72.220043 
137.459 
190.333333 
Source 
DF 
Type 1 SS Mean Square 
F Value 
Pr > F 
TREATMNT 
2 
318861.67 
159430.83 
8.44 
0.0014 

I 
424 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  M e a n s  
Summary Statistics for Exercise 7.1 03 
.............................................................................................................................................. 
Stayers (n, = 174) 
Leavers (n, = 335) 
....................................................................... 
Variable 
- 
- 
X l  
S l  
x z  
s 2  
.............................................................................................................................................. 
Initial performance 
3.51 
.51 
3.24 
.52 
Rate of career advancement 
.43 
.20 
.31 
.31 
Final performance appraisal 
3.78 
.62 
3.15 
.68 
consumers are concerned about product tampering. 
Large random samples of male and female consumers 
I 
were asked to rate their concern about product tam- 
pering on a scale of 1 (little or no concern) to 9 (very 
concerned). 
a. What are the appropriate null and alternative hy- 
potheses to determine whether a difference exists 
111 1 
in the mean level of concern about product tam- 
pering between men and women? Define any 
symbols you use. 
b. The statistics reported include those shown in the 
MINITAB printout below. Interpret thcse results. 
c. What assumptions are necessary to ensure the va- 
lidity of this test? 
7.105 Management training programs are often instituted to 
teach supervisory sk~lls and thereby increa~e produc- 
tivity. Suppose a company psychologist administers a 
kd 
SUPEXAM.DAT 
............................................................... 
Supervisor 
Pre-Test 
Post-Test 
.......................... 
.................... 
1 
63 
78 
2 
- 
93 
92 
3 
84 
91 
4 
72 
80 
5 
65 
69 
6 
72 
85 
7 
9 1 
99 
8 
84 
82 
9 
71 
81 
10 
80 
87 
MlNlTAB Output for Exercise 7.104 
set of examinations to each of 10 supervisors before 
such a training program begins and then administers 
similar examinations at the end of the program. The 
examinations are designed to measure supervisor! 
skills, with higher scores indicating increased skill.Thr 
results of the tests are shown in the table at left. 
a. Do the data provide evidence that the training pro- 
gram is effective in increasing supervisory skills, as 
measured by the examination scores? Use a = .lo. 
b. Find and interpret the approximate p-value for 
the test on the MINITAB printout below. 
7.106 Some power plants are located near rivers or oceans so 
that the available water can be used for cooling the 
condensers. Suppose that, as part of an environmental 
impact study, a power company wants to estimate the 
difference in mean water temperature between the dis- 
charge of its plant and the offshore waters. How many 
sample measurements must be taken at each site in 
order to estimate the true difference between means to 
within .2"C with 95% confidence? Assume that the 
range in readings will be about 4•‹C at each site and the 
j 
same number of readings will be taken at each site. 
*7.107 A hotel had a problem with people reserving rooms 
for a weekend and then not honoring their reserva- 
tions (no-shows). As a result, the hotel developed a 
new reservation and deposit plan that it hoped 
would reduce the number of no-shows. One year 
after the policy was initiated, management evaluated 
its effect in comparison with the old policy. Use a 
nonparametric test to compare the records given in 
the table (p. 425) on the number of no-shows for the 
TWOSAMPLE T FOR MSCORE VS FSCORE 
N 
MEAN 
STDEV 
SE MEAN 
MSCORE 200 
3.209 
2.33 
0.165 
FSCORE 200 
3.923 
2.94 
0.208 
TTEST MU MSCORE = MU FSCORE (VS NE): T= -2.69 P=0.0072 DF=398 
MlNlTAB Output for Exercise 7.1 05 
TEST OF MU = 0.000 VS MU N.E. 0.000 
N 
MEAN 
STDEV 
SE MEAN 
T 
P VALUE 
PRE-POST 
10 
-6.900 
5.425 
1.716 
-4.02 
0.0030 

10 nonholiday weekends preceding the institution of 
the new policy and the 10 nonholiday weekends pre- 
ceding the evaluation time. H a s  the situation 
improved under the new policy? Test at a = .05. 
Before 
After 
..................... 
................ 
10 
11 
4 
4 
5 
8
3
2
 
3 
9 
8 
5 
6 
6
5
7
 
7 
5 
6 
1 
7.108 Does the time of day during which one works affect 
job satisfaction? A study in t h e  J o ~ ~ r n u l  
o f  
Occupational Psychology (Sept. 1991) examined dif- 
ferences in job satisfaction between day-shift and 
night-shift nurses. Nurses' satisfaction with thcir hours 
of work, free time away from work, and breaks during 
work were measured. The following table shows the 
mean scores for each measure of job satisfaction 
(higher scorcs indicate greater satisfaction), along 
with thc observed significance level comparing the 
means for the day-shift and night-shift samples: 
................................................................................................................. 
Mean Satisfaction 
...................................................................... 
Day Shift 
Night Shift 
p-Value 
................................................................................................................. 
Satisfaction with: 
Hours of work 
3.91 
3.56 
313 
Free time 
2.55 
1.72 
,047 
Breaks 
2.53 
3.75 
,0073 
a. Specify the null and alternative hypotheses if we wish 
to test whether a difference in job satisfaction exists 
between day-shift and night-shift nurses on each of 
the three measures. Define any symbols you use. 
b. Interpret thep-value for each of the tests. (Each of 
the p-values in the table is two-tailed.) 
C. Assume that each of the tests is based on small 
samples of nurses from each group. What assump- 
tions are necessary for the tests to be valid? 
7.109 How does gender affect the type of advcrtising that 
proves to be most efkctive? An article in thc Journal of 
Advertising Reseurch (MayiJune 1990) makes reference 
to numerous studies that conclude males tend to be 
more competitive with others than with themselves. To 
apply this conclusion to advcrtising, the author creates 
two ads promoting a new brand of soft drink: 
Ad I: Four men are shown competing in racquetball 
Ad 2:One man is shown competing against himself in 
racquetball 
S u p p l e m e n t a r y  E x e r c i s e s  
425 
The author hypothesized that the first ad will be more 
effective when shown to males.To test this hypothesis, 
43 males were shown both ads and asked to measure 
their attitude toward the advertisement (Aad), their 
attitude toward the brand of soft drink (Ab), and their 
intention to purchase the soft drink (Intention). Each 
variable was measured using a seven-point scale, with 
higher scores indicating a more favorable attitude.The 
results are shown in the table below. 
Sample Means 
Aad 
Ab 
Intention 
.................................................................................................................... 
Ad 1 
4.465 
3.311 
4.366 
Ad 2 
4.150 
2.902 
3.813 
Level of significance 
p = ,091 
p = ,032 
p = ,050 
a. What are the appropriate null and alternative hy- 
potheses to test the author's research hypothesis? 
Define any symbols you use. 
b. Based on the information provided about this ex- 
periment, do you thmk this is an independent 
samples experiment or a paired difference exper- 
iment? Explain. 
c. Interpret the p-value for each test. 
d. What assumptions are necessary for the validity 
of the tests? 
"7.110 A state highway patrol was interested in knowing 
whether frequent patrolling of highways substan- 
tially rcduces the number ot speeders. Two similar 
interstate highways were selected for the study- 
one heavily patrolled and the other only occasion- 
ally patrolled. After 1 month, random samples of 
100 cars were chosen on each highway, and the 
number of cars exceeding the speed limit was 
recorded. This process was repeated on five ran- 
domly selected days. The data arc shown in the fol- 
lowing table. 
Highway 1 
Highway 2 
Day 
(heavily patrolled) 
(occasionally patrolled) 
Use a nonparametric procedure t o  determine 
whether the heavily patrolled highway tends to have 
fewer speeders per 100 cars than the occasionally 
patrolled highway. Test using cu = .05. 

426 
CHAPTER 7 
C o m p a r i n g  P o p u l a t i o n  Means 
Real-World Case The Kentuckv Milk Case- 
(A Case Covering Chapters 5-7) 
I 
n The Kentucky Milk Case-Part 
I, you used graphical 
and numerical descriptive statistics to investigate bid col- 
lusion in the Kentucky school milk market.This case ex- 
pands your previous analyses, incorporating inferential 
statistical methodology. The three areas of your focus are 
described below. (See page 114 for the file layout of 
MILK.DAT data.) Again, you should prepare a profession- 
al document which presents the results of the analyses and 
any implications regarding collusionary practices in the tri- 
county Kentucky milk market. 
1. Incumbency rates. Recall from Part I that market alloca- 
tion (where the same dairy controls the same school dis- 
tricts year after year) is a common form of collusive 
behavior in bidrigging conspiracies. Market allocation 
is typically gauged by the incumbency rate for a market 
in a given school year-defined 
as the percentage of 
school districts that are won by the same milk vendor 
who won the previous year. Past experience with milk 
bids in a competitive market reveals that a "normal" in- 
cumbency rate is about .7. That is, 70% of the school 
districts are expected to purchase their milk from the 
same vendor who supplied the milk the previous year. In 
the 13-district tri-county Kentucky market, 13 vendor 
transitions potentially exist each year. Over the 
1985-1988 period (when bid collusion was alleged to 
Part II 
have occurred), there are 52 potential vendor transi- 
tions. Based on the actual number of vendor transitions 
that occurred each year and over the 1985-1988 period, 
make an inference regarding bid collusion. 
2. Bid price dispersion. Recall that in competitive sealed- 
bid markets, more dispersion or variability among the 
bids is observed than in collusive markets. (This is due to 
conspiring vendors sharing information about their 
bids.) Consequently, if collusion exists, the variation in 
bid prices in the tri-county market should be signifi- 
cantly smaller than the corresponding variation in the 
surrounding market. For each milk product, conduct an 
analysis to compare the bid price variances of the two 
markets each year. Make the appropriate inferences. 
3. Average winning bid price. According to collusion theo- 
rists, the mean winning bid price in the "rigged" market 
will exceed the mean winning bid price in the competi- 
tive market for each year in which collusion occurs. In 
addition, the difference between the competitive aver- 
age and the "rigged" average tends to grow over time 
when collusionary tactics are employed over several 
consecutive years. For each milk product, conduct an 
analysis to compare the winning bid price means of the 
tri-county and surrounding markets each year. Make the 
appropriate inferences. 

C O M P A R I N G  P O P U L A T I O N  
P R O P O R T I O N S  
C O N T E N T S  
............................................................. 
8.1 
Comparing TWO Population Proportions: Independent Sampling 
8.2 
Determining the Sample Size 
8.3 
Comparing Population Proportions: Multinomial Experiment 
8.4 
Contingency Table Analysis 
S T A T I S T I C S  
I
N
 A
C
T
I
O
N
 
..................................................................................................................................................... 
Ethics in Computer Technology and Use 
I Where W e ' v e  B e e n  
I 
C 
hapter 7 presented both parametric and non- 
parametric methods for comparing two or more 
population means. 
w ,  
*"" 
W h e r e  W e ' r e  G o i n g  
I 
n this chapter, we will consider a problem of com- 
parable importance-comparing 
two or more 
population proportions. The need to compare popu- 
lation proportions arises because many business and 
social experiments involve questioning people and 
classifying their responses. We will learn how to 
determine whether the proportion of consumers 
favoring product A differs from the proportion of 
consumers favoring product B, and we will learn how 
to estimate the difference with a confidence interval. 

428 
CHAPTER 8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
Many experiments are conducted in business and the social sciences to com- 
pare two or more proportions. (Those conducted to sample the opinions of people 
are called sample surveys.) For example, a state government might wish to estimate 
the difference between the proportions of people in two regions of the state who 
would qualify for a new welfare program. Or, after an innovative process change, an 
engineer might wish to determine whether the proportion of defective items pro- 
duced by a manufacturing process was less than the proportion of defectives pro- 
duced before the change. In Section 8.1 we show you how to test hypotheses about 
the difference between two population proportions based on indcpendent random 
sampling. We will also show how to find a confidence interval for the difference. 
Then, in Sections 8.3 and 8.4 we will compare more than two population proportions. 
COMPARING TWO POPULATION PROPORTIONS: 
INDEPENDENT SAMPLING 
Suppose a manufacturer of camper vans wants to compare the potential market 
for its products in the northeastern United States to the market in the southeast- 
ern United States. Such a comparison would help the manufacturer decide where 
to concentrate sales efforts. Using telephone directories, the company randomly 
chooses 1,000 households in the northeast (NE) and 1,000 households in the 
southeast (SE) and determines whether each household plans to buy a camper 
within the next five years.The objective is to use this sample information to make 
an inference about the difference (p, - p2) between the proportion p, of all 
households in the NE and the proportion p2 of all households in the SE that plan 
to purchase a camper within five years. 
The two samples represent independent binomial experiments. (See Section 4.3 
for the characteristics of binomial experiments.) The binomial random variables are 
the numbers x, and x2 of the 1,000 sampled households in each area that indicate 
they will purchase a camper within five years. The results are summarized below. 
We can now calculate the sample proportions j?, and i32 of the households in the 
NE and SE, respectively, that are prospective buyers: 
The difference between the sample proportions (6, - p2) makes an intuitively ap- 
pealing point estimator of the difference between the population parameters 
( p ,  - p2). For our example, the estimate is 
To judge the reliability of the estimator (@, - p,), we must observe its per- 
formance in repeated sampling from the two populations. That is, we need to 
know the sampling distribution of (PI - P,). The properties of the sampling dis- 

SECTION 8.1 
C o m p a r i n g  Two Population P r o p o r t i o n s :  I n d e p e n d e n t  Sampling 
429 
I 
tribution are given in the next box. Remember that PI and P2 can be viewed as 
means of the number of successes per trial in the respective samples, so the Cen- 
tral Limit Theorem applies when the sample sizes are large. 
Since the distribution of (@, - @,) in repeated sampling is approximately 
normal, we can use the z statistic to derive confidence intervals for (p, - p,) or to 
test a hypothesis about ( p ,  - p,). 
For the camper example, a 95% confidence interval for the difference 
( P I  - PZ) is 
Thus, (PI - 34 is an 
2. The standard deviation of the sampling distribution of (p, - P,) is 
3. If the sample sizes nl and n2 are large (see Section 5.3 for a guideline), 
tely normal. 
The quantities p,q, and pzq, must be estimated in order to complete the cal- 
culation of the standard deviation a(pl-,-2) 
and hence the calculation of the confi- 
dence interval. In Section 5.3 we showed that the value of pq is relatively 
insensitive to the value chosen to approximate p. Therefore, PIGl and F22j2 will pro- 
vide satisfactory estimates to approximate plql and p2q2, respectively. Then 
1 
Substituting the sample quantities yields 
I 
and we will approximate the 95% confidence interval by 
or .018 f .016. Thus, we are 95% confident that the interval from .002 to .034 con- 
tains ( p ,  - p,). 
We infer that there are between .2% and 3.4% more households in the north- 
east than in the southeast that plan to purchase campers in the next five years. 

430 
CHAPTER 8 C o m p a r i n g  Population P r o p o r t i o n s  
The general form of a confidence interval for the difference (pl - pZ) be- 
tween population proportions is given in the following box. 
The z statistic, 
is used to test the null hypothesis that ( p ,  - p2) equals some specified difference, 
say Do. For the special case where Do = 0, that is, where we want to test the null 
hypothesis H,: (pl - p,) = 0 (or, equivalently, H,: p, = p,), the best estimate of 
p1 = p, = p is obtained by dividing the total number of successes (x, + x2) for 
the two samples by the total number of observations (nl + n,); that is 
The second equation shows that 2 is a weighted average of 
and F,, with the 
larger sample receiving more weight. If the sample sizes are equal, then 2 is a sim- 
ple average of the two sample proportions of successes. 
We now substitute the weighted average E for both p, and p2 in the formu- 
la for the standard deviation of (PI - p2): 
The test is summarized in the next box. 
repairs (morethan $500) within two years of their purchase. A sample of 400 two-year 
owners of model 1 is contacted, and a sample of 500 two-year owners of model 2 is 
contacted.The numbers x, and x, of owners who report that their cars needed major 
repairs within the first two years are 53 and 78, respective1y.Test the null hypothesis 
that no difference exists between the proportions in populations 1 and 2 needing 
major repairs against the alternative that a difference does exist. Use a = .lo. 
S o I u t i o n If we define p, and p2 as the true proportions of model 1 and model 2 owners. 
respectively, whose cars need major repairs within two years, the elements of the 
test are 

SECTION 8.1 
Comparing Two Population P r o p o r t i o n s :  I n d e p e n d e n t  Sampling 
431 
Test statistic: z = (PI - P2) - 0 
uG -a 
Rejection region (a = .lo): lzl > z ~ , ~  
= 2.0~ 
= 1.645 (see Figure 8.1) 
FIGURE 8.1 
Rejection region for Example 8.1 
z 
Observed 
z = -.99 
We now calculate the sample proportions of owners who need major car repairs, 
*The test can be adapted to test for a difference Do + 0. Because most applications call for a 
comparison of p, and p,, implying Do = 0, we will confine our attention to this case. 

432 
CHAPTER 8 C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
Then 
where 
Note that 13 is a weighted average of 2, and F2, with more weight given to the larg- 
er sample of model 2 owners. 
Thus, the computed value of the test statistic is 
The samples provide insufficient evidence at cr = .10 to detect a difference 
between the proportions of the two models that need repairs within two years. 
Even though 2.35% more sampled owners of model 2 found they needed major 
repairs, this difference is less than 1 standard deviation ( z  = -.99) from the hy- 
pothesized zero difference between the true proportions. 
S o I u t i o n The observed value of z for this two-tailed test was z = -.99. Therefore, the 
observed significance level is 
p-value = P(lz1 > .99) = P(z < -.99 or z > .99) 
This probability is equal to the shaded area shown in Figure 8.2. The area corre- 
sponding to z = .99 is given in Table IV of Appendix B as .3389. Therefore, the 
observed significance level for the test, the sum of the two shaded tail areas under 
the standard normal curve, is 
p-value = 2(.5 - .3389) = 2(.1611) = .3222 
F I G U R E  8.2 
The observed significance level for the test of 
,1611 
Example 8.1 
.A
-.99 
0 
.99 
The probability of observing a z as large as .99 or less than -.99 if in fact p, = pz 
is .3222. This large p-value indicates that there is little or no evidence of a differ- 
ence between p, andp,. 
+ 

SECTION 8.1 
c o m p a r i n g  T w o  P o p u l a t i o n  P r o p o r t i o n s :  I n d e p e n d e n t  S a m p l i n g  
433 
Learning the Mechanics 
8.1 Explain why the Central Limit Theorem is important 
in finding an approximate distribution for (j3, - 13,). 
8.2 In each case, determine whether the sample sizes are 
large enough to conclude that the sampllng distribution 
of (PI - F2) is approximately normal. 
a. n1 = 12, n, = 14, 6, = .42, 13, = .57 
b. n, = 12,n2 = 14. p, = .92,j3, = .86 
c. n, = n2 = 30, j3, = .70, 6, = .73 
d. n, = 100, n, = 250, p, = .93, 5, = .97 
e. n1 = 125, n, = 200, j3, = .08, p2 = .12 
8.3 For each of the following values of a, find the values of z 
for which HI,: ( p ,  - p,) = 0 would bc rejected in favor 
of Ha: (pl - p2) < 0. 
a. a = .Ol b. a = ,025 
c. a = .05 d. a = .lO 
8.4 Independent random samples, each containing 800 
observations, were selected from two binomial popula- 
tions. The samples from populations 1 and 2 produced 
320 and 400 successes, respectively. 
a. Test HI): ( p ,  - p2) = 0 against Ha: ( p ,  - p2) # 0. 
Use cu = .05. 
b. Test H,,: ( p l  - p,) = 0 against Ha: ( p ,  - p,) Z 0. 
Use cu = .01. 
c. Test HI): ( p ,  - p2) = 0 against Ha: ( p ,  - p,) < 0. 
Useu = .01. 
d. Form a 90% confidence interval for ( p ,  - p,). 
8.5 Construct a 95% confidence interval for ( p ,  - p2) in 
each of the following situations: 
a. n, = 400, F1 = .65: n2 = 400, E2 = .58 
b. n, = 180, F, = .31; n, = 250, j3, = .25 
C. nl = 100, PI = .46; n, = 120, p, = .61 
8.6 Sketch the sampling distribution of (j3, - i3,) based on 
independent random samples of n ,  = 100 and n, = 200 
observations from two binomial populations with suc- 
cessprobabilities j3, = .1 and j3, = .5, respectively. 
8.7 Random samples of size n1 = 55 and n2 = 65 were 
drawn from populations 1 and 2, respectively. The sam- 
ples yielded p, = .7 and ,E, 
= .6. Test HI< ( p ,  - p,) = 0 
against H,: ( p l  - p,) > 0 using a = .05. 
Applying the Concepts 
8.8 In evaluating the usefulness and validity of a question- 
naire, researchers often pretest the questionnaire on dif- 
ferent independently selected samplcs of respondcnts. 
Knowledge of the differences and similarities of the 
samples and their respective populations is important 
for interpreting the questionnaire's validity. Educational 
and Psychological Measurement (Feb. 1998) reported 
on a newly developed questionnaire for measuring the 
career success expectations of employees. The instru- 
ment was tested on the two independent samples 
described in the table. 
Managers 
Part-Time 
and Professionals 
MBA Students 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Sample size 
162 
109 
Gcnder (% males) 
95.0 
68.9 
Marital status (% married) 
91.2 
53.4 
- 
Source: Stephens, Gregory K., Szajna. Bernadette, and Broome, Kirk M., 
"The Career Success Expectation Scale: An exploratory and 
Confirmatory Factor Analysis," Erlucarional and Psychological 
Measurement, Vol. 58,No. 1,Feb. 1998,pp. 129-141. 
a. Does the population of managers and professionals 
from which the sample was drawn consist of more 
males than the part-time MBA population does? 
Conduct thc appropriate test using cw = .05. 
b. Describe any assumptions you made in conducting 
the test of part a and why you made them. 
c. Does the population of managers and professionals 
consist of more married individuals than the part-time 
MBA population does? Conduct the appropriate hy- 
pothesis test using a = .Ol. 
d. What assumptions must hold for the test of part c to 
be valid? 
8.9 Operation Crossroads was a 1946 military exercise in 
which atomic bombs were detonated over empty target 
ships in the Pacific 0cean.The Navy assigned sailors to 
wash down the test ships immediately after the atomic 
blasts. Thc National Academy of Science reported "that 
the overall death rate among operation-crossroads 
sailors was 4.6% higher than among a comparable 
group of sailors.. . . However, this increase was not sta- 
tistically significant." (Tampa Tribune, Oct. 30,1996.) 
a. Describe the parameter of interest in the National 
Academy of Science study. 
b. Interpret the statement: "This increase was not sta- 
tistically significant." 
8.10 A University of South Florida biologist conducted an 
experiment to determine whcther increased levels of 
carbon dioxide kill leaf-eating moths (USF Magazine, 
Winter 1999). Moth larvae were placed in open contain- 
ers filled with oak leaves. Half the containers had normal 
carbon dioxide levels while the other half had double 
the normal level of carbon dioxide. Ten pcrcent of the 
larvae in the containers with high carbonedioxide levels 
died, compared to five percent in the containers with 
normal levels. Assume that 80 moth larvae were placed, 
at random, in each of the two types of containers. Do the 
experimental result4 demonstrate that an increased level 
of carbon dioxide is effective in killing a higher percent- 
age of leaf-eating moth larvae? Test using a = .01. 

434 
CHAPTER 
8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
-- 
- - -  
- 
8.11 Working Women (June 1999) published the results of a 
1999 Gallup poll that found that 92% of adult Americans 
would vote for a woman president. In 1975, a similar poll 
found that only 73% would vote for a woman. 
a. Let pI9,, and p,,,, represent the population parame- 
ters of interest for this study. In the words of the 
problem, define these parameters. 
b. Assume the sample sizes were 2,000 in 1999 and 
1,500 in 1975. Are these sample sizes large enough 
ton conclude that the sampling distribution of 
(pls9y - ~~97,) 
is approximately normally distrib- 
uted? Justify your answer. 
c. Construct a 90% confidence interval for 
( P , ~ ~ ,  
- pIg7,). Interpret your confidence interval in 
the context of the problem. 
d. Rework part b under the assumption that the sample 
sizes for 1999 and 1975 are 20 and 50, respectively. 
8.12 Should marketers use ads that appeal to children to sell 
adult products? One controversial advertisement cam- 
paign was Camel cigarettes' use of the cartoon charac- 
ter "Joe Camel" as its brand symbol. (The Federal Trade 
Commission eventually banned ads featuring Joe Camel 
because they supposedly encouraged young people to 
:. 
smoke.) Lucy L. Henke, a marketing professor at the 
University of New Hampshire, assessed young chil- 
dren's abilities to recognize cigarette brand advertising 
symbols. She found that 15 out of 28 children under the 
age of 6, and 46 out of 55 children age 6 and over rec- 
ognized Joe Camel, the brand symbol of Camel ciga- 
rettes (Journal of Advertising, Winter 1995). 
a. Use a 95% confidence interval to estimate the pro- 
portion of all children that recognize Joe Camel. In- 
terpret the interval. 
b. Do the data indicate that recognition of Joe Camel 
increases with age? Test using a = .05. 
8.13 Price scanners are widely used in U.S. supermarkets. 
While they are fast and easy to use, they also make mis- 
takes. Over the years, various consumer advocacy 
groups have complained that scanners routinely gouge 
the customer by overcharging. A recent Federal Trade 
Commission study found that supermarket scanners 
erred 3.47% of the time and department store scanners 
erred 9.15% of thc time ("Scan Errors Help Public," 
Newark Star-Ledger, Oct. 23,1996). 
a. Assume the above error rates were determined from 
merchandise samples of size 800 and 900, respective- 
ly. Are these sample sizes large enough to apply the 
methods of this section to estimate the difference in 
the error rates? Justify your answer. 
b. Use a 98% confidence interval to estimate the dif- 
ference in the error rates. Interpret your result. 
c. What assumptions must hold to ensure the validity 
of the confidence interval of part b? 
8.14 Do you have an insatiable craving for chocolate or 
some other food? Since many North Americans appar- 
ently do, psychologists are designing scientific studies 
to examine the phenomenon. According to the New York 
Times (Feb. 22,1995), one of the largest studies of food 
cravings involved a survey of 1,000 McMaster University 
(Canada) students. The survey revealed that 97% of the 
women in the study acknowledged specific food crav- 
ings while only 67% of the men did. Assume that 600 of 
the respondents were women and 400 were men. 
a. Is there sufficient evidence to claim that the true 
proportion of women who acknowledge having food 
cravings exceeds the corresponding proportion of 
men? Test using a = .01. 
b. Why is it dangerous to conclude from the study that 
women have a higher incidence of food cravings than 
men? 
8.15 Industrial Marketing Management (Vol. 25,1996) puh- 
lished a study that examined the demographics, deci- 
sion-making roles, and time demands of product 
managers. Independent samples of n, = 93 con- 
sumer/commercial product managers and n2 = 212 
industrial product managers took part in the study. In 
the consumer/commercial group, 40% of the product 
managers are 40 years of age or older; in the industrial 
group, 54% are 40 or more years old. Make an infer- 
ence about the difference between the true proportions 
of consumer/commercial and industrial product man- 
agers who are at least 40 years old. Justify your choice 
of method (confidence interval or hypothesis test) and 
a level. Do industrial product managers tend to be 
older than consumer/commercial product managers? 
8.16 Many female undergraduates at four-year colleges and 
universities switch from science, mathematics, and engi- 
neering (SME) majors into disciplines that are not sci- 
ence based, such as journalism, marketing, and 
sociology. When female undergraduates switch majors, 
are their reasons different from those of their male 
counterparts? This question was investigated in Science 
Education (July 1995). A sample of 335 juniorlsenior 
undergraduates-172 
females and 163 males-at 
two 
large research universities were identified as "switch- 
ers," that is, they left a declared SME major for a non- 
SME major. Each student listed one or more factors 
that contributed to their switching decision. 
a. Of the 172 females in the sample, 74 listed lack or 
loss of interest in SME (i.e., "turned off" by science) 
as a major factor, compared to 72 of the 163 males. 
Conduct a test (at a = .lo) to determine whether the 
proportion of female switchers who give "lack of in- 
terest in SME" as a major reason for switching dif- 
fers from the corresponding proportion of males. 
b. Thirty-three of the 172 females in the sample admit- 
ted they were discouraged or lost confidence due to 
low grades in SME during their early years, com- 
pared to 44 of 163 males. Construct a 90% confidence 
interval for the difference between the proportions of 
female and male switchers who lost confidence due 
to low grades in SME. Interpret the result. 

SECTION 8.2 
D e t e r m i n i n g  t h e  Sample Size 
435 
DETERMINING THE SAMPLE SIZE 
The sample sizes n1 and n, required to compare two population proportions can be 
found in a manner similar to the method described in Section 7.3 for comparing two 
population means. We will assume equal sized samples, i.e., nl = n2 = n, and then 
choose n so that (p^, - j?,) will differ from (p, - p,) by no more than a bound B 
with a specified probability. We will illustrate the procedure with an example. 
- 
El 
m
"
-
-
-
m
 
A production supervisor suspects that a difference exists between the proportions 
p, and p, of defective items produced by two different machines. Experience has 
shown that the proportion defective for each of the two machines is in the 
neighborhood of .03. If the supervisor wants to estimate the difference in the 
proportions to within .005 using a 95% confidence interval, how many items must 
be randomly sampled from the production of each machine? (Assume that the 
supervisor wants n, = n2 = n) 
S o I u t i o n In this sampling problem, B = .005, and for the specified level of reliability, 
z,,, = z,,,,~ = 1.96. Then, letting pl = p, = .03 and nl = n, = n, we find the 
required sample size per machine by solving the following equation for n: 
You can see that this may be a tedious sampling procedure. If the supervisor 
insists on estimating (p, - p,) correct to within .005 with 95% confidence, ap- 
proximately 9,000 items will have to be inspected for each machine. 
'"9 
From the calculations in Example 8.3, note that a(,-, 
-p^2) (and hence the so- 
lution, nl = n, = n) depends on the actual (but unknown) values of pl and p,. In 
fact, the required sample size n, = n2 = n is largest when p1 = p, = .5. There- 
fore, if you have no prior information on the approximate values of pl and p,, use 
p1 = p2 = .5 in the formula for a(,-, 
-,-2). 
If p1 and p, are in fact close to .5, then the 
values of n, and n, that you have calculated will be correct. If p, and p2 differ sub- 
stantially from .5, then your solutions for nl and n, will be larger than needed. 
Consequently, using p, = p2 = .5 when solving for nl and n, is a conservative 
procedure because the sample sizes nl and n, will be at least as large as (and 
probably larger than) needed. 
  he 
for determining sample sizes necessary for estimating 
J 
(pl - p2) for the case nl = n, is given in the following box. 
"*PEP- 

436 
CHAPTER 
8 
c o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
Determination of Sample Size for Estimating p, - p, 
To estimate (p, - p2) to within a given bound B with probability (1 - a), use 
the following formula to solve for equal sample sizes that will achieve the de- 
sired reliability: 
u will need to substitute estimates for the values of p, and p2 before solving 
or the sample size. These estimates might be based on prior samples, ob- 
ned from educated guesses or, most conservatively, specified as 
= p2 = .5. 
Learning the Mechanics 
8.17 Assuming that n1 = n,, find the sample sizes nceded to 
estimate ( p ,  - p2) for each of the following situations: 
a. Bound = .O1 with 99% confidence. Assume that 
p, = .4 and p, = .7. 
b. A 90% confidence interval of width .05. Assume 
there is no prior information available to obtain ap- 
proximate values of p1 and p, . 
C. Bound = .03 with 90% confidence. Assume that 
p, = .2 and p, = .3. 
Applying the Concepts 
8.18 A pollster wants to estimate the difference between the 
proportions of men and women who favor a particular 
national candidate using a 90% confidence interval of 
width .04. Suppose the pollstcr has no prior inforrna- 
tion about the proportions. If equal numbers of men 
and women are to be polled, how large should the 
sample size be? 
8.19 Today, nearly all cable companies carry at least one 
home shopping channel. Who uses these home shop- 
ping services? Are the shoppers primarily men or 
women? Suppose you want to estimate thc difference in 
the proportions of men and women who say they have 
used or expect to use televised home shopping using an 
80% confidence interval of width .06 or less. 
a. Approximately how many people should be included 
in your samples? 
b. Suppose you want to obtain individual estimates for 
the two proportions of interest. Will the sample size 
found in part a be large enough to provide estimates 
of each proportion correct to within .02 with proba- 
bility equal to .90? Justify your response. 
8.20 Rat damage creates a large financial loss in the produc- 
tion of sugarcane. One aspect of the problem that has 
been investigated by the U.S. Department of Agriculture 
concerns the optimal place to locatc rat poison. To be 
most effective in reducing rat damage, should the poison 
be located in the middle of the field or on the outer 
perimeter? One way to answer this question is to deter- 
mine where the greater amount of damage occurs. If 
damage is measured by the proportion of cane stalks 
that have bcen damaged by rats, how many stalks from 
each section of the field should be sampled in order to 
estimate the true difference between proportions of 
stalks damaged in the two sections to within .02 with 
probability .95? 
8.21 A manufacturer of large-screen televisions wants to 
compare with a competitor the proportions of its best 
sets that need repair within 1 year. If it is desired to 
estimate the difference between proportions to within 
.05 with 90% confidence, and if the manufacturer plans 
t o  sample twice as many buyers (n,) of its sets as 
buyers (n,) of the competitor's sets, how many buyers 
of each brand must be sampled? Assume that the pro- 
portion of sets that need repair will be about .2 for both 
brands. 
8.22 Refer to the Working Women (June 1999) comparison 
of the percentages of adult Americans in 1975 and 
1999 w h o  would vote f o r  a woman president. 
Exercise 8.11 (p. 434). Suppose you want to make a 
similar comparison for the years 2000 and 2001. How 
many adults should be sampled each year to estimate 
the difference in percentages to within 3% with 90% 
confidence? Assume equal sample sizes will be col- 
lected. 

SECTION 8.3 
C o m p a r i n g  Population P r o p o r t i o n s :  Multinomial Experiment 
437 
COMPARING POPULATION PROPORTIONS: 
MULTlNOMlAL EXPERIMENT 
In this section, we consider a statistical method to compare two or more, say k, 
TABLE 8.1 
Consumer 
population proportions. For example, suppose a large supermarket chain con- 
Preference 
ducts a consumer preference survey by recording the brand qf bread purchased by 
Survey 
customers in its stores. Assume the chain carries three brands of bread-two 
major brands (A and B) and its own store brand. The brand preferences of a ran- 
A 
B 
Store Brand 
dom sample of 150 consumers are observed, and the resulting count data (i.e., 
............................. ....... ....................... 
61 
53 
36 
number of consumers in each brand category) appear in Table 8.1 Do you think 
these data indicate that a preference exists for any of the brands? 
To answer this question with a valid statistical analysis, we need to know the 
underlying probability distribution of these count data. This distribution, called 
the multinomial probability distribution, is an extension of the binomial distribu- 
tion (Section 4.3). The properties of a multinomial experiment are given in the fol- 
lowing box. 
1. The experiment consists of n identical trials. 
2. There are k possible outcomes to each trial. 
3. The probabilities of the k outcomes, denoted by p,, p2, . . . , pk, remain 
the same from trial to trial, where p, + p2 + . . , pk = 1 .  
4. The trials are independent. 
5. The rando 
,, n,, . . . , nk in ea 
the k cell 
Note that our consumer-preference survey satisfies the properties of a multi- 
nomial experiment. The experiment consists of randomly sampling n = 150 buyers 
from a large population of consumers containing an unknown proportion p, who 
prefer brand A, a proportion p2 who prefer brand B, and a proportion p, who prefer 
the store brand. Each buyer represents a single trial that can result in one of three 
outcomes: The consumer prefers brand A, B, or the store brand with probabilities 
p,, p2, and p,, respectively. (Assume that all consumers will have a preference.) 
The buyer preference of any single consumer in the sample does not affect the 
preference of another; consequently, the trials are independent. And, finally, you can 
see that the recorded data are the number of buyers in each of three consumer-pref- 
erence categories.Thus, the consumer-preference survey satisfies the five properties 
of a multinomial experiment. You can see that the properties of a multinomial ex- 
periment closely resemble those of the binomial experiment and that, in fact, a bi- 
nomial experiment is a multinomial experiment for the special case where k = 2. 
In the consumer-preference survey, and in most practical applications of the 
multinomial experiment, the k outcome probabilities p,, p2, . . . , pk are unknown 
and we typically want to use the survey data to make inferences about their val- 
ues.The unknown probabilities in the consumer-preference survey are 
pl = Proportion of all buyers who prefer brand A 
p2 = Proportion of all buyers who prefer brand B 
p3 = Proportion of all buyers who prefer the store brand 

CHAPTER 
8 C o m p a r i n g  Population P r o p o r t i o n s  
To decide whether the consumers have a preference for any of the brands, we will want 
to test the null hypothesis that the brands of bread are equally preferred (that is, 
p1 = p2 = p3 = )$) against the alternative hypothesis that one brand is preferred 
(that is, at least one of the probabilities p,, p2, and p, exceeds y3). Thus, we want to test 
Ho: p1 = p2 = p3 = 1/3 (no preference) 
Ha : At least one of the proportions exceeds 1/, (a preference exists) 
If the null hypothesis is true and pl = p2 = p3 = y3, the expected value (mean 
value) of the number of customers who prefer brand A is given by 
E ( q )  = np, = (n)'I3 = (150)'/, = 50 
, 
Similarly, E(n2) = E(n3) = 50 if the null hypothesis is true and no preference exists 
The following test statistic-the 
chi-square test-measures 
the degree of 
disagreement between the data and the null hypothesis: 
- 
- (nl - 50)2 + (n, - 50)' + (n, - 50)' 
50 
50 
50 
Note that the farther the observed numbers n,, n2, and n,, are from their expect- 
ed value (50), the larger x2 will become. That is, large values of X2 imply that the 
null hypothesis is false. 
We have to know the distribution of X2 in repeated sampling before we can de- 
cide whether the data indicate that a preference exists. When H, is true, X2 can be 
shown to have (approximately) a chi-square (X2) 
distribution. The shape of the chi- 
square distribution depends on the degrees of freedom (df) associated with the data 
analyzed. For this application, the X2 distribution has (k - 1) degrees of freedom.' 
TABLE 8.2 Reproduction of Part of Table VII in Appendix B 
Degrees of Freedom 
x~,,,~ 
X?QZS 
Xfom 
X.w 
2 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1 
2.70554 
5.02389 
6.63490 
7.87944 
2 
4.60517 
.99147 
7.37776 
9.21034 
10.5966 
3 
6.25139 
7.81473 
9.34840 
11.3449 
12.8381 
4 
7.77944 
9.48773 
11.1433 
13.2767 
14.8602 
5 
9.23635 
11.0705 
12.8325 
15.0863 
16.7496 
6 
10.6446 
12.5916 
14.4494 
16.8119 
18.5476 
7 
12.0170 
14.0671 
16.0128 
18.4753 
20.2777 
*The derivation of the degrees of freedom for X2 involves the number of linear restrictions 
imposed on the count data. In the present case, the only constraint is that En, = n, where n (the 
sample size) is fixed in advance. Therefore, df = k - 1. For other cases, we will give the degrees of 
freedom for each usage of ,y2 and refer the interested reader to the references for more detail. 

SECTION 8.3 
C o m p a r i n g  Population P r o p o r t i o n s :  Multinomial Experiment 
439 
Critical values of X2 are provided in Table VII of Appendix B, a portion of 
which is shown in Table 8.2. To illustrate, the rejection region for the consumer 
preference survey for a = .05 and k - 1 = 3 - 1 = 2 df is 
Rejection region: X2 > Xi5 
The value of X%s (found in Table VII of Appendix B) is 5.99147. (See Figure 8.3.) 
The computed value of the test statistic is 
FIGURE 8.3 
Rejection region for consumer- 
preference survey 
TABLE 8.3 Distribution of 
Pay Increases 
None 
Standard 
Merit 
, , , , , , , , , , , , , . . . . . . . , , . . , . , . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 
42 
365 
193 
Since the computed X2 = 6.52 exceeds the critical value of 5.99147, we conclude at 
the a = .05 level of significance that there does exist a consumer preference for 
one or more of the brands of bread. 
Now that we have evidence to indicate that the proporti~nsp~, 
p2, and p3 
are unequal, we can make inferences concerning their individual values using 
the methods of Section 6.5. [Note: We cannot use the methods of Section 8.1 to 
compare two proportions because the cell counts are dependent random vari- 
ables.] The general form for a test of multinomial probabilities is shown in the 
next box. 
annual pay increases for its employees. The system is based on a series of 
evaluation scores determined by the supervisors of each employee. Employees 
with scores above 80 receive a merit pay increase, those with scores between 50 
and 80 receive the standard increase, and those below 50 receive no increase. The 
firm designed the plan with the objective that, on the average, 25% of its 
employees would receive merit increases, 65% would receive standard increases, 
and 10% would receive no increase. After one year of operation using the new 
plan, the distribution of pay increases for the 600 company employees was as 
shown in Table 8.3. Test at a = .O1 to determine whether the distribution of pay 
increases differs significantly from the firm's proportions. 

C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
f the multinomial 
e expected number of 
H, is true. The total sample size is n. 
ection region: X2 > 
where X: has (k - 1) d 
Assumptionx 1. A multinomial experiment has been conducted. This is 
generally satisfied by taking a random sample from the 
population of interest. 
2. The sample size n will be large enough so that for every 
cell, the expected cell count E(n,) will be equal to 5 or 
more.* 
S o I u t i o n 
Define the population proportions for the three pay increase categories to be: 
p, = Proportion of employees who receive no pay increase 
p2 = Proportion of employees who receive a standard increase 
p, = Proportion of employees who receive a merit increase 
Then the null hypothesis representing the distribution of percentages in the firm's 
proposed plan is: 
and the alternative is 
Ha: At least two of the proportions differ from the firm's proposed plan 
Test statistic: X2 = 
[n, - E(n1>I2 
E(nJ 
where 
*The assumption that all expected cell counts are at least 5 is necessary in order to ensure that 
the ,y2 approximation is appropriate. Exact methods for conducting the test of a hypothesis 
exist and may be u\ed for small expected cell counts, but these methods are beyond the scope 
of this text. 

SECTION 8.3 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s :  M u l t i n o m i a l  E x p e r i m e n t  
441 
E(n,) = np,, = 600(.10) = 60 
E(n2) = np,,, = 600(.65) = 390 
E(n,) = np,,, = 600(.25) = 150 
Since all these values are larger than 5, the X 2  approximation is appropriate. 
Rejection region: For a = .O1 and df = k - 1 = 2, reject H, if X 2  > xi1, 
where (from Table VTI of Appendix B) Xi1 
= 9.21034. 
We now calculate the test statistic: 
X2 = (42 - 6 0 ) ~  (365 - 3 9 0 ) ~  (193 - 150)2 
+ 
+ 
60 
390 
150 
= 19.33 
If we focus on one particular outcome of a multinomial experiment, we 
can use the methods developed in Section 5.3 for a binomial proportion to es- 
tablish a confidence interval for any one of the multinomial probabilities." For 
example, if we want a 95% confidence interval for the proportion of the com- 
pany's employees who will receive merit increases under the new system, we 
calculate 
CHI -SQUARE 
Thus, we estimate that between 28% and 36% of the firm's employees will quali- 
fy for merit increases under the new plan. It appears that the firm will have to 
raise the requirements for merit increases in order to achieve the stated goal of a 
25% employee qualification rate. 
P-VALUE 
Learning the Mechanics 
8.23 Use Table VII of Appendix B to find each of the fol- 
c. X:o for df = 16 
g lowing X2 values: 
d. x:,,,, 
for df = 50 
a. X:,c for df = 10 
8.24 Find the rejection region for a one-dimensional X 2  test 
b. X&o for df = 50 
of a null hypothesis concerning p,, p,, . . . , p, if 
This value exceeds the table value of X2 (9.21034); therefore, the data provide strong 
*Note that focusing on one outcome has the effect of lumping the other (k - 1) outcomes into a 
single group.Thus, we obtain, in cllect, two outcomes-or 
a binomial experiment. 
evidence (a = .01) that the company's actual pay plan distribution differs from its 
P
~
~
P
~
~
~
~
P
~
~
~
.
 
2 
19.33 
The X test can also be conducted using an available statistical software 
FIGURE 8.4 
package. Figure 8.4 is a portion of an EXCEL printout of the analysis of the data 
EXCEL analysis of data in 
in Table 8.3; note that the p-value of the test is .0000634664. Since a = .O1 exceeds 
Table 8.3 
this p-value, there is sufficient evidence to reject Ho. 
5.346643-05 

CHAPTER 8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
a. What are the characteristics of a multinomial exper- 
iment? Compare the characteristics to those of a 
binomial experiment. 
b. What conditions must n satisfy to make the ,y2 test 
valid? 
A multinomial experiment with k = 3 cells and n = 320 
produced the dnta shown in the following one-way 
table. Do these data provide sufficient evidence to con- 
tradict the null hypothesis that p, = .25, p, = .25, and 
p, = SO? Test usmg a = .05. 
........................................................ 
Cell 
........................................ 
1 
2
 3
 
........................................................ 
n, 
78 
60 
182 
A multinomial experiment with k = 4 cells and n = 205 
produced the data shown in the one-way table below. 
a. Do these data provide sufficient evidence to con- 
clude that the multinomial probabilities differ? Test 
using a = .05. 
b. What are the Type I and 5 p e  11 errors associated 
with the test of part a'? 
........................................................... 
Cell 
.............................................. 
1
2
3
4
 
........................................................... 
ni 
43 
56 
59 
47 
Refer to Exercise 8.27. Construct a 95% confidence 
interval for the multinomial probability associated with 
cell 3. 
Applying the Concepts 
8.29 M&M's plain chocolate candies come in six different 
colors: dark brown, yellow, red, orange, green, and blue. 
According to the manufacturer (Mars, Inc.), the color 
ratio in each large production batch is 30% brown, 20% 
yellow, 20% red, 10% orange, 10% green, and 10% 
blue. To test this claim, a professor at Carleton College 
(Minnesota) had students count the colors of M&M's 
found in "fun size" bags of the candy (Teaching 
Statistics, Spring 1993). The results for 370 M&M's are 
displayed in the table below. 
Brown 
Yellow 
Red 
Orange 
Green 
Blue 
Total 
Source: Johnson, R.W. "Testing colour proportions of M&M'sn 
Teaching Statistics, Vol. 15, No. 1, Spring 1993, p. 2 (Table 1). 
a. Assuming the manufacturer's stated percentages are 
accurate, calculate the expected numbers falling into 
the six categories. 
b. Calculate the value of X 2  for testing the rnanufactur- 
er's claim. 
c. Conduct a test to determine whether the true per- 
centages of the colors produced differ from the 
manufacturer's stated percentages. Use a = .05. 
8.30 Bon Appetit magazine polled 200 of its readers concerning 
which of the four vegetables-brussel sprouts, okra, lima 
beans, and cauliflower-is their least favorite. The results 
(adapted from Adweek, Feb. 21, 2000) are presented in 
the table. Let p,, p2, p,, and p, represent the proportions 
of all Bon Appetit readers who indicate brussel sprouts. 
okra, lima beans, and cauliflower, respectively, as their 
least favorite vegetable. 
a BONAPP.DAT 
.............................................................................................................. 
Brussel 
Sprouts 
Okra 
Lima Beans 
Cauliflower 
.............................................................................................................. 
46 
76 
44 
34 
a. If in general, Bon Appetit readers do not have a prefer- 
ence for their least favorite vegetable, what are the val- 
ues of P I ,  p2, P,, and p4? 
b. Specify the null and alternative hypotheses that 
should be used to determine whether Bon Appetit 
readers have a preference for one of the vegetables 
as "least favorite." 
c. Conduct the test you described in part b using a = .05. 
Report your conclusion in the context of the problem. 
d. What assumptions must hold to ensure the validity of 
the test you conducted in part c? Which, if any, of these 
assumptions may be a concern in this application? 
8.31 In order to study consumer preferences for health care 
reform in the U.S., rescarchers from the University of 
Michigan surveyed 500 U.S. households (Journal of 
Consumer Affairs, Winter 1999). Heads of household 
were asked whether they are in favor of, neutral about. 
or opposed to a national health insurance program in 
which all Americans are covered and costs are paid by 
tax dollars. The 434 useable responses are summarized 
in the table below. A STATISTIX printout of the analy- 
sis of the data is shown on p. 443. 
Favor 
Neutral 
Oppose 
.............................................................................................................. 
234 
119 
81 
Source: Hong, G., and White-Means, S. "Consumer Preferences for 
Health Care Reform," Journal of Consumer Affairs, Vol33, No. 2. 
Winter 1999, pp. 237-253. 

SECTION 8.3 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s :  M u l t i n o m i a l  E x p e r i m e n t  
STATlSTlX Output for Exercise 8.31 
MULTINOMIAL TEST 
HYPOTHESIZED PROPORTIONS VARIABLE: HYPPROP 
OBSERVED FREQUENCIES VARIABLE: 
NUMBER 
HYPOTHESIZED OBSERVED 
EXPECTED 
CHI-SQUARE 
CATEGORY 
PROPORTION 
FREQUENCY 
FREQUENCY CONTRIBUTION 
1 
0.33333 
234 
144.67 
55.16 
2 
0.33333 
119 
144.67 
4.55 
3 
0.33333 
8 1 
144.67 
28.02 
OVERALL CHI-SQUARE 
87.74 
P -VALUE 
0.0000 
DEGREES OF FREEDOM 
2 
a. Is there sufficient evidence to conclude that opinions 
are not evenly divided on the issue of national health 
insurance? Conduct the appropriate test using a = .01. 
b. Construct a 95% confidence interval for the propor- 
tion of heads of household in the U.S. population 
who favor national health insurance. 
8.32 Interferons are proteins produced naturally by the 
human body that help fight infections and regulate the 
immune system. A drug developed from interferons, 
called Avonex, is now available for treating patients 
with multiple sclerosis (MS). In a clinical study, 85 MS 
patients received weekly injections of Avonex over a 
two-year period. The number of exacerbations (i.e., 
flare-ups of symptoms) was recorded for each patient 
and is summarized in the accompanying table. For MS 
patients who take a placebo (no drug) over a similar 
two-week period, it is known from previous studies that 
26% will experience no exacerbations, 30% one exacer- 
bation, 11% two exacerbations, 14% three exacerba- 
tions, and 19% four or more exacerbations. 
.............................................................................................................. 
Number of Exacerbations 
Number of Patients 
............................................................................................................. 
0 
32 
1 
26 
2 
15 
3 
6 
4 or more 
6 
Source: Biogen, Inc., 1997. 
a. Conduct a test to determine whether the exacerba- 
tion distribution of MS patients who take Avonex 
differs from the percentages reported for placebo 
patients. Test using a = .05 
b. Find a 95% confidence interval for the true percent- 
age of Avonex MS patients who are exacerbation-free 
during a two-year period. 
c. Refer to part b. Is there evidence that Avonex pa- 
tients are more likely to have no exacerbations than 
placebo patients? Explain. 
8.33 Inc. Technology (Mar. 18,1997) reported the results of the 
1996 EquifaxIHarris Consumer Privacy Survey in which 
328 Internet users indicated their level of agreement with 
the following statement: "The government needs to be 
able to scan Internet messages and user communications 
to prevent fraud and other crimesnThe number of users 
in each response category is summarized below. 
Agree 
Agree 
Disagree 
Disagree 
Strongly 
Somewhat 
Somewhat 
Strongly 
a. Specify the null and alternative hypotheses you 
would use to determine if the opinions of Internet 
users are evenly divided among the four categories. 
b. Conduct the test of part a using a = .05. 
c. In the context of this exercise, what is a Type I error? 
A Type I1 error? 
d. What assumptions must hold in order to ensure the 
validity of the test you conducted in part b? 
8.34 Data from supermarket scanners are used by researchers 
to understand the purchasing patterns and preferences of 
consumers. Researchers frequently study thc purchases of 
a sample of households, called a scanner panel. When 
shopping, these households present a magnetic identifica- 
tion card that permits their purchase data to be identified 

444 
CHAPTER 8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
and aggregated. Marketing researchers recently studied 
the extent to which panel households' purchase behavior is 
representative of the population of households shopping 
at the same stores (Marketing Research, Nov. 1996). The 
table below reports the peanut butter purchase data col- 
lected by A. C. Niclscn Company for a panel of 2,500 
households in Sioux Falls, SD, over a 102-week period.The 
market share percentages in the right column are dcrived 
from all peanut butter purchases at the same 15 stores at 
which the panel shopped during the same 102-week 
period. 
a. Do the data provide sufficient evidence to conclude 
that the prchases of the household panel are repre- 
sentative of the population of households? Test using 
a = .05. 
SCANNER.DAT 
................................................................................................... 
Number of Purchases 
Market 
Brand 
Size 
by Household Panel 
Shares 
Jif 
18 oz. 
3,165 
20.10% 
Jif 
28 
1,892 
10.10 
Ji f 
40 
726 
5.42 
Peter Pan 10 
4,079 
16.01 
Skippy 
18 
6,206 
28.65 
Skippy 
28 
1,627 
12.38 
Skippy 
40 
1,420 
7.32 
Total 
19,115 
Source: Gupta, S., et. al. "Do household scanner data 
provide representative inferences from brand choices? A 
comparison with store data." Journal of'Marketing Research, 
Vol. 33, Nov. 1996, p. 393 (Table 6). 
b. What assumptions must hold to ensure the validity 
of the testing procedure you used in part a? 
c. Find the approximate p-value for the test of 
part a and interpret it in thc context of the problem. 
8.35 Each year, approximately 1.3 million Americans 
suffer adverse drug effects (ADEs), that is, unintend- 
ed injuries caused by prescribed medication. A study 
in the Journal of the American Medical Association 
(July 5, 1995) identified the cause of 247 ADEs that 
occurred at two Boston hospitals. The researchers 
found that dosing errors (that is, wrong dosage pre- 
scribed andlor dispensed) were the most common. 
Wrong Dosage Cause 
Number of ADEs 
.............................................................................................................. 
(1) Lack of knowledge of drug 
29 
(2) Rule violation 
17 
(3) Faulty dose checking 
13 
(4) Slips 
9 
(5) Other 
27 
The previous table summarizes the proximate cause 
of 95 ADEs that resulted from a dosing error. 
Conduct a test (at a = .10) to determine whether the 
true percentages of ADEs in the five "cause" cate- 
gories are different. Use the accompanying EXCEL 
printout to arrive at your decision. 
EXCEL Output for Exercise 8.35 
I CAUSE 
I 
ADEs 
I 
NO KNOWLEDGE 
RULE VIOLATE 
FAULTY DOSE I 
13 1 
SLIPS 
OTHER 
CHI-SQUARE I 
16 
P -VALUE 
10.003019 
8.36 In education, the term instructional technology refers to 
products such as computers, spreadsheets, CD-ROMs, 
vidcos, and presentation software. How frequently do 
professors use instructional technology in the class- 
room? To answer this question, researchers at Western 
Michigan University surveyed 306 of their fellow faculty 
(Educational Technology, Mar.-Apr. 1995). Responses 
to the frequency-of-technology use in teaching were 
recorded as "weekly to every class," "once a semester to 
monthly," or "never." The faculty responses (number in 
each response category) for the three technologies are 
summarized in the next table. 
TECHUSE.DAT 
.............................................................................................................. 
Once a 
Semester1 
Technology 
Weekly 
Monthly 
Never 
Computer spreadsheets 
58 
67 
181 
Word processing 
168 
61 
77 
Statistical software 
37 
82 
187 
a. Determine whether the percentages in the three fre- 
quency-of-use response categories differ for com- 
puter spreadsheets. Use a = .01. 
b. Repeat part a for word processing. 
c. Repeat part a for statistical software. 
d. Construct a 99% confidence interval for the true per- 
centage of faculty who never use computer spread- 
sheets in the classroom. Interpret the interval. 
8.37 Although illegal, overloading is common in the truck- 
ing industry. A state highway planning agenc! 
(Minnesota Department of Transportation) monitored 
the movements of overwcight trucks on an interstate 
highway using an unmanncd, computerized scalc that is 

SECTION 8.4 
C o n t i n g e n c y  T a b l e  Analysis 
445 
built into the highway. Unknown to the truckers, the 
a. The planning agency would like to know whether 
scale weighed their vehicles as they passed over it. 
the number of overweight trucks per week is distrib- 
Each day's proportion of one week's total truck traffic 
uted over the seven days of the week in direct pro- 
(five-axle tractor truck semitrailers) is shown in the 
portion to the volume of truck traffic. Test using 
first table below. During the same week, the number of 
a = .05. 
overweight trucks per day is given in the second table. 
b. Find the approximatep-value for the test of part a. 
Monday 
Tuesday 
Wednesday 
Thursday 
Friday 
Saturday 
Sunday 
Monday 
Tuesday 
Wednesday 
Thursday 
Friday 
Saturday 
Sunday 
CONTINGENCY TABLE ANALYSIS 
In Section 8.3, we introduced the multinomial probability distribution and con- 
sidered data classified according to a single qualitative criterion. We now consid- 
er multinomial experiments in which the data are classified according to two 
qualitative criteria, that is, classification with respect to two factors. 
For example, high gasoline prices have made many consumers more aware 
of the size of the automobiles they purchase. Suppose an automobile manufac- 
turer is interested in determining the relationship between the size and manufac- 
turer of newly purchased automobiles. One thousand recent buyers of cars made 
in the United States are randomly sampled, and each purchase is classified with 
respect to the size and manufacturer of the automobile. The data are summa- 
rized in the two-way table shown in Table 8.4. This table is called a contingency 
table; it presents multinomial count data classified on two scales, or dimensions, of 
classification-namely, automobile size and manufacturer. 
TABLE 
8.4 
Contingency Table for Automobile Size 
Example 
Manufacturer 
A 
B 
C 
D 
Totals 
Small 
157 
65 
181 
10 
413 
Auto 
Intermediate 
126 
82 
142 
46 
396 
Size 
Large 
58 
4.5 
60 
28 
191 
Totals 
341 
192 
383 
84 
1,000 
The symbols representing the cell counts for the multinomial experiment in 
Table 8.4 are shown in Table 8%; and the corresponding cell, row, and column 
probabilities are shown in Table 8.5b. Thus, n,, represents the number of buyers 
who purchase a small car of manufacturer A and p, represents the corresponding 
cell probability. Note the symbols for the row and column totals and also the 
symbols for the probability totals. The latter are called marginal probabilities for 

C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
TABLE 
8.5a 
Observed Counts for Contingency Table 8.4 
Manufacturer 
A 
B 
C 
D 
Totals 
Small 
n ~ t  
n12 
n13 
1114 
'-1 
Auto 
Intermediate 
n2, 
nz2 
nZ3 
n,, 
r2 
Size 
Large 
n31 
n32 
n33 
n34 
r3 
Totals 
C1 
Cz 
C3 
C4 
n 
TABLE 
8.5b 
Probabilities for Contingency Table 8.4 
Manufacturer 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
A 
B 
C 
D 
Totals 
Auto 
Small 
PII 
P12 
P13 
P14 
Prl 
Intermediate 
p21 
p22 
p23 
p24 
Pr2 
Size 
Large 
P ~ I  
P ~ Z  
~
3
3
 ~
3
4
 
~
r
3
 
Totals 
Pel 
Pc2 
Pc3 
Pc4 
1 
each row and column. The marginal probability p,, is the probability that a small 
car is purchased; the marginal probability pcl is the probability that a car by man- 
ufacturer A is purchased. Thus, 
Thus, we can see that this really is a multinomial experiment with a total of 
1,000 trials, (3)(4) = 12 cells or possible outcomes, and probabilities for each cell 
as shown in Table 8.5b. If the 1,000 recent buyers are randomly chosen, the trials 
are considered independent and the probabilities are viewed as remaining con- 
stant from trial to trial. 
Suppose we want to know whether the two classifications, manufacturer and 
size, are dependent. That is, if we know which size car a buyer will choose, does that 
information give us a clue about the manufacturer of the car the buyer will choose? 
In a probabilistic sense we know (Chapter 3) that independence of events A and B 
implies P(AB) = P(A)P(B). Similarly, in the contingency table analysis, if the two 
classifications are independent, the probability that an item is classified in any 
particular cell of the table is the product of the corresponding marginal probabili- 
ties. Thus, under the hypothesis of independence, in Table 8Sb, we must have 
and so forth. 
To test the hypothesis of independence, we use the same reasoning employed 
in the one-dimensional tests of Section 8.3. First, we calculate the expected, or 
mean, count in each cell assuming that the null hypothesis of independence is true. 
We do this by noting that the expected count in a cell of the table is just the total 
number of multinomial trials, n, times the cell probability. Recall that n,, represents 

SECTION 
8.4 
C o n t i n g e n c y  Table Analysis 
447 
the observed count in the cell located in the ith row and jth column. Then the ex- 
pected cell count for the upper lefthand cell (first row, first column) is 
or, when the null hypothesis (the classifications are independent) is true, 
Since these true probabilities are not known, we estimate prl and p,, by the same 
proportions Pr1 = rl/n and PC, = c,/n. Thus, the estimate of the expected value 
E(n11) is 
Similarly, for each i, j, 
(Row total)(Column total) 
&,,) 
= 
Total sample size 
Thus, 
Using the data in Table 8.4, we find 
The observed data and the estimated expected values (in parentheses) are shown 
in Table 8.6. 
TABLE 
8.6 Observed and Estimated Expected (in Parentheses) Counts 
Manufacturer 
..................................................................................................................................................................................... 
A 
B 
C 
D 
Totals 
..................................................................................................................................................................................... 
Small 
157 
65 
181 
10 
(140.833) 
(79.296) 
(158.179) 
(34.692) 
413 
Auto 
Intermediate 
126 
82 
142 
46 
Size 
(135.036) 
(76.032) 
(151.668) 
(33.264) 
396 
Large 
58 
45 
60 
28 
(65.131) 
(36.672) 
(73.153) 
(16.044) 
191 
Totals 
341 
192 
383 
84 
1,000 

448 
CHAPTER 8 C o m p a r i n g  Population P r o p o r t i o n s  
We now use the X 2  statistic to compare the observed and expected (estimat- 
ed) counts in each cell of the contingency table: 
Note: The use of C. in the context of a contingency table analysis refers to a sum 
over all cells in the table. 
Substituting the data of Table 8.6 into this expression, we get 
Large values of X2 imply that the observed counts do not closely agree and hence 
that the hypothesis of independence is false. To determine how large X 2  must be 
before it is too large to be attributed to chance, we make use of the fact that the 
sampling distribution of X 2  is approximately a X 2  probability distribution when the 
classifications are independent. 
When testing the null hypothesis of independence in a two-way contingency 
table, the appropriate degrees of freedom will be (r - l)(c - I), where v is the 
number of rows and c is the number of columns in the table. 
For the size and make of automobiles example, the degrees of freedom for 
X2 is (r - 1)(c - 1) = (3 - 1)(4 - 1) = 6. Then, for a = .05, we reject the hy- 
pothesis of independence when 
Since the computed X2 = 45.81 exceeds the value 12.5916, we conclude that the 
size and manufacturer of a car selected by a purchaser are dependent events. 
The pattern of dependence can be seen more clearly by expressing the 
data as percentages. We first select one of the two classifications to be used as 
the base variable. In the automobile size preference example, suppose we select 
manufacturer as the classificatory variable to be the base. Next, we represent 
the responses for each level of the second categorical variable (size of auto- 
mobile in our example) as a percentage of the subtotal for the base variable. 
For example, from Table 8.6 we convert the response for small car sales for 
manufacturer A (157) to a percentage of the total sales for manufacturer A 
(341). That is, 
The conversions of all Table 8.6 entries are similarly computed, and the values are 
shown in Table 8.7. The value shown at the right of each row is the row's total ex- 
pressed as a percentage of the total number of responses in the entire table.Thus, the 
small car percentage is (413/1,000)(100%) = 41% (rounded to the nearest percent). 

Size as a percentage of 
manufacturer subtotals 
SECTION 8.4 
C o n t i n g e n c y  T a b l e  A n a l y s i s  
449 
TABLE 
8.7 
Percentage of Car Sizes by Manufacturer 
Manufacturer 
A 
B 
C 
D 
All 
Small 
46 
34 
47 
12 
41 
Auto 
Intermediate 
37 
43 
37 
55 
40 
Size 
Large 
17 
23 
16 
33 
19 
Totals 
100 
100 
100 
100 
100 
If the size and manufacturer variables are independent, then the percentages 
in the cells of the table are expected to be approximately equal to the corre- 
sponding row percentages. Thus, we would expect the small car percentages for 
each of the four manufacturers to be approximately 41 % if size and manufactur- 
er are independent. The extent to which each manufacturer's percentage departs 
from this value determines the dependence of the two classifications, with greater 
variability of the row percentages meaning a greater degree of dependence. A plot 
of the percentages helps summarize the observed pattern. In Figure 8.5 we show 
the manufacturer (the base variable) on the horizontal axis, and the size percent- 
ages on the vertical axis. The "expected" percentages under the assumption of in- 
dependence are shown as horizontal lines, and each observed value is represented 
by a symbol indicating the size category. 
Figure 8.5 clearly indicates the reason that the test resulted in the conclu- 
sion that the two classifications in the contingency table are dependent. Note 
that the sales of manufacturers A, B, and C fall relatively close to the expected 
percentages under the assumption of independence. However, the sales of man- 
ufacturer D deviate significantly from the expected values, with much higher 
percentages for large and intermediate cars and a much smaller percentage 
for small cars than expected under independence. Also, manufacturer B devi- 
ates slightly from the expected pattern, with a greater percentage of interme- 
diate than small car sales. Statistical measures of the degree of dependence 
and procedures for making comparisons of pairs of levels for classifications are 
available. They are beyond the scope of this text, but can be found in the refer- 
ences. We will, however, utilize descriptive summaries such as Figure 8.5 to ex- 
amine the degree of dependence exhibited by the sample data. 
- / A x .  
/ \ 
w 0  
-w' 
\ : Large (All) 
L 
L 
b 
Manufacturer 

450 
CHAPTER 8 c o m p a r i n g  Population P r o p o r t i o n s  
The general form of a two-way contingency table containing r rows and c 
columns (called an r x c contingency table) is shown in Table 8.8. Note that the 
observed count in the (ti) cell is denoted by n,,, the ith row total is ri, the jth col- 
umn total is c,, and the total sample size is n. Using this notation, we give the 
general form of the contingency table test for independent classifications in the 
next box. 
TABLE 
8.8 
General r x c Contingency Table 
-
.
 
Column 
................................................. 
... 
1 
2 
c 
Row Totals 
................................................................................................................................................... 
Column Totals 
CI 
c2 
... 
CC 
n 
: The two classifications are indep 
: The two classifications are dependent 
mptions: 1. The n observ 
ndom sample from the pop- 
ulation of interest. 
en consider this to be a multi- 
sample of 500 clients are selected, and each client is asked to rate his or her 
broker. The results are shown in Table 8.9. 
a. Test to determine whether there is evidence that broker rating and cus- 
tomer income are independent. Use a = .lo. 

SECTION 8.4 
C o n t i n g e n c y  Table Analysis 
451 
TABLE 
8.9 
Survey Results (Observed Clients), Example 8.5 
Client's Income 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Under $30,000 
$30,000-$60,000 
Over $60,000 
Totals 
Outstanding 
48 
Broker 
Average 
98 
Rating 
poor 
30 
Totals 
S o l u t i o n  
FIGURE 8.6 
SAS contingency table printout 
b. Plot the data and describe the patterns revealed. Is the result of the test sup- 
ported by the plot? 
a. The first step is to calculate estimated expected cell frequencies under the 
assumption that the classifications are independent. Rather than compute 
these values by hand, we resort to a computer. The SAS printout of the 
analysis of Table 8.9 is displayed in Figure 8.6. Each cell in Figure 8.6 con- 
tains the observed (top) and expected (bottom) frequency in that cell. Note 
that E ( n , , ) ,  the estimated expected count for the Outstanding, Under 
$30,000 cell is 53.856. Similarly, the estimated expected count for the 
Outstanding, $30,000-$60,000 cell is E(n,,) = 66.402. Since all the estimated 
expected cell frequencies are greater than 5, the X 2  approximation for the 
test statistic is appropriate. Assuming the clients chosen were randomly 
selected from all clients of the brokerage firm, the characteristics of the 
TABLE OF RATING BY INCOME 
RATING 
INCOME 
Frequency; 
I 
I 
I 
Expected IUNDER30K 1 30K-60K i O V E R ~ O K  
Total 
- - - - - - - - - - + - - - - - - - - - + - - - - - - - - - + - - - - - - - - +  
OUTSTAND 1 
48 : 
64 
1 
41 1 
153 
1 53.856 166.402 
1 
32.7421 
- - - - - - - - - - + - - - - - - - - - + - - - - - - - - - + - - - - - - +  
AVERAGE 
1 
98 
120 
1 
50 1 
268 
94.336 1116.31 
1 
57.3521 
- - - - - - - - - - + - - - - - - - - - + - - - - - - - - - + - - - - - - - - +  
POOR 
I 
I 
30 1 
33 : 
16 : 
7 9 
1 27.808 
1 34.286 : 16.906: 
- - - - - - - - - - + - - - - - - - - - + - - - - - - - - - + - - +  
Total 
17 6 
2 17 
107 
500 
STATISTICS FOR TABLE OF RATING BY INCOME 
Statistic 
DF 
Value 
Prob 
.................................................. 
Chi-square 
4 
4.278 
0.370 
Likelihood Ratio Chi-square 
4 
4.184 
0.382 
Mantel-Haenszel Chi-square 
1 
2.445 
0.118 
Phi Coefficient 
0.092 
Contingency Coefficient 
0.092 
Cramer's V 
0.065 
Sample Size = 500 

CHAPTER 
8 C o m p a r i n g  Population P r o p o r t i o n s  
TABLE 
8.10 
Broker Ratings as Percentage of Income Class 
Client's Income 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Under $30,000 
$30,000-$60,000 Over $60,000 
Totals 
Broker 
Outstanding 
27 
Rating 
Average 
56 
Poor 
17 
Totals 
100 
99* 
100 
101* 
- - - 
*Percentages do not add up to 100 because of rounding. 
FIGURE 8.7 
Plot of broker rating-customer 
60 
income contingency table 
A 
A 
0 ..-...... 
Average (All) 
' 0  
A 
*--- . - 
Poor (All) 
P 
P 
1 
2 
3 
4 
Income classification 
multinomial probability distribution are satisfied. The null and alternative 
hypotheses we want to test are: 
H,: The rating a client gives his or her broker is independent of client's 
income 
Ha: Broker rating and client income are dependent 
The test statistic, X2 = 4.278, is highlighted at the bottom of the printout as is 
the observed significance level (p-value) of the test. Since a = .10 is less 
than p = .370, we fail to reject H,. This survey does not support the firm's 
alternative hypothesis that affluent clients receive different broker service 
than lower-income clients. 
b. The broker rating frequencies are expressed as percentages of income cat- 
egory frequencies in Table 8.10. The expected percentages under the 
assumption of independence are shown at the right of each row. The plot 
of the percentage data is shown in Figure 8.7, where the horizontal lines 
represent the expected percentages assuming independence. Note that the 
response percentages deviate only slightly from those expected under the 
assumption of independence, supporting the result of the test in part a. 
That is, neither the descriptive plot nor the statistical test provides evi- 
dence that the rating given the broker services depends on (varies with) 
the customer's income. 
* 

SECTION 8.4 
C o n t i n g e n c y  T a b l e  A n a l y s i s  
453 
Using the TI-83 Graphing Calculator 
\" 
Finding p-values for Contingency Tables on the TI-83 
Start from the home screen. 
Step 1 Access the Matrix Menu and enter your observed values as Matrix [A]. 
and your expected values as Matrix [B]. 
Press 
MATRIX 
Arrow right to EDIT 
Press 
ENTER 
Enter the d~mensions of your observed Matrix 
Enter all values 
Press 
MATRIX 
Arrow right to EDIT 
Arrow down to 2:[B] 
Press 
ENTER 
Enter the dimensions of the expected values Matrix 
(It will be the same as step 1 above) 
Enter all values 
Step 2 Access the StatisticalTests Menu and perform the X2Test. 
Press 
STAT 
Arrow right to TESTS 
Arrow up to C: X 2  - Test.. . 
Press 
ENTER 
Enter the names for the Observed and Expected Matrices 
(Press Matrix arrow to desired Matrix, Press ENTER) 
Arrow down to Calculate 
Press 
ENTER 
View Display 
Step 3. Reject H, if the p-value > a. 
Example 
our Observed Matrix will be [A] = 39. 
19 12 28 
18 
172 61 44 
70 
37 1 
Our Expected Matrix will be 
48.952 
18.56 
12.992 22.736 
12.76 
PI = [ . 162.05 
61.44 
43.008 75.264 
42.24 
The hypotheses for this problem are as follows: 
1 
H,,: The Matrix entries represent Independent events. 
Ha: The Matrix entries represent events that are not independent. 
Step 1. Access Matrix Menu and enter'all values 
Press 
MATRIX 
Arrow r~ght to EDIT 
(continu 

454 
CHAPTER 8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
Press 
ENTER 
Enter the dimensions of our Observed Matrix (see screen 
below left) 
Enter all values (see screen above right) 
Press 
MATRIX 
Arrow right to EDIT 
Press 
ENTER 
Edter the dimensions of our Expected Matrix (same as above) . 
Enter all expected values* (see screen below) 
the product of (that row total)* 
IMATRIX[BI 2 x5 
step 2 
Perform the X 2  Test 
Press 
STAT 
Arrow right to TESTS 
Arrow up to C: X Z  - Test.. . 
Observed: [ A 1  
Exvected: [ E l  
Calculate Draw 
Press 
ENTER see screen 
Set 
Observed: [A] 
Expected: [B] 
Arrow down to Calculate 
Press 
ENTER (see screen) 
(continued) 

SECTION 8.4 
C o n t i n g e n c y  T a b l e  A n a l y s i s  
455 
Screen 
you.can see from the screen the p-value is 0.129. Since the p-value is 
not less than a we do not reject H,. 
Step 4 Clear screen for the next problem. Return to the home screen. 
Press 
CLEAR 
Learning the Mechanics 
8.38 Find the rejection region for a test of independence of 
two classifications where the contmgency table contains 
r rows and c columns. 
a. r = 5, c = 5, a = .05 
b. r = 3, c = 6, a = .10 
c. r = 2, c = 3, a = .O1 
8.39 Consider the accompanying 2 X 3 (i.e., r = 2 and c = 3) 
contingency table. 
graph, plot the cell percentages from part a using the 
row number as a plotting symbol. 
g. What pattern do you expect to see if the rows and 
columns are independent? Does the plot support the 
result of the test of independence in part d? 
8.40 Test the null hypothesis of independence of the two 
classifications, A and B, of the 3 X 3 contingency table 
shown here. Tcst using a = .05. 
Column 
a. Specify the null and alternative hypotheses that 
should be used in testing the independence of the 
row and column classifications. 
b. Specify the test statistic and the rejection region that 
should be used in conducting the hypothesis test of 
part a. Use a = .01. 
c. Assuming the row classification and the column clas- 
sification are independent, find estimates for the ex- 
pected cell counts. 
d. Conduct the hypothesis test of part a. Interpret your 
result. 
e. Convert the frequency responses to percentages by 
calculating the percentage o f  each column total 
falling in each row. Also convert the row totals to 
percentages of the total number of responses. Dis- 
play the percentages in a table. 
f. Create a graph with percentage on the vertical axis 
and column number on the horizontal axis. Showing 
the row total percentages as horizontal lines on the 
Applying the Concepts 
8.41 In order to create a behavioral profile of pleasure travel- 
ers, M. Bonn (Florida State University), L. Forr (Georgia 
Southern University), and A .  Susskind (Cornell 
University) interviewed 5,026 pleasure travelers in the 
Tampa Bay region (Journal of Travel Research, May 
1999). Two of the characteristics they investigated were 
the travelers' education level and their use of the Internet 
USE INTERNET 
EDUCATION 
Yes 
N o  
.............................................................................................................. 
College Degree or More 
1,072 
1,287 
Less than a College Degree 
640 
2,027 
Source: Bonn, M., Furr, L., and Susskind, A,, "Predicting a 
Behavioral Profile for Pleasure Travelers on the Basis of Internet 
Use Segmentation," Journal of Travel Research, Vol. 37, May 1999, 
pp. 333-340. 

456 
CHAPTER 8 
c o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
to seek travel information. The table below summarizes 
the results of the interviews. The researchers concluded 
that travelers who use the Internet to search for travel 
information are likely to be people who are college edu- 
cated. Do you agree? Test using a = .05. What assump- 
tions must hold to ensure the validity of your test? 
8.42 During the 2000 U.S. presidential campaign, Senator 
I 
il 
John McCain and Governor George W. Bush competed 
for the Republican nomination. Immediately prior to 
the South Carolina primary election, New~week com- 
missioned a telephone survey of 507 South Carolina 
voters who intended to vote in the Republican primary. 
The purpose was to determine where they stood on 
some of the important campaign issues. Of those sur- 
veyed, 218 were Bush supporters, 203 were McCain sup- 
porters, and the remainder favored neither. One 
question asked was: "Should most of the budget surplus 
be used to pay for a tax cut?" Of the Bush supporters, 
61% said yes, 30% said no, and 9 % were undecided. Of 
the McCain supporters, 42% said yes, 50% said no, and 
8% were undecided (Newsweek, Feb. 21,2000). Do the 
data provide sufficient evidence to conclude that a 
voter's position on the tax cut issue is related to his or 
her preferred presidential candidate? Test using a = .05. 
8.43 The American Journal of Public Health (July 1995) 
reported on a population-based study of trauma in 
Hispanic children. One of the objectives of the study 
was to compare the use of protective devices in motor 
vehicles used to transport Hispanic and non-Hispanic 
white children. On the basis of data collected from the 
San Diego County Regionalized Trauma System, 792 
children treated for injuries sustained in vehicular acci- 
dents were classified according to ethnic status 
(Hispanic or non-Hispanic white) and seatbelt usage 
(worn or not worn) during the accident. The data are 
summarized in the table below. 
Non-Hispanic 
Hispanic 
White 
Totals 
Seatbelts worn 
31 
148 
179 
Seatbelts not worn 283 
330 
613 
.......................................................................................................... 
Totals 
314 
478 
792 
Source: Matteneci, R. M. et al. "Trauma among Hispanic children: 
A population-based study in a regionalized system of trauma 
care." American Journal of Pirhlic Heulth, Vol. 85, No. 7, July 1995, 
p. 1007 (Table 2). 
a. Calculate the sample proportion of injured Hispanic 
children who were not wearing seatbelts during the 
accident. 
b. Calculate the sample proportion of injured non-His- 
panic white children who were not wearing seatbelts 
during the accident. 
c. Compare the two sample proportions, parts a and b. 
Do you think the true population proportions differ? 
d. Conduct a test to determine whether seatbelt usage 
in motor vehicle accidents depends on ethnic status 
in the San Diego County Regionalized Trauma Sys- 
tem. Use a = .01. 
e. Construct a 99% confidence interval for the differ- 
ence between the proportions, parts a and b. Inter- 
pret the interval. 
8.44 To better understand whether and how Total Quality 
Management (TQM) is practiced in US. companies, 
University of Scranton researchers N. Tamimi and R. 
Sebastianelli interviewed one manager in each of a 
sample of 86 companies in Pennsylvania, New York, and 
New Jersey (Production and Inventory Management 
Journal, 1996). Concerning whether or not the firms 
were involved with TQM, the following data were 
obtained: 
TQM.DAT 
......................................................................................................... 
Service Manufacturing 
Firms 
Firms 
......................................................................................................... 
Number practicing TQM 
34 
23 
Number not practicing TQM 18 
11 
......................................................................................................... 
Total 
52 
34 
Source: Adapted from Tamimi, N., and Sebastianelli, R. "How 
firms define and measure quality." Production and Inventory 
Management Journul, Third Quarter, 1996, p. 35. 
a. The researchers concluded that "manufacturing 
firms were not significantly more likely to be in- 
volved with TQM than service firms." Do you agree? 
Test using a = .05. 
b. Find and interpret the approximate p-value for the 
test you conducted in part a. 
c. What assumptions must hold in order for your test of 
part a and your p-value of part b to be valid? 
8.45 For over 20 years, movie critics Gene Siskel (formerly of 
the Chicago Tribune, now deceased) and Roger Ebert 
(Chicago Sun-Times) rated the latest film releases on 
national television, first on PBS with Sneak Previews, 
then in syndication with At the Movies. University of 
Florida statisticians examined data on 160 movie 
reviews by Siskel and Ebert during the period 
1995-1996 (Chance, Spring 1997). Each critic's review 
was categorized as pro ("thumbs up"), con ("thumbs 
down"), or mixed. Consequently, each movie has a 
Siskel rating (pro, con, or mixed) and an Ebert rating 
(pro, con, or mixed). A summary of the data is provided 
in the SPSS printout on page 457. 
a. Verify that the expected cell counts in the table are 
accurate. 
b. Conduct a test of hypothesis to determine whether 
the movie reviews of the two critics are independent. 
Use a = .01. 

SECTION 8.4 
C o n t i n g e n c y  T a b l e  A n a l y s i s  
457 
, <  
I * ? ,  
SPSS Output for Exercise 8.45 
SISKEL * EBERT Crosstabulation 
I 
EBERT 
Con I 
Mix 
Expected Count 
Mix 
Count 
Pro 
I 
Chi-square Tests 
Total 
SISKEL 
Con 
Count 
11.8 
8 
Expected Count 
Expected Count 
Total 
Count 
Expected Count 
I 
Value 
I df 
I (2-sided) 
Pearson Chi-square 
1 
45. 357a 1 
4 1 
.OOO 
24 1 
8 
1 
13 1 
4 5 
Likelihood Ratio 
43.233 1 
4 1 
.OOO / 
N of Valid Cases 
1 
160 
8.4 
13 
8.4 
21.8 
4 2 
42.0 
a. 0 cells (.O%) have expected count less than 5. The minimum expected count is 6.00. 
Pro 
Count 
8.46 University of Louisville professor Julia Karcher con- 
ducted an experiment to investigate the ethical 
behavior of accountants (Journal of Business Ethics, 
Vol. 15,1996). She focused on auditor abilities to 
detect ethical problems that may not be obvious. 
Seventy auditors from Big-Six accounting firms were 
given a detailed case study that contained several 
problems including tax evasion by the client. In 35 of 
the cases the tax evasion issue was severe; in the 
other 35 cases it was moderate. The auditors were 
asked to identify any problems they detected in the 
case. The following table summarizes the results for 
the ethical issue. 
24.8 
11 
6.0 
10 1 
9 1 
64 1 
83 
15.6 
3 0 
30.0 
ACCETHIC.DAT 
......................................................................................................... 
Severity of 
Ethical lssue 
......................................... 
Moderate 
Severe 
......................................................................................................... 
Ethical Issue Identified 
27 
26 
Ethical Issue Not Identified 
8 
9 
......................................................................................................... 
Source: Karcher, J. "Auditors' ability to discern the presence of 
ethical problems." Journal of Business Ethics, Vol. 15,1996, p. 1041 
(Table V). 
45.0 
3 2 
a. Did the severity of the ethical issue influence 
whether the issue was identified or not by the audi- 
tors? Test using a = .05. 
17.6 
45.7 
8 8 
88.0 
b. Suppose the lefthand column of the table con- 
tained the counts 35 and 0 instead of 27 and 8. 
Should the test of part a still be conducted? Ex- 
32.0 
83.0 
160 
160.0 
plain. 
c. Keeping the sample size the same, change the num- 
bers in the contingency table so that the answer 
you would get for the question posed in part a 
changes. 
8.47 Many companies use well-known celebrities in their ads, 
while other companies create their own spokespersons 
(such as the Maytag repairman). A study in the Journal 
of Marketing (Fall 1992) investigated the relationship 
between the gender of the spokesperson and the gender 
of the viewer in order to see how this relationship affect- 
ed brand awareness. Three hundred television viewers 
were asked to identify the products advertised by 
celebrity spokespersons.The results are presented in two 
tables on page 460. 
a. For the products advertised by male spokespersons, 
conduct a test to determine whether audience gen- 
der and product identification are dependent factors. 
Test using a = .05. 

458 
CHAPTER 
8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
  TAT IS TICS 
I N  k k h h  
Ethics in Computer Technology and Use 
'thics 
- 
refers to a set of rules or principles used for moral 
,decision-making. Employees in the computer industry 
ace ethical problems every day in the workplace. Illegal 
nd improper actions are practiced knowingly and unknow- 
ngly by computer technology users. Some recent examples 
,f unethical practices include Robert Morris's introduction 
~f a "worm" into the Internet and software copyright in- 
ringements by several reputable colleges and universities. 
Professors Margaret A. Pierce and John W. Henry of 
;eorgia Southern University explored the ethical decision- 
naking behavior of users of computers and computer tech- 
lology and published their results in the Journal of 
3usiness Ethics (Vol. 15, 1996). Three primary influencing 
actors were considered by Pierce and Henry: (1) the indi- 
idual's own personal code of ethics; (2) any informal code 
~f ethical behavior that is operative in the workplace; and 
3) the company's formal code of computer ethics (i.e., poli- 
ies regarding computer technology). 
The researchers mailed a computer ethics questionnaire 
o a random sample of 2,551 information systcms (IS) pro- 
essionals selected from members of the Data Processing 
danagement Association (DPMA). The issues and questions 
~ddressed are given in Figure 8.8. Approximately 14% of the 
pestionnaires were returned, yielding a total of 356 usable 
responses. Table 8.11 gives a breakdown of the respondents 
by industry type. Tables 8.12 (What Type of Code Is Impor- 
tant in Making Ethical Decisions?) and 8.13 (Which Code 
Do You Use?) summarize the responses to two questions 
and their relationship to the three influencing factors identi- 
fied by the researchers. (The tables show the number of re- 
sponses in each category. Due to nonresponse for some 
questions, the sample size is less than 356.) 
F o c u s  
a. Does the existence of a company code of ethics influ- 
ence computer users' perceptions of the importance of 
formal, informal, and personal ethics codes? If so, inves- 
tigate the pattern of dependence by plotting the appro- 
priate percentages on a graph. 
b. Does the position of the computer user (professional or 
employee) influence the use of formal, informal, and per- 
sonal ethics codes? If so, investigate the pattern of depen- 
dence by plotting the appropriate percentages on a graph. 
c. With respect to industry typc, is the sample of returned 
questionnaires rcpresentative of the 2,551 IS profes- 
sionals who were mailed the survey? Explain. 
Part I. Please answer the following statements/questions regarding ethics. In all parts of this survey "ethics" is defined as 
ethics related to computer technology/computer use. "Your company" refers to the organization or educational institution 
where you work. 
1. Gender: Female 
male 
2. Your age on your last birthday. 
3. Education 
(1) high school 
(2) 2-yr college 
(3) 4-yr college 
(Please circle the highest level attained.) 
(4) master's 
(5) doctorate 
4. Circle the category which best describes 
(1) CS/MIS educator 
(2) other educator 
(3) programmer 
your position. 
(4) DP manager 
(5) system supervisor 
(6) other 
5. Do you hold any professional certification or license? (1) no 
(2) yes, please specify 
6. Number of years: (1) in profession 
(2) with present employer 
7. Type of company you work for: 
(1) Manufacture (2) Government 
(3) Education 
(4) Finance 
(Please circle one or specify.) 
(5) Utilities 
(6) Service 
(7) Consulting 
(8) Wholesale/retail 
(9) Other (specify) 
8. Size of company (Number of employees) 
9. Do you think of yourself as (Please circle one.) (1) DP/computer professional (2) an employee of the company 
10. Circle the professional organizations listed to which you belong. 
(1) DPMA 
(2) ACM 
(3) IEEE-CS 
11. (a) Are you familiar with any of the codes of ethics of the above professional organizations? 
(1) yes 
(2) no 
(b) If yes which one@)? 
(1) DPMA 
(2) ACM 
(3) IEEE-CS 
(c) If yes do you use the code(s) to guide your own behavior? 
(1) yes 
(2) no 
12. Have you had any formal study concerning theories of ethics or ethical behavior? 
(I) yes 
(2) no 
-- - 
IGURE 8.8 
Computer ethics questionnaire, Part I 

I 
SECTION 8.4 
C o n t i n g e n c y  T a b l e  A n a l y s i s  
459 
Part II. Please respond to the following statements/questions about a formal company code of ethics (stated in writing or 
orally, representing the official position of the company), an informal code of ethics (ethical behavior actually practiced in 
the workplace), and a personal code of ethics (your own principles) related to computer use/computer technology. 
1. Does your company have a formal company code of ethics? 
(I) yes 
(2) no 
(If there is a written code, please include a copy of the code.) 
2. Which code of ethics is most important in guiding 
(1) formal code 
(2) informal code 
(3) personal code 
the behavior of employees where you work? 
(if there is one) 
3. Which code of ethics do you use most 
(I) formal code 
(2) informal code 
(3) personal code 
frequently to guide ethical decisions? 
(if there is one) 
4. These codes of ethics are deterrents to unethical behavior. 
a. formal company code of ethics 
strongly agree 
1 
2 
3 
4 
5 
strongly disagree 
b. informal code of ethics 
strongly agree 
1 
2 
3 
4 
5 
strongly disagree 
c. personal code of ethics 
strongly agree 
1 
2 
3 
4 
5 
strongly disagree 
5. There are opportunities in my company 
strongly agree 
1 
2 
3 
4 
5 
strongly disagree 
to engage in unethical behavior. 
6. Many people in my company engage in what 
strongly agree 
1 
2 
3 
4 
5 
strongly disagree 
I consider unethical behavior. 
7.1 am aware of the specifics of the 
strongly agree 
1 2 
3 
4 
5 
strongly disagree 
informal company code of ethics. 
8.1 have a well-formulated personal code of ethics 
strongly agree 
1 2 
3 
4 
5 
strongly disagree 
related to computer use/computer technology 
FIGURE 8.8 
Computer ethics questionnaire, Part II 
Source: Margaret A. Pierce and John W. Henry, "Conputer ethics: The role of personal, informal, and formal codes," lournal of Business 
Ethics, Vol. 1514, 1996, pp. 425-437. Reprinted with kind permission of Kluwer Academic Publishers, Margaret Pierce, and John W. Henry. 
Industry Type 
Number Returned 
Percent in Original Sample of 2,551 
Manufacturing 
DP ServiceIConsult 
Utilities 
WholesaleIRetail 
FinancialIReal Estate 
Education/Medical/Legal 
Government 
Other 
Total 
356 
100.0 
Source: Pierce, M .  A,. and Henry, J. W. "Computer ethics: The role of personal, informal, and formal 
codes." Journal of'Bu.sinr.s.s Ethics, Vol. 15,1996, p. 429 (Table I). 
Company Code 
Code 
Yes 
N o  
Formal 
51 
Informal 
47 
Personal 
70 
Source: Pierce, M. A,, and Henry, J. W. "Computer ethics: The 
role of personal, informal, and formal codes." .lournal of 
Business Ethics, Vol. 15,1996, p. 431 (Table 11). 
Ethics Code 
I 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , 
Formal 
Informal 
Personal 
Source: Pierce, M. A., anc 
role of personal, informal 
Business Ethics, Vol. 15,l 

460 
CHAPTER 
8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
b. Repeat part a for the products advertised by female 
8.48 To study the extent and nature of strategic planning 
being undertaken by boards of directors, A. Tashakori 
spokespersons. 
c. How would you interpret these results? 
Male Spokesperson 
Audience Gender 
Male 
Female 
Total 
....................................................................................................... 
Identified Product 
95 
41 
136 
Could Not Ident$yi%d.yct 
55 
109 
164 
................................................... b. ...................................................... 
Total 
f \  
150 
150 
300 
m M A A q p d  
........................................................................................................... 
Female Spokesperson 
.............................................................................................................. 
Audience Gender 
Male 
Female 
Total 
.............................................................................................................. 
Identified Product 
47 
61 
108 
Could Not Identify Product 
103 
89 
192 
.............................................................................................................. 
Total 
150 
150 
300 
SAS Output for Exercise 8.48 
and W. Boulton questioned a sample of 119 chief exec- 
utive officers of major U.S. corporations (Jolirnal of 
Business Strategy, Winter 1983). One objective was to 
determine if a relationship exists between the compo- 
sition of a board-i.e., 
a majority of oulside directors 
versus a majority of in-house directors-and 
its level of 
participation in the strategic planning process. The 
questionnaire data were used to classify the responding 
corporations according to the level of their board's par- 
ticipation in the strategic planning process as follows: 
Level 1: Board participates in formulation or imple- 
mentation or evaluation of strategy 
Level 2: Board participates in formulation and imple- 
mentation, formulation and evaluation, or implemen- 
tation and evaluation of strategy 
Level 3: Board participates in formulation, implemen- 
tation, and evaluation of strategy 
The 119 boards were also classified according to 
whether a majority of their directors were from inside 
the firm or outside the firm.The data are summarized in 
the SAS printout below. 
a. The researchers concluded that a relationship exists 
between a board's level of participation in the strate- 
gic planning process and the composition of the 
TABLE OF LEVEL BY COMPOSIT 
LEVEL 
COMPOSIT 
Frequency: 
I I 
I 
I 
Expected :INSIDE :OUTSIDE 
Total 
STATISTICS FOR TABLE OF LEVEL BY COMPOSIT 
Chi-square 
2 
4.976 
0.083 
Likelihood Ratio Chi-square 
2 
4.696 
0.096 
Mantel-Haenszel Chi-square 
1 
0.120 
0.729 
Phi Coefficient 
0.204 
Contingency Coefficient 
0.200 
Cramer's V 
0.204 
Sample Size = 119 

board. Do you agree? Construct the appropriate con- 
tingency table, and test using a = .lo. 
h. In the context of this problem, specify the Type I and 
Type I1 errors associated with the test of part a. 
c. Construct a graph that helps to interpret the result of 
the test in part a. 
8.49 Research has indicated that the stress produced by 
today's lifestyles results in health problems for a large 
proportion of society. An article in the International 
Journal of Sports Psychology (July-Sept. 1990) evaluat- 
ed the relationship between physical fitness and stress. 
Five hundred forty-nine employees of companies that 
participate in the Health Examination Program offered 
Services (HAS) were classi- 
fitness levels: good, average, 
Q u i c k  R e v i e w  
461 
and poor. Each person was tested for signs of stress. The 
table reports the results for the three groups. [Note: The 
proportions given are the proportions of the entire 
group that show signs of stress and fall into each partic- 
ular fitness level.] Do the data provide evidence to indi- 
cate that the likelihood for stress is dependent on an 
employee's fitness level? 
Proportions with 
Fitness Level 
Sample Size 
Signs of Stress 
........... . ............................................................................................. 
Poor 
242 
.I55 
Average 
212 
.I33 
Good 
95 
.lo8 
Key Terms 
Chi-square distribution 438 
Expected cell count 440 
Observed cell count 447 
Chi-square test 438 
Independence of two classifications 446 
One-way table 440 
Contingency table 445 
Marginal probabilities 445 
Sampling distribution of j& - p2 429 
Count data 437 
Multinomial experiment 437 
Two-way table 445 
Dimensions of classification 445 
Multinomial probability distribution 437 
Key Formulas 
x: = 
[n, - E(n,)I2 
E(nJ 
where n, = count for cell i 
E(n,) = np, 0 
plJ, = hypothesized value of p, in H, 
x! z 
[n,, - &,,)12 
& 4 , )  
where n,, = count for cell in row i, column j 
= r,c,ln 
r, = total for row i 
c, = total for column j 
n = total sample size 
Confidence interval for p, - p2 430 
Test statistic for H,: (p, - p,) = 0 431 
Sample size for estimating p, - p2 436 
X 2  test for one-way table 440 
X 2  test for two-way table 450 

I 
SECTION 8.4 
C o n t i n g e n c y  T a b l e  A n a l y s i s  
459 
Part II. Please respond to the following statements/questions about a formal company code of ethics (stated in writing or 
orally, representing the official position of the company), an informal code of ethics (ethical behavior actually practiced in 
the workplace), and a personal code of ethics (your own principles) related to computer use/computer technology. 
1. Does your company have a formal company code of ethics? 
(1) yes 
(2) no 
(If there is a written code, please include a copy of the code.) 
2. Which code of ethics is most important in guiding 
(1) formal code 
(2) informal code 
the behavior of employees where you work? 
(if there is one) 
3. Which code of ethics do you use most 
(1) formal code 
(2) informal code 
frequently to guide ethical decisions? 
(if there is one) 
4. These c
y
 
of 
deterrents to unethical behavior. 
a. formal ompany co 
of ethics 
stronglyagree 
1 
2 
3 
4 
5 
b. informal code ohethic 
stronglyagree 
1 2 
3 
4 
5 
stronglyagree 
1 2 
3 4 
5 
stronglyagree 
1 2 
3 4 
5 
6. Many people in my company engage in what 
stronglyagree 
1 2 
3 
4 
5 
I consider unethical behavior. 
7.1 am aware of the specifics of the 
stronglyagree 
1 
2 
3 
4 
5 
informal company code of ethics. 
8.1 have a well-formulated personal code of ethics 
stronglyagree 
1 2 
3 
4 
5 
related to computer use/computer technology 
(3) personal code 
(3) personal code 
strongly disagree 
strongly disagree 
strongly disagree 
strongly disagree 
strongly disagree 
strongly disagree 
strongly disagree 
I 
FIGURE 8.8 
Computer ethics questionnaire, Part I1 
I 
Source: Margaret A. Pierce and John W. Henry, "Conputer ethics: The role of personal, informal, and formal codes," lournal of Business 
Ethics, Vol. 1514, 1996, pp. 425-437. Reprinted with kind permission of Kluwer Academic Publishers, Margaret Pierce, and John W. Henry. I 
I 
TABLE 
8.1 1 
TABS-11.DAT 
Industry Type 
Number Returned 
Percent in Original Sample of 2,551 
........................................................................................................................................................................................... 
Manufacturing 
67 
19 
DP ServiceIConsult 
57 
16 
Utilities 
20 
5.5 
Wholesale/Retail 
18 
5 
FinancialIReal Estate 
42 
12 
EducationIMedicallLegal 
80 
22 
Government 
21 
6 
Other 
51 
14.5 
Total 
356 
100.0 
Source: Pierce, M. A,, and Henry, J. W. "Computer ethics: The role of personal, informal, and formal 
codes." Journal of Businexs Ethics, Vol. 15,1996, p. 429 (Table I). 
Company Code 
Code 
Yes 
N o  
Formal 
Informal 
Personal 
-- 
Position 
........................................................................ 
Ethics Code 
IS Professional 
Employee 
.................................................................................................................. 
Formal 
27 
2 
Informal 
34 
5 
Personal 
208 
63 
I 
Source: Pierce, M. A., and Henry, J. W. "Computer ethics: The 
I 
role of personal, informal, and formal codes." .lournu1 of 
I 
Business Ethics, Vol. 15,1996, p. 431 (Table 11). 
Source: Pierce, M. A., and Henry, J. W. "Computer ethics: The 
role of personal, informal, and formal codes." Journul of 
Business Ethics, Vol. 15, 1996,~. 432 (Table IV). 

462 
CHAPTER 
8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
Symbol 
Pronunciation 
p, - p, 
p-1 minus p-2 
PI - j?, 
p-l hat minus p-2 hat 
u 
slgma of p-1 hat minus p-2 hat 
Do 
D naught 
( n )  
Estimated expected value of n,, 
'-1 
r-i 
c~ 
c-j 
Description 
.......................................................................................................................................................... 
Difference between population proportions 
Difference between sample proportions 
Standard deviation of the sampling distribution of (F, - a) 
Hypothesized value of p, - p, 
Value of multinomial probability p, hypothesized in H, 
Test statistic used in analysis of count data 
Number of observed outcomes in cell i of one-way table 
Expected number of outcomes in cell i of one-way table when H, is true 
Probability of an outcome in row i and column j of a two-way contingency table 
Number of observed outcomes in row i and column j of a two-way 
contingency table 
Estimated expected number of outcomes in row i and column j of a two-way 
contingency table 
Total number of outcomes in row i of a contingency table 
Total number of outcomes in column j of a contingency table 
Learning the Mechanics 
8.50 Independent random samples were selected from two 
binomial populations. The sizes and number of 
observed successes for each sample are shown in the 
table below. 
8.52 A random sample of 250 observations was classified 
according to the row and column categories shown in 
the table. 
Sample 1 
Sample 2 
a. Test H,: (p, - p,) = 0 against Ha: (pl - p2) < 0. 
Use a = .lo. 
b. Form a 95% confidence interval for (p, - p2). 
c. What sample sizes would be required if we wish to 
use a 9.5% confidence interval of width .O1 to esti- 
mate ( P I  - ~
2
)
 
? 
8.51 A random sample of 150 observations was classified 
into the categories shown in the table below. 
LM8-5l.DAT 
........................................................................................................... 
Category 
a. Do the data provide sufficient evidence that the 
categories are not equally likely? Use a = .lo. 
b. Form a 90% confidence interval for p,, the probabil- 
ity that an observation will fall in category 2. 
Column 
1 
20 
20 
10 
Row 
2 
10 
20 
70 
3 
20 
50 
30 
a. Do the data provide sufficient evidence to conclude 
that the rows and columns are dependent? Test using 
a = .05. 
b. Would the analysis change if the row totals were 
fixed before the data were collected? 
c. Do the assumptions required for the analysis to be 
valid differ according to whether the row (or col- 
umn) totals are fixed? Explain. 
d. Convert the table entries to percentages by using 
each column total as a base and calculating each 
row response as a percentage of the correspond- 
ing column total. In addition, calculate the row to- 
tals and convert them to percentages of all 250 
observations. 
e. Plot the row percentages on the vertical axis agains~ 
the column number on the horizontal axis. Draw hor- 
izontal lines corresponding to the row total percent- 
ages. Does the deviation (or lack thereof) of the 
individual row percentages from the row total per- 
. 
centages support the result of the test conducted m 
part a? 

S u p p l e m e n t a r y  E x e r c i s e s  
463 
Applying the Concepts 
8.53 According to a national survey of 1,441 firms by the 
American Management Association, downsizing is no 
longer the dominant theme in the workplace (Newark 
Star-Ledger, Oct. 22,1996). But are there regional differ- 
ences in this phenomenon? Is there more growth in jobs 
in the Sunbelt than the Rustbelt? Assuming equal sample 
sizes for the two regions, how large would the samples 
in the proportion of 
next year in the two 
interval of width no more 
of life in California, 
where scientists have warned about "the big one" for 
decades. An article in the Annals of the Association of 
American Geographers (June 1992) investigated what 
influences homeowners in purchasing earthquake insur- 
ance. One factor investigated was the proximity to a 
major fault.The researchers hypothesized that the nearer 
a county is to a major fault, the more likely residents are 
to own earthquake insurance. Suppose that a random 
sample of 700 earthquake-insured residents from four 
California counties is selected, and the number in each 
county is counted and recorded in the table: 
Contra Santa 
Los 
San 
Costa 
Clara Angeles Bernardino 
Number Insured 
103 
213 
241 
143 
a. What are the appropriate null and alternative hy- 
potheses to test whether the proportions of all earth- 
quake-insured residents in the four counties differ? 
h. Do the data provide sufficient evidence that the pro- 
portions of all earthquake-insured residents differ 
among the four counties? Test using a = .05. 
TRAVTRIP.DAT 
.............................................................................................................. 
Number of Nights 
Preretirement 
Postretirement 
.............................................................................................................. 
4-7 
247 
172 
8-13 
82 
67 
14-21 
35 
52 
22 or more 
16 
32 
Total 
380 
323 
8.56 Because shareholders control the firm, they can transfer 
wealth from the firm's bondholders to themselves through 
several different dividend strategies This potential con- 
flict of interest between shareholders and bondholders 
can be reduced through the use of debt covenants. 
Accountants E. Griner and H. Huss of Georgia State 
University investigated the effects of insider ownership 
and the size of the firm on the types of debt covenants 
required by a firm's bondholders (Journal of Applied 
Business Research,Vol. 11,1995).As part of the study, they 
examined a sample of 31 companies whose bondholders 
required covenants based on tangible assets rather than on 
liquidity or net assets or retained earnings. Characteristics 
of those 31 firms are summarized below.The objective of 
the study is to determine if there is a relationship between 
the extent of insider ownership and the size of the firm for 
firms with tangible asset covenants. 
1NSIDOWN.DAT 
.............................................................................................................. 
Size 
..................................... 
Small 
Large 
Inside Ownership 
High 
C. Los Angeles County is closest to a major earthquake 
fault. Construct a 95% confidence interval for the 
proportion of all earthquake-insured residents in the 
four counties that reside in Los Angeles County. 
Source: Griner, E., and Huss, H. "Firm size, insider ownership; 
and accounting-based debt covenants." Journal ofApplied 
Business Research, Vol. 11, No. 4,1995, p. 7 (Table 4). 
d. Does the confidence interval you formed in part c 
support the conclusion of the test conducted in part 
b? Explain. 
855 Research indicates that the highest priority of retirees is 
travel. A study in the Annals of Tourism Research (Vol. 
19,1992) investigates the relationship of retirement status 
(pre- and postretirement) to various items related to the 
travel industry. One part of the study investigated the dif- 
ferences in the length of stay of a trip for pre- and postre- 
tirees. A sample of 703 travelers were asked how long 
they stayed on a typical trip. The results are shown in the 
next table. Use the information in the table to determine 
whether the retirement status of a traveler and the dura- 
tion of a typical trip are dependent.Test using a = .05. 
a. Assuming the null hypothesis of independence is 
true, how many firms are expected to fall in each cell 
of the table above? 
b. The researchers were unable to use the chi-square 
test to analyze the data. Show why. 
c. A test of the null hypothesis can be conducted using 
a small-sample method known as Fisher's exact test. 
This method calculates the exact probability (p- 
value) of observing sample results at least as contra- 
dictory to the null hypothesis as those observed for 
the researchers' data. The researchers reported the 
p-value for this test as ,0043. Interpret this result. 
d. Investigate the nature of the dependence exhibited by 
the contingency table by plotting the appropriate con- 
tingency table percentages. Describe what you find. 

464 
CHAPTER 
8 C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
8.57 Over the years, pollsters have found that the public's 
confidence in big business is closely tied to the eco- 
nomic climate. Harvcy Kahalas hypothesized that there 
is a relationship between the level of conl~dence in 
business and job satisfaction, and that this is true for 
both union and nonunion workers (Baylor Business 
Studies, Feb.-Apr. 1981). He analyzed sample data col- 
lected by the National Opinion Research Center 
les at the bottom of the page) and 
not supported. Do 
SPSS prmtouts on 
appropriate tests using a = .05. 
null and alternative hypotheses. 
day when accidents 
are most likely to occur, extra precautions can be insti- 
tuted during those times. A random sampling of the 
accident reports over the last year at a plant gives the 
frequency of occurrence of accidents during the differ- 
ent hours of the workday. Can it be concluded from the 
JANINDIC.DAT 
.............................................................................................................. 
Next 11 -Month Change 
......................................................... 
UP 
Down 
UP 
January Change 
Down 
25 
9 
a. Examine the contingency table. Based solely on your 
visual inspection, do the data appear to confirm the 
validity of the January indicator? Explain. 
b. Construct a plot of the percentage of years for 
which the 11-month movement is up based on the 
January change. Compare these two percentages 
to the percentage of times the market moved up 
during the last 11 months over all years in the sam- 
ple. What do you think of the January indicator 
data in the table that the proportions of accidents are 
now'! 
different for at least two of the four time periods? 
c. If a chi-square test of independence is to be used to 
investigate the January indicator, what are the ap- 
JOBACC.DAT 
propriate null and alternative hypotheses? 
......................................................................................................... 
d. Conduct the test of part c. Use a = .05. Interpret 
Hours 
1-2 
3 4  
5-6 
7-8 
your results in the context of the problem. 
......................................................................................................... 
Number of Accidents 
31 
28 
45 
47 
e. Would you get the same result in part d if a = .I0 
were used? Explain. 
8.59 Many investors believe that the stock market's direc- 
8.60 An economist was interested in knowing whether sons 
tional change in January signals the market's direction 
have a tendency to choose the same occupation as their 
for the remainder of the year. But is this "January" indi- 
fathers. To investigate this question, 500 males were 
cator valid? The table at right summarizes the relevant 
polled and each questioned concerning his occupation 
changes in the Dow Jones Industrial Average for the 
and the occupation of his father. A summary of the 
pried December 31,1927, through January 31,1981. J. 
numbers of father-son pairs falling in each occupation- 
Martmch appl~ed the chi-square test of mdependence 
a1 category 1s shown In the table on p. 466. Do the datd 
to these data to ~nvest~gate 
the January ~nd~cator 
( M d  
provide suttic~ent ev~dence at a = .05 to md~cate a 
South Busmess Journa1,Vol. 4,1984). 
dependence between a son's cho~ce of occupat~on and 
4 
i 
................................................................................................................................................................................................................................................... 
Job Satisfaction 
................................................................................................................................................................
Very Satisfied 
Moderately Satisfied 
A Little Dissatisfied Very Dissatisfied 
................................................................................................................................................................................................................................................... 
Union Member 
A Great Deal 
26 
15 
2 
1 
Confidence in 
Only Some 
95 
73 
16 
5 
Major Corporations 
Hardly Any 
34 
28 
10 
9 
I 
NONUNION.DAT 
...........................................................................................................................................................................................................................................
Job Satisfaction 
i 
I 
................................................................................................................................................................ 
Very Satisfied Moderately Satisfied A Little Dissatisfied Very Dissatisfied 
................................................................................................................................................................................................................................................... 
Nonunion Confidence A Great Deal 
111 
52 
12 
4 
246 
142 
37 
18 
in Major Corporations Only Some 
Hardly Any 
73 
51 
19 
9 

S u p p l e m e n t a r y  E x e r c i s e s  
SPSS Output for Exercise 8.57 
MIONCON by JOBSAT 
JOBSAT 
Little I Moderate 
Count 
Exp Val 
Row 
Total 
JNIONCON - 
OnlySome 
Column 
Total 
Chi-square 
Value 
---------- 
DF 
- - - - 
?earson 
13.36744 
6 
Likelihood Ratio 
12.08304 
6 
rlinimum Expected Frequency - 
2.102 
Significance 
------------ 
.03756 
.06014 
:ells with Expected Frequency < 5 - 
3 OF 
12 (25.0%) 
................................................................................ 
IOUNCON by JOBSAT 
Count 
Exp Val 
Row 
Total 
17 9 
23.1% 
152 
19.6% 
443 
57.2% 
774 
100.0% 
Very 
111 
99.4 
Little 
IOUNCON 
GreatDeal 
OnlySome 
I 
I 
Moderate 
Column 
Total 
None 
Significance 
------------ 
.I4088 
.I4449 
Chi-square 
----------------- --- 
Value 
---------- 
Pearson 
9.63514 
Likelihood Ratio 
9.55907 
linimum Expected Frequency - 
6.088 

466 
CHAPTER 
8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
SAS Output for Exercise 8.60 
TABLE OF FATHER BY SON 
FATHER 
SON 
Frequency 1 
I 
I 
I 
I 
Expected ;Farmer j prof /BUS j Skill 
j~nskill 
j 
Total 
STATISTICS FOR TABLE OF FATHER BY SON 
Chi-square 
9 180.874 
0.000 
Likelihood Ratio Chi-square 
9 160.832 
0.000 
Mantel-Haenszel Chi-square 
1 
52.040 
0.000 
Phi Coefficient 
0.601 
Contingency Coefficient 
0.515 
Cramer's V 
0.347 
Sample Size = 500 
Son 
.................................................................................................................... 
Professional or Business 
Skilled 
Unskilled 
Farmer 
Professional or Business 
55 
38 
7 
0 
Father 
Skilled 
79 
71 
25 
0 
Unskilled 
22 
75 
38 
10 
Farmer 
15 
23 
10 
32 
his father's occupation? Use the SAS printout at the 
top of the page to conduct the analysis. 
8.61 Wcstinghouse Electric Company has experimented with 
different means of evaluating the performance of solder 
joint inspectors. One approach involves comparing an 
individual inspector's classifications with those of the 
group of experts that comprise Westinghouse's Work 
Standards Committee. In one experiment conducted by 
Westinghouse, 153 solder connections were cvaluated 
by the committee and 111 were classified as acceptable. 
An inspector evaluated the same 153 connections and 
classified 124 as acceptable. Of the items rejected by the 
inspector, the committee agreed with 19. 
a. Construct a contingency table that summarizes the 
classifications of the committee and the inspector. 
b. Based on a visual examination of the table you con- 
structed in part a, does it appear that there is a rela- 
tionship between the inspector's classifications and 
the committee's? Explain. (A plot of the percentage 
rejected by cornmittcc and inspector will aid your 
examination.) 
c. Conduct a chi-square test of independence for these 
data. Use a = .05. Carefully interpret the results of 
your test in the context of the problem. 
8.62 Despite company policies allowing unpaid family leave 
for new fathers, many men fear that exercising this 
option would be held against them by their superiors 
(Minneapolis Star-Tribune, Fcb. 14, 1993). In a random 
sample of 100 male workers planning to become fatherc. 
35 agreed with the statement "If I knew there would be 

, 
S u p p l e m e n t a r y  E x e r c i s e s  
467 
no repercussions, I would choose to participate in the 
family leave program after the birth of a son or daugh- 
ter." However, of 96 men who became fathers in the pre- 
vious 16 months, only nine participated in the program. 
a. Specify the appropriate null and alternative hy- 
potheses to test whether the sample data provide 
sufficient evidence to reject the hypothesis that the 
proportion of new fathers participating in the pro- 
gram is the same as the proportion that would like to 
participate. Define any symbols you use. 
b. Are the sample sizes large enough to conclude that 
the sampling distribution of (a, - a2) is approxi- 
mately normal? 
c. Conduct the hypothesis test using a = .05. Report 
the observed significance level of the test. 
d. What assumptions must be satisfied for the test to be 
valid'? 
8.63 Product or service quality is often defined as fitness for 
use. This means the product or service meets the cus- 
tomer's needs. Generally speaking, fitness for use is 
based on five quality characteristics: technological (e.g., 
strength, hardness), psychological (taste, beauty), time- 
oriented (reliability), contractual (guarantee provi- 
sions), and ethical (courtesy, honesty). The quality of a 
service may involve all these characteristics, while the 
quality of a manufactured product generally depends 
on technological and time-oriented characteristics 
(Schroeder, Operations Management, 1993). After a 
barrage of customer complaints about poor quality, a 
manufacturer of gasoline filters for cars had its quality 
inspectors sample 600 filters-200 
per work shift-and 
check for defects.The data in the table resulted. 
FILTER.DAT 
............................................................... 
Shift 
Defectives Produced 
................................................................ 
First 
25 
Second 
35 
Third 
80 
a. Do the data indicate that the quality of the filters 
being produced may be related to the shift producing 
the filter? Test using a = .05. 
b. Estimate the proportion of defective filters pro- 
duced by the first shift. Use a 95% confidence 
interval. 
8.64 What makes entrepreneurs different from chief execu- 
tive officers (CEOs) of Fortune 500 companies? The 
Wall Street .Ic&nal 
hired the Gallup organization to 
investigate this question. For the study, entrepreneurs 
were defined as chief executive officers of companies 
listed by Inc. magazine as among the 500 fastest-growing 
smaller companies in the United States. The Gallup 
organization sampled 207 CEOs of Fortune 500 compa- 
nies and 153 entrepreneurs. They obtained the results 
shown in the table below. 
a. In each of the three areas-age, education, and em- 
ployment record-are 
the sample sizes large enough 
to use the inferential methods of this chapter to in- 
vestigate the differences between Fortune 500 CEOs 
and entrepreneurs? Justify your answer. 
b. Test to determine whether the data indicate that the 
fractions of CEOs and entrepreneurs who have been 
fired or dismissed from a job differ at the a = .O1 
level of significance. 
c. Construct a 99% confidence interval for the differ- 
ence between the fractions of CEOs and entrepre- 
neurs who have been fired or dismissed from a job. 
d. Which inferential procedure provides more informa- 
tion about the difference between employment 
records, the test of part b or the interval of part c? 
Explain. 
Variable 
Fortune 500 CEOs 
Entrepreneurs 
Age 
19 
96 
Under 45 years old 
Education 
195 
116 
Completed 4 years of college 
Employment record 
19 
47 
Have been fired or dismissed from a job 
Source: Graham, E. "The entrepreneurial mystique." Wall Street Journal, May 20,1985. 

468 
CHAPTER 8 
C o m p a r i n g  P o p u l a t i o n  P r o p o r t i o n s  
eal-World Case: Discrimination in the Workplace 
(A Case Covering Chapter 8) 
'tle VII of the Civil Rights Act of 1964 prohibits dis- 
crimination in the workplace on the basis of race, 
T 
color, religion, gender, or national origin. The Age 
Discrimination in Employment Act of 1967 (ADEA) pro- 
tects workers age 40 to 70 against discrimination based on 
age. The potential for discrimination exists in such process- 
es as hiring, promotion, compensation, and termination. 
In 1971 the U.S. Supreme Court established that em- 
ployment discrimination cases fall into two categories: dis- 
parate treatment and disparate impact. In the former, the 
issue is whether the employer intentionally discriminated 
against a worker. For example, if the employer considered 
an individual's race in deciding whether to terminate him, 
the case is one of disparate treatment. In a disparate impact 
case, the issue is whether employment practices have an 
adverse impact on a protected group or class of people, 
even when the employer does not intend to discriminate. 
Disparate impact cases almost always involve the use of 
statistical evidence and expert testimony by professional 
statisticians. Attorneys for the plaintiffs frequently use hy- 
pothesis test results in the form of p-values in arguing the 
case for their clients. 
Table C4.1 was recently introduced as evidence in a race 
case that resulted from a round of layoffs during the down- 
sizing of a division of a computer manufacturer. The com- 
pany had selected 51 of the division's 1,215 employees to 
lay off. The plaintiffs-in 
this case 15 of the 20 African 
Americans who were laid off-were 
suing the company for 
$20 million in damages. 
The company's lawyers argued that the selections fol- 
lowed from a performance-based ranking of all employees. 
The plaintiffs legal team and their expert witnesses, citing 
the results of a statistical test of hypothesis, argued that lay- 
offs were a function of race. 
The validity of the plaintiffs interpretation of the data i 
dependent on whether the assumptions of the test are met ir 
this situation. In particular, like all hypothesis tests present 
ed in this text, the assumption of random sampling mus 
hold. If it does not, the results of the test may be due to thc 
violation of this assumption rather than to discrimination. 11 
general, the appropriateness of the testing procedure is de 
pendent on the test's ability to capture the relevant aspect! 
of the employment process in question (DeGroot, Fienberg 
and Kadane, Statistics and the Law, 1986). 
Prepare a document to be submitted as evidence in thc 
case (i.e., an exhibit), in which you evaluate the validity 01 
the plaintiffs' interpretation of the data. Your evaluatior 
should be based in part on your knowledge of the process. 
es companies use to lay off employees and how well thost 
processes are reflected in the hypothesis-testing procedure 
employed by the plaintiffs. 
PART II: AGE DISCRIMINATION- 
You BE THE JUDGE 
In 1996, as part of a significant restructuring of product 
lines, AJAX Pharmaceuticals (a fictitious name for a real 
company) laid off 24 of 55 assembly-line workers in its 
Pithburgh manufacturing plant. Citing the ADEA, 11 of 
the laid-off workers claimed they were discriminated 
against on the basis of age and sued AJAX for $5,000,000. 
Management disputed the claim, saying that since the work- 
ers were essentially interchangeable, they had used random 
sampling to choose the 24 workers to be terminated. 
Table C4.2 lists the 55 assembly-line workers and identl- 
fies which were terminated and which remained active. 
Plaintiffs are denoted by an asterisk. These data were used 
by both the plaintiffs and the defendants to determine 
whether the layoffs had an adverse impact on workers age 
40 and over and to establish the cred~bility of manage- 
ment's random sampling claim. 
TABLE 
C4.1 
Summary of Downsizinq Data for Race Case 
Decision 
Retained 
Laid off 
........... . .......... . ..... ..... ............................... . ...... .......... . ...................................................... 
RACE 
White 
Black 
Source: Confidential personal communication with k? George Benson, 1997. 

S u p p l e m e n t a r y  Exercises 
469 
TABLE 
C4.2 
Data for Age Discrimination Case 
Yearly 
Employment 
Employee 
Wages 
Age 
Status 
. . . . , , . . . . . , . , . , . . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
*Adler, C.J. 
Alario, B.N. 
Anders, J.M. 
Bajwa, K.K. 
Barny, M.L. 
*Berger, R.W. 
Brenn, L.O. 
Cain, E.J. 
Carle, W.J. 
Castle, A.L. 
Chan, S.D. 
Cho, J.Y. 
Cohen, S.D. 
Darel, F.E. 
*Davis, D.E. 
*Dawson, P.K. 
Denker, U.H. 
Dorando, T.R. 
Dubois, A.G. 
England, N. 
Estis, K.B. 
Fenton, C.K. 
Finer, H.R. 
*Frees, O.C. 
Gary, J.G. 
Gillen, D.J. 
Harvey, D.A. 
Higgins, N.M. 
Terminated 
Active 
Active 
Active 
Active 
Terminated 
Active 
Terminated 
Active 
Active 
Terminated 
Active 
Active 
Active 
Terminated 
Terminated 
Active 
Active 
Active 
Active 
Active 
Active 
Terminated 
Terminated 
Terminated 
Active 
Terminated 
Active 
Yearly 
Employment 
Employee 
Wages 
Age 
Status 
................... .... ..................................................................................... 
*Huang, T.J. 
Jatho, J.A. 
Johnson, C.H. 
Jurasik, T.B. 
Klein, K.L. 
Lang,T.F. 
Liao, P.C. 
*Lostan, W.J. 
Mak, G.L. 
Maloff, V.R. 
McCall, R.M. 
*Nadeau, S.R. 
*Nguyen, O.L. 
Oas, R.C. 
*Patel, M.J. 
Porter, K.D. 
Rosa, L.M. 
Roth, J.H. 
Savino, G.L. 
Scott, I.W. 
Smith, E.E. 
Teel, Q.V. 
*Walker, F.O. 
Wang, T.G. 
Yen, D.O. 
Young, N.L. 
Zeitels, P.W. 
Terminated 
Active 
Active 
Active 
Terminated 
Active 
Active 
Terminated 
Terminated 
Terminated 
Terminated 
Terminated 
Terminated 
Active 
Terminated 
Terminated 
Active 
Terminated 
Active 
Terminated 
Active 
Active 
Terminated 
Active 
Terminated 
Active 
Active 
*Denotes plaintiffs 
Using whatever statistical methods you think are appro- 
priate, build a case that supports the plaintiffs' position. 
(Call documents related to this issue Exhibit A.) Similarly, 
build a case that supports the defendants' position. (Call 
these documents Exhibit B.) Then discuss which of the two 
cases is more convincing and why. [Note: The data for this 
case are available in the file DISCRIM.DAT, described in 
the table.] 
DISCRIM.DAT (Number of observations: 55) 
Variable 
Colurnn(s) 
Type 
LASTNAME 
1-10 
QL 
WAGES 
15-19 
QN 
AGE 
35-36 
QN 
STATUS 
47 
QL (A = active, 
T = terminated) 

S I M P L E  L I N E A R  R E G R E S S I O N  
( 
C O N T E N T S  
............................................................... 
9.1 
Probabilistic Models 
9.2 
Fitting the Model: The Least Squares Approach 
9.3 
Model Assumptions 
9.4 
An Estimator of a2 
, 9.5 
Assessing the Utility of the Model: Making Inferences About the Slope PI 
9.6 
The Coefficient of Correlation 
9.7 
The Coefficient of Determination 
9.8 
Using the Model for Estimation and Prediction 
9.9 
Simple Linear Regression: A Complete Example 
9.10 
A Nonparametric Test for Correlation (Optional) 
I 
S T A T I S T I C S  
I
N
 A
C
T
I
O
N
 
.............................................................................................................. 
.... 
Can "Dowsers" Really Detect Water? 
F 
Where W  
n 
W 
e've learned how to estimate and test hy- 
potheses about population parameters based 
on a random sample of observations from the popu- 
lation. We've also seen how to extend these meth- 
ods to allow for a comparison of parameters from 
two populations. 
7, 
, ' 
" 
r 
W h e r e  W e ' r e  G o i n g  
S 
uppose we want to predict the assessed value of a 
house in a particular community. We could select 
a single random sample of n houses from the com- 
munity, use the methods of Chapter 5 to estimate the 
mean assessed value p, and then use this quantity to 
predict the house's assessed value. A better method 
uses information that is available to any property ap- 
praiser, e.g., square feet of floor space and age of the 
house. If we measure square footage and age at the 
same time as assessed value, we can establish the re- 
lationship between these variables-one 
that lets us 
use these variables for prediction. This chapter cov- 
ers the simplest situation-relating 
two variables. 
The more complex problem of relating more than 
two variables is the topic of Chapter 10. 

472 
CHAPTER 
9 
S i m p l e  L i n e a r  Regression 
In Chapters 5-7 we described methods for making inferences about popu- 
lation means. The mean of a population was treated as a constant, and we 
showed how to use sample data to estimate or to test hypotheses about this con- 
stant mean. In many applications, the mean of a population is not viewed as a 
constant, but rather as a variable. For example, the mean sale price of residences 
sold this year in a large city can be treated as a constant and might be equal to 
$150,000. But we might also treat the mean sale price as a variable that de- 
pends on the square feet of living space in the residence. For example, the rela- 
tionship might be 
Mean sale price = $30,000 + $60(Square feet) 
This formula implies that the mean sale price of 1,000-square-foot homes is 
$90,000, the mean sale price of 2,000-square-foot homes is $150,000, and the mean 
sale price of 3,000-square-foot homes is $210,000. 
What do we gain by treating the mean as a variable rather than a constant? 
In many practical applications we will be dealing with highly variable data, data 
for which the standard deviation is so large that a constant mean is almost "lost" 
in a sea of variability. For example, if the mean residential sale price is $150,000 
but the standard deviation is $75,000, then the actual sale prices will vary consid- 
erably, and the mean price is not a very meaningful or useful characterization of 
the price distribution. On the other hand, if the mean sale price is treated as a vari- 
able that depends on the square feet of living space, the standard deviation of sale 
prices for any given size of home might be only $10,000. In this case, the mean 
price will provide a much better characterization of sale prices when it is treated 
as a variable rather than a constant. 
In this chapter we discuss situations in which the mean of the population is 
treated as a variable, dependent on the value of another variable. The depen- 
dence of residential sale price on the square feet of living space is one illustration. 
Other examples include the dependence of mean sales revenue of a firm on ad- 
vertising expenditure, the dependence of mean starting salary of a college gradu- 
ate on the student's GPA, and the dependence of mean monthly production of 
automobiles on the total number of sales in the previous month. 
In this chapter we discuss the simplest of all models relating a population 
mean to another variable, the straight-line model. We show how to use the sample 
data to estimate the straight-line relationship between the mean value of one 
variable, y, as it relates to a second variable, x. The methodology of estimating and 
using a straight-line relationship is referred to as simple linear regression analysis. 
PROBABILISTIC MODELS 
An important consideration in merchandising a product is the amount of money 
spent on advertising. Suppose you want to model the monthly sales revenue of an 
appliance store as a function of the monthly advertising expenditure. The first 
question to be answered is this: "Do you think an exact relationship exists be- 
tween these two variables?" That is, do you think it is possible to state the exact 
monthly sales revenue if the amount spent on advertising is known? We think you 
will agree with us that this is not possible for several reasons. Sales depend on 
many variables other than advertising expenditure-for 
example, time of year, the 
state of the general economy, inventory, and price structure. Even if many vari- 
ables are included in a model (the topic of Chapter lo), it is still unlikely that we 

SECTION 
9.1 
P r o b a b i l i s t i c  M o d e l s  
473 
would be able to predict the monthly sales exactly. There will almost certainly be 
some variation in monthly sales due strictly to random phenomena that cannot be 
modeled or explained. 
If we were to construct a model that hypothesized an exact relationship be- 
tween variables, it would be called a deterministic model. For example, if we be- 
lieve that y, the monthly sales revenue, will be exactly fifteen times x, the monthly 
advertising expenditure, we write 
This represents a deterministic relationship between the variables y and x. It im- 
plies that y can always be determined exactly when the value of x is known. There 
is no allowance for error in this prediction. 
If, on the other hand, we believe there will be unexplained variation in 
monthly sales-perhaps 
caused by important but unincluded variables or by ran- 
dom phenomena-we 
discard the deterministic model and use a model that ac- 
counts for this random error. This probabilistic model includes both a 
deterministic component and a random error component. For example, if we hy- 
pothesize that the sales y is related to advertising expenditure x by 
y = 15x + Random error 
we are hypothesizing a probabilistic relationship between y and x. Note that the 
deterministic component of this probabilistic model is 15x. 
Figure 9.la shows the possible values of y and x for five different months, 
when the model is deterministic. All the pairs of (x, y) data points must fall exact- 
ly on the line because a deterministic model leaves no room for error. 
FIGURE 9.1 
Y 
Y 
Possible sales 
A 
A 
revenues, y, for five 
Deterministic component 
different months, x 
4000 - 
Random error 
I . 
x 
. X  
0 
100 
200 
300 
0 
100 
200 
700 
a. Deterministic model: 
b. Probabilnt~c model: 
y = 15x 
y = 15x + Random error 
Figure 9.lb shows a possible set of points for the same values of x when 
we are using a probabilistic model. Note that the deterministic part of the 
model (the straight line itself) is the same. Now, however, the inclusion of a ran- 
dom error component allows the monthly sales to vary from this line. Since we 
know that the sales revenue does vary randomly for a given value of x, the 
probabilistic model provides a more realistic model for y than does the deter- 
ministic model. 

474 
CHAPTER 9 
S i m p l e  Linear Regression 
+ Random error 
is the variable of interest. We always assume that the mean value of 
om error equals O.This is equivalent to assuming that the mean value 
),equals the deterministic component of the model; that is 
E ( ~ )  
= Determinis 
In this chapter we present the simplest of probabilistic models-the 
straight- 
line model-which 
derives its name from the fact that the deterministic portion ot 
the model graphs as a straight line. Fitting this model to a set of data is an exam- 
ple of regression analysis, or regression modeling. The elements of the straight- 
line model are summarized in the next box. 
. 
' ,  
I . 
.jj 
. , 
:" 
. . @  
A First-Order (Straight-Line) Probabilistic Model 
ere 
Dependent or response variable (variable to be modeled) 
Independent or predictor variable (variable used as a 
predictor of y)* 
E(y) = Po + Pix = Deterministic component 
Random error component 
y-intercept of the line, that is, the point at which the line 
intercepts or cuts through the y-axis (see Figure 9.2) 
Slope of the line, that is, the amount of increase (or 
decrease) in the deterministic component of y for every 
1-unit increase in x. [As you can see in Figure 9.2, 
E(y) increases by the amount P, as x increases from 
2 to 3.1 
In the probabilistic model, the deterministic component is referred to as 
the line of means, because the mean of y, E(y), is equal to the straight-line com- 
ponent of the model. That is, 
E(y) = Po + PIX 
Note that the Greek symbols 
and PI, respectively, represent the y-intercept and 
slope of the model. They are population parameters that will be known only if we 
have access to the entire population of (x, y) measurements. Together with a spe- 
cific value of the independent variable x, they determine the mean value of y, 
which is just a specific point on the line of means (Figure 9.2). 
*The word independent should not be interpreted in a probabilistic sense, as defined in Chapter 3 
The phrase ~ndependent variable is used in regression analysis to refer to a predictor variable for 
the response y. 

SECTION 9.1 
P r o b a b i l i s t i c  M o d e l s  
475 
FIGURE 9.2 
Y 
The straight-line model 
1 
3 - 
1 - 
Po = y-intercept 
I 
I 
I 
I 
X 
0 
1 
2 
3 
4 
The values of Po and PI will be unknown in almost all practical applications 
of regression analysis. The process of developing a model, estimating the unknown 
parameters, and using the model can be viewed as the five-step procedure shown 
in the next box. 
m error term and estimate 
the standard deviation of this distribution (Sections 9.3 and 9.4). 
p 4 Statistically evaluate the usefulness of the model (Sections 9.5,9.6, and 9.7). 
ep 5 When satisfied that the model 
tion, estimation, and 
other purposes (Section 9.8 
Learnina the Mechanics 
Use these two equations to solve for p, and /3,; then 
d 
9.1 
In each case, graph the line that passes through the 
find the equation of the line that 
thrdugh the 
given points. 
points (-2,4) and (4,6). 
a. (1, I) and (5,s) 
b. (0,3) and (3,O) 
9.4 
Refer to Exercise 9.3. Find the equations of the lines 
c. (-1,l) and (4.2) d. (-6, -3) and (2,6) 
that pass through the points listed in Exercise 9.1. 
9.2 
Give the slope and y-intercept for each of the lines 
9S 
the 
lines: 
graphed in Exercise 9.1. 
a . y = 4 + x  b . y = 5 - 2 x  
c. y = - 4 + 3 x  
93 
The equation for a straight line (deterministic model) is 
d. y = -2x 
e. y = x f. y = S O  + 1 . 5 ~  
9.6 
Give the slope and y-intercept for each of the lines 
Y = Po + Pix 
defined in Exercise 9.5. 
If the line passes through the point (-2, 41, then 
9.7 
Why do we generally prefer a probabilistic model to a 
x = -2, y = 4 must satisfy the equation; that is, 
deterministic model? Give examples for which the two 
types of models might be appropriate. 
4 = Po + PI(-2) 
9.8 
What is the line of means? 
Similarly, 
if the line passes through the point (4, 6), then 
9.9 
If a straight-line probabilistic relationship relates the 
x = 4, y = 6 must satisfy the equation; that is, 
mean E(y) to an independent variable x, does it imply 
that every value of the variable y will always fall exact- 
6 = Po + Pd4) 
ly on the line of means? Why or why not? 

r 
476 
CHAPTER 9 
S i m p l e  Linear Regression 
FITTING THE MODEL: THE LEAST SQUARES 
APPROACH 
After the straight-line model has been hypothesized to relate the mean E(y) to 
the independent variable x, the next step is to collect data and to estimate the (un- 
known) population parameters, the y-intercept Po and the slope P,. 
To begin with a simple example, suppose an appliance store conducts a five- 
month experiment to determine the effect of advertising on sales revenue. The re- 
sults are shown in Table 9.1. (The number of measurements and the measurements 
themselves are unrealistically simple in order to avoid arithmetic confusion in this 
introductory example.) This set of data will be used to demonstrate the five-step 
procedure of regression modeling given in Section 9.1. In this section we hypothe- 
size the deterministic component of the model and estimate its unknown parame- 
ters (steps 1 and 2). The model assumptions and the random error component 
(step 3) are the subjects of Sections 9.3 and 9.4, whereas Sections 9.5-9.7 assess the 
utility of the model (step 4). Finally, we use the model for prediction and estimation 
(step 5) in Section 9.8. 
TABLE 
9.1 
Advertisinq-Sales Data 
Month 
Advertising Expenditure, x ($100~) 
Sales Revenue, y ($1,000~) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1 
1 
1 
2 
2 
1 
3 
3 
2 
4 
4 
2 
5 
5 
4 
Step 1 Hypothesize the deterministic component of the probabilistic model. As 
stated before, we will consider only straight-line models in this chapter. 
Thus, the complete model to relate mean sales revenue E ( y )  to 
advertising expenditure x is given by 
Step 2 Use sample data to estimate unknown parameters in the model. This step is 
the subject of this section-namely, how can we best use the information 
, - 
in the sample of five observations in Table 9.1 to estimate the unknown y- 
intercept Po and slope PI? 
To determine whether a linear relationship between y and x is plausible,it is 
helpful to plot the sample data in a scattergram. Recall (Section 2.10) that a scat- 
tergram locates each of the five data points on a graph, as shown in Figure 9.3. 
FIGURE 9 . 3  
Scattergram for data in Table 9.1 

SECTION 9.2 
Fitting t h e  Model: The Least S q u a r e s  Approach 
477 
Note that the scattergram suggests a general tendency for y to increase as x in- 
creases. If you place a ruler on the scattergram, you will see that a line may be 
drawn through three of the five points, as shown in Figure 9.4. To obtain the equa- 
tion of this visually fitted line, note that the line intersects the y-axis at y = -1, so 
the y-intercept is -1. Also,y increases exactly 1 unit for every 1-unit increase in x, 
indicating that the slope is + 1. Therefore, the equation is 
where 
is used to denote the predicted y from the visual model. 
Visual straight line fitted to the data in Figure 9.3 
One way to decide quantitatively how well a straight line fits a set of data is 
to note the extent to which the data points deviate from the line. For example, to 
evaluate the model in Figure 9.4, we calculate the magnitude of the deviations, i.e., 
the differences between the observed and the predicted values of y. These devia- 
tions, or errors of prediction, are the vertical distances between observed and 
predicted values (see Figure 9.4). The observed and predicted values of y, their dif- 
ferences, and their squared differences are shown in Table 9.2. Note that the sum 
of errors equals 0 and the sum of squares of the errors (SSE), which gives greater 
emphasis to large deviations of the points from the line, is equal to 2. 
TABLE 
9.2 
Comparing Observed and Predicted Values 
for the Visual Model 
X 
y y = - l + x  
( Y  - 7) 
( Y  - 7)2 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . - 
1 
1 
0 
(1 - 0) = 1 
1 
2 
1 
1 
1 - 1 = 0 
0 
3 
2 
2 
(2 - 2) = 0 
0 
4 
2 
3 
(2 - 3) = -1 
1 
5 
4 
4 
(4 - 4) = 0 
0 
Sum of errors = 0 
Sum of squared errors (SSE) = 2 
You can see by shifting the ruler around the graph that it is possible to find 
many lines for which the sum of errors is equal to 0, but it can be shown that there 
is one (and only one) line for which the SSE is a minimum. This line is called the 
least squares line, the regression line, or the least squares prediction equation. The 
methodology used to obtain this line is called the method of least squares. 
To find the least squares prediction equation for a set of data, assume that we 
have a sample of n data points consisting of pairs of values of x and y, say (x,, y,), 
(x2, y2), . . ., (xn, yn). For example, the n = 5 data points shown in Table 9.2 are 

478 
CHAPTER 9 
S i m p l e  L i n e a r  R e g r e s s i o n  
(1, I), (2, I), (3,2), (4,2), and (5,4).The fitted line, which we will calculate based on 
the five data points, is written as 
The "hats" indicate that the symbols below them are estimates: jj (y-hat) is an es- 
timator of the mean value of y, E(y), and a predictor of some future value of y; 
and PO and PI are estimators of Do and Dl, respectively. 
For a given data point, say the point (xi, 
y,), the observed value of y is yi and 
the predicted value of y would be obtained by substituting xi into the prediction 
equation: 
And the deviation of the ith value of y from its predicted value is 
Then the sum of squares of the deviations of the y-values about their predicted 
values for all the n points is 
The quantities PO and PI that make the SSE a minimum are called the least 
squares estimates of the population parameters Po and PI, and the prediction 
equation 
= Po + 8,x is called the least squares line. 
EFlNlTlON 9.1 
e least squares line y^ = 8, + p,x is one that has the following two prop- 
. the sum of the errors (SE) equals 0 
. the sum of squared errors (SSE) is smaller than for any other straight-line 
model 
The values of PO and 3, that minimize the SSE are (proof omitted) given by 
the formulas in the box.* 
Preliminary computations for finding the least squares line for the advertis- 
ing-sales example are presented in Table 9.3. We can now calculate 
*Students who are familiar with calculus should note that the values of Po and P, that minlmize 
SSE = C(y, - ?J2 are obtained by setting the two partial derivatives aSSE/dp, and dSSE/dp, 
equal to 0 The solut~ons to these two equations yield the formulas shown In the box 
Furthermore, we denote the wmnple solutions to the equations by p,, and i,, 
where the "hat" 
denotes that these are sample estimates of the true population intercept Po and true populat~on 
slope P,. 

SECTION 
9.2 
Fitting t h e  Model: The Least S q u a r e s  Approach 
479 
TABLE 
9.3 
Preliminary Computations for Advertising-Sales Example 
Totals 
Exi= 
15 
E Y, = 10 
x: = 55 
c xiyi = 37 
Then the slope of the least squares line is 
and the y-intercept is 
The least squares line is thus 
The graph of this line is shown in Figure 9.5. 
The predicted value of y for a given value of x can be obtained by substitut- 
ing into the formula for the least squares line. Thus, when x = 2 we predict y to be 

480 
CHAPTER 9 
Simple Linear Regression 
FIGURE 9.5 
Y 
The line j = -.l 
+ .7x fitted to the data 
9 " ,' 
1 
0 
X 
-1 
We show how to find a prediction interval for y in Section 9.8. 
The observed and predicted values of y, the deviations of the y values about 
their predicted values, and the squares of these deviations are shown in Table 9.4. 
Note that the sum of squares of the deviations, SSE, is 1.10, and (as we would ex- 
pect) this is less than the SSE = 2.0 obtained in Table 9.2 for the visually fitted line. 
TABLE 
9.4 
Comparing Observed and Predicted Values for the Least 
Squares Prediction Equation 
X 
Y 
^y = -.l + .7x 
(Y - 7) 
(Y - ?I2 
- - -  
Sum of errors = 0 
SSE = 1.10 
The calculations required to obtain so, PI, and SSE in simple linear regres- 
sion, although straightforward, can become rather tedious. Even with the use of a 
pocket calculator, the process is laborious and susceptible to error, especially when 
the sample size is large. Fortunately, the use of a statistical software package can 
significantly reduce the labor involved in regression caIculations. The SAS output 
for the s e l e  linear regression of the data in Table 9.1 is displayed in Figure 9.6. The 
values of /3, and PI are highlighted on the SAS printout under the Parameter Es- 
timate column in the rows labeled INTERCEP and X, respectively. These values, 
A p, = - .1 and 6, = .7, agree exactly with our hand-calculated values. The value of 
SSE = 1.10 is also highlighted in Figure 9.6, under the Sum of Squares column in 
the row labeled Error. 
Whether you use a hand calculator or a computer, it is important that you be 
able to interpret the intercept and slope in terms of the data being utilized to fit 
the model. In the advertising-sales example, the estimated y-intercept, Po = -.I, 
appears to imply that the estimated mean sales revenue is equal to -.I, or -$loo, 
when the advertising expenditure, x, is equal to $0. Since negative sales revenues 
are not possible, this seems to make the model nonsensical. However, the model 
parameters should be inrerpreted only within the sampled range of the independet~t 
variable-in 
this case, for advertising expenditures between $100 and $500.Thus. 
the y-intercept-which is, by definition, at x = 0 ($0 advertising expenditure)-is 
not within the range of the sampled values of x and is not subject to meaningful 
interpretation. 

SECTION 
9.2 
Fitting t h e  Model: The Least S q u a r e s  A p p r o a c h  
481 
SAS printout for advertising-sales regression 
A 
The slope of the least squares line, PI = .7, implies that for every unit in- 
crease of x, the mean value of y is estimated to increase by .7 unit. In terms of this 
example, for every $100 increase in advertising, the mean sales revenue is esti- 
mated to increase by $700 over the sampled range of advertising expenditures from 
$100 to $500. Thus, the model does not imply that increasing the advertising ex- 
penditures from $500 to $1,000 will result in an increase in mean sales of $3,500, 
because the range of x in the sample does not extend to $1,000 ( x  = 10). Be care- 
ful to interpret the estimated parameters only within the sampled range of x. 
Dependent Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
1 
4.90000 
4.90000 
13.364 
0.0354 
Error 
3 
1.10000 
0.36667 
, 
CTotal 
4 
6.00000 
Root MSE 
0.60553 
R-square 
0.8167 
Dep Mean 
2.00000 
Adj R-sq 
0.7556 
C.V. 
30.27650 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Variable DF 
Estimate 
Error Parameter=O 
Prob>lTI 
INTERCEP 
1 
-0.100000 
0.63508530 
-0.157 
0.8849 
X 
1 
0.700000 
0.19148542 
3.656 
0 .0354 
phing Calculator 
Straight-Line (Linear) Regression on the TI-83 
A. Finding the least squares regression equation 
Step 1 Enter the data 
Press STAT 1 for STAT Edit 
Enter your x-data in L1 and your y-data in L2. 
Step 2 Fmd the equation 
Press STAT and highlight CALC 
Press 4 for LinReg(ax + b) 
Press ENTER 
The screen will show the values for a and b in the equation y = ax + b. 
Example: The figures below show a table of data entered on the TI-83 and the 
regression equation obtained using the steps given above. 
(coiltinued) 

482 
CHAPTER 9 
S i m p l e  L i n e a r  Regression 
B. Finding rand r2 
(Note: We discuss these statistics in Sections 9.6 and 9.7.) 
If r aod r2 do not already appear on the LinReg screen from part A, 
Step 1 Turn the diagnostics feature on 
. 
Press 2nd 0 for CATALOG 
. 
Press the X-' key for D 
Press down the arrow key until Diagnosticson is highlighted 
Press ENTER twice - 
Step 2 Find the regression equation as shown in partA above 
The values for rand r2 will appear on the screen as well. 
Example: The figures below show a table of data entered on theTI-83 and the 
regression equation, r, and r2 obtained using the steps given above. 
C. Graphing the least squares line with the I
scatterplot 
Step 1 Enter the data as shown in part A above 
Step 2 Set up the data plot 
Press 2nd Y= for STATPLOT 
' 
Press 1 for PLOT1 
Use the arrow and ENTER keys to set up the screen as shown below. 
I 
. . 
I 
I 
Step 3 Find the regression equation as shown in partA above 
Step 4 Enter the regression equation 
Press Y= 
Press VARS 5 for Statistics . . . 
Highlight EQ and press ENTER 
You should see the regression equation in the Y= window. 
(continued) 

SECTION 9.2 
Fitting t h e  M o d e l :  T h e  L e a s t  S q u a r e s  A p p r o a c h  
483 
Step 5 View the scatterplot and regression lzne 
Press ZOOM 9 for ZoomStat 
You should see the data graphed alongSwith the regression line. 
Example: The figures below show a table of data entered on the TI-83, and the 
graph of the scatterplot and !east squares line obtained using the steps 
given above. 
Even when the interpretations of the estimated parameters are meaningful, 
we need to remember that they are only estimates based on the sample. As such, 
their values will typically change in repeated sampling. How much confidence do 
we have that the estimated slope, B,, 
accurately approximates the true slope, P,? 
This requires statistical inference, in the form of confidence intervals and tests of 
hypotheses, which we address in Section 9.5. 
To summarize, we defined the best-fitting straight line to be the one that 
minimizes the sum of squared errors around the line, and we called it the least 
squares line. We should interpret the least squares line only within the sampled 
range of the independent variable. In subsequent sections we show how to make 
statistical inferences about the model. 
Learning the Mechanics 
9.10 The following table is similar to Table 9.3. It is used for 
making the preliminary computations for finding the 
least squares line for the given pairs of x and y values. 
9.11 Refer to Exercise 9.10. After the least squares line has 
been obtained, the table below (which is similar to Table 
9.4) can be used for (1) comparing the observed and the 
predicted values of y, and (2) computing SSE. 
X
Y
Y
 
(Y - Y )  
(Y - 32 
a. Complete the table. 
b. Find SS,,. 
c. Find SS,,. 
d. Find 6,. 
e. Find i and L. 
f. Find &. 
g. Find the least squares line. 
(Y - $) = 
SSE = 
( y  - F)' = 
a. Complete the table. 
b. Plot the least squares line on a scattergram of the 
data. Plot the following line on the same graph: 
$ = 14 - 2 . 5 ~  
c. Show that SSE is larger for the line in part b than it is 
for the least squares line. 

484 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
9.12 Construct a scattergram for the data in the following 
table. 
a. Plot the following two lines on your scattergram: 
y = 3 - x  
and 
y = l + x  
b. Which of these lines would you choose to characterize 
the relationship between x and y? Explain. 
c. Show that the sum of errors for both of these lines 
equals 0. 
d. Which of these lines has the smaller SSE? 
e. Find the least squares line for the data and compare 
it to the two lines described in part a. 
9.13 Consider the following pairs of measurements: 
a. Construct a scattergram for these data. 
b. What does the scattergram suggest about the rela- 
tionship between x and y? 
c. Find the least squares estimates of P,, and P, on the 
MINITAB printout below. 
d. Plot the least squares line on your scattergram. Does 
the line appear to fit the data well? Explain. 
e. Interpret the y-intercept and slope of the least 
squares line. Over what range of x are these inter- 
pretations meaningful? 
Applying the Concepts 
9.14 The quality of the orange juice produced by a manufac- 
turer (e.g., Minute Maid,Tropicana) is constantly moni- 
tored. There are numerous sensory and chemical 
components that combine to make the best tasting 
MINITAB Output for Exercise 9.1 3 
orange juice. For example, one manufacturer has devel- 
oped a quantitative index of the "sweetness" of orange 
juice. (The higher the index, the sweeter the juice.) Is 
there a relationship between the sweetness index and a 
chemical measure such as the amount of water soluble 
pectin (parts per million) in the orange juice? Data col- 
lected on these two variables for 24 production runs at a 
juice manufacturing plant are shown in the table. 
Suppose a manufacturer wants to use simple linear 
regression to predict the sweetness (y) from the amount 
of pectin (x). 
O.JUICE.DAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Run 
Sweetness Index 
Pectin (ppm) 
Note: The data in the table are authentic. For 
confidentiality reasons, the manufacturer cannot 
be disclosed. 
The regression equation is 
Y = 8.54 - 0.994 X 
Predictor 
Coef 
Stdev 
Constant 
8.543 
1.117 
X 
-0.9939 
0.2208 
s = 1.069 
R-sq = 80.2% 
Analysis of Variance 
SOURCE 
DF 
SS 
Regression 
1 
23 .I44 
Error 
5 
5.713 
Total 
6 
28.857 
t-ratio 
P 
7.65 
0.001 
-4.50 
0.006 

SECTION 9.2 
F i t t i n g  t h e  M o d e l :  T h e  L e a s t  S q u a r e s  A p p r o a c h  
485 
a. Find the le_ast squ_ares line for the data. 
b. Interpret P,, and PI in the words of the problem. 
c. Predict the sweetness index if amount of pectin in the 
orangc juice is 300 ppm. [Note: A measure of reliabili- 
ty of such a prediction is discussed in Section 9.81 
9.15 Is the number of games won by a major league baseball 
team in a season related to the team's batting average? 
The information in the table, extracted from Sports 
Illustrated and Sporting News, shows the number of 
games won and the batting average for the 14 teams in 
the American League for the 1998 season. 
Team 
Games Won 
Batting Ave. 
New York 
114 
.288 
Toronto 
88 
.266 
Baltimore 
79 
.273 
Bmton 
92 
.280 
Tampa Bay 
63 
.261 
Cleveland 
89 
.272 
Detroit 
65 
.264 
Chicago 
80 
.271 
Kansas City 
72 
.263 
Minnesota 
70 
.266 
Anaheim 
85 
.272 
Texas 
88 
.289 
Seattle 
76 
.276 
Oakland 
74 
.257 
Sources Sports Illustrated and Sporting News, March 29,1999. 
a. If you were to model the relationship between the 
mean (or expected) number of games won by a major 
league team and the team's batting average, x, using a 
SPSS Output for Exercise 9.1 5 
straight line, would you expect the slope of the line to 
be positive or negative? Explain. 
b. Construct a scattergram of the data. Does the pat- 
tern revealed by the scattergram agree with your-an- 
swer in part a? 
c. An SPSS printout of the simple linear regression is 
provided below. Find the estimates of the>% on the 
printout and write the equation of the least squares 
line. 
d. Graph the least squares line on the scattergram. 
Does the least squares line seem to fit the poi& on 
the scattergram? 
e. Does the mean (or expected) number of games won 
appear to be strongly related to a team's batting av- 
erage? Explain. 
f. Interpret the values of p, and El in the words of the 
problem. 
9.16 Refer to the Forbes magazine (Jan. 11,1999) report on 
the financial standings of each team in the National 
Football League (NFL), Exercise 2.113 (p. 113). The 
table listing the current value (without deduction for 
debt, except stadium debt) and operating income for 
each team is reproduced on page 486. 
a. Propose a straight-line model relating an NFL team's 
current value (y) to its operating income (x). 
b. Fit the model to the data using the method of least 
squares. 
c. Interpret the least squares estimates of the slope and 
y-intercept in the words of the problem. 
9.17 In recent years US. banks have been merging to form 
mega banks that span many states.The table on page 486, 
extracted from the Journal of Banking and Finance (Feb. 
1999) lists the number of U.S. bank mergers each year 
from 1980 (year 1) to 1993 (year 14) for which $50 million 
or more changed hands in the transaction. 
Equation Number 1 
Dependent Variable.. 
WINS 
Block Number 1. 
Method: Enter 
BATAVE 
Variable(s) Entered on Step Number 
1.. 
BATAVE 
Multiple R 
.76684 
R Square 
.58804 
Adjusted R Square 
.5537i 
Standard Error 
8.78666 
Analysis of Variance 
DF 
Sum of Squares 
Mean Square 
Regression 
1 
1322.46420 
1322.46420 
Residual 
12 
926.46437 
77.20536 
------------------- Variables in the Equation------------------- 
Variable 
B 
SE B 
Beta 
T 
Sig T 
BATAVE 
1057.367150 
255.480401 
.766839 
4.139 
.0014 
(Constant) -205.777174 
69.347955 
-2.967 
.0118 

486 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
NFLVALUE.DAT 
........................................................................................................... 
Current 
Operating 
Value 
Income 
Team 
($ millions) 
($ millions) 
Dallas Cowboys 
663 
Washington Redskins 
607 
Tampa Bay Buccaneers 
502 
Carolina Panthers 
488 
New England Patriots 
460 
Miami Dolphins 
446 
Denver Broncos 
427 
Jacksonville Jaguars 
419 
Baltimore Ravens 
408 
Seattle Seahawks 
399 
Pittsburgh Steelers 
397 
Cincinnati Bengals 
394 
St. Louis Rams 
390 
New York Giants 
376 
San Francisco 49ers 
371 
Tennessee Titans 
369 
New York Jets 
363 
Kansas City Chiefs 
353 
Buffalo Bills 
326 
San Diego Chargers 
323 
Green Bay Packers 
320 
Philadelphia Eagles 
318 
New Orleans Saints 
315 
Chicago Bears 
313 
Minnesota Vikings 
309 
Atlanta Falcons 
306 
Indianapolis Colts 
305 
Arizona Cardinals 
301 
Oakland Raiders 
299 
Detroit Lions 
293 
Source: Forbes, Jan. 11,1999. 
STATlSTlX Output for Exercise 9.1 8 
ERGERS.DAT 
................................................... 
Year 
Number of Bank Mergers 
.................................................................... 
1 
4 
2 
17 
3 
19 
4 
45 
5 
25 
6 
37 
7 
44 
8 
35 
9 
27 
10 
31 
11 
21 
12 
38 
13 
45 
14 
49 
Source: Esty, B., Narasimhan, B., and 
Tufano P., "Interest-Rate Exposure and 
Bank Mergers," Journal of Bankzng and 
Fznance, Vol. 23, No. 2-4,Feb. 1999,p 264. 
a. Construct a scattergram for the data, where y = num- 
ber of mergers and x = year. Is there visual evidence 
of a linear relationship between x and y? Explain. 
b. Use the method of least squares to fit a straight line 
to the data. 
c. Graph the least squares line on your scattergram. 
d. According to the least squares line, how many 
mergers will occur in 1994 (year 15)? 
Compare your answer to the actual number of 1994 
mergers: 42. 
9.18 Due primarily to the price controls of the Organization 
of Petroleum Exporting Countries (OPEC), a cartel 
of crude-oil suppliers, the price of crude oil rose 
UNWEIGHTED LEAST SQUARES LINEAR REGRESSION OF GASOLINE 
PREDICTOR 
VARIABLES 
COEFFICIENT 
STD ERROR 
STUDENT'S T 
P 
- - - - - - - - - 
----------- 
- - - - - - - - - 
----------- 
------ 
CONSTANT 
30.1348 
5.45403 
5.53 
0.0000 
CRUDEOIL 
3.01815 
0.26542 
11.37 
0.0000 
R-SQUARED 
0.8660 
RESID. MEAN SQUARE (MSE) 
80.2262 
ADJUSTED R-SQUARED 
0.8593 
STANDARD DEVIATION 
8.95691 
CASES INCLUDED 22 
MISSING CASES 0 

SECTION 9.2 
F i t t i n g  t h e  M o d e l :  T h e  Least Squares Approach 
487 
dramatically from the mid-1970s to the mid-1980s. As a 
result, motorists saw an upward spiral in gasoline 
prices. The data in the table below are typical prices 
for a gallon of regular leaded gasoline and a barrel of 
crude oil (refiner acquisition cost) for the years 
1975-1996. 
Year 
Gasoline, y (centslgal.) 
Crude Oil, x ($/bbl.) 
1975 
57 
10.38 
1976 
59 
10.89 
1977 
62 
11.96 
1978 
63 
12.46 
1979 
86 
17.72 
1980 
119 
28.07 
1981 
131 
35.24 
1982 
122 
31.87 
1983 
116 
28.99 
1984 
113 
28.63 
1985 
112 
26.75 
1986 
86 
14.55 
1987 
90 
17.90 
1988 
90 
14.67 
1989 
100 
17.97 
1990 
115 
22.23 
1991 
72 
16.54 
1992 
71 
15.99 
1993 
75 
14.24 
1994 
67 
13.21 
1995 
63 
14.63 
1996 
72 
18.56 
Source. U.S. Bureau of the Census, Statistical Abstract of the 
Unlted States 1982-1 998. 
a. Use the STATISTIX printout on p. 486 to find the 
least squares line that describes the relationship be- 
tween the price of a gallon of gasoline and the price 
of a barrel of crude oil over the 22-year period. 
b. Construct a scattergram of all the data. 
C. Plot your least squares line on the scattergram. Does 
your least squares line appear to be an appropriate 
characterization of the relationship between y and x 
over the 22-year period? 
d. According to your model, if the price of crude oil 
fell to $15 per barrel, to what level (approximately) 
would the price of regular leaded gasoline fall'? Jus- 
tify your answer. 
9.19 Individuals who report perceived wrongdoing of a cor- 
poration or public agency are known as whistle blowers. 
Two researchers developed an index to measure the 
extent of retaliation against a whistle blower (Journal 
ofApplied Psychology, 1986). The index was based on 
the number of forms of reprisal actually experienced, 
the number of forms of reprisal threatened, and the 
number of people within the organization (e.g., 
coworkers or immediate supervisor) who retaliated 
against them. The next table lists the retaliation index 
Retaliation lndex 
Salary 
Retaliation lndex 
Salary 
.............................................................................................................. 
301 
$62,000 
535 
$19,800 
550 
36,500 
455 
44,000 
755 
21,600 
615 
46,600 
327 
24,000 
700 
15,100 
500 
30,100 
650 
70,000 
377 
35,000 
630 
21,000 
290 
47,500 
360 
16,900 
452 
54,000 
Source: Data adapted from Near, J. P., and Miceli, M. P. "Retaliation 
against whistle blowers: Predictors and effects." Journal ofApphed 
Psychology,Vol. 71, No 1,1986, pp. 137-145. 
(higher numbers indicate more extensive retaliation) 
and salary for a sample of 15 whistle blowers from fed- 
eral agencies. 
a. Construct a scattergram for the data. Does it appear 
that the extent of retaliation increases, decreases, or 
stays the same with an increase in salary? Explain. 
b. Use the method of least squares to fit a straight line 
to the data. 
c. Graph the least squares line on your scattergram. 
Does the least squares line support your answer to 
the question in part a? Explain. 
d. Interpret the y-intercept, P,,, of the least squares line 
in terms of this application. Is the interpretation 
meaningful? 
e. Interpret the slope, El, of the least squares line in 
terms of this application. Over what range of x is this 
interpretation meaningful? 
9.20 Sales and Marketing Management determined the 
"effective buying income" (EBI) of the average house- 
hold in a state. Can the EBI be used to predict retail 
sales per household in the store-group category "eating 
and drinking places"? 
a. Use the data for 13 states given in the table on 
page 488 to find the least squares line relating retail 
sales per household ('y) to average household EBI (x). 
b. Plot the least squares line, as well as the actual data 
points, on a scattergram. 
c. Based on the graph, part b, give your opinion regard- 
ing the predictive ability of the least squares line. 
The downsizing and restructuring that took place in cor- 
porate America during the 1990s encouraged both laid 
off middle managers and recent graduates of business 
schools to become entrepreneurs and start their own busi- 
nesses. Assuming a business start-up does well, how fast 
will it grow? Can it expect to need 10 employees in three 
years or 50 or 100? To answer these questions, a random 
sample of 12 firms were drawn from the Znc. Magazine's 
"1996 Ranking of the Fastest-Growing Private 
Companies in America."The age (in years since 1995), x, 
and number of employees (in 1995), y, of each firm are 

488 
CHAPTER 9 
S i m p l e  L i n e a r  R e g r e s s i o n  
EBI.DAT 
Average Household 
Retail Sales: Eating and Drinking 
State 
Buying Income ( 8 )  
Places ($ per household) 
Connecticut 
New Jersey 
Michigan 
Minnesota 
Florida 
South Carolina 
Mississippi 
Oklahoma 
Texas 
Colorado 
Utah 
California 
Oregon 
Source Sales and Marketing Management, 1995. 
INCU.DAT 
Firm 
Age, x 
Number of 
(years) 
Employees, y 
General Shelters of Texas 
5 
Productivity Point International 
5 
K.C. Oswald 
4 
Multimax 
7 
Pay + Benefits 
5 
Radio Spirits 
6 
KRA 
14 
Consulting Partners 
5 
Apex Instruments 
7 
Portable Products 
6 
Progressive System Technology 
5 
Viking Components 
7 
Source: Inc. 500, October 22,1996, pp. 103-132. 
SAS Output for Exercise 9.21 
recorded in the table at left. SAS was used to conduct a 
simple linear regression analysis for the model, 
E(y) = Po + Pix. The printout is shown below. 
a. Plot the data in a scattergram. Does the number of 
employees at a fast-growing firm appear to increase 
linearly as the firm's age increases? 
b. Find the estimates of Po and PI in the SAS printout. 
Interpret their values. 
Dependent Variable: NUMBER 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
1 23536.50149 
23536.50149 
11.451 
0.0070 
Error 
10 20554.41518 
2055.44152 
C Total 
11 44090.91667 
Root MSE 
45.33698 
R-square 
0.5338 
Dep Mean 
61.08333 
Adj R-sq 
0.4872 
C.V. 
74.22152 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Variable DF 
Estimate 
Error 
Parameter=O 
Prob > IT1 
INTERCEP 
1 
-51.361607 
35.71379104 
-1.438 
0.1809 
AGE 
1 
17.754464 
5.24673562 
3.384 
0.0070 

SECTION 9.3 
M o d e l  Assumptions 
489 
MODEL ASSUMPTIONS 
In Section 9.2 we assumed that the probabilistic model relating the firm's sales 
revenue y to the advertising dollars is 
We also recall that the least squares estimate of the deterministic component of 
the model, p, + Pix, is 
Now we turn our attention to the random component e of the probabilistic model 
and its relation to the errors in estimating po and p,. We will use a probability dis- 
tribution to characterize the behavior of c. We will see how the probability distri- 
bution of c determines how well the model describes the relationship between the 
dependent variable y and the independent variable x. 
Step 3 in a regression analysis requires us to specify the probability distri- 
bution of the random error c. We will make four basic assumptions about the gen- 
eral form of this probability distribution: 
Assumption 1: The mean of the probability distribution of e is 0. That is, the 
average of the values of E over an infinitely long series of experiments is 0 for each 
setting of the independent variable x. This assumption implies that the mean 
value of y, E(y), for a given value of x is E ( y )  = po + Pix. 
Assumption 2: The variance of the probability distribution of e is constant for 
all settings of the independent variable x. For our straight-line model, this assump- 
tion means that the variance of c is equal to a constant, say a2, for all values of x. 
Assumption 3: The probability distribution of c is normal. 
Assumption 4: The values of c associated with any two observed values of y 
are independent. That is, the value of c associated with one value of y has no 
effect on the values of c associated with other y values. 
The implications of the first three assumptions can be seen in Figure 9.7, 
which shows distributions of errors for three values of x, namely, x,, x2, and x3. 
Note that the relative frequency distributions of the errors are normal with a 
I 
errors 
I 
I 
I 
X 
X2 
X 3  
FIGURE 9.7 
Y 
The probability distribution of E ' 
E(y) when x = x, 
distribution 
Negative 

490 
CHAPTER 9 S i m p l e  L i n e a r  R e g r e s s i o n  
mean of 0 and a constant variance a2. (All the distributions shown have the same 
amount of spread or variability.) The straight line shown in Figure 9.7 is the line of 
means. It indicates the mean value of y for a given value of x. We denote this mean 
value as E(y). Then, the line of means is given by the equation 
These assumptions make it possible for us to develop measures of reliabili- 
ty for the least squares estimators and to develop hypothesis tests for examining 
the usefulness of the least squares line. We have various techniques for checking 
the validity of these assumptions, and we have remedies to apply when they ap- 
pear to be invalid. Several of these remedies are discussed in Chapter 10. Fortu- 
nately, the assumptions need not hold exactly in order for least squares estimators 
to be useful. The assumptions will be satisfied adequately for many applications 
encountered in practice. 
Elm A N  ESTIMATOR OF u2 
It seems reasonable to assume that the greater the variability of the random error 
E (which is measured by its variance a'), the greater will be the errors in the esti- 
mation of the model parameters Po and PI and in the error of prediction when j is 
used to predict y for some value of x. Consequently, you should not be surprised, 
as we proceed through this chapter, to find that a2 appears in the formulas for all 
confidence intervals and test statistics that we will be using. 
where SSE = 
(y, - 
= SS,, - &ss,, 
SS,, = 
( 2 Y
y
 
= z y : -  
To estimate the s 
d deviation a of E, we calculate 
We will refer to s as the estimated standard error of the regression model. 
n performing these calculations, you may be tempted to round 
In most practical situations, a2 is unknown and we must use our data to e\- 
timate its value. The best estimate of a2, denoted by s2, is obtained by dividing the 
sum of squares of the deviations of the y values from the prediction line, 
SSE = C (Y, - YJ2 
I 

SECTION 
9.4 
An E s t i m a t o r  of u 2  
491 
by the number of degrees of freedom associated with this quantity. We use 2 df to 
estimate the two parameters p, and p, in the straight-line model, leaving (n - 2) 
df for the error variance estimation. 
In the advertising-sales example, we previously calculated SSE = 1.10 for 
the least squares line 9 = - .1 + .7x. Recalling that there were n = 5 data points, 
we have n - 2 = 5 - 2 = 3 df for estimating a'. Thus, 
SSE 
1.10 
s 2 = - -  
- -- - .367 
n - 2  
3 
is the estimated variance, and 
s = V%? 
= .61 
is the standard error of the regression model. 
The values of s2 and s can also be obtained from a simple linear regression 
printout. The SAS printout for the advertising-sales example is reproduced in Fig- 
ure 9.8. The value of s2 is highlighted on the printout in the Mean Square column 
in the row labeled Error. (In regression, the estimate of c2 is called Mean Square 
for Error, or MSE.) The value, s2 = .36667, rounded to three decimal places 
agrees with the one calculated by hand. The value of s is highlighted in Figure 9.8 
next to the heading Root MSE. This value, s = .60553, agrees (except for round- 
ing) with our hand-calculated value. 
- -  
Dependent Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
1 
4.90000 
4.90000 
13.364 
0.0354 
Error 
3 
1.10000 
0.36667 
C Total 
4 
6.00000 
Root MSE 
0.60553 
R-square 
0.8167 
Dep Mean 
2.00000 
Adj R-sq 
0.7556 
C.V. 
30.27650 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Variable DF 
Estimate 
Error Parameter=O 
Prob > IT1 
INTERCEP 
1 
-0.100000 
0.63508530 
-0.157 
0.8849 
X 
1 
0.700000 
0.19148542 
3.656 
0.0354 
FIGURE 9.8 
SAS printout for advertising expenditure-sales revenue example 
You may be able to grasp s intuitively by recalling the interpretation of a 
standard deviation given in Chapter 2 and remembering that the least squares line 
estimates the mean value of y for a given value of x. Since s measures the spread of 
the distribution of y values about the least squares line, we should not be surprised 
to find that most of the observations lie within 2s, or 2(.61) = 1.22, of the least 
squares line. For this simple example (only five data points), all five sales revenue 

492 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
1 
I 
values fall within 2s (or $1,220) of the least squares line. In Section 9.8, we uses to 
1 
evaluate the error of prediction when the least squares line is used to predict a 
I 
value of y to be observed for a given value of x. 
! 
terpretation of s, the Estimate 
We expect most ( = 95%) of the observed y values to lie within 2s of their re- 
Learning the Mechanics 
9.22 Calculate SSE and s2 for each of t_he following cases: 
a. n = 20, SS,, = 95, SS,, = 50, P, = .75 
b. n = 40, xy2 = 860, x y  = 50, SS,r, = 2,700, 
p, = .2 
c. n = 10, x ( y i  - y)' = 58, SS,, = 91, SS,rr = 170 
9.23 Suppose you fit a least squares line to 26 data points 
and the calculated value of SSE is 8.34. 
a. Find s2, the estimator of a2 (the variance of the ran- 
dom error term E). 
b. What is the largest deviation that you might expect 
between any one of the 26 points and the least 
squares line? 
9.24 Visually compare the scattergrams shown below. If a 
least squares line were determined for each data set, 
which do you think would have the smallest variance, 
s2? Explain. 
9.25 Refer to Exercises 9.10 and 9.13. Calculate SSE, s2, and 
s for the least squarcs lines obtained in these exercises. 
Interpret the standard error of the regression model, s, 
for each. 
Applying the Concepts 
HOSPITAL.DAT 
............................................................................................................ 
Average Hospital 
Average Length 
State 
- 
Charge ($) 
of Stay (days) 
..................................................................................................... 
Massachusetts 
11,680 
3.64 
New Jersey 
11,630 
4.20 
Pennsylvania 
9,850 
3.84 
Minnesota 
9,950 
3.11 
Indiana 
8,490 
3.86 
Mich~gan 
9,020 
3.54 
Florida 
13.820 
4.08 
Georgia 
8,440 
3.57 
Tennessee 
8,790 
3.80 
Texas 
10,400 
3.52 
Arizona 
12,860 
3.77 
California 
16,740 
3.78 
Source: Statistical Bulletin, Vol. 80. No. 4,Oct.-Dec. 1999, p. 13. 
b. Use the method of least squares to model the relation- 
ship between average hospital charge ( y )  and length of 
hospital stay (x). 
c. Find the estimated standard error of the regression 
model and interpret its value in the context of the 
9.26 Statistical Bulletin (0ct.-Dec. 1999) reported the aver- 
problem. 
age hospital charge and the average length of hospital 
d. For a hospital stay of length x = 4 days, find 
stay for patients undergoing radical prostatectomies in a 
j; f 2s. 
sample of 32 states. The data are listed in the accompa- 
e. What fraction of the states in the sample have aver- 
nying table. 
age hospital charges within f 
2s of the least squares 
a. Plot the data on a scattergram. 
line? 
Scattergrams for Exercise 9.24 
a. 
Y 
b- 
Y 

SECTION 
9.4 
A n  E s t i m a t o r  of u 2  
493 
9.27 Prior to the 1970s the developing countries played a 
small role in world trade because their own economic 
policies hindered integration with the world economy. 
However, many of these countries have since changed 
their policies and vastly improved their importance to 
the global economy (World Economy, July 1992). Data 
(given in billions of U.S. dollars) for investigating the 
relationship between developing countries' and indus- 
trial countries' annual import levels are shown in the 
table above. 
a. Fit a least squares line to the data. Plot the data 
points and graph the least squares line as a check on 
your calculations. 
b. According to your least squares line, approximately 
what would you expect annual imports for develop- 
ing countries to be if annual imports for industrial 
countries were $1,600 billion? 
c. Calculate SSE and s2. 
d. Interpret the standard deviation s in the context of 
this problem. 
....................................................................................................................................................................... 
1950 
1960 
1970 
1980 
1990 
SPSS Output for Exercise 9.28 
Industrial Countries' Imports, x 
Developing Countries' Imports, y 
9.28 Refer to the simple linear regression relating games 
won by a major league baseball team y to team batting 
average x, Exercise 9.15 (p. 485). The SPSS printout is 
reproduced below. 
a. Find SSE, s2, and s on the printout. 
b. Interpret the value of s. 
9.29 Refer to the simple linear regression relating number 
of employees y to age x of a fast-growing firm, 
Exercise 9.21 (p. 487).The SAS printout is reproduced 
on the next page. 
a. Find SSE, s2, and s on the printout. 
b. Interpret the value of s. 
9.30 To improve the quality of the output of any produc- 
tion process, it is necessary first to understand the 
capabilities of the process (Gitlow, et al., Quality 
Management: Tools and Methods for Improvement, 
1995). In a particular manufacturing process, the useful 
life of a cutting tool is related to the speed at which the 
tool is operated. The data in the table on page 494 
were derived from life tests for the two different 
...................................................................................................................................................................... 
39.8 
85.4 
226.9 
1,370.2 
2,237.9 
21.1 
40.1 
75.6 
556.4 
819.4 
Equation Number 1 
Dependent Variable.. 
WINS 
Block Number 1. 
Method: 
Enter 
BATAVE 
Variable(s) Entered on Step Number 
1.. 
BATAVE 
Multiple R 
.76684 
R Square 
.58804 
Adjusted R Square 
.55371 
Standard Error 
8.78666 
Analysis of Variance 
DF 
Sum of Squares 
Mean Square 
Regression 
1 
1322.46420 
1322.46420 
Residual 
12 
926.46437 
77.20536 
Variable 
B 
SE B 
Beta 
T Sig T 
BATAVE 
1057.367150 
255.480401 
.766839 
4.139 
.0014 
(Constant) -205.777174 
69.347955 
-2.967 
-0118 

494 
CHAPTER 
9 S i m p l e  L i n e a r  R e g r e s s i o n  
SAS Output for Exercise 9.29 
Dependent Variable: 
Source 
Mode 1 
Error 
C Total 
Root MSE 
Dep Mean 
C.V. 
Variable DF 
INTERCEP 
1 
AGE 
1 
NUMBER 
Analysis of Variance 
Sum of 
Mean 
DF 
Squares 
Square 
F Value 
Prob>F 
1 23536.50149 
23536.50149 
11.451 
0.0070 
10 20554.41518 
2055.44152 
11 44090.91667 
45.33698 
R-square 
0.5338 
61.08333 
Adj R-sq 
0.4872 
74.22152 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Estimate 
Error 
Parameter=O 
Prob > IT1 
-51.361607 
35.71379104 
-1.438 
0.1809 
17.754464 
5.24673562 
3.384 
0.0070 
brands of cutting tools currently used in the produc- 
1 
CUTTOOLS.DAT 
tion process. 
................................................................................................................... 
Useful Life (Hours) 
....................................... 
Cutting Speed (meters per minute) 
Brand A 
Brand B 
................................................................................................... 
30 
4.5 
6.0 
30 
3.5 
6.5 
30 
5.2 
5.0 
40 
5.2 
6.0 
40 
4.0 
4.5 
40 
2.5 
5.0 
50 
4.4 
4.5 
50 
2.8 
4.0 
50 
1 .0 
3.7 
60 
4.0 
3.8 
60 
2.0 
3.0 
60 
1.1 
2.4 
70 
1.1 
1.5 
70 
.5 
2.0 
70 
3.0 
1.0 
a. Construct a scattergram for each brand of cutting 
tool. 
b. For each brand, the method of least squares was used 
to model the relationship between useful life and 
cutting speed. Find the least squares line for each 
brand on the EXCEL printouts shown on p. 495. 
c. Locate SSE, s2, and s for each least squares line on 
the printouts. 
d. For a cutting speed of 70 meters per minute, find 
j j  f 2s for each least squares line. 
e. For which brand would you feel more confident In 
using the least squares line to predict useful life for a 
given cutting speed? Explain. 
ASSESSING THE UTILITY OF THE MODEL: MAKING 
INFERENCES ABOUT THE SLOPE PI 
Now that we have specified the probability distribution of E and found an estimate 
of the variance a2, we are ready to make statistical inferences about the model's 
usefulness for predicting the response y. This is step 4 in our regression modeling 
procedure. 
Refer again to the data of Table 9.1 and suppose the appliance store's sales 
revenue is completely unrelated to the advertising expenditure. What could be 
said about the values of Do and 
in the hypothesized probabilistic model 

EXCEL Output for Exercise 9.30: Brand A 
EXCEL Output for Exercise 9.30: Brand B 

496 
CHAPTER 
9 
S i m p l e  Linear Regression 
I?! 
if x contributes no information for the prediction of y? The implication is that the 
mean of y-that 
is, the deterministic part of the model E(y) = p, + Pix-does 
not change as x changes. In the straight-line model, this means that the true slope, 
pi, is equal to 0 (see Figure 9.9).Therefore, to test the null hypothesis that the lin- 
ear model contributes no information for the prediction of y against the alterna- 
tive hypothesis that the linear model is useful for predicting y, we test 
H,: p, = 0 
H,: p, # 0 
FIGURE 9.9 
Y 
Graphing the P, = 0 model 
A 
y = P o + e  
. . .  
. . .  
. . . .  
P,, . 
. .  . 
. .  . 
If the data support the alternative hypothesis, we will conclude that x does con- 
tribute information for the prediction of y using the straight-line model (although 
the true relationship between E(y) and x could be more complex than a straight 
line). Thus, in effect, this is a test of the usefulness of the hypothesized model. 
The appropriate test statistic is found by considering the sampling distribu- 
tion of &, the least squares estimator of the slope PI, as shown in the following box. 
ampling Distribution of Px 
e make the four assumptions about E (see Section 9.3), the sampling dis- 
ibution of the least squares estimator 8, of the slope will be normal with 
ean p, (the true slope) and standard deviation 
0- 
up^, = ----- 
(see Figure 9.10) 
l/ss, 
S 
1 
estimate ail by SE, = 
and refer to this quantity as the estimated 
! 
andard error of the least squares slope ,&. 
Since a is usually unknown, the appropriate test statistic is a t statistic, 
I 
formed as follows: 

SECTION 9.5 
Assessing the Utility of the Model: Making Inferences About the Slope p, 
497 
pl - Hypothesized value of p, 
t =  
S 
where SF, = - 
SF, 
e 
Thus, 
Note that we have substituted the estimators for (T and then formed the estimated 
standard error sp, by dividing s by m. 
The number of degrees of freedom as- 
sociated with this t statistic is the same as the number of degrees of freedom as- 
sociated with s. Recall that this number is (n - 2) df when the hypothesized 
model is a straight line (see Section 9.4). The setup of our test of the usefulness of 
the straight-line model is summarized in the next box. 
Test of Model Utility: Simple Linear Regression 
................................................. 
" 
Ha: p, < 0 (or H,: p, > 0) 
Ha: p1 + 0 
A 
PI 
PI 
Test statistic: t = - 
= - 
Rejection region: t < - t, 
Rejection region: It 1 > t,,, 
(or t > t, when Ha: pl > 0) 
where t, and t,,, 
are based on (n - 2) degrees of freedom 
Assumptions: The four assumptions about e listed in Section 9.3. 
For the advertising-sales example, we will choose a = .05 and, since n = 5, 
twill be based on n - 2 = 3 df and the rejection region will be 
,. 
We previously calculated p1 = .7, s = .61, and SS,, = 10. Thus, 
Since this calculated t value falls in the upper-tail rejection region (see Figure 9.11), 
we reject the null hypothesis and conclude that the slope PI is not 0. The sample 
evidence indicates that advertising expenditure x contributes information for the 
prediction of sales revenue y when a linear model is used. 
We can reach the same conclusion by using the observed significance level 
(p-value) of the test from a computer printout. The SAS printout for the adver- 
tising-sales example is reproduced in Figure 9.12. The test statistic is highlighted 
on the printout under the T for HO: Parameter=O column in the row correspond- 
ing to X, while the two-tailed p-value is highlighted under the column labeled 
Prob ATI. Since the p-value = .0354 is smaller than a = .05, we will reject H,. 

CHAPTER 9 S i m p l e  L i n e a r  Regression 
FIGURE 9.1 1 
Rejection region and calculated 
t value for testing H,: p, = 0 
versus Ha: p, # 0 
1 
Dependent Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
1 
4.90000 
4.90000 
13.364 
0.0354 
Error 
3 
1.10000 
0.36667 
C Total 
4 
6.00000 
Root MSE 
0.60553 
R-square 
0.8167 
Dep Mean 
2.00000 
Adj R-sq 
0.7556 
C.V. 
30.27650 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Variable DF 
Estimate 
Error Parameter=O 
Prob > IT1 
INTERCEP 
1 
-0.100000 
0.63508530 
-0.157 
0.8849 
X 
1 
0.700000 
0.19148542 
3.656 
0.0354 
FIGURE 9.12 
SAS printout for advertising-sales example 
What conclusion can be drawn if the calculated t value does not fall in the 
rejection region or if the observed significance level of the test exceeds a? We 
know from previous discussions of the philosophy of hypothesis testing that such 
a t value does not lead us to accept the null hypothesis. That is, we do not conclude 
that 0, 
= 0. Additional data might indicate that 0, 
differs from 0, or a more com- 
plex relationship may exist between x and y, requiring the fitting of a model other 
than the straight-line model. 
Almost all statistical computer software packages report a two-tailed p-value 
for each of the parameters in the regression model. For example, in simple lin- 
ear regression, the p-value for the two-tailed test Ho: 
= 0 versus Ha: p, # 0 
given on the printout. If you want to conduct a one-tailed test of hypothesis, 
ou will need to adjust the p-value reported on the printout as follows: 
(continued) 

SECTION 9.5 
Assessing the Utility of the Model: Making Inferences About the Slope P ,  
499 
Lower-tailed test 
where p is the p- 
t is the value of the test 
statistic. 
Another way to make inferences about the slope PI is to estimate it using a 
confidence interval. This interval is formed as shown in the next box. 
pie Linear 
where the estimated standard error p, is calculated by 
and t+ is based on (n - 2) degrees of freedom. 
pti 
tion 9.3. 
For the advertising-sales example, ta12 is based on (n - 2) = 3 degrees of 
freedom. Therefore, a 95% confidence interval for the slope P,, the expected 
change in sales revenue for a $100 increase in advertising expenditure, is 
Thus, the interval estimate of the slope parameter P, is .09 to 1.31. In terms of this 
example, the implication is that we can be 95% confident that the true mean in- 
crease in monthly sales revenue per additional $100 of advertising expenditure is 
between $90 and $1,310.This inference is meaningful only over the sampled range 
of x-that 
is, from $100 to $500 of advertising expenditures. 
Since all the values in this interval are positive, it appears that P, is positive 
and that the mean of y, E(y), increases as x increases. However, the rather large 
width of the confidence interval reflects the small number of data points (and, 
consequently, a lack of information) in the experiment. Particularly bothersome is 
the fact that the lower end of the confidence interval implies that we are not 
even recovering our additional expenditure, since a $100 increase in advertising 
may produce as little as a $90 increase in mean sales. If we wish to tighten this in- 
terval, we need to increase the sample size. 
,. 
Learning the Mechanics 
a. p, = 3 1 , s =  3 , S S T , = 3 5 , n =  10 
,. 
931 Construct both a 95% and a 90% confidence interval 
h. PI = 64. SSE = 1,960, SS,, = 30, n = 14 
for p, for each of the following cases: 
c. p, = -8.4, SSE = 146, SS,, = 64, n  = 20 

500 
CHAPTER 9 
Simple L i n e a r  Regression 
P 
9.32 Consider the following pairs of observations: 
a. Construct a scattergram for the data. 
b. Use the method of least squares to fit a straight line 
to the seven data points in the table. 
c. Plot the least squares line on your scattergram of 
part a. 
d. Specih the null and alternative hypotheses you would 
use to test whether the data provide sufficient evidence 
to indicate that x contributes information for the (lin- 
ear) prediction of y. 
e. What is the test <tatistic that should be used in con- 
ducting the hypothesis test of part d? Specify the de- 
grees of freedom associated with the test statistic. 
f. Conduct the hypothesis test of part d using a = .05. 
9.33 Refer to Exercise 9.32. Construct an 80% and a 98% 
confidence interval for PI. 
9.34 Do the accompanying data provide sufficient evidence 
to conclude that a straight line is useful for characteriz- 
ing the relation5hip between x and y? 
4 
Applying the Concepts 
9.35 Some critics of big business argue that CEOs are over- 
paid and that their compensation is not related to the 
performance of their companies. To test this theory, 
Chief Executive (Sept. 1999) collected data on execu- 
tive's total pay and company's performance for each in 
a sample of 17 CEOs selected from a variety of indus- 
tries. The data are listed in the table below. (Note: 
Company performance is the three-year annualized 
total return to shareholders for the years 1996 to 1998. 
assuming dividends are reinvested.) 
a. Construct a scattergram for these data. Does it ap- 
pear that CEO pay is rclated to company perfor- 
mance? Explain. 
b. Use the method of least squares to model the rela- 
tionship between CEO pay (y) and company perfor- 
mance (x). 
c. Is CEO compensation related to company perfor- 
mance? Conduct the appropriate hypothesis test 
using a = .05. 
d. Interpret the estimate of P, in the context of the 
problem. 
1 
e. Construct a 90% confidence interval for P, and in- 
terpret your result in the context of the problem. 
f. How might the results of part e change if a sample of 
CEOs from the same industry were used'? 
9.36 Financial institutions have a legal and social responsi- 
bility to serve all communities. Do banks adequately 
serve both inner city and suburban neighborhoods, 
both poor and wealthy communities? In New Jersey. 
banks have been charged with withdrawing from urban 
I 
areas with a high percentage of minorities. To examine 
this charge, a regional New Jersey newspaper, the 
Asbury Park Press, compiled county by county data on 
the number (y) of people in each county per branch 
, 
bank in the county and the percentage ( x )  of the popu- 
Company 
Total Pay 
Performance 
CEO 
($ thousands) 
(percent) 
Cummins Engine 
James A. Hcnderson 
4,338 
Bank Of New York 
Thomas A. Renyi 
7,121 
SunTrust Banks 
L. Phillip Humann 
3,882 
Bear Stearns 
James E. Cayne 
25,002 
Charles Schwab 
Charles R. Schwab 
16,506 
Coca-Cola 
M. Douglas Ivester 
12,712 
Timc Warner 
Gcrald M. Levin 
25,136 
Humana 
Gregory H. Wolf 
4,516 
Engcl hard 
Orin R. Smith 
6,189 
Chubb 
Dean R. O'Hare 
4,052 
American Home Products 
John R. Stafford 
8,046 
Mcrck 
Raymond V. Gilmartin 
7,178 
Schering-Plough 
Richard J. Kogan 
6,818 
Home Depot 
Arthur M. Blank 
2,900 
Dell Computer 
Michael S. Dell 
115,797 
BellSouth 
F. Duane Ackerman 
18,134 
Delta Air Lines 
Leo F. Mullin 
17,085 
Source. Chlef Executive, Sept. 1999, pp. 45-59. 

SECTION 9.5 
Assessing the Utility of the Model: Making Inferences About the Slope p ,  
501 
County 
Number of People per Bank Branch 
Percentage of Minority Population 
............................................................................................................................................................................ 
Atlantic 
3,073 
23.3 
Bergen 
2,095 
13.0 
Burlington 
2,905 
17.8 
Camden 
3,330 
23.4 
Cape May 
1,321 
7.3 
Cumberland 
2,557 
26.5 
Essex 
3,474 
48.8 
Gloucester 
3,068 
10.7 
Hudson 
3,683 
33.2 
Hunterdon 
1,998 
3.7 
Mercer 
2,607 
24.9 
Middlesex 
3,154 
18.1 
Monmouth 
2,609 
12.6 
Morris 
2,253 
8.2 
Ocean 
2,317 
4.7 
Passaic 
3,307 
28.1 
Salem 
2,511 
16.7 
Somerset 
2,333 
12.0 
Sussex 
2,568 
2.4 
Union 
3,048 
25.6 
Warren 
2,349 
2.8 
Source: D'Ambrosio, P., and Chambers, S. "No checks and balances" Asbury Park Press, September 10,1995 
lation in each county that is minority. These data for 
each of New Jersey's 21 counties are provided in the 
table above. 
a. Plot the data in a scattergram. What pattern, if any, 
does the plot reveal? 
b. Consider the linear model E ( y )  = Po + Pix. If, in 
fact, the charge against the New Jersey banks is true, 
then an increase in the percentage of minorities (x) 
will lead to a decrease in the number of bank 
branches in a county and therefore will result in an 
increase in the number of people (y) per branch. Will 
the value of p, bc positive or negative in this situa- 
tion? 
c. Do these data support or refute the charge made 
against the New Jersey banking community? Test 
using a = .01. 
9.37 Tennis magazine (Feb. 2000) claims that "tennis players 
who tie the knot often see their games unravel." The 
next table lists a sample of players and their rankings on 
their wedding days and on their first anniversaries. 
a. Construct a scattergram for these data. Does it tend 
to support or refute the magazine's claim? Justify 
your answer. 
b. Use the method of least squares to construct a model 
of the relationship between wedding day ranking (x) 
and first anniversary ranking (y). 
c. Does the linear model you developed in part b con- 
tribute information for predicting players' rankings 
on their first anniversaries? Test at a = .05. 
Ranking on 
Player 
Wedding Day 
.................................................................................... 
Arthur Ashe 
12 
Jonathan Stark 
67 
Richey Reneberg 
28 
Paul Haarhuis 
28 
Richard Fromberg 
40 
Byron Black 
44 
Ranking on 
First Anniversary 
~abine 
Appelmans 
16 
49 
Pctr Korda 
7 
11 
Dominique Van Roost 
43 
46 
Ivan Lendl 
1 
3 
John McEnroe 
7 
9 
Stefan Edberg 
2 
3 
Chris Evert 
4 
4 
Mats Wilander 
3 
3 
Sandrine Testud 
14 
12 
Zina Garrison 
6 
4 
Yevgeny Kafelnikov 
8 
4 
Boris Becker 
11 
3 
Michael Stich 
15 
6 
Julie Halard-Decugis 
32 
15 
Todd Woodbridge 
71 
27 
Jason Stoltenberg 
82 
31 
Source: Tennis, Feb. 2000, p. 14. 
d. If there were no changes whatsoever in the rankings 
of the sample of players after getting married, what 
would the true values of P,, and P, be? 

502 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
9.38 The U.S. Department of Agriculture has developed 
and adopted the Universal Soil Loss Equation 
(USLE) for predicting water erosion of soils. In geo- 
graphical areas where runoff from melting snow is 
common, the USLE requires an accurate estimate of 
snowmelt runoff erosion. An article in the Journal of 
Soil and Water Conservation (Mar.-Apr. 1995) used 
simple linear regression to develop a snowmelt ero- 
sion index. Data for 54 climatological stations in 
Canada were used to model the McCool winter-adjust- 
ed rainfall erosivity index, y, as a straight-line function 
of the once-in-five-year snowmelt runoff amount, x 
(measured in millimeters). 
a. The data points are plotted in the scattergram 
shown below. Is there visual evidence of a linear 
trend? 
b. The data for seven stations were removed from the 
analysis due to lack of snowfall during the study pe- 
riod. Why is this strategy advisable? 
c. The simple linear regression on the remaining 
n = 47 data points yielded the following results: 
Use this information to construct a 90% confidence 
interval for p,. 
d. Interpret the interval, part c. 
9.39 One of the most common types of "information retrieval" 
processes is document-database searching. An experiment 
was conducted to investigate the variables that influence 
search performance in the Medline database and retrieval 
system (Journal of Information Science, Vol. 21, 1995). 
Simple linear regression was used to model the fraction y 
of the set of potentially informative documents that are 
retrieved using Medline as a function of the number x of 
terms in the search query. based on a sample of n = 124 
queries.The results arc summarized below: 
j j  = .202 + .135x 
t (for testing H,: p, = 0) = 4.98 
Two-tailed p-value = .001 
a. Is there sufficient evidence to indicate that x and y 
are linearly related? Test using cu = .01. 
b. If appropriate. use the model to predict the fraction 
of documents retrieved for a search query with x = 3 
terms. 
9.40 One of the most difficult tasks of developing and man- 
aging a global portfolio is assessing the risks of potential 
foreign investments. Duke University researcher C. R. 
Henry collaborated with two First Chicago Investment 
Management Company directors to examine the use of 
country credit ratings as a mcans of evaluating foreign 
investments (Journal of Portfolio Management, Wlnter 
1995). To be effective, such a measure should help 
explain and predict the volatility of the foreign market 
in question. The researchers analyzed data on annual- 
ized risk (y) and average credit rating (x) for the 40 
countries shown in the table on p. 504. An SPSS print- 
out for a simple linear regression analysis conducted on 
the data is also provided on p. 503. 
a. Locate the least squares estimates of Po and P, on 
the printout. 
b. Plot the data in a scattergram, then sketch the least 
squares line on the graph. 
c. Do the data provide sufficient evidence to conclude 
that country credit risk (x) contributes information 
for the prediction of market volatility (y)? 
0 1 
I 
I 
I 
I 
I 
0 
100 
200 
300 
400 
500 
ONCE/5-YR WINTER RUNOFF (rnrn) 

SECTION 9.5 
Assessing t h e  U t i l i t y  o f  t h e  Model: M a k i n g  Inferences A b o u t  t h e  Slope P ,  
SPSS Output for Exercise 9.40 
Equation Number 1 
Dependent Variable.. 
RISK 
Variable(s) Entered on Step Number 
1.. 
RATING 
Multiple R 
.57802 
R Square 
.33411 
Adjusted R Square 
.31658 
Standard Error 
12.67770 
Analysis of Variance 
DF 
Sum of Squares 
Mean Square 
Regression 
1 
3064.40538 
3064.40538 
Residual 
3 8 
6107.51862 
160.72417 
F = 
19.06624 
Signif F = 
.0001 
------------------- Variables in the Equation ...................... 
Variable 
B 
SE B 
Beta 
T 
Sig T 
RAT I NG 
-. 399606 
-091516 
-.578020 
-4.366 
.0001 
(Constant) 
57.755060 
6.127836 
9.425 
.OOOO 
SAS Output for Exercise 9.41 
Dependent Variable: 
Source 
Model 
Error 
C Total 
Root MSE 
Dep Mean 
C.V. 
Variable DF 
INTERCEP 
1 
AGE 
1 
NUMBER 
Analysis of Variance 
Sum of 
Mean 
DF 
Squares 
Square 
F Value 
Prob>F 
1 23536.50149 
23536.50149 
11.451 
0.0070 
10 20554.41518 
2055.44152 
11 44090.91667 
45.33698 
R-square 
0.5338 
61.08333 
Adj R-sq 
0.4872 
74.22152 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Estimate 
Error 
Parameter=O 
Prob > IT1 
-51.361607 
35.71379104 
-1.438 
0.1809 
17.754464 
5.24673562 
3.384 
0.0070 
d. Use the plot, part b, to visually locate any unusual 
data points (outliers). 
e. Eliminate the outlier(s), part d, from the data set and 
rerun the simple linear regression analysis. Note any 
dramatic changes in the results. 
9.41 Refer to Exercises 9.21 and 9.29 (p. 487,493). The SAS 
simple linear regression printout relating number of 
employees y to age of a fast-growing firm x is repro- 
duced above. 
a. Test to determine whether y is positively linearly re- 
lated to x. Use a = .01. 
b. Construct a 99% confidence interval for PI. Practi- 
cally interpret the result. 
9.42 H. Mintzberg's classic book, The Nature of Managerial 
Work (1973), identified the roles found in all manage- 
, 
rial jobs. An observational study of 19 managers from 
a medium-sized manufacturing plant extended 
Mintzberg's work by investigating which activities suc- 
cessful managers actually perform (Journal of Applied 
Behavioral Science, Aug. 1985). To measure success, 
the researchers devised an index based on the manag- 
er's length of time in the organization and his or her 


SECTION 9.6 
T h e  C o e f f i c i e n t  o f  C o r r e l a t i o n  
505 
Manager Success 
Number of Interactions 
Manager 
Index, y 
with Outsiders, x 
MINITAB Output for Exercise 9.42 
The regression equation is 
SUCCESS = 44.1 + 0.237 INTERACT 
Predictor 
Coef 
Stdev 
t-ratio 
P 
Constant 
44.130 
9.362 
4.71 
0.000 
INTERACT 
0.2366 
0. 1865 
1.27 
0.222 
s = 19.40 
R-sq = 8.6% 
R-sq(adj) = 3.3% 
Analysis of Variance 
SOURCE 
DF 
SS 
MS 
F 
P 
Regression 
1 
606.0 
606.0 
1.61 
0.222 
Error 
17 
6400.6 
376.5 
Total 
18 
7006.6 
! 
9.43 Refer to Exercise 9.19 (p. 487), in which the extent of 
ation is related to the power of the whistle blower in 
retaliation against whistle blowers was investigated. 
the organization. The researchers were unable to 
Sincc salary is a reasonably good indicator of a person's 
reject the hypothesis that the extent of retaliation is 
power within an organization, the data of Exercise 9.19 
unrelated to power. Do you agree'? Tcst using 
can be used to investigate whether the extent of retali- 
a = .05. 
THE COEFFICIENT OF CORRELATION 
Recall (from optional Section 2.10) that a bivariate relationship describes a rela- 
tionship between two variables,~ and y. Scattergrams are used to graphically de- 
scribe a bivariate relationship. In this section we will discuss the concept of 
correlation and show how it can be used to measure the linear relationship be- 
tween two variables x and y. A numerical descriptive measure of correlation is 
provided by the Pearson product moment coefficient o,f correlation, K 

506 
CHAPTER 
9 
S i m p l e  Linear Regression 
DEFINITION 9.2 
The Pearson product moment coefficient of correlation, r, is a measure of the 
strength of the linear relationship between two variables x and y. It is com- 
puted (for a sample of n measurements on x and y) as follows: 
Note that the computational formula for the correlation coefficient r given in 
Definition 9.2 involves the same quantities that were used in computing the least 
squares prediction equation. In fact, since the numerators of the expressions for j, 
and rare identical, you can see that r = 0 when 8, = 0 (the case where x contributes 
no information for the prediction of y) and that r is positive when the slope is positive 
and negative when the slope is negative. Unlike p,, the correlation coefficient r is 
scaleless and assumes a value between -1 and +1, regardless of the units of x and 1. 
A value of r near or equal to 0 implies little or no linear relationship be- 
tween y and x. In contrast, the closer r comes to 1 or - 1, the stronger the linear re- 
lationship between y and x. And if r = 1 or r = -1, all the sample points fall 
exactly on the least squares line. Positive values of r imply a positive linear rela- 
tionship between y and x; that is, y increases as x increases. Negative values of r 
imply a negative linear relationship between y and x; that is, y decreases as x in- 
creases. Each of these situations is portrayed in Figure 9.13. 
F I G U R E  9.1 3 
Values of rand their 
implications 
- 
a. Positive r: y increases 
as x increases 
b. r near 0: little or 
- .. 
:. Negative r: y decreases 
no relationship 
as x increases 
between y and x 
d. r = 1: a perfect 
e. r = -1: a perfect negative 
posltlve relationship 
relationship between y and x 
between y and x 
Y 
t 
-x 
f. r near 0: little or no 
linear relationship 
between y and x 

SECTION 9.6 
The Coefficient of Correlation 
507 
We demonstrate how to calculate the coefficient of correlation r using the 
I 
data in Table 9.1 for the advertising-sales example. The quantities needed to cal- 
- 
culate r are SS,,, SS,,, and SS,,. The first two quantities have been calculated pre- 
viously and are repeated here for convenience: 
( C Y)" 
ss,, = 7 
ss,, = 10 
ss,, = 2 y2 - - 
n 
We now find the coefficient of correlation: 
The fact that r is positive and near 1 in value indicates that the sales revenue 
y tends to increase as advertising expenditure x increases-for 
this sample of five 
months. This is the same conclusion we reached when we found the calculated 
value of the least squares slope to be positive. 
-"*"L".mm"L~"msM-"m 
Mississippi. The mayor of the city wants to know the correlation between the 
number-of casino employees and the yearly crime rate. The records for the past 
10 years are examined, and the results listed in Table 9.5 are obtained. Calculate 
the coefficient of correlation r for the data. 
TABLE 
9.5 
Data on Casino Employees and Crime Rate, Example 9.1 
Number of Casino Employees, 
Crime Rate, y (number of crimes 
Year 
x (thousands) 
per 1,000 population) 
................................................................. .. ............... . .... . ........................................ ........................................... 
" 
1991 
15 
1.35 
1992 
18 
1.63 
1993 
24 
2.33 
1994 
22 
2.41 
1995 
25 
2.63 
1996 
29 
2.93 
1997 
30 
3.41 
1998 
32 
3.26 
1999 
35 
3.63 
2000 
38 
4.15 
S o I u t i o n Rather than use the computing formula given in Definition 9.2, we resort to a 
statistical software package. The data of Table 9.5 were entered into a computer and 
MINITAB was used to compute r. The MINITAB printout is shown in Figure 9.14. 
Example 9.1 
FIGURE 9.14 
MINITAB printout fbr 
The coefficient of correlation, highlighted on the printout, is r = .987. Thus, the 
size of the casino workforce and crime rate in this city are very highly correlated- at 
Correlation of NOEMPLOY and CRIMERAT = 0.987 

508 
CHAPTER 9 
S i m p l e  Linear Regression 
least over the past 10 years. The implication is that a strong positive linear rela- 
tionship exists between these variables (see Figure 9.15). We must be careful, how- 
! 
ever, not to jump to any unwarranted conclusions. For instance, the mayor may be 
tempted to conclude that hiring more casino workers next year will increase the 
crime rate-that 
is, that there is a causal relationship between the two variables. 
However, high correlation does not imply causality. The fact is, many things have 
probably contributed both to the increase in the casino workforce and to the in- 
crease in crime rate. The city's tourist trade has undoubtedly grown since legalizing 
riverboat casinos and it is likely that the casinos have expanded both in services of- 
i 
fered and in number. We cannot infer a causal relationship on the basis of high sam- 
I 
ple correlation. When a high correlation is observed in the sample data, the only safe 
conclusion is that a lineur trend may exist between x and y. Another variable, such as 
the increase in tourism, may be the underlying cause of the high correlation be- 
tween x and y. 
* 
FIGURE 9.15 
Y 
Scattergram for Example 9.1 
. 
Number of employees (thousands) 
Keep in mind that the correlation coefficient r measures the linear correla- 
tion between x values and y values in the sample, and a similar linear coefficient of 
correlation exists for the population from which the data points were selected.The 
population correlation coefficient is denoted by the symbol p (rho). As you might 
expect, p is estimated by the corresponding sample statistic, r. Or, instead of estl- 
mating p, we might want to test the null hypothesis H,: p = 0 against Ha: p f O- 
that is, we can test the hypothesis that x contributes no information for the 
prediction of y by using the straight-line model against the alternative that the two 
variables are at least linearly related. 
However, we already performed this identical test in Section 9.5 when we 
tested H,: p, = 0 against Ha: p1 f 0. That is, the null hypothesis H,: p = O is 
equivalent to the hypothesis H,: PI = 0.* When we tested the null hypothesis 
& I  
H,,: p1 = 0 in connection with the advertising-sales example, the data led to a re- 
jection of the null hypothesis at the a = .05 level. This rejection implies that the 
null hypothesis of a 0 linear correlation between the two variables (sales revenue 
and advertising expenditure) can also be rejected at the a = .05 level. The only 
real difference between the least squares slope El and the coefficient of correla- 
tion r is the measurement scale. Therefore, the information they provide about the 
usefulness of the least squares model is to some extent redundant. For this reason. 
*The correlation test statistic that is equivalent tot = &/.sj, 
is t = 
r 
d(1 - r2)/(n - 2) 

SECTION 9.7 
T h e  C o e f f i c i e n t  o f  D e t e r m i n a t i o n  
509 
we will use the slope to make inferences about the existence of a positive or neg- 
ative linear relationship between two variables. 
THE COEFFICIENT OF DETERMINATION 
Another way to measure the usefulness of the model is to measure the contribution 
of x in predicting y. To accomplish this, we calculate how much the errors of predic- 
tion of y were reduced by using the information provided by x. To illustrate, consider 
the sample shown in the scattergram of Figure 9.16a. If we assume that x con- 
tributes no information for the prediction of y, the best prediction for a value of y is 
the sample mean y, which is shown as the horizontal line in Figure 9.16b. The verti- 
cal line segments in Figure 9.16b are the deviations of the points about the mean y. 
Note that the sum of squares of deviations for the prediction equation jj = y is 
A comparison of the sum of 
squares of deviations for two 
models 
I 
X 
I 
X 
a. Scattergram of data 
b. Assumption: x contributes no information 
for predicting y, 9 = j 
I
x
 
c. Assumption: x contr~bu~es 
information 
for predicting y, = P, + p,x 
Now suppose you fit a least squares line to the same set of data and locate 
the deviations of the points about the line as shown in Figure 9.16~. Compare the 
deviations about the prediction lines in Figures 9.16b and 9.16~. You can see that 
1. If x contributes little or no information for the prediction of y, the sums of 
squares of deviations for the two lines, 
and 
SSE = 2 (y, - 
will be nearly equal. 

510' 
CHAPTER 9 
S i m p l e  L i n e a r  Regression 
2. If x does contribute information for the prediction of y, the SSE will be small- 
er than SS,,. In fact, if all the points fall on the least squares line, then SSE = 0. 
Then the reduction in the sum of squares of deviations that can be attributed 
to x, expressed as a proportion of SS,,, is 
SS,, - SSE 
SSYY 
Note that SS,, is the "total sample variation" of the observations around the 
mean y and that SSE is the remaining "unexplained sample variability" after fit- 
ting the line 9. Thus, the difference (SS,, - SSE) is the "explained sample vari- 
ability" attributable to the linear relationship with x. Then a verbal description of 
the proportion is 
SS,, - SSE - Explained sample variability 
- 
S S ~ ~  
Total sample variability 
= Proportion of total sample variability explained 
by the linear relationship 
In simple linear regression, it can be shown that this proportion-called 
the coef- 
ficient of determination-is 
equal to the square of the simple linear coefficient of 
correlation r (the Pearson product moment coefficient of correlation). 
DEFINITION 9.3 
The coefficient of determination is 
It represents the proportion of the total sample variability around y that is ex- 
plained by the linear relationship between y and x. (In simple linear regres- 
sion, it may also be computed as the square of the coefficient of correlation r.) 
Note that r2 is always between 0 and 1, because r is between -1 and +I. 
Thus, an r2 of .60 means that the sum of squares of deviations of they values about 
their predicted values has been reduced 60% by the use of the least squares equa- 
tion 9, instead of 7, to predict y. 
" 
" 
3 
L "
1
1
I
I
j
"
 
Calculate the coefficient of determination for the advertising-sales example.The 
data are repeated in Table 9.6 for convenience. Interpret the result. 
TABLE 
9.6 
Advertising Expenditure-Sales Revenue Data 
Advertising Expenditure, x ($100~) 
Sales Revenue, y ($1,000~) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . 
1 
1 
2 
1 
3 
2 
4 
2 
5 
4 

SECTION 9.7 
T h e  C o e f f i c i e n t  of D e t e r m i n a t i o n  
511 
S o I u t i o n 
From previous calculations, 
SS,, = 6 and SSE = x ( y  - y)2 = 1.10 
Then, from Definition 9.3, the coefficient of determination is given by 
Another way to compute r2 is to recall (Section 9.6) that r = .904. Then we 
have r2 = (.904)~ = 22. A third way to obtain r2 is from a computer printout. This 
value is highlighted on the SAS printout reproduced in Figure 9.17, next to the 
heading R-square. Our interpretation is as follows: We know that using advertis- 
- 
ing expenditure, x, to predict y with the least squares line 
accounts for 82% of the total sum of squares of deviations of the five sample 
y values about their mean. Or, stated another way, 82% of the sample variation in 
sales revenue (y) can be "explained" by using advertising expenditure (x) in a 
straight-line model. 
sSc: 
bout 100(r2)% of the sample variation in y (measured by the total sum of 
of deviations of the sample y values about their mean 7) can be ex- 
d to) using x to predict y in the straight-line model. 
i 
Dependent Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
1 
4.90000 
4.90000 
13.364 
0.0354 
Error 
3 
1.10000 
0.36667 
C Total 
4 
6.00000 
Root MSE 
0.60553 
R-square 
0.8167 
Dep Mean 
2.00000 
Adj R-sq 
0.7556 
C.V. 
30.27650 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Variable DF 
Estimate 
Error Parameter=O 
Prob > IT1 
INTERCEP 
1 
-0.100000 
0.63508530 
-0.157 
0.8849 
X 
1 
0.700000 
0.19148542 
3.656 
0.0354 
FIGURE 9.1 7 
SAS printout for advertising-sales example 

512 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
Learning the Mechanics 
9.44 Explain what each of the following sample correlation 
coefficients tells you about the relationship between the 
x and y values in the sample: 
a . r = l  
b . r = - 1  
c . r = O  
d. r = .90 
e. r = .10 
f. r = -38 
/ 
9.45 Describe the slope of the least squares line if 
a . r = . 7  
b . r = - . 7  
c . r = O  
d . r 2 = . 6 4  
9.46 Construct a scattergram for each data set. Then calcu- 
late rand r2 for each data set. Interpret their values. 
9.47 Calculate r2 for the least squares line in each of the fol- 
lowing exercises. Interpret their values. 
a. Exercise 9.10 
b. Exercise 9.13 
Applying the Concepts 
9.48 If the economies of the world were tightly intercon- 
nected, the stock markets of different countries would 
move together. If they did, there would be no reason for 
investors to diversify their stock portfolios with stocks 
from a variety of countries (Sharpe, Alexander, and 
Bailey, Investments, 1999). The table below lists the cor- 
relations of returns on stocks in each of six countries 
with the returns of US. stocks. 
Correlation between 
Country 
Foreign and U.S. Stocks 
Australia 
.48 
Canada 
.74 
France 
S O  
Germany 
.43 
Japan 
.41 
U.K. 
.58 
Source: Sharpe, W. E,Alexander, G.J., and 
Ba~ley. Jeffery V ,  Inve~tments. Upper Saddle 
River, N.J.: Prentlce Hall, 1999, p. 887. 
a. Interpret the Australia1U.S. correlation. What does it 
suggest about the linear relationship between the 
stocks of the two countries? 
b. Sketch a scattergram that is roughly consistent with 
the magnitude of the France1U.S. correlation. 
c. Why must we be careful not to conclude from the in- 
formation in the table that the country which is most 
tightly integrated with the U.S. is Canada? 
9.49 Many high school students experience "math anxiety," 
which has been shown to have a negative effect on 
their learning achievement. Does such an attitude 
carry over to learning computer skills? A math and 
computer science researcher at Duquesne University 
investigated this question and published her results in 
Educational Technology (May-June 1995). A sample 
of 1,730 high school students-902 
boys and 828 
girls-from 
public schools in Pittsburgh, Pennsylvan~a. 
participated in the study. Using five-point Likert 
scales, where 1 = "strongly disagree" and 5 = "strong- 
ly agree," the researcher measured the students' inter- 
est and confidence in both mathematics and 
computers. 
a. For boys, math confidence and computer interest were 
correlated at r = .14. Fully interpret this result. 
b. For girls, math confidence and computer interest were 
correlated at r = .33. Fully interpret this result. 
9.50 Studies of Asian (particularly Japanese) and U.S. man- 
agers in the 1970s and 1980s found sharp differences of 
opinion and attitude toward quality management. Do 
these differences continue to'exis;? To find out, two 
California State University researchers (B. F. Yavas 
and T. M. Burrows) surveyed 100 U.S. and 96 Asian 
QLAGREE.DAT 
........................................................................................... 
Percentage of 
Managers Who Agree 
Statement 
United States 
Asian 
...................................................................................... 
1 
36 
38 
2 
31 
42 
3 
28 
43 
4 
27 
48 
5 
78 
58 
6 
74 
49 
7 
43 
46 
8 
50 
56 
9 
31 
65 
10 
66 
58 
11 
18 
21 
12 
61 
69 
13 
53 
45 
Source: Yavas, B F , and Burrows, T M. "A 
comparative study of attitudes of U S and Asian 
managers toward product quahty" Quality 
Munagement Jotrrnul, Fall 1994, p 49 (Table 5). 

managers in the electronics manufacturing industry 
(Quality Management Journal, Fall 1994). The accom- 
panying table givcs the percentages of U.S. and Asian 
managers who agree with each of 13 randomly select- 
ed statements regarding quality. (For example, one 
statement is "Quality is a problem in my company." 
Another is "Improving quality is expensive.") 
a. Find the coefficient of correlation r for these data 
on the MINITAB printout below. 
Correlation of USA and ASIAN = 0.570 
b. Interpret r in the context of the problem. 
I 
c. Refer to part b. Using the coefficient of correlation 
I 
r to make inferences about the difference in atti- 
tudes between U.S. and Asian managers regarding 
i 
quality can be misleading. The value of r measures 
i 
the strength of the linear relationship between two 
variables; it does not account for a difference be- 
tween the means of the variables. To illustrate this, 
examine the hypothetical data in the table below. 
I 
Show that r = 1, but the Asian percentage is ap- 
proximately 30 points higher for each quality state- 
ment. Would you conclude that the attitudes of US. 
and Asian managers are similar? 
Hypothetical Percentage 
of Managers Who Agree 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Quality Statement 
U.S. 
Asian 
9.51 The booming economy of the 1990s created many new 
billionaires. The 1999 Forbes 400 ranks the 400 wealthi- 
est people in the US. The top 15 billionaires on this list 
are described in the table above right. 
a. Construct a scattergram for these data. What does 
I 
the plot suggest about the relationship between age 
and net worth of billionaires? 
b. Find the coefficient of correlation and explain what 
it tells you about the relationship between age and 
net worth. 
C. If the correlation coefficient of part b had the op- 
posite sign, how would that change your interpre- 
tation of the relationship between age and net 
worth? 
I 
T h e  C o e f f i c i e n t  o f  D e t e r m i n a t i o n  
513 
1 
I 
FORBES400.DAT 
I 
Net Worth 
i, 
Name 
Age 
($ millions) 
Gates, William H. I11 
Allen, Paul Gardner 
Buffett, Warren Edward 
Ballmer, Steven Anthony 
Dell, Michael 
Walton, Jim C. 
Walton, Helen R. 
Walton, Alice L. 
Walton, John T. 
Walton, S. Robson 
Moore, Gordon Earl 
Ellison, Lawrence Joseph 
Anschutz, Philip E 
Kluge, John Werner 
Anthony, Barbara Cox 
Source: Forbes, Oct. 11,1999, p. 414 
d. Find the coefficient of determination for a straight- 
line model relating net worth (y) to age (x). Interpret 
the result in the words of the problem. 
9.52 The fertility rate of a country is defined as the number 
of children a woman citi7en bears, on average, in her 
lifetime. Scientific American (Dec. 1993) reported on 
the declining fertility rate in developing countries. The 
researchers found that family planning can have a great 
effect on fertility rate. The table on page 514 gives the 
fertility rate, y, and contraceptive prevalence, x (mea- 
sured as the percentage of married women who use 
contraception), for each of 27 developing countries. A 
SAS printout of the simple linear regression analysis is 
also provided on p. 504. 
a. According to the researchers, "the data reveal that 
differences in contraceptive prevalence explain 
about 90% of the variation in fertility rates." Do you 
concur? 
b. The researchers also concluded that "if contracep- 
tive use increases by 15 percent, women bear, on av- 
erage, one fewer child." Is this statement supported 
by the data'? Explain. 
9.53 A negotiable certificate of deposit is a marketable 
receipt for funds deposited in a bank for a specified 
period of time at a specified rate of interest (Lee, 
Finnerty, and Norton, 1997). The table on page 515 lists 
the end-ot-quarter interest rate for three-month certifi- 
cates of deposit from January 1982 through June 1999 
with the concurrent end-of-quarter values of Standard 
& Poor's 500 Stock Composite Average (an indicator 
of stock market activity). Find the coefficient of deter- 
mination and the correlation coefficient for the data 

514 
CHAPTER 9 
S i m p l e  L i n e a r  R e g r e s s i o n  
FERTRATE.DAT 
Contraceptive 
Contraceptive 
Country 
Prevalence, x 
Fertility Rate, y 
Country 
Prevalence, x 
Fertility Rate, y 
....................................................................................................... 
.................................................................................................. 
Mauritius 
76 
2.2 
Egypt 
40 
4.5 
Thailand 
69 
2.3 
Bangladesh 
40 
5.5 
Colombia 
66 
2.9 
Botswana 
35 
4.8 
Costa Rica 
71 
3.5 
Jordan 
35 
5.5 
Sri Lanka 
63 
2.7 
Kenya 
28 
6.5 
1
'
 
Turkey 
62 
3.4 
Guatemala 
24 
5.5 
Peru 
60 
3.5 
Cameroon 
16 
5.8 
Mexico 
55 
4.0 
Ghana 
14 
6.0 
Jamaica 
55 
2.9 
Pakistan 
13 
5.0 
Indonesia 
50 
3.1 
Senegal 
13 
6.5 
Tunisia 
51 
4.3 
Sudan 
10 
4.8 
El Salvador 
48 
4.5 
Yemen 
9 
7.0 
Morocco 
42 
4.0 
Nigeria 
7 
5.7 
Zimbabwe 
46 
5.4 
Source Robey, B., et a1 "The fertility decline in developing countries." Scientific American, December 1993, p. 62. [Note: The data 
values are estimated from a scatterplot.] 
SAS Output for Exercise 9.52 
Dependent Variable: FERTRATE 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
1 
35.96633 
35.96633 
74.309 
0.0001 
Error 
2 5 
12.10033 
0.48401 
C Total 
2 6 
48.06667 
Root MSE 
0.69571 
R-square 
0.7483 
Dep Mean 
4.51111 
Adj R-sq 
0.7382 
* -  
1 
C.V. 
15.42216 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Variable DF 
Estimate 
Error Parameter=O 
Prob > IT1 
INTERCEP 
1 
6.731929 
0.29034252 
23.186 
0.0001 
CONTPREV 
1 
-0.054610 
0.00633512 
-8.620 
0.0001 
and interpret those results. Use the STATISTIX print- 
out on p. 516 to arrive at your answer. 
9.54 Refer to the Journal of Information Science study of the 
relationship between the fraction y of documents 
retrieved using Medline and the number x of terms in 
the search query, Exercise 9.39. (p. 502) 
a. The value of r was reported in the article as r =.679. 
Interpret this result. 
b. Calculate the coefficient of determination, r2, and in- 
terpret the result. 
9.55 Are college football rankings correlated with the size of 
athletic department budgets? The table on page 516 lists 
a sample of athletic department budgets and Associated 
Press (AP) Top 25 rankings (as of Nov. 21,1999) for a 
sample of universities. 
a. Construct a scattergram for these data. Does it ap- 
pear that football ranking and athletic department 
budget are linearly related? Describe the strength of 
the relationship in words. 
b. Answer the question posed at the beginning of the 
exercise by finding and interpreting the coefficient of 
correlation for these data. 
9.56 Researchers at the University of Toronto conducted a 
series of experiments to investigate whether a com- 
mercially sold pet food could serve as a substitute diet 
for baby snow geese (Journal ofApplied Ecology,Vol.32. 

SECTION 9.7 
The C o e f f i c i e n t  o f  D e t e r m i n a t i o n  
515 
SP5W.DAT (Data for Exercise 9.53) 
. , . , . , , . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 
..................... . ............................................................................................. 
Year 
Quarter 
Interest Rate, x 
S h P  500, y 
Year 
Quarter 
Interest Rate, x 
S&P 500, y 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
1982 
I 
14.21 
111.96 
1991 
I 
6.71 
375.22 
I1 
14.46 
109.61 
I1 
6.01 
371.16 
111 
10.66 
120.42 
111 
5.70 
387.86 
IV 
8.66 
135.28 
IV 
4.91 
417.09 
1983 
I 
8.69 
152.96 
1992 
I 
4.25 
403.69 
I1 
9.20 
168.11 
I1 
3.86 
408.14 
111 
9.39 
166.07 
I11 
3.13 
417.80 
IV 
9.69 
164.93 
IV 
3.48 
435.71 
1984 
I 
10.08 
159.18 
1993 
I 
3.11 
451.67 
I1 
11.34 
153.18 
I1 
3.21 
450.53 
111 
11.29 
166.10 
I11 
3.12 
458.93 
IV 
8.60 
167.24 
IV 
3.17 
466.45 
1985 
I 
9.02 
180.66 
1994 
I 
3.77 
445.77 
I1 
7.44 
191.85 
I1 
4.52 
444.27 
111 
7.93 
182.08 
I11 
5.03 
462.69 
IV 
7.80 
211.28 
IV 
6.29 
459.27 
1986 
I 
7.24 
238.90 
1995 
I 
6.15 
500.71 
I1 
6.73 
250.84 
I1 
5.90 
544.75 
111 
5.71 
231.32 
I11 
5.73 
584.41 
IV 
6.04 
242.17 
IV 
5.62 
615.93 
1987 
I 
6.17 
291.70 
1996 
I 
5.29 
645.50 
I1 
6.94 
304.00 
I1 
5.46 
670.63 
I11 
7.37 
321.83 
I11 
5.51 
687.31 
IV 
7.66 
247.08 
IV 
5.44 
740.74 
1988 
I 
6.63 
258.89 
1997 
I 
5.53 
757.12 
I1 
7.51 
273.50 
11 
5.66 
885.14 
I11 
8.23 
271.91 
I11 
5.60 
947.28 
IV 
9.25 
277.72 
IV 
5.80 
970.43 
1989 
I 
10.09 
294.87 
1998 
I 
5.58 
1101.75 
I1 
9.20 
317.98 
I1 
5.60 
1133.84 
I11 
8.78 
349.15 
I11 
5.41 
1017.01 
IV 
8.32 
353.40 
IV 
5.14 
1229.23 
1990 
I 
8.27 
339.94 
1999 
I 
4.91 
1286.37 
I1 
8.33 
358.02 
I1 
5.13 
1372.71 
I11 
8.08 
306.05 
IV 
7.96 
330.22 
5ource. Standard & Poor's Stati~t~cal 
Service, Current Statistics. Standard & Poor's Corporation, 1992,1996,1999. 
1995). Goslings were deprived of food until their guts 
I 
were empty, then were allowed to feed for 6 hours on 
i 
a diet of plants or Purina Duck Chow. For each feed- 
ing trial, the change in the weight of the gosling after 
2.5 hours was recorded as a percentage of initial weight. 
! 
Two other variables recorded were digestion efficiency 
(measured as a percentage) and amount of acid-deter- 
gent fiber in the digestive tract (also measured as a per- 
centage). The data for 42 feeding trials are listed in the 
I 
table on page 517. 
a. The researchers were interested in the correlation be- 
tween weight change (y) and digestion efficiency (x). 
I 
Plot the data for these two variables in a scattergram. 
Do you observe a trend? 
b. On the SPSS printout on page 516, locate the coeffi- 
cient of correlation relating weight change y to di- 
gestion efficiency x. Interpret this value. 
c. Conduct a test (at a = .01) to determine whether 
weight change y is correlated with digestion efficien- 
cy x. (Note: The SPSS printout reports p-values for a 
test of the null hypothesis of zero correlation.) 
1 
d. Repeat parts b and c, but exclude the data for trials 
that used duck chow from the analysis. What do you 
t 
conclude? 
e. The researchers were also interested in the correla- 
tion between digestion efficiency ('y) and acid-deter- 
gent fiber (x). Repeat parts a-d for these two 
variables. 

516 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
STATlSTlX Output for Exercise 9.53 
CORRELATIONS (PEARSON) 
SP500 
INTRATE 
-0.5418 
UNWEIGHTED LEAST SQUARES LINEAR REGRESSION OF SP500 
PREDICTOR 
VARIABLES 
COEFFICIENT 
STD ERROR 
STUDENT'S T 
P 
- - - - - - - - - 
----------- 
- - - - - - - - - 
----------- 
------ 
CONSTANT 
909.430 
93.1408 
9.76 
0.0000 
INTRATE 
-67.7700 
12.7498 
-5.32 
0.0000 
R- SQUARED 
0.2935 
RESID. MEAN SQUARE (MSE) 
66183.7 
ADJUSTED R-SQUARED 0.2831 
STANDARD DEVIATION 
257.262 
SOURCE 
DF 
S S 
MS 
F 
P 
---------- 
--- 
---------- 
---------- 
----- ------ 
REGRESSION 
1 
1869911 
1869911 
28.25 
0.0000 
RESIDUAL 
6 8 
4500489 
66183.7 
TOTAL 
69 
6370401 
CASES INCLUDED 70 MISSING CASES 0 
ADBUDGETDAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Athletic Dept. 
Budget 
AP 
University 
(in millions) 
Ranking 
Michigan 
$47.6 
10 
Virginia Tech 
20.1 
2 
Arkansas 
24.2 
17 
Georgia 
26.5 
16 
Texas A&M 
27.6 
24 
Florida State 
31.0 
1 
Alabama 
33.4 
8 
Florida 
39.4 
5 
Tennessee 
45.0 
6 
Wisconsin 
41.4 
4 
Texas 
41.2 
7 
Georgia Tech 
21.6 
20 
Nebraska 
36.0 
3 
Source: Fortune, Dec. 20,1999, p. 172. 
SPSS Output for Exercise 9.56 
Correlations 
1 
USING THE MODEL FOR ESTIMATION AND 
PREDICTION 
WTCHNG 
Pearson Correlation 
Sig. (2-tailed) 
N 
DIGESTEF Pearson Correlation 
Sig. (2-tailed) 
N 
ACIDFIB 
Pearson Correlation 
Sig. (2-tailed) 
N 
If we are satisfied that a useful model has been found to describe the relationship 
between x and y, we are ready for step 5 in our regression modeling procedure: 
using the model for estimation and prediction. 
The most common uses of a probabilistic model for making inferences can be 
divided into two categories. The first is the use of the model for estimating the mean 
value of y, E(y), for a specific value of x. 
**. Correlation is significant at the 0.01 level (2-tailed). 
WTCHNG 
1.000 
4 2 
.6l2** 
.OOO 
42 
-.725** 
.OOO 
42 
DIGESTEF 
.612** 
.OOO 
4 2 
1.000 
42 
-.880** 
.OOO 
42 
ACIDFIB 
- .725** 
.OOO 
42 
-. 880** 
.OOO 
4 2 
1.000 
4 2 

SECTION 9.8 
Using t h e  M o d e l  f o r  E s t i m a t i o n  and P r e d i c t i o n  
517 
ata for Exercise 9.56) 
.............................................................................................. ............................................................................... 
Feeding Trial 
Diet 
Weight Change (%) 
Digestion Efficiency (%) 
Acid-Detergent Fiber (%) 
....................................................................................................................................................................................................................................... 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Source: Gadallah, EL., and Jefferies, R.L. "Forage quality in brood rearing areas of the lesser snow goose and the growth of captive goslins" 
Journal ofApplied Biology, Vol. 32, No. 2.1995, pp. 281-282 (adapted from Figures 2 and 3). 
For our advertising-sales example, we may want to estimate the mean sales 
revenue for all months during which $400 (x = 4) is expended on advertising. 
The second use of the model entails predicting a new indwidual y value for a 
given x. 
That is, if we decide to expend $400 in advertising next month, we may want 
to predict the firm's sales revenue for that month. 
In the first case, we are attempting to estimate the mean value of y for a very 
large number of experiments at the given x value. In the second case, we are trying 
to predict the outcome of a single experiment at the given x value. Which of these 
model uses-estimating 
the mean value of y or predicting an individual new value 
of y (for the same value of x)-can 
be accomplished with the greater accuracy? 

518 
CHAPTER 
9 
S i m p l e  L i n e a r  Regression 
Before answering this question, we first consider the problem of choosing an 
estimator (or predictor) of the mean (or a new individual) y value. We will use the 
least squares prediction equation 
both to estimate the mean value of y and to predict a specific new value of y for a 
given value of x. For our example, we found 
so that the estimated mean sales revenue for all months when x = 4 (advertising is 
$400) is 
or $2,700. (Recall that the units of y are thousands of dollars.) The same value is 
used to predict a new y value when x = 4. That is, both the estimated mean and 
the predicted value of y are j = 2.7 when x = 4, as shown in Figure 9.18. 
FIGURE 9.18 
Y 
Estimated mean value and predicted individual 
value of sales revenue y for x = 4 
2 
The difference between these two model uses lies in the relative accuracy of 
the estimate and the prediction. These accuracies are best measured by using the 
sampling errors of the least squares line when it is used as an estimator and as a 
predictor, respectively. These errors are reflected in the standard deviations given 
in the next box. 
The standard deviation of the sampling distribution of the estimator j of 
the mean value of y at a specific value of x, say x,, is 
the standard error of $. 

SECTION 
9.8 
U s i n g  t h e  Model for Estimation a n d  Prediction 
519 
The true value of u is rarely known, so we estimate a by s and calculate the 
estimation and prediction intervals as shown in the next two boxes. 
based on (n - 2) degrees of fre 
a
s
-
"
"
 
*as 
I*"Y * *"-m- 
SO* * 
/"W 
""~~"""""I*" 
"I 
-II 
U-3""- 
""s"a"--m*"m- 
Find a 95% confidence interval for the mean monthly sales when t 
store spends $400 on advertising. 
S o 1 u t i o n For a $400 advertising expenditure, x = 4 and the confidence interval for the 
F 
mean value of y is 
where t 025 is based on n - 2 = 5 - 2 = 3 degrees of freedom. Recall that 
9 = 2.7, s = .61, i = 3, and SS, 
= 10. From Table VI in Appendix B, 
t.ozs = 3.182. Thus, we have 
*The term prediction interval is used when the interval formed is intended to enclose the value of 
a random variable.The term confidence interval is reserved for estimation of population 
parameters (such as mean). 

520 
CHAPTER 
9 
S i m p l e  L i n e a r  Regression 
Therefore, when the store spends $400 a month on advertising, we are 95% con- 
fident that the mean sales revenue is between $1,600 and $3,800. Note that we 
/ 
used a small amount of data (small in size) for purposes of illustration in fitting 
the least squares line. The interval would probably be narrower if more informa- 
tion had been obtained from a larger sample. 
& 
S 0 I u t i 0 n To predict the sales for a particular month for which x, = 4, we calculate the 
95% prediction interval as 
Therefore, we predict with 95% confidence that the sales revenue next month (a 
month in which we spend $400 in advertising) will fall in the interval from $500 to 
$4,900. Like the confidence interval for the mean value of y, the prediction inter- 
I '  
val for y is quite large. This is because we have chosen a simple example (only five 
data points) to fit the least squares line. The width of the prediction interval could 
be reduced by using a larger number of data points. 
* 
Both the confidence interval for E(y) and prediction interval for y can be 
obtained using a statistical software package. Figures 9.19 and 9.20 are SAS print- 
outs showing confidence intervals and prediction intervals, respectively, for the 
data in the advertising-sales example. 
Dep Var 
Predict 
Std Err 
Lower95% 
Upper95% 
Obs 
X 
Y 
Value 
Predict 
Mean 
Mean 
Residual 
1 
1 
1.0000 
0.6000 
0.469 
-0.8927 
2.0927 
0.4000 
2 
2 
1.0000 
1.3000 
0.332 
0.2445 
2.3555 
-0.3000 
3 
3 
2.0000 
2.0000 
0.271 
1.1382 
2.8618 
0 
4 
4 
2.0000 
2.7000 
0.332 
1.6445 
3.7555 
-0.7000 
5 
5 
4.0000 
3.4000 
0.469 
1.9073 
4.8927 
0.6000 
FIGURE 9.19 
SAS printout giving 95% confidence intervals for E(y) 

SECTION 
9.8 
Using t h e  Model f o r  Estimation a n d  P r e d i c t i o n  
521 
I 
Deg Var 
Predict 
Std Err Lower95% 
Upper95% 
O b s  
X 
Y 
Value 
Predict 
Predict 
Predict Residual 
1 
1 
1.0000 
0.6000 
0.469 
-1.8376 
3.0376 
0.4000 
2 
2 
1.0000 
1.3000 
0.332 
-0.8972 
3.4972 
-0.3000 
3 
3 
2.0000 
2.0000 
0.271 
-0.1110 
4.1110 
0 
4 
4 
2.0000 
2.7000 
0.332 
0.5028 
4.8972 
-0.7000 
5 
5 
4.0000 
3.4000 
0.469 
0.9624 
5.8376 
0.6000 
FIGURE 9.20 
SAS printout giving 95% prediction intervals for y 
FIGURE 9.21 
A 95% confidence interval for 
mean sales and a prediction 
interval for sales when x = 4 
The 95% confidence interval for E(y) when x = 4 is highlighted in Figure 9.19 
in the row corresponding to 4 under the columns labeled Lower95% Mean and 
Upper9S0/o Mean. The interval shown on the printout, (1.6445,3.7555), agrees (ex- 
cept for rounding) with the interval calculated in Example 9.3. The 95% prediction 
interval for y when x = 4 is highlighted in Figure 9.20 under the columns 
Lower9S0/0 Predict and Upper95OA Predict. Again, except for rounding, the SAS in- 
terval (.5028,4.8972) agrees with the one computed in Example 9.4. 
A comparison of the confidence interval for the mean value of y and the 
prediction interval for a new value of y when x = 4 is illustrated in Figure 9.21. 
Note that the prediction interval for an individual new value of y is always 
wider than the corresponding confidence interval for the mean value of y. You 
can see this by examining the formulas for the two intervals and by studying Fig- 
ure 9.21. 
The error in estimating the mean value of y, E(y), for a given value of x, say 
x,, is the distance between the least squares line and the true line of means, 
E(y) = Po + P,x. This error, [ j  - E(y)], is shown in Figure 9.22. In contrast, the 
error (y, - T) in predicting some future value of y is the sum of two errors-the 
error of estimating the mean of y, E(y), shown in Figure 9.22, plus the random 
error that is a component of the value of y to be predicted (see Figure 9.23). Con- 
sequently, the error of predicting a particular value of y will be larger than the 
error of estimating the mean value of y for a particular value of x. Note from their 
formulas that both the error of estimation and the error of prediction take their 

522 
CHAPTER 9 
S i m p l e  L i n e a r  Regression 
FIGURE 9.22 
Y 
Error of estimating the mean 
value of y for a given value of x 
smallest values when x, = i. 
The farther x, lies from i, 
the larger will be the errors 
of estimation and prediction. You can see why this is true by noting the deviations 
for different values of x, between the line of means E(y) = p,, + P,x and the 
predicted line of means 
= 8, + pix shown in Figure 9.23.The deviation is larg- 
er at the extremes of the interval where the largest and smallest values of x in the 
data set occur. 
Both the confidence intervals for mean values and the prediction intervals for 
new values are depicted over the entire range of the regression line in Figure 9.24. 
You can see that the confidence interval is always narrower than the prediction in- 
terval, and that they are both narrowest at the mean i, increasing steadily as the 
distance lx - il increases. In fact, when x is selected far enough away from i so 
that it falls outside the range of the sample data, it is dangerous to make any in- 
ferences about E(y), or y. 
A 
Estimate of true 
rror of est~mation 
FIGURE 9.23 
Y 
Error of predicting a future 
value of y for a given value of x 
A 
Prediction of 
Particular value of y at x = xp 
Error of prediction 
I 
X~ 
* x 

SECTION 9.8 
U s i n g  t h e  M o d e l  f o r  E s t i m a t i o n  a n d  P r e d i c t i o n  
523 
FIGURE 9.24 
Confidence intervals for mean 
values and prediction intervals 
for new values 
A -,,,,, 
95% limits for mean 
11,,1,,111,,,11111111111111111111 
I ~ ~ ~ ~ ~ ~ , ~ , , ,  
95% limits 
for individual 
predicted values 
to predict a particular value of y for values of x that fall outside the range of 
the values of x contained in your sample data may lead to errors of estimation 
r prediction that are much larger than expected. Although the least squares 
ode1 may provide a very good fit to the data over the range of x values con- 
ined in the sample, it could give a poor representation of the true model for 
The confidence interval width grows smaller as n is increased; thus, in theo- 
ry, you can obtain as precise an estimate of the mean value of y as desired (at any 
given x) by selecting a large enough sample. The prediction interval for a new 
value of y also grows smaller as n increases, but there is a lower limit on its width. 
If you examine the formula for the prediction interval, you will see that the inter- 
val can get no smaller than ? & zo/p.* Thus, the only way to obtain more accu- 
rate predictions for new values of y is to reduce the standard deviation of the 
regression model, a. This can be accomplished only by improving the model, ei- 
ther by using a curvilinear (rather than linear) relationship with x or by adding 
- 
new independent variables to the model, or both. Methods of improving the 
model are discussed in Chapter 10. 
Learning the Mechanics ' 
9.57 Consider the following pairs of measurements: 
a. Construct a scattergram for these data. 
b. Find the least squares line, and plot it on your scatter- 
LM9-57.DAT 
gram. 
c. Find s2. 
d. Find a 90% confidence interval for the mean value 
Y 
of y when x = 3. Plot the upper and lower bounds of 
the confidence interval on your scattergram. 
*The result follows from the facts that, for large n, tmjz '= Z+ s = u, 
and the last two terms under 
the radical in the standard error of the predictor are approximately 0. 


SECTION 
9.8 
U s i n g  t h e  M o d e l  f o r  E s t i m a t i o n  a n d  P r e d i c t i o n  
525 
STATlSTlX Output for Exercise 9.61 
UNWEIGHTED LEAST SQUARES LINEAR REGRESSION OF HOMES 
PREDICTOR 
VARIABLES 
COEFFICIENT 
STD ERROR 
STUDENT'S T 
P 
--------- 
----------- 
- - - - - - - - - 
----------- 
------ 
CONSTANT 
5566.13 
253.996 
21.95 
0.0000 
INTRATE 
-210.346 
24.1940 
-8.69 
0.0000 
R-SQUARED 
0.8437 
RESID. MEANSQUARE (MSE) 
52438.8 
ADJUSTED R-SQUARED 0.8326 
STANDARD DEVIATION 
228.995 
SOURCE 
DF 
SS 
MS 
F 
P 
---------- 
--- 
---------- 
---------- 
----- ------ 
REGRESSION 
1 
3963719 
3963719 
75.59 
0.0000 
RESIDUAL 
14 
734143 
52438.8 
TOTAL 
15 
4697861 
PREDICTED/FITTED VALUES OF HOMES 
LOWER PREDICTED BOUND 
3364.1 
LOWER FITTED BOUND 
3714.7 
PREDICTED VALUE 
3883.4 
FITTED VALUE 
3883.4 
UPPER PREDICTED BOUND 
4402.7 
UPPER FITTED BOUND 
4052.0 
SE (PREDICTED VALUE ) 
242.12 
SE (FITTED VALUE) 
78.635 
UNUSUALNESS (LEVERAGE) 
0.1179 
PERCENT COVERAGE 
CORRESPONDING T 
PREDICTOR VALUES: INTRATE = 8.0000 
e. A 95% confidence interval for the mean annual 
number of existing single-family homes sold when 
the average annual mortgage interest rate is 8.0% is 
shown next to "LowerlUpper Fitted Bound" on the 
printout. Interpret this interval. 
f. A 95% prediction interval for the annual number of 
existing single-family homes sold when the average 
annual mortgage interest rate is 8.0% is shown next 
to"Lower1Upper Predicted Bound" on the printout. 
Interpret this interval. 
g. Explain why the widths of the intervals found in 
parts e and f differ. 
9.62 Refer to the simple linear regression of sweetness index y 
and amount of pectin x for n = 24 orange juice samples, 
Exercise 9.14 (p. 484).A 90% confidence interval for the 
mean sweetness index, E(y), for each value of x is shown 
on the SPSS spreadsheet on page 526. Select an observa- 
tion and interpret this interval. 
9.63 Refer to the simple linear regression of number of 
employees y and age x for fast-growing firms, 
Exercises 9.21,9.29, and 9.41. The SAS printout of the 
analysis is reproduced on page 526. 
a. A 95% prediction interval for y when x = 10 is 
shown at the bottom of the printout. Interpret this 
interval. 
b. How would the width of a 95% confidence interval 
for E(y) when x = 10 compare to the interval, part a? 
c. Would you recommend using the model to predict 
the number of employees at a firm that has been in 
business two years'? Explain. 
9.64 Managers are an important part of any organization's 
resource base. Accordingly, the organization should be 
just as concerned about forecasting its future manager- 
ial needs as it is with forecasting its needs for, say, the 
natural resources used in its production process 
(Northcraft and Neale, Organizational Behavior: A 
Management Challenge, 1994). A common forecasting 
procedure is to model the relationship between sales 
and the number of managers needed, since the demand 
for managers is the result of the increases and decreases 

526 
CHAPTER 
9 S i m p l e  L i n e a r  R e g r e s s i o n  
SPSS Spreadsheet for Exercise 9.62 
I 
I 
run 
1 
1.00 
2 
2.00 
3 
3.00 
4 
4.00 
5 
5.00 
6 
6.00 
7 
7.00 
8 
8.00 
9 
9.00 
10 
10.00 
11 
11.00 
12 
12.00 
13 
13.00 
14 
14.00 
15 
15.00 
16 
16.00 
17 
17.00 
18 
18.00 
19 
19.00 
20 
20.00 
2 1 
21.00 
22 
22.00 
23 
23.00 
24 
24.00 
sweet 
5.20 
5.50 
6.00 
5.90 
5.80 
6.00 
5.80 
5.60 
5.60 
5.90 
5.40 
5.60 
5.80 
5.50 
5.30 
5.30 
5.70 
5.50 
5.70 
5.30 
5.90 
5.80 
5.80 
5.90 
pectin 
lower90m 
upper90m 
220.00 
5.64898 
5.83848 
227.00 
5.63898 
5.81613 
259.00 
5.57819 
5.72904 
210.00 
5.66194 
5.87173 
224.00 
5.64337 
5.82560 
215.00 
5.65564 
5.85493 
231.00 
5.63284 
5.80379 
268.00 
5.55553 
5.71011 
239.00 
5.61947 
5.78019 
212.00 
5.65946 
5.86497 
410.00 
5.05526 
5.55416 
256.00 
5.58517 
5.73592 
306.00 
5.43785 
5.65219 
259.00 
5.57819 
5.72904 
284 .OO 
5.50957 
5.68213 
383.00 
5.15725 
5.57694 
271.00 
5.54743 
5.70434 
264.00 
5.65691 
5.71821 
227.00 
5.63898 
5.81613 
263.00 
5.56843 
5.72031 
232.00 
5.63125 
5.80075 
220.00 
5.64898 
5.83848 
246.00 
5.60640 
5.76091 
241.00 
5.61587 
5.77454 
SAS Output for Exercise 9.63 
Dependent Variable: NUMBER 
Source 
Model 
Error 
C Total 
Root MSE 
Dep Mean 
C.V. 
Variable DF 
INTERCEP 
1 
AGE 
1 
Obs 
AGE 
Analysis of Variance 
Sum of 
Mean 
DF 
Squares 
Square 
F Value 
Prob>F 
1 23536.50149 
23536.50149 
11.451 
0.0070 
10 20554.41518 
2055.44152 
11 44090.91667 
45.33698 
R- square 
0.5338 
61.08333 
Adj R-sq 
0.4872 
74.22152 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Estimate 
Error 
Parameter=O 
Prob > IT1 
-51.361607 
35.71379104 
-1.438 
0.1809 
17 .754464 
5.24673562 
3.384 
0.0070 
Dep Var 
NUMBER 
43.0000 
52.0000 
9.0000 
4O.OOOO 
6.0000 
12.0000 
200.0 
76.0000 
l5.OOOO 
4O.OOOO 
65.0000 
175.0 
Predict 
Value 
37.4107 
37.4107 
19.6563 
72.9196 
37 .dl07 
55.1652 
197.2 
37.4107 
72.9196 
55.1652 
37.4107 
72.9196 
126.2 
Std Err 
Predict 
14.840 
14.840 
17.921 
13.547 
14.840 
13.204 
42.301 
14.840 
13.547 
13.204 
14.840 
13.547 
23.268 
Lower95% 
Predict 
-68.8810 
-68.8810 
-88.9672 
-32 .!ill4 
-68.8810 
-50.0496 
59.0415 
-68.8810 
-32.5114 
-50.0496 
-68.8810 
-32 .!ill4 
12.6384 
Upper95% 
Predict 
143.7 
143.7 
128.3 
178.4 
143.7 
160.4 
335.4 
143.7 
178.4 
160.4 
143.7 
178.4 
239.7 
Residual 
5.5893 
14.5893 
-10.6562 
-32.9196 
-31.4107 
-43.1652 
2.7991 
38.5893 
-57.9196 
-15.1652 
27.5893 
102.1 

SECTION 9.8 
U s i n g  t h e  M o d e l  f o r  E s t i m a t i o n  a n d  P r e d i c t i o n  
527 
SPSS Output for Exercise 9.64 
Equation Number 1 
Dependent Variable.. 
MANAGERS 
Variable(s) Entered on Step Number 
1.. 
UNITS 
Multiple R 
.96386 
R Square 
.92903 
Adjusted R Square 
.92509 
Standard Error 
2.56642 
Analysis of Variance 
DF 
Sum of Squares 
Mean Square 
Regression 
1 
1551.99292 
1551.99292 
Residual 
18 
118.55708 
6.58650 
F = 
235.63225 
Signif F = 
.0000 
Variables in the Equation ------------------- 
Variable 
B 
SE B 
Beta 
T Sig T 
UNITS 
.586100 
.038182 
.963863 
15.350 
.OOOO 
(Constant) 
5.325299 
1.179868 
4.513 
.0003 
MANAGERS2.DAT (Data for Exercise 9.64) 
............................................................................................................................................................... 
Months 
Units Sold, x 
Managers, y 
Month 
Units Sold, x 
Managers, y 
in the demand for products and services that a firm 
offers its customers. To develop this relationship, the 
data shown in the table above are collected from a 
firm's records. An SPSS printout of the simple linear 
regression is provided above also. 
a. Test the usefulness of the model. Use a = .05. State 
your conclusion in the context of the problem. 
b. The company projects that it will sell 39 units in May 
of 2000. Use the least squares model to construct a 
90% prediction interval for the number of managers 
needed in May 2000. 
c. Interpret the interval in part b. Use the interval to 
determine the reliability of the firm's projection. 
9.65 The reasons given by workers for quitting their jobs gen- 
erally fall into one of two categories: (1) worker quits to 
seek or take a different job, or (2) worker quits to with- 
draw from the labor force. Economic theory suggests that 
wages and quit rates are related. The table on page 528 
lists auit rates (auits ner 100 emnlovees) and the averape 
hourly wage in a sample of 15 manufacturing industries. 
A MINlTAB printout of the simple linear regression of 
quit rate y on average wage x is shown on p. 528. 
a. Do the data present sufficient evidence to conclude 
that average hourly wage rate contributes useful in- 
formation for the prediction of quit rates? What does 
your model suggest about the relationship between 
q u ~ t  
rates and wages? 
b. A 95% prediction interval for the quit rate in an in- 
dustry with an average hourly wage of $9.00 is given 
at the bottom of the MINITAB printout. Interpret 
the result. 
c. A 95% confidence interval for the mean quit rate 
for industries with an average hourly wage of $9.00 is 
also shown on the printout. Interpret this result. 
9.66 The data for Exercise 9.30 are reproduced on page 528. 
a. Use a 90% confidence interval to estimate the mean 
useful life of a brand A cutting tool when the cutting 
<need ic 45 m ~ t ~ r c  
npr minute R e n e ~ t  
fnr hronrl R 

528 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
QUITTERS.D.4T (Data for Excercise 9.65) 
&! CUTTOOLS.DAT (Data for Bxcrrcisr 9.66) 
Industry 
Quit Rate, y 
Average Wage, x 
USEFULE LIFE (HOURS) 
Cutting Speed (meters per minute) 
Brand A 
Brand B 
Compare the widths of the two intervals and com- 
ment on the reasons for any difference. 
b. Use a 90% prediction interval to predict the useful 
life of a brand A cutting tool when the cutting speed 
is 45 meters per minute. Repeat for brand B. Com- 
pare the widths of the two intervals to each other, 
and to the two intervals you calculated in part a. 
Comment on the reasons for any differences. 
c. Note that the estimation and prediction you per- 
formed in parts a and b were for a value of x that 
was not included in the original sample. That is, the 
value x = 45 was not part of the sample. However, 
the value is within the range of x values in the sam- 
I 
sent interpolations. Suppose you were asked to pre- 
i 
dict the useful life of a brand A cutting tool for a 
cutting speed of x = 100 meters per minute. Since 
the given value of x is outside the range of the sam- 
ple x values, the prediction is an example of extrap- 
olation. Predict the useful life of a brand A cutting 
I 
tool that is operated at 100 meters per minute, and 
; 
construct a 95% confidence interval for the actual 
! 
useful life of the tool. What additional assumption 
i 
do you have to make in order to ensure the validit! 
of an extrapolation? 
- 
pie, so that the regression model spans the x value 
for which the estimation and prediction were made. 
In such situations, estimation and prcdiction repre- 
MINITAB Output for Exercise 9.65 
The regression equation is 
QuitRate = 4.86 - 0.347 AveWage 
Predictor 
Coef 
Stdev 
t-ratio 
P 
Constant 
4.8615 
0.5201 
9.35 
0.000 
AveWage 
-0.34655 
0.05866 
-5.91 
0.000 
s = 0.4862 
R-sq = 72.9% 
R-sq(adj) = 70.8% 
Analysis of Variance 
SOURCE 
DF 
SS 
MS 
F 
B 
Regression 
1 
8.2507 
8.2507 
34.90 
0.000 
Error 
13 
3.0733 
0.2364 
Total 
14 
11.3240 
Fit Stdev.Fit 
95% C.I. 
95% P.I. 
1.743 
0.128 
( 
1.467, 2.018) 
( 
0.656, 2.829) 

SECTION 9.9 
S i m p l e  L i n e a r  Regression: A C o m p l e t e  E x a m p l e  
529 
SIMPLE LINEAR REGRESSION: A C O M P L E T E  
E X A M P L E  
In the preceding sections we have presented the basic elements necessary to fit 
and use a straight-line regression model. In this section we will assemble these el- 
ements by applying them in an example with the aid of a computer. 
Suppose a fire insurance company wants to relate the amount of fire dam- 
age in major residential fires to the distance between the burning house and the 
nearest fire station. The study is to be conducted in a large suburb of a major city; 
a sample of 15 recent fires in this suburb is selected.The amount of  damage,^, and 
the distance between the fire and the nearest fire  station,^, are recorded for each 
fire. The results are given in Table 9.7. 
TABLE 
9.7 
Fire Damage Data 
Distance From Fire Station, x (miles) 
Fire Damage, y (thousands of dollars) 
Step 1 
Step 2 
First, we hypothesize a model to relate fire damage, y, to the distance 
from the nearest fire station, x. We hypothesize a straight-line 
probabilistic model: 
Next, we enter the data of Table 9.7 into a computer and use a statistical 
software package to estimate the unknown parameters in the 
deterministic component of the hypothesized model. The SAS printout 
for the simple linear regression analysis is shown in Figure 9.25. The least 
squares estimate of the slope PI and intercept P,, highlighted on the 
printout, are 
and the least squares equation is (rounded) 

Simple Linear Regression 
' 
Dep Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
Model 
1 
841.76636 
841.76636 
Error 
13 
69.75098 
5.36546 
C Total 
14 
911.51733 
Root MSE 
2.31635 
~-sguare 
Dep Mean 
26.41333 
Adj R-Sq 
C.V. 
Variable 
DF 
INTERCEP 
1 
X 
1 
Obs X 
1 
3.4 
2 
1.8 
3 
4.6 
4 
2.3 
5 
3.1 
6 
5.5 
7 
0.7 
8 
3.0 
9 
2.6 
10 
4.3 
11 
2.1 
12 
1.1 
13 
6.1 
14 
4.8 
15 
3.8 
16 
3.5 
Sum of Residuals 
8.76961 
Parameter Estimates 
Parameter 
Estimate 
10.277929 
4.919331 
Y 
26.2000 
l7.8OOO 
31.3000 
23.1000 
27.5000 
36.0000 
14.1000 
22.3000 
19.6000 
31.3000 
24.0000 
17.3000 
43.2000 
36.4000 
26.lOOO 
Standard 
Error 
1.42027781 
0.39274775 
Predict 
Value 
27.0037 
19.1327 
32.9068 
21.5924 
25.5279 
37.3342 
13.7215 
25.0359 
23.0682 
31.4311 
20.6085 
15.6892 
40.2858 
33.8907 
28.9714 
27.4956 
Sum of Squared Residuals 
69.7510 
Predicted Resid SS (Press) 
93.2117 
F Value 
Prob>F 
156.886 
0.0001 
T for HO: 
Parameter=O Prob > IT( 
7.237 
0.0001 
12.525 
0.0001 
Lower95% Upper95% 
Residual 
-0.8037 
-1.3327 
-1.6068 
1.5076 
1.9721 
-1.3342 
0.3785 
-2 -7359 
-3 -4682 
-0.1311 
3.3915 
1.6108 
2.9142 
2.5093 
-2.8714 
Predict 
21.8344 
13 .El41 
27.6186 
16.3577 
20.3573 
31.8334 
8.1087 
19.8622 
17.8678 
26.1908 
15.3442 
10.1999 
34.5906 
28.5640 
23.7843 
22.3239 
Predict 
32.1729 
24.4514 
38.1951 
26.8271 
30.6984 
42.8351 
19.3342 
30.2097 
28.2686 
36.6713 
25.8729 
21.1785 
45.9811 
39.2175 
34.1585 
32.6672 
F I G U R E  9.25 
SAS printout for fire damage regression analysis 
This prediction equation is graphed in Figure 9.26 along with a plot of the 
data points. 
The least squares estimate of the slope, B, = 4.919, implies that the 
estimated mean damage increases by $4,919 for each additional mile 
from the fire station. This interpretation is valid over the range of x, or 
from .7 to 6.1 miles from the station. The estimated y-intercept, 
6, = 10.278, has the interpretation that a fire 0 miles from the fire station 
has an estimated mean damage of $10,278. Although this would seem to 
apply to the fire station itself, remember that the y-intercept is 

SECTION 
9.9 
Simple Linear Regression: A C o m p l e t e  Example 
531 
FIGURE 9.26 
Y 
Least squares model 
for the fire damage 
2 I 
1 
data 
Step 3 
Step 4 
I 
I 
I 
I 
I 
I 
I 
c X 
0 
1 
2 
3 
4 
5 
6 
Distance from fire station (miles) 
the independent variable. Since x = 0 is outside the range in this case, 3, 
has no practical interpretation. 
Now we specify the probability distribution of the random error 
component 8. The assumptions about the distribution are identical to 
those listed in Section 9.3. Although we know that these assumptions are 
not completely satisfied (they rarely are for practical problems), we are 
willing to assume they are approximately satisfied for this example. The 
estimate of the standard deviation a of 8, highlighted on the printout, is: 
This implies that most of the observed fire damage (y) values will fall 
within approximately 2s = 4.64 thousand dollars of their respective 
predicted values when using the least squares line. 
We can now check the usefulness of the hypothesized model-that 
is, 
whether x really contributes information for the prediction of y using 
the straight-line model. First, test the null hypothesis that the slope p, is 0, 
that is, that there is no linear relationship between fire damage and the 
distance from the nearest fire station, against the alternative hypothesis 
that fire damage increases as the distance increases. We test 
The observed significance level for testing Ha: PI f 0, highlighted on the 
printout, is .0001. Thus, the p-value for our one-tailed test is p = .0001/2 = 
.00005. This small p-value leaves little doubt that mean fire damage and 
distance between the fire and station are at least linearly related, with 
mean fire damage increasing as the distance increases. 
We gain additional information about the relationship by forming a 
confidence interval for the slope PI. A 95% confidence interval is 

532 
CHAPTER 
9 
S i m p l e  Linear Regression 
I 
where i, 
= 4.919 and its standard error, sjl = .393, are both obtained 
from the printout. The value to,,, based on n - 2 = 13 df, is 2.160. 
1 
Therefore, the 95% confidence interval is 
We estimate that the interval from $4,070 to $5,768 encloses the mean 
increase (PI) in fire damage per additional mile distance from the fire 
station. 
Another measure of the utility of the model is the coefficient of 
determination, r2. The value (highlighted on the printout) is r2 = .9235. 
which implies that about 92% of the sample variation in fire damage (y) 
- * - *  
" 
is explained by the distance (x) between the fire and the fire station. 
The coefficient of correlation, r, that measures the strength of the linear 
relationship between y and x is not shown on the SAS printout and must 
be calculated. Using the facts that r = fl 
in simple linear regression 
and that r and pl have the same sign, we find 
The high correlation confirms our conclusion that PI is greater than 0; it 
appears that fire damage and distance from the fire station are positively 
correlated. All signs point to a strong linear relationship between y andx. 
Step 5 We are now prepared to use the least squares model. Suppose the 
insurance company wants to predict the fire damage if a major residential 
fire were to occur 3.5 miles from the nearest fire station. The predicted 
value (highlighted at the bottom of the printout) is jj = 27.4956, while the 
95% prediction interval (also highlighted) is (22.3239,32.6672). Therefore, 
with 95% confidence we predict fire damage in a major residential fire 3.5 
miles from the nearest station to be between $22,324 and $32,667. 
One caution before closing: We would not use this prediction model to 
make predictions for homes less than .7 mile or more than 6.1 miles from 
the nearest fire station. A look at the data in Table 9.7 reveals that all the 
x values fall between .7 and 6.1. It is dangerous to use the model to make 
predictions outside the region in which the sample data fal1.A straight line 
might not provide a good model for the relationship between the mean 
value of y and the value of x when stretched over a wider range of x 
values. 
A NONPARAMETRIC TEST FOR CORRELATION 
(OPTIONAL) 
When the simple linear regression assumptions (Section 9.3) are violated, e.g. the 
random error E has a highly skewed distribution, an alternative method of analy- 
sis is prefered. One technique is to apply a nonparametric test for correlation 
based on ranks. To illustrate, suppose 10 new car models are evaluated by two con- 
sumer magazines and each magazine ranks the braking systems of the cars from 1 
(best) to 10 (worst). We want to determine whether the magazines' ranks are re- 
lated. Does a correspondence exist between their ratings? If a car is ranked high 
h11 mana7ine 1 ic i t  Iikel\i tn h e  ranked hinh h17 nlanarino 77 n r  A n  hirrh r ~ n L ; n n r  

SECTION 9.10 
A N o n p a r a m e t r i c  Test f o r  C o r r e l a t i o n  ( O p t i o n a l )  
533 
f 
by one magazine correspond to low rankings by the other? That is, are the rank- 
ings of the magazines correlated? 
If the rankings are as shown in the "Perfect Agreement" columns of 
Table 9.8, we immediately notice that the magazines agree on the rank of every 
car. High ranks correspond to high ranks and low ranks to low ranks.This is an ex- 
ample of perfect positive correlation between the ranks. In contrast, if the rankings 
appear as shown in the "Perfect Disagreement" columns of Table 9.8, high ranks 
I 
for one magazine correspond to low ranks for the other. This is an example ofper- 
fect negative correlation. 
TABLE 
9.8 
Brake Rankings of 10 New Car Models by Two Consumer 
Magazines 
Perfect Agreement 
Perfect Disagreement 
....................................................... 
.......................................................... - 
Car Model 
Magazine 1 
Magazine 2 
Magazine 1 
Magazine 2 
.................................................................................. 
............................................................ 
1 
4 
4 
9 
2 
2 
1 
1 
3 
8 
3 
7 
7 
5 
6 
4 
5 
5 
1 
10 
5 
2 
2 
2 
9 
6 
6 
6 
10 
1 
7 
8 
8 
6 
5 
8 
3 
3 
4 
7 
9 
10 
10 
8 
3 
10 
9 
9 
7 
4 
In practice, you will rarely see perfect positive or negative correlation be- 
tween the ranks. In fact, it is quite possible for the magazines' ranks to appear as 
shown in Table 9.9. You will note that these rankings indicate some agreement be- 
tween the consumer magazines, but not perfect agreement, thus indicating a need 
for a measure of rank correlation. 
TABLE 
9.9 
Brake Rankings of New Car Models: Less Than Perfect Aqreement 
Magazine 
Difference Between Rank 1 And Rank 2 
................................................................................................................... 
Car Model 
1 
2 
d 
d2 
Spearman's rank correlation coefficient, r,, provides a measure of correlation 
between ranks. The formula for this measure of correlation is given in the next box. 
. 
. 
..... 
.....*...... 
\XIP 
, , I a n  
Q f r ~ r m l . l n  +he+ ;, :Ar\-+:,,l 
c, 
I-,.- 
41--..- 
1 
. 1  

534 
CHAPTER 
9 S i m p l e  L i n e a r  R e g r e s s i o n  
provides a good approximation to r, when the number of ties is small relative to the 
number of pairs. 
Note that if the ranks for the two magazines are identical, as in the second and 
third columns of Table 9.8, the differences between the ranks, d, will all be 0. Thus, 
That is, perfect positive correlation between the pairs of ranks is characterized by 
a Spearman correlation coefficient of r, = 1. When the ranks indicate perfect dis- 
agreement, as in the fourth and fifth columns of Table 9.8, Cd: = 330 and 
."~> 
r s = l - - -  6(330) 
lO(99) - -1 
i 
Rank of the ith 
v, = Rank of the ith 
n = Number of pairs of observations (number of observations in 
Shortcut Formula for r 
*The shortcut formula is not exact when there are tied measurements, but it is a good 
approximation when the total number of ties is not large relative to n. 

SECTION 9.10 
A N o n p a r a m e t r i c  T e s t  f o r  C o r r e l a t i o n  ( O p t i o n a l )  
535 
For the data of Table 9.9, 
The fact that r, is close to 1 indicates that the magazines tend to agree, but the 
agreement is not perfect. 
The value of r, always falls between -1 and +I, with +l indicating perfect 
positive correlation and -1 indicating perfect negative correlation. The closer r, 
falls to +1 or -1, the greater the correlation between the ranks. Conversely, the 
nearer r, is to 0, the less the correlation. 
Note that the concept of correlation implies that two responses are obtained 
for each experimental unit. In the consumer magazine example, each new car 
model received two ranks (one for each magazine) and the objective of the study 
was to determine the degree of positive correlation between the two rankings. 
Rank correlation methods can be used to measure the correlation between any 
pair of variables. If two variables are measured on each of n experimental units, 
we rank the measurements associated with each variable separately. Ties receive 
the average of the ranks of the tied observations. Then we calculate the value of r, 
for the two rankings. This value measures the rank correlation between the two 
variables. We illustrate the procedure in Example 9.5. 
rn ~n*s-a"m--ma~m* 
**s"-"--*n-- 
ften use preservatives to retard spoilage. One 
concern is that too much preservative will change the flavor of the food. Suppose 
an experiment is conducted using samples of a food product with varying amounts 
of preservative added. Both length of time until the food shows signs of spoiling 
and a taste rating are recorded for each sample. The taste rating is the average 
rating for three tasters, each of whom rates each sample on a scale from 1 (good) 
to 5 (bad). Twelve sample measurements are shown in Table 9.10. 
a. Calculate Spearman's rank correlation coefficient between spoiling time 
and taste rating. 
TABLE 
9.10 
Data and Correlations for Example 9.5 
Sample 
Days Until Spoilage 
Rank 
Taste Rating 
Rank 
Total = 536.5 
- 
Note:Tied measurements are assigned the average of the ranks they would be given if they were different but 
consecutive. 

536 
CHAPTER 9 
S i m p l e  L i n e a r  Regression 
b. Use a nonparametric test to find out whether the spoilage times and taste 
ratings are negatively correlated. Use a = .05. 
S o I u t i o n 
a. We first rank the days until spoilage, assigning a 1 to the smallest number 
1 
(26) and a 12 to the largest (109). Similarly, we assign ranks to the 12 taste 
ratings. [Note: The tied taste ratings receive the average of their respective 
ranks.] Since the number of ties is relatively small, we will use the shortcut 
formula to calculate r,. The differences d between the ranks of days until 
spoilage and the ranks of taste rating are shown in Table 9.10. The squares of 
the differences, d2, are also given. Thus, 
6x4 = I -  
6(536.5) 
r s = l -  
= 1 - 1.876 = -376 
n(n2 - 1) 
12(12~ - 1) 
FIGURE 9.27 
EXCEL printout for 
Example 9.5 
The value of r, can also be obtained using a computer. An EXCEL printout 
of the analysis is shown in Figure 9.27. The value of r,, highlighted on the 
printout, is -379 and agrees (except for rounding) with our hand-calculat- 
ed value. This negative correlation coefficient indicates that in this sample an 
increase in the number of days until spoilage is associated with (but is not 
necessarily the cause of) a decrease in the taste rating. 
Sample 
b. If we define p as the population rank correlation coefficient [i.e., the rank 
correlation coefficient that could be calculated from all (x, y) values in the 
population], this question can be answered by conducting the test 
Spearman r ( s )  
H,,: p = 0 (no population correlation between ranks) 
1 I 
30 1 
4.3 
Days 
Ha: p < 0 (negative population correlation between ranks) 
Taste 
-0.879160718 
Test statistic: r, (the sample Spearman rank correlation coefficient) 
To determine a rejection region, we consult Table XIV in Appendix B, which is 
partially reproduced in Table 9.11. Note that the left-hand column gives values 
of n, the number of pairs of observations. The entries in the table are values for 
0.000165104 

A N o n p a r a m e t r i c  Test f o r  C o r r e l a t i o n  ( O p t i o n a l )  
537 
TABLE 
9.1 1 
Reproduction of Part of Table XIV 
in Appendix B: Critical Values of 
Spearman's Rank Correlation 
Coefficient 
n 
a = .05 
a = .025 
a = .O1 
a = .005 
an upper-tail rejection region, since only positive values are given. Thus, for 
n = 12 and a = .05, the value .497 is the boundary of the upper-tailed rejec- 
tion region, so that P(r, > .497) = .05 if Ho: p = 0 is true. Similarly, for nega- 
tive values of r,, we have P(r, < -.497) = .05 if p = 0. That is, we expect to 
see r, < -.497 only 5% of the time if there is really no relationship between 
the ranks of the variables. The lower-tailed rejection region is therefore 
Rejection region (a = .05): r, < - .497 
Since the calculated r, = - 376 is less than -.497, we reject H,, at the 
a = .05 level of significance. That is, this sample provides sufficient evidence 
to conclude that a negative correlation exists between number of days until 
spoilage and taste rating of the food product. It appears that the preservative 
does affect the taste of this food adversely. [Note: The two-tailed p-value of 
the test is highlighted on the EXCEL printout next to the value of r, in 
Figure 9.27. Since the lower-tailed p-value, p = .00016/2 = .00008, is less 
than a = .05, our conclusion is the same: reject Ho.] 
+. 
A summary of Spearman's nonparametric test for correlation is given in 
the box on the next page. 
Learning the Mechanics 
d. P(rs < -.738 or r, > .738) when n = 8 
9.67 Use Table XIV of Appendix B to find each of the fol- 
9.68 Specify the rejection region for Spearman's nonpara- 
lowing probabilities: 
metric test for rank correlation in each of the following 
a. P(r, > S08) when n = 22 
situations: 
b. P(rs > .448) when n = 28 
a. H,,: p = 0; H,: p f 0, n = 10, a = .05 
c. P(r, 5 ,648) when n = 10 
b. H,: p = 0; Ha: p > 0, n = 20, a = .025 

538 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
ulas for calculating r,) 
I > rs.c5l2 
rs,n,2 is the value from 
XIV corresponding to the 
tail area a/2 and n pairs 
of observations 
ssumptions: 1. The sample of experimental units on which the two variables are 
measured is randomly selected. 
2. The probability distributions of the two variables are continuous. 
e,: Assign tied measurements the average of the ranks they would recelve 11 they 
1 but occurred in successive order. For example, if the third-ranked and 
ed measurements are tied, assign each a rank of (3 + 4)/2 = 3.5. The num- 
hould be small relative to the total number of observations. 
c. H,: p = 0; Ha: p < 0, n = 30, a = .O1 
9.69 Compute Spearman's rank correlation coefficient for 
each of the following pairs of sample observations: 
d. x 
5 
20 
15 
10 
3 
y 
80 
83 
91 
82 
87 
9.70 The following sample data were collected on variables x 
and y: 
x
o
3
0
-
4
3
0
4
 
y
o
2
2
 0
3
1
2
 
a. Specify the null and alternative hypotheses that 
should be used in conducting a hypothesis test to 
determine whether the variables x and y are 
correlated. 
b. Conduct the test of part a using a = .05. 
c. What is the approximate p-value of the test of part 
b ? 
d. What assumptions are necessary to ensure the valid- 
ity of the test of part b? 
Applying the Concepts 
9.71 Refer to the orange juice quality study, Exercise 9.14 
(p. 484). Recall that a manufacturer that has developed 
a quantitative index of the "sweetness" of orange juice 
is investigating the relationship between the sweetness 
index and the amount of water soluble pectin in the 
orange juice it produces. The data for 24 production 
runs at a juice manufacturing plant are reproduced in 
the table on page 539. 
a. Calculate Spearman's rank correlation coefficient 
between the sweetness index and the amount of 
pectin. Interpret the result. 
b. Conduct a nonparametric test to determine whether 
there is a negative association between the sweetness 
index and the amount of pectin. Use a = .01. 
9.72 Metropolitan areas with many corporate headquarters 
are finding it easier to transition from a manufacturing 
economy to a service economy through job growth in 
small companies and subsidiaries that service the cor- 
porate parent. James 0. Wheeler of the Univers~ty of 
Georgia studied the relationship between the number 
of corporate headquarters in eleven metropolltan areas 
and the number of subsidiaries located there (Gro~cth 
and Change, Spring 1988). He hypothesized that there 
would be a positive relationship between the variable5 

SECTION 9.10 
A N o n p a r a m e t r i c  T e s t  f o r  C o r r e l a t i o n  ( O p t i o n a l )  
Sweetness 
Pectin 
Sweetness 
Pectin 
Run 
Index 
( P P ~ )  
Run 
Index 
( P P ~ )  
.......................................... 
......................................................... 
1 
5.2 
220 
13 
5.8 
306 
2 
5.5 
227 
14 
5.5 
259 
3 
6.0 
259 
15 
5.3 
284 
4 
5.9 
210 
16 
5.3 
383 
5 
5.8 
224 
17 
5.7 
271 
6 
6.0 
215 
18 
5.5 
264 
7 
5.8 
231 
19 
5.7 
227 
8 
5.6 
268 
20 
5.3 
263 
9 
5.6 
239 
21 
5.9 
232 
10 
5.9 
212 
22 
5.8 
220 
11 
5.4 
410 
23 
5.8 
246 
12 
5.6 
256 
24 
5.9 
24 1 
Note The data In the table are authentic. For confidentiality reasons, the 
manufacturer cannot be disclosed. 
No. of Parent 
Metropolitan Area 
Companies 
No. of Subsidiaries 
................................................................................................................. 
New York 
643 
2,617 
Chicago 
381 
1,724 
Los Angeles 
342 
1,867 
Dallas-Ft. Worth 
251 
1,238 
Detroit 
216 
890 
Boston 
208 
681 
Houston 
192 
1,534 
San Francisco 
141 
899 
Minneapolis 
131 
492 
Cleveland 
128 
579 
Denver 
124 
672 
Year 
Federal Spending for 
Engineering Research 
($ millions) 
................................................. 
2,830 
3,618 
4,227 
5,509 
5,740 
5,680 
5,690 
Number of Scientists and 
Engineers Employed in 
Aircraft and Missile 
Industry (thousands) 
.................................................. 
90.6 
130.2 
115.3 
85.4 
68.2 
79.5 
95.1 
Source: US. Census Bureau, StatisticalAbstract of the United States, 1999. 
Source: Wheeler, J. 0. 
"The corporate role of large metropolitan areas 
in the United States" Growth and Change, Spring 1988, pp. 7548. 
a. Calculate Spearman's rank correlation coefficient for 
the data in the table above. What does it indicate 
about Wheeler's hypothesis? 
b. To conduct a formal test of Wheeler's hypothesis 
using Spearman's rank correlation coefficient, cer- 
tain assumptions must hold. What are they? Do they 
appear to hold? Explain. 
9.73 Is there an association between federal government 
spending for engineering research and the level of 
employment of scientists in the aircraft and missile 
industry? The data in the next table lists, for selected 
years, the amount (in millions of dollars) the federal 
government allocated to research in engineering and 
the number (in thousands) of scientists and engineers 
employed in the aircraft and missile industry. Conduct a 
nonparametric test to investigate the strength of the 
relationship between the two variables. Test using 
a = .lo. 
9.74 Two expert wine tasters were asked to rank six brands 
of wine. Their rankings are shown in the table. Do the 
data present sufficient evidence to indicate a positive 
correlation in the rankings of the two experts? 
Brand 
Expert 1 
Expert 2 
........................................................... 
A 
6 
5 
B 
5 
6 
C 
1 
2 
D 
3 
1 
E 
2 
4 
F 
4 
3 
9.75 An employee suggestion system is a formal process for 
capturing, analyzing, implementing, and recognizing 
employee-proposed organizational improvements. (The 
first known system was implemented by the Yale and 

1
540 
CHAPTER 9 
S i m p l e  L i n e a r  Regression 
S T A T I S T I C S  I N  
Can "Dowsers" Really Dete 
T 
he act of searching for and finding underground sup- 
plies of water using nothing more than a divining rod is 
commonly known as "dowsing." Although widely regarded 
among scientists as no morc than a superstitious relic from 
medieval times, dowsing remains popular in folklore and, to 
this day, there are individuals who claim to have this myste- 
rious skill and actually market their "services." 
Many dowsers in Germany claim that they respond to 
"earthrays" that emanate from the water source. These 
earthrays, say the dowsers, are a subtle form of radiation 
potentially hazardous to human health. As a result of these 
claims, the German government in the mid- 1980s conduct- 
ed a %-year experiment to investigate the possibility that 
dowsing is a genuine skill. If such a skill could be demon- 
strated, reasoned government officials, then dangerous lev- 
els of radiation in Germany could be detected, avoided, 
and disposed of. 
A group of university physicists in Munich, Germany, 
were provided a grant of 400,000 marks (= $250,000) to 
conduct the study. Approximately 500 candidate dowsers 
were recruited to participate in preliminary tests of their 
skill. To avoid fraudulent claims, the 43 individuals who 
seemed to be the most successful in the preliminary tests 
were selected for the final, carefully controlled, experiment. 
The researchers set up a 10-meter-long line on the 
ground floor of a vacant barn, along which a small wagon 
could be moved. Attached to the wagon was a short length 
of pipe, perpendicular to the test line, that was connected by 
hoses to a pump with running water. The location of the 
pipe along the line for each trial of the experiment was as- 
signed using a computer-generated random number. On the 
upper floor of the barn, directly above the experimental 
line, a 10-meter test line was painted. In each trial, a dowser 
was admitted to this upper level and required, with his or 
her rod, stick, or other tool of choice, to ascertain where the 
pipe with running water on the ground floor was located. 
Each dowser participated in at least one test series, that 
is, a sequence of from 5 to 15 trials (typically lo), with the 
pipe randomly repositioned after each trial. (Some dowsers 
undertook only one test series, selected others underwent 
more than 10 test series.) Over the 2-year experimental pe- 
riod, the 43 dowsers participated in a total of 843 tcsts. The 
experiment was "double-blind" in that neither the observer 
(researcher) on the top floor nor the dowser knew the 
pipe's location, even after a guess was made. [Note: Before 
the experiment began, a professional magician inspected 
the entire arrangement for potential deception or cheating 
by the dowsers.] 
For each trial, two variables were recorded: the actual 
pipe location (in decimeters from the beginning of the 
line) and the dowser's guess (also measured in decime- 
ters). Based on an examination of these data, the German 
physicists concluded in their final report that although 
most dowsers did not do particularly well in the experi- 
ments, "Some few dowsers, in particular tests. showed an 
extraordinarily high rate of success, which can scarcely if at 
all be explained as due to chance.. . a real core of dowser- 
phenomena can be regarded as empirically proven ... " 
(Wagner, Betz, and Konig, 1990). 
This conclusion was critically assessed by J.T. Enright, a 
professor of behavioral physiology at the University of 
California-San Diego (Skeptical Inquirer, Jan./Feb. 1999). 
Using scatterplots and the notion of correlation, Enright 
concluded exactly the opposite of the German 
According to Enright, "the Munich experiments constitute 
as decisive and complete a failure as can be imagined of 
dowsers to do what they claim they can." 
F o c u s  
a. Using scatterplots, Enright provided several hypothetical 
examples of outcomes that might be expected from the 
dowsing experiments, assunling various arbitrary cate- 
gories of dowser skill. Let x = dowser's guess and 
y = pipe location. Construct a scatterplot of hypothetical 
data that would reflect perfect prediction by the dowsers. 
b. Repeat part a for dowsers that have good (but not per- 
fect) skill. 
c. Repeat part a for dowsers that have no skill (i.e., that are 
making random guesses). 
d. Enright presented a scatterplot of the data for all 843 
tests performed in the Munich barn. A reproduction of 
this plot is displayed in Figure 9.28. Based on this graph. 
what inference would you make about the overall ability 
of the dowsers? Explain. [Note: In this plot, dowser's 
guess is shown on the vertical axis to make the graph 
comparable to the scatterplots you drew in parts a-c.] 
e. Recall that the German physicists found that a "few 
dowsers . . . showed an cxtraordinarily high rate of success," 
Consequently, they might argue that the scatterplot in Fig 
ure 9.28 on page 542 obscures these outstanding perfor- 
mances since it lumps all 43 dowsers (the majority of which 
are unskilled) together. In the researchers' final report. 
they identified three dowsers (those numbered 99, 18. 
and 108) as having particularly impressive results. All three 

of these "best" dowsers performed the experiment multi- 
ple times. The best test series (sequence of trials) for each 
of these three dowsers was identified; these data are listed 
inTable 9.12 and stored in the file DOWSING.DAT. Con- 
duct a complete simple linear regression analysis of the 
data in order to make an inference about the overall per- 
formance of each of the three best dowsers. 
f, The data in Table 9.12 represent the outcome of the 
dowsing experiment in its most favorable light. Can 
these results be reproduced by the best dowsers in com- 
parable tests? Remember, each of these three dowsers 
did participate in other test series. Enright plotted the 
data for these other series in which the three best 
dowsers performed; this scatterplot is reproduced in Fig- 
ure 9.29. Comment on the performance of the three best 
dowsers during these "rest of the best" trials. 
g. According to Enright, "there is another way of evaluat- 
ing the results from those dowsers who produced the 
best test series . . . Suppose that they had always left their 
dowsing equipment at home in the closet, and had sim- 
ply, in each and every test, just guessed that the pipe was 
located exactly at the middle of the test line." Replace 
the dowsers' guesses in Table 9.12 with the midpoint of 
the test line, 50 decimeters, and repeat the analysis of 
part e. What do you conclude from the analysis? 
h. Give a critical assessment of the Munich dowsing exper- 
iments. With whom do you tend to agree, the German 
physicists or J.T. Enright? 
TABLE 
9.1 2 Dowsing Trial Results: Best Series for the Three Best Dowsers 
Trial 
Dowser Number 
Pipe Location 
Dowser's Guess 
Source: Enright, J.T. "Testing dowsing: The failure of the Munich experiments" Skeptical 
Inquirer, Jan.lFeb. 1999, p. 45 (Figure 6a). 

542 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
(continued) 
FIGURE 9.28 
Results from All 843 Dowsing Trials 
Pipe location (decimeters) 
Results for Other Test Series that Three Best Dowsers 
Participated In 
0 
20 
40 
60 
80 
100 
Pipe location (decimeters) 

SECTION 9.10 
A N o n p a r a m e t r i c  T e s t  f o r  C o r r e l a t i o n  ( O p t i o n a l )  
543 
Towne Manufacturing Company of Stamford, 
Connecticut, in 1880.) Using data from the National 
Association of Suggestion Systems, D. Carnevale and 
B. Sharp examined the strengths of the relationships 
between the extent of employee participation in sug- 
gestion plans and cost savings realized by employers 
(Review of P~lblic Personnel Administration, Spring 
1993).The data in the table at right are representative of 
the data they analyzed for a sample of federal, state, 
and local government agencies. Savings are calculated 
from the first year measurable benefits were observed. 
a. Explain why the savings data used in this study may 
understate the total benefits derived from the imple- 
mented suggestions. 
b. Carnevale and Sharp concluded that a significant 
moderate positive relationship exists between par- 
ticipation rates and cost savings rates in public sec- 
tor suggestion systems. Do you agree? Test using 
a = .01. 
c. Justify the statistical methodology you used in part b. 
Employee Involvement 
(% of all employees 
Savings Rate 
submitting suggestions) 
(% of total budget) 
Source: Data adapted from Carnevale, D. G., and sharp, 
B. S. "The old employee suggestion box." Review of 
Public Personnel Administration, Spring 1993, pp. 82-92. 
9.76 A negotiable certificate of deposit is a marketable receipt 
time at a specified rate of interest (Lee, Finnerty, and 
for funds deposited in a bank for a specified period of 
Norton, 1997).The table below lists the end-of-quarter 
Interest 
SLP 500, 
Year 
Quarter 
Rate, x 
Y 
Interest 
ShP 500, 
Year 
Quarter 
Rate, x 
Y 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Source Standard & Poor's Current Statlstlcs, 1992,1996;Yahoo Finance Current Statzstm, February 2000; 
Board of Governors, Federal Reserve Board, H~stor~cal 
Statistics, March 2000. 

544 
CHAPTER 9 
S i m p l e  L i n e a r  R e g r e s s i o n  
STATISTIX Output for Exercise 9.76 
SPEARMAN RANK CORRELATIONS, CORRECTED FOR TIES 
INTRATE 
SP500 -0.5778 
MAXIMUM DIFFERENCE ALLOWED BETWEEN TIES 
0.00001 
I CASES INCLUDED 56 
MISSING CASES 0 
I 
interest rate for three-month certificates of deposit 
from January 1986 through December 1999 with the 
concurrent end-of-quarter values of Standard & Poor's 
500 Stock Composite Average (an indicator of stock 
market activity). 
a. Locate Spearman's rank correlation coefficient on 
the STATISTIX printout above. Interpret the result. 
b. Test the null hypothesis that the interest rate on cer- 
tificates of deposit and the S&P 500 are not corre- 
lated against the alternative hypothesis that these 
variables are correlated. Use a = .10. 
c. Repeat parts a and b using data from 1996 through 
the present, which can be obtained at your library in 
Standard & Poor's Current Statistics. Compare your 
results for the newer data with your results for the 
earlier period. 
Key Terms 
Starred (*) terms refer to the optional section in this chapter. 
I 
Bivariate relationship 505 
Coefficient of correlation 506 
Coefficient of determination 510 
Confidence interval for mean of y 519 
Dependent variable 474 
Deterministic model 473 
Errors of prediction 477 
Independent variable 474 
Least squares line 477 
Least squares estimates 478 
Line of means 474 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Key Formulas 
Method of least squares 477 
Pearson product moment coefficient of 
correlation 506 
Population correlation coefficient 508 
Population rank correlation 
coefficient 536 
Prediction interval for y 519 
Predictor variable 474 
Probabilistic model 473 
Random error 473 
*Rank correlation 533 
Regression analysis 474 
Response variable 474 
Scattergram 476 
Slope 474 
*Spearman's rank correlation 
coeffecient 533 
Standard error of regression model 490 
Straight-line (first-order) model 474 
Sum of squared errors 477 
y-intercept 474 
p = Po + p,x 
Least squares line 478 
ss,, 
p - - p  
- -  -- 
1 -  
> ~ - ~ - P I X  
ssxx 
Least squares estimates of p's 479 
where SS,, = 
xy - (Ex)( EY) 
n 
SSE 
s2 = - 
n - 2 
Estimated variance of u2 of e 490 
i 
SSE = 
(y, - jjJ2 = SS,, - &ss,, 
Sum of squared errors 490 
( E Y ) ~  
where SS,, = 
Y2 - - 
n 

F 
L a n g u a g e  L a b  
545 
I 
Estimated standard error of 3, 496 
s, 
\ 
t = -  
Test statistic for H,: P, = 0 497 
$p^, 
E l  5 (ta/2)~p^, 
(1 - a)100% confidence interval for PI 499 
SS,, 
r = 
= f 
(same sign as p1) 
Coefficient of correlation 506 
m 
SS,, - SSE 
r z  = 
SS," 
Coefficient of determination 510 
y * (ta,2)sdw 
(1 - a)100% confidence interval for E(y) when x = x, 
519 
(1 - a)100% prediction interval for y when x = x, 519 
*Spearman's rank correlation coefficient 534 
Symbol 
Pronunciation 
Description 
beta-zero 
beta-one 
beta-zero hat 
beta-one hat 
epsilon 
y-hat 
R-squared 
r-sub-s 
rho 
Dependent variable (variable to be predicted or modeled) 
Independent (predictor) variable 
Expected (mean) value of y 
y-intercept of true line 
Slope of true line 
Least squares estimate of y-intercept 
Least squares estimate of slope 
Random error 
Predicted value of y 
Error of predict~on 
Sum of errors (w~ll equal zero with least squares line) 
Sum of squared errors (will be smallest for least squares line) 
Sum of squares of x-values 
Sum of squares of y-values 
Sum of squares of cross-products, x - y  
Coetticient of correlation 
Coefficient of determination 
Value of x used to predict y 
"Spearman's rank correlation coefficient 
Population correlation coefficient 

546 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
[Note: Starred (*) exerases are from the optional section In this chapter.] 
Learning the Mechanics 
9.77 In fitting a least squares line to n = 15 data points, the 
following quantities were computed: SS,, = 55, 
SS,, = 198, SS,, = -88, i = 1.3, and 
= 35. 
a. Find the least squares line. 
b. Graph the least squares line. 
c. Calculate SSE. 
d. Calculate sZ. 
e. Find a 90% confidence interval for P,. Interpret this 
estimate. 
f. Find a 90% confidence interval for the mean value 
of y when x = 15. 
g. Find a 90% prediction interval for y when x = 15. 
9.78 Consider the following sample data: 
a. Construct a scattergram for the data. 
b. It is possible to find many lines for which 
x ( y  - j j )  = 0. For this reason, the criterion 
x ( y  - jj) = 0 is not used for identifying the "best- 
fitting" straight line. Find two lines that have 
2 ( y  - j j )  = 0. 
c. Find the least squares line. 
d. Compare the value of SSE for the least squares line 
to that of the two lines you found in part b. What 
principle of least squares is demonstrated by this 
comparison? 
9.79 Consider the 10 data points at the top of the next column. 
a. Plot the data on a scattergram. 
b. Calculate the values of r and r2. 
Exhaustion Index, y 
Concentration, x 
c. Is there sufficient evidence to indicate that x and y 
are linearly correlated? Test at the a = .I0 level of 
significance. 
*d. Calculate Spearman's rank correlation r,. 
Applying the Concepts 
9.80 Emotional exhaustion, or burnout, is a significant prob- 
lem for people with careers in the ficld of human ser- 
vices. Regression analysis was used to investigate the 
relationship between burnout and aspects of the human 
services professional's job and job-related behavlor 
(Journal ofApplied Behavioral Science, Vol. 22, 1986). 
Emotional exhaustion was measured with the Maslach 
Burnout Inventory, a questionnaire. One of the indepen- 
dent variables considered, called concentration, was the 
proportion of social contacts with individuals who belong 
to a person's work group.The table below lists the values 
of the emotional exhaustion index (higher values indi- 
cate greater exhaustion) and concentration for a sample 
of 25 human services professionals who work in a large 
public hospital. An SPSS printout of the simple linear 
regression is also provided on page 547. 
a. Construct a scattergram for the data. Do the vari- 
ables x and y appear to be related? 
b. Find the correlation coefficient for the data and inter- 
pret its value. Does your conclusion mean that con- 
centration causes emotional exhaustion? Explain. 
Exhaustion Index, y 
Concentration, x 


548 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
number of infections per leaf (y). A simple linear regres- 
sion analysis of the data produced the following results: 
9 = -.939 + .020x 
r2 = .816 
s = .288 
a. Interpret the value of 6,. 
b. Interpret the value of r2. 
c. Interpret the value of s. 
d. Calculate the value of r and interpret it. 
e. Use the result, part d, to test the utility of the 
model. Use a = .05. (Assume n = 100.) 
f. Predict the severity of the disease when the inci- 
dence of maize rust for a plant is 80%. [Note: Take 
the antilog (base 10) of 
to obtain the predicted 
average number of infections per leaf.] 
9.83 Refer to Exercise 2.97 (p. 106). The data in the value 
of 50 Beanie Babies collector's items, published in 
Beanie World Magazine, are reproduced on the next 
page. Can age (in months as of Sept. 1998) of a Beanie 
Baby be used to accurately predict its market value? 
Answer this question by conducting a complete 
simple linear regression anlysis on the data. Usc the 
SAS printout on page 550. 
*9.84 Universities receive gifts and donations from corpora- 
tions, foundations, friends, and alumni. It has long been 
argued that universities rise or fall depending on the 
level of support of their alumni.The table below reports 
the total dollars raised during a recent academic year 
by a sample of major US. universitics. In addition, it 
reports the percentage of that total donated by alumni. 
University 
Total Funds Raised 
Alumni Contribution 
Harvard 
Yale 
Cornell 
Wisconsin 
Michigan 
Pennsylvania 
Illinois 
Princeton 
Brown 
Northwestern 
Source: The Chronicle of Higher Education, Sept. 2,1996, p. 27. 
a. Do these data indicate that total fundraising and 
alumni contributions are correlated? Test using 
ff = .05. 
b. What assumptions must hold to ensure the validity 
of your test? 
9.85 A large proportion of US. teenagers work while 
attending high school. These heavy workloads often 
result in underachievement in the classroom and 
lower grades. A study of high school students in 
California acd Wisconsin showed that those who 
worked only a few hours per week had the highest 
grade point averages (Newsweek, Nov. 16, 1992). The 
following table shows grade point averages (GPAs) 
and number of hours worked per week for a sample of 
five students. Consider a simple linear regression relat- 
ing GPA (y) to hours worked (x). 
Grade Point 
Average, y 
2.93 
3.00 
2.86 
3.04 
2.66 
Hours Worked 
per Week, x 
12 
0 
17 
5 
21 
a. Find the equation of the least squares line. 
b. Plot the data and graph the least squares line. 
c. Test whether the model is useful for predicting grade 
point average. Use a = .lo. 
d. Predict the grade point average of a high school stu- 
dent who works 10 hours per week using a 90% pre- 
diction interval. Intrepret the result. 
9.86 The Minnesota Department of Transportation installed 
a state-of-the-art weigh-in-motion scale in the concrete 
surface of the eastbound lanes of Interstate 494 in 
Bloomington, Minnesota. After installation, a study 
was undertaken to determine whether the scale's read- 
ings correspond with the static weights of the vehicles 
being monitored. (Studies of this type are known as 
calibration studies.) After some preliminary compar- 
isons using a two-axle, six-tire truck carrying different 
loads (see the table on p. 551), calibration adjustments 
were made in the software of the weigh-in-motion 
system and the scales were reevaluated. 
a. Construct two scattergrams, one of y, versus x and 
the other of y, versus x. 
b. Use the scattergrams of part a to evaluate the per- 
formance of the weigh-in-motion scale both before 
and after the calibration adjustment. 
c. Calculate the correlation coefficient for both sets of 
data and interpret their values. Explain how these 
correlation coefficients can be used to evaluate the 
weigh-in-motion scale. 
d. Suppose the sample correlation coefficient for y, and 
x was 1. Could this happen if the static weights and 
the weigh-in-motion readings disagreed? Explain. 
9.87 Refer to Exercise 9.42 (p. 503). in which managerial suc- 
cess, y, was modeled as a function of the number of con- 
tacts a manager makes with people outside his or her 
: 
work unit, x, during a specific period of time. The data 
are repeated in the table on page 551. The MINITAB 
simple linear regression printout is also provided there. 
a. A particular manager was observed for two week$. 
as in the Journal of Applied Behavioral Scirrru 

S u p p l e m e n t a r y  E x e r c i s e s  
549 
BEANIE.DAT (Data for Exercise 9.83) 
Age (months) 
Retired (R)/ 
Name 
as of Sept. 1998 
Current (C) 
Value ($) 
........................................................................................................................................................................... 
i 
Ally the Alligator 
Batty the Bat 
Bongo the Brown Monkey 
Blackie the Bear 
Bucky the Beaver 
Bumble the Bee 
Crunch the Shark 
Congo the Gorilla 
Derby the Coarse Mained Horse 
Digger the Red Crab 
Echo the Dolphin 
Fetch the Golden Retriever 
Early the Robin 
Flip the White Cat 
Garcia the Teddy 
Happy the Hippo 
Grunt the Razorback 
Gig1 the Poodle 
Goldie the Goldfish 
Iggy the Iguana 
Inch the Inchworm 
Jake the Mallard Duck 
Kiwi the Toucan 
Kuku to Cockatoo 
Mistic the Unicorn 
Mel the Koala Bear 
Nanook the Husky 
Nuts the Squirrel 
Peace the Tie Died Teddy 
Patty the Platypus 
Quacker the Duck 
Puffer the Penguin 
Princess the Bear 
Scottie the Scottie 
Rover the Dog 
Rex the Tyrannosaurus 
Sly the Fox 
Slither the Snake 
Sk~p 
the Siamese Cat 
Splash the Orca Whale 
Spooky the Ghost 
Snowball the Snowman 
Stinger the Scorpion 
Spot the Dog 
Tank the Armadillo 
Stripes the Tiger (GoldlBlack) 
Teddy the 1997 Holiday Bear 
Tufty the Terrier 
Tracker the Basset Hound 
Zip the Black Cat 
Source: Beanie World Magazine, Sept. 1998. 
study. She made 55 contacts with people outside her 
b. A second manager was observed for two weeks. This 
work unit. Predict the value of the manager's suc- 
manager made 110 contacts with people outside his 
cess index. Use a 90% prediction interval. 
work unit. Give two reasons why caution should be 

SAS Output for Exercise 9.83 
Dependent Variable: VALUE 
Analysis of Variance 
Sum of 
Mean 
source 
DF 
Square 
F Value 
Probe>P 
Squares 
Model 
1 865745.59381 865745.59381 
10.548 
0.0021 
Error 
48 3939796.9062 82079.10221 
C Total 
49 4805542.5000 
Root MSE 
286.49451 
R-square 
0.1802 
Dep Mean 
128.90000 
~ d j  
R-sg 
0.1631 
C.V. 
222.26106 
Parameter Estimates 
parameter 
Standard 
T for HO: 
Variable DF 
Estimate 
Error 
Parameter=O 
Prob > 
IT1 
INTERCEP 
1 
-92.457684 
79.29105784 
-1.166 
0.2494 
AGE 
1 
8.346821 
2.57005393 
3.248 
0.0021 
Dep Var 
Predict 
Std Err Lower95% Upper95% 
Obs 
AGE 
VALUE 
Value 
Predict 
Predict 
Predict Residual 
55.0000 
12.0000 
40.0000 
10.0000 
45.0000 
600.0 
10.0000 
10.0000 
30.0000 
150.0 
20.0000 
l5.OOOO 
20.0000 
40.0000 
200.0 
20.0000 
175.0 
15.0000 
45.0000 
10.0000 
20.0000 
20.0000 
165.0 
20.0000 
45.0000 
10.0000 
l5.OOOO 
10.0000 
25.0000 
800.0 
15.0000 
15.0000 
65.0000 
28.0000 
15.0000 
825.0 
10.0000 
l9OO.O 
10.0000 
150.0 
40.0000 
4O.OOOO 
l5.OOOO 
65.0000 
85.0000 
400.0 
50.0000 
10.0000 
l5.OOOO 
~n nnnn 

S u p p l e m e n t a r y  Exercises 
551 
TRUCKWTS.DAT (Data for Exercise 9.86) 
................................................................................................................................................................................................................ 
Weigh-in-Motion Reading 
Weigh-in-Motion Reading 
Trial 
Static Weight of Truck, 
Prior to Calibration Adjustment, 
After Calibration Adjustment, 
Number 
x (thousand pounds) 
y, (thousand pounds) 
y, (thousand pounds) 
- 
....................................................................................................................................................................................................................... 
1 
27.9 
26.0 
27.8 
2 
29.1 
29.9 
29.1 
3 
38.0 
39.5 
37.8 
4 
27.0 
25.1 
27.1 
5 
30.3 
31.6 
30.6 
6 
34.5 
36.2 
34.3 
7 
27.8 
25.1 
26.9 
8 
29.6 
31.0 
29.6 
9 
33.1 
35.6 
33.0 
10 
35.5 
40.2 
35.0 
Source Adapted from data in Wright J. L., Owen, F., and Pena, D. "Status of MNDOT's weigh-in-motion program." St. Paul: 
Mmnesota Department of Transportation, January 1983 
MINITAB Output for Exercise 9.87 
The regression equation is 
SUCCESS = 44.1 + 0.237 INTERACT 
Predictor 
Coef 
Stdev 
t-ratio 
P 
Constant 
44.130 
9.362 
4.71 
0.000 
INTERACT 
0.2366 
0.1865 
1.27 
0.222 
s = 19.40 
R-sq = 8.6% 
R-sq(adj) = 3.3% 
Analysis of Variance 
SOURCE 
DF 
SS 
MS 
F 
P 
Regression 
1 
606.0 
606.0 
1.61 
0.222 
Error 
17 
6400.6 
376.5 
Total 
18 
7006.6 
I 
I 1 
MANAGERS.DAT (Data for Exercise 9.87) 
................................................................................................................. 
i 
Manager Success 
Number of Interactions 
Manager 
Index, y 
with Outsiders, x 
c. 
.................................................................................................................... 
40 
12 
73 
71 
exercised in using the least squares model developed 
from the given data set to construct a prediction in- 
terval for this manager's success index. 
In the context of this problem, determine the value 
of x for which the associated prediction interval for 
y is the narrowest. 
9.88 Firms planning to build new plants or make additions 
to existing facilities have become very conscious of the 
energy efficiency of proposed new structures and are 
interested in the relation between yearly energy con- 
sumption and the number of square feet of building 
shell. The table on p. 552 lists the energy consumption 
in British thermal units (a BTU is the amount of heat 
required to raise 1 pound of water 1•‹F) for 22 buildings 
that were all subjected to the same climatic conditions. 
The SAS printout that fits the straight-line model relat- 
ing BTU consumption, y, to building shell area, x, is 
shown on p. 553. 
a. Find the least squares estimates of the intercept Po 
and the slope P,. 
b. Investigate the usefulness of the model you devel- 
,.v.c.rl 
;" .-.,I,.* 
'. To .,e-..lr, 
e * - . - " . 7  
--.."..--&:-- 

552 
CHAPTER 9 S i m p l e  L i n e a r  R e g r e s s i o n  
BTU.DAT 
............................................................................................... 
BTU/Year (thousands) 
Shell Area (square feet) 
positively linearly related to the shell area of the 
building? Test using a = .lo. 
c. Calculate the observed significance level of the test 
of part b using the printout. Interpret its value. 
d. Find the coefficient of determination r2 and inter- 
pret its value. 
e. A company wishes to build a new warehouse that 
will contain 8,000 square feet of shell area. Find 
the predicted value of energy consumption and a 
95% prediction interval on the printout. Comment 
on the usefulness of this interval. 
f. The application of the model you developed in 
part a to the warehouse problem of part e is ap- 
propriate only if certain assumptions can be 
made about the new warehouse. What are these 
assumptions? 
*9.89 The perceptions of accounting professors with respect 
to the present and desired importance of various fac- 
tors considered in promotion and tenure decisions at 
major universities was investigated in the Journal of 
Accmnting Educution (Spring 1983). One hundred fif- 
teen professors at universities with accredited doctoral 
programs responded to a mailed questionnaire. The 
questionnaire asked the professors to rate (1) the actu- 
al importance placed on 20 factors in the promotion 
and tenure decisions at their universities and (2) how 
they believe the factors should be weighted. Responses 
were obtained on a five-point scale ranging from "no 
importance" to "extreme importance." The resulting 
ratings were averaged and converted to the rankings 
shown in the next table. Calculate Spearman's rank 
correlation coefficient for the data and carefully inter- 
pret its value in the context of the problem. 
TENURE.DAT 
................................................................................................................... 
Factor 
Actual 
Ideal 
I. Teaching (and related items): 
Teaching performance 
Advising and counseling students 
Students' complaints/praise 
11. Research: 
Number of journal articles 
Quality of journal articles 
Refereed publications: 
a. Applied studies 
b. Theoretical empirical studies 
c. Educationally oriented 
Papers at professional meetings 
Journal ed~tor or reviewer 
Other (textbooks, etc.) 
111. Service and professional interaction: 
Service to profession 
Professionallacademic awards 
Community service 
University service 
Collegiality/cooperativeness 
IV. Other: 
Academic degrees attained 
Professional certification 
Consulting activities 
Grantsmanship 
Source: Campbell, D. K., Gaertner, J., and Vecchio, R. P. "Perceptions 
of promotion and tenure criteria: A survey of accounting educators" 
Journal of Accounting Education, Vol. 1, Spring 1983, pp. 83-92. 
9.90 To develop a compensation plan designed to eliminate 
pay inequities, a sample of benchmark jobs are evalu- 
ated and assigned points, x, based on factors such a\ 
responsibility, skill, effort, and working conditions. One 
market survey was conducted to determine the market 
rates (or salaries), y, of the benchmark jobs (Public 
Personnel Management, Vol. 20, 1991). The table on 
page 555 gives the job evaluation points and salaries 
for a set of 21 benchmark jobs. 
a. Construct a scattergram for these data. What does it 
suggest about the relationship between salary and 
job evaluation points? 
b. The SAS printout on p. 554 shows the results of a 
straight-line model fit to these data. Identify and in- 
terpret the least squares equation. 
c. Interpret the value of r2 for this least squares 
equation. 
d. Is there sufficient evidence to conclude that a 
straight-line model provides useful information 
about the relationship in question? Interpret thep- 
value for this test. 
e. A job outside the set of benchmark jobs is evaluated 
and receives a score of 800 points. Under the compa- 

S u p p l e m e n t a r y  E x e r c i s e s  
553 
SAS Output for Exercise 9.88 
Dep Variable: BTU 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Model 
1 1.6584983+13 
1.6584983+13 
42.028 
Error 
20 
7.892323+12 394616010047 
C Total 
21 
2.447733+13 
Root MSE 628184.69422 
R-Square 
0.6776 
Dep Mean 1357904.54545 
Adj R-Sq 
0.6614 
C.V. 
46.26133 
Parameter Estimates 
Variable 
DF 
INTERCEP 
1 
AREA 
Obe 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
2 0 
2 1 
2 2 
23 
1 
AREA 
30001 
13530 
26060 
6355 
4576 
24680 
2621 
23350 
18770 
12220 
25490 
23680 
5650 
8001 
6147 
2660 
19240 
10700 
9125 
6510 
13530 
18860 
8000 
Sum of Residuals 
Parameter 
Estimate 
-99045 
102.814048 
BTU 
3870000 
1371000 
2422000 
672200 
233100 
218900 
354000 
3135000 
1470000 
1408000 
2201000 
2680000 
337500 
567500 
555300 
239400 
2629000 
1102000 
423500 
423500 
1691000 
1870000 
Standard 
T for HO: 
Error 
Parameter=O 
261617.65980 
-0.379 
15.85924082 
6.483 
Predict 
Value 
2985479 
1292029 
2580289 
554338 
371432 
2438405 
170430 
2301663 
1830774 
1157342 
2521685 
2335591 
481854 
723570 
532953 
174440 
1879097 
1001065 
839133 
570274 
1292029 
1840028 
723467 
Residual 
884521 
78971.2 
-158289 
117862 
-138332 
-2219505 
183570 
833337 
-360774 
250658 
-320685 
344409 
-144354 
-156070 
22347.3 
64959.9 
749903 
100935 
-415633 
-146774 
398971 
29972.3 
Lower95% 
Predict 
1546958 
-47949.3 
1183940 
-810192 
-1005463 
1054223 
-1222796 
927871 
482352 
-184021 
1130530 
959345 
-887287 
-631698 
-832898 
-1218433 
528832 
-343656 
-511035 
-793294 
-47949.3 
491266 
-631806 
Sum of Squared Residuals 
7.892323+12 
Predicted Resid SS (Press) 1.0127473+13 
Prob>F 
0.0001 
Prob > IT1 
rable-worth plan, what is a reasonable range within 
vers (Horngren, Foster, and Datar, Cost Accountzng, 
which a fan salary for this job should be found? 
1994). The cost data shown in the second table on 
0.7090 
0.0001 
Upper95% 
Predict 
4424000 
2632007 
3976637 
1918868 
1748327 
3822588 
1563657 
3675455 
3179196 
2498706 
3912840 
3711838 
1850995 
2078838 
1898804 
1567313 
3229362 
2345786 
2189301 
1933842 
2632007 
3188789 
2078740 
9.91 Managers are interested in modelmg past cost bchavior 
page 555 are from a rug manufacturer. Indirect manu- 
in order to make more accurete predictions of future 
facturing labor costs consist of mach~ne maintenance 
costs. Models of past cost behavior are called costfunc- 
costs and setup labor costs. Machine-hours and direct 
tlons. Factors that influence costs are called cost dri- 
manutacturmg labor-hours are cost dr~vers. 

554 
CHAPTER 
9 
S i m p l e  L i n e a r  R e g r e s s i o n  
SAS Output for Exercise 9.90 
Dependent Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>E 
Model 
1 66801750.334 
66801750.334 
74.670 
0.0001 
Error 
19 16997968.904 
894629.94232 
C Total 
20 83799719.238 
Root MSE 
945.84879 
R-square 
0.7972 
Dep Mean 
14804.52381 
Adj R-sq 
0.7865 
C.V. 
6.38892 
Variable 
INTERCEP 
X 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
DF 
Estimate 
Error 
Parameter=O 
Prob > IT1 
1 
12024 382.31829064 
31.449 
0.0001 
1 
3.581616 
Dep Var Predict 
Y 
Value 
15704.0 15497.8 
13984.0 13814.5 
14196.0 13348.9 
13380.0 12811.6 
13153.0 12919.1 
18472.0 16858 - 8  
14193.0 13707.0 
20642.0 
19330.2 
13614.0 
13348.9 
16869.0 16321.6 
15184.0 14960.6 
17341.0 18703.4 
15194.0 15838.1 
13614.0 15175.5 
12594.0 13241.4 
13126.0 13957.7 
12958.0 
13778.6 
13894.0 
15390.4 
13380.0 14172.6 
15559.0 14906.9 
13844.0 12811.6 
. 14888.9 
Std Err 
Predict 
221.447 
236.070 
266.420 
309.502 
300.351 
314.833 
242.349 
562.933 
266.420 
270.968 
207.190 
496.193 
238.553 
210.818 
274.451 
228.483 
238.109 
217.251 
218.972 
206.741 
309.502 
206.632 
Lower95% 
Predict 
13464.6 
11774.1 
11292.1 
10728.6 
10842.0 
14772.4 
11663.4 
17026.4 
11292.1 
14262.3 
12934.0 
16467.8 
13796.4 
13147.2 
11180.1 
ll92l.l 
11737.2 
13359.1 
12140.6 
12880.4 
10728.6 
12862.6 
8.641 
Upper95% 
Predict 
17531.0 
15854.9 
15405.6 
14894.6 
14996.2 
18945.3 
15750.6 
21633.9 
15405.6 
18380.9 
16987.2 
20938.9 
17879.8 
17203.7 
15302.7 
15994.4 
15820.1 
17421.6 
16204.7 
16933.3 
14894.6 
16915.3 
0.0001 
Residual 
206.2 
169.5 
847.1 
568.4 
233.9 
1613.2 
486.0 
1311.8 
265.1 
547.4 
223.4 
-1362.4 
-644.1 
-1561.5 
-647.4 
-831.7 
-820.6 
-1496.4 
-792.6 
652.1 
1032.4 

S u p p l e m e n t a r y  Exercises 
555 
JOBPOINT.DAT 
.......................................................................................................................................... 
lob Evaluation Points, x 
Salary, y 
......................................................................................................................................... 
970 
$1 5,704 
Electrician 
500 
13,984 
Semiskilled laborer 
370 
14,196 
Motor equipment operator 
220 
13,380 
Janitor 
250 
13,153 
Laborer 
1,350 
18,472 
Senior engineering technician 
470 
14,193 
Senior janitor 
2,040 
20,642 
Revenue agent 
370 
13,614 
Engineering aide 
1,200 
16,869 
Electrician supervisor 
820 
15,184 
Senior maintenance technician 
1,865 
17,341 
Registered nurse 
1,065 
15,194 
L~censed practical nurse 
880 
13,614 
Principal clerk typist 
340 
12,594 
Clerk typist 
540 
13,126 
Senior clerk stenographer 
490 
12,958 
Senior clerk typist 
940 
13,894 
Principal clerk stenographer 
600 
13,380 
Instrtutional attendant 
805 
15,559 
Eligibility technician 
220 
13,844 
Cook's helper 
Your task is to estimate and compare two alterna- 
tive cost functions for indirect manufacturing labor 
costs. In the first, machine-hours is the independent 
vanable; in the second, direct manufacturing labor- 
hours is the independent variable. Prepare a report 
that compares the two cost functions and recom- 
mends which should be used to explain and predict 
indirect manufacturing labor costs. Be sure to justify 
your choice. 
RUGDAT 
.................................................................................................................... 
Indirect 
Direct 
Manufacturing 
Manufacturing 
Week 
Labor Costs 
Machine-Hours 
Labor-Hours 
................................................................................................................ 
1 
$1,190 
68 
30 
2 
1,211 
88 
35 
3 
1,004 
62 
36 
4 
917 
72 
20 
5 
770 
60 
47 
6 
1,456 
96 
45 
7 
1,180 
78 
44 
8 
710 
46 
38 
9 
1,316 
82 
70 
10 
1,032 
94 
30 
11 
752 
68 
29 
12 
963 
48 
38 
Source: Data and exercise adapted from Horngren, C.T., Foster, G., and 
Datar, S. M. Cost Accounting, Englewood Cliffs, N.J.: Prentice-Hall, 1994. 

I N T R O D U C T I O N  T O  M U L T I P L E  
REGRESSION 
C O N T E N T S .  
............................................................. 
10:l 
Multiple Regression Models 
10.2 
The First-Order Model: Estimating and Interpreting the P Parameters 
10.3 
Model Assumptions 
10.4 
Inferences About the P Parameters 
10.5 
Checking the Overall Utility of a Model 
10.6 
Using the Model for Estimation and Prediction 
10.7 
Residual Analysis: Checking the Regression Assumptions 
10.8 
Some Pitfalls: Estimability, Multicollinearity, and Extrapolation 
S T A T I S T I C S  
I
N
 A
C
T
I
O
N
 
.......................................................................................................................................... 
.......... 
"Wringing" The Bell Curve 
n Chapter 9 we demonstrated how to model the 
his chapter extends the basic concept of Chap- 
: T 
Irelationship between a dependent variable y and i 
ter 9, converting it into a powerful estimation and 
an independent variable x using a straight line. We fit 
f prediction device by modeling the mean value of Y as a 
i funct~on of two or more independent variables. The 
the straight line to the data points, used r and r2 to : 
i techniques developed will enable you to build a model 
measure the strength of the relationship between y ; for a response, y, as a function of two or more van- 
and x, and used the resulting prediction equation to 
ahless 
in the case of a simple linear regression, a 
estimate the  an value of Y or to predict some fu- 
multiple regression analysis involves fitting the model 
ture value of y for a given value of x. 
i to a data set, testing the utility of the model, and using 
f it for estimation and prediction. 
557 

558 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
a 
MULTIPLE REGRESSION MODELS 
Most practical applications of regression analysis utilize models that are more 
complex than the simple straight-line model. For example, a realistic probabilistic 
modcl for reaction time stimulus would include more than just the amount of a 
particular drug in the bloodstream. Factors such as age, a measure of visual per- 
ception, and sex of the subject are a few of the many variables that might be re- 
lated to reaction time. Thus, we would want to incorporate these and other 
potentially important independent variables into the model in order to make ac- 
curate predictions. 
Probabilistic models that include more than one independent variable are 
called multiple regression models. The general form of these models is 
The dependent variable y is now written as a function of k independent variables, 
x,, x,, . . . , x,. The random error term is added to make the model probabilistic 
rather than deterministic. The value of the coefficient P, determines the contribu- 
tion of the independent variable x,, and P,, is the y-intercept.The coefficients Po, P, 
. . ., p, are usually unknown because they represent population parameters. 
At first glance it might appear that the regression model shown above would 
not allow for anything other than straight-line relationships between y and the in- 
dependent variables, but this is not true. Actually, x,, x,, . . . , x, can be functions 
of variables as long as the functions do not contain unknown parameters. For ex- 
ample, the reaction time, y, of a subject to a visual stimulus could be a function of 
the independent variables 
xl = Age of the subject 
x3 = 1 if male subject, 0 if female subject 
The x2 term is called a higher-order term, since it is the value of a quantitative 
variable (x,) squared (i.e., raised to the second power). The x, term is a dummy 
(coded) variable representing a qualitative variable (gender). The multiple re- 
gression model is quite versatile and can be made to model many different types 
of response variables. 
where 
y is the dependent variable 
of the independent variable x, 

I 
SECTION 10.2 
The First-Order Model: Estimating and Interpreting the P Parameters 
559 
As shown in the box, the steps used to develop the multiple regression 
model are similar to those used for the simple linear regression model. 
ng a Mul 
egression Mo 
ypothesize the deterministic component of the model. This compo 
lates the mean, E(y), to the independent variables x,, 
x,, . . , xk. T 
involves the choice of the independent variables to be included in t 
model. 
p 2 Use the sample data to estimate the unknown model paramet 
Po, PI, P2, . . , Pk in the model. 
ep 3 Specify the probability distribution of the random error term, E, and estimat 
the standard deviation of this distribution, u. 
ep 4 Check that the assumptions on E are satisfied, and make model mod 
tions if necessary. 
tep 5 Statistically evaluate the usefulness of the model. 
tep 6 When satisfied that the model is useful, use it for prediction, estimatio 
other purposes. 
In this introduction to multiple regression, we lay the foundation of model build- 
ing (or useful model construction). We consider the most basic multiple regression 
model, called the first-order model. 
THE FIRST-ORDER MODEL: ESTIMATING AND 
INTERPRETING THE P PARAMETERS 
A model that includes only terms for quantitative independent variables, called a 
first-order model, is described in the box. Note that the first-order model does not 
include any higher-order terms (such as x:). 
where xl, x2, . . . , xg are all quantitative variables that are not functions of 
other independent variables. 
Note: p, represents the 
f the line relating y to x, when all the other x's 
are held fixed. 
The method of fitting first-order models-and 
multiple regression models in 
general-is 
identical to that of fitting the simple straight-line model: the method 
of least squares. That is, we choose the estimated model 
1 
*The terminology "first-order" is derived from the fact that each x in the model is raised to the 
first power. 

560 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
, 
that minimizes 
SSE = X ( y  - y)2 
A 
As in the case of the simple linear model, the sample estimates p,, p,, . . . , P, are 
obtained as a solution to a set of simultaneous linear equations." 
The primary difference between fitting the simple and multiple regression 
models is computational difficulty. The (k + I) simultaneous linear equations that 
must be solved lo find the (k + I) estimated coefficients p,, p,, . . . , 3, are difficult 
(sometimes nearly impossible) to solve with a calculator. Consequently, we resort 
to the use of computers. Instead of presenting the tedious hand calculations re- 
quired to fit the models, we present output from a variety of statistical software 
packages. 
Suppose a property appraiser wants to model the relationship between the sale 
price of a residential property in a mid-size city and the following three 
independent variables: (1) appraised land value of the property, (2) appraised 
value of improvements (i.e., home value) on the property, and (3) area of living 
space on the property (i.e., home size). Consider the first-order model 
where 
y = Sale price (dollars) 
x, = Appraised land value (dollars) 
x2 = Appraised improvements (dollars) 
x3 = Area (square feet) 
To fit the model, the appraiser selected a random sample of n = 20 properties 
from the thousands of properties that were sold in a particular year. The resulting 
data are given in Table 10.1. 
a. Use scattergrams to plot the sample data. Interpret the plots. 
b. Use the method of least squares to estimate the unknown parameters Po, PI. 
p2, and p, in the model. 
c. Find the value of SSE that is minimized by the least squares method. 
S o I u t i o n 
a. SPSS scatterplots for examining the bivariate relationships between y and 
xi, 
y and x,, and y and x3 are shown in Figures 10.la-c. Of the three variables, 
appraised improvements (x,) appears to have the strongest linear relation- 
ship with sale price (y). (See Figure 10.lb.) 
*Students who are fa~iliar 
with calc_ulus should note th? &, El, . . . , Ek are the solutions to the set 
of equations i~SSEldp,, = 0, dSSE/dp, = 0, . . . , iK3E/apk = 0. The solution is usually given in 
matrix form, but we do not present the details here. See the references for details. 
FIGI
SPS! 
of Ti 

SECTION 10.2 
The First-Order M o d e l :  Estimating a n d  Interpreting t h e  P Parameters 
561 
TABLE 
1 0.1 
Real Estate Appraisal Data for 20 Properties 
Improvements 
Sale Price, 
Land Value, 
Value, 
Area, 
Property # (Obs.) 
Y 
XI 
X2 
X3 
Source: Alachua County (Florida) Property Appraisers Office. 
FIGURE 1 0 . l a  
Plot of Sale Price with Land Value 
SPSS scatterplots for the data 
ofTable 10.1 
n 
- 
0 
n 
- 
O 
n 
0 
- 
n 
n 
n 
n 
B 
0" 
- 
0 
" ,B 
0 
0 
I 
I 
10000 
20000 
30000 
LANDVAL 
b. The model hypothesized above is fit to the data of Table 10.1 using SAS. A 
portion of the SAS printout is reproduced in Figure 10.2 (page 563). The 
least squares estimates of the p parameters appear (highlighted) in the col- 
umn labeled Parameter Estimate. You can see that Po = 1,470.275919, 

I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
Plot of Sale Price with Improvements Value 
IMPROVAL 
Plot of Sale Price with Area 
AREA 
F, = 314490, p2 = 320445, and p3 = 13.528650. Therefore, the equation 
that minimizes SSE for this data set (i.e., the least squares prediction equa- 
tion) is 
c The minimum value of the SSE is highlighted in Figure 10.2 in the Sum of 
Squares column and the Error row. This value is SSE = 1,003,491,259.4. ,$ 

I 
I 
I 
SECTION 10.2 
The First-Order Model: Estimating and Interpreting the /3 Parameters 
563 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
3 8779676740.6 2926558913.5 
46.662 
0.0001 
Error 
16 1003491259.4 62718203.714 
C Total 
19 9783168000.0 
RootMSE 
7919.48254 
R-Square 
0.8974 
Dep Mean 
56660.00000 
Adj R-Sq 
0.8782 
C.V. 
13.97720 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Varlable 
DF 
Estlmate 
Error 
Parameter=O 
Prob > IT( 
INTERCEP 
1 
1470.275919 
5746.3245832 
0.256 
0.8013 
X 1 
1 
0.814490 
0.51221871 
1.590 
0.1314 
X2 
1 
0.820445 
0.21118494 
3.885 
0.0013 
X3 
1 
13.528650 
6.58568006 
2.054 
0.0567 
FIGURE 10.2 
SAS output for sale price model, Example 10.1 
After obtaining the least squares prediction equation, the analyst will usually 
want to make meaningful interpretations of the P estimates. Recall that in the 
straight-line model (Chapter 9) 
Po represents the y-intercept of the line and PI represents the slope of the line. 
From our discussion in Chapter 9, PI has a practical interpretation-it 
represents 
the mean change in y for every 1-unit increase in x. When the independent vari- 
ables are quantitative, the /3 parameters in the first-order model specified in Ex- 
ample 10.1 have similar interpretations. The difference is that when we interpret 
the p that multiplies one of the variables (e.g., x,), we must be certain to hold the 
values of the remaining independent variables (e.g., x2, x3) fixed. 
To see this, suppose that the mean E(y) of a response y is related to two 
quantitative independent variables, x1 and x2, by the first-order model 
In other words, Po = 1, PI = 2, and P2 = 1. 
Now, when x2 = 0, the relationship between E(y) and x, is given by 
E(y) = 1 + 2x, + (0) = 1 + 2x, 
A graph of this relationship (a straight line) is shown in Figure 10.3. Similar graphs 
of the relationship between E(y) and x, for x, = 1, 
- 
and for x2 = 2, 

564 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
- 
FIGURE 10.3 
Y 
x 2 = 2  
Graphs of E(y) = 1 + 2x, + x, for 
A 
8 - 
x 2 = l  
x, = 0, 1,2 
x,=O 
0 
1 
2 
+ " I  
also are shown in Figure 10.3. Note that the slopes of the three lines are all equal 
to pl = 2, the coefficient that multiplies x,. 
Figure 10.3 exhibits a characteristic of all first-order models: If you graph 
E(y) versus any one variable-say, 
x,-for fixed values of the other variables, the 
result will always be a straight line with slope equal to PI. If you repeat the process 
for other values of the fixed independent variables, you will obtain a set of paral- 
lel straight lines. This indicates that the effect of the independent variable x, on 
E(y) is independent of all the other independent variables in the model, and this 
effect is measured by the slope P, (see the box on p. 559). 
A three-dimensional graph of the model E ( y )  = 1 + 2x1 + x, is shown In 
Figure 10.4. Note that the model graphs as a plane. If you slice the plane at a par- 
ticular value of x, (say, x, = 0), you obtain a straight line relating E(y) to x1 (e.g.. 
E ( y )  = 1 + 2x,). Similarly, if you slice the plane at a particular value of x,, you 
obtain a straight line relating E(y) to x2. Since it is more difficult to visualize 
three-dimensional and, in general, k-dimensional surfaces, we will graph all the 
models presented in this chapter in two dimensions. The key to obtaining these 
graphs is to hold fixed all but one of the independent variables in the model. 
FIGURE 10.4 
The plane E(y) = 1 + 2x, + x2 
p _ _ . _ w m - * - - -  
fer to the first-order model for sale price y considered in Example 10.1. 
Interpret the estimates of the P parameters in the model. 

SECTION 10.3 
M o d e l  A s s u m p t i o n s  
565 
S o l u t i o n  The least squares prediction equation, as given in Example 10.1, is 
= 1,470.28 + .8145x1 + .8204x2 + 1 3 . 5 3 ~ ~ .  
We know that with first-order 
models P, represents the slope of the y-x, line for fixed x2 and x,. That is, P, 
measures the change in E(y) for every 1-unit increase in x, when all other 
independent variables in the model are held fixed. Similar statements can be 
made about p, and p,; e.g., p, measures the change in E(y) for every 1-unit 
increase in x ,  when all other x's in the model are held fixed. Consequently, we 
obtain the following interpretations: 
p, = .8145: We estimate the mean sale price of a property, E(y), to in- 
crease 3145 dollar for every $1 increase in appraised land value ( x , )  when 
both appraised improvements (x2) and area (x,) are held fixed. 
i2 
= 3204: We estimate the mean sale price of a property, E(y), to in- 
crease 3204 dollar for every $1 increase in appraised improvements (x2) 
when both appraised land value (x,) and area (x,) are held fixed. 
p3 = 13.53: We estimate the mean sale price of a property, E(y), to 
increase $13.53 for each additional square foot of living area (x,) when both 
appraised land value ( x , )  and appraised improvements (x2) 
are held fixed. 
The value 3, = 1,470.28 does not have a meaningful interpretation in this exam- 
- 
,. 
ple. To see this, note that 
= P,, when xl = x2 = x, = 0. Thus, Po = 1,470.28 rep- 
resents the estimated mean sale price when the values of all the independent 
variables are set equal to 0. Since a residential property with these characteristics- 
appraised land value of $0, appraised imp;fovements of $0, and 0 square feet of liv- 
ing area-is 
not practical, the value of Po has no meaningful interpretation. In 
general, 3, will not have a practical interpretation unless it makes sense to set the 
values of the x's simultaneously equal to 0. 
tation of the fl parameters in a multiple regression model will de- 
terms specified in the model. The interpretations above are for a 
model only. In practice, you should be sure that a first-orde 
ode1 is the correct model for ECy) before making these P interpretations. 
MODEL ASSUMPTIONS 
We noted in Section 10.1 that the general multiple regression model is of the form 
where y is the response variable that we wish to predict; Po, PI, . . ., Pk are parameters 
with unknown values; xl, x,, . . . , x, are information-contributing variables that are 
measured without error; and E is a random error component. Since Po, P,, . . . , pk and 
x,, x2, . . . , xk are nonrandom, the quantity 
represents the deterministic portion of the model. Therefore, y is composed of two 
components-ne 
fixed and one random-and, 
consequently, y is a random variable. 

566 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
Deterministic 
Random 
portion of model 
error 
r 
. * 
We will assume (as in Chapter 9) that the random error can be positive or nega- 
tive and that for any setting of the x values, x,, x,, . . . , xk, the random error E has 
a normal probability distribution with mean equal to 0 and variance equal to a'. 
Further, we assume that the random errors associated with any (and every) pair of 
y values are probabilistically independent. That is, the error, E, associated with any 
one y value is independent of the error associated with any other y value. These 
assumptions are summarized in the next box. 
, . . . , xk, the random error E has a 
normal probability distribution with mean equal to 0 and variance equal 
to a2. 
Note that a2 represents the variance of the random error E. As such, cr2 is an 
important measure of the usefulness of the model for the estimation of the mean 
and the prediction of actual values of y. If a2 = 0, all the random errors will equal 
0 and the predicted values, j, will be identical to E(y); that is E(y) will be esti- 
mated without error. In contrast, a large value of a2 implies large (absolute) val- 
ues of E and larger deviations between the predicted values, j, and the mean 
value, E(y). Consequently, the larger the value of a2, the greater will be the error 
in estimating the model parameters Po, pl, . . ., pk and the error in predicting a 
value of y for a specific set of values of xl, x2, . . . , xk. Thus, a2 plays a major role 
in making inferences about Po, P,, . . ., Pk, in estimating E(y), and in predicting 
for specific values of x , ,  x2, . . . , xk.- 
Since the variance, a2, of the random error, E ,  will rarely be known, we must 
use the results of the regression analysis to estimate its value. Recall that cr2 is the 
variance of the probability distribution of the random error, E ,  for a given set of 
values for x,, x,, . . . , xk; hence it is the mean value of the squares of the devia- 
tions of the y values (for given values of x , ,  x2, . . . , xk) about the mean value 
E(y).:Tince the predicted value, j estimates E(y) for each of the data points, it 
seems natural to use 
SSE = 
(yi - 
to construct an estimator of a 2 .  
*Since y = E ( ~ )  
+ E, E is equal to the deviation y - E(y). Also, by definition, the variance of a 
random variable is the expected value of the square of the deviation of the random variable from 
its mean. According to our model, E(E) = 0. Therefore, u2 
= E(e2). 

SECTION 10.3 
M o d e l  A s s u m p t i o n s  
567 
For example, in the first-order model of Example 10.2, we found that 
I 
SSE = 1,003,491,259.4. We naw want to use this quantity to estimate the variance 
of E. Recall that the estimator for the straight-line model is s2 = SSE/(n - 2) 
and note that the denominator is (n - Number of estimated /3 parameters), which 
I 
! 
is (n - 2) in the straight-line model. Since we must estimate four parameters, P,, 
PI, P2, and p, for the first-order model, the estimator of a' is 
SSE 
s2 = - 
n - 4  
The numerical estimate for this example is 
SSE 
1,003,491,259.4 
s2 = - 
- 
- 
16 
= 62,718,203.7 
20 - 4 
In many computer printouts and textbooks, s2 is called the mean square for error 
(MSE). This estimate of a' is shown in the column titled Mean Square in the 
SAS printout in Figure 10.2. 
The units of the estimated variance are squared units of the dependent variable y. 
Since the dependent variable y in this example is sale price in dollars, the units of s2 are 
(dollars)'. This makes meaningful interpretation of s2 difficult, so we use the standard 
deviations to provide a more meaningful measure of variability. In this example, 
which is given on the SAS printout in Figure 10.2 next to Root MSE. One useful in- 
terpretation of the estimated standard deviation s is that the interval f 
2s will provide 
a rough approximation to the accuracy with which the model will predict future values 
of y for given values of x.Thus, in Example 10.2, we expect the model to provide pre- 
dictions of sale price to within about f 2s = f 
2(7,919.5) = f 
15,839 dollars.* 
For the general multiple regression model 
we must estimate the (k + 1) parameters Po, PI, P2, . . ., Pk Thus, the estimator of 
a2 is SSE divided by the quantity (n - Number of estimated P parameters). 
We will use the estimator of a' both to check the utility of the model (Sections 
10.4 and 10.5) and to provide a measure of reliability of predictions and estimates 
when the model is used for those purposes (Section 10.6).Thus, you can see that the 
estimation of c2 plays an important part in the development of a regression model. 
Independent Variables 
s' = 
SSE 
- 
- 
SSE 
n - Number of estimated P parameters 
n - (k + 1) 
*The & 2s approximation will improve as the sample slze is increased. We will provide more 
precise methodology for the construction of prediction intervals In Section 10.6. 
tt 
I 

CHAPTER 
10 I n t r o d u c t i o n  t o  Multiple Regression 
INFERENCES A B O U T  T H E  P PARAMETERS 
Inferences about the individual P parameters in a model are obtained using either a 
confidence interval or a test of hypothesis, as outlined in the following two boxes.* 
Test of an Individual Par 
in the Multiple Regression Mod 
One-Tailed Test 
Two-Tailed Test 
". ............... . ...,., " 
Rejection region: t < -t, 
[or t > t, when Ha: p, > 01 
where t, and td2 are based on n - (k + 
k + 1 = Number of P parameters in the model 
Ass~mptions: See Section 10.3 for assu 
// 
bution for the random error componen 
here t,,, is based on n - (k + 1 
k + 1 = Number of P parameters in the model 
We illustrate these methods with another example. 
,s.a"-.s,am-*-m-,- 
* - 
A collector of antique grandfather clocks knows that the price received for the 
clocks increases linearly with the age of the clocks. Moreover, the collector 
- 
hypothesizes that the auction price of the clocks will increase linearly as the 
number of bidders increases. Thus, the following first-order model is hypothesized: 
*The formulas for computing ji 
and its standard error are so complex, the only reasonable way to 
present them is by using matrix algebra. We do not assume a prerequisite of matrix algebra for 
this text and, in any case, we think the formulas can be omitted in an introductory course without 
serious loss.They are programmed into almost all statistical software packages with multiple 
regression routines and are presented in some of the texts listed in the references. 
FIGI
MIN 
Exan

SECTION 10.4 
I n f e r e n c e s  A b o u t  t h e  P P a r a m e t e r s  
569 
FIGURE 10.5 
MINITAB printout for 
Example 10.3 
TABLE 
10.2 
Auction Price Data 
Number of 
Auction 
Age, x, 
Bidders, x, 
Price, y 
-- 
Number of 
Auction 
Age, x, 
Bidders, x, 
Price, y 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
170 
14 
$2,131 
182 
8 
1,550 
162 
11 
1,884 
184 
10 
2,041 
143 
6 
845 
159 
9 
1,483 
108 
14 
1,055 
175 
8 
1,545 
108 
6 
729 
179 
9 
1,792 
111 
15 
1,175 
187 
8 
1,593 
111 
7 
785 
115 
7 
744 
194 
5 
1,356 
168 
7 
1,262 
where 
y = Auction price 
x, = Age of clock (years) 
x2 = Number of bidders 
A sample of 32 auction prices of grandfather clocks, along with their age and the 
number of bidders, is given in Table 10.2. The model y = Po + P l x l  + P2x2 + E is 
fit to the data, and a portion of the MINTTAB printout is shown in Figure 10.5. 
a. Test the hypothesis that the mean auction price of a clock increases as the 
number of bidders increases when age is held constant, that is, test P, > 0. 
Use a = .05. 
b. Form a 90% confidence interval for PI and interpret the result. 
The regression equation is 
Y = -1339 + 12.7 X1 + 86.0 X2 
Predictor 
Coef 
StDev 
t-ratio 
P 
Constant 
-1339.0 
173.8 
-7.70 
0.000 
X1 
12.7406 
0.9047 
14.08 
0.000 
X2 
85.953 
8.729 
9.85 
0.000 
Analysis of Variance 
SOURCE 
DF 
S S 
MS 
F 
P 
Regression 
2 
4283063 
2141532 
120.19 
0.000 
Error 
2 9 
516727 
17818 
Total 
3 1 
4799789 

570 
CHAPTER 
10 I n t r o d u c t i o n  t o  Multiple Regression 
S o l u t i o n  
, **,' 
a. The hypotheses of interest concern the parameter P,. Specifically, 
H,: P2 = 0 
Ha: p, > 0 
The test statistic is a t statistic formed by dividingJhe sample estimate p, of 
the parameter p, by estimated standard error of p, (denoted sP2). These es. 
timates as well as the calculated t value are shown on the MINITAB print- 
out in the Coef, Stdev, and t-ratio columns, respectively. 
A pz 
85.953 
Test statistic: t = - 
= - 
= 9.85 
sg, 
8.729 
The rejection region for the test is found in exactly the same way as the 
rejection regions for the t-tests in previous chapters. That is, we consult 
Table VI in Appendix B to obtain an upper-tail value of t. This is a value t, 
such that P(t > t,) = a. We can then use this value to construct rejection 
regions for either one-tailed or two-tailed tests. 
For a = .05 and n - (k + 1) = 32 - (2 + 1) = 29 df, the critical t value 
obtained from Table VI is t,,,, = 1.699. Therefore, 
Rejection region: t > 1.699 (see Figure 10.6) 
FIGURE 10.6 
Rejection region for H,: p, = 0 vs. 
Ha: p, > 0 
Since the test statistic value, t = 9.85, falls in the rejection region, we 
have sufficient evidence to reject H,. Thus, the collector can conclude that 
the mean auction price of a clock increases as the number of bidders in- 
creases, when age is held constant. Note that the observed significance level 
of the test is also given on the printout. Since p-value = 0, any nonzero a 
will lead us to reject H,,. 
A 90% confidence interval for PI is (from the box): 
0 
Substituting /?, = 12.74, sp, = .905 (both obtained from the MINITAB print- 
out, Figure 10.5) and t,o, = 1.699 (from part a) into the equation, we obtain 
Rejection 
regron 
or (11.21,14.27). Thus, we are 90% confident that PI falls between 11.21 
and 14.27. Since PI is the slope of the line relating auction price (y) to 
age of the clock (xl), we conclude that price increases between $11.21 
and $14.27 for every 1-year increase in age, holding number of bidders 
(x,) constant. 
* 
1.699 

SECTION 10.4 
I n f e r e n c e s  A b o u t  t h e  P P a r a m e t e r s  
571 
: p, = 0, several conclusions are possible: 
There is no relationship between y and x,. 
A straight-line relationship between y and x exists (holding the other 
in the model fixed), but a Type I1 error occurred. 
A relationship between y and x, (holding the other x's in the mod 
fixed) exists, but is more complex than a straight-line relationship (e.g. 
curvilinear relationship may be appropriate). The most you can s 
about a 0 parameter test is that there is either sufficient (if you reje 
Ifo: p, = 0) or insufficient (if you do not reject No: p, = 0) evidence of 
linear (straight-line) relationship b 
and x,. 
The models presented so far utilized quantitative independent variables (e.g., 
home size, age of a clock, and number of bidders). Multiple regression models can in- 
clude qualitative independent variables also. For example, suppose we want to develop 
a model for the mean operating cost per mile, E(y), of cars as a function of the car man- 
ufacturer's country of origin. Further suppose that we are interested only in classifymg 
the manufacturer's origin as "domestic" or "foreign."Then the manufacturer's origin is 
a single qualitative independent variable with two levels: domestic and foreign. Recall 
that with a qualitative variable, we cannot attach a meaningful quantitative measure to 
a given level. Consequently, we utilize a system of coding described below. 
To simplify our notation, let p, be the mean cost per mile for cars manufac- 
tured domestically, and let p, be the corresponding mean cost per mile for those 
foreign-manufactured cars. Our objective is to write a single equation that will 
give the mean value of y (cost per mile) for both domestic and foreign-made cars. 
This can be done as follow: 
1 if the car is manufactured domestically 
where x = 0 
if the car is not manufactured domestically 
The variable x is not a meaningful independent variable as in the case of 
models with quantitative independent variables. Instead, it is a dummy (or indica- 
tor) variable that makes the model work. To see how, let x = 0. This condition will 
apply when we are seeking the mean cost of foreign-made cars. (If the car is not do- 
mestically produced, it must be foreign-made.) Then the mean cost per mile, E b ) ,  is 
This tells us that the mean cost per mile for foreign cars is Po. Or, using our 
notation, it means that p~ = Po. 
Now suppose we want to represent the mean cost per mile, E(y), for cars 
manufactured domestically. Checking the dummy variable definition, we see that 
we should let x = 1: 
or, since Po = p ~ ,  

572 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
PD = PF + P1 
Then it follows that the interpretation of P, is 
P1 = PD - PF 
which is the difference between the mean costs per mile for domestic and foreign 
cars. Consequently, a t-test of the null hypothesis H,j: PI = 0 is equiv, a l ent to 
testing H,: po - /LF = 0. Rejecting H,, then, implies that the mean costs per mile 
for domestic and foreign cars are different. 
It is important to note that p,, and PI in the dummy variable model above do 
not represent the y-intercept and slope, respectively, as in the simple linear re- 
gression model of Chapter 9. In general, when using the 1-0 system of coding* for 
a dummy variable, Po will represent the mean value of y for the level of the qual- 
itative variable assigned a value of O (called the base level) and PI will represent a 
difference between the mean values of y for the two levels (with the mean of the 
base level always subtracted.)? 
Learning the Mechanics 
10.1 Write a first-order model relating E(y) to: 
a. two quantitative independent variables 
b. four quantitative independent variables 
c. /fi-ve quantitative independent variables 
10.2 SAS was used to fit the model E ( y )  = P, + P,x, + 
P,x, to n = 20 data points and the printout shown on 
page 573 was obtained. 
a. What are the sample estimates of P,,, P,, and P,? 
b. What is the least squares prediction equation? 
c. Find SSE, MSE, and s. Interpret the standard deviation 
in the context of the problem. 
d. Test H,,: PI = 0 against Ha: p, # 0. Use a = .05. 
e. Use a 95% confidence interval to estimate P,. 
10.3 Suppose you fit the multiple regression model 
Y = Po + Ptx1 + P 2 ~ 2  + P3x3 + E 
to n = 30 data points and obtain the following result: 
jj = 3.4 - 4 . 6 ~ ~  
+ 2 . 7 ~ ~  
+ .93x3 
The estimated standard errors of p, and 3, are 1.86 
and .29, respectively. 
a. Test the null hypothesis H,: p, = 0 against the alter- 
native hypothesis Hi,: P, # 0. Use a = .05. 
b. Test the null hypothesis H,,: P, = 0 against the alter- 
native hypothesis Ha: /3, # 0. Use a = .05. 
c. The null hypothesis H,: P2 = 0 is not rejected. In 
contrast, the null hypothesis H,,: P, = 0 is rejected. 
Explain how this can happen even though pz > p3 
10.4 Suppose you fit the first-order multiple regression model 
to n = 25 data points and obtain the prediction equamil 
= 6.4 + 3 . 1 ~ ~  
+ .92x, 
The estimated stand_ard deviations of the sampling dis- 
tributions of Dl and p, are 2.3 and .27, respectively. 
a. Test H,,: p, = 0 against Ha: p, > 0. Use a = .05. 
b. Test H,,: p, = 0 against Ha: p, # 0. Use a = .05. 
c. Find a 90% confidence interval for PI. Interpret the 
interval. 
d. Find a 99% confidence interval for P,. Interpret the 
interval. 
10.5 How is the number of degrees of freedom available for 
estimating u2 
(the variance of E) related to the number 
of independent variables in a regression model? 
10.6 Consider the first-order model equation in three quan- 
titative independent variables 
a. Graph the relationship between y and x, for x2 = 1 
and x, = 3. 
*You do not have to use a 1-0 system of codmg for the dummy variables.Any two-value system wdl 
work, but the mterpretat~on glven to the model parameters w~ll depend on the code Umg the 1-0 
system makes the model parameters easy to mterpret 
?The system of codmg for a qualitative var~able at more than two, say k, levels requlres that you 
create k-1 dummy var~ables, one for each level except the base level. The mterpretation of P, is 
PL = &vrl 
r - 
level 

SECTION 10.4 
I n f e r e n c e s  A b o u t  t h e  p P a r a m e t e r s  
573 
SAS Output for Excercise 10.2 
Dep Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
2 128329.27624 
64164.63812 
7.223 
0.0054 
Error 
17 151015.72376 
8883.27787 
C Total 
19 279345.00000 
Root MSE 
94.25114 
R-Square 
0.4594 
Dep Mean 
360.50000 
Adj R-Sq 
0.3958 
C.V. 
26.14456 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
farlable 
DF 
Estimate 
Error 
Parameter=O Prob > IT1 
INTERCEP 
1 
506.346067 
45.16942487 
11.210 
0.0001 
X1 
1 
-941.900226 
275.08555975 
-3.424 
0.0032 
X2 
1 
-429.060418 
379.82566485 
-1.130 
0.2743 
b. Repeat part a for x, = -1 and x, = 1. 
c. How do thc graphed lines in parts a and b relate to 
each other? What is the slope of each line? 
d. If a linear model is first-order in three independent 
variables, what type of geometric relationship will 
you obtain when E(y) is graphed as a function of 
one of the independent variables for various combi- 
nations of values of the other independent variables? 
Applying the Concepts 
10.7 Detailed interviews were conducted with over 1,000 street 
vendors in the city of Puebla, Mexico, in order to study 
the factors influencing vendors' incomes (World 
viduals working in the street, and included vendors with 
carts and stands on wheels and excluded beggars, drug 
dealers, and prostitutes. The researchers collected data on 
gender, age, hours worked per day, annual earnings, and 
education level. A subset of these data appear in the table 
on page 574. 
a. Write a first-order model for mean annual earnings, 
E b ) ,  as a function of age (x,) and hours worked (x,). 
b. The model was fit to the data using STATISTIX. 
Find the least squares prediction equation on the 
printout shown below. 
c. Interpret the estimated /3 coefficients in your model. 
d. Is age x, a statistically useful predictor of annual earn- 
Development, Feb. 1998). Vendors were defined as indi- 
ings? Test using a = .01. 
STATISTIX Output for Exercise 10.7 
UNWEIGHTED LEAST SQUARES LINEAR REGRESSION OF EARNINGS 
PREDICTOR 
VARIABLES 
COEFFICIENT 
STD ERROR 
STUDENT'S T 
P 
R- SQUARED 
0.5823 
RESID. MEAN SQUARE (MSE) 
300016 
ADJUSTED R-SQUARED 0.5126 
STANDARD DEVIATION 
547.737 
SOURCE 
DF 
S S 
MS 
F 
P 
---------- 
- - - 
---------- ---------- ----- 
------ 
REGRESSION 
2 
5018232 
2509116 
8.36 
0.0053 
RESIDUAL 
12 
3600196 
300016 
TOTAL 
14 
8618428 
CASES INCLUDED 15 
MISSING CASES 0 

574 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
e. Construct a 99% confidence interval for P,. Inter- 
pret the interval in the words of the problem. 
Vendor 
Annual 
Hours Worked 
Number 
Earnings, y 
Age, x, 
per Day, x2 
Source: Adapted from Smith, Paula A., and Metzger, Michael R., 
"The Return to Education: Street Vendors in Mexico." World 
Development, Vol. 26, No. 2, Feb. 1998, pp. 289-296. 
10.8 Refer to the Chief Executive (Sept. 1999) study of chief 
e ecutive officers (CEOs) from a variety of industries, 
4 
, 
xercise 9.35 (p. 500). Recall that a CEO's pay (y) was 
modeled as a function of company performance (x,), 
where performance was measured as a three-year annu- 
alized total return to shareholders assuming dividends 
are reinvested. For this exercise, consider a second inde- 
pendent variable, company sales (x,). The data for all 
three variables are listed in the table below. 
a. Construct a scattergram of total pay versus company 
sales. Does your scattergram suggest that company 
sales will help explain the variation in CEO pay? 
Explain. 
b. The first-order model, E(y) = Po + P,x, t & .  
was lit to the data using EXCEL. Locate the least- 
squares estimates of the /3 coefficients on the print- 
out on p. 575 and interpret their values. 
C. Test H,,: /?, 
= 0 versus Ha: p2 < 0 using a = .05. Re- 
port your findings in the words of the problem. 
d. Locate a 95% confidence interval for fl, on 
the printout and interpret it in the words of the 
problem. 
10.9 Many variables influence the price of a company's 
common stock, including company-specific internal 
variables such as product quality and financial perfor- 
mance, and external market variables such as interest 
rates and stock market performance.The table on page 
576 contains quarterly data on three such external vari- 
ables (x,, x2, x3) and the price y of Ford Motor 
Company's Common stock (adjusted for a stock split). 
The Japanese Yen Exchange Rate (the value of a U.S. 
dollar expressed in yen), x,, measures the strength of 
the yen versus the U.S. dollar. The higher the rate, the 
cheaper are Japanese imports-such 
as the automo- 
biles of Toyota, Nissan, Honda, and Subaru-to US. 
consumers. Similarly, the higher the deutsche mark 
exchange rate, x,, the less expensive are BMW's and 
Mercedes Benz's to U.S. consumers. The S&P 500 
Index, x,, is a general measure of the performance of 
the market for stocks in U.S. firms. 
a. Fit the first-order model y = Po + P,x, + P2x2 
+ P3x3 + E to the data. Report the least squares pre- 
diction equation. 
CE017.DAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . , . . .. 
Total Pay, y 
Company 
Company Sales, 
Company 
CEO 
($ thousands) 
Performance, x, 
(S millions), x2 
................................................... 
. ....................................................................................................................................................................... 
Cummins Engine 
James A. Henderson 
4,338 
.8 
6,266 
Bank of New York 
Thomas A. Renyi 
7,121 
52.5 
63,579 
SunTrust Banks 
L. Phillip Humann 
3,882 
33.0 
93,170 
Bear Stearns 
James E. Cayne 
25,002 
46.1 
7,980 
Charles Schwab 
Charles R. Schwab 
16,506 
85.5 
3,388 
Coca-Cola 
M. Douglas Ivester 
12,712 
22.9 
18,813 
Time Warner 
Gerald M. Levin 
25,136 
49.6 
14,582 
Humana 
Gregory H. Wolf 
4,516 
-13.3 
9,781 
Engelhard 
Orin R. Smith 
6,189 
-1.8 
4,172 
Chubb 
Dean R. O'Hare 
4,052 
12.3 
6,337 
American Home Products 
John R. Stafford 
8,046 
35.5 
13,463 
Merck 
Raymond V. Gilmartin 
7.178 
33.4 
26.898 
Schering-Plough 
Richard J. Kogan 
6,818 
61.8 
8,077 
Home Depot 
Arthur M. Blank 
2,900 
58.6 
30,219 
Dell Computer 
Michael S. Dell 
115,797 
222.4 
13,663 
BellSouth 
F. Duane Ackerman 
18,134 
35.8 
23.123 
Delta Air Lines 
Leo F. Mullin 
17,085 
20.8 
14,138 
Source: Chief Executive, Sept. 1999, pp. 45-59. 

EXCEL Output for Exercise 10.8 
I SUMMARY OUTPUT 
I 
1 
R Sauare 
1 
0.8168492 1 
I 
I 
I 
I 
I 
Regression Statistics 1 
Multiple R 
0.9037971 1 
Adjusted R Square 
Standard Error 
Observations 
0 -7906848 
12136.8165 
17 
ANOVA 
Regression 
- 
Residual 
Total 
X Variable 2 
1 -0.175652631 
0.1291065761-1.3605242941 
0.195167091 
-0.4525589441 
0.10125368 
df 
2 
Intercept 
X Variable 1 
14 
16 
S S 
9197518606 
Coefficients 
397.819904 
451.741037 
2062232399 
11259751005 
MS 
4598759303 
147302314.2 
Standard Error 
4758.206523 
57.9979736 
F 
31.21987138 
t Stat 
0.083607112 
7.788910701 
Significance F 
6.912923-06 
P-value 
0.934552536 
1.866933-06 
Lower 95% 
-9807.527182 
327.3476448 
Upper 95% 
10603.167 
576.13443 

576 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
F0RDSTOCK.DAT (Data for Exercise 10.9) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Ford Motor Co. 
Yen Exchange 
Deutsche Mark 
Date 
Common Stock, y 
Rate, x, 
Exchange Rate, x2 
S h P  500, x, 
............................................................... . ...................................................................................................... . 
Sources: 1. International Financial Statistics, International Monetary Fund, Washington, D. C., 1998; 2. 
YahooFinance (www.yahoo.com). 
b. Find the standard deviation of the regression model 
and interpret its value in the context of this problem. 
c. Do the data provide sufficient evidence to conclude 
that the price of Ford stock decreases as the yen rate 
increases? Report the observed significance level 
and reach a con~lusion~using 
a = .05. 
d. Interpret the value of p, in terms of these data. Re- 
member that your interpretation must recognize the 
presence of the other variables in the model. 
10.10 A disabled person's acceptance of a disability is critical 
to the rehabilitation process. Thc Journal of 
Rehabilitation (Sept. 1989) published a study that inves- 
tigated the relationship between assertive behavior 
level and acceptance of disability in 160 disabled adults. 
The dependent variable, assertiveness (y), was mea- 
sured using the Adult Self Expression Scale (ASES). 
Scores on the ASES range from 0 (no assertiveness) to 
192 (extreme assertiveness). The model analyzed was 
E(Y) = P,, + PIX, + P 2 ~ 2  + P3~3, where 
xl = Acceptance of disability (AD) score 
x2 = Age (years) 
x3 = Length of disability (years) 
The regression results are shown in the table. 
Independent Variable 
t 
Two-Tailed p-Value 
AD score (x,) 
5.96 
.0001 
Age (x,) 
0.01 
.9620 
Length (x3) 
1.91 
,0576 
a. Is there sufficient evidence to indicate that AD 
score is positively linearly related to assertiveness 
level, once age and length of disability are account- 
ed for? Test using a = .05. 
b. Test the hypothesis H,: P, = 0 against Ha: fi, f 0 
Use a = .05. Give the conclusion in the words of 
the problem. 

SECTION 10.4 
I n f e r e n c e s  A b o u t  t h e  P P a r a m e t e r s  
577 
Weight 
Digestion 
Acid-Detergent 
Feeding Trial 
Diet 
Change ( O h )  
Efficiency (%) 
Fiber (96) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Plants 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Duck Chow 
Source: Gadallah, F. L. and Jefferies. R. L. "Forage quality in brood rearing areas of the lesser 
snow goose and the growth of captlve goslings." Journal ofApplied Biology,Vol. 32, No. 2,1995, 
pp. 281-282 (adapted from Figures 2 and 3). 
c. Test the hypothesis H,: /3, = 0 against Ha: P, > 0. 
Use a = .05. Give the conclusion in the words of 
the problem. 
10.11 Refer to the Journal ofApplied Ecology (Vol. 32,1995) 
study of the feeding habits of baby snow geese, 
Exercise 9.56 (p. 514). The data on gosling weight 
change, digestion efficiency, acid-detergent fiber (all 
measured as percentages) and diet (plants or duck 
chow) for 42 feeding trials are reproduced in the table 
' 
above.The botanists were interested in predicting weight 
change (y) as a function of the other variables. The 
first-order model E(y) = p,, + P,x, + P2x2, where x, 
is digestion efficiency and x, is acid-detergent fiber, 
was fit to the data. The MINITAB printout is provided 
on page 578. 
a. Find the least squares prediction equation for 
weight change, y. 
b. Interprct the p-estimates in the equation, part a. 

578 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
MINITAB Output for Exercise 10.1 1 
The regression equation is 
wtchnge = 12.2 - 0.0265 digest - 0.458 acid 
Predictor 
Coef 
StDev 
T 
P 
Constant 
12. 180 
4.402 
2.77 
0.009 
digest 
-0.02654 
0.05349 
-0.50 
0.623 
acid 
-0.4578 
0.1283 
-3.57 
0.001 
Analysis of Variance 
Source 
DF 
SS 
MS 
F 
P 
Regression 
2 
542.03 
271.02 
21.88 
0.000 
Error 
3 9 
483.08 
12.39 
Total 
4 1 
1025.12 
c. Conduct a test to determine if digestion efficiency, 
10.13 Location is one of the most important decisions for 
x,, is a useful linear predictor of weight change. U& 
a = .01. 
d. Form a 99% confidence interval for P2. Interpret 
the result. 
e. Explain how to include the qualitative variable diet 
into the model. 
10.12 Empirical research was conducted to investigate the 
variables that impact the size distribution of manufac- 
turing firms in international markets (World 
Development, Vol. 20,1992). Data collected on n = 54 
countries were used to model the country's size distri- 
bution y, measured as the share of manufacturing firms 
in the country with 100 or more workers. The model 
studied was E(y) = P, + P,x, + P2x2 + P3x3 + P4x4 
+ PSx5, where 
x1 = natural logarithm of Gross National Product 
(LGNP) 
x2 = geographic area per capita (in thousands of 
square meters) (AREAC) 
xg = share of heavy industry in manufacturing value 
added (SVA) 
x4 = ratio of credit claims on the private sector to 
Gross Domestic Product (CREDIT) 
x5 = ratio of stock equity shares to Gross Domestic 
Product (STOCK) 
hotel chains and lodging firms. A hotel chain that can 
select good sites more accurately and quickly than its 
competition has a distinct competitive advantage. 
Researchers S. E. Kimes (Cornell University) and J. 
A. Fitzsimmons (University of Texas) studied the site 
selection process of La Quinta Motor Inns, a moder- 
ately priced hotel chain (Interfaces, Mar.-Apr. 1990). 
Using data collected on 57 mature inns owned by La 
Quinta, the researchers built a regression model 
designed to predict the profitability for sites under 
construction.The least squares model is given below: 
where 
y = operating margin (measured as a percentage) 
- (profit + interest expenses + depreciation 
- 
total revenue 
x1 = state population (in thousands) divided by the 
total number of inns in the state 
x2 = room rate ($) for the inn 
x3 = square root of the median income of the area (in 
$ thousands) 
x4 = number of college students within four miles of 
the inn 
a. The researchers hypothesized that the higher the 
credit ratio of a country, the smaller the size distri- 
bution of manufacturing firms. Explain how to test 
this hypothesis. 
b. The researchers hypothesized that the higher the 
stock ratio of a country, the larger the size distribu- 
tion of manufacturing firms. Explain how to test this 
10.14 In the oil industry, water that mixes with crude oil 
hypothesis. 
during production and transportation must be 
All variables were "standardized" to have a mean of 0 
and a standard deviation of 1. Interpret the j3 estimates 
of the model. Commcnt on the effect of each indepen- 
dent variable on operating margin, y. [Note: A prof- 
itable inn is defined as one with an operating margin of 
over 50% .] 
C 
..... 
4
N
...... 
-
Sou, 
spec 
10.15 
1

SECTION 10.4 
I n f e r e n c e s  A b o u t  t h e  P P a r a m e t e r s  
579 
Disperse Phase 
Time 
Surfactant 
Solid 
Voltage, 
Volume, 
Salinity, 
Temperature, 
Delay, 
Concentration, 
Particles, 
Experiment 
Y 
XI 
X2 
X3 
X4 
X5 
Span: Triton, 
X7 
Number 
(kwlcm) 
(%I 
(YO) 
(='c> 
(hours) 
(YO) 
x6 
(YO) 
....................................................................................................................................................................................................................................... 
1 
.64 
40 
1 
4 
.25 
2 
.25 
.5 
2 
30 
80 
1 
4 
.25 
4 
.25 
2 
3 
3.20 
40 
4 
4 
.25 
4 
.75 
.5 
4 
.48 
80 
4 
4 
.25 
2 
.75 
2 
5 
1.72 
40 
1 
23 
.25 
4 
.75 
2 
6 
.32 
80 
1 
23 
.25 
2 
.75 
.5 
7 
.64 
40 
4 
23 
.25 
2 
.25 
2 
8 
.68 
80 
4 
23 
.25 
4 
.25 
.5 
9 
.12 
40 
1 
4 
24 
2 
.75 
2 
10 
.88 
80 
1 
4 
24 
4 
.75 
.5 
11 
2.32 
40 
4 
4 
24 
4 
.25 
2 
12 
.40 
80 
4 
4 
24 
2 
.25 
.5 
13 
1.04 
40 
1 
23 
24 
4 
.25 
.5 
14 
.12 
80 
1 
23 
24 
2 
.25 
2 
15 
1.28 
40 
4 
23 
24 
2 
.75 
.5 
16 
.72 
80 
4 
23 
24 
4 
.75 
2 
17 
1.08 
0 
0 
0 
0 
0 
0 
0 
18 
1.08 
0 
0 
0 
0 
0 
0 
0 
19 
1 .04 
0 
0 
0 
0 
0 
0 
0 
Yo~irce F@rdedal, H , et al. "A multwariate analys~s of W/O emulsions in high external electrlc fields as studled by means of dielectric time domain 
spectroscopy." Journal of Colloid and Interface Science, Vol. 173, No. 2, Aug. 1995, p. 398 (Table 2). 
removed. Chemists have found that the oil can be 
extracted from the waterloil mix electrically. 
Researchers at the University of Bergen (Norway) 
conducted a series of experiments to study the factors 
that influence the voltage (y) required to separate the 
water from the oil (Journal of Colloid and Interface 
Science, Aug. 1995). The seven independent variables 
investigated in the study are listed in the table above. 
(Each variable was measured at two levels-a 
"low" 
level and a "high" level.) Sixteen waterloil mixtures 
were prepared using different combinations of the 
independent variables; then each emulsion was 
exposed to a high electric field. In addition, three mix- 
tures were tested when all independent variables were 
set to 0. The data for all 19 experiments are also given 
in the table. 
a. Propose a first-order model for y as a function of all 
seven independent variables. 
b. Use a statistical software package to fit the model 
to the data in the table. 
c. Fully interpret the P estimates. 
10.15 The owner of an apartment building in Minneapolis 
believed that her property tax bill was too high because 
of an overassessment of the property's value by the city 
tax assessor.The owner hired an independent real estate 
appraiser to investigate the appropriateness of the city's 
assessment. The appraiser used regression analysis to 
explore the relationship between the sale prices of apart- 
ment buildings sold in Minneapolis and various charac- 
teristics of the properties. Twenty-five apartment build- 
ings were randomly sampled from all apartment build- 
ings that were sold during a recent year. The table on 
page 580 lists the data collected by the appraiser. The 
real estate appraiser hypothesized that the sale price 
(that is, market value) of an apartment building is related 
to the other variables in the table according to the model 
Y = Po + PIXI + P 2 ~ 2  + P3x3 + P4x4 + Psxs + &. 
a. Fit the real estate appraiser's model to the data in the 
table. Report the least squares prediction equation. 
b. Find the standard deviation of the regression model 
and interpret its value in the context of this problem. 
c. Do the data provide sufficient evidence to conclude 
that value increases with the number of units in an 
apartment building? Report the observed signifi- 
cance level and reach a_ conclusion using a = .05. 
d. Interpret the value of p, in terms of these data. Re- 
member that your interpretation must recognize the 
presence of the other variables in the model. 
e. Construct a scattergram of sale price versus age. 
What does your scattergram suggest about the rela- 
tionship between these variables? 
f. Test H,: p, = 0 against Ha: p2 < 0 using a = .01. In- 
terpret the result in the context of the problem. Does 
the result agree with your observation in part e? Why 
is it reasonable to conduct a one-tailed rather than a 
two-tailed test of this null hypothesis? 
g. What is the observed significance level of the hy- 
pothesis test of part f? 

580 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
MNSALES.DAT (Data for Exercise 10.15) 
.................................................................................................................................................................................................................................................. 
No. of 
Age of Structure, 
Lot Size, 
No. of On-Site 
Gross Building 
Code No. 
Sale Price, y ($) 
Apartments, q 
x, (years) 
x3 (sq. ft) 
Parking Spaces, x, 
Area, x, (sq. ft) 
........................................................................................................................................................................................................ 
0229 
90,300 
4 
82 
4,635 
0 
4,266 
0094 
384,000 
20 
13 
17,798 
0 
14,391 
0043 
157,500 
5 
66 
5,913 
0 
6,615 
0079 
676,200 
26 
64 
7,750 
6 
34,144 
0134 
165,000 
5 
55 
5,150 
0 
6,120 
0179 
300,000 
10 
65 
12,506 
0 
14,552 
0087 
108,750 
4 
82 
7,160 
0 
3,040 
0120 
276,538 
11 
23 
5,120 
0 
7.881 
0246 
420,000 
20 
18 
11,745 
20 
12,600 
0025 
950,000 
62 
7 1 
21,000 
3 
39,448 
0015 
560,000 
26 
74 
11,221 
0 
30,000 
0131 
268,000 
13 
56 
7,818 
13 
8,088 
0172 
290,000 
9 
76 
4,900 
0 
11,315 
0095 
173,200 
6 
21 
5,424 
6 
4,461 
0121 
323,650 
11 
24 
11,834 
8 
9,000 
0077 
162,500 
5 
19 
5,246 
5 
3,828 
0060 
353,500 
20 
62 
11,223 
2 
13,680 
0174 
134,400 
4 
70 
5,834 
0 
4,680 
0084 
187,000 
8 
19 
9,075 
0 
7,392 
0031 
155,700 
4 
57 
5,280 
0 
6,030 
0019 
93,600 
4 
82 
6,864 
0 
3,840 
0074 
110,000 
4 
50 
4 3  10 
0 
3,092 
0057 
573,200 
14 
10 
11,192 
0 
23,704 
0104 
79,300 
4 
82 
7,425 
0 
3,876 
0024 
272,000 
5 
82 
7,500 
0 
9,542 
Source Robinson Appra~sal Co., Inc., Mankato, Minnesota 
CHECKING THE OVERALL UTILITY OF A MODEL 
Conducting t-tests on each P parameter in a model is not the best way to determine 
whether the overall model is contributing information for the prediction of y. If we 
were to conduct a series of t-tests to determine whether the independent variables 
are contributing to the predictive relationship, we would be very likely to make one 
or more errors in deciding which terms to retain in the model and which to exclude. 
For example, suppose you fit a first-order model in 10 quantitative x vari- 
ables and decide to conduct t-tests on all 10 of the individual p's in the model, 
each at a = .05. Even if all the P parameters (except Po) are equal to 0, approx- 
imately 40% of the time you will incorrectly reject the null hypothesis at least 
once and conclude that some P parameter differs from O.* Thus, in multiple re- 
gression models for which a large number of independent variables are being 
considered, conducting a series of t-tests may include a large number of in- 
significant variables and exclude some useful ones. To test the utility of a multi- 
ple regression model, we need a global test (one that encompasses all the P 
parameters). We would also like to find some statistical quantity that measures 
how well the model fits the data. 
*The proof of this result proceeds as follows: 
P(Reject Hi, at least oncejp, = p, = ... = p,, = 0) 
= 1 - P(Re1ect H,, no t ~ m c s p ,  
= P, = -. . = P,,, = 0 )  
FIG
SAS 
prict 

SECTION 10.5 
C h e c k i n g  t h e  O v e r a l l  U t i l i t y  o f  a  M o d e l  
581 
We commence with the easier problem-finding 
a measure of how well a 
linear model fits a set of data. For this we use the multiple regression equivalent of 
r', the coefficient of determination for the straight-line model (Chapter 9), as 
shown in the box. 
EFlNlTlON 10 
The multiple coefficient of determination, R ~ ,  
is defined as 
SSE 
SS,, - SSE 
Explained variability 
~ 2 = 1 - - -  - 
- 
- 
S S ~ ~  S S ~ ~  Total variability 
Just as for the simple linear model, R2 represents the fraction of the sample vari- 
ation of the y values (measured by SS,,) that is explained by the least squares pre- 
diction equation. Thus, R2 = 0 implies a complete lack of fit of the model to the 
data and R' 
= 1 implies a perfect fit with the model passing through every data 
point. In general, the larger the value of R2, the better the model fits the data. 
To illustrate, the value R' = .8974 for the sale price model of Example 10.1 
is indicated in Figure 10.7. This high value of R2 implies that using the indepen- 
dent variables land value, appraised improvements, and home size in a first-order 
model explains 89.7% of the total sample variation (measured by SS,,) of sale 
price y. Thus, R2 is a sample statistic that tells how well the model fits the data and 
thereby represents a measure of the usefulness of the entire model. 
Model 
3 8779676740.6 2926558913.5 
46.662 
0.0001 
Error 
16 1003491259.4 62718203.714 
C Total 
19 9783168000.0 
Root MSE 
7919.48254 
DepMean 56660.00000 
Ad]R-Sq 
0.8782 
C.V. 
13.97720 
FIGURE 10.7 
SAS printout for sale 
price model 
I 
Parameter Estimates 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
I 
Parameter 
Standard 
T for HO: 
Variable 
DF 
Estimate 
Error 
Parameter=O 
Prob > IT1 
t I INTERCEP 
1 
1470.275919 
5746.3245832 
0.256 
0.8013 
A large value of R2 computed from the sample data does not necessarily mean 
that the model provides a good fit to all of the data points in the population. For ex- 
ample, a first-order linear model that contains three parameters will provide a perfect 
fit to a sample of three data points and R~ will equal 1. Likewise, you will always ob- 
tain a perfect fit (R2 = 1) to a set of n data points if the model contains exactly n pa- 
rameters. Consequently, if you want to use the value of R2 as a measure of how 
useful the model will be for predicting y, it should be based on a sample that contains 
substantially more data points than the number of parameters in the model. 

582 
CHAPTER 10 I n t r o d u c t i o n  t o  Multiple Regression 
As an alternative to using R2 as a measure of model adequacy, the adjusted 
multiple coefficient of deternzinution, denoted R:, is often reported. The formula 
for R: is shown in the box. 
The adjusted multiple coefficient of determination is given by 
Note: R: 5 R2 
R2 and R: have similar interpretations. However, unlike R2, R: takes into account 
("adiusts" for) both the sample size n and the number of P parameters in the 
model. R: will always be smaller than R2, and more importantly, cannot be 
"forced" to 1 by simply adding more and more independent variables to the 
model. Consequently, analysts prefer the more conservative R: when choosing a 
measure of model adequacy. In Figure 10.7, R: is shown directly below the value 
of R'. Note that R: = 3782, a value only slightly smaller than R'. 
Despite their utility, R2 and Rt are only sample statistics. Therefore, it is 
dangerous to judge the global usefulness of the model based solely on these val- 
ues. A better method is to conduct a test of hypothesis involving all the /3 param- 
eters (except Po) in a model. In particular, for the sale price model (Example 10.1). 
we would test 
H,: PI = p2 = p3 = 0 
Ha: At least one of the coefficients is nonzero 
The test statistic used to test this hypothesis is an F statistic, and several 
equivalent versions of the formula can be used (although we will usually rely on 
the computer to calculate the F statistic): 
(SS,, - SSE)/k - 
- 
~ 2 / k  
Test statistic: F = SSE/[n - ( k  + I)] 
(1 - ~ ~ ) / [ n  
- ( k  + I ) ]  
Both these formulas indicate that the F statistic is the ratio of the explnined 
variability divided by the model degrees of freedom to the unexplained variabili- 
ty divided by the error degrees of freedom. Thus, the larger the proportion of the 
total variability accounted for by the model, the larger the F statistic. 

1 
3 
" 
S 
I- 
1- 
) ?  
a1 
In 
ed 
ili- 
.he 
SECTION 
10.5 
C h e c k i n g  t h e  Overall Utility o f  a Model 
583 
To determine when the ratio becomes large enough that we can confidently 
reject the null hypothesis and conclude that the model is more useful than no 
model at all for predicting y, we compare the calculated F statistic to a tabulated 
F value with k df in the numerator and [n - (k + I)] df in the denominator. Re- 
call that tabulations of the F-distribution for various values of a are given in Tab- 
les VIII, IX, X, and XI of Appendix B. 
Rejection region: F > Fa, where F is based on k numerator and 
n - (k + 1) denominator degrees of freedom. 
For the sale price example [n = 20, k = 3, n - (k + 1) = 16, and a = .05], we will 
reject H,,: p, = P2 = p3 = 0 if 
From the SAS printout (Figure 10.7), we find that the computed F value is 46.66. 
Since this value greatly exceeds the tabulated value of 3.24, we conclude that at 
least one of the model coefficients P,, P2, and P, is nonzero. Therefore, this global 
F-test indicates that the first-order model y = Po + Plxl + P2x2 + P3x3 + E is 
useful for predicting sale price. 
Like SAS, most other regression packages give the F value in a portion of 
the printout called the "Analysis of Variance." This is an appropriate descriptive 
term, since the F statistic relates the explained and unexplained portions of the 
total variance of y. For example, the elements of the SAS printout in Figure 10.7 
that lead to the calculation of the F value are: 
Sum of Squares (Model)/df (Model) 
Mean Square (Model) 
F Value = 
- 
- 
Sum of Squares (Error)/df (Error) 
Mean Square (Error) 
Note, too, that the observed significance level for the F statistic is given under the 
heading Prob > F as .0001, which means that we would reject the null hypothesis 
H,: p, = P2 = P3 = 0 at any a value greater than .0001. 
The analysis of variance F-test for testing the usefulness of the model is 
summarized in the next box. 
s are unimportant for 
H,: At least one& # 0 
del term is useful for 
(SS,, - SSE)/k 
- 
- 
R2/k 
SSE/[n - (k + I)] 
(1 - R2)/[n - (k + I)] 
(continued) 

584 
CHAPTER 
10 I n t r o d u c t i o n  t o  Multiple Regression 
I 
Assumptions: The stand 
ression assumptions about the random error 
ection of the null hypothesis Hn: PI = 
to the conclusion [with 100(1 
atistically useful. However, statistically "useful" does not necessarily mean 
'best." Another model may prove even more useful in terms of providing 
more reliable estimates and predictions. This global F-test is usually regarded 
as a test that the model must pass to merit further consideration. 
wm---m-*s-B-""m 
"""mm-m"& 
*"m-,-*"-mm"-="*" 
"""-~""~~~"bm"~s"ama~~~-"b*x~m"%"%m"""mm-"""*~"""m"- 
~ ~ " ~ " " " " * ~ " " ~ m ~ ~ m s ~ ~ m M ~ m ~ ~ ~ - ~  
r to Example 10.3, in which an antique collector modeled the auction price I! 
of grandfather clocks as a function of the age of the clock, x,, and the number of 
bidders, x,. The hypothesized first-order model is 
Y = Po + P l ~ l  
+ P 2 ~ 2  + E 
A sample of 32 observations is obtained, with the results summarized in the 
MINITAB printout repeated in Figure 10.8. 
FIGURE 10.8 
MINITAB printout for 
Example 10.4 
The regression equation is 
Y = -1339 + 12.7 XI + 86.0 X2 
Predictor 
Coef 
StDev 
t-ratio 
P 
Constant 
-1339.0 
173.8 
-7.70 
0.000 
XI 
12.7406 
0.9047 
14.08 
0.000 
X2 
85.953 
8.729 
9.85 
0.000 
Analysis of Variance 
SOURCE 
DF 
SS 
MS 
F 
P 
Regression 
2 
4283063 
2141532 
120.19 
0.000 
Error 
2 9 
516727 
17818 
Total 
3 1 
4799789 
a. Find and interpret the adjusted coefficient of determination R: for this example. 
' 
b. Conduct the global F-test of model usefulness at the a = .05 level of signif- 
icance. 
1 
a. The Ra value (highlighted in Figure 10.8) is .885.This implies that the least 
' 
S o l u t i o n  
squares model has explained about 88.5% of the total sample variation in 
i 
y values (auction prices), after adjusting for sample size and number of 
j 
independent variables in the model. 
b. The elements of the global test of the model follow: 

SECTION 10.5 
C h e c k i n g  t h e  Overall Utility o f  a Model 
585 
H,,: p, = Pz = 0 
(Note: k = 2) 
Ha: At least one of the two model coefficients is nonzero 
Test statistic: F = 120.19 (highlighted in Figure 10.8) 
p-value: .000 
Conclusion: Since a = .05 exceeds the observed significance level, p = .000, 
the data provide strong evidence that at least one of the model coefficients 
is nonzero. The overall model appears to be statistically useful for predicting 
auction prices. 
:p 
Can we be sure that the best prediction model has been found if the global F- 
test indicates that a model is useful? Unfortunately, we cannot. The addition of 
other independent variables may improve the usefulness of the model. (See the 
box, p. 583-584.) 
To summarize the discussion in this section, both R~ and Ri are indicators 
of how well the prediction equation fits the data. Intuitive evaluations of the con- 
tribution of the model based on R2 must be examined with care. Unlike R:, the 
value of R2 increases as more and more variables are added to the model. Conse- 
quently, you could force R2 to take a value very close to 1 even though the model 
contributes no information for the prediction of y. In fact, R2 equals 1 when the 
number of terms in the model (including Po) equals the number of data points. 
Therefore, you should not rely solely on the value of R2 (or even R;) to tell you 
whether the model is useful for predicting y. Use the F-test for testing the global 
utility of the model. 
After we have determined that the overall model is useful for predicting y 
using the F-test, we may elect to conduct one or more t-tests on the individual p 
parameters (see Section 10.4). However, the test (or tests) to be conducted 
should be decided a priori, that is, prior to fitting the model. Also, we should 
limit the number of t-tests conducted to avoid the potential problem of making 
too many Type I errors. Generally, the regression analyst will conduct t-tests only 
on the "most important" P's. 
..' ** 
~ecomrnendation for Checking the Utility of a Multiple 
Regression Model 
1. First, conduct a test of overall model adequacy using the F-test, that is, test 
If the model is de 
eject H,), then proceed 
and fit another model. 
The new model may include more independent variables or higher- 
order terms. 
2. Conduct t-tests on those 
parameters in which you are particularly 
interested (that is, the "most important" P's). These usually involve only 
the 0's associated with higher-order terms (x,, x,x2, etc.). However, it is 
a safe practice to limit the number of 6's that are tested. Conducting a 
series of t-tests leads to a high overall Type I error rate 

586 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
Learning the Mechanics 
10.16 Suppose you fit the first-order model 
to n = 30 data points and obtain 
SSE = .33 R2 = .92 
a. Do the values of SSE and R2 suggest that the model 
provides a good fit to the data? Explain. 
b. Is the model of any use in predicting y? Test the null 
hypothesis H,,: P1 = P2 = P3 = P4 = P5 = 0 against 
the alternative hypothesis Ha: At least one of the 
parameters PI, P2, . . ., Ps is nonzero. Use (Y = .05. 
10.17 The first-order model y = Po + Plxl + P2x2 + E was 
fit to n = 19 data points with the results shown in the 
SAS printout provided below. 
a. Find R2 and interpret its value. 
b. Find Ri and interpret its value. 
c. Test the null hypothesis that P, = P2 = 0 against 
the alternative hypotheyis that at least one of P, and 
p2 is nonzero. Calculate the test statistic using the 
two formulas given in this section, and compare 
your results to each other and to that given on the 
printout. Use a = .05 and interpret the result of 
your test. 
d. Find the observed significance level for this test on 
the printout and interpret it. 
10.18 If the analysis of variance F-test leads to the conclu- 
sion that at least one of the model parameters is 
nonzero, can you conclude that the model is the best 
predictor for the dependent variable y? Can you con- 
SAS Output for Exercise 10.1 7 
clude that all of the terms in the model are important 
for predicting y? What is the appropriate conclusion? 
10.19 Suppose you fit the first-order model 
to n = 20 data points and obtain 
a. Construct an analysis of variance table for this re- 
gression analysis, using the same format as the 
printout in Exercise 10.17. Be sure to include the 
sources of variability, the degrees of freedom. the 
sums of squares, the mean squares, and the F statis- 
tic. Calculate R2 and Rt for the regression analysis. 
b. Test the null hypothesis that P, = P2 = 0 against the 
alternative hypothesis that at least one of the param- 
eters differs from 0. Calculate the test statistic in two 
different ways and compare the results. Use 0 = .05 
to reach a conclusion about whether the model con- 
tributes information for the prediction of y. 
Applying the Concepts 
10.20 Refer to the World Development (Feb. 1998) study of 
street vendors in the city of Puebla, Mexico, 
Exercise 10.7 (p. 573). Recall that the vendors' mean 
annual earnings E b )  was modeled as a first-order func- 
tion of age x, and hours worked x2. Refer to the STA- 
TISTIX printout on p. 573 and answer the following: 
a. Interpret the value of R2. 
b. Interpret the value of R:. Explain the relationship 
between R2 and R:. 
- 
Dep Variable: Y 
Analysis of Variance 
Source 
DF 
Model 
2 
Error 
16 
C Total 
18 
Root MSE 
Dep Mean 
C.V. 
Sum of 
Mean 
Squares 
Square 
0.43008 
R-Square 
3.56053 
Adj R-Sq 
12.07921 
F Value 
Prob>F 
65.478 
0.0001 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
Variable 
DF 
Estimate 
Error 
Parameter=O 
prob > ITI 
INTERCEP 
1 
0.734606 
0.29313351 
2 .  506 
0.0234 
X1 
1 
0.765179 
0.08754136 
8.741 
0.0001 
X2 
1 
-0.030810 
0.00452890 
-6.803 
0.0001 
lnde 
. . . . . . .
Con,
CH/ 
SIZl
COP 
RISl 
IND
BIG 
NAS 
So~tr
No. 3.

SECTION 10.5 
C h e c k i n g  t h e  O v e r a l l  U t i l i t y  o f  a M o d e l  
587 
c. Conduct a test of the global utility of the model at 
LY = .01. Interpret the result. 
10.21 Refer to the Chief Executive (Sept. 1999) study of CEOs, 
Exercise 10.8 (p. 574). Recall that a CEO's pay y was 
modeled as a function of company performance x, and 
company sales x2 using a first-order model. Refer to the 
EXCEL printout on p. 575 and answer the following: 
a. Find and interpret the value of the multiple coeffi- 
cient of determination. 
b. Give the null and alternative hypotheses for testing 
whether the overall model is statistically useful for 
predicting a CEO's pay. 
c. Give the value of the test statistic and correspond- 
ingp-value for the test of part h. 
d. Conduct the test of part b using a = .05. What is 
your conclusion? 
10.22 The Journal of Quantitative Criminology (Vol. 8,1992) 
published a paper on the determinants of area prop- 
erty crime levels in the United Kingdom. Several mul- 
tiple regression models for property crime prevalence, 
y, measured as the percentage of residents in a geo- 
graphical area who were victims of at least one prop- 
erty crime, were examined. The results for one of the 
models, based on a sample of n = 313 responses col- 
lected for the British Crime Survey, are shown in the 
table below. [Note: All variables except Density are 
expressed as a percentage of the base area.] 
a. Test the hypothesis that the density ( x , )  of a region 
is positively linearly related to crime prevalence (y), 
holding the other independent variables constant. 
b. Do you advise conducting t-tests on each of the 18 
independent variables in the model to determine 
Results for Exercise 10.22 
Variable 
fi 
t 
pvalue 
x, = Dens~ty (population per hectare) 
.331 
3.88 
p < .O1 
xz = Unemployed male population 
-.I21 
-1.17 
p > .I0 
x3 = Profess~onal population 
-.I87 
- 1.90 
.01 < p < .10 
x4 = Populat~on aged less than 5 
-.I51 
-1.51 
p > .10 
x, = Population aged between 5 and 15 
,353 
3.42 
p < .01 
x6 = Female populat~on 
.095 
1.31 
p > .lo 
x7 = 10-year changc. In population 
,130 
1.40 
p > .10 
x8 = M~nor~ty 
population 
-.I22 
-1.51 
p > .10 
x, = Young adult popula:ion 
.I63 
5.62 
p < .01 
xlo = 1 ~f North region, 0 if not 
,369 
1.72 
.01 < p < .10 
xll = 1 ~f Yorkshire reglon, 0 ~f not 
- ,210 
-1.39 
p > .10 
x12 = 1 ~f East M~dlands reglon, 0 if not 
- .I92 
-0.78 
p > .lo 
x13 = 1 ~f East Anglia reglon, 0 ~f not 
- .548 
-2.22 
.Ol < p < .10 
x14 = 1 ~f South East region, 0 ~f not 
.I52 
1.37 
p > .lo 
x15 = 1 ~f South West region, 0 ~f not 
-.I51 
-0.88 
p > .10 
X16 = 1 I•’ West Midlands region, 0 if not 
- .308 
-1.93 
.0l < p < .lo 
x,, = 1 ~f North West reglon, 0 if not 
.311 
2.13 
.O1 < p < .lo 
x18 = 1 ~t Wales region, 0 ~f not 
-.019 
-0.08 
p > .10 
Source Osborn, D R ,Tickett, A , and Elder, R "Area characteristics and reg~onal variates as determinants of area property cnme." Journal of 
Quantrtatwe Cnmmology, Vol 8, No 3,1992, Plenum Publ~sh~ng 
Corp. 
Results for Exercise 10.23 
......................................... 
... ......... ............................................................................................................................... 
' ............................................................. . 
Independent Variable 
Expected Sign of fi 
p Estimate 
t Value 
Level of Significance (p-Value) 
Constant 
CHANGE 
SIZE 
COMPLEX 
RISK 
INDUSTRY 
BIG8 
NAS 
.001 (two-tailed) 
.961 (one-tailed) 
.000(one-tailed) 
.000(one-tailed) 
.079(one-tailed) 
.000(one-tailed) 
.030(one-tailed) 
.OOO(two-tailed) 
R' = ,712 
F = 111.1 
Source Butterworth, S., and Houghton, K. A. "Audltor switching: The pricing of audit services." Journal of Busmess Fmunce and Account~ng,Vol. 22, 
No 3,Aprd 1995, p. 334 (Table 4). 

588 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
which variables are important predictors of crime 
prevalence? Explain. 
c. The model yielded R2 = .411. Use this information 
to conduct a test of the global utility of the model. 
Use a = .05 
10.23 External auditors are hired to review and analyze the 
financial and other records of an organization and to 
attest to the integrity of the organization's financial 
statements. In recent years, the fees charged by audi- 
tors have come under increasing scrutiny. S. 
Butterworth and K. A. Houghton, two University of 
Melbourne (Australia) researchers, investigated the 
effects of several variables on the fee charged by audi- 
tors. The variables are listed at the bottom of the page. 
The multiple regression model E(y) = P,, + P,x, + 
P2x2 + P3x3 + 
+ P7x7 was fit to data collected for 
n = 268 companies. The results are summarized in the 
table on page 587. 
a. Write the least squares prediction equation. 
b. Assess the overall fit of the model. 
c. Interpret the cstirnate of P,. 
d. The researchers hypothesized the direction of the 
effect of each independent variable on audit fees. 
These hypotheses are given in the "Expccted Sign 
\ \  
of p" column in the table on p. 587. (For example, if 
the expected sign is negative, the alternative hy- 
pothesis is Ha: P, < 0.) Interpret the results of the 
hypothesis test for P4. Use a = .05. 
e. The main objective of the analysis was to determine 
whether new auditors charge less than incumbent au- 
ditors in a given year. If this hypothesis is true, then 
the true value of p, is negative. Is there evidence to 
support this hypothesis? Explain. 
10.24 An important goal in occupational safety is "active 
caring." Employees demonstrate active caring (AC) 
about the safety of their co-workers when they identify 
environmental hazards and unsafe work practices and 
then implement appropriate corrective actions for these 
unsafe conditions or behaviors. Three factors hypothe- 
sized to increase thc propensity for an employee to 
actively care for safety are (1) high self-esteem. (2) opti- 
mism, and (3) group cohesiveness. Applied & Preventlw 
Psychology (Winter 1995) attempted to establish 
empirical support for the AC hypothesis by fitting the 
model E(y) = Po + Plxl + P2x2 + P3x1, where 
y = AC score (measuring active caring on a 15-poinl 
scale) 
x, = Self-esteem score 
x2 = Optimism score 
x3 = Group cohesion score 
The regression analysis, based on data collected for 
n = 31 hourly workers at a large fiber-manufacturing 
plant, yielded a multiple coefficient of determination 
ot R' = .362. 
a. Interpret the value of R2. 
b. Use the R2 value to test the global utility of the 
modcl. Use a = .05 
10.25 Refer to the Interfaces (Mar.-Apr. 1990) study of La 
Quinta Motor Inns, Exercise 10.13 (p. 578).The 
researchers used state population per inn (x,), inn 
room ratc (x,), median income of the area (x?), and 
college enrollment ( r4) to build a first-order model for 
operating margin (y) of a La Quinta Inn. Based on a 
sample of n = 57 inns, the model yielded R2 = .51. 
a. Glve a descriptive measure of model adequacy. 
b. Make an inference about model adequacy by con- 
ducting the appropriate test. Use a = .05. 
10.26 Regression analysis was employed to investigate the 
determinants of survival size of nonprofit hospitals 
(Applied Economics,Vol. 18,1986). For a given sample 
of hospitals, survival size, y, is defined as the largest 
size hospital (in terms of number of beds) exhibiting 
growth in market share over a specific time interval. 
Suppose 10 states are randomly sclccted and the sur- 
vival size for all nonprofit hospitals in each state is 
determined for two time periods five years apart, 
yielding two observations per state. The 20 survival 
sizes are listed in the table on page 589, along with the 
y = Logarithm of audit fee charged to auditee (FEE) 
1 if auditee changed auditors after one year (CHANGE) 
Xl = { 0 if not 
x2 = Logarithm of auditee's total assets (SIZE) 
x3 = Number of subsidiaries of auditee (COMPLEX) 
1 if auditee receives an audit qualification (RISK) 
x.4 = { 0 if not 
1 if auditee in mining industry (INDUSTRY) 
0 if not 
1 if auditee is a member of a "Big 8" firm (BIG8) 
0 if not 
x7 = Logarithm of dollar-value of non-audit services provided by auditor (NAS) 

SECTION 10.5 
C h e c k i n g  t h e  O v e r a l l  U t i l i t y  o f  a M o d e l  
589 
State 
Time period 
Survival size, y 
XI 
Xz 
x3 
q 
. . . . . . . . . . . . 
1 
1 
370 
.13 
.09 
5,800 
89 
1 
2 
390 
.15 
.09 
5,955 
87 
2 
1 
455 
.08 
.ll 
17,648 
87 
2 
2 
450 
.I 0 
.16 
17,895 
85 
3 
1 
500 
.03 
.04 
7,332 
79 
3 
2 
480 
.07 
.05 
7,610 
78 
4 
1 
550 
-06 
,005 
11,731 
80 
4 
2 
600 
.10 
.005 
11,790 
81 
5 
1 
205 
.30 
.12 
2,932 
44 
5 
2 
230 
.25 
.13 
3,100 
45 
6 
1 
425 
.04 
.01 
4,148 
36 
6 
2 
445 
.07 
.02 
4,205 
38 
7 
1 
245 
.20 
.01 
1,574 
25 
7 
2 
200 
.30 
.01 
1,560 
28 
8 
1 
250 
.07 
.08 
2,471 
38 
8 
2 
275 
.08 
.lo 
2,51 1 
38 
9 
1 
300 
.09 
.12 
4,060 
52 
9 
2 
290 
.12 
.20 
4,175 
54 
10 
1 
280 
.10 
.02 
2,902 
37 
10 
2 
270 
.ll 
.05 
2,925 
38 
Source Adapted from Bays, C. W. "The determinants of hospital size A survlvor analys~s." Applled Economics, 1986,Vol. 18, pp 359-377. 
following data for each state, for the second year in 
each time interval: 
xl = Percentage of beds that are for-profit hospitals 
x2 = Ratio of the number of persons enrolled in health 
maintenance organizations (HMOs) to the num- 
ber of persons covered by hospital insurance 
x3 = State population (in thousands) 
I I 
x4 = Percent of state that is urban 
SAS Output for Exercise 10.26 
The article hypothesized that the following model 
characterizes the relationship between survival size 
and the four variables just listed: 
a. The model was fit to the data in the table using SAS, 
with the results given in the printout below. Report 
the least squares prediction equation. 
b. Find the regression standard deviation s and inter- 
pret its value in the context of the problem. 
Dep Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
Model 
4 246537.05939 
61634.26485 
Error 
15 32807.94061 
2187.19604 
C Total 
19 279345.00000 
RootMSE 
46.76747 
R-Square 
Dep Mean 
360.50000 
Adj R-Sq 
C.V. 
12.97295 
Parameter Estimates 
Parameter 
Standard 
Variable 
DF 
Estimate 
Error 
INTERCEP 
1 
295.327091 
40.17888737 
X1 
1 
-480.837576 
150.39050364 
X2 
1 
-829.464955 
196.47303539 
X3 
1 
0.007934 
0.00355335 
X4 
1 
2.360769 
0.76150774 
F Value 
Prob>F 
28.180 
0.0001 
T for HO: 
Parameter=O Prob z IT1 
7.350 
0.0001 
-3.197 
0.0060 
-4.222 
0.0007 
2.233 
0.0412 
3.100 
0.0073 

590 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
c. Use an F-test to investigate the usefulness of the hy- 
pothesized model. Report the observed significance 
level, and use a = .025 to reach your conclusion. 
d. Prior to collccting the data it was hypothesized that 
increases in the number of for-profit hospital beds 
would decrease the survival size of nonprofit hospi- 
tals. Do the data support this hypothesis? Test using 
a = .05. 
10.27 Because the coefficient of determination R2 always 
increases when a new independent variable is addcd to 
the model, it is tempting to include many variables in a 
model to force R2 to be near 1. However, doing so 
reduces the degrees of freedom available for estimat- 
ing u 2 ,  which adversely affects our ability to makc reli- 
able inferences. Suppose you want to use 18 economic 
indicators to predict next year's Gross Domestic 
Product (GDP). You fit the model 
Y = PO + P l x l  + P 2 ~ 2  
+ ' ' ' + P 1 7 ~ 1 7  + P 1 8 ~ 1 8  + 
where y = GDP and xl, x2, . . ., X18 are the economic 
indicators. Only 20 years of data (n = 20) are used to 
fit the model, and you obtain R2 = .95. Test to see 
whether this impressive-looking R2 is large enough for 
you to infer that the model is useful, that is, that at 
least one term in the model is important for predicting 
- 
\ 
GDF! Use a = .05. 
10.28 Much research-and 
much litigation-has 
been con- 
ducted on the disparity between the salary levels of 
men and women. Research reported in Work and 
Occupations (Nov. 1992) analyzes the salaries for a 
sample of 191 Illinois managers using a regression 
analysis with the following independent variables: 
1 if white 
xz = Race of manager = 0 
if not 
x3 = Education level (in years) 
x4 = Tenure with firm (in years) 
x5 = Number of hours worked per week 
The regression results are shown in the table below as 
they were reported in the article. 
Variable 
3 
p-Value 
X I  
12.774 
< .05 
X2 
.713 
> .lo 
x 3  
1.519 
< .05 
X4 
.320 
< .05 
X s  
.205 
< .05 
Constant 
15.491 
- 
a. Write the hypothesized model that was used, and in- 
terpret each of the p parameters in the model. 
b. Write the least squares equation that estimates the 
model in part a, and interpret each of the j3 estimates 
c. Interpret the value of R 2 .  Test to determine whether 
the model is useful for predicting annual salary.Test 
using a = .05. 
d. Test to determine whether the gender variable indi- 
cates that male managers are paid more than female 
managers, even after adjusting for and holding constant 
the other four factors in the model.Test using a = .05. 
[Note: The p-values given in the table are two-tailed.] 
e. Why would one want to adjust for these other factors 
before conducting a test for salary discrimination? 
The regression equation is 
wtchnge = 12.2 - 0.0265 digest - 0.458 acid 
Predictor 
Coef 
StDev 
T 
P 
Constant 
12.180 
4.402 
2.77 
0.009 
digest 
-0.02654 
0.05349 
-0.50 
0.623 
acid 
-0.4578 
0.1283 
-3.57 
0.001 
Analysis of Variance 
Source 
DF 
SS 
MS 
F 
P 
 egression 
2 
542.03 
271.02 
21.88 
0.000 
Error 
3 9 
483.08 
12.39 
Total 
4 1 
1025.12 

SECTION 10.5 
C h e c k i n g  t h e  O v e r a l l  U t i l i t y  o f  a M o d e l  
591 
10.29 Refer to the Journal of Applied Ecology study of the 
feeding habits of baby snow geese, Exercise 10.11 
(p. 577).The MINITAB printout for the model relating 
weight change (y) to digestion efficiency (x,) and acid- 
detergent fiber (x2) is reproduced on page 590. 
a. Locate R2 and Rz on the MINITAB printout. Inter- 
pret these values. Which statistic is the preferred 
measure of model fit? Explain. 
b. Locate the global F value for testing the overall 
model on the MINITAB printout. Use the statistic 
to test the null hypothesis H,,: P, = P, = 0. 
10.30 Multiple regression is used by accountants in cost 
analysis to shed light on the factors that cause costs 
to be incurred and the magnitudes of their effects. 
The independent variables of such a regression 
model are the factors believed to be related to cost, 
the dependent variable. In some instances, however, 
it is desirable to use physical units instead of cost as 
the dependent variable in a cost analysis. This 
would be the case if most of the cost associated with 
the activity of interest is a function of some physical 
unit, such as hours of labor. The advantage of this 
approach is that the regression model will provide 
estimates of the number of labor hours required 
under different circumstances and these hours can 
then be costed at the current labor rate (Horngren, 
Foster. and Datar, 1994). The sample data shown in 
the table below have been collected from a firm's 
accounting and production records to provide cost 
information about the firm's shipping department. 
The EXCEL computer printout for fitting the 
model y = P, + Plx1 + P2x2 + P3x3 + E is provided 
on page 592. 
a. Find the least squares prediction equation. 
b. Use an F-test to investigate the usefulness of the 
model specified in part a. Use a = .01, and state 
your conclusion in the context of the problem. 
c. Tcst H,,: /3, = 0 versus Ha: p2 + 0 using a = .05. 
What do the results of your test suggest about the 
magnitude of the effects of x2 on labor costs? 
d. Find R2, and interpret its value in the context of the 
problem. 
e. If shipping department employees are paid $7.50 
per hour, how much less, on average, will it cost the 
company per week if the average number of pounds 
per shipmcnt increases from a level of 20 to 21 7 As- 
sume that x, and x2 remain unchanged. Your an- 
swer is an estimate of what is known in economics 
as the expected marginal cost associated with a one- 
pound increase in x,. 
f. With what approximate precision can this model be 
used to predict the hours of labor'? [Note: The pre- 
cision of multiple regression predictions is discussed 
in Section 10.6.1 
g. Can regression analysis alone indicate what factors 
cause costs to increase? Explain. 
Percentage of Units 
Labor, 
Pounds Shipped, 
Shipped by Truck, 
Average Shipment Weight, 
Week 
Y (hrs.1 
xl (1,000s) 
x2 
x, (Ibs.) 

EXCEL Output for Exercise 10.30 
Intercept 
Ship (xl) 
Truck (x2 
) 
Weight (x3) 
Coefficients 
131.9242521 
2.72608977 
0.047218412 
-2.587443905 
Standard Error 
25.69321439 
2.275004884 
0.093348559 
0.642818185 
t Stat 
5.134595076 
1.198278645 
0.505829045 
-4.025156669 
P-value 
9.985973-05 
0.24825743 
0.6198742 
0.000978875 
Lower 95% 
77.45708304 
-2.096704051 
-0.150671647 
-3.950157275 
Upper 95% 
186.3914211 
7.548883591 
0.245108472 
-1.224730536 

SECTION 
10.6 
Using t h e  Model f o r  E s t i m a t i o n  a n d  P r e d i c t i o n  
593 
USING THE MODEL FOR ESTIMATION AND 
PREDICTION 
In Section 9.8 we discussed the use of the least squares line for estimating the 
mean value of y, E(y), for some particular value of x, say x = x,. We also showed 
how to use the same fitted model to predict, when x = x,, some new value of y to 
be observed in the future. Recall that the least squares line yielded the same 
value for both the estimate of E(y) and the prediction of some future value of y. 
That is, both are the result of substituting x, into the prediction equation 
= p,, + pIx and calculating yp. There the equivalence ends. The confidence in- 
terval for the mean E(y) is narrower than the prediction interval for y because of 
the additional uncertainty attributable to the random error E when predicting 
some future value of y. 
These same concepts carry over to the multiple regression model. Consider, 
again, the first-order model relating sale price of a residential property to land 
value (x,), 
improvements (x,), and home size (x?). Suppose we want to estimate the 
mean sale price for a given property with x1 = $15,000, x, = $50,000, and x3 = 
1,800 square feet. Assuming that the first-order model represents the true relation- 
ship between sale price and the three independent variables, we want to estimate 
Substituting into the least squares prediction equation, we find the estimate of 
E(y) to be 
To form a confidence interval for the mean, we need to know the standard 
deviation of the sampling distribution for the estimator 7. 
For multiple regression 
models, the form of this standard deviation is rather complex. However, the re- 
gression routines of statistical computer software packages allow us to obtain the 
confidence intervals for mean values of y for any given combination of values of 
the independent variables. A portion of the SAS output for the sale price example 
is shown in Figure 10.9a. 
Obs 
X1 
x2 
X3 
Y 
Predlct 
Lower95% 
Upper95% 
Value 
Residual 
Mean 
Mean 
FIGURE 10.9a 
SAS printout for estimated mean sale price value and corresponding confidence interval 
The estimated mean value and corresponding 95% confidence interval for the 
selected x values are shown in the columns labeled Predict Value, Lower9S0/~ Mean, 
and Upper95% Mean, respectively. We observe that y^ = 79,061.4, which agrees 
with our calculation.The corresponding 95% confidence interval for the true mean 
of y, highlighted on the printout, is (73,380.7,84,742.1).Thus, with 95% confidence, 
we conclude that the mean sale price for all properties with xl = $15,000, x, = 
$50,000, and x, = 1,800 square feet will fall between $73,380.70 and $84,742.10. 

10 I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
If we were interested in predicting the sale price for a particular (single) 
property with xl = $15,000, x2 = $50,000, and x3 = 1,800 square feet, we would 
use y^ = $79,061.41 as the predicted value. However, the prediction interval for a 
new value of y is wider than the confidence interval for the mean value. This is re- 
flected by the SAS printout shown in Figure 10.9b, which gives the predicted 
value of y and corresponding 95% prediction interval under the columns Predict 
Value, Lower9S0/0 Predict, and Upper9S0/0 Predict, respectively. Note that the 
prediction interval is (61,337.9, 96,785). Thus, with 95% confidence, we conclude 
that the sale price for an individual property with the characteristics x, = $15,000, 
x2 = $50,000, and x, = 1,800 square feet will fall between $61,337.90 and $96,785. 
Obs 
X1 
X2 
X3 
Y 
Predict 
Lower958 
Upper95% 
Value 
Residual 
Predict 
Predict 
21 
15000 
50000 
1800 
. 
79061.4 
61337.9 
96785 
FIGURE 10.9b 
SAS printout for predicted sale price value and corresponding prediction interval 
Applying the Concepts 
10.31 Refer to the World Development (Feb. 1998) study of 
street vendors' earnings, y, Exercises 10.7 and 10.20 
(pp. 573,586).The STATISTIX printout below shows 
both a 95% prediction interval for y (left side) and a 
95% confidence interval for E(y) (right side) for a 
45-year-old vendor who works 10 hours a day (i.e., 
for x, = 45 and x, = 10). 
a. Interpret the 95% prediction interval for y in the 
words of the problem. 
b. Interpret the 95% confidence interval for E(y) in 
the words of the problem. 
c. Note that the interval of part a is wider than the 
interval of part b. Will this always be true? Ex- 
plain. 
10.32 Refer to the Journal of Applied Ecology study of the 
feeding habits of baby snow geese, Exercises 10.11 and 
10.29 (pages 577,59l).The MINITAB printout for the 
first-order model relating gosling weight change y to 
digestion efficiency x, and acid-detergent fiber x, ic 
STATlSTlX Output for Exercise 10.31 
PREDICTED/FITTED VALUES OF EARNINGS 
LOWER PREDICTED BOUND 
1 7 5 9 . 7  
LOWERFITTEDBOUND 
2620.3 
PRZDICTED VALUE 
3 0 1 7 . 6  
FITTED VALUE 
3017.6 
UPPER PREDICTED BOUND 
4 2 7 5 . 4  
UPPER FITTED BOUND 
3414.9 
SE (PREDICTED VALUE) 
5 7 7 . 2 9  
SE (FITTED VALUE) 
1 8 2 . 3 5  
UNUSUALNESS (LEVERAGE) 
0 . 1 1 0 8  
PERCENT COVERAGE 
9 5 . 0  
CORRESPONDING T 
2 . 1 8  
PREDICTOR VALUES: AGE = 4 5 . 0 0 0 ,  HOURS = 1 0 . 0 0 0  

SECTION 10.6 
U s i n g  t h e  M o d e l  f o r  E s t i m a t i o n  a n d  P r e d i c t i o n  
595 
The regression equation is 
wtchnge = 12.2 - 0.0265 digest - 0.458 acid 
Predictor 
Coef 
St Dev 
T 
P 
Constant 
12.180 
4.402 
2.77 
0.009 
digest 
-0.02654 
0.05349 
-0.50 
0.623 
acid 
-0.4578 
0.1283 
-3.57 
0.001 
s = 3.519 
R-Sq = 52.9% 
R-Sq(adj) = 50.5% 
Analysis of Variance 
Source 
DF 
SS 
MS 
F 
P 
Regression 
2 
542.03 
271.02 
21.88 
0 . 0 0 0  
Error 
3 9 
483.08 
12.39 
Total 
4 1 
1025.12 
Fit StDev Fit 
95.0% CI 
95.0% PI 
-1.687 
0.866 
( 
-3.440, 
0.065) ( 
-9.020, 
5.646) 
reproduced above. Both a confidence interval for E(y) 
logical station (station #9). 
x, = 30% are shown at the bottom of the printout. 
a. Interpret the confidence interval for E(y). 
b. Interpret the prediction interval for y. 
and a prediction interval for y when x, = 5% and 
10.35 In a production facility, an accurate estimate of man- 
hours needed to complete a task is crucial to manage- 
ment in making such decisions as the proper number 
10.33 Refer to Exercise 10.14 (p. 578). The researchers con- 
cluded that "in order to break a water-oil mixture with 
' 
the lowest possible voltage, the volume fraction of the 
disperse phase x, should be high, while the sahnity x2 
and the amount of surfactant x, should be low." Use 
this information and the first order model of 
Exerc~se 10.14 to find a 95% prediction interval for 
this "low" voltage y. Interpret the interval. 
10.34 An article published in Geography (July 1980) used mul- 
tiple regression to predict annual rainfall levels in 
California. Data on the average annual precipitation (y), 
altitude (x,), latitude (x,), and distance from the Pacific 
coast (x,) for 30 meteorological stations scattered 
throughout California are listed in the table on page 597. 
Initially, the first-order model y = Po + Plxl + 
P,x2 t P3x3 + E was fit to the data.The SAS printout of 
the analysis is provided on page 596. 
a. Is there evidence that the first-order model is useful 
for predicting annual precipitation y? Test using 
a = .05. 
b. Ninety-five percent prediction intervals for y are 
shown at the bottom of the printout. Locate and in- 
terpret the interval for the Giant Forest meteoro- 
of workers to hire, an accurate deadline to quote a 
client, or cost-analysis decisions regarding budgets. A 
manufacturer of boiler drums wants to use regression 
to predict the number of man-hours needed to erect 
the drums in future projects. To accomplish this, data 
for 35 boilers were collected. In addition to man-hours 
(y), the variables measured were boiler capacity 
(x, = Iblhr), boiler design pressure (x2 = pounds per 
square inch or psi), boiler type (x, = 1 if industry field 
erected, 0 if utility field erected), and drum type 
(x, = 1 if steam, 0 if mud). The data are provided in 
the table on page 598. A MINITAB printout for the 
model E(y) = P O  + PIXI + P 2 ~ 2  + P3x3 + P 4 ~ 4  is 
shown on page 597. 
a. Conduct a test for the global utility of the model. 
Use a = .01. 
b. Both a 95% confidence interval for E(y) and a 95% 
prediction interval for y when xl = 150,000, 
x2 = 500, x3 = 1 and x, = 0 are shown at the bot- 
tom of the MINITAB printout. Interpret both of 
these intervals. 

596 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
SAS Output for Exercise 10.34 
Model: MODEL1 
Dependent Variable: PRECIP 
Source 
Model 
Error 
C Total 
Root MSE 
Dep Mean 
Variable DF 
INTERCEP 
1 
ALTITUDE 
1 
LONGTUDE 
1 
COAST 
1 
Obs 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
2 0 
2 1 
2 2 
2 3 
2 4 
2 5 
2 6 
2 7 
2 8 
2 9 
3 0 
STATION 
Eureka 
RedBluf f 
Thermal 
FortBrag 
SodaSpri 
SanFranc 
Sacramen 
SanJose 
GiantFor 
Salinas 
Fresno 
PtPiedra 
PasaRobl 
Bakersf i 
Bishop 
Mineral 
Sant aBar 
Susanvil 
TuleLake 
Needles 
Burbank 
LosAngel 
LongBeac 
LosBanos 
Blythe 
SanDiego 
Dagget t 
DeathVal 
Crescent 
Colusa 
Analysis of Variance 
Sum of 
Mean 
DF 
Squares 
Square 
F Value 
Prob>F 
11.09799 
R-square 
0.6003 
19.80733 
Adj R-sq 
0.5542 
56.02968 
Parameter Estimates 
Parameter - 
Standard 
T for HO: 
Estimate 
Error 
Parameter=O 
Prob > ITI 
Dep Var 
PRECIP 
39.5700 
23.2700 
18.2000 
37.4800 
49.2600 
21.8200 
18.0700 
14.1700 
42.6300 
13.8500 
9.4400 
19.3300 
15.6700 
6.0000 
5.7300 
47.8200 
17.9500 
18.2000 
lO.O3OO 
4.6300 
14.7400 
15.0200 
12.3600 
8.2600 
4.0500 
9.9400 
4.2500 
1.6600 
74.8700 
15.9500 
Predict 
Value 
38.4797 
23.9136 
21.2729 
33.7750 
39.4605 
27.5918 
19.1828 
23.1015 
29 .2534 
22.8856 
9.3654 
20.9364 
19.4445 
11.0967 
14.8859 
36.6194 
16.7077 
25.4191 
38.7521 
-5.9539 
11.8145 
14.3149 
12.7793 
18.0332 
-7.4478 
9.8563 
11.7920 
-4.8355 
41.5529 
20.1703 
Std Err 
Predict 
4.568 
3.795 
5.132 
3.815 
5.799 
3.144 
2.988 
2.647 
5.596 
2.842 
3.029 
3.147 
2.629 
2.512 
4.193 
4.392 
3.526 
4.571 
4.646 
5.224 
3.046 
3.416 
3.595 
2.621 
4.950 
4.275 
3.298 
5.843 
5.121 
3.399 
Lower 9 5 
% 
Predict 
13.8110 
-0.1953 
-3.8600 
9.652 6 
13.7221 
3.8818 
-4.4416 
-0.3504 
3.7056 
-0.6628 
-14.2809 
-2.7752 
-3.99 87 
-12.2922 
-9.5000 
12.0861 
-7.2277 
0.7482 
14.0218 
-31.1665 
-11.8412 
-9.5536 
-11.1997 
-5.4064 
-32.4260 
-14.5899 
-12.0062 
-30.6159 
16.4295 
-3.6875 
Upper95% 
Predict 
63 .I483 
48.0226 
46.4057 
57.8973 
65.1990 
51.3018 
42.8072 
46.5535 
54.8012 
46.4340 
33.0116 
44.6480 
42.8877 
34.4857 
39.2717 
61.1527 
40.6432 
50.0899 
63.4823 
19.2587 
35.4701 
38.1834 
36.7583 
41.4729 
17.5303 
34.3025 
35.5902 
20.9448 
66.6764 
44.0280 
Residual 
1.0903 
-0.6436 
-3.0729 
3.7050 
9.7995 
-5.7718 
-1.1128 
-8.9315 
13.3766 
-9.0356 
0.0746 
-1.6064 
-3.7745 
-5.0967 
-9.1559 
11.2006 
1.2423 
-7.2191 
-28.7221 
10.5839 
2.9255 
0.7051 
-0.4193 
-9.7732 
11.4978 
0.0837 
-7.5420 
6.4955 
33.3171 
-4.2203 

SECTION 10.6 
U s i n g  t h e  M o d e l  f o r  E s t i m a t i o n  a n d  P r e d i c t i o n  
597 
0 CALIRAIN.DAT (Data for Exercise lO.34) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . . 
Precipitation, 
Altitude, 
Latitude, 
Distance 
Station 
y (inches) 
x, (feet) 
x, (degrees) 
x, (miles) 
1. Eureka 
39.57 
43 
40.8 
1 
2. Red Bluff 
23.27 
341 
40.2 
97 
3. Thermal 
18.20 
4152 
33.8 
70 
4. Fort Bragg 
37.48 
74 
39.4 
1 
5. Soda Springs 
49.26 
6752 
39.3 
150 
6. San Francisco 
21.82 
52 
37.8 
5 
7. Sacramento 
18.07 
25 
38.5 
80 
8. San Jose 
14.17 
95 
37.4 
28 
9. G~ant Forest 
42.63 
6360 
36.6 
145 
10. Salmas 
13.85 
74 
36.7 
12 
11. Fresno 
9.44 
331 
36.7 
114 
12. Pt P~edras 
19.33 
57 
35.7 
1 
13. Pasa Robles 
15.67 
740 
35.7 
31 
14 Bakersfield 
6.00 
489 
35.4 
75 
15. Blshop 
5.73 
4108 
37.3 
198 
16. Mineral 
47.82 
4850 
40.4 
142 
17. Santa Barbara 
17.95 
120 
34.4 
1 
18 Susanv~lle 
18.20 
4152 
40.3 
198 
19. Tule Lake 
10.03 
4036 
41.9 
140 
20. Needles 
4.63 
913 
34.8 
192 
21 Burbank 
14.74 
699 
34.2 
47 
22. Los Angeles 
15.02 
312 
34.1 
16 
23. Long Beach 
12.36 
50 
33.8 
12 
24. Los Banos 
8.26 
125 
37.8 
74 
25 Blythe 
4.05 
268 
33.6 
155 
26. San Diego 
9.94 
19 
32.7 
5 
27 Daggett 
4.25 
21 05 
34.1 
85 
28. Death Valley 
1.66 
-178 
36.5 
194 
29. Crescent City 
74.87 
35 
41.7 
1 
30. Colusa 
15.95 
60 
39.2 
91 
Source Taylor, PJ. "A pedagogic application of multiple regression analys~s" Geography, July 1980,Vol 65, pp. 203-212. 
MINITAB Output for Exercise 10.35 
I 
The regression equation is 
Y = -3783 + 0.00875 X1 + 1.93 X2 + 3444 X3 + 2093 X4 
Predictor 
Coef 
StDev 
t-ratio 
P 
Constant 
-3783 
1205 
-3.14 
0.004 
X1 
0.0087490 
0.0009035 
9.68 
0.000 
X2 
1.9265 
0.6489 
2.97 
0.006 
X3 
3444.3 
911.7 
3.78 
0.001 
X4 
2093.4 
305.6 
6.85 
0.000 
I Analysis of Variance 
I 
SOURCE 
DF 
S S 
MS 
F 
P 
Regression 
4 
230854848 
57713712 
72.11 
0.000 
~rror 
31 
24809760 
800315 
Total 
35 
255664608 
I R denotes an obs. with a large st. resid. 
Fit StDev.Fit 
95% C.I. 
95% P.I. 
1 
1936 
239 
( 
1449, 
2424) ( 
47, 
3825) 

598 
CHAPTER 
10 
I n t r o d u c t i o n  t o  Multiple Regression 
BOILERS.DAT (Data for Exercise 10.35) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . , , , , 
Man-Hours, 
Boiler Capacity, 
Design Pressure, 
Boiler Type, 
Drum Type, 
Y 
XI 
xz 
x3 
x4 
Source: Dr. Kelly Uscategui, University of Connecticut 
- 
RESIDUAL ANALYSIS: CHECKING THE 
REGRESSION ASSUMPTIONS 
When we apply regression analysis to a set of data, we never know for certain 
whether the assumptions of Section 10.3 are satisfied. How far can we deviate 
from the assumptions and still expect regression analysis to yield results that will 
have the reliability stated in this chapter? How can we detect departures (if they 
exist) from the assumptions and what can we do about them? We provide some 
answers to these questions in this section. 
Recall from Section 10.3 that for any given set of values of x,, x,, . . ., xk we 
assume that the random error term E has a normal probability distribution with 
mean equal to 0 and variance equal to a'. Also, we assume that the random errors 
are probabilistically independent. It is unlikely that these assumptions are ever sat- 
FIG
Act 
reg 

SECTION 10.7 
Residual Analysis: C h e c k i n g  t h e  Regression A s s u m p t i o n s  
599 
isfied exactly in a practical application of regression analysis. Fortunately, experi- 
ence has shown that least squares regression analysis produces reliable statistical 
tests, confidence intervals, and prediction intervals as long as the departures from 
the assumptions are not too great. In this section we present some methods for de- 
termining whether the data indicate significant departures from the assumptions. 
Because the assumptions all concern the random error component, E ,  of the 
model, the first step is to estimate the random error. Since the actual random error 
associated with a particular value of y is the difference between the actual y value 
and its unknown mean, we estimate the error by the difference between the actu- 
al y value and the estimated mean. This estimated error is called the regression 
residual, or simply the residuul, and is denoted by 2. The actual error E and resid- 
ual 2 are shown in Figure 10.10. 
Actual random error E and 
regression residual E 
A regression residual, E, is defined as the difference between an observed y 
value and its corresponding predicted value: 
( P o  + 3 1 x 1  + 3 2 x 2  + ' ' ' + P k ~ k )  
Since the true mean of y (that is, the true regression model) is not known, 
the actual random error cannot be calculated. However, because the residual is 
based on the estimated mean (the least squares regression model), it can be cal- 
culated and used to estimate the random error and to check the regression as- 
sumptions. Such checks are generally referred to as residual analyses. Two useful 
~ 
properties of residuals are given in the next box. 
The following examples show how a graphical analysis of regression residu- 
als can be used to verify the assumptions associated with the model and to support 
improvements to the model when the assumptions do not appear to be satisfied. 
Although the residuals can be calculated and plotted by hand, we rely on the sta- 
tistical software for these tasks in the examples and exercises. 

10 I n t r o d u c t i o n  t o  Multiple Regression 
First, we demonstrate how a residual plot can detect a model in which the 
hypothesized relationship between E(y) and an independent variable x is mis- 
specified. The assumption of mean error of 0 is violated in these types of models.* 
1. The mean of the residuals is equal to 0. This property follows from the 
fact that the sum of the differences between the observed y values and 
their least squares predicted ^y values is equal to 0. 
2 (Residuals) = 2 (y - ji) = 0 
2. The standard deviation of the residuals is equal to the standard deviation 
of the fitted regression model, s.This property follows from the fact that 
the sum of the squared residuals is equal to SSE, which when divided by 
the error degrees of freedom is equal to the variance of the fitted regres- 
sion model, s'. The square root of the variance is both the standard devi- 
ation of the residuals and the standard deviation of the regression model. 
2   residual^)^ = 2 (y - y)' = SSE 
consumers, builders, and energy conservationists. Suppose we wish to investigate 
- - 
A * 
., 
the monthly electrical usage, y, in all-electric homes and its relationship to the size, 
x, of the home. Data were collected for n = 10 homes during a particular month 
l 
and are shown in Table 10.3. A SAS printout for a straight-line model, 
1 
E(y) = Po + P,x, fit to the data is shown in Figure 10.1 1. The residuals from this 
model is highlighted in the printout.The residuals are then plotted on the vertical 
axis against the variable x, size of home, on the horizontal axis in Figure 10.12. 
TABLE 
1 0.3 Home Size-Electrical Usage Data 
Home Size x, 
Monthly Usage y, 
Home Size x, 
Monthly Usage y, 
(sq. ft.) 
(kilowatt-hours) 
(sq. ft.) 
(kilowatt-hours) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . , . . . . . , . , . . , * 
a. Verify that each residual is equal to the difference between the observed y 
value and the estimated mean value, ji. 
b. Analyze the residual plot. 
t 
*For a mlsspecified model, the hypothesized mean of y, denoted by Eh(y), w~ll not equal the true 
mean of y, E(Y). Smce y = Eh(y) + E, then E = y - E,(y) and 
E(E) = E [ ~  
- E h ( ~ ) l  = E ( ~ )  
- E h ( ~ )  # 

SECTION 10.7 
Residual Analysis: C h e c k i n g  t h e  Regression A s s u m p t i o n s  
601 
F I G U R E  10.1 1 
SAS printout for electrical 
usage example: Straight-line 
model 
t 
" 6. 
t 
13 
i 
'I' 
S o l u t i o n  
Dep Variable: Y 
Analysls of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
1 703957.18342 
703957.18342 
39.536 
0.0002 
Error 
8 142444.91658 
17805.61457 
C Total 
9 846402.10000 
Variable 
INTERCEP 
X 
Root MSE 
133.43766 
R-Square 
Dep Mean 1594.70000 
A d j  R-Sq 
C. V. 
8.36757 
Parameter Estimates 
Parameter 
Standard 
DF 
Estimate 
Error 
1 
578.927752 
166.96805715 
1 
0.540304 
0.08592981 
Predict 
Obs 
Y 
Value 
1 
1182.0 
1275.9 
2 
1172.0 
1308.3 
3 
1264.0 
1373.2 
4 
1493.0 
1443.4 
5 
1571.0 
1502.8 
6 
1711.0 
1573.1 
7 
1804.0 
1648.7 
8 
1840.0 
1783.8 
9 
1956.0 
1875.7 
10 
1954.0 
2162.0 
T for HO: 
Parameter=O Prob > IT1 
Sum of Residuals 
0 
Sum of Squared Residuals 
142444.9166 
a. For the straight-line model the residual is calculated for the first y value as - 
follows: 
where F is the first number in the column labeled Predict Value on 
the SAS printout in Figure 10.11. Similarly, the residual for the second y 
value is 
Both residuals agree (after rounding) with the values given in the column la- 
beled Residual in Figure 10.1 1. Similar calculations produce the remaining 
residuals. 
b. The plot of the residuals for the straight-line model (Figure 10.12) reveals a 
nonrandom pattern. The residuals exhibit a curved shape, with the residuals 
for the small values of x below the horizontal 0 (mean of the residuals) line, 
the residuals corresponding to the middle values of x above the 0 line, and 
the residual for the largest value of x again below the 0 line. The indication is 

602 
CHAPTER 10 I n t r o d u c t i o n  t o  Multiple Regression 
FIGURE 10.12 
Residual plot for electrical 
usage example: Straight-line 
model 
Plot of RESIDUAL*X Legend: A = 1 obs, B = 2 obs, etc. 
RESIDUAL ! 
that the mean value of the random error E within each of these ranges of x 
(small, medium, large) may not be equal to 0. Such a pattern usually indi- 
cates that curvature needs to be added to the model. One way to accomplish 
this is by adding the term, p2x2, 
to the model. This term is called a second- 
order or quadratic term. 
When the second-order term is added to the model, the nonrandom 
pattern disappears. Figure 10.13 is a SAS printout for the quadratic 
model, E(y) = p, + p,x + &x2, with residuals highlighted. These residu- 
als are plotted in Figure 10.14. In Figure 10.14, the residuals appear to be 
randomly distributed around the 0 line, as expected. Note, too, that the 
f 
2s standard deviation lines are at about +95 on the quadratic residual 
plot, compared to (about) ~t27.5 on the straight-line plot and that the 
adjusted-R2 for the quadratic model (.9767) is considerably higher than 
the adjusted-R' for the straight-line model (.8107).The implication is that 
the quadratic model provides a considerably better model for predicting 
electrical usage. 
Residual analyses are also useful for detecting one or more observations 
that deviate significantly from the regression model. We expect approximately 
95% of the residuals to fall within 2 standard deviations of the 0 line, and all or 
almost all of them to lie within 3 standard deviations of their mean of 0. Resid- 
uals that are extremely far from the 0 line, and disconnected from the bulk of 
the other residuals, are called outliers, and should receive special attention from 
the regression analyst. 
FIC
SA! 
usa 
mo 

SECTION 10.7 
Residual Analysis: Checking t h e  Regression Assumptions 
603 
FIGURE 10.1 3 
SAS printout for electrical 
usage example: Quadratic 
model 
- 
Dep Variable: Y 
Analysis of Variance 
Sum of 
Mean 
Source 
DF 
Squares 
Square 
F Value 
Prob>F 
Model 
2 831069.54637 
415534.77319 
189.710 
0.0001 
Error 
7 15332.55363 
2190.36480 
C Total 
9 846402.10000 
Variable 
INTERCEP 
X 
XSQ 
Root MSE 
46.80133 
R-Square 
Dep Mean 1594.70000 
Ad] R-Sq 
C. V. 
2.93480 
Parameter Estimates 
Parameter 
Standard 
DF 
Estimate 
Error 
1 
-1216.143887 
242.80636850 
1 
2.398930 
0.24583560 
1 
-0.000450 
0.00005908 
Predict 
Obs 
Y 
Value 
1 
1182.0 
1129.6 
2 
1172.0 
1202.2 
3 
1264.0 
1337.8 
4 
1493.0 
1470.0 
5 
1571.0 
1570.1 
6 
1711.0 
1674.2 
7 
1804.0 
1769.4 
8 
1840.0 
1895.5 
9 
1956.0 
1949.1 
10 
1954.0 
1949.2 
Sum of Residuals 
-2.27374E-12 
Sum of Squared Residuals 
15332.5536 
T for HO: 
Parameter=O Prob > IT1 
-5.009 
0.0016 
9.758 
0.0001 
-7.618 
0.0001 
A residual that is larger than 3s (in absolute value) is considered to be an 
outlier. 
--,",-, 
,,~ 
,"$,"*L,sa 
hich we 
e y o f a  
clock as a function of age x, and number of bidders x,. The data for this example 
are repeated in Table 10.4, with one important difference: The auction price of the 
clock at the top of the second column has been changed from $2,131 to $1,131 
". - 
(highlighted in Table 10.4). The first-order model 
E(Y) = Po + Plxl + P2xz 
Y 
is again fit to these (modified) data, with the MTNITAB printout shown in 
Figure 10.15. The residuals are shown highlighted in the printout and then 
plotted against the number of bidders, x2, in Figure 10.16. Analyze the 
residual plot. 

604 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
FIGURE 10.14 
Residual plot for electrical 
usage example: Quadratic 
model 
Plot of RESIDUAL*X Legend: A = 1 obs, B = 2 obs, etc. 
F I 
MI 
RESIDUAL 
g rt 
I 
wi 
I 
100 
7 
I .............................................................. 
I 
I 
75 
? 
I 
I 
50 
7 
A 
I 
A 
A 
I 
25 : 
A 
I 
I 
A 
A 
+------------------A 
------------------------------------------ 
O 
I 
I 
I 
-25 
A 
I I 
I 
-50 : 
A 
I 
I 
-75 
+ 
A 
I 
-100 : 
I 
----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---- 
1200 1400 1600 1800 2000 2200 2400 2600 2800 3000 
X 
TABLE 
10.4 
Altered Auction Price Data 
Number of 
Auction 
Number of 
Auction 
Age, xl 
Bidders, x2 
Price, y 
Age, xl 
Bidders, x2 
Price, y 
. . . . . . . . . . . . . . . . . . . . . . . . . . . 
1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . _ 
127 
13 
$1,235 
170 
14 
$1,131 
115 
12 
1,080 
182 
8 
1,550 
127 
7 
845 
162 
11 
1,884 
150 
9 
1,522 
184 
10 
2,041 
156 
6 
1,047 
143 
6 
845 
182 
11 
1,979 
159 
9 
1,483 
156 
12 
1,822 
108 
14 
1,055 
132 
10 
1,253 
175 
8 
1,545 
137 
9 
1,297 
108 
6 
729 
113 
9 
946 
179 
9 
1,792 
137 
15 
1,713 
11 1 
15 
1,175 
117 
11 
1,024 
187 
8 
1,593 
137 
8 
1,147 
111 
7 
785 
153 
6 
1,092 
115 
7 
744 
117 
13 
1,152 
194 
5 
1,356 
126 
10 
1,336 
168 
7 
1.262 
S o I u t i o n The residual plot in Figure 10.16 dramatically reveals the one altered 
measurement. Note that one of the two residuals at x2 = 14 bidders falls more 
than 3 standard deviations below 0. Note that no other residual falls more than 
2 standard deviations from 0. 
What do we do with outliers once we identify them? First, we try to deter- 
mine the cause. Were the data entered into the computer incorrectly? Was the 

 
SECTION 10.7 R e s i d u a l  A n a l y s i s :  C h e c k i n g  t h e  R e g r e s s i o n  A s s u m p t i o n s  
605 
FIGURE 10.15 
MINITAB printout for 
grandfather clock example 
with altered data 
The regression equation is 
Price = - 922 + 11.1 Age + 64.0 Bidders 
Predictor 
Coef 
SE Coef 
T 
P 
Constant 
-921.5 
258.7 
-3.56 
0.001 
Age 
11.087 
1.347 
8.23 
0.000 
Bidders 
64.03 
12.99 
4.93 
0.000 
Analysis of Variance 
Source 
DF 
SS 
MS 
F 
P 
Regression 
2 
3015671 
1507835 
38.20 
0.000 
Residual Error 29 
1144619 
39470 
Total 
31 
4160290 
obs 
~ g e  
1 
127 
2 
115 
3 
127 
4 
150 
5 
156 
6 
182 
7 
156 
8 
132 
9 
137 
10 
113 
11 
137 
12 
117 
13 
137 
14 
153 
15 
117 
16 
126 
17 
170 
18 
182 
19 
162 
2 0 
184 
2 1 
143 
2 2 
159 
2 3 
108 
24 
17 5 
2 5 
108 
2 6 
17 9 
2 7 
111 
2 8 
187 
2 9 
111 
3 0 
115 
3 1 
194 
32 
168 
Price 
1235.0 
1080.0 
845.0 
1522.0 
1047.0 
1979.0 
1822.0 
1253.0 
1297.0 
946.0 
1713.0 
1024.0 
1147.0 
1092.0 
1152.0 
1336.0 
1131.0 
1550.0 
1884.0 
2041.0 
845.0 
1483.0 
1055.0 
1545.0 
729.0 
1792.0 
1175.0 
1593.0 
785.0 
744.0 
1356.0 
1262.0 
Fit 
1318.9 
1121.8 
934.7 
1317.7 
1192.2 
1800.6 
1576.3 
1182.2 
1173.6 
907.5 
1557.8 
1079.9 
1109.6 
1158.9 
1208.0 
1115.7 
1859.6 
1608.5 
1578.8 
1758.7 
1048.0 
1417.5 
1172.2 
1530.9 
660.0 
1639.2 
1269.5 
1663.9 
757.3 
801.7 
1549.4 
1389.2 
SE Fit 
57.4 
56.8 
57.5 
36.1 
56.7 
67.6 
52.2 
39.0 
37.9 
57.3 
77.5 
51.5 
43.0 
56.6 
61.8 
42.9 
82.1 
60.1 
48.5 
64.8 
58.4 
39.7 
74.9 
53.5 
83.5 
56.8 
82.0 
65.3 
71.9 
67.9 
84.2 
52.5 
St Resid 
-0.44 
-0.22 
-0.47 
1.05 
-0.76 
0.96 
1.28 
0.36 
0.63 
0.20 
0.85 
-0.29 
0.19 
-0.35 
-0.30 
1.14 
-4.03R 
-0.31 
1.58 
1.50 
-1.07 
0.34 
-0.64 
0.07 
0.38 
0.80 
-0.52 
-0.38 
0.15 
-0.31 
-1.08 
-0.66 
R denotes an observation with a large standardized residual 

606 
CHAPTER 10 I n t r o d u c t i o n  t o  Multiple Regression 
FIGURE 10.16 
MINITAB residual plot against 
number of bidders 
10 
Bidders 
observation recorded incorrectly when the data were collected? If so, we correct 
the observation and rerun the analysis. Another possibility is that the observation 
is not representative of the conditions we are trying to model. For example, in 
this case the low price may be attributable to extreme damage to the clock, or to 
a clock of inferior quality compared to the others. In these cases we probably 
would exclude the observation from the analysis. In many cases you may not be 
able to determine the cause of the outlier. Even so, you may want to rerun the re- 
gression analysis excluding the outlier in order to assess the effect of that obser- 
vation on the results of the analysis. 
Figure 10.17 shows the printout when the outlier observation is excluded 
from the grandfather clock analysis, and Figure 10.18 shows the new plot of the 
residuals against the number of bidders. Now none of the residuals lies beyond 2 
standard deviations from 0. Also, the model statistics indicate a much better 
model without the outlier. Most notably, the standard deviation (s) has decreased 
from 198.7 to 134.2, indicating a model that will provide more precise estimates 
and predictions (narrower confidence and prediction intervals) for clocks that 
are similar to those in the reduced sample. But remember that if the outlier is re- 
moved from the analysis when in fact it belongs to the same population as the 
rest of the sample, the resulting model may provide misleading estimates and 
predictions. 
Outlier analysis is another example of testing the assumption that the ex- 
pected (mean) value of the random error E is 0, since this assumption is in doubt 
for the error terms corresponding to the outliers. The next example in this section 
checks the assumption of the normality of the random error component. 
, .",a, ,, 
",, 
Kcfcr to Example 10.6. lJse a stcm-and-leaf di\play (Section 2.2) l o  plot the 
frequency distribution of the residuals in the grandfather clock example, both 
before and after the outlier residual is removed. Analyze the plots and determine 
whether the assumption of a normally distributed error term is reasonable. 
FIG 
MIP 
Exa 
dele 

SECTION 10.7 
R e s i d u a l  A n a l y s i s :  C h e c k i n g  t h e  R e g r e s s i o n  A s s u m p t i o n s  
607 
FIGURE 10.1 7 
MINITAB printout for 
Example 10.6: Outlier 
deleted 
The regression equation is 
Price = - 1288 + 12.5 Age + 83.3 Bidders 
Predictor 
Coef 
SE Coef 
T 
P 
Constant 
-1288.3 
185.3 
-6.95 
0.000 
Age 
12.5397 
0.9419 
13.31 
0.000 
Bidders 
83.290 
9.353 
8.90 
0.000 
Analysis of Variance 
Source 
DF 
S S 
MS 
F 
P 
Regression 
2 
3627818 
1813909 
100.67 
0.000 
Residual Error 28 
504496 
18018 
Total 
30 
4132314 
Souce 
Age 
Bidders 
Obs 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
2 0 
2 1 
2 2 
2 3 
2 4 
2 5 
2 6 
2 7 
2 8 
2 9 
3 0 
3 1 
DF 
Seq SS 
1 2199077 
1 1428741 
Age 
Price 
127 
1235.0 
115 
1080.0 
127 
845.0 
150 
1522.0 
156 
1047.0 
182 
1979.0 
156 
1822.0 
132 
1253.0 
137 
1297.0 
113 
946.0 
137 
1713.0 
117 
1024.0 
137 
1147.0 
153 
1092.0 
117 
1152.0 
126 
1336.0 
182 
1550.0 
162 
1884.0 
184 
2041.0 
143 
845.0 
159 
1483.0 
108 
1055.0 
175 
1545.0 
108 
729.0 
179 
1792.0 
111 
1175.0 
187 
1593.0 
111 
785.0 
115 
744.0 
194 
1356.0 
168 
1262.0 
Fit 
1387.1 
1153.3 
887.3 
1342.3 
1167.7 
1910.2 
1667.4 
1199.9 
1179.3 
878.3 
1679.0 
1095.1 
1096.0 
1130.1 
1261.7 
1124.7 
1660.3 
1659.4 
1852.0 
1004.7 
1455.2 
1232.1 
1572.5 
565.8 
1706.0 
1353.0 
1723.0 
686.7 
736.8 
1560.9 
1401.4 
SE Fit 
40.4 
38.8 
39.6 
24.7 
38.5 
49.2 
38.4 
26.5 
25.6 
39.0 
56.2 
34.9 
29.2 
38.5 
42.7 
29.0 
41.5 
35.4 
46.5 
40.1 
27.5 
51.6 
36.8 
58.6 
40.0 
57.1 
45.2 
50.0 
47.2 
56.9 
35.6 
Residual 
-152.1 
-73.3 
-42.3 
179.7 
-120.7 
68.8 
154.6 
53.1 
117.7 
67.7 
34.0 
-71.1 
51.0 
-38.1 
-109.7 
211.3 
-110.3 
224.6 
189.0 
-159.7 
27.8 
-177.1 
-27.5 
163.2 
86.0 
-178.0 
-130.0 
98.3 
7.2 
-204.9 
-139.4 
St Resid 
-1.19 
-0.57 
-0.33 
1.36 
-0.94 
0.55 
1.20 
0.40 
0.89 
0.53 
0.28 
-0.55 
0.39 
-0.30 
-0.86 
1.61 
-0.86 
1.73 
1.50 
-1.25 
0.21 
-1.43 
-0.21 
1.35 
0.67 
-1.47 
-1.03 
0.79 
0.06 
-1.69 
-1.08 

608 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
FIGURE 10.18 
MINITAB residual plot for 
Example 10.6: Outlier deleted 
S o l u t i o n  
FIGURE 10.19a 
Stem-and-leaf display for 
grandfather clock example: 
Outlier included 
I 
10 
Bidders 
The stem-and-leaf displays for the two sets of residuals are constructed using 
MINITAB and are shown in Figure 10.19.* Note that the outlier appears to 
skew the frequency distribution in Figure 10.19a, whereas the stem-and-leaf 
display in Figure 10.19b appears to be more mound-shaped. Although the 
displays do not provide formal statistical tests of normality, they do provide a 
descriptive display. Histograms and normal probability plots can also be used to 
check the normality assumption. In this example the normality assumption 
appears to be more plausible after the outlier is removed. Consult the chapter 
references for methods to conduct statistical tests of normality using the 
residuals. 
Stem-and-leaf of Residual 
N = 32 
Leaf Unit = 10 
*Recall that the left column of the MINITAB printout shows the number of measurements at 
least as extreme as the stem. In Figure 10.19a, for example, the 6 corresponding to the 
STEM = 1 means that six measurements are less than or equal to -100. If one of the numbers 
in the leftmost column is enclosed in parentheses, the number in parentheses is the number of 
measurements in that row. and the median is contained in that row. 
FIG[ 
Sten 
gran 
Outl 

SECTION 10.7 
R e s i d u a l  A n a l y s i s :  C h e c k i n g  t h e  R e g r e s s i o n  A s s u m p t i o n s  
609 
FIGURE 10.19b 
Stem-and-leaf display for 
grandfather clock example: 
Outlier excluded 
1 Stem-and-leaf of Residual 
N = 31 
Of all the assumptions in Section 10.3, the assumption that the random 
error is normally distributed is the least restrictive when we apply regression 
analysis in practice. That is, moderate departures from a normal distribution 
have very little effect on the validity of the statistical tests, confidence intervals, 
and prediction intervals presented in this chapter. In this case, we say that re- 
gression analysis is robust with respect to nonnormal errors. However, great de- 
partures from normality cast doubt on any inferences derived from the 
regression analysis. 
Residual plots can also be used to detect violations of the assumption of 
constant error variance. For example, a plot of the residuals versus the predicted 
value ^y may display a pattern as shown in Figure 10.20. In this figure, the range in 
values of the residuals increases as j j  increases, thus indicating that the variance of 
the random error, E, becomes larger as the estimate of E(y) increases in value. 
Since E(y) depends on the x values in the model, this implies that the variance of 
E is not constant for all settings of the x's. 
FIGURE 10.20 
Residual plot showing 
changes in the variance of E 
In the final example of this section, we demonstrate how to use this plot to 
detect a nonconstant variance and suggest a useful remedy. 
50 social workers. The first-order model E ( y )  = P, + B,x was fitted to the data 
using MINITAB.The MINITAB printout isshowL"in Figure 10.21, followed by a 
plot of the residuals versus j in Figure 10.22. Interpret the results. Make model 
modifications, if necessary. 

CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
TABLE 
10.5 
Salary Data for Example 10.8 
Years of 
Years of 
Years of 
Experience, 
Salary, 
Experience, 
Salary, 
Experience, 
Salary, 
X 
Y 
X 
Y 
X 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Y 
7 
$26,075 
21 
$43,628 
28 
$99.139 
28 
79,370 
4 
16,105 
23 
52,624 
23 
65,726 
24 
65,644 
17 
50,594 
18 
41,983 
20 
63,022 
25 
53,272 
19 
62,308 
20 
47,780 
26 
65,343 
15 
41,154 
15 
38,853 
19 
46,216 
24 
53,610 
25 
66,537 
16 
54,288 
13 
33,697 
25 
67,447 
3 
20,844 
2 
22,444 
28 
64,785 
12 
32,586 
8 
32,562 
26 
- 
61,581 
23 
71,235 
20 
43,076 
27 
70,678 
20 
36.530 
21 
56,000 
20 
51,301 
19 
52,745 
-
,
+
 
18 
58,667 
18 
39,346 
27 
67.282 
7 
22,210 
1 
24,833 
25 
80,931 
2 
20,521 
26 
65,929 
12 
32.303 
18 
49,727 
20 
41,721 
11 
38.371 
The regression equation is 
Y = 11369 + 2 1 4 1  X 
Predictor 
Coef 
StDev 
t-ratio 
P 
Constant 
11369 
3 1 6  0 
3 . 6 0  
0 . 0 0 1  
X 
2 1 4 1 . 3  
1 6 0 . 8  
1 3 . 3 1  
0 . 0 0 0  
Analysis of Variance 
SOURCE 
DF 
SS 
MS 
F 
P 
Regression 
1 13238774784 13238774784 
1 7 7 . 2 5  
0.000 
Error 
48 
3585073152 
74689024 
Total 
49 16823847936 
Unusual Observations 
Obs . 
X 
Y 
Fit Stdev.Fit Residual 
St .Resid 
3 1 
1 . 0  
24833 
1 3 5 1 1  
3013 
11 3 2 2 
1 . 4 0  X 
3 5 
2 8 . 0  
99139 
71326 
2005 
27813 
3.31R 
4 5 
2 0 . 0  
36530 
54196 
1259 
-17666 
-2.07R 
R denotes an obs. with a large st. resid. 
X denotes an obs. whose X value gives it large influence. 
FIGURE 10.21 
MINITAB analysis for first-order model, Example 10.8 
S o I u t i o n The MINITAB printout, Figure 10.21, suggests that the first-order model 
provides an adequate fit to the data. The R2 value indicates that the model 
explains 78.7% of the sample variation in salaries. The t value for testing fl,. 
13.31, is highly significant (p-value = 0) and indicates that the model contributes 
information for the prediction of y. However, an examination of the residuals 

SECTION 10.7 
Residual Analysis: Checking t h e  Regression Assumptions 
611 
F I G U R E  10.22 
MINITAB residual plot for first-order model, Example 10.8 
30000+ 
- 
Residual- 
plotted against jj (Figure 10.22) reveals a potential problem. Note the "cone" 
shape of the residual variability; the size of the residuals increases as the 
estimated mean salary increases, implying that the constant variance assumption 
is violated. 
One way to stabilize the variance of E is to refit the model using a trans- 
formation on the dependent variable y. With economic data (e.g., salaries) a 
useful variance-stabilizing transformation is the natural logarithm of y.* We fit 
the model 
to the data of Table 10.5. Figure 10.23 shows the regression analysis printout for 
the n = 50 measurements, while Figure 10.24 shows a plot of the residuals from 
the log model. 
You can see that the logarithmic transformation has stabilized the error 
variances. Note that the cone shape is gone; there is no apparent tendency of the 
residual variance to increase as mean salary increases. We therefore are confident 
that inferences using the logarithmic model are more reliable than those using the 
untransformed model. 
Residual analysis is a useful tool for the regression analyst, not only to check 
the assumptions, but also to provide information about how the model can be im- 
proved. A summary of the residual analyses presented in this section to check the 
assumption that the random error E is normally distributed with mean 0 and con- 
stant variance is presented in the box on p. 613. 
*Other variance-stabilizing transformations that are used successfully in practice are fi 
and 
sin-' -\/T;. Consult the chapter references for more details on these transformations. 

CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
The regression equation is 
LOGY = 9.84 + 0.0500 X 
Predictor 
Coef 
StDev 
t-ratio 
P 
Constant 
9.84133 
0.05636 
174.63 
0.000 
X 
0.049978 
0.002868 
17.43 
0.000 
Analysis of Variance 
SOURCE 
DF 
SS 
MS 
F 
P 
Regression 
1 
7.2118 
7.2118 
303.65 
0.000 
Error 
4 8 
1.1400 
0.0238 
Total 
4 9 
8.3519 
Unusual Observations 
Obs . 
X 
LOGY 
Fit Stdev.Fit Residual 
St .Resid 
19 
4.0 
9.6869 
10.0412 
0.0460 
-0.3544 
- 2.41R 
3 1 
1.0 
10.1199 
9.8913 
0.0537 
0.2286 
1.58 X 
4 5 
20.0 
10.5059 
10.8409 
0.0225 
-0.3350 
-2.20R 
R denotes an obs. with a large st. resid. 
X denotes an obs. whose X value gives it large influence. 
FIGURE 10.23 
MlNlTAB printout for modified model, Example 10.8 
FIGURE 10.24 
MlNlTAB residual plot for modified model, Example 10.8 

SECTION 10.7 
Residual A n a l y s i s :  C h e c k i n g  t h e  Regression A s s u m p t i o n s  
613 
Using the TI-83 Graphing Calculator 
Plotting Residuals on the TI-83 
When you compute a regression equation on the TI-83, the residuals are automat- 
ically computed and saved to a list called RESID. RESID can be found under the 
LIST menu (2nd STAT). 
To make a scatterplot of the residuals, 
Step 1 Enter the data in Ll and L2 
Step 2' Compute the regression equation (see Section 9.2) 
Step 3 Set up the data plot 
Press 2nd Y= for STATPLOT 
Press 1 for Plat1 
Use the arrow and ENTER keys to set up the screen as shown below. 
YPET: 
E db 
m-- m 
V1ist:RESID 
Mark: I 
+ 
Note: 
To enter the RESID as your Ylist: 
1. 'Use the arrow keys to move the cursor after Ylist: 
2. Press 2nd STAT for LIST 
3. Highlight the listname RESID and press ENTER ' 
Step 4 View the scatterplot of the re~iduals 
Press ZOOM 9 for ZoomStat 
Example The figures below show a 
scatterplot of the residuals 
table of data entered on the TL-83 and 
obtained using the steps given above. 
the 
quantitative independent variables. Analyze each plot, looking for a curvilin- 
ear trend.This shape signals the need for a quadratic term in the mode1.T~ a 
second-order term in the variable against which the residuals are plotted. 
?- 
2. Examine the residual plots for outliers. Draw lines on the residual plots at 
2- and 3-standard-deviation distances below and above the 0 line. Examine 
(continued) 

I n t r o d u c t i o n  t o  Multiple Regression 
error in data collection or transcription, or corresponds to a member of a 
population different from that of the remainder of the sample, or simply 
mine its effect on the analysis. 
distribution of the 
ious departures from normality exist. Extreme skewness of the fre- 
(Normalizing transforma- 
ou can find information in 
g the residuals against the 
tern that indicates that the variance of E is not constant, refit the 
SOME PITFALLS: ESTIMABILITY, 
MULTICOLLINEARITY, AND EXTRAPOLATION 
You should be aware of several potential problems when constructing a prediction 
model for some response y. A few of the most important are discussed in this final 
section. 
Problem 1 
Parameter Estimability 
Suppose you want to fit a model relating annual crop yield y to the total expendi- 
ture for fertilizer x. We propose the first-order model 
E(Y) = Po + PIX 
Now suppose we have three years of data and $1,000 is spent on fertilizer each 
year. The data are shown in Figure 10.25. You can see the problem: The parame- 
ters of the model cannot be estimated when all the data are concentrated at a single 
x value. Recall that it takes two points (x values) to fit a straight line.Thus, the pa 
rameters are not estimable when only one x is observed. 
Yield and fertilizer expenditure data: Three years 
A 
9 
7 
5 
Fertilizer expenditure (dollars) 

 
i 
SECTION 10.8 
Some Pitfalls: Estimability, Multicollinearity, and Extrapolation 
615 
A similar problem would occur if we attempted to fit the quadratic model 
to a set of data for which only one or two different x values were observed (see Fig- 
ure 10.26). At least three different x values must be observed before a quadratic 
model can be fit to a set of data (that is, before all three parameters are estimable). 
Only two x values observed: Quadratic model is 
A 
not estimable 
0 
? 
9 
? 
0 
1,000 
2,000 
Fertilizer expenditure (dollars) 
In general, the number of levels of observed x values must be one more than 
the order of the polynomial in x that you want to fit. 
For controlled experiments, the researcher can select experimental designs 
that will permit estimation of the model parameters. Even when the values of the 
independent variables cannot be controlled by the researcher, the independent 
variables are almost always observed at a sufficient number of levels to permit es- 
timation of the model parameters. When the statistical software you use suddenly 
refuses to fit a model, however, the problem is probably inestimable parameters. 
Problem 2 
Multicollinearity 
Often, two or more of the independent variables used in the model for E(y) con- 
tribute redundant information. That is, the independent variables are correlated 
with each other. Suppose we want to construct a model to predict the gas mileage 
rating of a truck as a function of its load, x,, and the horsepower of its engine, x2. 
In general, we would expect heavy loads to require greater horsepower and to re- 
sult in lower mileage ratings. Thus, although both x1 and x2 contribute information 
for the prediction of mileage rating, some of the information is overlapping be- 
cause x, and x2 are correlated. 
If the model 
were fitted to a set of data, we might find that the t values for both pl and p2 (the 
least squares estimates) are nonsignificant. However, the F-test for H,: PI = P2 = 0 
would probably be highly significant. The tests may seem to produce contradictory 
conclusions, but really they do not. The t-tests indicate that the contribution of one 
variable, say xl = Load, is not significant after the effect of x2 = Horsepower has 
been taken into account (because x2 is also in the model). The significant F-test, on 
the other hand, tells us that at least one of the two variables is making a contribution 
to the prediction of y (that is, either PI or P2, 
or both, differ from 0). In fact, both are 
probably contributing, but the contribution of one overlaps with that of the other. 

CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
When highly correlated independent variables are present in a regression 
model, the results are confusing.The researcher may want to include only one of the 
variables in the final model. One way of deciding which one to include is by using a 
technique called stepwise regression. In stepwise regression, all possible one-variable 
models of the form E(y) = Po + Pix, are fit and the "best" x, is selected based on 
the t-test for p,. Next, two-variable models of the form E(y) = p,, + plxl + P2x, are 
fit (where x, is the variable selected in the first step); the "second best" x, is selected 
based on the test for p,. The process continues in this fashion until no more "impor- 
tant" x's can be added to the model. Generally, only one of a set of multicollinear 
independent variables is included in a stepwise regression model, since at each step 
every variable is tested in the presence of all the variables already in the model. For 
example, if at one step the variable Load is included as a significant variable in the 
prediction of the mileage rating, the variable Horsepower will probably never be 
added in a future step. Thus, if a set of independent variables is thought to be multi- 
collinear, some screening by stepwise regression may be helpful. 
Note that it would be fallacious to conclude that an independent variable x, 
is unimportant for predicting y only because it is not chosen by a stepwise regres- 
sion procedure. The independent variable x, may be correlated with another one, 
x2, that the stepwise procedure did select. The implication is that x, contributes 
more for predicting y (in the sample being analyzed), but it may still be true that 
x, alone contributes information for the prediction of y. 
Problem 3 
Prediction Outside the Experimental Region 
By the late 1960s many research economists had developed highly technical mod- 
els to relate the state of the economy to various economic indices and other inde- 
pendent variables. Many of these models were multiple regression models, where, 
for example, the dependent variable y might be next year's Gross Domestic Prod- 
uct (GDP) and the independent variables might include this year's rate of infla- 
tion, this year's Consumer Price Index (CPI), etc. In other words, the model might 
be constructed to predict next year's economy using this year's knowledge. 
Unfortunately, these models were almost all unsuccessful in predicting the 
recession in the early 1970s. What went wrong? One of the problems was that 
many of the regression models were used to extrapolate, i.e., predict y values of 
the independent variables that were outside the region in which the model was 
developed. For example, the inflation rate in the late 1960s, when the models 
were developed, ranged from 6% to 8%. When the double-digit inflation of the 
early 1970s became a reality, some researchers attempted to use the same models 
to predict future growth in GDP. As you can see in Figure 10.27, the model may be 
very accurate for predicting y when x is in the range of experimentation, but the 
use of the model outside that range is a dangerous practice. 
FIGURE 10.27 
Y 
Using a regression model outside the 
A 
experimental region 
B 0 
E
Lee 
10.2
10.3
APF
10.31 
-
1
 
0 
6 
8 
Inflation rate(%) 

SECTION 10.8 
S o m e  P i t f a l l s :  E s t i m a b i l i t y ,  M u l t i c o l l i n e a r i t y ,  a n d  E x t r a p o l a t i o n  
617 
Problem 4 
Correlated Errors 
Another problem associated with using a regression model to predict a variable y 
based on independent variables x,, 
x,, .... xk arises from the fact that the data are 
frequently time series. That is, the values of both the dependent and independent 
variables are observed sequentially over a period of time. The observations tend 
to be correlated over time. which in turn often causes the prediction errors of the 
regression model to be correlated. Thus, the assumption of independent errors is 
violated, and the model tests and prediction intervals are no longer valid. One so- 
lution to this problem is to construct a time series model; consult the references 
for this chapter to learn more about these complex, but powerful, models. 
Learning the Mechanics 
10.36 Identify the problem(s) in each of the residual plots 
shown at the bottom of the page. 
10.37 Consider fitting the multiple regression model 
E(Y) = Po + PIXI + P 2 ~ 2  
+ P3x3 + P4x4 + Psx5 
A matrix of correlations for all pairs of independent 
variables is given to the right. Do you detect a multi- 
collinearity problem? Explain. 
Applying the Concepts 
10.38 Chemical engineers at Tokyo Metropolitan University 
analyzed urban air specimens for the presence of low- 
Residual plots for Exercise 10.36 
a. 
Correlation Matrix for Exercise 10.37 
- 
.................................. ................................................ 
Xl 
x2 
x3 
x4 
x5 
.................................................................................... 
XI 
- .17 
.02 
-.23 
.19 
x2 
- .45 
.93 
.02 
x3 
- 
.22 
-.01 
x4 
- 
.86 
x5 
- 
molecular-weight dicarboxylic acid (Environmental 
Science & Engineering, Oct. 1993). The dicarboxylic 
acid (as a percentage of total carbon) and oxidant con- 
centrations for 19 air specimens collected from urban 

CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
I 
URBANAIRDAT 
..................................................................................................................................................................... 
Dicarboxylic Acid (%) 
Oxidant (ppm) 
Dicarboxylic Acid (%) 
Oxidant (ppm) 
................................................................................................................................................................... 
.85 
78 
S O  
32 
1.45 
80 
.38 
28 
1.80 
74 
.30 
25 
1.80 
78 
.70 
45 
1.60 
60 
3 0  
40 
1.20 
62 
.90 
45 
1.30 
57 
1.22 
41 
.20 
49 
1 .oo 
34 
.22 
34 
1 .OO 
25 
.40 
36 
Source: Kawamura, K., and Ikushima, K. "Seasonal changes in the distribut~on of d~carboxylic acids 
in the urban atmoswhere." Environmental Suence & Technology,Vol. 27. No. 10, Oct. 1993, p. 2232 
(data extracted from Figure 4). 
Tokyo are listed in the table above. SAS printouts for 
the straight-line model relating dicarboxylic acid pcr- 
centage (y) to oxidant concentration (x) are also pro- 
vided on pages 619-621. Conduct a complete residual 
analysis. 
10.39 World Development (Vol. 20,1992) published a study 
of the variables impacting the size distribution of man- 
ufacturing firms in international markets. Five inde- 
pendent variables, Gross Domestic Product (GDP), 
area per capita (AREAC), share of heavy industry in 
value added (SVA), ratio of credit claims to GDP 
(CREDIT), and ratio of stock equity of G D P  
(STOCK), were used to model the share, y, of firms 
- 
with 100 or more workers. Thc researchers detected a 
high correlation between pairs of the following inde- 
pendent variables: GDP and SVA, GDP and STOCK, 
and CREDIT and STOCK. Describe the problems 
that may arise if these high correlations are ignored in 
the multiple regression analysis of the model. 
10.40 Passive exposure to environmental tobacco smoke has 
been associated with growth suppression and an 
increased frequency of respiratory tract infections in 
normal children. Is this association more pronounced in 
children with cystic fibrosis? To answer this question, 43 
children (18 girls and 25 boys) attending a 2-week 
summer camp for cystic fibrosis patients were studied 
(The New England Journal of Medicine, Sept. 20,1990). 
Researchers investigated the correlation between a 
child's weight percentile (y) and the number of ciga- 
rettes smoked per day in the child's home (x). The table 
on page 621 lists the data for the 25 boys. A MINITAB 
regression printout (with residuals) for the straight-line 
model relating y to x is also provided on page 622. 
Examine the residuals. Do you detect any outliers? 
10.41 Road construction contracts in the state of Florida are 
awarded on the basis of com~etitive, sealed bids; the 
contractor who submits the lowest bid price wins the 
contract. During the 1980s, the Office of the Florida 
for 279 road construction contracts; the data are ava~l- 
able in the file FLAG.DAT. For each contract, the fol- 
lowing variables were measured: 
1. Price of contract ($thousands) bid by lowest bidder 
2. Department of Transportaion (DOT) engineer's es- 
timate of fair contract price ($thousands) 
3. Ratio of low (winning) bid price to DOT engineer's 
estimate of fair price. 
4. Status (fixed or competitive) of contract 
5. District (1,2,3,4, or 5) in which construction project 
is located 
6. Number of bidders on contract 
7. Estimated number of days to complete work 
8. Length of road project (miles) 
9. Percentage of costs allocated to liquid asphalt 
10. Percentage of costs allocated to base material 
11. Percentage of costs allocated to excavation 
12. Percentage of costs allocated to mobilization 
13. Percentage of costs allocated to structures 
14. Percentage of costs allocatcd to traffic control 
15. Subcontractor utilization (yes or no) 
FLAG wants to model the price (y) of the contract bid 
by lowest bidder in hopes of preventing price-fixing in 
the future. 
a. Do you detect any multicollinearity in these vari- 
ables? If so, do you recommend that all of these 
variables be used to predict low bid pricey? If not. 
which variables do you recommend? 
b. Using the variables selected in part a, fit a first- 
order model for E(y) to the data stored in the file. 
c. Conduct a complete residual analysis on the 
model fit in part b. Do you detect any outliers? Are 
the standard regression assumptions reasonably 
satisfied? 
Attorney General (FLAG) suspected numerous con- 
i 
tractors of practicing bid collusion, i.e., setting the win- 
. 
ning bid price above the fair, or competitive, price in 
order to increase profit margin. FLAG collected data 
1 

SECTION 10.8 
Some Pitfalls: Estimability, Multicollinearity, and Extrapolation 
619 
SAS Output for Exercise 10.38 
Dependent Variable: 
Source 
Model 
Error 
C Total 
Root MSE 
Dep Mean 
C.V. 
DICARBOX 
Analysis of Variance 
Sum of 
Mean 
DF 
Squares 
Square 
F Value 
Prob>F 
1 
2 .dl362 
2.41362 
17.080 
0.0007 
17 
2.40234 
0.14131 
18 
4.81597 
0.37592 
R-square 
0.5012 
0.92737 
Adj R-sq 
0.4718 
40.53600 
Variable 
INTERCEP 
OXIDANT 
Obs OXIDANT 
1 
7 8 
2 
8 0 
3 
;4 
4 
7 8 
5 
60 
6 
6 2 
7 
57 
8 
4 9 
9 
3 4 
10 
3 6 
11 
3 2 
12 
2 8 
13 
25 
14 
4 5 
15 
4 0 
16 
4 5 
17 
41 
18 
3 4 
19 
2 5 
Parameter Estimates 
Parameter 
Standard 
T for HO: 
DF 
Estimate 
Error Parameter=O 
Prob > IT1 
1 
-0.023737 
0.24576577 
-0.097 
0.9242 
1 
0.019579 
0.00473739 
4.133 
0.0007 
Dep Var 
DICARBOX 
0.8500 
1.4500 
1.8000 
1.8000 
1.6000 
1.2000 
1.3000 
0.2000 
0.2200 
0.4000 
0.5000 
0.3800 
0.3000 
0.7000 
0.8000 
0.9000 
1.2200 
1.0000 
1.0000 
Predict 
Value 
1.5034 
1.5425 
1.4251 
1.5034 
1.1510 
1.1901 
1.0922 
0.9356 
0.6419 
0.6811 
0.6028 
0.5245 
0.4657 
0.8573 
0.7594 
0.8573 
0.7790 
0.6419 
0,4657 
Std Err 
Predict 
0.164 
0.172 
0.148 
0.164 
0.102 
0.107 
0.095 
0.086 
0.110 
0.105 
0.117 
0.130 
0.141 
0.088 
0.095 
0.088 
0.093 
0.110 
0.141 
Residual 
-0.6534 
-0.0925 
0.3749 
0.2966 
0.4490 
0.0099 
0.2078 
-0.7356 
-0.4219 
-0.2811 
-0.1028 
-0.1445 
-0.1657 
-0.1573 
0.0406 
0.0427 
0.4410 
0.3581 
0.5343 
Std Err 
Residual 
0.338 
0.334 
0.346 
0.338 
0.362 
0.360 
0.364 
0.366 
0.359 
0.361 
0.357 
0.353 
0.348 
0.365 
0.364 
0.365 
0.364 
0.359 
0.348 
(Continued) 
I 
1042 Teaching Sociology (July 1995) developed a model for 
i 
the professional socialization of graduate students work- 
i I 
ing toward their doctorate. One of the dependent vari- 
ables modeled was professional confidence. y, measured 
on a 5-point scale. The model included over 20 indepen- 
dent variables and was fitted to data collected for a 
1 
sample of 309 graduate students. One concern is whet he^ 
multicollinearity exists in the data. A matrix of Pearson 
product moment correlations for ten of the independent 
variables is shown on page 622. [Note: Each entry in the 
table is the correlation coefficient r between the variable 
in the corresponding row and corresponding column.] 
a. Examine the correlation matrix and find the inde- 
pendent variables that are moderately or highly cor- 
related. 
b. What modeling problems may occur if the variables, 
part a, are left in the model? Explain. 
10.43 The data in the table on p. 624 were collected for a 
random sample of 26 households in Washington, D.C., 
during 2000. An economist wants to relate household 
food consumption, y, to household income, X I ,  and 
household size, x,, with the first-order model 

620 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
SAS Output for Exercise 10.38 (continued) 
UNIVARIATE PROCEDURE 
Variable=RESID 
Residual 
Moment e 
N 
Mean 
std Dev 
Skewness 
uss 
cv 
T :Mean= 0  
Sgn Rank 
Num 
A=O 
W: Normal 
100% Max 
75% Q3 
50% Med 
25% Q 1  
0% Min 
Range 
Q 3 - Q l  
Mode 
Lowest 
- 0 . 7 3 5 6 1  ( 
-0.65339 ( 
-0.42193 ( 
-0.28109 ( 
-0.16573 ( 
Stem Leaf 
4  
453 
2  
1067 
0  
144 
-0 
76409 
-2 
8 
-4 
2  
-6 
4 5  
Sum Wgt s 
Sum 
Variance 
Kurtosis 
css 
Std Mean 
Prob> [TI 
Prob> IS! 
ProbxW 
Extremes 
Obs 
Highest 
8 )  
0 . 3 5 8 0 6 6 (  
1 )  
0 . 3 7 4 9 2 4 (  
9 )  
0 . 4 4 1 0 1 6 (  
1 0 )  
0.449024 ( 
1 3 )  
0.534273 ( 
Boxplot 
I 
(Continued) 
The SPSS printout for the model below is followed by 
c. Comment on the assumption of constant error van. 
several residual plots on pages 623 and 625. 
ance. Does it appear to be satisfied? 
a. Do you detect any signs of multicollinearity in the 
d. Are there any outliers in the data? If so, ident~h 
data' Explain. 
them. 
b. Is there visual evidence that a second-order model 
e. Does the assumption of normal errors appear to b, 
may be more appropriate for predicting household 
reasonably satisfied? Explain. 
food consumption? Explain. 
I 

SECTION 10.8 
Some Pitfalls: Estimability, M u l t i c o l l i n e a r i t y ,  and E x t r a p o l a t i o n  
SAS Output for Exercise 10.38 (continued) 
Plot of RESID*OXIDANT. Legend: A = 1 obs, B = 2 obs,etc. 
OXIDANT 
CFSMOKE.DAT (Data for Exercise 10.40) 
............................................................................................................................................................................. 
No. of Cigarettes 
No. of Cigarettes 
Weight Percentile, y 
Smoked per Day, x 
Weight Percentile, y 
Smoked per, Day x 
.................... 
____ ............................................................................................................................................ 
6 
0 
43 
0 
6 
15 
49 
0 
2 
40 
50 
0 
8 
23 
49 
22 
11 
20 
46 
30 
17 
7 
54 
0 
24 
3 
58 
0 
25 
0 
62 
0 
17 
25 
66 
0 
25 
20 
66 
23 
25 
15 
83 
0 
3 1 
23 
87 
44 
35 
10 
Source: Rubin, B. K. "Exposure of children with cystic fibrosis to environmental tobacco smoke." The 
New England Journal of Medicine, Sept. 20,1990. Vol. 323, No. 12, p. 85 (data extracted from Figure 3). 

622 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
MINITAB Output for Exercise 10.40 
- 
- 
The regression equatlon is 
UTPCTILE = 41.2 - 0.262 SMOKED 
Predictor 
Coef 
Stdev 
t-ratio 
P 
:onstant 
41.153 
6.843 
6.01 
0.000 
SMOKED 
-0.2619 
0.3702 
-0.71 
0.486 
s = 24.68 
R-sq = 2.1% 
R-sqiad]) = 0.0% 
4nalysls of Variance 
SOURCE 
DF 
S S 
MS 
F 
P 
Regression 
1 
304.9 
304.9 
0.50 
0.486 
Error 
2 3 
14011.1 
609.2 
rota1 
2 4 
14316.0 
SMOKED 
0.0 
15.0 
40.0 
23.0 
20.0 
- 7.0 
3.0 
0.0 
25.0 
20.0 
15.0 
23.0 
10.0 
0.0 
0.0 
0.0 
22.0 
30.0 
0.0 
0.0 
0.0 
0.0 
23.0 
0.0 
44.0 
WTPCTILE 
6.00 
6.00 
2.00 
8.00 
11.00 
17.00 
24.00 
25.00 
17.00 
25.00 
25.00 
31.00 
35.00 
43.00 
49.00 
50.00 
49.00 
46.00 
54.00 
58.00 
62.00 
66.00 
66.00 
83.00 
87.00 
Fit Stdev.Fit Residual St.Resid 
Correlation matrix for Exercise 10.42 
.................................................................................................................................................................................................................................................. 
Independent Variable 
(1) 
(2) 
(3) 
(4) 
(5) 
(6) 
(7) 
(8) 
(9) 
(10) 
................................................................................................................................................................................................................................................... 
(1) Father's occupation 
1.000 
.363 
,099 
-.I10 
-.047 
-.053 
-.I11 
.I78 
.078 
,049 ' 
(2) Mother's education 
.363 
1.000 
.228 
-.I39 
-.216 
.084 
-.I18 
.I92 
(3) Race 
,099 
.228 
1.000 
.036 
-.515 
.014 
-.I20 
.I12 
.I17 
.33- 
(4) Sex 
-.I10 
-.I39 
,036 
1.000 
,165 
-.256 
.I73 
-.I06 
-.I17 
,073 
(5) Foreign status 
-.047 
-.216 
-.515 
.I65 
1.000 
-.041 
.I59 
-.I30 
-.I65 
-.I71 
(6) Undergraduate GPA 
0b8 I 
-.053 
.084 
.014 
-.256 
-.041 
1.000 
.032 
.028 
-.034 
,091 
(7) Year GRE taken 
-.I11 
-.I18 
-.I20 
.I73 
.I59 
.032 
1.000 
-.086 
-.602 
,016 
(8) Verbal GRE score 
.I78 
.I92 
.I12 
-.lo6 
-.I30 
.028 
-.086 
1.000 
.I32 
,087 
(9) Years in graduate program 
.078 
,125 
.I17 
-.I17 
-.I65 
-.034 
-.602 
,132 
1.000 
-.071 
(10) First-year graduate GPA 
.049 
,068 
.337 
.073 
-.I71 
.092 
.016 
'087 
-.071 
1.000 
Source: Keith, B., and Moore, H. A. "Training sociologists: An assessment of professional socializatoin and the emergence of career aspirations." 
Teaching Sociology, Vo. 23, No. 3, July 1995, p. 205 (Table 1). 
I 
< 
SPS -
E 
B 
MI
R 
A( 
St 
-. 
VB
In:
HC 
(C
Re 
kP
'R:
.z
' Z I  
'ot - 

SECTION 10.8 
Some Pitfalls: Estimability, M u l t i c o l l i n e a r i t y ,  a n d  E x t r a p o l a t i o n  
623 
SPSS Output for Exercise 10.43 
Equation Number 1. 
Dependent Variable. . 
FOOD 
Block Number 1. Method: Enter 
INCOME 
HOMESIZE 
Multlple R 
.74699 
Analysis of Variance 
R Square 
.55800 
DF 
Sum of Squares 
Adjusted R Square 
.51956 
Regression 
2 
15.00268 
Standard Error 
.71881 
Residual 
2 3 
11.88386 
- - - - - - - - - - - - - - - - - - Variables in the Equation ------------------ 
Variable 
B 
SE B 
Beta 
T Sig T 
INCOME 
-1.63937E-04 
.006564 
-.003495 
-.025 .9803 
HOMESIZE 
.383485 
.071887 
.746508 
5.335 .OOOO 
(Constant 
) 
2.794380 
.436335 
6.404 .OOOO 
Residuals Statistics : 
Min 
Max 
Mean Std Dev 
N 
"RED 
3.1664 
6.2383 
4.1885 
.7747 26 
*RESID 
-. 9748 
2.7894 
.0000 
.6895 26 
*ZPRED 
-1.3194 
2.6460 
.OOOO 
1.0000 26 
'ZRESID 
-1.3561 
3.8806 
.OOOO 
.9592 26 
rota1 Cases = 
2 6 
SPSS Plots for Exercise 10.43 
3l 
Regression Standardized Predicted Value 
2 
p 
I 
l o  
-1 
-2 
0 
I 
20 
40 
60 
80 
100 
0 
2 
4 
6 
8 
10 
Income 
Homesize 
- 
2 
- 
. 
9 l -  
.@ 
-9 
0 
- 
0 f 9.. . 
2 o -  
+ @. 
. 
0 
- 
0 
-1 
I 
I 
I 
I 
I 
-2 
- 
@
@
.
 
. : 
I
!
:
*
 . 
t
 
- 
@
,
 
I 
I 
I 
I 

I
624 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
# 
S 
"Wringing" The Bell Curve 
I 
n Statistics in Action in Chapter 4, we introduced The Bell 
Curve (Free Press, 1994) by Richard Herrnstein and 
Charles Murray, a controversial book about race, genes, IQ, 
and economic mobility.The book heavily employs statistics 
and statistical methodology in an attempt to support the 
authors' positions on the relationships among these vari- 
ables and their social consequences.The main theme of The 
Bell Curve can be summarized as follows: 
1. Measured intelligence (IQ) is largely genetically inherited. 
2. IQ is correlated positively with a variety of socioeco- 
nomic status success measures, such as prestigious job, 
high annual income, and high educational attainment. 
3. From 1 and 2, it follows that socioeconomic successes 
are largely genetically caused and therefore resistant to 
educational and environmental interventions (such as 
affirmative action). 
With the help of a major marketing campaign, the book 
became a best-seller shortly after its publication in October 
1994.The underlying theme of the book-that 
intelligence is 
hereditary and tied to race and class-apparently 
appealed 
to many readers. However, reviews of The Bell Curve in 
popular magazines and newspapers were mostly negative. 
Social critics have described the authors as "un-Americann 
and "pseudo-scientific racists," and their book as "alien and 
repellant." (On the other hand, there were defenders who 
labeled the book as "powerfully written" and "overwhelm- 
ingly convincing".) This Statistics in Action is based on two re- 
views of The Bell Curve that critique the statistical methodol- 
ogy employed by the authors and the inferences derived from 
the statistics. Both reviews, one published in Chance (Summer 
1995) and the other in The Journal of the American Statistical 
Association (Dec. 1995), were written by Carnegie Mellon 
University professors Bernie Devlin, Stephen Fienberg. 
Daniel Resnick, and Kathryn Roeder. (Devlin, Fienberg, and 
Roeder are all statisticians; Resnick, a historian.) 
Here, our focus is on the statistical method used repeat- 
edly by Herrnstein and Murray (H&M) to support their con- 
clusions in The Bell Curve: regression analysis.The following 
are just a few of the problems with H&M's use of regression 
that are identified by the Carnegie Mellon professors: 
Problem 1 H&M consistently use a trio of independent vari- 
ables-IQ, socioeconomic status, and age-in 
a series of firct- 
order models designed to predict dependent social outcomi. 
variables such as income and unemployment. (Only on a sin- 
gle occasion are interaction terms incorporated.) Consider. 
for example, the model: 
where y = income, x, = IQ,x2 = socioeconomic status, and 
x, = age. H&M utilize t-tests on the individual /3 parameter\ 
to assess the importance of the independent variables, A\ 
with most of the models considered in The Bell Curve, the 
esl 
cal 
er 
otl 
IQ 
P e' 
wh 
mo 
Prc 
reg 
c i e
hov 
ant]
den 
wit! 
the 
esm 
evitr 
like 
Prot 
butlc 
misc 
tellip 
IQ sc 
ditio~
form 
............................................................................................................................................................................................. 
................... 
Food Consumption 
Income 
Household 
Food Consumption 
Income 
Household 
Household 
($1,000~) 
($1,000~) 
Size 
Household 
($1,000~) 
($1,000~) 
Size 
....................................................................................................................................................................................................................... 
1 
4.2 
41.1 
4 
14 
4.1 
95.2 
2 
2 
3.4 
30.5 
2 
15 
5.5 
45.6 
9 
3 
4.8 
52.3 
4 
16 
4.5 
78.5 
3 
4 
2.9 
28.9 
1 
17 
5.0 
20.5 
5 
5 
3.5 
36.5 
2 
18 
4.5 
31.6 
4 
6 
4.0 
29.8 
4 
19 
2.8 
39.9 
1 
7 
3.6 
44.3 
3 
20 
3.9 
38.6 
3 
8 
4.2 
38.1 
4 
21 
3.6 
30.2 
2 
9 
5.1 
92.0 
5 
22 
4.6 
48.7 
5 
10 
2.7 
36.0 
1 
23 
3.8 
21.2 
3 
11 
4.0 
76.9 
3 
24 
4.5 
24.3 
7 
12 
2.7 
69.9 
1 
25 
4.0 
26.9 
F 
13 
5.5 
43.1 
7 
26 
7.5 
7.3 
j 
I 

 
1 
SECTION 10.8 
S o m e  P i t f a l l s :  E s t i r n a b i l i t y ,  M u l t i c o l l i n e a r i t y ,  a n d  E x t r a p o l a t i o n  
625 
estimate of p, in the income model is positive and statisti- 
cally significant at n = .05, and the associated t value is larg- 
er (in absolute value) than the t values associated with the 
other independent variables. Consequently, H&M clairn that 
IQ is a better predictor of income than the other two inde- 
pendent variables. No attempt was made to determine 
whether the model was properly specified or whether the 
model provides an adequate fit to the data. 
Problem 2 In an appendix, the authors describe multiple 
regression as a "mathematical procedure that yields coeffi- 
cients for each of [the independent variables], indicating 
how much of a change in [the dependent variable] can be 
anticipated for a given change in any particular [indepen- 
dent] variable, with all the others held constant." Armed 
with this information and the fact that the estimate of p, in 
the model above is positive, H&M infer that ~1 high IQ nec- 
essarily implies (or causes) a high income, and a low IQ in- 
evitably leads to a low income. (Cause-and-effect inferences 
like this are made repeatedly throughout the book.) 
Problem 3 The title of the book refers to the normal distri- 
bution and its well-known "bell-shaped" curve. There is a 
misconception among the general public that scorcs on in- 
telligence tests (IQ) are normally distributed. In fact, most 
IQ scores have distributions that are decidedly skewed. Tra- 
ditionally, psychologists and psychometricians have trans- 
formed these scores so that the resulting numbers have a 
precise normal distribution. H&M make a special point 
to do this. Consequently, the measure of ZQ used in all the 
regression models is normalized (i.e., transformed so that 
the resulting distribution is normal), despite the fact that re- 
gression methodology does not require predictor (inde- 
pendent) variables to be normally distributed. 
Problem 4 A variable that is not used as a predictor of 
social outcome in any of the models in The Bell Curve is 
level of education. H&M purposely omit education from 
the models, arguing that IQ causes education, not the 
othcr way around. Other researchers who have exam- 
ined H&M's data report that when education is included 
as an independent variable in the model, the effect of I Q  
on the dependent variable (say, income) is diminished. 
F
o
c
u
s
 
a. Comment on each of the problems identified by the 
Carnegie Mellon University professors in their review 
of The Bell Curve. Why do each of these problems cast 
a shadow on the inferences made by the authors? 
b. Using the variables specified in the model above, de- 
scribe how you would conduct the multiple regres- 
sion analysis. (Propose a more complex model and 
describc the appropriate model tests, including a 
residual analysis.) 
SPSS Histogram for Exercise 10.43 
Std. Dev = .96 
", 
1 .SO -1.00 S O  0.00 
30 
1 .OO 
1.50 
2.00 
2.50 
3.00 
3.50 
1.00 
Regression Standardized Residual 

626 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
Key Terms 
Adjusted multiple coefficient of 
determination 582 
Base level 572 
Correlated errors 617 
Curvature 602 
Dummy variables 558,571 
Extrapolation 616 
First-order model 559 
Global F-test 583 
Higher-order term 558 
Indicator variable 571 
Least squares prediction equation 
Mean square for error 567 
Model building 559 
Multicollinearity 
615 
Multiple coefficient of 
determination 581 
Multiple regression model 558 
Outlier 603 
Parameter estimability 
614 
Quadratic model 602 
Quadratic term 602 
562 
Residual 599 
Residual analysis 599 
Robust method 609 
Second-order model 602 
Second-order term 602 
Stepwise regression 616 
Time series model 617 
Variance-stabilizing 
transformation 611 
................................................................................................................................................................................................................................................ 
Key Formulas 
E(Y) = Po + PIX, + P 2 ~ 2  
First-order model with two quantitative independent variables 559 
E(Y) = Po + PIX + P2x2 
Quadratic Model 602 
E(Y) = Po + P I X  
Model with one qualitative variable at 2 levels 571 
1 if level A 
where x = 0 if level B 
s2 = MSE = 
SSE 
Estimator of a2 for a model with k independent variables 567 
n - (k + 1) 
t = - 
Test statistic for testing H,,: P, = 0 568 
SIT, 
where tmlz depends on n - (k + 1) df 
100(1 - a)% confidence interval for P, = 0 568 
Multiple coefficient of determination 581 
~ z = l -  
Adjusted multiple coefficient of determination 582 
MS (Model) - 
- 
R2/ k 
F =  
Test statistic for testing H,: Dl = P2 = 
= P k - 
- 0 583 
MSE 
(1 - R 2 ) / [ n  - (k + I)] 
Regression residual 599 
Symbol 
Pronunciation 
Description 
.................................................................................................................................................................................................................................... 
x2 
x-squared 
Quadratic term that allows for curvature in the relationship between y and I I 
MSE 
M-S-E 
Mean square for error (estimates a2) 
P, 
beta-i 
Coefficient of x, in the model 
3, 
beta-i-hat 
Least squares estimate of p, 
I 
s of beta-i-hat 
Estimated standard error of p, 
Lez 
10.4 
3 0  = 
SSE 
10.45 
10.46 

S u p p l e m e n t a r y  E x e r c i s e s  
627 
R2 
R-squared 
Multiple coefficient of determination 
R f 
R-squared adjusted 
Adjusted mult~ple coefficient of determination 
F 
Test statistic for testing global usefulness of model 
.. 
R 
epsilon-hat 
Estimated random error, or residual 
I O ~ Y  
Log of y 
Natural logarithm of dependent variable 
Learning the Mechanics 
10.44 Suppose you fit the model 
y = PO + Plxl + P~X: + h x 2  + P 4 ~ 1 ~ 2  
+ 
to n = 25 data points with the following results: 
SSE = .41 R2 = .83 
. 
a. Is there sufficient evidence to conclude that at least 
one of the parameters PI, P2, P3, or P4 is nonzero? 
Test using a = .05. 
h. Test H,,: 
= 0 against Ha: PI < 0. Use a = .05. 
c. Test H,,: p2 = 0 against Ha: p2 > 0. Use n = .05. 
d. Test H,,: p, = 0 against Ha: p, # 0. Use n = .05. 
10.45 When a multiple regression model is used for estimat- 
ing the mean of the dependent variable and for pre- 
dicting a new value of y, which will be narrower-the 
confidence interval for the mean or the prediction 
interval for the new y value? Why? 
10.46 Suppose you have developed a regression model to 
explain the relationship between y and x,, x2, and x,. 
The ranges of the variables you observed were as fol- 
lows: 10 5 y 5 100, 5 5 x, 5 55, .5 5 x2 5 1, and 
1,000 5 x, 5 2,000. Will the error of prediction be 
smaller when you use the least squares equation to 
MINITAB Output for Exercise 10.47 
predict y when x, = 30, x2 = .6, and x3 = 1,300, or 
x, = 60, x2 = .4, and x, = 900? Why? 
10.47 Suppose you used MINITAB to fit the model 
to n = 15 data points and you obtained the printout 
shown below. 
a. What is the least squares prediction equation? 
b. Find R2 and interpret its value. 
c. Is there sufficient evidence to indicate that the 
model is useful for predicting y? Conduct an F-test 
using a = .05. 
d. Test the null hypothesis H,: P, = 0 against the al- 
ternative hypothesis H,: P, + 0. Test using a = .05. 
Draw the appropriate conclusions. 
e. Find the standard deviation of the regression 
model and interpret it. 
10.48 The first-order model E ( y )  = Po + P,x1 was fit to 
n = 19 data points. A residual plot for the model is 
shown on p. 628. Is the need for a quadratic term in the 
model evident from the residual plot? Explain. 
10.49 To model the relationship between y, a dependent 
variable, and x, an indepcndent variable, a researcher 
has taken one measurement on y at each of three dif- 
ferent x values. Drawing on his mathematical exper- 
tise, the researcher realizes that he can fit the 
The regression equation is 
Y = 90.1 - 1.84 X1 + .285 X2 
Predictor 
Coef 
StDev 
t-ratio 
P 
Constant 
90.10 
23.10 
3.90 
0.002 
XI 
-1.836 
0.367 
-5.01 
0.001 
X2 
0.285 
0.231 
1.24 
0.465 
Analysis of Variance 
SOURCE 
DF 
S S 
MS 
F 
P 
Regression 
2 
14801 
7400 
64.91 
0.001 
Error 
12 
1364 
114 
Total 
14 
16165 
second-order model 

628 
CHAPTER 
10 I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
Residual Plot for Exercise 10.48 
A 
and it will pass exactly through all three points, yield- 
ing SSE = 0. The researcher, delighted with the 
"excellent" fit of the model, eagerly sets out to use it 
to make inferences. What problems will he 
encounter in attempting to make inferences? 
Applying the Concepts 
10.50 BestS Review (June 1999) compared the mortgage 
loan portfolios for a sample of 25 lifelhealth insur- 
ance companies. The information in the table on 
page 629 is extracted from the articlc. Suppose you 
want to model the percentage of problcm mortgages 
- 
(y) of a company as a function of total mortgage loans 
(x,), percentage of invested assets (x,), percentage of 
commercial mortgages (x,), and percentage of resi- 
dential mortgages (x,). 
a. Write a first-order model for E(y). 
b. Fit the model of part a to the data and evaluate its 
overall usefulness. Use a = .05. 
c. Interpret the P estimates in the fitted model. 
d. Construct scattergrams of y versus each of the four 
independent variables in the model. Which vari- 
ables warrant inclusion in the model as second- 
order (i.e., squared) terms? 
10.51 Emergency services (EMS) personnel are con- 
stantly exposed to traumatic situations. However, 
few researchers have studied the psychological 
stress that EMS personnel may experience. The 
Journal of Consulting und Clinical Psychology 
(June 1995) reported on a study of EMS rescue 
workers who responded to the 1-880 freeway col- 
lapse during the 1989 San Francisco earthquake. 
The goal of the study was to identify the predictors 
of symptomatic distress in the EMS workers. One 
of the distress variables studied was the Global 
Symptom Index (GSI). Several models for GSI, y, 
were considered based on the following indepen- 
dent variables: 
x, = Critical Incident Exposure scale (CIE) 
x2 = Hogan Personality Inventory-Adjustment scale 
(HPI-A) 
xg = Years of experience (EXP) 
x, = Locus of Control scale (LOC) 
x5 = Social Support scale (SS) 
x6 = Dissociative Experiences scale (DES) 
x7 = Peritraumatic Dissociation Experiences 
Questionnaire, self-report (PDEQ-SR) 
a. Write a first-order model for E(y) as a function of 
~. 
, 
the first five independent variables, x,-x5. 
b. The modcl of part a, fitted to data collected f o ~  
n = 147 EMS workers, yielded the following re- 
sults: R2 = .469, F = 34.47,~-value < ,001. Inter. 
pret these results. 
C. Write a first-order model for E(y) as a function oi 
all seven independent variables, x,-x7. 
d. The model, part c, yielded R2 = .603. Interpret this 
result. 
e. The t-tests for testing the DES and PDEQ-SR vari- 
ables both yielded ap-value of ,001. Interpret these 
results. 
Since the Great Depression of the 1930s. the link 
between the suicide rate and the state of the econo- 
my has been the subject of much research. Research 
exploring this link using regression analysis was 
reported in the .lournal of Socio-Economics (Spriny. 
1992). The rcsearchers collected data from a 45-year 
period on the following variables: 
y = Suicide rate 
xl = Unemployment rate 
x2 = Percentage of females in the labor force 
xg = Divorce rate 
x4 = Logarithm of Gross National Product (GNP) 
x5 = Annual percent change in GNP 
One of the models explored by the researchers was 7 
multiple regrcssion model relating y to linear terms 111 
x, through x5. The least squares model below resulted 
(the observed significance levels of the /3 estimatr. 
are shown in parentheses beneath the estimates): 
9 = .002 + .0204xl - .0231x2 + , 0 7 6 5 ~ ~  
+ .2760x4 t .00181 
(.002) 
(.02) 
(>.lo) 
(>.lo) 
p.10 
1 
R2 = .45 
a. Interpret the value of R2. IS there sufficient i.11 
dence to indicate that the modcl is useful for prt 
dicting the suicide rate? Use a = .05. 
b. Interpret each of the coefficients in the model,and 
each of the corrcsponding significance levels. 
c. Is there sufficient evidence to indicate that the un 
employment rate is a useful predictor of the suic~d~ 
rate? Use a = .05. 
10.53 To meet the increasing demand for new software 
products, many systems development experts hait 
adopted a prototyping methodology. The effects or 

. 
f
,
 
S u p p l e m e n t a r y  Exercises 
629 
BESTINSDAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Total 
O h  
YO 
YO 
Yo 
Mortgage 
Invested 
Commercial 
Residential 
Problem 
Company 
Loan, x, 
Assets, x, 
Mortgages, x, 
Mortgages, x, 
Mortgages, y 
TIAA Group 
$18,803,163 
20.7 
100.0 
0.0 
11.4 
Metropolltan 
Insurance 
18,171,162 
13.9 
77.8 
1.6 
3.8 
Prudent~al of 
Am Group 
16,213,150 
12.9 
87.4 
2.3 
4.1 
Principal 
Mutual IA 
11,940,345 
30.3 
98.8 
1.2 
32.6 
Northwestern 
Mutual 
10,834,616 
17.8 
99.5 
0.0 
2.2 
Cigna Group 
10,181,124 
25.1 
99.8 
0.2 
11.1 
John Hancock 
Group 
8,229,523 
20.4 
82.0 
0.1 
12.2 
Aegon USA Inc. 
7,695,198 
17.7 
73.0 
24.7 
6.4 
New York Life 
7,088,003 
9.4 
92.2 
7.8 
2.4 
Nationwide 
5,328,142 
26.3 
100.0 
0.0 
7.5 
Massachusetts 
Mutual 
4,965,287 
12.2 
78.6 
21.4 
6.3 
Equ~table Group 
4,905,123 
12.7 
63.6 
0.0 
27.0 
2etna US 
Healthcare 
Group 
3,974,881 
10.5 
94.1 
5.4 
8.7 
American Express 
Financial 
3,655,292 
13.9 
100.0 
0.0 
2.1 
ING Group 
3,505,206 
16.2 
99.8 
0.2 
0.7 
American 
General 
3,359,650 
6.4 
99.8 
0.2 
2.1 
Llncoln 
Nat~onal 
3,264,860 
11.5 
99.9 
0.1 
2.2 
SunAmer~ca Inc. 
3,909,177 
15.7 
100.0 
0.0 
2.6 
Allstate 
2,987,144 
10.9 
100.0 
0.0 
2.1 
Travelers 
Insurance 
Group 
2,978,628 
10.3 
74.9 
0.1 
3.2 
GE Capital 
Corp. Group 
2,733,981 
7.5 
99.7 
0.3 
0.7 
ReliaStar 
Fmancial Corp. 
2,342,992 
16.2 
69.9 
30.0 
6.4 
General 
American Life 
2,107,592 
15.2 
99.8 
0.2 
1.3 
Statc Farm 
Group 
2,027,648 
8.6 
97.6 
2.4 
0.1 
Pacific Mutual 
L~fe 
1,945,392 
9.7 
96.4 
3.6 
6.1 
Source Best's Review, (LifeIHealth), June 1999, p. 35. 
prototyping on the system development life cycle 
(SDLC) was investigated in t h e  Journal of 
Computer Information Systems (Spring 1993). A 
survey of 500 randomly selected corporate level 
MIS managers was conducted. Three potential inde- 
pendent variables were: (1) importance of prototyp- 
ing to each phase of t h e  SDLC; (2) degree of 
support prototyping provides for the SDLC; and (3) 
degree to which prototyping replaces each phase of 
the SDLC. The table on the next page gives the pair- 
wise correlations of the three variables in the survey 
data for one particular phase of the SDLC. Use this 
information to assess the degree of multicollinearity 
in the survey data. Would you recommend using all 
three independent variables in a regression analy- 
sis? Explain. 

630 
CHAPTER 
10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
Results for Exercise 10.53 
Variable Pairs 
Correlation Coefficient, r 
Importance-Replace 
.2682 
Importance-Support 
.6991 
Replace-Support 
- .0531 
Source: Hardgrave, B. C., Doke, E. R., and Swanson, N. E. 
"Prototyping effects of the system development life cycle: An 
empirical study." Journal of Computer Information System4 
Vol. 33, No. 3, Spring 1993, p. 16 (Table 1). 
10.54 Traffic forecasters at the Minnesota Department of 
Transportation (MDOT) use regression analysis to 
estimate weekday peak-hour traffic volumes on exist- 
ing and proposed roadways. In particular, they model 
y, the peak-hour volume (typically, the volume 
between 7 and 8 A.M.), as a function of x,, the road's 
total volume for the day. For one project involving the 
redesign of a section of Interstate 494, the forecasters 
collected n = 72 observations of peak-hour traffic 
volume and 24-hour weekday traffic volume using 
electronic sensors that count vehicles. The data are 
provided in the table below. 
a. Construct a scattergram for the data, plotting peak- 
hour volume y against 24-hour volume x,. 
Note the 
isolated group of observations at the top of the 
Observation Peak-Hour 24-Hour 
Number 
Volume 
Volume 
1-35 
scattergram. Investigators discovered that all of 
these data points were collected at the intersection 
of Interstate 35W and 46th Street. (These are ob- 
servations 55-72 in the table.) While all other loca- 
tions in the sample were three-lane highways. this 
location was unique in that the highway widens to 
four lanes just north of the electronic sensor. Con- 
sequently, the forecasters decided to include a 
dummy variable to account for a difference br- 
tween the I-35W location and all other locations. 
b. Propose a first-order model for E(y) as a function 
of 24-hour volume x, and the dummy variable for 
location. 
c. Using an available statistical software package, fit 
the model of part b to the data. Interpret the result\ 
d. Conduct a residual analysis of the model, part b. 
Evaluate the assumptions of normality and con- 
stant error variance, and determine whether any 
outliers exist. 
10.55 The audience for a product's advertising can be divided 
into two segments according to the degree of exposurr. 
received as a result of the advertising. These segments 
are groups of consumers who receive high (H) or lo\\ 
(L) exposure to the advertising. A company is interest- 
ed in exploring whether its advertising effort affects its 
product's market share. Accordingly, the cornpan! 
Observation 
Peak-Hour 24-Hour 
Number 
Volume 
Volume 
1-35 
Observation 
Peak-Hour 
Number 
Volume 
24-Hour 
Volume 
1-35 
Source: John Sem. Director: Allan E. Pint, State Traffic Forecast Engineer; and James Page Sr.,Transportation Planner,Traffic and Commoditiec 
Studies Section, Minnesota Department of Transportation, St. Paul, Minnesota. 

identifies 24 sample groups of consumers who have 
been exposed to its advertising, twelve groups at each 
exposure level. Then, the company determines its 
product's market share within each group. 
a. Write a regression model that expresses the com- 
pany's market share as a function of advertising 
exposure level. Define all terms in your model, and 
list any assumptions you make about them. 
b. The data in the table below were obtained by the 
company. Fit the model you constructed in part a 
to the data. 
Market Share Within Croup 
Exposure Level 
c. Is there evidence to suggest that the firm's expect- 
ed market share differs for the two levels of ad- 
vertising exposure? Test using a = .05. 
To determine whether extra personnel are needed for 
the day, the owners of a water adventure park would 
like to find a model that would allow them to predict 
the day's attendance each morning before opening 
based on the day of the week and weather conditions. 
The model is of the form 
where 
y = Daily admission 
1 if weekend 
XI = { 
(dummy variable) 
0 otherwise 
S u p p l e m e n t a r y  E x e r c i s e s  
631 
- 
1 if sunny 
(dummy variable) 
0 
if overcast 
x3 = Predicted daily high temperature ( O F )  
These data were recorded for a random sample of 30 
days, and a regression model was fitted to the data. 
The least squares analysis produced the following 
results: 
with 
a. Interpret the estimated model coefficients. 
b. Is there sufficient evidence to conclude that this 
model is useful tor the prediction of daily atten- 
dance? Use a = .05. 
c. Is there sufficient evidence to conclude that the 
mean attendance increases on weekends? Use 
CY = .lo. 
d. Use the model to predict the attendance on a 
sunny weekday with a predicted high temperature 
of 95•‹F. 
e. Suppose the 90% prediction interval for part d is 
(645,1,245). Interpret this interval. 
10.57 Many colleges and universities develop regression 
models for predicting the GPA of incoming freshmen. 
This predicted GPA can then be used to make admis- 
sion decisions. Although most models use many inde- 
pendent variables to predict GPA, we will illustrate by 
choosing two variables: 
xl = Verbal score on college entrance examination 
(percentile) 
x2 = Mathematics score on college entrance exami- 
nation (percentile) 
The data in the table on page 632 are obtained for a 
random sample of 40 freshmen at one college. The 
SPSS printout corresponding to the model 
y = PI, + Plxl + P2x2 + E is shown below the data. 
a. Interpret the least squares estimates P, and P, in 
the context of this application. 
b. Interpret the standard deviation and the adjusted 
coefficient of determination of the regression 
model in the context of this application. 
c. Is this model useful for predicting GPA? Conduct a 
statistical test to justify your answer. 
d. Sketch the relationship between predicted GPA, 
y, and verbal score, xl, for the following mathe- 
matics scores: x2 = 60,75, and 90. 
e. The residuals from the first-order model are plot- 
ted against xl and x, and shown on p. 633. Analyze 
the two plots, and determine whether visual evi- 
dence exists that curvature (a quadratic term) for 
either x, or x, should be added to the model. 

632 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  Regression 
COLLGPA.DAT 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Verbal, 
Mathematics, 
GPA, 
X l  
x 2  
Y 
Verbal, 
Mathematics, 
GPA, 
X l  
x 2  
Y 
Verbal, 
Mathematics, 
GPA, 
X1 
x 2  
Y 
SPSS Output for Exercise 10.57 
Multiple R 
.82527 
R Square 
.68106 
Adjusted R Square 
.66382 
Standard Error 
.40228 
Analysis of Variance 
DF 
Sum of Squares 
Mean Square 
Regression 
2 
12.78595 
6.39297 
Residual 
3 7 
5.98755 
.I6183 
------------------- Variables in the Equation------------------- 
Variable 
B 
SE B 
Beta 
T S i g  T 
X1 
.02573 4.02357E-03 
.59719 
6.395 .OOOO 
X2 
.03361 4.92751E-03 
.63702 
6.822 .OOOO 
(Constant) 
-1.57054 
.49375 
-3.181 .0030 

SPSS Plots for Exercise 10.57 
RESIDUAL PLOT FOR FIRST-ORDER MODEL 
S u p p l e m e n t a r y  E x e r c i s e s  
633 
RESIDUAL PLOT FOR FIRST-ORDER MODEL 
7 5 
1 
C 
X2 
40 cases plotted. 
40 cases plotted. 

634 
CHAPTER 10 
I n t r o d u c t i o n  t o  M u l t i p l e  R e g r e s s i o n  
Real-World Case: The Condo Sales Case 
(A Case Covering Chapters 9 and 10) 
T 
his case involves an investigation of the factors that 
pool, the parking lot, etc., are shown in the accompanying 
affect the sale price of oceanside condominium / figure. There are several features of the complex that you 
units. It represcnts an extension of an analysis of i should note: 
the same data by Herman Kelting (1979). Although 1 1. The units facing south, called ocean-view, face the beach 
condo sale prices have increased dramatically over the j 
and ocean. In addition, units in building 1 have a good 
past 20 years, the relationship between these factors and 
view of the pool. Units to the rear of the building, called 
sale price remain about the same. Consequently, the data i 
a 
bay-view, face the parking lot and an area of land that 
provide valuable insight into today's condominium sales ; . 
ultimately borders a bay.The view from the upper floors 
market. 
i 
of these units is primarily of wooded, sandy terrain.The 
The sales data were obtained for a new oceanside con- i 
a 
bay is very distant and barely visible. 
dominium complex consisting of two adjacent and connect- i 
ed eight-floor buildings.   he complex contains 200 units of 
2. The only elevator in the complex is located at the east 
equal size (approximately 500 square feet each). The loca- 1 
end of building 1, as are the office and the game room. 
tions of the buildings relative to the ocean, the swimming i 
People moving to or from the higher floor units in 
Pool 
v 
w 
Ground Floor 
Distance from 
elevator-1 
2 
3 
4 
5 
6 
113 115 117 119 121 123 125 
1- 
Office 
Buildmg 2 
Building 1 
Traffic flow 
Parking 
\ 
FIGURE C5.1 
Layout of condominium complex 
* 
Three-story 
motel 
4 
a 
P 
a 
ir 
t 1 
f1 
el 
g; 
for ea 
1. Sai 
for 
2. Flc 
lev,
-
I 
I ,
i 
1
t 
t 
3. 1
F-
a 
e 
4. C 
d 
P
t 1
5. 'I 
0 
w 
IT 
ti 
C( 
sa 
SF 
5. M 
dt 
IY
ni 
'n 
mplc 
1rod1
n d p
1 bui 
le hc 
'om 
tc., a 
ste t 

R e a l - W o r l d  C a s e  
635 
building 2 would likely use the elevator and move 
through the passages to their units. Thus, units on the 
higher floors and at a greater distance from the eleva- 
tor would be less convenient; they would require 
greater effort in moving baggage, groceries, etc., and 
would be farther away from the game room, the office, 
and the swimming pool. These units also possess an ad- 
vantage: there would be the least amount of traffic 
through the hallways in the area and hence they are 
the most private. 
3. Lower-floor oceanside units are most suited to active 
people; they open onto the beach, ocean, and pool.They 
are within easy reach of the game room and they are 
easily reached from the parking area. 
4. Checking the layout of the condominium complex, you 
discover that some of the units in the center of the com- 
plex, units ending in numbers 11 and 14, have part of 
their view blocked. 
5. The condominium complex was completed at the time 
of the 1975 recession; sales were slow and the developer 
was forced to sell most of the units at auction approxi- 
mately 18 months after opening. Consequently, the auc- 
tion data are completely buyer-specified and hence 
consumer-oriented in contrast to most other real estate 
sales data which are, to a high degree, seller and broker 
specified. 
6. Many unsold units in the complex were furnished by the 
developer and rented prior to the auction. Consequent- 
ly, some of the units bid on and sold at auction had fur- 
niture, others did not. 
This condominium complex is obviously unique. For ex- 
ample, the single elevator located at one end of the complex 
produces a remarkably high level of both inconvenience 
and privacy for the people occupying units on the top floors 
in building 2. Consequently, the developer is unsure of how 
the height of the unit (floor number), distance of the unit 
from the elevator, presence or absence of an ocean view, 
etc., affect the prices of the units sold at auction. To investi- 
gate these relationships, the following data were recorded 
for each of the 106 units sold at the auction: 
1. Sale price. Measured in hundreds of dollars (adjusted 
for inflation). 
2. Floor height. The floor location of the unit; the variable 
levels are 1,2,. ... 8. 
3. Distance from elevator. This distance, measured along 
the length of the complex, is expressed in number of con- 
dominium units. An additional two units of distance was 
added to the units in building 2 to account for the walk- 
ing distance in the connecting area between the two 
buildings.Thus, the distance of unit 105 from the elevator 
would be 3, and the distance between unit 113 and the el- 
evator would be 9. The variable levels are l, 2,. .., 15. 
4. View of ocean. The presence or absence of an ocean 
view is recorded for each unit and specified with a 
dummy variable (1 if the unit possessed an ocean view 
and 0 if not). Note that units not possessing an ocean 
view would face the parking lot. 
5. End unit. We expect the partial reduction of view of end 
units on the ocean side (numbers ending in 11) to re- 
duce their sale price. The ocean view of these end units 
is partially blocked by building 2. This qualitative vari- 
able is also specified with a dummy variable (1 if the 
unit has a unit number ending in 11 and 0 if not). 
6. Furniture. The presence or absence of furniture is record- 
ed for each unit, and represented with a single dummy 
variable (1 if the unit was furnished and 0 if not). 
Your objective for this case is to build a regression 
model that accurately predicts the sale price of a condo- 
minium unit sold at auction. Prepare a professional docu- 
ment that presents the results of your analysis. Include 
graphs that demonstrate how each of the independent vari- 
ables in your model affects auction price. A layout of the 
data file is described below. 
CONDO.DAT (Number of Observations: 106) 
.................................................................................................................. 
Variable 
Column(s) 
Type 
.................................................................................................................. 
PRICE 
1-3 
QN 
FLOOR 
5 
QN 
DISTANCE 
7-8 
QN 
VIEW 
10 
QL 
ENDUNIT 
12 
QL 
FURNlSH 
14 
QL 
[Important Note: You may want to consider cross-product 
terms of the form xlxz in your model. These terms, called 
interaction terms, allow the relationship between y and one 
of the independent variables, say x,, to change as the value 
of the other independent variable, x,, changes.] 

M E T H O D S  FOR Q U A L I T Y  
I M P R O V E M E N T  
C O N T E N T S  
..................................................... 
11:l 
Quality, Processes, and Systems 
11.2 
Statistical Control 
11.3 
The Logic of Control Charts 
' 11.4 
A Control Chart for Monitoring the Mean of a Process: The 2-Chart 
11.5 
A Control Chart for Monitoring the Variation of a Process: The R-Chart 
11.6 
A Control Chart for Monitoring the Proportion of Defectives Generated by a 
Process: The p-Chart 
S T A T I S T I C S  
I ' N  
A
C
T
I
O
N
 
.......................................................................................................... 
Deming's 14 Points 
r e  W e ' r e  G o i n g  
I 
n Chapters 5-8 we described methods for making i 
n this chapter, we turn our attention to processes. 
: I 
inferences about populations based on sample data. j 
Recall from Chapter 1 that a process is a series of 
In Chapters 9-10 we focused on modeling relation- j actions or operations that transform inputs to out- 
ships between variables using regression analysis. 
j puts. This chapter describes methods for improving 
j processes and the quality of the output they produce. 

638 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Over the last two decades U.S. firms have been seriously challenged by products 
of superior quality from overseas, particularly from Japan. Japan currently pro- 
duces 25% of the cars sold in the United States. In 1989, for the first time, the top- 
selling car in the United States was made in Japan: the Honda Accord. Although 
it's an American invention, virtually all VCRs are produced in Japan. Only one 
U.S. firm still manufactures televisions; the rest are made in Japan. 
To meet this competitive challenge, more and more U.S. firms-both 
manu- 
facturing and service firms-have 
begun quality-improvement initiatives of their 
own. Many of these firms now stress total quality management (TQM), it., the 
management of quality in all phases and aspects of their business, from the design 
of their products to production, distribution, sales, and service. 
Broadly speaking, TQM is concerned with ( 1 )  finding out what it is that the 
customer wants, (2) translating those wants into a product or service design, and 
(3) producing a product or service that meets or exceeds the specifications of the 
design. In this chapter we focus primarily on the third of these three areas and its 
major problem-product 
and service variation. 
Variation is inherent in the output of all production and service processes. No 
two parts produced by a given machine are the same; no two transactions per- 
formed by a given bank teller are the same. Why is this a problem? With variation m 
output comes variation in the quality of the product or service. If this variation is un- 
acceptable to customers, sales are lost, profits suffer, and the firm may not survive. 
The existence of this ever-present variation has made statistical methods 
and statistical training vitally important to industry, In this chapter we present 
some of the tools and methods currently employed by firms worldwide to monitor 
and reduce product and service variation. 
QUALITY, PROCESSES, A N D  SYSTEMS 
Quality 
Before describing various tools and methods that can be used to monitor and im- 
prove the quality of products and services, we need to consider what is meant by tht 
term quality. Quality can be defined from several different perspectives. To the en- 
gineers and scientists who design products, quality typically refers to the amount ot 
some ingredient or attribute possessed by the product. For example, high-quality ~ c e  
cream contains a large amount of butterfat. High-quality rugs have a large number 
of knots per square inch. A high-quality shirt or blouse has 22 to 26 stitches per inch 
To managers, engineers, and workers involved in the production of a produc~ 
(or the delivery of a service), quality usually means conformance to requiremen[\ 
or the degree to which the product or service conforms to its design specification\ 
For example, in order to fit properly, the cap of a particular molded plastic bottL 
must be between 1.0000 inch and 1.0015 inches in diameter. Caps that do nor 
conform to this requirement are considered to be of inferior quality. For an el 
ample in a service operation, consider the service provided to customers in a fast- 
food restaurant. A particular restaurant has been designed to serve customerc 
within two minutes of the time their order is placed. If it takes more than two ms- 
Utes, the service does not conform to specifications and is considered to be of m- 
ferior quality. Using this production-based interpretation of quality, well-madc 
products are high quality; poorly made products are low quality. Thus, a well- 
made Rolls Royce and a well-made Chevrolet Nova are both high-quality cars. 
Although quality can be defined from either the perspective of the designen 
or the producers of a product, in the final analysis both definitions should be dt- 
rived from the needs and preferences of the user of the product or service 1 

ucts 
xo- 
top- 
ugh 
one 
mu- 
heir 
, the 
sign 
: the 
and 
F the 
d its 
;. No 
per- 
m in 
s un- 
iive. 
hods 
,sent 
nitor 
j im- 
y the 
e en- 
nt of 
.y ice 
nber 
inch. 
)duct 
ients, 
ions. 
lottle 
not 
n ex- 
fast- 
mers 
min- 
3f in- 
nade 
well- 
ars. 
gners 
e de- 
ce. A 
SECTION 
11.1 
Quality, Processes, a n d  Systems 
639 
firm that produces goods that no one wants to purchase cannot stay in business. 
We define quality accordingly. 
DEFINITION 1 1.1 
The quality of a good or service is indicated by the extent to which it satisfies 
the needs and preferences of its users. 
Consumers' needs and wants shape their perceptions of quality. Thus, to 
produce a high-quality product, it is necessary to study the needs and wants of 
consumers. This is typically one of the major functions of a firm's marketing de- 
partment. Once the consumer research has been conducted, it is necessary to 
translate consumers' desires into a product design. This design must then be trans- 
lated into a production plan and production specifications that, if properly imple- 
mented, will turn out a product with characteristics that will satisfy users' needs 
and wants. In short, consumer perceptions of quality play a role in all phases and 
aspects of a firm's operations. 
But what product characteristics are consumers looking for? What is it that 
influences users' perceptions of quality? This is the kind of knowledge that firms 
need in order to develop and deliver high-quality goods and services. The basic el- 
ements of quality are summarized in the eight dimensions shown in the box. 
1. Performance: The primary operating characteristics of the product. For 
an automobile, these would include acceleration, handling, smoothness 
of ride, gas mileage, etc. 
2. Features: The "bells and whistles" that supplement the product's basic 
functions. Examples include CD players and digital clocks on cars and 
the frequent-flyer mileage and free drinks offered by airlines. 
3. Reliability: Reflects the probability that the product will operate prop- 
erly within a given period of time. 
4. Conformance: The extent or degree to which a product meets preestab- 
lished standards. This is reflected in, for example, a pharmaceutical man- 
ufacturer's concern that the plastic bottles it orders for its drugs have 
caps that are between 1.0000 and 1.0015 inches in diameter, as specified 
in the order. 
5. Durability: The life of the product. If repair is possible, durability relat 
to the length of time a product can be used before replacement is judge 
to be preferable to continued repair, 
6. Serviceability: The ease of repair, speed of repair, and competence and 
courtesy of the repair staff. 
7. Aesthetics: How a product looks, feels, sounds, smells, or tastes. 
8. Other perceptions that influence judgments of quality: Such factors as a 
firm's reputation and the 
its products that are 
created through advertisin 
In order to design and produce products of high quality, it is necessary to 
translate the characteristics described in the box into product attributes that can 
*Garvin, D. Managing Quality. New York: Free PressIMacmillan, 1988. 

640 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
be built into the product by the manufacturer. That is, user preferences must be in- 
terpreted in terms of product variables over which the manufacturer has control. 
For example, in considering the performance characteristics of a particular brand 
of wooden pencil, users may indicate a preference for being able to use the pencil 
for longer periods between sharpenings.The manufacturer may translate this per- 
formance characteristic into one or more measurable physical characteristics such 
as wood hardness, lead hardness, and lead composition. Besides being used to 
design high-quality products, such variables are used in the process of monitoring 
and improving quality during production. 
Processes 
Much of this textbook focuses on methods for using sample data drawn from a 
population to learn about that population. In this chapter and the next, however, 
our attention is not on populations, but on processes-such 
as manufacturing 
processes-and 
the output that they generate. In general, a process is defined as 
follows: 
A process is a series of actions or operations that transforms inputs to out- 
puts. A process produces output over time. 
Processes can be organizational or personal in nature. Organizational 
processes are those associated with organizations such as businesses and govern- 
ments. Perhaps the best example is a manufacturing process, which consists of a 
series of operations, performed by people and machines, whereby inputs such as 
raw materials and parts are converted into finished products (the outputs). Ex- 
amples include automobile assembly lines, oil refineries, and steel mills. Personal 
processes are those associated with your private life. The series of steps you go 
through each morning to get ready for school or work can be thought of as a 
process. Through turning off the alarm clock, showering, dressing, eating, and 
opening the garage door, you transform yourself from a sleeping person to one 
who is ready to interact with the outside world. Figure 11.1 presents a general de- 
scription of a process and its inputs. 
INPUTS 
OUTPUTS 
It is useful to think of processes as adding value to the inputs of the process. 
Manufacturing processes, for example, are designed so that the value of the out- 
puts to potential customers exceeds the value of the inputs-otherwise 
the firm 
would have no demand for its products and would not survive. 
FIGU 
Mod€
syster 
- 
Graphical depiction of 
a process and its 
inputs 
INFORMATION--, 
METHODS - 
ENERGY 
* 
MATERIALS - 
MACHINES - 
PEOPLE 
t 
PROCESS 
Operat~on 
C 
Operation 
A 
Operation 
B 

n- 
11. 
ld 
cil 
:r- 
ch 
to 
n g 
I a 
er, 
n g 
as 
nal 
rn- 
)f a 
1 as 
EX- 
ma1 
go 
is a 
and 
one 
de- 
UTS 
cess. 
out- 
firm 
FIGURE 11.2 
Model of a basic 
system 
t: 
34 . 
'a. 
SECTION 11.1 
Q u a l i t y ,  P r o c e s s e s ,  a n d  S y s t e m s  
641 
Systems 
To understand what causes variation in process output and how processes and their 
output can be improved, we must understand the role that processes play in systems. 
DEFINITION 11.3 
A system is a collection or arrangement of interacting processes that has an 
ongoing purpose or mission. A system receives inputs from its environment, 
transforms those inputs to outputs, and delivers them to its environment. In 
order to survive, a system uses feedback (i.e., information) from its environ- 
ment to understand and adapt to changes in its environment. 
Figure 11.2 presents a model of a basic system. As an example of a system, 
consider a manufacturing company. It has a collection of interacting processes- 
marketing research, engineering, purchasing, receiving, production, sales, distri- 
bution, billing, etc. Its mission is to make money for its owners, to provide high- 
quality working conditions for its employees, and to stay in business. The firm 
receives raw materials and parts (inputs) from outside vendors which, through its 
production processes, it transforms to finished goods (outputs).The finished goods 
are distributcd to its customers. Through its marketing research, the firm "listens" 
to (receives feedback from) its customers and potential customers in order to 
change or adapt its processes and products to meet (or exceed) the needs, prefer- 
ences, and expectations of the marketplace. 
SYSTEM 
I 
I 
FEEDBACK 
A 
Since systems are collections of processes, the various types of system inputs 
are the same as those listed in Figure 11.1 for processes. System outputs are prod- 
ucts or services. These outputs may be physical objects made, assembled, repaired, 
or moved by the system; or they may be symbolical, such as information, ideas, or 
knowledge. For example, a brokerage house supplies customers with information 
about stocks and bonds and the markets where they are traded. 
Two important points about systems and the output of their processes are: 
(1) No two items produced by a process are the same; (2) Variability is an inherent 
characteristic of the output of all processes. This is illustrated in Figure 11.3. No 
two cars produced by the same assembly line are the same: No two windshields 
are the same; no two wheels are the same; no two tires are the same; no two hub- 
caps are the same. The same thing can be said for processes that deliver services. 
Consider the services offered at the teller windows of a bank to two customers 
waiting in two lines. Will they wait in line the same amount of time? Will they be 
serviced by tellers with the same degree of expertise and with the same personal- 
ities? Assuming the customers' transactions are the same, will they take the same 
amount of time to execute? The answer to all these questions is no. 
Process 
OUTPUT 
C 
Process 
B 
+ 

FIGURE 11.3 
Output variation 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Measurement 
Measure particular 
Transformation 
characteristic of each 
unit of output and plot 
1 2 3 4 5 6 7  
Time 
In general, variation in output is caused by the six factors listed in the box. 
Awareness of this ever-present process variation has made training in sta- 
tistical thinking and statistical methods highly valued by industry. By statistical 
thinking we mean the knack of recognizing variation, and exploiting it in problem 
solving and decision-making. The remainder of this chapter is devoted to statisti- 
cal tools for monitoring process variation. 
STATISTICAL CONTROL 
For the rest of this chapter we turn our attention to control charts-graphical 
de- 
vices used for monitoring process variation, for identifying when to take action to 
improve the process, and for assisting in diagnosing the causes of process varia- 
tion. Control charts, developed by Walter Shewhart of Bell Laboratories in the 
mid 1920s, are the tool of choice for continuously monitoring processes. Before we 
go into the details of control chart construction and use, however, it is important 
that you have a fuller understanding of process variation. To this end, we discuss 
patterns of variation in this section. 
As was discussed in Chapter 2, the proper graphical method for describing 
the variation of process output is a time series plot, sometimes called a run chart. 
Recall that in a time series plot the measurements of interest are plotted against 
time or are plotted in the order in which the measurements were made, as in Fig- 
ure 11.4. Whenever you face the task of analyzing data that were generated over 
time, your first reaction should be to plot them. The human eye is one of our 
most sensitive statistical instruments. Take advantage of that sensitivity by plotting 
the data and allowing your eyes to seek out patterns in the data. 
Let's begin thinking about process variation by examining the plot in Figure 
11.4 more closely. The measurements, taken from a paint manufacturing process. 
are the weights of 50 one-gallon cans of paint that were consecutively filled by the 
same filling head (nozzle). The weights were plotted in the order of production. 
Do you detect any systematic, persistent patterns in the sequence of weights? For 
example, do the weights tend to drift steadily upward or downward over time? Do 
they oscillate-high, then low, then high, then low, etc.? 
I 
F I 
Ti r
for 
gal
FIGU
An el
paint

I- 
a1 
n 
i- 
=_ 
to 
a- 
le 
,e 
nt 
SS 
'g 
rt. 
st 
g- 
er 
ur 
'I? 
re 
SS, 
he 
~n. 
or 
10 
FIGURE 11.4 
10.020 
Time series plot of fill weights 
for 50 consecutively produced 
gallon cans of paint 
SECTION 11.2 
Statistical Control 
643 
1 
10 
20 
30 
40 
50 
Order of production 
To assist your visual examination of this or any other time series plot, 
Roberts (1991) recommends enhancing the basic plot in two ways. First, compute 
(or simply estimate) the mean of the set of 50 weights and draw a horizontal line 
on the graph at the level of the mean. This centerline gives you a point of refer- 
ence in searching for patterns in the data. Second, using straight lines, connect each 
of the plotted weights in the order in which they were produced. This helps display 
the sequence of the measurements. Both enhancements are shown in Figure 11.5. 
FIGURE 11.5 
An enhanced version of the 
10.020 
paint fill time series 
1 
10 
20 
30 
40 
50 
Order of production 
Now do you see a pattern in the data? Successive points alternate up and 
down, high then low, in an oscillating sequence. In this case, the points alternate 
above and below the centerline. This pattern was caused by a valve in the paint- 
filling machine that tended to stick in a partially closed position every other time 
it operated. 

644 
CHAPTER 
11 
M e t h o d s  f o r  Quality I m p r o v e m e n t  
Other patterns of process variation are shown in Figure 11.6. We discuss sev- 
eral of them later. 
In trying to describe process variation and diagnose its causes, it helps to 
think of the sequence of measurements of the output variable (e.g., weight, length. 
number of defects) as having been generated in the following way: 
1. At any point in time, the output variable of interest can be described by a par- 
ticular probability distribution (or relative frequency distribution). This dis- 
F I G U R E  11.6 
4 
Patterns of process variation: 
Some examples 
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
.
 
2 
4 
6 
8 
10 
12 
14 
Order of product~on 
a. Uptrend 
Order of production 
c. Increasing variance 
Order of production 
e. Meandering 
Order of production 
g. Level shift 
Order of production 
b. Downtrend 
1
1
1
1
1
1
1
1
1
1
1
1
t
1
1
1
.
 
2 
4 
6 
8 
10 
12 14 
Order of production 
d. Cyclical 
2 
4 
6 
8 
10 12 14 
Order of production 
f. ShocklFreakIOutlier 

SECTION 11.2 
S t a t i s t i c a l  C o n t r o l  
645 
FIGURE 11.7 
Distributions describing one output variable at 
e 
three points in time 
tribution describes the possible values that the variable can assume and their 
likelihood of occurrence. Three such distributions are shown in Figure 11.7. 
The particular value of the output variable that is realized at a given time 
can be thought of as being generated or produced according to the distribu- 
tion described in point 1. (Alternatively, the realized value can be thought of 
as being generated by a random sample of size n = 1 from a population of 
values whose relative frequency distribution is that of point 1.) 
The distribution that describes the output variable may change over time. For 
simplicity, we characterize the changes as being of three types: the mean (i.e., 
location) of the distribution may change; the variance (i.e., shape) of the dis- 
tribution may change; or both.This is illustrated in Figure 11.8. 
In general, when the output variable's distribution changes over time, we 
refer to this as a change in the process. Thus, if the mean shifts to a higher level, we 
say that the process mean has shifted. Accordingly, we sometimes refer to the dis- 
tribution of the output variable as simply the distribution of the process, or the 
output distribution of the process. 
Let's reconsider the patterns of variation in Figure 11.6 and model them 
using this conceptualization. This is done in Figure 11.9. The uptrend of Figure 
11.6a can be characterized as resulting from a process whose mean is gradually 
shifting upward over time, as in Figure 11.9a. Gradual shifts like this are a com- 
mon phenomenon in manufacturing processes. For example, as a machine wears 
out (e.g., cutting blades dull), certain characteristics of its output gradually change. 
The pattern of increasing dispersion in Figure 11.6~ 
can be thought of as re- 
sulting from a process whose mean remains constant but whose variance in- 
creases over time, as shown in Figure 11.9~. 
This type of deterioration in a process 
may be the result of worker fatigue. At the beginning of a shift, workers- 
whether they be typists, machine operators, waiters, or managers-are 
fresh and 
pay close attention to every item that they process. But as the day wears on, con- 
centration may wane and the workers may become more and more careless or 
more easily distracted. As a result, some items receive more attention than other 
items, causing the variance of the workers' output to increase. 
The sudden shift in the level of the measurements in Figure 11.6g can be 
thought of as resulting from a process whose mean suddenly increases but whose 
variance remains constant, as shown in Figure 11.9g. This type of pattern may be 
caused by such things as a change in the quality of raw materials used in the 
process or bringing a new machine or new operator into the process. 
One thing that all these examples have in common is that the distribution of 
the output variable ch~rnges over time. In such cases, we say the process lacks sta- 
bility. We formalize the notion of stability in the following definition. 
DEFINITION 11.4 
A process whose output distribution does not change over time is said to be in 
I 
a state of statistical control, or simply in control. If it does change, it is said to 
be out of statistical control, or simply out of control. 
I

11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
FIGURE 11.8 
Types of changes in 
output variables 
C . i 
1 
2 
3 
4 
5 
Time 
a. Change in mean (i.e., location) 
1 
2 
3 
4 
5 
Time 
b. Change in variance (i.e., shape) 
I 
I 
I 
I 
I . 
1 
2 
3 
4 
5 
Time 
c. Change in mean and variance 
Figure 11.10 illustrates a sequence of output distributions for both an in-con 
trol and an out-of-control process. 
To see what the pattern of measurements looks like on a time series plo 
for a process that is in statistical control, consider Figure 11.1 1. These data ar, 
from the same paint-filling process we described earlier, but the sequence ot 
measurements was made after the faulty valve was replaced. Notice that thert 
are no discernible persistent, systematic patterns in the sequence of measuri 
ments such as those in Figures 11.5 and 11.6a-11.6e. Nor are there level sh~tt\ 
FIGU
Patte
desc
distri
FIGURI
Com pa 
out-of-c

on- 
,lot 
are 
: of 
ere 
Ire- 
ifts 
FIGURE 11.9 
Patterns of process variation 
described by changing 
distributions 
SECTION 11.2 
S t a t i s t i c a l  C o n t r o l  
647 
I 
r-x 
Order of production 
a. Uptrend 
Order of production 
c. Increasing variance 
Order of production 
e. Meandering 
I 
t 
Order of production 
g. Level shift 
FIGURE 1 1.10 
Comparison of in-control and 
out-of-control processes 
Order of production 
b. Downtrend 
I 
t 
Order of production 
d. Cyclical 
I 
C 
Order of production 
f. ShockiFreaklOutlier 
Output variable - 
Output variable - 
(e.g., weight) 
In control 
Out of control 
or transitory shocks as in Figures 11.6f-11.6g. This "patternless" behavior is 
called random behavior. The output of processes that are in statistical control 
exhibits random behavior. Thus, even the output of stable processes exhibits 
variation. 

648 
CHAPTER 
11 
M e t h o d s  f o r  Quality I m p r o v e m e n t  
FIGURE 11.11 
Time series plot of 50 
consecutive paint can fills 
collected after replacing faulty 
valve 
Order of production 
If a process is in control and remains in control, its future will be like its past. 
Accordingly, the process is predictable, in the sense that its output will stay with- 
in certain limits. This cannot be said about an out-of-control process. As illustrat- 
ed in Figure 11.12, with most out-of-control processes you have no idea what the 
future pattern of output from the process may look like." You simply do not know 
what to expect from the process. Consequently, a business that operates out-of- 
control processes runs the risk of (1) providing inferior quality products and ser- 
vices to its internal customers (people within the organization who use the outputs 
of the processes) and (2) selling inferior products and services to its external cus- 
tomers. In short, it risks losing its customers and threatens its own survival. 
FIGURE 11.1 2 
In-control processes are 
predictable; out-of-control 
processes are not 
If the process remains 
in control, its future 
Y 
,/-c 
- 
/ 
,,---= 
1s nu1 prcuuaolc 
will be like its past. 
f 
lture of an 
u~~-ul-control 
process 1 
:...-A 
J:.L-,.,. 
7 
7" 
Time ' A ,  
Measurement ----) 
Measurement - 
(e.g., weight) 
(e.g., welght) 
In control 
Out of control 
One of the fundamental goals of process management is to identify out-of- 
control processes, to take actions to bring them into statistical control, and to 
keep them in a state of statistical control.The series of activities used to attain th~s 
goal is referred to as statistical process control. 
*The output variables of in-control processes may follow approximately normal distributions, as 
in Figures 11.10 and 11.12, or they may not. But any in-control process will follow the same 
distribution over time. Do not misinterpret the use of normal distributions in many figures in this 
chapter as indicating that all in-control processes follow normal distributions. 

1st. 
th- 
at- 
.he 
ow 
of- 
er- 
uts 
us- 
I 
) 
t-of- 
d to 
this 
is - 
SECTION 
11.2 
Statistical Control 
649 
The process of monitoring and eliminating variation in order to keep a 
process in a state of statistical control or to bring a process into statistical con- 
trol is called statistical process control (SPC). 
Everything discussed in this section and the remaining sections of this chap- 
ter is concerned with statistical process control. We now continue our discussion of 
statistical control. 
The variation that is exhibited by processes that are in control is said to be 
due to common causes of variation. 
DEFINITION 1 1.6 
Common causes of variation are the methods, materials, machines, personnel, 
and environment that make up a process and the inputs required by the 
process. Common causes are thus attributable to the design of the process. 
Common causes affect all output of the process and may affect everyone 
who participates in the process. 
The total variation that is exhibited by an in-control process is due to many 
different common causes, most of which affect process output in very minor ways. 
In general, however, each common cause has the potential to affect every unit of 
output produced by the process. Examples of common causes include the lighting 
in a factory or office, the grade of raw materials required, and the extent of work- 
er training. Each of these factors can influence the variability of the process out- 
put. Poor lighting can cause workers to overlook flaws and defects that they might 
otherwise catch. Inconsistencies in raw materials can cause inconsistencies in the 
quality of the finished product.The extent of the training provided to workers can 
affect their level of expertise and, as a result, the quality of the products and ser- 
vices for which they are responsible. 
Since common causes are, in effect, designed into a process, the level of 
variation that results from common causes is viewed as being representative of the 
capability of the process. If that level is too great (i.e., if the quality of the output 
varies too much), the process must be redesigned (or modified) to eliminate one 
or more common causes of variation. Since process redesign is the responsibility 
of management, the elimination of common causes of variation is typically the re- 
sponsibility of management, not of the workers. 
Processes that are out of control exhibit variation that is the result of both 
common causes and special causes of variation. 
EFINITION 11.7 
Special causes of variation (sometimes called assignable causes) are events or 
actions that are not part of the process design. Typically, they are transient, 
fleeting events that affect only local areas or operations within the process 
(e.g., a single worker, machine, or batch of materials) for a brief period of 
time. Occasionally, however, such events may have a persistent or recurrent 
effect on the process. 
Examples of special causes of variation include a worker accidentally setting the 
controls of a machine improperly, a worker becoming ill on the job and continuing 

650 
CHAPTER 
11 
M e t h o d s  f o r  Quality I m p r o v e m e n t  
FIGURE 11.1 3 
The effects of eliminating 
causes of variation 
to work, a particular machine slipping out of adjustment, and a negligent supplier 
shipping a batch of inferior raw materials to the process. 
In the latter case, the pattern of output variation may look like Figure 11.6f. 
If instead of shipping just one bad batch the supplier continued to send inferior 
materials, the pattern of variation might look like Figure 11.6g. The output of a 
machine that is gradually slipping out of adjustment might yield a pattern like Fig- 
ure 11.6a, 11.6b, or 11.6~. 
All these patterns owe part of their variation to common 
causes and part to the noted special causes. In general, we treat any pattern of 
variation other than a random pattern as due to both common and special causes* 
Since the effects of special causes are frequently localized within a process,specid 
causes can often be diagnosed and eliminated by workers or their immediate su- 
pervisor. Occasionally, they must be dealt with by management, as in the case of a 
negligent or deceitful supplier. 
It is important to recognize that most processes are not naturally in a stated 
statistical control. As Deming (1986, p. 322) observed: "Stahility [i.e.,  isti tical 
control] is seldom a natural state. It is an achievement, the result of elinzinatrng 
special causes one by one. . . leaving only the random variation of a stable process" 
(italics added). 
Process improvement first requires the identification, diagnosis, and removal 
of special causes of variation. Removing all special causes puts the process in a 
state of statistical control. Further improvement of the process then requires the 
identification, diagnosis, and removal of common causes of variation. The effects 
on the process of the removal of special and common causes of variation are il- 
lustratid in Figure l l .13. 
I 
I 
1 
Process in control: 
The variation due to one 
or more common causes 
has been reduced or 
elimmated. 
Process in control: 
Special causes eliminated; 
only common causes 
FIGUR
present. 
I 
A contl 
i 
Time 
I 
Output variable 
t 
In the remainder of this chapter, we introduce you to some of the methods 
of statistical process control. In particular, we address how control charts helpus 
determine whether a given process is in control. 
*For certain processes (e.g., those affected by seasonal factors), a persistent systematic pattern- 
such as the cyclical pattern of Figure 11.6d-is an inherent characteristic. In these special cases. 
some analysts treat the cause of the systematic variation as a common cause.This type of analyi~z 
is beyond the scope of this text. We refer the interested reader to Alwan and Roberts (1988). 

lier 
1.6f. 
rior 
3f a 
Fig- 
non 
1 of 
es.* 
rial 
SU- 
of a 
e of 
tical 
ting 
ess " 
oval 
in a 
i the 
'ects 
.e il- 
hods 
lp us 
- 
sis 
A control chart 
SECTION 
11.3 
T h e  Logir of C o n t r o l  C h a r t s  
651 
THE LOGIC OF CONTROL CHARTS 
We use control charts to help us differentiate between process variation due to 
common causes and special causes. That is, we use them to determine whether a 
process is under statistical control (only common causes present) or not (both 
common and special causes present). Being able to differentiate means knowing 
when to take action to find and remove special causes and when to leave the 
process alone. If you take actions to remove special causes that do not exist-that 
is called tampering with the process-you 
may actually end up increasing the 
variation of the process and, thereby, hurting the quality of the output. 
In general, control charts are useful for evaluating the past performance of 
a process and for monitoring its current performance. We can use them to deter- 
mine whether a process was in control during, say, the past two weeks or to de- 
termine whether the process is remaiqing under control from hour to hour or 
minute to minute. In the latter case, our goal is the swiftest detection and re- 
moval of any special causes of variation that might arise. Keep in mind that the 
primary goal of quality-improvement activities is variance reduction. 
In this chapter we show you how to construct and use control charts for both 
quantitative and qualitative quality variables. Important quantitative variables 
include such things as weight, width, and time. An important qualitative variable is 
product status: defective or nondefective. 
An example of a control chart is shown in Figure 11.14. A control chart is sim- 
ply a time series plot of the individual measurements of a quality variable (i.e., an 
output variable), to which a centerline and two other horizontal lines called control 
limits have been added. The centerline represents the mean of the process (i.e., the 
mean of the quality variable) when the process is in a state of statistical control. The 
upper control limit and the lower control limit are positioned so that when the 
process is in control the probability of an individual value of the output variable 
falling outside the control limits is very small. Most practitioners position the control 
limits a distance of 3 standard deviations from the centerline (i.e., from the process 
mean) and refer to them as 3-sigma limits. If the process is in control and following 
a normal distribution, the probability of an individual measurement falling outside 
the control limits is .0027 (less than 3 chances in 1,000).This is shown in Figure 11.15. 
Upper control limit: 
+ 30 
Lower control limit: 
- 30 
Order of production 
As long as the individual values stay between the control limits, the process 
is considered to be under control, meaning that no special causes of variation are 
influencing the output of the process. If one or more values fall outside the control 

652 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
FIGURE 11.1 5 
Output 
The probability of observing a measurement 
var~dble 
beyond the control limits when the process is in 
A 
control 
p t 3 0  
I' 
- 30 
L 4 6 ; 6 1 6 h  
I 
Order of production 
Normal d~strlbut~on 
w~th mean= p 
and standard dev~at~on 
= o 
limits, either a rare event has occurred or the process is out of control. Following 
the rare-event approach to inference described earlier in the text, such a result a 
interpreted as evidence that the process is out of control and that actions should 
be taken to eliminate the special causes of variation that exist. 
Other evidence to indicate that the process is out of control may be present 
on the control chart. For example, if we observe any of the patterns of variation 
shown in Figure 11.6, we can conclude the process is out of control even if all the 
points fall between the control limits. In general, any persistent, systematic vana- 
tion pattern (i.e., any nonrandom pattern) is interpreted as evidence that the 
process is out of control. We discuss this in detail in the next section. 
In Chapter 6 we described how to make inferences about populations usm9 
hypothesis-testing techniques. What we do in this section should seem quite siml- 
lar. Although our focus uow is on making inferences about a process rather than a 
population, we are again testing hypotheses. In this case, we test 
H,: Process is under control 
Ha: Process is out of control 
Each time we plot a new point and see whether it falls inside or outside of t h ~  
control limits, we are running a two-sided hypothesis tcst.The control lim~ts func- 
tion as the critical values for the test. 
What we learned in Chapter 6 about the types of errors that we might make 
in running a hypothesis test holds true in using control charts as well. Any time n e  
reject the hypothesis that the process is under control and conclude that thL 
process is out of control, we run the risk of making a Type I error (rejecting thL 
null hypothesis when the null is true). Anytime we conclude (or behave as  if\\^ 
conclude) that the process is in control, we run the risk of a Type 11 error (accept. 
ing the null hypothesis when the alternative is true). There is nothing magical or 
mystical about control charts. Just as in any hypothesis test, the conclusion sug 
gested by a control chart may be wrong. 
One of the main reasons that 3-sigma control limits are used (rather than 2. 
sigma or 1-sigma limits, for example) is the small Type I error probability associate> 
with their use. The probability we noted previously of an individual measurernt.n 
falling outside the control limits-.0027-is 
a Type 1 error probability. Since we 111 
terpret a sample point that falls beyond the limits as a signal that the process isou 
of control, the use of 3-sigma limits yields very few signals that are "false alarms 
To make these ideas more concrete, we will construct and interpret a contro 
chart for the paint-filling process discussed in Section 1 1.2. Our intention is s~rnph 
FICUR 
Contro 
50 con 

J - 
- P 
- 
5 I 
10 
=I' 
wing 
dt is 
ould 
sent 
ltion 
'1 the 
aria- 
. the 
 sing 
jimi- 
\an a 
f the 
unc- 
nake 
e we 
t the 
; 
the 
if we 
:ept- 
a1 or 
sug- 
an 2- 
iated 
men t 
le in- 
s out 
ns." 
ntrol 
mply 
FIGURE 1 1 .I 6 
Control chart of fill weights for 
50 consecutive paint can fills 
SECTION 11.3 
T h e  L o g i c  o f  C o n t r o l  C h a r t s  
653 
to help you better understand the logic of control charts. Structured, step-by-step 
descriptions of how to construct control charts will be given in later sections. 
The sample measurements from the paint-filling process, presented in 
Table 11.1, were previously plotted in Figure 11.11. We use the mean and standard 
deviation of the sample, X = 9.9997 and s = .0053, to estimate the mean and the 
standard deviation of the process. Although these are estimates, in using and in- 
terpreting control charts we treat them as if they were the actual mean p and stan- 
dard deviation a of the process. This is standard practice in control charting. 
TABLE 
1 1.1 
Fill Weights of 50 Consecutively Produced Cans of Paint 
The centerline of the control chart, representing the process mean, is drawn so 
that it intersects the vertical axis at 9.9997, as shown in Figure 1 1.16.The upper con- 
trol limit is drawn at a distance of 3s = 3(.0053) = .0159 above the centerline, and the 
lower control limit is 3s = .O159 below the centerline.Then the 50 sample weights are 
ploued on the chart in the order that they were generated by the paint-filling process. 
9.980 
1 
10 
20 
30 
40 
50 
Order of production 
As can be seen in Figure 11.16, all the weight measurements fall within the 
control limits. Further, there do not appear to be any systematic nonrandom patterns 

654 
CHAPTER 
11 
M e t h o d s  f o r  Quality I m p r o v e m e n t  
in the data such as displayed in Figures 11.5 and 11.6. Accordingly, we are unable 
to conclude that the process is out of control. That is, we are unable to reject the 
null hypothesis that the process is in control. However, instead of using this formal 
hypothesis-testing language in interpreting control chart results, we prefer simply 
to say that the data suggest or indicate that the process is in control. We do this, 
however, with the full understanding that the probability of a Type I1 error is 
generally unknown in control chart applications and that we might be wrong in 
our conclusion. What we are really saying when we conclude that the process is in 
control is that the data indicate that it is better to behave as if the process were under 
control than to tamper with the process. 
We have portrayed the control chart hypothesis test as testing "in control" 
versus "out of control." Another way to look at it is this: When we compare the 
weight of an individual can of paint to the control limits, we are conducting the 
following two-tailed hypothesis test: 
where 9.9997 is the centerline of the control chart. The control limits delineate the 
two rejection regions for this test. Accordingly, with each weight measurement 
that we plot and compare to the control limits, we are testing whether the process 
mean (the mean fill weight) has changed. Thus, what the control chart is monitor- 
ing is the mean of the process. The control chart leads us to accept or reject sta- 
tistical control on the basis of whether the mean of the process has changed or 
not. This type of process instability is illustrated in the top graph of Figure 11.8.h 
the paint-filling process example, the process mean apparently has remained con- 
stant over the period in which the sample weights were collected. 
Other types of control charts-one 
of which we will describe in Section 
11.5-help 
us determine whether the variance of the process has changed, as in 
the middle and bottom graphs of Figure 11.8. 
The control chart we have just described is called an individuals chart, or an 
x-chart. The term individuals refers to the fact that the chart use5 individual mea- 
surements to monitor the process-that 
is, measurements taken from individual 
units of process output. This is in contrast to plotting sample means on the control 
chart, for example, as we do in the next section. 
Students sometimes confuse control limits with product specification limm 
We have already explained control limits, which are a function of the natural van 
ability of the process. Assuming we always use 3-sigma limits, the position of thi 
control limits is a function of the size of a, the process standard deviation. 
Specification limits are boundary points that define the acceptable values for 
an output variable (i.e., for a quality characteristic) of a particular product or 
service. They are determined by customers, management, and product de- 
signers. Specification limits may be two-sided, with upper and lower limitsor 
one-sided, with either an upper or a lower limit. 
SE<
FIGU
Coml 
and s 
I 
Process output that falls inside the specification limits is said to conform to spec- 
ifications. Otherwise it is said to be nonconforming. 
Unlike control limits, specification limits are not dependent on the procesc 
in any way. A customer of the paint-filling process may specify that all cans con- 
tain no more than 10.005 pounds of paint and no less than 9.995 pounds. These arc 

ble 
the 
nal 
his, 
r is 
g in 
s in 
lder 
rol" 
the 
the 
the 
lent 
cess 
itor- 
sta- 
d or 
8. In 
con- 
:tion 
3s in 
)r an 
nea- 
dual 
ntrol 
mits. 
vari- 
f the 
for 
or 
de- 
, or 
spec- 
ocess 
, con- 
;e are 
& 
SECTION 11.4 
A Contro 
FIGURE 11.1 7 
Com~arison of control limits 
and ipecification limits 
I Chart for Monitoring t h e  Mean of a Process: The ?-Chart 
655 
specification limits. The customer has reasons for these specifications but may 
have no idea whether the supplier's process can meet them. Both the customer's 
specification limits and the control limits of the supplier's paint-filling process 
are shown in Figure 11.17. Do you think the customer will be satisfied with the 
quality of the product received? We don't. Although some cans are within the 
specification limits, most are not, as indicated by the shaded region on the figure. 
I 
LCL 
LSL 
USL 
UCL 
Weight (pounds) 
LCL = Lower control hmlt 
UCL = Upper control hmlt 
LSL = Lower spec~ficat~on 
h i t  
USL = Uppcr spec~fication limit 
A CONTROL CHART FOR MONITORING THE 
MEAN OF A PROCESS: THE i-CHART 
In the last section we introduced you to the logic of control charts by focusing on 
a chart that reflected the variation in individual measurements of process output. 
We used the chart to determine whether the process mean had shifted. The con- 
trol chart we present in this section-the i-chart-is 
also used to detect changes in 
the process mean, but it does so by monitoring the variation in the mean of sam- 
ples that have been drawn from the process. That is, instead of plotting individual 
measurements on the control chart, in this case we plot sample means. Because of 
the additional information reflected in sample means (because each sample mean 
is calculated from n individual measurements), the F-chart is more sensitive than 
the individuals chart for detecting changes in the process mean. 
In practice, the ?-chart is rarely used alone. It is typically used in conjunc- 
tion with a chart that monitors the variation of the process, usually a chart called 
an R-chart. The 2- and R-charts are the most widely used control charts in indus- 
try. Used in concert, these charts make it possible to determine whether a process 
has gone out of control because the variation has changed or because the mean 
has changed. We present the R-chart in the next section, at the end of which we 
discuss their simultaneous use. For now, we focus only on the T-chart. Conse- 
quently, we assume throughout this section that the process variation is stable.* 
*To the instructor:Technically, the R-chart should be constructed and interpreted before the T- 
chart. However. in our experience, students more quickly grasp control chart concepts if they are 
familiar with the underlying theory. We begin with ?-charts because their underlying theory was 
presented in Chapters 4-6. 

656 
CHAPTER 
11 M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Figure 11.18 provides an example of an ?-chart. As with the individuals 
chart, the centerline represents the mean of the process and the upper and lower 
control limits are positioned a distance of 3 standard deviations from the mean. 
However, since the chart is tracking sample means rather than individual mea- 
surements, the relevant standard deviation is the standard deviation of i not u, 
the standard deviation of the output variable. 
I 
Upper control limit: p + 3oi.iii 
-. 
A 
A
A
 
, \/V 
\ 
Centerline: 1 
Lower control limit: y - 3 0 1 6  
If the process were in statistical control, the sequence of x's plotted on the 
chart would exhibit random behavior between the control limits. Only if a rare 
event occurred or if the process went out of control would a sample mean fall be- 
yond the control limits. 
To better understand the justification for having control limits that involve 
a,, consider the following. The T-chart is concerned with the variation in i which, 
as we saw in Chapter 4, is described by x's sampling distribution. But what is the 
sampling distribution of i? If the process is in control and its output variable x is 
characterized at each point in time by a normal distribution with mean p and stan- 
dard deviation u, 
the distribution of ? (i.e., x's sampling distribution) also follows 
a normal distribution with mean p at each point in time. But, as we saw in Chap- 
ter 4, its standard deviation is a, = a/&. The control limits of the ?-chart are 
determined from and interpreted with respect to the sampling distribution of i, 
not the distribution of x. These points are illustrated in Figure 11.19.* 
In order to construct an i-chart, you should have at least 20 samples of I I  
items each, where n 2 2. This will provide sufficient data to obtain reasonably 
good estimates of the mean and variance of the process. The centerline, which rep- 
resents the mean of the process, is determined as follows: 
- 
x , + & +  
+ &  
Centerline: = 
k 
where k is the number of samples of size n from which the chart is to be con- 
structed and i, is the sample mean of the ith sample. Thus ; 
is an estimator of k. 
The control limits are positioned as follows: 
3cT 
Upper control limit: + - 
6 
3a 
Lower control limit: - - 
6 
*T%e sampling distribution of x can also be approximated using the Central Limit Theorem 
(Chapter 4). That is, when the process is under control and F is to be computed from a large 
sample from the process (n 2 30), the sampling distribution will be approximately normally 
distributed with the mean p and standard deviation c r / f i .  Even for samples as small as 4 or 5. 
the sampling distribution of i will be approximately normal as long as the distribution of x is 
reasonably symmetric and roughly bell-shaped. 

SECTION 11.4 
A C o n t r o l  C h a r t  f o r  M o n i t o r i n g  t h e  M e a n  o f  a  Process: T h e  i - C h a r t  
657 
FIGURE 1 1 . 1 9  
The sampling distribution of f 
If the process is under 
control and follows a 
normal d~str~bution 
wlth 
mean p and standard 
dewation o... 
I 
I 
F also follows a normal 
dlstrlbution with mean 
p but has standard 
dev~at~on 
olfi. 
Since a, the process standard deviation, is virtually always unknown, it must be 
estimated. This can be done in several ways. One approach involves calculating the 
standard deviations for each of the k samples and averaging them. Another involves 
using the sample standard deviation s from a large sample that was generated while 
the process was believed to be in control. We employ a third approach, however-the 
one favored by industry. It has been shown to be as effective as the other approach- 
es for sample sizes of n = 10 or less, the sizes most often used in industry. 
This approach utilizes the ranges of the k samples to estimate the process 
standard deviation, a. Recall from Chapter 2 that the range, R, of a sample is the 
difference between the maximum and minimum measurements in the sample. It 
can be shown that dividing the mean of the k ranges,R, by the constant d2, obtains 
an unbiased estimator for a. [For details, see Ryan (1 989).] The estimator, denot- 
ed by 5, is calculated as follows: 
where R, is the range of the ith sample and d2 is a constant that depends on the 
sample size. Values of d, for samples of size n = 2 to n = 25 can be found in Ap- 
pendix B, Table XV. 
Substituting 5 for (T in the formulas for the upper control limit (UCL) and 
the lower control limit (LCL), we get 
Notice that ( R / d , ) / f i  is an estimator of a,. The calculation of these limits can be 
simplified by creating the constant 

658 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Then the control limits can be expressed as 
UCL: T + A,R 
LCL: T - A ~ R  
where the values for A2 for samples of size n = 2 to n = 25 can be found in Ap- 
pendix B, Table XV. 
The degree of sensitivity of the i-chart to changes in the process mean de- 
pends on two decisions that must be made in constructing the chart. 
In order to quickly detect process change, we try to choose samples in such a 
way that the change in the process mean occurs between samples, not within sam- 
ples (i.e., not during the period when a sample is being drawn). In this way, every 
measurement in the sample before the change will be unaffected by the change 
and every measurement in the sample following the change will be affected.The 
result is that the i computed from the latter sample should be substantially dif- 
ferent from that of the former sample-a 
signal that something has happened to 
the process mean. 
DEFINITION 11.9 
Samples whose size and frequency have been designed to make it likely that 
process changes will occur between, rather than within, the samples are re- 
ferred to as rational subgroups. 
The samples (rational subgroups) should 
a manner that: 
1. Gives the maximum chance for the measurements in each sample to be 
similar (i.e., to be affected by the same sources of variation). 
2. Gives the maximum chance for the samples to differ (i.e., be affected by 
at least one different source of variation). 
The following example illustrates the concept of rational subgrouping. An 
operations manager suspects that the quality of the output in a manufacturine 
process may differ from shift to shift because of the preponderance of ne~l! 
hired workers on the night shift.The manager wants to be able to detect such dif- 
ferences quickly, using an i-chart. Following the rational subgrouping strategy, the 
control chart should be constructed with samples that are drawn within each shift. 

SECTION 11.4 
A Control Chart for Monitoring t h e  Mean of a Process: The ?-Chart 
659 
P- 
le- 
S 
h a 
im- 
erY 
nge 
The 
dif- 
j to 
at 
e- 
be 
by 
:. An 
lring 
ewly 
I dif- 
y, the 
shift. 
None of the samples should span shifts.That is, no sample should contain, say, the 
last three items produced by shift 1 and the first two items produced by shift 2. In 
this way, the measurements in each sample would be similar, but the x's would re- 
flect differences between shifts. 
The secret to designing an effective i-chart is to anticipate the types of spe- 
cial causes of variation that might affect the process mean. Then purposeful ratio- 
nal subgrouping can be employed to construct a chart that is sensitive to the 
anticipated cause or causes of variation. 
The preceding discussion and example focused primarily on the timing or fre- 
quency of samples. Concerning the size of the samples, practitioners typically work 
with samples of size n = 4 to n = 10 consecutively produced items. Using small 
samples of consecutively produced items helps to ensure that the measurements in 
each sample will be similar (i.e., affected by the same causes of variation). 
rt: A Summary 
1. Using a rational subgrouping strategy, collect at least 20 samples (sub- 
groups), each of size n 2 2. 
2. Calculate the mean and range for each sample. 
3. Calculate - the mean of the sample means, 7, and the mean of the sample 
ranges, R : 
- 
= 
x l + & + . . . + ; ' C k  
- R, + R, + 
+ Rk 
X = 
k 
R = 
k 
where 
k = number of samples (is., subgroups) 
- 
x, = sample mean for the ith sample 
R, = range of the ith sample 
4. 
Plot the c 
Upper control limit: + A,Z 
Lower control limit: 7 - A,E 
where A2 is a constant that depends on n. Its values are given in Appen- 
dix B,Table XV, for samples of size n = 2 to n = 25. 
5. 
Plot the k sample means on the control chart in the order that the sam- 
ples were produced by t 
When interpreting a control chart, it is convenient to think of the chart as 
consisting of six zones, as shown in Figure 11.20. Each zone is 1 standard deviation 
wide. The two zones within 1 standard deviation of the centerline are called C 
zones; the regions between 1 and 2 standard deviations from the centerline are 
called B zones; and the regions between 2 and 3 standard deviations from the cen- 
terline are called A zones. The box describes how to construct the zone bound- 
aries for an ?-chart. 

660 
CHAPTER 
1 1  
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
The zones of a control chart 
1 
Zone A 
UCL 
I 
Zone B 
Zone C 
Centerline 
Zone C 
Zone B 
Zone A 
LCL 
I 
. 
Order of production 
Constructing Zone Boundaries for an 2-Cha 
The zone boundaries can be constructed in either o 
wing ways: 
1. Using the 3-sigma control limits: 
2 
Upper A-B boundary: + -(A2R) 
3 
L 
Lower A-B boundary: - - ( A ~ R )  
3 
1 
Upper B-C boundary: ? + -(A,R) 
3 
1 
Lower B-C boundary: - -(A2R) 
3 
2. 
Using the estimated standard deviation of X, ( w d 2 ) / f i :  
1 
Practitioners use six simple rules that are based on these zones to help deter- 
mine when a process is out of control.The six rules are summarized in Figure 11.21. 
They are referred to as pattern-analysis rules. 

SECTION 11.4 
A Control Chart for M o n i t o r i n g  the Mean of a Process: The i - C h a r t  
661 
UCL 
A 
I 
UCL 
A 
Centerline pbF Centerline 
A 
LCL 
Rule 1: One point beyond Zone A 
UCL I 
A 
LCL 
Rule 3: Six points in a row steadily increasing or decreasing 
UCL l 
Centerline 
A 
f 
LCL 
Rule 5: Two out of three points in a row in Zone A or beyond 
A 
LCL 
Rule 2: Nine points in a row in Zone C or beyond 
UCL 
A 
A 
LCL 
Rule 4: Fourteen points in a row alternating up and down 
UCL 1 
Centerline 
A 
LCL 
Rule 6: Four out of five points in a row in Zone B or beyond 
Rules 1,2,5, and 6 should be applied separately to the upper and lower halves of 
the control chart. Rules 3 and 4 should be applied to the whole chart. 
FIGURE 11.21 
Pattern-analysis rules for detecting the presence of special causes of variation 
Rule 1 is the familiar point-beyond-the-control-limit rule that we have men- 
tioned several times. The other rules all help to determine when the process is out 
of control even though all the plotted points fall within the control limits. That is, the 
other rules help to identify nonrandom patterns of variation that have not yet bro- 
ken through the control limits (or may never break through). 

662 
CHAPTER 
11 
M e t h o d s  f o r  Quality I m p r o v e m e n t  
All the patterns shown in Figure 11.21 are rare events under the assumption 
that the process is under control. To see this, let's assume that the process is under 
control and follows a normal distribution. We can then easily work out the prob- 
ability that an individual point will fall in any given zone. (We dealt with this type 
of problem in Chapter 4.) Just focusing on one side of the centerline, you can 
show that the probability of a point falling beyond Zone A is .00135, in Zone A is 
.02135, in Zone B is .1360, and in Zone C is .3413. Of course, the same probabili- 
ties apply to both sides of the centerline. 
From these probabilities we can determine the likelihood of various patterns 
of points. For example, let's evaluate Rule 1. The probability of observing a point 
outside the control limits (i.e., above the upper control limit or below the lower 
control limit) is ,00135 + .00135 = .0027. This is clearly a rare event. 
As another example, Rule 5 indicates that the observation of two out of 
three points in a row in Zone A or beyond is a rare event. Is it? The probability of 
being in Zone A or beyond is .00135 + .02135 = .0227. We can use the binomial 
distribution (Chapter 4) to find the probability of observing 2 out of 3 points in or 
beyond Zone A. The binomial probability P(X = 2) when n = 3 and p = ,0227 is 
.0015. Again, this is clearly a rare event. 
In general, when the process is in control and normally distributed, the prob- 
ability of any one of these rules incorrectly signaling the presence of special caus- 
es of variation is less than .005, or 5 chances in 1,000. If all of the first four rules are 
applied, the overall probability of a false signal is about .01. If all six of the rules 
are applied, the overall probability of a false signal rises to .02, or 2 chances in 100. 
These three probabilities can be thought of as Type I error probabilities. Each in- 
dicates the probability of incorrectly rejecting the null hypothesis that the process 
is in a state of statistical control. 
Explanation of the possible causes of these nonrandom patterns is beyond 
the scope of this text. We refer the interested reader to AT&T's Statistical Qualr- 
ty Control Handbook (1956). 
We use these rules again in the next section when we interpret the R-chart 
pretin 
1. The process is out of control if one or more sample means fall beyond 
the control limits or if any of the other five patterns of variation of 
Figure 11.21 are observed. Such signals are an indication that one or 
more special causes of variation are affecting the process mean. We must 
identify and eliminate them to bring the process into control. 
2. 
The process is treated as being in control if none of the previously noted 
out-of-control signals are observed. Processes that are in control should 
not be tampered with. However, if the level of variation is unacceptably 
high, common causes of variation should be identified and eliminated. 
Assumption: The variation of the process is stable. (If it were not, the control 
limits of the ?-chart would be meaningless, since they are a function of the 
process variation.The R-chart, presented in the next section, is used to inves- 
tigate this assumption.) 
F 
In theory, the centerline and control limits should be developed usin! 
samples that were collected during a period in which the process was in control 
Otherwise, they will not be representative of the variation of the process (or, In 

1 
r 
c, " 
n 
S 
I- 
IS 
lt 
'r 
, 
f , 
f 
*1 
)r 
is 
3- 
S- 
re 
',S 
0. 
n- 
SS 
ld 
li- 
2. 
I 
I 
I 
n g 
01. 
, in 
J 
SECTION 11.4 
A Control Chart for Monitoring the Mean of a Process: The i-Chart 
663 
the present case, the variation of 2) when the process is in control. However, we 
will not know whether the process is in control until after we have constructed 
a control chart. Consequently, when a control chart is first constructed, the 
centerline and control limits are treated as trial values. If the chart indicates 
that the process was in control during the period when the sample data were 
collected, then the centerline and control limits become "official" (i.e., no 
longer treated as trial values). It is then appropriate to extend the control lim- 
its and the centerline to the right and to use the chart to monitor future process 
output. 
However, if in applying the pattern-analysis rules of Figure 11.21 it is de- 
termined that the process was out of control while the sample data were being 
collected, the trial values (i.e., the trial chart) should, in general, not be used to 
monitor the process. The points on the control chart that indicate that the process 
is out of control should be investigated to sec if any special causes of variation 
can be identified. If special causes of variation are found, (1) they should be 
eliminated, (2) any points on the chart determined to have been influenced by 
the special causes-whether 
inside or outside the control limits-should 
be dis- 
carded, and (3) new trial centerline and control limits should be calculated from 
the remaining data. However, the new trial limits may still indicate that the 
process is out of control. If so, repeat these three steps until all points fall within 
the control limits. 
If special causes cannot be found and eliminated, the severity of the out-of- 
control indications should be evaluated and a judgment made as to whether 
(1) the out-of-control points should be discarded anyway and new trial limits 
constructed, (2) the original trial limits are good enough to be made official, or 
(3) new sample data should be collected to construct new trial limits. 
* 
*a" " S*" 
"
>
"
*
m
P
m
-
-
<
 
Let's return to the paint-filling process described in Sections 11.2 and 11.3. 
Suppose instead of sampling 50 consecutive gallons of paint from the filling 
process to develop a control chart, it was decided to sample five consecutive cans 
once each hour for the next 25 hours.The sample data are presented in Table 11.2. 
This sampling strategy (rational subgrouping) was selected because several times 
a month the filling head in question becomes clogged. When that happens, the 
head dispenses less and less paint over the course of the day. However, the pattern 
of decrease is so irregular that minute-to-minute or even half-hour-to-half-hour 
changes are difficult to detect. 
a. Explain the logic behind the rational subgrouping strategy that was used. 
b. Construct an i-chart for the process using the data in Table 11.2. 
c. What does the chart suggest about the stability of the filling process 
(whether the process is in or out of statistical control)? 
d. Should the control limits be used to monitor future process output? 
S o I u t i o n 
a. The samples are far enough apart in time to detect hour-to-hour shifts or 
changes in the mean amount of paint dispensed, but the individual mea- 
surements that make up each sample are close enough together in time to 
. 
ensure that the process has changed little, if at all, during the time the indi- 
vidual measurements were made. Overall, the rational subgrouping 
employed affords the opportunity for process changes to occur between 
samples and therefore show up on the control chart as differences between 
the sample means. 

1 
M e t h o d s  f o r  Quality I m p r o v e m e n t  
TABLE 
11.2 
Twenty-Five Samples of Size 5 from the Paint-Filling Process 
Sample 
. . . . . . . . . . . . . . . . . . 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
Measurements 
. . . . . . . . . 
Mean 
. . . . . . . . . . . . . . . . . 
9.99995 
9.99704 
10.00082 
9.99800 
9.99649 
10.00141 
10.00358 
10.00116 
10.00339 
9.99594 
9.99874 
9.99882 
10.00080 
10.00016 
9.99822 
10.00033 
10.00127 
10.00130 
9.99798 
10.00212 
9.99764 
10.00272 
10.00009 
10.00146 
10.00015 
Range 
. . . . . . . . . . . . . . . . 
,0078 
,0092 
.0137 
.0111 
.0195 
,0042 
,0143 
.OM 
.0134 
,0039 
.0090 
.0062 
,0167 
,0076 
.0124 
,0137 
.0061 
.0051 
,0127 
,0112 
.0101 
,0058 
,0094 
.0134 
,0077 
b. Twenty-five samples (k = 25 subgroups), each containing n = 5 cans of 
paint, were collected from the process. The first step after collecting the 
data is to calculate the 25 sample means and sample ranges needed to con- 
struct the 2-chart. The mean and range of the first sample are 
All 25 means and ranges are displayed in Table 11.2. 
Next, we calculate the mean of the sample means and the mean of the sam- 
ple ranges: 
The centerline of the chart is positioned at 
= 9.9999. To determine the 
control limits, we need the constant A2, which can be found in Table XV 01 
Appendix B. For n = 5, A, = S77. Then, 
UCL: Z + A,R = 9.9999 + .577(.01028) = 10.0058 
LCL: T - A,R = 9.9999 - .577(.01028) = 9.9940 

I 
I 
of 
he 
In- 
m- 
the 
7 of 
SECTION 11.4 
A C o n t r o l  Chart f o r  M o n i t o r i n g  t h e  Mean of a  Process: The i - C h a r t  
665 
After positioning the control limits on the chart, we plot the 25 sample 
means in the order of sampling and connect the points with straight lines. 
The resulting trial T-chart is shown in Figure 1 1.22. 
FIGURE 11.22 
i-Chart for the paint-filling 
process 
10.0100 
10.0050 
UCL = 10.0058 
10.0000 
9.9950 
L .  
LCL = 9.9940 
1 
5 
10 
15 
20 
25 
Sample number 
c. To check the stability of the process, we use the six pattern-analysis rules for 
detecting special causes of variation, which were presented in Figure 11.21. 
To apply most of these rules requires identifying the A, B, and C zones of the 
control chart. These are indicated in Figure 11.22. We describe how they 
were constructed below. 
The boundary between the A and B zones is 2 standard deviations from the 
centerline, and the boundary between the B and C zones is 1 standard devi- 
ation from the centerline. Thus, using A,R and the 3-sigma limits previously 
calculated, we locate the A, B, and C zones above the centerline: 
A-B boundary = + $(A,R) = 9.9999 + +(.577)(.01028) = 10.0039 
B-C boundary = + 3(A2R) = 9.9999 + 5(.577)(.01028) = 10.0019 
Similarly, the zones below the centerline are located: 
A-B boundary = x - $(A,R) = 9.9959 
B-C boundary = x - ~ ( A , R )  = 9.9979 
A careful comparison of the six pattern-analysis rules with the sequence of 
sample means yields no out-of-control signals. All points are inside the con- 
trol limits and there appear to be no nonrandom patterns within the control 
limits. That is, we can find no evidence of a shift in the process mean. Ac- 
cordingly, we conclude that the process is in control. 

666 
 CHAPTER^^ 
M e t h o d s  
d. 
f o r  Q u a l i t y  I m p r o v e m e n t  
Since the process was found to be in control during the period in which the 
samples were drawn, the trial control limits constructed in part b can be con- 
sidered official. They should be extended to the right and used to monitor 
future process output. 
* 
- 
Ten new samples of size n = 5 were drawn from the paint-filling process oi'rhe 
previous example. The sample data, including sample means and ranges, are 
shown in Table 11.3. Investigate whether the process remained in control during 
, 
the period in which the new sample data were collected. 
TABLE 
11.3 
Ten Additional Samples of Size 5 from the Paint-Filling Process 
Sample 
Measurements 
Mean 
Range 
. . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . 
26 
10.0019 
9.9981 
9.9952 
9.9976 
9.9999 
9.99841 
.0067 
27 
10.0041 
9.9982 
10.0028 
10.0040 
9.9971 
10.00125 
.0070 
28 
9.9999 
9.9974 
10.0078 
9.9971 
9.9923 
9.99890 
.0155 
29 
9.9982 
10.0002 
9.9916 
10.0040 
9.9916 
9.99713 
.0124 
30 
9.9933 
9.9963 
9.9955 
9.9993 
9.9905 
9.99498 
.0088 
31 
9.9915 
9.9984 
10.0053 
9.9888 
9.9876 
9.99433 
.0177 
32 
9.9912 
9.9970 
9.9961 
9.9879 
9.9970 
9.99382 
,0091 
33 
9.9942 
9.9960 
9.9975 
10.0019 
9.9912 
9.99614 
.0107 
34 
9.9949 
9.9967 
9.9936 
9.9941 
10.0071 
9.99726 
.0135 
35 
9.9943 
9.9969 
9.9937 
9.9912 
10.0053 
9.99626 
,0141 
S o I u t i o n We begin by simply extending the control limits, centerline, and zone boundaries 
of the control chart in Figure 11.22 to the right. Next, beginning with sample 
number 26, we plot the 10 new sample means on the control chart and connect 
them with straight lines. This extended version of the control chart is shown in 
Figure 11.23. 
Extended :-chart for paint- 
filling process 
10.0100 
UCL = 10.0058 
A 
A 
LCL = 9.9940 
Now that the control chart has been prepared, we apply the six pattern- 
analysis rules for detecting special causes of variation (Figure 11.21) to the new se- 
quence of sample means. No points fall outside the control limits, but we notice six 
points in a row that steadily decrease (samples 27-32). Rule 3 says that if we ob- 

SECTION 11.4 
A C o n t r o l  C h a r t  f o r  M o n i t o r i n g  t h e  M e a n  of a Process: T h e  ;-Chart 
667 
serve six points in a row steadily increasing or decreasing, that is an indication of 
the presence of special causes of variation. 
Notice that if you apply the rules from left to right along the sequence of sam- 
ple means, the decreasing pattern also triggers signals from Rules 5 (samples 29-31) 
and 6 (samples 28-32). 
These signals lead us to conclude that the process has gone out of control. 
Apparently, the filling head began to clog about the time that either sample 26 or 
27 was drawn from the process. As a result, the mean of the process (the mean fill 
weight dispensed by the process) began to decline. 
* 
Learning the Mechanics 
- 
X 
11.1 What is a control chart? Describe its use. 
UCL 
11.2 Explain why rational subgrouping ~hould be used in 
constructing control charts. 
11.3 When a control chart is first constructed, why are the 
centerline and control limits treated as trial values? 
11.4 Which process parameter is an i-chart used to monitor? 
11.5 Even if all the points on an i-chart Pall between the 
control limits, the process may be out of control. 
Exnlain. 
- - 
1 
5 
10 
15 
20 
25 
11.6 What must be true about the variation of a process 
before an i-chart is used to monitor the mean of the 
Sample number 
process? Why? 
11.10 Twenty-five samples of size n = 5 were collected to 
11.7 Use the six pattern-analysis rules described in Fig- 
construct an i-chart. The accompanying sample means 
ure 11.21 to determine whether the process being 
and ranges were calculated for thcse data. 
monitored with the accompanying i-chart is out of sta- 
tistical control. 
LMll-IO.DAT 
......................................................................................................... 
- 
x 
Sample 
2 
R 
Sample 
Z 
R 
................................................................................................ 
UCL 
1  
80.2 
7.2 
14 
83.1 
10.2 
A 
LCL 
Sample number 
11.8 Is the process for which the i-chart at right was con- 
structcd affected by only special causes of variation, 
only common causes of variation, or both? Explain. 
11.9 Use Table XV in Appendix B to find the value of A, 
for each of the following sample sizes. 
a . n = 3  
b . n = 1 0  
c. n = 2 2  
a. Calculate the mean of the sample means, x, and the 
mcan of the sample ranges, R. 
b. Calculate and plot the centerline and the upper and 
lower control limits for the 2-chart. 
c. Calculate and plot the A, B, and C zone boundaries 
of thc i-chart. 

668 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
d. Plot the 25 sample means on the T-chart and use 
d. Calculate and plot the A, B, and C zone boundaries 
the six pattern-analysis rules to determine whether 
of the F-chart. 
the process is under statistical control. 
e. Plot the 20 sample means on the i-chart. Is the 
11.11 The data in the next table were collected for the pur- 
process in control? Justify your answer. 
pose of constructing an i-chart. 
Applying the Concepts 
LM11-11.DAT 
11.12 The central processing unit (CPU) of a microcomputer 
............................................................................................ " 
Sample 
Measurements 
.............. 
.................................................................... 
1 
19.4 
19.7 
20.6 
21.2 
2 
18.7 
18.4 
21.2 
20.7 
3 
20.2 
18.8 
22.6 
20.1 
4 
19.6 
21.2 
18.7 
19.4 
5 
20.4 
20.9 
22.3 
18.6 
6 
17.3 
22.3 
20.3 
19.7 
7 
21.8 
17.6 
22.8 
23.1 
8 
20.9 
17.4 
19.5 
20.7 
9 
18.1 
18.3 
20.6 
20.4 
10 
22.6 
21.4 
18.5 
19.7 
11 
22.7 
21.2 
21.5 
19.5 
12 
20.1 
20.6 
21.0 
20.2 
13 
19.7 
18.6 
21.2 
19.1 
14 
18.6 
21.7 
17.7 
18.3 
15 
18.2 
20.4 
19.8 
19.2 
16 
18.9 
20.7 
23.2 
20.0 
17 
20.5 
19.7 
21.4 
17.8 
18 
21 .O 
18.7 
19.9 
21.2 
19 
20.5 
19.6 
19.8 
21.8 
20 
20.6 
16.9 
22.4 
19.7 
is a computer chip containing millions of transistors. 
Connecting the transistors are slender circuit paths 
only .5 to .85 micron wide.To understand how narrow 
these paths are, consider that a micron is a millionth of 
a meter, and a human hair is 70 microns wide 
(Compute, 1992). A manufacturer of CPU chips knows 
that if the circuit paths are not S . 8 5  micron wide, a 
variety of problems will arise in the chips' perfor- 
mance. The manufacturer sampled four CPU chips six 
times a day (every 90 minutes from 8:00 A.M. until 
4:30 P.M.) for five consecutive days and measured the 
circuit path widths. These data and MINITAB were 
used to construct the i-chart shown below. 
a. Assuming that R = ,3162, calculate the chart's 
upper and lower control limits, the upper and lower 
A-B boundaries, and the upper and lower B-C 
boundaries. 
b. What does the chart suggest about the stability of 
the process used to put circuit paths on the CPU 
chip? Justify your answer. 
c. Should the control limits be used to monitor future 
process output? Explain. 
a. Calculate x and R for each sample. 
11.13 A machine at K-Company fills boxes with bran flakes 
b. Calculate and R. 
cereal.The target weight for the filled boxes is 24 ounces 
c. Calculate and plot the centerline and the upper and 
The company would like to use an 2-chart to monitor 
lower control limits for the T-chart. 
the performance of the machine.To develop the control 
MINITAB Output for Exercise 11.1 2 
X - b a r  C h a r t  for Pathwdth 
P 
Sample Number 
SAS 

:s 
ie 
er 
rs. 
hs 
IW 
of 
-l e 
NS 
. a 
)r- 
;ix 
ti1 
he 
re 
t's 
rer 
-C 
of ' u 
ire 
ces 
:es. 
tor 
rol 
SECTION 11.4 
A C o n t r o l  C h a r t  for M o n i t o r i n g  t h e  M e a n  of a Process: T h e  i - C h a r t  
669 
chart, the company decides to sample and weigh five 
b. What does the chart suggest about the stability of 
consecutive boxes of cereal five times each day (at 8:00 
the filling process (whether the process is in or out of 
and 11:00 A.M. and 2:00,5:00, and 8:00 P.M.) for twenty 
statistical control)? Justify your answer. 
consecutive days. The data are presented in the table, 
c. Should the control limits be used to monitor future 
along with a SAS printout with summary statistics. 
process output? Explain. 
a. Construct an i-chart from the given data. 
d. Two shifts of workers run the filling operation. Each 
day the second shift takes over at 3:00 P.M. Will the 
rational subgrouping strategy used by K-Company 
CEREALBAT 
facilitate or hinder the identification of process vari- 
......................................................................................................... 
ation caused by differences in the two shifts? 
Weight of Cereal Boxes (ounces) 
Explain. 
.......................................................... 
24.13 
11.14 A precision parts manufacturer produces bolts for use 
SAS Output for Exercise 11.1 3 
----------------------------------------- 
I 
I 
WEIGHT 
I 
in military aircraft. Ideally, the bolts should be 37 cen- 
timeters in length.The company sampled four consec- 
utively produced bolts each hour on the hour for 
25 consecutive hours and measured them using a com- 
puterized precision instrument.The data are presented 
below. A MINITAB printout with descriptive statis- 
tics for each hour is also shown on page 670. 
BOLTS.DAT 
.................................................................................................. 
Hour 
Bolt Lengths (centimeters) 
.......... 
............................................................................. 
a. What process is the manufacturer interested in 
monitoring? 
b. Construct an 2-chart from the data. 
c. Does the chart suggest that special causes of varia- 
tion are present? Justify your answer. 
d. Provide an example of a special cause of variation 
that could potentially affect this process. Do the 
same for a common cause of variation. 

670 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
MINITAB Output for Exercise 11 .I 4 
Variable HOUR 
LENGTH 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
2 0 
2 1 
2 2 
2 3 
2 4 
2 5 
Variable HOUR 
LENGTH 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
2 0 
2 1 
2 2 
2 3 
2 4 
2 5 
N 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
4 
MIN 
36.880 
36.850 
36.990 
36.980 
36.810 
36.890 
36.940 
36.910 
36.900 
36.870 
36.880 
36.900 
36.910 
37.040 
36.890 
36.900 
36.940 
36.910 
36.880 
36.900 
36.960 
36.930 
36.950 
36.900 
36.900 
Descriptive Statistics 
MEAN 
36.973 
36.957 
37.067 
37.065 
36.947 
36.998 
37.000 
37.005 
37.028 
36.970 
37.020 
36.982 
37.070 
37.072 
36.993 
36.955 
37.038 
37.010 
36.955 
37.035 
36.995 
37.023 
37.003 
36.995 
37.010 
MAX 
37.080 
37.040 
37.160 
37.200 
37.100 
37.130 
37.070 
37.120 
37.170 
37.110 
37.100 
37.060 
37.220 
37.100 
37.040 
36.990 
37.140 
37.110 
37.010 
37.150 
37.050 
37.120 
37.040 
37.070 
37.100 
MEDIAN 
36.965 
36.970 
37.060 
37.040 
36.940 
36.985 
36.995 
36.995 
37.020 
36.950 
37.050 
36.985 
37.075 
37.075 
37.020 
36.965 
37.035 
37.010 
36.965 
37.045 
36.985 
37.020 
37.010 
37.005 
37.020 
Q1 
36.885 
36.878 
36.995 
36.990 
36.835 
36.907 
36.953 
36.927 
36.927 
36.880 
36.918 
36.920 
36.940 
37.047 
36.920 
36.913 
36.947 
36.927 
36.895 
36.925 
36.960 
36.935 
36.962 
36.922 
TR MEAN 
36.973 
36.957 
37.067 
37.065 
36.947 
36.998 
37.000 
37.005 
37.028 
36.970 
37.020 
36.982 
37.070 
37.072 
36.993 
36.955 
37.038 
37.010 
36.955 
37.035 
36.995 
37.023 
37.003 
36.995 
37.010 
Q3 
37.067 
37.025 
37.147 
37.165 
37.068 
37.100 
37.053 
37.092 
37 -135 
37.080 
37.092 
37.043 
37.195 
37.095 
37.038 
36.987 
37.130 
37.092 
37.005 
37.135 
37.040 
37.113 
37.035 
37.058 
37.083 
STDEV 
0.098 
0.079 
0.081 
0.096 
0.121 
0.101 
0.054 
0.087 
0.111 
0.106 
0.098 
0.066 
0.132 
0.025 
0.069 
0.040 
0.097 
0.085 
0.058 
0.109 
0.044 
0.096 
0.039 
0.071 
0.083 
SE MEAN 
0.049 
0.040 
0.040 
0.048 
0.061 
0.051 
0.027 
0.044 
0.055 
0.053 
0.049 
0.033 
0.066 
0.013 
0.035 
0.020 
0.049 
0.043 
0.029 
0.055 
0.022 
0.048 
0.019 
0.036 
0.041 
Smtrce
Saddle

SECTION 11.4 
A C o n t r o l  Chart for M o n i t o r i n g  the Mean of a Process: The x-Chart 
671 
e. Should the control limits be used to monitor future 
process output? Explain. 
11.15 In their text, Q~~antitative 
Analysis of Management 
(1997), B. Render (Rollins College) and R. M. Stair 
(Florida State University), present the case of the 
Bayfield Mud Company. Bayfield supplies boxcars of 
50-pound bags of mud treating agents to the Wet-Land 
Drilling Company. Mud treating agents are used to 
control the pH and other chemical properties of the 
cone during oil drilling operations. Wet-Land has com- 
plained to Bayfield that its most recent shipment of 
bag3 were underweight by about 5%. (The use of 
underweight hags may result in poor chemical control 
during dr~lling, which may hurt drilling efficiency 
resulting in serious economic consequences.) Afraid 
of losing a long-time customer, Bayfield immediately 
began investigating their production process. 
Management suspected that the causes of the problem 
were the recently added third shift and the fact that all 
three shifts were under pressure to increase output to 
meet increasing demand for the product. Their quality 
control staff began randomly sampling and weighing 
six bags of output each hour. The average weight of 
each sample over the last three days is recorded in the 
table along with the weight of the heaviest and lightest 
bag in each sample. 
a. Construct an i-chart for these data. 
b. Is the process under statistical control? 
c. Does it appear that managemcnt's suspicion about 
the third shift is correct? Explain? 
Average Weight 
Time 
(pounds) 
Lightest 
Heaviest 
600 A.M. 
49.6 
48.7 
7:OO 
50.2 
49.1 
8:OO 
50.6 
49.6 
9:OO 
50.8 
50.2 
10:OO 
49.9 
49.2 
11:OO 
50.3 
48.6 
12 noon 
48.6 
46.2 
1:OO P.M 
49.0 
46.4 
2:OO 
49.0 
46.0 
3:OO 
49.8 
48.2 
400 
50.3 
49.2 
5:OO 
51.4 
50.0 
600 
51.6 
49.2 
7:00 
51.8 
50.0 
8:00 
51.0 
48.6 
9:OO 
50.5 
49.4 
1O:OO 
49.2 
46.1 
11:OO 
49.0 
46.3 
12 midnight 
48.4 
45.4 
l:00 A.M. 
47.6 
44.3 
2:OO 
47.4 
44.1 
3:OO 
48.2 
45.2 
400 
48.0 
45.5 
5:OO 
48.4 
47.1 
6:OO 
48.6 
47.4 
7:OO 
50.0 
49.2 
8:00 
49.8 
49.0 
9:OO 
50.3 
49.4 
1O:OO 
50.2 
49.6 
11:OO 
50.0 
49.0 
12 noon 
50.0 
48.8 
1:OO P.M 
50.1 
49.4 
2:OO 
49.7 
48.6 
3:OO 
48.4 
47.2 
4:OO 
47.2 
45.3 
5:OO 
46.8 
44.1 
Average Weight 
Time 
(pounds) 
Lightest 
Heaviest 
" ........................................................................................................... 
6:00 P.M 
7:OO 
8:OO 
9:OO 
1O:OO 
1 1 :oo 
12 midnight 
1:00 A.M. 
2:oo 
3:OO 
4:00 
5:oo 
6:OO 
7:OO 
8:00 
9:00 
1o:oo 
11:oo 
12 noon 
1:00 P.M. 
2:oo 
3:OO 
4:OO 
500 
6:OO 
7:OO 
8:OO 
9:OO 
1o:oo 
11:oo 
12 midnight 
1:00 A.M. 
2:oo 
3:OO 
4:OO 
5:OO 
Sorrrce: Kinard, J., Western Carolina University, as reported in Render, B., and Stair, Jr., R., Quantitative Analysis for Management, 6th ed. Upper 
Saddle River, N.J.: Prentice-Hall, 1997. 

672 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
11.16 University of Waterloo (Canada) statistician S.H. 
ll.17 A pharmaceutical company produces vials filled with 
Stciner applied control chart methodology to the man- 
ufacturing of a horseshoe-shaped metal fastener called a 
robotics clamp (Applied Statistics, Vol. 47,1998). Users 
of the clamp were concerned with the width of the gap 
between the two ends of the fastener. Their preferred 
target width is .054 inches. An optical measuring device 
was used to measure the gap width of the fastener 
during the manufacturing process. The manufacturer 
sampled five finished clamps every fifteen minutes 
throughout its 16-hour daily production schedule and 
optically measured the gap. Data for four consecutive 
hours of production are presented in the table below. 
Time 
........... 
00: 15 
00:30 
00:45 
01 :00 
01:15 
01:30 
01:45 
02:oo 
02:15 
02:30 
02:45 
03:OO 
03:15 
03:30 
03:45 
04:OO 
Gap Width (thousandths of an inch) 
morphine (Communications in Statktics, Vol. 27, 1998). 
Most of the time the filling process remains stable, but 
once in a while the mean value shifts off the target of 52.00 
grams. To monitor the process, one sample of size 3 is 
drawn from the process every 27 minutes. Measurements 
for 20 consecutive samples are shown in the table. 
Source: Adapted from Steiner, Stefan, H.. "Grouped Data 
Exponentially Weighted Moving Average Control Charts," 
Applied Statistics-JoitnzrrI 
of the Royal Statistical Society, Vol. 
47, Part 2,1998, pp. 203-216. 
a. Construct an ?-chart from these data. 
b. Apply the pattern-analysis rules to the control chart. 
Docs your analysis suggest that special causes of vari- 
ation are present in the clamp manulacturing process? 
Which of the six rules led you to your conclusion? 
c. Should the control limits be used to monitor future 
process output'? Explain. 
Sample 
Amount of Morphine in Vials (grams) 
....................................................................... 
.............. 
-~ - 
Source: Adapted from Costa. A.F.B., "VSSI X charts with 
Sampling at Fixed Times," Communications in Smristics- 
Theory und Methods, Vol. 27, No. 11 (1998). pp. 2853-2869. 
a. Construct an i-chart for these data. 
b. What does the i-chart suggest about the stability 
of the process? 
c. Is the process influenced by both common and spe- 
cial causes of variation? Explain. 
d. Should the control limits and centerline of the i- 
chart of part a be used to monitor future output of 
the morphine filling process? Explain. 
A CONTROL CHART FOR MONITORING THE 
VARIATION OF A PROCESS: THE R-CHART 
Recall from Section 11.2 that a process may be out of statistical control because its 
mean or variance or both are changing over time (see Figure 1 1.8). The T-chart of the 
previous section is used to detect changes in the process mean.The control chart we 
present in this section-the 
R-chart-is 
used to detect changes in process variation. 
The primary difference between the i-chart and the R-chart is that instead 
of plotting sample means and monitoring their variation, we plot and monitor 
the variation of sample ranges. Changes in the behavior of the sample range signal 
changes in the variation of the process. 

with 
998). 
, but 
52.00 
: 3 is 
lents 
..... 
1s) 
..... 
bility 
spe- 
;e its 
f the 
-t we 
tion. 
tead 
litor 
gnal 
SECTION 
11.5 
A Control Chart for Monitoring the Variation of a Process: The R-Chart 
673 
We could also monitor process variation by plotting sample standard devia- 
tions. That is, we could calculate s for each sample (i.e., each subgroup) and plot 
them on a control chart known as an s-chart. In this chapter, however, we focus on 
just the R-chart because (1) when using samples of size 9 or less, the s-chart and 
the R-chart reflect about the same information, and (2) the R-chart is used much 
more widely by practitioners than is the 5-chart (primarily because the sample 
range is easier to calculate and interpret than the sample standard deviation). For 
more information about s-charts, see the references at the end of the book. 
The underlying logic and basic form of the R-chart are similar to the ?-chart. 
In monitoring 2, we use the standard deviation of i to develop 3-sigma control 
limits. Now, since we want to be able to determine when R takes on unusually 
large or small values, we use the standard deviation of R, or a,, to construct 3-sigma 
control limits. The centerline of the i-chart represents the process mean p or, 
equivalently, the mean of the sampling distribution of i, 
pr. Similarly, the center- 
line of the R-chart represents p,, the mean of the sampling distribution of R. 
These points are illustrated in the R-chart of Figure 11.24. 
FIGURE 11.24 
R 
R-Chart 
Upper control limit: W R  + 3oR 
Centerline: p~ 
Lower control limit: hR - 3oR 
w 
2 
4 
6 
8 
10 12 14 
Sample number 
As with the ?-chart, you should have at least 20 samples of n items each 
(n r 2) to construct an R-chart. This will provide sufficient data to obtain reason- 
ably good estimates of p~ and u,. Rational subgrouping is again used for deter- 
mining sample size and frequency of sampling. 
The centerline of the R-chart is positioned as follows: 
Rl + R2 + 
+ Rk 
Centerline: R = 
k 
where k is the number of samples of size n and R, is the range of the ith sample. R 
is an estimate of pp 
In order to construct the control limits, we need an estimator of a,. The es- 
timator recommended by Montgomery (1991) and Ryan (1989) is 
where d2 and d, are constants whose values depend on the sample size, n. Values for 
d2 and d3 for samples of size n = 2 to n = 25 are given in Table XV of Appendix B. 
The control limits are positioned as follows: 
Upper control limit: R + 3GR = R + 3d3 (3 
- 
Lower control limit: R - 3GR = R + 3d3 

674 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Notice that R appears twice in each control limit. Accordingly, we can simplify the 
calculation of these limits by factoring out R: 
where 
The values for 4 and D, have been tabulated for samples of size n = 2 to n = 25 
and can be found in Appendix B, Table XV. 
For samples of size n = 2 through n = 6, D3 is negative, and the lower con- 
trol limit falls below zero. Since the sample range cannot take on negative values, 
such a control limit is meaningless. Thus, when n 5 6 the R-chart contains only 
one control limit, the upper control limit. 
Although D, is actually negative for n 5 6, the values reported in Table XV 
in Appendix B are all zeros. This has been done to discourage the inappropriate 
construction of negative lower control limits. If the lower control limit is calculat- 
ed using 4 = 0, you obtain D,R = 0. This should be interpreted as indicating that 
the R-chart has no lower 3-sigma control limit. 
structing an R-Chart: A Summary 
sing a rational subgrouping strategy, collect at least 20 samples (i.e., 
bgroups), each of size n r 2. 
2. 
Calculate the range of each sample. 
. C 
the mean of the 
- 
R = 
k = The number of samples (i.e., subgroups) 
R, = The range of the ith sample 
lot the centerline and control li 
Centerline: 
Upper control limit: ED, 
Lower control limit: ED3 
where 4 and D, are constants that depend on n. Their values can be 
found in Appendix B,Table XV. When n 5 6 , 4  = 0, indicating that the 
control chart does not have a lower control limit. 
lot the k sample ranges on the control chart in the order that the sam- 
ples were produced by the process. 

the 
: 25 
:on- 
ues, 
mly 
xv 
iate 
dat- 
that 
-- , 
be 
he 
m- 
-- 
SECTION 11.5 
A Control Chart for Monitoring the Variation of a Process: The R-Chart 
675 
- 
We interpret the completed R-chart in basically the same way as we did the 
x-chart. We look for indications that the process is out of control. Those indica- 
tions include points that fall outside the control limits as well as any nonrandom 
patterns of variation that appear between the control limits. To help spot nonran- 
dom behavior, we include the A, B, and C zones (described in the previous sec- 
tion) on the R-chart. The next box describes how to construct the zone boundaries 
for the R-chart. It requires only Rules 1 through 4 of Figure 11.21, because Rules 
5 and 6 are based on the assumption that the statistic plotted on the control chart 
follows a normal (or nearly normal) distribution, whereas R's distribution is 
skewed to the right." 
K: 
- 
. . 
h4 . cp .,t. 4".;4'"wrta 
Constructing Zone Boundaries for an R-Chart 
The simplest method of construction uses the estimator of the standard devi- 
ation of R, which is ii, = d3(%/d2): 
Lower A-B boundary: - 2d3 - (3 
Upper B-C boundary:% f d3 (3 
Lower B-C boundary - d3 - (3 
terpreting an R-Chart 
1. The process is out of control if one or more sample ranges fall beyond 
the control limits (Rule 1) or if any of the three patterns of variation de- 
scribed by Rules 2,3, and 4 (Figure 11.21) are observed. Such signals in- 
dicate that one or more special causes of variation are influencing the 
variation of the process. These causes should be identified and eliminat- 
ed to bring the process into control. 
2 
2. 
The process is treated as being in control if none of the noted out-of- 
As with the ?-chart, the centerline and control limits should be developed 
using samples that were collected during a period in which the process was in con- 
trol. Accordingly, when an R-chart is first constructed, the centerline and the control 
- 
limits are treated as triul values (see Section 11.4) and are modified, if necessary, be- 
fore being extended to the right and used to monitor future process output. 
*Some authors (e.g., Kane, 1989) apply all six pattern-analysis rules as long as n 2 4. 

676 
CHAPTER 
11 
M e t h o d s  for Quality I m p r o v e m e n t  
Refer to Example 11.1. 
S o l u t i o n  
FIGURE 11.25 
R-chart for the paint-filling 
process 
a. 
Construct an R-chart for the paint-filling process. 
b. 
What does the chart indicate about the stability of the filling process during 
the time when the data were collected? 
c. Is it appropriate to use the control limits constructed in part a to monitor 
future process output? 
a. The first step after collecting the data is to calculate the range of each 
sample. For the first sample the range is 
All 25 sample ranges appear in Table 11.2. 
Next, calculate the mean of the ranges: 
The centerline of the chart is positioned at R = .01028. To determine the 
control limits, we need the constants D3 and D,, which can be found in 
Table XV of Appendix B. For n = 5, D3 = 0 and D4 = 2.115. Since 4 = 0, 
the lower 3-sigma control limit is negative and is not included on the chart. 
The upper control limit is calculated as follows: 
UCL: RD, = (.01028)(2.115) = .02174 
After positioning the upper control limit on the chart, we plot the 25 sample 
ranges in the order of sampling and connect the points with straight lines. 
The resulting trial R-chart is shown in Figure 11.25. 
UCL = ,02174 
A 
I 
Sample number 
b. To facilitate our examination of the R-chart, we plot the four zone bound- 
aries. Recall that in general the A-B boundaries are positioned 2 standard 
deviations from the centerline and the B-C boundaries are 1 standard devi- 

- 
ing 
itor 
ach 
the 
d in 
= 0, 
nart. 
nple 
ines. 
mnd- 
~ d a r d  
devi- 
SECTION 11.5 
A Control Chart for Monitoring the Variation of a Process: The R-Chart 
677 
ation from the centerline. In the case of the R-chart, we use the estimated 
standard deviation of R, G ,  = d3(E/d2), and calculate the boundaries: 
Upper A-B boundary: R + 2d3 (z) 
= .01792 
Lower A-B boundary: R - 2d3 (E) = .(I0264 
Upper B-C boundary: R + d3 (z) 
= .0141O 
Lower B-C boundary: R - d3 (%) 
= .00646 
where (from Table XV of Appendix B) for n = 5, d2 = 2.326 and d3 = 364. 
Notice in Figure 11.25 that the lower A zone is slightly narrower than the 
upper A zone. This occurs because the lower 3-sigma control limit (the usual 
lower boundary of the lower A zone) is negative. 
All the plotted R values fall below the upper control 1imit.This is one indi- 
cation that the process is under control (i.e., is stable). However, we must 
also look for patterns of points that would be unlikely to occur if the process 
were in control. To assist us with this process, we use pattern-analysis 
rules 1-4 (Figure 11.21). None of the rules signal the presence of special 
causes of variation. Accordingly, we conclude that it is reasonable to treat 
the process-in 
particular, the variation of the process-as 
being under con- 
trol during the period in question. Apparently, no significant special causes 
of variation are influencing the variation of the process. 
c. Yes. Since the variation of the process appears to be in control during the 
period when the sample data were collected, the control limits appropriate- 
ly characterize the variation in R that would be expected when the process is 
in a state of statistical control. 
In practice, the %-chart and the R-chart are not used in isolation, as our pre- 
sentation so far might suggest. Rather, they are used together to monitor the 
mean (i.e., the location) of the process and the variation of the process simulta- 
neously. In fact, many practitioners plot them on the same piece of paper. 
One important reason for dealing with them as a unit is that the control lim- 
its of the y-chart are a function of R. That is, the control limits depend on the vari- 
ation of the process. (Recall that the control limits are i * A,R.) Thus, if the 
process variation is out of control the control limits of the i-chart have little 
meaning. This is because when the process variation is changing (as in the bottom 
two graphs of Figure 11.8), any single estimate of the variation (such as R or s) is 
not representative of the process. Accordingly, the appropriate procedure is to 
first construct and then interpret the R-chart. If it indicates that the process vari- 
ation is in control, then it makes sense to construct and interpret the i-chart. 
Figure 1 1.26 is reprinted from Kaoru Ishikawa's classic text on quality-im- 
provement methods, Guide to Quality Control (1986). It illustrates how particular 
changes in a process over time may be reflected in y- and R-charts. At the top of 
the figure, running across the page, is a series of probability distributions A, B, and 
C that describe the process (i.e., the output variable) at different points in time. In 
practice, we never have this information. For this example, however, Ishikawa 

678 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
FIGURE 11.26 
Changes in production process 
Combined 2- and R-chart 
-- 
Source: Reprinted from Guide to 
Quality Control, by Kaoru Ishikawa, 
O 1986 by Asian Productivity 
Organization, with permission of 
the aublisher Asian Productivity 
organization. Distributed in ~ b r t h  
I 
Distribution A 
1 
Dist. B 
I 
Dist. C 
I 
America by Qual~ty Resources, New 
York, NY. 
52 
- 50 
X 
48 
1 
LCL = 47.67 
1 
I 
I 
SEC
'm
Lear
11.18
11.19
11.20
11.21
worked with a known process (i.e., with its given probabilistic characterization) to 
illustrate how sample data from a known process might behave. 
The control limits for both charts were constructed from k = 25 samples of 
size n = 5. These data were generated by Distribution A. The 25 sample means 
and ranges were plotted on the 2- and R-charts, respectively. Since the distribution 
did not change over this period of time, it follows from the definition of statistical 
control that the process was under control. If you did not know this-as 
would be 
the case in practice-what 
would you conclude from looking at the control charts? 
(Remember, always interpret the R-chart before the F-chart.) Both charts indicate 
that the process is under control. Accordingly, the control limits are made official 
and can be used to monitor future output, as is done next. 
Toward the middle of the figure, the process changes. The mean shifts to a 
higher level. Now the output variable is described by Distribution B. The process 
is out of control. Ten new samples of size 5 are sampled from the process. Since the 
variation of the process has not changed, the R-chart should indicate that the 
variation remains stable. This is, in fact, the case. All points fall below the upper 
control limit. As we would hope, it is the T-chart that react 'o the change in the 
mean of the process. 
Then the process changes again (Distribution C). Ths 
,me the mean shifts 
back to its original position, but the variation of the process mcreases. The process 
is still out of control but this time for a different reason. Checking the R-chart 
first, we see that it has reacted as we would hope. It has detected the increase in 
the variation. Given this R-chart finding, the control limits of the x-chart become 
inappropriate (as described before) and we would not use them. Notice, however. 
how the sample means react to the increased variation in the process. This in- 
creased variation in T is consistent with what we know about the variance of i. It 
is directly proportional to the variance of the process, a; = a2/n. 
Keep in mind that what Ishikawa did in this example is exactly the opposite 
of what we do in practice. In practice we use sample data and control charts to 
make inferences about changes in unknown process distributions. Here, for the 

I t o  
; of 
3ns 
ion 
cal 
b e  
ts? 
ate 
:ial 
o a 
ess 
the 
the 
Per 
the 
ifts 
ess 
art 
: in 
me 
rer, 
in- 
'. It 
site 
i t o  
the 
SECTION 11.5 
A Control C h a r t  for Monitoring t h e  Variation of a Process: The R-Chart 
679 
purpose of helping you to understand and interpret control charts, known process 
distributions were changed to see what would happen to the control charts. 
Learning the Mechanics 
11.18 What characteristic of a process is an R-chart designed 
to monitor? 
11.19 In practice, i- and R-charts are used together to mon- 
itor a process. However, the R-chart should be inter- 
preted before the F-chart. Why? 
11.20 Use Table XV in Appendix B to find the values of 4 
and D, for each of the following sample sizes. 
a . n = 4  b . n = 1 2  c . n = 2 4  
11.21 Construct and interpret an R-chart for the data in 
Exercise 11.10 (p. 667). 
a. Calculate and plot the upper control limit and, if 
appropriate, the lower control limit. 
b. Calculate and plot the A, B, and C zone boundaries 
on the R-chart. 
G Plot the sample ranges on the R-chart and use pat- 
tern-analysis rules 1 4  of Figure 11.21 to determine 
whether the process is under statistical control. 
11.22 Construct and interpret an R-chart for the data in 
Exercise 11.21 (p. 668). 
a. Calculate and plot the upper control limit and, if 
appropriate, the lower control limit. 
b. Calculate and plot the A, B, and C zone boundaries 
c. Plot the sample ranges on the R-chart and deter- 
mine whether the process is in control. 
11.23 Construct and interpret an R-chart and an x-chart 
from the sample data shown below. Remember to 
interpret the R-chart before the ?-chart. 
Applying t h e  Concepts 
11.24 Refer to Exercise 11.12 (p. 668), where the desired cir- 
cuit path widths were .5 to .85 micron. The manufac- 
turer sampled four CPU chips six times a day (every 
90 minutes from 8:00 A.M. until 4:30 P.M.) for five con- 
secutive days.The path widths were measured and used 
to construct the MINITAB R-chart shown on page 680. 
a. Calculate the chart's upper and lower control limits. 
b. What does the R-chart suggest about the presence 
of special causes of variation during the time when 
the data were collected? 
c. Should the control limit(s) be used to monitor fu- 
ture process output? Explain. 
d. How many different R values are plotted on the 
control chart? Notice how most of the R values fall 
along three horizontal lines. What could cause such 
a pattern? 
on the R-chart: 
LMll 23.DAT 
Sample 
Measurements 
. . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . ........ . . . 

CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
MINITAB Output for Exercise 11.24 
R Chart for Pathwdth 
Sample Number 
11.25 A soft-drink bottling company is interested in moni- 
toring the amount of cola injected into 16-ounce bottles 
by a particular filling head.The process is entirely auto- 
mated and operates 24 hours a day. At 6 A.M. and 6 P.M. 
each day, a new dispenser of carbon dioxide capable of 
producing 20,000 gallons of cola is hooked up to the 
filling machine. In order to monitor the process using 
control charts, the company decided to sample five con- 
Sample 
Measurements 
.................................................................................................. 
secutive bottles of cola each hour beginning at 6:15 A.M. 
(i.e., 6:15 A.M.,7:15 A.M., 8:15 A.M., etc.).The data forthe 
first day are given in the table at left. An SPSS descrip- 
tive statistics printout is also provided on page 681. 
a. Will the rational subgrouping strategy that was used 
enable the company to detect variation in fill 
caused by differences in the carbon dioxide dis- 
pensers? Explain. 
b. Construct an R-chart from the data. 
c. What does the R-chart indicate about the stabilit! 
of the filling process during the time when the data 
were collected? Justify your answer. 
d. Should the control limit(s) be used to monitor fu- 
ture process output'? Explain. 
e. Given your answer to part c, should an ?-chart be 
constructed from the given data? Explain. 
11.26 In an effort to reduce customer dissatisfaction with 
delays in replacing lost automated teller machine 
(ATM) cards, some retail banks monitor the time 
required to replace a lost ATM card. Called replacement 
cycle time, it is the elapsed time from when the customer 
contacts the bank about the loss until the customer 
receives a new card (Mnnagement Science, Sept. 1999). 
A particular retail bank monitors replacement cycle 
time for the first five requests each week for replace- 
ment cards. Variation in cycle times is monitored usin2 
an R-chart. Data for 20 weeks is presented on page 681. 
a. Construct an R-chart for these data. 
b. What does the R-chart suggest about the presence 
of special causes of variation in the process? 
c. Should the control limits of your R-chart be used to 
monitor future replacement cycle times? Explain. 
d. Given your conclusion in part b and the pattern dis- 
played on the R-chart, discuss the possible future 
impact on the performance of the bank. 

..M. 
the 
rip- 
sed 
fill 
dis- 
ility 
lata 
fu- 
with 
line 
ime 
nent 
lmer 
mer 
j99). 
:ycle 
ace- 
ence 
:d to 
iin. 
I dis- 
lture 
I 
SECTION 11.5 
A C o n t r o l  C h a r t  f o r  M o n i t o r i n g  the V a r i a t i o n  of a P r o c e s s :  T h e  R-Chart 
681 
Week 
SPSS Output for Exercise 11.25 
Replacement Cycle Time (in days) 
I 
L 
11.27 The Journal of Quality Technology (July 1998) pub- 
lished an article examining the effects of the precision 
of measurement on the R-chart.The authors presented 
SAMPLE 
Variable 
Mean 
Range 
Minimum 
Maximum 
N 
1.00 
COLA 
16.006 
.05 
15.98 
16.03 
5 
2.00 
COLA 
16.000 
.06 
15.97 
16.03 
5 
3.00 
COLA 
16.008 
.06 
15.98 
16.04 
5 
4.00 
COLA 
16.002 
.05 
15.98 
16.03 
5 
5.00 
COLA 
16.008 
.07 
15.97 
16.04 
5 
6.00 
COLA 
16.008 
-07 
15.97 
16.04 
5 
7.00 
COLA 
16.004 
.09 
15.96 
16.05 
5 
8.00 
COLA 
16.010 
.08 
15.97 
16.05 
5 
9.00 
COLA 
15.992 
.08 
15.95 
16.03 
5 
10.00 
COLA 
16.012 
.ll 
15.95 
16.06 
5 
11.00 
COLA 
16.004 
-14 
15.93 
16.07 
5 
12.00 
COLA 
16.018 
.14 
15.94 
16.08 
5 
13.00 
COLA 
15.990 
.05 
15.96 
16.01 
5 
14.00 
COLA 
15.998 
-04 
15.98 
16.02 
5 
15.00 
COLA 
16.002 
.05 
15.98 
16.03 
5 
16.00 
COLA 
16.004 
.05 
15.97 
16.02 
5 
17.00 
COLA 
16.014 
.06 
15.99 
16.05 
5 
18.00 
COLA 
16.008 
.06 
15.98 
16.04 
5 
19.00 
COLA 
15.984 
.05 
15.96 
16.01 
5 
20.00 
COLA 
16.006 
.08 
15.96 
16.04 
5 
21.00 
COLA 
16.014 
.08 
15.97 
16.05 
5 
22.00 
COLA 
16.010 
.12 
15.95 
16.07 
5 
23.00 
COLA 
16.020 
.12 
15.95 
16.07 
5 
24.00 
COLA 
15.992 
.15 
15.93 
16.08 
5 
data from a British nutrition company that fills con- 
tainers labeled "500 grams" with a powdered dietary 
supplement. Once every 15 minutes, five containers 
are sampled from the filling process and the fill weight 
is measured. The table at the top of page 682 lists the 
measurements for 25 consecutive samples made with a 
scale that is accurate to .5 gram, followed by a table 
that gives measurements for the same samples made 
with a scale that is accurate t o  only 2.5 grams. 
Throughout the time period over which the samples 
were drawn, it is known that the filling process was in 
statistical control with mean 500 grams and standard 
deviation I gram. 
a. Construct an R-chart for the data that is accurate 
to .5 gram. Is the process under statistical control? 
Explain. 
b. Given your answer to part a, is it appropriate to 
construct an ?-chart for the data? Explain. 
c. Construct an R-chart for the data that is accurate to 
only 2.5 grams. What does it suggest about the sta- 
bility of the filling process? 
d. Based on your answers to parts a and c, discuss the 
importance of the accuracy of measurement instru- 
ments in evaluating the stability of production 
processes. 
11.28 Refer to Exercise 11.15 (p. 671), in which the Bayfield 
Mud Company was concerned with discovering why 

682 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
FILLWTLDAT 
................................................................................................................................. - 
Sample 
Fill Weights Accurate to .5 Cram 
Range 
................................................................................................................. 
Sample 
Fill Weights Accurate to 2.5 Grams 
Range 
................................................................................................................. 
Source: Adapted from Tricker, A., Coates, E. and Okell, E., "The Effects on the 
R-chart of Precision of Measurement," Journal of Quality Technology,Vol. 30, 
No. 3, July 1998. pp. 232-239. 

SECTION 11.6 
A Control Chart for Monitoring the Proportion of Defectives Generated by a Process 
683 
their filling operation was producing underfilled bags 
of mud. 
a. Construct an R-chart for the filling process. 
b. According to the R-chart, is the process under sta- 
tistical control? Explain. 
c. Does the R-chart provide any evidence concerning 
the cause of Bayfield's underfilling problem'? 
Explain. 
12.29 Refer to Exercise 12.16 (p. 712). in which a robotics 
clamp manufacturer was concerned about gap width. 
a. Construct an R-chart for the gap width. 
b. Which parameter of the manufacturing process 
does your R-chart provide information about? 
c. What does the R-chart suggest about the presence 
of special causes of variation during the time when 
the data were collected? 
A CONTROL CHART FOR MONITORING THE 
PROPORTION OF DEFECTIVES GENERATED BY A 
PROCESS: THE p-CHART 
Among the dozens of different control charts that have been proposed by re- 
searchers and practitioners, the Z- 
and R-charts are by far the most popular for use 
in monitoring quantitative output variables such as time, length, and weight. 
Among the charts developed for use with qualitative output variables, the chart we 
introduce in this section is the most popular. Called thep-chart, it is used when the 
output variable is categorical (i.e., measured on a nominal scale). With the p- 
chart, the  proportion,^, of units produced by the process that belong to a partic- 
ular category (e.g., defective or nondefective; successful or unsuccessful; early, 
on-time, or late) can be monitored. 
The p-chart is typically used to monitor the proportion of defective units 
produced by a process (i.e., the proportion of units that do not conform to speci- 
fication). This proportion is used to characterize a process in the same sense that 
the mean and variance are used to characterize a process when the output vari- 
able is quantitative. Examples of process proportions that are monitored in in- 
dustry include the proportion of billing errors made by credit card companies; the 
proportion of nonfunctional semiconductor chip produced; and the proportion of 
checks that a bank's magnetic ink character-recognition system is unable to read. 
As is the case for the mean and variance, the process proportion can change 
over time. For example, it can drift upward or downward or jump to a new level. 
In such cases, the process is out of control. As long as the process proportion re- 
mains constant, the process is in a state of statistical control. 
As with the other control charts presented in this chapter, the p-chart has a 
centerline and control limits that are determined from sample data. After k sam- 
ples of size n are drawn from the process, each unit is classified (e.g., defective or 
nondefective), the proportion of defective units in each sample-@- 
is calculated, 
the centerline and control limits are determined using this information, and the 
sample proportions are plotted on the p-chart. It is the variation in the p's over 
time that we monitor and interpret. Changes in the behavior of the @'s signal 
changes in the process proportion,p. 
The p-chart is based on the assumption that the number of defectives ob- 
served in each sample is a binomial random variable. What we have called the 
process proportion is really the binomial probability, p. (We discussed binomial 
random variables in Chapter 4.) When the process is in a state of statistical con- 
trol, p remains constant over time. Variation in @-as displayed on a p-chart-is 
used to judge whether p is stable. 
To determine the centerline and control limits for the p-chart we need to 
know $3 sampling distribution. We described the sampling distribution of @ in 
Section 5.4. Recall that 

684 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Number of defective items in the sample 
x 
p = 
- 
- - 
Number of items in the sample 
n 
and that for large samples p is approximately normally distributed. Thus, if p 
were known the centerline would be p and the 3-sigma control limits would be 
p k 3 d
m
.
 
However, since p is unknown, it must be estimated from the 
sample data. The appropriate estimator is p, the overall proportion of defective 
units in the nk units sampled: 
- Total number of defective units in all k samples 
P = 
Total number of units sampled 
To calculate the control limits of the p-chart, substitute p for p in the preceding ex- 
pression for the control limits, as illustrated in Figure 11.27. 
FIGURE 11.27 
b 
p-Chart 
Upper control limit: p + 3'.lji(l- p)ln 
Centerline: & = P 
Lower control limit: p - 3 djT(1- /i)h 
2 
4 
6 
8 
10 12 14 
Sample number 
In constructing ap-chart it is advisable to use a much larger sample size than 
is typically used for i- 
and R-charts. Most processes that are monitored in indus- 
try have relatively small process proportions, often less than .05 (i.e., less than 5% 
of output is nonconforming). In those cases, if a small sample size is used, sa! 
n = 5, samples drawn from the process would likely not contain any noncon- 
forming output. As a result, most, if not all, p's would equal zero. 
We present a rule of thumb that can be used to determine a sample size large 
enough to avoid this problem. This rule will also help protect against ending up with 
a negative lower control limit, a situation that frequently occurs when both p and 11 
are small. See Montgomery (1991) or Duncan (1986) for further details. 
Sample-Size Determination for Monitoring a Process Proportion 
Choose n such that n > 9(1 - PO) 
Po 
where 
n = Sample size 

if p 
1 be 
L the 
:tive 
; 
ex- 
than 
~dus- 
n 5% 
1, say 
Icon- 
large 
) with 
and n 
ion 
SECTION 11.6 
A Control Chart for Monitoring the Proportion of Defectives Generated by a Process 
685 
For example, if p is thought to be about .05, the rule indicates that samples of 
at least size 171 should be used in constructing the p-chart: 
In the next three boxes we summarize how to construct a p-chart and its 
zone boundaries and how to interpret a p-chart. 
Constructing a p-Chart: A Summary 
1. Using a rational subgrouping strategy, collect at least 20 samples, each of 
size 
where po is an estimate of p, the proportion defective (i.e., nonconform- 
ing) produced by the process. p, can be determined from sample data 
(i.e., 3) or may be based on expert opinion. 
For each sample, calculate F, the proportion of defective units in the 
sample: 
Number of defective items in the sample 
jj = 
Number of items in the sample 
3. Plot the centerline and control limits: 
- Total number of defective units in all k samples 
C 
Total number of units in all k samples 
Upper cont 
F 
Lower control limit: p - 
3
F
 
where k is the number of samples of size n and p is the overall propor- 
tion of defective units in the nk units sampled. p is an estimate of the un- 
known process proportion p. 
4. 
Plot the k sample proportions on the control chart in the order that the 
samples were produced by the process. 
As with the x- and R-charts, the centerline and control limits should be de- 
veloped using samples that were collected during a period in which the process 
was in control. Accordingly, when a p-chart is first constructed, the centerline and 
the control limits should be treated as trial values (see Section 11.4) and, if neces- 
sary, modified before being extended to the right on the control chart and used to 
monitor future process output. 

686 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  Improvementh 
,
.
 
I 
S I 
Constructing Zone Boundaries for a pChart 
Upper A-B boundary: + 2 P.7 
te: When the lower control limit is negative, it 
d not be plotted on the 
ontrol chart. However, the lower zone boundaries can still be plotted if they 
re nonnegative. 
Interpreting a p-Chart 
e process is out of control if one or more sample proportions fall be- 
yond the control limits (Rule 1) or if any of the three patterns of varia- 
n described by Rules 2,3, and 4 (Figure 11.21) are observed. Such 
gnals indicate that one or more special causes of variation are influ- 
ing the process  proportion,^. These causes should be identified and 
inated in order to bring the process into control. 
. The process is treated as being in control if none of the above noted out- 
control signals are observed. Processes that are in control should not 
d and eliminated. 
control in several areas within its warehouse operation. The manufacturer wants 
to begin with the order assembly process. Too frequently orders received by 
customers contain the wrong items or too few items. 
For each order received, parts are picked from storage bins in the ware- 
house, labeled, and placed on a conveyor belt system. Since the bins are spread 
over a three-acre area, items that are part of the same order may be placed on dif- 
ferent spurs of the conveyor belt system. Near the end of the belt system all spurs 
converge and a worker sorts the items according to the order they belong to.That 
information is contained on the labels that were placed on the items by the pickers 
The workers have identified three errors that cause shipments to be im- 
properly assembled: (1) pickers pick from the wrong bin, (2) pickers mislabel 
items, and (3) the sorter makes an error. 
The firm's quality manager has implemented a sampling program in which 
90 assembled orders are sampled each day and checked for accuracy. An assem- 
bled order is considered nonconforming (defective) if it differs in any way from 
the order placed by the customer. To date, 25 samples have been evaluated. The 
resulting data are shown in Table 11.4. 

e- 
3d 
if- 
Irs 
at 
rs. 
n- 
)el 
SECTION 11.6 
A Control Chart for Monitoring the Proportion of Defectives Generated by a Process 
687 
S o l u t i o n  
TABLE 
1 1.4 
Twenty-Five Samples of Size 90 from the 
Warehouse Order Assembly Process 
Sample 
Size 
Defective Orders 
Sample Proportion 
.................................................................................. 
............................................... 
1 
90 
12 
2 
.I3333 
90 
6 
3 
.06666 
90 
11 
4 
.I2222 
90 
8 
5 
.08888 
90 
13 
6 
.I4444 
90 
14 
7 
.15555 
90 
12 
8 
.I3333 
90 
6 
9 
.06666 
90 
10 
10 
.11111 
90 
13 
11 
.I4444 
90 
12 
12 
.I3333 
90 
24 
13 
.26666 
90 
23 
14 
.25555 
90 
22 
15 
.24444 
90 
8 
16 
.08888 
90 
3 
17 
.03333 
90 
11 
18 
.I2222 
90 
14 
19 
.I5555 
90 
5 
20 
.05555 
90 
12 
21 
.I3333 
90 
18 
22 
.20000 
90 
12 
23 
,13333 
90 
13 
24 
.I4444 
90 
4 
25 
.04444 
- 90 
6 
.06666 
Totals 
2,250 
292 
a. Construct ap-chart for the order assembly operation. 
b. What does the chart indicate about the stability of the process? 
c. Is it appropriate to use the control limits and centerline constructed in part 
a to monitor future process output? 
a. The first step in constructing the p-chart after collecting the sample data is to 
calculate the sample proportion for each sample. For the first sample, 
Number of defective items in the sample 
p = 
- 
- - -  
Number of items in the sample 
l2 - .I3333 
90 
All the sample proportions are displayed in Table 11.4. Next, calculate the 
proportion of defective items in the total number of items sampled: 
- Total number of defective items 
292 
- 
--- 
= Total number of items sampled 
2,250 - .I2978 
The centerline is positioned at p, and ji is used to calculate the control limits: 

688 
CHAPTER 11 M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
S
UCL: .23605 
LCL: .02351 
After plotting the centerline and the control limits, plot the 25 sample pro- 
portions in the order of sampling and connect the points with straight lines. 
The completed control chart is shown in Figure 11.28. 
F I G U R E  11.28 
p-Chart for order assembly 
process 
,2500 
,2000 
.I500 
.lo00 
.0500 
.0000 
Sample number 
- 
b. To assist our examination of the control chart, we add the 1- and 2-standard- 
deviation zone boundaries. The boundaries are located by substituting 
- 
p = .I2978 into the following formulas: 
Upper A-B boundary: p + 2 d
T
 
= .20063 
Lower A-B boundary: p - 2 JT 
= JJ589'3 
Upper B-C boundary: p + 
- ') 
= .I6521 
J--n 
Lower B-C boundary: p - 
- 
= .09435 
T - 7  
Because three of the sample proportions fall above the upper control limit 
(Rule I), there is strong evidence that the process is out of control. Noneof 
the nonrandom patterns of Rules 2,3, and 4 (Figure 11.21) are evident.7lle 
process proportion appears to have increased dramatically somewhere 
around sample 12. 
c. 
Because the process was apparently out of control during the period III 
which sample data were collected to build the control chart, it is not appro- 
priate to continue using the chart. The control limits and centerline are not 
representative of the process when it is in control. The chart must be revised 
before it is used to monitor future output. 

~dard- 
tuting 
rol limit 
None of 
lent. The 
lewhere 
In this case, the three out-of-control points were investigated and it was dis- 
covered that they occurred on days when a temporary sorter was working in 
place of the regular sorter. Actions were taken to ensure that in the future 
better-trained temporary sorters would be available. 
)eriod in 
3t appro- 
e are not 
,e revised 
a d L  
Since the special cause of the observed variation was identified and elimi- 
nated, all sample data from the three days the temporary sorter was working 
were dropped from the data set and the centerline and control limits were 
recalculated: 
1 
223 
Centerline: 3 = ----- = .I1263 
1980 
.11263(.88737) 
Control limits: j3 f 3
d
v
 
= .I1263 f 3
,
,
:
 
= .I1263 & .09997 
UCL: .21259 
LCL: .01266 
The revised zones are calculated by substituting 3 = .I1263 in the following 
formulas: 
* 
Upper B-C boundary: ji + 
Lower A-B boundary: p - 2 JP(' 
= .04598 
Lower B-C boundary:? - 
- 
= 07931 
c 
The revised control chart appears in Figure 11.29. Notice that now all sample 
proportions fall within the control limits.These limits can now be treated as 
official, extended to the right on thc chart, and used to monitor future 
orders. 
, 
FIGURE 11.29 
6 
Revised p-chart f o r  order 
assembly process 
,2500 1 
UCL = ,21259 
A 
LCL = .01266 
. O O O O 1 " " " " " " " " " " " '  
1
5
 10 
15 
20 
Sample number 

690 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Learning the Mechanics 
11.30 What characteristic of a process is a p-chart designed 
to monitor? 
11.31 The proportion of defective items generated by a man- 
ufacturing process is believed to be 8%. In construct- 
ing a p-chart for the process, determine how large the 
sample size should be to avoid ending up with a nega- 
tive lower control limit. 
11.32 To construct a p-chart for a manufacturing process, 25 
samples of size 200 were drawn from the process. The 
number of defectives in each sample is listed below. 
Sample 
Sample Size 
Defectives 
a. Calculate the proportion defective in each sample. 
b. Calculate and plot p and the upper and lower con- 
trol limits for the p-chart. 
c. Calculate and plot the A, B, and C zone boundaries 
on the p-chart. 
d. Plot the sample proportions on the p-chart and 
connect them with straight lines. 
e. Use the pattern-analysis rules 1-4 for detecting the 
presence of special causes of variation (Figure 11.21) 
to determine whether the process is out of control. 
11.33 To construct a p-chart, 20 samples of size 150 were 
drawn from a processThe proportion of defective items 
found in each of the samples is listed in the next table. 
Proportion 
Proportion 
Sample 
Defective 
Sample 
Defective 
...................................................................................... 
1 
.03 
11 
.07 
2 
.05 
12 
.04 
3 
.lo 
13 
.06 
4 
.02 
14 
.05 
5 
.08 
15 
.07 
6 
.09 
16 
.06 
7 
.08 
17 
.07 
8 
.05 
18 
.02 
9 
.07 
19 
.05 
10 
.06 
20 
.03 
a. Calculate and plot the centerline and the upper and 
lower control limits for the p-chart. 
b. Calculate and plot the A, B, and C zone boundaries 
on the p-chart. 
c. Plot the sample proportions on the p-chart. 
d. Is the process under control? Explain. 
e. Should the control limits and centerline of part a be 
used to monitor future process output? Explain. 
11.34 In each of the following cases, use the sample size for- 
mula to determine a sample size large enough to avoid 
constructing a p-chart with a negative lower control 
limit. 
a. p,= .Ol 
b. po= .05 c. po = . l O  d. po=.20 
Applying the Concepts 
11.35 A manufacturer produces micron chips for personal 
computers. From past experience the production man- 
ager believes that 1 % of the chips are defective. The 
company collected a sample of the first 1,000 chips 
manufactured after 4:00 P.M. every other day for a 
month. Thc chips were analyzed for defects, then these 
data and MINITAB were used to construct thep-chart 
shown on page 691. 
a. From a statistical perspective, is a sample size of 1,000 
adequate for constructing the p-chart'! Explain. 
b. Calculate the chart's upper and lower control limits 
c. What does the p-chart suggest about the presence 
of special causes during the time when the data 
were collected? 
d. Critique the rational subgrouping strategy used by 
the disk manufacturer. 
11.36 Goodstone Tirc & Rubber Company is interested in 
monitoring the proportion of defective tires generated 
by the production process at its Akron, Ohio, produc- 
tion plant. The company's chief engineer believes that 
the proportion is about 7%. Because the tires are 
destroyed during the testing process, the company 
would like to keep the number of tires tested to a min- 
imum. However, the engineer would also like to use a 

- 
and 
a b e  
n. 
: for- 
woid 
Introl 
:sonal 
man- 
e. The 
chips 
for a 
1 these 
,-chart 
,f 1,000 
1. 
limits 
-esence 
le data 
used by 
s t e d  in 
nerated 
produc- 
ves that 
ires are 
ompany 
o a min- 
to use a 
I 
SECTION 11.6 
A Control Chart for Monitoring the Proportion of Defectives Generated by a Proceri 
691 
MINITAB Output for Exercise 11.35 
I 
I 
Sample Number 
I 
p-chart with a positive lower control limit. A positive 
lower control limit makes it possible to determine 
when the process has generated an unusually small 
proportion of defectives. Such an occurrence is good 
news and would signal the engineer to look for causes 
of the superior performance. That information can be 
used to improve the production process. Using the 
sample size formula, the chief engineer recommended 
that the company randomly sample and test 120 tires 
from each day's production. To date, 20 samples have 
been taken. The data are presented bclow. 
a. Use the sample size formula to show how the chief en- 
gineer arrived at the recommended sample size of 120. 
b. Construct ap-chart for the tire production process. 
c. What does the chart indicate about the stability of 
the process? Explain. 
d. Is it appropriate to use the control limits to monitor 
future process output? Explain. 
e. Is the p-chart you constructed in part b capable of 
signaling hour-to-hour changes in p? Explain. 
11.37 Accurate typesetting is crucial to the production of 
high-quality newspapers. The editor of the Morristown 
Daily Tribune, a weekly publication with circulation of 
27,000, has instituted a process for monitoring the per- 
formance of typesetters. Each week 100 paragraphs of 
the paper are randomly sampled and read for accuracy. 
The number of paragraphs with errors is recorded in 
the table below for each of the last 30 weeks. 
Sample 
Sample Size 
Defectives 
.......................................................................... 
1 
120 
11 
2 
120 
5 
3 
120 
4 
4 
120 
8 
5 
120 
10 
6 
120 
13 
7 
120 
9 
8 
120 
8 
9 
120 
10 
10 
120 
11 
11 
120 
10 
:t 
12 
120 
12 
13 
_ 
120 
8 
14 
120 
6 
15 
120 
10 
16 
120 
5 
17 
120 
10 
18 
120 
10 
19 
120 
3 
20 
120 
8 
TYPESET.DAT 
.......................................................................................... 
Paragraphs 
Paragraphs 
Week 
with Errors 
Week 
with Errors 
......................................... 
........................................... 
1 
2 
16 
2 
2 
4 
17 
3 
3 
10 
18 
7 
4 
4 
19 
3 
5 
1 
20 
2 
6 
1 
21 
3 
7 
13 
22 
7 
8 
9 
23 
4 
9 - 
11 
24 
3 
10 
0 
2s 
2 
11 
3 
26 
2 
12 
4 
27 
0 
13 
2 
28 
1 
14 
2 
29 
3 
15 
8 
30 
4 
Primary Source: Jerry Kinard, Western Carolina University. 
Secondary Source: Render, B., and Stair, Jr., R. Quantitative 
Analysis for Management, 6th ed. Upper Saddle River, N. J.: 
Prentice-Hall. 1997. 

Deming's 14 Points 
H 
ow is it that the Japanese became quality leaders? What in- 
spired their concern for quality? In part, it was the statisti- 
cal and managerial expertise exported to Japan from the 
United States following World War 11. At the end of the war 
Japan faced the difficult task of rebuilding its economy.To this 
end, a group of engineers was assigned by the Allied com- 
mand to assist the Japanese in improving the quality of their 
communication systems. These engineers taught the Japanese 
the statistical quality control methods that had been devel- 
oped in the United States under the direction of Walter She- 
whart of Bell Laboratories in the 1920s and 1930s. Then, in 
1950, the Japanese Union of Scientists and Engineers invited 
W. Edwards Deming, a statistician who had studied with She- 
whart, to present a series of lectures on statistical quality-im- 
provcment methods to hundreds of Japanese researchers, plant 
managers, and engineers. During his stay in Japan he also met 
with many of the top executives of Japan's largest companies. 
At the time, Japan was notorious for the inferior quality of its 
products. Deming told the executives that by listening to what 
consumers wanted and by applying statistical methods in the 
production of those goods, they could export high-quality 
products that would find markets all over the world. 
In 1951 the Japanese established the Deming Prize to be 
given annually to companies with significant accomplish- 
ments in the area of quality. In 1989, for the first time, the 
Deming Prize was given to a U.S. company-Florida 
Power 
and Light Company. 
One of Deming's major contributions to the quality move- 
ment that is spreading across the major industrialized nations 
of the world was his recognition that statistical (and other) 
process improvement methods cannot succeed without the 
proper organizational climate and culture. Accordingly, he 
proposed 14 guidelines that, if followed, transform the organi- 
zational climate to one in which process-management efforts 
can flourish. These 14 points are, in essence. Deming's philos- 
ophy of management. H e  argues convincingly that all 14 
should be implemented, not just certain subsets. We list all 14 
points here, adding clarifying statements where needed. For a 
fuller discussion of these points, see Deming (1986), Gitlow et 
al. (199S),Walton (1 986), and Joiner and Goudard (1990). 
1. Create constancy of purpose toward improvement of 
product and service, with the aim to become competi- 
tive and to stay in business, and to provide jobs. The 
organization must have a clear goal or purposc. Every- 
one in the organization must be encouraged to work 
toward that goal day in and day out, year after year. 
2. Adopt the new philosophy. Reject detection-rejection 
management in favor of a customer-oriented, preven- 
tative style of management in which never-ending 
quality improvement is the driving force. 
3. Cease dependence on inspection to achieve quality. It 
is because of poorly designed products and excessive 
process variation that inspection is needed. If quality is 
designed into products and process management is 
used in their production, mass inspection of finished 
products will not be necessary. 
4. End the practice of awarding business on the basis of 
price tag. D o  not simply buy from the lowest bidder. 
Consider the quality of the supplier's products along 
with the supplier's price. Establish long-term relation- 
ships with suppliers based on loyalty and trust. Move 
toward using a single supplier for each item needed. 
5. Improve constantly and forever the system of produc- 
tion and service, to improve quality and productivity, 
and thus constantly decrease costs. 
a. Construct a p-chart for the process. 
defects are discovered, the disk is considered defective 
b. Is the process under statistical control? Explain. 
and is destroyed. The production process operates 
c. Should the control limits of part a be used to moni- 
20 hours per day, seven days a week. The table on p. 693 
tor future process output? Explain. 
rcports data for thc last three days of production. 
d. Suggest two methods that could be used to facilitate 
a. Construct a p-chart for the diskette productm 
the diagnosis of causes of process variation. 
process. 
11.38 A Japanese floppy disk manufacturer has a daily pro- 
b. w h a t  does it indicate about the stability of IIL 
: 
duction rate of about 20,000 high density 3.5-inch 
process? Explain. 
diskettes. Quality is monitored by randomly sampling 
C. What advice can you give the manufacturer to assk~ 
200 linishcd disks every other hour from the production 
them in their search for the special cause(s) of van- 
process and testing them for defects. If one or more 
ation that is plaguing the process? 

tive 
ltes 
693 
ion 
the 
sist 
ari- 
SECTION 11.6 
A Control Chart for Monitoring the Proportion of Defectives Generated by a Process 
693 
6. Institute training. Workers are often trained by other 
workers who were never properly trained themselves. 
The result is excessive process variation and inferior 
products and services. This is not the workers' fault; no 
one has told them how to do their jobs well. 
7. Institute leadership. Supervisors should help the work- 
ers to do a better job.Their job is to lead, not to order 
workers around or to punish thcm. 
8. Drive out fear, so that everyone may work effectively 
for the company. Many workers are afraid to ask ques- 
tions or to bring problems to the attention of manage- 
ment. Such a climate is not conducive to producing 
high-quality goods and services. People work best 
when they feel secure. 
9. Break down barriers between departments. Everyone 
in the organization must work together as a team. Dif- 
ferent areas within the firm should have complemen- 
tary, not conflicting, goals. People across the 
organization must realize that they are all part of the 
same system. Pooling their resources to solve prob- 
lems is better than competing against each other. 
10. Eliminate slogans, exhortations, and arbitrary numerical 
goals and targets for the workforce which urge the work- 
ers to achieve new levels of productivity and quality. 
Simply asking the workers to improve their work is not 
enough; they must be shown how to improve it. Man- 
agement must realize that significant improvements can 
be achieved only if management takes responsibility for 
quality and makes the necessary changes in the design of 
the system in which the workers operate. 
11. Eliminate numerical quotas. Quotas are purely quan- 
titative (e.g., numbcr of pieces to produce per day); 
they do not take quality into consideration. When 
faced with quotas, people attempt to meet them at any 
cost, regardless of the damage to the organization. 
12. Remove barriers that rob employees of their pride of 
workmanship. People must be treated as human be- 
ings, not commodities. Working conditions must be im- 
proved, including the elimination of poor supervision, 
poor product design, defective materials, and defec- 
tive machines. These things stand in the way of work- 
ers' performing up to their capabilities and producing 
work they are proud of. 
13. Institute a vigorous program of education and self-im- 
provement. Continuous improvement requires continu- 
ous learning. Everyone in the organization must be 
trained in the modern methods of quality improvement, 
including statistical concepts and interdepartmental team- 
work.Top management should be the first to be trained. 
14. Take action to accomplish the transformation. Hire 
people with the knowledge to implement the 14 
points. Build a critical mass of people committed to 
transforming the organization. Put together a top 
management team to lead the way. Develop a plan 
and an organizational structure that will facilitate the 
transformation. 
F
o
c
u
s
 
Contact a company located near your college or university 
and find out how many (if any) of Deming's 14 points have 
been implemented at the firm. Pool your results with those 
of your classmates to obtain a sense of the quality move- 
ment in your area. Summarize the results. 
Day 
Hour 
Number of 
Defectives 
Number of 
Day 
Hour 
Defectives 
Number of 
Day 
Hour 
Defectives 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
3 
1 
9 
2 
5 
3 
2 
4 
1 
5 
3 
6 
2 
7 
4 
8 
2 
9 
1 
10 
1 

694 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Key Terms 
Azone 659 
B zone 659 
conform to specs 654 
centerline 643 
common causes of variation 649 
control chart 642 
control limits 651 
Czone 659 
in control 645 
individuals chart 654 
lower control limit 651 
nonconforming 654 
oscillating sequence 643 
out of control 645 
output distribution 645 
p-chart 683 
pattern-analysis rules 660 
process 640 
process variation 642 
quality 639 
R-chart 672 
random behavior 647 
rare event 652 
rational subgroups 658 
run chart 642 
s-chart 673 
special (assignable) causes of vanation 
649 
specification limits 654 
statistical process control 649 
system 641 
stability 645 
statistical thinking 642 
3-sigma limits 651 
trial values 663 
total quality management 638 
upper control limit 651 
x-chart 654 
- 
x-chart 655 
................................................................................................................................................................................................................................................... 
Key Formulas 
Control Limits 
A-B Boundary 
B-C Boundary 
Control Chart 
Centerline 
(Lower, Upper) 
(Lower, Upper) 
(Lower, Upper) 
................................................................................................................................................................................................................................................... 
- 
Total number defectives 
p-chart 
= Total number units sampled 
n 
685,686 
- -  
n > 9(1 - 
where p,, estimates the true proportion defective 
Sample size for p-chart 684 
Po 
Symbol 
Pronunciation 
Description 
................................................................................................................................................................................................................................................... 
LCL 
L-C-L 
Lower control limit 
UCL 
U-C-L 
Upper control limit 
- 
- 
x 
x-bar-bar 
Average of the sample means 
- 
R 
R-bar 
Average of the sample ranges 
A2 
A-two 
Constant obtained from Table XV, Appendix B 
D3 
D-three 
Constant obtained from Table XV, Appendix B 
0 4  
D-four 
Constant obtained from Table XV, Appendix B 
d2 
d-two 
Constant obtained from Table XV, Appendix B 
d3 
d-three 
Constant obtained from Table XV, Appendix B 

S u p p l e m e n t a r y  E x e r c i s e s  
695 
P 
p-hat 
Estimated number of defectives in sample 
- 
P 
p-bar 
Overall proportion of defective units in all nk samples 
Po 
p-naught 
Estimated overall proportion of defectives for entire process 
SPC 
S-P-C 
Statistical process control 
Learning the Mechanics 
11.39 Define quality and list its important dimensions. 
11.40 What is a system? Give an example of a system with 
which you are familiar, and describe its inputs, out- 
puts, and transformation process. 
11.41 What is a process? Give an example of an organiza- 
tional process and a personal process. 
11.42 Select a personal process that you would like to 
better understand or to improve and construct a 
flowchart for it. 
TIMEWT.DAT 
..................................................... 
Order of 
Weight 
Production 
(grams) 
............................................. 
1 
6.0 
2 
5.0 
3 
7.0 
4 
5.5 
5 
7.0 
6 
6.0 
7 
8.0 
Order of 
Weight 
Production 
(grams) 
............................................. 
9 
6.5 
10 
9.0 
11 
3.0 
12 
11.0 
13 
3.0 
14 
12.0 
15 
2.0 
11-43 Describe the six major sources of process variation. 
8 
5.0 
i 
11.44 Suppose all the output of a process over the last year 
were measured and found to be within the specifics- 
11.50 The accompanying length measurements were made 
tion limits required by customers of the process. 
on 20 consecutively produced pencils. 
Should you worry about whether the process is in 
statistical control? Explain. 
11.45 Compare and contrast special and common causes of 
variation. 
11.46 Explain the role of the control limits of a control 
chart. 
11.47 Explain the difference between control limits and 
specification limits. 
11.48 A process is under control and follows a normal dis- 
tribution with mean 100 and standard deviation 10. 
In constructing a standard T-chart for this process, 
the control limits are set 3 standard deviations from 
the mean-i.e., 
100 f 3 ( 1 0 / 6 ) .  The probability of 
observing an i outside the control limits is 
(.00135 + ,00135) = ,0027. Suppose it is desired to 
construct a control chart that signals the presence of 
a potential special cause of variation for less 
extreme values of x. How many standard deviations 
from the mean should the control limits be set such 
that the probability of the chart falsely indicating 
the presence of a special cause of variation is .10 
rather than .0027? 
Applying the Concepts 
............................................................................................ 
Order of 
Length 
Order of 
Length 
Production 
(inches) 
Production 
(inches) 
.......................................................................................... 
1 
7.47 
11 
7.57 
. 
, 
2 
7.48 
12 
7.56 
3 
7.51 
13 
7.55 
4 
7.49 
14 
7.58 
5 
7.50 
15 
7.56 
6 
7.51 
16 
7.59 
7 
7.48 
17 
7.57 
8 
7.49 
18 
7.55 
9 
7.48 
19 
7.56 
10 
7.50 
20 
7.58 
a. Construct a time series plot. Be sure to connect the 
plotted points and add a centerline. 
b. Which type of variation pattern in Figure 11.6 best 
describes the pattern shown in your plot? 
11.51 Use the appropriate pattern-analysis rules to deter- 
mine whether the process being monitored by the 
control chart shown on page 696 is under the influ- 
ence of special causes of variation. 
11.49 Consider the following time series data for the weight 
11.52 A company that manufactures plastic molded parts 
of a manufactured product. 
believes it is producing an unusually large number 
a. Construct a time series plot. Be sure to connect the 
of defects. To investigate this suspicion, each shift 
points and add a centerline. 
drew seven random samples of 200 parts, visually 
b. Which type of variation pattern in Figure 11.6 best 
inspected each part to determine whether it was 
describes the pattern revealed by your plot? 
defective, and tallied the primary type of defect 

696 
CHAPTER 11 
M e t h o d s  f o r  Q u a  
Control Chart for Exercise 11.51 
l i t y  
- UCL 
I m p r o v e m e n t  
A 
LCL 
present (Hart, 1992). These data are presented in 
the table below. 
a. From a statistical perspective, are the number of 
samples and the sample size of 200 adequate for 
constructing ap-chart for these data? Explain. 
b. Construct ap-chart for this manufacturing process. 
c. Should the control limits be used to monitor fu- 
ture process output? Explain. 
d. Suggest a strategy for identifying the special causes 
of variation that may be present. 
11.53 A hospital has used control charts continuously since 
1978 to monltor the quality of its nursing care. A set 
of 363 scoring criteria, or standards, are applied at 
critical points in the patients' stay to determine 
whether the patients are receiving beneficial nursing 
care. Auditors regularly visit each hospital unit, 
sample two patients, and evaluate their care. The 
auditors review patients' records; interview the 
patients, the nurse, and the head nurse; and observe 
the nursing care given (International Journal of 
Quality and Reliability Management, Vol. 9, 1992). 
The data in the table on page 697 were collected over 
a three-month period for a newly opened unit of the 
hospital. 
a. Construct an R-chart for the nursing care process. 
b. Construct an T-chart for the nursing care process. 
c. Should the control charts of parts a and b be used 
to monitor future process output? Explain. 
d. The hospital would like all quality scores to exceed 
335 (their specification limit). Over the three- 
month periods, what proportion of the sampled pa- 
tients received care that did not conform to the 
hospital's requirements? 
11.54 AirExpress, an overnight mail service, is concerned 
about the operating efficiency of the package-sorting 
departments at its Toledo, Ohio, terminal.The company 
would like to monitor the time it takes for packages to 
be put in outgoing delivery bins from the time they are 
received. The sorting department operates six hours 
per day, from 6 P.M. to midnight.The company random- 
ly sampled four packages during each hour of opera- 
tion during four consecutive days. The time for each 
package to move through the system, in minutes, is 
given in the second table on the next page. 
Type of Defect 
Sample 
Shift 
# of Defects 
Crack 
Burn 
Dirt 
Blister 
Trim 
........................................................................................................................................................... 

'g 
it, 
l e  
1 e 
ve 
of 
!). 
er 
he 
is. 
S. 
ed 
ed 
e - 
)a- 
he 
ed 
n g 
"Y 
to 
ire 
1rs 
m- 
ra- 
c h  
, is 
S u p p l e m e n t a r y  E x e r c i s e s  
697 
Sample 
Scores 
Sample 
Scores 
Sample 
Scores 
Sample 
Waiting Time (mins.) 
........................................................................................................................ 
............................................................................... 
a. Construct an 2-chart from these data. In order for 
this chart to be meaningful, what assumption must 
be made about the variation of the process? Why? 
b. What does the chart suggest about the stability of 
the package-sorting process? Explain. 
c. Should the control limits be used to monitor future 
process output? Explain. 
TRANSIT.DAT 
.................................................................................. 
Sample 
Transit Time (mins.) 
11.55 Officials at Mountain Airlines are interested in mon- 
itoring the length of time customers must wait in line 
to check in at their airport counter in Reno, Nevada. 
In order to develop a control chart. five customers 
were sampled each day for 20 days. The data, in min- 
utes, are presented next. 
a. Construct an R-chart from these data. 
b. What does the R-chart suggest about the stability 
of the process? Explain. 
c. Explain why the R-chart should be interpreted 
prior to the T-chart. 
d. Construct an i-chart from these data. 
e. What does the ?-chart suggest about the stability 
of the process? Explain. 
f. Should the control limits for the R-chart and 
Y-chart be used to monitor future process output? 
Explain. 
11.56 Over the last year, a company that manufactures 
golf clubs has received numerous complaints about 
thc performance of its graphite shafts and has lost 
several market share percentage points. In response, 
the company decided to monitor its shaft produc- 
tion process t o  identify new opportunities t o  
improve its product. The process involves pultru- 
sion. A fabric is pulled through a thermosetting 
polymer bath and then through a long heated steel 
die. As it moves through the die. the shaft is cured. 
Finally, it is cut to the desired length. Defects that 
can occur during the process are internal voids, 
broken strands, gaps between successive layers, and 
microcracks caused by improper curing. The com- 
pany's newly formed quality department sampled 
10 consecutive shafts every 30 minutes and nonde- 
structive testing was used to seek out flaws in the 
shafts. The data from each eight-hour work shift 
were combined to form a shift sample of 160 shafts. 
Data on lhe proportion of defective shafts for 36 
shift samples arc presented in the table on page 698, 
followed by data on the types of flaws identified. 
[Note: Each defective shaft may have more than one 
flaw.] 

698 
CHAPTER 11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
SHAFI'LDAT 
........................................................................................................ 
Number of 
Proportion of 
Shift Number 
Defective Shafts 
Defective Shafts 
Source Kolarik, W. Creating Quality. Concepts, Systems, 
Strategec, und Tools New York: McGraw-Hill. 1995. 
SHAFI'2.DAT 
.................................................................................... 
Type of Defect 
Number of Defects 
............................................................................... 
Internal voids 
11 
Broken strands 
96 
Gaps between layer 
72 
Microcracks 
150 
a. Use the appropriate control chart to determine 
whether the process proportion remains stable 
over time. 
b. Does your control chart indicate that both com- 
mon and special causes of variation are present? 
Explain. 
c. To help diagnose the causes of variation in 
Rrocess output, construct a Pareto diagram for 
the types of shaft defects observed. Which are the 
"vital few"? The "trivial many"? 
11.57 A company called CRW runs credit checks for a 
large number of banks and insurance companies. 
Credit history information is typed into computer 
files by trained administrative assistants. The 
company is interested in monitoring the propor- 
tion of credit histories that contain one or more 
data entry errors. Based on her experience with 
the data entry operation, the director of the data 
processing unit believes that the proportion of 
histories with data entry errors is about 6%. 
CRW audited 150 randomly selected credit histo- 
ries each day for 20 days. The sample data are 
presented below. 
CRWDAT 
............................................................................................. 
Sample 
Sample Size 
Histories with Errors 
a. Use the sample size formula to show that a sample 
size of 150 is large enough to prevent the lower 
control limit of the p-chart they plan to construct 
from being negative. 
b. Construct ap-chart for the data entry process. 
c. What does the chart indicate about the presence of 
special causes of variation? Explain. 
d. Provide an example of a special cause of variation 
that could potentially affect this process. Do the 
same for a common cause of variation. 
e. Should the control limits be used to monitor fu- 
ture credit histories produced by the data entry op- 
eration? Explain. 
(A 
rhe I
lutol
lenlj
J.S. 2
med 
lard 
he c
net 
:om6
TI
with 
:atio 
atic
nanl
:noL 
orce
xod
was I
have
what
rhe 
hard 
of sc 
perfc
seml
Low, 
of th
peril
est ii 
The 
vealc 
teria 
and 
ty in
that 
the 1
fact1
mat1
knip
axis 
FIGU
A hz 
autc
-

R e a l - W o r l d  C a s e  
699 
n in 
for 
the 
lies. 
uter 
The 
lore 
with 
iata 
1 of 
5%. 
sto- 
are 
ple 
ver 
uct 
fu- 
'P- 
Real-World Case The Gasket Manufacturing Case 
(A Case Covering Chapter 1 1) 
The Problem A Midwestern manufacturer of gaskets for 
automotive and off-road vehiclc applications was sud- 
denly and unexpectedly notified by a major customer-a 
U.S. auto manufacturer-that 
they had significantly tight- 
ened the specification limits on the overall thickness of a 
hard gasket used in their automotive engines. Although 
the current specification limits were by and large being 
met by the gasket manufacturer, their product did not 
come close to meeting the new specification. 
The gasket manufacturer's first reaction was to negotiate 
with the customer to obtain a relaxation of the new specifi- 
cat~on. When these efforts failed, the customer-supplier re- 
lat~onship became somewhat strained. The gasket 
manufacturer's next thought was that if they waited long 
enough, the automotive company would eventually be 
forced to loosen the requirements and purchase the existing 
product. However, as time went on it became clear that this 
was not going to happen and that some positive steps would 
have to be taken to improve the quality of their gaskets. But 
what should be done? And by whom? 
The Product Figure C6.1 shows the product in question, a 
bard gasket. A hard gasket is comprised of two outer layers 
~f soft gasket material and an inner layer consisting of a 
~erforated piece of sheet metal. These three pieces are as- 
,embled, and some blanking and punching operations fol- 
ow, after which metal rings are installed around the inside 
)f the cylinder bore clearance holes and the entire outside 
~eriphery of the gasket. The quality characteristic of inter- 
:st m this case is the assembly thickness. 
The Process An initial study by the staff engineers re- 
realed that the variation in the thickness of soft gasket ma- 
erial-the 
two outer layers of the hard gasket-was 
large 
~nd undoubtedly respon4Ae for much of the total variabili- 
y in the final product. Figure C6.2 shows the roll mill process 
hat fabricates the sheets of soft gasket material from which 
he two outer layers of the hard gasket are made. To manu- 
~ t u r e  
a sheet of soft gasket material, an operator adds raw 
laterial, in a soft pelletlike form, to the gap-called 
the 
nipbetween the two rolls.The larger roll rotates about its 
xis with no lateral movement; the maller roll rotates and 
hard gasket for 
~tornotive applications 
moves back and forth laterally to change the size b;f the knip. 
As the operator adds more and more material to the knip, 
the sheet is formed around the larger roll. When the smaller 
roll reaches a preset destination (i.e., final gaplsheet thick- 
ness), a bell rings and a red light goes on telling the operator 
to stop adding raw material.The operator stops the rolls and 
cuts the sheet horizontally along the larger roll so that it may 
be pulled off the roll. The finished sheet, called a pull, is 
pulled onto a table where the operator checks its thickness 
with a micrometer.The operator can adjust the final gap if he 
or she believes that the sheets are coming out too thick or 
too thin relative to the prescribed nominal value (i.e., the 
target thickness). 
Process Operation Investigation revealed that the opera- 
tor runs the process in the following way. After each sheet is 
made, the operator measures the thickness with a microm- 
eter. The thickness values for three consecutive sheets are 
averaged and the average is plotted on a piece of graph 
paper that, at the start of the shift, has only a solid horizon- 
tal line drawn on it to indicate the target thickness value for 
the particular soft gasket sheet the operator is making. Pe- 
riodically, the operator reviews these evolving data and 
makes a decision as to whether or not the process mean- 
the sheet thickness-needs 
to be adjusted. This can be ac- 
complished by stopping the machine, loosening some 
clamps on the small roll, and jogging the small roll laterally 
in or out by a few thousandths of an inch-whatever 
the 
operator feels is needed.Tne clamps are tightened, the gap 
is checked with a taper gage, and if adjusted properly, the 
operator begins to make sheets again.Typically, this adjust- 
ment process takes 10 to 15 minutes.The questions of when 
to make such adjustments and how much to change the roll 
gap for each adjustment are completely at the operator's 
discretion, based on the evolving plot of thickness averages. 
ROU mi" 
Thickness 
Raw materlal 
FIGURE C6.2 
Roll mill for the manufacture 
of soft gasket material 

700 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Figure C6.3 shows a series of plots that detail the history 
of one particular work shift over which the operator made 
several process adjustments. (These data come from the 
same shift that the staff engineers used to collect data for a 
process capability study that is described later.) Figure 
C6.3(a) shows the process data after the first 12 sheets have 
been made-four 
averages of three successive sheet thick- 
ncsses. At this point the operator judgcd that the data were 
telling her that the process was running below the target, so 
she stopped the process and made an adjustment to slightly 
increase the final roll gap. She then proceeded to makc more 
sheets. Figure C6.3(b) shows the state of the process some- 
what later. Now it appeared to the operator that the sheets 
were coming out too thick, so she stopped and made another 
adjustment. As shown in Figure C6.3(c). the process seemed 
to run well for a while, but then an average somewhat below 
The Company's Stop-Gap Solution While the staff engi- 
neers were studying the problem to formulate an appro- 
priate action plan, something had to be done to make it 
possible to deliver hard gaskets within the new specification 
limits. Management decided to increase product inspection 
and, in particular, to grade each piece of material accordmg 
to thickness so that the wide variation in thickness could be 
balanced out at the assembly process. Extra inspectors were 
used to grade each piece of soft gasket material. Sheets of 
the same thickness were shipped in separate bundles on 
pallets to a sister plant for assembly. Thick and thin sheets 
were selected as needed to make a hard gasket that met the 
specification. The process worked pretty well and there was 
some discussion about making it permanent. However, 
some felt it was too costly and did not get at the root cause 
of the problem. 
the target led the operator to believe that another adjust- 
The Engineering Department's Analysis Meanwhile, the 
ment was necessary. Figures C6.3(d) and C6.3(e) show points 
staff engineers in the company were continuing to study 
in time where other adjustments were made. 
the problem and came to the conclusion that the existing 
Figure C6.3(f) shows the complete history of the shift. A 
roll mill process equipment for making the soft gasket 
total of 24 X 3, or 72, sheets were made during this shift. 
sheets simply was not capable of meeting the new specifi- 
When asked, the operator Indicated that the history of this 
cations. This conclusion was reached as a result of the ex- 
shift was quite typical of what happens on a day-to-day 
amination of production data and scrap logs over the past 
basis. 
FIGURE C6.3 
Process adjustment history 
over one shift 
Adjust 
5 a 
Time 
(b) 
Adjust 
'j 1 Jhipl 
mean 
g 
aJ 
M 
2 
2 
Time 
( 4  
Time 
(e) 
Time 
(f) 
-
se7
thi
t e
kt
cl1
is1
e q
thl
a1 
thl
th;
sic
P" 
thl
an
da
en
co
to
wi 
Fij
1 0 7
to
sic
-

R e a l - W o r l d  Case 
701 
several months. They had researched some new equipment 
that had a track record for very good sheet-to-sheet consis- 
tency and had decided to write a proposal to replace the ex- 
isting roll mills with this new equipment. 
To strengthen the proposal, their boss asked them to in- 
clude data that demonstrated the poor capability of the ex- 
isting equipment. The engineers, confident that the 
equipment was not capable, selected what they thought was 
the best operator and the best roll mill (the plant has sever- 
al roll mill lines) and took careful measurements of the 
thickness of each sheet made on an eight-hour shift. During 
that shift, a total of 72 sheetslpulls were made. This was con- 
sidered quite acceptable since the work standard for the 
process is 70 sheets per shift.The measurements of the sheet 
thickness (in the order of manufacture) for the 72 sheets 
are given in Table C6.1. The engineers set out to use these 
data to conduct a process capability study. 
Relying on a statistical methods course that one of the 
engineers had in college 10 years ago, the group decided to 
construct a frequency distribution from the data and use it 
to estimate the percentage of the measurements that fell 
within the specification limits. Their histogram is shown in 
Figure C6.4. Also shown in the figure are the upper and 
lower specification values.The dark shaded part of the his- 
togram represents the amount of the product that lies out- 
side of the specification limits. It is immediately apparent 
0.0430 
0.0450 
0.0470 
Soft gasket thickness (inches) 
FIGURE C6.4 
Histogram of data from process capability study 
from the histogram that a large proportion of the output 
does not meet the customer's needs. Eight of the 72 sheets 
fall outside the specification limits. Therefore, in terms of 
percent conforming to specifications, the engineers esti- 
mated the process capability to be 88.8%.This was clearly 
unacceptable. This analysis confirmed the engineer's low 
opinion of the roll mill process equipment.They included it 
in their proposal and sent their recommendation to replace 
the equipment to the president's office. 
TABLE 
C6.1 
Measurements of Sheet Thickness 
Sheet 
Thickness (in.) 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
0.0440 
0.0446 
0.0437 
0.0438 
0.0425 
0.0443 
0.0453 
0.0428 
0.0433 
0.0451 
0.0441 
0.0434 
0.0459 
0.0466 
0.0476 
0.0449 
0.0471 
0.0451 
0.0472 
0.0477 
0.0452 
0.0457 
0.0459 
0.0472 
Sheet 
Thickness (in.) 
Sheet 
Thickness (in.) 
................... . ............ . ...................... 
49 
0.0427 
50 
0.0437 
51 
0.0445 
52 
0.0431 
53 
0.0448 
54 
0.0429 
55 
0.0425 
56 
0.0442 
57 
0.0432 
58 
0.0429 
59 
0.0447 
60 
0.0450 
61 
0.0443 
62 
0.0441 
63 
0.0450 
64 
0.0443 
65 
0.0423 
66 
0.0447 
67 
0.0429 
68 
0.0427 
69 
0.0464 
70 
0.0448 
71 
0.0451 
72 
0.0428 

702 
CHAPTER 
11 
M e t h o d s  f o r  Q u a l i t y  I m p r o v e m e n t  
Your Assignment You have been hired as an external 
consultant by the company's president, Marilyn Carlson. 
She would like you to critique the engineers' analysis, con- 
clusion, and recommendations. 
Suspecting that the engineers' work may be flawed, 
President Carlson would also like you to conduct your own 
study and make your own recommendations concerning 
how to resolve the company's problem. She would like you 
to use the data reported in Table C6.1 along with the data 
of Table C6.2, which she ordered be collected for you. 
These data were collected in the same manner as the data 
in Table C6.1. However, they were collected during a peri- 
od of time when the roll mill operator was instructed not to 
adjust the sheet thickness. In your analysis, if you choose to 
construct control charts, use the same three-measurement 
subgrouping that the operators use. 
Prepare an in-depth, written report for the president that 
responds to her requests. It should begin with an executive 
summary and include whatever tables and figures are need- 
ed to support your analysis and recommendations. (A layout 
of the data file available for this case, stored in GAS- 
KET.DAT, is described below.) 
Variable 
Column(s) Type 
.................................................................................................................. 
SHEET 
1-2 
QN 
THICKNSS 
7-11 
QN 
ADJUST 
13 
QL (A = operator adjustments, 
N = no adjustments) 
TABLE 
C6.2 Measurements of Sheet Thickness for a Shift Run with No 
Operator Adjustment 
Sheet 
Thickness (in.) 
Sheet 
Thickness (in.) 
Sheet 
Thickness (in.) 
................................................ 
........................ 
......... 
........... 
1 
,0445 
25 
.0443 
49 
.0445 
2 
.0455 
26 
.0450 
50 
,0471 
3 
,0457 
27 
,0441 
51 
,0465 
4 
.0435 
28 
.0449 
52 
.0438 
5 
,0453 
29 
.0448 
53 
,0445 
6 
.0450 
30 
.0467 
54 
,0472 
7 
.0438 
31 
,0465 
55 
,0453 
8 
.0459 
32 
.0449 
56 
.0444 
9 
.0428 
33 
.0448 
57 
.0451 
10 
.0449 
34 
.0461 
58 
,0455 
11 
.0449 
35 
.0439 
59 
.0435 
12 
.0467 
36 
.0452 
60 
.0443 
13 
.0433 
37 
.0443 
61 
.0440 
14 
.0461 
38 
.0434 
62 
,0438 
15 
.0451 
39 
.0454 
63 
.0444 
16 
.0455 
40 
.0456 
64 
.0444 
17 
.0454 
41 
.0459 
65 
.0450 
18 
.0461 
42 
.0452 
66 
.0467 
19 
.0455 
43 
.0447 
67 
,0445 
20 
.0458 
44 
.0442 
68 
.(I447 
21 
.0445 
45 
.0457 
69 
.0461 
22 
.0445 
46 
.0454 
70 
.0450 
23 
.0451 
47 
.0445 
71 
.0463 
24 
.0436 
48 
.0451 
72 
.0456 
This case is based on the experiences of an actual company whose identity is disguised for confidentiality reasons. The case was originally 
written by DeVor, Chang. and Sutherland (Statistical Quality Design and Control [New York: Macmillan Publishing Co., 19921 pp. 298-329) 
and has been adapted to focus on the material presented in Chapter 11. 

BASIC C O U N T I N G  R U L E S  
Sample points associated with many experiments have identical characteristics. If 
you can develop a counting rule to count the number of sample points, it can be 
used to aid in the solution of many probability problems. For example, many ex- 
periments involve sampling n elements from a population of N. Then, as ex- 
plained in Section 3.1, we can use the formula 
N !  
( y) = n!(N - n)! 
to find the number of different samples of n elements that could be selected from 
the total of N elements.This gives the number of sample points for the experiment. 
Here, we give you a few useful counting rules. You should learn the charac- 
teristics of the situation to which each rule applies. Then, when working a proba- 
bility problem, carefully examine the experiment to see whether you can use one 
of the rules. 
Learning how to decide whether a particular counting rule applies to an ex- 
periment takes patience and practice. If you want to develop this skill, try to use 
the rules to solve some of the exercises in Chapter 3. Proofs of the rules below can 
be found in the text by W. Feller listed in the references to Chapter 3. 
Multiplicative Rule 
You have k sets of different elements, n, in the first set. n2 in the second set. . . .. 
nk in the kth set. Suppose you want to form a sample of k elements by 
ng one element from each of the k sets. The number of different samples 
can be formed 
. .. 
-
~
~
l
l
*
l
_
m
s
A product can be shipped by four airlines and each airline can ship via three 
different routes. How many distinct ways exist to ship the product? 
S 0 I u t i 0 n A method of shipment corresponds to a pairing of one airline and one route. 
Therefore, k = 2, the number of airlines is n, = 4, the number of routes is n2 = 3, 
and the number of ways to ship the product is 
i 
rile n2 = (4)(3) = 12 
* 
How the multiplicative rule works can be seen by using a tree diagram, in- 
troduced in Section 3.6. The airline choice is shown by three branching lines in 
Figure A.1. 
703 

704 
APPENDIX A 
B a s i c  C o u n t i n g  R u l e s  
FIGURE A . l  
Route 1 
Tree diagram for 
airline example 
twenty candidates for three different executive positions, E,, E,, and E, 
y different ways could you fill the positions? 
S o I u t i 0 n For this example, there are k = 3 sets of elements: 
Set 1: The candidates available to fill position El 
Set 2: The candidates remaining (after filling E l )  that are available to fill Ez 
Set 3: The candidates remaining (after filling El and E,) that are available to 
fill E, 
The numbers of elements in the sets are n, = 20, n2 = 19, and n3 = 18. Thus, the 
number of different ways to fill the three positions is 
artitions Rule 
u have a single set of N dist 
, and you want to par- 
st set containing n, elements, the second containing 
e number of different 
want to assign three workers to job 1, four to job 2, and five to job 3. How many 
different ways could you make this assignment? 
S o I u t i o n For this example, k = 3 (corresponding to the k = 3 job sites), N = 12, and 
n, = 3, n2 = 4, n, = 5. Then, the number of different ways to assign the workers 
to the job sites is 

E3. 
52 
3 to 
the 
t 
r- 
% 
nt 
- 
YOU 
lany 
and 
.kers 
* 
APPENDIX A 
B a s i c  C o u n t i n g  R u l e s  
705 
cia1 case (k = 2) of the pa 
tioning a set of N eleme 
nz = N - n, the nu 
P
"
"
"
s
b
s
"
s
-
 
How many samples of four fire fighters can be selected from a group of lo? 
S o I u t i 0 n We have N = 10 and n = 4; then, 

Tabl
Tabl
Tabl
Tabl
Tabl
Tabl
Tabl
Tabl 
Tabl 

Table I 
Table II 
Table Ill 
Table IV 
Table V 
Table VI 
Table VII 
Table Vlll 
Table IX 
Table X 
TABLES 
CONTENTS 
Random Numbers 
Binomial Probabilities 
Poisson Probabilities 
Normal Curve Areas 
Exponentials 
Critical Values of t 
Critical Values of X2 
Percentage Points of the 
F-Distribution, a = .10 
Percentage Points of the 
F-Distribution, a = .05 
Percentage Points of the 
F-Distribution, cu = .025 
Table XI 
Percentage Points of the 
F-Distribution, a = .O1 
732 
Table XI1 
Critical Values of TL and T ,  
for the Wilcoxon Rank Sum 
Test: Independent Samples 
734 
Table Xlll Critical Values of To in the 
Wilcoxon Paired Difference 
Signed Rank Test 
735 
Table XIV Critical Values of Spearman's 
Rank Correlation Coefficient 
736 
Table XV 
Control Chart Constants 
737 


TABLE 
I 
Random Numbers 
(continued) 

TABLE 
I Continued 
Column 
L 
P 
TABLE 
I 
Continued 

TABLE 
I 
Continued 
Source: Abridged from W. H. Beyer (ed.). CRC Standard Mathematrcal Tables, 24th edition. (C1eveland:The Chemical Rubber Company), 1976. Reproduced by permission of the publisher. 

712 
APPENDIX B T a b l e s  
i 
TABLE 
I1 
Binomial Probabilities 
k 
Tabulated values are 
p(x). (Computations are rounded at the third decimal place.) 

TABLE 
II Continued 
APPENDIX 
B 
T a b l e s  
713 
(continued) 

714 
APPENDIX B 
T a b l e s  
TABLE 
II 
Continued 
(continued) 

APPENDIX B 
Tables 
715 
TABLE 
I1 Continued 

716 
APPENDIX B 
T a b l e s  
TABLE 
Ill Poisson Probabilities 
k 
Tabulated values are I= p(x). (Computations are rounded at the third decimal place.) 
x = o  
(continued) 

TABLE 
Ill 
Continued 
(continued) 

718 
APPENDIX B T a b l e s  
TABLE 
Ill 
Continued 

TABLE 
Ill Continued 
APPENDIX B 
T a b l e s  
(continued) 

720 
APPENDIX B 
T a b l e s  
TABLE 
Ill Continued 

APPENDIX 
B 
T a b l e s  
721 
TABLE 
IV Normal Curve Areas 
z 
.O 
.1 
.2 
.3 
.4 
.5 
.6 
.7 
.8 
.9 
1.0 
1.1 
1.2 
1.3 
1.4 
1.5 
1.6 
1.7 
1.8 
1.9 
2.0 
2.1 
2.2 
2.3 
2.4 
2.5 
2.6 
2.7 
2.8 
2.9 
3.0 
Source: 
.08 
,0319 
,0714 
.I103 
,1480 
,1844 
,2190 
.2517 
,2823 
,3106 
.3365 
,3599 
,3810 
,3997 
,4162 
,4306 
.4429 
,4535 
,4625 
,4699 
,4761 
,4812 
,4854 
,4887 
.4913 
,4934 
,4951 
.4963 
.4973 
.4980 
.4986 
.4990 
Reproduced 
permission of A. Hald. 
.OO 
.0000 
,0398 
.0793 
.I179 
,1554 
,1915 
,2257 
,2580 
,2881 
.3159 
,3413 
.3643 
,3849 
.4032 
.4192 
,4332 
.4452 
,4554 
.4641 
,4713 
,4772 
.4821 
.4861 
.4893 
,4918 
.4938 
,4953 
.4965 
,4974 
.4981 
,4987 
Abridged from 
.09 
,0359 
,0753 
,1141 
,1517 
,1879 
,2224 
,2549 
,2852 
,3133 
.3389 
,3621 
,3830 
,4015 
,4177 
,4319 
.4441 
,4545 
,4633 
,4706 
,4767 
,4817 
,4857 
,4890 
.4916 
.4936 
,4952 
,4964 
,4974 
,4981 
.4986 
.4990 
by 
.01 
.0040 
,0438 
,0832 
.I217 
,1591 
,1950 
,2291 
,2611 
,2910 
,3186 
,3438 
.3665 
,3869 
,4049 
.4207 
.4345 
.4463 
,4564 
.4649 
.4719 
.4778 
.4826 
.4864 
,4896 
,4920 
.4940 
,4955 
.4966 
,4975 
,4982 
,4987 
Table I of 
.02 
.0080 
.0478 
.0871 
.I255 
.I628 
,1985 
,2324 
,2642 
.2939 
.3212 
,3461 
,3686 
,3888 
,4066 
.4222 
.4357 
.4474 
.4573 
.4656 
,4726 
.4783 
,4830 
.4868 
,4898 
,4922 
,4941 
,4956 
,4967 
.4976 
,4982 
,4987 
A. Hald, 
.03 
,0120 
,0517 
.0910 
,1293 
,1664 
.2019 
.2357 
,2673 
,2967 
,3238 
.3485 
,3708 
,3907 
,4082 
,4236 
,4370 
,4484 
.4582 
,4664 
.4732 
,4788 
,4834 
,4871 
,4901 
,4925 
,4943 
.4957 
,4968 
.4977 
,4983 
,4988 
Statistical 
.04 
.0160 
,0557 
,0948 
.I331 
,1700 
,2054 
,2389 
.2704 
,2995 
,3264 
,3508 
,3729 
,3925 
.4099 
,4251 
,4382 
,4495 
,4591 
,4671 
,4738 
,4793 
,4838 
.4875 
,4904 
,4927 
.4945 
,4959 
,4969 
.4977 
,4984 
,4988 
Tables and 
.05 
,0199 
,0596 
,0987 
,1368 
.I736 
.2088 
.2422 
,2734 
.3023 
,3289 
,3531 
.3749 
,3944 
,4115 
,4265 
.4394 
,4505 
,4599 
,4678 
,4744 
.4798 
,4842 
,4878 
,4906 
,4929 
,4946 
,4960 
,4970 
.4978 
,4984 
,4989 
Formulas 
.06 
.0239 
,0636 
,1026 
,1406 
,1772 
,2123 
,2454 
,2764 
,3051 
,3315 
,3554 
,3770 
,3962 
.4131 
,4279 
,4406 
,4515 
,4608 
,4686 
,4750 
,4803 
,4846 
,4881 
,4909 
,4931 
,4948 
.4961 
,4971 
,4979 
.4985 
.4989 
(New York: 
.07 
,0279 
,0675 
.I064 
,1443 
,1808 
,2157 
,2486 
.2794 
,3078 
,3340 
.3577 
,3790 
.3980 
,4147 
,4292 
.4418 
.4525 
.4616 
,4693 
.4756 
.4808 
,4850 
.4884 
,4911 
,4932 
.4949 
,4962 
,4972 
.4979 
,4985 
,4989 
Wiley), 195 

722 
APPENDIX B 
T a b l e s  

APPENDIX B 
T a b l e s  
723 
TABLE 
VI 
Critical Values of t 
. ,nP"-nZ 
f(t) 
4 
t
.
~
~
 
636.62 
31.598 
12.924 
8.610 
6.869 
5.959 
5.408 
5.041 
4.781 
4.587 
4.437 
4.318 
4.221 
4.140 
4.073 
4.015 
3.965 
3.922 
3.883 
3.850 
3.819 
3.792 
3.767 
3.745 
3 725 
3.707 
3.690 
3.674 
3.659 
3.646 
3.551 
3.460 
3.373 
3.291 
Pearson and 
H 0. Hartley (eds ), The B~ornetrtka Tables for Stattstrc~ans,Vol 1,3d ed , Biometnka, 1966 
t
.
~
~
 
63.657 
9.925 
5.841 
4.604 
4.032 
3.707 
3.499 
3.355 
3.250 
3.169 
3.106 
3.055 
3.012 
2.977 
2.947 
2.921 
2.898 
2.878 
2.861 
2.845 
2.831 
2.819 
2.807 
2.797 
2.787 
2.779 
2.771 
2.763 
2.756 
2.750 
2.704 
2.660 
2.617 
2.576 
of B~ometr~ka 
V 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
40 
60 
120 
m 
Source Th~s 
t . ~ l  
318.31 
22.326 
10.213 
7.173 
5.893 
5.208 
4.785 
4.501 
4.297 
4.144 
4.025 
3.930 
3.852 
3.787 
3.733 
3.686 
3.646 
3.610 
3 579 
3.552 
3.527 
3.505 
3.485 
3.467 
3.450 
3.435 
3.421 
3.408 
3.396 
3.385 
3.307 
3.232 
3.160 
3.090 
from E. S. 
t.~2S 
12.706 
4.303 
3.182 
2.776 
2.571 
2.447 
2.365 
2.306 
2.262 
2.228 
2.201 
2.179 
2.160 
2.145 
2 131 
2.120 
2.110 
2.101 
2.093 
2.086 
2.080 
2.074 
2.069 
2.064 
2.060 
2.056 
2.052 
2.048 
2.045 
2.042 
2.021 
2.000 
1.980 
1.960 
kmd permiss~on 
t . ~ l ~  
31.821 
6.965 
4.541 
3.747 
3.365 
3.143 
2.998 
2.896 
2.821 
2.764 
2.718 
2.681 
2.650 
2.624 
2.602 
2.583 
2.567 
2.552 
2.539 
2.528 
2.518 
2.508 
2.500 
2.492 
2.485 
2.479 
2.473 
2.467 
2.462 
2.457 
2.423 
2.390 
2.358 
2.326 
of the Trustees 
t . l ~  
3.078 
1.886 
1.638 
1.533 
1.476 
1.440 
1.415 
1.397 
1.383 
1.372 
1.363 
1.356 
1.350 
1.345 
1.341 
1.337 
1.333 
1.330 
1.328 
1.325 
1.323 
1.321 
1.319 
1.318 
1.316 
1.315 
1.314 
1.313 
1.311 
1.310 
1.303 
1.296 
1.289 
1.282 
table is reproduced 
t
.
~
~
 
6.314 
2.920 
2.353 
2.132 
2.015 
1.943 
1.895 
1.860 
1.833 
1.812 
1.796 
1.782 
1.771 
1.761 
1.753 
1.746 
1.740 
1.734 
1.729 
1.725 
1.721 
1.717 
1.714 
1.711 
1.708 
1.706 
1.703 
1.701 
1.699 
1 697 
1 684 
1.671 
1.658 
1.645 
wlth the 

724 
APPENDIX B 
T a b l e s  
TABLE 
VII 
Critical Values of XZ 
0 
2 
Xa 
Degrees of Freedom 
Source: From C. M.Thompson, "Tables of the Percentage Points of the ,yZ-Distribution," Biometrika, 1941.32, 
188-189. Reproduced by permission of the Biometrika Trustees. 
(continued) 

TABLE 
VII 
Continued 
Degrees of Freedom 
APPENDIX B 
Tables 
725 

'726 
APPENDIX B 
T a b l e s  
TABLE 
Vlll 
Percentage Points of the F-distribution, a = .I 0 
f(F) 
- F  
0 
Fa 
Reproduced by permission of the Biometrika Trustees. 
(continued) 
1 
2 
3 
4 
5 
6 
7 
8 
9 
E 10 
11 
W 
'2 
E 13 
ir 14 
15 
16 
2 17 
g 18 
a 19 
E 20 
g 21 
2 22 
3 23 
0 24 
25 
fl 26 
27 
28 
29 
30 
40 
60 
120 
m 
Source: From 
2 
49.50 
9.00 
5.46 
4.32 
3.78 
3.46 
3.26 
3.11 
3.01 
2.92 
2.86 
2.81 
2.76 
2.73 
2.70 
2.67 
2.64 
2.62 
2.61 
2.59 
2.57 
2.56 
2.55 
2.54 
2.53 
2.52 
2.51 
2.50 
2.50 
2.49 
2.44 
2.39 
2.35 
2.30 
and C. 
NUMERATOR 
4 
55.83 
9.24 
5.34 
4.11 
3.52 
3.18 
2.96 
2.81 
2.69 
2.61 
2.54 
2.48 
2.43 
2.39 
2.36 
2.33 
2.31 
2.29 
2.27 
2.25 
2.23 
2.22 
2.21 
2.19 
2.18 
2.17 
2.17 
2.16 
2.15 
2.14 
2.09 
2.04 
1.99 
1.94 
of Percentage 
1 
39.86 
8.53 
5.54 
4.54 
4.06 
3.78 
3.59 
3.46 
3.36 
3.29 
3.23 
3.18 
3.14 
3.10 
3.07 
3.05 
3.03 
3.01 
2.99 
2.97 
2.96 
2.95 
2.94 
2.93 
2.92 
2.91 
2.90 
2.89 
2.89 
2.88 
2.84 
2.79 
2.75 
2.71 
M. Merrington 
3 
53.59 
9.16 
5.39 
4.19 
3.62 
3.29 
3.07 
2.92 
2.81 
2.73 
2.66 
2.61 
2.56 
2.52 
2.49 
2.46 
2.44 
2.42 
2.40 
2.38 
2.36 
2.35 
2.34 
2.33 
2.32 
2.31 
2.30 
2.29 
2.28 
2.28 
2.23 
2.18 
2.13 
2.08 
M.Thompson, "Tables 
DEGREES 
5 
57.24 
9.29 
5.31 
4.05 
3.45 
3.11 
2.88 
2.73 
2.61 
2.52 
2.45 
2.39 
2.35 
2.31 
2.27 
2.24 
2.22 
2.20 
2.18 
2.16 
2.14 
2.13 
2.11 
2.10 
2.09 
2.08 
2.07 
2.06 
2.06 
2.05 
2.00 
1.95 
1.90 
1.85 
Points of the 
OF FREEDOM 
6 
58.20 
9.33 
5.28 
4.01 
3.40 
3.05 
2.83 
2.67 
2.55 
2.46 
2.39 
2.33 
2.28 
2.24 
2.21 
2.18 
2.15 
2.13 
2.11 
2.09 
2.08 
2.06 
2.05 
2.04 
2.02 
2.01 
2.00 
2.00 
1.99 
1.98 
1.93 
1.87 
1.82 
1.77 
Inverted Beta 
7 
58.91 
9.35 
5.27 
3.98 
3.37 
3.01 
2.78 
2.62 
2.51 
2.41 
2.34 
2.28 
2.23 
2.19 
2.16 
2.13 
2.10 
2.08 
2.06 
2.04 
2.02 
2.01 
1.99 
1.98 
1.97 
1.96 
1.95 
1.94 
1.93 
1.93 
1.87 
1.82 
1.77 
1.72 
(?'-Distribution," 
8 
59.44 
9.37 
5.25 
3.95 
3.34 
2.98 
2.75 
2.59 
2.47 
2.38 
2.30 
2.24 
2.20 
2.15 
2.12 
2.09 
2.06 
2.04 
2.02 
2.00 
1.98 
1.97 
1.95 
1.94 
1.93 
1.92 
1.91 
1.90 
1.89 
1.88 
1.83 
1.77 
1.72 
1.67 
Biometrika, 
9 
59.86 
9.38 
5.24 
3.94 
3.32 
2.96 
2.72 
2.56 
2.44 
2.35 
2.27 
2.21 
2.16 
2.12 
2.09 
2.06 
2.03 
2.00 
1.98 
1.96 
1.95 
1.93 
1 
1.92 
1 
1.91 
1.89 
1.88 
/ 
1.87 
1.87 
1 
1.86 
1.85 
1.79 
1.74 
1.68 
1.63 
1943,33,73-88. 

APPENDIX 
B 
T a b l e s  
727 
TABLE 
VIII Continued 
NUMERATOR DEGREES OF FREEDOM 

728 
APPENDIX 
B 
T a b l e s  
! 
TABLE 
IX 
Percentage Points of the F-distribution, a = .05 
A 
F 
0 
Fa 
Reproduced by permission of the Biometrika Trustees. 
(continued] 
DEGREES 
5 
230.2 
19.30 
9.01 
6.26 
5.05 
4.39 
3.97 
3.69 
3.48 
3.33 
3.20 
3.11 
3.03 
2.96 
2.90 
2.85 
2.81 
2.77 
2.74 
2.71 
2.68 
2.66 
2.64 
2.62 
2.60 
2.59 
2.57 
2.56 
2.55 
2.53 
2.45 
2.37 
2.29 
2.21 
Points of the 
NUMERATOR 
4 
224.6 
19.25 
9.12 
6.39 
5.19 
4.53 
4.12 
3.84 
3.63 
3.48 
3.36 
3.26 
3.18 
3.11 
3.06 
3.01 
2.96 
2.93 
2.90 
2.87 
2.84 
2.82 
2.80 
2.78 
2.76 
2.74 
2.73 
2.71 
2.70 
2.69 
2.61 
2.53 
2.45 
2.37 
of Percentage 
3 
215.7 
19.16 
9.28 
6.59 
5.41 
4.76 
4.35 
4.07 
3.86 
3.71 
3.59 
3.49 
3.41 
3.34 
3.29 
3.24 
3.20 
3.16 
3.13 
3.10 
3.07 
3.05 
3.03 
3.01 
2.99 
2.98 
2.96 
2.95 
2.93 
2.92 
2.84 
2.76 
2.68 
2.60 
M.Thompson, "Tables 
OF FREEDOM 
6 
234.0 
19.33 
8.94 
6.16 
4.95 
4.28 
3.87 
3.58 
3.37 
3.22 
3.09 
3.00 
2.92 
2.85 
2.79 
2.74 
2.70 
2.66 
2.63 
2.60 
2.57 
2.55 
2.53 
2.51 
2.49 
2.47 
2.46 
2.45 
2.43 
2.42 
2.34 
2.25 
2.17 
2.10 
Inverted Beta 
2 
199.5 
19.00 
9.55 
6.94 
5.79 
5.14 
4.74 
4.46 
4.26 
4.10 
3.98 
3.89 
3.81 
3.74 
3.68 
3.63 
3.59 
3.55 
3.52 
3.49 
3.47 
3.44 
3.42 
3.40 
3.39 
3.37 
3.35 
3.34 
3.33 
3.32 
3.23 
3.15 
3.07 
3.00 
and C. 
1 
2 
3 
4 
5 
6 
7 
8 
9 
z 10 
0 
n 11 
3 12 
13 
k l4 
0 15 
2 16 
2 17 
$ 18 
Ci 19 
erl 20 
8 :: 
8 23 
0 24 
25 
a 26 
27 
28 
29 
30 
40 
60 
120 
m 
Source: From 
1 
161.4 
18.51 
10.13 
7.71 
6.61 
5.99 
5.59 
5.32 
5.12 
4.96 
4.84 
4.75 
4.67 
4.60 
4.54 
4.49 
4.45 
4.41 
4.38 
4.35 
4.32 
4.30 
4.28 
4.26 
4.24 
4.23 
4.21 
4.20 
4.18 
4.17 
4.08 
4.00 
3.92 
3.84 
M. Merrington 
7 
236.8 
19.35 
8.89 
6.09 
4.88 
4.21 
3.79 
3.50 
3.29 
3.14 
3.01 
2.91 
2.83 
2.76 
2.71 
2.66 
2.61 
2.58 
2.54 
2.51 
2.49 
2.46 
2.44 
2.42 
2.40 
2.39 
2.37 
2.36 
2.35 
2.33 
2.25 
2.17 
2.09 
2.01 
(F)-Distribution," 
8 
238.9 
19.37 
8.85 
6.04 
4.82 
4.15 
3.73 
3.44 
3.23 
3.07 
2.95 
2.85 
2.77 
2.70 
2.64 
2.59 
2.55 
2.51 
2.48 
2.45 
2.42 
2.40 
2.37 
2.36 
2.34 
2.32 
2.31 
2.29 
2.28 
2.27 
2.18 
2.10 
2.02 
1.94 
Biometrika, 
9 
240.5 
19.38 
8.81 
6.00 
4.77 
4.10 
3.68 
3.39 
3.18 
3.02 
2.90 
2.80 
2.71 
2.65 
2.59 
2.54 
2.49 
2.46 
2.42 
2.39 
2.37 
2.34 
2.32 
2.30 
2.28 
2.77 
2.25 
2.24 
2.22 
2.21 
:b: ! 
1.96 
1.88 
1943,33,73-88. 

APPENDIX B 
T a b l e s  
729 
TABLE 
IX 
Continued 
NUMERATOR DEGREES OF FREEDOM 

730 
APPENDIX 6 
T a b l e s  
TABLE 
X 
Percentage Points of the F-distribution, a = .025 
NUMERATOR DEGREES OF FREEDOM 
1 
1 ;/;; 1 ;/; 1 ;;: 1 ;;; 
5.02 
3.69 
3.12 
2.79 
Source: From M .  Merrington and C. M.Thompson, "Tables of Percentage 
Reproduced by permission of the Biometrika Trustees. 
(continued) 
I 
921.8 
937.1 
948.2 
956.7 
963.3 
1 
39.30 
39.33 
39.36 
39.37 
39.39 
I 
14.88 
14.73 
14.62 
14.54 
14.47 
9.36 
9.20 
9.07 
8.98 
8.90 
7.15 
6.98 
6.85 
6.76 
6.68 
5.99 
5.82 
5.70 
5.60 
5.52 
5.29 
5.12 
4.99 
4.90 
4.82 
4.82 
4.65 
4.53 
4.43 
4.36 
, 
4.48 
4.32 
4.20 
4.10 
4.03 
4.24 
4.07 
3.95 
3.85 
3.78 
4.04 
3.88 
3.76 
3.66 
3.59 
3.89 
3.73 
3.61 
3.51 
3.44 
3.77 
3.60 
3.48 
3.39 
3.31 
3.66 
3.50 
3.38 
3.29 
3.21 
3.58 
3.41 
3.29 
3.20 
3.12 
3.50 
3.34 
3.22 
3.12 
3.05 
3.44 
3.28 
3.16 
3.06 
2.98 
3.38 
3.22 
3.10 
3.01 
2.93 
3.33 
3.17 
3.05 
2.96 
2.88 
3.29 
3.13 
3.01 
2.91 
2.84 
3.25 
3.09 
2.97 
2.87 
2.80 
3.22 
3.05 
2.93 
2.84 
2.76 
3.18 
3.02 
2.90 
2.81 
2.73 
3.15 
2.99 
2.87 
2.78 
2.70 
3.13 
2.97 
2.85 
2.75 
2.68 
3.10 
2.94 
2.82 
2.73 
2.65 
3.08 
2.92 
2.80 
2.71 
2.63 
3.06 
2.90 
2.78 
2.69 
2.61 
3.04 
2.88 
2.76 
2.67 
2.59 
3.03 
2.87 
2.75 
2.65 
2.57 
2.90 
2.79 
2.67 
2.57 
lints of the Inverted Beta (F)-Distribution," Biometrika, 1943,33,73-88. 
2.74 
2.63 
2.52 
2.41 
2.62 
2.51 
2.39 
2.29 
2.53 
2.41 
2.30 
2.19 
2.45 
2.33 
2.22 
2.11 

APPENDIX B 
Tables 
731 
TABLE 
X 
Continued 
NUMERATOR DEGREES OF FREEDOM 

732 
APPENDIX B 
Ta b l  e s  
TABLE 
XI 
Percentage Points of the F-distribution, a = .O1 
NUMERATOR DEGREES OF FREEDOM 
Source: From M. Merrington and C. M.Thompson, "Tables of Percentage Points of the Inverted Beta (F)-Distribution," Biometrika, 1943,33,73-88 
Reproduced by permission of the Biomc.trikrr Trustees. 
(continutdl 

Continued 
NUMERATOR DEGREES OF FREEDOM 
20 
24 
30 
40 
60 
120 
m 
6,209 
6,235 
6,261 
6,287 
6,313 
6,339 
6,366 
99.45 
99.46 
99.47 
99.47 
99.48 
99.49 
99.50 
26.69 
26.60 
26.50 
26.41 
26.32 
26.22 
26.13 
14.02 
13.93 
13.84 
13.75 
13.65 
13.56 
13.46 
9.55 
9.47 
9.38 
9.29 
9.20 
9.1 1 
9.02 
7.40 
7.31 
7.23 
7.14 
7.06 
6.97 
6.88 
6.16 
6.07 
5.99 
5.91 
5.82 
5.74 
5.65 
5.36 
5.28 
5.20 
5.12 
5.03 
4.95 
4.86 
4.81 
4.73 
4.65 
4.57 
4.48 
4.40 
4.31 
4.41 
4.33 
4.25 
4.17 
4.08 
4.00 
3.91 
4.10 
4.02 
3.94 
3.86 
3.78 
3.69 
3.60 
3.86 
3.78 
3.70 
3.62 
3.54 
3.45 
3.36 
3.66 
3.59 
3.51 
3.43 
3.34 
3.25 
3.17 
3.51 
3.43 
3.35 
3.27 
3.18 
3.09 
3.00 
3.37 
3.29 
3.21 
3.13 
3.05 
2.96 
2.87 
3.26 
3.18 
3.10 
3.02 
2.93 
2.84 
2.75 
3.16 
3.08 
3.00 
2.92 
2.83 
2.75 
2.65 
3.08 
3.00 
2.92 
2.84 
2.75 
2.66 
2.57 
3.00 
2.92 
2.84 
2.76 
2.67 
2.58 
2.49 
2.94 
2.86 
2.78 
2.69 
2.61 
2.52 
2.42 
2.88 
2.80 
2.72 
2.64 
2.55 
2.46 
2.36 
2.83 
2.75 
2.67 
2.58 
2.50 
2.40 
2.31 
2.78 
2.70 
2.62 
2.54 
2.45 
2.35 
2.26 
2.74 
2.66 
2.58 
2.49 
2.40 
2.31 
2.21 
2.70 
2.62 
2.54 
2.45 
2.36 
2.27 
2.17 
2.66 
2.58 
2.50 
2.42 
2.33 
2.23 
2.13 
2.63 
2.55 
2.47 
2.38 
2.29 
2.20 
2.10 
2.60 
2.52 
2.44 
2.35 
2.26 
2.17 
2.06 
2.57 
2.49 
2.41 
2.33 
2.23 
2.14 
2.03 
2.55 
2.47 
2.39 
2.30 
2.21 
2.11 
2.01 
2.37 
2.29 
2.20 
2.11 
2.02 
1.92 
1.80 
2.20 
2.12 
2.03 
1.94 
1.84 
1.73 
1.60 
2.03 
1.95 
1.86 
1.76 
1.66 
1.53 
1.38 
1.88 
1.79 
1.70 
1.59 
1.47 
1.32 
1.00 

734 
APPENDIX B 
T a b l e s  
TABLE 
XI1 
Critical Values of TL and Tu for the Wilcoxon Rank Sum Test: Independent Samples 
Test statistic is the rank sum associated with the smaller sample (if equal sample sizeq either rank sum can be used). 
a. a = .025 one-tailed; a = .05 two-tailed 
4 
6 
18 
11 
25 
12 
5 
6 
21 
12 
28 
18 
6 
7 
23 
12 
32 
19 
7 
7 
26 
13 
35 
20 
8 
8 
28 
14 
38 
21 
9 
8 
31 
15 
41 
22 
10 
9 
33 
16 
44 
24 
b. (Y = .05 one-tailed; a = .10 two-tailed 
- - 
Source: From F. Wilcoxon and R. A. Wilcox, "Some Rapid Approximate Statistical Procedures," 1964,20-23. Courtesy of Lederle Laboratories Division of 
American Cyanamld Company, Madlson, NJ 

APPENDIX B 
T a b l e s  
735 
Critical Values of To in the Wilcoxon Paired Difference 
Signed Rank Test 
One-Tailed 
a = .05 
a = ,025 
a = .01 
a = .005 
a = .05 
a = ,025 
a = .01 
a = ,005 
a = .05 
a = ,025 
a = .01 
a = ,005 
a = .05 
a = ,025 
a = .01 
a = .005 
a = .05 
a = ,025 
a = .01 
a = ,005 
a = .05 
a = .025 
a = .01 
a = .005 
a = .05 
a = .025 
a = .01 
a = ,005 
a = .05 
a = ,025 
a = .01 
a = .005 
Two-Tailed 
a = .I0 
a = .05 
a = .02 
a = .01 
a = .I0 
a = .05 
a = .02 
a = .01 
a = .I0 
a = .05 
a = .02 
a = .01 
a = .10 
a = .05 
a = .02 
a = .01 
a = .10 
a = .05 
a = .02 
a = .01 
a = .10 
a = .05 
a = .02 
a = .01 
a = .I0 
a = .05 
a = .02 
a = .01 
a = .10 
a = .05 
a = .02 
a = .01 
Source: From F. Wilcoxon and R.A. Wilcox, "Some Rapid Approximate Statistical Procedures," 1964, p. 28. 
Courtesy of Lederle Laboratories Division of American Cyanamid Company, Madison, NJ. 

736 
APPENDIX B 
T a b l e s  
TABLE 
XIV 
Critical Values of Spearman's Rank Correlation Coefficient 
The a values correspond to a one-tailed test of Ho: p = 0. The value should be doubled ,for two-tailed tests. 
- 
A 
Source: From E. G. Olds,"Distribution of Sums of Squares of Rank Differences for Small Samples," Annals of Mathematical Statistics, 1938,9. Reproduced 
with the permission of the Editor, Annuls oj'Mathematica1 Statistics. 

APPENDIX B 
T a b l e s  
737 
TABLE 
XV 
Control Chart Constants 
Number of Observations 
in Subgroup, n 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
More than 25 
Source:ASTM Manual on the Presentation of Data and Control Chart Analysis, Philadelphia, PA: American 
Society for Testing Materials, pp. 134-136,1976. 


CALCULATION 
J 
F O R M U L A S  FOR ANALYSIS O F  VARIANCE: 
I N D E P E N D E N T  S A M P L I N G  
- 
- 
SS(Tota1) = 
- 
- 
SST = 
- 
- 
SSE = 
MST = 
MSE = 
. 
Correction for mean 
(Total of all ob~ervations)~ - 
- 
Total ndinber of observations 
n  
Total sum of squares 
n 
(Sum of squares of all observations) - CM = 
y: - CM 
i = l  
Sum of squares for treatments 
Sum of squares of treatment totals with 
each square divided by the number of 
observations for that treatment 
Sum of squares for error = SS(Tota1) - SST 
SST 
Mean square for treatments = - 
P - 1  
SSE 
Mean square for error = - 
n - P  
MST 
F = Test statistic = - 
MSE 
where 
Total number of observations 
Number of treatments 
Total for treatment i (i = 1,2, . . . , p) 


Chapter 1 
1.3 population; variables; summary tools; conclusions 1.5 published source; designed experiment; survey; observationally 
1.13 qualitative; qualitative 1.15 a. all U S .  citizens b. president's job performance; qualitative c 2,000 polled individuals 
d. Estimate the proportion of all citizens who believe the president is doing a good job. e. survey f. not very likely 1.17 a. all 
U.S.employees b. employee's job status c. qualitative d. 1,000 employees surveyed e. majority of all workers would re- 
main in their jobs 1.19 a. quantitative b. quantitative c. qualitative d. quantitative e. qualitative f. quantitative 
g. qualitative 1.21 a. all department store executives b. job satisfaction; Machiavellian rating c. 218 department store 
exccutlves d. survey e. Executives with hlgher job-satisfaction scores are likely to have a lower 'mach' rating. 1.25 a. all 
major U.S. firms b. whether the job offers job-sharing c. 1,035 firms d. Estimate the proportion of all firms that offer job- 
$haring to their employees. 1.27 I. qualitative 11. quantitative 111. quantitative IV. qualitative V. qualitative VI. quantitative 
1.29 b. speed of the deliveries; accuracy of the invoices; quality of the packaging c. total numbers of questionnaires received 
Chapter 2 
2.1 16, .18; .45; .15; .14 2.3 b. yes c. banks: yes; department stores: no 2.5 a. .642, .204, .083, .071 2.7 a. response time 
c. 3,570 2.9 a. length of time small busincsses used the Internet per week c. .08 
2.13 50,75,125,100,25,50,50,25 
2.15 a. frequency histogram b. 14 c. 49 2.17 c. 28.6% 2.19 b. 22; .733 2.25 a. 44.75% 
b. .325 2.27 a. 33 b. 175 
c.20 
d.71 
e. 1,089 2.29 a. 6 b. 50 c. 42.8 2.31 a. i=2.717,rn=2.65 
2.33 a. 2.5;3;3 b. 3.08;3;3 c 49.6;49; 
50 2.35 m = 129,200.5; i = 197,632.25 2.37 a. i = 5.24,rn = 3, mode = 2 b. 48 c. i = 4.66, m = 3, mode = 2 
2.39 a. median b. mean 2.41 a. joint: 2 = 2.6545, m = 1.5; no prefihng: i = 4.2364, rn = 3.2; prepack: i = 1.81 85, rn = 1.4 
b.three centers 2.43 c. no; yes (if the data are between 0 and 1) 2.45 a. R = 4, s2 = 2.3, s = 1.52 
b. R = 6, s2 = 3.619, 
s = 1.90 c. R = 10, s2 = 7.111,s = 2.67 d. R = 5, s2 = 1.624, s = 1.274 2.47 a. i = 5.6, s2 = 17.3, s = 4.1593 
b. i = 13.75 feet, s2 = 152.25 square feet, s = 12.339 feet c. i = -2.5, s2 = 4.3, s = 2.0736 b. i = .33 ounce, s2 = .0587 
square ounce, s = ,2422 ounce 2.49 a. $17,360; $13,700 b. $36,202 
c. no 2.51 a. 150.30; 150.95 
b. 7.5; 7.8 c. 2.41; 
2.66 d. Chicago 2.53 a. R = 455.2, s2 = 25,367.88, s = 159.27 
b. R and s: million dollars; s2: million dollars squared 
c. Increase; increase 2.55 a. 68% b. 95% c. almost all 2.57 a. i = 8.24, s2 = 3.357, s = 1.83 
b. 18/25 = .72, 
24125 = .96,25/25 = 1 
d. R = 7 ,  s = 1.75 2.59 b. R = 48, s = between 8 and 12 c. at most 25%, at least 50% 
2.61 b. (-100.27,219.91) 
2.63 a. no b. (-1.107,6.205) 
c. 47/49 = .959 
d. no more than 6.2 months 2.65 do not buy 
2.67 11:30and 4:00 2.69 a. 75% b. 50% c. 20% d. 84% 2.71 a. z = 2 b. z = -3 
c. z = -2 
d. 2 = 1.67 
2.73 no 2.75 b. F = - 13,117.06, s = 21,889.6; Japan: z = -1.96; Egypt: z = .74 2.77 a. 0 b. 21 c. 5.90 d. yes 
2.79 a. z = .727, no b. z = -3.273, yes c. z = 1.364, no d. z = 3.727, yes 2.85 c. no d. yes 2.87 b. customers 268, 
26Y,and264 2.91 a. -1,1,2 
b. -2,2,4 
c. 1,3,4 d. .1,.3,.4 
2.93 a. 6,27,5.20 b. 6.25,28.25,5.32 
c. 7,37.67,6.14 
d. 3,0,0 2.99 b. marketing; 6.5 days, engineering: 7.0 days; accounting: 8.5 days 2.103 a. skewed right c. = 38 d. no, 
z = 3.333 2.105 b. yes, skcwed to the right c. 370 d. 0.46, -1.10 
f. Carolina, New England, Denver. Seattle, Pitts- 
burgh, Cincinnati g. Dallas h. operating income increases as current value increases 
Chapter 3 
3.1 a. .5 b. .3 
c. .6 
3.3 P(A) = .55, P(B) = .50, P(C) = .70 3.5 P(A) = 1/10, P(B) = 315, P(C) = 3/10 3.7 b. ,189, 
403,.258,.113,.038 c. S92 d. 212 3.9 1/20 3.11 a. .990,.010 
b. .195,.203,.576 
3.13 a. l t o 2  b. '1, c. 215 
3.15 b. 1/16 c. 5/16 3.19 a. 314 
b. 13/20 c. 1 d. 215 
e. 114 
f. 7/20 g. 1 h. 114 3.21 a. .65 
b. .72 c. .25 
d..08 e. .35 f. .72 
g. 0 h. A a n d C , B a n d C , C a n d D  3.23 a. B n C  b. Ac c. C U B  d. A n C C  
3.25 a. P(A) = .281, P(B) = .276, P(C) = ,044, P(D) = .079, P(E) = ,044 b. 0 c. 3 7  d. 0 e. .325 f. A and B, A and 
C,A and D, A and E 3.27 a. (1, R), (1, S), (1, E), (2, R), (2, S), (2, E), (3, R ) ,  (3, S), (3, E) b. sample space c. .24 
d. .lo e. .47 
f. .62 
g. .28 3.29 a. ( D ,  C), (D, T), (F, C), (F, T), ( G ,  C), ( G ,  T )  b. ,450, ,550, .338 
c. .578,0 d. .236, 
186 3.31 a. yes b. P(A) = .26, P(B) = .35, P(C) = .72, P(D) = .28, P(E) = .05 c. .56, .05, .77 
d. .74 e. C and D, D 
and E 3.33 a. .8,.7,.6 
b. .25,.375, .375 d. no 3.35 a. .37 b. .68 
c. .15 
d. .2206 e. 0 f. 0 g. no 3.37 a. A 
andC,BandC b. none c. .65,.90 
3.39 a. .08,.4,.52 
b. .12,.30 
3.41 a. 333 b. .5 
c. .333 
3.43 a. .9224 
b. ,0776 3.45 a. ,543 b. .221 c. .052 d. .914 3.47 a. .02 b. .08 3.49 a. .I16 b. .728 3.51 a. .3, .6 
b. dependent 
c. ~ndependent 3.53 a. 35,820,200 
b. 1/35,820,200 3.55 a. .000186 
c. no 3.61 .5 
3.63 a. 0,.2,.9,1,.7,.3,.4,0 

742 
A n s w e r s  t o  S e l e c t e d  E x e r c i s e s  
3.65 a. 720 b. 10 c. 10 d. 20 e. 1 3.67 a..25 
b. .13 c. .75 d. ,0325 3.69 a. .75 b. .2875 c. .6 d. .06 
e. no f. employee does not plan to retire at age 68 or the employee is not on the technical staff 
g. yes 3.71 a. 1/10,1/1O 
b. .641, .359 c. upper bounds 3.73 a. .00000625 b. ,0135 c. doubt validity of the manufacturer's claim 
d. no 
3.75.801 3.77b. .95 c..25 
d..5 
3.79a. .24 b..1 
c. .14 3.81.79 3.83a. .7127 b..2873 
3.85b.1/10 
c. 1110,3110 3.87 a. .550 b. .450 c. .272 d. .040 e. ,182 f. 257 g. .I82 
Chapter 4 
4.3 a. discrete b. discrete c. discrete d. continuous e. discrete f. continuous 4.11 a. .25 b. .40 c. .75 4.13 a. .3 
b. .1 c. .2 d. .7 e. .9 f. .9 4.15 a. 34.5,174.75,13.219 c. 1.00 4.17 a. .2592 b. .0870 c. .6826 4.19 b. .011,.052, 
.948, .2l9 d. ,138, .I96 4.21 a, = 2.4; a, = 1.5; a, = .90; a4 = .90; a, = .90; a, = 1.65 4.23 b. 6.5 c 1.9975 d. at least 0%, 
at least 75% e. 70%; 95% 4.25 a. 15 b. 10 
C. 1 d. 1 e. 4 4.27 a. .4096 b. .3456 c. .027 d. .0081 e. .3456 
f. .027 4.29 a. 12.5,6.25,2.5 b. 16,12.8,3.578 c. 60,24,4.899 d. 63,6.3,2.510 e. 48,9.6,3.098 f. 40,38.4,6.197 
4.31 a. ,015, ,030 b. .0706, .0022 c. .1328, .0085 d. .9129 4.33 b. .60 c. .346 d. .317 4.35 a. ==O b. ,4845 
c. independence of flights d. Air Force's e. .0803 4.37 a. 520,13.491 b. no, z = -8.895 
4.39 a. discrete b. Poisson 
d. p = 3 , ~ =  
1.7321 e. p = 3 , u =  1.7321 4.41 a. .934 b. .I91 c .I25 d. .223 e. .777 f. .001 4.43 a. 4,2 b. -1.5 
c. .889 4.45 a. 2 b. no, ~ ( x  
> 10) = ,003 4.47 a. .03 c. .0291, .9704 4.49 a. .6083 c. no, ~ ( x  
> 2) = .0064; yes. 
P(X< I ) =  ,6907 4.51 a. f(x)= 1/4(35~57),0otherwise b. 5,1.155 4.53 a. 0 b. 1 c. 1 455 a. p =  .03,g= .W13 
b. p = .75, u = ,0208 c. 1, .375 d. .5, .20,0 4.57 yes 4.59 a. continuous c. 7, .2887, (6.422,7.577) d. .5 e. 0 f. .75 
g. .0002 4.61 a. .4772 b. .4987 c. .4332 d. .2881 4.63 a. -31 b. .55 c 1.43 d. .21 e. -2.05 
f. .50 4.65 a. .3830 
b. .3023 c..1525 
d. .7333 e. .I314 f. .9545 4.67a. .6554 b. .4295 c. .9544 4.69a. ,1020 b. ,6879,3925 c..0032 
4.71 a. ,5124 b. yes c. no 4.73 a. .68% b. P(X < 6) = ,0068 4.75 5.068 4.77 a. 123 b. 1.295 c. yes 4.79 b. 2.765 
c. IQR/s = 1.70 4.81 data are not normal 4.85 a. .345, .3446 b. ,115, ,1151 c. .924, .9224 4.87 a. 1 b. p f 3~ = 
(-2.058,8.658) 
4.89 a. 5,000; 25,000 b. ,5438 c. no 4.91 a. no b. .6026, 3 5 5  c. no, yes, yes d. ,7190 4.93 a. 300 
b. 800 c 1.0 4.95 a. ,367879 b. ,082085 c. .000553 d..223130 4.97 a. .999447 b. ,999955 c. .981684 d. ,632121 
4.99 a. .0949 b. 10.54; 10.54 d. ,1729 4.101 a. eC5X b. .I35335 c. ,367879 d. no e. 820.85;3,934.69 f. 37 days 
4.103 a. 550671 b. ,263597 4.105 c. 1/16 4.107 c. .05 d. no 4.109 a. 5 b. E(7) = 5 c. E(m) = 4.778 4.111 a. 100,5 
b. 100,2 c. 100,l d. 100,1.414 e. 100, .447 f. 100, .316 4.113 a. 2.9,3.29,1.814 4.115 a. .0228 b. .0668 c. ,0062 
d. 3185 e. .0013 4.117 a. approximatelynormal b. .0322 c. ,8925 d. 19.1 e. lessthanl9.1 4.119 a. p,=406, 
u, = 1.6833, approximately normal b. ,0010 c. the first 4.121 a. =O 
b. yes,i = 5.55 4.123 a. discrete h. continuous 
c. continuous d. continuous 4.125 a. ,2734 b. .4096 c. .3432 4.127 a. .I92 b. .228 c. .772 d. .987,.960 f. 14,4.2, 
2.049 g. .975 4.129 a. f(x) = 1180,lO 5 x 5 90,O otherwise b. 50,23.09 d. ,625 e. 0 f. 375 g. .577 h. .I875 
4.131 a. .3821 b. ,5398 c. 0 d. .I395 e. ,0045 f. ,4602 4.133 a. .9975 b. .00012 c. 0 d. 1 e. .000006 
4.137 b. 20,4.4721 c. no,z= -3.55 
d. 0 4.139 $9.6582 4.141 a. .0918 b. 0 c. 4.87decibels 4.143 a. ,221199 
b. .002394 c. .082085 4.145 No 4.147 a. nothing about shape b. approximately normal c. ,2843 d. .I292 
Chapter 5 
5.1 a. 1.645 b. 2.58 c. 1.96 
5.5 a. 33.9 f .65 b. 33.9 f .32 c width is halved 5.7 d. claim probably not true 5.9 (.3526, .4921) 5.11 a. 66.83 & 4.69 
c. (41.009,49.602) 5.13 a. 2.228 b. 2.228 c. -1.812 
d. 1.725 e. 4.032 5.15 a. 97.94 f 4.24 b. 97.94 
6.74 
5.17 a. 2.886 f 4.034 b. .408 f .256 5.19 a. 49.3 f 8.6 b. 99% confident that the mean amount removed from all 
S( 
is 
5. 
31 
5. 
5. 
C 
6. 
c 
je 
C. 
C. 
d. 
6..
f. 
ce 
PI 
6.:
H 
6.1 
d. 
6.'
6.1 
b. 
6.!
CI
7.:
e. 
d. 
b. 
d. 
ed
f0l 
b. 
no
7.: 
7.2 
b. 
do
d. 
m: 
7.6 
saI
7.7 
F.3 
C. 
vic
b. 
C. 
7.9
Ha 
rej

A n s w e r s  t o  S e l e c t e d  E x e r c i s e s  
743 
soil specimens using the poisofi is between 40.70% and 57.90%. 5.21 184.99 f 133.93 5.23 a. 22.46 f 11.18 d. validity 
issuspect 5.25 a. yes b. no c. yes d. no 5.27 a. yes b. .46 f .065 5.29 b. .29 f .028 5.31 a. .24 b. .24 f ,181 
5.33 .85 * ,002 5.35 308 5.37 a. 68 b. 31 5.39 34 5.41 a. .226 f .007 b. ,014 c. 1,680 5.43 1,692 5.45 43; 171; 
385 5.47 no 5.49 a. -1.725 
b. 3.250 c. 1.860 d. 2.898 5.51 a. 32.5 f 5.16 b. 23,964 5.53 a. (298.6,582.3) 
5.55 a. 376 f ,003 5.57 a. men: 7.4 f .979; women: 4.5 f .755 h. men: 9.3 f 1.185; women: 6.6 f 1.138 
559 a. 12.2 f 1.645 b. 167 5.61 a. 191 5.63 b. 3.256 f .348 5.65 154 
Chapter 6 
6.1 null; alternative 6.3 a 6.7 no 6.9 H,: p = .lo, Ha: p < .10 6.11 c. a e. decrease f. increase 6.13 a. unsafe; safe 
c a 6.15 g. ,025, .05, ,005, .lo, .lo, .O1 6.17 a. z = 1.67, reject H, b. z = 1.67, do not reject H,, 6.19 z = - 1.86, do not re- 
ject H, 6.21 a. H,: p = 16, Ha: p < 16 b. z = -4.31, reject H, 6.23 a. yes,z = 7.02 6.25 a. H,: p = 10, Ha: p < 10 
c. z = -2.34, reject H,, 6.27 a. skewed to the right b. yes, z = 1.75 c. yes, no 6.29 a. do not reject H, b. reject H, 
c. reject H, d. do not reject H, e. do not reject H,, 6.31 .0150 6.33 a. do not reject H,, b. reject H,, c. reject H, 
d. do not reject H, 6.35 b. reject H,, c. reject Hu 6.37 a. H,: p = 2.5, Ha: p > 2.5 b. 0 c. reject H, 
6.39 a. H,: y = 16.5, H,:p > 16.5 b. ,0681 6.43 a. ltl > 2.160 b. t > 2.500 c. t > 1.397 d. t < -2.718 
e. It1 > 1.729 
f. t < -2.353 
6.45 b. p-value = .0382, reject H, c. .0764, reject H, 6.47 a. t = -1.79, reject H,, b. population o f  per- 
cent repellencies is normally distributed 
6.49 yes, t = 8.75 6.51 a. H,: p = .004, Ha: p > .004 c. plant 1: do not reject H,,; 
plant 2: do not reject H, 6.53 a. yes 
b. no c. yes 
d. no e. no 6.55 a. z = 1.13, do not reject H, b. ,1292 
6.57 a. no,z = 1.14 b. .I271 6.59 z = 33.47, reject H,, 6.61 a. z = -2.22, do not reject H, b. .0132 6.63 a. H,: p = .5, 
Ha: p < .5 b. do not reject H,, 6.65 a. ,035 b. ,363 c. ,004 d. .I51 e. .2119 6.67 p-value = .054; reject H, 
6.69 a. H,: 77 = 5, Ha: q > 5 b. 0 c. reject H, 6.71 a. sign test b. H,: q = 30, Ha: 7 < 30 c. S = .5, p-value < .O1 
d. p-value = ,109, do not reject H, 6.73 alternative 6.75 a. t = -7.51, reject Ha b. t = -7.51, reject H, 
6.77 a. z = -1.67, do not reject H, b. z = -3.35, reject H, 6.79 z = 1.20, do not reject Ho 6.81 a. yes, z = -1.93 
6.83 b. reject H,, at a = .05 c. Type I error 6.85 a. z = 12.97, reject H,: p = .5 b. 0 c. .6844 6.87 a. no, z = 1.41 
b. small c. .0793 6.89 a. No, z = -3.47 
6.91 a. H,: p = 1, Ha: p > 1 b. t > 1.345 d. t = 2.408, reject H,, 
6.93 a. H,: p = 209,700, Ha: p > 209,700 b. p-value = ,0188, reject Ho 
Chapter 7 
7.1 a. 35 + 24.5 b. z = 2.8,~-value = .0052, reject H, c. p-value = .0026 d. z = .8,p-value = .4238, do not reject H,, 
e. independentrandomsamples 7.3 a. no b. no c. no d. yes e. no 7.5 a. ,5989 b. yes,t = -2.39 
c. -1.24 f .98 
d. confidence interval 7.7 a. p-value = .115O, do not reject H ,  b. .0575 7.9 a. p-value = .1114, do not reject H, 
b. -2.50 k 3.12 7.11 a. HO: p, = p2. Ha: p, f p2 b. z = 7.71, reject Ha c. .51 f .14 7.13 a. yes,t = 1.9557 c. ,0579 
d. -7.4 k 6.38 7.15 a. yes 
b. t = 19.73, reject H,, 7.17 No significant difference for utili~ation of information, age, and 
education 7.19 a. beginning: 6.09 f 41.84; first: -52.24 f 40.84; second: -48.41 f 40.64; third: -37.68 f 39.78; 
fourth: -38.54 + 42.96 7.21 a. t > 1.796 b. t > 1.319 c. t > 3.182 d. t > 2.998 7.23 a. H,: p, = 0, Ha: p, < 0 
b, t = -5.29,~-value = ,0002, reject H,, c. (-5.284, -2.116) 
d. population o f  differences is normal 7.25 a. t = 31, do 
not reject H, b. p-value 2 .20 7.27 a. yes, t = 2.864 7.29 a. H,: p, = 0, Ha: p, < 0 b. t = -2.948, reject H, 
7.31 a. H,: p, = 0, Ha: p, # 0 b. t = 5.76, reject H, c. yes 
7.33 p-value = 0.65, do not reject H, 7.35 34 7.37 27 
7.39 n = 21 7.41 293 7.43 a. F > 2.19 b. F > 2.75 c. F > 3.37 d. F > 4.30 7.45 a. F = 2.26, do not reject Ho 
b. .I0 < p-value < .20 7.47 a. equal variances b. H,,: u: = a;, Ha: (T: 
# a; c. F = 28.22, reject Ho 7.49 a. F = 2.26, 
do not reject H,, 7.51 a. F = 8.29, reject H,, b. no 7.53 a. T2; T2 5 35 or T, 2 67 b. TI; TI 2 43 c. T2; T2 2 93 
d. z;lzi > 1.96 7.57 a. No, T2 = 105 b. less than .05 7.59 b. p-value = .0564, do not reject H, c. populations are nor- 
mal with equal variances; assumption o f  normality may be violated 
7.61 yes, TI = 39; yes 7.63 a. z = 1 . 7 5 ,  reject H, 
7.65 a. H,: Two sampled populations have identical probability distributions b. T- = 3.5, reject H, 7.69 a. H,,: Two 
sampled populations have identical probability distributions b. z = 2.499, reject H,, c. ,0062 7.71 T- = 3.5, reject H, 
7.73 T+ = 2, reject H, 7.75 No,p-value = .I728 7.77 dot plot b 7.79 a. MSE, = 2, MSEb = 14.4 b. t, = -6.12, 
Fa = 37.5; tb = -2.28, F, = 5.21 c. It1 > 2.228, F > 4.96 d. reject H,,; reject H, 7.81 a. 4;38 b. F = 14.80, reject H,, 
c. sample means 7.83 Do not reject H,: p, = p2 = p,, F = 1.62,~-value = .209; assumption of equal variances may be 
violated 7.85 a. Infrequency: reject H,,; obvious: reject H,; subtle: reject H,,; obvious-subtle: reject H,; dissimulation: reject H, 
b. no 7.87 a. H,: p, = p2 = pj = p4 = p5 = p6 b. no d. designed 
7.89 a. t = .78, do not reject Ha b. 2.50 f 8.99 
C. 225 7.91 a. 3.90 f .31 b. z = 20.60, reject H,, c. 346 7.93 a. t = 5.73, reject H,, b. 3.8 f 1.84 7.95 No, T = 1.5 
7.97 b. yes 
c. no 7.99 a. yes, = 7.679 b. .000597 d. .4167 f .I395 e. T = 0, reject H, 7.101 a. H,: p, - p, = 0, 
Ha: p1 - p2 # 0 b. z = -7.69, reject H, 7.103 initial performance: z = 5.68, reject H,,; rate of career advancement: z = 5.36, 
reject Ho; final performance appraisal: z = 10.63, reject H, 7.105 a. yes, t = -4.02 
h. ,0030 7.107 yes, T,,,,, 
= 132.5 

744 
A n s w e r s  t o  S e l e c t e d  E x e r c i s e s  
I 
7.109 a. H,: p~ = 0, Ha: pc~, > 0 b. paired difference c. Aad: do not reject H, for a = .05; Ab: reject H, for a = .05: In- 
tention: do not reject Ho for a = .05 
Chapter 8 
8.3 a. z < -2.33 
b. z < -1.96 
c. z < -1.645 
d. z < -1.28 
8.5 a. .07 f .067 b. .06 f .086 c. -.I5 f ,131 
8.7 z - 1.14, do not reject H, 
8.9 a. p, - p2 8.11 b. yes c. .19 f .02 d. normal approximation not adequate 
8.13 a. yes b. -.0568 f .0270 8.15 yes,z = -2.25 
8.17 a. n, = n2 = 29,954 b. n, = n2 = 2,165 c. n, = n2 = 1,113 
8.19 a. n, = n2 = 911 b. no 8.21 n, = 520, n, = 260 8.23 a. 18.3070 b. 29.7067 c. 23.5418 d. 79.4900 
8.25 b. E(n,) 2 5 8.27 a. X2 = 3.293 8.29 a. 111,74,74,37,37,37 b. 13.541 c. reject H, 
8.31 a. yes, 
X2 = 87.74, p-value = 0 b. .539 f .047 8.33 a. H": p, = p2 = p3 = p, = .25 b. X2 = 14.805, reject H, 
c. Type I error: 
conclude opinions of Internet users are not evenly divided among four categories when they are;Type I1 error: conclude opin- 
ions of Internet users are evenly divided among four categories when they are not; 8.35 X2 = 16, p-value = ,003, reject H, 
8.37 a. X2 = 12.734, do not reject H, 
b. .05 < p-value < .10 8.39 a. H,: row and column classifications are independent 
b. X2 > 9.21034 c. 14.37,36.79,44.84,10.63,26.21,33.16 d. X2 = 8.71, do not reject H, 
8.41 yes, X2 = 256.336 
8.43 a. ,901 b. ,690 d. X2 = 48.191, reject H, 
e. .211 f .070 8.45 b. X2 = 45.357, p-value = 0, reject Ho 
8.47 a. X2 = 39.22, reject H, 
b. X2 = 2.84, do not reject HI, 8.49 yes,x2 = 24.524 8.51 a. no,X2 = 2.133 b. ,233 f .057 
8.53 542 8.55 X2 = 19.10, reject Ho 8.57 union: X2 = 13.37, p-value = .038, reject H,; nonunion: X2 = 9.64, p-value = ,141, 
do not reject H,, 
8.59 a. no c. HI,: Jan. change and next 11-month change are independent d. X2 = 2.373, do not reject H, 
e. yes 
Committee 
Committee 
Totals 
Accept 
Reject 
Inspector Accept 
101 
23 
124 
Inspector Reject 
10 
19 
29 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Totals 
111 
42 
153 
b. yes c. X2 = 26.034, reject HI, 8.63 a. yes, X2 = 47.98 b. .I25 f .046 
Chapter 9 
9.3 P, = 113, P, = 1413, y = 1413 + 113x 9.9 no 9.11 a. 
( y  - 3) = 0.02, SSE = 1.2204 c. SSE = 108.00 
9.13 b. negative linear relationship 
c. -.9939,8.543 
e. range of x: 2 to 8 9.15 a. positive c. -205.777,1057.367 
9.17 b. 9 = 16.593 + 1.949~ d. 45.828 9.19 b. jj = 569.5801 - ,00192~ e. range of x: $16,900 to $70,000 
9.21 b. -51.362,17.754 
9.23 a. .3475 b. 1.179 9.25 10.10: SSE = 1.22, s2 = .2441, s = .4960; 10.13: SSE = 5.713, 
s2 = 1.143, s = 1.069 9.27 a. 
jj = 7.381 + .373x b. $604.181 billion c. SSE = 2,225.63, s2 = 27.24 
9.29 a. SSE = 20,554.415, s2 = 2,055.442, s = 45.337 9.31 a. 95% CI: 31 f 1.13;90% CI: 31 f .92 b. 95% CI: 64 f 4.28; 
90% C1: 64 f 3.53 c. 95% CI: -8.4 f .67;90% CI: -8.4 f .55 9.33 .82 f .76 9.35 a. yes b. jj = -3,284.5 + 451.4~ 
c. yes,t = 7.57 e. 451.4 f 104.5 9.37 a. support b. jj = 15.878 + .927x c. yes, t = 2.45 d. 0 and l 9.39 a. yes, 
t = 4.98,~-value = .001 b. .607 9.41 a. t = 3.384,~-value = .0035, reject H(, b. 17.75 + 16.63 9.43 yes, t = -.96 
9.45 a. positive b. negative 
c. 0 slope d. positive or negative 9.47 a. ,9438 b. 2020 9.49 a. very weak positwe 
linear relationship 
b. weak positive linear relationship 9.51 b. -.420 
d. ,1764 9.53 r2 = 0.2935, r = -.5418 
9.55 a. yes b. -.423 
9.57 b. 
jj = 1.5 + .946x c. 2.221 d. 4.338 f 1.170 e. 4.338 f 3.223 f. prediction interval 
for y 9.59 a. 2.2 f 1.382 d. t = 6.10, reject H,, 9.61 b. 
jj = 5,566.13 - 210.346~ c. t = -8.69, p = 0, reject H, 
d. 3437 e. (3,714.7,4,052.0) f. (3,364.1,4,402.7) 9.63 a. (12.6384,239.7) b. narrower c. no 9.65 a. yes,t = -5.91; 
negative b. (.656,2.829) c. (1.467,2.018) 9.67 a. .O1 b. .O1 c. .975 d. .05 9.69 a. .4 b. -.9 
c. -.2 
d. .2 
9.71 a. -.485 
b. reject H, 
9.73 r, = -.607, do not reject H,, 9.75 b. r, = .972, reject H, 
9.77 a. 3 = 37.08 - 1.6~ 
c 57.2 d. 4.4 e. -1.6 =k .5 f. 13.08 f 6.03 g. 13.08 f 7.86 9.79 b. r = -.1245, r2 = .0155 c. no,t = -.35 
d. -.091 
9.81 b. jj = 12.594 + .10936x c. yes,t = 3.50 d. 28.99 f 12.50 9.83 jj = -92.46 + 8.35x, reject H,,p-value = .0021 
9.85 a. jj = 3.068 - .015x c. t = -3.32, reject H,, d. 2.913 f .207 9.87 a. 57.14 f 34.82 b. 110 is outside range of x 
c. i = 44 9.89 ,8574 9.91 machine hours: t = 3.30, p = ,008, reject Ho, r2 = S21; labor hours: t = 1.43, p = ,183, do not 
reject H,, r2 = ,170 

I 
A n s w e r s  t o  S e l e c t e d  E x e r c i s e s  
745 
Chapter 10 
10.1 a E ( y )  = PO + PIXI + P 2 ~ 2  b. E(Y) = PO + PIXI + P2x2 + P3x3 + P 4 ~ 4  c E(Y) = DO + PIXI + P2x2 + P 3 ~ 3  + P 4 ~ 4  + 
pjx, 10.3 a. t = 1.45, do not reject HI) b. t = 3.21, rejcct HIl 10.5 n - (k + 1) 10.7 a. E(y) = PO + P,x, + P2x2 
b. ji = -20.352 + 13.3504~~ 
+ 243.714~~ 
d. no,t = 1.74 e. (49.69,437.74) 10.9 a 7 = 20.9 + 0 . 2 6 1 ~ ~  
- 7 . 8 ~ ~  
+ .0042x3 
b. 14.01 c. no,t = 1.09 10.11 a. 7 = 12.2 - .0265x, - .458x, 
c. t = -.50,p = ,623, donot reject H, d. -.458 f ,347 
e. x, = 1 if plants, 0 if not 10.15 a. 7 = 93,074 + 4 , 1 5 2 ~ ~  
- 855x2 + .924x3 + 2 , 6 9 2 ~ ~  
+ 1 5 . 5 ~ ~  
b. 33,225.9 c. yes, 
t = 2.78,~-value = .0059 f. t = -2.86, reject H, g. .00495 10.17 a. .8911 b. .8775 c. F = 65.462, reject HI, d. ,0001 
10.19 b. F = 8.321, reject H, 
10.19 a. 
10.21 a. ,8168 b. HI): 0, = P2 = 0 
Source 
d f 
SS 
M S 
F 
c. F = 31.22, p = .0000069 d. reject 
............................................................................................................ ; R2 = .4947; Ri = .4352 
H,, 
10.23 a. 7 = -4.30 - .002x1 + 
Model 
2 
12.09 
6.045 
8.321 
.336x2 + , 3 8 4 ~ ~  
+ , 0 6 7 ~ ~  
- , 1 4 3 ~ ~  
+ 
Error 
17 
12.35 
.72647 
.081x6 + .134x7 b. F = 111.1, reject 
............................................................................................................ 
19 
24.44 
H,) d. t = 1.76,~-value = ,079, do 
Total 
not reject H, 
e. no, t = -.049, 
p-value = ,961 10.25 a. 51 % of the 
variability in operating margins can be explained by the model b. F = 13.53, reje~t HO 10.27 F = 1.06. do not reject HO 
10.29 a. R~ = ,529; R: = S05; Ri b. F = 21.88,~-value = 0, reject H, 10.31 a. (1,759.7,4,275.4) b. (2,620.3,3,414.9) 
c. yes 10.33 (-1.233,1.038) 
10.35 a. F = 72.11, reject HtI 10.37 yes 10.41 a. yes 10.43 a. no b. yes c. no d. yes; 
26th household e. no 10.45 confidence interval 10.47 a. 7 = 90.1 - 1.836x, + .285x, b. .916 c. yes, F = 64.91 
d. t = -5.01, reject H, 
e. 10.677 10.49 no degrees of freedom for error 10.51 a. E(y) = PI, + P,x, + P2x2 + P3x3 
+ p,x, + P5xs b. reject HI,: PI = P2 = P3 = P4 = PS = 0 c E(Y) = PO + P+I + P Z ~ Z  
+ P 3 ~ 3  + P 4 ~ 4  + PSXS + P& + P7x7 
d. 60.3% of the variability in GSI scores is explained by the model e. both variables contribute to the prediction of GSI 
10.53 Importance and Support are correlated at ,6991; no 10.55 a. E(y) = PI, + P,x, where x = (1 if H, 0 if L} 
b. 
= 10.575 + .917x c. yes,t = 3.38 10.57 c. yes,F = 39.505,~-value = ,000 d. x, = 60: 7 = .47 + .026x,; 
X, = 75: 7 = .98 + .026x,; x, = 90: 
= 1.49 + .026x, e. add x: 
Chapter 11 
11.7 out of control 11.9 a. 1.023 b. 0.308 c. 0.167 11.11 b. ? = 20.11625, R = 3.31 c. UCL = 22.529, LCL = 
17.703 d. Upper A-B: 21.725, Lower A-B: 18.507, Upper B-C: 20.920, Lower B-C: 19.312 e. yes 11.13 a. 2 = 23.9971, 
- 
R = .1815, UCL = 24.102, LCL = 23.892, Upper A-B: 24.067, Lower A-B: 23.927, Upper B-C: 24.032, Lower B-C: 23.962 
b. in control c. yes 11.15 a. 2 = 49.129, R = 3.733, UCL = 50.932, LCL = 47.326, Upper A-B: 50.331, Lower A-B: 
47.927, Upper B-C: 49.730, Lower B-C: 48.528 b. no c. no 11.17 a. 2 = 52.6467, R = .755, UCL = 53.41 9, 
LCL = 51.874, Upper A-B: 53.162, Lower A-B: 52.132, Upper B-C: 52.904, Lower B-C: 52.389 b. out of control d. no 
11.21 a. UCL = 16.802 b. Upper A-B: 13.853, Lower A-B: 2.043, Upper B-C: 10.900, Lower B-C: 4.996 
c. in control 
11.23 R-chart: R = 4.03, UCL = 7.754, LCL = 0.306, Upper A-B: 6.513, Lower A-B: 1.547, Upper B-C: 5.271, Lower B-C: 
2.789. in control; T-chart: 2 = 21.728, UCL = 23.417, LCL = 20.039, Upper A-B: 22.854, Lower A-B: 20.602, Upper B-C: 
22.291, Lower B-C: 21.165, out of control 11.25 a. yes b. R = ,0796, UCL = .168, Upper A-B: .l39, Lower A-B: .020, 
Upper B-C: .109, Lower B-C: ,050 c. in control d. yes e. yes 11.27 a. R - 
= 2.08, UCL = 4.397, Upper A-B: 3.625, 
Lower A-B: ,535. Upper B-C: 2.853, Lower B-C: 1.307; in control b. yes c. R = 1.7, UCL = 3.594, Upper A-B: 2.963, 
Lower A-B: .437, Upper B-C: 2.331, Lower B-C: 1.069; out of control 11.29 a. R = 2.756, UCL = 5.826, Upper A-B: 
4.803,Lower A-B: ,709, Upper B-C: 3.780, Lower B-C: 1.732 b. variation 
c. in control 11.31 104 11.33 a. p = .0575, 
UCL = ,1145, LCL = ,0005, Upper A-B: .0955, Lower A-B: .0195, Upper B-C: .0765, Lower B-C: .0385 d. no e. no 
11.35 a. yes b. UCL = .02013, LCL = ,00081 c. Upper A-B: .01691, Lower A-B: .00403, Upper B-C: .01369, Lower 
B-C: ,00725; in control 11.37 a. p = .04, UCL = ,099, LCL = -.019, Upper A-B: .079, Lower A-B: .001, Upper B-C: 
.060, Lower B-C: .020 b. no 
c. no 11.49 a. 2 = 6.4 b. increasing variance 11.51 out of control 11.53 a. R = 7.4, 
UCL = 24.1758, Upper A-B: 18.5918, Lower A-B: -3.791 8. Upper B-C: 12.9959, Lower B-C: 1.8041; out of control 
b. x = 344.15, UCL = 358.062, LCL = 330.238, Upper A-B: 353.425, Lower A-B: 334.875, Upper B-C: 348.787, Lower B-C: 
339.513; out of control c. no d. .25 11.55 a. R = 5.455, UCL = 11.532, Upper A-B: 9.508, Lower A-B: 1.402, Upper B-C: 
7.481, Lower B-C: 3.429 b. in control d. x = 3.867, UCL = 7.015, LCL = .719, Upper A-B: 5.965, Lower A-B: 1.769, 
Upper B-C: 4.916, Lower B-C: 2.818 e. in control f. yes 11.57 a. n > 141 b. p = ,063, UCL = ,123, LCL = ,003, 
Upper A-B: ,103, Lower A-B: .023, Upper B-C: .083, Lower B-C: .043 c. out of control e. no 

HL
Ish 

Chapter 1 
Careers In Statistics. American Statistical Association, Bio- 
metric Society, Institute of Mathematical Statistics and 
Statistical Society of Canada, 1995. 
Chervany,N.L., Benson, P.G., and Iyer, R.K. "The planning 
stage in statistical reasoning." The American Statistician, 
Nov. 1980, pp. 222-239. 
Ethical Guidelines for Statistical Practice. American Statis- 
tical Association, 1995. 
Tanur, J.M., Mosteller, F., Kruskal, W.H., Link, R.F., Pieters, 
R.S., and Rising, G.R. Statistics:A Guide to the Un- 
known. (E.L. Lehmann, special editor.) San Francisco: 
Holden-Day, 1989. 
US. Bureau of the Census. Statistical Abstract of the United 
1 I 
States: I998 Washington, D C.: US Government Print- 
ing Office, 1998. 
What 1s a Survey? Section on Survey Research Methods, 
American Statistical Association, 1995. 
Chapter 2 
Adler, P. S., and Clark, K. B. "Behind the learning curve: A 
sketch of the learning process." Management Science, 
March 1991, p. 267. 
Alexander, G. J., Sharpe, W. E, and Bailey, J.V. Fundamen- 
tals of Investments, 2nd ed. Englewood Cliffs, N.J.: Pren- 
tice-Hall, 1993. 
Deming, W. E. Out of the Crisis. Cambridge, Mass: M.I.T. 
Center for Advanced Engineering Study, 1986. 
Fogarty, D. W., Blackstone, J. H., Jr., and Hoffman,T. R. 
Production and Inventory Management. Cincinnati, 
Ohio: South-Western, 1991. 
Gaither, N. Production and Operations Management, 7th ed. 
Belmont. Calif: Duxbury Press, 1996. 
Gitlow, H., Oppenheim, A., and Oppenheim, R. Quality Man- 
agement: Methods for Improvement, 2nd ed., Burr Ridge, 
Ill.: Irwin 1995. 
Huff, D. How to Lie with Statistics. New York: Norton, 1954. 
Ishikawa, K. Guide to Quality Control, 2nd ed. White Plains, 
N.Y.: Kraus International Publications, 1982. 
Juran, J. M. Juran on Planning for Quality. New York: The 
Free Press, 1988. 
Mendenhall, W. Introduction to Probability and Statistics, 
9th ed. North Scituate, Mass.: Duxbury, 1994. 
Schroeder, R. G. Operations Management, 4th ed. New York: 
McGraw-Hill, 1993. 
Tufte, E. R. Visual Explanations. Cheshire, Conn.: Graphics 
Press, 1997. 
Wasserman, P., and Bernero, J. Statistics Sources, 5th ed. 
Detroit: Gale Research Company, 1978. 
Zabel, S. L. "Statistical proof of employment discrimination." 
Statistics:A Guide to the Unknown, 3rd ed. Pacific Grove, 
Calif.: Wadsworth, 1989 
Chapter 3 
Benson, G. "Process thinking: The quality catalyst." Min- 
nesota Management Review, University of Minnesota, 
Minneapolis, Fall 1992. 
Feller, W. A n  Introduction to Probability Theory and Its 
Applications, 3d ed.,Vol. 1. New York: Wiley, 1968. 
Kotler, Philip. Marketing Management, 8th ed. Englewood 
Cliffs, N.J.: Prentice Hall, 1994. 
Kuehn, A. A. "An analysis of the dynamics of consumer be- 
havior and its implications for marketing management." 
Unpublished doctoral dissertation, Graduate School of 
Industrial Administration, Carnegie Institute of Tech- 
nology, 1958. 
Lindley, D.V. Making Decisions, 2d ed. London: Wiley, 
1985. 
Parzen, E. Modern Probability Theory and Its Applica- 
tions. New York: Wiley, 1960. 
Scheaffer, R. L., and Mendenhall, W. Introduction to Proba- 
bility: Theory and Applicahons. North Scituate, Mass.: 
Duxbury, 1975. 
Stickney, Clyde P., and Weil, Roman L. Financial Account- 
ing: A n  Introduction to Concepts, Methods, and Uses, 7th 
ed. Fort Worth: The Dryden Press, 1994. 
Williams, B. A Sampler on Sampling. New York: Wiley, 1978. 
Winkler, R.L. An Introduction to Bayesian Inference and 
Decision. New York: Holt, Rinehart and Winston, 1972. 
Chapter 4 
Alexander, G. J., and Francis, J. C. Portfolio Analysis. Engle- 
wood Cliffs, N.J.: Prentice Hall, 1996. 
Alexander, G. J., Sharpe, W. F., and Bailey, J.V. Fundamen- 
tals of Investments, 2nd edition, Englewood Cliffs, N.J.: 
Prentice Hall, 1993. 

Blume, M. "On the assessment of risk." Journal ofFinance, 
Mar. 1971,26, pp. 1-10. 
Camm, J. D., and Evans, J. R. Management Science: Model- 
ing, Analysis, and Interpretation. Cincinnati: South-West- 
ern, 1996. 
Clauss, Francis, J. Applied Management Science and Spread- 
sheet Modeling. Belmont, Calif.: Duxbury Press, 1996. 
Cowling, A., and James, P. The Essence of Personnel Man- 
agement and Industrial Relations. New York: Prentice 
Hall, 1994. 
Edwards, Jr., J. P., ed. Transportation Planning Handbook. 
Englewood Cliffs, N.J.: Prentice Hall, 1992. 
Elton, E. J., and Gruber, M. J. Modern Portfolio Theory and 
Investment Analysis. New York: Wiley, 1981. 
Herrnstein, R. J., and Murray, C. The Bell Curve. New York: 
The Free Press, 1994. 
Hogg, R. V., and Craig, A. T. Introduction to Mathematical 
Statistics, 4th ed. New York: Macmillan, 1978. 
Lindgren, B. W. StatisticalTheory, 3d ed. New York: 
Macmillan, 1976. 
Mendenhall, W. Introduction to Mathematical Statistics, 
8th ed. Boston: Duxbury, 1991. 
Mendenhall, W., Wackerly, D., and Scheaffer, R. L. Mathe- 
maticul Statistics with Applications, 4th ed. Boston: 
PWS-Kent, 1990. 
Mood,A. M., Graybill, E A., and Boes, D. C. Introduction 
to the Theory of Statistics, 3d ed. New York: McGraw- 
Hill, 1974. 
Moss, M. A. Applying TQM to Product Design and Devel- 
opment. New York: Marcel Dekker, 1996. 
Veter, J., Wasserman, W., and Whitmore, G. A. Applied Sta- 
tistics, 4th ed. Boston: Allyn & Bacon, 1993. 
'arzen, E. Modern Probability Theory and Its Applications. 
New York: Wiley, 1960. 
Zadcliffe, Robert C. Investments: Concepts, Analysis, and 
Strategy, 4th ed. New York: HarperCollins, 1994. 
Zamsey, P. P., and Ramsey, P. H. "Simple tests of normality 
in small samples." Journal of Quality Technology, Vol. 
22,1990, pp. 299-309. 
Zender, B., and Heizer, J. Principles of Operations Manage- 
ment. Englewood Cliffs, N. J.: Prentice Hall, 1995. 
Zoss, S. M. Stochastic Processes, 2d ed. New York: Wiley, 1996. 
Nillis, R. E., and Chervany, N.L. Statistical Analysis and 
Modeling for Management Decision-Making. Belmont, 
Calif.: Wadsworth, 1974. 
Ninkler. R. L., and Hays, W. Statistics: Probability, Znfer- 
ence, and Decision, 2d ed. New York: Holt, Rinehart and 
Winston, 1975. 
igrcsti, A., and Coull, B. A. "Approximate is better than 
'exact' for interval estimation of binomial proportions." 
The American Statistician, Vol. 52, No. 2, May 1998, 
pp. 119-126. 
Zochran, W. G. Sampling Techniques, 3d ed. New York: 
Wiley, 1997. 
Deming, W. E. Out of the Crisis. Cambridge, Mass.: MIT 
Center for Advanced Study of Engineering, 1986. 
Freedman, D., Pisani, R., and Purves, R. Statistics. New York: 
Norton, 1978. 
Kish, L. Survey Sampling. New York: Wiley, 1965. 
Mendenhall, W., and Beaver, B. Introduction to Probability 
and Statistics, 8th ed. Boston: PWS-Kent, 1991. 
Wilson, E. G. "Probable inference, the law of succession, 
and statistical inference." Journal of the American Statis- 
tical Association, Vol. 22,1927, pp. 209-212. 
Chapter 6 
Alexander, Gordon J., Sharpe, William F., and Bailey, Jef- 
fery. Fundamentals of Investments, 2nd ed. Englewood 
Cliffs, N.J.: Prentice Hall, 1993 
Conovcr, W. J. Practical Nonparametric Statistics, 3rd ed. 
New York: Wilcy, 1999. 
Daniel, W. W. Applied Nonparametric Statistics, 2nd ed. 
Boston: PWS-Kent, 1990. 
Mendenhall. W., Wackerly, D., and Scheaffer, R. Mathemati- 
cal Statistics with Applications, 4th ed. Boston: PWS- 
Kent, 1990. 
Snedecor, G. W., and Cochran, W. G. Statistical Methods, 7th 
ed. Anics: Iowa State University Press, 1980. 
Chapter 7 
Conover, W. J. Practical Nonparametric Statistics, 2nd ed. 
New York: Wiley, 1980. 
Freedman, D., Pisani, R., and Purves, R. Statistics. New York: 
W. W. Norton and Co., 1978. 
Gibbons, J. D. Nonparametric Statistical Inference, 2nd ed. 
New York: McGraw-Hill, 1985. 
Hollander, M., and Wolfe, D. A. Nonparametric Statistical 
 method^. New York: Wiley, 1973. 
Mendenhall, W. Introduction to Linear Models and the De- 
sign and Analysis of Experiments. Belmont, Calif.: 
Wadsworth, 1968. 
Mendenhall, W. Introduction to Probability and Statistics, 
8th ed. Boston: PWS-Kent, 1991. 
Miller, R. G., Jr. Simultaneous Statistical Inference. New York: 
Springcr-Verlag, 1981. 
Neter, J., Kutner, M., Nachtsheim, C., and Wasserman, W. 
Applied Linear Statistical Models, 4th ed. Homewood, 
Ill.: Richard D. Irwin, 1996. 
Satterthwaite, F. W. "An approximate distribution of esti- 
mates of variance components." Biometries Bulletin, 
Vol. 2,1946, pp. 110-114. 
ScheffC, H. "A method for judging all contrasts in the 
analysis of variance," Biometrica, Vol. 40.1953, pp. 
87-1 04. 
Snedecor, G. W., and Cochran, W. Statistical Methods, 7th 
ed. Ames: Iowa State University Press, 1980. 
Steel, R. G. D., and Torrie, J. H. Principles and Procedures 
of Statistics, 2nd ed. New York: McGraw-Hill, 1980. 
Stevenson, William J. Pmduction/Operations Management, 
5th ed. Chicago: Irwin. 1996. 
Tllk 
1 
Wir 
t 
Ch< 
Ag1 
coc 
1 
Cor 
I 
Hol 
1 
Sav 
I 
Sch 
I 
Siei 
f 
Chi 
Chz 
I 
Dra 
Gitl 
i 
L 
Gra 
r 
Hor 
i 
Kle 
L 
2 
Lee 
c 
( 
Mer 
S 
1 
Me1 
t, 
P 
Min 
k 
Netc 
s 
I 
Wei 
\ 
Chi 
Barr 
\ 

%key, J."Comparing individual means in the analysis of 
variance," Biometrics, Vol. 5,1949. pp. 99-114. 
Winer, B. J. Statistical Principles in Experimental Design, 2d 
ed. New York: McGraw-Hill, 1971. 
Chapter 8 
Agresti, A.. Categorical Data Analysis. New York: Wiley, 1990. 
Cochran, W.G. "The test of goodness of fit." Annals of 
Mathematical Statistics, 1952,23. 
Conover, W.J. Practical Nonparametric Statistics, 2nd ed. 
New York: Wiley, 1980. 
Hollander, M., and Wolfe, D. A. Nonparametric Statistical 
Methods. New York: Wiley, 1973. 
Savage, I.R. "Bibliography of nonparametric statistics and 
related topics." Journal of the American Statistical Asso- 
ciation, 1953,48. 
Schroeder, R. G. Operations Management, 4th ed. New York: 
McGraw-Hill, 1993. 
Siegel, S. Nonparametric Statistics for the Behavioral Sci- 
ences. New York: McGraw-Hill, 1956. 
Chapter 9 
Chatterjee, S., and Price, B. Regression Analysis by Exam- 
ple, 2nd ed. New York: Wiley, 1991. 
Draper, N., and Smith, H. Applied Regression Analysis, 
2nd ed. New York: Wiley, 1981. 
Gitlow, H., Oppenheim, A., and Oppenheim, R. Quality 
Management: Tools and Methods for Improvement, 
2nd ed. Burr Ridge, Ill.: Irwin, 1995. 
Graybill, F. Theory and Application of the Linear Model. 
North Scituate, Mass.: Duxbury, 1976. 
Horngren, C.T., Foster, G., and Datar, S.M. Cost Account- 
ing, 8th ed. Englewood Cliffs, N.J.: Prentice Hall, 1994. 
Kleinbaum, D., and Kupper, L. Applied Regression Analysis 
and Other Mutivariable Methods, 2nd ed. North Scitu- 
ate, Mass.: Duxbury, 1997. 
Lee, C., Finnerty, J. and Norton, E. Foundations of Finan- 
cial Management. Minneapolis, Minn.: West Publishing 
Co., 1997. 
Mendenhall, W. Introduction to Linear Models and the De- 
sign and Analysis of Experiments. Belmont, Ca.: 
Wadsworth, 1968. 
Mendenhall, W. and Sincich, T. A Second Course in Statis- 
tics: Regression Analysis, 5th ed. Upper Saddle River, 
N.J.: Prentice Hall, 1996. 
Mintzberg, H. The Nature of Managerial Work. New York: 
Harper and Row, 1973. 
Neter, J., Wasserman, W., and Kutner, M. Applied Linear 
Statistical Models, 3rd ed. Homewood, Ill.: Richard 
Irwin, 1992. 
Weisburg, S. Applied Linear Regression, 2nd ed. New York: 
Wiley, 1985. 
Chapter 10 
Bamett,V., and Lewis,T. Outliers in Statistical Data. New York: 
Wiley, 1978. 
Belsley, D.A., Kuh, E., and Welsch, R. E. Regression Diag- 
nostics: Identiiving Influential Data and Sources of 
Collinearity. New York: Wiley, 1980. 
Chase, R. B., and Aquilano, N. J. Production and Operations 
Management, 6th ed. Homewood, Ill.: Richard D. Irwin, 
1992. 
Chatterjee, S., and Price, B. Regression Analysis by Exam- 
ple, 2d ed. New York: Wiley, 1991. 
Draper, N., and Smith, H. Applied Regression Analysis, 
2nd ed. New York: Wiley, 1981. 
Graybill, F. Theory and Application of the Linear Model. 
North Scituate, Mass.: Duxbury, 1976. 
Horngren, C. T., Foster, G., and Datar, S. M. CostAccount- 
ing, 8th ed. Englewood Cliffs, N. J.: Prentice Hall, 1994. 
Lee, C., Finnerty, J., and Norton, E. Foundations of Finan- 
cial Management. Minneapolis, Minn.: West Publishing 
Co., 1997. 
Mendenhall, W. Introduction to Linear Models and the 
Design and Analysis of Experiments. Belmont, Calif.: 
Wadsworth, 1968. 
Mendenhall, W., and Sincich, T. A Second Course in Statis- 
tics: Regression Analysis, 5th ed. Upper Saddle River, 
N.J.: Prentice-Hall, 1996. 
Neter, J., Kutner, M., Nachtsheim, C., and Wasserman, W. 
Applied Linear Statistical Models, 4th ed. Homewood, 
Ill.: Richard D. Irwin, 1996. 
Rousseeuw, P. J., and Leroy, A. M. Robust Regression and 
Outlier Detection. New York: Wiley, 1987. 
Weisberg, S. Applied Linear Regression, 2nd ed. New York: 
Wiley, 1985. 
Wonnacott, R. J., and Wonnacott,T. H. Econometrics, 2nd 
ed. New York: Wiley, 1979. 
Chapter 11 
Alwan, L.C., and Roberts H.V. "Time-series modeling for 
statistical process control." Journal of Business and Eco- 
nomic Statistics, 1988, Vol. 6, pp. 87-95. 
Banks, J. Principles of Quality Control. New York:Wiley, 
1989. 
Checkland, F! Systems Thinking, Systems Practice. New York: 
Wiley, 1981. 
Deming, W.E. Out of the Crisis. Cambridge, Mass.: MIT 
Center for Advanced Engineering Study, 1986. 
DeVor, R.E., Chang,T., and Southerland, J.W. Statistical 
Quality Design and Control. New York: Macmillan, 1992. 
Duncan, A.J. Quality Control and Industrial Statistics. 
Homewood, Ill.: Irwin, 1986. 
The Ernst and Young Quality Improvement Consulting 
Group. Total Qua1ity:An Executive's Guide for the 
1990s. Homewood, Ill.: Dow-Jones Irwin, 1990. 
Feigenbaum, A.B. Total Quality Control, 3rd ed. New York: 
McGraw-Hill, 1983. 
Garvin, D.A. Managing Quality. New York: Free Press1 
Macmillan, 1988. 
Gitlow, H., Gitlow, S., Oppenheim,A., and Oppenheim, R. 
Tools and Methods for the Improvement of Quality. 
Homewood, Ill.: Irwin, 1995. 

d 
Grant, E.L., and Leavenworth, R.S. Statistical Quality Con- 
trol, 6th ed. New York: McGraw-Hill, 1988. 
Hart, Marilyn K. "Quality tools for improvement." Produc- 
tion and Inventory Management Journal, First Quarter 
1992, Vol. 33, No. 1, p. 59. 
Ishikawa, K. Guide to Quality Control. 2nd ed. White 
Plains, N.Y.: Kraus International Publications, 1986. 
Joiner, B.L., and Goudard, M.A. "Variation, management, 
and W. Edwards Deming." Quality Process, Dec. 1990, 
pp. 29-37. 
Juran, J. M. Juran on Planning for Quality. New York: 
Free Press/Macmillan, 1988. 
Juran, J. M., and Gryna, F. M., Jr. Quality Planning Analysis, 
2nd ed. New York: McGraw-Hill, 1980. 
Kane,V. E. Defect Prevention. New York: Marcel Dekker, 
1989. 
Latzko, W. J. Quality and Productivity for Bankers and Fi- 
nancial Managers. New York: Marcel Dekker, 1986. 
Moen, R.D., Nolan,T. W., and Provost, L. P. Improving 
Quality Through Planned Experimentation. New York: 
McGraw-Hill, 1991. 
Montgomery, D. C. Introduction to Statistical Quality Con- 
trol, 2nd ed. New York: Wiley, 1991. 
Nelson, L. L. "The Shewhart control chart -Tests for spe- 
cial causes." Journal of Quality Technology, Oct. 1984, 
Vol. 16, No. 4, pp. 237-239. 
Roberts, H. V. Data Analysis for Managers, 2nd ed. Red- 
wood City, Calif.: Scientific Press, 1991. 
Rosander, A. C. Applications of Quality Control in the Ser- 
vice Industries. New York: Marcel Dekker, 1985. 
Rummler, G. A,, and Brache,A. F'. 
Improving Performance: 
How to Manage the White Space on the Organization 
Chart. San Francisco: Jossey-Bass, 1991. 
Ryan, T.P. Statistical Methods for Quality Improvement, 
New York: Wiley, 1989. 
Statistical Quality Control Handbook. Indianapolis, Ind.: 
AT&T Technologies, Select Code 700-444 (inquiries: 
800-432-6600); originally published by Western Electric 
Company, 1956. 
Wadsworth, H.M., Stephens, K. S., and Godfrey,A. B. Modem 
Methods for Quality Control and Improvement. New York: 
Wiley, 1986. 
Walton, M. The Deming Management Method. New York: 
Dodd, Mead, & Company, 1986. 
Wheeler, D. J., and Chambers, D. S. Understanding Statisti- 
cal Process Control. Knoxville, Tenn.: Statistical Process 
Controls, Inc., 1986. 

Additive rule of probability, 135 
Adjusted multiple coefficient of 
determination, 582 
Alternative hypothesis, 300,304 
steps for selecting, 307 
Analysis of variance (ANOVA), 
400-410 
calculation formulas for, 739 
F-test, 402-405 
robustness of, 410 
t-test, 404 
Assignable causes of variation, 
649 
Bar graphs, 28,30 
Pareto diagram, 31-32 
Base level, 572 
Bell Curve, The, 251,624-625 
Bell-shaped distribution. See 
Normal distribution 
Bias 
in estimates, 15 
nonresponse, 16 
Binomial 
distribution, 181-192 
experiment, 181 
tables, 187-190 
Binomial probabilities 
table, 712-715 
using graphing calculator for, 
97-99 
using normal distribution to ap- 
proximate, 229-230 
Binomial random variable(s), 
181-182 
characteristics of, 181-182 
mean for, 185 
standard deviation for, 185 
tables, 187-190 
variance for, 185 
Bivariate relationships, 94-97,505 
Bound B, 287 
Bound on estimation error, 8 
Box plots, 84-91 
elements of, 86 
interpretation of, 87 
using graphing calculator for, 91 
Car & Driver's "Road Test Digest," 
104 
Causal relationship, 508 
Census, 5 
Centerline, in time series chart, 643 
Central Limit Theorem, 242-248 
Central tendency, 332 
measures of, 52-59 
Chebyshev, P. L., 70 
Chebyshev's Rule, 70,72 
for discrete random variables, 175 
Children Out of School in America, 
104 
Chi-square ( X 2 )  
critical values of (table), 724-725 
test, 438-439,448 
Class (of data), 26 
Class frequency, 26 
Class relative frequency, 26-27 
Cluster sampling, 182 
Cockroach movement pattern 
analysis, 4 16-417 
Coded variable (x3), 558 
Coefficient 
of correlation, 505-509 
of determination, 509-511 
practical interpretation of 
(r2), 511 
population rank correlation, 536 
Spearman's rank correlation co- 
efficient (r,), 533-538 
Combinations rule, 705 
Combinatorial mathematics, 127 
Combinatorial rule, 127 
Common causes of variation, 649 
Complement, 130 
Complementary events, 134 
Compound events, 130 
Conditional probability, 140-143 
formula, 141 
Condominium sales case, 634-635 
Confidence coefficient, 262 
Confidence interval(s) 
for a p parameter, 568 
defined, 262 
graphing, 274-275 
large-sample 
for a population mean, 
260-265 
for a population proportion, 
279 -284 
for paired difference experiment, 
366 
in simple linear regression, 519 
of slope PI, 499 
small-sample, for a population 
mean, 268-274 
using graphing calculator to find 
population mean, 274-275 
population proportion, 284 
Confidence level, 262 
Conformation to specification, 654 
Consumer Price Index (CPI), 4 
Contingency table analysis, 
445-455 
general form of, 450 
Continuous random variable(s), 
170,201 
Control charts, 642-650 
constants for (table), 737 
logic of, 651-655 
for monitoring mean of a process 
(F-chart), 655-667 
for monitoring process variation 
(R-chart), 672-679 
for monitoring proportion of de- 
fectives generated by process 
(p-chart), 683 -689 
individuals chart (x-chart), 654 
pattern-analysis rules for, 
660-662 
Control group, 15 
Control limits, 651 
Correction for continuity, 226 
Correlated errors, 617 
Correlation, 505 
coefficient of. See Coefficient 

752 
INDEX 
n 
Countable list, 169 
CPI. See Consumer Price Index 
(CPI) 
Critical values 
of t table, 723 
of X 2  table, 724-725 
Cumulative binomial probabilities, 
187 
Cyclical output, 644,647 
Data 
collecting, 14-17 
interval, 13 
nominal, 13 
ordinal, 13 
qualitative, 13 
quantitative, 13 
ratio, 13 
sample, 2 
statistical, 2 
time series, 98 
types of 13 
Data description, 25 -26 
distorting truth with, 100-104 
graphical methods for, 26 
bar graphs, 28,30,31-32 
box plots, 84-91 
dot plots, 36,38 
histograms, 36,38-41,42-44 
pie charts, 28 
scattergrams (scatterplots), 
94-97 
stem-and-leaf displays, 36, 
37-38,39,41-42 
time series plot, 97-100 
numerical methods for, 26 
measures of central tenden- 
cy, 52-59 
measures of relative standing, 
78-81 
measures of variability, 63-67 
summation notation, 50-51 
Defect Prevention, 31 
Deflation, 4 
Degrees of freedom (df), 269,351 
Deming Prize, 692 
Deming, W. Edwards, 99,692 
Deming's 14 Points, 692-693 
Dependent events. See Mutually 
exclusive events 
Dependent variable, 474 
Descriptive statistics 
defined, l , 2  
one-variable, 58-59 
Designed experiments, 14,15 
Destructive sampling, 272 
Deterministic model, 473 
Deterministic relationship, 473 
Deviation, 64-67,477. See also 
Error(s); Standard deviation 
Dimensions (of classification), 445 
Discrete random variable(s) 
binomial 
tables, 187-190 
distribution of, 181-192 
Chebyshev's Rule for, 175 
defined, 169,170 
Empirical Rule for, 175 
expected value (mean) of, 174 
probability distributions for, 
171-177 
standard deviation of, 175 
variance of, 175 
Discrimination in the workplace, 
468-469 
Distribution(s) 
for continuous random variables, 
20 1 
for discrete random variables, 
171-177 
exponential, 231-235 
mound-shaped, 70,73,81 
multinomial, 437 
normal. See Normal 
distribution 
Poisson, 194,195 
randomness, 202 
sampling. See Sampling 
distribution(s) 
uniform, 202-204,240 
Distribution of the process, 645 
Dot plots, 36,38,39 
Downtrend, 644,647 
Dowsing accuracy experiment, 
540-542 
Dummy variable, 571 
Empirical Rule, 71,72,73,235 
for discrete random variables, 175 
Equal population variances, 
377-38 1 
Error(s), 477 
correlated, 617 
random, 473 
Type I, 301,304 
Type 11,303,304 
Escalator clauses, 4 
Estimates, biased, 15 
Estimation error, bound on, 8 
Estimator 
interval, 262 
point, 260 
unbiased, 66 
Ethics, in computer technology 
and use, 458-459 
Events, 123 
complementary, 134 
compound, 130 
Expected cell count, 440 
Expected value 
of discrete random variables, 174 
of squared distance from the 
mean, 175 
Experiment, 118-119 
Exploding the Pareto diagram, 31 
Exponential distribution, 
231-235 
Exponential random variable, 232 
Exponentials table, 722 
Extrapolation, 616 
Factors, 95. See also Independent 
variable 
F-distribution, 377-378 
percentage points of (tables), 
726-733 
First-order model, multiple 
regression, 559-565 
Freak output, 644,647 
Frequency function, 201 
F statistic (test), 402-405 
F-test for equal population 
variances, 377-38 1 
summary of, 381 
Furniture fire case, 257 
Gasket manufacturing case, 
699-702 
GDP. See Gross Domestic Product 
( G W  
Generalization, 7,8 
Global F-test, 583 
Gosset, W. S., 269 
Graphing calculator 
binomial probabilities on, 97-99 
box plots on, 91 

confidence interval for popula- 
tion mean on, 274-275 
confidence interval for popula- 
tion proportion on, 284 
graphing area under standard 
normal on, 213 
histograms on, 42-44 
normal probability plots on, 
222-223 
one-variable descriptive statistics 
on, 58-59 
one-way ANOVA on, 407-408 
Poisson probabilities on, 198-199 
p-value for a z-test on, 317 
p-values for contingency tables 
on, 453-455 
scatterplots (scattergrams) on, 97 
straight-line (linear) regression 
on, 481-483 
Gross Domestic Product (GDP), 
10,94 
Guide to Quality Control, 677 
Handicapping sports events, 
338-339 
Herrnstein, Richard J., 251,624 
Higher-order term (x,), 558 
Hinges, 85,86 
Histograms, 36,38-41,42 
using graphing calculator for, 
42-44 
Hypothesis 
alternative (research), 300,304 
null, 300,304 
tests of. See Tests of hypotheses 
Increasing variance, 644,647 
Independent events, 146-147 
Independent random samples, 376 
Independent variable, 474 
Indicator variable, 571 
Individuals chart, 654 
Inference, 6 
Inferential statistics 
defined, 1,2-3 
example of, 3 -4 
Inflation, 4,94 
Inner fences, 85,86 
Insider trading, 326-327 
Interquartile range, 85 
Intersections, 131-133 
Interval data, 13 
Intervals, 38 
Invalid interval, 271 
Ishikawa, Kaoru, 677-679 
Kane,V. E., 31 
Kelting, Herman, 634 
Kentucky milk bid rigging case, 
114-115,426 
Law of Large Numbers, 120 
Least squares 
approach to simple linear 
regression, 476-483 
on graphing calculator, 
481-483 
estimates, 478 
formulas for, 479 
line, 477,478 
method, 477 
prediction equation, 477,562 
Level of significance, 304 
Level shift output, 644,647 
Line of means, 474 
Linear regression. See Simple lin- 
ear regression 
Lot acceptance sampling, 227 
Lottery Buster, 158-1 59 
Lower control limit, 651 
Lower quartile, 84-85 
Mann-Whitney U statistic, 386 
Marginal probabilities, 445-446 
Market basket, 4 
Mathematics, combinatorial, 127 
Mean square for error (MSE), 
402,567 
Mean square for treatments 
(MST), 402 
Mean(s) 
defined, 52 
of population. See Population 
mean(s) 
sample. See Sample mean 
Meandering output, 644,647 
Measurement, 5,118 
Measurement classes, 38 
Measurement processes, 11 
Measures of central tendency, 
52-59 
Median, 54-57. 
Method of least squares, 477 
Middle quartile, 84-85 
Modal class. 57-58 
Mode, 57-58 
Model building, 559 
Mound-shaped distributions, 70,73 
z-score for, 81 
Multicollinearity, 615-616 
Multinomial experiment, 437-441 
properties of, 437 
Multiple coefficient of 
determination (R,), 581 
Multiple regression 
assumptions about, 565-567 
checking, 598-614 
for estimation and prediction, 
593-594 
estimating standard error in, 567 
extrapolation of independent 
variables, 616 
general model, 558 
inferences about p parameters, 
568-572 
models, 558-559 
analyzing, 559 
pitfalls in, 614-617 
correlated errors, 617 
multicollinearity, 615-616 
parameter estimability, 
614-615 
prediction outside experi- 
mental region, 616 
residual analysis, 598-614 
test of an individual parameter 
coefficient in, 568 
time series model, 617 
usefulness of, 580-585 
adjusted multiple coefficient 
of determination, 582 
analysis of variance F-test, 
583-584 
global F-test, 583-584 
multiple coefficient of 
determination (R2), 581 
recommendation for 
checking, 585 
Multiplicative rule of probability, 
144-149,703-704 
Murray, Charles, 251,624 
Mutually exclusive events, 136,148 
Nilson survey, 3-4 
Nominal data, 13 
Nonconforming process outputs, 
654 

Nonparametric test (method), 
332-336 
for comparing two populations 
independent sampling, 
384-389 
paired difference 
experiments, 393-397 
for correlation in simple linear 
regression, 532-538 
Nonresponse bias, 16 
Normal curve areas table, 721 
Normal distribution, 206-21 7 
approximating binomial distribu- 
tion with, 225-230 
descriptive methods for assessing 
normality, 219-223 
formula for, 207 
graphing area under standard 
normal, 213 
property of, 211 
standard, 207-208 
using graphing calculator to 
graph, 213 
z-score and, 215-21 6 
Normal probability plot, 219,220, 
222-223. See also Normal 
distribution 
using graphing calculator to 
graph, 222-223 
Normal random variable, 206 
finding probability corresponding 
to, 212 
probability distribution for, 207 
Null hypothesis, 300,304 
steps for selecting, 307 
Numerical methods of data 
description, 26 
measures of central tendency, 
52-59 
measures of relative standing, 
78-81 
measures of variability, 63-67 
summation notation, 50-51 
Observation, 118 
Observational data, 14 
Observational studies, 15 
Observed cell count, 447 
Observed significance levels 
(p-values), 313-317 
Odds, 120 
One-tailed (one-sided) statistical 
test, 306 
about a population mean, 
306-307,310 
about a population proportion, 
328,43 1 
for comparing large-sample pop- 
ulation means, 348 
for comparing small-sample pop- 
ulation means, 352 
for paired difference experiment, 
367 
sign test, 333 
of Spearman's rank correlation, 
538 
for utility of simple linear regres- 
sion model, 497 
of Wilcoxon rank sum test for 
large samples, 389 
of Wilcoxon signed rank test for a 
paired difference experiment, 
395 
One-variable descriptive statis- 
tics, on graphing calculator, 
58-59 
One-way analysis of variance 
(ANOVA), on graphing 
calculator, 407-408 
Ordinal data, 13 
Organizational processes, 640 
Oscillating sequence, in time se- 
ries chart, 643 
Out of the Crisis, 99 
Outer fences, 85,86 
Outlier(s), 41,84-91,603 
analysis, 606 
output, 644,647 
rules for detecting, 90 
Output distribution of the process, 
645 
Paired difference experiment(s) 
appropriate uses of, 366 
for comparing two population 
means, 362 
confidence interval for, 366 
defined, 365 
determining sample size for, 376 
nonparametric test for compar- 
ing two populations, 393-397 
test of hypothesis for, 367 
Wilcoxon signed rank test, 
393-397 
Parameter, 236 
Parameter estimability, 614-615 
Pareto diagram, 31-32 
exploding, 31 
Pareto principle, 31 
Pareto, Vilfredo, 31 
Partitions rule, 704 
Pattern-analysis rules, 660-662 
p-chart, 683-689 
constructing zone boundaries 
for, 686 
interpreting, 686 
steps in constructing, 685 
Pearson product moment of coef- 
ficient of correlation (r), 
505 -509 
Perfect negative correlation, 533, 
534 
Perfect positive correlation, 533, 
534 
Pie charts, 28 
Point estimator, 260 
Poisson distribution, 194,195 
Poisson probabilities 
using graphing calculator for, 
198-199 
table, 716-720 
Poisson random variable(s), 
194-199 
characteristics of, 194 
mean, variance, and distribution 
of, 195 
Poisson, SimCon, 194 
Pooled sample estimator, 351-352 
Population correlation coefficient, 
508 
Population mean(s), 53-54 
comparing 
determining sample size, 
374 - 376 
large samples, 346-350 
confidence interval for, 
348 
properties of sampling 
distribution, 347 
test of hypothesis for, 348 
paired difference 
experiments, 362-369 
small samples, 351-356 

confidence interval for, 
352 
test of hypothesis for, 
352 
three or more, 400-410 
two, 346 
confidence intervals for 
large-sample, 260-265 
small-sample, 268-274 
estimating, 286-288 
large-sample tests of hypotheses 
about, 306-31 0 
conclusions for, 310 
one-tailed test, 306-307,310 
two-tailed test, 306-307,310 
nonparametric test for, 332-336 
independent sampling, 
384-389 
paired difference 
experiments, 393-397 
small-sample tests of hypotheses 
about, 319-323 
one-tailed test, 321 
t statistic for, 320-321 
two-tailed test, 321 
testing assumption of equal pop- 
ulation variances, 377-381 
Population proportion(s) 
comparing, multinomial 
experiment, 437-441 
comparing two 
determining sample size for, 
435-436 
independent sampling, 
428-432 
contingency table analysis in, 
445-455 
estimating, 288-290 
large-sample 
confidence interval for, 430 
tests of hypothesis about, 
326-330 
one-tailed, 328 
two-tailed, 328 
z-test, 327-328 
sampling distribution properties, 
429 
test of hypothesis about, 431 
Population rank correlation 
coefficient, 536 
Population variances, 377-381 
Population(s) 
defined, 4-5 
self-selected respondents, 16,18 
subsets of, 6 
Prediction interval, 519 
Prediction outside experimental 
region, 61 6 
Predictor variable, 474 
Probabilistic models, 472-475 
assumptions about, 489-490 
estimating standard error in, 
490-492 
for estimation and prediction, 
516-523 
first-order (straight-line), 474 
general form of, 474 
Probabilistic relationship, 473 
Probability density function (pdf), 
201 
Probability distribution, 172,201. 
See also Distribution(s) 
Probability(ies) 
additive rule of, 135-136 
conditional, 140-143 
defined, 120 
of events, 123-124 
calculating, 124-127 
complementary events, 134 
mutually exclusive events, 
136,148 
multiplicative rule of, 144-149 
Poisson, 198-199. See also Pois- 
son random variable(s) 
random sampling and, 154-156 
of sample points, 119-127 
sample space and, 119-121 
unconditional, 140,141-142 
unions and intersections, 
130-133 
Process(es) 
black box 
defined, 10 
illustrated, 11-12 
defined, 9,640 
measurement, 11 
sources of variation in output, 
642 
Product characteristics, 639 
pth percentile, 79 
Published sources of data, 14 
primary vs. secondary, 15 
p-values (observed significance 
level), 313-317 
for p coefficients in simple linear 
regression, 498-499 
for contingency tables, 
453-455 
population median, 333-334 
Quadratic model, 602 
Quadratic term, 602 
Qualitative data, 13,14 
description, 28,30,31-32. See 
also Data description 
Quality 
and output variation, 642. See 
also Control charts 
defined, 638-639 
dimensions of, 639 
Quality improvement. See also 
Control charts 
Deming's contributions to, 
692- 693 
total quality management 
(TQM), 638 
Quantitative data, 13 
graphical methods for describing 
box plots, 84-91 
distorting truth with, 
100-104 
dot plots, 36,38 
histograms, 36,38-41,42-44 
scattergrams (scatterplots), 
94-97 
stem-and-leaf displays, 36, 
37-38,39,41-42 
time series plot, 97-100 
numerical methods for describing 
measures of central tendency, 
52-59 
measures of relative standing, 
78-81 
measures of variability, 
63 - 67 
summation notation, 50-51 
Quartiles, 84-85 
Random behavior, 647 
Random error, 473 
Random number generators, 154 
Random numbers table, 155, 
709-711 

Random phenomena, 473 
Random sample, 16,154-156 
Random variable(s) 
defined, 168 
exponential, 232 
Poisson, 194-197 
types of, 168-170. See also Con- 
tinuous random variable(s); 
Discrete random variable(s) 
uniform, 202-204 
Randomized block experiment, 
365 
Randomness distribution, 202 
Range, 63-64 
Rank sums, 385 
Rare events, 652 
Rare-event approach, 90,248 
Rare-event concept, 300 
Ratio data, 13 
Rational subgroups, 648 
R-chart, 672-679 
constructing zone boundaries 
for, 675 
interpreting, 675 
steps in constructing, 674 
using with T-chart, 677 
Regression analysis, 474. See also 
Multiple regression; Simple 
linear regression 
robustness of, 609 
of statistics in The Bell Curve, 
624-625 
Regression line, 477 
Regression modeling, 474 
Regression residuals, 599. See also 
Residual analysis 
on graphing calculator, 613 
outliers, 603 
properties of, 600 
Rejection region, 302,304 
for common values of a, 307 
Relative frequency, 38 
histogram 38,39 
Relative standing 
measures of, 78-81 
percentile ranking, 78-79 
Reliability, 8 
Representative sample, 15 
Research hypothesis, 300,304 
Residual analysis, 598-614 
steps in, 613-614 
Resource constraints, 8 
Respondents, self-selected, 16 
Response variable, 474 
Robust method, 410 
Run chart, 98,642 
Sample(s) 
defined, 6,11 
random, 16 
representative, 15 
mean, 52-54 
median, 54-57 
z-score for, 79-81 
Sample points, 119-127 
probability rules for, 122 
Sample size, 54 
for comparing two population 
means, 374-376 
for comparing two population 
proportions, 435 -436 
confidence intervals and, 
287-288,289 
for independent random sam- 
ples, 376 
for monitoring a process 
proportion, 684 
for paired difference experiments, 
376 
for test of hypothesis about a 
population proportion, 
329-330 
Sample space, 119-121 
Sample standard deviations, 673 
Sample statistic, 236 
Sample surveys, 428 
Sampling, 2 
lot acceptance, 227 
Sampling distribution(s) 
Central Limit Theorem and, 
242-248 
defined, 237-238 
of least squares estimator, 496 
of mean, 245 -247 
properties of, 244 
Sampling errors, in simple linear 
regression, 518-519 
Scale break, 101 
Scallop sampling case, 292 
Scattergrams (scatterplots), 94-97, 
476-477 
using graphing calculator for, 97 
s-chart, 673 
Second-order term, 602 
Securities and Exchange 
Commission (SEC), 326 
Self-selected respondents, 16,18 
Shock output, 644,647 
Sign test for population median, 
332-336 
large-sample, 335 
summary box, 334 
Significance levels, observed, 
31 3-317. See also p-values 
Simple event, 119 
Simple linear regression 
assessing utility of (slope P,), 
494-499 
assumptions about, 489-490 
coefficient of correlation, 505-509 
coefficient of determination, 
505-509 
for estimation and prediction, 
516-523 
estimating standard error in, 
490-492 
example of, 529-532 
least squares approach, 
476-483 
nonparametric test for correla- 
tion in, 532-538 
probabilistic models, 472-475 
procedure for, 475 
Spearman's rank correlation 
coefficient (r,), 533-538 
using graphing calculator in, 
481-483 
Simple random sample, 154 
Skewed data, 56-57 
Slope of the line, 474 
Spearman's rank correlation coef- 
ficient (r;), 533-538 
shortcut formula for, 534 
critical values for (table), 736 
Special causes of variation, 649 
Specification limits, 654 
Spread of data. See Variability 
Stability, 645 
Standard deviation, 65-67 
for discrete random variables, 175 
interpretation of, 70-74 
Chebyshev's Rule, 70,72 
Empirical Rule, 71,72,73 

Standard error, 347 
of the mean, 244 
Standard normal distribution, 
207-208 
Standard normal random variable, 
208 
Statistical A bstr~ct of the United 
States, 14 
Statistical inference, 6 
Statistical process control, 
645-649 
defined, 649 
Statistical science, 2 
Statistical thinking, 17,642 
Statistics 
defined, 1,2 
fundamental elements of, 4-9 
in managerial decision-making, 17 
processes of, 2 
science of, 2 
types of, 2-4 
Statistics and the Law, 468 
Stem-and-leaf displays, 36,37-38, 
39,41-42 
Straight-line model, 472,474 
Sum of errors, 477 
Sum of squares for errors (SSE), 
402,477 
Sum of squares for treatments 
(SST), 401-402 
Summation notation, 50-51 
Survey of Current Business, 15 
Surveys, l4,15 
misleading and biased, 18-19 
sample, 428 
Systems, 641 
[,critical values of (table), 723 
Tables 
binomial probabilities, 712-715 
control chart constants, 737 
critical values of Spearman's rank 
correlation coefficient, 736 
critical values of To in the 
Wilcoxon paired difference 
signed rank test, 735 
critical values of TL and Tu for the 
Wilcoxon rank sum test, 734 
normal curve areas, 721 
percentage points of the 
F-distribution 
a = .01,732-733 
a = .025,730-731 
a = .05,728-729 
a = .lo, 726-727 
Poisson probabilities, 716-720 
random numbers, 709-71 1 
Test statistic, 300-301,304. See 
also z-test 
Tests of hypotheses 
for comparing large-sample pop- 
ulation means, 348 
elements of, 300-304 
summary box, 304 
about multinomial probabilities, 
439-440 
one-tailed (one-sided) statistical 
test, 306 
for paired difference experiment, 
367 
about a population mean 
large-sample test, 306-310 
small-sample test, 319-323 
about a population median, 
326-330 
one-tailed test, 334 
two-tailed test, 334 
about a population proportion, 
43 1 
large-sample test of, 326-330 
sample size for, 329-330 
small-sample test of, 330 
possible conclusions for, 310 
p-values, 313-317 
calculating, 314 
reporting as, 316 
two-tailed (two-sided) statistical 
test, 306 
Three-sigma limits, 651 
Time series data, 98 
Time series model, 617 
Time series plot, 97-100,642-643 
Treatment group, 15 
Treatments, 400 
sampling variability among 
means of (mean square for 
treatments), 402 
sampling variability around 
means of (sum of squares for 
error), 402 
sampling variability within means 
of (mean square for error), 402 
sampling variation between 
means of (sum of squares for 
treatments), 401-402 
Tree diagram, 146 
Trial values, 663 
Two-tailed (two-sided) statistical 
test, 306 
for comparing large-sample pop- 
ulation means, 348,352 
for paired difference experiment, 
367 
about a population mean, 
306-307,310 
for population proportions, 328, 
431 
of Spearman's rank correlation, 
538 
for utility of simple linear regres- 
sion model, 497 
of Wilcoxon rank sum test for 
large samples, 389 
of Wilcoxon signed rank test for 
a paired difference experi- 
ment, 395 
Two-way table, 445 
Type I error, 301,304 
Type I1 error, 303,304 
Unconditional probability, 140, 
141-142 
Unethical statistical practice, 18 
Uniform distribution, 202,203, 
240 
Uniform random variable(s), 
202-204 
mean, deviation, and distribution 
of, 203 
Unions, 131-133 
Upper control limit, 651 
Upper quartile, 84-85 
Uptrend, 644,647 
Variability, 54 
measures of, 52 
numerical measures of, 63-67 
Variable(s), 11 
coded (x3), 558 
defined, 5 
dependent, 474 
dummy, 571 
independen 1,474 

indicator, 571 
predictor, 474 
random. See Random variables 
response, 474 
Variance(s) 
for discrete random variables, 
175 
sample, 65-67 
Variance-stabilizing transforma- 
tion, 611 
Variation 
common causes of, 649 
special causes of, 649 
Venn diagrams, 120 
for mutually exclusive events, 
148 
for union and intersection, 131 
Waiting time distribution, 231 
Whiskers, 85,86 
Wilcoxon, Frank, 384 
Wilcoxon paired difference signed 
rank test, critical values of To 
(table), 735 
Wilcoxon rank sum test 
critical values of TL and Tu 
(table), 734 
defined, 384 
for independent samples, 
384-389 
summary, 386-387 
for large samples, 389 
Wilcoxon signed rank test, 
393-397 
for large samples, 397 
x-chart, 654 
- 
x-chart, 655-667 
constructing zone boundaries 
for, 660 
decisions in constructing, 658 
interpreting, 662 
rational subgrouping strategy 
for, 658 
steps in constructing, 659 
zones in, 659 
y-intercept of the line, 474 
z statistic, 346 
z-scores, 79-81,84,89-90 
z-test, 332 
p-value for, 317 

