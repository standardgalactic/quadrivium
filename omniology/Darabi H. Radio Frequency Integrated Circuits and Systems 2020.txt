

Radio Frequency Integrated
Circuits and Systems
Second Edition
This updated and expanded new edition equips students with a thorough understanding of the state
of the art in RF design and the practical knowledge and skills needed in industry. Introductory and
advanced topics are covered in depth, with clear, step-by-step explanations, including core topics
such as RF components, signals and systems, two-ports, noise, distortion, low-noise ampliﬁers,
power ampliﬁers, and transceiver architectures. New material has been added on wave propagation,
skin effect, antennas, mixers and oscillators, and digital PAs and transmitters. Two new chapters
detail the analysis and design of RF and IF ﬁlters (including SAW and FBAR duplexers and N-path
ﬁlters), phase-locked loops, frequency synthesizers, digital PLLs, and frequency dividers. Theory is
linked to practice through real-world applications, practical design examples, and exploration of the
pros and cons of various topologies. Over 250 homework problems are included, with solutions and
lecture slides for instructors available online. With its uniquely practical and intuitive approach, this
is an essential text for graduate courses on RFICs and a useful reference for practicing engineers.
Hooman Darabi is a Fellow of Broadcom, California, and a lecturer at the University of California,
Los Angeles. His research interests include analog and RF IC design for wireless communications.


Radio Frequency
Integrated Circuits
and Systems
Second Edition
HOOMAN DARABI
Broadcom Inc., Irvine

University Printing House, Cambridge CB2 8BS, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314–321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre, New Delhi – 110025, India
79 Anson Road, #06–04/06, Singapore 079906
Cambridge University Press is part of the University of Cambridge.
It furthers the University’s mission by disseminating knowledge in the pursuit of
education, learning, and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781107194755
DOI: 10.1017/9781108163644
© Cambridge University Press 2020
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2015
Second edition 2020
Printed in the United Kingdom by TJ International Ltd, Padstow Cornwall
A catalogue record for this publication is available from the British Library.
Library of Congress Cataloging-in-Publication Data
Names: Darabi, Hooman, 1972– author.
Title: Radio frequency integrated circuits and systems / Hooman Darabi Broadcom Inc., Irvine.
Description: Second edition. | Cambridge, United Kingdom ; New York, NY, USA : Cambridge University
Press, 2020.
Identiﬁers: LCCN 2019021297 | ISBN 9781107194755 (hardback)
Subjects: LCSH: Radio frequency integrated circuits–Design and construction.
Classiﬁcation: LCC TK7874.78 .D37 2020 | DDC 621.3841/2–dc23
LC record available at https://lccn.loc.gov/2019021297
ISBN 978-1-107-19475-5 Hardback
Additional resources for this publication at www.cambridge.org/darabi2
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.

To my family


CONTENTS
Preface to the Second Edition
page xiii
Preface to the First Edition
xv
Glossary
xviii
1.
RF Components
1
1.1
Electric Fields and Capacitance
2
1.2
Magnetic Fields and Inductance
5
1.3
Time-Varying Fields and Maxwell Equations
9
1.4
Circuit Representation of Capacitors and Inductors
11
1.5
Distributed and Lumped Circuits
12
1.6
Energy and Power
15
1.7
LC and RLC Circuits
17
1.8
The Uniform Plane Wave
26
1.9
Antennas
36
1.10 Integrated Capacitors
43
1.11 Integrated Inductors
47
1.12 Summary
70
1.13 Problems
70
1.14 References
77
2.
RF Signals and Systems
79
2.1
Fourier Transform and Fourier Series
80
2.2
Impulses
83
2.3
Fourier Transform of Periodic Signals
85
2.4
Impulse Response
86
2.5
Network Functions
88
2.6
Hilbert Transform and Quadrature Signals
93
2.7
Stochastic Processes
95
2.8
Analog Linear Modulation
109
2.9
Analog Nonlinear Modulation
115
2.10 Modern Radio Modulation Scheme
119
2.11 Single-Sideband Receivers
121
2.12 Summary
123
2.13 Problems
123
2.14 References
129

3.
RF Networks
130
3.1
Introduction to Two-Ports
130
3.2
Available Power
139
3.3
Impedance Transformation
149
3.4
Lossless Transmission Lines
166
3.5
Low-Loss Transmission Lines
173
3.6
Receive–Transmit Antennas as Two-Port Circuits
176
3.7
Smith Chart
179
3.8
Scattering Parameters
185
3.9
Differential Two-Ports
196
3.10 Summary
197
3.11 Problems
197
3.12 References
205
4.
RF and IF Filters
206
4.1
Ideal Filters
207
4.2
Doubly Terminated LC Filters
208
4.3
Active Filters
238
4.4
Surface and Bulk Acoustic Wave Filters
248
4.5
Duplexers
253
4.6
N-Path Filters
255
4.7
Quadrature Filters
260
4.8
Summary
270
4.9
Problems
270
4.10 References
274
5.
Noise
278
5.1
Types of Noise
279
5.2
Two-Port Equivalent Noise
296
5.3
Noise Figure
299
5.4
Minimum NF
303
5.5
Impact of Feedback on Noise Figure
309
5.6
Noise Figure of Cascade of Stages
312
5.7
Phase Noise
316
5.8
Sensitivity
317
5.9
Noise Figure Measurements
322
5.10 Summary
325
5.11 Problems
325
5.12 References
330
6.
Distortion
331
6.1
Blockers in Wireless Systems
332
6.2
Full-Duplex Systems and Coexistence
335
viii
Contents

6.3
Small Signal Nonlinearity
336
6.4
Large Signal Nonlinearity
356
6.5
Reciprocal Mixing
359
6.6
Harmonic Mixing
363
6.7
Transmitter Nonlinearity Concerns
364
6.8
Summary
382
6.9
Problems
382
6.10 References
385
7.
Low-Noise Ampliﬁers
386
7.1
Matching Requirements
387
7.2
RF Tuned Ampliﬁers
392
7.3
Common-Source and Common-Gate LNAs
397
7.4
Shunt Feedback LNAs
401
7.5
Series Feedback LNAs
405
7.6
Feedforward LNAs
410
7.7
LNA Practical Concerns
413
7.8
LNA Power–Noise Optimization
421
7.9
Signal and Power Integrity
425
7.10 LNA Design Case Study
431
7.11 Summary
433
7.12 Problems
433
7.13 References
436
8.
Mixers
437
8.1
Mixers Fundamentals
437
8.2
Evolution of Mixers
442
8.3
Active Mixers
445
8.4
Passive Current-Mode Mixers
460
8.5
Passive Voltage-Mode Mixers
484
8.6
Transmitter Mixers
486
8.7
Harmonic Folding in Transmitter Mixers
491
8.8
LNA/Mixer Case Study
494
8.9
Summary
502
8.10 Problems
503
8.11 References
507
9.
Oscillators
510
9.1
The Linear LC Oscillator
511
9.2
The Nonlinear LC Oscillator
517
9.3
Phase Noise Analysis of the Nonlinear LC Oscillator
521
9.4
LC Oscillator Topologies
540
9.5
Q-Degradation
551
Contents
ix

9.6
Frequency Modulation Effects
554
9.7
More LC Oscillator Topologies
562
9.8
Ring Oscillators
566
9.9
Quadrature Oscillators
577
9.10 Crystal and FBAR Oscillators
581
9.11 Summary
588
9.12 Problems
589
9.13 References
592
10. PLLs and Synthesizers
595
10.1
Phase-Locked Loops Basics
596
10.2
Type I PLLs
598
10.3
Type II PLLs
601
10.4
Integer-N Frequency Synthesizers
611
10.5
Fractional-N Frequency Synthesizers
618
10.6
Frequency Dividers
630
10.7
Introduction to Digital PLLs
640
10.8
Summary
647
10.9
Problems
647
10.10 References
649
11. Power Ampliﬁers
651
11.1
General Considerations
652
11.2
Class A PAs
654
11.3
Class B PAs
656
11.4
Class C PAs
660
11.5
Class D PAs
662
11.6
Class D Digital PAs
665
11.7
Class E PAs
669
11.8
Class F PAs
672
11.9
PA Linearization Techniques
673
11.10 Summary
685
11.11 Problems
685
11.12 References
688
12. Transceiver Architectures
690
12.1
General Considerations
691
12.2
Receiver Architectures
692
12.3
Blocker-Tolerant Receivers
707
12.4
Receiver Filtering and ADC Design
715
12.5
Receiver Gain Control
718
12.6
Transmitter Architectures
719
x
Contents

12.7
Transceiver Practical Design Concerns
734
12.8
Summary
751
12.9
Problems
751
12.10 References
754
Index
757
Contents
xi


PREFACE TO THE SECOND EDITION
While the ﬁrst edition was written to be equally used as a textbook in graduate-level RF courses
in academia, as well as among RF professional engineers, it was felt that it may be more
suitable to practicing RF engineers in industry. Personal teaching experience in the past few
years and feedback from some colleagues and friends inspired me to work on a new edition to
address the needs of entry-level graduate and senior undergraduate students more properly. To
that extent, without altering the overall organization of the book signiﬁcantly and retaining the
bulk of material from the ﬁrst edition, the book has been rewritten to address the fundamental
concepts more deeply, give more step-by-step design explanations, and provide many more
examples and clarifying points. The examples particularly are designed to cover both funda-
mental theoretical concepts as well as hands-on circuit-level design and simulations and have
been organized more distinctly to both complement the basic concepts and provide guidelines
for more advanced discussions. It has been the author’s intention to familiarize the readers early
on with two of RF designers’ best friends, Spectre-RF and EMX, through many of these
examples covering circuit-level analysis followed by veriﬁcation through actual simulations.
Furthermore, over 50 new additional problems, with guidance and hints, have been added
throughout the 12 chapters and may be assigned as homework problems or exam questions or
simply used as means of practicing the fundamental concepts.
Apart from this main motivation, there were several important concepts crucial in the RF
design that were missing from the ﬁrst edition or at least needed more elaboration. One of the
main additions of this edition is the inclusion of two new chapters, one to cover in-depth
analysis and design of RF and IF ﬁlters, including SAW, FBAR, duplexers, and N-path ﬁlters,
as well as a dedicated chapter to cover phase-locked loops, frequency synthesizers, digital
PLLs, and frequency dividers. Additionally, new discussions on wave propagation, skin effect,
and antennas were added to Chapter 1. This is introductory material but is deemed vital for RF
engineers as they are an essential part of RF design. Among other new additions are more
expanded discussion on RF two-ports and reciprocal networks, additional discussions of mixers
and oscillators, and a section on digital power ampliﬁers. One of the main innovations of this
edition is inclusion of a section to address signal and power integrity, a critical part of the RF
design. This was added to the low-noise ampliﬁers chapter, as being the most susceptible block,
though is applicable in general to any part of the radio. It covers various topics such as electric
and magnetic coupling, shielding, and power rails transient noise.
Neither in the ﬁrst edition nor in the current one does a dedicated chapter on the subject of the
wireless standards exist. The wireless standards are evolving, and as such a chapter examining
them would be drastically different today versus ﬁve or ten years in the future. It is more
important for RF designers to attain the ability to translate high-level system speciﬁcations into

circuit-level requirements rather than memorizing the standard itself. This is fully addressed in
Chapter 5 and especially Chapter 6, along with numerous references to the existing mainstream
RF standards.
I have been very fortunate to enjoy the company of many talented individuals at Broadcom,
from whom I have learned tremendously in my 20-year tenure there. I am thankful to all of
them. I would like to speciﬁcally thank the following Broadcom colleagues and friends who
helped proofread various chapters of the new edition: Wei-Liat Chan, Yuyu Chang, Saeed
Chehrazi, Matteo Conta, Milad Darvishi, Valentina Della Torra, Dale Douglas, Mohyee
Mikhemar, David Murphy, Bevin Perumana, and Hao Wu. I am also thankful to Dr. Ed Chien,
who helped on the PLL chapter in general with many useful discussions, and particularly for his
guidance on the digital PLL section. Likewise, thanks to Dr. Mikhemar, who co-wrote the
digital PA section, and Dr. Rich Ruby, who provided valuable feedback on the SAW and
FBAR section. I would also like to thank my teammates in Broadcom, Saeed Chehrazi, Milad
Darvishi, Daivd Murphy, and Hao Wu, with whom I have had many useful discussions on
various topics, directly or indirectly related to the book.
I am grateful to my Ph.D. advisor with whom I have kept close contact throughout the years,
Prof. Asad Abidi from UCLA, who has been a great inspiration. I have beneﬁtted tremendously
from his insights and innovative teaching methods in general, and particularly in many sections
of the book. I would also like to acknowledge my undergraduate instructor from Sharif
University, Prof. Masood Jahanbegloo, a UCLA alumnus himself, for his dedicated teaching,
and to whom I owe my fundamentals of basic circuit theory and electronics.
Lastly, I would like to thank my wife, Dr. Shahrzad Tadjpour, for her patience and technical
feedback, and my family for their support.
xiv
Preface to the Second Edition

PREFACE TO THE FIRST EDITION
In the past 20 years, radio frequency (RF) integrated circuits in CMOS have evolved dramatic-
ally, and matured. Started as a pure research topic in mid-1990 at several universities, they have
made their way into complex systems-on-a-chip (SoCs) for wireless connectivity and mobile
applications. The reason for this dramatic evolution comes primarily from two main factors: the
rapid improvement of CMOS technology and innovative circuits and architectures. In contrary
to the common belief that RF and analog circuits do not improve much with technology, a faster
CMOS process has enabled a number of topologies that have led to substantially lower cost and
power consumption. In fact to some extent, the recent inventions may not have been possible if
not for better and faster technology. This rapid change has caused the modern RF design to be
somewhat industry-based, and consequently it is timely, and perhaps necessary, to provide an
industry perspective. One main goal of this book has been to cover possibly fewer topics but in
a much deeper fashion. Even for RF engineers working on routine products in industry, a deep
understanding of fundamental concepts of RF IC design is very critical, and it is the intention of
this work to break this gap. During the course of writing the book, I have tried to address the
topics that I would have wanted as a wish list for my fellow future colleagues. Our main focus
then has been to elaborate the basic deﬁnitions and fundamental concepts, while an interested
designer with a strong background can explore other variations on his or her own.
The contents of this book stem largely from the RF courses taught at the University of
California, Los Angeles and Irvine, as well as many years of product experience at Broadcom.
Accordingly, the book is intended to be useful both as a text for students and as a reference
book for practicing RF circuit and system engineers. Each chapter includes several worked
examples that illustrate the practical applications of the material discussed, with examples of
real-life products and a problem set at the end to complement that.
RF circuit design is a multidisciplinary ﬁeld where a deep knowledge of analog integrated
circuits, as well as communication theory, signal processing, electromagnetics, and microwave
engineering is crucial. Consequently, the ﬁrst three chapters as well as parts of Chapter 4 cover
selected topics from the aforementioned ﬁelds, but customized and shaped properly to ﬁt the
principles of RF design. It is, however, necessary for the interested students or RF engineers to
have already taken appropriate senior-level undergraduate courses.
An outline of each chapter is given below along with suggestions for the material to be
covered if the book is to be used for a 20-lecture quarter-based course. Furthermore, in the
beginning of each chapter a list of speciﬁc items to be covered as well as more detailed
suggestion of which sections to include for the class use are outlined. For beginner and
intermediate practicing engineers we recommend following the selected topics suggested for
the class use, while more advanced readers may focus on the other topics assigned for reading.

Chapter 1 contains a review of basic electromagnetic concepts and particularly the inductors
and capacitors. Among many students and RF engineers, often the basic deﬁnition of capacitors
and inductors is neglected, despite using them very regularly. A short reminder is deemed
necessary. Furthermore, some basic understanding of Maxwell’s equations is needed to under-
stand transmission lines, electromagnetic waves, the antenna concept, and scattering param-
eters. These are discussed in Chapter 3. The chapter also gives an overview of integrated
inductors and capacitors in modern CMOS. Two lectures are expected to be needed to cover the
basic concepts.
Chapter 2 deals with basic communication and signal processing concepts, which are a
crucial part of RF design. The majority of the material is gathered to provide a reminder and
may be left to be studied outside the class, depending on the students’ background. However,
we cannot emphasize enough the importance of them. Spending a total of two or three lectures
on the stochastic processes, modulation section, as well as a brief general reminder of passive
ﬁlters and Hilbert transform may be helpful.
Chapter 3 is concerned with several key concepts in RF design such as available power,
matching topologies, transmission lines, as well as scattering parameters and complements
Chapter 1. Two lectures may be dedicated to cover the ﬁrst three sections, while the more
advanced material on transmission lines, the Smith chart, and scattering parameters may be very
brieﬂy touched or omitted altogether depending on the students’ background.
In Chapter 4 we discuss, noise, noise ﬁgure, sensitivity, and an introduction to phase noise.
The introductory part on types of noise may be assigned as reading, but the noise ﬁgure
deﬁnition, minimum noise ﬁgure, and sensitivity sections must be covered in full. A total of
two or three lectures sufﬁces.
Chapter 5 covers the distortion and blockers. A large portion of this chapter (as well as
Chapter 10) may be left for a more advanced course, and one lecture should sufﬁce to cover
only the basic concepts. However, the material may be very appealing to RF circuit and system
engineers who work in industry. A thorough knowledge of this chapter is crucial to understand
Chapter 10.
Chapters 6 to 9 deal with the RF circuit design. Chapter 6 is mostly built upon the concepts
covered in Chapters 3 and 4 and deals with low-noise ampliﬁers. Three lectures may be
dedicated to cover most of the topics presented in this chapter.
Chapter 7 provides a detailed discussion on receiver and transmitter mixers. Roughly two
lectures may be dedicated to this chapter to cover basic active and passive topologies with some
limited discussion on noise. The majority of the material on M-phase and upconversion mixers
may be assigned as reading.
Chapter 8 discusses oscillators, including LC, ring, crystal oscillators, and an introduction to
phase-locked loops. The chapter is long, and the latter three topics may be assigned as reading,
while two lectures could be dedicated to LC oscillators, and a brief introduction to phase noise.
A detailed discussion of phase noise is very math intensive, and may be beyond the scope of an
introductory RF course. Thus, it may be sufﬁcient to focus mostly on the premises of an abstract
linear oscillator, and summarize Bank’s general results to provide a more practical perspective.
Power ampliﬁers are discussed in Chapter 9. Basic classes are presented in the ﬁrst few
sections, followed by efﬁciency improvement and linearization techniques. Most of the material
xvi
Preface to the First Edition

on the latter subject may be skipped, and one or two lectures may be assigned to cover a few
examples of classes (perhaps only classes A, B, and F), as well as the introductory material on
the general concerns and the trade-offs.
Finally, in Chapter 10 transceiver architectures are presented. This is one of the longest
chapters of the book, and much of the material can be assigned as reading. The last section
covers some practical aspects of the design, such as packaging and production issues. It
presents a few case studies as well. The topics may be appealing for practicing RF engineers,
but the entire section may be skipped for class use. A maximum of two lectures is sufﬁcient to
cover selected key transceiver architectures.
I have been very fortunate to be working with many talented RF designers and instructors
throughout my carrier at UCLA, and subsequently at Broadcom. They have had an impact on
this book one way or another. However, I wish to acknowledge the following individuals who
have directly contributed to the book: Dr. David Murphy from Broadcom who co-wrote most of
Chapter 8, and provided very helpful insight on Chapter 6, particularly the LNA topologies; Dr.
Ahmad Mirzaei from Broadcom as well, who helped on the write up of sections of Chapters 9
and 10, and proofread the entire book painstakingly. They both have been major contributors to
this book beyond the chapters mentioned. I would also like to thank Dr. Hwan Yoon from
Broadcom with whom I had numerous helpful discussions on Chapter 1 material, and particu-
larly the integrated inductors. My sincere thanks go to Prof. Eric Klumperink of the University
of Twente, who proofread most of the book diligently, and provided valuable insight on various
topics. I would also like to acknowledge my sister Hannah, who helped design the book cover.
Lastly, I wish to thank my wife, Shahrzad Tadjpour, not only for her technical feedback on the
book, but for her general support throughout all these years.
Preface to the First Edition
xvii

GLOSSARY
ACLR
alternate adjacent channel leakage ratio
ADC
analog-to-digital converter
AM
amplitude modulation
BALUN
balanced-unbalanced
BJT
bipolar junction transistor
BNC
Bayonet Neill–Concelman
BPF
bandpass ﬁlter
BT
Bluetooth
BW
bandwidth
CG
common-gate
CMOS
complementary metal-oxide semiconductor
CP
charge pump
CS
common-source
DAC
digital-to-analog converter
dBc
decibels relative to the carrier
DSB
double sideband
DSP
digital signal processor
DUT
device under test
EDGE
enhanced data rate for GSM evolution
EMF
electromotive force
ENR
excess noise ratio
EVM
error vector magnitude
FBGA
ﬁne-pitch ball grid array
FDD
frequency division duplexing
FDMA
frequency division multiple access
FET
ﬁled effect transistor
FM
frequency modulation
FSK
frequency shift keying
GSM
global system for mobile communications
HD
harmonic distortion
HPF
highpass ﬁlter
IF
intermediate frequency
IMN
Nth-order intermodulation
IO
input/output
IPN
Nth-order intermodulation product

I/Q
in/quadrature phase
ISM
industrial–scientiﬁc–medical
LNA
low-noise ampliﬁer
LO
local oscillator
LPF
lowpass ﬁlter
LTE
long-term evolution
MATLAB
matrix laboratory
NB
narrowband
NF
noise ﬁgure
OFDM
orthogonal frequency division multiplexing
OOB
out of band
P1dB
1 dB compression point
PA
power ampliﬁer
PAPR
peak-to-average power ratio
PCB
printed circuit board
PD
phase detector
PDF
probability distribution function
PFD
phase-frequency detector
PGA
programmable gain ampliﬁer
PLL
phase-locked loop
PM
phase modulation
PPM
parts per million
PTAT
proportional-to-absolute temperature
QAM
quadrature amplitude modulation
RDL
redistribution layer
RMS
root mean square
RSSI
received signal strength indicator
RX
receiver
SAW
surface acoustic wave
SNR
signal-to-noise ratio
SSB
single sideband
TDD
time division duplexing
TDMA
time division multiple access
TIA
transimpedance ampliﬁer
TR
transmit–receive
TX
transmitter
VCO
voltage-controlled oscillator
WB
wideband
WCDMA
wideband code division multiple access
Wi-Fi
wireless ﬁdelity
WLAN
wireless local area network
XO
crystal oscillator
Glossary
xix


1
RF Components
In this chapter basic components used in RF design are discussed. Detailed modeling and
analysis of MOS transistors at high frequency can be found already in many analog books
[1], [2]. Although mainly offered for analog and high-speed circuits, the model is good enough
for most RF applications operating at several GHz and beyond, especially for nanometer CMOS
processes used today. Thus, instead we will have a more detailed look at inductors, capacitors,
and LC resonators in this chapter. We will also brieﬂy discuss the fundamental operation of
distributed circuits and transmission lines and follow up with more in Chapter 3. In Chapters 5
and 7 we will discuss some of the RF aspects of the transistors, including a more detailed noise
analysis as well as substrate and gate resistance. New to this edition are Sections 1.8 and 1.9,
which cover the fundamentals of wave propagation and antennas.
LC circuits are widely used in RF design, with applications ranging from tuned ampliﬁers to
matching circuits and LC oscillators. Inspired by superior noise and linearity compared to transis-
tors, historically radios have heavily relied on inductors and capacitors, with large portions of the
RF blocks occupied by them. Although this dependence has been reduced in modern radios
mostly for cost concerns, RF designers deal with integrated inductors and capacitors quite often.
We start the chapter with a brief introduction to electromagnetic ﬁelds and take a closer
look at capacitors and inductors from a ﬁeld perspective. We then discuss capacitors, induct-
ors, and LC resonators from the circuit point of view. We conclude the chapter by presenting
the principles and design trade-offs of integrated inductors and capacitors. Throughout this
section several examples of inductor and transformer design are presented using theory, as
much as possible, validated by EMX simulation, with the goal to familiarize students and junior
RF designers with the tool and its applications.
The speciﬁc topics covered in this chapter are:
• Capacitance and inductance electromagnetic and circuit deﬁnitions
• Maxwell’s equations
• Distributed elements and introduction to transmission lines
• Energy, power, and quality factor
• Wave propagation and antennas
• Integrated capacitors and inductors
For class teaching, we recommend focusing on Sections 1.7, 1.10, and 1.11, while Sections
1.1–1.6 as well as 1.8 and 1.9 may be assigned for reading or only a brief summary presented
if deemed necessary.

1.1
ELECTRIC FIELDS AND CAPACITANCE
..............................................................................................
Let us start with a brief overview of electric ﬁelds and electric potential. We shall deﬁne the
concept of capacitance accordingly.
Published ﬁrst in 1875 by Charles Coulomb, the French army ofﬁcer, Coulomb’s law states
that the force between two point charges separated in a vacuum or free space by a distance is
proportional to each charge and inversely proportional to the square of the distance between
them (Figure 1.1). It bears a great similarity to Newton’s gravitational law, discovered about a
hundred years earlier. Writing the force (Ft) as a force per unit charge gives the electric ﬁeld
intensity, E, measured in V/m (or volt per meter) as follows:
E = Ft
Qt
=
Q
4πE0r2 ar,
where the bold notation indicates a vector in 3D space, E0 =
1
36π  109F/m (or farad per meter)
is the permittivity in free space, and Q1 is the charge in C (or coulomb).2 ar is the unit vector
pointing to the direction of the ﬁeld, which is in the same direction as the vector r connecting
the charge Q to the point of interest P in space (see Figure 1.1). Qt is a test charge to which the
force (or ﬁeld) created by Q is applied.
In many cases the electric ﬁeld can be calculated more easily by applying Gauss’s law
instead,3 expressing that the electric ﬂux density D = E0E4 (measured in C/m2) passing through
any closed surface is equal to the total charge enclosed by that surface,5 and mathematically
expressed as
Þ
SD  dS = Q,
where
Þ
SD . dS indicates the integral over a closed surface. The dot product indicates the
product of the magnitude and the cosine of the smaller angle. The charge Q could be the sum of
Q
Qt
r = r1–r2
E
Origin
r1
r2
P
ar
Figure 1.1: Coulomb’s law
1 Not to be confused with Q, used as quality factor later in this chapter.
2 Like many units used in electronics throughout this book (farad, henry, tesla, weber, watt, etc.), coulomb is not one of the
seven base SI (international system) units. The SI unit for electric charge is s.A, or second times ampere.
3 Johann Carl Friedrich Gauss (1777–1855) was a German mathematician and physicist who made signiﬁcant contributions
to many mathematics, physics, and engineering ﬁelds.
4 Only in free space.
5 The expression itself is a result of Michael Faraday’s experiment. Gauss’s contribution is providing the mathematical tools
to formulate it.
2
RF Components

several charge points, that is Q =
X
Qi, a volume charge distribution Q =
Ð
VρVdV, a surface
distribution, and so forth. The nature of the surface integral implies that only the normal
component of D at surface contributes to the charge, whereas the tangential component leads
to D  dS equal to zero.
Example: Consider a long coaxial cable6 with the inner radius of a, and an outer radius
of b, carrying a uniform charge distribution of ρS per area on the outer surface of the inner
conductor (and  b
a ρS on the inner surface of the outer conductor) as shown in Figure 1.2.
For convenience, let us use the cylindrical coordinates [3].
The ﬂux will have components in the ar direction, normal to the surface. For an
arbitrary length of L in the z-axis direction, we can write:
ðL
z = 0
ð2π
ϕ = 0
Dr rdϕdz
ð
Þ = Q = ρS 2πaL
ð
Þ,
Thus inside the cable, that is for a < r < b:
D = ρSa
r ar:
The electric ﬁeld and ﬂux density are both zero outside the cable as the net charge is equal
to zero.
Based on the electric energy deﬁnition,7 the potential difference between points A and B
(VAB) is deﬁned as
VAB = W
Q = 
ðA
B
E :dL,
where W is the energy in J (or joule), and the right side is the line integral of the electric
ﬁeld. The physical interpretation of energy or potential is such that moving a charge
Q along with the electric ﬁeld from point B to A results in energy reduction (the charge
z
a
b
f
a
+
+
+
+
+
+
+
+
-
-
-
-
-
az
-
-
ar
-
Figure 1.2: Electric ﬂux in a coaxial cable
6 Coaxial cable was invented by English engineer and mathematician Oliver Heaviside, who patented the design in 1880.
7 We shall discuss the electric energy shortly.
1.1 Electric Fields and Capacitance
3

releases energy), and accordingly we expect point A to be at a lower potential. By
deﬁnition of the line integral, one can see that the sum of static potentials in a closed path
must be equal to zero, that is,
Þ
E. dL = 0 which is a general representation of Kirchhoff’s
voltage law or KVL. This is physically understood by noting that when the charge is moved
around a closed path, the total energy received and the energy released balance each other,
thus no net work is done.
Example: An interesting property of a charged piece of metal is that, no matter what its
shape is and if current is zero, the electric ﬁeld inside the piece of metal has to be zero. Free
charges in the metal go to the surfaces of the metal and arrange themselves so that the electric
ﬁeld is zero everywhere inside the metal. In fact the electric ﬁeld is always in a direction
normal to the surface. Consequently, a closed metal surface, no matter what its shape, screens
out external sources of electric ﬁeld, often referred to as a Faraday cage,8 which has
applications in RF shielding (see Chapter 7 for more details on shields and signal integrity).
We close this section by deﬁning capacitance. Suppose we have two oppositely charged
(each with a charge of Q) conductors M1 and M2 within a given dielectric with permittivity9 of
E = ErE0 (Figure 1.3). Assuming a potential difference of V0 between the conductors, we deﬁne
capacitance C measured in farad as
C = Q
V0
:
Alternatively, one can rewrite C as
C = E
Þ
SE dS

Ð
E dL
,
which indicates that capacitance is independent of the charge or potential, as E (or D) linearly
depends on Q according to Gauss’s law.
Physically capacitance indicates the capability of energy or equivalently electric ﬂux storage
in electrical systems, analogous to inductors that store magnetic ﬂux.
M1, –Q
M2, +Q
Dielectric
Figure 1.3: Capacitance deﬁnition
8 Michael Faraday (1791–1867) was a British scientist.
9 Er = 1 for free space.
4
RF Components

Example: Returning to our previous example of the coaxial cable, the potential between
the inner and outer conductors is calculated by taking the line integral of the E = D/E,
where D was obtained previously. This yields
V0 =  1
E
ða
b
aρS
r dr = aρS ln b
a
E
:
Thus the capacitance per unit length is equal to
C = 2πE
ln b
a
,
which is clearly only a function of the coaxial cable radii and the dielectric permittivity.
1.2
MAGNETIC FIELDS AND INDUCTANCE
..............................................................................................
A steady magnetic ﬁeld can be created in one of three ways: through a permanent magnet,
through a linear time-varying electric ﬁeld, or simply due to a direct current. The permanent
magnet has several applications in RF and microwave devices, such as passive gyrators used in
a lossless circulator, which is a passive, but nonreciprocal circuit [4], [5]. However, we will
mostly focus on the latter two methods of creating magnetic ﬁelds, and defer the gyrator
implementation details to [4].
In 1820, the law of Biot–Savart10 was proposed as follows which associates magnetic ﬁeld
intensity H (expressed in A/m) at a given point P to a current of I ﬂowing in a differential vector
length dL of an ideal ﬁlament:
dH = IdL  ar
4πr2
= IdL  r
4πr3
:
The cross product () indicates the product of the magnitude and the sine of the smaller angle.
The magnetic ﬁeld will then be perpendicular to the plain containing the current ﬁlament and
vector r, and whose direction is determined based on the right-hand rule. The law states that the
magnetic ﬁeld intensity is directly proportional to the current (I), but inversely proportional to
the square of the distance between P and differential length (r), and also proportional to the
magnitude of the differential element times the sinus of the angle  shown in Figure 1.4.
A more familiar law describing the magnetic ﬁeld was proposed by Ampere11 shortly afterward
in 1823, widely known as Ampere’s circuital law,12 and is mathematically expressed as
Þ
H. dL = I,
10 Named after Jean-Baptiste Biot and Félix Savart, who discovered this relationship in 1820.
11 André-Marie Ampère (1775–1836) was a French mathematician and physicist who is considered the father of
electrodynamics. Ampere, the current unit, is one of the seven SI base units.
12 Ampere’s law may be derived from Biot–Savart’s law.
1.2 Magnetic Fields and Inductance
5

indicating that the line integral of the magnetic ﬁeld (H) about any closed path is exactly equal
to the current enclosed by that path (Figure 1.5). This law proves to be more useful as it allows
us to calculate the ﬁeld more easily as long as it is properly determined which components of
the ﬁeld are present, and that the symmetry is invoked appropriately. By comparison, Ampere’s
circuital law is more analogous to Gauss’s law, whereas the law of Biot–Savart could be
considered similar to Coulomb’s law.
Example: Consider a long coaxial cable carrying a uniform current of I in the center
conductor, and –I in the outer one shown in Figure 1.6. Clearly the ﬁeld cannot have any
component in the z direction, as it must be normal to the current direction. Moreover, the
symmetry shows that H cannot be a function of ϕ or z, and thus could be expressed as a
general form of H = Hraϕ. Inside the coaxial cable, that is a < r < b, applying the line
integral then leads to
H =
I
2πr aϕ:
Moreover, similar to the electric ﬁeld, the magnetic ﬁeld is also zero outside the cable as
the net current ﬂow is zero, showing the concept of shielding provided by the coaxial
cable. Note that inside the cable, the magnetic ﬁeld consists of closed lines circling around
the current, as opposed to the electric ﬁeld lines that start on a positive charge and end on
a negative one.
P
q
dL
I
ar
r
Figure 1.4: Biot–Savart’s law expression
I
Arbitrary
closed path
dL
Figure 1.5: Ampere’s law
6
RF Components

In free space, magnetic ﬂux density B (measured in weber/m2 or tesla), is deﬁned as
B = μ0H,
where μ0 = 4π107H/m (or henry per meter) in free space and is the permeability. The
magnetic ﬂux, ϕ, is then the ﬂux passing through a designated area S, measured in weber, and is
deﬁned as
ϕ =
Ð
SB  dS.
Generally the magnetic ﬂux is a linear function of the current (I), that is, ϕ = LI, where the
proportionality constant, L, is known as the inductance, and is measured in henry. We can thus
say
L = μ0
Ð
SH  dS
Þ
H dL
,
and since H is a linear function of I, as established by Ampere’s (or Biot–Savart’s) law, the
inductance is a function of the conductor geometry and the distribution of the current, but not
the current itself.
Example: By calculating the total ﬂux inside the coaxial cable of the previous example,
one can simply show that the cable inductance per unit length is
L = μ0
2π ln b
a ,
whereas the capacitance per unit length of the same coaxial cable was calculated before
by applying Gauss’s law, equal to
C = 2πE
ln b
a:
Clearly
LC = μ0E.
z
a
az
ar
I
I
H
af
Figure 1.6: Magnetic ﬁeld in a coaxial cable
1.2 Magnetic Fields and Inductance
7

We conclude this section by deﬁning mutual inductance M12 between circuits 1 and 2 in
terms of their ﬂux linkage:
M12 = N2ϕ12
I1
,
where ϕ12 signiﬁes the ﬂux produced by I1 that links the path of the ﬁlamentary current I2, and
N2 is the number of turns in circuit 2. The mutual inductance therefore depends on the magnetic
interaction between the two currents.
Example: Consider an N-turn solenoid with a ﬁnite length of d, consisting of N closely
wound ﬁlaments that carry a current of I shown in Figure 1.7. We assume the solenoid is
long enough with respect to its diameter.
The magnetic ﬁeld is in the az direction, as the current is in the aϕ direction, and
Ampere’s law readily shows that within the solenoid
H = NI
d az:
If the radius is r, corresponding to an area of A = πr2, the self-inductance is
L = Nϕ
I
= μ0N2 A
d :
Example: Now consider two coaxial solenoids, with radius r1, and r0 < r1, carrying
currents of I1 and I0, and with different number of turns N1 and N0, respectively. The top
view is shown in Figure 1.8.
d
z
I
Figure 1.7: An N-turn solenoid
8
RF Components

To ﬁnd the mutual inductance M01, we can write
ϕ01 = μ0A0H0,
where H0 = N0I0
d is the magnetic ﬁeld intensity created by the smaller solenoid, and ϕ01 is
the magnetic ﬂux created in the larger solenoid by the smaller one. Note that H0 is zero
outside the radius of the smaller solenoid. By deﬁnition we have
M01 = N1
I0
μ0A0H0 = μ0N0N1
A0
d :
A similar procedure leads to M10 = N0ϕ10
I1
= N0
I1 μ0A0H1, which comes out to be equal to
M01. This is in agreement with reciprocity of course.
1.3
TIME-VARYING FIELDS AND MAXWELL EQUATIONS
..............................................................................................
As described earlier, time-varying ﬁelds could also be a source of electric or magnetic ﬁeld
creation. In 1831, Faraday published his ﬁndings from the following experiment where he
proved that a time-varying magnetic ﬁeld does indeed result in a current. He wound two
separate coils on an iron toroid and placed a galvanometer in one and a battery and switch
in the other (Figure 1.9). Upon closing the switch, he realized that the galvanometer was
momentarily deﬂected. He observed the same deﬂection but in an opposite direction when
the battery was disconnected. In terms of ﬁelds, we can say that a time-varying magnetic
ﬁeld (or ﬂux) produces an electromotive force (emf, measured in volts) that may establish
a current in a closed circuit. A time-varying magnetic ﬁeld may be a result of a time-
varying current, or relative motion of a steady ﬂux and a closed path, or a combination
of the two.
r0
r1
H
I1
I0
Figure 1.8: Two coaxial solenoids top view
Figure 1.9: Faraday’s experiment
1.3 Time-Varying Fields and Maxwell Equations
9

Faraday’s law as stated above is customarily formulated as
emf =
þ
E :dL =  dϕ
dt ,
where the line integral comes from basic deﬁnition of voltage (E is the electric ﬁeld intensity).
The minus sign indicates that the emf is in such a direction as to produce a current whose ﬂux, if
added to the original one, would reduce the magnitude of emf, and is generally known as
Lenz’s law.13
Similarly, a time-varying electric ﬂux results in a magnetic ﬁeld, and is generally formulated
by modifying the Ampere’s circuital law as follows:
þ
H: dL = I +
ð
S
∂D
∂t : dS,
where D is the electric ﬂux density, and
Ð
S
∂D
∂t :dS is termed as the displacement current by
Maxwell.14 To summarize, we can state the four Maxwell’s equations in the integral form as
follows:
þ
E:dL = 
ð
S
∂B
∂t :dS
þ
H:dL = I +
ð
S
∂D
∂t :dS
þ
S
D dS =
ð
V
ρVdV
þ
S
B dS = 0:
The third equation is Gauss’s law as we discussed earlier. The fourth equation15 states that
unlike the electric ﬁelds that begin and terminate on positive and negative charges, the magnetic
ﬁeld forms concentric circles. In other words the magnetic ﬂux lines are closed and do not
terminate on a magnetic charge16 (Figure 1.10). Therefore, the closed surface integral of a
magnetic ﬁeld (or magnetic ﬂux density) is zero.
In free space where the medium is sourceless, I (or ρV) is equal to zero. The ﬁrst two of
Maxwell equations, when combined, lead to a differential equation relating the second-order
derivative of E (or H) versus space, to its second order derivative versus time, describing the
wave propagation in free space. For example, if E = Exax, or if the electric ﬁeld is polarized
only in the x direction, with some straightforward math [6], and using Maxwell’s equations in
differential form, it can be shown that17
13 Emil Lenz (1804–1865) was a Russian physicist.
14 James Clark Maxwell was a Scottish scientist in the 19th century whose most notable achievement was to formulate the
theory of electromagnetic radiation. Maxwell’s equations are often described as the second great uniﬁcation in physics,
after the ﬁrst one realized by Newton.
15 The fourth equation is often known as Gauss’s law for magnetism.
16 Magnetic charges or monopoles have not been found in nature, although the magnetic monopole is used in physics as a
hypothetical elementary particle.
17 The more general form of the wave equation is r2E = μ0E0 ∂2E
∂t2 .
10
RF Components

∂2Ex
∂z2 = μ0E0
∂2Ex
∂t2 ,
and the propagation is in the z direction, whose velocity is deﬁned as
ν =
1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
μ0E0
p
= c,
where c = 3  108m/s is the speed of light in free space. More on this will be covered in
Section 1.8.
1.4
CIRCUIT REPRESENTATION OF CAPACITORS AND INDUCTORS
..............................................................................................
From a circuit point of view, a capacitor is symbolically represented as shown in Figure 1.11,
whose voltage and current (v(t) and i(t)) as shown satisfy the following relations [7]:
i tð Þ = dq
dt ,
where q is the charge stored in the capacitor. The above expression is widely known as the
continuity equation. For the case of a linear and time-invariant capacitor, since q = Cv, we can
write the well-known expression for the capacitor:
i tð Þ = C dv
dt :
Note that the continuity equation as expressed in most physics books is i tð Þ =  dq
dt, indicat-
ing that the outward ﬂow of the positive charge must be balanced by a decrease of the charge
within the closed surface (that is q). The minus sign is omitted since in Figure 1.11 as the
current ﬂow is associated into one terminal of the capacitor with the time rate of increase of
charge on that terminal, and not the outward current.
An inductor is symbolically represented as shown in Figure 1.11, whose voltage and current
(v(t) and i(t)) as shown satisfy the following relations:
v tð Þ = dϕ
dt ,
where ϕ is the magnetic ﬂux linkage. The above equation is a direct result of Faraday’s law, and
since ϕ = Li, we arrive at the well-known expression:
H
+
+
+
+
+
+
+
+
-
-
-
-
-
-
-
-
-
E
Figure 1.10: Lines of electric and magnetic ﬁelds in a
coaxial cable
1.4 Circuit Representation of Capacitors and Inductors
11

v tð Þ = L di
dt :
Note that the minus sign is again omitted from the inductor i–v equation, so let us verify if it
agrees with Lenz’s law. Suppose the current i(t) increases, that is di
dt > 0. This indicates that the
magnetic ﬁeld must also increase, hence dϕ/dt > 0, which follows v(t) > 0, that is, the potential
in node A is greater than node B. This is precisely the polarity required to oppose a further
increase in current, as required by Lenz’s law.
1.5
DISTRIBUTED AND LUMPED CIRCUITS
..............................................................................................
Kirchhoff’s voltage law or KVL states that the sum of electric potentials in a closed path is
equal to zero, that is,
Þ
E. dL = 0, whereas Maxwell’s ﬁrst equation (or Faraday’s law as
described before) says otherwise. The time-varying term in Maxwell’s second equation, that is,
the displacement current, is similarly in violation of KCL. To clarify further, let us study the
simple circuit shown in Figure 1.12, consisting of an ideal (zero inductance and resistance)
piece of wire attached to a parallel-plate capacitor, forming a loop around it.
Assume that within the loop an external magnetic ﬁeld is applied, varying sinusoidally
with time. Thus, an emf = V0 cos ω0t across the capacitor is produced, as predicted by
Faraday’s law. On the other hand, if the wire is ideal, KVL indicates that the shorted capacitor
must have zero voltage across it. Interestingly, the voltage across the capacitor creates a
current i in the wire:
i =  ω0CV0sin ω0t =  ω0
EA
d V0sin ω0t,
where E, A, and d are parallel plate capacitor parameters. In any closed path the Ampere’s
circuital law gives us the magnetic ﬁeld as a result of this current. Particularly, for a speciﬁc
closed path, which passes between the capacitor plates, we can determine the displacement
current. Within the capacitor
C
+
-
B
i
C
Figure 1.12: Description of Faraday’s law
in a closed path
+
–
v(t)
q(t)
i(t)
+
–
v(t)
i(t)
A
B
A
B
Figure 1.11: Capacitor and inductor circuit representation
12
RF Components

D = EE = E V0
d cos ω0t


,
and according to Maxwell’s second equation, the displacement current is
iD = ∂D
∂t A =  ω0
EA
d V0 sin ω0t,
which is equal to the earlier result obtained for the current in the loop.
This brings us to a general discussion about lumped and distributed circuits. We can say that
the basic elements in a circuit, and the connections between them, are considered lumped (and
thus KVL or KCL are applicable) if the time delay in traversing the elements is negligible, and
hence they can be treated as static. If the components are large enough, or the frequency is high
enough (or equivalently the delays are small enough), one must use distributed elements. This
means that the resistive, capacitive, or inductive characteristics must be evaluated on a per unit
distance basis. Common examples of the latter are transmission lines or waveguides, which are
intended to deliver electric energy from one point to the other, and naturally are separated by
long (relative to the wavelength) distances. To illustrate an example of how to deal with such
circuits, consider a lossless line, as shown in Figure 1.13, connecting a generator to a load. We
can construct a model for this transmission line using lumped capacitors and inductors. An
equivalent circuit of a differential section of the line (where the length dz is approaching zero)
with no loss is shown in Figure 1.13. Since each section corresponds to a very small portion of
the line, that is dz is approaching zero, KVL and KCL are valid for that section, despite the
distributed nature of the line.
Writing KVL leads to
v z; t
ð
Þ = Ldz
ð
Þ ∂i z; t
ð
Þ
∂t
+ v z; t
ð
Þ + ∂v z; t
ð
Þ
∂z
dz,
which results in
L ∂i
∂t =  ∂v
∂z :
Similarly by writing KCL we obtain
∂i
∂z =  C ∂v
∂t :
Lossless 
Transmission Line
v+
v–
i+
i–
Z0
+
–
+
–
z
Ldz
Cdz
i(z,t)
+
v(z,t)
–
v(z,t)+(∂v/∂z)dz
i(z,t)+(∂i/∂z)dz
+
–
Figure 1.13: Lossless transmission line and its lumped differential equivalent
1.5 Distributed and Lumped Circuits
13

Taking derivative of one of the two equations above versus space (or z), and the other versus
time (or t), the current component, i, could be eliminated, arriving at
∂2v
∂z2 = LC ∂2v
∂t2 :
Note the similarity of this differential equation with the one given for the wave propagation in
the previous section, where electric ﬁeld is replaced by voltage, and the propagation velocity (as
we will deﬁne shortly) is now equal to
1ﬃﬃﬃﬃﬃ
LC
p
. Since L and C are the inductance and capacitance
per unit length, they have the same units as μ and E in the wave equation, that is H/m and F/m.
The solution of this differential equation is of the form
v z; t
ð
Þ = f 1 t  z
ν


+ f 2 t + z
ν


= v + + v,
which could be veriﬁed by replacing v(z, t) above in the original differential equation
describing the distributed wave propagation. The functions f1 and f2 could be anything as
long as they are differentiable twice, and take arguments t  zν. The arguments of f1 and f2
indicate, respectively, travel of the functions in the forward and backward z directions, and
thus we assign symbols v+ and v– to them. To understand this better, suppose we would like to
keep the argument of f1 constant at zero. As time increases (as it should), z has to also increase
with a rate of ν  t (hence we call ν the velocity). Therefore the function f1 needs to move
forward or in positive z direction. On the other hand, for f2, z has to decrease, indicating a
backward motion. The forward moving signal is illustrated in Figure 1.14, where we assume
f1/2 are sinusoidal. This in fact will be the case, for the sinusoidal steady state solution, as we
show in Chapter 3.
The propagation velocity is obtained by replacing the solution in the original differential
equation. This yields
ν =
1ﬃﬃﬃﬃﬃﬃ
LC
p
:
A similar procedure results in the following solution for the current:
i z; t
ð
Þ = 1
Z0
f 1 t  z
ν


 1
Z0
f 2 t + z
ν


= i + + i,
z
t
t
t
t
t
t = z/n
Figure 1.14: Wave propagating in a transmission line
14
RF Components

where Z0 is deﬁned as the characteristic impedance of the line measured in ohm and is equal to
Z0 =
ﬃﬃﬃﬃ
L
C
r
:
Even though Z0 is measured in Ω, it is not a physical resistor as we already assumed that the line
is lossless. It simply relates the forward and backward voltages and currents in the line as
follows (Figure 1.13):
v + = Z0i +
v =  Z0i :
Example: Returning to our previous coaxial cable example, since the values of L and
C were obtained already, the characteristic impedance is readily given by
Z0 =
ﬃﬃﬃμ
E
r
ln b
a Ω:
Typical values of a, b, and E result in a characteristic impedance of several tens of ohm,
commonly set to 50Ω.
1.6
ENERGY AND POWER
..............................................................................................
From electromagnetic ﬁeld perspective, we can deﬁne electrostatic and magnetic energy stored
as follows [6]:
WE = 1
2
ð
V
D :EdV = 1
2 E
ð
V
E
j j2dV
WH = 1
2
ð
V
B :HdV = 1
2 μ
ð
V
H
j
j2dV,
where WE and WH denote electric and magnetic energy respectively in joules and the integrals
are performed over volume.18
From circuit perspective, let us consider Figure 1.15, where a generator is connected to a
one-port, with current i(t) entering the one-port, and a voltage v(t) across it.
The instantaneous power delivered to the one-port by the generator is deﬁned as
p(t) = v(t)i(t),
and the energy produced by the generator from initial time t0 to t is
W t0; t
ð
Þ =
ðt
t0
p 
ð Þd =
ðt
t0
v 
ð Þi 
ð Þd:
18 Both equations may be proven from basic deﬁnitions.
1.6 Energy and Power
15

For an ideal capacitor with initial zero voltage or charge, that is q(t0) = 0, we have
W tð Þ =
ðt
t0
v 
ð Þi 
ð Þd =
ðq tð Þ
0
q 
ð Þ
C
dq
d d = q tð Þ2
2C = 1
2 Cv tð Þ2,
where v and i are replaced with their q equivalents inside the integral. Similarly for an inductor
W tð Þ = 1
2 Li tð Þ2:
Again we can identify the resemblance between μ and E to L and C, and E and H to V and I in
the energy equations. Since E and E have units per distance (/m), the ﬁeld energy integral is
performed over volume. Note that sometimes it is more convenient to calculate the inductance
or capacitance for a given geometric structure from energy deﬁnition, for instance to use
L = 2WH
I2
for inductance calculation (as opposed to L = ϕ/I presented earlier). WH is obtained from its basic
deﬁnition as a function of B and H. Expressing WH and I based on H, it can be shown that19
L = μ
4π
þ
þ dL
r


:dL = μ
4π
þ þ dL1:dL2
r
,
which indicates that only the inductance is a function of geometry, and not the current.
A similar expression for the mutual inductance exists as well, where the integral is deﬁned
between two circuits carrying current:
M = μ
4π
þ þ dL1:dL2
r
:
r
C1
C2
M: Between C1 and C2
Figure 1.16: Self and mutual inductances as only
functions of geometry
One-Port
Generator
i(t)
i(t)
+
v(t)
–
Figure 1.15: Instantaneous power and energy
concept
19 The proof requires the use of vector magnetic potential (A), deﬁned as B = r  A, analogous to electric potential as
deﬁned before, where E =  r V.
16
RF Components

It is perhaps worthwhile to summarize the following similarities between electric and
magnetic ﬁelds, and to voltages and currents:
C F
ð Þ $ E F=m
ð
Þ
L H
ð Þ $ m H=m
ð
Þ
V V
ð Þ $ E V=m
ð
Þ
I A
ð Þ $ H A=m
ð
Þ
E $ H
D $ B
Also note the similarity (or duality) between Gauss’s and Ampere’s laws, as well as Coulomb’s
and Biot–Savart’s laws.
1.7
LC AND RLC CIRCUITS
..............................................................................................
With the background presented, we have now the right tools to analyze LC circuits. We start off
with ideal LC resonators and extend the analysis to more a practical, lossy LC circuit.
1.7.1
Lossless LC Resonator
An ideal (lossless) LC circuit is shown in Figure 1.17 (left side).
Let us assume that the capacitor is charged initially to a voltage of V0. From a circuit point of
view, the initial charge may be a result of an impulse current source of i(t) = V0δ(t) appearing in
parallel with the circuit. If the impulse has a magnitude of V0 coulomb, the capacitor initial
voltage will be vC(0+) = V0.
Taking the capacitor voltage vC(t) as the variable of interest, we can write
∂2vC
∂t2 + 1
LC vC = 0:
The differential equation is solved by taking the Laplace transform of the two sides. This yields
[7], [8]
s2 + 1
LC = 0:
This results in the poles of the circuit at s1,2 = 
jﬃﬃﬃﬃﬃ
LC
p
=  jω0. The ﬁnal solution is
vC(t) = V0 cos ω0t.
C
L
C
R
+
vc(t)
–
+
vc(t)
–
iL(t)
Figure 1.17: Ideal and lossy LC circuits
1.7 LC and RLC Circuits
17

Next we will calculate the energy stored in the capacitor and the inductor. From the previous
section
WC tð Þ = 1
2 CvC tð Þ2 = 1
2 CV0
2 cos ω0t2:
Similarly solving for the inductor current yields
iL tð Þ = 1
L
ð
vC tð Þdt = V0
Lω0
sin ω0t,
and since C =
1
Lω02 , we have
WL tð Þ = 1
2 CV0
2 sin ω0t2:
Therefore the total energy at any point of the time is WT tð Þ = Wc tð Þ + WL tð Þ = 1
2 CV02, which is
constant and equal to the initial energy stored in the capacitor. This is expected, as the LC
circuit is lossless. The energy is exchanged only between the inductor and the capacitor as
shown in Figure 1.18, indicating a steady oscillation.
Note the rate of the energy exchange is twice as fast as that of the capacitor voltage or the
inductor current.
1.7.2
Practical LC Resonator
In practice, both the capacitor and the inductor are lossy, and for now let us model the total loss
as a parallel resistor as shown in Figure 1.17 (right side). We assume the loss is moderate, that
is the value of R is large compared to the impedances of L or C at the frequency of interest. The
new differential equation is
∂2vC
∂t2 + 1
RC
∂vC
∂t + 1
LC vC = 0,
resulting in the complex poles s1,2 =  ω0
2Q  jω0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 
1
4Q2
q
=  α  jωd, where, for the
moment, we deﬁne the quality factor or Q as Q =
R
Lω0 = RCω0. In order to have complex poles,
Q must be greater than ½, which is consistent with our assumption of moderate loss. This
deﬁnition is only a mathematical expression for Q, and we will shortly attach a more physical
meaning to it based on the energy concept. Figure 1.19 shows the location of the complex poles
on the s-plane.
½CV0
2
w0t
p/2
p
Figure 1.18: Energy of capacitor in a lossless LC circuit
18
RF Components

Deﬁning ϕ = cos1 ωd
ω0, the capacitor voltage vC(t) and the inductor current iL(t) are given by
vC tð Þ = V0
ω0
ωd
eαt cos ω0t + ϕ
ð
Þ
iL tð Þ = V0
Lωd
eαt sin ω0t:
Assuming Q  1, then the total energy stored in the LC tank is approximately
WT tð Þ = Wc tð Þ + WL tð Þ  1
2 CV2
0e2αt:
Indicating an initial energy of 1
2 CV02 decaying exponentially as shown in Figure 1.20.
Similar to the ideal tank, the capacitor and the inductor energy move back and forth between
the two, but at a rate of ωd, slightly lower than ω0, but eventually decays to zero. The total
energy decay rate, or equivalently the power dissipated in the resistor is
p =  dWT
dt
= 2αWT = ω0
Q WT:
Rearranging the equation above, we arrive at a more physical and perhaps a more fundamental
deﬁnition for the quality factor:
Q = ω0
WT
p = ω0
Total energy stored
Average power dissipated :
Note that as shown in Figure 1.21 the normalized decay rate versus normalized time (that is the
number of cycles) is a constant and is equal to Q.
jw
s
jwd
–a
w0
f
Figure 1.19: Pole locations of an RLC circuit in jω plane
½CV0
2
p
w0t
/2
p
e-2at
Capacitor Energy
Figure 1.20: Energy in a lossy LC circuit
1.7 LC and RLC Circuits
19

To sustain a steady oscillation, the power dissipated in the resistor must be compensated.
Since the passive circuits are incapable of generating energy, this must be done by an active
circuit as shown in Figure 1.22. The power creation requires the v(t)  i(t) (v(t) = vC(t))
product to be negative, so we expect the iv characteristics of the active circuit to have a
negative slope as shown in Figure 1.22, effectively acting as a negative resistance compen-
sating the loss associated with the positive resistance. The sharper the slope, the more
efﬁcient this would be. Without being distracted with details of the active circuit, we could
ideally model that as a one-port whose iv curve is shown in Figure 1.22, illustrating a
sharp transition in the current around origin. The conservation of energy requires the energy
created to originate from somewhere, and that is usually from the DC power supplying the
active circuit (VDD in Figure 1.22). So it is reasonable to assume that as the voltage or the
current increases, they eventually reach a plateau where they can no longer increase, as
denoted by I0 in Figure 1.22.
Now at steady state when the power dissipated and the power created are balanced, the
capacitor voltage is equal to vC(t) = V0 cos ω0t as in an ideal tank, and the total energy stored in
the tank must be 1
2 CV02.
Since this voltage appears across the active circuit, we expect the current supplied by that to
the lossy LC tank (i(t)) to be as shown in Figure 1.23, as we assumed a sharp transition in the
active element iv characteristic.
Therefore, the average power dissipated in the tank (which is equal to power created in the
active one-port) is given by (Figure 1.23):
p =  1
T
ð
T
V0 cos ω0t
ð
Þi tð Þdt = 2V0I0
π
:
(½CV0
2)(w0/Q)
w0t
p/2
p
e–2at
Decay Rate
Q
WT
Figure 1.21: Power dissipated in a resistor of an RLC circuit vs.
cycles
C
R
+
vc(t)
–
L
Active Circuit
VDD
i
v
+I0
–I0
i(t)
i(t)
Figure 1.22: Active circuit to compensate for the loss of RLC circuit, and its iv characteristics
20
RF Components

Hence, according to the Q deﬁnition
Q = ω0
WT
p = ω0
1
2 CV02
2V0I0
π
= π
4 ω0C V0
I0
,
and since Q = RCω0 for a parallel RLC tank, then
V0 = 4
π RI0:
This shows that the steady oscillation amplitude, V0, is a function only of the active one-port
saturation current, I0, and the amount of loss. Since regardless of its voltage the one-port always
drains a steady current of 2I0 from the supply (to produce the waveform shown in Figure 1.22),
then the efﬁciency is equal to
η =
2V0I0
π
VDD2I0
=
V0
πVDD
= 2
π ,
assuming V0 can reach a maximum swing of 2VDD. This outcome can be intuitively explained
by realizing that the assumed high-Q nature of the tank produces a sinusoidal waveform,
whereas the current delivered by the active circuit is square-wave in nature (Figure 1.23), given
the sharp slope of its iv curve. Taking only the fundamental then leaves a loss factor of 2/π.
We will arrive at a similar result for hard-switching mixers, as we will discuss in Chapter 8.
We have not offered much insight into how to realize the active one-port necessary for
sustaining the oscillation. As our focus in this chapter has been LC circuits, we will leave it at
that, and present various circuit topologies that implement this active one-port in Chapter 9.
Contrary to our model, in practice inductors experience an ohmic loss due to the ﬁnite wire
conductivity, physically modeled as a small series resistance as shown in Figure 1.24. While we
will systematically prove it in Chapter 3, it can be easily shown that if the Q is large, the two
circuits shown in Figure 1.24 are equivalent. The quality factor (Q) is
t
vc(t)
–I0
+I0
I(t)
V0
–V0
Figure 1.23: Voltage and current waveforms in the case of steady
oscillation
1.7 LC and RLC Circuits
21

Q =
R
Lω0
= Lω0
r
:
Furthermore, assuming the elements are high-Q, if the capacitor has also a parallel resistive
loss, we can derive the equivalent parallel RLC circuit whose quality factor, QT, is
1
QT
= 1
QL
+ 1
QC
,
where QL and QC are the inductor and the capacitor quality factors (see Problem 15).
Example: A 1nH inductor has a series resistance of 2Ω, and resonates with a capacitance
whose Q is 25 at 5.5GHz. We would like to ﬁnd the overall LC tank quality factor, and
the equivalent shunt resistance at 5.5GHz.
The inductor Q is
QL = Lω0
r
= 17:3:
The total Q is then
QT =
QLQC
QL + QC
= 10:2:
The total shunt resistance is
RT = Lω0QT = 352.5Ω.
Note that the required capacitance to achieve resonance at 5.5GHz is about 837fF. The
corresponding shunt resistance due to the capacitor loss only is then RC = QC
Cω0 = 864Ω,
whereas that of the inductor is RL = Lω0QL = 597.8Ω. These two resistors in parallel will
lead to the same RT = 352.5Ω.
1.7.3
Resonator Analysis Based on Energy Conservation
Using energy conservation, the analysis offered in the previous section (Figure 1.22) may be
extended to any general nonlinear active circuit employed to compensate the resonator loss.20
L
r
L
R=rQ2
@
Figure 1.24: Inductor with series resistor, and its
equivalent model
20 Since the waveforms are periodic, a more rigorous analysis is offered in Chapter 9 based on Fourier series.
22
RF Components

Depicted in Figure 1.25 is an arbitrary nonlinear active device whose iv characteristics are
shown on the right side. The slope is negative, and thus it pumps energy to the lossy RLC
circuit, as desired. We assume the active element has a conductance of gnr(t) (also shown in the
ﬁgure), deﬁned as follows:
gnr tð Þ = dinr tð Þ
dvnr tð Þ = dinr tð Þ=dt
dvnr tð Þ=dt ,
where inr(t) and vnr(t) are the current and voltage of the active element.
Assuming the voltage across the resonator is mostly sinusoidal, that is vC(t) = V0 cos ω0t, at
steady state, we can write
V02
2R + 1
T
ð
T
V0 cos ω0t
ð
Þi tð Þdt = 0:
The left side of the equation is the power dissipated in the resistor, whereas the right integral is
the average power created by the active circuit over one cycle, which must balance each other
at steady state.
The sinusoidal resonator voltage implies a high quality factor, which is a practical assump-
tion. Nonetheless, the current produced by the active element may be very nonlinear, e.g., a
square-wave for the example of Figure 1.23.
Using the identity
Ð
xdy = xy 
Ð
ydx, the integral is simpliﬁed as
ð
T
V0 cos ω0t
ð
Þi tð Þdt =
V0
ω0
sin ω0t


i tð Þ


				
T
0

ð V0
ω0
sin ω0tdi = 
ð V0
ω0
sin ω0tdi:
Since
di = gnr(t)dvC = gnr(t)(V0ω0 sin ω0tdt),
we can further simplify Ð
T(V0 cos ω0t)i(t)dt = V0
2Ð
T sin ω0t2gnr(t)dt,
which results in
1
2R + 1
T
ð
T
sin2 ω0 tg nr tð Þdt = 0:
C
R
+
vC(t)
–
L
Active Circuit
(gnr(t))
VDD
i(t)
i(t)
5
20
10
0
–10
–20
0
–5
–1
–0.5
0
Voltage [V]
Current [mA]
Conductance [mS]
0.5
1
Figure 1.25: Arbitrary active circuit acting as a negative resistance to compensate the LC resonator loss
1.7 LC and RLC Circuits
23

Equivalently, for steady oscillation, the resonator conductance, G = 1
R must be
G = 2
T
ð
T
sin2 ω0 tg nr tð Þdt:
As the RLC circuit quality factor, and hence the conductance is often given, the equation above
sets a constraint on the oscillation amplitude by which the shape of gnr(t) is deﬁned.
The right-hand side integral deserves some more explanation. Using the simple trigonometric
identity we may further write
2
T
ð
T
sin2 ω0 tg nr tð Þdt = 1
T
ð
T
1  cos 2ω0t
ð
Þgnr tð Þdt = 1
T
ð
T
gnr tð Þdt  1
T
ð
T
cos 2ω0 tg nr tð Þdt:
Hence
G = Gnr[2]  Gnr[0],
where Gnr 0½  = 1
T
Ð
Tgnr tð Þdt is the DC average of the periodic waveform gnr(t), and
Gnr 2½  = 1
T
Ð
Tgnr tð Þ cos 2ω0tdt is the average normalized to cos 2ω0t.
Example: For the previous case of Figure 1.22 (sharp i  v transition), the corresponding
voltage and current are re-depicted in Figure 1.26, along with the waveform of gnr(t).
vC(t)
–I0
+I0
i(t)
V0
t
–2I0/V0w 0
gnr(t)
Figure 1.26: Waveforms
corresponding to square-wave-like
current produced by the active
element
24
RF Components

Since the active element current is assumed to be an ideal square-wave, we have
gnr tð Þ = dinr tð Þ=dt
dvnr tð Þ=dt =
dinr tð Þ=dt
V0ω0 sin ω0
tdt = 2I0
V0ω0
X
+ ∞
k = ∞
δ t  T
4  k T
2


:
Clearly, the oscillation amplitude directly impacts the shape of gnr(t); the higher the
amplitude, the smaller the conductance.
The value of the integral is easily found to be
2
T
ð
T
sin2 ω0 tg nr tð Þdt =
8I0
V0ω0T = 4
π
I0
V0
,
or V0 = 4
π RI0, as found previously. The efﬁciency may be calculated as
η =
V02
2R
VDD2I0
,
and is maximized for V0 = 2VDD to
ηmax = V0
2RI0
= 2
π :
The efﬁciency may be further improved if the active element injects currents only at the peaks
or valleys of the resonator voltage. The current will then consist of narrow pulses of width Δt,
whose height is now I0T/2Δt (Figure 1.27). In the limit case then, the current resembles a train
of impulses with the height of I0T, appearing at every maximum or minimum of the resonator
voltage. Compared to the previous case, if the current injected by the active element is square-
wave, it results in the ﬁrst harmonic of current (the rest are ﬁltered by the resonator) to be 4
π I0,
whereas the DC average is 2I0, leading to an efﬁciency of 2
π. On the contrary, in the idealistic
case of impulse current, the DC and all harmonics are of the same value, and hence we expect a
perfect efﬁciency.
From the ﬁgure it readily follows
gnr tð Þ =
I0T
2ω0ΔtV0 sin
ω0Δt
2


X
+ ∞
k = ∞
δ t  Δt
2  k T
2


+
X
+ ∞
k = ∞
δ t + Δt
2  k T
2


"
#
and
2
T
ð
T
sin2ω0 tg nr tð Þdt = 2I0
V0
sin
ω0Δt
2


ω0Δt
2
:
Thus
V0 = 2RI0
sin
ω0Δt
2


ω0Δt
2
:
1.7 LC and RLC Circuits
25

The maximum efﬁciency is now
ηmax = V0
2RI0
= sin
ω0Δt
2


ω0Δt
2
:
For the previous case of square-wave current, Δt = T
2, and hence V0 = 4
π RI0, leading to a
maximum efﬁciency of 2
π. However, as Δt approaches zero, the amplitude reaches to a
maximum of 2RI0, and the efﬁciency approaches 100%.
Although ideally a perfect efﬁciency is promised when the active element generates impulse
current, realizing such a device proves to be a challenge in practice. Whereas the square-wave
current is simply generated through a properly sized differential pair, producing impulses
requires biasing the transistors to be on only at the peaks of the voltage, which is not as
practical. Nonetheless, this type of circuitry known as class C has been successfully demon-
strated in the context of both efﬁcient oscillators and power ampliﬁers (see Chapters 9 and 11
for details of circuit realization and the challenges associated with the design).
1.8
THE UNIFORM PLANE WAVE
..............................................................................................
In this section as well as the next, we discuss the principles of wave propagation and provide a
brief introduction to antennas [5], [6]. A thorough understanding of electromagnetic waves and
vC(t)
+I0T/2Dt
i(t)
V0
t
gnr(t)
–I0T/2Dt
Dt
Dt/2
T/2
Figure 1.27: Waveforms corresponding to
impulse current generated by the active
element
26
RF Components

antennas perhaps requires several chapters or an entire book [9], [10]. The goal here is to offer
just an overview of basic RF design.
The uniform plane wave represents one of the simplest applications of Maxwell’s equations
and is the basic entity by which the energy is propagated. We focus on the free space ﬁrst, and
explore the solutions for a good (low-loss) conductor subsequently. The latter is important to
understand the skin effect and loss mechanisms associated with it when discussing integrated
inductors later.
1.8.1
Wave Propagation in Free Space
Earlier we presented the four Maxwell equations in integral form as follows:
þ
H: dL = I +
ð
s
∂D
∂t : dS
þ
E:dL = 
ð
s
∂B
∂t :dS
þ
S
D dS =
ð
V
ρVdV
þ
S
B dS = 0:
Using the divergence and Stokes’s theorems,21 we can express Maxwell’s equations in differen-
tial form, which proves to be more useful when deriving the wave equations,
r  H = J + E ∂E
∂t
r  E =  μ ∂H
∂t
r: E = ρV
r: H = 0,
where J is the current density, that is, I =
Ð
SJ. dS.
In free space where the medium is sourceless, thus J and ρV are equal to zero, and the four
equations simplify to
r  H = E0
∂E
∂t
r  E =  μ0
∂H
∂t
r:E = 0
r:H = 0:
21 According to divergence theorem, for an arbitrary vector A, we have
Þ
SA  dS =
Ð
V r . AdV, where V is the volume
enclosed by the closed surface S. Stokes’s theorem states that:
Þ
A  dL =
Ð
S r  A. dS, where S is the area enclosed by
the closed line. Both theorems can be readily proven using basic calculus principles.
1.8 The Uniform Plane Wave
27

Qualitatively speaking, we can infer the wave motion by considering the ﬁrst two equations
above. The ﬁrst equation states that if E is changing with time at some point, then H has a curl
at that point, and thus can be considered as forming a small closed loop linking the changing E
ﬁeld. A similar deduction can be made considering the second equation. Furthermore, the
changing ﬁeld is a small distance away from the disturbance point, and we will show (as it may
be already guessed) that the velocity by which the effect moves is the velocity of light.
To solve the wave equation, we use the identity r  r  A = r (r. A)  r2A, and take a
curl of the two sides of the ﬁrst equation:
r  r  H = r r: H
ð
Þ  r2H = E0
∂
∂t r  E
ð
Þ:
Note that the r operator is performed over space. Since r. H = 0 and r  E =  μ0
∂H
∂t , this
leads to
r2H = μ0E0
∂2H
∂t2 :
Similarly,
r2E = μ0E0
∂2E
∂t2 :
The above equation is widely known as the Helmholtz22 equation for the plane wave, named
after the German physicist.
Expanding the r2 (Laplacian) operator is quite formidable, and does not lead to a closed
solution. To gain insight, we postulate uniform wave in which both ﬁelds are in the transverse
plane, that is the plane whose normal is the direction of propagation. For this, such a wave is
sometimes called a transverse electromagnetic (TEM) wave. Consequently, we may assume
that for example E = Exax, that is, the electric ﬁeld is polarized only in the x direction. To
simplify matters further, we assume both the electric and magnetic ﬁelds vary only in the z
direction, that is the direction of wave propagation. With those assumptions we have
r  E = ∂Ex
∂z ay =  μ0
∂H
∂t =  μ0
∂Hy
∂t ay:
Note that while E is assumed to be in the x direction, H has a component in the y direction only,
both normal to the wave that propagates in the z direction. Similarly,
r  H =  ∂Hy
∂z ax = E0
∂E
∂t = E0
∂Ex
∂t ax:
The two equations above lead to
∂2Ex
∂z2 = μ0E0
∂2Ex
∂t2 :
22 Hermann Helmholtz was a German physicist in the 19th century (1821–1894). Helmholtz’s equation is the general partial
differential equation of the form: r2A + k2A = 0.
28
RF Components

This is very similar to the transmission line equation derived earlier, whose solution was shown
to be of the form
Ex z; t
ð
Þ = f 1 t  z
ν


+ f 2 t + z
ν


= Ex
+ + Ex
:
The propagation is in the z direction, as stated earlier, and has velocity
ν =
1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
μ0E0
p
= c,
where c = 3  108m/s is the speed of light in free space.
If the wave is sinusoidal, as it generally is, the functions f1 and f2 assume sinusoidal forms,
and we may write
Ex(z, t) = E01 cos (ωt  k0z + φ1) + E02 cos (ωt + k0z + φ2),
where k0 	 ω
c is the wave number.
In a manner consistent with our analysis of transmission lines, we can identify the forward
and backward wave propagations from the wave solution above. Furthermore, we deﬁne the
wavelength (λ) in free space as the distance over which the spatial phase shifts by 2π, assuming
ﬁxed time:
k0λ = 2π.
Thus
λ = 2π
k0
= c
f :
Now, consider an arbitrary point in the cosine of the ﬁrst term of the wave equation
(E01 cos (ωt  k0z + φ1)). To keep track of the chosen point, we then require the argument of
the cosine to be an integer multiple of 2π:
ωt  k0z = 2πm.
As time increases (as it should), the position z must also increase to satisfy the above condition.
As such, the entire wave moves in the forward z direction with a velocity of c = ω
k0. For the
second portion of the wave equation (E02 cos(ωt + k0z + φ2)), we can identify a motion in the
negative z direction, or backward propagation.
In the common case of sinusoidal propagation in time, it is more convenient to use
complex notations and phasor. This leads to the following for the ﬁrst two of Maxwell’s
equations:
r  H = jωE0E
r  E =  jωμ0H,
where E and H represent phasor vectors, and ω is the angular frequency of propagation.
Following a procedure similar to the one in the time domain, we arrive at
r2H =  ω2μ0E0H =  k0
2H,
1.8 The Uniform Plane Wave
29

and
r2E =  k0
2E,
where k0 = ω
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
μ0E0
p
= ω
c, as deﬁned earlier.
If for example the electric ﬁeld is polarized in the x direction, and assuming both magnetic
and electric ﬁelds vary only with z, in the phasor domain we have
Ex(z) = E01ejk0z + jφ1 + E02e+jk0z + jφ2,
which is the solution to the phasor domain wave equation derived from the general equation
(r2E =  k0
2E) expressed below:
∂2Ex
∂z2 =  k02Ex:
Taking the real part of the phasor solution multiplied by e jωt results in the same time domain
solution as we had before:
Ex(z, t) = Re [(E01ejk0z + jφ1 + E02e+jk0z + jφ2)e jωt].
Given the complex notation, we may conveniently arrive at a solution for the magnetic ﬁeld as
well. Since
r  E =  jωμ0H,
and given the TEM assumptions earlier, we have
dEx
dz =  jωμ0Hy:
Hence
Hy =
1
jωμ0
jk0
ð
ÞE01ejk0z + jφ1 +
jk0
ð
Þ
ð
ÞE02e + jk0z + jφ2


,
which could be rearranged as follows:
Hy = H01ejk0z + jφ1 + H02e + jk0z + jφ2 = E01
ﬃﬃﬃﬃﬃ
E0
μ0
r
ejk0z + jφ1  E02
ﬃﬃﬃﬃﬃ
E0
μ0
r
e + jk0z + jφ2:
and in the time domain
Hy z; t
ð
Þ = E01
ﬃﬃﬃﬃﬃ
E0
μ0
r
cos ωt  k0z + φ1
ð
Þ  E02
ﬃﬃﬃﬃﬃ
E0
μ0
r
cos ωt + k0z + φ2
ð
Þ:
Two key observations can be made: First, the forward and backward electric and magnetic
ﬁelds amplitudes are related by:
Ex01 = η0Hy01
Ex02 =  η0Hy02,
30
RF Components

where
η0 =
ﬃﬃﬃﬃﬃ
μ0
E0
r
= 120π = 377Ω:
The dimension of η0 is in ohms, evident from the fact that it relates electric ﬁled intensity
(measured in V/m) to the magnetic ﬁeld intensity (measured in A/m). It is a direct analogy to the
transmission line characteristic impedance Z0 =
ﬃﬃﬃ
L
C
q
, which was deﬁned as the ratio of the
voltage to the current of a traveling wave.
Second, we notice the minus sign between the forward and backward components of the two
ﬁelds. This is again consistent with our transmission line analysis where there was a minus sign
between forward and backward voltages and currents.
To have a feeling for the way the ﬁelds behave, plotted in Figure 1.28 are the electric and
magnetic ﬁelds where they vary over space (versus z), but are shown at t = 0.
In reality, a uniform plane wave cannot exist physically, as it extends to inﬁnity and requires
an inﬁnite amount of energy. Nonetheless, the distant ﬁeld of a transmitting antenna is basically
a uniform wave in some limited region. We apply our ﬁndings here to obtain insight into
antennas discussed in the next section. Before that, let us discuss the power as well as wave
propagation in conductors (as opposed to free space) ﬁrst.
1.8.2
Wave Propagation in a Good Conductor: Skin Effect
An important discussion related to wave propagation pertains the behavior of a good conductor
when a uniform plane wave is established in it. We will show that the primary transmission of
energy must take place in the region outside the conductor (or on the surface), as all the time-
varying ﬁelds attenuate very quickly within a good conductor.
Whereas in free space we assumed the current density J is zero, in the case of conductive
materials, in which currents are formed by the motion of free electrons (or holes) under the
inﬂuence of an electric ﬁeld, the governing relation is J = σE. With ﬁnite conductivity (σ), the
wave loses power through resistive heating of the material.
Consequently, Maxwell’s ﬁrst equation in sinusoidal steady state may be written as
r  H = J + jωEE = σE + jωEE = σ + jωE
ð
ÞE = jω E 1  j σ
ωE


h
i
E:
z
Ex
l
x
y
z
Hy
x
y
Figure 1.28: Instantaneous values of the electric and magnetic ﬁelds for t = 0
1.8 The Uniform Plane Wave
31

The solution then may be found exactly as before, but with k0 = ω
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
μ0E0
p
replaced with k
deﬁned as
jk = jω
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
μ E 1  j σ
ωE


h
i
r
= α + jβ,
which is directly resulted from E being replaced by E 1  j σ
ωE


. The new k is a complex number,
and the values of α and β may be obtained by expanding the term under square root. The
general solution for the electric ﬁeld phasor is
Ex(z) = E0ejkz = E0eαzejβz.
While ejβz results in the same time domain expression as before, the presence of eαz
indicates an exponential decay of the magnitude over space, resulting from losses in the
conductor.
In case of a good conductor, where the conduction current σE as expressed by Ohm’s law is
much larger than the displacement current (that is to say σ is large), we may approximate
jk = jω
ﬃﬃﬃﬃﬃ
μE
p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  j σ
ωE
r
ﬃjω
ﬃﬃﬃﬃﬃ
μE
p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
j σ
ωE
r
= j
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
jωμσ
p
:
Accordingly, as
ﬃﬃﬃﬃﬃ
j
p
= 1jﬃﬃ
2
p , we can readily obtain
α = β =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ωμσ
2
r
:
The electric ﬁeld will be
Ex(z, t) = E0eαz cos(ωt  βz),
and the current density in the conductor is
Jx = σEx = σE0eαz cos(ωt  βz),
which shows an exponential decay rate of
δ = 1
α =
1
2 ω0μ0σ

1=2
:
The parameter δ measured by the meter is known as skin depth, and denotes the depth by which
the electric ﬁeld (or the current) decays by e1. In typical CMOS processes, δ is several μm at
GHz frequency range.
If the skin depth is comparable to the width of the conductor, the effective resistance of the
conductor increases, as the current tends to stay only at the surface (Figure 1.29). Clearly, the
impact exacerbates as the frequency increases.
The solution to the magnetic ﬁeld is readily obtained, considering
η =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
μ
E + σ
jωE
v
u
u
t
=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
jωμE
σ + jωμE
s
,
32
RF Components

which in the case of a good conductor may be approximated as
η ﬃ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
jωμE
σ
r
= 1 + j
σδ :
Similar to k, η is a complex number, which results in an additional phase shift (of 45) between
magnetic and electric ﬁelds. Thus
Hy z; t
ð
Þ = σδE0
ﬃﬃﬃ
2
p
eαz cos ωt  βz  π
4


:
At a given point, the maximum amplitude of the magnetic ﬁeld happens one-eighth of a cycle
later with respect to that of the electric ﬁeld.
Example: In 16nm CMOS, the top metal layer has a thickness of about 2.8μm, and a
conductivity of 3.4  107S/m. The skin depth at 2.4GHz is
δ =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
πf μσ
s
=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
πf μ0σ =
s
1:8μm:
We see that the skin depth is quite comparable with the metal thickness at this frequency.
Physically, the skin effect can be interpreted considering that a unit ﬁlament of current at the center
links more ﬂux, and thus has more inductance. Since the current tends to ﬂow into the path of least
impedance (not necessarily the least resistance), it clings toward the outside of the wire (Figure 1.30).
z
x
y
d
0
a
b
J0
Figure 1.29: The current density in a good conductor
More inductance 
toward center
DC
AC
Figure 1.30: Physical interpretation of the skin
effect in a wire
1.8 The Uniform Plane Wave
33

Interestingly, the current sees a smaller resistance inside, but then larger inductance, and
overall takes an exponential distribution as we showed earlier.
1.8.3
Power Considerations
When dealing with waves and antennas, what ultimately matters is the amount of power
transmitted or received. We presented the power associated with static electric and magnetic
ﬁelds earlier. To ﬁnd the power in a uniform plane wave, it is necessary to describe a theorem
for the electromagnetic ﬁeld known as the Poynting theorem, originally developed by English
physicist John Poynting in 1884.
Using the vector identity
r. (E  H) =  E. r  H + H. r  E,
and some straightforward algebraic steps performed on Maxwell’s equations, one can show
r: E  H
ð
Þ = J: E + ∂
∂t
EE2
2 + μH2
2


,
where E = |E|, H = |H|. Taking a volume integral, and using the divergence theorem, we have

þ
S
E  H
ð
Þ dS =
ð
V
J: E
ð
ÞdV + ∂
∂t
ð
V
EE2
2 + μH2
2


dV:
The ﬁrst integral on the right is the total instantaneous ohmic power dissipated within the
volume (assuming a sourceless medium). The second integral on the right is the total energy
stored in the electric and magnetic ﬁelds, and the partial derivatives with respect to time lead to
the instantaneous power going to increase the stored energy within this volume. Thus, the right
side of the equation must be the total power ﬂowing into this volume. Consequently, on the left
side the term
Þ
S(E  H)  dS indicates the total power ﬂowing out of the volume. The integral is
taken over the closed surface surrounding the volume. The product E  H is known as the
Poynting vector,
W = E  H,
and may be interpreted as the instantaneous power density measured in W/m2. Considering
the cross product, it is clear that the Poynting vector must be normal to electric and magnetic
ﬁelds. This is consistent with our earlier example of a wave propagating in the z direction with
electric and magnetic ﬁelds having components at the x and y directions. Considering that in
free space
Ex z; t
ð
Þ = E0 cos ωt  k0z
ð
Þ
Hy z; t
ð
Þ = E0
η0
cos ωt  k0z
ð
Þ
34
RF Components

we have
Wx z; t
ð
Þ = E02
η0
cos2 ωt  k0z
ð
Þ,
and the average power density is
Wx,avg = 1
T
ðT
0
Px z; t
ð
Þdt = E02
2η0
,
which greatly resembles the average power dissipated in a lossy passive circuit. Note that the
equation above denotes the average power density, which is evident from the fact that the
electric ﬁeld is measured in V/m.
Example: For a good conductor discussed in the previous section (Figure 1.29), the
average power density becomes
Wx,avg = σδE02
2
ﬃﬃﬃ
2
p
e2z=δ cos π
4
 
= σδE02
4
e2z=δ:
Note the energy decay of e2z/δ. In terms of current density, since Jx = σEx, the above
equation can be rewritten as
Wx,avg = δJ02
4σ e2z=δ,
where J0 is the current density on the surface (but decays exponentially over the z
direction). The total power loss at the surface of the conductor is
Pavg = δJ02
4σ ab:
Example: As a thought experiment, let us ﬁnd the effective resistance of the conductor of
Figure 1.29. To do so, we shall ﬁnd the total current ﬁrst. We showed in the previous
section
Jx = σEx = J0ez/δ cos(ωt  βz).
The current is moving in the x direction (same as the electric ﬁeld). Thus
I =
ð∞
0
ðb
0
J0ez=δ cos ωt  βz
ð
Þdydz = J0bδﬃﬃﬃ
2
p
cos ωt  π
4


:
Continued
1.8 The Uniform Plane Wave
35

Assuming an effective resistance of Reff, the total power dissipated is
PL = 1
2 Reff Ij j2 = J0bδ
ð
Þ2
4
Reff :
When compared to the earlier expression for the average power (Pavg = δJ02
4σ ab), we
conclude
Reff = 1
σ
a
bδ = 1
σ
a
A ,
which is a familiar expression for the resistance of a piece of conductor with the length a,
and the total area of A = bδ.
If it were not for the skin effect (say at low frequency), the resistance would have been
zero as the conductor is assumed to have an inﬁnite width (in the z direction), despite its
ﬁnite conductivity. Interestingly, the presence of the skin effect reduces the conductor
area effectively to A = bδ, as if it has a ﬁnite width of equal to skin depth. This holds well
for a conductor with a circular cross section as well (e.g., a coaxial cable), if the skin
depth is small compared to the actual radius. We shall use this outcome in Chapter 3 to
arrive at an expression for a coaxial cable loss.
1.9
ANTENNAS
..............................................................................................
An antenna is any device that radiates electromagnetic ﬁelds into space. The ﬁelds originate
from a source that feeds the antenna through (typically) a transmission line (say a micro strip
line printed on the board). The antenna thus serves as an interface between the radio and space
when used as a transmitter, or between space and the radio when used as a receiver. As we will
discuss in Chapter 3, reciprocity results in the receive or transmit antenna characteristics to be
the same, however.
As stated earlier, a complete coverage of antennas is well beyond the scope of this book.
However, as they are an essential part of any wireless system, we shall have a brief discussion
of antenna basics and associated ﬁeld radiation in this section. Further reading on the subject
may be found in [9], [10], [11].
1.9.1
Antenna Basic Principles
Consider an ideal current ﬁlament of inﬁnitesimally small cross section with a length of l, placed
in a lossless medium (e.g., free space), as shown in Figure 1.31. The structure is widely known
as a Hertzian23 dipole, and is one of the earliest and most popular realizations of antennas.
23 Heinrich Hertz was the German physicist in the 19th century to whom the invention of the dipole antenna is assigned. He
was the ﬁrst to experimentally verify Maxwell’s equations and one of the pioneers of the invention of the radio in its
current form today. The SI unit of frequency, hertz, is named in his honor.
36
RF Components

We assume that the ﬁlament is carrying a uniform (with respect to z) sinusoidal current
(of I0 cos ωt), and that it is short, particularly with respect to the wavelength of the signal it is
carrying. For the moment, let us not concern ourselves with the source of this current, and the
apparent discontinuities at each end.
To obtain the electric and magnetic ﬁelds caused by the differential length, we use the vector
magnetic potential (A), brieﬂy discussed earlier, whose curl leads to magnetic ﬂux density,
B = r  A.
From Biot–Savart’s law, it readily follows that
A =
þ μIdL
4πR ,
where R is the distance in space from the differential length of dL, carrying a current of I. For
the case of the short ﬁlament of Figure 1.31, since l is small, the integration is no longer
necessary, and thus
A =
μI t  R
ν


l
4πR
az:
Note that the current is represented by I t  R
ν


, and that A is in the z direction only, as is the
ﬁlament itself (Figure 1.31). ν = ω
k is the velocity, and k = ω
ﬃﬃﬃﬃﬃ
μE
p
is as deﬁned earlier. Using
phasor notation, we have
Az = μI0l
4πR ejkR:
It is more convenient to express the results in the spherical coordinates (Figure 1.32), which will
readily lead to
Ar = μI0l
4πr ejkr cos 
A =  μI0l
4πr ejkr sin ,
z
x
y
l
Figure 1.31: A Hertzian dipole carrying a uniform sinusoidal
current
1.9 Antennas
37

where  is the angle between the z axis and the vector R, connecting the origin to the point of
interest in the space (whose coordinates are (r, , φ)).
From the deﬁnition of A, it follows that
H = 1
μ r  A,
which leads to
Hφ = I0l sin 
4π
ejkr jk
r + 1
r2


:
Note that the magnetic ﬁeld has only a component in φ direction, that is, it circles around the
ﬁlament. The interested reader may prove that if the ﬁlament current were static (see also the
problem sets), the magnetic potential would have been
A = μI0l
4πR az,
leading to the familiar solution of the magnetic ﬁeld as expressed by Biot–Savart’s law:
H = I0l sin 
4πR2 aφ = I0R  dL
4πR3
:
Having the magnetic ﬁeld already, the electric ﬁeld is obtained by
r  H = jωEE,
leading to electric ﬁeld components in the r and  directions:
Er = I0l cos 
2πjωE ejkr
jk
r2 + 1
r3


E = I0l sin 
4πjωE ejkr k2
r
+ jk
r2 + 1
r3


:
In the case of a far ﬁeld, that is, if kr  1, only 1
r terms remain, and consequently
Hφ ﬃjk I0l sin 
4πr
ejkr
z
x
y
q
Az
Ar
–Aq
Figure 1.32: Expressing the magnetic vector potential of a dipole in
spherical coordinates
38
RF Components

E ﬃjkη I0l sin 
4πr
ejkr = ηHφ,
and η =
ﬃﬃﬃﬃﬃﬃﬃ
μ=E
p
, as deﬁned before. Note that the Er terms goes away, and just like uniform plane
wave, the electric and magnetic ﬁelds are now related by E = ηHφ. In time domain, we can
now write
Hφ =  I0lksin
4πr
sin ωt  kr
ð
Þ = E
η :
The power density vector is in r direction and whose magnitude is equal to
Wr = EHφ = η I0lksin
4πr

2
sin2 ωt  kr
ð
Þ:
Note that the power density drops by 1
r2. The total instantaneous power crossing an arbitrary
sphere of radius r is then obtained by
P =
ð2π
0
ðπ
0
Wrr2 sin ddφ,
and the average power is readily calculated to be
Pavg = 10 I0lk
ð
Þ2 = 40π2 I0l
λ

2
:
Compared to a simple resistive circuit, we can deduce the effective radiation resistance of the
dipole as
Rradiation = 80π2
l
λ
 2
:
For the average radiated power to be meaningfully large, the dipole length needs to be
comparable to the wavelength (due to the term
l
λ

 2), as is often noted in the literature.
Equivalently, one must ensure that the effective radiation resistance is large with respect to
the ohmic loss of the wire and other parasitic effects.
It is possible to extend the analysis of the differential current ﬁlament to a short dipole. If the
dipole is short, the current distribution is generally not uniform, and one expects it to be zero at
the two ends and maximal at the center, as depicted in Figure 1.33. Also shown is a practical
current feed to the antenna through a transmission line. The antenna has identical currents at the
two halves, and the gap at the center point is typically small and has a negligible impact.
A linear current distribution results in an average current of I0/2, and thus one-fourth smaller
radiation resistance. In practice the current distribution may be somewhat different, perhaps
closer to sinusoidal. Furthermore, retardation effects may cause the signal arriving at any ﬁeld
point from the two ends of the antenna not to be in phase, and thus may result in some
cancellation.
For a half-wave dipole (l = λ
2), which is arguably one of the world’s most popular antennas,
we can show that the actual radiation resistance in about 73Ω, whereas the simple equation
1.9 Antennas
39

developed earlier underestimates a resistance of 49Ω (if an average current of I0/2 assumed). If
the current distribution were assumed to be sinusoidal, the average current would have been
2
π I0, leading to a closer estimate of 80Ω for the resistance.
1.9.2
Antenna Characteristics
To be able to fully describe and quantify the radiation of an antenna, several key parameters are
typically deﬁned.
For any antenna, at far-ﬁeld, we can show that the electric ﬁeld has the general phasor of the
form
E = E0 F ; φ
ð
Þa + G ; φ
ð
Þaφ

 ejkr
r
,
where F(, φ) and G(, φ) are normalized functions of  and φ only. The solution for the
magnetic ﬁeld is
H = E0
η
G ; φ
ð
Þa + F ; φ
ð
Þaφ

 ejkr
r
:
Accordingly, from our discussion in Section 1.8.3, the average power density is
Wavg = 1
2 Re E  H∗
½
 = E0
j
j2
2ηr2
F ; φ
ð
Þ
j
j2 + G ; φ
ð
Þ
j
j2
h
i
ar:
For a current ﬁlament, for example,
F ; φ
ð
Þ = sin 
E0 = jηkl I0
4π ,
while the electric ﬁeld has no component in the φ direction, and hence G(, φ) = 0.
For longer length dipoles, one can consider the antenna as made up of a stack of ﬁlaments of
inﬁnitesimally short length, with a sinusoidal current distribution. If each half of the antenna
(Figure 1.33) has an arbitrary length of l
2 (thus a total length of l), then by integration we obtain
z
y
Transmission Line
l
I0
Figure 1.33: A dipole with proper transmission line feed
40
RF Components

F ; φ
ð
Þ =
cos kl cos 
2


 cos kl
2
 
sin 
,
and
E0 = jη I0
2π :
For more details, see Problem 24.
Example: For a half-wave dipole, l = λ
2, thus
F ; φ
ð
Þ = F 
ð Þ =
cos π
2 cos 


sin 
:
This yields
Pavg =
ð2π
0
ðπ
0
E0
j
j2
2η
F 
ð Þ
j
j2 sin ddφ = 30I0
2
ðπ
0
F 
ð Þ
j
j2 sin d,
and the radiation resistance will be
Rradiation = 30
ðπ
0
F 
ð Þ
j
j2 sin d:
The integral may be evaluated numerically, leading to a radiation resistance of 73Ω.
With this background, let us take a look at a few key requirements.
– Radiated power: In general,
Pavg =
ð2π
0
ðπ
0
E0
j
j2
2η
F ; φ
ð
Þ
j
j2 + G ; φ
ð
Þ
j
j2
h
i
sin ddφ
Rradiation = 2Pavg
I02 :
Furthermore, the average radiated power density (in W/m2) may be expressed by
Wavg = 1
2 Re E  H∗
½
,
while the radiated power is in the r direction clearly.
For the dipole, since F(, φ) = sin , we showed that
Pavg = 40π2 I0l
λ

2
Rradiation = 80π2
l
λ
 2
:
1.9 Antennas
41

– Antenna directivity: The total radiated power was shown to be
Pavg =
ð2π
0
ðπ
0
Wr,avgr2 sin ddφ,
deﬁning the differential angle as
dΩ = sin ddφ,
and the radiation intensity as
K ; φ
ð
Þ = r2Wr,avg:
Since in general Wr,avg = E0
j
j2
2ηr2
F ; φ
ð
Þ
j
j2 + G ; φ
ð
Þ
j
j2
h
i
, then
K ; φ
ð
Þ = E0
j
j2
2η
F ; φ
ð
Þ
j
j2 + G ; φ
ð
Þ
j
j2
h
i
:
The radiated power is
Pavg =
ð2π
0
ðπ
0
KdΩ:
Interestingly, for all antennas at the far-ﬁeld (say ten wavelengths or more away), Wr,avg
exhibits a 1/r2 dependence. This is best understood from the conservation of energy; in a
lossless medium, the total power at an arbitrary space of r is evaluated by integration at the
sphere surface, which is equal to 4πr2. The radiation intensity thus comes out to be
independent of r, and only a function of  and φ.
For the special case of an isotropic radiator, that is to say, if the antenna radiation intensity
is constant (K(, φ) = K0), then
Pavg =
ð2π
0
ðπ
0
KdΩ = 4πK0:
Consequently, we deﬁne the antenna directivity as
D ; φ
ð
Þ = K ; φ
ð
Þ
K0
= 4π K ; φ
ð
Þ
Þ
SKdΩ
:
The signiﬁcance of directivity is that it indicates whether the antenna intensity is more
prominent in certain directions than in others.
Example: For a Hertzian dipole, we have
K ; φ
ð
Þ = K 
ð Þ = 1
2 η I0lk
4π

2
sin2 :
42
RF Components

Thus
D ; φ
ð
Þ = 2πη kl I0
4π

2 sin2 
10 I0lk
ð
Þ2
=
η
80π sin2  = 3
2 sin2 :
Hence, the maximum directivity of a Hertzian dipole is 3
2 or 1.76dB.
By contrast, for a half-wavelength antenna, by solving the integral numerically, we can
show that the maximum directivity of 1.6dB.
– Antenna gain and efﬁciency: Given the resistive losses within the antenna, the radiated
power (Pr), worked out earlier, is less than the total power delivered to the antenna (Pin). To
quantify, we deﬁne the radiation efﬁciency as
ηr = Pr
Pin
,
which is clearly always less than one.
Furthermore, assuming a lossy antenna with an isotropic radiation, we have
Pin = 4πK0.
Accordingly, the antenna gain is deﬁned as
G ; φ
ð
Þ = K ; φ
ð
Þ
K0
= ηrD ; φ
ð
Þ:
For a lossless antenna hence, the gain and directivity are the same.
The interested reader as an exercise may work out the above parameters for a general
dipole of length l, based on the F ; φ
ð
Þ =
cos kl cos 
2
ð
Þ cos
kl
2ð Þ
sin
function calculated earlier.
1.10 INTEGRATED CAPACITORS
..............................................................................................
It is often very desirable to tune the resonance frequency of LC tanks. For instance, in a tuned
ampliﬁer a discrete tuning may be required to extend the bandwidth, whereas in an oscillator
locked in a phase-locked loop, both discrete and continuous tuning are needed. Due to their
physical structure, inductors are usually not viable options, although several structures have
been proposed that vary the inductance through using multi-tap switched segments [12]. This
usually comes at the cost of performance, and at best offers only a discrete tuning. Capacitors,
on the other hand, are very well suited to provide the tuning. In this section we discuss a few
schemes that are commonly used in RF integrated circuits. Before that, let us ﬁrst brieﬂy take a
look at the common ﬁxed capacitors available in integrated circuits.
The gate capacitance of MOS transistors may be exploited to realize high density but
nonlinear capacitors. Shown in Figure 1.34 (the gray curve) is the simulated capacitance versus
gate voltage of a 40nm regular NMOS capacitor. Depending on the gate voltage, the device
1.10 Integrated Capacitors
43

operates in accumulation (approximately for VGS < 0), depletion (0 < VGS < VTH), or inversion
(VGS > VTH) [2]. The device threshold voltage (VTH) is estimated to be around 400mV. In
inversion or accumulation the capacitance reaches a maximum, close to gate-oxide capacitance,
COX. To achieve a reasonably linear response, the device should be biased at voltages well
above threshold (say greater than 500mV in our example below), which makes it unsuitable for
a low supply voltage application. Moreover, MOS capacitors have usually a very large gate
leakage, which may be problematic. For that reason, a thick-oxide device that is less dense but
has substantially less leakage may be chosen.
To avoid inversion, the NMOS may be placed inside an n-well [13] at no extra cost, known
as accumulation-mode MOS capacitor (Figure 1.35). The naming has to do with the fact that the
transistor must stay either in depletion or in accumulation.
This leads to the C–V characteristics also shown in Figure 1.34 (the black curve). Even
though the capacitance is still quite nonlinear, the accumulation starts right around 0V rather
than the threshold voltage. Consequently, it is easier to bias the device at low voltages and
beneﬁt from an almost ﬂat region where the gate capacitance has reached COX.
In many cases, for instance when the capacitance is placed in the feedback path of an op-
amp, it may not be practical to apply a relatively large bias voltage. An alternative is to use a
linear capacitor formed by the fringe ﬁelds that are quite strong in most modern CMOS
processes due to the close proximity of metal lines. While problematic for routing signals
2.0E-16
6.0E-16
1.0E-15
1.4E-15
1.8E-15
-1.2 -1.0 -0.8 -0.6 -0.4 -0.2 0.0 0.2 0.4 0.6 0.8 1.0 1.2
Accumulaon
Regular
Capacitance, F
VGS, V
Figure 1.34: Regular and accumulation-mode MOS capacitance
VG
VCTRL
n+
n+
p-sub
n-well
Figure 1.35: Accumulation-mode MOS capacitor
44
RF Components

and connecting blocks, this along with the large number of metal layers available could be
taken advantage of in building linear capacitors. An example is shown in Figure 1.36. To
maximize density, minimum width metal lines are placed at minimum spacing allowed by
technology, and the two terminals form a comb-like structure. Moreover, several layers of
metals connected on each end may be placed on top of each other to improve density further.
It is common for CMOS processes to provide a thick or ultra-thick top metal layer used for
clock tree routing or inductors. Since the minimum spacing allowed is usually too large (for
example 1.8μm for the very top layer known as the AP layer in 16nm CMOS), the top thick
metal may not be used. Additionally, there is a concern over how large the bottom plate
parasitic capacitance would be. Therefore, it may be advantageous to drop one or two of the
bottom metal layers as well (particularly the poly and metal one due to large sheet resistance), to
place the capacitor further away from the substrate and reduce the bottom plate capacitance.
However, if fewer metal layers are used, for the same value of capacitance the structures need to
be bigger, and hence the bottom plate parasitic increases accordingly. In a 40nm CMOS process
with a thick M6 option, the best compromise appears to be using M3–M5, leading to a density
of about 2fF/μm2. The bottom (or top) plate parasitic is generally very small, about 1–2%. For a
given structure, the exact amount of capacitance is very difﬁcult to calculate using closed
formulas, and it is often best to use extraction tools (such as EMX)24 to predict the capacitance.
A lumped model of the capacitance is presented in Figure 1.36. The bottom and top plate
parasitics that are generally symmetrical due to the physical structure of the capacitor are
connected to substrate. The substrate is lossy and is typically modeled by a parallel RC circuit.
Since the bottom plate parasitic capacitance (Cbottom) is small, and RSUB is usually large for bulk
processes, this loss is negligible for frequencies up to several GHz. Additionally, there is the
metal series resistance forming the comb lines. If for a given capacitance the structure is built to
consist of N smaller units in parallel, this resistance is then reduced by N2, typically leading to a
very high-Q capacitor for well-designed structures.
The fringe capacitors scale with technology to a good extent, as the physical spacing between
metal lines generally improves. Shown in Figure 1.37 is multi-ﬁnger fringe capacitance density
in fF/μm2 for several recent generations of standard CMOS processes. Note that unlike MIM
A
B
A
B
Substrate
Top View
Side View
Lumped Model
Cbottom
C
r
Cbottom
CSUB/RSUB
A
B
Figure 1.36: Fringe capacitors
24 EMX is a planar 3D integral equation solver that uses an accurate representation of Maxwell’s equations.
1.10 Integrated Capacitors
45

(metal–insulator–metal) capacitors, fringe capacitors do not require any additional process
steps, and thus incur no extra costs. By comparison, a thin-oxide MOS capacitor in 28nm is
23fF/μm2 (corresponding to an oxide thickness of about 1.25nm), whereas a thick oxide one is
10fF/μm2. Note that if MOS capacitors are used, it is still possible to ﬁll fringe capacitors on top
to further boost the density.
Continuous tuning may be achieved by using one of the two MOS structures discussed
earlier. Particularly NMOS in n-well is desirable as it provides a greater tuning range. For a
regular NMOS, if the voltage swing across the tank were large (as is the case for most CMOS
oscillators) regardless of the DC bias applied, the effective capacitance would be mostly COX.
That is because the depletion capacitance corresponds to a relatively narrow region of the C–V
curve (Figure 1.34). To illustrate this important point further, Figure 1.38 shows a large signal
simulation of a 28nm MOS capacitor. The effective capacitance is plotted versus the control
voltage, for four different values of signal swing across it, 0, 0.5V, 1V, and 1.8V. The effective
capacitance here is deﬁned as the magnitude of the fundamental component of the current,
divided by the voltage swing across the capacitance, normalized to the angular frequency.
In the case of a regular MOS capacitor, the ratio of maximum to minimum capacitance (that
is, approximately COX to COX||CDEP) is around 2.5, but diminishes to less than 1.4 as the signal
swing increases. The accumulation mode varactor, on the other hand, has a maximum to
minimum capacitance ratio of about 2, which is maintained reasonably well for signal swings
of as high as 1.8V. The two varactors are identical in size and use a thick oxide NMOS with a
channel length of 0.75μm. Although a shorter channel results in a better Q, it has a worse tuning
range and handles less swing due to reliability.
2
4
6
Density, fF/µm2
Technology
130n
65n
40n
28n
Figure 1.37: Fringe capacitance density in various processes
Capacitance, F
0.0E+00
5.0E-14
1.0E-13
1.5E-13
2.0E-13
2.5E-13
-1
-0.6
-0.2
0.2
0.6
1
1.4
1.8
2.2
2.6
3
3.4
3.8
0.0E+00
5.0E-14
1.0E-13
1.5E-13
2.0E-13
2.5E-13
-1
-0.6
-0.2
0.2
0.6
1
1.4
1.8
2.2
2.6
3
3.4
3.8
VCTRL, V
VCTRL, V
AC Swing
AC Swing
Accumulaon
Regular
Figure 1.38: Large signal MOS capacitor simulation
46
RF Components

Since the Q of continuously tuned capacitors may not be very high, a wider tuning range
without compromising Q can be achieved by incorporating discrete tuning using switched
linear capacitors along with MOS varactors, as illustrated in Figure 1.39 [14]. This also results
in less VCO gain, and thus less sensitivity to noise and interference at the VCO control voltage.
The MOS varactor needs to provide only enough range to cover the worst case discrete
step size.
A larger switch results in lower resistance and thus a better quality factor; however, the
switch parasitic capacitance in the off mode limits the tuning range. If designed differentially,
the same tuning range is achieved but with twice as much Q, as the on resistance is half.
A differential design in 28nm CMOS as an example is shown in Figure 1.39. It consists of
32 units of 40fF linear capacitors, with the total capacitance varying from 430fF to 1.36pF
(about 3), in steps of 29fF. The Q at 3.5GHz varies from a maximum of 80 to 45 when all the
capacitors are turned on. The switches are 111/0.1μm.
In the differential design, it may often be necessary to bias the switches’ drain and source,
which can easily be done by placing a large resistance there.
1.11 INTEGRATED INDUCTORS
..............................................................................................
First introduced into silicon in 1990 [15], [16], monolithic inductors have since been widely
used in RF and mm-wave applications. Due to fabrication limitations, on-chip inductors are
typically realized as metal spirals. To achieve a lower loss and thus better Q, it is common to
use the top metal layer, which is typically thick or ultra-thick.
Applying Biot–Savart’s law to calculate the magnetic ﬁeld, one can show that the self-
inductance of a piece of wire with a length of l, and a rectangular cross section at moderate
frequencies (several GHz) is [17]
L  μ0
2π l
ln
2l
W + t + 0:5


,
where t is the thickness of the metal, and is ﬁxed for a given technology, while W is the metal
width and is a design parameter. All units are metric, and we assume that the length is much
larger than the width. To gain some insight, the series resistance of the same line at low
frequency is given by
C
2C
2nC
… 
… 
Discrete Tuning Concept
Diﬀerenal Design
VCTRL
VCTRL
S1
S2
Sn
Figure 1.39: Discrete
tuning using switched
capacitors
1.11 Integrated Inductors
47

r = Rh
l
W ,
where R□is the metal sheet resistance (about 10.4mΩ/□for ultra-thick top layer for instance).
If the only concern is to maximize Q for a given inductance, then increasing the width helps, but
it must be noted that a larger W needs a larger length to keep the inductance constant, leading to
some increase in resistance and of course area.
Example: For a typical CMOS process considering an ultra-thick metal layer with R□= 10.4
mΩ/□and t = 2.8μm, the corresponding theoretical inductance suggested by the equations
above and Q have been plotted in Figure 1.40 at 4GHz, assuming a 1mm trace.
The quality factor predicted in Figure 1.40 applies only to low frequencies, as it assumes the
low-frequency series resistance is the only loss mechanism. This is certainly not true, as we
already know that at higher frequency the skin effect results in a higher resistance, and hence
lower value of Q as suggested in the example. As we discussed in Section 1.8.2, in a conducting
medium where the conduction current, σE, as expressed by Ohm’s law is much larger than the
displacement current, the solution for the electric ﬁeld is given by
E = E0axejkz = E0axeαzeβz,
where
α = β =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ωμσ
2
r
and δ =
1
2 ω0μ0σ

1=2 is the skin depth. As pointed out, this suggests that in the conductor, the
ﬁeld decays by an amount of e1 in a distance of one skin depth δ, which could be comparable
to metal width or its thickness at high frequencies. For instance, the skin depth for the top metal
layer used in the previous example is about 1.4μm at 4GHz. As a result, effectively the current
tends to ﬂow more at the surface, and the resistance will increase. Accordingly, a modiﬁed
expression for the metal resistance to include the skin effect is
Q
10
20
40
30
Width, µm
L, nH
0.6
0.8
0.4
1.0
1
13
1.2
5
17
9
Width, µm
1
13
5
17
9
Figure 1.40: Low-frequency theoretical inductance and quality factor for a 1mm trace versus its width
48
RF Components

r = Rh
l
W
t=δ
1  et=δ ,
where t is the metal thickness. At low frequency, δ is large and the equation simpliﬁes to the
original expression for the resistance. However, at very high frequencies, the exponential term
approaches zero and thus
r = Rh
l
W
t
δ = 1
σ
l
δW :
That is, t is replaced by δ at high frequency, which could lead to considerably higher resistance.
Example: A more thorough study of the inductance of a straight line is shown in Figure 1.41.
This not only is beneﬁcial for understanding the spiral inductors, but also gives a good
perspective on the implications of the long routing often needed for signals or power rails in
RF. Shown in Figure 1.41 is the simulated inductance and quality factor of a 1mm piece of
metal in 16nm CMOS using EMX. Three different widths are simulated using the top ultra-
thick metal layer (sheet resistance of 10.4mΩ/□and about 2.8μm thickness), along with a
fourth case of 20μm wide trace, but with the top metal as well as the next two top metal layers
(sheet resistance of 16.7mΩ/□and about 12μm thickness) all shorted together.
For the case of 10μm wide metal, the calculated low-frequency inductance is about
1.1nH, and the quality factor is 0.6 at 100MHz (Figure 1.40), both matching reasonably
well with the simulations. As do the other three cases. For instance, doubling the width to
20μm raises the Q to about 1.1, and shorting all the top three metals brings it up to 2.1.
However, evidently the quality factors do not rise linearly with frequency as explained
earlier. In fact, in addition to the skin effect, which is comparable to the metal widths
used, the substrate loss discussed shortly is another important contributor for integrated
inductors or transmission lines, especially at higher frequencies. At 4GHz, for instance,
the quality factor is simulated to be around 18.3 for 10μm wide metal, and increases only
to 27.4 if the metal width is doubled. Keeping the width at 20μm but shorting the top three
metals leads to only a small rise of about 10% to 30.8, primarily limited by the skin effect.
Q
10
20
25
30
Frequency, GHz
L, nH
0.6
0.8
0.4
1.0
0
20
5
15
4
8
12
16
1µm
1.2
Frequency, GHz
0
20
4
8
12
16
10µm
20µm
20µm 3 layers
1µm
10µm
20µm
20µm 3 layers
Figure 1.41: Simulated inductance and quality factor of a 1mm piece of metal in 16nm CMOS
1.11 Integrated Inductors
49

1.11.1 Spiral Inductors
Using a long piece of wire as described above is clearly not a viable option, as apart from the
area, connecting it to any circuit is impractical. It is more common to form spirals to make it
more compact and practical to use. The most natural choice would be a circle. However, circles
are not physically possible to be laid out in an integrated circuit. The same length could be
wound to a square spiral as shown in Figure 1.42. According to Biot–Savart’s law, the magnetic
ﬁelds of all four legs add up in the center, with a direction normal to this page of the book,
although they will not add quite constructively at the edges. A better approximation of the circle
may be made by using a hexagon or an octagon, as 45 angles are allowed. This results in a
more constructive addition of the magnetic ﬁelds (Figure 1.42), typically leading to a higher Q.
The inductance of the spiral could be given with the general expression as follows [17], [18]:
LT =
X
L +
X
M+ 
X
M,
where the ﬁrst term indicates the sum of the self-inductances of each leg, and the second and
third terms indicate the mutual inductances between parallel legs that carry the same or
opposite direction currents. In the case of a single-turn square spiral shown in Figure 1.42,
the second term does not exist as the parallel legs carry only opposite currents. Ignoring the
mutual inductances for the moment (the third term) and assuming a width of 10μm and a length
of roughly 1mm / 4 = 250μm for each leg, the total inductance is 4  0.21nH = 0.84nH, which
is somewhat less than the 1.1nH obtained for the straight line in the earlier example. Clearly,
this has to do with the logarithmic dependence of the inductance on the inductor length as
shown earlier. In reality the inductance is even less as the negative mutual inductance reduces it
further. Since the series resistance is roughly the same, the upper bound Q obtained earlier is
proportionally less. A closed form expression for the mutual inductance between two pieces of
wires with identical length l, separated by a space d, is quite tedious to calculate [18], [19].
Here, to gain some insight, we provide only the expression for two ﬁlamentary lines (that is,
t and W are much smaller than l and d), which has a simple closed form solution. The equation
may be readily obtained by applying Biot–Savart’s law and integrating over space:
M = μ0
2π l
ln
l
d +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 + l2
d2
s
0
@
1
A 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 + d2
l2
s
+ d
l
2
4
3
5:
For our previous example, if l
d ﬃ1, which is a good approximation for a square single-turn inductor,
then the mutual inductance between two legs is roughly 12% of the inductance of each leg.
H
I
More constructive 
H fields
d
√2d
Figure 1.42: Spiral inductor in integrated circuits
50
RF Components

The inductance may increase if another turn is added (Figure 1.43), assuming that the inner
diameter (DIN) is still large, that is, the inner and outer diameters (DOUT) are comparable. The
increase is due to the large contribution of positive mutual inductance between the adjacent legs
that carry the same current, while the negative mutual inductance of the opposite legs is still
small as they are far apart. Therefore, when designing spiral inductors, it is common to have
hollow structures, with the adjacent legs drawn as close as possible. Keeping the inner diameter
large, however, limits the number of turns allowed.
Multi-turn inductors typically enjoy a more compact design but somewhat larger capaci-
tance. If the inductance needed is small (say a few tenths of henry), then a single-turn inductor
with reasonably large diameter remains the best choice.
For a given structure in general, the inductance can be fully expressed by knowing the metal
width (W), the spacing between adjacent legs (S), the number of turns, and either the inner
diameter, the outer diameter, or the total length (Figure 1.43). For most RF applications, practical
values of integrated inductances range from a few tenths of nH to several nH. Apart from very
simple structures, having closed form expressions for the inductance value is not possible.
Numerous attempts have been made to calculate approximate closed form expressions for the
spiral inductors with somewhat limited accuracy [18], [19], [20], [21]. Given their efﬁciency and
precision, it is best to utilize common 3D electromagnetic simulators such as EMX or HFSS,25
widely used among many RF designers.
1.11.2 Second-Order Effects
Apart from the ohmic loss, there are several other contributors that limit the inductor performance.
Shown in Figure 1.44, the metal strips inevitably have a nonzero capacitance to the substrate.
This capacitance limits the maximum allowable frequency that the inductor can be used at.
This is typically expressed as the self-resonance frequency, that is, the frequency that the total
parasitic capacitance resonates with the inductance. To function properly, the self-resonance
frequency must be obviously well above the maximum frequency that the inductor is intended
to be used. Moreover, this capacitance is connected to the lossy silicon substrate which could
degrade the quality factor at higher frequencies. There is also a capacitance between various
legs of the inductor branches. This capacitance may be ignored for a single-turn structure. However,
for multi-turn inductors it would be relatively important as the adjacent legs are laid out very close
W
S
DIN
DOUT
Strong M
Weak M
Figure 1.43: Multi-turn versus single-turn
inductor
25 HFSS is a commercial ﬁnite element method solver for electromagnetic structures.
1.11 Integrated Inductors
51

to one another to maximize positive mutual inductance. This capacitance is substantially higher in
multi-stacked structures (Figure 1.45) where several inductors of similar structure are placed in
series using lower metal layers to increase the inductance without increasing the area. Since this
structure leads to Q degradation as well, given much larger sheet resistance of lower level metals, it
is not very common unless very large values of inductance are needed.
An alternative structure uses several inductors designed with lower metal layers connected to
each other in parallel instead (Figure 1.45). While this will not lead to an increase in the
inductance, it does improve the ohmic loss to some extent. However, that comes at the expense
of lower self-resonance frequency, as lower metals have higher capacitance to substrate. The
Q improvement as a result of this may not be very signiﬁcant for two reasons: First, the lower
metal levels typically have worse sheet resistance. Second, since the parasitic capacitance to
substrate is increased, Q degradation due to capacitive coupling is worse. At lower frequencies,
say 1GHz or less, this structure may be still helpful. At higher frequencies, say 2GHz or above,
Substrate
RSUB
CSUB
Substrate
H
Induced Current
in substrate
 
Capacitive Loss
Magnetic Loss
Displacement
Current
Figure 1.44: Substrate loss in on-chip inductors
Metal X
Metal X-1
Via X-1
Stacked Inductor
Shunt Inductor
Figure 1.45: Stacked and shunt inductors
52
RF Components

apart from the two reasons mentioned, the skin effect becomes an issue as well, and shunting
the metal layers may not improve the Q at all.
As demonstrated in Figure 1.44, there is also a magnetic loss created at high frequencies. The
magnetic ﬁeld created due to the AC current ﬂowing in the inductor branches results in a
magnetic ﬂux that is varying with time. Faraday’s law suggests that an electric ﬁeld ESi is
induced in the substrate. This electric ﬁeld leads to a current density ﬂow of J = σSiESi
according to Ohm’s law, where σSi is the silicon substrate conductivity. It is as if there is a
transformer reﬂecting the substrate resistance (or loss) in parallel with the inductor (Figure 1.44,
right side). A higher substrate resistance (lower σSi) is preferred to lower this loss. Fortuitously,
most modern CMOS processes use bulk substrate, where the resistivity is relatively high.
Unlike capacitive loss, where adding a metal shield could help, in the case of the magnetic loss
the shield is generally not helpful, as it effectively shorts out the inductor. The impact of the
shield is going to be further discussed in the context of an example shortly.
In addition to the substrate factor, there is another mechanism degrading the inductor quality
factor in the multi-turn spirals known as the proximity effect or current crowding [22], [23],
[24]. In the case of a single-turn inductor, the current and magnetic ﬁeld distributions are fairly
uniform except at the corners, which is expected. On the other hand, in multi-turn structures, the
assumption of uniform current distribution is no longer valid, especially for the metal strips
close to the center of the inductor, as the current as well as the magnetic ﬁeld distributions tend
to become higher near the inner edge. This non-uniform current distribution means that the
resistance increases because the majority of the current ﬂows through a smaller area, leading to
Q degradation because of the higher resistance.
Example: Shown in Figure 1.46 is a 3.6nH inductor designed at 2GHz for LTE applica-
tions. The inductor uses the AP (or RDL) layer, as well as the top two metal layers all
Continued
P1
P2
AP + Top 
Two Metals
280µm
280µm
150µm
15µm
1.8µm
Figure 1.46: A 3.6nH inductor in
16nm CMOS
1.11 Integrated Inductors
53

shorted to improve the ohmic losses (the AP and the top two metals have a sheet
resistance of 10.4mΩ/□, and 16.7mΩ/□, respectively, in the 16nm CMOS process used
here). The inductor uses a relatively large metal width of 15μm, and consequently is
rather large (280μm in dimension).
Shown in Figure 1.47 is the EMX simulated inductance and quality factor over
frequency (that is, the black solid curve labeled “no shield”; we shall discuss the others
shortly). The self-resonance frequency is about 9.6GHz, which is reasonable given the
relatively large inductance and is well above the 2GHz intended frequency of operation.
The quality factor is about 9.4 at 2GHz.
Shorting the top two metals along with AP layer results in a net sheet resistance of 4.6mΩ/□,
which is quite low, and we suspect that along with the skin effect to some extent, the main
reason for a relatively low Q of 9.4 is the substrate capacitive and magnetic losses. Hence,
inserting a shield as shown in Figure 1.48 may seem to be helpful at the ﬁrst glance.
Frequency, GHz
Q
4
8
10
12
Frequency, GHz
L, nH
4
6
2
8
1
2
3
4
10
5
1
10
Solid Shield
Patterned Shield
2
6
No Shield
Floating 
Shield
2
3
4
5
Patterned Shield
Solid Shield
No Shield
Floating 
Shield
Figure 1.47: The simulated performance of the 3.6nH inductance designed for LTE applications
Solid Shield
Patterned Shield
Figure 1.48: Two variations of the inductor of Figure 1.46 with a metal one-layer shield added
54
RF Components

On the left shown is a solid metal one-layer shield that once appropriately connected to an ideal
ground could potentially eliminate the capacitive losses to the substrate. This kind of shielding is
commonly done for the IO pads or RF capacitors and to eliminate the capacitive coupling to the
lossy substrate [25], [26], as if in the simple model of Figure 1.44, RSUB/CSUB is bypassed by the
low-resistance metal shield. In the case of an inductor, in contrast, while it potentially eliminates
the capacitive loss, the solid ground shield also disturbs the inductor’s magnetic ﬁeld. According
to Lenz’s law, an image current will be induced in the solid ground shield by the magnetic ﬁeld of
the spiral inductor. The image current in the solid ground shield will ﬂow in a direction opposite
to that of the current in the spiral. The resulting negative mutual coupling between the currents
reduces the magnetic ﬁeld, and thus the overall inductance. This can be intuitively explained by
placing a very small resistance in the secondary of the transformer in the simple model of
Figure 1.44. Problem 31 shows that assuming a small shield resistance, the effective inductance
is Leff  L1(1  k2), where L1 is the intended inductance, and k is the coupling coefﬁcient between
the inductance and the shield. As the losses stay the same, not only the inductance is reduced, but
also the quality factor could signiﬁcantly degrade.
A patterned shield realized by poly or metal one with slots orthogonal to the spiral as
illustrated in Figure 1.48 helps, on the other hand, as it increases the resistance of the image
current [27]. The slots effectively act as an open circuit to cut off the path of the induced
loop current. The technique is mostly helpful in singled-ended inductors though, and it
naturally tends to degrade the self-resonance frequency. The implications of the shield in
the differential inductors are explained in the next section. Figure 1.47 illustrates three
additional simulated cases for a patterned shield, a solid shield, and a ﬂoating patterned
shield added to the same inductor of the previous example. The shield results in a reduction
of the self-resonance frequency, as expected. For this reason, the effective inductance at
2GHz increases to about 4nH for the patterned shield. The solid shield results in lower
inductance and much worse Q, as anticipated, while the patterned shielded inductor
Q improves to about 12.4. Even though the self-resonance frequency drops to 5.4GHz, it
is still acceptable, as a positive trade-off. It must be emphasized that the shield must be
connected to a good ground with low inductance. As shown in the ﬁgure, the extreme case
of a ﬂoating shield results in no net improvement to Q, but a little worse self-resonance
frequency due to the extra metal layer.
Another interesting and related phenomenon is the lack or presence of the native layer
underneath the inductor. To illustrate this further, shown in Figure 1.49 is the simulated Q of the
3.6nH inductor of the previous example with and without the native layer. The lack of a native
layer results in the excess substrate implant to increase the threshold voltage of regular NMOS
devices.26 Consequently, the channel conductivity increases from 10mS/m to about 50mS/m.
Interestingly, the removal of the native layer, despite a lower substrate resistance, leads to
somewhat improved Q for both the patterned shield and the no shield design, and a Q of about
14 is achievable now.
One may argue that the reason for this behavior has to do with the fact that at the frequency
of interest the capacitive loss of the substrate is a dominant factor. While the shield is
26 Native NMOS transistors have a threshold voltage of close to zero.
1.11 Integrated Inductors
55

expected to help, it will not entirely eliminate that due to the nonzero resistance of the metal
1 layer (in this process, the sheet resistance of metal 1 is quite high, about 1.1Ω/□). Thus,
reducing the substrate resistance by removal of the native layer still helps both the unshielded
and the shielded inductor. At higher frequencies (3–4GHz and above), it is clear that removal
of the NATN layer hurts the Q, suggesting that the substrate magnetic loss is a more dominant
factor. This implies that improving the shield resistance, e.g., using the metal 2 layer shorted
to the original metal 1 layer, could help, a task we will defer to the interested reader to
experiment with.
1.11.3 Differential Inductors
If two identical inductors are used in a differential circuit, they may be replaced by a differential
inductor, where the two single inductors are combined (Figure 1.50) [28]. This naturally leads
to a more compact design. Furthermore, a smaller area means less substrate loss and capaci-
tance, which is important at high frequencies. This of course assumes that the size of the
differential inductor to realize an inductance twice as big as each single-ended one remains the
Frequency, GHz
1
2
3
4
10
5
Q
4
8
10
12
2
6
14
Patterned Shield
No Shield
W/O NATN
W/ NATN
Figure 1.49: Simulated Q of the inductor of
Figure 1.13 with and without the native layer
Differential Circuit
Differential Circuit
Two Single-Ended 
Inductors
Differential 
Inductors
Transformer
P1
P2
S1
S2
Figure 1.50: Differential inductors
56
RF Components

same. This is not exactly the case, and the area tends to grow some, but still there is substantial
saving.
Even though the capacitance to substrate is expected to decrease (ideally halve), the main
drawback of the differential topology is lower self-resonance frequency. This is caused by
higher capacitance between the adjacent legs, compared to two single-spaced legs far apart, as
shown in Figure 1.50. Another disadvantage of differential inductors is the fact that any
unwanted coupling to the inductor (through parasitic capacitive and particularly magnetic
sources) appears as an undesirable differential signal at the two terminals. For two single-
ended inductors, however, if the parasitic source is far enough, it appears as common-mode
noise at the outputs.
Example: A 2-turn 1nH differential inductor using the ultra-thick AP layer only in 16nm
CMOS has been laid out and simulated in EMX, as shown in Figure 1.51. The inductor
has a Q of 16.2 at 5.5GHz.
The inductor simulated performance over frequency is shown in Figure 1.52. In the case of
differential inductors, the presence of the patterned shield proves to be less helpful, as the
electric ﬁelds do not penetrate deeply into the substrate, rather they stay on surface between the
adjacent differential legs of the spiral. In practice, the degradation of the self-resonance
frequency is more of a concern, and often the shield is not used in the differential inductors.
175mm
AP Layer
175 mm
C
10mm
1.8mm
P1
P2
131mm
Figure 1.51: The 10mm-wide
1nH differential inductor layout
1.11 Integrated Inductors
57

Example: As an exercise, the physical structure of the inductor of the previous example has
been kept the same, but only the metal width has been varied. A wider metal of course leads
to a somewhat bigger inductor size (the size changes from 150μm to about 200μm when the
width varies). Shown in Figure 1.53 is the simulated Q of the structure versus the metal
width. In all cases the differential inductance is kept constant at 1nH. Given the relatively
small inductance value, the self-resonance frequency is above 20GHz in all cases. Also
shown is the Q for 10μm width, but two additional cases: AP layer changed to the top metal
(sheet resistance of about 16.7mΩ/□), and both AP and top metal shorted together (shown as
dots).
As expected, the Q improves for a wider metal width, but the effect plateaus beyond a
certain width. This is naturally a function of the frequency due to the skin effect, and it
seems that at 5.5GHz the optimum width is about 10–12μm in this process.
1.11.4 Transformers
An ideal transformer is realized by winding two coils with turn ratios of n1 and n2 respectively
on a magnetic core, as shown in Figure 1.54.
Frequency, GHz
Q
5
10
15
20
L, nH
0.4
0.8
1.2
1
2
3
4
10
5
20
1
2
3
4
10
5
20
Frequency, GHz
Figure 1.52: EMX simulation results of the inductor of Figure 1.51
Metal Width, µmm
Q
12
14
16
18
5
7.5
10
12.5
15
AP Only
AP+TOP
Top Only
Figure 1.53: Q versus the metal width of a 1nH
2-turn differential inductor
58
RF Components

If the core permeability is large (or ideally inﬁnite), the magnetic ﬂux is contained, and the
ﬂux linkages for each coil will be ϕ1 = n1ϕ and ϕ2 = n2ϕ. From Faraday’s law, as v1 = dϕ1
dt and
v2 = dϕ2
dt , we have
v1 tð Þ
v2 tð Þ = n1
n2
:
To ﬁnd the relation between currents, we notice that analogous to Ohm’s law and concept of
resistance for electric ﬁelds, we can deﬁne magnetic reluctance, Rm, relating the current and
magnetic ﬂux as follows (see [6] for more details):
n1i1 + n2i2 = Rmϕ,
and since Rm = 0 for an ideal core, this results in
i1 tð Þ
i2 tð Þ =  n2
n1
:
From this it follows that v1(t)i1(t) + v2(t)i2(t) = 0, for all t, stating that an ideal transformer is
lossless without energy storage capability (unlike inductors or capacitors). Moreover, the
energy conservation tells us that in an ideal transformer the self-inductance of the two coils
must be inﬁnite, with a coupling coefﬁcient of one.
Since a magnetic core with high permeability is not available in integrated circuits, practical
transformers behave more like coupled inductors with reasonably high coupling factor if
designed properly [29]. A differential inductor is in fact a transformer whose secondary ports
are shorted together and connected to a common voltage, as was shown in Figure 1.50.
Therefore, we face more or less similar trade-offs when designing transformers. Obviously it
is key to lay out the primary and secondary lines as close as possible to maximize the coupling
coefﬁcient (k). A k factor as high as 0.8 is achievable with a proper design.
Example: A 2-turn transformer using the ultra-thick AP layer is shown in Figure 1.55.
The secondary has a center tap (marked as C in the ﬁgure) as is usually commonly used in
many applications (e.g., RF ampliﬁers) for biasing purposes. The center tap has been
brought out with a lower metal (the dotted stripe). Since the length of this metal is short,
the impact on the quality factor is usually small. The primary and secondary parts are
labeled P1, P2, S1, S2.
Continued
+
v1
–
i1
+
v2
–
i2
B
Figure 1.54: An ideal transformer
1.11 Integrated Inductors
59

The primary has a simulated inductance of 1.25nH and a Q of 13.4 at 5.5GHz, and the
secondary inductance is 1nH with a Q of 15 at 5.5GHz. The coupling factor is about 0.7 at
5.5GHz and remains relatively ﬂat over frequency. More or less a similar trend as differential
inductors exists here in terms of the metal thickness, the type of metal layer used, etc. The EMX
simulation results of the transformer are shown in Figure 1.56.
Example: Shown in Figure 1.57 is another design, where primary is single turn, while the
secondary is kept at two turns with no center tap. The transformer uses both the AP and
the top metal layer shorted to improve the loss, but that comes at the expense of worse
μ
μ
Figure 1.55: A 2-turn transformer
with secondary center tap
Frequency, GHz
Q
4
8
12
16
Frequency, GHz
L, nH
1.0
1.5
2.5
0.5
2.0
1
2
3
4
10
5
20
1
2
3
4
10
5
20
Secondary
Primary
Secondary
Primary
Figure 1.56: EMX simulation results of the transformer of Figure 1.55
60
RF Components

self-resonance frequency (about 18 GHz). The primary has a simulated inductance of
0.44nH and a Q of 7 at 5.5GHz, and the secondary inductance is 1.14nH with a Q of 12.5
at 5.5GHz. The coupling factor is about 0.8 at 5.5GHz.
The primary reason for worse Q compared to the previous transformer is the large difference
between the primary and secondary inductance. In some applications such as impedance trans-
formation used in RF matching networks (see Chapter 3), different primary to secondary turn
ratios are needed, and the transformer of Figure 1.57 may become very handy. Rather than
specifying the quality factor of either the primary or the secondary, it may be more meaningful to
describe the insertion loss of the transformer. We will take a closer look at this topic in Chapter 3.
1.11.5 Inductor Lumped Circuit Model
Although they are distributed in nature due to their relatively large size, it is convenient to
model inductors by simple lumped elements. The most common circuit is shown in Figure 1.58.
It consists of the low-frequency inductance (L), the series ohmic resistance (r), the oxide
capacitance to substrates (COX), the substrate model (RSUB and CSUB), and CF, which models
the capacitance between adjacent legs. The main advantage of the model is that all its elements
are physical, while it produces a reasonable approximation valid over a wide range of
frequency. It is therefore very common among RF designers to model the inductor as such.
Since the substrate characteristics are not very well known, RSUB and CSUB are usually ﬁtting
parameters. The combination of COX and RSUB/CSUB is typically sufﬁcient to account for both
magnetic and capacitive loss of substrate. While the model could be ﬁt to represent the inductor
at least at one exact frequency, and possibly over a reasonable range, if one is interested in a
μ
μ
μ
Figure 1.57: A 1-turn primary, 2-turn
secondary transformer with no
center tap
1.11 Integrated Inductors
61

true wideband model, S-parameters generated by the simulator (EMX for example) may be
used. To speed up the simulations, EMX may be used to produce a lumped element equivalent
circuit comprising RLC element and dependent sources.27
Without loss of generality, let us take a closer look at the single-ended inductor equivalent
circuit model of Figure 1.58 where we assume one terminal is connected to an AC ground.
Ignoring CF, the input impedance is
ZIN ¼
r þ jlω
ð
Þ 1þ CSUB
COX þ
1
jRSUBCOXω


1 þ CSUB
COX þ
r
RSUB þ jω
L
RSUB þ rCSUB


 LCSiω2 þ
1
jRSUBCOXω
:
To simplify, we recognize that generally r << RSUB, CSUB << COX, and at frequencies of
interest and beyond
		
1
jRSUBCOXω
		  1. The latter arises from the fact that the substrate resistivity
is large, while at higher frequencies the impedance of COX is relatively small.
This leads to
ZIN ﬃ
r + jLω
1  LCSUBω2
ð
Þ + jω
L
RSUB + rCSUB

 :
The impedance is bandpass, although at very low frequencies it does not approach zero. Rather
it becomes equal to the low-frequency series resistance, r, which is expected. The self-
resonance frequency is ωSRF = 1=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LCSUB
p
, where the magnitude of impedance peaks to a value
of
L
L
RSUB + rCSUB ﬃRSUB. We made the assumption that at higher frequencies r << Lω, which is
true if the Q is reasonably large.
The inductance is naturally frequency dependent and by deﬁnition is equal to L ω
ð Þ = jIm ZIN
½
j
ω
.
This leads to
L ω
ð Þ 	 L
1  LCSUBω2
1  LCSUBω2
ð
Þ2þ
L
RSUB þ rCSUB


ω
h
i2 :
Evidently, the low-frequency inductance is equal to L, while the inductance eventually
approaches zero at self-resonance frequency. This makes sense, as at the self-resonance
L
r
COX
CSUB/RSUB
CF
Figure 1.58: Inductor lumped model
27 The equivalent circuit is not physical and is curve ﬁt to merely replace S-parameters to improve convergence and
simulation speed.
62
RF Components

frequency the input impedance has a phase of zero (and a peak magnitude of roughly RSUB, as
discussed before). Beyond the self-resonance frequency ZIN is capacitive. Taking the derivative
of L(ω) versus ω, we can show that the inductance is expected to peak right before approaching
the self-resonance frequency. Deﬁning a unitless parameter, η =
1
2RSUB
ﬃﬃﬃﬃﬃﬃﬃ
L
CSUB
q
, then the frequency
where the inductance peaks is roughly (1  η)ωSRF , and the value of the inductance at that
frequency is L
4η. For typical values, note that η  1. The reason that the inductance peaks before
self-resonance is due to the fact that the term (1  LCSUBω2)2 in the denominator starts
approaching zero faster than the numerator due to the square function.
Example: The modeled and simulated inductance of a differential inductor designed in
28nm CMOS is shown in Figure 1.59. The inductance is designed to be 1nH at 4GHz,
where the EMX and lumped equivalent are plotted. The measured characteristics of
the inductor are very close to the one predicated by EMX. The lumped model values
are L = 1nH, r = 0.44Ω, COX = 5.57pF, CSUB = 61fF, and RSUB = 872Ω. The inductor is
a 2-turn design using the top metal layer only. The total length is about 1.1mm, and the
width is 22μm. The DC resistance is then calculated to about 0.5Ω. If it were designed as
a long piece of wire, the DC inductance would be 1.1nH.
The self-resonance frequency is about 20GHz, very close to what is predicted by our
analysis, where the inductance reaches zero. Moreover, EMX and lumped model match
fairly well for a wide range of frequencies. According to our derivations, η = 0.074, and
we expect the inductance to peak to 3.4nH, at 18.5GHz.
Next, we shall present quantitative description of Q based on the lumped model input
impedance derived earlier. Deﬁning Q as
Q = Im ZIN
½

j
j
Re ZIN
½

we will arrive at a simpliﬁed expression for the quality factor of the inductor. Given the
approximate expression for ZIN derived earlier,
0.E+00
1.E-09
2.E-09
3.E-09
4.E-09
5.E-09
5.0E+08
1.7E+09
3.0E+09
4.2E+09
5.4E+09
6.6E+09
7.9E+09
9.1E+09
1.0E+10
1.2E+10
1.3E+10
1.4E+10
1.5E+10
1.6E+10
1.8E+10
1.9E+10
2.0E+10
Inductance, H 
Frequency, Hz
π-Model
EMX
Figure 1.59: Simulated inductance for a
1nH inductor
1.11 Integrated Inductors
63

ZIN ﬃ
r + jLω
1 +
r
RSUB
 LCSUBω2


+ jω
L
RSUB
+ rCSUB

 = r + jLω
A + jB ,
we can write
Re ZIN
½
 =
r +
r2
RSUB
+ Lω
ð
Þ2
RSUB
A2 + B2
and
Im ZIN
½
 =
Lω 1  LCSUBω2  r2CSUB
L


A2 + B2
:
Consequently, we have
Q =
Lω j 1  LCSUBω2  r2CSUB
L
j
r +
r2
RSUB
+ Lω
ð
Þ2
RSUB
:
Since r  RSUB, and given that r2CSUB
L
 1,we may rewrite
Q ﬃLω j 1  LCSUBω2 j
r + Lω
ð
Þ2
RSUB
:
Interestingly, the Q approaches zero at self-resonance frequency, ωSRF = 1=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LCSUB
p
, as ZIN is
purely real. This is of course erroneous and will be clariﬁed in the next section. At frequencies
well below the self-resonance, where the inductor is typically intended to be used, the Q may be
expressed as
Q ﬃ
Lω
r + Lω
ð
Þ2
RSUB
:
Two mechanisms contribute to the loss: At low frequencies, the second branch of the π-model
is not effective, and thus Q = Lω
r , which rises linearly with frequency but ﬂattens somewhat due
to the skin effect (although not included in the simple π-model). On the other hand, at higher
frequencies, COX becomes a short circuit, and the model simpliﬁes to a parallel RLC equivalent
circuit, consisting of L, RSUB, and CSUB (note that r may be ignored compared to Lω if the
frequency is sufﬁciently high). Thus Q = RSUB
Lω , which linearly falls with frequency. Moreover,
the high- and low-frequency quality factors become equal to each other at a frequency of
approximately ωQopt = 1
L
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
rRSUB
p
, where we expect the Q to peak. This suggests that balancing
the low- and high-frequency losses optimizes the inductor quality factor at a given frequency.
The optimum Q, as such, will be equal to
64
RF Components

Qopt = 1
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RSUB
r
r
,
which is only a function of the low-frequency ohmic loss, and the substrate resistance.
Example: The simulated Q for the same inductor of previous example is shown in
Figure 1.60. The quality factor due to only series resistance is 57 at 4GHz, whereas the
substrate resistance loss yields a Q of 35. Thus, the combined quality factor at 4GHz sums
up to be 21.7, which is slightly overestimating EMX results. The Q is expected to peak at
3.2GHz, which is close to EMX simulation results.
As one ﬁnal note on this topic, shown in Figure 1.61 is the lumped model of a differential
inductor created by EMX. It is substantially more complex than the simple model of Figure 1.58.
Frequency
Q
, Hz
EMX
π-Model
Lw/r
RSUB/Lw
Figure 1.60: Simulated Q of
the 1nH inductor
P1
P2
C
GND
Figure 1.61: An example of a differential
inductor lumped model created by EMX
1.11 Integrated Inductors
65

The model is created primarily by curve ﬁtting the inductor simulated behavior over the
frequencies of interest, but one can recognize some physical justiﬁcation for at least several of
the elements.
1.11.6 Fundamental versus Inductor Q Deﬁnitions
In the previous example, the quality factor approaching zero may have sounded non-intuitive
and perhaps deserves some clariﬁcation here. The deﬁnition of quality factor according to
Q = Im ZIN
½

j
j
Re ZIN
½
 is based on the assumption that the circuitry of interest is inherently an inductor
along with some small parasitic capacitances or resistances. This is certainly the case if the
inductor is to be utilized at frequencies well below self-resonance, as it typically is. For this
reason, this deﬁnition is widely adopted in both measurement equipment and the literature.
Close to the self-resonance frequency and beyond, however, it clearly falls apart.
To get around this shortcoming, one may suggest using the fundamental deﬁnition of the
Q presented earlier based on the energy stored and power dissipated at resonance:
Q = ω0
Total energy stored
Average power dissipated :
The problem with this deﬁnition is that it is mainly deﬁned for a second-order RLC circuit at
resonance, which is not directly applicable to an inductor especially at lower frequencies.
Nonetheless, if the inductor is well behaved, that is to say if the quality factor is reasonably
high, and parasitic capacitances are small, then one may effectively model it as a parallel RLC
circuit, where the parallel capacitance comprises that of the inductor itself as well as an extra
added part to create resonance at the frequency of interest (Figure 1.62).
Once expressed in terms of the parallel components (Rp, Lp, and Cp in the ﬁgure), at
resonance (ω =
1ﬃﬃﬃﬃﬃﬃﬃﬃ
LpCp
p
), the fundamental Q as derived earlier is
Q = Rp
Lpω = BpL
		
		
Gp
,
where Gp is the effective parallel conductance, and BpL is the inductive part of the parallel
susceptance at the frequency of interest. Note that Gp and BpL are frequency dependent, and that
BpL is negative. Furthermore, the assumption made here is that Cp consists of enough external
capacitance (Cext in the ﬁgure) to establish resonance at the frequency of interest.
Inductor Circuit
(Along w/ parasics)
Equivalent Parallel
RLC Circuit
Cext
Rp
Lp
Cp
Resonate @ w
Figure 1.62: Inductor circuit with parallel external
resonance
66
RF Components

To gain insight, let us derive the fundamental Q expression for the π-circuit developed earlier
as an exercise. The π-circuit input admittance was found to be
YIN =
r +
r2
RSUB
+ Lω
ð
Þ2
RSUB
"
#
 jLω 1 
LCSUBω2 + r2CSUB
L




r2 + Lω
ð
Þ2
:
Thus, the parallel effective conductance and the inductive susceptance are
Gp =
r +
r2
RSUB
+ Lω
ð
Þ2
RSUB
r2 + Lω
ð
Þ2
BpL =
Lω
r2 + Lω
ð
Þ2 :
Note the term
Lω LCSUBω2 +
r2CSUB
L


r2 + Lω
ð
Þ2
is the capacitive part of the susceptance, and is always smaller
than the inductive part unless at the self-resonance frequency that they equate. The Q deﬁnition,
however, assumes that enough external capacitance is added to create the resonance at any
arbitrary frequency below self-resonance.
Consequently, the fundamental Q is
Q =
Lω
r +
r2
RSUB
+ Lω
ð
Þ2
RSUB
ﬃ
Lω
r + Lω
ð
Þ2
RSUB
:
Interestingly (but not surprisingly), the Q does not depend on the parasitic capacitance anymore.
Furthermore, compared to the previous deﬁnition, the two expressions come out to be very
similar, except that the fundamental Q does not have the term 1  LCSUBω2  r2CSUB
L
j
			
			, and
hence never approaches zero (unless at ω ! ∞).
Example: Compared in Figure 1.63 are the previous example inductor quality factors
simulated in EMX according to both deﬁnitions.
Continued
0
5
10
15
20
25
5.0E+08
1.8E+09
3.0E+09
4.3E+09
5.5E+09
6.8E+09
8.0E+09
9.3E+09
1.1E+10
1.2E+10
1.3E+10
1.4E+10
1.6E+10
1.7E+10
1.8E+10
1.9E+10
Frequency, Hz
Q
Inductor
Resonator
Figure 1.63: Quality factor of 1nH inductor
based on two Q deﬁnitions
1.11 Integrated Inductors
67

Clearly, the two curves match very well at frequencies well below the self-resonance,
where the inductor is typically intended to be used. Whereas the inductor deﬁnition
predicts a Q of zero at self-resonance, the fundamental deﬁnition based on the resonance
circuitry leads to a Q of about 5, which is a more meaningful value.
The results above are not a coincidence, nor are limited to the simple π model of Figure 1.58.
Using Tellegen’s theorem,28 one can show (see [7] and Problems 26, 27 and 28) that for an
arbitrary RLC one-port (Figure 1.64) we have
ZIN = 2Pavg + 4jω WL  WC
ð
Þ
Ij j2
,
where Pavg is the total power dissipated in all the resistors, WL is the total energy stored in all the
inductors, and WC is the total energy stored in all the capacitors. They are naturally all real and
positive quantities.
The inductor deﬁnition of Q will then yield
QIND = Im ZIN
½

j
j
Re ZIN
½
 = ω 2 WL  WC
j
j
Pavg
:
Given a well-designed inductor considered as the one-port, at the frequencies well below the
resonance, the inductive part is dominant, which is to say, WC  WL and thus
QIND  ω 2WL
Pavg
:
On the other hand, according to the resonator (or fundamental) deﬁnition of Q,
QFUND = ω WL + WC
Pavg
= ω 2WL
Pavg
,
since at resonance WL = WC.
As expected, well below the self-resonance frequency, the two deﬁnitions are nearly
identical.
Around
resonance,
since
WL  WC,
QIND
diminishes
(erroneously),
but
QFUND holds.
RLC
ZIN
I
+
V
–
Figure 1.64: An arbitrary RLC one-port depicting the relation of its input
impedance to energy dissipated and/or stored
28 Published by Bernard Tellegen, the Dutch electrical engineer in 1952, it is one of the key theorems in network theory.
Notably, Tellegen was also the inventor of the pentode, a commonly used type of vacuum tube, and the gyrator.
68
RF Components

1.11.7 Transformer Modeling
A similar modeling may be developed for the transformers as well. Shown in Figure 1.65 is an
integrated transformer model, which consists of two inductors with the equivalent π-model
presented before, but also coupled to each other.
To gain some insight, ignoring the losses and capacitances, consider the circuits in
Figure 1.66.
For the coupled inductor on the left, we have
ϕ1 = L1i1 + Mi2
ϕ2 = Mi1 + L2i2
(
or equivalently, [ϕ] = [L][i], where L
½  =
L1
M
M
L2
h
i
is the inductance matrix [7]. The coupling
factor by deﬁnition is k =
M
j
j
ﬃﬃﬃﬃﬃﬃﬃ
L1L2
p
. Note that M could be positive or negative, but k is always positive.
Figure 1.65: A simpliﬁed model of an integrated transformer
Ideal
n1 : n2
L2
n1/n2=M/L2
Ideal
n1 : n2
L2
n1/n2=M/L2
Lossless
Lossy
ZL
RL2
Ctune
Figure 1.67: Integrated transformer equivalent model when k  1
+
v1
–
i1
+
v2
–
i2
M
Ideal
n1 : n2
L1
L2
M
L1–M
L2–M
L2
L1–M2/L2
n1/n2=M/L2
Figure 1.66: Lossless integrated transformer equivalent models
1.11 Integrated Inductors
69

Moreover, from an energy point of view, we can show that k  1, otherwise the overall energy of
the coupled inductor could become negative. One can derive the L matrix for the other two circuits
on the right and show that all three circuits have the same inductance matrix, and hence they are
equivalent. If the coupled inductor has a coupling factor close to one, then L1  M2
L2  0, and the
transformer can be represented by the equivalent models shown in Figure 1.67.
If the transformer circuit model is available from simulations, say by EMX, it follows that
L1 = z11 jω
ð
Þ
j
j
ω
L2 = z22 jω
ð
Þ
j
j
ω
,
and the mutual inductance is
M = z12 jω
ð
Þ
j
j
ω
= z21 jω
ð
Þ
j
j
ω
,
where z11, z21 (= z12), and z22, are the transformer open impedance parameters. The coupling
factor is thus k =
z12 jω
ð
Þ
j
j
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
z11 jω
ð
Þz22 jω
ð
Þ
p
.
1.12 Summary
This chapter has dealt with basic RF elements and the concepts associated with them.
– Sections 1.1, 1.2, and 1.4 dealt with the electromagnetic ﬁelds and the basic deﬁnition of
capacitors and inductors.
– Time-varying ﬁelds and Maxwell’s equations were discussed in Section 1.3.
– An introduction to distributed circuits was presented in Section 1.5, and is going to be
followed up on in Chapter 3 in the context of transmission lines.
– Resonance circuit properties and the energy dissipation were discussed in Sections 1.6 and
1.7, along with the deﬁnition of quality factor and its properties.
– A brief introduction to electromagnetic waves and antennas was presented in Sections 1.8 and 1.9.
– Sections 1.11 and 1.12 offered an in-depth discussion of properties and the design of
integrated capacitors, single-ended and differential inductors, and integrated capacitors.
Much of the discussion of the integrated inductors and tuned LC circuits in this chapter will be
used in Chapters 7, 9, and 11, as these elements are widely used in low-noise ampliﬁers,
oscillators, and power ampliﬁers.
1.13 Problems
1. Using spherical coordinates, ﬁnd the capacitance formed by two concentric spherical
conducting shells of radii a and b. What is the capacitance of a metallic marble with a
diameter of 1cm in free space? Hint: let b ! ∞, thus, C = 4πE0a = 0.55pF.
70
RF Components

2. Consider the parallel plate capacitor containing two different dielectrics. Find the total
capacitance as a function of the parameters shown in the ﬁgure.
Area: A
ε2
d1
d2
ε1
3. What would be the capacitance of the structure in Problem 2 if there were a third conductor
with zero thickness at the interface of the dielectrics? How would the electric ﬁeld lines
look? How does the capacitance change if the spacing between the top and bottom plates is
kept the same, but the conductor thickness is not zero?
4. Repeat Problem 2 if the dielectric boundary were placed normal to the two conducting plates
as shown below.
A1
ε2
ε1
d
A2
5. Analogs to the capacitance, using Ohm’s law, show that the leakage conductance of an
almost perfect conductor with a non-inﬁnite conductivity of σ is given by G = σ
Ð
S
E  dS
Ð
E:dL
.
Calculate the leakage conductance of a coaxial cable with radii a and b as was used
throughout the chapter.
6. Consider a very long hollow charge-free superconductor cylindrical shell with inner and
outer radii of a and b, respectively. A wire with a current I is placed at the center of the
cylinder. Calculate the magnetic ﬁeld inside and outside considering that the magnetic ﬁeld
inside the shell would have to be zero. If the current I is moved away from the center but
inside the shell, how would the magnetic ﬁelds inside and outside alter?
a
b
I
1.13 Problems
71

7. What is the internal inductance (per length) of a long straight wire with a circular cross
section of radius a (use energy deﬁnition)? Answer: μ0
8π.
8. Show that the DC inductance of a piece of wire with ﬁnite length l and radius r is
L = μ0l
2π
ln 2l
r  3
4


. What is the inductance of a copper bond-wire with length of 2mm and
a diameter of 25μm (practical bonding pads in integrated circuits are typically 5050μm2)?
Argue why traditionally, as a rule of thumb, an inductance of 1nH/mm is assumed for bond-
wires. Hint: Calculate both the internal (previous problem) and the external (using Biot–
Savart’s law and ﬂux deﬁnition) inductances. The equation is an approximate simpliﬁed for
the practical case of r  l. The calculations are detailed by Rosa.29
9. In Faraday’s experiment, assume the switch has a resistance of R, and the two coils are
identical with an inductance of L. The battery voltage is VBAT. Find the time-varying
current in the coil. Assuming the iron toroid has a large permeability, ﬁnd the magnetic
ﬂux in the second coil and estimate the emf read by the galvanometer.
10. Show that the solution of the general form V z; t
ð
Þ = f 1 t  z
ν


+ f 2 t + z
ν


satisﬁes the
transmission line equation. Find the proper value of velocity ν to satisfy the equation.
11. Consider the series RLC circuit below where the inductor has an initial current of I0. Solve
the circuit differential equation and ﬁnd the inductor current. What are the total energies
stored in the inductor, and dissipated in the resistor over time?
I0
L
C
R
12. For the circuit below, the inductor L1 has an initial stored current of I0. The switch is closed
at t = 0. Find the ﬁnal current of the inductors at t = ∞. Answer: iL1 ∞
ð Þ =  iL2 ∞
ð Þ =
L1
L1 + L2 I0
L1
L2
I0
R
t=0
29 Edward B. Rosa, “On the Self-Inductance of Circles,” Bulletin of the Bureau of Standards, 4, no. 2, 301–305, 1907.
72
RF Components

13. For the problem above argue intuitively how the ﬁnal currents of the two inductors look
with respect to each other. Find the total energy dissipated in the resistor, and from that ﬁnd
the ﬁnal energy and the currents of the two inductors. Is there a condition that leads to the
initial energy of the inductor L1 completely dissipated, leading to zero ﬁnal current?
Answer: Resistor energy: ER =
Ð ∞
0
RI0et=τ
ð
Þ
2
R
dt = 1
2
L1L2
L1 + L2


I02.
14. Suppose an LC tank used in a voltage-controlled oscillator (VCO) consists of a switchable
capacitance CF and a varactor with nominal capacitance C(v). We deﬁne the VCO gain as
KVCO = ∂ω
∂V, where V is the varactor voltage. Show that KVCO varies with frequency cubed
(ω0
3) as the switchable capacitance changes the nominal frequency of oscillation, ω0.
15. Find the Q of parallel RC, RL circuit shown below. Show that the overall Q can be
expressed by 1
Q =
1
QL +
1
QC, assuming the inductor and capacitor are high-Q.
RC
rL
L
C
16. Find the electric potential difference at distances r1 and r2, associated with a point charge
+Q located at the origin. Assuming the potential reference (V = 0) is associated with
r2 ! ∞, ﬁnd the potential of the point charge at an arbitrary distance from the origin.
17. An electric dipole is deﬁned as two point charges with the same magnitude, but opposite
polarity separated by a small distance (l), as shown below. Find the electric potential at a
distance of r from the origin. Assuming r  l, ﬁnd a simpliﬁed expression for the potential,
and from that calculate the electric ﬁeld associated with the dipole. Answer:
E =
Q
4πEr3 2 cos ar + sin a
ð
Þ.
z
x
y
r1
r
r2
+Q
–Q
θ
l
18. Find the magnetic ﬁeld and magnetic vector potential of the ideal current ﬁlament (shown
below) carrying a static current of I0.
1.13 Problems
73

z
x
y
I
I
0
19. Consider an ideal circular current loop carrying a total current of I0 as shown below.
Find the vector potential and the magnetic ﬁeld along the z axis. Answer:
H =
a2I0
2 z2 + a2
ð
Þ3=2 az.
z
x
y
f’
q
r
R
a
20. For the previous problem, ﬁnd the vector potential and the magnetic ﬁeld off the symmetry
axis. Hint: The solution for an arbitrary point in space leads to elliptic integrals that can be
solved only numerically. For far-ﬁeld (r  a), the integral may be approximated by Taylor
expansion and ignoring higher order terms, leading to H =
I0 πa2
ð
Þ
4πr3
2 cos ar + sin a
ð
Þ.
21. Show that the magnetic ﬁeld lines of the circular current loop are as depicted below. Argue
whether or not there is any resemblance to the ﬁeld lines of a small bar magnet.
N
S
y
z
22. Argue the similarity of the magnetic and electric ﬁelds between the electric dipole and the
circular current loop. How do the charge and current relate?
74
RF Components

23. A magnetic dipole consists of a circular current loop of radius a, carrying a sinusoidal
current of I0 cos ωt, as shown below. It is closely related to the Hertzian dipole
discussed earlier. To solve for the ﬁelds, we may take an indirect but easier approach
considering the duality between the E and H ﬁelds in Maxwell’s equations. Show that
for a sourceless medium, Maxwell’s equations remain intact if E is replaced with H, H
with –E, and E with μ. Invoking duality between the electric and magnetic dipoles
(previous problem), the symmetry of Maxwell’s equations, and that I = dQ
dt = jωQ,
show that the Hertzian dipole solution could be used to obtain the magnetic dipole ﬁelds,
but with l replaced by jωEπa2. Answer: For far-ﬁeld, Hφ ﬃωμπa2
ð
Þ j
η
I0β sin 
4πr
ejβr, and
E ﬃ ηHφ.
z
x
y
f
q
r
a
H
l
q
z
x
y
Hf
Ef
Eq
q
r
24. Show that for a general dipole of length l,
F ; φ
ð
Þ =
cos kl cos 
2


 cos kl
2
 
sin 
:
Assume that the current distribution is I zð Þ = I0 sin k
l
2  zj j



. Hint: Using the ﬁgure
below, show that for far-ﬁeld, the differential electric ﬁeld is dE = jηk I zð Þdz
4πr0 sin 0ejkr0 ﬃ
jηk I zð Þdz
4πr sin ejk rz cos 
ð
Þ. The total electric ﬁeld is obtained by E r; 
ð
Þ =
Ð l=2
l=2 dE.
z
q
–l/2
q
r
r’
I(z)
dz
zcosq
+l/2
1.13 Problems
75

25. For an RLC one-port with an input impedance of Z(jω), the quality factor is sometimes
deﬁned as
Q = Im Z
½ 
j
j
Re Z
½ :
Using the energy deﬁnition of the Q and the concept of complex power, justify this deﬁnition.
26. Find a similar equation based on the admittance of the one-port: Y jω
ð
Þ =
1
Z jω
ð
Þ. Discuss
how this deﬁnition works for a series (or parallel) RLC circuit.
27. (Tellegen’s theorem) Consider an arbitrary network with b branches. We assign branch
voltages vk and branch currents ik. If all branch voltages and currents satisfy KVL and
KCL, respectively, then Pb
k = 1vkik = 0. Hint: Assuming the circuit has n  1 nodes plus a
reference, using KVL express the branch voltages in terms of the node voltages compared
against the reference. Rewrite the summation in terms of the node voltages (el, l = 1, 2, . . .,
n  1), and then simplify using KCL.
vk
ik
+
–
ep
em
0
28. For the one-port of Figure 1.64, Tellegen’s theorem states
X
kVkIk
∗= 0, where Vk and Ik
are the branch voltages and currents phasors in sinusoidal steady state.30 Operator ∗
denotes the conjugate.
a. Show that ZIN|I|2 =
X
k(RkIk)Ik
∗+
X
m(jωLmIm)Im
∗+
X
nVn(jωCnVn)∗), where the
summation is broken into groups of resistors, inductors, and capacitors.
b. Using the results in part a, show that ZIN = 2Pavg + 4jω WLWC
ð
Þ
Ij j2
.
29. Design a 4nH single-layer spiral inductor assuming the inductance may be approximated
by L = μ0N2r, where N is the number of turns, and r is the spiral radius. Assume a metal
sheet resistance of 10mΩ/□, and constrain the design to an area of 200  200μm2, with an
inner diameter of greater than 150μm. The spacing between the metals is 5μm. The goal is
to maximize the Q given the constrains. Neglect the skin effect and other high-frequency
factors, and ﬁnd the optimum Q.
30. For the ﬁgure below, ﬁnd the input impedance looking into the primary of the transformer,
Z1. Show that if R2 is small, the effective inductance is Leff = Im Z1
½

ω
 L1 1  k2


, where
k =
M
j
j
ﬃﬃﬃﬃﬃﬃﬃ
L1L2
p
is the coupling factor.
30 The only constraint on Tellegen’s theorem is that the network must be lumped. Given the conclusions drawn in the
problem, the theorem is stated in the special form of sinusoidal steady state, which is limited to LTI networks only.
76
RF Components

L1
M
Z1
L2
R2
31. For the circuit shown below,
a. Show that equivalent inductance is Leq = L1L2 + L1L3 + L2L3M22ML3
L2 + L3
.
b. Show that Leq is always positive. Hint: Use the fact that the coupling factor k =
M
j
j
ﬃﬃﬃﬃﬃﬃﬃ
L1L2
p
is
equal to one at maximum. That sets an upper bound for M.
L1
L2
L3
M
Leq
32. Using EMX, try an experiment where the inductor of Figure 1.15 is shielded with a slotted
plane consisting of metal 1 and 2 layers shorted together. Use the sheet resistance values
provided in the text considering that metal 1 and metal 2 are the same. Assume NATN
layer is present. Find the inductance, quality factor, and self-resonance frequency. Answer:
Q improves from 12.4 to 12.8 at 2GHz.
1.14 References
[1] P. R. Gray and R. G. Meyer, Analysis and Design of Analog Integrated Circuits, John Wiley, 1990.
[2] Y. Tsividis and C. McAndrew, Operation and Modeling of the MOS Transistor, vol. 2, Oxford University
Press, 1999.
[3] R. Ellis and D. Gulick, Calculus, with Analytic Geometry, Saunders, 1994.
[4] R. E. Colline, Foundation for Microwave Engineering, McGraw-Hill, 1992.
[5] D. M. Pozar, Microwave Engineering, John Wiley, 2009.
[6] W. H. Hayt and J. A. Buck, Engineering Electromagnetics, vol. 73104639, McGraw-Hill, 2001.
[7] C. A. Desoer and E. S. Kuh, Basic Circuit Theory, McGraw-Hill, 2009.
[8] W. E. Boyce, R. C. DiPrima, and C. W. Haines, Elementary Differential Equations and Boundary Value
Problems, vol. 9, John Wiley, 1992.
[9] R. E. Collin and F. J. Zucker, Antenna Theory, McGraw-Hill, 1969.
[10] C. A. Balanis, Antenna Theory: Analysis and Design, vol. 1, John Wiley, 2005.
[11] W. L. Stutzman and G. A. Thiele, Antenna Theory and Design, John Wiley, 2012.
[12] M. Zargari, M. Terrovitis, S.-M. Jen, B. J. Kaczynski, M. Lee, M. P. Mack, S. S. Mehta, S. Mendis, K.
Onodera, H. Samavati, et al., “A Single-Chip Dual-Band Tri-Mode CMOS Transceiver for IEEE 802.11
a/b/g Wireless LAN,” IEEE Journal of Solid-State Circuits, 39, no. 12, 2239–2249, 2004.
1.14 References
77

[13] F. Svelto, S. Deantoni, and R. Castello, “A 1.3GHz Low-Phase Noise Fully Tunable CMOS LC VCO,”
IEEE Journal of Solid-State Circuits, 35, no. 3, 356–361, 2000.
[14] A. Kral, F. Behbahani, and A. Abidi, “RF-CMOS Oscillators with Switched Tuning,” in Custom
Integrated Circuits Conference, 1998. Proceedings of the IEEE, 1998.
[15] N. Nguyen and R. Meyer, “A 1.8-GHz Monolithic LC Voltage-Controlled Oscillator,” IEEE Journal of
Solid-State Circuits, 27, no. 3, 444–450, 1992.
[16] N. Nguyen and R. Meyer, “Si IC-Compatible Inductors and LC Passive Filters,” IEEE Journal of Solid-
State Circuits, 25, no. 4, 1028–1031, 1990.
[17] F. Grover, Inductance Calculations, Dover, 1946.
[18] H. Greenhouse, “Design of Planar Rectangular Microelectronic Inductors,” IEEE Transactions on Parts,
Hybrids, and Packaging, 10, no. 2, 101–109, 1974.
[19] S. S. Mohan, M. del Mar Hershenson, S. P. Boyd, and T. H. Lee, “Simple Accurate Expressions for Planar
Spiral Inductances,” IEEE Journal of Solid-State Circuits, 34, no. 10, 1419–1424, 1999.
[20] S. Jenei, B. K. Nauwelaers, and S. Decoutere, “Physics-Based Closed-Form Inductance Expression for
Compact Modeling of Integrated Spiral Inductors,” IEEE Journal of Solid-State Circuits, 37, no. 1,
77–80, 2002.
[21] A. Niknejad and R. Meyer, “Analysis, Design, and Optimization of Spiral Inductors and Transformers for
Si RF ICs,” IEEE Journal of Solid-State Circuits, 33, no. 10, 1470–1481, 1998.
[22] H.-S. Tsai, J. Lin, R. C. Frye, K. L. Tai, M. Y. Lau, D. Kossives, F. Hrycenko, and Y.-K. Chen,
“Investigation of Current Crowding Effect on Spiral Inductors,” in IEEE MTT-S Symposium on
Technologies for Wireless Applications Digest, 1997.
[23] W. B. Kuhn and N. M. Ibrahim, “Analysis of Current Crowding Effects in Multiturn Spiral Inductors,”
IEEE Transactions on Microwave Theory and Techniques, 49, 31–38, 2001.
[24] W. B. Kuhn and N. M. Ibrahim, “Approximate Analytical Modeling of Current Crowding Effects in
Multi-turn Spiral Inductors,” in IEEE MTT-S International Microwave Symposium Digest, 2000.
[25] A. Rofougaran, J. Y. Chang, M. Rofougaran, and A. A. Abidi, “A 1 GHz CMOS RF Front-End IC for a
Direct-Conversion Wireless Receiver,” IEEE Journal of Solid-State Circuits, 31, 880–889, 1996.
[26] T. Tsukahara and M. Ishikawa, “A 2 GHz 60 dB Dynamic-Range Si Logarithmic/Limiting Ampliﬁer with
Low Phase Deviations,” in IEEE International Conference on Solid-State Circuits, 1997.
[27] C. Yue and S. Wong, “On-Chip Spiral Inductors with Patterned Ground Shields for Si-Based RF ICs,”
IEEE Journal of Solid-State Circuits, 33, no. 5, 743–752, 1998.
[28] M. Danesh, J. R. Long, R. Hadaway, and D. Harame, “A Q-Factor Enhancement Technique for MMIC
Inductors,” in IEEE MTT-S International Microwave Symposium Digest, 1998.
[29] J. R. Long, “Monolithic Transformers for Silicon RF IC Design,” IEEE Journal of Solid-State Circuits,
35, 1368–1382, 2000.
78
RF Components

2
RF Signals and Systems
In this chapter we review some of the basic concepts in communication systems. We start with
a brief summary of Fourier and Hilbert transforms, both of which serve as great tools for
analyzing RF circuits and systems. We also present an overview of network functions and the
signiﬁcance of poles and zeros in circuits and systems. To establish a foundation for the noise
analysis presented in Chapter 5, we also provide a brief summary of stochastic processes and
random variables. We conclude this chapter by brieﬂy describing the fundamentals of analog
modulation schemes and analog modulators.
A majority of the material presented in this chapter is a review of various concepts that exist
in signal processing, communication systems, and basic circuit theory. However, we feel it is
important to present a reminder as well as a summary as throughout this book they will be
referred to continuously.
The speciﬁc topics covered in this chapter are:
• Fourier series and Fourier transform
• Impulse response, poles, zeros, and network functions
• Hilbert transform and quadrature signals
• Random processes, Gaussian signals, and stationary and cyclostationary processes
• Amplitude, phase, and frequency modulation
• Narrowband FM and Bessel functions
• Introduction to modern digital communication
For class teaching, we recommend focusing on selected topics from Sections 2.1, 2.8, 2.9, and
2.10, while Sections 2.1 through 2.5 and 2.7 may be comfortably assigned as reading.
The stochastic processes (Section 2.7) are crucial to attain a thorough understanding of
noise in RF circuits, and particularly oscillator phase noise. For an introductory RF course,
however, proper coverage of noise and phase noise may not be feasible. Consequently, we
defer Section 2.7 and the majority of the phase noise discussion (in Chapter 9) to a more
advanced course, and certainly to more astute readers. Section 2.7 offers a summary of
selected topics that are most relevant to RF design, which will greatly complement our
discussions on mixer and oscillator noise.

2.1
FOURIER TRANSFORM AND FOURIER SERIES
..............................................................................................
Electrical communication signals are analog time-varying quantities such as voltages or
currents. Although a signal physically exists in the time domain, we can also represent it in
the frequency domain, where we can view it as various sinusoidal components at different
frequencies, known as spectrum. We will mostly focus on nonperiodic signals, concentrated
over relatively short periods, and brieﬂy overview Fourier transform, which is used to represent
such signals in the frequency domain.
For a given nonperiodic signal, v(t), whether strictly time limited (such as a pulse) or
asymptotically time limited in the sense that it eventually approaches zero (such as an exponen-
tial function over time), we can deﬁne the signal energy over one period as
E =
ð∞
∞
v tð Þ
j
j2dt,
consistent with our previous deﬁnition of energy.1 If the integral yields E < ∞, then the signal
has a well-deﬁned energy, and accordingly the Fourier2 transform of v(t), symbolized as V( f ),
is deﬁned as
V f
ð Þ = F v tð Þ
½
 =
ð∞
∞
v tð Þej2πftdt:
Similarly, an inverse Fourier transform performed on V( f ) yields the time domain signal back:
v tð Þ = F 1 V f
ð Þ
½
 =
ð∞
∞
V f
ð Þe + j2πftdf :
The Fourier transform is evidently a complex function. If v(t) is real, then V(f ) = V∗( f ),
where * denotes the conjugate operator.
Example: One can easily show that for a rectangular pulse with a pulse width of τ,
deﬁned as
Πτ tð Þ =
1
tj j < τ
2
0
tj j > τ
2
8
>
<
>
:
:
The Fourier transform isa sinc function,3 whose magnitude and phase are shown in Figure 2.1:
V f
ð Þ = 1
πf sin πf τ = τ sinc f τ
1 For instance, it represents the voltage energy v(t) delivered to a 1Ω resistor.
2 Though initially presented in 1807 but rejected (largely because of his former advisor Lagrange), Joseph Fourier’s ﬁndings
on Fourier series were ﬁrst published in a book titled The Analytic Theory of Heat in 1822. The Fourier transform as well as
Fourier laws have also been named in his honor.
3 Our deﬁnition of sinc here includes a factor π in the argument, that is, sinc(x) = sin πx/πx, consistent with information
theory and signal processing deﬁnition. In mathematics, sinc is deﬁned as sinc(x) = sin x/x.
80
RF Signals and Systems

The basic deﬁnition of the integral allows us to express the energy in the frequency domain
as well, that is,
E =
ð∞
∞
v tð Þ
j
j2dt =
ð∞
∞
V f
ð Þ
j
j2df ,
which is known as Parseval’s energy theorem.
Example: Suppose the function of interest (v(t)) is multiplied by ej2πfct, thus the new
function is
v0(t) = v(t)ej2πfct.
The Fourier transform of the new function is
V0 f
ð Þ =
ð∞
∞
v tð Þe j2πf ctej2πftdt = V f  f c
ð
Þ:
Thus multiplying by ej2πfct results in a shift in the frequency domain. The outcome, though
very trivial, is the basis of how mixers and image-reject systems operate, as we shall
discuss later in Chapter 8.
In Table 2.1, a summary of basic properties of Fourier transform is listed. Refer to [1], [2] for
actual proof and more details. All the relations can be easily proven based on the integral deﬁnition.
If v(t) is a periodic function with period T = 1
f 0, it may be represented by its Fourier series
instead,
v tð Þ =
X
∞
k = ∞
ake j2πkf 0t,
where ak = 1
T
Ð
Tv tð Þej2πkf 0tdt is the Fourier coefﬁcient.4 The signal energy is
E =
ð
T
v tð Þ
j
j2dt,
f
1/t
t
180⁰ 
–180⁰ 
|V(f)|
∠V(f)
–1/t
–2/t
2/t
… 
… 
Figure 2.1: A rectangular pulse
Fourier transform
4 The Fourier coefﬁcients of a variable v(t) may also be denoted by V[k].
2.1 Fourier Transform and Fourier Series
81

which must be ﬁnite so that the Fourier coefﬁcients are ﬁnite. Parseval’s energy equation
becomes
1
T
ð
T
v tð Þ
j
j2dt =
X
∞
k = ∞
ak
j
j2:
If v(t) is real, then ak = a∗
k, and it is possible to represent the Fourier series as the sum of
cosines [1]. Similar properties as the ones shown in Table 2.1 exist for the Fourier series
as well.
Example: As a very useful case study, consider Figure 2.2, where a slow-varying
signal x(t) is compared against a high-frequency sawtooth signal varying between 1.
The resulting waveform xP(t) has a constant amplitude of 1, but its width varies
linearly with the input signal amplitude at the time location tk where x(t) intersects
with the sawtooth waveform. We would like to express xP(t) in terms of its Fourier
series.
Table 2.1: Summary of Fourier transform properties
Operation
Function
Transform
Superposition
α1v1 tð Þ þ α2v2 tð Þ
α1V1 fð Þ þ α2V2 fð Þ
Time delay
v t  τ
ð
Þ
V fð Þej2πf τ
Scaling
v αt
ð
Þ
1
α
j j V
f
α
 
Conjugation
v∗tð Þ
V∗f
ð
Þ
Duality
V tð Þ
v f
ð
Þ
Frequency translation
v tð Þej2πf ct
V f  f c
ð
Þ
Modulation
v tð Þ cos ωct þ ϕ
ð
Þ
1
2 V f  f c
ð
Þejϕ þ V f þ f c
ð
Þejϕ


Differentiation
dv tð Þ
dt
j2πf V fð Þ
Integration
Ð t
∞v θ
ð Þdθ
1
j2πf V fð Þ
Convolution
v∗w tð Þ ¼ Ð ∞
∞v τð Þw t  τ
ð
Þdτ
V fð ÞW fð Þ
Multiplication
v tð Þw tð Þ
V∗W fð Þ
82
RF Signals and Systems

The duration of each pulse, τk, may be deﬁned as
τk = Ts
2 1 + x tð Þ
ð
Þ,
where Ts is the sawtooth signal period. To prevent missing pulses or negative durations,
let us assume that |x(t)| < 1. Since the rate of the input signal variation is assumed to be
much less than the sampling frequency, we may assume uniform sampling, which is to
say τk could be treated nearly as constant. Thus, we can write
an = 1
Ts
ð
Ts
xP tð Þej2πnf stdt = 1
Ts
ðτk=2
τk=2
ej2πnf stdt = 1
πn sin nπ
2
1 + x tð Þ
ð
Þ


,
which leads to
xP tð Þ = 1
2 1 + x tð Þ
ð
Þ +
X
∞
n = 1
2
nπ sin nϕ tð Þ cos nωst,
where ϕ tð Þ = π
2 1 + x tð Þ
ð
Þ.
This kind of waveform is known as a pulse-width modulated signal and is commonly
used in class D power ampliﬁers, as we will discuss in Chapter 11.
2.2
IMPULSES
..............................................................................................
The impulse has no mathematical or physical meaning, unless it appears under the operation of
integration. Nevertheless, it proves to have a valuable role when analyzing linear networks and
systems. Particularly when dealing with spectrum, an impulse in the frequency domain could
represent a discrete frequency component.
In time domain, an impulse is represented as
δ tð Þ = lim
Δ!0 δΔ tð Þ = lim
Δ!0
1
Δ ΠΔ tð Þ,
where ΠΔ(t) represents a rectangular pulse deﬁned in the previous section. By virtue of the
deﬁnition above, it follows
+
–
Sawtooth 
Generator
x(t)
xp(t)
Comparator
x(t)
t
t
xp(t)
1
kTs
tk
tk
0
+1
–1
Ts
Figure 2.2: A slow-varying signal compared against a sawtooth waveform
2.2 Impulses
83

ð∞
∞
δ tð Þdt =
ð0 +
0 δ tð Þdt = 1
ð∞
∞
v tð Þδ t  t0
ð
Þdt = v t0
ð Þ:
The notation 0 or 0+ above signiﬁes the instant right before or after t = 0.
Example: We shall show δ tð Þ = du tð Þ
dt , where u(t) is the unity step function. From our
basic deﬁnition,
δ tð Þ = lim
Δ!0
u t + Δ
2


 u t  Δ
2


Δ
,
which is the very deﬁnition of du tð Þ
dt .
Closely related to the unit impulse function is the unit doublet δ0(t), which is deﬁned by
δ0 tð Þ =
singular
t = 0
0
t 6¼ 0

,
where the singularity at t = 0 is deﬁned such that δ tð Þ =
Ð t
∞δ0 θ
ð Þdθ. The symbols of a unit
impulse and doublet are shown in Figure 2.3.
In the frequency domain, the impulse represents a phasor or a constant. In particular, let
v(t) = 1 be a constant for all time. Although this signal has inﬁnite energy, we can still obtain
the Fourier transform in a limiting case considering that
v tð Þ = lim
W!0 sinc 2Wt
ð
Þ = 1,
and since the Fourier transform of a sinc is already shown to be a pulse, then
V f
ð Þ = lim
W!0
1
2W Π2W
f
2W


= δ f
ð Þ,
based on basic properties of Fourier transform summarized in the previous section. We can
generalize
d(t)
0
t
d ’(t)
0
t
Impulse
Doublet
Figure 2.3: Symbols of
impulse and doublet
functions
84
RF Signals and Systems

Aej2πfct $ Aδ( f  fc).
Similarly, according to duality, an impulse in the time domain will have a ﬂat response in the
frequency domain. This is very important, as it suggests that to characterize a system in the
frequency domain, one can analyze the impulse response where all the natural frequencies of
the system are excited.
2.3
FOURIER TRANSFORM OF PERIODIC SIGNALS
..............................................................................................
Fourier transform may be developed for periodic signals as well. Consider a signal v(t), which is
periodic and represented by its Fourier series as
v tð Þ =
X
∞
k = ∞
ake j2πkf 0t:
Since we already showed that the Fourier transform of ej2πkf0t is an impulse at kf0, then, the Fourier
transform of v(t) may be expressed as a linear combination of impulses equally spaced in frequency:
V f
ð Þ =
X
∞
k = ∞
akδ f  kf 0
ð
Þ:
Example: If v(t) = cos 2πf0t, since a1 = a1 = 1
2 with the rest of coefﬁcients zero, its
Fourier transform consists of a pair of impulses at f0 with a height of 1
2. Similarly,
the Fourier transform of a sine is a pair of impulses at f0 with a height of j
2 .
Example: Consider a train of impulses v tð Þ = P∞
k = ∞δ t  kT
ð
Þ. This signal is periodic
and its Fourier coefﬁcients are
ak = 1
T
ð
T
X
∞
n = ∞
δ t  nT
ð
Þ
 
!
ej2πkf 0tdt = 1
T
ðT=2
T=2
δ tð Þej2πkf 0tdt = 1
T :
Thus, the Fourier transform is also a train of impulses in frequency:
V f
ð Þ = 1
T
X
∞
k = ∞
δ f  kf 0
ð
Þ:
Table 2.2 shows the Fourier transform of some of the well-known signals. If periodic, also
given is their Fourier series coefﬁcients. They can all be easily veriﬁed by the reader given the
basic deﬁnition.
2.3 Fourier Transform of Periodic Signals
85

2.4
IMPULSE RESPONSE
..............................................................................................
It is well known that if a linear, time-invariant system’s impulse response is h(t), then the
response of the output y(t) to an arbitrary input x(t) is
y tð Þ = h∗x tð Þ =
ð∞
∞
h τð Þx t  τ
ð
Þdτ,
and in the frequency domain,
Y( f ) = H( f )X( f ),
where H( f ) is the system transfer function. It is important to point out that determining H( f )
does not necessarily involve h(t). In fact, if one knows the differential equations for a lumped
system, H( f ) can be directly expressed as a ratio of two polynomials:
Table 2.2: Basic Fourier transform pairs
Signal
Fourier transform
Fourier series coefﬁcient
P
∞
k¼∞
akej2πkf 0t
P
∞
k¼∞
akδ f  kf 0
ð
Þ
ak
Acos 2πf 0t þ ϕ
ð
Þ
A
2 ejϕδ f  f 0
ð
Þ þ ejϕδ f þ f 0
ð
Þ


a1 ¼ A
2 ejϕ, ϕ otherwise
1
δ fð Þ
a0 ¼ 1, ϕ otherwise
P
∞
k¼∞
δ t  kT
ð
Þ
1
T
X
∞
k¼∞
δ f  kf 0
ð
Þ
1
T
Periodic squarewave:
Π tð Þ ¼
1
tj j < τ
2
0
tj j > τ
2
8
>
<
>
:
Π(t + T) = Π(t)
P
∞
k¼∞
sin πkτ=T
πk
δ f  kf 0
ð
Þ
sin πkτ=T
πk
δ t  t0
ð
Þ
ej2πft0
None
u tð Þ
1
j2πf þ δ fð Þ
2
None
eαtu tð Þ
1
α þ j2πf
None
Πτ tð Þ ¼
1
tj j < τ
2
0
tj j > τ
2
8
>
<
>
:
1
πf sinπf τ ¼ τsincf τ
None
86
RF Signals and Systems

H f
ð Þ = b0 + b1 j2πf
ð
Þ +    + bm j2πf
ð
Þm
a0 + a1 j2πf
ð
Þ +    + an j2πf
ð
Þn :
Example: Consider the parallel resonance circuit shown in Figure 2.4 left, where the
response is the inductor current iL(t).
By deﬁnition, the impulse response is a zero-state response, that is, the response of a
circuit with an input excitation and no initial conditions (or state). Thus, the correspond-
ing differential equation describing the circuit is
iL
00 + 1
RC iL
0 + 1
LC iL = 1
LC δ tð Þ
iL 0
ð
Þ = 0
iL
0 0
ð
Þ = 0:
The second initial condition, iL
0(0) = 0, implies that the capacitor has no initial charge.
Perhaps the most convenient way of solving the equation is by applying Laplace transform,
but instead we try to directly solve it in the time domain to gain some insight. To do so, we
integrate the two sides of the differential equation from 0 to 0+, attempting to ﬁnd the initial
conditions at 0+. Thus,
ð0 +
0 iL
00dt + 1
RC
ð0 +
0 iL
0dt + 1
LC
ð0 +
0 iLdt = 1
LC
ð0 +
0 δ tð Þdt:
The last two terms on the left side are zero, as the only way for them not to be zero is if iL
0
or iL contain δ. If they did, then iL
00 will contain δ0 or δ
00, and that will violate the original
differential equation. Thus,
iL
0 0 +
ð
Þ  iL
0 0
ð
Þ = 1
LC ,
leading to iL0 0 +
ð
Þ =
1
LC. Obviously iL(0+) remains zero, or otherwise, as stated, iL
0 must
contain δ, which is not possible. Now for t > 0 we can then write
iL
00 + 1
RC iL
0 + 1
LC iL = 0
iL 0 +
ð
Þ = 0
iL
0 0 +
ð
Þ = 1
LC :
Continued
C
R
L
d(t)
iL
C
R
L
iL
Zero State
Zero Input
iL(0+)=0
i ’
L(0+)=1/LC
Figure 2.4: A parallel resonance circuit driven by an impulse current
2.4 Impulse Response
87

This is a simple zero-input circuit as shown on the right of Figure 2.4, and the response is
the homogenous solution of the differential equation,
iL tð Þ =
ω02
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
α2  ω02
p
es1t  es2t
ð
Þu tð Þ,
where s1,2 =  α 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
α2  ω02
p
, u(t) is the unit step function, signifying the fact that the
impulse response is valid for t > 0, and ω0 and α were deﬁned previously.5 Note that in
the case of underdamped response where α < ω0,
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
α2  ω02
p
becomes imaginary, but
also s1,2 are complex and the response is still real. By taking the derivatives of iL(t) the
reader can show that indeed iL
0 does not contain any δ, whereas iL
00 does, making up for
the δ(t) term on the right-hand side of the differential equation.
These results can be intuitively explained as follows: At t = 0, the source puts out an inﬁnite
current. The capacitor acts like a short (while the inductor is open) to absorb the current.
Effectively, the source wants to deliver 1 coulomb of charge instantly to the capacitor, which
results in the capacitor voltage to rise to vc 0 +
ð
Þ = 1
c
Ð 0 +
0 δ tð Þdt + vc 0
ð
Þ = 1
c. Consequently,
iL0 0 +
ð
Þ = vc 0 +
ð
Þ
L
=
1
LC. The inductor current does not change at 0+. If it did, it would require an
inﬁnite voltage in the capacitor, which leads to a doublet current.
2.5
NETWORK FUNCTIONS
..............................................................................................
In general, for a linear and time-invariant network (or system), we can deﬁne a network
function, H(s) as follows,
Network function = L 0  state response
½

L input
½

= B sð Þ
A sð Þ ,
where L denotes the Laplace transform [3], [4], and the zero-state response corresponds to the
response of the network to a given input at no initial conditions. The variable s = σ + jω =
σ + j2πf is the complex frequency. From basic circuit theory [4], it can be shown that the
network functions are rational functions of the complex frequency, with real coefﬁcients, that
is, ai and bi are real numbers. Thus, we can write in general
H sð Þ = b0 + b1s +    + bmsm
a0 + a1s +    + ansn = K
Qm
i = 1 s  zi
ð
Þ
Qn
j = 1 s  pj

 ,
where zi and pi are called zeros and poles of the network.6 Since the network coefﬁcients are
real, the poles and zeros of the system are either real or complex conjugate pairs. Moreover, if
5 As we showed in Chapter 1: α = ω0
2Q = 1
RC and ω0 =
1ﬃﬃﬃﬃﬃﬃ
LC
p
.
6 In the previous section we used the symbol Π to denote the pulse function. Here it has been used to indicate the product,
analogous to Σ showing the sum.
88
RF Signals and Systems

one replaces s with jω = j2πf, then one can obtain the frequency response of the system, which
is commonly expressed in terms of its magnitude and phase: H jω
ð
Þ = H jω
ð
Þ
j
je∡H jω
ð
Þ.
Finally, as was the case for the Fourier transform, by applying inverse Laplace transform, the
corresponding impulse response of the system is obtained:
h tð Þ = L1 H sð Þ
½
.
To arrive at a physical interpretation of the poles and zeros, let us consider the example of a
parallel RLC circuit driven by a current source discussed earlier. Let us take the voltage across
the circuit to be the response. The network function is
H sð Þ = 1
C
s
s2 + s
RC + 1
LC
= 1
C
s
s2 + 2αs + ω02 :
For the underdamped case where Q > ½, we have
h tð Þ = 1
C
ω0
ωd
eαt cos ωdt + ϕ
ð
Þ
t > 0:
The pole locations of this circuit were presented before in Chapter 1. Two examples of the
frequency response as well as the corresponding step responses are sketched in Figure 2.6. For
both cases, the resistance R is kept constant along with ωd = 1, and C, and L are modiﬁed
accordingly. The value of α is 0.3 in one case, and 0.1 in the other case. For convenience, the
time domain plots are normalized to have the same initial magnitude (which is 1
C ).
Figure 2.6 shows clearly that the distance between the pole and the jω axis determines
completely the rate of decay, as well as the sharpness of the frequency response. In fact, if the
poles were on the jω axis, there would be no decay. Moreover, the ordinate of the pole, ωd,
determines the distance between successive zero crossings of the impulse response.
In general, we can say that isolated poles close to the jω axis tend to produce sharper peaks
in the magnitude curve. The distance of the pole to the jω axis may be estimated by the fact that
2α ﬃ3dB bandwidth (in rad/s).
Moreover, any pole of the network function is the natural frequency of the corresponding
output.7 Suppose the input is an impulse. The Laplace transform of the output of interest will be
equal to H(s), which based on partial fraction expansion can be expressed as
V sð Þ = H sð Þ =
X
n
i = 1
Ki
s  pi
,
C
R
+
v(t)
-
L
Figure 2.5: Parallel RLC circuit driven by a current source
7 Although the opposite is not necessarily true: any natural frequency of a network variable need not be a pole of a given
network function that has this variable as the output. See Problem 6 for an example.
2.5 Network Functions
89

where Ki is the residue of the pole pi, and v(t) is the output of interest. Thus
v tð Þ =
X
n
i = 1
Kiepit,
and since for t > 0 the input is zero, the equation above may be considered as the zero-input
response, and thus pi is a natural frequency of the system.
Example: Consider the second-order circuit in Figure 2.7. It is a phase shift network
commonly used in Wien bridge oscillators.8 For simplicity, assume RC = 1. We shall ﬁrst
determine the impulse response of the circuit.
jw
s
s
jwd
–a
–a
f
wd = 1, a = 0.3
H(w)
jw
jwd
wd = 1, a = 0.1
t
w
1
R
h(t)
5
10
15
a = 0.1
a = 0.3
a = 0.3
a = 0.1
Figure 2.6: Impulse and frequency response of the parallel RLC circuit
8 Wien bridge oscillators were developed by Max Wien, the German physicist, in 1891.
R
C
vs(t)=d(t)
R
C
+
vo(t)
–
Figure 2.7: Second-order RC circuit used in
Wien bridge oscillators
90
RF Signals and Systems

The circuit differential equation is
vo
00 + 3
RC vo
0 +
1
RC
ð
Þ2 vo = 1
RC δ0 tð Þ:
To obtain the initial conditions at t = 0+, we use the circuit shown on the left side of
Figure 2.8, considering that the capacitors are short at t = 0 when the inﬁnite current is
passing through. That creates a current of δ tð Þ
R going through both capacitors, raising
their voltage to
1
RC at t = 0+.
At t = 0+, with the aid of the equivalent circuit on the right, it can be seen that a current
of vo 0 +
ð
Þ
R
=
1
R2C passes through the parallel resistor, and the series resistor current will be
vo 0 +
ð
Þ + vc1 0 +
ð
Þ
R
=
2
R2C. Thus, a net current of 3
R2C passes through the shunt capacitor, and as a
result we have
vo 0 +
ð
Þ = 1
RC = 1
vo
0 0 +
ð
Þ =
3
RC
ð
Þ2 =  3:
The circuit natural frequencies are directly obtained from the differential equation and are
equal to
s1,2 = 3 
ﬃﬃﬃ
5
p
2RC
= 3 
ﬃﬃﬃ
5
p
2
,
indicating that the circuit is overdamped, as any second-order RC network should.
Accordingly, the impulse response is
vo tð Þ =
3 +
ﬃﬃﬃ
5
p
2
ﬃﬃﬃ
5
p
es1t + 3 +
ﬃﬃﬃ
5
p
2
ﬃﬃﬃ
5
p
es2t
 
!
u tð Þ:
As for the network function, it is easy to show that
Vo
Vs
sð Þ =
s
RC
s2 + 3
RC s +
1
RC
ð
Þ2
:
The two poles are on the real axis on the left plane and are equal to the natural frequencies
obtained earlier, and there is one zero at the origin.
R
d(t)
d(t)
R
+
vo(0+)
–
t = 0
+ vc1(0+) –
/R
R
C
R
C
t = 0+
vo(0+)/R
Figure 2.8: Circuit to determine the initial conditions of the circuit of Figure 2.7 at v(t)
2.5 Network Functions
91

The zeros of the network function on the other hand simply indicate frequencies where the
corresponding output is zero regardless of the input. This is particularly of importance when
designing ﬁlters, as we will discuss in Chapter 4. When the zeros are located properly, they
allow the input to be blocked at certain frequencies of interest.
Example: Consider the circuit of Figure 2.9, showing a ladder network comprising series
inductors and shunt capacitors.
At very low frequencies, all the inductors are short, whereas all the capacitors are open,
and thus the input current appears entirely at the output. On the other hand, at very high
frequencies the capacitors are short, while the inductors are open, and input current does
not appear at the output resistor. Thus the circuit is known to be lowpass and comprises
only zeros at inﬁnity. In fact, for such a lowpass ladder in general, we expect the transfer
function to be of the form
H sð Þ =
K
sn + an1sn1 + . . . + a0
,
where n is the total number of reactive components, and K is the product of all capacitors
and inductors. To prove the latter intuitively, consider a given section, say one consisting
of Ci and Li, at very high frequencies. We expect the ratio of the output to the input
current to be
1
Cis
Lis + 1
Cis ﬃ
1
LiCis2. Thus, by considering |H(ω)| at very large frequencies, and
realizing how the current is divided accordingly, we expect
H ω ! ∞
ð
Þ
j
j =
1
L1C1ω2 
1
L2C2ω2     
1
LmCmω2 = K
ωn ,
assuming we have an equal number of Ls and Cs, that is, n is even and equal to 2m.
Moreover, the lowpass ladder consists of n zeros at inﬁnity.
Example: In the previous example of Figure 2.7, the zero at DC is justiﬁable considering
that the series capacitance is open, and hence there is no voltage at the output at DC.
L1
L2
C1
C2
C3
+
R       v
–
Figure 2.9: A lowpass ﬁlter with zeros at
inﬁnity
92
RF Signals and Systems

As for the usage of the network in the context of an oscillator, one can see that at the
frequency of ω =
1
RC, we have
Vo
Vs
j
RC


= 1
3 :
If the output is fed back to the input with zero phase shift and a gain of higher than 3,
a positive feedback is established and the circuit is going to oscillate. The interested
reader may see Problem 10 for more details.
2.6
HILBERT TRANSFORM AND QUADRATURE SIGNALS
..............................................................................................
Quadrature signals and ﬁlters are widely used in RF receivers and transmitters. A quadrature
ﬁlter is an allpass network that merely shifts the phase of the positive frequency components by
–90º, and negative frequency components by +90º. Since 90º phase shift is equivalent by
multiplying by ej90 = j, the transfer function can be written as
HQ f
ð Þ =
j
f > 0
+ j
f < 0

,
which is plotted in Figure 2.10.
By duality (see Problem 12), we obtain the time domain representation of the sign function in
the frequency domain expressed above to be hQ tð Þ = 1
πt. For an arbitrary input x(t), passing
through such quadrature ﬁlter results in an output x^(t) deﬁned as the Hilbert transform of the
input:
^x tð Þ = x tð Þ∗1
πt = 1
π
ð∞
∞
x τð Þ
t  τ dτ:
From the impulse response derived, it is clear that Hilbert transform, or in general a 90º phase
shift is physically not realizable as hQ(t) is noncausal, although its behavior can be well
approximated over a ﬁnite frequency range using a real network.
0
+j
–j
f
HQ(f)
Figure 2.10: Transfer function of a quadrature
phase shifter
2.6 Hilbert Transform and Quadrature Signals
93

Example: To illustrate further, consider a rectangular pulse with a width of t0, as shown
in Figure 2.11.
The Hilbert transform, that is the pulse shifted by 90º is given by solving the convolu-
tion integral and is plotted in Figure 2.11 as well:
x^ tð Þ = 1
π ln
t
t  t0

,
which is clearly noncausal. Speciﬁcally, the output approaches inﬁnity at t = 0 and t = t0,
where there are sharp transitions in the input.
Example: We wish to ﬁnd the Hilbert transform of the function x tð Þ = sin t
t , which is
basically a sinc. In the frequency domain, the Fourier transform of x(t) is a pulse with a
height of π and a width of 1
π:
X f
ð Þ =
π
fj j < 1
2π
0
fj j > 1
2π
8
>
>
<
>
>
:
:
The Hilbert transform in the frequency domain will then consist of two pulses with half
the width shifted by  1
4π,
X^ f
ð Þ =  jX1
2 f  1
4π


+ jX1
2 f + 1
4π


,
where X1
2 f
ð Þ =
π
fj j < 1
4π
0
fj j > 1
4π
8
>
>
<
>
>
:
. In the time domain each pulse is a sinc itself. Therefore,
1
t0
0
t
Input Pulse
Pulse Hilbert 
Transform
Figure 2.11: Hilbert transform of a
rectangular pulse
94
RF Signals and Systems

x^ tð Þ =  j
sin t
2
t
e j 1
4π2πt 
sin t
2
t
ej 1
4π2πt
2
64
3
75 =
2 sin2 t
2
t
= 1  cos t
t
:
Finally, if x(t) = A cos(ω0t + φ), then x^(t) = A sin(ω0t + φ). Moreover, any signal that con-
sists of a sum of sinusoids follows the above accordingly.
2.7
STOCHASTIC PROCESSES
..............................................................................................
All meaningful communication signals are unpredictable or random, as viewed from the
receiver end. Otherwise there would be little value in transmitting a signal whose behavior is
known beforehand. Furthermore, the noise that is a great part of our discussion here and affects
communication systems in a number of ways is random in nature. Therefore, we dedicate this
section to discussing random or stochastic processes brieﬂy. Such signals are random in nature,
but also a function of time. Therefore, unlike the deterministic signals that we are mostly used
to, they have to be dealt with statistically, as their exact value at a given point of time is not
predictable, or known.
A random variable, X(s), maps the outcomes of a chance experiments into numbers along the
real line [5], [6]. For instance, the random variable X(s) may be mapping the outcome of the
random experiment, rolling the dice, into a discrete number 1, 2, . . . 6. The probability density
function (PDF), fX(x), is then discrete, and consists of points with equal probability of ⅙, as is
shown in Figure 2.12.
By
deﬁnition,
for
the
case
of
a
discrete
process
such
as
the
one
above,
Probability X  xk
f
g = Pk
i = 1 f X xi
ð Þ. It follows that Pn
i = 1f X xi
ð Þ = 1. In the case of a continu-
ous PDF the P is replaced by
ð.
A random (or stochastic) process, on the other hand, maps the outcomes into real functions
of time [5]. The collection of time functions is called an ensemble, represented by v(t, s), where
each member is called a sample. For example, consider this experiment: pick a resistor at
random out of a large number of identical resistors, and observe the voltage across its terminals.
The random electron motion produces a random voltage waveform for a given resistor, which
differs from the other ones, and hence is not predictable. Figure 2.13 depicts some of the
waveforms from the ensemble v(t, s).
fX(x)
x
1
2
3
4
5
6
1/6
Figure 2.12: Probability density function of
experiment rolling the dice
2.7 Stochastic Processes
95

At a given point of time, say t0, v(t0, s) is now a random variable. For instance, the noise
voltage of a given resistor at a given point of time could assume any random value with a given
probability density function. This we can represent by simply V0, with a certain probability
density function of fV0(v0). So the probability of this event such that v(t0) < a can be then found
by performing the integration:
Ð a
∞f V0 v0
ð
Þdv0. For the case of the resistor example, that is
essentially the probability of a given selected resistor noise voltage to be less than a. Naturally,
for the random process v(t), the probability density function is a function of time and may be
generally expressed as fv(v, t).
For a given random process v(t) with a probability density function fv(v, t), at an arbitrary
time t, the expected value of v(t) is deﬁned as
v tð Þ = E v tð Þ
½
≜
ð∞
∞
v tð Þf v v; t
ð
Þdv:
Likewise, the autocorrelation function between two random variables, v(t1) and v(t2), repre-
senting the random process at two points of time, t1 and t2, is the expected value of the product
v(t1)v∗(t2):
Rv t1; t2
ð
Þ≜E v t1
ð Þv∗t2
ð Þ
½
 =
ð∞
∞
ð∞
∞
v1v	
2 f v v1; v2; t1; t2
ð
Þdv1dv2,
which simply signiﬁes how the two variables measured at two different times are correlated.
For the remainder of this section, we assume that the random signals we deal with are real,
and thus drop the conjugate notation, that is,
Rv(t1, t2) = E[v(t1)v(t2)]
assuming v(t) is real.
Example: A randomly phased sinusoid is a random process deﬁned as
v(t) = Acos(ω0t + ϕ),
where A and ω0 are constants while ϕ is a random variable uniformly distributed between
0 and 2π. The underlying experiment might be picking an oscillator at random over
t
t
t
v1(t)
v2(t)
v3(t)
t0
V0
Figure 2.13: Waveforms in an ensemble v(t,s)
96
RF Signals and Systems

a large collection of oscillators with constant amplitude and frequency, but with no
phase synchronization. For the phase, the probability density function is f ϕ ϕ
ð Þ = 1
2π, for
0  ϕ  2π. The expected value is
E v tð Þ
½
 = v tð Þ =
ð2π
0
A cos ω0t + ϕ
ð
Þf ϕ ϕ
ð Þdϕ = 0:
The autocorrelation is
Rv t1; t2
ð
Þ =
ð2π
0
A cos ω0t1 + ϕ
ð
ÞA cos ω0t2 + ϕ
ð
Þf ϕ ϕ
ð Þdϕ,
and after expansion, the ϕ dependent term averages to zero, and we are left with
Rv t1; t2
ð
Þ = A2
2
ð2π
0
cos ω0 t1  t2
ð
Þ
ð
ÞPϕ ϕ
ð Þdϕ = A2
2 cos ω0 t1  t2
ð
Þ
ð
Þ:
Interestingly, the autocorrelation is only a function of the time difference, t1  t2. More-
over, for t1 = t2 = t,
v2 tð Þ = Rv t; t
ð
Þ = A2
2 ,
indicating the notion of the power.
2.7.1
Stationary Processes and Ergodicity
For the example above, we notice that the expected value is a constant, and the autocorrelation
is a function of the time difference: t1  t2. This type of process is known as a stationary
process. To generalize, if the statistical characteristics of a random process remain invariant
over time (of course not necessarily the process itself), we call the process stationary (in the
strict sense). Two important consequences of stationarity are:
The mean value must be independent of time: η(t) = E[v(t)] = η0.
The autocorrelation must depend only on the time difference, that is, Rv(t1, t2) = E[v(t1)
v(t2)] = Rv(t1  t2) = Rv(τ), where z = t1  t2.
If only these two conditions hold, the process is said to be at least stationary in the wide sense.
From Condition 2, it follows that the mean square value9 (that is, E[v(t)2]) and the variance of a
stationary process are constant. Furthermore, we have E[v2(t)] = Rv(0), analogous to the auto-
correlation of a real deterministic power signal.
Properties of Rv(τ) that follow from the second condition are:
– Rv 0
ð Þ = v2
9 Also known as the second moment.
2.7 Stochastic Processes
97

– Rv(τ) = Rv(τ)10
– Rv(τ)  Rv(0)
The latter can be proven easily considering that
E[|v(t1)  v(t2)|
2] = E[(v(t1))2  2v(t1)v(t2) + (v(t2))2] 
 0,
which leads to
Rv(0) 
 Rv(τ).
For the previous example of randomly phased oscillator, we further notice that the ensemble
average equals the corresponding time averages of an arbitrary sample function. Speciﬁcally, if
we take an arbitrary sample of v(t) = Acos(ω0t + ϕk), and apply the time average,
< v tð Þ > = lim
T!∞
1
T
ðT=2
T=2
v tð Þdt,
we will ﬁnd that <v(t) > = E[v(t)], and <v(t)v(t  τ) > = E[v(t)v(t  τ)] = Rv(τ).
When all ensemble averages equal to the corresponding time averages, the process is said to
be ergodic.11 An ergodic process must be strictly stationary, but an arbitrary stationary process
is not necessarily ergodic. There is no ergodic simple test for a given process. If a process is
stationary, and we can reasonably argue that a typical long enough sample function captures all
statistical properties of the process, we can assume ergodicity. Fortuitously, many communi-
cation processes that we deal with, including noise, happen to be ergodic, which results in great
ﬂexibility in characterizing them.
2.7.2
Gaussian Processes
A random process v(t) is called a Gaussian (or normal) process if its probability density function
(fv) as well as all higher order joint PDFs are Gaussian for all values of t. The probability density
function of a Gaussian process is
f v v; t
ð
Þ =
1ﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ
p
e vμ
ð
Þ2
2σ2 ,
where μ and σ are the mean and standard deviation, respectively. Although its proof is well
beyond the scope of this book,12 and it can be found in [5], the central limit theorem (CLT)
may be invoked to determine if a given process is Gaussian. The theorem states that, given
10 If the random signal is not real, then Rv(τ) = R∗
v(τ).
11 The word ergodic is Greek and was chosen by Boltzmann while he was working on a problem in statistical mechanics.
12 It can be proven by establishing the characteristics function of a random vector. It follows that the density function of the
sum of independent random variables equals the convolution of their densities.
98
RF Signals and Systems

certain conditions, the arithmetic mean of a sufﬁciently large number of iterates of inde-
pendent random variables, each with a well-deﬁned expected value and well-deﬁned
variance, will be approximately normally distributed. Since the random variables are inde-
pendent, the mean and variance of the sum is equal to the sum of the mean and variance of
each variable.
A good example is a resistor thermal noise, which is produced by the random (Brownian)
motion of many electrons in a microscopic fashion. This results in a normal distribution of the
noise itself at a macroscopic level.
It can be shown that if v(t) is Gaussian, then:
1. The process is completely described by v tð Þ and Rv(t1, t2), leading to the values of μ and σ.
2. If v(t) satisﬁes the conditions for wide-sense stationarity, then the process is strictly
stationary and ergodic.
3. Any linear operation on v(t) produces another Gaussian process.
Example: Consider a normal process X with zero mean passing through a squarer with
the output Y = X2. We wish to ﬁnd the output probability density function.
If y < 0, clearly y = x2 has no solution, and thus, fY(y) = 0. For y 
 0, there are two
solutions, x = 
ﬃﬃﬃy
p . By deﬁnition,
fY(y)dy = P(y  Y  y + dy),
where P(.) denotes the probability. Referring to Figure 2.14, and considering the sym-
metry of a normal process:
P(y  Y  y + dy) = 2P(x  X  x + dx),
where the values of x is obtained from y = x2 relationship or x = 
ﬃﬃﬃy
p as depicted in the
ﬁgure. Shown as well is the probability of x  X  x + dx highlighted by the shaded area
on the variable X normal density curve.
Continued
Y
X
y
y+dy
Y=X2
fX(x)
x
dx
Figure 2.14: A normal random variable
passing through a squarer block
2.7 Stochastic Processes
99

Thus
f Y y
ð Þdy = 2f X
ﬃﬃﬃy
p


dx = f X
ﬃﬃﬃy
p


ﬃﬃﬃy
p
dy,
owing to the fact that dy = 2xdx or dx = dy
2x =
dy
2 ﬃﬃy
p . Therefore
f Y y
ð Þ =
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσy
p
e y
2σ2u y
ð Þ,
where u(.) is the unity step function.
2.7.3
Systems with Stochastic Inputs
In most communication systems, it is common to pass a certain random signal (or noise)
through a ﬁlter (or any type of linear and time-invariant system), as shown in Figure 2.15.
The resulting output is
y tð Þ = L x tð Þ
½
 =
ð∞
∞
h τð Þx t  τ
ð
Þdτ,
where L signiﬁes the linear operation that the system imposes on x(t), and h(t) is the impulse
response. Since convolution is a linear operation, we expect a Gaussian input produces a
Gaussian output whose properties will be completely described by its mean and variance. We
assume x(t) is stationary and real, and that h(t) is real too. We expect then y(t) to be real and
stationary as well.
From convolution integral basic deﬁnition, it is easy to show that
E{L[x(t)]} = L{E[x(t)]}.
In other words, the mean of output equals to the response of the system to the mean of the input.
Furthermore, the autocorrelation of the output, Ry(t1, t2), can be obtained by taking a two-step
approach as follows. For a given time t1, x(t1) is a constant, and thus
x(t1)y(t) = x(t1)L[x(t)] = L[x(t1)x(t)],
which yields
E[x(t1)y(t)] = L{E[x(t1)x(t)]}.
h(t)
H(f)
x(t)
Gx(f)
y(t)
Gy(f)
h(t2)
h(t1)
Linear System
Response to Autocorrelation
Rx(t1,t2)
Rxy(t1,t2)
Ry(t1,t2)
Figure 2.15: A stationary input passing through a linear time-invariant system
100
RF Signals and Systems

Similarly,
E[y(t)y(t2)] = L{E[x(t)y(t2)]}.
Letting t = t2 in either one of the equations above, leads to auto- or cross-correlation functions,
as depicted in Figure 2.15.
For a stationary process, the input output correlations are convolutions with the impulse
response as proved earlier, with τ = t2  t1, which follows:
Ryx τð Þ = h τð Þ∗Rx τð Þ
Ry τð Þ = h τ
ð
ÞRyx τð Þ = h τ
ð
Þ∗h τð Þ∗Rx τð Þ:
Note that the last result could have been directly obtained from the integral itself:
Ry(τ) = E[y(t + τ)y(t)] = E
ð
h(α)x(t + τ  α)dα
ð
h(β)x(t  β)dβ

.
Or
Ry(τ) =
ÐÐ
h(α)h(β)E[x(t + τ  α)x(t  β)]dαdβ =
ÐÐ
h(α)h(β)Rx(τ  α + β)dαdβ,
which could be rewritten as
Ry(τ) =
ð
h(β)(
ð
h(α)Rx(τ  α  β)dα)dβ,
leading to Ry(τ) = h(τ) ∗h(τ) ∗Rx(τ).
Example: A normal stationary random signal X(t) with zero mean and autocorrelation
RX(τ) passes through a squarer with an output Y(t) = X2(t). We have
E[Y(t)] = E[X2(t)] = RX(0).
Furthermore, it can be shown ([6] and also see Problem 23) that if X and Y are jointly
normal random processes (or variables) with zero mean, then
E[X2Y2] = E[X2]E[Y2] + 2E2[XY].
Therefore
RY(τ) = E[X2(t + τ)X2(t)] = E[X2(t + τ)]E[X2(t)] + 2E2[X(t + τ)X(t)],
resulting in
RY(τ) = RX
2(0) + 2RX
2(τ).
The density functions as calculated in the previous example are shown in Figure 2.16.
Continued
2.7 Stochastic Processes
101

Notably,
E[Y(t)2] = RY(0) = 3RX
2(0).
Example: A hard limiter is a memoryless system creating 1 output as shown in
Figure 2.17:
y =
1
if x < 0
+ 1
if x > 0

:
The output expected value is
E[y(t)] = 1  P(x > 0)  1  P(x < 0) = (1  Fx(0))  Fx(0) = 1  2Fx(0),
where Fx(x) is the distribution function of random signal x (the integral of the probability
density function, that is, f x x
ð Þ = ∂Fx x
ð Þ
∂x ).
fX(x)
fY(y)
x
y
y
x
t
x(t)
t
y(t)
Figure 2.16: A normal random process passing through a squarer
y
x
t
x(t)
t
y(t)
+1
–1
Figure 2.17: Random signal x(t) passing through a limiter
102
RF Signals and Systems

There is not a simple form for the autocorrelation of y(t) in general, though interest-
ingly, if x(t) is a stationary normal process, it can be shown that (see Problem 21 for the
proof) the autocorrelation of the limiter output is Ry τð Þ = 2
π sin1
Rx τð Þ
Rx 0
ð Þ


.
2.7.4
Power Spectral Density
It is often more insightful to characterize the stochastic processes in the frequency domain.
Applying Fourier transform to the time domain signal directly is not meaningful. Instead, we
need to resort to statistical characteristics of the random signal.
Let v(t) be a wide-sense stationary random signal.13 Let us deﬁne
PT = 1
T
ðT=2
T=2
v2 tð Þdt,
which is a random variable itself. We deﬁne the average power of the random signal v(t) to be
P = lim
T!∞E PT
½
 = lim
T!∞
1
T
ðT=2
T=2
E v2 tð Þ


dt = < E v2 tð Þ


> ,
which involves time averaging (<. >) after ensemble averaging (E[]). Since v(t) is stationary,
we expect E v2 tð Þ
½
 = v2 to be a constant. Consequently, < v2 > = v2 = P. If the source is
ergodic as well as stationary, then v2 and v may be obtained from simply time domain averages.
The power spectral density or simply power spectrum Sv( f ) tells us how the power is
distributed in the frequency domain. The autocorrelation function of a wide-sense stationary
random process has a spectral decomposition given by the power spectrum of that process,
which is deﬁned as
Sv f
ð Þ = F Rv τð Þ
½
 =
ð∞
∞
Rv τð Þej2πf τdτ,
and conversely,
Rv τð Þ = F 1 Sv f
ð Þ
½
 =
ð∞
∞
Sv f
ð Þe j2πf τdf :
Just as in the case of deterministic signals, the autocorrelation and spectral density constitute a
Fourier transform. Since Rv(τ) = Rv
∗(τ), the power spectrum is always real. Furthermore, if
v(t) is real, then since Rv(τ) becomes even, so will be Sv( f ), and it may be expressed as
Sv f
ð Þ = 2
ð∞
0
Rv τð Þ cos ωτdτ:
13 There is generally little value in deﬁning the power spectral density for nonstationary processes.
2.7 Stochastic Processes
103

From the basic deﬁnition it follows
ð∞
∞
Sv f
ð Þdf = Rv 0
ð Þ = v2 = P,
which shows that the area of the power spectrum of any process is positive. Moreover, according to
the Wiener–Khinchin theorem,14 Sv( f ) 
 0 for every f, which will be proven in the next section,
after discussing the power spectrum of ﬁltered random signals. Conversely, if Sv( f ) 
 0 for every f,
then a process v(t) can be found that has the power spectrum Sv( f ). The proof is as follows:
Consider the process v(t) = ej(2πFt+ ϕ), where F is a random variable with the density fF( f ), and ϕ is
a random variable independent of F with a uniform density in the interval 0  ϕ  2π. This process
is stationary in wide-sense as the mean is zero, and the autocorrelation is
Rv τð Þ = E e j 2πF t + τ
ð
Þ + ϕ
ð
Þej 2πFt + ϕ
ð
Þ
h
i
= E e j2πFτ


=
ð∞
∞
e j2πf τf F f
ð Þdf :
By comparison, since Rv τð Þ =
Ð ∞
∞Sv f
ð Þe j2πf τdf , then Sv( f ) = fF( f ). Note that the density
function fF( f ) is obviously always positive.
In summary, the function Sv( f ) is a power spectrum if and only if it is positive.
Example: For the case of the randomly phased sinusoid, we calculated
Rv τð Þ = A2
2 cos 2πf 0τ
ð
Þ,
so
Sv f
ð Þ = A2
4 δ f  f 0
ð
Þ + A2
4 δ f + f 0
ð
Þ,
which is plotted in Figure 2.18.
A2/4
0
f
–f0
f0
Figure 2.18: Power spectrum
of a randomly phased sinusoid
14 Norbert Wiener proved this theorem for the case of a deterministic function in 1930. Aleksandr Khinchin later formulated
a similar result for stationary stochastic processes. Albert Einstein explained, without proof, the idea in a memo in 1914.
104
RF Signals and Systems

The results derived above could be generalized to model an arbitrary stationary process.
Consider the stationary process v(t), modeled as an inﬁnite sum of sinusoids that are uncorrel-
ated in phase and separated in frequency by 1Hz,15
v tð Þ =
X
∞
k = 0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4Sv k
ð Þ
p
cos 2πkt + ϕk
ð
Þ,
where Sv(k) is the spectral density (per unit hertz) of v(t) at frequency of k hertz, and ϕk is the
uncorrelated random phase offset of each sinusoid with a uniform distribution. The spectral
density of each cosine is an impulse with an amplitude of Sv(k), and frequency of k, as shown in
Figure 2.19.
In Chapter 6 we shall exploit this to calculate the spectral density of band-limited white noise
squared. We also use this in Chapter 9 to discuss phase and frequency noise.
Example: Consider the modulation operation deﬁned as
z(t) = v(t) cos(2πfct + ϕ),
where v(t) is a stationary random signal, and ϕ is a random angle independent of v(t)
uniformly distributed over 2π radians. If we didn’t include ϕ, z(t) would not be stationary.
Inclusion of ϕ simply recognizes arbitrary choice of the time with respect to v(t) and
cos2πfct as two independent functions,
Rz(τ) = E[v(t + τ)v(t) cos(2πfc(t + τ) + ϕ) cos(2πfct + ϕ)],
and after trigonometric expansion, and realizing that the ϕ dependent term averages to
zero, we obtain
Rz(τ) = 1/2Rv(τ) cos 2πfcτ,
Continued
Sv(f)
f
k
Acos(2 kt+
k)
A2/4 = Sv(k)
… 
… 
p
f
Figure 2.19: An arbitrary stationary
process modeled as an inﬁnite sum of
impulses in the frequency domain
15 The choice of 1Hz is somewhat inaccurate; rather the frequency separation is in general Δf, with Δf approaching zero,
assuming there is an inﬁnite number of inﬁnitesimal frequency bins. If the frequencies of interest are well above 1Hz,
which is usually the case, 1Hz is a reasonable approximation.
2.7 Stochastic Processes
105

and the power spectrum is
Sz( f ) = 1/4[Sv( f  fc) + Sv( f + fc)].
So the modulation translates the power spectrum of v(t) up and down by fc. Modulation
can be generalized to the case of the product of two independent and stationary processes
z(t) = v(t)w(t):
Rz(τ) = Rv(τ)Rw(τ)
and
Sz( f ) = Sv( f ) ∗Sw( f ),
similar to the multiplication property of Fourier transform of deterministic signals.
2.7.5
Filtered Random Processes
We showed previously that if a stationary random process x(t) passes through an LTI system
with an impulse response of h(t), the output y(t) autocorrelation is
Ry(τ) = h(τ) ∗h(τ) ∗Rx(τ).
Therefore in terms of power spectral density
Sy( f ) =|H( f )|
2Sx( f ),
from which
y2 = Ry 0
ð Þ =
ð∞
∞
H f
ð Þ
j
j2Sx f
ð Þdf :
Also, we can easily show
E y tð Þ
½
 =
ð∞
∞
h tð Þdt


E x tð Þ
½
 = H 0
ð ÞE x tð Þ
½
,
where H(0) equals the system DC gain.
One important outcome of ergodicity is the basic principle that a spectrum analyzer operates
upon. Although random signals such as noise require statistical data collection to be character-
ized, as long as they are ergodic, a simple time domain measurement is sufﬁcient. Consider
Figure 2.20, illustrating a simpliﬁed block diagram of a typical spectrum analyzer, where x(t) is
a random signal under test.
106
RF Signals and Systems

The input is ﬁrst passed through a narrow ﬁlter tuned at a desired frequency of f0. Sweeping
frequency (that is, varying f0) extracts the signal spectrum over the range of interest. Squaring
and lowpass ﬁltering are equivalent to time averaging, that is,
z(t) = < y(t)2>,
and from ergodicity,
z tð Þ = y2 = Ry 0
ð Þ:
On the other hand, assuming the ﬁlter is sufﬁciently narrow with a passband gain of unity, we
can write
Ry 0
ð Þ =
ð∞
∞
H f
ð Þ
j
j2Sx f
ð Þdf ﬃ
ðf 0 + B=2
f 0B=2
Sx f
ð Þdf ﬃSx f 0
ð
Þ,
which proves that the output signal z(t) is the power spectrum of the input at f0. It is important to
point out that the time average set by the lowpass ﬁlter must be sufﬁciently long to ensure that
the time and ensemble averages are identical. This is generally controlled by adjusting the
sweep time, whereas the bandpass ﬁlter bandwidth, B, is set by adjusting the resolution
bandwidth.
Since Sx( f0) is equal to the output power of ﬁltered signal (Sx f 0
ð
Þ = y2), it must be positive.
This indicates that for an arbitrary stationary process, always Sx( f ) 
 0 for all f, which serves as
proof of the Wiener–Khinchin theorem, stated in Section 2.7.4.
Example: Let us consider the Hilbert transform x^ tð Þ = x tð Þ∗1
πt = 1
π
Ð ∞
∞
x τð Þ
tτ dτ as we
deﬁned earlier, where x(t) (which is itself a random signal) is a random process. Since
HQ( f ) =  j sgn f, then |HQ( f )|2 = 1, and thus the power spectral density of a Hilbert
transformed signal is identical to that of the input signal. It also follows that the
autocorrelations are the same, indicating that 90º phase shift does not alter the random
signal statistics. The complex process,
z(t) = x(t) + jx^(t),
is known as the analytic signal associated with x(t). Then the response of such system is
1 + j(j sgn f ) = 2u( f ), and Sz( f ) = 4Sx( f )u( f ), where u is the unity step function.
( ) 2
LPF
x(t)
f0
B
y(t)
z(t)
1
Figure 2.20: An example of a
simpliﬁed spectrum analyzer
function
2.7 Stochastic Processes
107

Example: Consider the random process y tð Þ = 1
2T
Ð t + T
tT x θ
ð Þdθ. The process y(t) is
obtained by passing x(t) (which itself is a random signal) through a system whose impulse
response is a rectangular pulse with a height of 1
2T and width of T around zero. Clearly
H f
ð Þ = 1
2T
ðT
T
ej2πf τdτ = sin 2πf T
2πf T
:
Thus
Sy f
ð Þ =
sin 2πf T
2πf T

2
Sx f
ð Þ:
Also we can show that
Ry τð Þ = 1
2T
ð2T
2T
1  θj j
2T


RX τ  θ
ð
Þdθ:
Effectively, y(t) is the moving average of x(t), causing the signal energy to be mostly
concentrated around DC.
2.7.6
Cyclostationary Processes
In some RF circuits such as oscillators or mixers, the spectral density of the noise sources vary
periodically due to changing of the operating points of the transistors. This type of process is
called a cyclostationary process. By deﬁnition, a process v(t) is called strict-sense cyclosta-
tionary with period T if its statistical properties are invariant to a shift of the origin by integer
multiples of T [6], [7]. Similarly, v(t) is cyclostationary in the wide-sense if the following two
conditions are met:
E v t + mT
ð
Þ
½
 = E v tð Þ
½
 = η tð Þ
Rv t1 + mT; t2 + mT
ð
Þ = Rv t1; t2
ð
Þ,
for every integer m.
Example: A commonly used practical example of a cyclostationary process is the pulse
amplitude modulated signal,
v tð Þ =
X
∞
n = ∞
anh t  nT
ð
Þ,
where an is the random amplitude sequence, and h(t) is a deterministic time-sampling
function. If an is stationary, clearly v(t) satisﬁes the above two conditions for mean and
autocorrelation.
108
RF Signals and Systems

System analysts have, for the most part, treated cyclostationary signals as if they were
stationary [7]. This is simply done by time averaging the statistical parameters over one
cycle:
η = 1
T
ðT
0
η tð Þdt
Rv τð Þ = 1
T
ðT
0
Rv t + τ; t
ð
Þdt:
This, in fact, is exactly what is viewed if a cyclostationary process is displayed over a
spectrum analyzer.
Example: As a constructive case study, let us deﬁne the shifted process as follows:
vs(t) = v(t  θ),
where θ is a random variable uniform in the interval (0,T), and is independent of v(t). If
v(t) is cyclostationary in wide-sense, then the shifted process is stationary in wide-sense.
To prove that, let us ﬁrst ﬁnd the expected value of the shifted process. Since v(t) and θ are
independent,
E vs tð Þ
½
 =
ð∞
∞
ðT
0
v t  θ
ð
Þf V v
ð Þ 1
T dvdθ = 1
T
ðT
0
η t  θ
ð
Þdt,
where η(t) = E[v(t)]. Since η(t) is periodic,
ηs = E vs tð Þ
½
 = 1
T
ðT
0
η t  θ
ð
Þdθ = 1
T
ðT
0
η tð Þdt:
Similarly, for the autocorrelation, we can show
Rvs τð Þ = 1
T
ðT
0
Rv t + τ; t
ð
Þdt:
We will follow up with our discussion on cyclostationary processes in Chapter 5 in the context
of periodically varying noise in active devices.
2.8
ANALOG LINEAR MODULATION
..............................................................................................
Effective communication over appreciable distance usually requires a high-frequency sinus-
oidal carrier. Consequently, most practical transmission signals are bandpass. A general block
diagram of such a system is shown in Figure 2.21. The input signal contains the desired
information intended to be transmitted, for example voice or data, whose spectrum is typically
2.8 Analog Linear Modulation
109

located around DC, hence known as the baseband signal. Among various functionalities, one
important role of the transmitter is to translate the baseband signal to a known and desirable
high-frequency carrier, resulting in a modulated spectrum at carrier frequency (fc). The receiver
is expected to perform the reverse functionality, and thus extract the original baseband, infor-
mation-bearing signal from the modulated spectrum. This reverse process is known as
demodulation. The transmission channel is air in the case of wireless systems. In general, we
expect an attenuated version of the transmitter output to appear at the receiver input, but with
some contamination, such as noise, and interference added to it.
Among the many reasons for which modulation is required are the following:
1. Accommodating a large number of users. Imagine that if all the FM radios were to transmit
information at baseband, the stations would interfere with each other. The concept of one
tuning to one’s desired station would not exist.
2. Efﬁcient transmission where the frequency and thus efﬁciency of the corresponding travel-
ing electromagnetic waves are chosen appropriately [10], [11].
3. Practical design of antennas.
4. Compatible frequency assignment for several wireless standards operating concurrently.
5. Wideband noise or interference reduction by exploiting a narrowband bandpass receiver.
We will describe transmitter and receiver functionality in detail in Chapter 12. In this section we
will brieﬂy describe the fundamentals of analog linear modulation. This is followed by a
nonlinear modulation description in the next section. More details may be found in [10], [11]
as here we only recast a summary to establish the basic concepts needed in RF circuit design.
Furthermore, the analog and digital modulation schemes may be found in [12], [13] in details.
Let us start with amplitude modulation. There are two types of double-sideband amplitude
modulation: standard amplitude modulation (AM) and suppressed-carrier double-sideband
modulation (DSB). Before deﬁning those, let us review some conventions regarding modulat-
ing signals.
The analog modulation is performed on an arbitrary baseband message waveform x(t), which
is a stochastic process, and could stand for a sample function from the ensemble of possible
messages produced by the information source. It must have a reasonably well deﬁned band-
width, W, so there is negligible energy for | f | > W, as shown in Figure 2.22. Also for
mathematical convenience, we will normalize all messages to have a magnitude not exceeding
0
Transmitter
Receiver
Channel
Noise, 
Interference, 
...
fc >> W
0
W
+ Noise ...
Figure 2.21: A generalized communication system
110
RF Signals and Systems

unity, so |x(t)|  1. Furthermore, even though x(t) is a stochastic process, for convenience we
may often express it in the frequency domain directly by applying Fourier transform.
For an ergodic message source (or a deterministic one), this normalization puts an upper limit
on the average message power: < x2(t) >  1. Finally, sometimes for the ease of analysis, x(t)
may be expressed as a single tone, that is, x(t) = Am cos ωmt where Am  1, and fm < W.
The unique property of AM is that the envelope of the modulated carrier has the same
shape as the message. Thus for a modulated envelope of A(t) with an unmodulated amplitude of
Ac, we can write
A(t) = Ac[1 + μx(t)],
where μ is a positive constant called the modulation index. The complete amplitude modulated
signal xc(t) is then
xc(t) = Ac[1 + μx(t)] cos(ωct).
An example of a typical message and its corresponding AM signal is shown in Figure 2.23.
We have assumed μ < 1, and that the message bandwidth W is much smaller than the carrier
|X(f)|
f
–W
W
0
Figure 2.22: Message spectrum with a
bandwidth of W
t
t
AC(1+m)
AC(1–m)
1
–1
x(t)
xC(t)
xC(t)
x(t)
AM Waveforms
Simplified Peak Detector
Figure 2.23: Typical AM waveform
2.8 Analog Linear Modulation
111

frequency fc. With these conditions satisﬁed, a simple envelope detector may be used to extract
x(t) as shown in Figure 2.23. With μ = 1, the envelop Ac[1 + μx(t)] varies between zero and a
maximum of 2Ac. If μ > 1 however, the envelope could become negative, resulting in phase
reversal and ultimately envelope distortion [10]. This is known as overmodulation, and is
typically avoided in AM.
In the frequency domain, applying Fourier transform to xc(t) results in an impulse created due
to the cosine term from the carrier itself, as well as the message signal shifted to fc, as we
established before in our example for modulation. This is shown in Figure 2.24.
The AM spectrum consists of symmetrical lower and upper sidebands, and thus the name
double-sideband AM. Evidently, AM requires twice the bandwidth compared to unmodulated
baseband signals.
Expanding xc(t)2, and assuming that the baseband signal carrier has no DC content, we have
< xc tð Þ2 > = 1
2 Ac
2 1 + μ2 < x tð Þ2 >


:
Statistical averaging yields a similar result for E[xc(t)]. The term
1
2 Ac2 represents the
unmodulated carrier power, whereas 1
4 Ac2μ2 < x tð Þ2 > is the power per sideband (half of
1
2 Ac2μ2 < x tð Þ2 > at each sideband). Since |μx(t)|  1, at least 50% of the total transmitted
power resides in a carrier that conveys no information.
The wasted carrier power can be eliminated by suppressing the unmodulated term and setting
μ = 1, leading to
xc(t) = Acx(t) cos(ωct),
known as double-sideband suppressed-carrier or simply DSB. The spectrum is the same as
regular AM but without unmodulated carrier impulses. However, unlike AM, as the envelope
takes the shape of |x(t)| rather than x(t), the modulated signal undergoes a phase reversal
whenever x(t) crosses zero. That is clear by considering the envelope and phase of the DSB
signal as given below:
A tð Þ = Ac x tð Þ
j
j and ϕ tð Þ =
0
x tð Þ > 0
180
x tð Þ < 0

:
|Xc(f)|
f
fc–W
+W
0
Carrier
fc
fc
–fc
Upper
sideband
Lower
sideband
Figure 2.24: AM spectrum
112
RF Signals and Systems

This implies that suppressed-carrier DSB, though more power efﬁcient, does come at a cost, as
a simple envelope detector can no longer be used. In fact, detection of DSB calls for a much
more sophisticated demodulation process [10], [11]. As for DSB generation, perhaps the most
practical way is to use a balanced modulator shown in Figure 2.25, where DSB is created by
using two identical AM modulators, save for the reversed sign.
For phase noise analysis of oscillators in Chapter 9, it is beneﬁcial to calculate the spectra of
AM and DSB signals in the simple case of tone modulation. Setting x(t) = Am cos ωmt we obtain
for DSB
xc tð Þ = AcAm cos ωmt cos ωct = AcAm
2
cos ωc  ωm
ð
Þt + AcAm
2
cos ωc + ωm
ð
Þt:
For AM we have an extra term for the unmodulated carrier. The results are shown in
Figure 2.26.
The upper and lower bands of DSB are related due to symmetry, so either one contains all the
information. Thus, having both sidebands seems unnecessary. Therefore, suppressing either
sideband can cut the transmission bandwidth. This also results in reducing the transmission
power by half. A conceptual approach to produce single-sideband AM is shown in Figure 2.27,
where a sideband ﬁlter is used to suppress one sideband. Also shown is the modulated signal
spectrum in the case of upper sideband.
Producing such a sharp sideband ﬁlter may be a challenge in practice. Only if the baseband
signal has no or little energy around DC might the ﬁlter be realizable. A more practical approach
may be considered if one obtains the SSB signal in the time domain. Although the frequency
AM
Modulator
Σ
AM
Modulator
1/2x(t)
x(t)Accoswct
Accoswct
+
–
–1/2x(t)
Ac(1+0.5x(t))coswct
Ac(1–0.5x(t))coswct
Figure 2.25: Balanced modulator
Amplitude
f
fc –fm
fc –fm
fc+fm
fc
1/4AcAm
Amplitude
f
fc+fm
fc
1/4mAcAm
½Ac
Figure 2.26: AM and DSB spectrum for tone modulation
2.8 Analog Linear Modulation
113

domain spectrum is very easy to depict, the time domain signal requires a few steps to be
calculated. We show only the ﬁnal result here, while more details may be found in [10], [11]:
xc(t) = 1/2Ac[x(t) cos ωct  x^(t) sin ωct].
Appearance of the Hilbert transform may seem surprising at the ﬁrst glance, but we can
observe that the sideband ﬁlter, say in the case of upper sideband, is created by shifting the low-
pass equivalent as shown in Figure 2.28 to fc. The lowpass equivalent frequency response is
therefore 1/2[1 + sgn ( f )] for | f | < W. The function sgn(f) is the signum function and is
represented by Hilbert transform in the time domain, as we showed in the earlier section. The
remaining steps follow fairly easily.
The time domain signal representation leads to a very interesting system level realization that
has been widely adopted in almost all RF transmitters. As shown in Figure 2.29, the appropriate
|Xc(f)|
f
0
fc+W
fc
–fc
Sideband Filter
Balanced
Modulator
x(t)
Accoswct
Sideband
Filter
SSB
Figure 2.27: Single-sideband AM generation and its spectrum
|HBP(f)|
0
1
fc+W
fc
f
|HlP(f)|
0
1
W
f
Figure 2.28: Sideband ﬁlter lowpass equivalent
Σ
xc(t)
+
–
Ac/2coswct
HQ(f)
–90º  
x(t)
x^ (t)
Figure 2.29: Single-sideband modulator
114
RF Signals and Systems

sideband may be selected through a 90º phase shift of the carrier, and applying Hilbert
transform to the baseband signal. Although our example considered the upper sideband, lower
sideband is realized by adding the two terms, rather than subtracting.
The quadrature phase shifter, HQ(f ), is not realizable as we showed that Hilbert
transform leads to a noncausal impulse response. However, it may be approximated
usually with the help of additional but identical phase networks in both branches. It still
creates phase distortion at very low frequencies, and thus it works best if the baseband
signal has low energy around DC. In most modern transmitters today, this is done in the
digital domain and the analog baseband signal is produced by using a data converter. Note
that the carrier should be also shifted by 90º.
2.9
ANALOG NONLINEAR MODULATION
..............................................................................................
Two fundamental features of linear modulation described in the previous section are that the
modulated signal is a direct translation of the baseband spectrum and the transmission band-
width is at most twice that of the baseband. Moreover, it can be shown [10] that the ﬁnal signal-
to-noise ratio is no better than that of the baseband signal, and can be improved only by
increasing the power.
In contrast, in nonlinear modulation, such as phase (PM) or frequency (FM) modulation, the
transmitted signal is not related to the baseband signal in a simple fashion. Consequently, the
modulated signal bandwidth may very well exceed twice the message bandwidth. However, it
can provide a better signal-to-noise ratio without increasing the transmitter power. We will
momentarily show that the phase modulation is very similar to frequency modulation, so in this
section we will mostly explore the properties of FM only.
Consider the CW signal with a constant envelope but time-varying phase:
xc(t) = Ac cos (ωct + ϕ(t)).
The instantaneous angle is deﬁned as
θc(t) = ωct + ϕ(t),
while the instantaneous frequency is the derivative of the angle,
f tð Þ = 1
2π
d
dt θc tð Þ = f c + 1
2π
d
dt ϕ tð Þ:
We can see that the phase and frequency modulations are simply related by an integral. In the
case of FM, we can represent the instantaneous frequency in terms of the baseband message
signal, x(t), where, as before, we assume |x(t)|  1,
f(t) = fc + fΔx(t),
2.9 Analog Nonlinear Modulation
115

where fΔ < fc is called the frequency deviation. The upper bound of fΔ ensures that f(t) is always
positive. The FM waveform then can be expressed as
xc(t) = Ac cos(ωct + 2πfΔ
ð
x(τ)dτ).
We assume that the message has no DC component. If it did, it would simply result in a
constant carrier frequency shift.
The PM waveform, on the other hand, is
xc(t) = Ac cos(ωct + ϕΔx(t)),
where ϕΔ represents the maximum phase shift produced by x(t). By comparison, it is clear that
there is little difference between FM and PM.
One very important aspect of both PM and FM is that unlike linear modulation, they are
constant envelope and the transmission power is always 1/2Ac
2. In contrast, the zero crossings
are not periodic and change according to the baseband signal. Figure 2.30 shows a comparison
between AM and FM for a simple step-like baseband signal.
Despite similarities between FM and PM, frequency modulation turns out to have superior
noise related properties. For example, for a given noise level, since instantaneous frequency is
f(t) = fc + fΔx(t), the signal can be raised by increasing frequency deviation fΔ, without raising
the transmitted power. This, however, comes at the expense of a wider modulated bandwidth.
Ironically frequency modulation was ﬁrst conceived as a means of reducing the bandwidth. The
argument was that if instead of modulating the amplitude we modulate the frequency by
swinging it over a certain range, say 100kHz, then the transmission bandwidth is always twice
that, 200kHz, regardless of the baseband signal bandwidth. The major ﬂaw with this argument
is that there is a fundamental difference between the instantaneous frequency and the actual FM
bandwidth.
t
t
x(t)
AM
t
FM
Figure 2.30: A comparison between AM and FM
116
RF Signals and Systems

To be able to calculate the FM bandwidth, let us start with a special case where we assume
the phase variations are small: |ϕ(t)|  1. The modulated signal is
xc(t) = Ac cos(ωct + ϕ(t)) = Ac[cos ωct cos ϕ(t)  sin ωct sin ϕ(t)],
which under the above assumption simpliﬁes to
xc(t)  Ac[cos ωct  ϕ(t) sin ωct],
and in the frequency domain for positive f,
Xc f
ð Þ = 1
2 Acδ f  f c
ð
Þ + j
2 AcΦ f  f c
ð
Þ:
In the case of FM, Φ(f) =  jfΔX( f )/f, given that frequency is the derivative of phase. Thus if
x(t) has a bandwidth of W, the FM signal has a bandwidth of 2W, assuming |ϕ(t)|  1. This
special case is known as the narrowband FM, but proves to be very useful in analyzing various
circuits, including phase noise of oscillators.
Next let us consider the tone modulation, where x(t) = Am cos ωmt. Thus ϕ(t) = β sin ωmt,
where β = (Am/fm)fΔ, and is known as the modulation index. Narrowband tone modulation
requires β  1, and thus we will have
xc tð Þ  Ac cos ωct  Acβ
2
cos ωc  ωm
ð
Þt + Acβ
2
cos ωc + ωm
ð
Þt:
The corresponding spectrum and phasor diagram are shown in Figure 2.31. The spectrum is
a lot like that of AM shown in Figure 2.26, with one fundamental difference: there is a
phase reversal of the lower sideband, which produces a component perpendicular or quadrature
to the carrier phasor as shown in the phasor diagram. In the case of AM, it is in line with that
carrier.
For an arbitrary modulation index where the narrowband approximation will not hold, we
can write
xc(t) = Ac[cos(β sin ωmt) cos ωct  sin(β sin ωmt) sin ωct],
f
fc–fm
fc+fm
fc
Acb/4
½Ac
–Acb/4
Ac
fm
fm
A(t)
bAc/2
f(t)
Figure 2.31: Narrowband tone modulation spectrum
2.9 Analog Nonlinear Modulation
117

despite the fact that xc(t) itself is not periodic, the terms cos(β sin ωmt) and sin(β sin ωmt) are,
and can be expanded using Bessel functions as follows:
cos β sin ωmt
ð
Þ = J0 β
ð Þ +
X
∞
n even
2Jn β
ð Þ cos nωmt
ð
Þ
sin β sin ωmt
ð
Þ =
X
∞
n odd
2Jn β
ð Þ sin nωmt
ð
Þ:
There is no closed form of expressing Jn(β), and one must use numerical methods or available
tables to calculate the values. Nevertheless, to gain some insight, knowing that Jn(β) =
(1)nJn(β), we arrive at
xc tð Þ = Ac
X
∞
n = ∞
Jn β
ð Þ cos ωct + nωm
ð
Þt:
The equation above shows that the FM spectrum consists of a carrier at fc, as well as an inﬁnite
number of sidebands at fc  nfm as shown in Figure 2.32 (for simplicity the ½ factors are
dropped from the spectrum). The sidebands are equally spaced, but odd-order lower sidebands
are reversed in phase. Note that as n increases, |Jn(β)| tends to reduce, so the sidebands get
smaller. Also to avoid the far negative sidebands from folding back to positive frequency
βfm  fc, which is usually the case.
The relative magnitude of the carrier J0(β) varies with the modulation index (β), and thus
depends only partly on the modulating signal. Interestingly, J0(β) could be zero for certain
values of β, such as 2.4, 5.5, and so on. For very small values of modulation index, only J0 and
J1 are signiﬁcant, and moreover J0  1, which is the case of narrowband FM. On the other
hand, for larger values of β, the higher order terms are still signiﬁcant, and thus the FM
bandwidth will extend to well beyond twice that of the modulation signal.
From the spectrum shown in Figure 2.32 we can see that the FM has theoretically an inﬁnite
bandwidth. However, practical FM systems are band-limited and thus inevitably some fre-
quency distortion could occur. The actual FM bandwidth depends on how fast Jn(β) decays, and
what kind of distortion is acceptable. This can be done by estimating Jn(β) behavior, and is
discussed in [10].
Another interesting observation is that from Figure 2.31, the magnitude of the modulated
signal is not exactly equal to Ac. The difference may be justiﬁed by the even-order sidebands
that were previously ignored for the narrowband approximation. This is graphically shown in
f
fc–fm
fc+fm
fc
J0(b)
J1(b)
–J1(b)
J2(b)
J2(b)
J3(b)
–J3(b)
Figure 2.32: FM spectrum for tone
modulation
118
RF Signals and Systems

Figure 2.33, where all spectral lines are included. The odd-order pairs are in quadrature with the
carrier, and provide the desired frequency modulation, plus unwanted amplitude modulation.
The resultant even-order sidebands, collinear with the carrier, correct for the amplitude
variations.
As for realizing analog FM modulators, there are a number of different methods that mostly
rely on fundamental property of a voltage controlled oscillator (VCO), shown in Figure 2.34.
For a baseband signal x(t) applied to the VCO control voltage, the VCO output is
xc(t) = Ac cos

2πfct + KVCO
ð
x(τ)dτ

,
where KVCO is the VCO gain, Ac is the VCO oscillation amplitude, and fc is the free running
frequency, all design parameters. This is precisely what is needed to produce an FM signal. In
practice, since the oscillator free running frequency that sets the carrier frequency could vary, it
is common to place it inside a phase-locked loop [14], [15]. More details on analog FM
modulators and FM detectors can be found in [10], [16].
2.10 MODERN RADIO MODULATION SCHEME
..............................................................................................
Most modern radios use more complex modulation schemes where both phase (or frequency)
and amplitude vary with time. The RF signal can be expressed in the general form of
xc(t) = A(t) cos(ωct + ϕ(t)).
f(t)
Ac
Odd–
order
Even–
order
Figure 2.33: FM phasor diagram for arbitrary β
x(t)
xC(t)
Vcontrol
Figure 2.34: A voltage controlled oscillator as an FM modulator
2.10 Modern Radio Modulation Scheme
119

Moreover, the actual modulation scheme and the modulator itself are digital and the analog
equivalent as described above is created through a data converter. A generic transmitter is
accordingly shown in Figure 2.35, which is evolved from the single-sideband modulation
concept depicted in Figure 2.29. The digital modulator produces two components that are
multiplied with signals that are 90º out of phase. For that reason, the two branches are
commonly known as I (in-phase) and Q (quadrature phase). Although in a single-sideband
AM modulator the two inputs are created by using Hilbert transform, and thus one can be
obtained from the other, in most modern transmitters the I and Q inputs to the modulator are
uncorrelated. This is necessary to ensure that the baseband bandwidth is half of the bandwidth
of the ﬁnal RF output. If the two signals were Hilbert transform of each other, producing
an RF signal with a bandwidth of W, they would have needed a baseband signal spanning
from –W to +W. This is clear from Figure 2.27. The required bandwidth can be halved if the
architecture presented in Figure 2.35 is employed. Each of the baseband signals in the I and Q
channels has a bandwidth equal to W
2. The information in the I and Q channels is images of the
trajectory of the complex baseband signal on the constellation diagram when mapped to the
horizontal and vertical axes. This explains why the two baseband signals are statistically
independent.
Now, assume that XBB,I( f ) and XBB,Q( f ) are Fourier transforms of the baseband signals in
Figure 2.35. For a give frequency offset fm, Fourier transforms of the RF signal at fc + fm and
fc  fm are proportional to XBB,I(+fm) + j  XBB,Q(+fm) and XBB,I(fm) + j  XBB,Q(fm). Since
XBB,I(fm) + j  XBB,Q(fm) 6¼ {XBB,I( fm) + j  XBB,Q( fm)}∗, the up-converted components at
fc + fm and fc  fm are not complex conjugate of each other. In fact, assuming a normal
distribution, independency of the baseband signals at +fm leads to the independency of the
frequency components at fc + fm and fc  fm.
The dual of the above discussion can be also applied to a wireless receiver. Assume that the
received channel is centered at fc with a channel bandwidth equal to W. Considering only the
desired signal, the down-converted baseband signals each occupy a channel bandwidth equal to
W
2 and are statistically independent. Outputs of the two channels are treated as a single complex
signal (xBB,I + j  xBB,Q). After passing through a ﬁxed rotation, the resulting complex signal
can be directly mapped to the nearest point on the constellation diagram.
The transmitter in Figure 2.35 is known as a Cartesian modulator, where the baseband signals
are produced as quadrature (or I and Q) components, as opposed to a polar modulator, which
Σ
xC(t)
+
–
Ac/2cos
–90º  
Lowpass 
Filter
DAC
Digital Modulator
DAC
I
Q
wCt
Figure 2.35: Generic transmitter using
single-sideband modulation
120
RF Signals and Systems

takes phase and amplitude directly, as shown in Figure 2.36. The polar modulator then consists of
a frequency modulator, or to be precise a PM modulator, which could be realized as a VCO inside
a phase-locked loop, as well as a second path that takes the envelope (or the AM) information.
Both the AM and PM information may be created in digital domain and converted to analog
through a data converter, similar to the Cartesian transmitter. Although a polar modulator seems a
more natural way of realizing the intended modulated signal, there are several implementation
issues that make them less suitable for especially application that the baseband signal is wide-
band. Various types of transmitters and their properties will be presented in Chapter 12.
2.11 SINGLE-SIDEBAND RECEIVERS
..............................................................................................
While the transceiver architectures will be extensively discussed in Chapter 12, as an exercise
and also a dual discussion to single-sideband transmitters presented earlier (Figure 2.29), we
shall say a few words here regarding the single-sideband receivers, which perform the reverse
function of a single-sideband transmitter.
A single-sideband transmitter as introduced earlier in Section 2.8 is shown in Figure 2.37 on
the left, in which the baseband signal (x(t)) is shifted up in frequency by means of quadrature
multiplication and Hilbert transform around the carrier frequency (fc). A single-sideband
receiver shown on the right could be thought of as the dual of the transmitter, where the
modulated signal (xc(t)) at only one side of the carrier is shifted down in frequency. Similar to
the transmitter, the single-sideband receiver relies on quadrature multiplication and Hilbert
transform.
We will illustrate the functionality of the single-sideband receiver through an example shown
in Figure 2.38. Suppose the receiver input (xc(t) in Figure 2.37) consists of two modulated
spectrums one at the upper side of the carrier (the triangles), and one at the lower side (the
rectangles), as shown in Figure 2.38.
The input is ﬁrst multiplied by a cosine at the carrier frequency on the I side, and a sine on the
Q side. The Fourier transforms of the cosine and sine are also shown, which consist of a pair of
impulses at the carrier frequency. Since multiplication in the time domain is equivalent to
DAC
Digital Modulator
xc(t)
DAC
PM
AM
PLL
PM Modulator
A(t)
cos(
+ (t))
(t)
f
wct f
Figure 2.36: A conceptual polar transmitter
2.11 Single-Sideband Receivers
121

convolving in the frequency domain, the input signal is shifted up and down in frequency. The
up shift of the positive spectrum (or the down shift of the negative spectrum) results in a signal
around twice the carrier frequency, which is a very high frequency, and is typically lowpass
ﬁltered at the multiplier output. The remaining signals in the I and Q channels will now be at
baseband, as desired. However, the upper and lower sideband signals are not distinguishable, as
they both appear at the same frequency. Since their phases are different though, Hilbert
transform could be used to extract one. As shown in Figure 2.38 once the Hilbert transform
is applied to the Q channel (with the I signal remaining intact), the upper and lower sidebands
are aligned, and depending on whether the I and Q outputs are added or subtracted at this point,
only one sideband remains as desired.
fc
fc
–fc
1/2
fc
–fc
j/2
–j/2
–fc
*
0
fm
1/2
1/2
0
j/2
–j/2
fm
Aer Mulplicaon 
& Lowpass Filtering
Aer Hilbert
Aer Addion
Receiver Input
0
1/2
1/2
0
1/2
–1/2
1
0
Aer Subtracon
1
0
j/2
–j/2
1/2
–1/2
1
1
fm
1/2
Cosine
Sine
I
Q
I
Q
Figure 2.38: Signals at various points of the single-sideband receiver of Figure 2.37
Hilbert
Σ
+
±
x(t)
x(t)
cos
sin
sin
Single-Sideband Transmier
Hilbert
Σ
xC(t)
xc(t)
+
±
Single-Sideband Receiver
I
Q
I
Q
wct
wct
wct
coswCt
Figure 2.37: Single-sideband receiver compared against a single-sideband transmitter
122
RF Signals and Systems

The single-sideband receiver, also known as the image-reject receiver, is the basis of most
modern radio receivers. The Hilbert transform may be performed entirely in the digital domain
once the I and Q channels are digitized after multiplication, or could be approximated by a
polyphase ﬁlter (see Chapter 4) in the analog domain.
2.12 Summary
This chapter covered basic concepts of circuit theory and communication systems, and pre-
sented a summary of several key topics that will be revisited throughout the book.
We started with a brief summary of Fourier and Hilbert transforms, both of which serve as
great tools to analyze RF circuits and systems. To establish some foundation for noise analysis
presented in Chapter 5, a brief summary of stochastic processes and random variables was
provided. The majority of the material presented in this chapter was a review of various
concepts that exist in signal processing, communication systems, and basic circuit theory.
However, we felt it was important to remind the reader, especially a less expert one, of those
basic concepts.
– Sections 2.1 and 2.3 presented a brief summary of Fourier transform and Fourier series and
their properties.
– Fundamental properties of impulse response, natural frequencies, and poles and zeros were
reviewed in Sections 2.2, 2.4, and 2.5.
– Hilbert transform was discussed in Section 2.6, and will be followed up in Chapter 4 in the
context of quadrature ﬁlter design.
– Section 2.7 discussed stochastic processes and their properties. Many of the signals we deal
with in radio design, such as noise, are random in nature. A good understanding of random
signals is hence very critical.
– Fundamentals of analog modulation schemes and analog modulators were presented in
Sections 2.8 and 2.9.
– A brief introduction to modern radio modulation schemes was presented in Section 2.10.
Of special importance is Section 2.7, where random signals were discussed; it is important
to understand noise in time-varying circuits such as mixers (Chapter 8) and oscillators
(Chapter 9).
2.13 Problems
1. Using Fourier transform basic deﬁnition, prove Parseval’s energy theorem:
ð∞
∞
x tð Þ
j
j2dt =
ð∞
∞
X f
ð Þ
j
j2df :
2. Show that multiplying the Fourier transform by ej2πfτ results in a shift in the time domain.
2.13 Problems
123

3. Show that if x(t) is real, then X(f ) = X∗( f ).
4. Prove Parseval’s energy theorem for the Fourier series:
1
T
ð
T
v tð Þ
j
j2dt =
X
∞
k = ∞
ak
j
j2:
5. Show that the Fourier transform of x tð Þ =
1
1 + t2 is X( f ) = πe2π|f|. Hint: Use the duality
property.
6. This exercise shows that while every pole of a system is a natural frequency, the opposite is
not necessarily true. Consider the circuit below.
a. If the input is an impulse is(t) = δ(t), ﬁnd the initial capacitor voltage and inductor initial
current at t = 0+.
b. Find the impulse response of the circuit v(t). Determine the natural frequencies.
c. Find the transfer impedance V sð Þ
Is sð Þ. What are the circuit poles?
7. In the ladder structure shown below, show that the transfer function is of the form
vOUT sð Þ
iIN sð Þ =
1
ansn + an1sn1 +    + a1s + a0
,
where n is the number of reactive components, and an is their product.
8. In the circuit below, ﬁnd the impulse response in three different ways (1) Laplace
transform, (2) solving the time domain differential equation by integrating from 0 to 0+,
and (3) by intuitively ﬁnding the circuit initial condition. The response is the inductor
current i(t).
is(t)
C
R
L
R
+
v(t)
–
iIN
+
vOUT
–
… 
124
RF Signals and Systems

9. Shown below is the circuit of a Wien bridge oscillator. The RC phase shift network operates
as explained in the example shown in Figure 2.7. The resistors Rf and Rb along with the
opamp create the required gain from the point A to the output.
a. Determine the frequency of oscillation and explain the circuit operation.
b. What is the minimum Rf
Rb required for the circuit to oscillate?
Hint: Find the loop gain by following the output to point A through the RC phase shift
circuit, and from there back to the output through the ampliﬁer. Determine the
magnitude and phase of the loop gain.
10. Find the Fourier transform of x tð Þ =
eαt
t > 0
eαt
t < 0

.
11. Prove that the impulse response of the Hilbert transform is hQ tð Þ = 1
πt. Hint: In the previous
problem set α = 0, and use duality.
12. Show that the Hilbert transform of x tð Þ =
1
1 + t2 is x^ tð Þ =
t
1 + t2.
13. A transfer function H( f ) is plotted below, which has a unity magnitude and phase of α
and +α for positive and negative frequencies, respectively. Prove that the impulse response
is given by the following expression: h tð Þ = sin α
πt + cos α  δ tð Þ.
is(t)=δ(t)
R
L
R
L
i(t)
R
C
R
C
Rf
Rb
vo
A
B
2.13 Problems
125

14. Consider the following comb ﬁlter, where the input x(t) is a stationary random signal.
Prove that the autocorrelations of the input and output are related according to the
following equation: Ry(τ) = 2Rx(τ)  Rx(τ  T)  Rx(τ + T).
15. Buffon’s needle: A ﬁne needle of length a is dropped at random on a board covered with
parallel line distance b > a apart given the ﬁgure below.
a. Assume that the distance from the needle center to the edge of the adjacent line is
denoted by the random variable x, and the angle of the needle by θ. Assuming uniform
distribution for both random variables, show that f x; θ
ð
Þ = f X x
ð Þf Θ θ
ð Þ = 1
b
1
π.
b. Show that the probability of the needle intersecting with one of the lines is 2a
πb. As such,
this can be used to experimentally determine the number π.
H f
H f
f
f
a
a
x t
t
t
T
y
x
t
x
a
x
b
q
126
RF Signals and Systems

16. For the process x(t) = r cos (ωt + ϕ), we assume that random variables r and ϕ are inde-
pendent, and ϕ is uniform in the interval (π, π). Find the mean and autocorrelation.
17. For the process x(t) = a cos (ωt + ϕ), the random variable ω has the probability density
function of f(ω), and the random variable ϕ is uniform in the interval (π, π), and
independent of ω. Find the mean and autocorrelation of x(t).
18. Prove the equation E[L{x(t)}] = L{E[x(t)]}, where L denotes the linear operation imposed
by convolution integral.
19. Prove the Schwarz inequality: (E{xy})2  E{x2}E{y2}. Hint: Consider that the quadratic
E{(ax  y)2} = a2E{x2}  2aE{xy} + E{y2} is always positive for any a, where a is an
arbitrary constant.
20. Suppose x(t) is a stationary process with zero mean, and autocorrelation Rx(τ), and random
variable s is deﬁned as s =
Ð T
T x tð Þdt. Find the variance of s (σs
2) in terms of Rx(τ).
Answer: σs2 = Ð 2T
2T 2T  τj j
ð
ÞRx τð Þdτ.
21. Consider the random variables X and Y. We form a new random variable Z = X/Y.
a. Show that the density function of Z is f Z zð Þ = Ð ∞
∞yj jf zy; y
ð
Þdy, where f(x, y) is the joint
density function of X and Y.
b. If X and Y are jointly normal with zero mean, their spectral density is given by
f x; y
ð
Þ =
1
2πσ1σ2 ﬃﬃﬃﬃﬃﬃﬃﬃ
1r2
p
exp 
1
2 1r2
ð
Þ
x2
σ12  2r xy
σ1σ2 + y2
σ22




, where σ1 and σ2 are the
standard deviations of X and Y respectively, and r = E XY
½

σ1σ2 is the correlation coefﬁcient.
Show that f Z zð Þ =
σ1σ2 ﬃﬃﬃﬃﬃﬃﬃﬃ
1r2
p
πσ22
zrσ1
σ2

2
+ πσ12 1r2
ð
Þ
, known as a Cauchy density.
c. Prove that |r|  1.
22. If the random variables X and Y are jointly normal with zero mean, show that E[X2Y2] = E
[X2]E[Y2] + 2E2[XY].
23. For the limiter of Figure 2.17, assume x(t) is a normal stationary process.
a. Show that Ry(τ) = P(x(t + τ)x(t) > 0)  P(x(t + τ)x(t) < 0) = 1  2P(x(t + τ)x(t) < 0).
b. Given that the processes x(t + τ) and x(t) are jointly normal with zero mean, show that
their variance is Rx(0), and the correlation coefﬁcient

r = E XY
½

σ1σ2

is Rx τð Þ
Rx 0
ð Þ.
c. Using parts a and b, and Problem 9b, show that Ry τð Þ = 2
π sin 1
Rx τð Þ
Rx 0
ð Þ


. This result is
known as the arcsine law.
24. For the pulse amplitude modulated process v tð Þ = P∞
n = ∞anh t  nT
ð
Þ, we assume an is a
stationary sequence, with autocorrelation Ra(n) = E[an + mam], and spectral density
Sa f
ð Þ = P∞
n = ∞Ra n
ð Þej2πfn. We form the impulse train w tð Þ = P∞
n = ∞anδ t  nT
ð
Þ.
Show that for the impulse train process the autocorrelation of the shifted process ws(t) =
w(t  θ) is Rws τð Þ = 1
T
P∞
n = ∞Ra n
ð Þδ τ  nT
ð
Þ. Show that the spectral density for the
shifted process vs(t) = v(t  θ) is Svs f
ð Þ = 1
T Sa f
ð Þ H f
ð Þ
j
j2. Hint: v(t) is the output of a
linear system with input w(t). Thus v(t) = h ∗w(t) and vs(t) = h ∗ws(t).
2.13 Problems
127

25. In the previous problem, suppose h(t) is a pulse with width T, and is an is white noise
taking the values 1 with equal probability. The resulting process is called binary
transmission. It is a cyclostationary process taking the values of 1 in every interval T.
Show that Svs ω
ð Þ = 4 sin 2 ωT=2
ð
Þ
ω2T
.
26. Assume that x is a random variable with mean μ and standard deviation σ.
a. Prove that the following inequality is held for any arbitrary values of a and b
(b is positive): p jx  aj 
 b
f
g 
E
xa
ð
Þ2
f
g
b2
. Hint: p x  a
j
j 
 b
f
g =
Ð ab
∞f X x
ð Þdx +
Ð + ∞
a + b f X x
ð Þdx 
Ð + ∞
∞
xa
ð
Þ2
b2
f x x
ð Þdx =
E
xa
ð
Þ2
½

b2
, since xa
ð
Þ2
b2
> 1.
b. Use the above inequality to prove the following extension of Chebyshev’s inequality:
p k1 < x < k2
f
g 
4
μk1
ð
Þ k2μ
ð
Þσ2
f
g
k2k1
ð
Þ2
. Chebyshev’s inequality is a special case of the
above inequality where k1 = μ  kσ and k2 = μ + kσ.
27. A random telegraph signal assumes only two values, 0 and A, which happen with equal
probabilities. The signal makes independent random shifts between these two values. The
number of shifts per unit time is governed by the Poisson distribution, with μ being the
average shift rate
p x = k; over time τ
f
g = μk
k! eμτ


. (a) Prove that the autocorrelation
function of the signal is found to be Rv τð Þ = A2
4 1 + e2μjτj


. (b) Use the above autocorrela-
tion to ﬁnd the power spectral density.
28. Show that the FM signal, vc(t) = Ac cos (ωct + 2πfΔ
ð
x(τ)dτ), satisﬁes the following
equation, known as the FM differential equation,
vc tð Þ  vc0 tð Þωi0 tð Þ
ωi tð Þ3
+ vc00 tð Þ
ωi tð Þ2 = 0,
where ωi(t) is the instantaneous frequency.
29. Show that the FM signal also satisﬁes the following integro-differential equation:
vc tð Þ +
ðt
0
ωi θ
ð Þ
ðθ
0
ωi τð Þvc τð Þdτ


dθ:
Accordingly, devise an FM modulator by a circuit comprising multipliers and integrators
(known as analog computer) that satisﬁes the equation.
t
A
v t
128
RF Signals and Systems

30. Show that the following circuit may be employed as an FM demodulator. Propose a proper
circuit to perform the differentiation suitable for high frequencies.
Hint: Use the circuit below, known as a balanced slope demodulator.
2.14 References
[1] A. V. Oppenheim, A. Willsky, and I. Young, Signals and Systems, Prentice Hall, 1983.
[2] A. V. Oppenheim, R. W. Schafer, J. R. Buck, et al., Discrete-Time Signal Processing, Prentice Hall, 1989.
[3] W. E. Boyce, R. C. DiPrima, and C. W. Haines, Elementary Differential Equations and Boundary Value
Problems, John Wiley, 1992.
[4] C. A. Desoer and E. S. Kuh, Basic Circuit Theory, McGraw-Hill, 2009.
[5] A. Papoulis, Stochastic Processes, McGraw-Hill, 1996.
[6] A. Papoulis and S. U. Pillai, Probability, Random Variables, and Stochastic Processes, McGraw-Hill,
2002.
[7] W. Gardner and L. Franks, “Characterization of Cyclostationary Random Signal Processes,” IEEE
Transactions on Information Theory, 21, no. 1, 4–14, 1975.
[8] R. E. Colline, Foundation for Microwave Engineering, McGraw-Hill, 1992.
[9] D. M. Pozar, Microwave Engineering, John Wiley, 2009.
[10] A. B. Carlson and P. B. Crilly, Communication Systems: An Introduction to Signals and Noise in
Electrical Communication, vol. 1221, McGraw-Hill, 1975.
[11] H. Taub and D. L. Schilling, Principles of Communication Systems, McGraw-Hill, 1986.
[12] J. G. Proakis, Digital Communications, McGraw-Hill, 1995.
[13] K. S. Shanmugam, Digital and Analog Communication Systems, John Wiley, 1979.
[14] F. M. Gardner, Phaselock Techniques, John Wiley, 2005.
[15] D. H. Wolaver, Phase-Locked Loop Circuit Design, Prentice Hall, 1991.
[16] K. K. Clarke and D. T. Hess, Communication Circuits: Analysis and Design, Krieger, 1994.
d dt
is
v t
o
f
f
c
f
f
c
is
2.14 References
129

3
RF Networks
This chapter is dedicated to reviewing some of the basic concepts in RF design such as
available power gain, matching circuits, and scattering parameters. We also present a more
detailed discussion on both lossless and low-loss transmission lines and introduce the Smith
chart. In addition, we recast a follow-up discussion on a receive–transmit antenna pair viewed
as a two-port system. Most of the material presented will be used in Chapters 5 and 7, when
we discuss noise and low-noise ampliﬁers.
The majority of our discussions in this chapter, including topics on antennas and transmis-
sion lines, are closely tied with the material presented in Chapter 1.
The speciﬁc topics covered in this chapter are:
• Reciprocal and lossless networks
• Available power and matching
• Wideband and narrowband transformers
• Series–parallel transformation
• Antennas circuit model
• Lossless and low-loss transmission lines
• Smith chart
• Scattering parameters
For class teaching, we recommend focusing on Sections 3.2 and 3.3, which are crucial for
the LNA design. The transmission lines, Smith chart, and S parameters, while important for RF
design, could be skipped for the class. However, the material is relatively easy to follow, and
the interested student or engineer may study individually.
3.1
INTRODUCTION TO TWO-PORTS
..............................................................................................
3.1.1
Two-Port Deﬁnition
A two-port is simply a network inside a black box that has only two pairs of accessible
terminals, usually one representing the input, the other one the output. Let us consider a one-
port network ﬁrst shown in Figure 3.1.
Given a linear network and a pair of terminals, we obtain a one-port network, which could be
fully characterized by its Thevenin equivalent shown on the right. N0 is the same network with

all independent source turned off (voltage sources shorted, and current sources opened), known
as the relaxed network, and eOC is the Thevenin open circuit voltage across the one-port.
A two-port is simply an extension of the one-port concept, and is shown in Figure 3.2, which
is essentially a four-terminal network with two pairs of accessible terminals. What distinguishes
a two-port from any arbitrary four-terminal network is the additional constraint that the current
going into a given port must come out as shown in the ﬁgure.
From basic circuit theory [1], since there are four unknown elements attached to the two-port
(i1, v1, i2, and v2), the two-port can impose only two linear constraints on these four variables.
Since there are only six ways of picking two elements out of four, there are six ways of
characterizing a linear and time-invariant two-port, namely impedance, admittance, two hybrid,
and two transmission matrices. Knowing one, any other one of the ﬁve remaining matrices
could be obtained. For instance, admittance matrix is inverse of the impedance matrix. We will
later show that a two-port could be also represented by scattering parameters, which is a more
convenient way of characterizing it at microwave frequencies. The scattering matrix could be
also converted into any of the six aforementioned forms matrices.
Example: Let us ﬁnd the Z matrix of the simple resistive network shown in Figure 3.3.
From the basic deﬁnition, Z11 (or Z22) may be found by calculating the impedance of
the corresponding port, with the other port open-circuited. Hence
Continued
+
v
–
i
i
N
+
v
–
i
N0
eOC
Figure 3.1: A linear one-port and its
Thevenin equivalent
+
v1
–
i1
i1
N
+
v2
–
i2
i2
Figure 3.2: A two-port network
+
v1
–
i1
i2
+
v2
–
R1
R2
R3
Figure 3.3: A resistive T two-port
3.1 Introduction to Two-Ports
131

Z11 = R1 + R2
Z22 = R3 + R2:
Also,
Z12 = V1
I2

I1 = 0
= R2
Z21 = V2
I1

I2 = 0
= R2:
In this particular example, it happens that Z12 = Z21. We shall show next that this condition is
met for any reciprocal circuit, such as linear resistive networks.
3.1.2
Reciprocal Two-Ports
Consider the network of Figure 3.4, comprising only linear and time-invariant passive elements
(no active circuits, plasmas,1 and ferrites).2 As such, the network may be constructed by linear
resistors, capacitors, self, and mutual inductors (RLCM). Such network is known to be
reciprocal, possessing several useful properties, some of which we will brieﬂy discus here,
particularly the ones related to our discussion of available power gain.
First, from the electromagnetic point of view, of the several theorems related to the reciprocal
networks, perhaps the most common one is the one proposed by Hendrik Lorentz,3 over a
century ago, as follows:
Suppose the network of Figure 3.4 contains two current sources with densities of J1, and J2,
producing the corresponding electric and magnetic ﬁelds of E1, H1, E2, and H2.
Then the Lorentz theorem states that for an arbitrary surface S enclosing a volume V, we
have
Ð
V(J1. E2  J2. E1)dV =Þ
S(E1  H2  E2  H1)  dS.
A common situation arises when the volume V entirely encloses the current sources J1 and J2,
and that there are no incoming waves from far away. Under such conditions, the right-hand side
surface integral above diminishes to zero, leaving
1 Plasma is one of the four fundamental states of matter (the other three being solid, liquid, and gas) and was ﬁrst detected by
William Crookes in 1879. Like gas, it does not have a deﬁned shape but responds to an electromagnetic ﬁeld very
differently. It is abundant in stars, such as the sun. By studying Maxwell’s equations in a plasma environment, it can be
shown that when a magnetic ﬁeld is present, the plasma becomes anisotropic and hence in general leads to nonreciprocity.
2 Some of the most practical anisotropic microwave materials are ferrimagnetic compounds, or simply ferrites. In contrast
to ferromagnetic materials (such as iron), they have a signiﬁcant amount of anisotropy, induced by applying a DC magnetic
bias. Consequently, a microwave ﬁeld may interact very strongly with the resultant magnetic dipole in certain directions
rather than others.
3 Hendrik Lorentz was a Dutch physicist who was awarded the Nobel Prize in 1902.
132
RF Networks

Ð
VJ1. E2dV =
Ð
VJ2. E1dV.
From the latter equation, it may be deduced that for any reciprocal circuit, the voltage at
position 1 from a current at 2 is identical to the voltage at 2 from the same current at 1 (this is
shown in Figure 3.5 top in the context of a two-port with positions 1 and 2 being the input/
output ports). Equivalently, one can say that the current at position 1 from a voltage at 2 is
identical to the current at 2 from the same voltage at 1 (Figure 3.5 bottom).
Strictly speaking from the circuit point of view, we can make the following statements for the
zero-state response of the circuit:4
1. Connect a current source i(t) to the port labeled 1, and measure the voltage v(t) across
the second port. Next reverse the operation, that is, apply the same current source i(t) to the
second port, and observe the open-circuit voltage across the ﬁrst terminal, v0(t). The
reciprocity asserts that for all t: v(t) = v0(t). This is described in Figure 3.5 top.
2. Connect a voltage source v(t) to the port labeled 1, and measure the current response i(t) at
the second port. Next, apply the same voltage source v(t) to the second port, and observe the
short-circuit current at the ﬁrst terminal, i0(t). The reciprocity asserts that for all t: i(t) = i0(t).
This is described in Figure 3.5 bottom.
+
v1
–
i1
RLCM
i2
+
v2
–
Figure 3.4: A general reciprocal network comprising resistors,
capacitors, self, and coupled inductors
RLCM
+
V
–
I
RLCM
+
V’
–
I
RLCM
I
V
RLCM
I’
Open Circuit
Short Circuit
V
2
1
2
1
2
1
2
1
Figure 3.5: Two common criteria to test reciprocity in a given network
4 The zero-state response is the circuit response with an initial state of zero.
3.1 Introduction to Two-Ports
133

Note that in the ﬁrst case we observe open-circuit voltages, whereas in the second case short-
circuit currents are observed. Consistent with that, in the ﬁrst case a current source is applied,
while in the second case a voltage source is used.
Since the reciprocity theorem deals with the zero-state response, it is often convenient to
describe it in terms of network functions. This could lead to certain constraints in the impedance
(or other network) matrices. Consider Figure 3.5 for instance. Describing the input current and
the open circuit voltages in terms of their steady state phasor equivalents (I(jω) and V(jω)),
clearly we have
Z21 jω
ð
Þ = V jω
ð
Þ
I jω
ð
Þ :
But, from reciprocity, the trans-impedance from second port to the ﬁrst one is
Z12 jω
ð
Þ = V0 jω
ð
Þ
I jω
ð
Þ :
Hence, Z21(jω) = Z12(jω) for all ω. Similarly, we may infer Y21(jω) = Y12(jω). Thus, for
reciprocal networks, the Z (or Y) matrices are symmetric, that is to say, [Z] = [Z]t (superscript t
denotes traverse matrix).
Example: To demonstrate reciprocity in a practical circuit, consider the T-inductive
network depicted below. This circuit is often used to model a transformer or a coupled
inductor, in general (see Section 1.11.7). We shall try the case of voltage source/short-
circuit current to determine the reciprocity.
For the circuit shown on the top right of Figure 3.6, we have
I jω
ð
Þ =
V jω
ð
Þ
jL1ω + jL2ωkjL3ω
ð
Þ
L2
L2 + L3
=
L2
jω L1L2 + L2L3 + L3L1
ð
Þ V jω
ð
Þ:
For the bottom right circuit, if the roles are reversed, only L1 $ L3, and clearly the
observed short-circuit current remains the same.
A T-inductive network
Reciprocity test for SC case
V
V
I
I’
L1
L2
L3
Figure 3.6: A T-inductive circuit used to demonstrate reciprocity
134
RF Networks

The above statements for reciprocity may be readily proven using Tellegen’s theorem
[1].5 Suppose the network of interest consists of N branches, in addition to the input and
output ports labeled as α and β. Then the associated voltage and current phasors are Vα, Vβ,
V1, V2,. . ., VN and Iα, Iβ, I1, i2,. . ., IN. When the roles are reversed, we assume the corres-
ponding branch voltages and currents are V0
α, V0
β, V0
1, V0
2,. . ., V0
N and I0
α, I0
β, I0
1, i0
2,. . ., I0
N
(Figure 3.7). The boxes labeled α, β, α0, and β0 represent voltage or current sources on one
side, and short or open circuits on the other side. For instance, in the short circuit experi-
ment of Figure 3.5, α and β0 are the voltage sources, whereas β and α0 and are the short
circuits.
Since all four sets of voltage and current phasors satisfy KVL/KCL, we can write
VαI0
α + VβI0
β +
X
N
k = 1
VkI0
K = 0
V0
αIα + V0
βIβ +
X
N
k = 1
V0
kIK = 0:
The internal branches of the network are composed of linear and time-invariant resistors,
capacitors, or inductors,6 and as such
Vk = ZkIk,
where Zk is the corresponding branch impedance. Consequently,
X
N
k = 1
VkI0
K =
X
N
k = 1
ZkIk
ð
ÞI0
K =
X
N
k = 1
ZkI0
K


Ik =
X
N
k = 1
V0
kIK:
RLCM
+
V
–
I
N branches
+
V
–
I
RLCM
+
V’
–
I’
N branches
’
’
+
V’
–
I’
Roles reversed
b
a
b
a
a
a
b
b
a
a
b
b
Figure 3.7: Proof of reciprocity using Tellegen’s theorem
5 Tellegen’s theorem states that in an arbitrary lumped network comprising b branches of voltage vk and current ik, we have
Pb
k = 1vkik = 0, as long as the branch voltages and branch currents satisfy KVL and KCL. See Chapter 1 for more details
and a proof. See also [1] for a detailed proof and other relevant discussions.
6 The case of coupled inductors is handled taking the two corresponding branches and including the mutual
inductance.
3.1 Introduction to Two-Ports
135

Thus,
VαI0
α + VβI0
β = V0
αIα + V0
βIβ:
Now consider the ﬁrst statement for instance (Figure 3.5 top). Clearly Iβ = I0
α = 0, given the
open-circuit condition. Thus if Iα = I0
β, that is, if in either condition the network is excited by
the same current, then Vβ = V0
α, which implies same open-circuit voltages observed at the other
terminal.
A third statement dealing with reciprocity theorem is demonstrated in Figure 3.8. If for all
time the waveforms ii(t), and vi(t) are identical, the reciprocity asserts that, for all t,
vo(t) = io(t).
The proof readily follows from the Tellegen’s theorem and the equation above (see also
Problem 19).
As a ﬁnal remark, we shall show that in general reciprocity and passivity are not equivalent
in the context of the following example.
Example: A common example of a passive nonreciprocal circuit is a gyrator [2] whose
circuit symbol is shown in Figure 3.9.7 In practice passive gyrators are made of ferrites,
and have applications in many microwave circuits such as circulators or isolators [3], [4].
We will show in Chapter 4 that an active implementation of the gyrator is widely used in
active ﬁlter design.
RLCM
+
Vo
–
Ii
Io
2
1
RLCM
Vi
2
1
Figure 3.8: Third criteria for reciprocity
+
v1
–
+
v2
–
i2
i1
Figure 3.9: Circuit of a gyrator. The symbol has been
proposed by Tellegen.
7 The gyrator idea and its circuit symbol were proposed by Tellegen.
136
RF Networks

An ideal gyrator is described by the equations
v1 tð Þ = i2 tð Þ
v2 tð Þ =  i1 tð Þ,
or in terms of the impedance matrix,8
Z
½  =
0
1
1
0


,
Clearly the circuit is linear and time-invariant. Furthermore, the power delivered by the
external world to the gyrator is zero for all t, as
v1(t)i1(t) + v2(t)i2(t) = 0,
and hence, it is passive. However, it is not reciprocal as one can easily verify by applying
the same currents to each terminal, and observing that the open-circuit voltages will be
opposite in polarity.
3.1.2.1 Reciprocity in Nonlinear and Time-Variant Networks
A critical step in proof of reciprocity came from substituting the branch voltage, Vk by ZkIk.
Clearly, this can apply only to a linear and time-invariant element. Here, through a couple of
examples we shall show heuristically that reciprocity does not hold in general in either
nonlinear or time-variant networks.
Example: To demonstrate nonreciprocity in nonlinear circuits, consider the common-
source ampliﬁer depicted in Figure 3.10.
Suppose a step voltage of v(t) = V0u(t) is applied to the gate. As long as V0 is greater
than the transistor threshold voltage, a steady short-circuit current is produced at the drain.
If the step voltage is applied to the drain, however, clearly no current is created at the gate.
v(t)
V0
RD
CS Amplifier
io
VDD
Figure 3.10: A common-source ampliﬁer as an
example of a nonlinear and nonreciprocal circuit.
A step voltage at gate results in a step current at
drain, whereas the same voltage applied to drain
leads to no current at gate.
8 In general Z
½  =
0
α
α
0


, where α is called the gyration ratio.
3.1 Introduction to Two-Ports
137

It is important to note that even if the ampliﬁer is linearized around some operating point, it
would remain nonreciprocal, despite consisting of linear and time-invariant elements (Figure 3.11).
This is due to the dependent current source modeling the transconductance gain from gate to drain.
This shows that when dependent sources are present, reciprocity does not hold in general.
As an exercise, the interested reader may consider modeling the gyrator of Figure 3.9
through dependent sources, and examine reciprocity in the equivalent circuit.
Example: Consider the network of Figure 3.12, comprising a time-varying resistor. We
shall show that the circuit is not reciprocal.
Assume the time-varying resistor is described by
R(t) = R0 sin ω0t,
and the input current is i(t) = cos ω0t. Furthermore, suppose the LC tank is tuned to 2ω0,
that is, ω0 =
1
2 ﬃﬃﬃﬃﬃ
LC
p
. The time-varying resistor may be loosely modeling a passive mixer as
we shall discuss later on. Given the nature of the source current and the time-varying
resistor, we expect a voltage at the frequency of 2ω0 present across the resistor. The ideal
tank blocks this component to appear across the other resistor, R1. If the current is applied
to the other side, however, a voltage at the frequency of ω0 appears across the time-
invariant resistor, R1. This voltage is not going to be blocked by the LC circuit, and we
expect some kind of voltage at 2ω0 present across R(t).
In conclusion, in general, time-variant networks are not reciprocal. An exception to this is a
network comprising linear but time-varying resistors only. If the summation derived earlier
according to Tellegen’s theorem is expressed in time domain, we will have
vα tð Þi0
α tð Þ + vβ tð Þi0
β tð Þ +
X
N
k = 1
vk tð Þi0
k tð Þ = 0:
+
vgs
–
gmvgs
ro
RL
Rs
Figure 3.11: Small signal model of a common-source
ampliﬁer at low frequency. The presence of the dependent
current source leads to nonreciprocity
L
C
i(t)
R1
R(t)
Figure 3.12: Network comprising a time-variant linear
resistor
138
RF Networks

In a resistive network (time-variant or not) vk(t) = Rk(t)ik(t), and the proof readily follows from
this (see also Problem 20).
We shall use this important outcome when describing passive mixers in Chapter 8. Since
passive mixers are commonly realized by time-varying linear switches, they fall into the
category of linear resistive networks, and thus could be treated as reciprocal (at least if the
frequency is low enough where the capacitances are ignored).
As a ﬁnal remark, one can easily show that any reciprocal network may be represented by its
π or T equivalent circuits shown in Figure 3.13.
It is interesting to note that the equivalent circuits do not include any dependent sources,
while a general two-port represented by its Z or Y matrices does.
3.2
AVAILABLE POWER
..............................................................................................
An important concept that would be repeatedly used throughout noise discussion and low-noise
ampliﬁer design is the available power, and the available power gain. In this section we
examine this concept and discuss its key properties in the context of ampliﬁers as well as
passive reciprocal networks such as ﬁlters.
3.2.1
Basic Concept
Consider the simple resistive circuit of Figure 3.14. Assume the source is sinusoidal with a peak
voltage of |Vs|. Shown also is the load line (the solid line representing V = RLI) as well as the
source line (the dashed line, representing V = Vs  RsI) on the VI plane.
The point that the load and source lines intercept is naturally the operation point that
corresponds to V; I
ð
Þ =
RL
Rs + RL Vs;
Vs
Rs + RL

	
.
Shown also on the ﬁgure is the power hyperbola representing the 1
2 VI constant, which for a
given load of RL corresponds to 1
2 VI =
RL
2 Rs + RL
ð
Þ2 Vs
j
j2. The power hyperbola intersects the
source line in general at two points ð V; I
ð
Þ =
RLVs
Rs + RL ;
Vs
Rs + RL

	
and
V; I
ð
Þ =
RsVs
Rs + RL ,
RL
RsVs
Rs + RL


,
one of which is naturally the operating point. As the load varies, the operating point moves on
the source line, and there is one point where the power hyperbola is tangent to the source line, in
which case the hyperbola is at its farthest right. This corresponds to the maximum power at the
Z11 – Z12
Z12
Z22– Z12
–Y12
Y11 + Y12
Y22 + Y12
Figure 3.13: Equivalent circuits of any arbitrary reciprocal two-port
3.2 Available Power
139

load and happens when RL = Rs, that is, when the operating point voltage and current are in the
middle. The power delivered to the load in this condition is
Pa = Vs
j
j2
8Rs
,
which is only a function of the source, and not the load. This power is known as the source
available power, and is the maximum power that the load can extract from the source. In other
words, regardless of what the load is, the source cannot deliver any more power, and hence, the
name available power. This is graphically illustrated in Figure 3.15.
For very small or large values of load, the power delivered is small, as either the load voltage
or its current is very small, and naturally there exists some optimum value somewhere in the
middle.
3.2.2
Unilateral Two-Ports
Consider the ampliﬁer shown in Figure 3.16, where the source and load are represented with a
more general complex impedances. The ampliﬁer can be expressed in any of the matrices
mentioned before, but for the moment we assume it is unilateral, as is the case for most
well-designed open-loop ampliﬁers. We shall represent it here by its input impedance,
V
I
Vs
Vs/Rs
RL
RS
VS
+
V
–
I
Vs/2
Vs/2Rs
Figure 3.14: Simple circuit to
demonstrate the available power
concept
PL = 1/2VI
RL
Rs
|Vs|2/8Rs
0
Figure 3.15: Power delivered to the load of the circuit of
Figure 3.14 as a function of the load impedance
Unilateral Ampliﬁer
+
vIN
–
gmvIN
vs
ZS
ZIN
ZO
ZL
Figure 3.16: A simpliﬁed unilateral
ampliﬁer model
140
RF Networks

transconductance gain, and output impedance. A voltage ampliﬁer may be realized by simply
using a Thevenin equivalent circuit at the output.
From basic circuit theory [1], the complex power delivered from the source to the ampliﬁer
input is
P = 1
2 VINIIN
∗= 1
2
ZIN Vs
j
j2
Zs + ZIN
j
j2 ,
where VIN and IIN represent the peak voltage and current to the ampliﬁer input. Deﬁning
ZIN = RIN + jXIN, and Zs = Rs + jXs, the average power delivered is
Pavg = Re P
½  = 1
2 Vs
j
j2
RIN
Rs + RIN
ð
Þ2 + Xs + XIN
ð
Þ2 ,
which is maximized when RIN = Rs, and XIN =  Xs, or when ZIN = Zs
∗. This condition is
known as power matching, or source conjugate matching. The power delivered under such
condition, which is the source available power, is
Pa,IN = Vs
j
j2
8Rs
:
The total power generated by the source is easily shown to be
Ps = Vs
j
j2
4Rs
,
and thus, under source conjugate matching condition, half of the source average power is
delivered to the ampliﬁer, resulting in a power efﬁciency of 50%.
For cases such as a radar receiver, the input is conjugate matched, otherwise the incoming
electromagnetic energy will be lost if not absorbed entirely at the input. On the other hand, if in
a certain application power efﬁciency is of a more importance, conjugate matching is not a
desirable condition as half the power produced will be lost. As we will see in Chapter 11, this
becomes very important when designing power ampliﬁers.
Similarly, using Thevenin equivalent at the output, we can deﬁne the available output power as
Pa,OUT = gmZovIN
j
j2
8Ro
,
where Ro = Re[Zo] The ampliﬁer available power gain is deﬁned as the ratio of the available
powers at the output to the input:
Ga = Pa,OUT
Pa,IN
=
gmZovIN
j
j2
8Ro
vs
j j2
8Rs
= Rs
Ro
ZIN
Zs + ZIN


2
gmZo
j
j2:
For a resistive source, and assuming the ampliﬁer is matched at its input and output ports,
Zo = ZIN = Zs
∗, then
Ga = gmZo
j
j2
4
:
3.2 Available Power
141

3.2.3
General Two-Port Available Power Gain
The analysis performed on unilateral ampliﬁers can be readily extended to any two-port.
Consider Figure 3.17, showing a general two-port described by its Z matrix. Problems 9–11
deal with the case of a two-port represented by its Y matrix.
The input impedance of the ampliﬁer is (see Problem 9)
ZIN = Z11  Z12Z21
Z22 + ZL
,
which simpliﬁes to Z11 if the ampliﬁer is unilateral (Z12 = 0). The available input power is
Pa,IN = Vs
j
j2
8Rs
,
which is delivered to the two-port input under condition Zs = ZIN∗. To ﬁnd the available
power at the output, consider the Thevenin equivalent of the output port depicted in
Figure 3.18.
To ﬁnd the Thevenin impedance, we set the source voltage to zero, and obtain
ZTH = ZOUT = Z22  Z12Z21
ZS + Z11
:
ZS
VS
I1
Z11
Z12I2
I2
Z22
Z21I1
ZL
Arbitrary 2-Port
ZOUT
(Z21/ZS+Z11)VS
ZL
Output Thevenin 
Equivalent
ZOUT=Z22–Z12Z21/ZS+Z11
Figure 3.18: Thevenin equivalent of
the two-port output based on the
Z matrix
[Z]
ZS
ZL
VS
+
V1
–
+
V2
–
Figure 3.17: A general two-port represented by its
Z matrix
142
RF Networks

The Thevenin voltage is
VTH = Z21
Vs
ZS + Z11
:
Now considering the Thevenin equivalent shown at the bottom of Figure 3.18, the available
power delivered to the load impedance ZL is
Pa,OUT = VTH
j
j2
8ROUT
=
Z21
Zs + Z11


2
Vs
j
j2
8ROUT
,
where ROUT = Re [ZOUT].
The available power gain is then
Ga =
Rs
ROUT
Z21
Zs + Z11


2
:
Note that the available power gain is not a function of the load.
If the ampliﬁer is unilateral,
Ga =
Rs
ROUT
Z21
Zs + ZIN


2
,
which is the result obtained previously.
3.2.4
Reciprocal Networks
3.2.4.1 Available Power Gain of Reciprocal Networks
With this background, let us now derive a general expression for the available power gain of
reciprocal networks. Consider the RLCM circuit shown in Figure 3.19.
Since the available power gain does not depend on the load, the inclusion of the load
impedance will not affect the ﬁnal result, and thus for simplicity is left out.
RLCM
2
+
V
–
+
V
–
Is
V/I=(Z21/RS+Z11)RS
Reciprocity
1
1
RLCM
2
Rs
Rs
Is
Figure 3.19: The available power gain of a
reciprocal network
3.2 Available Power
143

With the source represented by its Norton equivalent, the open-circuit voltage at the output is
V =
Rs
Rs + Z11
Z21Is:
If the output is excited by the same current Is, then according to reciprocity the open-circuit
voltage observed at the other end must be the same, that is, V =
Rs
Rs + Z11 Z21Is, as shown in the
bottom of Figure 3.19.
Considering Figure 3.19 bottom side, the total power delivered to the output port by the
exciting current source Is is
1
2 Re ZOUT
½
 Is
j j2 = 1
2 ROUT Is
j j2,
where ROUT = Re[ZOUT]. This power must be greater than that dissipated in Rs, as the network
does not contain any active elements. Hence,
1
2 ROUT Is
j j2  1
2
V
j j2
Rs
,
but V =
Rs
Rs + Z11 Z21Is, and consequently
Rs
Z21
Rs + Z11


2
 ROUT:
Recall that for an arbitrary two-port in general, the available power gain was shown to be
Ga =
Rs
ROUT
Z21
Zs + Z11


2
:
Thus, the available power gain of a reciprocal network is always less than one. Note, this
outcome may be derived through an alternative and more general approach presented in
Problem 11.
An important observation that may be made is the contrast between unilateral and recipro-
cal networks. A unilateral network, and particularly a unilateral ampliﬁer, is highly non-
reciprocal, as Z12 = 0, while Z21 is typically made large (compared to the ampliﬁer ROUT)
given the gain requirements. Whereas one may obtain voltage or current gain in a reciprocal
network (say a step-up or -down transformer), such network is never capable of producing
power gain.
3.2.4.2 Lossless Reciprocal Networks
In the special case of a reciprocal lossless N-port, the net average power delivered to the
network must be zero. As such, assuming exciting current of [I] = [I1, I2, . . ., IN] at the ports,
and the corresponding voltage of [V] = [V1, V2, . . ., VN], we can write
Pavg = 1
2 Re
V
½ t I½ ∗


= 1
2 Re
Z
½  I½ 
ð
Þt I½ ∗


= 1
2 Re
I½ t Z
½  I½ ∗


= 0,
144
RF Networks

where, given reciprocity, we have assumed [Z] = [Z]t. Hence
Pavg = 1
2 Re
X
N
m = 1
X
N
n = 1
ZnmInIm
∗
"
#
= 0:
Since the currents are independent, by setting all the currents except the one at the nth port
to zero, we must have the real part of each term inside the summation to be zero, that is,
Re[ZnnInIn
∗] = |In|2 Re [Znn] = 0. Thus,
Re [Znn] = 0.
Similarly, by setting all port currents except for In and Im (n 6¼ m) to be zero, we arrive at
Re [InIm
∗Znm + ImIn
∗Zmn] = Re [(InIm
∗+ ImIn
∗)Zmn] = 0.
However, generally speaking, (InIm
∗+ ImIn
∗) is a real quantity that cannot be necessarily zero,
and hence
Re [Zmn] = 0.
Thus, in a lossless reciprocal network, the Z (or Y) matrixes are symmetric, and imaginary.
Evidently, such network may be only constructed by capacitors, as well as self and coupled
inductors (or transformers).
From the argument presented in the previous section, it is obvious that a lossless reciprocal
network always has an available power gain of one.
3.2.5
Stability of Two-Port Ampliﬁers
Consider the two-port shown below (Figure 3.20) expressed by its Y parameters. We wish to
ﬁnd a condition that the two-port is unconditionally stable.
The two-port will be potentially unstable if the admittance (or impedance) of either port has a
negative conductance for a passive termination on the other port. This means that once the
source (or load) impedance is added, the real part of the combined impedances could become
negative, in which case the ampliﬁer will oscillate.
Consider the expression for the admittance of the input port,
YIN = Y11  Y12Y21
Y22 + YL
,
Y[ ]
YS
YL
VS
+
V1
–
+
VL
–
YIN
YOUT
Figure 3.20: Two-port ampliﬁer driven by a
source and terminated by a load
3.2 Available Power
145

where YL is the load impedance. Deﬁning
Y11 = G11 + jB11
Y22 = G22 + jB22
YL = GL + jBL
Y12Y21 = P + jQ,
we can rearrange the input admittance expression as
YIN = G11 + jB11 
P + jQ
G22 + jB22 + GL + jBL
:
With some manipulation we obtain
Re YIN
½
 =
G22 + GL
ð
Þ2 + B22 + BL
ð
Þ2 
P
G11 G22 + GL
ð
Þ 
Q
G11 B22 + BL
ð
Þ
G22 + GL
ð
Þ2 + B22 + BL
ð
Þ2
G11
:
For the ampliﬁer to be stable, G11 must be always positive, otherwise for a sufﬁciently large YL
(say shorting the output port), Re [YIN] becomes negative. A similar reasoning can be made for
G22 > 0. With G11 > 0, we note that the denominator of Re [YIN] is always positive, and thus we
need to seek the condition where the numerator is always positive. To do so, we rearrange the
numerator as
G22 + GL
ð
Þ2 + B22 + BL
ð
Þ2  P
G11
G22 + GL
ð
Þ  Q
G11
B22 + BL
ð
Þ
=
GL +
G22 
P
2G11



2
+
BL +
B22  Q
2B11



2
 P2 + Q2
4G112 :
The numerator is minimum for the load admittance of GL = 0 and BL = 
B22 
Q
2B11

	
(a reactive load). Under this condition, we must have
G22 
P
2G11

2
> P2 + Q2
4G112 ,
or
2G11G22  P
j
j >
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P2 + Q2
q
:
Deﬁning
C =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P2 + Q2
p
2G11G22  P ,
known as the Linvil stability factor, we must then have
0 < C < 1.
(Note that the condition 1 < C < 0 cannot be met. Why?) Alternatively, we can write
K = 2Re Y11
ð
ÞRe Y22
ð
Þ  Re Y12Y21
ð
Þ
Y12Y21
j
j
> 1:
146
RF Networks

Since the above expression will not change if the input and output ports are switched, it is often
used as a general criterion for the two-port unconditional stability.
Example: For a given ampliﬁer, Y =
2 + j2
ð
Þ  103
2  j20
ð
Þ  106
20  j3
ð
Þ  103
20 + j60
ð
Þ  106


. We wish to
evaluate the stability of the ampliﬁer.
We form
Y12Y21 = 2  j20
ð
Þ  106  20  j3
ð
Þ  103 = 100  j394
ð
Þ  109
= 406  109ej256:
Thus
K = 2Re Y11
ð
ÞRe Y22
ð
Þ  Re Y12Y21
ð
Þ
Y12Y21
j
j
= 0:44 < 1:
So the ampliﬁer is potentially unstable.
3.2.6
Maximum Power Gain
Considering the two-port of Figure 3.20, we shall deﬁne the power gain as the ratio of the
power delivered to the load, to the power appearing at the two-port input,
Gp = PL
PIN
,
where PL = 1
2 Re YL
½
 VL
j
j2, and PIN = 1
2 Re YIN
½
 V1
j
j2. Since VL =
Y21
Y22 + YL V1, we have
Gp = Re YL
½

Re YIN
½

VL
V1


2
=
Re YL
½
 Y21
j
j2
Re Y11  Y12Y21
Y22 + YL


Y22 + YL
j
j2
:
Clearly the power gain does not depend on the source impedance, and is only a function of the
two-port and the load.
Assuming the two-port is unconditionally stable (K > 1), we shall ﬁnd the load admittance for
which the power gain is maximized. To do so we must naturally solve for ∂Gp
∂GL = 0, and ∂Gp
∂BL = 0.
This leads to
GL,opt =
1
2G11
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2G11G22  P
ð
Þ2  P2 + Q2


q
BL,opt =
Q
2G11
 B22
Gp,MAX =
Y21
j
j2
2G11G22  P +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2G11G22  P
ð
Þ2  P2 + Q2


q
:
3.2 Available Power
147

The optimum load admittance obtained above does not necessarily mean the power delivered to
the load is maximized; rather it only guarantees that for a given power delivered to the input
(PIN), the power absorbed by the load is maximized. To maximize the power at the load for a
given source, we must also have
Ys = YIN
∗,
where YIN = Y11 
Y12Y21
Y22 + YL,opt is a function of the load admittance. This leads to the following for
the optimum source impedance:
Gs,opt =
1
2G22
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2G11G22  P
ð
Þ2  P2 + Q2


q
Bs,opt =
Q
2G22
 B11:
The above equations may be recast as the following more concise formulas (see Problems 9–11
as well as [5] for more details):
Ys,opt =
Y12Y21 + Y12Y21
j
j K +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p

	
2Re Y22
ð
Þ
 Y11
YL,opt =
Y12Y21 + Y12Y21
j
j K +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p

	
2Re Y11
ð
Þ
 Y22
Gp,MAX = Y21
Y12

 K 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p

	
,
where K is the stability factor obtained in the previous section.
Under the optimum source and load impedances, the two-port is known to be biconjugate
matched, that is, the source available power is delivered to the input, and simultaneously the
output available power is delivered to the load as well. In other words, if
Ys = Ys,opt
YL = YL,opt

, then
Ys = YIN
∗
YL = YOUT
∗

. In this case the power gain and the available power gains are equal and are both
maximum.
Clearly for the conditions above to hold we must have K > 1. If the two-port is potentially
unstable, Gp,MAX is meaningless, as for a certain load admittance, the power delivered to the
input (PIN = 1
2 Re YIN
½
 V1
j
j2) will be zero (since Re [YIN] can become negative, for some YL it
must be zero). Therefore, the power gain will become inﬁnite.
Example: The Y parameters of the transistor 2N3783 at 200MHz are as follows:
Y =
20 + j13
ð
Þ  103
0:015  j0:502
ð
Þ  103
41:5  j64
ð
Þ  103
0:25 + j1:9
ð
Þ  103
"
#
:
148
RF Networks

Thus,
Y12Y21 = P + jQ = (32.75  j19.84)  103.
The stability factor is then found to be
K = 2Re Y11
ð
ÞRe Y22
ð
Þ  Re Y12Y21
ð
Þ
Y12Y21
j
j
= 1:116,
so it is unconditionally stable. The optimum source and load admittances are
Ys,opt = 37:6  j52:7
ð
Þ  103
YL,opt = 0:47  j2:41
ð
Þ  103 :
We see that Bs,opt and BL,opt are negative. This makes sense as the internal capacitances of
the transistor must resonate with the optimum source and load inductances to create
conjugate matching.
3.2.6.1 Reciprocal and Unilateral Two-Ports
If the two-port is reciprocal, Y21 = Y12. Thus,
Gp,MAX = Y21
Y12

 K 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p

	
= K 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p
< 1:
In a unilateral two-port, however, Y12 = 0. Therefore, as long as Re (Y11) and Re (Y22) are
positive, the two-port is unconditionally stable. Additionally, with
Ys = Y11
∗
YL = Y22
∗

, the power
gain is maximized, and
Gp,MAX =
Y21
j
j2
4G11G22
:
3.3
IMPEDANCE TRANSFORMATION
..............................................................................................
In RF circuits, and particularly RF ampliﬁers, it is often necessary to transform the input
impedance to some desirable value. There are several reasons for this, mainly arising from the
fact that the input impedance of the ampliﬁer, often constrained by its performance parameters
such as gain or power consumption, may not match what is required say by maximum power
transfer or other considerations such as minimum noise ﬁgure.9 As shown in Figure 3.21, there
is often a need for an intermediate network, known as the matching network, to transform the
ampliﬁer input impedance to the optimum value.
9 We will discuss minimum noise ﬁgure in Chapter 5.
3.3 Impedance Transformation
149

Another common situation is a receiver often preceded by high-quality external ﬁlters that
are required to be terminated to 50Ω at their inputs and outputs (Figure 3.22). Typical example
of such ﬁlters include SAW (surface acoustic wave) ﬁlters, that are electromechanical devices
constructed of a piezoelectric crystal or ceramic (see Chapter 4 for more details). A non-50Ω
termination often degrades the ﬁlter passband loss, and reduces its stopband attenuation. On the
other hand, as we will discuss in Chapter 7, due to noise and power consumption trade-offs, it is
desirable to design the ampliﬁer with a different, and often much higher input impedance than
the 50Ω needed by the ﬁlter. Thus a matching network, so long as it does not contribute much
to the cost, becomes very handy.
Matching networks are not unique to the receivers, and are common in transmitter as well,
especially the power ampliﬁers, for similar reasons.
Since the matching network is at the very input of the ampliﬁer and often the entire radio, its
performance becomes very critical. For that reason, it is typically built of very low-loss passive
components such as high-Q inductors and capacitors. If the quality factor of integrated
components is not high enough, it is not uncommon to realize the matching network, or part
thereof, using external, higher Q elements. Given its importance, we will spend this section on
discussing a few common topologies. Shown in Figure 3.23 is various commonly used
matching networks in radios. Their functionality and their properties will be discussed in the
next few sections.
3.3.1
Lossless Matching Network Basic Properties
Before we get to the matching network implementation, we will discuss some general
properties ﬁrst.
Consider the circuit in Figure 3.24, consisting of a lossless (LCM) network (representing the
matching circuit) terminated to a source and a load. If the source or load have any reactive part,
it may be lumped into the LCM network without the loss of generality. VS represents the RMS
value of the source voltage.
ZIN
Matching
Network
Amplifier
ZOPT
Source
Figure 3.21: Role of matching networks
in RF ampliﬁers
Matching
Network
Receiver
50Ω
Figure 3.22: External SAW ﬁlter connected to a receiver
150
RF Networks

Assume the impedances looking into the right and left of the lossless circuit are Z1 and Z2,
respectively, as shown. Excluding the load, the circuit may be represented by its Thevenin
equivalent illustrated in Figure 3.25.
To ﬁnd the open circuit Thevenin voltage VOC, reciprocity dictates that if the current source
IS is applied to the right side of LCM network, it will induce the same open circuit voltage, VOC
on the resistor RS (bottom ﬁgure). Given the LCM circuit is lossless, the power conservation
demands
Re Z2
½
 IS
j j2 = VOC
j
j2
RS
,
and hence,
VOC
j
j2 = RSRe Z2
½
 IS
j j2 = Re Z2
½

RS
VS
j
j2:
Therefore we can replace the circuit of Figure 3.24 with the equivalent circuit as follows.
The power delivered to the load, PL is
PL =
VOC
RL + Z2


2
RL,
which must be equal to the power delivered to the input of the LCM network of Figure 3.24, P1,
where
Figure 3.23: Various
types of matching circuits
commonly used in radios
LCM
RL
RS
VS
Z1
Z2
+
VL
–
Figure 3.24: A terminated lossless matching network
3.3 Impedance Transformation
151

P1 =
VS
RS + Z1


2
Re Z1
½
:
Thus,
Re Z1
½
RS
RS + Z1
j
j2 = Re Z2
½
RL
RL + Z2
j
j2 :
With some simple algebra we arrive at
Z1  RS
Z1 + RS

 = Z2  RL
Z2 + RL

:
By deﬁnition, ρ1≜Z1RS
Z1 + RS is the input reﬂection coefﬁcient (or reﬂection factor), and
ρ2≜Z2RL
Z2 + RL is the output reﬂection coefﬁcient.10 Thus, reciprocity, and the lossless nature
of the LCM network demand equal magnitude for the input and output reﬂection coefﬁ-
cients. Furthermore, if one port is matched, say Z1 = RS, the other port is automatically
matched too, that is, Z2 must be equal to RL. The latter can be physically explained as
follows. If the input is matched, the source available power
VS
j
j2
4RS

	
is absorbed by the
lossless LCM network, which is then entirely delivered to the load. Hence, the output must
be matched as well.
LCM
RS
IS = VS/RS
+
VOC
–
Thevenin
Z2
VOC
LCM
RS
+
VOC
–
IS
Z2
Figure 3.25: The
Thevenin equivalent of the
source and LCM circuit of
Figure 3.24
Z2
VOC
RL
Figure 3.26: The equivalent circuit of Figure 3.24 using the Thevenin circuit
found in Figure 3.25
10 In some books reﬂection factor is deﬁned as ρ1= RSz1
RS+z1. We will use this deﬁnition in the next chapter when we discuss
ﬁlters.
152
RF Networks

For the network of Figure 3.24, we can deﬁne the voltage gain as follows:
AV = VL
VS
,
which may be greater than one. We may further deﬁne
Pa
PL
=
VS
j
j2
4RS
VL
j
j2
RL
= 1
2
ﬃﬃﬃﬃﬃ
RL
RS
r
1
AV


2
,
which is always greater or equal to one. Pa = VS
j
j2
4RS is the source available power. Consequently,
the transducer factor is deﬁned as
H sð Þ≜1
2
ﬃﬃﬃﬃﬃ
RL
RS
r
1
AV sð Þ :
Given that the matching network is lossless, the power delivered to its input is always equal to
the power delivered to the load: P1 = PL. On the other hand, P1  Pa. The difference,
Pr = Pa  P1,
is known as the reﬂected power, that is, the amount of power not delivered to the network when
it is not matched. It is easy to show that
Pr =|ρ1|
2Pa,
which can be physically explained knowing that P1 = Pa only when the input is matched, that is
when |ρ1| = 0.
Example: Consider the matching network shown in Figure 3.27 designed to match a load
RL > Rs to the source Rs. The matching circuit is used for impedance downconversion,
and the details will be discussed in Section 3.3.3. For now, we would like to ﬁnd the
available power gain and the reﬂection coefﬁcients.
The LC network Z parameters are
Z11 sð Þ = Ls + 1
Cs
Z12 sð Þ = Z21 sð Þ = 1
Cs
Z22 sð Þ = 1
Cs ,
Continued
RS
VS
+
V1
–
I1
RL
L
C
+
V2
–
I2
Z1
Z2
Lossless Matching
Figure 3.27: LC circuit to match an ampliﬁer
to the source
3.3 Impedance Transformation
153

and the impedances looking into the matching network are
Z1 sð Þ = RL + Ls + RLLCs2
1 + RLCs
Z2 sð Þ =
Rs + Ls
1 + RsCs + LCs2 :
From this, the reﬂection coefﬁcients are found to be
ρ1 sð Þ = Z1  RS
Z1 + RS
= RL  RS + L  RSRLCs
ð
Þs + RLLCs2
RL + RS + L + RSRLCs
ð
Þs + RLLCs2
ρ2 sð Þ = Z2  RL
Z2 + RL
= RS  RL + L  RSRLCs
ð
Þs  RLLCs2
RS + RL + L + RSRLCs
ð
Þs + RLLCs2 :
Clearly, |ρ1(jω)| = |ρ2(jω)|.
Finally, the available power gain is
Ga =
Rs
Re Z2 jω
ð
Þ
½

Z21 jω
ð
Þ
Rs + Z11 jω
ð
Þ


2
=
Rs
Rs
1LCω2
ð
Þ2 + RsCω
ð
Þ2
1
jCω
Rs + jLω +
1
jCω


2
= 1,
as expected.
Although we proved in Section 3.2.4.1 that the available power gain of any LCM network is 1,
the results above is worth some further discussion. To arrive at Ga = 1 in our example, there was
no assumption made on whether the circuit is matched or not. If not matched, only a portion of the
source available power (Pa,IN) reaches the LC circuit, as some (Pr = |ρ1|2Pa,IN) is reﬂected back.
The astute reader may question then how despite this the available gain is still 1. To answer that,
let us consider the Thevenin circuit of the source and the LC network as shown in Figure 3.28.
By deﬁnition, the output available power is
Pa,OUT =
VTH
j
j2
8Re Z2
½
 ,
and the power delivered to the load is
PL = V2
j
j2
2RL
=
1
2RL
RL
RL + Z2
VTH


2
:
RL
VTH
+
V2
–
I2
Z2
Thevenin
Figure 3.28: The Thevenin model of the circuit of Figure 3.27 looking
into the left of the matching network
154
RF Networks

Since the LC circuit is lossless, the power must be equal to the one delivered to it, that is,
PL = P1 = (1  |ρ1|2)Pa,IN.
From this we can write
Pa,OUT =
VTH
j
j2
8Re Z2
½
 =
1  ρ1
j
j2

	
Pa,INRL
8Re Z2
½

RL + Z2
RL


2
:
With some algebraic steps, we arrive at
Pa,OUT = Pa,IN
1  ρ1
j
j2
1  ρ2
j
j2 = Pa,IN,
since |ρ1| =|ρ2| for a lossless circuit. Equivalently,
(1 |ρ1|
2)Pa,IN = (1 |ρ2|
2)Pa,OUT.
While a mismatch at the input leads to less power absorbed by the LC network, and ultimately
reaching to the load, the input and output available powers always track since |ρ1| =|ρ2|.
Example: We shall ﬁnd the values of L and C in the previous example to match the load
to the source.
To do so, Z1 = RS, or ρ1(s) = 0. This leads to
Re Z1
½
 =
RL
1 + RLCω
ð
Þ2 = Rs
Im Z1
½
 = Lω 
RL2Cω
1 + RLCω
ð
Þ2 = 0,
which results in C =
1
RLω
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RL
RS  1
q
, and L = RS
ω
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RL
RS  1
q
. These are frequency dependent,
meaning that the matching works only at one speciﬁc frequency or is narrowband in
general. Also, this type of matching network can only reduce or downconvert the load
impedance. More details to follow in Section 3.3.3.
Our previous deﬁnition of the reﬂection coefﬁcient assumes a real reference impedance (e.g.
ρ1 = Z1RS
Z1 + RS, where RS is real). As we will discuss in Section 3.4, it is also consistent with the
transmission line reﬂection coefﬁcient deﬁnition, as most practical (i.e., lossless or low-loss)
transmission lines have a real characteristic impedance. It is however worthwhile discussing the
situation where the source impedance is complex.
Consider Figure 3.29, where a source with a complex impedance of ZS is attached to a two-
port with an input impedance of Z1.
3.3 Impedance Transformation
155

The average power delivered to the two-port is
P1 = Re 1
2 V1I1∗


= 1
2 Re Z1
½

VS
j
j2
ZS + Z1
j
j2 :
The source available power is
Pa =
Vs
j
j2
8Re Zs
½
 :
So the reﬂected power is
Pr = Pa  P1 =
Vs
j
j2
8Re Zs
½

1  4Re Zs
½
Re Z1
½

ZS + Z1
j
j2
 
!
= Pa
Z1  Zs∗
j
j2
Z1 + Zs
j
j2 :
Consistent with our deﬁnition of the reﬂection coefﬁcient, one may say
ρ1 = Z1  Zs∗
Z1 + ZS
:
This is also consistent with the fact that the source available power is absorbed entirely by the
two-port only if Z1 = Zs
∗.
3.3.2
Wideband Transformers
A transformer may be used to provide wideband impedance transformation. For an ideal
transformer, the iv relation,
v1 tð Þ
v2 tð Þ = n1
n2
,
and
i1 tð Þ
i2 tð Þ =  n2
n1
,
may be exploited for impedance conversion. Shown in Figure 3.30, it is clear that
ZIN jω
ð
Þ =
n1
n2
 	2
ZL jω
ð
Þ.
As we showed in Chapter 1, in a practical transformer, if the coupling factor is close to one,
then the transformer can be represented by the equivalent model shown on the left of
Two-port
Zs
Vs
Z1
+
V1
–
I1
Figure 3.29: Two-port attached to an arbitrary complex
source impedance
156
RF Networks

Figure 3.31. The transformer loss may be also modeled by a parallel resistor at the secondary as
shown on the right side of Figure 3.31.
Thus, a practical transformer can still upconvert or downconvert the impedance depending
on the primary to secondary turn ratios, but the self-inductances of the coils appear as well. If
needed, they may be tuned out as shown in Figure 3.31, but this reduces the bandwidth. The
capacitances that were ignored certainly lead to additional unwanted reactive components.
Example: As a related useful case study, let us consider the circuit of Figure 3.32, known
as a double-tuned circuit, consisting of two coupled identical RLC circuits.
By performing a simple node analysis, we can show that
ZIN = R
2
1
1 + jQ1
ω
ω1
 ω1
ω

 +
1
1 + jQ2
ω
ω2
 ω2
ω


2
664
3
775,
where ω1=2 =
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LC 1k
ð
Þ
p
, Q1/2 = RCω1/2, and k = M
L is the coupling factor. Thus, the circuit
effectively consists of two parallel RLC circuit in series, one slightly high-tuned, and the
Continued
n1 : n2
ZIN
ZL
Figure 3.30: Impedance transformation using an ideal transformer
Ideal
n1 : n2
L2
n1/n2=M/L2
Ideal
n1 : n2
L2
n1/n2=M/L2
Lossless
Lossy
ZL
RL2
Ctune
Figure 3.31: Integrated transformer equivalent model when K 	 1
M
ZIN
R
R
C
C
L
L
|ZIN|
1
2
w
w
w
Figure 3.32: A double-tuned circuit based on coupled inductors
3.3 Impedance Transformation
157

other one slightly low-tuned, depending on the value of k. A plot of the magnitude of ZIN
is also shown in Figure 3.32. For more details, see Problem 4.
Example: We wish to match a resistance of 250Ω modeling the input resistance of an
ampliﬁer to the 50Ω source using the 1-2 transformer of Figure 1.57. The primary had a
simulated inductance of 0.44nH and a Q of 7 at 5.5GHz, and the secondary inductance
was 1.14nH with a Q of 12.5 at 5.5GHz. The coupling factor was found to be about 0.8 at
5.5GHz leading to a mutual inductance of about M = 0.627nH. A simpliﬁed model of the
transformer as developed previously is shown in Figure 3.33. The effective inductance at
primary, L1  M2
L2 = L1 1  k2


, comes out to be around 0.158nH, which we have
ignored. Additionally, the resistive part at primary, which is L1ω0
Q1 = 2:2Ω, contributing
about a tenth of a dB loss, is ignored as well, Finally, RL = 250Ω represents the ampliﬁer
input impedance, and R2 captures the transformer loss.
The transformer ratio, n, is
n = L2
M =
ﬃﬃﬃ
5
p
,
which is suitable to match RL = 250Ω to Rs = 50Ω. The capacitance C2 is a combination
of the transformer parasitic, potentially the ampliﬁer input capacitive part, and enough
additional part to resonate with L2 at 5.5GHz.
Shown in Figure 3.34 is the simulated input reﬂection as well as the available power gain
to the ampliﬁer input. Judging from the reﬂection coefﬁcient, clearly the transformer
provides a good match to the source. The resonance created by C2 makes the matching
somewhat narrow, though still a reﬂection factor of less than –10dB over 1GHz is covered.
To calculate the available gain, we ﬁnd the Thevenin equivalent to the left of the ampliﬁer:
RTH = n2RskR2
VTH = n
R2
n2
Rs + R2
n2
Vs =
nR2
R2 + n2Rs
Vs:
1 : n
Ideal
L2
R2
RL
Rs
Vs
Thevenin
C2
Figure 3.33: Simpliﬁed model of the
transformer along with parasitic
elements
158
RF Networks

Therefore, the available power gain is found to be
Ga =
VTH
j
j2
4RTH
Vs
j
j2
4Rs
=
1
1 + n2Rs
R2
:
Or equivalently the insertion loss is
IL = 1
Ga
= 1 + n2Rs
R2
= 1 + RL
R2
:
This is rather expected, as the source power delivered to the right of the transformer is
basically divided between the ampliﬁer (RL), and the undesirable resistor (R2) modeling
the transformer loss.
Two important conclusions can be drawn: First, with no transformer loss, R2 = ∞and the
insertion loss approaches 0dB, which is rather obvious. Second, and more importantly, for a
given transformer loss, the higher the impedance transformation ratio, the larger the insertion
loss. This is has very important implications in design of matching networks for the low-noise
or power ampliﬁer ampliﬁers.
The resistance R2 is estimated to be
R2 = L2ω0Q2 = 604Ω,
which leads to an insertion loss of about 1.5dB at the resonance frequency of 5.5GHz and
agrees well with the simulation. As mentioned, the loss of primary, which was ignored, adds
about another 0.1–0.2dB to that.
Evidently, the matching network provides some moderate bandpass ﬁltering as well, which is
usually very desirable to attenuate the unwanted signals.
3.3.3
Parallel–Series Circuits
Although a transformer can ideally provide a wideband impedance transformation, practical
integrated transformers are somewhat narrowband due to ﬁnite self-inductance, and parasitic
Frequency, GHz
–15
–10
–5
1
2
3
4
10
0
–20
5
Reflection 
Coefficient
Available Gain
Figure 3.34: Insertion loss and reﬂection
coefﬁcient of the transformer in Chapter 1
matching a 250Ω load
3.3 Impedance Transformation
159

capacitances associated with them. Additionally, achieving a high coupling factor is typically
challenging. Finally, practical integrated transformers tend to be bigger and somewhat more lossy
than the integrated inductors. For narrowband applications, as is the case for many RF standards,
one could use lumped inductors and capacitors to approximate impedance transformation at a
single frequency, and possibly over a reasonable bandwidth around that. A convenient approach to
do so is through parallel to series impedance transformation, as shown in Figure 3.35.
Let us ﬁnd the input impedance of the parallel circuit on the right
ZIN = Rp jXp


Rp + jXp
= Rp
Xp2
Rp2 + Xp2 + jXp
Rp2
Rp2 + Xp2 ,
which is of the form of a resistance in series with a reactance. Since Xp is frequency dependent,
we expect the series resistance and reactance be frequency dependent as well. However, as long
as we are looking at only one frequency or a narrow band, we can represent them by the series
equivalent circuit shown on the left. To satisfy equivalency, we must have
Rs = Rp
Xp2
Rp2 + Xp2
and Xs = Xp
Rp2
Rp2 + Xp2 :
Alternatively, we can express the parallel circuit in terms of the series one:
Rp = Rs2 + Xs2
Rs
and Xp = Rs2 + Xs2
Xs
:
We can also show that the following identity must be met:
RsRp = XsXp.
The series RL circuit that was discussed in Chapter 1 to model the induction loss is a special
case where Rs = r, and Xs = Lω. Since Q = Lω
r , we have
Rp = r 1 + Q2


and
Xp = Lω 1 + 1
Q2


	 Lω,
which we had shown previously in Chapter 1.
The property of series–parallel circuits just shown could be exploited to change the real part
of an ampliﬁer input impedance. If the ampliﬁer real part turns out to be larger than what is
needed for example, then placing a shunt reactance will reduce that to the desirable value, or
vice versa. The remaining reactive part can be always tuned out by placing the proper reactive
component with the opposite polarity as long as we are operating at a speciﬁc frequency or
around a narrow bandwidth.
Xs
Xp
≡ 
Rs
Rp
Down
Up
Figure 3.35: Parallel to series impedance
conversion
160
RF Networks

Example: Consider Figure 3.36, where we wish to match the input impedance of an
ampliﬁer with RIN > Rs, to the source resistance, Rs at a given frequency of ω0.
Since we like to reduce the resistance, we need to insert a parallel reactance, which could
be either an inductor, or a capacitor. We choose to place an inductor with the value of L in
parallel with RIN. Since the equivalent series network will be inductive, we have to naturally
place a capacitor C in series to absorb the inductance. Thus our matching network consists
of a parallel L and a series C, as shown in Figure 3.36. The parallel network consisting of
RIN and L could be converted to a series one, where the new resistance must be equal to the
source resistance Rs, and the series inductance Ls to be tuned out by C. Thus
Rs = RIN
Lω0
ð
Þ2
RIN2 + Lω0
ð
Þ2 ,
which leads to L = RIN
ω0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs
RINRs
q
. For this to work, RIN must be obviously greater than Rs. If
smaller, we should have chosen a series L and a shunt C for instance. The new series
inductance can be also calculated easily:
Ls = L
RIN2
RIN2 + Lω0
ð
Þ2 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs RIN  Rs
ð
Þ
p
ω0
,
which must resonate with C at ω0. Thus
C =
1
Lsω02 =
1
ω0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs RIN  Rs
ð
Þ
p
:
The matching network components are clearly a function of ω0, and thus frequency dependent.
To have a sense of how much the frequency can deviate from ω0, let us calculate the quality
factor of the series RLC circuit:
Q =
1
RsCω0
=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RIN
Rs
 1
r
:
Since as we showed before Q is an indication of the 3dB bandwidth for an RLC circuit, we
have
ω3dB = ω0
Q = ω0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs
RIN  Rs
r
:
RIN
Amplifier
Matching Network
C
L
C
Rs
Ls
+
vIN
–
Figure 3.36: An LC circuit to match RIN > 50Ω to 50Ω
3.3 Impedance Transformation
161

As a rule of thumb, we can say that the circuit provides a reasonable match as long as we are
within the bandwidth given above. An important conclusion as a direct outcome of the equation
above is an upper limit for how big of an input impedance can be realistically matched. The
higher the RIN, the larger the Q, and the narrower the matching network becomes. Also, a larger
RIN implies a larger inductance, which could be problematic as the frequency increases.
Furthermore, we have assumed that the inductance is lossless. In practice, it isn’t, and a larger
RIN would result in more loss for a given inductor quality factor.
Example: For RIN = 250Ω, we obtain L = 10nH and C = 0.8pF to match 50Ω at 2GHz.
The corresponding Q is equal to 2. Using the same matching network but operating at
2.5GHz (the edge of the 3dB bandwidth), the impedance obtained is 70 + j33Ω, which
may be marginally acceptable for many applications.
If the input impedance of the ampliﬁer had some reactive component in addition to RIN, then
all we had to do was to modify the shunt L to absorb that reactance. The remaining steps would
have been the same.
The matching network of Figure 3.36 has several other features beyond the impedance
transformation. First, even though a lossless network as the one discussed here does not impact
the power, it is indeed capable of providing either voltage or current gain. Let us ﬁrst ﬁnd the
voltage at the input of the ampliﬁer across the resistor RIN,
vIN
vs
= 
RIN
RINRs
ω
ω0
 	2
1  RIN + Rs
RINRs
ω
ω0
 	2
+ 2j
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs
RINRs
q
ω
ω0
,
which is a highpass function, and whose magnitude peaks to 1
2
ﬃﬃﬃﬃﬃ
RIN
Rs
q
at ω = ω0, the center
frequency where the matching network components were originally chosen. Thus with RIN >
Rs , the available voltage gain from the source to the ampliﬁer input is
ﬃﬃﬃﬃﬃ
RIN
Rs
q
	 Q > 1. The
higher the Q, the narrower the response, and the higher the voltage gain. This is important, as it
helps reduce the ampliﬁer power consumption for a given input referred noise allowed.
However, the presence of the voltage gain from the source to the input implies that the
unwanted signals will be also ampliﬁed along with the desired input, making the design more
susceptible to nonlinearity and distortion.
Shown in Figure 3.37 is the available voltage gain from the source to the input versus the
frequency for RIN = 250Ω and f0 = 2GHz, for which the components were calculated before.
For frequencies lower than f0 and outside the network bandwidth, the matching circuit acts like
a ﬁlter, thus attenuating the unwanted signals that fall outside the bandwidth. The presence of a
series capacitor and a shunt inductor makes the matching network highpass. Thus, the attenu-
ation at frequencies above the center is not much as the transfer function ﬂattens out to
2RIN
RIN + Rs
(the extra factor of two is to account for available voltage gain). If needed, however, one could
choose other types of matching components that behave as lowpass or bandpass.
162
RF Networks

Example: We wish to ﬁnd the appropriate biconjugate matching network for the example
of Section 3.2.6. The complete schematic of the ampliﬁer along with the matching
networks details are shown in Figure 3.38. Resistors RB1 and RB2 are for biasing purposes,
and are large enough not to affect the transistor Y parameters. Similarly, CE is assumed to
create a short at the frequency of interest (200MHz).
We had already found
Ys,opt = 37:6  j52:7
ð
Þ  103
YL,opt = 0:47  j2:41
ð
Þ  103:
Assuming Rs = 50Ω for the source, at the input we insert a shunt inductance (L1) to reduce
the source resistance to the desired value of 9Ω (note that Zs,opt = 9 + j12.6Ω). The
resultant reactive part is too inductive, and capacitor C1 is used to reduce to the required
reactance of 12.6Ω. From the previous example,
XL1 = Rs
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs,opt
Rs  Rs,opt
s
= 23:4Ω,
which leads to L1 = 18.6nH. The corresponding reactive part will be
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs,opt Rs  Rs,opt


q
=
19:2Ω. Since what is required is 12.6Ω, we ﬁnd
C1 =
1
2π  200  106  19:2  12:6
ð
Þ = 120pF:
Note that if the required Xs,opt were greater than 19.2Ω, we could not have achieved the
required matching with a series capacitance, and instead we had to use a series inductance
along with the original shunt inductance (L1).
Continued
0.0
0.5
1.0
1.5
2.0
2.5
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 8.5 9 9.510
Available Voltage Gain
Frequency, GHz
Figure 3.37: Transfer function from the
source to the input for the matching
network of Figure 3.36
3.3 Impedance Transformation
163

The input matching network effective quality factor is
Q = Bs,opt
2Gs,opt

 = 0:7,
leading to a bandwidth of about 280MHz at the input.
For the output matching, we choose a series capacitance C2 to raise the load resistance
(which is 50Ω) to the desired value
1
0:47103S = 2:13kΩ (note that ZL,opt consists of
2.13kΩ resistance in parallel with a 415Ω reactance). The inductance L2 then creates
the required reactive part. The capacitance will be given by
C1 =
1
ω
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RL RL,opt  RL


q
=
1
2π  200  106  323 = 2:45pF:
The reader can verify that L2 = 144nH. The output quality factor is found to be 2.56, and
the effective bandwidth at the output would be 78MHz.
Vs
Rs=50W
L1
C1
RB1
RB2
RE
CE
VCC
L2
C2
RL=50W
Ys,opt
YL,opt
L1
C1
Complete Ampliﬁer Schemac
Input Matching Details
Rs=50W
Ys,opt
Rs,opt < Rs
C1
Xs,opt
L2
C2
Output Matching Details
RL=50W
YL,opt
RL,opt > RL
BL,opt
L2
Figure 3.38: 2N3783 ampliﬁer with source and load matching circuits
164
RF Networks

3.3.4
Narrowband Transformers
There is yet a third common method of transforming impedances that approximates an ideal
transformer with only capacitors or inductors, shown in Figure 3.39. Consequently, like the
previous circuit it is inherently narrowband. Let us ﬁnd the impedance looking into the circuit
shown on the left, ignoring the inductance for the moment.
We have
YIN = jC1ω 1 + jRC2ω
ð
Þ
1 + jR C1 + C2
ð
Þω :
Assuming the capacitive loss due the parallel resistor R is small, or equivalently |RC1/2ω| 
 1 at
the frequency of interest, then we can write
YIN 	
1
R C1 + C2
ð
Þω
ð
Þ2 jC1ω 1 + jRC2ω
ð
Þ 1  jR C1 + C2
ð
Þω
ð
Þ,
which simpliﬁes to
YIN 	
1
R 1 + C2
C1

	2 + j C1C2
C1 + C2
ω 1 +
1
C2 C1 + C2
ð
Þ Rω
ð
Þ2
"
#
:
Deﬁning n = 1 + C2
C1, and C =
C1C2
C1 + C2, and ignoring the last term assuming the loss is moderate
or small, we have
YIN 	 1
n2R + j C1C2
C1 + C2
ω,
and thus it simpliﬁes to the circuit shown on the right side, consisting of an ideal transformer
with a coil ratio of n and a net shunt C. The inductor may be used to tune out the equivalent
capacitance C, and provide a resistive component.
The transformer may have been realized by two series inductances L1 and L2, a shunt
capacitance to provide the resonance [6]. However, since it requires two inductors, it is not
as common as the one already shown. The arrangement shown in Figure 3.39 is commonly used
in Colpitts oscillators (Chapter 9).11
Ideal
n: 1
R
R
C1
C2
C
ZIN
Figure 3.39: Narrowband transformer-
like matching circuit
11 Edwin Colpitts (1872–1949) was an American engineer.
3.3 Impedance Transformation
165

Example: We shall show that the two circuits below (Figure 3.40) are equivalent, where
the circuit on the left illustrates an inductive narrowband transformer.
The steps are self-explanatory, and shown in Figure 3.41 (see also Problems 2 and 3).
If RL 
 (L1kL2)ω, then the ideal transformer upconverts RL to the proper value with the
transformation ratio of n2 = 1 + L1
L2

	2
. L1 + L2 at the input must resonate with C.
3.4
LOSSLESS TRANSMISSION LINES
..............................................................................................
In addition to lumped LC elements, transmission lines may be incorporated to provide
matching. In Chapter 1 we showed that in a lossless transmission line the general solution
appears to be of the form
v z; t
ð
Þ = f 1 t  z
ν

	
+ f 2 t + z
ν

	
= v + + v,
where f1 and f2 are arbitrary functions, signifying the forward and backward propagations. Now
suppose we are interested only in the sinusoidal steady state solution, where a signal with a
speciﬁc frequency of f = ω/2π is of our interest. We expect the solution to be sinusoidal as well,
that is,
vb/f(z, t) =|V0| cos(ωt  βz + ϕ),
RL
L1
C
L2
Ideal
1+L1/L2:1
L1+L2
C
L1||L2
RL
Narrowband Transformer
Equivalent Circuit w/ Ideal Transformer
Figure 3.40: Inductive narrowband transformer and its equivalent circuit with an ideal transformer
L1
L2
L1+L2
L2
M=L2
Ideal
1+L1/L2:1
L1||L2
L1+L2
Figure 3.41: Steps to simplify the narrowband transformer of Figure 3.40
166
RF Networks

where β = ω
ν is the phase constant (in rad/m), and ν is the phase velocity (in m/s). Same as
before, we expect the + to show the backward propagation, whereas the – to correspond to the
forward propagation of the signal, denoted by the indexes b and f, respectively. Choosing ϕ = 0
for now, if we were to ﬁx the time at t = 0, the signal becomes
vb/f(z, t) =|V0| cos(βz).
Evidently, β signiﬁes the spatial frequency. Deﬁning wavelength λ = 2π
β = ν
f, we note that the
function above repeats every integer increment of λ. In fact, for the forward propagating
waveform, setting the condition
ωt  βz = ω(t  z/ν) = 2πm,
the waveform at a given point of time is kept constant. With increasing time, z must also
increase in the positive direction, and at a rate of ν. A similar argument can be made for the
backward wave, although z in this case needs to decrease.
For any sinusoidal steady state condition we could use phasor to describe the forward and
backward signals. For the lossless transmission line, the original wave equation derived in
Chapter 1,
∂2v
∂z2 = LC ∂2v
∂t2 ,
then becomes
∂2V
∂z2 =  ω2LCV,
in phasor form in the case of steady state sinusoidal, where V denotes the complex phasor
voltage, and has a solution in the form of
V(z) = V0
+ejβz + V0
e+jβz,
consistent with our previous results. The time dependence is dropped, as we know the waves
will always be in the form of a cosine with a frequency of ω. Note that the line is assumed to be
lossless. If not, jβ must be replaced by γ = α + jβ, where α captures the loss of the line [3], [7].
Similarly,
I(z) = I0
+ejβz + I0
e+jβz.
We shall use the above two general equations for the voltage and current when dealing with the
transmission lines. By virtue of the wave differential equation, the two equations below always
hold as well:
I0
+ = V0 +
Z0
I0
 =  V0
Z0
,
where Z0 is the line characteristic impedance.
3.4 Lossless Transmission Lines
167

3.4.1
Terminated Transmission Lines
Any transmission line is inevitably terminated to some load. The need to satisfy all voltages and
currents boundary conditions at discontinuities, e.g., a load, results in reﬂected waves. The
basic reﬂection problem is shown in Figure 3.42.
For convenience, let us assume that the load is located at z = 0, thus the rest of the line will be
at z < 0. Suppose we have an incident voltage in the phasor format:
Vi(z) = V0
+ejβz.
We expect when the wave reaches the load, it creates a reﬂected wave propagating backward:
Vr(z) = V0
e+jβz.
At the load where z = 0, we have
VL = V0
+ + V0
,
where VL is the load voltage. The load current is
IL = 1
Z0
V0
+  V0

ð
Þ = VL
ZL
= V0 + + V0
ZL
:
We can solve for V0
+ and V0
, and more importantly, their ratio, known as the reﬂection
coefﬁcient:
Γ = V0
V0 + = ZL  Z0
ZL + Z0
:
The reﬂection coefﬁcient is a complex number in general, and has a similar format compared to
the one derived in Section 3.3.1 for lumped circuits. Knowing the incident and reﬂected
voltages and currents, we can evaluate the power associated with each as well. We can show
that the ratio of reﬂected to incident power is
Pr
Pi
= ΓΓ∗= Γ
j j2,
again consistent with our derivation earlier.
3.4.2
Voltage Standing Wave Ratio
It is instructive to monitor the signal in a terminated transmission line at different points. In
practice, this may be accomplished by inserting a voltage probe in a slotted transmission line to
Z0
ZL = RL +jXL
Z = 0
Vi
Vr
Figure 3.42: Voltage reﬂected from a complex load
168
RF Networks

measure the magnitude of the voltage at a desired point. We have already expressed the voltage
phasor in a transmission line in the general form of
V(z) = V0
+ejβz + V0
e+jβz = V0ejβz + ΓV0e+jβz,
where Γ = |Γ|ejϕ is the reﬂection coefﬁcient we just obtained as function of the load impedance.
After a few algebraic steps, the equation above can be expanded, and expressed as follows:
V(z) = V0(1  |Γ|)ejβz + 2V0|Γ|ejϕ/2 cos(βz + ϕ/2).
Converting from phasor format above to a time domain signal,
v(z, t) = Re [V(z)ejωt] = V0(1  |Γ|) cos(ωt  βz) + 2V0|Γ| cos(βz + ϕ/2) cos(ωt + ϕ/2).
The ﬁrst term has the form of cos(ωt  βz), and we expect it to propagate in the forward z
direction. Hence, we call it the traveling wave, with an amplitude of (1  |Γ|)V0. On the other
hand, the second term is known as standing wave, whose amplitude is 2V0|Γ|. As we move
along the line in the z direction, we expect the two terms to add or subtract, and hence result in
different probe readings. Evidently, the maximum amplitude observed in the line is (1 + |Γ|)V0,
when the standing and traveling waves add constructively. Finding the minimum is not as
obvious. Let us ﬁrst make the observation that since V(z) = V0ejβz + V0|Γ|ejϕe+jβz, the minimum
occurs when the two terms have 180 of phase shift, that is, when z =  1
2β ϕ + 2n + 1
ð
Þπ
ð
Þ. In
that case the minimum amplitude would be (1  |Γ|)V0. Although we already calculated the
maximum amplitude, through a similar deduction we can ﬁnd the location that it occurs to be
z =  1
2β ϕ + 2nπ
ð
Þ. The results are depicted in Figure 3.43.
The distance between each consecutive peak is λ/2, whereas the distance between a peak and
the neighboring valley is λ/4. The ratio of the maximum to minimum voltage observed in the
line is called the voltage standing wave ratio, and is known as VSWR in short. From our
analysis then we have
VSWR = 1 + Γ
j j
1  Γ
j j :
If the load is matched, there is no reﬂection and VSWR is one. This implies that there is no
standing wave in the line. On the other extreme, if the load is a short or an open circuit, |Γ| = 1,
and VSWR is inﬁnite.
l
Z0
Z = 0
ZL
z
|VS(z)|
(1+| |)V0
(1-| |)V0
/2
G
G
Figure 3.43: Magnitude of the voltage in the
transmission line
3.4 Lossless Transmission Lines
169

3.4.3
Transmission Line Input Impedance
Let us consider Figure 3.44, which shows a transmission line of ﬁnite length of l. We would like
to ﬁnd the impedance at a given point of the line knowing that it is terminated at z = 0 with a
complex impedance of ZL.
This can be done simply by ﬁnding the voltage and current phasors in the line, that is,
V zð Þ = V0
+ ejβz + V0
e + jβz
I zð Þ = I0
+ ejβz + I0
e + jβz = 1
Z0
V0
+ ejβz  V0
e + jβz


:
Considering that V0
 = ΓV0
+, we have the impedance at an arbitrary point:
Z zð Þ = Z0
ejβz + Γe + jβz
ejβz  Γe + jβz = Z0
ZL cos βz
ð
Þ  jZ0 sin βz
ð
Þ
Z0 cos βz
ð
Þ  jZL sin βz
ð
Þ :
As a sanity check, we can see that at z = 0, Z(0) = ZL. At the source side of the line, where
z = –l, the input impedance looking into the line is
ZIN = Z0
ZL cos βl
ð Þ + jZ0 sin βl
ð Þ
Z0 cos βl
ð Þ + jZL sin βl
ð Þ :
There are interesting properties associated with the equation above. For instance, if the line
length is equal to half the wavelength or any integer multiple of that, the input impedance is
always equal to the load impedance. If the length is a quarter wavelength, however, ZIN = Z02
ZL
instead. Hence, a short appears as an open circuit on the other end, and vice versa.
Example: Consider the lossless transmission line in Figure 3.45 with Z0 = 50Ω, termin-
ated to two equal loads of RL = 50Ω. The source is a 2GHz sinewave with a
Z0
Z = 0
ZL
RS
VS
Z = –l
Figure 3.44: Finite-length transmission line
Z0
RS
VS
RL
RL
l = 12cm
Figure 3.45: A 50Ω transmission
line connected to two equal
50Ω loads
170
RF Networks

magnitude of 1V RMS, and impedance of Rs = 50Ω. Assuming ν = 3  108m/s, then
λ = 15cm, and βl = 2π l
λ = 1:6π.
Since the load impedance is effectively 25Ω, the reﬂection coefﬁcient is Γ =  1
3, and
the VSWR is 2. The line input impedance is
ZIN = 50 25 cos 1:6π
ð
Þ + j50 sin 1:6π
ð
Þ
50 cos 1:6π
ð
Þ + j25 sin 1:6π
ð
Þ = 85ej24Ω,
which is capacitive. Physically, this means that the line stores more energy in its electric
ﬁeld than its magnetic ﬁeld. The current going into the line is
Vs
ZIN + Rs = 7:6ej15mA, and
the power delivered to the line is Re ZIN
½

Vs
ZIN + Rs


2
= 4:4mW. Since the line is lossless, this
power is split between the two load resistors, so each one absorbs 2.2mW, corresponding
to a load voltage of 1
3 V.
3.4.4
Transmission Lines Transient Response
So far, we have mostly paid attention to the sinusoidal steady state behavior of the transmission
lines, which is of course of great value. However, it is often constructive to study the transient
behavior of the forward and backward signals in the transmission lines as well, as it allows us to
study how the line could be used to store and release energy.
Consider the transmission line of Figure 3.46 of a length l. As a simple case study ﬁrst, let us
assume the source impedance is zero (ideal voltage source), and that the load is matched to the
line characteristic impedance Z0.
Now assuming the input is a step function of value V0 as shown in Figure 3.47, the incident
voltage at the input of the line is v+ = V0 right after the step signal is enforced. This voltage
propagates in the line, and reaches the load after l
ν seconds, at which point is entirely absorbed
by the matched load, as shown in the ﬁgure. Obviously if the length of the line is short, which is
to say if the circuit is lumped, this delay is negligible, and we see the output rising to V0
immediately.
Z0
Rs
RL
vs(t)
+
vL(t)
–
l
v+
v–
Figure 3.46: A lossless
transmission line attached to
arbitrary source and load
impedances
3.4 Lossless Transmission Lines
171

Next, let us assume the source and load are two arbitrary impedances. Upon applying the step
voltage, the forward voltage at the line input is
v1 += Z0i += Z0
V0  v1 +
Rs
,
or v1 + =
Z0
Z0 + Rs V0, which is a simple voltage division. Once reaching the load after l
ν seconds, a
reﬂected voltage (and current) of v1
 = v1
+ΓL is created, where ΓL = RLZ0
RL + Z0 is the load reﬂection
coefﬁcient. Now this reﬂected signal makes it to the source side at t = 2 l
ν, at which point a new
forward voltage of v2
+ = v1
+ΓLΓs is created, where Γs = RsZ0
Rs + Z0 is the source reﬂection coefﬁ-
cient. Voltage v1
+ exists everywhere ahead of the v1
 wave until it reaches the battery,
whereupon the entire line now is charged to voltage v1
+ + v1
. Now, the new forward voltage
v1
+ΓLΓs propagates to the load, and the process repeats. Shown in Figure 3.48 is the graphical
representation of the forward and backward voltages, as well as the voltage in the line at the
halfway point z = l
2.
The voltage gradually builds up to a ﬁnal values of
v1
+ + v1
 + v2
+ + v2
 +    =
Z0
Z0 + Rs
V0 1 + ΓL + ΓLΓs + ΓL
2Γs +   


:
Replacing ΓL and Γs with their values expressed in terms of source and load impedances, and
considering that both are less than one, the inﬁnite series converges to
RL
RL + Rs V0 at steady state
as expected.
vs(t)
t
t
vL(t)
l/v
V0
V0
Figure 3.47: Step response of the transmission line
of Figure 3.46 with matched termination
vs(t)
t
t
vL(t)
l/2v
z
t
0
l/2
l
2l/v
4l/v
l/v
6l/v
3l/v
5l/v
RLV0/(Rs+RL)
V0
v1
+
ΓLv1
+
ΓsΓLv1
+
ΓsΓL
2v1
+
3l/2v
5l/2v
7l/2v
v1
+
v1
+ + v1
–
v1
+ + v1
–+ v2
+ 
Figure 3.48: Transient response of the transmission line of Figure 3.46 with unmatched load and source
172
RF Networks

3.5
LOW-LOSS TRANSMISSION LINES
..............................................................................................
Although we dedicated most of our transmission line analysis to the lossless propagation, we
mentioned that in the general case of a lossy transmission line, the voltage phasor is
V(z) = V0
+eγz + V0
e+γz,
where γ = α + jβ, and parameter α captures the loss of the line [3], [4], [7]. These results can be
obtained by modifying the transmission line lumped equivalent circuit as shown in Figure 3.49,
where R and G signify the transmission line losses and, as with L and C, are per unit length. The
new differential equation describing the line is obtained as
∂2v
∂z2 = LC ∂2v
∂t2 + LG + RC
ð
Þ ∂v
∂t + RGv,
which simpliﬁes to our original differential equation if R = G = 0. Moreover, in steady-state
conditions, the phasor solution is of the form V(z) = V0
+eγz + V0
e+γz, as stated before, and γ is
easily shown to be [7]
γ = α + jβ =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
R + jLω
ð
Þ G + jCω
ð
Þ
p
:
For low-loss propagation, α and β are obtained as follows:
α = 1
2
R
Z0
+ GZ0


β = ω
ﬃﬃﬃﬃﬃﬃ
LC
p
1 + 1
8
G
Cω  R
Lω

2
 
!
,
where Z0 =
ﬃﬃﬃ
L
C
q
is the characteristic impedance. We can further show that when the waves
propagate in such a low-loss line, the power at a given point in the line decays as P(z) =
P0e2αz, very much like our RLC analysis performed in Chapter 1.
Example: A better model for a practical transmission line segment is shown in
Figure 3.50, where there is no assumption of an ideal ground (or return) plane. Note that
the return path is not assumed to be necessarily identical to the other path.
Continued
z
Ldz
Cdz
+
v(z,t)
–
v(z,t)+(∂v/∂z)dz
i(z,t)+(∂i/∂z)dz
+
–
i(z,t)
Rdz
Gdz
Figure 3.49: Low-loss transmission line lumped model
3.5 Low-Loss Transmission Lines
173

The reader can show that the new line equation is
∂2v
∂z2 = LeqC ∂2v
∂t2 + LeqG + ReqC

 ∂v
∂t + ReqGv,
where Leq = L1 + L2 + 2M, and Req = R1 + R2. So the overall behavior of the line will be
similar to the one described by the simpler model of Figure 3.49.
3.5.1
Reasons for Adopting 50Ω
Historically, most transmission lines are designed to be 50Ω or 75Ω. As a very constructive
case study, we shall discuss the reasons as to why this common practice has been adopted. Let
us consider the coaxial transmission line shown below (Figure 3.51).
Upon our analysis in Chapter 1, we obtained C = 2πϵ
lnb
a, and L = μ0
2π ln b
a, leading to
Z0 =
ﬃﬃﬃﬃ
μ0
ϵ
q
ln b
a = 60ﬃﬃﬃ
ϵr
p ln b
a. Moreover, we showed that D = ρSa
r ar, which may be expressed in
terms of the voltage as D = ϵV0
lnb
a
ar
r . We can further ﬁnd the values of G and R for the low-loss
coaxial line (Figure 3.49). The dielectric leakage, G, is found very much like the capacitance,
all needs to be done is to note that the current density J = σE, where σ is the dielectric
conductivity. Consequently, this leads to a very similar expression (see Chapter 1 problem sets
for the proof):
G = I
V = σ
Ð
SEdS

Ð
E:dL = 2πσ
ln b
a
:
It is reasonable to assume that the dielectric leakage, say in the case of an air coaxial line, is
very small, as conductivity is small, and thus G 	 0. To ﬁnd the conductor loss, R, we assume
Cdz
Gdz
L1dz
Mdz
R1dz
+
v(z,t)
–
i(z,t)
+
v(z,t)+(∂v/∂z)dz
–
i(z,t)+(∂i/∂z)dz
i(z,t)
L2dz
R2dz
Figure 3.50: A more proper model of a
segment of a lossy transmission line
a
b
r
Dielectric
e
Figure 3.51: Cross section of a lossy transmission line
174
RF Networks

that the frequency is high enough that the current is ﬂowing only into the skin depth, δ.
Moreover, let us assume that the current is distributed uniformly, and that the conductor has
a conductivity of σc. Thus, given that the area that the current ﬂows is roughly 2πδα for the
inner conductor, and 2πδb for the outer conductor, we have
R 	
1
2πδσc
1
a + 1
b


,
where we have added the resistance of the inner and outer conductors, as they appear effectively
in series. For an air transmission line, ignoring G, the loss factor is then
α =
1
240πδσc
1
a + 1
b


ln b
a
:
Now by taking the derivative of α versus b
a, the loss factor is minimized if b
a = 3:6, leading to a
characteristic impedance of 77Ω.
Moreover, since
E = V0
ln b
a
ar
r ,
the strongest value of the electric ﬁeld occurs at r = a, leading to Emax = V0
alnb
a . Thus the power
delivered to the load is
PL = V02
2Z0
= Emax2
120 a2ln b
a :
For a given acceptable maximum ﬁled, Emax, the power may be maximized if b
a =
ﬃﬃﬃe
p , leading
to Z0 = 30Ω.
Historically, the best coaxial cable impedances in high-power and low-attenuation applica-
tions were experimentally determined at Bell Laboratories in 1929 to be 30Ω, and 77Ω,
respectively, agreeing with our analysis above. It appears that a compromise between the two
conditions, that is maximum power delivery (for a certain maximum ﬁeld), and the minimum
power dissipated, sets the characteristic impedance to about 50Ω, as commonly used. On the
other hand, the approximate impedance required to match a center-fed dipole antenna in free
space is 73Ω, so 75Ω coax was commonly used for connecting shortwave antennas to receivers.
These typically involve such low levels of RF power that power-handling and high-voltage
breakdown characteristics are unimportant when compared to attenuation.12
There is obviously no need to consider a 50Ω interface in modern radios, depending on the
chip size and frequency. However, the majority of external components such as the RF SAW
ﬁlters or the antennas are traditionally designed to be 50Ω. As mentioned at the beginning, to
interface such elements it is often desirable to present a well-deﬁned and close to 50Ω
impedance at the boundaries of RF IC and the outside world. On the other hand, in an ideal
12 The interested reader may refer to the following online articles for more details: “Why 50 Ohms?,” Microwaves 101,
January 13, 2009; “Coax Power Handling,” Microwaves 101, September 14, 2008.
3.5 Low-Loss Transmission Lines
175

world, with a custom designed radio, there is no need to set the characteristic impedance to
50Ω. This number is arbitrary and is simply a legacy design parameter.
3.6
RECEIVE–TRANSMIT ANTENNAS AS TWO-PORT CIRCUITS
..............................................................................................
Throughout our discussion of antennas in Chapter 1, we treated them as single transmitting
devices, producing electromagnetic waves propagating in the air. In this section, we turn to
other fundamental purpose of an antenna, which is a means to detect (or receive) radiation
originated from a distant source, namely a transmit antenna. We will approach this as a two-port
network, comprising a receive and a transmit antenna, as well as their supporting circuitry.
Shown in Figure 3.52 is a simple example of a receive–transmit antenna arrangement, where
the two coupled antennas establish a linear two-port network.
The voltage and the current of the ﬁrst antenna affect the voltage and current of the second
one, and vice versa. Quantifying this coupling through trans-impedance parameters (Z12 and
Z21), we may write
V1 = Z11I1 + Z12I2
V2 = Z21I1 + Z22I2:
The impedances Z11 and Z22 are each antenna input impedance when the other one is isolated,
or equivalently, located very far away. In practice, they consist of the radiation resistance as
shown in Chapter 1, any associated ohmic loss, and possibly some reactance depending on the
antenna physical structure, and design parameters. On the other hand, trans-impedances Z12 and
Z21 depend on the distance and relative position of the two antenna. Regardless of the absolute
values of trans-impedances, given the reciprocity, we can always say
Z12 = Z21.
One important conclusion drawn from the above is that an antenna’s radiation and reception
patterns are identical. In other words, the extent to which the receiving antenna accepts power
is determined by its radiation pattern.
Now consider Figure 3.53, where the second antenna is terminated by some load impedance
ZL. This could model the receiver input impedance for instance. The two-port equivalent is also
depicted on the bottom of the ﬁgure. An important but realistic assumption here is that the
antennas are far enough that only the forward coupling is appreciable, that is, Z12I2 	 0.
Consequently, we assume the induced current I2 by the ﬁrst antenna is much less than I1. So
the current induced back in the ﬁrst antenna as a result of I2 is negligible compared to I1.
+
V1
–
Z21
Antenna 1
I1
+
V2
–
Z12
Antenna 2
I2
Figure 3.52: A pair of receive and transmit
antennas coupled to each other
176
RF Networks

We can then write
IL =  I2 =
Z21I1
Z22 + ZL
:
The average power dissipated in the load is
PL = 1
2 Re VLIL
∗
½
 = 1
2 RL I1
j j2
Z21
Z22 + ZL


2
,
under maximum power transfer condition, ZL = Z22
∗, and thus
PL = I1
j j2 Z21
j
j2
8R22
,
where R22 = Re [Z22], and is equal to the receiving antenna radiation resistance if ohmic losses
ignored. The average power transmitted by the ﬁrst antenna is
Pr = 1
2 R11 I1
j j2,
where R11 is the radiation resistance of the transmitting antenna. Consequently,
PL
Pr
=
Z21
j
j2
4R11R22
,
whereas R11 and R22 are equal to each antenna’s radiation resistance (if resistive losses are
negligible), the trans-impedance Z21 (or Z12) is a function of each antenna characteristics, as
well as their relative spacing and orientation.
3.6.1
Antenna Effective Area
To have a better understanding of Z21, consider Figure 3.54 as an example of a pair of dipole
antennas separated by a radial distance r, and a relative orientation angle of .
A common and convenient way of expressing the received power in an antenna is through its
effective area, expressed in m2. In Chapter 1 we showed that the power density radiated by an
antenna is given by
I1
Z22
Z11
ZL
+
V2
–
I2
V1
ZL
Z21I1
V1
I1
IL=–I2
Figure 3.53: Loaded coupled antennas with
the equivalent circuit model
3.6 Receive–Transmit Antennas as Two-Port Circuits
177

P1 r; 1; φ1
ð
Þ = Pr
4πr2 D1 1; φ1
ð
Þ,
where D1(1, φ1) is the directivity (of the ﬁrst antenna), Pr is the average power radiated, and
P1 r; 1; φ1
ð
Þ is the antenna average power density. The latter quantity, that is, P1 r; 1; φ1
ð
Þ,
produced by the ﬁrst antenna, induces a certain power on the receiver antenna, whose value is a
function of the antennas positioning and spacing. As such, we deﬁne the effective area of the
second (receiving antenna) as
PL = P1 r; 1; φ1
ð
Þ  A2 2; φ2
ð
Þ,
where PL is the power delivered to the load of the second antenna, and A2(2, φ2) is deﬁned as
the second antenna effective area. Note the subscript 1 (i.e., 1, φ1) signiﬁes the power density
created by the ﬁrst antenna (P1 r; 1; φ1
ð
Þ), which is a function of its positing, whereas the
subscript 2 (i.e., 2, φ2) denotes the relative positioning of the second antenna. Combining the
two equations above, we can write
PL
Pr
= D1 1; φ1
ð
ÞA2 2; φ2
ð
Þ
4πr2
:
However, since we showed in the previous section that PL
Pr =
Z21
j
j2
4R11R22, then
Z21
j
j2 = R11R22D1 1; φ1
ð
ÞA2 2; φ2
ð
Þ
πr2
:
As expected, Z21 depends not only on the individual characteristics of each antenna (R11 and
R22), but also on the spacing, and the relative positioning of the two, speciﬁcally the directivity
of the transmitting antenna, as well as the effective area of the receiving antenna.
We next note that if the roles of the antennas are reversed, that is, the second antenna
transmits to the ﬁrst, we must have
Z12
j
j2 = R11R22D2 2; φ2
ð
ÞA1 1; φ1
ð
Þ
πr2
:
From reciprocity it follows
D1 1; φ1
ð
Þ
A1 1; φ1
ð
Þ = D2 2; φ2
ð
Þ
A2 2; φ2
ð
Þ :
That is, the ratio of the directivity to effective area of any antenna is a constant.
1
2
r
E1
q
q
a
q
Figure 3.54: A pair of receive–transmit antenna with some
arbitrary orientation
178
RF Networks

3.6.2
Friis Transmission Formula
As we already established that the ratio D 1;φ1
ð
Þ
A 1;φ1
ð
Þ is a constant, one may attempt to calculate it for a
known simple antenna, for instance, the Hertzian dipole. To do so, consider again Figure 3.54,
showing a pair of Hertzian dipoles. We showed in Chapter 1 that the electric ﬁeld created by the
ﬁrst antenna at far ﬁeld is
E1 r; ; φ
ð
Þ = jkη I0l sin 
4πr
ejkr = ηH1φ:
Note that in a short dipole, given the symmetry the ﬁelds are not a function of φ. Consequently,
the electric ﬁeld of the transmitting antenna, when projected on the receiving antenna will be
E1 cos α, where α = 90 2 as shown in the ﬁgure. Thus, the voltage induced on the second
antenna given the electric ﬁeld of the ﬁrst antenna is
V2 = (E1 cos α)l = E1l sin 2.
From this one can calculate the power delivered to the second antenna under the matched load
condition, and the resultant effective area of
A2 2; φ2
ð
Þ = 3
8π λ2 sin22:
Since the directivity of a short dipole was shown to be
D2 2; φ2
ð
Þ = 3
2 sin22,
we conclude then
D ; φ
ð
Þ
A ; φ
ð
Þ = 4π
λ2
for any antenna.
Interestingly, the directivity of an antenna, which is a transmit characteristic, is related to its
effective area, which is a receive characteristic by 4π
λ2.
Using the above relation, we may further write
PL
Pr
= A1 1; φ1
ð
ÞA2 2; φ2
ð
Þ
λ2r2
=
λ
4πr

2
A1 1; φ1
ð
ÞA2 2; φ2
ð
Þ,
which is known as the Friis transmission formula. It simply suggests that the ratio of the power
delivered to the receive antenna to the power radiated from the transmit antenna is directly
proportional to the product of their directivity, whereas inversely proportional to the square of
the distance between the two antennas.
3.7
SMITH CHART
..............................................................................................
Transmission line problems often require manipulations with complex numbers. The work
involved could be greatly reduced without impacting accuracy much by using graphical
3.7 Smith Chart
179

methods, perhaps the most common one being the Smith chart [8]. The basic principle upon
which the chart is constructed is the reﬂection coefﬁcient equation
Γ = ZL  Z0
ZL + Z0
:
Since Γ is a complex number, it may expressed as Γ =|Γ|ejϕ = Γr + jΓi. In addition, as |Γ|  1,
for any ZL, the information always falls inside a unity circle depicting Γ in the complex plane. It
is customary to normalize the load impedance to the characteristics impedance of the line, and
express that as a complex number as follows:
zL = ZL
Z0
= r + jx:
Consequently,
Γ = zL  1
zL + 1 :
Alternatively, if we were to deﬁne the normalized admittance yL = YL
Y0 = Z0YL, where YL = 1
ZL,
then the reﬂection coefﬁcient may be expressed as
Γ =  yL  1
yL + 1 :
This indicates that using the normalized admittance instead leads to the same magnitude of the
reﬂection coefﬁcient, and a 180 shift for the phase. We shall use this outcome to interchange-
ably work with both admittances and impedances on the chart, whichever more convenient.
Clearly, yL = 1
zL.
Using normalized impedance, we have
Γ = zL  1
zL + 1 = r + jx  1
r + jx + 1 = Γr + jΓi:
With some simple steps of algebra, we arrive at the following set of equations expressing the
real and imaginary parts of Γ as functions of r and x:
Γr 
r
1 + r

2
+ Γi
2 =
1
1 + r

2
Γr  1
ð
Þ2 +
Γi  1
x

2
=
1
x

 2
8
>
>
>
>
<
>
>
>
>
:
:
Either equation describes a family of circles where each circle is associated with a speciﬁc value
of r (or x) and is shown in Figure 3.55.
The real part of impedance is expected to be positive, so r is always greater than zero, whereas x
assumes positive (inductive) or negative (capacitive) values. The circle r = 0 corresponds to the
unity circle, as |Γ| = 1. The two families of both circles appear on the Smith chart, where one can
obtain the magnitude and phase of Γ for a given load impedance. For instance, if ZL = 100 + j25Ω,
r = 2, and x = 0.5, corresponding to the point shown in the simpliﬁed Smith chart of Figure 3.56.
Accordingly, by virtue of measuring on the chart, we obtain: Γ ﬃ0.37∠23. Even in this
very simple example, using the original format of Γ equation, one has to take several steps of
tan–1 and magnitude calculations to obtain the same results. The Smith chart proves to be
180
RF Networks

considerably more powerful however when the impedance moving away from the load across
the transmission line needs to be calculated. We showed before at a given point z on the line
Z zð Þ = Z0
ejβz + Γe + jβz
ejβz  Γe + jβz :
Thus, the normalized input impedance at z = –l, that is at a distance of l away from the load, is
zIN = 1 + Γe2jβl
1  Γe2jβl ,
which shows that once Γ is obtained at the load position, that is for l = 0, the corresponding
impedance at a distance of –l from the load is found by keeping |Γ| constant, but rotating its phase
clockwise by 2βl = 4π
λ l. A half-circle rotation then corresponds to traveling a quarter wavelength,
which will rotate the phase by 180. What is shown in an actual Smith chart is not the angle of
rotation, but the distance traveling toward generator (that is rotating clockwise) normalized to
half-wavelength (or 360). This additional scale is shown in the simpliﬁed chart of Figure 3.56 as
well in dashed line. If impedances are known on the chart, the corresponding admittance is
obtained as the mirror image of the impedance. This, we established before, knowing that
Γi
Γr
r=0
r=0.5
r=1
r=2
r=
Γi
Γr
x=0
x=0.5
x=1
x=
x=1
x=-0.5
•
•
Figure 3.55: Constant-r and -x circles
Γi
Γr
r=0
r=0.5
r=1
r=2
x=0
x=0.5
x=1
x=–1
x=–0.5
0⁰ 
90⁰ 
180⁰ 
–90⁰ 
|Γ|=1
Toward 
generator
0
0.125
0.25
Figure 3.56: The Smith chart consisting of
constant-x and -r circles
3.7 Smith Chart
181

Γ = ZL  Z0
ZL + Z0
=  YL  Y0
YL + Y0
,
showing that|Γ| must remain the same, but its phase is 180 (or a quarter of a wavelength) different.
Shown in Figure 3.57 is an actual commercially available Smith chart, widely used among RF
designers. Note that the calculations may be performed using online software, easing the use of
the chart.
Example: Let us consider a 50Ω transmission line shown in Figure 3.58, terminated with
a load impedance of ZL = 250Ω, representing an ampliﬁer input. We showed how this
impedance may be matched to 50Ω using a lumped LC network or a transformer. The
Figure 3.57: A commercially available Smith chart
182
RF Networks

goal is to match that to 50Ω using transmission lines. This is commonly done by inserting
a short circuited stub with a constant length of dS at a distance d from the load.
We ﬁrst note that the shorted circuit stub, regardless of its length is always reactive, and it
will be placed in parallel with the line impedance at the point z = d. Since it is easier to
add admittances, we will perform everything using admittances instead. The normalized
load impedance is 5 + j0 as shown on the Smith chart in Figure 3.58. To convert to
admittance, we add a quarter wavelength, as the impedance is transferred to Z0
2/ZL, or
alternatively zL is changed to yL. Clearly yL corresponds to the r = 0.2 circle. That is shown
as point yL in the chart which is now at 0λ. Next, to match to 50Ω, we need to reside on the
r = 1 circle. Since moving across the transmission line only changes the angle of Γ, then the
desired point will be the intercept point of the r = 1 circle with constant |Γ| circle for
the point yL. This would be point P3 on the chart, which has a reading of 0.182 wavelength.
As a result, we have moved the load by a net length of 0.182 wavelength, or d = 0.182λ.
Point P3 has a real part equal to 1, but it is capacitive (note that we are dealing with
admittances). Reading the x family circles, we obtain the normalized imaginary part is equal
to 1.74. If the stub presents an imaginary part of –1.74, then once added to the line, it will
result in a pure real normalized admittance of 1 (or 50Ω). The appropriate length of stub is
found by intercepting the x = –1.74 circle with |Γ| = 1 circle, labeled as P4, and whose
reading is 0.37λ. Since the short circuit is at 0.25λ, then the length dS = 0.12λ.
It is clear that without using the Smith chart, the calculations would have been very difﬁcult.
If the load has some reactive component, the calculations would have been very similar.
Example: To show that the applications of the Smith chart go beyond transmission lines
and distributed elements, let us redo our previous example of matching the input imped-
ance of an ampliﬁer to 50Ω, through a lumped LC network (Figure 3.36), but this time
Continued
5+j0
SC
yL
P3
l=0.182
l=0.37
P4
1
–
ZL
Stub
d
d
s
Figure 3.58: A transmission line with a short-circuited stub
3.7 Smith Chart
183

using the Smith chart instead. Since RIN is greater than 50Ω, it will reside on the right-half
side of the circle (Figure 3.59). We also assume that it has a capacitive component
associated with, which is a more realistic model of an ampliﬁer input impedance. The
normalized impedance is shown as the point P1 on the chart.
Since ﬁrst a shunt inductance is placed, we convert zin to yin by adding a quarter
wavelength to arrive at point P2. Now to obtain a real part of eventually 50Ω, we would
like the matching inductance to move the point P2 to somewhere on the mirrored image
of the r = 1 circle (the shaded circle). If so, when converted back to impedance (to
conveniently add the series capacitance) it must reside on the r = 1 circle. This is
obtained by intercepting the constant r circle where P2 resides with the mirrored r = 1
circle. There are two solutions, but only the point P3 is valid. That is because the other
point when converted back to impedance will reside in the lower half of the circle,
corresponding to a capacitive component. This point then can be matched to 50Ω only
through a series inductor, whereas our matching network comprises a series capacitor.
The value of the inductance needed is obtained by considering the original susceptance,
and the new one corresponding to point P3. Point P3 is converted back to impedance,
resulting in point P4, which now resides on the r = 1 circle, and whose reactance is x4.
This point is inductive, and all that is needed is to add a series capacitance C such that
x4 =
1
Cω0
50Ω. It is clear by inspection that if RIN is less than 50Ω, or in general for any point
residing inside the shaded circle, there will be no solution for this speciﬁc matching
network, an outcome that is not so obvious by using the series–parallel calculations.
Back to our numerical example, if RIN = 250Ω, then yin = 0.2 + j0. After intercepting
with the mirrored r = 1 circle, x3 is read to be –0.4. Since at this point, we are still
dealing with normalized admittances, 0:4 = 50Ω
Lω0, or Lω0 = 125Ω. This leads to L = 10nH
at 2GHz. Point P4 reading on the chart is 1 + j2, which is now impedance. Thus
2 =
1
Cω0
50Ω, leading to C = 0.8pF at 2GHz. One other nice feature of the Smith chart is that
what is obtained is reactance or susceptance, and is not frequency dependent. It
becomes a function of the frequency only when converted to inductance or capacitance.
P3
P4
x4
Constant r 
for P2
r=1
r=1 mirror
x3
P2
x2
P1
Figure 3.59: Smith chart corresponding to
matching network of Figure 3.36
184
RF Networks

3.8
SCATTERING PARAMETERS
..............................................................................................
In addition to the six ways of characterizing a linear and time-invariant N-port described earlier
in Section 3.1.1 (impedance, admittance, two hybrid, and two transmission matrices), there is
yet another common method widely used in RF and especially microwave applications, known
as scattering parameters. Their basic properties and application will be presented in this section.
For a more detailed discussion, see [3], [4].
3.8.1
Basic Properties of Scattering Parameters
Describing microwave circuits with impedance (or admittance) matrixes may not be practical,
since voltages, currents, and impedances cannot be measured directly at microwave frequency.
Obtaining these matrices requires terminating the two-port by ideal short or open circuits,
which prove to be challenging at high frequencies. The quantities that are directly measurable
by means of a small probe used to sample the relative ﬁeld strength are the standing wave ratio
and power, which directly lead to reﬂection coefﬁcient. Also directly measurable is a relative
relation of the amplitude and phase of the transmitted signal as compared to those of the
incident (by using a directional coupler for instance). In other words, directly measurable
quantities are the relative (to the incident wave) amplitude and phases of the waves reﬂected,
or scattered. The matrix describing such relationship is called a scattering matrix, or S matrix.
Adopted from microwave circuits, it is not uncommon to use scattering parameters for RF
circuits as well, especially when dealing with the interface of the RF circuit and outside world,
i.e., receiver input or transmitter output.
Consider the N-port shown in Figure 3.60. If a wave with an associated equivalent voltage
V1
+ is incident at terminal 1, the reﬂected wave is V1
 = S11V1
+ in that terminal, where S11 is
the reﬂection coefﬁcient. Moreover, it is natural to assume that waves will be also scattered out
of the other ports, expressed as Vn
 = Sn1Vn
+, n = 2, 3, . . ., N.
When waves are incident at all ports, we can write in general
V1

V2

  
VN

2
6664
3
7775 =
S11
S12
  
S1N
S21
S21
  
S2N
  
  
  
  
SN1
SN2
  
SNN
2
6664
3
7775
V1
+
V2
+
  
VN
+
2
6664
3
7775,
or [V] = [S][V+], where [S] is the scattering matrix.
N-Port
V1
+
V1
–
VN
+
VN
–
Figure 3.60: An N-port showing scattered waves
3.8 Scattering Parameters
185

We assume that all the ports use the same characteristic impedance of Z0, and thus the same
as before
V + = Z0I +
V =  Z0I,
and
V = V + + V
I = I ++ I = 1
Z0
V +  V
ð
Þ:
Combining the equations above, one can show that the S matrix could be expressed in terms of
impedance or admittance matrixes. For example, in matrix format we have
V
½  = V +
½
 + V
½
 = Z
½  I½  = Z
½  V +
½
  Z
½  V
½
,
where Z
½  = 1
Z0 Z
½  is the N-port normalized impedance matrix. It follows that
V
½
 =
Z
½  + U
½ 
ð
Þ1 Z
½   U
½ 
ð
Þ V +
½
,
where U
½  =
1
0
  
0
0
1
  
0
  
  
  
  
0
0
  
1
2
4
3
5 is the unit matrix. According to the deﬁnition of the S matrix then,
S½  =
Z
½  + U
½ 
ð
Þ1 Z
½   U
½ 
ð
Þ:
This results to two important observations:
1. First, even though our discussion so far has involved incident and reﬂected waves,
S parameters are not solely limited to distributed elements. Any N-port, lumped or distrib-
uted, may be represented by the S matrix. However, using S parameters proves to be a
necessity at microwave frequencies due to the measurement limitation pointed out earlier.
We will have a more detailed discussion on this topic at the end of this section.
2. For any reciprocal N-port, the known symmetry of the impedance matrix readily results into
the symmetry of the S matrix. That is, [S] = [S]t, where the superscript t denotes the S matrix
transpose. This can be proven easily based on the basic deﬁnition.
In addition to the symmetry of the S matrix for a reciprocal N-port, the power conservation
leads to more simpliﬁcation if the circuit is lossless as well. Since the total power leaving the
lossless N-port must be equal the total incident power, we have
X
N
n = 1
Vn

j
j2 =
X
N
n = 1
Vn
+
j
j2:
Replacing Vn = PN
i = 1SniVi + , the power conservation may be expressed as
X
N
n = 1
X
N
i = 1
SniVi
+


2
=
X
N
n = 1
Vn
+
j
j2:
186
RF Networks

The Vn
+ are all independent incident voltages, if we choose all to be zero except for one of
them, say, Vi
+ we have
X
N
n = 1
SniVi
+
j
j2 = Vi
+
j
j2,
which leads to
X
N
n = 1
Sni
j
j2 =
X
N
n = 1
SniS∗
ni = 1,
where the index i is arbitrary. Similarly, we may choose for all Vn
+ to be zero, except for Vs
+
and Vr
+ (s 6¼ r). This leads to (see Problem 27 for proof )
X
N
n = 1
SnsS∗
nr = 0:
The above two conditions are sufﬁcient to restrict the scattering matrix to ½N(N + 1), as
opposed to N2. Such a matrix is known as the unitary matrix.
Since many common RF circuits are two-ports, let us focus on the scattering matrix of a two-
port shown in Figure 3.61.
The incident and scattered waves are related as
V1
 = S11V1
+ + S12V2
+
V2
 = S21V1
+ + S22V2
+ :
If the output is terminated with a matched load, V2
+ = 0, and thus S11 will represent the
reﬂection coefﬁcient. However, if the output is terminated with an arbitrary load of ZL, the ratio
of V2
+/ V2
– must be equal to the reﬂection coefﬁcient of the load (as V2
– is incident to the load),
thus
V2 +
V2 = ZL  Z0
ZL + Z0
= ΓL:
Moreover, solving for V1
+ and V1
– we obtain
V1
V1 + = S11  S12S21ΓL
S22ΓL  1 ,
which is the modiﬁed input reﬂection coefﬁcient.
Two-Port
V1
+
V1
–
V2
+
V2
–
S11
S22
Figure 3.61: A two-port circuit
3.8 Scattering Parameters
187

Example: Consider the circuit of Figure 3.62, where a circuit with an arbitrary reﬂection
coefﬁcient (ΓIN = ZINZ0
ZIN + Z0) is connected to the source with an attenuator in middle. We
further assume that the circuit is either terminated at the output, or is unilateral such that
its input S11 is equal to ΓIN. We wish to ﬁnd S11 looking into the attenuator.
The attenuator is typically realized by a Π resistive network as shown on the right,
often known as the Π-pad attenuator.13 Assuming the attenuator is matched at both ends,
and has an attenuation of L =  20 log α, (α < 1), then we can show that (see also
Problem 32 for more details)
R1 = Z0
1  α2
2α
R2 = Z0
1 + α
1  α ,
where Z0 is the reference (termination) impedance.
With reference to the ﬁgure, the incident voltage of V+ is attenuated by α coming into
the circuit, and the reﬂected signal of αV+ΓIN is created. The reﬂected signal travels to the
left, and once passed by the attenuator, a total reﬂected voltage of α2V+ΓIN is received
back by the source. Thus the reﬂection coefﬁcient at source is α2ΓIN, or in dB, it improves
by two times the loss of the pad or 2L.
It is not uncommon in RF to insert a pad to improve the interface in terms of matching for
sensitive measurements. Even a small attenuation of 3dB effectively boosts the S11 by 6dB, which
could be quite helpful. The loss of the attenuator must be naturally de-embedded from the system.
Note that the attenuator loss is deﬁned for matched ports, and thus the poor S11 of the circuit under
the test may affect it. Hence, that must also be included. See the example at the end of the section.
For a reciprocal two-port, S12 = S21. If the two-port is lossless, according to power conser-
vation we have
|S11| =|S22|,
Unmatched
Circuit
Attenuator
Vs
ZIN
Z0
V +
V+
R1
R2
R2
Π-Pad Attenuator
V+ΓIN
2V+ΓIN
a
a
a
Figure 3.62: Unmatched load preceded by an attenuator
13 Attenuators are sometimes referred to as pads due to their effect of padding down a signal by analogy with acoustics.
188
RF Networks

which tells us that the reﬂection coefﬁcients of the input and output ports are equal in
magnitude. Moreover,
S12
j
j =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  S11
j
j2
q
:
Example: Consider the shunt susceptance jB, connected across a transmission line with a
characteristics impedance of Z0 = 1
Y0, as shown in Figure 3.63.
The S11 is the input reﬂection coefﬁcient for a matched load, and thus
S11 = Y0  Yin
Y0 + Yin
= Y0  Y0 + jB
ð
Þ
Y0 + Y0 + jB
ð
Þ =
jB
2Y0 + jB ,
which must be equal to S22 due to symmetry. To ﬁnd S21, let us terminate the output,
forcing V2
+ to zero. For a shunt element, we must have V1
+ + V1
– = V2
– , which leads to
S21 = S21 = 1 + S11 =
2Y0
2Y0 + jB :
As an exercise, one can show that the obtained S parameters for the example of Figure 3.63,
indeed satisfy the two restraints set by the energy conservation.
Hypothetically, if the right side transmission line had a different characteristics impedance of
Z0
0 = 1
Y0
0 instead, we can show
S11 = Y0  Y0
0  jB
Y0 + Y0
0 + jB ,
and S22 and S21 could be obtained similarly.
Example: Consider the lumped ampliﬁer shown in Figure 3.64. We further assume that
the source and load are connected very close to the ampliﬁer, so no distributed element is
involved. Since the ampliﬁer is lumped, the incident and reﬂected waves may not be
meaningful. However, we shall show that they still give us some insight on the circuit
properties, particularly if one considers the available power concept.
Continued
Z0
Z0
jB
Figure 3.63: Shunt element in a transmission line
3.8 Scattering Parameters
189

We set the scattering matrix reference impedance to be equal to that of the source, that
is, RS. Since the circuit is unilateral, as is the case for most well-behaved RF ampliﬁers,
S12 = 0. It follows that
S11 = RIN  RS
RIN + RS
,
which is equal to the reﬂection coefﬁcient, regardless of the output termination. Although
the circuit is lumped, we could still calculate V1
+ and V1
 based on the basic deﬁnition
presented earlier. Since
V1 = V1
+ + V1

I1 = V1 +  V1
RS
,
we have
V1
+ = V1 + RSI1
2
= 1
2 VS
V1
 = S11V1
+ :
Now let us deﬁne the power associated with V1
+ and V1
, which we will call P1
+ and P1
:
P1
+ =
1
2RS
V1
+
j
j2 = VS
j
j2
8RS
P1
 = S11
j
j2P1
+ :
We note that P1
+ is in fact the circuit available power (Pa) as deﬁned before. Moreover,
the total power delivered to the ampliﬁer input, PIN, is found to be
PIN = V1
j
j2
2RIN
= P1
+  P1
 = 1  S11
j
j2

	
Pa:
This shows that P1
+ and P1
 signify similar concepts as incident and scattered waves. The
total power delivered to the circuit is the difference between the two, as if P1
+ is the power
incident, while P1
 is the power reﬂected back to the source. For a matched input, S11 = 0,
and thus the power reﬂected is zero, meaning that the source available power is entirely
delivered to the ampliﬁer.
RS
RIN
ROUT
RL
gV1
+
V1
–
VS
Figure 3.64: A lumped ampliﬁer
190
RF Networks

If we set the reference impedance of the output terminal to be ROUT, then
S22 = RL  ROUT
RL + ROUT
:
If the reference impedance Z0 is chosen such that Z0 = RS = ROUT, then the available
power gain is equal to
Ga =|S21|
2.
The general case of arbitrary source and load impedances will be discussed next.
Example: Consider the two-port of Figure 3.65 with arbitrary source and load imped-
ances. We would like to ﬁnd the available power gain in terms of the scattering param-
eters that are directly measurable at high frequencies.
We deﬁne the two-port input and output reﬂection coefﬁcients as
ΓIN = ZIN  Z0
ZIN + Z0
ΓOUT = ZOUT  Z0
ZOUT + Z0
,
where Z0 is the reference impedance. As we pointed out, ΓIN = S11, and ΓOUT = S22 if the
other port is terminated by Z0. Likewise, we deﬁne the reﬂection coefﬁcients for the
source and load, which are also directly measurable as
Γs = Zs  Z0
Zs + Z0
ΓL = ZL  Z0
ZL + Z0
:
We can further express the current going into the two-port in terms of the incident and
reﬂected input voltages:
Z0I1 = V1
+  V1

ZINI1 = V1
+ + V1
:
Continued
Two-Port
Rs
RL
Vs
+
V2
–
ZIN
ZOUT
+
V1
–
V1
+
V1
–
V2
+
V2
–
I1
I2
Figure 3.65: A two-port with arbitrary source
and load terminations
3.8 Scattering Parameters
191

Also the power delivered to the two-port is
PIN = Re [ZIN]|I1|
2.
Combining the three equations above and expressing ZIN in terms of ΓIN leads to
PIN = V1 +
j
j2
2Z0
1  ΓIN
j
j2

	
:
Similarly, the power delivered to the load would be
PL = V2
j
j2
2Z0
1  ΓL
j
j2

	
:
Next, we attempt to express V2
, the voltage absorbed by the load, versus V1
+, the voltage
delivered to the two-port in terms of the two-port scattering parameters. That is easily
done using the basic deﬁnition of scattering parameters:
V2
 = S21V1
+ + S22V2
+ = S21V1
+ + S22ΓLV2
.
Hence
V2
 =
S21
1  ΓLS22
V1
+ :
Therefore, the power gain, deﬁned as the power delivered to the load divided by the
power delivered to the input, is
GP = PL
PIN
=
S21
j
j2 1  ΓL
j
j2

	
1  ΓLS22
j
j2 1  ΓIN
j
j2

	 :
To ﬁnd the available power gain, we note that the power delivered to the input becomes the
available power if the two-port input is conjugate matched to the source, that is, if ΓIN = Γs
∗.
Likewise, a similar statement can be made for the output available power and PL if we have
ΓL = ΓOUT
∗. With a few steps of algebra (see problem 40), the available power gain would be
Ga =
S21
j
j2 1  Γs
j
j2

	
1  ΓsS11
j
j2 1  ΓOUT
j
j2

	 :
In conclusion, in general the available power gain is not equal to |S21|2. If the two-port output
impedance is matched to Z0, then Ga =
S21
j
j2
1 Γs
j
j2
ð
Þ, and only if its input is also matched to Z0, then
Ga = |S21|2, a conclusion we had already reached for unilateral ampliﬁers.
Example: Shown in Figure 3.66 is a circulator circuit realized based on a gyrator
introduced earlier (Figure 3.9). Considering the left ﬁgure, we have
V1
V3


=
0
1
1
0


Ia
Ib


,
where
0
1
1
0
h
i
is the gyrator impedance matrix.
192
RF Networks

We can write
Ia = I1 + I2
Ib = I3  I2,
and
V1 =  Ib = I2  I3
V3 =  Ia = I1 + I2
V2 = V1  V3 =  I1  I3:
Thus, the corresponding open impedance matrix is
Z =
0
1
1
1
0
1
1
1
0
2
4
3
5:
Assuming a reference impedance of Z0 = 1Ω, then the circulator scattering matrix is
found to be
S = Z + U
ð
Þ1 Z  U
ð
Þ =
0
1
0
0
0
1
1
0
0
2
4
3
5,
where U =
1
0
0
0
1
0
0
0
1
"
#
is the unit matrix as introduced earlier in this section.14
A typical circuit level conﬁguration of the circulator is shown in the right side of Figure 3.66,
where all the ports are terminated. For the moment, let us assume that all the ports are matched,
that is, R1 = R2 = R3 = Z0 = 1Ω. Given that, we can write
Power reflected from port 1
Source available power
= S11
j
j2 = 0
Power delivered to port 2
Source available power = S21
j
j2 = 0
Power delivered to port 3
Source available power = S31
j
j2 = 1:
+
V1
–
+
V3
–
+   V2   –
I2
I1
I3
Ia
Ib
Vs
R1
R2
R3
1
3
2
+   V2   –
+
V3
–
+
V1
–
Circulator based on a gyrator
Typical circulator configuration
Figure 3.66: Circulator circuit realized based on a gyrator
14 For the general case of a
0
a
a
0


gyrator, the S matrix is S =
1
3a2 + 1
a2  1
2a a  1
ð
Þ
2a a + 1
ð
Þ
2a a + 1
ð
Þ
a2  1
2a a  1
ð
Þ
2a a  1
ð
Þ
a a + 1
ð
Þ
a2  1
2
4
3
5. Clearly,
for either case of a =  1, an ideal circulator with either 1-2-3 or 3-2-1 port rotation is achieved.
3.8 Scattering Parameters
193

Consequently, the source available power that is absorbed by port 1 is entirely delivered to port
3, with no signal appearing at port 2. Moving the source to the other two ports, we can see that
the circulator achieves isolation between its adjacent ports in the clockwise direction, while the
source available power is delivered entirely to its adjacent port in the counterclockwise
direction (the direction of the arrow shown in the ﬁgure).
As mentioned earlier, the gyrators and thus the circulators, while passive, are nonreciprocal.
One of their applications is in full duplex transceivers as the receiver and the transmitter, which
are operating concurrently, need to be isolated (Figure 3.67). This way the receiver is protected
from the large transmitter output, while the antenna signal still shows in the receiver input. Full
duplex radios will be discussed in Chapter 6.
It must be noted that the perfect isolation is obtained only if all the ports are matched.
For instance, if port 3 is not matched ( Γ3 = R31
R3 + 1 6¼ 0), then the power delivered to the port
2 resistor is P2 = |Γ3|2Pa, and the power delivered to the port 3 resistor is P3 = 1 + Γ3
j
j2
R3
Pa, where
Pa = Vs
j
j2
8
is the source available power. The reader can verify that P2 + P3 = Pa, which agrees
with power conservation. Accordingly, the isolation from port 1 to port 2 is limited to how good
of a match can be achieved at port 3. We can physically justify this considering that if port 3 is
not matched, not all the source power would be delivered to R3, and the portion reﬂected must
inevitably leak to the second port. For more details and the general case, please see Problem 34
at the end of this chapter.
3.8.2
Two-Port Stability Using S Parameters
The two-port stability through admittance (or impedance) parameters was already discussed
earlier in Section 3.2.5. We can also derive stability criteria in terms of the input reﬂection
coefﬁcient and S parameters. Consider the two-port of Figure 3.68.
We showed earlier that the input reﬂection coefﬁcient can be expressed in terms of the two-
port S parameters
ΓIN = S11  S12S21ΓL
S22ΓL  1 ,
1
3
2
Receiver
Transmier
1
3
2
Direcon of power transfer
Figure 3.67: Circulator
used in full-duplex radios
194
RF Networks

where ΓL = ZLZ0
ZL + Z0 is the load reﬂection coefﬁcient. Since
ΓIN = ZIN  Z0
ZIN + Z0
,
then for Re[ZIN] to be positive (i.e., for the two-port to be unconditionally stable),
ΓIN
j
j = S11  S12S21  S11S22
ð
ÞΓL
S22ΓL  1

 < 1:
To simplify, we deﬁne Δ = S12S21  S11S22, which is the S matrix determinant. Hence,
S11  ΔΓL
S22ΓL  1

 < 1for all ΓL:
To ﬁnd the boundary between stability/instability, we have to set |ΓIN| = 1. With some algebraic
manipulations, we arrive at
ΓL  S21∗ Δ∗S11
S22
j
j2  Δ
j j2

 =
S12S21
j
j
S22
j
j2  Δ
j j2 ,
which is a circle with the center C = S21∗Δ∗S11
S22
j
j2 Δ
j j2 , and radius R =
S12S21
j
j
S22
j
j2 Δ
j j2 :
Example: The region of stability/instability for a given ampliﬁer is demonstrated by a
circle on the Smith chart as shown in Figure 3.69.
Continued
[S]
Zs
ZL
Vs
+
V2
–
ZIN
ZOUT
+
V1
–
V1
+
V1
–
V2
+
V2
–
I1
I2
Figure 3.68: Two-port described by its
S parameters
3.8 Scattering Parameters
195

The boundary line between stable and unstable operation at the input is when |ΓIN| = 1.
The contour of values for ΓL that produces a unity magnitude reﬂection coefﬁcient at the
input is then the input stability circle. Note that for ΓL = 0 (the Smith chart origin),
|ΓIN| = |S11|. Thus, since |S11| must be less than one (or else Re[YIN] < 0), the stable region
is outside the stability circle on the Smith chart.
3.9
DIFFERENTIAL TWO-PORTS
..............................................................................................
Differential two-ports in general and differential ampliﬁers in particular are widely used in RF
design for obvious well-known reasons. This includes better supply rejection, lower second-
order nonlinearity, and higher swings among other advantages. On the other hand, most signal
generators and network analyzers available to characterize our circuits are single-ended.
Typically external single-ended to differential hybrids are exploited to measure such circuits.
Consider Figure 3.70, illustrating a differential ampliﬁer with a differential input impedance
of 2RIN = 2Rs and an available voltage gain of g.
A 1:√2 ideal transformer at the input presents a net single-ended input impedance of Rs to the
source as intended. Since the transformer is ideal the power is expected to split in half at each
end of the secondary, with voltages √2 times smaller and 180º out of phase. Each voltage is
Figure 3.69: Stability circle on the
Smith chart for a given ampliﬁer
vs
Rs
2RIN
RL
1:√2
√2:1
Differential Amplifier
Ideal
Ideal
+vi/√2
–vi/√2
+gvi/√2
–gvi/√2
gvi
+
vi
–
Figure 3.70: A differential
matched ampliﬁer
196
RF Networks

ampliﬁed by a gain of g to the output. Once combined with a similar ideal transformer with a
turn ratio of √2:1 this time, a total available voltage gain of g is measured, as it would have been
the case for an identical single-ended design. While most receivers are matched at the input, it is
common to have a high impedance output, as the signal is residing at low frequencies. In
practice, the transformers used to make such measurements are realized with either on-board
narrowband Baluns or wideband hybrid circuits, whose loss must be characterized beforehand,
and be de-embedded from the measurement.
Although we are expected to discuss noise in the next section, one can show that the noise
performance of the circuit would be characterized similarly, as if there were two identical
single-ended ampliﬁers, but driven differentially [9].
3.10 Summary
In this chapter we have covered a broad range of topics essential to RF and microwave
engineering, such as available power gain, matching circuits, and scattering parameters.
– Section 3.1 presented a summary of two-ports and their circuit properties. Of great import-
ance in RF design are the reciprocal two-ports that consist of RLCM elements.
– The concepts of available power and available power gain were discussed in Section 3.2. The
available power of unilateral networks, reciprocal networks, and lossless reciprocal networks
was speciﬁcally derived and discussed.
– Impedance transformation and matching were discussed in Section 3.3. The concept of
matching is critical to the design of low-noise and power ampliﬁers. Several ways of
matching an ampliﬁer, such as lumped LC circuits, and transformers were discussed.
– Lossless and low-loss transmission lines were discussed in Sections 3.4 and 3.5. These are
examples of distributed networks that were introduced in Chapter 1, and are widely used in
RF and microwave design.
– Section 3.6 dealt with some additional properties of the antennas.
– In Section 3.7 the Smith chart was introduced and its applications in impedance transform-
ation and matching the ampliﬁers were discussed.
– Finally, scattering parameters as another common way of expressing an LTI two-port was
presented in Section 3.8.
3.11 Problems
1. Find the L matrix for the following circuits:
Ideal
n1 : n2
L1–M
L2–M
M
n1/n2=M/L2
L1–M2/L2
L2
3.11 Problems
197

2. Show that the two circuits below are equivalent.
L1
L2
L1+L2
L2
M=L2
3. Show that the two circuits below are equivalent, where k =
M
j
j
ﬃﬃﬃﬃﬃﬃﬃ
L1L2
p
is the coupling factor and
n = k
ﬃﬃﬃﬃ
L1
L2
q
.
L1
L2
k
Ideal
n : 1
(1–k2)L2
L1
4. Find the transfer function and input impedance of the double-tuned circuit shown
below.
M
ZIN
R
R
C
C
L
L
iS
+
vOUT
–
5. Using parallel–series transformation, ﬁnd the values of L and C to match the 250Ω
ampliﬁer input resistance to 50Ω.
6. Repeat the problem by using the Smith chart.
7. Using parallel–series transformation, design an LC matching network to match an ampliﬁer
with an input impedance of 20Ω||1pF to 50Ω.
8. Plot on the Smith chart the impedance of a series RLC circuit over frequency.
9. Consider the following two-port system terminated to admittance YL in the second port and
to a voltage source vs with output admittance Ys in the ﬁrst port.
198
RF Networks

a. Prove that
YIN = Y11  Y12Y21
Y22 + YL
YOUT = Y22  Y12Y21
Y11 + YS
Av = VL
Vs
= 
YSY21
YS + Y11
ð
Þ YL + Y22
ð
Þ  Y12Y21
:
b. Repeat part a and calculate ZIN, ZOUT, and Av in terms of Z parameters.
[Y]
YL
Ys
vs
YIN
YOUT
10. Using the circuit from Problem 7, prove that the condition of Ys + YIN = 0 or YL + YOUT = 0
for the boundary between stable and unstable regions both lead to (Ys + Y11)(YL + Y22) 
Y12Y21 = 0, which is equivalent to the condition that Av approaches inﬁnity.
11. Using the circuit from Problem 7, when the input and output are simultaneously conjugate
matched the power gain becomes maximum. This would happen if Ys and YL are found
such that the following two equations are met:
YIN = Y11  Y12Y21
Y22 + YL
= Y∗
s
YOUT = Y22  Y12Y21
Y11 + Ys
= Y∗
L :
Such Ys and YL are called Ys,opt and YL,opt.
a. Prove that Ys,opt and YL,opt are given by
Ys,opt =
Y12Y21 + Y12Y21
j
j K +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p

	
2Re Y22
ð
Þ
 Y11
YL,opt =
Y12Y21 + Y12Y21
j
j K +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p

	
2Re Y11
ð
Þ
 Y22,
where K is equal to K = 2Re Y11
ð
ÞRe Y22
ð
ÞRe Y12Y21
ð
Þ
Y12Y21
j
j
. This is a more compact equivalent to
the results obtained in Section 3.2.6.
b. Prove that under the above optimum condition the power gain is equal to
Gp = Y21
Y12

 K 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
K2  1
p

	
, which also proves that for a reciprocal network (Y21 = Y12)
3.11 Problems
199

the power gain is less than unity. As a special case, an LTI passive network cannot
amplify the power.
12. Common in transistor modeling, a two-port (refer to Figure 3.2) may be expressed by
hybrid parameters as follows:
V1 = h11I1 + h12V2
I2 = h21I1 + h22V2:
Express the hybrid matrix H =
h11
h12
h21
h22
h
i
in terms of the two-port admittance matrix.
13. Find the Z matrix for the following π two-port.
ZA
ZB
ZC
14. A student makes the following argument as to why an ideal transformer is not reciprocal:
A voltage v0(t) in primary results in a voltage of n2
n1 v0 tð Þ in the secondary, while the same
voltage of v0(t) in the secondary results in a different voltage of n1
n2 v0 tð Þ in the primary, as in
general n1 6¼ n2. What is the ﬂaw of the argument?
15. In the circuit shown below, the source is inductive, and is connected to a 50Ω load through
a lossless inductive network. Find ρ1 = Z1Z
S
Z1 + Z
S and ρ2 = Z2Z
L
Z2 + Z
L. Is |ρ1| = |ρ2|?
VS
L
L
50Ω
Lossless 2-Port
Z1
Z2
16. The gyrator shown below is described by the Z matrix Z
½  =
0
α
α
0
h
i
, and is loaded with an
ideal capacitance C. By ﬁnding the relation between the input current and voltage, show
that the circuit resembles an inductor. What is the input impedance?
C
ZIN
+
v1
–
i1
a
200
RF Networks

17. For the circuit below, calculate and plot the open-circuit voltages for the input current
i(t) = + I0 and i(t) =  I0. Is the circuit reciprocal? Why?
i(t)
R
R
+
v(t)
–
i(t)
R
R
+
v’(t)
–
18. Repeat the previous problem for a step input current: i(t) = u(t).
19. Prove the third reciprocity statement shown in Figure 3.8.
20. Show that the reciprocity theorem would be still valid to a network comprising linear but
time-varying resistors only.
21. For the pair of Hertzian dipole antennas shown below, work out the effective area of the
receiving antenna. Assume the load is matched (ZL = Z22
∗in Figure 3.53). Hint: Show that
the load current is IL =
E1lsin2
ð
Þ2
8R22
, and thus the power delivered is PL = 1
2 R22 IL
j
j2. Also use
P1 r; 1; φ1
ð
Þ = E12
2η .
1
2
r
E1
q
q
a
22. Calculate the differential equation of a low-loss transmission line and the value of γ.
23. Consider a transmission line with distributed series impedance of Zs and parallel admit-
tance of YP, both per unit length. (a) Prove that in the sinusoidal steady state case the
differential equation for the phasor of line voltage (or current) is given by this expression:
∂2V zð Þ
∂2z
= ZsYP  V zð Þ. (b) Show that the solution for this differential equation would be of
the form V+eγz + Ve+γz where γ =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ZsYP
p
. (c) Calculate the real and imaginary parts of γ
for a lossy transmission line where Zs = jωLs + Rs and YP = jωCP + GP. The real part of γ is
the decay rate of the wave magnitude.
24. Consider a loss-less distributed transmission line with a series inductance of L per unit
length and the distributed parallel capacitance of C(v) per unit length. The distributed
capacitance is a varactor that is a function of voltage. (a) Prove that any traveling wave in
the line must satisfy the following modiﬁed wave equation: LC v
ð Þ ∂2v
∂2t + L dC v
ð Þ
dv
∂v
∂t
 2 = ∂2v
∂2z.
(b) Assume that C(v) = C0 + αv, α 6¼ 0. Assuming that a solution could be of the form
3.11 Problems
201

f(ωt  βz) where β = ω
ﬃﬃﬃﬃﬃﬃﬃﬃ
LC0
p
and replacing it in the derived wave equation, prove that the
solution could be of the form v z; t
ð
Þ = k1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ωt  βz + k2
p
.
25. For the circuit below, ﬁnd the input reﬂection coefﬁcient.
1  :n
Z C =Z 0
l2
l1
Z C =Z 0
26. For the circuit shown below, ﬁnd the input reﬂection coefﬁcient and the VSWR. What
value of X and RL minimizes the VSWR?
jX
ZC=Z0
l
27. Using the Smith chart, recalculate the biconjugate matching components for the example of
Figure 3.38.
28. A 50Ω line on PCB connects the SMA connector on one end to an on-chip LNA input on
the other end. Since there is only access to the SMA, the loss of the line which must be
de-embedded to characterize the LNA performance accurately cannot be measured
directly. A common practice is to measure the input reﬂection of the line on the bare
board, where the LNA input is left open (no chip mounted yet) through the SMA
connector. Show that for a low-loss transmission line, the insertion loss of the line is
half this value in dB.
On-board transmission line
LNA
SMA
S21 ?
Open Circuit
S11 ?
29. Prove the equation PN
n = 1SnsS∗nr = 0, where s 6¼ r for an arbitrary N-port.
30. Find the S-matrix of a series reactance on a transmission line with two different character-
istics impedances as shown below. Answer (partial): S21 =
2Z02
jX + Z02 + Z01.
202
RF Networks

jX
ZC=Z01
ZC=Z02
31. Convert the S matrix of a two-port to a Y matrix and vice versa. Answer:
S½  =
U
½  + Y
½ 
ð
Þ1 U
½   Y
½ 
ð
Þ.
32. For the Π-pad attenuator shown below,
a. Show that for the two ports to be matched to Z0, we must have 1
Z0 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
R22 +
2
R1R2
q
.
b. Show that the available power gain of the circuit if the matching condition (part a) is
satisﬁed is
1
1 + R1
R2 + R1
Z0

	2 = α2, assuming R1 = Z0 1α2
2α and R2 = Z0 1 + α
1α.
R1
R2
R2
Π-Pad Attenuator
Z0
Z0
Vs
Hint: You could take the advantage of the symmetry, and use the image impedance
theorem, suggesting that the attenuator may be split in half and be terminated by itself.
33. Calculate the S matrix of the T network shown below by:
a. Direct analysis of forward and backward signals.
b. Finding the Y matrix ﬁrst and converting to the S matrix.
YB
YA
YC
34. In the circulator below, the scattering matrix is S =
0
1
0
0
0
1
1
0
0
"
#
, and Z0 = 1Ω. For arbitrary
port resistances:
a. Show that port 1 reﬂection coefﬁcient Γ1 = Z11
Z1 + 1 =  Γ2Γ3, where Γ2 = R21
R2 + 1 is the
port 2 reﬂection coefﬁcient, and Γ3 = R31
R3 + 1 is the port 3 reﬂection coefﬁcient. Thus, if
either one of the second or third ports are matched, the ﬁrst port is matched too.
3.11 Problems
203

b. Show that the voltages at the second and third port are V2 =
 1 + Γ2
ð
ÞΓ3
1 + R1
ð
Þ 1R1
ð
ÞΓ2Γ3 Vs and
V3 =
1 + Γ3
1 + R1
ð
Þ 1R1
ð
ÞΓ2Γ3 Vs, while the port 1 voltage is
1Γ2Γ3
1 + R1
ð
Þ 1R1
ð
ÞΓ2Γ3 Vs.
c. Find the power delivered from the source to port 1, and the powers dissipated in R2 and
R3, and show that the power balance is met.
Vs
R1
R2
R3
Z1
1
3
2
+   V2   –
+
V3
–
35. In the circuit below, the scattering matrix of the circulators is S =
0
1
0
0
0
1
1
0
0
"
#
, and Z0 = 1Ω.
Find all the voltages labeled (V1, V2, V3, V0
1, V0
2, and V0
3) in terms of Vs1 and Vs2.
1
3
2
Vs1
1W
Vs2
1W
1W
1W
+
V1
–
+
V3
–
+
V 3
–
+
V 1
–
1
3
2
+   V2   –
+   V 2   –
¢
¢
¢
36. Discuss the stability criteria for a unilateral ampliﬁer (S12 = 0) on the Smith chart.
37. Consider the following AM detector driven by a sinusoidal source, where vs(t) = A cos ω0t.
Rs
ZIN
vs
R
C
iD
vD
Ideal Diode
AM Demodulator
We assume for simplicity that the diode whose i–v characteristics are shown on the right
is ideal. Sketch the capacitor voltage and current, and from that ﬁnd the input current.
Calculate the instantaneous and average power delivered by the source to the detector.
What is the instance of the diode turning on? Knowing the average power, estimate the
average input resistance of the detector. Assume: R 
 Rs, RCω0 
 1. (Answer:
ton = T 
1
RCω02
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 + 4πRCω0
p
 1


, RIN 	 R
2).
38. Propose an LC circuit to match the nonlinear input resistance of the AM detector to source.
How does the instantaneous reﬂection coefﬁcient look?
204
RF Networks

39. Aside from full duplex transceivers, a circulator could be utilized to build an isolator.
Shown below is a realization, where the circulator second port is connected to the reference
impedance Z0, while the input and output (ports 1 and 3) are terminated with arbitrary
resistances Rs and RL.
a. Find the transfer function from port 1 to port 3, and vice versa.
b. Explain why the circuit works as an isolator.
Z0
RL
1
3
2
Vs
Rs
Isolator
40. In this problem, we will show the steps to derive the available power gain of a two-port.
a. Knowing that ΓIN = S11+ S12S21ΓL
1S22ΓL, show that in a similar fashion, ΓOUT = S22+ S12S21Γs
1S11Γs.
b. Using the two equations in part a, eliminating S12S21 term, show that: 1ΓINΓs
1ΓLΓOUT = 1S11Γs
1S22ΓL.
c. Using PIN =
V1+


2
2Z0
1  ΓIN
j
j2

	
and PL =
V1+


2
2Z0
S21
1ΓLS22


2
1  ΓL
j
j2

	
derived earlier,
and given that for available power gain we must have ΓIN = Γs
∗and ΓL = ΓOUT
∗,
calculate the expression for the available power given in section 3.8.1.
3.12 References
[1] C. A. Desoer and E. S. Kuh, Basic Circuit Theory, McGraw-Hill, 2009.
[2] B. D. H. Tellegen, “The Gyrator, a New Electric Network Element,” Philips Research Report, 3, 81–101,
1948.
[3] R. E. Colline, Foundation for Microwave Engineering, McGraw-Hill, 1992.
[4] D. M. Pozar, Microwave Engineering, John Wiley, 2009.
[5] R. Carson, High-Frequency Ampliﬁers, John Wiley, 1975.
[6] K. K. Clarke and D. T. Hess, Communication Circuits: Analysis and Design, Krieger, 1994.
[7] W. H. Hayt and J. A. Buck, Engineering Electromagnetics, 6th edn, McGraw-Hill, 2001.
[8] P. H. Smith, “Transmission Line Calculator,” Electronics, 12, no. 1, 29–31, 1939.
[9] A. Abidi and J. Leete, “De-embedding the Noise Figure of Differential Ampliﬁers,” IEEE Journal of Solid-
State Circuits, 34, no. 6, 882–885, 1999.
3.12 References
205

4
RF and IF Filters
Almost every radio includes one or more ﬁlters for the general purpose of separating a useful
information-bearing signal from unwanted signals such as noise or interferers. We will discuss
the role of ﬁlters and their requirements in Chapter 6 when we talk about distortion. Here we
discuss their properties from a circuit point of view and offer general design guidelines.
There are several types of ﬁlters present in a radio platform:
• RF on-chip ﬁlters, which are typically realized by LC circuits, and are used as standalone
ﬁlters or duplexers, as a part of the ampliﬁer matching circuit, or its tuned load. The amount
of ﬁltering they provide, given the limited quality factor of on-chip elements, is modest but,
nonetheless, very important.
• RF external ﬁlters, which are typically implemented using surface or bulk acoustic wave
elements, and have a very sharp transition and large stopband attenuation.
• IF on-chip ﬁlters that operate at hundreds of kHz to tens of MHz, and are typically realized
by transistors, resistors, and capacitors. They usually provide partial or full channel selection
in the receiver, as well as anti-aliasing for the receiver ADC, or are utilized to suppress the
DAC noise or image in the transmitter.
In this chapter we start by reviewing some of the basic concepts of ﬁlter theory and design.
We turn our attention to LC ﬁlters ﬁrst. While LC ﬁlters, given the inductor size concerns, are
used only at RF, the concepts are applicable to both active and SAW/FBAR ﬁlters that will be
discussed later in the chapter. We also present a detailed discussion of quadrature ﬁlters and
quadrature signal generation, and discuss a brief overview of N-path ﬁlters. The N-path ﬁlters
will be discussed more thoroughly in Chapter 8, as they effectively operate like mixers.
Filter design and circuit synthesis is at least a book of its own, and the purpose of this
chapter is to highlight what is necessary as far as RF design is concerned. More details may be
found in [1], [2], [3], [4].
The speciﬁc topics covered in this chapter are:
• Passive LC ﬁlters
• Active opamp-RC and gm-C ﬁlters
• SAW and FBAR ﬁlters
• Duplexers
• N-path ﬁlters
• Polyphase ﬁlters and quadrature generation
For class teaching, we recommend focusing on selected topics from Sections 4.1, 4.3, and 4.7,
while Sections 4.2, 4.4, 4.5, and 4.6 may be assigned as reading.

4.1
IDEAL FILTERS
..............................................................................................
The transfer function of an ideal bandpass ﬁlter (BPF) as an example is shown in Figure 4.1,
and is described below:
H fð Þ =
ej2πftd
f l  fj j  f h
0
elsewhere
(
:
The ﬁlter has a bandwidth of B = fh – fl with a passband gain of unity, and a constant delay of td.
fh and fl are the cutoff frequencies. Similarly we can deﬁne lowpass (LPF) and highpass ﬁlters
(HPF) by either setting fl = 0, or fh = ∞.
Such an ideal ﬁlter, however, is physically not realizable, as its characteristics cannot be
achieved with a ﬁnite number of elements. We will defer the mathematical proof1 to Problem 3,
and instead provide a qualitative perspective here.
Consider an ideal LPF as an example with a bandwidth of B, whose transfer function is
shown in Figure 4.2, and is equal to
H fð Þ = ej2πftdΠ
f
2B


:
The impulse response will be the inverse Fourier of H(f),
h(t) = 2B sinc[2B(t  td)],
also sketched in Figure 4.2.
Since h(t) is the response to δ(t), and has nonzero values for t < 0, it implies that the output
appears before the input is applied. Such a system is said to be noncausal, and is physically
impossible to realize. This has to do with inﬁnitely sharp transition in the frequency domain,
which results in a time domain response with inﬁnite duration.
Shown in Figure 4.3 is the magnitude of the frequency response of a practical BPF.
The cutoff frequencies fh and fl are typically deﬁned as where the gain drops by √2 or 3dB,
and B = fh – fl is the 3dB bandwidth. More importantly, between the passband and stopband are
transition regions, where the ﬁlter is expected to neither pass nor reject signals. This lies on the
premises that no unwanted signals are expected to exist at such a region. For instance, for a
GSM radio operating at band V, the receiver signal lies between 869–894MHz, whereas the
transmitter (which could potentially act as an interferer) is at 824–849MHz, and thus there is a
20MHz guard-band allowed between the edges of receiver and transmitter frequencies. This
makes the receiver ﬁlter realizable, but comes at the expense of an unoccupied portion of the
spectrum left unused.
1 It mathematically may be proven in the frequency domain using the Paley–Wiener criterion, stating that for a causal
function h(t) with ﬁnite energy,
Ð ∞
∞
LnjH ω
ð Þj
1 + ω2 dω must exist and be ﬁnite. See Problem 3 for more details.
4.1 Ideal Filters
207

4.2
DOUBLY TERMINATED LC FILTERS
..............................................................................................
Traditionally, LC ﬁlters have been realized as reactance two-ports, which are resistively
terminated at both ports (Figure 4.4).
There are several important reasons for this:
– In practice, all physical generators have a nonzero internal impedance, and in most cases the
loads are at least partially resistive.
– Doubly terminated reactive two-ports offer the possibility of simultaneously matching both
the generator and the load to the rest of the system as was shown in the previous chapter.
– They offer the least sensitivity to the components variation [5], [6], [7].
The last point here deserves more explanation. If the two-port is matched to the source, that is,
the impedance looking into the two-port Z1 is made equal to that of the source, then the source
fl
fh
1
0
|H(f)|
1/√2
Passband
Stopband
Stopband
f
Figure 4.3: Practical bandpass ﬁlter frequency
response
fl
f
f
h
1
–fh
–fl
|H(f)|
∠H(f)
Figure 4.1: Frequency response of an ideal BPF
1
|H(f)|
∠H(f)
t
2B
h(t)
td
1/B
B
Figure 4.2: An ideal LPF and its impulse response
208
RF and IF Filters

available power, Pa = VS
j
j2
4RS is entirely absorbed by the two-port. Since the two-port is lossless,
that power is delivered to the load, that is, PL = Pa. This is usually the case around the ﬁlter
passband as is desirable to minimize the loss. Assume now that any element of the two-port, say
the inductor Lk, is slightly varied from its nominal value Lnom.Whether the inductor increases or
decreases, the power delivered to the load is going to decrease. This situation is graphically
illustrated in Figure 4.5.
The important conclusion made here is that in the immediate vicinity of its nominal value, Lk
has little impact on the power delivered to the load, or equivalently the ﬁlter transfer function.
More explicitly, the sensitivity of PL to changes in Lk is zero, or
∂PL
∂Lk
= 0:
This argument can be of course made for any element of the reactive two-port.
There are several reasons as to why the two-port itself is often chosen to be reactive (or LC):
– A reactance two-port can process signal without dissipating any power of its own, keeping
the passband loss ideally zero.
– A reactance two-port exhibits a loss versus frequency characteristic, which can vary very
rapidly with frequency. This is of course crucial in the ﬁlter design.
While the ﬁrst point is rather obvious, the second point above may be clariﬁed by considering
the frequency response of a doubly terminated RC two-port compared to that of an LC circuit as
illustrated in Figure 4.6.
Without the loss of generality, we assume in each case the system has three poles, all real
poles for the case of RC two-port, whereas the LC two-port has one real pole, and a pair of
complex conjugate poles.2
RS
VS
RL
Z1
Z2
+
V2
–
+
V1
–
I1
I2
Lk
Ck
Reactance Two-Port
Figure 4.4: A doubly terminated reactive two-port
PL
Lk
Pa
Lnom
Figure 4.5: Power delivered to the output as a function of the LC
two-port inductance
2 It can be shown that any RC network can have only real poles, whereas RLC networks can have real or complex poles.
4.2 Doubly Terminated LC Filters
209

The voltage transfer function may be written as
AV sð Þ =
A0
s  p1
ð
Þ s  p2
ð
Þ s  p3
ð
Þ ,
and the magnitude of the transfer function is
AV jω
ð
Þ
j
j =
A0
j
j
jω  p1
ð
Þ
j
j jω  p2
ð
Þ
j
j jω  p3
ð
Þ
j
j =
A0
j
j
d1d2d3
,
where di is the distance from the pole pi to an arbitrary point on the jω axis. For the RC network,
the magnitude of the transfer function is maximum at DC (ω = 0), as the length of all the three
vectors d1, d2, and d3 is minimum. As we move up along the jω axis, that is to say, as the
frequency increases, |AV(jω)| monotonically reduces. The LC circuit has a local maximum at
DC, as well as another local maximum around the complex poles ordinate, ωd, as the length
of d1 (or d2) is minimum. In either case, the transfer function magnitude has a local maxima
around the pole frequency, but in the case of the RC circuit, since all the poles are real, this
happens only at DC. Furthermore, around the pole there is a sharp variation in the frequency
response, and clearly the LC two-port is advantageous from this point of view, as complex
poles with ordinate around the passband create sharp transition to stopband. This also gives us a
useful recipe as to how design the ﬁlter: place poles with ordinates around the passband edge
close to jω axis to create a sharp transition.
Example: Shown in Figure 4.7 is the frequency response of the following two transfer
functions:
H1 sð Þ =
1
s + 1
ð
Þ s2 + s + 1
ð
Þ
H2 sð Þ =
6
s + 1
ð
Þ s + 2
ð
Þ s + 3
ð
Þ :
j
Im[s]
Re[s]
d3
d2
d1
RC Two-Port
j
Im[s]
Re[s]
d3
d2
d1
LC Two-Port
p1
p2
p3
p1
p2
p3
–j
d
w
w
w
Figure 4.6: Magnitude of transfer function of RC and LC two-ports based on their pole location
210
RF and IF Filters

They both have a real pole at 1, whereas H1 has a pair of complex conjugate poles at
1j ﬃﬃ
3
p
2
, while H2 has two additional real poles at 2, and 3. The transfer function are
normalized to have a magnitude of 1 at DC. The two transfer functions both drop at a rate
proportional to 1
ω3 at high frequencies, but clearly H1 has a ﬂatter passband with sharper
stopband transition.
In summary, since RC two-ports have all of their poles on the σ axis, they show large
passband droop with modest stopband sharpness. The LC two-port on the other hand can have
complex poles arbitrarily close to the jω axis. A similar argument may be made for the RL
networks as well.
4.2.1
Transducer Parameters
Consider the doubly terminated LC circuit shown in Figure 4.4, consisting of a lossless (LC)
network (representing the ﬁlter) terminated to a source and a load. VS represents the RMS value
of the source voltage.
Assuming the impedances looking into the right and left of the lossless circuit are Z1 and Z2
respectively, we deﬁne the input and output reﬂection factors as
ρ1≜RS  Z1
RS + Z1
ρ2≜RL  Z2
RL + Z2
,
which is slightly different from the one we introduced in the previous chapter (ρ1 was deﬁned
as Z1RS
Z1 + RS, which is negative of the one above, and so on), but it is more consistent with ﬁlter
design textbooks.
Frequency, rad/s
1
Magnitude, dB
–30
0
2
–40
–20
–10
3
4
5
Complex (H1)
Real (H2)
0
1/
3
w
Figure 4.7: Magnitude of two transfer
functions, one with complex poles, the
other with all real poles
4.2 Doubly Terminated LC Filters
211

Using the power balance argument, we showed in the previous chapter that
|ρ1| = |ρ2|,
which is to say, if one port is matched, say Z1 = RS, the other port is automatically matched too,
that is, Z2 must be equal to RL.
We also deﬁned the voltage gain as
AV≜V2
VS
,
and the transducer factor as
H sð Þ≜1
2
ﬃﬃﬃﬃﬃ
RL
RS
r
1
AV sð Þ :
Given that the source available power is Pa = VS
j
j2
4RS , and the power delivered to the load is
PL = V2
j
j2
RL , then
Pa
PL
=
VS
j
j2
4RS
V2
j
j2
RL
= 1
2
ﬃﬃﬃﬃﬃ
RL
RS
r
1
AV


2
= H jω
ð
Þ
j
j2  1:
Since the LC network is lossless, the power delivered it to its input is always equal to the power
delivered to the load, that is, P1 = PL. On the other hand, P1  Pa. The difference,
Pr = Pa  P1,
is known as the reﬂected power, that is, the amount of power not delivered to the network when
it is not matched. This is graphically shown in Figure 4.8.
To ﬁnd the relation between the available power and the reﬂected power, we can write
Pr =Pa  P1 = VS
j
j2
4RS
 Re Z1
½

VS
RS + Z1


2
= VS
j
j2
4RS
RS +Z1
j
j2  4RSRe Z1
½

RS + Z1
j
j2
= VS
j
j2
4RS
RS  Z1
RS + Z1


2
or
Pr = |ρ1|2Pa.
This can be physically explained knowing that P1 = Pa only when the input is matched, that is,
when |ρ1| = 0.
Load
Generator
Pa
PL=P1
Pr
Lossless 2-Port
P1
Figure 4.8: Power ﬂow from the source to load in a lossless two-port
212
RF and IF Filters

Next we introduce the characteristic function, K(s), of the terminated two-port
K(s) ≜ρ1(s)H(s),
or in the jω domain
K
j j2 = ρ1
j
j2 H
j j2 = Pr
Pa
Pa
PL
= Pr
PL
= Pa  PL
PL
= H
j j2  1,
which leads to the Feldtkeller equality:
|H|2 = 1 + |K|2.
Since H(s) and K(s) are real rational functions of s, |H(jω)|2 = H(jω)H(jω), and |K(jω)|2 = K
(jω)K(jω). Replacing jω by s, we can rewrite the Feldtkeller equation in a more familiar form:
H(s)H(s) = 1 + K(s)K(s).
Example: Consider the circuit shown in Figure 4.9, representing a 3rd-order Butterworth
ﬁlter.
Using a mesh current analysis, we can write
1 + s + 1
2s
1
2s
1
2s
1 + s + 1
2s
2
664
3
775
I1
I2


=
VS
0


,
and
AV = V2
VS
= I2
VS
= Δ12
Δ =
1
2
s + 1
ð
Þ s2 + s + 1
ð
Þ ,
where Δ12 and Δ are the mesh matrix cofactor and determinant [8]. Thus, by deﬁnition
H sð Þ = 1
2
ﬃﬃﬃﬃﬃ
RL
RS
r
1
AV sð Þ = s + 1
ð
Þ s2 + s + 1

	
= s3 + 2s2 + 2s + 1:
Clearly, |H|2 = ω6 + 1  1. In fact |H| equals one only at DC, where the lowpass LC circuit
is a short, and the load and source are matched.
Continued
1Ω
VS
Z1
Z2
+
V2
–
+
V1
–
I1
I2
1H
1H
2F
1Ω
Figure 4.9: A 3rd-order Butterworth ﬁlter
4.2 Doubly Terminated LC Filters
213

Similarly, the admittance looking to the right of the source is
Y = I1
VS
= Δ11
Δ =
2s2 + 2s + 1
2 s + 1
ð
Þ s2 + s + 1
ð
Þ :
Thus,
Z1 = 1
Y  1 = 2s3 + 2s2 + 2s + 1
2s2 + 2s + 1
:
The reﬂection factor is then readily calculated to be
ρ1 sð Þ = 1  Z1
1 + Z1
=
s3
s3 + 2s2 + 2s + 1 :
As expected, |ρ1| = 0 at DC. Also note that the denominator of ρ1(s) is the same as the
numerator of H(s). This will be proven for a general case in the next section.
Finally, the characteristic function is
K(s) = ρ1(s)H(s) =  s3.
Now assuming |VS| = 2V RMS, the source available power would be
Pa = VS
j
j2
4RS
= 1W:
To ﬁnd the reﬂected power and the power delivered to the load at ω = 1rad/s, we have
ρ1 jω
ð
Þ
j
j2 =
ω6
ω6 + 1 ,
which gives Pr = ρ1 j1
ð Þ
j
j2Pa = 1
2 W, and PL = Pa  Pr = 1
2 W. Alternatively, |H(j1)|2 = 2,
which yields the same PL =
Pa
H j1
ð Þ
j
j2 = 1
2 W. We will shortly see that ω = 1rad/s is the ﬁlter
3dB passband edge, which justiﬁes why at this frequency only half of the power is absorbed
at the output.
4.2.2
Relation between Transducer and Immittance3 Parameters
It is common to express any two-port through its impedance or admittance parameters, as
typically that’s how the two-port and ultimately the ﬁlter are synthesized. With reference to
Figure 4.10, using the impedance (or z) parameters for instance, there are two constraints set on
the two-port input/output voltages/currents, and two additional constraints set by the source and
load as the following:
V1 = z11I1 + z12I2
V2 = z21I1 + z22I2
Vs = V1 + RsI1
V2 =  RLI2,
3 “Immittance” is a term coined by Bode describing either an impedance or an admittance.
214
RF and IF Filters

where z11, z12, z21, and z22 are the two-port z parameters. It must be noted that z11 and z22 are the
driving point input and output impedances when the other port is left open. Furthermore, since
the two-port is reciprocal, z12 = z21.
It follows that (see also Problem 16)
H sð Þ = z11 + Rs
ð
Þ z22 + RL
ð
Þ  z122
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RsRL
p
z12
and
K sð Þ = Rs  z11
ð
Þ RL + z22
ð
Þ + z122
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RsRL
p
z12
:
Now with H(s) and K(s) known based on certain ﬁlter characteristics (passband loss,
stopband rejection, etc.), one can determine the two-port z parameters. At ﬁrst, this may
seem an impossible task, as it involves solving two equation (H(s) and K(s)) for three
unknowns (z11, z12, and z22). However, since zijs specify the impedance parameters of a
reactance two-port, they are all odd rational functions of s. While this can be mathematic-
ally proven [3], [9] by Tellegen’s theorem [8], it can be physically justiﬁed considering that
a reactance network is lossless, and thus neither dissipates nor generates power. This
requires Re[zij(jω)] = 0 for all ω, which means zij(s) must be an odd function of s. With
that, and by identifying the even and odd parts of H(s), and K(s) (He, Ho, and Ke, Ko
respectively), it follows
z11 = Rs
He  Ke
Ho + Ko
z22 = RL
He + Ke
Ho + Ko
z12 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RsRL
p
Ho + Ko
:
Note that there are now four equations in terms He, Ho, Ke, and Ko, but the same three
unknowns. However, the four functions He, Ho, Ke, and Ko are related given the Feldtkeller
equality.
A similar expression can be developed in terms of the two-port y or ABCD (chain or
transmission) parameters [3]:
Lossless
2-port
RS
VS
RL
Z1
Z2
+
V2
–
+
V1
–
I1
I2
Figure 4.10: Double-terminated lossless two-port
4.2 Doubly Terminated LC Filters
215

Example: For the previous ﬁlter of Figure 4.9, it is easy to show that for the π-LC
network (Figure 4.11):
z11 = z22 = s + 1
2s = 2s2 + 1
2s
z12 = 1
2s :
On the other hand, since we already have the transducer and characteristic functions from
the previous section, we can write:
He = 2s2 + 1
Ho = s3 + 2s
Ke = 0
Ko =  s3:
Consequently,
z11 = Rs
He  Ke
Ho + Ko
= 2s2 + 1
2s
z12 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RsRL
p
Ho + Ko
= 1
2s :
These results of course match the ones calculated directly from the LC two-port. The
difference is that we do not have the actual LC circuit to begin with; rather what is known
is the characteristic or transducer functions for a given ﬁlter requirements. Once the z
parameters are obtained as shown above, then one can synthesize the corresponding LC
circuit, and not the other way around.
4.2.3
Transducer Parameters Properties
Next, we will discuss the properties of the transducer and characteristic functions from physical
point of view. This is important, since what is given in the course of the ﬁlter design is typically
the characteristic function. On the other hand, once K(s) is determined given a certain ﬁlter
characteristics (we will deal with this in the next section), one must ensure that it is realizable,
and if so, how it can be implemented.
1H
1H
2F
Figure 4.11: The LC section of the example of Figure 4.9
216
RF and IF Filters

4.2.3.1 Positive Real Property
Before we get to the properties of the transducer parameters, it must be emphasized that for
minimum z11 and z22 representing the open port driving impedances of the lossless two-port (as
well as Z1 and Z2, the terminated impedances) must be realizable impedances. The realizability
conditions for an RLCM one-port impedance (or admittance) was ﬁrst given by Otto Brune4 in
his classical 1931 paper [10] as follows:
An impedance function Z(s) is realizable using lumped RLCM elements (Figure 4.12) if and
only if it is a positive real (PR) function, that is,
1. Z(s) is a real rational function of s
2. Re[Z(s)]  0 if Re[s]  0
The proof is through stability argument [9], [10], or by Tellegen’s theorem [3], and will be
skipped here. Note that these are both necessary and sufﬁcient conditions. The sufﬁciency
follows from a synthesis algorithm developed by Brune that can successfully realize any PR
impedance using positive RLCM elements.
The conditions above, though elegant and concise, are somewhat useless from a practicality
point of view. There are several equivalent conditions, the most notable one being
1. Z(s) is a real rational function of s.
2. Re[Z(jω)]  0 for all ω.
3. All poles of Z(s) are in the closed5 left half-plane (LHP) of the s-plane. All the jω axis poles
(including zero and inﬁnity) must be simple with positive real residues.6
The second condition is simply justiﬁed considering that the power dissipated in the RLCM one-
port (assuming positive elements of course) must be positive or zero, and is easily deduced from
the original PR second condition. While the proof of the third condition is beyond the scope of
our RF book, one can tie that to the stability requirement of the RLCM one-port: Poles in the RHP
of the s-plane lead to terms like eαt (α > 0) in the impulse response of the one-port, while multiple
jω axis poles lead to terms like tn cos(ωt + φ) (n  1), both of which grow indeﬁnitely as t ! ∞.
The simplicity of the poles of Z(s) (or Y sð Þ =
1
Z sð Þ) at inﬁnity necessitates that the degree of
the numerator and denominator of Z(s) differ by no more than one, a condition that again may
be physically justiﬁed by examining the RLCM impedances at very high frequencies (see
Problem 9).
RLCM
Z(s)=1/Y(s)
Figure 4.12: An RLCM one-port
4 Otto Brune completed his Ph.D. at MIT in 1929. His Ph.D. work, later published in [10], is one of the key contributions to
modern network synthesis.
5 Inside the LHP or on the jω axis, including zero and inﬁnity.
6 Residues of partial fraction of Z(s). If Z sð Þ = N sð Þ
D sð Þ =
N sð Þ
sp1
ð
Þ sp2
ð
Þ... =
K1
sp1
ð
Þ +
K2
sp2
ð
Þ + . . ., then K1 is a residue of p1. If p1 lies
on jω axis, then K1 must be real and positive to satisfy the third equivalent condition.
4.2 Doubly Terminated LC Filters
217

In the case of z11 and z22 representing the driving point impedances of a reactive circuit, it is
easy to show that all the poles and zeros lie on the jω axis (in conjugate pairs), and of course are
simple with positive real residues. As stated earlier, z11(s) and z22(s) are odd rational functions
of s, or z11(jω) and z22(jω) are purely imaginary.
Example: Z sð Þ = 2s2 + 1
2s3 + 2s is a PR function, and since it is odd, it is a reactance function. If
expanded by partial fraction,
Z sð Þ = 2s2 + 1
2s3 + 2s =
1
2
s +
1
2 s
s2 + 1 =
1
2
s +
1
4
s + j +
1
4
s  j :
Thus, all the poles are simple on the jω axis, with positive real residues. Of course,
Re[Z(jω)] = 0.
From the partial fraction expansion (generally known as Foster’s method of synthe-
sis),7 since,
Z sð Þ =
1
2
s +
1
2 s
s2 + 1 =
1
2
s +
1
2s + 2
s
,
then the circuit representing Z(s) consists of a capacitor in series with an LC parallel
circuit, as shown in Figure 4.13 left. It is clear that if the residue condition is not met, it
would lead to complex or negative values of the inductors or capacitors.
While the topic of synthesis is well beyond the scope of this chapter, one can show that by
using Cauer’s method8 (removing poles of Y sð Þ =
1
Z sð Þ at inﬁnity) the LC circuit on the right is
obtained, which represents a 3rd-order Butterworth ladder ﬁlter as will be discussed shortly.
Clearly, unlike analysis, the synthesis does not lead to a unique answer.
It is interesting to point out that for any reactance function, with Z(jω) = jX(jω), we can show
d
dω X > 0 for all ω (see Problem 11 for the proof ). Consequently, the poles and zeros are located
2F
1/2H
2F
2H
1F
1F
Partial Fraction (Foster)
Pole Removal (Cauer)
Figure 4.13: Two possible
realizations of the impedance
Z sð Þ = 2s2 + 1
2s3 + 2s
7 Ronald Martin Foster was a Bell Labs engineer who made signiﬁcant contributions to the ﬁeld of circuit synthesis and ﬁlter
design.
8 Wilhelm Cauer was a German mathematician and scientist who sadly was executed by Soviet soldiers in 1945 at the end of
World War II during the fall of Berlin. He was the co-supervisor of Brune (along with Ernst Guillemin), and is most noted
for his signiﬁcant contributions to circuit synthesis and ﬁlter theory.
218
RF and IF Filters

interlaced on the jω axis [11], as shown in Figure 4.14. This is certainly true for the previous
example where there are two zeros at
ﬃﬃ
2
p
2 , and ∞, and two poles at 0 and 1.
With this background, let us derive other properties of the transducer function of the double-
terminated LC ﬁlter.
4.2.3.2 Realizability Conditions for Transducer Parameters
While z11 and z22 must be PR impedances, there are additional requirements for the two-port
impedance, as well as its transducer parameters to be realizable.
Listed below are the conditions under which the transducer function, H sð Þ = E sð Þ
P sð Þ, is realiz-
able. A detailed proof may be found in [3], and we will just offer a physical justiﬁcation here.
1. The numerator (E(s)) and the denominator (P(s)) are polynomials with real coefﬁcients.
2. The numerator (E(s)) is a strictly Hurwitz polynomial,9 that is all of its roots are on the left-
half of the s-plane (LHP). This is justiﬁed from a stability point of view.
3. |H(jω)|  1 for all ω.
4. P(s) is either an even or an odd polynomial, unless common factors of P(s) and E(s) cancel.
This follows from H sð Þ =
z11 + Rs
ð
Þ z22 + RL
ð
Þz122
2 ﬃﬃﬃﬃﬃﬃﬃ
RsRL
p
z12
, and that zijs are odd functions of s. Multiply-
ing by the common denominator of z11, z12, and z22 leaves an either odd or even denomin-
ator for H(s).
The degree of E(s) must be greater or equal than that of P(s). If not, for sufﬁciently large ω,
|H(jω)| will become less than one, violating the third condition.
Now let us consider K sð Þ = F sð Þ
P sð Þ. The expressions derived earlier for K(s) and H(s) in terms of
the two-port z parameters have both z12 in their denominator, and we therefore suspect K(s) and
H(s) have the same denominator, P(s). Furthermore, from Feldtkeller equality,
E(s)E(s) = F(s)F(s) + P(s)P(s).
Since the reﬂection factor, ρ1 sð Þ = K sð Þ
H sð Þ, then ρ1 sð Þ = F sð Þ
E sð Þ. Also as |ρ1(jω)|  1, then the degree
of E(s) must be greater than or equal to that of F(s) as well.
X( )
dX/d  > 0
w
w
w
•
Figure 4.14: Poles and zeros of a
reactance function
Z sð Þ =
s s2 + 2
ð
Þ
s2 + 1
ð
Þ s2 + 4
ð
Þ


interlaced on
the jω axis
9 In a strictly Hurwitz polynomial, all the zeros (or roots) happen either on the negative σ axis or in conjugate pairs inside
LHP. Thus, all the coefﬁcients of the polynomial must be positive, with no missing terms. This is, however, only a
necessary condition. See Problem 10 for an example.
4.2 Doubly Terminated LC Filters
219

4.2.3.3 Physical Interpretation of the Poles and Zeros of Transducer Function
On the second condition, since
H
j j2 = Z1 + Rs
j
j2
4RsRL
,
the only way for H(s) and consequently E(s) to be zero is if Z1(s) =  Rs. Now since Z1(s) is a
realizable impedance, it must be positive real, and can be negative only if Re[s] < 0, which
implies E(s) is strictly Hurwitz. Additionally, since H
j j2 = Pa
PL, E(s) = 0 requires the simultan-
eous physical condition of a nonzero output with a zero source voltage. Therefore the zeros of
E(s) are the nonzero natural frequencies of the network. It is now clear why these zeros must be
in open LHP.
The poles of K(s), which are also the poles of H(s), are the zeros P(s). At these frequencies,
|H| becomes inﬁnite, which implies no power is delivered to the output ( H
j j2 = Pa
PL, thus PL = 0),
or the loss becomes inﬁnite. Therefore, the zeros of P(s) are often called transmission zeros or
loss poles, and are a critical part of the ﬁlter design. If E(s) is of higher degree than that of P(s),
then ω ! ∞is a loss pole.
There is no restriction for the zeros P(s) to be in the LHP, but since P(s) have real
coefﬁcients, they must either be real or appear in complex conjugate pairs.
Example: Consider the same network of the example of Figure 4.9, where K(s) =  s3
was obtained. As we will see in the next section, this represents the characteristic
function of a 3rd-order maximally ﬂat (or Butterworth) ﬁlter. We wish to ﬁnd the
transducer function not having any knowledge of the actual circuit. Using the Feldtkel-
ler equation,
H(s)H(s) = 1 + K(s)K(s) =  s6 + 1,
the function H(s)H(s) =  s6 + 1 has six zeros grouped on the unity circle as shown in
Figure 4.15.
j
–1
1
+j√3/2
–j√3/2
–1/2
+1/2
/3
w
s
p
Figure 4.15: Zero location of the function s6 + 1
220
RF and IF Filters

Now, knowing that the zeros of H(s) must all be on the LHP, then for H(s) we choose
only the three zeros on the LHP, and assign the other three on the RHP to H(s). Thus,
H sð Þ = s + 1
ð
Þ s + 1 + j
ﬃﬃﬃ
3
p
2


s + 1  j
ﬃﬃﬃ
3
p
2


= s + 1
ð
Þ s2 + s + 1

	
,
which is the same result previously obtained.
4.2.4
Specifying the Filter
We showed earlier that an ideal ﬁlter cannot be implemented with a ﬁnite number of elements,
and hence given a certain requirement, the ﬁlter characteristic must be approximated with
realizable transducer parameters.
In most cases (unless the phase or time response of the ﬁlter is prescribed)10 the ﬁlter is
deﬁned through its transducer loss α, as follows:
α(ω) = 10 log10(|H(jω)|2) = 10 log10(1 + |K(jω)|2).
The ﬁlter is expected to have minimum loss in its passband, and hence H jω
ð
Þ
j
j2 = Pa
PL  1 (the
source available power is mostly absorbed by the load), whereas at stopband, it blocks the
source power reaching the load, and hence |H(jω)|2 ! ∞, or the loss is inﬁnite. A typical
lowpass ﬁlter transducer loss is illustrated in Figure 4.16 as an example.
The transducer loss is expected to be small (ideally zero) in the passband, and very large
in the stopband. For a practical ﬁlter, there is of course a transition region in between.
Generally the smaller the transition region, the sharper the ﬁlter, and the closer we become
to an ideal ﬁlter.
For example, a lowpass ﬁlter for WLAN applications may be speciﬁed as follows:
α  0:5dB
for
0  f  8:5MHz
α  40dB
for
35MHz  f  ∞,
(
or equivalently, αp = 0.5dB, ωp = 2π  8.5MHz, αs = 40dB, and ωs = 2π  35MHz.
The next step would be to ﬁnd the suitable transducer parameters. The branch of circuit
theory that deals with this is known as approximation theory, and is brieﬂy discussed next.
Knowing the transducer loss, it is possible to determine either |H(jω)|2 or |K(jω)|2. It is
however usually advantageous to ﬁnd |K(jω)|2, due to the similarity between transducer loss,
and characteristic function frequency behavior: in passband, α(ω)  0, and so is |K(jω)|2,
while in stopband both α(ω) ! ∞and |K(jω)|2 ! ∞. This allows us to readily determine the
pole and zero locations of K(s): put zeros in K(s) within the passband, and poles within the
stopband.
10 If we are interested in phase or group delay, Tphase ω
ð Þ = β ω
ð Þ
ω = 1
ω tan1 Im H jω
ð
Þ
½

Re H jω
ð
Þ
½
, and Tdelay ω
ð Þ = dβ ω
ð Þ
dω are commonly used.
4.2 Doubly Terminated LC Filters
221

Example: Suppose we would like to have a lowpass ﬁlter with a passband of 0  ω  1,
and a stopband of ω  3. Then one may choose
K sð Þ = K0
s  z1
ð
Þ s  z2
ð
Þ s  z3
ð
Þ s  z4
ð
Þ
s  p1
ð
Þ s  p2
ð
Þ s  p3
ð
Þ s  p4
ð
Þ :
To satisfy the passband and stopband values, we further select z1 = z2
∗= j0.25, z3 = z4
∗=
j0.75, p1 = p2
∗= j3.5, and p3 = p4
∗= j5.5. Setting K0 to 200, we have
K jω
ð
Þ = 200 ω2 + 0:252

	
ω2 + 0:752

	
ω2 + 3:52

	
ω2 + 5:52

	 :
Figure 4.17 shows the plot of the transducer loss versus frequency, which is well within
the requirements, and conﬁrms the effectiveness of the aforementioned pole/zero distri-
bution.
There are generally two ways of approximating the ﬁlter loss with what is ideally needed:
1. To compare the two functions and their ﬁrst n  1 derivatives at one speciﬁc point of the
independent variable (in the case of ﬁlter that would be frequency).
( )
p
s
p
s
Passband
Stopband
Transition
w
w
w
w
a
a
a
Figure 4.16: Transducer loss of a typical lowpass ﬁlter
1
Frequency, rad/s
Loss, dB
20
40
60
70
2
3
4
5
6
7
50
30
10
Figure 4.17: Loss response of
a ﬁlter with
K jω
ð
Þ = 200
ω2 + 0:252
ð
Þ ω2 + 0:752
ð
Þ
ω2 + 3:52
ð
Þ ω2 + 5:52
ð
Þ
222
RF and IF Filters

2. To evaluate the maximum deviation between the two functions in a range of the independent
variable.
In the ﬁrst criterion, known as the maximally ﬂat approximation [12], at certain frequency
ω = ω0 we must have
Fspec ω0
ð
Þ = Fapprox ω0
ð
Þ
dFspec ω0
ð
Þ
dω
= Fapprox ω0
ð
Þ
dω
...
dn1Fspec ω0
ð
Þ
dωn1
= dn1Fapprox ω0
ð
Þ
dωn1
:
We take up to the n  1 derivatives since an nth-order ﬁlter gives us n degrees of freedom. The
second criterion, known as the equal ripple approximation, suggests that the maximum absolute
error
Error = max |Fspec(ω)  Fapprox(ω)|
be minimized in a range of ω1  ω  ω2. Assuming again an nth-order ﬁlter, this usually
happens if the error function has n + 1 equal alternating extrema (minima and maxima) in the
range of ω1  ω  ω2. The two criteria are compared against in Figure 4.18.
As a case study, we will discuss the maximally ﬂat criterion next in some details, and brieﬂy
go over the equal ripple case as well.
4.2.4.1 Maximally Flat Approximation
A simple yet effective way of ﬁnding a realizable function is to carry out the maximally ﬂat (or
Butterworth)11 approximation at ω = 0. We ﬁrst observe that wherever dkα
dωk is zero, so is dk K
j j2
dω2k
0
Fspec
Fapprox
0
Maximally Flat
Equal Ripple
|Fspec–Fapprox|
|Fspec–Fapprox|
Fspec
Fapprox
w
w
w
w
w
w
Figure 4.18: Illustration of maximally ﬂat and equal ripple approximation
11 Stephen Butterworth (1885–1958) was a British physicist and mathematician who invented Butterworth ﬁlters.
4.2 Doubly Terminated LC Filters
223

(k = 0, 1, . . ., n  1). If one chooses |K|2 to be a polynomial rather than a rational function, that
is to say
|K|2 = Cnω2n + Cn  1ω2n  2 + . . . + C0,
then maximally ﬂat condition requires all the coefﬁcients to be zero except for Cn. Thus,
K
j j2 = Cnω2n
K sð Þ = 
ﬃﬃﬃﬃﬃﬃ
Cn
p
sn:
From the Feldtkeller equation,
H(s)H(s) = 1 + (1)nCns2n.
The zeros of H(s) that are the natural frequencies of the network thus lie on a unity circle in
LHP as shown in Figure 4.19.
The transducer loss is
α(ω) = 10 log(1 + |K(jω)|2) = 10 log (1 + Cnω2n),
which is plotted in Figure 4.20 for various values of n, with Cn = 1.
A higher order not only gives a higher stopband loss but also exhibits more passband
ﬂatness. The order of the ﬁlter is naturally a function of the required passband and stopband
loss, and must be such that (see Figure 4.16)
10 log 1 + Cnωp
2n

	
 αp
10 log 1 + Cnωs
2n

	
 αs:
Combining the two equations, with a few simple algebraic steps we have
n 
log 1
k1
log 1
k
=
log
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
10αs=10  1
10αp=10  1
s
log ωs
ωp
,
where k1≜
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
10αp=101
10αs=101
q
is the discrimination parameter, and k≜ωp
ωs is the selectivity factor.
j
–1
1
π/4
π/8
π/8
w
s
Figure 4.19: Natural frequencies and their mirror image of a 4th-order
Butterworth ﬁlter
224
RF and IF Filters

Alternatively, one can ﬁnd the ﬁlter order through ﬁlter design handbooks [13], [14], [15],
MATLAB,12 or ﬁlter design software, many of which are available online.
Example: For the WLAN ﬁlter example earlier, we had αp = 0.5dB, ωp = 2π  8.5MHz,
αs = 40dB, and ωs = 2π  35MHz. Thus n 
log
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
10
40
10  1
10
0:5
10  1
s
log35
8:5
= 3:99. So a 4th-order Butter-
worth ﬁlter meets the speciﬁcations.
Once the ﬁlter order is known, so are the loci of the H(s) zeros, which are the network natural
frequencies (Figure 4.19). For instance, for a 2nd-order maximally ﬂat ﬁlter (with 1Ω termin-
ation),
with
K(s) =  s2,
the
zeros
of
H(s) H(s) = 1 + s4
will
be
at
sk =
ejπ(n  1 + 2k)/2n, where n = 4 and k = 0, 1, 2, 3. Selecting the two zeros that lie on the LHP,
H sð Þ =
s +
ﬃﬃﬃ
2
p
+ j
ﬃﬃﬃ
2
p
2


s +
ﬃﬃﬃ
2
p
 j
ﬃﬃﬃ
2
p
2


= s2 +
ﬃﬃﬃ
2
p
s + 1:
Consequently,
z11 = Rs
He  Ke
Ho + Ko
=
1ﬃﬃﬃ
2
p
s
z22 = RL
He + Ke
Ho + Ko
= 2s2 + 1
ﬃﬃﬃ
2
p
s
z12 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RsRL
p
Ho + Ko
=
1ﬃﬃﬃ
2
p
s
:
Frequency, rad/s
Loss, dB
5
1
10
15
20
25
3
n=1
n=2
n=3
n=4
n=5
Figure 4.20: Loss response of 1st- to
5th-order Butterworth ﬁlter
12 MATLAB (Matrix Laboratory) is a numerical computing environment developed by MathWorks. Among its many
capabilities, it has an extensive ﬁlter design library.
4.2 Doubly Terminated LC Filters
225

The ﬁlter circuit is illustrated in Figure 4.21. We will show in the next section how the LC ﬁlter is
obtained knowing its impedance matrix. However, in this simple case of a 2nd-order, one may
realize the ﬁlter using the T equivalent of the LC two-port as shown on the right.
The reader can verify that the z parameters above correspond to the LC circuit of Figure 4.21.
The ﬁlter is normalized, e.g., its 3dB bandwidth is 1rad/s, with impractical values of inductors and
capacitors. The ﬁlter scaling subject will be covered in Section 4.2.6.
4.2.4.2 Equal Ripple Approximation
In the case of equal ripple approximation, we are interested to minimize the absolute error in a
certain range of say 0  ω  ωp, i.e., the ﬁlter passband. For convenience, we may choose
ωp = 1rad/s, and subsequently scale the ﬁlter to match our needs (Section 4.2.6). The desired
oscillatory behavior in Figure 4.18 suggests a squared and horizontally compressed trigono-
metric function, for instance, something like
|K|2 = kp
2 cos2nu(ω),
where
u(ω) = cos1ω.
Upon expansion (see Problem 14), it can be shown that |K|2 is in fact a polynomial in ω2, which
oscillates between 0 and kp
2 for 1  ω  + 1, taking on the value 0 n times, and the value of
kp
2 n + 1 times. Furthermore, |K|2 tends to monotonically increase with frequency, approaching
kp
222n  2ω2n as ω ! ∞as desired. In fact, for ω  1,
K
j j2 = kp2
4
ω +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ω2  1
p

n
+ ω +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ω2  1
p

n
h
i2
:
Given these properties, the ﬁlter prescribed as above satisﬁes our requirements. Besides the
ﬁlter degree, unlike the Butterworth ﬁlter, there is an additional degree of freedom set by the kp
that determines the maximum passband ripple as follows:
αp = 10 log(1 + kp
2).
The loss function of a 4th- and a 5th-order ﬁlter is plotted in Figure 4.22 for αp = 1dB.
√2H
1Ω
VS
√2F
1Ω
LC Filter
+
V2
–
Z11–Z12
Z12
Z22–Z12
LC Filter T Network
√2F
√2H
Figure 4.21: Second-order Butterworth ﬁlter schematic
226
RF and IF Filters

The ﬁlters that have |K|2 = kp
2 cos2(n cos1ω) are known as Chebyshev ﬁlters after the
mathematician ﬁrst analyzing the properties of the polynomials cos(n cos1x), known as
Chebyshev polynomials.13
At high frequencies, for a Butterworth ﬁlter, the loss may be approximated as
α  10 log Cnω2n = 10 log Cn + 20n log ω.
For an nth-order Chebyshev ﬁlter, assuming kp
2 = Cn to have the same passband loss at ω = 1,
then
α  10 log kp
222n  2ω2n = 10 log Cn + 20n log ω + 6.02(n  1).
The ﬁrst two terms are the same, but there is an additional term, 6.02(n  1), that accounts for
more stopband loss with the same degree for the Chebyshev ﬁlter. This suggests that the
Chebyshev implementation is a lot more efﬁcient than Butterworth, which is very desirable in
many applications. This comes at a cost though, as there is more phase variation associated with
the Chebyshev ﬁlters. A comparison between various degrees of Chebyshev (labeled as C) ﬁlter
with a 3rd-order Butterworth (labeled as B3) is shown Figure 4.23.
With a similar procedure as before, we can show that the order of the Chebyshev ﬁlter
follows from
n 
cosh1 1
k1
cosh1 1
k
=
cosh1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
10αs=10  1
10αp=10  1
s
cosh1 ωs
ωp
:
Frequency, rad/s
Loss, dB
1
1
2
3
4
n=4
n=5
Figure 4.22: Passband transducer loss of a
normalized Chebyshev ﬁlter
13 Pafnuty Lvovich Chebyshev (1821–1894) was a Russian mathematician.
4.2 Doubly Terminated LC Filters
227

Example: Back to the WLAN ﬁlter example, 1
k = 35
8:5 = 4:12,
1
k1 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1040=101
100:5=101
q
= 286:26,
which leads to n 3.03. So still a 4th-order ﬁlter is needed, but n= 3 marginally works as well!
Finally, it can be shown that [1], [3], [9] the zeros of H(s) lie on an ellipse, with half axes
a1=n + a1=n
2
and a1=na1=n
2
, where a = 1
kp +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
kp2 + 1
q
, as shown in Figure 4.24.
Once the zeros are found, then H(s), and ultimately the LC ﬁlter z parameters are determined.
The hand calculations may be tedious, and one can readily use the aforementioned tables or
ﬁlter software.
A closely related ﬁlter known as inverse Chebyshev may be obtained by replacing ω with
ω1 and |K|2 with |K|2 in the original |K|2 = kp
2 cos2(n cos1ω) equation. Thus
K
j j2 =
ks2
cos2 n cos1 1
ω

 :
Frequency, rad/s
1
C4
C5
C3
B3
C2
2
3
Loss, dB
10
20
30
40
50
60
Figure 4.23: Comparison between
Chebyshev ﬁlters of different order and a
3rd-order Butterworth ﬁlter
j
(a1/n–a–1/n)/2
(a1/n+a–1/n)/2
w
s
Figure 4.24: Natural frequencies of a 4th-order Chebyshev ﬁlter
228
RF and IF Filters

What is given now is the minimum stopband loss ks (or αs = 10 log(1 + ks
2)), and the unit
frequency is the stopband limit frequency (Figure 4.25).
The ﬁlter has the same degree as the Chebyshev for a given passband/stopband loss, but has
transmission zeros (or loss poles) at ﬁnite frequencies (ω1 and ω2 in Figure 4.25). This makes
the ﬁlter synthesis somewhat more difﬁcult, but provides ﬂexibility and advantages in many
applications.
4.2.4.3 General Stopband Filters
Important in many applications, a generalization of Chebyshev ﬁlters is provided by a class of
ﬁlters with equal ripple passband loss, and ﬁnite loss poles. The mathematical details are
beyond the scope of this chapter, and the interested reader may ﬁnd more details in [1].
A special case is obtained when the loss poles are in such a manner that the stopband as well
as the passband are equal ripple. Since such ﬁlter K(s) can be analytically constructed in terms
of elliptic functions [16], they are called elliptic ﬁlters. Shown in Figure 4.26 is an example of a
3rd-order elliptic ﬁlter with 0.2dB passband ripple.
The ﬁlter has a loss pole at ω = 1.57rad/s.
4.2.5
LC Filter Design
Let us summarize what we have discussed so far:
– Based on the ﬁlter requirements, transducer parameters are determined. This involves
approximating the desired ﬁlter characteristic with one of the well-known forms (maximally
ﬂat, Chebyshev, etc.). The transducer parameters must be circuit realizable. Section 4.2.3.2
highlights the conditions required to guarantee that.
– Transducer parameters lead to a unique value of the LC two-port impedance (or admittance,
chain, etc.) parameters.
Frequency, rad/s
1
10
Loss, dB
10
20
30
40
s=30dB
1
2
w
w
a
Figure 4.25: A 5th-order inverse Chebyshev
ﬁlter with αs = 30dB
4.2 Doubly Terminated LC Filters
229

– An LC circuit (typically ladder) is synthesized accordingly. The solution is usually not
unique.
The last part is what we have not discussed yet and requires the knowledge of circuit synthesis.
Synthesizing double-terminated LC two-ports is a rather difﬁcult task, since the transducer
parameters involve all three of z11, z12, and z22 to be satisﬁed simultaneously. In general,
synthesizing double-terminated two-ports starts with realizing either z11 or z22 as one-port imped-
ances by removing poles such that the transmission zeros, which are typically the zeros of z12, are
properly realized. In most cases all three of z11, z12, and z22 have the same poles, and often z11 and
z22 are the same except for a private lumped impedance that can be realized separately.
Both Butterworth and Chebyshev polynomials belong to a class of functions known as all-
pole transfer functions. All the transmission zeros or loss poles (zeros of z12 or poles of K(s)) are
at inﬁnity, and can be physically realized using a ladder structure consisting of series inductors
and shunt capacitors as shown in Figure 4.27. That is simply due to the fact that a series
inductor or a shunt capacitor blocks the signal from reaching the output at very large frequen-
cies, hence creating a zero at inﬁnity in the transfer function (or inﬁnite loss).
With the transmission zeros ﬁgured out, the driving point open impedance of the LC ladder
(z11 or z22) can be expanded by Stieltjes continued fraction,14 which will be explained in the
context of an example shortly:
z11 = α1s +
1
α2s +
1
α3s +
1
..
.
+ 1
αns
Since z11 is a PR reactance function, it can be shown that all the αi factors are real and positive,
describing the values of the corresponding series inductors and shunt capacitors. Furthermore,
the continued fraction will not end prematurely. Thus, for an nth-order all-pole lowpass ﬁlter,
Frequency, rad/s
1
Loss, dB
10
20
30
1.57
0.2dB
1
0
0
5
10
Figure 4.26: Loss function of a 3rd-order
elliptic ﬁlter with 0.2dB passband ripple
14 Thomas Joannes Stieltjes (1856–1894) was a Dutch mathematician. He was a pioneer in the ﬁeld of moment problems and
contributed to the study of continued fractions.
230
RF and IF Filters

there is a total of n LC elements. As can be seen, such realization requires the minimum number
of elements, and the realized circuit is often called canonical.
Example: Assume z11 and z22 of a 4th-order Butterworth ﬁlter are given as below:
z11 =
L2
C1
s2 +
1
C1C3
L2s3 +
1
C1
+ 1
C3


s
z22 =
L2L4s4 +
L2
C3
+ L4
C1
+ L4
C3


s2 +
1
C1C3
L2s3 +
1
C1
+ 1
C3


s
:
It will be clear momentarily as to why they are represented in this format. Both functions
are odd, indicating reactance functions, and it can be shown that they are PR (for instance
by partial fraction). This in turn has to do with the fact that the transducer parameters for
the ﬁlter satisfy the realizability criteria pointed out in Section 4.2.3.2. Also, despite the
fact that z11 and z22 are not identical, they have the same poles.
Let us start with z22. Since it has a pole at inﬁnity, we can ﬁrst try to remove that pole,
corresponding to a series inductor in the ladder. This is simply done by dividing the
numerator by the denominator as follows:
L2L4s4 +
L2
C3
+ L4
C1
+ L4
C3


s2 +
1
C1C3
L2s3 +
1
C1
+ 1
C3


s
= L4s +
L2
C3
s2 +
1
C1C3
L2s3 +
1
C1
+ 1
C3


s
:
The remaining impedance,
L2
C3
s2 +
1
C1C3
L2s3 +
1
C1
+ 1
C3


s
, is one degree simpler, and now has a zero at
inﬁnity. We can therefore remove a pole at inﬁnity from the admittance function, that is,
divide the denominator by the numerator. This will correspond to a shunt admittance in
the ladder, as it should be.
Continued
VS
LC Ladder
+
V2
–
…
Figure 4.27: LC ladder
structure for all-pole lowpass
ﬁlters
4.2 Doubly Terminated LC Filters
231

L2s3 +
1
C1
+ 1
C3


s
L2
C3
s2 +
1
C1C3
= C3s +
1
C3
s
L2
C3
s2 +
1
C1C3
The procedure can be carried out until we are left with a single capacitor (in the shunt
branch) or an inductor (in the series branch). This leads to the following for z22:
z22 = L4s +
1
C3s +
1
L2s +
1
C1s
:
Carrying out the continued fraction for z11 results in
z11 =
1
C1s +
1
L2s +
1
C3s
:
Note that since 1
z11 has a pole at inﬁnity, we start with 1
z11 . The pole removal at inﬁnity by
alternating between the impedance and admittance functions resulting in a ladder struc-
ture is known as Cauer 1 realization.15
The realized ﬁlter is shown in Figure 4.28. For the Butterworth realization, the
elements are L4 = 0.7654, C3 = 1.8478, L2 = 1.8478, C1 = 0.7654, which will be directly
obtained from transducer parameters, and subsequently the corresponding z11 and z22.
Other types of ﬁlters such as elliptic approximate more complex polynomials that are not
all-pole. The ﬁnite transmission zeros are often realized by either a parallel resonance
circuit in the series path or a series resonance circuit in the shunt path, as shown in
Figure 4.29. The resonance frequency of the series or parallel circuits is naturally at the
transmission zero(s).
The values of the element are often readily obtained through ﬁlter design tables [13], [14],
[15] or simple software programs, though the circuit can be directly synthesized as well [3], [9].
The synthesis often involves (partial) removal of poles at the transmission zeros frequency.
Shown in Figure 4.30 is an example of a 3rd-order elliptic ﬁlter with 0.2dB passband ripple (see
Figure 4.26 for ﬁlter response).
C1
C3
L2
L4
z11
z22
Figure 4.28: A 4th-order Butterworth ﬁlter
speciﬁed by
z22 =
L2L4s4 +
L2
C3
+ L4
C1
+ L4
C3


s2 +
1
C1C3
L2s3 +
1
C1
+ 1
C3


s
15 Cauer 2 realization involves removing poles at zero from the immittance function.
232
RF and IF Filters

4.2.6
Scaling Filters
In the WLAN ﬁlter example, we found n = 4. The degree of ﬁlter is independent of Cn.
However, since 10 log(1 + Cnωp
2n)  αp for αp = 0.5dB, and ωp = 2π  8.5MHz, we obtain,
Cn = 10αp=101
ωp2n
= 1:84  1063. The reader can verify that the other equation (10 log(1 + Cnωs
2n)
 αs) is going to be automatically met. Such an extremely small value for Cn, which will make
the subsequent design very tedious, results from carrying out the calculations without
normalization.
To avoid this we start with a normalized ﬁlter often with ωp = 1rad/s. This usually leads to
element values on the order of 1H or 1F. The termination resistor is also left at typically 1Ω, or
on that order. There are two types of scaling that can be made afterward:
1. Frequency scaling: Since the impedance of an inductor is Lω, and that of a capacitor is
1
Cω,
and that the resistors are frequency independent, then the ﬁlter frequency is scaled by a
factor α if all the capacitors and inductors are divided by α. This scaling shrinks or expands
only the frequency axis, and the overall shape or rejection of the ﬁlter remains intact.
2. Impedance scaling: By a similar argument, if all the resistors and inductors are multiplied by
α, and all the capacitors are divided by α, the ﬁlter response remains unchanged. Increasing
or reducing the impedance levels has only noise implications. This however allows us to
achieve more practical values for the components.
VS
+
V2
–
LC Ladder 1
…
VS
+
V2
–
…
LC Ladder 2
Figure 4.29: LC ladder structures to
realize ﬁnite transmission zeros
C1
C3
C2
L2
C1 = C3 = 0.88F
C2 = 0.56F
L2 = 0.73H
Figure 4.30: A 3rd-order elliptic ﬁlter and its corresponding
elements
4.2 Doubly Terminated LC Filters
233

Example: Looking back at the WLAN ﬁlter example, let us start with a normalized
4th-order Butterworth ﬁlter with 1Ω termination at both sides as shown in Figure 4.31.
For the normalized ﬁlter, at ω = 1rad/s the loss increases by 3dB. Since the
requirement is 0.5dB loss at 8.5MHz, the scaling factor is
2π8:5
0:77 = 6:97  107,
where ω = 0.77rad/s is the normalized frequency of 0.5dB passband loss. Furthermore,
we
would
like
to
design
the
ﬁlter
for
50Ω
termination,
which
results
in
L1 = 0:756450
6:97107 = 0:542μH,
C2 =
1:8478
500:53nFð6:97107Þ =530pF,
L3 = 1:847850
6:97107 =1:33μH,
C4 =
0:7564
500:53nFð6:97107Þ =217pF. These values are a lot more practical for such ﬁlter at
this frequency range.
The scaled ﬁlter simulated response is plotted in Figure 4.32 along with the new values.
The response follows that of Figure 4.20, except the frequency axis is scaled to the WLAN
ﬁlter requirements.
4.2.7
Bandpass LC Filters
All the ﬁlter types discussed thus far approximate an ideal lowpass ﬁlter. To create other types
of ﬁlters (e.g., highpass, bandpass, etc.) there are common impedance transformations that may
L1 = 0.7564H
C2 = 1.8478F
L3 = 1.8478H
C4 = 0.7564F
Figure 4.31: Normalized 4th-order Butterworth ﬁlter
Frequency, MHz
1
Loss, dB
10
20
30
40
L1 = 0.54mH
L3 = 1.33mH
C2 = 530pF
C4 = 217pF
50
60
70
10
100
35.3
Figure 4.32: Scaled ﬁlter response along with the element values for the 4th-order Butterworth
ﬁlter of Figure 4.31
234
RF and IF Filters

be used [17]. Given its importance, we will mostly discuss the bandpass transformation in this
section. Highpass or bandstop ﬁlters follow a very similar procedure.
To create a bandpass ﬁlter, let us ﬁrst take another look at the simple parallel RLC circuit
discussed earlier, and compare that to a 1st-order RC circuit also shown in Figure 4.33.
The frequency response of each circuit is
HLP jω
ð
Þ =
R
1 + jRCω
HBP jω
ð
Þ =
R
1 + jRC ω2  ω02
ω
:
Comparing the two transfer functions, one can realize that the lowpass response can be
converted to bandpass if one shifts the frequency from ω $ ω2ω02
ω
, or in the s domain, from
s $ s2 + ω02
s
.
To generalize, if the normalized lowpass transfer function is given by HLPn(s), the
bandpass response is obtained by HBP sð Þ = HLPn
s2 + ω02
sB


, where B is the bandpass ﬁlter
bandwidth, and ω0 is the center frequency. The appearance of B (bandwidth) in the denomin-
ator is due to the fact that what is used is the normalized lowpass transfer function. In the
simple circuit of Figure 4.33, for instance, the bandwidth is
1
RC. Given that the normalized
lowpass response is HLPn sð Þ =
1
1 + s, the bandpass response is readily obtained by applying the
transformation.
From a circuit point of view, this is equivalent to replacing each shunt capacitor with a
parallel LC circuit whose resonance frequency is set by ω0, as the lowpass capacitor admittance
needs to change from Cs $
C
B
 	
s +
1
B
Cω02


s
. This is also evident from Figure 4.33. Moreover,
one can show that the transformation also requires replacing each series inductor with a series
LC circuit resonating at ω0 as well. As an example, our previous 3rd-order lowpass ﬁlter could
be converted to bandpass through the equivalent ladder circuit shown in Figure 4.34. For the
same order, the number of reactive components doubles. At the center frequency ω0, clearly all
the series LC branches are short, whereas all the parallel LC legs are open, thus the circuit is
expected to pass. Moreover, at very high or very low frequencies the input signal is blocked,
and hence the bandpass response is achieved.
Assuming a lowpass frequency of Ω, and a bandpass frequency of ω, the transformation may
be expressed as
ω2  ωΩB  ω0
2 = 0,
C
R
+
v(t)
–
L
C
R
+
v(t)
–
Lowpass
Bandpass
Figure 4.33: A 1st-order RC lowpass
circuit compared to a 2nd-order bandpass
circuit
4.2 Doubly Terminated LC Filters
235

which has the following two roots:
ω = B
2 Ω +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
B2
4 Ω2 + ω0
2
s
, ω > 0
ω = B
2 Ω 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
B2
4 Ω2 + ω0
2
s
, ω < 0:
The equation above shows that while the center frequency shifts as intended, the lowpass
frequency response is not preserved entirely. Only if Ω 	 2ω0
B , that is, if the ﬁlter is narrow
enough, are its characteristics shifted intact. This is shown in Figure 4.35, indicating that the
transformation is not exactly linear. Also shown in the dashed line is the ideal curve. For small
deviations from the center, we have
ω  ω0  B
2 Ω:
However, if Ω is large,
ω  BΩ,
which clearly shows a large deviation from the ideal response.
RS
RL
f0
Figure 4.34: A 3rd-order bandpass ladder ﬁlter
Ω
–
0
+
0
0
Ideal
w
w
w
Figure 4.35: Plot of lowpass to bandpass frequency
transformation
236
RF and IF Filters

Example: The corresponding transfer functions of a 3rd-order Butterworth design is
shown in Figure 4.36.
As a ﬁnal note, let us examine the ﬁlter response in the time domain to a pulse or step. Since
a step function contains abrupt transitions in the time domain, we expect it to contain very high-
frequency components that will be attenuated by the ﬁlter. For a given lowpass ﬁlter as an
example, the output y(t) corresponding to a step input, that is, x(t) = u(t), is
y tð Þ =
ð∞
∞
h τð Þu t  τ
ð
Þdτ =
ðt
∞
h τð Þdτ:
To gain some insight, consider the extreme case of an ideal LPF with a bandwidth of B, where
h(t) is a sinc. The integral then becomes
y tð Þ
ðt
∞
2B sinc 2Bτ
ð
Þdτ = 1
2 + 1
π Si 2πBt
ð
Þ,
where Si tð Þ =
Ð t
0
sin α
α dα is the sine integral function. The ﬁlter step response is shown in
Figure 4.37, and compared to the response of a 1st-order RC ﬁlter.
As expected, the step response of the ideal ﬁlter has components at t < 0, signifying the fact
that such ﬁlter is not physically realizable. Nevertheless, it gives us some insight: for both cases
the step response approaches unity, and the rise time (tr)16 is 0.35/B for a 1st-order design,
whereas the ideal ﬁlter rise time is 0.44/B. Since the rise time appears not to be a strong function
of the ﬁlter order, as a general rule of thumb we approximate
tr ﬃ1
2B :
f
20 log|V(f)|
0dB
f0
–f0
LPF & BPF Frequency Responses
Figure 4.36: Lowpass and bandpass
Butterworth transfer functions
16 Rise time is typically deﬁned as the time it takes to reach from 10% to 90% of the ﬁnal value.
4.2 Doubly Terminated LC Filters
237

4.3
ACTIVE FILTERS
..............................................................................................
In the previous example of WLAN ﬁlter, the inductances were found to be on the order of μH,
and capacitances on the order of 100s of pF. These values are large, and would become even
larger for lower frequency ﬁlters (applications such as Bluetooth, GPS, or WCDMA need
ﬁlters on the order of a few MHz or less). Impedance scaling is not helpful, for instance, if at
the expense of higher noise the termination resistors are scaled by 20 times to 1kΩ, only the
capacitances reduce, while the inductances increase further. This certainly rules out LC ﬁlters,
despite all their good properties, as suitable candidates for IF ﬁlters as such large values of
inductor are impractical in integrated circuits. In this section we brieﬂy discuss the funda-
mental properties of the active ﬁlters, an alternative to the LC ladder that can be realized on
chip with practical element values. More detailed discussion of active ﬁlters may be found in
[1], [3], [4], [18].
4.3.1
Active Filters Ladder Design
Let us start with a 3rd-order Chebyshev ﬁlter realized as a passive ladder structure (Figure 4.38).
Also shown is the transducer loss in dB versus the frequency. As pointed out through the
example, at lower frequencies, say several hundreds of kHz to a few tens of MHz, the size of the
inductor L2 will be too big to be realized on chip.
An alternative realization may be conceived if one considers the signal ﬂow graph of the
passive ﬁlter. For that, we assign a voltage to every capacitor, and a current to every inductor, as
shown in Figure 4.38, and ensure that the KVL and KCL are satisﬁed at every loop and node of
the ladder ﬁlter. For instance, writing a KCL at V1 node yields
V1  VS
RS
+ sC1V1 + I2 = 0,
which can be rearranged as
V1 = 1
sC1
Vs
Rs
 V1
Rs
 I2


:
t
y(t)
1/2B
1/B
0
0.5
1
–1/2B
Ideal
1st order
Figure 4.37: Step response of an
ideal and a 1st-order ﬁlter
238
RF and IF Filters

Similarly, a KVL for I2 and a KCL for V3 after rearranging lead to the following:
I2 = 1
sL2
V1  V3
ð
Þ
V3 = 1
sC3
V3
RL
 I2


:
The corresponding ﬂow graph to realize the transfer function of the 3rd-order ﬁlter according to
the three equations above is shown in Figure 4.39.
By inspection, evidently the ﬁlter may be realized by analog building blocks: integrators,
adders, and multipliers. There are as many integrators as the reactive elements. The integrator
may be realized by an active-RC circuit, a gm-C circuit involving transconductors, or a
switched capacitor circuit.17 Examples of a gm-C and active-RC integrators are shown in
Figure 4.40.
Feeding multiple currents into a node realizes the addition, and multiplication is done by
scaling values of resistors or transconductance. A gm-C realization of the 3rd-order ﬁlter is
shown in Figure 4.41 as an example. Negative gain is easily realized in a differential scheme.
Similarly, the ﬁlter may be realized through opamp-RC integrators and is shown in
Figure 4.42. The addition and multiplication functions are performed by feeding various current
with appropriate impedance levels into the virtual ground of a given opamp.
VS
–V1
–1/sC 1
–1/sL2
–1/sC 3
1/RS
1/RS
–I2
V3
1/RL
1
–1
1
–1
Figure 4.39: Signal ﬂow graph of the Chebyshev ﬁlter
17 A switched current integrator is also an option, although is seldom used in practice.
C1
L2
C3
RS
RL
vS
Loss
p
p
Frequency
3rd-Order Chebyshev
i2
v1
v3
w
a
Figure 4.38: A 3rd-Order Chebyshev ladder ﬁlter
4.3 Active Filters
239

The negative resistors are readily realized in fully differential designs through cross coupling
the differential outputs of the corresponding stage. If a single-ended design is to be used, one
has no choice but to insert an inverting unity gain buffer in front of the negative resistors to ﬂip
their sign.
gm
–
+
R
Opamp-RC
gm-C
C
C
Figure 4.40: gm-C and active-RC
integrators
vS
–v1
–1/sC 1
–1/sL2
–1/sC 3
1/RS
1/RS
–i2
v3
1/RL
1
–1
1
–1
–1/RS
vS
–1/RS
–1
+1
–1
+1
–v1
C1
L2
C3
–i2
v3
–1/RL
Figure 4.41: gm-C realization of the 3rd-order ﬁlter of Figure 4.38
Rs
C1
RL
C3
L2
Vs
–V1
–I2
V3
1
–1
–1
1
Rs
Figure 4.42: Active-RC realization of the 3rd-order ﬁlter of
Figure 4.38
240
RF and IF Filters

Example: We wish to design a 3rd-order active-RC Chebyshev ﬁlter with 1dB passband
ripple and 10MHz passband frequency. The element values for the normalized ﬁlter
(ωp = 1rad/s) are
C1 = C3 = 2F, L2 = 1H, Rs = RL = 1Ω.
To scale to the desired frequency, all the capacitors must be multiplied by
1
2π107. To
further achieve more practical component values, we raise all the resistance to 4kΩ,
leading to the capacitance values of
2
2π107
4000 = 8pF for the ﬁrst and last lossy integrators, and
1
2π107
4000 = 4pF for the middle integrator. Furthermore, to achieve a passband gain of 1, as
opposed to 1
2, which is inherent in the double-terminated ladder, we reduce the source
resistance to 2kΩ. This completes the design, and the active-RC ﬁlter simulated frequency
response with the aforementioned elements is shown in Figure 4.43.
In the previous example, the capacitances on the order of pF and resistances on the order of
kΩ were obtained, which are very suitable values for integrated circuits. The resistance scaling
to 4kΩ was quite arbitrary, and is primarily driven by the noise constraints; e.g., at the expense
of doubling the noise, the ﬁlter capacitances may be halved, while the resistances may be
doubled. This generally imposes a trade-off between the ﬁlter size (cost), noise, and opamps
driving capability and consequently their power consumption.
The ﬁlter may be further scaled considering the following:
– If all the impedances connected to the input of a given opamp are multiplied by α, the ﬁlter
response remains intact. This is simply because the currents fed to that opamp input are all α
times less, but the overall gain of that opamp remains the same as the feedback impedance is
also α times bigger. This allows us to locally optimize the elements around each opamp to
further minimize the components spread if needed. For instance, it may be desirable to have
Frequency, MHz
10
|Vo/Vs|, dB
–60
–50
–30
0
20
100
–40
–20
–10
50
Figure 4.43: A 10MHz 3rd-order
Chebyshev ﬁlter
4.3 Active Filters
241

equal feedback capacitors for all the three opamps. Then one can halve the two negative
resistors connected to the middle opamp, and that leads to twice as big a feedback capacitor,
now the same as the other two.
– If all the impedances connected to the output of a given opamp are multiplied by α, the ﬁlter
overall response remains intact, but the gain of that node is α times bigger. This again is
obvious; while the particular opamp gain is raised by α, the currents fed to the other opamps
remain the same as the corresponding impedances are α times more. This is critical in active
ﬁlters, to ensure that all the opamps (or transconductors in the case of gm-C design) are
clipped at the same input level.
To clarify the previous point further, shown in Figure 4.44 is the transfer gain of the ﬁlter of
Figure 4.43 for each of the internal nodes, as well as that of the output. Evidently, the middle
opamp is clipped as much as 6.4dB earlier than the output. This can be remedied by reducing all
the impedances connected to that opamps by 2.09. A similar scaling must be done for the ﬁrst
opamp as well, resulting in the scaled ﬁlter response shown on the right, where all the three
stages are clipped at the same input level.
While this technique raises the ﬁlter noise [4], it overall leads to a more optimum dynamic
range.18
Another common realization of active ﬁlters is through switched-capacitor integrators [4],
the details of which we will defer to the reader (Figure 4.45). It is often possible to start with an
Frequency, MHz
–3
0
10 15
–7
–5
–1
1
3
5
V3
–V1
–I2
Frequency
|Vo/ Vs|, dB
|Vo/ Vs|, dB
, MHz
–1
0
10 15
–13
–11
–9
–7
–5
–3
V3
–V1
–I2
Original
Scaled
Figure 4.44: Scaling the ﬁlter of Figure 4.43 for the optimum dynamic range
C2
Vo
Vs
C1
f2
f2
f1
f1
f1
t
f2
f1
f2
R1 ≈ T/C1
T
Figure 4.45: A switched capacitor integrator
18 Dynamic range and noise will be extensively discussed in Chapters 5 and 6. For a ﬁlter, the dynamic range is usually
deﬁned as the ratio of the ﬁlter maximum input for some acceptable level of distortion to its integrated noise.
242
RF and IF Filters

active-RC equivalent, and simply replace each resistor with a switched capacitor equivalent
(as shown in the dashed box).
More elaborate designs using continuous- to discrete-domain mapping techniques, for
instance bilinear mapping, are also possible [19].
4.3.2
Active Filters Cascaded Design
The ladder realization of the ﬁlter leads to the least sensitivity to the elements variation as
pointed out in Section 4.2. However, the design is somewhat tedious and not quite straightfor-
ward. A simpler approach is to obtain the overall ﬁlter transfer function, through MATLAB or
by looking up (or calculating) the natural frequencies of the ﬁlter (recall those are the zeros
of H(s)). Then the ﬁlter may be synthesized by breaking the transfer function into a cascade of
second-order (or biquadratic) sections, known as biquads. If the ﬁlter order is odd, one ﬁrst-
order stage is also needed.
Shown in Figure 4.46 is a general realization of a 1st-order stage. It is easy to show that the
transfer function is
Vo
Vs
= K1s + K0
s + ω0
:
Figure 4.47 shows a general 2nd-order or biquad stage. The biquad transfer function can be
shown to be
Vo
Vs
= K2s2 + K1s + K0
s2 + ω0
Q s + ω0
2 :
1
1/K0
Vo
1/
0
K1
Vs
w
Figure 4.46: Active-RC realization of a generic 1st-order stage
Vs
1
1
K2
1/K1
0/K0
–1/
0
1/
0
Q/
0
Vo
w
w
w
w
Figure 4.47: A generic active-RC
biquad stage
4.3 Active Filters
243

This biquad is mostly suitable for the cases where the required quality factor Q is low. An
example of a high-Q biquad is discussed in Problem 16.
Example: For the same 3rd-order Chebyshev ﬁlter of previous example, from ﬁlter tables
or MATLAB the normalized natural frequencies can be found to be
s1 =  0:5
s2,3 =  0:25  j0:97:
Thus, the ﬁlter transfer function may be expressed as
Vo
Vs
=
1
4
s + 1
2


s2 + 1
2 s + 1

 =
1
2
s + 1
2


1
2
s2 + 1
2 s + 1

 :
The 1
4 in the numerator is arbitrarily spilt between the two stages. We raise all the
resistances to 4kΩ, and apply the same scaling factor of
1
2π107
4000 for the capacitors as in
the ladder example, which leads to the ﬁlter schematic of Figure 4.48. The input resistor is
halved to eliminate the 6dB inherent loss of the double-terminated ﬁlter. The biquad does
not need any additional scaling as both nodes (V2 and Vo) have the same peak gain.
However, the 1st-order stage output (V1) has 6dB higher gain, and thus the impedances at
the output of the 1st opamp are scaled down by a factor of 2, as shown in the ﬁgure. Note
that the 1st-order stage is usually preferred to go ﬁrst, and is often built in to the previous
stage (for example, the receiver downconversion mixer)
The ﬁlter has the same overall transfer function as the ladder design, and the ﬁnal scaled ﬁlter
characteristics is shown in Figure 4.49.
As mentioned earlier, the cascaded design doesn’t necessarily have the good property of low
sensitivity to element variations like the ladder design. However, in general, in integrated
circuits good matching between the resistors and capacitors is enjoyed. The key is to design the
resistors and the capacitors out of unit elements. For the previous case, for instance, one may
Vo
2k
Vs
8p
2k
8p
2k
4k
2k
V2
V1
4k
2k
4k
4k
8p
16p
Figure 4.48: Third-order Chebyshev ﬁlter with 10MHz passband using a cascade of a 1st- and a
2nd-order stage
244
RF and IF Filters

choose a unit of 2k for the resistors, and a unit of 8p for the capacitors. In many cases the
element values need to be rounded, which could cause some sensitivity.
Example: Shown in Figure 4.50 is another realization of an active-RC biquad known as
the Sallen–Key lowpass biquad stage [20].
The reader can verify that
Vo
Vs
=
ω02
s2 + ω0
Q s + ω02 ,
where ω0 =
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
R1R2C1C2
p
, and Q =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
R1R2C1C2
p
C2 R1 + R2
ð
Þ.
A more generic realization of Sallen–Key topology is discussed in Problem 26. The
Sallen–Key biquad requires only one opamp and thus half the power consumption, but
generally suffers from more sensitivity to element mismatches and rounding. Nonethe-
less, given the more superior power consumption it is commonly used.
4.3.3
Nonideal Effects in Active Filters
There are two fundamental limitations implementing high-frequency active ﬁlters, regardless of
the type of the integrator used. Let us consider a gm-C realization, though the conclusions may
Frequency, MHz
10
Transfer Function, dB
–60
–50
–30
0
20
100
–40
–20
–10
50
Vo
V1
V2
Figure 4.49: Transfer function of the
cascade design of Figure 4.48
Vs
Vo
R1
R2
C3
C4
Figure 4.50: Sallen–Key lowpass ﬁlter
4.3 Active Filters
245

be extended to opamp-RC or other types as well. First, a practical integrator has a ﬁnite DC gain
(of a0 = gmro for the transconductor for instance), and an internal pole (of ωp). Shown in
Figure 4.51 is the ideal versus practical integrator phase and frequency response. A ﬁnite DC
gain introduces a phase lead in the transfer function, which tends to introduce a passband loss.
On the other hand, a ﬁnite pole frequency creates a phase lag, which in turn results in peaking
and phase distortion at the edges of passband [21]. Both impacts must be carefully avoided
especially as the ﬁlter bandwidth becomes narrower.
To quantify these impacts, let us consider a 2nd-order resonator built out of a two back-to-
back nonideal integrators, as shown in Figure 4.52. Once loaded with a resistor R, a parallel
RLC network is built whose bandwidth is set by the resistor. The cross-coupled transconductors
create what is known as an active gyrator [22], [23]. When loaded by a capacitor (Figure 4.52),
the gyrator results into an inductor (L =
C
gm2) when looking into the other end:19
YIN = gm
2ZL = gm
2
jCω :
We shall ﬁrst ﬁnd the impact of ﬁnite output resistance of the integrators.
gm/C
20log|H(j )|
∠H(j )
0dB
–90º 
Ideal
Praccal
1/roC
p
w
w
Figure 4.51: Integrator phase and frequency response
gm
C
–gm
YIN
Inductor
R
Figure 4.52: A gm-C resonator
19 As a side note, Orchard shows in [68], [69] that active gyrators lead to bandpass ﬁlters with comparable sensitivity to the
element variations to that of double-terminated LC ladders if every inductor is replaced by the gyrator-C equivalent.
246
RF and IF Filters

Shown in Figure 4.53, one integrator resistor appears directly at the input. The other one, after
transformation by the gyrator, appears as a small resistance in series with the inductor. Once
converted to parallel RL circuit using the high-Q approximation showed in Chapter 1, it results in
a net resistance of ro/2. Consequently, a ﬁnite Q is observed even for the unloaded resonator.
Regarding the ﬁnite pole, let us assume that each transconductor has a transfer function of
gm
1 + s
p
:
Looking into the other end of the gyrator, the input admittance is
YIN =
gm
2
Cs 1 + s
p

2  gm
2
Cs
1  2s
p


= gm
2
Cs  2gm
2
Cp :
Thus, the ﬁnite pole results in a parallel negative resistance of Cp
2gm2 at the input. Similar
expressions may be derived for the opamp-RC integrators.
Shown in Figure 4.54 is the ladder ﬁlter of the previous example (Figure 4.43) simulated
with ideal opamps, along with two additional cases of a DC gain of 50 (or 34dB) but inﬁnite
bandwidth, and the same 34dB DC gain but a 3dB bandwidth of 2MHz (or a gain bandwidth
product of 1GHz) for all the opamps.
The ﬁnite DC gain leads to a passband loss of 0.5dB, and some rounding of the passband
edge, whereas the ﬁnite bandwidth leads to severe peaking around the passband edge as
expected.
gm
C
–gm
YIN
ro
ro
ro
1/gm
2ro
C/gm
2
≡ 
Figure 4.53: Impact of
ﬁnite DC gain of the
integrator
Frequency, MHz
|Vo/Vs|, dB
0
10 15
–1
–2
–3
–4
0
1
2
Ideal
A0=50
3
4
A0=50, BW=2M
Figure 4.54: Impact of ﬁnite gain and bandwidth in the
ﬁlter of example of Figure 4.43
4.3 Active Filters
247

These two factors cause a degradation of the resonator quality factor. As a consequence, the
overall Q of the actual ﬁlter, comprising several of these resonators, is limited. Considering
typical values of gain-bandwidth product of transconductor or opamp-based integrators, the
active ﬁlters are typically limited to lowpass structures up to several tens of MHz. If imple-
mented bandpass, their center frequency is limited to a few MHz with fairly wide bandwidth.
Next let us consider the noise properties of the active ﬁlters.20 Consider the gm-C resonator
shown in Figure 4.55, where we model each transconductor with an input referred noise voltage
whose spectral density is 4KTF
gm .
If the transconductor is built of only one transistor, F  1, whereas in practice F is somewhat
larger due to the other contributors. We can show that if the loaded resonator has a quality
factor of Q, set by the resistor R (Figure 4.55), its output noise is [24]
vn2 = KT
C FQ,
which indicates that the noise is exacerbated by a factor of Q. Similar to ﬁnite gain and
bandwidth issues, the excess noise sets how narrow the bandwidth could be for a certain center
frequency and the ﬁlter area (mostly dominated by the total capacitance).
We will see in Chapter 12 that these shortcomings fundamentally limit the choices of the
receiver architecture.
4.4
SURFACE AND BULK ACOUSTIC WAVE FILTERS
..............................................................................................
In many wireless applications such as mobile phones, very aggressive front-end ﬁltering is
required for the reasons that will be discussed in Chapter 6. The modest quality factor of the
integrated resonators along with IC variations often precludes the use of on-chip ﬁlters.
Consequently, in such platforms, RF ﬁltering is often dominated by surface acoustic wave
(SAW) and bulk acoustic wave (BAW) ﬁlters (also known as FBAR or thin ﬁlm bulk acoustic
resonator ﬁlters), which offer tremendous advantages in performance, cost, and size. Given
their importance, we shall recast a brief summary of their physical structure and properties in
this section. More general details may be found in [25], [26], [27], [28]. Also, for further
reading on FBAR resonators and ﬁlters, see [29], [30], [31], [32].
gm
C
–gm
R
Figure 4.55: gm-C resonator noise
20 We will discuss noise in Chapter 5, but assume the reader already has basic knowledge of noise from analog circuit design
courses.
248
RF and IF Filters

4.4.1
Filter Structure
Surface acoustic waves (SAWs) were ﬁrst explained in 1885 by Rayleigh, who described the
surface acoustic mode of propagation and predicted its properties [33]. However, it was not
until the early 1980s that FBAR devices appeared in the literature [34], [35]. SAW or FBAR
resonators and ﬁlters are essentially electromechanical devices where electrical signals are
converted to a mechanical wave in a device constructed of a piezoelectric crystal or ceramic;
this wave is delayed as it propagates across the device, before being converted back to an
electrical signal by further electrodes.
Given the desirable properties described in Section 4.2, the most common ﬁlter topology
for both FBAR and SAW ﬁlters is a doubly terminated ladder structure shown in
Figure 4.56.
The same as crystals (see Chapter 9), either resonator may be modeled by an equivalent RLC
circuit shown in Figure 4.57.
The top branch consisting of RM, LM, and CM model the motional (or acoustic) components,
whereas CO is the plate capacitance, and RO is used to model the loss associated with it.
Typically CM is much smaller than CO, resulting in good stability (see the crystal stability
discussion in Chapter 9 for more details on this). Furthermore, the quality factor of the resonator
is very high, often on the order of several thousands.
The resonator is a second-order circuit, which has a pole and zero, and whose magnitude
of its admittance is shown in Figure 4.58. The zero of admittance (pole of the impedance)
deﬁnes the parallel resonance, whereas the pole of the admittance deﬁne the series
resonance.
As such, from a circuit point of view the ﬁlter may be treated the same as a well-understood
LC ladder, with the exception that the resonators demonstrate substantially higher quality factor
and better stability.
RM
RO
CO
LM
CM
Figure 4.57: A SAW (or BAW) resonator circuit model
…
Series/Shunt 
Resonators
Figure 4.56: A SAW (or BAW) ﬁlter based
on a doubly terminated ladder structure
comprising series and shunt resonators
4.4 Surface and Bulk Acoustic Wave Filters
249

As an example, shown in Figure 4.59 is the frequency response of a commercial SAW ﬁlter
designed by Murata.21
The ﬁlter is intended to be used for cellular applications, and is tuned to the LTE (long-term
evolution) band 41 (2496~2690MHz). The ﬁlter has a stopband rejection of about 40dB at the
2.4GHz ISM band,22 which spans from 2402~2480MHz. This kind of steep stopband rejection
is not possible to be accomplished using integrated inductors and capacitors with modest
quality factors of 10–20.
4.4.2
Resonator Physical Implementation
The core element of the ﬁlter is the resonator. What differentiates BAW and SAW technologies
from the other technologies is their substantially higher Q as the acoustic materials have low
|Y(j )|
p
z
Parallel
Resonance
w
w
Figure 4.58: The BAW (or SAW) resonator pole and
zero deﬁne parallel and series resonance in its
admittance
1
–10
Frequency, GHz
Insertion Loss, dB
2
3
4
5
–20
–30
–40
–50
–60
–70
Figure 4.59: Frequency response
of a Murata SAW ﬁlter intended for
use in cellular platforms
21 Murata, PN: SAFRE2G59MA0F0A.
22 ISM stands for industrial, scientiﬁc, and medical.
250
RF and IF Filters

propagation loss. Moreover, the acoustic resonators and ﬁlters are much smaller than the other
technologies because the acoustic wave speed (ν) is several orders of magnitude less than the
speed of the electromagnetic waves (about 300m/s, compared to the speed of light). Hence, the
corresponding acoustic wavelength λ = ν
f is much shorter than that of the electromagnetic wave.
Finally, the resonators and the ﬁlters are often mass produced through semiconductor technolo-
gies such as photolithography or thin-ﬁlm deposition, which makes them cheaper.
Although the impedance responses of FBAR and SAW resonators look the same
(Figure 4.57), the resonances are realized quite differently. As their name suggests, a SAW is
an acoustic wave that travels along the surface of a crystal substrate in the y direction
(Figure 4.60), whereas FBAR travels inside solid material and in the z direction (Figure 4.61).
In a SAW, the amplitude of the motion decays rapidly with depth, and loses most of its acoustic
energy with one wavelength.
The key to making SAW and FBAR devices is the use of piezoelectric materials as the
medium, and the use of transducers to convert between electrical signals and acoustic waves. In
a piezoelectric material the application of an electric ﬁeld produces mechanical stress or force.
There is also an inverse effect where the imposition of a stress on the material produces an
electrical charge or electrical ﬁeld.
Reflector
Interdigital 
Transducer
z
y
x
Motion (y direction)
l
Figure 4.60: SAW resonator physical structure
y
x
Motion (z direction)
z
l/2
Piezoelectric 
Material
Figure 4.61: FBAR resonator structure and the propagation of the acoustic wave
4.4 Surface and Bulk Acoustic Wave Filters
251

A basic SAW resonator operating on a piezoelectric substrate is shown in Figure 4.60. The
IDT (interdigital transducer) is a pair of interleaving combs of ﬁngers, and it generates and
receives SAWs.
The electric ﬁelds and mechanical stresses between the ﬁngers alternate in sign because of
the alternating connections of the ﬁngers. The two grating reﬂectors reﬂect SAWs and form an
acoustic cavity between them. The SAW cavity is several wavelengths long, and a standing
wave is formed in this cavity. The frequency at which the resonance occurs is determined
mainly by the pitch of the IDT. The IDT and the grating reﬂectors are fabricated of thin-ﬁlm
metal, usually aluminum.
The basic FBAR resonators consist of a thin ﬁlm layer of an aluminum nitride (AIN)
piezoelectric material sandwiched between two metal thin ﬁlm electrodes [30], as shown in
Figure 4.61. The FBAR ﬁlter itself is manufactured on a silicon substrate, which makes it easy
to be implemented in a CMOS fab, thus eliminating much of the wafer cost. Furthermore, an
all-silicon package may be developed that eliminates much of the back-end costs.
Referring to Figure 4.61, the voltage or the electrical ﬁeld between the two electrodes excites
the acoustic wave. The wave bounces back from the top and bottom surfaces of the two
electrodes, and an acoustic cavity is formed between the top surface of the upper electrode
and the bottom surface of the lower electrode. The perfect boundary for totally reﬂecting the
acoustic wave into the medium is an air interface. The frequency at which the resonance occurs
is determined by the thickness of the piezoelectric layer and the thickness and mass of the
electrodes. There is only one-half of an acoustic wavelength in this cavity at fundamental
resonance.
It is noteworthy to point out that FBAR resonators have also been used in the context of
oscillators and reference generation [36], [37]. Their operation is very similar to crystal
oscillators, which will be discussed in Chapter 9 and thus will be skipped here.
4.4.3
Comparison between FBAR and SAW Filters
While both structures are commonly used in today’s radios, there are several advantages/
disadvantages of one versus the other [27], [28], [38]:
– FBAR resonators have demonstrated a higher quality factor than SAW resonators at RF
frequencies. Consequently, BAW ﬁlters can have lower insertion loss, and better selectivity.
– FBAR ﬁlters have better power handling (up to 36dBm), since BAW is based on a parallel
plate capacitor geometry, not the long, narrow, and thin interdigital ﬁngers as used in the
SAW ﬁlter (Figure 4.60). This is obviously critical in transmitters.
– The temperature coefﬁcient of an FBAR resonator appears to be somewhat better than SAW,
but not as good as ceramic ﬁlters. For mobile applications though, ceramic ﬁlters are
substantially larger, which precludes them from being used.23 See [39] for more on power
handling and temperature coefﬁcient studies in FBAR duplexers.
23 For example, a ceramic ﬁlter might be 5  5  10mm3, whereas a hermetically sealed FBAR ﬁlter is 0.5  0.5  0.2mm3,
about 5,000 smaller.
252
RF and IF Filters

– SAW ﬁlters are easier to manufacture, and hence typically cheaper. FBAR has many more
masks, and thus a longer manufacturing time.
– FBAR resonators generally have a higher ﬁgure of merit (FOM). A commonly used FOM is
deﬁned as [40]
FOM = kteff
2  Q,
where Q is the unloaded quality factor, and kteff
2 is the coupling coefﬁcient, which is a
function of the electrode material thickness ratio between electrode and piezoelectric mater-
ials. Since the discovery of Scandium in ﬁlms, the coupling coefﬁcient can be as high as 20%
in development and about 10% in production. The unloaded quality factor hovers between
2000 and 3000. Thus, the corresponding FOM is around 200 for FBAR resonators, which is
superior to that of a SAW resonator.
Despite all these, both technologies have been evolving rapidly, and both are commonly
used. Particularly, SAW ﬁlters appear to be more suitable for lower frequency range (say
around 1GHz), while BAW ﬁlters are more popular at higher frequencies (2GHz and above).
4.5
DUPLEXERS
..............................................................................................
The duplexer is a network with three ports to which are connected, respectively, the antenna
(ANT), the transmitter output (TX), and the receiver input (RX) as shown in Figure 4.62. In
certain applications that the RX and TX operate concurrently, the duplexer is needed to ideally
isolate the receiver from the transmitter; convey the available output power from the TX to the
antenna; and transfer the voltage induced on the antenna to the receiver input with no
attenuation. Given their generally very stringent requirements (see Chapter 6 for detailed
discussion of concurrent or full-duplex transceivers), they are typically realized through SAW
or FBAR technologies [30], [38], [41].
SAW (or FBAR) duplexers operate in well-deﬁned nonoverlapping narrow bands of fre-
quency for TX and RX, while providing an approximately constant resistance at the TX port.
They consist of RX and TX SAW bandpass ﬁlters with a sharp interband transition, so that the
RX ﬁlter presents a small input reactance across the TX sub-band. An integrated λ
4 line then
transforms this to a large reactance at the TX ﬁlter output where the antenna is also connected.
TX
RX
fTX
fRX
fTX
fRX
l/4
TX
RX
ANT
Figure 4.62: SAW/FBAR
duplexer schematic and its
realization
4.5 Duplexers
253

Thus, across the TX band, the SAW ﬁlter connected to the PA output is terminated essentially
only by the antenna impedance. The physical length of the λ
4 line is small, as it is set by the very
short acoustic wavelength.
It is obviously very desirable to integrate the duplexer functionality on chip, given the size
and cost concerns, especially in multiband applications where several of these duplexers, one
for each band of operation, are needed. On the other hand, mimicking the exact same design of
the SAW or FBAR duplexer on chip by using integrated inductors and capacitors is very
challenging, due to the reasons pointed out in the previous section, namely the very modest
quality factor and the variation of on chip passives.
To overcome this fundamental limitation, there have been recent efforts to integrate a
programmable duplexer on chip using the concept of electrical balance based on the hybrid
transformers [42], [43], [44], [45], [46]. The hybrid transformer’s roots stretch back to the
earliest years of telephony [47], [48]. In the pre-electronic telephone handset it served to isolate
the microphone from the earpiece, enabling signals on a pair of wires at each transducer on a
two-wire loop to the central ofﬁce, while suppressing crosstalk from microphone to the headset.
This concept could be revived to ideally isolate the RX and TX rather than the microphone and
headset through an integrate hybrid transformer. Three variations of such transformer are
shown in Figure 4.63.
The three circuits can be analyzed very similarly, and we for now will focus on the one on the
far right, which is perhaps the most suited for an RF electrical balance duplexer. The hybrid
transformer primary is symmetric, and is connected to the antenna on one end, and to a balancing
impedance (ZBAL) that is ideally exactly equal to the antenna impedance. Given the symmetry of
the circuit then, the TX output that is applied in the center tap of the primary is split equally on the
antenna and balancing impedance, and delivers half its power to the antenna, with the other half
wasted in the balancing network. On the other hand, assuming perfect symmetry, since the signals
at the two ends of the primary appear common mode, no signal will be induced on the secondary,
which will be driving a differential RX. Thus the receiver is ideally isolated from the transmitter.
The circuit thus has the added advantage that a differential input is created for the receiver. If the
symmetry is preserved, the circuit is capable of providing large isolation over a wide bandwidth.
Particularly, at balance there is no net differential voltage across the autotransformer, and so zero
self-inductance current ﬂows. The bandwidth is ultimately limited by the asymmetric parasitic
elements in the transformer or the surrounding circuitry. In contrast, the left circuit, which works
conceptually very similarly, is not as wideband as the self-inductance of the autotransformer
TX
RX
ZBAL
ITX
ITX
TX
ZBAL
RX
ZBAL
TX
RX
Figure 4.63: Different realizations of electrical balance duplexer
254
RF and IF Filters

introduces phase shift and limits the isolation bandwidth substantially. Finally, the middle circuit
has the drawback of the RX connected directly to antenna, and thus it can be heavily compressed,
while the isolation is merely achieved through the common mode rejection of the receiver.
A more complete analysis may be found in [42].
There are, however, several important drawbacks associated with the electrical balance
duplexer: First, half the TX signal is wasted in the balancing network, and when the implemen-
tation loss of the transformer due to ﬁnite Q is added, could lead up to 4dB of signal loss, which
is quite signiﬁcant. In contrast, an external duplexer using SAW technology has a typical
insertion loss of about 1.5–2dB. Second, the isolation created in the RX port depends on how
well the balancing network follows the antenna impedance. This will require a complicated
programmable network, which should tolerate a signal as large as the one at the antenna output,
and thus will be hard to design. Nonetheless, tremendous effort has been done in the recent
literature to overcome these issues [43], [44], [45], [46].
4.6
N-PATH FILTERS
..............................................................................................
Aside from the SAW or FBAR ﬁlters, another method of creating accurately controlled and
sharp ﬁlters at RF is through N-path ﬁltering concept. Unlike acoustic wave ﬁlters, N-path
ﬁlters are programmable, which is a substantial advantage, but they have their own limitations
and disadvantages. The N-path ﬁlters are best understood in the context of passive mixers, and
will be analyzed in detail in Chapter 8. Given the relevance however, we will provide an
overview in this section, and defer a more analytical discussion to the passive mixer section.
For further reading aside from our mixer chapter, see [49], [50], [51], [52], [53]. Also [54] gives
a summary and some historical perspective.
Probably the ﬁrst instance of an N-path ﬁlter, also referred to as a Barber ﬁlter, was described
by Barber in 1947 [55], and is conceptually depicted in Figure 4.64.
Suppose to the ﬁlter input a desired signal at f0 along with a close-by unwanted signal at f1 are
applied. For instance, a desired WLAN signal in the band of 2.4–2.48GHz may be accompanied
by an undesirable band-41 LTE signal at 2.51GHz. A traditional RF ﬁlter must then have a
passband of 2.4 to 2.48GHz, that is 80MHz, centered at 2.44GHz. The ratio of the center
ej2 f0t
e–j2pf0t
f0
f1
Δf
0
Δf
LPF
0
Δf
f0
f1
Δf
IN
OUT
p
Figure 4.64: N-path ﬁlter as described in [55]
4.6 N-Path Filters
255

frequency to pass band is about 30. For the ﬁlter to provide enough rejection at the close-by
frequency offset of 30MHz away where the LTE interferer is, the Q of the ﬁlter elements must be
much larger than 30, say few hundred or thousands, a task that may be accomplished only by a
SAW or FBAR resonator. On the other hand, as proposed in Figure 4.64, one may frequency shift
(that is to say downconvert) the signals at the ﬁlter input using complex multiplication at f0. Now
the desired signal is at DC, and the unwanted interferer at f1  f0 = Δf is easily removed by a
lowpass ﬁlter. For instance, a 3rd-order Butterworth ﬁlter with a 3dB passband edge of 10MHz
provides over 28dB of rejection at 30MHz where the interferer is. The ﬁltered signal is then
shifted back up to the original desired location of f0 through another set of quadrature multipliers.
Effectively, by means of frequency shifting of the signals, one can frequency shift a lowpass ﬁlter
to a narrow bandpass ﬁlter at a known and precise frequency of f0. The lowpass ﬁlter on the other
hand is easy to implement using integrated elements very efﬁciently as described earlier.
The actual complex multiplication may be accomplished using the arrangement shown in
Figure 4.65, representing a 2-path ﬁlter. Note that around where the desired signal is, the LPF
has a gain of one, and the signal is effectively multiplied by cos22πf0t + sin2 2πf0t = 1 as
desired. In most cases the multiplier and the signals are differential, effectively realizing a
4-path ﬁlter, which is the most common implementation of an N-path ﬁlter.
Shown in Figure 4.66 is the realization of an N-path ﬁlter as a one-port proposed by Smith
[56]. Apart from the fact that the one in Figure 4.65 is a two-port implementation, the ideas are
cos2pf0t
cos2pf0t
sin2pf0t
sin2pf0t
IN
OUT
+
Figure 4.65: A 2-path ﬁlter to realize the frequency
shift in practice
Z1
Z2
Z1
Z1
Z1
Z1
Figure 4.66: N-path ﬁlter proposed by Smith [56]
256
RF and IF Filters

very similar and both involve frequency shifting. The one-port N-path ﬁlter comprises a rotary
switch connected to one terminal of each of N identical impedances Z1. The switch is assumed
to be rotating at a constant frequency, ω0 = 2π
T , making contact with each of the networks for
a short period of T
N once each revolution. We wish to ﬁnd the impedance Z2 looking into the
one-port.
Although [56] makes the simplifying assumption of treating the network time-invariant, the
results are reasonably accurate and give us some perspective, and thus we will recast a
summary here.
Since Z1 is an LTI network, we can associate some typical impulse response (h1(t)) to it
which is the dashed line in Figure 4.67. Next, we try to ﬁnd the impulse response of the N-path
network, that is, the voltage produced across it if one coulomb of charge were to be dumped
into the network instantaneously. The current impulse passes through the commutating switch
to one of the networks and causes a voltage response, h1(t), in that one network. At some short
time later the commutator leaves that network and thereafter samples the voltage across it for a
short time, T
N, once each revolution. Thus the voltage on the switch arm, which is the impulse
response h2(t), would be as shown in the ﬁgure, which can be written as
h2 tð Þ =
h1 tð Þ
nT < t < n + 1
ð
ÞT
0
elsewhere
(
,
where n is an integer greater or equal than 0.
The impulse response h2(t) can be expressed as follows, as graphically shown in Figure 4.68,
h2 tð Þ = h1 tð Þ:f tð Þ = h1 tð Þ
X
k
akejkω0t,
where ak = 1
N ejkπ
N sinc k
N
 	
is the Fourier series coefﬁcients of f(t).
N-Path Filter
d(t)
+
h2(t)
–
t
h2(t)
h1(t)
T
T/N
Figure 4.67: Impulse
response of Z1 and that of the
N-path ﬁlter
t
h2(t)
T
T/N
t
h1(t)
=
t
f(t)
×
1
Figure 4.68: Representation of the impulse response h2(t) as the product of h1(t) and a sampling
function f(t)
4.6 N-Path Filters
257

Thus, in the frequency domain
Z2 ω
ð Þ = F h2 tð Þ
½
 =
X
k
akZ1 ω  kω0
ð
Þ,
which clearly shows the impedance Z1 is shifted to ω0 (the switch rotation frequency) and its
harmonics with a sinc function envelope. Around the main harmonic
Z2(ω)  a1Z1(ω  ω0) + a1
∗Z1(ω + ω0).
The analysis in [56], as shown already, as well as the one in [57], [58] involve sampled data
approximation, and hence the terminology sampled data bandpass ﬁlter has been commonly
used. A more rigorous analysis performed on the passive mixers in Chapter 8 shows that for
ω = 4, around the fundamental
Z2 ω
ð Þ  RSW + 2
π2 Z1 ω  ω0
ð
Þ + Z1 ω + ω0
ð
Þ
½
,
where RSW is one switch on resistance. Since at any point of time one and only one switch is on,
this simply comes at the series with the shifted impedance.
The N-path ﬁlters were quite popular in the 1970s and 1980s for lower frequency applica-
tions in the context of switched capacitor ﬁlters [4], but did not make it into RF until very
recently [59], [60], [61], [62] mainly due to the advent of good RF switches offered in
nanometer CMOS technology. An example of a 4-path ﬁlter in 16nm CMOS is shown in
Figure 4.69. Impedance Z1 is realized using a simple capacitor, which is advantageous as it is
inherently very linear and noiseless.
Example: The simulated reactance of the 4-path network of Figure 4.69 (driven by an
ideal current source) with the switches commutating at a frequency of 2GHz, and a
capacitance value of 20pF is shown in Figure 4.70. Evidently, the capacitance is shifted to
ω0 (and its harmonics), and it effectively behaves like a parallel resonance circuit at the
vicinity of ω0. Even with ideal switches, the tank is still lossy given the time variant
nature of the circuit and the aliasing of higher frequency harmonics back to the frequency
c
x1
c
x2
c
x4
….
IN
x1
x2
x4
0
T/4
T
x3
Figure 4.69: CMOS implementation
of a 4-path ﬁlter and the
corresponding waveforms of the
switches
258
RF and IF Filters

of interest [62]. Nonetheless, it still achieves superior quality factor compared to inte-
grated LC tanks, and more importantly, its resonance frequency is tightly controlled, and
is easily programmable.
With the N-path resonator of Figure 4.69 one can now build high-Q bandpass ﬁlters. A simple
2nd-order realization is shown in Figure 4.71. At 2GHz, the N-path circuit is ideally an open
circuit and the signal passes. However, given the ﬁnite Q of the N-path network an insertion
loss of about 2.4dB is simulated. Besides the ﬁnite Q, the switches’ parasitic capacitance at
2GHz also adds to the loss. From [50], the passband insertion loss due to the resistive part of a
4-path ﬁlter is
8
π2 or 1.8dB, and apparently the remaining 0.6dB is due to the switches’
capacitance (estimated to about 100fF).
The ﬁlter rejection at far-out frequencies is mostly limited by the nonzero switch resistance.
In this case, the switches have a resistance of about 20Ω, limiting the rejection to about 11dB
or so.
Frequency, GHz
2
Reactance, Ω
–600
0
1
4
6
8
10
–400
–200
+200
+400
+600
–1/CeqΔw
Figure 4.70: The reactance
looking into the input of the
circuit of Figure 4.69
Rs
…
Vs
+
Vo
–
Frequency, GHz
2
|Vo/Vs|, dB
–8
1
4
6
8
10
–12
–10
–6
–4
–2
Figure 4.71: A simple second-order bandpass ﬁlter based on the N-path resonator of Figure 4.69 and its
frequency response
4.6 N-Path Filters
259

Higher order ﬁltering is possible through the use of active circuits (e.g., transconductors) to
stagger tune and couple the resonators [52], [53].
N-path networks with a simple capacitor being commutated are generally low-noise. How-
ever, the noise of the clock signal controlling the switches ultimately decides the maximum
allowable interferer through reciprocal mixing (see Chapter 6). That means in most cases these
ﬁlters cannot be used for noise reduction; rather they are mostly suited to attenuate large signals
and relax the ampliﬁer compression. Furthermore, the ﬁlter linearity is limited by the switches,
which makes it difﬁcult to be used in transmitters’ very output. In the receivers the ﬁlter is
mostly limited to a few-dBm signals. They also suffer from harmonic aliasing, as is evident
from Figure 4.71. Given all these, the N-path ﬁlters cannot really replace the SAW or FBAR
ﬁlters, but certainly are very helpful to relax the radio and especially the receiver linearity
requirements, and are widely used in modern radio products.
4.7
QUADRATURE FILTERS
..............................................................................................
As we pointed out in Chapter 2, quadrature signals and ﬁlters are widely used in RF receivers
and transmitters. A quadrature ﬁlter is an allpass network that merely shifts the phase of the
positive frequency components by –90º, and negative frequency components by +90º. Since
90º phase shift is equivalent by multiplying by ej90 = j, the transfer function can be
written as
HQ fð Þ =
j
f > 0
+ j
f < 0

:
We also showed that for an arbitrary input x(t) passing through such quadrature ﬁlter (with
hQ(t) = 1/πt being impulse response) results in an output x^(t), deﬁned as the Hilbert transform of
the input:
x tð Þ = x tð Þ∗1
πt = 1
π
ð∞
∞
x τð Þ
t  τ dτ:
The Hilbert transform or in general 90º phase shift is physically not realizable as hQ(t) is
noncausal, although its behavior can be well approximated over a ﬁnite frequency range using a
real network. If x(t) = A cos(ω0t + φ), then x^(t) = A sin(ω0t + φ). Moreover, any signal that
consists of a sum of sinusoids follows the above accordingly.
With this background, let us take a closer look at quadrature ﬁlters and quadrature generation.
4.7.1
Passive Polyphase Filters
Quadrature generation and 90º phase shift may be accomplished by using a class of networks
known as polyphase ﬁlters [63]. Although their implementation is symmetric, they have an
asymmetric frequency response, that is, the ﬁlter responds to positive and negative frequencies
differently. Consider a 4-phase network in Figure 4.72, where two sets of four identical vectors
each 90 phase shifted with respect to one another is applied. The difference between each set is
that in one case the vectors are lagging when rotating counterclockwise, whereas in the other
260
RF and IF Filters

case they are leading. We expect Hpp(f) 6¼ Hpp(f), which at ﬁrst glance implies Hpp(f) is not
real, although we will see this is not the case.
Although in practice real RF signals have only positive frequencies, in complex domain the
set of vectors could be viewed as having identical magnitudes, but opposite frequencies as they
rotate in opposite directions. The polyphase ﬁlter is expected to respond to each set differently.
The underlying principle behind creating such asymmetry in the frequency response may be
understood by examining the LP to BP frequency transformation. For a real BPF, such as the
ones presented earlier, the transformation requires the frequency to change from ω $ ω2ω02
ω
.
This will accordingly preserve the symmetry of the negative and positive frequencies, as is
evident from Figure 4.36. On the other hand, if one transforms the frequency by applying:
ω $ ω  ω0, the symmetry will not be preserved. Such transformation, however, cannot be
achieved using real components. For example, the capacitor admittance needs to change from
jCω $ jCω  jCω0 . This results in the original capacitor in parallel with a frequency independ-
ent element (say a resistor with a value of jCω0), whose value is complex. This problem may
be resolved by considering that polyphase networks take multiphase inputs, for example a
quadrature sequence for a 4-phase realization. Thus the factor j for the resistor may be achieved
by connecting that resistor to the second input which is identical in magnitude, but 90º phase
shifted. The resulting complex capacitor is shown in Figure 4.73.
A 1st-order 4-phase RC ﬁlter may be realized using this concept as shown in Figure 4.74.
The circuit is symmetric, and takes a differential quadrature signal as an input. Since a real
capacitor in series with the signal creates a highpass function, that is, produces a null at DC, we
expect the polyphase ﬁlter to have the same characteristics but shifted to ω0 = 1
RC. This is
shown in Figure 4.74. Alternatively the polyphase transfer function may be understood based
on the fact that, in the case of the positive sequence (or positive frequency) input, after
experiencing phase shift from each RC branch, the signals are added constructively, thus
HPP( f)
V1
V2
V3
V4
0
90
180
270
0
90
180
270
Positive sequence
Negative sequence
0
f
Positive freq.
(or sequence)
Negative freq.
(or sequence)
1
2
3
4
1
2
3
4
Figure 4.72: A 4-phase network with inputs having negative and positive sequences
V1
V2 = –j× V1
C
Cw0
Figure 4.73: Complex capacitor realization
4.7 Quadrature Filters
261

providing a ﬂat passband with a gain of √2 at or around ω =
1
RC. On the other hand, for the
negative sequence, the inputs are subtracted after experiencing the phase shift. In fact at the
exact frequency of 1/RC for the negative sequence, each of the four signals that are –90º apart,
experiences exactly another +45º of phase shift, and they cancel entirely, creating a null in the
transfer function.
Note that the ﬁlter response plotted in Figure 4.74 is not exactly accurate. The polyphase
ﬁlter is indeed composed of real components (resistors and capacitors), and driven by real
signals, and hence its frequency response is symmetric along the y-axis. What the plot ignores is
the fact that at negative frequencies, the phase sequence of the input changes (Figure 4.72). In
other words, the ﬁlter will have a symmetric ﬂat passband for one sequence (labeled as main),
and has the null for the other sequence (labeled as image), as shown in Figure 4.75. The
w
|HPP(w)|
1/RC
0
–1/RC
3dB
R
C
Figure 4.74: A 1st-order RC polyphase ﬁlter
–
–
–
–
–
RC
RC
s
Figure 4.75: Frequency
response of a 1st-order
polyphase ﬁlter to two input
sequences
262
RF and IF Filters

reasoning for calling the sequences main versus image will be clear in Section 4.7.4 in the context
of single-sideband or image-reject receivers. The plot of Figure 4.74 is simply a convenient
representation of the ﬁlter characteristics, combining the response of the two sequences and
assigning one to the negative frequency, and the other to the positive frequencies.
Note that for the main sequence, the passband is not quite ﬂat. The passband has a gain of 1
(or 0dB) at very low and high frequencies, and peaks to
ﬃﬃﬃ
2
p
(or 3dB) at exactly ω =  1
RC. The
transfer function of the 1st-order polyphase ﬁlter (for positive frequencies only) is given below
for the main and image sequences:
HMAIN jω
ð
Þ = 1 + RCω
1 + jRCω
HIMAGE jω
ð
Þ = 1  RCω
1 + jRCω :
The null created by a 1st-order polyphase ﬁlter may be too narrow for many applications.
To extend the null width, as is common in any ﬁlter design, several staggered tuned stages
may be cascaded. The corresponding transfer function of three stages cascaded is shown
in Figure 4.76 (with main and image responses combined), where the stages are identical
but only tuned to 1/R1C1 < 1/R2C2 < 1/R3C3. In addition to the number of stages, the
extended bandwidth is also a function of the minimum stopband null depth. Unlike an
unloaded stage that has a passband gain of 3dB, when two identical stages are connected to
each other, they result in a passband loss of 3dB, and adding more stages rapidly increases the
loss further.
Practical concerns when using polyphase ﬁlters include passband loss, loading presented to
the previous stages, noise, as well as null depth limitation due to ﬁnite matching between
components. A more comprehensive study may be found in [64].
4.7.2
Active Polyphase Filters
Using a similar technique shown in Figure 4.73, active polyphase ﬁlters combined may be realized
[65]. An example of a biquad is shown in Figure 4.77 with the corresponding transfer function on
the right. As expected, the response of a ﬁrst order active lowpass ﬁlter (each branch on top or
bottom) is simply shifted in frequency. The cross-coupled resistors are connected to create
complex capacitors as illustrated in Figure 4.73 already. A negative resistor is simply realizable
w
|HPP(w)|
0
–1/R3C3
–1/R2C2
–1/R1C1
BW
Min null depth
Figure 4.76: Frequency response of a 3rd-
order passive polyphase ﬁlter
4.7 Quadrature Filters
263

in a differential structure, although for convenience the ﬁlter is drawn single-ended. The ﬁlter has a
passband gain of A, a 3dB bandwidth of 2
RC, and a center frequency of ω0 = QB = 2Q/RC. Though
not common due to their complexity, other variations of polyphase ﬁlters such as ladder structures
are also available based on the same concept shown in Figure 4.73 [66].
Example: Shown in Figure 4.78 is a single-stage active polyphase ﬁlter intended for
Bluetooth applications. Also shown is the ﬁlter transfer function for the I output. The
Q output has the same magnitude, but is 90 out of phase. The ﬁlter is intended to have a
3dB bandwidth of 2MHz, centered at 2MHz. The input resistor is adjusted for a passband
voltage gain of 20dB.
VI
VQ
C
R
–
R/2Q
R/2Q
w
R/A
VQ = –jVI
|HPP(w)|
2Q/RC
B = 2/RC
Figure 4.77: An active polyphase biquad
20k
VIP
VOP
2k
8p
Frequency, MHz
1
Transfer Function, dB
0
10
0
2
5
15
20
10
3
4
5
6
7
8
9
Main
Image
20k
VOQ
8p
VIQ
2k
+10k
–10k
Figure 4.78: Bluetooth biquad and the simulated ﬁlter transfer function
264
RF and IF Filters

The two transfer functions shown belong to the two cases of I leading Q, and I lagging.
The latter, labeled as image, could be thought of as negative frequencies, so when ﬂipped
and attached to the ﬁrst transfer function, it will resemble the composite plot of
Figure 4.77. The amount of image rejection for this ﬁrst order design is fairly small,
and about 13dB. Like other types of ﬁlter, several stages must be stagger-tuned to provide
sharper rejection.
Example: To improve the rejection of the ﬁlter of previous example we would like to
design a 2nd-order Butterworth ﬁlter with the same 2MHz bandwidth and center
frequency.
The characteristic function of a 2nd-order Butterworth ﬁlter is K(s) = s2, leading
to H sð Þ = s2 +
ﬃﬃﬃ
2
p
s + 1. So there are two complex poles (or natural frequencies) at
ﬃﬃ
2
p
2  j
ﬃﬃ
2
p
2 . A single-stage active polyphase ﬁlter (Figure 4.77) realizes a transfer
function of
A
RC
jω + 1
RC  j2Q
RC
:
Assuming normalized lowpass poles of α  jβ, and a scaling factor of k, shifting to ω0 will
result in
1
RC  j2Q
RC = kα  jkβ  jω0:
Thus,
1
RC = kα
Q = ω0  kβ
2kα
:
Making the arbitrary choice of setting all the feedback resistors to R = 20k, since α =
ﬃﬃ
2
p
2 ,
and k = 2π  106 (note that the equivalent lowpass bandwidth is 1MHz), we have
C = 11.3p. With ω0 = 2π  2  106, for the two stages we obtain Q1 = 0.93, and
Q2 = 1.92. We intentionally assign the lower Q to the ﬁrst stage, as it will be lower
tuned, which results in more stopband ﬁltering at the output of the ﬁrst stage.
Shown in Figure 4.79 is the complete 2nd-order ﬁlter schematic. The gain of the ﬁrst
stage is adjusted to 20dB, but since it is tuned at 1.41MHz, it has about 6dB of droop at
2MHz, and thus to get a net gain of 20dB, the input resistor of the 2nd stage is scaled to
have a net passband gain of 20dB.
Continued
4.7 Quadrature Filters
265

The ﬁlter frequency response is plotted in Figure 4.80. Also shown is the ﬁlter response at the
output of its ﬁrst stage, which is tuned at 1.41MHz. The image rejection at 2MHz is now 25dB.
Unlike their passive counterparts, the active polyphase stages provide gain, and also ﬁltering in
general, whereas the passive polyphase stages only reject the image, while not affecting the other
frequencies much. This of course comes at the expense of more noise and power consumption for
active ﬁlters.
4.7.3
Quadrature Generation
The polyphase ﬁlter to function properly requires a polyphase signal. For example, a quadrature
input is needed in the case of 4-phase networks shown earlier. There are a number of ways of
20k
VIP
VOP1
2k
11.3p
20k
VOQ1
11.3p
VIQ
2k
+10.8k
–10.8k
20k
VOP
10k
11.3p
20k
VOQ
10k
+5.2k
–5.2k
11.3p
Figure 4.79: A 2nd-order active polyphase ﬁlter
Frequency, MHz
1
Transfer Funcon, dB
–15
5
0
2
–5
15
10
3
4
5
6
7
8
9
Main
Image
Main, 1st stage
Figure 4.80: Frequency response of the 2nd-
order ﬁlter of Figure 4.80
266
RF and IF Filters

creating quadrature signals; perhaps the most natural one is to use the same polyphase network
shown earlier. Consider Figure 4.81, where a differential (2-phase) input is applied to a
polyphase ﬁlter whose adjacent inputs are shorted. The 2-phase input can be broken into two
4-phase signals with opposite sequences.
One sequence will be rejected by the polyphase ﬁlter, assuming its frequency is selected
appropriately to lie in the stopband of the ﬁlter. The resultant quadrature output has 6dB less
magnitude compared to the input, but since a balanced unloaded polyphase stage has a
passband gain of 3dB, the overall passband loss is 3dB. To achieve a reasonable bandwidth,
and to cover RC process variations, it is likely needed to cascade several stages, leading to
further loss. Thus using a polyphase ﬁlter may not be the most viable option to generate
quadrature signals.
A more common way is to use a frequency divider with a divide ratio of 2n, for example, a
divide by two. This results in an accurate quadrature generation with much wider bandwidth as
long as the divider is functional (Figure 4.82). The drawback is the need to run the master
oscillator at higher frequency, at least twice as much. There are however other advantages of
running the main oscillator at a different frequency from the carrier, which we will discuss in
Chapter 12. For these reasons, division by 2 (or 4) seems the most appealing method of
producing quadrature signals in most modern radios. The dividers and their limitations will
be extensively covered in Chapter 10.
Example: Consider a two-stage polyphase ﬁlter shown in Figure 4.83 used for quadrature
generation. The values of R and C to resonate at 5.5GHz would be R = 1kΩ, and C = 29fF.
Each of the stages are shifted in frequency by 10% to create as much ﬂatness as possible
around 5.5GHz center frequency, as shown in the ﬁgure.
Continued
Positive sequence
1
2
4
3
Negative sequence
1
2
4
3
Polyphase Filter
Quadrature Output
1
2
3
4
2
2
4
4
+
≡ 
Figure 4.81: Quadrature generation using polyphase ﬁlters
Divide by two
Quadrature Output
Differential Input
Figure 4.82: A divide by two used to produce quadrature outputs
PPF # 1
0.9R & C
1
2
3
4
PPF # 2
1.1R & C
0
180°
IP1
QP1
IN1
QN1
IP2
QP2
IN2
QN2
Figure 4.83: A two-stage polyphase
quadrature generator
4.7 Quadrature Filters
267

In Problem 24 we show that if the two stages are identical, the transfer function to the
I output of the ﬁrst state is
1 + jRCω
1 + 4jRCω  RCω
ð
Þ2 ,
and to the I output of the second stage is
1 + RCω
1 + 4jRCω  RCω
ð
Þ2 :
Thus, the ﬁrst stage has a passband loss of 1 + j
j
j
4j
j j = 9dB (to be precise at ω =
1
RC), whereas
the total loss is about 1 + 1
j
j
4j
j j = 6dB as the second stage has a gain of 3dB. The simulated
losses at 5.5GHz are 8.1dB and 5.6dB, respectively, for each stage. The small difference
is due to the approximation of assuming identical stages.
Similarly, the transfer function to the Q output of the ﬁrst state is
jRCω 1 + jRCω
ð
Þ
1 + 4jRCω  RCω
ð
Þ2 ,
and to the Q output of the second stage is
jRCω 1 + RCω
ð
Þ
1 + 4jRCω  RCω
ð
Þ2 :
Thus, the magnitude of gain imbalance between the I and Q outputs is
1 + RCω
j
j 1  RCω
j
j
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  RCω
ð
Þ2

2
+ 4RCω
ð
Þ2
r
:
The simulatedmagnitude of I/Q gain imbalance for each of the stages isshownin Figure 4.84.
Note that all the outputs have a perfect phase difference at all frequencies given the
symmetric nature of the ﬁlter (as long as there are no mismatches), whereas the gain imbalance
Frequency, GHz
2
Gain Imbalance, dB
10
1
4
6
8
10
0
5
15
3
5
7
9
Stage 2
Stage 1
0.25dB
Figure 4.84: Simulated gain
imbalance of the polyphase ﬁlter of
Figure 4.83
268
RF and IF Filters

is frequency dependent, as shown in Figure 4.84, and predicted by the equation. The addition
of a second stage extends the gain ﬂatness quite a bit, e.g., the gain imbalance remains below
0.25dB from 4.2GHz to 7.2GHz, roughly 3GHz.
4.7.4
Polyphase Filters Application in Single-Sideband Receivers
A common use of polyphase ﬁlters is in single-sideband or image-reject receivers introduced in
Chapter 2. There we showed that by exploiting quadrature multiplication along with the Hilbert
transform, the spectrum around one sideband of the carrier can be rejected (Figure 4.85 left
block diagram). As shown in the right block diagram of Figure 4.85, the Hilbert transform may
be realized in analog domain through a polyphase ﬁlter. In many cases the multiplier output is
differential, and hence the quadrature differential multiplication creates a 4-phase sequence
labeled by I+, I, Q+, and Q as needed in a polyphase ﬁlter.
To understand how the receiver functions, let us assume the input to the receiver is a tone at
the upper side of the carrier, that is,
xC(t) = cos(ωC + ωm)t.
After multiplication, assuming the multipliers lowpass ﬁlter the high-frequency component
around 2ωC, the following signals appear at the polyphase ﬁler inputs:  cos ωmt at the
differential I input, and ∓sin ωmt =  cos(ωmt + 90) at the differential Q input. So the
Q input is leading the I input by 90. Now if the input lies at the lower sideband, that is,
xC(t) = cos(ωC  ωm)t,
then the differential Q input changes to  cos(ωmt  90), while the differential I input remains
intact, which is to say the Q input is now lagging the I input. Thus, the polyphase input sees two
different sequences for the signals at main and image (or upper and lower) sidebands, and
consequently one is rejected if the ﬁlter is tuned to ωm. The choice of upper or lower sidebands
is of course arbitrary, and depends only on how the polyphase ﬁlter inputs are connected to the
differential I and Q multipliers.
w
w
xc(t)
t
I
Q
c
tc
x t
S
w tc
w tc
xc(t)
I
I–
–
Q
Q
Figure 4.85: Single-sideband receiver employing a polyphase ﬁlter
4.7 Quadrature Filters
269

4.8
Summary
This chapter deals with ﬁlter topologies used in RF and IF stages of radios.
– Ideal ﬁlters and their causality were discussed in Section 4.1.
– Section 4.2 discussed the general principles of ﬁlter speciﬁcation and realizability, and
presented the design procedure of double-terminated LC ladder ﬁlters.
– Following the LC ﬁlters, opamp-RC and gm-C active ﬁlters were presented in Section 4.3.
These ﬁlters are widely used at the IF of both transmitters and receivers in most modern radios.
– Surface and bulk acoustic wave ﬁlters were discussed in Section 4.4. Both ﬁlters are
commonly used at the RF input of transceivers.
– A brief recast of SAW/FBAR duplexers was presented in Section 4.5. Additionally, an
introduction to electrical balance duplexers as an alternative for external duplexers was
offered in that section.
– Section 4.6 dealt with N-path ﬁlters, which have become recently popular in mostly
receivers.
– Finally in Section 4.7 we discussed the principles of quadrature signals, polyphase ﬁlters, and
quadrature generation.
4.9
Problems
1. The input impedance of the circuit shown below is expressed as
Z sð Þ = N sð Þ
D sð Þ = ansn + an1sn1 +    + a1s + a0
bmsm + bm1sm1 +    + b1s
,
where |n  m|  1.
Z2(s)
C
Z(s)
Show that the value of the series input capacitor is
C =
∂
∂s D sð Þ

s = 0
N 0
ð Þ
:
2. A one-port has the input impedance
Z sð Þ = 2s3 + 2s + 1
s2 + 1
:
Using a similar approach as Problem 1, ﬁnd the value of the series input inductance, and
synthesize the rest of the circuit.
270
RF and IF Filters

3. For a causal function h(t) with ﬁnite energy (
Ð ∞
∞H ω
ð Þ
j
j2dω < ∞), the Paley–Wiener
theorem states that
Ð ∞
∞
Ln H ω
ð Þ
j
j
1 + ω2 dω must exist and be ﬁnite. Show, as such, an ideal ﬁlter
like the one shown in Figure 4.1 cannot exist.
4. As an alternative to the proof presented in the previous problem, in this problem we show
that an ideal ﬁlter requires inﬁnite number of elements, and hence is not realizable.
a. Show that no rational function
K
j j2 = a0 + a1ω2 + . . . + anω2n
b0 + b1ω2 + . . . + bmω2m
cannot be zero at all points of a frequency range 0  ω  ωp, unless ai = 0 for all i, and
hence |K|2 = 0.
b. Using the same reasoning as part a, show that
1
K
j j2 cannot be zero at every point of a
frequency range. What are the implications?
5. Consider the 3rd-order maximally ﬂat ﬁlter below.
a. Calculate the transducer parameters directly based on the deﬁnition.
b. Find the LC two-port impedance parameters.
c. Redo part a indirectly by using the two-port z parameters.
d. Assuming |VS| = 1V RMS, ﬁnd the reﬂected power and the power delivered to the load at
ω = 0, ω = 1, and ω = 10rad/s.
1W
VS
Z1
Z2
+
V2
–
+
V1
–
I1
I2
2H
1F
1W
1F
LC 2-Port
6. While the transducer factor (H(s)) can be obtained directly based the z parameters of the
two-port, a simpler yet more elegant approach is described below.
a. Show that the two-ports shown below are equivalent.
b. For the two-port on the right, show that IL
Vs = y21.
c. Knowing that [Y] = [Z]1, ﬁnd an expression for VL
Vs, and subsequently H(s).
RS
VS
RL
Lossless 2-port
z11+Rs
z22+RL
z12
z21
IL
z11
z22
z12
z21
+
VL
–
VS
IL
7. Prove the Feldtkeller equation using the H(s) and K(s) derived based on the two-port
impedance parameters.
8. Show that Δz = z11z22  z122 = RsRL
HoKo
Ho + Ko. Hint: Use the Feldtkeller equation.
4.9 Problems
271

9. Consider Z(s), representing the impedance of an RLCM one-port (Figure 4.12).
Arguing that at inﬁnity Z(s) is dominated by either its capacitors or inductors, show
that the degrees of the numerator and the denominator can differ by no more than one.
10. Show that the polynomial P(s) = s5 + s4 + 6s3 + 6s2 + 25s + 25 is not Hurwitz, despite
having positive coefﬁcients with no missing terms.
11. Assume Z(jω) = jX(jω) describes an LC one-port impedance. Considering that the LC
impedance has only simple jω axis poles, using partial fraction of the impedance prove that
d
dω X > 0 for all ω.
12. Show that the zeros of H(s)H(s) for a normalized maximally ﬂat ﬁlter are at
sk = ejπ(n  1 + 2k)/2n for k = 1, 2, . . ., 2n.
13. Prove that for a Butterworth ﬁlter, the ﬁlter degree is n 
log
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
10αs=101
10αp=101
q
log ωs
ωp
.
14. For a Chebyshev ﬁlter with |K|2 = kp
2 cos2nu = kp
2 cos2(n cos1ω), show that upon expan-
sion |K|2 is indeed a polynomial in ω2. Hint: Use the identity cos nu = Re [ejnu] =
Re [(cos u + j sin u)n], and expand.
15. Prove that in a Chebyshev ﬁlter, for ω  1: K
j j2 = kp2
4
ω+
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ω2  1
p

n
+ ω+
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ω2  1
p

n
h
i2
.
Hint: Use the identity cos nu
ð
Þ= ejnu +ejnu
2
.
16. Shown below is an active-RC biquad stage, suitable for high-Q applications.
a. Find the biquad transfer function.
b. Show the spread of the elements is less compared to the biquad of Figure 4.47 when the
required Q is large.
1
1
K2
K1/w0
w0/K0
–1/w0
1/w0
Vo
Vs
1/Q
17. The gyrator below is terminated by a capacitance C, and is described by an admittance
matrix of Y =
0
g1
g2
ϵ
h
i
, where ϵ, g1, g2 > 0.
a. With ϵ = 0, ﬁnd the impedance ZIN looking into the gyrator.
b. Explain how ϵ affects ZIN and construct an equivalent circuit model.
272
RF and IF Filters

C
ZIN
+
v1
–
i1
18. An active-RC gyrator to simulate a grounded inductor known as the Riordan gyrator [67] is
shown below.
a. Show that if the opamps are ideal, the effective inductance is given by L = R1R3R4
R2
C.
b. If the opamps have a ﬁnite DC gain of A0, show that the inductance quality factor is
equal to Q =
A0
R1R3Cω
R2
+
1
R3Cω.
C
R1
R2
R3
R4
ZIN
19. For the following active gyrator, the capacitor C is voltage-dependent given by C = f(v),
prove
that
the
effective
inductor
is
current-dependent
with
value
given
by
L =
1
gm2 f
1
gm iin


.
gm
C = f(v)
–gm
iIN
+
v
–
20. A generic Sallen–Key topology is illustrated below. Show that the ﬁlter transfer function is
Vo
Vs
=
Z3Z4
Z1Z2 + Z3 Z1 + Z2
ð
Þ + Z3Z4
:
Z3
Z4
Z2
Z1
Vs
Vo
–
4.9 Problems
273

21. Show that the input impedance of an unloaded polyphase ﬁlter is R
2 +
1
j2Cω.
22. Find the input impedance of a polyphase ﬁlter loaded by an arbitrary load ZL.
23. Find the input impedance of a polyphase ﬁlter loaded by an identical stage.
24. Consider a two-stage polyphase ﬁlter (Figure 4.83) with identical resistors of R and
capacitors of C used for quadrature generation. Show that the transfer function to the
I output of the ﬁrst state is
1 + jRCω
1 + 4jRCω RCω
ð
Þ2, and to the I output of the second stage is
1 + RCω
1 + 4jRCω RCω
ð
Þ2. Hint: Use the ﬁndings of Problem 21 to load the ﬁrst stage properly.
25. Consider the following one-stage polyphase ﬁlter, where all the resistors and capacitors are
identical, loaded by nonidentical loads. Calculate the transfer function. What is the
passband loss and image rejection if the loads are identical? Repeat for the case the
I and Q loads are different, as shown.
R
C
ZI
ZQ
ZI
ZQ
26. Design a two-stage passive polyphase ﬁlter to produce quadrature outputs from a differen-
tial clock signal at 1.6GHz. Assume the resistors and capacitors have each a process
variation of 10%. Design for the best possible quadrature accuracy given the variation of
the components.
4.10 References
[1] G. C. Temes and S. K. Mitra, Modern Filter Theory and Design, John Wiley, 1973.
[2] G. Temes, “The Present and Future of Filter Theory,” IEEE Transactions on Circuit Theory, 15, no. 12,
302 1968.
[3] G. C. Temes and J. W. Lapatra, Introduction to Circuit Synthesis and Design, vol. 15, McGraw-Hill,
1977.
[4] R. Gregorian and G. C. Temes, Analog MOS Integrated Circuits for Signal Processing, vol. 1, Wiley-
Interscience, 1986.
274
RF and IF Filters

[5] H. J. Orchard, G. C. Temes, and T. Cataltepe, “General Sensitivity Formulas for Lossless Two-Ports,”
Electronics Letters, 19, no. 7, 576–578, 1983.
[6] H. Orchard, G. Temes, and T. Cataltepe, “Sensitivity Formulas for Terminated Lossless Two-Ports,”
IEEE Transactions on Circuits and Systems, 32, no. 5, 459–466, 1985.
[7] G. Temes and H. Orchard, “First-Order Sensitivity and Worst Case Analysis of Doubly Terminated
Reactance Two-Ports,” IEEE Transactions on Circuit Theory, vol. 20, no. 9, 567–571, 1973.
[8] C. A. Desoer and E. S. Kuh, Basic Circuit Theory, McGraw-Hill Education, 2009.
[9] M. E. Van Valkenburg, Introduction to Modern Network Synthesis, John Wiley, 1965.
[10] O. Brune, “Synthesis of a Finite Two-Terminal Network Whose Driving-Point Impedance is a Prescribed
Function of Frequency,” Journal of Mathematics and Physics, 10, 191–236, 1931.
[11] R. M. Foster, “A Reactance Theorem,” Bell System Technical Journal, 3, no. 4, 259–267, 1924.
[12] H. J. Orchard and G. C. Temes, “Maximally Flat Approximation Techniques,” Proceedings of the IEEE,
56, no. 1, 65–66, 1968.
[13] A. I. Zverev, et al., Handbook of Filter Synthesis, vol. 47, John Wiley, 1967.
[14] L. Weinberg, Network Analysis and Synthesis, RE Krieger, 1975.
[15] E. Christian and E. Eisenmann, Filter Design Tables and Graphs, John Wiley, 1966.
[16] A. J. Grossman, “Synthesis of Tchebycheff Parameter Symmetrical Filters,” Proceedings of the IRE, 45,
454–473, 1957.
[17] H. Orchard and G. Temes, “Filter Design Using Transformed Variables,” IEEE Transactions on Circuit
Theory, 15, no. 12, 385–408, 1968.
[18] Y. Tsividis and J. Voorman, Integrated Continuous-Time Filters: Principles, Design, and Applications,
IEEE Press, 1993.
[19] G. Temes, H. Orchard, and M. Jahanbegloo, “Switched-Capacitor Filter Design Using the Bilinear z-
Transform,” IEEE Transactions on Circuits and Systems, 25, no. 12, 1039–1044, 1978.
[20] R. P. Sallen and E. L. Key, “A Practical Method of Designing RC Active Filters,” IRE Transactions on
Circuit Theory, 2, no. 3, 74–85, 1955.
[21] H. Khorramabadi and P. Gray, “High-Frequency CMOS Continuous-Time Filters,” IEEE Journal of
Solid-State Circuits, 19, no. 6, 939–948, 1984.
[22] B. D. H. Tellegen, “The Gyrator, a New Electric Network Element,” Philips Research Reports, 3, 81–101,
1948.
[23] A. G. J. Holt and J. Taylor, “Method of Replacing Ungrounded Inductors by Grounded Gyrators,”
Electronics Letters, 1, no. 6, 105, 1965.
[24] Y.-T. Wang and A. Abidi, “CMOS Active Filter Design at Very High Frequencies,” IEEE Journal of
Solid-State Circuits, 25, no. 6, 1562–1574, 1990.
[25] K. M. Lakin, J. R. Belsick, J. P. McDonald, K. T. McCarron, and C. W. Andrus, “Bulk Acoustic Wave
Resonators and Filters for Applications above 2GHZ,” in IEEE MTT-S Microwave Symposium Digest,
2002.
[26] J. Tsutsumi, S. Inoue, Y. Iwamoto, T. Matsuda, M. Miura, Y. Satoh, M. Ueda, and O. Ikata, “Extremely
Low-Loss SAW Filter and Its Application to Antenna Duplexer for the 1.9GHZ PCS Full-Band,” in IEEE
Proceedings of Frequency Control Symposium, 2003.
[27] F. Z. Bi and B. P. Barber, “Bulk Acoustic Wave RF Technology,” IEEE Microwave Magazine, 9, 65–80,
2008.
[28] R. Ruby, “FBAR—From Technology Development to Production,” in Proceedings of the 2nd
International Symposium on Acoustic Wave Devices for Future Mobile Communication Systems,
Chiba, Japan, 2004.
[29] R. Ruby and P. Merchant, “Micromachined Thin Film Bulk Acoustic Resonators,” in Proceedings of the
IEEE 48th Annual Symposium on Frequency Control, 1994.
[30] R. Ruby, P. Bradley, J. D. Larson, and Y. Oshmyansky, “PCS 1900 MHz Duplexer Using Thin Film Bulk
Acoustic Resonators (FBARs),” Electronics Letters, 35, no. 5, 794–795, 1999.
4.10 References
275

[31] R. Ruby, P. Bradley, J. Larson, Y. Oshmyansky, and D. Figueredo, “Ultra-Miniature High-Q Filters and
Duplexers Using FBAR Technology,” in Proceedings of the IEEE International Solid-State Circuits
Conference Digest of Technical Papers, 2001.
[32] K. M. Lakin, G. R. Kline, and K. T. McCarron, “Thin Film Bulk Acoustic Wave Filters for GPS,” in
Proceedings of the IEEE 1992 Ultrasonics Symposium, 1992.
[33] L. Rayleigh, “On Waves Propagated Along the Plane Surface of an Elastic Solid,” Proceedings of the
London Mathematical Society, 17, 4–11, 1885.
[34] T. W. Grudkowski, J. F. Black, T. M. Reeder, D. E. Cullen, and R. A. Wagner, “Fundamental Mode UHF/
VHF Miniature Resonators and Filters,” Applied Physics Letters, 39, 993–995, 1980.
[35] K. M. Lakin and J. S. Wang, “Acoustic Bulk Wave Composite Resonators,” Applied Physics Letters, 38,
125–127, 1981.
[36] K. A. Sankaragomathi, J. Koo, R. Ruby, and B. P. Otis, “25.9 A 3ppm 1.1mW FBAR Frequency
Reference with 750MHz Output and 750mV Supply,” in Proceedings of the IEEE International Solid-
State Circuits Conference – (ISSCC) Digest of Technical Papers, 2015.
[37] W. Pang, R. C. Ruby, R. Parker, P. W. Fisher, M. A. Unkrich, and J. D. Larson, “A Temperature-Stable
Film Bulk Acoustic Wave Oscillator,” IEEE Electron Device Letters, 29, no. 4, 315–318, 2008.
[38] R. Ruby, P. Bradley, D. Clark, D. Feld, T. Jamneala, and K. Wang, “Acoustic FBAR for Filters,
Duplexers and Front End Modules,” in Proceedings of the IEEE MTT-S International Microwave
Symposium Digest, 2004.
[39] J. D. Larson, J. D. Ruby, R. C. Bradley, J. Wen, S.-L. Kok, and A. Chien, “Power Handling and
Temperature Coefﬁcient Studies in FBAR Duplexers for the 1900 MHz PCS Band,” in Proceedings of
the IEEE Ultrasonics Symposium, 2000.
[40] Y. Wang, C. Feng, T. Lamers, D. Feld, P. Bradley, and R. Ruby, “FBAR Resonator Figure of Merit
Improvements,” in Proceedings of the IEEE International Ultrasonics Symposium, 2010.
[41] N. Kamogawa, S. Dokai, N. Shibagaki, M. Hikita, T. Shiba, S. Ogawa, S. Wakamori, K. Sakiyama, T.
Ide, and N. Hosaka, “Miniature SAW Duplexers with High Power Capability,” in Proceedings of the
IEEE Ultrasonics Symposium, 1998.
[42] M. Mikhemar, H. Darabi, and A. A. Abidi, “A Multiband RF Antenna Duplexer on CMOS: Design and
Performance,” IEEE Journal of Solid-State Circuits, 48, no. 9, 2067–2077, 2013.
[43] B. Debaillie, D. Broek, C. Lavín, B. Liempd, E. A. M. Klumperink, C. Palacios, J. Craninckx, B. Nauta,
and A. Pärssinen, “Analog/RF Solutions Enabling Compact Full-Duplex Radios,” IEEE Journal on
Selected Areas in Communications, 32, no. 9, 1662–1673, 2014.
[44] M. Elkholy, M. Mikhemar, H. Darabi, and K. Entesari, “Low-Loss Integrated Passive CMOS Electrical
Balance Duplexers with Single-Ended LNA,” IEEE Transactions on Microwave Theory and Techniques,
64, no. 5, 1544–1559, 2016.
[45] B. Hershberg, B. Liempd, X. Zhang, P. Wambacq, and J. Craninckx, “20.8 A Dual-Frequency 0.7-to-
1GHz Balance Network for Electrical Balance Duplexers,” in Proceedings of the IEEE International
Solid-State Circuits Conference, 2016.
[46] G. Qi, B. Liempd, P. Mak, R. P. Martins, and J. Craninckx, “A SAW-Less Tunable RF Front End for
FDD and IBFD Combining an Electrical-Balance Duplexer and a Switched-LCN-Path LNA,” IEEE
Journal of Solid-State Circuits, 53, no. 5, 1431–1442, 2018.
[47] G. A. Campbell and R. M. Foster, “Maximum Output Networks for Telephone Substation and Repeater
Circuits,” Transactions of the American Institute of Electrical Engineers, 39, no. 1, 231–290, 1920.
[48] E. Sartori, “Hybrid Transformers,” Materials and Packaging IEEE Transactions on Parts, 4, no. 9,
59–66, 1968.
[49] H. Darabi and A. Mirzaei, Integration of Passive RF Front End Components in SoCs, Cambridge
University Press, 2013.
[50] A. Ghaffari, E. A. M. Klumperink, M. C. M. Soer, and B. Nauta, “Tunable High-Q N-Path Band-Pass
Filters: Modeling and Veriﬁcation,” IEEE Journal of Solid-State Circuits, 46, 998–1010, 2011.
276
RF and IF Filters

[51] A. Ghaffari, E. A. M. Klumperink, and B. Nauta, “Tunable N-Path Notch Filters for Blocker Suppression:
Modeling and Veriﬁcation,” IEEE Journal of Solid-State Circuits, 48, no. 6, 1370–1382, 2013.
[52] M. Darvishi, R. Zee, and B. Nauta, “Design of Active N-Path Filters,” IEEE Journal of Solid-State
Circuits, 48, no. 12, 2962–2976, 2013.
[53] M. Darvishi, R. Zee, E. A. M. Klumperink, and B. Nauta, “Widely Tunable 4th Order Switched G_m-C
Band-Pass Filter Based on N-Path Filters,” IEEE Journal of Solid-State Circuits, 47, no. 12, 3105–3119,
2012.
[54] E. A. M. Klumperink, H. J. Westerveld, and B. Nauta, “N-Path Filters and Mixer-First Receivers:
A Review,” in Proceedings of the IEEE Custom Integrated Circuits Conference, 2017.
[55] N. Barber, “Narrow Band-Pass Filter Using Modulation,” Wireless Engineer, 24, 132–134, 1947.
[56] B. D. Smith, “Analysis of Commutated Networks,” Transactions of the IRE Professional Group on
Aeronautical and Navigational Electronics, PGAE-10, 21–26, 1953.
[57] L. E. Franks and I. W. Sandberg, “An Alternative Approach to the Realization of Network Transfer
Functions: The N-Path Filter,” IEEE RFIC Virtual Journal, 39, 1321–1350, 1960.
[58] L. Franks and F. Witt, “Solid-State Sampled-Data Bandpass Filters,” in Proceedings of the IEEE
International Solid-State Circuits Conference Digest of Technical Papers, 1960.
[59] A. Oualkadi, M. Kaamouchi, J. Paillot, D. Vanhoenacker-Janvier, and D. Flandre, “Fully Integrated High-
Q Switched Capacitor Bandpass Filter with Center Frequency and Bandwidth Tuning,” in Proceedings of
the IEEE Radio Frequency Integrated Circuits (RFIC) Symposium, 2007.
[60] A. Mirzaei, H. Darabi, and J. Leete, Frequency Translated Filter, US patent 8,301,101, ﬁled May 22,
2009, issued October 13, 2012.
[61] A. Mirzaei, H. Darabi, A. Yazdi, Z. Zhou, E. Chang, and P. Suri, “A 65 nm CMOS Quad-Band SAW-
Less Receiver SoC for GSM/GPRS/EDGE,” IEEE Journal of Solid-State Circuits, 46, no. 4, 950–964,
2011.
[62] A. Ghaffari, E. A. M. Klumperink, and B. Nauta, “A Differential 4-Path Highly Linear Widely Tunable
On-Chip Band-Pass Filter,” in Proceedings of the IEEE Radio Frequency Integrated Circuits Symposium,
2010.
[63] M. Gingell, “Single Sideband Modulation Using Sequence Asymmetric Polyphase Networks,” Electrical
Communication, 48, nos. 1–2, 21–25, 1973.
[64] F. Behbahani, Y. Kishigami, J. Leete, and A. Abidi, “CMOS Mixers and Polyphase Filters for Large
Image Rejection,” IEEE Journal of Solid-State Circuits, 36, no. 6, 873–887, 2001.
[65] J. Crols and M. Steyaert, “An Analog Integrated Polyphase Filter for a High Performance Low-IF
Receiver,” in Digest of Technical Papers: 1995 Symposium on VLSI Circuits, 1995.
[66] J. Haine, “New Active Quadrature Phase-Shift Network,” Electronics Letters, 13, no. 7, 216–218, 1977.
[67] R. H. S. Riordan, “Simulated Inductors Using Differential Ampliﬁers,” Electronics Letters, 3, no. 2,
50–51, 1967.
[68] H. J. Orchard, “Inductorless Filters,” Electronics Letters, 2, no. 6, 224–225, 1966.
[69] H. J. Orchard and D. F. Sheahan, “Inductorless Bandpass Filters,” IEEE Journal of Solid-State Circuits, 5,
no. 6, 108–118, 1970.
4.10 References
277

5
Noise
An unavoidable cause of electrical noise is the random thermal motion of electrons in
conducting media such as wires or resistors. Active circuits comprising MOS transistors suffer
from similar random motion of electrons leading to noise. As long as communication systems
are constructed from such devices, the noise will be with us. Amplifying arbitrarily weak signals
to make them detectable is unrealistic, as the presence of noise sets a lower limit to minimum
detectable signal.1 This ultimately limits the range where the transmitter and receiver can
communicate, yet maintaining a minimum signal-to-noise ratio at the detector output.
This chapter starts with a review of noise sources present in RF components, including how
they are modeled and dealt with in the context of two-ports. We then deﬁne the noise ﬁgure
as a universal ﬁgure of merit describing the noise properties of a circuit, and link that to the
minimum detectable signal achievable in a given radio. Finally we present the concept of
minimum noise ﬁgure, and a systematical approach to optimize the signal-to-noise in ampli-
ﬁers. Most of this chapter deals with linear and time-invariant circuits such as RF ampliﬁers.
We will also present the cyclostationary noise to set the foundation for the mixer and oscillator
noise analysis. A detailed study of noise in time-variant or nonlinear circuits such as mixers or
oscillators is presented in Chapters 8, and 9, respectively, although many basic concepts
introduced in this chapter are still applicable.
The speciﬁc topics covered in this chapter are:
• Thermal and white noise, cyclostationary noise, as well as FET thermal and ﬂicker noise
• Noise of lossy passive circuits
• Noise ﬁgure
• Minimum noise ﬁgure, and noise optimization
• Introduction to phase noise
• Sensitivity
• Noise measurement techniques
For class teaching, we recommend presenting a brief summary of Sections 5.1 and 5.2, while
fully covering Sections 5.3, 5.4, 5.6, and 5.8. Particularly, much of the material on noise ﬁgure
deﬁnition and noise optimization (Sections 5.3 and 5.4) will be directly used in Chapter 6.
Sections 5.7 and 5.9 may be assigned as reading.
1 The upper limit is set by the distortion that will be discussed in the next chapter.

5.1
TYPES OF NOISE
..............................................................................................
In this section we brieﬂy discuss the types of noise present in RF components, namely resistors,
capacitors, inductors, as well as transistors.
5.1.1
Thermal Noise
Thermal noise is the noise due to the random motion of charged particles, and particularly the
electrons in a conducting device. In 1906 Einstein predicted that the Brownian motion of
charged particles results in an electromotive force (emf ) across the two open terminals of a
resistor. The effect was ﬁrst observed by Johnson in 1928, and was mathematically formulated
by Nyquist.2 For that reason the thermal noise is sometimes designated as Johnson or Nyquist
noise as well. The results appeared in the July 1928 issue of a physical review magazine as
side-by-side articles [11], [12].
For a resistor R at a temperature T, the random electron motion produces a noise voltage v(t)
across the two open terminals of the resistor. From the equipartition law in thermodynamics
[17], for each degree of freedom there corresponds an average energy equal to 1
2 KT, where T is
the absolute temperature (measured in Kelvin), and K = 1.371023J/K is the Boltzmann
constant.
Now consider two of such resistors connected with a lossless line of length l (Figure 5.1).
According to the second law of thermodynamics, at a temperature T where the thermal
equilibrium is reached, the total energy as a result of thermal agitation created in one resistor
and delivered to the other is equal to the one produced by the second resistor and delivered to
the ﬁrst one.
With the help of this circuit it is proven in [11] that v2, the average voltage squared across the
resistor given a 1Hz integration bandwidth, is3
v2 = 2KTR:
To present the proof of above equation in a more intuitive way [6], let us consider a parallel
RC circuit (Figure 5.2). We shall ﬁrst ﬁnd the average energy stored on the capacitor as a result
of the resistor noise, and consequently, ﬁnd the noise spectral density.
l
R
R
Figure 5.1: Two resistors connected with a lossless line
2 Both Nyquist and Johnson were born in Sweden, immigrated to the United States, and worked at Bell Labs.
3 This noise is of course speciﬁed in a 1Hz bandwidth. The correct notation in general is v2 = 2KTRΔf for an arbitrary
bandwidth. Throughout this chapter, and most of the book, we take the simplifying assumption that Δf = 1Hz whenever
appropriate.
5.1 Types of Noise
279

As a result of the random thermal agitation of the electrons in the resistor, the capacitor will
be charged and discharged at random. The average energy stored in the capacitor will be
1
2 Cv2,
where v2 is the mean-square value of the voltage ﬂuctuation impressed across the capacitor.
Taken from thermodynamics, if a system has a temperature T, Maxwell–Boltzmann statistics4
states that the probability that it has an energy E is proportional to e
E
KT
ð Þ. Since in the RC circuit
the energy stored in the capacitor C is 1
2 Cv2, then the capacitor voltage has a probability density
function of
f V v
ð Þ = K0e
Cv2
2KT


:
The proportionality factor, K0, is obtained by considering that
ð∞
∞
f V v
ð Þdv = 1,
which is to say that the probability of the capacitor voltage to be between ∞and +∞is one.
Since
Ð ∞
∞ex2dx =
ﬃﬃﬃπ
p , with some simple algebraic steps we ﬁnd
K0 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
C
2πKT
r
:
Now we shall ﬁnd the mean-squared voltage v2 (the second moment):
v2 =
ð∞
∞
v2f V v
ð Þdv =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
C
2πKT
r
ð∞
∞
v2e
CV2
2KT


dv,
and since Ð ∞
∞x2ex2dx =
ﬃﬃπ
p
2 , the integral yields
v2 = KT
C :
Now we will prove that v2 = 2KTR with the help of a parallel RC circuit. We can model the
thermal noise in the resistor as an electromotive force (emf ) in series with a noiseless resistor R,
as shown in Figure 5.2.
R
emf
C
+
v(t)
–
Figure 5.2: Parallel RC circuit with a thermal noise emf associated with
the resistor
4 Maxwell–Boltzmann statistics states that the gas atom density is proportional to exp(–E/KT), where E is the potential
energy [18]. As a result, as the height increases, the gas is expected to be less dense due to higher potential energy.
Maxwell–Boltzmann as well as Fermi–Dirac statistics are widely used in quantum mechanics to describe electron and hole
density in semiconductors.
280
Noise

If the emf source is white and has a spectral density of Semf( f ), considering that the system
transfer function is H f
ð Þ =
1
1 + j2πRCf, the RMS voltage across the capacitor is
v2 = Semf 0
ð Þ
ð∞
∞
H f
ð Þ
j
j2df = 2Semf 0
ð Þ
ð∞
0
df
1 + 2πRCf
ð
Þ2 = Semf 0
ð Þ
2RC ,
which results in a spectral density of 2KTR for the resistor.
As the thermal noise spectrum is symmetric, it is common to consider only positive
frequencies. If so, an extra factor of two appears in the equation to account for the other
half of the energy residing at negative frequencies. Consequently, the thermal noise may be
expressed as 4KTR, and the energy integration will be performed from 0 to ∞instead. We
shall use both notations interchangeably throughput the book, whichever convenient. In the
case of linear ampliﬁers, we will mostly use 4KT. On the other hand, during our analysis of
nonlinear circuits such as oscillators where aliasing is involved, we will use 2KT
more often.
The equipartition law assigns a total energy of 1
2 KT per degree of freedom, regardless of the
frequency. This in fact is not quite accurate. Quantum mechanics shows [18] that the average
energy per degree of freedom is5
1
2
hf
ehf =KT  1 ,
where f is the frequency, and h = 6.61034 J.s is the Planck constant. Clearly, it simpliﬁes to
1
2 KT if the frequency is low enough.
Consequently, the power spectral density of noise is modiﬁed to
Sv f
ð Þ =
2Rhf
ehf =KT  1 ,
expressed in V2/Hz, and plotted in Figure 5.3.
Consistent with central limit theorem, v(t) has a Gaussian distribution, with zero mean. The
zero mean has to do with the fact that the noise voltage is a result of purely random motion of
many electrons. Hence, when observed over a large period of time the opposite direction
movements cancel each other.
f, GHz
Sv(f)
0
1000
2KTR
Figure 5.3: Thermal noise power spectral
density
5 This is derived from Planck’s law, proposed in 1900. Planck postulated that any physical entity can possess only total
energies E in discrete levels (i.e. E = nhf, where n is an integer).
5.1 Types of Noise
281

Example: We shall ﬁnd the thermal noise variance, calculated by ﬁnding v2 = E v2 tð Þ
½
.
By deﬁnition, we have
v2 =
ð∞
∞
Sv f
ð Þdf =
ð∞
0
4Rhf
ehf =KT  1 df = 4Rh
ð∞
0
fehf =KT
1  ehf =KT df :
The integral may be solved using the following expansion (for x > 0):
1
1  ex =
X
∞
n = 0
enx:
This leads to
v2 = 4R
h
KT
ð
Þ2 X
∞
n = 0
1
n + 1
ð
Þ2 :
Since P∞
n = 0
1
n + 1
ð
Þ2 = π2
6 , the variance is found to be
v2 = σv2 = 2 πKT
ð
Þ2
3h
R:
The noise variance calculated above has been experimentally proven as well. The noise of
a 50Ω resistor for instance has a standard deviation of σv = 4.66mV.
As depicted in Figure 5.3, thermal noise power spectrum is not ﬂat, although it is typically
assumed so. In fact if it were, it would have erroneously predicted v2 = ∞when integrated over
all f.6 However, it is instructive to have a sense of h/KT as it appears in the exponential term in
the denominator of the power spectral density equation. For standard room temperature of
25ºC, we obtain KT  410–21J, leading to KT
h  1013Hz, which falls into infrared portion of
the spectrum, clearly well above our frequencies of interest. Thus, for all practical purposes (at
least for now), we can safely assume that
Sv( f ) = 2KTR.
It is common to construct the Thevenin equivalent model of a thermal resistor as shown in
Figure 5.4, where only positive frequencies are considered. Similarly a Norton equivalent can
be obtained considering that Si f
ð Þ = Sv f
ð Þ
R2 . The resistors in Figure 5.4 are therefore noiseless.
Moreover, we have included an extra factor of 2 to assign the spectral density to only positive
frequencies where Sv( f ) = 4KTR.
As a useful example, a 50Ω resistor has an RMS noise voltage of 0.91nV/√Hz.
6 This primarily arises from the fact that an integral over all possible energy from classical mechanics is replaced by a
summation over discrete energy levels in quantum mechanics.
282
Noise

We could also describe the noise based on its available power. As we deﬁned in Chapter 3,
for a given source whose resistance is Zs = Rs + jXs, when driving a certain load with an
impedance ZL, the maximum power transfer then requires the load to be matched to the source:
ZL = ZS*. The noise of the source, vs(t), appears as vs/2 on the load, and the available power is
Pa = < vs tð Þ2 >
4Rs
:
Using the resistor Thevenin model, we can extend this concept, arriving at available spectral
density at the load resistor
Sa f
ð Þ = Sv f
ð Þ
4R
= KT,
which depends only on the temperature, and is independent of the value of R.
5.1.2
White Noise and Noise Bandwidth
Noise of thermal resistors as well as many other types of noise sources are Gaussian and have a
ﬂat power spectral density over practical range of frequencies of interest. Since such a spectrum
has all frequency components in equal proportion, the noise is said to be white, analogous to
white light. The power spectral density can be written in general as
S f
ð Þ = η
2 :
Hence
R τð Þ = η
2 δ τð Þ:
The autocorrelation is zero for τ 6¼ 0, so any two different samples of Gaussian white noise
signal are uncorrelated and hence statistically independent. As a result, if we display white
noise on oscilloscope, successive sweeps are always different from each other, yet the wave-
form looks the same, since all rates of time variation (or equivalently frequency components)
are contained in equal proportion. Similarly, if white noise drives a loudspeaker, it always
sounds the same, although it is not!
Now suppose a Gaussian white noise with the power spectral density of η is applied to an
LTI system with a transfer function H(f ). The output, y(t), will be Gaussian but colored, that is,
the power spectral density of the ﬁltered white noise takes the shape |H(f )|2. Note that the
integration is from 0 as opposed to –∞, which we used in Chapter 2. This takes into account the
R
Sv(f) = 4KTR
R
Si(f) = 4KT/R
Figure 5.4: Resistor noise Thevenin and
Norton equivalents
5.1 Types of Noise
283

fact that we are only considering positive frequencies, and thus assigned twice as much power
to the white noise spectral density.
Sy f
ð Þ = η
2 H f
ð Þ
j
j2
y2
!
= η
ð∞
0
H f
ð Þ
j
j2df
Example: Figure 5.5 shows a white noise passed through an ideal lowpass ﬁlter.
Evidently, Ry(τ) = Bη sinc 2Bτ, and y2 = ηB. Thus, the output power is directly propor-
tional to the ﬁlter bandwidth as expected.
Example: Consider an RC circuit shown in Figure 5.6, where the capacitor is ideal, but
the resistor is noisy.
Using the Thevenin equivalent, we arrive at the circuit on the right. We have Sx( f )= 4KTR,
and H f
ð Þ
j
j2 =
1
1 +
f
Bð Þ
2, where B is the 1st-order lowpass bandwidth equal to 1/2πRC. There-
fore for the output
Sy f
ð Þ =
4KTR
1 +
f
B
 2 ,
and the inverse transform yields
Ry τð Þ = KT
C e τj j=RC:
The output power is then y2 = KT
C , independent of the resistor value (this was already
proven earlier in the context of resistor thermal noise spectral density).
t
1/2B
–1/2B
hB
0
Ry(t)
B
–B
0
|H(f)|
f
1
Figure 5.5: White noise passed by an ideal lowpass ﬁlter
R
Sv(f) = 4KTR
R
C
C
+
v(t)
–
Figure 5.6: RC circuit with
noisy resistor
284
Noise

Given the example above, we deduce that the 1st-order RC ﬁlter could have been replaced by
an ideal lowpass ﬁlter whose bandwidth is
1
4RC, producing the same output power of KT
C . This is
known as the equivalent noise bandwidth. We can show that for a 2nd-order RLC circuit, the
equivalent noise bandwidth is also equal to
1
4RC. For the general case of a Butterworth nth-order
ﬁlter as we deﬁned in Chapter 4, one can prove (see Problem 3) that the equivalent noise
bandwidth (BN) is related to the 3dB bandwidth (B) by
BN =
πB
2n sin π
2n

 ,
and hence BN ! B as n ! ∞.
5.1.3
Inductors and Capacitors Noise
The inductors, capacitors, and transformers are generally noiseless. If there is a loss associated
with them, say an inductor wiring resistance, then that resistor is noisy whose power spectral
density was given earlier. If high-Q, this noise is negligible, unless the loss occurs at the very
input stage of the radio. For example, the loss of the matching network of a receiver comprising
Ls and Cs could lead to nonnegligible noise degradation in the radio.
5.1.4
Passive Lossy Network Noise
Consider Figure 5.7 showing a passive lossy circuit comprising resistors, capacitors, inductors,
or possibly coupled inductors. Since the circuit consists of passive RLCM elements, it is
reciprocal.
Before we analyze the circuit, let us consider the network on the right ﬁrst. The Nyquist
theorem states that the power spectrum of the output voltage v(t) is
Sv( f ) = 2KT Re [Z( f )],
where Z(s) is the impedance associated with that terminal.
We shall present the proof of the Nyquist theorem in a two-step approach. First, we assume
the circuit consists of only one resistor, along with the rest of inductors and capacitors. The
resistor is presented by a noiseless resistance, R, in parallel with its equivalent noise current, and
+
vo
–
ZOUT(s)
R
R
Z(s)
I(f)
V(f)
v(t)
Lossy Passive Network
Figure 5.7: Passive lossy circuit
5.1 Types of Noise
285

the remaining network contains only reactive elements. Therefore, v(t) is the voltage resulted
from the noise current associated with the resistor in response to the system function, H( f ).
From reciprocity, H f
ð Þ = V f
ð Þ
I f
ð Þ, where I( f ) is the current injected to the network as shown in
Figure 5.7 on the bottom, and V( f ) is the amplitude of the voltage across resistor. The input
power is |I( f )|2 Re [Z( f )], and the power delivered to the resistor is V f
ð Þ
j
j2
R
. Since the connecting
network is only reactive and thus lossless, the two must be equal, which yields
H f
ð Þ
j
j2 = V f
ð Þ
j
j2
I f
ð Þ
j
j2 = R  Re Z f
ð Þ
½
:
This results in
Sv f
ð Þ = 4KT
R
H f
ð Þ
j
j2 = 2KT Re Z f
ð Þ
½
:
The general case where the circuit consists of more than one resistor may be proven similarly,
considering the independence of resistor noise sources. Consider Figure 5.8, where the one-port
now consists of N arbitrary resistors each with a noise current in parallel, and the rest of the
network is reactive.
Assume that the transfer function from the noise source of resistor Rk to the output is Hk(f ),
indicating that if the resistor is excited with a current I in parallel (Figure 5.8, right), the voltage
appearing at the output port is
V( f ) = Hk( f )I( f ).
According to reciprocity then, if we excite the output port with a current I, the voltage
appearing across the resistor Rk (vk) must also obey that same transfer function, that is,
Vk( f ) = Hk( f )I( f ).
RN
v(t)
Z(s)
LCM
R1
Rk
V = HkI
LCM
I
Hk(f)
Rk
Vk = HkI
LCM
I
Hk(f)
Reciprocity
Figure 5.8: RLCM one-port
286
Noise

Now, since the rest of the network consists of only reactive components (ideal inductors,
capacitors, coupled inductors or transformers), then energy conservation7 entails that power
delivered to the one-port by the exciting current I must be equal to the sum of the powers
dissipated in the resistors,
Re Z f
ð Þ
½
 I f
ð Þ
j
j2 =
X
N
k = 1
Vk f
ð Þ
j
j2
Rk
=
X
N
k = 1
Hk f
ð Þ
j
j2 I f
ð Þ
j
j2
Rk
,
which results in
Re Z f
ð Þ
½
 =
X
N
k = 1
Hk f
ð Þ
j
j2
Rk
:
Since the noise current experiences a transfer function of Hk( f ) from the corresponding resistor
Rk to the output, the spectral density of the output considering that the noise sources are
uncorrelated is
Sv f
ð Þ =
X
N
k = 1
2KT
Rk
Hk f
ð Þ
j
j2 = 2KTRe Z f
ð Þ
½
,
which concludes our general proof of the Nyquist theorem. As a dual to the Nyquist theorem,
we can readily show that
Si( f ) = 2KT Re[Y( f )],
where Si( f ) is the noise current spectral density and Y( f ) is the output admittance of the one-port.
There are several other interesting results arisen from the Nyquist theorem. First, the
autocorrelation of the noise voltage for the circuit at the left side of Figure 5.8 is
Rv(τ) = KT(z(τ) + z(τ)),
where z(t) represents Z(s) in time domain. The proof is readily obtained, considering that for an
arbitrary function x(t) with a Fourier transform of X( f ), we have
F 1 Re X f
ð Þ
½

ð
Þ = x tð Þ + x t
ð
Þ
2
:
Since for the output impedance of any causal system, z(t) = 0, t < 0,
Rv(τ) = KTz(τ) τ > 0.
Second, deﬁning the network equivalent output capacitance, C, as
1
C = lim
ω!∞jωZ jω
ð
Þ,
7 The energy conservation, though it appears obvious, is a result of Tellegen’s theorem [13], which states that in an arbitrary
lumped network comprising b branches of voltage vk and current ik, we have Pb
k = 1vkik = 0, as long as the branch voltages
and branch currents satisfy KVL and KCL. It follows that the sum of the complex powers in each branch is zero, and since
the reactive branches have imaginary impedances associated with them, the energy conservation is resulted. See also
Chapter 1 for the proof and more details.
5.1 Types of Noise
287

we have
E v tð Þ2
h
i
= KT
C :
The proof immediately follows from initial value theorem stating that z 0 +
ð
Þ = lim s!∞sZ zð Þ.
Similarly, duality suggests that
L = lim
ω!∞jωY jω
ð
Þ,
where Y is the output admittance (Figure 5.9).
Example: Now let us reconsider our previous examples of RC and RLC equivalent noise
bandwidth shown in Figure 5.6. Clearly, for the RC circuit, E v tð Þ2
h
i
= KT
C , and since the
resistor noise spectral density is 4KTR, it follows that the equivalent noise bandwidth is
1/4RC, a result obtained by integration previously. For the RLC circuit, the integration is
quite more formidable, whereas from the Nyquist theorem we have
E v tð Þ2
h
i
= KT lim
ω!∞jωZ jω
ð
Þ = KT lim
ω!∞jω
jLω
1  LCω2 + jLω
R
= KT
C ,
leading to the same equivalent noise bandwidth.
Example: As a more general case, consider the circuit of Figure 5.10. It consists of a
noisy resistor R, and a lossless reciprocal (LCM) network. We wish to ﬁnd the average
energy stored in the capacitor produced by the resistor thermal agitation.
RLCM
Z(s)
RLCM
Y(s)
C
L
Figure 5.9: Equivalent capacitor
or inductor in a passive RLCM
network
Lossless 
Reciprocal
C
R
Z2(s)
Figure 5.10: Average energy stored in a capacitor
288
Noise

The network output impedance is
ZOUT sð Þ =
1
Cs Z2 sð Þ
1
Cs + Z2 sð Þ
=
Z2 sð Þ
1 + CsZ2 sð Þ :
Assume there is no other capacitance in parallel with C, that is, C represents the total
capacitance appearing at the output. We have
lim
s!∞sZOUT sð Þ = lim
s!∞
sZ2 sð Þ
1 + CsZ2 sð Þ = 1
C :
From the Nyquist theorem,
vOUT 2 = KT
C ,
where vOUT is the voltage at the network output, appearing across C. Thus the average
energy stored in the capacitor is8
1
2 CvOUT 2 = 1
2 KT:
In a similar fashion and using duality we could show that the average energy stored in an
arbitrary inductor is also 1
2 KT. Thus, assigning a degree of freedom associated with a
given reactive component, there exits an energy of 1
2 KT. This is consistent with the
equipartition law as we described at the very beginning.
5.1.5
MOSFET Thermal Noise
A great deal of work on solid-state devices noise was done by Van der Ziel [6] in the mid-
1900s. A detailed discussion of noise in MOS transistors is also presented in [7]. In this section
we brieﬂy summarize the results.
From basic semiconductor physics [8], [9], we know that a long channel MOS drain
current is
ID =  μnQ y
ð Þ dV y
ð Þ
dy
 μnQ y
ð Þ ΔV y
ð Þ
Δy
,
where V(y) is the voltage across the channel whose derivative leads to electric ﬁeld imposed by
the drain voltage (Figure 5.11), and Q(y) is the channel inversion charge:
Q(y) =  COX[VGS  VTH  V(y)]W.
8 The derivation implies there is no capacitive or inductive loop or cut-set.
5.1 Types of Noise
289

We can therefore assign a small resistance, ΔR = ΔV
ID for a given length of Δy at an arbitrary
point in the channel, as follows:
ΔR = ΔV
ID
=
Δy
μnQ y
ð Þ ,
This small resistance has some associated thermal noise, which is white, and in turn creates a
noise voltage disturbance, ΔV, whose spectral density is
SΔV = 4KTΔR = 4KT
Δy
μnQ y
ð Þ ,
Note that Q(y) is representing the inversion charge due to electrons in the case of an NMOS,
and thus it is a negative quantity. In [9] it is proven that based on the i–v equation of the MOS
transistor shown earlier, this small voltage disturbance in turn results in some small current
disturbance, Δi, which is
Δi = μnQ y
ð Þ
L
ΔV,
and thus the current noise spectral density is
SΔi = μnQ y
ð Þ
L


2
SΔV = 4KT μn
L2 Q y
ð ÞΔy:
Integrating SΔi over the channel leads to the total channel noise power spectral density,
Si = 4KT μn
L2
ðL
0
Q y
ð Þdy = 4KT μn
L2 QT
ð
Þ,
where QT is the total inversion charge. If the device is in the triode region, VDS  0, and QT =
 WLCOX(VGS  VTH), which leads to
Si = 4KTμnCOX
W
L VGS  VTH
ð
Þ = 4KTgDS:
The outcome is not surprising, as in triode region a MOSFET is essentially a resistor, with a
channel conductance of gDS = μnCOX W
L VGS  VTH
ð
Þ. On the other hand, in saturation, integrat-
ing the inversion charge leads to [8], [9]: QT =  2
3 WLCOX VGS  VTH
ð
Þ, and thus
Si = 4KT 2
3 μnCOX
W
L VGS  VTH
ð
Þ = 4KT 2
3 gm,
n+
n+
0
L
y
ΔR
- - - - - - - - -  
- - - - - - -   
- - - -  
V(y)
V(y)
y
L
0
VS
VD
ΔV
Figure 5.11: An NMOS transistor in strong inversion and its channel voltage
290
Noise

where gm is the long channel MOS transconductance.9 For shorter channel devices, the above
analysis is not accurate anymore, as there are various short channel impacts such as hot carrier
effects that could potentially lead to more noise. For that reason, we choose to express the
MOSFET noise in the general form of
Si = 4KTγgm,
where γ is a process- and channel-length-dependent factor, often experimentally obtained. In
40nm CMOS, for example, it appears that γ is close to one for minimum channel devices.
For a long channel MOS,10 with an arbitrary value of VDS between 0 and VDS,SAT, a common
expression obtained by integration of the channel total inversion charge is
Si = 8
3 KTgDS
1 + η + η2
1 + η
,
where η = 1 
VDS
VDS,SAT. Thus η is 1 when VDS = 0, and approaches 0 when the device enters
saturation, and the noise current density is consistent with our previous derivation.
Example: A simulation of a 200nm device in 28nm CMOS technology is shown in
Figure 5.12. The value of γ is very close to ⅔when the device enters saturation and the
noise current spectral density is in good agreement with our ﬁndings.
To model the device noise, we may place a parallel current source representing the noise
whose spectral density is given above. Equivalently, the device may be modeled with a voltage
source at gate whose spectral density is (Figure 5.13)
Sv = 4KTγ
gm
:
2.00E-23
2.50E-23
3.00E-23
3.50E-23
4.00E-23
4.50E-23
5.00E-23
5.50E-23
6.00E-23
0
0.08
0.16
0.24
0.32
0.4
0.48
0.56
0.64
0.72
0.8
0.88
0.96
1.04
1.12
1.2
VDS, V
Noise, A2/Hz
Figure 5.12: Simulated
noise of a 200nm long
device in 28nm CMOS
process
9 The factor ⅔is the same ⅔that shows in the gate-source capacitance, CGS, for a MOS in saturation.
10 Note that in a long channel MOSFET, gm = gDS.
5.1 Types of Noise
291

5.1.6
Flicker Noise
Besides channel thermal noise, which is Gaussian and white, there is another source of noise in
MOSFETs that is frequency dependent. This type of noise is known as ﬂicker or 1/f noise
(given that the spectral density is approximately inversely proportional to frequency), and is a
dominant source of noise at lower frequencies. The noise is still Gaussian, simply as the central
limit theorem is valid, but is colored (or frequency dependent).
The origin of the noise may be attributed to the random ﬂuctuations of carriers in the channel
due to ﬂuctuations in the surface potential [6]. That in turn is caused by trapping and releasing
the carriers near the Si–SiO2 interface with long time constants (Figure 5.14). The traps are a
result of imperfection in Si/SiO2 lattice.
The power spectral density of such a waveform is shown to be of the form
Si f
ð Þ =
ctτt
1 + 2πf
ð
Þ2τt2 ,
where ct is a constant, and τt is a characteristic time constant related to the average time between
capture and release. The deeper the trap inside the oxide, the less likely that the electron is
captured, and thus the longer τt will be. The noise spectrum is Lorentzian, that is, it is constant
at very low frequencies, and decreases as 1/f 2. However, with a large number of traps with
uniform distribution of τt values, the spectrum may be approximated with a 1/f behavior.
As the noise results from superposition of large number of variations due to many traps, the
larger the gate area, the more averaging, and thus the less noise. Additionally, since the trapping
and releasing effectively modulates the ﬂat-band voltage (see Figure 5.14 right) through the
term
Q
COX (Q is the inversion charge), we expect the noise power spectral density to be
proportional to
1
COX 2.
Si(f) = 4KTggm
Sv(f) = 4KTg/gm
Figure 5.13: Noise model of a MOSFET in
strong inversion
n+
n+
- - - - - - - - -  
Long t
-
-
-
Traps
EC
EV
Figure 5.14: MOSFET ﬂicker noise description along with energy bands
292
Noise

In general we can model the noise as a voltage source in series with gate, whose power
spectral density is
Sv f
ð Þ =
K
WLCOX2
1
f b ,
where b is between 0.7 and 1.2, and is often approximated to 1, and K is a process dependent
parameter. Consequently, the noise current spectral density at the drain is
Si( f ) = gm
2Sv( f ).
The dependence on COX and WL is clear from the qualitative discussion above. Moreover,
it is experimentally shown [14] that the noise spectral density as expressed above is not very
bias dependent.
A more detailed discussion may be found in [6].
5.1.7
Cyclostationary Noise
The types of noise we have discussed thus far assume that the operating point of the elements is
not changing over time. This applies to all linear and time-invariant circuits such as low-noise
ampliﬁers. As we said in Chapter 2, however, the time-varying nature of certain nonlinear
circuits such as oscillators results in cyclostationary noise instead [10], [15], whose statistical
characteristics vary periodically.
Consider a time-varying conductance G(t). As we discussed earlier, the derivation of the
resistor thermal noise was based on the assumption that the thermal equilibrium is reached. This
will not necessarily be the case if the resistor bias is changing over time. However, if the two
conditions below are satisﬁed [16]:
– the change in the operating points is slow enough so that the dissipative device approxi-
mately stays in thermal equilibrium
– the ﬂuctuations caused by noise are not large enough (compared to the deterministic time-
varying signal) to alter the operating points
then we could argue that the noise instantaneous spectral density is Si( f, t) = 4KTG(t). In such
case the spectral density is time-dependent, and the signal is not stationary anymore. If G(t) is
periodic, however, as is the case in most of the circuits we deal with such as mixers or
oscillators, the noise current will be cyclostationary.
To generalize, let us deﬁne
ncyclo(t) = n(t)w(t),
where n(t) is stationary (but not necessarily white), w(t) is the periodic modulating function, and
ncyclo(t) is the resultant cyclostationary noise.
To gain some insight, let us derive the autocorrelation of the cyclostationary noise.
According to deﬁnition,
Rncyclo(t + τ, t) = E[n(t + τ)w(t + τ)n∗(t)w∗(t)].
5.1 Types of Noise
293

To simplify, let us represent the periodic function w(t) by its Fourier series:
w tð Þ =
X
∞
k = ∞
wke jω0t,
where wk are the Fourier coefﬁcients, and ω0 = 2π
T is the angular frequency. After some
straightforward algebra,
Rncyclo t + τ; t
ð
Þ = Rn τð Þ
X
∞
k = ∞
X
∞
l = ∞
wkw∗
lejkω0τe jω0 kl
ð
Þt:
Since ncyclo(t) is not stationary, its autocorrelation depends on both t and τ. As we indicated in
Chapter 2, it is customary to treat the cyclostationary processes as stationary by taking the time
average of the mean and autocorrelation. By doing so, and knowing the t dependent terms
average to zero over one cycle, we obtain
Rncyclo τð Þ = 1
T
ð
T
Rncyclo t + τ; t
ð
Þdt = Rn τð Þ
X
∞
k = ∞
wk
j
j2ejkω0τ,
and the spectral density is
Sncyclo f
ð Þ = Sn f
ð Þ∗
X
∞
k = ∞
wk
j
j2δ f  kf 0
ð
Þ =
X
∞
k = ∞
wk
j
j2Sn f  kf 0
ð
Þ:
That is, the modulating signal w(t) samples the stationary noise n(t) at all harmonics of f0, as
shown in Figure 5.15.
If n(t) is stationary and also white, then
Sncyclo f
ð Þ = Sn
X
∞
k = ∞
wk
j
j2,
where Sn is the white noise spectral density. Furthermore, we can obtain simple expressions for
the instantaneous spectral density if n(t) is white. To do so, let us take the Fourier transform of
(with respect to τ) the cyclostationary autocorrelation function (Rncyclo(t + τ, t))
Sncyclo f ; t
ð
Þ =
ð∞
∞
Rncyclo t + τ; t
ð
Þej2πf τdτ,
0
kf0
… 
… 
–kf0
Sn
Sncyclo
|w0|2
f
|wk|2
Figure 5.15: Stationary noise sampled by the modulating signal
294
Noise

which can be written as
Sncyclo f ; t
ð
Þ =
ð∞
∞
Rn τð Þ
X
∞
k = ∞
X
∞
l = ∞
wkw∗
lejkω0τe jω0 kl
ð
Þtej2πf τdτ:
Rearranging the integral yields
Sncyclo f ; t
ð
Þ =
X
∞
k = ∞
X
∞
l = ∞
wke jω0ktw∗
lejω0lt
ð∞
∞
Rn τð Þejkω0τej2πf τdτ:
Since n(t) is white, the integral
Ð ∞
∞Rn τð Þejkω0τej2πf τdτ represents its spectral density Sn. Thus,
Sncyclo f ; t
ð
Þ = Sn
X
∞
k = ∞
X
∞
l = ∞
wke jω0ktw∗lejω0lt:
This can be further simpliﬁed to
Sncyclo( f, t) = Sn|w(t)|
2,
which is a function of time (but not frequency as n(t) is white).
Time-averaging the spectral density above yields
Sncyclo f
ð Þ = Sn
1
T
ðT
0
w tð Þ
j
j2dt:
This is identical to the result previously obtained (Sncyclo f
ð Þ = Sn
P∞
k = ∞wk
j
j2) given Parseval’s
energy theorem P∞
k = ∞W k½ 
j
j2 = 1
T
Ð
T w tð Þ
j
j2dt.
In the case of time-varying conductance (or a MOSFET in strong inversion), Sn = 4KT,11 and
w tð Þ =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
G tð Þ
p
. The instantaneous spectral density is Sncyclo( f, t) = 4KTG(t), and the average
spectral density as viewed on a spectrum analyzer is Sncyclo f
ð Þ = 4KT
T
Ð T
0 G tð Þdt.
Example: Let us start with the simple case of Figure 5.16, where a resistor is periodically
switched, and the noise current on the other side of the switch is monitored. The output
noise waveform is shown on the right side.
Continued
ion
R
in
SW(t)
t
SW(t)
in
ion
Figure 5.16: An example of a
cyclostationary noise
11 Sn f
ð Þ = 2KT if both positive and negative frequencies are considered.
5.1 Types of Noise
295

Clearly,
Sion f ; t
ð
Þ = 4KT
R
SW tð Þ
j
j2:
If viewed on a spectrum analyzer, the power spectral density will be the time average of
Sion( f ),
Sion f
ð Þ = 1
T
ðT
0
Sion f
ð Þdt = 2KT
R ,
which intuitively makes sense as half the noise energy is blocked to appear at the output.
Example: Consider the circuit depicted in Figure 5.17, where an input voltage source is
sampled by two switches driven by nonoverlapping clock signals, SW1 and SW2. As we
will explain in Chapter 8, this is essentially a single-ended voltage-mode passive mixer.
Let us ﬁnd the spectral density of the noise at the input of the ideal voltage buffer.
Using superposition, we can write
SvOUT( f, t) = 4KTRSW[|SW1(t)|2 + |SW2(t)|2] = 4KTRSW,
where RSW is the switch on resistance. Intuitively, at any given point of time, one and only
one switch appears in series with the input. Thus, the spectral density of the noise is
equivalent to what it would be if we had only one switch on at all times.
5.2
TWO-PORT EQUIVALENT NOISE
..............................................................................................
From basic circuit theory [1], any linear noisy two-port may be modeled by an equivalent
noiseless two-port, and an input-referred pair of voltage and current noise sources as shown in
Figure 5.18. The noiseless two-port is identical to the noisy one, except for all the internal noise
sources turned off; that is, the current noise sources are opened, and the voltage noise sources
are shorted. To obtain the input-referred noise voltage, we need to short the input, thus
Buﬀer
SW1
SW2
vs
+
vOUT
–
Figure 5.17: Single-ended voltage-mode passive mixer
296
Noise

effectively bypassing the input current noise source. The input noise voltage must be such that
the output noise spectral density is equal to that of the noisy two-port with a shorted input. The
input noise current is obtained similarly, but by performing an open circuit test, and thus
bypassing the input noise voltage.
In spite of complicating the analysis, both the input voltage and current noise sources are
needed, that is, to support any arbitrary value of source impedance. For instance, if one chooses
to model the noisy circuit with only an input-referred current noise, an ideal voltage source
whose output resistance is zero results in no output noise, which is clearly not the case.
Assuming the source impedance Zs is Zs = Rs + jXs, then we can use a Thevenin equivalent
noise source, veq, whose spectral density is
veq2 =
vn + Zsin
ð
Þ
j
j2 + vns2 =
vn + Zsin
ð
Þ
j
j2 + 4KTRs:
The equivalent circuit is shown in Figure 5.19.
Since vn and in could arise from the same internal noise source in the noisy two-port but under
two different test conditions (that being open and short cases), they may be correlated. Thus, in
general, they cannot be separated when calculating the noise variance or spectral density.
Example: As a useful case study, let us calculate the input-referred noise sources of a
single MOSFET intended to be used in a common-source conﬁguration at reasonably
high frequencies. Since the frequency is assumed to be high, the ﬂicker noise is ignored.
We use the high-frequency small signal model of a MOSFET, as shown in Figure 5.20.
Continued
Noise-Less 
Two-Port
Source
vn
in
Zs
vs
vns
Noisy Two-Port
Figure 5.18: A two-port noise equivalent
Noise-Less 
Two-Port
Zs
vs
veq
Figure 5.19: Thevenin equivalent circuit
idn
+
vgs
–
Cgs
Cgd
gmvgs
Rg
ro
ion
vn
in
Zs
Figure 5.20:
A single FET
equivalent input
noise
5.2 Two-Port Equivalent Noise
297

The gate resistance is represented by Rg, arising from the gate poly or metal ﬁnite
conductivity. It can be minimized to practically negligible values by proper layout using
multiﬁnger devices (see Chapter 7 for more details). Hence, we will ignore that. Neverthe-
less, it appears in series with the gate and the source so it could be absorbed to the source
if needed. Also for the moment we will ignore the gate-drain capacitance as it complicates
the analysis considerably. We will however discuss its impact on the ampliﬁer noise and
input resistance in Chapter 7. For typical design values and process parameters, Cgd is
roughly one-third to one-ﬁfth of Cgs for minimum channel devices. The values of vn and in
are found by applying a short and open circuit for Zs, and ﬁnd the output noise current.
Since vn appears directly across Cgs, we have,
vn2 = idn2
gm2 = 4KTγ
gm
:
On the other hand, for the open circuit test, vgs is produced by in ﬂowing through Cgs,
and thus
in2 =
idn2
gm
jωCgs


2 = 4KTγ
gm
ωCgs

2 = ωCgs

2vn2:
We can see that vn and in are completely correlated. Moreover, in becomes important only
at higher frequencies where the MOSFET input impedance starts to reduce.
Example: For an arbitrary source impedance of Zs, let us consider the circuit on the left
side of Figure 5.21.
We can write
vgs =
vn
Zs
+ in

	
Zsk
1
jωCgs

	
:
Since in2 = ωCgs

2vn2, we have
vgs2 =
1
Zs
j
j2 + ωCgs

2
 
!
Zsk
1
jωCgs


2
vn2 = vn2:
in
Zs
vn
+
vgs
–
Cgs
Zs
+
vgs
–
Cgs
vn
≡ 
Figure 5.21: MOS equivalent noise model
298
Noise

Therefore, the spectral density of the gate-source voltage is equal to vn2, regardless of
the source impedance. Consequently, the circuit may be simpliﬁed as shown on the
right, where only a voltage noise is sufﬁcient to represent it. The simpliﬁcation arises
from the fact that the equivalent input noise voltage and current are completely
correlated.
5.3
NOISE FIGURE
..............................................................................................
Consider the two-port shown in Figure 5.22, where Ga = So
Si is the available power gain, and So
and Si are the available output and input signals. From Chapter 3, we showed that Si = vs2
8Rs. The
available noise spectral density was shown to be KT, regardless of the source resistance. Thus,
the available noise power due to the source measured at a bandwidth of 1Hz at a certain
frequency of interest is KT. Let us assume that the available noise power at the output is No,
resulted from the source as well the two-port noise contributions. The available noise power
referred to the input is then equal to Ni = No
Ga.
By deﬁnition, the noise factor,12 F, is the signal-to-noise ratio (SNR) at the input, divided by
the SNR at the output. Unless the two-port is noiseless, we expect the output SNR to be less
than that of the input, as the two-port adds its own noise. Thus, the noise factor is always greater
than one (or zero dB).
The noise ﬁgure may be expressed in a more familiar format, by the two-port available gain
and noise [2]:
F = Si=KT
So=No
=
No
GaKT = Ni
KT :
Thus the available input-referred noise due to the two-port only is (F  1)KT.
Noise-Less 
vn
in
Rs
vns
ZIN
Figure 5.22: Noisy two-port
12 We make the distinction between the noise factor expressed as a number F, and the noise ﬁgure in dB as NF.
5.3 Noise Figure
299

For a noisy two-port with input-referred voltage and current noise sources as depicted in
Figure 5.22, we showed based on the Thevenin equivalent (Figure 5.19) that
Ni =
vn + Zsin
ð
Þ
j
j2 + 4KTRs
4Rs
,
which allows us to express the noise ﬁgure in terms of two-port input-referred noise:
F =
vn + Zsin
ð
Þ
j
j2 + 4KTRs
4Rs
KT
= 1 +
vn + Zsin
ð
Þ
j
j2
4KTRs
:
Note that we have expressed the results in terms of source complex impedance: Zs = Rs + jXs.
A few key observations are in order ﬁrst:
1. The noise ﬁgure is a function of source resistance Rs. This does not make the noise ﬁgure
deﬁnition any less valuable, it just simply compares the circuit noise contributors vn and in
resulted from internal noise sources, to a universally accepted reference, 4KTRs. For almost
all practical cases, Rs is agreed to be 50Ω.
2. As expected, the noise ﬁgure is a function of the two-port noise voltage and current. If the
two-port is noiseless, vn and in are zero, and thus F = 1. For any noisy circuit, F is always
greater than one, a result we already knew from basic deﬁnition.
3. For a source resistance of zero or inﬁnity, noise ﬁgure is inﬁnity. This is obvious from the
equation, but could be explained intuitively as well: If Rs = 0, regardless of how low noise the
two-port is, since its noise is always compared to a zero noise reference, the noise ﬁgure is
inﬁnity. Ironically, the lower the source resistance, despite the fact that a better SNR is achieved,
the circuit noise ﬁgure is higher! On the other hand, if Rs = ∞, no matter how small the input-
referred noise current is, it results into inﬁnite noise. This suggests that if for a given circuit in
were zero, the optimum noise ﬁgure would be achieved if source has inﬁnite resistance.
The latter observation is quite critical: For a given two-port, and thus ﬁxed values of vn and in,
there must be an optimum value for Rs where noise ﬁgure approaches a minimum (Figure 5.23).
This is particularly of great importance, as it allows us to systematically optimize the noise ﬁgure
of a given ampliﬁer. In practice, this is typically done along with optimizing the ampliﬁer as well,
and thus varying vn and in. We will discuss this in the next section
F
Rs
Fmin
Rs,opt
Figure 5.23: Minimum noise ﬁgure concept
300
Noise

Example: We start with a simple example describing a resistive voltage divider as shown
in Figure 5.24.
The noise at the output is
von = vns
Rp
Rp + Rs
+ vnp
Rs
Rp + Rs
:
Since the output noise due to the source only is vns
Rp
Rp + Rs, the noise factor becomes
F = 1 + 4KTRp
4KTRs
Rs
Rp

	2
= 1 + Rs
Rp
=
1
Rp
Rp + Rs
:
As expected, removing the shunt resistor leads to a noise factor of 1. Furthermore, the
available power gain of the circuit is
Ga =
Rs
RpkRs
Rp
Rp + Rs

	2
=
Rp
Rp + Rs
:
So the noise ﬁgure is equal to the inverse of the available power gain, or is basically the
same as the loss. We will show momentarily that this is true for any passive reciprocal
network.
Example: Let us calculate the noise ﬁgure of a single FET shown in Figure 5.25. The
output may be terminated to some noiseless load or simply shorted to supply.
Continued
VO
Vs
Rp
Rs
VOn
Vnp
Vns
Rp
Rs
Figure 5.24: Resistive voltage divider
in
vn
Zs
Cgs
vn
Ls = 1/Cgsw2
Figure 5.25: Noise
ﬁgure of a single FET
5.3 Noise Figure
301

From the noise ﬁgure equation, and based on the values of vn and in obtained before, we
have
F = 1 +
γ
gmRs
RsCgsω

2 + 1  XsCgsω

2
h
i
:
From the equation above, if Rs = 0, and Xs = 1/Cgsω, an optimum noise ﬁgure of 0dB is
achievable, regardless of the device noise or transconductance. To explain this rather
strange outcome, consider the equivalent circuit shown on the right side, as we obtained
previously (Figure 5.21). We can see that the series inductor representing Xs is resonating
with the gate-source capacitance under optimum noise conditions. Thus, it results in an
inﬁnite voltage gain from the source to vgs, assuming the inductor is lossless. Hence, the
circuit noise, however large it may be, is entirely suppressed.
Example: Consider the passive lossy circuit of Figure 5.26.
If the circuit has an output resistance of ROUT = Re [ZOUT], then the noise spectral
density at the output is 4KTROUT according to the Nyquist theorem. The total available
noise at the input is the output available noise power, divided by the network available
power gain,13 Ga:
Ni =
4KTROUT
4ROUT
Ga
:
This normalized to the source available power, KT, results in the noise ﬁgure:
F = 1
Ga
= Loss:
In Chapter 3 we saw that the available power gain may be expressed in terms of the two-port
scattering parameters, and would be equal to |S21|2 if the input and output are matched to Z0.
ZOUT(s)
Rs
vs
Figure 5.26: Noise ﬁgure of a passive lossy network
13 Since the circuit is passive and lossy, the available power gain, Ga, is less than one.
302
Noise

That is usually the case for many external passive lossy RF components, such as the SAW
ﬁlters or attenuators.
The previous example’s outcome could have been obtained intuitively: The available noise
power at the input and output is always equal to KT. As the signal is attenuated due the two-port
loss, the SNR degrades, and consequently the noise ﬁgure must be equal to the loss.
Thus the noise ﬁgure of lossy passive networks is equal to their loss. This is handy when
dealing with external ﬁlters, such as SAW ﬁlters placed at the receiver input. The loss of the
ﬁlter, typically about 1–2dB, directly translates to its noise ﬁgure in dB.
5.4
MINIMUM NF
..............................................................................................
In the previous section, we showed qualitatively that the noise ﬁgure may be optimize by
choosing the right source impedance. A systematic approach may be taken by taking the
derivative of noise ﬁgure versus source impedance, and ﬁnd the optimum source impedance.
Let us deﬁne
vn = vc + vu = Zcin + vu,
where Zc = Rc + jXc represents the correlation between the input-referred noise voltage
and current, and vu is the uncorrelated portion of the input noise voltage. For convenience,
let us assign the following nonphysical resistance and conductance to vu and in spectral
densities:
vu2 = 4KTRu and in2 = 4KTGn:
The noise ﬁgure is
F = 1 +
vn + Zsin
ð
Þ
j
j2
4KTRs
= 1 +
Zsin + Zcin + vu
ð
Þ
j
j2
4KTRs
= 1 + Zc + Zs
j
j2in2 + vu2
4KTRs
:
The last step uses the fact that vu and in are uncorrelated. Replacing vu2 and in2 with their
equivalent resistances, and after some simpliﬁcations, we arrive at
F = 1 +
Ru + Gn
Rs + Rc
ð
Þ2 + Xs + Xc
ð
Þ2
h
i
Rs
:
There are two variables, Rs and Xs. To ﬁnd the optimum noise, we need to take partial derivative
of F versus each, and set them to zero. By doing so we obtain
Rs,opt =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ru
Gn
+ Rc
2
r
Xs,opt =  Xc,
and the minimum noise ﬁgure when the optimum impedance is used is
Fmin = 1 + 2Gn Rc +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ru
Gn
+ Rc2
r

	
:
5.4 Minimum NF
303

Outside the optimum conditions,
F = Fmin + Gn
Rs
Zs  Zs,opt

2:
Clearly F  Fmin. It is insightful to rearrange the equation above as follows:
Rs 
Rs,opt + F  Fmin
2Gn

	

	2
+ Xs  Xs,opt

2 = F  Fmin
Gn
Rs,opt +
F  Fmin
2Gn

	2
:
If Zs = Zs,opt, then F must be equal to Fmin. However, for any other value of F, then the Xs–Rs
plane consists of noise circles as shown in Figure 5.27.
Since in a bilinear transformation circles are mapped again to circles, the constant noise
ﬁgure contour will also remain circular in the Smith chart, which depicts the plane of reﬂection
coefﬁcient. As proven in Problem 25, the source reﬂection coefﬁcient Γs = ZsZ0
Zs + Z0, may be
described by
Γs  Γs,opt
K + 1


2
=
K2 + K 1  Γs,opt

2


K + 1
ð
Þ2
,
where K = FFmin
4GnZ0 1  Γs,opt

2 is a positive real number and is a function of noise factor, and
Γs,opt = Zs,optZ0
Zs,opt + Z0 is the optimum noise impedance reﬂection coefﬁcient. The Γs circles for a
given noise factor, and thus a given K, are depicted on the Smith chart in Figure 5.28.
For F = Fmin, K = 0, and clearly Γs = Γs,opt. On the other extreme, if noise ﬁgure goes to
inﬁnity, Γs will reside on |Γ| = 1 circle. The center of the circles reside on the constant ∠Γs,opt
line, since K is real, as shown as a dashed line in Figure 5.28.
For an arbitrary two-port with a given input impedance, the optimum noise condition may be
accomplished by placing a lossless matching network to transform the impedance to the
desirable value (Figure 5.29). If the loss of the matching network is not signiﬁcant, it will not
affect the input SNR, however it will provide the optimum impedance to minimize the
noise ﬁgure.
The fundamental drawback of the noise matching approach as presented in Figure 5.29 is
that it may conﬂict with maximum available power requirements. To satisfy the latter condition,
the matching network must present an impedance equal to ZIN
*to the circuit, rather than Zs,opt,
and the two are not necessarily equal. Perhaps one of the biggest challenges of designing a good
low-noise ampliﬁer is to satisfy the two conditions simultaneously.
Xs
Rs
Xs,opt
Rs,opt
Fmin
F↑ 
Figure 5.27: Noise circles
304
Noise

Example: Returning to our previous example of the a single FET in Figure 5.25, one can
easily show that vu = 0, Zc = 1/jCgsω, and Zs,opt = –1/jCgsω, leading to Fmin = 1, a result
obtained previously.
Designing a low-loss matching network that could transform the 50Ω source resistance to a
pure reactance of Xs,opt = 1/Cgsω seems to be no easy task at all. As shown in Figure 5.30, this
may be accomplished by placing the inductor simply in series with Rs, and hoping that Xs,opt »
Rs. Since the 50Ω resistance is relatively large, this may lead to a low-Q inductor, unless the
inductance value is very large. This in turn implies that the device Cgs (or any parasitic
capacitance associated with it, such as routing or pad capacitance) that the inductor is resonat-
ing with must be very small.
Cgs
Ls = 1/Cgs
2
50W
w
Figure 5.30: Single common-source FET with matching network
Γi
Γr
0⁰ 
90⁰ 
180⁰ 
–90⁰ 
Γs
Γs,opt
|Γ|=1
Figure 5.28: The Γs circles on the Smith chart
vn
in
Rs
ZIN
Matching
Network
Zs,opt
vs
Figure 5.29: Using matching network to
achieve minimum noise conditions
5.4 Minimum NF
305

This is where the technology scaling could potentially help the RF design, as device transit
frequency fT, which is an indication of
1
Cgs (f T = 1
2π
gm
Cgs + Cgd ﬃ1
2π
gm
Cgs), scales favorably. More-
over, in contrast to our initial thought that the minimum noise ﬁgure is achieved regardless of
the device noise or gm, one can see that to maximize fT, the device needs to be biased at a very
large gate overdrive voltage. This in turn leads to a poor gm/ID, and thus a large bias current.
A plot of device fT versus gate overdrive for 40nm CMOS is shown in Figure 5.31 for the
reference. Also shown is the peak fT for several recent processes indicating the impact of
technology scaling.
For instance, a Cgs of 100fF, a typical value for a minimum channel 40nm device biased at a
few mA, leads to a value of 800Ω for Xs,opt at 2GHz. The corresponding inductance value is
64nH, which is quite large at especially 2GHz. On the other hand, despite the fact that Cgs is
small and scales favorably, other parasitics at the ampliﬁer input could dominate. For these
reasons, a practical low-noise ampliﬁer may not incorporate a simple common-source FET
structure.
Example: Consider a common-gate ampliﬁer shown in Figure 5.32. The fundamental
difference between this ampliﬁer and the common-source one is that the input impedance
1
gm k
1
jCgsω has a non-zero real part. By performing the same procedure, we ﬁnd
vn2 = 4KTγ
gm
in2 = jCgsω
gm


2
4KTγgm,
0
50
100
150
200
250
300
0
100
200
300
400
500
fT, GHz
Veff, mV
150
300
450
Peak fT, GHz
Technology
65n
40n
28n
20n
Figure 5.31: NMOS transit frequency
306
Noise

which leads to Zc =
1
jCgsω, the same as the common-source example. The minimum noise
ﬁgure and the optimum source impedance then happen to be identical to the common-
source topology.
Interestingly, even though a source follower conﬁguration is not considered an ampliﬁer, one
can show that (see Problem 1) its minimum noise ﬁgure is also zero, much like common-gate
and common-source conﬁgurations.
As a ﬁnal remark, if instead of noise voltage, we would have broken the input noise current as
in = ic + iu = Ycvn + iu.
In a similar manner we can show (see Problem 7)
F = 1 + Zs
j
j2 Gu + Rn Ys + Yc
j
j2
Rs
,
where iu2 = 4KTGu, vn2 = 4KTRn, Yc = Gc + jBc, and Ys = Gs + jBs is the source admittance.
The optimum noise admittance is
Gs,opt =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Gu
Rn
+ Gc2
r
Bs,opt =  Bc
and the minimum noise ﬁgure when the optimum admittance used is
Fmin = 1 + 2Rn Gc +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Gu
Rn
+ Gc2
r

	
:
Outside the optimum conditions,
F = Fmin + Rn
Gs
Ys  Ys,opt

2:
This is the dual of the equations derived earlier, obtained by breaking the input noise voltage
into correlated and uncorrelated portions. Either set of equations may be used depending on the
context and the type of the circuit under analysis.
Zs
in
vn
Figure 5.32: A common-gate ampliﬁer
5.4 Minimum NF
307

Example: To lower the noise ﬁgure of a matched receiver, a low-noise ampliﬁer with
matched input and output is placed before the receiver. Assuming the LNA has
|S21| = 10dB, and a noise ﬁgure of 2dB, we would like to ﬁnd the cascaded noise ﬁgure
if the receiver noise ﬁgure is 3dB.
A simpliﬁed block diagram of the source, LNA, and receiver input along with their
noise sources is shown in Figure 5.33.
The total noise at the receiver input is:
von ¼ 1
4 gvns þ 1
4 gvnLNA þ 1
2 vnRX
where g is the LNA voltage gain. Thus, the overall noise factor would be:
F ¼ FLNA þ FRX  1
g
2
 2
where FLNA ¼ 1 þ vnLNA2
4KTRs is the LNA noise factor, and FRX ¼ 1 þ vnRX2
4KTRs is the
receiver noise factor. On the other hand, for the matched LNA, the available power
gain is:
Ga ¼ S21
j
j2 ¼ g
2


2
Consequently, the overall noise factor would be:
F ¼ FLNA þ FRX  1
S21
j
j2
¼ 1:58 þ 3  1
10
¼ 2:5dB
Rs
Rs
Rs
von
vns
v1
v2
gv1
vnLNA
vnRX
Rs
LNA
RX
+
–
+
–
+
–
Figure 5.33: An LNA proceeding a receiver to improve the system overall noise ﬁgure
308
Noise

5.5
IMPACT OF FEEDBACK ON NOISE FIGURE
..............................................................................................
The impact of feedback on an ampliﬁer basic properties such as gain or input impedance is very
well understood [1]. In this section we shall study its impact on the ampliﬁer equivalent noise
and its minimum noise ﬁgure. We consider the case of an ideal feedback, as well as passive
lossless feedback. The latter is of great importance and, as we will see in Chapter 7, is employed
extensively to favorably lower the noise ﬁgure of ampliﬁers.
5.5.1
Ideal Feedback
Let us start off with Figure 5.34, showing an ampliﬁer in a shunt feedback. We assume the
feedback circuitry is ideal, and is particularly noiseless. The latter assumption is not unreason-
able, as at radio frequencies we typically incorporate capacitors and inductors to form a low-
noise feedback around a noisy ampliﬁer.
We use the Norton equivalent of the source, as is common in the case of shunt-shunt
feedback. The closed-loop transimpedance gain is
vo
is
=
g ZskZIN
ð
Þ
1 + fg ZskZIN
ð
Þ ,
where fg(ZskZIN) is the loop gain. The closed-loop input impedance is
ZIN,fb =
ZskZIN
1 + fg ZskZIN
ð
Þ :
This is the open-loop input impedance reduced by the loop gain, as expected in a shunt
feedback network.
Since the circuits are linear we can use superposition and consider each noise source one at
the time. By inspection, it is clear that the feedback is not going to change the input-referred
noise current, as one can slide it out of the feedback ampliﬁer without altering the circuit. The
vn
in
Zs
ZIN
vs
+
vin
–
gvin
+
vo
–
fvo
Shunt Feedback
Zs
vs/Zs
Norton Equivalent
Figure 5.34: Minimum noise
ﬁgure of a shunt feedback network
5.5 Impact of Feedback on Noise Figure
309

feedback impact on the input-referred noise voltage is not as obvious. Turning off the noise
current, performing a simple analysis yields
vin = vn
Zs

ZskZIN
1 + fg ZskZIN
ð
Þ ,
which is the original noise voltage appearing at the input, but simply reduced by the loop gain.
Consequently, the input-referred noise voltage can also be brought outside the feedback, as
shown in Figure 5.35.
In conclusion, an ideal noiseless feedback does not affect the circuit input-referred noise, and
hence its minimum noise ﬁgure. Although our analysis was done for a shunt-shunt feedback
network, it can be generalized to other types of feedback too, particularly the source degener-
ation, which is a form of series–series feedback.
5.5.2
Passive Lossless Feedback
Next, let us study the impact of reactive feedback (LCM) on an arbitrary ampliﬁer. Shown in
Figure 5.36 is the ampliﬁer modeled by its Y parameters, along with the feedback network. In
vn/Zs
in
ZIN
+
vin
–
Zs
Norton Equivalent
Figure 5.35: Equivalent noise sources of the shunt
feedback network
Y11
Y21V2
Y22
Y12V1
YL
vn
in
LCM
Network
Ys
`
Y11f
Y21fV2
Y22f
Y12fV1f
+
V2
–
+
V1
–
+
V1f
–
Noisy Ampliﬁer
Figure 5.36: Reactive shunt feedback around a noisy ampliﬁer. Both feedback and the ampliﬁer are
represented with their Y parameters.
310
Noise

this example a shunt feedback conﬁguration is considered, though the analysis is readily
extended to any type of feedback (see Problem 18 for the case of series feedback). Also shown
is the input-referred noise sources of the open-loop ampliﬁer. The feedback network is clearly
noiseless as it is reactive.
We postulate that the equivalent input-referred noise sources of the overall feedback
ampliﬁer (vneq and ineq) must be such that (less a negative sign which is unimportant for noise
sources) with the ampliﬁer itself noise sources present (vn and in), the output voltage or current
must be nulled, as shown in Figure 5.37.
Setting V2 to zero results in the input controlled current sources (Y12V2 and Y12fV) to go
away, which brings us to the circuit of Figure 5.38, consisting of the noisy ampliﬁer, the
feedback network represented by its Y parameters, and the equivalent noise sources of
the overall feedback ampliﬁer. The equivalent noise sources are obtained now, knowing that
the output voltage must be zero.
Keeping in mind that V2 is zero, and writing a KCL at the output, we will have
Y21V1 + Y21fV1f = 0.
Since V1f =V1 + vn, then
V1 = 
Y21f
Y21 + Y21f
vn:
LCM
Network
Noisy
Amplifier
YL
vneq
ineq
+
V2
–
V2 = 0
Ys
Noise Sources
of FB Amplifier
Figure 5.37: Overall feedback
ampliﬁer with equivalent input noise
sources shown explicitly. The output
voltage must be nulled
Y11
Y22
Y12V1
in
vneq
ineq
Y11f
Y22f
Y12fV1f
YL
Ys
V2 = 0
vn
+
V1
–
+
V1f
–
Figure 5.38: Equivalent circuit of the feedback ampliﬁer with a`ll the noise sources when the output
voltage is set to zero
5.5 Impact of Feedback on Noise Figure
311

The equivalent noise sources must work for any source impedance, and particularly short and
open sources. Setting the source impedance to zero, then
vneq =  vn + V1
ð
Þ = 
Y21
Y21 + Y21f
vn:
We can simplify the matters by noticing that in a well-designed feedback system, the open
loop ampliﬁer forward gain (Y21) is supposed to be much larger than that of the feedback
network (Y21f). Accordingly,
V1 ﬃ0,
and
vneq ﬃ vn.
Similarly, by setting the source impedance to inﬁnity,
ineq + in + Y11V1 + Y11fV1f = 0,
which leads to
ineq ﬃ (in + Y11fvn).
Since in = Ycvn + iu, the equivalent noise current of the feedback ampliﬁer may be expressed in
terms of the correlation admittance:
ineq = (YC + Y11f)vneq  iu.
As we showed in Chapter 3, the Y parameters of any lossless reciprocal network are imaginary.
Consequently, an LCM feedback circuitry modiﬁes only the imaginary part of the correlation
admittance. More importantly, as the minimum noise ﬁgure does not depend on the imaginary
part of Yc (recall that Fmin = 1 + 2Rn Gc +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Gu
Rn + Gc2
q


), an LCM feedback network does not
affect the minimum noise ﬁgure. Note that for the previous case of an ideal feedback, Y11f = 0,
and we arrive at the same conclusion.
The above outcome proves to be very helpful in designing low-noise ampliﬁers, as feedback
does change the input impedance of the ampliﬁer. This could be exploited to satisfy the 50Ω
matching, and optimum noise ﬁgure conditions simultaneously. As we will see in Chapter 7, a
broad category of low-noise ampliﬁers rely on this principle.
5.6
NOISE FIGURE OF CASCADE OF STAGES
..............................................................................................
Since any practical radio consists of several building blocks, it is very helpful to be able to
express the overall noise ﬁgure as a function of that of the individual blocks. Shown in
Figure 5.39, let us consider two stages with noise ﬁgure and available power gain of F1, Ga1,
and F2, Ga2, respectively. The results can be readily extended to any number of stages. We
need not show the input-referred noise sources, as they are already embedded in the noise
ﬁgures.
312
Noise

The input-referred available noise for each stage was shown to be (F1  1)KT and (F2  1)KT,
respectively. The ﬁrst stage is directly connected to the source, whereas the input noise of the
second stage is attenuated by the available power gain of the ﬁrst stage when referred to the
source. Thus, the total available noise at the input, including the source noise, is
Ni = KT + F1  1
ð
ÞKT + F2  1
ð
ÞKT
Ga1
,
and this normalized to KT is the cascaded noise ﬁgure:
F = F1 + F2  1
Ga1
:
The above equation, known as the Friis equation, does not require the stages to be matched to
one another. However, there is a subtle point that must be clariﬁed: For each stage, the noise
ﬁgure and the available power gain must be deﬁned with respect to the source driving it. For the
ﬁrst stage, this happens to be the input source, whereas for the second stage, the source is the
ﬁrst stage driving it. Thus F2 and Ga2 are deﬁned with respect to ROUT1, that being the output
resistance of the ﬁrst stage.
One important outcome of the Friis equation is that if the gain of the ﬁrst stage is large, the
noise of the second stage is not as important. On the other hand, the noise ﬁgure of the ﬁrst
stage directly contributes to the total noise. As a result, it is common to place a low-noise
ampliﬁer at the very input of the receiver, to minimize F1 and maximize Ga1.
Example: Consider Figure 5.40 representing a practical case in most receivers. The
circuit consists of two lossy passive stages with the losses L1 and L2, followed by an
ampliﬁer with a noise ﬁgure of F3, as shown in the ﬁgure. The passive lossy stages may
represent ﬁlters or switches placed at the receiver input. In most cases such blocks are
matched to 50Ω.
Continued
Zs
vs
F1, Ga1
F2, Ga2
Stage 1
Stage 2
Figure 5.39: Noise ﬁgure of cascade of two
stages
L1
L2
F3
Input
Figure 5.40: Cascade of two lossy stages and an ampliﬁer
5.6 Noise Figure of Cascade of Stages
313

The total noise ﬁgure is
F = L1 + L2  1
1
L1
+ F3  1
1
L1L2
= L1L2F3:
If expressed in dB the receiver overall noise ﬁgure is
NF = Loss1 + Loss2 + NF3.
So the losses simply add up to the receiver noise ﬁgure.
Example: Shown in Figure 5.41 is a two-stage MOS ampliﬁer. For the ﬁrst stage
gm1 = 20mS, RL1 = 500Ω, and for the second stage gm2 = 5mS, RL2 = 2kΩ (bias details
are not shown). Ignore ro and all the internal capacitances, and assume γ = 1. To match to
50Ω, we insert the shunt resistor Rp = Rs = 50Ω at the ﬁrst stage input. We wish to ﬁnd
the noise ﬁgure of the cascaded ampliﬁer.
RL1
M2
M2
ROUT= RL1
ind2
inL2
vnL1
RL2
RL2
RL1
VO
VO1
RP
RP
vns
Vs
vnp
Rs
Rs
M1
M1
RL1
ind1
inL1
Figure 5.41: Two-stage ampliﬁer noise ﬁgure example
314
Noise

The available power gain of each stage is
Ga1 = Rs
RL1
1
2 gm1RL1

	2
= Rs
RL1
Av1
2 = 2:5
Ga2 = RL1
RL2
gm2RL2
ð
Þ2 = RL1
RL2
Av2
2 = 25,
where Av1 and Av2 are the voltage gains of each stage. The factor 1
2 appearing in Ga1
signiﬁes the voltage division at the input due to shunt resistance. Note that for the
second stage, Ga2 is calculated with respect to the previous stage output resistance
(ROUT1 = RL1), which is effectively the source driving it. As we pointed out earlier,
the same thing must be done for noise ﬁgure calculations. The total available power
gain is
Ga = Ga1Ga2 = Rs
RL2
1
2 gm1RL1gm2RL2

	2
= 62:5:
The noise details of each stage are shown in Figure 5.41 as well. Considering the ﬁrst
stage, the total noise referred to the input (source) is
vns + vnp + ind1 + inL1
1
2 gm1

	2 :
Note that Rs = Rp. Thus, the ﬁrst stage noise factor is
F1 = 1 + 1 +
4KTγgm1 + 4KT
RL1
4KTRs
1
2 gm1

	2 = 2 +
4
gm1Rs
γ +
1
gm1RL1

	
= 6:4 = 8:1dB:
The noise contribution of the load resistor is suppressed by the gain of the ampliﬁer as
expected, and therefore may be ignored.
Similarly, for the second stage
F2 = 1 +
4KTγgm2 + 4KT
RL2
4KTRL1 gm2
ð
Þ2
= 1 +
1
gm2RL1
γ +
1
gm2RL2

	
 1:44 = 1:5dB:
Using the Friis equation,
F = F1 + F2  1
Ga1
= 2 +
4
gm1Rs
γ +
1
gm1RL1

	
+
1
gm2RL1
γ +
1
gm2RL2

	
Rs
RL1
1
2 gm1RL1

	2
= 6:6 = 8:2dB:
Despite consuming one-fourth of the current in the second stage, the noise ﬁgure is mostly
dominated by the ﬁrst stage, given the gain preceding the second stage.
Continued
5.6 Noise Figure of Cascade of Stages
315

Note that in the noise ﬁgure calculations the system does not need to be matched to the
source. In fact, the reader can show that with Rp removed, the noise ﬁgure will be
F = 1 +
1
gm1Rs
γ +
1
gm1RL1

	
+
1
gm2RL1
γ +
1
gm2RL2

	
Rs
RL1
gm1RL1
ð
Þ2
= 2:14 = 3:3dB,
which is lower than the original value. The price paid here is the absence of a good match
at the ampliﬁer input. That is a common trade-off, and in fact the main challenge in
designing low-noise ampliﬁers.
We can rearrange the noise ﬁgure equation above as follows:
F = F1 +
1
gm2Rs
γ +
1
gm2RL2

	
Av12
= F1 + F2jRs  1
Av12
,
where F2|Rs is the noise factor of the second stage referred to the original source
impedance (Rs), and not the ﬁrst stage output impedance. This noise is then refereed to
the input by the ﬁrst stage voltage gain, and not its power gain. This simpliﬁcation works
only if the ampliﬁer can be modeled by its input equivalent noise voltage, only, e.g., a
high impedance ampliﬁer like a common-source stage.
5.7
PHASE NOISE
..............................................................................................
In Chapter 2 we discussed that mixers (or multipliers) are used in modulators to upconvert the
baseband spectrum to carrier frequency. We also showed that in a similar fashion, we exploit
the mixers in receivers to downconvert the modulated spectrum around the carrier to a conveni-
ently low frequency, say zero, known as the intermediate frequency or IF (Figure 5.42).
Same as the modulator, the receive mixer is also driven by a local oscillator (or LO) at (or
very close to) the carrier frequency. The LO signal could be generally expressed as
xLO(t) = AC cos(2πfCt + ϕn(t)).
This is a similar notation we used in Chapter 2, except for the additional terms ϕn(t),
representing the noise in the active circuitry in the oscillator, known as phase noise. In Chapter 9
RF Input
Downconverted 
Output
LO
xLO(t)=Accos(2 fCt+
n(t))
XLO(f)
f
fC
Phase Noise
f
p
Figure 5.42: A mixer used in a receiver to downconvert the modulated spectrum
316
Noise

we will discuss the mechanisms responsible for producing this type of noise, but in this chapter
as well as Chapter 6 we will study its impact on the system level performance of the transceiver.
Since ϕn(t) represents the noise, we may say |ϕn(t)|  1. Therefore we can use the narrowband
FM approximation,
xLO(t)  AC[cos 2πfCt  ϕn(t) sin 2πfCt].
which indicates that the actual LO signal consists of an impulse representing the ideal cosine, as
well as a term representing noise in quadrature, and shaped around the carrier as shown in
Figure 5.42. The phase noise magnitude generally decays with a slope of 1/f2 moving away
from the carrier frequency, as predicted by Leeson [3]. This will be proven in Chapter 9, but we
will simply accept it for the moment.
This noisy LO signal is multiplied to the RF signal present at the mixer input. Thus the mixer
output, while translated in frequency, contains the phase noise convolved in the frequency
domain with the input. From this, we expect that in an otherwise ideal receiver, the LO phase
noise set a limit on the signal quality or SNR. Moreover, as we will show in Chapter 6, the
phase noise will also limit the receiver sensitivity when exposed to large unwanted signals,
known as blockers.
If the oscillator is embedded within a phase-locked loop (PLL), the phase noise proﬁle will
change according to the PLL frequency characteristics.
It is well known that [4], [5] the output noise of the VCO, once locked in PLL, will have a
phase noise proﬁle as shown in Figure 5.43. It consists of a relatively ﬂat passband set by the
PLL components, along with a region of 40dB/Dec (or 1/f2) slope set by the VCO noise. At
very far-out frequency offsets from the carrier, the noise ﬂattens out as the buffers or other hard-
limiting devices following the oscillator dominate. If such VCO is used in the transmit (or
receive) chain (Figure 5.43 right), this noise proﬁle is expected to appear at the output. We will
show in Chapter 6 that this noise along with the nonlinearity of the TX chain will be limiting
factors in the transmitter modulation mask requirements.
5.8
SENSITIVITY
..............................................................................................
The limit to the minimum detectable signal at the receiver input is readily found from the basic
noise ﬁgure deﬁnition:
Oﬀset from carrier
PLL Noise
PLL
VCO
BUF
PLL
Typical PLL Phase Noise Proﬁle
Typical RX/TX Chain
Figure 5.43: Typical PLL phase noise in a typical RX or TX chain
5.8 Sensitivity
317

F = SNRi
SNRo
=
Si
Ni
SNRo
:
We showed that the available noise power at the input is Ni = KT  41021W.s, expressed at a
1Hz bandwidth. If integrated over a certain bandwidth of interest denoted by B, the noise power
will be then KTB. Taking 10 log from each side, we can express noise ﬁgure in dB as follows:
NF = 10 log Si  10 log (KTB)  10 log SNRo.
Rearranging, and knowing that 10 log KT = 174dBm/Hz at room temperature,14 we will have
Sensitivity =  174 + NF + 10 log B + SNR.
Thus, guaranteeing a minimum SNR (in dB) at the detector output, the minimum detectable
signal or sensitivity expressed in dBm would be 174 + NF + 10 log B + SNR. Clearly, the
sensitivity may be improved by lowering the noise ﬁgure, or reducing the system bandwidth.
The latter directly leads to a lower throughput.
Example: Let us consider a 4G receiver shown in Figure 5.44. When operating in GSM
(Global System for Mobile Communications) mode, the standard requires a minimum
sensitivity of –102dBm. Most modern handsets achieve a much better sensitivity, around –
110dBm, corresponding to signal level of 0.7μV RMS at the antenna. To support multiple
bands and the transmit/receive multiplexing, a switch is inserted between the antenna and
multiple receivers (as well as the transmitter output though not shown) input. Moreover,
each receiver supporting a certain band is preceded by an external SAW ﬁlter (or a
duplexer in case of 3G or 4G) to attenuate unwanted signals.
The GSM signal is GMSK (Gaussian minimum shift keying) modulated, and takes a
bandwidth of about 200kHz. Typical modems need an SNR of at least about 5dB to detect
this signal properly. To achieve a sensitivity of –110dBm, the noise ﬁgure at the antenna
4G Receiver
4G Modem
⁞ 
Switch
SNR
Multiple Bands
Figure 5.44: A simpliﬁed 4G receiver block diagram
14 dBm is 10 log of a power quantity when expressed in mW. 1mW is then 0dBm. When expressing a power associated with
a peak voltage of V over a 50Ω resistor, then dBm = 10dB+ 20 log V = 10 + dBV.
318
Noise

must be 6dB. Furthermore, assuming a typical insertion loss of 3dB for the switch and
SAW ﬁlter combined, the receiver must have a minimum noise ﬁgure of 3dB. Note that
the switch and ﬁlter are considered lossy and passive components, so when placed at the
very input of the radio, their loss directly adds to the system noise ﬁgure.
Example: For the same receiver of previous example, we now assume that the output
noise of the receiver after downconverted to IF has a proﬁle as shown in Figure 5.45.
It consists of a ﬂat region, corresponding to the same 3dB noise ﬁgure, and starts
rising at lower frequencies due to the ﬂicker noise. The total output noise may be then
expressed as
No = NRX
1 + f c
f

	
,
where fc signiﬁes the ﬂicker noise corner frequency, that is, the frequency where the white
and ﬂicker noise contributions are equal. NRX when referred to the input must then
correspond to the same 3dB noise ﬁgure. Assume the downconverted signal occupies a
spectrum between fL and fH. Then total noise ﬁgure including the ﬂicker noise that was
previously ignored will be
F = NRX
GaKT
1
f H  f L
ðf H
f L
1 + f c
f

	
df = NRX
GaKT
1 + f c
ln f H
f L
f H  f L
0
B
B
@
1
C
C
A:
The second term is due to the excess noise resulted from ﬂicker noise, while the term NRX
GaKT
corresponds to a 3dB noise ﬁgure calculated previously. Assume that the GSM signal is
downconverted to a 135kHz IF. If the ﬂicker corner is, say, 100kHz, then the excess noise
factor is 1 + 100 ln235
35
200 = 1:95. Thus the effective sensitivity of the receiver degrades by
almost 3dB to –107dBm. Besides the obvious choice of reducing the ﬂicker noise corner,
another option is to place the signal at a higher IF. In Chapter 12, where we discuss the
receiver architectures, we will show that there are important repercussion of doing so. For
narrowband signals like GSM, the only viable option is to ensure the RX 1/f noise corner
is low enough. For instance, a ﬂicker corner of 10kHz would result in only 10 log 1.095 =
0.1dB degradation in sensitivity.
IF
RX Output Noise
fc
3dB NF
fL
fH
Downconverted 
Signal
Figure 5.45: 4G receiver output noise
5.8 Sensitivity
319

Example: Suppose the same receiver is operating in 3G mode, where a QPSK modulated
signal is received. The 3G signal is about 3.84MHz wide, and since it is spread spectrum,
the total SNR required is –18dB. In practice detecting a QPSK signal requires an SNR of
about +7dB. However, due to the spread spectrum nature of the 3G signal, there is what is
known as the processing gain, that is, the ratio of the received signal bandwidth to what it
will be after the decoding in the modem, in this case 30kHz. Thus,
Processing gain = 3:84MHz
30kHz
= 128 = 21dB:
Since there is an additional 4dB of coding gain, the net SNR is 7 – 21 – 4 = 18dB.
Ignoring the ﬂicker noise for the moment, the sensitivity is
174 + 6dB + 10 log (3.84MHz)  18 =  120dBm.
We assumed the loss of the combination of the duplexer and the switch is the same 3dB
we had in the case of GSM, which may be somewhat optimistic. The standard requires –
117dBm, that is, a 3dB margin if the receiver has 3dB noise. We will see in the next
chapter that there are other factors in the case of a 3G receiver that potentially lead to a
worst sensitivity than what we just calculated considering only the receiver
thermal noise.
Now let us consider the ﬂicker noise. Suppose we have the same corner frequency of
100kHz, which led to about 3dB degradation in the case of GSM. Also we assume the 3G
signal is downconverted to a zero IF. We perform the integration from an arbitrary lower bound
of 20kHz, to an upper bound of 1.92MHz where the signal resides. The particular choice of
20kHz lower bound (rather than zero) is due to the fact that in most modulations including 3G,
losing the signal energy around DC is acceptable. In fact most receivers incorporate some form
of a highpass ﬁlter to remove the DC offsets. The ﬁlter corner frequency is typically around tens
to hundreds of kHz, depending on the actual signal bandwidth. The ﬁlter settling would be too
slow if the highpass corner were to be pushed too low. With that, the excess noise is
1 + 0:1 ln1:92
0:02
1:9 = 1:23, and the sensitivity degradation is now only 0.9dB. If we were to integrate
from 10kHz instead, the excess noise would have increased to only 1.27, thus somewhat
justifying the rather arbitrary choice of the integration lower bound!
The above example points out a very important conclusion that the wideband receivers
such as 3G are far more tolerant of the ﬂicker noise even if the signal is downconverted to
DC. Thus zero-IF receivers are quite common for most wideband applications.
Example: As our last example, consider Figure 5.46, which shows more circuit-level
details of the 4G receiver. It consists of a low-noise transconductance ampliﬁer (LNTA), a
current-mode multiplier (or mixer), followed by an active-RC biquad.
320
Noise

The LNTA is matched to 50Ω and has a standalone noise ﬁgure of 2dB when properly
terminated with a noiseless load representing the mixer input impedance. It produces an
output current with a transconductance gain of gm = 100mS, ﬂowing into the current mode
mixer. We have simpliﬁed the mixer to a linear and time-invariant current mode ampliﬁer
with a current gain of α = 0.5, and simply assume it translates the signal frequency to a zero-
IF. The biquad, whose input stage is only shown, has a passband gain of 10, and presents an
input impedance of 2kΩ to the mixer. The receiver total available voltage gain is
Aa = gm 
500
500 + 20  α  4kk2k
ð
Þ  10 = 640:
Since the mixer is current mode, deﬁning a standard noise ﬁgure may not be as
meaningful. Thus, we instead assume that it can be modeled by an input-referred current
noise whose spectral density is 4KT20mS A2/Hz. The mixer noise when referred to the
source will be divided by gm/2, as shown in Figure 5.47. The extra factor of 2 has to do with
the voltage division between the source and the LNA input impedances, which are equal.
If the LNTA noise ﬁgure is F1, then the total noise referred to the source from the
LNTA and mixer is
F1  1
ð
Þ4KTRs +
2
gm

	2
 in22:
Therefore, the LNTA-mixer combined noise ﬁgure is
F = F1 +
2
gm

	2

in22
4KTRs
= 1:58 + 0:16 = 1:74 = 2:4dB:
Continued
Rs
vs
50Ω
500Ω
20Ω
4kΩ
2kΩ
gmv1
ai2
+
v1
–
i2
Low-noise TA
CM Mixer
Biquad
Figure 5.46: Simpliﬁed 4G receiver block diagram
Rs
vs
50Ω
500Ω
20Ω
gmv1
+
v1
–
i2
in2
2=4KT× 20m
Figure 5.47: Mixer noise referred to the
source
5.8 Sensitivity
321

Finally, let us assume that the biquad has a standalone noise ﬁgure of 4 or 6dB when
referred to the mixer output impedance of 4kΩ. The available voltage gain to the biquad
input was found to be 64, thus the total gain from the source to the biquad is 32. The
available power gain is then
322  Rs
Rout2
= 322  50
4000 = 12:8,
and the total noise ﬁgure is 1:74 + 41
12:8 = 1:97  3dB.
This is an example of how one can budget different noise and gain values to different
stages to meet a certain cascaded noise ﬁgure. In our case we started from the sensitivity
requirement of –110dBm, which is given to us, and that led to a noise ﬁgure of 3dB for
the RX. The rest of the numbers were chosen to satisfy the 3dB requirement for the entire
receiver.
5.9
NOISE FIGURE MEASUREMENTS
..............................................................................................
There are two common ways of measuring the noise ﬁgure that we will discuss here. Before
that, we should emphasize that the noise ﬁgure is usually expressed and measured at a given
frequency, known as spot noise ﬁgure. If one is interested, it could be characterized over a
range of frequencies of interest of course. Moreover, since noise levels are typically very
small, it is not uncommon to perform the noise measurements in isolated shielded chambers
immune to outside noise or interference. The noise monitored at the output of the device
under test (DUT) must be well above the noise ﬂoor of the measurement equipment. As a
result, it is often necessary to add pre- or post-ampliﬁers whose gain and noise are properly
de-embedded.
The ﬁrst method known as gain method is directly based on the basic deﬁnition of noise
ﬁgure:
F =
No
GaKT :
If one obtains the DUT available gain and the output noise (when terminated by 50Ω), as KT is
known, the noise ﬁgure is readily calculated. One potential issue with this type of measurement
is that the spectrum analyzer inherently needs to measure the noise integrated over a narrow
band deﬁned by its resolution bandwidth (RBW). This number may be converted to a spot noise
measured per frequency, if one has the exact knowledge of the type and shape of the ﬁlter. Most
modern spectrum analyzers have built-in functions to provide this information with a reason-
able accuracy. Also this method relies on two independent exact measurements of gain and
noise. Thus, the spectrum analyzer and the signal generator used in the setup must be very well
calibrated.
322
Noise

The second method, known as the Y-factor method, or hot–cold measurement,15 only
requires two relative measurements, and no knowledge of the spectrum analyzer ﬁlter is
required. Shown in Figure 5.48, the device under test is connected to a very accurate and
well-calibrated noise source, capable of producing two different levels of noise at the
DUT input.
If the noise source is off, it simply behaves like a 50Ω resistor. Once turned on, it still
provides a 50Ω termination but with α > 1 times more noise. The output noise of the DUT is
measured in each case by a spectrum analyzer or a power meter, and recorded. The input-
referred noise of the DUT is always (F  1)KT. So the two noise recordings when referred to
the input (labeled as N0 and N1) will be
N0 = KT + F  1
ð
ÞKT
N1 = αKT + F  1
ð
ÞKT:
The factor α, referred to as the excess noise ratio (ENR), is a known quantity, and is given by
the noise source manufacturer. By diving the two equations, any dependence on the absolute
accuracy of the noise measurement or DUT gain is eliminated:
N1
N0
= α + F  1
ð
Þ
F
:
Solving for F yields
F = α  1
N1
N0
 1
:
So just two relative measurements of the DUT noise are needed now, but they do require a well-
calibrated noise source. The value of excess noise (α) is typically available over a wide range of
frequencies of interest. Most modern network analyzers have built-in functions to use the noise
source, and express the noise ﬁgure directly.
It is interesting to note that if the device is noiseless, the increase in the output noise when the
source is turned on is exactly equal to the excess noise. The noisier the device is, the less
increase in the level of the output noise is observed, corresponding to less accuracy. Therefore,
DUT
Noise
Source
Spectrum
Analyzer
Rs=50Ω
4KTaRs
Figure 5.48: Y-factor noise ﬁgure
measurement
15 The naming convention is from the fact that two levels of noise are injected to the system corresponding to cold and hot
conditions given the noise dependence on the absolute temperature.
5.9 Noise Figure Measurements
323

if the device noise ﬁgure is expected to be too high compared to the source excess noise, one
may consider using a well calibrated preampliﬁer.
The noise source cannot be created using passive only noisy elements (why?), and typically
consists of an avalanche diode whose bias current is ﬁxed by a precise current regulator
followed by a matching network and an attenuator (Figure 5.49).
The BNC16 input turns the noise source on and off. When turned on, the avalanche diode
whose current IB is very well regulated, creates a well-deﬁned noise current with the spectral
density of 2qIB, where q = 1.6  1019C is the electron charge. This excess noise ultimately
appears at the output through a buffer and a matching network. The RF output is still matched
to 50Ω, but its noise spectral density is greater than that of a 50Ω resistor by an amount deﬁned
by the ENR, set by the noise generator circuitry.
An example of a commercially available noise source (Keysight 346C)17 is shown in
Figure 5.50. It has an ENR of 15dB, and works from 10MHz to 26.5GHz.
Current 
Regulator
Matching 
Network
DC Block
Attenuator
RF Output
BNC Input
IB
Noise 
Generator
Figure 5.49: Simpliﬁed circuit diagram of an RF noise source
Figure 5.50: Keysight 346C RF noise source
16 The BNC (Bayonet Neill–Concelman) connector is a miniature radio frequency connector used for coaxial cable.
17 See https://www.keysight.com/en/pd-1000001300%3Aepsg%3Apro-pn-346C/noise-source-10-mhz-to-265-ghz?pm=PL&
nid=-536902744.536880071&cc=US&lc=eng.
324
Noise

5.10 Summary
The important topic of noise was disused in this chapter, and will be extensively referred to in
Chapters 7, 8, 9, and 10 in the context of noise properties of RF building blocks such as low-
noise ampliﬁers, mixers, or oscillators.
– Section 5.1 discussed introductory material on the noise, and presented the types of noise in
commonly used RF elements such as resistors or transistors. We also discussed the noise of
passive reciprocal circuits, as well as cyclostationary noise, which is noise in periodically
varying circuits.
– In Section 5.2 we developed the two-port equivalent noise model.
– Noise ﬁgure and the minimum noise ﬁgure concept were discussed in Sections 5.3 and 5.4.
The minimum noise ﬁgure is an essential part of designing good low-noise ampliﬁers.
– The impact of feedback in general, and lossless feedback in particular, on noise were
presented in Section 5.5. Most low-noise ampliﬁers take advantage of lossless feedback in
some form to simultaneously satisfy the matching and minimum noise ﬁgure.
– Section 5.6 extended the deﬁnition of noise ﬁgure to more complex structures comprising
several sub-blocks.
– In Section 5.7 we brieﬂy discussed the concept of phase noise, which is required to
understand reciprocal mixing in ampliﬁers and receivers. A thorough treatment of phase
noise is presented in Chapter 9.
– Sensitivity was deﬁned in Section 5.8, followed by several practical examples.
– The chapter concluded by discussing practical implications of noise measurement.
5.11 Problems
1. Find the minimum noise ﬁgure of a FET in a source-follower conﬁguration. Ignore Cgd.
Answer: F = 1 + 1 + jωCgs1ZTH
gm1 + jωCgs1


2 γ gm1 + gm2
ð
Þ
Re ZTH
½
 , and Fmin = 0.
2. For the following circuits, ﬁnd the input-referred noise voltage. Ignore 1/f noise, ro, and
capacitances.
R2
M2
R1
M1
M1
R1
M1
5.11 Problems
325

3. Find the equivalent noise bandwidth of an nth-order Butterworth ﬁlter.
4. Using Laplace transform differentiation property, prove the initial value theorem, that
z 0 +
ð
Þ = lim s!∞sZ zð Þ.
5. For the following current-mode passive mixer, ﬁnd the noise spectral density at the input of
the transimpedance ampliﬁer (TIA). The TIA has a zero input impedance. What is the noise
if the input current source is ideal? Answer: SiOUT =
4KT
Rs + RSW.
iOUT
SW2
Rs
is
SW1
6. Find the impact of an ideal series–series feedback on equivalent noise sources, and the
minimum noise ﬁgure.
7. Show that instead of the input noise voltage, if we were to break the input noise current into
correlated and uncorrelated parts, the noise ﬁgure would be
F = 1 + Zs
j
j2 Gu + Rn Ys + Yc
j
j2
Rs
:
Find the optimum source admittance by taking partial derivatives of the noise equation,
and express the optimum noise ﬁgure in terms of the noise current parameters and the
correlation admittance (Yc).
8. Find the minimum noise ﬁgure of the resistively degenerated common-source ampliﬁer
shown below. Ignore all the capacitances, the body effect, and ro.
VDD
RL
RS
326
Noise

9. For the ampliﬁer shown below, the load is ideal (noiseless). Ignoring Cgd and the junction
capacitances (but not Cgs), ﬁnd the input impedance of the ampliﬁer. What are the
equivalent noise sources and the minimum noise ﬁgure? Assume ro = ∞, and ignore the
body effect.
ZL
VDD
LS
10. Prove the energy conservation for the circuit shown below using Tellegen’s theorem,
P = 1
2 ZIN jω
ð
Þ IS
j j2 = 1
2
P
i Ri Ii
j j2 + 1
2
P
k jωLk Ik
j j2  1
2
P
p
1
jωCp Ip
 2, where Ri, Li, and Ci,
are the one-port RLC components.
ZIN
IS
11. Calculate the insertion loss and noise ﬁgure (without using the Nyquist theorem) of the
following ladder ﬁlter, where the inductor has a ﬁnite Q, and show that they are equal.
Answer: F = 1 + r
Rs .
Rs
Rs
C
L
r
12. Prove the dual of the Nyquist theorem: the current noise spectral density at the output of an
RLCM one-port with output admittance Y(s) is Sin( f ) = 4KT Re [Y( f )].
13. Using basic noise deﬁnition (and not the Nyquist theorem) show that the noise ﬁgure of a
passive lossy circuit is equal to its loss. Lump all the loss as a shunt resistor at the output.
Hint: Use reciprocity.
14. Find the noise ﬁgure of the following resistive circuit with and without the Nyquist
theorem.
5.11 Problems
327

R2
R3
R1
15. Suppose v(t) is white noise, and the random variable s is deﬁned as s =
Ð T
T v tð Þdt. Find the
variance of s.
16. In the following network, by calculating transfer functions from thermal noise of resistor R
modeled as a noise voltage source to the capacitor voltages or the inductor current, and
calculating appropriate integrals over ω 2 (∞, +∞), prove that the mean square of thermal
noise voltages stored across the capacitors C1 and C2, and the mean square of thermal noise
current stored in inductor L are equal to kT/C1, kT/C2 and kT/L, respectively. Therefore, the
mean square of thermal noise energy stored in each memory element is equal to kT/2.
C1
L
R
C2
17. Assume that the input for an LTI system is a white noise x(t) with autocorrelation of
Rx τð Þ = N0
2 δ τð Þ and the output is y(t). Prove that cross-correlation Ryx(τ) is proportional to h
(τ), where h(t) is the system impulse response. This is a popular approach to estimate the
impulse response of an LTI system by applying a white noise source to the input and
correlating the same input with the response of the system.
18. Find the impact of series reactive feedback on the ampliﬁer minimum noise ﬁgure depicted
below. Use Z parameters to model the ampliﬁer and the feedback network.
LCM
Network
Noisy
Amplifier
ZL
vneq
ineq
Zs
19. A white Gaussian noise n(t) with a two-sided power spectral density of N0 V2/Hz is applied
to the control voltage of a sinusoidal voltage-controlled oscillator (VCO) with a VCO gain
328
Noise

of KVCO. Prove that the power spectral density of the VCO output voltage is Lorentzian
given by: SV ω
ð Þ =
K2
VCO
N0
2π
K2
VCO
N0
4π
ð
Þ
2 + ωω0
ð
Þ2. Hint: Establish the phasor V(t) = exp (j(ω0t + φ(t))),
representing the VCO signal, where φ(t) = KVCO
Ð
n(θ)dθ is the phase perturbation. Show
that RV(τ) = ejω0τE[ej(φ(t + τ)  φ(t))]. Deﬁne the variable x(t, τ) = φ(t + τ)  φ(t). Knowing
that φ(t + τ) and φ(t) are jointly Gaussian with a standard deviation σ, show that
E[ej(φ(t + τ)  φ(t))] = eσ2/2 = e(Rφ(0)  R
φ
(τ)). Obtain an expression for Rφ(τ) considering
that it is linearly dependent on n(t), and ﬁnd the VCO voltage spectral density.
20. Drive the noise ﬁgure of cascade of three stages, each stage represented only by its input-
referred noise voltage. The stages are assumed to have an inﬁnite input impedance, and
thus zero input-referred noise current.
21. Not ignoring the base resistance, ﬁnd the low-frequency input-referred noise voltage and
current of a BJT. How does that compare to a FET biased at the same current?
22. In the following gm-C resonator, the noise of the transconductors is modeled as current
sources in1 and in2 at their outputs. Derive transfer functions from these current sources to
the voltage across C1 and prove that one of the transfer functions is a lowpass and the other
one is a bandpass. Assuming one-sided power spectral density of these noise currents are
4kTFgm, prove that the mean square of the noise voltage across C1 is equal to kTF
C1 gmR and
kTF
C2 gmR contributed by noises in1 and in2, respectively.
gm
C2
–gm
in1
in2
C1
R
23. Find the input impedance and the input-referred noise of the following active gyrator. The
transconductors consist of a single FET with ideal active load. Ignore the device
capacitances.
gm
C
gm
+
–
+
–
+
–
+
–
24. Repeat Problem 23, where the transconductors are realized by inverters with identical
N and P devices.
5.11 Problems
329

25. Using
the
bilinear
relation
between
impedance
and
reﬂection
coefﬁcient
(Zs=s,opt = Z0
1 + Γs=s,opt
1Γs=s,opt , where Z0 is the characteristics impedance), map the noise factor
equation into the Smith chart. Hint: Describe the noise factor equation in terms of the
reﬂection coefﬁcient as follows: F = Fmin + 4GnZ0
ΓsΓs,opt
j
j
2
1 Γs
j
j2
ð
Þ 1Γs,opt
j
j
2. For a given ampliﬁer,
Gn, Fmin, and Γs,opt are known. Thus, we can rearrange Γs  Γs,opt
K + 1


2
=
K2 + K 1 Γs,opt
j
j
2


K + 1
ð
Þ2
. For
a given F, and hence K, Γs is described by a circle on the Smith chart.
5.12 References
[1] P. R. Gray and R. G. Meyer, Analysis and Design of Analog Integrated Circuits, John Wiley, 1990.
[2] H. Friis, “Noise Figures of Radio Receivers,” Proceedings of the IRE, 32, no. 7, 419–422, 1944.
[3] B. Leeson, “A Simple Model of Feedback Oscillator Noise Spectrum,” Proceedings of the IEEE, 54,
329–330, 1966.
[4] F. M. Gardner, Phaselock Techniques, John Wiley, 2005.
[5] D. H. Wolaver, Phase-Locked Loop Circuit Design, Prentice Hall, 1991.
[6] A. Van der Ziel, Noise in Solid State Devices and Circuits, John Wiley, 1986.
[7] Y. Tsividis and C. McAndrew, Operation and Modeling of the MOS Transistor, Oxford University Press,
2010.
[8] S. M. Sze and K. K. Ng, Physics of Semiconductor Devices, John Wiley, 2006.
[9] B. G. Streetman, Solid State Electronics, 4th ed., Prentice Hall, 1995.
[10] A. Papoulis and S. U. Pillai, Probability, Random Variables, and Stochastic Processes, McGraw-Hill,
2002.
[11] H. Nyquist, “Thermal Agitation of Electric Charge in Conductors,” Physical Review, 32, no. 1, 110–113,
1928.
[12] J. B. Johnson, “Thermal Agitation of Electricity in Conductors,” Physical Review, 32, no. 1, 97, 1928.
[13] C. A. Desoer and E. S. Kuh, Basic Circuit Theory, McGraw-Hill, 2009.
[14] J. Chang, A. Abidi, and C. Viswanathan, “Flicker Noise in CMOS Transistors from Subthreshold to
Strong Inversion at Various Temperatures,” IEEE Transactions on Electron Devices, 41, no. 11,
1965–1971, 1994.
[15] W. Gardner and L. Franks, “Characterization of Cyclostationary Random Signal Processes,” IEEE
Transactions on Information Theory, 21, no. 1, 4–14, 1975.
[16] A. Demir and A. Sangiovanni-Vincentelli, Analysis and Simulation of Noise in Nonlinear Electronic
Circuits and Systems, Kluwer, 1998.
[17] D. Halliday, R. Resnick, and J. Walker, Fundamentals of Physics, John Wiley, 2013.
[18] R. Eisberg, Fundamentals of Modern Physics, John Wiley, 1990.
330
Noise

6
Distortion
In Chapter 5 we showed that the thermal noise of a receiver sets a lower limit on the signal
detectable at the receiver input. The upper limit to the maximum signal a receiver can handle
is set by the distortion, arisen from nonlinearity present in the active circuits making up the
receiver. However, handling a desired large input is generally not an issue as it is typically
managed by the proper gain control in the receiver. On the other hand, we will show in this
chapter that the distortion has a far more detrimental impact on the receiver, when subject to
large unwanted signals, known as blockers. Similar to noise, the blockers will also set a lower
limit on the detectable signal.
We start this chapter with general description of blockers and their proﬁle in wireless
systems. We then present four distinct mechanisms that can impact the receiver performance
in the presence of large blockers: small signal nonlinearity, large signal nonlinearity, reciprocal
mixing, and harmonic mixing. We discuss the appropriate ﬁgures of merit for each case, and
describe their practical impacts on modern receivers.
The speciﬁc topics covered in this chapter are:
• General description of blockers in radios
• Full duplex systems
• 2nd-, 3rd-, and 5th-order intercept point
• Compression and desensitization
• Reciprocal mixing
• Harmonic distortion
• Noise and linearity in transmitters
• AM–AM and AM–PM distortion
• Pulling in transmitters and its impact on performance
While this chapter may be very appealing for RF circuit and system engineers, for class use we
recommend focusing only on a summary of Sections 6.1 and 6.2 and covering Sections 6.3.1,
6.3.3, 6.3.7, and 6.4. The rest of the material may be assigned as reading. The chapter
includes many practical examples of deriving blocker requirements for both receivers and
transmitters for various applications, such as cellular or wireless LAN.

6.1
BLOCKERS IN WIRELESS SYSTEMS
..............................................................................................
Let us consider a cellular network where the area under coverage is divided into hundreds of
cells. In a typical metropolitan environment, each cell is a few miles wide, where a simple
conceptual graph for the purpose of demonstration is shown in Figure 6.1.
To every cell is assigned a base station, and the base stations are connected to each other by
wire. Mobile handsets do not communicate directly, rather each handset residing in a given cell
communicates only with the corresponding base station, which is a similar radio in nature as the
handset, but with somewhat more stringent requirements.
It is well known that the energy of an electromagnetic wave decays in free space by 1
d2, d
being the distance between the transmitter and the receiver (Figure 6.2). In metropolitan areas,
on the other hand, the wave decays with much faster slope of 1
dn, where n > 2, and could be as
large as 4 [1], [2].
There are several reasons behind this which could be attributed to phenomena such as
multipath fading, or blocking as shown in Figure 6.2. In the case of fading, for instance, the
transmitted signal could be subtracted entirely from its reﬂected replica, if the delays between
the two paths are such that a 180º phase shift is created. Since the mobile users are moving, the
signal strength can be changed dynamically in either direction.
Now consider the cellular network of Figure 6.1, where a given handset is subject to a very
weak signal from its own intended base station for the reasons mentioned, but happens to be
receiving strong signals from the nearby base stations (Figure 6.3). The receiver must be still
able to detect the weak desired signal properly, despite being subject to such large undesirable
signals from other base stations.
Transmitter
Receiver
Fading
Blocking
1/d 4
d
Figure 6.2: Electromagnetic waves decaying in metropolitan areas
Base Station
Figure 6.1: A cellular network
332
Distortion

If the thermal noise were the only source of nonideality, this would not have been an issue.
As we will show shortly, however, other imperfections in the receiver such as nonlinearity or
phase noise would impact the weak desired signal drastically. These unwanted signals created
by the other base stations are commonly known as blockers or interferers. Typically in a given
standard, their strength and frequency proﬁle are provided to the RF designers. We should
emphasize that statistically speaking, there is always a probability, however small, for the
receiver to fail under very extreme conditions, but the standards are generally evolved to
minimize that as much as practically possible.
The blockers are not only limited to the other base stations in the case of a cellular network.
Any other wireless device that happens to be in the vicinity of the handset of interest may be a
potential interferer. These blockers are known as out-of-band blockers, which fall outside the
band of interest for a given standard, as opposed to in-band blockers discussed earlier. The
standard has provisions for these out-of-band blockers as well, although since they are generally
not as much under the control of the given network of interest, they happen to be more
challenging. On the other hand, since they are outside the band of operation, an RF ﬁlter
placed right at the input of the receiver could help attenuate them. Such a ﬁlter may not be as
much practical for the in-band blockers, as it would be too narrow. Moreover, it must be tunable
to ensure that as the receiver tunes to different channels (or effectively connects to different
base stations operating at different frequencies), the desired signal falls in the ﬁlter passband.
An example of GSM blocker proﬁle for 1900MHz band is shown in Figure 6.4.
Each channel is 200kHz wide, and the channel spacing is 200kHz. The total band is 60MHz
wide, from 1930 to 1990MHz, and thus it contains a total of 300 channels. The desired signal is
speciﬁed to be 3dB above the reference sensitivity, that is at –99dBm. The in-band blockers
strength vary from –43dBm to –26dBm, ranging from 600kHz offset from the desired signal to
3MHz and beyond. The out-of-band blockers, however, may be as large as 0dBm. The reason
that the blocker level progressively increases as the offset frequency from the desired signal
goes up has to do with the way the frequency is assigned to each cell. Typically adjacent cells
have frequencies that are relatively far from that of the desired. Their close vicinity, however,
Receiver
TX0
TX1
TX2
Desired
Interferer
Interferer
Desired
Blockers
TX2
TX1
Figure 6.3: A weak desired signal accompanied by a strong interferer
6.1 Blockers in Wireless Systems
333

results in strong blockers. The second adjacent cells that potentially result in somewhat weaker
blockers have frequencies closer and so on. This helps the receiver ﬁlter design as well as phase
noise requirements as we will discuss shortly.
To point out the challenge of applying a ﬁlter at the front end to attenuate the in-band
blockers, consider that a bandwidth of 200kHz, centered at around 1960MHz, needs to be
covered. This leads to a center frequency to bandwidth ratio of 9800. Whereas to only attenuate
the out-of-band blockers, the ratio is roughly 33, much more practical. We also note that there is
a 20MHz guard band on each end that blockers are still speciﬁed to be –26dBm. They do not
increase to 0dBm until 80MHz away from the edges of the band.
In addition to in-band blockers that are speciﬁed from 600kHz and beyond, there are also
adjacent blockers shown in Figure 6.5 that are closer in frequency but much weaker. The
desired signal is speciﬁed at –82dBm, well above the sensitivity. Thus it is possible to reduce
the receiver gain to some extent to enhance the blocker tolerance. While only shown on the
right side of the desired signal in the ﬁgure, the blockers could be located on either side with the
same frequency offset and strength.
≈ 
≈ 
… 
0dBm
–12dBm
–26dBm
–43dBm
–33dBm
1930MHz
1910MHz
1830MHz
600kHz
1.6MHz
3MHz
Desired
Out-of-Band
1990MHz
2010MHz
… 
… 
Out-of-Band
In-Band
Figure 6.4: GSM in- and out-of-band blockers
200kHz
600kHz
400kHz
Desired
–82dBm
–73dBm
–41dBm
–33dBm
Figure 6.5: GSM adjacent blockers
334
Distortion

6.2
FULL-DUPLEX SYSTEMS AND COEXISTENCE
..............................................................................................
Apart from the in- and out-of-band blockers, there is yet another blocker mechanism present in
full-duplex division (FDD) transceivers, such as 3G or LTE (long-term evolution) radios. In
contrast to time-duplex division (TDD) systems, in FDD radios, the receiver and the transmitter
operate concurrently. Shown in Figure 6.6, the receive and transmit chains are typically isolated
from one another by a duplexer, which could be thought of two SAW ﬁlters, each tuned to the
corresponding receiver and transmit bands (see Chapter 4 for more details).
In practice, the duplexer has a ﬁnite isolation, somewhere around 45–55dB, depending on
its size and cost. Thus, the output of the transmitter leaks to the receiver input and acts as a
blocker. In 3G radios, for instance, the transmitter output is about +27dBm (24dBm at the
antenna according to the standard, after experiencing 3dB loss for the duplexer and switch).
A 50dB isolation leads to an always present –23dBm blocker. This blocker may be accom-
panied by other in- and out-of-band blockers discussed before, further exacerbating the issue
(Figure 6.6).
In TDD systems on the other hand, only one of the TX or RX is on at a given point of the
time. Thus, all that is needed is a switch to connect each to the antenna (Figure 6.7), and there is
no such blocker concern. Examples of TDD systems are Bluetooth, Wi-Fi, and GSM radios.
Another similar concern arises from platforms where there are multiple radios present
supporting various applications. These radios may be integrated all on the same die, or be on
separate chips, but still at close vicinity to each other. An example is a smart handset consisting
of several radios for Bluetooth, Wi-Fi, cellular, and other applications. Each radio comprises its
Receiver
Transmitter
TR Switch
Figure 6.7: TDD radios
Receiver
fTX
fRX
Transmier
RX Desired
TX Leakage
Other Blocker
Figure 6.6: Full-duplex transceivers
6.2 Full-Duplex Systems and Coexistence
335

own antenna in general, but the antennas enjoy only a ﬁnite isolation of less than 20dB. In some
applications, antennas are shared and radios are separated by a duplexer, as in Figure 6.6. Since
in general all these applications may run simultaneously, we could have scenarios where one
transmitter acts as a blocker to the other receiver (Figure 6.8), leading to a very similar situation
as we observed in FDD transceivers.
With this background, let us now discuss the different mechanisms by which these blockers
can harm the receiver.
6.3
SMALL SIGNAL NONLINEARITY
..............................................................................................
Consider the circuit shown in Figure 6.9, where we assume the output–input characteristics is
not linear and is described below:
y = a1x + a2x2 + a3x3.
For the moment, let us consider only up to 3rd-order nonlinearity. Also we have ignored any
DC offset associated (the term a0), as it will not affect our discussion.
When a sinusoid input applied, that is, when x = A cos ωt, the output will be
y = a2A2
2
+
a1A + 3a3A3
4


cos ωt + a2A2
2
cos 2ωt + a3A3
4
cos 3ωt:
As a result of the 2nd-order nonlinearity, a DC term is created, despite the fact that we
assumed the DC term a0 is equal to zero. Additionally, the output consists of all the
harmonics of the fundamental frequency. This is known as harmonic distortion, and in
certain applications, such as audio ampliﬁers, it may be problematic, as the low-frequency
audio signal is distorted due to the presence of the unwanted harmonics. In most narrowband
RF applications, however, this is not a major concern as these harmonics are far away, and
subject to ﬁltering (Figure 6.10).
Receiver #1
Radio 1
… 
Transmitter #2
Radio 2
… 
RX1 Desired
TX2 Leakage
TX2 Output
Finite Isolation
Figure 6.8: Coexistence of several radios in one platform
336
Distortion

6.3.1
Input Intercept Point
Now suppose the input consists of two sinusoids, x = A1 cos(ω1t) + A2 cos(ω2t), where ω1 and
ω2 are relatively close. Once experiencing the nonlinearity, the output will consist of many
components; of those we consider only the ones that will fall around the desired components at
ω1 and ω2, knowing that the rest are subject to ﬁltering:
y = a1 A1 cos ω1t
ð
Þ + A2 cos ω2t
ð
Þ
ð
Þ + 3a3A12A2
4
cos 2ω1  ω2
ð
Þt
+ 3a3A22A1
4
cos 2ω2  ω1
ð
Þt +    :
If ω1 and ω2 are close to each other, then the two products located at 2ω1  ω2 , and 2ω2  ω1,
known as intermodulation products (IM), will also be close. Consequently, as shown in
Figure 6.11, they will not experience any signiﬁcant front-end ﬁltering, and may degrade the
receiver performance.
Particularly, this could be quite problematic if the either one of the intermodulation (IM)
products happen to be close to the desired signal. Consider the example of a GSM system,
where two in-band blockers are located at f1 = f0 + NΔf and f2 = f0 + 2NΔf; N is the channel
number; and Δf = 200kHz is the channel spacing. For the case of the 1900MHz band example
we showed earlier, N could be anything from 0 to 149 (2N is between 0 and 299). If the desired
signal happens to be at f0, the IM3 product1 will fall on the desired signal (Figure 6.12).
Same as noise and noise ﬁgure, we would like to attach a universal ﬁgure of merit describing
the 3rd-order intermodulation performance of a radio. For that, we deﬁne the 3rd-order input
intercept point (IIP3) as follows: Suppose we apply two tones with equal amplitude of A. At the
output, we have fundamentals with amplitude of roughly a1A, and IM3 components with an
amplitude proportional to |a3A3|. The value of the input amplitude A for which the two curves
intercept is known as IIP3 (Figure 6.13).
x
y = a1x+a2x2+a3x3
Figure 6.9: A generic nonlinear circuit
f
f
2f
3f
NB RF System
Figure 6.10: NB RF system ﬁltering the undesired
harmonics
1 The subscript 3 emphasizes the fact that these products are created due to 3rd-order nonlinearity.
6.3 Small Signal Nonlinearity
337

The fundamentals increase proportional to A (or a slope of 20dB/Dec), whereas the IM
products increase proportional to A3 (or a slope of 60dB/Dec). Therefore, they are expected to
intercept eventually, although in practice this never happens. This has to do with the fact that
almost all practical nonlinear systems are compressive, that is, the gain (or the slope) eventually
reaches zero for very large inputs. This in turn is due to the fact that large inputs could turn off
some transistors or that eventually the output is limited by the supply. In other words, the
characteristics polynomial has other terms beyond a3 that we have ignored. Nevertheless, the
two curves can be extrapolated, and at the interception point we can write
a1A
j
j = 3a3A3
4

,
which leads to
AIIP3 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
a1
a3


s
:
A perfectly linear system thus has an IIP3 of ∞.
f2
f1
f2
f1
2f1–f2
2f2–f1
Figure 6.11: Third-order nonlinearity when
two tones are applied
f2
f1
f0
f2
f1
f0
Desired
IM3
IM3
Figure 6.12: Intermodulation in a GSM receiver
f2
f1
2f1–f2
2f2–f1
a1A
3/4a3A
a A
a A
3
20logA
IIP3
Never reach due to 
compression
DP3
Figure 6.13: Illustration of input intercept point
338
Distortion

To measure the IIP3 properly, we must apply large enough inputs that the IM products are
well above the radio or the measurement equipment noise ﬂoor. However, they must be small
enough to avoid the compression. A practical sanity check is to ensure that a well-behaved
slope of 1 and 3 is observed for the desired and IM components.
Let us denote the difference between the fundamental and IM components in dBm (or dBV)
by ΔP3 (Figure 6.13). We have
ΔP3 = 20 log
a1A
3a3A3
4


= 2IIP3 in dBm
ð
Þ  40 log A = 2IIP3  2P,
where P = 20 log (A) is the input in dBV.2 Rearranging the equation above yields
IIP3 = P + ΔP3
2 :
This leads to a more convenient way of measuring IIP3, as long as we choose the input such that
a slope of 3:1 is guaranteed.
Now suppose an otherwise ideal 3rd-order nonlinear receiver is subject to a 2-tone blocker
with an amplitude of PB in dBm. This results in an undesirable IM component whose level in
dBm is
IM3 in dB
ð
Þ = PB  ΔP3 = 3PB  2IIP3:
If the intermod product falls on the desired signal, it must be at least an SNR below to detect the
signal properly. Note that the SNR was earlier deﬁned as the detector response to the noise.
However, since the IM product is resulting from a randomly modulated blocker, it is safe to
assume that the modem requires the same SNR. Under such assumption, the minimum input
that satisﬁes this equation deﬁnes the receiver sensitivity. Therefore,
Sensitivity = 3PB  2IIP3 + SNR:
The receiver is free of any noise, and the limit on the sensitivity is solely due to the response of
the nonlinear receiver to large blockers.
Example: Consider the GSM receiver. The standard speciﬁes a 2-tone blocker at –49dBm
located at 800kHz and 1.6MHz away from the desired input at –99dBm. Suppose we
would like to achieve an SNR of 10dB. Even though 5dB is typically sufﬁcient for most
modems, we would like to leave room for other nonidealities and particularly the noise.
Then the IIP3 may be calculated as
99 = 3  49  2IIP3 + 10,
Continued
2 The equation is equally valid if everything is expressed in dBm also, where dBm = 10 + dBV, with A representing the peak
voltage.
6.3 Small Signal Nonlinearity
339

leading to an IIP3 of –19dBm for the receiver. Every dB increase in the blocker level
results in 3dB degradation in the sensitivity. For the same IIP3, if the blockers are now –
47dBm, the SNR degrades to only 4dB, and the receiver fails.
Example: We shall calculate the IIP3 of a single FET. If we use the long channel I-V
characteristic that is square-law, the IIP3 will be inﬁnite as there is no 3rd-order nonlinearity.
To obtain a more meaningful result, let us assume a more realistic model that incorporates
both velocity saturation and mobility degradation due to the gate vertical ﬁeld [3]
ID = 1
2 μ0COX
W
L
VGS  VTH
ð
Þ2
1 +
μ0
2vsatL + θ


VGS  VTH
ð
Þ
,
where vsat is the saturated velocity, and μ0, COX, W, and L are the device parameters. The
parameter θ captures the impact of the vertical ﬁeld imposed by the gate. Let us deﬁne
θ0 =
μ0
2vsatL + θ:
If θ0 = 0, the device will be square-law. In practice however, the velocity saturation (the
ﬁrst term), as well as the vertical ﬁeld mobility degradation factor (the second term) result
in third and higher order nonlinearity terms.
For a given nonlinear function y = f(x), Taylor series [4] may be employed to ﬁnd the
coefﬁcients of the nonlinear function expanded around x = 0:
a1 = ∂y
∂x

x = 0
,
a2 = 1
2
∂2y
∂x2

x = 0
,
a3 = 1
6
∂3y
∂x3

x = 0
,    :
Performing these derivatives on the ID–VGS function, and considering that VGS consists of
a ﬁxed DC bias as well as an AC small signal component, we can obtain a1 and a3.
Accordingly, the IIP3 (in volts) is
AIIP3 = 1 + θ0Veff


ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
Veff 2 + 2Veff
θ
0


s
,
where Veff = VGS  VTH is the gate overdrive voltage. This derivation only considers ID–VGS
nonlinearity and the impact of channel length modulation and other 2nd-order effects are
ignored. Clearly the IIP3 monotonically improves as the overdrive voltage increases. On the
other hand the impact of θ0 is not as obvious. If it is very small, then we have
AIIP3 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
8
3
Veff
θ
0
r
:
However, for most modern CMOS processes θ0 is not negligible even for longer channel
devices and the above approximation may not hold.
340
Distortion

Example: For a BJT, the IC–VBE characteristics are exponential, and upon expanding, the
IIP3 is readily found to be constant and equal to
AIIP3 = 2
ﬃﬃﬃ
2
p
VT = 2
ﬃﬃﬃ
2
p
KT
q
,
which is about 70mV at room temperature.
It is well known that MOSFETs have exponential I–V characteristics in weak inversion,
similar to BJTs as shown below,
ID  μnCD
W
L
KT
q

2
ni
NA

2
e
VGSVGS∗
nKT=q ,
where CD is the depletion capacitance and n = 1 + CD
COX is roughly equal to 2 for typical
processes, ni is the Si intrinsic electron/hole density, and NA is the substrate doping. Thus the
IIP3 is constant and equal to 2
ﬃﬃﬃ
2
p
nVT.
Shown in Figure 6.14 is the simulated IIP3 of a single FET for two different channel
lengths, corresponding to two different values of θ0. The drain voltage is kept constant at VDD,
and the output current is monitored, thus eliminating the potential impact of ro nonlinearity.
Also shown is the calculated IIP3 in dashed line for each case. For VGS < VTH, the device is in
weak inversion and the IIP3 is constant at about 104mV. At the onset of device turning on, the
IIP3 peaks. This is attributed to a discontinuity for the second derivative of the drain current.
Although the phenomenon is real, it may not be much use in practice as it happens in a very
narrow region, and is likely to vary over process or temperature variation. Ignoring this region
(which is clearly not captured by the simple model), we observe a good agreement between
our hand calculations and the simulated IIP3. It is interesting that for modest to large values of
overdrive voltage, a shorter channel length, corresponding to a larger value of θ0, is more
linear.
2-tone
Veff
1.2V
io
Test Setup
L
q
L
q
Veff
¢
¢
Figure 6.14: Simulated IIP3 of a FET
6.3 Small Signal Nonlinearity
341

To achieve a reasonable linearity, an overdrive of 100–200mV is typical for most designs.
A higher overdrive leads to a better IIP3 of course, but the device gm and noise suffer for a given bias
current. To understand the trade-off, we show in Figure 6.15 gm/ID characteristics of a 40nm NMOS
transistor versus the overdrive voltage. For an overdrive voltage of 100mV, gm/ID is about 7V–1.
Note that gm/ID is expected to ﬂatten at roughly 1/nVT = 20V–1 (that is, n = 2) in weak inversion.
Example: Let us obtain the IIP3 of a 3G receiver. We consider the in-band blockers ﬁrst.
According to the standard QPSK modulated blockers at 10 and 20MHz away, each with
an amplitude of –46dBm accompany the desired signal 3dB above the reference sensitiv-
ity, as shown in Figure 6.16.
Assume we wish the resultant IM3 to be 10dB suppressed with respect to the signal less
SNR to provide sufﬁcient margin. The signal is at –117dBm + 3dB for band I for
instance,3 and thus the IM3 is required to be at –117 + 3 – (–18) – 10 = –106dBm.
If the two blockers have an equal magnitude of PB, we calculated before:
IM3 = 3PB  2IIP3:
Thus
106 = 346  2IIP3,
leading to an in-band IIP3 of –16dBm.
0
1
2
3
4
5
6
7
8
9
10
0
100
200
300
400
500
gm/ID, 1/V
Veﬀ, mV
Figure 6.15: gm/ID characteristics of a
40nm NMOS
10MHz
–46dBm
Sensivity+3dB
20MHz
Figure 6.16: 3G in-band IIP3
3 The reference sensitivity and some other requirements may vary by a few dB for different bands in both 3G and LTE cases.
342
Distortion

The second scenario is the case where the TX leakage mixes with an out-of-band
blocker at exactly half the frequency between the RX and TX signals as shown in
Figure 6.17. This results in an IM3 component falling on the desired RX signal.
Same as the in-band scenario, the signal is 3dB above the reference sensitivity, and we
assume the same 10dB margin. Hence, we wish to have the IM3 to be nomore than –106dBm.
For this case, the two blockers are not necessarily equal in amplitude, and the IM3
equation is modiﬁed to
IM3 = PB1 + 2PB2  2IIP3,
where PB2 corresponds to the blocker that is closest to the desired signal, in this case that
would be the out-of-band blocker. Thus, PB1 will represent the TX leakage. The out-of-
band blockers are speciﬁed to be at –15dBm for 3G. Assuming a duplexer isolation of
50dB, and a duplexer ﬁltering of 30dB on the blocker, we have
106dBm = 27dBm  50
ð
Þ + 2  15dBm  30
ð
Þ  2IIP3:
The required out-of-band IIP3 will be –3.5dBm.
6.3.2
IIP3 of Cascade of Stages
Same as noise ﬁgure, we would like to express the receiver IIP3 in terms of that of its sub-
blocks. Consider the cascade of two nonlinear stages, each with input–output characteristics
shown in Figure 6.18.
The small signal gain of each stage is a1 and b1, and the input IIP3 is AIIP3,1 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
a1
a3


r
, and
AIIP3,2 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
b1
b3


r
.
Receiver
fTX
fRX
TX Leakage
Out-of-band
∆f
∆f/2
Figure 6.17: 3G out-of-band IIP3
y = a1x+a2x2+a3x3
y = b1x+b2x2+b3x3
Figure 6.18: Cascade of two nonlinear stages
6.3 Small Signal Nonlinearity
343

The cascade input–output characteristics is
y = b1 a1x + a2x2 + a3x3


+ b2 a1x + a2x2 + a3x3

2 + b3 a1x + a2x2 + a3x3

3:
After performing a set of tedious derivatives, we obtain
y0 0
ð Þ = a1b1
y00 0
ð Þ
2
= a2b1 + a1
2b2
y000 0
ð Þ
6
= a3b1 + b3a1
3 + 2a1a2b2:
If we ignore the last term involved in y000(0) expression, assuming that the system is dominantly
3rd-order, we obtain the cascade IIP3 as follows:
AIIP3,T =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
a1b1
a3b1 + b3a13


s
:
Once rearranged, we obtain the well-known expression
1
AIIP3,T 2 =
1
AIIP3,12 +
a12
AIIP3,22 ,
indicating that the IIP3 of the second stage is dominant if the ﬁrst stage has a large gain,
opposite of the noise ﬁgure equation. This points out that the gain of the ﬁrst stage, often the
LNA, has to be carefully chosen to compromise the optimum noise ﬁgure and optimum IIP3 of
the overall system.
In addition to ignoring the third term in y000(0) equation, the above formula for cascaded IIP3
is correct only if both stages are compressive, or both are expansive. This is due to the fact that
to derive the equation, we have assumed same signs for a1/a3 and b1/b3 terms. If they had
opposite signs, it could have led to cancellations of nonlinearity. This outcome is generally
exploited in the context of pre-distortion linearization, as we will discuss in Chapter 11.
6.3.3
Second-Order Distortion
Similar to the 3rd-order nonlinearity, other order nonlinearities are expected to harm the receiver.
Of special interest is the 2nd-order nonlinearity, resulted from the term a2x2 is the general input–
output function described before. If the input consists of a 2-tone sinusoid signal, that is, if
x = A1 cos ω1t + A2 cos ω2t, considering only the 2nd-order nonlinearity, we have
y = a1 A1 cos ω1t + A2 cos ω2t
ð
Þ + a2A1A2 cos ω1  ω2
ð
Þt + a2A12
2
+ a2A22
2
+ . . . ,
where the terms subject to ﬁltering (e.g., at ω1 + ω2 or 2ω1) are not shown. The term
a2A1A2 cos(ω1  ω2)t may be problematic if the desired signal is eventually downconverted
344
Distortion

to or close to DC. Similar to IIP3, we can plot the two components (Figure 6.19), the desired
with a slope of 1, and the 2nd-order term with a slope of 2, where A1 = A2 = A.
The intercept point will be the IIP2 (in volt):
IIP2 = a1
a2

:
Furthermore, similar to IIP3, we can ﬁnd out the IIP2 of the cascade of several stages. Since we
had obtained the second derivative already, we arrive at a similar expression for the cascade of
two stages IIP2:
1
AIIP2,T
=
1
AIIP2,1
+
a1
AIIP2,2
:
As expected, if the gain of the ﬁrst stage is large, the second stage 2nd-order nonlinearity
dominates.
Example: We shall ﬁnd the IIP2 of an LTE (or 4G) receiver. Since in most 4G receivers
the desired signal is usually downconverted to DC, of several different mechanisms, the
most problematic one will be due to the amplitude demodulation of the transmitter
leakage as shown in Figure 6.20.
Continued
20logA
IIP2
a A
a A
Figure 6.19: IIP2 deﬁnition
Receiver
fTX
fRX
a(t)cos(
ct+ (t))
½ a2(t)
0
Desired
Desired
3G Spectrum
w
f
Figure 6.20: IIP2 of a 4G receiver
6.3 Small Signal Nonlinearity
345

Transmitter leakage is amplitude modulated and thus when squared results in a
spectrum that is roughly twice as wide as the receiver signal. Once passed through the
receiver ﬁlter, the integrated energy will be somewhat reduced, depending on the actual
modulation properties of the 4G signal. We denote this attenuation factor generally as α.
It is easy to show that for the second-order nonlinearity we have
IM2 = 2PB  IIP2:
Since the desired signal is at sensitivity, we would like for the IM2 component to be well
below the desired signal less SNR, say 10dB or more. Thus
IM2 =  117  18
ð
Þ  10 + α =  109dBm + α:
The blocker level (PB) is the TX leakage, which came out to be –23dBm for 50dB
duplexer isolation. Thus
IIP2 = 2  23 + 109  α = 66  α:
It turns out that for 3G where is the signal is QPSK modulated, the factor α is about 13dB.
In the case of LTE that the signal is OFDM (orthogonal frequency division multiplexing),
it is about 7dB. The corresponding required IIP2 at the TX frequency then will be 53/
59dBm for 3G/LTE cases.
One may wonder what the exact nature of the correction factor α is. As we pointed out, it
largely depends on the statistical characteristics of the modulated spectrum appearing at the
receiver input.
As a thought experiment, let us consider Figure 6.21, where a band-limited white noise is applied
to a system with 2nd-order nonlinearity. We shall ﬁnd the spectral density of the output y(t) = x(t)2.
Shown in Figure 6.21, the spectrum of the band limited white noise may be broken into
inﬁnitesimal bins of width Δf. In the limit case, each bin may be approximated by an impulse in
the frequency domain. Assuming a bandwidth of B for input noise, there are a total of N bins,
where N  B
Δf. The spectral density of the input then may be expressed as
Sx fð Þ = η
2
X
N
n = 0
nΔf :
( . )2
f
½
+B
–B
x(t)
y(t)
Sx(f)
f
½Bh2
+2B
–2B
nDf
Df
Sy(f)
h
Figure 6.21: Band-limited white noise passing through 2nd-order nonlinearity
346
Distortion

In Chapter 2 we showed that a randomly phase sinusoid,
v tð Þ = A cos ω0t + ϕ
ð
Þ,
has the spectral density of
Sv fð Þ = A2
4 δ f  f 0
ð
Þ + A2
4 δ f + f 0
ð
Þ,
where ϕ is a random variable uniformly distributed between 0 and 2π. Consequently, the band-
limited noise in time domain may be expressed as
x tð Þ = A
X
N
n = 0
cos n2πΔft + ϕn
ð
Þ,
where all ϕn are independent. If N is large (or Δf is small),
η
2 Δf = A2
4 ,
or A =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2ηΔf
p
. The output signal, y(t) = x(t)2, may be constructed accordingly:
y tð Þ = A2
2
X
N
i = 0
X
N
j = 0
cos i + j
ð
Þ2πΔft + ϕi + ϕj


+ cos i  j
ð
Þ2πΔft + ϕi  ϕj



	
:
Since ϕi and ϕj (i 6¼ j) are independent, we can show that ϕi + ϕj and ϕi  ϕj are also
independent. For the limit case Δf ! 0, the output spectral density may be found to be (see
Problem 16)
Sy fð Þ = η
2

 2
2B 1  fj j
2B


,
for |f |  2B, and zero otherwise (Figure 6.21).
The noise energy of the input within the bandwidth of B is clearly ηB. For the same band,
the energy of the squared signal is 3
4 ηB
ð
Þ2. Assuming η = 1
B such that the input energy is
normalized to one, the output energy will be three-fourths, or 1.3dB less.
To arrive at this conclusion, we assumed the phase components of each bin, ϕis, are completely
uncorrelated. For a general modulated signal, however, this is not necessarily the case. Conse-
quently, there will be additional components resulted from cross-correlation of the dependent
terms that alter the ﬁnal outcome. It turns out that for a 3G signal, for example, the squared output
once integrated has about 13dB less energy. If the signal would have been spread uniformly
across twice the bandwidth, we would have expected a factor of 2 loss. For white noise the output
is actually a triangle, and hence α is 1.3dB. For 3G, on the other hand, the squared signal has little
energy around DC (Figure 6.22), which results in a bigger reduction of the output energy.
6.3 Small Signal Nonlinearity
347

Example: Consider a Wi-Fi signal at sensitivity of 2472MHz accompanied by a band
40 LTE blocker located at 2510MHz. The LTE signal is 20MHz wide, and it is assumed
that, once squared, it will have a uniformly distributed power spectral density as shown in
Figure 6.23. This can be veriﬁed by system simulations. We assume the signals are
ultimately downconverted to zero.
Since both the LTE and WLAN signals are 20MHz wide, after the second-order
nonlinearity, the strength of the IM2 component once ﬁltered over the 20M bandwidth
is reduced by 3dB.
Assuming a NF of 3dB for the system with no blocker, and an SNR of 22dB for
64QAM, the Wi-Fi sensitivity is found to be
174 + NF + 10 log 20M
ð
Þ + SNR = 76dBm:
Assuming the LTE blocker level is –20dBm, to induce 3dB desensitization due to the
2nd-order nonlinearity, the IM2 level must be equal to the thermal noise ﬂoor, and is
found to be
IM2 = 174 + NF + 10 log 20M
ð
Þ = 98dBm:
The corresponding system IIP2 is
IIP2 = 2PB  IM2  3 = 55dBm:
The 3dB is subtracted to take into account the spreading of the IM2 component, as shown
in Figure 6.23.
For every dB increase to the blocker level, the system IIP2 must improve by 2dB to allow the
same level of desensitization. A –15dBm blocker demands an IIP2 of 65dBm, for instance.
As an interesting case study, consider the cascade of two ampliﬁers with second-order
nonlinearity as shown in Figure 6.24. We will show that even though the ampliﬁers do not
0
3G Signal
f
+2B
–2B
Sy(f)
0
f
Sy(f)
White Noise
+2B
–2B
+B
–B
+B
–B
Figure 6.22: A comparison between a 3G signal and white noise when squared
fB
f0
( . )2
0
20M
20M
Figure 6.23: A WLAN signal accompanied
by a 20MHz LTE blocker
348
Distortion

have any 3rd-order nonlinearity of their own, the IIP3 of the cascaded block is ﬁnite. Intuitively
this can be explained examining what happen to the system when two interferers at the
frequencies of f1 and f2 are applied to the input as graphically illustrated in the ﬁgure. Due to
the 2nd-order nonlinearity of the ﬁrst stage, an undesired tone at f1  f2 appears at its output.
This tone along with the original two-tone blocker at f1 and f2 once passed through the second
stage create a tone at 2f1  f2, which resembles the one created by the 3rd-order nonlinearity
(Figure 6.11).
Mathematically speaking, we can express the second stage output as
y = b1 a1x + a2x2


+ b2 a1x + a2x2

2,
where x is the ﬁrst stage input. After expanding and regrouping:
y = a1b1x + a2b1 + b2a1
2


x2 + 2a1a2b2x3 + b2a2
2x4:
The ﬁrst term is of course the desired one, showing a linear gain of a1b1. The second term leads
to the cascaded IIP2 as was discussed at the beginning of the section. However, the third term
shows that the overall system exhibits 3rd-order nonlinearity, with the effective IIP3 of
AIIP3,T =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
a1b1
2a1a2b2


s
=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
3
b1
b2
a2


v
u
u
u
t
,
or in dB,
IIP3,T = 3:5  10 log a2
j
j + 1
2 IIP2,2,
where IIP2,2 is the IIP2 of the second stage in dB.
There are two ways that this could be problematic in a system: First is if the ampliﬁers are
wideband enough such that the undesired signal at f1  f2 experiences little attenuation. That is
typically not the case. The second and more dominant cause would be if the low-frequency IM2
signal leaks to the second ampliﬁer through supply or ground or other paths alike. This can
happen even within an ampliﬁer. For instance, consider the cascode ampliﬁer shown in
Figure 6.25.
y = a1x+a2x2
f1
f2
y = b1x+b2x2
f1
f2
f1
f2
2f1–f2
≈
≈
f1–f2
f1–f2
Figure 6.24: Cascade two ampliﬁers with second-order nonlinearity
6.3 Small Signal Nonlinearity
349

The input transistor M1 experiences a relatively strong 2nd-order nonlinearity as is the case
for MOS devices. The IM2 current produced sees little ﬁltering once going to the cascode
transistor M2. If this transistor creates a strong 2nd-order nonlinearity, overall could lead to
worse than expected 3rd-order nonlinearity for the cascode ampliﬁer. This however in practice
may be as problematic, as typically the dominant source of the 3rd-order nonlinearity is the
input transistor itself, which could become an issue in certain cases.
6.3.4
Fifth-Order Intercept Point
Although not as commonly discussed as 2nd- or 3rd-order distortion, 5th-order distortion could
be problematic in certain cases. Shown in Figure 6.26, if there is a two-tone blocker at the
frequencies of f1, and f2, there will be additional sidebands due to the 5th-order terms. Also
shown in gray are the close-by sidebands due to the 3rd-order nonlinearity.
The system is generally characterized as
y = a1x + a2x2 + a3x3 + a4x4 + a5x5,
where higher order nonlinear terms up to ﬁfth have been included. With
x = A1 cos ω1t + A2 cos ω2t,
among many terms, the most notable ones due to the 5th-order nonlinearity are
y =    + 5a5A13A22
8
cos 3ω1  2ω2
ð
Þt + 5a5A14A2
8
cos 4ω1  ω2
ð
Þt
+ 5a5A12A23
8
cos 3ω2  2ω1
ð
Þt + 5a5A1A24
8
cos 4ω2  ω1
ð
Þt +    ,
vi
vo
M1
M2
2nd-Order current 
going to M2
Figure 6.25: A cascode ampliﬁer showing 3rd-order nonlinearity
f2
f1
3f2–2f1
a1A
5/8a5A5
DP5
3f2–2f1
4f2–f1
4f2–f1
2f2–f1
2f2–f1
3/4a3A3
Figure 6.26: A two-tone blocker leading to undesired sidebands
due to the 5th-order nonlinearity
350
Distortion

while the desired tones are a1(A1 cos(ω1t) + A2 cos(ω2t)). For A1 = A2 = A, the 5th-order input
intercept point is
AIIP5 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
8
5
a1
a5


4
s
:
Similar to IIP3, a short-cut method may be applied, in which case
IIP5 = P + ΔP5
4 ,
where P = 20 log (A) is the input in dBV, and IIP5 is now in dBV. ΔP5 is the distance between
the desired and 5th-order terms in dB.
Since often |a5|  |a3|, AIIP3 	 AIIP5, and thus IIP5 not as important. There are exceptions to
this, however. Consider a modulated blocker sitting close to the desired signal as depicted in
Figure 6.27.
Once passed through the nonlinear ampliﬁer, the blocker will experience spectral regrowth,
as shown in Figure 6.27. The root cause of spectral regrowth will be examined more closely
during our TX discussion later in this chapter (Figure 6.48), but simply put, if a modulated
signal has a bandwidth of say Δ, the 3rd-order nonlinearity leads to a bandwidth expansion of
3Δ, or the 5th-order nonlinearity will create 5Δ expansion. From this point of view, the 5th-
order nonlinearity may be more troublesome. While it could be less intense, the wider expan-
sion (up to 5) will create problems that would have not existed otherwise due to the 3rd-order
nonlinearity alone depending on the blocker spacing.
Example: Suppose a Bluetooth signal located at the edge of the ISM band (2.484GHz)
is accompanied by a Band 41 10MHz LTE blocker. Band 41 ranges from 2496MHz to
2690MHz, so the closest the blocker may be is at a center frequency of 2501MHz.
After spectral expansion due to the 3rd-order nonlinearity alone, the blocker edge will
be at 2486MHz (2501M  1.5  10M), not affecting the desired BT signal. On the
other hand, the 5th-order nonlinearity will cause the blocker to leak down to
2476MHz, overlapping the entire desired signal. For either case of 3rd- or 5th-order
nonlinearity however, a 20MHz LTE blocker (sitting at 2506MHz) will be problem-
atic. In this case, one can argue the 3rd-order nonlinearity is perhaps more of an issue
given that |a3| 	 |a5|.
fB
f0
y = a1x+a2x2+…+a5x5
fB
f0
D
DfB
Figure 6.27: A close-by blocker creating
interference to the desired signal due to the 5th-order
nonlinearity
6.3 Small Signal Nonlinearity
351

In addition to wider spectral regrowths, the 5th-order nonlinearity could be still problematic,
considering that it grows much more rapidly (with a slope of 5) as the blocker grows. We
showed earlier that for a blocker power of PB (dBm), the undesired 3rd-order intermod signal is
IM3 = 3PB  2IIP3. One can show that due to the 5th-order nonlinearity, the 5th-order intermod
strength is
IM5 = 5PB  4IIP5:
Even if IIP5 is larger than IIP3 given a smaller 5th-order coefﬁcient, the undesired 5th-order
intermod may be still signiﬁcant, which ultimately is what matters. For a given blocker level,
for the 3rd- and 5th-order IM components to be comparable, that is, to have comparable
contributions from the 3rd- and 5th-order distortion, then
IIP5 = PB + IIP3
2
:
Accordingly, the stronger the blocker is, the higher IIP5 is demanded.
6.3.5
Cross-Modulation
In the previous section it was shown that a ﬁnite IIP3 may affect a nonlinear system if there
happens to be a two-tone blocker with the frequency spacing such that the intermodulation term
falls on the desired signal. One may argue, however, that the likelihood of having two strong
blockers with a certain speciﬁc frequency separation may be low. There is another mechanism
that could affect a 3rd-order nonlinear system even if there is only a single blocker present.
Consider Figure 6.28, where a weak desired signal is accompanied by a single modulated
blocker at an offset frequency of ΔfB away from the signal. The ampliﬁer input may be
expressed as
x = A0 cos ω0t
ð
Þ + aB tð Þ cos ωBt + ϕB tð Þ
ð
Þ,
where aB(t) and ϕB(t) denote the amplitude and frequency modulation of the blocker. For
simplicity, the desired signal is represented as a tone, though it will not affect the general
conclusions drawn later.
y = a1x+a2x2+a3x3
fB
f0
DfB
fB
f0
DfB
Cross-mod 
term
Figure 6.28: A weak desired
signal accompanied by a large
modulated blocker may be
corrupted due to cross-
modulation
352
Distortion

The term due to the 3rd-order nonlinearity, a3(A cos(ω0t) + aB(t) cos(ωBt + ϕB(t)))3, after
expansion, leads to the following unwanted signal that falls right on the desired signal:
3
2 a3A0aB tð Þ2cos ω0t
ð
Þ:
This undesired signal, known as the cross-modulation term, is independent of the blocker
frequency, and has a bandwidth set by aB(t)2, likely about two times the blocker bandwidth. The
term due to the desired signal is
a1A0 cos ω0t
ð
Þ:
Thus, treating the cross-modulation like noise, it sets the signal-to-noise ratio at the output,
which is independent of the desired signal strength,
SNR =
2
3
a1
a3


aB tð Þ2 = AIIP32
2aB tð Þ2 ,
where aB tð Þ2 denotes the blocker amplitude squared mean value. If the blocker is constant
envelop, then cross-modulation leads to a DC term that may not be as important in many
applications. Interestingly, the cross-modulation term raises with the blocker level squared (not
cubed), despite the fact that it is created due to the 3rd-order nonlinearity, again similar to the
2nd-order nonlinearity.
Given that the cross-modulation itself is dependent on the blocker modulation, it is common
to quantify its impact through applying a nearby two-tone blocker as depicted in Figure 6.29.
The exact frequency of the blockers (fB1 and fB2) is not important, and matters only if there is
any prior ﬁltering. Their spacing (Δf in the ﬁgure) must be such that the cross-modulation
components that are Δf away from the desired signal lie in band. That is usually the case for
any arbitrary modulated blocker.
The input to the nonlinear ampliﬁer may be expressed as
x = A0 cos ω0t
ð
Þ + AB1 cos ωB1t
ð
Þ + AB2 cos ωB2t
ð
Þ,
leading to the following nearby components at the output:
3
2 a3A0AB1AB2 cos ω0  Δω
ð
Þt
ð
Þ:
With AB1 = AB2 = AB, the amount of blocker it takes to make the cross-modulation component
(XIM3) equal amplitude to the desired signal (a1A0 cos(ω0t)) is
fB1
f0
fB2
AB
Df
Df
f0+
f0–Df
Df
Figure 6.29: Cross-modulation due to a nearby two-tone blocker
6.3 Small Signal Nonlinearity
353

AB =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
3
a1
a3


s
= 1ﬃﬃﬃ
2
p AIIP3:
So the cross-modulation induced IIP3 is 3dB worse than the standard two-tone IIP3. This is
illustrated in Figure 6.30.
Example: A WLAN signal at 2.412GHz is accompanied by a –20dBm 10MHz LTE
interferer close by. Due to cross-modulation, the blocker creates an undesired cross-
modulation signal with about 20MHz bandwidth falling on the desired WLAN signal,
which is also 20MHz wide. Now the signal-to-noise ratio in dB is
SNR dB
ð
Þ = 6 + 2IIP3  2PB,
where PB is the power of the blocker squared signal. If for simplicity we assume this
power remains to be the same as the original blocker power of –20dBm, then the SNR is
calculated to be 34dB for a system IIP3 of 0dBm. This level is signal independent, but is
well above what is required to successfully demodulate an 802.11g signal (about 22dB).
6.3.6
Impact of Feedback on Linearity
We showed that if a noiseless feedback is incorporated, the ampliﬁer minimum noise ﬁgure is not
going to be affected, although the input impedance changes according to the type of feedback
used. We wish to ﬁnd the impact of the feedback on IIP2 and IIP3 here. From basic analog design,
we expect the feedback to improve linearity, and we shall prove that quantitatively.
Consider the general nonlinear ampliﬁer with an ideal feedback around it as shown in
Figure 6.31. We have
y = a1 x  βy
ð
Þ + a2 x  βy
ð
Þ2 + a3 x  βy
ð
Þ3:
We will not attempt to ﬁnd the closed form solution for y as a function of x; however, we can
exploit the Taylor series expansion to ﬁnd the coefﬁcients.
Upon taking derivatives up to the 3rd order, we will have
y =
a1
1 + a1β x +
a2
1 + a1β
ð
Þ2 x2 + a3 1 + a1β
ð
Þ  2βa22
1 + a1β
ð
Þ5
x3:
20logAB
20log(a1A
a A
)
–3dB+IIP3
B
Figure 6.30: Cross-modulation component as a function of the
blocker power
354
Distortion

The linear gain is reduced by the loop gain: 1 + a1β as expected. More importantly the 2nd- and
3rd-order coefﬁcients are decreased more steeply, leading to a net improvement for both IIP2
and IIP3. We can thus write
IIP2,fb = 1 + a1β
ð
Þ  IIP2,
and if the system is dominantly 3rd-order (that is, ignoring 2βa2
2 term),
IIP3,fb  1 + a1β
ð
Þ
3
2  IIP3:
It is interesting to point out that if the system is only 2nd-order, the presence of 2nd-order
nonlinearity in the feedforward path still leads to a ﬁnite IIP3 (see also Problem 4).
Example: We showed before that the IIP3 of a BJT is constant and equal to 2√2VT. If
degenerated, however (Figure 6.32), we can treat the degeneration as a local series
feedback, where the loop gain is 1 + gmR = 1 + RIC
VT .
Thus the IIP3 of a degenerated BJT is
IIP3 = 2
ﬃﬃﬃ
2
p
VT
1 + RIC
VT

3
2
,
which is not constant anymore, and can be improved by raising the bias current, or in
general the loop gain.
b
S
y = a1x+a2x2+a3x3
+
–
Figure 6.31: Nonlinear ampliﬁer in a feedback loop
VCC
io
R
Figure 6.32: A degenerated BJT
6.3 Small Signal Nonlinearity
355

6.3.7
Dynamic Range
With the lower end of a receiver acceptable input set by sensitivity, and the upper end
determined by linearity, we can specify the dynamic range. A widely accepted ﬁgure of merit
is spurious free dynamic range, deﬁned as follows:
The maximum 2-tone input that a receiver may take is such that the corresponding IM3 falls
at the receiver noise ﬂoor as shown in Figure 6.33.
The receiver noise ﬂoor is 174 + NF + 10 log BW, and the IM3 as a result of a 2-tone
blocker with a power of Pmax is IM3 = 3Pmax  2IIP3. This results in
Pmax = 2IIP3 + Noise floor
3
= 2IIP3 +  174 + NF + 10 log BW
3
:
With the lower limit being the sensitivity itself, the spurious free dynamic range (SFDR)
is then4
SFDR = Pmax  Sensitivity = 2 IIP3  Noise floor
ð
Þ
3
 SNR:
For our example of the GSM receiver, a noise ﬁgure of 3dB leads to a noise ﬂoor of –118dBm
at the receiver input. We found the required IIP3 to be –19dBm, leading to a SFDR of 61dB for
5dB SNR.
As we will show, this deﬁnition however does not capture all the various scenarios that the
blockers may affect the receiver. In many applications, the upper end of the acceptable blocker
may very well be worse than what is determined due to the 3rd-order nonlinearity alone.
6.4
LARGE SIGNAL NONLINEARITY
..............................................................................................
We earlier showed that the response of a nonlinear system to a given input with an amplitude
of A is
y =
a1A + 3a3A3
4


cos ωt +    ,
where only the fundamental component is shown as the other harmonics are subject to ﬁltering.
The fact that most practical ampliﬁers are compressive implies that a3 must be negative.
IM3
Noise Floor
Pmax
Figure 6.33: Spurious free dynamic range illustration
4 In some books the SNR does not appear in the equation, and sensitivity is simply deﬁned as the noise ﬂoor. This potentially
leads to a more generic deﬁnition, as SNR is a standard dependent parameter.
356
Distortion

Consequently, as the input increases, we expect the gain to reduce and eventually compress [5]
(Figure 6.34).
To describe the compression quantitatively, we deﬁne the input 1dB compression point
corresponding to the input level that causes the linear gain to drop by 1dB. Since 1dB reduction
means 0.89 times less, we have
0:89a1A = a1A + 3a3A3
4
,
which yields
A1dB =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  0:89
p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
a1
a3


s
= 0:33
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
a1
a3


s
:
If the IIP3 and 1dB compression are caused by the same type of nonlinearity, then the equation
above indicates that 1dB compression point in dB is 20log0.33 = –9.6dB smaller than IIP3 in
dB. This, however, is not always true as the compression and IIP3 could be caused by different
mechanisms.
Example: Consider a long channel MOS common-source ampliﬁer as shown in
Figure 6.35.
Assuming the device is square-law and is biased at a DC gate-source voltage of VGS0,
the output voltage will be
Vo =
VDD  1
2 RLβ VGS0  VTH
ð
Þ2


 RLβ VGS0  VTH
ð
ÞvIN  1
2 RLβvIN
2,
Continued
y
x
1dB
1dB Compression
Figure 6.34: Receiver gain compression
VDD
RL
Figure 6.35: A long channel MOS CS ampliﬁer
6.4 Large Signal Nonlinearity
357

where β = μCOX W
L. The IIP2 is
IIP2 = 4 VGS0  VTH
ð
Þ = 4Veff ,
and clearly the IIP3 is inﬁnite. On the other hand, the device will turn off if the input
swing exceeds VGS0  VTH = Veff, which will yield a ﬁnite 1dB compression.
The compression is typically not a concern in response to the desired signal only, as proper
gain control may be incorporated to adjust the receiver gain as the signal increases. The issue
will be when small desired signal is accompanied by a large blocker. As shown in Figure 6.36,
the large blocker drives the ampliﬁer into compression, and thus effectively reduces the gain (or
slope of the curve), despite the fact that the small signal is residing in the linear region. If the
ampliﬁer is expected to provide gain to suppress the noise of the following stages, this effective
reduction of gain results in noise ﬁgure degradation. As a result, the sensitivity suffers, and the
receiver is said to be desensitized.
To quantify this, we can expand the y–x nonlinear function in response to the signal and
blocker, where x = AD cos ωDt + AB cos ωBt. Assuming the signal level is much smaller than
blocker, AD  AB, and taking only the components at the desired signal frequency, as all the
other terms are subject the ﬁltering, we have
y = a1AD cos ωDt + 3a3AD cos ωDt AB cos ωBt
ð
Þ2 +    
a1 + 3a3
2 AB
2


AD cos ωDt:
Thus we have
Desensitized gain
Linear gain
= 1 + 3a3
2a1
AB
2:
Since a3 is negative, as the blocker increases the gain is expected to reduce.
All the blocker scenarios we have discussed could potentially lead to receiver compression,
but we will discuss a few more common cases here:
– The 3MHz blocker in GSM (Figure 6.4) could cause gain compression as it is subject to
little front-end ﬁltering. For low bands the blocker is speciﬁed to be –23dBm, 3dB stronger than
high band cases. In traditional voltage-mode low-noise ampliﬁers, this could lead to substantial
AB
AD
Less slope
AB
Figure 6.36: A small desired signal
accompanied by a large blocker passing
through a compressive ampliﬁer
358
Distortion

compression at the LNA output. We will show in Chapter 8 how reciprocity of a passive mixer
could be exploited to ameliorate this issue. Since the signal is speciﬁed to be 3dB above the
reference sensitivity, one may suggest to take advantage of some front-end gain reduction to
improve the compression point. This, however, is not a viable solution for the following reason:
To boost the receiver throughput as the desired signal increases, more complex modulation
schemes are exploited that require higher SNR. For instance, for the EDGE (enhanced data rates
for GSM evolution) MCS9 (modulation and coding schemes) case, most advanced receivers are
required to achieve a sensitivity of about –95dBm, which coincides with a –99dBm blocker case.
The receiver has no knowledge of which type of signal is being received a priori, and thus any
noise degradation as a result of gain control is not desired.
– The 0dBm out-of-band blocker, which is as close as 20/80MHz for low/high band cases, could
cause signiﬁcant compression. Since the blocker is out-of-band, however, a front-end ﬁlter may
be used. If the ﬁlter provides an attenuation of 23dB or more, these blockers will not cause any
bigger threat than the in-band 3MHz ones. Accordingly, the receiver is expected to function
properly, as it is already designed to handle the –23dBm blockers. Most practical SAW ﬁlters
provide more attenuation. Recently, to reduce cost, several topologies have been proposed that
allow the removal or relaxation of the front-end ﬁltering, leading to a more challenging
linearity requirement. We will discuss those architectures in Chapter 12.
– The transmitter leakage in 3G or LTE receivers is about –23dBm for a 50dB duplexer
isolation similar to GSM 3MHz blocker. Although the TX signal is further away (anywhere
from 35MHz to 400MHz depending on what band of 3G or LTE is used), the received signal
is at sensitivity and any level of noise degradation is not acceptable.
– The GSM 400kHz adjacent blocker (Figure 6.5) speciﬁed at –41dBm is not strong enough to
compress the receiver front-end. However, since it is very close to the desired signal, it may
potentially create issues for later stages of the receivers (for instance, channel-select ﬁlter or
the ADC) as it is subject to very little ﬁltering. For the reasons mentioned before, even
though the desired signal is at –82dBm, receiver noise ﬁgure degradation is generally not
desirable, limiting the gain control only to the later stages of the receiver.
We will revisit some of these cases more closely when we discuss the receiver architectures in
Chapter 12.
6.5
RECIPROCAL MIXING
..............................................................................................
In Chapter 5 we discussed that the LO signal used to shift the frequency of the incoming RF
signal is noisy, and may be generally expressed as
xLO tð Þ = AC cos 2πf Ct + ϕn tð Þ
ð
Þ,
where the term ϕn(t) represents the noise caused by the active circuitry in the oscillator, known
as phase noise. We also showed that using the narrowband FM approximation [6], the actual
LO signal consists of an impulse representing the ideal cosine, as well as a term representing
noise in quadrature, shaped around the carrier as shown in Figure 6.37.
6.5 Reciprocal Mixing
359

Thus the mixer output, while translated in frequency, contains the phase noise convolved in
the frequency domain with the input. We shall show that in an otherwise ideal receiver, the LO
phase noise limits the receiver sensitivity when exposed to blockers.
Consider Figure 6.38, where a small desired signal accompanied by a large blocker appear at
the input of an ideal mixer, driven by a noisy LO. At any given frequency offset Δf from the
carrier, the phase noise is typically expressed in dBc/Hz, with the noise integrated over a 1Hz
bandwidth at that offset, normalized to the carrier amplitude (Figure 6.38). For instance, if the
oscillator has an RMS amplitude of 1V, and the measured spot phase noise at a certain offset is
100nV√/Hz, then the phase noise is –140dBc/Hz.
As shown in Figure 6.38, when the noisy LO is convolved with the blocker, it results in the
skirt of the noise on the left sideband appearing on top of the desired signal. Note that although
not shown, the desired signal also convolves with the LO, but since its magnitude is small, the
resultant noise is negligible. If the phase noise of the LO at the offset frequency of ΔfB, that is,
the frequency where the blocker and desired signal are separated, is PN, then the total noise (in
dBm) integrated over the signal bandwidth is
PB + PN + 10 log BW,
where PB is the blocker power in dBm. Note that the phase noise is measured relative to the
carrier, and thus the noise itself is normalized by the blocker power. Furthermore, the multiplier
(or mixer) amplitude (AC) is inconsequential, as phase noise is normalized to carrier power, and
both signal and noise are scaled by the same carrier amplitude at the multiplier output. Also we
RF Input
Downconverted 
Output
LO
xLO(t)=Accos(2 fCt+
n(t))
XLO(f)
f
fC
Phase Noise
p
f
Figure 6.37: Downconversion mixer driven by a noisy LO
AB
AD
XLO(f)
f
fC
PN (dBc/Hz)
Δf
BW
SNR
ΔfB
Figure 6.38: Reciprocal mixing in a receiver
360
Distortion

made the approximation that the noise is relatively ﬂat over the signal bandwidth. The desired
signal can be successfully detected if this noise is an SNR below. Thus
Sensitivity = PB + PN + 10 log BW + SNR,
indicating that an otherwise ideal receiver sensitivity is set by the phase noise of the LO signal
in the presence of large blockers. This phenomenon is often known as reciprocal mixing, and
sets the requirements of the LO phase noise depending on the blocker proﬁle for a certain
standard.
Example: Consider the blocker proﬁle shown in Figure 6.4 corresponding to GSM
standard. Suppose an SNR of 10dB is required to achieve sufﬁcient margin. Since the
desired signal is at –99dBm, that is the sensitivity, and that the GSM bandwidth is
200kHz, a 600kHz blocker at –43dBm requires a phase noise of no higher than –99 –
(–43) – 10log(200kHz) – 10 = –119dBc/Hz at 600kHz offset. For the 3MHz blocker on
the other hand, as it is 17dB stronger, we expect a phase noise of –136dBm for the LO to
achieve the same SNR of 10dB. Assuming the phase noise drops with a slope of 1/f2 away
from the carrier, achieving –136dBm/Hz phase noise at 3MHz, will automatically result
in a phase noise of –136 + 20log(3MHz/600kHz) = –122dBm/Hz at 600kHz. Thus
meeting the 3MHz phase noise is sufﬁcient to pass the 600kHz blocker case. Considering
all other blockers, it turns out that the 3MHz is the most stringent one.
The blocker proﬁle shown in Figure 6.4 typically leads to a phase noise proﬁle shown in
Figure 6.39. Only one side is shown, but since the blockers could be present at either side, the
required phase noise proﬁle is symmetric around the carrier.
For a given phase noise speciﬁed at a certain offset, and for a given blocker, we can calculate
the receiver noise ﬁgure as a result of reciprocal mixing: the spot noise for a blocker power of
PB and a phase noise of PN is PB + PN in dBm/Hz. Since the available noise power is KT
or –174dBm/Hz, by deﬁnition, the noise ﬁgure is the ratio of the two, resulting in subtraction of
the two terms in dB,
NFB = 174 + PB + PN,
X LO (f)
f
fC
∆f
… 
1/f
2
Required PN
… 
Figure 6.39: Required LO phase noise according to the
blocker proﬁle
6.5 Reciprocal Mixing
361

where NFB expressed in dB signiﬁes the blocker induced noise ﬁgure, or in short, the blocker
noise ﬁgure.
Example: Consider the LTE receiver designed in Chapter 5 to achieve a GSM sensitivity
of –110dBm as shown in Figure 6.40. We calculated a noise ﬁgure of 3dB at the receiver
input, and 6dB at the antenna assuming 3dB loss due to the ﬁlter and switch. Now suppose
this receiver is subject to a –26dBm 3MHz blocker at the antenna. At the receiver input, the
blocker is 3dB weaker, and given a phase noise of –136dBm/Hz for the LO, the receiver
blocker noise ﬁgure is 174 + –29 + –136 = 9dB. Once the 3dB thermal noise of the receiver
is added, the total noise ﬁgure becomes 10dB at the receiver input, or 13 at the antenna.
The minimum detectable signal, given a minimum SNR of 5dB needed, will be then
about –103dBm, leaving us 4dB of margin. This calculation is, however, somewhat
optimistic, as the receiver gain compression may cause worse than 3dB noise ﬁgure,
and a composite noise ﬁgure of higher than 13dB.
Note that the front-end passive loss to the 1st-order does not affect the reciprocal
mixing induced noise ﬁgure.
Example: Consider a Wi-Fi receiver with 3dB base noise ﬁgure and a far-out phase
noise of –155dBc/Hz. Let us ﬁrst ﬁnd the receiver total noise ﬁgure in the presence of
a –20dBm blocker. The receiver thermal noise ﬂoor is –171dBm, whereas the noise
ﬂoor due to the blocker reciprocal mixing is
155dB=Hz  20dBm = 175dBm=Hz:
When the two added up, the total noise ﬂoor is –169.5dBm/Hz, leading to a noise ﬁgure of
4.5dB. Now suppose the receiver is preceded by an ampliﬁer with a gain of 10dB and noise
ﬁgure of 2dB. When referred to the ampliﬁer input, the new noise ﬂoor due to the blocker
is –165dBm/Hz as the blocker is 10dB stronger, and the total receiver noise ﬁgure becomes
9.8dB. Once referred to the ampliﬁer input, the noise factor according to Friis formula is
4G Receiver
4G Modem
Switch
SNR
Mulple Bands
Figure 6.40: A 4G receiver
362
Distortion

1:58 + 9:55  1
10
= 2:44,
or 3.86dB. Without the blocker, the cascaded noise ﬁgure would have been
10 log
1:58 + 2  1
10


= 2:25dB:
So the amount of desensitization due to the blocker in either case is about the same
(~1.5dB).
6.6
HARMONIC MIXING
..............................................................................................
Consider the receiver shown in Figure 6.41, where the low-noise ampliﬁer is assumed to have
kth-order nonlinearity as denoted by IIPk [7].
The mixer is driven by an LO signal at a frequency of fLO. As we will show in Chapter 8,
most practical mixers are designed based on the hard switching concept. Hence, effectively, the
LO signal driving them is assumed to be a square-wave, consisting of all odd harmonics as
shown in Figure 6.41. As a result, we expect for instance a blocker located at exactly 3fLO to be
also downconverted, falling on top of the desired signal, but only 20log(1/3)  –10dB weaker.
Suppose the LO is on the low-side of the desired signal, that is, the desired signal is located at
fLO + fIF, where fIF signiﬁes the intermediate frequency. This is known as low-side injection.
When the LO is at the high side of the desired signal, it is called high-side injection.
Any blocker at the frequency of (nfLO  fIF)/k results in an unwanted signal at the LNA
output at nfLO  fIF due to its kth-order nonlinearity. This signal is subsequently mixed with any
of the LO harmonics at nfLO (n is a positive integer), appearing on the top of the desired signal
after downconversion. If the mixer is differential, n is expected to be odd, like the example
shown. In practice, however, due to the mismatches the even harmonics of the LO may also be
IIPk
fLO
3fLO
5fLO
… 
Hard Switching
⅓ 
⅕ 
fLO+fIF
(nf LO± fIF)/k
Figure 6.41: Impact of harmonic mixing in receivers
6.6 Harmonic Mixing
363

responsible for the undesirable harmonic downconversion. The situation may be alleviated in
one of the following ways:
– The blocker may be attenuated by an RF ﬁlter placed before the LNA. The ﬁlter attenuation
depends on the IF, as well as different combination of values of n and k.
– The LNA linearity may be improved.
– The LO harmonics may be suppressed by manipulating the mixer. This will be discussed in
Chapter 8.
Let us consider a few common special cases.
1. n = k = 1. For a low-side injection, this blocker is located an IF below the LO (or two IF
below signal), commonly known as the image blocker. Since the LNA is perfectly linear in
this case, the image blocker can be attenuated only by ﬁltering. However, if IF is small
enough, as we will show in Chapter 12, a quadrature receiver may be exploited to remove
the image.
2. n = k = 2. Known as the half-IF blocker as is located at: fLO  ½fIF, the blocker is
problematic due to the LNA 2nd-order nonlinearity as well as the LO second harmonic.
A fully differential design is then expected to help. Compared to image case, on one hand
the blocker is caused due to the 2nd-order effects, and thus may not be as troubling. On the
other hand, it is only half-IF away from the desired signal, as opposed to twice the IF in the
case of image. Thus the half-IF blocker is subject to less ﬁltering. The image and half-IF
blockers scenarios are illustrated in Figure 6.42.
3. Harmonic blockers located at nfLO are downconverted despite the fact that a linear LNA is
used (k = 1), unless a harmonic rejection mixer [8] is used (Chapter 8).
Aside from harmonic blockers that may be attenuated only by ﬁltering, or through using
harmonic rejection mixers, the majority of other blockers largely depend on the choice of IF. As
we will discuss in Chapter 12, the choice of receiver architecture to a large extent relies on the
proper choice of IF, and the issues associated therewith.
6.7
TRANSMITTER NONLINEARITY CONCERNS
..............................................................................................
The majority of Chapter 5 and most of this chapter so far have been dedicated to the receivers.
The transmitters suffer from very similar issues whose principle was introduced. In fact, we
fLO+fIF
fLO–fIF
fLO
fLO+fIF
fLO–fIF/2
fLO
fLO–fIF/2
Image Blocker
Half-IF Blockers
Figure 6.42: Image and half-IF blockers
364
Distortion

could loosely consider transmitters as the dual of the receivers, both from the architecture point
of view as well as issues related to noise and distortion.
We categorize the transmitter requirements into three groups, output power, modulation
mask, and signal quality, and discuss each in this section.
6.7.1
Output Power
The transmitter output power along with the receiver sensitivity deﬁne the range of coverage. In
mobile applications, as a longer range is required, the transmitter output power needs to be
higher. In GSM for example, the low bands must put out 33dBm at the antenna (that is, 2W),
while for high bands the required output power is 30dBm. LTE, on the other hand, requires less
output power of about 23dBm for most of the bands as it supports a wider bandwidth and
requires a more stringent linearity.
For LAN (local area network) applications where a higher throughput is supported, the
output power is lower, generally in the range of the high teens. Furthermore, the receiver
sensitivity is worse, given the wider bandwidth, and higher SNR. In general, we can say that the
range of coverage is always traded for throughput.
The physical limit to raising the transmitter output power arises from a number of issues:
– High power transmitter imposes itself as a strong interferer to the other receivers.
– Higher throughput requires a higher ﬁdelity in the TX, or better SNR. Achieving a higher
SNR typically requires a more linear power ampliﬁer, as we will discuss next. In Chapter 11
we will show that linear power ampliﬁers tend to be less efﬁcient, and ultimately more power
consuming. Given the battery size and cost concerns, high-SNR applications such as WLAN
tend to support less output power. A GSM power ampliﬁer, on the other hand, is consider-
ably more efﬁcient as GSM uses constant envelope modulation.
6.7.2
Transmitter Mask
The transmitter mask is generally deﬁned to limit the amount of interference that a TX can
potentially cause for the nearby receivers. So transmitter mask requirements can be viewed as
dual of the receiver blocker requirements. The TX mask is limited by either the LO phase noise
or the transmitter chain nonlinearity. We discuss each case here.
In Chapter 5 we showed that if the oscillator is embedded within a phase-locked loop (PLL),
the phase noise proﬁle will change according to the PLL characteristics, and often looks like
what is shown in Figure 6.43.5 It consists of a relatively ﬂat passband set by the PLL, along
with a region of 20dB/Dec (or 1/f 2) slope set by the VCO characteristics. At very far-out
frequency offsets from the carrier, the noise ﬂattens as the buffers or other hard-limiting devices
following the oscillator dominate.
When multiplied by the TX baseband signal, this noise proﬁle appears directly at the
transmitter output as shown in Figure 6.44. In practice, any other part of the transmitter chain
5 We shall analytically prove this in Chapters 9 and 10, but will accept it for the moment.
6.7 Transmitter Nonlinearity Concerns
365

may contribute to this noise as well, although unless for far-out frequencies, the LO phase noise
is dominant.
Example: Let us consider GSM transmitter modulation mask requirements as shown in
Figure 6.45.
Since GSM uses GMSK modulation, which is constant envelope, the transmitter chain
linearity is not a major concern, and mask is typically limited by the phase noise. We will
show in Chapter 12 that this is not always true, especially if a Cartesian transmitter is
chosen. Ignoring the linearity impact for the moment, a key requirement is a 400kHz
mask that is speciﬁed to be 60dBc below the carrier measured in a 30kHz resolution
bandwidth. Suppose we would like to have a 3dB production margin, and leave another
Offset from carrier
PLL Noise
PLL
VCO
BUF
PLL
Typical PLL Phase Noise Proﬁle
Typical RX/TX Chain
Figure 6.43: Typical PLL
phase noise in a typical
RX or TX chain
BUF
+ TX
Offset from carrier
PLL
VCO
fC
TX Modulated 
Spectrum
TX Mask
Figure 6.44: Transmitter mask limited by the LO phase noise
100kHz/
10dB/
Figure 6.45: GSM modulation mask requirements
366
Distortion

2dB for process and temperature variations, giving us a typical requirement of –65dBc. If
the phase noise at 400kHz offset is PN, then the relative noise in dBc is
PN + 10 log 30kHz + 10 log 200kHz
30kHz :
The last term arises due to the fact that the GSM signal is roughly 200kHz wide, and as
the measurement is performed in a 30kHz bandwidth, the signal energy is subject to some
ﬁltering that must be adjusted. Accordingly, the required 400kHz phase noise is
PN = 65  10 log 30kHz  10 log 200kHz
30kHz = 118dBc=Hz:
Recall that for the GSM receiver, the 3MHz offset was the most critical requirement (–136dBc/Hz).
Assuming a 20dB/Dec roll-off, the equivalent 400kHz receiver phase noise would have been –
118.5dBc/Hz, coincidentally almost identical to the TX requirement.
The 200kHz and 250kHz mask requirements of –30dBc and –33dBc, respectively, are
generally limited only by the modulator and the ﬁltering incorporated, and the phase noise
does not play a major role. Also similar to the case of RX blockers, with a 20dB/Dec roll-off
assumed for the phase noise, meeting the 400kHz mask typically automatically guarantees the
other far-out frequencies.
There is yet another very stringent noise requirement for the GSM transmitter explained as
follows: the EGSM transmitter for instance occupies a band of 880–915MHz, whereas the
receiver takes 935–960MHz. Suppose a given handset is transmitting +33dBm at the upper
edge of the band, and a nearby handset is receiving at the lower edge as shown in Figure 6.46.
For this transmitter not to impose a problem for the nearby receiver, the noise at 20MHz
away (that is the worst case spacing between the two) is speciﬁed to be –79dBm or better when
measured at a 100kHz bandwidth. The rationale behind –79dBm number has to do with the fact
that if the isolation between the two handsets is say 30dB or better, the noise created by the TX
will be low enough not to affect the –102dBm sensitivity of the receiver. An isolation of worse
than 30dB requires the two handsets to be very close, within perhaps a few centimeters. The
noise is then equal to
880
915
935
960
+33dBm
–79dBm
Freq, MHz
EGSM TX
20MHz
EGSM RX
≈ 
≈ 
Figure 6.46: GSM 20MHz noise requirement
6.7 Transmitter Nonlinearity Concerns
367

79  10 log 100kHz  (+33dBm) =  162dBc/Hz
Typical power ampliﬁers have a noise ﬂoor of about –83 to –84dBm, and to have enough
margin, the radio must achieve an out-of-band (OOB) noise level of –165dBc/Hz or better.
Since this noise level is very low, not only the VCO and LO contribute, but also any other
component of the transmitter chain could potentially be a problem. This greatly affects the
choice of the GSM transmitter architecture, as we will discuss in Chapter 12.
A very similar noise requirement exists in 3G and LTE transmitters due to their full duplex
nature, where the 3G transmitter itself is the source of the noise, as opposed to the nearby
handset in the case of GSM (Figure 6.47). This could also exist in platforms (such as mobile
handsets) where several radios of different standards exist.
The noise requirement may be calculated similarly, and is illustrated as an example below:
Example: Assuming we would like to have less than say 0.5dB degradation is the LTE
receiver noise, we would want the TX induced noise to be –182dBm/Hz or less. Note that
a 3dB noise ﬁgure of receiver leads to an input-referred noise ﬂoor of –171dBm/Hz. Thus
the TX noise in dBc/Hz at the receiver frequency is
182dBm=Hz  + 27dBm  50
ð
Þ = 159dBc=Hz,
where a duplexer isolation of 50dB is assumed. The PA output power is 27dBm.
Note that in the case of 3G or LTE, the TX noise is not caused by an infrequent event of
having two handsets too close, and thus is somewhat more critical. On the other hand, the lower
output power compared to GSM is a helpful factor here.
The transmitter nonlinearity and spectral regrowth could be another source of mask viola-
tion. This is intuitively explained as shown in Figure 6.48.
For a given modulated signal, let us break it into several tones occupying the band of interest,
say 1.9MHz for the case of 3G. Every pair of two arbitrary tones then create IM3, IM5, . . .
components caused by the transmitter 3rd-, 5th-, . . . order nonlinearity. Since the frequency of
Receiver
fTX
fRX
Transmier
RX Desired
TX Leakage
Figure 6.47: A 3G or LTE transmitter noise
requirement
368
Distortion

the IM3 components is two times frequency of one component subtracted from the other, the
3rd-order nonlinearity-induced spectrum is as wide as three times the signal bandwidth, while
the 5th-order nonlinearity extends the spectrum to a ﬁve times larger bandwidth. Overall the TX
signal will look something like the one shown on the bottom of Figure 6.48.
For 3G (or LTE) it is common to specify adjacent channel leakage ratio (ACLR) measured
at 1.9MHz bandwidth at 5 or 10MHz away. Translating the required ACLR to a given IP3 or
IM3 requirement is a function of the modulation and its statistical properties, and there is no
closed equation.
Example: The ACLR of a 3G transmitter at 5MHz away versus IM3 is shown in
Figure 6.49, obtained from system-level simulations.
The standard requires an ACLR of better than –33dBc at 5MHz away. Assuming the
power ampliﬁer ACLR is –37dBc, with some margin included, a typical ACLR of
–40dBc may be considered for the radio.
Continued
… 
… 
fC
3rd
5th
fC
TX Mask
Figure 6.48: Transmitter nonlinearity leading to spectral
regrowth, and potentially mask violation
Figure 6.49: An example of 3G transmitter
linearity requirement
6.7 Transmitter Nonlinearity Concerns
369

This then translates to an IM3 of better than –31dBc for the TX deduced from Figure 6.49
plot. For a 2-tone measurement at the transmitter output with each tone at 0dBm (corres-
ponding to a total power of +3dBm), the output IP3 (OIP3) is then 15.5dBm (Figure 6.50).
This leads to an output compression point of about 15.5 – 9.6 = 5.9dBm. Thus to ensure
the ACLR is met, the transmitter output peak power is roughly 3dB below the compression.
In the case of 3G signal, which is QPSK modulated, the transmitter average power is known to
be about 3dB less than the peak power. This is often known as peak-to-average ratio (PAPR), and
is a function of the type of modulation used. Typically, the more complex modulation schemes
correspond to a larger PAPR. To ensure that the modulation mask is met, as a rule of thumb, the
transmitter output power must be backed off from the compression point by a value that is
comparable with PAPR. Therefore, a more complex modulation scheme that provides higher
throughput for the same bandwidth comes at the expense of a larger back-off. Consequently, a
worse efﬁciency is expected, as was pointed out. Note for a pure sinusoidal signal, the peak is
exactly 3dB higher than average (or the RMS value), coincidentally very similar to that of 3G.
Example: Shown in Figure 6.51 are the baseband IQ signals corresponding to LTE
20MHz, as well as 3G voice in time domain. The sample rate is 61.44MHz, and the plots
shown contain 100 samples. The LTE signal that supports a higher throughput clearly
contains more ﬂuctuations more frequently.
Statistically speaking, the portability of peak versus the average power is shown in Table 6.1.
For instance, there is a 1% probability that the 3G signal peaks as high as 2.6dB above the
average, while for the same probability the LTE signal may peak as much as 5dB.
–31dBc
+3dBm
0dBm
Figure 6.50: 3G transmitter OIP3 calculations
–2
–1.5
–1
–0.5
0
0.5
1
1.5
2
I/Q Amplitude, V
Time
Time
LTE 20MHz
3G Voice
–2
–1.5
–1
–0.5
0
0.5
1
1.5
2
Figure 6.51: Examples of 3G voice and LTE PAPR
370
Distortion

Leaving a margin of 2dB for power control, the total back-off for the LTE is about 8.4dB (for
less than 0.1%), which is considerably higher for what is needed for a 3G voice signal. This
demand for better linearity directly translates to a worse efﬁciency.
Finally, same as the receivers, we can deﬁne the OIP3 of the chain as sum of each individual
block as shown below:
1
AOIP3,T2 =
1
AOIP3,12 +
a12
AOIP3,22 +    :
To maintain the relative noise ﬂoor and other potential unwanted signals low, typically
transmitter signal is large from the very beginning of the chain. For that reason, almost all
blocks have a gain of close to unity at maximum output power, and they may all contribute to
the nonlinearity.
Example: Suppose we have a WLAN transmitter at 20dBm average output power. This
signal leaks to a nearby LTE receiver with 3dB noise ﬁgure (Figure 6.8). Assuming 40dB
of isolation between the WLAN TX and LTE RX, we shall ﬁnd the transmitter out-of-
band noise such that the LTE receiver is desensitized by no more than 1dB.
Since the receiver has a noise ﬁgure of 3dB, its input referred noise is –171dBm/Hz. To
desensitize by no more than 1dB, the TX noise leaking to the receiver should be about
6dBless, that is, –177dBm/Hz. So at the TX output it translates to –137dBm/Hz consider-
ing 40dB of isolation. Thus, the noise required will be –137 – 20 = –157dBc/Hz. Note
that the PAPR of the TX signal signiﬁes the amount of back-off from the peak transmitter
output, leading to a more stringent dynamic range for TX.
6.7.3
Transmitter Signal Quality
The transmitter signal must maintain a high enough signal-to-noise ratio to ensure that once
received at the other end, the signal quality is acceptable. This is typically characterized by
EVM (error vector magnitude) or phase error, and is directly related to the SNR. At the receiver
end, as the signal is typically weak, the SNR is usually limited by the receiver thermal noise, or
Table 6.1: 3G and LTE peak probability
Probability
3G Voice
LTE 20MHz
10%
1.7dB
2.8dB
1%
2.6dB
5dB
0.1%
3.2dB
6.4dB
0.01%
3.4dB
7.4dB
6.7 Transmitter Nonlinearity Concerns
371

the aforementioned blocker induced interference. However, as the receiver signal increases, and
in the absence of the blocker, the SNR of the receiver is also expected to improve to guarantee a
high throughput.
The EVM, measured in percent or dBc, is limited by any one of the three following
mechanisms:
The LO in-band phase noise ─As shown in Figure 6.44, the transmitter signal once
upconverted sits directly on top of the in-band noise of the PLL. This noise when integrated
over the band of interest leads to a certain phase error that sets the lower limit of SNR or EVM.
A good example is GSM, which uses constant envelope, so the signal is usually not affected by
other mechanisms. The GSM speciﬁes a phase error of better than 5º, whereas most typical
radios target for 1–2º to leave room for process or temperature variations and production related
variations. Consider Figure 6.52, which shows the in-band phase noise of a GSM transmitter as
an example. Let us assume that the noise is ﬂat over the 100kHz band of interest.
The integrated noise over GSM band is –89dBc + 10log200kHz = –36dBc. Since –36dBc is
0.0158 radians or 0.9º, the phase error is 0.9º. For applications where a high throughput is
supported such as LTE or WLAN family, the in-band noise requirement is more stringent, and
usually an integrated phase noise of a few tenths of a degree is targeted.
TX chain unwanted interferers ─Consider the simpliﬁed single-sideband modulator shown
in Figure 6.53.
Suppose for the moment only a single tone at the upper sideband (+fm) is being transmitted.
If the 90º phase shift has some error, or the quadrature signals produced at the baseband are not
perfectly 90º out of phase, a residual unwanted sideband (or image, same as the receiver) will
appear at –fm. Moreover, the carrier may directly feed through and appear as an unwanted tone
–89dBc
100kHz
Phase Noise
f
fC
Figure 6.52: GSM transmitter in-band phase noise
xC(t)
+
–
Ac/2
–90º  
I
Q
fC
fm
fm
Wanted Sideband
Unwanted Sideband
Feedthrough
coswCt
Σ
Figure 6.53: A single-sideband modulator
372
Distortion

at fC. Once a modulated signal is applied, the image components and the feed-through set a ﬂoor
that limits the SNR (Figure 6.54).
Once the impact of the in-band phase noise is also included, the EVM will be approximately
EVM 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
10IQ + 10LOFT + 10PN
p
,
where IQ is the TX image suppression, LOFT is the LO feed-through, and PN is the in-band
phase, all expressed in dB.
Note the above equation is not generally true in all modulation schemes; it only gives us an
idea of how to deal with various contributors. The ﬁrst term shows the contribution of the
quadrature imbalance, the second term is the feed-through, and the last term is the phase noise.
For 1% quadrature inaccuracy, –40dBc feed-through (also 1%), and an in-band noise of
–40dBc, the EVM will be
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 + 1 + 1
p
= 1:7%. Most practical transmitters achieve a typical
EVM of better than 3–5%.
Nonlinearities ─This is very similar to the case of spectral regrowth as was demonstrated in
Figure 6.48. As the IM3 components will also appear within the band of interest, they set a noise
ﬂoor that ultimately limits the SNR. However, for many applications, this not a dominant factor.
For instance, in our example of 3G transmitter, an IM3 of better than –31dBc was required to
guarantee a –40dB ACLR. This results in a negligible degradation of the EVM. We shall have a
more detailed discussion on the impact of nonlinearity on EVM and constellation shortly in
Section 6.7.5. On the other hand, in an 802.11ac WLAN application for a 1024QAM signal,
given the very stringent signal ﬁdelity needed, the transmitter nonlinearity could be a factor.
Similar mechanisms limit the receiver SNR when the signal is strong enough. The receiver
EVM requirement is usually very similar to that of the TX, except for it is meaningful only
when the desired signal is strong enough so as not limited by the blockers or receiver thermal
noise. In the case of the TX, the signal is always strong, at least for maximum output power.
6.7.4
Switching Spectrum and Time-Domain Mask
In addition to the modulation mask and frequency domain speciﬁcations described before, there
is yet another requirement for the TDMA (time division multiple access) systems, where
different users are assigned different time slots. In contrast to TDMA, in FDMA systems users
are assigned different frequencies. The examples of the latter are FM radio and satellite TV,
where each station transmits at a ﬁxed known frequency. GSM and EDGE radios are on the
other hand examples of TDMA-based systems. Consequently, a TDMA signal often consists
of frames, with each frame composed of several time slots. Shown in Figure 6.55, is a
fC
… 
… 
SNR
Figure 6.54: EVM limited by quadrature mismatches and LO feed-through
6.7 Transmitter Nonlinearity Concerns
373

GSM/EDGE frame for instance, where each time slot is about 577μS long, and one frame
consists of eight time slots.
In consequence, it is expected for the transmitter to produce an output signal that smoothly
ramps up and down to avoid sharp time-domain transitions, and hence undesired high-frequency
contents in the spectrum. Accordingly, a time-domain mask is deﬁned within which the transmit-
ter output must ﬁt properly, as shown in Figure 6.56.
Along with the time-domain mask, 2G transmitters must also satisfy a frequency-domain mask
measurement known as switching spectrum. Whereas a modulation mask of better than –60dBc
measured in a 30kHz resolution bandwidth is required in GSM for instance, a switching spectrum
of lower than –23dBm measured at the same bandwidth is speciﬁed as well. There are two distinct
differences between the modulation mask and the switching spectrum measurements:
– The switching spectrum is an absolute measurement speciﬁed in dBm (not dBc). For the full
output power of +33dBm, it translates a requirement of –56dBc. If the transmitter power is
backed off, however, the requirement relaxes proportionally.
– While modulation mask is an average measurements, with often 50 bursts taken, the switching
spectrum is a MAX hold measurement. That is, for the same 50 bursts measured for instance, the
spectrum analyzer is set to take the maximum instance of the 50 bursts at each point of the time
0
1
2
3
4
5
6
7
4.615mS
Tail
Data
S
Training
Tail
Data
S
577mS
GSM TDMA Frame
GSM Time Slot (Burst)
Figure 6.55: GSM frame and time slots
Time, µS
Power, dBm
~
~
Time-Domain Mask
TX Signal
Figure 6.56: Example of GSM time-domain mask
374
Distortion

Consequently, in a well-designed transmitter, often meeting the modulation mask is sufﬁcient
to pass the switching spectrum test. In the case of the worst case maximum power, the
switching spectrum is 4dB relaxed, although the MAX hold measurement could offset that.
On the other hand, if the transmitter time-domain output has sharp transitions, for instance due
to improper design of the ramping phase, the switching spectrum is expected to be affected,
even though the modulation mask may be met.
6.7.5
AM–AM and AM–PM in Transmitters
In addition to noise and static nonlinearities, there is yet another mechanism in transmitters, and
especially power ampliﬁers causing EVM and mask degradation.
Let us start with a more detailed analysis of static nonlinearity presented earlier in the context
of IM3, also known as AM–AM nonlinearity.
Consider the following narrowband RF signal,
x tð Þ = i tð Þcos ωct  q tð Þsin ωct,
where i(t) and q(t) are baseband signals with zero mean and ωc is the carrier frequency. The
autocorrelation Rx(τ) is found to be
Rx τð Þ = 1
2 Ri τð Þcos ωcτ + 1
2 Rq τð Þcos ωcτ + 1
2 Ri,q τð Þ  Ri,q τ
ð
Þ


sin ωcτ,
in which Ri(τ) and Rq(τ) are autocorrelations of i(t) and q(t), respectively, and Ri, q(τ) is their
cross-correlation. Therefore, for frequencies around +fc the power spectral density of x(t) is
given by the following expression:
Sx fð Þ = 1
4 Si f  f c
ð
Þ + 1
4 Sq f  f c
ð
Þ + 1
2 Im Si,q f  f c
ð
Þ


:
For two frequencies, fC  fm, where fm is a small offset, the ﬁrst two terms in Sx( f ) would lead to
identical positive numbers, i.e., Si(fm) = Si(fm) > 0, Sq(fm) = Sq(fm) > 0. However, the third
term would return negative values, i.e., Im[Si, q(fm)] =  Im [Si, q(fm)]. Consequently, any
correlation between the quadrature components of x(t) can potentially cause an asymmetric
power spectral density for x(t). This is because on one side the third terms adds up construct-
ively, whereas they add destructively on the other side. In contrast, if the two quadrature
components are statistically independent, the power spectral density of x(t) is symmetric. Later
we will make use of this conclusion to study power spectral densities caused by AM–AM and
AM–PM nonlinearities.
If i(t) and q(t) are partially correlated, q(t) can be written as q(t) = c(t) + u(t), where c(t) is the
correlated part, and u(t) is the uncorrelated part. c(t) can be written as f(i(t)), in which the
function f can be linear or nonlinear or a combination. It is readily proven that Ri, q(τ) is equal to
Ri, c(τ). For example, if c(t) is equal to i(t) ∗h(t), where h(t) is some impulse response, Ri, c(τ)
becomes equal to Ri(τ) ∗h(τ) (see Chapter 2). As a result, Si, q( f ) = Si( f )H∗( f ). Hence,
Im[Si, q( f )] = Si(f) Im [H∗( f )] given that Si( f ) is real and positive.
6.7 Transmitter Nonlinearity Concerns
375

Now, consider a modulated signal x(t) = A(t) cos (ωCt + ϕ(t)), where A(t) and ϕ(t) are
amplitude and phase information. For this signal the quadrature components are given by the
following expressions: i(t) = A(t) cos ϕ(t), and q(t) = A(t) sin ϕ(t). Assuming the modulation is
symmetric around the center of the constellation, and that all of the constellation points are
covered with equal probability, i(t) and q(t) are statistically independent. Therefore, the power
spectral density of x(t) is symmetric around the carrier.
Now, let us study the impact of AM–AM on the constellation diagram, and symmetry of the
power spectral density. Consider a system whose input is x(t) = A(t) cos (ωCt + ϕ(t)) and with an
output equal to y(t) = F(A(t)) cos (ωCt + ϕ(t)). The function F(A) is the AM–AM characteristic of
the system, represented by a nonlinear transfer function as we have seen before. For a distortion-
less system, F(A) must be proportional to A. In reality, power ampliﬁers and in general
transmitters are nonlinear and mostly compressive. As shown in Figure 6.57, each point in the
constellation with an amplitude of A and a phase of θ is mapped to another point with the
amplitude F(A) but with the same phase θ. Therefore, the constellation points are shifted radially
inward6 to origin. The quadrature components of the resulting signal are i(t) = F(A) cos ϕ and
q(t) = F(A) sin ϕ, which can be proven to be statistically independent (if we loosely assume that
A and ϕ are statistically independent). Note that the two quadrature components occupy more
bandwidth as a result of the spectral regrowth due to the AM–AM nonlinearity, but they still
remain statistically independent. This is the main reason for mask degradation.
In the memoryless nonlinear systems we have discussed thus far, input amplitude variation
only causes output amplitude distortion. In practice, the nonlinear parasitic capacitors often lead
to phase distortion as well. Known as AM–PM nonlinearity, we shall study its impact on the
constellation diagram and modulation spectrum.
The system is assumed to take the input of x(t) = A(t) cos (ωCt + ϕ(t)) and produce an output
of y(t) = A(t) cos (ωCt + ϕ(t) + F(A(t))), where F(A) is the AM–PM characteristic of the system.
Ideally F(A) must be zero for a distortionless system. As shown in Figure 6.58, each constella-
tion point with an amplitude of A and a phase of ϕ is mapped to another point with the same
amplitude A, but phase of ϕ + F(A). Therefore, the constellation points are rotated by the amount
equal to F(A). The quadrature components of the resulting signal are i(t) = A cos (ϕ + F(A)) and
Ideal 16QAM
16QAM Experiencing AM-AM
Figure 6.57: Impact of AM–AM
nonlinearity on constellation
6 For a compressive system of course.
376
Distortion

q(t) = A sin(ϕ + F(A)), which are not necessarily independent. Consequently, in general the
spectrum is not expected to remain symmetric around the carrier. Furthermore, the signal
bandwidth widens as a result of the AM–PM nonlinearity.
Example: Consider the following format of AM–PM distortion in a communication
system: y(t) = A cos (ωCt + ϕ + βA), where F(A) = βA. Assume that the input is an AM-
modulated signal given by x(t) = sin (ωmt) cos (ωCt). The resulting output will be equal to
y(t) = sin (ωmt) cos (ωCt + β sin ωmt), which contains both AM and PM modulations. Let
us use the following two identities as we introduced in Chapter 2:
cos ωct + β sin ωmt
ð
Þ =
X
+ ∞
n = ∞
Jn β
ð Þ cos ωc + nωm
ð
Þt
sin ωct + β sin ωmt
ð
Þ =
X
+ ∞
n = ∞
Jn β
ð Þ sin ωc + nωm
ð
Þt
:
The function Jn(β) is the Bessel function, and is described below (for positive n):
Jn β
ð Þ = βn
n!2n
1 
β2
2 2 + 2n
ð
Þ +
β4
2
ð Þ 4
ð Þ 2 + 2n
ð
Þ 4 + 2
ð
Þ    


:
One can prove that y(t) can be written as
y tð Þ =
X
+ ∞
n = ∞
1
2
Jn1 β
ð Þ  Jn + 1 β
ð Þ
f
g sin ωc + nωm
ð
Þt:
Knowing that Jn(β) = (1)nJn(β), the resulting spectrum in this case is symmetric
around the carrier ωc.
To illustrate how AM–PM could lead to spectral asymmetry, let us consider a more realistic
case shown in Figure 6.59. Depicted in the ﬁgure is the envelope signal varying at a frequency
of fm, and the corresponding phase variations caused due to AM–PM nonlinearity. As the phase
variations occur at every amplitude maxima or minima, they have a rate of twice the funda-
mental frequency [9]. Thus, F(A)  βA2.
Ideal 16QAM
16QAM Experiencing AM-PM
Figure 6.58: Impact of AM–PM
nonlinearity on constellation
6.7 Transmitter Nonlinearity Concerns
377

We shall also assume there is a 3rd-order nonlinearity on the envelope contents of the
RF signal, representing the AM–AM. For the case of a tone modulating the envelope,
A(t) = cos ωmt, and the RF output may be generally expressed as
y tð Þ = a1 cos ωmt + a3 cos 3ωmt
ð
Þ cos
ωCt + β
2 + β
2 cos 2ωmt


:
For simplicity, we ignore the constant phase shift β
2 as it has no impact on the outcome. It is clear
that the RF signal has additional unwanted components at 3ωm, 5ωm, . . . offset, leading to
spectral regrowth. For the moment, let us assume β  1. The general case may be analyzed
similarly using Bessel series as shown in the previous example (see Problem 26). Using
narrowband FM approximation, and focusing only on IM3 sidebands, upon expanding the
RF signal we obtain
y tð Þ = a3
2
cos ωC + 3ωm
ð
Þt + cos ωC  ω3m
ð
Þt
½

  a1β
8
sin ωC + 3ωm
ð
Þt + sin ωC  3ωm
ð
Þt
½

:
Even assuming no 3rd-order nonlinearity on the envelope, that is a3 = 0, there is still 3rd-order
distortion caused by AM–PM nonlinearity, leading to spectral regrowth. The spectrum, how-
ever, is still symmetric at 3ωm away from the carrier. The spectral asymmetry happens if we
introduce a ﬁnite delay between the envelope and phase components. Assuming a phase shift of
Δ = ωmτ for a delay of τ between the envelope and phase, the RF signal may be expressed as
y tð Þ = a1 cos ωmt  Δ
ð
Þ + a3 cos 3ωmt  3Δ
ð
Þ
ð
Þ cos
ωCt + β
2 cos 2ωmt


:
Upon expanding, we arrive at various components, of which we focus on only the terms
appearing at IM3 positive and negative sidebands, that is, the ones at ωC  3ωm, representing
the output distortion.
For positive sideband we can write
a3
2 cos 3Δ + a1β
8 sinΔ


cos ωC + 3ωm
ð
Þt + a3
2 sin 3Δ  a1β
8 cosΔ


sin ωC + 3ωm
ð
Þt,
Envelope
Time
Time
Phase Variation
T=1/fm
1/2fm
Figure 6.59: Envelope and corresponding
AM–PM phase variations
378
Distortion

while for the negative sideband we have
a3
2 cos 3Δ  a1β
8 sinΔ


cos ωC  ω3m
ð
Þt +  a3
2 sin 3Δ  a1β
8 cosΔ


sin ωC  3ωm
ð
Þt:
Therefore the magnitudes of the IM3 signal residing at positive and negative sidebands are
IM3P=N

 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
a3
2

2
+
a1β
8

2
∓a1a3β
8
sin2Δ
s
:
If the phase shift Δ = ωmτ is signiﬁcant, clearly the two sidebands are not equal, leading to
spectrum asymmetry. There are several reasons that such delay may exist. For instance, supply
rail voltage variations induced by varying current in a class AB power ampliﬁer could result in
time constants comparable to the envelope variations.
6.7.6
Pulling in Transmitters
In many applications the strong signal at the power ampliﬁer output may disturb the transmitter
VCO used to generate the carrier. Known as pulling, this is particularly problematic if the
carrier and PA output frequencies are the same, which is the case in a direct-conversion
transmitter.7 Shown in Figure 6.60 are two examples of a direct-conversion transmitter, one
with the VCO at the output frequency, and the other at twice that. The latter approach puts the
VCO frequency far away from the output, but as we will discuss shortly, it may be still pulled
by the PA second harmonic. In both cases, the problem arises from the fact that the VCO output
is a pure tone, at least ideally, whereas the PA output is a modulated spectrum.
The exact nature of pulling and its impact on the transmitters is beyond the scope of this
book. While details can be found in [10], [11], we shall recast a summary here to gain some
perspective for our discussion of transmitters in Chapter 12.
Generally, the pulling impact on an LC oscillator can be analyzed by solving what is known
as Adler’s differential equation [12],
dθ
dt = ω0 + ω0
2Q
Iinj
IS
sin θinj  θ


,
where θ describes the oscillator phase, ω0 is the un-pulled frequency of oscillation, Q is the LC
tank quality factor, IS is the oscillator current, and Iinjejθinj is the external source injected to the
oscillator in complex format. If the injection is a tone, the nonlinear differential equation has a
closed solution, but for most general cases, one may need to resort to numerical methods.
The pulling strength, η, is deﬁned as follows:
η = ω0
2Q
Iinj
IS
1
ω0  ωinj

 :
7 Various transmitter topologies will be discussed in Chapter 12.
6.7 Transmitter Nonlinearity Concerns
379

What the pulling strength signiﬁes is the fact that the further the frequency of the injected
source is from the oscillator frequency, the weaker the pulling. In contrast, even if the injected
current is small compared to the oscillator quiescent current, close-by injections may be quite
troublesome. Thus as shown in Figure 6.60, designing the VCO at twice the frequency may be a
more attractive choice.8 We shall thus focus on the more common case of VCO followed by the
divider. Although the pulling strength will be very small, presence of the 2nd-order nonlinearity
still creates unwanted components at the VCO frequency.
If η > 1, the oscillator is locked to the injected source, that is, its frequency of oscillation
changes to that of the injected source. In most cases η < 1, and solving the Adler’s equation [12]
reveals that the oscillation frequency shifts toward ωinj, but its spectrum is corrupted by
unwanted sidebands resulted from the injection source, as shown in Figure 6.61.
In the case of a direct-conversion transmitter, ﬁrst the injection source is not arbitrary, as
what is used to upconvert the baseband components is the VCO itself. Second, the VCO is not
free running, rather is locked inside a PLL to a reference (Figure 6.62).
PA
… 
fC
ACcos2πfCt
PA
… 
fC
ACcos4πfCt
¸2
VCO at the Output Frequency
VCO at Twice the Output Frequency
Figure 6.60: Illustration of pulling in direct-conversion transmitters
0
inj
b
b
b
Frequency shifts
w
w
w
w
w
Figure 6.61: Oscillator pulled by an external source
8 There are other advantages, such as convenient quadrature generation. See Chapter 4.
380
Distortion

Thus, the VCO phase is affected by its own transmitter (unwanted), as well as the PLL
interaction (wanted). Assuming the injection source is not too strong, which is a reasonable
assumption, the Adler differential equation may be modiﬁed as follows to capture these effects,
dθ
dt = ω0 + KVCO
ICP
2π
θref  θ
N


∗hLF tð Þ + ω0
2Q
γABB2
IS
sin 2θBB  Ψ
ð
Þ,
where KVCO is the VCO gain, ICP is the charge pump current, hLF is the loop ﬁlter impulse
response, θref is the reference phase, N is the PLL divide ratio, and ABB ∠θBB is the polar
representation of the baseband signal fed to the upconversion mixer. The parameter γ ∠Ψ is a
complex number that captures the unwanted 2nd-order nonlinearity, and the ﬁnite isolation
between the transmitter output and the VCO. Clearly, if γ ∠Ψ = 0, then the unwanted pulling
term (the last term) goes away, and the VCO phase is locked to that of the reference as
expected.
The above equation has a closed form solution. Deﬁning θ0 = θ  ω0t as the phase perturb-
ation, then the frequency domain solution is
Θ0 jω
ð
Þ = ω0
2Q
1
IS
F γABB2 sin 2θBB  Ψ
ð
Þ


jω + KVCO
N
ICP
2π HLF jω
ð
Þ
:
Apart from improving isolation, the pulling may be reduced by employing a higher Q resonator
or raising the VCO current. Moreover, as HLF(jω) is typically lowpass, the transfer function of
the denominator of the equation above is bandpass, typically peaking around the PLL 3dB
bandwidth. This indicates that the baseband frequency contents falling around the PLL cutoff
cause the most amount of pulling.
The equation above may be used to ﬁnd the impact of pulling on EVM and modulation mask
[11]. It is clear that as pulling only perturbs the VCO phase, it will not alter the magnitude of the
constellation points; rather it would spread the constellation rotationally, a very similar impact
as phase noise. Moreover, as the pulling is a direct function of the baseband signal, ABB ∠θBB,
PA/PAD
… 
¸2
PLL
Reference
ref
( )2
gÐY
q
Figure 6.62: Locked VCO pulled by its transmitter
6.7 Transmitter Nonlinearity Concerns
381

the amount of rotational movements for each symbol of the constellation is proportional to the
distance of that symbol from the center, as shown in Figure 6.63.
Similarly, we can show that the pulling causes spectral regrowth, an impact very similar to
the 3rd-order nonlinearity. This is due to the fact that the pulling phase perturbation results in an
error term that is twice as wide as the spectrum (given the square function cause by the 2nd-
order nonlinearity), subtracted from the signal. This leads to a spectrum as wide as three times
the wanted signal spectrum.
6.8
Summary
This chapter discussed various distortion mechanisms present in receivers and transmitters.
This, along with noise, deﬁnes the system dynamic range.
– Section 6.1 presented a summary of blockers and their implications in wireless systems.
– Full duplex operation and its impact on the transceiver were discussed in Section 6.2.
– Section 6.3 mainly dealt with the receiver small signal nonlinearity, including 2nd-, 3rd-, and
5th-order nonlinearity, and cross-modulation. The impact of feedback on nonlinearity and
dynamic range deﬁnition was also presented in this section.
– Receiver large signal nonlinearity and compression issues were discussed in Section 6.4.
– Section 6.5 dealt with the reciprocal mixing issue, which is primarily a receiver concern.
– Harmonic mixing in receiver, including image and half-IF concerns, was discussed in
Section 6.6.
– Section 6.7 dealt with a variety of issues in transmitters such as spectral mask, out-of-band
noise, phase error and EVM, AM–AM and AM–PM, and pulling.
6.9
Problems
1. Find the impact of the lowpass ﬁlter shown below on the IIP3 of a nonlinear system
following the ﬁlter:
Ideal 16QAM
16QAM w/ Pulled VCO
Figure 6.63: Impact of pulling on
constellation
382
Distortion

Blocker 1
Blocker 2
20log|H(f)|
f
r1
r2
The blockers are subject to an attenuation of r1 and r2 (in dB) respectively.
2. Calculate the IIP2, IIP3, and 1dB compression points of a single BJT. Answer: At room
temperature, the 1dB compression point is 24mV.
3. Prove the equation AIIP3 = 1 + θ0Veff


ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3 Veff 2 + 2Veff
θ0


r
for the IIP3 of a single FET. Also
ﬁnd the IIP2 of a single FET using the short channel ID–VGS equation.
4. Find the IIP3 of a 2nd-order system y = a1x + a2x2, with and without feedback. Show all
the steps.
5. Find the IIP3 of an inductively degenerated FET.
6. Find the cascaded IIP2 of two nonlinear stages represented by up to 3rd-order
nonlinearity.
7. A desired WLAN signal with 20MHz bandwidth is located at 2412MHz. A 20MHz LTE
blocker located in band 40 (2300–2400MHz) is sitting at 2380MHz. Considering the
spectral regrowth due to 3rd- or 5th-order distortion, show how this blocker may be
problematic. Label all the frequencies.
8. Fortheprevious problem, what is theminimum blockerspacing such thatthe3rd-orderdistortion
will not be an issue? What is the minimum for the 5th-order distortion not to be problematic?
9. A desired Bluetooth signal with 1MHz bandwidth is located at 2482MHz, and is accom-
panied by a 20MHz LTE blocker at 2510MHz. The system has an IIP3 of 5dBm, and the
blocker power is –15dBm. Find the minimum IIP5 such that the IM5 component created
due to the spectral regrowth is at least 10dB below the IM3 component.
10. Similar to the steps taken in Section 6.3.5 (Figure 6.29), work out the cross-modulation
formulas in the presence of the 5th-order nonlinearity. Find the equivalent signal-to-noise
ratio in terms of the system IIP5. Answer: XIM5 = 15
4 a5A0AB12AB22 cos
ω0  2Δω
ð
Þt
ð
Þ.
11. A two-tone blocker at 25101MHz accompanies a WLAN desired signal at 2472MHz.
Assuming the system has nonlinearity up to 5th order, identify all the undesired sidebands
around the signal at the output.
12. Consider a Bluetooth receiver with a noise ﬁgure of 3dB. Assuming an SNR of 14dB, and
a bandwidth of 1MHz, ﬁnd:
a. The sensitivity.
b. The equivalent noise ﬂoor at the input in dBm.
c. Required IIP2 for 3dB desensitization, assuming a –20dBm 20M LTE blocker is present
(follow Figure 6.23 for blocker 2nd-order induced calculations).
6.9 Problems
383

d. Receiver SNR (including the thermal noise) if IIP3=  2dBm, and a two-tone blocker
with 100kHz spacing and –15dBm level is present. Assume IIP2 is inﬁnite for this part.
13. A Bluetooth signal at 2.402GHz is accompanied by a –20dBm 5MHz LTE interferer close
by. Find the receiver SNR set by the blocker cross-modulation. Assume the receiver
IIP3 =  2dBm. Argue whether the receiver IIP3 is adequate. Hint: The BT signal has a
bandwidth of 1MHz, whereas the blocker squared signal is about 10MHz wide.
14. The cross-modulation could elevate the receiver noise ﬂoor even in the absence of a desired
signal due to the LO feedthrough. As we will show in Chapter 12, in direct-conversion
receivers, an undesired tone at the frequency of the signal can leak to the receiver input.
Explain how this could cause SNR degradation.
15. A two-tone nearby blocker at –20dBm is accompanied by a desired signal at –70dBm as
shown below. Assume the receiver has an IIP3 of 0dBm, and an IIP2 of 60dBm. Find which
is more problematic, the 2nd-order nonlinearity or cross-modulation?
f1
f2
f0
–20dBm
–70dBm
16. For the band-limited white noise example, show the output is y tð Þ = A2
2
PN
i = 0
PN
j = 0
cos
i + j
ð
Þ2πΔft + ϕi + ϕj


+ cos
i  j
ð
Þ2πΔft + ϕi  ϕj



	
. Show that for an arbitrary
bin located a point pΔf (p spans from 0 to 2N), the number of i and j that satisfy i + j = p is
p + 1 p  N
2N  p + 1 N < p  2N

. Similarly, the number of
i and j that satisfy |i  j| = p is
2 N  p + 1
ð
Þ p  N
0
N < p  2N

. Hence, the total is roughly 2N  p, if N is large. Consequently ﬁnd
the area under the bin, and ﬁnd the output spectral density. Answer: The area under the bin
pΔf is 1
4
A2
2

 2
2N  p
ð
Þ =
η
2
 22B 1  p
2N


Δf .
17. Calculate the required phase noise for a GSM receiver for a 0dBm blocker at 20MHz offset
from the desired signal at –99dBm. What about a 1.6MHz blocker at –33dBm? Which one
is more important if the phase noise has a roll-off of 40dB/Dec? Answer: –125dBc/Hz at
1.6MHz for 1.6MHz blocker.
18. A Bluetooth receiver has a base noise ﬁgure of 3dB, and a far-out phase noise of –150dBc/Hz.
Assume the receiver is accompanied by an close-by –25dBm blocker.
a. Find the overall noise ﬁgure of the receiver.
b. If the receiver is preceded with an ampliﬁer with 6dB of gain and 3dB noise ﬁgure, ﬁnd
the overall noise ﬁgure with and without the blocker.
19. A matched LNA has a noise ﬁgure of 2dB, and a nonlinear available voltage of
y = 10x  10x3. Find IIP3 and 1dB compression. What is the input-referred noise
voltage of the mixer to achieve a total noise ﬁgure of 3dB? What is the SFDR?
Answer: SFDR = 86dB.
20. Find the receiver noise ﬁgure, when a 0dBm blocker is present at the input of the receiver
of Problem 19. The LO has a phase noise is of –160dBc/Hz at the blocker offset.
384
Distortion

21. Find the OIP3 and output 1dB compression of a 3G transmitter if an ACLR of –46dBc at
5MHz is desired. Answer: The output 1dB compression is 9dBm.
22. A WLAN transmitter has 26dBm of average output power, with 6dB PAPR. Assuming 40dB
of isolation between the WLAN TX and a nearby LTE RX with 3dB noise ﬁgure, ﬁnd the
transmitter out-of-band noise such that the LTE receiver is desensitized by no more than 3dB.
23. Find the PAPR of the following signal: x(t) = A1 cos ω1t + A2 cos ω2t.
24. A 3G radio has a thermal noise ﬁgure of 3dB, IIP2 of 45dBm, and the transmitter
phase noise of –158dBc/Hz at the receiver frequency. There is a total front-end loss of
3dB from the duplexer to the radio. Find the minimum duplexer isolation to meet the
sensitivity.
25. Prove the autocorrelation equation of the following signal: x(t) = i(t) cos ωct  q(t) sin ωct
discussed in the AM–PM section.
26. Using Bessel series, ﬁnd the IM3 and IM5 components for the following RF
signal:
y tð Þ = a1 cos ωmt  Δ
ð
Þ + a3 cos 3ωmt  3Δ
ð
Þ
ð
Þ cos ωCt + β
2 + β
2 cos2ωmt


.
Answer (IM3 case): For
cos
ωC  3ωm
ð
Þt + β
2


:
a1J2
β
2ð Þ
2
cosΔ+
a3J0
β
2ð Þ
2
cos3Δ




a1J1
β
2ð Þ
2
sinΔ+
a3J3
β
2ð Þ
2
sin3Δ


. For sin
ωC 3ωm
ð
Þt+ β
2


:
a1J1
β
2ð Þ
2
cosΔ+
a3J3
β
2ð Þ
2
cos3Δ




a1J2
β
2ð Þ
2
sinΔ+
a3J0
β
2ð Þ
2
sin3Δ


. If: β
2 1, J0
β
2
 
1, J1
β
2
 
 β
8, J2
β
2
 
J3
β
2
 
 0, and we
arrive at the previous results.
6.10 References
[1] J. G. Proakis, Digital Communications, McGraw-Hill, 1995.
[2] K. S. Shanmugam, Digital and Analog Communication Systems, John Wiley, 1979.
[3] P. R. Gray and R. G. Meyer, Analysis and Design of Analog Integrated Circuits, John Wiley, 1990.
[4] R. Ellis and D. Gulick, Calculus, with Analytic Geometry, Saunders, 1994.
[5] R. G. Meyer and A. K. Wong, “Blocking and Desensitization in RF Ampliﬁers,” IEEE Journal of Solid-
State Circuits, 30, 944–946, 1995.
[6] H. Taub and D. L. Schilling, Principles of Communication Systems, McGraw-Hill, 1986.
[7] E. Cijvat, S. Tadjpour, and A. Abidi, “Spurious Mixing of Off-Channel Signals in a Wireless Receiver
and the Choice of IF,” IEEE Transactions on Circuits and Systems II: Analog and Digital Signal
Processing, 49, no. 8, 539–544, 2002.
[8] J. Weldon, R. Narayanaswami, J. Rudell, L. Lin, M. Otsuka, S. Dedieu, L. Tee, K.-C. Tsai, C.-W. Lee,
and P. Gray, “A 1.75-GHz Highly Integrated Narrow-Band CMOS Transmitter with Harmonic-Rejection
Mixers,” IEEE Journal of Solid-State Circuits, 36, no. 12, 2003–2015, 2001.
[9] S. Cripps, RF Power Ampliﬁers for Wireless Communications, Artech House, 2006.
[10] A. Mirzaei and H. Darabi, “Mutual Pulling between Two Oscillators,” IEEE Journal of Solid-State
Circuits, 49, no. 2, 360–372, 2014.
[11] A. Mirzaei and H. Darabi, “Pulling Mitigation in Wireless Transmitters,” IEEE Journal of Solid-State
Circuits, 49, no. 9, 1958–1970, 2014.
[12] R. Adler, “A Study of Locking Phenomena in Oscillators,” Proceedings of the IEEE, 61, no. 10,
1380–1385, 1973.
6.10 References
385

7
Low-Noise Ampliﬁers
In Chapter 5 we showed that according to the Friis equation the lower limit to a receiver noise
ﬁgure is set by the ﬁrst block. Moreover, the gain of the ﬁrst stage helps reduce the noise
contribution of the subsequent stages. Hence, it is natural to consider a low-noise ampliﬁer at
the very input of a receiver. A ﬁrst look then will tell us that for a given application, the higher
the gain of the ampliﬁer the better. However, the limit to that is typically imposed by the
distortion caused by the blocks following the low-noise ampliﬁer. As we stated earlier, there is
a compromise between the required gain, noise, and linearity for a given application, and a
certain cost budget. These requirements may be different for a different application or
standard. In this chapter we assume that these requirements are given to us, and our goal
is to understand the design trade-offs. In Chapter 12 we will study receiver architectures and
various trade-offs associated with each choice of architecture.
What makes a low-noise ampliﬁer (LNA) different from other typical ampliﬁers designed for
analog applicationsis theneed for the LNA topresent a well-deﬁnedtypically 50Ω input impedance
to the outside world. That, along with a relatively higher frequency of operation limit the choice of
topologies to only a handful. Most LNAs in practice use a variation thereof, one way or another.
We will start this chapter with a review of some of the basic concepts we presented in
Chapter 5 and expand those a little further. We then describe three general categories of the
LNAs, namely shunt feedback LNAs, series feedback LNAs, as well as feedforward LNAs. We
close this chapter by considering some practical aspects of LNA design regardless of its
topology. A simple case study in 16nm CMOS is presented as well. Also included in this
chapter is an introductory discussion on signal and power integrity.
The speciﬁc topics covered in this chapter are:
• LNA matching concerns
• Ampliﬁer design concerns for radio frequencies
• Series and shunt feedback LNAs
• Feedforward LNAs
• Impact of substrate and gate resistance on LNAs
• LNA layout and other practical considerations
• Signal and power integrity
For class teaching, we recommend covering most of this chapter, possibly with the exception of
Sections 7.7 and 7.9, which may be assigned as reading. Sections 7.6 and 7.8 may be skipped as
well if time does not permit, but we recommend presenting a brief summary at least.

7.1
MATCHING REQUIREMENTS
..............................................................................................
Consider a 50Ω source with an RMS amplitude of Vs, connected to the input of an ampliﬁer
through a lossless matching network comprising inductors, capacitors, or transformers as shown
in Figure 7.1. The source could simply represent a simple model of the antenna connected to the
receiver input. Shown in Figure 7.1 is also the Thevenin representation of the source and
matching network through an equivalent voltage source (VTH), an equivalent impedance (ZTH),
and a noise source modeling the equivalent noise of Rs seen by the ampliﬁer.
The Thevenin equivalent may be obtained as depicted in Figure 7.2, and is described
as follows:
First, let us represent the source with a Norton equivalent consisting of a shunt resistor and a
current source Is. Suppose the voltage appearing at the output of the matching network is V( f ),
as the response to the source current Is. We assume the transfer function from Is to V( f ) is H( f ).
Since the circuit consists of passive elements, it is reciprocal, and consequently, if we inject a
Rs
SvTH=4KT Re[ZTH]
Vs
ZTH
ZTH
VTH
º
Figure 7.1: Source driving an ampliﬁer through a lossless matching network
Rs
Is=Vs/Rs
+
V(f)
–
|H(f)|2=RsRe[ZTH]
Reciprocity
Rs
+
V(f)
–
Is=Vs/Rs
|H(f)|2=RsRe[ZTH]
ZTH
Figure 7.2: Finding the source Thevenin equivalent using reciprocity
7.1 Matching Requirements
387

current Is to the output of the matching network, we expect the same voltage V( f ) appearing
across the resistor as shown on the right side of the ﬁgure. Let us assume that the total
impedance looking into the output of the matching network is ZTH. The total power delivered
to the matching network by the current Is is then: |Is|2 Re [ZTH], and the total power dissipated in
the resistor is V
j j2
Rs .
Since the matching network is lossless, the two powers must be equal, which yields
H f
ð Þ
j
j2 = V
j j2
Is
j j2 = Rs  Re ZTH
½
:
From this, it follows that the total noise spectral density appearing at the matching network
output is 4KT Re[ZTH], which was already proven in Chapter 5 (Nyquist theorem). Thus, the
entire circuit may be represented by a Thevenin equivalent consisting of a voltage source VTH,
where
VTH
j
j2 = Vs
j
j2 Re ZTH
½

Rs
,
an equivalent impedance ZTH, and a noise source whose spectral density is
SvTH = 4KT Re[ZTH].
From the equivalent circuit model it readily follows that the total available power delivered to
the matching network output is
Pa =
VTH
j
j2
4 Re ZTH
½
 = Vs
j
j2
4Rs
,
and the available input noise is
Na = 4KT Re ZTH
½

4 Re ZTH
½

= KT:
Thus, the lossless matching network does not affect the available power and noise as expected.
We shall use this Thevenin equivalent circuit in Figure 7.1 as a general representation of
the source throughout this chapter. In addition, all the reactive components associated with
package, pad, ESD, routing, and other parasitic capacitances or inductances that are generally
low-loss can be lumped as part of the matching network. As shown in Figure 7.3, they may be
represented by the Thevenin equivalent circuit.
Although we have assumed the matching network is lossless, in practice its elements have a
ﬁnite Q, especially if implemented on-chip. In this case, still the Nyquist theorem is valid, as
we showed in Chapter 5, and the total noise seen at the output of the matching network is
4KT Re[ZTH]. Moreover, as a narrowband approximation, we can always bring out a parallel
noisy resistor at the ampliﬁer side to account for this loss. This will clearly result in noise ﬁgure
degradation. We shall detail this further at the end of this chapter.
388
Low-Noise Ampliﬁers

Example: Let us consider the matching circuit of Figure 7.4, where we showed in
Chapter 3 that it can be used to match the ampliﬁer input impedance of RIN to the source.
Using parallel–series conversion we showed
L = RIN
ω0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs
RIN  Rs
r
C =
1
Lsω02 =
1
ω0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs RIN  Rs
ð
Þ
p
:
Continued
Rs
Matching 
Network
vs
Ampliﬁer
ZTH
vTH
Package
Bondwire
Pad+ESD
Rs
vs
Lossless
SvTH=4KTRe[ZTH]
º
Figure 7.3: Equivalent circuit lumping the matching network, pad, package, and other reactive parasitic
Rs
vs
Matching Circuit
L
C
RIN @ 
0
+
vIN
–
w
Figure 7.4: LC circuit
to match ampliﬁer
input impedance to
source
7.1 Matching Requirements
389

With the values of L and C given above, then we expect to see an impedance of RIN
looking into the right side of the matching circuit at exact frequency of ω0. At an arbitrary
frequency of ω, the output impedance of the matching network has a real component of
Re ZOUT
½
 = Rs
RIN
RINRs
ω
ω0
 2

2
1 
RIN
RINRs
ω
ω0
 2

2
+
Rs
RINRs
ω
ω0
 2 :
Thus, according to the Nyquist theorem we expect the noise spectral density at the
output to be
4KTRs
RIN
RINRs
ω
ω0
 2

2
1 
RIN
RINRs
ω
ω0
 2

2
+
Rs
RINRs
ω
ω0
 2 :
Speciﬁcally, at ω = ω0, the noise spectral density becomes 4KTRIN as expected. Alterna-
tively, let us ﬁnd the transfer function from the source to the input of the ampliﬁer:
VIN
Vs
= H ω
ð Þ = 
RIN
RINRs
ω
ω0
 2
1 
RIN
RINRs
ω
ω0
 2
+ j
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs
RINRs
q
ω
ω0
:
Thus the output noise spectral density is
4KTRs H ω
ð Þ
j
j2 = 4KTRs
RIN
RINRs
ω
ω0
 2

2
1 
RIN
RINRs
ω
ω0
 2

2
+
Rs
RINRs
ω
ω0
 2 ,
which is the same as the result obtained by applying the Nyquist theorem. Moreover, at
ω = ω0, H ω
ð Þ
j
j2 = RIN
Rs , which is again consistent with Re ZOUT
½

Rs
predicted by the Nyquist
theorem.
Example: An alternative to the previous matching network is shown in Figure 7.5. Both
matching circuits downconvert the ampliﬁer input impedance (RIN > Rs), but the circuit of
Figure 7.5 is lowpass, whereas Figure 7.4 is highpass. Another feature of this topology is
that there is a series inductor to the source, which may be combined or even replaced with
the bondwire or input routing inductance, whereas the input parasitic capacitance could be
lumped in C. The reader may ﬁnd more details by analyzing the circuit in Problem 2.
390
Low-Noise Ampliﬁers

As stated before, if the ampliﬁer has an input capacitance, it can be simply lumped within the
matching inductor. This is shown in Figure 7.6, where the matching inductor consists of two
parallel legs, one that resonates with ampliﬁer input capacitance CIN, and the other whose value
was obtained before and converts RIN to Rs.
Furthermore, the loss of the inductor is shown as a parallel resistor, Rp, which effectively
modiﬁes the ampliﬁer input resistance, and must be taken into account in the design of the
matching network.
In Chapter 5 we also showed that for a given ampliﬁer represented by its input-referred noise
currents and voltages, there is an optimum value of the source impedance, ZTH = Zs,opt, to
minimize the noise. On the other hand, source matching requires ZTH = ZIN*, where ZIN is the
ampliﬁer input impedance (Figure 7.7). As we discussed in Chapter 5, Zs,opt is not a physical
resistor but rather a function of the device noise parameters, whereas ZIN is a physical
Vs
Rs
L
C
Matching
RIN > Rs
Figure 7.5: Lowpass LC matching circuit to
downconvert the ampliﬁer input impedance
Rs
vs
L
C
+
vIN
–
RIN||CIN
To resonate with CIN
RP
Matching Inductor
Figure 7.6: Matching an ampliﬁer
input impedance with reactive
component
ZTH
vTH
Noisy Ampliﬁer
ZIN
ZTH = Zs,opt
ZTH = ZIN*
Figure 7.7: Noisy ampliﬁer
connected to the source
7.1 Matching Requirements
391

impedance, and thus in general there is no reason for the two condition to be satisﬁed
simultaneously.
Example: To understand the above limit better, let us assume that the input impedance of
the ampliﬁer in Figure 7.7 has a noise voltage with a spectral density of 4KTα Re[ZIN],
where α is the noise factor. The total input-referred noise voltage spectral density is then
4KT Re[ZTH] + 4KTα Re[ZIN], and by deﬁnition the noise factor is
F = 1 + α Re ZIN
½

Re ZTH
½
 :
The matching requires ZIN = ZTH
∗, and the overall noise factor simply becomes
F = 1 + α.
Thus, for the simple case of realizing the real part of the input impedance by a physical
resistor, α = 1, NF = 3dB, which is often considered relatively poor. An example of such
realization is a common-gate topology (which will be discussed in the next section) that
has a subpar noise ﬁgure.
To overcome this fundamental drawback, two topologies may be sought. The ﬁrst topology
relies on the feedback principle. As we showed in Chapter 5, while a noiseless feedback does
not affect the circuit minimum noise ﬁgure, it may be exploited to alter the ampliﬁer input
impedance favorably. We will discuss both local shunt and series feedback topologies.
In either case, the feedback attempts to provide a noiseless (ideally) real part of the input
impedance.
Another scheme relies on noise cancellation, where intentionally the optimum noise condi-
tions are not met in favor of a 50Ω matching. The excess noise is only subsequently canceled at
the output through a feedforward path. Before presenting the LNA topologies, we shall have a
general discussions on the RF ampliﬁer design, as it differs from the conventional analog
ampliﬁers in certain aspects.
7.2
RF TUNED AMPLIFIERS
..............................................................................................
To emphasize the challenge of realizing a low-noise 50Ω-matched ampliﬁer, let us ﬁrst take a
closer look at the two well-known analog ampliﬁers, namely the common-source (CS) and
common-gate (CG) topologies as shown in Figure 7.8.
Both topologies are simple enough that given the high fT of current modern CMOS
technologies, they can operate at several GHz frequencies. A choice of active load for either
structure is not common for two reasons: First, it limits the ampliﬁer bandwidth, and second,
it adds noise. To clarify the latter, consider a CS stage for instance, using active load as shown
in Figure 7.9.
392
Low-Noise Ampliﬁers

The input-referred noise voltage can be shown to be
vn2 = 4KTγ
gmn
1 + gmp
gmn


= 4KTγ
gmn
1 + Veffn
Veffp


,
where Veff is the gate overdrive voltage. To minimize the noise, one may suggest increasing the
PMOS overdrive voltage (Veffp) to minimize Veffn
Veffp. On the other hand, for both transistors to stay
in saturation, VDD > Veffn + Veffp. Consequently, given the low supply voltages in most modern
CMOS processes, the PMOS overdrive must be kept small and perhaps comparable to that of
the NMOS device, effectively almost doubling the input-referred noise.
This problem is resolved if a complementary stage [1] is adopted as shown in Figure 7.9,
where the P device not only adds noise, but also contributes to the overall transconductance if
sized properly. In fact this structure leads to the same noise and transconductance at half the
bias current. As traditionally PMOS devices have about two times worse mobility, sizing them
up to achieve a similar gm as the NMOS device, leads to extra capacitance and worse bandwidth
which may not be acceptable. Moreover, at low supply voltage the headroom becomes an issue
that potentially leads to further degradation of the bandwidth, and of course the linearity. In
more recent technologies, the PMOS devices appear to be much closer to the NMOS transistors,
and thus using a complementary structure may be more advantageous. As a comparison,
Figure 7.10 shows the DC gain of minimum channel N and P devices versus transistor width
for a constant bias current of 1mA for 40nm processes. Evidently, in 40nm P devices have
about 50% less DC gain biased at the same overdrive voltage.
CS Stage
CG Stage
Figure 7.8: Common-source and common-gate stages.
Bias details not shown.
Active Load
Resistive Load
Tuned Load
RL
VDD
L
CL
CL
VDD
VDD
Complementary
VDD
Figure 7.9: Variations of CS ampliﬁer load
7.2 RF Tuned Ampliﬁers
393

The technology trend for the recent CMOS processes is shown in Figure 7.11. Not only the
DC gain has been improving, but also the gap between N and P devices is becoming smaller.
The sudden increase in the DC gain of 16nm devices may be attributed to the FinFET structure
adopted.
In addition to the trend pointed out above, the complementary structure may become
much more attractive in cases where the ampliﬁer is connected to a device with low input
impedance, such as a current-mode mixer (see the next chapter for more details), as shown
in Figure 7.12. Both headroom and bandwidth concerns will be less important if the mixer
input impedance is low enough to keep the swing at the ampliﬁer output low, and prevent
the ampliﬁer current from ﬂowing into parasitic capacitances (for example, into Cp in
Figure 7.12). In this case the ampliﬁer behaves more like a transconductance stage where
the net gm is the sum of the N and P devices’ transconductances.
µ
W
gm ro
Figure 7.10: DC gain of N and P devices in
40nm CMOS
8
16
24
DC Gain
Technology
40n
28n
20n
16n
P
N
Figure 7.11: Peak DC gain of N and P MOS devices versus
technology
VDD
CM Mixer
ZIN ≈  0
Cp
AC Coupling
Figure 7.12: Complementary ampliﬁer driving a current-
mode mixer
394
Low-Noise Ampliﬁers

Besides the features mentioned for the complementary ampliﬁer of Figure 7.12, there are also
some interesting linearity advantages. First, if the devices are sized properly, even in a single-
ended design, the 2nd-order nonlinearity of the N and P devices cancel to the ﬁrst order, leading
to high IIP2. Second, when the ampliﬁer is driven by a large input, the push–pull operation of
the N and P devices helps maintain a constant overall transconductance, leading to superior 1dB
compression and IIP3. Shown in Figure 7.13 is the large signal gm for N and P devices as well as
the net total transconductance for a 40nm design versus the input signal level. Even though the
N and P devices alone experience substantial distortion, the net transconductance of the
complementary structure stays relatively ﬂat for a wide input range.
Turning back to various load structures in Figure 7.9, another possibility for the load may be
a linear resistor, which could be superior in terms of bandwidth for applications where the
ampliﬁer is not connected to a low-input impedance stage, such as a voltage-mode ampliﬁer.
The input-referred noise voltage is
vn2 = 4KT
gm
γ +
1
gmRL


,
which is clearly less than the case of active load if the ampliﬁer gain, that is gmRL, is large.
Assuming the DC drop across the resistor is half the supply voltage, the ampliﬁer low-
frequency gain is
gmRL 
I
Veff

VDD
2
I
= VDD
2Veff
,
where I is the device bias current, and we assume the transconductance of short channel
devices is gm 
I
Veff. To achieve a reasonable linearity, from our discussion in the previous
chapter, we would like to maintain an overdrive voltage of say no less than 100mV, which
leads to a total gain of only 6 for a 1.2V supply device. Furthermore, if the device
transconductance is chosen to be say 50mS,1 the bias current will be 5mA, and the load
VIN, V
gm, S
Figure 7.13: Transconductance of the
complementary ampliﬁer versus
input voltage
1 To justify this particular value of gm, we note that a transconductance of 20mS corresponds to an input-referred noise
voltage roughly equivalent to that of a 50Ω resistor. Thus a gm of 50mS may be sufﬁcient to guarantee a low noise ﬁgure.
We will present an accurate discussion shortly.
7.2 RF Tuned Ampliﬁers
395

resistance is 120Ω. To maintain a ﬂat passband for up to 2GHz for instance, the bandwidth
may be set to 5GHz, in which case the total parasitic capacitance at the ampliﬁer output
cannot exceed 265fF. To ﬁnd out if our hand calculations check out, shown in Figure 7.14 is
the device gm/ID for 40nm process versus the gate overdrive voltage. For an overdrive voltage
of 100mV, gm/ID is about 7.5V–1, and hence a transconductance of 50mS requires a bias
current of 6.7mA somewhat higher than what we predicted, but not too far. Also note that a
gain of 6 is somewhat optimistic, if the device DC gain is around 10. This, however, may be
improved if a cascode structure is used.
The ampliﬁer gain may dramatically improve if it is loaded by an inductor, resonating with
the total parasitic capacitance at the output. Considering our previous example, if the total
parasitic capacitance is for instance 500fF, which is well above the 265fF limit for the resistive
load, an inductance of 12.7nH is needed to resonate at 2GHz. A Q of only 5 leads to an effective
parallel resistance of Lω0Q = 796Ω, leading to gain of roughly 40.2 Furthermore, the device
drain is now biased at roughly the supply voltage,3 leading to better linearity and less junction
capacitance at the drain. In addition, the relatively narrowband (NB) bandpass nature of the
load (as well as the input matching) provides some ﬁltering which attenuates the large far out-
of-band blockers (Figure 7.15).
0
1
2
3
4
5
6
7
8
9
10
0
100
200
300
400
500
gm/ID, 1/V
Veff, mV
Figure 7.14: NMOS gm/ID versus overdrive
voltage
L
CL
VDD
Ampliﬁer NB 
Response
Desired
Blockers
Bandpass 
Filters
Figure 7.15: Filtering resulted from the
ampliﬁer tuned load
2 We can show that there is an overall improvement of Q times in gain, Q being the inductor quality factor. See Problem 19
for more details.
3 For a modest Q of 5, the inductor series resistance is 32Ω, leading to a DC drop of 160mV for a 5mA bias current, as
opposed to 600mV for resistive load.
396
Low-Noise Ampliﬁers

The main disadvantage is the extra silicon area as the inductors are relatively bulky compared
to transistors or resistors. Nonetheless, in many applications the aforementioned advantages are
overwhelming enough that make the tuned ampliﬁers a popular choice, despite the extra cost.
Finally, we may consider using cascode structure to improve the DC gain as well as the
reverse isolation,4 which is important especially at radio frequencies.
7.3
COMMON-SOURCE AND COMMON-GATE LNAs
..............................................................................................
Inserting some form of LC matching network at the input, Figure 7.16 presents the common-
source and common-gate RF equivalent of the analog ampliﬁers originally shown in Figure 7.8.
The two structures shown in Figure 7.16, or some variations thereof, are popular choices for RF
LNAs. Note that in the case of CG circuit, the cascode may not be needed for isolation reasons,
but still may be used to improve the ampliﬁer gain. Also the matching network is expected to
provide a convenient DC current path to ground to avoid biasing by a current source for better
noise performance.
So far we have considered only the gain and linearity concerns, and we are yet to discuss the
noise properties of the two ampliﬁers shown in Figure 7.16. Let us start with the CS stage. We
include Cgs as a part of the matching network as well as any other reactive component
associated with the design, and we will ignore Cgd for now.5 If Cgd is negligible, then the
ampliﬁer input is purely capacitive, and it can be matched to 50Ω only if a parallel resistor is
inserted at the input as shown in Figure 7.17. This resistor need not be a separate component
and may be combined with the matching network, if its loss is high enough.
Using the equivalent Thevenin model for the source, as also shown in the ﬁgure, the noise
ﬁgure can be readily calculated to be
L
CL
VDD
L
CL
VDD
CS Stage
CG Stage
Figure 7.16: RF common-source and
common-gate ampliﬁers
4 That is, to reduce the gain from the output to the input.
5 The gate-drain capacitance creates a local shunt feedback that we will study in the next section.
7.3 Common-Source and Common-Gate LNAs
397

F = 1 +
ZTH
j
j2
Rp Re ZTH
½
 + 1 + ZTH
Rp
				
				
2
γ +
1
gmRL
gm Re ZTH
½
 ,
where we assume RL represents the equivalent parallel resistance due to the ﬁnite Q of the load
inductor when resonating with CL at the frequency of interest. The noise equation may be
greatly simpliﬁed when realizing that to satisfy the matching requirement, ZTH = ZIN
∗= Rp.
This leads to
F = 2 +
4
gmRp
γ +
1
gmRL


> 2:
Even if gm and RL are made arbitrarily large, the ampliﬁer noise ﬁgure never goes below 3dB.
This brings us to a very important conclusion that will be a recurring theme of this chapter:
As long as the real part of the ampliﬁer input impedance is made up of a noisy resistor, the
noise ﬁgure 3dB barrier cannot be broken. This can be generally proven (see also the example
discussed in Section 7.1), although we showed here only a more special case of a CS stage only.
In our analysis above, we assumed that the LNA needs to be perfectly matched to 50Ω. Not
only is this not possible in practice, in most cases it is not even necessary. For most applica-
tions, an input return loss of –10dB or better is acceptable.6 The input return loss may be traded
for a better noise ﬁgure.
Example: For the CS LNA, let us assume ZTH = Rp
2 . This implies that the parallel resistor
is larger (to be precise twice as large) than what is needed for a perfect 50Ω match. The
resultant input return loss (or reﬂection coefﬁcient) is
S11
j
j = Rp  ZTH
Rp + ZTH
				
				 = 1
3  10dB:
L
CL
VDD
Cgs
Rp
ZTH
º
Figure 7.17: CS LNA matched by a shunt
resistor
6 There is generally no hard requirement for S11. For most external ﬁlters or duplexers the stop band rejection or passband
loss is affected minimally if |S11| is around 10dB or better.
398
Low-Noise Ampliﬁers

If the load noise contribution is small, and assuming gmRp  1, the noise ﬁgure will be
F = 1:5 + 4:5
gmRp
γ +
1
gmRL


 1:5 = 1:76dB,
which is a far more acceptable value. While there are more elegant ways of realizing
LNAs with superior noise ﬁgure, this CS design may be adequate for many applications.
In fact, if the matching network is on-chip, the shunt resistor Rp may be simply incorpor-
ated as a part of the matching circuitry loss.
To elaborate further on the example, let us obtain the noise ﬁgure as a general function of S11. To
do so, we need to obtain ZTHas a function of Rp and S11 (ZTH= Rp only if S11 = 0), and use the general
noise equation obtained earlier. For simplicity, we assume S11 is real. In that case we can show:
F =
2
1 + S11
+
4
1 + S11
ð
Þ2
γ +
1
gmRL
gm Re ZTH
½
 :
If perfectly matched, | S11| = 0, and we arrive at the same equation as before where F > 2. On
the other hand, if we let Rp approach inﬁnity, then |S11| approaches 1, and we have
F = 1 +
γ +
1
gmRL
gm Re ZTH
½
 ,
which is expected as only the device and load contribute noise. Clearly, to improve noise ﬁgure
we would like S11 to be positive, which is to say, we would like Rp > ZTH.
A plot of noise ﬁgure versus the magnitude of S11 for two values of gm Re [ZTH] of 10 and 20
is shown in Figure 7.18. The load noise is ignored, and γ = 1.
The common-gate ampliﬁer may seem more favorable as it does provide a real input
impedance inherently as a part of the design. However, we shall prove shortly that it suffers
from a similar fundamental drawback. Consider the CG LNA shown in Figure 7.19, where, the
same as before, Cgs along with other reactive elements are considered a part of the matching
network. Moreover, we assume the matching network creates a DC path to ground, say through
a shunt inductor. Otherwise, a current source is needed to bias the ampliﬁer, which results in
|
|, dB
NF, dB
0
0.5
1
1.5
2
2.5
3
3.5
4
–26.0
–20.0
–16.5
–14.0
–12.0
–10.5
–9.1
–8.0
–6.9
–6.0
–5.2
–4.4
–3.7
–3.1
–2.5
–1.9
–1.4
–0.9
–0.4
0.0
|S11|<–10
gmRe[ZTH ]= 10
gmRe[ZTH ]= 20
S11
Figure 7.18: Noise ﬁgure versus return loss
7.3 Common-Source and Common-Gate LNAs
399

unnecessary excess noise. Cgd is included as a part of CL, and we assume that gmro is large, so
the impact of ro is ignored.
Under those assumptions, the LNA input impedance is purely real, and equal to
ZIN =
1
gm + gmb
,
where gmb =
ﬃﬃﬃﬃﬃﬃﬃ
2ϵqNA
p
COX
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2ϕB + VBS
p
gm = χgm represents the body effect as a function of the process
parameters (NA, ϕB, and COX). For reasons that we will outline shortly, we choose not to ignore
the body effect. The noise ﬁgure general expression is
F = 1 +
1
gm + gmb
ð
Þ Re ZTH
½

γ
gm
gm + gmb
+ 1 + gm + gmb
ð
ÞZTH
j
j2
gm + gmb
ð
ÞRL
 
!
,
and since ZTH = ZIN∗=
1
gm + gmb, it becomes
F = 1 + γ
gm
gm + gmb
+
4
gm + gmb
ð
ÞRL
 1 + γ
gm
gm + gmb
:
Ignoring the body effect, and assuming γ  1, we arrive at the same 3dB noise ﬁgure, simply
because the input resistance is created by a noisy component, in this case the transistor itself.
Despite the same 3dB noise ﬁgure, the CG LNA is still superior to the CS stage shown in
Figure 7.17 for two reasons: First, unlike the CS LNA where gm needs to be large to ensure the
transistor noise contribution is small, for the CG LNA gm is given, roughly set to 20mS, for a
50Ω match. For an overdrive voltage of 100mV, this leads to a considerably lower bias current
of 2mA. Second, the body effect helps improve the noise ﬁgure to some extent.7 In a typical
40nm design, at 0V body-source bias, gmb comes out to be roughly one-ﬁfth of gm.
Furthermore, considering the fact that γ is also close to 0.9 to be exact and not one for
minimum channel devices, the noise ﬁgure becomes 2.4dB. This again has to do with the fact
that gmb, which is contributing to the input impedance, is noiseless.
L
CL
VDD
Cgs
1/(gm+gmb)
gmro>>1
Figure 7.19: Common-gate LNA
7 That is no longer the case in recent FinFET topologies, however, where the gate tight control of the channel effectively
diminishes the body effect.
400
Low-Noise Ampliﬁers

Example: We shall work out the common-gate LNA noise ﬁgure as a function of its
return loss.
Since S11 =
1
gm + gmbZTH
1
gm + gmb + ZTH, we have
ZTH =
1
gm + gmb
1  S11
1 + S11
:
Ignoring the load noise, we can use the original noise equation derived above, and simply
replace ZTH with its S11 equivalent:
F  1 +
1
gm + gmb
ð
Þ Re ZTH
½

γgm
gm + gmb
= 1 +
γgm
gm + gmb
1
Re
1S11
1 + S11
h
i :
If a return loss of –10dB is acceptable (i.e., S11  1
3 ), for instance, ignoring the load
noise, and with γ = 0.9, and gmb = gm
5 , the noise ﬁgure becomes 1.4dB, all achieved at a
relatively small bias current.
The 3dB noise barrier (for a perfectly matched design at least) in the CS and CG LNAs may
be broken if the real part of the LNA input impedance is made up of a noiseless resistor. This
can be done by incorporating noiseless feedback, where the LNA input impedance is reduced/
increased by applying shunt/series feedback favorably. We shall study both cases next.
7.4
SHUNT FEEDBACK LNAs
..............................................................................................
Consider the ampliﬁer shown in Figure 7.20, where ZF represents the local shunt feedback. We
assume both the feedback and load impedances are complex and noisy, and represent them with
their associated noise currents.
We include the Cgs as a part of the matching network, and Cgd, as a part of ZF. The feedback
circuitry, that is the impedance ZF, can be represented by a Y network as is common in shunt
ZTH
ZL
ZF
ZF
ZF
+
v1
–
+
v2
–
fv1
f = – 1/ZF
ZF
fv2
vo
+
v1
–
+
v2
–
Figure 7.20: Ampliﬁer with local shunt feedback
7.4 Shunt Feedback LNAs
401

feedback networks and is shown on the right side of Figure 7.20. Doing so, we arrive at the
equivalent circuit of Figure 7.21 representing the feedback ampliﬁer. Although commonly the
feedforward gain of the feedback circuit is ignored, we have not done so here, and simply
modiﬁed the ampliﬁer transconductance gain to gm  1
ZF. At the particular frequency when
gm =
1
ZF sð Þ, the feedforward gain leads to a zero in the transfer function, as is evident from the
frequency response analysis of a CS ampliﬁer [2].
The loop gain is
gm  1
ZF


ZFkZL
ð
Þ:
Thus the ampliﬁer input impedance will be
ZIN =
ZF
1 + gm 
1
ZF


ZFkZL
ð
Þ
= ZF + ZL
1 + gmZL
,
and the ampliﬁer noise ﬁgure is
F = 1 + γgm + Re YL
½

Re ZTH
½

ZF + ZTH
gmZF  1
				
				
2
+ Re YF
½

Re ZTH
½

gmZTH + 1
gmZF  1
				
				
2
To simplify and gain some insight, let us assume the noise of the feedback circuit can be
ignored (the last term). This is usually a reasonable assumption in a well-designed feedback
ampliﬁer. Then, satisfying the matching condition, ZTH = ZIN
∗, and given that the input
impedance has been already calculated, we arrive at
F = 1 + ZF + ZTH
gmZF  1
				
				
2 γgm + Re YL
½

Re ZIN
½

:
The term
ZF + ZTH
gmZF1
			
			
2
arises from the impact of feedback impedance loading at the input. If
the feedback impedance consists of a capacitance in parallel with a resistance (RFkCF), the
feedback capacitance (CF) may be lumped within the matching circuit at the input, and the load
capacitance at the output.
Now let us consider a few commonly used LNAs that can be treated as special cases of our
general derivation.
ZTH
(gm–1/ZF)vgs
vo
ZF
fvo
+
vgs
–
ZF||ZL
4KT Re[ZTH]
4KT Re[YF]
4KT( gm+Re[YF]+Re[YL])
g
Figure 7.21: Equivalent circuit of the shunt feedback ampliﬁer
402
Low-Noise Ampliﬁers

7.4.1
Resistive Feedback with Large Loop Gain
This is the common shunt feedback ampliﬁer case, and it assumes |gmZL|  1. If the feedback
resistor is large, then
ZF + ZTH
gmZF + 1
				
				
2
 1
gm2 ,
and since
ZTH
∗= ZIN = ZF + ZL
1 + gmZL
 1
gm
1 + ZF
ZL


,
the noise equation then simpliﬁes to
F = 1 +
γ + Re YL
½

gm
Re 1 + ZF
ZL
h
i  1 +
γ
Re 1 + ZF
ZL
h
i ,
which shows that it is indeed possible to break the 3dB noise limit by maximizing Re 1 + ZF
ZL
h
i
.
For a purely resistive feedback, and thus ignoring Cgd, we have
Re 1 + ZF
ZL


= Re 1 + RF
1
RL
+ jωCL




= 1 + RF
RL
,
where we assumed the load impedance ZL, consists of RL and CL. Thus
F = 1 +
γ
1 + RF
RL
,
and achieving a sub-3dB noise ﬁgure is fairly straightforward if the load and feedback resist-
ances are chosen properly.
Note that our initial assumption has been |gmZL|  1, as it should be, otherwise the ampliﬁer
gain and bandwidth will suffer.
For many applications where RFCgdω can be kept small (this assumes the transistor Cgd is
small), a good design may incorporate a complementary structure with resistive feedback as
shown in Figure 7.22.
VDD
RF
CL
C∞ 
Figure 7.22: Complementary shunt feedback LNA
7.4 Shunt Feedback LNAs
403

Clearly, CL needs to be minimized as much as possible. Moreover, there may be no need for
an explicit RL, as it can be realized by the inherent ro of the devices (which are noiseless), as
long as the condition RF > ronkrop is met.
One important drawback of this scheme is the direct dependence of noise ﬁgure and input
impedance on the LNA load impedance. Thus, either the LNA load must be very well
characterized, and behave favorably over process or temperature variations, or a voltage buffer
may be needed to isolate the LNA output from the possible variations of the mixer input
impedance.
7.4.2
CS Cascode LNA
A second special case is a CS cascode LNA that was discussed before, but this time we include
Cgd, and denote that more generally as CF in case one choses to include additional capacitance.
The rationale behind this will be clear shortly. Without any feedback capacitance, we saw that
the LNA can be matched only through a lossy matching network, leading to > 3dB noise ﬁgure,
unless the return loss is traded for a better noise. Since the feedback is purely capacitive, it is
noiseless, and moreover, the feedback loading consists of a capacitance CF at the input and the
output of the ampliﬁer. The former will be lumped into the matching network, where the latter
is added to the load capacitance.
Let us assume that the total capacitance at the cascode node is Cp, and that the main and
cascode devices have the same transconductance. Moreover, we assume that gm
ωCp  1. Thus the
signal and noise pass through the cascode device and appear at the output without any loss.
At the cascade node, the load impedance including CF is
ZL =
1
j CF + Cp


ω k 1
gm
=
1
gm + jω CF + Cp


where f = jωCF is the feedback factor. The input impedance is
ZIN =
1
f gm + f
ð
ÞZL
=
1 + Cp
CF +
gm
jωCF
gm  jωCF
:
Note that CF appearing at the input (Figure 7.21) has been already lumped in the matching
network, and thus our expression for the input impedance does not include it. The input
impedance has a real part, which is
Re ZIN
½
 =
gm 2 + Cp
CF


gm + jωCF
j
j2 ,
and the noise factor is
F = 1 +
2γgm
gm  jωCF
j
j2Re ZTH
½

= 1 +
2γgm
gm  jωCF
j
j2Re ZIN
½

= 1 +
γ
1 + Cp
2CF
404
Low-Noise Ampliﬁers

Note the cascode device noise is assumed to be 4KTγgm, and has not been ignored. The
equation above shows that the noise ﬁgure 3dB limit may be now broken if Cp
2CF  1. Even if
CF includes only the gate-drain capacitance, this condition is fairly comfortably met, as Cp
consists of the source and drain junction capacitances of the cascode and main transistors, as
well as the cascode device Cgs.
It is constructive to take a look at the imaginary part of the input impedance as well:
Im ZIN
½
 =
gm
2
ωCF + ω CF + Cp


gm + jωCF
j
j2
 1
ωCF
If the feedback consists of only Cgd, then the ampliﬁer input impedance consists of a real
component in series with a relatively small capacitance, and thus it may be very hard to
match. This also leads to a relatively large gain from the source to the ampliﬁer input,
which degrades the linearity and makes the matching too sensitive. Moreover, the loss of
the large matching inductance could potentially lead to a lower bound on the noise ﬁgure
that can be practically achieved in this topology. Nonetheless, the fact that no additional
inductance is required to produce a real part for ZIN may still make this topology quite
attractive.
Ironically, if there is no parasitic capacitance at the cascode node, Re ZIN
½
 =
1
2gm, and the
noise factor will be F = 1 + γ!
7.5
SERIES FEEDBACK LNAs
..............................................................................................
A local series feedback may be incorporated by applying degeneration to a CS ampliﬁer as
shown in Figure 7.24 [2]. Let us assume that the degeneration is generally represented by a
noisy impedance of Zs, not to be confused with the input source impedance, and for simplicity,
we shall ignore the body effect. Moreover, we ignore Cgd, otherwise the calculations will
become too complicated. The impact of Cgd has been already discussed in details in the
previous section.
Knowing that the total output current, io, must inevitably ﬂow through the degeneration
impedance, we use the Thevenin equivalent shown in Figure 7.24 to analyze the circuit. The
CP
CF
Figure 7.23: Cascode LNA incorporating shunt capacitive
feedback
7.5 Series Feedback LNAs
405

feedback factor then is simply equal to Zs. The open-loop transconductance gain is
1
jωCgs
1
jωCgs
+ Zs
gm =
gm
1 + jωCgsZs, and the open-loop input impedance is
1
jωCgs + Zs. Thus, the closed-
loop input impedance is
ZIN =
1
jωCgs
+ Zs


1 +
gmZs
1 + jωCgsZs


=
1
jωCgs
+ Zs + gmZs
jωCgs
:
To ﬁnd the noise ﬁgure, we ignore ro, which is a fair assumption especially if a cascode
structure is used. We can show
F = 1 +
4KT Re Zs
½
 + 4KTγgm
1 + jωCgsZs + jωCgsZTH
gm
			
			
2
4KTRe ZTH
½

:
Let us assume Zs = r + jX. To satisfy matching,
Re ZTH
½
 = Re ZIN
½
 = Re r + gmX
ωCgs
+ 1 + gmr
jωCgs
+ jX


= r + gmX
ωCgs
:
We can see that both the real and imaginary parts of the degeneration impedance contribute to
the real part of the LNA input impedance. Replacing ZTH from the equation above into the noise
equation yields
F = 1 +
r + γ
gm
gmr
ð
Þ2 + gmX + 2ωCgsr

2
h
i
r + gmX
ωCgs
:
It is easy to show that the noise ﬁgure monotonically increases with r = Re[Zs], as shown in
Figure 7.25.
Cgs
ZTH
Zs
Rs
io
ZTH
Zs
gmvgs
io
Zs
Cgs
fio=Zsio
Series FB
Zs
io
ZTH
Figure 7.24: Local series feedback in a CS ampliﬁer
406
Low-Noise Ampliﬁers

Thus, despite the fact that r does contribute to the real part of LNA input impedance, since
it is a noisy resistor, we are better off not having it. In fact in the extreme case that X = 0, we
have
F = 1 +
r + γ
gm
gmr
ð
Þ2 + 2ωCgsr

2
h
i
r
> 2,
which leads to a noise ﬁgure of well above 3dB, as expected.
On the other hand, we notice that the imaginary part of the degeneration impedance, X, also
contributes to the real part of LNA input impedance through the term gmX
ωCgs. We will not consider
a capacitive degeneration as it leads to a positive feedback and negative real input impedance,8
so it leaves us with the choice Zs = jX = jωLs. The LNA input impedance then becomes
ZIN = gmLs
Cgs
+
1
jωCgs
+ jωLs,
and the noise ﬁgure is
F = 1 + γLsCgsω2.
From this we see that fundamentally there is no limit to reduce the noise ﬁgure, although there
are practical limitations as how far low the noise ﬁgure could be. For a given frequency, to
improve the noise ﬁgure we can either reduce Ls or Cgs. To understand the lower limit for the Ls,
consider Figure 7.26, which illustrates the LNA Thevenin model we discussed earlier.
F
Re[Zs]
1+ X Cgs
w
g
Figure 7.25: Noise ﬁgure versus r for degenerated CS LNA
ZTH
Cgs
fio=Zsio
Series FB
+
vTH
–
+
vgs=io/gm
–
jX
Figure 7.26: CS LNA Thevenin model to calculate the input gain
8 We will consider a capacitive degeneration to realize an oscillator in Chapter 8.
7.5 Series Feedback LNAs
407

Writing KVL yields
vTH = fio + io
gm
+ ZTH + jX
ð
Þ jωCgs
io
gm
,
and since ZTH = ZIN
∗, we ﬁnd the available voltage gain from the source to the voltage across
Cgs to be
vGS
vTH
=
1
jXgm
,
and the effective available transconductance gain of the LNA is
io
vTH
= 1
jX :
We can see that reducing degeneration inductance or X leads to a larger gain to the ampliﬁer
input. This is good as it suppresses the noise and thus leads to a lower noise ﬁgure, but results in
a poor linearity.
Ironically, the optimum noise ﬁgure is realized when both r and X are equal to zero. This in fact
is the case of a simple FET with no degeneration, which we discussed in Chapter 5, and concluded
that the minimum noise ﬁgure is indeed equal to zero. However, that can be accomplished only
through a large source matching inductance that provides an inﬁnite gain to the FET input.
Similarly, reducing Cgs leads to unreasonably large values for the matching inductance, at
which point its loss will start limiting the noise ﬁgure. Nevertheless, the CS LNA with inductive
degeneration provides perhaps the best noise ﬁgure at GHz frequency applications, but does
come at the cost of an extra inductor for source degeneration. It possible to incorporate the
degeneration inductance using bondwires (in cases where bondwires are used for packaging),
which leads to a more complex, but lower area design.
Finally, we can ﬁnd the impact of the ﬁnite Q of the degeneration inductance on the LNA
noise ﬁgure using the general noise equation we derived earlier, where r = X
Q. We can easily
show that if Q is reasonably large, say more than 5, the inductance loss has little impact on the
noise ﬁgure.
A complete schematic of the LNA is shown in Figure 7.27. A cascode scheme is very
desirable to improve the isolation.
L
CL
Ls
Ls
Cp
Figure 7.27: CS LNA complete schematic
408
Low-Noise Ampliﬁers

We have ignored the noise contribution of the cascode transistor, but in most cases it has a
negligible impact. Assuming the total parasitic capacitance at the cascode node is Cp
(Figure 7.27), from basic analog design we know that the signal loss, as well as the noise
contribution of the cascode transistor is negligible if
gm
ωCp  1. This can be accomplished to a
large extent by a proper layout as we will discuss later on.
Example: As a related case study, let us ﬁnd the optimum noise ﬁgure of the inductively
degenerated CS LNA. First with the aid of Figure 7.28 we will ﬁnd the equivalent input
noise sources of the LNA.
As we did earlier, with both the noise sources and the ampliﬁer noise itself present,
nulling the output current for the short and open conditions leads to the negative of the noise
values, but the actual sign is unimportant. Doing so (see Problem 10 for more details) yields
vn2 = 4KTγ 1  ω2Cgs Lg + Ls


		
		2
gm
in2 = 4KTγ ωCgs
		
		2
gm
:
Note that under source matching conditions ω2Cgs(Lg + Ls) = 1, and vn2 = 0, but as we
will see shortly this is inconsequential. The input equivalent voltage and current noise
sources are fully correlated, and we therefore have
Ru = 0
Zc = 1  ω2Cgs Lg + Ls


jωCgs
Gn = γ ωCgs
		
		2
gm
:
The optimum noise impedance will be reactive, and is equal to
Zs;opt =  1  ω2Cgs Lg + Ls


jωCgs
,
Continued
gmvgs
io
ind
Cgs
+
vgs
–
vn
in
Lg
Ls
Figure 7.28: Simpliﬁed CS LNA noise model
for equivalent input noise calculations
7.5 Series Feedback LNAs
409

and the minimum noise ﬁgure is
Fmin = 1 + 2Gn Rc +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ru
Gn
+ Rc2
r


= 1:
Under source matching conditions Zs,opt = 0, but this does not affect the minimum noise
ﬁgure as the optimum noise impedance is purely imaginary. This implies that to achieve a
minimum noise ﬁgure of 0dB, the LNA must be driven with an ideal voltage source that is
obviously not practical. The reader can verify that if the LNA is indeed driven by an ideal
voltage source, its output noise is zero!
If the source impedance has a resistive part of Rs, then the noise ﬁgure becomes
F = Fmin + Gn
Rs
Zs  Zs;opt
		
		2 = 1 + γ ωCgs
		
		2
gm
Rs:
Assuming the LNA is matched,
gmLs
Cgs = Rs, and the noise ﬁgure becomes F = 1 +
γLsCgsω2, as previously reported. This is obviously higher than the theoretical minimum
noise ﬁgure; nevertheless, it is quite low while providing the required impedance match-
ing at the same time. In practice, the LNA noise ﬁgure is usually limited by parasitic
elements and the matching network loss.
7.6
FEEDFORWARD LNAs
..............................................................................................
In our discussion earlier we saw that creating the 50Ω matching through a noisy resistance leads
to a noise ﬁgure always higher than 3dB, which may not be acceptable for many applications.
Also we saw that the majority of topologies that rely on feedback to break this trade-off result in
a relatively narrowband design. To realize a broadband matching, one alternative is to create a
noisy but wideband 50Ω match, for instance by using a CG topology, but cancel or reduce this
noise subsequently through a feedforward (FF) path [3]. The basic concept underlying this
principle is shown in Figure 7.29.
To create the matching, we insert a noisy resistor RIN, whose value if chosen to be equal to Rs
results in wideband but noisy match. Unlike the conventional ampliﬁers, let us monitor both the
Rs
vs
vIN
rmiIN
iIN
+
vo
–
RIN
+
vIN
–
a
Figure 7.29: Noise cancellation concept
410
Low-Noise Ampliﬁers

voltage across, and the current ﬂowing through RIN as shown in Figure 7.29. The corresponding
signals, that is, vIN and iIN, are fed to the output through dependent voltage sources, creating a
differential voltage. Let us ﬁrst ﬁnd the gain from the source to the output. We have
vIN =
RIN
RIN + Rs
vs
and
iIN =
vs
RIN + Rs
:
Thus, the total gain is
vo
vs
= αRIN  rm
RIN + Rs
:
Next, we will ﬁnd the noise ﬁgure. The source noise appears directly at the output, as would the
source voltage vs, whose transfer function we found previously. However, the noise of RIN, vnIN,
produces signals at the output with opposite polarities as the ones calculated for the source.
Turning off the source and its noise, the output noise voltage due to the RIN noise is
von = αRs + rm
RIN + Rs
vnIN,
and from this the noise ﬁgure is readily obtained:
F = 1 + RIN
Rs
αRs + rm
αRIN  rm
				
				
2
:
To satisfy matching RIN = Rs, and the noise ﬁgure simpliﬁes to
F = 1 + αRs + rm
αRs  rm
				
				
2
:
A plot of noise ﬁgure and normalized gain versus rm
αRs is shown in Figure 7.30.
Evidently, if rm =  αRs, a 0dB noise ﬁgure is obtained, while the differential gain
will be α, twice as much as a voltage-mode ampliﬁer.
–2
–1
0
rm/ Rs
NF, dB
0
1
2
3
Gain/
No cancellation
Perfect 
cancellation
a
a
Figure 7.30: Feedforward noise canceling LNA noise ﬁgure
and gain
7.6 Feedforward LNAs
411

The transistor level implementation could be done by incorporating a CS-CG topology as
shown in Figure 7.31.
We expect the common-gate device, M1, to provide the matching resistor, RIN = 1/gm1
(ignoring body effect and channel length modulation). Accordingly, the noise of M1 is subject
to cancellation if the parameters are chosen properly. The common-source device, M2, provides
the voltage monitoring, and thus we expect α = gm2R2, while M1 performs current monitoring,
and hence rm =  R1. Thus, if we choose R1
Rs = gm2R2, the noise of M1 is subject to perfect
cancellation. The CS transistor still contributes noise; however, this noise can be made
arbitrarily low by raising gm2 without worrying about matching.
The total gain from the source to the output is
vo
vs
= gm1R1 + gm2R2
1 + gm1Rs
:
The general expression for the noise ﬁgure is
F = 1 + γ
Rs
gm1 R1  gm2R2Rs
j
j2 + gm2 R2 1 + gm1Rs
ð
Þ
j
j2
gm1R1 + gm2R2
j
j2
+ R1 + R2
ð
Þ 1 + gm1Rs
j
j2
Rs gm1R1 + gm2R2
j
j2 :
The last term shows the load resistors’ noise contribution. With matching and noise cancellation
conditions both met, the noise ﬁgure simpliﬁes to
F = 1 +
γ
gm2Rs
+
R1 + R2
Rs gm2R2
j
j2  1 +
γ
gm2Rs
,
and the gain is gm2R2. The noise ﬁgure can be made arbitrarily low if gm2 is increased without
sacriﬁcing the matching. Another advantage of this LNA is that it provides a differential output
from a single-ended input. Keeping the capacitances low, a very wideband and low-noise
ampliﬁer can be realized at a reasonable power consumption.
A summary of various LNA topologies is shown in Table 7.1.
Obviously we have made a number of arbitrary assumptions, but one may be surprised that in
a well-designed LNA, in most available modern CMOS technologies used today, performance
metrics will not be drastically different from the ones shown above.
Rs
vs
M1
R1
+   vo   –
M2
R2
+
vIN
–
Figure 7.31: An example of a noise-canceling LNA
412
Low-Noise Ampliﬁers

7.7
LNA PRACTICAL CONCERNS
..............................................................................................
In this section we discuss some practical design aspects of the LNA, which to a large extent are
applicable to any of the topologies described before.
7.7.1
Gate Resistance
The gate material has typically a large sheet resistance (10–20Ω/□or even higher in recent
technologies). As the gate resistance usually appears directly at the input, it could potentially
lead to a large noise degradation. Fortunately it can be minimized by proper layout. Shown in
Figure 7.32, as far as noise is concerned gate resistance may be modeled by a resistor Rg whose
value is
Rg = 1
3
W
L Rh,
where R□is the gate sheet resistance, W, and L are the devices dimensions, and the factor 1/3
arises from the distributed nature of the gate resistance [4] (see Problem 15 for the proof ). As
the LNA devices tend to use short channel length and wide channel width, this resistance could
be very large. For instance, a sheet resistance of 10Ω/□, and a devices size of 20/0.04 leads to a
gate resistance of 1.6kΩ, appearing directly in the signal path.
The resistance may be reduced substantially if multiﬁnger layout is used as shown in
Figure 7.32. If the transistor is broken into 40 smaller devices of 0.5/0.04, the total size remains
the same but the net gate resistance is now about 1Ω only.
7.7.2
Cascode Noise Degradation and Gain Loss
We brieﬂy discussed the cascode noise earlier and concluded that its noise contribution is
typically small. Let us have a closer look here. Consider Figure 7.33, showing the cascode
Table 7.1: LNA topologies summary
LNA Type
CS
CG
CS w/Cas.
Complementary
CS w/Deg.
FF
Topology
Lossy
matching
Common-
gate
Shunt FB
Shunt FB
Series FB
Noise
cancellation
Typical NF
2–3dBa
2–3dBa
2dB
2dB
< 2dB
2dB
Linearity
Moderate
Good
Moderate
Good
Poor
Good
Current
5mA
2mA
5mA
2mA
3mA
4mA
Bandwidth
Narrow
Wide
Narrow
Wide
Narrow
Wide
a We assume an S11 of –10dB is acceptable.
7.7 LNA Practical Concerns
413

transistor noise current source, while the main device has been replaced with a resistor
modeling the channel length modulation, and a net parasitic capacitance of Cp.
If the cascode device ro is ignored, then the noise current density appearing at the output is
ion2 = 4KTγgm2
1
1 + gm2ZP
j
j2 :
Since gmro  1, at frequencies of interest the impact of Cp is more dominant. The breakdown of
the device capacitances is also shown in Figure 7.33, leading to
Cp  Cgs2 + Cgd1 + Csb2 + Cdb1  2Cgs.
In most modern technologies the gate-drain and junction capacitances are about one-third of the
gate-source capacitance, and thus the total parasitic at the cascode node is on the order of two
times gate-source capacitance. Knowing that the device transit frequency is roughly ωT  gm2
Cgs2,
we conclude that the cascode noise is suppressed by roughly
ωT
2ω
		
		2. Unless the frequency of
operation is too close to transit frequency, cascode noise contribution is indeed negligible.
If needed, the cascode node parasitic may be reduced if a dual-gate layout as shown in
Figure 7.34 is incorporated.
If the size of the main and cascode devices are the same, assuming no external access to the
cascode node is required,9 then there is no need to insert contacts at the source of the cascode
Rg=⅓R W/L
4KTRg
Rg/n
1/n*W/L
≡
Rg/n2
W/L
Gate Resistance Noise
Multi-Finger Layout
Figure 7.32: Gate resistance noise and its minimization
ZP
ro1
CP
M2
Cgs2
Cgd1
Cdb1
Csb2
M2
M1
Figure 7.33: Impact of cascode device noise
9 An example of a situation where access to cascode node is needed is when a current steering gain control is implemented at
the cascode node.
414
Low-Noise Ampliﬁers

device, minimizing the area and thus reducing the junction capacitances. This also eliminates
the metal capacitances due to contacts and routing. Moreover, by sharing the drain of two
devices, the output node junction capacitance is halved.
7.7.3
Substrate Impact
At radio frequencies, the substrate noise or any other harmful impact it may produce is typically
negligible. A simple model of the device including the substrate resistance is shown in
Figure 7.35.
The exact value of RSUB is very layout dependent, and may be found experimentally to be
included in the device small signal model. Shown on the right, even if the device source is
connected to ground, the substrate resistance noise appears at the output through body trans-
conductance. If RSUB is known, so is its thermal noise, and the small signal model shown in
Figure 7.35 may be used to ﬁnd the noise impact.
A common layout technique to minimize the impact of substrate is shown in Figure 7.36.
The device is broken into smaller ﬁngers, with each pair forming a dual-gate layout, and
put into an island surrounded with sufﬁcient substrate contacts connected to a clean
ground. This not only reduces the substrate noise, but also helps picking up any noise
injected to the substrate from close by noisy circuits. The drawback is a somewhat bigger
structure and more parasitic capacitance.
S1
D1/S2
D2
S1
D1/S2
Figure 7.34: Dual-gate layout to minimize cascode node parasitic
capacitance
RSUB
CSUB
Substrate Modeling
Substrate Noise
RSUB
… 
gmbvbs
gmvgs
vS
vb
–     vbs     +
CSUB
Figure 7.35: Substrate impact
7.7 LNA Practical Concerns
415

7.7.4
LNA Biasing
The LNA biasing circuitry is potentially a noise contributor, but fortuitously can be greatly
minimized by simple circuit techniques. Shown in Figure 7.37 is an example of a fully
differential structure with bias details.
The cascode device is conveniently biased at VDD by a resistor. This resistor along with a
bypass capacitor at the cascode gate (labeled as C∞, a sufﬁciently large capacitance at the
frequency of interest) helps ﬁlter any potential noise at supply. If the cascode gate is not
properly bypassed, looking into it, the input impedance may have a negative real component,
leading to potential instability.
The main device bias may be applied through a large resistor (several tens or hundreds of
kΩ), and the same as cascode, needs to be bypassed properly. The input itself is typically AC
coupled. The size of the AC coupling capacitor depends on the frequency of operation, but
usually a few pF is sufﬁcient for most RF applications.
Most of these concerns are greatly alleviated if a differential design is chosen. Still, if a large
blocker is present at the LNA input, the bias devices (attached to the node VBIAS in the ﬁgure)
… 
Figure 7.36: Proper layout to minimize substrate impact
C∞ 
C∞ 
RB
CB
VBIAS
VDD
Figure 7.37: Fully differential LNA with biasing details
416
Low-Noise Ampliﬁers

can substantially contribute noise due to nonlinearities. For this reason, proper bypassing is
always very critical. Since the LNA frequency of operation is high, the bypass capacitances are
typically small, ranging from a few to a few tens of pF.
7.7.5
Linearity
The LNA linearity is set by two factors:
– The device inherent nonlinearity, which was characterized in Chapter 6. Generally the IIP3
tends to improve if the gate overdrive is raised, but that comes at the expense of a higher
current if the device gm is desired to be kept constant.
– The matching network gain, although it improves the noise, results in a stronger signal at the
device input, and thus worse linearity. This also clearly leads to a trade-off between noise and
IIP3 if the bias current is kept constant.
The LNA 2nd-order distortion is generally not a major concern as the IM2 components created
due to 2nd-order nonlinearity appear at a very low frequency and are subject to ﬁltering. They,
however, may leak to the output in the presence of mismatches in the mixer stage following the
LNA. This will be analyzed in Chapter 8.
Example: A common scenario where 2nd-order distortion is important is when a blocker
around half the desired frequency appears at the LNA input (Figure 7.38). Although
subject to substantial ﬁltering at the LNA input if narrowband matching is employed, the
2nd-order nonlinearity in the LNA leads to a blocker close to the desired frequency at the
output.
For that reason, it is common to specify an IIP2 requirement for the LNA at half the
desired frequency. This is clearly a bigger concern in wideband and/or single-ended LNAs.
Example: Shown in Figure 7.39 is a common-gate LNA with an inductive load. Let us
assume that at the frequency of interest the load inductance resonates with the output
capacitance, effectively giving a net resistance of RD. The gate is biased at VB, and the
input carries a DC voltage of VDC. We would like to explore the LNA 1dB compression.
Continued
Blocker
( . )2
LNA
f0
Desired
f0/2
( )2
Figure 7.38: Second-order distortion in LNAs
7.7 LNA Practical Concerns
417

Assuming the LNA carries a DC current of IDC, a KVL at the input yields
VB =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2 IDC + is
ð
Þ
β
s
+ VTH + VDC + vs + Rs IDC + is
ð
Þ,
where VTH is the transistor threshold voltage, and
ﬃﬃﬃﬃﬃﬃﬃ
2IDC
β
q
is the effective voltage at
quiescent point (assuming square-law characteristics for the FET). For no AC input
(vs = 0), there will be no AC current (is = 0), and thus
VB =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2IDC
β
s
+ VTH + VDC + RsIDC:
Combining the two equations yields
vs = 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2IDC
β
s
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 + is
IDC
r
 1


+ Rsis
 
!
,
which after expanding
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 +
is
IDC
q
becomes
vs = 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2IDC
β
s
is
2IDC
 1
4
is
IDC

2
+ . . .
 
!
+ Rsis
"
!
:
This allows us to express the input AC voltage in terms of the output AC current. We
make the conscience judgment that given the high gain of the ampliﬁer, the LNA
compression is likely to be dominated by the output. If so, the term
is
IDC

2
may be
ignored, leading to
vs  
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
2βIDC
s
+ Rs
 
!
is:
VDD
VB
Rs
IDC + is
VDC + vs
Vo = VDD – RDis
L
C
Figure 7.39: A common-gate LNA and its compression mechanisms
418
Low-Noise Ampliﬁers

Since
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2βIDC
p
is the input device gm, and due to the matching requirements, it is the same
as 1
Rs. Thus
vs   2Rsis,
a result that could have been obtained by the small signal analysis as well. In Problem 17,
the reader will explore the situation where the LNA is compressed at the input.
For the output not to be compressed, the transistor must stay in saturation, hence
Vo  (VB  Vgs) > VDS, SAT,
or
VDD  RDis > VB  Vgs + VDS, SAT.
Since, Vgs  VDS, SAT  VTH, we have
is < VDD  VB + VTH
RD
:
Translated to the input,
vs
j j < 2Rs
RD
VDD  VB + VTH
ð
Þ:
Note that the compression occurs only at the input downswing, given that a common-gate
ampliﬁer is noninverting. Since the ampliﬁer gain is gmRD
2
= RD
2Rs, then the input compres-
sion in volts is roughly
P1dB  VDD  VB + VTH
Gain
,
or equivalently the output compression is roughly VDD  VB + VTH. On the other hand, for
the transistor to turn on,
VB > VTH + RsIDC,
So the upper bound for the output compression is VDD  RsIDC. Putting an inductor at the
source to carry the DC current (similar to the LNA of Figure 7.19) will eliminate the term
RsIDC, and the upper bound for the LNA output compression would increase up to VDD
roughly, which is expected.
7.7.6
Magnetic Coupling between the Inductors
Most LNAs feature two or more inductors that if integrated on-chip will interact with each other
through magnetic coupling given their close vicinity. In this section, we study this in the context
of an example.
7.7 LNA Practical Concerns
419

Shown in Figure 7.40 is an inductively degenerated CS LNA, where it is assumed the gate
and source inductors magnetically couple to each other. The case of source and output inductor
coupling is studied in Problem 14.
We shall ﬁnd the input impedance ﬁrst. The input voltage consists of the two inductors’
voltages, as well as the transistor VGS. Thus,
V = [jωLgI + jωM(gm + jωCgs)VGS] + VGS + [jωMI + jωLs(gm + jωCgs)VGS]
Since the input current I is equal to jωCgsVGS, then the input impedance is
ZIN = jω Ls + Lg + 2M


+
1
jωCgs
+ gm
Cgs
Ls + M
ð
Þ:
Compared to the earlier derivation, the inductive part has an extra term 2M, whereas the
resistive part has the extra term gm
Cgs M. This makes sense as both inductors carry a common
current of jωCgs, and hence the addition of 2jωM to the inductive part, though the source
inductor has an additional current component of gmVGS, which leads to the additional resistive
term gm
Cgs M.
To ﬁnd the LNA gain, we can similarly write
VGS
V
=
1
1  ω2Cgs Ls + Lg + 2M


+ gmjω Ls + M
ð
Þ :
If Cgs resonates with the inductive part, then
VGS
V
=
1
gmjω Ls + M
ð
Þ ,
which is a similar expression to what we had before, except for Ls changes to Ls + M.
Note that M could be positive or negative, and its impact, if understood and modeled
properly, is generally not an issue. In fact, one can take advantage of a positive M for instance,
to effectively use smaller Ls and Lg.
7.7.7
Gain Control
As we discussed in Chapter 6, the LNA gain is desired to vary if for instance the wanted signal
is too large, or in some cases to improve linearity in the presence of very large blockers. Of
various structures used, two of the more common techniques are shown in Figure 7.41.
Lg
Ls
M
+
V
–
I
(gm+j Cgs)VGS
+
VGS
–
ZIN
w
Figure 7.40: Common-source LNA with coupling between the
source and gate inductors
420
Low-Noise Ampliﬁers

In the ﬁrst method shown on the left, the device is broken into smaller pieces that can
be conveniently done given that multiﬁnger layout with many ﬁngers is desired for the
reasons we mentioned earlier. All the nodes are shorted, except for the gate of cascode
devices that are connected to on (VDD) or off (VSS) voltages. Thus the device size is
effectively chosen arbitrarily, and hence so is the gain. If laid out properly, the sections are
well matched and thus the gain steps will be very accurate. The main drawback of this
scheme is that the input matching is inevitably affected as the gate-source capacitance
varies. For small gain changes this may be acceptable, but larger gain steps typically result
in S11 degradation.
The second scheme relies on current steering where part of the signal is steered to VDD by
selecting the appropriate gate voltage of cascode branches. There are two main drawback with
this scheme: First, the parasitic at the cascode node is more than doubled, and moreover dual-
gate layout is not possible anymore. Second, as the gain reduces, the LNA bias current while
scales in the ﬁrst approach, in current steering method stays constant. However, the matching is
not affected much by the gain control.
Perhaps it may be prudent to use a combination of the two approaches, and apply current
steering at only very lower gain settings.
7.8
LNA POWER–NOISE OPTIMIZATION
..............................................................................................
In this section we discuss some of the trade-offs between noise, linearity, and the LNA power
consumption in a somewhat more methodical way. Let us start with a simple CS LNA as shown
in Figure 7.42, and let us assume that the matching is performed by an explicit resistor of Rp at
the input.
This resistor, as indicated before, may be treated as the loss of the matching network. We
make the sensible assumption that Rp is larger than the source resistance Rs, and thus we use the
shunt-L, series-C matching network discussed earlier to downconvert the impedance. More-
over, we lump all the parasitic capacitances into one capacitor CIN, which is also treated as a
part of the matching circuit. We showed that this ampliﬁer has a noise ﬁgure of greater than
3dB, unless input returns loss is allowed to be traded for noise. So we shall assume an input S11
of about –10dB across the band is acceptable.
… 
G0
G1
Gn–1
n–1
n–1
G0
G0
G
G
… 
Current Steering
Device Size Variation
Figure 7.41: LNA gain control
7.8 LNA Power–Noise Optimization
421

For an input return loss of S11
j
j = 1
3  9dB, we showed that the noise ﬁgure is
F = 1:5 + 4:5
gmRp
γ +
1
gmRL


 1:5 + 4:5
gmRp
:
To satisfy the noise ﬁgure shown above, and the corresponding S11
j
j = 1
3, then looking into the
right side of the matching network (Figure 7.42), the resistance seen must be
RIN = Rp
2 :
Or alternatively, on the source side looking into the left side of the matching network the
equivalent resistance must be 2Rs. This implies that the value of the parallel resistance is higher
than what would have been needed for perfect matching conditions. This in turn is the very
reason for a noise ﬁgure of lower than 3dB.
From the noise equation, all that can be optimized is the product of gmRp. The gm may be
raised to lower noise, but at the expense of more power consumption. Alternatively, for a given
gm, Rp may be increased, and converted to the desired resistance (in our example 2Rs) by
adjusting the matching network. To ﬁnd the upper limit for Rp, we need to understand what are
the consequences of increasing it:
A higher Rp results in more gain from the source to the ampliﬁer input, and thus worse
linearity.
Increasing Rp raises the matching network effective Q, which results in a smaller bandwidth
and more sensitivity to variations. Ultimately Rp is limited by the inherent Q of the
inductance used.
We showed before that to obtain an input resistance of RIN looking into the matching
network (Figure 7.42), the matching inductance is
L = RIN
ω0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs
RIN  Rs
r
:
If we assign a quality factor of Q  1 to the inductor, the total parallel resistance as a result is
Lω0Q. To avoid using an explicit resistor, we let the inductor loss be equal to Rp. Thus
CL
Rp
CIN
Rs
C
L
RIN
Figure 7.42: CS LNA with lossy matching
network
422
Low-Noise Ampliﬁers

Rp = Lω0Q = QRIN
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rs
RIN  Rs
r
:
To satisfy noise and matching we showed RIN = Rp
2 . This yields
Rp = Q2 + 4
2
Rs:
We also showed the total voltage gain from the source to the input is Q1
2 . So the upper limit to
Rp is simply determined by what kind of Q is acceptable or perhaps achievable for the matching
network.
If we choose a Q of 10, to allow the bandwidth to be roughly 10% of the center frequency,
then Rp is found to be 2.6kΩ. Moreover, there is a gain of 4.5 or 13dB from the source to the
input. Letting gmRp = 40, and assuming a short-channel device with an overdrive voltage of
200mV to allow sufﬁcient linearity (especially considering the large gain up front), the LNA
bias current is 3mA, and the noise ﬁgure is 2dB. In Chapter 6 we showed that with 200mV
overdrive the IIP3 of a single device is about 1V or 10dBm. Given the available voltage gain of
13 + 6 = 19dB in front, then we expect an IIP3 of about –9dBm for the LNA assuming it is
dominated by the input stage nonlinearity.
Note that the Q of 10 is not necessarily what is fundamentally achievable but what is
acceptable given the linearity and bandwidth requirements. The actual matching inductor in
fact consists of two components in parallel, the one that converts the impedance, and was
already calculated, and another part that needs to resonate with CIN, which we call LIN.
Assuming CIN = 1pF, then at 2GHz, LIN = 6nH. The total inductance is
1
Ltot
= 1
LIN
+ 1
L ,
which results in Ltot = 4.65nH. A parallel resistance of 2.6kΩ then implies an inherent Q of
45 for the inductor (substantially higher than 10), which is on the order of what external
inductors of this size can provide at 2GHz.
In this example, the matching network loss dominates the noise ﬁgure, and effectively it
matches its own loss. The 2dB noise ﬁgure may be improved if one of the feedback schemes
introduced earlier is incorporated to make up part of Rp as a noiseless resistor.
Let us assume there is a shunt capacitive feedback of CF between the input and cascode node.
The input impedance was calculated before, and is shown in Figure 7.43 (assuming gm
ωCF >> 1).
Using series–parallel conversion we have
YIN = jωCIN + 1
RP
+ jωCF +
2 + Cp
CF
gm
ωCF
ð
Þ2,
and we arrive at the equivalent model of the ampliﬁer input also shown at the bottom of
Figure 7.43.
The LNA noise ﬁgure is
F = 1 +
ZTH
j
j2
RP Re ZTH
½
 +
ZTH
gm + f
ð
Þ RPkZTHkZF
ð
Þ
				
				
2
2γgm
Re ZTH
½
 ,
7.8 LNA Power–Noise Optimization
423

where f =  jωCF is the feedback factor. As CF may be combined with the rest of CIN, and
assuming gm  ωCF, we have
F = 1 +
ZTH
j
j2
Rp Re ZTH
½
 + 1 + ZTH
RP
				
				
2
2γ
gm Re ZTH
½
 :
ZTH is the impedance looking into the matching network as a result of Rs upconversion (RIN in
Figure 7.42). This value is ﬁxed by the bandwidth and linearity concerns as we pointed out
earlier. The ﬁrst term in the noise equation is the impact of the matching network loss, and may
be reduced if Rp can be raised. To satisfy the S11 condition, the increase in Rp must be then
compensated by the term
2 +
Cp
CF
gm
ωCF
ð
Þ2 in the input impedance equation, which is a result of the
feedback. This assumes that a higher Q for the matching inductor is feasible. Now let us assume
the same current budget of 3mA, and hence a gm of 15mS. Furthermore, assuming a value of
25fF for CF, which is mostly made up of gate-drain capacitance, and that
Cp
CF = 6 (see
Figure 7.33), the parallel resistance as a result of the feedback is about 19kΩ. When compared
to the original values of 2.6kΩ for Rp, this indicates that the noise ﬁgure improvement is only
marginal unless CF can be raised substantially, or a higher gain for the matching network is
acceptable.
For a CS ampliﬁer using inductive degeneration, the equivalent input is shown in
Figure 7.44.
Rp
CIN
C
L
CF
Rp
CIN
CF
(2+CP/CF)/gm
CP
Rp
CIN
≡ 
CF
gm/(2+CP/CF)( CF)-2
w
Figure 7.43: LNA with lossy matching and capacitive shunt feedback
Rp
CIN
C
L
Rp
CIN
Cgs
Ls
T
Ls
≈ 
w
Figure 7.44: LNA with lossy matching and inductive degeneration
424
Low-Noise Ampliﬁers

Both Cgs and LsωT are expected to be larger than the corresponding values for the shunt
feedback, thus we expect a more favorable situation. For instance, if Cgs = 50fF, Ls = 0.5nH,
and fT = 100GHz, the net parallel resistor is now 8.5kΩ, which is roughly half of what we had
in the shunt feedback LNA (Figure 7.43), and thus a better noise ﬁgure is expected. Thus, the
total 2.6kΩ resistor is now made of a noiseless 8.5kΩ part in parallel with a noisy 3.75kΩ (as
opposed to 2.6kΩ before). Consequently, we expect a reduction in the LNA noise without
increasing the bias current.
7.9
SIGNAL AND POWER INTEGRITY
..............................................................................................
We have dedicated much of this chapter to dealing with the thermal noise of the resistors and
transistors, and ways to minimize this. Unfortunately, in a real environment this kind of noise
(call it intrinsic noise) is not the only source contaminating the LNA. In addition to the intrinsic
noise, there is usually extrinsic noise as well originated from blocks in the vicinity of the LNA
such as switching power supplies, crystal oscillators, or any digital circuitry with large activity.
This kind of noise can contaminate the sensitive block of interest through parasitic capacitive or
magnetic coupling, or through the power lines transient, effectively degrading the system
signal-to-noise ratio.
To remedy these issues, it is common among RF designers to use decoupling capacitors on
supplies, or use shielded lines to protect the sensitive blocks such as low-noise ampliﬁers or
oscillators. What is very important though is that if these techniques are not done properly,
very quickly they become ineffective or even harmful. For this reason we dedicate this section
to a deeper understanding of what is known as the signal or power integrity, essentially a
measure of the quality of the signal or power rails in the presence of the aforementioned
interference. For further reading see [5], [6], [7], [8], [9], [10], [11], [12]. Especially [5] has
very detailed discussions on coupling and shielding. In addition to noise pickup and shielding
concerns, an overview of electromagnetic waves and their impact on radios can also be found
in [6].
7.9.1
Power Lines
Shown in Figure 7.45, one may consider the following arrangement to connect the signal and
power lines to the ampliﬁer. The source is not necessarily close to the LNA. Often, it may be
external, say the antenna input that will be brought on-chip. This routing will have some
inductance and resistance associated with it. Similarly, the supply will be connected to the LNA
through some impedance, which is partially on-chip, and partially off-chip. These impedances
are represented with the gray RL circuits in the ﬁgure.
Often, RF designers forget that the notion of ground is nothing but a common reference point
for the entire circuit as taught to us in basic circuit theory.10 An alternative and more proper
10 Not to be confused with earth connection, which is primarily for safety reasons.
7.9 Signal and Power Integrity
425

deﬁnition for the ground would be a low impedance path for the current to return back to the
source. As such, as far as this discussion is concerned, the ground (or VDD) is simply treated
like any other signal connecting to the LNA.
The ampliﬁer naturally drains some transient high-frequency current from the supply, labeled
as ΔiVDD. This current must somehow go back to the supply, and KCL tells us that it must follow
the path shown in the ﬁgure (for the moment we ignore the current drained at the ampliﬁer input
from the source). As a result of this, there will be some voltage drop on the RL circuit
associated with the source (Δv in the ﬁgure), which will make the ampliﬁer input (vin) be
different from the actual source voltage (vs). In other words, the supply transient (noise) will
also appear at the input, and ampliﬁed along with the desired signal.
To avoid this, a better arrangement shown in Figure 7.46 may be considered. This way the
supply transient will not travel through the source parasitic impedance. Still, however, the
transient current will create voltage drop on the supply parasitic impedances, and depending on
the LNA supply rejection, it will translate to noise. To remedy this, one could consider adding a
decoupling capacitor placed physically close to the LNA (while the actual supply is often not).
Now the transient current will be supplied by the capacitor as long as its size is chosen properly,
rather the actual supply itself, and hence avoids the undesired voltage drop.
The decoupling capacitor itself must be carefully designed and modeled. It is obviously
naïve to expect having an ideal capacitor at GHz range frequencies. The parasitic inductance
(especially if the distance between the supply and ground ends of the LNA is long), and the
resistance associated with the routing could be problematic, and usually the notion of the larger
the decoupling capacitor, the better is not necessarily correct. If appropriate, one may consider
choosing the size of the capacitor to resonate with the parasitic inductance in series, creating a
near ideal short at the frequency of interest.
ΔiVDD
VDD
ΔiVDD
ΔiVDD
+
vin
–
vs
CL
–     Δv     +
Figure 7.45: Improper connection of the supply to an
ampliﬁer input
+
vin
–
vs
VDD
ΔiVDD
ΔiVDD
Cdecouplig
CL
Figure 7.46: Properly connected supply along with
decoupling capacitor
426
Low-Noise Ampliﬁers

We are yet to deal with the source parasitic impedance connecting to the LNA input.
Unfortunately, there is no easy way of eliminating that aside from common practices to
minimize the inductance and resistance. This often implies short and wide routing as much
as possible. Nonetheless, the impedances are present, and must be carefully modeled and
ultimately treated as a part of the ampliﬁer, for instance, lumped inside the matching network
if applicable. Some performance degradation in general is common, though all the parasitic
must be carefully modeled and minimized. A co-design with package/PCB may be often
needed to properly model the entire path.
7.9.2
Coupling and Shielding
There are two types of shielding common in RF:
– Shielding a noisy line to avoid it coupling to sensitive blocks
– Shielding a sensitive line to avoid picking up noise from the interfering blocks surrounding it
The concepts are similar, and will be brieﬂy explained here. We will consider both the
capacitive and magnetic coupling.
7.9.2.1 Capacitive Coupling
Shown in Figure 7.47 is simple demonstration of capacitive coupling from a noise source to the
desired block (represented by ZIN). This could arise from a number of reasons, most commonly
due to the signal and noise lines running side by side, with the coupling occurring due to the
stray capacitances. A simpliﬁed equivalent circuit is also shown in the ﬁgure.
The obvious way of reducing the coupled noise is to minimize the coupling capacitance,
which often requires increasing the physical separation between the noise source and the victim.
This, however, is not always possible due to ﬂoor planning constraints. Alternatively, the line
may be protected by placing it inside a metallic cage completely surrounding it, often known as
a Faraday cage, as shown in Figure 7.48. Similarly, the source of the noise may be shielded if
placed inside the Faraday cage. If the cage is completely closed, it need not be grounded, as the
electric ﬁeld inside the perfect conductor is always zero.
+
vin
–
ZIN
Common ground
ZIN
Noise Source
CC
Receiver
Capacitive Coupling Model
Noise Source
Desired signal path
Capacitive Coupling in Nearby Lines
Figure 7.47: Electrical coupling demonstration and a simple model
7.9 Signal and Power Integrity
427

If the cage has openings, as would be the case in an on-chip implementation, then the amount of
noise pickup would depend on its size, or its effective capacitance to ground [6]. If the cage is
physically large, it effectively acts like a ground, as it has a very large supply of charge that can easily
respond to an external disturbance. Otherwise, the cage may be grounded, in which case it allows the
charges to ﬂow freely on and off of the shield to maintain zero voltage on it. Consequently, with the
potential of the shield constant, the voltage pickup on the sensitive line remains zero.
The Faraday cage is obviously quite impractical to be implemented on-chip, though it can be
placed externally to protect the radio chip or other sensitive blocks. A common on-chip
implementation is shown in Figure 7.49, where the line to be shielded is sandwiched between
two metal layers connected to each other through a wall of vias. Since there is a minimum
spacing required between adjacent vias, the shield will not be perfect, and will have holes.
7.9.2.2 Magnetic Coupling
The side-by-side lines could also experience magnetic coupling, when the current of the noisy
line induces an electromotive force in the desired signal line through their mutual inductance.
Placing a conductive nonmagnetic shield around the desired line is absolutely ineffective at
shielding the magnetic ﬁeld as no current ﬂows in the shield. However, if the shield is grounded
in two points as shown in Figure 7.50, then given Faraday’s law, the noise current (in)
effectively creates an equal current but in the opposite direction in the shield (i2). The direction
of the shield current is determined according to Lenz’s law to be opposite, and if shield
resistance is small, it will be exactly equal to noise current. Note that it is this induced current
that effectively shields the signal, and not the shield itself. If the shield resistance is nonzero
(Rshield), the induced noise voltage is shown [6] to be around Rshieldin at RF.
Note that in the Figure 7.50 setup, not only is the ampliﬁer return path to the source coming
through the shield, but there is also a common ground connection that allows the shield current
ZIN
Noise Source
CC
Receiver
Faraday Cage
Figure 7.48: Shielding the desired signal using a Faraday cage
Vias
Shield
Figure 7.49: Coaxial shield implemented in an integrated circuit
428
Low-Noise Ampliﬁers

i2 to ﬂow. This common ground is often partially on-chip, and partially on PCB depending on
how far the source is. One potential concern is that this additional return path creates a large
loop (between the shield and the common ground), and is prone to pickup-interfering magnetic
ﬁelds. Consequently, a noise current is created in the shield that can potentially couple to the
signal line. This must be studied carefully depending on where the nearby interfering signals
are, how the coupling is created, and the situation of the common ground path. Another
important reason for not grounding at the other end is that we would like to force the return
current to be through the shielded line, and not through another lower impedance path.
Besides shielding, another common isolation technique is twisting the signal and its return
path, as shown in Figure 7.51. This is very effective as it reduces the area of the loop to which
the interfering magnetic ﬁeld can couple. Grounding both ends of the twisted pair may not be
wise, as it increases the area of the loop formed by the common ground line and the return path,
and negates the main beneﬁt.
The main limitation of the twisted pair wiring arises from the practical implementation, and
frequent cutoff throughout the line. It must be noted that the twisted pair can be further put
inside a shield, and thus enjoying extra beneﬁt of the shield as well (grounded at both ends like
shown in Figure 7.50).
Before we conclude, it must be emphasized that there is generally no unique recipe as to how
address the coupling and the shielding issues. Often the designer must painstakingly trace the
signal and return currents (basically the current ﬂowing through the ground line), and identify
which path is more desirable for the current to ﬂow, and force it accordingly by proper
placement of shield, and the relevant supply and ground connections.
7.9.3
Inductor Shield Case Study
Consider Figure 7.52, showing a 2-turn differential inductor using the top AP metal layer. The
standalone simulated differential inductance and quality factor are shown in Figure 7.53,
vs
+
vin
–
ZIN
Common ground
i1
i2
vn
in
Noise
Figure 7.50: Shielded ampliﬁer
input signal with connection at
two ends
ZIN
Common ground
Figure 7.51: Twisted pair with balanced
currents
7.9 Signal and Power Integrity
429

denoted by the black solid curves. The inductance at 5GHz is 1.06nH, and the EMX simulated
quality factor is 20.4.
Also shown in Figure 7.52 is a 5μm wide AP line running in parallel to the inductor 100μm
away, carrying an AC interfering signal. The 1nH inductor is resonating with a 1pF capacitance
at 5GHz as shown in the ﬁgure. The parallel line is also terminated by CL = 100f, carrying an
AC current of I1 = 2π  5  109  100f, assuming a 1V AC source. Ignoring the metal ring
around the inductor for the moment, the interfering current in turn induces a magnetic ﬁeld, and
consequently another current in the inductor that is measured differentially at the inductor
245mm
100mm
50mm
CL
1pF
I1
I2
Figure 7.52: 1nH differential inductor with
a source of coupling
Q
10
20
Frequency, GHz
L, nH
0.6
0.8
0.4
1.0
1
10
5
15
5
No ring
1.2
50 m
30 m
Frequency, GHz
1
10
5
50 m
30 m
No ring
Figure 7.53: Inductance and Q for the cases of inductor with and without shield
430
Low-Noise Ampliﬁers

terminals. Obviously the larger the CL, the larger the induced current, and hence the differential
voltage at the inductor output.
Shown in Figure 7.54 is the simulated differential voltage at the inductor output, which is
about –27dBc relative to the 1V AC voltage source, effectively representing the coupling form
the aggressor to the differential inductor, or the victim.
Next, we include a 5μm-wide AP layer shield around the inductor. Two cases are simulated,
the ring 50μm away from the inductor edge, and another case of only 30μm away (only the
50μm ring is shown in the ﬁgure). The EMX simulations of the inductance and the Q with the
ring are also depicted in Figure 7.53. The inductance is reduced by as much as about 8%,
whereas the Q drops to 18.1 for the case of the ring 30μm away, which is still a respectable Q at
5GHz. What is more interesting is the impact of the ring on the coupling. Due to the presence of
the ring, the interfering current I1 induces a magnetic ﬁeld, which according to Faraday’s law
creates an emf in the ring. The electromotive force when divided by the line resistance creates
another current in the ring of I2 in the opposite direction according to Lenz’s law. This current
creates a magnetic ﬁeld in the opposite direction, which partially cancels the interfering ﬁeld
and shields the inductor. The coupling for the two cases with the ring is also shown in
Figure 7.54. If the ring is placed close enough to the inductor, the two ﬁelds almost perfectly
cancel each other, reducing the coupling signiﬁcantly. The compromise is in the Q reduction
and in many cases may be well worth it. Essentially, the main trade-off the designer facing is
how close the ring needs to be, which primarily deﬁnes the Q degradation versus the coupling
improvement. There may be of course physical area constraints as well depending on the
overall chip ﬂoorplan.
The shield may or may not need to be connected to the local ground. Of course depending on
where it is grounded, and how many taps are there, the results could be affected, but it won’t
change the overall positive impact the shield has in protecting the inductor from picking up
nearby interfering signals. In most cases, connecting the shield to the ground is unnecessary.
7.10 LNA DESIGN CASE STUDY
..............................................................................................
To conclude this chapter, an inductively degenerated common-source 5.5GHz LNA in 16nm
CMOS is presented as a case study.
Coupling, dB
–80
–60
–100
–40
Frequency, GHz
1
10
5
50mm
30mm
No ring
Figure 7.54: Simulated coupling for the cases
of inductor with and without shield
7.10 LNA Design Case Study
431

Shown in Figure 7.55 is the LNA schematic with the components values. The transistors use
a channel length of 20nm (as opposed to minimum 16nm), and are biased at 3mA, correspond-
ing to gm = 40mS, and Cgs = 35fF. The transistors are biased close to weak inversion (an
overdrive voltage of about 65mV); nonetheless, they enjoy a transit frequency of about
fT = 180GHz. The cascode transistor is biased at VDD = 800mV, and given VTH = 320mV,
leaves about 400mV headroom for each NMOS. The combination of 10k resistor and 10p
capacitor provides supply ﬁltering. Obviously the gate of the cascode NMOS must be well
bypassed to avoid any instability, which is accomplished by the 10p capacitor to ground.
The core transistor is biased through a replica current mirror (not shown in the ﬁgure), along
with the 100k resistor and 4p AC coupling capacitor. The value of resistance is chosen large to
minimize its noise contribution.
The LNA simulated performance is shown in Figure 7.56.
With Ls = 400pH, the effective real part of the input impedance is about gmLs
Cgs = 457Ω, which
comes in series with Cgs. The simulated input impedance of the LNA is 160Ω  j470Ω,
however. The difference is attributed to the main transistor Cgd, which is about 15fF, and
0.8V
1nH, Q=8
0.4nH, Q=8
Lg
4p
10k
100k
10p
0.8p
10p
Bias
M1
M2
50f
Figure 7.55: Inductively degenerated common-source
LNA in 16nm CMOS
Frequency, GHz
10
20
30
1
2
3
4
10
0
–10
5
Gain
S11
NF
Figure 7.56: Simulated performance of the LNA
of Figure 7.55
432
Low-Noise Ampliﬁers

creates a shunt feedback around the transistor, effectively lowering the input impedance. This
impedance is matched to 50Ω through a shunt C-series L matching network. The matching
network is left ideal to show the LNA inherent performance. The simulated noise ﬁgure is
0.26dB, but it will be far worse once all the parasitic capacitances and a more realistic
matching network are utilized. Nevertheless, it demonstrates the superior noise ﬁgure of this
topology. The theoretical noise factor F = 1 + γLsCgsω2 leads to a noise ﬁgure of about 0.1dB,
but there are several factors raising this to the actual simulated value: noise contribution of the
cascode device, the ﬁnite Q of the load and source inductances, as well as other parasitic
elements within the transistor.
The simulated gain of the LNA is high, about 33dB, which is set by the load inductance, and
the gain of the matching network. The latter is relatively high, about 15dB, which justiﬁes the
relatively narrow S11. This can be improved by raising the source inductance to increase the
effective real part of the impedance, but comes at the expense of worse noise ﬁgure. It must be
noted that the design is not optimized, and is just an example of how the theory and practice
match in reality.
7.11 Summary
This chapter has discussed the theory and design procedure behind low-noise ampliﬁers.
– Section 7.1 discussed the matching networks and their properties. Matching is an essential
part of any RF ampliﬁer, and especially the LNAs.
– In Section 7.2 we gave a brief overview of RF ampliﬁers topologies and their pros and cons.
– Sections 7.4 and 7.5 discussed the general categories of the LNAs, namely shunt and series
feedback low-noise ampliﬁers. In both topologies, lossless feedback is exploited to satisfy
the conﬂicting impedance and noise matching requirements.
– Feedforward LNAs were presented in Section 7.6.
– Practical design and layout concerns in LNAs were discussed in Section 7.7.
– A general discussion on the LNA power consumption and the trade-offs involved was
offered in Section 7.8.
– Practical concerns originating from signal and power integrity of the ampliﬁer were dis-
cussed in Section 7.9. While this discussion was presented in the context of low-noise
ampliﬁers, the conclusions are general and apply to any building block of the radio.
– The chapter was concluded in Section 7.10 by presenting a simple case study highlighting
the design details of an inductively degenerated CS LNA.
7.12 Problems
1. Find the transfer function, noise spectral density of the following matching network with
and without using the Nyquist theorem. Answer: SvIN ω
ð Þ = 4KTRs
Lω
ð
Þ2
Lω
ð
Þ2 + Rs2.
7.12 Problems
433

Rs
vs
vIN
RIN
Rs
L
w
2. For the matching network of Figure 7.5:
a. Calculate the values of L and C to match RIN > Rs to the source.
b. Find the transfer function and output noise spectral density of the matching network.
c. Argue how that differs from the matching circuit of Figure 7.4.
3. Find the noise ﬁgure of the following complementary shunt-FB LNA. Ignore the capaci-
tances, but not the inverter ro. RF is noisy. Also for simplicity, assume gmro  1, and
gmRF  1, where gm is the inverter transconductance, and ro is its output resistance.
Answer: F  1 +
γ
1 + RF
ro
.
RF
4. Find the noise ﬁgure of a common-gate LNA with an ideal transformer of 1 : n at its input.
Use the gm–ID curve provided in Chapter 6 to determine the device DC current. Propose a
proper LC matching circuit to approximate the transformer. n = 4, and the frequency of
operation is 2GHz.
5. Repeat Problem 4, with a 4 : 1 transformer. Discuss the pros and cons of each case.
6. Derive an expression for the noise ﬁgure of a common-gate LNA versus the input reﬂection
coefﬁcient.
7. Find the minimum noise ﬁgure and the optimum noise source impedance for a common-
gate LNA.
8. Calculate the noise ﬁgure of a resistive shunt feedback LNA without using feedback
method.
9. Find the noise ﬁgure and gain of a cascode common-gate LNA, without ignoring the cascode
noise and gain loss. Assume no body effect and ro for the cascade, but nonzero capacitances.
10. Find the equivalent input noise sources of an inductively degenerated CS LNA. Assume
the LNA is matched to 50Ω. Hint: Use the circuit of Figure 7.28, and ﬁnd the input noise
sources such that the output current is nulled.
11. Show that if the inductively degenerated CS LNA (Figure 7.28) is driven by an ideal
voltage source, its output noise is zero.
12. Ignoring the cascode transistor and load noise, show that if an inductively degenerated CS
LNA is driven by an ideal voltage source, the output noise is zero.
434
Low-Noise Ampliﬁers

13. Using the gmID and IIP3 curves provided in Chapter 6, design a cascode LNA with proper
matching at 2GHz. The matching network available gain is 4. Assume Cdb = Csb = Cgd =
0.5Cgs, and the devices have an overdrive voltage of 100mV, and fT of 20GHz. Assume
matching network components have inﬁnite Q. What is the LNA IIP3?
14. As discussed in Section 7.7, in most practical inductively degenerated LNAs, due to the
close vicinity, the source (L1) and drain (L2) inductors are often mutually coupled to each
other. In this problem, we explore the impact of coupling between the source and drain
inductors on the LNA gain, input impedance, and tuning. Consider both cases of negative
and positive mutual inductance (M). Intuitively, explain the variation of gain and input
impedance for positive and negative coupling based on the feedback theory. Neglect ro and
all the capacitances expect for the main device gate-source and the load capacitance. The
degeneration inductor is otherwise ideal, whereas the drain inductor has a ﬁnite Q. Hint:
To simplify the analysis, assume the coupling is small, and thus its impact on the inductors’
original current (with no coupling), IL1, and IL2 is negligible.
15. To ﬁnd the power spectral density of distributed gate resistance, we break the transistor
into N identical devices, each with N times lower gm and gate resistance, as shown
below [4].
7.12 Problems
435

Show that for a given segment, ini = gmi
Pi
k = 1vnk (i = 1, . . ., N). Assuming that the input-
referred noise sources are uncorrelated, ﬁnd the total output current noise spectral density.
What is the equivalent input-referred noise voltage if N ! ∞?
16. Using current steering, design a variable-gain LNA with gain steps of –3, –6, and –12dB
from the maximum. Find the ratio between the device sizes.
17. For the common-gate LNA, derive simple expressions for the case that the LNA compres-
sion is set by the input. Compare the results with the case where the compression is set by
the output as derived in Section 7.5. Which one is likely to dominate? Hint: For the LNA
to be compressed at the input, IDC + is = 0.
18. In the shielded line of Figure 7.50, derive expressions for the shield current versus the noise
current based on the mutual inductances between the noisy line, the shield, and the signal
line. Find the induced noise voltage for both a zero resistance shield, and the case of a
nonzero resistance.
19. Consider a CS LNA with two cases of RC and LC loads. Assuming a ﬁxed total capacitance
at the LNA output for each case, show that the inductive load has about Q times higher gain
than the RC load.
7.13 References
[1] B. Nauta, “A CMOS Transconductance-C Filter Technique for Very High Frequencies,” IEEE Journal of
Solid-State Circuits, 27, no. 2, 142–153, 1992.
[2] P. R. Gray and R. G. Meyer, Analysis and Design of Analog Integrated Circuits, John Wiley, 1990.
[3] F. Bruccoleri, E. Klumperink, and B. Nauta, “Wide-Band CMOS Low-Noise Ampliﬁer Exploiting
Thermal Noise Canceling,” IEEE Journal of Solid-State Circuits, 39, no. 2, 275–282, 2004.
[4] B. Razavi, R.-H. Yan, and K. Lee, “Impact of Distributed Gate Resistance on the Performance of MOS
Devices,” IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications, 41, no.
11, 750–754, 1994.
[5] H. W. Ott, Noise Reduction Techniques in Electronic Systems, vol. 442, John Wiley, 1988.
[6] A. M. Niknejad, Electromagnetics for High-Speed Analog and Digital Communication Circuits,
Cambridge University Press, 2007.
[7] P. Brokaw, “An IC Ampliﬁer User’s Guide to Decoupling, Grounding, and Making Things Go Right for a
Change,” Analog Devices Application Note AN-202, 2000.
[8] P. Brokaw and J. Barrow, “Grounding for Low- and High-Frequency Circuits,” Dialogue, 18, 1, 1984.
[9] A. Rich, “Shielding and Guarding,” Analog Dialogue, 17, 8–13, 1983.
[10] A. Rich, “Understanding Interference-Type Noise,” Dialogue, 11, 10–16, 1977.
[11] H. W. Ott, “Ground – A Path for Current Flow,” in Proceedings of the IEEE International Symposium on
Electromagnetic Compatibility, 1979.
[12] H. W. Ott, “Digital Circuit Grounding and Interconnection,” in Proceedings of the IEEE International
Symposium on Electromagnetic Compatibility, 1981.
436
Low-Noise Ampliﬁers

8
Mixers
By this point we have established the need for mixers in a radio, which is to provide frequency
translation, and consequently to ease analog and digital signal processing by means of
performing them at a conveniently lower frequency. Since the frequency translation is created
due to either time variance or nonlinearity, or often both, the small signal analysis performed
typically on linear ampliﬁers does not hold. This makes understanding and analysis of the
mixers somewhat more difﬁcult. Although exact methods have been presented, in this
chapter we resort to more intuitive yet less complex means of analyzing the mixers. In most
cases this leads to sufﬁcient accuracy but more physical understanding of the circuit.
We present both active and passive mixers, and in each case discuss the noise and linearity
trade-offs based on physical models, mostly from the receiver point of view. We dedicate a
section at the end to upconversion mixers, although very similar in principle, as well.
The speciﬁc topics covered in this chapter are:
• Mixers’ basic requirements
• Active mixer operation
• Noise, linearity, and second-order distortion in active mixers
• Passive mixer operation
• Noise, linearity, and second-order distortion in passive mixers
• LO duty cycle optimization
• M-phase and harmonic-rejection mixers
• Transmitter mixers
• LNA/mixer practical design example
For class teaching, we recommend covering Section 8.1, as well as active and passive mixer
basic operation (initial parts of Sections 8.3 and 8.4). A qualitative discussion may also be
offered from the material presented in Section 8.8.
8.1
MIXERS FUNDAMENTALS
..............................................................................................
Before getting into the details of mixer circuit realization, let us ﬁrst have a short introductory
discussion of the basis of mixer operation from a black box system perspective. We shall also
discuss the general realization and the basic deﬁnitions in Section 8.1.2.

8.1.1
Mixer Operation from System Point of View
The exact role of a mixer in radios is best understood from the earlier discussion in Chapter 2.
We shall recast a summary ﬁrst in here, and present a somewhat broader perspective.
As almost all wireless transmitters produce signals around a high-frequency carrier (for the
reasons discussed in Chapter 2), a shift in frequency is often needed to delegate as much analog
and digital signal processing as possible to a conveniently lower frequency. As we showed, a
shift in frequency is equivalent to multiplying by ej2πf0t in the time domain, that is,
x(t)ej2πf0t $ X( f ∓f0),
where x(t) (either a voltage or a current) is the baseband signal. Shown in Figure 8.1 is a typical
RF signal spectrum, located around a carrier frequency of fC. Since the signal is real, its
spectrum is symmetric with respect to the y-axis,1 or positive and negative frequencies.
However, most practical RF signals are not symmetric with respect to the carrier frequency,2
and so it has been shown as such. If this signal is multiplied by ej2πf0t, it experiences a shift to
the left, as shown in the ﬁgure. That is due to the fact that the spectrum is convolved in the
frequency domain with an impulse at f0, representing the Fourier transform of ej2πf0t.
A lowpass ﬁlter wide enough to pass the entire shifted or downconverted spectrum now
located at fC  f0, known as intermediate frequency or IF, is often applied to remove the
component at fC  f0. This leaves us with a now lower frequency version of the original RF
signal, located at the intermediate frequency, as desired.
The main challenge of actually realizing the simple concept described above is the fact
that the signal ej2πf0t needed to shift the RF spectrum is not real. Using the Euler identity, one
may write
ej2πf0t = cos 2πf0t  j sin 2πf0t.
Accordingly, the shifting signal, ej2πf0t, is composed of a sine and a cosine, both of which
are real, and readily synthesizable. Depicted in Figure 8.2 is the RF signal multiplied (in the
time domain) by individual sine and cosine functions.
Either signal consists of two impulses at f0, with half the magnitude now. The half
magnitude results in signal loss, and thus performance degradation in general, but may or
may not be an issue, as it is often retrievable by employing either RF and/or IF ampliﬁcation.
The presence of two impulses, however, complicates the matters, as around DC a folded replica
of the shifted RF spectrum, basically its exact mirror image, presides as well. If fC  f0 is small
with respect to the signal bandwidth,3 the two replicas overlap, and are no longer distinguish-
able. Consequently, unless the IF is high enough to avoid the signal mixing with its image,
shifting or downconverting by either a sine or cosine alone is not possible. To avoid this issue,
the arrangement depicted in Figure 8.3 is often employed, leading to two versions of the
downconverted spectrum, labeled as I (in-phase), and Q (quadrature). Equivalently, this scheme
1 If x(t) is real, then X(f ) = X∗( f ).
2 Even though it may appear to be so when viewed on a spectrum analyzer. As discussed in Chapter 2, a symmetric spectrum
around the carrier leads to spectrum and transmission power inefﬁciency.
3 Many modern receivers employ fC  f0 = 0, known as zero-IF or direct-conversion receivers.
438
Mixers

0
f
fc
–fc
e–j2pf0t
0
f
fc–f0
–fc–f0
0
–f0
1
Figure 8.1: RF signal centered around carrier frequency of fC, multiplied by ej2πf0t
0
f
fc
–fc
cos(2pf0t)
0
f
fc – f0
0
f
fc
–fc
sin(2pf0t)
1/2
–fc+f0
fc+f0
–fc – f0
1/2
1/2
1/2
0
f
fc –f0
–j/2
–fc+f0
fc+f0
–fc –f0
+j/2
–j/2
+j/2
0
f0
–f0
–j/2
+j/2
0
f0
–f0
1/2
1/2
Figure 8.2: RF signal multiplied by real functions realized by sine and cosine
sin
cos(2pf0t)
(2pf0t)
I – jQ
e–j2pf0t
RF Signal
I
Q
Figure 8.3: Quadrature downconversion employed in most
modern radios to avoid signal mixing with its image
8.1 Mixers Fundamentals
439

realizes an ideal shift through ej2πf0t, if a collective combination of the I and Q signals (or to be
precise, I  jQ) is processed.
Example: As a useful exercise, let us consider Figure 8.4, where the I and Q channels
resulting from the quadrature downconversion (Figure 8.3) are further processed through
a pair of Hilbert transform units and adders.
We assume the original RF signal is of the general form shown already in Figure 8.1. As
discussed earlier, the Hilbert transform multiplies the positive frequency contents of the
spectrum by –j, and the negative components by +j. Hence, for instance, the Hilbert
transform of a cosine becomes a sine, as is evident from Figure 8.2 as well. Consequently,
the outputs after addition/subtraction look like what is shown on the right side of Figure 8.4.
Both spectrums are real, and thus symmetric, as they should be. Addition however results
in only the high side (with respect to carrier or fC) of the ideal shifted spectrum (see
Figure 8.1), whereas subtraction extracts the low side of the spectrum. Compared to the
spectrum of the ideal shifted signal (Figure 8.1), both spectrums in Figure 8.4 are real.
Furthermore, unlike shifting by sine or cosine only, the signal and its mirror image no
longer overlap. Even though the Hilbert transform is noncausal in general, as pointed out in
Chapter 2, it could be well approximated over a limited range of frequencies.
The above example is the basis of what is known as image-reject receiver, which we shall
analyze in more detail in Chapter 12.
8.1.2
Mixer Basic Circuit Operation
Ideally, a mixer needs to preserve the signal in its entirety, without adding any noise or
distortion of its own, and translate it only in the frequency domain. In practice, since almost
all mixers are transistor-based, they add both noise and distortion. As in any LTI system, the
input and output frequencies are the same; the frequency translation may only be achieved
through time variance or nonlinearity.
Hilbert
+
+
Hilbert
+
–
I
Q
High Side
Low Side
0
f
fc–f0
–fc+f0
0
f
fc–f0
–fc+f0
hQ(t) = 1/pt
Figure 8.4: Extracting the low- and high-sidebands through a Hilbert transform
440
Mixers

Given the inherent nonlinearity of any transistor-based circuitry, it is not difﬁcult to conceive
how one can create the frequency translation needed. Consider Figure 8.5, which represents a
general nonlinear system where two arbitrary inputs are applied.4
Suppose the signal applied to the port labeled RF is A1 cos(ω1t), and the other signal to the
LO port is A2 cos(ω2t). The signals are added and passed through a nonlinear system whose
input–output characteristic is y = a1x + a2x2 + a3x3. Then x = A1 cos(ω1t) + A2 cos(ω2t). As we
established in Chapter 5, the output consists of several terms, of which most will diminish after
lowpass ﬁltering, except for the difference term created due to the 2nd-order nonlinearity
assuming that ω1–ω2 « ω1 and ω2:
y =    + a2(A1 cos(ω1t) + A2 cos(ω2t))2 +    =    + a2A1A2 cos(ω1 ∓ω2)t +   .
Thus, only a component at ω1–ω2, that is, the difference between the RF and LO frequencies,
passes through the narrow LPF, and appears at the output. This is exactly what is needed to
realize a downconversion mixer. The mixer gain would be the ratio of the output amplitude to
that of the RF port, that is, a2A2. Thus, it depends not only on how strong the 2nd-order
nonlinearity is (i.e., a2), but also on the signal applied to the LO port.
Example: Any circuit with strong 2nd-order nonlinearity, such as a long channel FET
(Figure 8.6), could potentially be a mixer.
If the device is square-law, ignoring the bias details, the AC component of the output
voltage is
Continued
∑ 
y
x
y = a1x + a2x2 + a3x3
RF
LO
IF
IF
LO
RF
Figure 8.5: A nonlinear system acting
as a mixer
v1(t)=A1cosw1t
RL
vo
v2(t)=A2cosw2t
VDC
Figure 8.6: A long-channel FET operating as a mixer
4 A more generalized case would be in the form of y = f(RF,LO), as opposed to y = f(RF + LO). In that case the
multivariable Taylor series must be used instead.
8.1 Mixers Fundamentals
441

vo = 1
2 μCOX
W
L RLA1A2 cos ω1  ω2
ð
Þ =
1
2 μCOX
W
L RLA2


A1 cos ω1  ω2
ð
Þ:
Thus, the circuit is indeed behaving as a mixer whose gain is 1
2 μCOX W
L RLA2. Since an
exact squarer function is not needed to realize the mixer, the FET could have been replace
by a BJT, in which case the gain would have been 1
2
IS
VT 2 RLA2, where IS is the BJT
saturation current and VT = KT
q . The gain dependence on the LO amplitude as would be
the case for the simple mixer of Figure 8.6 is not desirable, and as we will show
momentarily, in most cases is eliminated by proper design of the LO port.
If instead of a LPF, a BPF tuned to ω1 + ω2 were to be used to select the component at the
sum frequency, the circuit would have acted as an upconversion mixer.
We expect the mixer then to be a three-port network, two inputs that are mixed, and one
output that is the result of frequency conversion. We label the main input as RF (radio
frequency), and the output as IF (intermediate frequency), whereas the second input terminal
would be the LO (local frequency). However, this convention applies only to downconversion
mixers.
As we saw in Chapter 6, the nonlinearity is often what we try to avoid, and thus it is often the
case that the mixer would rely on time variance, rather than nonlinearity. A good mixer is the
one that performs the frequency translation without imposing much noise or distortion on the
signal. How good the mixer needs to be is entirely a function of the radio speciﬁcations and the
application, as long as we can represent the mixers with typical known circuit properties such as
noise ﬁgure or IIP3.
We often treat a good mixer, then, as a linear but time-variant circuit with respect to its input
(RF) and output (IF) ports. That is, for example when doubling the RF amplitude, we expect the
amplitude of the IF signal to double as well. Obviously for the simple circuit shown in
Figure 8.5, this would be the case in spite of the fact that its very operation is based on
nonlinearity. As pointed out, however, most modern mixers rely on time variance, more so than
nonlinearity, to create the frequency translation. For that reason, they are all based on some
form of voltage or current switching.
8.2
EVOLUTION OF MIXERS
..............................................................................................
Mixers have been around before the invention of transistors, as a part of tube-based radios.
Shown in Figure 8.7, a structure commonly known as a diode-ring mixer relies on Schottky
diodes to act as fast switches, which result in frequency translation given the inherent time
variance of any switching circuitry.
The input and output signals are attached to transformers connected to the ring, whereas a
differential LO signal is applied to the center tap of the transformers. For the one half cycle
where LO is high, D2 and D4 are on, but D1 and D3 are off, and the output is equal to the input,
whereas for the next half cycle, where D1 and D3 are on, the positive–negative terminals of the
input and output are reversed. Thus, the output will be equal to the input signal, multiplied by
442
Mixers

P(t) as shown in Figure 8.7. The minimum required amplitude of the LO is then equal to diode
VON, to ensure that they turn on properly. Expanding P(t) using Fourier series we have
P tð Þ = 4
π
sin ωLOt  1
3 sin 3ωLOt + 1
5 sin 5ωLOt    


,
which consists of a fundamental at the LO frequency, as well as its odd harmonics. Assuming
the input signal is A sin ωRFt, and that the output is tuned to |ωRF  ωLO| to ﬁlter all undesired
terms, the mixer output is
2
π A cos ωRF  ωLO
ð
Þt:
Thus, the mixer has a conversion gain of 2
π, which is less than one, but is independent of the LO
amplitude, as long as it is large enough to turn the diodes on and off comfortably. In fact the LO
signal does not need to be a square-wave, if its slope is sharp enough during the transition from
one half cycle to the other. Moreover, the circuit is linear with respect to the input–output ports.
It wasn’t until 1968, well after the invention of the transistors and integrated circuits, that a
group of researchers at MIT proposed the idea of using a FET as a switch rather than the diode
[1] as shown in Figure 8.8.
The mixer operates exactly the same way as the diode ring circuit, except for the LO signals
are conveniently applied directly to the gate of the FETs. Moreover, the FET is a better switch
and thus results in a more linear mixer. Particularly, unlike diodes, one can completely shut
LO–
LO+
Input
Output
D1
D2
D3
D4
LO
–1
+1
>VON
P(t)
Figure 8.7: A diode-ring mixer
LO–
LO+
Input
Output
Figure 8.8: A FET-based mixer
8.2 Evolution of Mixers
443

down the FET if the proper voltage is applied. All passive mixers are fundamentally a variation
of this topology.
Also in 1968, Barrie Gilbert published his landmark paper [2], describing a precise four-
quadrant analog multiplier whose simpliﬁed diagram is shown in Figure 8.9.
Two sets of differential currents are applied to the multiplier on the left, where each may be
produced by a linear differential pair as shown on the right. We assume that the devices are
matched, that they have a perfect exponential characteristics, and that β is high. By writing
KVL we have
VBE1  VBE2 = VBE3  VBE4 = VBE5  VBE6.
Since for each transistor VBE = KT
q ln IE
IS, we arrive at
IE1
IE2
= IE3
IE4
= IE5
IE6
= 1 + x
1  x :
Writing KCL yields
IE1 + IE2 = 1  y
ð
Þ IE
2
IE3 + IE4 = 1 + y
ð
Þ IE
2 :
Solving for the three equations above results in Q1–4 as a function of input currents fed to the
multiplier:
IE1=2 = 1  x
ð
Þ 1  y
ð
Þ IE
4
IE3=4 = 1  x
ð
Þ 1 + y
ð
Þ IE
4 :
Io
(1–y)IE/2
(1+y)IE/2
(1+x)IB/2
(1–x)IB/2
Q1
Q2
Q3
Q4
Q5
Q6
VX+
VX–
IE
(1+y)IE/2
(1–y)IE/2
Simplified Gilbert Multiplier
Generation of Differential Current
Figure 8.9: Gilbert four-quadrant multiplier
444
Mixers

Since the differential output current is
Io = (IE2 + IE3)  (IE1 + IE4),
deﬁning z = Io
IE as the normalized output current, we arrive at
z = x  y.
What is remarkable about this design, and perhaps the reason for its longevity, is that a very
nonlinear I–V characteristic of a BJT is exploited to create a perfectly linear multiplier. If x and
y are the RF and the LO signals, the output z after lowpass ﬁltering will be the IF signal,
creating a mixer. The dependence on the LO voltage is eliminated by applying the proper signal
to the LO port as we will show in the next section. Almost all active mixers used today are
based on this topology or some variation thereof.
The main distinction between the passive and active mixers as described in Figure 8.8
and Figure 8.9 has to do with the fact that in one case an AC voltage (or current) is
being commutated by the switches, whereas in the other case a combination of small AC
and a large DC current is applied to the switching circuitry. A good analogy to this is
static CMOS logic to the current-mode logic (CML), where the latter is found to be much
more superior in terms of speed. This more or less applies to the mixers, as the active
mixers tend to operate at higher frequencies, since the passive-based topologies require
sharp rail-to-rail LO signals for proper operation. However, as we will show, passive
mixers appear to be more superior in terms of noise and linearity, as long as the switches
operate properly.
8.3
ACTIVE MIXERS
..............................................................................................
Active mixers rely on the concept of current switching. Let us start with the rearrangement of
the Gilbert multiplier of Figure 8.9 redrawn in Figure 8.10.
Instead of feeding a voltage created by the diode-connected pair Q5–6 to the base of core
transistors (nodes VX+ and VX), we apply a square-wave-like signal as shown on the right,
large enough to steer the emitter current abruptly from one device to the other at each zero
crossing. To understand this better, consider Figure 8.11, showing an emitter-coupled pair
whose I–V characteristics are shown on the right.
Io
VX+
VX–
(1–y)IE/2
Q1
Q2
(1+y)IE/2
Q4
Q3
VX+
»2VT
VX
Figure 8.10: A simpliﬁed Gilbert mixer
8.3 Active Mixers
445

From basic analog design [3], we know
Io = IEE tanh VX
2VT
,
where VX = VX+  VX is the differential input, and VT = KT
q . For values of |VX| > 2VT, most of
the current is steered from one device to the other due to the tanh sharp transition, and the
output current approaches IEE. Thus, in the time domain, once a voltage applied to the
differential pair with an amplitude large enough compared to 2VT  50m, an almost square-
wave current is created at the output. The current toggles between IEE, regardless of the shape
and amplitude of VX. Thus under such conditions
Io  4
π IEE
sin ωLOt  1
3 sin 3ωLOt + 1
5 sin 5ωLOt    


,
where VX is assumed to be at the LO frequency. In practice, the emitter current consists of a
large DC component, along with a small AC signal as a result of the input RF voltage,
IEE = 1  y
ð
Þ IE
2 = 1  A cos ωRFt
ð
Þ IE
2 ,
where we assume y = A cos ωRFt is the RF input (note that A is unit-less). If the DC quiescent
current is large, or equivalently if the amplitude of the RF voltage is small, as is the case in most
practical situations, the switching is mostly unaffected. Thus, ignoring other harmonics except
for the fundamental, the output current is
Io = 4
π 1  y
ð
Þ IE
2 sin ωLOt,
and once the second pair consisting of Q3–4 is added (Figure 8.10) to realize the fully differen-
tial circuit, the terms at fLO cancel as a result of subtraction at the output, whereas the terms
consisting of the RF inputs add up, leading to
z = Io
IE
= 4
π y  sin ωLOt = 2
π y cos ωRF  ωLO
ð
Þ
½
:
Consequently, the linear mixer function whose gain is independent of the LO signal is created.
The mixer is said to be double-balanced, as neither the LO nor the RF inputs feed through the
VX+
VX–
Q1
Q2
Io
IEE
|VX|>>2VT
Io
VX
Io
IEE
–IEE
2VT
t
Figure 8.11: An emitter-
coupled pair and its
I–V curve
446
Mixers

output. If the pairs are not matched, or the input is not perfectly differential, there is a small feed
through, which is usually unimportant as it is subject to output ﬁltering since in most cases:
ωRF  ωLO  ωRF and ωLO .
An MOS version of the Gilbert mixer is created upon the same principle, and is shown in
Figure 8.12.
Keeping the same notation as the BJT pair, for a MOS differential pair [3]
Io = 1
2 μCOX
W
L VX
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4IS
μCOX W
L
 VX2
s
,
where IS is the source-coupled pair current. The current is completely steered from one device
to the other if
VX
j
j =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2IS
μCOX W
L
s
=
ﬃﬃﬃ
2
p
Veff :
Thus, as long as the LO voltage is large enough compared with
ﬃﬃﬃ
2
p
Veff , the mixer functions as
described before, and the conversion gain is
2
π gmRL,
where gm is the input pair (M1–2) transconductance.
The mixer operation may be understood better if it is broken into three distinct functions:
1. The input V–I converter, which consists of a pseudo-differential pair. Any variation of that,
such as one with degeneration or a true source-coupled pair with a current source, may be
chosen (Figure 8.13), although the one shown in Figure 8.12 is the most common choice for
its simplicity, and gives the best compromise between headroom, noise, and linearity.
2. The switching quad (devices M3–6) commutates the RF current.
3. The load performs the I–V conversion. The load also may be active or passive.
Each of these stages potentially contributes to the mixer noise and nonlinearity, and will be
discussed next.
+       vo       –
+vin/2
–vin/2
LO+
LO+
LO–
I0+gmvin/2
I0–gmvin/2
RL
VDD
V–I
I–V
Switching
M1
M2
M3
M4
M5
M6
Figure 8.12: A double-balanced MOS
active mixer
8.3 Active Mixers
447

One ﬁnal note: as most antennas are single-ended, producing a differential RF voltage,
whether at the LNA input or output, requires an extra transformer that comes at a cost. If the
LNA output happens to be single-ended, then a single-ended version of the Gilbert mixer
known as a single-balanced mixer may be used (Figure 8.14). The output is still differential, and
in perfect matching conditions, the RF feedthrough is eliminated.
However, there is an LO feedthrough appearing at the output that is to the ﬁrst order
independent of the LO, as we already calculated before,
4
π RLI0 sin ωLOt,
where I0 is the input device bias current. The feedthrough may be removed only through IF
ﬁltering. Another drawback of the single-balanced scheme is that any noise or interferer at the
LO port appears at the output.
8.3.1
Active Mixers Linearity
We will present here only a qualitative discussion on active mixers linearity and IIP3. A more
rigorous analysis may be found in [4].
Consider the simpliﬁed mixer schematic shown in Figure 8.15. The load is typically not a
major nonlinearity contributor if designed properly, and particularly if it is resistive. The
switches also do not contribute much to the overall nonlinearity provided that the output and
+vin/2
–vin/2
M1
M2
Switching Quad
+vin/2
–vin/2
M1
M2
Switching Quad
2I0
Figure 8.13: Different variations of the input V–I converter
vin
+    vo    –
VDD
LO+
LO–
Figure 8.14: A single-balanced active mixer
448
Mixers

the LO DC biases are chosen such that for the half cycle that a given switch is on, it remains in
saturation to ensure that the lower transconductance devices are well isolated from the output.
The parasitic capacitance at the common source of each switching pair (Cp in Figure 8.15)
must be minimized. Speciﬁcally, one must ensure that gm34
Cp 	 ωLO. In modern nanometer
CMOS processes this condition is comfortably met for most GHz RF applications.
The transconductance stage appears to set the bottleneck. A detailed analysis of IIP3 of a FET
was presented in Chapter 6. To a 1st-order approximation, if designed properly, and assuming
that the devices stay in the intended region of operation, that will set the mixer IIP3. The latter
condition may be difﬁcult to be met, as the active mixer consists of at least three stages stacked,
and the headroom may be a challenge. Nevertheless, achieving an IIP3 of better than 1V
(or 10dBm) is possible, and has been reported for 1.2V supply voltages in the literature.
8.3.2
Active Mixers 1/f Noise Analysis
We deal with the noise contribution of each section of the mixer separately, and offer a physical
model to capture the noise with sufﬁcient accuracy [5].
Load  Noise in the output load does not suffer frequency translation, and competes directly
with the signal. Fortunately, this noise may be lowered in one of many ways. If a PMOS active
load is used, the device channel length must be chosen sufﬁciently large to reduce the 1/f noise
corner below the frequency of interest. Alternatively, at the expense of some voltage headroom
the mixer may be loaded with polysilicon resistors, which are free of ﬂicker noise.5
Input FETs  Noise in the lower transconductance FETs accompanies the RF input signal,
and is translated in frequency just like the signal is. Therefore, ﬂicker noise in these FETs is
upconverted to ωLO and other odd harmonics, while white noise at ωLO (and other odd
harmonics) is translated to DC. If the output of interest lies at or around zero IF, then the
transconductance FETs contribute only white noise after frequency translation, since the ﬂicker
corner of these devices is usually much lower than the LO frequency. Due to mismatches in the
LO+
I0
M1
M3
M4
ZL
VDD
…
 
LO–
ro
Must Remain in Sat.
Cp
Minimized
Figure 8.15: Active mixer nonlinearity contributors
5 This is not generally true, as the polysilicon resistors have been shown to have 1/f noise [28], [29]. However, in most cases
it may be ignored, as we choose to do throughout this chapter and the entire book.
8.3 Active Mixers
449

switching transistor quad, a small amount of the ﬂicker noise in the transconductance FETs can
appear at the loads. This is dealt with at the end of this section.
Switches  Consider the simpliﬁed double-balance balanced mixer in Figure 8.16. The
switch FETs M3–4 and M5–6 carry a bias current varying at a frequency ωLO. Flicker noise
arises from traps with much longer time constants than the typical period of oscillation at
RF, and it may be assumed that the average inversion layer charge in the channel determines
the RMS ﬂicker ﬂuctuations. Thus, these charge ﬂuctuations are referred to as a voltage to
the gate of one FET (say M3), with a non-time-varying RMS value and a spectral density
varying as 1/f (vn in Figure 8.16). Roughly speaking, this equivalent voltage may be thought
of as a slowly varying offset voltage associated with differential pair. It should be noted that
based on the carrier-density ﬂuctuation model, the input-referred ﬂicker noise of MOSFETs
is independent of the gate voltage. This has been experimentally veriﬁed for NMOS
transistors [6], [7].6
To simplify analysis, it is also assumed that a sine-wave drives the switches, and that the
circuit switches sharply, that is, a small differential voltage excursion (Vid) causes the current
(iod) to completely switch from one side of the differential pair to the other side (Figure 8.16).
Furthermore, as the noise transfer function to the output is linear (but time-variant), the
superposition holds. Thus, it is sufﬁcient to analyze the noise of one switch, and simply
multiply the result by four as all the noise sources are uncorrelated.
First consider the direct effect of the switch noise at the mixer output. The transconductance
section of the mixer may be replaced by a current source, I, at the tail. In the absence of noise,
for positive values of LO signal, M3–6 switch on and M4–5 switch off, and a current equal to
I appears at each branch, although no net current appears at the output due to the subtraction of
M3 and M6 currents. In the next half period, M4–5 are switched on and carry a current I. Once
noise is included though, the slowly varying vn modulates the time at which the pair M3–4
switches (Figure 8.17). Now at every switching event the skew in switching instant modulates
the differential current waveform at the mixer output. The height of the square-wave signal at
the output remains constant, but noise modulates its zero-crossing, by Δt = vn
S, where S is the
AsinwLOt
M3
M4
M5
M6
ion
vn
I
I
Vid
Iod
I
–I
«A
AsinwLOt
–AsinwLOt
Figure 8.16: 1/f noise model for mixer switches
6 In more recent CMOS processes this may not hold anymore. See [29] for more details. Nonetheless, to gain some insight
we make the assumption that the 1/f noise is not a strong function of the bias, which seems to be reasonably accurate.
450
Mixers

slope of LO signal at zero-crossing. The waveform at the mixer output then consists of a train of
pulses with width of Δt and amplitude of 2I and a frequency of 2ωLO (Figure 8.17).
Over one period the output current has an average value equal to
ion = 2
T  2I  Δt = 4I
vn
S  T ,
where T is the period of LO equal to 2π/ωLO. This means that the low-frequency noise at the
gate of switch, vn, is directly transferred to the output and will compete with a signal down-
converted to zero IF. The zero-crossing offset in the time domain, Δt, depends on the low-
frequency noise, vn, and the LO sine-wave slope, S. For a sine-wave LO signal, the slope is
equal to 2AωLO, where A is the amplitude of the LO. Thus, the base-band 1/f component
appearing at the output can be easily calculated to be
ion = I
πA vn:
To ﬁnd the complete spectrum of the mixer output noise, we notice that since Δt
T  1, the pulses
may be approximated with ideal impulses of amplitude of 2IΔt
S , and twice the LO frequency,
sampling the mixer noise (Figure 8.17). The resulting spectrum at the mixer output is then
easily obtained based on sampling theory, and is shown in Figure 8.18. It should be noted that
since noise pulses have a frequency of twice the LO frequency, noise spectrum is repeated at
2ωLO and its other even harmonics.
If such a mixer is used for upconversion, then there will be no ﬂicker noise contribution from
switches, as it can be seen from Figure 8.18, but the ﬂicker noise of transconductance stage will
be directly upconverted and appear at ωLO.
Δt
vn
Time
Time
vn
Δt
2I
vn
Time
T/2
Train of Impulses
Figure 8.17: Switch input
voltage and mixer output
current
8.3 Active Mixers
451

This analysis is also used to answer the earlier question about ﬂicker noise originating in the
transconductance devices, which leaks through switch FETs unbalanced by an offset. The noise
voltage vn is replaced with an offset voltage, VOS, and the ﬂuctuations of interest are in the
current I. The mixer output current is now a train of pulses of constant offset in its zero-
crossings, VOS/S, whose height is modulated by the noisy current, gmvni(t), where vni is the
input-referred ﬂicker noise of the transconductance FET, and gm 
I
Veff is the short-channel
transconductance of input FETs (Figure 8.19).
The low-frequency noise component is equal to
ion = 4I VOS
S  T = 4gmvni
VOS
S  T = I
πA vni
VOS
Veff
:
If it is assumed in comparing the two noise equations that the noise voltages are of a similar
order of magnitude, then switch noise is clearly more important as usually VOS  Veff. Note that
in the equation vni can also represent any kind of low-frequency interferer coupled to the mixer
input, such as the low-frequency noise on the ground line.
If the slope of the LO is increased to inﬁnity, that is, if a perfect square-wave is applied, the
mixer ﬂicker noise does not diminish entirely, rather is limited by the parasitic capacitance at
the common source of each switching. This indirect mechanism is analyzed in [5], and is
typically not a dominant factor as the slope of the LO in reality is never that large unless at very
low frequencies where the parasitic capacitances are not important.
8.3.3
Active Mixers White Noise Analysis
A similar analysis as the one presented for 1/f noise of switches may be extended to the
white noise.
Intuitively, we know that switches contribute noise at the mixer output in the time interval
when they are both on. That is because when one switch is on and the other one is off, clearly
the off switch contributes no noise. The on switch also cannot produce any noise current at the
f
≈ 
0
2fLO
I/pA×vn(f)
Figure 8.18: Mixer output noise spectrum
Time
Δt=VOS/S
gmivni
Figure 8.19: Flicker noise of input devices due
to switching pair offset
452
Mixers

mixer output as its drain current is ﬁxed by the bias current I produced by the input devices
(Figure 8.16). Thus, the output noise is effectively a result of the input-referred noise of each
switch, multiplied by a sampling function P(t), as shown in Figure 8.20.
The width of P(t) is approximately the time window that both switches are on, and its
frequency is twice the LO frequency. The exact shape of P(t) depends on the LO signal
characteristics, but can be well approximated if the LO amplitude is large, and the switching
is sharp, as is the case in most switching mixers. We can approximately ﬁnd the width and
height of the pulses if we assume a linear response for each switching pair during which they
are open as shown in Figure 8.21.
If the excursion that the switches are both open is ΔV, then in time domain the pulse width
must be ΔV/S, S being the slope of the LO signal. To keep the area of each pulse constant, the
height is then 2I/ΔV. This approximates the I–V response of the pair (Figure 8.16) fairly well,
and may be employed to gain some insight into mixer noise (and the 2nd-order nonlinearity as
we will discuss in the next section) mechanisms. However, as we will show momentarily, the
exact shape of the LO, and the switching pair I–V response is not as important as long as the
switching is abrupt.
To generalize, we can say
ion(t) = P(t)  vn(t).
Since the switches’ input-referred noise is white, and P(t) is a deterministic periodic function,
the resultant mixer output noise is white and cyclostationary (see Chapter 5). Consequently,
consistent with our derivations in Chapter 5, the spectral density of each switch noise will be
4KTγ, sampled by |P(t)|2 = gm(t), where gm(t) is the effective transconductance of each
switching pair (see Problem 9 for more details.). The average output noise spectral density
is then
vn
Time
Time
T/2
P(t)
LO
Figure 8.20: Mixer noise due to switches’
white noise
Vid
Iod
I
–I
ΔV«A
Figure 8.21: Simpliﬁed switching pair I–V response
8.3 Active Mixers
453

Sion = 4KTγ 1
T
ð
T
Gm tð Þdt = 8KTγ
T
ð
T=2
∂io
∂vLO
dt = 8KTγ
T
ð
T=2
∂io=∂t
∂vLO=∂t dt:
Without loss of generality, let us choose our reference time to be at t = 0. In the case of abrupt
switching, the mixer output current is a square-wave toggling between I at every zero
crossing. Thus, for the particular zero crossing at t = 0, ∂io
∂t may be approximated as
∂io
∂t ﬃ2Iδ tð Þ,
where δ(t) is the Dirac impulse function. Consequently, the integral simpliﬁes to
Sion = 8KTγ
T
ð
T=2
2Iδ tð Þ
∂vLO=∂t dt = 4KTγ
4I
S  T ,
where S = ∂vLO
∂t

t = 0 is the slope of the LO at zero crossing as deﬁned earlier. The switch white
noise spectral density comes out to be independent of LO waveform shape or switch size,
assuming abrupt switching. This is very similar to the 1/f noise results calculated earlier based
on the approach taken from [5]. For a sinusoidal LO, the spectral density of the output noise is
Sion = 4KTγ I
πA :
A more rigorous approach presented in [8] leads to a similar result assuming the LO amplitude
is large.
Next, we shall ﬁnd the noise contribution of the input FETs. The white noise of the FETs
downconverts to the IF along with the signal, as shown in Figure 8.22.
For the case of high-side injection, for instance, the signal is present only at fLO – fIF,
whereas noise appears at both sidebands of the fundamental, fLO  fIF, as well as all its odd
harmonics as shown in Figure 8.22. If we ignore the higher order harmonics for the
moment, the presence of signal at only one sideband leads to a factor of 2 or 3dB worse
SNR after the downconversion, as the white noise is inevitably present at both sides. This is
known as single side-band (SSB) noise ﬁgure. On the other hand, if a receiver is capable of
rejecting the image at the unwanted side-band after downconversion, such as a quadrature
receiver, the noise is removed as well, and the SNR is preserved. This is referred to as
double side-band noise ﬁgure.
fIF
fLO–fIF
fLO+fIF
fLO
3fLO
1
1/3
f
Figure 8.22: Mixer noise due to input FETs’ white noise
454
Mixers

For the general case, the total output noise spectral density due to one input FET is
Sion = 4KTγgm
2
π
 2
2 
1 + 1
32 + 1
52 +   




= 4KTγgm,
where 4KTγgm is the noise current spectral density of the input FET, 2
π is the current conversion
gain, and the last term signiﬁes the contribution of all the harmonics: the white noise at ωLO  ωIF
downconverted by the main harmonic of the LO, the white noise at 3ωLO ωIF downconverted
by the third harmonic of the LO whose amplitude is one-third of the main harmonic, and so forth.
Notice that LO is not necessarily a square-wave signal; however, due to the hard switching action
in the mixer, it will effectively perform as a square-wave. Particularly, the factor 2 arises from
SSB noise. It is interesting to note that the noise current of the input FET appears exactly intact at
the mixer output, whereas the signal is subject to a loss of 2
π. This is because the square-wave-like
LO downconverts the white noise at all harmonics, whereas the signal of interest lies only at a
speciﬁc sideband of the fundamental. This, along with the extra noise contribution of the
switches, is why mixers tend to be noisier than linear ampliﬁers.
The output noise spectral density could have been obtained intuitively without any of the
calculations above. Due to the hard switching, the output noise current is always
ion =  1  in, gm.
Thus
Sion = |1|2Sin, gm = Sin, gm = 4KTγgm.
When all the noise contributors added up, the mixer output noise spectral density will be
Sion = 2  4KTγgm + 4  4KTγ I
πA + 2  4KT
RL
,
where we assume the mixer is loaded with a resistance of RL. Since the current conversion gain
is 2
π gm, the noise ﬁgure with respect to a source resistance of RS is
F = 1 +
π2
4
gmRS
γ + 2γ
gm
I
πA +
1
gmRL


:
Assuming a transconductance of gm 
I
Veff for the short-channel input FET, and ignoring the
passive load noise contribution,
F  π2
4
Veff
RSI γ 1 + 2Veff
πA


:
The relative noise contribution of the switches to that of the transconductance FET is equal to
2Veff
πA . This means that as the overdrive of transconductance FET becomes close to LO amplitude,
switches contribute a comparable noise to what is contributed by the transconductance stage.
This clearly displays the trade-off between noise and linearity in active mixers: In linear mixers
a large overdrive (to enhance the linearity of the transconductance FET) with approximately
small LO swing (to keep the switch transistors in saturation) is desirable, which boosts the
relative noise contribution of the switches.
8.3 Active Mixers
455

Example: To improve linearity and enhance gain, and to avoid headroom issues, one may
choose an active load for the mixer as shown in Figure 8.23.
The device channel length must be large enough to lower the 1/f noise corner of the
PMOS load sufﬁciently. Nevertheless, the load may contribute signiﬁcant white noise.
The modiﬁed noise ﬁgure is (noise of RL ignored)
F  π2
4
Veff
RSI γ 1 + Veff
Veffp
+ 2Veff
πA


,
where Veffp is the PMOS load overdrive voltage. At low supply voltages, the PMOS
overdrive must be kept low to ensure it stays in saturation, and as a result the active load
will add as much or possibly more noise than the input FETs.
While the mixer thermal noise ﬁgure enjoys similar trade-offs as those of linear ampliﬁers, the
switches’ ﬂicker noise can be improved only by either increasing the LO amplitude or reducing the
switches input-referred noise. There are fundamental limitations to either option: the LO amplitude
is limited by the supply, while the switches’ input noise may be improved only by using bigger
devices, which has frequency response consequences.
Example: Considering that the output 1/f noise is
ion = I
πA vn:
One may suggest lowering noise through reducing the mixer bias current. However, this
is not a viable choice, as lowering the current degrades the signal as well. On the other
hand, if the switches’ bias current is lowered without considerably affecting the signal, we
can break the fundamental barrier of lowering the 1/f noise.
This goal may be accomplished by either one of the two active mixer topologies shown
in Figure 8.24, which we will discuss as case studies.
LO+
LO+
LO–
RL
VDD
M1
M2
M3
M4
M5
M6
CMFB
Figure 8.23: Mixer with active load
456
Mixers

In the left scheme, two constant currents of αI (α < 1) are fed to the input FETs, which
are biased at a constant current of I. This is not going to impact the input FET
transconductance, so we expect the signal gain to remain the same. However, the
switches’ DC current is lowered to (1  α)I, and so is their 1/f noise contribution. There
are two drawbacks to this approach: First, the current sources add their own white noise,
although they reduce 1/f noise. If they have a similar overdrive as the input FETs, as a
result the mixer white noise is raised by a factor of (α + 1). Second, reducing the switches’
bias effectively lowers their transconductance, and thus part of the input current produced
by the input FET is going to be wasted in the parasitic capacitance at the common source
of the switches (CP in Figure 8.24).
A better approach is to reduce the bias current of the switches only when needed through
a dynamic switching scheme as shown on the right side of Figure 8.24 [9]. We notice that
the switches contribute noise only when they are both on, or right around the zero-
crossings. Thus, we inject a dynamic current equal to I only at every zero-crossing. To
do so, we take advantage of the full-wave rectiﬁed input voltage present at the common
source of the switches as shown in Figure 8.24. This voltage is low right around zero-
crossing, and once fed to a cross-coupled PMOS pair, it turns on the top current source, and
a current of I is injected to each switching pair. Away from zero-crossings, the voltage is
high, and consequently the PMOS devices are off. Fabricated in 130nm CMOS, and biased
at 2mA from a 1.2V supply, this mixer achieves 11dB white noise ﬁgure when referred to
50Ω, and a 1/f noise corner of as low as 10kHz [9]. The input IP3 is 10dBm, showing the
fundamental limits of active mixers given the headroom and bias current trade-offs.
8.3.4
Active Mixers 2nd-Order Distortion
The mixer 2nd-order distortion can be analyzed very much through the same approach as we
took for 1/f noise. Besides the input stage and switches as potential contributors, there is yet
another mechanism caused by the feedthrough of the input voltage to LO ports. We shall study
each of these cases below, and defer to [10] for a more detailed analysis.
I
aI
CP
I
2I
Figure 8.24: Active mixer topologies with enhanced 1/f noise performance
8.3 Active Mixers
457

We must emphasize that, in a double-balanced mixer, 2nd-order distortion is always can-
celled when the output is taken differentially. Thus, in theory fully differential mixers have
inﬁnite IIP2. In practice, however, the mismatches cause a ﬁnite IIP2. Nonetheless, we expect
the IIP2 to vary from one sample to the other, and thus it must characterized statistically.
RF Self-Mixing ─Due to parasitic capacitive or magnetic coupling, the RF input voltage to
the mixer leaks to the LO port and appears as a differential voltage in series with the LO as
shown in Figure 8.25. Thus, the mixer downconverts the input RF signal with a composite LO
consisting of the original desired LO, as well as the superimposed RF leakage. Note that the
coupling from RF to LO is not generally differential, but given the common-mode rejection, we
would consider only a differential coupling here.
Let us assume that the coupling coefﬁcient is α « 1. With a similar rationale as the one we
used for the mixer noise, it is clear that self-mixing happens only during the window that both
switches are on, in which case the switching pair acts as a linear ampliﬁer, and whose current is
being modulated by the input RF voltage.
Thus, we deﬁne the sampling function, P(t), as shown in Figure 8.25 exactly as we
had before (Figure 8.20). During the on window, the effective transconductance gain of the
pair is
2I
ΔV = 2
ΔV I0 + gmvin
ð
Þ,
where ΔV is the switching pair input excursion (Figure 8.21). Thus, the output current caused
by self-mixing will be
io =
2
ΔV I0 + gmvin
ð
Þ


2αvin
ð
Þ:
However, this current is scaled by the window that the switches are on, that is, Ts
T=2. Thus the
2nd-order coefﬁcient of the output current is
a2 = 4α
ΔV gm
2Ts
T
=
8α
S  T gm:
The fundamental coefﬁcient is a1 = 2
π gm, as before. Thus, the IIP2 is
IIP2 = a1
a2
= S  T
4πα ,
AsinwLOt
–AsinwLOt
vIN
avIN
−avIN
Time
T/2
P(t)
1
Ts=ΔV/S
I0+gmvin
Figure 8.25: RF self-mixing
458
Mixers

and for a sinusoidal LO of amplitude A,
IIP2 = A
α :
Besides increasing the LO amplitude or its slope, to a 1st-order all that can be done is to
improve isolation to reduce α.
Input FET 2nd-Order Nonlinearity ─As it is very common to incorporate a pseudo-
differential pair for the input transconductance stage, a strong 2nd-order component is expected
to be present. The IM2 component, however, is at DC or around 2fLO, and thus ideally appears
at fLO at the output when mixed with the LO. However, very similar to the 1/f noise argument,
any mismatches in the switching pair results into low-frequency IM2 current to leak to the
output, and to ultimately set an upper limit for IIP2 (Figure 8.26).
In Chapter 6 we showed that a square-law FET creates a 2nd-order component,
1
2 βvin
2,
where β = μCOX W
L. The leakage current gain as a result of offset was found to be 4 VOS
ST in the
previous section. Thus the 2nd-order coefﬁcient is
a2 = 2β VOS
S  T ,
and the IIP2 is
IIP2 = Veff
VOS
S  T
π
= 4A Veff
VOS
,
where Veff is the input FET overdrive voltage. Evidently, we face very similar trade-offs as with
the 1/f noise.
Switching Quad ─The rigorous analysis of the switches is very lengthy in math, and is
presented in [10]. To summarize, the switches contribute mainly as a result of the parasitic
capacitances at their common source, and in the presence of mismatches. So their contribution
is dominant only at high frequencies, and can be improved by reducing the parasitic capaci-
tances at the common source of each pair.
AsinwLOt
–AsinwLOt
vIN
VOS
IM2
Figure 8.26: Transconductance stage 2nd-order distortion as a
result of offsets in switches
8.3 Active Mixers
459

Example: As another case study, we will discuss two schemes that are variations of the
original Gilbert cell, and are intended to boost IIP2 and 1/f noise performance of the mixer
[11], [12] (Figure 8.27). Both circuits are fully differential, while only half are shown.
In the left scheme, the RF self-mixing is improved by proper layout, and to avoid the
input FET 2nd-order nonlinearity, the device has been heavily degenerated. However, in
order not to affect the mixer gain and noise ﬁgure, the source degeneration is bypassed at
the frequency of interest by a shunt capacitor. With those precautions, the main contribu-
tor remains to be the switches’ high-frequency 2nd-order distortion. That has been
handled by resonating the switching pair common-source parasitic capacitance (CP) with
an inductor at 2fLO. The reason for choosing 2fLO is that there are two zero-crossings for
every cycle, and thus, similar to 1/f noise, we expect the IIP2 events to be at a rate of 2fLO.
The main drawback of this approach is the need for additional inductors, and that the
resistive degeneration takes a large headroom. Nevertheless, the mixer achieves an IIP2 of
+78dBm [11]. The latter issue is resolved by incorporating a common-mode feedback that
monitors the output 2nd-order distortion and injects a low-frequency current to the
switches to negate that. Since the common-mode current is heavily bypassed, it does
not affect the mixer regular performance.
8.4
PASSIVE CURRENT-MODE MIXERS
..............................................................................................
The passive mixers rely on on/off switches that dissipate no power. The notion of passive,
however, is somewhat misleading, as there are typically several active circuits associated with
the passive mixer that lead to a nonzero power dissipation.7 Moreover, to enhance the mixer
LO
…
CP
CMFB
C→∞ 
2fLO
LO
…
CP
C→∞ 
2fLO
Figure 8.27: Active mixer topologies with enhanced IIP2
7 In most RF applications, given the stringent performance requirements, this is true. However, using the passive gain and
employing resonance, it is possible to realize a true passive mixer [31]. This has been exploited in certain applications such
as wireless sensors, where extremely low power transceivers are needed.
460
Mixers

performance, the switches require sharp, rail-to-rail waveforms that generally lead to more
power consumption in the LO delivery circuits compared to active mixers.
As we discussed earlier, there are two fundamental drawbacks with the active mixers: modest
linearity due to several devices stacked and poor 1/f noise. Both of these issues can be avoided
if the active mixer is redesigned as shown in Figure 8.28.
As we said before, the active mixer consists of a transconductor stage that coverts the voltage
to current, the switching quad, and a load (passive or active) that converts the current back to
voltage. All three stages are stacked, which not only results in poor linearity, but also forces a
DC current passing through the switches, leading to poor 1/f noise. If the three stages are
cascaded instead as shown in Figure 8.28, both of these issues are resolved. Particularly,
placing a blocking capacitor in the signal path ensures that the switches are biased at zero
DC current, and thus for most practical purposes, this passive mixer arrangement is free of
ﬂicker noise. Thus, a fundamental difference between the active and passive mixers is that the
latter commutate the AC signal (whether it is a current or voltage) only.
If desired, the blocking capacitor may be removed and a common-mode feedback (CMFB)
circuitry may be incorporated to ensure that the DC level of the two sides of the switches are
equal, and thus they carry no DC current (Figure 8.29). Moreover, the V–I stage may be
combined with the low-noise ampliﬁer (known as low-noise transconductance ampliﬁer or
LNTA for short) as long as it can be ensured that the ampliﬁer operates in the current mode.
This largely has to do with the speciﬁc design of the stage following the mixer switches that
convert the current to voltage.
Ideally, a transimpedance ampliﬁer (TIA) is needed to take the input current and convert to
voltage, and, more importantly, to present a very low input impedance to the mixer switches
(Figure 8.29). This is required to guarantee that the mixer operates in current domain. As we
will discuss in Section 8.5, in the case of a voltage-mode passive mixer, the situation is the
opposite: the buffer following the mixer needs to present a high impedance circuit to ensure
voltage-mode operation.
LO+
LO–
LO+
ZIN≈0
V–I
LO+
LO+
LO–
M3
M4
M5
M6
I–V
V–I
I–V
Active Mixer
Passive Mixer
M3
M4
M5
M6
Figure 8.28: Active mixer to passive current-mode mixer evolution
8.4 Passive Current-Mode Mixers
461

In the next few sections, we will study the mixer performance more closely. Before that,
however, we would like to have a general discussion on the type and speciﬁcally the duty cycle
of the LO signal used to drive the mixer. There are several options, some of which are not as
optimum or as powerful. Consequently, once the less common ones are ruled out, we will focus
only on the more practical structures throughout the rest of this chapter.
8.4.1
LO Duty Cycle Concerns
Consider a single-ended ideal current source driving a current mode mixer connected to an ideal
TIA as shown in Figure 8.30.
Let us assume that the general waveform shown in Figure 8.31 is applied to the gate of each
switch. We assume the waveforms are periodic with a period of T, and are differential, meaning
that LO2 is half period shifted with respect to LO1. We assume that the LO waveforms may
have an overlap time of τ. If τ is negative, it will represent a case of nonoverlapping or negative
overlapping LO signals as shown in the ﬁgure.
In the case of overlapping clocks, for the period of time T/2 < t < T/2 + τ, both switches turn
on, resulting in the RF current splitting equally in half and appearing at both branches of the
output as shown in the right side of Figure 8.30. When taken differentially, this results in no
output current. On the other hand, for the nonoverlapping LO case, there is the same time
duration τ, where both switches are off and no current appears at the output.8 Thus, in either
case the output current io is equal to the source RF current, is, multiplied by the effective LO
waveform shown in Figure 8.31. A simple Fourier analysis shows that the fundamental of the
effective LO signal is
4
π cos ωLOτ
2
sin ωLOt  ωLOτ
2

	
,
LO+
LO–
LO+
LNTA
TIA
CMFB
Figure 8.29: Complete schematic of a current-
mode passive mixer using CMFB
8 Although it appears that this is in violation of KCL, in practice the current ﬂows through the parasitic paths at the mixer
input. We shall discuss this shortly.
462
Mixers

where ωLO = 2π
T is the LO angular frequency. Thus, when multiplied by a sinusoid RF input and
lowpass ﬁltered at the output to take only the difference frequency component, the mixer
conversion current gain, AI, will be
AI = 2
π cos ωLOτ
2
,
which is maximum for zero overlap, or equivalently for an LO with exactly 50% duty cycle.
A lower or higher duty cycle will result in the RF current to either not appear at all, or appear as
common-mode at the output.
The situation will be different if the mixer is used in a quadrature receiver. In Chapter 2 we
saw that single-sideband generation in transmitters require quadrature mixers to upconvert the
baseband quadrature components around carrier. Similarly, as we have discussed already and
will show in more detail in Chapter 12, detection of such signals requires a quadrature
downconversion path, as is shown in Figure 8.32.
The corresponding LO waveforms are shown in Figure 8.33. Each LO signal is shifted by
T/4, or π/2, and thus the pair LO1–3 represent the differential I LO signals, whereas the pair
LO2–4 represent the differential Q LO signals. As before, we have assumed an arbitrary overlap
time of τ.
For negative τ or effectively less than 25% duty cycle for each signal, the analysis has been
already carried out. Given there is a period of time that all four switches are off, the mixer
conversion gain is expected to go down.
Let us then consider the case that τ > 0, that is, there is a nonzero overlap as shown in
Figure 8.33. Consider the differential current ﬂowing through the I+ branch TIA: For τ < t < T/4,
TIA
(ZIN=0)
LO1
LO2
io
is
i1
i2
is
RSW
RSW
is/2
is/2
During Overlap
Figure 8.30: Single-
balanced current-
mode mixer
LO1
LO2
0
VDD
1
0
VDD
–1
0
0
T/2
T
0
T/2
T
Negative Overlap
Positive Overlap
t
t
Effecve LO
Figure 8.31: Mixer LO
waveforms with arbitrary
overlap
8.4 Passive Current-Mode Mixers
463

only LO1 is on, resulting in the entire RF current to appear at the TIA. At t = T/4, LO2 turns on,
and from this point on until t = T/4 + τ, both I+ and Q+ switches are on, resulting in the RF
current split in half into each branch. At t = T/4 + τ, the I switch turns off and no current
appears at the output till the rest of the period. For the beginning portion, 0 < t < τ, the RF
current also splits in half, but this time between the I+ and Q– branches. A similar situation
happens for the I– branch for the time period T/2 < t < 3T/4 + τ, resulting in an effective LO
RF gm
LOI
LOQ
I
Q
TIA_I
(ZIN=0)
LO1
LO3
ioI
is
TIA_Q
(ZIN=0)
LO4
ioQ
LO2
Quadrature Receiver
Quadrature Mixer Model
Cp
Figure 8.32: Quadrature mixers in a typical receiver
LO1
LO2
0
VDD
1
0
VDD
–1
–1
0
Effective LO
LO3
LO4
0
VDD
0
VDD
½ 
0
T/2
T
T/4
t
LO1
LO2
0
VDD
1
0
VDD
0
Effective LO
LO3
LO4
0
VDD
0
VDD
0
T/2
T
T/4
3T/4
3T/4
Overlapping LO Signals
Ideal LO Waveforms
Figure 8.33: LO waveforms in a quadrature mixer
464
Mixers

waveform shown in Figure 8.33 for the I branch. Fourier series analysis of this waveform
results in a fundamental LO signal of
2
ﬃﬃﬃ
2
p
π
cos ωLOτ
2
cos ωLOt  ωLOτ
2
 π
4

	
,
and thus the current conversion gain is
AI =
ﬃﬃﬃ
2
p
π cos ωLOτ
2
:
A 50% duty cycle LO in this case corresponds to an overlap of τ = T/4, which leads to a
conversion gain of 1/π. It is clear that the conversion gain is maximized for τ = 0, or a 25% duty
cycle LO signal, resulting in waveforms with a quarter of a period duration, progressively
shifted by quarter of a period, as shown on the right side of Figure 8.33. The mixer gain and
consequently noise ﬁgure both improve by 3dB as a result [13]. Note that the total area under
each waveform is the same, but the staircase-like shape of the overlapping LOs results in a
smaller portion of the sine being integrated, thus less conversion gain. Alternatively we could
say that the overlap cancels the signal, but not the noise.
A simulation of an actual 40nm passive mixer for each of the cases discussed is shown in
Figure 8.34. There is close agreement between our ﬁndings and the simulations. However, in
the case of less than 25% duty cycle for the IQ case (or less than 50% for the I only case), the
mixer gain does not drop as steep as what would have been predicated by the equation.
The explanation for this is as follows: During no overlap time, when all four switches are
disconnected, in the ideal setup, the RF current has nowhere to go, and the signal is entirely lost.
In a practical case, however, there is a parasitic capacitance (as well as a resistance) at the
output of the current source due to the switches’ junction or gate-source capacitance, as well as
the gm cell output parasitic (Figure 8.35). During this time, the RF current source charges this
capacitance almost linearly, and once any of the switches are turned back on, this charge is
delivered to the output, retrieving some of the signal loss.
–12
–9
–6
–3
0
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
Duty Cycle, %
I Only
IQ
2/p
√2/p
1/√2p
Conversion Gain, dB
Figure 8.34: Simulated mixer conversion for
various LO duty cycles
8.4 Passive Current-Mode Mixers
465

There are several other disadvantages associated with overlapping LO signals, and 50% duty
cycle waveforms. Generally speaking, the overlap results in a cross-talk between the I and
Q branches, or effectively appearance of an image current circulating between the two paths.
This cross-talk will cause further degradation in the mixer noise and linearity beyond the 3dB
loss of gain showed earlier. For these reasons, throughout the rest of this chapter we will
consider only passive mixers with exact no overlapping clocks, which are practically used in
almost all transceivers. A detailed discussion of 50% mixers and the issues associated therewith
can be found in [14].
One drawback of 25% mixers is the need for 25% quadrature LO signals whose waveforms
were shown in Figure 8.33. This in practice may be done by applying the AND function to any
of the two consecutive signals available in a 50% quadrature LO signal as shown in Figure 8.36.
A shift register can also be used with less delay between clock edge and LO edge, which is
fundamentally better for phase error and jitter [15], [16]. While the simplicity of the structure
shown in Figure 8.36 may justify its popularity for a 4-phase mixer, a shift register may be more
prominent if more than four phases are desired, as we will discuss next [17].
Although a more complex LO generation potentially leads to more power consumption, the
advantages of the 25% mixers are overwhelming enough to justify such extra power dissipation
for most cases. Moreover, the additional LO generation circuitry comprising AND gates or shift
registers is completely scalable by the technology.
Finally, the size of the inverter buffers driving the switches’ gate must be chosen such that
the overlap is minimized including the process and temperature variations. A small amount of
Cp
TIA_I
(ZIN=0)
ioI
is
TIA_Q
(ZIN=0)
ioQ
t
Δv ≈  t × is/Cp
Figure 8.35: Parasitic capacitance at the gm
output leading to less conversion gain loss
÷ 2
25%
50%
LO1
LO2
LO3
LO4
Figure 8.36: Using AND gates to create 25%
LO signals
466
Mixers

no overlap where all switches are disconnected is generally acceptable, as the signal loss will be
very small. On the other hand, overlapping must be avoided to prevent the aforementioned
cross-talk and image issues (Figure 8.37).
8.4.2
M-Phase Mixers
In Chapter 6, we saw that the square-wave-like nature of the LO waveforms results in a
harmonically rich signal, leading to down-conversion of certain unwanted blockers located at
or around the LO harmonics.
To understand the root cause of this issue better, let us start with a single mixer clocked by a
50% differential LO shown in the left side of Figure 8.38. Such an LO signal effectively
samples an ideal sine-wave with only two points, 1 and –1, as shown, and thus resembles
a differential square-wave toggling rail-to-rail. For that, we call this mixer arrangement a
2-phase mixer.
As we are interested in only the fundamental, once ﬁltered, the mixer output is 2
π times less
than the input. The nature of the square-wave LO results in all odd harmonics (odd because still
the LO is differential, or 2-phase) to downconvert as well, unless ﬁltered beforehand.
As we have shown before, almost all transceivers rely on quadrature mixing to select only
one sideband. In the case of receiver, this corresponds to rejecting the unwanted sideband on the
image side. To do so, we showed that we need a 4-phase LO signal whose effective LO was
derived as in Figure 8.33. This is equivalent to sampling the ideal sinusoid with four points as
Ideal LO
Practical LO
Figure 8.37: Practical LO waveforms for 25% mixers
2-Phase LO
4-Phase LO
T/4
T/2
Figure 8.38: Two- and
4-phase LO signals
8.4 Passive Current-Mode Mixers
467

shown on the right side of Figure 8.38. The combined output consisting of both I and
Q channels will have a net gain of 2 ﬃﬃ
2
p
π . The increase in the mixer conversion gain is a direct
result of 4-point sampling, that is, the unwanted sideband at –fLO is subject to cancellation, thus
more energy is focused in the fundamental component.
This concept may be extended to as many phases as desired. An example of 8-phase LO is
shown Figure 8.39, where the ideal sinusoidal LO is sampled by eight points at 1, 1/√2, 0, –1/
√2, –1, –1/√2, 0, and 1/√2. The actual LO waveforms are shown on the right side and are pulses
from 0 to VDD, each with one-eighth of a period duration, and shifted by one-eighth with respect
to one another. As the LO signals are square-wave, the effective scaling factor of1/√2 is
provided by changing the relative gain of the corresponding TIAs. Negative scaling is easily
accomplished if the design is differential. By employing an 8-phase LO, all the harmonics up to
the 7th are also rejected, leading to a more fundamental gain, but also less noise aliasing and
more immunity to harmonic blockers. The drawback is the need for generating LO signals that
are two times narrower compared to the 4-phase mixer. This is effectively done by placing the
fundamental at four times the LO, and using a divide by 4 along with AND gates, a scheme
similar to that shown in Figure 8.36 for 4-phase. As we mentioned earlier, employing a shift
register may also be another attractive option.
The concept of 8-phase mixer to suppress higher harmonics was ﬁrst introduced in 2001 in
transmitters using active mixers [18], but can be generalized to either active or passive mixers,
receivers, or transmitters.
To present this concept mathematically, we shall consider the general case of an M-phase
mixer shown in Figure 8.40 [19]. Given the practical implementation of the LO signals using
dividers, we assume M is two to the power of an integer, although the concept is readily
extended to any integer values of M.
Since the cosine is sampled by M points at time intervals of t = n  T
M, n = 0, 1, . . . ,
M1, dictated by the effective LO signal consisting of T/M pulses, the corresponding
scaling factor for the output vn is cos n 2π
M


, as shown in Figure 8.40. Thus there are
M outputs that are each phase shifted by 2π
M, with respect to each other; of those, only the
Effective 8-Phase LO
T/8
1/√2
Actual LO Waveforms
LO1
LO2
LO3
LO4
LO5
LO6
LO7
LO8
0
VDD
T/8
Figure 8.39: An 8-phase LO
468
Mixers

ﬁrst output is shown in Figure 8.40. This is performed by employing M banks of M-input,
1-output TIAs with the proper gain.
To obtain the effective LO signal, let us ﬁrst ﬁnd the Fourier series representation of each of
the LO signals driving the branches,
Sk tð Þ =
X
∞
n = ∞
anejkn2π
M ejnωLOt,
where Sk is the effective LO switching the kth branch, k = 1, . . ., M, and
an = ejn π
M
M sinc n
M

	
:
Note that consistent with our deﬁnition in Chapter 2, sinc
n
M

 
= sin nπ
M
nπ
M . It is obvious that the
effective LO signals are identical, but shifted only by T/M with respect to each other. Now the
net effective LO, S(t), consists of the effective LO signals of each branch, scaled by
cos
k  1
ð
Þ 2π
M


, and added together:
S tð Þ =
X
M
k = 1
cos
k  1
ð
Þ 2π
M


Sk tð Þ =
X
∞
n = ∞
ane jn2π
M ejnωLOt X
M1
k = 0
cos k 2π
M


ejnk2π
M :
Using simple algebraic unity, we can show that
X
M1
k = 0
cos k 2π
M


ejnk2π
M = M
2
for n = pM  1, p 2 Z, and zero otherwise.
For the main harmonic then, n =  1, and the effective LO for say the output v1 becomes
sinc 1
M


cos ωLOt  π
M

	
:
The effective LO amplitude for different harmonics is graphically shown in Figure 8.41, which
is consistent with the sampling theory.
LO1
LO2
LOM
iRF
vRF
cos(2p×1/M)
v1
LO1
LO2
LOM
0
VDD
T/M
cos(2p×0/M)
Figure 8.40: M-phase mixer and the corresponding LO signals
8.4 Passive Current-Mode Mixers
469

Let us point out a few key observations:
– With the number of phases (M) approaching inﬁnity, the effective LO approaches an ideal
cosine, despite the fact that the switches are still clocked by square-wave signals. The
effective LO amplitude approaches unity, and there is no harmonic downconversion.
– Any signal at the main harmonic, as well as any harmonic separated by pM (p is an integer)
folds on top of the desired signal. Thus, we expect the (M+1)th and (–M+1)th as the closest
harmonics to be downconverted along with the desired signal.
As M increases, the effective LO amplitude approaches unity very quickly, as shown in
Figure 8.42. Given the overhead of clock generation for large number of phases, perhaps
M = 8 is an optimum choice, both from gain/noise point of view, and the fact that only the 7th
harmonic and beyond are problematic. The 7th harmonic is far enough to receive reasonable
amount of ﬁltering. In the case of 8-phase, the effective LO amplitude is
8
π sin π
8
 	
 0:97,
which is very close to unity.
Setting M = 4, we arrive at the same derivations as we had presented before for the 25%
mixer, where the conversion gain was calculated to be
ﬃﬃ
2
p
π . Note that in the case of a 4-phase
sinc(n/M)
1
Harmonic #
1
M
M+1
–M+1
–M
M
M
Figure 8.41: M-phase
mixer effective LO
harmonic content assuming
a complex (I + jQ) output
–6
–4
–2
0
2
2
4
8
16
32
Number of Phases (M)
Effective LO Amplitude, dB
Figure 8.42: Mixer conversion gain versus the
number of phases
470
Mixers

mixer, the ﬁrst and third branches, each with a gain of 
ﬃﬃ
2
p
π , are subtracted, resulting in a net
gain for the effective signal (see Figure 8.40).
In the remainder of this section, we will mainly focus on 4-phase mixers as is the most
popular choice for narrowband receivers, given the complexity and LO generation overhead for
higher values of M. In Chapter 12, we will discuss wideband receivers consisting of 8-phase
mixers, primarily used for harmonic rejection purposes. The mixer operation is readily extend-
able to any number of phases desired however.
8.4.3
Passive Mixer Exact Operation
To analyze the mixer operation, let us consider Figure 8.43, where we assume each TIA has a
single-ended input impedance of ZBB, and the mixer LO voltages and the other corresponding
signals are labeled as shown in Figure 8.43.
The effective LO signals are denoted as S1(t), S2(t), . . . which are identical to LO1, LO2, . . .
except for they toggle from 0 to 1. Just as before, we take a single-ended input mixer for
simplicity, though the results derived are readily extended to a fully differential structure.
As done previously, we represent the effective LO signals using Fourier series
S1 tð Þ =
X
∞
n = ∞
anejnωLOt
S2 tð Þ =
X
∞
n = ∞
anejnπ
2ejnωLOt
S3 tð Þ =
X
∞
n = ∞
anejnπejnωLOt
LO1
LO3
iBBI
iRF
LO4
LO2
2ZBB
iBBQ
2ZBB
vRF
LO1
LO2
0
VDD
0
VDD
LO3
LO4
0
VDD
0
VDD
0
T/2
T
T/4
3T/4
+
vBBI
–
+
vBBQ
–
Figure 8.43: Current-mode mixer operation
8.4 Passive Current-Mode Mixers
471

S4 tð Þ =
X
∞
n = ∞
ane + jnπ
2ejnωLOt,
where an = ejnπ
4
4 sinc n
4

 
.
Since a given switch is on only at one quarter of a cycle, for the corresponding branch, say
the I switch toggled by LO1, we have
iBBI+ = S1(t)iRF(t),
and so on. This baseband current in turn creates a voltage across the input of the TIA,
vBBI+ = [S1(t)iRF(t)] ∗zBB(t),
where * denotes convolution. This baseband voltage is only transparent to the RF input when S1
is 1, and thus is effectively multiplied by S1 when monitoring the RF voltage.
Once all four branches are considered, including the switch resistance, RSW, which
always appears in series with the RF current, as one and only one switch is on at the time,
we have
vRF tð Þ = RSWiRF tð Þ +
X
4
k = 1
Sk tð Þ 
Sk tð ÞiRF tð Þ
½
∗zBB tð Þ
f
g:
The analysis may be carried on more easily in the frequency domain, if the Fourier transform
is utilized. By applying straightforward algebra, we can show the Fourier transform of
Sk(t)  {[Sk(t)iRF(t)] ∗zBB(t)} is
X
∞
m = ∞
X
∞
n = ∞
ej n + m
ð
Þ k1
ð
Þπ
2anamIRF ω  n + m
ð
ÞωLO
ð
ÞZBB ω  nωLO
ð
Þ,
where k = 1, 2, 3, 4 corresponds to any of the branches switched by the LOk signal, and an is the
Fourier series coefﬁcient obtained previously. Thus we arrive at
VRF ω
ð Þ = RSWIRF ω
ð Þ + 4
X
∞
m = ∞
X
∞
n = ∞
anamIRF ω  n + m
ð
ÞωLO
ð
ÞZBB ω  nωLO
ð
Þ,
where n + m is restricted to an integer multiple of 4. From this, we conclude that if for instance
the RF current is a sinusoid at a frequency of ωLO + ωm, then the RF voltage has its main
component at ωLO + ωm, and the rest reside at 3ωLO  ωm, 5ωLO + ωm, and so forth. Ignoring
the frequency components at third and higher harmonics,9 knowing that the receiver provides
some modest ﬁltering, then, n + m = 0, and we have
VRF ω
ð Þ = RSWIRF ω
ð Þ + 4
X
∞
n = ∞
an
j
j2IRF ω
ð ÞZBB ω  nωLO
ð
Þ:
9 With typical design values, it can be shown that [23] the harmonics have a negligible impact on the mixer performance and
its transfer function. As the goal of this chapter is to provide a sufﬁciently accurate yet intuitive description of the mixers,
we shall ignore their impact throughout the rest of this chapter.
472
Mixers

As VRF(ω) now becomes only a function of IRF(ω), we can effectively deﬁne the impedance
seen at the RF input node as
ZIN ω
ð Þ = RSW + 4
X
∞
n = ∞
an
j
j2ZBB ω  nωLO
ð
Þ,
which indicates that the TIA input impedance appears at RF, at around the LO frequency and its
harmonics. In the vicinity of ωLO, we have
ZIN ω
ð Þ  RSW + 2
π2 ZBB ω  ωLO
ð
Þ + ZBB ω + ωLO
ð
Þ
½
:
Thus the baseband impedance is transformed to the input around ωLO. Accordingly if the
baseband impedance is lowpass, the corresponding RF input sees a bandpass impedance, whose
center frequency is precisely set by the LO (Figure 8.44). This property may be utilized to
create low-noise narrowband ﬁlters, often known as N-path ﬁlters, something that active ﬁlters
fail to provide as we discussed in Chapter 4.
Intuitively, we showed in the previous section that a passive mixer with 25% LO has a
conversion gain of
ﬃﬃ
2
p
π . Since the passive mixer is reciprocal (ignoring the capacitances), then
we expect the baseband impedance to be upconverted to RF with a conversion factor of
ﬃﬃ
2
p
π

	2
= 2
π2, in agreement with our ﬁndings. This statement, however, is not accurate as we had
to ignore the impact of all the harmonics.
We showed already that
iBBI = S1 tð Þ  S3 tð Þ
½
iRF tð Þ = 2iRF tð Þ
X
∞
n = ∞, odd
anejnωLOt
iBBQ = S2 tð Þ  S4 tð Þ
½
iRF tð Þ = 2iRF tð Þ
X
∞
n = ∞, odd
anejnπ
2ejnωLOt:
Around the fundamental, n = 1, and a1 = ejπ
4
4 sinc π
4

 
= ejπ
4ﬃﬃ
2
p
π. Thus the mixer has a conversion
current gain of
ﬃﬃ
2
p
π to each of the I and Q channels, as derived before.
With the switches’ input impedance and current gain already calculated, it is now straightfor-
ward to ﬁnd the overall conversion gain of the mixer including the RF gm cell. A simple model of
the mixer is shown in Figure 8.45, and can be easily extended to a fully differential topology.
The gm cell is modeled by an ideal current source loaded with an impedance of ZL.
A capacitor C isolates the switches from the output of the gm stage. This is done to prevent
undesired low-frequency components at the gm output, such as IM2 or 1/f noise, to leak into the
ZBB
0
–fLO
+fLO
0
≈ 
≈ 
Figure 8.44: Passive mixer impedance transformation
8.4 Passive Current-Mode Mixers
473

switches’ output in the presence of mismatches. We shall assume the capacitor has an imped-
ance of ZC, which is not necessarily a short at the frequency of interest. In fact, we will show
that to maximize the gain, there is an optimum value for C.
Suppose the RF current has a magnitude of IRF, and a frequency of ωLO + ωm, thus residing
at the high side of LO. We also assume that ωm  ωLO, which is a reasonable assumption in
most narrowband radios.
Given the mixer input impedance of ZIN ω
ð Þ  RSW + 2
π2 ZBB ω  ωLO
ð
Þ + ZBB ω + ωLO
ð
Þ
½

looking into switches, the RF current is subject to a current division, and thus
IC =
ZL ωLO + ωm
ð
Þ
ZL ωLO + ωm
ð
Þ + ZC ωLO + ωm
ð
Þ + ZIN ωLO + ωm
ð
Þ IRF:
Since ZL and ZC are almost constant around ωLO, and ZBB is lowpass, we have
IC 
ZL ωLO
ð
Þ
ZL ωLO
ð
Þ + ZC ωLO
ð
Þ + RSW + 2
π2 ZBB ωm
ð
Þ
IRF:
We showed the current gain from the switch input to say I channel TIA is
ﬃﬃ
2
p
π ejπ
4. Thus we have
IBBI = IBBQe jπ
2 =
ﬃﬃﬃ
2
p
π ejπ
4
ZL ωLO
ð
Þ
ZL ωLO
ð
Þ + ZC ωLO
ð
Þ + RSW + 2
π2 ZBB ωm
ð
Þ
IRF:
If the load impedance ZL is large, that is, the gm cell is an ideal current source, we arrive at our
previous results. In practice, the gm cell is likely to be combined with the LNA, and its output is
either a parallel RLC circuit, or is RC.
LO1
LO3
iBBI
iRF
LO4
LO2
2ZBB
iBBQ
2ZBB
vRF
+
vBBI
–
+
vBBQ
–
ZL
ZC
iC(t)
ZIN
Figure 8.45: Simple model of a current-mode
passive mixer
474
Mixers

As we saw in Chapter 7, RF ampliﬁers commonly use an inductive load. To gain some
insight, let us assume ZL is a parallel RLC network. We also assume ZBB is mostly resistive and
equal to RBB at the frequency of interest, which is a reasonable assumption. Ideally, ZBB must be
zero. Since ZC is representing a capacitor, ZC =  jXC, and as RSW and ZBB are real, to
maximize the conversion gain, that is, to minimize the denominator of the equation above,
ZL must resonate with C at the frequency of interest. Now consider Figure 8.46, where we use
the parallel–series conversion to arrive at the equivalent circuit shown on right.
In most typical designs, the quantity
Rp
Xp

, which is an indication of the inductor Q, is large,10
and thus let us assume
Rp
Xp

 	 1:
Thus the equivalent series resistance is
Rp
Xp2
Rp2 + Xp2  Xp2
Rp
,
and the series reactance is
Xp
Rp2
Rp2 + Xp2  Xp,
which must resonate with the capacitor C, and thus Xp  XC.
From this the conversion gain is
ﬃﬃﬃ
2
p
π
ZL ωLO
ð
Þ
ZL ωLO
ð
Þ + ZC ωLO
ð
Þ + RSW + 2
π2 ZBB ωm
ð
Þ

 
ﬃﬃ
2
p
π XC
XC2
Rp + RSW + 2
π2 RBB
:
The equation above indicates that there is an optimum value of XC that the conversion gain is
maximized, and is found by taking the derivative of the gain expression versus XC,
XP
RP
–jXC
jXS
–jXC
RS
iRF
Figure 8.46: Series equivalent of the gm
cell load
10 Unless there is a parallel resonance at the output,
RP
XP

 is always less than the actual inductor Q. Nevertheless, it is
reasonable to assume
RP
XP

 is large.
8.4 Passive Current-Mode Mixers
475

XC,opt =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rp RSW + 2
π2 RBB


s
,
which leads to a maximum conversion gain of
1ﬃﬃﬃ
2
p
π
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Rp
RSW + 2
π2 RBB
s
:
For typical values of switch resistance, inductor Q, and the TIA input impedance, this leads to a
substantially higher gain if one were to resonate ZL and choose a large C. This passive gain in
front of the TIA helps reduce its noise contribution. To emphasize the importance of this,
shown in Figure 8.47 is the measured noise ﬁgure of a 40nm 3G receiver11 versus a sweep of
values of the load capacitor (CL) and the series capacitor between the gm cell and the mixer
input (CB). The capacitors are programmable, and what is shown on the plot is the program-
ming code applied to each. A suboptimum design may lead to as much as 2dB degradation in
the receiver noise ﬁgure! It is interesting to note an acceptable noise ﬁgure is obtained based on
several different combinations of CL and CB. For that reason the actual optimization may be
performed considering other receiver aspects such as gain or linearity.
Using a very similar procedure, we can show that if the RF current resides at the low side of
LO (at ωLO  ωm), the current ﬂowing into to the capacitor is a result of a current division
between ZL, ZC, and ZIN ωLO  ωm
ð
Þ  RSW + 2
π2 ZBB ωm
ð
Þ = RSW + 2
π2 ZBB∗ωm
ð
Þ, and thus
the output current is
IBBI = IBBQe + jπ
2 =
ﬃﬃﬃ
2
p
π e + jπ
4
ZL∗ωLO
ð
Þ
ZL∗ωLO
ð
Þ + ZC∗ωLO
ð
Þ + RSW + 2
π2 ZBB ωm
ð
Þ IRF:
NF, dB
 
 
2
4
6
8
10
12
2
4
6
8
10
12
14
1.8
2
2.2
2.4
2.6
2.8
3
3.2
3.4
3.6
gm
VDD
CL
CB
… 
CL
CB
Figure 8.47: Receiver noise ﬁgure optimized based on load and series capacitances
11 The details of the receiver design are presented in Chapter 12 in the practical transceiver design concerns section.
476
Mixers

We must note that since the signal is at the negative side, once the capacitor current is
downconverted to baseband, the resultant current is conjugated with respect to the case of high
side, that is, its imaginary part is 180 out of phase.
Comparing this equation with the one obtained for the signal at ωLO + ωm, we conclude that
unless ZBB is purely resistive, the mixer exhibits different conversion gains whether the signal is
located at the lower or higher side of the LO. That is because in general
ZL ωLO
ð
Þ + ZC ωLO
ð
Þ + RSW + 2
π2 ZBB
∗ωm
ð
Þ

 6¼ ZL ωLO
ð
Þ + ZC ωLO
ð
Þ + RSW + 2
π2 ZBB ωm
ð
Þ

:
To understand this intuitively, consider Figure 8.48, which shows a simpliﬁed block
diagram of the mixer, and let us assume for the moment that XC  0, and thus not shown in
the ﬁgure.
ZL then naturally resonates at the center frequency, which is ωLO. Let us assume that ZBB
consists of a resistor in parallel with a capacitor modeling the TIA input. For high-side, then,
when upconverted to the RF, the impedance looking in is capacitive, appearing in parallel
with ZL. On the other hand, for low-side, the upconverted impedance is inductive (due to the
term 2
π2 ZBB∗ωm
ð
Þ), whereas ZL has not appreciably changed, and thus the gm stage is loaded
differently, leading to different conversion gains. This situation is substantially worse if the
mixer LO were 50% due to the interaction of I and Q switches and appearance of the image
current [14].
If the high- and low-side conversion gains are not identical, as the signal has uncorrelated
energy at both sides of the spectrum, once downconverted, it will be distorted, which leads to
EVM degradation.
To minimize this, one must ensure that the TIA input (ZBB) is dominantly real at the
passband of interest. Alternatively, if ZL resonates with C, then ZL(ωLO) + ZC(ωLO) is real,
and thus the high- and low-side gains are identical (of course within the passband of the
resonance) regardless of ZBB. This will also lead to the optimum gain as we established
before.
Example: For ZBB = 100Ω||25pF, RSW = 15Ω, L = 2nH, Rp = 250Ω, the simulated high-
and low-side gains for both the conventional and optimum designs are shown in
Figure 8.49. The LO frequency is 2GHz.
Continued
gm
ZBB
ZL
ZBB
ZIN=RSW+2/p2ZBB
Figure 8.48: Mixer schematic to illustrate different high- and
low-side gains
8.4 Passive Current-Mode Mixers
477

Not only the optimum design has a higher gain, but also the difference between high-
and low-side gains is very small. Moreover, as IF increases, the capacitive part of the TIA
input impedance becomes more dominant, and thus more difference is observed as
expected.
8.4.4
Passive Mixer Noise
If the mixer LO signals have no overlap like shown in Figure 8.33, their noise contribution is
very small. Since the switches are in the Triode region with zero bias current, their 1/f noise
contribution is negligible as well. This is however not always the case, as it has been experi-
mentally shown in [20], and analyzed in [21], that depending on the bias conditions, the passive
mixers are indeed capable of producing 1/f noise. In a well-designed passive mixer however,
the 1/f noise, if it exists at all, is negligible.
If there are mismatches between the switches, however, the 1/f noise of the gm stage may leak
to the output. An analysis very similar to the one performed for the active mixers reveals that
the leakage gain is
2 VOS
S  T ,
where VOS models the switch mismatches as an input-referred offset voltage [22], and ST is
the normalized slope of the LO signals. This noise, however, may be easily suppressed if any
kind of highpass ﬁltering between the gm cell and switches is incorporated, the most simple one
being the insertion of a blocking capacitor (Figure 8.50).
Using a similar approach as we took to analyze the mixer current gain, and considering that
the mixer noise is cyclostationary (see Chapter 5), we can easily show that as far as switches’
thermal noise is concerned, they can be modeled as the Thevenin equivalent circuit shown in
Figure 8.51 [23].
–22
–18
–14
–10
–6
0
10
20
30
40
50
IF, MHz
Conversion Gain, dB
Optimum
Conventional
High
Low
Figure 8.49: Simulated high- and low-
side gains of the mixer
478
Mixers

This can be intuitively understood as at any given point of the time, there is one and only one
switch on whose resistance and its corresponding noise appears in series with the current
ﬂowing from the gm cell. This noise voltage, whose spectral density is then 4KTRSW (RSW is the
switch resistance), may be referred to as the gm cell output as also shown by the shaded circuit
source in Figure 8.51. The current noise spectral density is
4KTRSW
ZL
j
j2
:
If the gm cell is ideal, then ZL is inﬁnite, and the switches contribute no noise. That is simply
because the switch noise appears in series with an ideal current source. In practice, they do
however, but this noise contribution is quite small compared to the gm cell itself, as the switch
resistance is typically quite small compared to the output impedance of the gm cell.
8.4.5
Passive Mixer Linearity
The operation of passive mixer in the current domain, along with the impedance transformation
properties explained earlier, results in a superior linearity compared to active mixers [24].
Consider Figure 8.52 where a small desired signal is accompanied by a large blocker.
If the TIA ideally presents a very small input impedance to the switches, and assuming the
switches’ resistance is small, then the gm cell is going to see a very small impedance at its
output. This ensures that the swing at the gm cell output is small. Moreover, if a large
capacitance is present at the TIA input (large enough to present a short circuit at the blocker
offset frequency, ΔfB), a bandpass ﬁlter is created that will suppress the blocker. Once down-
converted to IF, the signal resides at DC, whereas the blocker is several tens of MHz away, and
is easily suppressed by a lowpass ﬁlter. The only challenge is to ensure that the ﬁltering is such
that the desired signal is not affected, while the blocker is suppressed adequately. This is
generally the case, as in most applications the ratio of the blocker offset to the signal bandwidth
g m
IM2, 1/f Noise
Blocking Capacitor
Figure 8.50: Highpass ﬁlter to block 1/f noise
iRF
vRF
ZL
RSW
4KTRSW
in = vn/ZL
Figure 8.51: Thevenin equivalent circuit to model
switch noise
8.4 Passive Current-Mode Mixers
479

is usually large (5–10), allowing room for sufﬁcient ﬁltering even if a simple 1st-order RC
ﬁlter is exploited. The main trade-offs are the size of the switches, as the larger they are made,
the more suppression of blocker is achieved, but more power consumption in the mixer buffer is
resulted. Moreover, the design of the TIA is critical, especially to guarantee a low enough input
impedance. This will be discussed shortly.
This property of current-mode passive mixers makes them unique and results in what is
known as a current-mode receiver, where the blocker tolerance is substantially boosted
compared to the traditional voltage-mode receivers.
8.4.6
Passive Mixer 2nd-Order Distortion
Passive mixer 2nd-order distortion arises from similar mechanisms as described for active
mixers, which can be summarized as follows: (1) Direct leakage of IM2 components created
inside the LNA to the baseband in presence of mismatches among the switches of the passive
mixer (this leakage gain was shown to be 2 VOS
ST ). (2) RF-to-LO coupling in the downconversion
mixer. This mechanism may be also analyzed very much like we did for the active mixer [25],
resulting in the exact same expression,
IIP2 = 2 S  T
πα ,
where α is the leakage gain and must be optimized by proper layout. We must note, however,
that in the case of passive mixer the slope of the LO, which is a square-wave rail-to-rail signal,
is somewhat larger than that of the active mixer driven by a sinewave. (3) Nonlinearity of the
mixer switches in the presence of β and threshold voltage mismatches.
Unlike the active mixers, the presence of a series capacitor between the LNA or the RF gm
cell and the switches attenuates those IM2 components generated inside the LNA; therefore,
they do not contribute to the IIP2 of the receiver. The rest of the IM2 sources mentioned above
can contribute to the IIP2 in two ways: (a) by modulating the resistance of the switches of the
passive mixer and (b) through modulating the on/off instants of the mixer switches. Fortuit-
ously, it appears that modulation of the window during which the switches are on does not
contribute much to the IM2 products compared to the resistance modulation of the switches
[25]. This is because the switches are clocked by rail-to-rail signals with fast rise and fall times.
In conclusion, in a properly designed passive mixer with 25% clocks, we expect the mixer
switches IIP2 contribution to be reasonably small.
g m
ZBB
ZBB
ZIN=RSW+2/p2ZBB≈0
fLO
Blocker
Desired
0
DfB
DfB
Figure 8.52: CM-mode
passive mixer linearity
480
Mixers

Example: We wish to ﬁnd the impact of RF to LO feedthrough in a passive current-
mode mixer.
The simpliﬁed mixer along with the LO waveforms are depicted in Figure 8.53. The RF
feedthrough is modeled as a single-ended source with the magnitude of αvIN appearing at
the gate of one switch.
Suppose the on conductance of the switches is g1, and g2, respectively. During the on
overlap (that is, the period of time when both switches are on, given ﬁnite rise and fall
times), the current splits as
iO =
g2
g1 + g2
iIN 
g1
g1 + g2
iIN = g2  g1
g1 + g2
iIN = g2  g1
g1 + g2
gmvIN:
Ideally no current appears at the TIA output if the switches are identical, but in
practice there is some current given the RF feedthrough. Assuming square-law
characteristics,
g1 = β(S1  VTH  αvIN)
g2 = β(S2  VTH),
where
β = μCOX
ω
L :
Therefore
iO =
β S2  S1
ð
Þ + βαvIN
β S1 + S2
ð
Þ  2βVTH  βαvIN
gmvIN:
Note that the on overlap happens only if the zero-crossings are above the FET switches’
threshold voltage as shown in the ﬁgure (on overlap).
Assuming symmetric waveforms with linear rise and fall times, and for α  1, the
reader can show (see also Problem 16) that the normalized 2nd-order term is
Continued
TIA
(ZIN=0)
LO1
LO2
io
RF gm
avIN
vIN
iIN=gmvIN
S1
S2
VTH
2(VDD–VTH)/S
Figure 8.53: Analysis of RF to LO feedthrough in passive mixer
8.4 Passive Current-Mode Mixers
481

Δt
T=2 
αgm
2 VDD  VTH
ð
Þ vIN
2 = 2 αgm
S  T vIN
2,
where Δt  2 VDDVTH
ð
Þ
S
is the overlap time as shown in the ﬁgure. Since the mixer desired
gain is 2
π gm,
IIP2 =
2
π gm
2 αgm
ST
= S  T
πα
:
In the case of off overlap, there will be no 2nd-order distortion, and as we mentioned, it is
beneﬁcial to design the mixer with slight off overlap if possible.
8.4.7
TIA and gm Cell Design
The gm cell design as mentioned earlier is not very different from a typical tuned RF
ampliﬁer. Particularly, if it is combined with the LNA, as is very commonly done, all the
design trade-offs described in Chapter 7 are applicable. Thus we shall describe only the TIA
design choices here.
Similar to active mixers, one may consider the TIA (or the I–V converter) comprising
simply a pair of resistors RBB where the downconverted current is directly fed to
(Figure 8.54). This approach, however, suffers from the fundamental drawback that the
mixer overall gain, and the TIA input impedances are set by the same resistor RBB. Thus, the
optimum condition of a high gain and a low input impedance may be never satisﬁed
simultaneously.
Consider the equivalent model shown on the right, where, as we established before, the RF
ampliﬁer current is divided between its output resistance (RL) and the input impedance
upconverted by the switches. This current is then downconverted by a loss factor of
ﬃﬃ
2
p
π , and
ultimately appears as a voltage at the output once multiplied by RBB. Thus, with a reasonable
approximation ignoring the switch resistance, the mixer total conversion gain is
gm
RL
RL + 2
π2 RBB
ﬃﬃﬃ
2
p
π RBB:
LO1
LO3
+
vBBI
–
RBB
TIA
gmvIN
√2/p
2/p2RBB
RBB
RF gm
RL
Figure 8.54: A simple TIA comprising only a pair of resistors
482
Mixers

Unless the RF ampliﬁer output resistance RL is inﬁnite, which is not the case in practice, and
for moderately large values of RBB, to the ﬁrst order the mixer gain becomes independent of the
TIA resistance. There are also severe linearity repercussions. To keep the swing at the ampliﬁer
output low, one must choose RBB to be very small, resulting in zero gain for the mixer.
To break this trade-off, we can consider one of the two choices: a common-gate ampliﬁer, or
an opamp in feedback, both of which are shown in Figure 8.55. Assuming the input devices
have the same size and bias current between the two circuits, then the single-ended input
resistance looking into each structure is approximately
1
gmBB, where gmBB is the input device
transconductance. This of course assumes a one-stage opamp. Large capacitance at the input
ensure that the TIA input impedance is kept low at the blocker offset frequency.
The gain, however, is set independently by the load or feedback resistor RF. The mixer gain
expression is now
gm
RL
RL + 2
π2 gmBB
ﬃﬃﬃ
2
p
π RF:
Consequently, the gain and input impedance may be set independently.
A feedback capacitor in parallel sets the TIA bandwidth, and can be treated as a single-pole
RC ﬁlter.
Since the load capacitance can be implemented differentially in the case of CG topology,
for the same bandwidth it requires four times less capacitance. Thus the CG structure tends to
be smaller, while the opamp may be superior in terms of linearity. Another drawback of the
CG structure is the noise contribution of the current source. If headroom allows, it may be
replaced by a resistor. Otherwise, very large devices may be needed to ensure a low
ﬂicker noise.
The opamp itself may be a two-stage design, or simply a complementary single-stage
structure (basically an inverter). If a two-stage structure is chosen, it must be ensured that the
opamp has sufﬁciently wide bandwidth to ensure a good linearity across all the downconverted
blocker frequencies.
CF
RF
Common-Gate TIA
Opamp-based TIA
–
+
+
–
RF
2CF
Resistor
Figure 8.55: Common
practical TIA circuits
8.4 Passive Current-Mode Mixers
483

8.5
PASSIVE VOLTAGE-MODE MIXERS
..............................................................................................
Unlike the current mixers, the voltage-mode passive mixers commutate the RF AC voltage. The
circuit driving the mixer, whether it is the LNA or some buffer, will not be much different from
that of the current-mode mixers, as RF ampliﬁers act neither like true voltage ampliﬁers that
have zero output impedance, nor like true current ampliﬁers that have an inﬁnite output
impedance. This is more prominent in CMOS, as a true voltage ampliﬁer with low output
impedance is not common. Instead, most CMOS ampliﬁers are transconductors.
The main distinguishing factor then between the voltage- and current-mode passive mixers is
the circuit that follows the switches. Shown in Figure 8.56, a voltage-mode passive mixer
drives ideally a voltage buffer whose input impedance is inﬁnite, as opposed to a current-mode
mixer, where the TIA input impedance is ideally zero.
The RF ampliﬁer that is preceding the switches, however, whether it is the LNA or a separate
buffer, is not much different from a current-mode mixer. In the case of the voltage-mode mixer
though, as the switches upconvert a large baseband impedance to RF, then the RF ampliﬁer acts
in voltage mode. If the condition RSW  ZIN met, then the mixer has a voltage conversion loss
of 2
π if the LO is sharp enough. Nonetheless, same as current-mode design, the baseband buffer
must have a very low impedance at the blocker offset frequency to ensure that the swings at the
output of the RF ampliﬁer are kept low.
The mixer principle operation as well as noise [21], [22] or linearity trade-offs are very
similar to those of the current-mode design, and we will not spend any more time in this section
describing them. See also [26] for more details on analysis of passive mixers in general. One
main distinction between the voltage- and current-mode passive mixers is the fact that in the
latter circuit, the switch is in series with a current source. Thus, the switch adds little noise or
distortion of its own. However, switch distortion in the desired signal frequency is not very
important. At the blocker frequency, assuming the voltage mixer buffer input impedance has
LO+
LO–
LO+
BUF
BUF
ZIN»1
RF Amp
ZL
gmvIN
Figure 8.56: A voltage-mode passive mixer
484
Mixers

been reduced enough, the current- and voltage-mode mixers behave very similarly. Neverthe-
less, the current-mode mixer appears to be superior from the mixer switch noise point of view.
Shown in Table 8.1 is a comparison between different types of the mixer. We assume the
overall power consumption of the mixer and its supporting circuitry is comparable between
different structures.
It is instructive to have a closer comparison between the mixer LO drive requirements.
Shown in Figure 8.57, let us assume a rail-to-rail sinusoid LO signal is applied to the active
mixer. The corresponding normalized slop of the LO is 2πVDD.
Passive mixers on the other hand almost always require nonoverlapping clocks with <50%
duty cycle. This prevents them from using sinusoidal LOs. Let us ﬁrst assume a 50% LO is
used. We also assume that the signal has an equal rise and ﬁle time of tr, and is shaped as shown
in Figure 8.57, where the LO stays ﬂat for at least 3tr. The rationale behind this choice is that
it leads to a normalized slope of 8VDD for the passive mixer LO, comparable to that of the
active mixer.
Using CML type logic along with tuned buffer, generating a sinusoidal signal for the active
mixer can be done quite efﬁciently, and at frequencies of up to one-third or so of the process
transit frequency, which is several 100GHz for nanometer CMOS. On the other hand, for a
typical 40nm CMOS process, the rise and fall time of logic gates are on the order of 10ps,
limiting the 50% LO signal to only 12.5GHz. For a 25% LO design, which is preferred, this
value is roughly reduced in half, to only 6.25GHz, that is, the maximum allowable frequency.
In an 8-phase mixer, this number reduces to 3.1GHz. In general, the increased number of phases
requires a larger normalized slope, and so a sharper rising/falling edge is needed.
It is clear that despite all the advantages, passive mixers may be used only at radio
frequencies, although this scales with technology. Moreover, it shows why passive mixers
have not been used as extensively until very recently.
Table 8.1: A performance summary of different mixer structures
Parameter
Commutation
White NF
1/f
Linearity
Loading
LO Swing
Active
DC current
Comparable
Poor
Modest
Capacitive
Modest
CM passive
AC current
Small
Good
BB impedance
transformation
Rail-rail
VM passive
AC voltage
Small
Good
VDD/2
S×T = 2πVDD
tr
tr
3tr
S×T = 8VDD
T=8tr
Figure 8.57: Mixer LO drive comparison
8.5 Passive Voltage-Mode Mixers
485

8.6
TRANSMITTER MIXERS
..............................................................................................
Similar requirements and design trade-offs apply to upconversion mixers more or less. Both
linearity and noise are critical, as we established in Chapter 6, to meet the close-in and far-out
mask. The second-order distortion is typically not a concern as the IM2 components are low
frequency once upconverted.12 In addition to the concerns mentioned above, the gain control
and LO isolation are more critical in transmitter mixers. As we saw in Chapter 6, the LO
feedthrough can potentially cause EVM issues, and must be properly dealt with.
In this section we will present both the active and passive mixer choices for transmitters, and
comment on pros and cons of each qualitatively. The exact operation is very similar to that for
downconversion mixers, which has been already presented.
8.6.1
Active Upconversion Mixers
Shown in Figure 8.58 is a generic Cartesian transmitter, where the IQ upconversion mixers are
followed by a power ampliﬁer (or a power ampliﬁer driver).
Similar to our discussion on downconversion mixers, it is more appropriate to discuss the
mixer performance issues in the context of a quadrature upconverter, consisting of I and
Q branches, and to include any possible interaction. An active quadrature upconverter is shown
in Figure 8.59.
The gain control is achieved through breaking the mixer into several unit cells turned on/off
by controlling the bias (GC1), in addition to a possible current steering on top (GC2). The
addition or subtraction is simply accomplished by tying the differential currents of the I and
Q branches. This current is subsequently fed into a tuned circuit to boost the gain, and alleviate
the headroom issue by setting the output bias at VDD. The input stage nonlinearity may be also
improved, employing a current mirror as shown in Figure 8.60. There are still three devices
stacked, and realizing the circuit through a low supply voltage may be a challenge, especially
given the large swing at the output.
The current generated by the DAC/LPF may be directly fed into the input transistors through
a mirror, as opposed to apply a voltage, and converted back to a current by the input devices.
The channel length modulation may be alleviated if the mirror is implemented through a
feedback as shown on the right. This is one advantage of TX mixers, as since the input is at
PA
… 
Figure 8.58: A generic Cartesian transmitter
12 Unless the IM2 products are created in baseband prior to upconversion.
486
Mixers

low frequency, more linearization may be applied. In either case, a capacitor at the gate can
provide some light ﬁltering relaxing the preceding lowpass ﬁlter order.
In addition to input-stage linearity enhancement, unlike the receiver mixers, 1/f noise and
second-order distortion are not a big concern anymore. Still, the upconversion active mixer
suffers from a few drawbacks:
– The need for several devices stacked could potentially lead to poor linearity despite the mixer
output being biased at VDD. It is unlikely for the mixer to function properly at low supply
voltages, given the relatively large swing at its output.
LOI
LOQ
INI
INQ
… 
… 
VDD
GC2
GC1
+ OUT –
Gain Control
Figure 8.59: Active upconverter
Input FET
Switches
Baseband Current
Input FET
Switches
Baseband Current
… 
… 
Figure 8.60: Active mixer input-stage linearity enhancement
8.6 Transmitter Mixers
487

– The gain control may cause some challenges. Apart from the complexity in routing and
layout, reducing the input signal strength is not desirable. In some applications such as 3G or
LTE, a very stringent gain control range of over 70dB is required, a big portion of which is
expected to be provided by the active mixer. The transmitter EVM, however, needs to stay
unaffected throughout the course of the gain control. Since the absolute level of the LO
feedthrough is relatively constant, mostly dominated by the LO signal directly leaking to the
output, the transmitter EVM may be compromised at lower gains.
Given the above challenges, let us now consider the passive mixers.
8.6.2
Passive Upconversion Mixers
All the advantages of 25% versus 50% mixers remain applicable to transmitter mixers as well.
Also, unlike the receivers that current-mode passive mixers seemed like a more natural choice,
they are not as suitable for transmitters. This is shown in Figure 8.61, where the RX and TX
current-mode mixers are compared.
In the case of a receive mixer, the RF current is always directed to one of the TIA’s inputs, as
one of the switches remains on. In the case of transmitter as shown on the left, the relatively
large baseband current fed to the switches becomes disconnected over a large portion of the
period when its corresponding switch is turned off. In addition to that, designing a TIA with low
input impedance is more challenging at high frequency.
With all those options ruled out, let us focus on 25% voltage-mode mixers, as shown in
Figure 8.62.
The input applied to the mixer is relatively strong (perhaps several hundreds of mV), to
ensure a good SNR is maintained throughout the TX chain. As long as the output stage of the
lowpass ﬁlter driving the mixer has a low output resistance, this will not be an issue as the
mixer switches are fairly linear. The mixer outputs are tied together (a single-ended design
shown for simplicity) and are connected to the input of the PA driver. The PA driver is very
similar to the active mixer shown in Figure 8.59, except the switches are removed. It consists
TIA
gm×VRF
TIA
TIA
gm×VBB
TX CM Mixer
RX CM Mixer
Figure 8.61: Current-mode passive mixers used in transmitters
488
Mixers

of several unit stages, each turned on/off by the cascode bias, with an additional current
steering applied on top (although not shown in Figure 8.62). The elimination of the switches
given the large LO swing applied results in better linearity at lower voltage. Moreover, the
relative ratio of the signal to LO feedthrough remains constant, and good EVM is expected
over the entire gain control.
To analyze the mixer performance, it is best to use a Thevenin equivalent circuit as the
passive mixer is linear (although time-variant) [27]. As shown in Figure 8.63, taking a very
similar approach as the one we presented for the RX mixer (Figure 8.51), we arrive at the
Thevenin equivalent illustrated on the right. The PA driver can be simply modeled as a
capacitor looking into its input.
A similar analysis to the one performed for the RX reveals that the Thevenin impedance is
ZTH ω
ð Þ  RSW + 2
π2 ZBB ω  ωLO
ð
Þ,
and the equivalent Thevenin voltage is found to be
vTH(t) = vBBI(t)[S1(t)  S3(t)] + vBBQ(t)[S2(t)  S4(t)],
PAD
… 
GC
PAD Units
… 
Figure 8.62: A 25% voltage-mode upconversion passive mixer
PAD
ZBB
ZOUT
vBBI(t)
–vBBI(t)
–vBBQ(t)
vBBQ(t)
ZTH
vTH(t)
 
ZL
CL
Figure 8.63: Passive mixer Thevenin equivalent circuit
8.6 Transmitter Mixers
489

indicating the upconversion of baseband IQ signals. Sk(t), k = 1, . . ., 4, is the effective LO
signal driving the switches, and is one when the corresponding LO is high, and zero otherwise.
The above analysis ignores the impact of higher order harmonics.
Using the equivalent circuit, we can make an approximation and use a linear time-invariant
analysis to ﬁnd the mixer transfer function. It easily follows that the Thevenin voltage is divided
between the mixer output equivalent impedance, and the load presented by the PA driver. Thus
the RF voltage at PA driver input is
VRF ω
ð Þ 
ﬃﬃﬃ
2
p
π
e jπ
4VBBI ω  ωLO
ð
Þ + ejπ
4VBBQ ω  ωLO
ð
Þ


ZL ω
ð Þ
ZL ω
ð Þ + RSW + 2
π2 ZBB ω  ωLO
ð
Þ ,
where the ﬁrst term is a result of upconversion of the baseband quadrature inputs, whereas the
second term shows the voltage division.
Example: To verify how accurate the above approximation is, shown in Figure 8.64 is a
comparison between the exact linear time-variant analysis, approximated time-invariant
analysis, as well as simulations for values: ZBB = 50Ω||100pF, RSW = 15Ω, and CL =
1.5pF. The LTV model and simulations match very closely. Although the LTI model
deviates a little, it still predicts the actual circuit behavior fairly accurately.
Similar to downconversion mixers, if ZBB is not dominantly real, and is large enough
with respect to the load impedance (ZL), different high- and low-side gains may be
observed. For the example shown in Figure 8.64, the parameters chosen result in very
little high- and low-side gain difference over the 2MHz 3G band that the design was
intended for.
Furthermore, to maximize the mixer gain, one must ensure that the circuit driving
mixer has sufﬁciently low output impedance (i.e. low ZBB) over the entire band of
interest.
–15
–14
–13
–12
1.5
1.7
1.9
2.1
2.3
2.5
LTI
LTV
Simulation
1MHz/
3G Ripple≈0.15dB
Frequency, GHz
Relative Gain, dB
Figure 8.64: TX mixer simulation versus analysis
490
Mixers

Similarly, we can easily show that from a noise point of view, assuming a switch resistance
of RSW, the following Thevenin models can be used, where the noise of all switches is replaced
by one source at RF whose power spectral density is
vn,TH2 = 4KTRSW,
where vn,TH
2 represents the combined switch noise (Figure 8.65).
This noise then will approximately (if we were to use the LTI model) appear in series with
the input-referred noise of the PA driver.
8.7
HARMONIC FOLDING IN TRANSMITTER MIXERS
..............................................................................................
While in downconversion mixers the LO component around the 3rd harmonic results in
unwanted blocker and noise downconversion, in the case of upconversion mixers it may result
in linearity degradation [27]. This applies to both passive and active realization.
Suppose the mixer output consists of a desired component vd(t) as follows:
vd(t) = A(t) cos(ωLOt + ϕ(t)).
Due to the LO 3rd harmonic, there exists an undesired component around 3fLO:
vu tð Þ  1
3 A tð Þ cos 3ωLOt  ϕ tð Þ
ð
Þ:
Now suppose the mixer output is passed through a PA (or PA driver) with 3rd-order non-
linearity, whose input–output characteristics are
y = a1x + a3x3,
as shown in Figure 8.66. Thus the PA driver output is
a1vd + a1vu + a3(vd + vu)3,
ZOUT
ZTH
vn,TH(t)
ZL
Figure 8.65: Passive mixer noise
8.7 Harmonic Folding in Transmitter Mixers
491

where the ﬁrst term (vd) is the desired output, while the second term (vd) is at 3fLO and
subject to the ﬁltering at the PA driver output. The third term consists of several compon-
ents that may be problematic due to the mixing and folding of the undesired signal at 3fLO,
combined with the PA driver 3rd-order nonlinearity. Focusing on this last term, after
expansion we have
a3(vd + vu)3 = a3vd
3 + 3a3vd
2vu + 3a3vdvu
2 + a3vu
3.
The ﬁrst three terms are expected to have components around fLO, whereas the term a3vu
3
gives rise to components only at 3fLO and higher frequency. Thus, we shall consider only the
ﬁrst three terms. Upon expansion, focusing only on the components that appear around fLO at
the PA driver output (assuming that the rest are subject to ﬁltering), we have the following
signals:
a3vd
3 ! 3
4 a3A tð Þ3 cos ωLOt + ϕ tð Þ
ð
Þ
3a3vd
2vu ! 1
4 a3A tð Þ3 cos ωLOt  3ϕ tð Þ
ð
Þ
3a3vdvu
2 ! 1
6 a3A tð Þ3 cos ωLOt + ϕ tð Þ
ð
Þ:
Thus the contribution of the PA driver output nonlinearity may be summarized as
a3 vd + vu
ð
Þ3 ! 11
12 a3A tð Þ3 cos ωLOt + ϕ tð Þ
ð
Þ + 1
4 a3A tð Þ3 cos ωLOt  3ϕ tð Þ
ð
Þ:
If the 3rd harmonic were not present, the only nonlinear term would have been
3
4 a3A tð Þ3 cos ωLOt + ϕ tð Þ
ð
Þ, consistent with our previous deﬁnition of IIP3 =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4
3
a1
a3


r
. However,
in practice, the presence of a strong 3rd harmonic results in worse nonlinearity, as one
would have expected considering only the PA driver nonlinearity. To gain more perspective,
shown in Figure 8.67 is the PA driver output in response to a 2-tone signal with fundamental
amplitude of A, and frequencies of ωLO + ω1 and ωLO + ω1 at the mixer output. We assume
ω1 and ω2  ωLO.
This suggests that the IIP3 is expected to degrade, as the energy of unwanted IM components
nearly doubles.
y = a1x+a3x3
fLO
3fLO
Mixer Output
Figure 8.66: Mixer output passing through a nonlinear next stage
492
Mixers

It must be noted that the two terms 11
12a3A tð Þ3cos ωLOt+ϕ tð Þ
ð
Þ and 1
4a3A tð Þ3cos ωLOt3ϕ tð Þ
ð
Þ
may have very different power spectral densities, and depending on the signal statistics, their
correlation may vary.
Example: Shown in Figure 8.68 is the simulated ACLR (adjacent channel leakage ratio)
for a 3G signal fed into an otherwise ideal mixer, but with 3rd-order nonlinearity, passed
through a typical 3G PA driver. For some typical nonlinear characteristics of the PA
driver used in this simulation, the ACLR at 5MHz degrades from –44dBc to –38dBc once
the impact of the 3rd harmonic is included.
To alleviate this issue, one may consider employing some ﬁltering at the mixer output to
attenuate the signal around the 3rd harmonic. In the case of the active mixer shown before
fLO+f1
fLO+f2
fLO+2f1–f2
fLO+2f2–f1
Desired
A
11/12a3A3
1/2a3A3
1/4a3A3
fLO–3f2
fLO–3f1
fLO–2f1–f2
fLO–2f2–f1
fLO+f1
fLO+f2
fLO+2f1–f2
fLO+2f2–f1
Desired
A
3/4a3A3
w/ 3rd Harmonic
w/o 3rd Harmonic
Figure 8.67: PA driver 2-tone output
Figure 8.68: Simulated
spectrum of a 3G output as a
result of mixer 3rd-order
harmonic folding
8.7 Harmonic Folding in Transmitter Mixers
493

(Figure 8.59), this is readily achieved as the mixer is loaded with a tuned LC circuit
resonating at fLO.
On the other hand, implementing a sharp ﬁlter at the passive mixer output is not quite
feasible, as unlike the active mixer, the output of the passive mixer is relatively low-impedance,
and a strong 3rd harmonic is expected. The two designs are compared against each other as
shown in Figure 8.69. For the passive design, it may be beneﬁcial to include some kind of notch
ﬁltering to trap the 3rd harmonic before entering the PA driver. Alternatively, an 8-phase mixer
may be employed at the expense of higher power consumption in the LO generation circuitry.
8.8
LNA/MIXER CASE STUDY
..............................................................................................
We conclude this chapter by discussing a case study detailing the design of an actual low-noise
ampliﬁer and a mixer. Designed for a 2/3/4G receiver, the circuit features a low-noise transcon-
ductance ampliﬁer (LNTA), followed by a current-mode 25% passive mixer. This speciﬁc choice
of architecture arises from the relatively stringent noise and linearity requirements imposed by
the full duplex operation of LTE and 3G radios. As we showed earlier, the current-mode nature
of the circuit boosts the linearity, yet is capable of achieving a low noise ﬁgure.
8.8.1
Circuit Analysis
The schematic of the LNTA and mixer is shown in Figure 8.70. The design is fully differential,
but for simplicity only half is shown. The matching circuit is external and consists of a shunt
L and a series C, which downconverts the impedance of the LNTA input to the source. The
matching network is intentionally designed to be highpass to provide modest ﬁltering at the
transmitter leakage frequency (which is always lower than the receiver frequency).
The mixer switches are followed by a common-gate transimpedance ampliﬁer. The choice
of a common-gate circuit is to ensure a lower area and more convenient means of gain control
(see Section 8.4.7). The main transistor (M2) is in fact followed by a cascode device, which
enables some gain control through switching unit devices on and off (the details are not shown
though).
PAD
I
Q
PAD
I
Q
Passive Realization
Active Realization
Filters 3fLO
Figure 8.69: Comparison of active and passive mixers in the presence of 3rd harmonic folding
494
Mixers

A simpliﬁed model of the front end used for gain and noise calculations is shown in
Figure 8.71.
For high bands, the LNTA features a tuned load using a 1.8nH inductance with a Q of 14 at
2GHz. The total shunt impedance as a result is about 280Ω at 2GHz, including the impact of
ﬁnite output resistance of the LNTA and other losses. As most cellular receivers need to support
various bands of operation, there are several ampliﬁers connected to the output, in which the
parasitic capacitances limit the inductance to a relatively small value.13 The matching circuit
CG
CG
CM Mixer
M1
M3
M2
RP
RL
½ of CG TIA
… 
1.2V
1.2V
XC
Matching
RIN
RMN
Figure 8.70: Low-noise transconductance ampliﬁer and mixer simpliﬁed schematic
Matching
gmRFVin
+
Vin
–
XP
XP
2/RP
RMN
Rs
RP
CG
CG
XC
RIN=RSW+2/π2RBB
XP
11dB=3.5
2RBB
√2/π
I
Q
Series 
resonance
Loss
Figure 8.71: Front-end model for noise and gain calculations
13 See Chapter 12 detailing the design of a multimode multiband cellular transceiver as a case study.
8.8 LNA/Mixer Case Study
495

design and noise trade-offs are for the most part the same as those described for the voltage-
mode LNAs in Chapter 7. We have chosen not to implement a degeneration inductor for area
reasons, especially knowing that several inductors are needed given the multiband nature of the
design. This comes at the expense of somewhat worse noise ﬁgure and narrower matching.
However, the combination of the matching circuit loss and the shunt feedback resulted by
the gate-drain capacitance is sufﬁcient to provide a reasonable matching with sufﬁciently low
noise ﬁgure.
The LNTA drains 6mA differentially, leading to a transconductance of about 30mS for each
of the core devices biased at about 125mV overdrive. If only limited by the transistor input
nonlinearity, this overdrive voltage would result in an IIP3 of about 1V (or 10dBm referred to
50Ω) for a single device. The LNTA device size is 288μm/60nm. A minimum channel device is
not used since it turns out that the impact of low DC gain due to poor ro on gain and linearity is
far more detrimental compared to the parasitic capacitances.
For this application an input return loss of about –10dB is targeted. If the noise contribution
of the LNTA transistors ignored (we shall shortly verify that), we showed in Chapter 7 that this
leads to a noise factor of 1.5. Given the shunt feedback formed by the gate-drain capacitance,
the actual noise ﬁgure would be somewhat less, as the real part of the input impedance would be
made up of a combination of the matching loss, and a noiseless part created by the shunt
feedback. Once all the package and parasitic reactances are included, the matching network
provides a net available voltage gain of about 11dB (or 3.5), large enough to suppress the
LNTA transistors noise. Given a transconductance of 30mS for the LNTA core device, when
referred to the input, the noise will be

4KTγ
30mS
3:5
2

2 = 4KT  10Ω,
assuming γ = 1. The noise degradation is relatively small, and somewhat offset by the fact that
the shunt feedback caused by gate-drain capacitance lowers the noise factor below 1.5, that is, if
the real of the input impedance were entirely made up of a noisy resistance.
Figure 8.72: Noise ﬁgure circles and optimum
conjugate matching
496
Mixers

As an example, noise ﬁgure circles are plotted in Figure 8.72 for band II (2GHz), as well as
the optimum impedance for conjugate matching (Figure 8.72). If matched to the source, the
noise ﬁgure will be around 3dB. In practice, a compromise may be made to improve the noise
ﬁgure, yet maintaining a reasonable input return loss.
The mixer switch size is 80μm/40nm, corresponding to an on resistance of about 10Ω. Each
TIA branch is biased at 0.5mA. The top and bottom current sources are sized to lower their
transconductance and thus their noise as much as possible, yet maintain a reasonable headroom.
The corresponding transconductances are 3.6mS and 2.8mS for the bottom and top devices.
The core device (M2) on the other hand is biased at weak inversion to maximize gm/ID, which
happens to be about 22V–1 for the process used. This leads to a transconductance of 11mS for
the main device, and consequently an input resistance of about 90Ω. All the devices are long
channel to lower ﬂicker noise. The mixer input resistance around the LO frequency is then
equal to
RIN = RSW + 2
π2 RBB  28Ω,
which is close to the simulated value of 32Ω.
To calculate the overall gain, let us consider Figure 8.71. We showed earlier that the total
available transconductance gain from the source to the TIA output is
GMNgmRF
ﬃﬃﬃ
2
p
π
XP
XP2
Rp + j XP + XC
ð
Þ + RIN


,
where GMN is the matching network gain, gmRF is the LNTA transconductance, and
RIN = RSW + 2
π2 RBB is the mixer input impedance. We also proved that the gain is maximized
if XC
j
j = XP
j
j =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RpRIN
p
. The optimum transconductance gain to each of the I or Q differential
outputs will then be
GMNgmRF
ﬃﬃﬃ
2
p
π
ﬃﬃﬃﬃﬃﬃﬃ
Rp
RIN
r
:
Considering GMN = 3.5, gmRF = 24mS, Rp = 280Ω, the available transconductance gain comes
out to be 60mS. Note that even though the LNTA transistors have a transconductance of 30mS,
the effective LNTA transconductance is somewhat less (24mS) due to the poor DC gain of
the devices, leading to some signal loss at the cascade node, despite not using minimum
channel length.
As we showed in Section 8.4.4, the impact of mixer switches on the overall noise ﬁgure is
minimal, which leaves us with the TIA. Shown in Figure 8.73 is a simpliﬁed schematic of the
mixer interface to the TIA input.
As the TIA is a current-mode buffer with low input impedance, its total output noise is a
function of the impedance appearing at its input. For the moment, we shall assume a time-
invariant single-ended mixer output resistance of R appearing at each branch. The TIA total
output noise current when monitored differentially at the output is then equal to
8.8 LNA/Mixer Case Study
497

ion2 = 2
gm2R
1 + gm2R


2
in12 +
1
1 + gm2R


2
in22 + in32
"
#
,
where in12, in22, and in32 are the spectral densities of the bottom current source (M1), the main
transistor (M2), and the top current source (M3), respectively, and gm2 is the main device
transconductance (Figure 8.70).
To ﬁnd the mixer output resistance, R, consider the right side of Figure 8.73. The resistance
seen by the TIA is evidently time-variant, and the exact analysis is quite involved in the math.
To gain some perspective though, we resort to the following approximation using an LTI
model: For a 25% mixer, at a given branch only at a quarter of a period does the RF
conductance (GRF) appear at the output when the corresponding switch is on. For the remainder
of the period, the conductance seen at the mixer output is zero. Hence, the effective output
conductance could be approximated by taking the time average. Furthermore, since for the
optimum gain the series capacitance (XC) must resonate with the LNTA shunt reactance (XP),
the admittance seen at the mixer input is mostly resistive (ignoring the switch parasitic) and is
equal to
GRF = RP
XP2 :
Consequently,
R  4 RSW + XP2
RP


,
which is found to be about 150Ω for our example. The factor of four is a result of time
averaging and the 25% operation of the mixer. In many cases, however, this approximation may
not hold, and the actual output impedance is probably smaller than this. It is because all the
harmonic folded impedances appear in parallel as well, and the LNTA’s output impedance at
higher harmonics could be a lot smaller than at the fundamental.
There appears to be an optimum for the mixer output resistance R. A larger R leads to higher
noise contribution from the current source, whereas a smaller R increases the TIA core device
… 
GRF=RP/XP
2
R
CG Input
1/R
GRF
t
TLO
XP
XC
Series 
resonance
XP
2/RP
Figure 8.73: CG TIA noise contributions
498
Mixers

noise. However, if the noise of the bottom current source and the core device are comparable, to
the ﬁrst order there is not a strong dependence on R, and it is best to maximize the gain by
providing a series resonance as we showed in Section 8.4.3. Furthermore, given a rather weak
dependence on the value of R, we shall continue to use the approximated formula given above
to estimate the TIA noise.
The situation may be quite different if an opamp-based TIA is used. As shown in Figure 8.74,
assuming a feedback resistance of RL, the opamp input-referred noise is ampliﬁed by
RL
R

 2.
Hence, a low output resistance at the mixer may exacerbates the TIA noise contribution
substantially. From a noise point of view, thus, there may exist a different optimum value for
the series capacitance (XC) as the one suggested by series resonance. On the extreme case, if one
chooses a more traditional design with large series capacitance (XC  0), and a parallel
resonance at the LNTA output, the mixer output resistance will be considerably higher, which
may be advantageous from TIA noise point of view.
Returning to our common-gate example, the total differential output noise current was shown to be
ion2 = 8KTγ
gm2R
1 + gm2R


2
gm1 +
1
1 + gm2R


2
gm2 + gm3
"
#
:
Assuming γ = 2
3 for long channel devices, using the values provided earlier, the noise will be
ion2 = 4KT  8mS:
When referred to the input, given the total available transconductance gain of 60mS, the noise
will be
4KT 8mS
60mS
2

2 = 4KT  10Ω,
which leads to a noise ﬁgure of 0.8dB if the LNTA were noiseless. Once the noise of the LNTA
included, the total noise ﬁgure is
F  1 + 0:7 + 10
50 + 10
50 = 1:9 = 2:7dB
The ﬁrst term is the noise of the source, the second is matching network noise, the third is that
of the LNTA input device, and the last term is the noise contribution of TSA. The results
agree well with the measurements.
CG TIA
R
R
RL
vn
Opamp-based TIA
Figure 8.74: Comparison between CG and
opamp-based TIA noise
8.8 LNA/Mixer Case Study
499

As for the linearity, assuming the input transistor is the dominant source, considering the
matching network gain of 11dB, the IIP3 is
IIP33 = 10dBm  11dB =  1dBm.
Any ﬁltering on the blocker caused by the matching network helps improving the IIP3. On the
other hand, the impact of ﬁnite ro and output nonlinearity, which has been ignored, may become
dominant. For this design, an out-of-band IIP3 of about +1dBm is measured for band II at an
offset of 80MHz, where the TX leakage resides.
Although the circuit ideally operates in current mode, it is beneﬁcial to ﬁnd the voltage gain
of the LNTA from the source to its output. Assuming a series resonance for the optimum gain,
the LNTA output impedance is
RPkjXPk jXC + RIN
ð
Þ = RPk XP2 + jXPRIN
RIN
:
Since XP
2 = RPRIN, the impedance will be
RPk(RP + jXP)  RP/2.
The voltage gain will be then
GMNgmRF
RP
2 :
If this gain is too high, the large swing at the LNTA output caused by the blocker may become
very problematic. Interestingly, for the series resonance case, this gain is not a direct function of
the mixer input impedance. However, this is not quite true. To achieve the same overall
transconductance gain, a lower RIN leads to a lower RP, and thus less voltage gain.14 On the
other hand, in a more traditional design where the series capacitance is larger, the voltage gain
is directly set by the mixer input impedance: GMNgmRFRIN. This clearly indicates a trade-off
between the gain and linearity.
8.8.2
Design Methodology
Although in the previous section we provided analytical details of the circuit of Figure 8.70, we
are yet to offer a methodical approach to obtain the design parameters. The ﬁrst step is to
choose the right circuit topology. The correct topology along with its pros and cons has been
discussed in great detail in the previous sections as well as in Chapter 6.
Once the right architecture is selected (say the one we just discussed), the next step is to ﬁnd
the right combination of the design parameters. This is typically quite application dependent,
and there often may not exist a unique answer. In this section, however, we offer a qualitative
approach to highlight the trade-offs, and provide some design guidelines:
14 Although once the output inductor is set, the value of RP is ﬁxed, one may choose a smaller inductance to lower RP and
hence improve the linearity.
500
Mixers

– The LNTA transconductance and matching network gain are directly determined by the
noise requirements as discussed in Chapter 7. This sets a lower bound for the noise
ﬁgure. We expect the TIA and the subsequent stages, if designed properly, to not
contribute much.
– Once the LNTA device transconductance and the matching are determined, the LNTA bias
current is set based on the linearity requirements. A combination of the matching network
gain and the input device overdrive sets an upper limit on the IIP3. In most modern processes,
it may not be surprising to see a nonlinearity contribution from the output given the poor
device gain and low supply voltages.
– The LNTA load is determined based on the overall gain of the front end, needed to
suppress the noise of the IF circuits, the estimated parasitic capacitances at the output,
and the linearity. The overall transconductance gain was found to be GMNgmRF
ﬃﬃ
2
p
π
ﬃﬃﬃﬃﬃ
Rp
RIN
q
. The
value of the shunt impedance (Rp) sets the transconductance gain (which impacts the
noise), as well as the voltage gain (which impacts the linearity). The linearity improves
with lowering Rp, yet the same overall gain may be maintained by lowering RIN proportion-
ally. The latter determines the bias current of the TIA.
– The TIA bias is obtained based on the overall transconductance gain and noise
requirements. In either common-gate or opamp-based designs, it is best to use long
channel devices biased in weak inversion for the core devices. A higher bias results in
lower RIN, and higher gain for the same linearity (or LNTA output swing). Suppose the
TIA core device has a transconductance of gmTIA. In the case of the CG design for
instance, the output noise current was found to be proportional to 4KTγgmTIA. On the
other hand, the overall transconductance gain is GMNgmRF
ﬃﬃ
2
p
π
ﬃﬃﬃﬃﬃ
Rp
RIN
q
 GMNgmRF
ﬃﬃ
2
p
π
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RpgmTIA
p
. The
TSA noise then, if referred to the input, will be to the ﬁrst order independent of gmTIA.
However, a larger gmTIA does lower the noise contribution of the stages following the
TIA such as the ADC or lowpass ﬁlter.
– The switch resistance is also a determining factor for the mixer input resistance (RIN). As a
rule of thumb, we set the switch size such that the two terms 2
π2 RBB and RSW are comparable.
A smaller switch size may be chosen to lower the LO power consumption, and the overall
RIN may be adjusted by burning more current in the TIA, and thus reducing RBB.
Once an initial set of parameters is chosen according to the application, often a few iterations
are needed to ﬁne-tune the design.
If the RF transconductance ampliﬁer does not incorporate a tuned load, for instance if it is
built of complementary FETs (basically an inverter), the design ﬂow will be much more
straightforward. Suppose the RF transconductor, shown in Figure 8.75, sees a shunt impedance
of Rpk
1
jCPω at its output. In the case of an inverter-like transconductor, Rp = ronkrop, and CP
represents all the parasitic capacitances at the output node.
The RF transconductance and the matching network are designed according to noise trade-
offs as before. The series capacitance is simply large enough to provide an AC short at the
frequency of interest. If possible, it may be removed altogether and replaced by a CMFB circuit
(see Section 8.4 and Figure 8.29). To minimize the RF loss, clearly RIN  Rp. The total
8.8 LNA/Mixer Case Study
501

bandwidth will then be set by the combination of the output parasitic capacitance Cp and the
mixer input impedance RIN. Additionally, RIN may be reduced further to lower the voltage gain
(which is now GMNgmRFRIN) to minimize the blocker swing at the mixer input. If the conditions
above are satisﬁed, the total transconductance gain will be
ﬃﬃﬃ
2
p GMNgmRF
π
:
This topology, when designed properly, leads to a wideband and blocker tolerant scheme,
commonly employed in the context of software-deﬁned radios (see Chapter 12 for more
details). The main challenge with the circuit of Figure 8.75 arises from the dependence of the
LNA noise and input impedance on the load resistance seen at the output, which is largely a
function of the mixer and the TIA. Thus, it is very critical to codesign the LNTA along with the
mixer and TIA very carefully. A cascode inverter may prove to be helpful, although it
compromises the headroom and linearity.
8.9
Summary
This chapter discussed the analysis and design of mixers for receivers and transmitters.
– Sections 8.1 and 8.2 covered the fundamental properties of the mixers, the general require-
ments, and their evolution from vacuum tube era to modern nanometer CMOS.
– Active downconversion mixers were discussed in Section 8.3. Section 8.3 also covered the
nonideal effects, including noise and distortion. Several topologies to circumvent noise and
2nd-order distortion were explained as case studies.
– Passive current-mode mixers were presented in Section 8.4, along with their nonideal
effects. Multiphase passive mixers and their properties were covered in this section
as well.
– Section 8.5 discussed the voltage-mode passive mixers.
– Transmitter mixers were discussed in Section 8.6. The relevant topic of harmonic folding
in transmitter mixers and its impact on the transmitter performance was covered in
Section 8.7.
– Finally, a 40nm receiver front end as a case study was presented in Section 8.8.
TIA
TIA
RIN=RSW+2/π2RBB
√2/π
I
Q
CP
RP
Matching
Figure 8.75: Passive mixer with
invert-like RF transconductor
502
Mixers

8.10 Problems
1. In the mixer shown below, assume the FET is square-law, and remains in saturation all the
time. If vRF(t) = a sin ω0t, and vLO(t) = A sin ωLOt, ﬁnd the mixer transconductance conver-
sion gain. How does that compare to the FET transconductance if it were to be used as a
linear ampliﬁer? Hint: The upper bound of the LO voltage is set by the requirement of the
FET staying on. Answer: Gc
Gm =
βA=2
β VGS0VTH
ð
Þ < 1
2.
VDD
IF
VB
LO
RF
+
vRF–vLO+VGS 0
–
w
w
w
2. The circuit shown below, known as a differential pair mixer, is intended to be used in a zero-
IF receiver. Assuming the BJTs remain in forward active mode, analyze the circuit operation
and ﬁnd the mixer transconductance conversion gain. Answer: Gc =
A
4VT
α
RE + re1, where A is
the LO amplitude, VT = KT
q , and α =
β
β + 1.
VCC
RF
IF
RC
RC
–VEE
LO
RE
RB1
RB2
Q1
Q2
Q3
8.10 Problems
503

3. In the previous problem, assume the supply voltage is 5V, and the LO amplitude is 200mV
peak. Design the circuit for a bias current of 1mA, and a voltage gain of 6dB.
4. Find the noise ﬁgure of a single-balanced active mixer with active load. Do not ignore the
load resistor noise.
5. Using the gm/ID and IIP3 curves provided in Chapter 6, design a double-balanced active
mixer with passive load with the following speciﬁcations: gain: 0dB, NF: 10dB,
IIP3:10dBm. Noise and IIP3 are referred to 50Ω for convenience. Find the proper LO swing
and its DC level. The supply voltage is 1.2V.
6. Repeat Problem 5, but assume the mixer is single-balanced with an active load, and the
required gain is 12dB. Assume N and P devices have a similar gm/ID. Ignore ro.
7. Find the noise ﬁgure of a double-balanced mixer, with one FET connected to a single-ended
input, and the other one left at a DC bias. Discuss the pros and cons of this scheme. Answer:
F = 1 +
8KTγgm + 16KTγ I
πA + 8KT
RL
4KTRs
2
πgm
ð
Þ
2
.
8. A sinusoid signal (A sin ω0t) accompanied by a small sideband (v1 = a sin(ω0 + ωm)t, a  A)
is applied to an ideal limiter as shown below. The limiter is simply a differential pair whose
devices overdrive voltage is much smaller than the sinusoid amplitude (Veff  A). Using the
same analysis provided for the switching pair ﬂicker noise, ﬁnd the spectrum at the limiter
output. Answer: The output consists of a square-wave toggling between I0 at the main
signal frequency, and sidebands at ωm offset with 6dB less relative amplitude than the
fundamental at ω0.
V
A
eff
v
a
A
IN
m
l
io
w
w
w
9. For the following single-balanced active mixer, show that the instantaneous transconduc-
tance of the switching pair is Gm tð Þ = ∂iOUT
vLO = 2 gm1 tð Þgm2 tð Þ
gm1 tð Þ + gm2 tð Þ. Show that the instantaneous
spectral density of the output current noise (due to the noise of both switches) is SiOUT( f )
= 8KTγGm(t), where the noise of each device is Sin1/2( f ) = 4KTγgm1/2(t). Find the output
noise power spectrum assuming a sinusoid LO with fast switching. Hint: The switches add
noise only at zero crossings where vLO  0.
504
Mixers

i
i
lDC
n
iOUT
n
10. To combat ﬂicker noise of switches in the active mixer used in a zero-IF receiver, a student
proposes the following active mixer circuit with two transconductances and a large
capacitor to store ﬂicker noise and random input-referred DC offset due to mismatches.
Explain the ﬂaw with this mixer circuit and why it cannot be used in the zero-IF receiver.
Hint: Show that the downconverted current has to pass through a capacitor, which is open
at DC.
vOUT
iIN IDC
iIN IDC
VDD
RL
R
C
L
VDD
11. Find the IIP2 of a single-balanced active mixer where the load resistors are mismatched
(one is RL, the other is RL(1 + α)). Simplify your answer assuming the input transistors are
square-law. Answer: IIP2 = 16
π
Veff
α .
12. Design a 6-phase mixer with ideal LO signals, each with one-sixth of a cycle duration. Find
the coefﬁcients of each branch, the effective LO, and the mixer gain. Discuss the pros and
cons of the mixer compared to a 4- and an 8-phase design.
13. Repeat Problem 12 for a 3-phase mixer.
14. Show that the minimum number of phases needed to distinguish the signal from its image
is 3. Why are 4-phase mixers more popular in zero-IF receivers?
8.10 Problems
505

15. Find the leakage gain of a passive current-mode mixer with an offset voltage at the gate of
one switch modeling the mismatches.
16. Calculate the IIP2 of a passive current-mode mixer when there is a nonzero RF to LO
feedthrough.
17. Design a current-mode passive mixer operating at 2GHz with a complementary (inverter-
like) RF gm, and a common-gate TIA. Use the gm/ID and IIP3 curves provided in Chapter 6.
The device DC gain is 10.
The mixer gain is 30dB, and its noise ﬁgure referred to 50Ω (although it is unmatched) is
3dB. The mixer has an out-of-band 1dB compression of –10dBm. Find the switch resist-
ance, the value of C1, the TIA input device gm, the load resistance and bias current, and the
RF gm current and overdrive voltage. The intended frequency of operation is 2GHz.
18. Repeat Problem 17, where the RF gm is an inductively loaded FET shown below. Assume
the shunt resistance at the LNTA output is 200Ω at 2GHz.
QL
19. Discuss the pros and cons of using an opamp-based TIA for Problems 17 and 18.
506
Mixers

20. Consider the fully differential passive current-mode mixer shown below, driven by a
single-ended gm cell.
P
P
Argue why one may choose this scheme where the second set of switches are connected to
ground (as opposed to removing them). Discuss the pros and cons of this scheme, and
particularly any degradation in mixer noise ﬁgure.
8.11 References
[1] R. Rafuse, “Symmetric MOSFET Mixers of High Dynamic Range,” in IEEE International Solid-State
Circuits Conference. Digest of Technical Papers, 1968.
[2] B. Gilbert, “A Precise Four-Quadrant Multiplier with Subnanosecond Response,” IEEE Journal of Solid-
State Circuits, 3, no. 4, 365–373, 1968.
[3] P. R. Gray and R. G. Meyer, Analysis and Design of Analog Integrated Circuits, John Wiley, 1990.
[4] M. Terrovitis and R. Meyer, “Intermodulation Distortion in Current-Commutating CMOS Mixers,” IEEE
Journal of Solid-State Circuits, 35, no. 10, 1461–1473, 2000.
[5] H. Darabi and A. Abidi, “Noise in RF-CMOS Mixers: A Simple Physical Model,” IEEE Journal of Solid-
State Circuits, 35, no. 1, 15–25, 2000.
[6] D. Binkley, C. Hopper, J. Cressler, M. Mojarradi, and B. Blalock, “Noise Performance of 0.35um SOI
CMOS Devices and Micropower Preampliﬁer from 77–400k,” IEEE Transactions on Nuclear Science,
51, no. 6, 3788–3794, 2004.
[7] J. Chang, A. Abidi, and C. Viswanathan, “Flicker Noise in CMOS Transistors from Subthreshold to
Strong Inversion at Various Temperatures,” IEEE Transactions on Electron Devices, 41, no. 11,
1965–1971, 1994.
[8] M. Terrovitis and R. Meyer, “Noise in Current-Commutating CMOS Mixers,” IEEE Journal of Solid-
State Circuits, 34, no. 6, 772–783, 1999.
[9] H. Darabi and J. Chiu, “A Noise Cancellation Technique in Active RF-CMOS Mixers,” IEEE Journal of
Solid-State Circuits, 40, no. 12, 2628–2632, 2005.
8.11 References
507

[10] D. Manstretta, M. Brandolini, and F. Svelto, “Second-Order Intermodulation Mechanisms in CMOS
Downconverters,” IEEE Journal of Solid-State Circuits, 38, no. 3, 394–406, 2003.
[11] M. Brandolini, P. Rossi, D. Sanzogni, and F. Svelto, “A +78dBm IIP2 CMOS Direct Downconversion
Mixer for Fully Integrated UMTS Receivers,” IEEE Journal of Solid-State Circuits, 41, no. 3, 552–559,
2006.
[12] M. Brandolini, M. Sosio, and F. Svelto, “A 750mV Fully Integrated Direct Conversion Receiver
Front-End for GSM in 90-nm CMOS,” IEEE Journal of Solid-State Circuits, 42, no. 6, 1310–1317,
2007.
[13] D. Kaczman, M. Shah, M. Alam, M. Rachedine, D. Cashen, L. Han, and A. Raghavan, “A Single-Chip
10-Band WCDMA/HSDPA 4-Band GSM/EDGE SAW-Less CMOS Receiver with DigRF 3G Interface
and 90dBm IIP2,” IEEE Journal of Solid-State Circuits, 44, no. 3, 718–739, 2009.
[14] A. Mirzaei, H. Darabi, J. Leete, X. Chen, K. Juan, and A. Yazdi, “Analysis and Optimization of Current-
Driven Passive Mixers in Narrowband Direct-Conversion Receivers,” IEEE Journal of Solid-State
Circuits, 44, no. 10, 2678–2688, 2009.
[15] X. Gao, E. Klumperink, and B. Nauta, “Advantages of Shift Registers over DLLs for Flexible Low Jitter
Multiphase Clock Generation,” IEEE Transactions on Circuits and Systems II: Express Briefs, 55, no. 3,
244–248, 2008.
[16] Z. Ru, N. Moseley, E. Klumperink, and B. Nauta, “Digitally Enhanced Software-Deﬁned Radio
Receiver Robust to Out-of-Band Interference,” IEEE Journal of Solid-State Circuits, 44, no. 12,
3359–3375, 2009.
[17] D. Murphy, H. Darabi, A. Abidi, A. Hafez, A. Mirzaei, M. Mikhemar, and M.-C. Chang, “A Blocker-
Tolerant, Noise-Cancelling Receiver Suitable for Wideband Wireless Applications,” IEEE Journal of
Solid-State Circuits, 47, no. 12, 2943–2963, 2012.
[18] J. Weldon, R. Narayanaswami, J. Rudell, L. Lin, M. Otsuka, S. Dedieu, L. Tee, K.-C. Tsai, C.-W. Lee,
and P. Gray, “A 1.75-GHz Highly Integrated Narrow-Band CMOS Transmitter with Harmonic-Rejection
Mixers,” IEEE Journal of Solid-State Circuits, 36, no. 12, 2003–2015, 2001.
[19] A. Mirzaei, H. Darabi and D. Murphy, “Architectural Evolution of Integrated M-Phase High-Q Bandpass
Filters,” IEEE Transactions on Circuits and Systems I: Regular Papers, 59, no. 1, 52–65, 2012.
[20] W. Redman-White and D. Leenaerts, “1/f Noise in Passive CMOS Mixers for Low and Zero IF Integrated
Receivers,” in Proceedings of the 27th European Solid-State Circuits Conference, 2001.
[21] S. Chehrazi, R. Bagheri, and A. Abidi, “Noise in Passive FET Mixers: A Simple Physical Model,” in
Proceedings of the IEEE Custom Integrated Circuits Conference, 2004.
[22] S. Chehrazi, A. Mirzaei and A. Abidi, “Noise in Current-Commutating Passive FET Mixers,” IEEE
Transactions on Circuits and Systems I: Regular Papers, 57, no. 2, 332–344, 2010.
[23] A. Mirzaei, H. Darabi, J. Leete, and Y. Chang, “Analysis and Optimization of Direct-Conversion
Receivers with 25% Duty-Cycle Current-Driven Passive Mixers,” IEEE Transactions on Circuits and
Systems I: Regular Papers, 57, no. 9, 2353–2366, 2010.
[24] E. Sacchi, I. Bietti, S. Erba, L. Tee, P. Vilmercati, and R. Castello, “A 15mW, 70kHz 1/f Corner Direct
Conversion CMOS Receiver,” in Proceedings of the IEEE Custom Integrated Circuits Conference,
2003.
[25] S. Chehrazi, A. Mirzaei, and A. Abidi, “Second-Order Intermodulation in Current-Commutating Passive
FET Mixers,” IEEE Transactions on Circuits and Systems I: Regular Papers, 56, no. 12, 2556–2568,
2009.
[26] M. Soer, E. Klumperink, P.-T. de Boer, F. van Vliet, and B. Nauta, “Uniﬁed Frequency-Domain Analysis
of Switched-Series-Passive Mixers and Samplers,” IEEE Transactions on Circuits and Systems I: Regular
Papers, 57, no. 10, 2618–2631, 2010.
[27] A. Mirzaei, D. Murphy, and H. Darabi, “Analysis of Direct-Conversion IQ Transmitters with 25% Duty-
Cycle Passive Mixers,” IEEE Transactions on Circuits and Systems I: Regular Papers, 58, no. 10,
2318–2331, 2011.
508
Mixers

[28] R. Brederlow, W. Weber, C. Dahl, D. Schmitt-Landsiedel, and R. Thewes, “Low-Frequency Noise of
Integrated Polysilicon Resistors,” IEEE Transactions on Electron Devices, 48, no. 6, 1180–1187,
2001.
[29] A. van der Wel, E. Klumperink, J. Kolhatkar, E. Hoekstra, M. Snoeij, C. Salm, H. Wallinga, and
B. Nauta, “Low-Frequency Noise Phenomena in Switched MOSFETs,” IEEE Journal of Solid-State
Circuits, 42, no. 3, 540–550, 2007.
[30] B. Cook, A. Berny, A. Molnar, S. Lanzisera, and K. Pister, “Low-Power 2.4GHz Transceiver with
Passive RX Front-End and 400mV Supply,” IEEE Journal of Solid-State Circuits, 41, no. 12,
2757–2766, 2006.
8.11 References
509

9
Oscillators
In this chapter we present a detailed discussion on various types of oscillators, including ring
and crystal oscillators. The LC resonators and integrated capacitors and inductors have been
already discussed in Chapter 1, and are essential to this chapter. Furthermore, some of the
communication concepts that we presented in Chapter 2, such as AM and FM signals, as well
as stochastic processes, are frequently used in this chapter.
Given the nonlinear nature of the oscillators, we will offer a somewhat different view on
noise compared to much of the material presented on ampliﬁers and mixers. This is captured
in the “Cyclostationary Noise” section (9.3.5), which is a continuation of our discussion in
Chapter 5. Even though we introduced the concept of phase noise in Chapter 6, we present a
detailed analysis based on the concept of energy balance, brieﬂy touched on in Chapter 1.
Although the focus of this chapter is mainly LC oscillators, which are widely used in RF
transceivers, we will also cast brief discussions on ring and quadrature oscillators. Both
schemes are not as common given the performance limitation that we shall discuss. We
conclude the chapter by presenting crystal oscillators basic properties, and discuss several
commonly used topologies.
The speciﬁc topics covered in this chapter are:
• Linear oscillators and Leeson’s model
• Nonlinear oscillators and energy balance model
• AM and PM noise
• Cyclostationary noise
• Bank’s general result
• Two-port oscillators
• Examples of common oscillators topologies: NMOS, CMOS, Colpitts, and class C
• Ring oscillators
• Quadrature oscillators
• Crystal oscillators
For class teaching, we recommend the linear oscillator (Section 9.1), and selected oscillator
topologies from Section 9.4. If deemed necessary, a summary of Bank’s results (Section 9.3.8)
may be presented to understand the phase noise derivation of various topologies better.
A detailed discussion of phase noise (Sections 9.2 and 9.3) must be deferred to a more
advanced course. Sections 9.7, 9.8, 9.9, and 9.10 may be assigned as reading.

9.1
THE LINEAR LC OSCILLATOR
..............................................................................................
An ideal LC oscillator consists of an inductor and capacitor connected in parallel. As discussed in
Chapter 1, any initial energy stored in this resonator (or tank) will oscillate back and forth between
the two components. Unfortunately, any physical realization of these passive components will
have some associated loss, which will result in a decaying oscillation. Therefore, to ensure a
constant oscillation amplitude, a practical LC oscillator requires a circuit that periodically injects
energy into the resonator in order to balance the energy dissipated by losses in the tank.
Practical (i.e., physically realizable) LC oscillators are by necessity nonlinear circuits.
Nevertheless, many basic insights into their operation can be gleaned by studying a simple
linear abstraction, and so the theoretical linear LC oscillator is ﬁrst reviewed in this section.
9.1.1
The Feedback Model
Shown in Figure 9.1 is a lossy resonator connected to an energy-restoring circuit. In RF-CMOS
the active circuit is typically some form of transconductance, and therefore we have modeled it
as such. The noise associated with the lossy resonator and the transconductance are both
modeled as current sources (i.e., inRp(t) is the noise source associated with the tank loss,
and ingm(t) is the noise associated with the transconductance). An aperiodic current source,
iSU(t), is also included, which will be used to start-up the oscillator. Using straightforward
manipulation, the circuit can be recast in the form of a feedback system (also shown in
Figure 9.1), where the noise sources and the start-up current become the inputs to an LTI
system whose transfer function is given by
H sð Þ =
Ztank sð Þ
1 + gmZtank sð Þ =
s 1
Cp
s2 + s 1 + gmRp
RpCp


+
1
LpCp
:
From feedback theory, it follows that the loop is stable if the poles of H(s) are in the left-half
plane (gm >  1/Rp), the loop is unstable if the poles of H(s) are in the right-half plane
Lp
Cp
Rp
iSU(t)
Ztank
VOSC
VOUT
VIN
gmVIN
ingm(t)
inRp(t)
Energy-Restoring Circuit
(transconductance)
∑ 
VOSC(t)
iSU(t) + 
inRp(t) + 
ingm(t)
Ztank
gm
Start-up
current
Figure 9.1: The linear LC oscillator
9.1 The Linear LC Oscillator
511

(gm <  1/Rp), while the loop is marginally stable if the poles of H(s) reside along the
imaginary-axis (gm =  1/Rp).
Now, consider the case where the start-up current is a single impulse, i.e., iSU(t) = qSUδ(t),
where qSU is in units of amperes times second (i.e., coulombs). The response of this linear
system to the impulse for the three different cases (assuming complex poles) is shown in
Figure 9.2. If the loop is stable, the injected energy will produce an oscillation that will
eventually decay, if the loop is unstable the oscillation amplitude will grow without bound
(drawing ever more energy from the ideal transconductance), while in the marginally stable
case a constant oscillation is produced with an amplitude proportional to the energy injected by
the start-up current,1 i.e., qSU/Cp.
The marginally stable condition results in the only desirable output; however, this condition
cannot be achieved in practice because any inﬁnitesimal deviation in gm will result in a growing
or decaying oscillation (hence why a linear oscillator is just an abstraction). Instead, oscillators
are designed such that gm <  1/Rp, which results in a growing oscillation. This growing
oscillation will eventually self-limit because a practical implementation of the transconductance
cannot draw inﬁnite power. Accordingly, the amplitude of oscillation in a real oscillator is
independent of the start-up current, and instead depends on the nonlinear characteristics of the
energy-restoring circuit.
As an oscillator is designed to ensure gm <  1/Rp, an explicit start-up current is generally
not required. This is because in this unstable state an arbitrarily small amount of injected energy
will excite a growing oscillation. This small amount of energy is typically just the noise sources
in the system (i.e., inRp(t) and/or ingm(t)).
9.1.2
Phase Noise in the Linear Oscillator
In 1966, Leeson used the linear feedback model to derive an expression for phase noise [1]. We
will present a simpliﬁed restatement of that work here. Taking the linear model (shown in
∑ 
VOSC(t)
iSU(t) = qSUδ(t)
Ztank
gm
gm> –1/Rp
gm =–1/Rp
gm<–1/Rp
qSU/Cp
qSU/Cp
qSU/Cp
VOSC(t)
VOSC(t)
VOSC(t)
Figure 9.2: Impulse response of
the linear LC oscillator
1 This result can be obtained using the initial value theorem, i.e., lim
t!0 vosc tð Þ = lim
s!∞sH sð ÞqSU.
512
Oscillators

Figure 9.3), we note that the noise transfer function for the marginally stable condition (i.e.,
gm =  1/Rp) is easily deduced as
H jω
ð
Þ
j
j2 =
ωLp
1  ω2LpCp


2
,
which is simply the squared impedance of a lossless resonator. This is more obvious if
we redraw the memoryless transconductance as a negative resistance equal1/Rp as shown
in Figure 9.3. In this case, the negative resistance (1/gm) perfectly cancels out Rp and the
noise current doesn’t see either the equivalent tank resistance or the negative resistance provide
by the energy-restoring circuit. The noise current only sees an ideal inductor and capacitor in
parallel.
Because of the strong ﬁltering action of the lossless resonator, the transfer function
close to the resonance frequency is the only region of interest in any RF application, i.e.,
around ω = ω0  Δω, where ω0 = 1=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LpCp
p
and Δω  ω0. This allows for a further simpliﬁ-
cation of the noise transfer function,
H j ω0 + Δω
ð
Þ
ð
Þ
j
j2 
1
2ΔωCp


2
= ω02Lp
2Δω


2
=
R2
p
4
1
Q2
ω0
Δω

2
,
where Q =
Rp
Lpω0
is the resonator quality factor. Given that we are still dealing with an LTI
system, the power spectral density (PSD) of the voltage noise around the oscillation frequency
is therefore simply v2
n = i2
n H j ω0 + Δω
ð
Þ
ð
Þ
j
j2. Now, as discussed in Chapter 6 and shown in
in( )
ZTANK
gm=-1/Rp
0
0
vn( )=in( )|H( )|2
Lp
Cp
Rp
vn
in
Energy-restoring
circuitmodelas
negativeresistance,
gm=-1/Rp
1/gm
H(ω)=(1/jωCp) || jωLp
in
Vn
H( )
Rp
Figure 9.3: Noise transfer function of the linear oscillator
9.1 The Linear LC Oscillator
513

Figure 9.4, the deﬁnition of phase noise is this voltage spectral density normalized to carrier
power, i.e.,
ℒΔω
f
g = v2
n ω0 + Δω
ð
Þ
A2=4
,
where A is the peak oscillation amplitude.2 Generally, this is quoted and/or plotted in unit of
decibels below carrier per hertz [dBc/Hz], i.e.,
ℒ{Δω}dBc/Hz = 10log10ℒ{Δω}.
In performing this normalization in the context of a linear oscillator, two fudges are
employed to account for fact we are modeling a real nonlinear oscillator with a linear
abstraction:
1. We divide i2
n by 2 before the normalization to account for the fact that in a nonlinear
oscillator generally half the noise is rejected because it is amplitude noise, i.e.,
v2
n = i2
n=2


H j ω0 + Δω
ð
Þ
ð
Þ
j
j2. The reasoning behind this maneuver will be fully detailed
in a later section, but at his point it is sufﬁcient to assume that roughly half of the noise
modulates the phase of the carrier, while the other half will modulate the amplitude of the
carrier. In practical oscillators, amplitude noise will be heavily suppressed by the nonlinear
nature of the circuit, while phase noise will persist.
2. As the large signal dynamics of the nonlinearity are unknown, we cannot (at this stage)
quantify the amount of noise that the nonlinearity itself injects. We will therefore represent
ω0
Sidebands
due to noise 
(vn{ω})
–ω0
0
ω0+Δω  
Carrier Power
A2/4
Carrier Power
A2/4
Ratio between 
carrier power 
and single-
sideband
(L{Δω})
ω0–Δω  
–ω0+Δω  
–ω0–Δω  
Figure 9.4: Phase noise is
the single-sideband noise
power normalized to the
carrier power. The ﬁgure
shows the double-sided
frequency spectrum, but
the phase noise deﬁnition
is valid whether a single-
sided or double-sided
frequency deﬁnition of
power is used
2 All spectral density terms used in this chapter (unlike previous chapters) are deﬁned on a double-sided frequency axis, not a
single-sided frequency axis. For the simple case of the spectral density of the voltage noise of resistor, R, the deﬁnition we
use is *v = *vDS = 2kTR rather than *vSS = 4kTR.
Furthermore, as the noise spectral density, v2
n, is deﬁned on the doubled-sided frequency spectrum, it is normalized to
A2/4 rather than the RMS power A2/2. See Figure 9.4 for further clariﬁcation.
514
Oscillators

the injected total current noise3 as i2
n = i2
Rp + i2
gm = 2kTF=Rp, where the unknown constant F,
which we will term “oscillator noise factor,” accounts for the uncertainty in the injected
noise. If the energy-restoring circuit is noiseless, F = 1 (much like the deﬁnition for LNA
noise factor).
Given these adjustments, which will be justiﬁed when we study a nonlinear oscillator, the phase
noise of the linear oscillator can be expressed as
ℒΔω
f
g =
i2
n
2
 !
H j ω0 + Δω
ð
Þ
ð
Þ
j
j2
A2=4
= kTFRp
A2
1
Q2
ω0
Δω

2
,
which is Leeson’s well-known expression for phase noise.
When ℒ{Δω}dBc/Hz is viewed on a spectrum analyzer (see Figure 9.5), three distinct regions
will generally be seen: a 20dB/decade region due to thermal noise in the system; a 30dB/
decade region due to ﬂicker noise in the system; and a ﬂat region far from the carrier that is not
due to the oscillator, but is attributable to either buffer noise or test equipment noise. The above
expression qualitatively predicts the –20dB/decade region, but it does not explain the –30dB/
decade region. This latter region can be explained only using more sophisticated nonlinear
analysis, which will be presented later in this chapter.
9.1.3
Efﬁciency
In order to deliver real power to the tank, the active circuit must take it from a power source,
which is typically the DC supply rail. Especially in wireless applications, it is important to
inject energy into the tank in the most efﬁcient manner possible. In the case of an oscillator, this
power efﬁciency is deﬁned as
η = Ptank tð Þ
PDC
= A2= 2Rp

	
VDDIDD
,
where Ptank tð Þ is the average power burned in tank over one oscillation period, and PDC is the
DC power drawn from the supply. Since there are no energy sources in the oscillator circuitry
–30dB/decade
(flicker noise region)
–20dB/decade
(thermal noise region)
L{Δω} [dBc/Hz]
Carrier Offset, Δω
Flicker noise 
corner
Flat region
(buffer/instrument noise)
Figure 9.5: Typical phase noise proﬁle (where
carrier offset is plotted on a log scale)
3 Note that since this chapter assumes a doubled-sided frequency axis, i2
n = 2kTF=Rp and not i2
n = 4kTF=Rp.
9.1 The Linear LC Oscillator
515

other than the supply, power efﬁciency cannot exceed 1 (or a 100%). Ideally all the DC power
is burned in the tank (compensating for the losses), and no power is burned in the active circuit.
Power efﬁciency can also be recast in the following form,
η = 1
2
Itank@ω0
IDD


A
VDD


= ηI
A
VDD
,
where ηI is the active circuit’s current efﬁciency [2]. It is a measure of how effectively the
supply current is injected into the tank at ω0 and is deﬁned as
ηI = Itank@ω0
2IDD
,
where Itank @ ω0 = A/Rp.
9.1.4
Oscillator Figure of Merit
It is common to benchmark various LC oscillator designs using the following ﬁgure of
merit [3],
FOM =
ω0
Δω

2
PDC=1mW
ð
Þ ℒΔω
f
g ,
which is essentially the phase noise per unit power normalized to oscillator frequency and
carrier offset. In general, FOM varies with carrier offset (see Figure 9.6), but when reported as a
single number it is assumed that FOM was calculated using measurements from the thermal noise
region where the FOM plateaus. We will follow this convention. To gain some insight we
substitute Leeson’s expression in the above deﬁnition for FOM and recast in the following form,
FOM =
ηQ2
F


2
kT


103,
10 dB /decade
FOM [dB/Hz]
–30dB/decade
–20dB/decade
L{Δω} [dBc/Hz]
Flat region
–20dB/decade
FOM quoted in this 
flat region
Carrier Offset, Δω
Figure 9.6: The oscillator ﬁgure of merit is a function
of carrier offset frequency. Typically, the FOM in the
thermal noise region is quoted
516
Oscillators

which demonstrates that FOM depends on only three variables: the quality factor of the LC tank
(Q), the efﬁciency of the oscillator (η), and the oscillator’s noise factor (F).
Maximizing Q (or, equivalently minimizing tank losses) is the single best way to improve the
performance of any LC oscillator. However, Q is technology dependent and largely outside the
control of an RF circuit designer. Moreover, it is independent of a speciﬁc oscillator topology,
and therefore, when assessing a given architecture we can say that a good architecture is simply
one that maximizes efﬁciency and minimizes noise factor. That is, the best topology is one that
maximizes η/F. By deﬁnition the maximum value of η/F is 1, which would correspond to a
noiseless, 100% efﬁcient active element [4].
9.2
THE NONLINEAR LC OSCILLATOR
..............................................................................................
At this point the astute reader has many unanswered questions: What is the value of the noise
factor F? Why can we disregard amplitude noise? How can we predict the oscillation ampli-
tude? How is the –30dB/decade region explained? To answer these and other important
questions, we need to analyze the LC oscillator as a nonlinear, time-varying circuit.
9.2.1
Intuitive Understanding
Shown in Figure 9.7 is a nonlinear LC oscillator with a tank loss of Rp = 100Ω. Compared to
Figure 9.1, the only difference is that energy-restoring-circuit4 is drawn as an explicit nonlinear
conductance, whose instantaneous conductance is some function of the voltage across its
terminals. We assume the energy-restoring-circuit is memoryless, which is to say it contains
no reactive components (i.e., no inductors, capacitors, or any other energy-storage devices).
As deduced from the I–V characteristic of the negative resistance (also shown in Figure 9.7),
the conductance is 20mS around vnr = 0 and, so, given that the tank resistance is 100Ω, the
oscillator will start up. However, as also shown in Figure 9.7, the waveform will eventually self-
limit. Plotting both gnr(t) = dinr(t)/dvnr(t) and vosc(t), we see that during start-up gnr(t) <  1/Rp
and consequently we see a growing oscillation, but when the amplitude stabilizes gnr(t) is less
than 1/Rp for only a small portion of the oscillation. This is because of the compressive nature of
the negative conductance, since it cannot provide an arbitrarily large amount of current when
presented with an arbitrarily large voltage. As all circuits will eventually compress if driven hard
enough, this is the mechanism through which the oscillation waveform self-limits.
As a thought experiment, suppose we separately drive the negative resistance and the tank
with a sinusoid whose frequency is the same as the tank’s resonant frequency (Figure 9.8). In
this setup, the amount of power dissipated in the tank and the amount of power provided by the
active circuit will be a function of the amplitude of the applied sinusoid. Notably, for amplitudes
less than 0.57V, the active resistor will provide more power than the tank dissipates, while for
4 Depending on the context, the oscillator’s energy-restoring circuit is referred to as a negative resistance, a negative conductance,
a nonlinear resistance, a nonlinear conductance, an active element, and/or an active circuit. These terms are essentially
synonymous.
9.2 The Nonlinear LC Oscillator
517

amplitudes greater than 0.57V, the tank will dissipate more power than the circuit can provide.5
Accordingly, in the oscillator of Figure 9.7, the output waveform will grow if the amplitude is less
than 0.57V, while it will decay if the amplitude is greater than 0.57V. As a result, the output
amplitude settles to 0.57V because it is the only stable large signal operating point. Even if a
disturbance (noise or otherwise) changes the instantaneous amplitude, it will eventually return to
this operating point. Therefore, unlike the linear oscillator, the oscillation amplitude of a non-
linear oscillator is independent of the initial energy stored in the tank.
In the next section, a mathematical description of this power balance is used to derive the
“effective” or “large signal” conductance provided by the active element. This effective
conductance, deﬁned as Geff, is equal to the negative of the tank loss conductance when
sustained oscillation occurs (as also shown in Figure 9.8).
Lp
Cp
Rp=100Ω
vosc(t)
gnr(t)
DC Characteristic of the Active Resistor
Start–up Behavior of the Nonlinear LC Oscillator
During start–up
gnr(t)<–1/Rp
gnr(t)<–1/Rp for only a 
portion of the oscillation
inr(t)
–1/Rp
–1/Rp
5
0
–5
Current [mA]
Conductance [mS]
–1
–0.5
0
Voltage [V]
0.5
20
10
0
–10
–20
1
1
0.5
0
–0.5
Output Voltage [V]
Output Voltage [V]
Conductance [mS]
Conductance [mS]
Output Voltage [V]
–10
10
20
30
40
50
Time [nS]
Time [nS]
0.5
0.25
0
–0.25
–0.5
30
31
32
33
80
–0.5
–0.25
0
0.25
0.5
81
82
83
–20
–10
0
10
20
–20
–10
0
10
20
Time [nS]
60
70
80
90
100
Figure 9.7: The nonlinear LC oscillator
5 The balance point (in this case 0.57V) depends on the nonlinearity used and the tank loss.
518
Oscillators

9.2.2
Power Conservation Requirements
Assuming the oscillator has started up, the average power delivered to the resonator must be
matched by the average power dissipated in the tank, i.e., <Pnr(t) > =  < PRp(t)>, or in
terms of currents and voltages,
ðT
0
vosc tð Þinr tð Þdt = 
ðT
0
vosc tð ÞiRp tð Þdt,
where vosc(t) is the output voltage, inr(t) is the current ﬂowing into the active element, iRp(t) is
the current ﬂowing into the tank resistance, and T is the oscillation period. If this power
conservation requirement was not satisﬁed, we would observe a growing or decaying oscilla-
tion. The frequency domain representation6 of this identity is expressed as
X
∞
k = ∞
Vosc k½ Inr k
½
 = 
X
∞
k = ∞
Vosc k½ IRp k
½
,
where Vosc[k], Inr[k], IRp[k] respectively deﬁne the Fourier coefﬁcients of vosc(t), inr(t), and
iRp(t). We assume a nearly sinusoidal output,7 that is, vosc(t) = A cos ωt, which is a reasonable
Geﬀ
Geﬀ
Figure 9.8: The power dissipated and provided in an LC oscillator
6 The Fourier series coefﬁcients used throughout this chapter are deﬁned with respect to the double-sided frequency
spectrum.
7 Throughout this chapter, we assume the output waveform has no initial phase offset, i.e., vosc (t) = A cos(ωt + ϕ), where
ϕ = 0. This is to simplify the math and to make it more readable. Essentially, we are selecting the time reference t = 0 to
coincide with an oscillation peak. Moving the time reference will have no effect on the ﬁnal noise result.
9.2 The Nonlinear LC Oscillator
519

assumption for LC oscillators with moderate Q values. This implies that all values of Vosc[k] are
ﬁltered when k 6¼  1, and Vosc[1] = Vosc[1] = A/2, which allows us to write
Inr 1
½
 + Inr 1½  =  2Vosc 1½ 
Rp
=  A
Rp
:
Note that although vosc(t) is assumed to be nearly sinusoidal, inr(t) can and typically does
contain signiﬁcant harmonic content. Now, if we deﬁne the instantaneous conductance of the
active resistance as gnr(t) = dinr(t)/dvnr(t), we can write inr(t) as
inr tð Þ = Inr DC
ð
Þ +
ð
gnr tð Þ dvnr tð Þ
dt


dt,
and, therefore, the Fourier’s series of inr(t) can be calculated as
Inr k½  =
Inr DC
ð
Þ,
k = 0
j
X
∞
l = ∞
l
k
 
Vnr l½ Gnr k  l
½
,
k 6¼ 0
j
8
>
<
>
:
:
Again, assuming a nearly sinusoidal output, vosc(t) = vnr(t) = A cos ωt, this condition implies
that for k 6¼ 0,
Inr k½  =
A
2k


Gnr k  1
½
  Gnr k + 1
½

ð
Þ ,
which can be used along with the result of the power conservation requirement (i.e., Inr[1] +
Inr[1] =  A/RP) to deﬁne the effective conductance [5], [6] of the active element:
Geff = Gnr 0½   1
2 Gnr 2
½
  1
2 Gnr 2½  =  1
Rp
:
This is the same effective conductance that is plotted in Figure 9.8, and must always
equal 1/Rp under steady state conditions. Note that the effective transconductance is not a
time-averaged transconductance, which would simply be Gnr[0]. If we assume the nonlinear
conductance is memoryless, the instantaneous conductance will be symmetric around t = 0 (i.e.,
gnr(t) = gnr(t) ). This symmetry is because the output waveform, which excites the memory-
less conductance, is deﬁned to be symmetric around t = 0 (i.e., vnr(t) = vnr(t) ). This means
that Gnr[2] = Gnr[2] and the effective conductance simpliﬁes to
Geff = Gnr 0½   Gnr 2½  =  1
Rp
:
Note that for a sustained oscillation to occur in a linear oscillator, the small signal
conductance must equal the tank loss (i.e., gm =  1/Rp in Figure 9.2), but this is a marginally
stable state that is impossible to achieve in practice. By contrast, in a nonlinear oscillator, a
sustained oscillation implies that the effective or large signal conductance balances the tank
loss: Geff =  1/Rp.
520
Oscillators

9.2.3
Oscillation Amplitude
Given the analysis in the previous section, the oscillation amplitude can be calculated as the
tank resistance times the fundamental of the current provided by the active element, i.e.,
A = 2Vosc[1] =  (Inr[1] + Inr[1])Rp.
Depending on the I–V characteristic of a given nonlinearity Inr[1] (and thus A) may or may
not be straightforward to calculate.
9.3
PHASE NOISE ANALYSIS OF THE NONLINEAR LC OSCILLATOR
..............................................................................................
In order to make the noise analysis of a nonlinear oscillator manageable, we are going to
analyze the noise mechanisms much like we analyze noise in a mixer,8 that is:
1. We will initially assume the circuit is completely noiseless, and solve for frequency,
amplitude, operating point, etc.
2. We will then inject small noise sources into circuit, and note its effect on the output
spectrum. We assume that “small” noise sources result in small perturbations in the output
spectrum.
3. Finally, we will treat the oscillator as an LTV system (with respect to noise) and sum the
phase perturbations from each of the noise sources in the system.
Despite these simpliﬁcations, such an approach can adequately quantify phase noise in the
thermal noise region of ℒ{Δω} (i.e., the –20dB/decade region). However, as this approach
deﬁnes a ﬁxed frequency with respect to a noiseless oscillator, it cannot quantify noise in the
spectrum that occurs because of frequency modulation effects. The 30dB/decade region in
ℒ{Δω} can be fully explained only using these effects. Therefore, separate analysis methods
that account for frequency modulation effects will be discussed in a later section.
We start with some basic deﬁnitions of phase, frequency, and amplitude noise and present
simple ways of visualizing them.
9.3.1
Deﬁning Phase, Frequency, and Amplitude Noise
Consider an amplitude, frequency, and phase modulated continuous sinusoid,
vosc tð Þ = A 1 + m tð Þ
ð
Þ cos
ðt
0
ω0 + ωΔ τð Þ
ð
Þdτ + ϕ tð Þ
0
@
1
A
= A 1 + m tð Þ
ð
Þ cos ω0t +
ðt
0
ωΔ τð Þdτ + ϕ tð Þ
0
@
1
A,
8 The analysis approach presented in this chapter is based on [5], [6], [8], [9], [32].
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
521

where m(t) modulates amplitude, ωΔ(τ) modulates frequency, and ϕ(t) modulates phase.
Assuming small modulation indexes, i.e., m(t)  1, ωΔ(τ)  ω0, and ϕ(t)  2π, this can be
rewritten using the small angle approximation as
vosc tð Þ  A cos ω0t + m tð Þ A cos ω0t 
ϕ tð Þ +
ðt
0
ωΔ τð Þdτ
0
@
1
AA sin ω0t,
which in the frequency domain is
Vosc (ω)  Aπδ (ω  ω0) + Aπδ (ω + ω0) + A
2 M ω  ω0
ð
Þ + A
2 M ω + ω0
ð
Þ



A
2j Φ ω  ω0
ð
Þ  A
2j Φ ω + ω0
ð
Þ


 
A
2 ω  ω0
ð
Þ Ω ω  ω0
ð
Þ +
A
2 ω + ω0
ð
Þ Ω ω + ω0
ð
Þ


,
where M(ω), Ω(ω), and Φ(ω) are the Fourier transforms of m(t), ωΔ(τ), and ϕ(t), respectively.
We assume m(t), ωΔ(τ), and ϕ(t) vary at a rate much less than ω0. If each of these terms are
noise sources, the spectral density of noise around the carrier at an offset of Δω is
SN(ω0 + Δω) = SPM(ω0 + Δω) + SFM(ω0 + Δω) + SAM(ω0 + Δω),
which is the sum of the noise around the carrier that is due to phase ﬂuctuations, frequency
ﬂuctuations, and amplitude ﬂuctuation (respectively). These terms are deﬁned as
SPM ω0 + Δω
ð
Þ = A2
4 Sϕ Δω
ð
Þ
SFM ω0 + Δω
ð
Þ = A2
4
SΩ Δω
ð
Þ
Δω
j
j2
SAM ω0 + Δω
ð
Þ = A2
4 SM
Δω
f
g:
The total noise power, SN(ω0 + Δω), normalized to the total carrier power, is the deﬁnition of
phase noise, i.e.,
ℒΔω
f
g = SN ω0 + Δω
ð
Þ
A2=4
= Sϕ Δω
ð
Þ + SM Δω
ð
Þ + SΩ Δω
ð
Þ
Δω
j
j2 :
Therefore this deﬁnition for phase noise, i.e., single-sideband noise normalized to carrier
power, is somewhat of misnomer as it includes noise that causes perturbations in phase,
frequency, and amplitude. However, as we will soon discover, in practical LC oscillators, it
is generally the case that SM(Δω) is small and can be neglected, and so the term can be
approximated as
ℒΔω
f
g  Sϕ Δω
ð
Þ + SΩ Δω
ð
Þ
Δω
j
j2 :
522
Oscillators

Moreover, as demonstrated in the next section, we cannot distinguish between frequency noise
and phase noise. Therefore, if SΩ(Δω)/|Δω|2 exists at all, it is considered as a part of Sϕ(Δω).
Consequently, it is common to write9
ℒ{Δω}  Sϕ(Δω).
9.3.2
Similarity of FM and PM Noise
To understand why we cannot distinguish between FM and PM noise, consider that a stationary
noise source can be modeled as an inﬁnite sum of sinusoids that are uncorrelated in phase and
separated in frequency by 1Hz [7],
n tð Þ =
X
∞
k = 0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4Sn 2πk
ð
Þ
p
cos 2πkt + θk
ð
Þ,
where Sn(2πk) is the spectral density per unit hertz of n(t) at frequency of k Hz, and θk is the
uncorrelated random phase offset of each sinusoid. This was proven in Chapter 2 in the context
of randomly phased sinusoid. Also in Chapter 6, it was exploited to calculate the spectral
density of band limited white noise squared.
Now consider a sinusoid, whose frequency is modulated by a noise source,
vFM tð Þ  A cos ω0t 
ðt
0
ωΔ τð Þdτ
0
@
1
AA sin ω0t,
where
ωΔ τð Þ =
X
∞
k = 0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4SΩ 2πk
ð
Þ
p
cos 2πkt + θk
ð
Þ:
Calculating the integral gives us
vFM tð Þ  A cos ω0t 
X
∞
k = 0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4SΩ 2πk
ð
Þ
p
2πk
cos 2πkt  π=2 + θk
ð
Þ
 
!
A sin ω0t:
Now consider a sinusoid, whose phase is modulated by a noise source, i.e.,
vPM tð Þ  A cos ω0t 
X
∞
k = 0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4Sϕ 2πk
ð
Þ
q
cos 2πkt + θk
ð
Þ
 
!
A sin ω0t:
As θ[k = 0, 1, 2, . . .] is a set of random uncorrelated phases, we note that a noise source with
spectral (2πk)2Sx(2πk) that modulates frequency will have exactly the same effect on the output
9 In some books, a factor of ½ relates Sϕ(Δω) to ℒ{Δω}. However, as we have deﬁned Sϕ(Δω) on the double-sided frequency
axis, that term does not appear, in other words, ℒ{Δω} = Sϕ
DS(Δω)=Sϕ
SS(Δω)/2.
When viewed/measured on a spectrum analyzer ℒ{Δω} is single-sideband noise normalized to carrier power. However,
the IEEE deﬁnition of ℒ{Δω} is ℒ{Δω} = Sϕ
DS(Δω)=Sϕ
SS(Δω)/2, which ignores amplitude noise even if it is present.
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
523

spectrum as a noise of spectral Sx(2πk) that modulates phase. Therefore, we cannot distinguish
between the two by observing the output, just as was the case for FM and PM signals discussed
in Chapter 2. Moreover, a nonlinear element will respond to frequency noise and phase noise in
exactly the same way, and therefore we can treat frequency noise and phase noise as one and
the same.
9.3.3
Recognizing AM and PM Sidebands
A small source that modulates the amplitude or phase of a carrier generates correlated sidebands
around the carrier. If the modulation index is small, it is not possible to know whether the
sidebands are the result of amplitude or phase modulation by simply looking at the sideband
magnitude. However, by observing the relative phase of the sidebands with to respect to
the carrier, we are able to make this distinction [7], [8]. Consider an arbitrary PM source given by
ϕ(t) = Δϕ sin(Δωt + φ)
that modulates an arbitrary carrier, resulting in
v(t) = A cos(ω0t + ϕ(t) + θ).
Assuming Δϕ  2π, this can be approximated as
v (t)  A cos(ω0t + θ)  Δϕ sin(Δωt + φ)A sin(ω0t + θ),
and can be written in the form
v(t)  vc(t) + vLSB(t) + vUSB(t),
where the unmodulated carrier, the lower sideband (LSB) and the upper sideband (USB) are
given, respectively, by
vc(t) = A cos(ω0t + θ)
vLSB tð Þ = ΔϕA
2
cos ω0  Δω
ð
Þt + π + θ  φ
ð
Þ
vUSB tð Þ = ΔϕA
2
cos ω0 + Δω
ð
Þt + θ + φ
ð
Þ:
Note that the magnitudes LSB and USB are equal (i.e., ΔϕA/2), while the mean of the phase of
LSB and USB is 90 offset from the phase of the carrier. This is visualized in the phasor plot
shown in Figure 9.9.
Now consider an arbitrary AM carrier given by
m(t) = Δm sin(Δωt + φ)
v(t) = A(1 + m(t)) cos(ω0t + θ),
which can be again written in the form
v(t)  vc(t) + vLSB(t) + vUSB(t).
524
Oscillators

The unmodulated carrier, LSB, and USB are given by
vc(t) = A cos(ω0t + θ)
vLSB tð Þ = ΔmA
2
cos
ω0  Δω
ð
Þt + π
2 + θ  φ


vUSB tð Þ = ΔmA
2
cos
ω0 + Δω
ð
Þt  π
2 + θ + φ


:
Again the amplitude of the sidebands are the same, but unlike phase modulation, in amplitude
modulation the mean of the phase of the USB and LSB is either in phase or 180 out of phase
with the carrier. This is visualized in Figure 9.10.
9.3.4
Decomposing an SSB into AM and PM Sidebands
It is possible to represent a small uncorrelated sideband as a set of small correlated AM and PM
sidebands each with half the magnitude of the original sideband (as shown in Figure 9.11) [7],
[9]. This decomposition is useful when analyzing the response of a nonlinear circuit to a
modulated waveform because, as we will see, PM and AM sidebands respond differently when
passed through a nonlinear circuit. For example, if we pass a modulated waveform through a
hard-limiting nonlinearity the PM sideband-to-carrier will be preserved, but the AM sideband-
to-carrier will be removed. Therefore, as shown in Figure 9.12, passing a sinusoid modulated by
a single-sideband through a limiter results in a sinusoid with phase modulated sidebands at the
A
ΔΦA/2
Magnitude
Spectrum
Phasor Representation
ΔΦA/2
θ 
Carrier
USB
LSB
θ+φ+Δωt
Sum of USB and LSB
Perpendicular to carrier
π+θ–φ–Δωt
Figure 9.9: The sum of the
PM sidebands will always
be perpendicular to the
carrier
A
ΔmA/2
Magnitude
Spectrum
Phasor Representation
ΔmA/2
θ 
Carrier
USB
USB
θ+φ+π/2+Δωt
Sum of USB and LSB
Colinear to carrier
θ–φ–π/2–Δωt
Figure 9.10: The sum of
the AM sidebands will
always be colinear (i.e., in
phase or 180 out of phase)
to the carrier
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
525

output, which are half the magnitude of the original single-sideband, while the AM sidebands
will be removed.
To show this decomposition, consider the simple case of a continuous sinusoid, vc (t) = A
cos ω0t, modulated by a very small sideband vSSB(t) = ΔA cos((ω0 + Δω)t + θ). This can be
written in the form
v (t) = vc (t) + vSSB(t)
= A cos ω0t + ΔA cos((ω0 + Δω)t + θ)
= vc (t) + vPM(t) + vAM(t),
where
vPM tð Þ = ΔA
2 cos ω0 + Δω
ð
Þt + θ
ð
Þ  ΔA
2 cos ω0  Δω
ð
Þt  θ
ð
Þ
vAM tð Þ = ΔA
2 cos ω0 + Δω
ð
Þt + θ
ð
Þ + ΔA
2 cos ω0  Δω
ð
Þt  θ
ð
Þ:
A
ΔAejθ
A
0.5ΔAe jθ
–0.5ΔAe–jθ
0.5ΔAe jθ
0.5ΔAe–jθ
Carrier
modulated by 
single–sideband
Carrier
PM sidebands
AM sidebands
Figure 9.11: Representing
a single band as the sum of
PM and AM sidebands
A
ΔAejθ
A
0.5ΔAe jθ
–0.5ΔAe–jθ
0.5ΔAejθ
0.5ΔAe–jθ
Fundamental
modulated by 
single sideband
Fundamental
PM sidebands
AM sidebands
A
Fundamental
0.5ΔAe
Δ
jθj
0.5ΔAe
Δ
–j
– θj
AM sidebands
0.5ΔAe
Δ
jθj
–0.5ΔAe–j
– θj
PM sidebands
A
G*A
G*0.5ΔAe jθ
–G*0.5ΔAe–jθ
Fundamental
PM sidebands
AM sidebands
G*A
Fundamental
AM sidebands
G*0.5ΔAe
Δ
jθj
–G*0.5ΔAe–j
– θj
PM sidebands
Limiter with infinitely 
sharp transition
Fundamental
modulated by 
PM sidebands
PM sidebands
preserved at 
output
AM sidebands
attenuated at 
output
Figure 9.12: PM and AM sidebands response to a nonlinearity. In general, PM sidebands experience the same gain as the
carriers, while AM sidebands are attenuated (assuming a compressive nonlinearity).
526
Oscillators

To reconcile the above decomposition with the deﬁnition of a phase and amplitude modulated
sinusoid described previously, we can write v(t) in the form of
v(t) = A cos(ω0t) + m(t) A cos ω0t  ϕ(t)A sin ω0t,
where the modulation components are given by
ϕ tð Þ = ΔA
A sin Δωt + θ
ð
Þ
m tð Þ = ΔA
A cos Δωt + θ
ð
Þ:
As stated previously, noise can be modeled as an inﬁnite sum of sinusoids (or in this context an
inﬁnite sum of small sidebands). Therefore in the case of additive stationary noise where a noise
source n(t) with a PSD of Sn(ω) is simply added to a continuous sinusoid, v (t) = A cos ω0t, the
decomposition reveals that half of the additive noise will modulate the phase of the carrier,
while the other half will modulate the amplitude:
SPM ω0 + Δω
ð
Þ = SAM ω0 + Δω
ð
Þ = 1
2 Sn ω0 + Δω
ð
Þ:
Unfortunately not all noise sources in an oscillator are stationary, as discussed next.
9.3.5
Cyclostationary Noise
In an oscillator, the noise injected by the parasitic tank resistance, Rp, is a stationary noise
source (with Sv(ω) = 2kTRp), but this is typically not the case for noise sources associated with
the active element. The spectral density of such sources will normally vary periodically because
of the changing operating points of the transistors used in the circuit [10]. As stated in Chapter 5,
this type of periodically varying noise source is called a cyclostationary noise source and can be
deﬁned as
nCYCLO(t) = n(t)w(t),
where n(t) is a stationary noise source, and w(t) is a periodic waveform, which will be referred
to as a noise-shaping waveform. The autocorrelation and spectral density of cyclostationary
noise were calculated in Chapter 5. Given their importance to oscillator noise discussion, we
shall present a summary here.
The autocorrelation of the cyclostationary noise, was found to be
RnCYCLO(t, τ) = Rn(τ)w(t)w∗(t + τ),
where Rn(τ) is the autocorrelation of n(t). This can be expanded as
RnCYCLO t; τ
ð
Þ = Rn τð Þ
X
∞
k = ∞
X
∞
m = ∞
W k½ W∗m
½ e j km
ð
Þω0tejmω0τ,
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
527

where W[k] are the Fourier coefﬁcients10 of the periodic noise shaping waveform w(t). If RnCYCLO(t, τ)
is time-averaged, the time (t) dependence is removed, and the spectral density is found to be
SnCYCLO ω
ð Þ =
X
∞
k = ∞
W k½ 
j
j2Sn ω  kω0
ð
Þ:
For the case of white cyclostationary noise, given the Parseval’s energy relation, the above
expression was shown to simplify as follows,
SnCYCLO(ω, t) = Sn|w(t)|2,
where Sn is the white noise spectral density and is frequency independent. Figure 9.13 shows a
practical example of a transistor with a time-varying gate voltage. In this case the noise current
can be modeled as a stationary current source with spectral density Sn = 2kTγ, modulated by the
noise-shaping waveform w tð Þ =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
gm tð Þ
p
. Given this, the PSD is
SnCYCLO(ω, t) = Snw2(t) = Sngm(t) = 2kTγgm(t),
which, of course, varies periodically with time. When viewed on a spectrum analyzer the PSD
displayed will be a time-average of SnCYCLO(ω, t), i.e.,
SnCYCLO ω
ð Þ = 2kTγgm tð Þ:
A stationary noise source implies that the noise voltages at two distinct frequencies are
completely uncorrelated.11 However, as a cyclostationary noise is modeled as a stationary
source modulated with a periodic waveform, its spectrum can be highly correlated. For
example, low-frequency noise when mixed with a square waveform generates correlated noise
around harmonics of the square waveform. In the context of oscillator noise analysis, we need
to carefully account for this correlation in order to distinguish between noise that modulates the
nCYCLO(t)= n(t)w(t)
IN(t)
nCYCLO(t)
n(t) is a stationary noise
Sn=2kTγ 
SCYCLO=Snw2(t)=2kTγgm(t)
w(t) shapes stationary 
noise
w2(t)=gm (t)
nCYCLO(t)t = n(t)w(t)
SCYCLO=Sn
S w
n
2
w (t( )=2kTγ
T gm(t( )
n(t( )t is a stationary noise
Sn
S =2kTγ 
T
w(t)t shapes stationary
noise
w2
w (t( )=gm (t)
v
Figure 9.13: The output
noise of a transistor is
cyclostationary when the
gate is driven by a periodic
waveform
10 As in this chapter we deal with several variables with complex notations, we use W[k] to represent the Fourier series
coefﬁcients, as opposed to wk used previously.
11 This is not to be confused with colored noise or noise that is shaped in the frequency domain. Colored noise is uncorrelated
in the frequency domain, but correlated in the time domain. Stationary noise, which may or may not be colored, is always
uncorrelated in the frequency domain.
528
Oscillators

phase of a carrier, and noise that modulates the amplitude of a carrier. The previous section
dealt with the straightforward case of stationary noise. To make this distinction for the more
general case of cyclostationary noise, consider again the example of an amplitude and phase
modulated continuous sinusoid. Assuming that m(t)  1, and ϕ(t)  2π, we can write
vosc (t)  A cos ω0t + m(t) A cos ω0t  ϕ(t)A sin ω0t.
We also assume that both m(t) and ϕ(t) are varying at rate much less than ω0. Let us model the
modulation terms (the second and third terms in the expression) as a cyclostationary noise
source, i.e.,
nCYCLO(t) = n(t)w(t) = Am(t) cos ω0t  Aϕ(t) sin ω0t,
where n(t) is a stationary noise source and w(t) is an arbitrary noise-shaping waveform.
Consequently, the PM/AM components can be retrieved as follows:
ϕ tð Þ =
 2
A n tð Þw tð Þ sin ω0t


m tð Þ =
2
A n tð Þw tð Þ cos ω0t


:
The function hi retains only low-frequency components. To ﬁnd the spectral density of the AM
and PM components, let us take an intermediate step ﬁrst, and deﬁne the following two variables,
~ϕ tð Þ =  2
A n tð Þw tð Þ sin ω0t
~m tð Þ = 2
A n tð Þw tð Þ cos ω0t,
which are the unﬁltered versions of ϕ(t) and m(t). This is conceptually shown in Figure 9.14.
Both ~ϕ tð Þ and ~m tð Þ can be understood as cyclostationary noise where the noise-shaping
waveforms are, respectively, w~ϕ tð Þ = 2=A
ð
Þw tð Þ sin ω0t and w~m tð Þ = 2=A
ð
Þw tð Þ cos ω0t. Now,
as ~ϕ tð Þ and ~m tð Þ represent noise, we can calculate the PSD of the phase noise and amplitude
noise as
S~ϕ ω
ð Þ =
X
∞
k = ∞
W ~ϕ k½ 


2
Sn ω  kω0
ð
Þ = 1
A2
X
∞
k = ∞
W k  1
½
  W k + 1
½

j
j2Sn ω  kω0
ð
Þ
S~m ω
ð Þ =
X
∞
k = ∞
W ~m k½ 
j
j2Sn ω  kω0
ð
Þ = 1
A2
X
∞
k = ∞
W k  1
½
 + W k + 1
½

j
j2Sn ω  kω0
ð
Þ,
m(t)
–2/AnCYCLO
cos
0t
(t)
sin
0t
w
w
f
Figure 9.14: Obtaining AM and PM sidebands
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
529

where W[k], W ~ϕ k½ , and W ~m k½  respectively deﬁne the Fourier coefﬁcients of w(t), w~ϕ tð Þ, and
w~m tð Þ, and Sn is the PSD of n(t). As we are concerned only with noise around the carrier,
evident from the lowpass ﬁltering shown in Figure 9.14, these terms assuming a small carrier
offset lead to
Sϕ Δω
ð
Þ = 1
A2
X
∞
k = ∞
Sn Δω  kω0
ð
Þ W k  1
½
  W k + 1
½

j
j2
SM Δω
ð
Þ = 1
A2
X
∞
k = ∞
Sn Δω  kω0
ð
Þ W k  1
½
 + W k + 1
½

j
j2:
The folding involved in the generation of phase noise is visualized in Figure 9.15, while the
folding involved in the generation of amplitude noise is visualized in Figure 9.16. Note
that stationary noise is a special case of the above analysis when the noise-shaping waveform
is unity, i.e., w(t) = 1.
Sn(ω)
A2SΦ(ω)
A2SΦ(ω)
|W[–1]-W[1]|2
|W[0]-W[2]|2
|W[1]-W[3]|2
|W[–2]-W[0]|2
|W[–3]-W[–1]|2
–ω0
–2ω0
ω0
2ω0
Sn(ω)
|W[–1]-W[1]|2
|W[0]-W[2]|2
|W[1]-W[3]|2
|W[–2]-W[0]|2
|W[–3]-W[–1]|2
–ω0
–2ω0
ω0
2ω0
Figure 9.15: A stationary noise modulated by periodic waveform w(t) results in phase noise when reference to
a cosine carrier through the weightings shown
Sn(ω)
|W[–1]+W[1]|2
|W[0]+W[2]|2
|W[1]+W[3]|2
|W[–2]+W[0]|2
|W[–3]+W[–1]|2
–ω0
–2ω0
ω0
2ω0
A2SM(ω)
Figure 9.16: A stationary noise modulated by
periodic waveform w(t) results in amplitude
noise when reference to a cosine carrier through
the weightings shown
530
Oscillators

If n(t) is a white noise source with PSD equal to Sn, this simpliﬁes to
Sϕ Δω
ð
Þ = Sn wϕ̃ tð Þ


2
= 2
A2 Snp tð Þ 1  cos 2ω0t
ð
Þ = 2
A2 Sn P 0½   1
2 P 2
½
  1
2 P 2½ 


SM Δω
ð
Þ = Sn wm̃ tð Þ
j
j2 = 2
A2 Snp tð Þ 1 + cos 2ω0t
ð
Þ = 2
A2 Sn P 0½  + 1
2 P 2
½
 + 1
2 P 2½ 


,
where p(t) = w2(t), and P[k] is the Fourier series of p(t). As discussed previously, these terms
can be related back to the PSD of sidebands around the carrier,
SPM ω0 + Δω
ð
Þ = A2
4 Sϕ Δω
ð
Þ = Sn
1
2 P 0½   1
4 P 2
½
  1
4 P 2½ 


SAM ω0 + Δω
ð
Þ = A2
4 SM Δω
ð
Þ = Sn
1
2 P 0½  + 1
4 P 2
½
 + 1
4 P 2½ 


:
Example: In the case of the transistor with the time-varying input, Sn = 2kTγ,
w tð Þ =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
gm tð Þ
p
, and p(t) = w2(t) = gm(t), the phase noise sidebands will be
SPM ω0 + Δω
ð
Þ = 2kTγ 1
2 GM 0½   1
4 GM 2
½
  1
4 GM 2½ 


,
where GM[k] is the Fourier series of gm(t).
Another important case is when n(t) originates from a low-frequency noise source, for
example ﬂicker noise in a CMOS device or low-frequency noise on a supply line. In this
case, Sϕ (ω) is negligible except for frequencies much less than the fundamental, and we
can write
SPM ω0 + Δω
ð
Þ = A2
4 Sϕ Δω
ð
Þ = 1
4 Sn Δω
ð
Þ W 1
½
  W 1½ 
j
j2
SAM ω0 + Δω
ð
Þ = A2
4 SM Δω
ð
Þ = 1
4 Sn Δω
ð
Þ W 1
½
 + W 1½ 
j
j2:
If the noise-shaping function is symmetric (i.e., W[1] = W[1]), the phase noise side-
bands SPM(ω0 + Δω) are nulled, and the low-frequency noise component does not corrupt
the oscillation output’s phase. This is the case for all the active elements discussed in this
chapter because they are all considered to be memoryless.
Example: In the trivial case of a stationary white source, the noise shaping waveform is
equal to unity (i.e., w(t) = 1), which means that p(t) = w2(t) is also equal to unity.
Accordingly, a stationary noise source is decomposed as follows,
Continued
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
531

SPM ω0 + Δω
ð
Þ = A2
4 Sϕ Δω
ð
Þ = Sn
2
SAM ω0 + Δω
ð
Þ = A2
4 SM Δω
ð
Þ = Sn
2 ,
which is consistent with our previous analysis of stationary noise where we found that
half of the noise modulates the phase of the carrier and half modulates the amplitude.
Now that we are comfortable decomposing noise into phase and amplitude modulating
components around a carrier, it is time to see why this decomposition is so useful in nonlinear
circuits.
9.3.6
Noise Passing through a Nonlinearity
Consider the nonlinear transconductance shown in Figure 9.17, where the output current (iout) is
some function of the input voltage (vin). Using the Taylor series approximation, we can
calculate the output given a small deviation of the input (Δvin), i.e.,
iout vin + Δvin
ð
Þ = iout vin
ð
Þ + diiout vin
ð
Þ
dvin
Δvin + . . . :
Assuming Δvin is very small, we can neglect higher order derivatives, and the output becomes
iout(vin + Δvin) = iout(vin) + g(t)Δvin(t).
Therefore the deviation in output current due to Δvin(t) is simply g(t)Δvin(t), where g(t) is the
instantaneous transconductance deﬁned as g(t) = diiout(vin)/dvin. As g(t) is a periodic waveform,
we can express the deviation in output current as
Δiout tð Þ = Δvin tð Þg tð Þ = Δvin tð Þ
X
∞
k = ∞
G k½ ejkω0t
 
!
,
where G[k] deﬁnes the Fourier coefﬁcients of g(t). If Δvin(t) is a small single-sideband around
the carrier, the output is an LTV not an LTI response. This is seen in Figure 9.17 where the
input to the nonlinearity contains only a USB, while the output contains both an LSB and a
USB. However, if Δvin(t) is composed of phase modulating sidebands, i.e., Δvin(t) =  Aϕ
(t) sin ω0t, the output in the frequency domain is calculated as
Δiout tð Þ =  Aϕ tð Þg tð Þ sin ω0t =  Aϕ tð Þ
2j
X
∞
k = ∞
G k  1
½
  G k + 1
½

ð
Þejkω0t
 
!
:
Now, if ϕ(t) has only low-frequency components, and we are concerned only with Δiout(t)
around ω0, the only values of k in the above summation that are relevant are 1. Therefore, the
expression simpliﬁes to
Δiout tð Þ =  Aϕ tð Þ
2j
G 0½   G 2½ 
ð
Þe jω0t + G 2
½
  G 0½ 
ð
Þejω0t

	
:
532
Oscillators

Assuming G[2] = G[2], which is the case for a memoryless active circuit,
Δiout(t) =  Aϕ(t)((G[0]  G[2]) sin ω0t) = (G[0]  G[2])Δvin(t),
which is an LTI response (i.e., GPM = G[0]  G[2]). To reiterate, we have assumed that we can
neglect components far from carrier, which will be eventually ﬁltered by the resonator. If
Δvin(t) is composed of amplitude-modulating sidebands, i.e., Δvin(t) = Am(t) cos ω0t, the output
around the carrier is calculated using a similar approach,
Δiout(t) = (G[0] + G[2])Δvin(t),
which, again, is an LTI response (i.e., GAM = G[0] + G[2]). This is also visualized in
Figure 9.17.
Note that, as was shown in Section 9.2.2, the carrier gain is also given by Geff =
GPM = G[0]  G[2], and so we can state the following assuming a small modulation index:
– The carrier-to-sideband ratio of a phase-modulated signal is preserved when it is passed
through nonlinearity.
A
SSB
USB
LSB
USB
LSB
Case 1:
Single sideband
Case 3:
AM sidebands
Creation of LSB
due to LTV response
Nonlinearity
Case 2:
PM sidebands
Bandpass 
filter @ ω0
A
GPM*USB 
GPM*LSB 
Gc*A
GAM*USB 
GAM*LSB
A
Case 1
Case 3
Case 2
Carrier and PM 
sidebands experience 
same gain, i.e.
Gc =GPM=G[0]–G[2]
Carrier and AM 
sidebands experience 
different gain, i.e.
Gc =G[0]–G[2]
GAM =G[0]+G[2]
G*A
Gc*A
Figure 9.17: Output of a nonlinearity due to SSB-modulated, PM-modulated, and AM-modulated carriers.
The bandpass ﬁlter is included as we are concerned only with the output around ω0
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
533

– The carrier-to-sideband ratio of an amplitude-modulated signal is not preserved when it is
passed through nonlinearity. In the case of a compressive nonlinearity, the carrier-to-sideband
ratio of an amplitude-modulated signal will be attenuated, since (G[0] + G[2]) < (G[0] G[2]).
Moreover, despite the strongly nonlinear and time-varying action of the conductance, the
transfer function of small PM sidebands, and small AM sidebands can be considered as an
LTI response.
Of course, we have already seen how a single-sideband (which experiences an LTV-
response) can be decomposed in PM and AM (which both experience separate LTI responses).
Therefore, once we have calculated the noiseless steady-state operating conditions of the active
circuit, G[k], we should be able to able to analyze noise provided we decomposed it into AM
and PM components. This is done in the next section.
9.3.7
Reaction of Noiseless Oscillator to an External Noise
We have showed how an arbitrary cyclostationary noise source can be decomposed into AM
and PM components. We also showed how the active element exhibits an LTI response with
respect to PM or AM sidebands. This allows us to independently analyze the effect of a PM
noise source and an AM noise source on a noiseless oscillator, as shown in Figure 9.18. With
respect to the PM sidebands, the response for every device is linear and, therefore, the following
must hold:
ZPM sð Þ = vPM sð Þ
iPM sð Þ = 1
sCP
ksLPkRPk
1
Gnr 0½   Gnr 2½  :
Lp
Cp
Rp 
vosc(t)
gnr(t)
PM noise
w.r.t. inr(t)
inr(t)
Lp
Cp
ZPM
PM sidebands 
see lossless
LC tank
Lp
Cp
Rp 
vosc(t)
AM noise
w.r.t. inr(t)
inr(t)
Lp
Cp
ZAM
AM 
sidebands 
see lossy
LC tank
Rp||1/GAM
|ZPM|2
|ZAM|2
Carrier Offset [Hz]
Noise TF
–20dB/decade
ω0
ω 
|ZAM|2
|ZPM|2
Noise TF
Figure 9.18: Impedance perceived by PM and AM noise sources
534
Oscillators

Because of the power conservation requirement, the effective conductance is given by Geff =
Gnr[0]  Gnr[2] =  1/Rp, which simpliﬁes the above expression to
ZPM sð Þ
j
j2 =
ωL
1  ω2LPCP


2
,
and, so, around the carrier the impedance is given by
ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2  ω02L
2Δω


2
=
R2
p
4
1
Q2
ω0
Δω

2
:
Remarkably, this is the same noise transfer function as the perfectly linear oscillator. Therefore,
if the injected current phase modulates the carrier, it sees a lossless impedance, which is the
assumption made during the derivation of Leeson’s expression (see Figure 9.3). In the case of
the AM sidebands, the transfer function is given by
ZAM sð Þ = vPM sð Þ
iPM sð Þ = 1
sCP
sLP
j
j
j
jRPk
1
Gnr 0½  + Gnr 2½  ,
which is a lossy LC tank. Both transfer functions are plotted versus carrier offset in Figure 9.18.
Close to the carrier ZAM(s)  ZPM(s), which is why amplitude is generally of little concern in an
LC oscillator. Accordingly, once a noise source has been decomposed into AM and PM
components, its contribution to ℒ{Δω} is calculated as
v2
PM + v2
AM
A2
c=4
,
where
v2
PM = i2
PM ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2
v2
AM = i2
AM ZAM j ω0 + Δω
ð
Þ
ð
Þ
j
j2:
In the case of a stationary white noise source, i2
n, the decomposition is i2
PM = i2
AM = i2
n=2. This
explains why amplitude noise can generally be disregarded and why we needed to introduce the
factor of 2 division when deriving Leeson’s expression. In the more general case of a colored
cyclostationary noise source, nCYCLO(t) = n(t)w(t), the resultant AM and PM contributions are
v2
PM = ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2
4
X
∞
k = ∞
Sn Δω  kω0
ð
Þ W k  1
½
  W k + 1
½

j
j2
v2
AM = ZAM j ω0 + Δω
ð
Þ
ð
Þ
j
j2
4
X
∞
k = ∞
Sn Δω  kω0
ð
Þ W k  1
½
 + W k + 1
½

j
j2:
If the cyclostationary noise is white, it simpliﬁes to
v2
PM = ZPM
j
j2Sn
1
2 P 0½   1
4 P 2
½
  1
4 P 2½ 


9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
535

v2
AM = ZAM
j
j2Sn
1
2 P 0½  + 1
4 P 2
½
 + 1
4 P 2½ 


:
Again, it should be emphasized that both |ZPM|2 and |ZAM|2 are linear transfer functions.
Therefore, the noise analysis is greatly simpliﬁed provided we refer all noise currents across
the resonator and decompose them into AM and PM components.
9.3.8
Bank’s General Result
We now possess the tools needed to analyze the negative-gm LC oscillator model, which is
redrawn in Figure 9.19 along with explicit noise sources. However, it is useful to ﬁrst
summarize three important results:
1. Due to energy-balance in an LC oscillator, the active circuit has to precisely balance the tank
loss, Rp. Accordingly, if we deﬁne the instantaneous conductance of the element as gnr(t),
this requirement implies that
Gnr 0½   Gnr 2½  =  1
Rp
,
where Gnr[k] are the Fourier coefﬁcients of gnr(t).
2. An arbitrary cyclostationary noise source, (nCYCLO(t)), can be modeled as a stationary
noise source (n(t)) modulated by a periodic waveform (w(t)), i.e., nCYCLO(t) = n(t)w(t).
This noise can then be decomposed into AM and PM components with respect to some
carrier. The PM component of such a noise source with respect to a zero-phase cosine
waveform is
SPM Δω
ð
Þ = 1
4
X
∞
k = ∞
Sn Δω  kω0
ð
Þ W k  1
½
  W k + 1
½

j
j2,
where Sn(ω) is the spectral density of n(t), and W[k] are the Fourier coefﬁcient of w(t). If
Sn(ω) is white, this simpliﬁes to
SPM Δω
ð
Þ = Sn
1
2 P 0½   1
4 P 2
½
  1
4 P 2½ 


,
where P[k] are the Fourier coefﬁcient of p(t) = w2(t).
Lp
Cp
Rp
gnr(t)
ignr(t)
iRp(t)
Cyclostationary noise 
due to active circuit
Stationary noise 
due to tank loss
S=2kT/Rp
S=2kTγgnr(t)
Figure 9.19: Negative gm LC oscillator satisfying
Bank’s general equation
536
Oscillators

3. If a PM noise current is applied to a noiseless LC oscillator, it “sees” a lossless LC tank. In
other words, the transfer function of a PM current source to PM voltage noise is given by
v2
PM = i2
PM ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2 = i2
PM
R2
p
4
1
Q2
ω0
Δω

2
:
Returning to Figure 9.19, the current noise due to tank loss is simply 2kT/Rp, while we assume
the noise of the active resistor can be modeled as cyclostationary white noise source with PSD
equal to 2kTγgnr(t), where gnr(t) is the instantaneous conductance of the active element circuit,
and γ is some constant. Note that this assumption has some physical basis as the active element
is generally composed of transistors operating in saturation where γ = 2/3 in long channel
devices. Ignoring the contribution of amplitude noise, ℒ{Δω} is calculated as
ℒΔω
f
g =
v2
Rp PM
ð
Þ + v2
nr PM
ð
Þ
A2
c=4
=
i2
Rp PM
ð
Þ + i2
nr PM
ð
Þ
A2
c=4
ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2,
where the PM components of noise are given by
i2
Rp PM
ð
Þ =
i2
Rp
2 = kT=Rp
i2
nr PM
ð
Þ = 2kTγ
2
Gnr 0½   Gnr 2½ 
ð
Þ = kTγ=Rp:
Note that because of energy-balance i2
nr PM
ð
Þ does not depend on the speciﬁcs of gnr(t).
Simplifying the expression for phase noise gives
ℒΔω
f
g = kTRp 1 + γ
ð
Þ
A2
1
Q2
ω0
Δω

2
:
Comparing this expression to Leeson’s analysis, we see that the unknown oscillator noise
factor is given by F = 1 + γ. This is actually quite a powerful result because phase noise was
quantiﬁed knowing only the relationship between the noise PSD and the instantaneous con-
ductance of the active circuit. In other words,
If the PSD of a noise source injected into the tank is directly proportional to the time-
varying conductance of the active circuit, its contribution to noise factor F depends only
on the proportionality constant that relates the noise and the instantaneous conductance.
This is Bank’s general result [11], and as we will see, many of the most common LC topologies
satisfy this condition (at least partially).
Furthermore, as we are concerned only with the spectrum around the oscillation frequency, a
single-tank nearly-sinusoidal LC oscillator can generally be redrawn in the form of the
negative-gm model. Doing this often simpliﬁes the analysis.
Example: Shown in Figure 9.20 is a distributed lossy LC tank and a two terminal
negative conductance. Using straightforward analysis, the circuit is recast in the form of
the negative-gm model using the transformation variables α and β. Depending on where
Continued
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
537

the terminals of the conductance are connected, α and β can assume any value from 0 to 1.
Given this, and assuming the PSD of the active element current noise is equal to 2kTγg(t),
Bank’s general result can be used to quantify the noise factor as
F = 1 + β
α γ:
The oscillator power efﬁciency can be deﬁned in terms of the power efﬁciency of the
oscillator if the active circuit is connected across the entire tank (ηg), i.e.,
ηOSC = β2ηg.
Therefore the FOM is given by
FOM =
β2
1 + β
α γ

 ηg
2Q2
kT 1mW,
which is maximized by connecting the negative conductance across the entire tank, which
ensures α = β = 1. Therefore, it is generally best practice to connect the energy-restoring
circuit directly across the LC tank, rather than tapping some intermediate node of the tank.
Since the optimum connection arrangement is α = β = 1, and the maximum efﬁciency
of any active circuit is 1, we can state that the maximum achievable FOM of any single-
tank, nearly sinusoidal LC oscillator is given by
FOMMAX =
Q2
1 + γ
2
kT 1mW:
This maximum achievable FOM will be used to evaluate the various topologies discussed
in the next few sections.
V→I
Terminals can be connected 
to any nodes of LC tank,
vC1
vL1
vL 2
vL∞
vC2
vC∞
Lp
Cp
Rp 
gnr(t)
ignr(t)
iRp(t)
gnr(t) = (αβ)*g(t)
vout(t)
g(t)=dig(t)/dvg(t)
in(t)
inr(t)
vg(t)=αvout(t)
βig(t)=inr(t)
ig(t)
vg(t)
Transformation 
variables: α,β
ignr(t) = β*in(t)
Sgnr = 2kT(βγ/α)gnr(t)
Sn = 4kTγg(t)
Figure 9.20: Recasting an arbitrary topology in the form of the negative-gm model
538
Oscillators

9.3.9
Two-Port Oscillators
So far we have primarily focused on one-port oscillators, that is, oscillators where the active
circuit has a one (differential or single-ended) port and that can be easily redrawn in the form of
the negative-gm LC model. This is the simplest and mostly widely used arrangement; however,
other topologies do exist and have some potential beneﬁts. Before we discuss a few examples of
the one-post oscillators in the next section, it is appropriate to say a few words about two-port
oscillators.
As described by Mazzanti and Bevilacqua [12], if an oscillator is partitioned into a two-port
reactive element and a memoryless conductance, as shown in Figure 9.21, the noise factor is
F = 1 + γ/|Av|, where γ is the constant that relates the noise current of the conductance with its
instantaneous conductance, and Av is the voltage gain across the two-port resonator. Accord-
ingly, as Av becomes very large, conductance noise is suppressed, F approaches one, and the
optimum FOM, in dBc/Hz, becomes
FOMMAX = 2Q2
kT 1mW,
or in dB,
FOM2PORT(MAX) = 176.8 + 20log10Q,
which is equal to the FOM of a 100% efﬁcient oscillator with a noiseless conductance
quoted in [4].
While excellent results (particularly in terms of ﬂicker noise suppression) have been
achieved using this “step-up” technique [2], [13], [14], [15], making |Av| > 1 can be problem-
atic. First, in order to maximize oscillator efﬁciency, the swing at the output of the conduct-
ance should always be maximized, which in the case of a CMOS conductance means the
swing will be VDD or, in the case of a NMOS-only or PMOS-only conductance, will be 2VDD.
This implies that the swings on gate oxides will be |Av|VDD (or |Av|2VDD), which can
compromise reliability if a large |Av| is employed. Second, the step-up transformer used in
such a design should not result in an effective tank Q degradation, i.e., the Q of the
impedance parameter Z21 of the two-port tank [4] that is degraded with respect to the Q of
a tank that uses a single inductor occupying the same area. Although these issues can be
managed, such designs do not currently outperform designs with |Av| = 1, which corresponds
RLCM
2-port 
Resonator
2-Port Resonator
1-Port Resonator
RLCM
1-port 
Resonator
Large Av 
suppresses gm
noise
gm
gm
gm
gm
Figure 9.21: The distinction between oscillators using two-port and one-port resonators
9.3 Phase Noise Analysis of the Nonlinear LC Oscillator
539

to the one-port oscillator also shown in Figure 9.21. In the case of this one-port design, the
optimum FOM becomes
FOM1PORT(MAX) = 176.8 + 20log10Q  10log10(1 + α).
When a single transistor or a differential pair is used as the negative conductance, the noise
coefﬁcient α is approximately equal to γ = 0.67 and, so, the one-port limit becomes
FOM1PORT(MAX) = 174.6 + 20log10Q,
which is only 2.2dB less than optimal. As will be shown in the next sections, a number of
modern topologies get within 1dB of this practical limit (or 3dB of the absolute limit).
9.4
LC OSCILLATOR TOPOLOGIES
..............................................................................................
So far we have taken an abstract approach to understanding the operation of an LC oscillator. It
is now time to explore some speciﬁc transistor-level examples.
9.4.1
The Standard NMOS Topology
The LC oscillator with a negative-conductance consisting of a current-biased, cross-coupled
differential pair is, perhaps, the most fabricated of all CMOS LC oscillator. Shown in
Figure 9.22, the topology has more recently been referred to as a class B topology [16], but
we will simply refer to it as the standard NMOS topology.
In this topology, the differential pair provides the negative conductance, which is shown
separately in Figure 9.23 along with its I–V characteristic and transconductance. In order for the
oscillator to start-up, it is required that gnr0 < 1/Rp, where gnr0 is the negative conductance
Rp/2
Lp/2
Rp/2
Lp/2
2Cp
2Cp
IBIAS
inr(t)
vout(t)
Rp
Lp
Cp
vout(t)
inr(t)
inr(t)
vout(t)
—IBIAS/2
IBIAS/2
Active 
Element
gnr(t)
t
t
t
Figure 9.22: Standard LC oscillator topology
540
Oscillators

when the differential voltage is zero. Assuming gnr0  1/Rp, the I–V characteristic can be
approximated as a hard switching nonlinearity deﬁned as
iNR vnr
ð
Þ   IBIAS
2 sgn vnr
ð
Þ =
IBIAS
2
,
vnr < 0
 IBIAS
2
,
vnr > 0
8
>
>
<
>
>
:
,
where sgn() is the sign or signum function. Thus, under oscillation conditions iNR(t) will
approximate a square wave (see waveforms in Figure 9.22), which implies that the fundamental
component of the current injected into the tank is given by INR[1] =  (1/π)IBIAS, which in turn
implies a differential oscillation amplitude of
A = 2
π IBIASRp
and a power efﬁciency of
η = 1
π
A
VDD
,
which is consistent with the analysis in Chapter 1. Therefore to maximize the topology’s
power efﬁciency, the amplitude must be as large as possible. In a practical design, the
maximum amplitude will be limited by the headroom requirement of the current source, i.e.,
AMAX  2(VDD  Veff), where Veff = VGS  VTH is the overdrive voltage of the current source. By
minimizing Veff, the maximum achievable efﬁciency of this topology can approach 2/π
(or 63.7%).
In order to analyze the topology’s phase noise performance, we redraw the circuit in the
form of the negative-gm model (see the right-hand side of Figure 9.22). We note that
the noise of the differential pair is directly proportional to the conductance of the differential
IBIAS
inr(t)
vnr(t)
gR(t)
gL(t)
inR(t)
inL(t)
gCS
inCS(t)
IBIAS
Current [A]
0.5IBIAS
0
–0.5IBIAS
Voltage [V]
–2VDD
2VDD
0
Conductance [S]
Voltage [V]
2VDD
0
–2VDD
0
–gR||gL
Figure 9.23: Active element used in class B topology, and the associated I–V characteristic and
conductance plot
9.4 LC Oscillator Topologies
541

pair. That is, assuming the current source stays in saturation, the differential conductance is
given by
gnr tð Þ =  gR tð ÞgL tð Þ
gR tð Þ + gL tð Þ ,
while the noise due to the differential pair can be quantiﬁed as
i2
gnr = 2kTγ gR tð ÞgL tð Þ
gR tð Þ + gL tð Þ = 2kTγgnr tð Þ:
This satisﬁes Bank’s general result in that the noise due to the differential pair is directly
proportional to its conductance. Consequently, the contribution of the differential pair to the
oscillator’s noise factor is simply the proportional constant γ

or in other words, the PM
contribution of the tank loss and differential pair are related as follows: i2
gnr PM
ð
Þ = γi2
Rp PM
ð
Þ

.
The current source noise iCS(t) – much like noise associated with the input transconductance
of a single-balanced active mixer (see Chapter 8) – is mixed with a unity square wave
and injected into the tank, and so it appears as a cyclostationary noise source across the tank
given by
iCS tð Þ ½
ð Þsgn vOSC tð Þ
ð
Þ =
iCS tð Þ
2
,
vosc tð Þ < 0
 iCS tð Þ
2
,
vosc tð Þ > 0
8
>
>
<
>
>
:
:
This is essentially a stationary noise iCS(t) modulated by the noise-shaping waveform w(t) =
(½)sgn(vOSC(t)). Noting that iCS(t) is a white noise source and p(t) = w2(t) = 1/4, we can use the
PM decomposition documented previously to derive the PM contribution as
i2
cs PM
ð
Þ = i2
cs
1
2 P 0½   1
4 P 2
½
  1
4 P 2½ 


= i2
cs
8 = 1=4
ð
ÞkTγgCS:
Accordingly, the phase noise of the standard NMOS topology is calculated as
ℒΔω
f
g =
i2
Rp PM
ð
Þ + i2
gnr PM
ð
Þ + i2
cs PM
ð
Þ
A2=4
ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2
ℒΔω
f
g = kTFRp
A2
1
Q2
ω0
Δω

2
,
where the noise factor is
F = 1 + γ + γgCSRp
4
:
Note that the third term (due to the current source) can be minimized by increasing the current
source’s overdrive voltage. Therefore, we can say that the absolute minimum noise factor of
this topology is F = 1 + γ. However, this will come at the expense of current source headroom,
542
Oscillators

which will in turn limit the maximum amplitude and efﬁciency. To see this we can rewrite the
above expression in terms of the overdrive voltage of the current source device (or equivalently
its headroom):
F = 1 + γ + γ πA
4Veff
:
We need to carefully choose the Veff of the current source in order to optimize FOM. If
the current source is on the edge of saturation (which is a good design choice), the FOM is
given by
FOM =
A
FVDD
2Q2
kT 1mW =
2 1  Veff
VDD


π 1 + γ + γπ
2
VDD
Veff
 1



 2Q2
kT 1mW:
If γ = 2/3, the best choice of effective voltage is around Veff = (1/2)VDD, which corresponds to a
FOM of roughly 7.5dB less than the maximum achievable ﬁgure of merit (FOM1port(MAX)).
The above analysis assumes the current source transistor always operates in saturation. If the
current-source enters triode, both phase noise and FOM begin to degrade, as shown in
Figure 9.24. This is because when the differential pair is hard-switched, the LC tank sees a
resistance composed of a differential-pair transistor in triode along with the current-source in
triode. This is a relatively low impedance (compared to a device in saturation), and so the
effective Q of the LC tank will be degraded. Accordingly, a good design will ensure that the
current source is just at the edge of saturation, but does not drop into triode for any signiﬁcant
portion of the oscillation period.
This implies that once the tank inductance and Q are set (which are largely a function of the
oscillation frequency and the tuning range), the oscillator bias current is set. Thus, all is left is to
adjust the device sizes to achieve a reasonably sharp switching. The oscillator bias current may
be reduced then only if Rp is increased. This in turn may be accomplished only by increasing
the inductance, given a maximum allowable Q for the technology used. Increasing the induct-
ance however typically comes at the expense of lower tuning range.
If a lower current design is desired, one may choose a complementary structure (next section)
or a class C topology (7.2).
Voltage 
Limited 
Regime
Current 
Limited 
Regime
(2/π)IBIASRP
Amplitude [V]
FOM [dB20]
Current [A]
Figure 9.24: Transition between current-limited and voltage-
limited regime occurs when current source transistor enters the
triode region for some portion of the oscillation
9.4 LC Oscillator Topologies
543

9.4.2
The Standard CMOS Topology
It is possible to realize a negative resistance with cross-coupled PMOS instead of NMOS
transistors. It is also possible to employ both, as shown in Figure 9.25. This standard CMOS
topology uses the active element, shown separately in Figure 9.26, to provide the required
negative conductance. In this case, the fundamental of the current switched into the tank is
INR[1] =  (2/π)IBIAS, and the differential voltage is therefore
A = 4
π IBIASRp,
IBIAS
inr(t)
vout(t)
Rp
Lp
Cp
vout(t)
inr(t)
inr(t)
vout(t)
–IBIAS
IBIAS
gnr(t)
t
t
t
Figure 9.25: Standard CMOS LC topology
IBIAS
inr(t)
vnr(t)
gnR(t)
gnL(t)
innR(t)
innL(t)
gCS
inCS(t)
inpR(t)
inpL(t)
gpR(t)
gpL(t)
Current [A]
IBIAS
0
–IBIAS
Voltage [V ]
VDD
0
Conductance [S]
Voltage [V]
VDD
0
0
–gpR||gpL–gnR||gnL
–VDD
–VDD
Figure 9.26: Active element used in standard CMOS topology, and the associated I–V characteristic and
conductance plots
544
Oscillators

which is twice as large as the standard NMOS topology (assuming the same bias current). The
power efﬁciency is given by
η = 2
π
A
VDD
,
which is again twice as large as the standard NMOS topology (assuming the same amplitude).
At ﬁrst glance, this would suggest the CMOS topology is a more attractive topology, however,
the maximum differential amplitude of the CMOS is limited to VDD, while the NMOS-only
design is limited to 2VDD. Accordingly, the maximum achievable efﬁciency of both topologies
is comparable when achievable amplitudes are maximized.
In terms of phase noise, the time-varying conductance and noise due to the differential pair
transistors are related, as follows,
gnr tð Þ =  gnR tð ÞgnL tð Þ
gnR tð Þ + gnL tð Þ  gpR tð ÞgpL tð Þ
gpR tð Þ + gpL tð Þ
i2
gnr PM
ð
Þ = 2kT
γ gnR tð ÞgnL tð Þ
gnR tð Þ + gnL tð Þ + γ gpR tð ÞgpL tð Þ
gpR tð Þ + gpL tð Þ
 
!
= 2kTγgnr tð Þ,
where we assumed the channel noise coefﬁcient, γ, is the same for both the PMOS and NMOS
devices [6]. As the noise contribution of the differential pair is proportional to its conductance,
Bank’s result can again be used to state that i2
gnr PM
ð
Þ = γi2
Rp PM
ð
Þ.
As was done in the NMOS-topology, the noise due to the current source can be referred
across the tank as a cyclostationary noise source given by iCS(t) sgn (vOSC(t)), which has a PM
component equal to i2
cs PM
ð
Þ = kTγgCS. Therefore the complete expression for phase noise is
given by
ℒΔω
f
g =
i2
Rp PM
ð
Þ + i2
gnr PM
ð
Þ + i2
cs PM
ð
Þ
A2=4
ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2
ℒΔω
f
g = kTFRp
A2
1
Q2
ω0
Δω

2
,
where the noise factor is
F = 1 + γ + γgCSRp = 1 + γ + γ πA
Veff
:
Compared to the NMOS-only, the CMOS topology can achieve lower phase noise, higher
amplitude, and better efﬁciency for the same current and tank. However, if the amplitude of
both topologies is maximized (as is the case in a good design), the NMOS-only achieves better
phase noise, while achieving similar FOM and efﬁciency numbers. This is visualized in
Figure 9.27. Note that to gain some insight, the current source is assumed to be noiseless.
It should be noted that the above analysis assumes that the tank capacitance and any parasitic
capacitance appears differentially across the tank. If a substantial amount of capacitance is
9.4 LC Oscillator Topologies
545

connected from either output terminal to ground, the PMOS transistors have the potential to
load the tank and substantially degrade performance [6], [17]. (When the PMOS devices enter
the triode region, a single-ended capacitor will present a low impedance path to ground, while a
differential cap will not.) Because of this, the NMOS topology generally exhibits better
performance when large single-ended capacitors banks are used to provide wideband tuning.
9.4.3
The Colpitts Topology
The Colpitts oscillator, shown in Figure 9.28, is another widely used topology. Assuming the
conducting transistor stays in the saturation region when on, the transistor will inject current
into tank for a short time during the trough of the oscillation waveform. The conduction time is
generally kept small in order to maximize the oscillator’s efﬁciency. If we approximate this
current injection as an impulse train equal to ids tð Þ = IBIASTP∞
n = ∞δ t  nT
ð
Þ, where T is the
oscillation period, the fundamental component of ids(t) is Ids[1] = IBIAS, and we can approximate
the oscillation amplitude as
A = 2IBIAS
C2
C1 + C2
Rp,
2VDD
VDD
Bias Current
π/2
Amplitude
Efficiency
Phase Noise
Amplitude
Amplitude
VDD
2VDD
VDD
2VDD
Standard NMOS
Standard CMOS
6dB
Figure 9.27: Comparison of the standard NMOS and standard CMOS topologies assuming identical tanks and
a noiseless current source
Rp
Lp
IBIAS
ids(t)
ids(t)
vout(t)
gm(t)
vout(t)
C1
C2
gm(t)
Conduction time (portion of 
period when transistor is on)
t
t
t
Figure 9.28: The Colpitts
topology
546
Oscillators

which results in an efﬁciency of
η =
C2
C1 + C2
A
VDD
:
Naturally, a ﬁnite conduction time will result in an efﬁciency and amplitude of less than that
predicted by these expressions. A simple way to calculate the phase noise of the Colpitts
oscillator is to redraw the circuit in the form of the negative-gm model. This is done in
Figure 9.29, where the equivalent time-varying resistance is calculated as
gnr tð Þ =  gm tð Þ
C1C2
C1 + C2
ð
Þ2 ,
and the cyclostationary noise due to the conducting transistor referred across the tank is
i2
gnr PM
ð
Þ = 2kTγgm tð Þ
C2
C1 + C2

2
= 2kTγgnr tð Þ C2
C1
:
Given that the noise PSD of the conducting transistor is directly proportional to the time-
varying conductance gnr(t), we can use Bank’s general result to deduce that injected PM noise
is related to the tank noise as follows:
i2
gnr PM
ð
Þ = γ C2
C1
i2
Rp PM
ð
Þ:
Rp
Lp
iTRAN(t)=–gm(t)vx(t)
vout(t)
C1
C2
gm(t)
vx(t)=vout(t)C1/(C1+C2)
in(gm)(t)
in(cs)(t)
IBIAS
Lp
Rp
C1
C2
–gm(t)vout(t)x
C1/(C1+C2)
in(gm)(t)
in(cs)(t)
Complete Topology
Simplified Topology
(with biasing circuitry removed)
Lp
Rp
CP=C1C2/(C2+C2)
–gm(t)x
C1C2/(C1+C2)2
Negative-gm Equivalent Model
in(Rp)(t)
in(gm)(t)C2/(C1+C2)
in(cs)(t)C1/(C1+C2)
Figure 9.29: Redrawing the Colpitts topology in the form of the negative-gm model
9.4 LC Oscillator Topologies
547

The noise of the current source can also be referred across the tank using a simple AC
transformation, which results in a PSD of
i2
cstank = 2kTγgcs
C1
C1 + C2

2
:
As this is a stationary noise source, its PM component is simply half this value. Accordingly
the phase noise of the Colpitts topology is calculated as
ℒΔω
f
g =
i2
Rp PM
ð
Þ + i2
gnr PM
ð
Þ + i2
cstank PM
ð
Þ
A2=4
ZPM j ω0 + Δω
ð
Þ
ð
Þ
j
j2,
which simpliﬁes to
ℒΔω
f
g = kTFRp
A2
1
Q2
ω0
Δω

2
,
where the noise factor is
F = 1 + C2
C1
γ + γgCSRp
C1
C1 + C2

2
:
If we ignore the third term due to the current source, the noise factor becomes F = 1 + (C2/C1)γ.
Therefore, if C1 is designed to be greater than C2, a noise factor less than that of the standard
cross-coupled topology (where F = 1 + γ) can be attained. However, it must be noted that
increasing C1 also reduces the oscillator’s efﬁciency, and it can be shown that the achievable
FOM of a Colpitts oscillator is always less than the standard topology [18].
9.4.4
Oscillator Design Methodology
Table 9.1 summarizes the key features of the three topologies discussed. Note that the Colpitts
design is single-ended (although it can be extended to differential), whereas the NMOS and
CMOS topologies are differential.
For a given application, typically the nominal frequency of oscillation, the tuning range, and
the phase noise at a certain offset are given.
To understand the trade-offs involved, let us say a few words about the tuning range ﬁrst. As
we saw in Chapter 1, most practical oscillators incorporate some kind of switchable array of
capacitors to provide coarse frequency tuning. Let us assume that there is a total capacitance of
CP at the output due to the device, inductor, and routing parasitics. We also assume the
switched capacitor array exhibits a capacitance of CF when all the switches are off, resulting
from switch parasitic and capacitor top plate, with an additional capacitance of CV accounting
for the variable part. Thus, the total capacitance of the tank varies from CMIN = CP + CF to
CMAX = CP + CF + CV. To achieve a reasonable Q for the tunable array, typically CF and CP are
comparable. In Chapter 1, we saw an example of a discrete tunable capacitor with 32 units of
40fF capacitors, ranging from 430fF to 1.36P with a Q of better than 45 at 3.5GHz. Thus, for
548
Oscillators

that particular design, CF = 430fF. Assuming a tank inductance of LP, the lowest and highest
frequencies of oscillation are
ωL =
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LPCMAX
p
ωH =
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LPCMIN
p
,
and the nominal oscillation frequency is ω0 = ωL + ωH
2
. The tuning range may be then obtained as
(Problem 11)
TR = ωH  ωL
ω0
= 2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
CMAX
CMIN
r
 1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
CMAX
CMIN
r
+ 1
:
Consequently, if the total parasitic capacitance CP is small, the tuning range to the ﬁrst order is
independent of the tank inductance and nominal frequency of oscillation, as it depends only on
the ratio of on/off mode capacitance of the array. For a constant Q, the unit capacitor and the
switch size may be scaled while keeping the ratio constant. Although this is not quite true in
practice, we shall make use of it to ﬁnd a ﬁrst-cut estimate of the oscillator design parameters. In
our tunable capacitor example of Chapter 1, if CF and CP are comparable, the tuning range is
calculated to be 36%.
We further assume that considering the technology and area constraints, the tank quality
factor, mostly dominated by that of the inductor (at least at GHz frequencies), is given. Finally,
we make the observation that the oscillation optimum amplitude is also given for a certain
Table 9.1: Comparison between various oscillator topologies
Topology
NMOS
CMOS
Colpitts
Differential amplitude
2
π IBIASRp
4
π IBIASRp
2IBIAS
C2
C1 + C2
Rp
Maximum amplitude
2VDD
VDD
VDD
Efﬁciency
1
π
A
VDD
2
π
A
VDD
C2
C1 + C2
A
VDD
Noise factor
1 + γ + γ πA
4Veff
1 + γ + γ πA
Veff
1 + C2
C1
γ + γ πA
Veff
C1
C1 + C2

2
Noise factor, excluding the current source12
1 + γ
1 + γ
1 + C2
C1
γ  1 + γ
12 The current source noise may be eliminated using a class C or bias ﬁltering scheme, as we shall discuss in Section 9.7.
9.4 LC Oscillator Topologies
549

technology, as it solely depends on the supply voltage, that is, A = 2VDD for an NMOS design
for instance.
With these assumptions in mind, once a certain topology is chosen:
– Given the acceptable phase noise, the tank resistor (Rp) is set. This is based on the
assumption that the phase noise given by ℒΔω
f
g = kTFRp
A2
1
Q2
ω0
Δω

	2 depends only on F, A,
Q, and Rp. The ﬁrst three parameters are mostly set based on technology, and area
constraints.
– Once Rp is set, the oscillator bias current (IBIAS), known as the oscillation amplitude, is
known and given by A = 2
π IBIASRp = 2VDD (for an NMOS oscillator for instance).
– Assuming a small signal transconductance of gm for the NMOS design for instance, the
oscillator small signal gain is
gm
2 Rp 
IBIAS
2
Veffc
2
Rp
=
πA
8Veffc
= πVDD
4Veffc
,
where Veffc is the NMOS core transistors overdrive voltage. Assuming a small signal gain
of 5 is needed as a rule of thumb to ensure hard switching and start-up over PVT variations,
we obtain Veffc = πVDD
20 . The device size is then chosen accordingly, which determines the
device parasitic capacitance at the output.
– With Rp and Q known, the tank inductance Lp =
Rp
Qω0 is obtained.
With this choice of tank inductance, the nominal oscillation frequency may come out to be
less than ω0, depending on how large CP is. If this is the case, a new value of inductance may
need to be chosen, which sets a new Rp and IBIAS. Often one or two iterations may be required to
ﬁnalize the oscillator parameters and complete the design. Note that the new sets of parameters
may lead to a different and possibly better phase noise if Lp and hence Rp need to be lowered. In
consequence, while in an optimum design the bias current should be determined based on the
required phase noise, the maximum oscillation frequency may invoke a higher current. How-
ever, this is usually not the case in most RF oscillators operating at several GHz.
9.4.5
Optimum Tank Q
A useful exercise would be to ﬁnd the optimum frequency where the net LC tank quality factor
is maximum. This is motivated by the fact that the switched capacitor Q usually monotonically
reduces as the frequency increases, whereas the inductors’ Q tend to increase by frequency, at
least up to a certain frequency. Consequently, we set up the following exercise: We start with a
1.2nH differential inductor optimized for the best Q used in a 4GHz LC tank. The choice of
1.2nH is somewhat arbitrary, but a value in this range is quite typical for a 4GHz VCO. We
further assume a required tuning range of 20% for the VCO. From the last section, this sets the
ratio of the maximum to minimum total capacitance of the tank
CMAX
CMIN


to about 1.5	. For that
550
Oscillators

we design a switched capacitor array similar to the ones showed in Chapter 1. For this exercise,
we chose a 16nm process, with roughly a simulated ratio of 5.5	 maximum to minimum
capacitance for each unit. In reality, the routing and other parasitic elements will degrade this
somewhat. Four more cases are considered for frequencies of 8, 12, 16, and 20GHz, where in
each case the inductance value is scaled such that Lpω0 is kept constant. If the Q remains the
same, so will the net tank quality factor, as well as Rp = Lpω0Q, but that is certainly not the case.
As the frequency goes up, a smaller number of units is used for the capacitance, but the units as
well as the CMAX
CMIN ratio are maintained. For all cases the inductors are designed using only the
thick RDL layer, and optimized for the best Q. Naturally, for lower inductances designed for
higher frequencies, the physical size of the inductor reduces, though no particular constraint
was put on the size. With the exception of 4GHz, all the inductors are single-turn with sizes
varying from 160μm to 290μm.
The results are illustrated in Figure 9.30, where shown are the simulated quality factor over
frequency for the switched capacitor unit cell, the inductors, and the overall LC tank.
As expected the tank Q raises quickly and somewhat ﬂatten after 8GHz, reaching an
optimum value of close to 21 at 16GHz. Beyond that point, the increase in the inductor Q is
not much, while the capacitance Q linearly reduces with frequency, leading to a net drop in the
tank Q. This result is clearly technology dependent, and is also a function of the assumed tuning
range. Furthermore, the simulated quality factor and the maximum to minimum unit capaci-
tance used here are optimistic, as the post-layout routing and other parasitic factors will kick in
and degrade them. This overall leads to a shift of the optimum point to the left. Roughly
speaking though, it appears that if one ever has an option of choosing an optimum frequency for
the VCO, something around 10–15GHz gives the best trade-off between the L and C quality
factors. Moreover, this frequency range is reasonably away from the point that the tank
capacitance becomes too small, where the parasitic elements dominate.
9.5
Q-DEGRADATION
..............................................................................................
In the case of the standard NMOS and standard CMOS, the amplitude and the achievable FOM
are limited by the headroom requirement of the current source. The question, therefore, arises as
to why this current source is required at all.
Frequency, GHz
100
150
2
4
8
20
16
12
Q
50
25
75
125
175
Capacitor
22
18
26
Tank
Inductor
4
20
Figure 9.30: Simulated quality factor of the LC
tank and individual capacitor and inductor
9.5 Q-Degradation
551

Looking at Figure 9.23, we can see that active element provides a negative conductance only
when the input voltage is small. For larger voltages, one of the transistors in the differential pair
will be off, while the other will be on, and the conductance drops to zero. This is because the on
transistor will be degenerated by the high impedance of the current source. Even when the on
transistor enters the triode region, the current through it will be completely determined by the
current source. This is shown in Figure 9.31.
If the current source is removed, when either of the transistors enters the triode region a time-
varying positive resistance due to the drain-source resistance (gds) is seen by the LC tank (see
Figure 9.31 and Figure 9.32). In this case, the time-varying conductance is given by
gnr tð Þ = 
gmL tð Þ + gmR tð Þ
2


+
gdsL tð Þ + gdsR tð Þ
2


,
which consists of the required negative-conductance due to the transconductance of the devices
(i.e., gmL and gmR), and the unwanted positive-conductance due to the drain-source resistance
(i.e., gdsL and gdsR). This unwanted positive-conductance degrades the tank’s Q and, as a result,
the oscillator’s phase noise and FOM. Accordingly, this voltage-biased oscillator should be
avoided.
Even if the current source is retained, it is important that its impedance is large enough
to degenerate the on transistor when the differential pair is hard-switched. This is straight-
forward to do at DC, but a large impedance is ideally needed at all even order harmonics
with 2ω0 being the most critical (in a perfectly balanced oscillator, only even-order
harmonics appear at the source of the differential pair, i.e., node VP in Figure 9.31). For
high-frequency oscillators, parasitic capacitance at the source of the differential pair
can reduce the impedance at these even-order harmonics frequencies and allow the
differential pairs to load the tank. Therefore, the current-biased oscillator can behave like
a voltage-biased oscillator. Figure 9.33 shows the effect of increasing capacitance on
efﬁciency and FOM.
IBIAS
Current-biased
OFF
ON
(Triode)
gds
Z=∞ 
Voltage-biased
OFF
ON
(Triode)
gds
Z=gds 
VP
Figure 9.31: The current
source in the standard
topology prevents the
differential pair loading
the tank during triode
operation
552
Oscillators

Rp/2
Lp/2
Rp/2
Lp/2
2Cp
2Cp
inr(t)
vout(t)
Topology
Rp
Lp
Cp
vout(t)
inr(t)
inr(t)
vout(t)
Negative-gm Model
gnr(t)
–(gmR(t)+gmL(t))/2
(gdsR(t)+gdsL(t))/2
Negative-conductance
Positive-conductance
(cause of Q-degradation)
Time-Domain Waveforms
Positive 
conductance 
due to triode 
conduction
MR
ML
Dip due to 
triode 
conduction
t
t
t
Figure 9.32: The voltage-biased LC oscillator
CTAIL
Parasitic 
Cap
4pF
1.8V
1Ω 
1.6nH
W=40μm
L=0.15μm
W=80μm
L=0.5μm
8dB 
drop
30%
drop
60
50
40
30
20
10
Efficiency [%]
FOM@10MEHz [dB20]
10f
194
192
190
188
186
18410f
100f
1p
Tail Capacitance [F]
10p
100p
100f
1p
10p
100p
Tail Capacitance [F]
30%
drop
8dB 
drop
Figure 9.33: Effect of parasitic tail capacitor on oscillator’s performance
9.5 Q-Degradation
553

9.6
FREQUENCY MODULATION EFFECTS
..............................................................................................
The noise mechanisms documented to this point suggests that ﬂicker-noise only produces
amplitude noise, which can be ignored. However, as anyone familiar with CMOS oscillator
design can attest, ﬂicker noise does appear in the output spectrum, and can often dominate in a
bad design. The shortcoming in the analysis is because ﬂicker noise and other low-frequency
noise are up-converted to the output spectrum through frequency-modulation effects that were
not captured in the model. The problem being that we assumed a ﬁxed frequency deﬁned by the
equivalent noiseless oscillator. Therefore to augment the analysis, this section shows how low-
frequency noise sources can cause perturbations in the oscillation frequency, which contributes
directly to ℒ{Δω}. Two speciﬁc mechanisms are reviewed: one due to nonlinear reactive
elements [19] and one due to harmonic currents [9].
9.6.1
Nonlinear Capacitance
We have so far assumed the RLC resonant tank is completely linear, but this is rarely the
case in practical circuits. Device capacitance associated with the active circuit can be very
nonlinear, and almost all VCOs employ varactors to provide some level of continuous
tuning (as discussed in Chapter 1, the capacitance of varactors is a strong nonlinear
function of the oscillation amplitude). Therefore, the amplitude of oscillation will generally
have some effect on the frequency of oscillation. Assuming a linear inductance, which is
reasonable for any integrated or bond-wire inductance, the oscillation frequency is gener-
alized as
ω0 A
ð Þ =
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
L C A
ð Þ
p
,
where the oscillation frequency is a function of amplitude because of the dependence of the
nonlinear capacitance on amplitude. As a result, small changes in amplitude will also produce
small changes in the oscillation frequency [19]. The rate of this AM–FM conversion is
quantiﬁed as
KAMFM = dω0
dA = 
1
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LC A
ð Þ
p
1
C A
ð Þ
dC A
ð Þ
dA
:
Because of this AM–FM conversion process, amplitude noise can produce small perturbations
in frequency. The spectral density of this frequency modulation is calculated as
SΩ Δω
ð
Þ = KAMFM
j
j2v2
AM = ω02
4C2
dC
dA


2
v2
AM,
where v2
AM is the power spectral density of amplitude noise, which although small will never be
zero. This can then be related to phase noise as follows:
ℒΔω
f
g = SΩ Δω
ð
Þ
Δω
j
j2
= KAMFM
j
j2v2
AM
Δω
j
j2
:
554
Oscillators

Therefore if KAMFM is large and the carrier offset |Δω| is small, even a small amount of
residual amplitude noise present in the oscillator can be converted into a signiﬁcant amount of
frequency noise, which as discussed previously is indistinguishable from phase noise.
This AM–FM conversion is generally the dominant mechanism through which ﬂicker-noise
and other low-frequency noise sources are up-converted to the output frequency. Consider the
negative-gm model shown in Figure 9.34: If the tank contains a linear capacitor, no ﬂicker noise
appears in the phase noise plot. However, if the linear capacitor is replaced with a nonlinear
capacitor, ﬂicker noise does appear in the phase noise proﬁle.
Because of this AM–FM mechanism, it is not advisable to design a VCO with one large
varactor. Instead, as explained in Chapter 1, a good VCO design will contain a digitally
controlled capacitor bank to provide coarse frequency tuning, and a small varactor to provide
just enough continuous tuning between digital codes. As a digitally controlled capacitor bank
can be much more linear than a varactor, ﬂicker noise upconversion can be minimized [20].
It should be noted that the nonlinear capacitance of the active element can also present
signiﬁcant nonlinear capacitance, as shown in Figure 9.35. In this case, the nonlinear capaci-
tance is a strong function of the tail capacitance, which generally results in a larger value of
|dC/dA|2, which is yet another reason to minimize the tail capacitance.
Finally it is important to remember that this AM–FM mechanism is dependent on the value
of |dC/dA|2, not on the total capacitance. Therefore for a speciﬁc amplitude, A, it is possible that
|dC/dA|2 will be nulled and the ﬂicker noise upconversion will be eliminated [19]. However,
since nonlinear capacitance is difﬁcult to model, and tight control over the oscillation amplitude
is not easy, it is always best to minimize the total amount of nonlinear capacitance rather than
seeking to |dC/dA|2 for a speciﬁc value of A.
Cp
inr(t)=2.5tanh(–4vout(t)) [mA]
Cyclo-Stationary 
Flicker Noise 
Source
Nonlinear 
capacitance results 
in flicker noise in 
output spectrum
Si=(4kT105/f)inr(t)
1.6nH
200Ω 
inr(t)
vout(t)
Figure 9.34: Nonlinear reactive elements results in ﬂicker noise appearing in the output spectrum
9.6 Frequency Modulation Effects
555

9.6.2
Effective Nonlinear Capacitance
More insight into the impact of nonlinear tank capacitance, and particularly the varactor, may
be obtained using the quasi-static approach presented in [19]. Shown in Figure 9.36 is a
schematic of a simpliﬁed LC oscillator tank, along with typical MOS varactor characteristics.
The varactor C–V curve was analyzed in Chapter 1, and was indicated there that an
accumulation-mode MOS capacitance is commonly employed, which results in the character-
istics shown below on the left.
For a standalone MOS varactor, it was shown that the threshold where the capacitance goes
from low to high is around 0V, where the device moves from depletion region to accumulation.
In an actual VCO on the other hand, this depends on the control voltage and the VCO output
DC bias, which is typically at VDD. As the control voltage is also limited to supply, one may
employ an independent DC bias to achieve a wider tuning range for the same varactor size
(Figure 9.36 right side). This however comes at the expense of additional parasitic capacitance,
and imposes a trade-off on the biasing resistor size to optimize the loading on the tank, and the
resistor noise contribution. To generalize, we label the transition threshold as an arbitrary
voltage V0, which is a function of the control voltage, and the varactor biasing (VDD or
otherwise), and that can be adjusted as needed. Assuming a nearly sinusoidal VCO output
CTAIL
Nonlinear
Cap
VNR
W=40μm
L=0.15μm
W=120μm
L=1μm
CTAIL=1.5pf
CTAIL=1fF
Figure 9.35: The active element can be a source of signiﬁcant nonlinear capacitance. The presence of a large
tail capacitance can signiﬁcantly affect the nonlinearity
Cnr
v
VDD
VBIAS
VCONT
VCONT
Optional Varactor 
Biasing
V0
Figure 9.36: A typical CMOS VCO tank along with the varactor characteristics
556
Oscillators

voltage of A cos ω0t, at steady state, a certain effective capacitance (Ceff) is presented to the tank
which not only depends on V0, but also is a function of the VCO output amplitude, A. While
this was already shown in Chapter 1, we shall present an approximate mathematical expression
for Ceff here based on [19].
9.6.2.1 Graphical Interpretation
Consider a memoryless system, such as the nonlinear resistor employed in the VCO to sustain
steady oscillation, whose I–V curve is shown in Figure 9.37 left side. Since the negative
resistance is memoryless, the area described by the instantaneous point of work in the (inr, vnr)
coordinate must be zero for a total period of the fundamental frequency. Consequently, the line
integral of the I–V locus must be equal to zero:
Þ
inrdvnr = 0.
That is to say, moving along the curve back and forth results in no net work, as it can be
clearly seen from the ﬁgure. On the contrary, if the system has hysteresis for instance, moving
back and forth takes place on two different paths, leading to a nonzero line integral.
Now, let us consider a linear (for the moment) capacitance of C, where a sinusoidal voltage
of A cos ω0t is applied across its terminals. The capacitor has memory, and intuitively we expect
a nonzero line integral. We have
vC(t) = A cos ω0t
iC(t) =  ACω0 sin ω0t.
Consequently, we can write
iC
ACω0

2
+ vC
A

2
= 1,
which indicates an ellipse in the (ic, vc) coordinate (Figure 9.37 right side). The line integral
Þ
iCdvC is clearly no longer zero, and is described by the area of the ellipse:
Þ
iCdvC = πA2Cω0.
If the capacitor is nonlinear, as in the case of a varactor, the I–V locus driven by a periodic
waveform consists of several ellipses of different heights but the same width. This will be
clariﬁed further next, when a simpliﬁed MOS varactor is analyzed.
inr
vnr
iC
vC
Memory-Less
Linear Capacitor
A
ACw0
Figure 9.37: Comparison
of I–V characteristics of a
memoryless system with a
capacitor
9.6 Frequency Modulation Effects
557

9.6.2.2 Mathematical Expression
Consider Figure 9.38, which shows a MOS varactor driven by a sinusoidal periodic signal of
amplitude A.
For simplicity, let us assume the varactor varies between two values of CL and CH, with a
step transition as the voltage reaches V0. The corresponding capacitance over time, along with
its I–V locus, are shown in Figure 9.39.
Let us deﬁne the small signal nonlinear capacitance as Cnr tð Þ = dQ
dV, whose value over time is
shown above for the simpliﬁed MOS varactor. Since the nonlinear capacitance is periodic, we
may describe it using a Fourier series:
Cnr tð Þ =
X
+ ∞
m = ∞
Cnr m
½ ejmω0t:
Note that the ﬁxed (or linear part of the) tank capacitance is inconsequential in this analysis, and
will be dealt with shortly. The tank voltage (which is the same as the capacitance voltage) is
periodic as well, and may be expressed as
vC tð Þ =
X
+ ∞
n = ∞
VC n½ ejnω0t:
Thus, the inductor current is
Cnr
v
V0
t
+A
–A
CH
CL
VCONT
VBIAS + Acosw0t
Figure 9.38: Varactor C–V curve swept by the
VCO large sinusoidal output
iC
vC
Varactor I-V Curve
A
V0
Cnr
t
CH
CL
V0
t0
Varactor Capacitance
t0 = cos–1(V0/A)
Figure 9.39: Nonlinear capacitance over time and its I–V locus
558
Oscillators

iL tð Þ = 1
L
ð
vC tð Þdt = 1
L
X
+ ∞
n = ∞
VC n½ 
jnω0
ejnω0t:
The capacitor current is
iC tð Þ = dQ
dt = dQ
dvC
dvC
dt = Cnr tð Þ d
dt
X
+ ∞
n = ∞
VC n½ ejnω0t:
After expansion,
iC tð Þ =
X
n
X
m
jnω0Cnr m
½ VC n½ e j m + n
ð
Þω0t:
KCL demands,
iC tð Þ + iL tð Þ = 1
L
X
+ ∞
n = ∞
VC n½ 
jnω0
ejnω0t +
X
n
X
m
jnω0Cnr m
½ VC n½ e j m + n
ð
Þω0t = 0:
The quasi-static approximation entails a nearly sinusoidal tank voltage, i.e.,
VC 1½  = VC 1
½
 = A
2
VC[n]  0, for n 6¼  1.
As a consequence, with higher harmonics ignored, we have
A
2
jLω0
e jω0t  ejω0t

	
+ jω0
A
2
Cnr 0½   1
2 Cnr 2½ 


e jω0t 
Cnr 0½   1
2 Cnr 2
½



ejω0t


= 0,
which simpliﬁes to
1
jLω0
+ j Cnr 0½   1
2 Cnr 2½   1
2 Cnr 2
½



ω0 = 0:
Note that since Cnr(t) is an even symmetric function, Cnr[m] = Cnr[m] for all m.
Thus, we shall deﬁne the effective tank capacitance as
Ceff = Cnr 0½   1
2 Cnr 2½   1
2 Cnr 2
½
:
The ﬁrst term is the time-average capacitance, which includes any ﬁxed linear capacitance in
parallel with the nonlinear tank capacitance, while the other two terms are described by the
nonlinear capacitance 2nd-order Fourier coefﬁcients. Clearly, the time-average capacitance
alone does not correctly account for the effective capacitance, as it does not properly deal with
the balance of the tank voltage and current. Note that a very similar expression was derived
in
Section
9.2.2
for
the
effective
conductance
of
the
nonlinear
active
element
Geff = Gnr 0½   1
2 Gnr 2
½
  1
2 Gnr 2½ 

	
.
The above expression is not entirely accurate, as it neglects the effect of mixing of higher
harmonics of the nonlinear capacitance with higher order components of the tank voltage. If the
tank quality factor is large, however, this expression is reasonably correct.
9.6 Frequency Modulation Effects
559

Note that, as shown in Problem 14, we can say in general
Ceff =
Þ
iCdvC
πA2ω0
,
which is obvious for the linear capacitance, and may be easily extended to a nonlinear
capacitance as well.
9.6.3
Groszkowski Effect
In analyzing LC oscillators we have thus far assumed for the most part that the output is
sinusoidal, this is to say the harmonics of the output waveform have been neglected entirely.
Although small, these harmonics do exist (even in a perfectly linear LC tank), and can affect the
frequency of oscillation. In 1933, Groszkowski [21] explained and quantiﬁed how this har-
monic current produces a downward shift in the oscillation frequency.
Shown in Figure 9.40 is a simpliﬁed LC oscillator, where the active element is excited by the
output waveform vnr(t), and generates an energy-restoring current inr = f(vnr), with signiﬁcant
harmonic content. The fundamental of this current compensates for tank losses, while higher
order harmonics (which must go somewhere) ﬂow through the least resistance path, i.e.,
capacitor. Since the negative resistance is memoryless, as we showed previously, the area
described by the instantaneous point of work in the (inr, vnr) coordinate must be zero for a total
period of the fundamental frequency:
Þ
inrdvnr = 0.
Switching to the frequency domain, this condition leads to the following identity
X
∞
k = ∞
kInr k½ Vnr k
½
 = 0,
where Inr[k] and Vnr[k] are the kth Fourier coefﬁcients of the current and voltage, respectively.
This can be further rewritten as
X
∞
k = ∞
k Vnr k½ 
j
j2
Z k½ 
= 0,
where Z[k] is the tank impedance at the kth harmonic. Collecting the fundamental components
on one side of the equation, this becomes
Vnr 1½ 
j
j2
Z 1½ 
j
j
= 
X
∞
k = 2
k Vnr k½ 
j
j2
Z k½ 
j
j :
Rp
Lp
vout(t)
inr(t)
Cp
Fundamental
Component
Higher Order
Harmonic
Components
Figure 9.40: Higher-order harmonics of the
current from the active element ﬂows through
the capacitor. This harmonic content produces a
downward shift in the oscillation frequency
(compared to that predicted by linear analysis).
560
Oscillators

Around the fundamental, the tank impedance is given by
Z 1½ 
j
j  Lpω02
2Δω ,
where Δω is the shift in frequency with respect to the natural resonant frequency, and
ω0 = 1=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
LpCp
p
. At higher harmonics (k > 1), the tank impedance is capacitive, and its magni-
tude is approximately equal to
Z k½ 
j
j 
k
k2  1

	 Lpω0:
Thus,
Δω
ω0
  1
2
X
∞
k = 2
k2  1

	 Vnr k½ 
j
j2
Vnr 1½ 
j
j2 :
Alternatively, we could have expressed the results in terms of harmonic current content,
Δω
ω0
  1
2Q2
X
∞
k = 2
k2
k2  1
Inr k½ 
j
j2
Inr 1½ 
j
j2 ,
where Q =
Rp
Lpω0 is the tank quality factor.
If no harmonic components are present, evidently Δω/ω0 = 0, which is satisﬁed at the natural
resonant frequency of the tank. However, if signiﬁcant harmonic content exists, the identity
demands that Δω/ω0 < 0, which is satisﬁed only when oscillation frequency is less that natural
resonant frequency of the tank. Naturally a higher Q will result in a smaller frequency shift for
the same harmonic current.
This effect may be also qualitatively explained as follows: In the presence of harmonic
current, the electrostatic energy stored in the capacitor is larger than if harmonics did not exist.
Because the active circuit is memoryless, this extra energy must be balanced by the inductor,
which is accomplished by a downward shift in the oscillation frequency, thereby allowing it to
store more electromagnetic energy.
We have previously deduced that in the case of an oscillator with linear reactive elements,
ﬂicker noise will only modulate the amplitude of the oscillation waveform, and will not produce
phase noise. This, however, was based on the nearly sinusoidal approximation. If the harmonic
content of the output is not ignored, noise that modulates any harmonic of the output waveform
will produce frequency noise, which directly contributes to ℒ{Δω} [9].
To eliminate this frequency modulation effect, the active element should be made as linear as
possible, so as to not introduce any harmonic content. It should be noted, however, that designs with
hard-switching nonlinearities are much more power efﬁcient and, so, using a linear (or soft-limiting)
active element is not advisable for a CMOS LC oscillator. Moreover, even with a linear active-
element, frequency modulation effects due to nonlinear reactive elements would still be present.
9.6.4
Supply Pushing
Low-frequency supply noise and spurs, just like ﬂicker noise, can produce AM sidebands,
which are in turn converted to frequency noise through nonlinear capacitance. The magnitude
9.6 Frequency Modulation Effects
561

of this “supply pushing” is an important consideration, especially in modern SoCs, which may
have relatively noisy supplies. For this reason, the supply of a VCO is typically generated by a
separate low-dropout regulator (LDO), which isolates the circuit from noise elsewhere on
the chip.
9.7
MORE LC OSCILLATOR TOPOLOGIES
..............................................................................................
Improved understanding of the operation of LC oscillators has led to the development of
topologies with enhanced FOMs. Two important topologies are now discussed, which achieve
close to the maximum theoretical FOM of any one-port LC oscillator.
9.7.1
The Standard Topology with Noise Filter
In the standard NMOS topology, the current source ultimately limits the achievable
FOM. If a large current source device is used, its transconductance will be large and will
inject a large amount of noise into tank. If a small device is used, the headroom
requirement will be large, and the oscillation amplitude will be reduced. However, as
noted previously, the current source needs only to present a high impedance around the
second harmonic, and so it is possible to employ a simple passive network that resonates
at 2ω0 [22]. As shown in Figure 9.41, a large device that functions as a current source
can be retained, but its noise is ﬁltered off using a large capacitor. A series inductor is
then designed to resonate at 2ω0 using the parasitic capacitance at the source node of
differential pair transistors. In this way the current source introduces no noise, the
differential pair does not load the tank, and the headroom of the current source can be
made arbitrarily small. As a result, the noise factor is simply
F = 1 + γ,
while, assuming the output is driven rail to rail, the efﬁciency can approach (and even exceed)
η = 2/π = 63.7%. Accordingly the FOM is given by
FOM =
4=π
1 + γ
ð
Þ
Q2
kT 1mW,
which is only 2dB less than the maximum achievable FOM of a CMOS oscillator. This FOM is
preserved even if the tail transistor is removed, and the oscillator is voltage-biased.
To emphasize the power of this common-mode resonance consider the idealized oscillator
shown in Figure 9.42. The transistors are thick oxide devices from a 28nm process. The tail
inductor is half the size of the tank inductance and has a similar Q for the same frequency. A tail
capacitance is then swept and the FOM is plotted. For a tank of quality factor of 12, the
maximum achievable FOM is 196. When the tail inductor resonates at 2ω0 (when the tail
capacitance is equal 6.25pF), the FOM of this oscillator is within 1dB of this value. Equally the
562
Oscillators

ﬂicker noise is almost entirely eliminated as the FOM is preserved whether it is measured at
50kHz or at a 10MHz offset. Note that the current switched into the tank is not a perfect square,
but rather as a waveform with ﬁnite rise/falls times, which results in more energy at ω0 and
better efﬁciency.
The standard CMOS oscillator can also employ this technique. In order to prevent the PMOS
transistor loading the tank, it is advisable to include a third inductor series inductor as shown in
Figure 9.43.
It is also possible to employ Hegazi’s common-mode resonance technique without the use of
an additional inductor. This is because in any differential oscillator design the tank has two
distinct modes, i.e., a common mode and a differential mode. If we ensure that common-mode
resonance frequency occurs at twice the differential resonance frequency, all the beneﬁts of
Hegazi’s oscillator will be reaped without the need for an additional inductor. These two
different modes are shown in Figure 9.44, and can be controlled by either adjusting the
Filtered
Current 
Source
High 
Impedance 
@ 2FLO
LC Tank 
Resonates 
@ FLO
Parasitic
Cap
VTAIL
Vcs
Voutp
Voutn
VTAIL
oscillates
@2ω0
VDD
VCS
(Optional)
time
voltage
Figure 9.41: The standard NMOS topology with noise ﬁlter
Cp
LS
QTANK=12@fLO
RS
LS= 333pH
Theoretical max 
FOM for any LC 
VCO with Q=12
LTAIL
RTAIL
CTAIL
QTAIL=24@2fLO
LTAIL= 160pH
Flicker noise 
suppressed
fLO=2.1GHz
Figure 9.42: Importance of
common-mode resonance on
FOM
9.7 More LC Oscillator Topologies
563

differential inductors magnetic coupling, k, or adjusting the arrangement of capacitors in
the tank.
9.7.2
The Class C Topology
As shown in Figure 9.45, if the active element of an LC oscillator converts the DC supply
current into a square wave at ω0, the maximize possible power efﬁciency is given by
η = 2
π
A
VDD
,
which reaches a maximum of 63.7% when A = VDD. If, instead, the supply current is injected
into the tank as series of impulses, the efﬁciency becomes
η =
A
VDD
,
which can potentially reach 100% when A = VDD. This is analogous to class C power ampli-
ﬁers (see Chapter 11).
vout(t)
High 
Impedance 
@ 2FLO
Parasitic
Cap
High 
Impedance 
@ 2FLO
Parasitic
Cap
2nd noise filter 
advisable in CMOS 
implementation
Figure 9.43: The standard CMOS topology
with two noise ﬁlters
564
Oscillators

In [2], an active element was proposed that sought to generate this impulse injection. As
shown in Figure 9.46, by introducing a DC offset in the biasing the differential pair transistors,
the majority of the current is injected as an impulse at the peak and trough of each oscillation.
The offset effectively increases the turning on instant of each device, and so a larger voltage
swing is required, which results in the current being injected only when the instantaneous
voltage is large. The complete circuit, known as a class C topology, is shown in Figure 9.47. If
the differential pair transistors don’t enter the triode region, and the current source noise is
stripped off with a large capacitor,13 the noise factor is given by F = 1 + γ (because of Bank’s
general result), and the FOM can be calculated as
FOM =
1
1 + γ
ð
Þ
A
VDD
Q2
kT 1mW:
k
VCM
ICM
ICM
2VDM
IDM
IDM
Common Mode 
(Resonates @ 2FLO)
Differential Mode 
(Resonates @ FLO)
2CDM
CCM
LS
)
)(
1(
1
DM
CM
S
DM
C
C
k
L
+
+
=
w
CM
S
CM
C
k
L
)
1(
1
−
=
w
Figure 9.44: An oscillator with implicit common-mode resonance
inr(t)
VDD
IDC
inr(t)
–IDC
IDC
–IDC
IDC
inr(t)
Square Wave Injection
(up to 63.7% Efficient)
Impulse Wave Injection
(up to 100% Efficient)
t
t
Active
Circuit
Figure 9.45: Injecting the energy-
restoring current as an impulse can
improve oscillator efﬁciency
13 It is suggested [2] that the size of the capacitor should be limited to two to three times the total tank capacitance in order to
avoid an amplitude instability effect known as “squegging.”
9.7 More LC Oscillator Topologies
565

Therefore, if the A can be made close to 2VDD, the topology can theoretically achieve close
to the maximum achievable FOM of an LC oscillator. Published performance metrics [2]
show that this topology can achieve a similar FOM to that of the standard topology
employing a tail ﬁlter [22], and has the advantage not requiring an additional inductor.
Furthermore, biasing the devices closer to threshold leads to a lower power design com-
pared to the standard NMOS topology. Hence, it is fair to say that in typical applications,
the class C topology tends to offer a better ﬁgure of merit and a lower bias current, but not
necessarily a better phase noise.
9.8
RING OSCILLATORS
..............................................................................................
Ring oscillators are another well-known type of CMOS oscillator. This section presents a
simple overview of their operation and noise performance with a particular focus on the
inr(t)
CTAIL
VDD–VB
(offset increases 
effective VTH)
vnr(t)
IBIAS
vnr(t)
t
inr(t)
–IBIAS/2
IBIAS/2
t
VB=VDD
VB<VDD
Figure 9.46: The active element of
the class C topology. The shift in
the DC bias of differential pair
transistors is modeled with ideal
series voltage sources
inr(t)
vout(t)
VB
Large cap 
creates virtual 
ground
inr(t)
–IBIAS/2
IBIAS/2
vout(t)
gnr(t)
Gate DC bias 
reduced
t
t
t
Figure 9.47: The class
C topology
566
Oscillators

inverter-based design. The primary goal of this section is to show that the phase noise per
unit power of a ring oscillator (i.e., FOM) is signiﬁcantly worse than that of an LC
oscillator.
9.8.1
Basic Operation
At its simplest a ring oscillator consists of a chain of an odd number of inverting
ampliﬁers connected in unity feedback. A basic inverter-based oscillator is shown in
Figure 9.48. Assuming, the small signal gain of the ampliﬁer chain is greater than 1,
and the delay of the chain is nonzero (which is always the case in a real design), the circuit
will oscillate. In the case of the inverter-based ampliﬁer, the oscillation period will be
equal to the time a particular transition edge takes to propagate twice around the loop,
which is calculated as
f 0 = 1
T0
=
1
N τinv rð Þ + τinv f
ð Þ

	 ,
where T0 is oscillation period, N is the number of inverter stages, τinv(r) is the propagation delay
of the inverter given a rising edge output, and τinv( f ) is the delay of the inverter given a falling
edge output. Assuming the inverters are sized to give approximately equal rising and falling
edges (i.e., τinv = τinv(r) = τinv( f )), the oscillation frequency simpliﬁes to
f 0 =
1
2Nτinv
:
Therefore, the frequency of a ring oscillator can be increased by reducing the number of stages
(ensuring that N is always odd and greater than or equal to 3), or decreasing the inverter delay.
Given that the total load capacitance at the output of each inverter is completely charged and
discharged every cycle, the power burned by each inverter can be approximated as
PINV  CLOADV2
DDf 0,
VDD
IDD
Outputs assuming N=5
N = number of inverters 
VO<0>
VO<1> VO<N–2>
VO<N–1>
VO <0>
VO <1>
VO <2>
VO <3>
VO <4>
t
t
t
t
t
Figure 9.48: A simple inverter-based ring oscillator. N should be odd and greater than 3
9.8 Ring Oscillators
567

where CLOAD is the total load capacitance perceived by the inverter, and VDD is the supply
voltage. The power dissipated by the oscillator is simply the sum of the power dissipated in
each inverter, i.e.,
POSC = NPINV  NCLOADV2
DDf 0,
which gives a total oscillator current of
IDD  NCLOADVDDf0.
Typically it is best to calculate the inverter delay through simulation. Consider the
inverter shown in Figure 9.49. If the input changes instantaneously, the propagation delay
given a rising edge output (i.e., the time for the output to charge up to VDD/2) is calculated
as
τinv rð Þ =
ðVDD=2
0
CLOAD v
ð Þ
IPMOS v
ð Þ dv,
where IPMOS is the current through the PMOS device. In general, both the device current and
the capacitance, CLOAD, are strong nonlinear functions of the output voltage. Moreover,
the equation does not even account for an input with a ﬁnite slope. This makes calculation of
an accurate close-form expression for the delay of an inverter embedded in a ring oscillator
difﬁcult [23].
Nevertheless, some valuable design insight can be attained by making some crude
simpliﬁcations. Rewriting the expression for oscillator current in terms of frequency
gives
f 0  1
N
IDD
CLOADVDD
:
Now, at any given instance one node in the oscillator is being pulled up and one node is being
pulled down. Assuming the inverters are sized to give equal rise and fall times, we can say that
at all times one PMOS device is conducting (charging up a node) and one NMOS device is
conducting (discharging a different). Therefore we can get a rough estimate of the upper bound
VIN
VOUT
CLOAD
IPMOS
INMOS
VOUT
VIN
|VTP|
VDD
Triode
Region
Saturation
Region
IPMOS
t
t
VDD/2
tinv(r)
β/2(VDD–|VTP|)2
Figure 9.49: Response of a CMOS
inverter to a step function
568
Oscillators

of IDD as the quiescent current of one fully on NMOS (or PMOS) device, which assuming the
square law model is given by
IDD  1
2 β VDD  Vth
j
j
ð
Þ2,
where β = μ(W/L)COX. This gives an approximate upper bound on the oscillation frequency of
f 0  1
2N
β VDD  Vth
j
j
ð
Þ2
CLOADVDD
:
Therefore, as well as adjusting the number of stages, adjusting CLOAD, VDD, and device sizes
(via β / W/L) can be used to set the oscillation frequency. Note that if CLOAD arises
primarily from the inverter gate capacitance (i.e., CLOAD / WLCOX), increasing the device
width will not have a strong effect on frequency since it increases both β and CLOAD in the
same proportion. If, however, CLOAD is dominated by the routing capacitance, the buffer
load, or is simply an explicit ﬁxed capacitance, increasing the device width will increase the
oscillation frequency (this is typically the case in most practical designs where the oscillator
is needed to drive a load). Naturally a more accurate model will provide a more accurate
frequency prediction, but the qualitative effect of N, CLOAD, VDD, and β on the oscillation
frequency is valid.
9.8.2
Estimating Phase Noise in Hard-Switching Circuits
The output of a ring oscillator generally toggles between supply rails and so resembles a
square wave rather than a sinusoid as was the case for an LC oscillator. Therefore it is more
natural to describe the frequency instability of such an oscillator in terms of the time deviation
of its period from the expected period of a noiseless oscillator as measured at waveform
transitions.
Shown in Figure 9.50 is the simple case of an inverter toggled periodically between 0 and
VDD. In the presence of device noise, the transition time can be seen to either advance or
retard with respect to a noiseless device. By sampling the output noise at the expected (i.e.,
noiseless) transition time, a good estimate of the phase noise can be calculated. As
highlighted in Figure 9.50, the sampled phase noise at the rising and falling edges can be
deﬁned as
ϕδr tð Þ = 2π
T0
1
λr
vδr tð Þ
ϕδf tð Þ = 2π
T0
1
λf
vδf tð Þ,
where λr and λf are the rising and falling edge slopes at the transition point, and the sampled
noise voltage is given by
9.8 Ring Oscillators
569

vδr tð Þ =
X
∞
n = ∞
vn tð Þδ t  tr  nT0
ð
Þ
vδf tð Þ =
X
∞
n = ∞
vn tð Þδ t  tf  nT0

	
,
where vn(t) is the noise voltage of output waveform, tr is the time of the ﬁrst (noiseless) rising
transition through the midrail (i.e., VDD/2), and tf is the time of the ﬁrst (noiseless) falling
transition through the midrail. If we assume this sampled phase noise persists between the
measuring instances, we can say that a good estimate of phase instability (i.e., ϕ(t)) is a sampled
and held version of the sampled phase noise, i.e.,
ϕEST(t) = ϕδr(t) ∗wr(t) + ϕδf(t) ∗wf(t).
identical inverters, i/p toggled at fOSC
Voltage
t
IPMOS
VIN
VOUT
VOUT
IPMOS
INMOS
Noiseless
Waveforms
t
Midrail = VDD/2
Noisy output
perturbs 
transition point
VOUT
t
Midrail
tr
tf
λr
vn
–τn
Noise causes 
waveform to 
transition τn
seconds early 
Equivalent phase perturbation
Φ=2π(τn/T0)
=(2π/T0)*(vn/λr)
(slope)
VIN
Noiseless
Noisy
TW
T0
INMOS
t
Figure 9.50: Phase noise can be estimate by sampling the voltage at the expected transition point
570
Oscillators

The symbol ∗denotes convolution and wr(t) and wf(t) are unity waveforms given by
wr tð Þ =
1,
0 
 x < TW
0,
otherwise

wf tð Þ =
1,
0 
 x < T0  TW
0,
otherwise

,
where TW is time between a rising and falling transition (i.e., TW/T0 is the duty cycle of the
waveform; see Figure 9.50). While presented as a theoretical construct, this estimate is
essentially the phase deviation perceived by subsequent circuits after the output of the oscillator
has passed through hard switching buffers. For simplicity, let’s assume the duty cycle is 50%
and the rise and falls times are equal (i.e., TW = T0/2, |λ| = |λr| = |λf|, and tf = tr  T0/2), which
gives an estimate of phase deviation as
ϕEST(t) = (ϕδr(t) + ϕδf(t)) ∗w(t),
or, in terms of sampled voltage,
ϕEST tð Þ = 2π
T0
1
λj j vδr tð Þ  vδf tð Þ

	
∗w tð Þ,
where
w tð Þ =
1,
0 
 x < T0=2
0,
otherwise

:
If the rising and falling edge voltages are uncorrelated (as is generally the case for the noise of a
buffer), the spectral density becomes
SϕEST ω
ð Þ 
Sϕδr ω
ð Þ + Sϕδf ω
ð Þ


sin ωT0
4

	
ω=2
 
!2
:
In a ring oscillator the noises associated with the rising and falling edges are strongly correlated
(i.e., vδf(t)   vδr(t  TOSC/2)), which implies the spectral density is closer to
SϕEST ω
ð Þ  4Sϕδ ω
ð Þ
sin ωT0
4

	
ω=2
 
!2
,
where Sϕδ(ω) is the spectral density of the phase noise sampled at either a rising or falling edge.
The reason rising and falling edges are correlated will become obvious in the next section.
Generally, we are concerned only with the low-frequency component of ω, which is responsible
for noise close to the carrier. Therefore, we can say that a reasonable estimate of phase noise is
related to the spectral density of ϕδ(t) as follows,
9.8 Ring Oscillators
571

ℒΔω
f
g  SϕEST Δω
ð
Þ  Sϕδ Δω
ð
ÞT2
0,
where Δω <<ωOSC. Alternatively, we can deﬁne phase noise in terms of the spectral density of
the sampled noise at the transition point, i.e.,
ℒΔω
f
g  4π2
λj j2 Svδ Δω
ð
Þ:
Again, this estimate can be measured at either a rising or falling edge, since, in the context of
ring oscillators, the noise on a rising and falling edge will be strongly correlated. In the case of
uncorrelated noise on the rising and falling edge noise, this equation would be approximately
given by
ℒΔω
f
g  π2
λj j2 Svδr Δω
ð
Þ + Svδf Δω
ð
Þ

	
:
9.8.3
Simple Ring Oscillator Noise Model
A ring oscillator can be viewed as a delay line with unity feedback, which enables a simpliﬁed
noise analysis [24]. Figure 9.51 models the inverter chain as a delay line, and models the total
noise of inverter chain as an additive noise source, vCHAIN(t). Given this setup, the noise voltage
of the oscillator is given by
vRING tð Þ =  vRING t  T0
2


+ vCHAIN tð Þ,
alternatively,
vRING tð Þ = vRING t  T0
ð
Þ + vCHAIN tð Þ  vCHAIN
t  T0
2


:
Delay Line
T0/2
Delay
–1
v(t)
–v(t–T0/2)
∑ 
vCHAIN(t)
Additive noise 
models noise 
of delay line
T0/2
Delay
–1
∑ 
vCHAIN(t)
Simple noise model
(valid at transition points)
vRING(t)
Figure 9.51: Simpliﬁed noise model of ring oscillator
572
Oscillators

This model is only valid around the transition points, where the delay line gain is –1. If we
sample the noise voltage at these transition points (i.e., a rising or falling edge), we may write
vδRING(r)(t) = vδRING(r)(t  T0) + vδCHAIN(r)(t)  vδCHAIN( f )(t)
vδRING( f )(t) = vδRING( f )(t  T0) + vδCHAIN( f )(t)  vδCHAIN(r)(t),
where
vδRING rð Þ tð Þ =
X
∞
n = ∞
vRING tð Þδ t  nT0
ð
Þ
vδRING f
ð Þ tð Þ =
X
∞
n = ∞
vRING tð Þδ t  T0
2  nT0


vδCHAIN rð Þ tð Þ =
X
∞
n = ∞
vCHAIN tð Þδ t  nT0
ð
Þ
vδCHAIN f
ð Þ tð Þ =
X
∞
n = ∞
vCHAIN tð Þδ t  T0
2  nT0


:
To simplify matters it is assumed that one of the rising edge transition points coincides with
t = 0. Moreover, we assume the rising and falling edge transition points are TOSC/2 seconds
apart (i.e., a 50% duty cycle).
In general, the noise due to the rising and falling edge of a delay line will be uncorrelated (for
instance, in a simple inverter the rising edge noise will be dominated by the PMOS, while the
falling edge will be dominated by the NMOS device). Therefore, in the frequency domain, the
spectral density of the voltage noise of the oscillator measured at either the rising or falling edge
is given by
Svδ RING
ð
Þ ω
ð Þ = Svδ CHAINr
ð
Þ ω
ð Þ + Svδ CHAINf
ð
Þ ω
ð Þ
1  ejωT0
j
j2
= Svδ CHAINr
ð
Þ ω
ð Þ + Svδ CHAINf
ð
Þ ω
ð Þ
1
4 sin2 ωT0
2


,
where Svδ(CHAINr) and Svδ(CHAINf ) are the spectral density of the noise voltage of the chain
sampled at the rising and falling edge, respectively. We are concerned only with components of
Svδ(RING) that lie close to harmonics, since it is only noise close to the harmonics that has the
ability to be frequency translated close to the carrier. Moreover, because of impulse sampling,
the noises around all the harmonics are identical, and so we need only look at the very low
frequency of Svδ(RING)(ω). Therefore, using the small angle approximation, we can write
Svδ OSC
ð
Þ Δω
ð
Þ  Svδ CHAINr
ð
Þ ω
ð Þ + Svδ CHAINf
ð
Þ ω
ð Þ

	 1
4π2
ωOSC
Δω

2
,
where Δω <<ωOSC. This expression can be used to generate an estimate of ℒ{Δω}, i.e.,
ℒΔω
f
g  1
λ


2
Svδ CHAINr
ð
Þ ω
ð Þ + Svδ CHAINf
ð
Þ ω
ð Þ

	 ωOSC
Δω

2
:
9.8 Ring Oscillators
573

In an N-stage inverter chain, the noise contribution of each inverter is typically independent,
and the spectral density of the time delay due to noise accumulates, and so
Svδ CHAINr
ð
Þ =
N + 1
2


Svδ INVr
ð
Þ +
N  1
2


Svδ INVf
ð
Þ
Svδ CHAINf
ð
Þ =
N  1
2


Svδ INVr
ð
Þ +
N + 1
2


Svδ INVf
ð
Þ,
where Svδ(INVr) and Svδ(INVf ) are the spectral densities of noise voltage sampled at rising and
falling edge of a single inverter, respectively. In keeping with our notation from the previous
section, N is the number of inverter stages, which is assumed to be odd and greater than 3.
Accordingly, the phase noise of the ring oscillator can be written as
ℒΔω
f
g  N
λj j2 Svδ INVr
ð
Þ Δω
ð
Þ + Svδ INVf
ð
Þ Δω
ð
Þ

	 ω0
Δω

2
:
Therefore, if we know the sampled spectral density of a single inverter, we can calculate a
closed form expression for the ring oscillator. Indeed, we can rewrite this expression directly in
terms of inverter phase noise as
ℒΔω
f
g  N
π2 ℒINV Δω
f
g ω0
Δω

2
,
where ℒINV{Δω} is the phase noise of a driven inverter assuming the same toggling frequency
as the ring oscillator, and the same rise and fall times. This is visualized in Figure 9.52.
9.8.4
Phase Noise of a Single Inverter
In practice, it is best to calculate the noise of an inverter (i.e., Svδ(INVr)(Δω), Svδ(INVf )(Δω) or
simply ℒINV{Δω}) through simulation. This is because the device used in the inverter
VDRIVEN
t
N-stage inverter chain
N-stage ring oscillator
Same period,
rise/fall time as 
equivalent 
oscillator
VCHAIN(t)
VRING(t)
Ring Oscillator
Phase Noise [dBc/Hz] 
Carrier Offset, Δω
Flicker noise 
corner
(N/π2)LINV{Δω}(ω0/Δω)2
N LINV{Δω}
Inverter Chain
Figure 9.52: Relationship between phase noise of inverter chain and a ring oscillator
574
Oscillators

transitions through many different regimes. Nevertheless, simpliﬁed models have been pro-
posed that are useful in guiding design and determining achievable performance. Notably, in
[23] the inverter noise is portioned into two sources. On the rising edge, the noise that
perturbs the zero-crossing is a combination of the PMOS noise being integrated onto the load
capacitor (see Figure 9.53), and kT/C noise due to the NMOS device that was in triode before
the switching event. Equally, on a falling edge, the noise is modeled as a combination of the
NMOS noise integrated onto the load capacitor, and the kT/C noise due to the PMOS device
that was in triode before the switching event. Following this approach it is possible
to generate closed form expressions for sampled voltage noise both on the rising and falling
edge. To simplify matters, however, we note that simulation suggests that the phase noise
of an inverter in the thermal noise region (with equal rise and fall times) is proportional to
kT/C, i.e.,
Svδ INVr
ð
Þ Δω
ð
Þ /
kT
CLOAD
1
T0
Svδ INVf
ð
Þ Δω
ð
Þ /
kT
CLOAD
1
T0
,
Noise current 
integrated 
onto capacitor
CLOAD
in(t)
|VTP|
VOUT
t
VDD/2
τd=τinv(r)
vn(t)
PMOS ON
NMOS OFF
VIN
PMOS noise 
current changes 
transition time
Noiseless
Noisy
Midrail
λr
vn
(slope)
Figure 9.53: Phase noise model of inverter. For simplicity, input is assumed to switch instantaneously, and
charging current is from device in saturation
9.8 Ring Oscillators
575

where T0 is the period of the toggling frequency. Simulation suggests that the proportional
constant is close to 4 over a wide range of operating conditions. In the preceding section, we
found that the phase noise of an N-stage ring oscillator is
ℒΔω
f
g  N
λj j2 Svδ iINVr
ð
Þ Δω
ð
Þ + Svδ INVf
ð
Þ Δω
ð
Þ

	 ω0
Δω

2
:
Substituting in the approximations for Svδ(iINV  r)(Δω) and Svδ(iINV  f )(Δω), and making the
simplifying assumptions that To = 1/fo = 2NCLOADVDD/IDD and λ = IDD/CLOAD = 2NVDD/T0,
this expression becomes
ℒΔω
f
g 
4kT
VDDIDD
ω0
Δω

2
:
Therefore, the only way to improve the phase noise performance of a ring oscillator is to
increase its power consumption either through increasing IDD by increasing the device size, or
raising VDD. A more sophisticated analysis [23] shows some dependence on the threshold
device |Vth|,
ℒΔω
f
g  2kT
IDD
2γ
VDD  Vth
j
j +
1
VDD

 ω0
Δω

2
,
which suggests subthreshold operation should be avoided. In practice, the performance of ring
oscillators close to subthreshold does not degrade as rapidly as the equation suggests (owing to
the breakdown of the square law model used in derivation).
9.8.5
Ring Oscillator and LC Oscillator Comparison
In order to draw a comparison between the achievable performance of a ring oscillator and an
LC oscillator, we return to the concept of ﬁgure of merit (FOM), which is normalized phase
noise per unit power. In the case of a ring oscillator where VDD  |Vth| this is calculated as
FOM =
ω0
Δω

	2
PDC=1mW
ð
Þ ℒΔω
f
g  103
4kT :
Therefore the ratio of FOM of an LC oscillator and a ring oscillator (when measured in the
thermal region) is given by approximately
FOMLC
FOMRING

ηQ2
F


8:
Assuming a well-design LC oscillator with a F = 2 and η = 1/2, this expression becomes
FOMLC
FOMRING
 2Q2:
This is quite a dramatic difference. For instance, in this example, a ring oscillator would need to
burn 200 times more power to achieve the same phase noise performance as a well-designed LC
576
Oscillators

oscillator with a Q of 10. (Published results show an upper-limit FOM for ring oscillators of
167dB, while an LC VCO with an FOM in excess of 190dB is not uncommon.) Moreover, the
ﬂicker noise corner of a ring oscillator is typically much larger than a well-designed LC
oscillator. For these reasons, LC oscillators are favored in RF-front ends.
The poor noise performance of a ring oscillator compared to an LC oscillator can be traced to the
time reference inherent in each circuit [25]. In the ring oscillator, the time constant is related to the
time required for a device current to charge (or discharge) a capacitor (i.e., T / I/C). At tempera-
tures above 0 kelvin, a nonzero amount of thermal noise will be associated with such a current, and
so I/C is an inherently noisy time reference. By contrast, in an LC oscillator the time reference is
related to the inductor and capacitor size, i.e., T /
ﬃﬃﬃﬃﬃﬃ
LC
p
. An ideal LC tank has no associated
thermal noise and so is a noiseless time reference. In other words, any noise in the system is a
parasitic effect and not fundamental to the time reference. Q is a measure of the parasitic loss of an
LC tank, and so increasing Q naturally improves an LC oscillator’s performance.
9.9
QUADRATURE OSCILLATORS
..............................................................................................
In previous chapters we have shown that most practical transceivers rely on quadrature LO
signals for downconversion as well as upconversion. We also showed in Chapter 4 two different
methods of quadrature LO generation, one based on the divider, and the other based on polyphase
ﬁltering. There is yet another mechanism that relies on quadrature LC VCOs. As we will show
shortly, there are several drawbacks with this latter scheme that makes them somewhat uncom-
mon in GHz RF applications. Nevertheless, we shall have a brief qualitative glance on quadrature
oscillators (QOSC) in this section, and explain the reasons behind their unpopularity.
The conventional QOSC consists of two cross-coupled LC oscillator cores with an inversion
in the feedback path (Figure 9.54). The two cores are ideally identical, and mutually locked to a
common frequency.
While a linear model may describe the oscillator performance, we choose to use a more
realistic model based on hard-limiting transconductors, as shown in Figure 9.55. The latter
Q+
Q–
I
IC
I–
I+
I+
I–
I
IC
Q+
Q–
Figure 9.54: Generic quadrature oscillator
9.9 Quadrature Oscillators
577

approach proves to be more accurate, and predicts the oscillation amplitude properly. It also
anticipates all possible modes of oscillation, and their stability. We assume that the QOSC is
designed differentially and the oscillation amplitude is large enough to completely steer the tail
current from one side to the other.
As shown in Figure 9.55, two arbitrary phase-shifters ϕ are also inserted in the two coupling
paths prior to the coupling transconductors. For the conventional QOSC that does not have these
phase-shifters, ϕ is zero. The transconductors commutate their corresponding currents at the zero-
crossings of their input voltages. Filtering in the LC circuit attenuates all higher order harmonics of
currents leading to a quasi-sinusoidal tank voltage. Therefore, we need to consider only fundamen-
tal components of the transconductor output currents. The LC tank resonance frequency is ω0, and
magnitude and phase of its impedance versus frequency are also shown in the ﬁgure.
Two coupled oscillator cores are locked and oscillate at a common frequency ωosc, which can
be different from ω0. V1, and V2 are phasors of oscillator outputs, and without loss of the
generality we may assume V2 lags V1 by an unknown angle ψ. Output currents of the
transconductors, I1, I2, IC1, and IC2 are depicted accordingly. The voltage of the ﬁrst tank, V1,
is obtained by summing the current I1 and IC1 and multiplying that by the tank impedance
whose phase and magnitude is shown in Figure 9.55. Similarly, V2 is obtained by summing the
corresponding current, and passing through the tank.
9.9.1
Modes of Oscillation
Performing a vector analysis we can obtain four possible modes of oscillations [26], [27].
Speciﬁcally, we can show jI1 j = j I2 j = I, and jIC1 j = j IC2 j = IC which is expected from the
symmetry of the circuit. The four solutions are summarized as follows:
f
f
–1
|Z(jw)|
w
w
wosc
w0
ÐZ(jw)
q
V1
I1
IC2
I2
V2
IC1
Figure 9.55: Quadrature oscillator model
578
Oscillators

1. ψ = + π
2, and ωosc > ω0.
2. ψ =  π
2, and ωosc < ω0.
3. ψ >  π
2, and ωosc < ω0.
4. ψ <  π
2, and ωosc < ω0.
The ﬁrst and second modes are quadrature with identical oscillation amplitudes in the two
cores. However, the quadrature sequences of these two modes are the opposite. The third and
fourth modes are nonquadrature with different oscillation amplitudes in each of the two cores.
Using the perturbation analysis method [27], it can be shown that the third and fourth modes
of oscillation are unconditionally unstable. Furthermore, the second mode is stable only for
ϕ < sin1(IC/I), which is the case for most practical realizations of the quadrature oscillator, as
ϕ, is typically equal to zero. If, however, one can insert a phase shift large enough to break the
condition ϕ < sin1(IC/I), the second mode will be ruled out. However, creating a phase shift,
say by using an RC circuit, proves to be a challenge. A small resistor loads the tank, while a
large resistor adds noise. For that reason, most practical realizations of the quadrature oscillator
do not include any phase shift, and both modes may exist. This could become a major problem,
as image rejection mixers would dangerously suffer from the existent ambiguity in the sequence
of quadrature signals.
It is worth pointing out that the ﬁrst mode has higher amplitude than the second one.
This emphasizes the tendency of this mode to prevail even if the second mode is stable. The
reason for this has to do with the series resistor of the inductor, which makes the tank
frequency response somewhat asymmetric around ω0 (Figure 9.55). Thus, the ﬁrst mode
may predominate during the start-up process, although this is not guaranteed for any given
design.
Considering only the ﬁrst mode with ϕ = 0, from Figure 9.55 it can be easily shown that
tan θ = IC
I :
Using the LC tank equation, the oscillation frequency is readily obtained:
ωosc ﬃω0 + ω0
2Q
IC
I :
Evidently, the frequency of oscillation is generally a function of the coupling ratio m = IC
I . In
fact, m can be utilized as a means to control the oscillation frequency. Applying KCL on the V1
node leads to
V
1
RP
+ j Cωosc 
1
Lωosc




= 4
π I + ICe jπ
2

	
:
Separating the real and imaginary parts results in the amplitude of oscillation as follows,
V = 4
π RPI,
where RP is the tank resistor, and I is the core bias current.
9.9 Quadrature Oscillators
579

9.9.2
Quadrature Accuracy Due to Mismatches
If the two oscillator cores perfectly match, their output phases are in precise quadrature.
However, mismatches between the two cores would cause the outputs to depart from quadra-
ture. In the following section, we study quadrature inaccuracy caused by mismatches in
resonance frequencies of the two tanks. A more complete analysis including other sources of
mismatch may be found in [26].
Let us assume that the two tanks have different resonance frequencies, ω01 and ω02. It is also
assumed that the mismatch is small enough such that both cores oscillate at a common
frequency ωosc. Deﬁning the phase deviation of Δψ from quadrature, either geometrically or
algebraically, it can be shown that
Δψ
Δθ = 1 + m2 + 2m sin ϕ
2m m + sin ϕ
ð
Þ ,
where m = IC
I is the coupling factor. Furthermore, by making use of impedance equation of the
LC tank, Δθ is found in terms of the mismatch Δω = ω01  ω02:
Δθ
Δω ﬃ 2Q
ω0
:
From Figure 9.55, θ is the phase of each tank at the frequency of oscillation. Given the tanks are
assumed to have different center frequencies, we expect different values of θ for each, as shown
above. Thus, the resulting quadrature error is obtained as
Δψ ﬃQ 1 + m2 + 2m sin ϕ
m m + sin ϕ
ð
Þ
Δω
ω0
:
It is instructive to compare the resilience of two extreme cases against the mismatch Δω
between the two tank resonance frequencies. If there is no phase-shifter ϕ = 0, which is the
case for most designs, the quadrature error reduces into Δψ =  Q 1 + 1
m2

	
Δω
ω0


. Since the
coupling factor m is typically a small number usually between 0.1 and 0.4, the phase inaccuracy
due to the mismatch between the tank center frequencies could be quite substantial. A phase
shifter helps improve the dependence to 1 + 1/m but has implementation issues, as pointed out.
Also, the deviation is proportional to the quality factor Q. This is intuitively expected, as
higher Q results in a steeper phase variation of the tank impedance.
9.9.3
Phase Noise Analysis
In this section we present a qualitative description of QOSC white phase noise. The ﬂicker
noise analysis and more details on the derivations may be found in [27].
In the noise analysis of a classical LC oscillator it was proven that the noise factor F of the
oscillator due to thermal noise sources is 1 + γ. This minimum noise factor happens when the
thermal noise of the tail current source is ﬁltered out and does not contribute to the phase noise.
580
Oscillators

If a similar phase noise analysis is performed on the quadrature oscillator, the oscillator phase
noise is found to be
ℒΔω
f
g = kTFRP
2A2
1
Q2
ω0
Δω

2
,
where F is given by
F = 1 +
m cos ϕ
1 + m sin ϕ

2
+
γ
1 + m sin ϕ
1 + m
m + sin ϕ
1 + m sin ϕ

2
 
!
:
For a more common case of no phase shift,
F = 1 + m2 + γ(1 + m3).
The ﬁrst term reﬂects the contribution of the tank loss on the phase noise, while the second term
predicts that of the switches in the coupling and regenerative transconductors. Also, as
the coupling factor m approaches zero, F converges to 1 + γ. Assuming m is small, phase noise
of the QOSC is 3dB lower compared to the corresponding standalone LC oscillator. Since
the power consumption is also doubled, the FOM remains intact. In fact, the ratio of FOM
of the QOSC FOMQOSC to that of the corresponding standalone LC oscillator FOMcore is
found to be
FOMQOSC
FOMcore
=
1 + γ
1 + m
ð
Þ 1 + m2 + 1 + m3
ð
Þγ
½
 
1
1 + m ,
where in the above derivation the current of the standalone oscillator is adjusted to have the
same amplitude as that of the QOSC. Thus, the FOM of a QOSC cannot be better than its
standalone core oscillator. Only if the coupling is weak (small m), the QOSC approaches to
have a similar phase noise performance (for the same total current), as a single VCO.
Given the quadrature ambiguity, relatively large quadrature inaccuracy due to mismatches, a
bigger area, as well as a somewhat worse phase noise in the quadrature oscillators, they are not
very commonly used. Furthermore, the use of a divide by two reduces the transmitter sensitivity
to pulling, as we disused in Chapter 6, which makes them a more attractive means of providing
IQ LO signals, despite running the VCO at twice the frequency of the carrier.
9.10 CRYSTAL AND FBAR OSCILLATORS
..............................................................................................
A crystal oscillator (XO) is a critical component of every RF system, providing the reference
clock to various key building blocks, such as the frequency synthesizer, data converters,
calibration circuits, baseband, and peripheral devices (Figure 9.56).
The reason why one employs a piezoelectric crystal resonator in place of an LC tank is that
the crystal quality factor is substantially higher (several thousand or more), which directly leads
to much better frequency stability. Hence crystal oscillators are used as ﬁxed-frequency, highly
stable references for frequency or timing.
9.10 Crystal and FBAR Oscillators
581

9.10.1 Crystal Model
To facilitate the derivation of the crystal oscillator principles, we ﬁrst discuss the crystal
electrical model. The main material used as a mechanical resonator for oscillator is the
crystalline quartz. The property of this material differs in different directions, and in addition,
each different cut may be mounted and vibrated in several different ways. The crystal is
commonly modeled as several parallel RLC circuits, in addition to a ﬁxed shunt capacitance,
C0, as shown in Figure 9.57. As frequency of oscillation is normally very close to the series
resonance of only one branch, the model is simpliﬁed to only that branch, in parallel with C0, as
shown on the right. The multiple branches are a result of mechanical vibrations at approxi-
mately odd harmonics, commonly known as overtones.
Since the mechanical frequency of the fundamental vibration is proportional to the crystal
dimensions, practical considerations limit the crystal frequency to tens of MHz. By operating
on an overtone, a higher frequency is possible (usually the third overtone), although overtone
crystal oscillators are not very common. This is mainly due to the fact that the crystal does not
want to resonate on its overtone frequency voluntarily, and the oscillator circuit needs to force
the correct overtone, which creates some overhead, and possibly performance degradation. The
most common type of overtone crystal oscillators employ an LC resonance tank tuned to the
overtone frequency such that the positive feedback dies out at the main crystal frequency, while
remaining effective at the overtone frequency. An example of a practical overtone crystal
oscillator will be discussed at the end of this section.
PLL
Reference
ADC
XO
Crystal
Figure 9.56: Crystal oscillator providing
reference clock to many radio blocks
… 
C0
r
L
C
C0
Figure 9.57: Crystal
electrical model
582
Oscillators

The quality factor of crystal, determined by the equivalent series resistor (ESR), is several or
tens of thousands. The series branch components consisting of r, L, and C are known as motion
components, while C0 is the total parallel capacitor resulted from mounting. The crystal is
intended to produce the exact frequency of oscillation speciﬁed when loaded properly with a
certain total parallel capacitance. For instance, for a commercially available 8pF 26MHz
crystal, the following values are commonly speciﬁed: C0 = 1pF, C = 3.641fF, L =
10.296mH, and r = 26Ω. The crystal produces exactly 26MHz when loaded by a total shunt
capacitance of 8pF. As typically the value of the inherent parallel capacitors C0 is less than that,
it is common to load the crystal with extra capacitance, preferably tunable, to obtain the exact
desired frequency (Figure 9.58). The corresponding crystal quality factor is over 64000.
The total shunt capacitance is now C0 +
C1C2
C1 + C2, which must be 8pF. C1 and C2 may
include the oscillator and other related parasitic.
The motion capacitance, C, is much smaller than C0, a property that results in crystal
stability, as we shall discuss shortly. For simplicity, we assume C0 consists of the total shunt
capacitance (that is, C1 and C2 are included).
The total admittance is
Y sð Þ = sC0
s2 + r
L s +
1 + C
C0


ω0
2
s2 + r
L s + ω0
2
,
where ω0 =
1ﬃﬃﬃﬃﬃ
LC
p
, and the quality factor is Q = Lω0
r . Since C  C0, we expect the poles and zeros
of Y(s) to be very close to each other, as shown in Figure 9.59.
There are two modes of operation where the crystal oscillator is built upon accordingly:
– Series: Crystal behaves as a low impedance element, and resonates near the pole of Y(s).
Crystal is typically placed in the feedback path directly, for instance to shunt a large resistor
which will otherwise prevent the oscillation.
C2
C
L
r
C
1
C0
Figure 9.58: Properly loaded crystal
9.10 Crystal and FBAR Oscillators
583

– Parallel: Crystal exhibits a high impedance, and resonates near the zero of Y(s). Thus, the
crystal behaves as a large shunt inductance that is resonating with the circuit capacitances.
Most common practical crystal oscillators rely on the parallel resonance, and thus we shall
focus mostly on the parallel mode.
To understand the reason for crystal oscillator stability, consider the parallel resonance as an
example, and suppose the total shunt capacitance varies from C0 ! C0 + ΔC0. This can be
caused by temperature or process variations in the oscillator, or inaccurate modeling of the
capacitances. The oscillation frequency, which is near the zero of Y(s) (see Figure 9.59), then
shifts by
Δω 
C
2 C0 + ΔC0
ð
Þ  C
2C0


ω0   C
2C0
ω0 	 ΔC0
C0
:
Thus, as the frequency of oscillation is roughly
1 +
C
2C0


ω0, the crystal sensitivity is
S 
Δω
ω0
ΔC0
C0


= C
2C0
:
Since C  C0, the frequency variation as a result of oscillator process variations is small. For
instance, for the values presented earlier for a 26MHz crystal, 10% variation of the total shunt
capacitance leads to only 22.75ppm variation in frequency. This in fact is exploited to tune the
crystal frequency in the presence of circuit variations or aging to a given desired accuracy. We
shall discuss this more shortly.
Intuitively, given our discussion of LC oscillators previously, we expect a substantially
higher stability of the oscillation frequency thanks to a much larger resonator quality factor.
9.10.2 Practical Crystal Oscillators
Apart from frequency stability, a crystal oscillator must satisfy several other exacting require-
ments. It must have low phase noise in order not to degrade the receive SNR or transmit EVM.
C0
r
L
C
w0
≈w0×C/2C0
w0/2Q
Figure 9.59: Crystal poles
and zeros
584
Oscillators

For supplying clocks to external peripheral devices, the phase noise requirements are even
more stringent. For instance for the WLAN IEEE 802.11n 5GHz band, the required phase
noise is around –145dBc/Hz at a 10kHz frequency offset relative to 26MHz, a commonly
used crystal for handsets. The oscillator must also be very low power, as it is the only block
that remains on while the system is idle. Moreover, in many applications, such as those for
cellular phones, the crystal oscillator must have a wide tuning capability to cover crystal and
circuit variations.
A well-designed crystal oscillator must stop oscillating if the crystal is removed, and should
minimize the crystal driving current and voltage. The latter is to avoid physical damage caused
by overdriving, and to minimize self-heating. This is typically accomplished by proper circuit
design, and often by employing some kind of amplitude control loop to avoid crystal
overdriving.
An example of a series-mode crystal oscillator is shown in Figure 9.60. It is based on a
Colpitts oscillator topology (Section 9.4.3), except for the crystal is placed in the feedback path.
As a result, the positive feedback is only enforced around the zero of the crystal impedance (or
the pole of Y(s)). The drain LC tank is tuned around the intended oscillation frequency.
Two examples of parallel-mode crystal oscillators are shown in Figure 9.61 (bias details not
shown). In both cases the crystal behaves like a series RL circuit, and the drain inductors are
simply placed for biasing purposes.
A more practical version of the Pierce XO is shown in Figure 9.62, which is based on a
complementary structure (simply a self-biased inverter) to avoid the biasing inductor. When the
inverter is sized properly, it results in a stable and robust design, and for that reason this
structure is commonly adopted in many radios today. The capacitor arrays are added for tuning
purposes (see the next section).
An example of an overtone Pierce crystal oscillator is shown in Figure 9.63. To understand
the operation of the oscillator, we ﬁrst note that in the fundamental oscillator on the left, the
inverter creates 180 of phase shift, and that along with the combination of the crystal and the
capacitors (C1 and C2) give a total phase shift of 360, establishing the intended positive
feedback at the frequency of the interest. Now, compared to the fundamental oscillator, in the
C
C
Figure 9.60: Series-mode crystal oscillator
9.10 Crystal and FBAR Oscillators
585

Pierce XO
Miller XO
Figure 9.61: Parallel-mode crystal
oscillator examples
Cap Array
Cap Array
Tuning
|Y(jw)|
w
Praccal Pierce XO
Crystal Pole-Zero
p
zz
Parallel
Resonance
Figure 9.62: Practical Pierce crystal oscillator
Fundamental Pierce XO
3rd Overtone Pierce XO
C1
C2
C1
C2
L
Figure 9.63: A fundamental and an overtone Pierce crystal oscillator
586
Oscillators

overtone oscillator the inductor L has been added in parallel to C2, such that the impedance of
the parallel L–C2 is inductive at the fundamental frequency, but remains capacitive at the
overtone frequency. The inductive impedance prevents the oscillation at the fundamental
frequency, as the desired 360 will not be established. See also Problems 18 and 19 for a more
analytical justiﬁcation.
Alternatively, one could add a highpass ﬁlter at the output of the active circuit to reduce the
loop gain at the fundamental frequency, effectively starving the gain of the oscillator at that
frequency.
Apart from the need for additional hardware, there are several other disadvantages associated
with the overtone crystal oscillators. The overtone series resistance is typically higher, leading
to a worse Q, and a higher power consumption in the active circuitry to establish the required
loop gain. Also the motion capacitance is smaller (nine times less in a 3rd overtone oscillator,
for instance), which makes the tuning or calibration harder (see the next section for tuning
requirements). On the other hand, as fundamental crystals over tens of MHz are not common
(the thickness of the crystal which is inversely proportional to its frequency becomes too small
to handle properly in volume production), the overtone oscillators are a viable solution to
extend the frequency.
9.10.3 Tuning Requirements
Cellular standards require that the average frequency deviation of the transmitted carrier from
handsets to be better than 0.1ppm with respect to the receiving carrier frequency in base
stations. To achieve such stringent accuracy, an automatic frequency control (AFC) loop in
the handset is employed to synchronize the handset crystal oscillator with the base station. The
handset generates the corresponding digital codes based on the frequency difference to vary the
digitally controlled crystal oscillator (DCXO) frequency until the desired oscillation frequency
is achieved. In practice, after taking into account the crystal and DCXO variations as well as
AFC loop imperfection, the frequency deviation must be much smaller than 0.1 ppm, which
poses a design challenge for the DCXO tuning circuitry.
The tuning is typically achieved in two steps: a coarse calibration for a one-time frequency
correction at the factory, and a ﬁne calibration for time-varying frequency errors in the phone. The
coarse calibration covers the crystal frequency toleranceof 10ppm due to crystal process and part-
to-part variations, and the DCXO circuit process variations. The remaining residual errors due to
aging, temperature variations, and voltage drift are corrected through the ﬁne calibration continu-
ously running as a part of an AFC loop in the transceiver. To ensure that little of the total frequency
budget of 0.1ppm is consumed, a fairly wide range with a resolution of better than 0.01ppm (about
one-tenth of the speciﬁcation) is targeted. Moreover, achieving a small frequency error required for
proper AFC operation mandates monotonic tuning characteristics.
These requirement are typically satisﬁed by incorporating switchable array of capacitances
with ﬁne resolution (Figure 9.62), properly laid out to ensure monotonicity and the required
accuracy [28]. An alternative approach is to use a varactor driven by a high-resolution DAC.
This may not be as desirable, however. Although this approach makes the capacitor array
design easier, as the varactor inevitably requires a large gain to cover the range, it makes the
9.10 Crystal and FBAR Oscillators
587

oscillator very sensitive to supply pushing and control-voltage noise. In actual implementations,
this condition might lead to a much larger frequency error. Moreover, for other sensitive
circuits, the DAC noise and clock harmonics become problematic.
9.10.4 FBAR Oscillators
In Chapter 4 we presented the circuit model of an FBAR resonator, which was very similar to
the crystal electrical model discussed in Figure 9.57. As such, we expect to see large similarity
between the crystal and FBAR oscillators, with the main difference being the frequency of
operation. Shown in Figure 9.64 is an example of a Pierce FBAR oscillator operating at 2GHz
[29]. The P transistor Mr is in the triode region and self-biases the core device M1. M2 is an
open-drain buffer for testing purposes, and could be replaced by an on-chip self-biased inverter
for on-chip distribution. Otherwise the oscillator operates very similarly to the parallel reson-
ance Pierce crystal oscillator shown in Figure 9.61.
The oscillator dissipates 25μW at 2GHz (using a forward-bias substrate technique explained
in [29]), and has an excellent ﬁgure of merit of over 220dB at 100kHz offset.
While FBAR resonators operate at much higher frequencies than the crystal, their tempera-
ture drift is substantially worse. They also have generally lower quality factors. More examples
of FBAR oscillators can be found in [30], [31].
9.11 Summary
This chapter covered various oscillators and VCOs topologies, and presented a detailed and
rigorous discussion of the oscillator phase noise.
– In Section 9.1 a linear feedback model of the oscillators was presented.
– A more realistic and practical nonlinear model of the oscillators was presented in Section 9.2.
Bias
Open-Drain Buffer
M1
M2
Mr
FBAR
C1
C2
VDD
Figure 9.64: A low-power 2GHz
FBAR oscillator
588
Oscillators

– Oscillator phase noise analysis based on the nonlinear feedback model was discussed in
Section 9.3. Cyclostationary noise as well as AM and PM noise were covered in this section
as well.
– Various commonly used LC oscillator topologies such as NMOS, CMOS, and Colpitts
oscillators were discussed in Section 9.4. A general design and optimization methodology
was presented as well. More VCO topologies were discussed in Section 9.7.
– LC tank Q degradation due to oscillator nonlinearity was discussed in Section 9.5.
– Frequency modulation effects due to the tank nonlinearities were discussed in Section 9.6.
– Section 9.8 discussed the design and phase noise properties of ring oscillators.
– Quadrature oscillators were covered in Section 9.9.
– Section 9.10 presented an overview of crystal and FBAR oscillators.
9.12 Problems
1. Prove that the linear oscillator shown in Figure 9.1 can be redrawn in the form
of a linear feedback system (also shown in Figure 9.1). Derive the resultant transfer
function H(s).
2. Prove that the amplitude of oscillation in a noiseless linear LC oscillator is equal to qSU/Cp if
the startup current is an impulse deﬁned as iSU(t) = qSUδ(t). Assume the circuit is marginally
stable. Hint: Use the initial value theorem, f t = 0 +
ð
Þ = lim s!∞sF sð Þ.
3. Given the generic negative-gm topology shown below, which active element will ensure
start-up? Which active element can never sustain an oscillation? Which element could
sustain an oscillation, but would require some separate startup mechanism? Suggest such
a mechanism.
Lp
Cp
Rp=100Ω
vout(t)
gnr(t)
inr(t)
Case 2
V
I
2V
–2V
16mA
–16mA
Case 1
V
I
2V
–2V
20mA
–20mA
Case 3
V
I
3V
30mA
–30mA
1
4. Given the generic negative-gm shown below, what is the expected voltage spectral density
noise around the carrier of the oscillator for the two of the active elements shown? Assume
the noise injected by each active element is proportional to its instantaneous conductance.
Further, assume the oscillator has started up. Hint: Use Bank’s general result.
Answer: SV Δω
ð
Þ = A2
4 ℒΔω
f
g = θωkT 1 + α
ð
ÞRp
4
1
Q2
ω0
Δω

2
.
9.12 Problems
589

Lp
Cp
Rp=100Ω
vout(t)
gnr(t)
inr(t)
Case 2
V
I
1V
–1V
12mA
–12mA
Case 1
V
I
–2V
4mA
5. Prove that in limit as the active element of the negative-gm LC oscillator becomes linear,
amplitude and phase noise will be equal in magnitude, i.e., *ϕ Δω
f
g = *M Δω
f
g.
6. In regard to Figure 9.20, prove that the optimum arrangement is to connect the input and
output terminals of the negative transconductance to vout(t).
7. Derive the noise factor for the Hartley oscillator shown below. Assume the transistor never
operates in the triode region. Hint: For simplicity you may assume both resonators have the
same Q. Use the narrowband transformer approximation introduced in Chapter 3.
ids(t)
vout(t)
Cp
L2
L1
R2
R1
8. Derive the noise factor for the standard topology shown below where the current source has
been replaced by a simple resistor. What are the advantages of this topology? What are the
disadvantages? Answer: F = 1 + γ +
Rp
4RBIAS
.
Rp/2
Lp/2
Rp/2
Lp/2
2Cp
2Cp
RBIAS
inr(t)
vout(t)
IBIAS
590
Oscillators

9. For a set bias current and inductor size, which is a better choice of topology: the standard
NMOS topology or the standard CMOS topology? Assume the current is low enough that
both operate in the current-limited regime (i.e., the current source doesn’t enter the triode
region).
10. The Colpitts oscillator can provide a noise factor arbitrarily close to 1. Under what limiting
condition is this possible? And explain why it is generally not a good idea to design at this
point. (Hint: Think in terms of power efﬁciency.) Derive an expression for the FOM of a
Colpitts oscillator.
11. Show that the oscillator tuning can expressed in terms of tank maximum and minimum
capacitance as follows:
TR = 2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
CMAX
CMIN
r
 1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
CMAX
CMIN
r
+ 1
:
12. Derive the maximum amplitude of the class C topology that will ensure startup, but will not
drive the differential pair transistors into triode. If startup is ensured through some other
means, what is the maximum amplitude? Hint: Both answers are a function of the DC
gate bias.
13. It is often stated that amplitude noise is of little concern because it will be stripped out by
any subsequent hard-switching circuit (e.g., a hard-limiting buffer or mixing). Under what
conditions might a circuit designer be concerned about amplitude noise?
14. Assuming a near sinusoidal tank voltage, show that
Ceff =
Þ
iCdvC
πA2ω0
:
15. Prove that square wave injection of bias current can result in a maximum power efﬁciency
of η = 2/π, while impulse-injection can result in a maximum power efﬁciency of η = 1.
16. Design an NMOS LC VCO intended for cellular transmitter applications. The VCO must
cover a range of 3GHz to 4GHz, and have a phase noise of better than –152dBc/Hz at
20MHz offset. Assume the supply is 1.2V, and the tank Q is 10. Ignore 1/f noise, and
assume γ = 1. Also assume the current source has an overdrive voltage of 200mV.
17. Repeat the previous problem for a CMOS topology, assuming identical N and P transistors.
18. In the two circuits shown below, the transistor is in saturation (bias details are not shown).
Ignore ro and the internal capacitances of the FET.
a. Find the impedances (Z1 and Z2) looking into the nodes 1-10.
b. If a crystal is connected to the nodes 1-10, which circuit is capable of potentially
oscillating?
Answer: Z1 =
1
jC1ω +
1
jC2ω 
gm
C1C2ω2 and Z2 =
1
jC1ω + jL2ω + gmL2
C1
.
9.12 Problems
591

C1
C2
Z1
1
1¢
C1
L2
Z2
1
1¢
19. The simpliﬁed AC model of a Pierce crystal oscillator is shown below, where the crystal in
parallel resonance is approximated by a series RL circuit (r and L in the ﬁgure).
a. Using the ﬁndings of the previous problem, determine the required transistor gm such
that the circuit is on the verge of oscillating.
b. What is the frequency of oscillation?
c. By tracing the transistor input voltage (vgs) through the feedback loop, argue how the
360 phase shift needed for oscillation is established.
9.13 References
[1] D. Leeson, “A Simple Model of Feedback Oscillator Noise Spectrum,” Proceedings of the IEEE, 54, no.
2, 329–330, 1966.
[2] A. Mazzanti and P. Andreani, “Class-C Harmonic CMOS VCOs, with a General Result on Phase Noise,”
IEEE Journal of Solid-State Circuits, 43, no. 12, 2716–2729, 2008.
[3] P. Kinget, “Integrated GHz Voltage Controlled Oscillators,” in Analog Circuit Design, Kluwer, 1999,
353–381.
[4] M. Garampazzi, S. D. Toso, A. Liscidini, D. Manstretta, P. Mendez, L. Romanò, and R. Castello, “An
Intuitive Analysis of Phase Noise Fundamental Limits Suitable for Benchmarking LC Oscillators,” IEEE
Journal of Solid-State Circuits, 49, no. 3, 635–645, 2014.
[5] C. Samori, A. L. Lacaita, F. Villa, and F. Zappa, “Spectrum Folding and Phase Noise in LC Tuned
Oscillators,” IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Process, 45, no. 7,
781–790, 1998.
C1
C2
Crystal in Parallel Resonance
r
L
+
vgs
–
gmvgs
592
Oscillators

[6] D. Murphy, J. Rael, and A. Abidi, “Phase Noise in LC Oscillators: A Phasor-Based Analysis of a General
Result and of Loaded Q,” IEEE Transactions on Circuits and Systems I: Fundamental Theory and
Application, 57, no. 6, 1187–1203, 2010.
[7] W. P. Robins, Phase Noise in Signal Sources: Theory and Applications, Institution of Electrical
Engineers, 1984.
[8] J. J. Rael and A. A. Abidi, “Physical Processes of Phase Noise in Differential LC Oscillators,” in IEEE
Custom Integrated Circuits Conference (CICC), 2000.
[9] E. Hegazi, J. J. Rael, and A. A. Abidi, The Designer’s Guide to High-Purity Oscillators, Springer, 2004.
[10] J. Phillips and K. Kundert, “Noise in Mixers, Oscillators, Samplers, and Logic: An Introduction to
Cyclostationary Noise,” in IEEE Custom Integrated Circuits Conference (CICC), 2000.
[11] J. Bank, A Harmonic-Oscillator Design Methodology Based on Describing Functions, Chalmers
University of Technology, 2006.
[12] A. Mazzanti and A. Bevilacqua, “On the Phase Noise Performance of Transformer-Based CMOS
Differential-Pair Harmonic Oscillators,” IEEE Transactions on Circuits and Systems I: Regular Papers,
62, no. 9, 2334–2341, 2015.
[13] M. Babaie and R. B. Staszewski, “An Ultra-Low Phase Noise Class-F 2 CMOS Oscillator with 191 dBc/
Hz FoM and Long-Term Reliability,” IEEE Journal of Solid-State Circuits, vol. 50, no. 3, 679–692, 2015.
[14] M. Babaie, A. Visweswaran, Z. He, and R. B. Staszewski, “Ultra-Low Phase Noise 7.2–8.7 Ghz Clip-and-
Restore Oscillator with 191 dBc/Hz FoM,” in Proceedings of the IEEE Radio Frequency Integrated
Circuits Symposium (RFIC), 2013.
[15] M. Shahmohammadi, M. Babaie, and R. B. Staszewski, “A 1/f Noise Upconversion Reduction Technique
for Voltage-Biased RF CMOS Oscillators,” IEEE Journal of Solid-State Circuits, 51, no. 11, 2610–2624,
2016.
[16] L. Fanori and P. Andreani, “Class-D CMOS Oscillators,” IEEE Journal of Solid-State Circuits, 48, no. 12,
3105–3119, 2013.
[17] P. Andreani and A. Fard, “More on the 1/f 2 Phase Noise Performance of CMOS Differential-Pair LC-
Tank Oscillators,” IEEE Journal of Solid-State Circuits, 41, no. 12, 2703–2712, 2006.
[18] P. Andreani, X. Wang, L. Vandi, and A. Fard, “A Study of Phase Noise in Colpitts and LC-Tank CMOS
Oscillators,” IEEE Journal of Solid-State Circuits, 40, no. 5, 1107–1118, 2005.
[19] E. Hegazi and A. A. Abidi, “Varactor Characteristics, Oscillator Tuning Curves, and AM-FM
Conversion,” IEEE Journal of Solid-State Circuits, 36, no. 12, 1033–1039, June 2003.
[20] A. Kral, F. Behbahani, and A. Abidi, “RF-CMOS Oscillators with Switched Tuning,” in IEEE Custom
Integrated Circuits Conference (CICC), 1998.
[21] J. Groszkowski, “The Interdependence of Frequency Variation and Harmonic Content, and the Problem of
Constant-Frequency Oscillators,” Proceedings of the Institute of Radio Engineers, 21, no. 7, 958–981,
1933.
[22] E. Hegazi, H. Sjoland, and A. A. Abidi, “A Filtering Technique to Lower LC Oscillator Phase Noise,”
IEEE Journal of Solid-State Circuits, 36, no. 12, 1921–1930, 2001.
[23] A. A. Abidi, “Phase Noise and Jitter in CMOS Ring Oscillators,” IEEE Journal of Solid-State Circuits,
41, no. 8, 1803–1816, 2006.
[24] A. Homayoun and B. Razavi, “Relation between Delay Line Phase Noise and Ring Oscillator Phase
Noise,” IEEE Journal of Solid-State Circuits, 49, no. 2, 384–391, 2014.
[25] R. Navid, T. Lee, and R. Dutton, “Minimum Achievable Phase Noise of RC Oscillators,” IEEE Journal of
Solid-State Circuits, 40, no. 3, 630–637, 2005.
[26] A. Mirzaei, M. Heidari, R. Bagheri, S. Chehrazi, and A. Abidi, “The Quadrature LC Oscillator:
A Complete Portrait Based on Injection Locking,” IEEE Journal of Solid-State Circuits, 42, no. 9,
1916–1932, 2007.
[27] A. Mirzaei, “Clock Programmable IF Circuits for CMOS Software Deﬁned Radio Receiver and Precise
Quadrature Oscillators,” Doctoral dissertation, University of California, Los Angeles, 2006.
9.13 References
593

[28] Y. Chang, J. Leete, Z. Zhou, M. Vadipour, Y.-T. Chang, and H. Darabi, “A Differential Digitally
Controlled Crystal Oscillator with a 14-Bit Tuning Resolution and Sine Wave Outputs for Cellular
Applications,” IEEE Journal of Solid-State Circuits, 47, no. 2, 421–434, 2012.
[29] A. Nelson, J. Hu, J. Kaitila, R. Ruby, and B. Otis, “A 22µW, 2.0GHz FBAR oscillator,” in Proceedings of
the IEEE Radio Frequency Integrated Circuits Symposium, 2011.
[30] W. Pang, R. C. Ruby, R. Parker, P. W. Fisher, M. A. Unkrich, and J. D. Larson, “A Temperature-Stable
Film Bulk Acoustic Wave Oscillator,” IEEE Electron Device Letters, 29, no. 4, 315–318, 2008.
[31] K. A. Sankaragomathi, J. Koo, R. Ruby and B. P. Otis, “25.9 A 3ppm 1.1mW FBAR Frequency
Reference with 750MHz Output and 750mV Supply,” in Proceedings of the IEEE International Solid-
State Circuits Conference (ISSCC) – Digest of Technical Papers, 2015.
[32] Q. Huang, “Phase Noise to Carrier Ratio in LC Oscillators,” IEEE Transactions on Circuits and Systems
I: Fundamental Theory and Application, 47, no. 7, 965–980, July 2000.
594
Oscillators

10
PLLs and Synthesizers
In this chapter we present the phase-locked loops and synthesizers, built upon the discussions
of the previous chapter, VCOs and crystal oscillators. It is a new chapter in this edition,
although some pieces of it existed in the previous edition under Chapter 8. A detailed
discussion of PLLs and synthesizers would perhaps require an entire book of its own, and
our objective here is only to establish enough background to allow design and analysis of
synthesizers for typical radio applications.
A phase-locked loop is a mixed-mode nonlinear feedback system. As we have already
established, most modern radios require precise tunable LO signals typically created through a
frequency synthesizer, which relies on the concept of phase locking. We therefore begin our
discussion with basics of phase-locked loops and their building blocks, followed by presenting
both fractional and integer synthesizers. A frequency synthesizer generates a range of frequencies
from a single reference frequency, and relies on frequency multiplication or division using phase-
locked loops. Through an approximate linear model commonly used among PLL designers, noise
and transient properties of PLLs and synthesizers are discussed, and design guidelines are offered.
We also present a detailed discussion on latches and multi-modulus frequency dividers as
they are key building blocks of every frequency synthesizer. We conclude this chapter by
offering an introductory discussion of digital PLLs and theirs pros and cons.
The analysis of PLL dynamics and its noise performance offered in this chapter is particularly
important as it sets the foundation for our discussion on polar and PLL-based transmitters in
the next chapter.
The speciﬁc topics covered in this chapter are:
• Phase-locked loops building blocks
• Type I and II PLLs
• PLL linear analysis
• Integer and fractional synthesizers
• PLL noise sources
• Frequency dividers
• Introduction to digital PLLs
For class teaching, we recommend spending no more than two lectures to cover the basics of
PLLs (Sections 10.1, 10.2, 10.3), and an introduction to integer and fractional synthesizers
(selected parts of Sections 10.4 and 10.5). If time permits though, a lecture may also be spent
on the divider topologies (Section 10.6).

10.1 PHASE-LOCKED LOOPS BASICS
..............................................................................................
Like operational ampliﬁers, RF oscillators are seldom used open-loop. As in most applications
a precise carrier frequency is needed, it is common to stabilize the oscillator within a feedback
system, namely a phase-locked loop or PLL. Like any feedback system, a PLL requires a sense
and a return mechanism to correct for VCO frequency drift. Unlike ampliﬁer feedback loops,
though, the variable of interest here is neither voltage nor current, but is rather phase (or
frequency). With that in mind, one can build the PLL as follows:
– A phase detector (PD) that takes the phase difference between the two inputs and produces an
output voltage or current accordingly. Thus, the PD output may be ideally expressed as
KPDΔϕ, where Δϕ = ϕIN1  ϕIN2 denotes the input signals phase difference (Figure 10.1),
and KPD is the phase detector gain.
– A loop ﬁlter, whose role is to remove the unwanted frequency components produced at the
phase detector output. We will ﬁnd out later that this is not the only purpose of the loop ﬁlter
in a PLL. In fact the loop ﬁlter plays a critical role in the PLL stability and its transient
response.
– And of course the VCO itself, which from the PLL point of view takes a voltage (sometimes
current) as the input and produces an output frequency proportional to that. In practice, the
VCO output may be applied to subsequent blocks through a buffer, which is often an
inverter. Since it is not going to affect the PLL functionality, for simplicity it is omitted here.
So ideally, one may build a PLL as shown in Figure 10.2, where the phase detector provides the
means of sense, and what is sensed is, of course, the VCO phase (or frequency). What is
returned is the phase detector output after being lowpass ﬁltered, which is a voltage and is
applied to the VCO control voltage input.
Of the three blocks involved, the VCO has been covered in details already in the previous
chapter. The loop ﬁlter could be as simple as an RC circuit whose role will be more clear once
we get to the PLL transfer function and its dynamics in the next section. So for the remainder of
this section, we will spend some time on the phase detector.
PD
PD
Loop Filter
REF
Figure 10.2: A simple phase-locked loop consisting of a
VCO, a phase detector, and a loop ﬁlter
PD
B
A
O
O, V
Df, ° 
Figure 10.1: An ideal phase detector
output–input characteristic
596
PLLs and Synthesizers

10.1.1 Phase Detectors
A phase detector may be simply realized through multiplying the two inputs. For instance if the
A and B inputs are
vA(t) = A0 cos(ω1t + ϕ1)
vB(t) = B0 cos(ω2t + ϕ2),
the product once lowpass ﬁltered will be
A0B0
2
cos
ω1  ω2
ð
Þt + ϕ1  ϕ2
ð
Þ,
and if the frequencies are the same, the output becomes proportional to cos(ϕ1  ϕ2). Since the
phase detector input signals are often rail-to-rail digital-type waveforms, in practice the
multiplication may be accomplished by an XOR gate as shown in Figure 10.3.
If the inputs are perfectly aligned, the XOR output is zero. As one starts to lag (say B in our
example above), the XOR produces short pulses at twice the frequency, whose DC component
tracks the input phase difference linearly. The XOR output reaches a maximum if the inputs are
180⁰ out of phase.
Example: The XOR circuit can be implemented by PMOS (or NMOS) switches as shown
in Figure 10.4. Also shown is the XOR gate truth table. The output will be equal to VDD or
logic one, if either one of the inputs is high with the other one low, as desired.
Figure 10.3: Phase detector realization using
an XOR gate
A
B
B
A
A
B
B
A
Truth Table
Q
VDD
VDD
A
B
Q
0
0
0
1
0
1
1
1
0
0
1
1
Figure 10.4: CMOS XOR gate
10.1 Phase-Locked Loops Basics
597

In practice, the inputs of PD could have different frequencies prior to the PLL locking.
Figure 10.5 shows two examples of the XOR PD output, where on the left the B signal is
slower than A, while in the right B is faster. In either case, the PD creates a proper output,
which once ﬁltered and applied to the VCO results in its frequency to increase or decrease
as desired.
An example of a current-mode XOR gate using only PMOS switches is shown in
Figure 10.6.
Interestingly, even though the main objective of the PLL is to stabilize the VCO frequency, a
frequency detector alone is not enough. This is because, like any feedback system, the output
tracks only the changes in the input around a certain operating point, which is to say in the case
of a frequency detector, the frequencies track but are not necessarily the same. On the other
hand, if the loop phase locks, the phases track, and the frequencies that are the derivative of the
phases are then identical. As we will see in Section 10.3.1, it is very common though to use a
phase-frequency detector that accomplishes both tasks.
10.2 TYPE I PLLs
..............................................................................................
With the background earlier, we are now ready to take a closer look at the PLL of Figure 10.2.
10.2.1 PLL Qualitative Analysis
Let us ﬁrst try to understand the PD and VCO behavior qualitatively during the locking process.
Suppose initially the VCO is slower than the reference as depicted in Figure 10.7. The PD
produces a sequence of pulses that, once passed through the loop ﬁlter, will slowly raise the
control voltage, and thus the VCO frequency. As the VCO frequency gets closer to the
reference, the PD pulses become smaller, and eventually the loop locks, that is, the VCO and
A
B
O
A
B
O
B slightly slower than A
B slightly faster than A
Figure 10.5: Phase detector waveforms when the two inputs have different frequencies
A
B
A
B
O
VDD
Figure 10.6: Current-mode XOR circuit realization
using PMOS switches
598
PLLs and Synthesizers

reference have the same frequency, but there is a nonzero phase difference to set the required
control voltage for the VCO to operate.
Depending on the loop dynamics, there may be an overshoot (like the example) or even some
ringing, though obviously not desirable. This has to do with the speciﬁc choice of the loop ﬁlter
bandwidth and the VCO and PD gains. We will discuss the transient behavior of the PLL
quantitatively in the next section.
Example: As a practical circuit implementation of type I PLL, consider the circuit shown
in Figure 10.8, consisting of a PMOS XOR (Figure 10.6) as a phase detector, an RC loop
ﬁlter, and a ring oscillator whose frequency is adjusted through changing its supply
voltage, effectively varying the inverter’s transconductance or delay.
The XOR output will sit below VDD, such that when the loop is locked the proper
control voltage (i.e., supply) is fed to the ring oscillator. The PD could be thought of a
mixer (or multiplier) creating a DC output (once ﬁltered), and is capable of providing the
DC current required by the oscillator.
10.2.2 PLL Linear Model
Since the PLL transient response is a nonlinear phenomenon, it is not easy to derive a simple
formula to capture all the mechanisms involved. Nevertheless, it is very common to use an
approximate linear model to obtain the PLL transfer function, and consequently to gain insight
into PLL dynamics and the trade-offs involved.
While the PLL building blocks such as VCO or phase detector produce voltage outputs, it is
only meaningful to view the PLL as a hybrid system that deals with phase (or frequency) as
well as voltage. Accordingly, a linear model can be derived, as shown in Figure 10.9.
REF
VCO
PD
LPF
Figure 10.7: Type I PLL time domain behavior
R
C
Loop Filter
VCO
REF
Figure 10.8: Example of a simple type
I PLL circuit realization
10.2 Type I PLLs
599

The phase detector compares the phase difference between the reference and the VCO, and
creates a voltage with the appropriate gain KPD, measured in V/rad. For example, for the XOR
phase detector of Figure 10.6, the voltage–phase characteristics are depicted in Figure 10.10,
where the y-axis represents the average output voltage. This average voltage is effectively
created by the loop ﬁlter whose transfer function is generally denoted by F(s). Hence, for
the XOR,
KPD = VDD
π
:
The VCO produces a frequency proportional to the ﬁltered phase detector voltage,
vVCO(t) = A cos(ω0t + KVCO
Ð
vCTRL(t)dt),
where vCTRL(t) is the loop ﬁlter output (or the VCO input). Since the output phase is the
integral of frequency, in our linear model the VCO may be generally described by KVCO
s , where
KVCO is the VCO gain measured in rad/s/V. The factor s represents the integration in Laplace
domain.
From the Figure 10.9 block diagram, assuming the loop ﬁlter is a simple RC circuit like
that of Figure 10.8, then the PLL is modeled as a linear unity feedback loop, with an open-loop
gain of
KVCOKPD
s
F sð Þ = KVCOKPD
s 1 + RCs
ð
Þ :
Since the open-loop gain has one zero at the origin (due to the VCO), this type of PLL is
referred to as type I. Consequently, the closed-loop transfer function, H(s), becomes
H sð Þ = ΔΦOUT
ΔΦIN
=
KVCOKPD
RC
s2 +
1
RC s + KVCOKPD
RC
:
fIN
VCO
Loop
Filter
fOUT
+
–
KPD
KVCO/s
F(s)
Phase 
Detector
Figure 10.9: Type I PLL linear phase model
VDD
VDD
VO
<VO>
A
B
t T f
f
Figure 10.10: Voltage–phase characteristics of the XOR phase detector of Figure 10.6
600
PLLs and Synthesizers

This is a 2nd-order response, and using familiar control theory notations, it can be
expressed as
H sð Þ =
ωn2
s2 + 2ζωns + ωn2 ,
where ωn =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
KPDKVCO
RC
q
, and ζ =
1
2RCωn =
1
2 ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
RCKPDKVCO
p
. Now, we can justify the transient response
of the PLL shown in Figure 10.7. For a critically damped response, which is often desirable,
ζ = 1, whereas the example depicted in Figure 10.7 has a small overshoot, and corresponds to
an underdamped response, or ζ < 1.
A few observations are in order:
– The PLL transfer function is lowpass, i.e., the PLL tracks only the low-frequency variations
of the reference. This is expected, given the presence of a lowpass ﬁlter in the feedforward
path of the feedback system. For a given loop ﬁlter cutoff, the PLL simply will not be fast
enough to track the reference high-frequency perturbations.
– When locked, there will be a nonzero static phase difference between the input and the VCO.
In other words, the PD has a nonzero output that maintains the right frequency of oscillation.
This means that in general the phase difference between the reference and VCO (ϕOUT  ϕIN)
will be a constant. Since frequency is the derivative of phase, however, fOUT  fIN = 0 as
desired. Furthermore, despite the nonzero phase difference, any change of the input phase
will be exactly followed by the VCO, which is to say ΔϕOUT  ΔϕIN = 0.
– To have a favorable transient response, and to achieve a sufﬁcient phase margin, it is
desirable to keep the damping factor, ζ, close to one. This presents a trade-off between the
loop stability, and the lowpass ﬁlter bandwidth. A lower loop ﬁlter cutoff enjoys more
ﬁltering, but reduces the damping factor, and hence produces less stability.
The linear model predicts the PLL dynamics only when there is a small phase (or frequency)
perturbation around the desired lock point. It fails to give us any information on the VCO
frequency transient up to the vicinity of the loop locking. Nonetheless, it provides useful
insights into designing and optimizing the PLL building blocks and the entire system, and is
widely used among RF designers.
10.3 TYPE II PLLs
..............................................................................................
Despite their simplicity, type I PLLs are seldom used in most modern radios due to their limited
lock range, the bandwidth–stability trade-off, and, to a lesser extent, the nonzero phase
difference between the reference and the VCO during the lock. Lock range is a measure of
how different the VCO and reference frequency can be from one another, and yet the PLL still
acquires the lock. In the case of a type I PLL, the limited lock range mainly arises from the fact
that the phase detector simply has no sense of its input frequency difference.1 This issue is
1 More information on the lock range and the PLL dynamics during the lock acquisition may be found in [21], [22].
10.3 Type II PLLs
601

addressed if a phase-frequency detector is exploited rather than a simple phase detector, and is
discussed next.
10.3.1 Phase-Frequency Detection
Ideally, the phase-frequency detector (or PFD) must:
– Be insensitive to the inputs duty cycles or their shape (only zero crossings matter)
– Create the appropriate output(s) if the inputs frequencies are different, say positive if one is
higher, negative if lower
– Create the appropriate output(s) if the inputs phases are different
A very commonly used circuit that satisﬁes all the above properties is shown in Figure 10.11.
The edge-triggered D ﬂip-ﬂops (in this case positive edge-triggered) eliminate any depend-
ence on the duty cycle, and only respond to the positive edge of either input. Both ﬂip-ﬂops
inputs are connected to VDD (or logic 1), and the inputs (A and B) are applied to the clock
port. If the input A is leading B (as shown as an example on the right), the positive edge of
A arrives ﬁrst, which results in the upper ﬂop output (U or up) going high. The U output
stays high until the positive edge of B input arrives, which will result in the D or down
output to go high as well. The U and D outputs will stay high only shortly after, until the
AND gate resets the two D ﬂip-ﬂops. So the U output consists of pulses tracking the phase
lag between A and B, while the D output consists of narrow pulses whose width is equal to
the delay of the D ﬂip-ﬂop plus the AND gate, and are known as reset delay pulses. Reset
delay pulses are often useful to avoid the dead-zone in the charge pump, that is, a region
where neither output is sufﬁciently large to turn on the subsequent stages. This usually
occurs when the phase difference between the two inputs is so small that the PFD cannot
generate wide enough up and down pulses to turn on the next stage.
The circuit implementation of the D ﬂip-ﬂops is very straightforward, and is covered in
Section 10.6.1. Since the B input is lagging, the PFD is effectively commanding the B signal
(being represented by the VCO in the context of a PLL) to speed up, and hence a series of up
pulses are issued. The scenario of course will be reversed if A is lagging B.
It is evident that the PFD outputs create the desired signal whether the inputs have phase or
frequency difference.
Figure 10.11: Phase-frequency
detector
602
PLLs and Synthesizers

Example: Consider Figure 10.12, where on the left A and B have the same frequency but
A is lagging, while on the right B has a higher frequency.
In either case, a series of down pulses are created to effectively slow down the B signal.
Generally, one can utilize the PFD in the PLL by simply subtracting the outputs and apply to
the loop ﬁlter, as illustrated in Figure 10.13.
We will show next that this task is performed more elegantly by employing a charge pump
circuit.
10.3.2 Charge Pump
A more effective way of taking advantage of the up and down pulses created by the PFD is
through applying them to two switched current sources known as a charge pump (or CP), shown
in Figure 10.14. The current sources are always accompanied by a capacitor, whose need will be
clear shortly. The timing diagram for the case of A leading B as an example is shown on the right.
Given the timing diagram on the right, since A is leading (or A is faster), U output consists of
a series of up pulses, while D output has only the reset delay pulses. Once U is high, the top
current source is on, pushing a current of ICP to the capacitor C at the output. Consequently the
output voltage rises as the capacitor charges up. Once the reset delay comes, both current
sources are on, and no net current ﬂows to the output. We will discuss shortly what happens if
A
B
U
D
A
B
U
D
A lags B but same frequency
A slower than B
Figure 10.12: PFD timing diagram with one input lagging or slower than the other
1
1
REF
VCO
D
Q
Clk
Reset
D
Q
Clk
Reset
U
D
O
VCO Input
Figure 10.13: Phase-frequency detector
conceptual use in a PLL
10.3 Type II PLLs
603

the two current sources are not identical. So overall the output voltage linearly goes up in
discrete steps. We can postulate that if this voltage is applied to the VCO (after some
appropriate ﬁltering), it will raise the VCO frequency as it should. Obviously if A is slower
than B, now the down pulses are effective, pushing the same current of ICP to the output, but in
a reverse direction, causing the capacitor to discharge.
10.3.2.1 Charge Pump Circuit Implementation
Two simple candidates to implement the charge pump circuit are shown in Figure 10.15. The
circuit on the left is exactly how one would implement the conceptual design shown in
Figure 10.14: transistors M1 and M4 are biased to create the current, while M2 and M3 act as
switches.
Alternatively, one could use the circuit on the right, where the switches are moved to the
source and away from the output. This could be advantageous, as clock feedthrough or charge
sharing caused by the up and down signals’ sharp transition are alleviated.
Figure 10.16 shows a differential implementation, where the P and N differential pairs create
current-mode switches. Unlike the two examples of Figure 10.15, in the differential implemen-
tation the current sources always stay on, and the differential pair steer the current only either to
the output or to a dummy path, whose voltage is kept the same as the output through a unity
gain buffer.
This has a few advantages: It avoids any undesirable charge to be deposited to the output due
to the current sources turning on or off. Furthermore, it will be a faster design, though in many
U
D
ICP
ICP
VO
C
A
B
U
D
VO
Figure 10.14: Schematic of a typical charge
pump and the corresponding waveforms
DN
UP
VDD
BIASN
BIASP
M1
M2
M3
M4
OUT
DN
UP
VDD
BIASN
BIASP
M1
M2
M3
M4
OUT
Figure 10.15: Examples of simple charge
pump circuits
604
PLLs and Synthesizers

cases the PFD/CP circuits run at relatively low frequencies (e.g., tens of MHz). The disadvan-
tages are the need for a differential PFD, and a unity gain opamp with rail-to-rail input as the
charge pump output usually is biased at the mid-rail, and should ideally swing as large as the
headroom allows. The opamp does not add any noise, however, as its output is connected to
the dummy path.
Apart from charge sharing and charge feedthrough, which are typically not a major concern,
one potential issue in the charge pump arises from inevitably unequal up and down currents.
This leads to nonlinearity and unwanted spurs at the PLL output, which we will address in
details in Sections 10.3.3 and 10.5.3.2. To alleviate this, in all the three circuits shown, cascode
current sources may be used to achieve more accuracy at the expense of voltage headroom. It is
also possible to exploit feedback to equalize the up and down currents. An example of the latter
is shown in Figure 10.23, and will be discussed in Section 10.3.3.
10.3.2.2 Charge Pump Modeling
In the case of type I PLLs, it was rather straightforward to quantify the phase detector gain or
KPD (Figure 10.10 for instance), used subsequently to derive the PLL transfer function. To do
the same for the PFD/CP circuit, let us take a closer look at the timing diagram of Figure 10.14.
First we observe that the charge pump output is not linear; e.g., if the input’s phase skew
doubles, the output waveform is not stretched two times. Second, the charge pump output is
really a discrete signal, and thus must be treated as such. On the other hand, one can think of the
charge pump output current as pulse-width modulated (PWM) bursts, or effectively as a
continuous waveform sampled at the reference frequency as depicted in Figure 10.17.
The width of the pulses, ΔT, is proportional to the input’s phase difference,
ΔT = ϕREF  ϕVCO
ωREF
,
where ωREF =
2π
TREF is the reference frequency, and ϕREF and ϕVCO are the reference (that the
VCO must lock into) and VCO phases, respectively. The PWM currents sequence may be
assumed to be a continuous current sampled by a train of impulses at the reference frequency,
UP
DN
UP
DN
iOUT
VDD
I
I
Figure 10.16: Charge pump implementation using a differential
pair as a current-mode switch
10.3 Type II PLLs
605

provided that the rate of variation of the current pulses going into the capacitor is much less than
the reference frequency. That is usually the case, as the loop ﬁlter bandwidth that directly
determines this rate is much smaller than the reference frequency. The approximated current
impulses as well as the original burst are depicted in Figure 10.18 as a comparison. We have
assumed that the up and down currents are the same and equal to I0.
Either waveform in Figure 10.18 will eventually lead to the correct charge pump voltage
once integrated by the charge pump capacitor, the only difference being the abrupt change in
the capacitor voltage if the impulse approximation is utilized (Figure 10.19).
In the frequency domain, the train of impulses becomes
1
TREF
X
k
δ f  kf REF
ð
Þ,
which is convolved by the continuous current whose height at each sampling point is
I0
ϕREFϕVCO
ωREF
. The principal spectrum of current appears around DC, with all the other images
iOUT
TREF
DT
TREF
iOUT
iOUT
IU
ID
t
t
t
d(t)
Figure 10.17: Charge pump
output viewed as PWM currents
sampled by the reference
iOUT
TREF
DT=
t
I0
TREF
t
I0
fREF–fVCO
wREF
iOUT
fREF–fVCO
wREF
Figure 10.18: Charge pump current approximated by a
train of impulses
iOUT
TREF
DT=
t
I0
fREF–fVCO
wREF
vOUT
t
vOUT
t
Actual
Impulse approximation
fREF–fVCO
wREF
I0
C
fREF–fVCO
wREF
I0
C
Figure 10.19: Charge pump output voltage as a result
of current sequence integrated on the capacitor
606
PLLs and Synthesizers

at the harmonics of the reference removed by the loop ﬁlter. The height of the current impulses
at each point is
1
TREF
I0
ϕREF  ϕVCO
ωREF
= I0
2π ϕREF  ϕVCO
ð
Þ,
or in the Laplace domain,
IOUT sð Þ = I0
2π ϕREF sð Þ  ϕVCO sð Þ
ð
Þ:
Thus, the PFD/CP gain is equal to I0
2π, with I0 being the charge pump current. With the capacitor
at the output included, the charge pump output voltage will be
VOUT sð Þ = 1
sC
I0
2π ϕREF sð Þ  ϕVCO sð Þ
ð
Þ:
That is, it behaves like an integrator, and therefore has inﬁnite gain at DC. Intuitively this is
justiﬁed by noting that, when locked, a phase difference between the VCO and reference,
however small, will result in a small charge to be deposited on the capacitor at every cycle,
which goes on forever. So in a type II PLL, at least with an ideal charge pump, the VCO and
reference are not only frequency locked, but also phase aligned. We will show, however, that in
a more realistic charge pump with unequal up and down currents, there will be a small phase
difference, causing unwanted reference spurs at the output.
10.3.3 Type II PLL Analysis and Nonideal Effects
The combination of the PFD, CP, and output capacitor provides, for the most part, the same
functionality as the PD and loop ﬁlter in the case of a type I PLL. Consequently, one can
surmise the PLL may be built like shown in Figure 10.20, only that there is an additional
resistor in series to the capacitor as well, whose role will be clear in a moment.
Let us assume ﬁrst there is no resistance, as has been the case thus far, that is R = 0 in the
ﬁgure. Then the open-loop gain is
G sð Þ = I0
2π
1
sC
KVCO
s
:
PFD
REF
CP
R
C
Figure 10.20: A simple type II PLL
10.3 Type II PLLs
607

The open-loop gain has two zeros at origin, and hence the terminology type II PLL, but once
put in the unity feedback it creates an oscillatory system. To avoid this, a resistor is added in
series, which makes the open-loop gain
G sð Þ = I0
2π
R + 1
sC

 KVCO
s
:
There are still two zeros in the origin, but now a left-half plain zero is added, which improves
the phase margin. The closed-loop PLL transfer function is now
H sð Þ =
ωn2 1 + RCs
ð
Þ
s2 + 2ζωns + ωn2 ,
where ωn =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I0
2πKVCO
C
q
, and ζ = RCωn
2
= R
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I0
2π CKVCO
q
. Unlike type I PLL, here reducing the loop
ﬁlter bandwidth (or PLL bandwidth) will not necessarily reduce the damping factor. Further-
more, the addition of the LHP zero helps tremendously with the phase margin and stability, a
feature not present in a type I PLL.
In practice, to achieve a sharper roll off to suppress far-out noise and spurs, additional poles
are often added, and the actual loop ﬁlter looks more like the one shown in Figure 10.21. As a
rule of thumb, usually C2 = C1
10, and the third pole set by R3/C3 is chosen to be about 5–10 times
higher than the PLL bandwidth. So apart from minor degradation in the phase margin, they
have little impact on PLL close-in response or bandwidth, but certainly provide much-needed
rejection at higher frequencies. This is especially important in fractional PLLs, to be discussed
in Section 10.5.3.3.
It must be emphasized that the linear analysis presented is based on the assumption that the
rate of variation of the VCO phase is small compared to the reference frequency, i.e., the loop
bandwidth is sufﬁciently small with respect to the reference. If this assumption does not hold,
the charge pump can no longer be approximated as a continuous circuit, and the PLL must be
analyzed in the discrete domain. Given the stability concerns as well as the general desire of
having sufﬁcient ﬁltering from the loop ﬁlter, this assumption is usually satisﬁed, and thus the
simpler linear model works ﬁne for most purposes.
More on the PLL transfer function and its noise sources can be found in Sections 10.4.1
and 10.4.2.
Apart from noise concerns which will be discussed in the next section, the main issue in
the type II PLLs arises from the unwanted spurs located around the VCO at the reference
CP
R1
C1
R3
C3
C2
Figure 10.21: More practical loop ﬁlter implementation of type
II PLLs
608
PLLs and Synthesizers

frequency and its harmonics, known as the reference spurs. This primarily (there may be
also direct feedthrough due to parasitic paths from the reference to the VCO) arises from
unequal up and down currents in charge pump. Consider Figure 10.22, where we have
assumed the up current is slightly less than the down current. If the currents are equal, the
VCO and reference will be exactly phase aligned, and the charge pump only turns on
shortly during the reset delay, but since the equal up and down currents offset each other, it
will have no impact on the control voltage or VCO. On the other hand, if the up current is
less, as shown in the ﬁgure, the up pulse must be wider such that the net charge deposited
on the capacitor during one cycle is zero. This will cause the control voltage to go up ﬁrst,
after which point is reduced back to the steady-state level due to a larger down current,
which is effective only during the reset delay phase. Naturally, the VCO and reference are
not phased aligned anymore,2 but the feedback loop of course ensures that the frequencies
are the same.
Consequently, the VCO control voltage will not be ﬂat, rather it has a small perturbation
on it happening at the reference frequency. Once applied to the VCO, it will frequency
modulate its output, creating sidebands at the reference frequency and all its harmonics.
Since this waveform is subject to the lowpass loop ﬁltering, usually the main harmonic is
the most troublesome, though it ultimately depends on where exactly the blockers are
located.
The unequal up and down currents are inevitable, and are caused mainly by the
mismatches and/or the channel length modulation in the current sources. The former is
often not a dominant factor, and can be improved by sizing the current sources properly.
Since the charge pump output is often biased at mid-rail, and ideally should entertain as
large a swing as possible,3 the ﬁnite output resistance of the current sources due to the
channel length modulation is the most problematic factor. Typical remedies are to use
cascode current sources at the expense of precious headroom, or use feedback to equalize
the currents.
REF
VCO
U
D
VCTRL
Figure 10.22: Demonstration of reference spur in PLLs in
the presence of mismatch in up and down currents
2 This is usually unimportant.
3 This is primarily to reduce the VCO gain as much as possible for a given desired locking range, which in turn is to avoid
low-frequency noise modulating the VCO through a large varactor as discussed in the previous chapter.
10.3 Type II PLLs
609

Example: Shown in Figure 10.23 is a charge pump circuit utilizing feedback to alleviate
the channel length modulation [1].
A similar idea is used in low-voltage bandgaps as well [2], and works as follows: The
high gain opamp ensures that the charge pump output and node A are at the same potential.
Thus, between the main charge pump devices (M1–M4), and the replica path (MM1–MM4),
all have the same gate, source, and drain voltage. Since KCL forces the N and P currents to
be the same in the replica path (MM2 and MM3), so should be the main charge pump up and
down currents. In other words, the opamp sets the bias of the P transistor (M3) to offset the
channel length modulation, as opposed to the traditional implementation (Figure 10.15),
where the P bias is created externally. The trade-offs here are the need for a rail-to-rail
opamp, which adds noise and power consumption. It may be possible though to at least
partially ﬁlter the opamp noise by placing a capacitor at its output.
Example: Another possible source of reference spurs in PLLs, shown in Figure 10.24, is
the leakage current caused by the varactor or the loop ﬁlter capacitors (especially if MOS
capacitors are used for the lower silicon area).
DN
UP
VDD
BIASN
M1
M2
M3
M4
MM1
MM2
MM4
MM3
VDD
iOUT
A
Figure 10.23: Charge pump with feedback loop to
improve current matching [1]
UP
DN
ICP
ICP
C
VDD
VCO
ILeakage
REF
VCO
UP
DN
VCTRL
VCTRL
t
Figure 10.24: Leakage casing unequal up and down currents, leading to reference spurs
610
PLLs and Synthesizers

The leakage current results in the control voltage continuously decreasing, and hence to
make up for that, the UP signal must turn on a little bit earlier, causing the reference to
lead the VCO. Assuming a reference lead time of τ, we should have
(ICP  ILeakage)τ = ILeakage(TREF  τ),
where ICP is the charge pump current, ILeakage is the leakage current, and TREF is the
reference period. Therefore,
τ = ILeakage
ICP
TREF:
The strength of the spur of course depends on how large the leakage current, or the VCO
and reference phase lead, are.
10.4 INTEGER-N FREQUENCY SYNTHESIZERS
..............................................................................................
Although PLLs as described so far are used in radios for purposes of LO generation, what
actually is needed is a frequency synthesizer. Two simple reasons: First, the VCO frequency is
usually in GHz range to supply the mixers, while the practical references have frequencies on
the tens of MHz range due to the limitation of crystals. Second, the VCO frequency, which
provides the RX or TX LOs, must be tunable, usually in a wide range, while the crystals are not.
The issues are resolved by simply inserting a programmable divider in the feedback path,
known as the feedback divider, as shown in Figure 10.25 (the divide-by-N circuit). Further-
more, the reference must be also divided by a proper value (K in the ﬁgure, known as the
reference divider) so that the PFD input frequency becomes equal to the required channel
spacing such that by varying N in integer steps, the desired RF channel is selected.
The feedback loop in the PLL naturally forces the output frequency to be
f OUT = N f REF
K
= Nf Channel,
÷N
REF
PFD/
CP
1 2
M
fChannel = fREF/K
…
÷K
Frequency Control
Multiple RF channels
Figure 10.25: Integer-N frequency synthesizers in
wireless radios
10.4 Integer-N Frequency Synthesizers
611

where fChannel is the required channel spacing (Figure 10.25). Since the synthesizer produces
frequencies only in integer multiples, it is often referred to as an integer-N synthesizer, or simply
an integer synthesizer, as opposed to the fractional synthesizers discussed in Section 10.5.
Example: In Bluetooth, the desired channel located in the ISM band can assume any
frequency between 2402MHz to 2480MHz in steps of 1MHz. Thus, fChannel = 1MHz (the
reference divide ratio of course depends on the crystal frequency), and a programmable
divider with a divide ratio of 2402 to 2480 is needed. The dividers will be discussed at the
end, in Section 10.6.
In the remainder of this section, we will extend our PLL linear analysis to include the
feedback divider, and also discuss the noise sources in the synthesizer. For the most part, the
synthesizer of Figure 10.25 behaves much the same as the PLL (Figure 10.20) discussed
already in detail, and suffers from very similar issues (e.g., the reference spur, lock range, etc.).
10.4.1 Signal Transfer Functions
The synthesizer transfer function and its phase noise may be obtained by using the linear model
shown in Figure 10.26. The noise of each block is injected accordingly as shown in the ﬁgure.
The feedback divider simply divides the VCO phase (or frequency) by N, and is represented
by 1
N. The open-loop gain is given by
G sð Þ = KPFDF sð Þ KVCO
s
1
N ,
where F(s) is the loop ﬁlter transfer function, and KPD is the PD or PFD/CP gain, whichever is
used. In the more common case of using a type II PLL, KPD is I0
2π as derived in Section 10.3.2.2.
Accordingly, the PLL output (including the noise sources) may be expressed as
ϕOUT =
NG
1 + G ϕIN +
NG
1 + G vnDIV +
1
1 + G vnVCO +
N
KPD
G
1 + G vnPD + vnLF
ð
Þ:
Ignoring the noise sources for the moment, the PLL closed-loop transfer function is
H sð Þ = ϕOUT
ϕIN
= N
G sð Þ
1 + G sð Þ :
fIN
KPD
F(s)
vnPD
vnLF
KVCO/s
f OUT
vnDIV
vnVCO
1/N
+
–
Figure 10.26: PLL linear model
612
PLLs and Synthesizers

Shown in Figure 10.27 is the Bode plot of the open-loop gain (G(s)) as well as the PLL closed-
loop transfer function (H(s)). Also shown is the transfer function from the VCO to the output,
which is
1
1 + G sð Þ.
In the case of a type I synthesizer, there is one pole at origin in the loop gain resulted
from the frequency integration inherent in the VCO (KVCO
s ). In the case of a type II PLL, the
loop ﬁlter has an additional pole at origin. This justiﬁes why the loop gain reduces by a
slope of –40dB/Dec initially, as shown in Figure 10.27. Furthermore, as we discussed in
Section 10.3.3, to ensure stability, the loop ﬁlter may employ a left-half plane zero (ωz), at
which point the loop gain drops by –20dB/Dec slope, reaching one at the unity gain
frequency, ωu. The exact location of the unity gain frequency depends on the loop ﬁlter
transfer function.
At frequencies well below ωu, |G(jω)|  1, and thus |H(jω)|  N. This implies that the output
frequency must be exactly N times that of the input (or reference). On the other hand, at
frequencies well above ωu, |G(jω)|  0, and |H(jω)| follows |G(jω)|, hence reducing with a
20dB/Dec slope. The PLL closed-loop bandwidth is then expected to be roughly equal to ωu.
Right around the unity gain frequency, the exact shape of the PLL closed-loop transfer function
will depend on the loop ﬁlter characteristics. It may peak or smoothly drop according to the
loop ﬁlter components values.
The VCO transfer function (the third plot in Figure 10.27) may be justiﬁed similarly.
To derive some numerical values for the PLL bandwidth, let us assume the charge pump
output drives a simple RC circuit (Figure 10.20) only, and ignore the second and third poles that
may exist in a more realistic loop ﬁlter (Figure 10.21). As indicated, the resistors and capacitors
are often chosen such that the additional poles or zeros created are far from the PLL bandwidth.
This is to ensure the stability, and a good phase margin for the PLL. Consequently, the
additional ﬁltering may help only at far-out frequencies.
20log|G(jw)|
20log|H(jw)|
20log|1/(1+G)|
wz
w
20logN
0dB
–2
–1
wu
0dB
Figure 10.27: Key synthesizer transfer functions
10.4 Integer-N Frequency Synthesizers
613

Therefore, the loop ﬁlter transfer function may be simply expressed as
F sð Þ = R + 1
Cs = 1 + RCs
Cs
:
Accordingly, the synthesizer closed-loop transfer function is
H sð Þ = N
ωn2 1 + RCs
ð
Þ
s2 + 2ζωns + ωn2 ,
where ωn =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
KPDKVCO
CN
q
, and ζ = RCωn
2 .
For a CP PII, KPD = Io
2n to ensure a critically damped
response, ζ = 1, which follows RCωn = 2. Under these circumstances, the synthesizer 3dB
bandwidth is calculated to be
ω3dB = 2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
3 +
ﬃﬃﬃﬃﬃ
10
p
p
RC
 5
RC :
Or expressed in terms of the synthesizer parameters,
ω3dB  2:5
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
KPDKVCO
CN
r
,
and the unity gain frequency is
ωu = 2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2 +
ﬃﬃﬃ
5
p
p
RC
 4
RC :
Example: We wish to calculate the PLL phase margin for the critically damped case. The
open-loop transfer function was found to be
G sð Þ = ωn2
s2
1 + s
ωz


,
where ωz =
1
RC. The corresponding Bode plot is shown in Figure 10.28.
Since ωu  4ωz, the phase margin is found to be
PM = tan1(4) = 76.
20log|G(jw)|
wz
w
–2
–1
wu
w
ÐG(jw)
0dB
–180°
–90°
Figure 10.28: Open-loop transfer function of
the PLL Bode plot for the critically damped case
614
PLLs and Synthesizers

Example: Consider a Bluetooth transmitter. The synthesizer reference is 1MHz, same as
channel spacing, and suppose we set the PLL bandwidth to be one-tenth of the reference,
100kHz. Assume KVCO is equal to 2π  15MHz/V. With ζ = 1, we have
RC =
5
ω3dB
=
5
2π  100kHz = 8μS:
For noise concerns (see the next section), we choose R = 20k, which leads to C = 400p, a
fairly large capacitance, though it can be partially implemented with MOSCAPs. Since
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
KPDKVCO
CN
q
= ωn =
2
RC = 0:4ω3dB, and with N = 2440, we ﬁnd KPD = 0.0013V/rad, which
leads to charge pump current of 4.1mA. This is rather large, and can be reduced by either
reducing the loop ﬁlter capacitor or by increasing the VCO gain, both of which have noise
implications of course. As the divide ratio changes to cover the 80MHz ISM band, the
PLL characteristics change slightly. Since this is predictable, one may choose to compen-
sate by varying the charge pump current accordingly, though since its impact is small, it is
often left alone.
Interestingly, if we could have used a smaller divide ratio, a lower charge pump
current would have been obtained. This is not possible in integer PLLs, but as we will
see shortly, fractional PLLs allow for much higher reference frequencies, which in turn
imposes a much more reasonable trade-off on the charge pump value and the loop
ﬁlter size.
10.4.2 Noise Sources in Synthesizer
As we already have the transfer function of various noise sources to the output, we may now
explain the PLL phase noise proﬁle as was shown previously in Chapter 5, and depicted again
in Figure 10.29.
The reference, phase detector, and divider go through a lowpass transfer function given by
G sð Þ
1 + G sð Þ (with different scaling factors, however). Shown in Figure 10.30 is the reference noise
transfer function to the output.
w
PLL Noise
REF
PLL
VCO
BUF
PLL BW
–2
–2
Figure 10.29: PLL general phase noise proﬁle, and various
noise contributors
10.4 Integer-N Frequency Synthesizers
615

Assuming a simple RC loop ﬁlter, the transfer function follows as
N
ωn2 1 + RCs
ð
Þ
s2 + 2ζωns + ωn2 ,
and the two poles of the transfer function (assuming overdamped function) are given by
ωP1,2 = ωn ζ 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ζ2  1
q


:
The VCO noise, on the other hand, enjoys a highpass transfer function determined by
1
1 + G sð Þ =
s2
s2 + 2ζωns + ωn2, and is shown in Figure 10.31.
Consequently, for frequencies below the PLL bandwidth, we expect the PLL components
such as the phase detector or divider to dominate. As the reference is typically a crystal
oscillator, at very low frequencies, where its noise rises with 20dB/Dec slope, we expect it to
dominate. Beyond the PLL bandwidth, the noise of the PLL is suppressed given the lowpass
nature of the response. On the other hand, the VCO noise appears directly at the output, and
dominates. Finally at very far-out frequencies, the noise ﬂattens as the VCO buffer and
following stages start to dominate.
Intuitively, we may explain the PLL noise proﬁle as follows: At low frequencies within
the PLL bandwidth, any ﬂuctuation at the VCO frequency resulted from its noise is
suppressed by the PLL due to the presence of a strong feedback. As the VCO frequency
is expected to follow the reference precisely, the reference noise (as well as that of the
divider or PD) is expected to appear at the output. On the other hand, at high frequencies,
the feedback is essentially ineffective, and the VCO noise appears at the output unﬁltered.
Reference Noise TF
wP1
w
20logN
wP2
wz
Figure 10.30: Reference noise transfer function to the
output that is lowpass
VCO Noise TF
wP1
w
0dB
wP2
Figure 10.31: VCO noise transfer function to the output
that is bandpass
616
PLLs and Synthesizers

Example: We shall ﬁnd the synthesizer phase noise due to the loop ﬁlter resistor, as
shown in Figure 10.32.
We can show that the resistor noise transfer function to the output is (see Problem 2)
ϕOUT
vn
sð Þ = KVCO
s
s2 + 2ζωns + ωn2 :
The transfer function is bandpass, and peaks at the PLL natural frequency, ωn, located at
0.4ω3dB, assuming critically damped condition (ω3dB is the PLL bandwidth). Thus, the
peak phase noise caused by the loop ﬁlter resistor is
ℒωn
f
g = 2KTR ϕOUT
vn
jωn
ð
Þ


2
= KVCO
2ωn


2
2KTR:
Note that what is shown above is the SSB phase noise, and thus the resistor noise is
considered: 2KTR. For a given PLL bandwidth, the required phase noise determines the
resistor size, and consequently, the capacitor value.
As an example, Figure 10.33 shows the noise contribution of the loop ﬁlter resistor, the
reference, and the VCO one at a time with everything else noiseless, as well as the composite
phase noise with all the sources acting simultaneously. Given the linear model, the superpos-
ition applies, and therefore we can ﬁnd the noise contribution of each building block separately,
and then add them all up:
– The reference and the VCO can be simulated free running and then translated to the output
using the proper transfer function.
fOUT
KVCO/S
KPD
–1
÷N
C
Loop Filter
PD
R
Vn
Figure 10.32: Loop ﬁlter resistor noise
10.4 Integer-N Frequency Synthesizers
617

– The PFD/CP noise can be estimated running AC noise simulation, considering the time
charge pump is on, or run a PSS4 simulation based on a realistic PFD/CP behavior. In integer
PLLs, the charge pump is on only shortly and is not expected to contribute much noise. This
is, however, not the case in fractional PLLs, as we will ﬁnd out soon.
– Loop ﬁlter noise can be estimated as ℒωn
f
g = KVCO
2ωn


2
2KTR, as was just described, or can
be simply simulated using an AC analysis of the loop ﬁlter through the linearized
PLL model.
– The divider noise can be estimated using a PSS simulation with an ideal input at the proper
frequency.
Then every noise source is translated to the output using the proper transfer function and added
up. That is the thick black curve on the plot of Figure 10.33. At very far-out offsets the noise
proﬁle follows the VCO noise, and at very low offsets it follows the reference. In between, all
the PLL blocks contribute, and it often follows the PLL transfer function. However, it is not
correct to estimate the PLL bandwidth or transfer function based on solely its output noise
proﬁle in general.
The linear model proves to be very convenient and fast and is widely used. Alternatively, one
could run transient noise simulation, which is more realistic but is a very slow simulation. It
may be helpful to use an ideal VCO, and run transient only to capture the PLL noise.
10.5 FRACTIONAL-N FREQUENCY SYNTHESIZERS
..............................................................................................
Despite their simplicity, the integer-N synthesizers have a major drawback arising from the fact
that the reference frequency cannot be higher than the channel spacing, which is typically
limited to a few hundred kHz, or a few MHz. This in turn sets the upper bound of the loop
bandwidth, which causes several implications on:
Loop Filter
Overall
VCO
Reference
Frequency Offset
Phase Noise
Figure 10.33: Synthesizer typical noise
contributors
4 Periodic steady state simulation in Cadence Spectre RF.
618
PLLs and Synthesizers

– The size of the loop ﬁlter capacitors and resistors
– Synthesizer settling time
– Close-in and far-out phase noise
– Ability to work with any arbitrary crystal frequency
– Reference spurs, and the amount of ﬁltering they could be subject to
The above issues can be alleviated if a fractional divider could be implemented. This in practice
can be devised if the ﬁx divider by N is replaced with a dual-modulus divider by N/N + 1, in
such a way that for several cycles it divides by N, and for several other cycles divides by N + 1.
Then, on average, over a long period of time, a fractional divide ratio of N + α is achieved,
where 0  α  1. The high level concept is illustrated in Figure 10.34, where the modulus
control block is responsible for choosing the divider modulus properly to accomplish the
required fractional divide ratio.
For instance, as a simplest form of modulus control, imagine the divider is programmed to
divide by N for K  1 cycles, and N + 1 for one last cycle, and this repeats periodically. Since
the PLL negative feedback forces the PFD inputs to have the same frequency, then on average
for K cycles of the reference, a divide ratio of
K1
ð
ÞN + N + 1
ð
Þ
K1
ð
Þ + 1
= N + 1
K is achieved, where
0  1
K  1 represents the fraction (α = 1/K).
Example: In the Bluetooth synthesizer of the previous example, we chose KVCO to be
2π  15MHz/V. Assuming a fractional synthesizer with reference frequency of 40MHz,
we set the loop bandwidth to 200kHz now as the channel spacing constraint is removed,
and with ζ = 1, we have RC = 4μS. This leads to a smaller loop ﬁlter capacitance of
C = 200p for the same resistance of R = 20k. Furthermore, with a reference frequency of
40MHz, N = 61, and since
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ICP
2π KVCO
CN
q
= 0:4ω3dB, we ﬁnd ICP = 205μA.
The main drawback of the simple approach outlined in Figure 10.34 is the creation of
fractional spurs. To demonstrate this, shown in Figure 10.35 is a hypothetical example of
dividing by N for three cycles, and by N + 1 for the fourth cycle. Now, assume the PLL
feedback loop forces the output steady-state frequency to be
÷N/N+1
REF
PFD/
CP
Modulus 
Control
Figure 10.34: Fractional-N synthesizer high-level schematic
10.5 Fractional-N Frequency Synthesizers
619

f OUT = f REF
N + 1
K


,
as desired, where fREF is the reference frequency, and for this example K = 4.
For the ﬁrst three cycles of dividing by N, the divider frequency is
f DIV =
f REF
N + 1
K


N
> f REF:
Thus, the PFD starts to generate down pulses to slow down the VCO, which in turn causes
the control voltage to reduce (the reset delay pulses are not shown for simplicity in
Figure 10.35). On the fourth cycle, however, the VCO is divided by N + 1, resulting in
divider output to be slower than the reference, and hence an up signal is created that raises
the control voltage. This pattern repeats every K = 4 cycles, leading to the VCO being
modulated by a periodic signal with a period of f REF
K = α:f REF, and hence creating sidebands
at α. fREF, and its harmonics. On the other hand, to accommodate the desired channel
selection, α. fREF could be as small as the channel spacing, and hence the same limitation as
the integer-N synthesizer exists, that is, the presence of low-frequency spurs as low as the
channel spacing.
10.5.1 Noise Shaping
One very common and elegant technique to deal with fractional spurs is through exploiting the
noise shaping concept widely used in data converters [3], [4].
First, we realize that the periodicity of the control voltage could be broken if the divider
modulus is randomly selected between N and N + 1, but still maintaining the desired
average value. By doing so, the deterministic fractional spurs appearing as tones will be
converted to noise spreading around the VCO signal, with the total energy remaining the
same of course.
We can therefore write the relation between the divider and output frequencies as
f DIV =
f OUT
N + b tð Þ ,
REF
DIV
U
D
VCTRL
÷N
÷N+1
Figure 10.35: Demonstration of fractional spurs due to the periodic
variation of the control voltage
620
PLLs and Synthesizers

where b(t) is a random stream of 0s and 1s with an average value of α. The bit stream can be
then broken up into the desired value, α, and an additive quantization noise, q(t) [5], [6]:
b(t) = α + q(t).
Thus,
f DIV =
f OUT
N + α + q tð Þ =
f OUT
N + α
1 +
q tð Þ
N + α
ﬃf DIV,nom 1  q tð Þ
Nnom


,
where f DIV,nom = f OUT
N + α is the divider nominal frequency, and Nnom = N + α is the nominal divide
ratio. Thus, when referred to the divider output, the normalized instantaneous frequency
departure, y(t), is
y tð Þ =  q tð Þ
Nnom
:
If the spectral density of the quantization noise is Sq( f ), the spectral density of the normalized
frequency departure is
Sy f
ð Þ = Sq f
ð Þ
Nnom2 :
Since phase is the integral of frequency, in terms of phase noise then
Sϕ,DIV f
ð Þ = f DIV,nom
2
f 2
Sy f
ð Þ =
f DIV,nom
Nnomf

2
Sq f
ð Þ:
Note that Sy( f ) is the normalized frequency departure, hence in our derivation above there is the
additional multiplication by fDIV,nom. When referred to the VCO output,
Sϕ,OUT f
ð Þ =
f OUT
Nnomf

2
Sq f
ð Þ =
f REF
f

2
Sq f
ð Þ:
Despite the fact that the randomization process eliminates the fractional spurs, it could still rise
to a substantial amount of phase noise, which is typically unacceptable for most applications.
The latter issue is dealt with by shaping the noise through ΔΣ modulation, as used in the
realization of oversampled data converters [6], [7].
A simpliﬁed block diagram of a 1-bit ΔΣ analog to digital converter (ADC) is shown in
Figure 10.36 to illustrate the concept. It consists of an adder (Σ), an integrator (Δ), a 1-bit ADC
(comparator), and a 1-bit DAC.
Ignoring the ADC quantization noise for the moment, the signal transfer function is
Y
X sð Þ =
1
s
1 + 1
s
=
1
s + 1 ,
which is lowpass. For simplicity it is assumed that the integrator transfer function is 1
s. If the
ADC quantization noise is modeled as an additive source, q(t), at its output, the noise transfer
function is highpass and given by
10.5 Fractional-N Frequency Synthesizers
621

Y
Q sð Þ =
s
s + 1 :
This means that if the signal of interest is lowpass, it passes through ADC, whereas the ADC
quantization noise around low frequencies where the signal resides is suppressed, a very
desirable property.
A digital implementation of the 1-bit ΔΣ modulator above is shown in Figure 10.37. The
analog integrator is replaced with a delay cell in feedback loop. Given that a delay cell has a
discrete-domain transfer function of z1, the discrete integrator transfer function (shown in the
dashed box) is
H zð Þ =
z1
1  z1 :
Commonly used in switched-capacitor ﬁlters [8], this in fact represents the forward Euler s to
z domain conversion, denoted by s $ 1
T z  1
ð
Þ. Since z = ejωT (T is the clock frequency),
H jωT
ð
Þ =
1
ejωT  1 ﬃ
1
jωT ,
as expected.
Since the modulator is implemented digitally, the 1-bit D/A is not required, and ﬁnally the
comparator is replaced by simply a D ﬂip-ﬂop fed by the integrator MSB, discarding all the
other k1 bits of the integrator. Thus, for the k-bit integrator, the input (which is the digital
representation of the desired fractional offset) has k1 bits, and the output is simply 1-bit.
This clearly results in large levels of quantization noise, which is modeled by the additive
noise source shown in Figure 10.38. Similar conclusions to that of the analog modulator of
Figure 10.36 can be made here.
å
∫ 
1-bit ADC
1-bit DAC
Integrator
+ –
x
y
Figure 10.36: A 1-bit analog ΔΣ ADC
Â
K
+ –
Â
D
D
Q
Clk
CK
MSB
b(t)
(0 or 1)
k bits
Z –1/1–Z –1
Figure 10.37: Block diagram of a 1-bit digital ΔΣ
modulator
622
PLLs and Synthesizers

The signal transfer function is
B
K zð Þ =
z1
1z1
1 +
z1
1z1
= z1,
i.e., the output simply tracks the input with a delay, while the noise transfer function becomes
B
Q zð Þ = 1  z1,
which is highpass again.
To ﬁnd the corresponding phase noise, we ﬁrst express the noise in terms of the divider,
N(z) = Nnom + (1  z1)Q(z),
where Nnom = N + α is the fractional divider value as deﬁned earlier, and N(z) is the discrete-
domain divide ratio.5 The output frequency can be expressed in the z-domain as well:
FOUT(z) = N(z)fREF = NnomfREF + fREF(1  z1)Q(z).
The ﬁrst term is the desired output frequency, whereas the second term is the impact of the
shaped quantization noise. What we are interested in is ultimately the phase noise, which
is the integral of frequency. In continuous form, the phase noise is ϕOUT =
Ð
ωOUT(t)dt = 2π
Ð
fOUT(t)dt, which in the discrete domain translates to
ΦOUT zð Þ = 2π
T
z  1 f REF 1  z1


Q zð Þ:
Or, the noise spectral density,
Sϕ,OUT f
ð Þ =
2π
z  1


2
1  z1

2Sq f
ð Þ,
where z = ejωT = ej2πfT.
The term |1  z1|2 = 4|sin(πfT)|2 is the noise shaping function, which is highpass as
expected. Consequently, the quantization noise is suppressed around DC as desired. The noise
suppression function (4|sin(πfT)|2) has been plotted in Figure 10.39.
K
q
b
Â
Figure 10.38: Simple equivalent model of
the 1-bit digital ΔΣ modulator
5 To distinguish from the dual-modulus divide ratio N, we are using a bold notation for N(z).
10.5 Fractional-N Frequency Synthesizers
623

Finally, assuming a 1-bit quantizer has a uniform quantization error, the error power is then
δ2
12, where δ is the minimum step size of the quantizer [4]. Because we are quantizing to integers,
δ = 1, and the quantization error power is 1
12. Since this power is spread over a bandwidth of
fREF, the power spectral density of noise is
Sq f
ð Þ =
1
12f REF
:
10.5.2 Higher Order ΔΣ Modulators
The integrator stage of the ΔΣ modulator introduces a zero at the origin, thus noise shaping
the quantization noise in the frequency domain. For the 1st-order ΔΣ modulation illustrated in
Figure 10.37, the integration applied when converting from frequency to phase removes
the zero from the noise-shaping function. That is evident from the phase noise expression
derived earlier:
Sϕ,OUT f
ð Þ =
2π
z  1


2
1  z1

2Sq f
ð Þ = 2π
ð
Þ2Sq f
ð Þ =
2π
ð
Þ2
12f REF
:
Furthermore, the 1st-order ΔΣ modulation also fails to randomize the quantization error
[9], and consequently spurious frequency components become a problem. However, a
second or higher order of integration can be used to reduce the practical impact of this
periodicity as demonstrated by numerous ΔΣ modulator structures used in oversampled
data converters [7]. An example of a 2nd-order ΔΣ modulator implementation is shown in
Figure 10.40.
The noise shaping function is derived the same way as the 1st-order modulator (see
Problem 7). Ignoring the input, with only the quantization noise present, the output will be
1st-Order D−S noise suppression
f
1/2T
4
Figure 10.39: Noise suppression in a 1st-order ΔΣ modulator
S
D
S
1/1–Z–1
K
+ –
S
D
k bits
Z–1/1–Z–1
S
+ –
D
Q
Clk
CK
b
Figure 10.40: An example
of a 2-bit ΔΣ modulator
624
PLLs and Synthesizers

B
Q zð Þ = 1  z1

2:
Consequently, the noise shaping function will be |2 sin(πfT)|4. Shown in Figure 10.41 is a
comparison between the 1st- and a 2nd-order noise shaping functions.
A 2nd-order noise shaping enjoys lower in-band noise levels, but the far-out noise rises more
rapidly. This is potentially an issue for many applications where the far-out noise is important
and is dealt with in Section 10.5.3.3.
It is certainly possible to add more integrator stages to obtain sharper noise suppression.
However, feedback loops containing more than two integrators are potentially unstable,
requiring various stabilization techniques [7]. In general, for an mth-order modulator, it can
be shown that the phase noise spectral density is
Sϕ,OUT f
ð Þ =
2π
ð
Þ2
12f REF
2 sin πfT
ð
Þ
j
j2 m1
ð
Þ ﬃ2π
ð
Þ2m
12f REF
f
f REF

2 m1
ð
Þ
:
An alternative approach to avoid stability concerns is to take advantage of cascade of stages as
shown in Figure 10.42. Here, a subtractor ﬁnds the difference between the input (a1) and the
output (b1) of the ﬁrst quantizer. If this is applied to another 1st-order ΔΣ modulator (shown
in the dashed box), we expect the quantization error to be less.
D−S noise suppression
f
1/2T
16
4
1st-order
2nd-order
Figure 10.41: A comparison between the 1st- and
2nd-order noise shaping in ΔΣ modulators
S
D
D
Q
Clk
CK
k+1 bits
S
K
+ –
S
D
D
Q
Clk
CK
k bits
S
+ –
S
+ –
Combiner
2 bits
k bits
1 bit
1 bit
b1
b2
a1
Integrator1
Integrator2
(MSB)
(MSB)
Figure 10.42: A 1-1 cascaded ΔΣ modulator
10.5 Fractional-N Frequency Synthesizers
625

Modeling the quantization noise of each stage as an additive source at the output of each
D ﬂip-ﬂop as we did before, we can write
B1 = Kz1 + (1  z1)Q1
B2 = Q1z1 + (1  z1)Q2,
where Q1 and Q2 are the quantization noise of each stage. Note that the input to the second
stage, B1  A1, is actually the quantization noise of the ﬁrst stage. The quantization noise of the
ﬁrst stage can be eliminated if B1 is multiplied by z1, and B2 is multiplied by (1  z1) and the
two are subtracted inside the combiner. Then the 2-bit combiner output (Bcombiner) will be
Bcombiner = Kz2  (1  z1)2Q2,
which has the same noise shaping as a 1-bit 2nd-order ΔΣ modulator has.
The cascaded structures (also known as MASH) can achieve higher order of noise shaping
without the risk of instability. They need multi-modulus dividers, however, as the output
has more than one bit. For instance, the MASH 1-1 structure of Figure 10.42 requires division
by N  1, N, N + 1, and N + 2.
10.5.3 ΔΣ Modulator Nonideal Effects
In this section we discuss several issues associated with fractional synthesizers and ΔΣ
modulators.
10.5.3.1 Low-Frequency Tones and Dithering
Consider the 1st-order ΔΣ modulator of Figure 10.37. The input K is a (k – 1)-bit digital
signal fed to the digital integrator. If this input is constant, it is easy to see that the modulator
output is not really random (though the quantization noise is still shaped). Depending on the
value of K, the repetitive pattern that exists in the output (also known as limit cycle)
ultimately leads to spurious tones, which if lying within the PLL bandwidth, will not enjoy
PLL ﬁltering.
This is shown in Figure 10.43, where for a small K, the signal at the integrator output starts to
build up slowly in small increments, producing a low-frequency pulse at the ΔΣ modulator
output. The average value of the pulse naturally represents the small fraction set by K, but
creates a low-frequency spur in the VCO output.
The simple ﬁx is to break the periodicity, say toggle the LSB of K randomly between
0 and 1. Known as dithering, this will eliminate the spur but introduces some noise whose level
is usually low and acceptable in many cases.
10.5.3.2 Charge Pump Nonlinearity
As we discussed in Section 10.3, the PFD/CP charge-phase characteristic is not perfectly linear,
due to a number of reasons, such as up and down current mismatches or channel length
modulations. This nonlinearity typically leads to excess in-band noise and spurious tones
[10], [11].
626
PLLs and Synthesizers

To understand the sources of nonlinearity better, consider a simple charge pump with
different up and down currents of IUP and IDN (Figure 10.44). The difference arises from
several factors, such as random mismatches or channel length modulation, though the latter is
often dominant.
During the ﬁrst pulse, since the reference is leading the feedback divider, an up signal is
created, leading to a positive net charge pump current going to the loop ﬁlter. There is a small
period of time (τ in Figure 10.44) when both up and down current sources are on due to the PFD
reset delay. The total charge going to the loop ﬁlter is then
QOUT = IUPT1 + (IUP  IDN)τ,
where T1 is the reference lead time. The second term above will not exist if the up and down
currents are equal, while in the ﬁgure, exaggeratedly an up current of twice the down has been
assumed. Regardless, this term leads to only a small phase difference between the reference and
the divider outputs once the loop is locked.
In the next pulse, if the divider is now leading (say by the same amount T1), and the total
output charge delivered becomes
QOUT =  IDNT1 + (IUP  IDN)τ.
t
b
a
k
K
Â
Â
D
t
Tspur
Figure 10.43: Limit cycles in ΔΣ modulator
REF
DIV
UP
DN
ICP
t
T1
UP
DN
OUT
T1
τ
IUP
IDN
VDD
Figure 10.44: Charge pump
nonlinearity due to unequal up and
down currents
10.5 Fractional-N Frequency Synthesizers
627

It is clear from the equations and the ﬁgure that the charge delivered to the loop ﬁlter is
exhibiting nonlinearity, unless IUP = IDN. The charge pump total charge versus the PFD inputs
delay time is plotted in Figure 10.45. The slope of the curve is obviously changing depending
on whether the reference is leading or lagging.
Recall that the main advantage of using a ΔΣ modulator is its ability to shape the noise
favorably, that is, the noise is moved to higher frequencies (Figure 10.39), which will be
subsequently attenuated by the loop ﬁlter. However, this is true only in the context of a PLL
linear model as has been previously developed. The presence of any nonlinearity results in
noise folding and could increase the PLL in-band noise signiﬁcantly.
To improve this, one can use the feedback charge pump circuit shown in Figure 10.23,
although still the random mismatches could cause unequal up and down currents, which is of a
lesser importance and can be alleviated by increasing the transistors sizes. As we said, the main
drawback of the feedback circuit is the need for a rail-to-rail input opamp, which adds noise and
power consumption.
Another common way to avoid the nonlinearity is to shift the charge pump characteristic
away from the origin by adding a constant offset current (in either direction) as shown in
Figure 10.46.
Example: To ﬁnd the amount of shift (TOFF in Figure 10.46), let us examine the PFD input
signals in the presence of such an offset, but let us assume that the PLL is locked. As shown
in Figure 10.47, given that the offset current (IOFF< I0 in Figure 10.46) is positive, the
Q CP
DTPFD
IUP
IDN
(IUP–IDN)t
Figure 10.45: The charge pump characteristic is nonlinear in the presence
of different up and down currents
UP
DN
OUT
IUP
IDN
VDD
VDD
IOFF
QCP
DTPFD
IUP
IDN
TOFF
DS Operaon
Figure 10.46: Adding an offset
current moves the charge pump
output away from the nonlinear
region
628
PLLs and Synthesizers

divider leads the reference, and the corresponding down pulse will result in a current of
IOFF  I0 lasting TOFF seconds, which will offset the continuous current of IOFF for the
remainder of the cycle. We have assumed for simplicity IUP = IDN= I0, but the same
conclusion may be drawn for the more realistic case of unequal currents. Therefore,
IOFFTREF = I0TOFF, or
TOFF = IOFF
I0
TREF,
where TREF is the reference signal period.
Note that in practice, unlike the integer PLLs, the inputs of the PFD are not perfectly aligned
at the same point in every cycle even in the locked condition. Due to this phase (or time) skew,
the offset current must be sufﬁciently large to stay away from the origin given the largest skew
possible (Figure 10.46). Fortunately, for a given ΔΣ modulator design, the time skew is
predictable and can be planned for accordingly. Increasing the number of bits or the order of the
ΔΣ modulator generally causes more vulnerability to charge pump nonlinearity given a larger
skew. See Problem 11 for an example.
The main drawback of the offset current is creation of more noise from the charge up as it
stays on longer, and more ripple on the control voltage. Interestingly, in integer PLLs unequal
up and down currents do not result in excess noise, but only lead into reference spurs as
demonstrated earlier in Figure 10.22.
10.5.3.3 Out-of-Band Noise
It must be emphasized that the ΔΣ modulation does not change the total noise energy, rather
the noise shaping just shifts the noise from low frequencies to high frequencies. This is certainly
problematic for many applications where far-out phase noise is important. However, since the
ΔΣ modulator enjoys the same lowpass loop suppression as the divider or reference do, the
high-frequency noise is subject to the inherent ﬁltering provided by the PLL (Figure 10.48). So
overall, the ΔΣ output noise will be
REF
DIV
UP
DN
ICP
t
TREF
IOFF
IOFF–I0
0
VCTRL
TOFF
Figure 10.47: PFD input signals in locked mode
when there is an offset current in charge pump
(Figure 10.46)
10.5 Fractional-N Frequency Synthesizers
629

Sϕ,OUT,PLL( f ) = Sϕ,OUT( f )|HPLL( f )|2,
where HPLL( f ) is the PLL lowpass transfer function, and Sϕ, OUT( f ) is the ΔΣ output referred
noise calculated earlier.
There is likely some peaking outside the PLL 3dB bandwidth, where the PLL suppression is
not sufﬁcient to balance the sharp rise of the ΔΣ modulator noise. This alone may not be
much of a problem, depending on the other PLL noise contributors in that region, especially the
VCO, which could be dominant. Nonetheless, the noise shaping must be carefully evaluated to
ensure that the ΔΣ modulator noise contribution is within the requirement at all the offset
frequencies.
Higher order ΔΣ modulators that enjoy a lower in-band noise experience a potentially
higher far-out noise considering a more steep increase of the noise proﬁle.
As an example, assuming a simple RC loop ﬁlter like the one in Figure 10.20, the PLL
closed-loop transfer function was shown to be
HPLL f
ð Þ
j
j2 = ωn
4
1 + 2ζωωn
ð
Þ2
ωn2  ω2
ð
Þ2 + 4ζ2ωn2ω2 ,
where ω = 2πf. Note that the divide ratio (N) has been dropped from the equation as the ΔΣ
modulator noise is already referred to the output. So the overall phase noise at the PLL output
assuming a 2nd-order ΔΣ modulator is
Sϕ,OUT,PLL f
ð Þ =
2π
ð
Þ2
12f REF
2 sin πfT
ð
Þ
j
j2ωn
4
1 + 2ζωωn
ð
Þ2
ωn2  ω2
ð
Þ2 + 4ζ2ωn2ω2 :
While at far-out frequencies the PLL rolls off with a slope of f2, the 2nd-order modulator noise
rises with the same slope, and the noise is expected to plateau. In practice, the loop ﬁlter looks
more like the one shown Figure 10.21, which results in ample noise suppression at very high
frequencies.
10.6 FREQUENCY DIVIDERS
..............................................................................................
The need for programmable divider in synthesizers has been already established. In this section,
we will discuss a few common circuit ideas to realize these dividers.
D−S noise through PLL
f
1/2T
PLL TF
D−S noise suppression
Overall
Figure 10.48: The noise of ΔΣ modulator subject to the PLL
lowpass ﬁltering
630
PLLs and Synthesizers

10.6.1 Latches and D Flip-Flops
A latch is the basic building block of any frequency divider. The latch may be implemented
using standard CMOS logic. Shown in Figure 10.49 is an example of such implementation. It
takes an input (D), a complementary clock signal (CK, CK), and has an output (Q). The latch
consists of an input inverter enabled by the clock, followed by two inverters back to back
creating the latch function.
When the clock is on, the inverter is enabled, and the latch is transparent, that is, Q = D.
When the clock turns off, the input inverter is disabled, and the value it had at that instant of the
clock going low is stored in the back-to-back inverters. The positive feedback enforced in the
back-to-back inverters makes sure that the output holds its state despite the input being
disconnected. The latch of Figure 10.49, given its simplicity, works quite well up to several
tens of GHZ in current nanometer CMOS processes, and is widely adopted.
Shown in Figure 10.50 is the dynamic realization of the latch, where the back-to-back
inverters are removed. The (parasitic) capacitance at the latch output is in principle sufﬁcient
to hold the output when the clock is disabled. This would naturally lead to somewhat higher
speed, but the output may be easily disturbed by any noise or interference (such as one on the
supply), which may not desirable.
An analog version of the CMOS latch of Figure 10.49 is shown in Figure 10.51, often
referred to as a current-mode logic (CML) latch. There are several attributes that potentially
make the CML latch faster:
• It comprises only NMOS transistors, which are traditionally faster. This is however not true
for the more recent CMOS processes (28nm and beyond, including Fin-FET), where N and
P FETs are almost equal.
• The resistive load leads to less parasitic at the output, hence a higher speed. This again is not
necessarily the case in the recent CMOS nodes where the PMOS transistors are as good
as NMOS.
• The current-mode differential pairs are faster to turn on and off, and require less voltage
swing. This is analogous to the active versus passive mixer speed trade-offs discussed in
Chapter 8.
D
CK
Q
CK
Q
Latch
Figure 10.49: Schematic of a static CMOS latch
10.6 Frequency Dividers
631

Apart from design complexity, the main drawback of the analog topology is headroom and
consumption of static power. The former especially is important considering the trend of
reducing supply voltage at lower nodes of process. It is not uncommon to remove the tail
current source (Mb in the ﬁgure) to alleviate the headroom concerns.
The latch functionality is very similar to that of the CMOS version shown in Figure 10.49.
When the clock is high, the pair M2–MM2 is enabled, acting like an analog inverter along with
the load resistors, and the latch is transparent. When clock goes low, the input inverter is
disabled, and the cross-coupled pair (M3–MM3) hold the output through enforcing the positive
D
CK
CK
Q
Figure 10.50: Dynamic CMOS latch
VDD
CK
CK
D
D
Q
Q
M1
MM1
M2
MM2
M3
MM3
RD
RD
Mb
Bias
Figure 10.51: An analog current-mode latch
632
PLLs and Synthesizers

feedback. The size of the cross-coupled transistors must be chosen such that the negative
resistance created due to the positive feedback dominates the load resistance.
Two latches put back to back with opposite clocks form a D ﬂip-ﬂop (DFF), as shown in
Figure 10.52. Shown also in the ﬁgure is the timing diagram of the output (Q) versus the input
and clock. In this example, the output is latched at the positive edge of the clock.
A circuit level example of the D ﬂip-ﬂop using the dynamic latches is shown in Figure 10.53.
Once put in a feedback loop, the D ﬂip-ﬂops becomes a divide-by-two circuit as shown in
Figure 10.54, where the Q output is fed back to the D input. The corresponding timing diagram
is shown on the right.
When the clock (input) goes high, the ﬁrst latch is transparent, and sees the output of the
second latch, which is low, and since Q of the second latch is fed back, it goes high. When the
L1
CK
D
Q
L2
CK
D
Q
CK
D
Q
CK
CK1
CK2
D
Q
Figure 10.52: D ﬂip-ﬂop formed with two back-to-back latches
D
CK
CK
CK
CK
Q
Figure 10.53: A dynamic CMOS ﬂip-ﬂop
D
Q
Clk
Q
IN
L1 OUT
IN
OUT
L2 OUT
TP L
TP L
TP
L
TP
L
Figure 10.54: Divide-by-2 using a toggle
ﬂip-ﬂop (ﬂip-ﬂop in a feedback loop)
10.6 Frequency Dividers
633

input goes low, the high logic is latched in the ﬁrst, and the second latch output, which is now
transparent, goes high. Once the clock goes back up the output, which is high, is latched, and a
low is fed back to the input latch, which is now transparent. Consequently, the latch outputs are
at half the frequency of the input as desired.
For the divider to function properly, the delay of one latch must be less than half the input
signal period as depicted in Figure 10.55.
Once the input goes high, the ﬁrst latch is transparent, and its input is expected to go up, but
with some delay in practice (Δ1 in the ﬁgure). This signal must be ready before the second latch
becomes transparent, which is when the input goes back low, or else the divider fails. In 16nm
CMOS for instance, the CMOS latch (Figure 10.49) delay is of the order of tens of pS, and thus
the divider functions up to tens of GHz comfortably.
10.6.2 Dual-Modulus Dividers
With the D ﬂip-ﬂops used as the main building block, and with the aid of a few simple gates, we
can construct the dual- or multi-modulus dividers that are needed in the synthesizer design.
A few examples will be covered in this section.
Example: Shown in Figure 10.56 is a programmable divider by 2 or 3 widely used in
synthesizers. Also shown is the divider timing diagram for the case of dividing by 3. The
CK
L1 OUT
L2 OUT
∆1
D2
Figure 10.55: Speed concerns in a divide-by-2 circuit
D
Q
Clk
Q
D
Q
Clk
Q
(÷ 2/3)
IN
Q1
Q2
MC
A1
O1
IN
Q1
A1
1
2
3
Q2
MC = 0 maers
Q2
Figure 10.56: An example
of a divide-by-2/3 circuit
and the corresponding
timing diagram
634
PLLs and Synthesizers

signal MC sets the divide ratio. If MC = 1, the OR output, O1, is high all the time, so the
ﬁrst DFF is invisible from the second DFF, which is conﬁgured to act like a divide-by-2
as A1 = Q2.
With MC= 0, O1 = Q1, so the OR is effectively disabled, and the back-to-back D ﬂip-
ﬂops create a divide-by-3. Without the AND gate, the reader can easily show that the back-
to-back ﬂip-ﬂops put in a feedback loop (Q2 connected to the ﬁrst DFF input) create a
divide-by-4 circuit. The AND, however, causes the output to go high one cycle earlier,
effectively realizing a divide-by-3 as shown in the timing diagram. Assuming positive edge
D ﬂip-ﬂops with some nonzero delay, we start with all the outputs at zero (Q1 = Q2 = 0,
Q2 = 1). When the ﬁrst clock edge arrives, Q1 goes high, since the ﬁrst DFF input, Q2, is
high. On the other hand, the AND output (A1) has been zero, and given the gate delays, the
second DFF remains to see zero at the clock edge, and thus Q2 remains zero. Now, both of
the AND input are high, and thus at the second clock edge, Q2 goes high (Q2 goes low after
some delay). Since right at the second clock edge Q2 is still high, Q1 remains high. At the
third clock edge, since Q2 is low, so is the AND output, which results in Q2 going low or
Q2 going up. This means that at the fourth clock edge, Q1 will go back high, resulting in a
divide-by-3. Without the AND, Q2 would have remained high (Q2 low) at the third clock
edge, resulting in Q1 to remain low at the fourth clock edge. It is interesting to point out that
at the ﬁrst two clock cycles, since Q1 is high, the state of MC is unimportant. It is only at the
third input cycle that MC must be zero to realize a divide-by-3. This becomes important in
cases that the divide-by-2/3 will be used to create more complex dual- or multi-modulus
dividers. We will discuss a few examples of this shortly.
As a simple rule of thumb, to create a certain divide ratio, n, the number of latches needed is
usually chosen such that 2n is the closest integer larger than the desired divide ratio, e.g.,
two latches for a divide-by-3, or three latches for a divide-by-5, or 6.
Example: As a second case study, shown in Figure 10.57 is a divide-by-4/5 circuit [12].
If MC = 0, N2 is high, and the third DFF output is always high. Thus, N1 = Q2, and the
output (Q2) divides the input by four.
Continued
D
Q
Clk
Q
D
Q
Clk
Q
D
Q
Clk
Q
IN
Q1
Q2
Q3
N1
N2
(÷ 4/5)
MC
Figure 10.57: Divide-by-4/5 circuit
10.6 Frequency Dividers
635

On the other hand, if MC = 1, N2 = Q2, and we have the ﬁrst two D ﬂip-ﬂops in
feedback, with the addition of Q3 appearing at the ﬁrst DFF through the N1 AND gate.
The timing diagram (starting from reset point) is shown below in Figure 10.58, and is self-
explanatory.
Note that Q2 is following Q1 with one input cycle delay, and Q3 is following Q2 with
one input cycle delay.
Example: Figure 10.59 shows a divide-by-8/9 circuit [13]. The divider operation can be
analyzed much the same way as the examples before. With MC = 0, the divide-by-2/3
operates in divide-by-2 mode, followed by two other divide-by-2s (the second and third
D ﬂip-ﬂops in feedback), resulting in a cascaded divide-by-8 circuit. If MC = 1, the circuit
will divide by 9, and the analysis is left to the reader.
Several other examples of divider circuits may be found in [12], [14], [15].
Q1
Q2
Q3
IN
Figure 10.58: Waveforms of the divide-by-5 circuit of
Figure 10.57
D
Q
Clk
Q
D
Q
Clk
Q
÷2/3
MOD
IN
OUT
Q1
Q2
Q3
(÷ 8/9)
MC
Figure 10.59: Divide-by-8/9
636
PLLs and Synthesizers

Example: As the ﬁnal example for this section, shown in Figure 10.60 is a divide-by-4
circuit that creates an 8-phase LO for an 8-phase blocker tolerant receiver [16], [17],
employing a shift register-based (or Johnson) divider. Note that the divider is not a part of
the frequency synthesizer, rather it is used to create the proper LO signals for the receiver
mixer directly from the VCO.
One register cell stores a logic high, while all other registers store a low. The input, at
four times the output frequency, moves this logic high along the register to generate the
required 8-phase nonoverlapping clocks. The register cell is designed with the following in
mind: a negative clock transition should propagate a high present at the D input, while a
positive clock transition should always pull the output low. The logic high is propagated via
the internal node. This node is pulled low by input when the previous stage output is high,
while inputs precharge the internal node and enforce the condition that only one register
outputs a high at any given time. Importantly, this internal node enables the pull-up PMOS
transistor only in the output stage, and so the transistors to the left of ideally contribute no
phase noise. The output of each cell is triggered by one of the high-frequency clocks, and the
same clock triggers output clocks offset by 180 (in fact, every other cell is triggered by the
Continued
start_up
Q
int
Single NMOS is only 
significant uncorrelated 
noise source
1
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO0
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO1
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO2
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO3
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO4
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO5
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO6
D
Q
Qb+1
int
Qb
Qb+2
Qb+3
Qb+4
LO7
4*FLO
0
0
0
0
0
0
0
Qb+4
Qb+3
Qb+2
Qb+1
HF_b
D
clk
Qb
clk
These devices do not contribute 
any phase noise
PMOS is shared 
between differential 
LOs →   Noise is 
correlated
Register Cell
Figure 10.60: An 8-phase divide-by-4 to generate receiver LO
10.6 Frequency Dividers
637

same high-frequency clock). This retiming limits the source of uncorrelated noise between
clocks offset by 180 to the single highlighted NMOS device, thereby limiting the deterior-
ation in noise ﬁgure from LO-to-RF coupling. Because a master clock strobes every stage, the
phase noise of the circuit is also very low and was simulated at less than –172dBc/Hz at an
80MHz offset from a 1.5GHz carrier. The divider is functional from 80MHz up to 2.7GHz
(limited by the capacitive load of the mixer switches), and consumes between 3 and 36mA.
Half this current is dissipated in the high-frequency buffers. As the divider employs rail-to-
rail CMOS logic, the LO power consumption is proportional to frequency (13.3mA/GHz).
The dual-modulus dividers presented earlier are not directly usable in integer or fractional
synthesizers, given that typically much larger divide ratios are needed. They can, however, be
used to create programmable multi-modulus dividers, which are discussed next.
10.6.3 Multi-Modulus Dividers
A widely used programmable multi-modulus divider (MMD) consisting of several divide-by-2/3
stages presented earlier (Figure 10.56) is shown in Figure 10.61. By choosing the 3-bit program-
ming word, M2M1M0, a programmable divide ratio of 8 to 15 can be achieved. The timing
diagram for the case of divide-by-15 is shown as well. At the very ﬁnal output, a D ﬂip-ﬂop is
inserted to retime to the input, a common technique to relax the noise requirement of the divider
intermediate stages.
To analyze the MMD, for the moment let us ignore the ﬁnal D ﬂip-ﬂop, and suppose M2M1M0
= 111. Starting from zero state, with the input rising edge, all the dividers outputs (Q1, Q2, and Q3)
go high. With both Q2 and Q3 as well as M0 high, the ﬁrst divider is going to divide-by-3 (the MOD
port is zero, see Figure 10.56), and the input remains low for the third input cycles as shown in
Figure 10.61 timing plot. At the fourth input edge, Q1 which is effectively the clock of the second
divider goes high, which causes Q2 to go low. The third divider output remains high, until the
second rising edge of Q2 which acts as its input. With Q3 and M1 high, the second divider divides
÷2/3
MOD
÷2/3
MOD
÷2/3
MOD
D
Q
Clk
Q
M0
M1
M2
Q1
Q2
Q3
IN
OUT
Reming
Q1
Q2
Q3
IN
M0
M1
M2
IN
Q3
OUT
Figure 10.61: Multi-modulus divider using a cascade of divide-by-2/3s
638
PLLs and Synthesizers

by 3 as well, staying low for two cycles of Q1, which is equivalent to four cycles of the input, as the
ﬁrst stage is now dividing by 2, given that Q2 is low. Once Q2 goes high, Q3 goes low and will
divide by 3 as M2 is high, skipping two cycles of Q2, or four cycles of Q1, or eight input cycles.
Note that with Q3 going low and staying low for the remainder of the output, the second stage will
divide by 2. So overall one output cycle is worth 3 + 4 + 8 = 15 input cycles.
With any of modulus control bits zero, the MOD input of the corresponding divide-by-2/3
will be high, and thus it will act like a divide-by-2. The reader can easily work out the other
combinations, and show that the modulus can be programmed as follows,
N = 8 + 20M0 + 21M1 + 22M2,
providing a divide range of 8~15. The design can be extended to create any arbitrary divide
ratio through cascading more stages and with the aid of the necessary logic. Since each
subsequent divider operates at at least half the frequency, its size and power may be scaled,
leading to a very efﬁcient design at GHz frequencies. The circuit or its variations are commonly
used in fractional synthesizers.
The purposes of the last D ﬂip-ﬂop is to retime the output with the clean input, and reduce the
accumulated noise through several stages of the divider. The corresponding timing diagram is
shown on the bottom right. When the clock edge arrives, the output of the last divider (Q3) goes
high after some delay. Assuming this delay is less than one input cycle, the actual output will be
latched at the rising edge of the next input cycle, and whose jitter will only depend on the last ﬂop
noise and the input itself, thus effectively bypassing the noise of the rest of the divider.
Another widely used multi-modulus divider, especially in integer synthesizers that need very
large divide ratios, is shown in Figure 10.62, commonly known as a pulse-swallow divider.
It consists of a dual-modulus divide-by-N/N+1 (any of the circuits of Figure 10.56,
Figure 10.57, or Figure 10.59 for example), or a programmable swallow counter (S in the
ﬁgure, it essentially divides its input [the dual-modulus divider output] by S)), and a pulse
counter (P in the ﬁgure, which divides the dual-modulus output by P). Usually N and P are
ﬁxed. After the reset, the swallow counter output is zero, and the dual-modulus divider divides
by N + 1 until the swallow counter is full, that is, after S  (N + 1) cycles of the input. Once full,
it ﬂags high, resulting in the dual-modulus divider (also known as prescaler) to divide by N,
while the swallow counter starts from 0. Thus far, the program counter has counted S cycles of
the prescaler, and has another P  S cycles to ﬁll up (naturally the design requires P > S). After
(P  S)  N additional cycles of the input (recall that the prescaler is dividing by N), the
÷N/N+1
MOD
÷P
÷S
IN
OUT
Reset
Pulse Counter
Swallow Counter
N+1
N
Reset
S×(N+1)
(P-S)×N
Swallow counter 
is full
Pulse counter 
is full
Figure 10.62: Pulse-swallow multi-modulus divider
10.6 Frequency Dividers
639

program counter ﬁlls up, after which point resets everything. So the output has counted overall
[S  (N + 1)] + [(P  S)  N] = NP + S cycles.
Example: For the example of the Bluetooth integer-N synthesizer, recall that the divide ratio
required must be between 2402 to 2480. This can be accomplished for instance by using a
divide-by-4/5, a program counter of P = 480, and a programmable swallow counter of
S = 2~80. The counter is realized by cascading of several shift registers (ﬂip-ﬂops basically).
10.7 INTRODUCTION TO DIGITAL PLLs
..............................................................................................
We have dedicated this section to present a brief overview on digital PLLs. More information
on the digital PLL fundamental design and trade-offs may be found in [18].
Before discussing digital PLLs (DPLLs) details, let us review several important limitations of
the analog PLLs ﬁrst.
– Depending on the noise requirements and the frequency of the reference, the size of the loop
ﬁlter can become large. While the capacitors do scale with technology, still their size does not
reduce as favorably as the digital gates.
– Often a large charge pump current is required to achieve a low in-band phase noise.
– PFD/CP linearity could be a concern for certain applications.
– There is an important trade-off between the noise contribution of the PLL building blocks, and
particularly the VCO and the ΔΣ modulator. As explained earlier, the ΔΣ modulator noise
follows the PLL lowpass transfer function, while the VCO noise transfer function to the output
is highpass. As often the VCO is the most power consuming part of the synthesizer, it may be
quite beneﬁcial to increase the loop bandwidth of the PLL to suppress the VCO in-band phase
noise contribution, and hence reduce its power consumption. For a given integration band-
width, this in turn will result in the noise contribution of the reference and particularly the ΔΣ
modulator to increase. This trade-off is illustrated in Figure 10.63, where the same PLL noise
contributors, and most notably the VCO and ΔΣ modulator, are highlighted for two loop
bandwidths of 350kHz and 800kHz, with everything else the same. While increasing the loop
D−S Noise
VCO
350kHz Loop BW
D−S Noise
VCO
800kHz Loop BW
Overall
Overall
Figure 10.63: Analog PLL noise for two different loop bandwidths and ΔΣ noise impact
640
PLLs and Synthesizers

bandwidth does reduce the VCO contribution, the ΔΣ modulator noise especially at far-out
frequencies substantially go up. On the other hand, if somehow the modulator noise could be
cancelled, a wider loop leads to considerable power saving in VCO and the overall PLL.
Considering that many of the analog PLL building blocks are pseudo-digital (e.g., phase
detector), one may consider devising a digital version as depicted in Figure 10.64.
Instead of a phase detector, one could use a time-to-digital converter (TDC) which effectively
measures the inputs (reference and MMD output) time difference, and creates a proportional digital
output. This signal now can be processed digitally and fed back to the VCO. The VCO however can
only take a digital control line (hence often called digitally controlled oscillator), which could be
accomplished either through a switchable cap array, or by inserting a DAC and feeding the
corresponding analog signal to the varactor. This arrangement offers several advantages:
– The loop ﬁlter and phase detection (TDC) are all digital, which could potentially occupy a
smaller area in general, but more importantly their area and performance scales with
technology.
– The noise (and spurs) of the ΔΣ modulator can be digitally corrected.
The ΔΣ modulator noise cancellation is conceptually depicted in Figure 10.65. The phase error
Φe is estimated by integrating the quantization error at the ΔΣ modulator output (Q(z)), which is
known beforehand. This phase error can be subtracted from the TDC output to cancel. The
quantization error Φe will pass through a highpass ﬁlter (HPF) to ﬁlter out DC, and is correlated
PFD/CP
REF
R
C
MMD
TDC
REF
MMD
Digital 
LF
Simpliﬁed Analog PLL
Simpliﬁed Digital PLL
DCO
Figure 10.64: A simpliﬁed block diagram of a digital PLL, and comparison to its analog counterpart
TDC
LF
S
MMD
D−S
Q(z)
Fe
∫
Re
HPF
HPF
Correlator
∫
Re
Figure 10.65: Illustration of noise cancellation
in a digital PLL
10.7 Introduction to Digital PLLs
641

with the residual error Re. If there is any residual error, the correlator output will have nonzero
average output, which will be integrated to control the gain correction block after the TDC. Note
that the perfect cancellation of the modulator noise requires the exact knowledge of the phase
detector (or TDC) gain, which can be effectively corrected through the calibration loop as shown.
While this can be done at least conceptually in the analog PLL as well, it proves to be a lot
more convenient in the digital domain, and in the context of a digital PLL. The main limitation
of analog implementation is the need for a very linear and low-noise DAC to inject the error to
the loop ﬁlter, whereas this can be done much more efﬁciently in the digital domain.
In the remainder of the section, we will brieﬂy discuss the digital PLL building blocks in
more details.
10.7.1 Time-to-Digital Converters
The TDC may be thought of an ADC except for its input is time rather than voltage. As such,
the TDC creates some quantization noise that will ultimately limit the overall PLL phase noise.
Similar to an ADC, the TDC quantization noise is shown to be ΔTres2
12 , where ΔTres is the TDC
resolution. This noise is usually uniformly spread between  f REF
2 , and thus the TDC quantiza-
tion noise spectral density is
Sq f
ð Þ = ΔTres2
12f REF
:
Similar to the noise of the ΔΣ modulator, the noise spectral density of the TDC when referred
to the PLL output is shown to be
Sϕ,OUT f
ð Þ = ΔTres2
12f REF
2πf REF
ð
Þ2 HPLL f
ð Þ
j
j2  2πΔTres
ð
Þ2
12
f REFN2,
considering that for in-band noise, |HPLL( f )|2  N2.
Example: Consider a 4GHz digital PLL for LTE applications, where the reference
frequency is 40MHz. Assuming an in-band phase noise of –120dBc/Hz is budgeted for
the TDC, we can write
120 = 10 log
2πΔTres
ð
Þ2
12
f REFN2
"
#
:
With N = 100 and fREF = 40MHz, the TDC resolution is found to be ΔTres = 0.87pS.
10.7.1.1 TDC Circuit Realization
Below we will discuss a few examples of TDC circuit implementation.
Shown in Figure 10.66 is a delay line TDC circuit. Using the same notation as before, we
label the TDC input signals as A and B (typically representing the reference and MMD output)
642
PLLs and Synthesizers

with the corresponding timing diagram. Once the input A arrives, a sequence of the signal along
with its delayed replica are fed to an array of D ﬂip-ﬂops. When the B input arrives, only the
ones that have received a high signal at their input are triggered high. Naturally, when
the outputs of DFFs are decoded, they will represent the delay between the rising edges of
the A and B inputs, which is precisely what we are looking for.
Obviously, the TDC resolution is limited by the minimum delay of each delay cell.
Furthermore, the mismatch between various delay cells could create nonlinearity.
Another TDC realization based on an oscillator and a counter is shown in Figure 10.67.
Shown also in the ﬁgure is the corresponding timing diagram. For the moment, let us assume
that the enable signal turning the ring oscillator on is always high. The counter start and stop
point are determined by the rising edges of the input signals, and what is counted is the number
of the cycles of the ring oscillator. Note that in either implementation the exact value of the
phase or time difference is not going to affect the PLL locking functionality; however, it will
affect the loop dynamics, as will be discussed in Section 10.7.4. Same as the previous TDC, the
resolution is determined by the minimum delay of the ring oscillator cells. Furthermore, the ring
oscillator is continuously running, which could be power consuming.
To improve the oscillator-based TDC power consumption, the ring oscillator may be enabled
by the reference input, and disabled by the MMD, with its initial state being stored and used as
initial condition for the next cycle. Known as a gated ring oscillator TDC [19], the gating
effectively realizes a 1st-order noise shaping, which will also help reduce the phase noise
contribution of the TDC for a given achievable delay. For instance, the raw delay achievable in
a 16nm CMOS process is on the order of 4–5pS, whereas with gating sub-pS effective delays
are achievable.
D
Q
Clk
t
t
D
Q
Clk
D
Q
Clk
t
t
D
Q
Clk
t
D
Q
Clk
Decoder
A
B
LF
A1
A2
A3
Q1
Q2
Q3
Q4
…
A
B
A1
A2
A3
Q1 = 1
Q2 = 1
Q3 = 0
Q4 = 0
t
Figure 10.66: A delay line TDC
10.7 Introduction to Digital PLLs
643

Finally, an alternative approach using an ADC-based scheme utilizing a slop detector is
discussed in [20], which we leave to the interested reader.
10.7.2 Digital Loop Filters
As will be discussed in Section 10.7.4, the same analysis performed to capture the analog PLL
transfer function is directly applicable to DPLLs. Consequently, one may estimate the required
values of the loop ﬁlter components (namely R and C for say the type II PLL of Figure 10.20)
based on the required DPLL transfer function. Once the analog loop ﬁlter is determined in the
s-domain, forward Euler s- to z-domain approximation, denoted by s $ 1
T z  1
ð
Þ, may be
utilized to determine the digital loop ﬁlter. This is similar to the design procedure often used in
the switched capacitor ﬁlters, as explained in Section 10.5.1. The ﬁnal loop ﬁlter transfer
function can then be simulated and optimized in the z-domain. This approach works well if the
loop bandwidth is well below the reference frequency, which is often the case.
Example: Consider Figure 10.68, where a type II RC ﬁlter is shown on the top.
In the analog domain we can write
HLF sð Þ = VOUT
IIN
sð Þ = R + 1
Cs :
Replacing s with 1
T z  1
ð
Þ, we have
HLF zð Þ = VOUT
IIN
zð Þ = R + T
C
z1
1  z1 :
Logic
Counter
A
B
Reset
Enable
A
B
Osc.
Counter
Phase Error
Figure 10.67: Oscillator-based TDC
644
PLLs and Synthesizers

The corresponding z-domain implementation is shown on the right. The transfer function
is readily found to be
VOUT
IIN
zð Þ = C1 + C2z1
1  z1 :
Thus, C1 = R, and C2 = T
C.
The type I ﬁlter may be designed similarly shown on the bottom of the ﬁgure (see
Problem 17). It can be shown that
VOUT
IIN
zð Þ =
T
RC
1 
T
RC
1 
T
RC


z1
1  1 
T
RC


z1 = C1C2z1
1  C2z1 ,
where C1 =
T
RC
1 T
RC, and C2 = 1  T
RC.
10.7.3 Digitally Controlled Oscillators
Two variations of a DCO are depicted in Figure 10.69. As explained in Chapter 9, along with a
varactor, almost all VCOs utilize a digitally controlled array of capacitors to coarse tune the
VCO and effectively reduce the VCO gain for a given range.
Shown on the left, the varactor may be replaced with another array of switchable capacitors
to create the required ﬁne-tuning. Depending on the acceptable frequency error set by the
application, realizing such ﬁne steps may lead to impractical values, and often proves to be a
difﬁcult task.
IIN
+
VOUT
–
R
C
R
C
+
VOUT
–
VIN
S
z–1
S
C1
C2
IIN(z)
VOUT(z)
Analog
Digital
S
C1
C2
z–1
VOUT(z)
VIN(z)
Analog
Digital
Figure 10.68: Digital loop ﬁlter examples
10.7 Introduction to Digital PLLs
645

An alternative approach shown on the right takes advantage of a DAC driving a more
traditional VCO with varactor. The DAC noise and power consumption is obviously adding
some overhead, but it typically leads to a more straightforward design. Especially in high-
performance applications, a high dynamic range for the DAC may be required. The DAC
LSB is set based on the required DCO resolution, or effectively, the acceptable frequency
error. In either approach, ΔΣ modulation may be incorporated. In the case of ﬁne array, the
ΔΣ helps achieving ﬁner resolutions at the cost of extra noise or possibly spurs, nonetheless
it is often used; while in the DAC approach, ΔΣ modulation helps boost the DAC
dynamic range.
Example: Consider a continuous VCO with KVCO = 15MHz/V to be used in a DPLL
along with a DAC. Assuming a 10-bit DAC with a full-scale voltage of 0.5V, the DAC
LSB will be about 0.5mV. The frequency resolution will then be 0.5mV  15MHz/V
= 7.5kHz. If used for a 2.4GHz WLAN application, the frequency resolution will be
about 3ppm.
10.7.4 DPLL Linear Analysis
The DPLL linear transfer function and noise analysis may be carried out much the same way as
the analog PLLs discussed in Sections 10.4.1 and 10.4.2. Replacing KPFD with KTDC, and KVCO
with KDCO, same equations as before may be used with the PLL closed-loop transfer function
expressed as
H sð Þ = N
ωn2 1 + RCs
ð
Þ
s2 + 2ζωns + ωn2 ,
where ωn =
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
KTDCKDCO
CN
q
and ζ = RCωn
2 .
As before, noise from reference, TDC, and MMD goes through a lowpass transfer function,
whereas the noise transfer function from the DCO to the output is highpass. The noise of each
block may be estimated and simulated in block level, and eventually added up by multiplying
by the proper transfer function.
Fine Cap 
Bank
Coarse 
Cap Bank
Loop Filter
VCO Calibraon
Coarse 
Cap Bank
Loop Filter
VCO Calibraon
DAC
RC
Figure 10.69: Examples of DCO realization
646
PLLs and Synthesizers

10.8 Summary
Phase-locked loops, frequency synthesizers, and frequency dividers were covered in this chapter.
– Section 10.1 discussed basic properties and building blocks of a phase-locked loop.
– Type I PLLs were presented in Section 10.2. A linear model of the PLL commonly used in
PLL phase noise analysis was also discussed.
– Type II PLLs were discussed in Section 10.3. Key building blocks such as phase frequency
detectors and charge pumps were discussed.
– Section 10.4 discussed the integer frequency synthesizers.
– Fractional synthesizer were presented in Section 10.5. The concepts of noise shaping and
ΔΣ modulators were covered in this section.
– Latches, frequency dividers, as well as dual- and multi-modulus dividers were discussed in
Section 10.6.
– A brief overview of digital PLLs was presented in Section 10.7.
10.9 Problems
1. InthetypeIPLLofFigure10.8,thereferenceis5GHz,andKVCO= 1GHz/V.DesignthePLLfor
a bandwidth of 500MHz, assuming critically damped condition. What is the PLL phase margin?
2. In the following type II PLL, the loop ﬁlter resistor and PD noise are modeled by a series
voltage source and a parallel current source. Find the noise transfer function for each.
Answer: SϕOUT =
N
KPD


2
G
1 + G

2 Sin + Svn
F
j j2

	
.
Vn
in
KPD
KVCO/S
C
R
N
3. Assuming the charge pump noise is given by Sin  2KTICP, show that the phase noise at the
PLL
natural
frequency
due
to
the
charge
pump
noise
alone
is
given
by
SϕOUT ωn
ð
Þ = 5π2N2
ICP 2KT.
4. A charge pump PLL intended for LTE applications uses a 52MHz reference frequency, and
creates an output at 1960MHz. The VCO gain is 40MHz/V. Find the charge pump current,
10.9 Problems
647

and the loop ﬁlter components such that the PLL 3dB bandwidth is 100kHz, and the
resistor phase noise is less than –100dBc/Hz (the loop is critically damped). Assuming a
VCO phase noise of –90dBc/Hz at PLL natural frequency (ωn), what is the total phase
noise at ωn (including the charge pump noise a stated in the previous problem)? Answer:
ICP = 9.5μA, R = 50kΩ, C = 160pF, –93.8dBc/Hz.
5. Consider a fractional synthesizer where the VCO is ﬁrst divided by 2 before being applied
to the MMD. Discuss the pros and cons of this topology compared to the one where the
VCO is directly fed to the MMD. Hint: Consider the ΔΣ modulator quantization noise
contribution in each case.
6. Analyze the divide-by-8/9 circuit in Figure 10.59. Draw the timing diagram for either
divide ratio.
7. Modeling the quantizer as an additive noise source, ﬁnd the noise shaping function and the
output–input characteristic of the 2nd-order ΔΣ modulator of Figure 10.40.
8. Show that for an mth-order ΔΣ modulator, the SSB phase noise is given by
Sϕ,OUT f
ð Þ =
2π
ð
Þ2
12f REF 2 sin πfT
ð
Þ
j
j2 m1
ð
Þ.
9. Consider a type-II PLL with a reference frequency of 40MHz, creating an output frequency
of 2GHz. Assume the VCO gain is 100MHz/V.
a. Find the charge pump current and the loop ﬁlter components if the PLL 3dB bandwidth
is to be 1MHz.
b. Assuming there is an up offset current of 25% of the nominal charge pump current,
sketch the PFD input and output signals, and the charge pump current over one cycle.
10. Redo Problem 9, part b for the case where the up current is 10% lower than the down current.
11. Consider a fractional synthesizer with a reference frequency of 50MHz, and an output
frequency of 1GHz. The synthesizer uses a MASH 1-1 ΔΣ modulator, dividing the output by
N  1,N,N+1,andN+2.Assumethechargepumphasequalupanddowncurrentsof200μA.
a. Find out the time skew at the PFD input. Hint: Assume N  20 and ﬁnd the divider
output frequencies for various values of N  1, N, N + 1, and N + 2.
b. Design a charge pump with an offset current to avoid the nonlinearity.
c. From the charge pump nonlinearity point of view, is a higher reference frequency
more desired or a lower one?
12. Modify the circuit of Figure 10.56 to create a divide-by-3/4 circuit.
13. Using a divide-by-3/4 (previous problem), an OR gate, and two additional D ﬂip-ﬂops,
design a divide-by-15 circuit. Answer: See below!
D
Q
Clk
Q
D
Q
Clk
Q
÷3/4
MOD
IN
OUT
Q1
Q2
Q3
648
PLLs and Synthesizers

14. Shown below is a divide-by-3 circuit creating a 6-phase output. Analyze the circuit, and
plot the corresponding timing diagram.
3FLO
DP
DN
QP
QN
DP
DN
QP
QN
DP
DN
QP
QN
Dp
Dn
Qn
Qp
CLKp
CLKn
B+
B-
A+
A+
A+
A-
A-
Differential
XOR Gate
Latch
CLK1
CLK4
CLK2
CLK5
CLK3
CLK6
CLK5
CLK1
CLK6
CLK2
CLK1
CLK3
CLK2
CLK4
CLK3
CLK5
CLK4
CLK6
LO1
LO2
LO3
LO4
LO5
LO6
X1
X4
X5
X2
X3
X6
X5
X2
X3
X6
X1
X4
6-phase 16.67% Duty 
Cycle Clocks
A
B
15. Using four divide-by-2/3 circuits (Figure 10.56), and the appropriate logic, design a divide-
by-8~31 multi-modulus divider.
16. Prove that for the MMD of Figure 10.61, N = 8 + 20M0 + 21M1 + 22M2. Work out the
timing diagram of two cases of M2M1M0 = 100, and M2M1M0 = 011.
17. Using the same approach as Section 10.7.2, synthesize the digital equivalent of the type
I RC ﬁlter of Figure 10.68.
18. Considering that the TDC quantization noise spectral density is Sq f
ð Þ =
Tres2
12f REF, calculate
the PLL in-band noise due to the TDC quantization noise.
10.10 References
[1] J.-S. Lee, M.-S. Keel, S.-I. Lim, and S. Kim, “Charge Pump with Perfect Current Matching Characteristics
in Phase-Locked Loops,” Electronics Letters, 36, no. 11, 1907–1908, 2000.
[2] P. R. Gray and R. G. Meyer, Analysis and Design of Analog Integrated Circuits, John Wiley, 1990.
[3] T. Riley, M. Copeland, and T. Kwasniewski, “Delta-Sigma Modulation in Fractional-N Frequency
Synthesis,” IEEE Journal of Solid-State Circuits, 28, no. 5, 553–559, 1993.
[4] B. Miller and R. J. Conley, “A Multiple Modulator Fractional Divider,” IEEE Transactions on
Instrumentation and Measurement, 40, no. 6, 578–583, 1991.
10.10 References
649

[5] J. Candy, “Use of Double Integration in Sigma Delta Modulation,” IEEE Transactions on
Communication, 33, no. 3, 249–258, 1985.
[6] J. Candy, “Use of Limit Cycle Oscillations to Obtain Robust Analog-to-Digital Converters,” IEEE
Transactions on Communication, 22, no. 3, 298–305, 1974.
[7] R. Schreier and G. C. Temes, Understanding Delta-Sigma Data Converters, vol. 74, IEEE Press, 2005.
[8] R. Gregorian and G. C. Temes, Analog MOS Integrated Circuits for Signal Processing, vol. 1, John
Wiley, 1986.
[9] J. Candy and O. Benjamin, “The Structure of Quantization Noise from Sigma-Delta Modulation,” IEEE
Transactions on Communications, 29, no. 9, 1316–1323, 1981.
[10] B. D. Muer and M. S. J. Steyaert, “A CMOS Monolithic Δ; Σ-Controlled Fractional-N Frequency
Synthesizer for DCS-1800,” IEEE Journal of Solid-State Circuits, 37, no. 7, 835–844, 2002.
[11] S. Pamarti, L. Jansson and I. Galton, “A Wideband 2.4-GHz Delta-Sigma Fractional-NPLL with 1-Mb/s
In-Loop Modulation,” IEEE Journal of Solid-State Circuits, 39, no. 1, 49–62, 2004.
[12] H.-I. Cong, J. M. Andrews, D. M. Boulin, S.-C. Fang, S. J. Hillenius, and J. Michejda, “Multigigahertz
GHz Dual-Modulus Prescaler IC,” IEEE Journal of Solid-State Circuits, 23, no. 5, 1189–1194, 1988.
[13] P. Larsson, “High-Speed Architecture for a Programmable Frequency Divider and a Dual-Modulus
Prescaler,” IEEE Journal of Solid-State Circuits, 31, no. 5, 744–748, 1996.
[14] J. Craninckx and M. Steyaert, “A 1.75GHz 3V Dual-Modulus Divide-by-128/129 Prescaler in 0.7μm
CMOS,” IEEE Journal of Solid-State Circuits, 31, no. 7, 890–897, 1996.
[15] C. Vaucher, I. Ferencic, M. Locher, S. Sedvallson, and Z. Wang, “A Family of Low-Power Truly Modular
Programmable Dividers in Standard 0.35μm CMOS Technology,” IEEE Journal of Solid-State Circuits,
35, no. 7, 1039–1045, 2000.
[16] D. H. H. X. Murphy, “A Noise-Cancelling Receiver Resilient to Large Harmonic Blockers,” IEEE
Journal of Solid-State Circuits, 50, 1336–1350, 2015.
[17] D. Murphy, H. Darabi, A. Abidi, A. A. Hafez, A. Mirzaei, M. Mikhemar, and M.-C. F. Chang,
“A Blocker-Tolerant, Noise-Cancelling Receiver Suitable for Wideband Wireless Applications,” IEEE
Journal of Solid-State Circuits, 47, 2943–2963, 2012.
[18] R. B. Staszewski and P. T. Balsara, All-Digital Frequency Synthesizer in Deep-Submicron CMOS, John
Wiley, 2006.
[19] C. Hsu, M. Z. Straayer, and M. H. Perrott, “A Low-Noise Wide-BW 3.6-GHz Digital ΔΣ Fractional-N
Frequency Synthesizer with a Noise-Shaping Time-to-Digital Converter and Quantization Noise
Cancellation,” IEEE Journal of Solid-State Circuits, 43, no. 12, 2776–2786, 2008.
[20] X. Gao, L. Tee, W. Wu, K. Lee, A. A. Paramanandam, A. Jha, N. Liu, E. Chan, and L. Lin, “9.4 A 28nm
CMOS Digital Fractional-N PLL with 245.5dB FOM and a Frequency Tripler for 802.11abgn/ac radio,”
in Proceedings of the IEEE International Solid-State Circuits Conference Digest of Technical Papers,
2015.
[21] F. M. Gardner, Phaselock Techniques, John Wiley, 2005.
[22] D. H. Wolaver, Phase-Locked Loop Circuit Design, vol. 177, Prentice Hall, 1991.
650
PLLs and Synthesizers

11
Power Ampliﬁers
In this chapter we study the challenging problem of delivering power to antenna efﬁciently.
The linear ampliﬁer topologies that we have discussed thus far are fundamentally incapable of
achieving high efﬁciency. Considering the high demand for improving battery life, this
shortcoming becomes very critical when delivering hundreds of mW or several watts of power
into the antenna. This issue is exacerbated in most modern radios that employ complex
modulation schemes to improve the throughput without raising the bandwidth. As we
discussed in Chapter 6, such systems demand more linearity on the power ampliﬁer, and
hence achieving a respectable efﬁciency becomes more of a challenge.
We start this chapter by general description of challenges and concerns, as well as linearity–
efﬁciency trade-offs. We then have a detailed description of different classes of PAs. We
conclude the chapter by discussing various techniques employed to linearize the PA, or to
improve the efﬁciency in an attempt to ameliorate the challenging linearity–efﬁciency issues.
The speciﬁc topics covered in this chapter are:
• Power ampliﬁer basic operation
• PAs classes A, B, and C
• Switching power ampliﬁers (classes D, E, and F)
• Digital transmitters and digital PAs
• Power combining techniques
• Predistortion
• Envelope elimination and restoration
• Envelope tracking
• Dynamic biasing
• Doherty power ampliﬁers
For class teaching, we recommend covering Section 11.1, and selected parts of Sections
11.2–11.8 (for instance, only classes A, B, and E or F). The discussion on Doherty PAs and
linearization techniques may be deferred to a more advanced course, although most of the
material is easy to follow, if assigned as reading.

11.1 GENERAL CONSIDERATIONS
..............................................................................................
When dealing with power ampliﬁers, there are several important factors that distinguish them
from the small signal ampliﬁers we have shown so far:
– The notion of maximum power transfer accomplished by conjugate matching is not quite
applicable to PAs (Figure 11.1).
As we showed in Chapter 3, in a receiver, conjugate matching to the source results in
maximum power transfer from the antenna to the LNA input, but also causes 50% power loss.
For instance, in the case of a GSM PA that needs to deliver 2W of power to the antenna, the
50% efﬁciency results in dissipating 2W of power in the PA itself, which is not acceptable,
considering that there are many other practical limitations that lower PA efﬁciency further. In
fact from Figure 11.1, the output power at the antenna is proportional to
POUT / 1
2 RANT
1
RANT + ZOUT


2
,
and for a given antenna impedance RANT, the output power is maximum if the PA output
impedance (ZOUT) is zero. For that reason, most practical PAs are designed to deliver a certain
power set by the application with the highest possible efﬁciency. As we saw earlier, even for the
receivers, apart from certain impedance requirements imposed by the external components,
matching to source does not always result in optimum performance.1
– Similar to the LNAs, the PAs rely on matching networks quite often, but for an entirely
different reason. Consider the example of the GSM PA that needs to deliver 2W to a 50Ω
antenna. This results in a swing of about 14V peak at the antenna, well exceeding the 3.7V
nominal supply available to most handsets. As shown in Figure 11.2, a lossless transformer
may be used to alter the swing at the transistor output favorably, yet delivering the intended
power to the antenna.
ZOUT
RANT
Figure 11.1: Maximum power transfer in receivers and transmitters
1 In the case of a receiver that would be mainly the noise ﬁgure.
652
Power Ampliﬁers

The matching network may be realized by any of the circuit topologies that we discussed in
Chapter 3, but in almost all cases it tends to downconvert the load impedance to the device
output for obvious reasons (thus n is always  1). While in the case of LNA the matching loss
proved to be critical due to noise ﬁgure concerns, in the case of a PA, it is important to be
minimized so as not to degrade the efﬁciency. That, along with the need to deal with large
swings, limits the choice of matching networks components to high-Q inductors, capacitors,
and transformers sometimes even realized externally.2 Similar to LNAs, we simply assume
there is a load resistance of RL at the PA output, and the lossless matching network transfers the
power and impedance as desired.
There are several other features associated with the matching network: they are often used to
absorb the parasitic capacitances (which could be very large given the size of the transistors),
and they ﬁlter the undesired harmonics.
– Another concern arises from the fact that the PA devices, especially the ones at the later
stages, are constantly under stress given the large voltage swing that they must undergo.
Reliability and aging are common design concerns, which may sometimes limit the swing at
the PA output. Although one may argue that regardless of the swing the required power is
always delivered through the matching network, in practice a larger impedance transform-
ation results in more loss given the ﬁnite Q of the elements (see Problem 1 that explores the
impact of transformer ratio on loss).
Finally, let us present two common deﬁnitions for the efﬁciency that prove to be the biggest
design metric for the PAs: The drain efﬁciency (in the case of a MOS PA) is deﬁned as
η = POUT
PDC
,
where POUT is the power delivered to the load, and PDC is the power dissipated in the PA. On
the other hand, the power added efﬁciency is deﬁned as
η = POUT  PIN
PDC
,
LCM
Matching Network
50W
PA
Antenna
VDD
50/n2 W
1 : n
28V
2VDD
Figure 11.2: Role of the
matching network in a PA
2 It is not uncommon to employ a package substrate or PCB for matching purposes.
11.1 General Considerations
653

where PIN is the power delivered to the PA. If the PA has sufﬁciently large gain (power gain to
be exact), the two metrics will be very close. Throughout this chapter we use the former
deﬁnition unless otherwise stated.
11.2 CLASS A PAs
..............................................................................................
The main distinguishing feature between the classes A, B, and C is how the device is biased,
and its impact on efﬁciency. Otherwise, the PA schematics look almost identical.
A simpliﬁed class A power ampliﬁer is shown in Figure 11.3. The load inductance, L,
primarily sets the output at VDD, which is important to maximize the swing, and could also
absorb some of the parasitic. We assume it is lumped with the rest of the matching
network, which provides a net resistance or RL to the transistor output. The class
A device is biased such that it always stays in a linear (or semilinear) mode of operation.
Thus the input is biased such that the signal never goes below the device threshold voltage,
and the output swing is such that the transistor stays in saturation. Hence, the device
current never reaches zero. The corresponding transistor drain current and voltage are
shown in Figure 11.3.
Assuming a drain swing of A, the drain voltage is
VDS = VDD + A sin ω0t,
and given the load resistance RL, the drain current is
IDS = IDC + A
RL
sin ω0t,
where IDC is the device quiescent current. Clearly, IDC > A
RL to ensure operation in class A.
Assuming a lossless matching network, the efﬁciency then is
η = POUT
PDC
=
A2
2RL
IDCVDD
:
VDS
RL
L
VDD
VDD
IDC
IDS
t
A
Figure 11.3: A simpliﬁed class A PA
654
Power Ampliﬁers

To maximize the efﬁciency, then, one must maximize the swing and minimize the bias current.
Given the constraints imposed by linearity and supply, we have
ηMAX =
A2
2RL
A
RL VDD
=
A
2VDD
= 1
2 = 50%:
This condition is never reached though, as the drain voltage cannot go below VDS,SAT, and the
device current must not reach zero. In addition, the loss of the matching network degrades the
efﬁciency further.
Apart from using much larger devices to deliver the required power, we can see that the main
difference between a class A PA and the small signal ampliﬁers we have discussed before is that
to maintain a reasonable efﬁciency, in a class A PA, the device AC current is comparable to its
quiescent current.
Assuming the PA DC current is ﬁxed at IDC = VDD
RL , the efﬁciency is
η =
A2
2VDD2 ,
which is plotted in Figure 11.4 as a function of drain swing.
It is often desirable for the PA to provide some kind of gain control in case less power is
needed to be delivered. This, however, leads to degradation in efﬁciency, which quadratically
depends on the swing at the PA output. This issue may be alleviated in two ways:
– The matching network may be altered to present a larger impedance to the device output,
thus while keeping the swing at VDD, less power is delivered to the load.
– The PA supply may be reduced proportionally.
Both options, however, still result in lower efﬁciency at lower powers, simply because the
efﬁciency is a function of A2. Considering that
η =
A2
2RLIDCVDD
,
A
h
½
VDD
Figure 11.4: Class A PA efﬁciency versus output swing
11.2 Class A PAs
655

another option would be to reduce the supply and PA DC bias simultaneously as the swing is
reduced, assuming RL is ﬁxed. A more practical class A PA based on this idea is shown in
Figure 11.5.
The cascode devices may incorporate thick oxide devices that are more tolerant of larger
voltage swings, while the core devices use thin oxide to provide more gain. Moreover, by
selectively turning the cascode bias on or off, the PA bias current may be varied to maintain a
better efﬁciency at lower output powers. Similarly, a variable VDD is supplied using a switching
regulator. Changing the bias current may affect matching, and thus it may be needed to employ
some kind of switchable capacitor in the matching network to accommodate for that. Finally,
the PA may be entirely designed differentially, and only a single-ended output is created at the
last stage of the matching network through a transformer (Figure 11.6).
11.3 CLASS B PAs
..............................................................................................
The somewhat poor efﬁciency of class A PAs is a direct result of leaving a large DC current
unused in the device, that is to say, a current that is not contributing to the power delivered to
LCM
Switcher
Variable VDD
Figure 11.5: Class A PA with gain control
… 
… 
INN
INP
VDD
Figure 11.6: A fully differential
class A PA
656
Power Ampliﬁers

the load. It is clear from Figure 11.3 that if the conduction angle is reduced (pushing IDC lower)
such that only at a fraction of cycle both drain voltage and current are nonzero, a better
efﬁciency is expected. In a class B PA this is accomplished by biasing the PA input right at
the threshold, and thus only conducting at half the cycle (Figure 11.7).
Although it may seem that this kind of biasing results in substantial nonlinearity, one must
note that the nonlinear drain current resulting from the 50% conduction angle is ﬁltered at the
output given the narrowband matching network, and still a sinusoid drain voltage is expected.
Clearly, in the case of class B PAs, and in fact other high-efﬁciency topologies that we will
discuss later, a high-Q matching network is mandatory to lower the far-out emission caused by
the nonlinear PA.
The output current is approximately a half-wave rectiﬁed sinusoid. In each half cycle that the
device is off, the load current is directly sourced from the supply, pointing to a better efﬁciency.
For the other half cycle, the on transistor sinks current from the load. To determine the peak
current, IP, let us ﬁrst express the drain current (Figure 11.7) in terms of its Fourier series:
IDS = IP
π + IP
2 sin ω0t  2IP
3π cos 2ω0t +    :
The DC term, IP
π, determines the supply average current, whereas the fundamental leads to the
output voltage assuming the higher order harmonics are ﬁltered by the tank. When the
fundamental component of the current reaches its peak, IP
2, the total current sank from the load
is A
RL, assuming a peak swing of A at the drain. Hence,
IP
2 = A
RL
:
The efﬁciency can be readily found to be
η = POUT
PDC
=
A2
2RL
IP
π VDD
= π
4
A
VDD
,
which reaches a maximum of π
4 = 78% when the output swing approaches VDD. Interestingly,
the efﬁciency not only is higher, but now drops linearly as the output swing is lowered
(Figure 11.8).
VDD
LCM
50W
RL
IDS
t
t
VDS
VDD
A
VTH
IP
Figure 11.7: A simpliﬁed class B PA
11.3 Class B PAs
657

A more practical class B PA employs a push–pull [1] scheme to supply current at both half
cycles. Although PMOS devices used in more conventional push–pull ampliﬁers are not as
suitable for RF PAs, in a fully differential design an NMOS-only PA may be easily realized by
employing a transformer (Figure 11.9).
Assuming the transformer is lossless, this conﬁguration is not going to affect the efﬁciency:
each device drains the same supply current, and delivers the same power to the load as
calculated before. The output powers are then simply combined at the other end of the
transformer. The advantage, however, is that the same output power is achieved with half the
swing at the drain of each transistor, which is important with the new process nodes as lower
supply voltages are used. Alternatively, with the same swing, a higher impedance at the device
output results in the same total output power, leading to lower loss in the matching network.
The idea of power combining in general appears as a very attractive option in PAs to overcome
the issues associated with low supply voltages, devices stress, and inefﬁciency of on-chip
transformers with more than 1:1 turn ratio. One realization especially in discrete implementation
is to use transmission-line based combiners, such as the Wilkinson power combiner [2]. Shown in
Figure 11.10, when connected to a matched load, it results in a low-loss 2:1 power combining.
This structure can be readily extended to an N-way combiner/divider. However, in GHz RF
applications, transmission lines are not practical to be realized on-chip, given their large physical
geometries and relatively high losses associated with Si substrate and routing.
A more practical approach is accomplished by combining the outputs of several push–pull
stages using a distributed active transformer [3], [4]. A simpliﬁed schematic of such structure is
A
h
½
VDD
p/4
Class B
Class A
Figure 11.8: Efﬁciency of class A and B PAs
VDD
50W
Figure 11.9: A differential push–pull class B PA
658
Power Ampliﬁers

shown in Figure 11.11, where four push–pull stages are combined. For simplicity, the tuning
capacitors are not shown.
The advantage is that for each core, the impedance transformation ratio is less (ideally 1), yet
the overall desired output power is achieved through combining the powers of four stages. This
minimizes the loss of the matching network, especially if on-chip components are used. There
are several other advantages, offered by the circular geometry. For instance, the AC grounds
are conveniently available between the devices of adjacent push–pull cores (for instance, MN1
and MP2), minimizing the ground loss and sensitivity to parasitics. Finally the power combin-
ing is accomplished by introducing a 1-turn metal strip inside the circular geometry to act as a
magnetic pickup of the output power.
One challenge is the input signal distribution, which must be carefully done through a similar
distributed transformer. It must be noted that this topology is not unique to a class A or
B design, and could be extended to any other class of PA.
2Z0
P1
l/4
P2
P0
√2Z0
l/4
√2Z0
Z0
Z0
Z0
Figure 11.10: Wilkinson power combiner
MP1
MN1
+
-
MP2
MN2
MP3
MN3
MP4
MN4
VOUT
Figure 11.11: Four push–pull stages combined
by an distributed active transformer
11.3 Class B PAs
659

11.4 CLASS C PAs
..............................................................................................
The higher efﬁciency of class B PAs as a result of the smaller conduction angle may inspire us
to further reduce the conduction angle, and possibly enjoy better efﬁciency. Known as class
C PAs, the typical waveforms are shown in Figure 11.12, where the input is pushed further
lower to cause conduction duration of less than 50%.
Assuming a conduction duration of τ < T
2, where T is one cycle, we can see that the device
turns on and off at the two points:
tON=OFF = T
4 ∓τ
2 :
Given the input waveform as shown in Figure 11.12, τ = T
cos1VTH
Vp
π
. Accordingly, we deﬁne the
conduction angle as θ = π
T τ = cos1 VTH
Vp . A class B PA has a conduction angle of π
2, or a duration
of half a cycle. Although the calculations are somewhat more complex, same as class B, all that
is needed is to express the drain current in terms of its Fourier series, and ﬁnd the average and
the fundamental components.
Assuming that as soon as the device turns on, that is, when the input reaches VTH, it starts
conducting linearly, or that it behaves like an ideal current source, the drain current then
consists of narrow pulses that may be approximated by top pieces of sinusoids (Figure 11.12).
During the conduction, we can express the drain current as
IDS = IP( cos θ + sin ω0t)
tON  t  tOFF,
where the term cos θ accounts for the fact that the current pulses exist for less than half the
cycle. One can verify that for t = tON/OFF, IDS = 0. Calculating the Fourier series, we have
IDS = IP
π
sin θ  θ cos θ
ð
Þ +
θ  sin 2θ
2


sin ω0t +   


,
where higher order harmonics are not shown. Assuming the tank Q is high enough, the second
term results in a sinusoidal voltage with an amplitude of A, as shown in Figure 11.12, whereas
IDS
t
t
VDS
VDD
A
VTH
t
VGS
VP
0
t
Figure 11.12: Typical waveforms of a class C PA
660
Power Ampliﬁers

the ﬁrst term represents the average power dissipated. Therefore, to establish a swing of A at the
output load RL, during the conduction we must have
IP = π
A
RL
θ  sin 2θ
2

 :
The efﬁciency is
η = POUT
PDC
=
A2
2RL
IP
π sin θ  θ cos θ
ð
ÞVDD
=
θ  sin 2θ
2
sin θ  θ cos θ
A
2VDD
,
and allowing a drain swing of VDD,
η =
θ  sin 2θ
2
2 sin θ  θ cos θ
ð
Þ ,
which indicates that if the conduction angle approaches zero, the efﬁciency reaches 100%.
Interestingly, setting the conduction angle to π or π
2, we arrive at the exact same expression we
had for class A and B PAs.
By setting t = T
4 in the drain current expression, IDS = IP( cos θ + sin ω0t), we can ﬁnd the
peak current,
IDS,Peak = IP 1  cosθ
ð
Þ = A
RL
π
1  cosθ
ð
Þ
θ  sin 2θ
2

 :
If we let θ ! 0,
IDS,Peak  3
4
A
RL
π
θ ,
which indicates that to maintain the same output swing (to deliver the same desired power), the
drain current peaks to inﬁnity. This makes sense, as the pulse width approaches zero when
the conduction angle approaches zero, and to deliver the same fundamental current to the load,
the peak reaches inﬁnity. The total area of each pulse is then expected to remain constant and is
calculated to be A
RL.
A plot of efﬁciency versus the conduction angle is shown in Figure 11.13. Also shown in the
plot is the drain peak current normalized to the load peak current, A
RL. Note that for class A the
drain current has an AC peak equal to the load peak current, but also carries a constant DC
current, and thus its net peak is twice the load peak current, same as class B.
We can see that class A and B PAs could have been treated as special cases of the general
class C that we discussed. Accordingly, one may consider a conduction angle of between
π
2 ; π
	

11.4 Class C PAs
661

to compromise the efﬁciency for linearity. This type of PA is known as class AB PA, and is a
common choice for high-linearity applications such as WLAN.
11.5 CLASS D PAs
..............................................................................................
The classes of PA discussed so far treat the device as a current source to deliver the required
power to the load. Class D PAs as well as a few other topologies that we will present shortly,
rely on the active device used as a switch. The notion of switch as being a passive component
implies zero (ideally) power dissipation, and thus 100% efﬁciency. Naturally, the switching
action involved makes these classes of PAs suitable only for constant envelope applications
such as GSM or FM radio, as the ampliﬁer is inevitably nonresponsive to the input signal AM
content.
The class D PA is traced back to as early as 1959 [5]. A simpliﬁed push–pull class D PA is
shown in Figure 11.14. Similar to class B, the design can be extended to an NMOS-only push-
pull topology using center-tapped transformers (Figure 11.9).
Apart from the switching nature of the design, guaranteed by the high-gain preampliﬁer, the
circuit differs from previous classes as a series RLC tank is incorporated, consistent with the
voltage switching-mode nature of the circuit, as opposed to controlled current source designs
we saw before. However, the class D ampliﬁer may also be implemented in a current-mode
switching scheme (Figure 11.15), in which case a parallel tank is used (known as inverse3 class
D, or class D–1). Nonetheless, in either case, the tank is expected to ﬁlter the undesired
harmonic, and the voltage across the load resembles a sinusoid.
Assuming fast switching, an equivalent circuit for the class D PA (Figure 11.14), along with
the corresponding waveforms (for NMOS switch) are shown in Figure 11.16. The switch as
well as the tank inductor are assumed to have a small resistance. In the half cycle that the
N switch is on, the current is sunk from the load. Since the series RLC ﬁlters the undesired
harmonics, the load voltage as well as the drain current are expected to be sinusoidal. In the
0
10
20
30
40
50
60
70
80
90
100
5
15
25
35
45
55
65
75
85
95
105
115
125
135
145
155
165
175
Conduction Angle, º 
Efficiency, %
Normalized 
Current Peak
A
B
C
AB
Figure 11.13: Class A/B/C efﬁciency
3 The inverse classes, derived based on the duality principle, apply to other switching power ampliﬁers too such as class F.
662
Power Ampliﬁers

next half cycle, the N switch turns off, and the drain voltage is pulled to VDD by the P switch,
which sources current to the load through the supply.
The load voltage peak amplitude is
VLoad = 2
π VDD
RL
RL + rL + RSW
,
and the load current amplitude is
ILoad = 2
π VDD
1
RL + rL + RSW
:
RL
VDD
Figure 11.14: A simpliﬁed class D PA
L∞ 
RL
L∞ 
VDD
VDD
IDC
IDC
Tuned to w0
Figure 11.15: Class D–1 power ampliﬁer
IDSN
t
t
VDSN
VDD
VIN
t
RL
RSW
rL
VDD
Figure 11.16: Class D PA
waveforms
11.5 Class D PAs
663

The DC current drained from the supply corresponds to the half-sinusoid shown in Figure 11.16,
and is equal to
IDC = ILoad
π
:
Thus the efﬁciency is
η = POUT
PDC
=
VLoad  ILoad
2
IDCVDD
=
RL
RL + rL + RSW
,
which can reach 100% if the switch resistance is small, and inductor Q is large. This of course
relies on the fast switching of the transistor, such that it always sees either a zero current, or a
zero drain voltage. In practice, nonideal switching guarantees some nonzero power dissipation,
especially at the higher frequencies that the switching speed degrades at. The main trade-off
arises from the fact that increasing the switch size reduces RSW, which helps improve the
efﬁciency, but in turn results in an increase in the dynamic power dissipation (CVDD
2f) due to
the increase in the switch parasitic capacitance.
Apart from nonzero switch resistance and capacitance, another potential issue arises from the
ﬁnite rise and fall times of the switching signal. Consequently, there will be a certain period of
time during which both the N and P transistors turn on as shown in Figure 11.17.
Known as shoot-through, since the switch resistances are small, this could lead to large
current drain during the overlap time. As such, often nonoverlapping clocks are devised to
minimize that, but it could lead into some distortion.
Since the output power depends only on VDD, the only viable choice for gain control is to
vary the supply voltage, but the efﬁciency is expected to remain high even at lower output
powers.
One common application of class D PAs is in audio. Evidently, amplitude modulation cannot
be supported given the switching nature of the ampliﬁer. Instead, it is common to utilize what is
known as pulse-width modulation4 (PWM) [6], [7]. The basic concept is illustrated in
Figure 11.18.
A sawtooth signal when compared to the input (x(t)) results in the waveform xP(t) shown,
which has a constant amplitude of A, but whose width linearly varies with the input signal
amplitude at the time location tk.
–VTHN
VTHN
VDD
Figure 11.17: Demonstration of shoot-through in class D power
ampliﬁers
4 Also known as pulse-duration modulation (PDM).
664
Power Ampliﬁers

Examination of waveforms in Figure 11.18 reveals that the modulation duration depends on
the message value at the time location tk of the pulse edge, rather than the apparent sample time
kTs. As shown in Chapter 2, the duration of each pulse, τk, may be deﬁned as
τk = Ts
2 1 + x tð Þ
ð
Þ,
where Ts is the sawtooth signal period. To prevent missing pulses or negative durations, let us
assume that x(t) is normalized such that |x(t)| < 1. Since the rate of the input signal variation is
assumed to be much less than the sampling frequency, we may assume uniform sampling,
which is to say τk could be treated as nearly a constant. Thus, we can write the Fourier series
coefﬁcients as
an = 1
Ts
ð
Ts
xP tð Þej2πnf stdt = A
Ts
ð
τk=2
τk=2
ej2πnf stdt = A
πn sin nπ
2
1 + x tð Þ
ð
Þ


,
which leads to
xP tð Þ = A
2 1 + x tð Þ
ð
Þ +
X
∞
n = 1
2A
nπ sin nϕ tð Þcos nωst,
where ϕ tð Þ = π
2 1 + x tð Þ
ð
Þ. The PWM signal contains the input x(t) plus a DC component as
well as phase-modulated waves at the harmonics of fs. As the phase modulation has negligible
overlap in the input signal band provided that the sampling frequency is high, x(t) can be fully
recovered by lowpass ﬁltering with a DC block.
11.6 CLASS D DIGITAL PAs
..............................................................................................
Most modern wireless communication standards employ modulation with a time-varying
envelope to improve the spectral efﬁciency. As mentioned in the last section, conventional
class D PA achieves the high efﬁciency by switching rail to rail, thus eliminating amplitude
information from the input signal. For narrowband signals, PWM is used to change the output
+
–
Saw-Tooth 
Generator
x(t)
xp(t)
PWM Output
Comparator
x(t)
t
t
xp(t)
A
kTs
tk
tk
Ts
+1
–1
Figure 11.18: Basic concept of PWM and the corresponding waveforms
11.6 Class D Digital PAs
665

signal amplitude by changing the duty cycle of the input signal as shown in Figure 11.18. For
wider bandwidth signals, however, that require high dynamic range, PWM is not as suitable,
and often digital class D PAs are used.
In a digital PA (or DPA) the total size of the PA is designed to deliver the target maximum
power, then the total size is divided into N unit cells that can be individually turned on or off.
Each cell is driven by a rail-to-rail input, which passes through only if the cell is selected with
an enable selection bit (Figure 11.19). Similarly a segmented inverse class D PA can be
constructed as shown in Figure 11.20, where each cell has a differential switchable current
source and two cascode devices. The differential currents from all units are summed up in the
load balun and converted to single-ended voltage on the load resistance [8], [9].
The DPA is essentially a high-speed digital-to-analog converter (DAC). Like any DAC, the
nonlinearity mechanisms can be divided into two groups:
1. Analog nonlinearity caused by the dependence of each cell output on the value of the
combined output. For example, the switch resistance of an on MOS device depends on the
drain to source voltage, which is the total output voltage. For instance, as was proved in
Section 11.5, the output voltage is function of the switch resistance.
2. Unit cell mismatch, where random and systematic mismatch mechanisms cause the output of
each cell to be different. For example, the random mismatch of the threshold voltages of the
MOS devices would cause a mismatch in the switch resistance and therefore the output voltage.
Mismatches could result in differential nonlinearity (DNL) or integral nonlinearity (INL).
A poor DNL results in high quantization noise, which degrades the noise ﬂoor, typically
important for out-of-band requirements. On the other hand, high INL degrades the in-band
linearity. In the context of DPA, the INL is related to OIP3, OIP5, and so forth. Therefore, a
poor INL would degrade EVM and results in spectral regrowth that might violate the transmis-
sion mask. To achieve good linearity, the accumulated knowledge of high performance DACs
N Unit Cells
RL
Output
Enable<1>
Enable<2>
Enable<N>
 
Figure 11.19: Segmented
differential class D PA
666
Power Ampliﬁers

is leveraged. For instance, to optimize the DNL, the DPA cells are divided into two sections:
unary and binary. The unary bank of cells are all identical and controlled with thermometer
code, while the binary bank has regular binary weighted cells. The segmentation is done as
explained in [10], as a trade-off between DNL and the area and power overhead of
segmentation.
To improve the linearity over the segmented class D PA of Figure 11.19 a switched capacitor
(SC) architecture may be sought [11]. In the switched capacitor PA, the matching capacitor is
segmented as well, such that each cell has a small unit cap with an impedance higher than that
of the driving inverter, as depicted in Figure 11.21. This topology improves the linearity
substantially, because the gain of each cell is determined by an extremely linear passive
capacitor in comparison to the nonlinear MOS switch resistance. Capacitors also can handle
larger swing, scale well with the technology (same as switch), and have excellent matching
properties.
Moreover, the power efﬁciency of SC-PA at back-off is better than class D because the gain
setting element is reactive and does not consume power in the off state.
The DPA can be designed with polar or quadrature architectures. In a polar arrangement, the
input clock to the DPA is modulated with the phase information, while the amplitude infor-
mation controls how many unit are turned on. As will be discussed in the next chapter, polar
architecture requires CORDIC module to generate the phase and amplitude data from the I and
Q data. It also requires delay matching between the amplitude and phase paths, which makes it
more suitable for narrowband modulation schemes where the delay requirement can be
practically met.
On the other hand, in a quadrature DPA, the I and Q data can be combined in digital or
analog. In analog combining, I and Q data are applied to separate DPA and the output current or
voltage is combined in one balun. The more convenient digital combining is shown in
Enable<1>
N Unit Cells
+ Phase –
V
Output
DD
Enable<N>
RL
 
Figure 11.20: Segmented inverse class D PA
11.6 Class D Digital PAs
667

Figure 11.22, where 25% duty-cycle clocks are used to multiplex the I and Q data for each cell.
These clocks are globally multiplexed using the sign bit of the I and Q data [12].
11.6.1 Practical Limitations of DPA
The high efﬁciency of the DPA and the continuous improvement in its performance with
technology scaling have made it an attractive choice for integrated CMOS PAs. Yet DPAs
suffer from practical limitations that make the design challenging. The main limitation of the
DPA is its code-dependent nonlinearity. For example, in the current-mode segmented inverse
class D DPA, the output impedance of the current sources changes based on the code, resulting
N Unit Cells
RL
Output
Enable<1>
Enable<2>
Enable<N>
Figure 11.21: Switched
capacitor digital PA with
improved linearity
t
t
t
Figure 11.22: Digital mixing of I and Q data
668
Power Ampliﬁers

in a code-dependent gain, which degrades the linearity substantially. Similarly, in SC-PA, the
inevitable supply routing resistance and inductance will cause unintended modulation of the
supply voltage with the signal envelope (Figure 11.23). This is called remodulation and results
in degraded linearity in the form of EVM degradation and spectral regrowth.
It has been demonstrated that digital predistortion DPD can be used to correct for various
types of nonlinearities to a level suitable for commercial products [13] (see also Section 11.9.1).
It should be noted, however, that DPD, especially the two-dimensional [14], adds complexity to
the system and comes with an area and power overhead. However, with technology downscal-
ing, it is expected that the DPD overhead will be more manageable and will make the DPA
suitable for more applications.
11.7 CLASS E PAs
..............................................................................................
The main challenge of class D PAs is to minimize: the voltage across the switch when it carries
current, and the current through it when there exists a voltage across. These conditions imply
fast switching, which may not be feasible at high frequencies. If the switch voltage and current
overlap, as they do in practice due to ﬁnite rise and fall times, the efﬁciency degradation may be
substantial. This may be avoided by proper design of the matching network,5 which adds
enough degrees of freedom to ensure that there is no appreciable time duration that voltage and
current simultaneously exist [15].
A simpliﬁed class E power ampliﬁer is shown in Figure 11.24.
The drain inductor is large and is used for biasing purposes.6 The load resistance RL and the
supply voltage are chosen a priori, based on the maximum available or allowable (given the
device stress concerns) supply, and the power delivery requirements.
The matching network consists of the series RLC circuit (L, C2, RL), as well as the parallel
capacitance C1 that includes the device and the drain inductor parasitic. This capacitance
ensures that when the device turns off, the drain voltage stays low until the drain current
reaches zero. This is especially important at high frequencies where the switch does not respond
as quickly as needed. The matching network components (L, C1, and C2) are chosen as follows:
VIN
VOUT
VSUP
VDC
RSUP
LSUP
Figure 11.23: Supply impedance model of DPA
5 This type of network is often referred to as a ZVS (zero voltage switching) network, for the reasons we will describe
shortly.
6 A class E PA may be designed with a modest drain inductor, absorbed in the rest of the matching network.
11.7 Class E PAs
669

When the switch turns off, the circuit simpliﬁes to a damped RLC network (Figure 11.25).
The drain inductor current which may be assumed constant if the inductance is large, charges up
C1. If at the instant that switch turns on the capacitor voltage is nonzero, this voltage is dumped
to ground, and causes power loss. Furthermore, the nonzero capacitor voltage violates the
condition that the voltage across the switch must be zero when it carries current.
Thus, the quality factor of the RLC circuit, QL = Lω0
RL , must be chosen such that at the instant
of turning on, the voltage across C1 (VDS in Figure 11.25) has reached zero. If the circuit is too
damped, it will never reach zero, and if it is underdamped, it may become negative which could
ultimately turn on the switch in the reverse mode. Furthermore, it is desirable for this voltage to
reach zero, with a zero slope to reduce the sensitivity to process variations. There is also a trade-
off between the quality factor of series RLC circuit (QL), and the amount of ﬁltering provided to
remove the undesirable harmonic.
The exact analysis of the circuit requires solving nonlinear differential equations and is given
in [16]. To gain some perspective, we offer a more simpliﬁed approach here when the optimal
conditions are satisﬁed. Let us ﬁrst focus on the off half cycle (T
2 < t < T). Assume that the
current ﬂowing to the load contains only the fundamental, and thus can be generally expressed as
iOUT = I0 cos(ω0t + θ0).
During the off mode (T
2 < t < T), the drain inductor current (IDC), which can be assumed
constant if the inductance is large enough, ﬂows through C1, and the capacitor current
according to KCL is (Figure 11.25)
iC1 = IDC  I0 cos(ω0t + θ0).
VDD
L∞ 
RL
C1
C2
L
Figure 11.24: Class E power ampliﬁer
RL
C1
VDD
C2
L
VDS
VDS
time
Underdamped
d/dt = 0
toff
Turn-on 
instant
IDC
Figure 11.25: Off-mode class E PA
670
Power Ampliﬁers

The capacitor voltage, which is equal to the drain voltage, is the integral of the current,
vC1 = IDCt
C1

I0
ω0C1
sin ω0t + θ0
ð
Þ + K,
where K is a constant resulted from integration. Now these conditions must be met: First,
vC1jt = T
2 = 0, as that is the instant of the switch turning off, until which time the capacitor has
been shorted by the switch. Second, vC1jt = T = 0 to ensure that when turning the switch back on,
no power is lost due to nonzero capacitance voltage. Finally,
dvC1
dt

t = T = 0 to ensure low
sensitivity to variation. With these conditions met, we obtain
vC1 = IDC
C1ω0
ω0t  π
2
sin ω0t + θ0
ð
Þ
sin θ0
 3π
2


,
where I0 = IDC
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 + π2
4
q
, and θ0 = tan 1 π
2 = 1 rad.
At t = 1  θ0
π
	

T = 0:68T, the drain voltage peaks to
IDC
C1ω0 π  2θ0
ð
Þ = 1.13 IDC
C1ω0, and
eventually falls to zero as desired at the end of the cycle.
By obtaining the capacitor voltage Fourier series, and satisfying the KVL and energy
conservation (see problem set) we can show that when the proper design conditions are met,
the drain current and voltage resemble the ones shown in Figure 11.26. The matching
network as stated before is expected to extract the main harmonic of the signal when
appearing at the load, although the inductor need not necessarily resonate with C2 or C2 in
series with C1.
The drain voltage is expected to reach a peak value of π sin 1
π
1 + π2
4 VDD = 3:562VDD, and fall
to
zero
with
zero
slope
at
the
end
of
the
cycle.
The
drain
current
peaks
to
IDC + I0 = IDC 1 +
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 + π2
4
q


, and eventually falls to 2IDC at the instant of the switch turning
off t = T
2
	

[16].
VDS
t
t
IDS
ton
toff
Figure 11.26: Class E PA optimum waveforms
11.7 Class E PAs
671

11.8 CLASS F PAs
..............................................................................................
A class E PA has a somewhat poor power capability as it results in a large peak drain current
and voltage. Also the large current drain may degrade the efﬁciency as practical switches have a
nonzero on resistance. These issues may be avoided in a class F design that relies on the
matching network to shape the switch voltage and current to advantage. Speciﬁcally, if the even
order contents of the drain voltage are removed, while its odd harmonics are ampliﬁed, one
expects the drain voltage to resemble an ideal square-wave that results in perfect efﬁciency.
Shown in Figure 11.27 is the circuit diagram of such implementation.
A parallel tank tuned to fundamental frequency ensures that the impedance seen on the right
side of the transmission line is equal to RL. If the line characteristics impedance Z0 is equal to
RL, on the left side the impedance seen is also RL, as desired. At other frequencies and
particularly at the harmonics, the parallel tank is a short circuit. As we saw in Chapter 3, a
quarter wavelength line reverses the impedance. Thus the short appears as an open circuit at all
odd harmonics, but remains as an open circuit at all even harmonics as the effective length is
equal to half-wavelength or its integers. This is exactly what is needed to produce a square-like
waveform at the output.
As the device sees open circuit at all the odd harmonics, only the fundamental component of
the current ﬂows to the load, and thus the drain current, is expected to be a sinusoid. When the
device turns off, the load current is directly sourced by the supply, similar to class B PA. The
corresponding drain voltage and current waveforms are shown in Figure 11.28.
VDD
L∞ 
RL
C∞ 
Z0
l/4 at w 0
Tuned to w 0
Figure 11.27: Class F power ampliﬁer using a λ/4
transmission line
IDS
t
t
VDS
2VDD
VIN
t
Figure 11.28: Class F device waveforms
672
Power Ampliﬁers

Assuming all the harmonics are subject to the ﬁltering, the peak voltage at the load is 4
π VDD,
and the drain current peak is 8
π
VDD
RL , twice as large as the output peak current.
An alternative class F PA using lumped elements is shown in Figure 11.29. Instead of the
transmission line, a parallel tank tuned to 3ω0 removes the second harmonic.
Although this is not going to produce a perfect square-wave, in practice it may be sufﬁcient
to achieve a respectable efﬁciency. Adding more resonance branches is an option, although the
loss created due to their ﬁnite Q may offset the efﬁciency improvement caused by a more
favorable waveform.
A more analytical description of switching power ampliﬁers in general, and classes E and
F in particular, is found in [17].
11.9 PA LINEARIZATION TECHNIQUES
..............................................................................................
The efﬁciency-linearity trade-offs pointed out thus far may result in considerably poor efﬁ-
ciency in many applications with complex modulation schemes that demand high linearity. One
idea to break this trade-off is to start with an efﬁcient yet nonlinear power ampliﬁer, and
compensate for the linearity through some kind of feedback or feedforward mechanism. In this
section we discuss some of these schemes and discuss their pros and cons.
11.9.1 Predistortion
Widely used in wireless transmitters, the predistortion (PD) technique compensates the power
ampliﬁer’s nonlinear gain or phase responses by shaping the input signal such that the overall
cascade response becomes linear. The predistorter realizes the inverse of the power ampliﬁer’s
response to counterbalance its nonlinearity. This way the PA can be biased in high-efﬁciency
regions such as class AB while maintaining a good linearity. Since power ampliﬁers are
typically compressive, the predistorter has an expansive response.
The predistortion can be performed directly at the RF in the analog domain using diodes and
other nonlinear devices. An example of the RF predistortion making use of analog devices is
shown in Figure 11.30.
VDD
L∞ 
RL
Tuned to w 0
Tuned to 3w 0
Figure 11.29: Class F power ampliﬁer using lumped
elements
11.9 PA Linearization Techniques
673

The intention is to partially cancel the nonlinearity of the power ampliﬁer by adding a cubic
component of the signal with proper phase and magnitude at the input of the PA. The PA input
is divided into two paths. In the main path the transmitted signal is applied after experiencing a
delay of τ, to make up for the delay created in the second path. The second path is responsible
for providing the cubic nonlinearity followed by a scaling using a variable gain and phase
ampliﬁer. The two signals are added together to construct the predistorted signal, and are
applied to the power ampliﬁer that is weakly nonlinear.
In modern wireless transmitters the predistortion is realized at the baseband digital processor.
A digital predistortion can lead to a better correction and is the most suitable structure for
wideband applications. Through a feedback, the predistortion can adaptively follow the pro-
cess, voltage, and temperature variations (PVT) of the PA, making it a robust and reliable
linearizer. Figure 11.31 shows a simpliﬁed block diagram of an IQ transmitter with an adaptive
predistortion performed in the digital baseband.
The PA output is attenuated and downconverted to the baseband by a feedback receiver. The
downconverted signal is digitized and fed to the DSP to evaluate the transmitted signal both
within the channel (for EVM) and out of it (for ACLR). An inverse predistortion function
needed to linearize the PA’s nonlinear characteristic is calculated and implemented on the
digital IQ signals. The distorted baseband signals occupy a wider bandwidth than that of the
original undistorted ones. For example, the presence of the cubic terms in the modiﬁed base-
band signals would triple the occupied bandwidth. Ignoring the scaling factor, assume that the
ideal RF input to a linear PA is supposed to be xRF(t) = xBB,I(t) cos ωct  xBB,Q(t) sin ωct.
However, to compensate for the PA nonlinearity, its input must be xRF tð Þ + βx3
RF tð Þ. It can be
readily proven that the baseband signals must be modiﬁed to the following,
xBB,I,mod = xBB,I tð Þ + 3
4 β x2
BB,I tð Þ + x2
BB,Q tð Þ
n
o
xBB,I tð Þ
xBB,Q,mod = xBB,Q tð Þ + 3
4 β x2
BB,I tð Þ + x2
BB,Q tð Þ
n
o
xBB,Q tð Þ,
indicating that the bandwidth of the modiﬁed baseband signals widens by a factor of three.
PA
( . )3
Aejf
t
x(t)
vOUT
vIN
vOUT
vIN
Figure 11.30: An RF cubic predistorter
674
Power Ampliﬁers

Consequently, the bandwidth of the lowpass ﬁlters following the DACs must be adequately
high. The increased bandwidth of the lowpass ﬁlter may increase the transmitter noise and
degrade the emission mask, and thus may lead to some design trade-offs.
The distortion cancellation architecture is generic and is applicable to PAs with smooth
nonlinearity such as class A or class AB. However, the nonlinearity of PAs with steep slopes in
the characteristic curve may not be corrected.
A major issue in the described IQ transmitter with adaptive predistortion is possible non-
linear distortion caused by the feedback receiver. This nonlinear distortion can adversely impact
the open loop linearity, and produce unwanted post-predistortion nonlinear components.
Another drawback is related to the power consumption associated to the DSP processing and
bandwidth limitations enforced by the DSP clock. The feedback can be activated with a duty
cycle to save in the power consumption. The correction coefﬁcients must be refreshed with an
adequate rate to cover and correct effects of variations caused by PVT as well as changes on the
antenna impedance as the mobile device is moved.
The adaptive predistortion technique described for IQ transmitters, can also be applied to any
other transmitter architectures such as polar and outphasing (see Chapter 12 for more details on
polar and outphasing architectures). The operation principle remains the same, meaning that the
transmitted signal is detected by the feedback receiver and its quality is evaluated and necessary
corrections are applied to the underlying signal components.
11.9.2 Envelope Elimination and Restoration
The concept of envelope elimination and restoration (EER) is presented in Figure 11.32, where
the envelope and the phase information of the modulated transmitted signal are decoupled
across two separate paths. The modulated signal’s envelope is extracted with the help of an
PA
I
Q
DAC
DAC
Digital 
Pre-
distorter
Attenuator
ADC
ADC
Feedback Receiver
Directional 
Coupler
Figure 11.31: Transmitter with adaptive IQ predistorter
11.9 PA Linearization Techniques
675

envelope detector and the phase-only-modulated signal is constructed by passing the input
signal through a limiter, which is typically a hard-limiting buffer. The phase-modulated RF
signal has a constant amplitude, therefore can be ampliﬁed using a highly efﬁcient nonlinear
PA. The PA supply voltage is now modulated by the extracted envelope signal. A switching
regulator with a high efﬁciency is responsible to provide this supply voltage to the PA, and
typically is the main building block that limits the bandwidth of the transmitted signal using the
EER architecture.
Linearity of the EER-based transmitters is independent of the linearity of the constituent
power transistors of the PA and is only a function of the switching regulator’s performance. The
EER architecture generally presents a good linearity for applications with narrow or modest
envelope bandwidths. Besides the envelope bandwidth, the linearity and accuracy performance
of the transmitter is greatly affected by the timing alignment of envelope and phase
components.
The EER technique was proposed by Kahn in 1952 [18] and has been successfully utilized in
high-power transmitters with good efﬁciencies. With the advent of the digital CMOS signal
processing technology, the envelope and phase information can be prepared in the baseband with
the minimum hardware overhead eliminating the need for the limiter and the envelope detector.
Of course, the transmitter must perform phase-modulation into the carrier. This way, not only the
analog imperfections of the limiter and the envelope detector are eliminated, but also the delay
between the envelop and the phase paths can be controlled with a greater accuracy.
The concept of EER has evolved into polar architecture, which was covered in more detail in
Chapter 12.
11.9.3 Envelope Tracking
The maximum theoretical efﬁciency of a linear power ampliﬁer happens at the onset of the
saturation level. This maximum efﬁciency is 50% and 78.5% (π/4) for class A and class
B PAs, respectively (Figure 11.8). When the swing of the PA input is reduced from its peak
at the onset of saturation, the efﬁciency drops too. As the input level departs further from the
peak the drop in the efﬁciency would be substantial. This problem especially becomes severe
Switching 
Regulator
PA
DC Supply
Envelope Detector
Limiter
xRF(t)
Figure 11.32: Operation principle of EER
676
Power Ampliﬁers

when the input signal is modulated and has a large peak-to-average power ratio (PAPR).
Modulations with large PAPRs are now common in modern wireless communication systems
such as quadrature amplitude modulation (QAM). These modulation signals with variable
envelopes require linear power ampliﬁers where the PA is forced to operate away from its
saturation level for most of the times, leading to a low average efﬁciency. In other words, a
large PAPR mandates a large back-off from the saturation level causing degradation in
efﬁciency. Typical values of efﬁciency as low as 10% or less are reported for some high
data-rate modulation standards.
To boost the efﬁciency of linear power ampliﬁers, the use of envelope tracking (ET)
technique has become an attractive and viable option. According to the ET technique, through
a switching regulator the supply voltage of a linear PA tracks the envelope of the RF signal to
be ampliﬁed. With the ET architecture assuming the efﬁciency of the switching DC–DC
converter is 100%, the maximum efﬁciency of a linear PA is theoretically achievable with
any modulated signal, for instance, 50% for a class A PA. The block diagram of an ET
transmitter is shown in Figure 11.33, where the linear PA is supplied by a switching DC–DC
converter with a bandwidth wide enough to faithfully track the envelope of the input RF signal.
This DC–DC converter is called the envelope ampliﬁer (EA).
In the ET architecture, the intention is to boost the overall efﬁciency by using a linear
ampliﬁer in the vicinity of its saturation level all the time. The input to the PA is the actual and
the ﬁnal form of the intended modulated signal to be transmitted. Thus, typically a linear IQ
transmitter is responsible to generate the modulated RF signal to the PA input.
Assuming a class A PA is used, the bias current remains almost constant at all time over the
entire range of the input swing. Note that the efﬁciency would not be improved if the envelope
ampliﬁer is a linear regulator, because only location of the power loss would be shifted from the
PA to the regulator. Consequently, the envelope ampliﬁer has to be in the switching-mode with
high efﬁciency. Usually the switching DC–DC converter is some derivation of the basic buck
converter [19]. This form of DC–DC converter is very attractive for its simplicity, high
efﬁciency, and relatively fast dynamic response. A simpliﬁed diagram of the switcher is shown
in Figure 11.34.
The main idea arises from the fact that a switched inductor can ideally produce an output
voltage whose value may be controlled through switching rate or duty cycle. A simpliﬁed block
Switching 
Regulator
PA
Battery
Envelope Detector
xRF(t)
t
Figure 11.33: Concept of envelope tracking
11.9 PA Linearization Techniques
677

diagram describing the buck converter basic operation is shown in Figure 11.35. The steady-
state waveform corresponding to the continuous mode (the inductor current never goes to zero)
is also shown on the right. The converter may be analyzed through volt-second and charge
balance principles [21], and is brieﬂy outlined below.
During the on mode, the inductor voltage is positive and equal to
VL = VBAT  VDC.
Thus, the inductor current increases, and the inductor stores magnetic energy. The net increase
in the current is
ΔIL + = VBAT  VDC
L
αT,
where αT is the on mode duration. During the off mode, the inductor current decreases, and
similarly, we can show that the net decrease in the current is
ΔIL = VDC
L
1  α
ð
ÞT:
PWM 
Generator
Compensation 
Circuitry
L
VDC
Battery
T
Figure 11.34: A conceptual DC–DC
converter
L
VDC
VBAT
C∞
IL
ON Mode
L
VDC
VBAT
C∞
IL
OFF Mode
Waveforms
t
t
t
T
aT
IL
VL
VBAT –VDC
–VDC
VPULSE
Figure 11.35: Basic operation of a buck converter
678
Power Ampliﬁers

In the steady-state, we must have
ΔIL+ + ΔIL = 0,
which results in
VDC = αVBAT.
So the output voltage is simply controlled by the duty cycle (α) of the pulse applied. Clearly the
output voltage cannot exceed the input, and thus this kind of converter is known as a step-down
(or buck) converter. If the inductor loss and switch resistance are negligible, unlike a linear
regulator, the buck converter of Figure 11.34 is capable of reducing the output voltage
efﬁciently. That is because the load current is drained from the battery only during the on
mode. Consequently, the battery current is scaled by the duty cycle, as is the output voltage. See
also Problems 5 and 6 to gain more insight into switched-inductor circuits, and DC–DC
converters. Problem 6 presents an example of a boost or step-up converter.
The envelope ampliﬁer and the DC–DC converter must have a sufﬁcient bandwidth to
generate an acceptable version of the envelope signal as the PA supply. A switcher with a
feedback system is slower than one with no feedback (open-loop). As we showed, the output
voltage is proportional to the duty cycle of the input to the converter (Figure 11.34), which can
be controlled in an open-loop manner. The duty-cycle must then be proportional to the envelope
of the RF signal to ensure the regulated output voltage of the converter follows the RF signal’s
envelope. Note that this linear relationship between the regulated output voltage and the input is
valid only when the switcher operates in the continuous conduction mode; otherwise, the
relationship would be heavily nonlinear [21].
In the ET the PA supply roughly tracks the instantaneous signal envelope without introdu-
cing compression within the power ampliﬁer. Since the envelope is a nonlinear function of the
quadrature baseband signals (Figure 11.36), the envelope bandwidth is much larger than those
of the constituent quadrature signals.
To ensure the switching regulator is fast enough to track the wideband envelope, stringent
requirements on the loop bandwidth and slew rate are imposed. Under such circumstances the
PAD
DAC
DAC
DSP
PA
DAC
Envelope 
Calculator
Switching 
Regulator
Baery
Linear PA/PAD
Figure 11.36: Simpliﬁed IQ transmitter with envelope tracking
11.9 PA Linearization Techniques
679

power consumption overhead caused by the extra signal processing of the envelope calculator
and the following DAC, LPF, and the DC–DC converter may defeat the intended power saving
in the PA. Furthermore, the DSP, DAC, and switcher need to work at higher clock speeds,
further exacerbating the situation. For modern high data-rate applications, the clock speed and
power consumption of the DC–DC converter may prove to be impractical. One technique to
relax the bandwidth requirements of the envelope tracker is shown in Figure 11.37, where a
modiﬁed signal replaces the RF signal’s envelope as the input to the DC–DC converter. This
modiﬁed signal is derived from the original envelope such that it has smoother transitions with
less dynamic range than the envelope itself by limiting its minimum (beyond a certain low
value the envelope waveform is clipped).
To obtain a good efﬁciency, the PA and the switching regulator must be codesigned. As the
combined PA and switching regulator is a nonlinear system, extensive digital predistortion and
calibration can be utilized to improve the system performance. Also, the PA gain typically falls off
with reduced supply voltage, which could cause AM–AM nonlinearity, and must be compensated.
The sensitivity of the PA gain to its supply variations would also reduce the overall power supply
rejection ratio (PSRR) from the main DC supply of the switching converter to the transmitter
output. A thorough system modeling of DSP/DAC/LPF/converter/PA is critical for a digital
predistortion and nonlinear signal processing. Also, the design of output matching network is
critical. Speciﬁcally, the matching must be preserved while the PA supply is modulated across its
entire range. Since harmonics of the transmitted signal degrade abruptly as the ampliﬁer enters the
compression region, the matching network must suppress harmonic spurious growth. Finally, the
interface between the envelope tracker (the switching regulator) and the PA is critical for both ET
and EER-based transmitter architectures. This matter entails design trade-offs between the interface
capacitance, the stability, the system bandwidth, and the overall PSRR.
As we discussed, the transmitter based on the envelope elimination and restoration (EER)
architecture also employs a switching regulator as an envelope ampliﬁer. In fact, linearity and
noise requirement of the envelop ampliﬁer in an EER architecture is much more stringent than
that of an ET transmitter. This is due to the fact that in the ET architecture the envelope tracking
does not have to be exact and small deviations are tolerable, as in the ET the PA input is the RF
signal in its ﬁnal format and the PA is linear. However, unlike the ET transmitter, in the EER
transmitter the PA input signal is only phase-modulated and the PA is nonlinear operating deep
in compression for maximum efﬁciency. Consequently, the envelope ampliﬁer is responsible to
reconstruct the envelope of the transmitted signal, which is why it must provide the envelope
information with a greater accuracy to the PA’s supply voltage. This justiﬁes why in ET, the
DC–DC converter or the envelope ampliﬁer has much more relaxed requirements.
Envelope 
Calculator
DAC
Envelope 
Shaping
Figure 11.37: Envelope tracking
with modiﬁed envelope signal
680
Power Ampliﬁers

11.9.4 Dynamic Biasing
We have seen that bandwidth efﬁcient modulations such as 64QAM embed a great portion of
the modulation information in envelop of a signal. Transmitting such signals with varying
amplitudes needs a highly linear power ampliﬁer to drive the transmitter antenna with an
acceptable EVM and emission mask. Dynamic biasing of the PA is another simple approach to
improve efﬁciency of linear PAs employed for these applications. The philosophy of the
dynamic biasing technique is to improve the PA efﬁciency by dynamically lowering the bias
current drawn from the main supply at times when the output power level is low. The dynamic
biasing of the PA leads to a reliable, low-power, and low-cost solution for improving the PA
efﬁciency.
Consider a commonly used CMOS PA based on a common-source structure. The dynamic
biasing technique applicable to this PA can be categorized into two main forms: (1) dynamic
biasing of the gate and (2) dynamic biasing of the drain. Let us brieﬂy discuss the latter ﬁrst.
With the dynamic bias of the drain, the drain voltage of the PA is appropriately reduced
whenever the transmitter signal level is low. The reason for this reduction of the PA supply
voltage is to ensure that the PA operates close to the saturation level in order to maintain a good
efﬁciency. In other words, this dynamic reduction of the PA supply voltage adjusts the load line
such that the RF signal swings across almost the entire load line all the time. The envelope
tracking scheme we discussed earlier operates based on this principle. Note that for PAs using
dynamic biasing of the drain, almost the entire current drawn by the PA is provided by the
envelope ampliﬁer, which is a switching regulator with good efﬁciency.
In the dynamic biasing of the gate, however, the gate voltage, which deﬁnes the quiescent
current of the PA, is adjusted. Under the power back-off situation, the gate voltage is reduced to
increase the efﬁciency. A simple PA circuit operating based on this power saving idea is shown
in Figure 11.38. Since modifying the gate voltage can alter the characteristic curve of the PA
considerably, the AM–PM and AM–AM nonlinearities can be substantial, and the system may
require a predistortion to correct them.
The nonlinearity effect could become severe as the gate bias voltage approaches the transis-
tor threshold voltage. The AM-to-PM and AM-to-AM characteristics of PAs utilizing dynamic
biasing are typically lower when the drain is dynamically biased instead of the gate. Another
Matching 
Network
VB = f(Envelope)
Figure 11.38: PA with dynamic biasing of gate
11.9 PA Linearization Techniques
681

potential issue with this approach is its susceptibility to any noise sources capable of effectively
modifying the gate voltage.
The major beneﬁt of the dynamic biasing of the gate is its relatively small and compact size.
Since the dynamic biasing circuit does not need to be routed beyond the gate of the input
device, the circuit size is typically very small and has a negligible die area.
11.9.5 Doherty Power Ampliﬁer
Another topology to improve the efﬁciency yet maintaining acceptable linearity is to use
multiple power ampliﬁers, each responsible for some subset of the power range. The earliest
realization of such scheme is traced back to 1936 by Doherty [20].
First let us consider the circuit shown in Figure 11.39, consisting of two arbitrary power
ampliﬁers7 separated by a quarter wavelength transmission line. The transmission line may be
approximated by a π lumped LC circuit as shown in Figure 11.39.
From Chapter 3, the voltage and current in the transmission line can be generally
expressed as
V(z) = V+ejβz + Ve+jβz
I zð Þ = 1
R0
V + ejβz  Ve + jβz
	

,
PA1
l/4, R0
PA2
RL
+
V1
–
+
V2
–
I1
I2
z=0
z=l/4
jR0
– jR0
– jR0
Figure 11.39: Form of high-efﬁciency power ampliﬁer
7 The original design proposed by Doherty uses tubes.
682
Power Ampliﬁers

where z is an arbitrary point in the line, and β = 2π
λ .
Assuming the current of the second PA is related8 to the ﬁrst one by I2 = AejϕI1, solving for
V1/I1 and V2/I2 at boundaries (z = 0 and λ
4), yields
Z1 = V1
I1
= R0
R0
RL
 jAejϕ


,
which is the impedance seen by PA1. Assuming that the input voltages of the PAs are 90º out of
phase (ϕ = π
2), and for the speciﬁc choice of RL = R0
2 ,
Z1 = R0(2  A).
As in the quarter wavelength lines the input impedance is inversely proportional to the
terminating impedance, the network of Figure 11.39 presents to the ﬁrst PA an impedance
of R0, when the effective terminating impedance is also R0, that is, when the second PA is
contributing to half the power to the load (A = 1). However, should the second PA be
removed from the circuit, or prevented from contributing to the output (A = 0), the terminat-
ing impedance is reduced to R0
2 . Consequently, the impedance seen by the ﬁrst PA increases
to 2R0.
Devised according to this principle, the block diagram of a Doherty PA is shown in
Figure 11.40. It is composed of a main PA (PA1) operating in the class B region, and an
auxiliary PA (PA2) operating in the class C region. The 90º phase shift is generated by an
additional transmission line in front of the second PA. Furthermore, to create a load
impedance of half the antenna impedance, another transmission line with characteristic
impedance of Z0
0 = Z0ﬃﬃ
2
p
is placed between the antenna (whose impedance is Z0) and the
output.
The main PA is active when the power level is low, and the input swing is not large enough
to activate the auxiliary PA. The total output power is entirely obtained from the ﬁrst PA,
which is working at 2R0 ohms, twice the impedance it is working at when delivering its peak
power. The corresponding output voltage and DC current of each of the ampliﬁers versus the
PA1
l/4, Z0
PA2
l/4, Z0
l/4, Z’
0
ZANT=Z0
ZL=Z0/2
Figure 11.40: A simpliﬁed
Doherty PA
8 This is accomplished by feeding input voltages that are related accordingly.
11.9 PA Linearization Techniques
683

input are shown in Figure 11.41. Note that the output voltage is the same as the second PA
voltage.
At a certain input power, denoted as the carrier power, PA1 is saturated. Beyond this point, the
output characteristics, unassisted, would ﬂatten (the dashed line in Figure 11.41). The second PA,
however, is permitted to come into play, and not only delivers power of its own, but through the
action of impedance inversion causes an effective reduction in the impedance of the ﬁrst PA. Thus,
PA1 may increase its power without increasing its output voltage, which has already reached a
maximum. At the peak of the input, the voltages of each PA are the same (VP), and they each deliver
a power of VP2
2R0, twice the carrier power. So the total instantaneous power is four times the
carrier power.
Prior to carrier, the voltage of PA1 is twice as that of the output, and 90º out of phase, a
property that can be shown using the transmission line characteristics (see the problem sets).
The current of the second PA is almost zero up to the carrier, at which point it starts to raise
twice as rapidly as the PA1 current. At the peak input, the currents are equal, indicating that the
two PAs contribute to the output equally.
One can recognize that the Doherty power ampliﬁer resembles a class B push–pull PA,
where half the power is handled by half the circuit. In fact, it can be shown that the instantan-
eous efﬁciency increases linearly with the output power, reaching a maximum efﬁciency of
78.5%, similar to an ideal class B PA efﬁciency.
The main application of Doherty PAs is for base station transmitters for the superior
efﬁciency they offer. Also, for applications with very high peak-to-average ratio, where the
ampliﬁer is delivering a modest average power, but occasionally large powers due to the peaks,
the Doherty PA may be suitable. This is largely due to the fact that the power delivery is mostly
done by the main PA, which is low-power and efﬁcient, and the large peaks are assisted by the
high-power auxiliary PA. The design of the two PAs, and the threshold that the second PA must
conduct, then may largely depend on the statistical properties of the modulation used.
The use of a Doherty PA for wireless devices in GHz range is very limited, mainly due to the
bulky λ/4 transmission lines on the PCB, which can be several centimeters in length. Efforts to
replace these transmission lines with equivalent lumped elements were unsuccessful due to
narrowband operation and loss of efﬁciency. Furthermore, the distortion may be a concern, and
often feedback is required to enhance that.
PA1
PA2
IDC1
IDC2
Input Voltage
Output Voltage
Carrier
VP
Figure 11.41: Voltage and currents
of the two ampliﬁers in Doherty PA
684
Power Ampliﬁers

11.10 Summary
The power ampliﬁer and digital transmitters are presented in this chapter:
– In Section 11.1 general properties of power ampliﬁers and the challenges involved were
discussed.
– Various classes of PAs were presented in Sections 11.2 to 11.8.
– Digital transmitters were discussed in Section 11.6.
– An overview of PA linearization techniques such as predistortion and envelope tracking was
given in Section 11.9.
11.11 Problems
1. An LC matching circuit with a ﬁxed inductor Q downconverts the load impedance in a PA
as illustrated in the ﬁgure. Show that the larger the impedance transformation (n), the more
power is lost in the matching. Answer: Relative power loss is  n
Q.
PA
L
C
RP=Lw0Q
RL
PA Matching
RLPA
2. Calculate class C efﬁciency and output power. Show all the steps.
3. Explain why a class B topology cannot be used for the 3rd harmonic peaking.
4. Plot the N and P switches’ waveforms in a class D push–pull PA. Expand the Fourier series
up to 3rd harmonic, and ﬁnd the output waveform, and the load and supply powers.
5. Find the output waveforms of the following circuit where a periodic input is applied
(α < 1). Assume ideal switching in the transistor. Consider the two cases of T » L/R,
and T « L/R.
aT (1–a)T
L
VDD
R
11.11 Problems
685

6. Find the output voltage of the following circuit, known as a boost switching regulator. Plot
the inductor current and voltage in steady-state conditions. Assume the load impedance is
very large, and that the diode is ideal. Answer: VDC = VBAT
1α.
aT (1
)T
L
T (1–a)T
C
VDC
VBAT
IDC
Load
7. For the previous problem, suppose the load drains a constant current of IDC. Plot the inductor
and capacitor voltage and current waveforms. What is the average inductor current? Assume
Tﬃﬃﬃﬃﬃ
LC
p
 1. Answer: The capacitor voltage discharges/charges almost linearly between
VBAT
1α +
IDC
C αT and VBAT
1α. The inductor current is iL tð Þ 
IDC
1  α + VBAT
L
t  αT
ð
Þ
IDC
1  α 
α
1  α
VBAT
L
t  αT
ð
Þ
8
<
:
for on/off
modes. The inductor average current is
IDC
1α  VBAT
2L αT  IDC
1α, as expected from power
conservation.
8. Using Fourier series, ﬁnd the fundamental component of C1 voltage in a class E ampliﬁer.
By equating that to the voltage on the RLC series load, express the impedance of
C1 based on the load resistor. Answer: a1 =
2
π  π
4
	

 IDC
C1ω0, b1 =  1
2
IDC
C1ω0, and
1
C1ω0 = RL
1 + π2
4
2
π .
9. Using energy conservation, show that in a class E power ampliﬁer RLIDC = 2VDD
1 + π2
4 , and
IDC
C1ω0 = πVDD.
10. Show that in class E design, under optimum conditions we have
1
C2ω0 = Lω0 1 +
π
4 1π2
4
	

QL


.
Clearly C2 and L do not resonate at ω0. QL = Lω0
RL is the series circuit quality factor.
11. Calculate the peak voltage at the drain of a class E ampliﬁer. Answer: (π  2θ0)π
VDD = 3.6VDD.
12. Find the peak drain current of a class E ampliﬁer.
13. In an IQ transmitter assume that prior to the up-conversion the quadrature baseband signals
experience a memoryless nonlinearity given by y = x + βx3. If the ideal output RF signal
was to be A cos(ω0t + θ), derive the modiﬁed RF signal and prove the existence of
undesired components proportional to the following: A3 cos(ω0t + θ) and A3 cos(ω0t  3θ).
Answer: ^y tð Þ = A + 3
4 βA3
	

cos ω0t + θ
ð
Þ + 1
4 βA3 cos ω0t  3θ
ð
Þ.
14. Consider the following source follower power ampliﬁer. Assume Veff to be effective
voltages for the input transistor as well as the current source.
a. Derive equation for the drain efﬁciency.
b. Prove that the maximum efﬁciency approaches 25% if VDD 	 Veff.
686
Power Ampliﬁers

VDD
IDC
vIN
vOUT
RL
15. Consider the following common-source power ampliﬁer with a resistive load, where Veff is
the FET overdrive voltage. Derive an equation for the drain efﬁciency, and show that the
maximum efﬁciency approaches 25% if VDD 	 Veff.
VDD
vIN
vOUT
RL
16. Consider the PA with dynamic gate biasing. Assume that gate is biased at VTH + f(A),
where A is the envelope of the RF signal. To preserve the linearity the envelope of the input
RF signal is predistorted given by g(A), i.e. g(A) cos (ωLOt + θ) is applied to the PA input.
Assume that the NMOS transistor is modeled by the long channel equations. Find g(A)
such that the output remains the same as the case where the gate bias voltage is ﬁxed
at VGS, Q. Answer:
A VGS,QVth
ð
Þ
f A
ð Þ
.
17. For the previous problem, assume f(A) is chosen to be
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
VGS,Q  Vth
ð
ÞA
p
. Prove that ratio
of the average currents drawn from the supply voltage between two dynamic and ﬁxed
biases for a give amplitude value A is
3A=2 VGS,QVth
ð
Þ
VGS,QVth
ð
Þ
2 + 1=2A2. For a given probability density
function p(A) for the envelope of a modulated signal, derive equation for ratio of the
average currents drawn from the supply voltage. Answer:
3=2 VGS,QVth
ð
ÞE A
½ 
VGS,QVth
ð
Þ
2 + 1=2E A2
½ 
.
18. The envelope of a white bandpass signal has a Rayleigh distribution p(A) = (A/σ2)eA2/2σ2,
where p(A) is the probability density function, and A is the envelope. If this signal is passed
once through a class A PA with an efﬁciency of η = A2=2V2
DD and another time through a
class B PA with an efﬁciency of (π/4)A/VDD, calculate the average efﬁciency in both cases.
Assume σ  Amax = VDD, such that the limit of integrals can be taken from 0 to +∞.
Answer: Pout =
Ð + ∞
0
Pout A
ð Þp A
ð ÞdA, PDC =
Ð + ∞
0
PDC A
ð Þp A
ð ÞdA and η = Pout=PDC.
11.11 Problems
687

19. Find the voltage of PA1 as a function of the output voltage in a Doherty power
ampliﬁer.
Assume
a
piecewise
linear
characteristics
for
PA1.
Answer:
V1 =  j Z1
R0 V2 =  j 2  A
ð
ÞV2.
11.12 References
[1] P. R. Gray and R. G. Meyer, Analysis and Design of Analog Integrated Circuits, John Wiley, 1990.
[2] E. Wilkinson, “An N-Way Hybrid Power Divider,” IRE Transactions on Microwave Theory and
Techniques, 8, no. 1, 116–118, 1960.
[3] I. Aoki, S. Kee, D. Rutledge, and A. Hajimiri, “Fully Integrated CMOS Power Ampliﬁer Design Using
the Distributed Active-Transformer Architecture,” IEEE Journal of Solid-State Circuits, 37, no. 3,
371–383, 2002.
[4] I. Aoki, S. Kee, R. Magoon, R. Aparicio, F. Bohn, J. Zachan, G. Hatcher, D. McClymont, and
A. Hajimiri, “A Fully-Integrated Quad-Band GSM/GPRS CMOS Power Ampliﬁer,” IEEE Journal of
Solid-State Circuits, 43, no. 12, 2747–2758, 2008.
[5] P. Baxandall, “Transistor Sine-Wave LC Oscillators. Some General Considerations and New
Developments,” Proceedings of the IEEE – Part B: Electronic and Communication Engineering, 106,
no. 16, 748–758, 1959.
[6] K. K. Clarke and D. T. Hess, Communication Circuits: Analysis and Design, Krieger, 1994.
[7] A. B. Carlson and P. B. Crilly, Communication Systems: An Introduction to Signals and Noise in
Electrical Communication, vol. 1221, McGraw-Hill, 1975.
[8] D. Chowdhury, S. V. Thyagarajan, L. Ye, E. Alon, and A. M. Niknejad, “A Fully-Integrated Efﬁcient
CMOS Inverse Class-D Power Ampliﬁer for Digital Polar Transmitters,” IEEE Journal of Solid-State
Circuits, 47, no. 5, 1113–1122, 2012.
[9] D. Chowdhury, L. Ye, E. Alon, and A. M. Niknejad, “An Efﬁcient Mixed-Signal 2.4-GHz Polar Power
Ampliﬁer in 65-nm CMOS Technology,” IEEE Journal of Solid-State Circuits, 46, no. 8, 1796–1809,
2011.
[10] C.-H. Lin and K. Bult, “A 10-b, 500-MSample/s CMOS DAC in 0.6 mm²,” IEEE Journal of Solid-State
Circuits, 33, no. 12, 1948–1958, 1998.
[11] S. Yoo, J. S. Walling, E. C. Woo, B. Jann, and D. J. Allstot, “A Switched-Capacitor RF Power Ampliﬁer,”
IEEE Journal of Solid-State Circuits, 46, no. 12, 2977–2987, 2011.
[12] Z. Deng, E. Lu, E. Rostami, D. Sieh, D. Papadopoulos, B. Huang, R. Chen, H. Wang, W. Hsu, C. Wu, and
O. Shanaa, “9.5 A Dual-Band Digital-WiFi 802.11a/b/g/n Transmitter SoC with Digital I/Q Combining
and Diamond Proﬁle Mapping for Compact Die Area and Improved Efﬁciency in 40nm CMOS,” in
Proceedings of the IEEE International Solid-State Circuits Conference (ISSCC), 2016.
[13] R. Winoto, A. Olyaei, M. Hajirostam, W. Lau, X. Gao, A. Mitra, O. Carnu, P. Godoy, L. Tee, H. Li,
E. Erdogan, A. Wong, Q. Zhu, T. Loo, F. Zhang, L. Sheng, D. Cui, A. Jha, X. Li, W. Wu, K. Lee,
D.
Cheung,
K.
W.
Pang,
H.
Wang,
J.
Liu,
X.
Zhao,
D.
Gangopadhyay,
D.
Cousinard,
A. A. Paramanandam, X. Li, N. Liu, W. Xu, Y. Fang, X. Wang, R. Tsang, and L. Lin, “9.4 A 22
WLAN and Bluetooth Combo SoC in 28nm CMOS with On-Chip WLAN Digital Power Ampliﬁer,
Integrated 2G/BT SP3T Switch and BT Pulling Cancelation,” in Proceedings of the IEEE International
Solid-State Circuits Conference (ISSCC), 2016.
[14] H. Wang, C. Peng, Y. Chang, R. Z. Huang, C. Chang, X. Shih, C. Hsu, P. C. P. Liang, A. M. Niknejad, G.
Chien, C. L. Tsai, and H. C. Hwang, “A Highly-Efﬁcient Multi-band Multi-mode All-Digital Quadrature
Transmitter,” IEEE Transactions on Circuits and Systems I: Regular Papers, 61, no. 5 1321–1330, 2014.
[15] N. Sokal and A. Sokal, “Class E-A New Class of High-Efﬁciency Tuned Single-Ended Switching Power
Ampliﬁers,” IEEE Journal of Solid-State Circuits, 10, no. 3, 168–176, 1975.
688
Power Ampliﬁers

[16] R. Zulinski and J. W. Steadman, “Class E Power Ampliﬁers and Frequency Multipliers with Finite
DC-Feed Inductance,” IEEE Transactions on Circuits and Systems, 34, no. 9, 1074–1087, 1987.
[17] S. Kee, I. Aoki, A. Hajimiri and D. Rutledge, “The Class-E/F Family of ZVS Switching Ampliﬁers,”
IEEE Transactions on Microwave Theory and Techniques, 51, no. 6, 1677–1690, 2003.
[18] L. Kahn, “Single-Sideband Transmission by Envelope Elimination and Restoration,” Proceedings of the
IRE, 40, no. 7, 803–806, 1952.
[19] B. Sahu and G. Rincon-Mora, “System-Level Requirements of DC-DC Converters for Dynamic Power
Supplies of Power Ampliﬁers,” in ASIC 2002 Proceedings, 2002.
[20] W. Doherty, “A New High Efﬁciency Power Ampliﬁer for Modulated Waves,” Proceedings of the
Institute of Radio Engineers, 24, no. 9, 1163–1182, 1936.
[21] R. Erickson and D. Maksimovic, Fundamentals of Power Electronics, Springer, 2001.
11.12 References
689

12
Transceiver Architectures
By now we have a general idea of what the receivers and transmitter look like. Nonetheless,
the exact arrangement of the blocks, the frequency planning involved, the capabilities of
digital signal processing, and other related concerns result in several different choices that are
mostly application dependent. While our general goal is to ultimately meet the standard
requirements, arriving at the proper architecture is largely determined by the cost and power
consumption concerns. The goal of this chapter is to highlight these trade-offs, and present
the right architecture for a given application, considering the noise, linearity, and cost trade-
offs, which were generally described in Chapters 5 and 6. Moreover, we will see that the
proper arrangement of the building blocks is a direct function of the circuit capabilities that
we presented in Chapters 7–11.
We start this chapter with general descriptions of the challenges and concerns when
realizing RF transceivers. We then offer a detailed description of both receivers and transmitter
architectures, and present several case studies. At the end of the chapter, a practical trans-
ceiver design example is presented, along with some discussion on production-related issues,
packaging requirements, and integration challenges.
The speciﬁc topics covered in this chapter are:
• Transceiver general considerations
• Super-heterodyne receivers
• Zero- and low-IF receivers
• Quadrature downconversion and image reject receivers
• Dual-conversion receivers
• Blocker tolerant receivers
• ADC, ﬁltering, and gain control in receivers
• Linear transmitters
• Direct-modulated and polar transmitters
• Out-phasing transmitters
• Transceiver case study
• Packaging and product qualiﬁcation
• Production-related concerns
For class teaching, we recommend covering only Sections 12.1, 12.2.1, 12.2.2, 12.2.3, and
12.6.1. A brief introduction to nonlinear transmitters (Sections 12.6.3 and 12.6.4) may be also
very helpful, if time permits. The remaining sections, and particularly Section 12.7, are easy to
follow and may be appealing to practicing RF engineers.

12.1 GENERAL CONSIDERATIONS
..............................................................................................
Since almost all the radios today rely on digital modulation, the transceivers inevitably require a
very sophisticated digital processing unit. On the other hand, the electromagnetic waves
transmitted and received are analog in nature. Hence we expect our transceivers to at least
include a pair of data converters, as shown in Figure 12.1.
This architecture in fact has been proposed recently in the context of software-deﬁned radios,
that is, radios that are capable of receiving or transmitting any standard at any desired frequency
[1]. Despite being wideband in nature and very ﬂexible, the problem with this idealistic approach
is the stringent blocker and mask requirements for the receiver and transmitter, respectively.
Example: Consider Figure 12.2, where it shows the desired receiver signal at –99dBm is
accompanied by in- and out-of-band blockers that are as large as –23/0dBm, respectively,
as speciﬁed in GSM.
To receive the signal successfully at –99dBm, let us assume that the ADC quantization
noise needs to be at least 10dB below the signal. Assuming that the ADC needs to receive
up to 2GHz to cover various bands (and thus it requires a minimum clock frequency of
4GHz), then the ADC noise level needs to be at
99dBm  10 + 10 log
2GHz
200kHz


=  69dBm,
given that the GSM signal is 200kHz wide. On the other hand, to be able to tolerate a
0dBm blocker with say 3dB of margin, the ADC full scale comes out to be +3dBm. Thus
Continued
ADC
DAC
DSP
Figure 12.1: An ideal transceiver comprising
a pair of data converters
Desired
Blockers
–23dBm
0dBm
TX Output
TX Mask
–165dBc/Hz
Figure 12.2: Receiver blocker and
transmitter mask requirements
12.1 General Considerations
691

the dynamic range needed is 72dB, or roughly 12bits at 4GHz sampling frequency. This
kind of requirement leads to a substantially large power consumption in the ADC alone.
Even if a front-end ﬁlter is incorporated to attenuate the out-of-band blocker, the
receiver still needs to take –23dBm in-band blockers, and an 8-bit 4GHz ADC is needed
that is quite power hungry.
Similarly, relatively stringent requirements are needed to satisfy the far-out mask require-
ments if one chooses to use a DAC to interface the output directly.
Example: Assume an out-of-band noise level of –165dBc/Hz is required for the trans-
mitter to avoid desensitizing the nearby receivers. Assuming a clock frequency of 4GHz,
the noise ﬂoor is
165dBc=Hz + 10 log 2GHz
ð
Þ =  72dBc:
Depending on the application, the DAC dynamic range would be
Dynamic range = 72 + PAPR,
where PAPR is the transmitted signal peak-to-average power. For a 64QAM WLAN
transmitter, PAPR  10dB, and roughly a 14-bit DAC is needed. The DAC dynamic range
is far better than what is needed to guarantee the EVM requirements, and is mostly limited
by the OOB noise spec. For instance, to achieve an EVM of –50dBc, a 9-bit DAC sufﬁces.
Given these challenges, as we pointed out before, both receivers and transmitters rely on some kind
of frequency translation, often provided by the means of a mixer to perform the analog and digital
signal processing much more efﬁciently at lower power consumption. With this in mind, let us take a
closer look at various choices to realize the RX and TX architecture.
12.2 RECEIVER ARCHITECTURES
..............................................................................................
From our discussion before, we expect a given receiver to look something like what is
illustrated in Figure 12.3, where the need for the building blocks shown is justiﬁed as follows:
– An optional front-end ﬁlter to suppress the out-of-band blockers
– The LNA to suppress the noise of following stages
– The mixer1 to provide the frequency translation, and to ease the burden on the following
blocks
1 Although not explicitly shown, throughout this chapter we assume the downconversion mixer output employs some kind of
modest lowpass ﬁltering (say an RC stage) to remove the component at the sum frequency.
692
Transceiver Architectures

– Partial or full ﬁltering (or channel selection) at IF to attenuate the downconverted blockers,
mostly in-band if an RF ﬁlter is used, and thus relax the subsequent stages linearity
After proper ampliﬁcation and ﬁltering, the signal may be passed to a relatively low-frequency
and low-power ADC for digitization.
Figure 12.3 also shows how the out- and in-band blockers are progressively ﬁltered through-
out the receive chain, while the desired signal is subject to ampliﬁcation.
Invented by Armstrong,2 this architecture is known as a super-heterodyne3 receiver [2], and
has been around since as early as 1918. We shall have a closer look in the next section and
discuss its pros and cons.
12.2.1 Super-Heterodyne Receiver
While downconversion to IF eases the power consumption requirement of the following stages,
it introduces several issues of its own. As we showed in Chapter 6, there are several blockers
that are subject to downconversion as well, and given the harmonically rich nature of the mixer
LO, as well as nonlinearities present in the chain, this leads to SNR degradation [3]. Consider
the image and half-IF blockers in a GSM4 receiver shown in Figure 12.4. The GSM signal may
be anywhere from 925 to 960MHz. In the extreme case of the signal at the edge of the band, say
at 960MHz with low-side injection, the image resides at the lower end as shown in Figure 12.4.
The SAW ﬁlter stopband typically starts at 20MHz away from the edge of the passband, which
LNA
LO
To ADC
RF Filter
IF Filter
Desired
Out-of-Band
In-Band
IF
Figure 12.3: A basic receiver topology
2 Edwin Armstrong (1890–1954) was an American electrical engineer and inventor, best known for developing FM radio and
the super-heterodyne receiver system.
3 Heterodyning is a radio signal processing technique invented by Canadian engineer R. Fessenden in which a new frequency
is generated by combining (or mixing) two frequencies. The word heterodyne is Greek and means different-power.
4 The reason to choose GSM in many of our examples has to do with its very stringent blocking requirements.
12.2 Receiver Architectures
693

is at 925MHz. Thus, to achieve an appreciable rejection on the image, it must be at least 55MHz
(960  925 + 20) away, and thus the IF must be at least 55/2 = 22.5MHz. Depending on the
receiver 2nd-order nonlinearity and LO harmonics, if half-IF blockers are dominant, a much
higher IF is needed. For instance, for the one closer to the signal, the IF must be at least 552 =
110MHz to force the blocker to reside in the ﬁlter stopband.
In the example of GSM, out-of-band blockers are at 0dBm, whereas the desired signal is at –
99dBm, and thus to achieve a reasonable SNR, a total rejection of over 105dB is needed. As the
external ﬁlters provide a typical rejection of 40–50dB, often two ﬁlters are needed, which along
with the LNA modest ﬁltering, an adequate rejection may be provided. As a result, a typical
super-heterodyne receiver looks like what is shown in Figure 12.5, where the IF is typically tens
or hundreds of MHz.
Of the two RF ﬁlters needed, one is usually placed before the LNA to adequately attenuate
the 0dBm blockers and thus relax the LNA linearity, whereas the other one is placed after the
LNA. Otherwise, the noise ﬁgure degradation due to the loss of two ﬁlters may be unaccept-
able. The two RF ﬁlters are inevitably external, but so is the IF ﬁlter, which is centered at
several tens of MHz. Since the GSM signal is 200kHz wide, a >22.5MHz IF ﬁlter with such a
narrow bandwidth cannot be realized on-chip, as we discussed in Chapter 4. Thus a super-
heterodyne receiver, despite its robustness, is too expensive to implement as it requires several
external ﬁlters. Moreover, since these ﬁlters are generally 50Ω matched, driving them exter-
nally requires somewhat power hungry ampliﬁers.
12.2.2 Zero-IF Receivers
An alternative approach to relax the ﬁltering and consequently to reduce the cost of a super-
heterodyne receiver is to set the IF at zero, in which case the image or other problematic
fLO+fIF
fLO–
–
fIF
fLO
fLO+fIF
fLO fIF/2
fLO
fLO+fIF/2
Image Blocker
Half-IF Blockers
GSM Example
925M
960M
20M
Figure 12.4: Image and half-IF blockers in a GSM receiver
LNA
LO
RF Filter
IF Filter
RF Filter
To achieve sufficient IR
IF > 22.5MHz
Figure 12.5: Super-
heterodyne receiver
694
Transceiver Architectures

blockers will be of a less concern.5 This, however, creates a new problem as the signal is now
its own image. As we established before, almost all RF signals rely on single-sideband
spectrum generation. Thus, at either sideband of the carrier there exists uncorrelated spectrums,
that even though they may look the same, they are not. As shown in Figure 12.6, when such
signal is downconverted to zero IF, the negative and positive sides fold and fall on each other.
A similar scheme as a transmitter, where quadrature LO signals are used to upconvert the
baseband components, is applicable to receivers. Shown in Figure 12.7, a quadrature down-
converter consisting of I and Q branches clocked with LO signals 90 out of phase is capable of
distinguishing high or low sidebands.
Suppose the signal of interest is a tone residing on the high side of the LO, as shown in
Figure 12.8. The frequency spectrum of the I and Q LO signals is shown as well. Multiplication
in the time domain results in convolution in the frequency domain, and leads to the down-
converted spectrum shown on the right side.
If the signal resides on the low-side, the resultant spectrum is depicted in Figure 12.9.
Comparing Figure 12.8 and Figure 12.9, it is evident that even though the downconverted
spectrums of both high- and low-side signals reside at fm, the phase contents are not identical.
This could be taken advantage of to discriminate the two sides.
In Chapter 2 we showed that applying Hilbert transform to a signal results in multiplication
of the positive frequency components by –j, and those of negative frequencies by +j. We also
showed that while in principle Hilbert transform is a noncasual operation, it may be well
approximated over a reasonable frequency range. Shown in Figure 12.10, by applying Hilbert
transform on the Q output, and adding or subtracting that from the I channel, only one sideband
≈ 
fLO
–fLO
≈ 
0
Downconversion
Figure 12.6: Image problem in a zero-IF
receiver
cos ωLOt
sin ωLOt
I
Q
Figure 12.7: Quadrature receiver to reject one sideband
5 Zero-IF receivers are also called homodyne or direct-conversion.
12.2 Receiver Architectures
695

fLO
fLO
–fLO
1/2
fLO
–fLO
j/2
–j/2
–fLO
fm
*
=
0
fm
1/2
1/2
0
j/2
-j/2
≈ 
Figure 12.8: High-side signal downconverted by quadrature LOs
fLO
fLO
–f LO
1/2
fLO
–f LO
j/2
–j/2
–f LO
fm
*
=
0
fm
1/2
1/2
0
j/2
–j/2
≈ 
Figure 12.9: Low-side signal downconverted by quadrature LOs
0
fm
1/2
1/2
0
j/2
–j/2
I
Q
Hilbert transform
0
fm
1/2
1/2
0
1/2
1/2
High-Side
0
fm
1/2
1/2
0
j/2
–j/2
I
Q
Hilbert transform
0
fm
1/2
1/2
0
–1/2
–1/2
Low-Side
Figure 12.10: Hilbert
transformation of quadrature
outputs
696
Transceiver Architectures

may be selected. This is exactly the opposite of single-sideband selection in transmitters we
showed in Chapter 2.
A more complete block diagram of the quadrature receiver used to detect the zero-IF signal is
shown in Figure 12.11. The Hilbert transform and other processing involved is typically
performed in digital domain where the I and Q downconverted spectrums are passed to the
modem after the ADC.
It must be noted that the quadrature receivers as shown in Figure 12.11 are not unique to
zero-IF applications. Such a scheme may be used to reject the image if the IF is not zero.
However, while a necessity in a zero-IF receiver, quadrature downconversion may be replaced
by RF ﬁltering in a super-heterodyne receiver as long as the IF is high enough.
One drawback of the quadrature receiver may seem to be the need for duplicating the entire
IF path. This, however, is not true, as the signals on the I and Q outputs eventually add
constructively, while the noise of the IF chain blocks are uncorrelated. Thus, for the same total
power and area as a single path (that is, half the power and area for each of the building blocks
of the I and Q paths), the overall SNR remains the same. Moreover, as the image is rejected
after the downconversion, DSB noise ﬁgure applies to the mixer when calculating the overall
receiver noise. However, quadrature LO generation does come at a cost, as typically the
techniques mentioned in Chapter 2 result in some power consumption overhead.
If there is some I and Q imbalance either in the LO or in the receive chain, effectively one
undesired sideband appears at the other and vice versa. This is shown in Figure 12.12, and is a
source of SNR degradation.
In high throughput applications such as WLAN or LTE, as a large SNR is required, this may
impose some challenges. For instance, in 802.11ac application, an SNR of better than 40dB over
a wide bandwidth of 80MHz is required, which is typically not feasible given the mismatches
present in integrated circuits. To circumvent this, often an IQ calibration scheme is needed.
coswLOt
sinwLOt
fLO
I
Q
Figure 12.11: Complex output of a quadrature zero-IF receiver
0
Residual Image
SNR
Figure 12.12: SNR degradation due to IQ mismatches
12.2 Receiver Architectures
697

In addition to quadrature generation and IQ accuracy concerns, there are several other issues
that must be dealt with when using zero-IF receivers [4]:
– As the signal is now located at zero IF, any low-frequency noise or interference directly
competes with the desired signal. This includes the ﬂicker noise, as well as any 2nd-order
distortion. As we discussed in Chapter 5, 1/f noise may not as problematic in wider band
applications (such as 3/4G or WLAN), where the noise is integrated over a wide bandwidth.
Still, 2nd-order distortion is a concern (for instance in a full-duplex radio such as an LTE
transceiver), and must be dealt with using proper circuits or through calibration (see [5] for
an example of IP2 calibration).
– LO self-mixing: We showed in Chapter 8 that RF self-mixing is a source of 2nd-order
distortion. Similarly, LO self-mixing results in an unwanted DC offset at the zero-IF mixer
output. The value of the offset is channel dependent, as the amount of LO leakage varies with
frequency. This along with the other static DC offsets present in the chain due to mismatches
as well as the DC offset created due to the 2nd-order nonlinearities must be removed using
one of the known DC offset calibration schemes.
Fortuitously, most of the aforementioned problems may be avoided by employing calibration
circuitry that leverages on the strong digital signal processing available in CMOS radios today.
A complete zero-IF receiver with several calibration circuitry involved is shown in
Figure 12.13.
Since the signal is located at DC, only low-Q lowpass ﬁlters are needed for channel selection,
which leads to a lower cost and power receiver. The DC offset as well as the 2nd-order
distortion may be monitored in the digital domain, and corrected in the radio. The quadrature
inaccuracy may be also compensated for in the digital domain, leading to a fairly robust
performance at a low power consumption. Still the 1/f noise may be a concern, and thus this
architecture may not be as suitable for narrowband applications such as GSM where the signal
is only 100kHz wide.
cosωLOt
sinωLOt
I
Q
LNA
ADC
ADC
DSP
(IQ Cal)
DC, IIP2
Figure 12.13: Zero-IF receiver with enhanced performance using calibration
698
Transceiver Architectures

Example: Consider a zero-IF receiver where a desired signal located at ω0 accompanied
by a modulated blocker at an offset frequency of ΔωB is down-converted to zero IF by a
noisy LO. We wish to ﬁnd the receiver noise due to the reciprocal mixing of the
modulated blocker with the LO phase noise.
We assume the blocker is stationary, which is true for most practical cases. Further-
more, the blocker offset frequency is assumed to be large compared to its bandwidth,
which again is a fair assumption for any typical out-of-band blocker. The blocker
modulation is however assumed to be arbitrary.
From chapter 9 the LO may be expressed as an inﬁnite sum of noise sinusoids that are
uncorrelated in phase and separated in frequency by 1Hz:
xLO tð Þ ¼ A0 cos ω0t 
X
∞
k¼0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4Sϕ 2πk
ð
Þ
q
cos 2πkt þ θk
ð
Þ
 
!
A0 sin ω0t
where Sϕ(2πk) is the phase noise per unit Hertz at an offset frequency of k Hz from the
carrier, and θk is the uncorrelated random phase with a uniform distribution.
The reciprocal mixing noise component may be then expressed as:
xRM tð Þ ¼  A0
2
X
∞
k¼0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
4Sϕ 2πk
ð
Þ
q
sin ω0t þ 2πkt þ θk
ð
Þ þ sin ω0t  2πkt  θk
ð
Þ
ð

½
Þ xB tð Þ
 
Continued
Figure 12.14: Reciprocal mixing in a direct-conversion receiver
12.2 Receiver Architectures
699

where xB(t) is the modulated blocker. Therefore, as depicted in Figure 12.14, in frequency
domain replicas of the blocker are convolved (or downconverted to baseband) with each
of the noise impulses and folded on top of each other. Knowing that the sum frequency
components are lowpass ﬁltered at the mixer output, the reciprocal mixing noise spectral
density around baseband is:
SRM ω
ð Þ ¼ A02
4
X
∞
k¼∞
Sϕ 2π kj j
ð
Þ SBB ω  ΔωB þ 2πk
ð
Þ þ SBB ω  ΔωB þ 2πk
ð
Þ
½

where SBB(ω) is the blocker baseband spectral density replica as shown in Figure 12.14
(note that the blocker is not necessarily symmetric around ωB). Since the summation is
over inﬁnitesimal steps of 1Hz, it may be replaced by an integral. Normalized to the
carrier power, the reciprocal mixing noise (LRM ω
ð Þ) is then:
LRM ω
ð Þ ¼
ð∞
∞
Sϕ α þ ΔωB
j
j
ð
Þ SBB ω þ α
ð
Þ þ SBB ω  α
ð
Þ
½
dα
At DC where the desired signal is centered, the reciprocal mixing noise becomes:
LRM 0
ð Þ ¼
ð∞
∞
Sϕ α þ ΔωB
j
j
ð
Þ SBB α
ð Þ þ SBB α
ð
Þ
½
dα
With the blocker bandwidth of BW, the integration is effectively from  BW
2 to BW
2 . If the
phase noise is assumed to stay ﬂat in this range, it may be approximated with its value at
the center:
Sϕ(|α + ΔωB|)  Sϕ(ΔωB)
Thus:
LRM 0
ð Þ  Sϕ ΔωB
ð
Þ
ð∞
∞
SBB α
ð Þ þ SBB α
ð
Þ
½
dα
On the other hand, by deﬁnition, the integral represents the blocker average power:
PB ¼
ð∞
∞
SBB α
ð Þ þ SBB α
ð
Þ
½
dα
Therefore:
LRM 0
ð Þ ¼ Sϕ ΔωB
ð
ÞPB
which is in agreement with the result obtained in chapter 6. To the 1st order, the noise is
only a function of the blocker average power, and the LO phase noise at the blocker offset
frequency, but independent of the blocker modulation.
700
Transceiver Architectures

12.2.3 Low-IF Receivers
For narrower band applications where the low-frequency noise or distortion may be too difﬁcult
to cope with, a compromise may be made to set the IF to some higher value, high enough to
push the signal well above the problematic noise or distortion. This may then sound exactly like
the super-heterodyne receiver, yet there is fundamental difference between the low-IF receiver
as we will describe shortly, and a heterodyne radio.
In a super-heterodyne receiver, to attenuate the image and other problematic blockers the IF is
intentionally high enough to locate those blockers outside the passband of the RF ﬁlter. This results in
(1) a very demanding requirement for image rejection as the out-of-band blockers are very strong; (2)
highercost dueto theneed for external ﬁlters, particularly forIF channel selection. In contrast, in alow-
IF receiver, the IF is low enough to ensure the image is in-band, and thus not only an integrated IF ﬁlter
becomes feasible, but the image rejection requirement is also more manageable. However, the image
may now be removed only through quadrature downconversion, whose principles where described
previously. Thus, we expect a low-IF receiver to conceptually look as shown in Figure 12.15.
This type of receiver architecture is generally known as a Hartley image-reject receiver [6],
and is obviously suitable for low-IF applications. It may also be incorporated in a more
conventional heterodyne receiver to improve the image rejection, and thus relax the external
ﬁltering, and in consequence, the cost.
As we showed in Figure 12.10, the Hilbert transform and the subsequent addition/subtraction
results in only one sideband to be selected, and thus the image, located on the other sideband,
is entirely canceled in the absence of mismatches. In practice the mismatches set an upper limit on
the image rejection feasible. It is instructive to quantify the amount of image rejection in terms
of the I and Q accuracy. Let us assume the I channel LO is cos ωLOt, whereas the Q channel LO
is (1 α) sin(ωLOt + β). Ideally both α and β are zero, but in practice they are not due to
mismatches. Although there may be mismatches in any of the other blocks of the receiver, for
simplicity we have assumed they are all lumped in the LO. This is a good approximation, especially
for the gain mismatches. Note that α and β may be a function of both RF (due to LO), and IF (due to
post-mixer blocks) frequencies. Assuming the signal applied to the input is cos(ωLO ωm)t, we can
easily show that the following signals appear at the output of receiver of Figure 12.15:
Desired sideband : cos ωmt
ð
Þ + 1  α
ð
Þ cos ωmt  β
ð
Þ
Image sideband : cos ωmt
ð
Þ  1  α
ð
Þ cos ωmt + β
ð
Þ :
coswLOt
sinwLOt
Hilbert
+
± 
Image Rejection
Figure 12.15: Low-IF receiver basic operation
12.2 Receiver Architectures
701

In the absence of mismatches, α = β = 0, and the second terms representing the unwanted
sideband disappears. For nonzero values of α and β, the signal at the image side is not entirely
canceled, and its relative amplitude with respect to the main component is
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
α2 + 4 1  α
ð
Þ sin β
2

2
α2 + 4 1  α
ð
Þ cos β
2

2
v
u
u
t
:
A plot of image rejection ratio in dB versus gain imbalance (α) is shown in Figure 12.16 for
three different values of phase imbalance (β).
Typical values of gain and phase imbalance achievable in modern CMOS processes limit the
uncalibrated image rejection to around 30–40dB.
The amount of achievable image rejection sets an upper limit on the acceptable IF. This has
to do with adjacent blockers proﬁle, and the fact that they progressively become stronger as the
frequency offset from the desired signal increases.
Example: To understand this trade-off better, consider a GSM receiver where the image
is one of the adjacent blockers located at an integer multiple of 200kHz away from the
desired signal (Figure 12.17).
b
b
b
Figure 12.16: Image rejection in a low-IF
receiver versus gain and phase imbalance
coswLOt
sinwLOt
Desired
Image
n×200k
fLO
IF
0
IF
Figure 12.17: Image blocker in a GSM low-IF
receiver
702
Transceiver Architectures

After downconversion, the blocker folds on top of the desired signal and is located at
n  200kHz  IF,
away from the desired signal. The GSM adjacent blockers for n = 1, 2, and 3 are shown in
Figure 12.18. Shown on the right is the amount of image reception ratio (IMRR) as a
function of IF.
Consider the case where IF is 100kHz. Then the image is the ﬁrst adjacent blocker,
which is only 9dB stronger, leading to a relaxed image rejection requirement. On the
other hand, if the IF is 200kHz, the image is the second adjacent blocker, which is 41dB
stronger, leading to a stringent requirement of about 50dB. For values in between, the tail
of the second adjacent blocker folding over the signal is still large enough to cause a steep
increase in image rejection. Most practical GSM receivers use an IF of about low 100kHz,
which is still advantageous with respect to noise or 2nd-order distortion, but not too high
to demand an impractical image rejection. From the two graphs shown in Figure 12.16
and Figure 12.18, we conclude that unless a digital enhancement is employed, the IF may
not exceed 130–140kHz.
Rather than using Hilbert transform, a practical low-IF receiver may be realized by
polyphase ﬁltering as was discussed in Chapter 4 [7]. The polyphase ﬁlter rejects the
unwanted sideband, and may be combined with the following active IF ﬁlter. Accord-
ingly, an active polyphase ﬁlter makes a popular choice for the low-IF receivers.
A complete schematic of a low-IF receiver is shown in Figure 12.19. Similar to zero-
IF receivers, the RF ﬁlter, though it does not provide any image rejection, may be still
needed to attenuate some of the large out-of-band blockers.
200kHz
600kHz
400kHz
Desired
–82dBm
–73dBm
–41dBm
–33dBm
120
140
160
180
IF, kHz
IMRR, dBc
30
35
40
45
GSM Adjacent Blocker
Mostly 200kHz
Tail of 400kHz
400kHz
Figure 12.18: Adjacent blockers setting the upper limit of IF
12.2 Receiver Architectures
703

There may be yet a better way of realizing the low-IF receiver, if the ADC has high enough
dynamic range to tolerate the unﬁltered image blocker. The main disadvantage of the low-IF
receiver shown in Figure 12.19 is that after passing through the polyphase ﬁlter, the image and
signal cannot be distinguished anymore. Hence, applying any digital correction afterward is not
feasible, and the amount of image rejection is set by what is achievable given the RF and analog
inaccuracies. Shown in Figure 12.20, the receiver may employ only real lowpass ﬁlters, and
thus keeping the I and Q paths separate.
The advantage is that the image is entirely canceled in the digital domain, and thus image
rejection may be enhanced digitally. However, the image blocker is subject to very little
ﬁltering. For instance, suppose the IF is set at 135kHz where an image rejection of about
40dB is needed. Since the GSM signal is 100kHz, the lowpass ﬁlter passband must be at least
235kHz not to affect the desired signal. The 400kHz adjacent blocker, the one residing on the
image sideband, once downconverted, appears at 400 – 135 = 265kHz, which is subject to
almost no ﬁltering. This puts some burden on the ADC design. We shall discuss the trade-offs
involved with ADC and IF ﬁltering shortly.
By comparison, the low-IF receiver shown in Figure 12.20 is almost identical to the zero-IF
receiver of Figure 12.13. All digital enhancements for IQ correction, DC offset removal, and
coswLOt
sinwLOt
LNA
I
Q
ADC
ADC
DSP
PPF
Figure 12.19: Complete block diagram of a low-IF receiver
coswLOt
sinwLOt
LNA
I
Q
ADC
ADC
DSP
(IMR)
Lowpass Filter
Figure 12.20: An alternative low-IF receiver
704
Transceiver Architectures

IIP2 improvement are applicable to both architectures. The only difference lies in the choice of
LO, and whether the desired signal is placed directly at DC, or at a slightly higher frequency.
The latter may be critical for narrower band applications such as GSM, GPS, or Bluetooth. The
receiver is completely reconﬁgurable, however, and can support zero-IF architecture if the
signal is wide enough, for instance if the radio switches to 3G or LTE modes.
12.2.4 Weaver Receiver
An alternative approach to provide on-chip image rejection is known as the Weaver image-
reject receiver [8], and is shown in Figure 12.21.
If the input is located at ω0, assuming low-side injection for both stages of downconversion,
we must have ω0 = ωLO1 + ωIF1 = ωLO1 + (ωLO2 + ωIF2) = ωLO1 + ωLO2 + ωIF2. The other
combinations of high- and low-side injection may be treated similarly and are covered in
Problem 9.
From our previous discussion, we can imagine that the second quadrature downconversion is
effectively providing the Hilbert transform (see Problem 12). It is then easy to conceive that the
image is subject to cancellation at the second IF when the I and Q sides are added (or subtracted
for high-side injection). The signal and image progression along the receive chain are shown in
Figure 12.22.
Unfortunately, unless the second IF is zero,6 the Weaver receiver suffers from the issue of
the second image. We can see that (Figure 12.22) the second image after the ﬁrst down-
conversion is located at
ωImage2 = ωIF1  2ωIF2 =  ω0 + ωLO1 + 2ωLO2:
coswLO1t
sinwLO1t
LNA
coswLO2t
sinwLO2t
IF1
IF2
–
+
Figure 12.21: Weaver image-reject receiver
6 Setting the second IF to zero requires a quadrature second downconversion to create I and Q signals in the second IF. See
also Problem 10.
12.2 Receiver Architectures
705

Or equivalently, it resides at the input ω0 + 2ωLO1 + 2ωLO2. As shown in Figure 12.23, the
second image may be removed only by ﬁltering at the ﬁrst IF (or at the receiver input if it is far
enough).
Due to this issue, along with the need for two stages of downconversion in the signal path,
the Weaver receiver is not as commonly used as the low-zero IF receivers.
12.2.5 Dual-Conversion Receivers
Another compromise to the zero-IF receiver may be made if the receiver employs two steps of
downconversion [9], as shown in Figure 12.24.
The main advantage is that as we discussed in Chapter 8, the mixer related issues such as 1/f
noise or 2nd-order distortion directly improve if the relative slope of the LO is increased, or
equivalently, if a lower frequency LO is used. At the ﬁrst IF, where the LO frequency is high,
the low-frequency noise and distortion are not important, whereas at the second IF, which may
be chosen to be zero or very low, the aforementioned problems are expected to improve thanks
wLO1
wIF1
wIF2
w0
+j
–j
I
Q
–
Figure 12.22: Signal and image progression in Weaver receiver
w0
wLO1
2nd Image
wIF1
I/Q
Input
First IF
0
I/Q
Second IF
wLO2
−w0+wLO1+2wLO2
wIF2
wIF2=w0−wLO1-wLO2
−w0+2wLO1+2wLO2
IF1 Filter
Figure 12.23: Weaver receiver second image problem
706
Transceiver Architectures

to lower frequency LO. Moreover, only the second LO needs to be quadrature, and is readily
created by dividing down the ﬁrst single-phase LO signal. Consequently, the receiver requires
only one VCO/PLL. Using a divide by N = 2n (to produce quadrature signal), we have
IF1 =
f RF
N  1 :
The appearance of  in the denominator is whether we use low- or high-side LO. This kind of
frequency planning results in the ﬁrst IF to vary with the RF channel, and hence is known as a
sliding IF receiver.
The main disadvantages of this scheme are introducing an additional mixer in the main
receiver path, as well as the image issue for the ﬁrst IF. For this reason the ﬁrst IF is typically
very large, limiting the choice of divider usually to N = 2 or 4. The second IF image is not
critical if the second IF is very low or zero.
12.3 BLOCKER-TOLERANT RECEIVERS
..............................................................................................
In almost all the architectures we have discussed so far, the existence of RF ﬁlter seems
inevitable, particularly due to the very large out-of-band blockers. For instance, in the case of
GSM, blockers as large as 0dBm could easily compress the receiver, and consequently desensi-
tize it. In recent years tremendous work [10], [11], [12], [13], [14] has been done to relax or
remove the RF ﬁltering, and we will brieﬂy discuss some of these topologies. In all the
presented architectures, the choice of IF, whether zero or not, is arbitrary, but they all rely on
quadrature downconversion as the RF ﬁlter is intended to be removed.
12.3.1 Current-Mode Receivers
In Chapter 8, when discussing the passive mixer IIP3, we brieﬂy introduced the concept of
current-mode receivers. A current-mode receiver consists of a low-noise transconductance
LO2I
LO2Q
LNA
LO1
÷ N
PLL
LO2I
LO2Q
LO1
… 
Figure 12.24: A dual-
conversion receiver
12.3 Blocker-Tolerant Receivers
707

ampliﬁer (LNTA), followed by passive mixers that operate in current domain, as shown in
Figure 12.25 [15].
Relying on impedance transformation properties of the passive mixers, this scheme provides
two critical features:
– If the TIA input impedance that the mixer switches drive is low, and that the mixer switch
resistance is low as well, the LNTA is loaded by a very low-impedance circuit, and hence the
swing at its output is very low.
– A lowpass roll-off of the TIA translates into a high-Q bandpass ﬁlter appearing at the LNTA
output.
As a result, we expect good linearity at the RF front end, and progressive ﬁltering of the
blockers along the receive chain. Once downconverted, the blocker is several tens of MHz
away, and is ﬁltered by the TIA or the subsequent IF ﬁlter if one is needed. A large capacitor at
the TIA input helps attenuate the blocker given that the TIA input impedance tend to increase at
higher frequencies.
Example: As a case study, let us consider a multimode, multiband receiver designed for
3G applications [16] as shown in Figure 12.26. The receiver consists of two sets of
LNTAs, one for low bands (869–960MHz), and one for high bands (1805–2170MHz).
The LNTA outputs are combined and drive a quadrature current mode passive mixer,
whose LO is created by dividing the master clock at around 4GHz by either 2 or 4. The
mixer output consist of a common-gate TIA which provides a 1st-order roll-off (set at
270kHz or 2.2MHz, for 2/3G modes), followed by a biquad resulting in a 3rd-order
lowpass response.
LOI
LOQ
gm
TIA
TIA
∆fB
∆fB
0
Lowpass
ZIN ≈ 0 
∆fB
0
Figure 12.25: Current-mode receivers
708
Transceiver Architectures

The receiver achieves a noise ﬁgure of better than 2.5dB for all the bands, and the out-
of-band IIP3 is about –2dBm, sufﬁcient for 3G applications.
12.3.2 Mixer-First Receivers
Even though the current mode receivers improve the linearity substantially, external ﬁltering
(directly or through the duplexer) may still be required to tolerate the 0dBm GSM blocker.
Another proposal to boost the receiver linearity and consequently remove the RF ﬁlter is to
dispense with the low-noise ampliﬁer entirely [10], [14]. A simpliﬁed schematic of such a
receiver using an M-phase mixer is shown in Figure 12.27. Such a receiver would clearly result
in substantial improvement of linearity, but the noise ﬁgure is expected to suffer.
Based on the analysis we offered for M-phase passive mixers earlier in Chapter 8 (also see
Problem 13), the receiver noise ﬁgure may be expressed as
F 
1 + RSW
Rs
+
vbb2
4MKTRs
"
#
K,
LOI
LOQ
I
Q
ADC
ADC
DCOC, 
Filtering, 
IQ, ...
Biquad
HB
LB
HB/LB
~4GHz
TIA
1st-Order
270k/2.2M
Figure 12.26: An example of a 3G receiver
I
Q
M
Figure 12.27: M-phase mixer-ﬁrst
receiver
12.3 Blocker-Tolerant Receivers
709

where RSW is the mixer switch resistance, Rs is the source resistance, vbb2 is the TIA input noise
voltage referred to each single-ended switch, and K =
π
M
sin π
M

2
captures the noise folding. The
impact of harmonics have been ignored.
Example: Figure 12.28 shows the mixer-ﬁrst noise ﬁgure for M = 4, and 8, and a
complementary TIA biased at 1 or 2mA. Everything else is assumed to be ideal.
Evidently, even for the 8-phase design that enjoys less aliasing but comes at the
expense of more LO power consumption, the receiver noise ﬁgure reaches 3dB and
higher once the input matching condition is satisﬁed (RSW  50Ω). In practice, the
receiver noise ﬁgure is even worse, once the impact of capacitances and other parasitic
elements included.
There are certain cases where a somewhat worse noise ﬁgure may be acceptable,
especially for low-power applications such as Bluetooth or low-power WLAN. In those
cases the mixer-ﬁrst receiver may be an appropriate choice. In more demanding applica-
tions such as cellular, the higher noise ﬁgure is typically not acceptable.
12.3.3 Noise-Canceling Receivers
The mixer ﬁrst receiver may be thought of an LNA using explicit 50Ω resistance for matching.
Although linear and wideband, the noise ﬁgure of such ampliﬁer is poor. If, however, one can
alleviate the noise issue of this topology by providing both voltage and current measurements
and taking the advantage of noise cancellation [17] (as we discussed in Chapter 7), then an
arbitrarily low noise ﬁgure may be achieved, regardless of matching [12]. The concept is shown
in Figure 12.29, which is similar to the noise-canceling LNAs, but in the context of a receiver.
The mixer ﬁrst path provides a current measurement, and the 50Ω matching is accomplished
Ω
M
M
RSW
M
I
I
I
Figure 12.28: Mixer-ﬁrst receiver noise
ﬁgure
710
Transceiver Architectures

by adjusting the mixer switch and TIA input resistance. Ignoring the mixer’s loss, the total
available current gain to this path (we call it the main path) is 1
Rs, and the available voltage gain
to the TIA output is RM
Rs . A second path, which we call the auxiliary path, is added to provide
the voltage measurement by employing a linear current-mode receiver consisting of a low-noise
transconductance stage and current-mode mixers. The total gain of this path is gm  RA.
Thus, for noise cancellation to be satisﬁed, as we showed in Chapter 7,
gmRA = RM
Rs
:
This criterion is simply met by adjusting the feedback resistors of each TIA. Once the noise
cancellation condition is satisﬁed, an arbitrarily low noise ﬁgure with sufﬁciently high linearity
is achievable.
As a case study, a complete noise-canceling receiver [12] based on the concept shown in
Figure 12.29 is illustrated in Figure 12.30. The receiver is intended to be used in wideband
applications, and thus must be very resilient to blockers. To achieve harmonic rejection, 8-
phase mixers are used in both main and auxiliary paths, and hence all the harmonics up to the
7th are rejected. The low-noise transconductor linearity is critical, and thus a complementary
structure is chosen, which as we showed in Chapter 7 can tolerate a large input as long as its
output is loaded with a low resistance. In this design, the mixers’ resistance is adjusted such that
the RF transconductor sees a low impedance of 10Ω. On the other hand, the mixer ﬁrst path is
designed to provide 50Ω. The eight outputs of main and auxiliary TIAs are fed into a harmonic
rejection as well as noise cancellation block.
With the noise of the main path (the mixer-ﬁrst portion) canceled, and as the noise aliasing
for an 8-phase mixer is very close to unity, the receiver noise ﬁgure is
F  1 +
γ
gmRs
,
where gm is the transconductance of the RF cell. In the above equation, we have ignored the
noise contribution of TIAs in the auxiliary path as they are suppressed by the large gain of the
RF gm cell.
gm
Rs
–
+
–
+
RSW+2/π2RBB≈Rs
RA
RM
+
vOUT
–
Figure 12.29: The concept of
noise-canceling receiver
12.3 Blocker-Tolerant Receivers
711

The receiver measured noise ﬁgure over an input frequency range of 0.1–3GHz is shown in
Figure 12.31.
Without noise cancellation (auxiliary path off), the receiver is simply a mixer-ﬁrst, and as
expected a poor noise ﬁgure is measured. Once the noise cancellation is enabled, a sub-2dB
noise ﬁgure for the entire receiver is achieved over a wide input range. The receiver can tolerate
blockers as large as 0dBm without much gain compression or noise degradation. The measured
0dBm blocker noise ﬁgure is 4dB.
This receiver combines the three ideas presented before to satisfy opposing requirements of
good noise ﬁgure and linearity simultaneously: current-mode receiver concept, noise cancella-
tion, as well as mixer-ﬁrst receiver idea based on low-noise passive mixers.
gm
Harmonic Recombination 
& Noise Cancellation
I
Q
10Ω
50Ω
Figure 12.30: An 8-phase noise-
canceling receiver
Figure 12.31: Noise-canceling receiver noise
ﬁgure
712
Transceiver Architectures

Example: Since the noise cancellation is a function of the source impedance Rs, a
legitimate question arises as to how sensitive the noise-canceling receiver (or the noise-
canceling LNA for that matter) is to source impedance variation. We are going to study
that in the context of an example shown in Figure 12.32. The mixers are eliminated for
simplicity creating a linear time-invariant noise model of the receiver, though the main
path mixer is replaced by its equivalent resistance Rs providing the matching. Further-
more, the noise of the TIAs is ignored, which is a reasonable assumption. Other relevant
noise sources, particularly those of the RF gm and main path mixers, are explicitly shown.
The source impedance is assumed to be arbitrary, and equal to Zs.
Using superposition, the receiver input voltage is
VIN =
Rs
Rs + Zs
Vs + vns
ð
Þ 
Zs
Rs + Zs
vn2:
Finding the current of each path (I1 and I2), the output voltage is
VOUT = gmRARs + RM
Rs + Zs
Vs + vns
ð
Þ + gmRAvn1 + RM  gmRAZs
Rs + Zs
vn2,
which, considering that gmRA = RM
Rs , simpliﬁes to
VOUT =  gmRA
2Rs
Rs + Zs
Vs + vns
ð
Þ + vn1 + Rs  Zs
Rs + Zs
vn2
	

:
If the source impedance Zs is equal to the nominal value of Rs, we arrive at the same
conclusions as before. In general though, the receiver noise factor is
Continued
gm
Rs
–
+
–
+
RA
RM
+
VOUT
–
Zs
Vs
vns
vn1
vn2
+
VIN
–
I1
I2
Figure 12.32: A simple noise model of the noise-canceling receiver with an arbitrary source impedance
12.3 Blocker-Tolerant Receivers
713

F = 1 +
Rs + Zs
2Rs
j
j2vn12 + RsZs
2Rs


2
vn22
4KTRe Zs
½

= 1 +
γ
gmRe Zs
½

Rs + Zs
2Rs


2
+
Rs
Re Zs
½

Rs  Zs
2Rs


2
:
The above equation tells us that in the presence of a nonideal source7 not only is the noise
of the RF gm increased (the ﬁrst term), but only partial noise cancellation is achieved (the
second term). The former is common in any other receiver as well, whereas the latter is
unique to noise-canceling receivers. Note that the output noise is normalized to 4KTRe
[Zs], and not 4KTRs, as, by the deﬁnition, the signal-to-noise ratio at the input is
determined by
Vs
j
j2
4KTRe Zs
½
.
It is often customary to express the noise ﬁgure degradation in terms of the source
standing wave ratio (VSWR). So let us deﬁne
Γs = Zs  Rs
Zs + Rs
= ρejϕ:
The magnitude of the source reﬂection coefﬁcient ρ may be expressed in terms of its
standing wave ratio (VSWR):
ρ = VSWR  1
VSWR + 1 :
Rearranging the noise equation, we arrive at
F = 1 + Fnom  1 + ρ2
1  ρ2
= Fnom
1  ρ2 ,
where Fnom = 1 +
γ
gmRs is the receiver noise ﬁgure under nominal source impedance of Rs.
The receiver noise ﬁgure over various VSWR values is illustrated in Figure 12.32. The
nominal noise ﬁgure is assumed to be 3dB.
Figure 12.33: The noise ﬁgure of the noise-
canceling receiver under mismatch
7 This is often characterized by performing source pull measurements in the receiver.
714
Transceiver Architectures

If one chooses to calibrate the noise cancellation for every given source (Zs), we must
have gmRA = RM
Zs , and the noise factor simply becomes
F = 1 +
γ
gmRe Zs
½
 = 1 + Fnom  1
ð
Þ 1 + ρ2 + 2ρ cos ϕ
1  ρ2
:
That is essentially how a regular receiver behaves over mismatch. In general, the
difference in noise ﬁgure is fairly small for moderate values of VSWR when the noise-
canceling receiver is used. Furthermore, if need be, the noise cancellation can indeed be
recalibrated under source mismatch as described in [18]. The actual source pull measure-
ments conﬁrm this, indicating that the noise cancellation is fairly insensitive to source
mismatches.
12.4 RECEIVER FILTERING AND ADC DESIGN
..............................................................................................
In this section we will discuss the receiver ADC requirements. The ADC dynamic range is set
based on the combination of three concerns:
– The receiver noise ﬁgure, which ideally must not be affected by the ADC quantization noise.
– The receiver available ﬁltering, and particularly the IF ﬁltering.
– The strength of the signals appearing at the ADC input, whether desired or blocker, or any
other signal due to receiver nonidealities such as uncorrected DC offsets. If the desired signal
is the main concern, the receiver gain control is then a factor as well.
As the desired signal is expected to receive plenty of ampliﬁcation by the time entering the
ADC, the unﬁltered blockers perhaps are the most critical factor. There often exists a subtle
trade-off between the IF ﬁlter order, and the ADC effective number of bits. For a given
bandwidth, once the acceptable noise is set, the higher the order, the bigger the ﬁlter, and thus
more cost. As shown in Figure 12.34, if a blocker is close to the desired signal, and hence
gm
TIA
0
ADC
In-band blocker
Modest analog ﬁlter
DSP
Sharp digital ﬁlter
0
Figure 12.34: Receiver ﬁltering and ADC requirements
12.4 Receiver Filtering and ADC Design
715

subject to little analog ﬁltering, it appears as a strong signal at the ADC input. As long as the
ADC has high enough dynamic range so as not to be compressed, the strong blocker is subject
to subsequent more aggressive digital ﬁltering, which is much cheaper.
It is fair to assume that the out-of-band blockers are subject to enough ﬁltering by the time
they appear at the ADC input. Thus, our main focus is mostly on the in-band blockers, which
are subject only to post-downconversion ﬁltering. Let us consider a few examples:
Example: GSM ADC Requirements ─As we discussed in previous section, in the case of
the low-IF receiver shown in Figure 12.20, we expect almost no ﬁltering applied to the
strong 400kHz blocker residing at the image side. We expect this blocker, which is 41dB
stronger, to set the bottleneck, and as such we calculate the ADC dynamic range as follows:
– We leave 10dB of margin for down and up fading. The fading arises from the fact that
the mobile user may be subject to a sudden drop of signal (for example the vehicle
entering a tunnel), and the receiver gain control is not fast enough to respond. Since the
signal and blocker are at different frequencies, the fading may happen in opposite
directions for each.
– A margin of 5dB is considered for inaccuracy in gain control and other nonidealities
caused by process or temperature variations.
– We would like the signal to be 20dB above the ADC noise. This may be too generous
of a margin, but ensures that the receiver sensitivity is mainly dominated by the
receiver RF blocks that are generally more difﬁcult to be managed.
When everything is added up, this leads to an ADC dynamic range of 86dB as shown in
Figure 12.35. As a result of this lineup, the desired signal lies 56dB below the ADC full
scale, which is to leave room for the blocker, up-fading, and nonidealities.
ADC Full Scale
Blocker
Margin
5dB
10dB
41dB
10dB
20dB
ADC Q Noise
Signal
Up-Fading
Blocker
Down-Fading
Noise 
Margin
86dB
Figure 12.35: GSM ADC requirements
716
Transceiver Architectures

One can go through other blocker scenarios and show that indeed the 400kHz blocker is the
most stringent as far as the ADC is concerned. For instance, even though the 600kHz blocker is
8dB stronger (Figure 12.17), once downconverted it will reside at 600 – 135 = 465kHz.
Assuming a ﬁlter passband of 235kHz (for a 135kHz IF), even a 1st-order roll-off is adequate
to make up for the 8dB difference.
Example: 3G ADC Requirements ─In the case of 3G, the ADC dynamic range is
mainly set by the need for higher SNR. As we mentioned in Chapter 6, as the desired
signal increases, the system supports higher throughput by switching into more
complex modulation schemes. This not only results in a higher SNR needed, but
also the processing gain reduces to support higher bandwidth. In the case of 3G, a
data rate of up to 21Mbps may be supported when using a 64QAM modulation
scheme, which requires a net SNR of 30dB or higher. Moreover, as we showed in
Chapter 5, the more complex modulated spectrums cause a higher peak-to average
power ration (PAR).
Once all these factor taken into account, we arrive at a total dynamic range of 72dB for
the 3G ADC (Figure 12.36).
It turns out that this dynamic range comfortably covers the unﬁltered in-band blockers
even if a simple low-cost ﬁlter is used.
In many modern receivers, higher dynamic range ADCs are enabled by providing them a
high clock frequency. Since the noise requirements of such clock signal is relatively stringent, it
is common to feed a divide-down version of the RF LO. This results in the ADC clock to vary
as the RF channel changes, but can be compensated for using a rate adapter in digital domain,
which is relatively cheap in nanometer CMOS processes (Figure 12.36).
ADC Full Scale
Margin
5dB
12dB
30dB
10dB
ADC Q Noise
Signal
PAPR
SNR
Fading
72dB
15dB
Noise 
Margin
Figure 12.36: 3G ADC requirements
12.4 Receiver Filtering and ADC Design
717

It is not uncommon to see ADCs with sampling frequencies of several GHz in many modern
radios.
12.5 RECEIVER GAIN CONTROL
..............................................................................................
As the desired signal increases, the receiver gain is expected to reduce to accommodate for the
larger signal. This, however, must be done carefully, as it is desirable to improve the receiver
SNR to support higher data rates when the signal is strong. To accomplish this goal, the receiver
front-end gain (such as the LNA gain) is ideally expected not to change unless the desired
signal is very large, strong enough to compress the front end. Ideally we expect a 1dB increase
in SNR for a 1dB increase in the signal level, which can be accomplished only if the receiver
noise ﬁgure stays constant.
Example: A practical GSM receiver [19] SNR is shown in Figure 12.38. Also shown is
the ideal SNR curve which is a straight line with a slope of one.
I
Q
ADC
ADC
DSP
Rate 
Adapter
Lowpass Filter
¸N
Figure 12.37: ADC clocked by RF VCO
Figure 12.38: The measured SNR of a GSM
receiver
718
Transceiver Architectures

There are several factors that the actual SNR could deviate from the ideal one:
– It may be desirable to reduce the front-end gain slightly to accommodate for the large
in-band blockers. In the case of GSM, the 3MHz blocker at –23dBm is strong and could
potentially saturate the receiver. As the desired signal is speciﬁed to be at –99dBm,
around this region the receiver front-end gain is slightly reduced, and thus there is a slight
deviation from the ideal curve. If a blocker detection mechanism is incorporated, this may
be done more efﬁciently, only when a large blocker is present.
– At very large inputs, the receiver SNR is not determined by the receiver chain thermal noise
any more. Other contributors such as the LO in-band phase noise, or IQ mismatches, which
are independent of the signal power, limit the SNR. At this point (around –65dBm for the
example of Figure 12.38) it may be appropriate to reduce the front-end gain.
– At around –82dBm, there are several adjacent blocker tests. These blockers are
typically not strong enough to saturate the front end, but the IF gain must be adjusted
properly. A good example of this is the 400kHz image blocker that was discussed previously.
Fortuitously, in most cases, the reduction of the IF gain has a negligible impact on the SNR.
The receiver relative RF and IF gains are hypothetically depicted in Figure 12.39. The IF gain is
expected to provide more resolution and track the signal more closely.
As we showed in the previous section, the desired signal is well below the ADC full scale.
Thus, at early stages the gain control is not as critical, and it may be deemed necessary only to
accommodate the blockers.
12.6 TRANSMITTER ARCHITECTURES
..............................................................................................
As we saw in Chapter 6, from a requirements point of view, the transmitter was more or less
dual of the receiver. We shall see in this section that from the architectural point of view, this is
also somewhat true.
Input Level, dBm
Relave Gain, dB
–95
–80
–65
–50
–35
In-band
Adajent
RF Gain
IF Gain
Figure 12.39: Receiver RF and IF gain
12.6 Transmitter Architectures
719

12.6.1 Direct-Conversion Transmitters
We showed in Chapter 2 that a single-sideband modulator consisting of a quadrature LO has
been evolved to be the basis of a Cartesian transmitter, also known as a direct-conversion
transmitter (Figure 12.40). The I and Q signals are created digitally,8 and are fed into IQ DACs
that provide the analog equivalent input to the quadrature upconverter. A lowpass ﬁlter after the
DAC is typically needed to remove the DAC image signal and possibly improve the far-out
noise. In addition, an RF ﬁlter before the antenna may be necessary to clean the output spectrum
to ensure that the far-out modulation mask is met. In the case of FDD application, the duplexer
provides the ﬁltering automatically.
Despite versatility, direct-conversion transmitters suffer from several important drawbacks:
– As we pointed out in Chapter 6, the feed-through of the LO signal to the output as well as
the I and Q imbalances lead to EVM degradation. Similar to direct-conversion receiver, IQ
calibration and LO feed-through cancellation may be employed to enhance the
performance.
– The far-out noise of the transmitter is somewhat poor as all the building blocks in the TX
chain, as well as the LO generation circuitry contribute. This problem is dealt with using
alternative topologies that we will discuss shortly.
– As the transmitter output signal coincides in frequency with the VCO, this strong signal
disturbs the VCO operation once leaked to the VCO output due to ﬁnite isolation.
The latter issue, as we discussed in Chapter 6, is known as pulling, and in certain applications it
may prohibit the use of the direct-conversion architecture. To understand the impact of the
pulling issue better, consider Figure 12.41, which shows a direct-conversion TX transmitting a
tone at a frequency offset of fm from the carrier. As a result, at the power ampliﬁer output a
strong signal at fLO + fm appears. Given the ﬁnite isolation between the PA output and the
VCO, this component leaks back to the VCO, and creates unwanted sideband at fm away from
coswLOt
sinwLOt
PA/PAD
I
Q
DAC
DAC
DSP
Figure 12.40: Direct-conversion transmitters
8 As we said in Chapter 2, the I and Q baseband signals are statistically independent in most modern radios.
720
Transceiver Architectures

the VCO output signal. Consequently, once this corrupted spectrum is fed to the mixers to
upconvert the baseband input, the transmitter EVM and modulation mask are affected adversely
[20]. See Chapter 6 for more details.
To alleviate this issue, one may consider using a VCO at twice the frequency along with a
divider by two. This has the added advantage of creating quadrature LO signals readily. By
employing a divider, the VCO and PA output frequency are spaced far from each other, and the
pulling is expected to improve, as the pulling strength is shown to be inversely proportional to
the frequency offset between the signals [20], [21], [22]. This, however, is not quite true as the
pulling could be still signiﬁcant due to the 2nd-order nonlinearity of the PA, which is often very
strong (Figure 12.42).
PA/PAD
… 
coswLOt
sinwLOt
coswmt
sinwmt
fLO
fm
fLO
fm
To TX
fm
Figure 12.41: Pulling in direct-conversion transmitters
PA/PAD
… 
coswmt
sinwmt
½f0
fm
f0
2fm
2fm
¸2
( )2
Figure 12.42: Using divider to alleviate the pulling
12.6 Transmitter Architectures
721

Alternatively, one may choose a dual-conversion architecture, where the VCO and TX
frequencies are not harmonically related anymore. We shall discuss this next.
Example: As a case study, an example of an LTE transmitter using the direct-conversion
architecture is shown in Figure 12.43. The pulling is simply avoided by using a divide by
2/4 to produce high/low band LO signals, along with a careful layout, and package
design.
In the 3G mode, a 10b DAC followed by a 3rd-order lowpass ﬁlter to clean that DAC
output is used. The ﬁlter is about 2MHz wide. The mixers are 25% passive, followed by a
PA driver that provides over 70dB of gain control. That along with additional 10–20dB
gain control provided by the PA are sufﬁcient to cover the 74dB gain range needed in 3G
standard. The LTE mode is also very similar except for the ﬁlter that is wider. We shall
discuss more details of the transmitter later in this chapter (Section 12.7.2).
12.6.2 Dual-Conversion Transmitters
As shown in Figure 12.44, similar to receivers, a dual-conversion transmitter employs two steps
of upconversion [9]. The main advantage is considerably less sensitivity to pulling.
In order to use only one VCO, similar to receiver, the 2nd quadrature LO is obtained through
a divider. With the VCO frequency at fLO1, the TX output frequency is
f TX = f LO1 1 + 1
N


:
Clearly the two frequencies are not harmonically related anymore, and thus the pulling is
expected to be of little concern. If this architecture is employed for the transmitter for obvious
PAD
I
Q
DAC
DAC
DSP
PA
Duplexer/
Switch
70dB
10–20dB
–50  to +24dBm
÷ 2/4
LOI
LOQ
4GHz
10b, 104MHz
25%
3rd Order
Figure 12.43: A typical 4G direct-conversion transmitter
722
Transceiver Architectures

pulling concerns, the choice of the VCO frequency and the frequency planning involved
inevitably dictates a dual-conversion architecture for the receiver as well, despite the fact that
there may not be as much advantage for the RX.
An alternative architecture that alleviates the pulling issue similar to dual-conversion archi-
tecture but still enjoys the simplicity of direct-conversion transceiver is to exploit a VCO
frequency shifting circuitry shown in Figure 12.45 [23], [24].
Once the VCO is mixed with its own divided version, it creates LO outputs that are related to
the original VCO frequency by
f LO = f VCO 1  1
N


,
which is similar to the dual-conversion TX. In addition, the quadrature LOs are readily
available due to the divider (as long as N = 2n). The drawback of this scheme as well as the
dual-conversion TX is the spurious signals produced as a result of mixing. Proper ﬁltering,
often with the help of tuned buffers, must be employed, which leads to larger area and cost. In
the latter approach of VCO shifting, the mixing is not in the signal path, which is advantageous
especially for the receiver.
12.6.3 Direct-Modulation Transmitters
Despite the fact that the direct conversion architecture is very versatile and beneﬁts from
relatively low complexity, some important repercussions apply when used in certain applica-
tions such as cellular:
LO2I
LO2Q
PA/PAD
LO1
¸N
LO2I
LO2Q
LO1
… 
Figure 12.44: A dual-
conversion transmitter
¸N
LOI
LOQ
To Direct-
Conversion TX
Figure 12.45: LO generation circuitry
to avoid pulling
12.6 Transmitter Architectures
723

1. In Chapter 6 we saw that in order not to desensitize a nearby receiving mobile handset, a
very stringent transmitter noise level of –79dBm at the corresponding receive band is
speciﬁed. This translates to a phase noise of –165dBc/Hz at an offset frequency of
20MHz at the RF IC output. In the case of a direct-conversion TX, in addition to the voltage
controlled oscillator (VCO) and the local oscillator (LO) chain, the entire TX path such as
the DACs, reconstruction ﬁlters, and active or passive mixers contribute to this noise.
2. Even though the GSM signal is only phase modulated, in the case of a direct-conversion
architecture the linearity of the modulator and the PA is a concern. This may sound
counterintuitive at ﬁrst, but can be understood by noting that in the switching mixers used
in most modulators a replica of the modulated input of opposite phase exists at the LO third
harmonic. When mixed down due to the third order nonlinearity of the PA or the PA driver,
this signal replica could cause degradation of the modulation spectrum. This was detailed in
Chapter 8.
3. As we discussed earlier, despite operating the TX VCO at two or four times the output
frequency in most common radios, a direct-conversion scheme suffers from the potential
pulling caused by the PA running at 2W, and drawing more than 1A of current from the
battery.
4. As we pointed out, direct-conversion transmitters generally require good I  Q imbalance in
the signal and LO path. Although the requirements can be met by adopting some kind of
calibration, it adds to the complexity. Moreover, the DC offset of the baseband section
including the DAC and the following reconstruction ﬁlters needs to be corrected.
For these reasons GSM transmitters have traditionally adopted an alternative architecture, using
translational loops [25] to eliminate the external front-end ﬁlter at reasonably low power
consumptions as shown in Figure 12.46.
The PLL feedback forces the VCO output to be a replica of the modulated input spectrum fed
to the phase frequency detector (PFD), thus translating the IF spectrum to RF. Unlike the
direct-conversion case, here only the VCO and LO chain contribute to the far-out noise, as
usually the PLL bandwidth is narrow enough to suppress the noise of the rest of the loop,
including the mixer and its LO. It is clear that
f VCO = f LO + f IF,
PA/PAD
PFD/CP
Modulator
DAC
LO
fVCO
fIF
Figure 12.46: Translational loops used as
GSM transmitters
724
Transceiver Architectures

where LO is a tone created by a second PLL, but the IF signal is frequency modulated, and thus
so will be the output signal fed to the antenna.
The translational loop can be simpliﬁed to a direct-modulated PLL [19], [26], [27], [28],
where modulation is injected via a ΔΣ modulator by changing the fractional divider modulus
over time (Figure 12.47).
The main advantage is the elimination of the baseband modulator needed in the translational
loop, which could be a potential noise and nonlinearity contributor. The LO needed for the
mixing in the loop can be eliminated as well, which reduces the area and power consumption
further. This typically requires the PLL to run off the available 26MHz crystal oscillator,
although one may choose to adopt an auxiliary PLL to ease some of the typical problems of
the fractional PLLs caused by low-frequency reference signal [19]. Overall, if designed
properly, the direct-modulated PLL leads to substantial area and power savings, yet meeting
the GSM stringent far-out noise requirements.
As we showed in Chapter 6, to meet GSM close-in mask, a stringent phase noise requirement
of better than –118dBc at 400kHz for the entire PLL is required. To meet this challenge, the
PLL bandwidth is typically chosen to be 100 to 200kHz to minimize the noise contribution of
the reference, the loop ﬁlter, and the charge pump (CP). Even with such a narrow bandwidth,
the rest of the PLL may contribute as much as 1~2dB, leading to a stringent noise requirement
of <–120dBc/Hz for the TX VCO. Since the loop bandwidth is relatively narrow, the
frequency modulated (FM) equivalent spectrum will be subject to distortion. Such distortion
can be compensated with a digital predistortion block whose frequency response is the inverse
of the PLL, hence providing an overall all-pass shape for the injected modulation
(Figure 12.47). However, as the PLL characteristics tend to vary over process the overall
response will generally not be ﬂat, causing phase error degradation in the transmitted signal. It
is often critical to employ some kind of calibration to stabilize the PLL bandwidth, particularly
due the VCO gain variations [19], [30]. Alternatively a digital PLL may be chosen [27], [28] at
the expense of more power consumption, and increase in the spurious level of the output
spectrum.
There are also some concerns with the nonlinearity of the PLL components such as the
charge-pump or the VCO as that the VCO control voltage is not a DC signal anymore, rather
carries modulation. This is not a major concern for GMSK, but as we will discuss shortly, it
may become a problem for higher data rate applications such as EDGE or 3G.
PFD/CP
MMD
DS
PA/PAD
Modulator/
Predistoron
REF
Figure 12.47: Direct-modulated PLL
12.6 Transmitter Architectures
725

12.6.4 Polar Transmitters
The main disadvantage of the PLL-based transmitter is its lack of support for amplitude
modulated standards as the VCO is capable of producing only a phase modulated spectrum.
A time-varying AM component, as needed for EDGE modulation for instance, can be super-
imposed on the PM signal, as shown in Figure 12.48. Known as a polar transmitter, it has been
originally devised to boost the power ampliﬁer efﬁciency. As more complex modulations that
support higher data rates come at the expense of higher PAPR, a better linearity from the PA is
demanded, leading to a poor efﬁciency.
To ameliorate this fundamental trade-off, one could break the IQ signals into phase (θ) and
amplitude (r), or from Cartesian into polar domain:
I + jQ $ re jθ:
The phase modulated signal is created by a VCO/PLL, which essentially form a direct-
modulated transmitter as was discussed. Accordingly, the phase signal is directly fed to the
PA, and ideally often drives the ampliﬁer into near saturation, hence not compromising the
efﬁciency. The amplitude content is applied to the PA commonly through modulating its supply
voltage (Figure 12.48). Once aligned properly, the composite PA output signal carries the
intended phase and amplitude modulation.
A modern polar transmitter based on the concept just described is shown in Figure 12.49
[29], [30], [31]. The AM signal is typically produced by employing another ΔΣ modulator,9 as
shown in Figure 12.49.
The modulator produces the phase (PM) and amplitude (AM) components digitally. The PM
is fed to the PLL, which is expected to create a frequency (or phase) modulated spectrum at the
VCO output. The AM component, once passed through the ΔΣ DAC, modulates the PA driver,
which can be thought of a single-balanced mixer. It is not uncommon to apply the AM into the
PA driver, rather than the PA, and use a linear power ampliﬁer, often known as small signal
PA
CORDIC
AM
PM
PLL
I
Q
VDD
Figure 12.48: A conceptual
polar transmitter
9 This is merely to enhance the DAC performance. Otherwise, the use of a ΔΣ modulator for the AM path is not a
requirement of polar architecture.
726
Transceiver Architectures

polar architecture. This is done merely to avoid extra complexity when the PA nonideal effects
are considered. Although this does not take full advantage of the efﬁciency improvement idea,
it still is advantageous compared to the alternative choice of using a direct-conversion trans-
mitter for the reasons already discussed. The PA driver still can operate closer to saturation
compared to a linear TX, further improving the power consumption. Additionally, the polar TX
enjoys a simpler 50%, single-phase LO path, as opposed to the linear transmitters that typically
require quadrature 25% LO, exacerbating the power efﬁciency problem.
When using a polar transmitter, in addition to the PM path, the AM path is a key factor [30].
The PM issues remain the same as the ones described for the case of direct-modulated TX,
however, with a greater impact on performance. To understand this better, it is beneﬁcial to
study the phase and amplitude spectrums individually before being combined at the PA driver
output. An example of an EDGE spectrum is shown in Figure 12.50.
PFD/CP
MMD
DS
PA/PAD
Modulator
REF
AM
PM
A(t)
cos(wct+f(t))
A(t)cos(wct+f(t))
DS
DAC
Figure 12.49: Modern polar transmitter
Figure 12.50: PM and AM signals
corresponding to an EDGE polar transmitter
12.6 Transmitter Architectures
727

Compared to the ideal output, both the PM and AM spectrums are considerably wider.
Particularly the PM signal is very wide, drooping by only about 30dB at 400kHz offset,
compared to 68dB for the ideal EDGE spectrum. Although this spectral growth may be
mathematically proven by examining the modulation properties of the I and Q signals, and
their nonlinear transformation into polar domain, we shall present a more intuitive perspective
here in the context of the following example.
Example: A signal that carries both amplitude and phase modulation is passed through an
ideal limiter, leading to the amplitude component being stripped away. Thus, we are left
with only a phase modulated signal (Figure 12.51). That is because the limiter does not
affect the zero-crossing dictated by the phase (or frequency) modulation. In other words,
by applying the EDGE signal into an ideal limiter, one expects to produce the PM
contents only.
Now suppose only a tone at a frequency of fm representing the highest frequency
content of the modulated signal is considered. Clearly this signal has a bandwidth of fm.
Once passed through the limiter, however, strong components at all odd harmonics are
produced, and hence the signal at the limiter output has an inﬁnite bandwidth. Particularly
the tone at 3fm is only 10dB lower, resulting in substantially wider signal for the PM
only contents.
The PM spectral growth demands larger swings at the VCO input, thus raising the sensitivity
to nonlinearities. The swing at the VCO input of an EDGE transmitter assuming a VCO gain of
about 2ϕ40MHz/V is shown in Figure 12.52. Representing the PM signal as
cos ωCt + KVCO
ð
f τð Þdτ


,
the swing (f(t)) depends only on the EDGE PM characteristics, described by ϕ(t) = KVCO
Ð
f(τ)
dτ, which is known, and the VCO gain (KVCO). Although increasing the VCO gain helps, it
results in phase noise degradation. If the PLL bandwidth is set to around 200kHz or less as
PM
A(t)cos(wct+f(t))
cos(wct+f(t))
fm
… 
fm
3fm
Zero-crossing 
not affected
Figure 12.51: Producing the PM signal employing an ideal limiter
728
Transceiver Architectures

demanded by stringent phase noise requirements at the key 400kHz offset, the loop gain is
expected to drop at 400kHz and beyond. Thus, the PLL feedback becomes almost ineffective,
pronouncing the negative impact of loop nonlinearities in the presence of larger swings.
Moreover, a narrow bandwidth increases the sensitivity to variations. This is illustrated in
Figure 12.53, showing that the desired all-pass response set by the combination of the PLL and a
digital predistortion is subject to distortion if the analog PLL characteristics vary. As mentioned,
either the PLL must be well calibrated, or a digital PLL may be employed.
This issue is dramatically worse if a wider application such as 3G is considered. Now, the
composite 3G signal is about 1.9MHz wide, whereas the PM component is about 10MHz
[31]. Such a wide signal not only suffers substantially more from narrow PLL variations, but
also becomes much more sensitive to the VCO nonlinearity. The latter may be resolved either
by using a digital VCO/PLL [29], or by incorporating some kind of feedback to linearize the
VCO [31], [32]. The former issue may be alleviated by employing a two-point PLL as shown in
Figure 12.54 [29], [31].
µ
A(t)
f(t)
cos(wct+ (t
∫f
dt)
)
Figure 12.52: Swing at the VCO input for a polar EDGE transmitter
Figure 12.53: Impact of variations of PLL characteristics
12.6 Transmitter Architectures
729

Applying a second signal to the VCO control voltage directly creates a highpass response,
and once the two responses are combined, the net PLL characteristics becomes all-pass. For the
two frequency responses to match perfectly, still the VCO gain must be very well behaved.
In addition to the nonidealities of the AM and PM paths individually, the alignment between
the AM and PM signals becomes critical, as shown in Figure 12.55.
Example: To understand the AM–PM alignment requirement, suppose there is a small
delay of τ between the two paths; thus when combined, the output will be
PFD/CP
MMD
PA/PAD
Modulator
REF
AM
PM
DS
DS
DAC
Figure 12.54: A two-point PLL to extend the useful bandwidth
Figure 12.55: AM–PM alignment
inaccuracy causing mask violation
730
Transceiver Architectures

A t  τ
ð
Þ cos ωCt + ϕ tð Þ
ð
Þ:
Using the Taylor expansion of the amplitude component, A(t), around τ we have
A t  τ
ð
Þ  A tð Þ  τ ∂A
∂t ,
which results in the original signal as well as an error term:
A tð Þ cos ωCt + ϕ tð Þ
ð
Þ  τ ∂A
∂t cos ωCt + ϕ tð Þ
ð
Þ:
The error waveform, whose amplitude is proportional to the small delay, is formed by
the time-derivative of the desired envelope modulated to the carrier frequency. Differ-
entiation in time will accentuate high-frequency content in the envelope, leading to an
error spectral density that could encroach into adjacent channels and possibly violate the
transmit mask.
From Figure 12.55, in order not to degrade the EDGE spectrum signiﬁcantly, an alignment
error of less than 20ns is needed. Thus, the PLL bandwidth as well as that of the AM path
reconstruction ﬁlter must be tightly controlled. For the 3G case, the requirement is considerably
more stringent; only a delay of a few nS may be acceptable. Thus a much tighter control of the
PLL characteristics is needed.
As for the AM path, both the AM–AM and AM–PM nonlinearities are important factors.
Especially AM–PM generated in the PA or the PA driver (in the case of small signal polar TX)
is a key contributor. As we discussed before, presence of a strong AM–PM not only causes
modulation mask degradation, but also results in an asymmetric spectrum. Shown in Figure 12.56
is the measured +400kHz and –400kHz modulation mask of a polar EDGE transmitter in the
presence of AM–PM nonlinearity in the PA driver. With the correct alignment, the modulation
mask improves, but remains asymmetric when AM–PM distortion is present. Once the AM–PM is
Figure 12.56: Impact of AM–PM
nonlinearity on an EDGE polar transmitter
12.6 Transmitter Architectures
731

corrected through digital calibration, the two sides become symmetric, and in addition a 2dB
improvement in the modulation mask is observed.
Using a nonlinear power ampliﬁer, the AM–PM and AM–AM distortion are expected to be
considerably worse. As we said earlier, it may be more practical to consider a small signal polar
transmitter, and still beneﬁt from a number of advantages mentioned. This results in a subpar
efﬁciency, but more robust performance for the overall transmitter, especially when production
issues considered.
Finally, similar to direct-conversion architecture, the PM feed-through (as opposed to LO
feed-through as LO is modulated) causes both EVM and mask degradation. The latter has to do
with the wide nature of the PM signal, whose magnitude does not drop enough at the key offset
frequencies of 400 and 600kHz.
12.6.5 Outphasing Transmitters
Another attractive transmitter architecture that takes advantage of a high-efﬁciency PA, yet is
capable of transmitting nonconstant envelope signals is outphasing, invented by Chireix [33].
Later rediscovered, and named by Cox in 1975 [34], the outphasing transmitter is also known as
LINC, which stands for linear ampliﬁcation using nonlinear components. The basic idea is
described in Figure 12.57. The modulated phasor whose magnitude and phase are both time-
varying is decomposed as a sum of two constant amplitude but phase-varying phasors. The
resultant two phasors are mirrors of each other with respect to the original one. Such decom-
position is also called signal component separation.
For a general amplitude and phase modulated phasor of A(t)ejθ(t), deﬁning the mirrored phase
component ϕ tð Þ = cos1 A tð Þ
2A0 , we have
A tð Þejθ tð Þ = 2A0 cos ϕ tð Þ
ð
Þejθ tð Þ = A0e j θ tð Þ + ϕ tð Þ
ð
Þ + A0e j θ tð Þϕ tð Þ
ð
Þ:
PA1
PLL
PLL
PA2
Signal 
Separator
A(t)e jq(t)
A0ej(q(t)+f(t))
A0e j(q(t)–f(t))
Figure 12.57: Concept of outphasing
732
Transceiver Architectures

The corresponding phase-only modulated RF signals (A0ej(θ(t)  ϕ(t))) can be ampliﬁed by two
highly efﬁcient nonlinear power ampliﬁers. The ampliﬁed signals can conceptually be com-
bined to reconstruct a high-power version of the intended modulated signal. The gains and
phases that the two outphasing signals experience must be well-matched. As the two paths are
identical, performing a careful and symmetric layout is a necessity in order to achieve a good
phase/gain matching between the two transmitter paths. Any mismatch between the two
transmitter paths along with other imperfections such as mutual interactions between the two
PAs can be compensated to some extent through digital predistortion of phases in the two signal
paths [35].
The major challenge of the outphasing transmitter is combining the outputs of the two high-
power PAs. A low-loss power combiner is needed to efﬁciently add the two PA outputs. It also
has to be passive in order to deal with large voltage swings. The combiner should also provide a
good isolation between the two PA outputs, while combining their signals and delivering the
net power to the antenna. Furthermore, the two PAs must experience a ﬁxed load while the RF
signal’s envelope varies, in order to maintain their good efﬁciencies. The latter condition can be
met if the two ports of the combiner are impedance-matched. However, it can be shown that a
lossless three-port passive network cannot satisfy the matching conditions [36]. To satisfy the
matching requirements, a fourth port terminated to a lossy resistor is needed. The signal
delivered to the fourth terminal would be the difference of the two PA outputs while their
sum would be delivered to the antenna. With this scheme, for a given PAPR at the output,
(PAPR-1) times of the transmitted power is wasted in the resistor of the fourth terminal.
Therefore, even with a 3dB PAPR (or 2 in linear scale), the wasted power is roughly the same
as the transmitted power, imposing an upper limit of 50% for the transmitter efﬁciency.
Including the ohmic loss of the four-port combiner, the overall loss can be as large as 4dB.
With a PAPR of 10dB, the upper limit for the efﬁciency would be 10%, which is no longer
acceptable.
Due to its poor efﬁciency, the four-port combiner is not an attractive solution. Focusing on
the three-terminal combiner (also called the Chireix combiner), consider Figure 12.58, where
the two PAs are to put out two constant-envelope signals, given by A0ej(θ  ϕ) and A0ej(θ + ϕ).
Consequently, the combined output signal delivered to the antenna would be 2NA0 cos ϕ(t) 
cos(ωLOt + θ(t)) = A(t) cos(ωLOt + θ(t)), where A(t) = 2NA0 cos ϕ(t), and N is the transformer’s
PA1
PA2
A0ej(q(t)+f(t))
A0ej(q(t)–f(t))
Z1
Z2
RANT
Figure 12.58: Outphasing transmitter with
three-point combiner
12.6 Transmitter Architectures
733

secondary to primary turn ratio. It can be shown that the impedances seen by two PAs vary over
time, and are given by the following two expressions [36],
Z1 = Rant
2N2 1 + j tan ϕ
ð
Þ
Z2 = Rant
2N2 1  j tan ϕ
ð
Þ,
where Rant is the input impedance looking into the antenna. Therefore, the PA loads are
modulated by the outphasing angle, ϕ, indicating that their outputs would no longer be
constant envelope, defeating the original purpose of outphasing. This would lead to a large
magnitude and phase distortions in the ﬁnal RF signal, and must be somehow corrected. One
approach to correct the PA’s load modulation is proposed in [36], which uses switched
capacitors at the PAs outputs. By switching them in or out at the outputs of the two PAs
based on the instantaneous values of ϕ, the reactive portions of the load modulation are
compensated. The real part may be compensated through scaling of the current sources used
to deliver the power in the two PAs. There are still several challenges in the proposed scheme:
The design is open-loop, and in practice the parasitic effects may limit the performance,
especially at high frequencies. Also, the three-port combiner prohibits the differential
implementation.
Besides the problems associated with the power combining, the outphasing transmitter
architecture is not suitable for applications where a large range of power control is needed.
Given all the aforementioned problems, the outphasing transmitter architecture is seldom used
in modern wireless devices.
12.7 TRANSCEIVER PRACTICAL DESIGN CONCERNS
..............................................................................................
We conclude this chapter, and the book, by discussing several practical issues associated with
real-life transceivers and provide a few case studies. Although the majority of the designs have
been discussed in detail, we mostly focus on practical aspects of them.
Shown in Figure 12.59 is a general description of RF design ﬂow, from inception of a product
up to volume production. We have already discussed in Chapters 5 and 6 how to derive the circuit
and system parameters for a given standard. We have also shown in Chapters 9–11 how to select
the right circuits for a given application, and design them accordingly. Once the design is
complete and the radio has been fabricated, there are two levels of veriﬁcation involved:
– Device veriﬁcation and testing (DVT): This involves radio veriﬁcation and optimization. If
the ﬁrst silicon (often labeled as A0) does not meet all the requirements, revisions are
required. In a metal-only tape-out, the revision number changes (e.g., A1), whereas if an
all-layer tape-out is deemed necessary, the letter changes (e.g., B0).
– Automatic testing equipment (ATE): This is a fully automated process, and lasts as long as
the product is being shipped. Unless the requirements are guaranteed to be met by design, the
automatic testing is performed on every part that is to be shipped.
734
Transceiver Architectures

As the ATE and DVT environments are inherently different, often a careful correlation process
between the two is needed to ensure that the ATE results are accurate. This is often known as
bench-ATE correlation process.
In this section, we will brieﬂy discuss the production-related concerns describe above. We
shall start with a few case studies, and then discuss the challenges of volume production.
12.7.1 Receiver Case Study
As our ﬁrst case study, let us start with a cellular receiver designed in 40nm intended for 2/3G
applications. The design can be extended to support LTE by adjusting the IF bandwidth. This
radio is currently in volume production, and its die microphotograph is shown in
Figure 12.60.
A simpliﬁed block diagram of the receiver and the corresponding gain distribution is shown
in Figure 12.61. It uses a current-mode passive mixer with 25% duty cycle LO signals. The TIA
is a common-gate design with a 1st-order RC roll-off at its output (280kHz/1.7MHz for 2/3G),
followed by an active RC biquad.
The 2G receiver uses a low-IF architecture with an intermediate frequency of 135kHz.
The receiver front end is shown in Figure 12.62. The LNA is an inductively degenerated
design that uses two stages of current steering to provide three gain steps.
The general performance and key challenges are highlighted below:
– A noise ﬁgure of less than 3.5dB over temperature at all frequencies. There is about a typical
noise contribution of 25% from the matching, 25% from the LNA devices, and 20% from
the TIA.
– An IIP2 of better than 50dBm at TX frequency.
– In-band IIP3 of better than –6dBm, and out-of-band IIP3 of better than –1dBm.
– A blocker noise ﬁgure of better than 10dB for the GSM (especially 600kHz and 3MHz
blockers).
Standard
System
Circuits
DVT
ATE
Revisions
Sensivity, 
Blockers, ...
Noise, 
Linearity, ...
Characterizon, 
Opmizaon, 
Corner lots
Yield, 
Reliability, 
Robustness
Correlaon
Figure 12.59: RF product design ﬂow
12.7 Transceiver Practical Design Concerns
735

– An EVM of less than 2% corresponding to better than 35dB SNR. This ensures that the
receiver can support 64QAM modulation, intended to be used in HSPA+ mode, which
achieves a data rate of over 20Mbps.
As an example, the 3G receiver sensitivity for band I (2110–2170MHz) for two values of PA
power is shown in Figure 12.63.
The receiver sensitivity degrades by only a fraction of a dB when the transmitter operates at
its full 23dBm power at the antenna (as opposed to –5dBm for the other case). This shows that
the transmitter noise as well as the receiver second-order distortion are adequately met.
12.7.2 Transmitter Case Study
As our second case study, we describe design details of a reconﬁgurable multiband multimode
cellular transmitter covering all four bands of EDGE/GSM 2.5G and ﬁve bands of WCDMA
3G. The block diagram of the transmitter is presented in Figure 12.64. The transmitter has four
single-ended RF outputs; of those, two cover high bands and the other two cover low bands.
Furthermore, for each of the high or low bands, one of the two dedicated RF outputs is assigned
for the 3G mode and the other one for the 2G mode. Except for the constant envelope GSM
mode where the TX is conﬁgured to operate as a direct-modulation transmitter, for all other
modes of operation the transmitter architecture is linear IQ direct-conversion. The transmitter
RX
TX
RX VCO/PLL
TX VCO/PLL
Figure 12.60: 3G transceiver die photo in 40nm CMOS
gm
TIA
ADC
Biquad
TIA
ADC
3~49dB
280k/1.7M
85/71dB
–6~16dB
Figure 12.61: 2/3G receiver architecture
736
Transceiver Architectures

features two on-chip baluns as loads of the on-chip PA drivers, one for the high-band RF
outputs and one for the low-band ones (Figure 12.64). Besides the differential-to-single-ended
conversion responsibility, these baluns also provide on-chip 50 Ω matching for the single-ended
RF outputs for all bands and modes with no need to any external matching components. All
building blocks of the TX-RF front end prior to the baluns, such as DACs, LPFs, upconversion
LC-MN
TIA
TIA
gm
HB1
LC-MN
gm
HB2
LC-MN
gm
HB3
VDD
LC-MN
gm
LB1
LC-MN
gm
LB2
VDD
I
Q
1.7–2.2GHz
0.8–1GHz
Figure 12.62: 3G receiver front-end details
Figure 12.63: 3G receiver sensitivity
12.7 Transceiver Practical Design Concerns
737

mixers, and PA drivers, have been designed differentially, although for simplicity only one path
is shown.
In the GSM mode, the DACs, LPFs, and upconversion mixers are all powered down, and the
corresponding PA driver is biased in the class B region. The PA driver differential inputs are
driven directly by phase-modulated LO clocks derived from the VCO through a frequency
division of two or four for the high and low bands, respectively.
In EDGE or 3G modes, the upconversion mixer is passive operating in the voltage mode,
whose switches are driven by 25% LO clocks. In the linear mode, the PA driver operates in the
class A region for a superior linearity. All the gain controls are implemented at the RF side after
the upconversion mixer with 72dB gain control embedded in the PA driver and 12dB in the
secondary of the balun. As we discussed in Chapter 8, having all the gain control after the
passive mixer causes the LO feed-through (LOFT) to be proportionally scaled up or down with
the transmitted power. Similarly, the post-mixer gain control leads to a single point calibration
against the mismatch between the I and Q channels because the image rejection ratio (IRR)
remains intact with the gain control.
The circuit of the PA driver is shown in Figure 12.65. The input devices act as transconduc-
tance converting the differential input voltage to a differential current, which ﬂows into the PA
driver load after passing through two cascode stages. The supply voltage for the PA driver is
2.5V, which is why devices in the second cascode stage are high-voltage transistors to
guarantee a reliable operation across all output power levels and temperature conditions. As
mentioned earlier, the PA driver is loaded to a differential-to-single-ended balun. The balun and
the PA driver have been codesigned in such a way that the simulated and measured return loss
looking into the RFIC is better than –10dB. The capacitor arrays in the primary of the balun are
tuned for maximum output power for various bands of operation.
Imposed by the 3G standard, an overall range of 84dB or 14 bits of power control was
implemented in the transmitter. Six bits of this power control is embedded in the transconduc-
tance stage of the PA driver. As shown in Figure 12.65, this stage is composed of 63 identical
unit cells, in which by disconnecting gates of the cascode devices from the bias voltage and
connecting them to the ground the unit is disabled or enabled otherwise. The 63 unit cells are
laid out as an array of 7  9 cells surrounded by extra dummy cells around the boundary for a
I/Q
I/Q
I/Q
Figure 12.64: 2/3G transmitter block diagram
738
Transceiver Architectures

better matching among the cells. Reducing the power level by disabling the transconductance
units lowers the power consumption of the transmitter proportionally, which is very desirable in
3G systems.
Another 36dB or 6 bits of the power control is embedded in the second cascode stage of the
PA driver, where a portion of the signal current generated by the transconductance stage can be
diverted away from its main path into 2.5V supply voltage. For this purpose this stage is
composed of ﬁve parallel pairs of cascode devices with their sizes increased in binary format
and their drains supplying the primary of the balun. Each pair is accompanied with another pair
of transistors with similar sizes but with drains shorted to the PA driver’s supply voltage. Gate
voltages of transistors in the two pairs are complementary to each other. Another 12dB or 2 bits
of the power control is implemented in the secondary of the balun by stealing a portion of the
signal current away from the 50 Ω load of the external PA into the AC ground.
The lowpass ﬁlter is a reconﬁgurable two-stage third-order Butterworth with complex poles
implemented in the ﬁrst stage, and the real pole in the following buffer (Figure 12.64). The ﬁrst
stage is an active-RC ﬁlter. The bandwidth of the ﬁlter is adjustable from 100KHz for the 2.5G
EDGE mode to 2MHz for the 3G WCDMA mode. Since the passive ﬁlter does not have the
driving capability, the interstage buffer is placed between the LPF and the passive mixer. This
buffer must have the following key stringent performance requirements: (1) a good linearity
while handling a differential 1V p–p swing at its output; (2) low output impedance (<5Ω) over
the desired signal band in order to accommodate a large conversion gain for the mixer; (3) low
output noise at the RX band, i.e., 20MHz for the EDGE mode and 45MHz and beyond for the
VDD
VDD
VB
VB
Figure 12.65: Circuit of the PA driver
12.7 Transceiver Practical Design Concerns
739

3G mode; and (4) large output impedance at the RX band to lower the conversion gain for the
noise components of the buffer residing at these frequencies.
While the use of passive mixer with 25% duty cycle provides power and area advantages, it
imposes challenging requirements for the previous driving circuit in addition to the aforemen-
tioned difﬁcult requirements. The switching action of the passive mixer makes the PA driver
input capacitance appear as a resistor seen from the baseband side of the mixer. This resistor is
inversely proportional to the product of the input capacitance seen from the PA driver and the
TX-LO frequency. For the high-band mode, this resistor is the lowest equal to 500Ω differen-
tially for the designed PA driver. Using a simple source follower as the buffer is not a good
option as it would suffer from a moderate linearity, and a poor driving capability due to its large
output impedance.
To alleviate these drawbacks without jeopardizing the noise performance, the source-
follower buffer was modiﬁed to the one shown in Figure 12.66, where feedback has been
added. Only one half of the differential circuit is shown for simplicity. The basic idea behind
this circuit is that the feedback loop forces the current passing through M1 and therefore gm1 to
be constant. As a result, nonlinearity due to the transconductance variations is minimized, and
node S1 follows Vin with a ﬁxed gate-source voltage drop. Moreover, this results in the buffer
output impedance seen by the upconversion mixer to be very low.
As node D1 is low impedance (due to M4), it causes the current source M3 to remain almost
unaltered across the entire range of input and output swings. The only high impedance node in
the buffer circuit is the drain of M4 (and current source M5), which makes compensation of the
feedback loop very convenient. At the RX frequency offset the loop-gain diminishes thanks to
the pole created by C1 and R1, which increases the output impedance looking into the buffer as
a result. The increased output impedance of the buffer lowers the conversion gain for the noise
components of the buffer compared to that of the desired signal improving the out-of-band
VOUTP
VINP
Figure 12.66: Circuit of the buffer driving the TX mixers
740
Transceiver Architectures

noise performance of the transmitter. For the EDGE mode where the RX band noise is located
at 20MHz offset, the resistor R1 is included in the feedback system, while it is bypassed for the
3G mode to widen the feedback bandwidth.
The transmitter delivers an output power of 6.3dBm for 3G mode, with better than –40dBc
ACLR at 5MHz. The measured EVM is 3.4/4.3% for LB/HB outputs. A receive-band noise of
better than –160dBc/Hz is achieved.
12.7.3 SoC Concerns
To lower cost and size, it is common to integrate many functions in the same silicon, including
RF, analog, mixed-mode, and digital building blocks. Known as system-on-a-chip (SoC), there
are several practical concerns arising from the coupling of the noisy baseband blocks to the
critical radio components, such as the VCO or LNA. Especially in cellular applications, very
stringent noise and spur requirements are targeted, and must be satisﬁed with careful layout and
architectural techniques.
The principles of power and signal integrity were detailed in Chapter 7. We will present some
highlights here. There are several coupling sources, such as substrate, supplies, package, and the
board. In order to minimize those we may take a two-step approach. One is to minimize the
coupling itself, while the second scheme is to improve the radio resilience to coupling, which is
inevitable no matter how good of an isolation is achieved. As for the former, shown in
Figure 12.67, there are several well-known techniques often employed to minimize the coupling:
1. On-chip linear regulators (LDO or low-drop output) help isolate the supply of the radio
blocks, and particularly the sensitive ones such as the VCO. Multiple bypass capacitors
Noisy 
Digital
Magnec 
Coupling
LDO
Control lines
CMOS Sub.
Deep N-well
Clean Sub Contacts
Dummy
Figure 12.67: Sources of coupling in
an SoC
12.7 Transceiver Practical Design Concerns
741

comprising high-density MOS capacitors with linear fringe on top may be used to provide a
low-resistance path to the local clean ground.
2. A wide Deep N-well guard band may be placed between the radio and the rest of the
baseband, with proper ground connection to a dedicated clean VSS or preferably VDD, to
reduce the CMOS substrate coupling.
3. It is common to place the radio on the top corner of the die (see Figure 12.69 as our case
study example) to provide two sides for the pads so that critical supplies as well as RF IOs
can be accessed with low-inductance routing on packages and PCB. Moreover, less noisy
baseband blocks could be placed around the radio to avoid the coupling through substrate
and package bondwires.
4. To further reduce the magnetic coupling through the package and bondwires, dummy
bondwires connected to ground may be placed between the radio and baseband sections.
Moreover, the digital and RF ground planes could be separated on package. To ensure that
the charge device model ESD (electrostatic discharge) targets are met, secondary ESD
protection between RF and digital domains could be used. Most low-cost handsets do not
allow any bypass components at the back side of the phone, where the key pad is placed.
Thus the sensitive radio supplies that require low-inductance bypass must be located as close
as possible to the periphery of the package.
As it is not possible to entirely eliminate the coupling, especially in a low-cost SoC with a cheap
package option, the radio tolerance to noise sources must be enhanced. To achieve that, several
architectural techniques can be employed:
1. A clock shifting scheme may be implemented in the baseband where a different frequency
created by a fractional PLL, is assigned near the harmonics of troublesome baseband clocks,
thus shifting the spurs away from the desired channel. Illustrated in Figure 12.68, except for a
few blocks that require a clock frequency at the exact integer of 26MHz, such as the modem, the
majority of the digital circuits such as the multimedia, the memory controller, and the periphery
run at an optional clock frequency close to an integer ratio of 26MHz, but far enough from the
critical RF channel of interest susceptible to coupling (such as EGSM channel 5 at 936MHz,
which is the 36th harmonic of 26MHz). This puts the spur created by the aforementioned blocks,
which compose the majority of the noisy baseband, far away from the desirable channel.
PLL1 
(Integer)
PLL2 
(Fraconal)
XO
Mulplexer
IO
ARM
MEM
… 
DSP/Modem
Figure 12.68: Clock shifting architecture to alleviate coupling
742
Transceiver Architectures

2. A spur cancellation block at the receiver output ensures that the downconverted spur
resulting from a 26MHz integer harmonic coupling, whose location is well predictable for
a given channel, is removed from the band of interest. This, however, is based on two
assumptions: First, the spur must be a single tone, and not a wideband modulated spectrum.
Second, the digital activity causing the spur should remain constant. Both assumptions hold
well for most cases in a receiver.
An example of a 65nm CMOS SoC intended for GSM/EDGE applications [19] is shown in
Figure 12.69.
The die is housed in a low-cost 12mm  12mm 407-pin FBGA package (see next section for
package design details). The radio analog and RF portion including the pads occupy an area of
3.95mm2, a small portion of the 30mm2 die, which is mostly taken by the baseband. Despite the
high level of integration, almost no performance degradation is observed in the sensitivity of the
receiver thanks to the techniques mentioned.
12.7.4 Packaging Concerns
The package design is often as important as the radio design itself. If not done properly, despite
the best circuits used, it may lead to poor performance, particularly RF signal loss, noise ﬁgure
degradation, coupling and spurs, and pulling.
There are several types of packages used in modern radios today, the most common ones
being FBGA (ﬁne ball grid array) and WCSP (wafer level chip scale). The latter uses bumps
inside the chip (as opposed to bonding pads), which are routed and redistributed by an RDL10
Figure 12.69: An example of a GSM/
EDGE SoC
10 RDL is an extra level of routing (typically copper) available on chip. Although originally intended for package routing,
given its relatively small sheet resistance, it may be used for general signal and supply routing, or inductor design as we
saw in Chapter 1. RDL layer is often called AP layer as well.
12.7 Transceiver Practical Design Concerns
743

layer (redistribution layer). The package balls may be directly mounted on the die, which is
cheaper. On the other hand, in an FBGA package, majority of the routing happens on the
package substrate. Two- or four-level substrates are common, although very complex SoCs
may use higher number of layers, which leads to higher cost.
Shown in Figure 12.70 is an example of an FBGA package and the design details. On the left
is the package back side consisting of 80 balls that are soldered on the PCB. Shown on the right
is some details of the package design.
The pads are ﬁrst bonded to bonding ﬁngers inside the package, which are subsequently
routed to the balls on different layers on package substrate. Below several important common
design practices are summarized:
– The supply and ground routings must be wide and short to minimize inductance. The VSS
balls may be distributed evenly across the package, to provide convenient low-inductance
connection to different parts of the radio. These VSS balls need to be connected by an
extremely low-inductance plane on the substrate (VSS islands).
– The RF routings must be as short as possible. For differential IOs, the length of the two paths
must be well matched.
– The package substrate may be isolated between sensitive RF section and noisy digital
portion. This is clearly a bigger concern for complex SoCs. This however may lead to poor
interdomain ESD protection, and is often resolved by using secondary ESD protection.
Compared to WCSP design, FBGA packages offer more ﬂexibility but are typically more expen-
sive. One other advantage of WCSP is smaller inductance due to the elimination of band wires.
Balls
Bonding Pads
Bonding Fingers
Radio
Substrate 
Roung
Figure 12.70: An example of an FBGA package
744
Transceiver Architectures

12.7.5 Variations
There are several sources of variations that may impact the radio performance:
– Devices: including threshold voltage, mobility, and oxide variations, caused by ﬁnite
accuracy of the fabrication process. They affect the device transconductance, noise, head-
room, gain or linearity. The foundry guarantees a certain window where the device
parameters (such as threshold voltage) must fall within. This is typically gauged by wafer
acceptance test (WAT) done at the foundry. An example of WAT data for NMOS
threshold voltage in 65nm process is shown in Figure 12.70. The threshold voltage is
typically measured to be 372mV, but can vary to as large as 444mV in slow corner and as
low as 320mV in fast corner. This corresponds to 4.5σ variations, with the data collected
over a large number of wafers.
In addition to process corners, there are temperature and voltage variations that must be
included. The circuit performance must be guaranteed within these limits, and for that reason it
is crucial to run corner simulations (and eventually split lot measurements).
– Passives: caused by metal width or oxide thickness variations. They affect the inductance and
capacitances, and consequently the bandwidth or resonance frequency. As the on-chip
inductance is typically a function of the number of turns, metal width, and other parameters
discussed in Chapter 1, it is expected to vary over process, but not as strongly as devices or
capacitors.
– External components: This includes the supply (or battery), the antenna impedance, external
ﬁlter passband loss or rejection, as well as the crystal. The circuit parameters such as noise or
linearity are typically derived with such variations included. We showed examples of how to
deal with crystal variation in Chapter 9.
As we will discuss shortly, as a part of product qualiﬁcation it is crucial to ensure that the radio
performance is within the limits set by the data sheet when measured across a large number of
VTH, mV
444
372
320
SSS
TTT
FFF
σ = 12mV
Cold
Hot
Target 
(383mV)
Figure 12.71: WAT data for 65nm process
12.7 Transceiver Practical Design Concerns
745

samples including various corner lots, with temperature, voltage, and external component
variations considered.
12.7.6 Product Qualiﬁcation
Prior to entering mass production, the radio must undergo a rigorous set of tests to ensure its
quality. This includes the following steps:
– Characterization over extreme supply, temperature, and corners on a large number of parts.
– ESD (electrostatic discharge) and latch-up test. The ESD test includes HBM (human body
model, which typically covers a single voltage domain), CDM (charged device model that is
between various domains), and MM (machine model).
– Burn-in test at extreme temperatures to ensure reliability. The circuits that undergo large
swings such as VCO or PA are generally of a more concern. To perform the test, a large
number of samples are measured under normal condition, and are left to remain at high
temperature under extreme conditions (for example maximum transmitter power to ensure
PA reliability) for a speciﬁed period of time (say 1000 hours). The devices are subsequently
tested, and are expected to achieve a similar performance. If there is any degradation, that
may be added to the production test limits.
It is not uncommon for RF circuit designers to perform aging simulations on critical blocks.
It anticipates the device degradation when operating under extreme voltage, and produces new
sets of models to reﬂect the aged performance. The design may be modiﬁed accordingly if the
degradation is unacceptable.
– Package qualiﬁcation, including thermal shock and temperature cycles
– Achieving acceptable yield
An example of the test setup for product qualiﬁcation is shown in Figure 12.72.
Many of these tests such as reliability or ESD must be thought of at the very early stages of
the design. Underestimating these requirements may result in extra revisions at later stages,
despite the fact that the part may be perceived to pass the technical speciﬁcations.
Figure 12.72: Product qualiﬁcation setup example
746
Transceiver Architectures

12.7.7 Production Issues
As we mentioned earlier, the production testing is fully automated and is performed to ensure
the quality of the product is within the limits promised in the data sheet. An example of the
automated test equipment is shown in Figure 12.73.
There are several challenges associated with the ATE:
– The ATE environment is very different, often less controllable and more unpredictable,
compared to the DVT environment. This mostly has to do with the automated process, and
the cost concerns associated with it.
– The ATE board is not as optimized and as RF friendly as one would desire. Shown in
Figure 12.73 is an example of the ATE test board.
To stand the mechanical pressure, the board is usually a few inches thick, and has over 30
layers. This results in longer traces, which leads to more inductance on traces. This in turn
causes a few potential issues, such as larger noise ﬁgure, or lower output power. In addition, as
shown on the right, it is much harder to access the pins, for instance to place bypass capacitor
Figure 12.73: An example of ATE
Socket
≈
≈
CBypass
CBypass
Figure 12.74: ATE test board example
12.7 Transceiver Practical Design Concerns
747

on the critical supplies, or to provide low inductance ground. Moreover, a socket must be
inevitably used, as opposed to soldering down the parts as is the case in an actual product,
leading to further performance degradation.
– For cost reasons, it is desirable to perform the ATE testing as quickly as possible. Test times
on the order of a few seconds or less are common. This is another factor that could result in
less predictably as we will see shortly.
We shall discuss how these factors may be quantiﬁed for a product, and present various ways of
dealing with the aforementioned challenges.
ATE-Bench Correlation ─The poor performance of the ATE board, and the environment
less predictability may not be as bad if one can show that the ATE results are consistently worse
than the DVT (or bench). This requires a subtle and often time-consuming process of correlat-
ing the test data between the DVT environment and ATE.
The correlation is typically gauged by the coefﬁcient of correlation or R2, indicating how
well data points ﬁt into a statistical model – sometimes simply a line or curve. Suppose a data
set has values yi, each of which has an associated modeled value fi, where f may be simply a
linear ﬁt. The variability of the data is deﬁned by the total sum of squares as
SSTot =
X
n
i = 1
yi  y
ð
Þ2,
where y is the statistical mean, y = 1
n
Pn
i = 1yi, and n is the number of observations. We also
deﬁne the residual sum of squares as
SSRes =
X
n
i = 1
yi  f i
ð
Þ2:
The coefﬁcient of determination is deﬁned as
R2 = 1  SSRes
SSTot
= 1 
Pn
i = 1 yi  f i
ð
Þ2
Pn
i = 1 yi  y
ð
Þ2 :
A perfect ﬁt results in R2 = 1, but in general: R2  1. An example of a linear ﬁt is shown in
Figure 12.75. The gray squares represent the residual sum of squares (SSRes). The bigger the
squares, the worse the correlation, and the smaller R2 is. As a rule of thumb, we would like R2 to
be greater than 0.8.
f
y
x
Figure 12.75: Description of a linear ﬁt and
the corresponding R2
748
Transceiver Architectures

Examples of the coefﬁcient of determination for an EDGE receiver IIP2 and the noise ﬁgure
are shown in Figure 12.76.
Using a linear ﬁt, for the IIP2 an R2 of 0.976 is calculated, indicating a strong correlation,
evident from the plot, whereas the R2 for the noise ﬁgure test is 0.035. The poor correlation for
the noise ﬁgure is attributed to two factors: First, accurate noise measurements require long
averaging, which is not feasible given the test time concerns; and second, as the noise levels are
generally very low, the measurement is much more sensitive compared to gain or linearity for
instance. Even though the ATE results (shown after de-embedding the losses) are within tenths
of a dB of the bench data, the correlation is poor. As a result, in this case the noise ﬁgure of the
radio must be guaranteed by design to be within the requirements. This is something that may
often need to be thought of at the early stages of the design.
Gauge R&R ─The uncertainty of the ATE environment, often exacerbated by the test time
concerns, is typically determined by gauge R&R (reproducibility and repeatability), indicating
how reliable the measured data are.
Let us consider the 400kHz modulation mask of a GSM transmitter as an example. The
requirement set by the standard is –60dBc. To leave room for the power ampliﬁer contribution
and other production-related concerns, suppose a modulation mask of better than –63dBc is
intended for the radio. This means that every radio shipped, under the extreme conditions
indicated in the data sheet (temperature, frequency, or supply) must have a 400kHz modula-
tion mask of no higher than –63dBc.
By performing more averaging, a more reliable measurement is obtained, and thus a lower
gauge R&R is observed, but at the expense of test time and ultimately cost. Table 12.1 shows a
summary.
As it is common to perform the ATE measurements at room temperature, guard band must be
added to account for the extreme temperature and other possible conditions. In this case of
400kHz mask, the high temperature performance is consistently worse by no more than 0.8dB,
which must be added to the ATE test limit. Furthermore, performing statistical analysis on the
date, it is shown that performing a 50-busrt average results in as much as 0.9dB of variation in the
measured data, for the same part at exact same conditions. This is simply a result of ATE
Figure 12.76: Examples of the coefﬁcient of determination and the noise ﬁgure
12.7 Transceiver Practical Design Concerns
749

measurement uncertainty, which must also be added to the test limit. A lower number of averages
causes a higher gauge R&R. Thus, the actual ATE limit is determined to be –64.7/–65.9dBc for
50-/10-burst averaging.
Shown in Figure 12.77 is the measured 400kHz mask over a large number of parts (over
10000) in the ATE. Evidently, setting a limit of –65.9dBc corresponding to 10 average results
in too big a fallout, and consequently a poor yield. Thus, in this case 50 averages may be
preferred, which results in almost no yield hit, but comes at the expense of longer test time.
This is why higher margins are often desirable.
To reduce test time, if one can ﬁnd a frequency where the 400kHz mask is consistently the
worst, only that frequency may be tested. Otherwise, a range of frequencies (often low, mid,
and high) may be considered. For instance, if the 400kHz modulation is mostly affected by the
phase noise, it may not be unreasonable to assume that the highest frequency that the radio is
intended to operate is the worst case. This must however be statistically established by
performing sufﬁcient testing on a large number of samples prior to reaching mass production.
Table 12.1: Gauge R&R for GSM 400kHz modulation mask
Data Sheet
Limit
Guard
Band
GRR,
10AVG
GRR,
50AVG
ATE Limit,
10AVG
ATE Limit,
50AVG
400kHz
modulation
–63dBc
0.8dB
2.1dB
0.9dB
–65.9dBc
–64.7dBc
500
400
300
200
100
0
-66.7
-66.6
-66.5
-66.4
-66.3
-66.2
-66.1
-66.0
-65.9
-65.8
-65.7
-65.6
-65.5
-65.4
-65.3
-65.3
-65.2
-65.1
-65.0
-64.9
-64.8
-64.7
-64.6
500
400
300
200
100
0
-66.7
-66.6
-66.5
-66.4
-66.3
-66.2
-66.1
-66.0
-65.9
-65.8
-65.7
-65.6
-65.5
-65.4
-65.3
-65.3
-65.2
-65.1
-65.0
-64.9
-64.8
-64.7
-64.6
Figure 12.77: Measured 400kHz modulation in the ATE
750
Transceiver Architectures

12.8 Summary
In this last chapter of the book we covered the transceiver architectures and some practical
aspects of the radio design and related production issues.
– Section 12.1 discussed the general architectural concerns such as noise or blocking
requirements.
– In Section 12.2 we presented various commonly used receiver architectures, including super-
heterodyne, direct-conversion, and image-reject receivers.
– Section 12.3 discussed some of the more recent receiver topologies such as mixer-ﬁrst or
noise-canceling receivers generally known as blocker-tolerant receivers.
– The receiver gain control, ﬁltering requirements, and the ADC specs were discussed in
Sections 12.4 and 12.5.
– Transmitter architectures such direct-conversion, dual-conversion, polar, and out-phasing
topologies were presented in Section 12.6.
– The chapter concluded in Section 12.7, where a case study was presented. Furthermore, in
this section we discussed practical aspects of radio design such as layout, packaging, and
production testing.
12.9 Problems
1. Assuming a 3G transmitter consists of a 2GHz DAC directly connected to the PA, ﬁnd the
DAC effective number of bits. The DAC must put out a power of 0dBm, and the receive
band noise must be better than –160dBc/Hz. The 3G signal has a PAPR of 3dB.
2. An RF DAC serves as a WLAN transmitter with 10dB PAPR. Find the DAC
effective number of bits such that it desensitizes a nearby LTE receiver with 3dB noise
ﬁgure by no more than 1dB. The WLAN transmitter and LTE receiver have 20dB of
isolation.
3. Redo the previous problem if an ADC is used as the receiver. Assume the receiver needs to
have an effective noise ﬁgure of 3dB, and is subject to a nearby WLAN blocker as large
as –20dBm.
4. In a GSM receiver tuned to 950MHz, the IF is at 110MHz (high-side injection). Assuming
a hard-switching differential mixer, identify all the problematic blockers and the ﬁltering
needed. The LNA has an IIP2 of 35dBm, and IIP3 of 0dBm. Everything else is ideal.
5. Redo Problem 4 with low-side injection. Which one is better?
6. Assume a 2.4GHz WLAN receiver is set up to capture the entire 80MHz ISM band,
whereas each channel is only 20MHz wide. Assuming a PAPR of 10dB for 64QAM, and a
required SNR of 22dB to demodulate, calculate the ADC dynamic range for two cases:
a. Only one 20MHz channel is being received
b. The entire 80MHz band is captured
12.9 Problems
751

Assume the signal is accompanied by a –20dBm nearby WLAN blocker, and the
receiver has a noise ﬁgure of 3dB. We do not want the ADC to add more than 1dB of
its own noise to the 3dB noise ﬁgure.
7. Using basic sine-cosine trigonometric properties, show how one sideband is rejected in the
low-IF receiver below.
LOt
w
LOt
w
8. Using basic trigonometric properties, show how the ﬁrst image is canceled in a Weaver
receiver.
9. Find the second image location in a Weaver receiver for all the combinations of low- and
high-side injection for the two LOs.
10. Argue why in the original Weaver architecture the second IF cannot be zero. Propose a
modiﬁed Weaver architecture with the second IF at zero. Discuss the advantages and
disadvantages.
11. The receiver shown below is represented with an input-referred current noise source of
inRX, and has a nominal noise factor of FRX when matched to the nominal source
impedance Rs.
a. Derive and expression for FRX based on the receiver input-referred noise.
b. Find the receiver noise ﬁgure under mismatch, that is, when the source has an arbitrary
input impedance of Zs. Express your result based on source reﬂection coefﬁcient.
Vs
vns
inRX
Rs
Zs
12. Consider the following system where multipliers are ideal and α is an arbitrary phase-shift.
a. Prove that the overall system is LTI with the following impulse response:
h(t) cos(ω0t + α).
752
Transceiver Architectures

b. Prove that this transfer function is the cascade of a system with the impulse response of
h(t) cos ω0t and a Hilbert-like transfer function with magnitude of unity and phase-shift
of +α and α for positive and negative frequencies, respectively.
t
w
t
w
a
t
w
t
w
a
h(t)
h(t)
13. Prove the noise ﬁgure equation of an M-phase mixer-ﬁrst receiver: F  1 + RSW
Rs +
vbb2
4MKTRs
h
i
K.
Hint: Use the simpliﬁed model shown below and work out the noise contributors based on the
analysis we provided for M-phase mixers in Chapter 7.
Rs
RSW
RBB
RBB
RBB
KTRs
KTRSW
v2bb
14. In a dual-conversion receiver with sliding IF, a divide-by-2 is employed to create the second
LO, intended for use in Bluetooth applications with RF input at the ISM band
(2402–2480MHz). Find two possible choices for the LO range, and the IF. Discuss the pros
and cons of each.
15. Repeat Problem 14 if the receiver employs a divide-by-4, and is intended for use in
802.11a applications (5180–5825MHz).
16. Find the GSM ADC requirements for 600kHz and 3MHz blockers, assuming a 1st-order
RC lowpass ﬁlter with 270kHz cut-off. The IF is 135kHz. Which case is more stringent,
and how do they compare to 400kHz adjacent blocker case?
17. Calculate ADC requirements for a WLAN receiver as follows: The required SNR to
demodulate a 20MHz 64QAM OFDM signal with 10dB PAPR is 22dB. The receiver
noise ﬁgure is 3dB in the absence of the ADC noise, and must not degrade by more than
12.9 Problems
753

0.1dB when ADC is present. A desired signal 3dB above the sensitivity may be accom-
panied by a nearby blocker of –20dBm, with 10dB of IF ﬁltering.
18. Assume that in an IQ transmitter the quadrature baseband signals I = A cos θ and Q = A sin θ
are upconverted and combined to generate the RF signal A cos(ω0t + θ) as the PA input.
a. Due to the AM-to-PM nonlinearity of the PA, the actual output is distorted and becomes
A cos(ω0t + θ + F(A)). Prove that the baseband signals need to be predistorted to the
followings to correct this nonlinearity:
Imod = Icos F
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
q




+ Qsin F
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
q




Qmod = Qcos F
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
q




 Isin F
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
q




b. Due to the AM-to-AM nonlinearity of the PA, the actual output is distorted and becomes
F(A)cos(ω0t + θ). Prove that the baseband signals need to be predistorted to the following
to correct this nonlinearity:
Imod = I
F1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
p


ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
p
Qmod = Q
F1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
p


ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I2 + Q2
p
19. Knowing that the pulling in a direct-conversion TX is described as below,
dθ
dt = ω0 + KVCO
ICP
2π
θref  θ
N


∗hLF tð Þ + ω0
2Q
γABB2
IS
sin 2θBB  Ψ
ð
Þ,
propose an architecture that counterbalances the pulling through modifying the transmitter
VCO control voltage. Derive the signal that needs to be applied to VCO. Is this scheme
capable of eliminating the pulling entirely?
12.10 References
[1] J. Mitola, “The Software Radio Architecture,” Communications Magazine, IEEE, 33, no. 5, 26–38, 1995.
[2] E. H. Armstrong, “The Super-heterodyne – Its Origin, Development, and Some Recent Improvements,”
Proceedings of the Institute of Radio Engineers, 12, no. 5, 539–552, 1924.
[3] E. Cijvat, S. Tadjpour, and A. Abidi, “Spurious Mixing of Off-Channel Signals in a Wireless Receiver
and the Choice of IF,” IEEE Transactions on Circuits and Systems II: Analog and Digital Signal
Processing, 49, no. 8, 539–544, 2002.
[4] A. Abidi, “Direct-Conversion Radio Transceivers for Digital Communications,” IEEE Journal of Solid-
State Circuits, 30, no. 12, 1399–1410, 1995.
[5] D. Kaczman et al., “A single-chip 10-bond WCDMA/HSDPA L1-band GSM/EDGE SAW-less CMOS
receiver with digRF 3G interface and 90dBm IIP2,” IEEE Journal of Solid-State Circuits, 44, no. 3,
718–739, 2009.
[6] R. Hartley, “Single-Sideband Modulator.” U.S. Patent No. 1666206, April 1928.
754
Transceiver Architectures

[7] J. Crols and M. Steyaert, “An Analog Integrated Polyphase Filter for a High Performance Low-IF
Receiver,” in Symposium on VLSI Circuits, Digest of Technical Papers, 1995.
[8] D. Weaver, “A Third Method of Generation and Detection of Single-Sideband Signals,” Proceedings of
the IRE, 44, no. 12, 1703–1705, 1956.
[9] M. Zargari, M. Terrovitis, S.-M. Jen, B. J. Kaczynski, M. Lee, M. P. Mack, S. S. Mehta, S. Mendis,
K. Onodera, H. Samavati, et al., “A Single-Chip Dual-Band Tri-Mode CMOS Transceiver for IEEE
802.11 a/b/g Wireless LAN,” IEEE Journal of Solid-State Circuits, 39, no. 12, 2239–2249, 2004.
[10] C. Andrews and A. Molnar, “A Passive Mixer-First Receiver with Digitally Controlled and Widely
Tunable RF Interface,” IEEE Journal of Solid-State Circuits, 45, no. 12, 2696–2708, 2010.
[11] S. Blaakmeer, E. Klumperink, D. Leenaerts, and B. Nauta, “The Blixer, a Wideband Balun-LNA-I/Q-
Mixer Topology,” IEEE Journal of Solid-State Circuits, 43, no. 12, 2706–2715, 2008.
[12] D. Murphy, H. Darabi, A. Abidi, A. Hafez, A. Mirzaei, M. Mikhemar, and M.-C. Chang, “A Blocker-
Tolerant, Noise-Cancelling Receiver Suitable for Wideband Wireless Applications,” IEEE Journal of
Solid-State Circuits, 47, no. 12, 2943–2963, 2012.
[13] Z. Ru, N. Moseley, E. Klumperink, and B. Nauta, “Digitally Enhanced Software-Deﬁned Radio
Receiver Robust to Out-of-Band Interference,” IEEE Journal of Solid-State Circuits, 44, no. 12,
3359–3375, 2009.
[14] M. Soer, E. Klumperink, Z. Ru, F. van Vliet, and B. Nauta, “A 0.2-to-2.0GHz 65nm CMOS Receiver
Without LNA Achieving 11dBm IIP3 and 	6.5dB NF,” in Solid-State Circuits Conference – Digest of
Technical Papers, 2009.
[15] E. Sacchi, I. Bietti, S. Erba, L. Tee, P. Vilmercati, and R. Castello, “A 15mW, 70kHz 1/f Corner Direct
Conversion CMOS Receiver,” in Proceedings of the IEEE Custom Integrated Circuits Conference, 2003.
[16] M. Mikhemar, A. Mirzaei, A. Hadji-Abdolhamid, J. Chiu, and H. Darabi, “A 13.5mA Sub-2.5dB NF
Multi-band Receiver,” in Symposium on VLSI Circuits, 2012.
[17] F. Bruccoleri, E. Klumperink, and B. Nauta, “Wide-Band CMOS Low-Noise Ampliﬁer Exploiting
Thermal Noise Canceling,” IEEE Journal of Solid-State Circuits, 39, no. 2, 275–282, 2004.
[18] D. Murphy et al., “A Noise-Cancelling Receiver Resilient to Large Harmonic Blockers,” IEEE Journal of
Solid-State Circuits, 50, 1336–1350, 2015.
[19] H. Darabi, P. Chang, H. Jensen, A. Zolfaghari, P. Lettieri, J. Leete, B. Mohammadi, J. Chiu, Q. Li, S.-L.
Chen, Z. Zhou, M. Vadipour, C. Chen, Y. Chang, A. Mirzaei, A. Yazdi, M. Nariman, A. Hadji-
Abdolhamid, E. Chang, B. Zhao, K. Juan, P. Suri, C. Guan, L. Serrano, J. Leung, J. Shin, J. Kim,
H. Tran, P. Kilcoyne, H. Vinh, E. Raith, M. Koscal, A. Hukkoo, C. Hayek, V. Rakhshani, C. Wilcoxson,
M. Rofougaran, and A. Rofougaran, “A Quad-Band GSM/GPRS/EDGE SoC in 65nm CMOS,” IEEE
Journal of Solid-State Circuits, 46, no. 4, 870–882, 2011.
[20] A. Mirzaei and H. Darabi, “Mutual Pulling between Two Oscillators,” IEEE Journal of Solid-State
Circuits, 49, no. 2, 360–372, 2014.
[21] R. Adler, “A Study of Locking Phenomena in Oscillators,” Proceedings of the IEEE, 61, no. 10,
1380–1385, 1973.
[22] A. Mirzaei and H. Darabi, “Pulling Mitigation in Wireless Transmitters,” IEEE Journal of Solid-State
Circuits, 49, no. 9, 1958–1970, 2014.
[23] H. Darabi, S. Khorram, H.-M. Chien, M.-A. Pan, S. Wu, S. Moloudi, J. Leete, J. Rael, M. Syed, R. Lee,
B. Ibrahim, M. Rofougaran, and A. Rofougaran, “A 2.4-GHz CMOS Transceiver for Bluetooth,” IEEE
Journal of Solid-State Circuits, 36, no. 12, 2016–2024, 2001.
[24] H. Darabi, J. Chiu, S. Khorram, H. J. Kim, Z. Zhou, Hung-Ming Chien, B. Ibrahim, E. Geronaga, L. Tran,
and A. Rofougaran, “A Dual-Mode 802.11b/Bluetooth Radio in 0.35-um CMOS,” IEEE Journal of Solid-
State Circuits, 40, no. 3, 698–706, 2005.
[25] O. Erdogan, R. Gupta, D. Yee, J. Rudell, J.-S. Ko, R. Brockenbrough, S.-O. Lee, E. Lei, J. L. Tham,
H. Wu, C. Conroy, and B. Kim, “A Single-Chip Quad-Band GSM/GPRS Transceiver in 0.18um Standard
CMOS,” in Solid-State Circuits Conference, 2005. Digest of Technical Papers, 2005.
12.10 References
755

[26] P.-H. Bonnaud, M. Hammes, A. Hanke, J. Kissing, R. Koch, E. Labarre, and C. Schwoerer, “A Fully
Integrated SoC for GSM/GPRS in 0.13um CMOS,” in Solid-State Circuits Conference, 2006. Digest of
Technical Papers, 2006.
[27] R. Staszewski, J. Wallberg, S. Rezeq, C.-M. Hung, O. Eliezer, S. Vemulapalli, C. Fernando, K. Maggio,
R. Staszewski, N. Barton, M.-C. Lee, P. Cruise, M. Entezari, K. Muhammad, and D. Leipold, “All-Digital
PLL and Transmitter for Mobile Phones,” IEEE Journal of Solid-State Circuits, 40, no. 12, 2469–2482,
2005.
[28] R. Staszewski, D. Leipold, O. Eliezer, M. Entezari, K. Muhammad, I. Bashir, C.-M. Hung, J. Wallberg,
R. Staszewski, P. Cruise, S. Rezeq, S. Vemulapalli, K. Waheed, N. Barton, M.-C. Lee, C. Fernando,
K. Maggio, T. Jung, I. Elahi, S. Larson, T. Murphy, G. Feygin, I. Deng, T. Mayhugh, Y.-C. Ho,
K.-M. Low, C. Lin, J. Jaehnig, J. Kerr, J. Mehta, S. Glock, T. Almholt, and S. Bhatara, “A 24mm2
Quad-Band Single-Chip GSM Radio with Transmitter Calibration in 90nm Digital CMOS,” in Solid-State
Circuits Conference, 2008. Digest of Technical Papers, 2008.
[29] Z. Boos, A. Menkhoff, F. Kuttner, M. Schimper, J. Moreira, H. Geltinger, T. Gossmann, P. Pfann,
A. Belitzer, and T. Bauernfeind, “A Fully Digital Multimode Polar Transmitter Employing 17b RF DAC
in 3G Mode,” in Solid-State Circuits Conference Digest of Technical Papers, 2011.
[30] H. Darabi, H. Jensen, and A. Zolfaghari, “Analysis and Design of Small-Signal Polar Transmitters for
Cellular Applications,” IEEE Journal of Solid-State Circuits, 46, no. 6, 1237–1249, 2011.
[31] M. Youssef, A. Zolfaghari, B. Mohammadi, H. Darabi, and A. Abidi, “A Low-Power GSM/EDGE/
WCDMA Polar Transmitter in 65-nm CMOS,” IEEE Journal of Solid-State Circuits, 46, no. 12,
3061–3074, 2011.
[32] M. Wakayama and A. Abidi, “A 30-MHz Low-Jitter High-Linearity CMOS Voltage-Controlled
Oscillator,” IEEE Journal of Solid-State Circuits, 22, no. 6, 1074–1081, 1987.
[33] H. Chireix, “High Power Outphasing Modulation,” Proceedings of the Institute of Radio Engineers, 23,
no. 11, 1370–1392, 1935.
[34] D. Cox and R. Leck, “Component Signal Separation and Recombination for Linear Ampliﬁcation with
Nonlinear Components,” IEEE Transactions on Communications, 23, no. 11, 1281–1287, 1975.
[35] J. Qureshi, M. Pelk, M. Marchetti, W. Neo, J. Gajadharsing, M. van der Heijden, and L. de Vreede, “A 90-
W Peak Power GaN Outphasing Ampliﬁer with Optimum Input Signal Conditioning,” IEEE Transactions
on Microwave Theory and Techniques, 57, no. 8, 1925–1935, 2009.
[36] S. Moloudi and A. Abidi, “The Outphasing RF Power Ampliﬁer: A Comprehensive Analysis and a Class-
B CMOS Realization,” IEEE Journal of Solid-State Circuits, 48, no. 6, 1357–1369, 2013.
756
Transceiver Architectures

INDEX
ΔΣ modulator, 621, 624
ΔΣ modulator noise, 622, 630
ΔΣ modulator nonideal effects, 626
1/f noise, 292, 449
1/f noise in passive mixers, 478, 603
1dB compression, 357
25% LO, 466
25% mixer, 467
25% upconversion mixer, 489
50Ω, 174
8-phase divide by 4, 637
accumulation-mode MOS capacitor, 44
active ﬁlters, 238
active ﬁlters ladder design, 238
active ﬁlters nonideal effects, 245
active mixer, 461
active mixer 2nd-order distortion, 457
active mixers, 445
active mixers 1/f noise, 479
active mixers linearity, 448
active mixers white, 452
active polyphase ﬁlters, 263
active upconversion mixer, 486
active upconverter, 487
active-RC integrator, 240
adjacent channel leakage ratio, 369
adler’s differential equation, 379
all-pole transfer function, 230
AM sideband, 524–525
AM–AM, 375
Ampere’s circuital law, 5
amplitude modulation, 110
amplitude noise, 521
AM–PM, 375
AM–PM nonlinearity, 731
analog multiplier, 444
antenna, 36
antenna characteristics, 36
antenna directivity, 42
antenna effective area, 177
antenna efﬁciency, 43
antenna gain, 43
antenna radiation resistance, 41
antennas as two-port circuits, 176
approximation theory, 221
ATE, 747
attenuator, 188
autocorrelation, 96
automatic testing equipment (ATE), 734
available power, 139
available power gain, 191, 191
available power gain, reciprocal networks,
142
backed off, 370
balanced AM modulator, 113
band-limited white noise, 346
bandpass ﬁlter, 236
bandpass LC ﬁlter, 234
Bank’s general result, 536
baseband signal, 110
basic receiver topology, 693
Bessel functions, 118
biconjugate matching, 148, 163
Biot–Savart, law, 5
biquad, 243
blocker, 333
blocker-tolerant receiver, 707
bonding pads, 743
Brownian motion, 279
buck converter, 678
bulk acoustic wave, 248
bumps, 743
burn-in test, 746
Butterworth, 223
Butterworth ﬁlter, 213, 234
capacitance, 4
capacitive coupling, 427
capacitor lumped model, 45
capacitor noise, 285
carrier, 439
carrier frequency, 110
cartesian transmitter, 486
cascode LNA, 405
cellular network, 332
central limit theorem, 98
characteristic function, 213
characteristics impedance, 15, 31
charge, 2
charge pump, 602
charge pump, 604
charge pump modeling, 605
charge pump nonlinearity, 627
Chebyshev ﬁlter, 227
Chebyshev polynomial, 227
Chireix combiner, 733
circulators, 192
circulators in full-duplex radios, 194
class A PA, 654
class A PA with gain control, 656
class B PA, 656
class C oscillator, 564
class C PA, 660
class C PA efﬁciency, 661
class D digital PA, 665
class D PA, 662
class D–1 PA, 663
class E PA, 669
class F PA, 672
class-A PA efﬁciency, 655
CMOS oscillator, 544
CMOS oscillator noise factor, 521
coaxial cable, 3
coaxial cable capacitance, 5
coaxial shield, 428
coexistence, 336
Colpitts oscillator, 546
Colpitts oscillator noise factor, 521
common-source LNA, 398
common-gate LNA, 400
complementary ampliﬁer, 394
complementary shunt feedback LNA,
403
compression, 357
compressive, 338
conjugate matching, 141, 652
Coulomb’s law, 2
coupling, 427
coupling and shielding, 427
cross-modulation, 352
crystal electrical model, 582
crystal model, 582
crystal oscillator, 581
crystal overdriving, 585
crystal poles and zeros, 584
cubic pre-distorter, 674

current switching, 442, 445
current-mode mixer, 471
current-mode passive mixer, 462
current-mode receiver, 707
cyclostationary noise, 293, 527
cyclostationary process, 108
D ﬂip ﬂop, 633
DC gain, 394
DC–DC converter, 678
dead-zone, 602
decoupling capacitors, 425
demodulation, 110
desensitization, 358
device veriﬁcation and testing (DVT), 734
differential class A PA, 656
differential inductors, 56
differential two-ports, 168
digital loop ﬁlter, 644
digital PA, 666
digital PLL, 640
digital PLL linear analysis, 646
digitally controlled oscillator (DCO), 645
diode-ring mixer, 442
dipole, 38
direct-conversion, 379
direct-conversion transmitter, 720
direct-modulation transmitter, 723
discrete tuning, 47
distributed circuits, 13
divide-by-2, 633
divide-by-2/3, 634
divide-by-4/5, 635
Doherty PA, 682–683
double side-band noise, 454
doublet, 84
doubly terminated, 208
downconversion mixer, 441
drain efﬁciency, 653
dual-conversion receiver, 706
dual-conversion transmitter, 722
dual-modulus divider, 634
duplexer, 253
dynamic CMOS ﬂip ﬂop, 633
dynamic CMOS latch, 632
efﬁciency, 652
efﬁciency of class A and B PAs, 658
electric energy, 3
electric ﬁeld, 2
electric ﬁeld intensity, 2
electric ﬂux density, 2
electrical balance duplexer, 254
electromechanical, 249
electromotive force (emf ), 9
electrostatic discharge (ESD), 746
electrostatic energy, 15
emitter-coupled pair, 446
EMX, 54
energy conservation, 22
envelope elimination and restoration,
675
envelope tracking, 676, 681
equal ripple, 223, 226
equipartition law, 279, 281
ergodicity, 97
error vector magnitude, 371
error vector magnitude (EVM),
371
excess noise ratio, 323
expected value, 96
Faraday cage, 4, 427
Faraday’s law, 9
FBAR oscillator, 581, 588
FBAR resonator, 251
FBGA package, 743
feedback, 511
feedback divider, 611
feedback oscillator model, 511
feedback system nonlinearity, 354
feedforward LNA, 410
feedforward noise canceling LNA,
411
ferrites, 132, 136
FET-based mixer, 443
FET-equivalent input noise, 297
FET IIP3, 340–341
FET thermal noise, 289
ﬁfth-order distortion, 350
ﬁlter scaling, 233
ﬁltered random process, 106
ﬂicker noise, 292
FM bandwidth, 116
FM noise, 523
Fourier series, 81
Fourier transform, 80
Fourier transform of periodic signals,
85
Fourier transform properties, 82
four-phase LO, 467
fractional divider, 619
fractional spurs, 620
fractional-N synthesizer, 611, 619
frequency deviation, 116
frequency divider, 630
frequency modulation, 115
frequency noise, 521
Friis transmission formula, 179
fringe capacitance density, 46
fringe capacitor, 45
fringe capacitors, 44
full-duplex, 335
full-duplex division, 335
gain compression, 357
gain method noise measurement,
322
gate resistance, 413
Gauss’s law, 2
Gaussian process, 98
Gilbert mixer, 445
Gilbert multiplier, 444
gm-C integrator, 240
Groszkowski effect, 560
GSM, 333
gyration ratio, 137
gyrator, 136
half-IF blocker, 364
hard limiter, 102
harmonic distortion, 336
harmonic folding, 491
harmonic mixing, 363
harmonic rejection mixer, 364
Hartley image-reject receiver,
701
Helmholtz equation, 28
Hertzian dipole, 36
high-side injection, 363
Hilbert transform, 93, 440
ideal ﬁlter, 207
ideal transformer, 58
IIP2, 345
IIP3, 337
IIP3 of cascade of stages, 343
image, 438
image and half-IF blockers, 694
image blocker, 364
image in zero-IF receiver, 695
image rejection, 702
image-reject receiver, 440
impedance transformation, 149
impulse, 83
impulse response, 86
in-band blockers, 333
inductance, 5
inductively degenerated CS LNA, 432,
409
inductor lumped model, 61
inductor noise, 285
inductor Q deﬁnitions, 66
inductor shield, 429
initial value theorem, 288, 512
input intercept point, 337
instantaneous frequency, 116
instantaneous spectral density, 293
integer-N synthesizer, 612
integrated capacitors, 43
integrated inductors, 47
interferer, 333
758
Index

intermediate frequency, 438
inverter phase noise, 574
IQ mismatch, 697
IQ pre-distorter, 675
latch, 631
LC ﬁlter design, 229
LC ﬁlters, 208
LC oscillator, 511
Leeson, 512
Leeson’s phase noise expression,
515
Lenz’s law, 10
linear LC oscillator, 511
Linvil stability factor, 146
LNA biasing, 416
LNA case study, 431
LNA gain control, 420
LNA linearity, 417
LNA practical concerns, 413
LNA/mixer case study, 494
LO duty cycle, 462
LO feed-through, 373
local shunt feedback, 401
loop ﬁlter, 596
Lorentz theorem, 132
Lorentzian, 292
loss poles, 220
lossless LC circuit, 17
lossless matching, 388
lossless matching network, 388
lossless reciprocal network, 144
lossless transmission, 166
lossy LC circuit energy, 19
lossy transmission line, 173
low-IF receiver, 701
low-noise transconductance ampliﬁer,
495
low-side injection, 363
lumped circuits, 13
magnetic coupling, 419, 428
magnetic energy, 15
magnetic ﬁeld, 5
magnetic ﬁeld intensity, 5
magnetic ﬂux, 7
magnetic ﬂux density, 7
MASH, 626
matching, 150, 387
matching network, 150
matching network in PA, 653
maximally ﬂat, 223
maximum power gain, 147
Maxwell’s equations, 10
Maxwell–Boltzmann statistics,
280
metal shield, 55
minimum NF, 303
mixer 2nd-order distortion, 480
mixer basic operation, 438
mixer conversion gain, 465, 470
mixer design methodology, 500
mixer impedance transformation,
473
mixer noise spectrum, 452
mixer operation, 440
mixer with active load, 456
mixer-ﬁrst receiver, 709
modulated spectrum, 110
modulation, 110
modulation index, 111, 117
modulation mask, 366
MOS gate capacitance, 43
MOS gm/ID, 396
M-phase mixer, 467
multi-modulus divider, 638
multi-path fading, 332
multi-turn inductor, 51
multi-turn inductors, 51
narrowband FM, 117
narrowband transformers, 165
native layer, 55
network function, 88
NMOS oscillator, 540
NMOS oscillator noise factor, 542
noise bandwidth, 283
noise-canceling receiver, 710
noise circles, 304
noise ﬁgure, 299
noise ﬁgure, double or single sideband,
454
noise ﬁgure measurement, 322
noise ﬁgure of a FET, 301
noise ﬁgure of a passive lossy network,
302
noise ﬁgure of cascade of stages,
312
noise ﬁgure versus return loss, 399
noise ﬁgure, impact of feedback, 309
noise shaping, 620
noise-canceling LNA, 412
noise-shaping waveform, 527
nonlinear capacitance, 554, 556, 558
nonlinear LC oscillator, 517
nonlinear oscillator, 520
normal process, 98
N-path ﬁlters, 255
Nyquist theorem, 285
one-port, 130
one-port oscillator, 539
optimum noise impedance, 303
oscillation amplitude, 521
oscillator efﬁciency, 515
oscillator feedback model, 511
oscillator ﬁgure of merit, 516
oscillator frequency modulation,
554
oscillator noise factor, 537
oscillator power conservation, 519
oscillator Q degradation, 551
oscillator supply pushing, 561
out-of-band blockers, 333
outphasing transmitter, 732
PA dynamic biasing, 681
PA linearization, 673
packaging concerns, 743
Paley–Wiener criterion, 207
parallel resonance circuit, 87
parallel to series impedance
transformation, 160
parallel-mode crystal oscillator, 586
parallel–series circuit, 159
Parseval’s energy theorem, 81
passive lossless feedback, 310
passive lossy network noise, 285
passive mixer, 460
passive mixer linearity, 479
passive mixer noise, 478
passive polyphase ﬁlters, 260
passive upconversion mixer, 488
patterned shield, 55
peak-to-average ratio, 370
Pierce crystal oscillator, 586
permeability, 7
permittivity, 2
phase constant, 167
phase detector, 596–597
phase modulation, 115
phase noise, 316, 359, 521
phase noise deﬁnition, 514
phase noise in the linear oscillator,
512
phase noise of nonlinear LC oscillator,
521
phase velocity, 167
phase-frequency detector, 598, 602
piece of wire inductance, 47
PLL transfer function, 600, 608
PM noise, 523
PM sideband, 524–525
polar transmitter, 726
poles, 88
poles and zeros physical interpretation,
220
polyphase ﬁlter, 262
positive real, 217
potential difference, 3
power added efﬁciency, 653
Index
759

power integrity, 425
power spectral density, 103
power spectrum, 103
practical LC resonator, 18
pre-distortion, 673
probability density function, 95
product design ﬂow, 735
product qualiﬁcation, 746
propagation velocity, 14
pulling in direct-conversion transmitters,
721
pulling, 379
pulse amplitude modulated, 108
pulse-width modulation, 664
push–pull class B PA, 658
Poynting vector, 34
quadrature downconversion, 439, 463
quadrature ﬁlters, 93, 260
quadrature generation, 266
quadrature mixer, 464
quadrature oscillator, 577
quadrature receiver, 695
quadrature signals, 93
quality factor, 18–19, 66, 550
realizability conditions, 219
realizable impedance, 217
receiver ADC design, 715
receiver ADC requirements, 716
receiver architectures, 692
receiver ﬁltering, 715
receiver gain control, 718
reciprocal, 132
reciprocal mixing, 360–361
reciprocal two-port, 132
reciprocity criteria, 133
reciprocity proof, 135
reciprocity theorem, 134
rectangular pulse, 81
reference divider, 611
reference noise transfer function,
616
reﬂected power, 153, 212
reﬂection coefﬁcient, 152, 168
reﬂection factor, 152, 211
resistive feedback LNA, 403
RF ampliﬁer, 392
RF common-gate ampliﬁer, 397
RF common-source ampliﬁer, 397
RF to LO feedthrough, 481
RF tuned ampliﬁer, 392
ring oscillator, 566
ring oscillator noise, 572
SAW resonator, 251
scattering parameters, 185
second-order distortion, 344, 698
self-mixing, 458, 698
self-resonance frequency, 51
sensitivity, 317
series feedback, 406
series feedback LNA, 405
series-mode crystal oscillator,
585
shield, 425
shielding, 427
shifted process, 109
shoot-through, 664
shunt feedback, 402
shunt feedback LNA, 401
signal integrity, 425
sinc function, 80
single sideband (SSB), 525
single sideband (SSB) noise,
454
single-balanced mixer, 448
single-sideband AM, 113
single-sideband receivers, 121
skin depth, 32
skin effect, 31, 48
small signal nonlinearity, 336
Smith chart, 180
software-deﬁned radio, 691
solenoid, 8
spatial frequency, 167
spectral regrowth, 368
spectrum, 80
spiral inductors, 50
spot noise ﬁgure, 322
spurious free dynamic range, 356
square-wave-like LO, 455
stability of two-port ampliﬁers,
145
stacked inductors, 52
standing wave, 169
static CMOS latch, 631
stationary noise, 294, 523, 527
stationary processes, 97
Stieltjes continued fraction, 230
stochastic processes, 95
stopband ﬁlter, 229
substrate loss in inductors, 52
substrate noise, 415
superheterodyne receiver, 693
surface acoustic wave, 248
switched capacitor digital PA, 668
switching spectrum, 374
synthesizer, 612
synthesizer noise sources, 615
system-on-a-chip (SoC), 741
tank, 511
tank Q, 550
Tellegen’s theorem, 135, 138
terminated transmission lines, 168
thermal noise, 299
thermal noise spectral density, 281
thermal noise variance, 282
third-order nonlinearity, 338
time division multiple access, 373
time-duplex division, 335
time-to-digital converter (TDC), 642
time-varying ﬁelds, 9
transceiver practical design concerns, 734
transducer factor, 212
transducer loss, 221
transducer parameters, 214, 211
transducer parameters properties, 216
transformer modeling, 69
transformers, 58, 156
transformers, integrated, 58
transimpedance ampliﬁer (TIA), 482,
497
translational loop, 724
transverse electromagnetic (TEM),
28
transmission line, 13, 166
transmission lines transient response,
171
transmission zeros, 220
transmitter architectures, 719
transmitter mask, 365
transmitter mixer, 486
transmitter nonlinearity, 364
traveling wave, 169
twisted pair, 429
two-phase LO, 467
two-port, 130
two-port equivalent noise, 296
two-port oscillator, 539
two-port stability using, 194
type I PLL, 598, 599
type I PLL linear model, 599
type II PLL, 601
type II PLL analysis, 607
types of noise, 279
uniform plane wave, 26
unilateral two-port, 140
upconversion mixer, 442
uppressed-carrier double-sideband
modulation, 110
760
Index

varactor, 556
VCO drift, 596
VCO noise transfer function, 616
vector magnetic potential, 37
V–I converter, 448
voltage standing wave ratio, 169
voltage switching, 442
voltage-mode passive mixer,
484
wave propagation, 14, 26
wavelength, 13, 29
WCSP package, 743
Weaver receiver, 705
white noise, 283
wideband impedance transformation,
156
Wien bridge oscillator, 90
Wiener–Khinchin theorem, 104
Wilkinson power combiner, 659
XOR gate, 597
XOR phase detector, 597
Y-factor noise measurement, 323
zero-IF receiver, 694
zeros, 88
Index
761


